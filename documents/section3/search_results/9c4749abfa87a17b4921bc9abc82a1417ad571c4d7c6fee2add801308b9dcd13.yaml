- DOI: https://doi.org/10.3390/agronomy10010140
  analysis: '>'
  authors:
  - Deepak Gautam
  - Vinay Pagay
  citation_count: 36
  full_citation: '>'
  full_text: ">\nagronomy\nReview\nA Review of Current and Potential Applications\
    \ of\nRemote Sensing to Study the Water Status of\nHorticultural Crops\nDeepak\
    \ Gautam\nand Vinay Pagay *\nSchool of Agriculture, Food and Wine, The University\
    \ of Adelaide, PMB 1, Glen Osmond, SA 5064, Australia;\ndeepak.gautam@adelaide.edu.au\n\
    * Correspondence: vinay.pagay@adelaide.edu.au; Tel.: +61-8-83130773\nReceived:\
    \ 25 August 2019; Accepted: 9 January 2020; Published: 17 January 2020\n\x01\x02\
    \x03\x01\x04\x05\x06\a\b\x01\n\x01\x02\x03\x04\x05\x06\a\nAbstract: With increasingly\
    \ advanced remote sensing systems, more accurate retrievals of crop water\nstatus\
    \ are being made at the individual crop level to aid in precision irrigation.\
    \ This paper summarises\nthe use of remote sensing for the estimation of water\
    \ status in horticultural crops. The remote\nmeasurements of the water potential,\
    \ soil moisture, evapotranspiration, canopy 3D structure, and\nvigour for water\
    \ status estimation are presented in this comprehensive review. These parameters\n\
    directly or indirectly provide estimates of crop water status, which is critically\
    \ important for irrigation\nmanagement in farms. The review is organised into\
    \ four main sections: (i) remote sensing platforms;\n(ii) the remote sensor suite;\
    \ (iii) techniques adopted for horticultural applications and indicators of\n\
    water status; and, (iv) case studies of the use of remote sensing in horticultural\
    \ crops. Finally, the\nauthors’ view is presented with regard to future prospects\
    \ and research gaps in the estimation of the\ncrop water status for precision\
    \ irrigation.\nKeywords: UAS; UAV; drone; unmanned; satellite; water stress; irrigation;\
    \ vegetation index\n1. Introduction\nUnderstanding the water status of crops is\
    \ important for optimal management and application\nof water to accommodate for\
    \ inter and intra-ﬁeld variability to achieve a speciﬁc target, such as\nmaximum\
    \ water use eﬃciency, yield, quality, or proﬁtability [1,2]. The importance of\
    \ optimal water\nmanagement in agriculture in semi-arid or arid regions has become\
    \ increasingly important in light\nof recent water scarcities through reduced\
    \ allocations, as well as increased demand due to greater\nareas under production\
    \ [3,4]. Climate change is expected to further intensify the situation due to\n\
    the increased frequency of heatwaves and drought episodes [5]. Climate change\
    \ coupled with the\nnecessity to increase food production due to an increase in\
    \ global population has placed pressure on\nhorticultural sector to improve eﬃciencies\
    \ in resources use, e.g., water, for sustainable farming [6–10].\nHorticultural\
    \ crops will have to produce more ‘crop-per-drop’ in the face of limited water\
    \ resources.\nInformed management of water resources whilst maintaining or increasing\
    \ crop quality and yield are\nthe primary goals of irrigation scheduling in horticulture.\
    \ These goals can be achieved by improving\nour understanding of the water status\
    \ of the crops at key phenological stages of development.\nTraditional decision-making\
    \ for irrigation of horticultural crops includes using information from\na combination\
    \ of sources such as historical regimes, soil moisture measurements, visual assessments\
    \ of\nsoil and/or crop, weather data including evapotranspiration (ET), and measurements\
    \ of crop water\nstatus using direct-, proximal- or remote-sensing techniques\
    \ [11–13]. Some growers undertake routine\nground-based measurements, e.g., pressure\
    \ chamber, for estimation of crop water status to make\ndecisions on irrigation\
    \ [14–16]. These ground-based measurements are robust; however, destructive,\n\
    Agronomy 2020, 10, 140; doi:10.3390/agronomy10010140\nwww.mdpi.com/journal/agronomy\n\
    Agronomy 2020, 10, 140\n2 of 35\ncumbersome, and expensive to acquire a reasonable\
    \ amount of data [14,16–18]. Consequently, the\nmeasured leaf is assumed to represent\
    \ the average population of leaves of the individual crop, and\na few crops are\
    \ assumed to represent the average population of the entire irrigation block.\
    \ As a\nresult, over- or under-watering can occur, which can lower yield and fruit\
    \ quality [19–22]. This is\nespecially evident for non-homogenous blocks where\
    \ spatial variability of soil and water status is\nexpected [23–25].\nTo address\
    \ some of the limitations of ground-based measurements, remote measurement\ntechniques\
    \ were introduced with capabilities to measure at higher spatial resolution, larger\
    \ area, and\non a regular basis [26–29]. Remote sensing, in particular, unmanned\
    \ aircraft systems (UAS), presents a\nﬂexible platform to deploy on-demand sensors\
    \ as a tool to eﬃciently and non-destructively measure\ncrop water status [30].\
    \ Using thermal and spectral signatures, remote sensing techniques can be used\n\
    to characterise a crop’s water status. Knowledge of crop water status allows growers\
    \ to more eﬃciently\nschedule irrigation (i.e., when and how much water to apply).\
    \ In this regard, UAS platforms provide a\nconvenient methodology to monitor the\
    \ water status across a farm, both spatially and temporally at\nthe canopy level\
    \ [31–33]. The spectral, spatial, and temporal ﬂexibility oﬀered by UAS-based\
    \ remote\nsensing may in future assist growers in irrigation decision-making [34,35].\n\
    This review provides an overview of the application of remote sensing to understand\
    \ the\ncrop’s water status (e.g., leaf/stem water potential, leaf/canopy conductance),\
    \ soil moisture, ET, and\nphysiological attributes, all of which can contribute\
    \ to understanding the crop’s water status to\nimplement precision irrigation.\
    \ Although the key focus of this review is UAS-based remote sensing,\na comparison\
    \ has been undertaken with other remote sensing platforms, such as earth observation\n\
    satellites, which are being increasingly used to acquire similar information.\
    \ In the following sections,\nwe provide an overview of the most common remote\
    \ sensing platforms in horticulture, various sensors\nused for remote sensing,\
    \ and several predictive indices of crop water status. Two case studies of remote\n\
    sensing in horticultural crops, grapevine and almond, are then presented followed\
    \ by an overview of\nthe current research gaps and future prospects.\n2. Remote\
    \ Sensing Platforms\nGround-based direct or proximal sensors acquire instantaneous\
    \ water status measurement from\na spatial location. For decision-making purposes,\
    \ the data is generally collected from multiple\nlocations across a ﬁeld, which\
    \ allows geospatial interpolation, such as kriging, to be applied [36–38].\nThis\
    \ scale of data collection is, however, cumbersome, ineﬃcient, and error-prone,\
    \ especially for water\nstatus measurements of large areas [17]. Monitoring and\
    \ observing farms at a larger spatial scale\nprompted the launch of several earth\
    \ observation satellite systems that typically operate at an altitude\nof 180–2000\
    \ km [39]. Manned high-altitude aircraft (operating within few km) and, more recently,\
    \ UAS\n(operating under 120 m) ﬁlled the spatial gap between high-resolution ground\
    \ measurements and\nrelatively low-resolution satellite measurements [40,41].\
    \ In the context of water status estimation for\nhorticultural crops, all the\
    \ aforementioned remote sensing platforms are utilised depending on the\nuser\
    \ requirements [23,42,43]. Each remote sensing platform has its own advantage\
    \ and shortcomings.\nThe decision to obtain remote sensing crop water status data\
    \ from one or more of these platforms will\ndepend on the spatial and temporal\
    \ resolution desired. Satellite and manned aircraft can be useful\nfor regional-scale\
    \ characterisation, whereas UAS can be more useful to map the intra-ﬁeld variability.\n\
    Vehicle-based ground systems also possess similar measurement capabilities, like\
    \ remote sensing,\nhowever, at a smaller scale [44,45]. These systems can move\
    \ within the horticultural rows obtaining\nwater status measurements of adjacent\
    \ plants while the vehicle is moving, enabling them to cover a\nrelatively larger\
    \ area as compared to ground-based direct measurements [46–48].\n2.1. Satellite\
    \ Systems\nThe use of satellite systems for remote sensing started with the launch\
    \ of Landsat-1 in 1972 [39,49].\nThe subsequent launch of SPOT-1 in 1986 and Ikonos\
    \ in 1999 opened the era of commercial satellite\nAgronomy 2020, 10, 140\n3 of\
    \ 35\nsystems that resulted in rapid improvement in imaging performance, including\
    \ spatial and spectral\nresolution [50]. Continued launch of satellites from the\
    \ same families, with newer sensor models\nand improved capability, resulted in\
    \ the formation of satellite constellations (e.g., Landsat, Sentinel,\nSPOT, RapidEye,\
    \ GeoEye/WorldView families). The satellite constellation substantially improved\
    \ the\nrevisit cycle of the satellite system [51]. Recently, the miniature form\
    \ of the satellite termed Nanosat or\nCubesat has been developed, which can be\
    \ deployed on the same orbit in a large number (20s–100s),\nenabling frequent\
    \ and high-resolution data acquisition (e.g., Dove satellite from Planet Labs)\
    \ [52].\nThe earth observation satellite system, such as Landsat, Sentinel, MODIS,\
    \ RapidEye, and GeoEye,\nhave been used to study horticultural crops (Table 1).\
    \ These satellite system oﬀer camera systems\nwith spectral bands readily available\
    \ in visible, near infrared (NIR), short-wave infrared (SWIR), and\nthermal infrared\
    \ (TIR). The measurement in these bands provides opportunities to study a crop’s\
    \ water\nstatus indirectly via, for example, calculation of the normalised diﬀerence\
    \ vegetation index (NDVI),\ncrop water stress index (CWSI), and ET [8–10] at the\
    \ ﬁeld- and regional-scales.\nTable 1. Some satellite systems that have been used\
    \ to study the water status of horticultural crops.\nSatellites\nBand Numbers:\
    \ Band Designation\nSpatial Resolution (m)\nRevisit Cycle\nLandsat 7\n8: V 3,\
    \ NIR 1, SWIR 2, TIR 1, Pan 1\n15–60\n16 days\nLandsat 8\n11: C 1, V 3, NIR 1,\
    \ SWIR 2, Pan 1, Ci 1, TIR 2\n15–100\n16 days\nSentinel-2\n13: C 1, V 3, RE 3,\
    \ NIR 2, WV 1, Ci 1, SWIR 2\n10–60\n5 days\nSpot-6 and-7\n5: Pan 1, V 3, NIR 1\n\
    1.5\n1 day\nRapidEye\n5: V 3, NIR 1, RE 1\n5\n5.5 days\nGeoEye-1\n5: Pan 1, V\
    \ 3, NIR 1\n0.41–2\n3 days\nNote: Superscript integers 1, 2, 3 represent the number\
    \ of bands; V = visible, NIR = near infrared, SWIR = short-wave\ninfrared, TIR\
    \ = thermal infrared, Pan = panchromatic, C = coastal, Ci = cirrus, RE = red edge,\
    \ WV = water vapour.\nThe reﬂected/emitted electromagnetic energy from the crop\
    \ reaching the sensor is recorded at a\nspeciﬁc wavelength. The width of the observed\
    \ wavelength expressed in full width at half maximum\n(FWHM) is called spectral\
    \ resolution. The number of observed bands and the spectral resolution\nindicates\
    \ the ability of the satellite to resolve spectral features on the earth’s surface.\
    \ Commonly used\nearth observation satellite systems possess between four and\
    \ 15 bands with approximately 20–200 nm\nFWHM spectral resolution. The bands are\
    \ generally designated for the visible and NIR region with\nextended capabilities\
    \ in SWIR, TIR, as well as red edge region (Table 1). The most widely used band\n\
    combinations to study the water status of vegetation are the visible, NIR and\
    \ TIR bands [23,25,53,54].\nWith the plethora of satellite systems currently available,\
    \ user requirements on band combination\nmay be achieved by using multiple satellites.\
    \ However, acquiring an extra or a narrower band to the\nexisting capabilities\
    \ is not possible.\nThe ground distance covered per pixel of the satellite image\
    \ is called the spatial resolution,\nwhereby, a higher spatial resolution indicates\
    \ a smaller ground distance. Existing satellite systems,\ndue to their lower spatial\
    \ resolution and large coverage, are suited to study larger regions [55]. For\
    \ a\nsmaller observation area, such as a farm block, an irrigation zone, a single\
    \ row of the horticultural crop,\nor a single canopy, this spatial resolution\
    \ is considered sub-optimal. Often, a pixel of the satellite image\ncomprises\
    \ of multiple rows and multiple canopies of horticultural crops [42,56]. Thus,\
    \ the spectral\nresponse on a single pixel of the satellite image includes a mixed\
    \ spectral signal from the canopy,\ninter-row vegetation and/or bare soil. The\
    \ mixed-pixel is particularly unavoidable in horticultural\ncrops with large inter-row\
    \ surfaces, introducing errors in satellite-based estimations [42,56]. Improving\n\
    the spatial resolution from freely available Landsat/Sentinel satellites (spatial\
    \ resolution 10–15 m) to\nsuch as WorldView-3 (spatial resolution 0.3 m), does\
    \ not necessarily resolve single canopies of many\nhorticultural crops.\nCurrent\
    \ satellite systems generally oﬀer a temporal resolution of about 1–2 weeks this\
    \ resolution\ncorresponds to the satellite’s revisit interval (Table 1). For example,\
    \ freely available Landsat-8 and\nSentinel-2 oﬀer revisit cycles of 16 and 5 days,\
    \ respectively. Although the MODIS sensor on NASA’s\nAgronomy 2020, 10, 140\n\
    4 of 35\nTerra and Aqua satellites oﬀer a greater temporal resolution (1–2 days),\
    \ its spatial resolution is relatively\ncoarse (250 m–1 km) to be valuable for\
    \ horticulture [25]. The revisit cycle of satellites does not alone\nrepresent\
    \ the timeframe on which the data can be interpreted. For instance, post-data\
    \ acquisition,\nthere are often delays in data transfer to the ground station,\
    \ handling, and delivery to the end user.\nThe end user then needs to process\
    \ the data before making an interpretation. Such processing can\nbe a combination\
    \ of atmospheric, radiometric, and geometric corrections, where applicable [57,58].\n\
    Furthermore, as the agricultural applications of the satellite imagery are illumination\
    \ sensitive and\nweather dependent, conditions have to be optimal on the satellite\
    \ revisit day to avoid data corruption\ndue to, for example, cloud cover [23,53].\
    \ Cloud corrupted data (~55% of the land area is covered by\ncloud at any one\
    \ time [59]) will require users to wait for the next revisit to attempt the data\
    \ acquisition.\nTime-series image fusion techniques, such as the spatial and temporal\
    \ adaptive reﬂectance fusion\nmodel, can improve the spatial and temporal resolution\
    \ of the satellite data [60,61]. These fusion\ntechniques blend the frequent (however\
    \ low-resolution) with higher-resolution (but infrequent) satellite\ndata [62,63].\
    \ The result combines the best aspects of multiple satellite systems to produce\
    \ frequent and\nhigher-resolution data, which can be useful for timely monitoring\
    \ of water status.\nThe clear advantage of the satellite system is the ability\
    \ to capture data at a large scale and at an\naﬀordable cost (e.g., the user can\
    \ download Landsat and Sentinel data for free). The compromise with\nthe satellite\
    \ data is in spatial resolution, as well as the relatively long revisit cycle\
    \ (in the order of days\nto weeks), making the data less than ideal for speciﬁc\
    \ applications, e.g., irrigation scheduling.\n2.2. Manned Aircraft System\nOperating\
    \ within few kilometres above ground level, manned aircraft have been used to\
    \ remotely\nacquire agricultural data at higher spatial detail (compared to the\
    \ satellites) and over a larger region\n(compared to UAS) [42,64]. Light ﬁxed-wing\
    \ aircraft and helicopters are the commonly used manned\naircraft employed in\
    \ agricultural remote sensing. The ﬁxed-wing aircraft generally ﬂies higher and\n\
    faster, enabling the coverage of a larger area, whereas the helicopters are traditionally\
    \ ﬂown lower\nand slower, enabling a spatially detailed observation. A signiﬁcant\
    \ advantage of the manned aircraft,\ncompared to UAS, lies in their ability to\
    \ carry heavier high-grade sensors, such as AVIRIS, HyPlant,\nHySpex SWIR-384,\
    \ Specim AisaFENIX, and Riegl LMS Q240i-60 [65–67]. The use of manned aircraft\
    \ is,\nhowever, limited by high operational complexity, safety regulations, scheduling\
    \ inﬂexibility, costs, and\nproduct turnaround time. As a result, these platforms\
    \ are barely used as compared to the recent surge\nin the use of UAS, speciﬁcally\
    \ for horticultural crops [68–70].\nIn horticulture, manned aircraft was used\
    \ to characterise olive and peach canopy temperature\nand water stress using speciﬁc\
    \ thermal bands (10.069 µm and 12.347 µm) of a wideband (0.43–12.5 µm)\nairborne\
    \ hyperspectral camera system [71,72]. This work found moderate correlations (R2\
    \ = 0.45–0.57)\nof ground vs. aerial olive canopy temperature measurements [72],\
    \ and high correlations (R2 = 0.94)\nof canopy temperature vs. peach fruit size\
    \ (diameter) [71]. The advantage of manned aircraft for\nremote sensing of a large\
    \ region was highlighted in recent work that characterised regional-scale\ngrapevine\
    \ (Vitis vinifera L.) water stress responses of two cultivars, Shiraz and Cabernet\
    \ Sauvignon, in\nAustralia [64]. Airborne thermal imaging was able to discriminate\
    \ between the two cultivars based on\ntheir water status responses to soil moisture\
    \ availability (Figure 1).\nAgronomy 2020, 10, 140\n5 of 35\nAgronomy 2020, 10,\
    \ 140 \n5 of 35 \n \n \nFigure 1. Water status of Shiraz and Cabernet Sauvignon\
    \ under similar soil moisture as captured from \nmanned aircraft [64]. \n2.3.\
    \ Unmanned Aircraft Systems \nBoth the fixed-wing and the rotary-wing variant\
    \ of UASs are used in agricultural remote \nsensing. Each variant has its advantages\
    \ and shortcomings vis-à-vis sensor payload, flexibility, and \ncoverage. In this\
    \ regard, the literature provides a list of state-of-the-art UAS [73], their categorisation\
    \ \n[74], and overview of structural characteristics, as well as flight parameters\
    \ [75], in the context of \nagricultural use. Depending on the number of rotors,\
    \ a rotary-wing UAS can be a helicopter, a \nquadcopter, a hexacopter, or an octocopter,\
    \ among others. Rotary-wing UAS are more agile and can \nfly with a higher degree\
    \ of freedom [76], while fixed-wing UAS needs to be moving forward at a \ncertain\
    \ speed to maintain thrust. As a result, rotary-wing UAS provides flexibility\
    \ and specific \ncapabilities, such as hovering, vertical take-off and landing,\
    \ vertical (up and down) motions, or return \nto the previous location. On the\
    \ contrary, fixed-wing UAS fly faster, carry heavier payloads, and have \ngreater\
    \ flying time enabling coverage of larger areas in a single flight [77]. Recently\
    \ developed fixed-\nwing UAS with vertical take-off and landing capabilities,\
    \ such as BirdEyeView FireFly6 PRO, Elipse \nVTOL-PPK, and Carbonix Volanti, captures\
    \ the pros of both fixed-wing and rotary-wing, making \nthem a promising platform\
    \ for agricultural purposes. In the context of precision agriculture, the \napplication\
    \ of UAS, their future prospects, and knowledge gaps are discussed in [53,78–81].\
    \ While \nmany horticultural crops have been studied using UAS technology, the\
    \ most studied horticultural \ncrops are vineyards [31,82–84], citrus [85,86],\
    \ peach [32,33], olive [18,87,88], pistachio [89,90], and \nalmond [91–94], among\
    \ others [95–99]. Some of the UAS types used for water status studies of \nhorticultural\
    \ crops are shown in Figure 2. \n \n \n(a) \n(b) \nFigure 1. Water status of Shiraz\
    \ and Cabernet Sauvignon under similar soil moisture as captured from\nmanned\
    \ aircraft [64].\n2.3. Unmanned Aircraft Systems\nBoth the ﬁxed-wing and the rotary-wing\
    \ variant of UASs are used in agricultural remote sensing.\nEach variant has its\
    \ advantages and shortcomings vis-à-vis sensor payload, ﬂexibility, and coverage.\n\
    In this regard, the literature provides a list of state-of-the-art UAS [73], their\
    \ categorisation [74], and\noverview of structural characteristics, as well as\
    \ ﬂight parameters [75], in the context of agricultural use.\nDepending on the\
    \ number of rotors, a rotary-wing UAS can be a helicopter, a quadcopter, a hexacopter,\n\
    or an octocopter, among others. Rotary-wing UAS are more agile and can ﬂy with\
    \ a higher degree of\nfreedom [76], while ﬁxed-wing UAS needs to be moving forward\
    \ at a certain speed to maintain thrust.\nAs a result, rotary-wing UAS provides\
    \ ﬂexibility and speciﬁc capabilities, such as hovering, vertical\ntake-oﬀ and\
    \ landing, vertical (up and down) motions, or return to the previous location.\
    \ On the contrary,\nﬁxed-wing UAS ﬂy faster, carry heavier payloads, and have\
    \ greater ﬂying time enabling coverage of\nlarger areas in a single ﬂight [77].\
    \ Recently developed ﬁxed-wing UAS with vertical take-oﬀ and landing\ncapabilities,\
    \ such as BirdEyeView FireFly6 PRO, Elipse VTOL-PPK, and Carbonix Volanti, captures\n\
    the pros of both ﬁxed-wing and rotary-wing, making them a promising platform for\
    \ agricultural\npurposes. In the context of precision agriculture, the application\
    \ of UAS, their future prospects,\nand knowledge gaps are discussed in [53,78–81].\
    \ While many horticultural crops have been studied\nusing UAS technology, the\
    \ most studied horticultural crops are vineyards [31,82–84], citrus [85,86],\n\
    peach [32,33], olive [18,87,88], pistachio [89,90], and almond [91–94], among\
    \ others [95–99]. Some of\nthe UAS types used for water status studies of horticultural\
    \ crops are shown in Figure 2.\nAgronomy 2020, 10, 140 \n5 of 35 \n \n \nFigure\
    \ 1. Water status of Shiraz and Cabernet Sauvignon under similar soil moisture\
    \ as captured from \nmanned aircraft [64]. \n2.3. Unmanned Aircraft Systems \n\
    Both the fixed-wing and the rotary-wing variant of UASs are used in agricultural\
    \ remote \nsensing. Each variant has its advantages and shortcomings vis-à-vis\
    \ sensor payload, flexibility, and \ncoverage. In this regard, the literature\
    \ provides a list of state-of-the-art UAS [73], their categorisation \n[74], and\
    \ overview of structural characteristics, as well as flight parameters [75], in\
    \ the context of \nagricultural use. Depending on the number of rotors, a rotary-wing\
    \ UAS can be a helicopter, a \nquadcopter, a hexacopter, or an octocopter, among\
    \ others. Rotary-wing UAS are more agile and can \nfly with a higher degree of\
    \ freedom [76], while fixed-wing UAS needs to be moving forward at a \ncertain\
    \ speed to maintain thrust. As a result, rotary-wing UAS provides flexibility\
    \ and specific \ncapabilities, such as hovering, vertical take-off and landing,\
    \ vertical (up and down) motions, or return \nto the previous location. On the\
    \ contrary, fixed-wing UAS fly faster, carry heavier payloads, and have \ngreater\
    \ flying time enabling coverage of larger areas in a single flight [77]. Recently\
    \ developed fixed-\nwing UAS with vertical take-off and landing capabilities,\
    \ such as BirdEyeView FireFly6 PRO, Elipse \nVTOL-PPK, and Carbonix Volanti, captures\
    \ the pros of both fixed-wing and rotary-wing, making \nthem a promising platform\
    \ for agricultural purposes. In the context of precision agriculture, the \napplication\
    \ of UAS, their future prospects, and knowledge gaps are discussed in [53,78–81].\
    \ While \nmany horticultural crops have been studied using UAS technology, the\
    \ most studied horticultural \ncrops are vineyards [31,82–84], citrus [85,86],\
    \ peach [32,33], olive [18,87,88], pistachio [89,90], and \nalmond [91–94], among\
    \ others [95–99]. Some of the UAS types used for water status studies of \nhorticultural\
    \ crops are shown in Figure 2. \n \n \n(a) \n(b) \nFigure 2. Cont.\nAgronomy 2020,\
    \ 10, 140\n6 of 35\nAgronomy 2020, 10, 140 \n6 of 35 \n \n \n \n(c) \n(d) \nFigure\
    \ 2. Examples of unmanned aircraft systems (UAS) used to study water status in\
    \ horticulture \ncrops: (a) hexacopter equipped with RGB, multispectral and thermal\
    \ camera at The University of \nAdelaide, Adelaide, Australia (b) quadcopter equipped\
    \ with a thermal and multispectral camera \n[100], (c) fixed-wing aircraft used\
    \ for GRAPEX project to carry RGB, thermal and monochrome camera \nwith narrowband\
    \ filters [101], and (d) helicopter used for various studies of crop water status\
    \ \n[18,92,102]. \nUAS offers flexibility on spatial resolution, observation scale,\
    \ spectral bands, and temporal \nresolution to collect data on any good weather\
    \ day. However, like satellite and manned aircraft, the \nUAS is inoperable during\
    \ precipitation, high winds, and temperatures. By easily altering the flying \n\
    altitude, the UAS provides higher flexibility to observe a larger area with lower\
    \ spatial resolution or \nsmaller area with much greater detail [103]. Temporally,\
    \ the UAS can be scheduled at a user-defined \ntime at short notice, thus accommodating\
    \ applications that are time-sensitive, such as capturing vital \nphenological\
    \ stages of crop growth. Spectrally, UAS offer flexibility to carry on-demand\
    \ sensors and \ninterchangeability between sensor payloads; thus, any desired\
    \ combination of sensors and spectral \nbands can be incorporated to target specific\
    \ features. \nUAS-acquired image data requires post-processing before it can be\
    \ incorporated into the grower \ndecision-making process. Mosaicking of UAS images\
    \ currently has a turnaround time of \napproximately one day to one week, subject\
    \ to the size of the dataset, computational power, and \nspectral/spatial quality\
    \ of the product [104,105]. Spectral quality of the data is of optimal importance,\
    \ \nwhereas the spatial quality can be of less importance, such as for well-established\
    \ horticultural crops. \nHigher spectral quality demands calibration of the spectral\
    \ sensors and correction of atmospheric \neffects. Following post-processing of\
    \ aerial images, the UAS-based spectral data have shown to be \nhighly correlated\
    \ with ground-based data [82,102,106]. \nThe most common UAS-based sensor types\
    \ to study the crop water status are the thermal, \nmultispectral and RGB, while\
    \ hyperspectral and LiDAR (Light detection and ranging) sensors are \nused less\
    \ often [23,79,107]. Spectral sensors provide the capability to capture broader\
    \ physiological \nproperties of the crop, such as greenness (related to leaf chlorophyll\
    \ content and health) and biomass, \nthat generally correlate with crop water\
    \ status [82,108]. Narrower band spectral sensors provide \ndirect insight into\
    \ specific biophysical and biochemical properties of crops, such as via photochemical\
    \ \nreflectance index (PRI) and solar-induced chlorophyll fluorescence (SIF),\
    \ which reflects a plant’s \nphotosynthetic efficiency [109,110]. Thermal-based\
    \ sensors capture the temperature of the crop’s \nsurface, which indicates the\
    \ plant’s stress (both biotic and abiotic) [53]. Generally, digital RGB camera\
    \ \nand LiDAR can be used to quantify 3D metrics, such as the plant size and shape,\
    \ via 3D pointclouds \nwith sufficient accuracy for canopy level assessment [111–118].\
    \ \n3. Remote Sensor Types \n3.1. Digital Camera \nA digital camera typically\
    \ incorporates an RGB, modified RGB, and a monochrome digital \ncamera. The lens\
    \ quality of the camera determines the sharpness of the image, while the resolution\
    \ \nFigure 2. Examples of unmanned aircraft systems (UAS) used to study water\
    \ status in horticulture\ncrops: (a) hexacopter equipped with RGB, multispectral\
    \ and thermal camera at The University of\nAdelaide, Adelaide, Australia (b) quadcopter\
    \ equipped with a thermal and multispectral camera [100],\n(c) ﬁxed-wing aircraft\
    \ used for GRAPEX project to carry RGB, thermal and monochrome camera with\nnarrowband\
    \ ﬁlters [101], and (d) helicopter used for various studies of crop water status\
    \ [18,92,102].\nUAS oﬀers ﬂexibility on spatial resolution, observation scale,\
    \ spectral bands, and temporal\nresolution to collect data on any good weather\
    \ day. However, like satellite and manned aircraft, the\nUAS is inoperable during\
    \ precipitation, high winds, and temperatures. By easily altering the ﬂying\n\
    altitude, the UAS provides higher ﬂexibility to observe a larger area with lower\
    \ spatial resolution or\nsmaller area with much greater detail [103]. Temporally,\
    \ the UAS can be scheduled at a user-deﬁned\ntime at short notice, thus accommodating\
    \ applications that are time-sensitive, such as capturing vital\nphenological\
    \ stages of crop growth. Spectrally, UAS oﬀer ﬂexibility to carry on-demand sensors\
    \ and\ninterchangeability between sensor payloads; thus, any desired combination\
    \ of sensors and spectral\nbands can be incorporated to target speciﬁc features.\n\
    UAS-acquired image data requires post-processing before it can be incorporated\
    \ into the grower\ndecision-making process. Mosaicking of UAS images currently\
    \ has a turnaround time of approximately\none day to one week, subject to the\
    \ size of the dataset, computational power, and spectral/spatial\nquality of the\
    \ product [104,105]. Spectral quality of the data is of optimal importance, whereas\
    \ the\nspatial quality can be of less importance, such as for well-established\
    \ horticultural crops. Higher\nspectral quality demands calibration of the spectral\
    \ sensors and correction of atmospheric eﬀects.\nFollowing post-processing of\
    \ aerial images, the UAS-based spectral data have shown to be highly\ncorrelated\
    \ with ground-based data [82,102,106].\nThe most common UAS-based sensor types\
    \ to study the crop water status are the thermal,\nmultispectral and RGB, while\
    \ hyperspectral and LiDAR (Light detection and ranging) sensors are\nused less\
    \ often [23,79,107]. Spectral sensors provide the capability to capture broader\
    \ physiological\nproperties of the crop, such as greenness (related to leaf chlorophyll\
    \ content and health) and biomass,\nthat generally correlate with crop water status\
    \ [82,108]. Narrower band spectral sensors provide\ndirect insight into speciﬁc\
    \ biophysical and biochemical properties of crops, such as via photochemical\n\
    reﬂectance index (PRI) and solar-induced chlorophyll ﬂuorescence (SIF), which\
    \ reﬂects a plant’s\nphotosynthetic eﬃciency [109,110]. Thermal-based sensors\
    \ capture the temperature of the crop’s\nsurface, which indicates the plant’s\
    \ stress (both biotic and abiotic) [53]. Generally, digital RGB camera\nand LiDAR\
    \ can be used to quantify 3D metrics, such as the plant size and shape, via 3D\
    \ pointclouds\nwith suﬃcient accuracy for canopy level assessment [111–118].\n\
    3. Remote Sensor Types\n3.1. Digital Camera\nA digital camera typically incorporates\
    \ an RGB, modiﬁed RGB, and a monochrome digital camera.\nThe lens quality of the\
    \ camera determines the sharpness of the image, while the resolution of the\n\
    Agronomy 2020, 10, 140\n7 of 35\ncamera determines its spatial resolution and\
    \ details within an image. The RGB camera uses broad\nspectral bandwidth within\
    \ the blue, green and red spectral region to capture energy received at the\n\
    visible region of the electromagnetic spectrum. The images are used to retrieve\
    \ dimensional properties\nof the crop, terrain conﬁguration, macrostructure of\
    \ the ﬁeld, and the spatial information. Based on\nthe dimensional properties,\
    \ such as size, height, perimeter, and area of the crown, the resource need\n\
    practices can be estimated [119–121]. Generally, a larger crop is expected to\
    \ more quickly use available\nwater resources, resulting in crop water stress\
    \ at a later stage of the season if irrigation is not suﬃcient.\nThe evolution\
    \ of canopy structure within and between seasons can be useful to understand the\
    \ spatial\nvariability within the ﬁeld and corresponding water requirements. The\
    \ macro-structure of horticultural\ncrops, such as row height, width, spacing,\
    \ crop count, the fraction of ground cover, and missing\nplants, can be identiﬁed\
    \ remotely, which can aid in the allocation of resources [113,122]. The terrain\n\
    conﬁguration in the form of a digital elevation model (DEM) generated from a digital\
    \ camera can also\nenable understanding of the water status in relation to the\
    \ aspect and slope conﬁguration of the terrain.\n3.2. Multispectral Camera\nA\
    \ multispectral camera oﬀers multiple spectral bands across the electromagnetic\
    \ spectrum.\nMost common airborne multispectral cameras have 4–5 bands which include\
    \ rededge and NIR\nbands in addition to the visible bands, R-G-B (e.g., Figure\
    \ 3a,c). Conﬁgurable ﬁlter placement of\nthe spectral band is also available,\
    \ which can potentially target certain physiological responses of\nhorticultural\
    \ crops [102]. Spectrally, the airborne multispectral camera has been reported\
    \ to perform\nwith consistency, producing reliable measurements following radiometric\
    \ calibration and atmospheric\ncorrection [123–125].\nTheir spatial resolution\
    \ has been found to be suﬃcient for horticultural\napplications enabling canopy\
    \ level observation of the spectral response. For this reason, as well as\nrelatively\
    \ low cost, multispectral cameras are used more frequently in horticulture applications.\n\
    Agronomy 2020, 10, 140 \n7 of 35 \n \nof the camera determines its spatial resolution\
    \ and details within an image. The RGB camera uses \nbroad spectral bandwidth\
    \ within the blue, green and red spectral region to capture energy received \n\
    at the visible region of the electromagnetic spectrum. The images are used to\
    \ retrieve dimensional \nproperties of the crop, terrain configuration, macrostructure\
    \ of the field, and the spatial information. \nBased on the dimensional properties,\
    \ such as size, height, perimeter, and area of the crown, the \nresource need\
    \ practices can be estimated [119–121]. Generally, a larger crop is expected to\
    \ more \nquickly use available water resources, resulting in crop water stress\
    \ at a later stage of the season if \nirrigation is not sufficient. The evolution\
    \ of canopy structure within and between seasons can be \nuseful to understand\
    \ the spatial variability within the field and corresponding water requirements.\
    \ \nThe macro-structure of horticultural crops, such as row height, width, spacing,\
    \ crop count, the \nfraction of ground cover, and missing plants, can be identified\
    \ remotely, which can aid in the \nallocation of resources [113,122]. The terrain\
    \ configuration in the form of a digital elevation model \n(DEM) generated from\
    \ a digital camera can also enable understanding of the water status in relation\
    \ \nto the aspect and slope configuration of the terrain. \n3.2. Multispectral\
    \ Camera \nA multispectral camera offers multiple spectral bands across the electromagnetic\
    \ spectrum. Most \ncommon airborne multispectral cameras have 4–5 bands which\
    \ include rededge and NIR bands in \naddition to the visible bands, R-G-B (e.g.,\
    \ Figure 3a,c). Configurable filter placement of the spectral \nband is also available,\
    \ which can potentially target certain physiological responses of horticultural\
    \ \ncrops [102]. Spectrally, the airborne multispectral camera has been reported\
    \ to perform with \nconsistency, producing reliable measurements following radiometric\
    \ calibration and atmospheric \ncorrection [123–125]. Their spatial resolution\
    \ has been found to be sufficient for horticultural \napplications enabling canopy\
    \ level observation of the spectral response. For this reason, as well as \nrelatively\
    \ low cost, multispectral cameras are used more frequently in horticulture applications.\
    \ \n \n \n(a) \n(b) \n \n \n(c) \n(d) \nFigure 3. Some examples of sensors used\
    \ on a UAS platform to study water status of horticultural \ncrops: (a) A multispectral\
    \ camera (Tetracam Mini-MCA-6, Tetracam, Inc., Chatsworth, CA, USA) \n[126]. (b)\
    \ A thermal camera (FLIR TAU II, FLIR Systems, Inc., USA) [100,108]. (c) A multi-sensor\
    \ \ncamera setup with an RGB (Sony α7R III, Sony Electronics, Inc., Minato, Tokyo,\
    \ Japan), a multispectral \n(MicaSense RedEdge, MicaSense Inc., Seattle, WA, USA),\
    \ and a thermal (FLIR TAU II 640, FLIR \nSystems, Inc., USA) camera. (d) A micro-hyperspectral\
    \ camera (Micro-Hyperspec, Headwall \nPhotonics, MA, USA) [110]. \nChlorophyll\
    \ and cellular structures of vegetation absorb most of the visible light and reflect\
    \ \ninfrared light. The rise in reflectance between the red and NIR band is unique\
    \ to live green vegetation \nand is captured by vegetation spectral index called\
    \ NDVI (Table 2, Equation (3). Once the vegetation \nFigure 3. Some examples of\
    \ sensors used on a UAS platform to study water status of horticultural\ncrops:\
    \ (a) A multispectral camera (Tetracam Mini-MCA-6, Tetracam, Inc., Chatsworth,\
    \ CA, USA) [126].\n(b) A thermal camera (FLIR TAU II, FLIR Systems, Inc., USA)\
    \ [100,108]. (c) A multi-sensor camera setup\nwith an RGB (Sony α7R III, Sony\
    \ Electronics, Inc., Minato, Tokyo, Japan), a multispectral (MicaSense\nRedEdge,\
    \ MicaSense Inc., Seattle, WA, USA), and a thermal (FLIR TAU II 640, FLIR Systems,\
    \ Inc., USA)\ncamera. (d) A micro-hyperspectral camera (Micro-Hyperspec, Headwall\
    \ Photonics, MA, USA) [110].\nChlorophyll and cellular structures of vegetation\
    \ absorb most of the visible light and reﬂect\ninfrared light. The rise in reﬂectance\
    \ between the red and NIR band is unique to live green vegetation\nand is captured\
    \ by vegetation spectral index called NDVI (Table 2, Equation (3)). Once the vegetation\n\
    starts to experience stress (biotic and abiotic), its reﬂectance in the NIR region\
    \ is reduced, while the\nreﬂectance in the red band is increased. Thus, such stress\
    \ is reﬂected in the vegetation proﬁle and\nAgronomy 2020, 10, 140\n8 of 35\n\
    easily captured by indices, such as NDVI. For this reason, NDVI has shown correlations\
    \ with a wide\narray of crops response including vigour, chlorophyll content,\
    \ leaf area index (LAI), crop water stress,\nand occasionally yield [34,82–84,127].\n\
    The rededge band covers the portion of the electromagnetic spectrum between the\
    \ red and NIR\nbands where reﬂectance increases drastically. Studies have suggested\
    \ that the sharp transition between\nthe red absorbance and NIR reﬂection is able\
    \ to provide additional information about vegetation and\nits hydric characteristics\
    \ [128]. Using the normalised diﬀerence red edge (NDRE) index, the rededge\nband\
    \ was found to be useful in establishing a relative chlorophyll concentration\
    \ map [127]. Given the\nsensitivity of NDRE, it can be used for applications,\
    \ such as crops drought stress [107]. With regard to\nthe water use eﬃciency,\
    \ a combination of vegetation indices (VIs) along with structural physiological\n\
    indices were found to be useful to study water stress in horticultural crops [34,82,129].\n\
    3.3. Hyperspectral\nHyperspectral sensors have contiguous spectral bands sampled\
    \ at a narrower wavelength intervals\nspanning from visible to NIR spectrum at\
    \ a high to ultra-high spectral resolution (Figure 3d). Scanning\nat contiguous\
    \ narrow-band wavelengths, a hyperspectral sensor produces a three dimensional\
    \ (two\nspatial dimensions and one spectral dimension) data called hyperspectral\
    \ data cube. The hyperspectral\ndata cube is a hyperspectral image where each\
    \ pixel contain spatial information, as well as the entire\nspectral reﬂectance\
    \ curve [130]. Based on the operating principle and output data cube, hyperspectral\n\
    sensors for remote sensing can include a point spectrometer (aka spectroradiometer),\
    \ whiskbroom\nscanner, pushbroom scanner, and 2D imager (Figure 4) [130,131].\
    \ A point spectrometer, samples\nwithin its ﬁeld of view solid angle to produce\
    \ an ultra-high spectral resolution spectral data of a\npoint [130,132]. A whiskbroom\
    \ scanner deploys a single detector onboard to scan one single pixel at a\ntime.\
    \ As the scanner rotates across-track, successive scans form a row of the data\
    \ cube, and as the\nplatform moves forward along-track, successive rows form a\
    \ hyperspectral image [133]. A pushbroom\nscanner deploys a row of spatially contiguous\
    \ detectors arranged in the perpendicular direction of\ntravel and scans the entire\
    \ row of pixels at a time. As the platform moves forward, the successive\nrows\
    \ form a two-dimensional hyperspectral image [40,134]. The 2D imager using diﬀerent\
    \ scanning\ntechniques [130] captures hyperspectral data across the image scene\
    \ [135,136]. The point spectrometer\noﬀers the highest spectral resolution and\
    \ lowest signal-to-noise ratio (SNR) among the UAS-compatible\nhyperspectral sensors\
    \ [137,138].\nAgronomy 2020, 10, 140 \n8 of 35 \n \nstarts to experience stress\
    \ (biotic and abiotic), its reflectance in the NIR region is reduced, while the\
    \ \nreflectance in the red band is increased. Thus, such stress is reflected in\
    \ the vegetation profile and \neasily captured by indices, such as NDVI. For this\
    \ reason, NDVI has shown correlations with a wide \narray of crops response including\
    \ vigour, chlorophyll content, leaf area index (LAI), crop water stress, \nand\
    \ occasionally yield [34,82–84,127]. \nThe rededge band covers the portion of\
    \ the electromagnetic spectrum between the red and NIR \nbands where reflectance\
    \ increases drastically. Studies have suggested that the sharp transition \nbetween\
    \ the red absorbance and NIR reflection is able to provide additional information\
    \ about \nvegetation and its hydric characteristics [128]. Using the normalised\
    \ difference red edge (NDRE) \nindex, the rededge band was found to be useful\
    \ in establishing a relative chlorophyll concentration \nmap [127]. Given the\
    \ sensitivity of NDRE, it can be used for applications, such as crops drought\
    \ stress \n[107]. With regard to the water use efficiency, a combination of vegetation\
    \ indices (VIs) along with \nstructural physiological indices were found to be\
    \ useful to study water stress in horticultural crops \n[34,82,129]. \n3.3. Hyperspectral\
    \ \nHyperspectral sensors have contiguous spectral bands sampled at a narrower\
    \ wavelength \nintervals spanning from visible to NIR spectrum at a high to ultra-high\
    \ spectral resolution (Figure \n3d). Scanning at contiguous narrow-band wavelengths,\
    \ a hyperspectral sensor produces a three \ndimensional (two spatial dimensions\
    \ and one spectral dimension) data called hyperspectral data \ncube. The hyperspectral\
    \ data cube is a hyperspectral image where each pixel contain spatial \ninformation,\
    \ as well as the entire spectral reflectance curve [130]. Based on the operating\
    \ principle \nand output data cube, hyperspectral sensors for remote sensing can\
    \ include a point spectrometer (aka \nspectroradiometer), whiskbroom scanner,\
    \ pushbroom scanner, and 2D imager (Figure 4) [130,131]. A \npoint spectrometer,\
    \ samples within its field of view solid angle to produce an ultra-high spectral\
    \ \nresolution spectral data of a point [130,132]. A whiskbroom scanner deploys\
    \ a single detector onboard \nto scan one single pixel at a time. As the scanner\
    \ rotates across-track, successive scans form a row of \nthe data cube, and as\
    \ the platform moves forward along-track, successive rows form a hyperspectral\
    \ \nimage [133]. A pushbroom scanner deploys a row of spatially contiguous detectors\
    \ arranged in the \nperpendicular direction of travel and scans the entire row\
    \ of pixels at a time. As the platform moves \nforward, the successive rows form\
    \ a two-dimensional hyperspectral image [40,134]. The 2D imager \nusing different\
    \ scanning techniques [130] captures hyperspectral data across the image scene\
    \ \n[135,136]. The point spectrometer offers the highest spectral resolution and\
    \ lowest signal-to-noise \nratio (SNR) among the UAS-compatible hyperspectral\
    \ sensors [137,138]. \n \nFigure 4. The data cube structure of different spectral\
    \ sensors. The number of bands and resolution is \nshown as an example and does\
    \ not indicate true sensor capability (adapted from [130]). \nFigure 4. The data\
    \ cube structure of diﬀerent spectral sensors. The number of bands and resolution\
    \ is\nshown as an example and does not indicate true sensor capability (adapted\
    \ from [130]).\nIn horticultural applications, hyperspectral data, due to the\
    \ high resolution contiguous spectral\nsampling, possesses tremendous potential\
    \ to detect and monitor speciﬁc biotic and abiotic stresses [139].\nNarrowband\
    \ hyperspectral data was used to detect water stress using the measurement of\
    \ ﬂuorescence\nAgronomy 2020, 10, 140\n9 of 35\nand PRI over a citrus orchard\
    \ [110]. PRI was identiﬁed as one of the best predictors of water stress for a\n\
    vineyard in a study that investigated numerous VIs using hyperspectral imaging\
    \ [140]. High-resolution\nthermal imagery obtained from a hyperspectral scanner\
    \ was used to map canopy stomatal conductance\n(gs) and CWSI of olive orchards\
    \ where diﬀerent irrigation treatments were applied [18]. With the\nlarge volume\
    \ of spatial/spectral data extracted from the hyperspectral data cube, machine\
    \ learning\nwill likely be adopted more widely in the horticultural environment\
    \ to model water stress [141].\nSee Reference [54] for a comprehensive review\
    \ of hyperspectral and thermal remote sensing to detect\nplant water status.\n\
    3.4. Thermal\nThermal cameras use microbolometers to read passive thermal signals\
    \ in the spectral range of\napproximately 7–14 µm (Figure 3b). Small UAS are capable\
    \ of carrying a small form-factor thermal\ncamera with uncooled microbolometers,\
    \ which does not use an internal cooling mechanism and,\ntherefore, does not achieve\
    \ the high SNR that can be found in cooled microbolometer-based thermal\ncameras.\
    \ An array of microbolometer detectors in the thermal camera receives a thermal\
    \ radiation\nsignal and stores the signal on the corresponding image pixel as\
    \ raw data number (DN) values.\nThe result is a thermal image where each pixel\
    \ has an associated DN value, which can be converted to\nabsolute temperature.\
    \ A representative list of commercial thermal cameras used on UAS platforms\n\
    and their applications with regard to agricultural remote sensing is found in\
    \ the literature [23,53,73].\nThermal imagery enables the measurement of the foliar\
    \ temperature of plants. The foliar temperature\ndiﬀerence between well-watered\
    \ and water-stressed crops is the primary source of information for\nwater stress\
    \ prediction using a thermal sensor [142]. When mounted on a remote sensing platform,\
    \ the\ncanopy level assessment of crop water status can be performed on a large\
    \ scale.\nThermal cameras are limited by their resolution (e.g., 640 × 512 is\
    \ the maximum resolution of\nUAS compatible thermal cameras in the current market)\
    \ and high price-tag [53]. The small number of\npixels results in low spatial\
    \ resolution limiting either the ability to resolve a single canopy or ability\
    \ to\nﬂy higher and cover a larger area. If ﬂown at a higher altitude, the eﬀective\
    \ spatial resolution may\nbe inadequate for canopy level assessment of some horticultural\
    \ crops. For example, a FLIR Tau2\n640 thermal camera with a 13 mm focal length\
    \ when ﬂown at an altitude of approximately 120 m\nresults in a spatial resolution\
    \ of 15.7 cm. For relatively large horticultural crops, such as grapevine,\nalmond,\
    \ citrus, and avocado, the resolution at a maximum legal ﬂying altitude of 120\
    \ m in Australia\n(for small-sized UAS) oﬀers an adequate spatial resolution to\
    \ observe a single canopy.\nAnother challenge with the use of thermal cameras\
    \ is the temporal drift of the DN values\nwithin successive thermal images, especially\
    \ with uncooled thermal cameras [143]. Due to the lack\nof an internal cooling\
    \ mechanism for the microbolometer detectors, DN values registered by the\nmicrobolometers\
    \ experience temporal drift i.e., the registered DN values for the same temperature\n\
    target will drift temporally. Thus, the thermal image can be unreliable especially\
    \ when the internal\ntemperature of the camera is changing rapidly, such as during\
    \ camera warmup period or during the\nﬂight when a gust of cool wind results in\
    \ cooling of the camera. To overcome this challenge, the user\nmay need to provide\
    \ suﬃcient startup time before operation (preferably 30–60 min) [102,143–145],\n\
    shield the camera to minimize the change in the internal temperature of the camera\
    \ [142], calibrate the\ncamera [146–153], and perform frequent ﬂat-ﬁeld corrections.\n\
    3.5. Multi-Sensor\nTo carry multiple sensors, the total UAS payload needs to be\
    \ considered that includes, in\naddition to the sensors, an inertial measurement\
    \ unit (IMU) and global navigation satellite system\n(GNSS) for the georeferencing\
    \ purpose [40,154]. Higher accuracy sensors tend to be heavier, and in\na multi-sensor\
    \ scenario, the payload can quickly reach or even exceed the payload limit. This\
    \ has\nlimited contemporary measurements in earlier multirotor UAS requiring separate\
    \ ﬂights for each of\nsensor [126]. The use of ﬁxed-wing UAS has allowed carrying\
    \ higher payloads due to the much larger\nAgronomy 2020, 10, 140\n10 of 35\nthrust-to-weight\
    \ ratio as compared to a rotary-wing aircraft [155]. Similarly, recent advancement\
    \ in\nUAS technology and lightweight sensors have enabled multirotor (payload\
    \ 5–6 kg readily available) to\nonboard multi-sensors.\nWater status of crops\
    \ is a complex process inﬂuenced by a number of factors including the\nphysiology\
    \ of the crop, available soil moisture, the size and vigour of the crop, and meteorological\n\
    factors [30,108,116,156,157]. For this reason, a multi-sensor platform is used\
    \ to acquire measurements\nof the diﬀerent aspects of the crop for water status\
    \ assessment [34,102,108]. The most common\ncombination of sensors found in the\
    \ literature is the RGB, multispectral (including rededge and NIR\nbands) and\
    \ thermal. Together, these sensors can be used to investigate the water status\
    \ of the crop\nusing various indicators, such as PRI, CWSI, ﬂuorescence, and structural\
    \ properties, with the aim of\nimproving the water use eﬃciency [102,110,158–160].\n\
    4. Techniques of Remote Sensing in Horticulture\n4.1. Georeferencing of Remotely\
    \ Sensed Images\nGeoreferencing provides a spatial reference to the remotely sensed\
    \ images such that the pixels\nrepresenting crops or regions of interest on the\
    \ images are correctly associated with their position on\nEarth. The georeferencing\
    \ process generally uses surveyed coordinate points on the ground, known\nas ground\
    \ control points (GCPs), to determine and apply scaling and transformation to\
    \ the aerial\nimages [161]. Alternatively, instead of GCPs, the user can georeference\
    \ aerial images by using the\naccurate position of the camera, or by co-registration\
    \ with the existing georeferenced map [105,162].\nIn the case of UAS-based images,\
    \ the capture timing is scheduled to ensure a recommended\nforward overlap (>80%)\
    \ between successive images.\nThe ﬂight path is designed to ensure the\nrecommended\
    \ side overlap (>70%) between images from successive ﬂight strips. Thus, the captured\n\
    series of images are processed using the Structure-from-Motion (SfM) technique\
    \ to generate a 3D\npointcloud and orthomosaic [73,130] (see Figure 5). Commonly\
    \ used SfM software to process the\nremote sensing images are Agisoft PhotoScan\
    \ and Pix4D. The commonly retrieved outputs from the\nSfM software for assessment\
    \ of horticulture crops include the orthomosaic, digital surface model\n(DSM),\
    \ DEM, and 3D pointcloud [113,126,163]. This technique of georeferencing can be\
    \ applied to any\nsensor that produces images, e.g., RGB, thermal, or multispectral\
    \ cameras [126,164,165].\nAgronomy 2020, 10, 140 \n10 of 35 \n \nsensor [126].\
    \ The use of fixed-wing UAS has allowed carrying higher payloads due to the much\
    \ larger \nthrust-to-weight ratio as compared to a rotary-wing aircraft [155].\
    \ Similarly, recent advancement in \nUAS technology and lightweight sensors have\
    \ enabled multirotor (payload 5–6 kg readily available) \nto onboard multi-sensors.\
    \ \nWater status of crops is a complex process influenced by a number of factors\
    \ including the \nphysiology of the crop, available soil moisture, the size and\
    \ vigour of the crop, and meteorological \nfactors [30,108,116,156,157]. For this\
    \ reason, a multi-sensor platform is used to acquire measurements \nof the different\
    \ aspects of the crop for water status assessment [34,102,108]. The most common\
    \ \ncombination of sensors found in the literature is the RGB, multispectral (including\
    \ rededge and NIR \nbands) and thermal. Together, these sensors can be used to\
    \ investigate the water status of the crop \nusing various indicators, such as\
    \ PRI, CWSI, fluorescence, and structural properties, with the aim of \nimproving\
    \ the water use efficiency [102,110,158–160]. \n4. Techniques of Remote Sensing\
    \ in Horticulture \n4.1. Georeferencing of Remotely Sensed Images \nGeoreferencing\
    \ provides a spatial reference to the remotely sensed images such that the pixels\
    \ \nrepresenting crops or regions of interest on the images are correctly associated\
    \ with their position on \nEarth. The georeferencing process generally uses surveyed\
    \ coordinate points on the ground, known \nas ground control points (GCPs), to\
    \ determine and apply scaling and transformation to the aerial \nimages [161].\
    \ Alternatively, instead of GCPs, the user can georeference aerial images by using\
    \ the \naccurate position of the camera, or by co-registration with the existing\
    \ georeferenced map [105,162]. \nIn the case of UAS-based images, the capture\
    \ timing is scheduled to ensure a recommended \nforward overlap (>80%) between\
    \ successive images. The flight path is designed to ensure the \nrecommended side\
    \ overlap (>70%) between images from successive flight strips. Thus, the captured\
    \ \nseries of images are processed using the Structure-from-Motion (SfM) technique\
    \ to generate a 3D \npointcloud and orthomosaic [73,130] (see Figure 5). Commonly\
    \ used SfM software to process the \nremote sensing images are Agisoft PhotoScan\
    \ and Pix4D. The commonly retrieved outputs from the \nSfM software for assessment\
    \ of horticulture crops include the orthomosaic, digital surface model \n(DSM),\
    \ DEM, and 3D pointcloud [113,126,163]. This technique of georeferencing can be\
    \ applied to \nany sensor that produces images, e.g., RGB, thermal, or multispectral\
    \ cameras [126,164,165]. \n \nFigure 5. A typical workflow of structure-from-motion\
    \ (SfM) to produce georeferenced products from \nUAS-based image sets and ground\
    \ control points (adapted from [166,167]). SIFT = scale-invariant \nfeature transform;\
    \ ANN = approximate nearest neighbour; RANSAC = random sample consensus; \nFigure\
    \ 5. A typical workﬂow of structure-from-motion (SfM) to produce georeferenced\
    \ products from\nUAS-based image sets and ground control points (adapted from\
    \ [166,167]). SIFT = scale-invariant\nfeature transform; ANN = approximate nearest\
    \ neighbour; RANSAC = random sample consensus;\nCMVS = clustering views for multi-view\
    \ stereo; PMVS = patch-based multi-view stereo; GCP = ground\ncontrol points.\n\
    Agronomy 2020, 10, 140\n11 of 35\nThe complexity of georeferencing of hyperspectral\
    \ observations depends on the sensor type, i.e.,\nimaging or non-imaging. A non-imaging\
    \ spectroradiometer relies on the use of a GNSS antenna and\nan IMU for georeferencing\
    \ the point observation [130,132,138,168]. An imaging hyperspectral camera,\n\
    generally, in addition to GNSS and IMU measurement, uses the inter-pixel relation\
    \ in SfM to produce a\ngeoreferenced orthomosaic [40,134,135,169,170].\n4.2. Calibration\
    \ and Correction of Remotely Sensed Images\nEnsuring consistency, repeatability,\
    \ and quality of the spectral observation requires stringent\nradiometric, spectral,\
    \ and atmospheric corrections [123,171–177]. Spectral and radiometric calibration\n\
    is performed in the spectral calibration facility in darkroom settings. The sensor’s\
    \ optical properties\nand shift in spectral band position are corrected during\
    \ the spectral calibration process. Radiometric\ncalibration enables conversion\
    \ of the recorded digital values into physical units, such as radiance.\nInﬁeld\
    \ operation of the spectral sensor is inﬂuenced by variations in atmospheric transmittance\n\
    from thin clouds, invisible to the human observer. Changes in atmospheric transmittance\
    \ aﬀect the\nradiance incident on the plant. As a result, the change in acquired\
    \ spectral response by the sensor\nmay not represent the change in plants response\
    \ but the change in incident radiation on the plant.\nThe most common method to\
    \ convert the spectral data to reﬂectance is by generating an empirical line\n\
    relationship between sensor values and spectral targets, such as a Spectralon®\
    \ or calibration targets.\nThe use of downwelling sensors, such as a cosine corrector\
    \ [137], or the use of a ground-based PAR\nsensor enables absolute radiometric\
    \ calibration to generate radiance [130].\nThe calibration of the broad wavelength\
    \ multispectral sensor is generally less stringent than\nthe hyperspectral. Generally,\
    \ multispectral sensors are used to compute normalised indices such\nas NDVI.\
    \ The normalised indices are relatively less inﬂuenced, although signiﬁcant, by\
    \ the change\nin illumination conditions which aﬀect the entire spectrum proportionally\
    \ [29,101]. In this regard,\nradiometric calibration of the multispectral camera\
    \ has used a range of stringent to simpliﬁed, and\nvicarious approaches [123,125,171,173,178–180].\
    \ Some multispectral cameras are equipped with a\ndownwelling light sensor, which\
    \ is aimed at correcting for variations in atmospheric transmittance.\nHowever,\
    \ the performance of such downwelling sensors (without a cosine corrector) on\
    \ multispectral\ncameras have been reported to have directional variation resulting\
    \ in unstable correction, indicating\nthe inability of the sensor to incorporate\
    \ the entire hemisphere of diﬀused light [124,137].\nThe radiometric calibration\
    \ of the thermal images is typically based on the camera’s DN to object\ntemperature\
    \ curve, which provides the relationship between the DN of a pixel and a known\
    \ object\ntemperature, usually of a black body radiator. Measurement accuracy\
    \ and SNR of the camera under\nvarying ambient temperatures can be improved by\
    \ using calibration shutters, which are recently\navailable commercially. Furthermore,\
    \ for low measurement errors (under 1 ◦C), thermal data requires\nconsideration\
    \ to the atmospheric transmittance [18,102]. Flying over a few temperature reference\n\
    targets placed on the ground reduces the temporal drift of the camera [142,143,181].\
    \ Temperature\naccuracy within a few degrees was achieved by ﬂying over the targets\
    \ three times (at the start, middle\nand end of UAS operation) and using three\
    \ separate calibration equations for each overpass [142].\nAdditionally, using\
    \ the redundant information from multiple overlapping images, drift correction\n\
    models have been proposed, which lowered temperature error by 1 ◦C as compared\
    \ to uncorrected\northomosaic [152]. The manufacturer stated accuracies (generally\
    \ ±5 ◦C) can be suﬃcient to access the\nﬁeld variability and to detect “hotspots”\
    \ of water status. However, the aforementioned calibration and\ncorrection of\
    \ the thermal cameras are required for quantitative measurement as a goal [143].\
    \ In this\nregard, current challenges and best practices for the operation of\
    \ thermal cameras onboard a UAS is\nprovided in the literature [143].\n4.3. Canopy\
    \ Data Extraction\nA key challenge in remote sensing of horticultural as compared\
    \ to agricultural crops arises due\nto the proportion of inter-row ground/vegetation\
    \ cover and resulting mixed pixels. The proportion\nAgronomy 2020, 10, 140\n12\
    \ of 35\nof the mixed pixels increases with the decrease in spatial resolution\
    \ of the image. Most of the pixels\ntowards the edge of the canopy contain a blend\
    \ of information originating from the sun-lit canopy,\nshadowed leaves, and inter-row\
    \ bare soil/cover crop. A further challenge can arise for some crops,\nsuch as\
    \ grapevine, due to overlapping of adjacent plants.\nThe canopy data from orthomosaic\
    \ has been extracted using either a pixel-based or an object-based\napproach.\
    \ Earlier studies manually sampled from the centre of crop row which most likely\
    \ eliminated\nthe mixed pixels [182]. In the pixel-based approach, techniques,\
    \ such as applying global threshold\nand masking, have been used. Binary masks,\
    \ such as NDVI, eliminates non-canopy pixels from\nthe sampling [82,84]. Combining\
    \ the NDVI mask with the canopy height mask can exclude the\npixels associated\
    \ with non-vegetation, as well as vegetation that does not meet the height threshold.\n\
    The pixel-based approach, however, can result in inaccurate identiﬁcation of some\
    \ crops due to pixel\nheterogeneity, mixed pixels, spectral similarity, and crop\
    \ pattern variability.\nIn the object-based approach, using object detection techniques,\
    \ neighbouring pixels with\nhomogenous information, such as spectral, textural,\
    \ structural, and hierarchical features, are grouped\ninto “objects”. These objects\
    \ are used as the basis of object-based image analysis (OBIA) classiﬁcation\n\
    using classiﬁers, such as k-nearest neighbour, decision tree, support vector machine,\
    \ random forest,\nand maximum likelihood [122,183–185]. In the horticultural environment,\
    \ OBIA has been adopted\nto classify and sample from pure canopy pixels [119,122,186].\
    \ Consideration should be provided on\nthe number of features and their suitability\
    \ for a speciﬁc application to reduce the computational\nburden, as well as to\
    \ maintain the accuracies. The generalisation of these algorithms for transferability\n\
    between study sites usually penalises the achievable accuracy. For details in\
    \ object-based approach of\nsegmentation and classiﬁcation, readers are directed\
    \ to literatures [122,183,185,187–189].\nOther techniques found in the literature\
    \ include algorithms, such as ‘Watershed’, which has been\ndemonstrated in palm\
    \ orchards [82,190]. Vine rows and plants have been isolated and classiﬁed using\n\
    image processing techniques, such as clustering and skeletisation [188,191–193].\
    \ Similarly, the gridded\npolygon, available in common GIS software, such as ArcGIS\
    \ and QGIS, can be used in combination\nwith zonal statistics for this purpose.\
    \ When working with the low-resolution images, co-registration\nwith the high-resolution\
    \ images has been proposed, whereby, the high-resolution images enable better\n\
    delineation of the mixed pixels [194]. For this reason, spectral and thermal sensors,\
    \ which are usually\nlow in resolution, are generally employed along with high-resolution\
    \ digital cameras.\n4.4. Indicators of Crop Water Status\nA crop’s biophysical\
    \ and biochemical attributes can be approximated using diﬀerent indices and\n\
    quantitative products. For example, CWSI is used to proxy leaf water potential\
    \ (Ψleaf), stem water\npotential (Ψstem), gs, and net photosynthesis (Pn) [83,100,195].\
    \ With regard to horticultural crops, water\nstatus has been assessed using a\
    \ number of spectral and thermal indices (Table 2).\nTable 2. Commonly used vegetation\
    \ and thermal indices to study the water status of horticultural crops.\nIndicators\n\
    Sensor\nPurpose\nReferences\nTc, (Tc − Ta)\nThermal\nΨstem, gs, yield\n[34,82,85,99,110]\n\
    Ig, I3\nThermal\nΨstem, gs\n[82,196]\nCWSI\nThermal\nΨleaf, Ψstem, gs, Pn, yield\n\
    [18,31,33,85,90,97,99,100,182,194,197–199]\n(Tc − Ta)/NDVI\nThermal + multispectral\n\
    Ψstem, gs\n[82,200]\nNDVI\nMultispectral\nΨstem, gs, yield, LAI, vigour\n[34,56,82,86,182,201]\n\
    GNDVI\nMultispectral\nΨstem, gs, yield\n[34,82]\nRDVI\nMultispectral\nΨstem, gs\n\
    [82,86,182]\nPRI\nMultispectral\nΨleaf, gs\n[86,110,182]\nFluorescence\nHyperspectral\n\
    Ψleaf, gs\n[110]\nWBI\nHyperspectral\nΨleaf, gs\n[139,202,203]\nSIF\nHyperspectral\n\
    Water stress\n[204–206]\nNote the acronyms: Tc = Canopy temperature, Ta = ambient\
    \ temperature, Ig = conductance index, I3 = stomatal\nconductance index, CWSI\
    \ = crop water stress index, NDVI = normalised diﬀerence vegetation index, GNDVI\
    \ = green\nnormalised diﬀerence vegetation index, RDVI = renormalized diﬀerence\
    \ vegetation index, PRI = photochemical\nreﬂectance index, Fluorescence = chlorophyll\
    \ ﬂuorescence, WBI = water band index, SIF = solar-induced chlorophyll\nﬂuorescence,\
    \ LAI = leaf area index.\nAgronomy 2020, 10, 140\n13 of 35\n4.4.1. Canopy Temperature\n\
    A plant maintains its temperature by transpiring through the stomata to balance\
    \ the energy\nﬂuxes in and out of the canopy. As the plant experience stress (both\
    \ biotic and abiotic), the rate of\ntranspiration decreases, which results in\
    \ higher canopy temperature (Tc), which can be a proxy to\nunderstand the water\
    \ stress in the plant [207]. In this regard, crop water stress showed a correlation\n\
    with canopy temperature extracted from the thermal image [208], which enables\
    \ mapping the spatial\nvariability in water status [209]. Leaf/canopy temperature\
    \ alone, however, does not provide a complete\ncharacterisation of crop water\
    \ status, for instance, an equally stressed canopy can be 25 ◦C or 35 ◦C,\ndepending\
    \ on the current ambient temperature (Ta). Thus, canopy-to-air temperature diﬀerence\n\
    (Tc − Ta) was proposed, which showed a good correlation with the Ψstem, Ψleaf,\
    \ and gs in horticultural\ncrops [85,99,182].\n4.4.2. Normalised Thermal Indices\n\
    The CWSI, the conductance index (Ig) and the stomatal conductance index (I3) are\
    \ thermal\nindices most commonly used to estimate crop water status and gs [210–212].\
    \ These indices provide\nsimilar information, however, use a diﬀerent range of\
    \ numbers to represent the level of water stress.\nThe CWSI is normalised within\
    \ zero and one, whereas Ig and I3 represent stress using numbers\nbetween zero\
    \ and inﬁnity. CWSI has been adopted most widely in horticultural applications\
    \ to\nassess the water status of crops, such as the grapevines [100,213], almond\
    \ [91,198], citrus [85,110], and\nothers [18,87,99,214]. By normalising between\
    \ the lower and upper limits of (Tc − Ta), the CWSI of the\ncanopy presents quantiﬁable\
    \ relative water stress. The formula for CWSI computation is deﬁned as in\nEquation\
    \ (1) [208,212].\nCWSI =\n(Tc − Ta) − (Tc − Ta)LL\n(Tc − Ta)UL − (Tc − Ta)LL\n\
    (1)\nwhere (Tc − Ta)UL and (Tc − Ta)LL represent the upper and lower bound of\
    \ (Tc − Ta) which are found in\nthe water-stressed canopy and well-watered canopy\
    \ transpiring at the full potential (or maximum) rate,\nrespectively. Assuming\
    \ a constant ambient temperature, Equation (1) can be simpliﬁed to Equation (2),\n\
    which is the most widely reported formulation of CWSI with regard to the horticultural\
    \ remote sensing.\nCWSI = (Tc − Twet)\n\x10\nTdry − Twet\n\x11\n(2)\nwhere Twet\
    \ is the temperature of canopy transpiring at the maximum potential, and Tdry\
    \ is the\ntemperature of the non-transpiring canopy. CWSI has been shown to be\
    \ well-correlated with direct\nmeasurements of crop water status in the horticultural\
    \ environment [18,31,32,90,99]. In this regard,\na correlation of CWSI with various\
    \ ground measurements, such as Ψleaf [18,31,197], Ψstem [33,90,194],\nand gs [18,90,100],\
    \ have been established. Diurnal measurements of CWSI compared with Ψleaf showed\n\
    the best correlation at noon [89,197,209].\nCWSI is a normalised index, i.e.,\
    \ relative to a reference temperature range between Twet and Tdry,\nwhich is speciﬁc\
    \ to a region and crop type; thus, CWSI is not a universal quantitative indicator\
    \ of crop\nwater status. For instance, a CWSI of 0.5 for two diﬀerent varieties\
    \ of grapevines at diﬀerent locations\ndoes not conclusively inform that they\
    \ have equal or superior/inferior water status. Furthermore,\nthe degree of correlation\
    \ can change depending on the isohydric/anisohydric response of crop [214]\nwhere\
    \ early/late stomatal closure aﬀects the indicators of water stress [110]. Moreover,\
    \ phenological\nstage aﬀects the relationship between remotely sensed CWSI and\
    \ water stress [197]. Thus, water stress\nin a diﬀerent crop, at a diﬀerent location\
    \ and at a diﬀerent phenological stage, will have a unique\ncorrelation with CWSI\
    \ and, therefore, needs to be established independently.\nThere are multiple methods\
    \ to measure the two reference temperatures, Twet and Tdry, which\ncould result\
    \ in variable CWSI values depending on the method used. The ﬁrst method is to\
    \ measure the\ntwo reference temperatures on the crop of interest. Tdry can be\
    \ estimated by inducing stomatal closure,\nAgronomy 2020, 10, 140\n14 of 35\n\
    which is the leaf temperature approximately 30 min after applying a layer of petroleum\
    \ jelly e.g.,\nVaseline to both sides of a leaf. This eﬀectively blocks stomata\
    \ and, therefore, impedes leaf transpiration.\nTwet can be estimated by measuring\
    \ leaf temperature approximately 30 s after spraying water on the\nleaf, which\
    \ emulates maximum transpiration [23,83]. The advantage of this method is that\
    \ the stress\nlevels are normalised to actual plants response, whereas the necessity\
    \ to repeat the measurement for\nevery test site after each ﬂight can be cumbersome.\
    \ In an alternative (second) approach the range can\nbe established based on meteorological\
    \ data e.g., setting Tdry to 5 ◦C above air temperature and Twet\nmeasured from\
    \ an artiﬁcial surface. This method is also limited to local scale and presents\
    \ a problem\nregarding the choice of material, which ideally needs to have similar\
    \ to leaf emissivity, aerodynamic\nand optical properties [54,87]. The third method\
    \ uses the actual temperature measurement range\nof the remote sensing image [33,97].\
    \ This method is simple to implement, however, works on the\nassumption that the\
    \ ﬁeld contains enough variability to contain a representative Twet and Tdry.\
    \ Fourth,\nthe reference temperatures can be estimated by theoretically solving\
    \ for the leaf surface energy balance\nequations, however, are limited by the\
    \ necessity to compute the canopy aerodynamic resistance [87].\nStandard and robust\
    \ Twet and Tdry measurements are needed to characterize CWSI with accuracy,\n\
    especially for temporal analysis [85,87,211]. The level of uncertainty due to\
    \ the adaptation of diﬀerent\napproaches for Twet and Tdry determination in the\
    \ instantaneous and seasonal measurements of CWSI\nis not known. Nonetheless,\
    \ adopting a consistent approach, CWSI has been shown to be suitable for\nmonitoring\
    \ the water status and making irrigation decisions of horticultural crops [31,85].\n\
    4.4.3. Spectral Indices\nCrops reﬂectance properties convey information about\
    \ the crop, for instance, a healthier crop has\nhigher reﬂectance in the NIR band.\
    \ Most often, the bands are mathematically combined to form VIs,\nwhich provide\
    \ information on the crop’s health, growth stage, biophysical properties, leaf\
    \ biochemistry,\nand water stress [29,215–218]. Using multispectral or hyperspectral\
    \ data, several Vis, such as green\nnormalised diﬀerence vegetation index (GNDVI),\
    \ renormalised diﬀerence vegetation index (RDVI),\noptimized soil-adjusted vegetation\
    \ index (OSAVI), transformed chlorophyll absorption in reﬂectance\nindex (TCARI),\
    \ and TCARI/OSAVI, amongst others [34,79,82], can be calculated that correlate\
    \ with the\nwater stress of horticultural crops (see Table 2). The most widely\
    \ studied VI in horticulture, in this\nregard, is the NDVI (Equation (3)).\nNDVI\
    \ = Rnir − Rr\nRnir + Rr\n(3)\nwhere Rnir and Rr represent the spectral reﬂectance\
    \ acquired at the NIR and red spectral regions,\nrespectively. In horticulture,\
    \ NDVI has been used as a proxy to estimate the vigour, biomass, and water\nstatus\
    \ of the crop. A vigorous canopy with more leaves regulates more water, therefore\
    \ remaining\ncooler when irrigated [200] and experiencing early water stress when\
    \ unirrigated. With regard to\nirrigation, the broadband normalised spectral indices\
    \ (such as NDVI) are suitable to detect spatial\nvariability and to identify the\
    \ area that is most vulnerable to water stress. However, these indices are\nnot\
    \ expected to change rapidly to reﬂect the instantaneous water status of plants\
    \ that are needed to\nmake decisions on irrigation scheduling.\nThe multispectral\
    \ indices along with complementary information in thermal wavelengths have\nproven\
    \ to be well suited to monitoring vegetation, speciﬁcally in relation to water\
    \ stress [219]. The ratio\nof canopy surface temperature to NDVI, deﬁned as temperature-vegetation\
    \ dryness index (TVDI),\nwas found to be useful for the study of water status\
    \ in horticultural crops. TVDI exploits the fact that\nvegetation with larger\
    \ NDVI will have a lower surface temperature unless the vegetation is under\n\
    stress. As most vegetation normally remains green after an initial bout of water\
    \ stress, the TVDI is\nmore suited than NDVI for early detection of water stress\
    \ as the surface temperature can rise rapidly\neven during initial water stress\
    \ [200].\nSimilarly, narrowband VIs that have been studied in relation to remote\
    \ sensing of water status are\nPRI and chlorophyll ﬂuorescence, which have been\
    \ directly correlated to the crop Ψleaf, gs [110,182,204].\nAgronomy 2020, 10,\
    \ 140\n15 of 35\nSeveral hyperspectral indices to estimate water status have been\
    \ identiﬁed [139]; however, their\napplication in remote sensing of horticultural\
    \ crops is at its infancy. Hyperspectral indices speciﬁc to\nwater absorption\
    \ bands around 900 nm, 1200 nm, 1400 nm, and 1900 nm may be used to detect the\n\
    water status of horticultural crops. The absorption features were found to be\
    \ highly correlated with\nplant water status [139]. Water band index (WBI), as\
    \ deﬁned in Equation (4), has been shown to closely\ntrack the changes in the\
    \ plant water status of various crops [202,203].\nWBI = R970\nR900\n(4)\nOther\
    \ water-related hyperspectral indices with potential application for horticultural\
    \ crops can\nbe found in the literature [139,202,203]. Hyperspectral data possess\
    \ the capability to reﬂect the\ninstantaneous water status of the plant, which\
    \ can be useful for quantitative decision-making on\nirrigation scheduling.\n\
    4.4.4. Soil Moisture\nThe moisture status of the soil provides an indication of\
    \ the available water resource to the crop.\nSoil moisture is traditionally measured\
    \ indirectly using soil moisture sensors placed below the surface\nof the soil.\
    \ A key challenge with using soil moisture sensors are the spatial distribution\
    \ of moisture,\nboth vertically and horizontally, to account for inherent ﬁeld-scale\
    \ variability. For instance, the root\nsystem of some horticultural crops, such\
    \ as grapevine, is capable of accessing water up to 30 m deep,\nwhile customer-grade\
    \ soil moisture probes generally extend to 1.5 m in depth or less. Thus, soil\n\
    moisture probes do not capture all the water available to the crop as they are\
    \ point measures and\nnot necessarily where the roots are located. Moreover, estimation\
    \ of soil moisture across spatial and\ntemporal scales is of interest for various\
    \ agricultural and hydrological studies. Optical, thermal, and\nmicrowave remote\
    \ sensing with their advantages relating to high spatial scale and temporal resolutions\n\
    could potentially be used for soil moisture estimation [220–222]. L-band microwave\
    \ radiometry,\na component of synthetic aperture radar systems, has been shown\
    \ to be a reliable approach to estimate\nsoil moisture via satellite-based remote\
    \ sensing [223], such as using the ESA’s Soil Moisture and\nOcean Salinity (SMOS)\
    \ [224] and NASA’s Soil Moisture Active Passive (SMAP) satellites [225,226].\n\
    The limitation of the SMOS and SMAP missions, with regard to horticultural application,\
    \ is their\ndepth of retrieval (up to 5 cm) and spatial resolution (in the order\
    \ of tens of kilometre) [227–229].\nAs an airborne application, the volumetric\
    \ soil moisture has been estimated by analysing the SNR of\nthe GNSS interference\
    \ signal [230,231]. With aforementioned capabilities, a combination of satellite\n\
    and airborne remote sensing may, in the future, be a reliable tool to map soil\
    \ moisture across spatial,\ntemporal and depth scales.\n4.4.5. Physiological Attributes\n\
    Using the SfM on remotely-sensed images, 3D canopy structure, terrain conﬁgurations,\
    \ and canopy\nsurface models can be derived [113,114,119,186,232]. By employing\
    \ a delineation algorithm on the 3D\nmodels, the 3D attributes of the crops and\
    \ macrostructure are determined more accurately [120,122,233].\nCrop surface area\
    \ and terrain conﬁguration (e.g., slope and aspect) may help to develop an optimal\n\
    resource management strategy. For example, crops located at a higher elevation\
    \ within an irrigation\nzone may experience a level of water stress due to the\
    \ gravitational ﬂow of irrigated water.\nUsing the structural measurements, such\
    \ as the canopy height, canopy size, the envelope of each\nrow, LAI, and porosity,\
    \ among others, the water demand of the crop may be estimated. Generally,\nlarger\
    \ canopies tend to require more water than smaller canopies with less leaf area\
    \ [116,157]. Using\nthe temporal measurement of the plant’s 3D attributes, the\
    \ vigour can be computed. Monitoring\ncrop vigour over the season and over subsequent\
    \ years can provide an indication of its health and\nperformance, e.g., yield,\
    \ within an irrigation zone. Canopy structure metrics are closely related to\n\
    horticultural tree growth and provide strong indicators of water consumption,\
    \ whereby canopy size\nAgronomy 2020, 10, 140\n16 of 35\ncan be used to determine\
    \ its water requirements [234]. Other 3D attributes, such as the crown perimeter,\n\
    width, height, area, and leaf density, have been shown to enable improved pruning\
    \ of horticultural\nplants [116,119].\nLAI can be estimated using the 3D attributes\
    \ obtained from remote sensing [114,157,201], whereby,\nhigher LAI is equivalent\
    \ to more leaf layers, implying greater total leaf area and, consequently, canopy\n\
    transpiration. Leaf density, LAI, and exposed leaf area of a crop drive its water\
    \ requirement and\nproductivity [235–237]. Knowledge of ﬁeld attributes, such\
    \ as row and plant spacing, may assist in\ninter-row surface energy balance to\
    \ determine the irrigation need of the plant [238]. Combining the\nstructural\
    \ properties with spectral VIs provide an estimation of biomass [239], which can\
    \ serve as\nanother indicator of the plant’s water requirements. Although physiological\
    \ attributes have been used\nto understand plant water status and its spatial\
    \ variability, they have not been directly applied to make\nquantitative decisions\
    \ on irrigation.\n4.4.6. Evapotranspiration\nThe estimation of ET via remote sensing,\
    \ numerical modelling, and empirical methods have been\nextensively studied and\
    \ reviewed in the literature [240–247]. These models are based on either surface\n\
    energy balance (SEB), Penman-Monteith (PM), Maximum entropy production (MEP),\
    \ water balance,\nwater-carbon linkage, or empirical relationships.\nSEB models\
    \ are based on a surface energy budget in which the latent heat ﬂux is estimated\
    \ as a\nresidual of the net radiation, soil heat ﬂux, and sensible heat ﬂux. The\
    \ models are either one-source\n(canopy and soil treated as a single surface for\
    \ the estimation of sensible heat ﬂux) or two-source\n(canopy and soil surfaces\
    \ treated separately). Improvements over the original one-source SEB models\n\
    were in the form of Surface Energy Balance Algorithm for Land (SEBAL) algorithm\
    \ [248,249] and\nMapping EvapoTranspiration with high Resolution and Internalized\
    \ Calibration (METRIC) [249,250].\nSEBAL oﬀers a simpliﬁed approach to collect\
    \ ET data at both local and regional scales thereby increasing\nthe spatial scope,\
    \ while METRIC uses the same (SEBAL) technique but auto-calibrates the model using\n\
    hourly ground-based reference ET (ETr) data [251]. As such, these and other (e.g.,\
    \ MEP) models rely\non accurate measurements of surface (e.g., canopy) and air\
    \ temperatures, which can be erroneous\nunder non-ideal conditions, e.g., cloudy\
    \ days. There is also a reliance on ground-based sensors to\ncapture ambient air\
    \ temperatures required by the model.\nAmong the existing methods, FAO’s PM is\
    \ the most widely adopted model to estimate reference\nET (ETref or ET0) [252].\
    \ The PM method uses incident and reﬂected solar radiation, emitted thermal\n\
    radiation, air temperature, wind speed, and vapour pressure to calculate ET0 [253].\
    \ Remote sensing\nprovides a cost-eﬀective method to estimate the ET0 at regional\
    \ to global scales [241] by estimating\nreﬂected solar and emitted thermal radiation.\
    \ One of the advantages of using the PM approach is\nthat it is parametrised using\
    \ micrometeorological data easily obtained from ground-based automatic\nweather\
    \ stations. However, PM suﬀers from the drawback that canopy transpiration is\
    \ not dynamic\nas inﬂuenced by soil moisture availability via stomatal regulation\
    \ [241]. From a practical standpoint,\nPM-derived ET0 estimates are used in conjunction\
    \ with crop factors or crop coeﬃcients (kc), which are\nclosely related to the\
    \ light interception of the canopy [254].\nCrop evapotranspiration (ETc) is deﬁned\
    \ as the product of kc and ET0. In the absence of accurate\nETc measurements,\
    \ kc is an easy and practical means of getting reliable estimates of ETc using\
    \ ET0 [255].\nIn this regard, studies have focused on the use of remote sensing\
    \ to study spatial variability in kc and\nETc [101,256–258]. Thermal and NIR imagery\
    \ can be used to compute kc and ETc as transpiration\nrate is closely related\
    \ to canopy temperature [259–261] and kc has been shown to correlate with\ncanopy\
    \ reﬂectance [101,255]. Various thermal indices, such as CWSI, canopy temperature\
    \ ratio, canopy\ntemperature above non-stressed, and canopy temperature above\
    \ canopy threshold, can be used to\nestimate ETc, where CWSI- based ETc was found\
    \ to be the most accurate [24].\nET at a larger scale is typically estimated based\
    \ on satellite remote sensing. The temporal resolution\nof satellites is, however,\
    \ low and inadequate for horticultural applications, such as irrigation scheduling\n\
    Agronomy 2020, 10, 140\n17 of 35\n(e.g., Landsat has a 16-day revisit cycle).\
    \ In contrast, high temporal resolution satellites are coarse in\nspatial resolution\
    \ for ﬁeld-scale observations [25]. The daily or even instantaneous estimation\
    \ of ETc at\nthe ﬁeld scale is crucial for irrigation scheduling and is expected\
    \ to have great application prospects\nin the future [240,259,262,263]. In this\
    \ regard, the future direction of satellite-based ET estimates\nmay focus on temporal\
    \ downscaling either by extrapolation of instantaneous measurement [264],\ninterpolation\
    \ between two successive observations [201], data fusion of multiple satellites\
    \ [25,260], and\nspatial downscaling using multiple satellites [265–268]. An example\
    \ of early satellite-based remote\nsensing for ET is the MODIS Global Evapotranspiration\
    \ Project (MOD16), which was established in\n1999 to provide daily estimates of\
    \ global terrestrial evapotranspiration using data acquired from a\npair of NASA\
    \ satellites in conjunction with Algorithm Theoretical Based Documents (ATBDs)\
    \ [269].\nThese estimates correlated well with ground-based eddy covariance ﬂux\
    \ tower estimates of ET despite\ndiﬀerences in the uncertainties associated with\
    \ each of these techniques.\nUASs are being increasingly utilised to acquire multi-spectral\
    \ and thermal imagery to compute\nET at an unprecedented spatial resolution [270,271].\
    \ Using high-resolution images, ﬁltering the\nshadowed-pixel is possible, which\
    \ showed signiﬁcant improvement in the estimation of ET in\ngrapevine [101]. Using\
    \ high-resolution thermal and/or multispectral imagery, ET has been derived for\n\
    horticultural crops, such as grapevines [270] and olives [271]. The seasonal monitoring\
    \ of ETc at high\nspatial and temporal resolutions is of high importance for precision\
    \ irrigation of horticultural crops in\nthe future [259].\n5. Case Studies on\
    \ the Use of Remote Sensing for Crop Water Stress Detection\nThe increasing prevalence\
    \ of UAS along with low-cost camera systems has brought about much\ninterest in\
    \ the characterisation of crop water status/stress during the growing season to\
    \ inform orchard\nor farm management decisions, in particular, irrigation scheduling\
    \ [272,273]. Traditional methodologies\nto assess crop water stress are constrained\
    \ by limitations relating to large farm sizes and accompanying\nspatial variability,\
    \ high labour costs to collect data, and access to instrumentation that is both\
    \ inexpensive\nand portable [272]. The beneﬁts of precision agriculture [274],\
    \ including through precision irrigation\npractices [1], result in higher production\
    \ eﬃciencies and economic returns through site-speciﬁc crop\nmanagement [275,276].\
    \ This approach has motivated the use of high-resolution imagery acquired\nfrom\
    \ remote sensing to identify irrigation zones [99,277]. The ﬁrst horticultural\
    \ applications of UAS\nplatforms for crop water status measurement were in orange\
    \ and peach orchards where both thermal\nand multispectral-derived VIs, speciﬁcally\
    \ the PRI, were shown to be well-correlated to crop water\nstatus [102]. Here,\
    \ we explore the use of remote sensing and accompanying image acquisition platforms\n\
    to characterise the spatial and temporal patterns of the water status of two economically\
    \ important\nhorticultural crops, grapevine and almond.\n5.1. Grapevine (Vitis\
    \ spp.)\nThe characterisation of spatial variability in vine water status in a\
    \ vineyard provides valuable\nguidance on irrigation scheduling decisions [82],\
    \ and this spatial variability can be eﬃciently\ncharacterised by the use of remote\
    \ sensing platforms [29]. The ﬁrst use of remote sensing in vineyards\nfor crop\
    \ water stress detection was using manned aircraft ﬂown over an irrigated vineyard\
    \ in Hanwood\n(NSW) Australia where CWSI was mapped at a spatial resolution of\
    \ 10 cm [278]. Subsequently, UAS\nplatforms began to be used in vineyards for\
    \ vine water stress characterisation. Early work in this\ncrop used a fuel-based\
    \ helicopter with a 29 cc engine and equipped with thermal (Thermovision\nA40M)\
    \ and multispectral (Tetracam MCA-6) camera systems [102]. The study observed\
    \ strong (inverse)\nrelationships between (Tc − Ta) and gs. A related study showed\
    \ strong correlations between thermal\nand multispectral VIs, and traditional,\
    \ ground-based measures of water status, such as Ψleaf and\ngs [182]. In this\
    \ study, normalised PRI was shown to have correlation coeﬃcients exceeding 0.8\
    \ versus\nboth Ψleaf and gs, indicating that remotely-sensed VIs can be reliable\
    \ indicators of vine water status.\nThermal indices, such as (Tc − Ta) and CWSI,\
    \ were also well-correlated to Ψleaf and gs at speciﬁc times of\nAgronomy 2020,\
    \ 10, 140\n18 of 35\nthe day. The use of thermal indices, such as CWSI or Ig,\
    \ requires reference temperatures (Twet, Tdry) or\nnon-water stressed baselines\
    \ (NWSB) [279]. Due to the diﬃculty of obtaining reference temperatures or\nNWSB\
    \ using remote sensing, some authors have used the minimum temperature found from\
    \ all canopy\npixels as Twet [199], and Ta + 5 ◦C as Tdry [213,280]. NWSB is typically\
    \ obtained from well-watered\ncanopies, measuring (Tc − Ta) under a range of vapour\
    \ pressure deﬁcit conditions [279]. Thermal water\nstress indices have also shown\
    \ to be useful to distinguish between water use strategies of diﬀerent\ngrapevine\
    \ cultivars [83,281], which is useful for customising irrigation scheduling based\
    \ on the speciﬁc\nwater needs of a given cultivar. More recently, studies have\
    \ used UAS-based multispectral-based\nVIs to train an artiﬁcial neural network\
    \ (ANN) models to predict spatial patterns of Ψstem [84,282].\nUsing UAS-based\
    \ multispectral data, the authors showed that ANN estimated Ψstem with higher\n\
    accuracy (RMSE lower than 0.15 MPa) as compared to the conventional multispectral\
    \ indices based\nestimation (RMSE over 0.32 MPa).\n5.2. Almond (Prunus Dulcis)\n\
    Almonds are perennial nut trees grown in semi-arid climates and are reliant on\
    \ irrigation\napplications. Their water requirements are relatively high, with\
    \ seasonal ETc exceeding 1000 mm [283].\nThe requirement for prudent irrigation\
    \ management in the face of decreased water availability is\ncritical for maintaining\
    \ tree productivity, yield, and nut quality [284]. Towards this goal, UAS-based\n\
    remote sensing has been used to characterise the spatial patterns of tree water\
    \ status in almond\norchards. A UAS-based thermal camera was used to acquire tree\
    \ the crown temperature data from\na California almond orchard; this temperature\
    \ was used to determine the temperature diﬀerence\nbetween crown and air (Tc −\
    \ Ta) and compared to shaded leaf water potential (Ψsl) [92]. The study\nfound\
    \ a strong negative correlation (R2 = 0.72) between (Tc − Ta) and Ψsl. The same\
    \ authors conducted\na follow on study in Spain on several fruit tree species\
    \ including almond. The negative relationship\n(slope and oﬀset) between (Tc −\
    \ Ta) and Ψstem was observed to vary based on the time of observation;\nmorning\
    \ measurements had weak relationships, whereas afternoon measurements had stronger\n\
    relationships [99]. Their proposed methodology allowed for the spatial characterisation\
    \ of orchard\nwater status on a single-tree basis, demonstrating the utility of\
    \ UAS-based crop water stress data.\nBeyond the characterisation of crop water\
    \ stress for irrigation scheduling, there is an opportunity to\nuse this data\
    \ to quantify the economic impact at a spatial level.\n6. Future Prospective and\
    \ Gaps in the Knowledge\nPrecision irrigation is a promising approach to increase\
    \ farm water use eﬃciency for sustainable\nproduction, including for horticultural\
    \ crops [3,5,9,10,274,285]. It is envisioned that the future of\nprecision irrigation\
    \ will incorporate UAS, manned aircraft, and satellite-based remote sensing platforms\n\
    alongside ground-based proximal sensors coupled with wireless sensor networks.\
    \ The automation\nof UAS technology will continue to develop further to a point\
    \ that even novice users can adopt\nthe technology with ease. It is also expected\
    \ that the data processing pipeline of remote sensing\nimages will become automated\
    \ to be ‘ﬁt for purpose’ for crop water status measurements. The ideal\nsolution\
    \ may lie in the use of satellites (or sometimes manned aircraft) for regional\
    \ estimation and\nplanning [55,260], UAS for seasonal monitoring and zoning [32,100,197,286],\
    \ proximal sensors for\ncontinuous measurement [287], and artiﬁcial intelligence\
    \ to derive decision-ready products [84,282]\nthat can be used for making irrigation\
    \ scheduling decisions [31,288–295]. Continued technological\ndevelopments in\
    \ this space will enable growers to acquire actionable data with ease, and eventually\n\
    transition towards semi-automated or fully-automated irrigation applications.\n\
    Remote sensing and current irrigation application technologies are limited in\
    \ temporal and\nspatial resolution, respectively. Although UAS technology can\
    \ deliver sub-plant level spatially explicit\ninformation of water status, the\
    \ size of the management block is much coarser, typically over 10 m.\nHence, further\
    \ improvements in variable rate application technologies, e.g., boom sprayers,\
    \ or zoned\ndrip irrigation, are required to fully exploit high-resolution UAS\
    \ measurements. Nonetheless, the\nAgronomy 2020, 10, 140\n19 of 35\nrequired resolution\
    \ of remote sensing should be guided by the underlying spatial variability of\
    \ the crop.\nFor ﬁelds with relatively lower spatial variability, low/medium-resolution\
    \ remote sensing imagery\nmay suﬃce for crop water status assessment [278,296,297].\n\
    Remote sensing provides an indirect estimate of plant water status using the regression-based\n\
    approach through several calculated reﬂectance indices. In comparison, physical\
    \ and mechanistic\nmodels, e.g., radiative transfer models and energy balance\
    \ models, incorporate both direct and indirect\nmeasures of the canopy, therefore\
    \ establishing a basis for diﬀerences in plant water status. Using a\nsimilar\
    \ approach, predictions of crop water status using regression-based remote sensing\
    \ models can\nbe improved by incorporating some direct auxiliary variables.\n\
    Further developments in thermal remote sensing are also expected, speciﬁcally,\
    \ the advent of new\nthermal and hybrid thermal-multispectral water status/stress\
    \ indices that are more sensitive to canopy\ntranspiration. The most widely-adopted\
    \ thermal index, CWSI, is an instantaneous measure that is\nnormalised to local\
    \ weather conditions and inﬂuenced by genotype and phenotype. For example,\nthe\
    \ relationship between CWSI and crop water status is inﬂuenced by environmental\
    \ conditions\n(e.g., high incident radiation and low humidity vs low incident\
    \ radiation and high humidity) and\nphenological stage [197,214,298]. As a result,\
    \ corresponding ground-based measurements are required\nfor each temporal remote\
    \ measurement to determine the correlation with water status. Hence, temporal\n\
    assessments of water status using thermal cameras will require the incorporation\
    \ of meteorological\ndata along with the thermal response using novel indices.\n\
    In the area of satellite remote sensing, we foresee further developments on temporal\
    \ downscaling\nto achieve daily measurements. A higher temporal resolution may\
    \ be achieved by fusion of multiple\nsatellite observations, such as freely available\
    \ Landsat and Sentinel. Further reductions of temporal\nresolution will require\
    \ interpolation between two successive observations. Furthermore, temporal\nmodels\
    \ of water status could be developed to assist the interpolation to eventually\
    \ satisfy the\nrequirements for irrigation scheduling [25,201,263]. The continued\
    \ advancement and greater availability\nof Nanosat/Cubesat may provide an alternate\
    \ method to capture high-resolution data at a higher\na greater temporal resolution,\
    \ which can be suitable to study the water status of horticultural\ncrops [299–301].\n\
    Crop water status is a complex phenomenon, which can be interpreted with respect\
    \ to a\nnumber of variables. These variables can include spectral response, thermal\
    \ response, meteorological\ndata, 3D attributes of the canopy, and macrostructure\
    \ of the block (farm).\nClearly, there is\nan opportunity for a multi-disciplinary\
    \ approach, potentially incorporating artiﬁcial intelligence\ntechniques which\
    \ incorporate the aforementioned variables to provide a robust estimation of crop\n\
    water status [84,141,282,302,303]. Furthermore, with machine learning algorithms,\
    \ hyperspectral\nremote sensing will provide a wealth of data to estimate crop\
    \ water status. A quantitative product,\nsuch as SIF, derived from hyperspectral\
    \ data will have the potential for direct quantiﬁcation of water\nstress [204,205,304].\
    \ In this regard, the upcoming FLEX satellite mission [305,306] and recent advances\n\
    in aerial spectroradiometry [109,132,137,307–310] dedicated for observation of\
    \ SIF may be unique and\npowerful tools for high-value horticultural crops.\n\
    Multi-temporal images represent an excellent resource for seasonal monitoring\
    \ of changes in crop\nwater status. Five to six temporal points of data acquisition\
    \ at critical phenological stages of crop\ndevelopment have been recommended for\
    \ irrigation scheduling [31,32]. However, for semi-arid or arid\nregions, irrigation\
    \ is typically required multiple times per week. Acquisition and post-processing\
    \ of\nremote sensing data for actionable products multiple times a week is currently\
    \ logistically unfeasible.\nThe fusion of UAS-based remote sensing data, continuous\
    \ ground-based proximal or direct sensors,\nincluding weather station data, can\
    \ potentially inform daily estimates of water status at canopy level.\nThis approach\
    \ will require predictive models, such as those based on machine learning algorithms,\
    \ to\nestimate the current and future water status of the crop. Eventually, growers\
    \ would beneﬁt from the\nknowledge of crop water requirements for the determination\
    \ of seasonal irrigation requirements to\nsustainably farm into the future.\n\
    Agronomy 2020, 10, 140\n20 of 35\nOne vision for the future of precision irrigation\
    \ is in automated pipelines to explicitly manage\nirrigation water at the sub-block\
    \ level. This automated pipeline would likely include remote and\nproximal data\
    \ acquisition and processing, prediction and interpretation of crop water status\
    \ and\nrequirements, and subsequently, control of irrigation systems. Recent rapid\
    \ developments in cloud\ncomputing and wireless technology could assist in the\
    \ quasi-real-time processing of the remote sensing\ndata soon after acquisition\
    \ [311–313]. Eventually, automation and computational power will merge to\ndevelop\
    \ smart technology in which artiﬁcial intelligence uses real-time data analysis\
    \ for diagnosis\nand decision-making. Growers of the future will be able to take\
    \ advantage of precise irrigation\nrecommendations using information sourced from\
    \ a ﬂeet of UAS that map large farm blocks on a daily\nschedule, continuous ground-based\
    \ proximal and direct sensors, and weather stations. This data can be\nstored\
    \ on and accessed from the cloud almost instantaneously, used in conjunction with\
    \ post-processing\nalgorithms for decision-making on optimised irrigation applications\
    \ [311,314].\n7. Conclusions\nThis paper provides a comprehensive review of the\
    \ use of remote sensing to determine the water\nstatus of horticultural crops.\
    \ One of our objectives was to survey the range of remote sensing tools\navailable\
    \ for irrigation decision-making. Earth observation satellite systems possess\
    \ the required bands\nto study the water status of vegetation and soil. Satellites\
    \ are more suitable for scouting, planning,\nand management of irrigation applications\
    \ that involve large areas, and where data acquisition is\nnot time-constrained.\
    \ Manned aircraft are sparingly used in horticultural applications due to the\n\
    cost, logistics, and speciﬁc expertise needed for the operation of the platform.\
    \ UAS-based remote\nsensing provides ﬂexibility in spatial resolution (crop level\
    \ observation achievable), coverage (over\n25 ha achievable in a single ﬂight),\
    \ spectral bands, as well as temporal revisit. Routine monitoring of\nhorticultural\
    \ crops for water status characterisation is, therefore, best performed using\
    \ a UAS platform.\nWe envision a future for precision irrigation where satellites\
    \ are used for planning, and UAS used in\nconjunction with a network of ground-based\
    \ sensors to achieve actionable products on a timely basis.\nThe plant’s instantaneous\
    \ response to water stress can be captured using thermal cameras (via\nindices,\
    \ such as CWSI) and potentially narrow-band hyperspectral sensors (via, for example,\
    \ SIF),\nmaking them suitable to draw quantiﬁable decisions with regard to irrigation\
    \ scheduling. Broadband\nmultispectral and RGB cameras capture the non-instantaneous\
    \ water status of crops, making them\nsuitable for general assessment of crop\
    \ water status. Integrated use of thermal and multispectral\nimagery may be the\
    \ simplest yet eﬀective sensor combinations to capture the overall as well as\n\
    instantaneous water status of the plant. With regard to irrigation scheduling,\
    \ further developments\nare required to establish crop-speciﬁc thresholds of remotely-sensed\
    \ indices to decide when and how\nmuch to irrigate.\nAuthor Contributions: Performed\
    \ the article review and prepared the original draft, D.G.; contributed to write\n\
    the case studies, V.P., and together with D.G. contributed to review and edit\
    \ the manuscript. All authors have read\nand agreed to the published version of\
    \ the manuscript.\nFunding: This research and the APC was funded by Wine Australia\
    \ (Grant number: UA 1803-1.3).\nAcknowledgments: The authors would like to acknowledge\
    \ the funding body Wine Australia, The University of\nAdelaide, and anonymous\
    \ reviewers for their contribution.\nConﬂicts of Interest: The authors declare\
    \ no conﬂict of interest.\nReferences\n1.\nMonaghan, J.M.; Daccache, A.; Vickers,\
    \ L.H.; Hess, T.M.; Weatherhead, E.K.; Grove, I.G.; Knox, J.W. More\n‘crop per\
    \ drop’: constraints and opportunities for precision irrigation in European agriculture.\
    \ J. Sci.\nFood Agric. 2013, 93, 977–980. [CrossRef]\n2.\nSmith, R. Review of\
    \ Precision Irrigation Technologies and Their Applications; University of Southern\
    \ Queensland\nDarling Heights: Queensland, Australia, 2011.\nAgronomy 2020, 10,\
    \ 140\n21 of 35\n3.\nPiao, S.; Ciais, P.; Huang, Y.; Shen, Z.; Peng, S.; Li, J.;\
    \ Zhou, L.; Liu, H.; Ma, Y.; Ding, Y.; et al. The impacts of\nclimate change on\
    \ water resources and agriculture in China. Nature 2010, 467, 43. [CrossRef]\n\
    4.\nHowden, S.M.; Soussana, J.-F.; Tubiello, F.N.; Chhetri, N.; Dunlop, M.; Meinke,\
    \ H. Adapting agriculture to\nclimate change. Proc. Natl. Acad. Sci. USA 2007,\
    \ 104, 19691–19696. [CrossRef]\n5.\nWebb, L.; Whiting, J.; Watt, A.; Hill, T.;\
    \ Wigg, F.; Dunn, G.; Needs, S.; Barlow, E. Managing grapevines through\nsevere\
    \ heat: A survey of growers after the 2009 summer heatwave in south-eastern Australia.\
    \ J. Wine Res.\n2010, 21, 147–165. [CrossRef]\n6.\nDatta, S. Impact of climate\
    \ change in Indian horticulture-a review. Int. J. Sci. Environ. Technol. 2013,\
    \ 2,\n661–671.\n7.\nWebb, L.; Whetton, P.; Barlow, E. Modelled impact of future\
    \ climate change on the phenology of winegrapes\nin Australia. Aust. J. Grape\
    \ Wine Res. 2007, 13, 165–175. [CrossRef]\n8.\nWang, J.; Mendelsohn, R.; Dinar,\
    \ A.; Huang, J.; Rozelle, S.; Zhang, L. The impact of climate change on China’s\n\
    agriculture. Agric. Econ. 2009, 40, 323–337. [CrossRef]\n9.\nBeare, S.; Heaney,\
    \ A. Climate change and water resources in the Murray Darling Basin, Australia.\n\
    In Proceedings of the 2002 World Congress of Environmental and Resource Economists,\
    \ Monterey, CA, USA,\n24–27 June 2002.\n10.\nKhan, S.; Tariq, R.; Yuanlai, C.;\
    \ Blackwell, J. Can irrigation be sustainable? Agric. Water Manag. 2006, 80,\n\
    87–99. [CrossRef]\n11.\nDroogers, P.; Bastiaanssen, W. Irrigation performance\
    \ using hydrological and remote sensing modeling.\nJ. Irrig. Drain. Eng. 2002,\
    \ 128, 11–18. [CrossRef]\n12.\nRay, S.; Dadhwal, V. Estimation of crop evapotranspiration\
    \ of irrigation command area using remote sensing\nand GIS. Agric. Water Manag.\
    \ 2001, 49, 239–249. [CrossRef]\n13.\nKim, Y.; Evans, R.G.; Iversen, W.M. Remote\
    \ sensing and control of an irrigation system using a distributed\nwireless sensor\
    \ network. IEEE Trans. Instrum. Meas. 2008, 57, 1379–1387.\n14.\nRitchie, G.A.;\
    \ Hinckley, T.M. The pressure chamber as an instrument for ecological research.\
    \ In Advances in\nEcological Research; Elsevier: Amsterdam, The Netherlands, 1975;\
    \ Volume 9, pp. 165–254.\n15.\nSmart, R.; Barrs, H. The eﬀect of environment and\
    \ irrigation interval on leaf water potential of four\nhorticultural species.\
    \ Agric. Meteorol. 1973, 12, 337–346. [CrossRef]\n16.\nMeron, M.; Grimes, D.;\
    \ Phene, C.; Davis, K. Pressure chamber procedures for leaf water potential\n\
    measurements of cotton. Irrig. Sci. 1987, 8, 215–222. [CrossRef]\n17.\nSantos,\
    \ A.O.; Kaye, O. Grapevine leaf water potential based upon near infrared spectroscopy.\
    \ Sci. Agric.\n2009, 66, 287–292. [CrossRef]\n18.\nBerni, J.A.J.; Zarco-Tejada,\
    \ P.J.; Sepulcre-Cantó, G.; Fereres, E.; Villalobos, F. Mapping canopy conductance\n\
    and CWSI in olive orchards using high resolution thermal remote sensing imagery.\
    \ Remote Sens. Environ.\n2009, 113, 2380–2388. [CrossRef]\n19.\nChaves, M.M.;\
    \ Santos, T.P.; de Souza, C.; Ortuño, M.; Rodrigues, M.; Lopes, C.; Maroco, J.;\
    \ Pereira, J.S.\nDeﬁcit irrigation in grapevine improves water-use eﬃciency while\
    \ controlling vigour and production quality.\nAnn. Appl. Biol. 2007, 150, 237–252.\
    \ [CrossRef]\n20.\nBravdo, B.; Hepner, Y.; Loinger, C.; Cohen, S.; Tabacman, H.\
    \ Eﬀect of irrigation and crop level on growth,\nyield and wine quality of Cabernet\
    \ Sauvignon. Am. J. Enol. Vitic. 1985, 36, 132–139.\n21.\nMatthews, M.; Ishii,\
    \ R.; Anderson, M.; O’Mahony, M. Dependence of wine sensory attributes on vine\
    \ water\nstatus. J. Sci. Food Agric. 1990, 51, 321–335. [CrossRef]\n22.\nReynolds,\
    \ A.G.; Naylor, A.P. ‘Pinot noir’ and ‘Riesling’ grapevines respond to water stress\
    \ duration and soil\nwater-holding capacity. HortScience 1994, 29, 1505–1510.\
    \ [CrossRef]\n23.\nAlvino, A.; Marino, S. Remote sensing for irrigation of horticultural\
    \ crops. Horticulturae 2017, 3, 40. [CrossRef]\n24.\nKullberg, E.G.; DeJonge,\
    \ K.C.; Chávez, J.L. Evaluation of thermal remote sensing indices to estimate\
    \ crop\nevapotranspiration coeﬃcients. Agric. Water Manag. 2017, 179, 64–73. [CrossRef]\n\
    25.\nSemmens, K.A.; Anderson, M.C.; Kustas, W.P.; Gao, F.; Alﬁeri, J.G.; McKee,\
    \ L.; Prueger, J.H.; Hain, C.R.;\nCammalleri, C.; Yang, Y.; et al. Monitoring\
    \ daily evapotranspiration over two California vineyards using\nLandsat 8 in a\
    \ multi-sensor data fusion approach. Remote Sens. Environ. 2015, 185, 155–170.\
    \ [CrossRef]\n26.\nJackson, R.D. Remote sensing of biotic and abiotic plant stress.\
    \ Annu. Rev. Phytopathol. 1986, 24, 265–287.\n[CrossRef]\nAgronomy 2020, 10, 140\n\
    22 of 35\n27.\nMoran, M.; Clarke, T.; Inoue, Y.; Vidal, A. Estimating crop water\
    \ deﬁcit using the relation between surface-air\ntemperature and spectral vegetation\
    \ index. Remote Sens. Environ. 1994, 49, 246–263. [CrossRef]\n28.\nLamb, D.; Hall,\
    \ A.; Louis, J. Airborne remote sensing of vines for canopy variability and productivity.\n\
    Aust. Grapegrow. Winemak. 2001, 449a, 89–94.\n29.\nHall, A.; Lamb, D.; Holzapfel,\
    \ B.; Louis, J. Optical remote sensing applications in viticulture-a review. Aust.\
    \ J.\nGrape Wine Res. 2002, 8, 36–47. [CrossRef]\n30.\nDe Bei, R.; Cozzolino,\
    \ D.; Sullivan, W.; Cynkar, W.; Fuentes, S.; Dambergs, R.; Pech, J.; Tyerman,\
    \ S.\nNon-destructive measurement of grapevine water potential using near infrared\
    \ spectroscopy. Aust. J. Grape\nWine Res. 2011, 17, 62–71. [CrossRef]\n31.\nBellvert,\
    \ J.; Zarco-Tejada, P.J.; Marsal, J.; Girona, J.; González-Dugo, V.; Fereres,\
    \ E. Vineyard irrigation\nscheduling based on airborne thermal imagery and water\
    \ potential thresholds. Aust. J. Grape Wine Res. 2016,\n22, 307–315. [CrossRef]\n\
    32.\nBellvert, J.; Marsal, J.; Girona, J.; Gonzalez-Dugo, V.; Fereres, E.; Ustin,\
    \ S.; Zarco-Tejada, P. Airborne thermal\nimagery to detect the seasonal evolution\
    \ of crop water status in peach, nectarine and Saturn peach orchards.\nRemote\
    \ Sens. 2016, 8, 39. [CrossRef]\n33.\nPark, S.; Ryu, D.; Fuentes, S.; Chung, H.;\
    \ Hernández-Montes, E.; O’Connell, M. Adaptive estimation of crop\nwater stress\
    \ in nectarine and peach orchards using high-resolution imagery from an unmanned\
    \ aerial vehicle\n(UAV). Remote Sens. 2017, 9, 828. [CrossRef]\n34.\nEspinoza,\
    \ C.Z.; Khot, L.R.; Sankaran, S.; Jacoby, P.W. High resolution multispectral and\
    \ thermal remote\nsensing-based water stress assessment in subsurface irrigated\
    \ grapevines. Remote Sens. 2017, 9, 961.\n[CrossRef]\n35.\nEzenne, G.I.; Jupp,\
    \ L.; Mantel, S.K.; Tanner, J.L. Current and potential capabilities of UAS for\
    \ crop water\nproductivity in precision agriculture. Agric. Water Manag. 2019,\
    \ 218, 158–164. [CrossRef]\n36.\nOliver, M.A.; Webster, R. Kriging: A method of\
    \ interpolation for geographical information systems. Int. J.\nGeogr. Inf. Syst.\
    \ 1990, 4, 313–332. [CrossRef]\n37.\nHa, W.; Gowda, P.H.; Howell, T.A. A review\
    \ of downscaling methods for remote sensing-based irrigation\nmanagement: Part\
    \ I. Irrig. Sci. 2013, 31, 831–850. [CrossRef]\n38.\nHa, W.; Gowda, P.H.; Howell,\
    \ T.A. A review of potential image fusion methods for remote sensing-based\nirrigation\
    \ management: Part II. Irrig. Sci. 2013, 31, 851–869. [CrossRef]\n39.\nBelward,\
    \ A.S.; Skøien, J.O. Who launched what, when and why; trends in global land-cover\
    \ observation\ncapacity from civilian earth observation satellites. ISPRS J. Photogramm.\
    \ Remote Sens. 2015, 103, 115–128.\n[CrossRef]\n40.\nLucieer, A.; Malenovskỳ,\
    \ Z.; Veness, T.; Wallace, L. HyperUAS—Imaging spectroscopy from a multirotor\n\
    unmanned aircraft system. J. Field Robot. 2014, 31, 571–590. [CrossRef]\n41.\n\
    McCabe, M.F.; Rodell, M.; Alsdorf, D.E.; Miralles, D.G.; Uijlenhoet, R.; Wagner,\
    \ W.; Lucieer, A.; Houborg, R.;\nVerhoest, N.E.; Franz, T.E.; et al. The future\
    \ of Earth observation in hydrology. Hydrol. Earth Syst. Sci. 2017,\n21, 3879.\
    \ [CrossRef]\n42.\nMatese, A.; Toscano, P.; Di Gennaro, S.; Genesio, L.; Vaccari,\
    \ F.; Primicerio, J.; Belli, C.; Zaldei, A.; Bianconi, R.;\nGioli, B. Intercomparison\
    \ of UAV, aircraft and satellite remote sensing platforms for precision viticulture.\n\
    Remote Sens. 2015, 7, 2971–2990. [CrossRef]\n43.\nMancini, A.; Frontoni, E.; Zingaretti,\
    \ P. Satellite and UAV data for Precision Agriculture Applications.\nIn Proceedings\
    \ of the 2019 International Conference on Unmanned Aircraft Systems (ICUAS 2019),\
    \ Atlanta,\nGA, USA, 11–14 June 2019; pp. 491–497.\n44.\nDiago, M.P.; Bellincontro,\
    \ A.; Scheidweiler, M.; Tardáguila, J.; Tittmann, S.; Stoll, M. Future opportunities\n\
    of proximal near infrared spectroscopy approaches to determine the variability\
    \ of vineyard water status.\nAust. J. Grape Wine Res. 2017, 23, 409–414. [CrossRef]\n\
    45.\nGutierrez, S.; Diago, M.P.; Fernández-Novales, J.; Tardaguila, J. Vineyard\
    \ water status assessment using\non-the-go thermal imaging and machine learning.\
    \ PLoS ONE 2018, 13, e0192037. [CrossRef] [PubMed]\n46.\nFernández-Novales, J.;\
    \ Tardaguila, J.; Gutiérrez, S.; Marañón, M.; Diago, M.P. In ﬁeld quantiﬁcation\
    \ and\ndiscrimination of diﬀerent vineyard water regimes by on-the-go NIR spectroscopy.\
    \ Biosyst. Eng. 2018, 165,\n47–58. [CrossRef]\nAgronomy 2020, 10, 140\n23 of 35\n\
    47.\nDiago, M.P.; Fernández-Novales, J.; Gutiérrez, S.; Marañón, M.; Tardaguila,\
    \ J. Development and validation of a\nnew methodology to assess the vineyard water\
    \ status by on-the-go near infrared spectroscopy. Front. Plant Sci.\n2018, 9,\
    \ 59. [CrossRef]\n48.\nAquino, A.; Millan, B.; Diago, M.-P.; Tardaguila, J. Automated\
    \ early yield prediction in vineyards from\non-the-go image acquisition. Comput.\
    \ Electron. Agric. 2018, 144, 26–36. [CrossRef]\n49.\nMarkham, B.L.; Helder, D.L.\
    \ Forty-year calibrated record of earth-reﬂected radiance from Landsat: A review.\n\
    Remote Sens. Environ. 2012, 122, 30–40. [CrossRef]\n50.\nToth, C.; Jó´zków, G.\
    \ Remote sensing platforms and sensors: A survey. ISPRS J. Photogramm. Remote\
    \ Sens.\n2016, 115, 22–36. [CrossRef]\n51.\nTyc, G.; Tulip, J.; Schulten, D.;\
    \ Krischke, M.; Oxfort, M. The RapidEye mission design. Acta Astronaut. 2005,\n\
    56, 213–219. [CrossRef]\n52.\nSweeting, M.N. Modern small satellites-changing\
    \ the economics of space. Proc. IEEE 2018, 106, 343–361.\n[CrossRef]\n53.\nKhanal,\
    \ S.; Fulton, J.; Shearer, S. An overview of current and potential applications\
    \ of thermal remote sensing\nin precision agriculture. Comput. Electron. Agric.\
    \ 2017, 139, 22–32. [CrossRef]\n54.\nGerhards, M.;\nSchlerf, M.;\nMallick, K.;\n\
    Udelhoven, T. Challenges and Future Perspectives of\nMulti-/Hyperspectral Thermal\
    \ Infrared Remote Sensing for Crop Water-Stress Detection: A Review.\nRemote Sens.\
    \ 2019, 11, 1240. [CrossRef]\n55.\nRyan, S.; Lewis, M. Mapping soils using high\
    \ resolution airborne imagery, Barossa Valley, SA. In Proceedings\nof the Inaugural\
    \ Australian Geospatial Information and Agriculture Conference Incorporating Precision\n\
    Agriculture in Australasia 5th Annual Symposium, Orange, NSW, Australia, 17–19\
    \ July 2001.\n56.\nKhaliq, A.; Comba, L.; Biglia, A.; Ricauda Aimonino, D.; Chiaberge,\
    \ M.; Gay, P. Comparison of satellite and\nUAV-based multispectral imagery for\
    \ vineyard variability assessment. Remote Sens. 2019, 11, 436. [CrossRef]\n57.\n\
    Jones, H.G.; Vaughan, R.A. Remote Sensing of Vegetation: Principles, Techniques,\
    \ and Applications; Oxford\nUniversity Press: Oxford, UK, 2010.\n58.\nThenkabail,\
    \ P.S.; Lyon, J.G. Hyperspectral Remote Sensing of Vegetation; CRC Press: Boco\
    \ Raton, FL, USA, 2016.\n59.\nKing, M.D.; Platnick, S.; Menzel, W.P.; Ackerman,\
    \ S.A.; Hubanks, P.A. Spatial and temporal distribution of\nclouds observed by\
    \ MODIS onboard the Terra and Aqua satellites. IEEE Trans. Geosci. Remote Sens.\
    \ 2013, 51,\n3826–3852. [CrossRef]\n60.\nChen, X.; Liu, M.; Zhu, X.; Chen, J.;\
    \ Zhong, Y.; Cao, X. “Blend-then-Index” or “Index-then-Blend”:\nA Theoretical\
    \ Analysis for Generating High-resolution NDVI Time Series by STARFM. Photogramm.\
    \ Eng.\nRemote Sens. 2018, 84, 65–73. [CrossRef]\n61.\nYin, T.; Inglada, J.; Osman,\
    \ J. Time series image fusion: Application and improvement of STARFM for land\n\
    cover map and production. In Proceedings of the 2012 IEEE International Geoscience\
    \ and Remote Sensing\nSymposium, Munich, Germany, 22–27 July 2012; pp. 378–381.\n\
    62.\nGevaert, C.M.; García-Haro, F.J. A comparison of STARFM and an unmixing-based\
    \ algorithm for Landsat\nand MODIS data fusion. Remote Sens. Environ. 2015, 156,\
    \ 34–44. [CrossRef]\n63.\nLi, L.; Wang, X.; Li, M. Study on the fusion of MODIS\
    \ and TM images using the spectral response function\nand STARFM algorithm. In\
    \ Proceedings of the 2011 International Conference on Image Analysis and Signal\n\
    Processing, Wuhan, China, 21–23 October 2011; pp. 171–176.\n64.\nPagay, V.; Kidman,\
    \ C.M. Evaluating Remotely-Sensed Grapevine (Vitis vinifera L.) Water Stress Responses\n\
    Across a Viticultural Region. Agronomy 2019, 9, 682. [CrossRef]\n65.\nRascher,\
    \ U.; Alonso, L.; Burkart, A.; Cilia, C.; Cogliati, S.; Colombo, R.; Damm, A.;\
    \ Drusch, M.; Guanter, L.;\nHanus, J.; et al. Sun-induced ﬂuorescence—A new probe\
    \ of photosynthesis: First maps from the imaging\nspectrometer HyPlant. Glob.\
    \ Chang. Biol. 2015, 21, 4673–4684. [CrossRef]\n66.\nBuckley, S.; Vallet, J.;\
    \ Braathen, A.; Wheeler, W. Oblique helicopter-based laser scanning for digital\
    \ terrain\nmodelling and visualisation of geological outcrops. Int. Arch. Photogramm.\
    \ Remote Sens. Spat. Inf. Sci. 2008,\n37, 1–6.\n67.\nPullanagari, R.; Kereszturi,\
    \ G.; Yule, I. Mapping of macro and micro nutrients of mixed pastures using\n\
    airborne AisaFENIX hyperspectral imagery. ISPRS J. Photogramm. Remote Sens. 2016,\
    \ 117, 1–10. [CrossRef]\n68.\nHaboudane, D.; Miller, J.R.; Tremblay, N.; Zarco-Tejada,\
    \ P.J.; Dextraze, L. Integrated narrow-band vegetation\nindices for prediction\
    \ of crop chlorophyll content for application to precision agriculture. Remote\
    \ Sens.\nEnviron. 2002, 81, 416–426. [CrossRef]\nAgronomy 2020, 10, 140\n24 of\
    \ 35\n69.\nMiao, Y.; Mulla, D.J.; Randall, G.W.; Vetsch, J.A.; Vintila, R. Predicting\
    \ chlorophyll meter readings with aerial\nhyperspectral remote sensing for in-season\
    \ site-speciﬁc nitrogen management of corn. Precis. Agric. 2007, 7,\n635–641.\n\
    70.\nHaboudane, D.; Miller, J.R.; Pattey, E.; Zarco-Tejada, P.J.; Strachan, I.B.\
    \ Hyperspectral vegetation indices\nand novel algorithms for predicting green\
    \ LAI of crop canopies: Modeling and validation in the context of\nprecision agriculture.\
    \ Remote Sens. Environ. 2004, 90, 337–352. [CrossRef]\n71.\nSepulcre-Cantó, G.;\
    \ Zarco-Tejada, P.J.; Jiménez-Muñoz, J.; Sobrino, J.; Soriano, M.; Fereres, E.;\
    \ Vega, V.;\nPastor, M. Monitoring yield and fruit quality parameters in open-canopy\
    \ tree crops under water stress.\nImplications for ASTER. Remote Sens. Environ.\
    \ 2007, 107, 455–470. [CrossRef]\n72.\nSepulcre-Cantó, G.; Zarco-Tejada, P.J.;\
    \ Jiménez-Muñoz, J.; Sobrino, J.; De Miguel, E.; Villalobos, F.J. Detection\n\
    of water stress in an olive orchard with thermal remote sensing imagery. Agric.\
    \ For. Meteorol. 2006, 136,\n31–44. [CrossRef]\n73.\nColomina, I.; Molina, P.\
    \ Unmanned aerial systems for photogrammetry and remote sensing: A review.\nISPRS\
    \ J. Photogramm. Remote Sens. 2014, 92, 79–97. [CrossRef]\n74.\nZecha, C.; Link,\
    \ J.; Claupein, W. Mobile sensor platforms: Categorisation and research applications\
    \ in\nprecision farming. J. Sens. Sens. Syst. 2013, 2, 51–72. [CrossRef]\n75.\n\
    Urbahs, A.; Jonaite, I. Features of the use of unmanned aerial vehicles for agriculture\
    \ applications. Aviation\n2013, 17, 170–175. [CrossRef]\n76.\nGautam, D.; Ha,\
    \ C. Control of a quadrotor using a smart self-tuning fuzzy PID controller. Int.\
    \ J. Adv. Robot.\nSyst. 2013, 10, 380. [CrossRef]\n77.\nShi, Y.; Thomasson, J.A.;\
    \ Murray, S.C.; Pugh, N.A.; Rooney, W.L.; Shaﬁan, S.; Rajan, N.; Rouze, G.; Morgan,\
    \ C.L.;\nNeely, H.L.; et al. Unmanned aerial vehicles for high-throughput phenotyping\
    \ and agronomic research.\nPLoS ONE 2016, 11, e0159781. [CrossRef]\n78.\nZhang,\
    \ C.; Kovacs, J.M. The application of small unmanned aerial systems for precision\
    \ agriculture: a review.\nPrecis. Agric. 2012, 13, 693–712. [CrossRef]\n79.\n\
    Mulla, D.J. Twenty ﬁve years of remote sensing in precision agriculture: Key advances\
    \ and remaining\nknowledge gaps. Biosyst. Eng. 2013, 114, 358–371. [CrossRef]\n\
    80.\nHuang, Y.; Thomson, S.J.; Hoﬀmann, W.C.; Lan, Y.; Fritz, B.K. Development\
    \ and prospect of unmanned aerial\nvehicle technologies for agricultural production\
    \ management. Int. J. Agric. Biol. Eng. 2013, 6, 1–10.\n81.\nZude-Sasse, M.; Fountas,\
    \ S.; Gemtos, T.A.; Abu-Khalaf, N. Applications of precision agriculture in horticultural\n\
    crops. Eur. J. Hortic. Sci. 2016, 81, 78–90. [CrossRef]\n82.\nBaluja, J.; Diago,\
    \ M.P.; Balda, P.; Zorer, R.; Meggio, F.; Morales, F.; Tardaguila, J. Assessment\
    \ of vineyard\nwater status variability by thermal and multispectral imagery using\
    \ an unmanned aerial vehicle (UAV).\nIrrig. Sci. 2012, 30, 511–522. [CrossRef]\n\
    83.\nMatese, A.; Baraldi, R.; Berton, A.; Cesaraccio, C.; Di Gennaro, S.F.; Duce,\
    \ P.; Facini, O.; Mameli, M.G.;\nPiga, A.; Zaldei, A. Estimation of water stress\
    \ in grapevines using proximal and remote sensing methods.\nRemote Sens. 2018,\
    \ 10, 114. [CrossRef]\n84.\nPoblete, T.; Ortega-Farías, S.; Moreno, M.; Bardeen,\
    \ M. Artiﬁcial neural network to predict vine water status\nspatial variability\
    \ using multispectral information obtained from an unmanned aerial vehicle (UAV).\
    \ Sensors\n2017, 17, 2488. [CrossRef]\n85.\nGonzalez-Dugo, V.; Zarco-Tejada, P.J.;\
    \ Fereres, E. Applicability and limitations of using the crop water stress\nindex\
    \ as an indicator of water deﬁcits in citrus orchards. Agric. For. Meteorol. 2014,\
    \ 198, 94–104. [CrossRef]\n86.\nStagakis, S.; González-Dugo, V.; Cid, P.; Guillén-Climent,\
    \ M.L.; Zarco-Tejada, P.J. Monitoring water stress\nand fruit quality in an orange\
    \ orchard under regulated deﬁcit irrigation using narrow-band structural and\n\
    physiological remote sensing indices. ISPRS J. Photogramm. Remote Sens. 2012,\
    \ 71, 47–61. [CrossRef]\n87.\nAgam, N.; Cohen, Y.; Berni, J.A.J.; Alchanatis,\
    \ V.; Kool, D.; Dag, A.; Yermiyahu, U.; Ben-Gal, A. An insight to\nthe performance\
    \ of crop water stress index for olive trees. Agric. Water Manag. 2013, 118, 79–86.\
    \ [CrossRef]\n88.\nPoblete-Echeverría, C.; Sepulveda-Reyes, D.; Ortega-Farias,\
    \ S.; Zuñiga, M.; Fuentes, S. Plant water stress\ndetection based on aerial and\
    \ terrestrial infrared thermography: A study case from vineyard and olive\norchard.\
    \ In Proceedings of the XXIX International Horticultural congress on Horticulture:\
    \ Sustaining Lives,\nLivelihoods and Landscapes (IHC2014): International Symposia\
    \ on Water, Eco-Eﬃciency and Transformation\nof Organic Waste in Horticultural\
    \ Production, Brisbane, Australia, 25 October 2016; pp. 141–146.\nAgronomy 2020,\
    \ 10, 140\n25 of 35\n89.\nTesti, L.; Goldhamer, D.; Iniesta, F.; Salinas, M. Crop\
    \ water stress index is a sensitive water stress indicator in\npistachio trees.\
    \ Irrig. Sci. 2008, 26, 395–405. [CrossRef]\n90.\nGonzalez-Dugo, V.; Goldhamer,\
    \ D.; Zarco-Tejada, P.J.; Fereres, E. Improving the precision of irrigation in\
    \ a\npistachio farm using an unmanned airborne thermal system. Irrig. Sci. 2015,\
    \ 33, 43–52. [CrossRef]\n91.\nGarcía-Tejero, I.F.; Rubio, A.E.; Viñuela, I.; Hernández,\
    \ A.; Gutiérrez-Gordillo, S.; Rodríguez-Pleguezuelo, C.R.;\nDurán-Zuazo, V.H.\
    \ Thermal imaging at plant level to assess the crop-water status in almond trees\
    \ (cv. Guara)\nunder deﬁcit irrigation strategies. Agric. Water Manag. 2018, 208,\
    \ 176–186. [CrossRef]\n92.\nGonzalez-Dugo, V.; Zarco-Tejada, P.; Berni, J.A.;\
    \ Suárez, L.; Goldhamer, D.; Fereres, E. Almond tree canopy\ntemperature reveals\
    \ intra-crown variability that is water stress-dependent. Agric. For. Meteorol.\
    \ 2012, 154,\n156–165. [CrossRef]\n93.\nZhao, T.; Stark, B.; Chen, Y.; Ray, A.L.;\
    \ Doll, D. Challenges in water stress quantiﬁcation using small\nunmanned aerial\
    \ system (sUAS): Lessons from a growing season of almond. J. Intell. Robot. Syst.\
    \ 2017, 88,\n721–735. [CrossRef]\n94.\nZhao, T.; Doll, D.; Wang, D.; Chen, Y.\
    \ A new framework for UAV-based remote sensing data processing and\nits application\
    \ in almond water stress quantiﬁcation. In Proceedings of the 2017 International\
    \ Conference on\nUnmanned Aircraft Systems (ICUAS 2017), Miami, FL, USA, 13–16\
    \ June 2017; pp. 1794–1799.\n95.\nHerwitz, S.; Johnson, L.; Dunagan, S.; Higgins,\
    \ R.; Sullivan, D.; Zheng, J.; Lobitz, B.; Leung, J.; Gallmeyer, B.;\nAoyagi,\
    \ M.; et al. Imaging from an unmanned aerial vehicle: agricultural surveillance\
    \ and decision support.\nComput. Electron. Agric. 2004, 44, 49–61. [CrossRef]\n\
    96.\nFurfaro, R.; Ganapol, B.D.; Johnson, L.; Herwitz, S. Model-based neural network\
    \ algorithm for coﬀee ripeness\nprediction using Helios UAV aerial images. In\
    \ Remote Sensing for Agriculture, Ecosystems, and Hydrology VII;\nInternational\
    \ Society for Optics and Photonics: Bruges, Belgium, 2005; Volume 5976, p. 59760X.\n\
    97.\nPark, S.; Nolan, A.; Ryu, D.; Fuentes, S.; Hernandez, E.; Chung, H.; O’connell,\
    \ M. Estimation of crop\nwater stress in a nectarine orchard using high-resolution\
    \ imagery from unmanned aerial vehicle (UAV).\nIn Proceedings of the 21st International\
    \ Congress on Modelling and Simulation, Gold Coast, QLD, Australia,\n29 November–4\
    \ December 2015; pp. 1413–1419.\n98.\nBulanon, D.M.; Lonai, J.; Skovgard, H.;\
    \ Fallahi, E. Evaluation of diﬀerent irrigation methods for an apple\norchard\
    \ using an aerial imaging system. ISPRS Int. J. Geo-Inf. 2016, 5, 79.\n99.\nGonzalez-Dugo,\
    \ V.; Zarco-Tejada, P.; Nicolás, E.; Nortes, P.A.; Alarcón, J.; Intrigliolo, D.S.;\
    \ Fereres, E. Using\nhigh resolution UAV thermal imagery to assess the variability\
    \ in the water status of ﬁve fruit tree species\nwithin a commercial orchard.\
    \ Precis. Agric. 2013, 14, 660–678. [CrossRef]\n100. Santesteban, L.G.; Di Gennaro,\
    \ S.F.; Herrero-Langreo, A.; Miranda, C.; Royo, J.B.; Matese, A. High-resolution\n\
    UAV-based thermal imaging to estimate the instantaneous and seasonal variability\
    \ of plant water status\nwithin a vineyard. Agric. Water Manag. 2017, 183, 49–59.\
    \ [CrossRef]\n101. Aboutalebi, M.; Torres-Rua, A.F.; Kustas, W.P.; Nieto, H.;\
    \ Coopmans, C.; McKee, M. Assessment of diﬀerent\nmethods for shadow detection\
    \ in high-resolution optical imagery and evaluation of shadow impact on\ncalculation\
    \ of NDVI, and evapotranspiration. Irrig. Sci. 2018, 1, 1–23. [CrossRef]\n102.\
    \ Berni, J.A.; Zarco-Tejada, P.J.; Suárez, L.; Fereres, E. Thermal and narrowband\
    \ multispectral remote sensing\nfor vegetation monitoring from an unmanned aerial\
    \ vehicle. IEEE Trans. Geosci. Remote Sens. 2009, 47,\n722–738. [CrossRef]\n103.\
    \ Candiago, S.; Remondino, F.; De Giglio, M.; Dubbini, M.; Gattelli, M. Evaluating\
    \ multispectral images and\nvegetation indices for precision farming applications\
    \ from UAV images. Remote Sens. 2015, 7, 4026–4047.\n[CrossRef]\n104. Thomasson,\
    \ J.A.; Shi, Y.; Olsenholler, J.; Valasek, J.; Murray, S.C.; Bishop, M.P. Comprehensive\
    \ UAV\nagricultural remote-sensing research at Texas AM University. In Autonomous\
    \ Air and Ground Sensing Systems\nfor Agricultural Optimization and Phenotyping;\
    \ International Society for Optics and Photonics: Baltimore, MD,\nUSA, 2016; Volume\
    \ 9866, p. 986602.\n105. Turner, D.; Lucieer, A.; Wallace, L. Direct georeferencing\
    \ of ultrahigh-resolution UAV imagery. IEEE Trans.\nGeosci. Remote Sens. 2014,\
    \ 52, 2738–2745. [CrossRef]\n106. Primicerio, J.; Di Gennaro, S.F.; Fiorillo,\
    \ E.; Genesio, L.; Lugato, E.; Matese, A.; Vaccari, F.P. A ﬂexible\nunmanned aerial\
    \ vehicle for precision agriculture. Precis. Agric. 2012, 13, 517–523. [CrossRef]\n\
    107. Pajares, G. Overview and current status of remote sensing applications based\
    \ on unmanned aerial vehicles\n(UAVs). Photogramm. Eng. Remote Sens. 2015, 81,\
    \ 281–330. [CrossRef]\nAgronomy 2020, 10, 140\n26 of 35\n108. Di Gennaro, S.F.;\
    \ Matese, A.; Gioli, B.; Toscano, P.; Zaldei, A.; Palliotti, A.; Genesio, L. Multisensor\
    \ approach\nto assess vineyard thermal dynamics combining high-resolution unmanned\
    \ aerial vehicle (UAV) remote\nsensing and wireless sensor network (WSN) proximal\
    \ sensing. Sci. Hortic. 2017, 221, 83–87. [CrossRef]\n109. Cendrero-Mateo, M.P.;\
    \ Wieneke, S.; Damm, A.; Alonso, L.; Pinto, F.; Moreno, J.; Guanter, L.; Celesti,\
    \ M.;\nRossini, M.; Sabater, N.; et al. Sun-induced chlorophyll ﬂuorescence III:\
    \ Benchmarking retrieval methods\nand sensor characteristics for proximal sensing.\
    \ Remote Sens. 2019, 11, 962. [CrossRef]\n110. Zarco-Tejada, P.J.; González-Dugo,\
    \ V.; Berni, J.A.J. Fluorescence, temperature and narrow-band indices\nacquired\
    \ from a UAV platform for water stress detection using a micro-hyperspectral imager\
    \ and a thermal\ncamera. Remote Sens. Environ. 2012, 117, 322–337. [CrossRef]\n\
    111. Harwin, S.; Lucieer, A. Assessing the accuracy of georeferenced point clouds\
    \ produced via multi-view\nstereopsis from Unmanned Aerial Vehicle (UAV) imagery.\
    \ Remote Sens. 2012, 4, 1573–1599. [CrossRef]\n112. Wallace, L.; Lucieer, A.;\
    \ Malenovskỳ, Z.; Turner, D.; Vopˇenka, P. Assessment of forest structure using\
    \ two\nUAV techniques: A comparison of airborne laser scanning and structure from\
    \ motion (SfM) point clouds.\nForests 2016, 7, 62. [CrossRef]\n113. Weiss, M.;\
    \ Baret, F. Using 3D point clouds derived from UAV RGB imagery to describe vineyard\
    \ 3D\nmacro-structure. Remote Sens. 2017, 9, 111. [CrossRef]\n114. Mathews, A.;\
    \ Jensen, J. Visualizing and quantifying vineyard canopy LAI using an unmanned\
    \ aerial vehicle\n(UAV) collected high density structure from motion point cloud.\
    \ Remote Sens. 2013, 5, 2164–2183. [CrossRef]\n115. Stone, C.; Webster, M.; Osborn,\
    \ J.; Iqbal, I. Alternatives to LiDAR-derived canopy height models for softwood\n\
    plantations: a review and example using photogrammetry. Aust. For. 2016, 79, 271–282.\
    \ [CrossRef]\n116. Wu, D.; Phinn, S.; Johansen, K.; Robson, A.; Muir, J.; Searle,\
    \ C. Estimating changes in leaf area, leaf area\ndensity, and vertical leaf area\
    \ proﬁle for mango, avocado, and macadamia tree crowns using terrestrial laser\n\
    scanning. Remote Sens. 2018, 10, 1750. [CrossRef]\n117. Rosell, J.R.; Llorens,\
    \ J.; Sanz, R.; Arno, J.; Ribes-Dasi, M.; Masip, J.; Escolà, A.; Camp, F.; Solanelles,\
    \ F.;\nGràcia, F.; et al. Obtaining the three-dimensional structure of tree orchards\
    \ from remote 2D terrestrial LIDAR\nscanning. Agric. For. Meteorol. 2009, 149,\
    \ 1505–1515. [CrossRef]\n118. Matese, A.; Di Gennaro, S.F. Technology in precision\
    \ viticulture: A state of the art review. Int. J. Wine Res.\n2015, 7, 69–81. [CrossRef]\n\
    119. Johansen, K.; Raharjo, T.; McCabe, M.F. Using multi-spectral UAV imagery\
    \ to extract tree crop structural\nproperties and assess pruning eﬀects. Remote\
    \ Sens. 2018, 10, 854. [CrossRef]\n120. Tu, Y.-H.; Johansen, K.; Phinn, S.; Robson,\
    \ A. Measuring canopy structure and condition using multi-spectral\nUAS imagery\
    \ in a horticultural environment. Remote Sens. 2019, 11, 269. [CrossRef]\n121.\
    \ Mu, Y.; Fujii, Y.; Takata, D.; Zheng, B.; Noshita, K.; Honda, K.; Ninomiya,\
    \ S.; Guo, W. Characterization of\npeach tree crown by using high-resolution images\
    \ from an unmanned aerial vehicle. Hortic. Res. 2018, 5, 74.\n[CrossRef]\n122.\
    \ De Castro, A.I.; Jiménez-Brenes, F.M.; Torres-Sánchez, J.; Peña, J.M.; Borra-Serrano,\
    \ I.; López-Granados, F. 3-D\ncharacterization of vineyards using a novel UAV\
    \ imagery-based OBIA procedure for precision viticulture\napplications. Remote\
    \ Sens. 2018, 10, 584. [CrossRef]\n123. Del Pozo, S.; Rodríguez-Gonzálvez, P.;\
    \ Hernández-López, D.; Felipe-García, B. Vicarious radiometric\ncalibration of\
    \ a multispectral camera on board an unmanned aerial system. Remote Sens. 2014,\
    \ 6, 1918–1937.\n[CrossRef]\n124. Tu, Y.-H.; Phinn, S.; Johansen, K.; Robson,\
    \ A. Assessing radiometric correction approaches for multi-spectral\nUAS imagery\
    \ for horticultural applications. Remote Sens. 2018, 10, 1684. [CrossRef]\n125.\
    \ Stow, D.; Nichol, C.J.; Wade, T.; Assmann, J.J.; Simpson, G.; Helfter, C. Illumination\
    \ geometry and ﬂying\nheight inﬂuence surface reﬂectance and NDVI derived from\
    \ multispectral UAS imagery. Drones 2019, 3, 55.\n[CrossRef]\n126. Turner, D.;\
    \ Lucieer, A.; Watson, C. Development of an unmanned aerial vehicle (UAV) for\
    \ hyper resolution\nvineyard mapping based on visible, multispectral, and thermal\
    \ imagery.\nIn Proceedings of the 34th\nInternational Symposium on Remote Sensing\
    \ of Environment, Sydney, Australia, 10–15 April 2011; p. 4.\n127. Jorge, J.;\
    \ Vallbé, M.; Soler, J.A. Detection of irrigation inhomogeneities in an olive\
    \ grove using the NDRE\nvegetation index obtained from UAV images. Eur. J. Remote\
    \ Sens. 2019, 52, 169–177. [CrossRef]\n128. Filella, I.; Penuelas, J. The red\
    \ edge position and shape as indicators of plant chlorophyll content, biomass\n\
    and hydric status. Int. J. Remote Sens. 1994, 15, 1459–1470. [CrossRef]\nAgronomy\
    \ 2020, 10, 140\n27 of 35\n129. Zúñiga, C.E.; Khot, L.R.; Jacoby, P.; Sankaran,\
    \ S. Remote sensing based water-use eﬃciency evaluation\nin sub-surface irrigated\
    \ wine grape vines. In Autonomous Air and Ground Sensing Systems for Agricultural\n\
    Optimization and Phenotyping; International Society for Optics and Photonics:\
    \ Baltimore, MD, USA, 2016;\nVolume 9866, p. 98660O.\n130. Aasen, H.; Honkavaara,\
    \ E.; Lucieer, A.; Zarco-Tejada, P. Quantitative remote sensing at ultra-high\
    \ resolution\nwith uav spectroscopy: A review of sensor technology, measurement\
    \ procedures, and data correction\nworkﬂows. Remote Sens. 2018, 10, 1091. [CrossRef]\n\
    131. Adão, T.; Hruška, J.; Pádua, L.; Bessa, J.; Peres, E.; Morais, R.; Sousa,\
    \ J. Hyperspectral imaging: A review on\nUAV-based sensors, data processing and\
    \ applications for agriculture and forestry. Remote Sens. 2017, 9, 1110.\n[CrossRef]\n\
    132. Gautam, D.; Watson, C.; Lucieer, A.; Malenovský, Z. Error budget for geolocation\
    \ of spectroradiometer point\nobservations from an unmanned aircraft system. Sens.\
    \ Switz. 2018, 18, 3465. [CrossRef] [PubMed]\n133. Uto, K.; Seki, H.; Saito, G.;\
    \ Kosugi, Y.; Komatsu, T. Development of a low-cost hyperspectral whiskbroom\n\
    imager using an optical ﬁber bundle, a swing mirror, and compact spectrometers.\
    \ IEEE J. Sel. Top. Appl.\nEarth Obs. Remote Sens. 2016, 9, 3909–3925. [CrossRef]\n\
    134. Suomalainen, J.; Anders, N.; Iqbal, S.; Roerink, G.; Franke, J.; Wenting,\
    \ P.; Hünniger, D.; Bartholomeus, H.;\nBecker, R.; Kooistra, L. A lightweight\
    \ hyperspectral mapping system and photogrammetric processing chain\nfor unmanned\
    \ aerial vehicles. Remote Sens. 2014, 6, 11013–11030. [CrossRef]\n135. Iseli,\
    \ C.; Lucieer, A. Tree species classiﬁcation based on 3d spectral point clouds\
    \ and orthomosaics acquired\nby snapshot hyperspectral UAS sensor. ISPRS-Int.\
    \ Arch. Photogramm. Remote Sens. Spat. Inf. Sci. 2019, 4213,\n379–384. [CrossRef]\n\
    136. Hagen, N.A.; Kudenov, M.W. Review of snapshot spectral imaging technologies.\
    \ Opt. Eng. 2013, 52, 090901.\n[CrossRef]\n137. Bendig, J.; Gautam, D.; Malenovsky,\
    \ Z.; Lucieer, A. Inﬂuence of Cosine Corrector and UAS Platform Dynamics\non Airborne\
    \ Spectral Irradiance Measurements. In Proceedings of the 2018 IEEE International\
    \ Geoscience\nand Remote Sensing Symposium (IGARSS 2018), Valencia, Spain, 22–27\
    \ July 2018; pp. 8822–8825.\n138. Gautam, D. Direct Georeferencing and Footprint\
    \ Characterisation of a Non-Imaging Spectroradiometer\nMounted on an Unmanned\
    \ Aircraft System. Ph.D. Thesis, University of Tasmania, Hobart, Tasmania,\nAustralia,\
    \ 2019.\n139. Rodríguez-Pérez, J.R.; Riaño, D.; Carlisle, E.; Ustin, S.; Smart,\
    \ D.R. Evaluation of hyperspectral reﬂectance\nindexes to detect grapevine water\
    \ status in vineyards. Am. J. Enol. Vitic. 2007, 58, 302–317.\n140. Hurley, S.P.;\
    \ Horney, M.; Drake, A. Using hyperspectral imagery to detect water stress in\
    \ vineyards.\nIn Autonomous Air and Ground Sensing Systems for Agricultural Optimization\
    \ and Phenotyping IV; International\nSociety for Optics and Photonics: Baltimore,\
    \ MD, USA, 2019; Volume 11008, p. 1100807.\n141. Loggenberg, K.; Strever, A.;\
    \ Greyling, B.; Poona, N. Modelling water stress in a shiraz vineyard using\n\
    hyperspectral imaging and machine learning. Remote Sens. 2018, 10, 202. [CrossRef]\n\
    142. Gómez-Candón, D.; Virlet, N.; Labbé, S.; Jolivot, A.; Regnard, J.-L. Field\
    \ phenotyping of water stress at tree\nscale by UAV-sensed imagery: new insights\
    \ for thermal acquisition and calibration. Precis. Agric. 2016, 17,\n786–800.\
    \ [CrossRef]\n143. Kelly, J.; Kljun, N.; Olsson, P.-O.; Mihai, L.; Liljeblad,\
    \ B.; Weslien, P.; Klemedtsson, L.; Eklundh, L. Challenges\nand best practices\
    \ for deriving temperature data from an uncalibrated UAV thermal infrared camera.\n\
    Remote Sens. 2019, 11, 567. [CrossRef]\n144. Smigaj, M.; Gaulton, R.; Suarez,\
    \ J.; Barr, S. Use of miniature thermal cameras for detection of physiological\n\
    stress in conifers. Remote Sens. 2017, 9, 957. [CrossRef]\n145. Clarke, I. Thermal\
    \ Infrared Remote Sensing from Unmanned Aircraft Systems (UAS) for Precision Viticulture.\n\
    Master’s Thesis, University of Tasmania, Hobart, Tasmania, Australia, 2014.\n\
    146. Daakir, M.; Zhou, Y.; Pierrot Deseilligny, M.; Thom, C.; Martin, O.; Rupnik,\
    \ E. Improvement of\nphotogrammetric accuracy by modeling and correcting the thermal\
    \ eﬀect on camera calibration. ISPRS J.\nPhotogramm. Remote Sens. 2019, 148, 142–155.\
    \ [CrossRef]\n147. Nugent, P.W.; Shaw, J.A. Calibration of uncooled LWIR microbolometer\
    \ imagers to enable long-term ﬁeld\ndeployment. In Infrared Imaging Systems: Design,\
    \ Analysis, Modeling, and Testing XXV; International Society\nfor Optics and Photonics:\
    \ Baltimore, MD, USA, 2014; Volume 9071, p. 90710V.\nAgronomy 2020, 10, 140\n\
    28 of 35\n148. Budzier, H.; Gerlach, G. Calibration of uncooled thermal infrared\
    \ cameras. J. Sens. Sens. Syst. 2015, 4,\n187–197. [CrossRef]\n149. Lin, D.; Maas,\
    \ H.-G.; Westfeld, P.; Budzier, H.; Gerlach, G. An advanced radiometric calibration\
    \ approach for\nuncooled thermal cameras. Photogramm. Rec. 2018, 33, 30–48. [CrossRef]\n\
    150. Ribeiro-Gomes, K.; Hernández-López, D.; Ortega, J.F.; Ballesteros, R.; Poblete,\
    \ T.; Moreno, M.A. Uncooled\nthermal camera calibration and optimization of the\
    \ photogrammetry process for UAV applications in\nagriculture. Sensors 2017, 17,\
    \ 173. [CrossRef]\n151. Lin, D.; Westfeld, P.; Maas, H.G. Shutter-less temperature-dependent\
    \ correction for uncooled thermal camera\nunder fast changing FPA temperature.\
    \ Int. Arch. Photogramm. Remote Sens. Spat. Inf. Sci.—ISPRS Arch. 2017,\n42, 619–625.\
    \ [CrossRef]\n152. Mesas-Carrascosa, F.J.; Pérez-Porras, F.; de Larriva, J.E.M.;\
    \ Frau, C.M.; Agüera-Vega, F.; Carvajal-Ramírez, F.;\nMartínez-Carricondo, P.;\
    \ García-Ferrer, A. Drift correction of lightweight microbolometer thermal sensors\n\
    on-board unmanned aerial vehicles. Remote Sens. 2018, 10, 615. [CrossRef]\n153.\
    \ Torres-Rua, A. Vicarious calibration of sUAS microbolometer temperature imagery\
    \ for estimation of\nradiometric land surface temperature. Sensors 2017, 17, 1499.\
    \ [CrossRef] [PubMed]\n154. Bendig, J.; Bolten, A.; Bareth, G. Introducing a low-cost\
    \ mini-UAV for thermal-and multispectral-imaging.\nInt. Arch. Photogramm Remote\
    \ Sens. Spat. Inf. Sci. 2012, 39, 345–349. [CrossRef]\n155. Raymer, D. Aircraft\
    \ Design: A Conceptual Approach; American Institute of Aeronautics and Astronautics,\
    \ Inc.:\nReston, VA, USA, 2018.\n156. Tardieu, F.; Simonneau, T. Variability among\
    \ species of stomatal control under ﬂuctuating soil water status\nand evaporative\
    \ demand: modelling isohydric and anisohydric behaviours. J. Exp. Bot. 1998, 49,\
    \ 419–432.\n[CrossRef]\n157. White, W.A.; Alsina, M.M.; Nieto, H.; McKee, L.G.;\
    \ Gao, F.; Kustas, W.P. Determining a robust indirect\nmeasurement of leaf area\
    \ index in California vineyards for validating remote sensing-based retrievals.\n\
    Irrig. Sci. 2019, 37, 269–280. [CrossRef]\n158. Zarco-Tejada, P.J.; Berni, J.A.;\
    \ Suárez, L.; Sepulcre-Cantó, G.; Morales, F.; Miller, J.R. Imaging chlorophyll\n\
    ﬂuorescence with an airborne narrow-band multispectral camera for vegetation stress\
    \ detection.\nRemote Sens. Environ. 2009, 113, 1262–1275. [CrossRef]\n159. Gago,\
    \ J.; Douthe, C.; Florez-Sarasa, I.; Escalona, J.M.; Galmes, J.; Fernie, A.R.;\
    \ Flexas, J.; Medrano, H.\nOpportunities for improving leaf water use eﬃciency\
    \ under climate change conditions. Plant Sci. 2014, 226,\n108–119. [CrossRef]\n\
    160. Suárez, L.; Zarco-Tejada, P.J.; Sepulcre-Cantó, G.; Pérez-Priego, O.; Miller,\
    \ J.; Jiménez-Muñoz, J.; Sobrino, J.\nAssessing canopy PRI for water stress detection\
    \ with diurnal airborne imagery. Remote Sens. Environ. 2008,\n112, 560–575. [CrossRef]\n\
    161. Eugenio, F.; Marqués, F. Automatic satellite image georeferencing using a\
    \ contour-matching approach.\nIEEE Trans. Geosci. Remote Sens. 2003, 41, 2869–2880.\
    \ [CrossRef]\n162. Hugenholtz, C.; Brown, O.; Walker, J.; Barchyn, T.; Nesbit,\
    \ P.; Kucharczyk, M.; Myshak, S. Spatial accuracy of\nUAV-derived orthoimagery\
    \ and topography: Comparing photogrammetric models processed with direct\ngeo-referencing\
    \ and ground control points. Geomatica 2016, 70, 21–30. [CrossRef]\n163. Matese,\
    \ A.; Di Gennaro, S.F.; Berton, A. Assessment of a canopy height model (CHM) in\
    \ a vineyard using\nUAV-based multispectral imaging. Int. J. Remote Sens. 2017,\
    \ 38, 2150–2160. [CrossRef]\n164. Yahyanejad, S.; Misiorny, J.; Rinner, B. Lens\
    \ distortion correction for thermal cameras to improve aerial\nimaging with small-scale\
    \ UAVs. In Proceedings of the 2011 IEEE International Symposium on Robotic and\n\
    Sensors Environments (ROSE 2011), Montreal, QC, Canada, 17–18 September 2011;\
    \ pp. 231–236.\n165. Maes, W.; Huete, A.; Steppe, K. Optimizing the processing\
    \ of UAV-based thermal imagery. Remote Sens. 2017,\n9, 476. [CrossRef]\n166. Smith,\
    \ M.; Carrivick, J.; Quincey, D. Structure from motion photogrammetry in physical\
    \ geography.\nProg. Phys. Geogr. 2016, 40, 247–275. [CrossRef]\n167. Westoby,\
    \ M.J.; Brasington, J.; Glasser, N.F.; Hambrey, M.J.; Reynolds, J.M. ‘Structure-from-Motion’\n\
    photogrammetry: A low-cost, eﬀective tool for geoscience applications. Geomorphology\
    \ 2012, 179, 300–314.\n[CrossRef]\n168. Gautam, D.; Lucieer, A.; Malenovský, Z.;\
    \ Watson, C. Comparison of MEMS-based and FOG-based IMUs to\ndetermine sensor\
    \ pose on an unmanned aircraft system. J. Surv. Eng. 2017, 143. [CrossRef]\nAgronomy\
    \ 2020, 10, 140\n29 of 35\n169. Turner, D.; Lucieer, A.; McCabe, M.; Parkes, S.;\
    \ Clarke, I. Pushbroom hyperspectral imaging from an\nunmanned aircraft system\
    \ (UAS)–geometric processingworkﬂow and accuracy assessment. ISPRS-Int. Arch.\n\
    Photogramm. Remote Sens. Spat. Inf. Sci. 2017, XLII-2/W6, 379–384. [CrossRef]\n\
    170. Fang, J.; Wang, X.; Zhu, T.; Liu, X.; Zhang, X.; Zhao, D. A Novel Mosaic\
    \ Method for UAV-Based Hyperspectral\nImages. In Proceedings of the 2019 IEEE\
    \ International Geoscience and Remote Sensing Symposium (IGARSS\n2019), Yokohama,\
    \ Japan, 28 July–2 August 2019; pp. 9220–9223.\n171. Tagle, X. Study of Radiometric\
    \ Variations in Unmanned Aerial Vehicle Remote Sensing Imagery for Vegetation\n\
    Mapping. Master’s Thesis, Lund University, Lund, Sweden, 2017.\n172. Kedzierski,\
    \ M.; Wierzbicki, D.; Sekrecka, A.; Fryskowska, A.; Walczykowski, P.; Siewert,\
    \ J. Inﬂuence of lower\natmosphere on the radiometric quality of unmanned aerial\
    \ vehicle imagery. Remote Sens. 2019, 11, 1214.\n[CrossRef]\n173. Kelcey, J.;\
    \ Lucieer, A. Sensor correction of a 6-band multispectral imaging sensor for UAV\
    \ remote sensing.\nRemote Sens. 2012, 4, 1462–1493. [CrossRef]\n174. Maes, W.H.;\
    \ Steppe, K. Perspectives for remote sensing with unmanned aerial vehicles in\
    \ precision agriculture.\nTrends Plant Sci. 2019, 24, 152–164. [CrossRef]\n175.\
    \ McCabe, M.F.; Houborg, R.; Lucieer, A. High-resolution sensing for precision\
    \ agriculture:\nfrom\nEarth-observing satellites to unmanned aerial vehicles.\n\
    In Remote Sensing for Agriculture, Ecosystems,\nand Hydrology XVIII; International\
    \ Society for Optics and Photonics: Edinbrugh, UK, 2016; Volume 9998,\np. 999811.\n\
    176. Dinguirard, M.; Slater, P.N. Calibration of space-multispectral imaging sensors:\
    \ A review. Remote Sens. Environ.\n1999, 68, 194–205. [CrossRef]\n177. Geladi,\
    \ P.; Burger, J.; Lestander, T. Hyperspectral imaging: calibration problems and\
    \ solutions. Chemom. Intell.\nLab. Syst. 2004, 72, 209–217. [CrossRef]\n178. Iqbal,\
    \ F.; Lucieer, A.; Barry, K. Simpliﬁed radiometric calibration for UAS-mounted\
    \ multispectral sensor.\nEur. J. Remote Sens. 2018, 51, 301–313. [CrossRef]\n\
    179. Mamaghani, B.; Salvaggio, C. Multispectral Sensor Calibration and Characterization\
    \ for sUAS Remote\nSensing. Sensors 2019, 19, 4453. [CrossRef] [PubMed]\n180.\
    \ Mamaghani, B.; Salvaggio, C. Comparative study of panel and panelless-based\
    \ reﬂectance conversion\ntechniques for agricultural remote sensing. arXiv 2019,\
    \ arXiv:191003734.\n181. Jensen, A.M.; McKee, M.; Chen, Y. Calibrating thermal\
    \ imagery from an unmanned aerial system-AggieAir.\nIn Proceedings of the 2013\
    \ IEEE International Geoscience and Remote Sensing Symposium (IGARSS 2013),\n\
    Melbourne, Australia, 21–26 July 2013; pp. 542–545.\n182. Zarco-Tejada, P.J.;\
    \ Victoria, G.-D.; Williams, L.; Suárez, L.; Berni, J.A.; Goldhamer, D.; Fereres,\
    \ E. A PRI-based\nwater stress index combining structural and chlorophyll eﬀects:\
    \ Assessment using diurnal narrow-band\nairborne imagery and the CWSI thermal\
    \ index. Remote Sens. Environ. 2013, 138, 38–50. [CrossRef]\n183. Blaschke, T.\
    \ Object based image analysis for remote sensing. ISPRS J. Photogramm. Remote\
    \ Sens. 2010, 65,\n2–16. [CrossRef]\n184. De Castro, A.; Torres-Sánchez, J.; Peña,\
    \ J.; Jiménez-Brenes, F.; Csillik, O.; López-Granados, F. An automatic\nrandom\
    \ forest-OBIA algorithm for early weed mapping between and within crop rows using\
    \ UAV imagery.\nRemote Sens. 2018, 10, 285. [CrossRef]\n185. Peña-Barragán, J.M.;\
    \ Ngugi, M.K.; Plant, R.E.; Six, J. Object-based crop identiﬁcation using multiple\
    \ vegetation\nindices, textural features and crop phenology. Remote Sens. Environ.\
    \ 2011, 115, 1301–1316. [CrossRef]\n186. Johansen, K.; Raharjo, T. Multi-temporal\
    \ assessment of lychee tree crop structure using multi-spectral RPAS\nimagery.\
    \ ISPRS Int. Arch. Photogramm. Remote Sens. Spat. Inf. Sci. 2017, XLII-2/W6, 165–170.\
    \ [CrossRef]\n187. Ma, L.; Li, M.; Ma, X.; Cheng, L.; Du, P.; Liu, Y. A review\
    \ of supervised object-based land-cover image\nclassiﬁcation. ISPRS J. Photogramm.\
    \ Remote Sens. 2017, 130, 277–293. [CrossRef]\n188. Pádua, L.; Vanko, J.; Hruška,\
    \ J.; Adão, T.; Sousa, J.J.; Peres, E.; Morais, R. UAS, sensors, and data processing\n\
    in agroforestry: a review towards practical applications. Int. J. Remote Sens.\
    \ 2017, 38, 2349–2391. [CrossRef]\n189. Torres-Sánchez, J.; López-Granados, F.;\
    \ Peña, J.M. An automatic object-based method for optimal thresholding\nin UAV\
    \ images: Application for vegetation detection in herbaceous crops. Comput. Electron.\
    \ Agric. 2015, 114,\n43–52. [CrossRef]\n190. Cohen, Y.; Alchanatis, V.; Prigojin,\
    \ A.; Levi, A.; Soroker, V. Use of aerial thermal imaging to estimate water\n\
    status of palm trees. Precis. Agric. 2012, 13, 123–140. [CrossRef]\nAgronomy 2020,\
    \ 10, 140\n30 of 35\n191. Comba, L.; Gay, P.; Primicerio, J.; Aimonino, D.R. Vineyard\
    \ detection from unmanned aerial systems images.\nComput. Electron. Agric. 2015,\
    \ 114, 78–87. [CrossRef]\n192. Nolan, A.; Park, S.; Fuentes, S.; Ryu, D.; Chung,\
    \ H. Automated detection and segmentation of vine rows using\nhigh resolution\
    \ UAS imagery in a commercial vineyard. In Proceedings of the 21st International\
    \ Congress\non Modelling and Simulation, Gold Coast, QLD, Australia, 29 November–4\
    \ December 2015; Volume 29,\npp. 1406–1412.\n193. Bobillet, W.; Da Costa, J.-P.;\
    \ Germain, C.; Lavialle, O.; Grenier, G. Row detection in high resolution remote\n\
    sensing images of vine ﬁelds. In Proceedings of the 4th European Conference on\
    \ Precision Agriculture,\nBerlin, Germany, 15–19 June 2003; pp. 81–87.\n194. Poblete,\
    \ T.; Ortega-Farías, S.; Ryu, D. Automatic coregistration algorithm to remove\
    \ canopy shaded pixels in\nUAV-borne thermal images to improve the estimation\
    \ of crop water stress index of a drip-irrigated cabernet\nsauvignon vineyard.\
    \ Sensors 2018, 18, 397. [CrossRef]\n195. Ihuoma, S.O.; Madramootoo, C.A. Recent\
    \ advances in crop water stress detection. Comput. Electron. Agric.\n2017, 141,\
    \ 267–275. [CrossRef]\n196. Jones, H.G. Use of infrared thermometry for estimation\
    \ of stomatal conductance as a possible aid to irrigation\nscheduling. Agric.\
    \ For. Meteorol. 1999, 95, 139–149. [CrossRef]\n197. Bellvert, J.; Marsal, J.;\
    \ Girona, J.; Zarco-Tejada, P.J. Seasonal evolution of crop water stress index\
    \ in grapevine\nvarieties determined with high-resolution remote sensing thermal\
    \ imagery. Irrig. Sci. 2015, 33, 81–93.\n[CrossRef]\n198. García-Tejero, I.F.;\
    \ Gutiérrez-Gordillo, S.; Ortega-Arévalo, C.; Iglesias-Contreras, M.; Moreno,\
    \ J.M.;\nSouza-Ferreira, L.; Durán-Zuazo, V.H. Thermal imaging to monitor the\
    \ crop-water status in almonds\nby using the non-water stress baselines. Sci.\
    \ Hortic. 2018, 238, 91–97. [CrossRef]\n199. Alchanatis, V.; Cohen, Y.; Cohen,\
    \ S.; Moller, M.; Sprinstin, M.; Meron, M.; Tsipris, J.; Saranga, Y.; Sela, E.\n\
    Evaluation of diﬀerent approaches for estimating and mapping crop water status\
    \ in cotton with thermal\nimaging. Precis. Agric. 2010, 11, 27–41. [CrossRef]\n\
    200. Goetz, S. Multi-sensor analysis of NDVI, surface temperature and biophysical\
    \ variables at a mixed grassland\nsite. Int. J. Remote Sens. 1997, 18, 71–94.\
    \ [CrossRef]\n201. Sun, L.; Gao, F.; Anderson, M.; Kustas, W.; Alsina, M.; Sanchez,\
    \ L.; Sams, B.; McKee, L.; Dulaney, W.;\nWhite, W.; et al. Daily mapping of 30\
    \ m LAI and NDVI for grape yield prediction in California Vineyards.\nRemote Sens.\
    \ 2017, 9, 317. [CrossRef]\n202. Peñuelas, J.; Filella, I.; Biel, C.; Serrano,\
    \ L.; Save, R. The reﬂectance at the 950–970 nm region as an indicator\nof plant\
    \ water status. Int. J. Remote Sens. 1993, 14, 1887–1905. [CrossRef]\n203. Jones,\
    \ C.L.; Weckler, P.R.; Maness, N.O.; Stone, M.L.; Jayasekara, R. Estimating water\
    \ stress in plants\nusing hyperspectral sensing. In Proceedings of the 2004 ASAE\
    \ Annual Meeting, Ottawa, ON, Canada,\n1–4 August 2004; p. 1.\n204. Aˇc, A.; Malenovskỳ,\
    \ Z.; Olejníˇcková, J.; Gallé, A.; Rascher, U.; Mohammed, G. Meta-analysis assessing\n\
    potential of steady-state chlorophyll ﬂuorescence for remote sensing detection\
    \ of plant water, temperature\nand nitrogen stress. Remote Sens. Environ. 2015,\
    \ 168, 420–436. [CrossRef]\n205. Mohammed, G.H.; Colombo, R.; Middleton, E.M.;\
    \ Rascher, U.; van der Tol, C.; Nedbal, L.; Goulas, Y.;\nPérez-Priego, O.; Damm,\
    \ A.; Meroni, M.; et al. Remote sensing of solar-induced chlorophyll ﬂuorescence\n\
    (SIF) in vegetation: 50 years of progress. Remote Sens. Environ. 2019, 231, 111177.\
    \ [CrossRef]\n206. Panigada, C.; Rossini, M.; Meroni, M.; Cilia, C.; Busetto,\
    \ L.; Amaducci, S.; Boschetti, M.; Cogliati, S.; Picchi, V.;\nPinto, F.; et al.\
    \ Fluorescence, PRI and canopy temperature for water stress detection in cereal\
    \ crops. Int. J.\nAppl. Earth Obs. Geoinformation 2014, 30, 167–178. [CrossRef]\n\
    207. Jones, H.G.; Stoll, M.; Santos, T.; Sousa, C.D.; Chaves, M.M.; Grant, O.M.\
    \ Use of infrared thermography for\nmonitoring stomatal closure in the ﬁeld: application\
    \ to grapevine. J. Exp. Bot. 2002, 53, 2249–2260. [CrossRef]\n208. Jackson, R.D.;\
    \ Idso, S.B.; Reginato, R.J.; Pinter, P.J. Canopy temperature as a crop water\
    \ stress indicator.\nWater Resour. Res. 1981, 17, 1133–1138. [CrossRef]\n209.\
    \ Bellvert, J.; Zarco-Tejada, P.J.; Girona, J.; Fereres, E. Mapping crop water\
    \ stress index in a ‘Pinot-noir’vineyard:\ncomparing ground measurements with\
    \ thermal remote sensing imagery from an unmanned aerial vehicle.\nPrecis. Agric.\
    \ 2014, 15, 361–376. [CrossRef]\n210. Fuentes, S.; De Bei, R.; Pech, J.; Tyerman,\
    \ S. Computational water stress indices obtained from thermal image\nanalysis\
    \ of grapevine canopies. Irrig. Sci. 2012, 30, 523–536. [CrossRef]\nAgronomy 2020,\
    \ 10, 140\n31 of 35\n211. Jackson, R.D. Canopy temperature and crop water stress.\
    \ In Advances in Irrigation; Elsevier: Amsterdam,\nThe Netherlands, 1982; Volume\
    \ 1, pp. 43–85.\n212. Idso, S.; Jackson, R.; Pinter, P., Jr.; Reginato, R.; Hatﬁeld,\
    \ J. Normalizing the stress-degree-day parameter for\nenvironmental variability.\
    \ Agric. Meteorol. 1981, 24, 45–55. [CrossRef]\n213. Möller, M.; Alchanatis, V.;\
    \ Cohen, Y.; Meron, M.; Tsipris, J.; Naor, A.; Ostrovsky, V.; Sprintsin, M.; Cohen,\
    \ S.\nUse of thermal and visible imagery for estimating crop water status of irrigated\
    \ grapevine. J. Exp. Bot. 2006,\n58, 827–838. [CrossRef] [PubMed]\n214. Egea,\
    \ G.; Padilla-Díaz, C.M.; Martinez-Guanter, J.; Fernández, J.E.; Pérez-Ruiz, M.\
    \ Assessing a crop water\nstress index derived from aerial thermal imaging and\
    \ infrared thermometry in super-high density olive\norchards. Agric. Water Manag.\
    \ 2017, 187, 210–221. [CrossRef]\n215. Bannari, A.; Morin, D.; Bonn, F.; Huete,\
    \ A. A review of vegetation indices. Remote Sens. Rev. 1995, 13, 95–120.\n[CrossRef]\n\
    216. Ballester, C.; Zarco-Tejada, P.; Nicolas, E.; Alarcon, J.; Fereres, E.; Intrigliolo,\
    \ D.; Gonzalez-Dugo, V. Evaluating\nthe performance of xanthophyll, chlorophyll\
    \ and structure-sensitive spectral indices to detect water stress in\nﬁve fruit\
    \ tree species. Precis. Agric. 2018, 19, 178–193. [CrossRef]\n217. Romero-Trigueros,\
    \ C.; Nortes, P.A.; Alarcón, J.J.; Hunink, J.E.; Parra, M.; Contreras, S.; Droogers,\
    \ P.; Nicolás, E.\nEﬀects of saline reclaimed waters and deﬁcit irrigation on\
    \ Citrus physiology assessed by UAV remote sensing.\nAgric. Water Manag. 2017,\
    \ 183, 60–69. [CrossRef]\n218. Zhao, T.; Stark, B.; Chen, Y.; Ray, A.; Doll, D.\
    \ More reliable crop water stress quantiﬁcation using small\nunmanned aerial systems\
    \ (sUAS). IFAC-PapersOnLine 2016, 49, 409–414. [CrossRef]\n219. Sandholt, I.;\
    \ Rasmussen, K.; Andersen, J. A simple interpretation of the surface temperature/vegetation\
    \ index\nspace for assessment of surface moisture status. Remote Sens. Environ.\
    \ 2002, 79, 213–224. [CrossRef]\n220. Wang, L.; Qu, J.J. Satellite remote sensing\
    \ applications for surface soil moisture monitoring: A review.\nFront. Earth Sci.\
    \ China 2009, 3, 237–247. [CrossRef]\n221. Colaizzi, P.D.; Barnes, E.M.; Clarke,\
    \ T.R.; Choi, C.Y.; Waller, P.M. Estimating soil moisture under low frequency\n\
    surface irrigation using crop water stress index. J. Irrig. Drain. Eng. 2003,\
    \ 129, 27–35. [CrossRef]\n222. Ahmed, A.; Zhang, Y.; Nichols, S. Review and evaluation\
    \ of remote sensing methods for soil-moisture\nestimation. SPIE Rev. 2011, 2,\
    \ 028001.\n223. Kerr, Y.H. Soil moisture from space: Where are we? Hydrogeol.\
    \ J. 2007, 15, 117–120. [CrossRef]\n224. Kerr, Y.H.; Waldteufel, P.; Wigneron,\
    \ J.-P.; Delwart, S.; Cabot, F.; Boutin, J.; Escorihuela, M.-J.; Font, J.; Reul,\
    \ N.;\nGruhier, C.; et al. The SMOS mission: New tool for monitoring key elements\
    \ ofthe global water cycle.\nProc. IEEE 2010, 98, 666–687. [CrossRef]\n225. Entekhabi,\
    \ D.; Njoku, E.G.; O’Neill, P.E.; Kellogg, K.H.; Crow, W.T.; Edelstein, W.N.;\
    \ Entin, J.K.; Goodman, S.D.;\nJackson, T.J.; Johnson, J.; et al. The soil moisture\
    \ active passive (SMAP) mission. Proc. IEEE 2010, 98, 704–716.\n[CrossRef]\n226.\
    \ Yueh, S.; Entekhabi, D.; O’Neill, P.; Njoku, E.; Entin, J. NASA soil moisture\
    \ active passive mission status\nand science performance. In Proceedings of the\
    \ 2016 IEEE International Geoscience and Remote Sensing\nSymposium (IGARSS 2016),\
    \ Beijing, China, 10–16 July 2016; pp. 116–119.\n227. Piles, M.; Sánchez, N.;\
    \ Vall-llossera, M.; Camps, A.; Martínez-Fernández, J.; Martínez, J.; González-Gambau,\
    \ V.\nA Downscaling Approach for SMOS Land Observations: Evaluation of High-Resolution\
    \ Soil Moisture Maps\nOver the Iberian Peninsula. IEEE J. Sel. Top. Appl. Earth\
    \ Obs. Remote Sens. 2014, 7, 3845–3857. [CrossRef]\n228. Cui, C.; Xu, J.; Zeng,\
    \ J.; Chen, K.-S.; Bai, X.; Lu, H.; Chen, Q.; Zhao, T. Soil moisture mapping from\
    \ satellites:\nAn intercomparison of SMAP, SMOS, FY3B, AMSR2, and ESA CCI over\
    \ two dense network regions at\ndiﬀerent spatial scales. Remote Sens. 2018, 10,\
    \ 33. [CrossRef]\n229. Peng, J.; Loew, A.; Merlin, O.; Verhoest, N.E. A review\
    \ of spatial downscaling of satellite remotely sensed soil\nmoisture. Rev. Geophys.\
    \ 2017, 55, 341–366. [CrossRef]\n230. Roussel, N.; Darrozes, J.; Ha, C.; Boniface,\
    \ K.; Frappart, F.; Ramillien, G.; Gavart, M.; Van de Vyvere, L.;\nDesenfans,\
    \ O.; Baup, F. Multi-scale volumetric soil moisture detection from GNSS SNR data:\
    \ Ground-based\nand airborne applications. In Proceedings of the 2016 IEEE Metrology\
    \ for Aerospace (MetroAeroSpace),\nFlorence, Italy, 22–23 June 2016; pp. 573–578.\n\
    231. Yan, S.; Zhang, N.; Chen, N.; Gong, J. Feasibility of using signal strength\
    \ indicator data to estimate soil\nmoisture based on GNSS interference signal\
    \ analysis. Remote Sens. Lett. 2018, 9, 61–70. [CrossRef]\nAgronomy 2020, 10,\
    \ 140\n32 of 35\n232. Johansen, K.; Sohlbach, M.; Sullivan, B.; Stringer, S.;\
    \ Peasley, D.; Phinn, S. Mapping banana plants from\nhigh spatial resolution orthophotos\
    \ to facilitate plant health assessment. Remote Sens. 2014, 6, 8261–8286.\n[CrossRef]\n\
    233. Hall, A.; Louis, J.; Lamb, D.W. Low-resolution remotely sensed images of\
    \ winegrape vineyards map spatial\nvariability in planimetric canopy area instead\
    \ of leaf area index. Aust. J. Grape Wine Res. 2008, 14, 9–17.\n[CrossRef]\n234.\
    \ Furness, G.; Magarey, P.; Miller, P.; Drew, H. Fruit tree and vine sprayer calibration\
    \ based on canopy size and\nlength of row: unit canopy row method. Crop Prot.\
    \ 1998, 17, 639–644. [CrossRef]\n235. Rosell, J.; Sanz, R. A review of methods\
    \ and applications of the geometric characterization of tree crops in\nagricultural\
    \ activities. Comput. Electron. Agric. 2012, 81, 124–141. [CrossRef]\n236. Lee,\
    \ K.; Ehsani, R. A laser scanner based measurement system for quantiﬁcation of\
    \ citrus tree geometric\ncharacteristics. Appl. Eng. Agric. 2009, 25, 777–788.\
    \ [CrossRef]\n237. Li, F.; Cohen, S.; Naor, A.; Shaozong, K.; Erez, A. Studies\
    \ of canopy structure and water use of apple trees on\nthree rootstocks. Agric.\
    \ Water Manag. 2002, 55, 1–14. [CrossRef]\n238. Kustas, W.; Agam, N.; Alﬁeri,\
    \ J.; McKee, L.; Prueger, J.; Hipps, L.; Howard, A.; Heitman, J. Below canopy\n\
    radiation divergence in a vineyard: Implications on interrow surface energy balance.\
    \ Irrig. Sci. 2019, 37,\n227–237. [CrossRef]\n239. Bendig, J.V. Unmanned aerial\
    \ vehicles (UAVs) for multi-temporal crop surface modelling. A new method for\n\
    plant height and biomass estimation based on RGB-imaging. Ph.D. Thesis, University\
    \ of Cologne, Cologne,\nGermany, 2015.\n240. Gowda, P.H.; Chavez, J.L.; Colaizzi,\
    \ P.D.; Evett, S.R.; Howell, T.A.; Tolk, J.A. ET mapping for agricultural\nwater\
    \ management: present status and challenges. Irrig. Sci. 2008, 26, 223–237. [CrossRef]\n\
    241. Zhang, K.; Kimball, J.S.; Running, S.W. A review of remote sensing based\
    \ actual evapotranspiration estimation.\nWiley Interdiscip. Rev. Water 2016, 3,\
    \ 834–853. [CrossRef]\n242. Liou, Y.-A.; Kar, S. Evapotranspiration estimation\
    \ with remote sensing and various surface energy balance\nalgorithms—A review.\
    \ Energies 2014, 7, 2821–2849. [CrossRef]\n243. Courault, D.; Seguin, B.; Olioso,\
    \ A. Review on estimation of evapotranspiration from remote sensing data:\nFrom\
    \ empirical to numerical modeling approaches. Irrig. Drain. Syst. 2005, 19, 223–249.\
    \ [CrossRef]\n244. Kalma, J.D.; McVicar, T.R.; McCabe, M.F. Estimating land surface\
    \ evaporation: A review of methods using\nremotely sensed surface temperature\
    \ data. Surv. Geophys. 2008, 29, 421–469. [CrossRef]\n245. Li, Z.-L.; Tang, R.;\
    \ Wan, Z.; Bi, Y.; Zhou, C.; Tang, B.; Yan, G.; Zhang, X. A review of current\
    \ methodologies\nfor regional evapotranspiration estimation from remotely sensed\
    \ data. Sensors 2009, 9, 3801–3853. [CrossRef]\n246. Marshall, M.; Thenkabail,\
    \ P.; Biggs, T.; Post, K. Hyperspectral narrowband and multispectral broadband\n\
    indices for remote sensing of crop evapotranspiration and its components (transpiration\
    \ and soil evaporation).\nAgric. For. Meteorol. 2016, 218, 122–134. [CrossRef]\n\
    247. Maes, W.; Steppe, K. Estimating evapotranspiration and drought stress with\
    \ ground-based thermal remote\nsensing in agriculture: a review. J. Exp. Bot.\
    \ 2012, 63, 4671–4712. [CrossRef]\n248. Bastiaanssen, W.G.; Menenti, M.; Feddes,\
    \ R.; Holtslag, A. A remote sensing surface energy balance algorithm\nfor land\
    \ (SEBAL). 1. Formulation. J. Hydrol. 1998, 212, 198–212. [CrossRef]\n249. Allen,\
    \ R.; Irmak, A.; Trezza, R.; Hendrickx, J.M.; Bastiaanssen, W.; Kjaersgaard, J.\
    \ Satellite-based ET estimation\nin agriculture using SEBAL and METRIC. Hydrol.\
    \ Process. 2011, 25, 4011–4027. [CrossRef]\n250. Allen, R.G.; Tasumi, M.; Trezza,\
    \ R. Satellite-based energy balance for mapping evapotranspiration with\ninternalized\
    \ calibration (METRIC)—Model. J. Irrig. Drain. Eng. 2007, 133, 380–394. [CrossRef]\n\
    251. Allen, R.G.; Tasumi, M.; Morse, A.; Trezza, R.; Wright, J.L.; Bastiaanssen,\
    \ W.; Kramber, W.; Lorite, I.;\nRobison, C.W. Satellite-Based Energy Balance for\
    \ Mapping Evapotranspiration with Internalized Calibration\n(METRIC)-Applications.\
    \ J. Irrig. Drain. Eng. 2007, 133, 395–406. [CrossRef]\n252. Allen, R.G.; Pereira,\
    \ L.S.; Raes, D.; Smith, M. FAO Irrigation and drainage paper No. 56. Rome Food\
    \ Agric.\nOrgan. U. N. 1998, 56, e156.\n253. Jackson, R.D.; Moran, M.S.; Gay,\
    \ L.W.; Raymond, L.H. Evaluating evaporation from ﬁeld crops using airborne\n\
    radiometry and ground-based meteorological data. Irrig. Sci. 1987, 8, 81–90. [CrossRef]\n\
    254. Williams, L.; Ayars, J. Grapevine water use and the crop coeﬃcient are linear\
    \ functions of the shaded area\nmeasured beneath the canopy. Agric. For. Meteorol.\
    \ 2005, 132, 201–211. [CrossRef]\nAgronomy 2020, 10, 140\n33 of 35\n255. Jayanthi,\
    \ H.; Neale, C.M.; Wright, J.L. Development and validation of canopy reﬂectance-based\
    \ crop\ncoeﬃcient for potato. Agric. Water Manag. 2007, 88, 235–246. [CrossRef]\n\
    256. Samani, Z.; Bawazir, A.S.; Bleiweiss, M.; Skaggs, R.; Longworth, J.; Tran,\
    \ V.D.; Pinon, A. Using remote sensing\nto evaluate the spatial variability of\
    \ evapotranspiration and crop coeﬃcient in the lower Rio Grande Valley,\nNew Mexico.\
    \ Irrig. Sci. 2009, 28, 93–100. [CrossRef]\n257. Kustas, W.P.; Anderson, M.C.;\
    \ Alﬁeri, J.G.; Knipper, K.; Torres-Rua, A.; Parry, C.K.; Nieto, H.; Agam, N.;\n\
    White, W.A.; Gao, F.; et al. The grape remote sensing atmospheric proﬁle and evapotranspiration\
    \ experiment.\nBull. Am. Meteorol. Soc. 2018, 99, 1791–1812. [CrossRef]\n258.\
    \ Kamble, B.; Kilic, A.; Hubbard, K. Estimating crop coeﬃcients using remote sensing-based\
    \ vegetation index.\nRemote Sens. 2013, 5, 1588–1602. [CrossRef]\n259. Hou, M.;\
    \ Tian, F.; Zhang, L.; Li, S.; Du, T.; Huang, M.; Yuan, Y. Estimating crop transpiration\
    \ of soybean\nunder diﬀerent irrigation treatments using thermal infrared remote\
    \ sensing imagery. Agronomy 2019, 9, 8.\n[CrossRef]\n260. Knipper, K.R.; Kustas,\
    \ W.P.; Anderson, M.C.; Alﬁeri, J.G.; Prueger, J.H.; Hain, C.R.; Gao, F.; Yang,\
    \ Y.;\nMcKee, L.G.; Nieto, H.; et al. Evapotranspiration estimates derived using\
    \ thermal-based satellite remote\nsensing and data fusion for irrigation management\
    \ in California vineyards. Irrig. Sci. 2019, 37, 431–449.\n[CrossRef]\n261. Hoﬀmann,\
    \ H.; Nieto, H.; Jensen, R.; Guzinski, R.; Zarco-Tejada, P.; Friborg, T. Estimating\
    \ evapotranspiration\nwith thermal UAV data and two source energy balance models.\
    \ Hydrol. Earth Syst. Sci. Discuss. 2016, 20,\n697–713. [CrossRef]\n262. Cammalleri,\
    \ C.; Anderson, M.; Kustas, W. Upscaling of evapotranspiration ﬂuxes from instantaneous\
    \ to\ndaytime scales for thermal remote sensing applications. Hydrol. Earth Syst.\
    \ Sci. 2014, 18, 1885–1894.\n[CrossRef]\n263. Biggs, T.W.; Marshall, M.; Messina,\
    \ A. Mapping daily and seasonal evapotranspiration from irrigated crops\nusing\
    \ global climate grids and satellite imagery: Automation and methods comparison.\
    \ Water Resour. Res.\n2016, 52, 7311–7326. [CrossRef]\n264. Chávez, J.L.; Neale,\
    \ C.M.; Prueger, J.H.; Kustas, W.P. Daily evapotranspiration estimates from extrapolating\n\
    instantaneous airborne remote sensing ET values. Irrig. Sci. 2008, 27, 67–81.\
    \ [CrossRef]\n265. McCabe, M.F.; Wood, E.F. Scale inﬂuences on the remote estimation\
    \ of evapotranspiration using multiple\nsatellite sensors. Remote Sens. Environ.\
    \ 2006, 105, 271–285. [CrossRef]\n266. Kustas, W.; Li, F.; Jackson, T.; Prueger,\
    \ J.; MacPherson, J.; Wolde, M. Eﬀects of remote sensing pixel resolution\non\
    \ modeled energy ﬂux variability of croplands in Iowa. Remote Sens. Environ. 2004,\
    \ 92, 535–547. [CrossRef]\n267. Hong, S.; Hendrickx, J.M.; Borchers, B. Eﬀect\
    \ of scaling transfer between evapotranspiration maps derived\nfrom LandSat 7\
    \ and MODIS images. In Targets and Backgrounds XI: Characterization and Representation;\n\
    International Society for Optics and Photonics: Orlando, FL, USA, 2005; Volume\
    \ 5811, pp. 147–159.\n268. Abiodun, O.O.; Guan, H.; Post, V.E.; Batelaan, O. Comparison\
    \ of MODIS and SWAT evapotranspiration over\na complex terrain at diﬀerent spatial\
    \ scales. Hydrol. Earth Syst. Sci. 2018, 22, 2775–2794. [CrossRef]\n269. Justice,\
    \ C.; Townshend, J.; Vermote, E.; Masuoka, E.; Wolfe, R.; Saleous, N.; Roy, D.;\
    \ Morisette, J. An overview\nof MODIS Land data processing and product status.\
    \ Remote Sens. Environ. 2002, 83, 3–15. [CrossRef]\n270. Nieto, H.; Bellvert,\
    \ J.; Kustas, W.P.; Alﬁeri, J.G.; Gao, F.; Prueger, J.; Torres-Rua, A.; Hipps,\
    \ L.E.; Elarab, M.;\nSong, L. Unmanned airborne thermal and mutilspectral imagery\
    \ for estimating evapotranspiration in irrigated\nvineyards. In Proceedings of\
    \ the 2017 IEEE International Geoscience and Remote Sensing Symposium\n(IGARSS\
    \ 2017), Fort Worth, TX, USA, 23–28 July 2017; pp. 5510–5513.\n271. Ortega-Farías,\
    \ S.; Ortega-Salazar, S.; Poblete, T.; Poblete-Echeverría, C.; Zúñiga, M.; Sepúlveda-Reyes,\
    \ D.;\nKilic, A.; Allen, R. Estimation of olive evapotranspiration using multispectral\
    \ and thermal sensors placed\naboard an unmanned aerial vehicle. Acta Hortic.\
    \ 2017, 1150, 1–8. [CrossRef]\n272. Gago, J.; Douthe, C.; Coopman, R.E.; Gallego,\
    \ P.P.; Ribas-Carbo, M.; Flexas, J.; Escalona, J.; Medrano, H. UAVs\nchallenge\
    \ to assess water stress for sustainable agriculture. Agric. Water Manag. 2015,\
    \ 153, 9–19. [CrossRef]\n273. Sepúlveda-Reyes, D.; Ingram, B.; Bardeen, M.; Zúñiga,\
    \ M.; Ortega-Farías, S.; Poblete-Echeverría, C. Selecting\ncanopy zones and thresholding\
    \ approaches to assess grapevine water status by using aerial and ground-based\n\
    thermal imaging. Remote Sens. 2016, 8, 822. [CrossRef]\n274. McBratney, A.; Whelan,\
    \ B.; Ancev, T.; Bouma, J. Future directions of precision agriculture. Precis.\
    \ Agric. 2005,\n6, 7–23. [CrossRef]\nAgronomy 2020, 10, 140\n34 of 35\n275. Ferguson,\
    \ R.; Rundquist, D. Remote sensing for site-speciﬁc crop management. In Precision\
    \ Agriculture Basics;\nShannon, D.K., Clay, D.E., Kitchen, N.R., Eds.; American\
    \ Society of Agronomy: Madison, WI, USA; Crop\nScience Society of America: Madison,\
    \ WI, USA; Soil Science Society of America: Madison, WI, USA, 2018;\npp. 103–118.\n\
    276. Florin, M.J.; McBratney, A.B.; Whelan, B.M. Extending site-speciﬁc crop management\
    \ from individual ﬁelds\nto an entire farm. In Proceedings of the Precision agriculture\
    \ ’05, Proceedings of the 5th European Conference\non Precision Agriculture, Uppsala,\
    \ Sweden, 9–12 June 2005; pp. 857–863.\n277. Perea-Moreno, A.J.; Aguilera-Urena,\
    \ M.J.; Merono-de Larriva, J.E.; Manzano-Agugliaro, F. Assessment of\nthe potential\
    \ of UAV video image analysis for planning irrigation needs of golf courses. Water\
    \ 2016, 8, 584.\n[CrossRef]\n278. Meron, M.; Tsipris, J.; Charitt, D. Remote mapping\
    \ of crop water status to assess spatial variability of crop\nstress. Precis.\
    \ Agric. 2003, 405–410.\n279. Idso, S.B. Non-water-stressed baselines: A key to\
    \ measuring and interpreting plant water stress. Agric. Meteorol.\n1982, 27, 59–70.\
    \ [CrossRef]\n280. Cohen, Y.; Alchanatis, V.; Meron, M.; Saranga, Y.; Tsipris,\
    \ J. Estimation of leaf water potential by thermal\nimagery and spatial analysis.\
    \ J. Exp. Bot. 2005, 56, 1843–1852. [CrossRef] [PubMed]\n281. Pagay, V.; Kidman,\
    \ C.; Jenkins, A. Proximal and remote sensing tools for regional-scale characterisation\
    \ of\ngrapevine water and nitrogen status in Coonawarra. Wine Vitic. J. 2016,\
    \ 31, 42–47.\n282. Romero, M.; Luo, Y.; Su, B.; Fuentes, S. Vineyard water status\
    \ estimation using multispectral imagery from an\nUAV platform and machine learning\
    \ algorithms for irrigation scheduling management. Comput. Electron. Agric.\n\
    2018, 147, 109–117. [CrossRef]\n283. Goldhamer, D.A.; Viveros, M.; Salinas, M.\
    \ Regulated deﬁcit irrigation in almonds: eﬀects of variations in\napplied water\
    \ and stress timing on yield and yield components. Irrig. Sci. 2006, 24, 101–114.\
    \ [CrossRef]\n284. Girona, J.; Marsal, J.; Cohen, M.; Mata, M.; Miravete, C. Physiological,\
    \ growth and yield responses of almond\n(Prunus dulcis L ) to diﬀerent irrigation\
    \ regimes. Acta Hortic. 1993, 335, 389–398. [CrossRef]\n285. Sadler, E.; Evans,\
    \ R.; Stone, K.; Camp, C. Opportunities for conservation with precision irrigation.\
    \ J. Soil\nWater Conserv. 2005, 60, 371–378.\n286. Corbane, C.; Jacob, F.; Raclot,\
    \ D.; Albergel, J.; Andrieux, P. Multitemporal analysis of hydrological soil surface\n\
    characteristics using aerial photos: A case study on a Mediterranean vineyard.\
    \ Int. J. Appl. Earth Obs. Geoinf.\n2012, 18, 356–367. [CrossRef]\n287. Osroosh,\
    \ Y.; Peters, R.T.; Campbell, C.S. Daylight crop water stress index for continuous\
    \ monitoring of water\nstatus in apple trees. Irrig. Sci. 2016, 34, 209–219. [CrossRef]\n\
    288. Osroosh, Y.; Peters, R.T.; Campbell, C.S.; Zhang, Q. Comparison of irrigation\
    \ automation algorithms for\ndrip-irrigated apple trees. Comput. Electron. Agric.\
    \ 2016, 128, 87–99. [CrossRef]\n289. Lamm, F.R.; Aiken, R.M. Comparison of temperature-time\
    \ threshold-and ET-based irrigation scheduling for\ncorn production. In Proceedings\
    \ of the 2008 ASABE Annual International Meeting, Providence, RI, USA,\n29 June–2\
    \ July 2008; p. 1.\n290. O’Shaughnessy, S.A.; Evett, S.R.; Colaizzi, P.D.; Howell,\
    \ T.A. A crop water stress index and time threshold\nfor automatic irrigation\
    \ scheduling of grain sorghum. Agric. Water Manag. 2012, 107, 122–132. [CrossRef]\n\
    291. Bellvert, J.; Zarco-Tejada, P.; Gonzalez-Dugo, V.; Girona, J.; Fereres, E.\
    \ Scheduling vineyard irrigation based\non mapping leaf water potential from airborne\
    \ thermal imagery. In Precision Agriculture’13; Staﬀord, J.V., Ed.;\nSpringer:\
    \ Cham, Switzerland, 2013; pp. 699–704.\n292. Bellvert, J.; Girona, J. The use\
    \ of multispectral and thermal images as a tool for irrigation scheduling in\n\
    vineyards. In The Use of Remote Sensing and Geographic Information Systems for\
    \ Irrigation Management in\nSouthwest Europe; Erena, M., López-Francos, A., Montesinos,\
    \ S., Berthoumieu, J.-P., Eds.; CIHEAM: Zaragoza,\nSpain, 2012; pp. 131–137.\n\
    293. Erdem, Y.; ¸Sehirali, S.; Erdem, T.; Kenar, D. Determination of crop water\
    \ stress index for irrigation scheduling\nof bean (Phaseolus vulgaris L.). Turk.\
    \ J. Agric. For. 2006, 30, 195–202.\n294. Osroosh, Y.; Troy Peters, R.; Campbell,\
    \ C.S.; Zhang, Q. Automatic irrigation scheduling of apple trees using\ntheoretical\
    \ crop water stress index with an innovative dynamic threshold. Comput. Electron.\
    \ Agric. 2015, 118,\n193–203. [CrossRef]\n295. Irmak, S.; Haman, D.Z.; Bastug,\
    \ R. Determination of crop water stress index for irrigation timing and yield\n\
    estimation of corn. Agron. J. 2000, 92, 1221–1227. [CrossRef]\nAgronomy 2020,\
    \ 10, 140\n35 of 35\n296. Acevedo-Opazo, C.; Tisseyre, B.; Ojeda, H.; Ortega-Farias,\
    \ S.; Guillaume, S. Is it possible to assess the spatial\nvariability of vine\
    \ water status? OENO One 2008, 42, 203–219. [CrossRef]\n297. Acevedo-Opazo, C.;\
    \ Tisseyre, B.; Guillaume, S.; Ojeda, H. The potential of high spatial resolution\
    \ information\nto deﬁne within-vineyard zones related to vine water status. Precis.\
    \ Agric. 2008, 9, 285–302. [CrossRef]\n298. Petrie, P.R.; Wang, Y.; Liu, S.; Lam,\
    \ S.; Whitty, M.A.; Skewes, M.A. The accuracy and utility of a low cost\nthermal\
    \ camera and smartphone-based system to assess grapevine water status. Biosyst.\
    \ Eng. 2019, 179,\n126–139. [CrossRef]\n299. Woellert, K.; Ehrenfreund, P.; Ricco,\
    \ A.J.; Hertzfeld, H. Cubesats: Cost-eﬀective science and technology\nplatforms\
    \ for emerging and developing nations. Adv. Space Res. 2011, 47, 663–684. [CrossRef]\n\
    300. Kramer, H.J.; Cracknell, A.P. An overview of small satellites in remote sensing.\
    \ Int. J. Remote Sens. 2008, 29,\n4285–4337. [CrossRef]\n301. McCabe, M.; Aragon,\
    \ B.; Houborg, R.; Mascaro, J. CubeSats in Hydrology: Ultrahigh-Resolution Insights\n\
    Into Vegetation Dynamics and Terrestrial Evaporation. Water Resour. Res. 2017,\
    \ 53, 10017–10024. [CrossRef]\n302. Trombetti, M.; Riaño, D.; Rubio, M.; Cheng,\
    \ Y.; Ustin, S. Multi-temporal vegetation canopy water content\nretrieval and\
    \ interpretation using artiﬁcial neural networks for the continental USA. Remote\
    \ Sens. Environ.\n2008, 112, 203–215. [CrossRef]\n303. King, B.; Shellie, K. Evaluation\
    \ of neural network modeling to predict non-water-stressed leaf temperature in\n\
    wine grape for calculation of crop water stress index. Agric. Water Manag. 2016,\
    \ 167, 38–52. [CrossRef]\n304. Shan, N.; Ju, W.; Migliavacca, M.; Martini, D.;\
    \ Guanter, L.; Chen, J.; Goulas, Y.; Zhang, Y. Modeling canopy\nconductance and\
    \ transpiration from solar-induced chlorophyll ﬂuorescence. Agric. For. Meteorol.\
    \ 2019, 268,\n189–201. [CrossRef]\n305. Moreno, J.; Goulas, Y.; Huth, A.; Middelton,\
    \ E.; Miglietta, F.; Mohammed, G.; Nebdal, L.; Rascher, U.;\nVerhof, W. Report\
    \ for mission selection: CarbonSat ﬂex–An earth explorer to observe vegetation\
    \ ﬂuorescence.\nEur. Space Agency 2015, 1330/2, 179–185.\n306. Drusch, M.; Moreno,\
    \ J.; Del Bello, U.; Franco, R.; Goulas, Y.; Huth, A.; Kraft, S.; Middleton, E.M.;\
    \ Miglietta, F.;\nMohammed, G.; et al. The ﬂuorescence explorer mission concept-ESA’s\
    \ Earth explorer 8. IEEE Trans. Geosci.\nRemote Sens. 2017, 55, 1273–1284. [CrossRef]\n\
    307. Gautam, D.; Lucieer, A.; Watson, C.; McCoull, C. Lever-arm and boresight\
    \ correction, and ﬁeld of view\ndetermination of a spectroradiometer mounted on\
    \ an unmanned aircraft system. ISPRS J. Photogramm.\nRemote Sens. 2019, 155, 25–36.\
    \ [CrossRef]\n308. Garzonio, R.; Di Mauro, B.; Colombo, R.; Cogliati, S. Surface\
    \ reﬂectance and sun-induced ﬂuorescence\nspectroscopy measurements using a small\
    \ hyperspectral UAS. Remote Sens. 2017, 9, 472. [CrossRef]\n309. Gautam, D.; Lucieer,\
    \ A.; Bendig, J.; Malenovský, Z. Footprint Determination of a Spectroradiometer\
    \ Mounted\non an Unmanned Aircraft System. IEEE Trans. Geosci. Remote Sens. 2019,\
    \ 1–12. [CrossRef]\n310. Bendig, J.; Malenovskỳ, Z.; Gautam, D.; Lucieer, A. Solar-Induced\
    \ Chlorophyll Fluorescence Measured\nFrom an Unmanned Aircraft System: Sensor\
    \ Etaloning and Platform Motion Correction. IEEE Trans. Geosci.\nRemote Sens.\
    \ 2019, 1–8. [CrossRef]\n311. TongKe, F. Smart agriculture based on cloud computing\
    \ and IOT. J. Converg. Inf. Technol. 2013, 8, 210–216.\n312. Ojha, T.; Misra,\
    \ S.; Raghuwanshi, N.S. Wireless sensor networks for agriculture: The state-of-the-art\
    \ in\npractice and future challenges. Comput. Electron. Agric. 2015, 118, 66–84.\
    \ [CrossRef]\n313. Hori, M.; Kawashima, E.; Yamazaki, T. Application of cloud\
    \ computing to agriculture and prospects in other\nﬁelds. Fujitsu Sci. Tech. J.\
    \ 2010, 46, 446–454.\n314. Goap, A.; Sharma, D.; Shukla, A.; Krishna, C.R. An\
    \ IoT based smart irrigation management system using\nMachine learning and open\
    \ source technologies. Comput. Electron. Agric. 2018, 155, 41–49. [CrossRef]\n\
    © 2020 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open\
    \ access\narticle distributed under the terms and conditions of the Creative Commons\
    \ Attribution\n(CC BY) license (http://creativecommons.org/licenses/by/4.0/).\n"
  inline_citation: '>'
  journal: Agronomy (Basel)
  limitations: '>'
  pdf_link: https://www.mdpi.com/2073-4395/10/1/140/pdf
  publication_year: 2020
  relevance_score1: 0
  relevance_score2: 0
  title: A Review of Current and Potential Applications of Remote Sensing to Study
    the Water Status of Horticultural Crops
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.51983/ajcst-2018.7.s1.1799
  analysis: '>'
  authors:
  - V Sudha
  - Shashank Mohan
  - S. Arivalagan
  citation_count: 1
  full_citation: '>'
  full_text: '>

    404 Not Found'
  inline_citation: '>'
  journal: Asian Journal of Computer Science and Technology
  limitations: '>'
  pdf_link: https://ojs.trp.org.in/index.php/ajcst/article/view/1799/892
  publication_year: 2018
  relevance_score1: 0
  relevance_score2: 0
  title: Big Data Analytics to Increase the Agricultural Yield by Using Machine Learning
    Approaches
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1515/jisys-2022-0046
  analysis: '>'
  authors:
  - S. Premkumar
  - A. N. Sigappi
  citation_count: 5
  full_citation: '>'
  full_text: '>

    Research Article

    S. Premkumar* and AN. Sigappi

    IoT-enabled edge computing model for smart

    irrigation system

    https://doi.org/10.1515/jisys-2022-0046

    received January 10, 2022; accepted March 16, 2022

    Abstract: Precision agriculture is a breakthrough in digital farming technology,
    which facilitates the appli-

    cation of precise and exact amount of input level of water and fertilizer to the
    crop at the required time for

    increasing the yield. Since agriculture relies on direct rainfall than irrigation
    and the prediction of rainfall

    date is easily available from web source, the integration of rainfall prediction
    with precision agriculture

    helps to regulate the water consumption in farms. In this work, an edge computing
    model is developed for

    predicting soil moisture in real time and managing the water usage in accordance
    with rain prediction. A

    soil moisture prediction hybrid algorithm (SMPHA) has been developed that revolves
    around the decision-

    making techniques with live environmental parameters including weather parameters
    for the prediction of

    soil moisture through the impact of precipitation. Numerous algorithms with the
    combination of regression

    + clustering are estimated, and it is inferred that XGBoost + k-means outperforms
    other algorithmic com-

    binations that is deployed in edge model. This model is used as an intermediary
    between the end IoT

    devices and cloud that results in the saving of computationally intensive processing
    performed on cloud

    servers. The servers located on a local edge network perform the developed algorithmic
    computations.

    Avoiding transmission over the cloud results in signiﬁcant latency, response time,
    and computation power

    savings and therefore increases the eﬃciency of data transfer. The proposed edge
    computing model is

    implemented in Raspberry Pi as an edge, Heroku as cloud, and edge nodes as the
    combination of Pi with

    actuators and sensors. The monitored data from Pi are stored in MongoDB webserver
    that is controlled by

    Web dashboard. Finally, the developed model is implemented in cloud and edge where
    the edge server

    implementation performs better in terms of latency, bandwidth, throughput, response
    time, and CPU

    memory usage.

    Keywords: smart irrigation, edge-based irrigation, edge computing, precision agriculture,
    soil moisture

    prediction, irrigation management system, IoT, oﬄoading mechanism

    1 Introduction

    It is evident that agriculture always has a specialized role in the anthrophonic
    evolution and has been

    serving as an important economic factor for the growth of a country [1]. Around
    58% of the population

    depend on agriculture as the chief source of livelihood in India. The quality
    and productivity of agricultural

    products have declined over these years as several factors have inﬂuenced the
    crop productivity both

    directly and indirectly. Some major factors that aﬀect the crop production are
    climatic changes, global

    warming, and water scarcity [2]. The agricultural land’s productivity is aﬀected
    by the direct and indirect

    

    * Corresponding author: S. Premkumar, Department of Computer Science and Engineering,
    Faculty of Engineering and

    Technology, Annamalai University, Chidambaram - 608002, Tamilnadu, India, e-mail:
    premambal@gmail.com

    AN. Sigappi: Department of Computer Science and Engineering, Faculty of Engineering
    and Technology, Annamalai University,

    Chidambaram - 608002, Tamilnadu, India, e-mail: an.sigappi@gmail.com

    Journal of Intelligent Systems 2022; 31: 632–650

    Open Access. © 2022 S. Premkumar and AN. Sigappi, published by De Gruyter.

    This work is licensed under the Creative

    Commons Attribution 4.0 International License.

    changes in climate [3,4]. The crop growth has been already aﬀected by the changes
    in climate incurred by

    global warming. The nutrition quality of soil, ground water level, sea, and ocean
    are aﬀected by the

    modiﬁcations in average temperature, rainfall, and extreme weather conditions
    such as hail storms, dust

    storms, heatwaves, etc. due to global warming [5,6]. Degradation of soil is primarily
    created by various

    methods including 93.7% by water erosion, 9.5% by wind erosion, 5.9% by salinity
    and alkalinity, etc.

    Further changes in climate would inﬂuence adversely the crop production [7]. Since
    water is an indispen-

    sable requirement for plants and cultivation, the high level of soil is eroded
    and thereby the fertility is also

    declined. Due to the ever-changing climate, water scarcity has become a huge problem.
    Drought-like

    conditions is already formed in several areas and thereby the present and conventional
    farming practices

    are not suitable. New and unique environment preserving techniques are the need
    of the hour [8].

    The conventional approaches in agriculture are enhanced by the advent of several
    advancements in

    technology [9]. These new improved methodologies ensure optimized utilization
    of resources, accurate

    forecast of water needs and environmental parameters, reduction of human intervention,
    etc. [10]. Conse-

    quently, the outcomes of crops in terms of yield and quality are higher with cost-eﬀective
    methods. One

    such booming technology is the Internet of things (IoT) [11].

    IoT is the collection of components embedded in the sensor for measuring and transferring
    data via

    network devices as sensed from pumps and tractors to weather stations. Primarily,
    IoT deals with the

    transmission and reception of data related to farms through devices using the
    Internet for prediction

    and providing decisions to the farmers. IoT-based methodologies has brought a
    changeover in agricultural

    patterns and farming approaches [12]. IoT devices can gather information about
    soil moisture, chemical

    properties, dam levels, livestock health, and weather details in real time. The
    information acquired from IoT

    devices facilitates the farmers in tracking farms periodically. Farmers can save
    time and money by

    responding faster to farm conditions. Cloud computing models integrated with on-ﬁeld
    agricultural sensors

    need to be incorporated for tackling the issue of processing huge voluminous data.

    One of the major challenges of IoT is the processing of huge datasets in a sequential
    way. Some of the

    key factors that need to be focused on this process are as follows: information
    about the type and nature of

    data, the way of acquiring the data, etc. The preliminary stage comprises acquiring
    the data and ingesting

    the data to the system. Substantial cognizance of data are achieved as the data
    pass through all the

    gateways where it is cleansed and transformed before entering into the system.
    In the near future, dynamic

    prediction of soil moisture and precipitation techniques are to be developed for
    smart irrigation systems.

    Therefore, a system is developed for eﬃcient and optimal utilization of fresh
    water in irrigation along with

    drip irrigation system. It aids in ﬁnding which one of the plants fails to get
    suﬃcient water. When the water

    supply is provided the next day, this delay should not disturb the system. It
    becomes important for the

    farmers to understand the optimal usage of water and fertilizers to bring out
    sustenance in the agricultural

    industry. Therefore, processing must be done for analyzing the data, so that patterns
    can be analyzed and

    planning can be done for the long term, accordingly. Hence, it gives a broad vision
    in deciding where the

    processing is to be done exactly. Therefore, it is obvious that not all data are
    crucial, and it provides a clear

    view of which data need to be stored, discarded, and retained for both long-term
    and short-term purposes.

    Thus, all these challenging issues require to be addressed and that is where storage
    technologies are

    actually highlighted. The poor quality of Internet access in developing nations
    makes the implementation

    quite challenging. An applicable solution to solve this problem is through edge
    computing where the

    essential data could be oﬄoaded from the cloud over the edge of the cloud, and
    this is the exact point

    where the approach of smart sensing with edge computing gets in.

    With the purpose of broadening the potential of edge computing and using it in
    the agriculture domain,

    a novel approach using machine learning (ML) methods is proposed for analyzing
    the data acquired by the

    IoT devices deployed at the farm. Here, the data acquired from IoT components
    undergo preprocessing and

    ML models on the edge nodes to analyze and assess the appropriate results for
    providing the best instruc-

    tions for controlling the actuators (e.g., light, pumps at diﬀerent locations)
    in the farms.

    This article presents an automated system, as shown in Figure 1, to predict the
    soil moisture using the

    ﬁeld information acquired from the self-designed sensor node deployed at the ﬁeld
    and the forecast

    information of weather via Internet. A unique algorithm has been developed that
    revolves around the

    IoT-enabled edge computing model for smart irrigation system

    

    633

    machine learning techniques for the prediction of soil moisture. Here, many algorithms
    with the combina-

    tion of regression + clustering was estimated, and it is inferred that XGBoost
    + k-means outperforms other

    algorithmic combinations, and therefore, it is deployed for the prediction of
    soil moisture in the proposed

    work. The proposed algorithm makes eﬀective irrigation decisions with optimized
    usage of water in a more

    accurate and reliable manner. The eﬀective decision-making refers to the process
    of predicting the rainfall,

    thereby reducing the water usage in advance by the proposed algorithm in accordance
    with the predicted

    rainy days. Through this automatic decision-making, over watering is avoided by
    saving the soil. The

    server-side software is developed with node-side connectivity using the information
    for visualization and

    decision support features. This proposed algorithm is implemented in edge to prove
    the eﬃciency of the

    edge server handling the automated system better than the cloud control. The performance
    of the decen-

    tralized edge-based architecture has been evaluated for downloading the hybrid
    algorithm from cloud in

    real time execution. The performance can be enhanced by adopting edge computing
    architecture and

    measured with the help of network parameters like latency, bandwidth, and response
    time. Edge computing

    capacity is also estimated using the CPU processor and memory consumption while
    executing the proposed

    algorithm with irrigation scheduling.

    2 Related work

    In ref. [13], a smart irrigation system not aﬀected by communication disconnection
    and delay is developed

    using edge nodes deployed at the farms. Environmental parameters have an intricate
    impact on the plant

    growth. It becomes necessary for evaluating multiple AI models simultaneously
    in an actual cultivation

    environment for comparing AI models under the same conditions. Due to the working
    of existing irrigation

    systems on the cloud, communication is instable in the concurrent evaluation of
    AI models. However, the

    instability does not induce an edge node in its performance.

    The factors such as type of plant, soil, climate, humidity, temperature, and soil
    moisture need to be

    considered for the irrigation system packed with potential smart decisions. The
    nature and type of plant,

    soil, and climate are queried by ontology (branch of metaphysics dealing with
    the nature of being), whereas

    other factors such as temperature, humidity, and soil moisture are sensed by the
    sensor network. The

    trained ML model predicts the watering decisions based on ontology and other factors
    as mentioned earlier.

    Figure 1: Architecture of the proposed system.

    634

    

    S. Premkumar and AN. Sigappi

    Smart irrigation has three modules: (i) sensor network modules that sense the
    parameters impacting the water

    requirement by using sensors DHT22, light sensor BH1750, and HL-69 hygrometer
    for sensing the temperature,

    soil moisture, light, and humidity in air. (ii) Edge and IoT server’s module to
    send and receive data through

    HTTP requests. (iii) Training module in which KNN is applied on the sample dataset
    for training and decision-

    making regarding the water needs. Based on the input values, the trained model
    categorizes the input into ﬁve

    possible classes: highly not needed, not needed, average, needed, and highly needed
    [14].

    A decentralized smart irrigation approach is proposed for strawberry greenhouses
    in contrast to con-

    ventional cloud-based solutions for keeping the agricultural data at the edge
    of the network. A full-scale

    smart irrigation system in an actual strawberry greenhouse environment is developed
    after a small-scale

    smart irrigation networking prototype system and a reference architecture targeting
    edge data distribution

    for strawberry greenhouse applications are framed. A three-step industrial approach
    is formed for

    designing, implementing, and validating a solution for smart strawberry irrigation
    in greenhouses and

    keeping the corresponding data at the edge of the network at the same time: (i)
    A small-scale smart

    irrigation prototype solution with oﬀ-the-shelf hardware and software equipment
    is tested and evaluated

    on various types of plants for gaining useful insights for deployments on a large
    scale. (ii) A reference

    network architecture is designed for targeting smart irrigation and edge data
    distribution speciﬁcally for

    strawberry greenhouses. (iii) A large-scale system in an actual strawberry greenhouse
    environment is

    developed in Greece, incorporating the proposed reference architecture [15].

    Edge computing is proposed for addressing the issues by taking advantage of computing
    resources in

    the edge of the network. The issues such as an edge mobile device make it easier
    to achieve low end-to-end

    latency, high bandwidth, and low jitter to services located on the edge network.
    An edge can enforce the

    privacy policies of its owner prior to the release of the data to the cloud through
    edge analytics. If a cloud

    service becomes unavailable due to network failure, cloud failure, or a denial-of-service
    attack, a fallback

    service on a nearby edge can temporarily mask the failure. Cloud services, partial
    analysis, and control

    functions are extended to the edge nodes from the cloud data center. Edge nodes
    facilitate the timely

    monitoring of sensors in smart farming by the reduced latency and enhanced data
    transmission. Due to

    these factors, edge computing is applied through farming [16,17]. A three-tier
    open-source software plat-

    form we proposed by authors, and the platform enhanced the precision agriculture
    by introducing edge

    computing and fog computing. An network functions virtualization (NFV)-based approach
    is deployed for

    performing the local operational decisions at the edge level for mitigating the
    inﬂuence of network failures

    while using cloud data centers [18]. For control processing in smart farming,
    a platform enabling cost-

    eﬀective sensor/actuator network based on IoT, utilizes edge computing [19,20].

    The authors in ref. [21] predicted the soil moisture using a mathematical model
    that measures the

    values given by a sensor matrix on the ground. Due to the huge interval in measurements
    (10 minutes), the

    model presented estimated error by more than 10%. This methodology has incorporated
    the online

    approach by making the sensors to send data every minute to edge devices without
    time-based interruption.

    The authors of ref. [22] applied a combinative approach of using ﬁeld sensor network’s
    data along with

    weather forecast station’s data for the management of optimality in water conditions
    for the enhanced

    growth of grapes. The generated data are forwarded to a web server, which displays
    graphics without

    statistical analysis of such data. The analysis must be performed a posteriori
    by the user.

    The watering mechanism for a plant via IoT methodology is devised by the proposed
    smart irrigation

    model without acquiring any pre-processed data. A prototype application is developed,
    which gets adapted

    to the parameters needed in irrigation after a couple of human-made irrigations.
    With the usage of various

    ML algorithms, several tests are devised for manual and automated irrigations
    for the performance evalua-

    tion. After the evaluation using four diﬀerent ML algorithms such as logistic
    regression (LR), K-nearest

    neighbors (KNN), Gaussian naive Bayes (GNB), and gradient boosting regression
    trees (GBRT), it is found

    that GBRT outperforms other algorithms. To analyze the overall performance, a
    test bed for the sensor edge,

    mobile client, and the decision service on the cloud is established. Two diﬀerent
    indoor species are selected

    as test items for the prototype, namely, Peace lily and Sardinia. The outcomes
    were quite good, and it is

    inferred that the prototype has learned the patterns of irrigation and making
    decisions automatically with a

    high rate of accuracy [23].

    IoT-enabled edge computing model for smart irrigation system

    

    635

    The authors from ref. [24] adopted the deep learning methodology for detecting
    the type and the

    category of the plant using an automated plant irrigation system. The water necessity
    of the plant is

    determined using the recognition of predeﬁned set of plant images and data set
    acquired from farm. It

    utilizes the database for fetching the irrigation information after the recognition
    process is completed.

    Modeling the training processes are time consuming as voluminous set of images
    needs to be stored.

    The authors in refs [25,26] incorporated ML methods in the irrigation decision
    support model using a

    pre-processed irrigation data set. A model is developed for learning the irrigation
    needs of any plants

    progressively rather than using a readily available dataset. Several ML algorithms
    are evaluated with their

    precision for concluding the irrigation decisions. Manual irrigations are performed
    two times before making

    precise decisions. Due to the dynamicity in model, data processing is done progressively,
    and it can be

    applied to several plants having varying irrigation conditions. There is a need
    for the learning model that

    can be trained by itself using a comparatively lighter learning process using
    environmental parameters that

    do not need larger storage in the system but need higher computation. From the
    aforementioned survey for

    making a precise decision with instant computation locally, edge computing needs
    to be integrated into the

    irrigation system. This article is directed towards presenting a platform that
    implies IoTs and edge com-

    puting in monitoring soil moisture via sensors, data communication between sensors
    and edge devices, and

    an Analytics-as-a-Service cloud. It analyzes the collected data in the form of
    a density map of soil moisture

    for denoting the areas in need of greater or lesser frequency of irrigation. Here,
    density map does not refer to

    the geographical point data by satellite mapping, and it actually denotes the
    point of dry area and watery

    area through soil moisture detection point. This point is averaged among areas
    of irrigation to be done and

    the irrigation process is controlled with prediction of rainfall using the proposed
    system.

    3 The proposed system

    The proposed learning model for irrigation is implemented in a prototype IoT system
    that has four compo-

    nents: (i) Edge node layer – This layer consists of sensors, actuator, and two
    microcontrollers. In this layer,

    edge node acquires the sensor data from the surroundings and controls the actuator
    for actuating water

    pumps to start irrigation. (ii) Edge server layer – This layer consists of Raspberry
    Pi that act as edge server

    and capable of multitask processing. Here, edge server controls the edge nodes
    for sending signal and

    receiving data at regular interval of time. It is also connected to the cloud
    server for receiving developed and

    trained machine learning model to be deployed and make irrigation decision for
    controlling edge nodes.

    (iii) Edge service layer – This layer is deployed in the edge server and it is
    responsible for controlling the

    whole system through a developed web dashboard. The dashboard has live feed data,
    control of edge

    nodes, and cloud services access. This service layer also has the control access
    of the proposed machine

    learning model. (iv) Cloud server layer – This layer composed of cloud services
    and cloud storage where its

    role is to train the machine learning model and store the data in database. It
    sends the trained proposed

    model to the edge server for decision-making regarding irrigation scheduling.
    The comprehensive inter-

    connections in the system are shown in Figure 2. The proposed IoT-based smart
    irrigation system includes

    ﬁve major components: ﬁeld deployed module, Web-based interface, Web API weather
    input, soil moisture

    prediction mechanism, and edge communication model.

    3.1 Field deployed module

    In the ﬁeld requirements, a wireless sensor network of the sensor nodes needs
    to be deployed as shown in

    Figure 3. Here, ﬁeld data collection device accommodates four diﬀerent sensors:
    Capacitive Soil Moisture

    Sensor V2.0, DS18B20 Water Proof Temperature Sensor Probe for soil temperature,
    ultraviolet (UV) Light

    Radiation, DHT11 – Temperature and Humidity Sensor Module, and GYML8511 Analog
    Output Ultra-Violet

    636

    

    S. Premkumar and AN. Sigappi

    Light Sensor Module. An Arduino Mega connected to Raspberry Pi 4 Model-B read,
    the output of these

    sensors where the program is developed in Python for the Pi model to fetch the
    hourly data from sensors

    and store the data in MongoDB [27] database. It is then synchronized with the
    server database using the

    developed web service. A Wi-Fi-enabled Arduino controls the water pump connected
    to a relay switch.

    Figure 2: Components of the proposed system.

    Figure 3: Real-time prototype of the proposed edge model.

    IoT-enabled edge computing model for smart irrigation system

    

    637

    For the real time monitoring, a trigger is made for controlling the web service
    from the responsive web-

    based interface. The irrigation decisions are checked periodically by the proposed
    model performed in the

    server. The water pump is actuated, and irrigation process is started only if
    the server makes any irrigation

    decision. A wireless sensor network (WSN) [28] scenario with ZigBee [29] technology
    can be implemented

    for a large farming area in which several sensor nodes can be aﬃxed in the speciﬁed
    area and every sensor

    node possesses sensors similar to a standalone device. Then, the Arduino Mega
    reads the sensor output

    connected to ZigBee for transferring data to Gateway Node for aggregating the
    received data and storing it

    in MongoDB locally and also for transferring the data via web service to the edge
    server.

    3.2 Web-based interface

    The proposed framework consists of a web-based application to allow farmers visualize
    the growing data

    and interacting with the garden in real time. In addition, users can also be able
    to examine and analyze the

    historical growing data, if needed, through functionalities such as irrigation
    control, motor control predic-

    tion model deployment, and manual data entry implemented in this web application.
    Here, Node.js was

    chosen for developing the web application [30,31], while MongoDB [27] was utilized
    as the database system.

    Data stored in the database, which is deployed in the cloud, will be used for
    further data analysis in the

    future. The web application’s functions are designed following a software design
    pattern called model-

    view-controller (MVC) as shown in Figure 4. In the frontend, ChartJS is used to
    represent data through

    dynamic charts. The web application is also used as an interface to manage all
    the physical devices/

    actuators in the garden. To deploy the web-server to the cloud, a cloud platform
    as a service (PaaS), namely,

    Heroku, had been utilized. Heroku is a cloud platform that provides platform as
    a service (PaaS), facilitates

    the creation of applications and deploying these online rapidly [32,33]. It also
    enhances scalability and

    functionality by integrating several add-on services. The ﬁeld data are sent to
    the server by Raspberry Pi

    using this web service. This web service manages the network outage/ﬂuctuation
    during data synchroniza-

    tion from the ﬁeld device to the server by taking the help of ﬂag settings at
    the database level. The interface

    facilitates the scheduling of irrigation along with visualizing real time sensors
    and predicted soil moisture

    for upcoming days and precipitation information. By using the denoted threshold
    value of soil moisture

    suggested by agronomists, the irrigation can be scheduled by the user. The system
    maintains the threshold

    value depending on the predicted pattern of soil moisture and precipitation information.
    The process of

    irrigation is initiated automatically and stopped after the speciﬁed threshold
    value generated from the

    proposed algorithm of soil moisture when it is reached.

    Figure 4: Web interface for the irrigation system.

    638

    

    S. Premkumar and AN. Sigappi

    3.3 Web API weather input

    The weather prediction data are collected by a web service developed in Python.
    The forecast data such as

    humidity, temperature, ultra violet index, precipitation, and cloudiness of web
    forecasting portals like

    Open Weather API are aggregated by the developed web service [34]. These portals
    provide the forecasted

    information in HTML, XML, or JSON format. The predicted data with JSON format
    are read by the developed

    web and stored in database at the edge server, which is concerned in the prediction
    algorithm. Also, these

    data are utilized as testing dataset in the ML model for predicting the soil moisture.

    3.4 Soil moisture prediction mechanism

    An algorithm for predicting the soil moisture based on data derived from ﬁeld
    sensors and weather fore-

    casting using the combination of supervised and unsupervised machine learning
    techniques has been

    developed underpinned by regression algorithms and k-means clustering for estimating
    the diﬀerence/

    change in soil moisture owing to weather conditions. Many regression algorithms
    are compared against

    each other and infusing each of them with k-means to check the preciseness in
    mean square error (MSE),

    R2, accuracy and mean absolute percentage error (MAPE) for prediction of soil
    moisture of upcoming days

    with the help of sensor data and weather forecasting days. The information about
    soil moisture for the

    upcoming days and suggestions for irrigation in accordance with the prescribed
    levels of soil moisture and

    predicted precipitation values, thereby saving energy and water, is presented
    by the algorithm. The infor-

    mation generated from the device and the predicted values from the algorithm soil
    moisture prediction

    hybrid algorithm (SMPHA) are stored in the server.

    3.5 Edge communication model

    The communication protocols in the proposed framework are ﬂexible and transparent
    in nature for

    accepting both wired and wireless methodologies. For the maximum utilization of
    potentiality in edge

    computing components, the communication among various components in the edge-IoT
    system requires

    intense probing by using the versatility among the devices in network edges. For
    transferring the data

    gathered from pivot sensors, a communication technology such as Zigbee [35] is
    needed for the irrigation

    systems. Therefore, the communication component in the proposed work is classiﬁed
    into three main areas

    as shown in Figure 5. The Message Query Telemetry Transport (MQTT) protocol is
    used for the

    Figure 5: Proposed edge communication model.

    IoT-enabled edge computing model for smart irrigation system

    

    639

    communication in the proposed system. The analysis in ref. [36] presented seven
    IoT messaging protocols

    (MQTT, CoAP, XMPP, AMQP, DDS, REST-HTTP, and WebSocket) as communication protocols
    that play a

    major role in smart farming. The authors have concluded that MQTT proved to be
    the most secure protocol

    after probing all the protocols with respect to latency, energy and bandwidth
    requirements, throughput,

    reliability, and security. Moreover, MQTT is secure in both end-to-end architecture
    and gateway server

    architecture. In an MQTT setup, a MQTT server termed as MQTT broker executes on
    the IoT solution [37].

    Under a common identiﬁer, a “publisher” and a “subscriber” link among themselves
    to this broker. In the

    IoT solution, publishers and subscribers are the IoT devices and IoT hubs or control
    devices, respectively.

    When the publishers have new data for recording, the data are published to the
    broker. The broker then

    ﬂags that it has new publisher data, and the corresponding data are read by the
    subscriber. Then, the

    subscriber analyzes the data and reacts accordingly.

    The ﬁrst level accomplishes with connecting the end users to system with the help
    of mobile or web-

    based applications through the Internet. The next level (cloud computing server)
    deals with the connection

    of web server and MQTT broker for directing the user requests and other components
    at the edge landscape

    or from the farms to the right cloud-based services like displaying the real time
    status of the farm for the

    users, triggering a new deployment of the updated ML model to the corresponding
    edge node. The third

    level (farming area) is directed toward the deployment of sensors and IoT devices
    (actuators) for commu-

    nicating with other components in the entire system.

    4 Deployment of soil moisture prediction hybrid algorithm

    The watering mechanism of the plant has diﬀerent approaches in the proposed model.
    Primarily, the system

    is trained with manual irrigations datasets during the process of learning with
    respect to suggestions

    deﬁned by agronomists. The model is trained to learn the needs of irrigation in
    the ﬁrst level of deployment

    in cloud without the inclusion of pre-processed data. After acquiring the required
    data and training, the

    proposed system is initiated to grasp the plant’s watering needs by undergoing
    plenty of manual irrigations.

    Thereafter, manual irrigation is not required and the system makes automated decisions
    in watering using

    the gathered data and the application of ML methods. The proposed model then decides
    the irrigation

    strategies automatically using ML methods without the need including collected
    datasets in the automatic

    irrigation process. The proposed model can be improved through the learning process
    when the number of

    precise irrigation inputs is provided to the model at each stage of training.

    The decision-making procedure is developed with two modules for irrigation strategies
    according to the

    soil moisture prediction for upcoming days. The ﬁrst module deals with training
    the model in cloud with

    manual irrigation datasets through steps such as data collection, data preprocessing,
    training, and model

    development. The system acquires values of air temperature (TH), soil temperature
    (SMT), soil moisture

    (SM), humidity (HU), and ultraviolet rays (UV) periodically from the physical
    environment in the data

    collection stage, which is essentially required for arriving at the watering decisions.
    Also, the time of

    performing the manual irrigation is recorded in the database. These data are timestamped
    and stored in

    as datasets to aid in making decisions for knowing the time of irrigation. In
    the next step of pre-processing,

    inconsistencies are eliminated and outliers caused by sensor errors are detected
    from the irrigation dataset,

    thereby helping in the removal of broken data. The training stage involves the
    application of supervised

    machine learning (ML) algorithms. Here the regression algorithms such as support
    vector regression (SVR),

    multiple linear regression (MLR), lasso regression (LR), decision tree regressor
    (DTR), random forest

    regressor (RF), and XG-boost regressor (XB) techniques are used for the deployment.
    The regression algo-

    rithms are trained using the collected datasets. Finally, through training, regression
    models are created,

    namely, SVR model, MLR model, LR model, DTR model, RF model, and XB model that
    are been combined

    with the second module for decision-making.

    The second module caters to the prediction of irrigation for upcoming days by
    infusing the weather data

    as an input to the regression trained models. The live datasets from the weather
    API for future prediction of

    640

    

    S. Premkumar and AN. Sigappi

    soil moisture variable are used. The dependent variables from weather forecast
    data like temperature (TH),

    humidity (HU), ultraviolet (UV), and precipitation (PC) are tested in the aforementioned
    model for soil

    moisture prediction. Then, the regression trained model is evaluated and deployed
    using the weather

    testing data for the prediction of soil moisture in accordance with the precipitation.
    After the prediction

    of data for the upcoming days, these developed regression models are combined
    with unsupervised ML

    algorithm named k-means clustering for estimating the changes incurred in soil
    moisture prediction due to

    the impact of weather conditions. Further, each regression models with k-means
    algorithm are evaluated

    for performances in terms of irrigation decision-making process as shown in Table
    1. The combined algo-

    rithms are estimated through MAPE, MSE, R2, execution speed, power consumption,
    and accuracy. The

    estimation and computation of these parameters are detailed by the authors in
    ref. [38].

    XGBoost + k-means (XB+k-means) approach provides more accuracy with less MSE comparatively
    and

    also the R2 with 98% in soil moisture prediction using combined approach is given
    in Table 1. It is evident

    that the proposed combination performs better when compared to other regression
    + k-means-based

    approaches. XB + k-means-based hybrid machine learning algorithm is applied in
    irrigation planning

    module on account of aforementioned performance metrices of ML. Although it performs
    moderately in

    terms of execution time and power usage, it is selected for the deployment in
    edge computing as it has

    better performed in terms of accuracy, R2, MSE, and MAPE metrices. It is observed
    that the prediction of soil

    moisture for the upcoming days from the proposed algorithm (XB+k-means) is nearer
    to the actual value as

    shown in Table 2, and hence, XB+k-means is selected for the implementation of
    SMPHA in edge-based

    irrigation scheduling.

    4.1 Hardware setup

    IoT system is crucial to handle, collect, and transfer the data to the computing
    nodes at the edge or in the

    cloud. These devices are connected to the edge nodes through wireless communication
    protocols like

    ZigBee. It is used in reducing the latency and loss of data. An Arduino micro-control
    unit controls the

    combined IoT sensors and actuators at the same part of a ﬁeld into a cluster,
    each connected to a Raspberry

    Table 2: Comparison of predicted SM value with actual SM value

    Date

    Average SM value

    from sensor

    Average predicted SM

    value (XB+k-means)

    28-09-2021

    35.23

    34.04

    29-09-2021

    36.41

    37.20

    30-09-2021

    31.57

    30.46

    01-10-2021

    34.66

    33.15

    02-10-2021

    36.73

    37.12

    03-10-2021

    32.88

    33.01

    Table 1: Comparison of performance metrices obtained from various ML algorithms

    Algorithms used

    Accuracy

    R2

    MSE

    MAPE (%)

    Execution time

    Power (J)

    SVR + k-means

    0.96

    0.96

    0.25

    1.98

    0.06078

    1164.85

    MLR + k-means

    0.94

    0.88

    0.31

    2.15

    0.02075

    429.30

    LR + k-means

    0.95

    0.94

    0.32

    2.23

    0.02482

    351.35

    DTR + k-means

    0.93

    0.95

    0.29

    1.62

    0.15687

    914.70

    RF + k-means

    0.95

    0.91

    0.27

    1.57

    0.16745

    1475.13

    XB + k-means

    0.97

    0.98

    0.20

    1.08

    0.03547

    537.87

    IoT-enabled edge computing model for smart irrigation system

    

    641

    Pi that acts as an edge node in processing the gathered data and controlling the
    actuators. For example,

    Figure 2 shows an edge architecture with a Raspberry Pi connected to two components:
    Arduino Uno and

    Arduino Mega units via ZigBee connection. The ﬁrst Arduino Mega node is responsible
    for collecting data

    from sensors and the second one is for controlling the actuators in the ﬁeld.
    Depending on the sensor type

    with collecting Arduino unit, the sensors are connected via analog or digital
    PWM pins while controlling

    Arduino uno joins with actuators in the ﬁeld and controls (turn on/oﬀ) them in
    accordance with upper

    layers (from the edge web server). The trained (cloud) and deployed ML model in
    edge nodes provides the

    necessary instructions to the edge nodes.

    4.2 Web layer setup

    The deployment of web server assists the user in planning and managing the irrigation
    system. It visualizes

    the crucial information of factors like temperature of air and soil, UV, humidity,
    and soil moisture in live

    irrigation with real time updates in the form of various charts. In accordance
    with the selected ﬁeld, the web

    application redirects the user to the ﬁeld’s dashboard as shown in Figure 4. The
    dashboard consists of ﬁeld

    parameters as well as control signals for activating all the physical devices/actuators
    at the garden layer.

    These signals are denoted as switch buttons, and each switch controls (turn on/oﬀ)
    a particular kind of

    actuator (for instance, water pump to start and stop the irrigation). The user
    interface facilitates remote

    controlling of the ﬁeld by just clicking on the buttons as shown in Figure 4.

    4.3 Edge layer setup

    The edge node acts as a computing center where incoming data are analyzed and
    fed as the input vector to

    the ML model for processing and to return the control signals for activating or
    deactivating the actuators

    placed at the farm. Edge node processes the physical data (real time) at every
    end device such as the

    collected and processed data via the Raspberry Pi nodes presented in the proposed
    scheme. The prediction

    model is designed using TensorFlow API and trained, tested on Google Colab in
    this work. Amazon Web

    Service (AWS) oﬀers a library named Boto3 having many APIs to upload and download
    objects. After the

    development of model, it is transferred to Amazon S3, a service provided by AWS.
    The edge node utilizes the

    trained model from S3 for analyzing the sensed data acquired from garden’s sensors.
    The decision is

    delivered based on real time data analysis at the edge node and transmitted to
    Arduino nodes in the ﬁelds

    landscape immediately for controlling the actuators. In another ﬂow, the data
    collected from sensors are

    ﬁltered so as to keep only the modiﬁed data at the edge node before being sent
    back for mitigating the

    communication cost to the database in the cloud. These data are used in the updation
    of the ML model to

    enhance its eﬃciency.

    4.4 Analytics setup

    The main goal of this experiment lies in gathering the various physical parameters
    of a farming land via

    sensors and utilizing the fetched data along with weather forecast information
    for developing an algorithm

    using hybrid machine learning approach to infuse higher accuracy in predicting
    the soil moisture for the

    upcoming days. As discussed in Section 4, for the proper planning and provisioning
    of optimal irrigation,

    the algorithm provides a predictable estimate of soil moisture with the assistance
    of various statistical

    measures as shown in Table 1. The measures are adopted for estimating the appropriateness
    and error rate

    of the proposed algorithm. It is inferred from the experiment that, optimal irrigation
    is feasible using a good

    642

    

    S. Premkumar and AN. Sigappi

    estimation (close to the actual value) of the soil moisture (Table 2), with the
    support of ﬁeld data and

    forecast information, thereby utilizing the natural rain eﬃciently.

    The SMPHA ML model is interdependent on dynamic changes in weather environment
    where the

    models deployed on edge nodes need to change the controls accordingly after model
    gets trained con-

    tinuously. For the process of retraining, the trained model needs to be updated.
    The parameters such as TM,

    HU, ST, UV, SM about grown plants are logged for the training purpose, and these
    generated datasets are

    recorded from the already developed manual mode system [39]. The growth of the
    Indian Mundu Chilli [40]

    is taken for the observation from the ﬁrst stage to the last grown stage for 95
    days. While retraining the

    model, the training is carried in cloud without causing eﬀect to the functionalities
    at edge nodes. A signal is

    transferred to the corresponding edge server for triggering the task of updating
    the SMPHA model from the

    web server. At that time, the newly trained model is downloaded to replace the
    existing one at the con-

    sidering edge server. From then, the ML model at the edge server is called to
    be updated with the real-world

    knowledge and is ready for its garden controlling tasks (to apply in the next
    farming season).

    4.5 Work ﬂow

    The ﬂowchart in Figure 6 depicts the working of the proposed system based on the
    decision support system

    that is beneﬁcial for irrigation needed for the growth of vegetables. The chilli
    plant is grown in a growbag

    attached with sensors and Pi as shown in Figure 3 and monitored for 95 days of
    data collection. To bring out

    optimality in the irrigation system, features relating to climate, soil, crop,
    and ﬁeld infrastructure are to be

    considered. To provide several recommendations in the production of vegetables,
    decision support systems

    (DSSs) are designed, which process voluminous information [39]. This proposed
    work is the extension of

    soil moisture diﬀerences (SMD) model [41] developed for soil moisture prediction.
    The threshold values of

    soil moisture are used in the SMD model where the system schedules the irrigation
    date based on the

    predicted soil moisture and weather forecast (precipitation) information automatically
    using SVR+ k-means

    modeling. Therefore, in the extension of the aforementioned work, further more
    number of sensors are used

    to log soil moisture value, which is averaged in the proposed model. This model
    is developed in two

    divisions of ﬂowchart as shown in Figure 7, where both are interconnected. It
    is observed that the prediction

    of XB + k-mean approach provides better results as presented in Table 2.

    The ﬁrst phase of the ﬂowchart describes the hybrid algorithm for the soil moisture
    prediction (SMPHA)

    using the combination of XB + k-means algorithm. During the data collection step,
    the sensor data for the

    parameters, namely, TM, HU, ST, UV, and SM, are collected. During preprocessing,
    null values and outliers

    are removed and the preprocessed data are used to train the XG-Boost model. The
    developed model is then

    trained with variables of live weather features (TM, HU, UV, PC) obtained from
    Weather API for the

    prediction of SM data. These data are given as input to k-means clustering algorithm
    to predict the soil

    moisture, which is deﬁned as SMPHA value to be infused in the next phase of the
    ﬂowchart. The second

    phase of the ﬂowchart deﬁnes the automatic irrigation planning setup. The setup
    starts obtaining the soil

    moisture maximum (SMMax) and soil moisture minimum (SMMin) values in the dashboard
    for setting the

    maximum and minimum level of soil moisture. Then, the current soil moisture (CuSM)
    is sensed and

    compared against the threshold SMMin. If the resulting value is less than SMMin,
    the process proceeds

    with SMPHA. On the contrary, it stops the irrigation process by sending 0 to the
    relay. In SMPHA, the

    nearest precipitation date is selected and it is assigned to the predicted soil
    moisture (PSM). The SMMax is

    decided by ﬁnding the minimum of (PSM + SMMin, SMMax), and the predicted SMMax
    is further checked

    against CuSM with a condition if SMMax is greater the CuSM then it sends 1 to
    the relay as a signal to start

    irrigation. If the condition fails, then it sends 0 to stop irrigation. The process
    of automatic irrigation ends

    by forecasting the irrigation schedule in accordance with the live weather parameters.

    IoT-enabled edge computing model for smart irrigation system

    

    643

    5 Experimental setup and evaluation

    The test bed is developed and deployed, and the data are collected for the analysis
    in irrigation manage-

    ment. Here, Heroku cloud platform is used to deploy the cloud web server. The
    same cloud is also installed

    at a local edge that is at two Raspberry Pi units equipped with Wi-Fi 802.11n
    connections to denote the edge

    nodes. JMeter application is used to get sequential accesses to the web page from
    various users for eval-

    uating the network parameters. The speciﬁcation of these servers is given in Tables
    3 and 4.

    We evaluated the performance of the proposed IoT-based smart farm on two diﬀerent
    platforms,

    namely, in the cloud and on the local computer to show the feasibility and the
    beneﬁt of the edge com-

    puting scheme. Further many parameters are considered for evaluation and discussed
    in the next section to

    show that edge deployment is better than cloud.

    Figure 6: Flow chart of the proposed edge model.

    644

    

    S. Premkumar and AN. Sigappi

    5.1 Evaluation

    A hybrid machine learning methodology is used in evaluating the ﬁrst stage of
    the proposed model. The

    predicted value of the soil moisture is better in terms of their accuracy and
    error rate. From the comparison

    of the other ML algorithms as shown in Table 2, XB + k-means performs better and
    taken further to be

    deployed in edge and cloud to check its eﬃciency with each other. Therefore, for
    analyzing the eﬃciency of

    the edge server in accordance with the proposed hybrid algorithm SMPHA is evaluated
    in terms of the time

    taken to train the ML model in edge and cloud. In this experiment Raspberry Pi
    is used to train the SMPHA

    model with 196,400 rows, that is, input data sample size and takes around 1,710,000
    ms (approximately

    28.5 min). The same model when it is trained in Google Colab cloud environment,
    it takes 204,000 ms

    (approximately 3.4 min) as depicted in Table 5. The main purpose is to run the
    trained model on edge not to

    train the model at edge. So due to the lack of computing capability at the edge,
    it takes more time to train

    the model, but it can be ignored as it does not aﬀect the purpose of the proposed
    model. Here, edge is

    introduced to obtain the task of computing from the cloud (i.e., oﬄoading the
    task) by making the system

    more edge-oriented deployment. It can be accomplished rapidly as it requires only
    14 s to download a

    trained SMPHA model from the cloud to the edge node with a size of 3,101 kb as
    given in Table 5. The time to

    Figure 7: Average response time with 10 test scenarios.

    Table 3: Conﬁguration of raspberry Pi

    CPU

    Broadcom BCM2711, Quad core Cortex-A72 (ARM v8) 64-bit SoC @ 1.5 GHz

    RAM

    8 GB LPDDR4-3200 SDRAM

    Network

    2.4 GHz and 5.0 GHz IEEE 802.11ac wireless, Bluetooth 5.0, BLE, Gigabit Ethernet

    Pinboard

    8 GB LPDDR4-3200 SDRAM

    Operating system, language

    Raspbian , Python 3

    Table 4: Conﬁguration of Heroku cloud

    Country

    United states

    Service

    Amazon web service S3

    Processor

    2.4 GHz Intel Xeon E5-2676 v3 Processor

    CPU Power

    8 GB

    Virtual CPUs

    3–5

    IoT-enabled edge computing model for smart irrigation system

    

    645

    download varies according to the size of the trained model. So, from this process
    it can be inferred that

    downloading the trained model saves time when compared to training the model at
    the edge. Through this

    in real time, deployment of the trained SMPHA model in edge is better compared
    to deployment in cloud

    services. Furthermore, network parameters like latency, throughput, bandwidth,
    and response time are

    adopted to measure the performance improvements in edge computing.

    The performance metrices taken into account are latency, bandwidth, and response
    time [42]. The

    latency of an application is the product of two factors: computing latency and
    transmission latency. The

    time spent on data processing and transmission between end devices to cloud servers
    is termed as com-

    puting latency and transmission latency, respectively. The computational capacity
    of the system decides

    the computing latency as the network servers possess a considerable amount of
    capacity to make the data

    processing faster, whereas the sensors come with limited computing capacity. The
    latency in transmission

    is increased by the end devices and cloud servers. Bandwidth: As large number
    of sensors are deployed in

    IoT, data generated would be huge that consumes an intense range of bandwidth
    and leads to several

    problems such as delay in transmission and loss of packets. It becomes unacceptable
    for the data to be

    transferred directly to cloud servers without applying compression. Therefore,
    data preprocessing and

    aggregation are needed for IoT gateways before redirecting them to remote cloud
    servers. Then, the issue

    to be confronted is to control the traﬃc ﬂow by migrating data processing and
    aggregation tasks optimally

    to decrease the bandwidth needs of the end users while maintaining the data quality.
    Response time: The

    total response time is calculated by adding up transmission and processing time.
    The local deployment of

    the proposed model for controlling IoT-based irrigation are deployed on two modes:
    (i) Cloud mode: The

    developed SMPHA model is implemented in the cloud communicating with IoT sensors
    nodes directly to

    manage the irrigation process. The data are stored and processed at the cloud
    server itself where it uses

    Heroku platform. (ii) Edge mode – Raspberry Pi is deployed as an edge server that
    involves in processing of

    the SMPHA model controlling the IoT sensor nodes. Here, the data are stored and
    processed locally within

    the edge servers. This SMPHA model from both the edge and cloud does the job of
    controlling the actuators

    to initiate and quit the working of water ﬂow motors. Through this deployment
    in both the environments,

    performance of edge server and cloud server can be checked in terms of latency,
    throughput, bandwidth,

    and response time is shown in aforementioned graphs in Figures 6, 8, and 9. This
    performance metrices is

    not feasible to calculate while deploying in real time, so the aforementioned
    scenarios of two modes are

    virtually created by generating many request and response threads between the
    servers. This sampling,

    load test, and distributed testing are conducted through JMeter application [43]
    and also veriﬁed with

    Wireshark [44] in cloud servers. The test scenario is created here by data of
    sending and receiving sampling

    data between cloud to IoT sensors and between Edge to IoT sensors. The sampling
    data considered in this

    work refer to the approximate number of requests generated by Arduino to cloud
    and Arduino to Raspberry

    Pi that are calculated in real time. The test scenario is divided into 10 days
    of sampling data collected for

    each day. The evaluation results are depicted for latency and response times in
    10 days perspective. In

    latency parameter, edge service has decreased by an average of 77.85% time compared
    to the with cloud. In

    the same manner, the response time of edge service is also decreased by 74.09%
    time compared to cloud

    service. In throughput calculation, sampling data are calculated for an hourly
    basis for the 10 hours data in

    a day. From the hourly comparisons of throughput value, edge outperforms with
    67.17% high Mbps usage.

    Through this analysis as shown in Table 6, it is evident that the proposed edge
    computing methodology

    deployed in Raspberry Pi or in local computers outperforms the cloud-oriented
    approach.

    Table 5: Comparison of model training time

    Edge

    Cloud

    Model training time

    28.4 min

    3.4 min

    Downloading time

    Not applicable

    14 s

    646

    

    S. Premkumar and AN. Sigappi

    Finally, to illustrate the eﬃciency of resource management in edge computing,
    CPU and memory

    utilization are considered for the analysis as both factors rely on the service
    execution model and the

    computational needs of the services being ﬁred from oﬀ-loaders. Figure 10 depicts
    the utilization of CPU

    and RAM on the Raspberry Pi acting as an edge node in two cases: with and without
    the deployment of

    SMPHA model on it. As shown in Figure 10, the SMPHA model aﬀects the CPU of the
    Raspberry Pi node

    signiﬁcantly as it consumed around 41.2% of the CPU compared to only 3.5% when
    it does not host the

    Figure 8: Average latency with 10 test scenarios.

    Figure 9: Average throughput value with 10 h test scenarios.

    Table 6: Performance metrices for cloud and edge services

    Performance metrices

    Cloud service

    Edge service

    Throughput (Mbps)

    0.04944

    0.08265

    Latency (ms)

    1415.8

    313.6

    Response time (ms)

    1519.6

    393.8

    Bandwidth (bps)

    86

    1,365

    IoT-enabled edge computing model for smart irrigation system

    

    647

    SMPHA model. However, the memory (RAM) utilization in both the cases (with and
    without deployment of

    an SMPHA model) is nearly the same which is around 31%. Comparatively RAM utilization
    does not have

    much diﬀerence in with and without SMPHA. It is worthwhile to note that, the CPU
    utilization is still much

    lower than the 50% of total CPU capacity in Raspberry Pi. Therefore, it becomes
    feasible for adopting edge

    server implementation in the proposed irrigation system.

    6 Conclusion

    This article proposed a novel approach to edge-based irrigation system to facilitate
    decision-making on

    watering the plants on scheduled time. The proposed approach applying IoT with
    an edge computing

    framework enables the farming system to adapt to the changes in environmental
    conditions automatically

    and eﬃciently. The process of automatic irrigation regulates irrigation according
    to the live weather para-

    meters for forecasting the irrigation process. Soil moisture prediction was performed
    using major regression

    algorithms that are again combined with k-means clustering for estimating the
    changes incurred in soil

    moisture prediction. These techniques were compared through metrics such as MAPE,
    MSE, speed, and

    power consumption from which XB + k-means was found to perform better. The XB
    + k-means algorithm

    was further used for the implementation of decision mechanism on the developed
    edge computing model.

    The proposed edge model saves the data communication cost and reduces the response
    time of IoT services.

    It can be deployed on existing devices on the network edges serving as edge nodes,
    thereby reducing the

    overall implementation cost of a large-scale IoT system. The edge-based approach
    was found to perform

    better than the cloud-based approach in terms of response time, latency, throughput,
    and bandwidth

    usage. Finally, the edge model was analyzed through CPU and memory usage while
    running with and

    without the algorithm. In both cases, the memory utilization is almost lower to
    total available resource of

    the edge device. From this, edge device can allocate its remaining resource for
    other computing services,

    which increases the eﬃciency of edge computing device. The number of end edge
    nodes can be increased

    according to the ﬁeld area and then to check the potency of the system.

    Conﬂict of interest: The authors declare no conﬂict of interest.

    Data availability statement: All data that support the ﬁndings of this study are
    included within the article.

    Figure 10: CPU and memory utilization with and without SMPHA.

    648

    

    S. Premkumar and AN. Sigappi

    References

    [1]

    India: Issues and Priorities for Agriculture, The World Bank, May 17, 2012. https://www.worldbank.org/en/news/feature/

    2012/05/17/india-agriculture-issues-priorities.

    [2]

    India at a glance in Agriculture, FAO in India. https://www.fao.org/india/fao-in-india/india-at-a-glance/en/.

    [3]

    Cavicchioli R, Ripple WJ, Timmis KN, Azam F, Bakken LR, Baylis M, et al. Scientists’
    warning to humanity: Microorganisms

    and climate change. Nature Rev Microbiol. 2019;17(9):569–86. doi: 10.1038/s41579-019-0222-5.

    [4]

    Huong NTL, Bo YS, Fahad S. Economic impact of climate change on agriculture using
    Ricardian approach: A case of

    Northwest Vietnam. J Saudi Society Agricult Sci. 2019;18(4):449–457. doi: 10.1016/j.jssas.2018.02.006.

    [5]

    Fagodiya RK, Pathak H, Bhatia A, Jain N, Kumar A, Malyan SK. Global warming impacts
    of nitrogen use in agriculture: An

    assessment for India since 1960. Carbon Management. 2020;11(3):291–301. doi: 10.1080/17583004.2020.1752061.

    [6]

    Sarkar S, Chatterjee S, Misra S. Assessment of the suitability of fog computing
    in the context of internet of things. IEEE

    Trans Cloud Comput. 2018;6(1):46–59. doi: 10.1109/TCC.2015.2485206.

    [7]

    Porter JR, Xie L, Challinor AJ, Cochrane K, Howden SM, Iqbal MM, et al. Food security
    and food production systems. In: Field

    CB, Barros VR, Dokken DJ, Mach KJ, Mastrandrea MD, Bilir TE, et al., editors.
    Climate Change 2014: Impacts, Adaptation,

    and Vulnerability. Part A: Global and Sectoral Aspects. Contribution of Working
    Group II to the Fifth Assessment Report of

    the Intergovernmental Panel on Climate Change Cambridge, United Kingdom: Cambridge
    University Press and New York,

    NY, USA; 2014. p. 485–533.

    [8]

    Lal R. Adaptation and mitigation of climate change by improving agriculture in
    India. In: S. SherazMahdi (Ed.), Climate

    Change and Agriculture in India: Impact and Adaptation. Cham: Springer International
    Publishing; 2019. p. 217–27.

    [9]

    Saravanan K, Julie G, Robinson H. (Eds.), Handbook of research on implementation
    and deployment of IoT projects in

    smart cities. Hershey: IGI global, 2019.

    [10] Baylis A. Advances in precision farming technologies for crop protection.
    Outlooks Pest Manag. 2017;28(4):158–61.

    [11]

    Mulla D, Khosla R. Historical evolution and recent advances in precision farming.
    Soil-Speciﬁc Farming Precision

    Agriculture. Boca Raton: CRC Press; 2015.

    [12] Dutta L, and Basu TK. Extraction and optimization of leaves images of mango
    tree and classiﬁcation using ANN. IJRAET

    2013;1(3):46–51.

    [13] Kawai T, Mineno H. Evaluation environment using edge computing for artiﬁcial
    intelligence-based irrigation system. 2020

    16th International Conference on Mobility, Sensing and Networking (MSN). Tokyo,
    Japan: IEEE; 2020. p. 214–9.

    [14] Munir MS, Bajwa IS, Ashraf A, Anwar W, Rashid R. Intelligent and smart irrigation
    system using edge computing and IoT.

    Complexity. 2021;2021:1–16.

    [15] Angelopoulos CM, Filios G, Nikoletseas S, Raptis TP. Keeping data at the
    edge of smart irrigation networks: A case study in

    strawberry greenhouses. Comput Netw. 2020;167:107039.

    [16] Satyanarayanan M. The emergence of edge computing. Computer. 2017;50(1):30–9.

    [17] Shi W, Dustdar S. The promise of edge computing. Computer. 2016;49(5):78–81.

    [18] Ramirez Izolan PL, Diniz Rossi F, Hohemberger R, Konzen MP, da Cunha Rodrigues
    G, Saquette LR, et al. Low-cost fog

    computing platform for soil moisture management. In: 2020 International Conference
    on Information Networking (ICOIN).

    Barcelona, Spain: IEEE; 2020. p. 499–504.

    [19] Ferrandez-Pastor F, Garcia-Chamizo, J, Nieto-Hidalgo, M, Mora-Pascual, J,
    Mora-Martínez, J. Developing ubiquitous sensor

    network platform using internet of things: application in precision agriculture.
    Sensors. 2016;16(7):1141.

    [20] Xu X, Liu X, Xu Z, Dai F, Zhang X, Qi L. Trust-oriented IoT service placement
    for smart cities in edge computing. IEEE Internet

    Things J. 2020;7(5):4084–91.

    [21] Wu X, Liu M. In-situ soil moisture sensing: Measurement scheduling and estimation
    using compressive sensing. In: 2012

    ACM/IEEE 11th International Conference on Information Processing in Sensor Networks
    (IPSN). Beijing, China: IEEE; 2012.

    p. 1–11.

    [22] Kameoka T, Nishioka K, Motonaga Y, Kimura Y, Hashimoto A, Watanabe N. Smart
    sensing in a Vineyard for advanced

    viticultural management. In: Proceedings of the 2014 International Workshop on
    Web Intelligence and Smart Sensing.

    Saint Etienne France; 2014. p. 1–4.

    [23] Cagri Serdaroglu K, Onel C, Baydere S. IoT-based smart plant irrigation system
    with enhanced learning. In: 2020 IEEE

    Computing, Communications and IoT Applications (ComComAp.) Beijing, China: IEEE;
    2020. p. 1–6.

    [24] Kwok J, Sun Y. A smart IoT-based irrigation system with automated plant recognition
    using deep learning. In: Proceedings

    of the 10th International Conference on Computer Modeling and Simulation - ICCMS2018.
    Sydney, Australia: ACM Press;

    2018. p. 87–91.

    [25] Goldstein A, Fink L, Meitin A, Bohadana S, Lutenberg O, Ravid G. Applying
    machine learning on sensor data for irrigation

    recommendations: Revealing the agronomist’s tacit knowledge. Precision Agricult.
    2018;19(3):421–44.

    [26] Vij A, Vijendra S, Jain A, Bajaj S, Bassi A, Sharma A. IoT and machine learning
    approaches for automation of farm irrigation

    system. Proc Comput Sci. 2020;167:1250–7.

    [27] Krishnan H, Scholar R. MongoDB – a comparison with NoSQL databases. Int J
    Scientiﬁc Eng Res. 2016;7(5):1035–7.

    IoT-enabled edge computing model for smart irrigation system

    

    649

    [28] Ojha T, Misra S, Raghuwanshi NS. Wireless sensor networks for agriculture:
    The state-of-the-art in practice and future

    challenges. Comput Electr Agricult. 2015;118:66–84.

    [29] Gutierrez J, Villa-Medina JF, Nieto-Garibay A, Porta-Gandara MA. Automated
    irrigation system using a wireless sensor

    network and GPRS module. IEEE Trans Instrument Measurement. 2014;63(1):166–76.

    [30] Chanthakit S, Keeratiwintakorn P, Rattanapoka C. An IoT system design with
    real time stream processing and data ﬂow

    integration. In: 2019 Research, Invention, and Innovation Congress (RI2C.) Bangkok,
    Thailand: IEEE; 2019. p. 1–5.

    [31] Lv H, Wang S. Design and application of IoT microservices based on Seneca.
    USA: DEStech Transactions on Computer

    Science and Engineering, (icte.). 2016.

    [32] Lee B-H, Dewi EK, Wajdi MF. Data security in cloud computing using AES under
    HEROKU cloud. In: 2018 27th Wireless and

    Optical Communication Conference (WOCC). Hualien: IEEE; 2018. p. 1–5.

    [33] Lopez Pena MA, Munoz Fernandez I. SAT-IoT: An architectural model for a high-performance
    fog/edge/cloud IoT platform.

    In: 2019 IEEE 5th world forum on internet of things (WF-IoT.) Limerick, Ireland:
    IEEE; 2019. p. 633–8.

    [34] Weather API. Retrieved from https://openweathermap.org/api.

    [35] Drew Gislason. Zigbee wireless networking, 1st ed. Newnes, London: Elsevier
    Publisher; 2008.

    [36] Tanabe K, Tanabe Y, Hagiya M. Model-based testing for MQTT applications.
    In: Virvou M, Nakagawa H, Jain LC. (Eds.),

    Knowledge-Based Software Engineering: 2020. Cham: Springer International Publishing;
    2020. p. 47–59.

    [37] Babun L, Denney K, Celik ZB, McDaniel P, Uluagac AS. A survey on IoT platforms:
    Communication, security, and privacy

    perspectives. Comput Netw. 2021;192:108040.

    [38] Rastogi K, Lohani D. Edge computing-based internet of things framework for
    indoor occupancy estimation. Int J Ambient

    Comput Intell. 2020;11(4):16–37.

    [39] Premkumar S, Sigappi AN. Functional framework for edge-based agricultural
    system. In: AI, Edge and IoT-based Smart

    Agriculture, 1st ed. USA: Academic Press, Elsevier; 2021. p. 71–100.

    [40] Phani Kumar J, Paramaguru P, Arumugam T, Manikanda Boopathi N, Venkatesan
    K. Genetic divergence among Ramnad

    mundu chilli (Capsicum annuum L.) genotypes for yield and quality. Electr J Plant
    Breeding. 2021;12(1):228–34.

    [41] Goap A, Sharma D, Shukla AK, Rama Krishna C. An IoT-based smart irrigation
    management system using Machine learning

    and open source technologies. Comput Electronic Agricult. 2018;155:41–9.

    [42] Aslanpour MS, Gill SS, Toosi AN. Performance evaluation metrics for cloud,
    fog and edge computing: A review, taxonomy,

    benchmarks and standards for future research. Internet Things. 2020;12:100273.

    [43] Sunardi A, Suharjito MVC architecture: a comparative study between Laravel
    framework and slim framework in freelancer

    project monitoring system web based. Proc Comput Sci. 2019;157:134–41.

    [44] Robert Shimonski. The wireshark ﬁeld guide, 1st ed. New York: Syngress Press,
    Elsevier; 2013.

    650

    

    S. Premkumar and AN. Sigappi

    '
  inline_citation: '>'
  journal: Journal of intelligent systems
  limitations: '>'
  pdf_link: https://www.degruyter.com/document/doi/10.1515/jisys-2022-0046/pdf
  publication_year: 2022
  relevance_score1: 0
  relevance_score2: 0
  title: IoT-enabled edge computing model for smart irrigation system
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.14569/ijacsa.2023.01407107
  analysis: '>'
  authors:
  - Md. Mamun Hossain
  - Md. Ashiqur Rahman
  - Sudipto Chaki
  - Humayra Ahmed
  - Ahsanul Haque
  - Iffat Tamanna
  - Silvio Felipe Barbosa Lima
  - Most. Jannatul Ferdous
  - Mohammad Shaifur Rahman
  citation_count: 1
  full_citation: '>'
  full_text: ">\n(IJACSA) International Journal of Advanced Computer Science and Applications,\n\
    Vol. 14, No. 7, 2023\nSmart-Agri: A Smart Agricultural Management with\nIoT-ML-Blockchain\
    \ Integrated Framework\nMd. Mamun Hossain, Md. Ashiqur Rahman, Sudipto Chaki,\
    \ Humayra Ahmed, Ahsanul Haque,\nIffat Tamanna, Sweety Lima, Most. Jannatul Ferdous,\
    \ Md. Saifur Rahman\nDepartment of Computer Science and Engineering,\nBangladesh\
    \ University of Business and Technology, Dhaka, Bangladesh\nAbstract—This paper\
    \ presents intuitive directions for field\nresearch by introducing a ground-breaking\
    \ IoT-ML-driven in-\ntelligent farm management platform. This study’s main goal\n\
    is to address agricultural difficulties by providing a thorough,\nintegrated solution.\
    \ This work makes a variety of important\ncontributions. By utilizing cutting-edge\
    \ technology like IoT and\nMachine Learning (ML), it first improves conventional\
    \ farm\nmanagement procedures. Farmers now have the capacity to\nremotely monitor\
    \ and regulate irrigation management thanks to\nsensor-based real-time data. Second,\
    \ based on data gathered from\nagricultural fields, our machine learning model\
    \ offers improved\nwater control management and fertilizer use recommendations,\n\
    maximizing production while minimizing resource usage. The\nsuggested solution\
    \ also uses blockchain technology to create a\nsafe, decentralized network that\
    \ guarantees data integrity and\ndefends against threats. We also introduce energy\
    \ harvesting\ntechnology to address the issue of continuous energy supply for\n\
    IoT devices, which lessens the load on farmers by removing the\nrequirement for\
    \ additional batteries. We achieved 89.5% accuracy\nin our proposed machine learning\
    \ model. The suggested model\nwould provide a variety of services to farmers,\
    \ including pesticide\nrecommendations and water motor control via mobile applications\n\
    and a cloud database.\nKeywords—Smart agriculture; machine learning; internet\
    \ of\nthings; energy harvesting; blockchain technology\nI.\nINTRODUCTION\nWithout\
    \ a doubt, agriculture is the most important source of\nlivelihood in Bangladesh.\
    \ As the world’s population expands,\nincreased agricultural output is essential.\
    \ The amount of\nfresh water and appropriate fertilizer used in irrigation must\n\
    be raised in order to maintain enhanced farm productivity.\nUnintentional water\
    \ waste happens when water consumption\nis not planned. Choosing the right fertilizer\
    \ for a particular\nfarmland is likewise a difficult challenge for our farmers.\n\
    This demonstrates the urgent need for alternatives to reduce\nwater waste and\
    \ appropriate fertilizer choices without placing\nfarmers under stress. In the\
    \ Electronic age, agriculture is rapidly\nbecoming a data-intensive sector, with\
    \ farmers collecting and\nanalyzing massive amounts of data from various sources\
    \ (e.g.,\nsensors, farming machinery, etc.) to obtain vital information\nand become\
    \ more efficient in production. Technology nowadays\nhas advanced a lot. With\
    \ the help of Machine Learning and\nIoT devices, a drastic change can be made\
    \ possible in the\nagricultural industry [1].\nWith the release of open-source\
    \ Arduino devices and the\navailability of different sensors, it is now possible\
    \ to build\ndevices that can monitor soil moisture content and irrigate\nfields\
    \ or landscapes as needed. Machine learning algorithms\nare used to assess various\
    \ agricultural data and may readily\nforecast which decisions should be made to\
    \ improve farmland\nproductivity. In comparison to their previous farming ways,\n\
    the farmer may easily combine ML and IoT into their farming\nand create an automated\
    \ system that is more time effective\nand less risky. Here, Fig. 1 depicts the\
    \ difference between the\ntraditional system with the ML-based agricultural framework.\n\
    Wireless Sensor Networks(WSNs) technologies have a\nmajor challenge with limited\
    \ energy. Many research in WSNs\nhas also been focused on reliable energy supply\
    \ to extend\nthe survival time of limited power sources in a network [2].\nEnergy\
    \ harvesting techniques are used to overcome the energy-\nscarcity problem of\
    \ WSNs. Energy harvesting is a process in\nwhich energy is obtained from the environment\
    \ as renewable\nenergy sources like solar radiation, Radio Frequency (RF),\nwind,\
    \ geothermal, electromagnetic (EM) waves, hydro, etc.,\nand is stored effectively\
    \ for driving various applications systems\nwhich may include wireless sensor\
    \ networks (WSNs) [3] [4].\nTherefore, it can be used to operate the devices of\
    \ the embedded\nsystem for a reliable energy supply.\nSecurity is one of the most\
    \ critical aspects of IoT, as it\ndeals with the protection of data and devices\
    \ from unauthorized\naccess, use, disclosure, disruption, modification, or destruction\n\
    [5]. Encryption mechanisms are mostly used to ensure that\ndata is securely transmitted.\
    \ But, regularly used encryption\nalgorithms such as DES, AES, and RSA will be\
    \ heavy for small-\nscale embedded systems. Therefore, blockchain technology can\n\
    be used as a lightweight calculation technique to reliably operate\nand secure\
    \ an IoT system[6] [7].\nThis paper presents the latest IoT-ML-driven intelligent\
    \ agri-\ncultural management and provides a substantial new research\ndirection.\
    \ The central insight of this work is to offer possible\nsolutions to farming\
    \ hazards while providing a combined\nframework. Some significant contributions\
    \ of this paper are\noutlined as follows:\n•\nSmart Management: Traditional agricultural\
    \ manage-\nment is strengthened with edge-cutting technologies\n(i.e., IoT and\
    \ Machine Learning).\n•\nDistant Monitoring and Controlling: Farmers can\nmonitor\
    \ and control irrigation management from a\ndistance in terms of sensor-based\
    \ real-time data.\n•\nIntelligent Decision Making: Our machine learning\nmodel\
    \ provides substantial water control management\nwww.ijacsa.thesai.org\n985 |\
    \ P a g e\n(IJACSA) International Journal of Advanced Computer Science and Applications,\n\
    Vol. 14, No. 7, 2023\nFig. 1. Architectural differences between traditional agricultural\
    \ management\nwith IoT-ML-Blockchain based agricultural framework.\nand fertilizer\
    \ utilization direction for a minimum\nresource with a maximum throughput based\
    \ on the\ndata collected from the farming field.\n•\nBlock chain Based Security\
    \ System: Our proposed\nsolution uses blockchain technology to create a secure\n\
    and decentralized network that can ensure data integrity\nand protect data from\
    \ denial of service (DDoS) attacks,\nand man-in-the-middle (MITM) attacks.\n•\n\
    Energy Harvesting: To ensure a continuous energy\nsupply for the IoT system, we\
    \ have introduced energy\nharvesting technology which reduces the hassle for the\n\
    farmers of using extra batteries.\nThe rest of the paper is organized as follows:\
    \ Section II\nprovides an overview of existing works related to our proposed\n\
    framework. Section III provides a detailed description of the\nhardware that have\
    \ used in this research. Section IV discusses\nthe proposed IoT-ML-based smart\
    \ agricultural framework.\nSection V discusses the blockchain-based security of\
    \ our system.\nSection VI presents the real-life implementation of our project.\n\
    Next, Section VII illustrates and analyzes the experimental\nresult from our machine\
    \ learning models. Section VIII future\nresearch directions in this field of research.\
    \ Finally, Section IX\ngives a brief conclusion.\nII.\nRELATED RESEARCH\nSeveral\
    \ ML-IoT-based researches and project works on\nagriculture systems have been\
    \ carried out till today.\nIn [8], For remote sensing and smart agriculture, Ullo\
    \ et al.\npresented a review of research on the developments in smart\nsensors\
    \ and IoT. They put forth some suggestions for IoT\nadvancements that will support\
    \ researchers and agriculturalists\nin their work.\nIn [9], Samuel et al. analyzed\
    \ numerous techniques for crop\nselection, crop sowing, weed detection, and system\
    \ monitoring.\nThey have recommended different image processing methods\nfor weed\
    \ and leaf detection and evaluated the benefits and\ndrawbacks of each. Drone\
    \ implementation has been considered\nfor real-time monitoring and seed planting.\
    \ However, no actual\nimplementation is shown in this research; they have only\n\
    reviewed several smart agricultural strategies.\nIn [10], they analyze soil moisture\
    \ levels and apply auto\nirrigation to the crops. In order to eliminate the need\
    \ for human\ninvolvement, this system also senses temperature, humidity, and\n\
    the presence of impediments in the targeted region. These data\nare accessible\
    \ to the user via mobile from the cloud. By giving\nthe motor driver the command\
    \ YES/NO based on this data, the\nuser can control the operation of the motor.\n\
    In [11], they use a cloud-based architecture and the Internet\nof Things to examine\
    \ a smart irrigation system. This system\nis designed to measure soil moisture\
    \ and humidity and then\nprocess this data in the cloud using a variety of machine-\n\
    learning techniques. Farmers receive accurate information\nregarding water content\
    \ regulations. If farmers apply smart\nirrigation, they can reduce their water\
    \ usage.\nIn [12], they use IoT and machine learning to predict\nlate blight disease\
    \ in potatoes and tomatoes prior to the first\noccurrence. This will send farmers\
    \ a warning message on the\nprecise time to apply the protective pesticides.\n\
    In [13], for yield prediction, they present a hybrid ML\nmodel using IoT. They\
    \ use a two-tier ML approach named\naKNCN and ELM-mBOA.In the first tire, they\
    \ estimate soil\nquality and in the second tier, they predict the crop yield.\n\
    In agriculture, supply, and demand have always been crucial\nissues for sustainable\
    \ production management. To address\nand provide a possible solution to this problem,\
    \ M. Lee et\nal. proposed an IoT-based controlled agricultural production\nmanagement\
    \ [14]. The authors developed a decision support\nsystem to predict specific criteria\
    \ based on IoT-enabled sensor\ndata.\nA cloud-based real-time data analysis model\
    \ is proposed\nin [15] instead of dew-point humidity. In this regard, they\ndesigned\
    \ a CMM index measurement model to evaluate the\ncrops’ comfort level of relative\
    \ humidity levels.\nTo increase the crop production rate, real-time data analysis\n\
    based on an artificial model is proposed by Y. Zhou et al. in [16].\nThe current\
    \ innovation trend expects farmers to use IoT and\ntechnology to identify the\
    \ organization of those difficulties they\nface, such as water management deficiencies\
    \ in agriculture\nand productivity concerns. This research has attempted to\n\
    build dazzling agricultural cultivation patterns utilizing IoT\ntechnologies.\
    \ IoT has significantly improved agriculture by\nanalyzing various agricultural\
    \ difficulties and issues.\nAn IOT-based intelligent technology for agriculture\
    \ that can\nsense soils and environmental factors was proposed by Abhijith\nH.\
    \ V. et al. in [17]. In order to identify the urgent needs for\noptimal crop growth,\
    \ they applied data mining techniques to\nthe sensed data.\nAbraham et al. [18]\
    \ create a proof-of-concept farm surveil-\nlance system that employs IoT and deep\
    \ learning to identify\nwww.ijacsa.thesai.org\n986 | P a g e\n(IJACSA) International\
    \ Journal of Advanced Computer Science and Applications,\nVol. 14, No. 7, 2023\n\
    farm encroachment.\nThe purpose of the study Wongpatikaseree et al. [19], is\n\
    to propose a traceability system, summarizing and presenting\nobserved data from\
    \ the smart farm.\nFor smart farming, Deden Ardiansyah et al. [20] suggested\n\
    a WSN Server that can handle and optimize agricultural data.\nThey instantly store\
    \ the data in the database, which is afterward\nrepresented as a website and accessible\
    \ through the Internet\nnetwork.\nAutomation in agriculture is a basic need for\
    \ remote\ncontrol-based agricultural management to ensure sustainable\ndevelopment\
    \ in this field of research. In this regard, L.\nVijayaraja et al. proposed an\
    \ IoT-based monitoring system\nusing wireless communication networks in [21].\
    \ The power\nsupply management used in this framework is entirely from the\nrenewable\
    \ energy source that provides a cost-effective model\nfor sensor-based decision\
    \ management in intelligent farming.\nIn [22], Yaw-Wen Kuo, et al. presented a\
    \ Long-range IoT\nsystem where they developed four types of IoT units based on\n\
    Long-range technology. They employed pH, ORP, and EC in\nType A and water, air,\
    \ and humidity sensors in Type B. In type\nC, the pump can be operated remotely,\
    \ and in type D, a water\nflow or water meter-controlling system is provided.\n\
    They presented a cloud service-based architecture in [23]\nthat includes a variety\
    \ of services for farmers, including agri-\nfood-related services, financing,\
    \ fostering, warehouse manage-\nment, etc. They have suggested interactive video\
    \ conferencing,\nvoice-based services, text messaging, web portal services, and\n\
    more under the heading of cloud services.\nA key component of practicing smart\
    \ agriculture is precision\nagriculture. In this context, Patil et al. [24] suggested\
    \ a system\nthat measures soil moisture using sensors for temperature,\nhumidity,\
    \ and soil moisture. Additionally, they offered various\nmethods for highlighting\
    \ the issue of data loss.\nIn [25], Quasim et al. use blockchain techniques in\
    \ smart\nhealthcare systems to ensure the security of healthcare data.\nIt provides\
    \ the security, privacy, and efficiency of the data in\ntransmission between wearable\
    \ sensors and Internet of Things\n(IoT) devices.\nIn [26], Makhdoom et al. made\
    \ a blockchain-based frame-\nwork for privacy-preserving and secure data sharing\
    \ in smart\ncities. The system secures data sharing by segmenting the\nblockchain\
    \ network into different channels, where each channel\nconsists of a limited number\
    \ of authorized organizations and\nhandles a particular type of data, such as\
    \ financial information,\nhealth data, smart car data, or data related to smart\
    \ energy.\nAdditionally, smart contracts contain access control rules that\nregulate\
    \ who has access to the data of users within a channel.\nMany different types\
    \ of intelligent agricultural systems were\ndeveloped in the earlier work. Some\
    \ of these current systems\nare tabulated in Table I.\nIII.\nSYSTEM HARDWARE\n\
    To set up the IoT environment for a smart agricultural\nsystem, we have selected\
    \ a variety of hardware components,\nincluding the ESP8266 Node MCU (Fig. 2) processing\
    \ unit\nand several sensors, including capacitive soil moisture (Fig. 3),\nPH\
    \ sensor (Fig. 4), MH-RD Rain Sensor (Fig. 5), and LDR\nSensor (Fig. 6). Our IoT\
    \ system is powered by DC-DC power\nconverter (Fig. 9), solar energy harvesting\
    \ components (Fig.\n10), single-channel relay modules (Fig. 7), DC motors (Fig.\
    \ 8),\netc.\nA. Node MCU ESP8266\nFig. 2. Node MCU module.\nFeatures1:\n•\nOperating\
    \ Voltage: 3.3V\n•\nInput Voltage: 7-12V\n•\nDigital I/O Pins (DIO): 16\n•\nClock\
    \ Speed: 80 MHz\n•\nSmall size module\nB. Capacitive Soil Moister Sensor v1.0\n\
    Fig. 3. Soil moisture sensor.\nFeatures2:\n•\nOperating Voltage: DC 3.3-5.5V\n\
    •\nOutput Voltage: DC 0-3.0V\n•\nDigital I/O Pins (DIO): 16\n•\nAnalog output\n\
    •\nSupports 3-Pin Sensor interface\nC. PH Sensor(SEN-00239)\nFeatures3:\n•\nSupply\
    \ voltage: 5V\n•\nCurrent: 5-10 mA\n•\nConsumption: ≤ 0.5 W\n•\nWorking temperature:\
    \ 10-50◦C\nwww.ijacsa.thesai.org\n987 | P a g e\n(IJACSA) International Journal\
    \ of Advanced Computer Science and Applications,\nVol. 14, No. 7, 2023\nTABLE\
    \ I. PREVIOUS RESEARCH WORKS IN TERMS OF OBJECTIVES, USED TOOLS, AND POSSIBLE\
    \ RESEARCH GAPS\nReference\nResearch Purpose\nUsed Technologies/Techniques\nFocused\
    \ Methods\nChallenges/Research Gaps\n[11]\nIoT-Cloud based automated Ir-\nrigation\n\
    Raspberry Pi, central cloud storage, soil\ndata set, machine learning techniques,\n\
    and mobile applications\nFocused to measure soil moisture and\nhumidity and then\
    \ process this data in\nthe cloud using a variety of machine\nlearning techniques\n\
    Farmers get information about water\nonly, no other necessary information.\n[12]\n\
    IoT-based agriculture monitor-\ning system for predictive anal-\nysis\nAir temperature\
    \ sensor, air humidity\nsensor, and soil moisture sensor, Micro-\ncontroller Unit\
    \ (NodeMCU), MQTT pro-\ntocol, R-Pi 3 microcontroller, MYSQL\nFocused to predict\
    \ the late blight disease\nin potatoes and tomatoes before the first\noccurrence\n\
    Not fully automated, need human inter-\nference to apply the action\n[14]\nIoT-based\
    \ agricultural produc-\ntion System\nDual CDMA protocol, pH sensor, water\nsensor,\
    \ and temperature sensor\nFocus on reliable agricultural production\nmanagement\n\
    Absence of dynamic data analysis model\n[15]\nIoT-Cloud based agricultural\nmonitoring\
    \ system\nArduino UNO, temperature and humidity\nsensors, Arduino Ethernet shield\
    \ and\nThingSpeak cloud platform\nFinding the index of thermal control\nfunctions\
    \ to find the comfort levels of\nagricultural parameters\nSensor data processing\
    \ time is slower\nin terms of CMM-MIST measurement\nalgorithm.\n[16]\nMachine\
    \ Learning based agri-\ncultural management\nThreat Model (TM), Deep Crop Map-\n\
    ping Model (DCMM), Random Forest\nRegression Algorithm (RFRA)\nAn intelligent\
    \ management to predict\nsoil moisture content based on the ML\narchitecture\n\
    The key challenge of this research is real-\ntime data processing\n[17]\nIntelligent\
    \ technology for IOT-\nbased agriculture\nPH sensor, temperature, rainfall, humid-\n\
    ity sensor, Predictive classification algo-\nrithm, MatLab\nFocused on the identification\
    \ of urgent\nneeds for optimal crop growth\nPrediction of specific need isn’t\
    \ gained\nproperly\n[18]\nComprehensive farm monitor-\ning system\nArduino Board,\
    \ Node MCU, Sensors,\nmobile App, machine learning, deep\nlearning\nCentered on\
    \ a surveillance system pro-\ntotype and an app-based remote admin-\nistration\
    \ solution\nRemotely monitoring but not fully auto-\nmated controlling\n[19]\n\
    IoT-based Smart farming\nSensors, mobile technology, Wi-Fi, cloud\ncomputing\n\
    Can measure soil temperature, soil\nmoister, humidity, pH and EC values\nHuman\
    \ interaction, water wastage\n[20]\nWater management based on\nIoT\nSoil moisture,\
    \ Wi-Fi segments\nReal-time data monitoring for soil mois-\nture and remote data\
    \ access\nLow or excessive irrigation, and water\nwaste\n[21]\nIoT-based cost-effective\
    \ agri-\ncultural management\nMoisture and Water sensors, Node MCU,\nSolar panel\
    \ and LCD display unit\nFocused on the low-cost parameter while\nensuring a sustainable\
    \ energy efficient\nmanagement\nThe key research gap of this work is\nthat this\
    \ model is applicable for small\nfarming areas.\n[22]\nIoT platform has a long\
    \ range\nfor controlling pumps and\nmonitoring agriculture\nLP WAN, Base station,\
    \ Ph sensor, Elec-\ntrical Conductivity sensor, Water Tem-\nperature Sensor, GY39\n\
    Presented a complete IoT system includ-\ning the design of a remote unit and server\n\
    construction\nIt is required to conduct additional re-\nsearch on the pH sensor\
    \ because the data\nthat has been gathered is inaccurate and\ncollected from other\
    \ vendors.\n[23]\nCloud service architecture for\nagriculture using IoT and Big\n\
    Data\nDifferent Sensor, Central Cloud Database\nProposed a cloud-based architecture\
    \ for\nthe agricultural industry that comprised\na range of services, including\
    \ farm mon-\nitoring, market-oriented service, agri-\nbusiness monitoring, etc.\n\
    Not implemented just proposed an archi-\ntectural model.\n[24]\nAI in smart agriculture\
    \ appli-\ncations\nArduino UNO, Soil moisture sensor, Wi-\nFi module\nAimed to\
    \ use a single moisture sensor\nand make decisions, such as turning on or\noff\
    \ the pump, based on the data collected.\nDiscussing the disease of crop using\n\
    image analysis technique but no actual\nimplementation is shown.\nProposed\nSystem\n\
    Smart\nagricultural\nsystem\nbased\non\nan\nIoT-ML-\nBlockchain\nIntegrated\n\
    Framework\nIoT devices, Mobile Application, Ma-\nchine Learning, and Blockchain-based\n\
    security system\nFocused on intelligent decision making,\nDistant Controlling,\
    \ Energy Harvesting,\nand Security based smart agricultural\nmanagement system\n\
    Future target to ensure Low latency net-\nwork and high bandwidth transmission,\n\
    easy deployment of Networks elements\nand Edge computing technology.\nFig. 4.\
    \ PH Sensor with module.\nFig. 5. MH RD rain sensor.\nD. MH-RD Rain Sensor\nFeatures4:\n\
    •\nWorking voltage: 5V\n•\nOutput format: Digital switching output (0 and 1)\n\
    •\nWith bolt holes for easy installation\n•\nUses a wide voltage LM393 comparator\n\
    E. LDR (Light Dependent Resistor)\nFeatures5:\n•\nAble to detect variable light\
    \ resistance (50-100 K\nOhms)\n1https : //components101.com/development − boards/nodemcu\
    \ −\nesp8266 − pinout − features − and − datasheet\n2https : //how2electronics.com/interface\
    \ − capacitive − soil −\nmoisturesensor − arduino/#Features038Specifications\n\
    3https\n:\n//www.techshopbd.com/detail/2576/PHSensorwith −\nModuletechshopbangladesh\n\
    4https : //components101.com/sensors/rain − drop − sensor −\nmodule#%20value\n\
    5https\n:\n//www.indiamart.com/proddetail/ldr − light −\ndependent − resistor\
    \ − 18812839691.html\nwww.ijacsa.thesai.org\n988 | P a g e\n(IJACSA) International\
    \ Journal of Advanced Computer Science and Applications,\nVol. 14, No. 7, 2023\n\
    Fig. 6. Light dependent resistor.\n•\nPhoto-resistor (photo-conductive cell)\n\
    •\nPower Level: 200 W\n•\nDiameter: 3-20 mm\nF. Single-Channel Relay Module\n\
    Fig. 7. Single-Channel relay module.\nFeatures6:\n•\nGround Voltage: 0 V\n•\n\
    VCC: Provide input to the relay coil\n•\nSupply Voltage: 3.75 to 6 V\n•\nCurrent:\
    \ 2 mA\n•\nRelay Maximum Current: 10 A\nG. DC Motor 6V\nFig. 8. DC motor.\nFeatures7:\n\
    •\nDiameter of the motor: 23.5mm\n•\nHeight: 30mm\n•\nStart voltage: 0.8V\n•\n\
    Rated voltage: 6V\n•\nNon-charging current: 25mA\n•\nSpeed: 2980 RPM\nFig. 9.\
    \ Adjustable DC-DC power converter.\nH. Adjustable DC-DC Power Converter (1.25V\
    \ - 35V-3A)\nFeatures8:\n•\nInput Voltage: 3.2V - 40VDC\n•\nOutput Voltage: 1.25V\
    \ - 35VDC\n•\nMax. Output Current: 3A\n•\nMax. Efficiency: 92\n•\nOutput Ripple:\
    \ ≤ 100mV\n•\nSwitching Frequency: 65KHz\n•\nOperating Temperature: -45°C to +85°C\n\
    •\nDimensions: 43mm*21mm*14mm(l*w*h)\nI.\nMSP430 Solar Energy Harvesting Tool\n\
    Fig. 10. MSP430 solar energy harvesting development tool texas instruments\nEZ430-RF2500-SEH.\n\
    Features9:\n•\nBattery-less operation\n•\nFunctions in dim ambient light and 400+\
    \ transmissions\n•\nAdaptable to any RF network or sensor input\n•\nInputs available\
    \ for external harvesters (thermal, piezo,\n2nd solar panel, etc.)\n•\nUSB debugging\
    \ and programming interface with ap-\nplication backchannel to PC\n•\n18 available\
    \ analog and communications input/output\npins\n•\nHighly integrated, ultra-low-power\
    \ MSP430 MCU with\n16-MHz performance\nwww.ijacsa.thesai.org\n989 | P a g e\n\
    (IJACSA) International Journal of Advanced Computer Science and Applications,\n\
    Vol. 14, No. 7, 2023\nFig. 11. Schematic pin configuration of our proposed framework.\n\
    IV.\nPROPOSED FRAMEWORK\nA. Circuit Diagram and Connections\nWe used Fritzing10,\
    \ an open-source hardware online appli-\ncation to make a schematic pin (Fig.\
    \ 11) diagram of our smart\nagriculture system.\nWe used ESP8266 NodeMCU V3, with\
    \ an integrated WIFI\nmodule as our processing hardware component. The system\n\
    connects an analog capacitive soil moisture sensor and an\nanalog pH sensor using\
    \ multiplexing to the A0 analog input\nof NodeMCU, a photo-resistor known as Light\
    \ Dependent\nResistors (LDR) sensor to a D3 digital input, and a raindrop\nsensor\
    \ with rain board and control module to D0 input Pin. In\naddition, the device\
    \ is connected with a D3 output pin to a DC\n5V micro submersible mini water pump\
    \ with the relay. We used\n6https : //components101.com/switches/5v − single −\
    \ channel −\nrelay − module − pinout − features − applications − working\n7https\n\
    :\n//techshopbd.com/detail/248/DCMotor6Vtechshop −\nbangladesh\n8https : //techshopbd.com/detail/2067/Adjustable\
    \ − DC − DC −\nPowerConverter\n9https\n:\n//www.radiolocman.com/op/device.html?di\n\
    =\n66638&/eZ430 − RF2500 − SEH\n10ıFritzing − circuitdesign, ȷhttps : //fritzing.org/\n\
    the NodeMCU’s 5V VU pin to power the Motor and Relay.\nHowever the LDR Sensor\
    \ and Rain Drop Sensor, only need\na 3.3V supply, the Capacitive Soil Moisture\
    \ Sensor and pH\nSensor need 5V. The GND pin serves as the common ground\nfor\
    \ every sensor. A solar panel system that is coupled to a\n9-volt battery backup\
    \ powers the system.\nB. Working Principle\nWe have divided our proposed framework\
    \ into different\nsubparts and each part’s working procedure is given below. The\n\
    overall working procedure is depicted in Fig. 12.\n1) Collecting Data From Sensor:\
    \ We used four different\ntypes of sensors, including capacitive soil moisture\
    \ sensors, pH\nsensors, MH-RD rain sensors, and LDR sensors, to execute\nsmart\
    \ IoT agriculture. We can estimate how much water is in\nthe soil with the aid\
    \ of a soil moisture sensor. A pH sensor,\nwhich ranges from 0 to 14, allows us\
    \ to determine the water’s\nacidity or alkalinity. Water turns acidic if the value\
    \ falls below\n7, else it is alkanoic. Consider levels 5.5 to 7 to be ideal for\n\
    growing crops. We can choose the best fertilizer for the soil\nwith the aid of\
    \ a pH sensor.\nBasically, a rain sensor is used to detect rain. A rain board\n\
    that can detect rain and a control module that can compare\nwww.ijacsa.thesai.org\n\
    990 | P a g e\n(IJACSA) International Journal of Advanced Computer Science and\
    \ Applications,\nVol. 14, No. 7, 2023\nData from \nmoisture, \nrain, \ndaylight\
    \ and \npH sensors\nFirebase Cloud \nDatabase\nDataset \nExtraction\nDataset \n\
    Preprocessing\nTrain ML \nModel\nML Predicted \nResult\nMonitor and \nControl\
    \ via \nMobile App\nPerform actions \nwhether on-off pump \nor apply suitable\
    \ \nfertilizers\nNode MCU Unit\nData from Node MCU to Firebase \nvia Blockchain\
    \ Network\nEnergy \nharvesting using \nsolar panel\nFig. 12. Proposed IoT-ML-Blockchain\
    \ framework for smart agricultural management.\nanalog and digital values are\
    \ both included. The raindrop sensor\naids in our selection of how to operate\
    \ the motor. The LDR\nsensor, which is used to detect the presence of light, has\
    \ also\nbeen employed.\nNow, each of these sensors is linked to a node MCU board\n\
    in our project, and data from the sensors is uploaded to the node\nMCU board and\
    \ shown on the serial monitor of the Arduino\nUNO editor and\n2) Sending Data\
    \ to Cloud Server: The node MCU board\nreceives all sensor data, which we would\
    \ love to save in the\ncloud in order to control for remote distance. We have\
    \ utilized\nFirebase as a cloud server. We linked the Firebase authentication\n\
    and real-time database URL that we built for our project with\nthe Arduino UNO\
    \ script in order to integrate Firebase with\nNode MCU.\nAll data is sent as a\
    \ parent-child combination to Firebase.\nAll of the sensor data is sent from the\
    \ node MCU as a child\nof Smart Irrigation, which we have constructed as Parent.\
    \ The\nFirebase stores the child value as a key-value pair.\n3) Data Collection:\
    \ The Firebase’s database contains all of\nthe sensor data, which is compiled\
    \ as a CSV file. Four columns\nmake up our dataset: pH, LDR, Rain, and Moisture.\
    \ Nearly\n820 data are in our dataset. Only integer values are accepted in\nthe\
    \ Moisture column here, whereas string values are accepted\nin the Rain and LDR\
    \ columns.\n4) Data Pre-processing: Data can be often inconsistent.\nMissing values\
    \ or values out of range is typical. So, the dataset\nneeds some pre-processing\
    \ before it can be used to train any\nmodel [27]. For this reason, we have considered\
    \ three such\ncases.\n•\nMissing Value Handling: While exploring our dataset,\n\
    we observed humidity, raining status, daylight status,\nand pH level fields with\
    \ missing values. Therefore, we\nhave filled them with average values of the respective\n\
    field.\n•\nOne Hot Decoder: Label encoding is simply the\nprocess of converting\
    \ each value in a column to a\nnumber. By using label encoding, we have converted\n\
    the categorical text data into model-understandable\nnumerical data. We had to\
    \ use the label encoding to\nget our dataset ready for our model.\n•\nAbnormal\
    \ Data Handling: Some data contain abnor-\nmal values. For example, the range\
    \ of the temperature\nin our dataset falls between -20 to 30 degrees Celsius.\n\
    However, we have even found some data above and\nbelow this range. Data tuples\
    \ with these abnormalities\nhave been dropped from the dataset.\n•\nNormalization:\
    \ Normalization is used to increase the\naccuracy of models [28]. It is simply\
    \ the process of\nhaving all the data on the same scale. We have used\nwww.ijacsa.thesai.org\n\
    991 | P a g e\n(IJACSA) International Journal of Advanced Computer Science and\
    \ Applications,\nVol. 14, No. 7, 2023\ntemperature, pressure, relative humidity,\
    \ and pressure\nas features to train our model. The features used\nto teach a\
    \ machine-learning algorithm have different\nranges of values. This can badly\
    \ affect the machine’s\nlearning ability. To solve this problem, we have\nstandardized\
    \ the feature values so that all the features\nstand equal in their representation.\
    \ By normalization,\nall the feature values are mapped in the range between\n\
    0 and 1.\n5) Machine Learning Model: The developed architecture is\na Neural Network\
    \ (NN) based because of its great accuracy. The\nfundamental advantage of NN over\
    \ classical machine learning\nmodels is that it recognizes significant traits\
    \ automatically\nand without human intervention. It’s a feed-forward NN with\n\
    parameters using the back-propagation algorithm and stochastic\ngradient descent.\
    \ Distinct processing layers serve different\npurposes. The output of the feature\
    \ map is produced by\nconventional layers, which conduct linear convolution between\n\
    a series of input tensors and filters. The nonlinear transformation\nis performed\
    \ using the ReLU, which is the most widely\nemployed activation function. The\
    \ activation function for the\nfully connected layer to the end must be careful\
    \ on the tasks.\nBatch normalization and an activation layer are performed after\n\
    each convolution.\nReLU = max(0, X)\n(1)\nd(x) = activation(wx + b)\n(2)\nDropout(x,\
    \ p) = (x : prob., p) (x : prob., 1 − p)\n(3)\nS(x) =\n1\n1 + e−x\n(4)\n6) Mobile\
    \ Application Development: A smart remote con-\ntrol application can ease our\
    \ maximum task [29]. We have used\nthe MIT app inventor to make the mobile application\
    \ that will\nbe connected to our system and by using this app we can do\nthe following\
    \ task\n•\nFertilizer Suggestion: By analyzing the pH value, the\napp may suggest\
    \ which fertilizer is best for a given\nsoil. The app will recommend some alkanoic\
    \ fertilizer\nif the pH value rises to help reduce the rising pH value\nand vice\
    \ versa. Algorithm 1 depicts how the fertilizer\nis suggested in our system.\n\
    •\nVisualization of Predicted Results: In order to predict\nwhether the motor\
    \ would turn off or not based on\nthe moisture, LDR, and raindrop sensor values,\
    \ we\nconstruct a neural network model and link it with\nour mobile app. Algorithm\
    \ 2 depicts how the remote\ncontrolling is done to control the motor in our system.\n\
    •\nRemote Motor Controlling: The farmer can use the\napp to control the motor\
    \ from any distant or remote\nAlgorithm 1: Decision Making for Fertilizer Sugges-\n\
    tion\n1. Initialize the pH sensor\n2. Read data from pH sensor\n3.if pH >= 6.5\
    \ && pH <= 7.5 then\nSoil is balanced.\nNo fertilizer is recommended.\n4.else\
    \ if pH < 6.5 then\nSoil is acidic.\nStore the pH amount.\nFind the level_id corresponding\
    \ pH amount.\nSearch through the fertilizer data(in JSON format)\nif level_id\
    \ == keyofJSONdata then\nSend the fertilizer name back to the user.\nelse\nThe\
    \ result doesn’t match our dataset.\nelse\nSoil is alkanoic\nStore the pH amount\n\
    Find the level_id corresponding pH amount\nSearch through the fertilizer data(in\
    \ JSON format)\nif level_id == keyofJSONdata then\nSend the fertilizer name back\
    \ to the user\nelse\nThe result doesn’t match our dataset\nAlgorithm 2: Decision\
    \ Making for Pump on/off\n1. Initialize the Moisture, Rain, and LDR sensors.\n\
    2. Read data from each sensor.\n3. Send the data to the server using an HTTP POST\n\
    request.\n4. Apply machine learning to the collected data.\n5. Retrieve the predicted\
    \ result(PUMP ON/OFF).\n6. Send Predicted results to the mobile phone.\n7. Wait\
    \ for user input from the mobile phone.\n8. if user_action = true then\nSend a\
    \ signal to the node MCU board.\nPerform action according to signal.\nelse\nWait\
    \ for 300 seconds\nTake an automated action according to the\npredicted result\
    \ (PUMP ON/OFF)\nlocation based on the prediction outcome. When the\nfarmer presses\
    \ the off button, it sends a value of 0 to\nthe firebase, which then passes this\
    \ signal on to the\nnode MCU via the wifi module and sets the pin value\nto the\
    \ LOW, so turning off the motor.\nV.\nBLOCKCHAIN-BASED SMART-AGRI\nBlockchain\
    \ was described as a data structure using asym-\nmetric encryption algorithms\
    \ and hash functions to ensure\nthat data tampering and forgery are impossible\
    \ [30] [31] [32].\nEvery smart system needs to be taken under the shelter of a\n\
    security system to avoid getting an external attack. Our smart\nagricultural system\
    \ is public so any intruder can make attacks\nsuch as DoS attacks to crash the\
    \ system, and spoofing to alter\nthe control. In the IoT environment where high\
    \ computational\nencryption, decryption, and high-level security are not possible.\n\
    www.ijacsa.thesai.org\n992 | P a g e\n(IJACSA) International Journal of Advanced\
    \ Computer Science and Applications,\nVol. 14, No. 7, 2023\nTherefore, We are\
    \ implanting blockchain technologies into our\nsmart agricultural system through\
    \ which we are capable to\nmaintain high throughput, low latency, low communication\n\
    cost, and tamper-proof and traceability. Blockchain refers to a\ndistributed ledger\
    \ system where data or transactions are stored\nin blocks that are connected to\
    \ each other through making\nhash which can not only serve as unique IDs but also\
    \ prove\nthe integrity of the blocks. The hash of the previous block is\nused\
    \ to make a hash for the next block along with its data.\nIf any intruder wants\
    \ to tamper or alter the block data, all\nthe consecutive block hash will be changed.\
    \ Therefore, any\nintruder attempts to alter the data or spoof the blockchain\
    \ will\nnot be possible.\nIn this system, we consider nodeMCU, Firebase cloud,\
    \ and\nmobile app as nodes. In order to avoid altering data in the\nnetwork, we\
    \ are using blockchain technology. When any node\nwants to send data to other\
    \ nodes, it encapsulates the data\ninto a block along with its hash values (SHA256)\
    \ and nodeID\nthen adds it to the blockchain. All these nodes will contain the\n\
    blockchain locally. After adding the block, the node sends it\nto the cloud through\
    \ the network. We are not using any PoW,\nPoS, or accountant selection algorithms\
    \ which is not possible\nbecause of a very small amount of nodes and our nodeMCU\n\
    has very limited capabilities to run these algorithms (Algorithm\n3). When the\
    \ block is sent to the cloud, I validate the block by\nchecking all the hashes\
    \ of the previous block along with the\nnodeID. If it gets any error, the node\
    \ will consider the block\nas from an attacker and reject the block from adding\
    \ to the\nchain. Fig. 13 depicts the blockchain in our system.\nFig. 13. Blockchain\
    \ in the system.\nVI.\nIMPLEMENTATION\nA. Hardware Implementation\nOur Smart-agri\
    \ system hardware demo showed in Fig. 14.\nB. Mobile App Implementation\nThe interface\
    \ of the mobile app that we developed in\nthe MIT App Inventor resembles (Fig.\
    \ 15). The “Fertilizer\nSuggestion\" button can be found in the app. Depending\
    \ on the\nAlgorithm 3: Blockchain-based data security in smart-\nagri\n1. Initialization\n\
    2. Read data\n3. Block_Hash ← SHA256 (Previous_hash, data,\nnodeId, timestamp,\
    \ nonce)\n4. Make a block (Block_hash, data, nonce, nodeID,\ntimestamp)\n5. Add\
    \ the block to the chain locally.\n6. Send the block to the cloud.\n7.if Block_hash\
    \ = Previous_Hash then\nAccept the block, then add it to the chain.\nSend acknowledgment.\n\
    Fig. 14. Hardware set-up of our proposed framework.\npH sensor measurement, this\
    \ button tells us whether the soil\nis alkanoic or acidic when we click it. We\
    \ used the decision\ntree algorithm to determine the ideal fertilizer for a given\
    \ soil\nbased on its quality.\nThe farmer can view the data from the moisture,\
    \ raindrop,\nand daylight sensors in our app. Our program uses a neural\nnetwork\
    \ model that we built and implemented to forecast\nwhether the motor would be\
    \ on or off. We can operate our\nmotor using the two buttons in our app labeled\
    \ “ON\" and\n“OFF\". The motor status in the firebase changes to 1 when we\npress\
    \ the “ON\" button, and the firebase sends a signal to the\nnodeMCU board, which\
    \ then turns the motor on automatically.\nAnd that is how we can use our mobile\
    \ app to implement\nremote control.\nwww.ijacsa.thesai.org\n993 | P a g e\n(IJACSA)\
    \ International Journal of Advanced Computer Science and Applications,\nVol. 14,\
    \ No. 7, 2023\nTABLE II. SYSTEM EVALUATION WITH THE EXISTING SYSTEMS\nReference\n\
    Remote Motor\nControlling\nEnergy\nHar-\nvesting\nCustomised\nMobile\nApplication\n\
    Machine\nLearning\nIntegrated\nFramework\nCreating Own\nData set\nCentral Cloud\n\
    Database\npH based fer-\ntilizer sugges-\ntions\nBlockchain\nbased\nSecurity\n\
    Full au-\ntoma-\ntion\n[11]\n×\n×\n✓\n✓\n×\n✓\n×\n×\n×\n[12]\n×\n×\n×\n✓\n×\n\
    ×\n×\n×\n×\n[14]\n×\n×\n×\n✓\n×\n×\n×\n×\n[16]\n×\n×\n×\n✓\n✓\n×\n×\n×\n×\n[17]\n\
    ×\n×\n×\n✓\n×\n×\n✓\n×\n×\n[18]\n✓\n×\n✓\n✓\n×\n×\n✓\n×\n×\n[19]\n✓\n×\n✓\n×\n\
    ×\n✓\n×\n×\n×\n[20]\n✓\n×\n✓\n×\n×\n×\n×\n×\n✓\n[21]\n×\n×\n×\n×\n×\n×\n×\n×\n\
    ×\n[22]\n✓\n×\n✓\n×\n×\n✓\n×\n×\n×\n[23]\n✓\n×\n×\n×\n✓\n✓\n×\n×\n×\n[24]\n✓\n\
    ×\n✓\n×\n×\n✓\n×\n×\n×\nProposed\nMethod\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\nTABLE III.\
    \ SUMMARY OF PROPOSED NEURAL NETWORK PERFORMANCE PARAMETERS\nEpochs\nProcessing\
    \ Time /msec\nBinary Cross Entropy Validation Loss\nGradient Descent Neural Network\
    \ Validation Accuracy\n10\n7\n0.5478\n0.8947\n25\n8\n0.4525\n0.8948\n50\n7\n0.3766\n\
    0.8948\n75\n7\n0.3462\n0.8949\n100\n8\n0.3376\n0.8948\nVII.\nEXPERIMENTAL RESULT\
    \ ANALYSIS\nA. System Evaluation\nIn Table II, we have shown the difference between\
    \ our\nsystem and the existing systems. The criterion based on which\nwe have\
    \ shown the differences are remote monitor control, data\nvisualization, customized\
    \ mobile application, machine learning\nintegrated framework, creating own database,\
    \ central cloud\ndatabase, pH-based fertilizer suggestions, Machine learning\n\
    model development, and full automation. The references from\n[11] to [24] there\
    \ is no such system that has implemented all the\ncriteria in their system. But\
    \ we have successfully implemented\nall the criteria in our systems.\nB. Machine\
    \ Learning Model Evaluation\nOur deep learning neural network is implemented with\n\
    the help of our own dataset. We split the dataset into 80-20\nratios for training\
    \ and validation purposes. The heat map of the\nfeatures columns is illustrated\
    \ in Fig. 16. We fit our gradient\ndescent neural network within the data set.\
    \ The input layer\nof the neural network receives 3 input lines from the features\n\
    column, namely, rain status, moisture level, and daylight status\nrespectively.\
    \ Then we add one dense layer with 16 neurons and\nthe activation function as\
    \ ReLu. The next layer is a dropout\nlayer with a 20% drop rate. Next, we add\
    \ another dense layer\nwith 8 neurons and apply the activation function as ReLu.\n\
    Then we add another dropout layer with a 20% drop rate.\nFinally, for the output\
    \ layer, we add another dense layer with\na single neuron with is satiable for\
    \ binary classification (i.e.\nmotor on-off decision) with activation function\
    \ as Sigmoid.\nThe experimental result of our model is represented in\nTable III\
    \ while showing the validation loss rate as binary cross\nentropy and validation\
    \ accuracy level in different epochs. Our\nmodel successfully outcomes a stable\
    \ level of accuracy for\nthe different epochs. We got almost 89.5% accuracy in\
    \ our\nexperimental set-up.\nVIII.\nFUTURE RESEARCH DIRECTION\nFor future smart\
    \ irrigation management, several issues must\nbe addressed as follows:\n•\nLow-latency\
    \ in Real-Time Application: The moni-\ntoring and controlling mobile application\
    \ must be able\nto transmit real-time data to the farmers or its entity\nwhile\
    \ ensuring a low latency network.\n•\nHigh Bandwidth: To facilitate a buffer-less\
    \ transmis-\nsion, we need to ensure maximum bandwidth level to\nthe transmission\
    \ process.\n•\nConnectivity: To meet the high communication de-\nmands of future\
    \ IoT-ML integrated irrigation systems,\nreliable synchronization between linked\
    \ autos would\nbe required.\n•\nDeployment of Network Elements: When a network\n\
    has a high enough number of nodes, its overall\nperformance increases. Because\
    \ network equipment\ndeployment is costly, it is vital to have the required\n\
    number of network components up and running as\nquickly as feasible.\n•\nAugmented\
    \ Reality: AR is a multimedia application\nthat mixes real-world scenes into virtual\
    \ scenes and\nsuperimposes virtual scenes over real-world scenes to\nsupplement\
    \ traditional real-image information. This\ntechnology has the potential to help\
    \ farmers become\nmore aware of the app’s functionality.\n•\nEdge Computing: This\
    \ networking approach is built\non a network control layer that is logically centralized.\n\
    www.ijacsa.thesai.org\n994 | P a g e\n(IJACSA) International Journal of Advanced\
    \ Computer Science and Applications,\nVol. 14, No. 7, 2023\nFig. 15. Mobile application\
    \ interface.\nFig. 16. Heat-Map of the features of our ML part.\nIt contributes\
    \ to the creation of a dependable resource\nmanagement and traffic control system.\n\
    IX.\nCONCLUSION\nWe have put forth an integrated solution that enables\nfarmers\
    \ to solve the challenges that limit their production\nand profitability by utilizing\
    \ cutting-edge technologies like\nmachine learning (ML), the Internet of Things\
    \ (IoT), and\nblockchain. Through user-friendly mobile applications and\na secure\
    \ cloud database, this model, implemented with a\ngenerated database, offers helpful\
    \ insights and recommendations\nto farmers, including pesticide usage and water\
    \ motor control.\nReal-time monitoring and data collecting is made possible\n\
    by the integration of IoT devices, enabling accurate decision-\nmaking and assuring\
    \ optimal resource allocation. Incorpo-\nrating blockchain technology also improves\
    \ data traceability,\ntransparency, and integrity, fostering trust and accountability\n\
    throughout the agricultural ecosystem. Farmers may gain from\nhigher productivity,\
    \ decreased expenses, and enhanced general\nagricultural management by implementing\
    \ our Smart-Agri\nframework. They can obtain up-to-date, accurate information,\n\
    make decisions that will increase productivity and reduce\nwaste, and improve\
    \ their agricultural techniques. We have\napplied the gradient descent neural\
    \ network model for water\ncontrol management and achieved up to 89.5% accuracy.\
    \ In\naddition, the suggested structure creates chances for cooperation,\ninformation\
    \ exchange, and market access, all of which help\nthe agricultural industry thrive\
    \ and flourish sustainably.\nIn the future, the framework’s scalability, and its\
    \ inter-\noperability can all be explored through more research and\ndevelopment\
    \ in this area, along with potential problems like\nconnectivity problems and\
    \ data privacy issues. We can build an\necosystem that really revolutionizes the\
    \ agriculture sector by\ncontinually improving and building upon these technological\n\
    achievements, making it more intelligent, efficient, and robust\nin the face of\
    \ changing global issues.\nACKNOWLEDGMENT\nWe would like to acknowledge the support\
    \ of the\nBangladesh University of Business and Technology and the\nIoT lab for\
    \ their suggestion and resource sharing.\nREFERENCES\n[1]\nA. Rehman, T. Saba,\
    \ M. Kashif, S. M. Fati, S. A. Bahaj, and H. Chaudhry,\n“A revisit of internet\
    \ of things technologies for monitoring and control\nstrategies in smart agriculture,”\
    \ Agronomy, vol. 12, no. 1, p. 127, 2022.\n[2]\nM. Biswas, A. Rahman, M. S. Kaiser,\
    \ S. Al Mamun, K. S. Ebne Mizan,\nM. S. Islam, and M. Mahmud, “Indoor navigation\
    \ support system for\npatients with neurodegenerative diseases,” in Brain Informatics:\
    \ 14th\nInternational Conference, BI 2021, Virtual Event, September 17–19,\n2021,\
    \ Proceedings 14.\nSpringer, 2021, pp. 411–422.\n[3]\nH. Elahi, K. Munir, M. Eugeni,\
    \ S. Atek, and P. Gaudenzi, “Energy\nharvesting towards self-powered iot devices,”\
    \ Energies, vol. 13, no. 21,\np. 5528, 2020.\n[4]\nA. Sabovic, A. K. Sultania,\
    \ C. Delgado, L. De Roeck, and J. Famaey,\n“An energy-aware task scheduler for\
    \ energy-harvesting batteryless iot\ndevices,” IEEE Internet of Things Journal,\
    \ vol. 9, no. 22, pp. 23 097–\n23 114, 2022.\n[5]\nM. A. Rahman, H. Ahmed, and\
    \ M. M. Hossain, “An integrated hardware\nprototype for monitoring gas leaks,\
    \ fires, and remote control via mobile\napplication,” International Journal of\
    \ Advanced Computer Science and\nApplications, vol. 13, no. 10, 2022.\n[6]\nK.\
    \ Demestichas, N. Peppes, T. Alexakis, and E. Adamopoulou,\n“Blockchain in agriculture\
    \ traceability systems: A review,” Applied\nSciences, vol. 10, no. 12, p. 4113,\
    \ 2020.\nwww.ijacsa.thesai.org\n995 | P a g e\n(IJACSA) International Journal\
    \ of Advanced Computer Science and Applications,\nVol. 14, No. 7, 2023\n[7]\n\
    O. Bermeo-Almeida, M. Cardenas-Rodriguez, T. Samaniego-Cobo,\nE. Ferruzola-Gómez,\
    \ R. Cabezas-Cabezas, and W. Bazán-Vera,\n“Blockchain in agriculture: A systematic\
    \ literature review,” in Technolo-\ngies and Innovation: 4th International Conference,\
    \ CITI 2018, Guayaquil,\nEcuador, November 6-9, 2018, Proceedings 4.\nSpringer,\
    \ 2018, pp. 44–\n56.\n[8]\nS. L. Ullo and G. R. Sinha, “Advances in iot and smart\
    \ sensors for\nremote sensing and agriculture applications,” Remote Sensing, vol.\
    \ 13,\nno. 13, p. 2585, 2021.\n[9]\nK. Malarvizhi, S. Karthik, M. G. SG et al.,\
    \ “Machine learning and\ninternet of things based smart agriculture,” in 2020\
    \ 6th International\nConference on Advanced Computing and Communication Systems\n\
    (ICACCS).\nIEEE, 2020, pp. 1101–1106.\n[10]\nJ. Boobalan, V. Jacintha, J. Nagarajan,\
    \ K. Thangayogesh, and S. Tamila-\nrasu, “An iot based agriculture monitoring\
    \ system,” in 2018 international\nconference on communication and signal processing\
    \ (ICCSP).\nIEEE,\n2018, pp. 0594–0598.\n[11]\nK. Phasinam, T. Kassanuk, P. P.\
    \ Shinde, C. M. Thakar, D. K. Sharma,\nM. Mohiddin, A. W. Rahmani et al., “Application\
    \ of iot and cloud\ncomputing in automation of agriculture irrigation,” Journal\
    \ of Food\nQuality, vol. 2022, 2022.\n[12]\nA. A. Araby, M. M. Abd Elhameed, N.\
    \ M. Magdy, N. Abdelaal, Y. T.\nAbd Allah, M. S. Darweesh, M. A. Fahim, H. Mostafa\
    \ et al., “Smart iot\nmonitoring system for agriculture with predictive analysis,”\
    \ in 2019 8th\nInternational Conference on Modern Circuits and Systems Technologies\n\
    (MOCAST).\nIEEE, 2019, pp. 1–4.\n[13]\nA. Gupta and P. Nahar, “Classification\
    \ and yield prediction in smart\nagriculture system using iot,” Journal of Ambient\
    \ Intelligence and\nHumanized Computing, pp. 1–10, 2022.\n[14]\nM. Lee, J. Hwang,\
    \ and H. Yoe, “Agricultural production system based\non iot,” in 2013 IEEE 16Th\
    \ international conference on computational\nscience and engineering.\nIEEE, 2013,\
    \ pp. 833–837.\n[15]\nM. S. Mekala and P. Viswanathan, “Clay-mist: Iot-cloud enabled\
    \ cmm\nindex for smart agriculture monitoring system,” Measurement, vol. 134,\n\
    pp. 236–244, 2019.\n[16]\nY. Zhou, Q. Xia, Z. Zhang, M. Quan, and H. Li, “Artificial\
    \ intelligence\nand machine learning for the green development of agriculture\
    \ in the\nemerging manufacturing industry in the iot platform,” Acta Agriculturae\n\
    Scandinavica, Section B—Soil & Plant Science, vol. 72, no. 1, pp.\n284–299, 2022.\n\
    [17]\nH. Abhijith, D. A. Jain, and U. A. A. Rao, “Intelligent agriculture\nmechanism\
    \ using internet of things,” in 2017 International Conference\non Advances in\
    \ Computing, Communications and Informatics (ICACCI).\nIEEE, 2017, pp. 2185–2188.\n\
    [18]\nG. Abraham, R. Raksha, and M. Nithya, “Smart agriculture based on\niot and\
    \ machine learning,” in 2021 5th International Conference on\nComputing Methodologies\
    \ and Communication (ICCMC).\nIEEE, 2021,\npp. 414–419.\n[19]\nK. Wongpatikaseree,\
    \ P. Kanka, and A. Ratikan, “Developing smart farm\nand traceability system for\
    \ agricultural products using iot technology,”\nin 2018 IEEE/ACIS 17th International\
    \ Conference on Computer and\nInformation Science (ICIS), 2018, pp. 180–184.\n\
    [20]\nD. Ardiansyah, A. S. M. Huda, Darusman, R. G. Pratama, and\nA. P. Putra,\
    \ “Wireless sensor network server for smart agriculture\noptimatization,” IOP\
    \ Conference Series: Materials Science and\nEngineering, vol. 621, no. 1, p. 012001,\
    \ oct 2019. [Online]. Available:\nhttps://doi.org/10.1088/1757-899x/621/1/012001\n\
    [21]\nL. Vijayaraja, R. Dhanasekar, R. Kesavan, D. Tamizhmalar, R. Premku-\nmar,\
    \ and N. Saravanan, “A cost effective agriculture system based on\niot using sustainable\
    \ energy,” in 2022 6th International Conference\non Trends in Electronics and\
    \ Informatics (ICOEI).\nIEEE, 2022, pp.\n546–549.\n[22]\nY.-W. Kuo, W.-L. Wen,\
    \ X.-F. Hu, Y.-T. Shen, and S.-Y. Miao, “A lora-\nbased multisensor iot platform\
    \ for agriculture monitoring and submersible\npump control in a water bamboo field,”\
    \ Processes, vol. 9, no. 5, p. 813,\n2021.\n[23]\nP. Srinivasulu, M. S. Babu,\
    \ R. Venkat, and K. Rajesh, “Cloud service\noriented architecture (csoa) for agriculture\
    \ through internet of things\n(iot) and big data,” in 2017 IEEE international\
    \ conference on electrical,\ninstrumentation and communication engineering (ICEICE).\
    \ IEEE, 2017,\npp. 1–6.\n[24]\nR. K. Patil and S. S. Patil, “Cognitive intelligence\
    \ of internet of things in\nsmart agriculture applications,” in 2020 IEEE Pune\
    \ Section International\nConference (PuneCon).\nIEEE, 2020, pp. 129–132.\n[25]\n\
    M. T. Quasim, F. Algarni, A. A. E. Radwan, and G. M. M. Alshmrani, “A\nblockchain\
    \ based secured healthcare framework,” in 2020 International\nConference on Computational\
    \ Performance Evaluation (ComPE). IEEE,\n2020, pp. 386–391.\n[26]\nI. Makhdoom,\
    \ I. Zhou, M. Abolhasan, J. Lipman, and W. Ni, “Privyshar-\ning: A blockchain-based\
    \ framework for privacy-preserving and secure\ndata sharing in smart cities,”\
    \ Computers & Security, vol. 88, p. 101653,\n2020.\n[27]\nM. Rahaman, M. Chowdhury,\
    \ M. A. Rahman, H. Ahmed, M. Hossain,\nM. H. Rahman, M. Biswas, M. Kader, T. A.\
    \ Noyan, and M. Biswas,\n“A deep learning based smartphone application for detecting\
    \ mango\ndiseases and pesticide suggestions,” International Journal of Computing\n\
    and Digital Systems, vol. 13, no. 1, pp. 1–1, 2023.\n[28]\nM. N. Rahaman, S. Chaki,\
    \ M. S. Biswas, M. Biswas, S. Ahmed, M. J. N.\nMahi, and N. Faruqui, “Identifying\
    \ the signature of suicidality: A\nmachine learning approach,” in THEETAS 2022:\
    \ Proceedings of The\nInternational Conference on Emerging Trends in Artificial\
    \ Intelligence\nand Smart Systems, THEETAS 2022, 16-17 April 2022, Jabalpur, India.\n\
    European Alliance for Innovation, 2022, p. 279.\n[29]\nM. A. R. Milon Biswas,\
    \ H. Ahmed, A. Anis, and M. M. Hossain, “A\nsmartphone-based application for medical\
    \ assistance of elderly patients,”\nInternational Journal of Research and Innovation\
    \ in Applied Science\n(IJRIAS), vol. 7, no. 6, pp. 15–19, 2022.\n[30]\nZ. Zheng,\
    \ S. Xie, H.-N. Dai, X. Chen, and H. Wang, “Blockchain\nchallenges and opportunities:\
    \ A survey,” International journal of web\nand grid services, vol. 14, no. 4,\
    \ pp. 352–375, 2018.\n[31]\nY. Yuan, F.-Y. Wang et al., “Blockchain: the state\
    \ of the art and future\ntrends,” Acta Automatica Sinica, vol. 42, no. 4, pp.\
    \ 481–494, 2016.\n[32]\nS. Ahmed, M. Biswas, M. Hasanuzzaman, M. J. N. Mahi, M.\
    \ A. Islam,\nS. Chaki, and L. Gaur, “A secured peer-to-peer messaging system based\n\
    on blockchain,” in 2022 3rd International Conference on Intelligent\nEngineering\
    \ and Management (ICIEM).\nIEEE, 2022, pp. 332–337.\nwww.ijacsa.thesai.org\n996\
    \ | P a g e\n"
  inline_citation: '>'
  journal: International journal of advanced computer science & applications (Online)
  limitations: '>'
  pdf_link: http://thesai.org/Downloads/Volume14No7/Paper_107-Smart_Agri_A_Smart_Agricultural_Management.pdf
  publication_year: 2023
  relevance_score1: 0
  relevance_score2: 0
  title: 'Smart-Agri: A Smart Agricultural Management with IoT-ML-Blockchain Integrated
    Framework'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.14569/ijacsa.2023.01406123
  analysis: '>'
  authors:
  - El Mehdi Raouhi
  - Mohamed Lachgar
  - Hamid Hrimech
  - Ali Kartit
  citation_count: 2
  full_citation: '>'
  full_text: '>

    IJACSA-International Journal of Advanced Computer Science and Applications,

    Vol. 14, No. 6, 2023

    Unmanned Aerial Vehicle-based Applications in

    Smart Farming: A Systematic Review

    El Mehdi Raouhi1, Mohamed Lachgar2, Hamid Hrimech3 Ali Kartit4

    LTI Laboratory, ENSA, University ChouaibDoukkali, El Jadida, Morocco1,2,4

    LAMSAD Laboratory, ENSA, University Settat, Berrechid, Morocco3

    Abstract—On one hand, the emergence of cutting-edge tech-

    nologies like AI, Cloud Computing, and IoT holds immense

    potential in Smart Farming and Precision Agriculture. These

    technologies enable real-time data collection, including high-

    resolution crop imagery, using Unmanned Aerial Vehicles (UAVs).

    Leveraging these advancements can revolutionize agriculture by

    facilitating faster decision-making, cost reduction, and increased

    yields. Such progress aligns with precision agriculture principles,

    optimizing practices for the right locations, times, and quantities.

    On the other hand, integrating UAVs in Smart Farming faces

    obstacles related to technology selection and deployment, par-

    ticularly in data acquisition and image processing. The relative

    novelty of UAV utilization in Precision Agriculture contributes to

    the lack of standardized workflows. Consequently, the widespread

    adoption and implementation of UAV technologies in farming

    practices are hindered. This paper addresses these challenges by

    conducting a comprehensive review of recent UAV applications

    in Precision Agriculture. It explores common applications, UAV

    types, data acquisition techniques, and image processing methods

    to provide a clear understanding of each technology’s advantages

    and limitations. By gaining insights into the advantages and

    challenges associated with UAV-based applications in Precision

    Agriculture, this study aims to contribute to the development

    of standardized workflows and improve the adoption of UAV

    technologies.

    Keywords—Artificial intelligence; internet of things; sensor; big

    data; cloud; unmanned aerial vehicle; smart farming

    I.

    INTRODUCTION

    The agriculture industry is currently undergoing a sig-

    nificant transformation fueled by cutting-edge technologies,

    offering promising prospects for enhanced farm productivity

    and profitability. Precision Agriculture, which focuses on the

    precise application of inputs where and when they are needed,

    represents the third stage of the modern agricultural revolution.

    Advanced farm knowledge systems, empowered by the abun-

    dance of data, have further propelled the evolution of Preci-

    sion Agriculture [1]. Numerous studies have demonstrated the

    positive impacts of adopting Precision Agriculture technolo-

    gies, such as increased net returns and operating profits, as

    reported by the U.S. Department of Agriculture (USDA) [2].

    Moreover, there is a growing emphasis on implementing these

    technologies in environmentally conscious ways to ensure

    sustainable farm production. However, effectively harnessing

    the vast amount of data generated by crops remains a persistent

    challenge [3].

    To address these challenges, it is crucial to explore and

    integrate cutting-edge technologies in the realm of Smart

    Farming and Precision Agriculture. Unmanned Aerial Vehicles

    (UAVs), Cloud Computing, Internet of Things (IoT), Big Data

    analytics, and Artificial Intelligence (AI) have emerged as key

    enablers of innovation in this domain [4]. UAVs equipped with

    advanced sensors and imaging capabilities allow for real-time

    data collection, including high-resolution imagery of crops.

    Cloud Computing provides the infrastructure for data storage,

    processing, and analysis, while IoT facilitates the seamless

    integration of various agricultural devices and sensors. Big

    Data analytics and AI techniques enable intelligent insights

    and decision-making based on the collected data [5], [6].

    This paper aims to delve into the theoretical background

    and related work of UAV, Cloud, IoT, Big Data, and AI

    approaches in Smart Farming and Precision Agriculture. Ad-

    ditionally, authors propose a comprehensive systematic review

    study that investigates the current state of research and de-

    velopment in this area. By analyzing existing literature, in

    order to identify the gaps, challenges, and opportunities for

    utilizing these technologies in the context of Smart Farming

    and Precision Agriculture, Fig. 1, depicted below, offers valu-

    able insights into the evolution characteristics and challenges

    of agricultural development, spanning from Farming 1.0 to

    Farming 5.0. This figure serves as a valuable tool to showcase

    the effective utilization and evolution of technologies within

    the realms of Smart Farming and Precision Agriculture. The

    problem statement of this study revolves around the lack

    of a standardized framework for leveraging UAVs, Cloud

    Computing, IoT, Big Data, and AI in Smart Farming and

    Precision Agriculture. This lack of standardization hinders the

    widespread adoption and implementation of these technolo-

    gies, limiting their potential benefits for farmers, agricultural

    productivity, and sustainable practices. To address this prob-

    lem, our proposed solution is to conduct a systematic review

    that synthesizes existing research, identifies key insights, and

    provides recommendations for the development of standard-

    ized frameworks and practices in this field.

    The motivation behind this work stems from the immense

    potential of integrating UAVs, Cloud Computing, IoT, Big Data

    analytics, and AI in Smart Farming and Precision Agriculture.

    By leveraging these technologies effectively, farmers can make

    faster and more informed decisions, reduce costs, optimize

    resource utilization, and increase yields. Moreover, this inte-

    gration aligns with the growing demand for sustainable farming

    practices and the need to meet the rising global food demands.

    The contribution of this paper lies in the comprehensive review

    of existing literature, which consolidates knowledge, identifies

    research gaps, and proposes recommendations for the future

    development of Smart Farming and Precision Agriculture.

    By providing insights into the theoretical foundations, related

    work, problem statement, proposed solution, and motivation,

    www.ijacsa.thesai.org

    1150 | P a g e

    IJACSA-International Journal of Advanced Computer Science and Applications,

    Vol. 14, No. 6, 2023

    Fig. 1. Characteristics and challenges of agricultural development (from Farming
    1.0 to Farming 5.0.

    in order to advance the understanding and adoption of UAVs,

    Cloud Computing, IoT, Big Data analytics, and AI in the

    agricultural domain.

    This paper is structured as follows. Firstly, Section 1

    presents the theorical background of UAV, Cloud, IoT, Big

    Data and AI approaches. Afterwards, current technical compo-

    nents of Smart farning and precision agriculture in the research

    area are specified. Within this section, a more in-depth reflec-

    tion is carried out on the rising of AI and IoT in smart farming.

    Secondly, Section 2 describes the detailed process steps of the

    systematic review and the defined research methodology of this

    study. Then, Section 3 summarizes the research results. Section

    4 describes the discussion with challenges and future directions

    of this research study. Finally, a conclusion is presented in the

    last section of this paper.

    II.

    BACKGROUND

    A. Unnamed Aerial Vehicles for Agriculture

    Unmanned Aerial Systems (UAS), also known as drones,

    have become increasingly popular in agriculture due to their

    ability to provide a quick, cost-effective and efficient way to

    gather data and perform tasks on large fields and crops [7].

    UAS (Unmanned Aerial Systems) indeed come in different

    types and can be equipped with a variety of sensors and

    cameras presented in Fig. 2 that can capture high-resolution

    images, aerial maps and thermal imagery, which can be used

    for a range of agriculture applications, including:

    •

    Crop monitoring: UAS can be used to gather real-time

    data on crop health, growth, and yield potential.

    •

    Irrigation management: Drones can be equipped with

    infrared cameras to identify areas that are in need of

    irrigation and to help optimize water use.

    •

    Pest and disease management: Drones can be used

    to detect and map the spread of pests and diseases in

    crops, helping farmers to take timely action to prevent

    or treat these issues.

    •

    Field mapping: UAS can produce high-resolution

    maps of fields, providing data on soil structure, to-

    pography, and plant populations, which can be used to

    make informed decisions about planting, fertilization

    and other aspects of crop management.

    •

    Livestock management: Drones can be used to monitor

    the health and behavior of livestock, as well as to keep

    track of the location of animals.

    Overall, the use of UAS in agriculture provides a new tool for

    farmers to gather data, monitor their crops and make more

    informed decisions, ultimately leading to improved yields,

    increased efficiency and reduced costs.

    B. Cloud, Internet of Things, Big data and IA

    1) Cloud: computing plays a crucial role in smart farming,

    which is an application of the Internet of Things (IoT) in

    agriculture. The cloud enables farmers to store, process, and

    analyze large amounts of data generated from various IoT

    devices and sensors on their farms [9]. This data can include

    information on weather patterns, soil moisture levels, crop

    growth, and even the health of livestock. By analyzing this data

    in real-time, farmers can make more informed decisions about

    crop management and animal husbandry, leading to increased

    productivity and efficiency.

    Additionally, cloud-based solutions can provide farmers

    with access to advanced algorithms and predictive analytics

    tools that can help them optimize their farming operations.

    For example, cloud-based machine learning models can predict

    www.ijacsa.thesai.org

    1151 | P a g e

    IJACSA-International Journal of Advanced Computer Science and Applications,

    Vol. 14, No. 6, 2023

    Fig. 2. Different types of agricultural UAVs (Harvesting UAV, Spraying UAV, Mapping
    UAV, Sensing UAV) [8].

    crop yields, identify pest infestations, and suggest the most

    appropriate treatments. Furthermore, the cloud allows farmers

    to monitor their farms remotely and receive real-time updates

    on conditions and activities.

    2) Internet of Things: The concept of the Internet of Things

    (IoT) pertains to a network comprising physical devices,

    vehicles, appliances, and various objects. These entities are

    equipped with sensors, software, and connectivity features that

    empower them to gather and exchange data via the internet.

    These connected devices can communicate and interact with

    each other, as well as with humans, creating a vast ecosystem

    of interconnected systems [10]. The IoT has the potential to

    revolutionize various sectors, including agriculture, healthcare,

    transportation, smart homes, and many others, by enabling

    increased automation, efficiency, and data-driven decision-

    making. In smart farming, IoT is used to gather real-time data

    from various sources such as weather stations, soil moisture

    sensors, and crop and animal monitoring systems.

    IoT devices and sensors in smart farming can range from

    simple weather sensors to more complex systems such as pre-

    cision agriculture systems that use Global Positioning System

    (GPS) to monitor the growth and health of crops. These devices

    can also be connected to irrigation systems, allowing farmers

    to control the amount of water they use based on real-time

    soil moisture levels. One of the key benefits of IoT in smart

    farming is that it enables farmers to make data-driven decisions

    in real-time. This leads to more efficient use of resources and

    improved crop yields. IoT also enables farmers to monitor their

    farms remotely, reducing the need for on-site visits and freeing

    up more time for other tasks.

    In addition to its direct benefits, IoT in smart farming

    can also help address important global challenges such as

    food security and sustainability [11]. By using technology to

    optimize their operations, farmers can produce more food using

    fewer resources, reducing their carbon footprint and helping to

    ensure that future generations have access to safe and healthy

    food. Overall, the Internet of Things is revolutionizing the way

    farming is done and is poised to play a crucial role in the future

    of agriculture.

    Wireless Sensor Networks (WSNs) are networks of small,

    low-cost, and low-power devices that can be used to monitor

    and collect data from the environment [12]. These devices,

    called “nodes”, are equipped with sensors, microcontrollers,

    and wireless communication capabilities, allowing them to

    transmit data wirelessly to a central location for analysis.

    WSNs are widely used in a variety of applications, in-

    cluding smart farming, where they are used to monitor soil

    moisture, temperature, light, and other environmental param-

    eters that affect crop growth [13]. The data collected by the

    sensor nodes can be used to make informed decisions about

    irrigation, fertilization, and other agricultural practices, leading

    to increased efficiency and higher crop yields.

    One of the key benefits of WSNs is that they are low-cost

    and easy to deploy, making them accessible to farmers of all

    sizes and resources. They are also scalable, allowing farmers

    to add more nodes as their needs grow [14]. Finally, a review

    of 77 research papers published between 2012 and 2022 on

    the implementation of IoT in various agricultural applications

    showed that roughly 16% focused on precision agriculture

    and the same percentage on irrigation monitoring. 13% of

    the papers delved into soil monitoring, while temperature and

    animal monitoring were each covered in 11% of the research.

    Air and disease monitoring each received 5% of attention, with

    water monitoring accounting for 7%. Fertilization monitoring

    was the least studied, with only 4% of the research papers

    devoted to it in [15].

    C. Big Data

    Big Data plays a significant role in the context of smart

    farming. Smart farming involves the application of advanced

    technologies, such as sensors, Internet of Things (IoT) de-

    vices, and data analytics, to enhance agricultural practices and

    decision-making processes [16]. These technologies generate

    vast amounts of data from various sources, including weather

    conditions, soil moisture levels, crop health indicators, and

    machinery performance.

    www.ijacsa.thesai.org

    1152 | P a g e

    IJACSA-International Journal of Advanced Computer Science and Applications,

    Vol. 14, No. 6, 2023

    Big Data analytics allows for the collection, storage, pro-

    cessing, and analysis of large volumes of agricultural data in

    real-time or near-real-time. By applying advanced analytics

    techniques, such as machine learning and predictive model-

    ing, valuable insights can be extracted from this data. These

    insights can help optimize farming practices, improve resource

    allocation, enhance crop yield, and enable more informed

    decision-making for farmers and agricultural stakeholders [17].

    Furthermore, Big Data analytics can enable predictive capa-

    bilities in smart farming. By leveraging historical data and

    machine learning algorithms, models can be developed to

    forecast disease outbreaks, pests infestation, crop yield, and

    market demand. These predictive insights empower farmers to

    make proactive decisions, mitigate risks, and optimize resource

    allocation. In summary, the integration of Big Data analyt-

    ics in smart farming allows for data-driven decision-making,

    optimization of agricultural practices, and the potential for

    increased productivity, sustainability, and profitability in the

    agriculture industry [18], [19].

    D. Artificial Intelligence

    Artificial Intelligence (AI) encompasses the creation of

    computer systems capable of executing tasks typically requir-

    ing human intelligence, including pattern recognition, predic-

    tion, and learning from experience. In smart farming, AI is

    used to automate various processes and make more informed

    decisions [16]. One of the key applications of AI in smart

    farming is precision agriculture, where AI algorithms are used

    to analyze data from various sources, such as weather stations

    and sensors, to determine the best practices for growing crops.

    For example, AI can be used to optimize irrigation and fer-

    tilization practices, leading to increased efficiency and higher

    yields. AI can also be used in animal husbandry to monitor

    the health and behavior of livestock. Also, AI algorithms can

    be used to detect signs of illness in animals, such as changes

    in their heart rate or behavior, and alert farmers to take action.

    Another application of AI in smart farming is in the detection

    and control of pests and diseases. AI algorithms can be used to

    analyze images of crops and detect signs of pests or diseases,

    allowing farmers to take proactive measures to address them. In

    conclusion, AI is a valuable tool in the development of smart

    farming, enabling farmers to make more informed decisions

    and automate various processes [20]. By using AI, farmers can

    improve efficiency, increase yields, and reduce waste, making

    a valuable contribution to the future of agriculture. However,

    it’s important to note that while AI has the potential to greatly

    benefit the agriculture industry; it also presents challenges,

    such as the need for large amounts of data and the potential

    for bias in algorithms. Thus, it’s important to approach the

    integration of AI in smart farming with caution and a focus

    on ethical and sustainable practices.

    III.

    METHODOLOGY

    In recent years, the academic community has extensively

    analyzed numerous works related to smart farming develop-

    ment from various perspectives. For instance, [21] introduced a

    systematic review focusing on precision farming. Then, authors

    in [22] provided a review on technologies in precision agricul-

    ture, highlighting innovations, technologies, and applications.

    Also, authors in [23] explored the use of big data on smart

    farming, emphasizing the primary opportunities and challenges

    associated with this technology. Additionally, [24] conducted a

    quantitative literature review, offering an overview of academic

    production in smart farming.

    In order to enhance the existing analyses, the present

    study seeks to conduct a comprehensive review of UAV based

    applications in the field of smart farming. To accomplish this

    objective, we employed the Preferred Reporting Items for

    Systematic Reviews (PRISMA) methodology [25], a frame-

    work specifically designed to facilitate literature reports and

    systematic reviews. In October 2022, authors conducted a

    search using the available search tool on the Scopus database

    website. Additionally, another search was performed in april

    2023 within the same database to include papers published

    in the year 2023. Scopus was selected due to its exten-

    sive coverage and relevance in similar bibliographic reviews

    mentioned in [24] and [26]. Our search strategy focused

    on terms related to technological applications in agriculture,

    such as “Precision Agriculture,” “Precision Farming,” “Smart

    Farming,” and “Smart Agriculture,” in conjunction with “UAV”

    and related terms. The publication date of articles was not a

    basis for exclusion. However, we restricted our research scope

    to journal and conference articles published in English. To

    ensure methodological rigor, this systematic review adhered to

    the guidelines outlined in the Preferred Reporting Items for

    Systematic Reviews and Meta-Analyses (PRISMA), with the

    most recent version being 2020. In Table I, you will find a

    compilation of the research questions (RQ) that the Systematic

    Literature Review (SLR) aims to address.

    In this paper, a systematic literature review (SLR) was

    conducted to assess recent research papers on the use of IoT,

    Big data, Cloud & AI techniques in the field of Smart farm-

    ing. However, advancements in technology and the increasing

    availability of digital resources have led to the development of

    new systematic review process, but the traditional systematic

    literature review methodology remains the standard approach

    for conducting systematic reviews, new tools and techniques

    are emerging that can enhance the process and provide addi-

    tional benefits to researchers and decision-makers. However,

    it is important to consider the limitations of these new ap-

    proaches and to ensure that the results of the systematic review

    remain reliable and trustworthy. The following are the steps

    involved in the systematic literature review methodology: In

    this context, lookup has produced a plethora of SLR standards

    that should be observed to reap tremendous empirical research.

    In this paper, we concentrate on the SLR guidelines proposed

    by authors in [19], which can be classified into the following

    categories. There are four steps:

    •

    Step 1: Identifying the research goal(s).

    •

    Step 2: Research subject framing (conceptual bound-

    aries).

    •

    Step 3: Using inclusion/exclusion criteria to collect

    data.

    •

    Step 4: Validation of the research findings is the fourth

    step.

    www.ijacsa.thesai.org

    1153 | P a g e

    IJACSA-International Journal of Advanced Computer Science and Applications,

    Vol. 14, No. 6, 2023

    TABLE I. RESEARCH QUESTIONS OF THE STUDY

    Number

    Research Question (RQ)

    RQ1

    What are the various applications of UAVs in Precision Agriculture?

    RQ2

    Which crops are monitored by UAV systems?

    RQ3

    How can UAV-based technologies be adapted for use in different types

    of crops or farming environments?

    RQ4

    What types of data can be obtained through the use of UAVs?

    RQ5

    Which methods of data processing can be employed to analyze the

    agricultural data collected by UAVs?

    RQ6

    What are the challenges associated with using drones for disease

    detection in agriculture?

    RQ7

    What are the potential ethical and legal implications associated with

    the use of drones in agriculture, and how can these issues be ad-

    dressed?

    A. Research Objectives

    This study attempts to systematically analyze possible

    future possibilities for IoT, Cloud, Big Data and AI in Smart

    Farming by analyzing current knowledge and the state of the

    research, with a focus on recent research advancements. This

    paper is interested in learning how this study topic has changed

    throughout time. Furthermore, the outcomes of the evaluation

    will be utilized to identify critical activities for future study as

    well as practical applications.

    B. Framing of the Research Subject

    The goal of this study is to evaluate Big Data, Cloud,

    internet of things, artificial intelligence technologies for Smart

    Farming in a systematic way. As a result, the research subject,

    i.e. the conceptual boundaries, were defined in the agriculture

    environment using the terms “Unnamed Aerial Vehicle”, “Big

    Data”, “Cloud”, “internet of things”, “artificial intelligence”

    and related concepts “machine learning” and “deep learning.”

    The following Table II displays the Inclusion and exclusion

    criteria identified to refine the search request.

    C. Data Collection by Using Criteria

    A definition of search parameters, databases, search key-

    words, and publication time is also required by the SLR.

    The selection of search resources and the choice of search

    phrases are both part of the search strategy. To find the papers,

    automated search engine from the most relevant sources were

    chosen: Scopus. A further examination of similar databases

    (ACM Digital Library and Emerald) revealed significant vari-

    ations in the research studies that resulted. As a result, Scopus

    was used as the primary database for secondary data evaluation

    in this research study. The systematic research approach [24]

    and the inclusion and exclusion criterias, which are based on

    the process query depicted in Fig. 3.

    Screening the article title, abstract, and keywords for rele-

    vant literature for Blockchain, IoT and AI in the subject areas

    of management was the first step. We included a variety of

    document formats in this stage and limited them to the English

    language. This first method was mostly utilized to obtain a

    sense of where research was at the time. As a result, the study

    was not limited intialy to a specific period. In total, 536 studies

    were found as a result of this method. We concentrated on

    studies in the areas of Smart Farming and Precision Agriculture

    in the second step. As a consequence, we narrowed down

    the previously identified 536 publications to 186 papers that

    contained the terms Smart Farming or Precision Agriculture.

    TABLE II. INCLUSION CRITERIA (IC) AND EXCLUSION CRITERIA (EC).

    Number

    Question

    IC1

    Paper published in a peer reviewed scientific journal

    IC2

    Works published in English

    IC3

    Articles on Computer Science Subject Area

    IC4

    Keywords on Agriculture, Unmanned Aerial Vehicles, Machine Learn-

    ing

    EC1

    Reviews, conference papers, conference reviews, letters, books, book

    chapters and editorials are excluded from this study

    EC2

    Works that do not provide enough information on the methodology

    adopted and that do not report their results in a clear way are excluded.

    EC3

    Articles whose full text is not available are excluded

    TABLE III. QUALITY ASSESSMENT QUESTIONS

    Number

    Question

    Q1

    Have the study’s objectives been effectively communicated and de-

    fined?

    Q2

    Is the scope and context of the study clearly outlined and appropriately

    described?

    Q3

    Has the proposed solution been thoroughly explained and supported

    by empirical evidence?

    Q4

    Do the variables utilized in the study demonstrate both validity and

    reliability?

    Q5

    Is the research process adequately documented and transparent?

    Q6

    Have all the research questions been adequately addressed?

    Q7

    Are any negative findings presented or discussed within the study?

    Q8

    Are the main findings clearly stated, emphasizing credibility, validity,

    and reliability?

    Furthermore, we created a ranking of all detected keywords,

    which was utilized to verify the meta-search query for the

    current database investigation. In our research strategy, no

    important terms were left out. To evaluate only high-quality

    studies, the study was limited to conference papers, conference

    reviews, articles, or reviews in the third step. In conclusion,

    the final meta-search query was as follows:

    Research Query : (“UAV” OR “Unnamed Aerial Vehicle”)

    AND (“Machine Learning” OR “Deep Learning”) AND (“IoT

    technology” OR “IoT” OR “Internet of Things” OR “internet-

    of-things”) AND (“Smart Farming” OR “Smart Agriculture”

    OR “Precision Farming” OR “Precision Agriculture”) AND

    (“Cloud Computing”).

    The chosen papers were evaluated using eight quality

    assessment questions listed in Table III [27]. Scores of 1 (high

    quality), 0.5 (moderate quality), or 0 (poor quality) were given

    to each paper. Papers that received a total score below four

    were removed from the study.

    IV.

    RESULTS

    This section present the results obtained and content

    analysis on the complete texts of the identified papers. The

    initial stage of the selection process involved screening the

    title, abstract, and introduction of each paper to ascertain

    its relevance. The subsequent step was to eliminate papers

    that did not meet the exclusion criteria outlined in Table II.

    As a result, 80 papers were identified as the basis for the

    further research process. It is important to note that quotation

    marks are used to ensure that multi-word terms are searched

    together, preventing individual words from being considered

    separately. After conducting the search, the resulting articles

    were manually reviewed by analyzing their titles, keywords,

    abstracts, and texts. Duplicate articles were eliminated, and

    the remaining articles were assessed to determine whether

    www.ijacsa.thesai.org

    1154 | P a g e

    IJACSA-International Journal of Advanced Computer Science and Applications,

    Vol. 14, No. 6, 2023

    Fig. 3. Process steps of the systematic literature review.

    they were relevant to the study’s objectives. Valid articles

    were those that focused on IoT-based solutions for agricultural

    problems, were not literature reviews, were written in English,

    Portuguese, or Spanish, and pertained to agriculture rather than

    livestock activities. The study’s search and selection process is

    summarized in Fig. 4. The initial search yielded 536 articles,

    which were then analyzed and narrowed down to 186 articles

    that met the study’s eligibility criteria. During the screening

    phase, 350 articles were deemed invalid and discarded based on

    their lack of relevance to the study’s objectives. Of these, 65%

    did not focus on smart farming. Additionally, almost 35% of

    the discarded papers were literature reviews or studies related

    to smart farming that did not involve IoT. A small number

    of papers pertained to smart farming but did not address IoT

    (about 5% were related to sensors), and some papers had

    abstracts or texts that were not available (about 2%).

    In the eligibility phase, the content of the 80 remaining

    articles was reviewed using the same criteria as in the screening

    phase. Of these, 23 articles were discarded, with 27% not

    related to IoT and 32% not to smart farming. The remain-

    ing 41% were literature reviews or papers without available

    content. This research analysis conducted in 57 articles that

    were eligible for inclusion in the study’s sample.

    A. Description Analysis

    57 papers were ultimately assigned to the topic and rated as

    relevant for deep analysis, out of a total of 536 papers that had

    been previously identified regarding the application of Cloud,

    Big Data, IoT, AI, within UAV Application in Smart Farming.

    The distribution of the selected studies’ suitability, which was

    assessed by reading their titles and abstracts, the distribution

    of articles published per year is shown in Fig. 5, then the

    distribution of documents per year per source is provided

    in Fig. 6 and finally the Fig. 7 describe the distribution of

    documents by appropriateness.

    The decrease in research on the application of drones in

    precision agriculture may be multiple and dependent on vari-

    ous factors such as funding, research priorities, technological

    advancements, etc. However, some possible hypotheses can

    be suggested: Recent technological advancements may have

    solved a significant portion of the issues related to drone

    application in precision agriculture, thereby reducing the need

    for further research in this field. Funding for research in this

    field may have been reduced or directed towards other research

    areas. The scientific community may be transitioning to other

    agricultural monitoring technologies or methods, such as the

    use of remote sensors or satellites. It is also possible that the

    number of scientific publications on the subject has decreased,

    but research is still ongoing in other contexts as provided in

    the distribution of document by subject area provided in Fig.

    8, such as in the private industry. Ultimately, it is important to

    realize that the decrease in research in a given field does not

    necessarily imply that research should be abandoned or that

    previous results are no longer relevant. Existing research can

    still be used to improve existing applications and guide future

    research.

    Out of the 166 full texts in the field of smart farming

    that were found, 96 papers (58%) were rated as having high

    appropriateness, 53 papers (32%) as having medium appropri-

    ateness, and 17 papers (10%) as having low appropriateness in

    relation to the goal of this research project. Book chapters are

    of total of 21%, while research articles are 44%, and reviews

    are 23%.

    Based on the 166 complete articles that were found, Fig.

    8 displays the distribution of document types in the field of

    smart farming by subject area.

    B. Content Analysis

    The complete texts of the papers were reviewed and iden-

    tified in this section. Table IV summarizes the most important

    clusters, primary references, to group the chosen literature into

    related clusters, we engaged in a thorough content analysis.

    In addition Table V complete this set of research documents

    by UAV articles analyzed by characteristics and limitations

    identified in the survey.

    IoT (Internet of Things) technology is transforming the

    agricultural industry by enabling farmers to collect and an-

    alyze data from various sources to make informed decisions.

    However, like any technology, IoT also presents challenges and

    issues, particularly in the context of smart farming. Table VI

    provides a comparison of IoT issues and challenges in smart

    farming:

    www.ijacsa.thesai.org

    1155 | P a g e

    IJACSA-International Journal of Advanced Computer Science and Applications,

    Vol. 14, No. 6, 2023

    Fig. 4. Flow chart of databases search criteria and identification process of
    records.

    Fig. 5. Distribution of articles published per year.

    RQ1. WHAT ARE THE VARIOUS APPLICATIONS OF UAVS

    IN PRECISION AGRICULTURE?

    The use of Artificial Intelligence (AI) and cloud technol-

    ogy in Unmanned Aerial Vehicles (UAVs) has brought about

    significant improvements in smart farming. Here are some of

    the impacts:

    •

    Soil Analysis: UAVs can be used to collect soil

    samples, analyze soil moisture levels, and assess soil

    quality, which can help farmers optimize fertilization

    and irrigation practices.

    •

    Planting: UAVs can be used to plant seeds precisely

    and efficiently, reducing labor costs and increasing

    planting accuracy. Crop spraying: UAVs equipped

    with spraying systems can be used to apply pesticides,

    herbicides, and fertilizers accurately, reducing the en-

    Fig. 6. Distribution of documents per year per source.

    Fig. 7. Distribution of document by appropriateness.

    www.ijacsa.thesai.org

    1156 | P a g e

    IJACSA-International Journal of Advanced Computer Science and Applications,

    Vol. 14, No. 6, 2023

    TABLE IV. SELECTED PRIMARY STUDIES IN SCOPUS

    Ref

    Authors

    Year

    Technology and Subject Area

    [28]

    I. Buja et al.

    2021

    Plant diseases

    [29]

    K.A. Awan et al.

    2020

    Cloud based IoT

    [30]

    M.E. P´erez-Pons

    et al.

    2021

    Sustainable agricultural market

    [20]

    P. Placidi et al.

    2021

    Crop health monitoring

    [22]

    T. Kawai

    2021

    Agricultural systems

    [12]

    A.Z. Bayih et al.

    2022

    Sustainable Smallholder Agricul-

    ture

    [[13]

    T. Qayyum et al.

    2022

    Clustering model in smart farming

    [14]

    J. Bravo-Arrabal

    et al.

    2021

    The internet of cooperative agents

    [9]

    D. Loukatos et al.

    2023

    Malfunction Detection of Water

    Pump Equipment

    [11]

    N.N.

    Thilakarathne

    et al.

    2022

    Crop Recommendation Platform

    [10]

    A. Saleh et al.

    2022

    Edge Node for IoT-Enabled Sensor

    Networks

    [3]

    A. Cravero et al.

    2022

    Agricultural Big Data

    [6]

    G. Giray et C.

    Catal

    2021

    Sustainable agriculture

    [1]

    S. Pal et al.

    2023

    IoT-Based Smart Farming

    [31]

    Z. Nurlan et al.

    2022

    Wireless Sensor Network

    [32]

    F.S. Alrayes et al.

    2023

    Fuzzy Logic-IoT-Cloud Environ-

    ment

    [33]

    S.S. Sarnin et al.

    2019

    Smart insects repeller

    [15]

    Y. Liu et al.

    2022

    Intelligent Data Management Sys-

    tem

    [34]

    P. Deepika et B.

    Arthi

    2022

    Plant pest detection

    [35]

    K. Sharma et al.

    2022

    Predictive Analysis and Smart agri-

    culture

    [36]

    W. Zhao et al.

    2023

    Smart Irrigation and Crop Monitor-

    ing

    [37]

    T. Sutikno et D.

    Thalmann

    2022

    Internet of things

    [38]

    A.

    Zervopoulos

    et al.

    2020

    Wireless sensor network synchro-

    nization

    [39]

    C.G.V.N. Prasad

    et al.

    2022

    Edge Computing and Blockchain

    [40]

    M.L. Rathod et

    al.

    2022

    Cloud Computing and Networking

    [41]

    C.H. Wu et al.

    2020

    Long Short-Term Memory

    [42]

    S. Yadav et al.

    2022

    Disruptive Technologies - Senti-

    ment Analysis.

    [43]

    C. Bersani et al.

    2022

    Monitoring and Control of Smart

    Greenhouses

    [44]

    M. Junaid et al.

    2021

    Smart agriculture cloud

    [45]

    J. Almutairi et al.

    2022

    UAV-Enabled

    Edge-Cloud

    Com-

    puting Systems

    [46]

    B. Almadani et

    S.M. Mostafa

    2021

    IoT based multimodal communica-

    tion model

    [47]

    A.S.P. Pamula et

    al.

    2022

    Real-Time Monitoring

    [48]

    E. Petkov et al.

    2023

    Smart Egg Incubation

    [49]

    S. Chaterji et al.

    2021

    Digital Agriculture

    [50]

    S. Katiyar et A.

    Farhana

    2021

    Artificial Intelligence and IoT

    [51]

    M.Z. Islam et al.

    2022

    QoS Provisioning

    [52]

    Y. Gong et al.

    2022

    Grid-Based coverage path planning

    [53]

    R. Winkler

    2021

    Environmental monitoring

    Fig. 8. Distribution of document by subject area.

    vironmental impact and saving time and money.

    •

    Irrigation Management: UAVs equipped with thermal

    sensors can be used to identify areas of the field that

    need irrigation, allowing farmers to optimize water

    usage and reduce waste.

    •

    Yield Mapping: UAVs can be used to generate yield

    maps, which can help farmers optimize crop manage-

    ment practices and increase overall yield.

    •

    Livestock Monitoring: UAVs equipped with cameras

    can be used to monitor livestock, detect health prob-

    lems, and track animal behavior.

    •

    Crop Monitoring: UAVs equipped with sensors and

    cameras can be used to monitor crop health and

    growth, detect diseases, pests, and stress factors af-

    fecting the crop and generate crop health maps.

    The integration of AI and cloud technology in UAVs has

    brought about significant improvements in smart farming. It

    has enabled precision agriculture, increased efficiency, reduced

    environmental impact, and enabled real-time monitoring of

    farm operations. Also, drones have revolutionized many in-

    dustries, including precision agriculture. So the Fig. 9 provide

    significant UAV applications in precision agriculture using

    AI and Cloud Technologies. Overall, UAVs can significantly

    improve efficiency, accuracy, and sustainability in precision

    agriculture, making it a valuable tool for modern farmers.

    RQ2. WHICH CROPS ARE MONITORED BY UAV

    SYSTEMS?

    Unmanned Aerial Vehicle (UAV) systems are increasingly

    being used for crop monitoring and management in agriculture.

    Various types of crops can be monitored using UAV systems,

    including different Cereals. These crops are often monitored

    for growth stages, yield prediction, and disease detection [63].

    Fruits and vegetables: Such as grapes, citrus, apples, tomatoes,

    and potatoes. UAV systems can monitor the growth and health

    of these crops, detect pests and diseases, and assess yield.

    Oilseeds: Such as soybeans, sunflowers, and canola. UAV

    systems can be used to monitor crop growth, assess the health

    of plants, and predict yields. Specialty crops: Such as coffee,

    tea, cocoa, and tobacco. UAV systems can help monitor the

    health of these crops, detect early signs of disease or pest

    www.ijacsa.thesai.org

    1157 | P a g e

    IJACSA-International Journal of Advanced Computer Science and Applications,

    Vol. 14, No. 6, 2023

    TABLE V. CHARACTERISTICS AND LIMITATIONS OF THE RESEARCH: SET OF UAV ANALYZED
    ARTICLES BY PUBLICATION YEAR, SHORT DESCRIPTION,

    AUTHOR AND AREA OF APPLICATION

    Reference

    Author

    Publication

    year

    Description

    Characteristics

    Limitations

    [54]

    N. A. Sehree

    and

    A.

    M.

    Khidhir

    2022

    Classification of olive tree

    cases based on deep con-

    volutional neural network

    using unmanned aerial ve-

    hicle (UAV) imagery

    This paper proposes a framework

    that integrates UAVs with IoT and

    cloud computing for smart agricul-

    ture. The authors demonstrate the

    feasibility of the proposed frame-

    work through a case study. They

    conclude that the proposed frame-

    work can improve crop yield and

    reduce costs for farmers.

    The authors primarily focus on the

    challenges associated with imple-

    menting UAV-based systems, rather

    than discussing potential solutions

    or strategies for overcoming these

    challenges. While this is an im-

    portant aspect to consider, a more

    detailed analysis of potential solu-

    tions or strategies could be useful

    for practitioners and researchers in

    the field.

    [55]

    J. M. Jurado

    et al.

    2020

    Individual

    charac-

    terization

    of

    olive

    trees

    through

    multi-

    temporal monitoring and

    multispectral mapping on

    3D models.

    This study proposes an intelligent

    UAV-based system that uses deep

    learning and IoT for crop growth

    monitoring. The authors demon-

    strate the effectiveness of the pro-

    posed system through experiments.

    They conclude that the proposed

    system can accurately monitor crop

    growth and help farmers make in-

    formed decisions.

    The authors used a greenhouse to

    conduct their experiments, which

    may not accurately reflect the chal-

    lenges and limitations of imple-

    menting a UAV-based crop moni-

    toring system in an outdoor agri-

    cultural environment.

    [56]

    P. Rallo et al.

    2020

    Investigating the use of

    UAV imagery to enhance

    genotype selection in olive

    breeding programs.

    This

    paper

    proposes

    a

    novel

    approach

    to

    weed

    detection

    in

    smart

    agriculture

    using

    UAVs

    and deep learning. The authors

    demonstrate the effectiveness of

    the

    proposed

    approach

    through

    experiments.

    They

    conclude

    that the proposed approach can

    accurately

    detect

    weeds

    and

    help farmers reduce the use of

    herbicides.

    The authors used only one type

    of UAV (a DJI Phantom 4 Pro

    drone) for their experiments. Dif-

    ferent types of UAVs have differ-

    ent capabilities, such as flight time,

    payload capacity, and camera qual-

    ity, which could impact the effec-

    tiveness and accuracy of a UAV-

    based weed detection system.

    [57]

    A. Safonova

    et al.

    2021

    Estimating the biovolume

    of olive trees using multi-

    resolution image segmen-

    tation with Mask Region-

    based Convolutional Neu-

    ral Network (R-CNN) on

    UAV imagery.

    The authors demonstrate the fea-

    sibility of the proposed system

    through experiments. They con-

    clude that the proposed system

    can improve crop yield and reduce

    costs for farmers.

    The authors do not address any po-

    tential security or privacy concerns

    related to the use of IoT and UAV-

    based systems in smart farming.

    [58]

    A. Di Nisio

    et al.

    2020

    Rapid

    detection

    of

    olive

    trees

    affected

    by

    Xylella

    fastidiosa

    using

    multispectral

    imaging

    from UAVs.

    This study proposes a UAV-based

    smart farming system that uses

    machine learning and cloud com-

    puting. The authors demonstrate

    the effectiveness of the proposed

    system through experiments. They

    conclude that the proposed system

    can improve crop yield and reduce

    costs for farmers

    The

    system’s

    ability

    to

    handle

    varying weather conditions, crop

    types, and growth stages. Addition-

    ally, the authors do not discuss any

    potential environmental impacts of

    using UAVs for crop monitoring

    and the potential disruption to local

    wildlife.

    [59]

    A.

    Castrignan`o

    et al.

    2021

    Development of a semi-

    automatic approach to de-

    tect Xylella fastidiosa in

    olive trees at an early

    stage. This method uti-

    lizes

    UAV

    multispectral

    imagery.

    This study proposes a UAV-based

    crop monitoring system that uses

    IoT

    The study may have only tested the

    UAV-based crop monitoring system

    in a limited range of environmental

    conditions, which may limit the

    generalizability of the findings.

    [60]

    ˇSiljeg et al.

    2023

    Utilizing

    Geospatial

    Object-Based

    Image

    Analysis

    (GEOBIA)

    and

    Vegetation

    Indices

    for

    extracting

    olive

    tree

    canopies

    from

    highly

    detailed

    UAV

    multispectral imagery.

    This study proposes a UAV-based

    crop monitoring system that uses

    IoT

    The study may have only tested the

    UAV-based crop monitoring system

    in a limited range of environmental

    conditions, which may limit the

    generalizability of the findings.

    www.ijacsa.thesai.org

    1158 | P a g e

    IJACSA-International Journal of Advanced Computer Science and Applications,

    Vol. 14, No. 6, 2023

    TABLE VI. CHARACTERISTICS OF THE RESEARCH: COMPARISON OF IOT ISSUES AND CHALLENGES
    IN UAV APPLICATIONS ON SMART FARMING

    (Y-YES, N-NON AND N/A-NON APPLICABLE)

    Properties

    [61]

    [36]

    [45]

    [54]

    [55]

    [56]

    [62]

    [57]

    [58]

    [59]

    [13]

    Security

    Y

    N

    N

    N

    N

    N

    Y

    N

    N

    N

    N

    Control actuators Network lifetime

    Y

    Y

    N

    N

    N

    Y

    N

    N

    N

    N

    N

    Network latency Transmission reliability Quality of experience

    (QoE)

    Y

    Y

    N

    N

    N

    Y

    N

    N

    N

    N

    N

    Reduce risk of pesticides harming Animals or Human Semantic

    interoperability

    Y

    Y

    N

    N

    N

    Y

    N

    N

    N

    N

    N

    Detection of weather conditions Yes

    Y

    Y

    N

    N

    N

    Y

    N

    N

    N

    N

    N

    Preventive measures using IoT Semantic interoperability

    Y

    Y

    N

    N

    N

    Y

    N

    N

    N

    N

    N

    Architecture

    Y

    Y

    N

    N

    N

    Y

    N

    N

    N

    N

    N

    Reduce communication cost Quality of Service (QoS)

    Y

    Y

    N/A

    N

    N/A

    N/A

    N/A

    N/A

    N/A

    N/A

    N/A

    Sensing and actuators as a service (SaaS) Handle multi-keyword

    search.

    N/A

    N/A

    N/A

    N/A

    Y

    N/A

    Y

    N/A

    N/A

    N

    N

    Failure detection Prediction for IoT

    N/A

    N/A

    N/A

    N

    Y

    N

    N

    N

    N/A

    N/A

    N/A

    Increased computational time Faster detection rate for crop disease

    Y

    N/A

    N/A

    N/A

    N/A

    N/A

    N/A

    N/A

    Y

    Y

    N/A

    Reduced the time of diagnosis of animal illness.

    Y

    Y

    N/A

    N

    N

    Y

    N/A

    N

    N

    N

    N/A

    Enhanced data transmission

    N

    N

    N

    N

    N

    N

    N

    N

    N

    N

    N

    Interactive voice response with farmers Determination of soil

    condition

    N

    N

    N

    N

    N

    N/A

    N/A

    N/A

    N

    N

    N

    Soil conductivity Protection of crop disease using IoT

    N

    N

    N

    N

    N

    N

    N/A

    N/A

    N/A

    N/A

    N/A

    Color-based segmentation for early detection and utilization of

    three-dimensional point cloud

    N/A

    N/A

    N/A

    N/A

    N/A

    N/A

    N/A

    N/A

    N/A

    N/A

    N/A

    Fig. 9. Significant UAV applications in smart farming using AI and cloud.

    infestations, and optimize harvest. While the use of UAV

    systems for crop monitoring has several advantages, there

    are also some limitations to the types of crops that can

    be effectively monitored. Here are some of the limitations

    collected by analyzing the following articles [64], [65], [66].

    So, there are several limitations to using UAVs for crop

    monitoring. Firstly, UAVs can only cover a limited area in

    a single flight, which makes it difficult to monitor large farms

    efficiently. Secondly, UAVs are affected by weather conditions

    and may not be able to fly in adverse weather, which can

    impact data collection. Thirdly, UAVs require skilled operators

    and specialized equipment, which can be costly and time-

    consuming to maintain. Then, regulations around the use of

    UAVs can be complex and vary between countries, which can

    add another layer of complexity to their use in crop monitoring.

    These limitations must be carefully considered when deciding

    whether to use UAVs for crop monitoring and when planning

    a UAV-based monitoring program.

    In conclusion, while UAV systems can be an effective tool

    for crop monitoring, there are limitations to the types of crops

    that can be effectively monitored. Crop height, density, size,

    weather conditions, and sensor limitations are all factors that

    www.ijacsa.thesai.org

    1159 | P a g e

    IJACSA-International Journal of Advanced Computer Science and Applications,

    Vol. 14, No. 6, 2023

    Fig. 10. UAV system technologies.

    can affect the effectiveness of UAV monitoring. Generally,

    UAV systems can provide farmers with valuable insights and

    data to optimize crop management, increase productivity, and

    reduce the use of pesticides and fertilizers.

    RQ3. HOW CAN UAV-BASED TECHNOLOGIES BE

    ADAPTED FOR USE IN DIFFERENT TYPES OF CROPS OR

    FARMING ENVIRONMENTS?

    Precision agriculture involves the use of various tech-

    nologies to optimize crop management and increase yields.

    Unmanned Aerial Vehicle (UAV) systems are becoming in-

    creasingly popular in precision agriculture due to their ability

    to collect high-resolution data quickly and efficiently. Here are

    some UAV system technologies in Fig. 10 that are commonly

    adopted in precision agriculture:

    •

    Multispectral imaging: UAVs equipped with multi-

    spectral cameras can capture images of crops at dif-

    ferent wavelengths, providing valuable information on

    plant health, stress levels, and nutrient deficiencies.

    •

    Thermal imaging: Thermal cameras mounted on UAVs

    can detect differences in temperature across a field,

    helping to identify areas of stress or water deficiency

    in crops.

    •

    Lidar (Light Detection and Ranging): UAVs equipped

    with Lidar technology can create high-resolution 3D

    maps of crops and terrain, which can be used for crop

    modeling and yield prediction.

    •

    Global Positioning System (GPS): UAVs equipped

    with GPS can precisely navigate and collect data on

    a field, helping farmers to monitor crop growth and

    identify problem areas.

    •

    Machine learning and artificial intelligence: UAV sys-

    tems can collect vast amounts of data that can be

    analyzed and processed using machine learning and

    artificial intelligence algorithms.

    •

    Variable rate application (VRA): UAV systems can be

    used for VRA, where the data collected can be used to

    tailor crop management practices to specific areas of a

    field, optimizing inputs like fertilizers and pesticides,

    reducing costs and environmental impact.

    Overall, these UAV system technologies can provide farm-

    ers with detailed information on crop health, growth, and yield

    potential, helping them to make more informed decisions on

    crop management and increase productivity.

    RQ4. WHAT TYPES OF DATA CAN BE OBTAINED

    THROUGH THE USE OF UAVS?

    Unmanned Aerial Vehicles are deployed in various appli-

    cations, including agriculture, environmental monitoring, and

    infrastructure inspection. UAVs are equipped with sensors that

    can capture different types of data. Here are some examples

    of data that can be acquired by UAVs:

    •

    Visual imagery: UAVs can capture high-resolution

    visual imagery using cameras that range from standard

    RGB cameras to more specialized cameras like mul-

    tispectral, hyperspectral, and thermal cameras. These

    images can be used to monitor vegetation health,

    detect anomalies, and map land cover.

    •

    LiDAR: LiDAR sensors can be mounted on UAVs

    to generate high-resolution 3D maps of the terrain,

    vegetation, and structures. This data can be used

    for precise measurements of features such as height,

    volume, and biomass.

    •

    GPS data: UAVs can collect GPS data, which can

    be used to generate maps, track the drone’s position,

    and measure distances. Environmental data: UAVs

    can be equipped with sensors that measure environ-

    mental variables such as temperature, humidity, and

    air quality. This data can be used for environmental

    monitoring and disaster response.

    •

    Magnetic and acoustic data: UAVs can be equipped

    with magnetometers to measure the magnetic field

    of the Earth’s surface. This data can be used for

    geological surveys and mineral exploration. UAVs can

    also be equipped with microphones to capture acoustic

    data.

    Overall, UAVs can capture a wide range of data types,

    which can be used for various applications in fields such as

    agriculture, environmental monitoring, infrastructure inspec-

    tion, and disaster response.

    RQ5. WHICH METHODS OF DATA PROCESSING CAN BE

    EMPLOYED TO ANALYZE THE AGRICULTURAL DATA

    COLLECTED BY UAVS?

    The data acquired by UAVs in precision agriculture can

    be processed and analyzed using various techniques to extract

    useful information. Here are some examples of data processing

    methods that can be used to exploit agricultural data acquired

    by UAVs described in Fig. 11.

    •

    Image processing: UAVs capture high-resolution im-

    ages of crops, which can be processed using image

    processing techniques to extract information such as

    crop health, leaf area index, and crop growth stage.

    www.ijacsa.thesai.org

    1160 | P a g e

    IJACSA-International Journal of Advanced Computer Science and Applications,

    Vol. 14, No. 6, 2023

    Fig. 11. Data processing methods used to exploit data collected by UAV.

    •

    Geographic Information System (GIS): UAV data can

    be integrated with GIS to create maps that provide

    valuable information about crop health, yield, and soil

    properties.

    •

    3D modeling: UAVs can capture data in the form of

    point clouds using LIDAR sensors, which can be used

    to create 3D models of the field. These models can

    be used to estimate crop height, biomass, and plant

    spacing.

    In summary, the data acquired by UAVs in precision agri-

    culture can be processed and analyzed using various techniques

    to extract valuable information about crop health, yield, and

    soil properties. These techniques include image processing,

    GIS, multispectral data analysis, machine learning, and 3D

    modeling.

    RQ6. WHAT ARE THE CHALLENGES ASSOCIATED WITH

    USING DRONES FOR DISEASE DETECTION IN

    AGRICULTURE?

    The challenges can be categorized into two primary

    groups: dataset-related challenges and model-building chal-

    lenges. Dataset-related challenges encompass deformations in

    the image dataset, insufficient availability of expert-labeled

    data, significant randomness in the data, and inadequate repre-

    sentation of classes in the dataset. Challenges associated with

    model building are the scarcity of training samples, extended

    training and processing times. Out of the papers analyzed, only

    two proposed potential solutions for these difficulties. The use

    of UAV in smart farming has become increasingly popular

    due to their ability to collect vast amounts of data quickly

    and accurately. However, the integration of Internet of Things

    (IoT) technologies into UAV applications also brings unique

    challenges and issues. The Table VI provides a comparison

    of the key challenges and issues related to IoT in UAV

    applications for smart farming.

    RQ7. WHAT ARE THE POTENTIAL ETHICAL AND LEGAL

    IMPLICATIONS ASSOCIATED WITH THE USE OF DRONES

    IN AGRICULTURE, AND HOW CAN THESE ISSUES BE

    ADDRESSED?

    The use of drones in agriculture presents various ethical

    and legal implications that need to be considered and ad-

    dressed. From an ethical standpoint, privacy concerns arise

    as drones can capture sensitive information about individuals

    or their properties. There is also the potential for drones to

    infringe on airspace regulations, endangering other aircraft

    or public safety. Furthermore, the automation and autonomy

    of drones raise questions about accountability and liability

    in case of accidents or damage caused by these devices. To

    address these issues, several measures can be implemented.

    Firstly, clear regulations and guidelines should be established

    regarding the operation of drones in agricultural settings. These

    regulations should address aspects such as flight restrictions,

    licensing requirements, and privacy protection. Adequate en-

    forcement mechanisms should be in place to ensure compli-

    ance.

    Secondly, public awareness campaigns and education ini-

    tiatives can inform both farmers and the general public about

    the responsible and legal use of drones in agriculture. This can

    help foster understanding and mitigate privacy concerns. Addi-

    tionally, technological solutions can be developed to enhance

    privacy protection, such as implementing geofencing mecha-

    nisms that restrict drone access to certain areas or utilizing

    data anonymization techniques. Collaboration between stake-

    holders, including farmers, drone operators, regulatory bodies,

    and legal experts, is crucial for developing comprehensive

    guidelines and frameworks that address the ethical and legal

    implications of drone use in agriculture. Regular review and

    updates of regulations can also ensure they remain relevant

    as technology evolves. Ultimately, a balanced approach is

    needed that considers the benefits of drone technology in

    agriculture while safeguarding privacy, public safety, and legal

    compliance.

    www.ijacsa.thesai.org

    1161 | P a g e

    IJACSA-International Journal of Advanced Computer Science and Applications,

    Vol. 14, No. 6, 2023

    TABLE VII. SIGNIFICANT REVIEW STUDIES ON UAV BASED APPLICATIONS ON SMART FARMING
    COMPARED TO THIS SYSTEMATIC REVIEW

    References

    Objectives of the review

    Method/Guidelines

    Analysis Criteria

    Results

    [67]

    Help potential researchers de-

    tect

    relevant

    IoT

    problems

    and, based on the applica-

    tion requirements, adopt suit-

    able technologies.

    SLR

    Recent advancements and chal-

    lenges of Internet of Things in

    smart farming

    The upcoming studies, inventions, and

    initiatives mostly in field of IoT-based

    smart agriculture would improve the

    quality of living for farmers and result

    in significant improvements in the agri-

    cultural sector.

    [68]

    Pinpoints the challenges in im-

    plementing the solutions in the

    farmer’s field in real-time.

    SLR

    Recent trends in computer vision

    such as generative adversarial net-

    works (GAN), vision transformers

    (ViT) and other popular deep learn-

    ing architectures.

    Integration of the deep learning com-

    puter vision approaches with the UAV,

    and spectral data can help in building

    advanced-intelligent solutions.

    [69]

    Presents an analysis of drone

    technologies and their mod-

    ifications

    with

    time

    in

    the

    agriculture sector in the last

    decade.

    SLR

    Artificial Intelligent (AI) and deep

    learning for the remote monitoring

    of crops has

    There is a ramp in drone application for

    precision agriculture after 2017. This

    is due to the reduction of weight, cost

    of UAVs, and increment in payload

    capability

    [26]

    Suggest further research to im-

    prove the current food produc-

    tion globally

    SLR

    The application of smart farming

    to crop and animal production and

    post-harvesting

    An effective Intelligent IoT system for

    smart farming can start the beginning of

    the journey toward by providing more

    information within the farming system

    for non-academics and researchers.

    Proposed

    Systematic

    Review

    Propose future research direc-

    tions and highlight areas of

    improvement for the effective

    implementation of these tech-

    nologies in agriculture.

    SLR & PRISMA

    Data collection and sensing tech-

    nologies, AI and data analysis

    techniques, IoT and connectivity,

    Cloud computing and data manage-

    ment, Performance and effective-

    ness, Challenges and limitations

    Exploration of the integration of un-

    manned aerial systems (UAS), AI, IoT,

    and cloud technologies specifically in

    the context of smart farming, providing

    an up-to-date and in-depth analysis of

    the benefits, challenges, and future re-

    search directions in this rapidly evolv-

    ing field.

    V.

    DISCUSSIONS

    The reason to conduct this systematic review on UAV-

    based applications in smart farming using AI, IoT, and cloud

    technologies is to provide a comprehensive overview of the

    current state-of-the-art in this field. This review aims to gather

    and analyze existing research studies, to identify gaps in the

    literature, and to provide insights into the potential of these

    technologies for smart farming.

    The systematic review will contribute to the research field

    in several ways. Firstly, it will provide a clear understanding

    of the current state-of-the-art in UAV-based applications in

    smart farming, including the various applications, benefits,

    and challenges associated with the use of these technologies.

    Secondly, it will identify gaps in the literature and areas where

    further research is needed. This will help researchers to focus

    their efforts on areas that are most promising and where further

    advancements are needed. Thirdly, it will provide insights into

    the potential of these technologies to transform the agriculture

    industry, promote sustainable farming practices, and address

    global food security challenges.

    UAV-based applications in smart farming using AI, IoT,

    and cloud technologies face several data challenges that must

    be addressed for successful implementation. These challenges

    include acquiring and efficiently storing the large amounts of

    data generated by UAVs, ensuring the quality and reliability

    of the data, processing and analyzing the data in real-time

    using AI and cloud technologies, seamlessly integrating the

    UAV-based applications with other systems, and ensuring

    data privacy and security. Overcoming these challenges will

    require the development of robust data management strategies,

    advanced algorithms for data analysis, secure and interoperable

    systems, and effective policies and regulations for data privacy

    and security. Addressing these challenges will be crucial for

    the successful implementation of UAV-based applications in

    smart farming and the realization of their potential benefits for

    the agricultural industry. Meteorological conditions can have a

    significant impact on UAV-based applications in smart farming

    that use AI, IoT, and cloud technologies. For example, wind

    speed and direction can affect the stability and maneuverability

    of the UAV, which can impact the quality of the data collected.

    Similarly, rain, fog, and low-light conditions can affect the

    quality of the images and sensor readings collected by the

    UAV, which can impact the accuracy of the data analysis.

    Extreme weather conditions such as hurricanes, thunder-

    storms, and blizzards can also pose safety risks for the UAV

    and the personnel operating it. High winds, lightning, and

    heavy precipitation can damage the UAV or cause it to crash,

    while snow and ice can affect its mobility and stability. To mit-

    igate the impact of meteorological conditions on UAV-based

    applications in smart farming, it is important to have reliable

    weather forecasting systems in place. This can help farmers

    and operators plan UAV flights around weather patterns, avoid-

    ing unsafe conditions and optimizing data collection.

    Additionally, it is important to use UAVs equipped with

    weather-resistant sensors and cameras that can operate in a

    range of environmental conditions. This can help ensure the

    accuracy and reliability of the data collected, even in adverse

    weather conditions. In summary, meteorological conditions can

    www.ijacsa.thesai.org

    1162 | P a g e

    IJACSA-International Journal of Advanced Computer Science and Applications,

    Vol. 14, No. 6, 2023

    have a significant impact on UAV-based applications in smart

    farming, and it is important to have reliable weather forecasting

    systems and weather-resistant equipment to mitigate these

    effects.

    Overall, this systematic review will be a valuable resource

    for researchers, policymakers, and practitioners interested in

    UAV-based applications in smart farming using AI, IoT, and

    cloud technologies. It will help to identify areas where further

    research is needed, and provide insights into the potential

    of these technologies to address some of the most pressing

    challenges facing the agriculture industry today.

    By validating and comparing the PRISMA (Preferred Re-

    porting Items for Systematic Reviews and Meta-Analyses)

    results with the presented objectives, scenarios, and analysis

    criteria in Table VII, this systematic review aims to enhance the

    existing survey methodology. It strives to provide an updated

    research review based on established guidelines, which can

    have several advantages. So, by employing a validated method-

    ology and adhering to established guidelines like PRISMA, this

    work aims to provide a reliable, transparent, and up-to-date

    resource that can contribute to the existing body of knowledge

    in UAV-based applications in smart farming using AI, IoT, and

    cloud technologies. Despite the numerous benefits associated

    with the use of UAVs, AI, IoT, and cloud technologies in smart

    farming, there are still some limitations and challenges that

    need to be addressed in the future. One of the main limitations

    is the high cost of acquiring and maintaining these technolo-

    gies, which may limit their adoption by smallholder farmers.

    Another limitation is the lack of regulatory frameworks and

    policies to guide their use, particularly in developing countries.

    Overall, this systematic review will be a valuable resource

    for researchers, policymakers, and practitioners interested in

    UAV-based applications in smart farming using AI, IoT, and

    cloud technologies. It will help to identify areas where further

    research is needed, and provide insights into the potential

    of these technologies to address some of the most pressing

    challenges facing the agriculture industry today. Despite the

    numerous benefits associated with the use of UAVs, AI, IoT,

    and cloud technologies in smart farming, there are still some

    limitations and challenges that need to be addressed in the

    future.

    VI.

    CONCLUSION

    In

    conclusion,

    this

    paper

    provides

    a

    comprehensive

    overview of the utilization of unmanned aerial vehicules

    (UAS), or drones, in agriculture and the integration of AI, IoT,

    and cloud technologies for precision farming. The systematic

    review conducted following the PRISMA method highlights

    the potential of UAV-based applications in smart farming using

    these advanced technologies. The major takeaways from this

    work include the significant potential of UAVs in enhanc-

    ing agricultural productivity and sustainability. The findings

    demonstrate that UAVs offer valuable capabilities for data

    collection, precision monitoring, and decision-making in large-

    scale farming operations. The integration of AI, IoT, and cloud

    technologies further enhances these capabilities by enabling

    real-time data analysis, remote accessibility, and efficient re-

    source management. The justification for this research lies

    in the growing importance of technology-driven solutions

    in modern agriculture. By leveraging UAVs and advanced

    technologies, farmers can make informed decisions, optimize

    resource usage, and improve crop yields. The presented work

    serves as a valuable resource for researchers, policymakers,

    and practitioners interested in understanding the potential and

    challenges of UAV-based applications in smart farming.

    Moving forward, future research should focus on devel-

    oping more advanced machine learning models to enhance

    accuracy in crop yield predictions and pest infestation iden-

    tification. Additionally, exploring the feasibility of drones for

    other agricultural tasks such as irrigation management and soil

    analysis can provide valuable insights. Conducting empirical

    studies will further validate the benefits and limitations of these

    technologies in agriculture.

    REFERENCES

    [1]

    S. Pal, H. VijayKumar, D. Akila, N. Z. Jhanjhi, O. A. Darwish,

    and

    F.

    Amsaad,

    “Information-Centric

    IoT-Based

    Smart

    Farming

    with

    Dynamic

    Data

    Optimization,”

    Computers,

    Materials

    and

    Continua, vol. 74, no. 2, pp. 3865–3880, 2023. [Online]. Available:

    https://doi.org/10.32604/cmc.2023.029038

    [2]

    J. Nie, Y. Wang, Y. Li, and X. Chao, “Sustainable computing in smart

    agriculture: survey and challenges,” Turkish Journal of Agriculture

    and Forestry, vol. 46, no. 4, pp. 550–566, 2022. [Online]. Available:

    https://doi.org/10.55730/1300-011X.3025

    [3]

    A. Cravero, S. Pardo, P. Galeas, J. L´opez Fenner, and M. Caniup´an,

    “Data Type and Data Sources for Agricultural Big Data and Machine

    Learning,” Sustainability (Switzerland), vol. 14, no. 23, pp. 1–37,

    2022. [Online]. Available: https://doi.org/10.3390/su142316131

    [4]

    A. Sharma, E. Podoplelova, G. Shapovalov, A. Tselykh, and A. Tselykh,

    “Sustainable smart cities: Convergence of artificial intelligence and

    blockchain,” Sustainability (Switzerland), vol. 13, no. 23, 2021.

    [Online]. Available: https://doi.org/10.3390/su132313076

    [5]

    A. Abdollahi, K. Rejeb, A. Rejeb, M. M. Mostafa, and S. Zailani,

    “Wireless sensor networks in agriculture: Insights from bibliometric

    analysis,” Sustainability (Switzerland), vol. 13, no. 21, 2021. [Online].

    Available: https://doi.org/10.3390/su132112011

    [6]

    G.

    Giray

    and

    C.

    Catal,

    “Design

    of

    a

    data

    management

    reference

    architecture

    for

    sustainable

    agriculture,”

    Sustainability

    (Switzerland),

    vol.

    13,

    no.

    13,

    2021.

    [Online].

    Available:

    https://doi.org/10.3390/su13137309

    [7]

    Aqeel-Ur-Rehman and Z. A. Shaikh, “Smart agriculture,” Applications

    of Modern High Performance Networks, pp. 120–129, 2009. [Online].

    Available: https://doi.org/10.2174/978160805077210901010120

    [8]

    J. Kim, S. Kim, C. Ju, and H. I. Son, “Unmanned aerial vehicles in agri-

    culture: A review of perspective of platform, control, and applications,”

    IEEE Access, vol. 7, pp. 105 100–105 115, 2019.

    [9]

    D. Loukatos, M. Kondoyanni, G. Alexopoulos, C. Maraveas, and

    K. G. Arvanitis, “On-Device Intelligence for Malfunction Detection

    of Water Pump Equipment in Agricultural Premises: Feasibility and

    Experimentation,” Sensors, vol. 23, no. 2, 2023. [Online]. Available:

    https://doi.org/10.3390/s23020839

    [10]

    A. Saleh, P. Joshi, R. S. Rathore, and S. S. Sengar, “Trust-Aware

    Routing Mechanism through an Edge Node for IoT-Enabled Sensor

    Networks,” Sensors, vol. 22, no. 20, pp. 1–22, 2022. [Online].

    Available: https://doi.org/10.3390/s22207820

    [11]

    N. N. Thilakarathne, M. S. A. Bakar, P. E. Abas, and H. Yassin,

    “A Cloud Enabled Crop Recommendation Platform for Machine

    Learning-Driven Precision Farming,” Sensors, vol. 22, no. 16, 2022.

    [Online]. Available: https://doi.org/10.3390/s22166299

    [12]

    A. Z. Bayih, J. Morales, Y. Assabie, and R. A. de By, “Utilization

    of Internet of Things and Wireless Sensor Networks for Sustainable

    Smallholder Agriculture,” Sensors, vol. 22, no. 9, pp. 1–31, 2022.

    [Online]. Available: https://doi.org/10.3390/s22093273

    [13]

    T. Qayyum, Z. Trabelsi, A. Malik, and K. Hayawi, “Trajectory

    design for uav-based data collection using clustering model in

    smart farming,” Sensors, vol. 22, no. 1, 2022. [Online]. Available:

    https://doi.org/10.3390/s22010037

    www.ijacsa.thesai.org

    1163 | P a g e

    IJACSA-International Journal of Advanced Computer Science and Applications,

    Vol. 14, No. 6, 2023

    [14]

    J.

    Bravo-Arrabal,

    M.

    Toscano-Moreno,

    J.

    J.

    Fernandez-Lozano,

    A. Mandow, J. A. Gomez-Ruiz, and A. Garc´ıa-Cerezo, “The internet

    of cooperative agents architecture (X-ioca) for robots, hybrid sensor

    networks, and mec centers in complex environments: A search and

    rescue case study,” Sensors, vol. 21, no. 23, 2021. [Online]. Available:

    https://doi.org/10.3390/s21237843

    [15]

    Y. Liu, R. Kumar, A. Tripathi, A. Sharma, and M. Rana, “he

    Application of Internet of Things and Oracle Database in the

    Research

    of

    Intelligent

    Data

    Management

    System,”

    Informatica

    (Slovenia), vol. 46, no. 3, pp. 403–410, 2022. [Online]. Available:

    https://doi.org/10.31449/inf.v46i3.4019

    [16]

    R.

    H.

    Ip,

    L.

    M.

    Ang,

    K.

    P.

    Seng,

    J.

    C.

    Broster,

    and

    J.

    E.

    Pratley,

    “Big

    data

    and

    machine

    learning

    for

    crop

    protection,” Computers and Electronics in Agriculture, vol. 151,

    no.

    November

    2017,

    pp.

    376–383,

    2018.

    [Online].

    Available:

    https://doi.org/10.1016/j.compag.2018.06.008

    [17]

    M. v. Sch¨onfeld, R. Heil, and L. Bittner, “Big Data on a Farm—Smart

    Farming,” pp. 109–120, 2018.

    [18]

    S. Himesh, E. V. Prakasa Rao, K. C. Gouda, K. V. Ramesh, V. Rakesh,

    G. N. Mohapatra, B. Kantha Rao, S. K. Sahoo, and P. Ajilesh,

    “Digital revolution and Big Data: A new revolution in agriculture,” CAB

    Reviews: Perspectives in Agriculture, Veterinary Science, Nutrition and

    Natural Resources, vol. 13, no. 021, pp. 1–7, 2018.

    [19]

    S. Wolfert, L. Ge, C. Verdouw, and M. J. Bogaardt, “Big Data in Smart

    Farming – A review,” Agricultural Systems, vol. 153, pp. 69–80, 2017.

    [20]

    P. Placidi, R. Morbidelli, D. Fortunati, N. Papini, F. Gobbi, and

    A.

    Scorzoni,

    “Monitoring

    soil

    and

    ambient

    parameters

    in

    the

    iot precision agriculture scenario: An original modeling approach

    dedicated to low-cost soil water content sensors,” Sensors, vol. 21,

    no. 15, 2021. [Online]. Available: https://doi.org/10.3390/s21155110

    [21]

    A. Chodorek, R. R. Chodorek, and P. Sitek, Monitor Urban and

    Industrial Areas, 2021.

    [22]

    T. Kawai, “Video slice: image compression and transmission for

    agricultural systems,” Sensors, vol. 21, no. 11, 2021. [Online].

    Available: https://doi.org/10.3390/s21113698

    [23]

    J. Majumdar, S. Naraseeyappa, and S. Ankalaki, “Analysis of agriculture

    data using data mining techniques : application of big data,” Journal

    of Big Data, 2017. [Online]. Available: https://doi.org/10.1186/s40537-

    017-0077-4

    [24]

    Y. Kalyani and R. Collier, “A systematic survey on the role

    of

    cloud,

    fog,

    and

    edge

    computing

    combination

    in

    smart

    agriculture,” Sensors, vol. 21, no. 17, 2021. [Online]. Available:

    https://doi.org/10.3390/s21175922

    [25]

    C. Sohrabi, T. Franchi, G. Mathew, A. Kerwan, M. Nicola, M. Griffin,

    M. Agha, and R. Agha, “PRISMA 2020 statement: What’s new and the

    importance of reporting guidelines,” International Journal of Surgery,

    vol. 88, no. March, pp. 39–42, 2021.

    [26]

    G. Idoje, T. Dagiuklas, and M. Iqbal, “Survey for smart farming

    technologies:

    Challenges

    and

    issues,”

    Computers

    and

    Electrical

    Engineering, vol. 92, no. February 2020, p. 107104, 2021. [Online].

    Available: https://doi.org/10.1016/j.compeleceng.2021.107104

    [27]

    B. Kitchenham, O. Pearl Brereton, D. Budgen, M. Turner, J. Bailey,

    and S. Linkman, “Systematic literature reviews in software engineering

    -

    A

    systematic

    literature

    review,”

    Information

    and

    Software

    Technology, vol. 51, no. 1, pp. 7–15, 2009. [Online]. Available:

    http://dx.doi.org/10.1016/j.infsof.2008.09.009

    [28]

    I. Buja, E. Sabella, A. G. Monteduro, M. S. Chiriac`o, L. De Bellis,

    A. Luvisi, and G. Maruccio, “Advances in plant disease detection

    and monitoring: From traditional assays to in-field diagnostics,”

    Sensors,

    vol.

    21,

    no.

    6,

    pp.

    1–22,

    2021.

    [Online].

    Available:

    https://doi.org/10.3390/s21062129

    [29]

    K. A. Awan, I. U. Din, A. Almogren, and H. Almajed, “Agritrust—a

    trust management approach for smart agriculture in cloud-based

    internet of agriculture things,” Sensors (Switzerland), vol. 20, no. 21,

    pp. 1–21, 2020. [Online]. Available: https://doi.org/10.3390/s20216174

    [30]

    M. E. P´erez-Pons, R. S. Alonso, O. Garc´ıa, G. Marreiros, and J. M.

    Corchado, “Deep q-learning and preference based multi-agent system

    for sustainable agricultural market,” Sensors, vol. 21, no. 16, pp. 1–16,

    2021. [Online]. Available: https://doi.org/10.3390/s21165276

    [31]

    Z.

    Nurlan,

    T.

    Zhukabayeva,

    M.

    Othman,

    A.

    Adamova,

    and

    N. Zhakiyev, “Wireless Sensor Network as a Mesh: Vision and

    Challenges,” IEEE Access, vol. 10, pp. 46–67, 2022. [Online].

    Available: https://doi.org/10.1109/ACCESS.2021.3137341

    [32]

    F. S. Alrayes, N. Alshuqayran, M. K. Nour, M. Al Duhayyim,

    A.

    Mohamed,

    A.

    A.

    A.

    Mohammed,

    G.

    P.

    Mohammed,

    and

    I.

    Yaseen,

    “Optimal

    Fuzzy

    Logic

    Enabled

    Intrusion

    Detection

    for

    Secure

    IoT-Cloud

    Environment,”

    Computers,

    Materials

    and

    Continua, vol. 74, no. 3, pp. 6737–6753, 2023. [Online]. Available:

    https://doi.org/10.32604/cmc.2023.032591

    [33]

    S. S. Sarnin, N. J. H. Binti Mohammad, N. F. Naim, N. Ya’acob,

    A. Idris, W. N. Wan Mohamad, and M. N. Md Tan, “Smart insects

    repeller,” Indonesian Journal of Electrical Engineering and Computer

    Science, vol. 17, no. 1, pp. 205–212, 2019. [Online]. Available:

    https://doi.org/10.11591/ijeecs.v17.i1.pp205-212

    [34]

    P.

    Deepika

    and

    B.

    Arthi,

    “Prediction

    of

    plant

    pest

    detection

    using improved mask FRCNN in cloud environment,” Measurement:

    Sensors, vol. 24, no. October, p. 100549, 2022. [Online]. Available:

    https://doi.org/10.1016/j.measen.2022.100549

    [35]

    K. Sharma, C. Sharma, S. Sharma, and E. Asenso, “Broadening the

    Research Pathways in Smart Agriculture: Predictive Analysis Using

    Semiautomatic Information Modeling,” Journal of Sensors, vol. 2022,

    2022. [Online]. Available: https://doi.org/10.1155/2022/5442865

    [36]

    W. Zhao, M. Wang, and V. T. Pham, “Unmanned Aerial Vehicle and

    Geospatial Analysis in Smart Irrigation and Crop Monitoring on IoT

    Platform,” Mobile Information Systems, vol. 2023, 2023. [Online].

    Available: https://doi.org/10.1155/2023/4213645

    [37]

    T.

    Sutikno

    and

    D.

    Thalmann,

    “Insights

    on

    the

    internet

    of

    things:

    past,

    present,

    and

    future

    directions,”

    Telkom-

    nika

    (Telecommunication

    Computing

    Electronics

    and

    Control),

    vol.

    20,

    no.

    6,

    pp.

    1399–1420,

    2022.

    [Online].

    Available:

    https://doi.org/10.12928/TELKOMNIKA.v20i6.22028

    [38]

    A.

    Zervopoulos,

    A.

    Tsipis,

    A.

    G.

    Alvanou,

    K.

    Bezas,

    A. Papamichail, S. Vergis, A. Stylidou, G. Tsoumanis, V. Komianos,

    G. Koufoudakis, and K. Oikonomou, “Wireless sensor network

    synchronization for precision agriculture applications,” Agriculture

    (Switzerland), vol. 10, no. 3, pp. 1–20, 2020. [Online]. Available:

    https://doi.org/10.3390/agriculture10030089

    [39]

    C. G. Prasad, A. Mallareddy, M. Pounambal, and V. Velayutham,

    “Edge Computing and Blockchain in Smart Agriculture Systems,”

    International Journal on Recent and Innovation Trends in Computing

    and Communication, vol. 10, no. 1, pp. 265–274, 2022. [Online].

    Available: https://doi.org/10.17762/ijritcc.v10i1s.5848

    [40]

    M. L. Rathod, A. Shivaputra, H. Umadevi, K. Nagamani, and

    S. Periyasamy, “Cloud Computing and Networking for SmartFarm

    AgriTech,” Journal of Nanomaterials, vol. 2022, no. i, 2022. [Online].

    Available: https://doi.org/10.1155/2022/6491747

    [41]

    C. H. Wu, C. Y. Lu, J. W. Zhan, and H. T. Wu, “Using Long

    Short-Term Memory for Building Outdoor Agricultural Machinery,”

    Frontiers in Neurorobotics, vol. 14, no. May, pp. 1–8, 2020. [Online].

    Available: https://doi.org/10.3389/fnbot.2020.00027

    [42]

    S. Yadav, A. Kaushik, M. Sharma, and S. Sharma, “Disruptive

    Technologies in Smart Farming: An Expanded View with Sentiment

    Analysis,” AgriEngineering, vol. 4, no. 2, pp. 424–460, 2022. [Online].

    Available: https://doi.org/10.3390/agriengineering4020029

    [43]

    C. Bersani, C. Ruggiero, R. Sacile, A. Soussi, and E. Zero, “Internet of

    Things Approaches for Monitoring and Control of Smart Greenhouses

    in Industry 4.0,” Energies, vol. 15, no. 10, 2022. [Online]. Available:

    https://doi.org/10.3390/en15103834

    [44]

    M. Junaid, A. Shaikh, M. U. Hassan, A. Alghamdi, K. Rajab, M. S.

    Al Reshan, and M. Alkinani, “Smart agriculture cloud using AI based

    techniques,” Energies, vol. 14, no. 16, 2021. [Online]. Available:

    https://doi.org/10.3390/en14165129

    [45]

    J.

    Almutairi,

    M.

    Aldossary,

    H.

    A.

    Alharbi,

    B.

    A.

    Yosuf,

    and

    J.

    M.

    Elmirghani,

    “Delay-Optimal

    Task

    Offloading

    for

    UAV-Enabled

    Edge-Cloud

    Computing

    Systems,”

    IEEE

    Access,

    vol.

    10,

    pp.

    51 575–51 586,

    2022.

    [Online].

    Available:

    https://doi.org/10.1109/ACCESS.2022.3174127

    [46]

    B.

    Almadani

    and

    S.

    M.

    Mostafa,

    “IIoT

    based

    multimodal

    communication model for agriculture and agro-industries,” IEEE

    Access,

    vol.

    9,

    pp.

    10 070–10 088,

    2021.

    [Online].

    Available:

    https://doi.org/10.1109/ACCESS.2021.3050391

    www.ijacsa.thesai.org

    1164 | P a g e

    IJACSA-International Journal of Advanced Computer Science and Applications,

    Vol. 14, No. 6, 2023

    [47]

    A. S. Pamula, A. Ravilla, and S. V. H. Madiraju, “Applications of the

    Internet of Things (IoT) in Real-Time Monitoring of Contaminants in

    the Air, Water, and Soil †,” Engineering Proceedings, vol. 27, no. 1,

    2022. [Online]. Available: https://doi.org/10.3390/ecsa-9-13335

    [48]

    E.

    Petkov,

    T.

    Kalushkov,

    D.

    Valcheva,

    and

    G.

    Shipkovenski,

    “Fault Tolerance Smart Egg Incubation System with Computer

    Vision,” International Journal of Advanced Computer Science and

    Applications, vol. 14, no. 2, pp. 511–517, 2023. [Online]. Available:

    https://doi.org/10.14569/IJACSA.2023.0140260

    [49]

    S. Chaterji, N. DeLay, J. Evans, N. Mosier, B. Engel, D. Buckmaster,

    M. R. Ladisch, and R. Chandra, “Lattice: A Vision for Machine

    Learning, Data Engineering, and Policy Considerations for Digital

    Agriculture

    at

    Scale,”

    IEEE

    Open

    Journal

    of

    the

    Computer

    Society, vol. 2, no. June, pp. 227–240, 2021. [Online]. Available:

    https://doi.org/10.1109/ojcs.2021.3085846

    [50]

    S. Katiyar and A. Farhana, “Smart Agriculture: The Future of

    Agriculture

    using

    AI

    and

    IoT,”

    Journal

    of

    Computer

    Science,

    vol.

    17,

    no.

    10,

    pp.

    984–999,

    2021.

    [Online].

    Available:

    https://doi.org/10.3844/jcssp.2021.984.999

    [51]

    M. Z. Islam, R. Ali, A. Haider, and H. S. Kim, “QoS Provisioning:

    Key Drivers and Enablers Toward the Tactile Internet in Beyond

    5G Era,” IEEE Access, vol. 10, pp. 85 720–85 754, 2022. [Online].

    Available: https://doi.org/10.1109/ACCESS.2022.3197900

    [52]

    Y. Gong, K. Chen, T. Niu, and Y. Liu, “Grid-Based coverage

    path planning with NFZ avoidance for UAV using parallel self-

    adaptive ant colony optimization algorithm in cloud IoT,” Journal

    of Cloud Computing, vol. 11, no. 1, 2022. [Online]. Available:

    https://doi.org/10.1186/s13677-022-00298-2

    [53]

    R.

    Winkler,

    “MeteoMex:

    open

    infrastructure

    for

    networked

    environmental

    monitoring

    and

    agriculture

    4.0,”

    PeerJ

    Computer

    Science,

    vol.

    7,

    pp.

    1–23,

    2021.

    [Online].

    Available:

    https://doi.org/10.7717/PEERJ-CS.343

    [54]

    N. A. Sehree and A. M. Khidhir, “Olive trees cases classification based

    on deep convolutional neural network from unmanned aerial vehicle

    imagery,” Indonesian Journal of Electrical Engineering and Computer

    Science, vol. 27, no. 1, pp. 92–101, 2022. [Online]. Available:

    https://doi.org/10.11591/ijeecs.v27.i1.pp92-101

    [55]

    J. M. Jurado, L. Ortega, J. J. Cubillas, and F. R. Feito, “Multispectral

    mapping on 3D models and multi-temporal monitoring for individual

    characterization of olive trees,” Remote Sensing, vol. 12, no. 7, pp.

    1–26, 2020. [Online]. Available: https://doi.org/10.3390/rs12071106

    [56]

    P.

    Rallo,

    A.

    I.

    de

    Castro,

    F.

    L´opez-Granados,

    A.

    Morales-

    Sillero, J. Torres-S´anchez, M. R. Jim´enez, F. M. Jim´enez-Brenes,

    L.

    Casanova,

    and

    M.

    P.

    Su´arez,

    “Exploring

    UAV-imagery

    to

    support genotype selection in olive breeding programs,” Scientia

    Horticulturae, vol. 273, no. July, p. 109615, 2020. [Online]. Available:

    https://doi.org/10.1016/j.scienta.2020.109615

    [57]

    A. Safonova, E. Guirado, Y. Maglinets, D. Alcaraz-Segura, and

    S. Tabik, “Olive tree biovolume from uav multi-resolution image

    segmentation with mask r-cnn,” Sensors, vol. 21, no. 5, pp. 1–17,

    2021. [Online]. Available: https://doi.org/10.3390/s21051617

    [58]

    A. D. Nisio, F. Adamo, G. Acciani, and F. Attivissimo, “Fast

    detection of olive trees affected by xylella fastidiosa from uavs using

    multispectral imaging,” Sensors (Switzerland), vol. 20, no. 17, pp.

    1–23, 2020. [Online]. Available: https://doi.org/10.3390/s20174915

    [59]

    A. Castrignan`o, A. Belmonte, I. Antelmi, R. Quarto, F. Quarto,

    S. Shaddad, V. Sion, M. R. Muolo, N. A. Ranieri, G. Gadaleta,

    E. Bartoccetti, C. Riefolo, S. Ruggieri, and F. Nigro, “Semi-automatic

    method for early detection of xylella fastidiosa in olive trees using

    uav multispectral imagery and geostatistical-discriminant analysis,”

    Remote Sensing, vol. 13, no. 1, pp. 1–23, 2021. [Online]. Available:

    https://doi.org/10.3390/rs13010014

    [60]

    A. S. R. M. F. D. M. J. I. M. L. P. D. R. R. Milosevic,

    “GEOBIA and Vegetation Indices in Extracting Olive Tree Canopies

    Based on Very High-Resolution UAV Multispectral Imagery,” Applied

    Sciences (Switzerland), vol. 13, no. 2, 2023. [Online]. Available:

    https://doi.org/10.3390/app13020739

    [61]

    M. A. Uddin, A. Mansour, D. L. Jeune, M. Ayaz, and E. H. M.

    Aggoune, “Uav-assisted dynamic clustering of wireless sensor networks

    for crop health monitoring,” Sensors (Switzerland), vol. 18, no. 2,

    2018. [Online]. Available: https://doi.org/10.3390/s18020555

    [62]

    K. Neupane and F. Baysal-Gurel, “Automatic identification and

    monitoring of plant diseases using unmanned aerial vehicles: A

    review,” Remote Sensing, vol. 13, no. 19, 2021. [Online]. Available:

    https://doi.org/10.3390/rs13193841

    [63]

    A. D. Boursianis, M. S. Papadopoulou, P. Diamantoulakis, A. Liopa-

    Tsakalidi, P. Barouchas, G. Salahas, G. Karagiannidis, S. Wan, and

    S. K. Goudos, “Internet of Things (IoT) and Agricultural Unmanned

    Aerial Vehicles (UAVs) in smart farming: A comprehensive review,”

    Internet of Things (Netherlands), vol. 18, no. xxxx, p. 100187, 2022.

    [Online]. Available: https://doi.org/10.1016/j.iot.2020.100187

    [64]

    K. Zou, X. Chen, F. Zhang, H. Zhou, and C. Zhang, “A field weed

    density evaluation method based on uav imaging and modified u-net,”

    Remote Sensing, vol. 13, no. 2, pp. 1–19, 2021. [Online]. Available:

    https://doi.org/10.3390/rs13020310

    [65]

    T. B. Shahi, C. Y. Xu, A. Neupane, D. Fresser, D. O’Connor,

    G. Wright, and W. Guo, “A cooperative scheme for late leaf

    spot estimation in peanut using UAV multispectral images,” PloS

    one,

    vol.

    18,

    no.

    3,

    p.

    e0282486,

    2023.

    [Online].

    Available:

    http://dx.doi.org/10.1371/journal.pone.0282486

    [66]

    S. F. di Gennaro, E. Battiston, S. di Marco, O. Facini, A. Matese,

    M. Nocentini, A. Palliotti, and L. Mugnai, “Unmanned Aerial Vehicle

    (UAV)-based remote sensing to monitor grapevine leaf stripe disease

    within a vineyard affected by esca complex,” Phytopathologia Mediter-

    ranea, vol. 55, no. 2, pp. 262–275, 2016.

    [67]

    B. B. Sinha and R. Dhanalakshmi, “Recent advancements and

    challenges of Internet of Things in smart agriculture: A survey,”

    Future Generation Computer Systems, vol. 126, pp. 169–184, 2022.

    [Online]. Available: https://doi.org/10.1016/j.future.2021.08.006

    [68]

    V. G. Dhanya, A. Subeesh, N. L. Kushwaha, D. K. Vishwakarma,

    T. Nagesh Kumar, G. Ritika, and A. N. Singh, “Deep learning

    based computer vision approaches for smart agricultural applications,”

    Artificial Intelligence in Agriculture, vol. 6, pp. 211–229, 2022.

    [Online]. Available: https://doi.org/10.1016/j.aiia.2022.09.007

    [69]

    A. Hafeez, M. A. Husain, S. P. Singh, A. Chauhan, M. T. Khan,

    N. Kumar, A. Chauhan, and S. K. Soni, “Implementation of drone

    technology for farm monitoring & pesticide spraying: A review,”

    Information Processing in Agriculture, vol. 10, no. 2, pp. 192–203,

    2022. [Online]. Available: https://doi.org/10.1016/j.inpa.2022.02.002

    www.ijacsa.thesai.org

    1165 | P a g e

    '
  inline_citation: '>'
  journal: International Journal of Advanced Computer Science and Applications
  limitations: '>'
  pdf_link: http://thesai.org/Downloads/Volume14No6/Paper_123-Unmanned_Aerial_Vehicle_based_Applications_in_Smart_Farming.pdf
  publication_year: 2023
  relevance_score1: 0
  relevance_score2: 0
  title: 'Unmanned Aerial Vehicle-based Applications in Smart Farming: A Systematic
    Review'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.20944/preprints202307.1162.v1
  analysis: '>'
  authors:
  - Natalia M. Matsveichuk
  - Yuri N. Sotskov
  citation_count: 1
  full_citation: '>'
  full_text: '>

    This website uses cookies We use cookies to personalise content and ads, to provide
    social media features and to analyse our traffic. We also share information about
    your use of our site with our social media, advertising and analytics partners
    who may combine it with other information that you’ve provided to them or that
    they’ve collected from your use of their services. Consent Selection Necessary
    Preferences Statistics Marketing Show details             Deny Allow selection
    Allow all Instructions for Authors Awards About FAQ Submit Log in/Register preprints.org
    > biology and life sciences > agricultural science and agronomy > doi: 10.20944/preprints202307.1162.v1
    Preprint Review Version 1 Preserved in Portico This version is not peer-reviewed
    Digital Technologies, Internet of Things and Cloud Computations Used in Agriculture:
    Surveys and Literature in Russian Natalia M. Matsveichuk and Yuri N. Sotskov *
    Version 1 : Received: 17 July 2023 / Approved: 17 July 2023 / Online: 18 July
    2023 (13:51:22 CEST) How to cite: Matsveichuk, N.M.; Sotskov, Y.N. Digital Technologies,
    Internet of Things and Cloud Computations Used in Agriculture: Surveys and Literature
    in Russian. Preprints 2023, 2023071162. https://doi.org/10.20944/preprints202307.1162.v1
    Copy Abstract Development of agriculture in Russia and Belarus is based on the
    practical implementation of "smart" systems in agriculture based on the use of
    modern wireless, intelligent technologies and Internet of Things. This review
    presents research articles (mainly, in Russian) published in the period of 2013
    – 2022 on the use of cloud technologies and Internet of Things for the development
    of agriculture in Russia and Belarus. An analysis of the use of cloud technologies
    and Internet of Things in the modern world is given on the basis of research articles
    and reviews published in English in the period of 2017 – 2022. The main directions
    of digitalization of modern agriculture are listed. The uses of cloud technologies
    and Internet of Things in agriculture are described along with promising directions
    for further research and applications. Keywords modern agriculture; smart farming;
    cloud computing; internet of things; survey Subject Biology and Life Sciences,
    Agricultural Science and Agronomy Copyright: This is an open access article distributed
    under the Creative Commons Attribution License which permits unrestricted use,
    distribution, and reproduction in any medium, provided the original work is properly
    cited. Download PDF Comments (0) We encourage comments and feedback from a broad
    range of readers. See criteria for comments and our Diversity statement. Leave
    a public comment Send a private comment to the author(s) * All users must log
    in before leaving a comment Related Articles Peer-review Articles Smart Farming
    Techniques for Climate Change Adaptation in Cyprus George Adamides et al. Atmosphere,
    2020 Smart Agriculture and Rural Revitalization and Development Based on the Internet
    of Things under the Background of Big Data Xi Ma Sustainability, 2023 IoT Sensing
    Platform as a Driver for Digital Farming in Rural Africa Antonio Oliveira-Jr et
    al. Sensors, 2020 Precision Agriculture Design Method Using a Distributed Computing
    Architecture on Internet of Things Context Francisco Ferrández-Pastor et al. Sensors,
    2018 Exploring the Adoption of Precision Agriculture for Irrigation in the Context
    of Agriculture 4.0: The Key Role of Internet of Things Sergio Monteleone et al.
    Sensors, 2020 Irriman Platform: Enhancing Farming Sustainability through Cloud
    Computing Techniques for Irrigation Management Manuel Forcén-Muñoz et al. Sensors,
    2021 Applying Adaptive Security Techniques for Risk Analysis of Internet of Things
    (IoT)-Based Smart Agriculture Abdur Riaz et al. Sustainability, 2022 A Cloud-Based
    IoT Platform for Precision Control of Soilless Greenhouse Cultivation Alaa Sagheer
    et al. Sensors, 2020 A Review on Security of Smart Farming and Precision Agriculture:
    Security Aspects, Attacks, Threats and Countermeasures Abbas Yazdinejad et al.
    Applied Sciences, 2021 LoRaFarM: A LoRaWAN-Based Smart Farming Modular IoT Architecture
    Gaia Codeluppi et al. Sensors, 2020 Views 93 Downloads 213 Comments 0 Get PDF
    Cite Share 0 Bookmark BibSonomy Mendeley Reddit Delicious Alerts Notify me about
    updates to this article or when a peer-reviewed version is published. Preprints.org
    is a free preprint server subsidized by MDPI in Basel, Switzerland. Contact us
    RSS MDPI Initiatives SciProfiles Sciforum Encyclopedia MDPI Books Scilit Proceedings
    JAMS Important links How it Works Advisory Board FAQ Friendly Journals Instructions
    for Authors About Statistics Subscribe Choose the area that interest you and we
    will send you notifications of new preprints at your preferred frequency. Subscribe
    © 2024 MDPI (Basel, Switzerland) unless otherwise stated Disclaimer Privacy Policy
    Terms of Use  Feedback'
  inline_citation: '>'
  journal: ''
  limitations: '>'
  pdf_link: null
  publication_year: 2023
  relevance_score1: 0
  relevance_score2: 0
  title: 'Digital Technologies, Internet of Things and Cloud Computations Used in
    Agriculture: Surveys and Literature in Russian'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1007/978-3-031-17040-9
  analysis: '>'
  authors:
  - Bernd Stahl
  - Doris Schroeder
  - Rowena Rodrigues
  citation_count: 1
  full_citation: '>'
  full_text: '>

    Your privacy, your choice We use essential cookies to make sure the site can function.
    We also use optional cookies for advertising, personalisation of content, usage
    analysis, and social media. By accepting optional cookies, you consent to the
    processing of your personal data - including transfers to third parties. Some
    third parties are outside of the European Economic Area, with varying standards
    of data protection. See our privacy policy for more information on the use of
    your personal data. Manage preferences for further information and to change your
    choices. Accept all cookies Skip to main content Advertisement Log in Find a journal
    Publish with us Track your research Search Cart Book Open Access © 2023 Ethics
    of Artificial Intelligence Case Studies and Options for Addressing Ethical Challenges
    Home Book Authors: Bernd Carsten Stahl , Doris Schroeder , Rowena Rodrigues    Is
    open access, which means that you have free and unlimited access Provides the
    first book collection of real-life AI ethics case studies Each AI ethics case
    study is accompanied by commentary and possible solutions Written accessibly without
    jargon to be suitable for a wide range of audiences Part of the book series: SpringerBriefs
    in Research and Innovation Governance (BRIEFSREINGO) 83k Accesses 10 Citations
    113 Altmetric Sections Table of contents About this book Keywords Reviews Authors
    and Affiliations About the authors Bibliographic Information Publish with us Table
    of contents (9 chapters) Search within book Search Front Matter Pages i-xii PDF
    The Ethics of Artificial Intelligence: An Introduction Bernd Carsten Stahl, Doris
    Schroeder, Rowena Rodrigues Pages 1-7Open Access PDF Unfair and Illegal Discrimination
    Bernd Carsten Stahl, Doris Schroeder, Rowena Rodrigues Pages 9-23Open Access PDF
    Privacy Bernd Carsten Stahl, Doris Schroeder, Rowena Rodrigues Pages 25-37Open
    Access PDF Surveillance Capitalism Bernd Carsten Stahl, Doris Schroeder, Rowena
    Rodrigues Pages 39-52Open Access PDF Manipulation Bernd Carsten Stahl, Doris Schroeder,
    Rowena Rodrigues Pages 53-61Open Access PDF Right to Life, Liberty and Security
    of Persons Bernd Carsten Stahl, Doris Schroeder, Rowena Rodrigues Pages 63-78Open
    Access PDF Dignity Bernd Carsten Stahl, Doris Schroeder, Rowena Rodrigues Pages
    79-93Open Access PDF AI for Good and the SDGs Bernd Carsten Stahl, Doris Schroeder,
    Rowena Rodrigues Pages 95-106Open Access PDF The Ethics of Artificial Intelligence:
    A Conclusion Bernd Carsten Stahl, Doris Schroeder, Rowena Rodrigues Pages 107-111Open
    Access PDF Back Matter Pages 113-116 PDF Back to top About this book This open
    access collection of AI ethics case studies is the first book to present real-life
    case studies combined with commentaries and strategies for overcoming ethical
    challenges. Case studies are one of the best ways to learn about ethical dilemmas
    and to achieve insights into various complexities and stakeholder perspectives.
    Given the omnipresence of AI ethics in academic, policy and media debates, the
    book will be suitable for a wide range of audiences, from scholars of different
    disciplines (e.g. AI science, ethics, politics, philosophy, economics) to policy-makers,
    lobbying NGOs, teachers and the educated public.  Back to top Keywords Open Access
    Artificial intelligence, AI Ethics of technology Computer ethics Information ethics
    Responsible research and innovation Back to top Reviews “Ethical Machines: Your
    Concise Guide to Totally Unbiased, Transparent, and Respectful AI, the first book
    in this brief literature review … . This is explained by the intended audience
    of the book, which presents itself as a practical handbook for policy makers,
    engineers, and other professionals involved in the design, development, and deployment
    of AI. … The book is systematically structured. … The illustrative examples drawn
    from real-life events are one of the main assets of this book.” (Christian Goglin,
    Journal of Business Ethics, Vol. 188 (3), 2023)  “The present book examines the
    complex ethical landscape surrounding AI. … The concluding chapter serves as a
    synthesis of the ethical concerns and debates surrounding AI as discussed throughout
    the book. The core argument revolves around the notion that the ethical challenges
    posed by AI are often not intrinsic to the technology itself, but arise from its
    application, deployment, and reliability in various contexts.” (M. Caramihai,
    Computing Reviews, November 10, 2023) Back to top Authors and Affiliations School
    of Computer Science, University of Nottingham, Nottingham, UK Bernd Carsten Stahl
    Centre for Professional Ethics, University of Central Lancashire, Preston, UK
    Doris Schroeder Trilateral Research, London, UK Rowena Rodrigues Back to top About
    the authors   Bernd Carsten Stahl is Professor of Critical Research in Technology
    at the School of Computer Science of the University of Nottingham and former Director
    of the Centre for Computing and Social Responsibility at De Montfort University,
    Leicester, UK. His interests cover philosophical issues arising from the intersections
    of business, technology, and information. This includes ethical questions of current
    and emerging of ICTs, critical approaches to information systems and issues related
    to responsible research and innovation.     Doris Schroeder is Professor of Moral
    Philosophy and Director at the Centre for Professional Ethics, UCLan UK and Professor
    in the School of Law at UCLan Cyprus. Her specialist areas of expertise are research
    ethics and inclusive research and innovation. She is the lead author of the Global
    Code of Conduct for Research in Resource-Poor Settings which is now used in over
    50 countries after adoption by the European Commission and NATURE.   Rowena Rodrigues
    (Phd) is Head of Innovation & Research Services at Trilateral Research Ltd and
    co-leads and works to drive the growth of the Innovation & Research services in
    defined strategic business areas. She carries out legal, ethical and policy research
    related to new and emerging technologies (e.g., AI, robotics) and provides regulatory,
    industry and policy advice. She co-edited Privacy and Data Protection Seals (TMC
    Asser/Springer 2018). Back to top Bibliographic Information Book Title Ethics
    of Artificial Intelligence Book Subtitle Case Studies and Options for Addressing
    Ethical Challenges Authors Bernd Carsten Stahl, Doris Schroeder, Rowena Rodrigues
    Series Title SpringerBriefs in Research and Innovation Governance DOI https://doi.org/10.1007/978-3-031-17040-9
    Publisher Springer Cham eBook Packages Religion and Philosophy, Philosophy and
    Religion (R0) Copyright Information The Editor(s) (if applicable) and The Author(s)
    2023 Softcover ISBN 978-3-031-17039-3 Published: 02 November 2022 eBook ISBN 978-3-031-17040-9
    Published: 01 November 2022 Series ISSN 2452-0519 Series E-ISSN 2452-0527 Edition
    Number 1 Number of Pages XII, 116 Number of Illustrations 1 b/w illustrations,
    5 illustrations in colour Topics Engineering Ethics, Artificial Intelligence,
    Philosophy of Technology, Computers and Society Back to top Publish with us Policies
    and ethics Back to top Download book PDF Download book EPUB Buy it now Buying
    options Softcover Book USD 37.99 Tax calculation will be finalised at checkout
    Other ways to access Licence this eBook for your library Learn about institutional
    subscriptions Discover content Journals A-Z Books A-Z Publish with us Publish
    your research Open access publishing Products and services Our products Librarians
    Societies Partners and advertisers Our imprints Springer Nature Portfolio BMC
    Palgrave Macmillan Apress Your privacy choices/Manage cookies Your US state privacy
    rights Accessibility statement Terms and conditions Privacy policy Help and support
    129.93.161.219 Big Ten Academic Alliance (BTAA) (3000133814) - University of Nebraska-Lincoln
    (3000134173) © 2024 Springer Nature'
  inline_citation: '>'
  journal: SpringerBriefs in research and innovation governance
  limitations: '>'
  pdf_link: null
  publication_year: 2023
  relevance_score1: 0
  relevance_score2: 0
  title: Ethics of Artificial Intelligence
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'

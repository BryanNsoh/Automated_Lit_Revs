- DOI: https://doi.org/10.3390/agriengineering2030029
  analysis: '>'
  authors:
  - Zongmei Gao
  - Zhongwei Luo
  - Wen Zhang
  - Zhenzhen Lv
  - Yanlei Xu
  citation_count: 52
  full_citation: '>'
  full_text: ">\nAgriEngineering\nReview\nDeep Learning Application in Plant Stress\
    \ Imaging:\nA Review\nZongmei Gao 1\n, Zhongwei Luo 2, Wen Zhang 2,*\n, Zhenzhen\
    \ Lv 2,* and Yanlei Xu 3\n1\nDepartment of Biological Systems Engineering, Center\
    \ for Precision and Automated Agricultural Systems,\nWashington State University,\
    \ Prosser, WA 99350, USA; zongmei.gao@wsu.edu\n2\nSchool of Life Science and Engineering,\
    \ Southwest University of Science and Technology,\nMianyang 621010, China; zhongweiluo593@gmail.com\n\
    3\nCollege of Information and Technology, JiLin Agricultural University, Changchun\
    \ 130118, China;\nyanleixu@jlau.edu.cn\n*\nCorrespondence: wenzhang@swust.edu.cn\
    \ (W.Z.); zhenzhenlv139@gmail.com (Z.L.);\nTel.: +86-816-6089521 (W.Z.)\nReceived:\
    \ 19 May 2020; Accepted: 7 July 2020; Published: 14 July 2020\n\x01\x02\x03\x01\
    \x04\x05\x06\a\b\x01\n\x01\x02\x03\x04\x05\x06\a\nAbstract: Plant stress is one\
    \ of major issues that cause signiﬁcant economic loss for growers.\nThe labor-intensive\
    \ conventional methods for identifying the stressed plants constrain their\napplications.\
    \ To address this issue, rapid methods are in urgent needs. Developments of advanced\n\
    sensing and machine learning techniques trigger revolutions for precision agriculture\
    \ based on deep\nlearning and big data. In this paper, we reviewed the latest\
    \ deep learning approaches pertinent\nto the image analysis of crop stress diagnosis.\
    \ We compiled the current sensor tools and deep\nlearning principles involved\
    \ in plant stress phenotyping. In addition, we reviewed a variety of deep\nlearning\
    \ applications/functions with plant stress imaging, including classiﬁcation, object\
    \ detection,\nand segmentation, of which are closely intertwined. Furthermore,\
    \ we summarized and discussed the\ncurrent challenges and future development avenues\
    \ in plant phenotyping.\nKeywords: deep learning; convolutional neural network;\
    \ crop stress; precision phenotyping\n1. Plant Stress and Sensors\nPlant stress\
    \ is one of the major threats to crops causing signiﬁcant reduction of crop yield\n\
    and quality [1]. The detection and diagnosis of the plant stress is urgently needed\
    \ for rapid and\nrobust application of precision agriculture in crop measurement.\
    \ Presently, intensive studies focus\non developing optical imaging methods for\
    \ plant disease detection. Diﬀerent from the conventional\nmethods using the visual\
    \ scoring, optical imaging is advanced to measure changes caused by abiotic\n\
    or biotic stressors in the plant physiology rapidly and without contact. In general,\
    \ the common\nimaging technologies have been employed for detecting the crop stress,\
    \ including digital, ﬂuorescence,\nthermography, LIDAR, multispectral, and hyperspectral\
    \ imaging techniques [2]. The common optical\nsensors used for plant stress detection\
    \ are shown in Figure 1.\nAgriEngineering 2020, 2, 430–446; doi:10.3390/agriengineering2030029\n\
    www.mdpi.com/journal/agriengineering\nAgriEngineering 2020, 2\n431\nFigure 1.\
    \ Typical optical sensors used for plant stress detection. (a) Digital sensor\
    \ for maize heat\nstress [3]; (b) multispectral imaging sensor for maize water\
    \ stress [4]; (c) ﬂuorescence imaging sensor\nfor chilling injury of tomato seedlings\
    \ [5]; (d) thermal imaging sensor for potato water stress [6], and (e)\nhyperspectral\
    \ imaging sensor for apple water stress [7].\nDigital imaging sensors acquire\
    \ the visible range of wavelengths, i.e., RGB colored images with red,\nblue,\
    \ and green channels to detect plant diseases. Such images provide physical attributes\
    \ of the plants,\nsuch as canopy vigor, leaf color, leaf texture, size, and shape\
    \ information [8]. Color and texture features\nare important for identifying the\
    \ characteristic diﬀerence between healthy and symptomatic plants.\nFrequently\
    \ used color features are RGB, LAB, YCBCR, and HSV spaces [9]. Additionally, contrast,\n\
    homogeneity, dissimilarity, energy, and entropy features of images are descriptive\
    \ facets of texture [10].\nIn other words, quantitative diagnosis features for\
    \ identifying the symptomatic and healthy plants\nhave been collected in these\
    \ images.\nThermal imaging sensors obtain infrared radiating images ranging from\
    \ 8 to 12 µm, which are\noften applied for predicting plant temperatures. Under\
    \ the infection, the temperature of infected plant\ntissues varies and related\
    \ to the impacts caused by pathogens. The temperature variance, other the\nhand,\
    \ appears with a counter-eﬀect on transpiration rate [11]. In other words, stress\
    \ from the infection\ntrigger both transpiration rate decrease and leaf temperature\
    \ increase, resulting in stomatal closure\nin plants. In turn, based on these\
    \ alterations, thermal imaging sensors could identify the infection\ndiseases.\
    \ Each pixel of the thermal image represents the temperature value of the object,\
    \ which is\nexpressed in manners of false color. In plant disease detection, the\
    \ thermal sensor could be mounted to\nground automated vehicles (GAV) and unmanned\
    \ aerial vehicles (UAV).\nFluorescence imaging sensors are often utilized to identify\
    \ variations of plant photosynthetic\nactivity [12]. The diﬀerences of stressed\
    \ and healthy leaves will be expressed in the diﬀerences of\nphotosynthetic activities,\
    \ which will be assessed by the photosynthetic electron transform using the\n\
    ﬂuorescence imaging sensor with an LED or laser illumination. For normal cases,\
    \ 685 nm is the\nAgriEngineering 2020, 2\n432\nwavelength at which chlorophyll\
    \ ﬂuorescence is emitted from photo-system II (PSII). The stressed\nplants could\
    \ change the patterns of chlorophyll ﬂuorescence emission, which could be reﬂected\
    \ and\nobserved in the ﬂuorescence imaging [13].\nBased on the number of spectral\
    \ bands in the optical sensing technologies, sensors contain 3–10 spectral\nbands\
    \ are named multispectral imaging sensors. The multispectral imaging sensors normally\
    \ extract a few\nor a stack of images from the visible to near-infrared spectrum\
    \ [14]. Plant stress often causes an increase in\nvisible reflectance, with a\
    \ decrease in chlorophyll and absorption of visible light. Additionally, reduced\n\
    near infrared (NIR) reflectance will happen due to changes of the leaf tissue.\
    \ Thus, the most used band\nchannels are green, red, red-edge and NIR. Multispectral\
    \ imaging sensor combined with drones have been\napplied broadly in remote sensing\
    \ for plant disease detection [15], while this type of sensors is limited to a\n\
    few spectral bands and sometimes cannot quantify the diseased plants severity.\n\
    Despite many successful studies having been applied to crop stress detection using\
    \ cheap\npassive imagery sensors, i.e., digital and near infrared (NIR), most\
    \ of the applications require fast\nimage processing and computational algorithms\
    \ for image analysis. Among the image analysis\ntechniques, supervised methods\
    \ have been popular with training data being used to develop a system.\nSuch methods\
    \ include shape segmentation, feature extraction, and classiﬁers for stress diagnosis.\n\
    In addition, machine learning algorithms search for the optimal decision boundary\
    \ in the feature space\nwith high dimensionality, which provides the basis for\
    \ many available image analysis systems [16].\nFor improving the image analysis\
    \ systems, deep learning has played a key role. Deep neural networks\nhave many\
    \ layers which transform input images to outputs (i.e., healthy or stressed) with\
    \ learning deep\nfeatures. The most applied networks are convolutional neural\
    \ networks (CNNs) in crop image analysis.\nCNNs consist of dozens or hundreds\
    \ of layers that process the images with convolution filters with a\nrespective\
    \ small size of batches [17]. Despite such initial successes, CNNs cannot collect\
    \ momentum\nwithout the advances in core computing systems and deep convolutional\
    \ networks become the current\nfocus. In agriculture, deep learning shows accepted\
    \ performance considering accuracy and efficiency based\non large datasets. To\
    \ build precise classifiers for improving plant disease diagnosis, the PlantVillage\
    \ project\n(https://plantvillage.psu.edu/posts/6948-plantvillage-dataset-download)\
    \ has obtained a large number of\nimages of healthy and diseased crops for free\
    \ [18]. Combined with the big data, deep learning has been put\nforwarded as the\
    \ future promising method in plant phenotyping [19]. For example, CNNs can effectively\n\
    detect and diagnose plant diseases [20] and classify plant fruits in the field\
    \ [21]. The promising results\npromote studies carrying out other phenotyping\
    \ tasks using deep learning, such as leaf morphological\nclassification [22].\
    \ Thus, we read many references about the utilization of deep learning in image-based\n\
    crop stress detection. Summarizing, with this paper we aim to:\n1.\nState the\
    \ principle of deep learning in the application for crop stress diagnosis based\
    \ on images.\n2.\nSearch for the challenges of deep learning in crop stress imaging.\n\
    3.\nHighlight the future directions that could be helpful for circumventing the\
    \ challenges in plant\nphenotyping tasks.\n2. Deep Learning Principle\n2.1. Machine\
    \ Learning\nMachine learning is a subset of artiﬁcial intelligence which is used\
    \ to operate speciﬁc tasks by\ncomputer systems [23]. In general, it is split\
    \ into supervised and unsupervised learning methods.\nSupervised learning methods\
    \ are expressed with an input matrix of independent x and dependent\ny variables.\
    \ This dependent variable of y has few formats, varying based on solving problems.\n\
    For classiﬁcation issues, y is usually a scalar for representing the category\
    \ labels, and it is a vector\ncontaining continuous values under regression [24].\
    \ Under segmented learning conditions, y is\nsometimes the ground truth label\
    \ image [25]. Supervised learning methods often aim to ﬁnd optimal\nmodel parameters,\
    \ which could predict the data to the greatest extent based on the loss function.\n\
    AgriEngineering 2020, 2\n433\nUnsupervised learning methods operate data processing\
    \ without dependent labels and aim to\nsearch for patterns (e.g., latent variables).\
    \ Common unsupervised learning methods include principal\ncomponent analysis (PCA),\
    \ k-nearest neighbors clustering, and T-distributed stochastic neighbor\nembedding\
    \ clustering [26]. Unsupervised training usually uses many diﬀerent loss functions\
    \ to process,\nsuch as reconstructing the loss function. The model must learn\
    \ to reconstruct the loss function in a\nsmaller dimension to reconstruct the\
    \ input data [27].\n2.2. Neural Network\nA neural network is built to recognize\
    \ patterns and provides the basis for most deep learning\nalgorithms [28]. A neural\
    \ network contains nodes that integrate input data with a set of coeﬃcients\n\
    and weights with amplify or dampen the input for learning the assigned tasks,\
    \ e.g., the common\nactivation function α and parameters Θ = \bw, β\t, here, w\
    \ represents the weights and β represents the\nbiases. An activation function\
    \ is normally followed by an elemental nonlinear factor/coeﬃcient σ, as a\ntransfer\
    \ function, as shown in Equation (1) [28]:\nα = σ\n\x10\nWTx + b\n\x11\n(1)\n\
    Sigmoidal and hyperbolic tangent functions are the common transfer functions for\
    \ neural networks.\nThe multilayer perceptron (MLP) is the most popular one in\
    \ traditional neural networks, with few\nconversion layers [28]:\nf(x; Θ) = σ\n\
    \x10\nWLσ\n\x10\nWL−1 . . . σ\n\x10\nW0x + b0\x11\n+ bL−1\x11\n+ bL\x11\n(2)\n\
    where WL is a matrix containing rows wk that is related with activation k in the\
    \ output, and L is the ﬁnal\nlayer. The so-called hidden layers are the layers\
    \ between input and output layers. A neural network\nwith many layers is often\
    \ called deep neural network (DNN), thence deep learning. The activation of\n\
    the last layer is mapped to distribution on the class P (y|x; Θ) through a softmax\
    \ function [28]:\nP\n\x10\ny\n\f\f\fx; Θ\n\x11\n= softmax (x; Θ) =\ne(WL\ni )Tx+bL\n\
    i\nPK\nk=1 e(WL\nk )Tx+bL\nk\n(3)\nwhere WL\ni is the weight vector associated\
    \ with class i to the output node. The typical diagram of deep\nneural network\
    \ MLP is shown in Figure 2.\nFigure 2. Typical architectures of deep neural network\
    \ used in imaging analysis. (a) autoencoder and\n(b) convolutional neural network.\n\
    AgriEngineering 2020, 2\n434\nCurrently, stochastic gradient descent (SGD) is\
    \ the famous method for ﬁtting the parameter Θ\nto process a small population\
    \ dataset. With SGD, a small batch is employed in each gradient and\nmaximum likelihood\
    \ optimization is used to minimize the negative impact of the log-likelihood.\n\
    It tracks the log loss for a binary classiﬁcation task and the softmax loss for\
    \ multiclass classiﬁcation.\nA disadvantage of this method is that it usually\
    \ does not directly optimize the quantity of interest [28].\nDNN became popular\
    \ in 2016, when it performed layer-by-layer training (pre-training) in an\nunsupervised\
    \ manner, and then supervised and ﬁne-tuned the stacked network to obtain good\n\
    performance. Such a DNN architecture includes a stacked autoencoder (SAE) and\
    \ a deep summary\nnetwork (DBN). However, such methods are often complex, which\
    \ need a great deal of engineering\nto obtain acceptable results [28,29]. Recently,\
    \ end-to-end training has been conducted on popular\narchitectures in a supervised\
    \ manner by streamlining the training procedure. The common architectures\nare\
    \ CNN and recurrent neural network (RNN) [30,31]. CNN has been widely used for\
    \ image analysis,\nand RNN is becoming more and more popular.\n2.3. Convolutional\
    \ Neural Network\nThe main diﬀerence between MLP and CNN is reﬂected in two aspects.\
    \ First, weights of the\nCNN architecture are shared with a network when the architecture\
    \ operates convolutions on the input\nimage [32]. In this way, separate detector\
    \ learning is not required for the same object appearing at\ndiﬀerent locations\
    \ in the image. As a result, the network is equally variable in the translation\
    \ of input\nimages. In addition, the number of parameters to be learned is reduced.\n\
    During CNN training, the input images are convolved with a set of K kernels W\
    \ =\n\bW1, W2, W3, . . . WK\n\t and biases β =\nn\nb1, . . . , bK\no\nin the convolution\
    \ layer, yielding a new feature\nmap Xk. Such features are exposed to a nonlinear\
    \ transformation parameter σ and such process would\nrepeat for each respective\
    \ convolutional layer l [32]:\nXl\nk = σ\n\x10\nWl−1\nk\n× Xl−1 + bl−1\nk\n\x11\
    \n(4)\nSecond, the main diﬀerence between MLP and CNN is the pooling layer. In\
    \ such layers, the pixels\nof the neighborhood are added based on the permutation\
    \ invariant function in CNN. This may prompt\na certain amount of rendering invariance\
    \ [33]. Then, the fully connected layers are usually added\nwith constant weights\
    \ after convolutional processing. Then, the softmax function is used to provide\n\
    activation information in the last layer, resulting in a category assignment.\
    \ A typical CNN architecture\nis shown in Figure 3 for identifying the ripeness\
    \ of strawberry based on hyperspectral imagery [34].\nFigure 3. One typical CNN\
    \ architecture for estimating the ripeness of strawberry based on hyperspectral\n\
    imagery [34]. Note: Conv represents convolutional layer; FC: fully connected layer.\n\
    AgriEngineering 2020, 2\n435\n2.4. CNN Architecture\nCNN normally uses a 2D image\
    \ as input, with a format of m × n × 3 (m × n × 1 for greyscale\nimages), where\
    \ m and n are the respective image height and width, and 3 is the number of image\n\
    channels. The CNN architecture often contains a few diﬀerent layers, including\
    \ convolutional layers,\npooling layers, and fully connected layers. The convolutional\
    \ and pooling layers are initial layers. A set\nof convolutional kernels (also\
    \ called ﬁlters) is used for each layer performing multiple transformations.\n\
    The convolution operations extract the associated features from small slices divided\
    \ from the full image.\nEach kernel is applied to the input slice and the output\
    \ of each kernel is applied to non-linear processing\nunits, making it capable\
    \ of learning abstraction and embedding non-linearity in the feature space [35].\n\
    The non-linear processing provides diﬀerent patterns of activations corresponding\
    \ to diﬀerent responses,\nwhich helps learn the semantic diﬀerences over the full\
    \ image. Then, the subsampling is applied to the\noutput of non-linear processing,\
    \ with summarizing the results and making the input insensitive to\nthe geometric\
    \ deformation [36]. The CNN architecture has been applied to many aspects, including\n\
    classiﬁcation, segmentation, and object detection, etc.\n2.4.1. Classiﬁcation\
    \ Architectures\nAmong the pre-trained networks, AlexNet is commonly used for\
    \ images classiﬁcation, which is\nrelatively simple with ﬁve convolutional layers.\
    \ The activation function of AlexNet is the hyperbolic\ntangent, which is the\
    \ most common choice in CNNs [37]. Then, the deep pre-trained networks appeared,\n\
    such as the VGG19 with 19 deep layers, winning the ImageNet challenge of 2014\
    \ [38]. These deeper\nnetworks use smaller stacked kernels and have lower memory\
    \ during inference, which improves\nthe performance of mobile computing devices,\
    \ such as smartphones [39]. Later, in 2015, the ResNet\narchitecture won the ImageNet\
    \ challenge and was made up of the ResNet blocks. The residual blocks\nlearn the\
    \ residuals and pre-processes the learning mapping for each layer, thereby providing\
    \ eﬀective\ntraining performance for deeper architectures. Szegedy et al. (2016)\
    \ developed a 22-layer neural\nnetwork referred as GoogLeNet, which employed the\
    \ inception blocks [40]. The advantage of using the\ninception blocks is that\
    \ it could increase the training process eﬃciency while decreasing the number\n\
    of parameters. The performance on ImageNet reached saturation after 2014 and crediting\
    \ the better\nperformance to the more complex architectures is biased. On the\
    \ other hand, it is not necessary\nto perform plant stress detection with the\
    \ deeper networks, providing a lower memory footprint.\nTherefore, AlexNet or\
    \ other relatively simple methods, such as VGG16, are still practical for crop\n\
    stress images.\n2.4.2. Segmentation Architectures\nSegmentation is important in\
    \ crop stress image analysis. The pixel in the image could be classiﬁed\nby the\
    \ CNN and the classiﬁed pixel could be presented with patches that extracted from\
    \ neighboring\npixels [41]. The disadvantage of this method is that the input\
    \ patches overlap, and the same convolution\nis repeatedly calculated. Fortunately,\
    \ the linear operators (convolution and dot product) can be written\nas convolutions\
    \ [42]. With a fully connected layer, a CNN can have a larger input image than\
    \ the\ntrained image and can generate a likelihood map instead of the output of\
    \ a pixel. Then, such a full\nconvolutional network can be eﬀectively applied\
    \ to the full input image.\n2.5. Hardware and Software\nThe dramatic increase\
    \ of deep learning applications could be due to the widespread development\nof\
    \ GPUs [43]. GPU computing started when NVIDIA launched CUDA (Computing Uniﬁed\
    \ Device\nArchitecture) and AMD launched Stream. The GPU is a highly parallel\
    \ computing engine which\noﬀers a great advantage compared with a central processing\
    \ unit (CPU). The Open Computing\nLanguage (OpenCL) uniﬁes diﬀerent GPU general\
    \ computing application programming interface\n(API) implementations and provides\
    \ a framework that can be used to write programs that execute on\nAgriEngineering\
    \ 2020, 2\n436\nheterogeneous platforms composed of a CPU and GPU. With the hardware,\
    \ deep learning on the GPU\nis much faster than on the CPU [44].\nOpen source\
    \ software packages also promote the development and application of deep learning.\n\
    These software packages allow users to operate the computing at a high level without\
    \ having to worry\nabout eﬃcient implementation. By far the most popular packages\
    \ include:\nCaﬀé, which oﬀers C++ and python interfaces, developed by graduate\
    \ students at UC Berkeley\nAI Research.\nTensorFlow, which provides C++ and python\
    \ interfaces, developed by Google Brain team.\nTheano, which provides a python\
    \ interface, developed by MILA lab in Montreal.\nPyTorch, which provides C++ and\
    \ python interface, developed by Facebook’s AI Research lab.\n3. Applications\
    \ of Deep Learning in Plant Stress Imaging\n3.1. Classiﬁcation\nDeep learning\
    \ has been applied successfully in plant phenotyping combined with various sensors\n\
    and speciﬁc tasks, including harvesting crop counting, weed control, and crop\
    \ stress detection [17,45–47].\nRegarding crop stress detection, with various\
    \ speciﬁc tasks, the image analysis methods are often\nvarying among classiﬁcation,\
    \ segmentation, and object detection in crop stress detection combined\nwith various\
    \ sensors (Figure 4). Image classiﬁcation is one of the earliest areas where deep\
    \ learning\ncontributed signiﬁcantly to the analysis of plant stress images. In\
    \ crop stress image classiﬁcation, one or\nmore images are usually used as input\
    \ data, and a diagnostic decision is used as output (e.g., healthy\nor diseased).\
    \ In this case, each diagnosis is a sample, and the size of the dataset is usually\
    \ smaller\ncompared to computer vision (thousands or millions of samples). Therefore,\
    \ for such applications,\nthe transfer learning should be popular for researchers.\
    \ Transfer learning essentially uses pre-trained\nnetworks to try to meet the\
    \ needs of deep network training on large datasets. At present, two transfer\n\
    learning methods are commonly applied: (1) the speciﬁc pre-trained network is\
    \ directly applied in\nimages processing, and (2) ﬁne-tuning the speciﬁed pre-trained\
    \ network for the aiming objective\nimages. Another beneﬁt of the former strategy\
    \ is that training a deep network is not necessary, making\nit easy to insert\
    \ the extracted features into existing image analysis pipelines. However, it is\
    \ still a\nchallenge to ﬁnd the best strategy. Barbedo (2019) used a CNN to classify\
    \ individual lesions and spots\non plant leaves instead of considering the entire\
    \ leaf [45]. This identiﬁed multiple diseases that aﬀect\nthe same leaf. The accuracy\
    \ obtained using this method was, on average, 12% higher than that obtained\n\
    using the original image. While proper symptom segmentation is still required\
    \ manually, preventing\nfull automation. Also, in this paper, the authors applied\
    \ deep learning to detect the individual lesions\nand spots for 14 plant species.\
    \ Speciﬁcally, this study used a pre-trained GoogLeNet CNN for training\nthe models.\
    \ The images were split into two groups for addressing diﬀerent objectives. The\
    \ ﬁrst group\nwas aimed to image classiﬁcation, to identify the origin of the\
    \ observed symptom, while the second one\nwas for object detection, which was\
    \ to identify disease areas amidst healthy tissue and to determine if\nsubsequent\
    \ classiﬁcation was conducted or not. The results showed that accuracies obtained\
    \ using this\napproach were, in average, 12% higher than those achieved using\
    \ the original images. The accuracies\nwere higher than 75% for all the considered\
    \ conditions or number of detected diseases, while the author\nalso claimed that\
    \ the resized input images for pre-trained neural network were not as advantageous\
    \ as\nthe original images under certain conditions. Other studies that applied\
    \ the deep learning into the\ncrop stress image classiﬁcation are shown in Table\
    \ 1.\nAgriEngineering 2020, 2\n437\nFigure 4. Applications of deep learning for\
    \ crop stress detection based on diﬀerent image analysis.\n(a) Classiﬁcation (images\
    \ from [47]), (b) segmentation (images from [48]), and (c) object detection\n\
    (images from [49]).\nTable 1. Applications of deep learning for crop stress classiﬁcation.\n\
    Reference\nSensor\nStress Type\nMethod\nApplication\n[50]\nRGB sensor\nBiotic\n\
    CNN pre-trained with\nAlexNet\nApple leaf Diseases\n[51]\nRGB sensor\nBiotic\n\
    CNN pre-trained with\nGoogLeNet\nCassava leaf Diseases\n[52]\nRGB sensor\nBiotic\n\
    FCN pre-trained with VGG,\nCNN pre-trained with VGG\nWheat leaf diseases\n[53]\n\
    RGB sensor\nBiotic\nCNN\nMaize leaf disease\n[54]\nRGB sensor\nAbiotic\nDNN\n\
    Tomato water stress\n[55]\nRGB sensor\nAbiotic and\nbiotic\nFaster R-CNN, R-FCN,\
    \ SSD\npre-trained with VGG,\nResNet\nNine tomato diseases\nand pests\n[56]\n\
    RGB sensor\nBiotic\nCNN pretrained with\nVGG16 and MSVM\nFive major diseases of\n\
    eggplant\n[57]\nRGB sensor\nAbiotic and\nbiotic\nCNN\nEight diﬀerent soybean\n\
    stresses\n[58]\nHyperspectral\nimaging\nBiotic\nCNN and RNN\nWheat Fusarium head\n\
    blight disease\nAgriEngineering 2020, 2\n438\nTable 1. Cont.\nReference\nSensor\n\
    Stress Type\nMethod\nApplication\n[59]\nRGB sensor\n(datasets from\nplantVillage)\n\
    Biotic\nVGG 16, Inception V4,\nResNet, DenseNets\n38 diﬀerent classes\nincluding\
    \ diseased and\nhealthy images of leaves\nof 14 plants\n[60]\nRGB sensor\nBiotic\n\
    SIFT encoding and CNN\npretrained with MobileNet\nGrapevine esca disease\n[61]\n\
    RGB sensor\nAbiotic\nDCNN pretrained with\nResNet\nMaize drought stress\n[62]\n\
    RGB sensor\n(datasets from\nplantVillage)\nBiotic\nCNN pretrained with\nAlexNet,\
    \ GoogLeNet,\nInception v3, ResNet-50,\nResNet-101 and SqueezeNet.\nGrapevine\
    \ yellows\ndisease\n[63]\nRGB sensor\nBiotic\nCNN\nRice blast disease\n[64]\n\
    RGB sensor\n(datasets from AI\nChallenger Global\nAI Contest)\nBiotic\nPD2SE-Net\
    \ based on CNN\nand ResNet\nApple, cherry, corn,\ngrape, peach, pepper,\npotato,\
    \ strawberry,\ntomato diseases\n[65]\nSmartphones\nBiotic\nCNN AlexNet, GoogLeNet,\n\
    ResNet, VGG16,\nMobileNetV2\nCoﬀee leaves with rust,\nbrown leaf spot and\ncercospora\
    \ leaf spot\n[66]\nHyperspectral\nimaging\nBiotic\nCNN\nYellow rust in winter\n\
    wheat\n[67]\nRGB sensor\nBiotic\nCNN\n14 crop species with\n38 classes of diseases.\n\
    [68]\nHyperspectral\nimaging\nBiotic\nGAN\nTomato spotted wilt\nvirus\n[69]\n\
    RGB sensor\nBiotic\nGAN, VGG16\nTea red scab, tea red leaf\nspot and tea leaf\
    \ blight\nNote: SIFT: Scale-invariant feature transform.\n3.2. Segmentation\n\
    Segmentation is used to identify the set of pixels or contours that make up the\
    \ target object [70].\nSegmentation is a common topic in papers applying deep\
    \ learning to plant disease imaging.\nVarious methods have been applied to segmentation,\
    \ such as developing unique segmentation\narchitectures based on CNNs and application\
    \ of RNNs. The popular segmentation CNN architectures\ninclude U-Net and Mask\
    \ R-CNN [71]. U-Net was investigated in biomedical image segmentation\nﬁrstly\
    \ [72], which was built upon a fully convolutional network (FCN). FCN is to provide\
    \ one\ncontracting network by continuous layers in which pooling layers are substituted\
    \ by up-sampling\noperators. The continuous layer would learn to gather a more\
    \ precise output, with an increase of\nthe resolution of the output. U-Net is\
    \ symmetric, that is, it has the same number of up-sampling\nand down-sampling\
    \ layers. The skip connections in U-Net use a concatenation operator between the\n\
    up-sampling and down-sampling layers [73]. This method connects the features in\
    \ the contact path\nand the extension path. This means that the entire image is\
    \ enabled to be processed forward through\nU-Net to directly generate a segmentation\
    \ mapping. In this way, U-Net could consider the entire image,\nwhich make it\
    \ more advanced than the patch-based CNN. Furthermore, Çiçek et al. (2016) built\
    \ one\n3D U-Net segmentation by replacing all 2D operations with their 3D counterparts\
    \ [74]. Lin et al. (2019)\napplied a U-Net CNN to segment and detect cucumber\
    \ powdery mildew-infected cucumber leaves\nobtained by an RGB sensor [46]. In\
    \ this study, since the powdery mildew-infected pixels were less than\nthat of\
    \ non-infected pixels, the authors proposed binary cross entropy loss function\
    \ to magnify the\nAgriEngineering 2020, 2\n439\nloss value of the powdery mildew-infected\
    \ pixels by 10 times. The results showed that the semantic\nsegmentation CNN model\
    \ achieved an average pixel accuracy of 96.08% for segmenting the diseased\npowdery\
    \ mildew on cucumber leaf images. It was still challenging to apply such deep\
    \ neural network\nin ﬁeld conditions. Diﬀerent applications of deep learning into\
    \ the crop stress image segmentation are\nsummarized in Table 2.\nTable 2. Applications\
    \ of deep learning for crop stress segmentation.\nReference\nSensor\nStress Type\n\
    Method\nApplication\n[75]\nSmart phone\nBiotic\nCNN\nCucumber diseases\n[76]\n\
    RGB (from Plant\nVillage, datasets)\nBiotic\nFractal Texture Analysis\n(SFTA)\
    \ and local binary\npatterns (LBP) combined with\nVGG16 and Caﬀe-AlexNet\nFruit\
    \ crops diseases\n[77]\nRGB sensor\nBiotic\nMask R-CNN\nRice leaf diseases\n[78]\n\
    RGB sensor (from AI\nChallenger 2019)\nBiotic\nCNN pre-trained with U-Net\nNineteen\
    \ plant\ndiseases\n[79]\nRGB sensor\nBiotic\nGlobal pooling dilated\nconvolutional\
    \ neural network\n(GPDCNN)\nCucumber leaf\ndisease\nR-CNN combines rectangular\
    \ region proposals with CNN features. Generally, R-CNN includes\ntwo-stage detection\
    \ procedures. Firstly, the algorithm detects subset regions of an image which\
    \ may\ncontain an object and extracts CNN features from the region proposals.\
    \ Then the object in each region\nis classiﬁed. R-CNN takes a large amount of\
    \ training of the deep neural network when there are\n2000 or more region proposals\
    \ per image that need to be classiﬁed. Meanwhile, there is no learning\nprocedure\
    \ at the ﬁrst searching stage as the selective search algorithm is ﬁxed. As a\
    \ result, it may lead\nto tricky candidate region proposals being generated [80,81].\
    \ During R-CNN processing, the region\nproposals need to be cropped and resized,\
    \ while the Faster R-CNN detector processes the entire\nimage. Thus, Faster R-CNN\
    \ can be applied for real-time object detection. Additionally, Faster R-CNN\n\
    is the backbone of Mask R-CNN. Faster R-CNN includes two outputs, that is, a class\
    \ label and a\nbounding-box oﬀset. A third branch is added to mask R-CNN upon\
    \ faster R-CNN architecture, which\noutputs the object mask [71]. In addition,\
    \ Mask R-CNN is one of the instance segmentation algorithms\nwhich produce a mask\
    \ that uses color or grayscale values to identify pixels belonging to the same\n\
    object. Except to feed the feature map to the region proposal network and the\
    \ classiﬁer, Mask R-CNN\nuses a feature map to predict a binary mask for the object\
    \ inside the bounding box.\n3.3. Object Detection\nObject detection is a key part\
    \ in imaging diagnosis and one of the most laborious tasks.\nTypically, the task\
    \ involves locating and identifying objects throughout the image [82]. For a long\n\
    time, the research goal of computer vision was to automatically detect objects,\
    \ for improving detection\naccuracy, and reducing labor. The object detection\
    \ based on deep learning uses CNN for pixel\nclassiﬁcation and then applies some\
    \ post-processing to obtain object candidates [81–83]. Since the\nimage classiﬁcation\
    \ is to classify each pixel in the image, which is basically equal to object classiﬁcation,\n\
    thereby the CNN architectures of segmentation are alike to those for the classiﬁcation\
    \ task, while the\nimage labels imbalance, hard negative detecting, and eﬃcient\
    \ processing image pixels etc., still remain\nas the challenging issues to be\
    \ addressed for object detection. Fuentes et al., (2017) applied Faster\nR-CNN\
    \ and a VGG-16 detector to recognize tomato plant diseases and pests [55]. Diseases\
    \ and pests\ncould be identiﬁed using the bounding-box and score for each class\
    \ being shown on each infected leaf.\nThat is, the detection method provides a\
    \ solution for detecting the class and location of diseases in\ntomato plants\
    \ practically. R-CNN and Faster R-CNN have been applied to object detection as\
    \ well,\nAgriEngineering 2020, 2\n440\nusing the regions in the image to locate\
    \ the object. Recently, the YOLO algorithm has often been\napplied for object\
    \ detection, which uses a single convolutional network to predict the bounding\
    \ boxes\nand classify such boxes [84]. The YOLO algorithm divides the image into\
    \ an M × M grid, then m\n(m<M) bounding boxes are taken within each of the grids.\
    \ The network yields a class probability\nfor each bounding box. When the bounding\
    \ boxes have higher class probability than a threshold\nvalue, they would be selected\
    \ and applied for locating the objects in the image. The limitation of the\nYOLO\
    \ network is that it sometimes cannot identify small objects in the images [84].\
    \ Singh et al. (2020)\napplied Faster R-CNN with an InceptionResnetV2 model and\
    \ a MobileNet model on PlantVillage\ndatasets to detect plant disease, which included\
    \ 2598 images from 13 plants and over 17 diseases [85].\nOther applications for\
    \ object detection are summarized in Table 3.\nTable 3. Application of deep learning\
    \ for crop stress object detection.\nReference\nSensor\nStress Type\nMethod\n\
    Application\n[55]\nRGB sensor\nAbiotic and\nbiotic\nFaster R-CNN, R-FCN\nNine\
    \ tomato diseases\nand pests\n[60]\nRGB sensor\nBiotic\nCNN pretrained with\n\
    RetinaNet\nGrapevine esca disease\n[82]\nRGB sensor\nBiotic\nYOLOv2 and YOLOv3\n\
    Mosquito bugs and red\nspider mites\n[83]\nRGB sensor\nBiotic\nMask R-CNN\nNorthern\
    \ leaf blight of\nmaize\n[86]\nSmartphone\nBiotic\nFaster R-CNN\nRice false smut\n\
    [87]\nRGB image from\nthe Internet\nBiotic\nFaster R-CNN and Mask\nR-CNN\nTen\
    \ tomato disease\n[88]\nSmartphones\nBiotic\nFaster R-CNN\nStrawberry\nverticillium\
    \ wilt\n[89]\nRGB image\nBiotic\nFaster R-CNN\nSweet Pepper Disease\nand Pest\n\
    4. Unique Challenges in Plant Stress Based on Imagery\nNoncontact plant stress\
    \ detection has been conducted on diﬀerent application scales, i.e., laboratory,\n\
    ground-based, and UAV. Additionally, the modality has been operated based on a\
    \ variety of sensors,\nsuch as digital, thermal, multispectral, and hyperspectral\
    \ imagery, with diﬀerent numbers of spectral\nchannels, from three to hundreds.\
    \ Such sensors could monitor the size, shape, and structural features\nor crops\
    \ based on the external views obtained from digital cameras. The digital sensors\
    \ could be\neasily operated under the natural light environment. Hyperspectral\
    \ imaging sensors could obtain the\ninside spectral signatures beyond the visible\
    \ wavelength range which could reﬂect the healthy crop\nconditions in a wide range\
    \ of spectra, while most of the commercial hyperspectral imaging sensors\ncould\
    \ only work in laboratory with controlled light conditions at present. On the\
    \ other hand, the wind\nwill make the crops move around. In general, for image\
    \ acquisition, it is still challenging for ﬁeld work.\nFurther, the crops are\
    \ not static:\nthe physiological properties change with their growth.\nEspecially\
    \ for biotic stress infected crops, the fungi or viruses in the crops have great\
    \ impacts\non the physiological changes. It will be diﬃcult to detect the stress\
    \ at an early stage without symptoms\nshowing based on image analysis. Further,\
    \ for the application of deep learning-assisted image analysis,\na lack of datasets\
    \ is a major obstacle as well. At present, the available open source images are\
    \ mainly\nfrom the PlantVillage dataset. On the other hand, one signiﬁcant challenge\
    \ is that of ground-truth\nlabelling, which is hugely laborious. The Amazon SageMaker\
    \ Ground Truth provides a service for\nmanaging the labelling, including two features.\
    \ One is annotation consolidation, which combines\nAgriEngineering 2020, 2\n441\n\
    diﬀerent people’s annotation task results into one high-ﬁdelity label. The second\
    \ one is automated\ndata labeling, which utilizes machine learning to label portions\
    \ of the provided data automatically.\nMoreover, to detect crop stress, the classiﬁcation\
    \ and segmentation are often used as binary\ntasks, i.e., healthy versus infected,\
    \ target infected area versus background. However, since these\ntwo categories\
    \ can be highly heterogeneous, this is usually a general simpliﬁcation. For instance,\n\
    the samples of the healthy class mainly consist of completely healthy objects\
    \ but also rarely few objects\nshowing early stresses. This could lead to classiﬁers\
    \ that are able to exclude the healthy samples but\ncannot identify the few rare\
    \ ones. The strategy for this case is to make a deep learning system with\nmulticlass\
    \ by giving it detailed annotations of all possible classes. Meanwhile, the within-class\
    \ variance\nfrom images may reduce the sensitivity of the deep learning system.\
    \ However, the between-classes\nvariance from a dataset that may not be generalized\
    \ to every image, such as the diﬀerent severity of\ndisease images, can obtain\
    \ a pseudo-deep learning training architecture in one certain experiment,\nbut\
    \ obstruct the usefulness of its broad application to practical decision-making\
    \ unless the nature of\nthis dataset is precisely understood. Parameter optimization\
    \ of the deep learning training models, i.e.,\nbatch size, learning rate, dropout\
    \ rate, etc., is a remaining challenge as well. There is currently no exact\n\
    method to achieve the best combinations of hyperparameters, which is often operated\
    \ empirically,\neven though Bayesian optimization has been put forwarded.\n5.\
    \ Outlook\nDeep learning has been applied successfully in plant stress (i.e.,\
    \ abiotic, and biotic stress) detection\neven though it still has many challenges.\
    \ Most of the papers we have reviewed are based on the 2D\nimages for symptomatic\
    \ stages, for example the digital and greyscale images. Such images could be\n\
    enabled to operate in the deep transfer learning architecture, such as Alexnet,\
    \ VGG, GoogleNet, while\nsuch pre-trained transfer networks could not be applied\
    \ to the 3D datasets, such as hyperspectral\nimages, which are more sensitive\
    \ to detecting the early-infected plants. In the future, deep neural\nnetworks\
    \ that can be used for 3D images should be the focus and early detections of plant\
    \ disease is\npivotal to the precision disease management, especially for diseases\
    \ without therapy using pesticide.\nOn the other hand, many tasks in plant stress\
    \ detection analysis could be granted, such as classiﬁcation,\nand such a strategy\
    \ may not be always optimal since it probably requires some post-processing, such\n\
    as segmentation. Further, semi-supervised and unsupervised deep learning are worthy\
    \ of being\nexploratory in the application of plant stress detection, though most\
    \ of studies are based on supervised\napproaches. The advantage of unsupervised\
    \ methods is that the networks training process could be\noperated without the\
    \ ground truth labels. The unsupervised approach for detecting the plant stress\n\
    are generative adversarial networks (GANs) [90], while another common unsupervised\
    \ approach,\ni.e., variational autoencoders (VAEs), is rarely applied for crop\
    \ disease diagnosis yet based on our\nknowledge [91]. Further, deep learning has\
    \ been applied for other objectives in agricultural imaging,\ne.g., crop load\
    \ estimation and harvesting, while image reconstruction remains unexplored, especially\n\
    for LiDAR point cloud data. In general, deep learning has provided promising results\
    \ in plant stress\ndetection, which could accelerate the development of precision\
    \ agriculture with the extension of\nﬁeld application.\nAuthor Contributions:\
    \ Conceptualization, Z.G., Y.X.; Supervision, W.Z.; Visualization, Z.L. (Zhongwei\
    \ Luo), Z.L.\n(Zhenzhen Lv); Writing—Original Draft Preparation, Z.G.; Writing—Review\
    \ & Editing, Z.G. and W.Z.; All authors\nhave read and agreed to the published\
    \ version of the manuscript.\nFunding: This research was funded by [National Natural\
    \ Science Foundation of China] grant number [31801625];\n[Applied Basic Research\
    \ Program of Science and Technology Department of Sichuan Province] grant number\n\
    [2019YJ0444]; [Program of Key Laboratory of Modern Agricultural Equipment and\
    \ Technology, Ministry of\nEducation] grant number [JNZ201919], and [Longshan\
    \ Academic Talent Research Supporting Program of SWUST]\ngrant number [17LZX546].\n\
    Conﬂicts of Interest: The authors declare no conﬂict of interest.\nAgriEngineering\
    \ 2020, 2\n442\nReferences\n1.\nCattivelli, L.; Rizza, F.; Badeck, F.W.; Mazzucotelli,\
    \ E.; Mastrangelo, A.M.; Francia, E.; Stanca, A.M.\nDrought tolerance improvement\
    \ in crop plants:\nAn integrated view from breeding to genomics.\nField Crop.\
    \ Res. 2008, 105, 1–14. [CrossRef]\n2.\nAraus, J.L.; Cairns, J.E. Field high-throughput\
    \ phenotyping: The new crop breeding frontier. Trends Plant Sci.\n2014, 19, 52–61.\
    \ [CrossRef] [PubMed]\n3.\nElazab, A.; Ordóñez, R.A.; Savin, R.; Slafer, G.A.;\
    \ Araus, J.L. Detecting interactive eﬀects of N fertilization and\nheat stress\
    \ on maize productivity by remote sensing techniques. Eur. J. Agron. 2016, 73,\
    \ 11–24. [CrossRef]\n4.\nZhang, L.; Zhang, H.; Niu, Y.; Han, W. Mapping maize\
    \ water stress based on UAV multispectral remote\nsensing. Remote Sens. 2019,\
    \ 11, 605. [CrossRef]\n5.\nDong, Z.; Men, Y.; Liu, Z.; Li, J.; Ji, J. Application\
    \ of chlorophyll ﬂuorescence imaging technique in analysis\nand detection of chilling\
    \ injury of tomato seedlings. Comput. Electron. Agric. 2020, 168, 105109. [CrossRef]\n\
    6.\nGerhards, M.; Rock, G.; Schlerf, M.; Udelhoven, T. Water stress detection\
    \ in potato plants using leaf\ntemperature, emissivity, and reﬂectance. Int. J.\
    \ Appl. Earth Obs. Geoinf. 2016, 53, 27–39. [CrossRef]\n7.\nKim, Y.; Glenn, D.M.;\
    \ Park, J.; Ngugi, H.K.; Lehman, B.L. Hyperspectral image analysis for water stress\n\
    detection of apple trees. Comput. Electron. Agric. 2011, 77, 155–160. [CrossRef]\n\
    8.\nMahlein, A.K. Plant disease detection by imaging sensors–parallels and speciﬁc\
    \ demands for precision\nagriculture and plant phenotyping. Plant Dis. 2016, 100,\
    \ 241–251. [CrossRef]\n9.\nBarbedo, J.G.A. Digital image processing techniques\
    \ for detecting, quantifying and classifying plant diseases.\nSpringerPlus 2013,\
    \ 2, 660. [CrossRef]\n10.\nGebejes, A.; Huertas, R. Texture characterization based\
    \ on grey-level co-occurrence matrix. Databases 2013,\n9, 10.\n11.\nLindenthal,\
    \ M.; Steiner, U.; Dehne, H.W.; Oerke, E.C. Eﬀect of downy mildew development\
    \ on transpiration\nof cucumber leaves visualized by digital infrared thermography.\
    \ Phytopathology 2005, 95, 233–240. [CrossRef]\n[PubMed]\n12.\nBuschmann, C.;\
    \ Langsdorf, G.; Lichtenthaler, H.K. Imaging of the blue, green, and red ﬂuorescence\
    \ emission\nof plants: An overview. Photosynthetica 2000, 38, 483–491. [CrossRef]\n\
    13.\nMutka, A.M.; Bart, R.S. Image-based phenotyping of plant disease symptoms.\
    \ Front. Plant Sci. 2015, 5, 734.\n[CrossRef] [PubMed]\n14.\nGao, Z.; Zhao, Y.;\
    \ Khot, L.R.; Hoheisel, G.A.; Zhang, Q. Optical sensing for early spring freeze\
    \ related\nblueberry bud damage detection: Hyperspectral imaging for salient spectral\
    \ wavelengths identiﬁcation.\nComput. Electron. Agric. 2019, 167, 105025. [CrossRef]\n\
    15.\nBoulent, J.; Foucher, S.; Théau, J.; St-Charles, P.L. Convolutional Neural\
    \ Networks for the Automatic\nIdentiﬁcation of Plant Diseases. Front. Plant Sci.\
    \ 2019, 10, 941. [CrossRef] [PubMed]\n16.\nWernick, M.N.; Yang, Y.; Brankov, J.G.;\
    \ Yourganov, G.; Strother, S.C. Machine learning in medical imaging.\nIEEE Signal\
    \ Process. Mag. 2010, 27, 25–38. [CrossRef]\n17.\nBauer, A.; Bostrom, A.G.; Ball,\
    \ J.; Applegate, C.; Cheng, T.; Laycock, S.; Zhou, J. Combining computer vision\n\
    and deep learning to enable ultra-scale aerial phenotyping and precision agriculture:\
    \ A case study of lettuce\nproduction. Hortic. Res. 2019, 6, 1–12. [CrossRef]\n\
    18.\nHughes, D.; Salathé, M. An open access repository of images on plant health\
    \ to enable the development of\nmobile disease diagnostics. arXiv 2015, arXiv:1511.08060.\n\
    19.\nSevetlidis, V.; Giuﬀrida, M.V.; Tsaftaris, S.A. Whole image synthesis using\
    \ a deep encoder-decoder network.\nIn International Workshop on Simulation and\
    \ Synthesis in Medical Imaging; Springer: Cham, Switzerland, 2016;\npp. 127–137.\n\
    20.\nMohanty, S.P.; Hughes, D.P.; Salathé, M. Using deep learning for image-based\
    \ plant disease detection.\nFront. Plant Sci. 2016, 7, 1419. [CrossRef]\n21.\n\
    Pawara, P.; Okafor, E.; Surinta, O.; Schomaker, L.; Wiering, M. Comparing Local\
    \ Descriptors and Bags of\nVisual Words to Deep Convolutional Neural Networks\
    \ for Plant Recognition. In ICPRAM; Science and\nTechnology Publications: Porto,\
    \ Portugal, 2017; pp. 479–486.\n22.\nNarvaez, F.Y.; Reina, G.; Torres-Torriti,\
    \ M.; Kantor, G.; Cheein, F.A. A survey of ranging and imaging\ntechniques for\
    \ precision agriculture phenotyping. Ieee ASME Trans. Mechatron. 2017, 22, 2428–2439.\n\
    [CrossRef]\nAgriEngineering 2020, 2\n443\n23.\nKoza, J.R.; Bennett, F.H.; Andre,\
    \ D.; Keane, M.A. Automated design of both the topology and sizing of analog\n\
    electrical circuits using genetic programming. In Artiﬁcial Intelligence in Design’96;\
    \ Springer: Dordrecht, The\nNetherlands, 1996; pp. 151–170.\n24.\nHarrington,\
    \ P. Machine Learning in Action; Manning Publications: Greenwich, CT, USA, 2012;\
    \ p. 384.\n25.\nCouprie, C.; Farabet, C.; Najman, L.; LeCun, Y. Indoor semantic\
    \ segmentation using depth information.\narXiv 2013, arXiv:1301.3572.\n26.\nAmruthnath,\
    \ N.; Gupta, T. A research study on unsupervised machine learning algorithms for\
    \ early fault\ndetection in predictive maintenance. In Proceedings of the 2018\
    \ 5th International Conference on Industrial\nEngineering and Applications (ICIEA),\
    \ Singapore, 26–28 April 2018; pp. 355–361.\n27.\nSrivastava, N.; Mansimov, E.;\
    \ Salakhudinov, R. Unsupervised learning of video representations using\nlstms.\
    \ In Proceedings of the International Conference on Machine Learning, Lille, France,\
    \ 6–11 July 2015;\npp. 843–852.\n28.\nGu, J.; Wang, Z.; Kuen, J.; Ma, L.; Shahroudy,\
    \ A.; Shuai, B.; Chen, T. Recent advances in convolutional neural\nnetworks. Pattern\
    \ Recognit. 2018, 77, 354–377. [CrossRef]\n29.\nHasan, M.; Tanawala, B.; Patel,\
    \ K.J. Deep Learning Precision Farming: Tomato Leaf Disease Detection\nby Transfer\
    \ Learning. In Proceedings of the 2nd International Conference on Advanced Computing\
    \ and\nSoftware Engineering (ICACSE), Sultanpur, India, 8–9 February 2019; pp.\
    \ 843–852.\n30.\nZhang, J.; He, L.; Karkee, M.; Zhang, Q.; Zhang, X.; Gao, Z.\
    \ Branch detection for apple trees trained\nin fruiting wall architecture using\
    \ depth features and Regions-Convolutional Neural Network (R-CNN).\nComput. Electron.\
    \ Agric. 2018, 155, 386–393. [CrossRef]\n31.\nSingh, A.K.; Ganapathysubramanian,\
    \ B.; Sarkar, S.; Singh, A. Deep learning for plant stress phenotyping:\nTrends\
    \ and future perspectives. Trends Plant Sci. 2018, 23, 883–898. [CrossRef] [PubMed]\n\
    32.\nAkhtar, N.; Ragavendran, U. Interpretation of intelligence in CNN-pooling\
    \ processes: A methodological\nsurvey. Neural Comput. Appl. 2020, 32, 879–898.\
    \ [CrossRef]\n33.\nYonaba, H.; Anctil, F.; Fortin, V. Comparing sigmoid transfer\
    \ functions for neural network multistep ahead\nstreamﬂow forecasting. J. Hydrol.\
    \ Eng. 2010, 15, 275–283. [CrossRef]\n34.\nGao, Z.; Shao, Y.; Xuan, G.; Wang,\
    \ Y.; Liu, Y.; Han, X. Real-time hyperspectral imaging for the in-ﬁeld\nestimation\
    \ of strawberry ripeness with deep learning. Artif. Intell. Agric. 2020. [CrossRef]\n\
    35.\nUbbens, J.R.; Stavness, I. Deep plant phenomics: A deep learning platform\
    \ for complex plant phenotyping\ntasks. Front. Plant Sci. 2017, 8, 1190. [CrossRef]\
    \ [PubMed]\n36.\nKhan, A.; Sohail, A.; Zahoora, U.; Qureshi, A.S. A survey of\
    \ the recent architectures of deep convolutional\nneural networks. arXiv 2019,\
    \ arXiv:1901.06032.\n37.\nQayyum, A.; Malik, A.S.; Saad, N.M.; Iqbal, M.; Faris\
    \ Abdullah, M.; Rasheed, W.; Bin Jafaar, M.Y.\nScene classiﬁcation for aerial\
    \ images based on CNN using sparse coding technique. Int. J. Remote Sens. 2017,\n\
    38, 2662–2685. [CrossRef]\n38.\nSimonyan, K.; Zisserman, A. Very deep convolutional\
    \ networks for large-scale image recognition. arXiv\n2014, arXiv:1409.1556.\n\
    39.\nChen, C.F.; Lee, G.G.; Sritapan, V.; Lin, C.Y. Deep convolutional neural\
    \ network on iOS mobile devices.\nIn Proceedings of the 2016 IEEE International\
    \ Workshop on Signal Processing Systems (SiPS), Dallas, TX,\nUSA, 26–28 October\
    \ 2016; pp. 130–135.\n40.\nSzegedy, C.; Vanhoucke, V.; Ioﬀe, S.; Shlens, J.; Wojna,\
    \ Z. Rethinking the inception architecture for computer\nvision. In Proceedings\
    \ of the IEEE Conference on Computer Vision and Pattern Recognition, Las Vegas,\
    \ NV,\nUSA, 26 Jun–1 July 2016; pp. 2818–2826.\n41.\nLi, H.; Zhao, R.; Wang, X.\
    \ Highly eﬃcient forward and backward propagation of convolutional neural\nnetworks\
    \ for pixelwise classiﬁcation. arXiv 2014, arXiv:1412.4526.\n42.\nMallat, S. Understanding\
    \ deep convolutional networks. Philos. Trans. Royal Soc. A Math. Phys. Eng. Sci.\n\
    2016, 374, 20150203. [CrossRef] [PubMed]\n43.\nAwan, A.A.; Hamidouche, K.; Hashmi,\
    \ J.M.; Panda, D.K. S-caﬀe: Co-designing mpi runtimes and caﬀe\nfor scalable deep\
    \ learning on modern gpu clusters. In ACM Sigplan Notices; ACM: Austin, TX, USA,\
    \ 2017;\nVolume 52, pp. 193–205.\n44.\nSteinkraus, D.; Buck, I.; Simard, P.Y.\
    \ Using GPUs for machine learning algorithms. In Proceedings of\nthe Eighth International\
    \ Conference on Document Analysis and Recognition (ICDAR’05), Seoul, Korea,\n\
    31 August–1 September 2005; pp. 1115–1120.\nAgriEngineering 2020, 2\n444\n45.\n\
    Barbedo, J.G.A. Plant disease identiﬁcation from individual lesions and spots\
    \ using deep learning. Biosyst.\nEng. 2019, 180, 96–107. [CrossRef]\n46.\nLin,\
    \ K.; Gong, L.; Huang, Y.; Liu, C.; Pan, J. Deep learning-based segmentation and\
    \ quantiﬁcation of cucumber\nPowdery Mildew using convolutional neural network.\
    \ Front. Plant Sci. 2019, 10, 155. [CrossRef]\n47.\nFerentinos, K.P. Deep learning\
    \ models for plant disease detection and diagnosis. Comput. Electron. Agric.\n\
    2018, 145, 311–318. [CrossRef]\n48.\nHa, J.G.; Moon, H.; Kwak, J.T.; Hassan, S.I.;\
    \ Dang, M.; Lee, O.N.; Park, H.Y. Deep convolutional neural\nnetwork for classifying\
    \ Fusarium wilt of radish from unmanned aerial vehicles. J. Appl. Remote Sens.\
    \ 2017,\n11, 042621. [CrossRef]\n49.\nSchumann, A.; Waldo, L.; Holmes, W.; Test,\
    \ G.; Ebert, T. Artiﬁcial Intelligence for Detecting Citrus Pests,\nDiseases and\
    \ Disorders. In Citrus Industry News, Technology; AgNet Media, Inc.: Gainesville,\
    \ FL, USA, 2 July\n2018.\n50.\nLiu, B.; Zhang, Y.; He, D.; Li, Y.; Liu, B.; Zhang,\
    \ Y.; Li, Y. Identiﬁcation of Apple Leaf Diseases Based on Deep\nConvolutional\
    \ Neural Networks. Symmetry 2017, 10, 11. [CrossRef]\n51.\nRamcharan, A.; Baranowski,\
    \ K.; McCloskey, P.; Ahmed, B.; Legg, J.; Hughes, D.P. Deep Learning for\nImage-Based\
    \ Cassava Disease Detection. Front. Plant Sci. 2017, 8, 1852. [CrossRef]\n52.\n\
    Lu, J.; Hu, J.; Zhao, G.; Mei, F.; Zhang, C. An in-ﬁeld automatic wheat disease\
    \ diagnosis system. Comput.\nElectron. Agric. 2017, 142, 369–379. [CrossRef]\n\
    53.\nDeChant, C.;\nWiesner-Hanks, T.;\nChen, S.;\nStewart, E.L.;\nYosinski, J.;\n\
    Gore, M.A.;\nLipson, H.\nAutomated identiﬁcation of northern leaf blight-infected\
    \ maize plants from ﬁeld imagery using deep\nlearning. Phytopathology 2017, 107,\
    \ 1426–1432. [CrossRef]\n54.\nKaneda, Y.; Shibata, S.; Mineno, H. Multi-modal\
    \ sliding window-based support vector regression for\npredicting plant water stress.\
    \ Knowl. Based Syst. 2017, 134, 135–148. [CrossRef]\n55.\nFuentes, A.; Yoon, S.;\
    \ Kim, S.C.; Park, D.S. A robust deep-learning-based detector for real-time tomato\
    \ plant\ndiseases and pests recognition. Sensors 2017, 17, 2022. [CrossRef]\n\
    56.\nRangarajan, A.K.; Purushothaman, R. Disease Classiﬁcation in Eggplant Using\
    \ Pre-trained VGG16 and\nMSVM. Scientiﬁc Reports 2020, 10, 1–11.\n57.\nGhosal,\
    \ S.; Blystone, D.; Singh, A.K.; Ganapathysubramanian, B.; Singh, A.; Sarkar,\
    \ S. An explainable deep\nmachine vision framework for plant stress phenotyping.\
    \ Proc. Natl. Acad. Sci. USA 2018, 115, 4613–4618.\n[CrossRef]\n58.\nJin, X.;\
    \ Jie, L.; Wang, S.; Qi, H.; Li, S.; Jin, X.; Li, S.W. Classifying Wheat Hyperspectral\
    \ Pixels of Healthy\nHeads and Fusarium Head Blight Disease Using a Deep Neural\
    \ Network in the Wild Field. Remote Sens.\n2018, 10, 395. [CrossRef]\n59.\nToo,\
    \ E.C.; Yujian, L.; Njuki, S.; Yingchun, L. A comparative study of ﬁne-tuning\
    \ deep learning models for\nplant disease identiﬁcation. Comput. Electron. Agric.\
    \ 2019, 161, 272–279. [CrossRef]\n60.\nRançon, F.; Bombrun, L.; Keresztes, B.;\
    \ Germain, C. Comparison of SIFT Encoded and Deep Learning\nFeatures for the Classiﬁcation\
    \ and Detection of Esca Disease in Bordeaux Vineyards. Remote Sens. 2018, 11,\
    \ 1.\n[CrossRef]\n61.\nAn, J.; Li, W.; Li, M.; Cui, S.; Yue, H.; An, J.; Yue,\
    \ H. Identiﬁcation and Classiﬁcation of Maize Drought Stress\nUsing Deep Convolutional\
    \ Neural Network. Symmetry 2019, 11, 256. [CrossRef]\n62.\nCruz, A.; Ampatzidis,\
    \ Y.; Pierro, R.; Materazzi, A.; Panattoni, A.; De Bellis, L.; Luvisi, A. Detection\
    \ of\ngrapevine yellows symptoms in Vitis vinifera L. with artiﬁcial intelligence.\
    \ Comput. Electron. Agric. 2019,\n157, 63–76. [CrossRef]\n63.\nLiang, W.; Zhang,\
    \ H.; Zhang, G.; Cao, H. Rice Blast Disease Recognition Using a Deep Convolutional\
    \ Neural\nNetwork. Sci. Rep. 2019, 9, 2869. [CrossRef] [PubMed]\n64.\nLiang, Q.;\
    \ Xiang, S.; Hu, Y.; Coppola, G.; Zhang, D.; Sun, W. PD2SE-Net: Computer-assisted\
    \ plant disease\ndiagnosis and severity estimation network. Comput. Electron.\
    \ Agric. 2019, 157, 518–529. [CrossRef]\n65.\nEsgario, J.G.; Krohling, R.A.; Ventura,\
    \ J.A. Deep learning for classiﬁcation and severity estimation of coﬀee\nleaf\
    \ biotic stress. Comput. Electron. Agric. 2020, 169, 105162. [CrossRef]\n66.\n\
    Zhang, X.; Han, L.; Dong, Y.; Shi, Y.; Huang, W.; Han, L.; Sobeih, T. A Deep Learning-Based\
    \ Approach for\nAutomated Yellow Rust Disease Detection from High-Resolution Hyperspectral\
    \ UAV Images. Remote Sens.\n2019, 11, 1554. [CrossRef]\nAgriEngineering 2020,\
    \ 2\n445\n67.\nBrahimi, M.; Mahmoudi, S.; Boukhalfa, K.; Moussaoui, A. Deep interpretable\
    \ architecture for plant diseases\nclassiﬁcation. arXiv 2019, arXiv:1905.13523.\n\
    68.\nWang, D.; Vinson, R.; Holmes, M.; Seibel, G.; Bechar, A.; Nof, S.; Tao, Y.\
    \ Early Detection of Tomato Spotted\nWilt Virus by Hyperspectral Imaging and Outlier\
    \ Removal Auxiliary Classiﬁer Generative Adversarial Nets\n(OR-AC-GAN). Sci. Rep.\
    \ 2019, 9, 4377. [CrossRef]\n69.\nHu, G.; Wu, H.; Zhang, Y.; Wan, M. A low shot\
    \ learning method for tea leaf’s disease identiﬁcation. Comput.\nElectron. Agric.\
    \ 2019, 163, 104852. [CrossRef]\n70.\nGhosh, P.; Mitchell, M.; Tanyi, J.A.; Hung,\
    \ A.Y. Incorporating priors for medical image segmentation using a\ngenetic algorithm.\
    \ Neurocomputing 2016, 195, 181–194. [CrossRef]\n71.\nZhao, T.; Yang, Y.; Niu,\
    \ H.; Chen, Y.; Wang, D. Comparing U-Net convolutional networks with fully\nconvolutional\
    \ networks in the performances of pomegranate tree canopy segmentation. In Multispectral,\n\
    Hyperspectral, and Ultraspectral Remote Sensing Technology, Techniques and Applications\
    \ VII; Larar, A.M.,\nSuzuki, M., Wang, J., Eds.; SPIE: Bellingham, WA, USA, 2018;\
    \ Volume 10780, p. 64.\n72.\nBaumgartner, C.F.; Koch, L.M.; Pollefeys, M.; Konukoglu,\
    \ E. An exploration of 2D and 3D deep learning\ntechniques for cardiac MR image\
    \ segmentation. In International Workshop on Statistical Atlases and Computational\n\
    Models of the Heart; Springer: Cham, Switzerland, 2017; pp. 111–119.\n73.\nPeng,\
    \ C.; Li, Y.; Jiao, L.; Chen, Y.; Shang, R. Densely Based Multi-Scale and Multi-Modal\
    \ Fully Convolutional\nNetworks for High-Resolution Remote-Sensing Image Semantic\
    \ Segmentation. IEEE J. Sel. Top. Appl.\nEarth Obs. Remote Sens. 2019, 12, 2612–2626.\
    \ [CrossRef]\n74.\nÇiçek, Ö.; Abdulkadir, A.; Lienkamp, S.S.; Brox, T.; Ronneberger,\
    \ O. 3D U-Net: Learning Dense Volumetric\nSegmentation from Sparse Annotation;\
    \ Springer: Cham, Switzerland, 2016; pp. 424–432.\n75.\nMa, J.; Du, K.; Zheng,\
    \ F.; Zhang, L.; Gong, Z.; Sun, Z. A recognition method for cucumber diseases\
    \ using leaf\nsymptom images based on deep convolutional neural network. Comput.\
    \ Electron. Agric. 2018, 154, 18–24.\n[CrossRef]\n76.\nKhan, M.A.; Akram, T.;\
    \ Sharif, M.; Awais, M.; Javed, K.; Ali, H.; Saba, T. CCDF: Automatic system for\n\
    segmentation and recognition of fruit crops diseases based on correlation coeﬃcient\
    \ and deep CNN features.\nComput. Electron. Agric. 2018, 155, 220–236. [CrossRef]\n\
    77.\nDas, S.; Roy, D.; Das, P. Disease Feature Extraction and Disease Detection\
    \ from Paddy Crops Using Image\nProcessing and Deep Learning Technique. In Computational\
    \ Intelligence in Pattern Recognition; Springer:\nSingapore, 2020; pp. 443–449.\n\
    78.\nHuang, S.; Liu, W.; Qi, F.; Yang, K. Development and Validation of a Deep\
    \ Learning Algorithm for the\nRecognition of Plant Disease. In Proceedings of\
    \ the 2019 IEEE 21st International Conference on High\nPerformance Computing and\
    \ Communications; IEEE 17th International Conference on Smart City; IEEE\n5th\
    \ International Conference on Data Science and Systems (HPCC/SmartCity/DSS), Zhangjiajie,\
    \ China,\n10–12 August 2019; pp. 1951–1957.\n79.\nZhang, S.; Zhang, S.; Zhang,\
    \ C.; Wang, X.; Shi, Y. Cucumber leaf disease identiﬁcation with global pooling\n\
    dilated convolutional neural network. Comput. Electron. Agric. 2019, 162, 422–430.\
    \ [CrossRef]\n80.\nKamilaris, A.; Prenafeta-Boldú, F.X. Deep learning in agriculture:\
    \ A survey. Comput. Electron. Agric. 2018,\n147, 70–90. [CrossRef]\n81.\nPatrício,\
    \ D.I.; Rieder, R. Computer vision and artiﬁcial intelligence in precision agriculture\
    \ for grain crops: A\nsystematic review. Comput. Electron. Agric. 2018, 153, 69–81.\
    \ [CrossRef]\n82.\nBhatt, P.; Sarangi, S.; Pappula, S. Detection of diseases and\
    \ pests on images captured in uncontrolled\nconditions from tea plantations. In\
    \ Autonomous Air and Ground Sensing Systems for Agricultural Optimization\nand\
    \ Phenotyping IV; Thomasson, J.A., McKee, M., Moorhead, R.J., Eds.; SPIE: Bellingham,\
    \ WA, USA, 2019;\np. 33.\n83.\nStewart, E.L.;\nWiesner-Hanks, T.;\nKaczmar, N.;\n\
    DeChant, C.;\nWu, H.;\nLipson, H.;\nGore, M.A.\nQuantitative Phenotyping of Northern\
    \ Leaf Blight in UAV Images Using Deep Learning. Remote Sens. 2019,\n11, 2209.\
    \ [CrossRef]\n84.\nGandhi, R. R-CNN, Fast R-CNN, Faster R-CNN, YOLO—Object Detection\
    \ Algorithms. Available online: https:\n//towardsdatascience.com/r-cnn-fast-r-cnn-faster-r-cnn-yolo-object-detection-algorithms-36d53571365e\n\
    (accessed on 19 June 2020).\nAgriEngineering 2020, 2\n446\n85.\nSingh, D.; Jain,\
    \ N.; Jain, P.; Kayal, P.; Kumawat, S.; Batra, N. PlantDoc: A dataset for visual\
    \ plant disease\ndetection. In Proceedings of the 7th ACM IKDD CoDS and 25th COMAD,\
    \ Hyderabad, India, 5–7 January\n2020; Association for Computing Machinery: New\
    \ York, NY, USA; pp. 249–253.\n86.\nSethy, P.K.; Barpanda, N.K.; Rath, A.K.; Behera,\
    \ S.K. Rice False Smut Detection based on Faster R-CNN.\nIndonesian J. Elect.\
    \ Eng. Comput. Sci., 2020, 19. [CrossRef]\n87.\nWang, Q.; Qi, F.; Sun, M.; Qu,\
    \ J.; Xue, J. Identiﬁcation of Tomato Disease Types and Detection of Infected\n\
    Areas Based on Deep Convolutional Neural Networks and Object Detection Techniques.\
    \ Computational\nIntelligence and Neuroscience 2019, 2019. [CrossRef]\n88.\nNie,\
    \ X.; Wang, L.; Ding, H.; Xu, M. Strawberry Verticillium Wilt Detection Network\
    \ Based on Multi-Task\nLearning and Attention. IEEE Access 2019, 7, 170003–170011.\
    \ [CrossRef]\n89.\nLin, T.L.; Chang, H.Y.; Chen, K.H. The pest and disease identiﬁcation\
    \ in the growth of sweet peppers using\nfaster R-CNN and mask R-CNN. J. Internet\
    \ Technol. 2020, 21, 605–614.\n90.\nForster, A.; Behley, J.; Behmann, J.; Roscher,\
    \ R. Hyperspectral Plant Disease Forecasting Using Generative\nAdversarial Networks.\
    \ In Proceedings of the 2019 IEEE International Geoscience and Remote Sensing\n\
    Symposium (IGARSS 2019), Yokohama, Japan, 28 July–2 August 2019; pp. 1793–1796.\n\
    91.\nPardede, H.F.; Suryawati, E.; Sustika, R.; Zilvan, V. Unsupervised convolutional\
    \ autoencoder-based feature\nlearning for automatic detection of plant diseases.\
    \ In Proceedings of the 2018 International Conference on\nComputer, Control, Informatics\
    \ and its Applications (IC3INA), Tangerang Indonesia, 1–2 November 2018;\npp.\
    \ 158–162.\n© 2020 by the authors. Licensee MDPI, Basel, Switzerland. This article\
    \ is an open access\narticle distributed under the terms and conditions of the\
    \ Creative Commons Attribution\n(CC BY) license (http://creativecommons.org/licenses/by/4.0/).\n"
  inline_citation: '>'
  journal: AgriEngineering
  limitations: '>'
  pdf_link: https://www.mdpi.com/2624-7402/2/3/29/pdf?version=1594725436
  publication_year: 2020
  relevance_score1: 0
  relevance_score2: 0
  title: 'Deep Learning Application in Plant Stress Imaging: A Review'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.3390/bios10120193
  analysis: '>'
  authors:
  - Alanna V. Zubler
  - Jeong Yeol Yoon
  citation_count: 40
  full_citation: '>'
  full_text: ">\nbiosensors\nReview\nProximal Methods for Plant Stress Detection Using\n\
    Optical Sensors and Machine Learning\nAlanna V. Zubler and Jeong-Yeol Yoon *\n\
    Department of Biosystems Engineering, The University of Arizona, Tucson, AZ 85721,\
    \ USA;\navzubler@email.arizona.edu\n* Correspondence: jyyoon@arizona.edu\nReceived:\
    \ 25 September 2020; Accepted: 26 November 2020; Published: 29 November 2020\n\
    \x01\x02\x03\x01\x04\x05\x06\a\b\x01\n\x01\x02\x03\x04\x05\x06\a\nAbstract: Plant\
    \ stresses have been monitored using the imaging or spectrometry of plant leaves\
    \ in the\nvisible (red-green-blue or RGB), near-infrared (NIR), infrared (IR),\
    \ and ultraviolet (UV) wavebands,\noften augmented by ﬂuorescence imaging or ﬂuorescence\
    \ spectrometry. Imaging at multiple speciﬁc\nwavelengths (multi-spectral imaging)\
    \ or across a wide range of wavelengths (hyperspectral imaging)\ncan provide exceptional\
    \ information on plant stress and subsequent diseases. Digital cameras, thermal\n\
    cameras, and optical ﬁlters have become available at a low cost in recent years,\
    \ while hyperspectral\ncameras have become increasingly more compact and portable.\
    \ Furthermore, smartphone cameras\nhave dramatically improved in quality, making\
    \ them a viable option for rapid, on-site stress detection.\nDue to these developments\
    \ in imaging technology, plant stresses can be monitored more easily using\nhandheld\
    \ and ﬁeld-deployable methods. Recent advances in machine learning algorithms\
    \ have\nallowed for images and spectra to be analyzed and classiﬁed in a fully\
    \ automated and reproducible\nmanner, without the need for complicated image or\
    \ spectrum analysis methods. This review will\nhighlight recent advances in portable\
    \ (including smartphone-based) detection methods for biotic and\nabiotic stresses,\
    \ discuss data processing and machine learning techniques that can produce results\
    \ for\nstress identiﬁcation and classiﬁcation, and suggest future directions towards\
    \ the successful translation\nof these methods into practical use.\nKeywords:\
    \ abiotic stress; plant disease; ﬂuorescence; hyperspectral imaging; thermography;\n\
    RGB imaging; smartphone imaging; support vector machine (SVM); artiﬁcial neural\
    \ network (ANN);\nmachine learning\n1. Introduction\nNew and innovative management\
    \ techniques are needed to ensure a sustainable future for the\nagricultural industry\
    \ as the world population continues to increase. There will be over 9 billion\
    \ people\ninhabiting the earth by 2050 [1]. Feeding such a large population is\
    \ a complex problem that will\nrequire the utilization of a variety of ideas and\
    \ techniques across disciplines. Among these is ensuring\nmaximum crop yields\
    \ with minimal losses from plant stresses such as drought, lack of nutrients,\n\
    and disease. If proper attention is not given to the mitigation of these yield\
    \ losses, several components\nof food security such as availability and economic\
    \ access may be aﬀected [2].\nPathogens and biotic stresses have received considerable\
    \ attention in plant stress studies.\nAbout 20–30% of crops are lost due to pests\
    \ and pathogens globally, with many of these losses\noccurring almost every growing\
    \ season [3]. Furthermore, many species of plant pathogens can\ntravel over long\
    \ distances, whether by wind, water, or human activities such as trade and travel\
    \ [4].\nThe distribution of pathogens may also be shifted due to the eﬀects of\
    \ climate change [5]. The detection\nof plant diseases is therefore essential\
    \ not only to implement appropriate disease management strategies\nand mitigate\
    \ potential losses but also to monitor changes in pathogen distribution. Most\
    \ diseases can be\nBiosensors 2020, 10, 193; doi:10.3390/bios10120193\nwww.mdpi.com/journal/biosensors\n\
    Biosensors 2020, 10, 193\n2 of 27\ndetected relatively easily when symptoms are\
    \ fully developed due to noticeable changes in the plant’s\nappearance; however,\
    \ early detection is essential in preventing large yield losses. It is also needful\n\
    to detect abiotic stresses such as water and nutrient deﬁciencies at an early\
    \ stage before damages\nsigniﬁcantly aﬀect crop yields; furthermore, these stresses\
    \ will become more prevalent in the agriculture\nindustry due to climate change\
    \ eﬀects such as drought stress and increased salinity [6], which will\nproduce\
    \ a need for increased environmental monitoring for more reﬁned management practices.\n\
    Bioreceptor-based direct detection methods such as polymerase chain reaction (PCR)\
    \ [7],\nenzyme-linked immunosorbent assay (ELISA) [8], and ﬂow cytometry (FC)\
    \ [9] are widely available\nfor the detection of plant diseases; however, these\
    \ methods require specialized training and can be\ntime-consuming and labor-intensive.\
    \ An alternative detection method that can be used both for biotic\nand abiotic\
    \ stresses is a simple visual observation by an expert [10], but this technique\
    \ can be prone to\nbias, with varying results based on the experience of the evaluator.\n\
    Optical techniques hold considerable advantages over the previously mentioned\
    \ techniques,\nsuch as a greater potential for rapid disease detection (with some\
    \ methods producing results in\nnear-real-time [11]), standardized results that\
    \ are not subject to individual biases, and the ability to\ndetect both biotic\
    \ and abiotic stresses. Techniques using proximal (near to the target) sensing\
    \ methods\nhave been utilizing optical sensors that are becoming increasingly\
    \ smaller and more portable. Although\noptical sensors provide greater simplicity\
    \ in the data collection process, the data itself can be complex\nand large in\
    \ size (especially in regard to hyperspectral imaging), requiring the use of sophisticated\
    \ data\nprocessing and statistical methods. Furthermore, images and spectroscopic\
    \ data are not very speciﬁc\nto particular stresses, as opposed to bioreceptor-based\
    \ (e.g., chemical ligands, antibodies, nucleic acids,\netc.) direct detection\
    \ methods. Despite these limitations, stress speciﬁcity and complex data analysis\n\
    can still be achieved using machine learning techniques, which can analyze the\
    \ data provided to\nﬁnd patterns that are speciﬁc to the plant stress in question.\
    \ Many studies have successfully utilized\nmachine learning to interpret optical\
    \ sensor data for the detection of speciﬁc stresses. This review aims\nto provide\
    \ an outline of current optical sensor types and machine learning methods used\
    \ to proximally\ndetect plant stresses.\n2. Spectral Properties of Plant Tissues\n\
    Many physiological and chemical properties of plants inﬂuence the way their tissues\
    \ reﬂect and\nabsorb light. These properties can change when a plant is subjected\
    \ to stress and alter the reﬂectance\nspectrum of its leaves (Figure 1).\nChlorophyll\
    \ is a pigment that is involved in the photosynthesis process. Due to its important\
    \ role\nin absorbing light, changes in chlorophyll content resulting from stress\
    \ will alter the way the plant\ninteracts with light energy. A decrease in chlorophyll\
    \ content may occur when the plant is subjected to\nstress, which can be characterized\
    \ in various ways including an increase of reﬂectance near 700 nm [12]\nand decreased\
    \ reﬂectance in the 530–630 nm range [13]. Other pigments besides chlorophyll,\
    \ such as\ncarotenes [14] and xanthophylls [15], can also alter a plant’s reﬂectance\
    \ properties.\nIn addition to pigmentation, leaf anatomical properties (Figure\
    \ 2) such as the convexity of\nepidermal cells [16], surface texture and thickness\
    \ of the leaf cuticle [17], and high trichome density [18]\ncan be altered under\
    \ stress and consequently aﬀect a leaf’s spectral properties. For example, exposure\n\
    to UV radiation can result in changes to chlorophyll content and increased leaf\
    \ thickness, which can\nalter chlorophyll ﬂuorescence levels [19]. Reﬂectance\
    \ in the 950–970 nm range was found by Peñuelas\net al. (1993) to be inﬂuenced\
    \ by cell wall elasticity, which decreases in response to drought stress [20].\n\
    Small openings on plant leaves (stomata) can also aﬀect leaf properties under\
    \ stress [21].\nThese pores are important to regulate moisture and control gas\
    \ exchange in the leaves; however,\nmicroorganisms such as bacteria and fungi\
    \ can use them to enter and infect a plant. Plants can recognize\nthese pathogens\
    \ using pathogen- or microbe-associated molecular patterns (PAMPs or MAMPs),\n\
    which can then trigger stomatal closure to prevent entry [22]. Stomatal closure\
    \ can lead to an increase\nin leaf temperature, which can be detected in the infrared\
    \ region of the electromagnetic spectrum.\nBiosensors 2020, 10, 193\n3 of 27\n\
    Biosensors 2020, 10, x FOR PEER REVIEW \n3 of 28 \n \nFigure 1. Reflectance spectra\
    \ of Quercus aquifolioides leaves at different altitudes. Vegetation \nreflectance\
    \ curves in general typically display this kind of pattern, with low reflectance\
    \ in the visible \nregion (influenced by leaf pigments), “red edge” connecting\
    \ the visible and near-infrared (NIR) \nregion, and high reflectance in the NIR\
    \ region (influenced by cell structure). After 1300 nm, reflectance \ncharacteristics\
    \ are mostly influenced by leaf water content. Reprinted from [12]. ©2020 Zhu\
    \ et al. \n \nFigure 2. Drawing of a cross-section of a typical leaf with labeled\
    \ cell types and layers. Basic light \ninteractions with leaf layers are annotated.\
    \ Reprinted from [21]. ©2008 Liew et al. \nThe biochemical properties of leaves,\
    \ such as cellulose, hemicellulose, lignin, protein, sugar, and \nstarch can also\
    \ change under various stresses and affect the reflectance properties of leaves\
    \ [23]. For \nexample, salt stress can result in spectral changes by damaging\
    \ leaf mesophyll cells and altering \nFigure 1. Reﬂectance spectra of Quercus\
    \ aquifolioides leaves at diﬀerent altitudes. Vegetation reﬂectance\ncurves in\
    \ general typically display this kind of pattern, with low reﬂectance in the visible\
    \ region\n(inﬂuenced by leaf pigments), “red edge” connecting the visible and\
    \ near-infrared (NIR) region, and high\nreﬂectance in the NIR region (inﬂuenced\
    \ by cell structure). After 1300 nm, reﬂectance characteristics\nare mostly inﬂuenced\
    \ by leaf water content. Reprinted from [12]. ©2020 Zhu et al.\nBiosensors 2020,\
    \ 10, x FOR PEER REVIEW \n3 of 28 \n \nFigure 1. Reflectance spectra of Quercus\
    \ aquifolioides leaves at different altitudes. Vegetation \nreflectance curves\
    \ in general typically display this kind of pattern, with low reflectance in the\
    \ visible \nregion (influenced by leaf pigments), “red edge” connecting the visible\
    \ and near-infrared (NIR) \nregion, and high reflectance in the NIR region (influenced\
    \ by cell structure). After 1300 nm, reflectance \ncharacteristics are mostly\
    \ influenced by leaf water content. Reprinted from [12]. ©2020 Zhu et al. \n \n\
    Figure 2. Drawing of a cross-section of a typical leaf with labeled cell types\
    \ and layers. Basic light \ninteractions with leaf layers are annotated. Reprinted\
    \ from [21]. ©2008 Liew et al. \nThe biochemical properties of leaves, such as\
    \ cellulose, hemicellulose, lignin, protein, sugar, and \nstarch can also change\
    \ under various stresses and affect the reflectance properties of leaves [23].\
    \ For \nexample, salt stress can result in spectral changes by damaging leaf mesophyll\
    \ cells and altering \nFigure 2. Drawing of a cross-section of a typical leaf\
    \ with labeled cell types and layers. Basic light\ninteractions with leaf layers\
    \ are annotated. Reprinted from [21]. ©2008 Liew et al.\nBiosensors 2020, 10,\
    \ 193\n4 of 27\nThe biochemical properties of leaves, such as cellulose, hemicellulose,\
    \ lignin, protein, sugar,\nand starch can also change under various stresses and\
    \ aﬀect the reﬂectance properties of leaves [23].\nFor example, salt stress can\
    \ result in spectral changes by damaging leaf mesophyll cells and altering\npolysaccharide\
    \ and lignin composition in the cell wall [24]. Leaf water content can also inﬂuence\n\
    reﬂectance spectra as light absorption in the infrared region (>1300 nm) is primarily\
    \ due to water\nabsorption [25].\n3. Sensors and Data Collection\nA variety of\
    \ optical sensors have been used to evaluate plant health, including hyperspectral,\n\
    multispectral, thermal, and ﬂuorescence sensors (Table 1). The reﬂectance data\
    \ collected by these\ndevices can be represented using images acquired by imaging\
    \ techniques or spectral graphs produced\nusing spectroscopic methods. An important\
    \ element that can aﬀect a device’s success in stress detection\nis the sensor’s\
    \ sensitivity to areas in the plant’s reﬂectance spectrum that are altered by\
    \ biotic and\nabiotic stresses. Generally, the most sensitive region in the electromagnetic\
    \ spectrum for evaluating\nplant health is the visible region [26], but other\
    \ regions can also be inﬂuenced by stress. A diagram\ndisplaying various wavelength\
    \ regions in the electromagnetic spectrum is presented in Figure 3 [27].\nBiosensors\
    \ 2020, 10, x FOR PEER REVIEW \n4 of 28 \npolysaccharide and lignin composition\
    \ in the cell wall [24]. Leaf water content can also influence \nreflectance spectra\
    \ as light absorption in the infrared region (>1300 nm) is primarily due to water\
    \ \nabsorption [25]. \n3. Sensors and Data Collection \nA variety of optical sensors\
    \ have been used to evaluate plant health, including hyperspectral, \nmultispectral,\
    \ thermal, and fluorescence sensors (Table 1). The reflectance data collected\
    \ by these \ndevices can be represented using images acquired by imaging techniques\
    \ or spectral graphs \nproduced using spectroscopic methods. An important element\
    \ that can affect a device’s success in \nstress detection is the sensor’s sensitivity\
    \ to areas in the plant’s reflectance spectrum that are altered \nby biotic and\
    \ abiotic stresses. Generally, the most sensitive region in the electromagnetic\
    \ spectrum \nfor evaluating plant health is the visible region [26], but other\
    \ regions can also be influenced by stress. \nA diagram displaying various wavelength\
    \ regions in the electromagnetic spectrum is presented in \nFigure 3 [27]. \n\
    \ \nFigure 3. Ranges of the electromagnetic spectrum that are utilized by various\
    \ sensor types. Useful \nwavelengths for plant stress detection tend to be in\
    \ the ultra-violet (UV), visible, and NIR ranges. \nReprinted from [27]. ©2019\
    \ Rosique et al. \n3.1. Hyperspectral Imaging \nHyperspectral imaging utilizes\
    \ both imaging and spectroscopy methods to produce multi-\ndimensional data. Spectral\
    \ information for a wide range of individual wavelengths is assigned to \nevery\
    \ pixel in an image [28]. Rather than collecting spectra from an entire image\
    \ or an entire plant \nleaf, where spectra from the stressed and unaffected areas\
    \ are mixed together, hyperspectral imaging \ncan provide more sophisticated data\
    \ that can isolate spectra only from the affected area and identify \nspecific\
    \ imaging patterns and characteristics. This method has become increasingly popular\
    \ for plant \nphenotyping and stress detection in agriculture [29–31] and has\
    \ been used to identify plant responses \nto both abiotic and biotic stresses,\
    \ such as drought stress in maize [32] and barley [33], yellow rust \n[34] and\
    \ powdery mildew [35] in wheat, salt stress in okra [36], and Black Sigatoka disease\
    \ in banana \nplants [37].  \nHyperspectral imaging for plant status evaluation\
    \ typically uses a wavelength range of about \n250–2500 nm, i.e., UV (ultraviolet),\
    \ visible, and NIR (near-infrared), with the most important areas in \nthe visible\
    \ and NIR ranges [38]. Other areas of the spectrum are still being explored in\
    \ terms of their \ncapability for plant stress detection. For example, Brugger\
    \ et al. (2019) used hyperspectral imaging in \nFigure 3.\nRanges of the electromagnetic\
    \ spectrum that are utilized by various sensor types.\nUseful wavelengths for\
    \ plant stress detection tend to be in the ultra-violet (UV), visible, and NIR\
    \ ranges.\nReprinted from [27]. ©2019 Rosique et al.\n3.1. Hyperspectral Imaging\n\
    Hyperspectral imaging utilizes both imaging and spectroscopy methods to produce\n\
    multi-dimensional data. Spectral information for a wide range of individual wavelengths\
    \ is assigned\nto every pixel in an image [28]. Rather than collecting spectra\
    \ from an entire image or an entire plant\nleaf, where spectra from the stressed\
    \ and unaﬀected areas are mixed together, hyperspectral imaging\ncan provide more\
    \ sophisticated data that can isolate spectra only from the aﬀected area and identify\n\
    speciﬁc imaging patterns and characteristics. This method has become increasingly\
    \ popular for plant\nphenotyping and stress detection in agriculture [29–31] and\
    \ has been used to identify plant responses\nto both abiotic and biotic stresses,\
    \ such as drought stress in maize [32] and barley [33], yellow rust [34]\nand\
    \ powdery mildew [35] in wheat, salt stress in okra [36], and Black Sigatoka disease\
    \ in banana\nplants [37].\nBiosensors 2020, 10, 193\n5 of 27\nHyperspectral imaging\
    \ for plant status evaluation typically uses a wavelength range of about\n250–2500\
    \ nm, i.e., UV (ultraviolet), visible, and NIR (near-infrared), with the most\
    \ important areas\nin the visible and NIR ranges [38]. Other areas of the spectrum\
    \ are still being explored in terms of\ntheir capability for plant stress detection.\
    \ For example, Brugger et al. (2019) used hyperspectral\nimaging in the UV range\
    \ to detect salt stress in barley [39]. Due to the sensors’ ability to detect\
    \ a wide\nrange of wavelengths in the electromagnetic spectrum, many possibilities\
    \ remain for evaluating new\ncombinations of wavelengths for plant stress detection.\n\
    The data acquired using hyperspectral techniques are often used to compute and\
    \ create vegetation\nindices (VIs). VIs are computed using ratios and combinations\
    \ of reﬂectance measurements at a few\nspeciﬁc wavelengths and have been used\
    \ extensively for plant stress monitoring [40–42]. In addition\nto VIs, hyperspectral\
    \ data can be used to develop spectral disease indices (SDIs) with the purpose\n\
    of discriminating between speciﬁc plant diseases [43] (Table 2). Some examples\
    \ include indices for\ndetecting powdery mildew in wheat [44] and sugar beet [45],\
    \ cercospora leaf spot in sugar beet [45],\nleaf rust in wheat [46], and myrtle\
    \ rust [47]. Notable vegetation indices include the normalized\ndiﬀerence vegetation\
    \ index (NDVI) [48], water index (WI) [49], and photochemical reﬂectance index\n\
    (PRI) [50]. The vast amount of spectral data that is collected using hyperspectral\
    \ imaging provides\ngreat potential in developing new VIs and SDIs for the detection\
    \ of highly speciﬁc plant stresses.\nThe main advantages of hyperspectral imaging\
    \ include its robustness and ability to provide a\nlarge amount of data for analysis;\
    \ however, this can result in instruments being relatively expensive.\nIn addition,\
    \ traditional hyperspectral imaging sensors can be bulky and large, which limits\
    \ their\nportability and range of applications; however, the development of handheld\
    \ spectroradiometers and\nsmall hyperspectral cameras (Figure 4) has largely addressed\
    \ this problem. While these instruments\ntypically have a more limited spectral\
    \ range than a standard hyperspectral sensor, they have the\ncapacity to be used\
    \ with real-time detection applications [51,52]. Spectroradiometers are unable\
    \ to\ncapture hyperspectral images; however, they have been used in many studies\
    \ to detect plant stresses,\nsuch as peanut leaf spot disease [53] and powdery\
    \ mildew in barley [52].\nBiosensors 2020, 10, x FOR PEER REVIEW \n5 of 28 \n\
    the UV range to detect salt stress in barley [39]. Due to the sensors’ ability\
    \ to detect a wide range of \nwavelengths in the electromagnetic spectrum, many\
    \ possibilities remain for evaluating new \ncombinations of wavelengths for plant\
    \ stress detection. \nThe data acquired using hyperspectral techniques are often\
    \ used to compute and create \nvegetation indices (VIs). VIs are computed using\
    \ ratios and combinations of reflectance \nmeasurements at a few specific wavelengths\
    \ and have been used extensively for plant stress \nmonitoring [40–42]. In addition\
    \ to VIs, hyperspectral data can be used to develop spectral disease \nindices\
    \ (SDIs) with the purpose of discriminating between specific plant diseases [43]\
    \ (Table 2). Some \nexamples include indices for detecting powdery mildew in wheat\
    \ [44] and sugar beet [45], cercospora \nleaf spot in sugar beet [45], leaf rust\
    \ in wheat [46], and myrtle rust [47]. Notable vegetation indices \ninclude the\
    \ normalized difference vegetation index (NDVI) [48], water index (WI) [49], and\
    \ \nphotochemical reflectance index (PRI) [50]. The vast amount of spectral data\
    \ that is collected using \nhyperspectral imaging provides great potential in\
    \ developing new VIs and SDIs for the detection of \nhighly specific plant stresses.\
    \ \nThe main advantages of hyperspectral imaging include its robustness and ability\
    \ to provide a \nlarge amount of data for analysis; however, this can result in\
    \ instruments being relatively expensive. \nIn addition, traditional hyperspectral\
    \ imaging sensors can be bulky and large, which limits their \nportability and\
    \ range of applications; however, the development of handheld spectroradiometers\
    \ and \nsmall hyperspectral cameras (Figure 4) has largely addressed this problem.\
    \ While these instruments \ntypically have a more limited spectral range than\
    \ a standard hyperspectral sensor, they have the \ncapacity to be used with real-time\
    \ detection applications [51,52]. Spectroradiometers are unable to \ncapture hyperspectral\
    \ images; however, they have been used in many studies to detect plant stresses,\
    \ \nsuch as peanut leaf spot disease [53] and powdery mildew in barley [52]. \
    \ \nHyperspectral imaging sensors have become increasingly smaller and less expensive;\
    \ however, \nconsiderable progress still remains to create a device that costs\
    \ less than a few hundred U.S. dollars. \nCurrently, the cost of these cameras\
    \ is in the thousands of U.S. dollars, which can make them cost-\nprohibitive\
    \ to many. Future advances in imaging technology over the coming years should\
    \ be able \nto produce a hyperspectral camera or spectrophotometer that is cheaper\
    \ and more accessible. \n \nFigure 4. SpecimIQ miniature hyperspectral camera\
    \ (Specim Ltd., Oulu, Finland). Reprinted from \n[52]. ©2018 Behmann et al. \n\
    3.2. Multispectral Imaging and Spectroscopy \nMultispectral techniques utilize\
    \ data from ranges of wavelengths, rather than hundreds of \nindividual wavelengths\
    \ or narrow wavebands as demonstrated in hyperspectral techniques. A few \nwavelengths\
    \ or wavebands of interest can be chosen for incorporation into a device that\
    \ uses either \nimaging or spectroscopic techniques. Multispectral imaging involves\
    \ data collection using a camera \nor other sensing device to produce image data\
    \ in specified wavelength or waveband regions, while \nmultispectral spectroscopy\
    \ produces spectral data for specified wavebands. Both multispectral \nimaging\
    \ and multispectral spectroscopy have been successfully used to identify plant\
    \ stresses; for \nFigure 4. SpecimIQ miniature hyperspectral camera (Specim Ltd.,\
    \ Oulu, Finland). Reprinted from [52].\n©2018 Behmann et al.\nHyperspectral imaging\
    \ sensors have become increasingly smaller and less expensive; however,\nconsiderable\
    \ progress still remains to create a device that costs less than a few hundred\
    \ U.S. dollars.\nCurrently, the cost of these cameras is in the thousands of U.S.\
    \ dollars, which can make them\ncost-prohibitive to many. Future advances in imaging\
    \ technology over the coming years should be\nable to produce a hyperspectral\
    \ camera or spectrophotometer that is cheaper and more accessible.\n3.2. Multispectral\
    \ Imaging and Spectroscopy\nMultispectral techniques utilize data from ranges\
    \ of wavelengths, rather than hundreds of\nindividual wavelengths or narrow wavebands\
    \ as demonstrated in hyperspectral techniques. A few\nBiosensors 2020, 10, 193\n\
    6 of 27\nwavelengths or wavebands of interest can be chosen for incorporation\
    \ into a device that uses\neither imaging or spectroscopic techniques. Multispectral\
    \ imaging involves data collection using a\ncamera or other sensing device to\
    \ produce image data in speciﬁed wavelength or waveband regions,\nwhile multispectral\
    \ spectroscopy produces spectral data for speciﬁed wavebands. Both multispectral\n\
    imaging and multispectral spectroscopy have been successfully used to identify\
    \ plant stresses;\nfor example, multispectral imaging was used to detect leaf\
    \ spot disease in oilseed rape [54], gray mold\nin tomato leaves [55], and nutrient\
    \ deﬁciencies in tomato plants [56], while multispectral spectroscopy\nwas used\
    \ to detect nitrogen deﬁciency stress in maize [57], drought stress in tomato\
    \ plants [58],\nand nitrogen deﬁciency in canola plants [59]. Multispectral techniques\
    \ oﬀer more aﬀordable sensors\nthan their hyperspectral counterparts; however,\
    \ they do not provide as much information about the\nplant and its environment\
    \ due to the broader wavebands. Nevertheless, other advantages multispectral\n\
    methods have are their portability and ﬂexibility, which can aid in the creation\
    \ of customized devices.\nBand-pass ﬁlters could be used in conjunction with a\
    \ camera or other imaging device to acquire data\nin desired spectral ranges at\
    \ a low cost. Recent modiﬁcations in smartphone cameras now permit\nthe capture\
    \ of NIR wavelengths; Chung et al. (2018) utilized an 800 nm high-pass ﬁlter attached\
    \ to a\nsmartphone to acquire both NIR and red images towards detection of plant\
    \ stress [60].\n3.3. RGB Imaging\nRGB (visible or red-green-blue) imaging employs\
    \ sensors that utilize the red, green, and blue\nregions of the spectrum to produce\
    \ image data (which is the standard working principle of digital\ncameras). The\
    \ wavelengths captured are approximately 400–499 nm for blue light (maximum at\n\
    475 nm), 500–549 nm for green light (maximum at 520 nm), and 550–750 nm for red\
    \ light (maximum\nat 650 nm) [38]. In this sense, RGB imaging may be considered\
    \ as a special case of multispectral\nimaging. However, as RGB imaging data are\
    \ typically acquired using a digital camera or smartphone\nwhile multispectral\
    \ imaging requires more speciﬁc equipment or instrumentation, they are typically\n\
    treated separately.\nThe main advantages of RGB imaging are its aﬀordability and\
    \ small, portable sensor size.\nRGB image sensors are already present on smartphones\
    \ and have been used to successfully evaluate\nplant stresses (Figure 5), such\
    \ as iron deﬁciency chlorosis in soybean [11], various nutrient deﬁciencies in\n\
    black gram [61], early and late blight in potato plants [62], and biotic stresses\
    \ in wheat [63]. Furthermore,\nRGB imaging (especially with smartphones) does\
    \ not require much technical expertise on the user’s\nside since they typically\
    \ make use of commonly used devices such as digital cameras and smartphones.\n\
    Smartphones also have enough computing power to process the captured data, which\
    \ enables rapid\nassessments of plant stresses. However, many factors can complicate\
    \ RGB data, such as lighting,\nenvironmental conditions, time of day, and spectral\
    \ resolution [64,65]. Illumination is a particularly\nimportant concern in terms\
    \ of ﬁeld applications since it can vary greatly depending on the season and\n\
    weather conditions. Diseases with various symptoms and complex image backgrounds\
    \ can create\nfurther complications in processing the data; however, many of these\
    \ diﬃculties can be overcome\nusing image processing and machine learning techniques\
    \ [11].\n3.4. Thermal Imaging/Thermography\nThe main diﬀerence between thermography\
    \ and other methods is its measurement of emitted\nradiation from an object, rather\
    \ than reﬂected radiation [66]. Thermal cameras detect radiation\nin the infrared\
    \ wavelength range, with the resulting measurements being displayed as false-color\n\
    images (Figure 6) where the pixels contain the temperature values. Thermographic\
    \ methods for plant\nstress detection primarily exploit changes in surface temperature\
    \ being a notable stress symptom.\nSmall openings on plant leaves (stomata) that\
    \ control water loss from transpiration may close under\nstress, causing the temperature\
    \ of the plant to increase [67]. Thermography has been used to detect a\nvariety\
    \ of biotic and abiotic stresses, such as Aspergillus carbonarius infection in\
    \ grapes [66], drought\nstress in maize [68], apple scab disease [69], and drought\
    \ stress in sesame plants [70].\nBiosensors 2020, 10, 193\n7 of 27\nBiosensors\
    \ 2020, 10, x FOR PEER REVIEW \n7 of 28 \n \nFigure 5. Smartphone being used to\
    \ evaluate the leaf color of rice plant leaves, which is applicable in \ndetecting\
    \ nitrogen deficiencies. Reprinted with permission from [65]. ©2020 Elsevier.\
    \ \n3.4. Thermal Imaging/Thermography \nThe main difference between thermography\
    \ and other methods is its measurement of emitted \nradiation from an object,\
    \ rather than reflected radiation [66]. Thermal cameras detect radiation in the\
    \ \ninfrared wavelength range, with the resulting measurements being displayed\
    \ as false-color images \n(Figure 6) where the pixels contain the temperature\
    \ values. Thermographic methods for plant stress \ndetection primarily exploit\
    \ changes in surface temperature being a notable stress symptom. Small \nopenings\
    \ on plant leaves (stomata) that control water loss from transpiration may close\
    \ under stress, \ncausing the temperature of the plant to increase [67]. Thermography\
    \ has been used to detect a variety \nof biotic and abiotic stresses, such as\
    \ Aspergillus carbonarius infection in grapes [66], drought stress in \nmaize\
    \ [68], apple scab disease [69], and drought stress in sesame plants [70]. \n\
    Thermography is a relatively simple method that can be incorporated into systems\
    \ designed for \nthe rapid detection of plant stress. Thermal cameras are often\
    \ very portable, and attachments have \nbeen developed that can be used with smartphones.\
    \ Among these is the FLIR One, which was used \nby Petrie et al. (2019) to assess\
    \ the water status of grapevines [71]. However, thermographic methods \nare highly\
    \ affected by varying environmental conditions [70], which may make them more\
    \ applicable \nin controlled environment applications rather than an open field.\
    \ Furthermore, thermography lacks \nspecificity and therefore provides a more\
    \ general solution to plant stress detection. It is recommended \nto combine thermography\
    \ with other methods when specific diseases need to be identified since this \n\
    method is not able to distinguish between different stresses and diseases on its\
    \ own [69]. \nFigure 5. Smartphone being used to evaluate the leaf color of rice\
    \ plant leaves, which is applicable in\ndetecting nitrogen deﬁciencies. Reprinted\
    \ with permission from [65]. ©2020 Elsevier.\nBiosensors 2020, 10, x FOR PEER\
    \ REVIEW \n8 of 28 \n \nFigure 6. Thermographic image data used to evaluate drought\
    \ stress in maize plants. In (A,C) the top \nrow consists of well-watered plants,\
    \ while the bottom row is drought-stressed. Similarly, in (B,D), \nwell-watered\
    \ plants are in the left row, while drought-stressed plants are in the right.\
    \ Reprinted with \npermission from [68]. ©2019 Casari et al. \n3.5. Fluorescence\
    \ Spectroscopy \nThe above-mentioned imaging methods (hyperspectral, multispectral,\
    \ and RGB imaging) \nquantify the attenuations of incident light by the samples\
    \ (plant leaves in this case) over the range of \nwavelengths, i.e., spectrophotometric\
    \ detection. Since many components in plant leaves exhibit \ncolorations and subsequently\
    \ spectrophotometric responses, the resulting spectrophotometric \nimages tend\
    \ to be quite complex. Fluorescence-based methods can fix this issue, as only\
    \ a small \nnumber of components in plant leaves exhibit fluorescence. Fluorescent\
    \ molecules (e.g., chlorophyll, \nFigure 6. Thermographic image data used to evaluate\
    \ drought stress in maize plants. In (A,C) the top\nrow consists of well-watered\
    \ plants, while the bottom row is drought-stressed. Similarly, in (B,D),\nwell-watered\
    \ plants are in the left row, while drought-stressed plants are in the right.\
    \ Reprinted with\npermission from [68]. ©2019 Casari et al.\nThermography is a\
    \ relatively simple method that can be incorporated into systems designed for\n\
    the rapid detection of plant stress. Thermal cameras are often very portable,\
    \ and attachments have\nBiosensors 2020, 10, 193\n8 of 27\nbeen developed that\
    \ can be used with smartphones. Among these is the FLIR One, which was used by\n\
    Petrie et al. (2019) to assess the water status of grapevines [71]. However, thermographic\
    \ methods\nare highly aﬀected by varying environmental conditions [70], which\
    \ may make them more applicable\nin controlled environment applications rather\
    \ than an open ﬁeld. Furthermore, thermography lacks\nspeciﬁcity and therefore\
    \ provides a more general solution to plant stress detection. It is recommended\n\
    to combine thermography with other methods when speciﬁc diseases need to be identiﬁed\
    \ since this\nmethod is not able to distinguish between diﬀerent stresses and\
    \ diseases on its own [69].\n3.5. Fluorescence Spectroscopy\nThe above-mentioned\
    \ imaging methods (hyperspectral, multispectral, and RGB imaging) quantify\nthe\
    \ attenuations of incident light by the samples (plant leaves in this case) over\
    \ the range of wavelengths,\ni.e., spectrophotometric detection. Since many components\
    \ in plant leaves exhibit colorations and\nsubsequently spectrophotometric responses,\
    \ the resulting spectrophotometric images tend to be quite\ncomplex. Fluorescence-based\
    \ methods can ﬁx this issue, as only a small number of components in plant\nleaves\
    \ exhibit ﬂuorescence. Fluorescent molecules (e.g., chlorophyll, ﬂuorescent dyes,\
    \ etc.) absorb light\nat a speciﬁc wavelength (excitation) and emit at a speciﬁc,\
    \ longer wavelength (emission), thus incident\nand emitted light can be separated.\
    \ The two main types of ﬂuorescence emitted by vegetation are\nblue-green ﬂuorescence\
    \ (400–600 nm) [72] and chlorophyll ﬂuorescence (650–800 nm) [73]. The latter\n\
    can be useful in evaluating photosynthetic activity, which can decrease under\
    \ pathogenic stresses [74].\nAlthough several techniques are available, two major\
    \ methods for acquiring ﬂuorescence data in\nplants are pulse-amplitude modulation\
    \ (PAM) of the measuring light and continuous illumination [75].\nPulse-amplitude\
    \ modulation devices use a pulsed measuring light source, an actinic light source,\
    \ and a\nsaturating light to obtain ﬂuorescence signals [76]. In contrast, light\
    \ is not pulsed when continuous\nillumination is utilized.\nFluorescence can be\
    \ measured as a spectrum from a single point in time [77], or the change in\n\
    ﬂuorescence over time can be monitored (chlorophyll ﬂuorescence kinetics). The\
    \ basic principle behind\nchlorophyll ﬂuorescence techniques is a lowered rate\
    \ of photosynthesis from stresses and subsequent\ndissipation of chlorophyll ﬂuorescence\
    \ [78]. Fluorescence kinetics measurements require the use of\ndark adaptation,\
    \ which consists of placing a plant (or the part of the plant to be measured)\
    \ in the dark\nfor a certain period of time before ﬂuorescence measurements are\
    \ taken. Dark adaptation allows for\nthe measurement of the minimum level of ﬂuorescence\
    \ [79], which is a fundamental value in kinetics\nanalysis since it provides a\
    \ baseline for the other ﬂuorescence measurements taken after the excitation\n\
    light has been introduced. Plants are usually dark-adapted for a period of 30\
    \ min [80–82]. Regardless\nof whether dark adaptation is utilized or not, it is\
    \ essential to give plants the necessary time to adapt to\nlight conditions before\
    \ measurements (for kinetics applications or standard spectra) are taken.\nFluorescence\
    \ ratios are often used to analyze ﬂuorescence data (both images and spectra)\
    \ for\nevaluating plant stresses. Common ratios involving UV-induced (320–400\
    \ nm) ﬂuorescence include\nF440/F520, F440/F690, F440/F740, and F690/F740; F440/F690\
    \ and F440/F740 are particularly useful for\nearly stress detection applications\
    \ (F represents ﬂuorescence and the numbers represent emission\nwavelengths) [83].\
    \ Bürling et al. (2011) used red/far-red and blue/green amplitude ratios acquired\n\
    from spectral signatures to diﬀerentiate between nitrogen deﬁciency, leaf rust,\
    \ and powdery mildew\nstresses [84]. Although the ratios mentioned above are relatively\
    \ well-established in ﬂuorescence\nresearch, there is still room for exploration\
    \ in determining other ratios that could be used to process data.\nFluorescence\
    \ spectroscopy can identify the location and amount of a speciﬁc component from\n\
    the sample through applying a narrow-range excitation light and detecting a narrow-range\
    \ emission\nfrom such component. Figure 7 is an example of ﬂuorescence spectroscopy,\
    \ where the plant leaves are\nexcited at 488 nm (blue color) and a spectrum with\
    \ wavelengths of >500 nm (green and red colors) is\ncollected. There is a clear\
    \ diﬀerence between the healthy and virus-infected plant leaves. Fluorescence\n\
    spectroscopy has been used in many other studies to detect both biotic and abiotic\
    \ stresses, including\nBiosensors 2020, 10, 193\n9 of 27\ndrought stress in passion\
    \ fruit [80]; nutrient stresses in maize [81], tomato [81], and rapeseed [82]\
    \ crops;\nand citrus canker on grapefruit plants [85].\nFluorescence spectroscopy\
    \ has advantages such as simplicity of use, low cost, and an ability\nto be incorporated\
    \ into hand-held devices for screening applications [79]. In addition, the use\
    \ of\nlaser light as an excitation light source can be more reliable than other\
    \ optical methods, as excitation\nexactly at the sample’s peak excitation wavelength\
    \ can generate stronger and more speciﬁc ﬂuorescent\nemission (as opposed to passive\
    \ measurements) [86]. Fluorescence data can be collected across\nmultiple wavelengths,\
    \ which can provide more information than ﬂuorescence captured at a single\ntargeted\
    \ wavelength. However, ﬂuorescence spectroscopy alone still lacks speciﬁcity [85]\
    \ because\nchanges in ﬂuorescence can be indicative of a wide variety of stresses.\
    \ Therefore, it is necessary to\ncombine this method with others if discrimination\
    \ between speciﬁc stresses is to be achieved. Another\nchallenge related to chlorophyll\
    \ ﬂuorescence kinetics is the reduction of ﬂuorescence intensity over\ntime (photoquenching\
    \ or photobleaching); however, Saleem et al. (2020) were able to mitigate its\
    \ eﬀects\nby measuring ﬂuorescence spectra quickly (about 15 s) after the excitation\
    \ light was introduced [85].\nBiosensors 2020, 10, x FOR PEER REVIEW \n9 of 28\
    \ \nnecessary time to adapt to light conditions before measurements (for kinetics\
    \ applications or standard \nspectra) are taken.  \nFluorescence ratios are often\
    \ used to analyze fluorescence data (both images and spectra) for \nevaluating\
    \ plant stresses. Common ratios involving UV-induced (320–400 nm) fluorescence\
    \ include \nF440/F520, F440/F690, F440/F740, and F690/F740; F440/F690 and F440/F740\
    \ are particularly useful for \nearly stress detection applications (F represents\
    \ fluorescence and the numbers represent emission \nwavelengths) [83]. Bürling\
    \ et al. (2011) used red/far-red and blue/green amplitude ratios acquired \nfrom\
    \ spectral signatures to differentiate between nitrogen deficiency, leaf rust,\
    \ and powdery mildew \nstresses [84]. Although the ratios mentioned above are\
    \ relatively well-established in fluorescence research, \nthere is still room\
    \ for exploration in determining other ratios that could be used to process data.\
    \ \nFluorescence spectroscopy can identify the location and amount of a specific\
    \ component from \nthe sample through applying a narrow-range excitation light\
    \ and detecting a narrow-range emission \nfrom such component. Figure 7 is an\
    \ example of fluorescence spectroscopy, where the plant leaves \nare excited at\
    \ 488 nm (blue color) and a spectrum with wavelengths of >500 nm (green and red\
    \ colors) \nis collected. There is a clear difference between the healthy and\
    \ virus-infected plant leaves. \nFluorescence spectroscopy has been used in many\
    \ other studies to detect both biotic and abiotic \nstresses, including drought\
    \ stress in passion fruit [80]; nutrient stresses in maize [81], tomato [81],\
    \ \nand rapeseed [82] crops; and citrus canker on grapefruit plants [85].  \n\
    \ \nFigure 7. Fluorescence emission spectra of leaves excited at 488 nm. (a) chlorotic\
    \ part of tobacco leaf \ninfected by cucumber mosaic virus; (b) green part of\
    \ tobacco leaf infected with cucumber mosaic \nvirus; (c) a healthy tobacco leaf.\
    \ Reprinted with permission from [77]. ©2016 John Wiley and Sons. \nFluorescence\
    \ spectroscopy has advantages such as simplicity of use, low cost, and an ability\
    \ to \nbe incorporated into hand-held devices for screening applications [79].\
    \ In addition, the use of laser \nlight as an excitation light source can be more\
    \ reliable than other optical methods, as excitation exactly \nat the sample’s\
    \ peak excitation wavelength can generate stronger and more specific fluorescent\
    \ \nemission (as opposed to passive measurements) [86]. Fluorescence data can\
    \ be collected across \nmultiple wavelengths, which can provide more information\
    \ than fluorescence captured at a single \ntargeted wavelength. However, fluorescence\
    \ spectroscopy alone still lacks specificity [85] because \nchanges in fluorescence\
    \ can be indicative of a wide variety of stresses. Therefore, it is necessary\
    \ to \ncombine this method with others if discrimination between specific stresses\
    \ is to be achieved. \nAnother challenge related to chlorophyll fluorescence kinetics\
    \ is the reduction of fluorescence \nintensity over time (photoquenching or photobleaching);\
    \ however, Saleem et al. (2020) were able to \nFigure 7. Fluorescence emission\
    \ spectra of leaves excited at 488 nm. (a) chlorotic part of tobacco leaf\ninfected\
    \ by cucumber mosaic virus; (b) green part of tobacco leaf infected with cucumber\
    \ mosaic virus;\n(c) a healthy tobacco leaf. Reprinted with permission from [77].\
    \ ©2016 John Wiley and Sons.\n3.6. Fluorescence Imaging\nFluorescence imaging\
    \ utilizes a camera to obtain images of ﬂuorescence (Figure 8). It is considered\n\
    an improvement over spectroscopy since it obtains ﬂuorescence data with higher\
    \ dimensions, which can\nprovide more information than single spectra. Rather\
    \ than collecting a spectrum from an area of\ninterest (i.e., ﬂuorescence spectroscopy),\
    \ ﬂuorescence imaging can isolate the area of interest from that\nof non-interest.\
    \ For example, Su et al. (2019) used ﬂuorescence imaging to successfully discriminate\n\
    crops from weeds [87]. One category of continuous ﬂuorescence imaging is multicolor\
    \ ﬂuorescence\nimaging, which typically uses UV excitation light and collects\
    \ ﬂuorescence data from multiple bands,\nsuch as red (F680), far-red (F740), green\
    \ (F520), and blue (F440) [83]. Multicolor ﬂuorescence imaging is\nconceptually\
    \ similar to multispectral imaging since only certain ﬂuorescence wavebands are\
    \ collected\nand combined to produce the image. Fluorescence imaging can also\
    \ be used with dark adaptation and\nchlorophyll ﬂuorescence kinetics applications.\n\
    Fluorescence imaging has been used in many studies to detect both biotic and abiotic\
    \ stresses,\nsuch as herbicide stress in soybeans [88], cold stress in tomato\
    \ seedlings [89], and biotic and abiotic\nBiosensors 2020, 10, 193\n10 of 27\n\
    stresses in barley, grapevine, and sugar beet [90]. A relatively simple and portable\
    \ option for ﬂuorescence\nimage acquisition could consist of a smartphone and\
    \ band-pass ﬁlters (as demonstrated in [91]); however,\nit is currently diﬃcult\
    \ to ﬁnd methods with this type of setup for plant stress applications.\nOne advantage\
    \ of ﬂuorescence-based techniques is their sensible cost of equipment [92]; however,\n\
    they do not always produce a clear distinction of healthy and diseased plant tissues\
    \ at the early stage\nof a disease, so additional methods may be necessary to\
    \ complement ﬂuorescence for early disease\ndetection [93]. Fluorescence-related\
    \ methods could beneﬁt from an increased sensitivity that could\nallow them to\
    \ be used for stress discrimination applications rather than simple stress identiﬁcation.\n\
    data from multiple bands, such as red (F680), far red (F740), green (F520), and\
    \ blue (F440) [83]. \nMulticolor fluorescence imaging is conceptually similar\
    \ to multispectral imaging since only certain \nfluorescence wavebands are collected\
    \ and combined to produce the image. Fluorescence imaging can \nalso be used with\
    \ dark adaptation and chlorophyll fluorescence kinetics applications. \nFluorescence\
    \ imaging has been used in many studies to detect both biotic and abiotic stresses,\
    \ \nsuch as herbicide stress in soybeans [88], cold stress in tomato seedlings\
    \ [89], and biotic and abiotic \nstresses in barley, grapevine, and sugar beet\
    \ [90]. A relatively simple and portable option for \nfluorescence image acquisition\
    \ could consist of a smartphone and band-pass filters (as demonstrated \nin [91]);\
    \ however, it is currently difficult to find methods with this type of setup for\
    \ plant stress \napplications. \nOne advantage of fluorescence-based techniques\
    \ is their sensible cost of equipment [92]; \nhowever, they do not always produce\
    \ a clear distinction of healthy and diseased plant tissues at the \nearly stage\
    \ of a disease, so additional methods may be necessary to complement fluorescence\
    \ for \nearly disease detection [93]. Fluorescence-related methods could benefit\
    \ from an increased sensitivity \nthat could allow them to be used for stress\
    \ discrimination applications rather than simple stress \nidentification. \n \n\
    Figure 8. Fluorescence ratios of barley leaves with nitrogen (N) deficiencies\
    \ of varying severity. \nReprinted from [90]. ©2014 Konanz et al. \n3.7. Combination\
    \ of Sensors \nCombining two or more of the methods mentioned above can provide\
    \ more information on \nplant health as opposed to using just one method. The\
    \ merging of data from multiple sensors has \nFigure 8. Fluorescence ratios of\
    \ barley leaves with nitrogen (N) deﬁciencies of varying severity.\nReprinted\
    \ from [90]. ©2014 Konanz et al.\n3.7. Combination of Sensors\nCombining two or\
    \ more of the methods mentioned above can provide more information on\nplant health\
    \ as opposed to using just one method. The merging of data from multiple sensors\
    \ has\nbeen successful in plant stress detection; for example, Moshou et al. (2011)\
    \ used a combination of\nmultispectral and hyperspectral imaging to detect yellow\
    \ rust in wheat [94]. Many advantages are\noﬀered by using multiple sensors, including\
    \ higher accuracy and decreased sensitivity to changes in\nthe environment [94];\
    \ however, a major challenge is the merging of diﬀerent data types. One possible\n\
    solution is a discriminant analysis, which was used by Berdugo et al. (2014) to\
    \ combine thermographic,\nhyperspectral, and chlorophyll ﬂuorescence data to diﬀerentiate\
    \ between cucumber mosaic virus, green\nmottle mosaic virus, and powdery mildew\
    \ in cucumber plants [95]. Sensor combination shows great\npotential in producing\
    \ accurate, highly speciﬁc data; however, more research is needed in methods\n\
    to combine data from multiple sources with diﬀerent properties and work with larger\
    \ amounts of\ndata [95]. Machine learning could be a pivotal tool in analyzing\
    \ such combinatory sensor data.\nA variety of sensors have been used to identify\
    \ stresses in agricultural crops [96–101]; however,\ntheir detection capabilities\
    \ could be greatly enhanced by incorporating machine learning techniques,\nwhich\
    \ are discussed in the following sections.\nBiosensors 2020, 10, 193\n11 of 27\n\
    Table 1. Optical Methods Used for Plant Stress Detection.\nMethod\nWavelengths\n\
    Plant\nStress Type\nReferences\nHyperspectral\nImaging\n500–850 nm\nMaize\nDrought\
    \ stress\n[32]\n430–890 nm\nBarley\nDrought stress\n[33]\n350–2500 nm\nWheat\n\
    Yellow rust\n[34]\n350–1350 nm\nWheat\nPowdery mildew\n[35]\n380–1030 nm\nOkra\n\
    Salt stress\n[36]\n400–1000 nm\nBanana\nBlack Sigatoka\n[37]\n250–430 nm\nBarley\n\
    Salt stress\n[39]\n400–1000 nm\nBarley\nPowdery mildew\n[52]\n325–1075 nm\nPeanut\n\
    Leaf spot\n[53]\nMultispectral\nSpectroscopy\n400–1100 nm\nMaize\nNutrient deﬁciency\n\
    [57]\n400–980 nm\nTomato\nDrought Stress\n[58]\n430–870 nm\nCanola\nNutrient deﬁciency\n\
    [59]\nMultispectral\nImaging\n365–960 nm\nOilseed Rape\nLight leaf spot\n[54]\n\
    475, 560, 668, 717, 840 nm\nTomato\nGray Mold\n[55]\n550, 660, 735, 790 nm\nTomato\n\
    Nutrient deﬁciency\n(multiple)\n[56]\n620, 870 nm\nPoinsettia\nNitrogen content\n\
    [96]\n450–950 nm\nWheat\nStripe rust, brown rust,\nseptoria tritici blotch\n[97]\n\
    RGB Imaging\nRGB\nSoybean\nIron deﬁciency\n[11]\nRGB\nBlack Gram\nNutrient deﬁciency\
    \ (multiple)\n[61]\nRGB\nPotato\nEarly blight, late blight\n[62]\nRGB\nBasil\n\
    Nitrogen stress\n[98]\nThermography\n7.5–13 µm\nTable Grapes\nAspergillus carbonarius\n\
    [66]\n7.5–13 µm\nMaize\nDrought stress\n[68]\n8–12 µm\nApple\nApple scab\n[69]\n\
    8–14 µm\nSesame\nDrought stress\n[70]\n8–14 µm\nWheat\nDrought stress\n[99]\n\
    Fluorescence\nSpectroscopy 1\n650 nm\nPassion Fruit\nDrought stress\n[80]\n635\
    \ nm\nMaize, Tomato\nNutrient deﬁciency (multiple)\n[81]\n650 nm\nRapeseed\nNutrient\
    \ deﬁciency (multiple)\n[82]\n405 nm\nGrapefruit\nCitrus canker\n[85]\n337 nm\n\
    Wheat\nNutrient deﬁciency, leaf rust,\npowdery mildew\n[84]\nFluorescence\nImaging\
    \ 1\n340, 447, 550 nm\nBarley, Grapevine,\nSugar Beet\nNutrient deﬁciency, black\
    \ rot,\nleaf spot\n[90]\n460 nm\nSoybean\nHerbicide stress\n[88]\n620 nm\nCitrus\n\
    Huanglongbing\n[100]\n684, 687, 757.5, 759.5 nm\n(emission)\nCassava\nMosaic virus\n\
    [101]\n1 In ﬂuorescence spectroscopy and ﬂuorescence imaging, excitation wavelengths\
    \ are shown except noted otherwise.\nTable 2. Equations and Applications of Vegetation\
    \ and Disease Indices.\nIndex Name\nEquation 1\nApplication\nReferences\nVegetation\
    \ Indices\nEnhanced Vegetation Index\nEVI = 2.5 ×\nR800−R670\nR800+6.0R670−7.5R479+1\n\
    Rate of photosynthesis, water stress detection\n[41]\nNormalized Diﬀerence Vegetation\
    \ Index\nNDVI = RNIR−RRED\nRNIR+RRED\nPlant growth and development monitoring\n\
    [48]\nWater Index\nWI = R900\nR970\nPlant water content estimation\n[49]\nPhotochemical\
    \ Reﬂectance Index\nPRI = R570−R531\nR570+R531\nPhotosynthetic eﬃciency\n[50]\n\
    Disease Indices\nPowdery Mildew Index (Wheat)\nPMI = R515−R698\nR515+R698 − 0.5R738\n\
    Powdery mildew detection in wheat\n[44]\nPowdery Mildew Index (Sugar Beet)\nPMI\
    \ = R520−R584\nR520+R584 + R724\nPowdery mildew detection in sugar beet\n[45]\n\
    Cercospora Leaf Spot Index\nCLS = R698−R570\nR698+R570 − R734\nCercospora leaf\
    \ spot detection in sugar beet\n[45]\nLeaf Rust Disease Severity Index 1\nLRDSI1\
    \ = 6.9 R605\nR455 − 1.2\nSeverity estimation of wheat leaf rust\n[46]\nLeaf Rust\
    \ Disease Severity Index 2\nLRDSI2 = 4.2 R695\nR455 − 0.38\nSeverity estimation\
    \ of wheat leaf rust\n[46]\nLemon Myrtle—Myrtle Rust Index\nLMMR =\n\x10 R545\n\
    R555\n\x11 5\n3 × R1505\nR2195\nMyrtle rust detection in lemon myrtle\n[47]\n\
    1 R represents the measured reﬂectance at the wavelength or waveband speciﬁed\
    \ by the subscript.\nBiosensors 2020, 10, 193\n12 of 27\n4. Machine Learning for\
    \ Data Processing\nMachine learning has opened possibilities for new data analysis\
    \ methods in a myriad of ﬁelds,\nincluding medicine, environmental science, and\
    \ economics. Fundamentally, machine learning employs\ntechniques to learn from\
    \ the given data without providing explicit programming commands [102],\nwhich\
    \ can result in the detection of new patterns that may otherwise be overlooked\
    \ using traditional\nanalytical methods. Major processes in a machine learning\
    \ procedure include data acquisition and\nstorage, preprocessing, classiﬁcation,\
    \ and trait extraction [103]. Figure 9 [104] outlines a simpliﬁed\npathway for\
    \ machine learning data analysis methods.\nDisease Severity \nIndex 2 \n\U0001D43F\
    \U0001D445\U0001D437\U0001D446\U0001D43Cଶ = 4.2 \U0001D445ସହହ\n0.38 \nof wheat\
    \ leaf rust \n[46] \nLemon Myrtle—\nMyrtle Rust \nIndex \n\U0001D43F\U0001D440\
    \U0001D440\U0001D445 = ൬\U0001D445ହସହ\n\U0001D445ହହହ\n൰\nହ\nଷ\n× \U0001D445ଵହ଴ହ\n\
    \U0001D445ଶଵଽହ\n \nMyrtle rust \ndetection in lemon \nmyrtle \n[47] \n1 \U0001D445\
    \ represents the measured reflectance at the wavelength or waveband specified\
    \ by the subscript. \n4. Machine Learning for Data Processing \nMachine learning\
    \ has opened possibilities for new data analysis methods in a myriad of fields,\
    \ \nincluding medicine, environmental science, and economics. Fundamentally, machine\
    \ learning \nemploys techniques to learn from the given data without providing\
    \ explicit programming commands \n[102], which can result in the detection of\
    \ new patterns that may otherwise be overlooked using \ntraditional analytical\
    \ methods. Major processes in a machine learning procedure include data \nacquisition\
    \ and storage, preprocessing, classification, and trait extraction [103]. Figure\
    \ 9 [104] outlines \na simplified pathway for machine learning data analysis methods.\
    \ \n \nFigure 9. A simplified machine learning pathway. Reprinted from [104].\
    \ ©2018 Liakos et al. \nFigure 9. A simpliﬁed machine learning pathway. Reprinted\
    \ from [104]. ©2018 Liakos et al.\nMachine learning is advantageous in agriculture-related\
    \ ﬁelds because it can detect patterns using\nsimultaneous combinations of multiple\
    \ factors instead of examining traits individually [102]. The use\nof multiple\
    \ factors is important due to the frequently high complexity of the environment\
    \ surrounding\nplants, where variables such as changing light intensity, direction,\
    \ and leaf angle can alter results.\nMachine learning can be used not only for\
    \ classiﬁcation purposes but also for pre-processing steps\nsuch as feature extraction\
    \ and dimensionality reduction.\nThe assessment of plant health includes stress\
    \ identiﬁcation, discrimination, and quantiﬁcation.\nIdentiﬁcation involves looking\
    \ for symptoms (early or late) of a speciﬁc stress, discrimination consists\n\
    of both identifying a speciﬁc stress and separating the symptoms from those of\
    \ other stresses,\nand quantiﬁcation is a measurement of the severity of the stress.\
    \ Machine learning has been utilized\nfor all these applications, as outlined\
    \ in Table 3.\nThe selection of a machine learning method or pathway depends on\
    \ the speciﬁc problem being\naddressed; as such, there is currently no speciﬁc\
    \ approach that can be recommended for all applications.\nThe following sections\
    \ will provide an overview of machine learning data processing techniques that\n\
    have been used for various agricultural applications.\n4.1. Preprocessing\nData\
    \ preprocessing is essential to ensure the accuracy and reproducibility of classiﬁcation\n\
    results [105]. Preprocessing consists of one or more operations that aim to improve\
    \ the performance of\nthe classiﬁcation algorithms by providing data in a more\
    \ accessible and normalized format. Image\npreprocessing techniques may include\
    \ image cropping, background removal, contrast enhancement,\nimage thresholding,\
    \ noise removal with ﬁlters, clustering, and principal component analysis (PCA)\
    \ [102].\nAlthough this section deals mostly with imaging techniques, spectral\
    \ data may also be processed\nusing some of the listed methods, such as PCA. Outlined\
    \ below are some preprocessing steps that are\ncommonly applied to imaging data.\n\
    4.1.1. Color Space Conversion\nColor space conversion is a data processing technique\
    \ that can be used with RGB images as another\nway to represent color. Color spaces\
    \ can be used to acquire additional color features from images to\naid in feature\
    \ extraction and image classiﬁcation. Several studies have used features obtained\
    \ from\nBiosensors 2020, 10, 193\n13 of 27\ncolor space conversion to process\
    \ RGB data for plant stress detection, including L*a*b* (L* = lightness\nfrom\
    \ black to white, a* = from green to red, and b* = from blue to yellow) to detect\
    \ bacterial blight,\nfruit spot, fruit rot, and leaf spot in pomegranate plants\
    \ [106]; HSI (hue, saturation, intensity) to detect\nearly scorch, late scorch,\
    \ cottony mold, ashen mold, and tiny whiteness in plants [107]; and YCbCr\n(Y\
    \ = luma component; Cb and Cr = blue- and red-diﬀerences of chroma components)\
    \ to detect diseases\nin soybean [108]. A few alternative color spaces are outlined\
    \ in Figure 10 [109].\nBiosensors 2020, 10, x FOR PEER REVIEW \n14 of 28 \n \n\
    Figure 10. An RGB (visible or red-green-blue) image represented using other color\
    \ spaces. Adapted \nwith permission from [109]. ©2018 John Wiley and Sons. \n\
    4.1.2. Dimensionality Reduction \nDimensionality reduction is a process that aims\
    \ to provide a more compact representation of \ndata while preserving as much\
    \ information as possible. A common method for dimensionality \nreduction is principal\
    \ component analysis (PCA), which geometrically projects data onto lower \ndimensions\
    \ (principal components) that act as feature summaries [110]. PCA can combine\
    \ dependent \n(or highly correlated) variables into a common variable while minimizing\
    \ the loss of information. By \ndoing so, the dimensionality of data can be reduced.\
    \ The first principal component (PC1) is evaluated \nfrom the data set. Then PC2\
    \ is evaluated from the remainders, and the process is repeated, e.g., PC3, \n\
    PC4, etc. The principal components (PCs) represent data variances, and these can\
    \ be plotted in 2D or \n3D plots (in the case of two or three PCs) known as PCR\
    \ score plots.  \nAll PCs can also be fed into the various machine learning models\
    \ as a pre-processing step of \ndimensionality reduction. PCA has been used in\
    \ many studies as an important preprocessing step to \nmanage both imaging and\
    \ spectral data. For example, PCA was used in an image preprocessing \npipeline\
    \ by Lu et al. (2017) to aid in acquiring feature maps [111]. While better dimensionality\
    \ \nreduction methods have recently emerged, e.g., linear discriminant analysis\
    \ (LDA) that can maximize \nthe class separation, PCA is often preferred over\
    \ the recent methods as an unbiased dimensionality \nreduction method. PCA can\
    \ be a valuable tool to aid in data interpretation, but one disadvantage of \n\
    this method is its ability to be influenced by outliers in the data [112]. \n\
    4.1.3. Segmentation \nImage segmentation is a process that can organize an image\
    \ into key areas, such as the object \nand its background. This technique is useful\
    \ in agricultural applications due to its ability to reduce \nerrors or misclassifications\
    \ resulting from noise in the background. Notable methods include \nclustering-based\
    \ approaches such as k-means, which can be useful in identifying stressed areas\
    \ of a \nplant in an image [107]. Disease detection applications may require other\
    \ techniques such as pixel \nremoval and masking [113]. For example, Ma et al.\
    \ (2018) used excess red index (ExR), H from the \nFigure 10. An RGB (visible\
    \ or red-green-blue) image represented using other color spaces. Adapted\nwith\
    \ permission from [109]. ©2018 John Wiley and Sons.\n4.1.2. Dimensionality Reduction\n\
    Dimensionality reduction is a process that aims to provide a more compact representation\
    \ of data\nwhile preserving as much information as possible. A common method for\
    \ dimensionality reduction\nis principal component analysis (PCA), which geometrically\
    \ projects data onto lower dimensions\n(principal components) that act as feature\
    \ summaries [110]. PCA can combine dependent (or highly\ncorrelated) variables\
    \ into a common variable while minimizing the loss of information. By doing so,\n\
    the dimensionality of data can be reduced. The ﬁrst principal component (PC1)\
    \ is evaluated from the\ndata set. Then PC2 is evaluated from the remainders,\
    \ and the process is repeated, e.g., PC3, PC4, etc.\nThe principal components\
    \ (PCs) represent data variances, and these can be plotted in 2D or 3D plots\n\
    (in the case of two or three PCs) known as PCR score plots.\nAll PCs can also\
    \ be fed into the various machine learning models as a pre-processing step of\n\
    dimensionality reduction. PCA has been used in many studies as an important preprocessing\
    \ step\nto manage both imaging and spectral data. For example, PCA was used in\
    \ an image preprocessing\npipeline by Lu et al. (2017) to aid in acquiring feature\
    \ maps [111]. While better dimensionality reduction\nmethods have recently emerged,\
    \ e.g., linear discriminant analysis (LDA) that can maximize the class\nseparation,\
    \ PCA is often preferred over the recent methods as an unbiased dimensionality\
    \ reduction\nmethod. PCA can be a valuable tool to aid in data interpretation,\
    \ but one disadvantage of this method\nis its ability to be inﬂuenced by outliers\
    \ in the data [112].\nBiosensors 2020, 10, 193\n14 of 27\n4.1.3. Segmentation\n\
    Image segmentation is a process that can organize an image into key areas, such\
    \ as the object and\nits background. This technique is useful in agricultural\
    \ applications due to its ability to reduce errors or\nmisclassiﬁcations resulting\
    \ from noise in the background. Notable methods include clustering-based\napproaches\
    \ such as k-means, which can be useful in identifying stressed areas of a plant\
    \ in an\nimage [107]. Disease detection applications may require other techniques\
    \ such as pixel removal and\nmasking [113]. For example, Ma et al. (2018) used\
    \ excess red index (ExR), H from the HSV (hue,\nsaturation, value) color space,\
    \ and b* from the L*a*b* color space to discriminate between disease spots\nand\
    \ background in images [114]. An example of segmentation being used to separate\
    \ plants from the\nbackground of an image is demonstrated in Figure 11 [115].\n\
    Biosensors 2020, 10, x FOR PEER REVIEW \n15 of 28 \n \nFigure 11. A visualization\
    \ of the image segmentation process. (a,d) are the original samples of well-\n\
    watered and drought-stressed maize plants. (b,e) are preliminary segmentation\
    \ images acquired \nusing RGB pixel values and linear support vector machine (SVM),\
    \ while (c,f) are the images denoised \nusing the mathematical morphology method.\
    \ Reprinted with permission from [115]. ©2017 Elsevier. \n4.1.4. Feature Extraction\
    \ \nFeature extraction can be used to express data in a format that is more accessible\
    \ to machine-\nlearning algorithms [105]. It consists of reducing redundant data\
    \ and collecting a set of extracted \nfeatures; for images, available techniques\
    \ include Global Color Histogram [116], Local Binary \nPatterns [117], and Color\
    \ Coherence Vector [118]. Features can include color-related characteristics \n\
    such as the variance of color channels and texture features such as contrast and\
    \ channel homogeneity \n[114]. These acquired features are then analyzed using\
    \ the classification algorithms. \n4.2. Machine Learning Algorithms for Classification\
    \ \nOnce the necessary preprocessing steps are complete, the data can be fed into\
    \ a machine learning \nalgorithm for classification. These algorithms attempt\
    \ to find patterns in data to use in assigning \nclasses (e.g., stressed vs. healthy)\
    \ to unlabeled data [29]. Machine learning algorithms can be divided \ninto supervised,\
    \ weakly-supervised, and unsupervised categories, all of which can be used for\
    \ \nclassification [119,120]. The major difference among these algorithms is supervised\
    \ learning involves \nthe use of labeled training data to predict the labels of\
    \ testing data; weakly-supervised learning can \nuse smaller datasets, coarse\
    \ labels, or misclassified labels for training, and unsupervised learning \nuses\
    \ only unlabeled data [120]. One of the most prominent examples of unsupervised\
    \ learning is \nclustering algorithms, which create clusters consisting of samples\
    \ with similar traits [121].  \nMany machine learning algorithms have been used\
    \ in agriculture to classify data; however, the \nmost common methods include\
    \ artificial neural networks (ANNs) [122] and support vector machines \n(SVMs)\
    \ [29]. This review will primarily focus on SVM, ANN, and deep learning methods;\
    \ however, \nFigure 11. A visualization of the image segmentation process. (a,d)\
    \ are the original samples of\nwell-watered and drought-stressed maize plants.\
    \ (b,e) are preliminary segmentation images acquired\nusing RGB pixel values and\
    \ linear support vector machine (SVM), while (c,f) are the images denoised\nusing\
    \ the mathematical morphology method. Reprinted with permission from [115]. ©2017\
    \ Elsevier.\n4.1.4. Feature Extraction\nFeature extraction can be used to express\
    \ data in a format that is more accessible to machine-learning\nalgorithms [105].\
    \ It consists of reducing redundant data and collecting a set of extracted features;\n\
    for images, available techniques include Global Color Histogram [116], Local Binary\
    \ Patterns [117],\nand Color Coherence Vector [118]. Features can include color-related\
    \ characteristics such as the variance\nof color channels and texture features\
    \ such as contrast and channel homogeneity [114]. These acquired\nfeatures are\
    \ then analyzed using the classiﬁcation algorithms.\n4.2. Machine Learning Algorithms\
    \ for Classiﬁcation\nOnce the necessary preprocessing steps are complete, the\
    \ data can be fed into a machine learning\nalgorithm for classiﬁcation. These\
    \ algorithms attempt to ﬁnd patterns in data to use in assigning\nclasses (e.g.,\
    \ stressed vs.\nhealthy) to unlabeled data [29].\nMachine learning algorithms\
    \ can be\ndivided into supervised, weakly-supervised, and unsupervised categories,\
    \ all of which can be used for\nclassiﬁcation [119,120]. The major diﬀerence among\
    \ these algorithms is supervised learning involves\nthe use of labeled training\
    \ data to predict the labels of testing data; weakly-supervised learning can\n\
    use smaller datasets, coarse labels, or misclassiﬁed labels for training, and\
    \ unsupervised learning uses\nBiosensors 2020, 10, 193\n15 of 27\nonly unlabeled\
    \ data [120]. One of the most prominent examples of unsupervised learning is clustering\n\
    algorithms, which create clusters consisting of samples with similar traits [121].\n\
    Many machine learning algorithms have been used in agriculture to classify data;\
    \ however,\nthe most common methods include artiﬁcial neural networks (ANNs) [122]\
    \ and support vector\nmachines (SVMs) [29]. This review will primarily focus on\
    \ SVM, ANN, and deep learning methods;\nhowever, other algorithms such as random\
    \ forest [123] have been successfully used for plant stress\nidentiﬁcation applications.\n\
    Machine learning techniques can be very robust classiﬁers, yet one drawback is\
    \ their tendency\nto overﬁt the data (especially when the data set is small),\
    \ which results in incorrect classiﬁcations.\nIn addition, machine learning can\
    \ be time-consuming, especially when large image ﬁles are involved.\nBoth issues,\
    \ however, can be mitigated using some of the following processes. One method\
    \ that has been\nused to mitigate overﬁtting errors in image classiﬁcation is\
    \ data augmentation, which consists of slightly\ndistorting the images using techniques\
    \ such as rotation [124], mirroring [125], and color variation [126].\nIf data\
    \ augmentation and image manipulation are deemed necessary in the data processing\
    \ pathway,\nthey must be performed before running the data through the classiﬁcation\
    \ algorithm.\n4.2.1. Support Vector Machine (SVM)\nSVM is a supervised learning\
    \ method, i.e., requiring training data set to identify classes of\nunknown data.\
    \ Let us assume a simple case that most (e.g., >90%) of the training data set\
    \ can be\nreduced to two dimensions through dimensionality reduction methods such\
    \ as PCA. These data can be\nplotted on a 2D coordinate system (i.e., PCA score\
    \ plot). With known classes (e.g., stressed vs. healthy)\nof the data, it is possible\
    \ to draw a line that can best separate all of the data into two classes; this\
    \ line is\ncalled a decision boundary (demonstrated in Figure 12 [127]). The procedure\
    \ can also be used for three\nor more dimensions of data, where the boundary becomes\
    \ a plane for three dimensions or a hyperplane\nfor dimensions higher than three.\
    \ It may be necessary to use about 10 principal components from PCA,\nbut this\
    \ dimension number is still substantially small compared to the dimensions of\
    \ the raw data,\nwhich could range from hundreds (for spectra) to millions (for\
    \ images). Testing data is fed into the\nsame data processing pathway as the training\
    \ data, and the decision boundary formed during training\ndetermines the class\
    \ of testing data. While SVM is inherently a linear method, non-linear separation\n\
    is also possible using non-linear kernels. Classiﬁcation into multiple classes\
    \ is also possible using\nmultiple decision boundaries.\nBiosensors 2020, 10,\
    \ x FOR PEER REVIEW \n16 of 28 \nvariation [126]. If data augmentation and image\
    \ manipulation are deemed necessary in the data \nprocessing pathway, they must\
    \ be performed before running the data through the classification \nalgorithm.\
    \ \n4.2.1. Support Vector Machine (SVM) \nSVM is a supervised learning method,\
    \ i.e., requiring training data set to identify classes of \nunknown data. Let\
    \ us assume a simple case that most (e.g., >90%) of the training data set can\
    \ be \nreduced to two dimensions through dimensionality reduction methods such\
    \ as PCA. These data can \nbe plotted on a 2D coordinate system (i.e., PCA score\
    \ plot). With known classes (e.g., stressed vs. \nhealthy) of the data, it is\
    \ possible to draw a line that can best separate all of the data into two classes;\
    \ \nthis line is called a decision boundary (demonstrated in Figure 12 [127]).\
    \ The procedure can also be \nused for three or more dimensions of data, where\
    \ the boundary becomes a plane for three dimensions \nor a hyperplane for dimensions\
    \ higher than three. It may be necessary to use about 10 principal \ncomponents\
    \ from PCA, but this dimension number is still substantially small compared to\
    \ the \ndimensions of the raw data, which could range from hundreds (for spectra)\
    \ to millions (for images). \nTesting data is fed into the same data processing\
    \ pathway as the training data, and the decision \nboundary formed during training\
    \ determines the class of testing data. While SVM is inherently a \nlinear method,\
    \ non-linear separation is also possible using non-linear kernels. Classification\
    \ into \nmultiple classes is also possible using multiple decision boundaries.\
    \ \n \nFigure 12. A decision boundary is established (a line for 2D data) for\
    \ the data reduced in two \ndimensions, e.g., through PCA. Many boundaries can\
    \ be drawn, but the best separation will need to \nbe determined. For 3D, the\
    \ decision boundary is a plane. For dimensions higher than three, the \ndecision\
    \ boundary is a hyperplane. Reprinted with permission from [127]. ©2020 Elsevier.\
    \ \nSVMs are one of the most common machine learning algorithms used in agriculture\
    \ \napplications. They have been successfully used in many studies relating to\
    \ plant stress detection, \nsuch as identifying Huanglongbing (HLB; also known\
    \ as citrus greening disease) and nutrient \nstresses in citrus leaves [100],\
    \ as well as rating the severity of iron deficiency chlorosis in soybeans \n[11].\
    \ A similar method, relevance vector machine (RVM), was used to identify stripe\
    \ rust and \npowdery mildew in wheat. [63].  \nWhile SVM is simple in principle\
    \ and works quite well with very high dimensions of data (such \nas spectra and\
    \ images), it does not explain how close or far away errors are from the true\
    \ class \nFigure 12. A decision boundary is established (a line for 2D data) for\
    \ the data reduced in two dimensions,\ne.g., through PCA. Many boundaries can\
    \ be drawn, but the best separation will need to be determined.\nFor 3D, the decision\
    \ boundary is a plane. For dimensions higher than three, the decision boundary\
    \ is a\nhyperplane. Reprinted with permission from [127]. ©2020 Elsevier.\nSVMs\
    \ are one of the most common machine learning algorithms used in agriculture applications.\n\
    They have been successfully used in many studies relating to plant stress detection,\
    \ such as identifying\nBiosensors 2020, 10, 193\n16 of 27\nHuanglongbing (HLB;\
    \ also known as citrus greening disease) and nutrient stresses in citrus leaves\
    \ [100],\nas well as rating the severity of iron deﬁciency chlorosis in soybeans\
    \ [11]. A similar method, relevance\nvector machine (RVM), was used to identify\
    \ stripe rust and powdery mildew in wheat [63].\nWhile SVM is simple in principle\
    \ and works quite well with very high dimensions of data\n(such as spectra and\
    \ images), it does not explain how close or far away errors are from the true\
    \ class\nidentiﬁcation. This is particularly problematic when the data set is\
    \ noisy, where a distinct decision\nboundary cannot be determined clearly.\n4.2.2.\
    \ Artiﬁcial Neural Network (ANN)\nAn artiﬁcial neural network (ANN) is a machine\
    \ learning model that mimics the function of a\nbiological neural network [128].\
    \ The basic architecture consists of artiﬁcial neurons that process several\n\
    inputs weighted according to their importance and produce a corresponding output\
    \ [124].\nANNs have been used successfully in many studies for the identiﬁcation\
    \ and classiﬁcation\nof various plant stresses. These include detecting powdery\
    \ mildew and soft rot in zucchini [129],\nclassifying biotic stresses in pomegranate\
    \ [106], detecting orange spotting disease in oil palm [130],\nand identifying\
    \ crown rot in wheat [131]. A major advantage of ANNs is their ability to be used\n\
    without specialized knowledge on the data and its interpretation; however, disadvantages\
    \ include\nbeing prone to overﬁtting and requiring greater amounts of computational\
    \ resources [132]. Several\ntypes of ANNs exist, some of which are outlined in\
    \ Figure 13 [133].\nBiosensors 2020, 10, x FOR PEER REVIEW \n17 of 28 \nidentification.\
    \ This is particularly problematic when the data set is noisy, where a distinct\
    \ decision \nboundary cannot be determined clearly. \n4.2.2. Artificial Neural\
    \ Network (ANN)  \nAn artificial neural network (ANN) is a machine learning model\
    \ that mimics the function of a \nbiological neural network [128]. The basic architecture\
    \ consists of artificial neurons that process \nseveral inputs weighted according\
    \ to their importance and produce a corresponding output [124].  \nANNs have been\
    \ used successfully in many studies for the identification and classification\
    \ of \nvarious plant stresses. These include detecting powdery mildew and soft\
    \ rot in zucchini [129], \nclassifying biotic stresses in pomegranate [106], detecting\
    \ orange spotting disease in oil palm [130], \nand identifying crown rot in wheat\
    \ [131]. A major advantage of ANNs is their ability to be used \nwithout specialized\
    \ knowledge on the data and its interpretation; however, disadvantages include\
    \ \nbeing prone to overfitting and requiring greater amounts of computational\
    \ resources [132]. Several \ntypes of ANNs exist, some of which are outlined in\
    \ Figure 13 [133]. \n \nFigure 13. Structures of four types of ANNS: (a) multilayer\
    \ perceptron, where xi represents inputs, Oi \nrepresents output neurons, hi represents\
    \ hidden layer neurons, and wi represents the weights between \nneurons; (b) wavelet,\
    \ where Ψ represents the wavelet function, t represents the translation coefficient,\
    \ \nλ represents the dilation coefficient; (c) radial basis function, where Ri\
    \ represents the radial basis \nfunction; and (d) Elman, where ui represents components\
    \ in the hidden and undertake layers. \nReprinted with permission from [133].\
    \ ©2019 Elsevier. \n4.2.3. Deep Learning  \nDeep learning is a subcategory of\
    \ machine learning that utilizes ANNs and consists of more \nadvanced models with\
    \ multiple layers (“deep” indicates the depth of layers). A common model used\
    \ \nin agriculture is the convolutional neural network (CNN), which performs convolutions\
    \ on data for \nimage classification [134]. CNNs and their variations have been\
    \ frequently used in plant stress studies \nthat utilize machine learning, such\
    \ as detecting the breaking virus in tulips [135], identifying potato \nFigure\
    \ 13. Structures of four types of ANNS: (a) multilayer perceptron, where xi represents\
    \ inputs,\nOi represents output neurons, hi represents hidden layer neurons, and\
    \ wi represents the weights\nbetween neurons; (b) wavelet, where Ψ represents\
    \ the wavelet function, t represents the translation\ncoeﬃcient, λ represents\
    \ the dilation coeﬃcient; (c) radial basis function, where Ri represents the radial\n\
    basis function; and (d) Elman, where ui represents components in the hidden and\
    \ undertake layers.\nReprinted with permission from [133]. ©2019 Elsevier.\nBiosensors\
    \ 2020, 10, 193\n17 of 27\n4.2.3. Deep Learning\nDeep learning is a subcategory\
    \ of machine learning that utilizes ANNs and consists of more\nadvanced models\
    \ with multiple layers (“deep” indicates the depth of layers). A common model\
    \ used\nin agriculture is the convolutional neural network (CNN), which performs\
    \ convolutions on data\nfor image classiﬁcation [134]. CNNs and their variations\
    \ have been frequently used in plant stress\nstudies that utilize machine learning,\
    \ such as detecting the breaking virus in tulips [135], identifying\npotato Y\
    \ virus [136], gauging the severity of apple black spot [119], classifying biotic\
    \ stresses on\ncucumber leaves [114], and rating the severity of biotic stresses\
    \ on coﬀee leaves [126]. Pretrained CNN\nmodels such as GoogleLeNet [137], AlexNet\
    \ [114], ResNet [138], and VGG [139] have also been used.\nFor instances where\
    \ an extensive array of training data is required, many studies utilize databases\n\
    such as PlantVillage [140] and the Wheat Disease Database [141], both of which\
    \ have been used in\nconjunction with deep learning models.\nOne advantage of\
    \ deep learning techniques is that they work well with raw data [142],\nwhich\
    \ therefore cuts down on time spent in data preprocessing (color space conversion,\
    \ dimensionality\nreduction, segmentation, and feature extraction). In addition,\
    \ feature extraction is sometimes performed\nin the deep learning model without\
    \ the need for an outside processing step [143]. However, a major\ndisadvantage\
    \ is a need for large datasets (often numbering in the thousands [139,144]) to\
    \ produce\naccurate results [111].\nBiosensors 2020, 10, 193\n18 of 27\nTable\
    \ 3. Machine Learning Algorithms Used for Plant Stress Detection.\nPurpose\nData\
    \ Type\nPlant\nStress\nAlgorithm\nAccuracy\nReferences\nIdentiﬁcation\nFluorescence\
    \ imaging\nZucchini\nSoft rot\nANN\n100%\n[129]\nSVM\n90%\nLogistic regression\
    \ analysis\n60%\nPowdery mildew\nANN\n71.2%\nSVM\n48.1%\nLogistic regression analysis\n\
    73.1%\nIdentiﬁcation\nHyperspectral\nOil palm\nOrange spotting disease\nMultilayer\
    \ perceptron neural\nnetwork\n-\n[130]\nIdentiﬁcation\nHyperspectral\nWheat\n\
    Crown rot\nANN\n74.14%\n[131]\nLogistic regression\n53.45%\nK nearest-neighbors\n\
    58.62%\nDecision trees\n56.90%\nExtreme random forest\n58.62%\nSVM\n50%\nIdentiﬁcation\n\
    RGB images\nTulip\nTulip breaking virus\nFaster R-CNN\n86% *\n[135]\nIdentiﬁcation\n\
    Hyperspectral\nPotato\nPotato virus Y\nFully convolutional neural\nnetwork\n92%\
    \ *\n[136]\nClassiﬁcation\nRGB images from\nsmartphone\nWheat\nPowdery mildew,\
    \ stripe rust\nRVM\n88.89%\n[63]\nSVM\n77.78%\nClassiﬁcation\nRGB images from\n\
    database\nPomegranate\nFruit spot, bacterial blight,\nfruit rot, leaf spot\nMultilayer\
    \ perceptron\n90%\n[106]\nClassiﬁcation\nRGB images\nCucumber\nAnthracnose, downy\
    \ mildew,\npowdery mildew, target leaf\nspots\nDeep CNN\n92.2%\n[114]\nSVM\n81.9%\n\
    AlexNet\n92.6%\nRandom Forest\n84.8%\nClassiﬁcation\nHyperspectral\nSugar beet\n\
    Cercospora leaf spot, sugar\nbeet rust, powdery mildew\nSVM\n86.42%\n[29]\nClassiﬁcation\n\
    RGB images from\ndatabase\nWheat\nPowdery mildew, smut, black\nchaﬀ, stripe rust,\
    \ leaf blotch,\nleaf rust\nVGG-CNN-S\n73%\n[141]\nVGG-FCN-S\n95.12%\nVGG-CNN-VD16\n\
    93.27%\nVGG-FCN-VD16\n97.95%\nQuantiﬁcation\nHyperspectral\nBarley\nDrought stress\n\
    Ordinal SVM\n67.9%\n[33]\nBiosensors 2020, 10, 193\n19 of 27\nTable 3. Cont.\n\
    Purpose\nData Type\nPlant\nStress\nAlgorithm\nAccuracy\nReferences\nQuantiﬁcation\n\
    RGB images from\ndigital camera\nSoybean\nIron deﬁciency chlorosis\nHierarchical\
    \ SVM-SVM\n99.2%\n[11]\nHierarchical LDA-SVM\n98.3%\nDecision tree\n99.7%\nQuadratic\
    \ discriminant\nanalysis\n98.5%\nNaïve Bayes\n98.4%\nK-Nearest-Neighbors\n99.5%\n\
    Random forest\n99.1%\nGaussian mixture model\n99.4%\nLinear discriminant analysis\n\
    (LDA)\n98.5%\nSVM\n97.3%\nQuantiﬁcation\nRGB images from\ndatabase\nApple\nBlack\
    \ rot\nVGG16\n90.4%\n[119]\nResNet50\n80%\nQuantiﬁcation\nRGB images from\nsmartphone\n\
    Coﬀee\nLeaf miner, rust, brown leaf\nspot, cercospora leaf spot\nAlexNet\n84.13%\n\
    [126]\nGoogleLeNet\n82.94%\nVGG16\n86.51%\nResNet50\n84.13%\nMobileNetV2\n84.52%\n\
    * Indicates a recall value, not an accuracy value.\nBiosensors 2020, 10, 193\n\
    20 of 27\n5. Concluding Remarks\nA variety of optical sensing methods and machine\
    \ learning techniques have been used to recognize\nboth biotic and abiotic stresses,\
    \ especially plant diseases. One observation is that machine learning is\ncommonly\
    \ used to process imaging data (especially RGB images), but spectroscopic methods\
    \ more\nfrequently utilize traditional statistical methods. In the future, machine\
    \ learning methods could be\nfurther incorporated into spectroscopic data analysis\
    \ pathways.\nCurrently, many of the studies mentioned are producing detection\
    \ results that are speciﬁc to just\na few plants. Leaf reﬂectance properties can\
    \ diﬀer greatly between plant species, so it is diﬃcult to\nproduce results that\
    \ are generalizable to several plants in diﬀerent circumstances. The development\
    \ of\nmore generalized (rather than species-speciﬁc) results is likely a future\
    \ direction in plant stress detection;\nhowever, more research is needed to ﬁnd\
    \ features and parameters that can lead to such results. Methods\nsuch as smartphone\
    \ imaging, thermography, and ﬂuorescence imaging have the potential to be scaled\n\
    up to larger-scaled systems to analyze plant canopies in open ﬁelds or controlled\
    \ environments.\nImaging devices (especially multispectral/RGB sensors) have improved\
    \ in quality and become\nmore compact over recent years. Optical resolutions of\
    \ recent smartphones’ cameras are comparable\nto most standalone digital cameras,\
    \ eﬀectively eliminating the bulk of digital camera markets and\nonly leaving\
    \ the high-end markets. Sensitivity has also improved dramatically; the white\
    \ LED ﬂash\nis rarely necessary with recent smartphones. Computing power and memory\
    \ have also improved\nsigniﬁcantly for recent smartphones, which has enabled on-board\
    \ image processing to become a\nreality. Cloud storage and computing for remote\
    \ ﬁle management and execution also complements the\nsmartphone’s computing power\
    \ and memory capacity, allowing for more advanced data processing\noperations\
    \ to be performed. Optical zooms (which magnify images mechanically using optical\
    \ lenses)\nare possible with recent smartphones, although limited at 2x − 4x at\
    \ the time of writing. Furthermore,\nsmartphones have the data processing power\
    \ needed to run machine learning algorithms and thus can\nprovide a rapid, on-site\
    \ assessment of plant stresses.\nThe discrimination of speciﬁc stresses (especially\
    \ stresses from speciﬁc nutrients) remains a\nchallenge. Discrimination may become\
    \ more feasible with improvements in the sensitivity of optical\ndevices; however,\
    \ this increased sensitivity may result in data being more prone to noise from\
    \ the\nsurrounding environment. Environmental noise could be overcome by the use\
    \ of image segmentation\nand machine learning models to help distinguish between\
    \ noise and the targeted characteristic.\nMany improvements are being made with\
    \ imaging technology and data processing techniques that\nwill enable the development\
    \ of robust, portable devices for plant stress detection. Although research is\n\
    still needed in many areas such as the fusion of data from multiple sensors and\
    \ discrimination between\nspeciﬁc biotic and abiotic stresses, current developments\
    \ have great potential to be deployed as useful\ntools for the agriculture industry.\n\
    Author Contributions: Conceptualization, A.V.Z. and J.-Y.Y.; literature survey\
    \ and data collection; A.V.Z.;\nliterature analysis: A.V.Z.; writing—original\
    \ draft preparation, A.V.Z.; writing—review and editing, J.-Y.Y.;\nsupervision\
    \ and project administration, J.-Y.Y. All authors have read and agreed to the\
    \ published version of\nthe manuscript.\nFunding: This research received no external\
    \ funding.\nAcknowledgments: We would like to thank the reviewers for their detailed\
    \ comments that helped us improve\nthe manuscript.\nConﬂicts of Interest: The\
    \ authors declare no conﬂict of interest.\nBiosensors 2020, 10, 193\n21 of 27\n\
    References\n1.\nThe Future of Food and Agriculture: Trends and Challenges; Food\
    \ and Agriculture Organization of the United\nNations: Rome, Italy, 2017; ISBN\
    \ 978-92-5-109551-5.\n2.\nSavary, S.; Bregaglio, S.; Willocquet, L.; Gustafson,\
    \ D.; Mason D’Croz, D.; Sparks, A.; Castilla, N.; Djurle, A.;\nAllinne, C.; Sharma,\
    \ M.; et al. Crop health and its global impacts on the components of food security.\n\
    Food Secur. 2017, 9, 311–327. [CrossRef]\n3.\nSavary, S.; Willocquet, L.; Pethybridge,\
    \ S.J.; Esker, P.; McRoberts, N.; Nelson, A. The global burden of\npathogens and\
    \ pests on major food crops. Nat. Ecol. Evol. 2019, 3, 430–439. [CrossRef] [PubMed]\n\
    4.\nMcDonald, B.A.; Stukenbrock, E.H. Rapid emergence of pathogens in agro-ecosystems:\
    \ Global threats to\nagricultural sustainability and food security. Philos. Trans.\
    \ R. Soc. B Biol. Sci. 2016, 371, 20160026. [CrossRef]\n[PubMed]\n5.\nShaw, M.W.;\
    \ Osborne, T.M. Geographic distribution of plant pathogens in response to climate\
    \ change:\nPathogen distributions and climate. Plant Pathol. 2011, 60, 31–43.\
    \ [CrossRef]\n6.\nYeo, A. Predicting the interaction between the eﬀects of salinity\
    \ and climate change on crop plants. Sci. Hortic.\n1998, 78, 159–174. [CrossRef]\n\
    7.\nSui, X.; Zheng, Y.; Li, R.; Padmanabhan, C.; Tian, T.; Groth-Helms, D.; Keinath,\
    \ A.P.; Fei, Z.; Wu, Z.;\nLing, K.-S. Molecular and Biological Characterization\
    \ of Tomato mottle mosaic virus and Development of\nRT-PCR Detection. Plant Dis.\
    \ 2017, 101, 704–711. [CrossRef]\n8.\nCimmino, A.; Iannaccone, M.; Petriccione,\
    \ M.; Masi, M.; Evidente, M.; Capparelli, R.; Scortichini, M.; Evidente, A.\n\
    An ELISA method to identify the phytotoxic Pseudomonas syringae pv. actinidiae\
    \ exopolysaccharides: A tool\nfor rapid immunochemical detection of kiwifruit\
    \ bacterial canker. Phytochem. Lett. 2017, 19, 136–140. [CrossRef]\n9.\nAndolﬁ,\
    \ A.; Cimmino, A.; Evidente, A.; Iannaccone, M.; Capparelli, R.; Mugnai, L.; Surico,\
    \ G. A New Flow\nCytometry Technique to Identify Phaeomoniella chlamydospora Exopolysaccharides\
    \ and Study Mechanisms of\nEsca Grapevine Foliar Symptoms. Plant Dis. 2009, 93,\
    \ 680–684. [CrossRef]\n10.\nMcKenzie, D.B.; Hossner, L.R.; Newton, R.J. Sorghum\
    \ cultivar evaluation for iron chlorosis resistance by\nvisual scores. J. Plant\
    \ Nutr. 1984, 7, 677–685. [CrossRef]\n11.\nNaik, H.S.; Zhang, J.; Lofquist, A.;\
    \ Assefa, T.; Sarkar, S.; Ackerman, D.; Singh, A.; Singh, A.K.;\nGanapathysubramanian,\
    \ B. A real-time phenotyping framework using machine learning for plant stress\n\
    severity rating in soybean. Plant Methods 2017, 13, 23. [CrossRef]\n12.\nZhu,\
    \ J.; He, W.; Yao, J.; Yu, Q.; Xu, C.; Huang, H.; Mhae, B.; Jandug, C. Spectral\
    \ Reﬂectance Characteristics\nand Chlorophyll Content Estimation Model of Quercus\
    \ aquifolioides Leaves at Diﬀerent Altitudes in Sejila\nMountain. Appl. Sci. 2020,\
    \ 10, 3636. [CrossRef]\n13.\nLichtenthaler, H.K.; Gitelson, A.; Lang, M. Non-Destructive\
    \ Determination of Chlorophyll Content of Leaves\nof a Green and an Aurea Mutant\
    \ of Tobacco by Reﬂectance Measurements. J. Plant Physiol. 1996, 148, 483–493.\n\
    [CrossRef]\n14.\nGitelson, A.A.; Zur, Y.; Chivkunova, O.B.; Merzlyak, M.N. Assessing\
    \ Carotenoid Content in Plant Leaves\nwith Reﬂectance Spectroscopy. Photochem.\
    \ Photobiol. 2002, 75, 272–281. [CrossRef]\n15.\nVilfan, N.; Van der Tol, C.;\
    \ Yang, P.; Wyber, R.; Malenovský, Z.; Robinson, S.A.; Verhoef, W. Extending\n\
    Fluspect to simulate xanthophyll driven leaf reﬂectance dynamics. Remote Sens.\
    \ Environ. 2018, 211, 345–356.\n[CrossRef]\n16.\nBone, R.A.; Lee, D.W.; Norman,\
    \ J.M. Epidermal cells functioning as lenses in leaves of tropical rain-forest\n\
    shade plants. Appl. Opt. 1985, 24, 1408. [CrossRef] [PubMed]\n17.\nGrant, L.;\
    \ Daughtry, C.S.T.; Vanderbilt, V.C. Polarized and specular reﬂectance variation\
    \ with leaf surface\nfeatures. Physiol. Plant. 1993, 88, 1–9. [CrossRef]\n18.\n\
    Ehleringer, J.; Bjorkman, O.; Mooney, H.A. Leaf Pubescence: Eﬀects on Absorptance\
    \ and Photosynthesis in a\nDesert Shrub. Science 1976, 192, 376–377. [CrossRef]\n\
    19.\nBornman, J.F.; Vogelmann, T.C. Eﬀect of UV-B Radiation on Leaf Optical Properties\
    \ Measured with Fibre\nOptics. J. Exp. Bot. 1991, 42, 547–554. [CrossRef]\n20.\n\
    Peñuelas, J.; Filella, I.; Biel, C.; Serrano, L.; Savé, R. The reﬂectance at the\
    \ 950–970 nm region as an indicator\nof plant water status. Int. J. Remote Sens.\
    \ 1993, 14, 1887–1905. [CrossRef]\n21.\nLiew, O.; Chong, P.; Li, B.; Asundi, A.\
    \ Signature Optical Cues: Emerging Technologies for Monitoring Plant\nHealth.\
    \ Sensors 2008, 8, 3205–3239. [CrossRef]\nBiosensors 2020, 10, 193\n22 of 27\n\
    22.\nSawinski, K.; Mersmann, S.; Robatzek, S.; Böhmer, M. Guarding the Green:\
    \ Pathways to Stomatal Immunity.\nMol. Plant-Microbe Interact. 2013, 26, 626–632.\
    \ [CrossRef] [PubMed]\n23.\nFourty, T.; Baret, F.; Jacquemoud, S.; Schmuck, G.;\
    \ Verdebout, J. Leaf optical properties with explicit\ndescription of its biochemical\
    \ composition: Direct and inverse problems. Remote Sens. Environ. 1996,\n56, 104–117.\
    \ [CrossRef]\n24.\nde Lima, R.B.; dos Santos, T.B.; Vieira, L.G.E.; de Lourdes\
    \ Lúcio Ferrarese, M.; Ferrarese-Filho, O.; Donatti, L.;\nBoeger, M.R.T.; de Oliveira\
    \ Petkowicz, C.L. Salt stress alters the cell wall polysaccharides and anatomy\
    \ of\ncoﬀee (Coﬀea arabica L.) leaf cells. Carbohydr. Polym. 2014, 112, 686–694.\
    \ [CrossRef] [PubMed]\n25.\nAllen, W.A.; Richardson, A.J. Interaction of Light\
    \ with a Plant Canopy. J. Opt. Soc. Am. 1968, 58, 1023.\n[CrossRef]\n26.\nCarter,\
    \ G.A. Responses of Leaf Spectral Reﬂectance to Plant Stress. Am. J. Bot. 1993,\
    \ 80, 239–243. [CrossRef]\n27.\nRosique, F.; Navarro, P.J.; Fernández, C.; Padilla,\
    \ A. A Systematic Review of Perception System and Simulators\nfor Autonomous Vehicles\
    \ Research. Sensors 2019, 19, 648. [CrossRef]\n28.\nPandey, P.; Ge, Y.; Stoerger,\
    \ V.; Schnable, J.C. High Throughput In vivo Analysis of Plant Leaf Chemical\n\
    Properties Using Hyperspectral Imaging. Front. Plant Sci. 2017, 8, 1348. [CrossRef]\n\
    29.\nRumpf, T.; Mahlein, A.-K.; Steiner, U.; Oerke, E.-C.; Dehne, H.-W.; Plümer,\
    \ L. Early detection and classiﬁcation\nof plant diseases with Support Vector\
    \ Machines based on hyperspectral reﬂectance. Comput. Electron. Agric.\n2010,\
    \ 74, 91–99. [CrossRef]\n30.\nYang, W.; Yang, C.; Hao, Z.; Xie, C.; Li, M. Diagnosis\
    \ of Plant Cold Damage Based on Hyperspectral Imaging\nand Convolutional Neural\
    \ Network. IEEE Access 2019, 7, 118239–118248. [CrossRef]\n31.\nZovko, M.; Žibrat,\
    \ U.; Knapiˇc, M.; Kovaˇci´c, M.B.; Romi´c, D. Hyperspectral remote sensing of\
    \ grapevine\ndrought stress. Precis. Agric. 2019, 20, 335–347. [CrossRef]\n32.\n\
    Asaari, M.S.M.; Mertens, S.; Dhondt, S.; Inzé, D.; Wuyts, N.; Scheunders, P. Analysis\
    \ of hyperspectral images\nfor detection of drought stress and recovery in maize\
    \ plants in a high-throughput phenotyping platform.\nComput. Electron. Agric.\
    \ 2019, 162, 749–758. [CrossRef]\n33.\nBehmann, J.; Steinrücken, J.; Plümer, L.\
    \ Detection of early plant stress responses in hyperspectral images.\nISPRS J.\
    \ Photogramm. Remote Sens. 2014, 93, 98–111. [CrossRef]\n34.\nZhang, J.; Yuan,\
    \ L.; Pu, R.; Loraamm, R.W.; Yang, G.; Wang, J. Comparison between wavelet spectral\
    \ features\nand conventional spectral features in detecting yellow rust for winter\
    \ wheat. Comput. Electron. Agric. 2014,\n100, 79–87. [CrossRef]\n35.\nCao, X.;\
    \ Luo, Y.; Zhou, Y.; Duan, X.; Cheng, D. Detection of powdery mildew in two winter\
    \ wheat cultivars\nusing canopy hyperspectral reﬂectance. Crop Prot. 2013, 45,\
    \ 124–131. [CrossRef]\n36.\nFeng, X.; Zhan, Y.; Wang, Q.; Yang, X.; Yu, C.; Wang,\
    \ H.; Tang, Z.; Jiang, D.; Peng, C.; He, Y. Hyperspectral\nimaging combined with\
    \ machine learning as a tool to obtain high-throughput plant salt-stress phenotyping.\n\
    Plant J. 2020, 101, 1448–1461. [CrossRef] [PubMed]\n37.\nOchoa, D.; Cevallos,\
    \ J.; Vargas, G.; Criollo, R.; Romero, D.; Castro, R.; Bayona, O. Hyperspectral\
    \ Imaging\nSystem for Disease Scanning on Banana Plants. In Proceedings of the\
    \ Sensing for Agriculture and Food\nQuality and Safety VIII, Baltimore, MD, USA,\
    \ 20–21 April 2016. [CrossRef]\n38.\nLowe, A.; Harrison, N.; French, A.P. Hyperspectral\
    \ image analysis techniques for the detection and\nclassiﬁcation of the early\
    \ onset of plant disease and stress. Plant Methods 2017, 13, 80. [CrossRef]\n\
    39.\nBrugger, A.; Behmann, J.; Paulus, S.; Luigs, H.-G.; Kuska, M.T.; Schramowski,\
    \ P.; Kersting, K.; Steiner, U.;\nMahlein, A.-K. Extending Hyperspectral Imaging\
    \ for Plant Phenotyping to the UV-Range. Remote Sens. 2019,\n11, 1401. [CrossRef]\n\
    40.\nRyu, J.-H.; Jeong, H.; Cho, J. Performances of Vegetation Indices on Paddy\
    \ Rice at Elevated Air Temperature,\nHeat Stress, and Herbicide Damage. Remote\
    \ Sens. 2020, 12, 2654. [CrossRef]\n41.\nLiu, Q.; Zhang, F.; Chen, J.; Li, Y.\
    \ Water stress altered photosynthesis-vegetation index relationships for\nwinter\
    \ wheat. Agron. J. 2020, 112, 2944–2955. [CrossRef]\n42.\nIhuoma, S.O.; Madramootoo,\
    \ C.A. Sensitivity of spectral vegetation indices for monitoring water stress\
    \ in\ntomato plants. Comput. Electron. Agric. 2019, 163, 104860. [CrossRef]\n\
    43.\nMeng, R.; Lv, Z.; Yan, J.; Chen, G.; Zhao, F.; Zeng, L.; Xu, B. Development\
    \ of Spectral Disease Indices for\nSouthern Corn Rust Detection and Severity Classiﬁcation.\
    \ Remote Sens. 2020, 12, 3233. [CrossRef]\nBiosensors 2020, 10, 193\n23 of 27\n\
    44.\nHuang, W.; Guan, Q.; Luo, J.; Zhang, J.; Zhao, J.; Liang, D.; Huang, L.;\
    \ Zhang, D. New Optimized Spectral\nIndices for Identifying and Monitoring Winter\
    \ Wheat Diseases. IEEE J. Sel. Top. Appl. Earth Obs. Remote Sens.\n2014, 7, 2516–2524.\
    \ [CrossRef]\n45.\nMahlein, A.-K.; Rumpf, T.; Welke, P.; Dehne, H.-W.; Plümer,\
    \ L.; Steiner, U.; Oerke, E.-C. Development\nof spectral indices for detecting\
    \ and identifying plant diseases. Remote Sens. Environ. 2013, 128, 21–30.\n[CrossRef]\n\
    46.\nAshourloo, D.; Mobasheri, M.; Huete, A. Developing Two Spectral Disease Indices\
    \ for Detection of Wheat\nLeaf Rust (Pucciniatriticina). Remote Sens. 2014, 6,\
    \ 4723–4740. [CrossRef]\n47.\nHeim, R.H.J.; Wright, I.J.; Allen, A.P.; Geedicke,\
    \ I.; Oldeland, J. Developing a spectral disease index for myrtle\nrust (Austropuccinia\
    \ psidii). Plant Pathol. 2019, 68, 738–745. [CrossRef]\n48.\nRouse, J.W.; Haas,\
    \ R.H.; Schell, J.A.; Deering, D.W. Monitoring Vegetation Systems in the Great\
    \ Plains with\nERTS. NASA Goddard Space Flight Cent. 3d ERTS-1 Symp. 1974, 1,\
    \ 9.\n49.\nPenuelas, J.; Pinol, J.; Ogaya, R.; Filella, I. Estimation of plant\
    \ water concentration by the reﬂectance Water\nIndex WI (R900/R970). Int. J. Remote\
    \ Sens. 1997, 18, 2869–2875. [CrossRef]\n50.\nGamon, J.A.; Peñuelas, J.; Field,\
    \ C.B. A narrow-waveband spectral index that tracks diurnal changes in\nphotosynthetic\
    \ eﬃciency. Remote Sens. Environ. 1992, 41, 35–44. [CrossRef]\n51.\nBalasundram,\
    \ S.K.; Golhani, K.; Shamshiri, R.R.; Vadamalai, G. Precision Agriculture Technologies\
    \ for\nManagement of Plant Diseases. In Plant Disease Management Strategies for\
    \ Sustainable Agriculture through\nTraditional and Modern Approaches; Ul Haq,\
    \ I., Ijaz, S., Eds.; Sustainability in Plant and Crop Protection;\nSpringer:\
    \ Cham, Switzerland, 2020; Volume 13, pp. 259–278, ISBN 978-3-030-35954-6.\n52.\n\
    Behmann, J.; Acebron, K.; Emin, D.; Bennertz, S.; Matsubara, S.; Thomas, S.; Bohnenkamp,\
    \ D.; Kuska, M.;\nJussila, J.; Salo, H.; et al. Specim IQ: Evaluation of a New,\
    \ Miniaturized Handheld Hyperspectral Camera\nand Its Application for Plant Phenotyping\
    \ and Disease Detection. Sensors 2018, 18, 441. [CrossRef]\n53.\nChen, T.; Zhang,\
    \ J.; Chen, Y.; Wan, S.; Zhang, L. Detection of peanut leaf spots disease using\
    \ canopy\nhyperspectral reﬂectance. Comput. Electron. Agric. 2019, 156, 677–683.\
    \ [CrossRef]\n54.\nVeys, C.; Chatziavgerinos, F.; AlSuwaidi, A.; Hibbert, J.;\
    \ Hansen, M.; Bernotas, G.; Smith, M.; Yin, H.; Rolfe, S.;\nGrieve, B. Multispectral\
    \ imaging for presymptomatic analysis of light leaf spot in oilseed rape. Plant\
    \ Methods\n2019, 15, 4. [CrossRef]\n55.\nFahrentrapp, J. Detection of Gray Mold\
    \ Leaf Infections Prior to Visual Symptom Appearance Using a\nFive-Band Multispectral\
    \ Sensor. Front. Plant Sci. 2019, 10, 628. [CrossRef] [PubMed]\n56.\nCardim Ferreira\
    \ Lima, M.; Krus, A.; Valero, C.; Barrientos, A.; del Cerro, J.; Roldán-Gómez,\
    \ J.J. Monitoring\nPlant Status and Fertilization Strategy through Multispectral\
    \ Images. Sensors 2020, 20, 435. [CrossRef]\n[PubMed]\n57.\nKiti´c, G.; Tagarakis,\
    \ A.; Cselyuszka, N.; Pani´c, M.; Birgermajer, S.; Sakulski, D.; Matovi´c, J.\
    \ A new low-cost\nportable multispectral optical device for precise plant status\
    \ assessment. Comput. Electron. Agric. 2019,\n162, 300–308. [CrossRef]\n58.\n\
    Veys, C.; Hibbert, J.; Davis, P.; Grieve, B. An ultra-low-cost active multispectral\
    \ crop diagnostics device.\nIn Proceedings of the 2017 IEEE Sensors, Glasgow,\
    \ UK, 29 October–1 November 2017; pp. 1–3.\n59.\nHabibullah, M.; Mohebian, M.R.;\
    \ Soolanayakanahally, R.; Bahar, A.N.; Vail, S.; Wahid, K.A.; Dinh, A.\nLow-Cost\
    \ Multispectral Sensor Array for Determining Leaf Nitrogen Status.\nNitrogen 2020,\
    \ 1, 67–80.\n[CrossRef]\n60.\nChung, S.; Breshears, L.E.; Yoon, J.-Y. Smartphone\
    \ near infrared monitoring of plant stress. Comput. Electron.\nAgric. 2018, 154,\
    \ 93–98. [CrossRef]\n61.\nWatchareeruetai, U.; Noinongyao, P.; Wattanapaiboonsuk,\
    \ C.; Khantiviriya, P.; Duangsrisai, S. Identiﬁcation of\nPlant Nutrient Deﬁciencies\
    \ Using Convolutional Neural Networks; IEEE: Krabi, Thailand, 2018; pp. 1–4.\n\
    62.\nIslam, M.; Anh, D.; Wahid, K.; Bhowmik, P. Detection of potato diseases using\
    \ image segmentation and\nmulticlass support vector machine. In Proceedings of\
    \ the 2017 IEEE 30th Canadian Conference on Electrical\nand Computer Engineering\
    \ (CCECE), Windsor, ON, Canada, 30 April–3 May 2017; pp. 1–4.\n63.\nXie, X.; Zhang,\
    \ X.; He, B.; Liang, D.; Zhang, D.; Huang, L. A System for Diagnosis of Wheat\
    \ Leaf Diseases\nBased on Android Smartphone. In Proceedings of the International\
    \ Symposium on Optical Measurement\nTechnology and Instrumentation, Beijing, China,\
    \ 9–11 May 2016. [CrossRef]\n64.\nMattupalli, C.; Moﬀet, C.; Shah, K.; Young,\
    \ C. Supervised Classiﬁcation of RGB Aerial Imagery to Evaluate\nthe Impact of\
    \ a Root Rot Disease. Remote Sens. 2018, 10, 917. [CrossRef]\nBiosensors 2020,\
    \ 10, 193\n24 of 27\n65.\nTao, M.; Ma, X.; Huang, X.; Liu, C.; Deng, R.; Liang,\
    \ K.; Qi, L. Smartphone-based detection of leaf color levels\nin rice plants.\
    \ Comput. Electron. Agric. 2020, 173, 105431. [CrossRef]\n66.\nMastrodimos, N.;\
    \ Lentzou, D.; Templalexis, C.; Tsitsigiannis, D.I.; Xanthopoulos, G. Development\
    \ of\nthermography methodology for early diagnosis of fungal infection in table\
    \ grapes: The case of Aspergillus\ncarbonarius. Comput. Electron. Agric. 2019,\
    \ 165, 104972. [CrossRef]\n67.\nJones, H.G. Use of infrared thermometry for estimation\
    \ of stomatal conductance as a possible aid to irrigation\nscheduling. Agric.\
    \ For. Meteorol. 1999, 95, 139–149. [CrossRef]\n68.\nCasari, R.; Paiva, D.; Silva,\
    \ V.; Ferreira, T.; Souza, J.M.; Oliveira, N.; Kobayashi, A.; Molinari, H.; Santos,\
    \ T.;\nGomide, R.; et al. Using Thermography to Conﬁrm Genotypic Variation for\
    \ Drought Response in Maize.\nInt. J. Mol. Sci. 2019, 20, 2273. [CrossRef] [PubMed]\n\
    69.\nOerke, E.-C.; Fröhling, P.; Steiner, U. Thermographic assessment of scab\
    \ disease on apple leaves. Precis. Agric.\n2011, 12, 699–715. [CrossRef]\n70.\n\
    Khorsandi, A.; Hemmat, A.; Mireei, S.A.; Amirfattahi, R.; Ehsanzadeh, P. Plant\
    \ temperature-based indices\nusing infrared thermography for detecting water status\
    \ in sesame under greenhouse conditions. Agric. Water\nManag. 2018, 204, 222–233.\
    \ [CrossRef]\n71.\nPetrie, P.R.; Wang, Y.; Liu, S.; Lam, S.; Whitty, M.A.; Skewes,\
    \ M.A. The accuracy and utility of a low\ncost thermal camera and smartphone-based\
    \ system to assess grapevine water status. Biosyst. Eng. 2019,\n179, 126–139.\
    \ [CrossRef]\n72.\nLang, M.; Siﬀel, P.; Braunová, Z.; Lichtenthaler, H.K. Investigations\
    \ of the Blue-green Fluorescence Emission\nof Plant Leaves. Bot. Acta 1992, 105,\
    \ 435–440. [CrossRef]\n73.\nKrause, G.H.; Weis, E. Chlorophyll ﬂuorescence as\
    \ a tool in plant physiology: II. Interpretation of ﬂuorescence\nsignals. Photosynth.\
    \ Res. 1984, 5, 139–157. [CrossRef]\n74.\nSwarbrick, P.J.; Schulze-Lefert, P.;\
    \ Scholes, J.D. Metabolic consequences of susceptibility and resistance\n(race-speciﬁc\
    \ and broad-spectrum) in barley leaves challenged with powdery mildew. Plant Cell\
    \ Environ.\n2006, 29, 1061–1076. [CrossRef]\n75.\nLawson, T.; Vialet-Chabrand,\
    \ S. Chlorophyll Fluorescence Imaging.\nIn Photosynthesis; Covshoﬀ, S.,\nEd.;\
    \ Methods in Molecular Biology; Springer: New York, NY, USA, 2018; Volume 1770,\
    \ pp. 121–140.\nISBN 978-1-4939-7785-7.\n76.\nBrooks, M.D.; Niyogi, K.K. Use of\
    \ a Pulse-Amplitude Modulated Chlorophyll Fluorometer to Study the\nEﬃciency of\
    \ Photosynthesis in Arabidopsis Plants.\nIn Chloroplast Research in Arabidopsis;\
    \ Jarvis, R.P.,\nEd.; Methods in Molecular Biology; Humana Press: Totowa, NJ,\
    \ USA, 2011; Volume 775, pp. 299–310,\nISBN 978-1-61779-236-6.\n77.\nLei, R.;\
    \ Du, Z.; Qiu, Y.; Zhu, S. The detection of hydrogen peroxide involved in plant\
    \ virus infection\nby ﬂuorescence spectroscopy: Detection of hydrogen peroxide\
    \ in plant by ﬂuorescence spectroscopy.\nLuminescence 2016, 31, 1158–1165. [CrossRef]\n\
    78.\nLichtenthaler, H.K.; Rinderle, U. The Role of Chlorophyll Fluorescence in\
    \ the Detection of Stress Conditions\nin Plants. CRC Crit. Rev. Anal. Chem. 1988,\
    \ 19, S29–S85. [CrossRef]\n79.\nMurchie, E.H.; Lawson, T. Chlorophyll ﬂuorescence\
    \ analysis: A guide to good practice and understanding\nsome new applications.\
    \ J. Exp. Bot. 2013, 64, 3983–3998. [CrossRef]\n80.\nGomes, M.T.G.; da Luz, A.C.;\
    \ dos Santos, M.R.; do Carmo Pimentel Batitucci, M.; Silva, D.M.; Falqueto, A.R.\n\
    Drought tolerance of passion fruit plants assessed by the OJIP chlorophyll a ﬂuorescence\
    \ transient. Sci. Hortic.\n2012, 142, 49–56. [CrossRef]\n81.\nKalaji, H.M.; Oukarroum,\
    \ A.; Alexandrov, V.; Kouzmanova, M.; Brestic, M.; Zivcak, M.; Samborska, I.A.;\n\
    Cetner, M.D.; Allakhverdiev, S.I.; Goltsev, V. Identiﬁcation of nutrient deﬁciency\
    \ in maize and tomato plants\nby in vivo chlorophyll a ﬂuorescence measurements.\
    \ Plant Physiol. Biochem. 2014, 81, 16–25. [CrossRef]\n[PubMed]\n82.\nKalaji,\
    \ H.M.; B ˛aba, W.; Gediga, K.; Goltsev, V.; Samborska, I.A.; Cetner, M.D.; Dimitrova,\
    \ S.; Piszcz, U.;\nBielecki, K.; Karmowska, K.; et al. Chlorophyll ﬂuorescence\
    \ as a tool for nutrient status identiﬁcation in\nrapeseed plants. Photosynth.\
    \ Res. 2018, 136, 329–343. [CrossRef] [PubMed]\n83.\nBuschmann, C.; Lichtenthaler,\
    \ H.K. Principles and characteristics of multi-colour ﬂuorescence imaging of\n\
    plants. J. Plant Physiol. 1998, 152, 297–314. [CrossRef]\nBiosensors 2020, 10,\
    \ 193\n25 of 27\n84.\nBürling, K.; Hunsche, M.; Noga, G. Use of blue–green and\
    \ chlorophyll ﬂuorescence measurements for\ndiﬀerentiation between nitrogen deﬁciency\
    \ and pathogen infection in winter wheat. J. Plant Physiol. 2011,\n168, 1641–1648.\
    \ [CrossRef]\n85.\nSaleem, M.; Atta, B.M.; Ali, Z.; Bilal, M. Laser-induced ﬂuorescence\
    \ spectroscopy for early disease detection\nin grapefruit plants. Photochem. Photobiol.\
    \ Sci. 2020, 19, 713–721. [CrossRef]\n86.\nLins, E.C.; Belasque, J.; Marcassa,\
    \ L.G. Detection of citrus canker in citrus plants using laser induced\nﬂuorescence\
    \ spectroscopy. Precis. Agric. 2009, 10, 319–330. [CrossRef]\n87.\nSu, W.H.; Fennimore,\
    \ S.A.; Slaughter, D.C. Fluorescence imaging for rapid monitoring of translocation\n\
    behaviour of systemic markers in snap beans for automated crop/weed discrimination.\
    \ Biosyst. Eng. 2019,\n186, 156–167. [CrossRef]\n88.\nLi, H.;\nWang, P.;\nWeber,\
    \ J.;\nGerhards, R. Early Identiﬁcation of Herbicide Stress in Soybean\n(Glycine\
    \ max (L.) Merr.) Using Chlorophyll Fluorescence Imaging Technology.\nSensors\
    \ 2017, 18, 21.\n[CrossRef]\n89.\nDong, Z.; Men, Y.; Li, Z.; Zou, Q.; Ji, J. Chlorophyll\
    \ ﬂuorescence imaging as a tool for analyzing the eﬀects of\nchilling injury on\
    \ tomato seedlings. Sci. Hortic. 2019, 246, 490–497. [CrossRef]\n90.\nKonanz,\
    \ S.; Kocsányi, L.; Buschmann, C. Advanced Multi-Color Fluorescence Imaging System\
    \ for Detection\nof Biotic and Abiotic Stresses in Leaves. Agriculture 2014, 4,\
    \ 79–95. [CrossRef]\n91.\nChung, S.; Breshears, L.E.; Perea, S.; Morrison, C.M.;\
    \ Betancourt, W.Q.; Reynolds, K.A.; Yoon, J.-Y.\nSmartphone-Based Paper Microﬂuidic\
    \ Particulometry of Norovirus from Environmental Water Samples at\nthe Single\
    \ Copy Level. ACS Omega 2019, 4, 11180–11188. [CrossRef] [PubMed]\n92.\nTakayama,\
    \ K.; Nishina, H. Chlorophyll ﬂuorescence imaging of the chlorophyll ﬂuorescence\
    \ induction\nphenomenon for plant health monitoring. Environ. Control Biol. 2009,\
    \ 47, 101–109. [CrossRef]\n93.\nPérez-Bueno, M.L.; Pineda, M.; Barón, M. Phenotyping\
    \ Plant Responses to Biotic Stress by Chlorophyll\nFluorescence Imaging. Front.\
    \ Plant Sci. 2019, 10, 1135. [CrossRef] [PubMed]\n94.\nMoshou, D.; Bravo, C.;\
    \ Oberti, R.; West, J.S.; Ramon, H.; Vougioukas, S.; Bochtis, D. Intelligent multi-sensor\n\
    system for the detection and treatment of fungal diseases in arable crops. Biosyst.\
    \ Eng. 2011, 108, 311–321.\n[CrossRef]\n95.\nBerdugo, C.A.; Zito, R.; Paulus,\
    \ S.; Mahlein, A.-K. Fusion of sensor data for the detection and diﬀerentiation\n\
    of plant diseases in cucumber. Plant Pathol. 2014, 63, 1344–1356. [CrossRef]\n\
    96.\nAdhikari, R.; Li, C.; Kalbaugh, K.; Nemali, K. A low-cost smartphone controlled\
    \ sensor based on image\nanalysis for estimating whole-plant tissue nitrogen (N)\
    \ content in ﬂoriculture crops. Comput. Electron. Agric.\n2020, 169, 105173. [CrossRef]\n\
    97.\nBebronne, R.; Carlier, A.; Meurs, R.; Leemans, V.; Vermeulen, P.; Dumont,\
    \ B.; Mercatoris, B. In-ﬁeld proximal\nsensing of septoria tritici blotch, stripe\
    \ rust and brown rust in winter wheat by means of reﬂectance and\ntextural features\
    \ from multispectral imagery. Biosyst. Eng. 2020, 197, 257–269. [CrossRef]\n98.\n\
    Brambilla, M. Application of a low-cost RGB sensor to detect basil (Ocimum basilicum\
    \ L.) nutritional status at\npilot scale level. Precis. Agric. 2020, 20. [CrossRef]\n\
    99.\nBanerjee, K.; Krishnan, P.; Das, B. Thermal imaging and multivariate techniques\
    \ for characterizing and\nscreening wheat genotypes under water stress condition.\
    \ Ecol. Indic. 2020, 119, 106829. [CrossRef]\n100. Cen, H.; Weng, H.; Yao, J.;\
    \ He, M.; Lv, J.; Hua, S.; Li, H.; He, Y. Chlorophyll Fluorescence Imaging Uncovers\n\
    Photosynthetic Fingerprint of Citrus Huanglongbing. Front. Plant Sci. 2017, 8,\
    \ 1509. [CrossRef] [PubMed]\n101. Raji, S.N.; Subhash, N.; Ravi, V.; Saravanan,\
    \ R.; Mohanan, C.N.; Nita, S.; Kumar, T.M. Detection of mosaic\nvirus disease\
    \ in cassava plants by sunlight-induced ﬂuorescence imaging: A pilot study for\
    \ proximal sensing.\nInt. J. Remote Sens. 2015, 36, 2880–2897. [CrossRef]\n102.\
    \ Singh, A.; Ganapathysubramanian, B.; Singh, A.K.; Sarkar, S. Machine Learning\
    \ for High-Throughput Stress\nPhenotyping in Plants. Trends Plant Sci. 2016, 21,\
    \ 110–124. [CrossRef] [PubMed]\n103. Ramos-Giraldo, P.; Reberg-Horton, C.; Locke,\
    \ A.M.; Mirsky, S.; Lobaton, E. Drought Stress Detection Using\nLow-Cost Computer\
    \ Vision Systems and Machine Learning Techniques. IT Prof. 2020, 22, 27–29. [CrossRef]\n\
    104. Liakos, K.; Busato, P.; Moshou, D.; Pearson, S.; Bochtis, D. Machine Learning\
    \ in Agriculture: A Review.\nSensors 2018, 18, 2674. [CrossRef] [PubMed]\n105.\
    \ Tsaftaris, S.A.; Minervini, M.; Scharr, H. Machine Learning for Plant Phenotyping\
    \ Needs Image Processing.\nTrends Plant Sci. 2016, 21, 989–991. [CrossRef] [PubMed]\n\
    Biosensors 2020, 10, 193\n26 of 27\n106. Dhakate, M.; Ingole, A.B. Diagnosis of\
    \ pomegranate plant diseases using neural network. In Proceedings\nof the 2015\
    \ Fifth National Conference on Computer Vision, Pattern Recognition, Image Processing\
    \ and\nGraphics (NCVPRIPG), Patna, India, 16–19 December 2015; pp. 1–4.\n107.\
    \ Al Bashish, D.; Braik, M.; Bani-Ahmad, S. A framework for detection and classiﬁcation\
    \ of plant leaf and stem\ndiseases. In Proceedings of the 2010 International Conference\
    \ on Signal and Image Processing, Chennai,\nIndia, 15–17 December 2010; pp. 113–118.\n\
    108. Shrivastava, S.; Singh, S.K.; Hooda, D.S. Color sensing and image processing-based\
    \ automatic soybean plant\nfoliar disease severity detection and estimation. Multimed.\
    \ Tools Appl. 2015, 74, 11467–11484. [CrossRef]\n109. Kahu, S.Y.; Raut, R.B.;\
    \ Bhurchandi, K.M. Review and evaluation of color spaces for image/video compression.\n\
    Color Res. Appl. 2018, 44, 8–33. [CrossRef]\n110. Lever, J.; Krzywinski, M.; Altman,\
    \ N. Principal component analysis. Nat. Methods 2017, 14, 641–642.\n[CrossRef]\n\
    111. Lu, Y.; Yi, S.; Zeng, N.; Liu, Y.; Zhang, Y. Identiﬁcation of rice diseases\
    \ using deep convolutional neural\nnetworks. Neurocomputing 2017, 267, 378–384.\
    \ [CrossRef]\n112. Wold, S.; Esbensen, K.; Geladi, P. Principal Component Analysis.\
    \ Chemom. Intell. Lab. Syst. 1987, 2, 37–52.\n[CrossRef]\n113. Singh, V.; Misra,\
    \ A.K. Detection of plant leaf diseases using image segmentation and soft computing\n\
    techniques. Inf. Process. Agric. 2016, 4, 41–49. [CrossRef]\n114. Ma, J.; Du,\
    \ K.; Zheng, F.; Zhang, L.; Gong, Z.; Sun, Z. A recognition method for cucumber\
    \ diseases using leaf\nsymptom images based on deep convolutional neural network.\
    \ Comput. Electron. Agric. 2018, 154, 18–24.\n[CrossRef]\n115. Zhuang, S.; Wang,\
    \ P.; Jiang, B.; Li, M.; Gong, Z. Early detection of water stress in maize based\
    \ on digital\nimages. Comput. Electron. Agric. 2017, 140, 461–468. [CrossRef]\n\
    116. Yue, J.; Li, Z.; Liu, L.; Fu, Z. Content-based image retrieval using color\
    \ and texture fused features.\nMath. Comput. Model. 2011, 54, 1121–1127. [CrossRef]\n\
    117. Ojala, T.; Pietikainen, M.; Maenpaa, T. Multiresolution gray-scale and rotation\
    \ invariant texture classiﬁcation\nwith local binary patterns. IEEE Trans. Pattern\
    \ Anal. Mach. Intell. 2002, 24, 971–987. [CrossRef]\n118. Vatamanu, O.A.; Frandes,\
    \ M.; Ionescu, M.; Apostol, S. Content-Based Image Retrieval using Local Binary\n\
    Pattern, Intensity Histogram and Color Coherence Vector.\nIn Proceedings of the\
    \ 2013 E-Health and\nBioengineering Conference (EHB), Iasi, Romania, 21–23 November\
    \ 2013; pp. 1–6.\n119. Wang, G.; Sun, Y.; Wang, J. Automatic Image-Based Plant\
    \ Disease Severity Estimation Using Deep Learning.\nComput. Intell. Neurosci.\
    \ 2017, 2017, 1–8. [CrossRef]\n120. Zhou, Z.-H. A brief introduction to weakly\
    \ supervised learning. Natl. Sci. Rev. 2018, 5, 44–53. [CrossRef]\n121. Rodriguez,\
    \ M.Z.; Comin, C.H.; Casanova, D.; Bruno, O.M.; Amancio, D.R.; da Costa, L.F.;\
    \ Rodrigues, F.A.\nClustering algorithms: A comparative approach. PLoS ONE 2019,\
    \ 14, e0210236. [CrossRef]\n122. Bindushree, H.B.; Sivasankari, G.G. Application\
    \ of Image Processing Techniques for Plant Leaf Disease\nDetection. Int. J. Eng.\
    \ Res. Technol. (IJERT) 2015, 3, 19.\n123. Johannes, A.; Picon, A.; Alvarez-Gila,\
    \ A.; Echazarra, J.; Rodriguez-Vaamonde, S.; Navajas, A.D.;\nOrtiz-Barredo, A.\
    \ Automatic plant disease diagnosis using mobile capture devices, applied on a\
    \ wheat use\ncase. Comput. Electron. Agric. 2017, 138, 200–209. [CrossRef]\n124.\
    \ Sladojevic, S.; Arsenovic, M.; Anderla, A.; Culibrk, D.; Stefanovic, D. Deep\
    \ Neural Networks Based\nRecognition of Plant Diseases by Leaf Image Classiﬁcation.\
    \ Comput. Intell. Neurosci. 2016, 2016, 1–11.\n[CrossRef] [PubMed]\n125. Ghosal,\
    \ S.; Blystone, D.; Singh, A.K.; Ganapathysubramanian, B.; Singh, A.; Sarkar,\
    \ S. An explainable deep\nmachine vision framework for plant stress phenotyping.\
    \ Proc. Natl. Acad. Sci. USA 2018, 115, 4613–4618.\n[CrossRef] [PubMed]\n126.\
    \ Esgario, J.G.M.; Krohling, R.A.; Ventura, J.A. Deep learning for classiﬁcation\
    \ and severity estimation of coﬀee\nleaf biotic stress. Comput. Electron. Agric.\
    \ 2020, 169, 105162. [CrossRef]\n127. Cervantes, J.; Garcia-Lamont, F.; Rodríguez-Mazahua,\
    \ L.; Lopez, A. A comprehensive survey on support\nvector machine classiﬁcation:\
    \ Applications, challenges and trends. Neurocomputing 2020, 408, 189–215.\n[CrossRef]\n\
    Biosensors 2020, 10, 193\n27 of 27\n128. Krenker, A.; Bester, J.; Kos, A. Introduction\
    \ to the Artiﬁcial Neural Networks.\nIn Artiﬁcial Neural\nNetworks—Methodological\
    \ Advances and Biomedical Applications; Suzuki, K., Ed.; InTech: Rijeka, Croatia,\
    \ 2011;\nISBN 978-953-307-243-2.\n129. Pineda, M.; Pérez-Bueno, M.L.; Paredes,\
    \ V.; Barón, M. Use of multicolour ﬂuorescence imaging for diagnosis\nof bacterial\
    \ and fungal infection on zucchini by implementing machine learning. Funct. Plant\
    \ Biol. 2017,\n44, 563. [CrossRef]\n130. Golhani, K.; Balasundram, S.K.; Vadamalai,\
    \ G.; Pradhan, B. Selection of a Spectral Index for Detection\nof Orange Spotting\
    \ Disease in Oil Palm (Elaeis guineensis Jacq.) Using Red Edge and Neural Network\n\
    Techniques. J. Indian Soc. Remote Sens. 2019, 47, 639–646. [CrossRef]\n131. Humpal,\
    \ J.; McCarthy, C.; Percy, C.; Thomasson, J.A. Detection of crown rot in wheat\
    \ utilising near-infrared\nspectroscopy: Towards remote and robotic sensing. In\
    \ Proceedings of the Autonomous Air and Ground\nSensing Systems for Agricultural\
    \ Optimization and Phenotyping V, Online, 27 April–8 May 2020. [CrossRef]\n132.\
    \ Tu, J.V. Advantages and disadvantages of using artiﬁcial neural networks versus\
    \ logistic regression for\npredicting medical outcomes. J. Clin. Epidemiol. 1996,\
    \ 49, 1225–1231. [CrossRef]\n133. Elsheikh, A.H.; Sharshir, S.W.; Abd Elaziz,\
    \ M.; Kabeel, A.E.; Guilan, W.; Haiou, Z. Modeling of solar energy\nsystems using\
    \ artiﬁcial neural network: A comprehensive review. Sol. Energy 2019, 180, 622–639.\
    \ [CrossRef]\n134. Jin, K.H.; McCann, M.T.; Froustey, E.; Unser, M. Deep Convolutional\
    \ Neural Network for Inverse Problems\nin Imaging. IEEE Trans. Image Process.\
    \ 2017, 26, 4509–4522. [CrossRef]\n135. Polder, G.; van de Westeringh, N.; Kool,\
    \ J.; Khan, H.A.; Kootstra, G.; Nieuwenhuizen, A. Automatic Detection\nof Tulip\
    \ Breaking Virus (TBV) Using a Deep Convolutional Neural Network. IFAC-PapersOnLine\
    \ 2019,\n52, 12–17. [CrossRef]\n136. Polder, G.; Blok, P.M.; de Villiers, H.A.C.;\
    \ van der Wolf, J.M.; Kamp, J. Potato Virus Y Detection in Seed\nPotatoes Using\
    \ Deep Learning on Hyperspectral Images. Front. Plant Sci. 2019, 10, 209. [CrossRef]\
    \ [PubMed]\n137. Mohanty, S.P.; Hughes, D.P.; Salathé, M. Using Deep Learning\
    \ for Image-Based Plant Disease Detection.\nFront. Plant Sci. 2016, 7, 1419. [CrossRef]\
    \ [PubMed]\n138. Zhang, K.; Wu, Q.; Liu, A.; Meng, X. Can Deep Learning Identify\
    \ Tomato Leaf Disease? Adv. Multimed. 2018,\n2018, 1–10. [CrossRef]\n139. Ferentinos,\
    \ K.P. Deep learning models for plant disease detection and diagnosis. Comput.\
    \ Electron. Agric.\n2018, 145, 311–318. [CrossRef]\n140. Saleem, M.H.; Potgieter,\
    \ J.; Mahmood Arif, K. Plant Disease Detection and Classiﬁcation by Deep Learning.\n\
    Plants 2019, 8, 468. [CrossRef]\n141. Lu, J.; Hu, J.; Zhao, G.; Mei, F.; Zhang,\
    \ C. An in-ﬁeld automatic wheat disease diagnosis system.\nComput. Electron. Agric.\
    \ 2017, 142, 369–379. [CrossRef]\n142. Brahimi, M.; Boukhalfa, K.; Moussaoui,\
    \ A. Deep Learning for Tomato Diseases: Classiﬁcation and Symptoms\nVisualization.\
    \ Appl. Artif. Intell. 2017, 31, 299–315. [CrossRef]\n143. LeCun, Y.; Bengio,\
    \ Y.; Hinton, G. Deep learning. Nature 2015, 521, 436–444. [CrossRef]\n144. Dyrmann,\
    \ M.; Karstoft, H.; Midtiby, H.S. Plant species classiﬁcation using deep convolutional\
    \ neural network.\nBiosyst. Eng. 2016, 151, 72–80. [CrossRef]\nPublisher’s Note:\
    \ MDPI stays neutral with regard to jurisdictional claims in published maps and\
    \ institutional\naﬃliations.\n© 2020 by the authors. Licensee MDPI, Basel, Switzerland.\
    \ This article is an open access\narticle distributed under the terms and conditions\
    \ of the Creative Commons Attribution\n(CC BY) license (http://creativecommons.org/licenses/by/4.0/).\n"
  inline_citation: '>'
  journal: Biosensors
  limitations: '>'
  pdf_link: https://www.mdpi.com/2079-6374/10/12/193/pdf?version=1606894587
  publication_year: 2020
  relevance_score1: 0
  relevance_score2: 0
  title: Proximal Methods for Plant Stress Detection Using Optical Sensors and Machine
    Learning
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1016/j.rse.2022.113198
  analysis: '>'
  authors:
  - Katja Berger
  - Miriam Machwitz
  - Marlena Kycko
  - Shawn C. Kefauver
  - Shari Van Wittenberghe
  - Max Gerhards
  - Jochem Verrelst
  - Clement Atzberger
  - Christiaan van der Tol
  - Alexander Damm
  - Uwe Rascher
  - Ittai Herrmann
  - Verónica Sobejano-Paz
  - Sven Fahrner
  - Roland Pieruschka
  - Egor Prikaziuk
  - Ma. Luisa Buchaillot
  - Andrej Halabuk
  - Marco Celesti
  - Gerbrand Koren
  - Esra Tunç Görmüş
  - Micol Rossini
  - Michael Foerster
  - Bastian Siegmann
  - Asmaa Abdelbaki
  - Giulia Tagliabue
  - Tobias Hank
  - Roshanak Darvishzadeh
  - Helge Aasen
  - Mónica García
  - Isabel Pôças
  - Subhajit Bandopadhyay
  - Mauro Sulis
  - Enrico Tomelleri
  - Offer Rozenstein
  - Lachezar Filchev
  - Gheorghe Stancile
  - Martin Schlerf
  citation_count: 52
  full_citation: '>'
  full_text: '>

    Skip to main content Skip to article Journals & Books Search Register Sign in
    Brought to you by: University of Nebraska-Lincoln View PDF Download full issue
    Outline Highlights Abstract Keywords 1. Introduction 2. Stress definitions and
    physiology 3. Remote sensing of stress: Time domains and methodologies 4. Review
    of multi-domain and multi-sensor studies 5. New concepts of sensor synergies 6.
    Conclusions Funding Credit author statement Declaration of Competing Interest
    Acknowledgments References Show full outline Cited by (63) Figures (13) Show 7
    more figures Tables (1) Table 1 Remote Sensing of Environment Volume 280, October
    2022, 113198 Review Multi-sensor spectral synergies for crop stress detection
    and monitoring in the optical domain: A review Author links open overlay panel
    Katja Berger a b, Miriam Machwitz c, Marlena Kycko d, Shawn C. Kefauver e f, Shari
    Van Wittenberghe a, Max Gerhards g, Jochem Verrelst a, Clement Atzberger h, Christiaan
    van der Tol i, Alexander Damm j k, Uwe Rascher l, Ittai Herrmann m, Veronica Sobejano
    Paz n, Sven Fahrner l, Roland Pieruschka l, Egor Prikaziuk i, Ma. Luisa Buchaillot
    e f, Andrej Halabuk o, Marco Celesti p, Gerbrand Koren q…Martin Schlerf c Show
    more Add to Mendeley Share Cite https://doi.org/10.1016/j.rse.2022.113198 Get
    rights and content Under a Creative Commons license open access Highlights • Synergistic
    usage of optical domains permits a holistic view of plant stress. • Three dose-
    and duration-related phases of stress defined. • Study designs were mainly driven
    by available sensors and economic reasons. • Coupling multi-domain observations
    with integrated crop growth models is proposed. Abstract Remote detection and
    monitoring of the vegetation responses to stress became relevant for sustainable
    agriculture. Ongoing developments in optical remote sensing technologies have
    provided tools to increase our understanding of stress-related physiological processes.
    Therefore, this study aimed to provide an overview of the main spectral technologies
    and retrieval approaches for detecting crop stress in agriculture. Firstly, we
    present integrated views on: i) biotic and abiotic stress factors, the phases
    of stress, and respective plant responses, and ii) the affected traits, appropriate
    spectral domains and corresponding methods for measuring traits remotely. Secondly,
    representative results of a systematic literature analysis are highlighted, identifying
    the current status and possible future trends in stress detection and monitoring.
    Distinct plant responses occurring under short-term, medium-term or severe chronic
    stress exposure can be captured with remote sensing due to specific light interaction
    processes, such as absorption and scattering manifested in the reflected radiance,
    i.e. visible (VIS), near infrared (NIR), shortwave infrared, and emitted radiance,
    i.e. solar-induced fluorescence and thermal infrared (TIR). From the analysis
    of 96 research papers, the following trends can be observed: increasing usage
    of satellite and unmanned aerial vehicle data in parallel with a shift in methods
    from simpler parametric approaches towards more advanced physically-based and
    hybrid models. Most study designs were largely driven by sensor availability and
    practical economic reasons, leading to the common usage of VIS-NIR-TIR sensor
    combinations. The majority of reviewed studies compared stress proxies calculated
    from single-source sensor domains rather than using data in a synergistic way.
    We identified new ways forward as guidance for improved synergistic usage of spectral
    domains for stress detection: (1) combined acquisition of data from multiple sensors
    for analysing multiple stress responses simultaneously (holistic view); (2) simultaneous
    retrieval of plant traits combining multi-domain radiative transfer models and
    machine learning methods; (3) assimilation of estimated plant traits from distinct
    spectral domains into integrated crop growth models. As a future outlook, we recommend
    combining multiple remote sensing data streams into crop model assimilation schemes
    to build up Digital Twins of agroecosystems, which may provide the most efficient
    way to detect the diversity of environmental and biotic stresses and thus enable
    respective management decisions. Previous article in issue Next article in issue
    Keywords Precision agriculture multi-modal solar-induced fluorescence satellite
    hyperspectral multispectral biotic and abiotic stress 1. Introduction One of the
    most challenging concerns of today is finding answers to the question “How to
    feed the world?”, as formulated in the 2nd Sustainable Development Goal (SDG),
    FAO (2021). The task is huge as the world population is expected to increase to
    9.8 billion by 2050 (UN, 2017). Thus, global food production needs to be expanded
    by 70% in order to feed the future population, maintain nutritional security,
    account for changing diets and the increasing demand for biological products from
    the construction and energy sectors (Galieni et al., 2021; Mueller et al., 2012;
    Tester and Langridge, 2010). In this context, the environmental impact of agriculture
    must be minimized to protect water, climate, soil, and biodiversity resources
    (Gomiero et al., 2011) while reducing production risks for farmers. Climate change
    is adding pressure, as the frequency of extreme weather events as well as major
    shifts in precipitation and temperature patterns are expected to increase worldwide
    (Cogato et al., 2019; Gomiero et al., 2011). As a consequence, abiotic (e.g.,
    heat and drought) and/or biotic (e.g., diseases and pests) stresses and their
    combinations (Govender et al., 2009), will also become more frequent and lead,
    without swift and effective management responses, to decreases in crop productivity
    (Atzberger, 2013). Thus, early detection of crop stress prior to irreversible
    damage is essential to be able to respond with suitable agrotechnical solutions
    and thus minimize yield loss. For the detection and quantification of biotic and
    abiotic stresses in agricultural crops, destructive and non-destructive methods
    can be used. Some quantitative methods provide sensitive analyses of molecules
    in biological systems, also known as high-throughput-omic techniques (Fiehn, 2001;
    Llanes et al., 2018). However, these methods are not only destructive but also
    time-consuming and costly, limiting their use in continuous monitoring and scalable
    research (Galieni et al., 2021). As for non-destructive quantitative methods,
    remote sensing (RS) technologies have been established, such as imaging spectroscopy,
    fluorescence spectroscopy, thermal and microwave remote sensing, which all provide
    insights into the effects of stress in plants. In contrast to omic techniques,
    RS can be applied at larger spatial scales, with high revisit frequency, hence
    enabling a cost-effective detection of crop stress status and spatiotemporal dynamics
    across cultivated landscapes. Furthermore, RS is suitable for global coverage
    and can thus potentially contribute to enhanced food security in developing countries
    (e.g., Rembold et al., 2000). Driven by new platforms and sensors with enhanced
    spatial, temporal and spectral capacities, RS studies focusing on agricultural
    applications grew exponentially in the last decades (Weiss et al., 2020). Together
    with improvements in computing power and machine learning (ML), unprecedented
    possibilities are offered for precision agriculture and other agricultural applications,
    going along with major improvements in crop stress detection. The most common
    crop stress type analysed by means of RS techniques is drought, i.e., water deficit
    stress Damm et al., 2022; Gago et al., 2015; Gerhards et al., 2016; Govender et
    al., 2009; Ihuoma and Madramootoo, 2017; Parkash and Singh, 2020; Virnodkar et
    al., 2020). Also, other stress factors have been studied with RS, such as insects
    (Herrmann et al., 2017) and pathogens (Gold et al., 2020; Herrmann et al., 2018;
    Mahlein, 2016; Sishodia et al., 2020) nutrient deficiency (Baret et al., 2007;
    Herrmann et al., 2010; Mahajan et al., 2021) or soil contamination (Gholizadeh
    and Kopacková, 2019). Optical remote sensing covers the wavelengths from the visible
    to the shortwave infrared (VSWIR, 400–2500 nm) and the thermal infrared (TIR,
    8–14 μm), collecting radiation reflected and emitted from the observed surfaces.
    When it comes to the detection of plant responses to diverse stresses, visible
    (VIS, 400–700 nm), near-infrared (NIR, 700–1300 nm) and shortwave infrared (SWIR,
    1300–2500 nm) reflectance, but also TIR and solar-induced fluorescence (SIF, often
    at 687 nm and 760 nm, or over the full emission wavelength between 650 and 800
    nm) have been the most exploited passive sensing signals (Gerhards et al., 2019).
    In these spectral domains, information on plant morphology and structure can also
    be derived by means of active sensing devices, such as LiDAR (light detection
    and ranging; Madec et al., 2017), and through stereophotogrammetry using multi-spectral
    imagery (St-Onge et al., 2008). Note that this review explicitly excludes microwave
    technologies. Passive microwave remote sensing operates at spatial scales (typically
    at 0.25°) being too coarse for studies at the farm or field scale. Active microwave
    remote sensing (RADAR) has been shown useful in obtaining crop type information
    (Gella et al., 2021) and surface soil moisture, with potentially high relevance
    for assessing crop water availability. However, we restrict this review to crop
    traits for stress detection and exclude soil attributes. Beyond usage of single
    RS domains, observations in multiple spectral domains are strongly suggested,
    potentially providing a deeper understanding of the complex interactions of stressors
    and affected crop traits (Damm et al., 2018; Jiao et al., 2021). Optical multi-sensor
    synergies for stress-related research in agriculture have been identified for
    precision agriculture (Chaerle et al., 2006; Gerhards et al., 2019; Maes and Steppe,
    2019), but also for plant breeding projects (Herrmann et al., 2020; Pineda et
    al., 2020; Singh et al., 2016; Yang et al., 2017a). The synergistic use of data
    from various electromagnetic domains goes back to the launch of the Thematic Mapper
    (TM) onboard Landsat-4 in 1982. However, the rather coarse spectral and spatial
    resolutions of the sensor and its successors prevented a deeper look into plant
    conditions at sub-field scales. By the end of the 1990s, plant scientists promoted
    near-range sensing for single leaves and plants using thermography, VIS and NIR,
    as well as fluorescence imaging, to improve understanding of plant physiological
    states and related stresses (Chaerle and Van Der Straeten, 2000; Lichtenthaler
    et al., 1998), but challenges in precise image alignment and data calibration
    prevented synergistic usage of such multi-domain data. First synergistic use of
    multi-domain acquisitions has been realized using piloted aircraft (Gerhards et
    al., 2018; Mohammed et al., 2019; Panigada et al., 2014) while miniaturization
    in sensor design has led to the development of drone systems allowing for multi-sensor
    integration at the field level (Aasen et al., 2018). For the first time, the FLuorescence
    EXplorer-Sentinel 3 (FLEX-S3) tandem mission will provide concurrent observations
    of VIS, NIR, SWIR and TIR along with SIF at satellite level. (e.g., Drusch et
    al., 2017). Recent studies propose efficient early stress detection using multi-scale
    UAVs and satellite observations. Within such frameworks, the advantages of both
    platforms can be explored, such as the availability of higher temporal and spatial
    resolution data (Alvarez-Vanhard et al., 2021; Sagan et al., 2019). However, the
    integration of multi-scale approaches goes beyond the scope of this review, which
    is explicitly constrained to synergistic exploitation of multiple spectral domains
    for stress detection in agriculture. While the developments in sensor and airborne
    platform technologies allow for coincident recordings from multiple (spectral)
    domains (e.g., Timmermans et al., 2015), studies exploring these data by applying
    integrative methods to assess plant stress are still rare. Before a multi-domain
    retrieval approach can be defined, all acquired remotely sensed signals must be
    translated into meaningful values (proxies) related to stress (i.e. affected plant
    traits). In this respect, a multitude of modeling and retrieval approaches have
    been investigated (Verrelst et al., 2015, Verrelst et al., 2019a). The majority
    of proposed methods relied on parametric regressions, i.e. use of spectral bands,
    vegetation indices (VIs) or spectral ratios and their relationships with functional
    traits linked to plant stress (e.g. Gerhards et al., 2016; Govender et al., 2009;
    Herrmann et al., 2020). To better understand cause–effect relationships, and to
    simultaneously use the full set of spectral variables, physically-based methods
    opened attractive pathways. For instance, a promising approach is provided by
    the soil-canopy observation, photochemistry and energy fluxes (SCOPE) model (Van
    der Tol et al., 2009; Yang et al., 2021a) and its vertically heterogeneous versions
    mSCOPE (Yang et al., 2017b) and senSCOPE (Pacheco-Labrador et al., 2021), which
    combines radiative transfer approaches with photosynthesis and energy balance
    modeling. In contrast to physically-based approaches, other studies investigated
    methods of reduced complexity but increased efficiency via implementation of data-driven
    approaches, in particular ML regression algorithms (Gewali et al., 2019; Singh
    et al., 2016; Virnodkar et al., 2020). To provide a scientific foundation to the
    pros and cons of different approaches, Sishodia et al. (2020) recently reviewed
    stress-related applications of RS in precision agriculture, including water stress
    and disease detection. The authors stated that advanced approaches using process-based
    physical models should be pursued to complement ML regression algorithms, as for
    instance demonstrated by Reichstein et al. (2019) in the context of surface energy
    balance (SEB) modeling. A pioneering example is provided by Zarco-Tejada et al.
    (2018) who used multi-sensor acquisitions (airborne hyperspectral and thermal)
    to analyse trees undergoing early stress caused by infection with the vector-transmitted
    bacterial plant pathogen Xylella Fastidiosa. The authors estimated fluorescence
    efficiency by exploring a three-dimensional radiative transfer model (RTM) in
    a multi-step inversion scheme. Also, thermal stress indicators were derived, and
    canopy structural and leaf biochemical traits were estimated from RTM inversion.
    In addition, narrow-band spectral indices known to be sensitive to certain functional
    plant traits (i.e., chlorophylls, carotenes and xanthophylls) were calculated.
    All traits and indicators were processed within a multivariate analysis based
    on ML algorithms for the classification of the (pre-visual) disease incidence
    and severity at the landscape scale. Another example of early stress detection
    by multiple spectral domains is provided by Hernández-Clemente et al. (2019).
    The authors reviewed the capability of remotely sensed physiological indicators,
    such as canopy temperature, chlorophyll fluorescence, photosynthesis and pigments
    to monitor the early responses of plants to a variety of stressors. They pointed
    towards the main challenges for the RS community in detecting stress, being: (1)
    the availability of high spatial, spectral and temporal resolution data, (2) the
    validation of diverse retrieval methods, (3) upscaling of physiological traits
    from leaf to canopy-level, and (4) capturing the temporal dynamics and interaction
    of traits as stress proxies. Altogether, despite these advances, critical knowledge
    and methodological gaps for crop stress detection remain. The main gap is that
    currently no concept exists that uses multiple spectral domains in an integrated
    way for a complete view of crop conditions to differentiate between crop stress
    types and to understand the degree of stress severity. This shortcoming can be
    addressed by leveraging the full potential of spectral information provided by
    multi-domain RS data sources in a synergistic way. Therefore, we aim to elaborate
    and propose a new methodological concept for the assessment of multiple plant
    stresses in agriculture through optical RS synergies. To achieve this, we review,
    synthesize and integrate current knowledge across spectral domains, remote sensing
    platforms and retrieval methods for the identification of crop stress. The paper
    is organized as follows: in Chapter 2, we present a general introduction on plant
    stress, physiological strain as well as adaptations to stress at different temporal
    stages. This is followed by RS of stress using distinct proxies and sensor systems
    in Chapter 3. Chapter 4 concentrates on the systematic literature review about
    multi-domain and multi-sensor studies, and Chapter 5 elaborates the proposed multi-sensor
    synergy concept. 2. Stress definitions and physiology 2.1. Stress definitions
    Plants are sessile organisms exposed to biotic and abiotic pressures, i.e. the
    physical, chemical and biological environment characterizing their habitat (Jones
    and Jones, 1989). Abiotic stress includes, among others, radiation, salinity,
    flooding (waterlogging), water stress, temperature extremes, nutrient shortage
    and heavy metals (Gull et al., 2019; Larcher, 2003). Second, plants are influenced
    by their biotic surroundings, referring to other co-occurring organisms. Specifically,
    biotic stress involves inter- and intra-specific competitions as well as diseases
    caused by fungal and bacterial pathogens (Lichtenthaler, 1996), weeds, insect
    pests and/or damage to plants by nematodes, protists, viruses, and viroids (Madani
    et al., 2019). Both the biotic and abiotic interactions can impact the survival
    or success of plant species. Thus, understanding the impacts of different stress
    factors on plants have been the focus of plant physiologists (Larcher, 2003),
    particularly important in crop sciences (Blum, 2016). In general terms, plant
    stress can be defined according to Lichtenthaler (1996) as: ‘any unfavourable
    condition or substance that affects or blocks a plant''s metabolism, growth or
    development’. A simplified description of the effect of various stress factors
    on a plant is outlined in Fig. 1 (Blum, 2016; Kranner et al., 2010). Accordingly,
    plants respond to a changing environment by a coordinated short-term acclimation.
    The response is initiated by biochemical triggers like phytohormones or enzymes
    and leads to a damage and repair cycle, activating the plant metabolism usually
    with small or non-visible phenotypic adaptation (reversible and adaptive strain
    tolerance). With increased severity and duration of the stress exposure, plants
    change their phenotypic expressions through long-term adaptations. This affects,
    for instance, leaf size and thickness, stomatal density, or function of chloroplasts
    depending on high or low light conditions. Depending on the stress factor, the
    adaptation may take days or weeks, while persistent and severe (long-term) stress
    may arise in the final stage and even lead to apoptosis (Lichtenthaler, 1996).
    The ability of plants to vary their phenotypic expression in response to environmental
    conditions is also described as “phenotypic plasticity” (Sultan, 2000), which
    can result in altered phenotypic traits and fluxes. Download : Download high-res
    image (440KB) Download : Download full-size image Fig. 1. Scheme of plant stress,
    strain, and signaling, leading to plant responses and resistance. Adapted from
    (Blum, 2016). It has to be noted that the impact of any stress factor usually
    results in a complex interplay between the plant''s genes and its environment
    often leading to multiple strains, not explicitly shown in Fig. 1. For example,
    high light stress affects fluorescence parameters, impacts photosynthesis, increases
    non-photochemical quenching (NPQ), and enhances leaf temperature leading to increased
    transpiration and changes in leaf angle. Likewise, it must be remarked that the
    effect of a single and/or multiple stress factors, as well as the combination
    of biotic and/or abiotic stresses, can often lead to very similar physiological
    responses in the plants (Blum, 2016; Kranner et al., 2010), see Fig. 1. It is
    also important to consider the timing of stress impacts. For example, short-term
    environmental changes may be reflected in changing flux rates of photosynthesis,
    respiration, and transpiration (Damm et al., 2018). Stress occurring over long-term
    periods during different development stages may affect growth variously. For example,
    drought stress in wheat may affect leaf expansion in the initial phase, the number
    of tillers in the tillering phase, plant height in the stem elongation phase,
    and grain development during the flowering stage, with the period between stem
    elongation and flowering being the most sensitive to drought (Sarto et al., 2017).
    2.2. Stages of plant stress responses Reactions to biotic and abiotic stresses
    usually are continuous but often also non-linear processes (Kranner et al., 2010).
    In general, three phases of the plant stress response may be identified with respect
    to the severity and duration of one or multiple stressors. We exemplary demonstrate
    the phases (or stages) of drought stress and subsequent plant response in Fig.
    2. very mild drought stress usually has little impact on the plant, i.e., initial
    stomatal closure may occur, but the photosynthetic capacity remains high and no
    phenotypic changes are observed. Under increasing stress levels, however, stomatal
    closure reduces the internal CO2 availability, which often triggers the production
    of reactive oxygen species (ROS) and lowers the photosynthetic rates. Moreover,
    leaf temperature increases and changes in leaf angle or leaf rolling are observed.
    As a result, plant growth may be inhibited. A stronger decrease in water availability
    will result in a reduced stomatal conductance affecting the leaf turgor (Abdullah
    et al., 2019). Overproduction and accumulation of ROS and membrane instability
    will lead to cellular damage beyond repair and thus to necrotic spots. Under severe
    drought stress, growth usually stops, and continuous damage may eventually lead
    to apoptosis (see Fig. 1, Fig. 2). Download : Download high-res image (883KB)
    Download : Download full-size image Fig. 2. Biotic and abiotic stress factors
    and the plants'' responses to stress as a function of dose and exposure time:
    early (mild), medium-term or mild long-term, and severe/chronic exposure. These
    stress phases may vary for diverse or combined stressors. This is particularly
    important for agriculture, where often even mild stress may reduce crop growth,
    and finally the yield, particularly when it occurs at crucial growth stages (Fahad
    et al., 2017). Consequently, it is essential to detect and quantify crop stress
    at the earliest possible stage. Only responses affecting the biophysical and functional
    properties and thus, traits of the plants may be detected by RS. Stress factors
    such as water scarcity, water logging, salinity, heat and excessive light often
    induce changes in the rates of photosynthesis, respiration, transpiration and
    stomatal conductance in the early stress stage. This is usually followed by changes
    in amounts and ratios of the photosynthetic pigments (chlorophylls and carotenoids),
    and the concentration of different metabolites at later stages (Lichtenthaler,
    1996). While the remote detection of altered phenotypic traits, such as pigments
    and water content, is prevalent when monitoring medium-term, mild long-term and
    severe or chronic stress, altered photosynthesis and transpiration fluxes and
    their possible feedback mechanisms already show subtle responses under the first
    occurring stress (e.g., Gerhards et al., 2016; Jonard et al., 2020). In fact,
    daily occurring cycles of stress are common for crops as diurnal cycles in radiation
    and temperature show strong variation, often reaching excessive energy inputs
    at solar noon. In general, electromagnetic energy absorbed by plants is used to
    fuel photosynthesis, but under excessive irradiation the photosynthetic apparatus
    needs to immediately adapt energy pathways to avoid photo-damage. Increasing stress
    that inhibits the photosynthetic light reactions induces an increasing dissipation
    of energy by NPQ and reduces the fluorescence yield. The latter is detectable
    over vast vegetated areas as solar-induced fluorescence (SIF), a subtle energy
    flux emitted by vegetation that may be used to detect the onset and progress of
    stress (Ač et al., 2015; Demmig-Adams et al., 2020; Gerhards et al., 2019). Dynamic
    adjustments under early stress are also observed for transpiration, an energy-demanding
    process that decreases leaf surface temperature. Therefore, sensing the canopy
    surface temperature became a useful tool for assessing early changes in plant-water
    and plant-health status (Idso et al., 1981; Jackson et al., 1988; Maes and Steppe,
    2012). 2.3. Common symptoms of crop stress In the following, we describe the causalities
    and illustrate several examples of stress occurrence in crops (Fig. 3). Download
    : Download high-res image (1MB) Download : Download full-size image Fig. 3. Examples
    of distinct biotic (upper box) and abiotic (lower box) stressors (bold) and corresponding
    affected traits/symptoms on crops (mainly). Photographs were provided by the authors.
    Biotic stress responses result from complex interactions between plants and other
    biological organisms and can be very diverse. Often plant responses are induced
    directly by the biotic agents. For instance, in the (common) case of herbivory
    (see Fig. 3(a)), the immediate effect is loss of water content due to wounding
    and loss of functional leaf area combined with the necrosis of the wounded leaf
    parts (Meza-Canales et al., 2017). In this way, biotic pathogens often affect
    a plant locally and then induce a systemic plant response. This may include the
    activation of signal pathways to reduce stomatal conductance (Aldea et al., 2005)
    or increased production of volatile organic compounds (VOCs) as defence mechanisms
    (Holopainen and Gershenzon, 2010; Kessler, 2001). Viruses can also lead to biotic
    stress as shown in Fig. 3(b) for an example of Maize Lethal Necrosis (MLN). MLN
    causes mostly pigment damage but also some structural wilting in advanced stages
    due to necrosis and viral replication related to phosphorous deficiencies. A broad
    diversity in fungal pathogens exists. Some pathogens, such as yellow rust, can
    stimulate photosynthesis during early infection stages as the fungus benefits
    from the increase in sugar production (Chang et al., 2013). However, at a later
    stress stage it may cause decreases in photosynthetic capacity, leading to visible
    foliar lesions (Vergara-Diaz et al., 2015). The diversity of fungal pathogens
    may cause plant diseases, such as anthracnose, leaf spot, rust, or wilt (for an
    overview, see Jain et al. (2019)). Many of these diseases are manifested as changes
    in optical reflectance properties of the canopy, which may be specific to the
    pathogen. Such changes in optical properties can either be detected as radiometric
    changes or can be identified at leaf level through computer vision approaches
    for classification of plant diseases (Singh et al., 2020). Similar symptoms can
    be caused by microbes, as shown in the example of downy mildew in Fig. 3(c). Radiation
    stress or excessive exposure to ultraviolet (UV) sunlight also disturbs plant
    growth when the absorbed excess energy cannot dissipate. It results in an overproduction
    of ROS that may be detoxified or eventually disturb the overall cellular homeostasis
    of the plant (Singh et al., 2020). In Fig. 3(d), the effects of radiation stress
    are shown for an exemplary vineyard. As illustrated in Fig. 3(e), frost or cold
    stress is another serious threat to crops (Yadav, 2010). Moderate cold stress
    reduces plant growth and development, but severe cold stress may lead to stronger
    symptoms. When cold stress coincides with high light intensities, it leads to
    yellowing of leaves (i.e., chlorosis), reduced leaf expansion and wilting, and
    finally necrosis, i.e. apoptosis. Waterlogging is among the major abiotic stressors
    for crops. Fig. 3(f) shows a previously flooded field. Waterlogging induces a
    number of alterations in soil properties, such as soil pH, redox potential and
    oxygen level. Thus, plants growing on waterlogged soil face a stressful environment
    in terms of hypoxia (deficiency of O2) or anoxia (absence of O2), which may substantially
    reduce plant growth, development and survival (Tewari and Mishra, 2018). One very
    frequent source of abiotic stress is drought, as demonstrated in Fig. 3(g) for
    a very severe drought stress event. Plants require a number of essential nutrients
    for growth, which are supplied either from soil minerals and soil organic matter,
    or as organic and inorganic fertilizers as part of agricultural management. The
    deficiency of one or multiple nutrients may lead to manifestations, as demonstrated
    in Fig. 3(h). These few selected examples illustrate that: (i) diverse stressors
    may lead to the same symptoms, and (ii) the same stressor may cause distinct symptoms
    under varying environmental conditions. This also depends on the scale of observation
    and the actual development stage of the crops. To better relate stressors and
    the corresponding symptoms, a deeper understanding about species-specific plant
    physiological responses is required. Ultimately, all abiotic and biotic stress
    factors have in common that they pose a large risk for the agricultural sector:
    major yield losses and thus decrease in agricultural productivity. 3. Remote sensing
    of stress: Time domains and methodologies From a sensing point of view and in
    accordance with the dose and duration of stress exposure, we group the detection
    of plant stress responses into three main categories. Table 1 lists the stress
    phases (short-term, medium-term and longer-term) along with the (i) physiological
    responses of the plants, (ii) the primarily affected or adapted traits or stress
    proxies, and (iii) typical or optimal sensing domains. In accordance with that
    and to associate the stress proxies to these three temporal phases of stress,
    we grouped the affected traits into fluxes, biochemical and structural, as delineated
    in Fig. 4. In addition, the Figure illustrates the interplay of “optimal” spectral
    domains to estimate these stress proxies for an example of decreasing crop water
    availability. The resulting health status and potential yield losses are delineated
    below as a chronological function of stress duration and severity. Before a multi-sensor
    concept can be defined, the potential of each of these spectral domains has to
    be understood. Hence, in the following sub-sections, we will discuss the capabilities
    of various RS technologies to track plant stress responses as a function of dose
    and exposure times, providing an overview of commonly used methodologies. Table
    1. Short- medium- and long-term effects of plant stress, with physiological responses,
    primarily affected traits (examples) that act as stress proxies and optimal spectral
    domains to detect the traits. Exemplary references exploring the different stress
    proxies with defined sensing domains are also given. Spectral responses to stress
    exposure are further related to plant genotypes, not being considered here (cf.,
    Galieni et al. (2021) for an overview of such responses). Stress phase Physiological
    response Primarily affected traits Optimal spectral domains References Early responses
    (minutes to hours) Downregulation of photosynthetic electron transport, SIFyield
    Normalized fluorescence, VIS/NIR Magney et al. (2019) ⁝ Activation of NPQ Xanthophylls
    500–600 nm (quick) Acebron et al. (2021) ⁝ Van Wittenberghe et al. (2021) ⁝ (and
    chlorophyll) 500–750 nm (slow) Van Wittenberghe et al. (2019) ⁝ Photo-avoidance
    through Absorption by VIS Kasahara et al. (2002), ⁝ chloroplast movement chloroplast
    pigments Brugnoli and Bjorkman (1992) ⁝ Reduced stomatal conductance, Leaf/canopy
    temperature TIR Gerhards et al. (2016) ⁝ transpiration, stomatal closures Medium-term
    responses: Leaf turgor loss Leaf water content NIR/SWIR Seelig et al. (2008) (hours
    to days) Changes in pigment contents Leaf chlorophyll and VIS/NIR Baret et al.
    (2007) ⁝ (chlorosis) carotenoid contents Gitelson (2020) Longer-term responses
    Leaf movement Leaf angle, fraction of VIS/NIR/SWIR Spišić et al. (2022) (days
    to weeks): and rolling photosynthetically active radiation ⁝ Baret et al. (2018)
    ⁝ Reduced leaf expansions Leaf area index, biomass ⁝ Berni et al. (2009b) ⁝ ⁝
    ⁝ ⁝ Hazaymeh and Hassan (2017) Download : Download high-res image (464KB) Download
    : Download full-size image Fig. 4. Integrated concept of plant responses to (drought)
    stress with optimal sensing domains (i.e. solar-induced fluorescence (SIF), thermal
    infrared (TIR) visible to near infrared (VNIR) and shortwave infrared (SWIR))
    for estimating trait groups (i.e., fluxes, biochemicals and structural) and exemplary
    stress proxies (PRI: photochemical reflectance index). Changing plant health conditions
    and yield loss probability are delineated as a chronological function of stress
    duration and severity through decreasing water availability. 3.1. Remote sensing
    methods for early and mild stress detection 3.1.1. Solar-induced chlorophyll fluorescence
    During the diurnal course of the day, vegetation is perceiving a large gradient
    of incoming solar energy, fluctuating between low light conditions up to excessive
    amounts of incident radiation. The energy in the photosynthetically active radiation
    (PAR, 380–710 nm) region triggering the photosynthetic light reactions is, therefore,
    easily reaching harmful doses of energy requiring dissipation. SIF corresponds
    to the energy directly emitted from the photosynthetic machinery when the photosynthetic
    pigments get excited by the incoming radiance. The harvested light triggering
    this SIF emission depends on the amount of photosynthetic pigments and their composition
    within the photosystem II antenna complexes. Passive fluorescence techniques quantify
    the absolute values of SIF emission. Hereby, retrieval methods disentangle surface
    reflectance from the fluorescence signal using data from very high spectral resolution
    spectroradiometers. By means of these techniques, fluorescence emission can be
    retrieved as scalar values in the oxygen absorption regions or within the Fraunhofer
    lines, where the reflected radiance is strongly retained due to absorption of
    the incoming sunlight (Meroni et al., 2009). By exploiting distinct absorption
    features in the red and NIR spectral window, it is possible to reconstruct the
    entire spectrum of chlorophyll fluorescence. There are two peaks around 685 nm
    and 740 nm, which are mechanistically related to the photosynthetic electron transport
    within the two photosystems of plant''s photosynthetic apparatus (Mohammed et
    al., 2019). Recent approaches model the entire fluorescence spectrum (Cogliati
    et al., 2019), which will open the path towards a more complete signal analysis.
    The intensity of the SIF signal is in its first order related to the total PAR,
    which is absorbed by the canopy. Secondly, structural canopy properties determine
    the escape probability of the emitted SIF signal (Guanter et al., 2014). Recent
    studies developed methods to correct the SIF emission for scattering (Yang and
    van der Tol, 2018; Zeng et al., 2019) and re-absorption effects (Liu et al., 2020)
    by determining the escape probability and thus made it possible to down-scale
    SIF from the canopy to the leaf level. To further disentangle illumination related
    variations from the underlying physiological information carried by the down-scaled
    SIF signal, the calculation of an (apparent) yield can be employed by further
    normalizing for the amount of chlorophyll (Goulas et al., 2017) or radiation absorbed
    by chlorophyll (Yang et al., 2020a). This step allows the comparison between species,
    independent of their pigment pool sizes and facilitates the quantitative detection
    of variations in plant physiology (Migliavacca et al., 2017; Van der Tol et al.,
    2016). Mechanistically, SIFyield, i.e. the SIF emission normalized by the absorbed
    energy triggering the emission, is closely related to the efficiency of the photosynthetic
    electron transport. Thus it can be used as an early stress indicator when photosynthetic
    electron transport is affected by the specific stress reaction. However, as a
    matter of fact, SIFyield is not linearly related to photosynthetic electron transport,
    as the dynamic nature of NPQ mechanisms renders these relationships non-linear.
    Plants have evolved a variety of protection mechanisms, which can be actively
    regulated to optimize light harvesting especially in stressful times to avoid
    over-energization of the photosynthetic apparatus. These NPQ mechanisms act as
    energy quenchers and, as a consequence, may also affect the intensity of SIF (Bilger
    and Bjorkman, 1990). Thus, for stress detection, SIFyield needs to be further
    constrained by an independent measure of NPQ. Some NPQ processes are linked to
    a reversible conversion of the xanthophyll pigment pool (Jahns and Holzwarth,
    2012), which may result in consequential optical reflectance change in the 500–600
    nm range (Acebron et al., 2021; Gamon and Surfus, 1999; Van Wittenberghe et al.,
    2021), or even further changes in the VIS–NIR range (Van Wittenberghe et al.,
    2019). To circumvent the above described complexities, the Photochemical Reflectance
    Index (PRI) has been frequently used to detect these instantaneous optical changes
    and to exploit the modification in the light use efficiency behaviour under excessive
    radiation (Garbulsky et al., 2011). However, the PRI is also known to be affected
    by both facultative and constitutive pigment effects (Gamon and Berry, 2012; Moncholi-Estornell
    et al., 2022). These multiple underlying pigments effects illustrate the complexity
    of the pigment dynamics affecting the PAR on both short and longer time scales.
    3.1.2. Thermal infrared sensing: Temperature There has been a long interest in
    using canopy temperature as a remote indicator of plant water stress (Jones and
    Vaughan, 2010). Although RS-based surface energy balance (SEB) approaches allow
    an estimation of the actual evapotranspiration (indirectly as the residual term
    of the SEB equation, using thermal data to calculate heat flux), they require
    vast meteorological input data and parameterisation of conductance (Tolomio and
    Casa, 2020). Other than SEB models, the direct use of thermal data in water stress
    indices has been promoted. TIR radiance measurements obtained over vegetation
    depend mainly on the temperatures of the (sunlit or shaded) leaves and the soil,
    the leaf and soil spectral emissivities, and eventual contributions from the surroundings
    and the atmosphere (Gerhards et al., 2019; Norman and Becker, 1995). Temperatures
    and emissivities of vegetated surfaces can be retrieved from a variety of algorithms
    that use - depending on the number of spectral bands - different approaches to
    correct for atmospheric effects and to separate temperature and emissivities from
    each other (Li et al., 2013). At a given ambient air temperature, canopy temperature
    (Tc) is inversely related to the rate of water loss from the canopy. The transpiration
    itself is closely linked to stomatal conductance (Jones and Vaughan, 2010). To
    take into account the effects of weather conditions on Tc, the crop water stress
    index (CWSI) has been developed as a simplified means to quantify water stress.
    Besides the effects of air temperature (Ta) the index also considers atmospheric
    relative humidity, expressed as vapour pressure deficit (VPD). CWSI is based on
    a simple scaling operation, where Tc is normalized by the Ts of a fully transpiring
    crop (Tsmax) and the Ts of a crop that is not transpiring at all (Tsmin). Different
    approaches to calculate CWSI were developed (see Maes and Steppe, 2012 for a comprehensive
    review): The empirical CWSI (CWSIe) establishes a relationship between TcTa and
    VPD from which Tsmax is derived (Idso et al., 1981). Hence, it requires only three
    input measurements (Tc, Ta, and VPD) for its application. However, the lower limit
    is sensitive to changes in radiation and wind speed (Gonzalez-Dugo et al., 2014)
    and therefore cannot be transferred across growing seasons. The theoretical CWSI
    (CWSIt) calculates the upper and lower limits (Tsmax and Tsmin) from equations
    based on a combination of the Penman-Monteith and the energy balance equations.
    The CWSI can be used in day-to-day water stress monitoring, but requires measurement
    of additional atmospheric variables (i.e., net radiation, wind speed, canopy resistance)
    and the challenging estimation of aerodynamic resistance (rA) (Jackson et al.,
    1981, Jackson et al., 1988). To overcome this limitation, the use of an empirical
    upper limit together with the theoretical lower limit has been suggested for practical
    purposes (Agam et al., 2013; Rud et al., 2014). This so-called hybrid CWSh (Ekinzog
    et al., 2022) eliminates the need for estimating rA and achieved comparable accuracies
    as CWSIt and CWSIe. The development and early application of CWSI was done on
    point based Tc measurements, but has been adapted and applied to high resolution
    thermal imagery for assessing the spatial variability of crop water status using
    the direct or image based CWSI (Agam et al., 2013). Hereby, the fully and non-transpiring
    Ts along with Tc are measured directly using wet and dry artificial reference
    surfaces placed within the image (Gerhards et al., 2018). CWSI showed to exhibit
    good relationships with in situ soil based measures such as soil water content
    (DeJonge et al., 2015; Taghvaeian et al., 2014) and plant based measures, such
    as leaf water potential and stomatal conductance (Berni et al., 2009a; Bian et
    al., 2019; Han et al., 2018). The index proved to be robust in many arid and semi-arid
    regions around the globe and for various agricultural crops (Cohen et al., 2017;
    DeJonge et al., 2015), and more recently also in humid regions (Ekinzog et al.,
    2022; Hoffmann et al., 2016). Moreover, CWSI requires a fully closed canopy and
    this limitation has been tried to overcome using the water deficit index (WDI,
    Moran et al., 1994), relating TcTa with the fractional cover or a vegetation index
    (VI). The empirical version of WDI is derived from a Ts – VI scatterplot, without
    requiring any ground-based weather measurement and is thus widely applied in thermal
    RS (Maes and Steppe, 2012). 3.1.3. Thermal infrared sensing: Emissivity Analysing
    the thermal infrared spectral region, relatively little attention has been paid
    so far to the spectral emissivity of plants (leaf and canopy), which responds
    to environmental stresses. This could be explained with the following reasons
    (Ribeiro da Luz and Crowley, 2007): (i) hyperspectral TIR instruments were lacking
    until a few years ago, (ii) gap in knowledge about the origin of complex spectral
    emissivity variations, (iii) low signal-to-noise-ratio (SNR) together with low
    spectral and spatial resolution of the available sensors prevented to detect these
    subtle changes in spectral emissivity, (iv) lack of advanced pre-processing algorithms
    (i.e., atmospheric correction and Temperature-Emissivity-Separation). However,
    Salisbury (1986) and the ground-breaking studies by Ribeiro da Luz and Crowley
    (2010), Ribeiro da Luz and Crowley (2007) and Neinavaz et al. (2016) showed that
    differences in the spectral emissivity among plant species are related to differences
    in structural and biochemical leaf surface and canopy properties. These findings,
    in combination with recent advances in sensor technologies, e.g., spatially enhanced
    broadband array spectrograph system (SEBASS, Vaughan et al., 2003), Telops Hyper-Cam
    LW (Schlerf et al., 2012), or hyperspectral thermal emission spectrometer (HyTES,
    Meerdink et al., 2019), opened the field to study the application of spectral
    emissivity for plant stress detection. So far, only two studies pursued the question
    if spectral emissivity can be used for the detection of plant responses to environmental
    stresses. Based on laboratory measurements, Buitrago et al. (2016) were able to
    use spectral emissivity for the detection of cold and water stress on European
    beech (Fagus sylvatica) and rhododendron (Rhododendron cf. catawbiense) leaves.
    Gerhards et al. (2016) successfully showed in a greenhouse experiment that the
    spectral emissivity of potato plants (Solanum tuberosum L. Cilena) is equally
    sensitive to water stress as compared to temperature based indices (e.g., CWSI).
    However, further research is needed to better understand the linkages between
    stress, leaf traits and spectral emissivity features. Overall, using emissivity
    as an indicator of thermal stress is challenging as it requires TIR measurements
    at high spectral resolution, correction of atmospheric effects and the separation
    of temperature and emissivity (Gerhards et al., 2019). 3.2. Quantification of
    mild long-term and severe stress using optical reflective approaches Mild long-term,
    chronic or severe stress induces visible symptoms on crop leaves and canopies.
    Those symptoms are also captured by remote sensing data in the reflective optical
    domain, including the VIS, NIR and SWIR. The first remote sensing studies for
    linking remote sensing in the optical domain to stressed vegetation canopies started
    in the early 1970''s (see Fig.1 in Houborg et al., 2015) with the milestone publication
    by Knipling (1970). This study related leaf and canopy spectral signatures to
    effects of physiological stress. With this, Knipling (1970) identified the two
    main groups of traits, which are affected first by medium-term and mild long-term
    stress - the biochemical compounds - and second, those affected by chronic and
    severe stress, i.e. the structural variables. Here we refer to Fig. 2 (the two
    blocks on the right), and Table 1 (second and third lines). The use of these traits
    as stress proxies has since been confirmed by numerous studies. According to Baret
    et al. (2007), for instance, retrieval of leaf chlorophyll content (Cab) and leaf
    area index (LAI) can serve to diagnose plant (nitrogen) stress: whereas Cab decreases
    due to limited synthesis or destruction of chloroplasts, losses in leaf area (i.e.,
    LAI) indicates a decrease of leaf production going along with an increase in senescence.
    The study of Carter and Knapp (2001), linking a variety of stressors to physiological
    responses, observed that consistent stress induces changes in leaf reflectance
    within the visible range due to changing Cab. In the study of Linke et al. (2008),
    relative leaf water content decreased during water stress periods going along
    with changes in spectral leaf reflectance. It was also found that recovery from
    stress was not reflected by leaf reflectance as expected: still some differences
    remained between the formerly stressed plant and the control plant, suggesting
    that secondary effects followed the stress, such as changes in cell structure
    and biochemistry. This points towards the need to retrieve multiple plant traits
    instead of a single one to accurately diagnose medium or longer lasting stress
    events in crops. To derive traits from optical reflective measurements, it is
    necessary to convert the measured signals into semantic values. Four broad methodological
    categories have been identified recently, and were summarized in the review studies
    of Verrelst et al., 2015, Verrelst et al., 2019a (for general vegetation properties
    retrievals) and specifically for nitrogen in Berger et al. (2020): • parametric
    regressions, referring to the use of VIs; • nonparametric regressions, which include
    chemometric methods and ML regression algorithms, • mechanistic or physically-based,
    using radiative transfer modeling (RTM), and • hybrid approaches, combining ML
    regression algorithms with RTM. The first studies evaluating the use of optical
    reflective RS for nitrogen stress quantification were mainly based on empirical
    relationships employing spectral indices sensitive to chlorophyll content (Penuelas
    et al., 1994). Later, the study of Lebourgeois et al. (2012) used different VIs
    to investigate crop nitrogen status in cases of combined nitrogen and water stresses.
    Further, hyperspectral data opened the opportunity for the development of narrowband
    VIs (Broge and Leblanc, 2001), which were used for estimation of plant water status
    and stress (Gerhards et al., 2019; Zhang and Zhou, 2019). According to Singh et
    al. (2016), ML regression algorithms emerged as one of the most promising tools
    for the retrieval of vegetation traits in the context of stress. ML allows analysing
    huge data sets to detect patterns by simultaneously looking at multiple factors
    instead of analysing each predictor and/or feature (trait) individually. As an
    example of RTM exploitation, the study by Richter et al. (2008) used a look-up
    table (LUT) inversion of the PROSAIL model to estimate LAI, Cab and a soil brightness
    factor for the diagnosis of drought risk zones within wheat fields. Hereby, crop
    growth variability was caused by the sandy soil type, leading to limited water
    availability for the crops, which was reflected in lower LAI and Cab values compared
    to other soil types. Merging physically-based and data-driven methods to hybrid
    approaches seems ideal for functional traits retrieval and thus stress identification
    due to the complementary nature: RTMs provide physical constraints and domain
    knowledge to fast and efficient ML algorithms (Verrelst et al., 2015, Verrelst
    et al., 2021). The efficiency of these hybrid methods can be even enhanced by
    exploring active learning for optimisation of ML training samples (Berger et al.,
    2021). These methods can be powerful for the detection of stress levels, for instance,
    by investigating the ratio of Cab and leaf carotenoid contents (Hendry and Price,
    1993; Sonobe et al., 2020). Recently, Lassalle (2021) reviewed the advances in
    optical reflective hyperspectral remote sensing of plant stress over the last
    five decades. The author pointed out that for most stressors, high to very-high
    spatial resolution is preferable. Optimally, the VNIR spectral region should be
    exploited using VIs and ML methods. In some cases, the SWIR region improved the
    performance of the methods in the analysed studies. Nevertheless, we believe that
    exploiting multiple domains provided by diverse sensors (SIF, TIR, VIS-SWIR) may
    be an advantage over using only hyperspectral optical reflectance. Such a “multi-view”
    is required to obtain more complete insights about stressors, crop physiological
    responses and affected traits. We therefore examined the existing literature to
    identify the current state of the art with respect to multi-domain and multi-sensor
    approaches. 4. Review of multi-domain and multi-sensor studies 4.1. Identification
    of relevant literature The main purpose of the systematic review was to identify
    all published studies detecting agricultural stress by exploring synergies of
    different optical domains. To collect all relevant studies, we followed the approach
    by Cronin et al. (2008). The literature analysis included four main steps: 1.
    identification of relevant literature by means of well-defined keywords, 2. screening
    of the overall suitability of the selected records, 3. evaluation of the eligibility
    and inclusion, i.e. fully scanning the records, and 4. extraction of meta-information.
    In the identification step (1.), the keywords “remote sensing & (fusion OR synergy
    OR multi OR multi-sensor) & stress & (agriculture OR crops)” were searched for
    in ISI Web of Science and similar search engines within the period from 1994 to
    2021. Finally, a large pool of records was collected. The identification step
    followed a first rough checking to remove duplicates. This resulted in approximately
    300 papers eligible for further investigation. In the screening step (2.), at
    first, non-peer reviewed records being considered irrelevant (i.e., conference
    proceedings or reports), were removed. Reading of titles and abstracts led further
    to the exclusion of all records that either focused on other than agricultural
    applications, employed active RS data or were review studies. The screening step
    resulted in a total of 133 studies. In the eligibility part (3.), these 133 studies
    underwent intense screening, i.e. full reading, required to extract the criteria
    listed below. Hereby, records that mentioned stress but focused on yield or soil
    properties, or used only one sensor (or domain) for stress evaluation were excluded.
    From the remaining 96 records, detailed information was extracted, including the
    following variables: • Meta-information: authors, title, journal, year; • Site:
    location, studied vegetation (crop, orchard); • Stress type (biotic, abiotic)
    and specification; • Analysed traits (individual and according to the three trait
    groups, see chapter 2); • Time scale of stress period (short-, medium- and long-term);
    • Observational levels (leaf-level, top-of-canopy or top-of-atmosphere); • Observational
    scales (micro/plant, local, regional, global); • Platforms (handheld, gantry,
    tower, unmanned aerial vehicle (UAV), airborne, satellite); • Spectral domains
    (VIS, SIF, NIR, SWIR, TIR); • Algorithms (classification, regression, anomaly
    detection); • Methodologies (parametric, nonparametric, RTMs, hybrid, SEBM). Note
    that with the performed literature search we do not claim completeness. There
    is a high certainty of additional potentially relevant records, which may be missed
    due to deviating keywords. However, due to the high number of co-workers and repetitive
    literature searches, we believe to have covered the essential studies exploring
    multiple spectral sensing domains to assess stress in agricultural research. 4.2.
    Factor analysis In a first step, we analysed the contribution of the different
    variables via principal component analysis (PCA), see Fig. 5. A PCA reveals the
    strongest patterns between all variables and thus provides an attractive method
    to explore general trends within the database. In the first dimension (x-axis),
    the largest discrepancies can be found between platforms (satellite vs handheld),
    spectral resolutions (multispectral vs hyperspectral), as well as the duration
    of the stress periods (long-term vs short-term stress). These patterns can be
    interpreted with the investigation of either one or the other aspect, but rarely
    both together. The second dimension (y-axis) indicates, among others, the exclusive
    use of one stress type (biotic or abiotic). In addition, parametric and nonparametric
    nonlinear approaches point towards opposite directions. Download : Download high-res
    image (466KB) Download : Download full-size image Fig. 5. Principal component
    analysis of literature variables (first two dimensions). Positively correlated
    variables point to the same direction and negatively correlated variables to the
    opposite. The groups refer to the variable categories searched for in the reviewed
    studies (algorithm, classification method, period of stress, platform, regression
    method, scales, spectral domain, spectral resolution, stress type, traits level).
    On the other hand, variables pointing in the same direction may indicate a joint
    usage, for instance, the estimation of biotic stresses (e.g., diseases) by means
    of nonparametric nonlinear approaches (i.e., machine learning), or the estimation
    of abiotic (i.e., drought stress) by parametric methods (e.g., vegetation indices).
    Since this PCA analysis can only give an approximate idea of the complex interplay
    of all these variables, the following sub-chapters describe and illustrate the
    findings for the individual criteria. 4.3. Platforms and sensors Aggregation of
    the publications over 5-year periods reveals clear trends in platform usage over
    time (Fig. 6). While only handheld and airborne platforms prevailed during the
    period 2000–2005, their usage continuously decreased from 2005 onwards. At the
    same time, researchers made increasing use of sensors onboard UAVs (e.g., Di Gennaro
    et al., 2017; Joalland et al., 2018) and satellites (e.g., Anderson et al., 2018;
    Bayat et al., 2018). With respect to UAVs, this can be largely explained by the
    miniaturization of sensor technologies for (hyperspectral) VNIR, SWIR and TIR,
    and recently also for SIF cameras on drones (Gonzalez Toro and Tsourdos, 2021).
    Regarding satellites, multispectral satellite images, such as Sentinel-2 A/B (from
    June 2015) and Landsat (from October 2008), are easily accessible nowadays. The
    analysis further revealed that the majority of UAV spectral domain combinations
    were composed of VIS-NIR-TIR sensors. As SIF measurements are not yet available
    from satellite sensors in spatial resolutions required for precision agriculture
    applications, studies using SIF data mainly explored airborne data sets. Download
    : Download high-res image (86KB) Download : Download full-size image Fig. 6. Change
    in platform usage for the detection of stress in agriculture over 5-year periods.
    Note that the years refer to a 5-years period, e.g. 2005 stands for 2003–2007.
    4.4. Algorithms and methodologies As discussed in section 3, the detection of
    stress conditions in crops often relies on the estimation of traits linked to
    the crop status. In the investigated studies, most focused on quantifying traits
    using regression or RTM methods, whereas the usage of classification or anomaly
    detection was less pronounced. Among the papers reviewed in this study, about
    72% were based on parametric approaches (e.g., Gerhards et al., 2016; Guan et
    al., 2017; Panigada et al., 2014), 22% on nonparametric linear approaches (e.g.,
    Ainsworth et al., 2014; Sobejano-Paz et al., 2020; Thomas et al., 2017), about
    17% on nonparametric nonlinear approaches (e.g., Camino et al., 2021; Gao et al.,
    2009; Zarco-Tejada et al., 2018), nearly 15% on surface energy balance models
    (e.g., Bayat et al., 2018; Bhattarai et al., 2019; Zhuang et al., 2020), 16% used
    radiative transfer models (e.g., Camino et al., 2018; Celesti et al., 2018) and
    only a few on hybrid approaches (e.g., De Grave et al., 2020; Delalieux et al.,
    2014). Note that several studies employed multiple methods. Fig. 7 indicates the
    use of different methodologies in studies published from 1999 to 2021. Though
    a clear trend was missing, we noticed that on a percentual basis, the use of parametric
    and nonparametric linear approaches has been slightly decreasing, while SEBMs,
    RTMs and hybrid approaches gained popularity. With respect to machine learning
    regression algorithms, mainly conventional shallow learning methods were employed,
    such as support vector machine (regression), random forest or neural network approaches.
    Although it may be promising for stress detection, the exploration of deep learning
    algorithms is still missing. RTMs and hybrid approaches have been receiving attention
    in recent years due to improved performance in computational speed, flexibility
    and generic applicability (Verrelst et al., 2019a). Also, they have been demonstrated
    to be attractive methods as regards to mapping large areas, especially in operational
    and global contexts (Verrelst et al., 2015). Accurate and fast mapping of crop
    traits over large cultivated areas by means of these hybrid methods reveals potential
    for the quantification and monitoring of stress-related proxies. Download : Download
    high-res image (153KB) Download : Download full-size image Fig. 7. Change of retrieval
    methods usage over 5-year periods to infer vegetation traits as stress proxies.
    PA: parametric regressions (e.g., vegetation indices), NNA: nonparametric nonlinear
    approaches (e.g., machine learning), NLA: nonparametric linear approaches (e.g.,
    principal component regression), RTM: radiative transfer models (inversion), Hybrid:
    hybrid methods (i.e., combination of RTM and NNA methods), SEBM: surface energy
    balance models. Note that the years refer to a 5-years period, e.g. 2005 stands
    for 2003–2007. Regarding the retrieved traits, Fig. 8 shows that the highest percentage
    of the studies focused on the retrieval of traits related to fluxes (mostly ET),
    followed by those related to biochemical traits and finally structural traits,
    independently of the method used. The only exception are hybrid approaches, which
    were mainly applied to retrieve biochemical traits, rather than those related
    to fluxes. Download : Download high-res image (156KB) Download : Download full-size
    image Fig. 8. Applied retrieval methods as function of distinct trait groups.
    PA: parametric regressions (e.g., vegetation indices), NNA: nonparametric nonlinear
    approaches (e.g., machine learning), NLA: nonparametric linear approaches (e.g.,
    principal component regression), RTM: radiative transfer models (inversion), Hybrid:
    hybrid methods (i.e., combination of RTM and NNA methods), SEBM: surface energy
    balance models. 4.5. Observational levels and scales Regarding observational levels
    and spatial scales considered in the selected studies, mostly the top-of-canopy
    (TOC) level was addressed with 72%, followed by the leaf level with 45% or both.
    Only six studies addressed (exclusively) the top-of-atmosphere (TOA) level (Bhuiyan
    et al., 2017; Knipper et al., 2019; Mladenova et al., 2017; Navarro et al., 2016).
    The majority of the TOA studies investigated regional scale stress levels. In
    fact, most of the papers considered the field/plot scale (67%), but multiple studies
    addressed the micro/plant scale (i.e., 31%) with little overlap between these
    categories. As illustrated by regional-scale TOA studies, there was a strong relationship
    between the spatial scales and observational levels. For example, all but one
    out of the plant scale studies focused on leaf level traits, with the exception
    of Kim and Glenn (2017), where the authors proposed a new multi-modal stress detection
    system for plants by integrating off-the shelf sensors in a custom-made platform
    and by developing software for processing data flows. 4.6. Spectral domains Overall,
    the number of publications between 1999 and 2021 increased approximately by factor
    of four. With respect to the explored wavelengths, this increase was reflected
    by all domains, though with higher absolute numbers of NIR, VIS and TIR studies
    compared to SWIR and SIF. The utilization and synergistic use of different spectral
    domains within the selected studies is demonstrated by a Venn diagram (Fig. 9).
    Here, we observe that the combination of VIS-NIR-TIR domains represents the largest
    category (N = 33). Regarding the two-domain combinations, the VIS-NIR and VIS-TIR
    were the most often used (N = 5). In addition, the VIS domain was employed by
    the majority of studies. As two spectral regions in the optical reflective domain
    are insufficient to detect short-term stress, the combination with TIR sensors
    proved to be useful. For instance, the study by Baluja et al. (2012) examined
    crop water status using multispectral VIS and NIR sensors along with thermal imagery.
    The authors found that with the latter technology it was possible to detect short-term
    responses. However, normalized difference vegetation index (NDVI) and two other
    VIs calculated from the VIS-NIR data were rather reflecting the results of cumulative
    water deficits on the observed crop, hence its response to chronic stress exposure.
    Download : Download high-res image (290KB) Download : Download full-size image
    Fig. 9. Venn diagram visualizing the different combinations of used spectral domains
    (VIS, SIF, NIR, SWIR, and TIR) in the reviewed studies (left). Number of studies
    using different sensor combinations (two to five) with respect to the different
    spectral domains (right). In total, only four studies concurrently exploited all
    five main domains (i.e., VIS, SIF, NIR, SWIR and TIR) (Camino et al., 2021; Gerhards
    et al., 2018; Mahlein et al., 2019; Zarco-Tejada et al., 2018). This gap could
    be explained, among others, by the still limited (for SWIR) and missing (for SIF)
    availability of high spatial resolution satellites, and rather high prizes for
    sensors, such as UAV-suitable cameras. In fact, for the detection of very early
    stresses, the optimal spectral domains could mainly be provided by a combination
    of SIF and TIR, which however, was realized by only a few studies (N = 4) (Chaerle
    et al., 2004, Chaerle et al., 2009; Ni et al., 2015; Pérez-Bueno et al., 2015).
    All in all, these findings suggest that many study designs were mainly driven
    by sensor availability and practical economical reasons, respectively, leading
    to a common usage of VIS-NIR sensors. This was confirmed by a study analysing
    costs of multi-sensor systems (Appeltans et al., 2020), calculating, for instance,
    total costs of 200.000 euros for a combination of a hyperspectral, thermal and
    fluorescence sensor. 4.7. Stress types and plant responses Fig. 10 clearly demonstrates
    that the majority of the selected studies investigated abiotic stress, in particular
    drought stress. On a short-term scale, drought stress influences transpiration
    through stomatal closure (see chapter 2.2). Consequently, the analysis of TIR
    data (i.e., temperature) may provide the most useful information. However, TIR
    sensors struggle with lower spatial and spectral resolutions leading to weaker
    SNR in comparison to sensors measuring optical reflective signals (VSWIR). This
    means if the detectors of both measurement types are of comparable size, less
    energy is available in the TIR than for VSWIR, which limits the applicability
    of TIR in precision farming contexts (Gerhards et al., 2019). Moreover, the TIR
    signal is highly influenced by environmental factors, such as wind turbulence
    and background cover (e.g., weed or soil type) (Döpper et al., 2020). Thus, a
    combination of TIR data with the VNIR/SWIR spectral domains is most common (see
    Fig. 10). Within this combination, the majority of studies investigated long-term
    stress, as such data enable studying different traits with the evolution from
    short-term fluxes to longer-term biochemical and structural changes. Fig. 11 demonstrates
    the behaviour of the three trait groups as a function of stress duration or severity.
    As expected, variations of fluxes have been related most often to short-term stress,
    whereas the structural traits are mainly used as proxies for longer term or chronic
    stress. Interestingly, there is a balance of all three trait groups for the long-term
    stress category (see Fig. 12). It may be explained by the fact that the same traits
    are observed over longer study periods, instead of using only the most responsive
    trait at a certain stress stage. Download : Download high-res image (179KB) Download
    : Download full-size image Fig. 10. Usage of diverse spectral sensor combinations
    with respect to targeting biotic and abiotic stresses. Download : Download high-res
    image (137KB) Download : Download full-size image Fig. 11. Usage of diverse spectral
    sensor combinations with respect to targeting short-, medium-, and long-term stresses.
    Download : Download high-res image (105KB) Download : Download full-size image
    Fig. 12. Detection of different trait groups acting as proxies for crop stress
    in the reviewed studies, aggregated to time scales (short-, medium and long-term
    stress). The traits refer to fluxes-related, such as transpiration or SIF yield,
    biochemicals, i.e. leaf water or pigment contents, and structure-related traits,
    e.g. leaf inclination, LAI or biomass. In particular, the combination of VIS/NIR
    with TIR sensors can increase the accuracy of the long-term stress assessment
    since the same traits are observed based on distinct principles (e.g., Chaerle
    and Van Der Straeten, 2000; Gerhards et al., 2016). As stated above, this specific
    wavelength domain combination is also driven by the availability and comparatively
    low costs of the sensors. In contrast to TIR data, being applied to any time scale,
    SIF data was almost exclusively employed to analyse short-term (flux-related)
    responses (Campbell et al., 2007; Ni et al., 2015; Pérez-Bueno et al., 2015; Zarco-Tejada
    et al., 2018). Similarly to the analysis of TIR data, the SIF signal might be
    weak and interpretability can be increased by combining the data with measurements
    from other spectral domains (e.g., Alonso et al., 2017; Celesti et al., 2018;
    Chaerle et al., 2009). Overall, we found that studies including SIF data were
    rather underrepresented. A smaller number of studies focused on biotic stress
    (see Fig. 10), mainly disease detection (e.g., Bendel et al., 2020; Mahlein et
    al., 2019; Savian et al., 2020). Here we observed a large variety in the combination
    of spectral domains. However, it must be remarked that the number of analysed
    traits in those studies was also large, including structural, biophysical and
    biochemical traits. In conclusion, we observed that the majority of reviewed studies
    was rather restricted to a comparison of the outcomes by diverse sensors and spectral
    domains as opposed to a synergistic usage of the multi-domain data. Only a few
    studies were working on synergistic integration of RS data from various spectral
    domains (e.g., Zarco-Tejada et al., 2018) targeting stress detection. 4.8. Disentangling
    abiotic and biotic stress sources Since plant pathogens pose an enormous threat
    to global food security causing yield losses exceeding 30% in selected regions
    or even up to 100% on a local scale (Savary et al., 2019; Zarco-Tejada et al.,
    2021), we address this specific topic here. The differentiation of biotic and
    abiotic stressors is a challenging task, as symptoms triggered by pathogens may
    be confounded with abiotic-induced responses. Also, the distinction between multiple
    biotic-induced stressors remains to be investigated, in order to provide quantitative
    tools for pre-symptomatic disease detection allowing respective measures and adaptation
    of management practices. So far, only a few studies focused on disentangling infection
    sources with similar symptoms (e.g., Fallon et al., 2020; Gold et al., 2020; Moshou
    et al., 2014; Poblete et al., 2021). Gold et al. (2020), for instance, sampled
    hyperspectral measurements of hemibiotrophic and necrotrophic pathogen-affected
    potato crops, estimating multiple traits over the optical reflective domains,
    which were synergistically explored using chemometric models. This approach allowed
    to provide a pre- and post-symptomatic differentiation of the two foliar diseases.
    In Poblete et al. (2021), olive trees affected by two pathogenes were investigated,
    restricting water and nutrient flow through the xylem, which leads to symptoms
    similar to those caused by drought stress. The authors applied three-stage machine
    learning algorithms to airborne hyperspectral and thermal imagery to discriminate
    the two diseases successfully. Zarco-Tejada et al. (2021) explored thermal and
    hyperspectral reflectance data revealing the existence of divergent pathogen-
    and host-specific spectral pathways through uncoupling of specific biotic and
    abiotic spectral effects. All in all, these studies concluded that a multi-sensor
    approach is absolutely necessary for in-depth stress analysis, and presented in
    a pioneering way how synergy of different domains and sensors (mainly with hyperspectral
    resolutions in the VIS/NIR/SWIR domain) can be used to predict and distinguish
    biotic and abiotic stressors. However, it needs to be mentioned that differentiation
    is still vague in many cases and advanced methods such as machine learning should
    be explored (Behmann et al., 2015; Neupane and Baysal-Gurel, 2021). The review
    by Zhang et al. (2019) about monitoring plant diseases and pests using RS also
    concluded that the detection of abiotic stress is still challenging and under-exploited
    through the simultaneous appearance of multiple stressors. Hence, we need to advance
    near real-time detection at larger spatial scales, especially for pests, pathogens
    and diseases, causing significant global production losses (Savary et al., 2019).
    This is even more evident, as our literature analysis revealed that the majority
    of available studies in this domain rather concentrated on single crops and pathogens
    at local and experimental levels. 5. New concepts of sensor synergies Combining
    distinct spectral domains acquired from one or multiple sensors leads to more
    data for an improved (post-)processing of signals or quantities to derive plant
    physiological, biochemical and structural information. In addition, it offers
    advanced possibilities to observe a complete range of plant responses (i.e., traits),
    which can be directly related to stress. This review has clearly indicated a possibly
    strong - and currently largely underexploited - potential of using spectral information
    from multiple sensors or domains in a synergistic way for crop stress detection,
    monitoring and management. Based on these insights, we propose four ways forward
    to increasing complexity by employing multi-domains data, as delineated in Fig.
    13, fostering: • Combined acquisition and analysis of spectral data from multiple
    sensors representing multiple modalities and using parametric regressions (see
    Section 5.1); • Simultaneous retrieval of plant traits using multi-domain RTMs
    and ML methods (see Section 5.2); • Assimilation of estimated plant traits based
    on data from different spectral domains into mechanistic models (see Section 5.3);
    • Conceptual framework: Development of fully integrated mechanistic and radiative
    transfer models directly simulating the full variety of spectral measurements
    that can thereafter be assimilated (see Section 5.4). Download : Download high-res
    image (779KB) Download : Download full-size image Fig. 13. Four concepts of sensor
    synergies for stress detection with increasing complexity. The colors blue, green,
    orange and red refer to the spectral domains VIS/NIR, SIF, SWIR, and TIR, respectively,
    and with respect to the derived indices or traits. The indices and traits in the
    small coloured boxes are some selected representative examples. The box on the
    right shows the concept of our proposed conceptual framework, the iCGM - integrated
    crop growth model. (For interpretation of the references to colour in this figure
    legend, the reader is referred to the web version of this article.) 5.1. Combined
    acquisition and analysis of multi-sensor data In the short run - and directly
    feasible with existing methodologies and sensors - we believe that stress detection
    towards operational monitoring should employ at least one sensor and one parametric
    regression or classification method per trait group (i.e. functional, biochemical,
    structural), typically representing plant adaptation responses at varying time
    scales (see Fig.13, left). The synergistic database can then be used to train
    machine learning regression algorithms for generating crop stress prediction models.
    This procedure may allow: i) to better understand the sensitivity of various spectral
    indices to stress occurrence, which will ultimately enable ii) to distinguish
    between diverse stress severity (e.g. mild to severe water stress). For instance,
    Zarco-Tejada et al. (2021) obtained several spectral traits from multi-sensor
    data and used the derived spectral fingerprints for distinguishing different diseases.
    Another study by Damm et al. (2022) investigated temporal sensitivity of multi-sensor
    derived vegetation information for evolving water stress. Since such kinds of
    studies are still scarce, we advocate more research aiming to obtain a holistic
    view of plants under biotic and abiotic stress through synergistic usage of spectral
    information from multiple sensors or domains. However, the differentiation between
    distinct types of stresses (e.g. water-deficit or nutrient stress) will remain
    a challenge with purely RS-based approaches because distinct stressors often lead
    to similar stress reactions (Poblete et al., 2021; Zhang et al., 2019). 5.2. Simultaneous
    retrieval of plant traits employing multi-sensor data, multi-domain RTMs and hybrid
    retrieval methods As a second strategy, we encourage exploiting multi-domain radiative
    transfer models for simultaneous usage of VNIR/SWIR hyperspectral, TIR and SIF
    observations (Yang et al., 2020b). One advantage of using a unified radiative
    transfer scheme for these spectral domains is that the retrieval can be better
    constrained. For example, several studies retrieved crop traits and stress responses
    by combining the VNIR/SWIR and SIF signals with the model SCOPE (Celesti et al.,
    2018; Van der Tol et al., 2016; Yang et al., 2019) and FluorFlight (Hernández-Clemente
    et al., 2017). The analogy of radiative transfer among these spectral domains
    and between reflected and emitted radiation enabled the decomposition of SIF patterns
    into structure related effects (such as leaf inclinations) and physiological stress
    responses. Some of the difficulties of using TIR data can also be overcome with
    multi-domain radiative transfer modeling. For example, Duffour et al. (2015) used
    vegetation traits that can be retrieved from VNIR/SWIR data in SCOPE to simulate
    radiative transfer in the TIR domain as well as the directionality of the TIR
    signal. The improved understanding of the influence of the geometry dependent
    fraction of sunlit and shaded leaves and soil supports the interpretation of TIR
    for stress detection. The inclusion of photosynthesis and non-radiative heat exchange
    (evaporative and convective cooling) in a RTM opens further possibilities for
    multi-domain retrieval. Stomatal and photochemical responses, for example, can
    simultaneously respond to variations in incident solar radiation, both affecting
    the TIR and SIF emissions and radiation absorption in the VIS. With such integrated
    approach, the joint retrieval from the VNIR and TIR domains (Bayat et al., 2018)
    or from the VNIR and SIF (Pacheco-Labrador et al., 2019b) enables the estimation
    of photochemical parameters and stomatal aperture. Suarez et al. (2021) retrieved
    photosynthetic parameters from SCOPE, but using hyperspectral data of the VNIR
    region including subtle responses in the 530–570 nm range caused by xanthophyll
    pigment changes associated with non-photochemical quenching in response to excess
    light as modelled by Vilfan et al. (2018). These studies demonstrate the benefit
    of multi-domain and multi-process models, but analysis of such datasets can be
    complex and computationally intensive. For larger datasets, the capabilities of
    these models can be preserved without additional computational burden by using
    machine learning or deep learning approaches: the retrieval of proxies could be
    accomplished by means of hybrid approaches which combine machine learning with
    RTMs (Verrelst et al., 2019a), as delineated in Fig.13 (second left). 5.3. Assimilation
    of remotely derived crop traits into crop growth models For efficient stress detection
    and prognosis, the assimilation of spatially derived trait maps from RS observations
    into crop growth models (CGM) (e.g., van Diepen et al., 1989; Hank et al., 2015;
    Jones et al., 2003) would be beneficial. These mechanistic models also account
    for weather and soil variables or agricultural management practices, which could
    help to identify the cause of the stress (Baret et al., 2007). The continuous
    description of crop growth and development using mechanistic models offers means
    to summarize current knowledge about the main processes in the soil-plant-atmosphere
    continuum, which also include stress related processes and phenomena (Weiss et
    al., 2020). Therefore, we propose to explore this concept (see also Fig.13, second
    right), which can serve for the development of a digital twin (DT) of the farming
    system (Verdouw et al., 2021). Such DTs are digital equivalents of real-life objects,
    virtually mirroring the behaviour and states of physical systems over their whole
    lifetime (Grieves and Vickers, 2016). In relation to precision agriculture applications,
    current state-of-the-art CGMs include advanced crop growth models (Peng et al.,
    2018), crop-specific parameterizations (Boas et al., 2021; Sulis et al., 2015),
    and crop management practices like irrigation and nitrogen fertilization (Lombardozzi
    et al., 2020). The synergistic use of CGMs and RS is already being explored for
    building operational monitoring and prediction platforms capable of delivering
    useful information for agricultural applications and decisions (e.g., McNally
    et al., 2017; Peters-Lidard et al., 2021). These platforms are mainly based on
    the assimilation of water cycle measurements (e.g., soil moisture) and remotely
    sensed vegetation variables (e.g., LAI), obtaining clear improvements in the estimation
    of vegetation biomass, evapotranspiration, root zone soil moisture, and carbon
    fluxes. More complex and realistic representation of physical processes recently
    implemented in CGMs and the exploitation of the different optical domains in RS
    open the opportunity to predict better a wider range of crop processes, most notably
    to capture the onset of crop water and heat stress, reducing also the uncertainty
    in crop model variable estimation. The assimilation of multiple data streams into
    CGMs and thus the establishment of DTs, represents also a viable approach for
    getting an improved understanding about physical mechanisms and feedback controlling
    the development, duration, and impacts of stress on plant growth and yield. However,
    significant challenges have to be addressed in order to fully exploit this potential.
    These challenges include consistency checks between diverse RS observations and
    between the retrieval algorithms and the crop model parameterizations, as well
    as the robust quantification of the uncertainties along traceable processing chains.
    5.4. Proposed conceptional framework: Integration of crop growth and radiative
    transfer models Future stress research should focus on the integration of suitable
    multi-domain radiative transfer models (e.g. SCOPE) with dynamic crop growth models
    to build up DTs of agroecosystems. Such integrated models (iCGMs) directly simulate
    remotely observed signals based on the status of the underlying CGM at any given
    point in time (see Fig.13, right). This means the iCGM simulates the spectral
    signatures of the canopy (400–2500 nm), the SIF emission as well as the thermal
    properties, along with physiological processes (Delécolle et al., 1992; Moulin
    et al., 1998). The integration of CGMs and RTMs has several compelling advantages.
    On the one hand, the CGM can benefit from all available satellite data while the
    assimilation scheme can weigh the value of observations by using information about
    their uncertainties. However, combining data with various spatial and temporal
    resolution needs to be considered carefully in the conceptual design (Huang et
    al., 2019). Traits that appear both as a status variable in the CGM and as an
    input of the RTM have to permit the RTM to simulate spectral properties across
    all domains. For the number of traits, being sensitive in the different spectral
    domains, assimilation strategies need to be developed taking into account the
    different availability (timing) of sensor data. The assimilation needs to allow
    for a model update at different times, where only a part of the variables are
    assimilated, with model-intern constraints and links to further variables. On
    the other hand, the RTM could benefit from the background information of the CGM.
    Satellite derived time series of vegetation traits can be noisy due to atmospheric,
    orbital and geometric effects. The use of retrievals in close proximity in time
    as background information has shown to be effective in making the satellite data
    smoother (Mousivand et al., 2015; Yang et al., 2021b). CGMs provide continuous
    series of temporal growth dynamics which can be used to detect outliers and to
    improve the construction of smooth time-series from heterogeneous satellite data.
    In this respect, the use of a CGM assimilating these data is a step up. Furthermore,
    by inserting a morphological sub-model, one could simulate the physiological appearance
    of plants, which lead - using a suitable sensor model - to temporal evolution
    of point clouds observable through photogrammetry or Lidar (Liu et al., 2019).
    Expanding existing RTMs from the optical spectral domain to the microwave range
    would similarly lead to the simulation of temporal sequences of (active and passive)
    microwave signatures (e.g. using a RADAR backscatter model). The combined set
    of spectral properties would be simulated simultaneously for each time step of
    the iCGM, which ideally should be hourly. For executing iCGMs over large areas
    in high temporal and spatial resolutions, this physically based modeling could
    be combined with machine learning to estimate traits or stress proxies within
    a hybrid manner. The complex models can also be partly replaced through surrogate
    models or emulators speeding up the forward simulations (Verrelst et al., 2019b).
    As CGMs are driven by weather variables, it is also easy to conceive the integration
    of weather forecasts and/or weather scenarios in such iCGM (see Section 5.3).
    This dynamic nature would meet the requirements of a DT of agroecosystems, which
    besides the representation of current behaviour, also predicts their future behaviour
    (Verdouw et al., 2021). Therefore, we consider the iCGM as the most promising
    approach and this section is meant as a way to stimulate further discussion about
    DTs within the community. Once developed, such iCGMs facilitate tackling various
    research gaps needed to define future sensitive Earth observational approaches
    and stimulate the development of applications in the realm of precision agriculture.
    In the near future, we will have a multitude of spectral data available to feed
    the proposed iCGM. Besides the recently available and upcoming spaceborne imagine
    spectrometer data, such as the Environmental Mapping and Analysis Program (EnMAP)
    (Guanter et al., 2015), PRecursore IperSpettrale della Missione Applicativa (PRISMA)
    (Cogliati et al., 2021; Loizzo et al., 2019), Copernicus Hyperspectral Imaging
    Mission for the Environment (Rast et al., 2021) or the ECOsystem Spaceborne Thermal
    Radiometer Experiment on Space Station (ECOSTRESS) data (Fisher et al., 2020),
    UAVs became a crucial platform with respect to sensor synergies. Several light
    multi- and hyperspectral VIS, NIR and SWIR, thermal and SIF sensors are available
    nowadays (overviews provided by Aasen et al. (2018); Awais et al. (2022); Herrmann
    and Berger (2021); Messina and Modica (2020); Neupane and Baysal-Gurel (2021);
    Yang et al. (2017a)), which can be explored for model development or validation
    of physiological traits related to crop stress. Besides spectral synergies, the
    exploitation of multi-scale multi-sensor data allows to fill temporal gaps and
    improve spatial resolutions. Hence, such upcoming multi-scale approaches are foreseen
    to play a more dominant role in future studies (Alvarez-Vanhard et al., 2021;
    Inoue et al., 2018; Machwitz et al., 2021; Sagan et al., 2019). Some applications
    and use cases of our proposed conceptional framework are laid out below. Sensitivity
    assessment of state-of-the-art approaches: Remote sensing measurements and retrieved
    crop information can be subject to insensitivity or uncertainties caused by various
    sources, e.g., instrumental effects and calibration issues (Pacheco-Labrador et
    al., 2019a), spatial-spectral-temporal sampling design (Aasen et al., 2019), retrieval
    assumptions (Cendrero-Mateo et al., 2019), cf. Buman et al. (2022) for an overview
    of related uncertainties on SIF. Such effects can result in a mismatch between
    expected and observed crop behaviour (e.g. spatio-temporal dynamics of crop state
    variables). The proposed conceptual framework (section 5.4) can be applied to
    facilitate sensitivity analysis aiming to assess potential crop responses and
    their spatio-temporal dynamics. Resulting insights allow us to identify sensitive
    wavelength regions, sampling schemes, and sensor modalities for crop stress symptoms.
    In this way, artificially modulated dynamics inherent to state-of-the art observational
    approaches, e.g., trends caused by sensor degradation, anomalies, and covariance
    between traits due to imperfect retrievals, can be unraveled. Benchmarking and
    uncertainty assessment for mission development: Experimental or operational satellite
    missions require dedicated tools to define scientific needs and requirements (Malenovský
    et al., 2012). The conceptual framework holds the capacity to support the evaluation
    of such requirements. One example is to parameterize the framework with densely
    sampled multi-sensor data to assess subtle stress responses of crops, such as
    photosynthesis, gas exchange or pigment degradation (Jin et al., 2018). In an
    ablation study, data scarcity can be simulated to quantify uncertainties related
    to e.g. reduced spectral, temporal and spatial resolutions. Resulting insights
    allow assessing critical sampling dimensions for various stress symptoms and to
    make recommendations towards new experimental or operational crop stress missions
    or to design dedicated in situ or close range approaches. Stress detection via
    anomalies: The framework allows to calculate potential crop states and functioning
    (e.g. growth rates, gas exchange) as induced by environmental drivers (Huang et
    al., 2019). The comparison of actual estimates of crop state and functioning against
    its simulated potential offers a pathway to identify anomalous crop conditions
    (e.g. caused by crop stress). Forecasting of crop stress and tools: The framework
    allows to learn - through simulation - how ecosystems behave under current and
    future environmental conditions, also known as scenario analysis (Machwitz et
    al., 2018). The coupling also enables forecasting of crop stress responses when
    upcoming growth conditions can be reasonably well simulated. The ultimate goal
    of developing advanced crop monitoring and forecasting tools is to provide reliable
    and usable information to public and private stakeholders in the agricultural
    sector. This goal can be achieved by targeting distinct spatial scales (i.e.,
    from field to the regional scale) and temporal horizons (from short-range to seasonal)
    that match with farmers'' activities and planning. In this context, the seamless
    integration of CGM + RTM data assimilation cycles into operational weather forecast
    chains that cover the full temporal spectrum of farmers'' decisions appears the
    most straightforward approach in order to accomplish this objective. The additional
    use of meteorological information relevant during the distinct crop development
    stages (e.g., accumulated heat time, probability of heat/cold stress) also has
    the advantage to improve the interpretation of environmental stresses for a given
    crop development stage (McNally et al., 2017; Peters-Lidard et al., 2021). The
    wealth of numerical information extracted from such monitoring and forecasting
    tools needs to be translated into crop-specific stress indicators to create an
    interface between scientific advancements and the decision-making process. Finally,
    the probabilistic character of the meteorological forecasts and the uncertainties
    in RS observations and numerical models formulations must be accounted for. 6.
    Conclusions Timely and efficient detection of crop stress remains a challenge
    but can be approached by exploring multiple RS data sources. In addition, the
    portfolio of available tools and retrieval methods for the identification of specific
    stresses has been increasing in the last decade. In this review, we focused on
    the use of optical sensor synergies for improving spectral sampling to better
    characterize and interpret crop stresses in support of sustainable agriculture.
    We identified three different phases (stages) of stress depending on duration
    and severity: (1) early and short-term, (2) medium-term and mild (3) chronic and
    severe. The three phases can best be detected by optical RS domains through specifically
    affected traits, such as fluxes at early stages sensed by SIF and TIR, and biochemicals
    and structural properties at later stress stages, measured with reflective optical
    systems in the VIS, NIR and SWIR wavelength ranges. Our review revealed that the
    combination of VIS, NIR and TIR domains was employed by the majority of studies
    addressing crop stress. However, this choice was mainly driven by economical and
    practical reasons, i.e. the availability of sensors. Furthermore, in most publications,
    the exploration of diverse spectral domains was rather based on a comparison of
    respective methods than on synergistic and integrated methodological concepts.
    An efficient crop stress detection framework has to be versatile, easy to operate,
    and inexpensive so that it can be easily integrated into precision agriculture
    and breeding systems. To achieve this, we pursue four ways forward of increasing
    complexity. These possible concepts involve: (i) Combined analysis of data from
    multiple sensors using representative parametric regressions and ML approaches,
    leading to qualitative stress maps. (ii) Simultaneous retrieval of plant traits
    using multi-domain RTMs and ML methods, providing quantitative stress maps. (iii)
    Assimilation of estimated plant traits based on data from different spectral domains
    into CGMs, and integrated dynamic CGMs (iv), which both lead to quantitative stress
    and stressor maps also enabling stress prediction. In this way, the digital twinning
    of agroecosystems provides a new perspective for real-life, highly accurate and
    holistic views of stress and stressors, allowing to act on time and thus contributing
    to a sustainable agricultural production needed to feed the future world population.
    Hence, we suggest that the community progresses towards such a DT design for stress
    effects, causes and prediction in a joint initiative. Such a synergistic approach
    has the potential to extract essential information about the plant stress status
    and may reveal the causes of biophysical, physiological and photochemical changes
    over cultivated areas in space and time. Funding This research was funded by the
    EnMAP scientific preparation program under the DLR Space Administration with resources
    from the German Federal Ministry of Economic Affairs and Energy, grant number
    50EE1923 (K. Berger). This research was also funded by the European Research Council
    (ERC) under the ERC-2017-STG SENTIFLEX project (grant agreement 755617) (K. Berger)
    and Ramón y Cajal Contract (Spanish Ministry of Science, Innovation and Universities)
    (J. Verrelst). S.C. Kefauver is supported by the Ramon y Cajal RYC-2019-027818-I
    research fellowship from the Ministerio de Ciencia e InnovaciÃ3n, Spain. S. Van
    Wittenberghe is supported by the European Research Council (ERC) under the ERC-2021-STG
    PHOTOFLUX project (grant agreement 101041768). M. Celesti was supported by a Living
    Planet Fellowship (ESA/Contract No. 4000125442/18/I-NS) of the European Space
    Agency. V. Sobejano Paz PhD thesis was supported by the AgWIT JPI project ERA-NET
    Co-fund Water Works 2015 Call and a SDC grant (Sino Danish Council). Credit author
    statement Conceptualisation: KB, MM, MK, SK, JV, UR, AD, MSc; Investigation: KB,
    MM, MK, ETG, MR, MF, BS, AA, GT, IP, MG, ET, OR, LF, GS, MSc; Methodology: KB;
    Visualisation: KB, MM, SVW, VSP, MG, GK, MF, EP, ET, TH, MSc; Software: KB, MC,
    EP; Writing - original draft: KB, MM, MK, SVW, UR, IH, CA, MG, AH, GK, CvT, MR,
    MF, BS, GT, SB, AD, MSu, ET, OR, MSc; Writing - review and editing: KB, MM, SK,
    MC, JV, IH, CA, SF, RP, CvT, MR, HA, AD, MLB, RD, TH, MSc; Project administration:
    KB, MM, MSc. Declaration of Competing Interest The authors declare that they have
    no known competing financial interests or personal relationships that could have
    appeared to influence the work reported in this paper. Acknowledgments The research
    was mainly supported by the Action CA17134 SENSECO (Optical synergies for spatiotemporal
    sensing of scalable ecophysiological traits) funded by COST (European Cooperation
    in Science and Technology, www.cost.eu (accessed on 16/03/2022)). The publication
    is also the result of the project implementation: “Scientific support of climate
    change adaptation in agriculture and mitigation of soil degradation” (ITMS2014+313011W580)
    supported by the Integrated Infrastructure Operational Programme funded by the
    ERDF. We also thank the two reviewers for their fundamental suggestions. References
    Aasen et al., 2018 H. Aasen, E. Honkavaara, A. Lucieer, P.J. Zarco-Tejada Quantitative
    remote sensing at ultra-high resolution with UAV spectroscopy: a review of sensor
    technology, measurement procedures, and data correction workflows Remote Sens.,
    10 (2018), p. 1091, 10.3390/rs10071091 View in ScopusGoogle Scholar Aasen et al.,
    2019 H. Aasen, S. Van Wittenberghe, N. Sabater Medina, A. Damm, Y. Goulas, S.
    Wieneke, A. Hueni, Z. Malenovský, L. Alonso, J. Pacheco- Labrador, M.P. Cendrero-Mateo,
    E. Tomelleri, A. Burkart, S. Cogliati, U. Rascher, A. Mac Arthur Sun-induced chlorophyll
    fluorescence II: review of passive measurement setups, protocols, and their application
    at the leaf to canopy level Remote Sens., 11 (2019), p. 927, 10.3390/rs11080927
    View in ScopusGoogle Scholar Abdullah et al., 2019 H. Abdullah, A.K. Skidmore,
    R. Darvishzadeh, M. Heurich Timing of red-edge and shortwave infrared reflectance
    critical for early stress detection induced by bark beetle (Ips typographus, L.)
    attack Int. J. Appl. Earth Obs. Geoinf., 82 (2019), Article 101900, 10.1016/j.jag.2019.101900
    View PDFView articleView in ScopusGoogle Scholar Ač et al., 2015 A. Ač, Z. Malenovský,
    J. Olejníčková, A. Gallé, U. Rascher, G. Mohammed Meta-analysis assessing potential
    of steady-state chlorophyll fluorescence for remote sensing detection of plant
    water, temperature and nitrogen stress Remote Sens. Environ., 168 (2015), pp.
    420-436, 10.1016/j.rse.2015.07.022 View PDFView articleView in ScopusGoogle Scholar
    Acebron et al., 2021 K. Acebron, S. Matsubara, C. Jedmowski, D. Emin, O. Muller,
    U. Rascher Diurnal dynamics of nonphotochemical quenching in Arabidopsis npq mutants
    assessed by solar-induced fluorescence and reflectance measurements in the field
    New Phytol., 229 (2021), pp. 2104-2119, 10.1111/nph.16984 View in ScopusGoogle
    Scholar Agam et al., 2013 N. Agam, Y. Cohen, V. Alchanatis, A. Ben-Gal How sensitive
    is the CWSI to changes in solar radiation? Int. J. Remote Sens., 34 (2013), pp.
    6109-6120, 10.1080/01431161.2013.793873 View in ScopusGoogle Scholar Ainsworth
    et al., 2014 E.A. Ainsworth, S.P. Serbin, J.A. Skoneczka, P.A. Townsend Using
    leaf optical properties to detect ozone effects on foliar biochemistry Photosynth.
    Res., 119 (2014), pp. 65-76, 10.1007/s11120-013-9837-y View in ScopusGoogle Scholar
    Aldea et al., 2005 M. Aldea, J.G. Hamilton, J.P. Resti, A.R. Zangerl, M.R. Berenbaum,
    E.H.D. Elucia Indirect effects of insect herbivory on leaf gas exchange in soybean
    Plant Cell Environ., 28 (2005), pp. 402-411, 10.1111/j.1365–3040.2005.01279.x
    View in ScopusGoogle Scholar Alonso et al., 2017 L. Alonso, S. Van Wittenberghe,
    J. Amorós-López, J. Vila-Francés, L. Gómez-Chova, J. Moreno Diurnal cycle relationships
    between passive fluorescence, pri and npq of vegetation in a controlled stress
    experiment Remote Sens., 9 (2017), 10.3390/rs9080770 URL:https://www.mdpi.com/2072-4292/9/8/770
    Google Scholar Alvarez-Vanhard et al., 2021 E. Alvarez-Vanhard, T. Corpetti, T.
    Houet UAV & satellite synergies for optical remote sensing applications: a literature
    review Sci. Remote Sens., 3 (2021), Article 100019, 10.1016/j.srs.2021.100019
    View PDFView articleView in ScopusGoogle Scholar Anderson et al., 2018 M. Anderson,
    F. Gao, K. Knipper, C. Hain, W. Dulaney, D. Baldocchi, E. Eichelmann, K. Hemes,
    Y. Yang, J. Medellin-Azuara, W. Kustas Field-scale assessment of land and water
    use change over the California delta using remote sensing Remote Sens., 10 (2018),
    p. 889, 10.3390/rs10060889 View in ScopusGoogle Scholar Appeltans et al., 2020
    S. Appeltans, A. Guerrero, S. Nawar, J. Pieters, A.M. Mouazen Practical recommendations
    for hyperspectral and thermal proximal disease sensing in potato and leek fields
    Remote Sens., 12 (2020), p. 1939, 10.3390/rs12121939 View in ScopusGoogle Scholar
    Atzberger, 2013 C. Atzberger Advances in remote sensing of agriculture: context
    description, existing operational monitoring systems and major information needs
    Remote Sens., 5 (2013), pp. 949-981, 10.3390/rs5020949 View in ScopusGoogle Scholar
    Awais et al., 2022 M. Awais, W. Li, M.J.M. Cheema, Q.U. Zaman, A. Shaheen, B.
    Aslam, W. Zhu, M. Ajmal, M. Faheem, S. Hussain, A.A. Nadeem, M.M. Afzal, C. Liu
    UAV-based remote sensing in plant stress imagine using high-resolution thermal
    sensor for digital agriculture practices: a meta-review Int. J. Environ. Sci.
    Technol. (2022), pp. 1-18, 10.1007/s13762-021-03801-5 View in ScopusGoogle Scholar
    Baluja et al., 2012 J. Baluja, M.P. Diago, P. Balda, R. Zorer, F. Meggio, F. Morales,
    J. Tardaguila Assessment of vineyard water status variability by thermal and multispectral
    imagery using an unmanned aerial vehicle (UAV) Irrig. Sci., 30 (2012), pp. 511-522,
    10.1007/s00271-012-0382-9 View in ScopusGoogle Scholar Baret et al., 2007 F. Baret,
    V. Houles, M. Guérif Quantification of plant stress using remote sensing observations
    and crop models: the case of nitrogen management J. Exp. Bot., 58 (2007), pp.
    869-880, 10.1093/jxb/erl231 View in ScopusGoogle Scholar Baret et al., 2018 F.
    Baret, S. Madec, K. Irfan, J. Lopez, A. Comar, M. Hemmerlé, D. Dutartre, S. Praud,
    M.H. Tixier Leaf-rolling in maize crops: from leaf scoring to canopy-level measurements
    for phenotyping J. Exp. Bot., 69 (2018), pp. 2705-2716, 10.1093/jxb/ery071 View
    in ScopusGoogle Scholar Bayat et al., 2018 B. Bayat, C. Van der Tol, W. Verhoef
    Integrating satellite optical and thermal infrared observations for improving
    daily ecosystem functioning estimations during a drought episode Remote Sens.
    Environ., 209 (2018), pp. 375-394, 10.1016/j.rse.2018.02.027 View PDFView articleView
    in ScopusGoogle Scholar Behmann et al., 2015 J. Behmann, A.K. Mahlein, T. Rumpf,
    C. Römer, L. Plümer A review of advanced machine learning methods for the detection
    of biotic stress in precision crop protection Precis. Agric., 16 (2015), pp. 239-260,
    10.1007/s11119–014–9372-7 View in ScopusGoogle Scholar Bendel et al., 2020 N.
    Bendel, A. Kicherer, A. Backhaus, H.C. Klück, U. Seiffert, M. Fischer, R.T. Voegele,
    R. Töpfer Evaluating the suitability of hyper- and multispectral imaging to detect
    foliar symptoms of the grapevine trunk disease Esca in vineyards Plant Methods,
    16 (2020), p. 142, 10.1186/s13007-020-00685-3 View in ScopusGoogle Scholar Berger
    et al., 2020 K. Berger, J. Verrelst, J.B. Féret, Z. Wang, M. Wocher, M. Strathmann,
    M. Danner, W. Mauser, T. Hank Crop nitrogen monitoring: recent progress and principal
    developments in the context of imaging spectroscopy missions Remote Sens. Environ.,
    242 (2020), p. 8, 10.1016/j.rse.2020.111758 Google Scholar Berger et al., 2021
    K. Berger, J.P. Rivera Caicedo, L. Martino, M. Wocher, T. Hank, J. Verrelst A
    survey of active learning for quantifying vegetation traits from terrestrial earth
    observation data Remote Sens., 13 (2021), p. 287, 10.3390/rs13020287 Google Scholar
    Berni et al., 2009a J. Berni, P. Zarco-Tejada, G. Sepulcre-Cantó, E. Fereres,
    F. Villalobos Mapping canopy conductance and CWSI in olive orchards using high
    resolution thermal remote sensing imagery Remote Sens. Environ., 113 (2009), pp.
    2380-2388 URL: https://linkinghub.elsevier.com/retrieve/pii/S0034425709002090
    https://doi.org/10.1016/j.rse.2009.06.018 View PDFView articleView in ScopusGoogle
    Scholar Berni et al., 2009b J.A.J. Berni, P.J. Zarco-Tejada, L. Suarez, E. Fereres
    Thermal and narrowband multispectral remote sensing for vegetation monitoring
    from an unmanned aerial vehicle IEEE Trans. Geosci. Remote Sens., 47 (2009), pp.
    722-738, 10.1109/TGRS.2008.2010457 View in ScopusGoogle Scholar Bhattarai et al.,
    2019 N. Bhattarai, K. Mallick, J. Stuart, B.D. Vishwakarma, R. Niraula, S. Sen,
    M. Jain An automated multi-model evapotranspiration mapping framework using remotely
    sensed and reanalysis data Remote Sens. Environ., 229 (2019), pp. 69-92, 10.1016/j.rse.2019.
    04.026 View PDFView articleView in ScopusGoogle Scholar Bhuiyan et al., 2017 C.
    Bhuiyan, A.K. Saha, N. Bandyopadhyay, F.N. Kogan Advances in remote sensing and
    GIS-based drought monitoring analyzing the impact of thermal stress on vegetation
    health and agricultural drought - a case study from Gujarat, India GI- Sci. Remote
    Sens., 54 (2017), pp. 678-699, 10.1080/15481603.2017.1309737 View in ScopusGoogle
    Scholar Bian et al., 2019 J. Bian, Z. Zhang, J. Chen, H. Chen, C. Cui, X. Li,
    S. Chen, Q. Fu Simplified evaluation of cotton water stress using high resolution
    unmanned aerial vehicle thermal imagery Remote Sens., 11 (2019), 10.3390/rs11030267
    Google Scholar Bilger and Bjorkman, 1990 W. Bilger, O. Bjorkman Role of the xanthophyll
    cycle in photoprotection elucidated by measurements of light-induced absorbance
    changes, fluorescence and photosynthesis in leaves of Hedera canariensis Photosynth.
    Res., 25 (1990), pp. 173-185, 10.1007/BF00033159 View in ScopusGoogle Scholar
    Blum, 2016 A. Blum Stress, strain, signaling, and adaptation –not just a matter
    of definition J. Exp. Bot., 67 (2016), pp. 562-565, 10.1093/jxb/erv497 View in
    ScopusGoogle Scholar Boas et al., 2021 T. Boas, H. Bogena, T. Grünwald, B. Heinesch,
    D. Ryu, M. Schmidt, H. Vereecken, A. Western, H.J. Hendricks Franssen Improving
    the representation of cropland sites in the community land model (clm) version
    5.0 Geosci. Model Dev., 14 (2021), pp. 573-601 URL: https://gmd.copernicus.org/articles/14/573/2021/
    https://doi.org/10.5194/gmd-14-573-2021 CrossRefView in ScopusGoogle Scholar Broge
    and Leblanc, 2001 N.H. Broge, E. Leblanc Comparing prediction power and stability
    of broadband and hyperspectral vegetation indices for estimation of green leaf
    area index and canopy chlorophyll density Remote Sens. Environ., 76 (2001), pp.
    156-172, 10.1016/S0034-4257(00)00197-8 View PDFView articleView in ScopusGoogle
    Scholar Brugnoli and Bjorkman, 1992 E. Brugnoli, O. Bjorkman Chloroplast movements
    in leaves: influence on chlorophyll fluorescence and measurements of light-induced
    absorbance changes related to pH and zeaxanthin formation Photosynth. Res., 32
    (1992), pp. 23-35, 10.1007/BF00028795 View in ScopusGoogle Scholar Buitrago et
    al., 2016 M.F. Buitrago, T.A. Groen, C.A. Hecker, A.K. Skidmore Changes in thermal
    infrared spectra of plants caused by temperature and water stress ISPRS J. Photogramm.
    Remote Sens., 111 (2016), pp. 22-31, 10.1016/j.isprsjprs.2015.11.003 View PDFView
    articleView in ScopusGoogle Scholar Buman et al., 2022 B. Buman, A. Hueni, R.
    Colombo, S. Cogliati, M. Celesti, T. Julitta, A. Burkart, B. Siegmann, U. Rascher,
    M. Drusch, A. Damm Towards consistent assessments of in situ radiometric measurements
    for the validation of fluorescence satellite missions Remote Sens. Environ., 274
    (2022), Article 112984, 10.1016/j.rse.2022.112984 View PDFView articleView in
    ScopusGoogle Scholar Camino et al., 2018 C. Camino, P.J. Zarco-Tejada, V. Gonzalez-Dugo
    Effects of heterogeneity within tree crowns on airborne-quantified sif and the
    cwsi as indicators of water stress in the context of precision agriculture Remote
    Sens., 10 (2018), 10.3390/rs10040604 URL: https://www.mdpi.eom/2072-4292/10/4/604
    Google Scholar Camino et al., 2021 C. Camino, R. Calderón, S. Parnell, H. Dierkes,
    Y. Chemin, M. Román-Écija, M. Montes-Borrego, B.B. Landa, J.A. Navas-Cortes, P.J.
    Zarco- Tejada, P.S.A. Beck Detection of Xylella fastidiosa in almond orchards
    by synergic use of an epidemic spread model and remotely sensed plant traits Remote
    Sens. Environ., 260 (2021), Article 112420, 10.1016/j.rse.2021.112420 View PDFView
    articleView in ScopusGoogle Scholar Campbell et al., 2007 P.K.E. Campbell, E.M.
    Middleton, J.E. McMurtrey, L.A. Corp, E.W. Chap-pelle Assessment of vegetation
    stress using reflectance or fluorescence measurements J. Environ. Qual., 36 (2007),
    pp. 832-845, 10.2134/jeq2005.0396 View in ScopusGoogle Scholar Carter and Knapp,
    2001 G.A. Carter, A.K. Knapp Leaf optical properties in higher plants: linking
    spectral characteristics to stress and chlorophyll concentration Am. J. Bot.,
    88 (2001) URL: https://pubmed.ncbi.nlm.nih.gov/11302854 arXiv:11302854 Google
    Scholar Celesti et al., 2018 M. Celesti, C. Van der Tol, S. Cogliati, C. Panigada,
    P. Yang, F. Pinto, U. Rascher, F. Miglietta, R. Colombo, M. Rossini Exploring
    the physiological information of Sun-induced chlorophyll fluorescence through
    radiative transfer model inversion Remote Sens. Environ., 215 (2018), pp. 97-108,
    10.1016/j.rse.2018.05.013 View PDFView articleView in ScopusGoogle Scholar Cendrero-Mateo
    et al., 2019 M.P. Cendrero-Mateo, S. Wieneke, A. Damm, L. Alonso, F. Pinto, J.
    Moreno, L. Guanter, M. Celesti, M. Rossini, N. Sabater, S. Cogliati, T. Julitta,
    U. Rascher, Y. Goulas, H. Aasen, J. Pacheco-Labrador, A. Mac Arthur Sun-induced
    chlorophyll fluorescence III: benchmarking retrieval methods and sensor characteristics
    for proximal sensing Remote Sens., 11 (2019), p. 962, 10.3390/rs11080962 View
    in ScopusGoogle Scholar Chaerle and Van Der Straeten, 2000 L. Chaerle, D. Van
    Der Straeten Imaging techniques and the early detection of plant stress Trends
    Plant Sci., 5 (2000), pp. 495-501, 10.1016/S1360–1385(00)01781–7 View PDFView
    articleView in ScopusGoogle Scholar Chaerle et al., 2004 L. Chaerle, D. Hagenbeek,
    E. De Bruyne, R. Valcke, D. Van Der Straeten Thermal and chlorophyll-fluorescence
    imaging distinguish plant- pathogen interactions at an early stage Plant Cell
    Physiol., 45 (2004), pp. 887-896, 10.1093/pcp/pch097 arXiv:15295072 View in ScopusGoogle
    Scholar Chaerle et al., 2006 L. Chaerle, I. Leinonen, H.G. Jones, D. Van Der Straeten
    Monitoring and screening plant populations with combined thermal and chlorophyll
    fluorescence imaging J. Exp. Bot., 58 (2006), pp. 773-784, 10.1093/jxb/ erl257
    Google Scholar Chaerle et al., 2009 L. Chaerle, S. Lenk, I. Leinonen, H.G. Jones,
    D.V.D. Straeten, C. Buschmann Multi-sensor plant imaging: towards the development
    of a stress-catalogue Biotechnol. J., 4 (2009), pp. 1152-1167, 10.1002/biot.200800242
    View in ScopusGoogle Scholar Chang et al., 2013 Q. Chang, J. Liu, Q. Wang, L.
    Han, J. Liu, M. Li, L. Huang, J. Yang, Z. Kang The effect of Puccinia striiformis
    f. sp. tritici on the levels of water-soluble carbohydrates and the photosynthetic
    rate in wheat leaves Physiol. Mol. Plant Pathol., 84 (2013), pp. 131-137, 10.1016/j.pmpp.2013.09.001
    View PDFView articleView in ScopusGoogle Scholar Cogato et al., 2019 A. Cogato,
    F. Meggio, M. De Antoni Migliorati, F. Marinello Extreme weather events in agriculture:
    a systematic review Sustainability, 11 (2019), p. 2547, 10.3390/su11092547 View
    in ScopusGoogle Scholar Cogliati et al., 2019 S. Cogliati, M. Celesti, F. Miglietta,
    L. Genesio, T. Julitta, D. Schuettemeyer, M. Drusch, U. Rascher, P. Jurado, R.
    Colombo A spectral fitting algorithm to retrieve the fluorescence spectrum from
    canopy radiance Remote Sens., 11 (2019), p. 1840, 10.3390/rs11161840 View in ScopusGoogle
    Scholar Cogliati et al., 2021 S. Cogliati, F. Sarti, L. Chiarantini, M. Cosi,
    R. Lorusso, E. Lopinto, F. Miglietta, L. Genesio, L. Guanter, A. Damm, S. Pérez-López,
    D. Scheffler, G. Tagliabue, C. Panigada, U. Rascher, T.P.F. Dowling, C. Giardino,
    R. Colombo The PRISMA imaging spectroscopy mission: overview and first performance
    analysis Remote Sens. Environ., 262 (2021), Article 112499, 10.1016/j.rse.2021.112499
    View PDFView articleView in ScopusGoogle Scholar Cohen et al., 2017 Y. Cohen,
    V. Alchanatis, Y. Saranga, O. Rosenberg, E. Sela, A. Bosak Mapping water status
    based on aerial thermal imagery: comparison of methodologies for upscaling from
    a single leaf to commercial fields Precis. Agric., 18 (2017), pp. 801-822, 10.1007/s11119-016-9484-3
    View in ScopusGoogle Scholar Cronin et al., 2008 P. Cronin, F. Ryan, M. Coughlan
    Undertaking a literature review: a step-by-step approach Br. J. Nurs., 23 (2008),
    10.12968/bjon.2008.17.1.28059 17, 38–43. arXiv:18399395 Google Scholar Damm et
    al., 2018 A. Damm, E. Paul-Limoges, E. Haghighi, C. Simmer, F. Morsdorf, F. Schneider,
    C. Van der Tol, M. Migliavacca, U. Rascher Remote sensing of plant-water relations:
    An overview and future perspectives J. Plant Physiol., 227 (2018), pp. 3-19 URL:
    https://www.sciencedirect.com/science/article/pii/S0176161718301172 https://doi.org/10.1016/j.jplph.2018.04.012
    from aqua- porin to ecosystem: Plants in the water cycle View PDFView articleView
    in ScopusGoogle Scholar Damm et al., 2022 A. Damm, S. Cogliati, R. Colombo, L.
    Fritsche, A. Genangeli, L. Genesio, J. Hanus, A. Peressotti, P. Rademske, U. Rascher,
    D. Schuettemeyer, B. Siegmann, J. Sturm, F. Miglietta Response times of remote
    sensing measured sun-induced chlorophyll fluorescence, surface temperature and
    vegetation indices to evolving soil water limitation in a crop canopy Remote Sens.
    Environ., 273 (2022), Article 112957, 10.1016/j.rse.2022. 112957 View PDFView
    articleView in ScopusGoogle Scholar De Grave et al., 2020 C. De Grave, J. Verrelst,
    P. Morcillo-Pallarés, L. Pipia, J. Rivera-Caicedo, E. Amin, S. Belda, J. Moreno
    Quantifying vegetation biophysical variables from the sentinel-3/flex tandem mission:
    Evaluation of the synergy of olci and floris data sources Remote Sens. Environ.,
    251 (2020), Article 112101, 10.1016/j.rse.2020.112101 View PDFView articleView
    in ScopusGoogle Scholar DeJonge et al., 2015 K.C. DeJonge, S. Taghvaeian, T.J.
    Trout, L.H. Comas Comparison of canopy temperature-based water stress indices
    for maize Agric. Water Manag., 156 (2015), pp. 51-62 URL: https://linkinghub.elsevier.com/retrieve/pii/S0378377415001067
    https://doi.org/10.1016/j.agwat.2015.03.023 View PDFView articleView in ScopusGoogle
    Scholar Delalieux et al., 2014 S. Delalieux, P.J. Zarco-Tejada, L. Tits, M.A.
    Jimenez Bello, D.S. Intrigliolo, B. Somers Unmixing-based fusion of hyperspatial
    and hyperspectral airborne imagery for early detection of vegetation stress IEEE
    J. Select. Top. Appl. Earth Observ. Remote Sens., 7 (2014), p. 25712582, 10.1109/JSTARS.2014.2330352
    Google Scholar Delécolle et al., 1992 R. Delécolle, S.J. Maas, M. Guérif, F. Baret
    Remote sensing and crop production models: present trends ISPRS J. Photogramm.
    Remote Sens., 47 (1992), pp. 145-161, 10.1016/0924-2716(92)90030-D View PDFView
    articleView in ScopusGoogle Scholar Demmig-Adams et al., 2020 B. Demmig-Adams,
    J. Stewart, M. López-Pozo, S. Polutchko, W. Adams III Zeaxanthin, a molecule for
    photoprotection in many different environments Molecules, 25 (2020), p. 5825 URL:
    https://www.mdpi.com/1420-3049/25/24/5825 https://doi.org/10.3390/molecules25245825
    CrossRefView in ScopusGoogle Scholar Di Gennaro et al., 2017 S.F. Di Gennaro,
    A. Matese, B. Gioli, P. Toscano, A. Zaldei, A. Palliotti, L. Genesio Multisensor
    approach to assess vineyard thermal dynamics combining high-resolution unmanned
    aerial vehicle (UAV) remote sensing and wireless sensor network (WSN) proximal
    sensing Sci. Hortic., 221 (2017), pp. 83-87, 10.1016/j.scienta.2017.04.024 View
    PDFView articleView in ScopusGoogle Scholar Döpper et al., 2020 V. Döpper, T.
    Gränzig, B. Kleinschmit, M. Förster Challenges in UAS-based TIR imagery processing:
    image alignment and uncertainty quantification Remote Sens., 12 (2020), p. 1552,
    10.3390/rs12101552 View in ScopusGoogle Scholar Drusch et al., 2017 M. Drusch,
    J. Moreno, U. Del Bello, R. Franco, Y. Goulas, A. Huth, S. Kraft, E. Middleton,
    F. Miglietta, G. Mohammed, L. Nedbal, U. Rascher, D. Schuttemeyer, W. Verhoef
    The fluorescence explorer mission concept-esa’s earth explorer 8 IEEE Trans. Geosci.
    Remote Sens., 55 (2017), pp. 1273-1284, 10.1109/TGRS.2016. 2621820 View in ScopusGoogle
    Scholar Duffour et al., 2015 C. Duffour, A. Olioso, J. Demarty, C. Van der Tol,
    J.P. Lagouarde An evaluation of scope: a tool to simulate the directional anisotropy
    of satellite-measured surface temperatures Remote Sens. Environ., 158 (2015),
    pp. 362-375, 10.1016/j.rse.2014.10.019 View PDFView articleView in ScopusGoogle
    Scholar Ekinzog et al., 2022 K. Ekinzog, M. Schlerf, M. Kraft, F.A.R. Werner,
    G. Rock, K. Mallick Revisiting crop water stress index based on potato field experiments
    in Northern Germany Agric. Water Manag., 269 (2022), p. 107664, 10.1016/j.agwat.2022.107664
    View in ScopusGoogle Scholar Fahad et al., 2017 S. Fahad, A.A. Bajwa, U. Nazir,
    S.A. Anjum, A. Farooq, A. Zohaib, S. Sadia, W. Nasim, S. Adkins, S. Saud, M.Z.
    Ihsan, H. Alharby, C. Wu, D. Wang, J. Huang Crop production under drought and
    heat stress: plant responses and management options Front. Plant Sci., 8 (2017),
    p. 1147, 10.3389/fpls.2017.01147 View in ScopusGoogle Scholar Fallon et al., 2020
    B. Fallon, A. Yang, C. Lapadat, I. Armour, J. Juzwik, R.A. Montgomery, J. Cavender-Bares
    Spectral differentiation of oak wilt from foliar fungal disease and drought is
    correlated with physiological changes Tree Physiol., 40 (2020), pp. 377-390, 10.1093/treephys/tpaa005
    View in ScopusGoogle Scholar FAO, 2021 FAO Sustainable Food And Home Food And
    Agriculture - PDF Free Download URL: https://zbook.org/sustainable-food-and-home-food-and-agriculture_MjUzODMw.html
    (2021) [Online; accessed 25. Feb. 2021] Google Scholar Fiehn, 2001 O. Fiehn Combining
    genomics, metabolome analysis, and biochemical modelling to understand metabolic
    networks Comp. Funct. Genom., 2 (2001), p. 155, 10.1002/cfg.82 View in ScopusGoogle
    Scholar Fisher et al., 2020 J.B. Fisher, B. Lee, A.J. Purdy, G.H. Halverson, M.B.
    Dohlen, K. Cawse-Nicholson, A. Wang, R.G. Anderson, B. Aragon, M.A. Arain, D.D.
    Baldocchi, J.M. Baker, H. Barral, C.J. Bernacchi, C. Bernhofer, S.C. Biraud, G.
    Bohrer, N. Brunsell, B. Cappelaere, S. Castro-Contreras, J. Chun, B.J. Conrad,
    E. Cremonese, J. Demarty, A.R. Desai, A. De Ligne, L. Foltýnová, M.L. Goulden,
    T.J. Griffis, T. Grünwald, M.S. Johnson, M. Kang, D. Kelbe, N. Kowalska, J.H.
    Lim, Maïnassara, M.F. McCabe, J.E.C. Missik, B.P. Mohanty, C.E. Moore, L. Morillas,
    R. Morrison, J.W. Munger, G. Posse, A.D. Richardson, E.S. Russell, Y. Ryu, A.
    Sanchez-Azofeifa, M. Schmidt, E. Schwartz, I. Sharp, L. Šigut, Y. Tang, G. Hulley,
    M. Anderson, C. Hain, A. French, E. Wood, S. Hook ECOSTRESS: NASA’s next generation
    mission to measure evapotranspiration from the international space station Water
    Resour. Res., 56 (2020), 10.1029/2019WR026058 e2019WR026058 Google Scholar Gago
    et al., 2015 J. Gago, C. Douthe, R. Coopman, P. Gallego, M. Ribas-Carbo, J. Flexas,
    J. Escalona, H. Medrano Uavs challenge to assess water stress for sustainable
    agriculture Agric. Water Manag., 153 (2015), pp. 9-19 URL: https://www.sciencedirect.com/science/article/pii/S0378377415000293
    https://doi.org/10.1016/j.agwat.2015.01.020 View PDFView articleView in ScopusGoogle
    Scholar Galieni et al., 2021 A. Galieni, N. D’Ascenzo, F. Stagnari, G. Pagnani,
    Q. Xie, M. Pisante Past and future of plant stress detection: an overview from
    remote sensing to positron emission tomography Front. Plant Sci., 11 (2021), 10.3389/fpls.2020.609155
    Google Scholar Gamon and Berry, 2012 J. Gamon, J. Berry Facultative and constitutive
    pigment effects on the photochemical reflectance index (pri) in sun and shade
    conifer needles Israel J. Plant Sci., 60 (2012), pp. 85-95, 10.1560/IJPS.60.1-2.85
    View in ScopusGoogle Scholar Gamon and Surfus, 1999 J. Gamon, J. Surfus Assessing
    leaf pigment content and activity with a reflectometer New Phytol., 143 (1999),
    pp. 105-117, 10.1046/j.1469-8137.1999.00424.x View in ScopusGoogle Scholar Gao
    et al., 2009 B.C. Gao, M.J. Montes, C.O. Davis, A.F. Goetz Atmospheric correction
    algorithms for hyperspectral remote sensing data of land and ocean Remote Sens.
    Environ., 113 (2009), pp. S17-S24, 10.1016/j.rse.2007.12.015 View PDFView articleView
    in ScopusGoogle Scholar Garbulsky et al., 2011 M.F. Garbulsky, J. Peñuelas, J.
    Gamon, Y. Inoue, I. Filella The photochemical reflectance index (PRI) and the
    remote sensing of leaf, canopy and ecosystem radiation use efficiencies: a review
    and metaanalysis Remote Sens. Environ., 115 (2011), pp. 281-297, 10.1016/j.rse.2010.08.023
    View PDFView articleView in ScopusGoogle Scholar Gella et al., 2021 G.W. Gella,
    W. Bijker, M. Belgiu Mapping crop types in complex farming areas using SAR imagery
    with dynamic time warping ISPRS J. Photogramm. Remote Sens., 175 (2021), pp. 171-183,
    10.1016/j.isprsjprs. 2021.03.004 View PDFView articleView in ScopusGoogle Scholar
    Gerhards et al., 2016 M. Gerhards, G. Rock, M. Schlerf, T. Udelhoven Water stress
    detection in potato plants using leaf temperature, emissivity, and reflectance
    Int. J. Appl. Earth Obs. Geoinf., 53 (2016), pp. 27-39, 10.1016/j.jag.2016.08.004
    View PDFView articleView in ScopusGoogle Scholar Gerhards et al., 2018 M. Gerhards,
    M. Schlerf, U. Rascher, T. Udelhoven, R. Juszczak, G. Alberti, F. Miglietta, Y.
    Inoue Analysis of airborne optical and thermal imagery for detection of water
    stress symptoms Remote Sens., 10 (2018), p. 1139, 10.3390/rs10071139 View in ScopusGoogle
    Scholar Gerhards et al., 2019 M. Gerhards, M. Schlerf, K. Mallick, T. Udelhoven
    Challenges and future perspectives of multi−/hyperspectral thermal infrared remote
    sensing for crop water-stress detection: a review Remote Sens., 11 (2019), 10.3390/rs11101240
    URL: https://www.mdpi.com/2072-4292/11/10/1240 Google Scholar Gewali et al., 2019
    U.B. Gewali, S.T. Monteiro, E. Saber Machine learning based hyperspectral image
    analysis: A survey arXiv:1802.08701 (2019) Google Scholar Gholizadeh and Kopacková,
    2019 A. Gholizadeh, V. Kopacková Detecting vegetation stress as a soil contamination
    proxy: a review of optical proximal and remote sensing techniques Int. J. Environ.
    Sci. Technol., 16 (2019), pp. 2511-2524, 10.1007/s13762-019-02310-w Google Scholar
    Gitelson, 2020 A. Gitelson Towards a generic approach to remote non-invasive estimation
    of foliar carotenoid-to-chlorophyll ratio J. Plant Physiol., 252 (2020), Article
    153227, 10.1016/j.jplph.2020.153227 arXiv:32683162 View PDFView articleView in
    ScopusGoogle Scholar Gold et al., 2020 K.M. Gold, P.A. Townsend, A. Chlus, I.
    Herrmann, J.J. Couture, E.R. Larson, A.J. Gevens Hyperspectral measurements enable
    pre-symptomatic detection and differentiation of contrasting physiological effects
    of late blight and early blight in potato Remote Sens., 12 (2020), p. 286, 10.3390/rs12020286
    View in ScopusGoogle Scholar Gomiero et al., 2011 T. Gomiero, D. Pimentel, M.G.
    Paoletti Environmental impact of different agricultural management practices:
    conventional vs. organic agriculture Crit. Rev. Plant Sci., 30 (2011), pp. 95-124,
    10.1080/07352689.2011.554355 View in ScopusGoogle Scholar Gonzalez Toro and Tsourdos,
    2021 F. Gonzalez Toro, A. Tsourdos UAV Sensors for Environmental Monitoring -
    CORE URL: https://core.ac.uk/display/286407874 (2021) [Online; accessed 9. Oct.
    2021] Google Scholar Gonzalez-Dugo et al., 2014 V. Gonzalez-Dugo, P.J. Zarco-Tejada,
    E. Fereres Applicability and limitations of using the crop water stress index
    as an indicator of water deficits in citrus orchards Agric. For. Meteorol., 198–199
    (2014), pp. 94-104, 10.1016/j.agrformet.2014.08.003 View PDFView articleView in
    ScopusGoogle Scholar Goulas et al., 2017 Y. Goulas, A. Fournier, F. Daumard, S.
    Champagne, A. Ounis, O. Marloie, I. Moya Gross primary production of a wheat canopy
    relates stronger to far red than to red solar-induced chlorophyll fluorescence
    Remote Sens., 9 (2017), p. 97, 10.3390/rs9010097 Google Scholar Govender et al.,
    2009 M. Govender, P.J. Govender, I.M. Weiersbye, E. Witkowski, F. Ahmed Review
    of commonly used remote sensing and ground-based technologies to measure plant
    water stress 1 (2009), p. 35, 10.4314/wsa.v35i5.49201 Google Scholar Grieves and
    Vickers, 2016 M. Grieves, J. Vickers Digital twin: mitigating unpredictable, undesirable
    emergent behavior in complex systems Transdisciplinary Perspectives on Complex
    Systems: New Findings and Approaches, Springer, Cham, Switzerland (2016), pp.
    85-113, 10.1007/978-3-319-38756-7_4 View in ScopusGoogle Scholar Guan et al.,
    2017 K. Guan, J. Wu, J.S. Kimball, M.C. Anderson, S. Frolking, B. Li, C.R. Hain,
    D.B. Lobell The shared and unique values of optical, fluorescence, thermal and
    microwave satellite data for estimating large-scale crop yields Remote Sens. Environ.,
    199 (2017), pp. 333-349 URL: https://www.sciencedirect.com/science/article/pii/S0034425717303024
    https://doi.org/10.1016/j.rse.2017.06.043 View PDFView articleView in ScopusGoogle
    Scholar Guanter et al., 2014 L. Guanter, Y. Zhang, M. Jung, J. Joiner, M. Voigt,
    J.A. Berry, C. Frankenberg, A.R. Huete, P. Zarco-Tejada, J.E. Lee, M.S. Moran,
    G. Ponce-Campos, C. Beer, G. Camps-Valls, N. Buchmann, D. Gianelle, K. Klumpp,
    A. Cescatti, J.M. Baker, T.J. Griffis Global and time-resolved monitoring of crop
    photosynthesis with chlorophyll fluorescence Proc. Natl. Acad. Sci., 111 (2014),
    pp. E1327-E1333, 10.1073/pnas.1320008111 View in ScopusGoogle Scholar Guanter
    et al., 2015 L. Guanter, H. Kaufmann, K. Segl, S. Foerster, C. Rogass, S. Chabrillat,
    T. Kuester, A. Hollstein, G. Rossner, C. Chlebek, C. Straif, S. Fischer, S. Schrader,
    T. Storch, U. Heiden, A. Mueller, M. Bachmann, H. Muhle, R. Muller, M. Habermeyer,
    A. Ohndorf, J. Hill, H. Bud-denbaum, P. Hostert, S. van der Linden, P.J. Leitao,
    A. Rabe, R. Doerffer, H. Krasemann, H. Xi, W. Mauser, T. Hank, M. Locherer, M.
    Rast, K. Staenz, B. Sang The EnMAP spaceborne imaging spectroscopy mission for
    Earth observation Remote Sens., 7 (2015), p. 8830, 10.3390/rs70708830 View in
    ScopusGoogle Scholar Gull et al., 2019 A. Gull, A. Lone, N. Wani Biotic and Abiotic
    Stresses in Plants (2019), 10.5772/intechopen.85832 Google Scholar Han et al.,
    2018 M. Han, H. Zhang, K.C. DeJonge, L.H. Comas, S. Gleason Comparison of three
    crop water stress index models with sap flow measurements in maize Agric. Water
    Manag., 203 (2018), pp. 366-375 URL: https://linkinghub.elsevier.com/retrieve/pii/S0378377418301252
    https://doi.org/10.1016/j.agwat.2018.02.030 View PDFView articleView in ScopusGoogle
    Scholar Hank et al., 2015 T.B. Hank, H. Bach, W. Mauser Using a remote sensing-supported
    hydro-agroecological model for field-scale simulation of heterogeneous crop growth
    and yield: application for wheat in Central Europe Remote Sens., 7 (2015), pp.
    3934-3965, 10.3390/rs70403934 View in ScopusGoogle Scholar Hazaymeh and Hassan,
    2017 K. Hazaymeh, Q.K. Hassan A remote sensing-based agricultural drought indicator
    and its implementation over a semi-arid region, Jordan J. Arid Land, 9 (2017),
    pp. 319-330, 10.1007/s40333-017-0014-6 View in ScopusGoogle Scholar Hendry and
    Price, 1993 G. Hendry, A. Price Stress indicators chlorophylls and carotenoids,
    methods in comparative plant ecology (1993) Google Scholar Hernández-Clemente
    et al., 2017 R. Hernández-Clemente, P.R. North, A. Hornero, P.J. Zarco-Tejada
    Assessing the effects of forest health on sun-induced chlorophyll fluorescence
    using the fluorflight 3-d radiative transfer model to account for forest structure
    Remote Sens. Environ., 193 (2017), pp. 165-179, 10.1016/j.rse.2017.02.012 View
    PDFView articleView in ScopusGoogle Scholar Hernández-Clemente et al., 2019 R.
    Hernández-Clemente, A. Hornero, M. Mottus, J. Penuelas, V. González- Dugo, J.C.
    Jiménez, L. Suárez, L. Alonso, P.J. Zarco-Tejada Early diagnosis of vegetation
    health from high-resolution hyperspectral and thermal imagery: lessons learned
    from empirical relationships and radiative transfer modelling Curr. Forestry Rep.,
    5 (2019), pp. 169-183, 10.1007/s40725-019-00096-1 View in ScopusGoogle Scholar
    Herrmann and Berger, 2021 I. Herrmann, K. Berger Remote and proximal assessment
    of plant traits Remote Sens., 13 (2021), p. 1893, 10.3390/rs13101893 View in ScopusGoogle
    Scholar Herrmann et al., 2010 I. Herrmann, A. Karnieli, D.J. Bonfil, Y. Cohen,
    V. Alchanatis SWIR-based spectral indices for assessing nitrogen content in potato
    fields Int. J. Remote Sens., 31 (2010), pp. 5127-5143, 10.1080/01431160903283892
    View in ScopusGoogle Scholar Herrmann et al., 2017 I. Herrmann, M. Berenstein,
    T. Paz-Kagan, A. Sade, A. Karnieli Spectral assessment of two-spotted spider mite
    damage levels in the leaves of greenhouse-grown pepper and bean Biosyst. Eng.,
    157 (2017), pp. 72-85, 10.1016/j.biosystemseng.2017.02.008 View PDFView articleView
    in ScopusGoogle Scholar Herrmann et al., 2018 I. Herrmann, S.K. Vosberg, P. Ravindran,
    A. Singh, H.X. Chang, M.I. Chil-vers, S.P. Conley, P.A. Townsend Leaf and canopy
    level detection of fusarium virguliforme (sudden death syndrome) in soybean Remote
    Sens., 10 (2018), p. 426, 10.3390/rs10030426 View in ScopusGoogle Scholar Herrmann
    et al., 2020 I. Herrmann, E. Bdolach, Y. Montekyo, S. Rachmilevitch, P.A. Townsend,
    A. Karnieli Assessment of maize yield and phenology by drone-mounted superspectral
    camera Precis. Agric., 21 (2020), pp. 51-76, 10.1007/s11119–019–09659-5 View in
    ScopusGoogle Scholar Hoffmann et al., 2016 H. Hoffmann, R. Jensen, A. Thomsen,
    H. Nieto, J. Rasmussen, T. Friborg Crop water stress maps for an entire growing
    season from visible and thermal UAV imagery Biogeosciences, 13 (2016), pp. 6545-6563
    URL: https://bg.copernicus.org/articles/13/6545/2016/ https://doi.org/10.5194/bg-13-6545-2016
    CrossRefView in ScopusGoogle Scholar Holopainen and Gershenzon, 2010 J.K. Holopainen,
    J. Gershenzon Multiple stress factors and the emission of plant vocs Trends Plant
    Sci., 15 (2010), pp. 176-184, 10.1016/j.tplants.2010.01.006 View PDFView articleView
    in ScopusGoogle Scholar Houborg et al., 2015 R. Houborg, J. Fisher, A. Skidmore
    Advances in remote sensing of vegetation function and traits Int. J. Appl. Earth
    Obs. Geoinf., 43 (2015), pp. 1-6, 10.1016/j.jag.2015.06.001 View PDFView articleView
    in ScopusGoogle Scholar Huang et al., 2019 J. Huang, J.L. Gómez-Dans, H. Huang,
    H. Ma, Q. Wu, P.E. Lewis, S. Liang, Z. Chen, J.H. Xue, Y. Wu, F. Zhao, J. Wang,
    X. Xie Assimilation of remote sensing into crop growth models: current status
    and perspectives Agric. For. Meteorol., 276–277 (2019), Article 107609, 10.1016/j.agrformet.2019.06.008
    View PDFView articleView in ScopusGoogle Scholar Idso et al., 1981 S.B. Idso,
    R.D. Jackson, P.J. Pinter, R.J. Reginato, J.L. Hatfield Normalizing the stress-degree-day
    parameter for environmental variability Agric. Meteorol., 24 (1981), pp. 45-55,
    10.1016/0002-1571(81) 90032-7 View PDFView articleView in ScopusGoogle Scholar
    Ihuoma and Madramootoo, 2017 S.O. Ihuoma, C.A. Madramootoo Recent advances in
    crop water stress detection Comput. Electron. Agric., 141 (2017), pp. 267-275,
    10.1016/j.compag.2017.07.026 View PDFView articleView in ScopusGoogle Scholar
    Inoue et al., 2018 Y. Inoue, R. Darvishzadeh, A. Skidmore Hyperspectral assessment
    of ecophysiological functioning for diagnostics of crops and vegetation Biophysical
    and Biochemical Characterization and Plant Species Studies, CRC Press, Boca Raton,
    FL, USA (2018), pp. 25-71, 10.1201/9780429431180-2 Google Scholar Jackson et al.,
    1981 R.D. Jackson, S.B. Idso, R.J. Reginato, P.J. Pinter Canopy temperature as
    a crop water stress indicator Water Resour. Res., 17 (1981), pp. 1133-1138, 10.1029/wr017i004p01133
    View in ScopusGoogle Scholar Jackson et al., 1988 R.D. Jackson, W.P. Kustas, B.J.
    Choudhury A reexamination of the crop water stress index Irrig. Sci., 9 (1988),
    pp. 309-317, 10.1007/BF00296705 View in ScopusGoogle Scholar Jahns and Holzwarth,
    2012 P. Jahns, A.R. Holzwarth The role of the xanthophyll cycle and of lutein
    in photoprotection of photosystem II Biochim. Biophys. Acta (BBA) - Bioenergetics,
    1817 (2012), pp. 182-193, 10.1016/j.bbabio.2011.04.012 View PDFView articleView
    in ScopusGoogle Scholar Jain et al., 2019 A. Jain, S. Sarsaiya, Q. Wu, Y. Lu,
    J. Shi A review of plant leaf fungal diseases and its environment speciation Bioengineered,
    10 (2019), pp. 409-424, 10.1080/21655979.2019.1649520 View in ScopusGoogle Scholar
    Jiao et al., 2021 W. Jiao, L. Wang, M.F. McCabe Multi-sensor remote sensing for
    drought characterization: current status, opportunities and a roadmap for the
    future Remote Sens. Environ., 256 (2021), Article 112313, 10.1016/j.rse.2021.112313
    View PDFView articleView in ScopusGoogle Scholar Jin et al., 2018 X. Jin, L. Kumar,
    Z. Li, H. Feng, X. Xu, G. Yang, J. Wang A review of data assimilation of remote
    sensing and crop models Eur. J. Agron., 92 (2018), pp. 141-152, 10.1016/j.eja.2017.11.002
    View PDFView articleView in ScopusGoogle Scholar Joalland et al., 2018 S. Joalland,
    C. Screpanti, H.V. Varella, M. Reuther, M. Schwind, C. Lang, A. Walter, F. Liebisch
    Aerial and ground based sensing of tolerance to beet cyst nematode in sugar beet
    Remote Sens., 10 (2018), p. 787, 10.3390/rs10050787 View in ScopusGoogle Scholar
    Jonard et al., 2020 F. Jonard, S. De Cannière, N. Brüggemann, P. Gentine, D.J.S.
    Gianotti, G. Lobet, D.G. Miralles, C. Montzka, B.R. Pagán, U. Rascher, H. Vereecken
    Value of sun-induced chlorophyll fluorescence for quantifying hydrological states
    and fluxes: current status and challenges Agric. For. Meteorol., 291 (2020), Article
    108088, 10.1016/j.agrformet.2020.108088 View PDFView articleView in ScopusGoogle
    Scholar Jones and Jones, 1989 H.G. Jones, M.B. Jones Plants under stress. Introduction:
    some terminology and common mechanisms. Seminar series - Society for Experimental
    Biology URL: https://agris.fao.org/agris-search/search.do?recordID=US201302682914
    (1989) Google Scholar Jones and Vaughan, 2010 H. Jones, R. Vaughan Remote Sensing
    of Vegetation: Principles, Techniques, and Applications OUP Oxford (2010) URL:
    https://books.google.it/books?id=sTmcAQAAQBAJ Google Scholar Jones et al., 2003
    J.W. Jones, G. Hoogenboom, C.H. Porter, K.J. Boote, W.D. Batchelor, L.A. Hunt,
    P.W. Wilkens, U. Singh, A.J. Gijsman, J.T. Ritchie The DSSAT cropping system model
    Eur. J. Agron., 18 (2003), pp. 235-265, 10.1016/S1161–0301(02)00107–7 View PDFView
    articleView in ScopusGoogle Scholar Kasahara et al., 2002 M. Kasahara, T. Kagawa,
    K. Oikawa, N. Suetsugu, M. Miyao, M. Wada Chloroplast avoidance movement reduces
    photodamage in plants Nature, 420 (2002), pp. 829-832, 10.1038/nature01213 View
    in ScopusGoogle Scholar Kessler, 2001 A. Kessler Defensive function of herbivore-induced
    plant volatile emissions in nature Science, 291 (2001), pp. 2141-2144, 10.1126/science.291.5511.2141
    View in ScopusGoogle Scholar Kim and Glenn, 2017 J.Y. Kim, D.M. Glenn Multi-modal
    sensor system for plant water stress assessment Comput. Electron. Agric., 141
    (2017), pp. 27-34, 10.1016/j.compag.2017.07.009 View PDFView articleGoogle Scholar
    Knipling, 1970 E.B. Knipling Physical and physiological basis for the reflectance
    of visible and near-infrared radiation from vegetation Remote Sens. Environ.,
    1 (1970), pp. 155-159, 10.1016/S0034-4257(70)80021-9 View PDFView articleView
    in ScopusGoogle Scholar Knipper et al., 2019 K.R. Knipper, W.P. Kustas, M.C. Anderson,
    M.M. Alsina, C.R. Hain, J.G. Alfieri, J.H. Prueger, F. Gao, L.G. McKee, L.A. Sanchez
    Using high-spatiotemporal thermal satellite ET retrievals for operational water
    use and stress monitoring in a California vineyard Remote Sens., 11 (2019), 10.3390/rs11182124
    Google Scholar Kranner et al., 2010 I. Kranner, F.V. Minibayeva, R.P. Beckett,
    C.E. Seal What is stress? Concepts, definitions and applications in seed science
    New Phytol., 188 (2010), pp. 655-673 URL: https://doi.org/10.1111/j.1469-8137.2010.03461.x
    CrossRefView in ScopusGoogle Scholar Larcher, 2003 W. Larcher Physiological Plant
    Ecology: Ecophysiology and Stress Physiology of Functional Groups Springer-Verlag,
    Berlin Heidelberg (2003) URL: https://www.springer.com/gp/book/9783540435167 https://doi.org/10.1086/419487
    Google Scholar Lassalle, 2021 G. Lassalle Monitoring natural and anthropogenic
    plant stressors by hyperspectral remote sensing: recommendations and guidelines
    based on a meta-review Sci. Total Environ., 788 (2021), Article 147758, 10.1016/j.scitotenv.2021.147758
    View PDFView articleView in ScopusGoogle Scholar Lebourgeois et al., 2012 V. Lebourgeois,
    A. Bégué, S. Labbé, M. Houlès, J.F. Martiné A light-weight multi-spectral aerial
    imaging system for nitrogen crop monitoring Precis. Agric., 13 (2012), pp. 525-541,
    10.1007/s11119-012-9262-9 View in ScopusGoogle Scholar Li et al., 2013 Z.L. Li,
    B.H. Tang, H. Wu, H. Ren, G. Yan, Z. Wan, I.F. Trigo, J.A. Sobrino Satellite-derived
    land surface temperature: Current status and perspectives Remote Sens. Environ.,
    131 (2013), pp. 14-37, 10.1016/j.rse.2012.12.008 View PDFView articleView in ScopusGoogle
    Scholar Lichtenthaler, 1996 H.K. Lichtenthaler Vegetation stress: an introduction
    to the stress concept in plants J. Plant Physiol., 148 (1996), pp. 4-14, 10.1016/S0176–1617(96)80287–2
    View PDFView articleGoogle Scholar Lichtenthaler et al., 1998 H.K. Lichtenthaler,
    O. Wenzel, C. Buschmann, A. Gitelson Plant stress by reflectance and fluorescence
    Ann. N. Y. Acad. Sci., 851 (1998), pp. 271-285 URL: https://doi.org/10.1111/j.1749-6632.1998.tb09002.x
    CrossRefView in ScopusGoogle Scholar Linke et al., 2008 R. Linke, K. Richter,
    J. Haumann, W. Schneider, P. Weihs Occurrence of repeated drought events: can
    repetitive stress situations and recovery from drought be traced with leaf reflectance?
    Period. Biol., 110 (2008), pp. 219-229 URL: https://hrcak.srce.hr/32569 View in
    ScopusGoogle Scholar Liu et al., 2019 J. Liu, T. Wang, A.K. Skidmore, S. Jones,
    M. Heurich, B. Beudert, J. Premier Comparison of terrestrial lidar and digital
    hemispherical photography for estimating leaf angle distribution in european broadleaf
    beech forests ISPRS J. Photogramm. Remote Sens., 158 (2019), pp. 76-89, 10.3390/rs13163325
    View PDFView articleGoogle Scholar Liu et al., 2020 X. Liu, L. Liu, J. Hu, J.
    Guo, S. Du Improving the potential of red sif for estimating gpp by downscaling
    from the canopy level to the photosystem level Agric. For. Meteorol., 281 (2020),
    p. 107846 URL: https://www.sciencedirect.com/science/article/pii/S0168192319304629
    https://doi.org/10.1016/j.agrformet.2019.107846 View PDFView articleView in ScopusGoogle
    Scholar Llanes et al., 2018 A. Llanes, A. Andrade, S. Alemano, V. Luna Metabolomic
    approach to understand plant adaptations to water and salt stress Plant Metabolites
    and Regulation Under Environmental Stress, Academic Press, Cambridge, MA, USA
    (2018), pp. 133-144, 10.1016/B978–0–12-812689-9.00006-6 View PDFView articleView
    in ScopusGoogle Scholar Loizzo et al., 2019 R. Loizzo, M. Daraio, R. Guarini,
    F. Longo, R. Lorusso, L. Dini, E. Lopinto Prisma mission status and perspective
    IGARSS 2019–2019 IEEE International Geoscience and Remote Sensing Symposium, IEEE
    (2019), pp. 4503-4506, 10.1109/IGARSS.2019.8899272 View in ScopusGoogle Scholar
    Lombardozzi et al., 2020 D.L. Lombardozzi, Y. Lu, P.J. Lawrence, D.M. Lawrence,
    S. Swenson, K.W. Oleson, W.R. Wieder, E.A. Ainsworth Simulating agriculture in
    the community land model version 5 J. Geophys. Res. Biogeosci., 125 (2020) e2019JG005529
    Google Scholar Machwitz et al., 2018 M. Machwitz, E. Haß, J. Junk, T. Udelhoven,
    M. Schlerf CropGIS – A web application for the spatial and temporal visualization
    of past, present and future crop biomass development Comput. Electron. Agric.,
    161 (2018), 10.1016/j.compag.2018.04.026 Google Scholar Machwitz et al., 2021
    M. Machwitz, R. Pieruschka, K. Berger, M. Schlerf, H. Aasen, S. Fahrner, J. Jiménez-Berni,
    F. Baret, U. Rascher Bridging the gap between remote sensing and plant phenotyping—challenges
    and opportunities for the next generation of sustainable agriculture Front. Plant
    Sci., 0 (2021), 10.3389/fpls.2021.749374 Google Scholar Madani et al., 2019 B.
    Madani, A. Mirshekari, Y. Imahori Chapter 19 - Physiological responses to stress
    E.M. Yahia (Ed.), Postharvest Physiology and Biochemistry of Fruits and Vegetables,
    Woodhead Publishing (2019), pp. 405-423 URL: https://www.sciencedirect.com/science/article/pii/B9780128132784000208
    https://doi.org/10.1016/B978-0-12-813278-4.00020-8 View PDFView articleGoogle
    Scholar Madec et al., 2017 S. Madec, F. Baret, B. de Solan, S. Thomas, D. Dutartre,
    S. Jezequel, M. Hemmerlé, G. Colombeau, A. Comar High-throughput phenotyping of
    plant height: comparing unmanned aerial vehicles and ground LiDAR estimates Front.
    Plant Sci., 8 (2017), 10.3389/fpls.2017.02002 Google Scholar Maes and Steppe,
    2012 W.H. Maes, K. Steppe Estimating evapotranspiration and drought stress with
    ground-based thermal remote sensing in agriculture: a review J. Exp. Bot., 63
    (2012), pp. 4671-4712, 10.1093/jxb/ers165 View in ScopusGoogle Scholar Maes and
    Steppe, 2019 W. Maes, K. Steppe Perspectives for remote sensing with unmanned
    aerial vehicles in precision agriculture Trends Plant Sci., 24 (2019), pp. 152-164
    URL: https://biblio.ugent.be/publication/8642827 View PDFView articleView in ScopusGoogle
    Scholar Magney et al., 2019 T.S. Magney, C. Frankenberg, P. Köhler, G. North,
    T.S. Davis, C. Dold, D. Dutta, J.B. Fisher, K. Grossmann, A. Harrington, J. Hatfield,
    J. Stutz, Y. Sun, A. Porcar-Castell Disentangling changes in the spectral shape
    of chlorophyll fluorescence: implications for remote sensing of photosynthesis
    J. Geophys. Res. Biogeosci., 124 (2019), pp. 1491-1507, 10.1029/2019JG005029 View
    in ScopusGoogle Scholar Mahajan et al., 2021 G.R. Mahajan, B. Das, D. Murgaokar,
    I. Herrmann, K. Berger, R.N. Sahoo, K. Patel, A. Desai, S. Morajkar, R.M. Kulkarni
    Monitoring the foliar nutrients status of mango using spectroscopy-based spectral
    indices and PLSR-combined machine learning models Remote Sens., 13 (2021), p.
    641, 10.3390/rs13040641 Google Scholar Mahlein, 2016 A.K. Mahlein Plant Disease
    Detection by Imaging Sensors – Parallels and Specific Demands for Precision Agriculture
    and Plant Phenotyping. Plant Dis (2016), 10.1094/PDIS-03-15-0340-FE Google Scholar
    Mahlein et al., 2019 A.K. Mahlein, E. Alisaac, A. Al Masri, J. Behmann, H.W. Dehne,
    E.C. Oerke Comparison and combination of thermal, fluorescence, and hyperspectral
    imaging for monitoring fusarium head blight of wheat on Spikelet scale Sensors,
    19 (2019), p. 2281, 10.3390/s19102281 View in ScopusGoogle Scholar Malenovský
    et al., 2012 Z. Malenovský, H. Rott, J. Cihlar, M. Schaepman, J. Garcia, C.A-Santos,
    G, R. Fernandes, M. Berger Sentinels for science: potential of Sentinel-1, −2,
    and −3 missions for scientific observations of ocean, cryosphere, and land Remote
    Sens. Environ., 120 (2012), pp. 91-101 View PDFView articleView in ScopusGoogle
    Scholar McNally et al., 2017 A. McNally, K. Arsenault, S. Kumar, S. Shukla, P.
    Peterson, S. Wang, C. Funk, C.D. Peters-Lidard, J.P. Verdin A land data assimilation
    system for sub-Saharan Africa food and water security applications Scientific
    Data, 4 (2017), 10.1038/sdata.2017.12 Google Scholar Meerdink et al., 2019 S.
    Meerdink, D. Roberts, G. Hulley, P. Gader, J. Pisek, K. Adamson, J. King, S.J.
    Hook Plant species’ spectral emissivity and temperature using the hyperspectral
    thermal emission spectrometer (HyTES) sensor Remote Sens. Environ., 224 (2019),
    pp. 421-435, 10.1016/j.rse.2019.02.009 View PDFView articleView in ScopusGoogle
    Scholar Meroni et al., 2009 M. Meroni, M. Rossini, L. Guanter, L. Alonso, U. Rascher,
    R. Colombo, J. Moreno Remote sensing of solar-induced chlorophyll fluorescence:
    review of methods and applications Remote Sens. Environ., 113 (2009), pp. 2037-2051
    URL: http://linkinghub.elsevier.com/retrieve/pii/S003442570900162Xhttp://www.sciencedirect.com/science/article/pii/S003442570900162X
    https://doi.org/10.1016/j.rse.2009.05.003 View PDFView articleView in ScopusGoogle
    Scholar Messina and Modica, 2020 G. Messina, G. Modica Applications of UAV thermal
    imagery in precision agriculture: state of the art and future research outlook
    Remote Sens., 12 (2020), p. 1491, 10.3390/rs12091491 View in ScopusGoogle Scholar
    Meza-Canales et al., 2017 I.D. Meza-Canales, S. Meldau, J.A. Zavala, I.T. Baldwin
    Herbivore perception decreases photosynthetic carbon assimilation and reduces
    stomatal conductance by engaging 12-oxo-phytodienoic acid, mitogen- activated
    protein kinase 4 and cytokinin perception Plant Cell Environ., 40 (2017), pp.
    1039-1056, 10.1111/pce.12874 View in ScopusGoogle Scholar Migliavacca et al.,
    2017 M. Migliavacca, O. Perez-Priego, M. Rossini, T.S. El-Madany, G. Moreno, C.
    Van der Tol, U. Rascher, A. Berninger, V. Bessenbacher, A. Burkart, A. Carrara,
    F. Fava, J.H. Guan, T.W. Hammer, K. Henkel, E. Juarez-Alcalde, T. Julitta, O.
    Kolle, M.P. Martin, T. Musavi, J. Pacheco-Labrador, A. Pérez-Burgueño, T. Wutzler,
    S. Zaehle, M. Reichstein Plant functional traits and canopy structure control
    the relationship between photosynthetic co2 uptake and far-red sun-induced fluorescence
    in a mediterranean grassland under different nutrient availability New Phytol.,
    214 (2017), pp. 1078-1091 URL: https://doi.org/10.1111/nph.14437 CrossRefView
    in ScopusGoogle Scholar Mladenova et al., 2017 I.E. Mladenova, J.D. Bolten, W.T.
    Crow, M.C. Anderson, C.R. Hain, D.M. Johnson, R. Mueller Intercomparison of soil
    moisture, evaporative stress, and vegetation indices for estimating corn and soybean
    yields over the US IEEE J. Select. Top. Appl. Earth Observ. Remote Sens., 10 (2017),
    pp. 1328-1343, 10.1109/JSTARS.2016.2639338 View in ScopusGoogle Scholar Mohammed
    et al., 2019 G.H. Mohammed, R. Colombo, E.M. Middleton, U. Rascher, C. Van der
    Tol, L. Nedbal, Y. Goulas, O. Pérez-Priego, A. Damm, M. Meroni, J. Joiner, S.
    Cogliati, W. Verhoef, Z. Malenovský, J.P. Gastellu-Etchegorry, J.R. Miller, L.
    Guanter, J. Moreno, I. Moya, J.A. Berry, C. Franken-Berg, P.J. Zarco-Tejada Remote
    sensing of solar-induced chlorophyll fluorescence (sif) in vegetation: 50 years
    of progress Remote Sens. Environ., 231 (2019), 10.1016/j.rse.2019.04.030 Google
    Scholar Moncholi-Estornell et al., 2022 A. Moncholi-Estornell, S. Van Wittenberghe,
    M.P. Cendrero-Mateo, L. Alonso, Z. Malenovský, J. Moreno Impact of structural,
    photochemical and instrumental effects on leaf and canopy reflectance variability
    in the 500–600 nm range Remote Sens., 14 (2022), pp. 56-70, 10.3390/rs14010056
    View in ScopusGoogle Scholar Moran et al., 1994 M.S. Moran, T.R. Clarke, Y. Inoue,
    A. Vidal Estimating crop water deficit using the relation between surface-air
    temperature and spectral vegetation index Remote Sens. Environ., 49 (1994), pp.
    246-263, 10.1016/0034–4257(94)90020–5 View PDFView articleView in ScopusGoogle
    Scholar Moshou et al., 2014 D. Moshou, X.E. Pantazi, D. Kateris, I. Gravalos Water
    stress detection based on optical multisensor fusion with a least squares support
    vector machine classifier Biosyst. Eng., 117 (15–22) (2014), 10.1016/j.biosystemseng.2013.07.008
    4th International Workshop on Computer Image Analysis in Agriculture, held at
    CIGR- AgEng, Valencia, SPAIN, JUL 08–12, 2012 Google Scholar Moulin et al., 1998
    S. Moulin, A. Bondeau, R. Delecolle Combining agricultural crop models and satellite
    observations: From field to regional scales Int. J. Remote Sens., 19 (1998), pp.
    1021-1036, 10.1080/014311698215586 View in ScopusGoogle Scholar Mousivand et al.,
    2015 A. Mousivand, M. Menenti, B. Gorte, W. Verhoef Multi-temporal, multi-sensor
    retrieval of terrestrial vegetation properties from spectral- directional radiometric
    data Remote Sens. Environ., 158 (2015), pp. 311-330 View PDFView articleView in
    ScopusGoogle Scholar Mueller et al., 2012 N.D. Mueller, J.S. Gerber, M. Johnston,
    D.K. Ray, N. Ramankutty, J.A. Foley Closing yield gaps through nutrient and water
    management Nature, 490 (2012), pp. 254-257 CrossRefView in ScopusGoogle Scholar
    Navarro et al., 2016 A. Navarro, J. Rolim, I. Miguel, J. Catalao, J. Silva, M.
    Painho, Z. Vekerdy Crop monitoring based on spot-5 take-5 and sentinel-1a data
    for the estimation of crop water requirements Remote Sens., 8 (2016), p. 525 CrossRefView
    in ScopusGoogle Scholar Neinavaz et al., 2016 E. Neinavaz, R. Darvishzadeh, A.K.
    Skidmore, T.A. Groen Measuring the response of canopy emissivity spectra to leaf
    area index variation using thermal hyperspectral data Int. J. Appl. Earth Obs.
    Geoinf., 53 (2016), pp. 40-47, 10.1016/j.jag.2016.08.002 View PDFView articleView
    in ScopusGoogle Scholar Neupane and Baysal-Gurel, 2021 K. Neupane, F. Baysal-Gurel
    Automatic identification and monitoring of plant diseases using unmanned aerial
    vehicles: a review Remote Sens., 13 (2021), p. 3841, 10.3390/rs13193841 View in
    ScopusGoogle Scholar Ni et al., 2015 Z. Ni, Z. Liu, H. Huo, Z.L. Li, F. Nerry,
    Q. Wang, X. Li Early water stress detection using leaf-level measurements of chlorophyll
    fluorescence and temperature data Remote Sens., 7 (2015), pp. 3232-3249 URL: https://www.mdpi.com/2072-4292/7/3/3232
    https://doi.org/10.3390/rs70303232 CrossRefView in ScopusGoogle Scholar Norman
    and Becker, 1995 J.M. Norman, F. Becker Terminology in thermal infrared remote
    sensing of natural surfaces Agric. For. Meteorol., 77 (1995), pp. 153-166, 10.1016/0168–1923(95)02259-Z
    View PDFView articleView in ScopusGoogle Scholar Pacheco-Labrador et al., 2019a
    J. Pacheco-Labrador, A. Hueni, L. Mihai, K. Sakowska, T. Julitta, J. Kuusk, D.
    Sporea, L. Alonso, A. Burkart, M.P. Cendrero-Mateo, H. Aasen, Y. Goulas, A. Mac
    Arthur Sun-Induced chlorophyll fluorescence I: instrumental considerations for
    proximal spectro- radiometers Remote Sens., 11 (2019), p. 960, 10.3390/rs11080960
    View in ScopusGoogle Scholar Pacheco-Labrador et al., 2019b J. Pacheco-Labrador,
    O. Perez-Priego, T.S. El-Madany, T. Julitta, M. Rossini, J. Guan, G. Moreno, N.
    Carvalhais, M.P. Martín, R. Gonzalez-Cascon, O. Kolle, M. Reischtein, C. van der
    Tol, A. Carrara, D. Martini, T.W. Hammer, H. Moossen, M. Migliavacca Multiple-constraint
    inversion of SCOPE. Evaluating the potential of GPP and SIF for the retrieval
    of plant functional traits Remote Sens. Environ., 234 (2019), p. 111362 URL: https://linkinghub.elsevier.com/retrieve/pii/S0034425719303815
    https://doi.org/10.1016/j.rse.2019.111362 View PDFView articleView in ScopusGoogle
    Scholar Pacheco-Labrador et al., 2021 J. Pacheco-Labrador, T.S. El-Madany, C.
    Van der Tol, M.P. Martin, R. Gonzalez-Cascon, O. Perez-Priego, J. Guan, G. Moreno,
    A. Carrara, M. Reichstein, M. Migliavacca senSCOPE: Modeling mixed canopies combining
    green and brown senesced leaves. Evaluation in a Mediterranean Grassland Remote
    Sens. Environ., 257 (2021), Article 112352, 10.1016/j.rse.2021.112352 View PDFView
    articleView in ScopusGoogle Scholar Panigada et al., 2014 C. Panigada, M. Rossini,
    M. Meroni, C. Cilia, L. Busetto, S. Amaducci, M. Boschetti, S. Cogliati, V. Picchi,
    F. Pinto, A. Marchesi, R. Colombo Fluorescence, PRI and canopy temperature for
    water stress detection in cereal crops Int. J. Appl. Earth Obs. Geoinf., 30 (2014),
    pp. 167-178, 10.1016/j.jag.2014.02.002 View PDFView articleView in ScopusGoogle
    Scholar Parkash and Singh, 2020 V. Parkash, S. Singh A review on potential plant-based
    water stress indicators for vegetable crops Sustainability, 12 (2020), 10.3390/su12103945
    URL: https://www.mdpi.com/2071-1050/12/10/3945 Google Scholar Peng et al., 2018
    B. Peng, K. Guan, M. Chen, D.M. Lawrence, Y. Pokhrel, A. Suyker, T. Arkebauer,
    Y. Lu Improving maize growth processes in the community land model: Implementation
    and evaluation Agric. For. Meteorol., 250–251 (2018), pp. 64-89 URL: https://www.sciencedirect.com/science/article/pii/S0168192317303854
    https://doi.org/10.1016/j.agrformet.2017.11.012 View PDFView articleView in ScopusGoogle
    Scholar Penuelas et al., 1994 J. Penuelas, J.A. Gamon, A.L. Fredeen, J. Merino,
    C.B. Field Reflectance indices associated with physiological changes in nitrogen-
    and water-limited sunflower leaves Remote Sens. Environ., 48 (1994), pp. 135-146
    View PDFView articleView in ScopusGoogle Scholar Pérez-Bueno et al., 2015 M.L.
    Pérez-Bueno, M. Pineda, E. Díaz-Casado, M. Baron Spatial and temporal dynamics
    of primary and secondary metabolism in phaseolus vulgaris challenged by pseudomonas
    syringae Physiol. Plant., 153 (2015), pp. 161-174, 10.1111/ppl.12237 View in ScopusGoogle
    Scholar Peters-Lidard et al., 2021 C.D. Peters-Lidard, D.M. Mocko, L. Su, D.P.
    Lettenmaier, P. Gentine, M. Barlage Advances in land surface models and indicators
    for drought monitoring and prediction Bull. Am. Meteorol. Soc., 102 (2021), 10.1175/BAMS-D-20-0087.1
    E1099 – E1122. URL: https://journals.ametsoc.org/view/journals/bams/102/5/BAMS-D-20-0087.1.xml
    Google Scholar Pineda et al., 2020 M. Pineda, M. Barón, M.L. Pérez-Bueno Thermal
    imaging for plant stress detection and phenotyping Remote Sens., 13 (2020), p.
    68, 10.3390/rs13010068 Google Scholar Poblete et al., 2021 T. Poblete, J.A. Navas-Cortes,
    C. Camino, R. Calderon, A. Hornero, V. Gonzalez-Dugo, B.B. Landa, P.J. Zarco-Tejada
    Discriminating Xylella fastidiosa from verticillium dahliae infections in olive
    trees using thermal- and hyperspectral-based plant traits ISPRS J. Photogramm.
    Remote Sens., 179 (2021), pp. 133-144, 10.1016/j.isprsjprs.2021.07.014 View PDFView
    articleView in ScopusGoogle Scholar Rast et al., 2021 M. Rast, J. Nieke, J. Adams,
    C. Isola, F. Gascon Copernicus Hyperspectral Imaging Mission for the Environment
    (Chime) 2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS.
    IEEE (2021), pp. 108-111, 10.1109/IGARSS47720.2021.9553319 View in ScopusGoogle
    Scholar Reichstein et al., 2019 M. Reichstein, G. Camps-Valls, B. Stevens, M.
    Jung, J. Denzler, N. Carvalhais, Prabhat Deep learning and process understanding
    for data-driven earth system science Nature, 566 (2019), pp. 195-204 CrossRefView
    in ScopusGoogle Scholar Rembold et al., 2000 F. Rembold, S. Carnicelli, M. Nori,
    G.A. Ferrari Use of aerial photographs, Landsat TM imagery and multidisciplinary
    field survey for land-cover change analysis in the lakes region (Ethiopia) Int.
    J. Appl. Earth Obs. Geoinf., 2 (2000), pp. 181-189, 10.1016/S0303-2434(00)85012-6
    View PDFView articleView in ScopusGoogle Scholar Ribeiro da Luz and Crowley, 2007
    B. Ribeiro da Luz, J.K. Crowley Spectral reflectance and emissivity features of
    broad leaf plants: Prospects for remote sensing in the thermal infrared (8.0–14.0
    μm) Remote Sens. Environ., 109 (2007), pp. 393-405, 10.1016/j.rse.2007.01.008
    View PDFView articleView in ScopusGoogle Scholar Ribeiro da Luz and Crowley, 2010
    B. Ribeiro da Luz, J.K. Crowley Identification of plant species by using high
    spatial and spectral resolution thermal infrared (8.0–13.5μm) imagery Remote Sens.
    Environ., 114 (2010), pp. 404-413, 10.1016/j.rse.2009.09.019 View PDFView articleView
    in ScopusGoogle Scholar Richter et al., 2008 K. Richter, P. Rischbeck, J. Eitzinger,
    W. Schneider, F. Suppan, P. Weihs Plant growth monitoring and potential drought
    risk assessment by means of Earth observation data Int. J. Remote Sens., 29 (2008),
    pp. 4943-4960, 10.1080/01431160802036268 View in ScopusGoogle Scholar Rud et al.,
    2014 R. Rud, Y. Cohen, V. Alchanatis, A. Levi, R. Brikman, C. Shenderey, B. Heuer,
    T. Markovitch, Z. Dar, C. Rosen, D. Mulla, T. Nigon Crop water stress index derived
    from multi-year ground and aerial thermal images as an indicator of potato water
    status Precis. Agric., 15 (2014), pp. 273-289, 10.1007/s11119-014-9351-z View
    in ScopusGoogle Scholar Sagan et al., 2019 V. Sagan, M. Maimaitijiang, P. Sidike,
    M. Maimaitiyiming, H. Erkbol, S. Hartling, K.T. Peterson, J. Peterson, J. Burken,
    F. Fritschi UAV/SATELLITE Multiscale DATA Fusion for Crop Monitoring and Early
    Stress Detection. International Archives of the Photogrammetry, Remote Sensing
    and Spatial Information Sciences XLII-2-W13 (2019), pp. 715-722, 10.5194/isprs-archives-XLII-2-W13–715-2019
    View in ScopusGoogle Scholar Salisbury, 1986 J.W. Salisbury Preliminary measurements
    of leaf spectral reflectance in the 8–14 μm region Int. J. Remote Sens., 7 (1986),
    pp. 1879-1886, 10.1080/01431168608948981 View in ScopusGoogle Scholar Sarto et
    al., 2017 M.V.M. Sarto, J.R.W. Sarto, L. Rampim, J.S. Rosset, D. Bassegio, P.F.d.
    Costa, A.M. Inagaki Wheat phenology and yield under drought: a review Aust. J.
    Crop. Sci., 11 (2017), pp. 941-946 URL: https://www.cabdirect.org/cabdirect/abstract/20183392190
    CrossRefView in ScopusGoogle Scholar Savary et al., 2019 S. Savary, L. Willocquet,
    S.J. Pethybridge, P. Esker, N. McRoberts, A. Nelson The global burden of pathogens
    and pests on major food crops Nat. Ecol. Evol., 3 (2019), pp. 430-439, 10.1038/s41559-018-0793-y
    View in ScopusGoogle Scholar Savian et al., 2020 F. Savian, M. Martini, P. Ermacora,
    S. Paulus, A.K. Mahlein Prediction of the kiwifruit decline syndrome in diseased
    orchards by remote sensing Remote Sens., 12 (2020), 10.3390/rs12142194 URL:https://www.mdpi.com/2072-4292/12/14/2194
    Google Scholar Schlerf et al., 2012 M. Schlerf, G. Rock, P. Lagueux, F. Ronellenfitsch,
    M. Gerhards, L. Hoffmann, T. Udelhoven A hyperspectral thermal infrared imaging
    instrument for natural resources applications Remote Sens., 4 (2012), pp. 3995-4009,
    10.3390/rs4123995 View in ScopusGoogle Scholar Seelig et al., 2008 H.D. Seelig,
    A. Hoehn, L.S. Stodieck, D.M. Klaus, W.W. Adams Iii, W.J. Emery The assessment
    of leaf water content using leaf reflectance ratios in the visible, near-, and
    short-wave-infrared Int. J. Remote Sens., 29 (2008), pp. 3701-3713, 10.1080/01431160701772500
    View in ScopusGoogle Scholar Singh et al., 2016 A. Singh, B. Ganapathysubramanian,
    A.K. Singh, S. Sarkar Machine learning for high-throughput stress phenotyping
    in plants Trends Plant Sci., 21 (2016), pp. 110-124, 10.1016/j.tplants.2015.10.015
    View PDFView articleView in ScopusGoogle Scholar Singh et al., 2020 S. Singh,
    A. Fatima, S. Tiwari, S.M. Prasad Plant responses to radiation stress and its
    adaptive mechanisms Plant Life Under Changing Environment, Academic Press, Cambridge,
    MA, USA (2020), pp. 105-122, 10.1016/B978-0-12-818204-8.00006-0 View PDFView articleGoogle
    Scholar Sishodia et al., 2020 R.P. Sishodia, R.L. Ray, S.K. Singh Applications
    of remote sensing in precision agriculture: A review Remote Sens., 12 (2020),
    10.3390/rs12193136 URL: https://www.mdpi.com/2072-4292/12/19/3136 Google Scholar
    Sobejano-Paz et al., 2020 V. Sobejano-Paz, T.N. Mikkelsen, A. Baum, X. Mo, S.
    Liu, C.J. Köppl, M.S. Johnson, L. Gulyas, M. García Hyperspectral and thermal
    sensing of stomatal conductance, transpiration, and photosynthesis for soybean
    and maize under drought Remote Sens., 12 (2020), p. 3182, 10.3390/rs12193182 Google
    Scholar Sonobe et al., 2020 R. Sonobe, H. Yamashita, H. Mihara, A. Morita, T.
    Ikka Estimation of leaf chlorophyll a, b and carotenoid contents and their ratios
    using hyperspectral reflectance Remote Sens., 12 (2020), p. 3265, 10.3390/rs12193265
    Google Scholar Spišić et al., 2022 J. Spišić, D. Šimić, J. Balen, A. Jambrović,
    V. Galić Machine learning in the analysis of multispectral reads in maize canopies
    responding to increased temperatures and water deficit Remote Sens., 14 (2022),
    p. 2596, 10.3390/rs14112596 View in ScopusGoogle Scholar St-Onge et al., 2008
    B. St-Onge, C. Vega, R.A. Fournier, Y. Hu Mapping canopy height using a combination
    of digital stereo-photogrammetry and lidar Int. J. Remote Sens., 29 (2008), pp.
    3343-3364, 10.1080/01431160701469040 View in ScopusGoogle Scholar Suarez et al.,
    2021 L. Suarez, V. González-Dugo, C. Camino, A. Hornero, P.J. Zarco-Tejada Physical
    model inversion of the green spectral region to track assimilation rate in almond
    trees with an airborne nano-hyperspectral imager Remote Sens. Environ., 252 (2021),
    Article 112147 View PDFView articleView in ScopusGoogle Scholar Sulis et al.,
    2015 M. Sulis, M. Langensiepen, P. Shrestha, A. Schickling, C. Simmer, S.J. Kollet
    Evaluating the influence of plant-specific physiological parameterizations on
    the partitioning of land surface energy fluxes J. Hydrometeorol., 16 (2015), pp.
    517-533 URL: https://journals.ametsoc.org/view/journals/hydr/16/2/jhm-d-14-0153_1.xml
    https://doi.org/10.1175/JHM-D-14-0153.1 View in ScopusGoogle Scholar Sultan, 2000
    S.E. Sultan Phenotypic plasticity for plant development, function and life history
    Trends Plant Sci., 5 (2000), pp. 537-542, 10.1016/S1360-1385(00) 01797-0 View
    PDFView articleView in ScopusGoogle Scholar Taghvaeian et al., 2014 S. Taghvaeian,
    L. Comas, K.C. DeJonge, T.J. Trout Conventional and simplified canopy temperature
    indices predict water stress in sunflower Agric. Water Manag., 144 (2014), pp.
    69-80 URL: https://linkinghub.elsevier.com/retrieve/pii/S0378377414001796 https://doi.org/10.1016/j.agwat.2014.06.003
    View PDFView articleView in ScopusGoogle Scholar Tester and Langridge, 2010 M.
    Tester, P. Langridge Breeding technologies to increase crop production in a changing
    world Science, 327 (2010), pp. 818-822 CrossRefView in ScopusGoogle Scholar Tewari
    and Mishra, 2018 S. Tewari, A. Mishra Flooding stress in plants and approaches
    to overcome Plant Metabolites and Regulation Under Environmental Stress, Academic
    Press, Cambridge, MA, USA (2018), pp. 355-366, 10.1016/B978–0–12-812689-9.00018-2
    View PDFView articleView in ScopusGoogle Scholar Thomas et al., 2017 S. Thomas,
    M. Wahabzada, M.T. Kuska, U. Rascher, A.K. Mahlein Observation of plant-pathogen
    interaction by simultaneous hyperspectral imaging reflection and transmission
    measurements Funct. Plant Biol., 44 (2017), pp. 23-34, 10.1071/FP16127 View in
    ScopusGoogle Scholar Timmermans et al., 2015 W.J. Timmermans, C. Van der Tol,
    J. Timmermans, M. Ucer, X. Chen, L. Alonso, J. Moreno, A. Carrara, R. Lopez, F.
    de la Cruz Tercero, H.L. Corcoles, E. de Miguel, J.A.G. Sanchez, I. Pérez, B.
    Franch, J.C.J. Munoz, D. Skokovic, J. Sobrino, G. Soria, A. MacArthur, L. Vescovo,
    I. Reusen, A. Andreu, A. Burkart, C. Cilia, S. Contreras, C. Corbari, J.F. Calleja,
    R. Guzinski, C. Hellmann, I. Herrmann, G. Kerr, A.L. Lazar, B. Leutner, G. Mendiguren,
    S. Nasilowska, H. Nieto, J. Pachego-Labrador, S. Pulanekar, R. Raj, A. Schikling,
    B. Siegmann, S. von Bueren, Z.B. Su An overview of the regional experiments for
    land-atmosphere exchanges 2012 (REFLEX 2012) campaign Acta Geophys., 63 (2015),
    pp. 1465-1484, 10.2478/s11600-014-0254-1 View in ScopusGoogle Scholar Tolomio
    and Casa, 2020 M. Tolomio, R. Casa Dynamic crop models and remote sensing irrigation
    decision support systems: a review of water stress concepts for improved estimation
    of water requirements Remote Sens., 12 (2020), p. 3945, 10.3390/rs12233945 Google
    Scholar UN, 2017 UN World Population Prospects: The 2017 Revision | Multimedia
    Library - United Nations Department of Economic and Social Affairs URL: https://www.un.org/development/desa/publications/world-population-prospects-the-2017-revision.html
    (2017) [Online; accessed 13. Jun. 2022] Google Scholar Van der Tol et al., 2009
    C. Van der Tol, W. Verhoef, J. Timmermans, A. Verhoef, Z. Su An integrated model
    of soil-canopy spectral radiances, photosynthesis, fluorescence, temperature and
    energy balance Biogeosciences, 6 (2009), p. 31093129, 10.5194/bg-6-3109-2009 Google
    Scholar Van der Tol et al., 2016 C. Van der Tol, M. Rossini, S. Cogliati, W. Verhoef,
    R. Colombo, U. Rascher, G. Mohammed A model and measurement comparison of diurnal
    cycles of sun-induced chlorophyll fluorescence of crops Remote Sens. Environ.,
    186 (2016), pp. 663-677 URL: https://www.sciencedirect.com/science/article/pii/S0034425716303649
    https://doi.org/10.1016/j.rse.2016.09.021 View PDFView articleView in ScopusGoogle
    Scholar van Diepen et al., 1989 C.A. van Diepen, J. Wolf, H. van Keulen, C. Rappoldt
    WOFOST: a simulation model of crop production Soil Use Manag., 5 (1989), pp. 16-24,
    10.1111/j.1475–2743.1989.tb00755.x View in ScopusGoogle Scholar Van Wittenberghe
    et al., 2019 S. Van Wittenberghe, L. Alonso, Z. Malenovsky, J. Moreno In vivo
    photoprotection mechanisms observed from leaf spectral absorbance changes showing
    vis-nir slow-induced conformational pigment bed changes Photosynth. Res., 142
    (2019), pp. 283-305 CrossRefView in ScopusGoogle Scholar Van Wittenberghe et al.,
    2021 S. Van Wittenberghe, V. Laparra, J. Garcia-Plazaola, B. Fernandez-Marin,
    J. Moreno Combined dynamics of the 500–600 nm leaf absorption and chlorophyll
    fluorescence changes in vivo: evidence for the multifunctional energy quenching
    role of xanthophylls Biochim. Biophys. Acta Bioenerg., 1862 (2021), Article 148351
    View PDFView articleView in ScopusGoogle Scholar Vaughan et al., 2003 R.G. Vaughan,
    W.M. Calvin, J.V. Taranik SEBASS hyperspectral thermal infrared data: surface
    emissivity measurement and mineral mapping Remote Sens. Environ., 85 (2003), pp.
    48-63, 10.1016/S0034-4257(02)00186-4 View PDFView articleView in ScopusGoogle
    Scholar Verdouw et al., 2021 C. Verdouw, B. Tekinerdogan, A. Beulens, S. Wolfert
    Digital twins in smart farming Agric. Syst., 189 (2021), Article 103046, 10.1016/j.agsy.2020.
    103046 View PDFView articleView in ScopusGoogle Scholar Vergara-Diaz et al., 2015
    O. Vergara-Diaz, S.C. Kefauver, A. Elazab, M.T. Nieto-Taladriz, J.L. Araus Grain
    yield losses in yellow-rusted durum wheat estimated using digital and conventional
    parameters under field conditions Crop J., 3 (2015), pp. 200-210 URL: https://www.sciencedirect.com/science/article/pii/S2214514115000355
    https://doi.org/10.1016/j.cj.2015.03.003 special Issue: Breeding to Optimize Agriculture
    in a Changing World View PDFView articleView in ScopusGoogle Scholar Verrelst
    et al., 2015 J. Verrelst, G. Camps Valls, J. Munoz-Marí, J. Rivera, F. Veroustraete,
    J. Clevers, J. Moreno Optical remote sensing and the retrieval of terrestrial
    vegetation bio-geophysical properties - a review ISPRS J. Photogramm. Remote Sens.,
    108 (2015), pp. 273-290 View PDFView articleView in ScopusGoogle Scholar Verrelst
    et al., 2019a J. Verrelst, Z. Malenovský, C. Van der Tol, G. Camps-Valls, J.P.
    Gastellu-Etchegorry, P. Lewis, P. North, J. Moreno Quantifying vegetation biophysical
    variables from imaging spectroscopy data: a review on retrieval methods Surv.
    Geophys., 40 (2019), pp. 589-629, 10.1007/s10712–018-9478-y View in ScopusGoogle
    Scholar Verrelst et al., 2019b J. Verrelst, J. Vicent, J.P. Rivera-Caicedo, M.
    Lumbierres, P. Morcillo-Pallarés, J. Moreno Global sensitivity analysis of leaf-canopy-atmosphere
    RTMs: implications for biophysical variables retrieval from top-of-atmosphere
    radiance data Remote Sens. (2019), p. 11 Google Scholar Verrelst et al., 2021
    J. Verrelst, J.P. Rivera-Caicedo, P. Reyes-Muñoz, M. Morata, E. Amin, G. Tagliabue,
    C. Panigada, T. Hank, K. Berger Mapping landscape canopy nitrogen content from
    space using PRISMA data ISPRS J. Photogramm. Remote Sens., 178 (2021), pp. 382-395,
    10.1016/j.isprsjprs.2021.06.017 View PDFView articleView in ScopusGoogle Scholar
    Vilfan et al., 2018 N. Vilfan, C. Van der Tol, P. Yang, R. Wyber, Z. Malenovskỳ,
    S.A. Robinson, W. Verhoef Extending fluspect to simulate xanthophyll driven leaf
    reflectance dynamics Remote Sens. Environ., 211 (2018), pp. 345-356 View PDFView
    articleView in ScopusGoogle Scholar Virnodkar et al., 2020 S.S. Virnodkar, V.K.
    Pachghare, V.C. Patil, S.K. Jha Remote sensing and machine learning for crop water
    stress determination in various crops: a critical review Precis. Agric., 21 (2020),
    pp. 1121-1155 CrossRefView in ScopusGoogle Scholar Weiss et al., 2020 M. Weiss,
    F. Jacob, G. Duveiller Remote sensing for agricultural applications: a meta-review
    Remote Sens. Environ., 236 (2020), Article 111402 View PDFView articleView in
    ScopusGoogle Scholar Yadav, 2010 S.K. Yadav Cold stress tolerance mechanisms in
    plants. A review Agron. Sustain. Dev., 30 (2010), pp. 515-527, 10.1051/agro/2009050
    View in ScopusGoogle Scholar Yang and van der Tol, 2018 P. Yang, C. van der Tol
    Linking canopy scattering of far-red sun- induced chlorophyll fluorescence with
    reflectance Remote Sens. Environ., 209 (2018), pp. 456-467, 10.1016/j.rse.2018.02.029
    View PDFView articleView in ScopusGoogle Scholar Yang et al., 2017a G. Yang, J.
    Liu, C. Zhao, Z. Li, Y. Huang, H. Yu, B. Xu, X. Yang, D. Zhu, X. Zhang, R. Zhang,
    H. Feng, X. Zhao, Z. Li, H. Li, H. Yang Unmanned aerial vehicle remote sensing
    for field-based crop phenotyping: current status and perspectives Front. Plant
    Sci., 8 (2017), p. 1111, 10.3389/fpls.2017.01111, arXiv:28713402 View in ScopusGoogle
    Scholar Yang et al., 2017b P. Yang, W. Verhoef, C. van der Tol The mSCOPE model:
    a simple adaptation to the SCOPE model to describe reflectance, fluorescence and
    photosynthesis of vertically heterogeneous canopies Remote Sens. Environ., 201
    (2017), pp. 1-11 URL: https://www.sciencedirect.com/science/article/pii/S0034425717303954https://linkinghub.elsevier.com/retrieve/pii/S0034425717303954
    https://doi.org/10.1016/j.rse.2017.08.029 View PDFView articleGoogle Scholar Yang
    et al., 2019 P. Yang, C. van der Tol, W. Verhoef, A. Damm, A. Schickling, T. Kraska,
    O. Muller, U. Rascher Using reflectance to explain vegetation biochemical and
    structural effects on sun-induced chlorophyll fluorescence Remote Sens. Environ.,
    231 (2019), Article 110996 View PDFView articleView in ScopusGoogle Scholar Yang
    et al., 2020a P. Yang, C. van der Tol, P.K. Campbell, E.M. Middleton Fluorescence
    Correction Vegetation Index (FCVI): a physically based reflectance index to separate
    physiological and non-physiological information in far- red sun-induced chlorophyll
    fluorescence Remote Sens. Environ., 240 (2020), Article 111676 URL: https://linkinghub.elsevier.com/retrieve/pii/S0034425720300456
    https://doi.org/10.1016/j.rse.2020.111676 View PDFView articleGoogle Scholar Yang
    et al., 2020b P. Yang, W. Verhoef, C. Van der Tol Unified four-stream radiative
    transfer theory in the optical-thermal domain with consideration of fluorescence
    for multi-layer vegetation canopies Remote Sens., 12 (2020), p. 3914 CrossRefGoogle
    Scholar Yang et al., 2021a P. Yang, E. Prikaziuk, W. Verhoef, C. van der Tol SCOPE
    2.0: a model to simulate vegetated land surface fluxes and satellite signals Geosci.
    Model Dev., 14 (2021), pp. 4697-4712 URL: https://gmd.copernicus.org/articles/14/4697/2021/
    https://doi.org/10.5194/gmd-14-4697-2021 CrossRefView in ScopusGoogle Scholar
    Yang et al., 2021b P. Yang, W. Verhoef, E. Prikaziuk, C. Van der Tol Improved
    retrieval of land surface biophysical variables from time series of Sentinel-3
    OLCI TOA spectral observations by considering the temporal autocorrelation of
    surface and atmospheric properties Remote Sens. Environ., 256 (2021), Article
    112328, 10.1016/j.rse.2021.112328 View PDFView articleView in ScopusGoogle Scholar
    Zarco-Tejada et al., 2018 P.J. Zarco-Tejada, C. Camino, P.S.A. Beck, R. Calderon,
    A. Hornero, R. Hernandez-Clemente, T. Kattenborn, M. Montes-Borrego, L. Susca,
    M. Morelli, V. Gonzalez-Dugo, P.R.J. North, B.B. Landa, D. Boscia, M. Saponari,
    J.A. Navas-Cortes Previsual symptoms of Xylella fastidiosa infection revealed
    in spectral plant-trait alterations Nat. Plants, 4 (2018), pp. 432-439, 10.1038/s41477-018-0189-7
    View in ScopusGoogle Scholar Zarco-Tejada et al., 2021 P.J. Zarco-Tejada, T. Poblete,
    C. Camino, V. Gonzalez-Dugo, R. Calderon, A. Hornero, R. Hernandez-Clemente, M.
    Román-Écija, M.P. Velasco- Amo, B.B. Landa, P.S.A. Beck, M. Saponari, D. Boscia,
    J.A. Navas- Cortes Divergent abiotic spectral pathways unravel pathogen stress
    signals across species Nat. Commun., 12 (2021), pp. 1-11, 10.1038/s41467-021-26335-3
    Google Scholar Zeng et al., 2019 Y. Zeng, G. Badgley, B. Dechant, Y. Ryu, M. Chen,
    J. Berry A practical approach for estimating the escape ratio of near-infrared
    solar- induced chlorophyll fluorescence Remote Sens. Environ., 232 (2019), p.
    111209 URL: https://www.sciencedirect.com/science/article/pii/S0034425719302226
    https://doi.org/10.1016/j.rse.2019.05.028 View PDFView articleView in ScopusGoogle
    Scholar Zhang and Zhou, 2019 F. Zhang, G. Zhou Estimation of vegetation water
    content using hyperspectral vegetation indices: a comparison of crop water indicators
    in response to water stress treatments for summer maize BMC Ecol., 19 (2019),
    pp. 1-12, 10.1186/s12898-019-0233-0 Google Scholar Zhang et al., 2019 J. Zhang,
    Y. Huang, R. Pu, P. Gonzalez-Moreno, L. Yuan, K. Wu, W. Huang Monitoring plant
    diseases and pests through remote sensing technology: a review Comput. Electron.
    Agric., 165 (2019), Article 104943, 10.1016/j.compag.2019.104943 View PDFView
    articleView in ScopusGoogle Scholar Zhuang et al., 2020 Q. Zhuang, H. Wang, Y.
    Xu Comparison of remote sensing based multi-source et models over cropland in
    a semi-humid region of china Atmosphere, 11 (2020), 10.3390/atmos11040325 URL:
    https://www.mdpi.eom/2073-4433/11/4/325 Google Scholar Cited by (63) Inferring
    global terrestrial carbon fluxes from the synergy of Sentinel 3 &amp; 5P with
    Gaussian process hybrid models 2024, Remote Sensing of Environment Show abstract
    Immediate and lagged vegetation responses to dry spells revealed by continuous
    solar-induced chlorophyll fluorescence observations in a tall-grass prairie 2024,
    Remote Sensing of Environment Show abstract Comparing high-cost and lower-cost
    remote sensing tools for detecting pre-symptomatic downy mildew (Pseudoperonospora
    cubensis) infections in cucumbers 2024, Computers and Electronics in Agriculture
    Show abstract Water availability and atmospheric dryness controls on spaceborne
    sun-induced chlorophyll fluorescence yield 2024, Remote Sensing of Environment
    Show abstract Retrieval of leaf-level fluorescence quantum efficiency and NPQ-related
    xanthophyll absorption through spectral unmixing strategies for future VIS-NIR
    imaging spectroscopy 2024, Remote Sensing of Environment Show abstract An interval
    band selection method based on class saliency map to identify vegetation under
    natural gas microleakage stress 2024, Microchemical Journal Show abstract View
    all citing articles on Scopus © 2022 The Authors. Published by Elsevier Inc. Recommended
    articles Hyperspectral response of agronomic variables to background optical variability:
    Results of a numerical experiment Agricultural and Forest Meteorology, Volume
    326, 2022, Article 109178 Lin Gao, …, Clement Atzberger View PDF Far-red sun-induced
    chlorophyll fluorescence shows ecosystem-specific relationships to gross primary
    production: An assessment based on observational and modeling approaches Remote
    Sensing of Environment, Volume 166, 2015, pp. 91-105 A. Damm, …, M.E. Schaepman
    View PDF Optical remote sensing and the retrieval of terrestrial vegetation bio-geophysical
    properties – A review ISPRS Journal of Photogrammetry and Remote Sensing, Volume
    108, 2015, pp. 273-290 Jochem Verrelst, …, José Moreno View PDF Show 3 more articles
    Article Metrics Citations Citation Indexes: 47 Captures Readers: 206 View details
    About ScienceDirect Remote access Shopping cart Advertise Contact and support
    Terms and conditions Privacy policy Cookies are used by this site. Cookie settings
    | Your Privacy Choices All content on this site: Copyright © 2024 Elsevier B.V.,
    its licensors, and contributors. All rights are reserved, including those for
    text and data mining, AI training, and similar technologies. For all open access
    content, the Creative Commons licensing terms apply.'
  inline_citation: '>'
  journal: Remote sensing of environment
  limitations: '>'
  pdf_link: null
  publication_year: 2022
  relevance_score1: 0
  relevance_score2: 0
  title: 'Multi-sensor spectral synergies for crop stress detection and monitoring
    in the optical domain: A review'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.3390/rs10050787
  analysis: '>'
  authors:
  - Samuel Joalland
  - Claudio Screpanti
  - Hubert Varella
  - Marie Reuther
  - Mareike Schwind
  - Christian Lång
  - Achim Walter
  - Frank Liebisch
  citation_count: 36
  full_citation: '>'
  full_text: ">\nremote sensing  \nArticle\nAerial and Ground Based Sensing of Tolerance\
    \ to Beet\nCyst Nematode in Sugar Beet\nSamuel Joalland 1,2 ID , Claudio Screpanti\
    \ 1, Hubert Vincent Varella 1, Marie Reuther 3,\nMareike Schwind 3, Christian\
    \ Lang 3, Achim Walter 2 and Frank Liebisch 2,* ID\n1\nSyngenta Crop Protection\
    \ Münchwillen AG, Schaffhauserstrasse, 4332 Stein, Switzerland;\nsamueljoalland49@gmail.com\
    \ (S.J.); Claudio.Screpanti@syngenta.com (C.S.);\nhubert.vincent.varella@outlook.com\
    \ (H.V.V.)\n2\nInstitute of Agricultural Sciences, ETH Zürich, Universitätstrasse\
    \ 2, 8092 Zürich, Switzerland;\nachim.walter@usys.ethz.ch\n3\nVerband der Hessisch-Pfälzischen\
    \ Zuckerrübenanbauer e.V., Rathenaustraße 10, 67547 Worms, Germany;\nmarie_reuther@ymail.com\
    \ (M.R.); schwind@ruebe.info (M.S.); lang@ruebe.info (C.L.)\n*\nCorrespondence:\
    \ frank.liebisch@usys.ethz.ch; Tel.: +41-52-354-9125\nReceived: 1 April 2018;\
    \ Accepted: 18 May 2018; Published: 19 May 2018\n\x01\x02\x03\x01\x04\x05\x06\a\
    \b\x01\n\x01\x02\x03\x04\x05\x06\a\nAbstract: The rapid development of image-based\
    \ phenotyping methods based on ground-operating\ndevices or unmanned aerial vehicles\
    \ (UAV) has increased our ability to evaluate traits of interest\nfor crop breeding\
    \ in the ﬁeld. A ﬁeld site infested with beet cyst nematode (BCN) and planted\
    \ with\nfour nematode susceptible cultivars and ﬁve tolerant cultivars was investigated\
    \ at different times\nduring the growing season. We compared the ability of spectral,\
    \ hyperspectral, canopy height- and\ntemperature information derived from handheld\
    \ and UAV-borne sensors to discriminate susceptible\nand tolerant cultivars and\
    \ to predict the ﬁnal sugar beet yield. Spectral indices (SIs) related to\nchlorophyll,\
    \ nitrogen or water allowed differentiating nematode susceptible and tolerant\
    \ cultivars\n(cultivar type) from the same genetic background (breeder). Discrimination\
    \ between the cultivar\ntypes was easier at advanced stages when the nematode\
    \ pressure was stronger and the plants and\ncanopies further developed. The canopy\
    \ height (CH) allowed differentiating cultivar type as well but\nwas much more\
    \ efﬁcient from the UAV compared to manual ﬁeld assessment. Canopy temperatures\n\
    also allowed ranking cultivars according to their nematode tolerance level. Combinations\
    \ of SIs in\nmultivariate analysis and decision trees improved differentiation\
    \ of cultivar type and classiﬁcation of\ngenetic background. Thereby, SIs and\
    \ canopy temperature proved to be suitable proxies for sugar\nyield prediction.\
    \ The spectral information derived from handheld and the UAV-borne sensor did\
    \ not\nmatch perfectly, but both analysis procedures allowed for discrimination\
    \ between susceptible and\ntolerant cultivars. This was possible due to successful\
    \ detection of traits related to BCN tolerance\nlike chlorophyll, nitrogen and\
    \ water content, which were reduced in cultivars with a low tolerance\nto BCN.\
    \ The high correlation between SIs and ﬁnal sugar beet yield makes the UAV hyperspectral\n\
    imaging approach very suitable to improve farming practice via maps of yield potential\
    \ or diseases.\nMoreover, the study shows the high potential of multi-sensor and\
    \ parameter combinations for plant\nphenotyping purposes, in particular for data\
    \ from UAV-borne sensors that allow for standardized\nand automated high-throughput\
    \ data extraction procedures.\nKeywords: hyperspectral images; spectrometry; canopy\
    \ height; thermography; UAV; Heterodera schachtii;\nroot; field\n1. Introduction\n\
    Sugar beet is a root crop widely cultivated in Europe and North America for sugar\
    \ production.\nTwenty percent of the world’s supply of sugar is derived from sugar\
    \ beet [1].\nOne of the main\nRemote Sens. 2018, 10, 787; doi:10.3390/rs10050787\n\
    www.mdpi.com/journal/remotesensing\nRemote Sens. 2018, 10, 787\n2 of 21\nsoil\
    \ borne parasites that limits sugar beet production worldwide is the Beet Cyst\
    \ Nematode (BCN),\nHeterodera schachtii. It is the most important pest of sugar\
    \ beet [2]. BCN causes severe damage and\nsignificant yield losses of up to 60%\
    \ [3]. In addition, this pathogen can infect more than 200 different plant\nspecies,\
    \ making their management in the crop cycle a challenging task [4,5]. Most nematode\
    \ damage\noccurs belowground including reduction of beet growth and the appearance\
    \ of many secondary roots\nto compensate for those infested by nematodes. BCN\
    \ also causes shoot symptoms such as stunted\ngrowth, decreased chlorophyll content,\
    \ and wilting of the canopy due to water stress [6,7]. In the ﬁeld,\nnematodes\
    \ occur in patches and have very low mobility. This makes sugar beet breeding\
    \ with respect\nto BCN infestation a good target for the use of non-destructive\
    \ ground and aerial based phenotyping\nmethodology in the ﬁeld.\nApart from direct\
    \ observation of nematode-induced damage in excavated roots, an indirect\nobservation\
    \ of belowground damage via performance of the aboveground shoot performance is\
    \ the\nonly way to address the severity of crop deterioration. Such assessment\
    \ can be done via remote sensing\nmethods. For nematode-induced stress, several\
    \ sensor-based methods have been tested in a variety of\ncrops such as potatoes,\
    \ soybeans or sugar beet using ground and airborne platforms [8–11].\nFor differentiation\
    \ of nematode infested and non-infested treatments under greenhouse and\nsemi-controlled\
    \ ﬁeld conditions, ground based visible imaging has been successfully used on\
    \ sugar\nbeet [12,13]. The canopy area of the plant can be robustly calculated\
    \ and reﬂects root biomass\nin a variety of plant species [14–17]. Phenotyping\
    \ methods based on multi- and hyper-spectral\nmeasurements showed promising results\
    \ for evaluating the symptoms caused by BCN on sugar\nbeet plants under ﬁeld and\
    \ semi-controlled ﬁeld conditions [11,13]. These methods are based on the\ncalculation\
    \ of spectral vegetation indices (SIs). SIs are combinations of spectral bands\
    \ that enhance the\nsensitivity to speciﬁc canopy characteristic while reducing\
    \ the effect of non-desirable factors such as\nsoil background [18]. In the ﬁeld,\
    \ the use of speciﬁc SIs has been reported to predict the ﬁnal beet yield\nand\
    \ the nematode population in the soil [19]. Schmitz et al. [20] reported the ability\
    \ of aerial remote\nsensing thermography to detect changes in the canopy temperature\
    \ of sugar beet plants infested with\nnematodes in the ﬁeld. This increase in\
    \ canopy temperature of the nematode- infested sugar beet\nplants was also observed\
    \ in semi-controlled ﬁeld conditions under artiﬁcial nematode infestation on\n\
    nematode susceptible and tolerant cultivars [13].\nThe recent technological advances\
    \ in unmanned aerial vehicles (UAV), miniaturization of sensors\nand developments\
    \ of software and algorithms enabled the application of digital imaging methodology\n\
    from aerial view covering larger areas in a shorter time [21–23]. Recent work\
    \ has demonstrated the\nability of UAV coupled with a range of imaging sensors\
    \ to provide suitable phenotype information\nfor several purposes such as breeding\
    \ support or precision farming and for different crops [24–28].\nVery few studies\
    \ have made use of the new technologies for investigation or detection of sugar\
    \ beet\nBCN infestation in ﬁelds.\nFor aerial crop phenotyping, applied sensors\
    \ and methodology comprise usage of visible, multi- to\nhyperspectral sensors\
    \ [29–32], thermal imaging [31,33], and extraction of crop height information\
    \ [34,35].\nAmong the applications of UAV based phenotyping are detection of weeds,\
    \ soil characteristics,\nwater status, diseases, pest management and fertilization\
    \ support or yield estimation [36,37].\nNevertheless, robust and reliable extraction\
    \ of information from airborne sensors remains one of\nthe biggest challenges.\n\
    For visible and spectral images, information can be extracted by band combination\
    \ math [29,32]\nor via other methods such as partial least square regression [38]\
    \ or machine learning algorithms [39].\nAlthough SIs have been proven robust trait\
    \ indicators in many studies, machine learning algorithms\nare not yet applied\
    \ without task speciﬁc learning or calibration in agriculture. Thermal information\n\
    can be retrieved from calibrated or non-calibrated cameras and often needs consideration\
    \ of the actual\nweather conditions for correct interpretation. Crop or canopy\
    \ height information can be extracted\nusing “Structure from Motion” (SfM) algorithms\
    \ subtracting the soil elevation model from the canopy\nelevation model. Although\
    \ it is technically feasible, combinations of sensors have rarely been applied\n\
    Remote Sens. 2018, 10, 787\n3 of 21\nfor phenotyping tasks. The use of different\
    \ sensors in combined or single mode and post processing\nmethodology, SIs and\
    \ SfM for instance offer a high return of information for applications in crop\n\
    phenotyping and large-scale precision agriculture.\nFor crop breeding or research,\
    \ such aerial-based information retrieval offers faster and more\nfrequent measurements.\
    \ For precision agriculture, it enables the evaluation of larger areas and the\n\
    robust use of information for crop management decisions.\nFor the sugar beet BCN\
    \ infestation scenario, aerial derived trait maps combined with a\nreduced number\
    \ of soil samples in the ﬁeld can conﬁrm the presence of nematodes and allow\n\
    exact determination of spatial distribution and density of nematode infestation\
    \ in agricultural ﬁelds.\nSuch knowledge may help to select the optimal sugar\
    \ beet cultivar.\nThere is still a need to develop fast and reliable methods to\
    \ evaluate the status of soil borne\npathogen infestation such as BCN under real\
    \ ﬁeld conditions and give a ﬁrst prediction of the yield\npotential. Applications\
    \ would be proﬁtable not only for breeding purposes but also for farmers to help\n\
    for the selection of the best countermeasures such as crop rotation and the use\
    \ of appropriate cultivars\nor catch crops.\nThe present study therefore investigates\
    \ the ability of thermography, ﬁeld spectrometry and aerial\nhyperspectral imaging\
    \ to identify the stress caused by nematodes on susceptible and tolerant sugar\n\
    beet cultivars in the ﬁeld. More speciﬁcally, the main objectives were to (1)\
    \ Compare the ability of\nthermography and spectrometry methods to discriminate\
    \ and rank susceptible and tolerant sugar\nbeet cultivars; (2) Evaluate the capability\
    \ of the phenotyping methods to predict the sugar beet yield\nand (3) Validate\
    \ the ability of aerial UAV-based and hyperspectral imaging to discriminate and\
    \ rank\nsusceptible and tolerant sugar beet cultivars and predict nematode population\
    \ and ﬁnal yield.\n2. Materials and Methods\n2.1. Experimental Site\nTwo sugar\
    \ beet ﬁeld trials were carried out side by side in 2016 in a ﬁeld (0.4 ha) in\
    \ Ober-Flörsheim\n(Rhineland-Palatinate, Germany) by the interest group for ﬁeld\
    \ experiments and extension in sugar\nbeet (“Arbeitsgemeinschaft für Versuchswesen\
    \ und Beratung im Zuckerrübenanbau Südwest”-ARGE\nZuckerrübe Südwest). The site\
    \ is located 49◦68′N, 8◦15′E at an altitude of 244 m above sea level.\nThe ﬁeld\
    \ site was selected based on its natural infestation with BCN. The soil is a sandy\
    \ loam (pH 7.5)\ncontaining 29.5 kg P2O5 ha−1, 45 kg K2O ha−1, 9.2 kg Mg ha−1.\
    \ Fertilizer application followed best\npractice, with a base fertilizer application\
    \ of 159 kg N ha−1, 54 kg P2O5 ha−1, 96 kg K2O ha−1 and\n24 kg Mg ha−1 prior to\
    \ sowing on 24 March.\nHerbicide was applied during the first two months after\
    \ sowing to avoid the influence of weeds on\nthe plant growth (18 April: 1.2 L\
    \ ha−1 Powertwin Plus + 1.5 L ha−1 Goltix, (Feinchemie Schwebda GmbH,\nEschwege,\
    \ Germany); 2 May: 1.25 L ha−1 Powertwin Plus + 1.5 L ha−1 Goltix; 7 May: 0.5\
    \ L ha−1 Gallant,\n(Dow Agrosciences, Indianapolis, IN, USA); 17 May: 1.25 L ha−1\
    \ Powertwin Plus + 1.5 L ha−1 Goltix +\n0.2 L ha−1 Tramat (Bayer Cropscience,\
    \ Monheim, Germany). To control fungal pathogens one liter h −1\nSpyrale (Syngenta\
    \ AG, Basel, Switzerland) was applied twice during the season, on 19 July and\n\
    18 August. This management reﬂects conventional intensive sugar beet cultivation\
    \ in the region.\nThe climate of the study area is temperate with a mean annual\
    \ rainfall of around 611 mm.\nFrom sowing on 24 March until harvest on 6 October,\
    \ mean minimum and mean maximum\ntemperatures were 10.1 ◦C and 21.0 ◦C, respectively.\n\
    2.2. Experimental Design\nTwo trials were established in two separate block designs\
    \ (Table 1 and Figure 1) with the initial\npurpose of the trial to compare susceptible\
    \ and tolerant cultivars from the same seed provider;\nplots were gathered at\
    \ the same locations in order to minimize the variability in nematode pressure.\n\
    No gradients in soil conditions were observed within the experimental ﬁeld. Individual\
    \ plots were\nRemote Sens. 2018, 10, 787\n4 of 21\nthree meters wide by eight\
    \ meters long with a row distance of 0.5 m and a target sowing density of\n11.1\
    \ seeds per m2. In trial 1, one susceptible and two tolerant cultivars were planted\
    \ (Sus A, Tol A1,\nand Tol A2 from the breeder A). In trial 2, three susceptible\
    \ and three tolerant cultivars were sown\n(Breeders B, C and D). In the present\
    \ manuscript, A, B, C, and D are groups of cultivars corresponding\nto four different\
    \ breeders (companies), supposedly reﬂecting different genetic backgrounds.\n\
    Sugar beet cultivars were randomized in a block design with 16 and eight replicates\
    \ per treatment\nfor experiments 1 and 2, respectively. Both trials were located\
    \ in the same ﬁeld.\nFigure 1. Orthophoto of the experimental ﬁeld extracted from\
    \ the hyperspectral imager containing\nthe experimental setup of the two investigated\
    \ ﬁeld trials (A); detail of the reﬂectance plates used for\nradiometric calibration\
    \ as placed in the ﬁeld (B); contour map of the initial BCN population density\
    \ in\nthe topsoil (0–30 cm) (C); The map was linearly interpolated from the 108\
    \ data points representing the\nsampled plots using the average of its neighbors\
    \ for non-sampled plots.\nTable 1. Summary of the experimental settings and the\
    \ crop management operations during the two\nﬁeld trials.\nSugar beet cultivars\n\
    Susceptible\nTolerant\nSus A\nTol A1\nTol A2\nSus B\nTol B\nSus C\nTol C\nSus\
    \ D\nTol D\nSowing\n24 March 2016\nFertilizer application\nMid-March\nHerbicide\
    \ applications\n18 April\n2 May\n7 May\n17 May\nFungicide application\n19 July\n\
    18 August\nRemote Sens. 2018, 10, 787\n5 of 21\nTable 1. Cont.\nGround measurements\n\
    Spectrometry\n20 June (88 das *)\n4 July (102 das)\n23 August (152 das)\nCanopy\
    \ height\n4 July (102 das)\nThermography\n23 August (152 das)\nUAV Hyperspectral\
    \ images acquisition\n4 July (102 das)\n23 August (152 das)\nHarvest and sampling\n\
    6 October\n* Days after sowing.\n2.3. Plant and Nematode Evaluation\nThe trials\
    \ were harvested 196 days after sowing (das) on 6 October 2016. Three middle rows\
    \ were\nharvested for each plot (17 m2). Final beet fresh weight and white sugar\
    \ yield were determined for\neach single plot as described in Reuther et al. [40].\n\
    The initial BCN population density (pi) in the different plots was assessed at\
    \ the time of planting\nand the ﬁnal BCN population (pf) was assessed at harvest.\
    \ Soil cores were sampled in each plot\nwith a hydraulic soil sampler (Nietfeld,\
    \ DUOPROB 60-UP, Quakenbrück, Germany). Ten samples\nwere collected and automatically\
    \ separated in topsoil (0–30 cm) and subsoil (30–60 cm) in the soil\nsampler.\
    \ They were mixed to obtain one topsoil and one subsoil sample of minimum 500\
    \ g each per\nplot. Samples were stored in the dark at 4 ◦C before analysis. The\
    \ nematode population was evaluated\nusing a method described by Grosse et al.\
    \ [41]. Based on the observation that 50% of the dormant\nnematodes hatched, the\
    \ nematode infestation levels were determined by multiplying the observed\ninfestation\
    \ levels by a correction factor of two [42]. Infestation level was expressed as\
    \ the number of\njuveniles (J2s) of H. schachtii per 100 g of soil.\n2.4. In-Field\
    \ Measurements\nCanopy height measurements were performed manually in the ﬁeld\
    \ 102 das using a ruler.\nTwo measurements were taken from the middle of two rows,\
    \ respectively on the ﬁrst third of each plot\nand subsequently averaged (CHruler).\n\
    Thermal images were acquired 152 das using an infrared camera (Testo 885, Testo\
    \ Ltd., Alton, UK),\nhaving a Si sensor with 320 × 240 pixels covering a spectral\
    \ range of 8–14 µm, and a sensor sensitivity\nof <30 mK at 30 ◦C. As in a previous\
    \ study [13] the thermal device was calibrated prior to taking\npictures by setting\
    \ up the emissivity to 96% and the reﬂected temperature compensation parameter\
    \ to\nthe current air temperature [43]. One picture was taken from the same side\
    \ of each plot with an angle\nof 45◦ at a height of 1.5 m above the ground. Canopy\
    \ temperature (TC) was determined by combining\nboth thermal and visible images\
    \ generated by the thermal camera. Temperature ﬂuctuation in the ﬁeld\nwas assessed\
    \ by evaluating the naked soil temperature (TS) between rows with the thermal\
    \ camera ten\ntimes during the measurements. On average, TS was 28.7 ◦C (±0.4\
    \ ◦C) and relative humidity was 54%\nat the time of measurement. Because of the\
    \ stable ambient temperature (ﬂuctuating less than 1.5%)\nduring measurements\
    \ no normalization to ambient temperatures was applied.\nSpectral measurements\
    \ in the ﬁeld were performed at das 88, 102 and 152 during the plant\ndevelopment\
    \ using a non-imaging spectro-radiometer (ASD FieldSpec® 4, Analytic Spectral\
    \ Devices,\nBoulder, CO, USA) with a spectral range of 350–2500 nm. Canopy spectra\
    \ were acquired from\nnadir view of the plots at a height of 1 m above canopy\
    \ with a 25◦ ﬁeld of view. For each plot,\nﬁve spectra were randomly taken at\
    \ distinct positions consisting of ﬁve spectral samples and averaged.\nInstrument\
    \ radiometric optimization and reﬂectance calibration were performed each time\
    \ prior\nto spectral sampling in every third plot using a Zenith Polymer® (SphereOptics,\
    \ Herrsching am\nAmmersee, Germany) 99% reﬂectance target as white reference.\n\
    Remote Sens. 2018, 10, 787\n6 of 21\nUAV-Based Data Acquisition\nAerial image\
    \ spectroscopy was acquired 102 and 152 das with a Gamaya OXI VNIR 40 camera\n\
    system (Gamaya, SA, Lausanne, Switzerland) consisting of two individual cameras\
    \ measuring\n16 bands in the visible (VIS) and 25 bands in the near-infrared (NIR)\
    \ range, respectively. The System\nwas mounted on a Solo drone (3D Robotics, Inc.,\
    \ San Diego, USA). The camera system provides\n40 spectral bands between 475 nm\
    \ and 875 nm with a full width half maximum (FWHM) ranging\nfrom approximately\
    \ 15 to 25 nm. It was equipped with 25 mm focal length optics. The images were\n\
    captured from an altitude of 80 m with at least 75% overlap and 60% sidelap. VIS\
    \ and NIR images\nwere de-convolved with the Sprocket software provided by Gamaya,\
    \ using the raw images and a\ncamera speciﬁc calibration proﬁle resulting in two\
    \ megapixel images (2048 × 1088 pixels) for each\ncamera. Both sets of images\
    \ were processed in Agisoft Photoscan Professional (v. 1.26, Agisoft, LLC,\nSt.\
    \ Petersburg, Russia) resulting in a digital surface model (DSM) and an orthophoto\
    \ for VIS and NIR,\nrespectively. Geometrically correct overlay was facilitated\
    \ using virtual markers such as distinctive\nﬁeld (stones, plot corners) or infrastructure\
    \ (street breaks or gully covers) features.\nReﬂectance computation was also done\
    \ with the Sprocket software from Gamaya and the ﬁnal\nhypercube was exported\
    \ as a band interleaved by line (bil) format. Three targets of different reﬂectance\n\
    were placed in the ﬁeld, measured with the ASD spectro-radiometer and selected\
    \ in the hypercube\n(Figure 1). The radiance spectra of those targets, as seen\
    \ by the hyperspectral camera, are then used to\nestimate the most likely sunlight\
    \ spectrum, which is assumed constant throughout the data acquisition.\nThe sunlight\
    \ spectrum can be estimated for each target, by dividing for each band the target’s\
    \ radiance\nfrom the camera by its known reﬂectance measured in the ﬁeld. As three\
    \ different targets were used,\nthe three sunlight estimations were fused into\
    \ the most likely one through the least square regression\nfunction in the sprocket\
    \ software.\nRegions of interest (ROI) reﬂecting individual plots were manually\
    \ identiﬁed on the hyperspectral\nimages using the ENVI software (v. 5.1, Harris\
    \ Corporation, Melbourne, FL, USA). For each ROI,\nthe average spectrum was extracted.\
    \ At 102 and 152 das, canopy height measurements were extracted\nfrom the DSM\
    \ computed from the hyperspectral drone images (CHDSM). CHDSM for each plot was\n\
    calculated as the difference between the average canopy elevation extracted from\
    \ a ROI on the ﬁrst\nthird of the plot (1.8 m2, 3500 pixels ± 500) and the average\
    \ soil elevation extracted in front of each\nplot (1.8 m2, 3500 pixels ± 500),\
    \ respectively.\nFor each date of measurement and each plot, 123 published SIs\
    \ were computed using the ﬁeld\nspectrometer measurements. Seventy-seven SIs (reduced\
    \ spectral range) were calculated from the\nhyperspectral images using the closest\
    \ available channels for the SI calculation. The number of\nSIs was reduced subsequently\
    \ for both spectral devices using a correlation matrix as described by\nJoalland\
    \ et al. [13] to a small number of SIs, reﬂecting a range of traits, selected\
    \ for further analysis\n(Table 2). In brief, SIs highly inter-correlated to each\
    \ other (Pearson’s correlation coefﬁcient p > 0.8)\nwere grouped. One SI was then\
    \ selected for each group. Selected SIs reﬂect the broad range of traits\nfor\
    \ which the SIs were initially developed.\nTable 2. Selected SIs, their respective\
    \ equations (ﬁeld spectrometer), the proposed detection trait\nand references.\n\
    SIs\nEquation\nTraits\nReference\nNDVI\n(R800 − R680)/(R800 + R680)\nBiomass,\
    \ coverage\n[44]\n780/740\nR780/R740\nNitrogen content\n[45]\n780/700\nR780/R700\n\
    Nitrogen content\n[45]\nTCARI\n3 × [(R700 − R670) − 0.2 × (R700 − R550) × (R700/R670)]\n\
    Chlorophyll content\n[46]\nTGI\n−0.5×[(W670 − W480)×(R670 − R550) − (W670 − W550)×(R670\
    \ − R480)]\nChlorophyll content\n[47]\nANTH\nR760 − R800 × (1/R540 − R560 − 1/R690\
    \ − R710)\nAnthocyanins\n[48]\nCHLG\n(R760 − R800)/(R540 − R560)\nChlorophyll\
    \ content\n[48]\nPRI\n(R531 − R570)/(R531 + R570)\nStress\n[49]\nNDWI\n(R860 −\
    \ R1240)/(R860 + R1240)\nPlant water status\n[50]\nRemote Sens. 2018, 10, 787\n\
    7 of 21\nTable 2. Cont.\nNDWI1650\n(R840 − R1650)/(R840 + R1650)\nPlant water\
    \ status\n[51]\nWI\n(R900/R970)\nPlant water status\n[52]\nHI\n(R534 − R698)/(R534\
    \ + R698) − R704/2\nPlant health\n[53]\n2.5. Statistical Data Analysis\nData were\
    \ analyzed with the statistical program R [54]. Beet fresh weight, white sugar\
    \ yield\nand BCN population were exposed to analysis of variance (ANOVA) at a\
    \ signiﬁcance level of 0.05.\nANOVA was used to compare and differentiate the\
    \ cultivars for the computed or measured traits.\nPCA (Principal component analysis)\
    \ was performed using the main selected phenotyping parameters\ncomputed from\
    \ the inﬁeld measurements (thermal images and ﬁeld spectrometer) and the UAV\n\
    hyperspectral imager respectively.\nTo build decision trees we used the WEKA software\
    \ (The Waikato Environment for Knowledge\nAnalysis v. 3.8, 2016) and the J48 algorithm\
    \ [55]. The decision trees were calibrated and cross-validated\nusing an n-fold\
    \ approach with n = 10 [56]. This cross-validation is considered as a conservative\n\
    estimation of model accuracy. The total dataset was partitioned into 10 groups\
    \ and 10 new subsets\nof the total were created using nine out of the 10. Ten\
    \ test trees were then built using the reduced\ndatasets; the unused 10% in each\
    \ case was used to compute the classiﬁcation error for each tree.\nOnce the 10\
    \ test trees were built, their classiﬁcation error rate as a function of tree\
    \ size was averaged.\nFinally, the reference tree was pruned to the number of\
    \ nodes matching the size that produced the\nminimum cross validation cost [57].\
    \ The decision trees were built for two sets of data: (1) Ground\nphenotyping\
    \ (123 SIs, TC and CHruler) and (2) UAV derived parameters (77 SIs, CHDSM) at\
    \ 102 and\n152 das.\n3. Results\n3.1. Spatial BCN Distribution in the Field\n\
    The spatial distribution of the initial BCN population density varied strongly\
    \ throughout the\nexperimental ﬁeld (Figure 1). At sowing, BCN population densities\
    \ ranged from 306 to 2284 J2s\nper 100 g of the topsoil and from 320 to 3457 J2s\
    \ per 100 g in the subsoil. Overall, BCN population\ndistribution was relatively\
    \ even and high, with 90% of the plots infested with more than 600 J2s per\n100\
    \ g of soil (Figure 1c).\nThe initial BCN population density per treatment (cultivar)\
    \ varied from 814 to 1283 J2s per 100 g\nsoil on average in the topsoil (CV of\
    \ 15%) (Table 3). There was no signiﬁcant difference between the\ninitial BCN\
    \ infestations of the treatments, which were all affected by a high BCN pressure\
    \ on average.\nThe ratio pf/pi is an indicator for reproduction and represents\
    \ the ability of the cultivar to prevent\nnematode reproduction in the roots [58].\
    \ The reproduction index pf/pi in the topsoil was on average\n1.1 for the tolerant\
    \ cultivars and 8.6 for the susceptible cultivars (Figure 2). Tolerant cultivars\
    \ B and D\nperformed the best with an average pf/pi ratio below one (0.65 and\
    \ 0.55, respectively).\n3.2. Beet Fresh Weight and Nematode Population\nThe tolerant\
    \ cultivars produced higher beet fresh weight (BFW) than the susceptible cultivars.\n\
    The highest white sugar yield (WSY) of 17.17 t ha−1 was observed for the tolerant\
    \ cultivar D.\nOn average, BFW and WSY were signiﬁcantly higher for the tolerant\
    \ cultivars compared to the\nsusceptible ones (on average +18% and +17%, respectively).\
    \ There was no signiﬁcant correlation\nbetween the initial BCN population density\
    \ and the yield of the different cultivars. Thus, we assume\nyield differences\
    \ between cultivars were not caused by differences in initial BCN population density\n\
    but by differences in the cultivar response to nematodes.\nFor both susceptible\
    \ and tolerant cultivars, ﬁnal beet fresh weight was not signiﬁcantly correlated\n\
    with the pf/pi ratio (Figure 3). However, there was a trend showing that the more\
    \ nematodes reproduce\nRemote Sens. 2018, 10, 787\n8 of 21\nin the roots, the\
    \ higher is the yield-reducing effect. This trend was higher for the susceptible\
    \ cultivars\n(R2 = 0.58, p = 0.24) than for the tolerant ones (R2 = 0.28, p =\
    \ 0.37).\nTable 3. Beet fresh weigh, white sugar yield and initial BCN population\
    \ density of each sugar beet\ncultivar. Displayed, are the mean ± standard error\
    \ of each treatment. Different lower case letters\nwithin each column indicate\
    \ signiﬁcant differences between genotypes (p < 0.05).\nCultivar Type\nGenotype\n\
    Beet Fresh Weight (t)\nWhite Sugar Yield (t)\nInitial BCN Population\n(Number\
    \ of J2s per 100 g soil)\nSusceptible\nSusceptible A\n73.27 ± 1.39 a\n12.13 ±\
    \ 0.23 a\n1283 ± 131 a\nSusceptible B\n78.08 ± 2.30 a\n13.63 ± 0.44 b\n886 ± 144\
    \ a\nSusceptible C\n69.10 ± 1.18 c\n13.00 ± 0.22 b\n919 ± 94 a\nSusceptible D\n\
    83.56 ± 2.05 d\n15.14 ± 0.38 cd\n1073 ± 140 a\nAverage\n76.00 ± 1.09\n13.48 ±\
    \ 0.22\n1031\nTolerant\nTolerant A1\n91.41 ± 1.01 bf\n15.52 ± 0.17 c\n1160 ± 126\
    \ a\nTolerant A2\n85.48 ± 0.97 d\n14.80 ± 0.14 d\n1134 ± 128 a\nTolerant B\n87.99\
    \ ±1.53 ef\n15.60 ± 0.30 c\n1512 ± 62 a\nTolerant C\n87.30 ± 0.80 de\n15.81 ±\
    \ 0.22 c\n814 ± 90 a\nTolerant D\n94.66 ± 1.13 b\n17.17 ± 0.19 e\n1154 ± 103 a\n\
    Average\n89.37 ± 0.63\n15.78 ± 0.13\n1026\nFigure 2. Average initial pi and pf\
    \ BCN population in the soil for nine different cultivars. Error bars\nrepresent\
    \ the standard error. Different letters behind pf/pi values indicate significant\
    \ differences at p < 0.05.\nFigure 3. Beet fresh weight at harvest as a function\
    \ of the nematode reproduction rate (pf/pi) in the\nsoil for the four susceptible\
    \ and ﬁve tolerant genotypes. Correlations were not signiﬁcant.\nRemote Sens.\
    \ 2018, 10, 787\n9 of 21\n3.3. Canopy Height Measurements\nCHDSM and CHruler showed\
    \ a good correlation 102 das (R2 = 0.55, p < 0.01) demonstrating that\nthe DSM\
    \ derived from a UAV platform is a valuable source to evaluate the canopy height\
    \ (Figure 4a).\nThe error on the canopy height evaluation was less than 3 cm.\
    \ The DSM tends to underestimate the\nCHruler by 14.5 cm measured in the middle\
    \ of rows. However, the amount of CHruler measurements\nwas limited in number\
    \ due to the need for physically entering the ﬁeld and plot. The relatively\n\
    high underestimation is likely caused by the selective use of the middle row height\
    \ only for CHruler,\nbeing higher than the average plot height reﬂected by CHDSM\
    \ because inter-row height were not\nmeasured on the ground. Nevertheless, CHruler\
    \ reﬂects a genotype speciﬁc height measure sufﬁcient\nto differentiate tolerant\
    \ and susceptible genotypes. Therefore, we consider CHDSM as equivalent or\neven\
    \ better.\nSugar yield prediction power using CHDSM extracted 152 das was weak\
    \ but signiﬁcant (R2 = 0.39,\np < 0.01).\nHowever, CHDSM of the tolerant cultivars\
    \ was signiﬁcantly higher than the CHDSM of the\nsusceptible ones at the two dates\
    \ of measurements (Figure 4d), which was not the case for CHruler,\nwhere no signiﬁcant\
    \ differences were observed between the two types of cultivars 102 das (Figure\
    \ 4c).\nInterestingly, CHDSM of susceptible cultivars was signiﬁcantly lower by\
    \ 1.4 cm at the measurement on\n152 das, while CHDSM of the tolerant cultivars\
    \ signiﬁcantly increased by 3.6 cm during the same time.\nFigure 4. (A) Relationship\
    \ between canopy height derived from the digital elevation model (CHDSM)\nand\
    \ canopy measured by a ruler (CHruler) 102 das (n = 104, p < 0.01); (B) ﬁnal sugar\
    \ yield as a function\nof the CHDSM 152 das (n = 104, p < 0.01); (C) average CHruler\
    \ of tolerant and susceptible cultivars\n102 das; (D) average CHDSM of tolerant\
    \ and susceptible cultivars 102 and 152 das. Error bars represent\nthe standard\
    \ error. Different lower case letters indicate signiﬁcant differences between\
    \ cultivar types at\np < 0.05.\nRemote Sens. 2018, 10, 787\n10 of 21\n3.4. Thermography\n\
    Canopy temperature (TC) allowed us to rank cultivars according to their ability\
    \ to cool down under\nmoderate environmental stress (TAIR 28.7 ◦C, RH 54%). Average\
    \ TC of the susceptible cultivars was\nsigniﬁcantly higher than TC of the tolerant\
    \ ones (24.7 ◦C ± 0.1 vs. 23.8 ± 0.1 on average). The average\ncooling effect\
    \ of the tolerant cultivars was 5.4% higher than that of the susceptible cultivars\
    \ (data not\nshown). Three susceptible cultivars displayed the highest TC (Figure\
    \ 5). Susceptible cultivar D\ndisplayed a TC similar to the tolerant cultivars.\n\
    Figure 5. Average canopy temperatures of ﬁve tolerant and four susceptible cultivars\
    \ 153 das. Error bars\nrepresent the standard error. Different lower case letters\
    \ indicate signiﬁcant differences between\ngenotypes (p < 0.05).\nRelationships\
    \ between TC and sugar yield are presented at the plot and cultivar levels in\
    \ Figure 6.\nAt the plot level, high correlations could be observed between the\
    \ canopy temperature and the white\nsugar yield for the susceptible cultivars\
    \ (R2 = 0.40, p < 0.01). The correlation was very high at the\ncultivar level\
    \ for the susceptible cultivars (R2 = 0.99, p < 0.01). In contrast, no correlation\
    \ between TC\nand ﬁnal yield could be observed for the tolerant cultivars.\nFigure\
    \ 6. White sugar yield at harvest as a function of the canopy temperature 152\
    \ das at the (A) plot\nand (B) cultivar levels.\nRemote Sens. 2018, 10, 787\n\
    11 of 21\n3.5. Spectrometry and UAV Hyperspectral Imaging\n3.5.1. Discrimination\
    \ of Susceptible and Tolerant Cultivars\nWe found several SIs suitable for discriminating\
    \ susceptible and tolerant cultivars of each group\nfor both ﬁeld spectroscopy\
    \ and UAV hyperspectral imaging (Table 4). The selected SIs reﬂect plant\ntraits\
    \ such as leaf chlorophyll and water content, leaf area index, and biomass which\
    \ are expected\nto be affected by severe BCN infestation. Surprisingly, it was\
    \ not possible to ﬁnd SIs to signiﬁcantly\ndiscriminate susceptible and tolerant\
    \ cultivars at 88 das; this was likely related to the subtle or small\ndifferences\
    \ related to the small plant size in early growth stages. For later stages, the\
    \ SIs HI, CHLG or\n780/700 were particularly suitable for differentiating susceptible\
    \ and tolerant cultivars over two dates\nof measurements and three different cultivars.\
    \ After 102 days, the main differences between susceptible\nand tolerant cultivars\
    \ were related to biomass (NDVI), chlorophyll content of the leaves (780/700,\n\
    CHLG) and general stress (HI). At 152 das, susceptible cultivars could also be\
    \ differentiated from the\ntolerant ones using the SIs related to water content\
    \ (NDWI1650, NDWI). The range of the hyperspectral\nimager on the UAV did not\
    \ include short wave infrared bands, which prevented the calculation of\nspectral\
    \ indices related to the water absorption bands. SIs extracted from the UAV hyperspectral\n\
    device were not able to differentiate between the two types of cultivars from\
    \ group C.\nTable 4. SIs that allow statistical discrimination of susceptible\
    \ and tolerant cultivars in each group\n(p < 0.05). (A) Field spectrometer; (B)\
    \ UAV hyperspectral imager. SIs common to both tools are\nhighlighted in bold.\n\
    (A)\nExperiment 1\nExperiment 2\nSus A/Tol A1–Tol A2\nSus B/Tol B\nSus C/Tol C\n\
    Sus D/Tol D\n88 das\n102 das\n780/700\nHI\nCHLG\nPRI\nNDVI\n780/700\nCHLG\nHI\n\
    PRI\nTGI\nANTH\nHI\nNDWI1650\nNDWI\nHI\n152 das\n780/700\nHI\nTGI\nPRI\nCHLG\n\
    TCARI\nNDWI1650\nCHLG\nNDWI\nNDWI1650\nPRI\nTCARI\nTGI\nANTH\nHI\nNDWI1650\n780/700\n\
    ANTH\nCHLG\nNDVI\nNDWI\nNDWI1650\n(B)\nExperiment 1\nExperiment 2\nSus A/Tol A1–Tol\
    \ A2\nSus B/Tol B\nSus C/Tol C\nSus D/Tol D\n102 das\nCHLG\nHI\nANTH\nPRI\nCHLG\n\
    ANTH\nPRI\nCHLG\nHI\nANTH\nPRI\n152 das\nCHLG\nANTH\nTGI\nHI\n785/705\nNDVI\n\
    CHLG\nANTH\nHI\nCHLG\nANTH\nTGI\nHI\n785/705\n3.5.2. Correlations with the Yield\
    \ in Susceptible and Tolerant Cultivars\nBest correlations between SIs and the\
    \ ﬁnal sugar yield were obtained for susceptible cultivars\n(Table 5). Correlations\
    \ were higher using SIs from the ﬁeld spectrometer than from the hyperspectral\n\
    imager.\nFor the imager, signiﬁcant correlations to sugar yield were only found\
    \ after 102 days.\nAlready after 88 days, SIs related to chlorophyll content (780/700,\
    \ CHLG) or water content (NDWI1650,\nRemote Sens. 2018, 10, 787\n12 of 21\nWI)\
    \ allowed to predict the ﬁnal sugar yield for the susceptible cultivars (Table\
    \ 5). Correlations between\nSIs and ﬁnal yield were lower for the tolerant cultivars\
    \ at the two ﬁrst dates of measurements. 152 das\nprediction of yield was good\
    \ for both types of cultivars.\nTable 5. Coefﬁcient of determination R2 for the\
    \ relationship between SIs and white sugar yield for\nsusceptible and tolerant\
    \ cultivars at different measurement times. (A) Field spectrometer; (B) UAV\n\
    hyperspectral imager. * indicates signiﬁcant correlations (n = 56 for the susceptible\
    \ and n = 40 for the\ntolerant cultivar, p < 0.05).\nSpectral Vegetation Index\n\
    88 Das\n102 Das\n152 Das\nSusceptible\nTolerant\nSusceptible\nTolerant\nSusceptible\n\
    Tolerant\n(A)\n780/740\n0.47 *\n0.12\n0.73 *\n0.40 *\n0.70 *\n0.62 *\n780/700\n\
    0.62 *\n0.42 *\n0.67 *\n0.39 *\n0.63 *\n0.62 *\nCHLG\n0.46 *\n0.38 *\n0.66*\n\
    0.37 *\n0.64 *\n0.62 *\nHI\n0.22\n0.61 *\n0.33\n0.32\n0.20\nNDVI\n0.57 *\n0.42\
    \ *\n0.59 *\n0.49 *\n0.61 *\n0.49 *\nNDWI1650\n0.71 *\n0.27\n0.56 *\n0.52 *\n\
    WI\n0.71 *\n0.28\n0.57 *\n0.56 *\n(B)\n785/555\n0.62 *\n0.34 *\n0.21\n0.21\nANTH\n\
    0.64 *\n0.34 *\n0.20\n0.21\nCHLG\n0.61 *\n0.34 *\n0.20\n0.21\nHI\n0.36 *\n0.23\n\
    0.13\n3.5.3. Field Spectrometer versus UAV Hyperspectral Imager\nGood correlations\
    \ were observed for the determination of the CHLG index between both\nspectrometers\
    \ at the two dates of measurements (Figure 7). Other indices related to chlorophyll\n\
    (780/700, ANTH) or photosynthesis (TGI) were well correlated after 152 das. The\
    \ two methods\ndiffered signiﬁcantly in terms of the values of HI. At 102 das,\
    \ values of most of the indices were not\nconsistent between both sensors.\nFigure\
    \ 7. (A) Coefﬁcient of determination R2 for the relationship between SIs computed\
    \ from the ﬁeld\nspectrometer and from the UAV hyperspectral imager. * Signiﬁcant\
    \ correlations (n = 96, p < 0.05);\n(B) relationship between CHLG index computed\
    \ from ﬁeld spectrometer and UAV hyperspectral\nimager at 102 (p < 0.01) and 152\
    \ das (p < 0.01).\nRemote Sens. 2018, 10, 787\n13 of 21\n3.6. Multivariate Analysis\n\
    Studying single parameters allowed to differentiate between susceptible and tolerant\
    \ cultivars\nfrom the same group and to predict yield with a fairly good accuracy.\
    \ Multivariate analysis allowed us\nto go further and discriminate between the\
    \ type of cultivars independently from the group.\nTwo PCA were performed separately\
    \ using ground data (PCAground) and UAV data (PCAUAV)\non the third date of measurements\
    \ 152 das (Figure 8). Sugar yield and beet fresh weight were\nused as explanatory\
    \ variables. In the PCAground, 81% of the variance is explained by the two ﬁrst\n\
    principal components (Figure 8a,b). Results conﬁrmed that high canopy temperature\
    \ is correlated\nto yield reduction. Canopy temperature and HI appeared particularly\
    \ suitable for differentiating\nsusceptible and tolerant cultivars (Figure 8a).\
    \ Cultivars from breeder A and D could be easily\ndiscriminated using indices\
    \ related to chlorophyll (CHLG, 780/700, TGI) and biomass (NDVI)\n(Figure 8b).\
    \ Cultivars from the two other companies showed a similar proﬁle in terms of canopy\n\
    reﬂectance. Overall, principal component F2 represents the ability of the sugar\
    \ beets to tolerate\nnematodes while principal component F1 seems more related\
    \ to the genetic background of the plants.\nFigure 8.\nPrincipal component analysis\
    \ (PCA) of the main phenotyping parameters 152 das.\nThe percentage of variance\
    \ explained by each component is displayed in parentheses. (A,B) Display\nPCA\
    \ using ground data (main ﬁeld spectrometer SIs and canopy temperature); (C,D)\
    \ show PCA using\nmain SIs and canopy height extracted from the UAV. The susceptible\
    \ and tolerant cultivars are depicted\nin blue and orange, respectively in graphs\
    \ (A,C). The genetic background (breeder) are shown in\ndifferent colors (graphs\
    \ (B,D)). Each data point represents one ﬁeld plot (n = 96).\nRemote Sens. 2018,\
    \ 10, 787\n14 of 21\nThe differences observed between PCAground and PCAUAV conﬁrms\
    \ the low correlations between\nSIs computed from the ﬁeld spectrometer and from\
    \ the UAV hyperspectral imager. Variables used did\nnot allow us to discriminate\
    \ easily between the types of cultivars (Figure 8c). One reason is surely the\n\
    missing thermal data at the UAV level. Another reason is that height measurements\
    \ at ground level\nwere not sufﬁcient to reveal genotypic differences between\
    \ the investigated sugar beet types, which in\ncontrast UAV-based height measurements\
    \ could show on plot level. PCAUAV conﬁrmed the close\nrelationship between canopy\
    \ height and sugar yield at this advanced stage of the sugar beet growth.\nCultivars\
    \ from groups A and D could be differentiated using CHLG and TGI indices conﬁrming\
    \ the\ngood ability of chlorophyll related indices for the characterization of\
    \ genetic background.\n3.7. Decision Trees\nThe univariate decision trees (UDT)\
    \ were used to classify sugar beet according to the type of\ncultivar (susceptible\
    \ or tolerant) or the genetic background (breeder) using multiple traits. The\
    \ cross\nvalidation produced accurate results without an independent dataset for\
    \ assessing the accuracy of\nthe model [59]. We found that decision trees could\
    \ classify cultivar type and genetic background\nusing just a few parameters (Table\
    \ 6). Model accuracy was very similar using parameters evaluated\nat the ground\
    \ level and information sensed with the UAV hyperspectral imager. Average cultivar\n\
    classiﬁcation accuracy was 77% and 83% on 102 and 152 das, respectively. Classiﬁcation\
    \ of plots\nwas slightly higher for the type of cultivars compared to the genetic\
    \ background of the cultivars.\nOverall coefﬁcients of agreement were good. The\
    \ Kappa coefﬁcient varied from 0.46, which can be\nconsidered as a “moderate”\
    \ agreement to 0.74, which corresponds to a “substantial” agreement [60].\nTable\
    \ 6. Decision tree classiﬁcation accuracy (10-fold cross-validation) for cultivar\
    \ BCN tolerance type\nand genetic background (breeder) using ground data and UAV-based\
    \ imager data. Kappa coefﬁcient\nrepresents the degree of beyond-chance agreement.\
    \ 96 plots were considered in the analysis.\nTrait Detection Level\nDas\nClassiﬁcation\
    \ Accuracy “Type of\nCultivars” (Kappa)\nClassiﬁcation Accuracy “Genetic\nBackground”\
    \ (Kappa)\nField parameters\n(123 SIs + Tc + CHruler)\n102\n0.74 (0.46)\n0.76\
    \ (0.61)\n152\n0.78 (0.55)\n0.76 (0.63)\nUAV based imager\n(77 SIs + CHDSM)\n\
    102\n0.79 (0.57)\n0.72 (0.56)\n152\n0.88 (0.74)\n0.68 (0.53)\nInterestingly the\
    \ best classiﬁcation between tolerant or susceptible cultivars was obtained 152\
    \ das\nusing the UAV information with 88%. The UDT using UAV based data for the\
    \ classiﬁcation of\nsusceptible or tolerant cultivars used the CHDSM as a main\
    \ parameter for classiﬁcation. This was\nnot the case for the classiﬁcation according\
    \ to the genetic background. Overall, information related\nto vegetation density,\
    \ height, water content and pigment content in the leaves were suitable for\n\
    cultivar type classiﬁcation (see the Supplementary Materials). Physiological information\
    \ related to\nphotosynthesis, canopy temperature, nitrogen content and water content\
    \ were selected in the UDT to\ndifferentiate genetic backgrounds.\n4. Discussion\n\
    The results of this study demonstrated that ground-based and airborne phenotyping\
    \ methods\nincluding imaging, spectrometry and thermometry can be used in the\
    \ ﬁeld to evaluate the level of beet\ncyst nematode (BCN) tolerance of sugar beet\
    \ cultivars and predict sugar yield.\nInfestation levels observed in this ﬁeld\
    \ study can be considered as moderate to high. The tolerance\nlimit, which is\
    \ the nematode population below which no damage is detectable, could not be precisely\n\
    evaluated in this study. However, it is estimated to be between 300 and 1000 J2s\
    \ per 100 g of soil for the\nnine cultivars according to the ﬁeld location and\
    \ soil temperatures observed during the season [61,62].\nUnder such nematode stress,\
    \ it was possible to rank cultivars according to their ability to withstand or\n\
    Remote Sens. 2018, 10, 787\n15 of 21\nrecover from the nematode attack and yield\
    \ well. As expected, the ﬁve cultivars described as tolerant\nshowed higher yield\
    \ than the ones known to be susceptible [63]. The high nematode multiplication\
    \ rate\nobserved in the four susceptible cultivars is aligned with the lower yield\
    \ observed for these cultivars.\nInterestingly, two tolerant cultivars (B and\
    \ D) presented a multiplication rate below one, indicating\nthem as resistant\
    \ since they decreased the nematode population in the ﬁeld [40,64]. Cultivar D\n\
    combines high tolerance (high yield under nematode infestation) and high resistance\
    \ (prevention of\nnematode multiplication), which is of advantage for use in infested\
    \ ﬁelds. No signiﬁcant correlation\ncould be found between the initial number\
    \ of BCN and the ﬁnal yield. This was also shown by\nReuther et al. [40] and may\
    \ possibly be explained by the range of initial BCN population in the ﬁeld,\n\
    which was above the damage threshold.\nCanopy height extracted from the DSM allowed\
    \ us to differentiate between susceptible and\ntolerant cultivars which was not\
    \ the case for the manual measurements CHruler. Since CHDSM takes\napproximately\
    \ 3500 pixels representing single height estimates it can be assumed that the\
    \ derived\naverage canopy height is more realistic compared to the too few ground\
    \ measurements per plot.\nThis clearly shows a beneﬁt of UAV-based imaging evaluation\
    \ of traits such as canopy height that\nrequire lots of time and effort for manual\
    \ evaluation in the ﬁeld. The higher CHDSM differences\nbetween susceptible and\
    \ tolerant cultivars observed 152 das can be explained by the higher nematode\n\
    effect on susceptible cultivars, which increased over the season in contrast to\
    \ the tolerant ones.\nHowever, DSM estimates can likely be improved with a higher\
    \ overlap of images and crosswise\nﬂight paths and eventually a lower ﬂying altitude.\
    \ Additionally, stationary markers as used in [35]\nfor geo-localization will\
    \ further improve UAV-based height measurements. Such markers will also\nfacilitate\
    \ automated feature extraction based on geo-coordinates and thus reduce data extraction\
    \ time.\nThe canopy temperature (TC) showed high potential for classifying cultivars\
    \ according to their\nsusceptibility or tolerance to nematodes. Three out of four\
    \ susceptible cultivars had the highest TC,\nreﬂecting the lower ability of these\
    \ plants to transpire water and thus cool down. TC is closely correlated\nwith\
    \ the prevailing temperature of the local environment, the leaf transpiration\
    \ rate and the stomatal\nconductance [30,42,65,66]. BCN damage in the roots decreases\
    \ water uptake, which subsequently\nreduces the leaf transpiration rate and results\
    \ in a higher TC [67–69]. The high correlation observed\nbetween TC and ﬁnal sugar\
    \ yield for the susceptible cultivars likely reﬂects the nematode damage\neffect.\
    \ The higher the BCN damage on the roots is, the higher is the TC. Schmitz et\
    \ al. [20] and\nJoalland et al. [13] had similar results for susceptible cultivars\
    \ under ﬁeld and semi-ﬁeld conditions,\nrespectively. That no correlation was\
    \ observed for tolerant cultivars is likely related to the less affected\nwater\
    \ uptake and transpiration rate compared to those of susceptible cultivars [70–72].\
    \ Thus, TC is\nsuitable to determine the level of susceptibility but less for\
    \ determination of tolerance level or to\npredict ﬁnal yield.\nSIs were found\
    \ to be useful indicators for quantitative and qualitative evaluation of the sugar\n\
    beet canopy. Under moderate to high BCN infestation, single SIs related to chlorophyll\
    \ content (CHLG),\nphotosynthetic activity (PRI), plant biomass (NDVI) or general\
    \ stress (HI) were able to discriminate tolerant\nand susceptible cultivars from\
    \ the same breeder (same genetic background). This is in line with many\nstudies\
    \ using spectroscopy methods to investigate genotype trials or plant stress detection\
    \ [11,19,27,53].\nThus, for crop improvement studies or other experimental trials,\
    \ spectrometry and/or spectral imaging is\na fast and reliable screening method\
    \ to characterize and rank different cultivars from the same genetic\nbackground\
    \ according to their reaction to treatments or stresses. Here, we were able to\
    \ demonstrate this\nfor sugar beet cultivars and for their ability to tolerate\
    \ nematodes. Yet, when the genetic background\nbetween cultivars differed widely\
    \ (namely between cultivars from different seed companies), it was not\npossible\
    \ to use a single SI to robustly discriminate the tolerant and susceptible cultivars.\
    \ Here, the use\nof several relatively independent SIs was needed to identify\
    \ the type of cultivars under BCN infestation.\nCombining SIs and thermal information\
    \ integrates various aspects of plant growth and development\nsuch as canopy structure,\
    \ biomass, pigment and water content, and photosynthetic activity, so such\nRemote\
    \ Sens. 2018, 10, 787\n16 of 21\na combination can be a powerful tool to classify\
    \ cultivars, even in experiments incorporating high\ngenetic diversity.\nIn this\
    \ study we combined the various measured parameters by using decision trees.\n\
    After 152 days, CHDSM, chlorophyll- and water-content-related SIs were essential\
    \ for discrimination\nbetween susceptible and tolerant cultivars, which demonstrates\
    \ the high diversity and non-speciﬁcity\nof nematode-caused symptoms [6].\nInterestingly,\
    \ cultivars from group A and group D could be classiﬁed with high accuracy. This\
    \ is\nclearly reﬂected in the PCA where plots from both groups were separately\
    \ clustered. Such results\nillustrate the high variability caused by the intrinsic\
    \ genetic background of each breeder, which is\nreﬂected in the plant physiology\
    \ (water content, pigment concentration, photosynthetic activity)\nand plant performance\
    \ (CHDSM, biomass). Cultivars that were bred using different germplasm\npools\
    \ may display very different reﬂectance spectra although depicting a similar tolerance\
    \ level.\nWhile CHDSM appeared as an important parameter for the cultivar type\
    \ classiﬁcation, it was not useful\nfor classiﬁcation of the breeder.\nSIs related\
    \ to leaf chlorophyll showed high correlations with the ﬁnal sugar yield for all\n\
    ground and aerial measurements for the susceptible cultivars. This observation\
    \ is consistent with\nthe observation that more nematode damage on the roots triggers\
    \ more visible symptoms on the\nshoots and thus causes yield reduction. As early\
    \ as 88 das, SIs related to nitrogen status and water\ncontent such as 780/700\
    \ and NDWI, respectively could be used to predict yield with high precision.\n\
    Hillnhütter et al. [19] also showed correlations between water content or leaf\
    \ pigment related SIs and\nbeet fresh weight in an infested ﬁeld. However, yield\
    \ prediction on tolerant cultivars was best after\n152 days, when environmental\
    \ conditions were more constraining (air temperature 28.7 ◦C, RH 54%)\nand likely\
    \ the nematode stress affected the sugar beet growth for a longer period making\
    \ differences\nmore pronounced. Such moderate environmental stress as observed\
    \ in this ﬁeld study was obviously\nincreased by the nematode stress and allowed\
    \ to signiﬁcantly differentiate tolerant cultivars and better\npredict ﬁnal yield.\
    \ Stronger symptoms were also observed on a tolerant cultivar under semi-ﬁeld\n\
    conditions when drought stress was higher [13].\nThe data obtained from the ﬁeld\
    \ spectrometer and the hyperspectral imager were not consistently\ncorrelated,\
    \ which is also reﬂected by the differences observed between PCA computed with\
    \ ground and\nUAV data. Such partly mismatch can be explained by differences between\
    \ sensors and the measurement\nand calibration procedure. The instruments used\
    \ have different sensor and ﬁlter technology causing\ndifferent spectral resolution\
    \ and spectral response, which causes the slightly altered shape of the\nderived\
    \ spectra. The ﬁeld spectrometer had a very high resolution, while the hyperspectral\
    \ imager\nhad a lower spectral resolution. As a consequence, some SIs, such as\
    \ HI, were computed using slightly\ndifferent bands, which resulted in low correlation\
    \ between them [19]. In addition, the ground sampling\nresolution differed between\
    \ the two measurement approaches. Whereas the average spectra per\nplot for the\
    \ ﬁeld spectrometer are the average of ﬁve point measurements with a footprint\
    \ of about\n50 cm diameter at random locations in each plot, the plot spectra\
    \ obtained from the hyperspectral\nimaging were an average of thousands of pixels\
    \ with an instantaneous ﬁeld of view (ifov) of two\ncm. Further, the processing\
    \ and calibration steps of both instruments differ. The ﬁeld spectrometer\nis\
    \ calibrated every 15 measurements (every three plots) using a white reference.\
    \ The hyperspectral\nimages are orthomosaicked using structure from motion procedures\
    \ in Agisoft software before being\ncalibrated to reﬂectance with a partial least\
    \ squares regression using three reﬂectance panels differing\nin absolute reﬂectance\
    \ intensity (Figure 1). Better understanding of the procedures in the sensors\
    \ used\nand the consequences for the resulting measurements will surely improve\
    \ the use of aerial imaging\nmethods in the future. First attempts can be seen\
    \ in the standardization of calibration methodology\nand cross validation [73].\n\
    Although SIs computed from the ﬁeld spectrometer and from the spectral imager\
    \ were not fully\nconsistent, results and conclusions regarding the sugar beet\
    \ phenotype were similar. Both tools\nwere able to detect stress caused by nematodes\
    \ and predict the ﬁnal yield. This showed the great\nRemote Sens. 2018, 10, 787\n\
    17 of 21\npotential of UAV hyperspectral imagery to generate maps of nematode\
    \ symptoms and yield potential\nof sugar beets with a high throughput. Such maps,\
    \ combined with a reduced number of soil samples\nin the ﬁeld to conﬁrm the presence\
    \ of nematodes, allow determination of spatial distribution and\ndensity of nematode\
    \ infestation in agricultural ﬁelds. Such knowledge may help to select the right\n\
    countermeasure such as optimized crop rotations or use of catch crops or appropriate\
    \ tolerant sugar\nbeet cultivars. For breeding purposes, such technology can make\
    \ selection monitoring more efﬁcient\nand thus accelerate crop improvement [74].\
    \ In our experimental ﬁeld, tolerant and susceptible cultivars\ncould be classiﬁed\
    \ with an accuracy of over 80% on average. Speciﬁc SIs alone or combined and\n\
    added to canopy height and temperature information have the ability to quantify\
    \ traits related to\nBCN damage and to ﬁnal sugar yield. Cultivar response to\
    \ nematodes can be deduced in a fast and\nefﬁcient manner and might be linked\
    \ to physiological traits such as chlorophyll and water content,\nplant biomass\
    \ or photosynthesis rate. Such a targeted analysis of traits will signiﬁcantly\
    \ improve the\nefﬁciency of sugar beet breeding for nematode tolerance and resistance.\n\
    5. Conclusions\nRemote sensing methods were able to identify BCN symptoms on sugar\
    \ beet plants and\ndiscriminate the type of cultivars under real ﬁeld conditions.\
    \ While thermography appeared suitable\nfor yield prediction on susceptible cultivars\
    \ only, ﬁeld spectrometry and aerial UAV hyperspectral\nimaging were able to predict\
    \ yield on susceptible and tolerant cultivars, likewise. Despite disparities\n\
    in spectral and spatial resolution, both spectral tools can be used to characterize\
    \ nematode symptoms\nand classify cultivars. Multivariate methods were precious\
    \ tools to identify genetic backgrounds of\nthe sugar beet cultivars and their\
    \ ability to tolerate nematodes using a diversity of spectral indices.\nThe UAV\
    \ equipped with a hyperspectral imager proved to be a valuable tool for BCN stress\
    \ diagnosis\nin the ﬁeld and for improving breeding efﬁciency facilitating the\
    \ monitoring of multiple traits at the\nsame time and potentially at multiple\
    \ sites. The most valuable remotely sensed traits to monitor\nfor BCN tolerance\
    \ and yield potential were canopy height, spectrally inferred chlorophyll content,\n\
    leaf area or biomass, and canopy temperature.\nSupplementary Materials: The following\
    \ are available online at http://www.mdpi.com/2072-4292/10/5/787/s1,\nTable S1:\
    \ Classification and mis-classification matrices for BCN tolerance type of cultivar\
    \ using ground measurements\nand UAV hyperspectral data 102 and 152 das.\n(1)\
    \ Ground-102 das; (2) Ground-152 das; (3) UAV-102 das;\n(4) UAV-152 das; Table\
    \ S2: Classiﬁcation and mis-classiﬁcation matrix for genetic background (breeder)\
    \ using\nground measurements and UAV hyperspectral data 102 and 152 das. (1) Ground-102\
    \ das; (2) Ground-152 das;\n(3) UAV 102 das; (4) UAV 152 das; Table S3: Additional\
    \ SIs selected by the UDT model to classify the types of\ncultivar and genetic\
    \ background.\nAuthor Contributions: M.R., M.S. and C.L. conceived and designed\
    \ the trial. S.J. and F.L. planned and performed\nthe remote sensing campaigns\
    \ supported by C.S. and A.W. S.J., F.L. and H.V.V. analyzed the data and performed\n\
    the statistical analysis. All authors contributed to writing and reviewing of\
    \ the manuscript.\nAcknowledgments: We are very grateful for the technical support\
    \ of the “Arbeitsgemeinschaft für Versuchswesen\nund Beratung im Zuckerrübenanbau\
    \ Südwest”-ARGE Zuckerrübe Südwest (Germany) in setting up the ﬁeld\ntrial.\n\
    We also thank Marc Bonﬁls for leading the collaboration with Ruebe and making\
    \ the phenotyping\nmeasurements possible. We also thank Lukas Roth for the great\
    \ support in processing the hyperspectral UAV\ndata, Norbert Kirchgessner for\
    \ the contour map, and Verity Paul for her careful review of the manuscript and\
    \ for\nher valuable suggestions and corrections.\nConﬂicts of Interest: The authors\
    \ declare no conﬂict of interest.\nReferences\n1.\nFood and Agriculture Organization\
    \ (FAO). Global Agriculture towards 2050; Food and Agriculture Organization\n\
    (FAO): Rome, Itlay, 2009.\n2.\nMüller, J. The economic importance of Heterodera\
    \ schachtii in Europe. Helminthologia 1999, 36, 205–213.\n3.\nBiancardi, E.; McGrath,\
    \ J.M.; Panella, L.W.; Lewellen, R.T.; Stevanato, P. Sugar beet. In Root and Tuber\
    \ Crops;\nSpringer: New York, NY, USA, 2010; pp. 173–219.\nRemote Sens. 2018,\
    \ 10, 787\n18 of 21\n4.\nSteele, A.E.; Arnold, E. The host range of the sugar\
    \ beet nematode; Heterodera schachtii Schmidt. J. Am. Soc.\nSugar Beet Technol.\
    \ 1965, 13, 573–603. [CrossRef]\n5.\nHarveson, R.M.; Jackson, T.M. Sugar Beet\
    \ Cyst Nematode; University of Nebraska–Lincoln Extension:\nLincoln, NE, USA,\
    \ 2008.\n6.\nCooke, D.A. Beet cyst nematode (Heterodera schachtii Schmidt) and\
    \ its control on sugar beet. Agric. Zool. Rev.\n1987, 2, 135–183.\n7.\nSchmitz,\
    \ A.; Tartachnyk, I.I.; Kiewnick, S.; Sikora, R.A.; Kühbauch, W. Detection of\
    \ Heterodera schachtii\ninfestation in sugar beet by means of laser-induced and\
    \ pulse amplitude modulated chlorophyll ﬂuorescence.\nNematology 2006, 8, 273–286.\
    \ [CrossRef]\n8.\nHeath, W.L.; Haydock, P.P.J.; Wilcox, A.; Evans, K. The potential\
    \ use of spectral reﬂectance from the potato\ncrop for remote sensing of infection\
    \ by potato cyst nematodes. Asp. Appl. Biol. 2000, 60, 185–188.\n9.\nNutter, F.W.;\
    \ Tylka, G.L.; Guan, J.; Moreira, A.J.D.; Marett, C.C.; Rosburg, T.R. Use of remote\
    \ sensing to detect\nsoybean cyst nematode-induced plant stress. J. Nematol. 2002,\
    \ 34, 222–231. [PubMed]\n10.\nLaudien, R. Entwicklung Eines GIS-Gestützten Schlagbezogenen\
    \ Führungsinformationssystems für die\nZuckerwirtschaft. (Development of a Field-\
    \ and GIS-Based Management Information System for the Sugar\nBeet Industry). Ph.D.\
    \ Thesis, University of Hohenheim, Stuttgart, Germany, 2005.\n11.\nHillnhütter,\
    \ C.; Mahlein, A.K.; Sikora, R.A.; Oerke, E.C. Use of imaging spectroscopy to\
    \ discriminate\nsymptoms caused by Heterodera schachtii and Rhizoctonia solani\
    \ on sugar beet. Precis. Agric. 2012, 13, 17–32.\n[CrossRef]\n12.\nJoalland, S.;\
    \ Screpanti, C.; Gaume, A.; Walter, A. Belowground biomass accumulation assessed\
    \ by digital\nimage based leaf area detection. Plant Soil. 2016, 398, 257–266.\
    \ [CrossRef]\n13.\nJoalland, S.; Screpanti, C.; Liebisch, F.; Varella, H.V.; Gaume,\
    \ A.; Walter, A. Comparison of visible imaging;\nthermography and spectrometry\
    \ methods to evaluate the effect of Heterodera schachtii inoculation on sugar\n\
    beets. Plant Methods 2017, 13, 73. [CrossRef] [PubMed]\n14.\nSher-Kaul, S.; Oertli,\
    \ B.; Castella, E.; Lachavanne, J.B. Relationship between biomass and surface\
    \ area of six\nsubmerged aquatic plant species. Aquat. Bot. 1995, 51, 147–154.\
    \ [CrossRef]\n15.\nSmith, S.M.; Garrett, P.B.; Leeds, J.A.; McCormick, P.V. Evaluation\
    \ of digital photography for estimating live\nand dead aboveground biomass in\
    \ monospeciﬁc macrophyte stands. Aquat. Bot. 2000, 67, 69–77. [CrossRef]\n16.\n\
    Mizoue, N.; Masutani, T. Image analysis measure of crown condition; foliage biomass\
    \ and stem growth\nrelationships of Chamaecyparis obtusa. For. Ecol. Manag. 2003,\
    \ 172, 79–88. [CrossRef]\n17.\nTackenberg, O. A new method for non-destructive\
    \ measurement of biomass; growth rates; vertical biomass\ndistribution and dry\
    \ matter content based on digital image analysis. Ann. Bot. Lond. 2007, 99, 777–783.\n\
    [CrossRef] [PubMed]\n18.\nBaret, F.; Guyot, G. Potentials and limits of vegetation\
    \ indices for LAI and APAR assessment. Remote Sens. Environ.\n1991, 35, 161–173.\
    \ [CrossRef]\n19.\nHillnhütter, C.; Mahlein, A.K.; Sikora, R.A.; Oerke, E.C. Remote\
    \ sensing to detect plant stress induced by\nHeterodera schachtii and Rhizoctonia\
    \ solani in sugar beet ﬁelds. Field Crop Res. 2011, 122, 70–77. [CrossRef]\n20.\n\
    Schmitz, A.; Kiewnick, S.; Schlang, J.; Sikora, R.A. Use of high resolution digital\
    \ thermography to detect\nHeterodera schachtii infestation in sugar beets. Commun.\
    \ Agric. Appl. Biol. Sci. 2004, 69, 359–363. [PubMed]\n21.\nColomina, I.; Molina,\
    \ P. Unmanned aerial systems for photogrammetry and remote sensing: A review.\n\
    ISPRS J. Photogramm. Remote Sens. 2014, 92, 79–97. [CrossRef]\n22.\nAraus, J.L.;\
    \ Cairns, J. Field high-throughput phenotyping—The new crop breeding frontier.\
    \ Trends Plant Sci.\n2014, 19, 52–61. [CrossRef] [PubMed]\n23.\nWalter, A.; Liebisch,\
    \ F.; Hund, A. Plant phenotyping: From bean weighing to image analysis. Plant\
    \ Methods\n2015, 11, 14. [CrossRef] [PubMed]\n24.\nBendig, J.; Bolten, A.; Bareth,\
    \ G. Introducing a low-cost mini-UAV for thermal- and multispectral-imaging.\n\
    In Proceedings of the XXII ISPRS Congress, Melbourne, Australia, 25 August–1 September\
    \ 2012; pp. 345–349.\n25.\nGuo, T.;\nKujirai, T.;\nWatanabe, T. Mapping crop status\
    \ from an unmanned aerial vehicle for\nprecision agriculture applications. In\
    \ Proceedings of the XXII ISPRS Congress, Melbourne, Australia,\n25 August–1 September\
    \ 2012; pp. 485–490.\n26.\nPrimicerio, J.; Di Gennaro, S.F.; Fiorillo, E.; Genesio,\
    \ L.; Lugato, E.; Matese, A.; Vaccari, F.P.A. Flexible unmanned\naerial vehicle\
    \ for precision agriculture. Precis. Agric. 2012, 13, 517–523. [CrossRef]\nRemote\
    \ Sens. 2018, 10, 787\n19 of 21\n27.\nTattaris, M.; Reynolds, M.P.; Chapman, S.C.\
    \ A Direct Comparison of Remote Sensing Approaches for\nHigh-Throughput Phenotyping\
    \ in Plant Breeding. Front. Plant Sci. 2016, 7, 1131. [CrossRef] [PubMed]\n28.\n\
    Akhtman, Y.; Golubeva, E.; Tutubalina, O.; Zimin, M. Application of hyperspectral\
    \ images and ground data\nfor precision farming. Geogr. Environ. Sustain. 2017,\
    \ 10, 117–128. [CrossRef]\n29.\nConstantin, D.; Rehak, M.; Akhtman, Y.; Liebisch,\
    \ F. Detection of crop properties by means of hyperspectral\nremote sensing from\
    \ a micro UAV. In Bornimer Agrartechnische Berichte; Leibniz-Institut für Agrartechnik\n\
    Potsdam-Bornim eV: Potsdam, Germany, 2015; pp. 129–137.\n30.\nKhanna, R.; Möller,\
    \ M.; Pfeifer, J.; Liebisch, F.; Walter, A.; Siegwart, R. Beyond point clouds-3d\
    \ mapping\nand ﬁeld parameter measurements using UAVs. In Proceedings of the IEEE\
    \ 20th Conference on Emerging\nTechnologies and Factory Automation (ETFA), Luxembourg,\
    \ 8–11 September 2015; pp. 1–4.\n31.\nLiebisch, F.; Kirchgessner, N.; Schneider,\
    \ D.; Walter, A.; Hund, A. Remote, aerial phenotyping of maize traits\nwith a\
    \ mobile multi-sensor approach. Plant Methods 2015, 11, 9. [CrossRef] [PubMed]\n\
    32.\nBurkart, A.; Hecht, V.L.; Kraska, T.; Rascher, U. Phenological analysis of\
    \ unmanned aerial vehicle based time\nseries of barley imagery with high temporal\
    \ resolution. Precis. Agric. 2018, 19, 134–146. [CrossRef]\n33.\nJimenez-Bello,\
    \ M.A.; Royuela, A.; Manzano, J.; Zarco-Tejada, P.J.; Intrigliolo, D. Assessment\
    \ of drip irrigation\nsub-units using airborne thermal imagery acquired with an\
    \ Unmanned Aerial Vehicle (UAV). In Precision\nAgriculture 13; Wageningen Academic\
    \ Publishers: Wageningen, The Netherlands, 2013; pp. 705–711.\n34.\nDiaz-Varela,\
    \ R.A.; de la Rosa, R.; Leon, L.; Zarco-Tejada, P.J. High-resolution airborne\
    \ UAV imagery to assess\nolive tree crown parameters using 3D photo reconstruction:\
    \ Application in breeding trials. Remote Sens.\n2015, 7, 4213–4232. [CrossRef]\n\
    35.\nRoth, L.; Streit, B. Predicting cover crop biomass by lightweight UAS-based\
    \ RGB and NIR photography:\nAn applied photogrammetric approach. Precis. Agric.\
    \ 2017, 1–22. [CrossRef]\n36.\nSankaran, S.; Khot, L.R.; Espinoza, C.Z.; Jarolmasjed,\
    \ S.; Sathuvalli, V.R.; Vandemark, G.J.; Miklas, P.N.;\nCarter, A.H.; Pumphrey,\
    \ M.O.; Knowles, N.R.; et al. Low-altitude; high-resolution aerial imaging systems\
    \ for\nrow and ﬁeld crop phenotyping: A review. Eur. J. Agron. 2015, 70, 112–123.\
    \ [CrossRef]\n37.\nYang, G.; Liu, J.; Zhao, C.; Li, Z.; Huang, Y.; Yu, H.; Xu,\
    \ B.; Yang, X.; Zhu, D.; Zhang, X.; Zhang, R.; et al.\nUnmanned Aerial Vehicle\
    \ Remote Sensing for Field-Based Crop Phenotyping: Current Status and Perspectives.\n\
    Front. Plant Sci. 2017, 8, 1111. [CrossRef] [PubMed]\n38.\nYu, K.; Lenz-Wiedemann,\
    \ V.; Chen, X.; Bareth, G. Estimating leaf chlorophyll of barley at different\
    \ growth\nstages using spectral indices to reduce soil background and canopy structure\
    \ effects. ISPRS J. Photogramm.\n2014, 97, 58–77. [CrossRef]\n39.\nSa, I.; Chen,\
    \ Z.; Popovic, M.; Khanna, R.; Liebisch, F.; Nieto, J.; Siegwart, R. weedNet:\
    \ Dense Semantic Weed\nClassiﬁcation Using Multispectral Images and MAV for Smart\
    \ Farming. IEEE Robot. Autom. Lett. 2018, 3,\n588–595. [CrossRef]\n40.\nReuther,\
    \ M.; Lang, C.; Grundler, F.M.W. Nematode-tolerant sugar beet varieties—Resistant\
    \ or susceptible to\nthe Beet Cyst Nematode Heterodera schachtii? Sugar Ind. 2017,\
    \ 142, 277–284.\n41.\nGrosse, E.; Banasiak, L.; Lyr, H.; Jock, M. Neuer Labortest\
    \ zum Nachweis des Rübennematoden\n(Heterodera schachtii). Nachr.-Bl. Pﬂanzenschutz\
    \ DDR 1985, 39, 111–112.\n42.\nGrosse, E.; Decker, H. Untersuchungen zur Eignung\
    \ von Biotest und Schlupftest für den quantitativen Nachweis\ndes Rübenzystenälchen\
    \ (Heterodera schachtii) in Bodenproben. Nachr.-Bl. Pflanzenschutz DDR 1989, 43,\
    \ 227–230.\n43.\nOerke, E.C.; Steiner, U. Potential of digital thermography for\
    \ disease control. In Precision Crop Protection—\nThe Challenge and Use of Heterogeneity;\
    \ Oerke, E.C., Gerhards, R., Menz, G., Sikora, R.A., Eds.; Springer:\nDordrecht,\
    \ The Netherlands, 2010; pp. 167–182.\n44.\nRouse, J.W.; Haas, R.H.; Schell, J.A.;\
    \ Deering, D.W. Monitoring Vegetation Systems in the Great Plains with ERTS;\n\
    NASA: Goddard, MD, USA, 1974; Volume 351, p. 309.\n45.\nMistele, B.; Gutser, R.;\
    \ Schmidhalter, U.; Mulla, D.J. Validation of ﬁeld-scaled spectral measurements\
    \ of the\nnitrogen status in winter wheat. In Proceedings of the 7th International\
    \ Conference on Precision Agriculture\nand Other Precision Resources Management,\
    \ Hyatt Regency, Minneapolis, MN, USA, 25–28 July 2004;\nPrecision Agriculture\
    \ Center, Department of Soil, Water and Climate, University of Minnesota: Minneapolis,\n\
    MN, USA, 2004; pp. 25–28, 1187–1195.\n46.\nHaboudane, D.; Miller, J.R.; Tremblay,\
    \ N.; Zarco-Tejada, P.J.; Dextraze, L. Integrated narrow-band vegetation\nindices\
    \ for prediction of crop chlorophyll content for application to precision agriculture.\
    \ Remote Sens. Environ.\n2002, 81, 416–426. [CrossRef]\nRemote Sens. 2018, 10,\
    \ 787\n20 of 21\n47.\nHunt, E.R.; Daughtry, C.S.T.; Eitel, J.U.; Long, D.S. Remote\
    \ sensing leaf chlorophyll content using a visible\nband index. Agron. J. 2011,\
    \ 103, 1090–1099. [CrossRef]\n48.\nGitelson, A.A.; Keydan, G.P.; Merzlyak, M.N.\
    \ Three-band model for noninvasive estimation of chlorophyll;\ncarotenoids; and\
    \ anthocyanin contents in higher plant leaves. Geophys. Res. Lett. 2006, 33. [CrossRef]\n\
    49.\nGamon, J.A.; Penuelas, J.; Field, C.B. A narrow-waveband spectral index that\
    \ tracks diurnal changes in\nphotosynthetic efﬁciency. Remote Sens. Environ. 1992,\
    \ 41, 35–44. [CrossRef]\n50.\nGao, B.C. NDWI—A normalized difference water index\
    \ for remote sensing of vegetation liquid water from\nspace. Remote Sens. Environ.\
    \ 1996, 58, 257–266. [CrossRef]\n51.\nClay, D.E.; Kim, K.I.; Chang, J.; Clay,\
    \ S.A.; Dalsted, K. Characterizing water and nitrogen stress in corn using\nremote\
    \ sensing. Agron. J. 2006, 98, 579–587. [CrossRef]\n52.\nPenuelas, J.; Pinol,\
    \ J.; Ogaya, R.; Filella, I. Estimation of plant water concentration by the reﬂectance\
    \ water\nindex WI (R900/R970). Int. J. Remote Sens. 1997, 18, 2869–2875. [CrossRef]\n\
    53.\nMahlein, A.K.; Rumpf, T.; Welke, P.; Dehne, H.W.; Plümer, L.; Steiner, U.;\
    \ Oerke, E.C. Development of spectral\nindices for detecting and identifying plant\
    \ diseases. Remote Sens. Environ. 2013, 128, 21–30. [CrossRef]\n54.\nR Development\
    \ Core Team. R: A Language and Environment for Statistical Computing; R Foundation\
    \ for\nStatistical Computing: Vienna, Austria, 2008. Available online: http://www.R-project.org\
    \ (accessed on\n1 July 2017).\n55.\nWitten, I.H.; Frank, E.; Hall, M.A.; Pal,\
    \ C.J. Data Mining: Practical Machine Learning Tools and Techniques;\nMorgan Kaufmann:\
    \ Burlington, MA, USA, 2016.\n56.\nWeiss, S.M.; Kulikowski, C.A. Computer Systems\
    \ that Learn; Kaufmann Publishers: San Mateo, CA, USA, 1991.\n57.\nBreiman, L.;\
    \ Friedman, J.; Olshen, R.; Stone, C. Classiﬁcation and Regression Trees; Wadsworth\
    \ International\nGroup: Belmont, CA, USA, 1984.\n58.\nOostenbrink, M. Major characteristics\
    \ of the relations between nematodes and plants. In Proceedings of the\n8th International\
    \ Symposium of nematology, Antibes, France, 8–14 September 1966.\n59.\nSherrod,\
    \ P.H. DTREG Predictive Modeling Software. Users Manual. Available online: www.dtreg.com/\n\
    DTREG.pdf (accessed on 1 February 2018).\n60.\nLandis, J.R.; Koch, G.G. The measurement\
    \ of observer agreement for categorical data. Biometrics 1977, 33,\n159–174. [CrossRef]\
    \ [PubMed]\n61.\nSeinhorst, J.W. The relation between nematode density and damage\
    \ to plants. Nematologica 1965, 11, 137–154.\n[CrossRef]\n62.\nCooke, D.A.; Thomason,\
    \ I.J. The relationship between population density of Heterodera schachtii; soil\
    \ temperature;\nand sugarbeet yields. J. Nematol. 1979, 11, 124. [PubMed]\n63.\n\
    Hauer, M.; Koch, H.J.; Märländer, B. Water use efﬁciency of sugar beet cultivars\
    \ (Beta vulgaris L.) susceptible;\ntolerant or resistant to Heterodera schachtii\
    \ (Schmidt) in environments with contrasting infestation levels.\nField Crops\
    \ Res. 2015, 183, 356–364. [CrossRef]\n64.\nTrudgill, D.L. Resistance to and tolerance\
    \ of plant parasitic nematodes in plants. Annu. Rev. Phytopathol.\n1991, 29, 167–192.\
    \ [CrossRef]\n65.\nInoue, Y.; Kimball, B.A.; Jackson, R.D.; Pinter, P.J.; Reginato,\
    \ R.J. Remote estimation of leaf transpiration rate\nand stomatal resistance based\
    \ on infrared thermometry. Agric. For. Meteorol. 1990, 51, 21–33. [CrossRef]\n\
    66.\nJones, H.G.; Schoﬁeld, P. Thermal and other remote sensing of plant stress.\
    \ Gen. Appl. Plant Physiol. 2008, 34,\n19–32.\n67.\nTrudgill, D.L. Effects of\
    \ Globodera rostochiensis and fertilisers on the mineral nutrient content and\
    \ yield of\npotato plants. Nematologica 1980, 26, 243–254. [CrossRef]\n68.\nHaverkort,\
    \ A.J.; Fasan, T.; Van de Waart, M. The inﬂuence of cyst nematodes and drought\
    \ on potato growth.\n2. Effects on plant water relations under semi-controlled\
    \ conditions. Eur. J. Plant Pathol. 1991, 97, 162–170.\n[CrossRef]\n69.\nJones,\
    \ H.G. Application of thermal imaging and infrared sensing in plant physiology\
    \ and ecophysiology.\nAdv. Bot. Res. 2004, 41, 107–163.\n70.\nEvans, K.; Franco,\
    \ J. Tolerance to cyst-nematode attack in commercial potato cultivars and some\
    \ possible\nmechanisms for its operation. Nematologica 1979, 25, 153–162. [CrossRef]\n\
    71.\nTrudgill, D.L. Concepts of resistance; tolerance and susceptibility in relation\
    \ to cyst nematodes. In Cyst Nematodes;\nSpringer: Boston, MA, USA, 1986; pp.\
    \ 179–189.\nRemote Sens. 2018, 10, 787\n21 of 21\n72.\nRadcliffe, D.E.; Hussey,\
    \ R.S.; McClendon, R.W. Cyst nematode vs. tolerant and intolerant soybean cultivars.\n\
    Agron. J. 1990, 82, 855–860. [CrossRef]\n73.\nAasen, H.; Bolten, A. Multi-temporal\
    \ high-resolution imaging spectroscopy with hyperspectral 2D imagers—\nFrom theory\
    \ to application. Remote Sens. Environ. 2018, 205, 374–389. [CrossRef]\n74.\n\
    Shakoor, N.; Lee, S.; Mockler, T.C. High throughput phenotyping to accelerate\
    \ crop breeding and monitoring\nof diseases in the ﬁeld. Curr. Opin. Plant Biol.\
    \ 2017, 38, 184–192. [CrossRef] [PubMed]\n© 2018 by the authors. Licensee MDPI,\
    \ Basel, Switzerland. This article is an open access\narticle distributed under\
    \ the terms and conditions of the Creative Commons Attribution\n(CC BY) license\
    \ (http://creativecommons.org/licenses/by/4.0/).\n"
  inline_citation: '>'
  journal: Remote Sensing
  limitations: '>'
  pdf_link: https://www.mdpi.com/2072-4292/10/5/787/pdf?version=1526718687
  publication_year: 2018
  relevance_score1: 0
  relevance_score2: 0
  title: Aerial and Ground Based Sensing of Tolerance to Beet Cyst Nematode in Sugar
    Beet
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1109/jstars.2017.2788426
  analysis: '>'
  authors:
  - Ali AlSuwaidi
  - Bruce Grieve
  - Ali AlSuwaidi
  citation_count: 37
  full_citation: '>'
  full_text: '>

    This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences Typesetting
    math: 86% IEEE.org IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create
    Account Personal Sign In Browse My Settings Help Access provided by: University
    of Nebraska - Lincoln Sign Out All Books Conferences Courses Journals & Magazines
    Standards Authors Citations ADVANCED SEARCH Journals & Magazines >IEEE Journal
    of Selected Topi... >Volume: 11 Issue: 4 Feature-Ensemble-Based Novelty Detection
    for Analyzing Plant Hyperspectral Datasets Publisher: IEEE Cite This PDF Ali AlSuwaidi;
    Bruce Grieve; Hujun Yin All Authors 35 Cites in Papers 1062 Full Text Views Abstract
    Document Sections I. Introduction II. Background and Related Work III. Machine
    Learning Techniques IV. Materials and the Proposed Method V. Experimental Results
    Show Full Outline Authors Figures References Citations Keywords Metrics Footnotes
    Abstract: Recently, there has been a significant increase in the use of proximal
    or remote hyperspectral imaging systems to study plant properties, types, and
    conditions. Numerous financial and environmental benefits of using such systems
    have been the driving force behind this growth. This paper is concerned with the
    analysis of hyperspectral data for detecting plant diseases and stress conditions
    and classifying crop types by means of advanced machine learning techniques. Main
    contribution of the work lies in the use of an innovative classification framework
    for the analysis, in which adaptive feature selection, novelty detection, and
    ensemble learning are integrated. Three hyperspectral datasets and a nonimaging
    hyperspectral dataset were used in the evaluation of the proposed framework. Experimental
    results show significant improvements achieved by the proposed method compared
    to the use of empirical spectral indices and existing classification methods.
    Published in: IEEE Journal of Selected Topics in Applied Earth Observations and
    Remote Sensing ( Volume: 11, Issue: 4, April 2018) Page(s): 1041 - 1055 Date of
    Publication: 26 January 2018 ISSN Information: DOI: 10.1109/JSTARS.2017.2788426
    Publisher: IEEE CFS uses the correlation between features and classes to evaluate
    the significance of the features. It uses Shannon''s entropy and information gain
    to measure average feature-class and average feature-feature correlations. The
    features are then evaluated heuristically on merit to determine the significance
    as follows: The search strategy in this algorithm is based on the best first search
    and the process halts if no improvement is achieved after five consecutive iterations.
    Authors Figures References Citations Keywords Metrics Footnotes More Like This
    Soft sensor of melt index based on sparse least square support vector machine
    2016 35th Chinese Control Conference (CCC) Published: 2016 Gas identification
    by wavelet transform-based fast feature extraction and support vector machine
    from temperature modulated semiconductor gas sensors The 13th International Conference
    on Solid-State Sensors, Actuators and Microsystems, 2005. Digest of Technical
    Papers. TRANSDUCERS ''05. Published: 2005 Show More IEEE Personal Account CHANGE
    USERNAME/PASSWORD Purchase Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile
    Information COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION TECHNICAL INTERESTS
    Need Help? US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT
    Follow About IEEE Xplore | Contact Us | Help | Accessibility | Terms of Use |
    Nondiscrimination Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy Policy
    A not-for-profit organization, IEEE is the world''s largest technical professional
    organization dedicated to advancing technology for the benefit of humanity. ©
    Copyright 2024 IEEE - All rights reserved.'
  inline_citation: '>'
  journal: IEEE journal of selected topics in applied earth observations and remote
    sensing (Print)
  limitations: '>'
  pdf_link: null
  publication_year: 2018
  relevance_score1: 0
  relevance_score2: 0
  title: Feature-Ensemble-Based Novelty Detection for Analyzing Plant Hyperspectral
    Datasets
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.3390/rs12193216
  analysis: '>'
  authors:
  - Matthew Maimaitiyiming
  - Vasit Sagan
  - Paheding Sidike
  - Maitiniyazi Maimaitijiang
  - Allison J. Miller
  - Misha T. Kwasniewski
  citation_count: 21
  full_citation: '>'
  full_text: ">\nremote sensing  \nArticle\nLeveraging Very-High Spatial Resolution\n\
    Hyperspectral and Thermal UAV Imageries\nfor Characterizing Diurnal Indicators\
    \ of\nGrapevine Physiology\nMatthew Maimaitiyiming 1,*\n, Vasit Sagan 2,3\n, Paheding\
    \ Sidike 4\n,\nMaitiniyazi Maimaitijiang 2,3\n, Allison J. Miller 5,6\nand Misha\
    \ Kwasniewski 1,7\n1\nDepartment of Food Science, University of Missouri, Columbia,\
    \ MO 65211, USA; mtk5407@psu.edu\n2\nDepartment of Earth and Atmospheric Sciences,\
    \ Saint Louis University, St. Louis, MO 63108, USA;\nvasit.sagan@slu.edu (V.S.);\
    \ mason.maimaitijiang@slu.edu (M.M.)\n3\nGeospatial Institute, Saint Louis University,\
    \ St. Louis, MO 63108, USA\n4\nDepartment of Applied Computing, Michigan Technological\
    \ University, Houghton, MI 49931, USA;\nspahedin@mtu.edu\n5\nDepartment of Biology,\
    \ Saint Louis University, St. Louis, MO 63103, USA; allison.j.miller@slu.edu\n\
    6\nDonald Danforth Plant Science Center, St. Louis, MO 63132, USA\n7\nDepartment\
    \ of Food Science, The Pennsylvania State University, University Park, PA 16802,\
    \ USA\n*\nCorrespondence: maimaitiyimingm@umsystem.edu\nReceived: 6 September\
    \ 2020; Accepted: 29 September 2020; Published: 2 October 2020\n\x01\x02\x03\x01\
    \x04\x05\x06\a\b\x01\n\x01\x02\x03\x04\x05\x06\a\nAbstract: Eﬃcient and accurate\
    \ methods to monitor crop physiological responses help growers\nbetter understand\
    \ crop physiology and improve crop productivity. In recent years, developments\n\
    in unmanned aerial vehicles (UAV) and sensor technology have enabled image acquisition\
    \ at\nvery-high spectral, spatial, and temporal resolutions. However, potential\
    \ applications and limitations\nof very-high-resolution (VHR) hyperspectral and\
    \ thermal UAV imaging for characterization of\nplant diurnal physiology remain\
    \ largely unknown, due to issues related to shadow and canopy\nheterogeneity.\
    \ In this study, we propose a canopy zone-weighting (CZW) method to leverage the\n\
    potential of VHR (≤9 cm) hyperspectral and thermal UAV imageries in estimating\
    \ physiological\nindicators, such as stomatal conductance (Gs) and steady-state\
    \ ﬂuorescence (Fs). Diurnal ﬂights and\nconcurrent in-situ measurements were conducted\
    \ during grapevine growing seasons in 2017 and\n2018 in a vineyard in Missouri,\
    \ USA. We used neural net classiﬁer and the Canny edge detection\nmethod to extract\
    \ pure vine canopy from the hyperspectral and thermal images, respectively. Then,\n\
    the vine canopy was segmented into three canopy zones (sunlit, nadir, and shaded)\
    \ using K-means\nclustering based on the canopy shadow fraction and canopy temperature.\
    \ Common reﬂectance-based\nspectral indices, sun-induced chlorophyll ﬂuorescence\
    \ (SIF), and simpliﬁed canopy water stress index\n(siCWSI) were computed as image\
    \ retrievals. Using the coeﬃcient of determination (R2) established\nbetween the\
    \ image retrievals from three canopy zones and the in-situ measurements as a weight\n\
    factor, weighted image retrievals were calculated and their correlation with in-situ\
    \ measurements\nwas explored. The results showed that the most frequent and the\
    \ highest correlations were found for\nGs and Fs, with CZW-based Photochemical\
    \ reﬂectance index (PRI), SIF, and siCWSI (PRICZW, SIFCZW,\nand siCWSICZW), respectively.\
    \ When all ﬂights combined for the given ﬁeld campaign date, PRICZW,\nSIFCZW,\
    \ and siCWSICZW signiﬁcantly improved the relationship with Gs and Fs. The proposed\n\
    approach takes full advantage of VHR hyperspectral and thermal UAV imageries,\
    \ and suggests that\nthe CZW method is simple yet eﬀective in estimating Gs and\
    \ Fs.\nKeywords: remote sensing; PRI; SIF; CWSI; stomatal conductance; fluorescence;\
    \ canopy zone-weighing\nRemote Sens. 2020, 12, 3216; doi:10.3390/rs12193216\n\
    www.mdpi.com/journal/remotesensing\nRemote Sens. 2020, 12, 3216\n2 of 30\n1. Introduction\n\
    Grapevine (Vitis spp.) is one of the most commercially important berry crops in\
    \ the world [1].\nIn grapevines, moderate water deﬁcit is necessary to achieve\
    \ desired berry quality and yield, although\nthe eﬀects of deﬁcit irrigation on\
    \ berry and quality are dependent upon the weather during the\ngrowing season,\
    \ soil type, grapevine variety, and timing of water application [2–5]. Understanding\n\
    the physiological responses of grapevine to mild to moderate water stress is fundamental\
    \ to optimize\ndeﬁcit irrigation timing and amount [5,6]. Additionally, vine physiology\
    \ is sensitive to diurnal cycles\nand vineyard microclimates, with even temporary\
    \ stress having the potential to alter berry chemistry\nand vine growth [7,8].\
    \ Therefore, it is critical to account for physiological changes associated with\n\
    these factors in ﬁeld conditions throughout diurnal cycles rather than focusing\
    \ only on pre-dawn or\nmidday measurements, which are often used [5,6].\nCurrent\
    \ methods for estimating physiological processes include quantiﬁcation of gas\
    \ exchange,\nstomatal conductance, canopy temperature, and stem water potential\
    \ [9]. These approaches are\ntime-consuming, labor-intensive, and destructive\
    \ (leaves need to be detached for stem water potential).\nFurther, they are unsuitable\
    \ for automation, subject to measurement and sampling errors, and the\ninstrumentation\
    \ required can be prohibitive in terms of cost [10,11]. More importantly, the\
    \ data\ncollected with traditional tools represent incomplete spatial and temporal\
    \ characterization of key vine\nphysiological parameters due to the time involved\
    \ in taking the measurements and the capacity of\nthe instruments themselves [12,13].\
    \ Therefore, it is necessary to have eﬃcient monitoring systems\nthat enable accurate\
    \ tracking of key parameters governing vine function at high spatial and temporal\n\
    resolution to obtain a reliable overview of vine physiology.\nHyperspectral and\
    \ thermal sensors installed on ﬁeld robots-, aircraft-, and satellite-based platforms\n\
    are an increasingly common approach used to characterize plant physiology [14–17].\
    \ In hyperspectral\nremote sensing, sensors measure radiative properties of plants\
    \ with hundreds to thousands of\ncontinuous narrow bands in the optical domain\
    \ (0.35–2.5 µm). This abundant spectral information\nincreases the chance of detecting\
    \ subtle physiological changes compared to multispectral data,\nwhich have a small\
    \ number of bands averaged over a wide spectral region and are insensitive to\
    \ narrow\nspectral signatures [18–20]. Photochemical reﬂectance index (PRI) and\
    \ sun-induced ﬂuorescence\n(SIF) retrieved from hyperspectral remote sensing are\
    \ the most widely used indicators in the remote\nassessment of plant photosynthetic\
    \ activity [21–24]. The PRI was formed to track the xanthophyll\ncycle, which\
    \ relates to plant oxidative stress associated with photosynthesis, using changes\
    \ in green\nreﬂectance centered at 531 nm [25]. SIF is a direct proxy of photosynthesis,\
    \ because it detects reemitted\nexcess light energy at 600–800 nm, from photosystems\
    \ I and II, to minimize photosystem damage as a\npart of the plant photo-protective\
    \ mechanism [26–29].\nThermal remote sensing (8–14 µm) is a popular tool but unlike\
    \ the aforementioned indices that\nrely on factors related to photosynthetic activity,\
    \ thermal data is a strong proxy for transpiration activity.\nTherefore, the rationale\
    \ behind the application of thermal remote sensing for plant stress detection\
    \ is\nthe correlation between stress level and plant temperature increase, which\
    \ is triggered by stomatal\nclosure and reduced transpiration [30]. To overcome\
    \ the eﬀects of varying meteorological conditions\non the stress and temperature\
    \ relationship, the canopy water stress index (CWSI) was developed by\nthe normalizing\
    \ canopy (Tc) and air temperate (Ta) diﬀerence with the evaporative demand [31,32].\n\
    When\nsatellite-\nor\naircraft-based\nhyperspectral\nand\nthermal\nobservations\n\
    are\nmade,\nthe above-mentioned remotely sensed indices are aﬀected by many factors,\
    \ including soil/background,\ncanopy architecture, and shadow due to the lack\
    \ of spatial resolution [17,33–36]. This is particularly true\nfor highly heterogeneous\
    \ ﬁelds of perennial woody crops (e.g., orchard and vineyards), where plants are\n\
    planted in rows with cover crops or bare soil between the rows [15,37,38]. Further,\
    \ low revisit frequency,\nhigh cost, and potential cloud occurrence limit the\
    \ suitability of satellite remote sensing in agriculture,\nwhile operational complexity\
    \ presents a major constraint for manned airborne platforms [39–41].\nAlternatively,\
    \ remotely sensed data from ﬁeld-based platforms (poles/towers and manned/unmanned\n\
    vehicles) have the capacity to assess plant health status [42,43]. However, there\
    \ are shortcomings in\nRemote Sens. 2020, 12, 3216\n3 of 30\nthese as well, such\
    \ as that ﬁeld-based remote sensing platforms are not easily transported and often\n\
    oﬀer a limited footprint [44–46].\nWithin the past few years, huge strides have\
    \ been made in unmanned aerial vehicles\n(UAVs) and sensor technologies, which\
    \ have enabled image acquisition at high spectral, spatial,\nand temporal resolutions\
    \ over small to medium ﬁelds. Inexpensive and agile UAVs equipped with\nlightweight\
    \ miniaturized sensors oﬀer attractive alternatives for ﬁeld-scale phenotyping\
    \ and precision\nagriculture [44,47,48]. However, UAV-based studies have been\
    \ limited by cost, experienced pilot\nshortages, lack of methods for fast data\
    \ processing, and strict airspace regulations [44]. With the\navailability of\
    \ lower-cost commercial UAV platforms (which are easy to operate) and sensors,\n\
    improved image processing methods, and eﬀective airspace regulations, those limitations\
    \ are becoming\nless relevant [44,49,50]. Indeed, high spatial resolution images\
    \ acquired at low altitudes have a\nfavorable signal-to-noise ratio; further,\
    \ it is possible to eliminate soil and shadow pixels with high\nconﬁdence [51–56].\
    \ Additionally, image information (radiance, reﬂectance, and temperature) extracted\n\
    from pure vegetation pixels is likely to reduce the eﬀects of shadows and background\
    \ soils, thus\nimproving the estimation of crop biochemical, biophysical, and\
    \ physiological parameters [22,35,56–58].\nRecently, questions have arisen regarding\
    \ the eﬀects of background and within canopy\nheterogeneity on SIF (sun-induced\
    \ ﬂuorescence) and CWSI (canopy water stress index) [17,38].\nHernández-Clemente\
    \ et al. [17] demonstrated the eﬀects of background pixels on SIF retrievals in\n\
    monitoring forest health impacted by water stress and Phytophthora infections.\
    \ Camino et al. [38]\nshowed an improved relationship between the SIF and photosynthetic\
    \ rate when SIF retrieved from\nthe sunlit pixels of the almond tree canopy, while\
    \ Gs has the best correlation with CWSI, which was\ncalculated using the coldest\
    \ and purest canopy pixels (under the 25th and the 50th percentile of\nthe canopy\
    \ pixels). Therefore, it is critical to ﬁrst separate non-vegetation pixels (shadows\
    \ and\nbackground soils) and pure vegetation pixels, before establishing the relationship\
    \ between remote\nsensing stress indicators such as SIF and CWSI, and in-situ\
    \ measurements. Importantly, studies\nby Hernández-Clemente et al. [17] and Camino\
    \ et al. [38] highlighted the signiﬁcance of very-high\nspatial (VHR) resolution\
    \ hyperspectral and thermal images for further understanding the eﬀects of\nbackground\
    \ and canopy structure on remote sensing stress indicators. Additionally, there\
    \ is a lack of\nconsensus on determining canopy temperature in vineyards due to\
    \ the unique canopy architecture\nthat can be divided into sunlit, nadir, and\
    \ shaded zones [59]. Reinert et al. [60] and Pou et al. [61]\nfound a high correlation\
    \ between sunlit canopy zone temperature and Gs and stem water potential.\nIn\
    \ contrast, Baluja et al. [62] and Möller et al. [63] showed promising results\
    \ when the nadir canopy\nzone was used to extract canopy temperature. These ﬁndings\
    \ guarantee further understanding of the\neﬀect of canopy structure on the commonly\
    \ used remote sensing indicators to take full advantage of\nthe information contained\
    \ within VHR hyperspectral and thermal images.\nIn this study, we build on previous\
    \ work and further explore applications of VHR hyperspectral and\nthermal images\
    \ in the quantiﬁcation of physiological parameters in plants. The objectives of\
    \ this study\nare (i) to investigate the relationship between information extracted\
    \ from VHR aerial images over three\ndiﬀerent canopy zones (sunlit, nadir, and\
    \ shaded zones) and in-situ physiological indicators, such as\nstomatal conductance\
    \ (Gs) and steady-state ﬂuorescence (Fs), and (ii) to test the canopy zone-weighting\n\
    (CZW) method’s capacity to use aerial data to approximate diurnal physiological\
    \ indicators.\n2. Materials and Methods\n2.1. Experimental Site Description and\
    \ Meteorological Measurements\nGround and aerial data were collected during the\
    \ 2017 and 2018 growing seasons in a 0.9 ha\nexperimental vineyard at the University\
    \ of Missouri-Columbia Southwest Research Center in Mount\nVernon, Missouri, USA\
    \ (37◦4′27.17′′ N, 93◦52′46.70′′ W). The climate of the region is continental\
    \ with\nan average annual temperature of 15.6 ◦C and a mean annual rainfall of\
    \ 1067 mm. The experimental\nvineyard consists of ungrafted ‘Chambourcin’ vines\
    \ and ‘Chambourcin’ scions grafted to one of\nRemote Sens. 2020, 12, 3216\n4 of\
    \ 30\nthe following rootstocks: Selection Oppenheim 4 (SO4), 1103 Paulsen (1103P),\
    \ and 3309 Couderc\n(3309C). In total, the vineyard includes four scion/rootstock\
    \ combinations: ‘Chambourcin ungrafted’,\n‘Chambourcin/SO4’, ‘Chambourcin/1103P’,\
    \ and ‘Chambourcin/3309C’. The ungrafted and grafted vines\nare planted in rows\
    \ with 3 m row and 3 m vine spacing along the row (Figure 1a). The vineyard has\n\
    an east–west row orientation. Vines were planted in 2009 and were eight years\
    \ old at the beginning\nof sampling in this study. ‘Chambourcin’ vines were trained\
    \ with a high wire cordon trellis and\nspur-pruned. The soil on the vineyard is\
    \ a combination of sandy loam, silt loam, and loam, with an\naverage pH of 6.\
    \ Additional details of the study site are available in Maimaitiyiming et al.\
    \ [64] and\nMaimaitiyiming et al. [65].\nThe ‘Chambourcin’ experimental vineyard\
    \ consists of nine rows, each of which is treated with one\nof three diﬀerent\
    \ irrigation treatments, replacing 0%, 50%, and 100% of evapotranspiration (ET)\
    \ losses.\nEach irrigation treatment is replicated three times (in three of the\
    \ nine rows) and ET is obtained from a\nweather station installed at 270 m from\
    \ the site. Each vineyard row includes 32 vines planted in cells\nof four adjacent\
    \ vines of the same type (‘Chambourcin’ ungrafted or grafted to the same rootstocks).\n\
    Within each four-vine cell, the two central vines were monitored through ground\
    \ measurements.\nMeasurements of hourly air temperature (◦C), relative humidity\
    \ (%), solar radiation (Watts/m2),\nand wind speed (m/s) were obtained from the\
    \ weather station. Vapor pressure deﬁcit (VPD, hPa),\nwhich represents water demand\
    \ of the atmosphere better than relative humidity [66], was calculated\nfrom air\
    \ temperature and relative humidity using the equations of Struthers et al. [67].\n\
    Figure 1. Central irrigation treatment rows and grapevines with diﬀerent rootstocks\
    \ (a). Figure (b)\nwas obtained with a Headwall Nano hyperspectral camera (red:\
    \ 659.27 nm, green: 549.27 nm,\nand blue: 479.69 nm, true-color image). Figure\
    \ (c) was obtained with an ICI (Infrared Cameras Inc.)\nthermal camera.\n2.2.\
    \ Diurnal Physiological Measurements\nStomatal conductance (Gs) and steady-state\
    \ chlorophyll ﬂuorescence (Fs) were employed as\nimportant indicators of plant\
    \ physiology because stomatal closure is one of the ﬁrst responses to water\n\
    deﬁcit occurring in the leaves, and both Gs and Fs are closely correlated with\
    \ net photosynthesis\nin grapevines and other species [9,68–71]. Measurements\
    \ of Gs and Fs were taken at veraison (the\nstage at which the berries begin shifting\
    \ from green to dark red, usually late July/early August)\nin 2018, and preharvest\
    \ in 2017 and 2018 under full sun conditions, coinciding with diurnal aerial\n\
    campaigns (15 September 2017, 1 August and 19 September 2018) (Figure 1).\nTable\
    \ 1 presents\ndetails on the ﬁeld and aerial data acquisition campaigns in the\
    \ two growing seasons. In 2017,\nGs and Fs were measured on 2–3 sunlit, youngest\
    \ fully-matured leaves (one leaf per shoot) from\nRemote Sens. 2020, 12, 3216\n\
    5 of 30\nmain exterior shoots per vine using a porometer (SC-1, Decagon, Pullman,\
    \ Washington, USA) and\nﬂuorometer (FluorPen FP 110, Photon Systems Instruments,\
    \ Drásov, Czech Republic), respectively.\nThe porometer has a manufacturer-claimed\
    \ measurement range of 0 to 1000 mmol H2O m−2 s−1 with\nan accuracy of 10% [72].\
    \ The physiological measurements were taken from the leaves located on\nthe upper\
    \ third and sunny (south-facing) side of the canopy to represent a whole vine\
    \ physiology,\nfollowing previous similar studies [17,38,59]. In 2018, leaf gas\
    \ exchange (Gs, photosynthetic CO2\nassimilation rate, etc.) and Fs measurements\
    \ were performed on a single leaf (the same standard from\nthe previous year was\
    \ applied for leaf selection) per vine using a portable LI-6400XT infrared gas\n\
    analyzer equipped with a pulse amplitude modulated leaf ﬂuorometer chamber (Li-Cor\
    \ Biosciences Inc.,\nLincoln, NE, USA). The leaves were measured at a controlled\
    \ CO2 concentration of 400 µmol mol−1,\nat a photosynthetic photon ﬂux density\
    \ of 1000 µmol photons m−2 s−1, and ambient conditions\nof air temperature and\
    \ relative humidity. Eighteen vines (four scion/rootstock combinations plus\n\
    ‘Chambourcin ungrafted’ and ‘Chambourcin/SO4’ combinations for each irrigation\
    \ treatment) in\n2017 and twelve vines (four scion/rootstock combinations for\
    \ each irrigation treatment) in 2018 were\nmonitored for physiology at the time\
    \ of each diurnal ﬂight, representing both irrigation and rootstock\ntreatments.\
    \ This experimental design was expected to cause a wider range of vine physiological\n\
    variations and aﬀorded the ideal site for high variability in a relatively small\
    \ area. Additionally, due to\nthe time per measurement needed, it would have been\
    \ unfeasible to representatively sample each\nsubgroup to correlate with diurnal\
    \ hyperspectral data.\nTable 1.\nSummary of ﬁeld campaign dates, platforms, sensors,\
    \ sampling instruments, and the\nnumber of grapevines monitored for stomatal conductance\
    \ (Gs) and steady-state ﬂuorescence (Fs).\nOn 15 September 2017, the thermal images\
    \ were acquired in the midmorning (10:00 a.m.), at midday\n(12:45 p.m.), and in\
    \ the afternoon (03:45 p.m.). On 1 August 2018, the thermal and hyperspectral\
    \ images\nwere acquired in the midmorning (11:00 a.m.), at midday (12:45 p.m.),\
    \ in the midafternoon (02:00 p.m.),\nand afternoon (03:45 p.m.). On 19 September\
    \ 2018, the thermal images were acquired in the morning\n(09:30 a.m.) and at midday\
    \ (12:30 p.m.).\nFlight\nDates\nFlight Time\nAerial\nPlatforms\nSensors\nGround\n\
    Sampling\nDistance\n(cm)\nGrowing\nStages\nField\nSampling\nInstruments\nTotal\
    \ Number\nof Vines\nMonitored\n09/15/2017\nMidmorning\nMidday Afternoon\nDJI S1000\n\
    ICI (thermal)\n4\nPreharvest\nFluorometer,\nporometer\n54\n08/01/2018\nMidmorning\n\
    Midday\nMidafternoon\nAfternoon\nDJI M600\nFlir (thermal),\nHeadWall\n(hyperspectral)\n\
    5 (Hyper)\n9 (thermal)\nVeraison\nLi-6400XT\n48\n09/19/2018\nMorning Midday\n\
    DJI S1000\nICI (thermal)\n4\nPreharvest\nLi-6400XT\n24\n2.3. Aerial Image Acquisition\
    \ and Pre-Processing\nThe diurnal aerial campaigns were carried out in 2017 and\
    \ 2018 using thermal and hyperspectral\ncameras onboard UAVs (Figure 2). Ideally,\
    \ ground and aerial data collection should be carried out\nwith the same instruments\
    \ and cameras. In our case, this ideal scenario was not attainable due to\nlimited\
    \ resources and ﬁeld crew availability. However, this also aﬀorded us the opportunity\
    \ to validate\ncertain ﬁndings across multiple systems.\nOn 15 September 2017,\
    \ a DJI S1000+ octocopter, rotary-wing platform (DJI Technology Co., Ltd.,\nShenzhen,\
    \ China) was employed to carry an ICI (Infrared Cameras Inc.) 8640 P-Series thermal\
    \ camera\n(Beaumont, Texas, USA) (Figure 2a,b). The aerial platform was equipped\
    \ with a Pixhawk autopilot\nsystem, which enables autonomous ﬂights based on user-deﬁned\
    \ waypoints. The ICI thermal camera\nwas mounted on a custom-designed two-axis\
    \ gimble. During the aerial campaigns, the UAV was ﬂown\nat 30 m altitude above\
    \ the ground with a ﬁxed speed of 5 m/s. The ICI thermal camera has a resolution\n\
    of 640 × 512 pixels in a spectral range of 7–14 µm with a 13 mm focal length,\
    \ providing a ground\nsampling distance (GSD) of 4 cm at 30 m ﬂight height. To\
    \ successfully construct thermal orthomosaics,\nRemote Sens. 2020, 12, 3216\n\
    6 of 30\nthe ﬂight missions were planned to have 90% forward and 80% side overlap\
    \ of the thermal images,\nand the ICI camera was conﬁgured to capture a 14-bit\
    \ radiometric JPEG image every second during\nthe ﬂight.\nOn 1 August 2018, aerial\
    \ hyperspectral and thermal images were acquired using a visible and\nnear-infrared\
    \ (VNIR, 400–1000 nm) push-broom hyperspectral camera (Nano-Hyperspec VNIR model,\n\
    Headwall Photonics, Fitchburg, MA, USA) installed in tandem with a FLIR (Forward-looking\
    \ infrared)\nthermal camera (FLIR Vue Pro R 640, FLIR Systems, Inc., Wilsonville,\
    \ OR, USA) onboard a DJI\nhexacopter (Matrice 600 Pro, DJI Technology Co., Ltd.,\
    \ Shenzhen, China) (Figure 2c,d). The Matrice\n600 Pro is equipped with a DJI\
    \ 3A Pro Flight Controller, real-time kinematic (RTK), and a Global\nNavigation\
    \ Satellite System (GNSS) for positioning, which can provide ±0.5 m vertical and\
    \ ±1.5 m\nhorizontal accuracy. The cameras and an Applanix APX-15 global positioning\
    \ system (GPS)/inertial\nmeasuring unit (IUM) (Applanix, Richmond Hill, ON, Canada)\
    \ were ﬁxed on a DJI JI Ronin-MX\n3-axis gimbal, which directly connected to the\
    \ aerial platform. The ﬂight missions were carried out\nat an altitude of 80 m\
    \ above the ground with 2 m/s forward velocity, which produced the GSDs\n(ground\
    \ sampling distances) of 5 and 9 cm for the hyperspectral and thermal image, respectively.\n\
    The hyperspectral camera records 640 spatial pixels and 270 spectral bands in\
    \ the VNIR range at\n2.2 nm/pixel with a radiometric resolution of 12 bits. The\
    \ full width at half maximum of the camera is\n6 nm with an entrance slit width\
    \ of 20 µm. The hyperspectral images were acquired 40 frames per\nsecond at 2.5\
    \ ms integration time using a 12 mm focal length lens, yielding 25◦ of the ﬁeld\
    \ of view\nat nadir. The FLIR thermal camera has an image array of 640 × 512 pixels\
    \ with a 13 mm focal length,\nproviding 45◦ ﬁeld of view (FOV). It can acquire\
    \ longwave radiation in the 7.5–13.5 µm range at 14 bits,\nthe thermals were recorded\
    \ in a 14-bit JPEG format every second during the ﬂights. The ﬂight missions\n\
    were planned for the hyperspectral camera with a 40% side overlap, which ensured\
    \ the FLIR thermal\nimages had at least 80% forward and side overlap because of\
    \ the wide thermal camera FOV.\nOn 19 September 2018, thermal images were acquired\
    \ using the ICI thermal camera. The ﬂight\nmissions and the ICI thermal camera\
    \ settings were consistent with the 2017 aerial campaigns.\nFigure 2. UAV systems\
    \ and interrelated sensors. DJI S1000+ UAV system (a) with ICI thermal\ncamera\
    \ (b), DJI-Matrice 600 Pro UAV system, (c) with Headwall Nano Hyperspectral and\
    \ FLIR thermal\ncameras (d).\nRemote Sens. 2020, 12, 3216\n7 of 30\nBoth thermal\
    \ cameras used in this study are radiometrically calibrated sensors, which are\
    \ composed\nof uncooled microbolometers. Even with the radiometric calibrations\
    \ provided by manufacturers,\nthe performance of thermal cameras may be aﬀected\
    \ by atmospheric conditions, target emissivity,\nand distance. To improve the\
    \ accuracy of derived surface temperature, these factors were accounted\nfor by\
    \ background temperature, ambient humidity, barometric pressure, target emissivity,\
    \ and distance\nas calibration parameters and using algorithms in associated software\
    \ tools. For the ICI camera,\nthe raw thermal images were converted to surface\
    \ temperature (◦C) in 32-bit TIFF format by a\nproprietary equation within IR\
    \ (Infrafred) Flash version 2.18.9.17 software (ICI, Beaumont, TX, USA),\nwhich\
    \ allows adjusting atmospheric conditions and target properties. Similarly, before\
    \ FLIR imaging,\nthe temperature calibration parameters were entered to the FLIR\
    \ UAS version 2.0.16 app, which can\ncontrol the camera settings through Bluetooth\
    \ connection from a mobile device. The calibrated thermal\nimages were mosaiced\
    \ using Pix4DMapper version 4.3.31 software (Pix4D SA, Lausanne, Switzerland)\n\
    and georeferenced using the GCPs. Before each ﬂight, the thermal cameras were\
    \ turned on for at least\n30 min for stabilization and the local atmospheric parameters\
    \ were acquired from the on-site weather\nstation. Additionally, a calibrated\
    \ black body Model 1000 (Everest Interscience Inc., USA) and surface\ntemperature\
    \ of diﬀerent objects measured with a thermal spot imager FLIR TG167 (FLIR Systems,\
    \ USA,\n±1.5 ◦C accuracy) were used for the assessment of the thermal products.\
    \ For further details please see\nSagan et al. [73] and Maimaitijiang et al. [74].\n\
    The hyperspectral image preprocessing included radiometric correction, orthorectiﬁcation,\n\
    and atmospheric correction. In the radiometric correction step, digital numbers\
    \ of the raw 12-bit\nhyperspectral images were converted to calibrated radiometric\
    \ values using the SpectralView version\n5.5.1 software (Headwall Photonics, Fitchburg,\
    \ MA, USA). In the same software, the calibrated\nradiance images were orthorectiﬁed\
    \ using the Applanix IMU unit data as input. Further, the radiance\nwas converted\
    \ to reﬂectance in ENVI (Environment for Visualizing Images) version 5.5 software\n\
    (Harris Geospatial Solutions Inc., Boulder, CO, USA) by the empirical line correction\
    \ (ELC)\nmethod [75]. During the overpass of the aerial platform, a portable ﬁeld\
    \ spectroradiometer PSR-3500\n(Spectral Evolution Inc., Lawrence, MA, USA) was\
    \ available to provide reﬂectance spectra of an\naerial calibration tarp with\
    \ three levels of known reﬂectance levels (56%, 32%, and 11%), grapevines,\ngrass,\
    \ and soil, which were used as a spectral reference in the ELC method. The spectroradiometer\n\
    records upwelling radiant energy in a range 350–2500 nm with a spectral resolution\
    \ of 3.5 nm in\nthe 350–1000 nm range, 10 nm in the 1000–1900 nm range, and 7\
    \ nm in the 1900–2500 nm spectral\nrange. The targets were measured 3–5 times\
    \ at nadir from 30 cm distance, and a 99% Spectralon\ncalibration panel (Labsphere,\
    \ Inc., North Sutton, NH, USA) was used to convert the target radiance to\nreﬂectance.\
    \ The averaged target reﬂectance spectra were resampled to match the spectral\
    \ resolution\nof the Headwall spectral camera. The radiance of the aerial images\
    \ was extracted from a 25-pixel\n(5 by 5 pixels) region at the center of each\
    \ target. Finally, the relationship between the reference spectra\nand the image\
    \ radiance was established using the ELC method.\n2.4. Extraction of Grapevine\
    \ Canopy Row\nTo avoid the eﬀects of shadow and soil components and due to spatial\
    \ resolution discrepancy\nbetween thermal and hyperspectral images, extraction\
    \ of grapevine rows is accomplished diﬀerently\nfor thermal and hyperspectral\
    \ images. Over each monitored target grapevine, a 1 m wide region of\ninterest\
    \ (width of the region was determined by canopy size) was deﬁned and pixel values\
    \ within this\nregion were extracted for further analysis.\n2.4.1. Canopy Row\
    \ Extraction From Hyperspectral Images\nNeural net classiﬁers were trained to\
    \ extract pure grapevines row pixels from high-resolution\nhyperspectral images.\
    \ We chose to use a neural net classiﬁer due to the recent success of neural\n\
    networks in hyperspectral image classiﬁcation [76–80]. The neural net classiﬁers\
    \ were implemented\nusing ENVI version 5.5 software (Harris Geospatial Solutions\
    \ Inc., Boulder, CO, USA) by providing\nRemote Sens. 2020, 12, 3216\n8 of 30\n\
    regions of interest for ﬁve diﬀerent classes, including grapevine, grass, vine\
    \ canopy, shadow, and soil\n(Figure 3a). More than 6000 pixels were selected for\
    \ these classes, accounting for target and illumination\nvariability. The best\
    \ performance of neural net classiﬁers was found using 2 hidden layers and logistic\n\
    activation function with 500 training iterations. For other necessary parameters,\
    \ default values were\nused and the parameters included training threshold contribution,\
    \ training rate, training momentum,\nand training root mean square exit criteria.\
    \ The trained neural net classiﬁers showed an overall\naccuracy better than 99.33%\
    \ and a Kappa coeﬃcient of 0.991. Figure 3b shows the results of the\ndelineated\
    \ grapevine canopy boundary.\nFigure 3. Hyperspectral reﬂectance spectra of grapevine,\
    \ grass, grapevine canopy shadow, and soil (a).\nThe results of grapevine canopy\
    \ row delineation (white outlines, b).\n2.4.2. Canopy Row Extraction from Thermal\
    \ Images\nPure grapevine canopy pixels required for thermal image retrieval were\
    \ extracted using the Canny\nedge detection method [81]. Canny edge detection\
    \ is a multi-step algorithm that was designed to detect\nmagnitude and orientation\
    \ of image intensity changes. This method has been proven to be eﬀective\nin extracting\
    \ pure canopy pixels from high-resolution thermal images [82,83]. Canny edge detection\n\
    was implemented using the Open-source Computer Vision library (version 4.0.0)\
    \ with Python 2.7.\nThe detected vine canopy edges were diluted by up to ﬁve pixels\
    \ along the direction of the thermal\ngradient for more conservative extraction\
    \ of the vine pixels. Finally, the vine canopy edges were\nconverted into polyline\
    \ vector and the thermal orthomosaics were clipped using the vine edge polyline\n\
    vector (Figure 4).\nFigure 4. The thermal images showing the extraction of pure\
    \ grapevine pixels to estimate canopy\ntemperature (red polygons). (a) Example\
    \ of thermal orthomosaic acquired with ICI camera. (b) Example\nof thermal acquired\
    \ obtained with FLIR camera.\nRemote Sens. 2020, 12, 3216\n9 of 30\n2.5. Estimation\
    \ of Pixelwise Canopy Shadow Fraction\nShadowing estimates of grapevine canopy\
    \ were produced using the Sequential Maximum Angle\nConvex Cone (SMACC) method\
    \ [84]. The SMACC was developed to generate spectral endmembers\nand endmember\
    \ abundance with less expert knowledge and time [85]. The SMACC can also calculate\n\
    shadow fractions of the abundances of reﬂectance when the sum of the fractions\
    \ of each endmember\nfor a pixel is constrained to one or less. Shadow fraction\
    \ of each grapevine canopy pixels within the\nhyperspectral images was estimated\
    \ using the SMACC tool in ENVI software. Figure 5a and b show\nhyperspectral reﬂectance\
    \ spectra of diﬀerent canopy zones and canopy show fractions modeled with\nthe\
    \ SMACC method.\nFigure 5. (a) Hyperspectral reﬂectance spectra of diﬀerent canopy\
    \ zones. (b) Canopy shadow fraction\nmodeled with the Sequential Maximum Angle\
    \ Convex Cone (SMACC) method.\n2.6. Grapevine Canopy Segmentation\nExtracted grapevine\
    \ canopies from hyperspectral and thermal images were segmented into three\ncanopy\
    \ regions, corresponding to sunlit (slt), nadir (ndr), and shaded (shd) zones\
    \ using K-means\nclustering, a machine learning-based unsupervised clustering\
    \ algorithm [86] (Figures 6 and 7). K-mean\nclustering is an iterative algorithm\
    \ that tries to ﬁnd homogenous and non-overlapping clusters within\ndata. The\
    \ algorithm uses Euclidean distance as a similarity measure to minimize within-cluster\n\
    variation while also keeping the clusters as diﬀerent as possible. We employed\
    \ K-mean clustering for\nvine canopy segmentation, where we grouped canopy pixels\
    \ with similar shadow fraction (in the case\nof hyperspectral images) or canopy\
    \ temperature (in the case of thermal images), depending on the\ntype of the input\
    \ image. The K-means clustering was implemented to divide vine canopies into three\n\
    regions (K = 3) with maximum iterations of 100 in ENVI software.\nFigure 6. Subsets\
    \ of grapevine canopy zones extracted from the hyperspectral image. (a) Entire\n\
    grapevine canopy, (b) sunlit (slt) canopy zone, (c) nadir (ndr) canopy zone, (d)\
    \ shaded (shd) canopy zone.\nRemote Sens. 2020, 12, 3216\n10 of 30\nFigure 7.\
    \ Subsets of grapevine canopy zones extracted from the thermal image. (a) Entire\
    \ grapevine\ncanopy, (b) sunlit (slt) canopy zone, (c) nadir (ndr) canopy zone,\
    \ (d) shaded (shd) canopy zone.\n2.7. Calculation of Spectral Indices and Features\
    \ from Aerial Image\n2.7.1. Hyperspectral Indices and SIF Retrieval\nCommonly\
    \ used hyperspectral reﬂectance indices closely related to plant physiology, pigment\n\
    concentration, structure, and water content were calculated from the hyperspectral\
    \ images to assess\ntheir ability to track diurnal physiological changes. Table\
    \ 2 summarizes speciﬁc spectral indices grouped\nby their categories associated\
    \ with (1) xanthophyll, (2) chlorophyll, (3) structure, (4) water content,\nand\
    \ (5) chlorophyll ﬂuorescence. Sun-induced chlorophyll ﬂuorescence (SIF) emission\
    \ was quantiﬁed\nfrom hyperspectral radiance images using the Fraunhofer Line\
    \ Depth (FLD) principle [87]. The FLD is\na radiance-based in-ﬁlling method, which\
    \ takes advantage of both the narrow absorption feature of\nO2-A absorption and\
    \ high spectral resolution [28]. Furthermore, the FLD method has shown reliable\n\
    SIF retrieval performance using hyperspectral cameras with relatively broad spectral\
    \ bandwidths\n(ranging between 5 and 7 nm FWHM), spectral sampling (lower than\
    \ 2.5 nm), and signal-to-noise\nratios of 300:1 or higher [22,88,89]. The FLD\
    \ was calculated from a total of three bands (FLD3) in and\nout O2–A feature,\
    \ using Equation (1) which is described in Reference [22,36].\nSIF = (Eout × Lin\
    \ − Ein × Lout)/(Eout − Ein)\n(1)\nwhere Eout is an average value of incident\
    \ solar irradiance at 750 and 780 nm, Lout is an average value\nof target radiance\
    \ at 750 nm and 780 nm, and Ein and Lin are incident solar irradiance and target\n\
    radiance at 760 nm, respectively. The incident solar irradiance was measured at\
    \ the time ﬂight using\nthe PSR spectroradiometer attached with a cosine corrector-diﬀuser\
    \ (180◦) for the entire spectral region\n(350–2500 nm).\nTable 2. Hyperspectral\
    \ image retrievals used in this study.\nHyperspectral Image Retrievals\nAcronym\n\
    Equation\nReferences\nXanthophyll\nPhotochemical reﬂectance index\nPRI\n(R570\
    \ – R531)/(R570 + R531)\n[25]\nChlorophyll\nRed Edge ratio index\nRE\nR750/R710\n\
    [90]\nStructure\nNormalized diﬀerence vegetation index\nNDVI\n(R800 – R670)/(R800\
    \ + R670)\n[91]\nSimple Ratio\nSR\nR800/R670\n[92]\nWater content\nWater index\n\
    WI\nR900/R970\n[93]\nChlorophyll ﬂuorescence\nSun-induced chlorophyll ﬂuorescence\n\
    SIF\n(Eout × Lin − Ein × Lout)/(Eout − Ein)\n[87]\nR stands for reﬂectance, and\
    \ numbers are wavelengths in nanometer (nm).\nRemote Sens. 2020, 12, 3216\n11\
    \ of 30\n2.7.2. Simpliﬁed Canopy Water Stress Index (siCWSI)\nThe CWSI was proposed\
    \ by Jones [94] as:\nCWSI = (Tcanopy − Twet)/(Tdry − Twet\n(2)\nwhere Tcanopy\
    \ is average canopy temperature extracted from pure vine pixels, Twet is the temperature\n\
    of fully transpiring leaves, and Tdry is temperature of non-transpiring leaves.\
    \ Determination of\nTwet and Tdry for conventional CWSI calculation is always\
    \ climate-dependent, complex, and\ntime-consuming [95–97]. Conversely, histogram\
    \ analysis-based CWSI uses thermal images as a\nmajor input and it has reduced\
    \ the meteorological data dependency and ﬁeld measurements [82,83].\nWhen Twet\
    \ and Tdry were obtained using a canopy temperature histogram which follows Gaussian\n\
    distribution [98], it is necessary to remove mixed pixels that partially cover\
    \ canopy and background,\nincluding soil, shadow, and weed [82,83]. In particular,\
    \ simpliﬁed CWSI (siCWSI) developed by\nBian et al. [82] was used in this study\
    \ as this method outperformed other forms of CWSI in terms of\nmonitoring plant\
    \ water status from UAV-based high-resolution thermal images. To obtain siCWSI\n\
    parameters, Twet and Tdry were determined by the mean of the lowest 0.5% and the\
    \ highest 0.5% of\ncanopy temperatures, respectively. More details about the calculation\
    \ of siCWSI can be found in\nBian et al. [82].\n2.8. Proposed Canopy Zone-Weighting\
    \ (CZW) Method\nDiﬀerent canopy zones are expected to bring complementary information\
    \ on the targeted vine\nphysiology measurements by mitigating eﬀects caused by\
    \ illumination, viewing angle, and canopy\nstructure. Considering certain canopy\
    \ zones show higher coeﬃcients of determination (R2) than others\nin vine physiology\
    \ estimation [59,61], a weighting strategy to diﬀerent canopy zone can be detrimental\n\
    for estimating of vine physiology. Inspired by our previous work on fusing various\
    \ water quality\nvariables and spectral reﬂectance through weighted prior decision-level\
    \ fusion scheme [99], we herein\nproposed a new zone-weighting method, namely\
    \ canopy zone-weighting (CZW), to systemically\nintegrate canopy zone contribution,\
    \ in which R2 of each canopy zone was used to determine the\ncontributing weight,\
    \ denoted as ωi in Equation (3). The integration of multiple regression model\n\
    outputs may explain a wide range of variations in a target variable compared to\
    \ a single regression\nmodel [100]. The proposed CZW method is expected to leverage\
    \ the strengths and limit the potential\nbiases of using a single zone-based estimation.\n\
    A summary of the implementation steps of the CZW method is described as follows:\
    \ (1) Establish\nrelationships between aerial images’ retrievals (hyperspectral\
    \ indices and siCWSI) extracted from three\ncanopy zones (slt, ndr, and shd) and\
    \ grapevine physiological parameters (Gs and Fs), (2) determine the\ncontributing\
    \ weight (ω) and contribution weight ratio (c) of the canopy zones to the target\
    \ grapevine\nphysiological indicator using the best relationships obtained in\
    \ the previous step, and (3) calculate\ncanopy zone-weighted image retrieval (ξczw)\
    \ from three canopy zones using the corresponding c.\nRelationships between the\
    \ aerial image retrievals and grapevine physiological parameters were\nestablished\
    \ in the form of the coeﬃcient of determination (R2) using ﬁve diﬀerent linear\
    \ and non-linear\nregression models (e.g., second-degree polynomial, logarithmic,\
    \ exponential, and power) [24], and the\nbest R2 values of the canopy zones were\
    \ used to calculate the ω of each zone through Equation (3):\nωi =\n1\nlogR2\n\
    i\nP3\ni = 1 logR2\ni\n(3)\nwhere ωi is the contributing weight of ith canopy\
    \ zone, and R2\ni is the coeﬃcient of determination that\nindicates the strength\
    \ of the relationship between the ith canopy zone retrieval and the grapevine\n\
    physiological parameters.\nRemote Sens. 2020, 12, 3216\n12 of 30\nc of the three\
    \ canopy zones to the grapevine physiological parameters were calculated by:\n\
    ci =\nωi\nP3\ni = 1 ωi\n(4)\nwhere ci is the contribution weight ratio of the\
    \ ith canopy zone.\nBased on the obtained c and the original image retrievals,\
    \ ξczw can be formulated by:\nξCZW = cslt × ξslt + cndr × ξndr + cshd × ξshd\n\
    (5)\nwhere cslt is the contribution weight ratio of the sunlit canopy zone, cndr\
    \ is the contribution weight\nratio of the nadir canopy zone, and cshd is the\
    \ contribution weight ratio of the shaded canopy zone.\nξstl is the original image\
    \ retrieval of the sunlit canopy zone, ξndr is the original image retrieval of\
    \ the\nnadir canopy zone, and ξshd is the original image retrieval of the shaded\
    \ canopy zone.\nThe aerial image retrievals derived from three canopy zones (slt,\
    \ ndr, and shd), the combination\nof any two canopy zones (slt + ndr, slt + shd,\
    \ and ndr + shd), the average value of entire canopy\n(avg), and the ξCZW (CZW)\
    \ were compared against Gs and Fs across all measurement time points\nand dates.\
    \ To explore the performance of the image retrievals on the entire diurnal dataset,\
    \ separate\nanalyses were carried out for all ﬂights together on a given ﬁeld\
    \ campaign date. Full relationships\nand their signiﬁcance obtained with the linear\
    \ and non-linear regression models were included as\nSupplementary Materials Tables\
    \ S1–S3. The workﬂow from aerial image acquisition and preprocessing,\nvine canopy\
    \ extraction and segmentation, and to implementation of the CWZ method and performance\n\
    assessment is demonstrated in Figure 8.\nRemote Sens. 2020, 12, 3216\n13 of 30\n\
    Figure 8. A workﬂow diagram of aerial image acquisition and preprocessing, vine\
    \ canopy extraction\nand segmentation, and implementation of the CWZ (Canopy Zone-Weighting)\
    \ method and its\nperformance assessment.\n3. Results\nIn the following sections,\
    \ we report on several aspects of the experiments. First, we describe the\nenvironmental\
    \ conditions of the vineyard and vine physiological indicators. Next, correlations\
    \ of\nimage retrievals (calculated from slt, ndr, shd, slt + ndr, slt + shd, ndr\
    \ + shd, and avg canopy zone\npixels and CZW method) with physiological indicators\
    \ were analyzed to assess the eﬀectiveness of our\nproposed approach. Finally,\
    \ we show the diurnal changes in representative image retrievals within the\n\
    vine canopy and their ability to track diurnal variations of vine physiological\
    \ indicators.\nRemote Sens. 2020, 12, 3216\n14 of 30\n3.1. Environmental Conditions\
    \ and Diurnal Physiological Indicators of Grapevine\nThere was no major diﬀerence\
    \ in the trends of environmental conditions for the three measurement\ndates (Figure\
    \ 9). Air temperature and VPD increased gradually until 16:00 p.m., and then decreased\n\
    sharply. Solar radiation followed a similar pattern as air temperature and VPD,\
    \ but solar radiation\nrapidly rose only until midday. Relative humidity was at\
    \ high levels in the morning, followed by a\ndecreasing trend, and then began\
    \ to increase from 16:00 p.m.. However, environmental conditions\non 19 September\
    \ 2018 were characterized by higher air temperature and lower relative humidity\n\
    throughout the day compared to the previous two measurement dates, resulting in\
    \ higher VPD values,\nthus more water-demanding atmosphere. All three measurement\
    \ dates were calm, with wind speed of\n3 m/s or lower, suitable for UAV data collection.\n\
    Figure 9. Air temperature, relative humidity, solar radiation, vaper pressure\
    \ deﬁcit (VPD), as well as\nwind speed for 15 September 2017, 1 August 2018, and\
    \ 19 September 2018.\nThe diurnal variations of grapevine physiological indicators\
    \ on all measurement dates had a\nsimilar trend. The Gs values were low in the\
    \ morning, increased sharply, and reached a maximum\naround midday (Figure 10a,c).\
    \ Afterwards, Gs decreased until the afternoon. The trend was caused,\nmost likely,\
    \ by environmental conditions. In general, the diurnal change of Fs followed the\
    \ same\npattern of Gs (Figure 10b,d). On most of the measurement dates, maximum\
    \ Fs values occurred\naround noon, while lower Fs values occurred in the morning\
    \ and afternoon. There were no signiﬁcant\ndiﬀerences in in-situ physiological\
    \ measurements at each ﬂight time among the irrigation and rootstock\ntreatments.\
    \ Daily Gs and Fs showed a relatively high coeﬃcient of variation (CV). Gs had\
    \ larger\ndaily variability compared to Fs for all the measurement dates. Both\
    \ Gs and Fs on 15 September 2017,\nhad 1–2 times higher values than the values\
    \ on 1 August 2018, and this could be due to the diﬀerent\ninstruments used to\
    \ determine the physiological indicators. Additionally, when the same instruments\n\
    were used, lower Gs and Fs values were observed on 19 September 2018 than the\
    \ corresponding values\non 15 September 2017. This agreed with higher VPD occurring\
    \ on 19 September 2018.\nRemote Sens. 2020, 12, 3216\n15 of 30\nFigure 10.\nDiurnal\
    \ variation of in-situ leaf stomatal conductance (Gs, (a,c,e)) and steady stage\n\
    ﬂuorescence (Fs, (b,d,f)) on ﬁeld campaign days over two growing seasons. Error\
    \ bars indicate standard\ndeviation and coeﬃcient of variation (CV) stands for\
    \ daily coeﬃcient of variations.\n3.2. Relationship between the Aerial Image Retrievals\
    \ and Grapevine Physiology\nOn 15 September 2017, the strongest correlation was\
    \ established with the midday and afternoon\nmeasurements of Gs for siCSWIczw\
    \ (R2 = 0.61, p < 0.01 and R2 = 0.60, p < 0.01 respectively), followed\nby siCWSIavg\
    \ in the midmorning (R2 = 0.30, p < 0.05) (Figure 11a). siCSWIczw provided the\
    \ strongest\nrelationship to Fs in the midmorning and midday (R2 = 0.82, p < 0.001\
    \ and R2 = 0.83, p < 0.001,\nrespectively), followed by siCWSIndr in the afternoon\
    \ (R2 = 0.52, p < 0.01) (Figure 11b). Comparing\nthe correlations from pooled\
    \ three ﬂights, both Gs and Fs were strongly correlated with siCWSIczw\n(R2 =\
    \ 0.71, p < 0.01 and R2 = 0.73, p < 0.01), followed by siCWSIavg with Gs and siCWSIslt+ndr\
    \ with\nFs, respectively.\nOn 1 August 2018, PRI, SIF, and siCWSI captured diurnal\
    \ changes in Gs and Fs as a function\nof grapevine physiological response. There\
    \ were no noticeable canopy structural eﬀects, pigments\ndegradation, and canopy\
    \ water content change between irrigation treatments during the hyperspectral\n\
    imaging campaign. This resulted in weak correlations (R2 ≤ 0.30) between RE, NDVI,\
    \ SR, and WI and\ngrapevine physiological parameters (Gs and Fs). Similar results\
    \ were observed for both separate ﬂights\nand when all ﬂights were combined. Therefore,\
    \ the results and discussion sections were focused on\nthe results of PRI and\
    \ SIF for hyperspectral data analysis.\nRemote Sens. 2020, 12, 3216\n16 of 30\n\
    Figure 11. Circular bar plots show the relationships (R2) established between\
    \ siCWSI from diﬀerent\ncanopy zones and stomatal conductance (Gs, (a)) and steady-state\
    \ ﬂuorescence (Fs, (b)) for the three\nthermal ﬂights on 15 September 2017 and\
    \ all three ﬂights combined. slt is for sunlit canopy zone, ndr is\nfor nadir\
    \ canopy zone, shd is for shaded canopy zone, avg is for average value of entire\
    \ canopy zone,\nand CZW is for canopy zone-weighting method.\nPRI more strongly\
    \ correlated with Gs during afternoon hours (2:00 p.m. and 3:45 p.m.) than\nearlier\
    \ hours (11:00 a.m. and 12:45 p.m.), while SIF showed a strong correlation with\
    \ Gs for all four\nﬂights (Figure 12a,b). When three canopy zones were considered\
    \ separately, PRIslt and PRIndr seemed\nto be correlated well with Gs. For SIF,\
    \ there was no single canopy zone that showed a consistently\nstrong relationship\
    \ with Gs (R2 ≤ 0.60). In most cases, PRI and SIF derived from two combined canopy\n\
    zones had a slightly higher correlation with Gs than that of a single canopy zone.\
    \ Meanwhile, slightly\nlower relationships were found by comparing PRIavg, and\
    \ SIFavg and Gs, except for the PRIavg in\nthe afternoon, where PRIavg showed\
    \ the highest correlation (R2 = 0.96, p < 0.001) compared to any\nPRI from single\
    \ canopy zone or combination of two. Generally, PRIczw and SIFczw improved the\n\
    relationship with Gs. In particular, PRIczw showed the strongest correlation in\
    \ the midmorning and\nafternoon (R2 = 0.35, p < 0.01 and R2 = 0.98 p < 0.001).\
    \ On the other hand, SIFczw appeared to have the\nclosest relationship with Gs\
    \ in the midmorning (R2 = 0.45, p < 0.05). When all ﬂights were analyzed\ntogether,\
    \ the relationships between PRIczw and SIFczw were stronger than the relationship\
    \ with PRI\nand SIF derived from any single, combined, and average canopy zone\
    \ pixels (R2 = 0.70, p < 0.01 and\nR2 = 0.89, p < 0.001).\nRegarding Fs, the obtained\
    \ results for all the ﬂights showed trends similar to those found for\nGs (Figure\
    \ 12c,d). Both PRI and SIF showed a strong and signiﬁcant relationship with Fs.\
    \ PRIsunlit\n(midmorning and midday) and PRIslt+ndr (midafternoon and afternoon)\
    \ showed the best ﬁtting with\nFs, while SIFczw was well-correlated with Fs for\
    \ all the ﬂights, except for midmorning. When four\nﬂights combined, the best\
    \ correlations were obtained with PRIczw and SIFczw, yielding (R2 = 0.76,\np <\
    \ 0.001 and R2 = 0.89, p < 0.001).\nThe highest correlation emerged between siCSWIczw\
    \ and Gs in the midmorning and afternoon\n(R2 = 0.98, p < 0.001 and R2 = 0.47,\
    \ p < 0.01) (Figure 12e). However, in the midday and midafternoon,\nsiCWSIslt+shd\
    \ and siCWSIndr respectively, showed the strongest relationship with Gs (R2 =\
    \ 0.89, p < 0.001\nand R2 = 0.96, p < 0.001), followed by siCWSIczw at both time\
    \ points (R2 = 0.87, p < 0.001 and R2 = 0.91,\np < 0.001). The strength of the\
    \ relationship for siCWSIndr was the strongest with Fs in the midafternoon\n(R2\
    \ = 0.96, p < 0.001), followed by sCSWIczw (R2 = 0.95, p < 0.001) (Figure 12f).\
    \ The strongest correlation\nwas observed between siCWSIslt+shd and Fs midmorning\
    \ and afternoon, respectively (R2 = 0.80, p < 0.01\nand R2 = 0.88, p < 0.001).\
    \ siCWSIczw was strongly correlated to Fs only in the midday (R2 = 0.72,\np <\
    \ 0.01). Using all four diurnal datasets, the strongest correlation was found\
    \ between siCWSIczw and\nboth Gs and Fs (R2 = 0.75, p < 0.01 and R2 = 0.74, p\
    \ < 0.01).\nRemote Sens. 2020, 12, 3216\n17 of 30\nFigure 12. Circular bar plots\
    \ show the relationships (R2) established between the image retrievals\n(PRI,\
    \ SIF, and siCWSI) and physiological indicators (Gs and Fs) for the four ﬂights\
    \ conducted on\n1 August 2018 and all ﬂights combined on this date. (a,b,e) show\
    \ the R2 values between PRI, SIF,\nand siCWSI from diﬀerent canopy zones and stomatal\
    \ conductance (Gs), and (c,d,f) show the R2 values\nbetween PRI, SIF, and siCWSI\
    \ from diﬀerent canopy zones and steady-state ﬂuorescence (Fs). slt is for\nsunlit\
    \ canopy zone, ndr is for nadir canopy zone, shd is for shaded canopy zone, avg\
    \ is for average\nvalue of entire canopy zone, and CZW is for canopy zone-weighting\
    \ method.\nOn 19 September 2018, siCWSIczw showed the strongest relationship with\
    \ Gs in the morning and\nfor the combined datasets of two ﬂights carried out on\
    \ this date (R2 = 0.70, p < 0.01 and R2 = 0.60,\np < 0.01) (Figure 13a). During\
    \ the midday, the highest correlation was found between siCWSIndr+shd\nand Gs\
    \ (R2 = 0.59, p < 0.01). For Fs, siCWSIndr+shd and siCWSIslt+ndr had the best\
    \ correlation with Fs\nRemote Sens. 2020, 12, 3216\n18 of 30\nin the morning and\
    \ midday (R2 = 0.59, p < 0.01 and R2 = 0.73, p < 0.001) respectively, which were\n\
    followed by siCWSIczw at both time points (R2 = 0.56, p < 0.01 and R2 = 0.70,\
    \ p < 0.01) (Figure 13b).\nWhen datasets from two ﬂights were combined, siCWSIczw\
    \ was the most highly correlated with Fs\n(R2 = 0.71, p < 0.01).\nFigure 13. Circular\
    \ bar plots show the relationships (R2) established between siCWSI from diﬀerent\n\
    canopy zones and stomatal conductance (Gs, (a)) and steady-state ﬂuorescence (Fs,\
    \ (b)) for the two\nthermal ﬂights on 19 September 2018 and all ﬂights combined.\
    \ slt is for sunlit canopy zone, ndr is for\nnadir canopy zone, shd is for shaded\
    \ canopy zone, avg is for average value of entire canopy zone,\nand CZW is for\
    \ canopy zone-weighting method.\n3.3. Diurnal Changes in Aerial Image Retrievals\
    \ and Tracking Physiological Indicators\nSIF and siCWSI retrievals from the VHR\
    \ images on 1 August 2018 showed diurnal changes in\nthe vine canopy (Figures\
    \ 14 and 15). It can be noted that there was no visual diﬀerence between\nirrigation\
    \ and rootstock treatments, and this was consistent with the in-situ physiological\
    \ measurements.\nHowever, visual diﬀerences between sunlit, nadir, and shaded\
    \ canopy zones could be easily recognized\nin both SIF and siCWSI images. Within-canopy\
    \ variability of SIF increased until midday and then\ndecreased (Figure 14b–e),\
    \ following the gradual decline in solar radiation. The highest within-canopy\n\
    variability of siCWSI was observed in the afternoon (Figure 15d), when air temperature\
    \ and VPD\nreached the maximum values for the day. In general, the eﬀects of diurnally\
    \ changing environmental\nfactors such as solar radiation, air temperature, and\
    \ VPD on the vine canopies corroborate the need\nto separate canopy zones, as\
    \ is shown with SIF and siCWSI retrievals. Furthermore, wide ranges of\nSIF and\
    \ siCWSI values were found (1–6.5 W sr−1 m−2 nm−1 and 0.1–1, respectively) for\
    \ each ﬂight,\nwhich conﬁrmed the relevance of canopy heterogeneity and the pertinence\
    \ of accounting for the\nvariability related to canopy structure.\nRemote Sens.\
    \ 2020, 12, 3216\n19 of 30\nFigure 14. Diurnal SIF at the canopy level retrieved\
    \ from the hyperspectral images acquired on\n1 August 2018. (a) Zoom on three\
    \ vine rows corresponding to three irrigation treatments, (b–e) zoom\non vine\
    \ rows showing SIF retrieval values.\nRemote Sens. 2020, 12, 3216\n20 of 30\n\
    Figure 15.\nDiurnal siCWSI at the canopy level retrieved from the thermal images\
    \ acquired on\n15 September 2018. (a) Zoom on canopy temperature of three vine\
    \ rows corresponding to three\nirrigation treatments, (b–d) zoom on vine rows\
    \ showing siCWIS retrieval values.\nThe in-situ physiological indicators measured\
    \ on 1 August 2018 were compared against PRI, SIF,\nand siCWSI to assess the diurnal\
    \ trends (Figure 16). Diurnal PRI, SIF, and siCWSI values for each\nmeasurement\
    \ time point showed agreements with Gs and Fs (regardless of the opposite direction\n\
    shown in Figure 16a,c). Generally, these ﬁgures showed that diurnal PRI, SIF,\
    \ and siCWSI followed the\nsame pattern as that followed by vine physiological\
    \ indicators during the experiment.\nRemote Sens. 2020, 12, 3216\n21 of 30\nFigure\
    \ 16. Diurnal trends for both in-situ physiological measurements and aerial image\
    \ retrievals\nobserved on 1 August 2018. (a) Steady-state ﬂuorescence (Fs) and\
    \ PRI, (b) Fs and SIF, and (c) stomatal\nconductance (Gs) and siCWSI.\n4. Discussion\n\
    Using diurnal VHR aerial images and in-situ physiological measurements, the current\
    \ study\ninvestigated relationships between aerial image retrievals from diﬀerent\
    \ canopy zones and grapevine\nphysiological indicators. Implemented irrigation\
    \ treatments and rootstock/scion combinations in this\nstudy provided a wide range\
    \ of grapevine physiological status for testing the capability of aerial\nimages\
    \ in characterizing grapevine physiology. The pure grapevine canopy pixels were\
    \ extracted with\nhigh conﬁdence from the high spatial resolution images coupled\
    \ with neural network and computer\nvision-based methods. Then, the vine canopy\
    \ was segmented into three diﬀerent canopy zones using\nan unsupervised machine\
    \ learning algorithm. Additionally, the siCWSI values were well within\nthe range\
    \ of the theoretical CWSI limit (<1), conﬁrming that calculated siCWSI was based\
    \ on pure\nvegetation pixels and not subjected to soil background contamination.\
    \ It is worth mentioning that the\nemployed methods in this study stood out among\
    \ the limited similar studies [17,38,59] by taking full\nadvantage of spectral\
    \ information and temperature data as the basis for identifying diﬀerent canopy\n\
    zones and applying automated methods to streamline canopy zone segmentation from\
    \ hyperspectral\nand thermal images.\n4.1. Contribution of Diﬀerent Canopy Zones\
    \ to Grapevine Physiology: Hyperspectral Image Retrievals\nIn line with previous\
    \ studies [22,101–103], PRI and SIF derived from high-resolution aerial images\n\
    closely followed the diurnal physiological changes of grapevine indicated by Gs\
    \ and Fs (Figure 16).\nThe results of sunlit, nadir, and shaded canopy zones showed\
    \ diﬀerent levels of correlation with\ngrapevine physiology depending on the type\
    \ of aerial images and retrievals. There were only a few\ninstances where a single\
    \ canopy zone (either sunlit or nadir) showed the strongest correlations. PRI\
    \ and\nRemote Sens. 2020, 12, 3216\n22 of 30\nSIF derived from either combination\
    \ of two canopy zones (slt + shd more frequent than slt + ndr) or\naveraged entire\
    \ canopy zone pixels showed the most frequent and the strongest correlation with\
    \ Gs\nand Fs measurements.\nAmong the recent eﬀorts to improve the ability of\
    \ PRI, some studies indicated the strong\ndependence of PRI on canopy shadow fraction\
    \ and conﬁrmed the importance of shaded leaves in\nthe simulation of canopy PRI\
    \ [104,105]. Zhang et al. [106] used a two-leaf (sunlit and shaded leaves)\napproach\
    \ to improve the ability of PRI as a proxy of light use eﬃcacy, which is closely\
    \ related to Gs, by\naccounting for sunlit and shaded leaf portion with weighted\
    \ leaf area index. Takala and Mõttus [84]\nexplained the illumination-related\
    \ apparent variation in canopy PRI by considering shadow eﬀects.\nThe results\
    \ of this study conﬁrmed the importance of considering both sunlit and shaded\
    \ canopy zones\nto improve the ability of PRI in tracking diurnal physiological\
    \ changes.\nSIF is also inﬂuenced by illumination, sunlit/shaded canopy, and soil\
    \ background, and these\ninﬂuences intensify when very-high-resolution hyperspectral\
    \ images are used for analysis [17,36].\nHernández et al. [17] and Camino et al\
    \ [38], who considered the eﬀects of canopy heterogeneity on SIF,\ndemonstrated\
    \ the signiﬁcance of sunlit canopy pixels in determining tree physiological status\
    \ and\nunderperformance of entire canopy pixels. This is somewhat contradictory\
    \ to what was observed in\nthis study, where SIF from entire canopy pixels also\
    \ performed well in multiple instances, and this\ncould be attributed to the discrepancy\
    \ in spatial resolution of the hyperspectral images used in this\nstudy (5 cm)\
    \ and previous studies (20 and 60 cm, respectively), where canopy pixels tend\
    \ to be easily\ncontaminated by soil and shaded background. In general, our results\
    \ showed the improvements from\ncombined (slt + ndr and slt + shd) or entire canopy\
    \ zones over sunlit zones, implying the importance\nof heterogeneity within canopy\
    \ structure in determining the relationship between SIF and in-situ\nphysiological\
    \ measurements.\n4.2. Contribution of Diﬀerent Canopy Zones to Grapevine Physiology:\
    \ Thermal Image Retrieval\nThe results from this study regarding the relationship\
    \ between the siCWSI and the physiological\nindicators were in agreement with\
    \ those from previous reports [103,107]. Canopy temperature is\naﬀected by tree\
    \ structure, which in turn aﬀects thermal image indices such as CWSI [31,32].\
    \ Furthermore,\nthere is a lack of consensus regarding the section of the sampling\
    \ zones (sunlit, nadir, and shaded\nzones). Sepúlveda et al. [59] and Belﬁore\
    \ [108] suggested to take into consideration the eﬀect of\nselecting canopy zones\
    \ to analyze thermal images. Suárez et al. [33] and Sepulcre et al. [107] found\n\
    a stronger relationship between canopy temperature and plant physiology in the\
    \ morning than\nmidday hours and indicated the importance of high spatial resolution\
    \ thermal images to minimize\nthe intensiﬁed midday soil eﬀects. This was not\
    \ the case in this study as siCWSI consistently showed\nstrong diurnal correlation\
    \ with in-situ measurements, suggesting that midday soil thermal eﬀects may\n\
    have been avoided with pure canopy pixel extracted from high-resolution thermal\
    \ images using the\ncomputer-vision-based method. However, the results showed\
    \ the slightly weaker relationship between\nsiCWSI and physiological indicators\
    \ at preharvest (15 September 2017 and 19 September 2018) than\nveraison (1 August\
    \ 2018), while thermal images collected at veraison had a lower spatial resolution.\n\
    This ﬁnding may be attributable to the diﬀerent growing stage because later in\
    \ the season, grapevines\nare more likely to be senescent [109] and in-situ measurements\
    \ may not represent the physiology of\nthe whole canopy well [59,63].\n4.3. Canopy\
    \ Zone-Weighting (CZW) Method Provided the Most Robust Estimates of Correlations\
    \ between\nAerial Image Retrievals and Grapevine Physiology\nTraditionally, image\
    \ retrievals were calculated over canopy pixels and averaged for each sampling\n\
    location for in-situ measurements. With recent advancements in UAV and sensor\
    \ technology, high\nspatial resolution aerial images have made it possible to\
    \ identify pure canopy pixels, and sunlit and\nshaded portions within tree canopies\
    \ [17,38,56]. When it comes to high-resolution hyperspectral\nimagery, Hernández-Clemente\
    \ et al. and Camino et al. [17,38] suggested separating sunlit and shaded\nRemote\
    \ Sens. 2020, 12, 3216\n23 of 30\ncanopy zones to minimize the eﬀects of within-canopy\
    \ shadows caused by the illumination condition\nand canopy heterogeneity. Similarly,\
    \ Sepúlveda-Reyes et al. and Pou et al. [59,61] divided vine canopy\ninto sunlit,\
    \ nadir, and shaded zones in thermal imagery and found conﬂicting results in terms\
    \ of\nselecting an eﬀective canopy zone as a proxy for physiology. The CZW method\
    \ proposed in this\nstudy utilized the accumulated contribution of diﬀerent canopy\
    \ zones within the tree canopy instead\nof using a mean value averaged over a\
    \ certain portion of the canopy or entire canopy. Compared\nto conventional ways\
    \ of calculating image retrievals (using only sunlit pixels, while ignoring the\n\
    shaded pixels), the CZW better characterized the grapevine canopy heterogeneity,\
    \ and thus grapevine\nphysiology. Generally, our study is the only case that revealed\
    \ the complementary relationships\nbetween diﬀerent canopy zones using the CZW\
    \ method for tracking diurnal physiological changes.\nThe performance of diﬀerent\
    \ image retrieval from diﬀerent canopy zones was evaluated for\neach ﬁeld measurement\
    \ time point and all the measurement time points together for the given ﬁeld\n\
    date. The availability of thermal images enabled us to investigate the robustness\
    \ of the CZW method\nover multiple growing seasons (2017 and 2018) and stages\
    \ (veraison and preharvest). When a single\nmeasurement point was considered,\
    \ our results showed that PRIczw, SIFczw, and siCWSIczw were better\nrelated to\
    \ Gs and Fs in some cases than the image retrieval from a single canopy zone,\
    \ the combination\nof any two canopy zones, and the entire canopy. When all ﬂights\
    \ were analyzed, CZW-based retrievals\nalways performed better than any other\
    \ retrieval approaches, suggesting that CZW indeed worked well\nregardless of\
    \ hyperspectral or thermal images when there were large variations both in image\
    \ data and\nﬁeld measurements determined by illumination, bidirectional reﬂectance\
    \ factor (BRDF), within-canopy\nheterogeneity, and diurnal physiological changes.\
    \ It is worth noting here that the CWZ would have\nled to even better performance\
    \ if the irrigation treatments had induced strong physiological changes\nduring\
    \ the ﬂights (that was not the case here).\nIt is commonly accepted that recorded\
    \ radiance and temperature from vegetation canopies are\nsubject to eﬀects of\
    \ sun angle, BRDF (especially in the case of hyperspectral imaging), shadows,\
    \ canopy\nbackground, structure, and leaf angle distribution, which in turn contribute\
    \ to the changes in the results\nto a diﬀerent degree. This is also true even\
    \ though the aerial images used in this study were acquired at\nlow altitudes\
    \ on sunny days with stable atmospheric conditions. Additionally, these eﬀects\
    \ may vary\ndepending on the diﬀerent canopy zones used in this study. Therefore,\
    \ it would be a logical follow-up\neﬀort to carry out a full analysis of the sensitivity\
    \ of the relationship between image retrievals and plant\nphysiology, focusing\
    \ on normalization or mitigation of these eﬀects speciﬁcally for each canopy zone.\n\
    4.4. Outlook\nWhile the proposed CZW method has been demonstrated to be a promising\
    \ advancement,\nfurther improvements may include the application of a pixel-weighting\
    \ approach and data fusion.\nIndeed, leaf photosynthetic status, water content,\
    \ pigment concentration, leaf angle distribution,\nand canopy architecture were\
    \ spatially diﬀerent within each canopy zone that was considered in this\nstudy.\
    \ Some of these spatial changes can be explained through rich spectral information\
    \ within a\npixel from hyperspectral images, and thus provide important information\
    \ about the plant physiology.\nLiDAR (Light Detection and Ranging) or photogrammetric\
    \ point clouds, on the other hand, allow\nus to obtain accurate information about\
    \ the canopy architecture and the heterogeneity within the\ncanopy. Weighted pixels\
    \ containing spectral, thermal, and structural information can be combined\nand\
    \ will contribute to an improved understanding of plant physiology. Note that\
    \ the integration of\nmultisensory image data requires a highly accurate co-registration.\
    \ Despite the relatively diverse\ndataset (i.e., diurnal, two growing seasons\
    \ and stages for thermal images, and a single growing season\nand stage for hyperspectral\
    \ image), further work is needed to explore the robustness of the CZW\nmethod\
    \ on diﬀerent growing stages of grapevines, presence of a wide range of structural\
    \ and pigment\nchanges, and tree species other than grapevines.\nRemote Sens.\
    \ 2020, 12, 3216\n24 of 30\n5. Conclusions\nThis study aimed to maximize the beneﬁts\
    \ of VHR hyperspectral and thermal UAV images to\nimprove the relationship between\
    \ the aerial image retrievals and diurnal indicators of grapevine\nphysiology.\
    \ Ultimately, this work allowed us to characterize physiological parameters at\
    \ a scale and\nwith speed not possible through other traditional measurements\
    \ of vine physiology. Besides enabling\nextraction of grapevine canopy with high\
    \ conﬁdence from both hyperspectral and thermal images,\nthe VHR images made it\
    \ feasible to quantitatively analyze the contribution of diﬀerent canopy zones\n\
    for characterizing diurnal physiological indicators. We proposed the CZW method\
    \ and evaluated\nits performance against the traditional image retrieval methods.\
    \ The results indicated that PRI, SIF,\nand siCWSI from sunlit and nadir zones\
    \ provided the best estimate of Gs and Fs when a single canopy\nzone was considered.\
    \ At a single ﬂight, PRI, SIF, and siCWSI computed over the combination of two\n\
    canopy zones (sunlit + nadir, sunlit + shaded, or nadir + shaded) or entire canopy\
    \ pixels showed a\nbetter relationship with diurnal Gs and Fs changes than the\
    \ PRI, SIF, and siCWSI calculated over a\nsingle canopy zone. Importantly, the\
    \ most frequent and the highest correlations were found for Gs\nand Fs with PRIczw,\
    \ SIFczw, and siCWSIczw. When all ﬂights combined for the given ﬁeld campaign\n\
    date, PRIczw, SIFczw, and siCWSIczw always signiﬁcantly improved the relationship\
    \ with Gs and Fs.\nIn summary, this study ﬁrst introduced the CZW concept to VHR\
    \ hyperspectral and thermal UAV\nimageries and provided a new train of thought\
    \ to the research and application of VHR images for\nremote assessment of plant\
    \ physiological indicators.\nSupplementary Materials: The following are available\
    \ online at http://www.mdpi.com/2072-4292/12/19/3216/s1,\nFull relationships and\
    \ their signiﬁcance obtained with the linear and non-linear regression models\
    \ were included\nas Supplementary Tables S1–S3.\nAuthor Contributions: Conceptualization,\
    \ M.M. (Matthew Maimaitiyiming) and P.S.; Data curation, M.M.\n(Matthew Maimaitiyiming);\
    \ Formal analysis, M.M. (Matthew Maimaitiyiming) and M.M. (Maitiniyazi\nMaimaitijiang);\
    \ Funding acquisition, V.S., A.J.M. and M.K.; Methodology, M.M. (Matthew Maimaitiyiming),\
    \ P.S.\nand M.M. (Maitiniyazi Maimaitijiang); Resources, V.S. and M.K.; Software,\
    \ V.S.; Supervision, V.S., A.J.M. and M.K.;\nVisualization, M.M. (Matthew Maimaitiyiming)\
    \ and M.M. (Maitiniyazi Maimaitijiang); Writing—original draft,\nM.M. (Matthew\
    \ Maimaitiyiming); Writing—review & editing, V.S., P.S., M.M. (Maitiniyazi Maimaitijiang),\
    \ A.J.M.\nand M.K. All authors have read and agreed to the published version of\
    \ the manuscript.\nFunding: This work was mainly supported by the National Science\
    \ Foundation Plant Genome Research Program\n1546869, partially supported by Missouri\
    \ Grape and Wine Institute at the University of Missouri-Columbia,\nand Missouri\
    \ Wine Marketing and Research Council.\nAcknowledgments: The authors thank the\
    \ University of Missouri Southwest Research Center, Sean Hartling,\nand Kyle Peterson\
    \ for their support during the aerial data collection and the image preprocessing.\
    \ The authors\nare also grateful to Ahmad Daloye, Alissa Benchimol, Siming Lu,\
    \ Hasan Erkbol, and Abdurahman Tevekkul for\ntheir ﬁeldwork in the vineyard. The\
    \ editors and the anonymous reviewers are acknowledged for their valuable\nrecommendations\
    \ and careful reviews.\nConﬂicts of Interest: The authors declare no conﬂict of\
    \ interest.\nReferences\n1.\nVivier, M.A.; Pretorius, I.S. Genetically tailored\
    \ grapevines for the wine industry. Trends Biotechnol. 2002, 20,\n472–478. [CrossRef]\n\
    2.\nIntrigliolo, D.S.; Castel, J.R. Interactive eﬀects of deﬁcit irrigation and\
    \ shoot and cluster thinning on grapevine\ncv. Tempranillo. Water relations, vine\
    \ performance and berry and wine composition. Irrig. Sci. 2011, 29,\n443–454.\
    \ [CrossRef]\n3.\nIntrigliolo, D.S.; Pérez, D.; Risco, D.; Yeves, A.; Castel,\
    \ J.R. Yield components and grape composition responses\nto seasonal water deﬁcits\
    \ in Tempranillo grapevines. Irrig. Sci. 2012, 30, 339–349. [CrossRef]\n4.\nMirás-Avalos,\
    \ J.M.; Buesa, I.; Llacer, E.; Jiménez-Bello, M.A.; Risco, D.; Castel, J.R.; Intrigliolo,\
    \ D.S. Water versus\nsource–sink relationships in a semiarid Tempranillo vineyard:\
    \ Vine performance and fruit composition.\nAm. J. Enol. Vitic. 2017, 68, 11–22.\
    \ [CrossRef]\nRemote Sens. 2020, 12, 3216\n25 of 30\n5.\nChaves, M.M.; Zarrouk,\
    \ O.; Francisco, R.; Costa, J.M.; Santos, T.; Regalado, A.P.; Rodrigues, M.L.;\
    \ Lopes, C.M.\nGrapevine under deﬁcit irrigation: Hints from physiological and\
    \ molecular data. Ann. Bot. 2010, 105,\n661–676. [CrossRef]\n6.\nChaves, M.M.;\
    \ Santos, T.P.; Souza, C.D.; Ortuño, M.; Rodrigues, M.; Lopes, C.; Maroco, J.;\
    \ Pereira, J.S.\nDeﬁcit irrigation in grapevine improves water-use eﬃciency while\
    \ controlling vigour and production quality.\nAnn. Appl. Biol. 2007, 150, 237–252.\
    \ [CrossRef]\n7.\nReynolds, A.G.; Wardle, D.A.; Naylor, A.P. Impact of training\
    \ system, vine spacing, and basal leaf removal\non Riesling. Vine performance,\
    \ berry composition, canopy microclimate, and vineyard labor requirements.\nAm.\
    \ J. Enol. Vitic. 1996, 47, 63–76.\n8.\nFerrandino, A.; Lovisolo, C. Abiotic stress\
    \ eﬀects on grapevine (Vitis vinifera L.): Focus on abscisic\nacid-mediated consequences\
    \ on secondary metabolism and berry quality.\nEnviron.\nExp.\nBot.\n2014,\n103,\
    \ 138–147. [CrossRef]\n9.\nCifre, J.; Bota, J.; Escalona, J.M.; Medrano, H.; Flexas,\
    \ J. Physiological tools for irrigation scheduling in\ngrapevine (Vitis vinifera\
    \ L.): An open gate to improve water-use eﬃciency? Agric. Ecosyst. Environ. 2005,\
    \ 106,\n159–170. [CrossRef]\n10.\nHall, A.; Lamb, D.; Holzapfel, B.; Louis, J.\
    \ Optical remote sensing applications in viticulture—A review.\nAust. J. Grape\
    \ Wine Res. 2002, 8, 36–47. [CrossRef]\n11.\nRapaport, T.; Hochberg, U.; Shoshany,\
    \ M.; Karnieli, A.; Rachmilevitch, S. Combining leaf physiology,\nhyperspectral\
    \ imaging and partial least squares-regression (PLS-R) for grapevine water status\
    \ assessment.\nISPRS J. Photogramm. Remote Sens. 2015, 109, 88–97. [CrossRef]\n\
    12.\nTrought, M.C.; Bramley, R.G. Vineyard variability in Marlborough, New Zealand:\
    \ Characterising spatial and\ntemporal changes in fruit composition and juice\
    \ quality in the vineyard. Aust. J. Wine Res. 2011, 17, 79–89.\n[CrossRef]\n13.\n\
    Bramley, R. Understanding variability in winegrape production systems 2. Within\
    \ vineyard variation in\nquality over several vintages. Aust. J. Wine Res. 2005,\
    \ 11, 33–42. [CrossRef]\n14.\nGuanter, L.; Alonso, L.; Gómez-Chova, L.; Amorós-López,\
    \ J.; Vila, J.; Moreno, J. Estimation of solar-induced\nvegetation ﬂuorescence\
    \ from space measurements. Geophys. Res. Lett. 2007, 34. [CrossRef]\n15.\nSepulcre-Cantó,\
    \ G.; Zarco-Tejada, P.J.; Jiménez-Muñoz, J.; Sobrino, J.; Soriano, M.; Fereres,\
    \ E.; Vega, V.;\nPastor, M. Monitoring yield and fruit quality parameters in open-canopy\
    \ tree crops under water stress.\nImplications for ASTER. Remote Sens. Environ.\
    \ 2007, 107, 455–470. [CrossRef]\n16.\nWendel, A.; Underwood, J. Illumination\
    \ compensation in ground based hyperspectral imaging. ISPRS J.\nPhotogramm. Remote\
    \ Sens. 2017, 129, 162–178. [CrossRef]\n17.\nHernández-Clemente, R.; North, P.R.J.;\
    \ Hornero, A.; Zarco-Tejada, P.J. Assessing the eﬀects of forest health\non sun-induced\
    \ chlorophyll ﬂuorescence using the FluorFLIGHT 3-D radiative transfer model to\
    \ account for\nforest structure. Remote Sens. Environ. 2017, 193, 165–179. [CrossRef]\n\
    18.\nAneece, I.; Thenkabail, P. Accuracies Achieved in Classifying Five Leading\
    \ World Crop Types and their\nGrowth Stages Using Optimal Earth Observing-1 Hyperion\
    \ Hyperspectral Narrowbands on Google Earth\nEngine. Remote Sens. 2018, 10, 2027.\
    \ [CrossRef]\n19.\nMariotto, I.; Thenkabail, P.S.; Huete, A.; Slonecker, E.T.;\
    \ Platonov, A. Hyperspectral versus multispectral\ncrop-productivity modeling\
    \ and type discrimination for the HyspIRI mission. Remote Sens. Environ. 2013,\n\
    139, 291–305. [CrossRef]\n20.\nThenkabail, P.S.; Enclona, E.A.; Ashton, M.S.;\
    \ Legg, C.; De Dieu, M.J. Hyperion, IKONOS, ALI, and ETM+\nsensors in the study\
    \ of African rainforests. Remote Sens. Environ. 2004, 90, 23–43. [CrossRef]\n\
    21.\nSuárez, L.; Zarco-Tejada, P.J.; Berni, J.A.; González-Dugo, V.; Fereres,\
    \ E. Modelling PRI for water stress\ndetection using radiative transfer models.\
    \ Remote Sens. Environ. 2009, 113, 730–744. [CrossRef]\n22.\nZarco-Tejada, P.J.;\
    \ González-Dugo, V.; Berni, J.A. Fluorescence, temperature and narrow-band indices\n\
    acquired from a UAV platform for water stress detection using a micro-hyperspectral\
    \ imager and a thermal\ncamera. Remote Sens. Environ. 2012, 117, 322–337. [CrossRef]\n\
    23.\nAtherton, J.; Nichol, C.J.; Porcar-Castell, A. Using spectral chlorophyll\
    \ ﬂuorescence and the photochemical\nreﬂectance index to predict physiological\
    \ dynamics. Remote Sens. Environ. 2016, 176, 17–30. [CrossRef]\n24.\nPanigada,\
    \ C.; Rossini, M.; Meroni, M.; Cilia, C.; Busettoa, L.; Amaducci, S.; Boschetti,\
    \ M.; Cogliati, S.;\nPicchi, V.; Pinto, F.; et al. Fluorescence, PRI and canopy\
    \ temperature for water stress detection in cereal crops.\nInt. J. Appl. Earth\
    \ Obs. Geoinf. 2014, 30, 167–178. [CrossRef]\nRemote Sens. 2020, 12, 3216\n26\
    \ of 30\n25.\nGamon, J.; Penuelas, J.; Field, C. A narrow-waveband spectral index\
    \ that tracks diurnal changes in\nphotosynthetic eﬃciency. Remote Sens. Environ.\
    \ 1992, 41, 35–44. [CrossRef]\n26.\nKrause, G.H.; Weis, E. Chlorophyll ﬂuorescence\
    \ as a tool in plant physiology. Photosynth. Res. 1984, 5,\n139–157. [CrossRef]\
    \ [PubMed]\n27.\nGuanter, L.; Rossini, M.; Colombo, R.; Meroni, M.; Frankenberg,\
    \ C.; Lee, J.-E.; Joiner, J. Using ﬁeld spectroscopy\nto assess the potential\
    \ of statistical approaches for the retrieval of sun-induced chlorophyll ﬂuorescence\
    \ from\nground and space. Remote Sens. Environ. 2013, 133, 52–61. [CrossRef]\n\
    28.\nMeroni, M.; Rossini, M.; Guanter, L.; Alonso, L.; Rascher, U.; Colombo, R.;\
    \ Moreno, J. Remote sensing of\nsolar-induced chlorophyll ﬂuorescence: Review\
    \ of methods and applications. Remote Sens. Environ. 2009,\n113, 2037–2051. [CrossRef]\n\
    29.\nMoya, I.; Camenen, L.; Evain, S.; Goulas, Y.; Cerovic, Z.G.; Latouche, G.;\
    \ Flexas, J.; Ounis, A. A new instrument\nfor passive remote sensing: 1. Measurements\
    \ of sunlight-induced chlorophyll ﬂuorescence. Remote Sens.\nEnviron. 2004, 91,\
    \ 186–197. [CrossRef]\n30.\nInoue, Y.; Kimball, B.A.; Jackson, R.D.; Pinter, P.J.;\
    \ Reginato, R.J. Remote estimation of leaf transpiration rate\nand stomatal resistance\
    \ based on infrared thermometry. Agric. For. Meteorol. 1990, 51, 21–33. [CrossRef]\n\
    31.\nIdso, S.; Jackson, R.; Pinter, P., Jr.; Reginato, R.; Hatﬁeld, J. Normalizing\
    \ the stress-degree-day parameter for\nenvironmental variability. Agric. Meteorol.\
    \ 1981, 24, 45–55. [CrossRef]\n32.\nJackson, R.D.; Idso, S.; Reginato, R.; Pinter,\
    \ P. Canopy temperature as a crop water stress indicator.\nWater Resour. Res.\
    \ 1981, 17, 1133–1138. [CrossRef]\n33.\nSuárez, L.; Zarco-Tejada, P.J.; Sepulcre-Cantó,\
    \ G.; Pérez-Priego, O.; Miller, J.R.; Jiménez-Muñoz, J.; Sobrino, J.\nAssessing\
    \ canopy PRI for water stress detection with diurnal airborne imagery. Remote\
    \ Sens. Environ. 2008,\n112, 560–575. [CrossRef]\n34.\nRossini, M.; Fava, F.;\
    \ Cogliati, S.; Meroni, M.; Marchesi, A.; Panigada, C.; Giardino, C.; Busetto,\
    \ L.;\nMigliavacca, M.; Amaducci, S.; et al. Assessing canopy PRI from airborne\
    \ imagery to map water stress in\nmaize. ISPRS J. Photogramm. Remote Sens. 2013,\
    \ 86, 168–177. [CrossRef]\n35.\nSantesteban, L.G.; Di Gennaro, S.F.; Herrero-Langreo,\
    \ A.; Miranda, C.; Royo, J.B.; Matese, A. High-resolution\nUAV-based thermal imaging\
    \ to estimate the instantaneous and seasonal variability of plant water status\n\
    within a vineyard. Agric. Water Manag. 2017, 183, 49–59. [CrossRef]\n36.\nZarco-Tejada,\
    \ P.J.; Suárez, L.; González-Dugo, V. Spatial resolution eﬀects on chlorophyll\
    \ ﬂuorescence retrieval\nin a heterogeneous canopy using hyperspectral imagery\
    \ and radiative transfer simulation. IEEE Geosci.\nRemote Sens. 2013, 10, 937–941.\
    \ [CrossRef]\n37.\nMatese, A.; Di Gennaro, S. Practical Applications of a Multisensor\
    \ UAV Platform Based on Multispectral,\nThermal and RGB High Resolution Images\
    \ in Precision Viticulture. Agriculture 2018, 8, 116. [CrossRef]\n38.\nCamino,\
    \ C.; Zarco-Tejada, P.J.; Gonzalez-Dugo, V. Eﬀects of Heterogeneity within Tree\
    \ Crowns on\nAirborne-Quantiﬁed SIF and the CWSI as Indicators of Water Stress\
    \ in the Context of Precision Agriculture.\nRemote Sens. 2018, 10, 604. [CrossRef]\n\
    39.\nChapman, S.; Merz, T.; Chan, A.; Jackway, P.; Hrabar, S.; Dreccer, M.; Holland,\
    \ E.; Zheng, B.; Ling, T.;\nJimenez-Berni, J. Pheno-Copter: A Low-Altitude, Autonomous\
    \ Remote-Sensing Robotic Helicopter for\nHigh-Throughput Field-Based Phenotyping.\
    \ Agronomy 2014, 4, 279. [CrossRef]\n40.\nGevaert, C.M.; Suomalainen, J.; Tang,\
    \ J.; Kooistra, L. Generation of Spectral–Temporal Response Surfaces by\nCombining\
    \ Multispectral Satellite and Hyperspectral UAV Imagery for Precision Agriculture\
    \ Applications.\nIEEE J. Stars 2015, 8, 3140–3146. [CrossRef]\n41.\nZaman-Allah,\
    \ M.; Vergara, O.; Araus, J.L.; Tarekegne, A.; Magorokosho, C.; Zarco-Tejada,\
    \ P.J.; Hornero, A.;\nAlbà, A.H.; Das, B.; Craufurd, P.; et al. Unmanned aerial\
    \ platform-based multi-spectral imaging for ﬁeld\nphenotyping of maize. Plant.\
    \ Methods 2015, 11, 35. [CrossRef] [PubMed]\n42.\nAraus, J.L.; Cairns, J.E. Field\
    \ high-throughput phenotyping: The new crop breeding frontier. Trends Plant Sci.\n\
    2014, 19, 52–61. [CrossRef]\n43.\nHilker, T.; Gitelson, A.; Coops, N.C.; Hall,\
    \ F.G.; Black, T.A. Tracking plant physiological properties from\nmulti-angular\
    \ tower-based remote sensing. Oecologia 2011, 165, 865–876. [CrossRef] [PubMed]\n\
    44.\nYang, G.; Liu, J.; Zhao, C.; Li, Z.; Huang, Y.; Yu, H.; Xu, B.; Yang, X.;\
    \ Zhu, D.; Zhang, X.; et al. Unmanned Aerial\nVehicle Remote Sensing for Field-Based\
    \ Crop Phenotyping: Current Status and Perspectives. Front. Plant Sci.\n2017,\
    \ 8, 1111. [CrossRef] [PubMed]\nRemote Sens. 2020, 12, 3216\n27 of 30\n45.\nGago,\
    \ J.; Douthe, C.; Coopman, R.E.; Gallego, P.P.; Ribas-Carbo, M.; Flexas, J.; Escalona,\
    \ J.; Medrano, H. UAVs\nchallenge to assess water stress for sustainable agriculture.\
    \ Agric. Water Manag. 2015, 153, 9–19. [CrossRef]\n46.\nLelong, C.; Burger, P.;\
    \ Jubelin, G.; Roux, B.; Labbé, S.; Baret, F. Assessment of Unmanned Aerial Vehicles\n\
    Imagery for Quantitative Monitoring of Wheat Crop in Small Plots. Sensors 2008,\
    \ 8, 3557. [CrossRef]\n[PubMed]\n47.\nMaes, W.H.; Steppe, K. Perspectives for\
    \ Remote Sensing with Unmanned Aerial Vehicles in Precision\nAgriculture. Trends\
    \ Plant Sci. 2018, 24, 152–164. [CrossRef] [PubMed]\n48.\nShi, Y.; Thomasson,\
    \ J.A.; Murray, S.C.; Pugh, N.A.; Rooney, W.L.; Shaﬁan, S.; Rajan, N.; Rouze,\
    \ G.;\nMorgan, C.L.S.; Neely, H.L.; et al. Unmanned Aerial Vehicles for High-Throughput\
    \ Phenotyping and\nAgronomic Research. PLoS ONE 2016, 11, e0159781. [CrossRef]\n\
    49.\nBarbedo, J.G.A. A Review on the Use of Unmanned Aerial Vehicles and Imaging\
    \ Sensors for Monitoring and\nAssessing Plant Stresses. Drones 2019, 3, 40. [CrossRef]\n\
    50.\nJang, G.; Kim, J.; Yu, J.-K.; Kim, H.-J.; Kim, Y.; Kim, D.-W.; Kim, K.-H.;\
    \ Lee, C.W.; Chung, Y.S. Review:\nCost-Eﬀective Unmanned Aerial Vehicle (UAV)\
    \ Platform for Field Plant Breeding Application. Remote Sens.\n2020, 12, 998.\
    \ [CrossRef]\n51.\nSankaran, S.; Khot, L.R.; Espinoza, C.Z.; Jarolmasjed, S.;\
    \ Sathuvalli, V.R.; Vandemark, G.J.; Miklas, P.N.;\nCarter, A.H.; Pumphrey, M.O.;\
    \ Knowles, N.R. Low-altitude, high-resolution aerial imaging systems for row\n\
    and ﬁeld crop phenotyping: A review. Eur. J. Agron. 2015, 70, 112–123. [CrossRef]\n\
    52.\nGuan, S.; Fukami, K.; Matsunaka, H.; Okami, M.; Tanaka, R.; Nakano, H.; Sakai,\
    \ T.; Nakano, K.; Ohdan, H.;\nTakahashi, K. Assessing Correlation of High-Resolution\
    \ NDVI with Fertilizer Application Level and Yield of\nRice and Wheat Crops Using\
    \ Small UAVs. Remote Sens. 2019, 11, 112. [CrossRef]\n53.\nYeom, J.; Jung, J.;\
    \ Chang, A.; Maeda, M.; Landivar, J. Automated Open Cotton Boll Detection for\
    \ Yield\nEstimation Using Unmanned Aircraft Vehicle (UAV) Data. Remote Sens. 2018,\
    \ 10, 1895. [CrossRef]\n54.\nRasmussen, J.; Nielsen, J.; Garcia-Ruiz, F.; Christensen,\
    \ S.; Streibig, J.C. Potential uses of small unmanned\naircraft systems (UAS)\
    \ in weed research. Weed Res. 2013, 53, 242–248. [CrossRef]\n55.\nGao, J.; Liao,\
    \ W.; Nuyttens, D.; Lootens, P.; Vangeyte, J.; Pižurica, A.; He, Y.; Pieters,\
    \ J.G. Fusion of pixel\nand object-based features for weed mapping using unmanned\
    \ aerial vehicle imagery. Int. J. Appl. Earth\nObs. Geoinf. 2018, 67, 43–53. [CrossRef]\n\
    56.\nJay, S.; Baret, F.; Dutartre, D.; Malatesta, G.; Héno, S.; Comar, A.; Weiss,\
    \ M.; Maupas, F. Exploiting the\ncentimeter resolution of UAV multispectral imagery\
    \ to improve remote-sensing estimates of canopy structure\nand biochemistry in\
    \ sugar beet crops. Remote Sens. Environ. 2019, 231, 110898. [CrossRef]\n57.\n\
    Zarco-Tejada, P.J.; Guillén-Climent, M.L.; Hernández-Clemente, R.; Catalina, A.;\
    \ González, M.R.; Martín, P.\nEstimating leaf carotenoid content in vineyards\
    \ using high resolution hyperspectral imagery acquired from\nan unmanned aerial\
    \ vehicle (UAV). Agric. Forest Meteorol. 2013, 171–172, 281–294. [CrossRef]\n\
    58.\nBerni, J.A.J.; Zarco-Tejada, P.J.; Sepulcre-Cantó, G.; Fereres, E.; Villalobos,\
    \ F. Mapping canopy conductance\nand CWSI in olive orchards using high resolution\
    \ thermal remote sensing imagery. Remote Sens. Environ.\n2009, 113, 2380–2388.\
    \ [CrossRef]\n59.\nSepúlveda-Reyes, D.; Ingram, B.; Bardeen, M.; Zúñiga, M.; Ortega-Farías,\
    \ S.; Poblete-Echeverría, C.\nSelecting canopy zones and thresholding approaches\
    \ to assess grapevine water status by using aerial\nand ground-based thermal imaging.\
    \ Remote Sens. 2016, 8, 822. [CrossRef]\n60.\nReinert, S.; Bögelein, R.; Thomas,\
    \ F.M. Use of thermal imaging to determine leaf conductance along a canopy\ngradient\
    \ in European beech (Fagus sylvatica). Tree Physiol. 2012, 32, 294–302. [CrossRef]\n\
    61.\nPou, A.; Diago, M.P.; Medrano, H.; Baluja, J.; Tardaguila, J. Validation\
    \ of thermal indices for water status\nidentiﬁcation in grapevine. Agric. Water\
    \ Manag. 2014, 134, 60–72. [CrossRef]\n62.\nBaluja, J.; Diago, M.P.; Balda, P.;\
    \ Zorer, R.; Meggio, F.; Morales, F.; Tardaguila, J. Assessment of vineyard\n\
    water status variability by thermal and multispectral imagery using an unmanned\
    \ aerial vehicle (UAV).\nIrrig. Sci. 2012, 30, 511–522. [CrossRef]\n63.\nMöller,\
    \ M.; Alchanatis, V.; Cohen, Y.; Meron, M.; Tsipris, J.; Naor, A.; Ostrovsky,\
    \ V.; Sprintsin, M.; Cohen, S.\nUse of thermal and visible imagery for estimating\
    \ crop water status of irrigated grapevine. J. Exp. Bot. 2006,\n58, 827–838. [CrossRef]\
    \ [PubMed]\n64.\nMaimaitiyiming, M.; Ghulam, A.; Bozzolo, A.; Wilkins, J.L.; Kwasniewski,\
    \ M.T. Early Detection of Plant\nPhysiological Responses to Diﬀerent Levels of\
    \ Water Stress Using Reﬂectance Spectroscopy. Remote Sens.\n2017, 9, 745. [CrossRef]\n\
    Remote Sens. 2020, 12, 3216\n28 of 30\n65.\nMaimaitiyiming, M.; Sagan, V.; Sidike,\
    \ P.; Kwasniewski, M.T. Dual Activation Function-Based Extreme\nLearning Machine\
    \ (ELM) for Estimating Grapevine Berry Yield and Quality. Remote Sens. 2019, 11,\
    \ 740.\n[CrossRef]\n66.\nAnderson, D.B. Relative humidity or vapor pressure deﬁcit.\
    \ Ecology 1936, 17, 277–282. [CrossRef]\n67.\nStruthers, R.; Ivanova, A.; Tits,\
    \ L.; Swennen, R.; Coppin, P. Thermal infrared imaging of the temporal\nvariability\
    \ in stomatal conductance for fruit trees. Int. J. App. Earth Obs. Geoinf. 2015,\
    \ 39, 9–17. [CrossRef]\n68.\nFlexas, J.; Briantais, J.-M.; Cerovic, Z.; Medrano,\
    \ H.; Moya, I. Steady-State and Maximum Chlorophyll\nFluorescence Responses to\
    \ Water Stress in Grapevine Leaves:\nA New Remote Sensing System.\nRemote Sens.\
    \ Environ. 2000, 73, 283–297. [CrossRef]\n69.\nPapageorgiou, G.C. Chlorophyll\
    \ a Fluorescence: A Signature of Photosynthesis; Springer Science & Business\n\
    Media: Berlin/Heidelberg, Germany, 2007; Volume 19.\n70.\nZarco-Tejada, P.J.;\
    \ Catalina, A.; González, M.; Martín, P. Relationships between net photosynthesis\
    \ and\nsteady-state chlorophyll ﬂuorescence retrieved from airborne hyperspectral\
    \ imagery. Remote Sens. Environ.\n2013, 136, 247–258. [CrossRef]\n71.\nRahmati,\
    \ M.; Mirás-Avalos, J.M.; Valsesia, P.; Lescourret, F.; Génard, M.; Davarynejad,\
    \ G.H.; Bannayan, M.;\nAzizi, M.; Vercambre, G. Disentangling the eﬀects of water\
    \ stress on carbon acquisition, vegetative growth,\nand fruit quality of peach\
    \ trees by means of the QualiTree model. Front. Plant Sci. 2018, 9, 3. [CrossRef]\n\
    72.\nDecagon Devices. Leaf Porometer—Operator’s Manual: Version: October 17, 2016;\
    \ Decagon Devices: Pullman,\nWA, USA, 2016.\n73.\nSagan, V.; Maimaitijiang, M.;\
    \ Sidike, P.; Eblimit, K.; Peterson, K.T.; Hartling, S.; Esposito, F.; Khanal,\
    \ K.;\nNewcomb, M.; Pauli, D.; et al. UAV-Based High Resolution Thermal Imaging\
    \ for Vegetation Monitoring,\nand Plant Phenotyping Using ICI 8640 P, FLIR Vue\
    \ Pro R 640, and thermoMap Cameras. Remote Sens. 2019,\n11, 330. [CrossRef]\n\
    74.\nMaimaitijiang, M.; Sagan, V.; Sidike, P.; Hartling, S.; Esposito, F.; Fritschi,\
    \ F.B. Soybean yield prediction from\nUAV using multimodal data fusion and deep\
    \ learning. Remote Sens. Environ. 2020, 237, 111599. [CrossRef]\n75.\nConel, J.E.;\
    \ Green, R.O.; Vane, G.; Bruegge, C.J.; Alley, R.E.; Curtiss, B.J. AIS-2 radiometry\
    \ and a comparison of\nmethods for the recovery of ground reﬂectance. In Proceedings\
    \ of the Third Airborne Imaging Spectrometer\nData Analysis Workshop, Pasadena,\
    \ CA, USA, 8–10 April 1985.\n76.\nRaczko, E.; Zagajewski, B. Comparison of support\
    \ vector machine, random forest and neural network\nclassiﬁers for tree species\
    \ classiﬁcation on airborne hyperspectral APEX images. Eur. J. Remote Sens. 2017,\
    \ 50,\n144–154. [CrossRef]\n77.\nNevalainen, O.; Honkavaara, E.; Tuominen, S.;\
    \ Viljanen, N.; Hakala, T.; Yu, X.; Hyyppä, J.; Saari, H.;\nPölönen, I.; Imai,\
    \ N. Individual tree detection and classiﬁcation with UAV-based photogrammetric\
    \ point\nclouds and hyperspectral imaging. Remote Sens. 2017, 9, 185. [CrossRef]\n\
    78.\nSidike, P.; Sagan, V.; Maimaitijiang, M.; Maimaitiyiming, M.; Shakoor, N.;\
    \ Burken, J.; Mockler, T.; Fritschi, F.B.\ndPEN: Deep Progressively Expanded Network\
    \ for mapping heterogeneous agricultural landscape using\nWorldView-3 satellite\
    \ imagery. Remote Sens. Environ. 2019, 221, 756–772. [CrossRef]\n79.\nEssa, A.;\
    \ Sidike, P.; Asari, V. Volumetric Directional Pattern for Spatial Feature Extraction\
    \ in Hyperspectral\nImagery. IEEE Geosci. Remote Sens. 2017, 14, 1056–1060. [CrossRef]\n\
    80.\nSumsion, G.R.; Bradshaw, M.S.; Hill, K.T.; Pinto, L.D.G.; Piccolo, S.R. Remote\
    \ sensing tree classiﬁcation with\na multilayer perceptron. PeerJ 2019, 7, e6101.\
    \ [CrossRef]\n81.\nCanny, J. A computational approach to edge detection. IEEE\
    \ Trans. Pattern Anal. Mach. Intell. 1986, 679–698.\n[CrossRef]\n82.\nBian, J.;\
    \ Zhang, Z.; Chen, J.; Chen, H.; Cui, C.; Li, X.; Chen, S.; Fu, Q. Simpliﬁed Evaluation\
    \ of Cotton\nWater Stress Using High Resolution Unmanned Aerial Vehicle Thermal\
    \ Imagery. Remote Sens. 2019, 11, 267.\n[CrossRef]\n83.\nPark, S.; Ryu, D.; Fuentes,\
    \ S.; Chung, H.; Hernández-Montes, E.; O’Connell, M. Adaptive Estimation of Crop\n\
    Water Stress in Nectarine and Peach Orchards Using High-Resolution Imagery from\
    \ an Unmanned Aerial\nVehicle (UAV). Remote Sens. 2017, 9, 828. [CrossRef]\n84.\n\
    Takala, T.L.H.; Mõttus, M. Spatial variation of canopy PRI with shadow fraction\
    \ caused by leaf-level\nirradiation conditions. Remote Sens. Environ. 2016, 182,\
    \ 99–112. [CrossRef]\nRemote Sens. 2020, 12, 3216\n29 of 30\n85.\nGruninger, J.H.;\
    \ Ratkowski, A.J.; Hoke, M.L. The sequential maximum angle convex cone (SMACC)\n\
    endmember model. In Algorithms and Technologies for Multispectral, Hyperspectral,\
    \ and Ultraspectral Imagery X,\nProceedings of SPIE; Orlando, FL, USA, 12–15 April\
    \ 2004, Shen, S.S., Lewis, P.E., Eds.; SPIE: Bellingham, WA,\nUSA, 2004; Volume\
    \ 5425, pp. 1–14.\n86.\nMacQueen, J. Some methods for classiﬁcation and analysis\
    \ of multivariate observations. In Proceedings\nof the Fifth Berkeley Symposium\
    \ on Mathematical Statistics and Probability, Berkeley, CA, USA,\n21 June–18 July\
    \ 1967; Volume 1, pp. 281–297.\n87.\nPlascyk, J.A.; Gabriel, F.C. The Fraunhofer\
    \ line discriminator MKII-an airborne instrument for precise\nand standardized\
    \ ecological luminescence measurement. IEEE Trans. Instrum. Meas. 1975, 24, 306–313.\n\
    [CrossRef]\n88.\nCamino, C.; Gonzalez-Dugo, V.; Hernandez, P.; Zarco-Tejada, P.J.\
    \ Radiative transfer Vcmax estimation from\nhyperspectral imagery and SIF retrievals\
    \ to assess photosynthetic performance in rainfed and irrigated plant\nphenotyping\
    \ trials. Remote Sens. Environ. 2019, 111186. [CrossRef]\n89.\nDamm, A.; Erler,\
    \ A.; Hillen, W.; Meroni, M.; Schaepman, M.E.; Verhoef, W.; Rascher, U. Modeling\
    \ the impact\nof spectral sensor conﬁgurations on the FLD retrieval accuracy of\
    \ sun-induced chlorophyll ﬂuorescence.\nRemote Sens. Environ. 2011, 115, 1882–1892.\
    \ [CrossRef]\n90.\nZarco-Tejada, P.J.; Miller, J.R.; Noland, T.L.; Mohammed, G.H.;\
    \ Sampson, P.H. Scaling-up and model inversion\nmethods with narrowband optical\
    \ indices for chlorophyll content estimation in closed forest canopies with\n\
    hyperspectral data. IEEE Trans. Geosci. Remote Sens. 2001, 39, 1491–1507. [CrossRef]\n\
    91.\nRouse, J.W., Jr.; Haas, R.; Schell, J.; Deering, D. Monitoring vegetation\
    \ systems in the Great Plains with\nERTS. In Proceedings of the 3rd ERTS Symposium,\
    \ Washington, DC, USA, 10–14 December 1973; Volume 1,\npp. 309–317.\n92.\nJordan,\
    \ C.F. Derivation of Leaf-Area Index from Quality of Light on the Forest Floor.\
    \ Ecology 1969, 50,\n663–666. [CrossRef]\n93.\nPeñuelas, J.; Filella, I.; Biel,\
    \ C.; Serrano, L.; Save, R. The reﬂectance at the 950–970 nm region as an indicator\n\
    of plant water status. Int. J. Remote Sens. 1993, 14, 1887–1905. [CrossRef]\n\
    94.\nJones, H. Plants and Microclimate: A Quantitative Approach to Environmental\
    \ Plant Physiology; Cambridge\nUniversity Press: Cambridge, UK, 1992.\n95.\nAlchanatis,\
    \ V.; Cohen, Y.; Cohen, S.; Moller, M.; Sprinstin, M.; Meron, M.; Tsipris, J.;\
    \ Saranga, Y.; Sela, E.\nEvaluation of diﬀerent approaches for estimating and\
    \ mapping crop water status in cotton with thermal\nimaging. Precis. Agric. 2010,\
    \ 11, 27–41. [CrossRef]\n96.\nLeinonen, I.; Jones, H.G. Combining thermal and\
    \ visible imagery for estimating canopy temperature and\nidentifying plant stress.\
    \ J. Exp. Bot. 2004, 55, 1423–1431. [CrossRef]\n97.\nRomero-Trigueros, C.; Bayona\
    \ Gambín, J.M.; Nortes Tortosa, P.A.; Alarcón Cabañero, J.J.; Nicolás Nicolás,\
    \ E.\nDetermination of Crop Water Stress Index by Infrared Thermometry in Grapefruit\
    \ Trees Irrigated with Saline\nReclaimed Water Combined with Deﬁcit Irrigation.\
    \ Remote Sens. 2019, 11, 757. [CrossRef]\n98.\nMeron, M.; Sprintsin, M.; Tsipris,\
    \ J.; Alchanatis, V.; Cohen, Y. Foliage temperature extraction from thermal\n\
    imagery for crop water stress determination. Precis. Agric. 2013, 14, 467–477.\
    \ [CrossRef]\n99.\nPeterson, K.T.; Sagan, V.; Sidike, P.; Hasenmueller, E.A.;\
    \ Sloan, J.J.; Knouft, J.H.J.P.E.; Sensing, R. Machine\nLearning-Based Ensemble\
    \ Prediction of Water-Quality Variables Using Feature-Level and Decision-Level\n\
    Fusion with Proximal Remote Sensing. Photogramm. Eng. Remote Sens. 2019, 85, 269–280.\
    \ [CrossRef]\n100. Ghulam, A.; Kusky, T.M.; Teyip, T.; Qin, Q. Sub-canopy soil\
    \ moisture modeling in n-dimensional spectral\nfeature space. Photogramm. Eng.\
    \ Remote Sens. 2011, 77, 149–156. [CrossRef]\n101. Zarco-Tejada, P.J.; Berni,\
    \ J.A.; Suárez, L.; Sepulcre-Cantó, G.; Morales, F.; Miller, J. Imaging chlorophyll\n\
    ﬂuorescence with an airborne narrow-band multispectral camera for vegetation stress\
    \ detection.\nRemote Sens. Environ. 2009, 113, 1262–1275. [CrossRef]\n102. Gerhards,\
    \ M.; Schlerf, M.; Rascher, U.; Udelhoven, T.; Juszczak, R.; Alberti, G.; Miglietta,\
    \ F.; Inoue, Y. Analysis\nof Airborne Optical and Thermal Imagery for Detection\
    \ of Water Stress Symptoms. Remote Sens. 2018, 10,\n1139. [CrossRef]\n103. Zarco-Tejada,\
    \ P.J.; González-Dugo, V.; Williams, L.E.; Suárez, L.; Berni, J.A.J.; Goldhamer,\
    \ D.; Fereres, E.\nA PRI-based water stress index combining structural and chlorophyll\
    \ eﬀects: Assessment using diurnal\nnarrow-band airborne imagery and the CWSI\
    \ thermal index. Remote Sens. Environ. 2013, 138, 38–50.\n[CrossRef]\nRemote Sens.\
    \ 2020, 12, 3216\n30 of 30\n104. Hall, F.G.; Hilker, T.; Coops, N.C.; Lyapustin,\
    \ A.; Huemmrich, K.F.; Middleton, E.; Margolis, H.; Drolet, G.;\nBlack, T.A. Multi-angle\
    \ remote sensing of forest light use eﬃciency by observing PRI variation with\
    \ canopy\nshadow fraction. Remote Sens. Environ. 2008, 112, 3201–3211. [CrossRef]\n\
    105. Hilker, T.; Hall, F.G.; Coops, N.C.; Lyapustin, A.; Wang, Y.; Nesic, Z.;\
    \ Grant, N.; Black, T.A.; Wulder, M.A.;\nKljun, N.; et al.\nRemote sensing of\
    \ photosynthetic light-use eﬃciency across two forested biomes:\nSpatial scaling.\
    \ Remote Sens. Environ. 2010, 114, 2863–2874. [CrossRef]\n106. Zhang, Q.; Chen,\
    \ J.M.; Ju, W.; Wang, H.; Qiu, F.; Yang, F.; Fan, W.; Huang, Q.; Wang, Y.-P.;\
    \ Feng, Y.; et al.\nImproving the ability of the photochemical reﬂectance index\
    \ to track canopy light use eﬃciency through\ndiﬀerentiating sunlit and shaded\
    \ leaves. Remote Sens. Environ. 2017, 194, 1–15. [CrossRef]\n107. Sepulcre-Cantó,\
    \ G.; Zarco-Tejada, P.; Jiménez-Muñoz, J.; Sobrino, J.; de Miguel, E.; Villalobos,\
    \ F. Within-ﬁeld\nthermal variability detection as function of water stress in\
    \ Olea europaea L. orchards with high spatial remote\nsensing imagery. Agric.\
    \ For. Meteorol. 2006, 136, 31–44. [CrossRef]\n108. Belﬁore, N.; Vinti, R.; Lovat,\
    \ L.; Chitarra, W.; Tomasi, D.; de Bei, R.; Meggio, F.; Gaiotti, F. Infrared\n\
    Thermography to Estimate Vine Water Status: Optimizing Canopy Measurements and\
    \ Thermal Indices for\nthe Varieties Merlot and Moscato in Northern Italy. Agronomy\
    \ 2019, 9, 821. [CrossRef]\n109. Bellvert, J.; Marsal, J.; Girona, J.; Zarco-Tejada,\
    \ P.J. Seasonal evolution of crop water stress index in grapevine\nvarieties determined\
    \ with high-resolution remote sensing thermal imagery. Irrig. Sci. 2015, 33, 81–93.\n\
    [CrossRef]\n© 2020 by the authors. Licensee MDPI, Basel, Switzerland. This article\
    \ is an open access\narticle distributed under the terms and conditions of the\
    \ Creative Commons Attribution\n(CC BY) license (http://creativecommons.org/licenses/by/4.0/).\n"
  inline_citation: '>'
  journal: Remote sensing (Basel)
  limitations: '>'
  pdf_link: https://www.mdpi.com/2072-4292/12/19/3216/pdf?version=1602213928
  publication_year: 2020
  relevance_score1: 0
  relevance_score2: 0
  title: Leveraging Very-High Spatial Resolution Hyperspectral and Thermal UAV Imageries
    for Characterizing Diurnal Indicators of Grapevine Physiology
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'

- DOI: https://doi.org/10.1016/s0034-4257(01)00299-1
  analysis: '>'
  authors:
  - Ian B. Strachan
  - E. Pattey
  - J. B. Boisvert
  citation_count: 253
  full_citation: '>'
  full_text: '>

    Skip to main content Skip to article Journals & Books Search Register Sign in
    Brought to you by: University of Nebraska-Lincoln View PDF Download full issue
    Outline Abstract Keywords 1. Introduction 2. The study area 3. Materials and methods
    4. Results and discussion 5. Summary Acknowledgements References Show full outline
    Cited by (267) Figures (9) Show 3 more figures Tables (3) Table 1 Table 2 Table
    3 Remote Sensing of Environment Volume 80, Issue 2, May 2002, Pages 213-224 Impact
    of nitrogen and environmental conditions on corn as detected by hyperspectral
    reflectance Author links open overlay panel Ian B. Strachan a, Elizabeth Pattey
    b, Johanne B. Boisvert c Show more Add to Mendeley Share Cite https://doi.org/10.1016/S0034-4257(01)00299-1
    Get rights and content Abstract Indices derived from hyperspectral reflectance
    spectra have the potential to be used as indicators of environmental stress in
    crops. This study uses canopy-scale, ground-based measurements of hyperspectral
    reflectance to demonstrate the temporal patterns in corn development under imposed
    fertility (N rate) and environmental (water availability) stresses. In 1998, two
    large areas in a 30-ha corn (Zea mays, L.) field near Ottawa, Canada (45°18′N,
    75°44′W) were supplied with 99 and 17 kg N ha−1, while the balance of the field
    received the recommended rate of 155 kg N ha−1. Reflectance measurements were
    taken nine times using a portable spectroradiometer at georeferenced locations
    within these areas. Individual reflectance-based indices demonstrated the relative
    differences between application rates and identified both nitrogen and water stresses
    at various times in the growing season. No single index was able to describe the
    status of the corn crop throughout the season. Canonical discriminant analysis
    provided accurate classification of samples by N rate during early, mid, and late
    season conditions with overall success rates of 70%, 88%, and 93%, respectively.
    A shift in importance from green-based derivatives to red-based derivatives was
    noted from mid to late season and attributed to the natural reduction in green
    pigments as the crop entered senescence. Canopy-scale photochemical reflectance
    index (PRI) was shown to be correlated with canopy radiation use efficiency (RUE).
    Mid-season water stress affected the relationship. Multiple years of data are
    required to demonstrate robust relationships between hyperspectral indices and
    corn ecophysiological status because of the interaction between environmental
    and nutrient stresses. Identifying areas of fields sensitive to weather-induced
    stresses will allow better management of N application. Timing the collection
    of hyperspectral image data at early and late vegetative phase could enhance precision
    agriculture by allowing supplemental nutrient application, identifying stress
    patterns and aid in yield forecasting. Previous article in issue Next article
    in issue Keywords Hyperspectral reflectancePrecision agricultureStress detectionCorn
    fieldRadiation use efficiencyChlorophyllLeaf area indexCrop water content 1. Introduction
    Reflectance spectra have been studied intensively as a means to remotely detect
    the status of crops Hatfield & Pinter, 1993, Jackson, 1984. Hyperspectral sensors
    measure reflectance in a large number of narrow wavebands, generally with bandwidths
    of less than 10 nm. With these narrow bands, reflectance and absorption features
    related to specific crop physical and chemical characteristics can be detected.
    Research has indicated good relationships between biochemical composition, physical
    structure, water content, and plant ecophysiological status (e.g., Gamon et al.,
    1992, Peñuelas & Filella, 1998). Numerous indices have been developed, which attempt
    to detect conditions of stress within the crop. Such vegetation indices are usually
    normalized to minimize atmospheric interference by “calculating” ratios or linear
    combinations of two or more wavelengths within the visible and near-infrared (NIR).
    Gamon et al. (1992) introduced a photochemical reflectance index (PRI), which
    is associated with radiation use efficiency (RUE). Peñuelas, Filella, Biel, Serrano,
    and Savé (1993) and Peñuelas, Piñol, Ogaya, and Filella (1997) used the NIR water
    absorption band to develop a Water Band Index (WBI) as a measure of plant moisture
    status, and Demetriades-Shah, Steven, and Clark (1990) explored the use of the
    transition point between the red and NIR (termed the red edge) as an indicator
    of plant stress. Although much hyperspectral reflectance work to date has been
    done at the leaf scale, typically on excised leaves, in situ measurements made
    above the canopy are becoming more widely used, driven by the need to simulate
    the scales involved in airborne or satellite measurements (i.e., remotely sensed
    imagery at the canopy scale). This work is intimately connected to the growing
    body of research in precision agriculture where the ability to detect the ecophysiological
    status of crops and relate it to management practices at the field scale necessitates
    the use of remote sensing from airborne or satellite platforms. In this experiment,
    our intention was to use ground-based hyperspectral remote sensing and micrometeorological
    techniques to monitor different N application rates within field-grown corn. The
    idea was to simulate variable rate fertilization through different application
    rates and monitor crop growth within the resulting variability in N stress across
    large sections of the field. Results of this work were published in Pattey, Strachan,
    Boisvert, Desjardins, and McLaughlin (2001) who used crop water use efficiency
    measured in situ as an indicator of corn response to environmental stresses. Their
    results suggested that the corn growth in this study year was influenced significantly
    by water availability. Sections of the field receiving the optimum N application
    rate displayed greater signs of water stress during the vegetative phase when
    soil water decreased because of the faster rate of leaf expansion. The change
    in crop ecophysiological status was measured by a reduction in water use efficiency
    as compared to other portions of the field. This paper reports our attempts to
    detect the effects of environmental stress (those driven by weather conditions)
    and nitrogen stress (from application rates) on the same corn crop using hyperspectral
    reflectance indices available in the literature. We applied such indices to reflectance
    data collected using a portable spectroradiometer above the corn canopy from a
    distance where the sensor is detecting the top of the canopy. These results will
    serve as an exploration in support of subsequent work at the canopy level in conjunction
    with aircraft-based hyperspectral measurements at this field site. The objectives
    of the research presented in this paper were: 1. To use canopy-scale hyperspectral
    indices to detect both environmental and N stresses as they occurred throughout
    a growing season. 2. To determine if canopy-scale hyperspectral indices could
    be used to discriminate between N application rates at various times throughout
    the growing season. 2. The study area The experiment site is presented in detail
    in Pattey et al. (2001) and only a brief description is provided here. A corn
    crop (Pioneer 3893; 2700 CHU) was planted on a 30-ha ploughed field consisting
    of a drained clay loam soil (Dalhousie series) near Ottawa, Canada (45°18′N, 75°44′W)
    in May 1998. The field was divided into three regions as follows: a 2.6-ha area
    (175×150 m) received 17 kg N ha−1 as starter fertilization; a 3.7-ha area (half
    an octagon shape of about 250×170 m) received a rate of 99 kg N ha−1 or 64% of
    the recommended rate; the remainder of the field received the recommended rate
    of 155 kg N ha−1. These areas were termed 17N, 99N, and 155N, respectively. The
    experimental design simulated a typical range in application rates and provided
    an artificial control area. Within each application rate, and in a representative
    150×150 m section of 155N, an array of georeferenced points spaced every 50 m
    was established resulting in nine sampling locations in the 155N and 17N areas.
    Within the 99N area, there were 13 sample locations. 3. Materials and methods
    3.1. Plant sampling Measurements of plant biomass components (leaf, stalk, and
    grain mass and moisture content; plant height) and destructive leaf area index
    (LAI) were obtained by randomly harvesting 20 plants from each of the three N
    application areas on seven occasions during the season. LAI was measured by passing
    all leaves through an area meter (LI-3100, LI-COR, Lincoln, NE) and multiplying
    the resulting total leaf area per plant by the average plant density of 6.67 plants
    m−2. Estimates of leaf chlorophyll content were obtained using a portable chlorophyll
    meter (SPAD-502, Minolta, Japan). SPAD readings were made in situ on the plants
    designated for harvesting, midway along the youngest fully expanded leaf. The
    relationship developed by Dwyer, Tollenaar, and Houwing (1991) for corn was used
    to convert SPAD readings to chlorophyll concentration per unit leaf area (mg m−2).
    These estimates were scaled to the canopy by multiplying by the appropriate measured
    LAI resulting in chlorophyll concentration per unit ground area (mg m−2). 3.2.
    Micrometeorological measurements Measurements of canopy exchange of CO2 were made
    over the 99N and 155N application rates using eddy covariance measuring systems
    as described in Pattey et al. (2001). Thirty-minute average CO2 fluxes were converted
    to net photosynthesis by subtracting out the CO2 contribution from the soil. Net
    photosynthesis was used with coincident measurements of 30-min average incident
    photosynthetic photon flux density (Qp) made in situ by a quantum sensor (model
    LI-190SA, LI-COR) to compute average canopy RUE (mol CO2 mol−1 Qp) between 10:00
    and 14:00 h Eastern Standard Time on days of hyperspectral reflectance measurements.
    3.3. Reflectance measurements A portable spectroradiometer (GER1500, GER, Millbrook,
    NY) measured radiance between 350 and 1050 nm in wavebands approximately 2 nm
    in width. At each georeferenced location within each area, 5–10 samples were obtained
    from a 2-m radius centred on the georeferenced point. Spectral reflectance was
    calculated as the ratio of measured radiance to radiance from a white standard
    (Spectralon, Labsphere, North Sutton, NH) taken under the same sky conditions
    and immediately preceding the plant radiance measurements. Reflectance measurements
    were obtained nine times between June 9 and September 17, 1998. Measurements were
    made as close to solar noon as possible on days with no overhead cloud cover to
    avoid the effects of solar angle and contributions from diffuse light Lord et
    al., 1988, Lord et al., 1985. Reflectance was averaged over the 5–10 samples collected
    at each location within each area. Initially, a fore-optic lens with a field of
    view (FOV) of 3° was used. Later, as the canopy grew, a longer fibre-optic lens
    (mounted on a metal pole) with a FOV of 23° was used. In each case, the optic
    was fixed in the nadir position viewing the upper portion of the canopy, which
    would be seen by an airborne sensor. The timing of reflectance measurements was
    dictated by the need to adhere to strict protocol regarding sky conditions. The
    plant sampling described above was completed within a few days of the reflectance
    measurements. Prior to crop emergence, reflectance measurements of the bare soil
    surface were made on a 100×100 m grid across the entire field. From these measurements,
    the slope and intercept of the relationship between reflectance in the NIR and
    red (termed the soil line by Baret, Jacquemoud, & Hanocq, 1993) were computed.
    Sporadic spikes in the reflectance spectra were removed using a simple procedure
    without changing any dominant features. Specifically, if the difference between
    the reflectance for waveband “i” (Ri) and that of waveband “i−2” (Ri−2) divided
    by Ri−2 was greater than the seven-band coefficient of variation centred at waveband
    “i,” then the reflectance value was replaced with the average reflectance of the
    surrounding wavebands (Ri−3 to Ri+3). Derivative spectra were computed as the
    slope of the smoothed reflectance spectra using a five-band window centred on
    waveband “i.” 3.4. Hyperspectral indices A number of indices have been developed
    to exploit the narrow waveband properties of hyperspectral reflectance spectra.
    We have highlighted five such indices which have been designed to detect different
    physical and chemical properties that can be related to stress. The Structure-Independent
    Pigment Index (SIPI; Peñuelas, Baret, & Filella, 1995) can be defined as where
    Rx represents the reflectance measurement at x nm. SIPI uses blue and red wavelengths
    to assess the proportion of total photosynthetic pigments to chlorophyll (i.e.,
    carotenoid–chlorophyll ratio). The NIR wavelength is used to account for the structural
    changes that may coincide with pigment changes. Increases in the relative concentration
    of carotenoids have been observed under stress conditions (Young & Britton, 1990).
    Peñuelas, Baret, et al. (1995) and Peñuelas, Gamon, Fredeen, Merino, and Field
    (1994) showed that the ratio of chlorophyll to carotenoids in plants also increased
    during senescence and decreased for healthy plants and therefore SIPI should increase
    in value with stress. The PRI exploits the fact that reflectance at 531 nm has
    been associated with nonradiative dissipation of photon energy via the xanthophyll
    cycle (Gamon et al., 1990). Under excessive light conditions, violaxathin is converted
    rapidly to zeaxanthin via antheraxanthin (Demmig-Adams & Adams, 1996). When light
    limits, this cycle is reversed. These changes result in a detectable reflectance
    signature near 531 nm. PRI was formulated as following Gamon et al. (1992), who
    reported that a reference wavelength of 570 nm may work well under conditions
    of water stress to avoid overlapping spectral features unrelated to the xanthophyll
    signature. PRI is advantageous because it offers a potential means to remotely
    detect RUE in leaves and (more controversially) in canopies Peñuelas et al., 1995,
    Peñuelas et al., 1994. As formulated, PRI decreases with increasing photosynthetic
    efficiency. The water absorption band between 930 and 980 nm can be compared with
    a reference wavelength (900 nm), which does not absorb water resulting in a WBI
    Peñuelas et al., 1993, Peñuelas et al., 1997 where values of WBI increase with
    plant water content. Further research has indicated that the position of the spectral
    water absorption trough is not static but rather shifts during stress conditions
    Peñuelas et al., 1993, Peñuelas et al., 1997, Shibayama et al., 1993 and in response
    to phenology. A floating-position WBI (fWBI) can be defined by the ratio of R900
    and the minima in reflectance between 930 and 980 nm where The normalized difference
    vegetation index (NDVI) is often used as a measure of canopy “greenness.” While
    popular because of its ability to monitor large-scale changes in vegetation, NDVI
    is sensitive to soil optical properties (Rondeaux, Steven, & Baret, 1996). Prior
    to canopy closure, reflectance contamination from the soil can be controlled by
    using various versions of the Soil-Adjusted Vegetation Index (SAVI; Huete, 1988).
    The slope and intercept of the soil line can be used to compute the transformed
    SAVI (TSAVI; Baret & Guyot, 1991). Although TSAVI requires site-specific soil
    characteristics, the soil line information can be easily acquired remotely from
    a precropped field image. Here, we used the variation of a narrow-band TSAVI given
    by Rondeaux et al. (1996): where a and b are the slope and intercept of the soil
    line, respectively, as determined by ground-based reflectance spectra at the 100×100
    m grid previously mentioned. The red edge describes the position of the maximum
    slope of reflectance and defines the transition between the red and near infrared
    portions of the spectrum (Horler, Dockray, & Barber, 1983). Reflectance in the
    red is low because of chlorophyll absorption and is high in the NIR because of
    leaf scattering. Thus, the red edge combines two mechanisms by which plant stress
    may be indicated: variations in chlorophyll content, which are associated with
    nutrient levels, and structural changes, which may be associated with other stresses
    such as water availability. Stress has been shown to cause a shift in the red
    edge position to shorter wavelengths Curran et al., 1995, Filella & Peñuelas,
    1994, Hoque & Hutzler, 1992. Demetriades-Shah et al. (1990) suggested that derivatives
    of canopy reflectance may be used to eliminate the contribution from soil background
    reflectance, thus improving the possibility of isolating the ecophysiological
    state of the canopy. Additionally, we examined a number of indices based on the
    first and second derivatives of reflectance (see Table 1). Table 1. Indices used
    in the discriminant analysis with formulation and reference Index Formulation
    Reference TSAVI a(R875−aR680−b)/[R680+a(R875−b)+0.08(1+a2)] Rondeaux et al., 1996
    R550 Reflectance at 550 nm – R680 Reflectance at 680 nm – Rshoulder Average reflectance
    between 750 and 850 nm – C420 R420/R695 Carter, 1994 SIPI (R800−R445)/(R800−R680)
    Peñuelas et al., 1995 PRI (R570−R531)/(R570+R531) Gamon et al., 1992 WBI R900/R970
    Peñuelas et al., 1997 fWBI R900/min(R930–980) Peñuelas et al., 1997 RE Wavelength
    of red edge Demetriades-Shaw et al., 1990 dRE Value of the first derivative at
    the red edge Demetriades-Shaw et al., 1990 sumEdge Integral of first derivative
    values beneath the red edge maximum Peñuelas et al., 1994 dg Minimum first derivative
    value in the green Peñuelas et al., 1994 dG Maximum first derivative value in
    the green Peñuelas et al., 1994 GGND Normalized difference between dg and dG Peñuelas
    et al., 1994 EGND Normalized difference between the maximum first derivative in
    the green and dRE Peñuelas et al., 1994 ddRE Value of the second derivative at
    the red edge Demetriades-Shaw et al., 1990 ddG Maximum second derivative value
    in the green – 3.5. Multivariate analyses Discriminant analysis offers great potential
    for separating out application rates and eventually to identify areas of the canopy
    that are under ecophysiological stress from various sources. It has been used
    successfully at both leaf (Peñuelas et al., 1994) and canopy (Filella, Serrano,
    Serra, & Peñuelas, 1995) levels. Three days were chosen to represent early (July
    7; Day 184), mid (July 23; Day 204), and late (August 27; Day 239) season conditions
    in the corn canopy. The wavelengths and spectral indices selected for further
    investigation were chosen because of their sensitivity to properties such as plant
    structure, water content, chlorophyll and carotenoid concentrations, and ecophysiological
    status (Table 1). Canonical discriminant analysis was used with a stepwise procedure
    for variable selection for each day of analysis. Data screening resulted in unequal
    sample sizes between application rates for a given day. Probabilities for classification
    were derived from the sample size for all canonical discriminant analysis. 4.
    Results and discussion 4.1. Detection of environmental and N stresses Destructive
    LAI and SPAD readings indicated that, initially, plants in the 155N application
    rate had faster leaf expansion than their counterparts in the 99N and 17N application
    rate areas. This pattern changed mid-season, and thereafter, the 155N and 99N
    regions displayed similar leaf deployment (Fig. 1a). The 17N region showed lower
    chlorophyll content throughout the season compared with the 99N and 155N (Fig.
    1b and c). This was especially evident from Day 210 onwards when the SPAD readings
    for 17N were up to 20% less than the 99N and 155N. A clearly lower LAI in the
    17N appeared after this point. The short-term observed impact of reduced N was
    a delay in leaf expansion during the early stages (as seen in the 17N and 99N).
    Download : Download full-size image Fig. 1. Seasonal course of (a) destructive
    LAI, (b) SPAD reading, and (c) estimated canopy chlorophyll content. Error bars
    represent 95% CI. (a) is reprinted from Pattey et al. (2001): Effects of nitrogen
    application rate and weather on corn using micrometeorological and hyperspectral
    reflectance measurements (Fig. 4b, p. 92, Copyright (2001)), with permission from
    Elsevier Science. The impact of mid-season transient water stress can be demonstrated
    in the canopy chlorophyll content for each application rate. Up to 51 days after
    sowing (DAS), the canopy chlorophyll content increased with N application rate
    (Fig. 1c). Two weeks later (64 DAS), the chlorophyll content of the 155N is lower
    than that in the 99N area. The measurements at 64 DAS corresponded to a period
    of reduced rainfall within which the larger 155N canopy experienced water stress,
    which slowed leaf expansion relative to the 99N canopy. Eddy covariance measurements
    of canopy evapotranspiration and CO2 flux for the same experimental period indicated
    that the 99N had higher water use efficiency than the 155N during the water stress
    period (Pattey et al., 2001). By 85 DAS, the water stress period had ended and
    the higher N application rate allowed the 155N canopy chlorophyll content to rise
    to a comparable level to that of the 99N application rate. The net effect of the
    mid-season transient water stress is that a period of reduced expansion slowed
    the growth of the higher N corn and resulted in a yield for the 155N corn that
    was similar to that in the 99N area of the field (Pattey et al., 2001). SPAD readings,
    and, therefore, by extension, chlorophyll contents, were found to be best correlated
    with green reflectance at 556 nm (Fig. 2a). A significant relationship between
    SPAD and R556 nm was found across all N application rate areas (Fig. 2b). These
    findings would make the remote estimation of leaf chlorophyll contents at the
    field scale by aircraft possible, although multiple years of data are necessary
    to strengthen these relationships. LAI could be determined by a normalized vegetation
    index (Fig. 2c) enabling the scaling of chlorophyll to the canopy level in the
    absence of direct LAI measurements. This is especially relevant for the early
    vegetative phase for corn when early stress detection is important if remediation
    strategies are to occur. Other vegetation indices such as TSAVI may offer better
    discrimination between green biomass and soil, however, they also saturate at
    fairly low LAI values. Download : Download full-size image Fig. 2. (a) Correlation
    by wavelength between SPAD reading and canopy reflectance; (b) the relationship
    between SPAD reading and canopy reflectance at 556 nm for all nitrogen application
    rates; and (c) the relationship between NDVI and LAI fit with a rectangular hyperbola.
    The time series of SIPI indicates only minimal differences between the N application
    rates (Fig. 3). An initial decrease in SIPI associated with chlorophyll production
    is followed by a generally static pattern, which increases again in late summer
    because of senescence. Late in the season, the 17N application rate showed the
    highest values for SIPI indicating a higher proportion of photosynthetic pigments
    to chlorophyll—an indication of stress (Young & Britton, 1990) or in this case,
    senescence. The corresponding reflectance measurement during the water stress
    period was Day 204 (July 23) where SIPI for the 155N is higher (more stress) than
    the 99N application rate. The 155N and 99N remain similar for the remainder of
    the season. Note that SIPI for the 17N remained higher throughout the summer growth
    season in response to reduced N availability and the induced lower chlorophyll
    content in the leaves of plants within this application rate. The relationship
    between SIPI and the carotenoid–chlorophyll ratio is highly nonlinear and SIPI
    has been shown to have a low sensitivity to changes in the carotenoid–chlorophyll
    ratio at low values of SIPI (Peñuelas, Baret, et al., 1995). SIPI has been shown
    to track the larger changes in phenology associated with initial growth and senescence
    and also been used to separate large differences in N application rates (Filella
    et al., 1995). The small magnitude of the differences between application rates
    indicated in Fig. 3 indicates that SIPI alone may not be of use in discriminating
    transient stress in vegetation or in consistently separating levels of N stress
    rates, especially from an airborne or satellite platform. Download : Download
    full-size image Fig. 3. Time series of SIPI for a range of nitrogen applications.
    Error bars represent 95% CI. With the seasonal course of PRI, it was again difficult
    to discern trends except by the end of the season where 17N was indicating clearly
    more positive values of PRI than 99N and 155N—an indication of reduced photosynthetic
    efficiency and a function of senescence (Fig. 4). A general decline in the value
    of PRI was evident, attributable to the increasing photosynthetic efficiency related
    to canopy growth and development, until senescence where PRI increased rapidly.
    Values of PRI are typically small and therefore measured changes can be confounded
    by such effects as canopy structure and instrument error (Peñuelas & Filella,
    1998). RUE was plotted against PRI for six of the sample days representing periods
    with positive RUE. A negative linear relationship between RUE and PRI was found
    for each application rate (Fig. 5). Recall that in this formulation of PRI, increasing
    photosynthetic efficiency is indicated by decreasing values of PRI. The data points
    representing Day 204 fall in the peak growth period of the season where both CO2
    flux and incident Qp were at their highest levels. As mentioned previously, it
    is during this period that the canopy experienced water stress. These points are
    indicated by the circle on Fig. 5 and were not included in the regression fit.
    Water stress has been previously shown to cause the PRI–efficiency relationship
    to diverge (Gamon et al., 1992). There was more scatter (poorer fit) for the 99N
    than the 155N as would be expected; the reduction in N lead to increased spatial
    variability (Pattey et al., 2001). Download : Download full-size image Fig. 4.
    Time series of PRI for a range of nitrogen applications. Error bars represent
    95% CI. Download : Download full-size image Fig. 5. Relationship between canopy
    PRI and canopy RUE for the 99N and 155N regions for six dates between July 2 and
    September 17, 1998. Water-stressed measurements are indicated on the graph and
    correspond to Day 204 (July 23). Error bars represent 95% CI. Canopy-scale estimates
    of PRI provide a potentially powerful mechanism for assessing canopy photosynthesis
    remotely when used in conjunction with measurements of Qp. Nichol et al. (2000)
    examined the relationship between PRI and RUE for canopy-scale coniferous and
    deciduous boreal tree species using the AVIRIS sensor platform and concluded that
    canopy-scale estimates of RUE were feasible but required more study for application
    at larger scales. Peñuelas, Filella, et al. (1995) reported that the relationship
    between PRI and RUE was not constant across species at the leaf scale. In contrast,
    PRI has been shown to be related to photosynthetic RUE for upper canopy leaves
    across species and nutrient application rates (Gamon, Serrano, & Surfus, 1997).
    In this study, data for the peak radiation and growth period under non-environmentally
    stressed conditions were lacking making generalizations difficult. It is clear
    that several years of data for a given species need to be taken before a relationship
    can be established for field-based crops. Environmental influences during critical
    phases of development will cause the relationship between RUE and PRI to change.
    The influence of soil contribution to the spectra prior to significant biomass
    accumulation cannot be discounted also and is likely the cause of the inconsistent
    results from measurements early in the season. Peñuelas and Inoue (2000) used
    ground-based measurements at 45° to minimize the soil contribution and this technique
    should be explored further. The attractiveness of PRI remains with its ability
    to detect short-term variability in canopy photosynthetic efficiency beyond the
    point where NDVI has saturated (Gamon et al., 1992). Although much work has been
    done on diurnal cycles in PRI (e.g., Gamon et al., 1997), the detection threshold
    for events leading to changes in photosynthetic efficiency needs to be evaluated.
    The fixed-position WBI has been positively correlated with water content (Peñuelas
    et al., 1997) and, therefore, such indices may provide an indication of leaf water
    content (LWC) per unit ground area. Using the destructive harvest data collected
    between June 9 and August 27 and excluding samples collected during the water
    stress period, LWC, and vegetative (leaves and stalks) water content (VWC) were
    expressed as kilograms of water per unit ground area by multiplying by the appropriate
    LAI value for each date and application rate. Both VWC and LWC showed good correlation
    with fWBI and two independent relationships emerged (Fig. 6). VWC, which includes
    the stalk and leaves, had a larger slope when regressed against fWBI. In corn,
    the majority of the plant water is held in the stalk, a fact that has implications
    for the remote sensing of water content. Measured reflectance is primarily from
    the leaves with very little contribution from the vertically oriented stalk which
    presents little area in the nadir view. A linear relationship was found between
    LWC and VWC (LWC=0.20VWC+0.04; r2=.96; n=14). Each of these relationships was
    derived from data across N application rates and throughout phenological stage.
    It would require multiple years of data to test their robustness. Further, these
    relationships were based on averaged data that were close in time (within a couple
    of days), but certainly were not coincident. Download : Download full-size image
    Fig. 6. Relationship between VWC per unit ground area and LWC per unit ground
    area and the floating WBI. Both fixed and floating versions of WBI demonstrated
    a general increase in value towards peak growth and then a decline through senescence
    (e.g., fWBI in Fig. 7a). For the majority of the season, a gradient in fWBI existed
    with 155N having the largest values, and 17N having the smallest values. Again,
    the 155N canopy seemed to have been affected the most during the water stress
    period as indicated by the smaller fWBI value on Day 204. This change in fWBI
    is likely indicating a change in LWC per unit ground area caused by the transient
    water stress. Download : Download full-size image Fig. 7. (a) Time series of floating
    WBI by nitrogen application rate and (b) the position of the maximum water trough
    in the region 930–980 nm for 155N. Error bars represent 95% CI. The position of
    the water band minima (Fig. 7b) for the 155N was approximately 950 nm early in
    the season and then shifted to approximately 970 nm during active growth. The
    water band minima shifted towards the blue during the period of water stress as
    the trough shallows and migrates. The minima again blue-shifted at the end of
    the season in response to the drying during senescence. Although the cause of
    stress cannot be uniquely identified using the red edge, by combining information
    with other indices such as fWBI, a picture of the canopy status developed. On
    Day 204, a blue-shift in the 155N application rate could be seen (Fig. 8). N application
    rates could be spectrally separated using the red edge position in early August
    (Day 213) and in the absence of the mid-season water stress, the time series would
    indicate that the red edge position could be useful in separating areas of the
    field receiving different N application rates earlier in the season. If N stress
    is identified early enough, there is the potential for a variable rate application
    strategy to be employed in a split fertilizer management scheme. The red edge
    position could be useful in determining canopy chlorophyll levels (Fig. 8b) using
    LAI to scale the SPAD–chlorophyll relationship mentioned previously. The red edge–SPAD
    regression had a slightly lower standard error of the estimated SPAD readings
    than did the R550–SPAD regression depicted in Fig. 2 (2.4 and 2.7 SPAD units,
    respectively). This results in a difference in standard error between the two
    relationships of 5 mg·m−2 of canopy chlorophyll content at a LAI of 1.0. Download
    : Download full-size image Fig. 8. (a) Time series of the red edge position for
    a range of nitrogen application rates. Error bars represent 95% CI and (b) the
    relationship between red edge position and SPAD readings for all nitrogen application
    rates. 4.2. Discrimination between N application rates Spectral measurements (n=99)
    were taken on the precropped field following a 100×100 m grid after tillage and
    disking. The soil line was generated from reflectance values at 660 and 865 nm
    (Fig. 9). The resulting slope (1.062) and intercept (0.022) are similar to values
    reported by Rondeaux et al. (1996) for a range of clay and sandy textured soils
    and were used to compute TSAVI. The variation in TSAVI decreased as the fraction
    of canopy cover increased, however, the index saturated out after LAI=1.5 (canopy
    closure of 0.65)—a problem common to all such vegetation indices Carlson & Ripley,
    1997, Rondeaux et al., 1996. Discrimination between N application rates is difficult
    due to this early saturation after Day 184. For a corn canopy, our results showed
    that greenness indices could still be used for comparing leaf expansion during
    the rapid growth phase providing that two airborne images are collected at early
    and late vegetative stages. Download : Download full-size image Fig. 9. The red–NIR
    soil line for soil-adjusted structural indices. Canonical discriminant analysis
    was used to determine which combinations of hyperspectral reflectance indices
    could correctly classify samples by application rate. For July 3 (Day 184), PRI,
    fWBI, the reflectance of the chlorophyll well region (R680), and the ratio between
    red and blue wavelengths (C420) remained in the model (Table 2) and were able
    to correctly classify 70% of the samples by application rate (Table 3). LWC per
    unit ground area was important (fWBI), as was relative chlorophyll content. R680
    and C420 indicated a sensitivity to pigments. PRI added discriminatory power at
    this early canopy stage. The 17N and 99N application rates were better discriminated
    than was the 155N (65%, 84%, and 34% correctly categorized, respectively). The
    17N and 155N application rates were clearly separated suggesting that the maximum
    imposed N stress had a detectable effect early in the growing season. This is
    of interest in precision agriculture. On this date, the corn was at the sixth
    leaf stage (V6; Ritchie, Hanway, & Benson, 1993) and N could still be applied
    in accordance with plant''s needs. Under such a precision agriculture–variable
    rate application strategy, remotely sensed information would be combined with
    other characteristics of the field (topography, drainage patterns, etc.) in the
    management decision to determine the potential economic benefit to any N application.
    Table 2. Hyperspectral indices retained by canonical discriminant analysis for
    July 3, July 23, and August 27 Definitions are given in Table 1. July 3 July 23
    August 27 PRI PRI WBI fWBI fWBI TSAVI R680 R680 C420 C420 TSAVI RE ddG ddRE GGND
    EGND sumEdge Table 3. Results of canonical discriminant analysis for July 3, July
    23, and August 27 Overall success rate is calculated by pooling the data from
    each of the application rates. Application rate No. of cases Predicted membership
    (%) 17N 99N 155N July 3—early vegetative phase 17N 72 65 35 0 99N 115 11 84 5
    155N 32 0 66 34 Overall success rate: 70%  July 23—water stress 17N 29 100 0 0
    99N 53 2 91 8 155N 30 13 13 73 Overall success rate: 88%  August 27—senescence
    17N 16 94 6 0 99N 22 0 96 4 155N 16 0 12 88 Overall success rate: 93% The July
    23 (Day 204) sample date occurred during a period of water stress to the canopy.
    fWBI, R680, and PRI were retained by the stepwise procedure, as were TSAVI, and
    three indices based on spectral derivatives (ddG, GGND, and sumEdge; Table 2).
    Although, on an individual basis, TSAVI has saturated by this date, it may be
    detecting changes in LAI caused by the water stress and therefore provides added
    value to the composite classification. The sumEdge index has been well correlated
    with LAI through the effect of total biomass on the position of the red edge (Filella
    & Peñuelas, 1994). The second derivative in the green (ddG) has been shown to
    be positively correlated with leaf water potential (Peñuelas et al., 1994). ddG
    quite clearly indicated a reduction in value from the 155N and 99N application
    rates for Day 204 and then an increase for the remainder of the season (data not
    shown). This is likely the same water content signature (stressed/nonstressed)
    detected by the other indices. GGND has been shown to be negatively correlated
    with leaf epoxidation state (Peñuelas et al., 1994). The positive correlation
    between chlorophyll level and LWC per unit ground area is likely represented in
    GGND where the proportion of carotenoids to chlorophyll has increased in relation
    to falling LWC per unit ground area and reduced chlorophyll. The combination of
    indices stated above resulted in an overall 88% predictive success rate (Table
    3). The imposed nitrogen stress is well discriminated as there is perfect placement
    of the 17N samples into that category. Although each of the application rates
    is better discriminated on July 23 than on July 3, it is interesting to note that
    the water stress has caused some of the 155N signatures to be mistaken for 17N
    signatures. By August 27 (Day 239), senescence had begun in regions of the field.
    Water was not limiting, however, the canopy was drying due to the change in phenology.
    fWBI and TSAVI were again retained (Table 2). C420 was added and R680 was removed
    suggesting the reduced importance of the chlorophyll well region during senescence.
    The red edge position was added as were ddRE and EGND. The shift in importance
    from green-based derivatives to red-based derivatives may be a function of the
    increased senescence in the crop and a reduction in green pigments. The time series
    of the red edge position (Fig. 8) indicated that in the absence of water stress,
    this index might be a key discriminating variable. ddRE has been shown to be negatively
    correlated with leaf chlorophyll and positively correlated with leaf water potential
    (Peñuelas et al., 1994). EGND has been shown to be positively correlated with
    chlorophyll and nitrogen content at leaf levels (Peñuelas et al., 1994). The overall
    success rate for this period is 93% (Table 3). Note that no samples from the 99N
    or 155N application rates were mistaken for 17N and that no 17N samples were mistaken
    as 155N. Not surprisingly, the greatest misclassification occurs between the 155N
    and 99N application rates where maximum variability occurred. In each case, fixed
    and floating versions of the WBI were used in separate runs of the discriminant
    analysis. The floating WBI consistently provided superior results (in terms of
    classification success rate) to the fixed-position WBI. This is likely due to
    fWBI''s ability to better capture the depth of the water trough. The position
    of the maximum trough shifts with canopy development and with stress (e.g., Fig.
    7b). This feature may make better identification of water-stressed areas of the
    field possible. A floating WBI may also offer better sensitivity to the actual
    canopy water content. This should be explored further. 4.3. Timing of image acquisition
    Moran, Inoue, and Barnes (1997) gave an excellent synthesis of the opportunities
    and limitations for remote sensing in precision agriculture. They indicated that
    a major limitation was the inadequate repeat coverage available from commercial
    systems. Key periods need to be identified and monitored. An image in the early
    vegetative phase, when used in conjunction with soil fertility data, can provide
    information about nutrient-deficient areas of the field in time for remedial action
    to be taken. Under split application fertilizer management, a second application
    of fertilizer is typically applied around the sixth leaf stage (V6) for corn.
    This application is usually a single rate across the field based on presowing
    nutrient status and does not consider the current plant status. Under precision
    agriculture management, this application could be customized to meet the crop''s
    current needs based on the timely analysis of remotely sensed data. This would
    require a rapid turnaround, in the order of days, between acquisition and recommendation.
    More research is needed on the potential economic benefits of this approach. A
    second image taken either towards the end of the vegetative phase or in the reproductive
    phase can be used for yield forecasting and crop insurance applications. By combining
    the two images, information on the relative rates of leaf expansion across the
    field can be determined. The second image would not require as rapid a turnaround
    as crop growth has slowed and translocation of nutrients has begun. These images
    could be of further use to producers in determining any modifications to their
    field management practices for coming seasons. Early in the season, measures of
    either canopy greenness or red edge position would appear to be a simple means
    for estimating chlorophyll content. LAI can be derived from a biomass-sensitive
    vegetation index (such as NDVI) enabling scaling of the chlorophyll estimates
    to the canopy level. The nutrient status of areas of the field is in this way
    related to a measure of leaf elongation. This technique requires validation at
    the field scale with independent samples. Imagery later in the season can be used
    to identify portions of the field affected by environmental stress. In combination
    with field-specific information on soils and topography, the management practices
    within such areas can be adjusted in future years to maximize the efficiency of
    crop production. In our example, the producer would have had little choice but
    to accept the outcome of the combined stresses. If, however, remotely sensed data
    over several years could be used to identify water-sensitive areas of the field,
    a revised management strategy could be employed. A crop growth model could be
    used to track the growth dynamic under different weather scenarios and determine
    which part of the growth is related to weather limitations. In water-sensitive
    areas, less fertilizer would be applied. In good water years, productivity would
    be lower, but this is compensated for lower fertilizer costs in poor years and
    an overall benefit to both the producer and the environment in the longer term.
    5. Summary We have used indices derived from ground-based, canopy-scale hyperspectral
    reflectance data to demonstrate the temporal patterns in corn growth when exposed
    to imposed nitrogen (reduced application rate) and environmental (water availability)
    stresses. In the absence of other limiting factors, growth is a function of the
    availability of N and water. In field corn, there can be a complex interaction
    between these two stresses—each with its own temporal dynamic as highlighted in
    this study. The N stress was imposed by design, and, in the absence of environmental
    stresses, would slowly evolve into separable outcomes by N application rate in
    terms of leaf expansion, LAI, and yield over the course of the season. The evidence
    presented here suggests that a mid-season water stress of short duration overrode
    the effects of the slowly evolving N stress and caused the 155N to mimic the 99N,
    at least temporarily. Following the water stress period, the higher N allowed
    the 155N corn to at least perform at the same level as the 99N corn. In terms
    of remote sensing this complex dynamic, no single index was able to describe the
    status of the corn crop throughout the season. Rather, several hyperspectral reflectance
    signatures and indices were required to assess the evolution of the crop ecophysiology.
    Accurate identification of application rate membership was obtained using canonical
    discriminant analysis at three points in the season (early growth, stressed vegetative,
    senescence). This technique offers a means for reducing the voluminous information
    provided by hyperspectral data sets. A measured reduction in canopy-scale fWBI
    was associated with a period of reduced rainfall and a temporary stress condition
    in the canopy. fWBI was shown to be correlated with area-weighted water content
    for both leaf and vegetative components and provides the opportunity for remote
    detection of the LWC per unit ground area. We have shown that PRI was correlated
    with canopy-scale RUE for field corn but that the relationship could be influenced
    by transient environmental stress conditions. When taken at an appropriate scale
    and timing, hyperspectral reflectance can provide valuable information to the
    agricultural producer to identify stressed regions in order to implement remediation
    strategies or in forecasting yield months prior to harvest. Acknowledgements The
    authors wish to thank Dave Dow, Ozan Gonenç, Catherine Champagne, and Philippe
    Xu for field and data assistance. Dr. Heather McNairn of the Canada Centre for
    Remote Sensing, Dr. Ray Desjardins of AAFC, and one anonymous reviewer provided
    helpful comments on earlier versions of this manuscript. This work was conducted
    in part through a Matching Investment Initiative agreement between AAFC and Agrimage,
    Sherbrooke, QC. The authors acknowledge the support of Dr. Gilles Daoust throughout
    this aspect of the project. ECORC contribution #00-1600. References Baret & Guyot,
    1991 F. Baret, G. Guyot Potentials and limits of vegetation indices for LAI and
    PAR assessment Remote Sensing of Environment, 35 (1991), pp. 161-173 View PDFView
    articleView in ScopusGoogle Scholar Baret et al., 1993 F. Baret, S. Jacquemoud,
    J.F. Hanocq The soil line concept in remote sensing Remote Sensing Reviews, 7
    (1993), pp. 65-82 CrossRefView in ScopusGoogle Scholar Carlson & Ripley, 1997
    T.N. Carlson, D.A. Ripley On the relation between NDVI, fractional vegetation
    cover, and leaf area index Remote Sensing of Environment, 62 (1997), pp. 241-252
    View PDFView articleView in ScopusGoogle Scholar Carter, 1994 G.A. Carter Ratios
    of leaf reflectance in narrow wavebands as indicators of plant stress International
    Journal of Remote Sensing, 15 (1994), pp. 697-703 CrossRefView in ScopusGoogle
    Scholar Curran et al., 1995 P.J. Curran, W.R. Windham, H.L. Gholz Exploring the
    relationship between reflectance red edge and chlorophyll concentration in slash
    pine leaves Tree Physiology, 15 (1995), pp. 203-206 CrossRefView in ScopusGoogle
    Scholar Demetriades-Shah et al., 1990 T.H. Demetriades-Shah, M.D. Steven, J.A.
    Clark High resolution derivative spectra in remote sensing Remote Sensing of Environment,
    33 (1990), pp. 55-64 View PDFView articleView in ScopusGoogle Scholar Demmig-Adams
    & Adams, 1996 B. Demmig-Adams, W.W. Adams The role of xanthophyll cycle carotenoids
    in the protection of photosynthesis Trends in Plant Science, 1 (1996), pp. 21-26
    View PDFView articleView in ScopusGoogle Scholar Dwyer et al., 1991 L.M. Dwyer,
    M. Tollenaar, L. Houwing A nondestructive method to monitor leaf greenness in
    corn Canadian Journal of Plant Science, 71 (1991), pp. 505-509 CrossRefGoogle
    Scholar Filella & Peñuelas, 1994 I. Filella, J. Peñuelas The red edge position
    and shape as indicators of plant chlorophyll content, biomass and hydric status
    International Journal of Remote Sensing, 15 (1994), pp. 1459-1470 CrossRefView
    in ScopusGoogle Scholar Filella et al., 1995 I. Filella, L. Serrano, J. Serra,
    J. Peñuelas Evaluating wheat nitrogen status with canopy reflectance indices and
    discriminant analysis Crop Science, 35 (1995), pp. 1400-1405 View in ScopusGoogle
    Scholar Gamon et al., 1990 J.A. Gamon, C.B. Field, W. Bilger, O. Björkman, A.L.
    Fredeen, J. Peñuelas Responses of photosynthesis and carbohydrate-partitioning
    to limitations in nitrogen and water availability in field-grown sunflower Plant
    Cell Environment, 14 (1990), pp. 963-970 Google Scholar Gamon et al., 1992 J.A.
    Gamon, J. Peñuelas, C.B. Field A narrow-waveband spectral index that tracks diurnal
    changes in photosynthetic efficiency Remote Sensing of Environment, 41 (1992),
    pp. 35-44 View PDFView articleView in ScopusGoogle Scholar Gamon et al., 1997
    J.A. Gamon, L. Serrano, J.S. Surfus The photochemical reflectance index: an optical
    indicator of photosynthetic radiation use efficiency across species, functional
    types, and nutrient levels Oecologia, 112 (1997), pp. 492-501 View in ScopusGoogle
    Scholar Hatfield & Pinter, 1993 J.L. Hatfield, P.J. Pinter Jr. Remote sensing
    for crop protection Crop Protection, 12 (1993), pp. 403-414 View in ScopusGoogle
    Scholar Hoque & Hutzler, 1992 E. Hoque, P.J.S. Hutzler Spectral blue-shift of
    red edge monitors damage class of beech trees Remote Sensing of Environment, 39
    (1992), pp. 81-84 View PDFView articleView in ScopusGoogle Scholar Horler et al.,
    1983 D.N.H. Horler, M. Dockray, J. Barber The red edge of plant leaf reflectance
    International Journal of Remote Sensing, 4 (1983), pp. 273-288 CrossRefView in
    ScopusGoogle Scholar Huete, 1988 A.R. Huete A Soil-Adjusted Vegetation Index (SAVI)
    Remote Sensing of Environment, 25 (1988), pp. 295-309 View PDFView articleView
    in ScopusGoogle Scholar Jackson, 1984 R.D. Jackson Remote sensing of vegetation
    characteristics for farm management SPIE, 475 (1984), pp. 81-96 CrossRefGoogle
    Scholar Lord et al., 1988 D. Lord, R.L. Desjardins, P.A. Dubé Sun-angle effects
    on the red and near infrared reflectances of five different crop canopies Canadian
    Journal of Remote Sensing, 14 (1988), pp. 46-55 CrossRefView in ScopusGoogle Scholar
    Lord et al., 1985 D. Lord, R.L. Desjardins, P.A. Dubé, E.J. Brach Variations of
    crop canopy spectral reflectance measurements under changing sky conditions Photogrammetric
    Engineering and Remote Sensing, 51 (1985), pp. 689-695 View in ScopusGoogle Scholar
    Moran et al., 1997 M.S. Moran, Y. Inoue, E.M. Barnes Opportunities and limitations
    for image-based remote sensing in precision crop management Remote Sensing of
    Environment, 61 (1997), pp. 319-346 View PDFView articleView in ScopusGoogle Scholar
    Nichol et al., 2000 C.J. Nichol, K.F. Huemmrich, T.A. Black, P.A. Jarvis, C.L.
    Walthall, J. Grace, F.G. Hall Remote sensing of photosynthetic-light-use efficiency
    of boreal forest Agricultural and Forest Meteorology, 101 (2000), pp. 131-142
    View PDFView articleView in ScopusGoogle Scholar Pattey et al., 2001 E. Pattey,
    I.B. Strachan, J.B. Boisvert, R.L. Desjardins, N.B. McLaughlin Effects of nitrogen
    application rate and weather on corn using micrometeorological and hyperspectral
    reflectance measurements Agricultural and Forest Meteorology, 108 (2001), pp.
    85-99 View PDFView articleView in ScopusGoogle Scholar Peñuelas et al., 1995 J.
    Peñuelas, F. Baret, I. Filella Semi-empirical indices to assess carotenoids/chlorophyll
    a ratio from leaf spectral reflectance Photosynthetica, 31 (1995), pp. 221-230
    View in ScopusGoogle Scholar Peñuelas & Filella, 1998 J. Peñuelas, I. Filella
    Visible and near-infrared reflectance techniques for diagnosing plant physiological
    status Trends in Plant Science, 3 (1998), pp. 151-156 View PDFView articleView
    in ScopusGoogle Scholar Peñuelas et al., 1993 J. Peñuelas, I. Filella, C. Biel,
    L. Serrano, R. Savé The reflectance at the 950–970 nm region as an indicator of
    plant water status International Journal of Remote Sensing, 14 (1993), pp. 1887-1905
    CrossRefView in ScopusGoogle Scholar Peñuelas et al., 1995 J. Peñuelas, I. Filella,
    J.A. Gamon Assessment of photosynthetic radiation-use efficiency with spectral
    reflectance New Phytologist, 131 (1995), pp. 291-296 CrossRefView in ScopusGoogle
    Scholar Peñuelas et al., 1994 J. Peñuelas, J.A. Gamon, A.L. Fredeen, J. Merino,
    C.B. Field Reflectance indices associated with physiological changes in nitrogen-
    and water-limited sunflower leaves Remote Sensing of Environment, 48 (1994), pp.
    135-146 View PDFView articleView in ScopusGoogle Scholar Peñuelas & Inoue, 2000
    J. Peñuelas, Y. Inoue Reflectance assessment of canopy CO2 uptake International
    Journal of Remote Sensing, 21 (2000), pp. 3353-3356 View in ScopusGoogle Scholar
    Peñuelas et al., 1997 J. Peñuelas, J. Piñol, R. Ogaya, I. Filella Estimation of
    plant water concentration by the reflectance Water Index WI (R900/R970) International
    Journal of Remote Sensing, 18 (1997), pp. 2869-2875 View in ScopusGoogle Scholar
    Ritchie et al., 1993 Ritchie, S. W., Hanway, J. J., & Benson, G. O. (1993). How
    a corn plant develops. In J. Clayton Herman (Ed.). Ames, IA: Iowa State University
    of Science and Technology, Cooperative Extension Service. Special report no. 48,
    reprints 1993, 21 pp. Google Scholar Rondeaux et al., 1996 G. Rondeaux, M. Steven,
    F. Baret Optimization of soil-adjusted vegetation indices Remote Sensing of Environment,
    55 (1996), pp. 95-107 View PDFView articleView in ScopusGoogle Scholar Shibayama
    et al., 1993 M. Shibayama, W. Takahashi, S. Morinaga, T. Akiyama Canopy water
    deficit detection in paddy rice using a high resolution field spectroradiometer
    Remote Sensing of Environment, 45 (1993), pp. 117-126 View PDFView articleView
    in ScopusGoogle Scholar Young & Britton, 1990 A. Young, G. Britton Carotenoids
    and stress R.G. Alscher Jr., J.R. Cumming (Eds.), Stress responses in plants:
    adaptation and acclimation mechanisms, Wiley-Liss, New York (1990), pp. 87-112
    Google Scholar Cited by (267) Performance and mechanism of SMX removal by an electrolysis-integrated
    ecological floating bed at low temperatures: A new perspective of plant activity,
    iron plaque, and microbial functions 2024, Journal of Hazardous Materials Show
    abstract Spectral response to early detection of stressed oil palm seedlings using
    near-infrared reflectance spectra at region 900-1000 nm 2023, Infrared Physics
    and Technology Show abstract Combining machine learning algorithm and multi-temporal
    temperature indices to estimate the water status of rice 2023, Agricultural Water
    Management Show abstract Monitor water quality through retrieving water quality
    parameters from hyperspectral images using graph convolution network with superposition
    of multi-point effect: A case study in Maozhou River 2023, Journal of Environmental
    Management Show abstract Retrieving canopy nitrogen concentration and aboveground
    biomass with deep learning for ryegrass and barley: comparing models and determining
    waveband contribution 2023, Field Crops Research Show abstract Leaf nitrogen content
    estimation using top-of-canopy airborne hyperspectral data 2021, International
    Journal of Applied Earth Observation and Geoinformation Citation Excerpt : In
    very few studies, leaf water and nitrogen contents were studied together using
    hyperspectral data. Strachan et al. (2002) used canopy-level 350–1000 nm hyperspectral
    data to demonstrate the maize development under nitrogen and water stress conditions.
    Canonical discriminate analysis was used to classify different nitrogen rate canopies.
    Show abstract View all citing articles on Scopus View Abstract Copyright © 2002
    Elsevier Science Inc. All rights reserved. Recommended articles Estimating leaf
    nitrogen concentration considering unsynchronized maize growth stages with canopy
    hyperspectral technique Ecological Indicators, Volume 107, 2019, Article 105590
    Peng-Fei Wen, …, Jun Li View PDF Estimation of water content in corn leaves using
    hyperspectral data based on fractional order Savitzky-Golay derivation coupled
    with wavelength selection Computers and Electronics in Agriculture, Volume 182,
    2021, Article 105989 Jingjing Sun, …, Guangwei Ding View PDF Rapid estimation
    of leaf nitrogen content in apple-trees based on canopy hyperspectral reflectance
    using multivariate methods Infrared Physics & Technology, Volume 111, 2020, Article
    103542 Shaomin Chen, …, Hongxiang Li View PDF Show 3 more articles Article Metrics
    Citations Citation Indexes: 261 Captures Readers: 196 Social Media Shares, Likes
    & Comments: 7 View details About ScienceDirect Remote access Shopping cart Advertise
    Contact and support Terms and conditions Privacy policy Cookies are used by this
    site. Cookie settings | Your Privacy Choices All content on this site: Copyright
    © 2024 Elsevier B.V., its licensors, and contributors. All rights are reserved,
    including those for text and data mining, AI training, and similar technologies.
    For all open access content, the Creative Commons licensing terms apply.'
  inline_citation: '>'
  journal: Remote Sensing of Environment
  limitations: '>'
  pdf_link: null
  publication_year: 2002
  relevance_score1: 0
  relevance_score2: 0
  title: Impact of nitrogen and environmental conditions on corn as detected by hyperspectral
    reflectance
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1071/fp12060
  analysis: '>'
  authors:
  - Christoph Römer
  - Mirwaes Wahabzada
  - Agim Ballvora
  - Francisco Pinto
  - Micol Rossini
  - Cinzia Panigada
  - Jan Behmann
  - Jens Léon
  - Christian Thurau
  - Christian Bauckhage
  - Kristian Kersting
  - Uwe Rascher
  - Lutz Plümer
  citation_count: 123
  full_citation: '>'
  full_text: '>

    Register      Login CSIRO PUBLISHING HOME BOOKS JOURNALS LEARNING BLOG Plant function
    and evolutionary biology Shopping Cart: ( empty ) Search our journals You are
    here: Home > Journals > FP > FP12060 RESEARCH ARTICLE Previous Next Contents Vol
    39(11) Early drought stress detection in cereals: simplex volume maximisation
    for hyperspectral image analysis Christoph Römer A F , Mirwaes Wahabzada B , Agim
    Ballvora C , Francisco Pinto D , Micol Rossini E , Cinzia Panigada E , Jan Behmann
    A , Jens Léon C , Christian Thurau B , Christian Bauckhage B , Kristian Kersting
    B , Uwe Rascher D and Lutz Plümer A + Author Affiliations  Functional Plant Biology
    39(11) 878-890 https://doi.org/10.1071/FP12060 Submitted: 24 February 2012  Accepted:
    8 July 2012   Published: 28 August 2012 Abstract Early water stress recognition
    is of great relevance in precision plant breeding and production. Hyperspectral
    imaging sensors can be a valuable tool for early stress detection with high spatio-temporal
    resolution. They gather large, high dimensional data cubes posing a significant
    challenge to data analysis. Classical supervised learning algorithms often fail
    in applied plant sciences due to their need of labelled datasets, which are difficult
    to obtain. Therefore, new approaches for unsupervised learning of relevant patterns
    are needed. We apply for the first time a recent matrix factorisation technique,
    simplex volume maximisation (SiVM), to hyperspectral data. It is an unsupervised
    classification approach, optimised for fast computation of massive datasets. It
    allows calculation of how similar each spectrum is to observed typical spectra.
    This provides the means to express how likely it is that one plant is suffering
    from stress. The method was tested for drought stress, applied to potted barley
    plants in a controlled rain-out shelter experiment and to agricultural corn plots
    subjected to a two factorial field setup altering water and nutrient availability.
    Both experiments were conducted on the canopy level. SiVM was significantly better
    than using a combination of established vegetation indices. In the corn plots,
    SiVM clearly separated the different treatments, even though the effects on leaf
    and canopy traits were subtle. Additional keywords: canopy, imaging spectroscopy,
    matrix factorisation, non-invasive, pattern recognition, plant phenotyping, unsupervised
    learning, water stress.  References Aitichison J (1982) ‘The statistical analysis
    of compositional data.’ (Chapman & Hall: London)  Aldakheel YY, Danson FM (1997)
    Spectral reflectance of dehydrating leaves: measurements and modelling. International
    Journal of Remote Sensing 18, 3683–3690. |  Spectral reflectance of dehydrating
    leaves: measurements and modelling. Crossref | GoogleScholar Google Scholar |  Bateson
    CA, Asner GP, Wessmann CA (2000) Endmember bundles: a new approach to incorporating
    endmember variability into spectral mixture analysis. IEEE Transactions on Geoscience
    and Remote Sensing 38, 1083–1094. |  Endmember bundles: a new approach to incorporating
    endmember variability into spectral mixture analysis. Crossref | GoogleScholar
    Google Scholar |  Bilger W, Björkman O (1990) Role of the xanthophylls cycle in
    photoprotection elucidated by measurements of light-induced absorbance changes,
    fluorescence and photosynthesis in leaves of Hedera canariensis. Photosynthesis
    Research 25, 173–185. |  Role of the xanthophylls cycle in photoprotection elucidated
    by measurements of light-induced absorbance changes, fluorescence and photosynthesis
    in leaves of . Crossref | GoogleScholar Google Scholar | 1:CAS:528:DyaK3cXmtVymsbs%3D&md5=438bfb82476a83f01957e3366c76e84d
    CAS |  Bilger W, Schreiber U, Bock M (1995) Determination of the quantum efficiency
    of photosystem II and of non-photochemical quenching of the chlorophyll fluorescence
    in the field. Oecologia 102, 425–432. |  Determination of the quantum efficiency
    of photosystem II and of non-photochemical quenching of the chlorophyll fluorescence
    in the field. Crossref | GoogleScholar Google Scholar |  Bishop CM (2006) ‘Pattern
    recognition and machine learning.’ (Springer: New York)  Chaves MM, Flexas J,
    Pinheiro C (2009) Photosynthesis under drought and salt stress: regulation mechanisms
    from whole plant to cell. Annals of Botany 103, 551–560. |  Photosynthesis under
    drought and salt stress: regulation mechanisms from whole plant to cell. Crossref
    | GoogleScholar Google Scholar | 1:CAS:528:DC%2BD1MXktVGnu7s%3D&md5=5500739fc94ee3295b2dea488c3004b7
    CAS |  Çivril A, Magdon-Ismail M (2009) On selecting a maximum volume sub-matrix
    of a matrix and related problems. Theoretical Computer Science 410, 4801–4811.
    |  On selecting a maximum volume sub-matrix of a matrix and related problems.
    Crossref | GoogleScholar Google Scholar |  Cohen WB (1991) Temporal versus spatial
    variation in leaf reflectance under changing water stress conditions. International
    Journal of Remote Sensing 12, 1865–1876. |  Temporal versus spatial variation
    in leaf reflectance under changing water stress conditions. Crossref | GoogleScholar
    Google Scholar |  Colombo R, Meroni M, Marchesi A, Busetto L, Rossini M, Giardino
    C, Panigada C (2008) Remote sensing of leaf and canopy water content in poplar
    plantations by means of hyperspectral data. Remote Sensing of Environment 112,
    1820–1834. |  Remote sensing of leaf and canopy water content in poplar plantations
    by means of hyperspectral data. Crossref | GoogleScholar Google Scholar |  Cox
    T, Cox M (1984) ‘Multidimensional scaling.’ (Chapman & Hall: London)  Cutler A,
    Breiman L (1994) Archetypal analysis. Technometrics 36, 338–347.  Damm A, Elbers
    J, Erler E, Giolo B, Hamdi K, Hutjes R, Kosyancoya M, Meroni M, Miglietta F, Moreno
    J, Schickling A, Sonnenschein R, Udelhoven T, van der Linden S, Hostert P, Rascher
    U (2010) Remote sensing of sun induced fluorescence to improve modeling of diurnal
    courses of gross primary production (GPP). Global Change Biology 16, 171–186.
    |  Remote sensing of sun induced fluorescence to improve modeling of diurnal courses
    of gross primary production (GPP). Crossref | GoogleScholar Google Scholar |  Danson
    FM, Steven MD, Malthus TJ, Clark JA (1992) High-spectral resolution data for determining
    leaf water content. International Journal of Remote Sensing 13, 461–470. |  High-spectral
    resolution data for determining leaf water content. Crossref | GoogleScholar Google
    Scholar |  Fiorani F, Rascher U, Jahnke S, Schurr U (2012) Imaging plants dynamics
    in heterogenic environments. Current Opinion in Biotechnology |  Imaging plants
    dynamics in heterogenic environments. Crossref | GoogleScholar Google Scholar
    |  Gamon JA, Penuelas J, Field CB (1992) A narrow waveband spectral index that
    tracks diurnal changes in photosynthetic efficiency. Remote Sensing of Environment
    41, 35–44. |  A narrow waveband spectral index that tracks diurnal changes in
    photosynthetic efficiency. Crossref | GoogleScholar Google Scholar |  Gitelson
    AA, Keydan GP, Merzylak MN (2006) Three-band model for non-invasive estimation
    of chlorophyll, carotenoids, and anthocyanin contents in higher plant leaves.
    Geophysical Research Letters 33, L11402 |  Three-band model for non-invasive estimation
    of chlorophyll, carotenoids, and anthocyanin contents in higher plant leaves.
    Crossref | GoogleScholar Google Scholar |  Haboudane D, Tremblay N, Miller JR,
    Vigneault P (2008) Remote estimation of crop chlorophyll content using spectral
    indices derived from hyperspectral data. IEEE Transactions on Geoscience and Remote
    Sensing 46, 423–437. |  Remote estimation of crop chlorophyll content using spectral
    indices derived from hyperspectral data. Crossref | GoogleScholar Google Scholar
    |  Hunt ER, Rock BN (1989) Detection of changes in leaf water content using near-
    and middle-infrared reflectances. Remote Sensing of Environment 30, 43–54. |  Detection
    of changes in leaf water content using near- and middle-infrared reflectances.
    Crossref | GoogleScholar Google Scholar |  Jackson RD, Huete AR (1991) Interpreting
    vegetation indices. Preventive Veterinary Medicine 11, 185–200. |  Interpreting
    vegetation indices. Crossref | GoogleScholar Google Scholar |  Kimes DS, Newcomb
    WW, Shutt JB, Pinter PJ, Jackson RD (1984) Directional reflectance factor distributions
    of a cotton row crop. International Journal of Remote Sensing 5, 263–277. |  Directional
    reflectance factor distributions of a cotton row crop. Crossref | GoogleScholar
    Google Scholar |  Knipling EB (1970) Physical and physiological basis for the
    reflectance of visible and near-infrared radiation from vegetation. Remote Sensing
    of Environment 1, 155–159. |  Physical and physiological basis for the reflectance
    of visible and near-infrared radiation from vegetation. Crossref | GoogleScholar
    Google Scholar |  Mahlein AK, Oerke E-C, Steiner U, Dehne H-W (2012) Recent advances
    in sensing plant diseases for precision crop protection. European Journal of Plant
    Pathology 133, 197–209. |  Recent advances in sensing plant diseases for precision
    crop protection. Crossref | GoogleScholar Google Scholar | 1:CAS:528:DC%2BC38XkvVCrsbk%3D&md5=9909017b82d6e53fedbadaa08461f964
    CAS |  Malenovský Z, Mishra KB, Zemek F, Rascher U, Nedbal L (2009) Scientific
    and technical challenges in remote sensing of plant canopy reflectance and fluorescence.
    Journal of Experimental Botany 60, 2987–3004. |  Scientific and technical challenges
    in remote sensing of plant canopy reflectance and fluorescence. Crossref | GoogleScholar
    Google Scholar |  Meroni M, Rossini M, Picchi V, Panigada C, Cogliati S, Nali
    C, Colombo R (2008) Assessing steady-state fluorescence and PRI from hyperspectral
    proximal sensing as early indicators of plant stress: the case of ozone exposure.
    Sensors 8, 1740–1754. |  Assessing steady-state fluorescence and PRI from hyperspectral
    proximal sensing as early indicators of plant stress: the case of ozone exposure.
    Crossref | GoogleScholar Google Scholar | 1:CAS:528:DC%2BD1cXkvVCrtb4%3D&md5=f9f3f90e3fe2b05803c2d8ca8b6116b7
    CAS |  Meroni M, Panigada C, Rossini M, Picchi V, Cogliati S, Colombo R (2009a)
    Using optical remote sensing techniques to track the development of ozone-induced
    stress. Environmental Pollution 157, 1413–1420. |  Using optical remote sensing
    techniques to track the development of ozone-induced stress. Crossref | GoogleScholar
    Google Scholar | 1:CAS:528:DC%2BD1MXktF2lurg%3D&md5=129fec8ee57cc255050eab753604331f
    CAS |  Meroni M, Rossini M, Guanter L, Alonso L, Rascher U, Colombo R, Moreno
    J (2009b) Remote sensing of solar induced chlorophyll fluorescence: review of
    methods and applications. Remote Sensing of Environment 113, 2037–2051. |  Remote
    sensing of solar induced chlorophyll fluorescence: review of methods and applications.
    Crossref | GoogleScholar Google Scholar |  Niinemets U (2007) Photosynthesis and
    resource distribution through plant canopies. Plant, Cell & Environment 30, 1052–1071.
    |  Photosynthesis and resource distribution through plant canopies. Crossref |
    GoogleScholar Google Scholar | 1:CAS:528:DC%2BD2sXhtVeiurrN&md5=f2cbcb4d65b56899813d9e58680bf147
    CAS |  Peñuelas J, Filella L (1998) Technical focus: visible and near-infrared
    reflectance techniques for diagnostic plant physiological status. Trends in Plant
    Science 3, 151–156. |  Technical focus: visible and near-infrared reflectance
    techniques for diagnostic plant physiological status. Crossref | GoogleScholar
    Google Scholar |  Penuelas J, Filella I, Gamon JA (1995) Assessment of photosynthetic
    radiation-use efficiency with spectral reflectance. New Phytologist 131, 291–296.
    |  Assessment of photosynthetic radiation-use efficiency with spectral reflectance.
    Crossref | GoogleScholar Google Scholar |  Penuelas J, Pinol J, Ogaya R, Filella
    I (1997) Photochemical reflectance index and leaf photosynthetic radiation-use-efficiency
    assessment in Mediterranean trees. International Journal of Remote Sensing 18,
    2869–2875. |  Photochemical reflectance index and leaf photosynthetic radiation-use-efficiency
    assessment in Mediterranean trees. Crossref | GoogleScholar Google Scholar |  Rascher
    U, Nichol CJ, Small C, Hendricks L (2007) Monitoring spatio-temporal dynamics
    of photosynthesis with a portable hyperspectral imaging system. Photogrammetric
    Engineering and Remote Sensing 73, 45–56.  Rascher U, Damm A, van der Linden S,
    Okujeni A, Pieruschka R, Schickling A, Hostert P (2010) Sensing of photosynthetic
    activity of crops. In ‘Precision crop protection – the challenge and use of heterogeneity’.
    (Ed. E-C Oerke) pp. 878–99. (Springer Science & Business Media: Dordrecht, The
    Netherlands)  Richards RA, Rebetzke GJ, Watt M, Condon AG, Spielmeyer W, Dolferus
    R (2010) Breeding for improved water productivity in temperate cereals: phenotyping,
    quantitative trait loci, markers and the selection environment. Functional Plant
    Biology 37, 85–97. |  Breeding for improved water productivity in temperate cereals:
    phenotyping, quantitative trait loci, markers and the selection environment. Crossref
    | GoogleScholar Google Scholar |  Römer C, Bürling K, Rumpf T, Hunsche M, Noga
    G, Plümer L (2011) Robust fitting of fluorescence spectra for presymptomatic wheat
    leaf rust detection with support vector machines. Computers and Electronics in
    Agriculture 79, 180–188. |  Robust fitting of fluorescence spectra for presymptomatic
    wheat leaf rust detection with support vector machines. Crossref | GoogleScholar
    Google Scholar |  Rouse JW, Haas RH, Schell JA, Deering DW, Harlan JC (1974) Monitoring
    the vernal advancement of retrogradation of natural vegetation, NASA/GSFC, Type
    III, Final Report, Greenbelt, MD.  Scholander P, Bradstreet E, Hemmingsen E, Hammel
    H (1965) Sap pressure in vascular plants: negative hydrostatic pressure can be
    measured in plants. Science 148, 339–346. |  Sap pressure in vascular plants:
    negative hydrostatic pressure can be measured in plants. Crossref | GoogleScholar
    Google Scholar | 1:STN:280:DC%2BC3cvlsVKquw%3D%3D&md5=7a95ab02c16d02693138b3c00d255211
    CAS |  Schreiber U, Bilger W (1993) Progress in chlorophyll fluorescence research:
    major development during the past years in retrospect. Progress in Botany 53,
    151–173.  Schulte D, Close TJ, Graner A, Langridge P, Matsumoto T, Muehlbauer
    G, Sato K, Schulman AH, Waugh R, Wise RP, Stein N (2009) The international barley
    sequencing consortium – at the threshold of efficient access to the barley genome.
    Plant Physiology 149, 142–147. |  The international barley sequencing consortium
    – at the threshold of efficient access to the barley genome. Crossref | GoogleScholar
    Google Scholar | 1:CAS:528:DC%2BD1MXjt1Wqsb0%3D&md5=98a7dbf8144a7411805e517a30b2eb82
    CAS |  Somers B, Asner GP, Tits L, Coppin P (2011) Endmember variability in spectral
    mixture analysis: a review. Remote Sensing of Environment 115, 1603–1616. |  Endmember
    variability in spectral mixture analysis: a review. Crossref | GoogleScholar Google
    Scholar |  Tenenbaum JB, De Silva V, Langford JC (2000) A global geometrix framework
    for nonlinear dimensionality reduction. Science 290, 2319–2323. |  A global geometrix
    framework for nonlinear dimensionality reduction. Crossref | GoogleScholar Google
    Scholar | 1:STN:280:DC%2BD3M%2Fnt1yitQ%3D%3D&md5=8c415061e1b41e9c18899a15b6f51c9f
    CAS |  Thenkabail PS, Smith RB, De Pauw E (2000) Hyperspectral vegetation indices
    and their relationships with agricultural crop characteristics. Remote Sensing
    of Environment 71, 158–182. |  Hyperspectral vegetation indices and their relationships
    with agricultural crop characteristics. Crossref | GoogleScholar Google Scholar
    |  Thurau C, Kersting K, Bauckhage C (2010) Yes we can – simplex volume maximization
    for descriptive web-scale matrix factorization. In ‘Proceedings of the conference
    on information and knowledge management’. pp. 1785–1788.  Tilling AK, O’Leary
    GJ, Ferwerda JG, Jones SD, Fitzgerald GJ, Rodriguez D, Belford R (2007) Remote
    sensing of nitrogen and water stress in wheat. Field Crops Research 104, 77–85.
    |  Remote sensing of nitrogen and water stress in wheat. Crossref | GoogleScholar
    Google Scholar |  Ustin S, Gamon JA (2010) Remote sensing of plant functional
    types. New Phytologist 186, 795–816. |  Remote sensing of plant functional types.
    Crossref | GoogleScholar Google Scholar |  Yilmaz MT, Hunt ER, Jackson TJ (2008)
    Remote sensing of vegetation water content from equivalent water thickness using
    satellite imagery. Remote Sensing of Environment 112, 2514–2522. |  Remote sensing
    of vegetation water content from equivalent water thickness using satellite imagery.
    Crossref | GoogleScholar Google Scholar |   Full Text PDF (1.4 MB) Export Citation
    Cited By (114) Get Permission Share View Dimensions 127 Journal Navigation JOURNAL
    HOME About the Journal Editorial Structure Publishing Policies Contacts CONTENT
    Latest Just Accepted Most Read Collections All Content Special Issues Research
    Fronts Virtual Issues Reviews Evolutionary Reviews Call for Papers FOR AUTHORS
    General Information Scope Submit Article Author Instructions Licence to Publish
    Open Access Read and Publish Publishing Charges Awards and Prizes FOR REVIEWERS
    Reviewer Guidelines Review Article Reviewer Recognition Annual Reviewer Index
    FOR SUBSCRIBERS Subscription Prices Customer Service Library Recommendation FOR
    ADVERTISERS e-Alerts Subscribe to our Email Alert or feeds for the latest journal
    papers.  LINKS Links first column About Us Contact Us Help Workshops Building
    Technology Resources BROWSE BY SUBJECT Browse by subject first column Animals
    Built Environment Food & Agriculture Gardening & Horticulture Children Browse
    by subject second column Marine & Freshwater Natural Environment Physical Sciences
    Plants & Fungi Science in Society CONNECT WITH US We acknowledge the Traditional
    Owners of the land, sea and waters, of the areas that we live and work on across
    Australia. We acknowledge their continuing connection to their culture, their
    contribution to our shared knowledge, and pay our respects to their Elders past
    and present. Copyright Legal Notice and Disclaimer Privacy'
  inline_citation: '>'
  journal: Functional Plant Biology
  limitations: '>'
  pdf_link: null
  publication_year: 2012
  relevance_score1: 0
  relevance_score2: 0
  title: 'Early drought stress detection in cereals: simplex volume maximisation for
    hyperspectral image analysis'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1109/jstars.2014.2330352
  analysis: '>'
  authors:
  - Stephanie Delalieux
  - Pablo J. Zarco‐Tejada
  - Laurent Tits
  - M.A. Jiménez-Bello
  - Diego S. Intrigliolo
  - Ben Somers
  citation_count: 47
  full_citation: '>'
  full_text: '>

    This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org
    IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal
    Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln
    Sign Out All Books Conferences Courses Journals & Magazines Standards Authors
    Citations ADVANCED SEARCH Journals & Magazines >IEEE Journal of Selected Topi...
    >Volume: 7 Issue: 6 Unmixing-Based Fusion of Hyperspatial and Hyperspectral Airborne
    Imagery for Early Detection of Vegetation Stress Publisher: IEEE Cite This PDF
    Stephanie Delalieux; Pablo J. Zarco-Tejada; Laurent Tits; Miguel Ángel Jiménez
    Bello; Diego S. Intrigliolo; Ben Somers All Authors 40 Cites in Papers 615 Full
    Text Views Abstract Document Sections I. Introduction II. Methods III. Materials
    IV. Results and Discussion V. Conclusion Authors Figures References Citations
    Keywords Metrics Footnotes Abstract: Many applications require a timely acquisition
    of high spatial and spectral resolution remote sensing data. This is often not
    achievable since spaceborne remote sensing instruments face a tradeoff between
    spatial and spectral resolution, while airborne sensors mounted on a manned aircraft
    are too expensive to acquire a high temporal resolution. This gap between information
    needs and data availability inspires research on using Remotely Piloted Aircraft
    Systems (RPAS) to capture the desired high spectral and spatial information, furthermore
    providing temporal flexibility. Present hyperspectral imagers on board lightweight
    RPAS are still rare, due to the operational complexity, sensor weight, and instability.
    This paper looks into the use of a hyperspectral-hyperspatial fusion technique
    for an improved biophysical parameter retrieval and physiological assessment in
    agricultural crops. First, a biophysical parameter extraction study is performed
    on a simulated citrus orchard. Subsequently, the unmixing-based fusion is applied
    on a real test case in commercial citrus orchards with discontinuous canopies,
    in which a more efficient and accurate estimation of water stress is achieved
    by fusing thermal hyperspatial and hyperspectral (APEX) imagery. Narrowband reflectance
    indices that have proven their effectiveness as previsual indicators of water
    stress, such as the Photochemical Reflectance Index (PRI), show a significant
    increase in tree water-stress detection when applied on the fused dataset compared
    to the original hyperspectral APEX dataset (R 2 = 0.62, p <;0.001 vs. R 2 = 0.21,
    p > 0.1). Maximal R 2 values of 0.93 and 0.86 are obtained by a linear relationship
    between the vegetation index and the resp., water and chlorophyll, parameter content
    maps. Published in: IEEE Journal of Selected Topics in Applied Earth Observations
    and Remote Sensing ( Volume: 7, Issue: 6, June 2014) Page(s): 2571 - 2582 Date
    of Publication: June 2014 ISSN Information: DOI: 10.1109/JSTARS.2014.2330352 Publisher:
    IEEE Funding Agency: SECTION I. Introduction For many precision farming applications,
    the continuous retrieval of spatial, spectral, and/or thermal variability within
    heterogeneous crops is of great importance. This detailed information is needed
    for identifying vegetation stress, which is one of the major factors influencing
    farming management decisions making. Since wilting and dying of plants only occur
    at extreme developed stress stages, a visual inspection of vegetation health status
    is most often not time-efficient to avoid yield losses. Numerous studies have
    focused on early, nondestructive stress detection for more efficient crop management
    practices. From these, we can conclude that the physiological responses to stress
    can be captured in reflectance signals and temperature profiles [1]–[3]. Methods
    regarding canopy temperature were mainly focused on the effects of water stress
    on stomatal closure and thermal energy dissipation pathways. In 1982, Idso [4]
    found out that a large difference between canopy temperature and ambient temperature
    (Tc–Ta) was associated with water stressed plants, whereas low difference values
    were associated with well-irrigated plots. Other studies mainly focused on reflectance
    patterns. Vegetation indices (VIs) provide a very simple yet elegant method for
    extracting the green plant quantity signal from complex canopy spectra. Often
    computed as differences, ratios, or linear combinations of reflected light in
    visible and NIR wavebands [5]–[8], VIs exploit the basic differences between soil
    and plant spectra. Broad waveband Vis, however, typically lacks diagnostic capability
    for identifying a particular type of stress or for determining why biomass is
    at a certain level. Narrower band, hyperspectral, indices such as the Photochemical
    Reflectance Index (PRI), Water Band Index (WBI), and Normalized Pigment Chlorophyll
    Ratio Index (NPCI) are examples of reflectance indices that are correlated with
    certain physiological plant responses and have promise for diagnosing water and
    nutrient stress [9]–[11]. Next to the high spectral and temporal resolution imagery
    needed to timely capture subtle differences in reflectance spectra caused by plant
    physiological responses, also high spatial resolution data are needed. Suarez
    et al. [12], e.g., indicated the importance of acquiring very high spatial resolution
    imagery ( Undefined control sequence \nbsp ) for assessing fruit quality and water
    stress in citrus and olive orchards. Stuckens et al. [13] came to a similar conclusion
    when exploring the number of spectrally mixed pixels (i.e., trees, weeds and/or
    soil all occur within a single image pixel) in simulated orchards. They concluded
    that pixel sizes should be smaller than 1 m in order to obtain a minimum of 50%
    pure pixels and smaller than 10 cm for 82% pure pixels. Followup studies demonstrated
    that these mixing effects of plants and background/litter, whether linear or nonlinear,
    play an important role in obstructing a detailed assessment of crop conditions
    in these heterogeneous architectures [14], [15]. Until recently, it was not feasible
    or affordable to capture high spectral, spatial, and temporal resolution image
    datasets. For high temporal resolution imagery, one should refer to spaceborne
    data. However, due to physical limitations and data-transfer requirements the
    design and development of spaceborne remote sensors face a tradeoff between the
    spatial and spectral resolution [16]. The Hyperion sensor on board the EO-1 satellite
    currently offers the highest spectral resolution available from space. The spatial
    resolution of 30 m restricts, however, a proper use of the inherent potential
    of these data for detailed mapping purposes [17] and precision farming applications
    [18]. On the other hand, sensors such as Quickbird and WorldView-2 are able to
    offer very high spatial resolution imagery, but at the expense of their spectral
    resolution: panchromatic at submeter spatial resolution, and 4 (Quickbird) to
    8 (Worldview-2) broad spectral bands with approximately 2.5 m spatial resolution.
    With the launch of new high-resolution (HR) satellites such as Worldview-3 and
    planned hyperspectral missions like Enmap [19], [20], Prisma [21], and Hyspiri
    [22] much more data will become available to the user community. Still, the tradeoff
    in spectral and spatial resolution will remain and new advanced data and decision
    fusion approaches are needed to make optimal use of the future sensor ensembles.
    Full-range (400–2500 nm) hyperspectral airborne sensors such as Airborne Prism
    EXperiment (APEX), Airborne Hyperspectral Scanner (AHS), Airborne Visible/Infrared
    Imaging Spectrometer (AVIRIS), and Hyperspectral Mapper (Hymap), also face this
    spectral–spatial resolution tradeoff [16]. These hyperspectral airborne sensors
    are limited to a spatial resolution of around 2 m, which for the above mentioned
    precision farming application might not be sufficient. Novel hyperspectral sensors,
    such as HYSPEX and FIRST, could be mounted on a manned aircraft which, when flying
    very low, might provide high spatial and spectral resolution data. However, due
    to the high operational cost of manned flight campaigns, the temporal resolution
    of this kind of data will be limited. Innovative developments in Remotely Piloted
    Aircraft Systems (RPAS) platforms and associated sensing technologies are nowadays
    expanding at an increasing rate, bringing image resolutions to unprecedented levels
    of detail, thereby opening exciting new application opportunities [23]. This is
    especially of huge interest to the precision farming community [24], which requires
    flexible and frequent data capturing. Although, mainly due to payload restrictions,
    full-range optical hyperspectral sensors (i.e., ranging from 350 to 2500 nm) are
    not yet suited to be operated in an operational manner on these lightweight RPAS
    platforms proposed for precision agriculture. Only few studies have successfully
    tested pushbroom hyperspectral VNIR sensors on a small, lightweight, fixed-wing
    RPAS [25]. In an attempt to overcome current spatial, spectral, temporal resolution
    tradeoffs in spectral sensor design, this study investigates the possibility of
    assembling a promising new data source through fusing very-high spatial and high
    spectral imagery based on unmixing techniques, as such enabling more detailed
    monitoring purposes. We thereby hypothesize that the combination of the high spatial
    resolution imagery captured by a sensor mounted on a RPAS and the more detailed
    spectral information available from airborne hyperspectral sensors, albeit at
    lower spatial resolution, can help to overcome the spatial–spectral data availability
    tradeoff. Reviews of data fusion methods can be found in [26] and [27]. An interesting
    unmixing-based fusion technique was previously proposed by Zurita-Milla et al.
    [28], who extended on the work of Zhukov et al. [29] and Filiberti [30]. In each
    of these studies, a multisensor, multiresolution fusion technique was applied
    to unmix low spatial resolution images using the information about their pixel
    composition from coregistered high spatial resolution images. Yet, none of these
    studies were performed on very high spatial (cm resolution) and hyperspectral
    datasets. Filiberti [30] merged a high-spatial-resolution panchromatic band with
    a low-spatial-resolution multispectral Landsat TM band with a 1:2 ground sample
    distance (GSD) ratio between the panchromatic (15 m) and the TM multispectral
    band (30 m). As such, he aimed at restoring the multispectral image using content
    from the higher resolution panchromatic image. Zurita-Milla et al. [28] showed
    that the unmixing-based data fusion approach can be used to successfully downscale
    MERIS FR information (300 m pixel size, 15 bands) to a Landsat-like spatial resolution
    (25 m pixel size, 6 bands) and as such obtain better MERIS land products. They
    successfully used the MERIS fused images to assess vegetation status by evaluating
    the Normalized Difference Vegetation Index (NDVI), the Modified Transformed Chlorophyll
    Index (MTCI), and the Modified Green Vegetation Index (MGVI). To address the needs
    for the early detection of vegetation stress, i.e., high detailed, hyperspectral,
    and frequent data, we investigated the added value of unmixing-based fusion of
    unmanned aerial systems and airborne hyperspectral imagery. A spatial unmixing
    fusion algorithm is, therefore, implemented and applied on simulated and experimental
    hyperspatial and hyperspectral citrus orchard image datasets. The simulated citrus
    orchard thereby serves as a preliminary validation tool for the fusion algorithm.
    For the in situ datasets, the fusion process is applied on the most detailed information
    available both spectrally and spatially. Hyperspatial (cm) images are gathered
    by a thermal sensor installed on a highly flexible RPAS, whereas the hyperspectral
    data are acquired by the APEX sensor. The hyperspectral and hyperspatial datasets
    are fused or spatially unmixed (SpU) in order to assess the performance of narrowband
    physiological indices for estimating water stress levels in citrus orchards at
    a 20-cm scale. SECTION II. Methods A. Drought Stress Assessment Stem water potential
    ( ψ_stem ) is known to be a reliable plant-based water status indicator for irrigation
    scheduling in fruit trees [31], [32]. However, its measurement is a cumbersome
    procedure and requires frequent trips to the field and a significant input of
    labor. Measurements of the stem water potential are, therefore, not useful to
    monitor drought stress in an operational way. For that reason, spectral VIs were
    preferred for estimating water stress from complex canopy spectra, since they
    provide a simple and efficient method to do so. The NDVI is probably the most
    studied and implemented vegetation index ever [33]. The NDVI makes use of the
    characteristic features of vegetative reflectance spectra, namely low reflectance
    in the red region of the spectrum due to chlorophyll absorption and high reflectance
    values in the near infrared domain due to scattering caused by internal leaf structure.
    The optimal information on the physiological status of a plant is, however, not
    necessarily related to those two regions. Moreover, the NDVI is often not a good
    indicator of stress as it is only accurate for Leaf Area Index (LAI) (defined
    as the one-sided green leaf area per unit ground surface area), biomass, and chlorophyll
    determination at relatively low factor levels, due to a saturation effect at higher
    levels of those factors [34], [35]. The theory that underpins this vegetation
    index is, however, promising. Standardized indices have the potential of estimating
    biophysical parameters in a manner more meaningful than simple ratio indices due
    to their inherent characteristic of reducing the effects of spectral variations
    caused by surface topography [36] and sun elevation for different parts of an
    image. In line with this assumption, the standardized difference of the simulated
    spectral reflectance values [of low-resolution hyperspectral (LR-HS), HR, high-resolution
    hyperspectral (HR-HS) images], and of the unmixing-based fused HR, hyperspectral
    image, referred to as SpU image was calculated for each possible combination of
    two different wavelengths for realistic ranges of chlorophyll and water content
    values (1) [37] SDVI= λ i − λ j λ i + λ j (1) View Source with λ i and λ j being
    the spectral reflectance at wavelength i and wavelength j , respectively, with
    i and j ranging from 400 to 2500 nm. Since the data in the validation experiment
    was simulated, the portions or fractions of soil and vegetation for each pixel
    were known as well. Multiplying these fractions with the leaf water and chlorophyll
    content values enabled the reconstruction of reference water and chlorophyll maps.
    Hitherto, two reference biophysical parameter maps and four spectral images (LR-HS,
    HR, HR-HS, and SpU) were available. A map representing the coefficients of determination
    ( R 2 ) of the linear relationship between each possible SDVI map and the reference
    water and chlorophyll maps was then calculated. This approach allowed the selection
    of an optimal SDVI to estimate water and chlorophyll content and in the meantime
    allowed to check how well the commonly used biophysical parameter related VIs
    perform on the 1) hyperspectral-low spatial (LR-HS), 2) hyperspatial–hyperspectral
    (HR-HS), and the 3) fused hyperspectral–hyperspatial (SpU) dataset. Since narrowband
    indices (Table I) closely related to the 1) epoxidation state of the xanthophylls
    cycle; 2) chlorophyll a+b concentration; 3) blue/green/red ratio indices; 4) carotenoid
    concentration; and 5) tree crown structure have been applied in a previous study
    to detect water stress in citrus orchards at the tree level [11], our focus was
    reoriented on these indices for the experimental study. Zarco-Tejada concluded
    from his study that the xanthophyll pigment related PRI calculated with the 570
    nm (PRI570) [38] as well as with 515 nm (PRI515) band as a reference [39], was
    significantly related to the stem water potential, and as such indirectly to the
    water status of the plant. Also in other studies, PRI has been used to assess
    previsual water stress at leaf level [40], [41], at canopy level [42]–[44] and
    using airborne imaging spectroscopy [45]. The PRI index [38], [46] is based on
    the short-term reversible xanthophyll pigment changes accompanying plant stress
    [9], [47]. These changes are linked to the dissipation of excess absorbed energy
    that cannot be processed through photosynthesis [10], [48]–[51]. At the leaf and
    canopy levels, the PRI has been extensively found adequate to estimate photosynthetic
    performance [52]. TABLE I Coefficients of Determination R 2 Obtained Through Narrowband
    Indices From APEX and SpU Imagery Against Stem Potential Also the Transformed
    Chlorophyll Absorption Ratio Index (TCARI) showed sensitivity to stress levels,
    and the blue/green ratio BGI1 was highly significant. The effects of water stress
    on the canopy structure were successfully captured by structural indices such
    as NDVI, RDVI, SR, MSR, OSAVI, TVI, and MTVI. For the 14 trees under investigation
    in the three selected orchards of the study area, the correlation between all
    possible SDVIs, including the above-mentioned indices, and the stem water potential
    was calculated. The index pixel values of the fused image (28 cm) were averaged
    over each tree. A linear relationship was sought between the VIs, calculated from
    the fused and the original APEX datasets, and the in situ measured stem water
    potentials as well as between the thermal data and the stem water potentials.
    B. Fusion Method—SpU SpU is a fusion technique, which aims at combining the detailed
    information from two images over the same study area: one with low spatial and
    high spectral resolution (in our case a hyperspectral airborne image), and one
    with high spatial and low spectral resolution (in our case a thermal RPAS image)
    [28], [29]. In order to easily understand this fusion method, some theoretical
    background knowledge on spectral unmixing or spectral mixture analysis (SMA) is
    required. Therefore, we hereby shortly introduce this commonly used image analysis
    technique, which converts mixed pixel reflectance values into numerical subpixel
    fractions of a few ground components [53]. Although nonlinear mixing effects are
    well-acknowledged in vegetated areas [54], [55], [14], [96], [97], linear mixing
    models have proven to be adequate in the monitoring of vegetative systems [59],
    [60]. In the linear mixing model, mixed pixel signals (r) are modeled as a linear
    combination of pure spectral signatures of its constituent components (i.e., endmembers),
    weighted by their subpixel fractional cover [56] r=Mf+ε. (2) View Source In (2),
    M is a matrix in which each column corresponds to the spectral signal of a specific
    endmember. f is a column vector [f1,…,fm ] T denoting the cover fractions occupied
    by each of the m endmembers in the pixel. ε is the portion of the spectrum that
    cannot be modeled using these endmembers. A critical success factor of SMA is
    the selection of appropriate endmembers [57], [58]. The spectral signatures of
    the endmembers may be 1) derived from spectral libraries built from field or laboratory
    measurements, obtained using ground-based or portable spectroradiometers (e.g.,
    [59], [60]); 2) derived directly from the image data themselves (e.g., [61]–[63]);
    or 3) simulated using radiative transfer models (e.g., [64]–[66], Once the endmembers
    and their spectral signatures are known and if the number of endmembers is less
    than the number of spectral bands, the system of (1) is over-determined and may
    uniquely be inverted using techniques to solve for the fractions to solve for
    the fractions minimizing the error term ε in (2). Least squares regression analysis
    is one of the most commonly used optimization techniques [67]. SMA can be implemented
    without constraints (e.g., [68]), but physically meaningful abundance estimates
    are often obtained by constraining the coefficients in (2) to sum to unity and
    to be positive [69], [70]. The SpU fusion algorithm applied in this study differs
    from spectral unmixing as it tries to recover the spectra for endmember classes
    within a pixel, instead of the cover fractions of the different materials. The
    material fractions can be deduced from the high spatial, low spectral resolution
    RPAS image. Fig. 1 gives a visual representation of the spatial unmixing technique.
    Several steps are involved in the procedure starting with the classification of
    the high spatial resolution image in m classes (in casu, soil, and vegetation).
    Fraction maps F are subsequently created per predefined kernel k (in casu, five
    by five) of the hyperspectral pixels, by counting for each class the amount of
    HR pixels, which are present in the corresponding lower resolution pixel. Once
    the fraction maps F are calculated and given the hyperspectral reflectance values
    for the hyperspectral pixels R at a particular wavelength of interest, the spatial
    unmixing equation can be solved by least squares optimization, in order to find
    the reflectance value at that particular wavelength of the class endmembers M
    . The unmixing is thus solved for each low spatial resolution band independently.
    Therefore, a kernel size larger than or equal to the number of classes present
    in the neighborhood had to be chosen, because each hyperspectral pixel provides
    only one mixing equation [28]. Finally, each of the m classes present in the central
    pixel of the kernel is replaced by its corresponding unmixed signal. By repeating
    this operation for all the airborne hyperspectral pixels and bands, and for different
    combinations of m and k , a series of fused images is generated in which endmember
    variability is induced, which can be seen as a major benefit of this unmixing-based
    fusion method [69]. Fig. 1. Overview of the spatial unmixing technique. Show All
    Analogous to (2), the unmixing-based fusion method can be defined as follows:
    R i,k = M i,k,m ⋅ F k,m +ε. (3) View Source In (3), R i,k is a vector that contains
    the values of band i for all the hyperspectral pixels present in the neighborhood
    k . M i,k,m is the unknown vector containing spectral information of each of the
    classes present in k . F k,m is a matrix containing the cover fractions occupied
    by each of the m endmembers in each pixel in k . ε is the portion of the spectrum
    that cannot be modeled. This indirectly implies that the number of classes ( m
    ) and the size of the neighborhood ( k ) need to be optimized. m needs to be optimized
    based on the application demand and on the spectral variability of the scene.
    k also needs to be optimized because it has a great impact on the spectral quality
    of the fused image. The performance of the fusion method was first tested on a
    simulated dataset, which is further described in detail in Section III-A. A robust
    classification of the hyperspatial image was achieved by the linear discriminant
    analysis method with endmember selection as available in the open source ENVI/IDL
    code [71]. After a sensitivity analysis (results not shown), a kernel size of
    5×5 pixels was defined as optimal for spatial unmixing of these datasets. Changing
    the kernel size had a major impact on the endmember variability in the scene and
    played an important role in the reconstruction of the hyperspectral signatures.
    Next to the assessment of the index performances, the hyperspectral signatures
    reconstruction through unmixing-based fusion was evaluated as well. The root-mean-square
    error (RMSE) and relative-root-mean-square error (RRMSE) were calculated to compare
    the hyperspectral signals from the reference HR-HS image and the modeled signals
    from the SpU and LR-HS (upscaling with a factor 10) images. RMSE, defined (4),
    is a measure of the standard deviation, whereas RRMSE, defined in (5), is RMSE
    as a percentage of the mean observation. RMSE and RRMSE should be as small as
    possible, optimally zero RMSE RRMSE = ∑ i=1 n ( O i − P i ) 2 n − − − − − − −
    − − − − −  ⎷   = ∑ i=1 n ( O i − P i ) 2 n − − − − − − − − − − − −  ⎷  
    ⋅ 1 O ¯ ¯ ¯ ¯ . (4) (5) View Source In (4) and (5), O i is the reference or observed
    value at wavelength i ; P i the predicted value at wavelength i ; n the total
    amount of measurements; and O ¯ ¯ ¯ ¯ the average of the observations. After validating
    the fusion algorithm on a simulated dataset, the algorithm was applied on an experimental
    dataset, which is described in Section III-B. By fusing the information from the
    hyperspectral (APEX) and hyperspatial (thermal RPAS) datasets into an SpU, hyperspatial,
    hyperspectral resolution scene (SpU), we aimed at a more efficient assessment
    of the level of water stress in capital intensive citrus orchards. The thermal
    RPAS data were, therefore, classified in three physiological meaningful temperature
    classes. A kernel size of 5×5 was defined as most optimal. Combining different
    kinds of images requires a perfect coregistration. Fifteen ground control points
    (GCPs) were identified in both images for this purpose. SECTION III. Materials
    A. Simulated Data Experiment For this study, a ray-tracing experiment in a fully
    calibrated virtual 3-D representation of a citrus orchard was used. This 3-D radiative
    transfer model has been integrated in the web-based RAMI Online Model Checker
    (ROMC) service [72], and has previously been used as a reference tool for validation
    of image analysis techniques for precision farming (e.g., [18], [66], Based on
    detailed in situ calibration measurements, virtual 3-D replicas of orchard trees
    were built as triangular meshes using a tree geometry algorithm developed in Weber
    and Penn [73] (Fig. 2). Fig. 2. (Left) a virtual 3-D replica of an orchard tree,
    (right) a real orchard tree. Show All All reference data for calibration (and
    validation) were collected in a 9-year-old Valencia “Midknight” orange grove near
    Wellington, South Africa ( 33 ∘ 13 ′ 60 ′′ S ; 18 ∘ 15 ′ 60 ′′ E , altitude 100
    m). The orchard block had a row spacing of 4.5 m, a tree spacing of 2 m, and a
    row azimuth of 7.3 ∘ . For each tree, dendrometric (LAI, height, crown width,
    and diameter) and optical properties (leaf and canopy reflectance) were determined.
    Canopy and leaf reflectance spectra were collected using an ASD FR spectroradiometer
    (Analytical Spectral Devices, Boulder, CO) ranging from 350 to 2500 nm with a
    spectral resolution of 3 nm in the VIS and NIR and 10 nm in the SWIR. The noise
    level for this instrument is provided by the manufacturer as Undefined control
    sequence \nbsp at 700 nm, Undefined control sequence \nbsp at 1400 nm, and Undefined
    control sequence \nbsp at 2100 nm. A 25 ∘ field of view (FOV) bare fiber optic
    was used. Within the orchard, 60 trees were selected that cover the range of structural
    and spectral variability encountered in the orchard. Leaf chlorophyll and water
    content were derived from the measured leaf spectra through inversion of the PROSPECT
    model [74]. These field measurements were used to calibrate 3-D replicas of the
    measured trees. In order to increase the observed variability in tree conditions,
    we further created for each of the 3-D trees three additional clones. While the
    overall tree architecture remained the same, we created 1) one clone with similar
    leaf spectra but with a LAI, which was 56% of the reference trees by randomly
    removing part of the leaves; 2) one clone with similar LAI and leaf water content
    but reduced leaf chlorophyll content (50% of the reference chlorophyll) (note
    that the new reflectance coefficients were recalculated with the PROSPECT model
    [75]); and 3) one clone with similar LAI and leaf chlorophyll but reduced water
    content (70% of reference). The new reflectance coefficients were recalculated
    with the PROSPECT model [75]. Thus, extra variability in the biophysical parameters
    and the spectral data were created to incorporate different types of stress. All
    3-D tree replicas were then randomly placed in the orchard. The physical and optical
    properties of the soil (sandy texture, gravimetric moisture content ranging between
    0% and 15%) were determined in the field and applied in the virtual model. Full
    details on the calibration procedure can be found in Stuckens et al. [75], whereas
    a more detailed description of the field campaign can be found in Somers et al.
    [76]. Three synthetic images of the virtual orchard were generated using a modified
    version of a physically based ray-tracer [77] (Fig. 3, The first image of Undefined
    control sequence \nbsp provided information in 216 spectral bands ranging from
    350 to 2500 nm with a spectral resolution of 10 nm and a spatial resolution of
    2 m (referred to as, low-resolution–hyperspectral or LR-HS, left panel of Fig.
    3). This is comparable to the resolutions obtained by airborne hyperspectral sensors,
    such as APEX and CASI. Fig. 3. RGB representation of the synthetic images of the
    virtual orchard (left: LR-HS—2 m, center: HR—0.2 m and right: HR-HS—0.2 m) generated
    using a modified version of a physically based ray-tracer. Show All The second
    scene, depicted in the center panel of Fig. 3, represents an image captured by
    a RGB sensor onboard a RPAS. The image of Undefined control sequence \nbsp with
    a spatial resolution of 0.2 m is further referred to as high resolution or HR)
    (Fig. 3, center panel). The third or reference image scene simulated a 216-band
    hyperspectral sensor ranging from 350 to 2500 nm with a spectral resolution of
    10 nm and a spatial resolution of 0.20 m (high resolution-hyperspectral or HR-HS).
    Such detailed imagery is currently not yet achievable on a recurrent basis (high
    temporal resolution) by satellite or airborne systems. The airborne hyperspectral
    cameras, such as Hyspex, can possibly be used in manned aircrafts to gather high
    spatial and spectral resolution data, but the temporal resolution will be limited
    due to financial constraints (manned aircrafts are expensive). Notwithstanding
    this, it serves as a perfect reference scene to test the efficiency of the unmixing-based
    data fusion of the first two image scenes. For each simulated image scene, detailed
    fraction maps (cf. Section II-B) were available. B. Real Data Experiment An additional
    experiment was conducted in a 310-ha drip irrigated commercial Citrus orchard
    near Picassent, in the province of Valencia (Spain, 39.38N, 0.475E, altitude 47
    m). In Citrus, an accurate and previsual detection of water stress is of utmost
    economic importance for farmers [78]. The orchard design was characterized by
    large (5–6 m) row spacing, with canopy ground cover below 65% even in the more
    vigorous orchards. Three test orchards were selected based on the large variation
    in plant water status of the measured trees. A total of 14 trees were used for
    assessment of midday stem water potential ( ψ s ) determined using a pressure
    chamber in leaves that were bagged at least 1 h prior to the measurements. Stem
    water potential was chosen as the true field determination of citrus trees water
    status due to its sensitivity to water deprivation [79]. The ψ s measurements
    of each tree were related with the individual tree canopy temperature (Tc) extracted
    from the airborne imagery. Within the selected trees, ψ s varied from −0.6 to
    Undefined control sequence \nbsp . According to a previous study by Ballester
    et al. [80], these values correspond to well watered and relatively severe tree
    water stress conditions, respectively. Airborne hyperspectral APEX imagery was
    acquired over the study area on September 8, 2011 around solar noon. The air temperature
    and vapor pressure deficit (VPD) at the time of the flight were 30.4 ∘ and 2.1
    kPa, respectively. The APEX sensor recorded the reflected light in 288 bands,
    ranging from 380 to 2500 nm with a spatial resolution of 2.7 m. The airborne measurements
    were accompanied with spectral field and lab measurements for calibration and
    validation of the airborne data. APEX geometric correction was accomplished based
    on the delivered metadata (i.e., IMU). Atmospheric correction was performed with
    the processing chain of VITO, based on the algorithms of ATCOR [81]. The geometric
    correction was performed by VITO’s own developed C++ module and is based on direct
    georeferencing. Input data from the sensor’s GPS/IMU, boresight correction data
    and the SRTM DEM were further used during the geometric correction process (Fig.
    4). Another set of aerial images was collected on August 23, 2011 at 10:00 GMT
    time with a thermal sensor installed on a RPAS, acquiring imagery at 20 cm resolution.
    A thermal camera (Miricle 307 K; Thermoteknix Systems Ltd, Cambridge, U.K.) was
    installed on a RPAS developed at the Laboratory for Research Methods in Quantitative
    Remote Sensing (Quantalab; IAS-CSIC, Córdoba, Spain), as described by Zarco-Tejada
    et al. [25]. The camera has a resolution of 640×480 pixels, is equipped with a
    14.25-mm f1.3 lens, and is connected to a computer via a USB 2.0 protocol. The
    spectral response was in the range Undefined control sequence \nbsp . The air
    temperature and VPD at the time of the flight were 31.6 ∘ and 1.9 kPa, respectively.
    The camera was calibrated in the laboratory to obtain radiance values, and then
    upwelling and down welling sky temperature was measured during the flight. In
    addition, indirect calibrations were conducted using surface temperature measurements
    to improve the calibration. The accuracy of this method was evaluated by Berni
    et al. [23], who have demonstrated an accuracy less than 1 K. The mosaicking process
    selects only the most nadir part of the overlapping images, limiting the viewing
    angle and thus avoiding directional effects and thermal hotspot. Each snapshot
    had a relative temperature scale, being the minimum value the coldest pixel and
    the maximum value the hottest pixel of the snapshot [23]. Based on the temperature
    differences between plant canopy and air temperature (Tc-Ta), all background and
    nonphotosynthetic trees were masked. This region of interest was subsequently
    overlaid on the APEX image to remove all redundant information from the APEX scene.
    This, however, also implied the removal of all warm, i.e., nontranspiring and/or
    dead trees. The hyperspectral APEX and hyperspatial, thermal images were resampled
    to 2.8 and 0.28 m, respectively. SECTION IV. Results and Discussion A. Simulated
    Dataset The unmixing-based fusion of the LR-HS and HR simulated image data resulted
    in an SpU image containing 216 bands at 20 cm resolution. The fused image product
    (SpU) now contains more detailed spectral and spatial information on the individual
    image elements or endmembers (e.g., orchard trees). This becomes clearer when
    looking into the results of the hyperspectral signature reconstruction evaluation
    study (Fig. 5). Fig. 4. Left: APEX region of interest with 288 spectral bands
    and 2.80 m spatial resolution, mid: RPAS region of interest with 1 thermal band
    and 0.28 m spatial resolution. Right top: 10× zoom of APEX orchard with 288 spectral
    bands and 2.80 m spatial resolution, right bottom: RPAS orchard with 1 thermal
    band and 0.28 m spatial resolution. Show All Fig. 5. RMSE (left) and RRMSE (right)
    plots calculated from the reference spectra and 1) the reconstructed SpU spectra
    and 2) the downscaled LR-HS spectra. Show All Fig. 6. The reference chlorophyll
    (left) and water map (right). Show All Overall, we observed a significant increase
    in signature modeling accuracy compared to the spectra of the LR image. The increased
    accuracy was specifically remarkable in the 350–800 nm and 1200–2500 nm domain,
    which is most probably due to the higher differences between soil and vegetation
    spectra in these spectral regions [76]. This highlights that the spectral mixing
    of vegetation and soil spectra, which remains the main bottleneck when using LR
    imagery in precision agriculture [13], [82], [18], can, to a large extent, be
    solved by SpU. By better modeling the spatial variability in crop spectra—i.e.,
    by removing the effects of undesired background effects—SpU opens new opportunities
    for the site-specific monitoring of the condition of crops (i.e., precision farming).
    In this light, we evaluated the added value of the proposed method in estimating
    the crop canopy water and chlorophyll content. Recall that for this simulated
    scene we reconstructed HR (0.2 m resolution) reference maps of the chlorophyll
    ( Chl ref ) and water ( C w REF ) content of the crop canopies (Fig. 6). For each
    simulated image, i.e., HR, LR-HS, and HR-HS, the coefficients of determination
    ( R 2 ) of the linear regression between all possible SDVIs and the water ( C
    wREF ) and chlorophyll ( Chl ref ) content maps are summarized in Fig. 7. Fig.
    7. R 2 values indicating the performances of each possible SDVI to estimate chlorophyll
    (top) and water content (bottom) of the LR-HS, SpU, and HR-HS simulated images.
    A lower threshold value is defined for each image to enlarge the color contrast.
    Show All As expected, the SDVI’s most closely related to chlorophyll and water
    content, were mainly identical throughout the three images. For the LR-HS ( Undefined
    control sequence \nbsp ) image a maximum R 2 of 0.35 and 0.30 were observed for
    water and chlorophyll, respectively. A significant increase in predictive power
    was found for the SpU image with maximal R 2 values up to 0.77 for water and 0.71
    for chlorophyll. The most appropriate water and chlorophyll related indices contain
    wavebands corresponding to the highest coefficient of absorption by water (SWIR)
    [83] and chlorophyll (620–700 nm) [84], respectively. It has to be mentioned that
    these spectral regions correspond to the regions with the highest gain in signature
    modeling accuracy by applying the unmixing-based fusion compared to the original
    LR-HS and HR images (Fig. 5). This noticeably stresses the potential of the proposed
    technique for better estimating plant stress related to changes in biochemical
    parameter contents, such as chlorophyll and water. From Fig. 7, it was revealed
    that the best SDVIs to estimate canopy water (6) and chlorophyll content (7) were,
    respectively λ 730 − λ 1510 λ 730 + λ 1510 λ 540 − λ 590 λ 540 + λ 590 . (6) (7)
    View Source The corresponding SDVI maps are shown in Figs. 8 and 9. For easy interpretation,
    and to allow a fair comparison, also the reference water ( C wREF ) and chlorophyll
    ( Chl ref ) maps are shown. Fig. 8. Index (5) maps representing water content
    extracted from the LR ( R 2 =0.34 ) (top left), SpU ( R 2 =0.77 ) (top right),
    HR-HS ( R 2 =0.93 ) (bottom left) images, and reference water content map (bottom
    right). Show All Fig. 9. Index (6) maps representing chlorophyll content extracted
    from the LR-HS ( R 2 =0.30 ) (top left), SpU ( R 2 =0.71 ) (top right), HR-HS
    ( R 2 =0.86 ) (bottom left) images, and reference chlorophyll content map (bottom
    right). Show All Coefficients of determination ( R 2 ) calculated for the linear
    regression between the reference ( C wREF and Chl ref ) maps and the most appropriate
    SDVI (6) and (7) maps, showed significant differences in prediction accuracy for
    SpU ( C w SpU : R 2 =0.77 and Chl SpU : R 2 =0.71 ), compared to the original
    LR image ( C w LR : R 2 =0.35 and Chl ref : R 2 =0.30 ). The highest possible
    linear relationship between the selected SDVI (6) and (7) maps and the biophysical
    parameter content maps ( C wREF and Chl ref ) is shown in the C w HR−HS (with
    R 2 =0.93 ) and the Chl HR−HS ( R 2 =0.86 ) maps. From these results, we can conclude
    that the spatial resolution of 2 m can be beneficial for large scale mapping and
    monitoring of the citrus orchard, e.g., for delineating management zones in the
    orchard. However, the resolution is too coarse to precisely manage the orchard
    system in which an optimization of yield with a restricted input of natural resources
    is endeavored. This corroborated previous findings of Stuckens et al. [75] who
    illustrated that image interpretation in citrus orchards was already seriously
    aggravated at pixel sizes as small as 0.1 m resolution. At this resolution about
    18% of the pixels were still mixed, while for Undefined control sequence \nbsp
    , no pure pixels were present anymore. In addition, Zarco-Tejada et al. [85] demonstrated
    serious effects of soil background admixture on the chlorophyll concentration
    estimates of olive trees using 1 m ROSIS imagery. The SpU methodology provides
    a means to combine: 1) the high spatial detail needed to reduce undesired background
    effects; and 2) the high spectral detail for detailed characterization of the
    plant state. The data fusion approach as such allows providing adequate information
    support for agricultural production and accurate and precise management of fruit
    orchards. B. Real Data Experiment Applying the spatial unmixing technique on the
    0.28-m thermal RPAS and the 2.8-m hyperspectral APEX datasets resulted in an SpU
    image providing 288 bands at 0.28 m spatial resolution (Fig. 10). Fig. 10. SpU
    image and detailed view. Show All A visual inspection of the APEX pixel spectra
    already revealed an intimate mixture of soils and crops. This could quantitatively
    be verified, in Table I, comparing the coefficients of determination extracted
    from the relationship between narrowband index values acquired from the APEX and
    SpU images, respectively, against the stem water potential values. Results are
    shown for 21 narrowband stress-related VIs, already previously described in a
    similar case study in citrus performed by Zarco-Tejada et al. [25]. Although similar
    trends were found for the indexes extracted from the APEX and SpU pixels, an overall
    better relationship (higher R 2 ) was found for SpU. Due to the presence or admixture
    of soil background and vegetation in the larger APEX pixels, all indices performed
    worse in estimating water stress in the LR-HS APEX image. This was particularly
    true for the PRI570 index [Table I and Fig. 11, significant relationships ( p<0.05
    ) are shown in bold] with R 2 =0.62 for the SpU image compared to R 2 =0.21 for
    the LR-HS APEX image. The added value of the hyperspatial resolution lies herein
    that VIs can be applied on pure vegetation pixels without the contribution of
    soil background and structural effects [15], [18]. Knowing that the stem water
    potential is a good and reliable estimator of plant water stress, it can be concluded
    from the relationship shown in Fig. 11 that detailed spatial information is vital
    in water stress detection studies. Fig. 11. Representation of the correlation
    between the coefficients of determination R 2 obtained through narrowband indices
    from APEX and SpU imagery against stem potential. Show All When we also show results
    for all other SDVI’s in Fig. 12, it becomes clear that an even better water stress
    detection becomes possible when also the reflectance patterns of the SWIR domain
    could be captured by the sensor. Numerous previous studies have proven that the
    spectral behavior of vegetation in the SWIR spectral domain is severely influenced
    and masked by water absorption. In this study, R 2 values up to 0.81 (compared
    to 0.62 for PRI570) were obtained through a linear relationship of SpU derived
    SDVIs based on 562 and 1650 nm against stem water potential. The reflectance absorptions
    in the 1650–1850-nm region are known to reflect not only the leaf water content,
    but also the contents of leaf cellulose and lignin, and are directly related to
    the plant growing status [86], [87]. Fig. 12. R 2 values of the linear relationship
    between the stem water potential of the 14 trees of interest and all possible
    SDVIs (left) calculated from APEX pixels (right) calculated from SpU pixels. Atmospheric
    water absorption bands were masked from the analysis. Show All This is a particularly
    interesting observation, since current technology does not yet allow to gather
    such a high spatial, high spectral imagery over the full spectral range with airborne
    sensors. Yet, by fusing hyperspatial and full range (including SWIR) hyperspectral
    images we can create a new data source which, as shown in Fig. 12, opens new and
    promising opportunities for detailed water stress mapping. From the previous studies
    [1], [88]–[95], we know that a good correlation should exist between thermal data
    and water stress or stem potentials, which was not found in our study, due to
    a miscalibration of the thermal sensor. Within one image, the relationship between
    stem potentials and thermal data were high ( R 2 =0.72 ), but not as high as the
    PRI calculated from the SpU and water potentials relationship ( R 2 =0.80 ) within
    this same image. The temperature differences caused by the sensor were masked
    in the fusion method due to its inherent characteristic to reconstruct hyperspectral
    endmember signatures based on the materials present in the pixels within the kernel.
    SECTION V. Conclusion The aim of this study was to apply an unmixing-based fusion
    technique on a hyperspectral airborne and hyperspatial RPAS dataset for a better
    assessment of biophysical parameters in agricultural areas. We first tested the
    unmixing-based fusion method on simulated datasets to evaluate the proposed method
    through standardized VIs and spectral signature reconstruction. Based on the high
    correlations between the SDVI performances calculated from the SpU image and those
    calculated from the reference images, and the high R 2 ; values of the SDVI biophysical
    parameter content relations compared to those of the low-resolution (LR) image,
    we concluded that the SpU method has potential for more detailed research in water
    and chlorophyll content estimation. Subsequently, the fusion method was applied
    on a real test case, in which hyperspectral APEX and hyperspatial thermal RPAS
    images were combined in order to better and more accurately detect water stress
    in commercial citrus orchards. Thereby, a better relationship was found between
    the stem water potential, and the PRI570 index, both known to be good and reliable
    water stress indicators, when calculated on the fused image compared to the one
    obtained from the original lower resolution image ( R 2 =0.62 vs. 0.21). Furthermore,
    VIs containing shortwave infrared spectral bands have appeared to make a sound
    contribution in terms of the strength of relationships between spectral reflectance
    and water stress levels. This fusion technique offers new opportunities to the
    user community in that higher spatial spectral dataset become available for their
    research or operations. The need for a perfect coregistration of the two input
    images (i.e., high spatial and high spectral) can be seen as the major drawback
    of this technique. Efforts have to be made in this processing step, which has
    a large impact on the resulting fused image if not carefully done. Ideally, the
    two sensors, of which one is focused on the spatial detail and the other focused
    on the spectral detail should be mounted on one chip, so that coregistration issues
    are minimized. This approach could be extended globally for the fusion of high
    spatial and high spectral resolution satellite imagery, enabling also a temporal
    hyperspectral, hyperspatial analysis. Ongoing research focuses on quantification
    of nonlinear mixing effects in orchards, and its influence on the accuracy of
    unmixing models. If proven to be important, the implementation of nonlinear mixing
    models will be necessary to further improve the performance of the proposed algorithm.
    ACKNOWLEDGMENT D. Notario, A. Vera, R. Romero, and A. Hornero are also acknowledged
    for their technical support during the field and airborne campaigns. Authors Figures
    References Citations Keywords Metrics Footnotes More Like This Calculation of
    vegetation index for short wave infrared hyperspectral images 2017 25th Signal
    Processing and Communications Applications Conference (SIU) Published: 2017 Specific
    band ratio for vegetation indices calculation in hyperspectral images 2015 7th
    Workshop on Hyperspectral Image and Signal Processing: Evolution in Remote Sensing
    (WHISPERS) Published: 2015 Show More IEEE Personal Account CHANGE USERNAME/PASSWORD
    Purchase Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile Information
    COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help?
    US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow
    About IEEE Xplore | Contact Us | Help | Accessibility | Terms of Use | Nondiscrimination
    Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy Policy A not-for-profit
    organization, IEEE is the world''s largest technical professional organization
    dedicated to advancing technology for the benefit of humanity. © Copyright 2024
    IEEE - All rights reserved.'
  inline_citation: '>'
  journal: IEEE Journal of Selected Topics in Applied Earth Observations and Remote
    Sensing
  limitations: '>'
  pdf_link: null
  publication_year: 2014
  relevance_score1: 0
  relevance_score2: 0
  title: Unmixing-Based Fusion of Hyperspatial and Hyperspectral Airborne Imagery
    for Early Detection of Vegetation Stress
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.3791/56251
  analysis: '>'
  authors:
  - Gernot Bodner
  - Mouhannad Alsalem
  - Alireza Nakhforoosh
  - Thomas Arnold
  - Daniel Leitner
  citation_count: 22
  full_citation: '>'
  full_text: ">\nJournal of Visualized Experiments\nwww.jove.com\nCopyright © 2017\
    \  Creative Commons Attribution-NonCommercial-NoDerivs 3.0 Unported\nLicense\n\
    August 2017 |  126  | e56251 | Page 1 of 21\nVideo Article\nRGB and Spectral Root\
    \ Imaging for Plant Phenotyping and Physiological\nResearch: Experimental Setup\
    \ and Imaging Protocols\nGernot Bodner1, Mouhannad Alsalem1, Alireza Nakhforoosh1,\
    \ Thomas Arnold2, Daniel Leitner3,4\n1Division of Agronomy, Department of Crop\
    \ Sciences, University of Natural Resources and Life Sciences\n2Carinthian Tech\
    \ Research AG, High Tech Campus Villach\n3Computational Science Center, University\
    \ of Vienna\n4Simulationswerkstatt\nCorrespondence to: Gernot Bodner at gernot.bodner@boku.ac.at\n\
    URL: https://www.jove.com/video/56251\nDOI: doi:10.3791/56251\nKeywords: Environmental\
    \ Sciences, Issue 126, Root System, Hyperspectral Imaging, RGB Images, Plant stress,\
    \ Phenotyping, Rhizobox, Spectral\nAnalysis\nDate Published: 8/8/2017\nCitation:\
    \ Bodner, G., Alsalem, M., Nakhforoosh, A., Arnold, T., Leitner, D. RGB and Spectral\
    \ Root Imaging for Plant Phenotyping and Physiological\nResearch: Experimental\
    \ Setup and Imaging Protocols. J. Vis. Exp. (126), e56251, doi:10.3791/56251 (2017).\n\
    Abstract\nBetter understanding of plant root dynamics is essential to improve\
    \ resource use efficiency of agricultural systems and increase the resistance\n\
    of crop cultivars against environmental stresses. An experimental protocol is\
    \ presented for RGB and hyperspectral imaging of root systems.\nThe approach uses\
    \ rhizoboxes where plants grow in natural soil over a longer time to observe fully\
    \ developed root systems. Experimental\nsettings are exemplified for assessing\
    \ rhizobox plants under water stress and studying the role of roots. An RGB imaging\
    \ setup is described\nfor cheap and quick quantification of root development over\
    \ time. Hyperspectral imaging improves root segmentation from the soil background\n\
    compared to RGB color based thresholding. The particular strength of hyperspectral\
    \ imaging is the acquisition of chemometric information on\nthe root-soil system\
    \ for functional understanding. This is demonstrated with high resolution water\
    \ content mapping. Spectral imaging however\nis more complex in image acquisition,\
    \ processing and analysis compared to the RGB approach. A combination of both\
    \ methods can optimize a\ncomprehensive assessment of the root system. Application\
    \ examples integrating root and aboveground traits are given for the context of\
    \ plant\nphenotyping and plant physiological research. Further improvement of\
    \ root imaging can be obtained by optimizing RGB image quality with better\nillumination\
    \ using different light sources and by extension of image analysis methods to\
    \ infer on root zone properties from spectral data.\nVideo Link\nThe video component\
    \ of this article can be found at https://www.jove.com/video/56251/\nIntroduction\n\
    Roots provide several essential functions for plants such as storage of assimilates,\
    \ anchorage of terrestrial plants in soil, and uptake and\ntransport of water\
    \ and nutrients1. From an evolutionary point of view, the formation of root axes\
    \ is considered a fundamental precondition for the\norigin of land plants2. In\
    \ spite of this important role, historically roots have occupied only a marginal\
    \ position in biological research. In more recent\ntimes, however, there is increasing\
    \ scientific interest in plant root systems as evidenced in Figure 1.\nJournal\
    \ of Visualized Experiments\nwww.jove.com\nCopyright © 2017  Creative Commons\
    \ Attribution-NonCommercial-NoDerivs 3.0 Unported\nLicense\nAugust 2017 |  126\
    \  | e56251 | Page 2 of 21\n \nFigure 1: Relevance of root studies in plant sciences.\n\
    \ \nNumber of root related studies as a percentage of all published plant studies\
    \ in SCI journals over the last decades. Search result from Scopus\nusing keywords\
    \ \"plant\" and \"plant AND root\". Please click here to view a larger version\
    \ of this figure.\nTwo main reasons can be hypothesized to underlie the recent\
    \ advances in root research. First, terrestrial vegetation is exposed to more\
    \ frequent\nenvironmental stresses as a result of global change3. In the context\
    \ of agricultural crop production it is estimated that globally around 30% of\n\
    the agricultural area are limited by water and phosphorus4,5. Stress reduction\
    \ of crop yields are a main reason for significant yield gaps that are\nglobally\
    \ estimated at lower 50% of potential productivity for rainfed agro-ecosystems6.\
    \ Besides low resource availability, this is also related to\npoor resource use\
    \ efficiency, i.e. insufficient capacity of a plant to exploit available resources7.\
    \ This results in losses of mobile resources such\nas nitrate which can negatively\
    \ affect other ecosystems. The current global nitrogen use efficiency for example\
    \ is estimated at 47%8. Better\nresource use efficiency via improved management\
    \ methods and cultivars is therefore of high importance for both sustained growth\
    \ of agricultural\noutputs as well as for environmental sustainability. In this\
    \ context plant roots are considered to be a key target for improved crops and\
    \ cropping\nsystems9,10.\nA second important background for the recent interest\
    \ in plant roots is technological advance in measurement methods. Root methods\
    \ have\nlong been restricted by two key challenges: for measurement of roots from\
    \ plants growing in soil they had to be isolated for quantification,\nmostly by\
    \ washing11, thereby disturbing the architectural arrangement of root axes. In-situ\
    \ root observation using excavation methods, thereby\nconserving the natural location\
    \ of roots in soil, have been used for botanical description12. Still they are\
    \ very time-consuming and thus do not\nmeet the throughput requirements of comparative\
    \ structural-functional root system analysis. On the other hand high-throughput\
    \ methods for\nroot architecture measurement were mostly done on artificial media\
    \ and for seedling plants13 where the extrapolation to the natural growth\nenvironment\
    \ of plants is questionable14.\nThe recent boom of root research is tightly linked\
    \ to the advance in imaging methods15. Imaging approaches in root studies can\
    \ be roughly\ngrouped into three types. First there are high resolution 3D methods\
    \ such as CT and MRI16. These methods are most suitable to study\ninteraction\
    \ processes of plant roots with soil, such as drought induced xylem embolism17.\
    \ Typically they are applied to comparatively small\nsamples where they allow\
    \ detailed observations. A comparison of CT and MRI for differently sized pots\
    \ and fine root imaging is provided in18.\nSecond, there are high-throughput imaging\
    \ methods19,20. These methods are mostly based on common 2D RGB imaging of roots\
    \ growing\non artificial media (gel, germination paper) where high contrast allows\
    \ comparatively simple dissection between roots and background. They\nare appropriate\
    \ for high throughput comparison among seedling root traits of different crop\
    \ genotypes under standardized artificial growing\nconditions13. In between these\
    \ two approaches are rhizobox methods: they use 2D imaging of roots growing in\
    \ soil over longer time period and\nhave medium throughput21,22. A recent challenge\
    \ to (2D) root imaging is to capture also indicators of root functionality in\
    \ addition to description of\nstructure23.\nIn the present paper we present the\
    \ experimental protocols for imaging rhizobox grown root systems using (i) a cheap\
    \ and simple custom-made\nRGB imaging setup and (ii) a more complex NIR imaging\
    \ setup. Example results obtained from these two setups are shown and discussed\
    \ in the\ncontext of plant phenotyping and plant physiological research.\nJournal\
    \ of Visualized Experiments\nwww.jove.com\nCopyright © 2017  Creative Commons\
    \ Attribution-NonCommercial-NoDerivs 3.0 Unported\nLicense\nAugust 2017 |  126\
    \  | e56251 | Page 3 of 21\nProtocol\n1. Rhizoboxes for plant growth\nNOTE: The\
    \ experimental system uses rhizoboxes to grow plants for root imaging. First the\
    \ design of the boxes and the substrate used are\ndescribed, and then details\
    \ on the filling procedure are given.\n1.\nDesign of rhizoboxes\n1.\nCreate rhizoboxes\
    \ (Figure 2) with a back plate and side frames made of grey PVC with 15 mm strength.\
    \ Use a box size of 300 mm x\n1000 mm. For the front window, use 6 mm mineral\
    \ glass which is attached to the PVC frame by metal rails being screwed into the\
    \ side\nwalls.\n2.\nCreate three holes on the bottom frame to allow drainage of\
    \ excess water. These holes can be optionally closed by plastic screws.\n3.\n\
    Before filling, adapt the inner diameter of the rhizobox (between 10 mm and 30\
    \ mm) by inserting PC multiwall sheets. An inner space of\n10 mm is recommended\
    \ for most crops to reduce the weight (rhizobox weight without soil is 13.2 kg)\
    \ of the entire system.\n \nFigure 2: Rhizobox experimental system and its components.\n\
    \ \nLeft figure shows the dimensions of a rhizobox and right figure its single\
    \ components, being a grey PVC back plate with side frame, a front\nmineral glass,\
    \ multiwall sheets for variable inner diameter and metal angles to fix the front\
    \ glass to the back compartment. Please click here to\nview a larger version of\
    \ this figure.\n2.\nSubstrate\n1.\nFill the rhizoboxes with field soil (for this\
    \ experiment: silt loam top soil from a calcareous chernozem) sieved to 2 mm particle\
    \ size.\n2.\nOpen the rhizoboxes for filling the substrate into the inner compartment\
    \ (back plate with side frames) in horizontal position using pre-\nwetted substrate.\
    \ Fill horizontally to avoid layering and segregation between fine and coarse\
    \ particles which occurs when filling in\nvertical position by pouring the substrate\
    \ through the upper opening.\n3.\nPre-wet the substrate before filling. Depending\
    \ on the type of substrate (particularly on its silt and clay content), do not\
    \ exceed a water\ncontent of 0.12-0.18 cm3*cm-3 to avoid smearing and structure\
    \ degradation. Add the difference between pre-mixing and target water\ncontent\
    \ after filling the substrate into the rhizoboxes.\n \nNOTE: Filling with (oven-)dry\
    \ substrate and subsequent addition of the entire water is not recommended as\
    \ is can result in strong\nsettlement of the substrate and formation of large\
    \ cracks.\n3.\nStep by step filling example\nJournal of Visualized Experiments\n\
    www.jove.com\nCopyright © 2017  Creative Commons Attribution-NonCommercial-NoDerivs\
    \ 3.0 Unported\nLicense\nAugust 2017 |  126  | e56251 | Page 4 of 21\n1.\nDefine\
    \ the target water content. Here it is initially set at 80% plant available water\
    \ (PAW) where plants do not suffer from any water\nshortage.\n2.\nDetermine field\
    \ capacity (FC) and permanent wilting point (PWP) of the substrate. Here obtain\
    \ FC using a PVC tube of equivalent\nheight (100 cm) as the rhizoboxes.\n1.\n\
    Close the tube at the bottom with a stubble having small drainage holes, add 1\
    \ cm of gravel to avoid closure of the holes from\nfiner substrate and fill the\
    \ substrate to the same bulk density as used for the rhizoboxes (1.3 g cm-3).\n\
    2.\nSaturate the tube with water until drainage occurs and leave it for two days\
    \ to equilibrate (the resulting water content is per\ndefinition equivalent to\
    \ field capacity), while covering the upper opening with cling-film to avoid evaporation.\
    \ The field capacity\nvalue achieved for the soil in this experiment was 0.357\
    \ cm3 cm-3.\n \nNOTE: Water content at PWP has to be known in advance from standard\
    \ soil physical methods (e.g. pressure plate\nmeasurements24) or from texture\
    \ based pedotranfer functions25. Here it is equal 0.12 cm3 cm-3 for the soil used.\n\
    3.\nWhen measuring FC by pressure plate extraction too, take the water content\
    \ at a matrix potential of h=-100 hPa and not h=-330\nhPa in order to correspond\
    \ to the rhizobox geometry (height of 100 cm = 100 hPa).\n4.\nCalculate the water\
    \ content (WC) at 80% PAW: WC (cm3 cm-3) = 0.80 (FC-PWP) + PWP. For the hydraulic\
    \ limits of the soil used\nhere this gives a volumetric water content at 80% PAW\
    \ of 0.31 cm3 cm-3.\n5.\nCalculate the water amount for a rhizobox volume of 2850\
    \ cm3 (30 cm width, 1 cm inner space, 95 cm in height, with top 5 cm\nkeeping\
    \ free of substrate for watering). This gives a water volume of 883.5 cm3 equal\
    \ 883.5 g for the density of water being 1.0 g\ncm-3 at 20 °C.\n3.\nDefine the\
    \ bulk density (db) to fill the rhizoboxes. Here, set at 1.3 g cm-3 corresponding\
    \ to values typically found in agricultural field\nsoils. The amount of dry substrate\
    \ required to fill a rhizobox volume of 2850 cm3 at this db equals 3705 g of dry\
    \ soil.\n4.\nPre-wet the dry soil to a gravimetric water content of 0.108 g g-1\
    \ (equal to a volumetric water content of 0.14 cm3 cm-3) by adding 400 g\nof water\
    \ for 3705 g of dry soil and mix it gently to obtain a homogeneous water distribution.\
    \ Manually disrupt larger aggregates to keep\nthe particle size ≤ 2 mm.\n5.\n\
    Fill the pre-wetted soil into the opened rhizoboxes and compact it gently using\
    \ a polystyrene sheet (30 x 10 x 1.5 cm) to cover the inner\nvolume of the box,\
    \ thereby resulting in a homogeneous db of 1.3 g cm-3.\n6.\nAdd the remaining\
    \ amount of water (483.2 g) to achieve the target water content of 0.31 cm3 cm-3\
    \ by spraying onto the surface with\na spray bottle. Ensure small drop size to\
    \ avoid surface structure degradation and homogeneous wetting. Keep the box on\
    \ a balance\nduring spraying to monitor the amount of water actually added to\
    \ substrate.\n7.\nLet the water redistribute for 10 minutes and then press the\
    \ glass onto the surface and fix it with the side metal rails. The average final\n\
    weight of rhizoboxes with wetted substrate was 17818 ± 68 g (13230 g rhizobox\
    \ weight + 3705 g dry soil + 883 g water).\n \nNOTE: The homogeneous water content\
    \ filled in the horizontal boxes will redistribute when the boxes are set in their\
    \ final position\naccording to the resulting potential gradient. This is a physical\
    \ process in all plant growth pots according to their geometry (height) and\n\
    experimenters should be conscious on their pot hydraulics26.\n2. Climate room\
    \ setup\n1.\nEquip the climate room (Figure 3) with 8 LED lamps providing homogeneous\
    \ illumination of 450 μmol m-2 s-1 with spectral peaks at 440\n(blue) and 660\
    \ (red) nm for optimum plant growth.\nJournal of Visualized Experiments\nwww.jove.com\n\
    Copyright © 2017  Creative Commons Attribution-NonCommercial-NoDerivs 3.0 Unported\n\
    License\nAugust 2017 |  126  | e56251 | Page 5 of 21\n \nFigure 3: Climate chamber\
    \ with rhizoboxes for stress experiment.\n \n(A) Left view of entire chamber with\
    \ LED illumination, weather station and PC (here for logging leaf hygrometers);\
    \ right view with a close-\nup of the metal frame holding rhizoboxes in 45 ° inclination\
    \ and wooden plates used to shied rhizobox glass window against light. (B) Stress\n\
    experiment with sugar beet combining four stages with stress due to different\
    \ atmospheric demand (high/low) and soil water availability (high/\nlow). Green\
    \ bars of mean stomata conductance give an indication of plant stress response.\
    \ Please click here to view a larger version of this\nfigure.\n2.\nSet the ambient\
    \ parameters according to plant/experimental needs. Here, use 14 hours light and\
    \ 10 hours dark for illumination. During\nplant establishment and before stress\
    \ treatments started, set the temperature to 20° C during day and 15° C during\
    \ night and keep relative\nhumidity at 50 ± 8%.\n3.\nPut the rhizoboxes at an\
    \ inclination of 45° using an adequate metal framework. This maximizes root growth\
    \ towards the glass surface due to\ngravitropism.\n4.\nCover the glass window\
    \ by a wooden plate to keep the root zone in dark and avoid algae growth due to\
    \ light penetrating through the glass\nsurface.\n3. Sugar beet example setup and\
    \ treatments\n1.\nPre-germinate sugar beet seeds on wet filter paper for three\
    \ days at 20 °C in an incubator until the radicle emerges. This ensures seeding\n\
    with viable plants.\n \nNOTE: Pre-germination is not required for plants with\
    \ high germination vigor, thereby avoiding the risk of damaging the radicle at\
    \ seeding.\nFor sugar beet seeds with a thick pericarp, however the risk of non-viable\
    \ seeds is high and pre-germination significantly accelerates the\nemergence of\
    \ the radicle compared to direct seeding into soil.\n2.\nDrill a small hole to\
    \ about 1.5 cm soil depth in the middle of the rhizobox with a screwdriver, position\
    \ one seed in it using tweezers with the\nradicle oriented downwards and next\
    \ to the glass window (this improves the initial visibility) and gently cover\
    \ it with soil.\n3.\nAdd a 0.5 cm layer of fine gravel (2-4 mm) on top of soil\
    \ to protect the soil aggregates from slaking during irrigation and reduce evaporation\n\
    losses. To facilitate emergence, keep the soil surface free of gravel where the\
    \ seed has been positioned.\n4.\nAdd 10 g of water to enhance establishment.\n\
    5.\nDuring establishment and early growth until experimental stress treatments\
    \ start, irrigate the rhizoboxes every 2-4 days to keep the initial\nmoisture\
    \ content of 80% PAW.\n1.\nDetermine the amount of irrigation water required by\
    \ weighing the rhizoboxes and adding water until achieving the initial weight\
    \ of each\nindividual box. For manual irrigation use a pipette to avoid surface\
    \ structure degradation during watering.\n6.\nArrange the rhizoboxes according\
    \ to the established design in the climate room. The protocol reported here is\
    \ based on an experiment with\nsix sugar beet cultivars in five replicates in\
    \ a completely randomized design (CRD).\nJournal of Visualized Experiments\nwww.jove.com\n\
    Copyright © 2017  Creative Commons Attribution-NonCommercial-NoDerivs 3.0 Unported\n\
    License\nAugust 2017 |  126  | e56251 | Page 6 of 21\n1.\nReposition rhizoboxes\
    \ each time when taking them out of the metal holder for weighing and watering.\
    \ This avoids any effects of\nresidual (light) inhomogeneity inside the climate\
    \ room.\n7.\nDefine the time for onset of stress treatments and the type of stress.\
    \ The following settings (Figure 4) are used here.\n1.\nStart measurements at\
    \ BBCH 15 (five leaves unfolded) with roots covering around 75% of the rhizobox\
    \ depth and the canopy being\nsufficiently developed for measurements at the leaves.\
    \ Keep each stage for at least three days to ensure adaptation to the new settings\n\
    and make measurement.\n2.\nFor the non-stress observations keep the initial settings\
    \ with optimum soil moisture (80% PAW) and ambient conditions (20° C/15° C\ntemperature,\
    \ 50 ± 8% rH) giving a daytime vapor pressure deficit (VPD) of 1.28 ± 0.1 kPa\
    \ (cf. Figure 3 C).\n3.\nRaise the atmospheric demand to a daytime VPD of 2.45\
    \ ± 0.4 kPa by increasing the temperature to 27°C/20°C and decreasing rH to\n\
    35%, while keeping soil moisture at 80% PAW.\n4.\nSubsequently dry down the rhizoboxes\
    \ to 40% PAW equivalent to a water content of 0.215 cm3 cm-3 by withholding irrigation.\
    \ Reset the\ninitial ambient conditions with low atmospheric demand (VPD of 1.28\
    \ kPa).\n5.\nCombine stresses increasing the atmospheric demand to a VPD of 2.45\
    \ kPa and keep soil moisture at 40% PAW.\n4. Root imaging methods\n1.\nCombine\
    \ imaging methods to make use of their respective advantages and depending on\
    \ the information targeted.\n1.\nApply RGB imaging in the VIS range to track root\
    \ growth, architecture and morphology over time which implicitly requires frequent\n\
    measurement. Advantages of RGB imaging are (i) low costs, (ii) rapid image acquisition,\
    \ (iii) low requirements of hard-disk space\n(image size: 48 MB) and (iv) high\
    \ resolution (3648 x 5472 pixels).\n2.\nUse hyperspectral imaging (HSI) in the\
    \ NIR range when chemometric features of root and soil are required. Advantages\
    \ are (i) spectral\nfeatures for segmentation between roots and soil background\
    \ and (ii) access to physico-chemical system properties (e.g. soil water\ncontent,\
    \ root age). Disadvantages are (i) higher scanning time (about 16 minutes per\
    \ rhizobox), (ii) large size of datasets (13.7 GB per\nrhizobox image) and (iii)\
    \ lower resolution of the NIR camera (320 x 256 Pixel), and (iv) higher complexity\
    \ of data analysis.\n2.\nRGB root imaging\n1.\nUse an imaging box (Figure 4) that\
    \ shields from ambient light and fixes the camera position consisting of a metal\
    \ frame with a width of\n1 m and a height of 1 m with side walls lined with pressboards.\
    \ At the front end, fix the camera at two positions at a distance of 80 cm\nfrom\
    \ the rhizobox.\n1.\nAttach a tapeline on the rhizobox frame with transparent\
    \ adhesive tape and position the rhizobox in the holder of the imaging\nbox.\n\
    2.\nIlluminate the rhizobox using four 24 W fluorescent light tubes attached at\
    \ a distance of 80 cm from the rhizobox. Also, mount\nfour 15 W UV tubes at 20\
    \ cm from the rhizobox as alternative illumination making use of root auto-fluorescence\
    \ in case of low\ncontrast between root and (bright colored) substrate background.\n\
    3.\nTake two images (top and bottom position) to cover the upper and the lower\
    \ half of a rhizobox with an overlap of about 3 cm.\n2.\nAcquire RGB images with\
    \ a digital single-lens reflex camera which is fixed by quick release plates on\
    \ the respective positions of the\nimaging box.\n1.\nApply the following settings\
    \ when using the fluorescent light tubes. Adapt these example settings for any\
    \ changes in dimensions\nand illumination as well as the camera model.\n1.\nTurn\
    \ off autofocus and stabilizer on the camera objective. Set camera to manual mode.\n\
    2.\nSet ISO speed to 500. Set shutter speed to 13. Set Aperture to 5.6.\n3.\n\
    Turn off the mirror lock. Set the white balance to Auto White Balance.\n2.\nUse\
    \ the following settings for illumination with UV tubes:\n1.\nTurn off autofocus\
    \ and stabilizer on the camera objective. Set camera in manual mode.\n2.\nSet\
    \ ISO speed to 1000. Set shutter speed to 13. Set Aperture to 5.6.\n3.\nTurn off\
    \ the mirror lock. Set the white balance to Fluorescence.\n3.\nMerge the RGB images\
    \ from top and bottom of the rhizobox into a single image a photo editor (e.g.,\
    \ Adobe Photoshop). Use the\ntapeline at the side frame of the rhizoboxes and\
    \ control overlapping objects (root and soil features).\n1.\nCopy the two separate\
    \ images, each with pixels size of 3648 x 5472, into a new file of size 3648 x\
    \ 10944 pixels and white\nbackground.\n2.\nReduce the layer opacity for one image\
    \ to 60% and align overlapping parts of the images (tapeline, objects). Thereafter\
    \ restore\nlayer opacity to 100%.\n3.\nBased on the ruler on the image add two\
    \ red lines of exactly 1 cm to the top of the image where no roots are present.\
    \ These\nlines are later used at image analysis to scale the image to correct\
    \ length dimensions.\n4.\nMerge all layers and remove parts of the image outside\
    \ the soil filled window with the cropping tool.\n5.\nSave the image as tiff-file\
    \ for further analysis.\n6.\nIn case of images with UV illumination, reduce colors\
    \ to greyscale before saving using the toolbar Adjustments-Black & White,\nand\
    \ selecting the predefined High Contrast Blue filter.\n4.\nFor segmentation between\
    \ roots and soil background as well as for quantification of root traits of interest\
    \ (e.g. length, surface,\ndiameter, branching) use any root analysis software\
    \ (see www.plant-image-analysis.org for available tools). Here WinRhizo is used.\n\
    1.\nOpen the rhizobox tiff-image the software.\n2.\nCalibrate the length scale\
    \ of the image using the scaling bars added to the image.\n3.\nSelect Based on\
    \ Color in the Analysis menu where selecting Root & Background Distinction.\n\
    Journal of Visualized Experiments\nwww.jove.com\nCopyright © 2017  Creative Commons\
    \ Attribution-NonCommercial-NoDerivs 3.0 Unported\nLicense\nAugust 2017 |  126\
    \  | e56251 | Page 7 of 21\n4.\nDefine a calibration file with color classes corresponding\
    \ to roots and soil (background). For the example images used here (cf.\nFigure\
    \ 8) three root color classes (old laterals, young laterals, tap root) and three\
    \ soil color classes are defined.\n5.\nFor the greyscale images (UV-illumination)\
    \ select (i) Based on grey levels, and (ii) Pale Root on Black Background in the\
    \ Root &\nBackground Distinction menu and use a local Lagarde intensity threshold\
    \ for segmentation.\n6.\nOpen a data file where results are saved.\n7.\nRun the\
    \ analysis and subsequently control whether there are regions (e.g. at the edges)\
    \ which are mismatched. In this case\ndefine an exclusion region and restart the\
    \ analysis. For roots not classified, add additional color classes and restart\
    \ the analysis.\nFor elements wrongly classified as roots, activate/increase the\
    \ Debris & Rough Edges filtering options.\n \nFigure 4: Imaging box to acquire\
    \ RGB rhizoboxes pictures.\n \nLeft view of front side where rhizoboxes are attached\
    \ for imaging with light sources inside; right view of backside where the camera\
    \ is mounted.\nPlease click here to view a larger version of this figure.\n3.\n\
    Hyperspectral root imaging\n1.\nHardware setup\n1.\nUse a hyperspectral root imaging\
    \ system (Figure 5) consisting of (i) a thermo-electrically cooled 14-bit monochrome\
    \ NIR camera\nwith a spectral range from 900 nm to 1700 nm, 320 by 256 pixels\
    \ and a frame rate of 100Hz and (ii) an imaging spectrograph\nwith a spectral\
    \ range 900 nm to 2500 nm and a spectral resolution of 3.6 nm. Arrange a halogen\
    \ line illumination source (four 50\nW halogen spots) in a 45°/-45° geometry.\
    \ Mount the imaging sensor on a two-axis positioning system. The scan window has\
    \ a\nsize of 240 x 1000 mm, i.e. 30 mm at each edge of the rhizobox are not covered\
    \ by the image.\n2.\nControl the system by a Matlab script for (i) white and dark\
    \ standard acquisition, (ii) setting of camera integration time, (iii)\nselecting\
    \ spatial (pixel size 0.1 mm; pixel size 1.0 mm) and spectral resolution (all\
    \ 222 spectral bands with a resolution of 3.6 nm;\nsmoothed spectrum with 54 bands\
    \ and a resolution of 14.8 nm), and (iv) defining the scan region on the rhizobox.\n\
    3.\nSave images as SIF-files. To avoid problems during saving of large files,\
    \ subdivide each scanned image stride (9 strides per\nrhizobox) into four segments\
    \ (three of 300 mm length, one of 100 mm length) and save separately with a unique\
    \ file name\nconsisting of stride number (1 to 9) and part (1 to 4) as well as\
    \ date and time (YYYY.MM.DD HH:MM:SS). An entire rhizobox\nscan requires a hard-disk\
    \ space of 13.7 GB.\nJournal of Visualized Experiments\nwww.jove.com\nCopyright\
    \ © 2017  Creative Commons Attribution-NonCommercial-NoDerivs 3.0 Unported\nLicense\n\
    August 2017 |  126  | e56251 | Page 8 of 21\n2.\nImage acquisition and analysis.\n\
    \ \nNOTE: Figure 6 shows the steps of image acquisition, segmentation and analysis.\n\
    1.\nImage acquisition comprises selection of camera setting for optimum image\
    \ quality and definition of scan parameters.\n1.\nDetermine the camera integration\
    \ times for the rhizobox scan and the white standard in the camera software.\n\
    1.\nOpen the imaging GUI and move the camera to a position of the rhizobox where\
    \ roots are present.\n2.\nAdjust the integration time of the camera targeting\
    \ a light object (i.e. root) in a way that approximately 85% of the full\ndynamic\
    \ range of the camera is used on the histogram displayed by the software. Repeat\
    \ for the white standard by\nmoving the camera positioning system to target the\
    \ white standard. Then close the camera software.\n2.\nOpen the Matlab Imaging\
    \ GUI and make all settings for the current rhizobox scan. For the data reported\
    \ here, use the\nfollowing settings:\n \nIntegration time white standard: 1000\n\
    \ \nIntegration time rhizobox: 4000\n \nSpectral resolution: Full resolution (i.e.\
    \ 222 narrow-range spectral bands)\n \nFull spatial resolution (pixel size of\
    \ 0.1 mm)\n1.\nAcquire the dark and white standards before each imaging run, e.g.\
    \ once a day. The dark standard represents\nthe camera noise, while the white\
    \ standard gives the maximum reflectivity. These data are required for image\n\
    normalization during pre-processing.\n2.\nDefine whether the entire rhizobox or\
    \ only part of it is scanned. For the present case entire rhizoboxes are imaged.\n\
    Then start the scan.\n2.\nProcess the image with a Matlab script. Operations performed\
    \ by the script are described.\n \nNOTE: Scripts are currently in an undocumented\
    \ version and can be obtained from the corresponding author. After\nproper documentation,\
    \ they will be available for download from the website of the corresponding author's\
    \ institution\n(www.dnw.boku.ac.at/pb/).\n1.\nCompose an entire image stride from\
    \ the rhizobox center (containing roots) merging the four parts of the stride.\n\
    \ \nNOTE: At this stage it is neither necessary nor recommended to use a spectral\
    \ image of an entire rhizobox (i.e. all 9\nstrides) as the file size will make\
    \ each calculation step in Matlab very time consuming and the information contained\
    \ in one\ncentral stride is sufficient for the first steps of image analysis.\n\
    2.\nNormalize the image using the acquired dark and white standards and taking\
    \ into account the different integration times of\nwhite standard and rhizobox\
    \ scans which are saved automatically during scanning in a file.\n3.\nOptionally\
    \ apply a smoothing filter to remove noise from the image. The script currently\
    \ offers 3x3 kernel median filtering\nand multiple scatter correction. For the\
    \ image evaluation presented here, no filters are applied.\n4.\nDisplay the image\
    \ at all recorded spectral bands to obtain a first insight and decide a wavelength\
    \ to be displaying for\nselecting regions of interest (cf. image segmentation).\n\
    3.\nPerform segmentation between roots and soil background in a separate script\
    \ with the following steps.\n1.\nSelect regions of interest (ROI) for root and\
    \ soil to find spectral features for segmentation. Use the freehand selection\
    \ tool\nto mark a ROI on the image displayed at a wavelength previously identified\
    \ with good contrast between roots and soil.\nHere, use three ROIs on the root\
    \ (old and young laterals, tap root) and two ROIs in the soil (dry, wet region).\n\
    2.\nDisplay a rectangle with the selected ROIs and the remaining part as a black\
    \ mask and visualize the selected ROI image\nat all wavelengths.\n3.\nRemove all\
    \ lines in the image matrix containing pixels of spectral intensity = 0 (black\
    \ pixels).\n4.\nFuse the root and soil ROIs into one foreground (root) and one\
    \ background (soil) matrix for segmentation.\n5.\nSearch spectral bands (intensity\
    \ of single spectra or spectral ratios) providing the best separation between\
    \ root foreground\nand soil background27. Quantify the distinction between the\
    \ resulting pixel histograms for root and soil using Bhattacharyya\ndistance28.\n\
    6.\nSelect a threshold intensity value separating the histograms.\n7.\nCreate\
    \ a binary image by applying the selected threshold to the original image. This\
    \ sets all pixels having smaller intensity\nthan the threshold to zero and those\
    \ with higher intensity to one (done automatically be the script).\n8.\nSave the\
    \ binary image as tiff-file.\n4.\nOpen the binary image and analyze root traits.\
    \ Select (i) Based on grey levels, and (ii) Pale Root on Black Background in the\n\
    Root & Background Distinction menu and use global intensity threshold (the image\
    \ is already binarized).\n5.\nFor mapping the water content from the hyperspectral\
    \ data acquire a calibration dataset and apply a calibration equation to a\nrhizobox\
    \ image.\n1.\nSubdivide a rhizobox into 5 cm compartments using polystyrene sheets\
    \ to fill them with soil (same substrate and db as\nused for the experiment) at\
    \ different water contents (Figure 8).\n2.\nCalculate the respective amounts of\
    \ water to be mixed with soil and fill the compartments (same procedure as described\
    \ in\n1.3. for the entire rhizobox).\n3.\nScan the calibration rhizobox with the\
    \ same settings as used for the planted rhizoboxes.\n4.\nPerform the following\
    \ steps using a script.\n1.\nMerge the four parts of a stride from the water calibration\
    \ box to one stride and normalize it with dark and white\nstandards.\n2.\nSelect\
    \ rectangular boxes at each compartment with different water content and save\
    \ them in a structure array.\n3.\nDetermine the spectral feature that best separates\
    \ the water content compartments. This is done with a search\nalgorithm for the\
    \ global maximum of the intensity differences between mean spectra of adjacent\
    \ water contents.\n4.\nCalculate the mean spectral intensity value for this feature\
    \ for each water content compartment of the calibration\nrhizobox.\nJournal of\
    \ Visualized Experiments\nwww.jove.com\nCopyright © 2017  Creative Commons Attribution-NonCommercial-NoDerivs\
    \ 3.0 Unported\nLicense\nAugust 2017 |  126  | e56251 | Page 9 of 21\n5.\nFit\
    \ a regression equation through the directly measured water content and the respective\
    \ spectral quantifier.\n6.\nApply the regression equation to each pixel not classified\
    \ as root on a rhizobox image and for the spectral feature\n(band) determined\
    \ above which best relates to water content.\n \nFigure 5: Hyperspectral root\
    \ scanner.\n \nThe main components of the scanner are indicated. The small picture\
    \ shows the camera during imaging of a rhizobox. Please click here to view\na\
    \ larger version of this figure.\nJournal of Visualized Experiments\nwww.jove.com\n\
    Copyright © 2017  Creative Commons Attribution-NonCommercial-NoDerivs 3.0 Unported\n\
    License\nAugust 2017 |  126  | e56251 | Page 10 of 21\n \nFigure 6: Steps in hyperspectral\
    \ root imaging.\n \nHyperspectral root imaging consists of three mains steps being\
    \ (i) image acquisition, (ii) image segmentation and (iii) analysis of the spectral\n\
    data. Please click here to view a larger version of this figure.\nJournal of Visualized\
    \ Experiments\nwww.jove.com\nCopyright © 2017  Creative Commons Attribution-NonCommercial-NoDerivs\
    \ 3.0 Unported\nLicense\nAugust 2017 |  126  | e56251 | Page 11 of 21\n \nFigure\
    \ 7: Rhizobox for water calibration.\n \nThe rhizobox contains compartments with\
    \ substrate at different water content which are subdivided by polystyrene sheets.\
    \ Germination paper\nat the dry compartments ensures that soil particles do not\
    \ rinse into neighboring compartments. Please click here to view a larger version\
    \ of this\nfigure.\n5. Application examples\nNOTE: Quantitative root information\
    \ is applied in the context of plant phenotyping (cultivar comparison) and for\
    \ plant physiological research. The\nfollowing aboveground data are reported to\
    \ exemplify these cases.\n1.\nLeaf area: Measure leaf area non-destructively at\
    \ selected stages during the experiment via the length and width of leaves as\
    \ a proxy.\nAlternatively canopy images can be used29.\n1.\nAt the end of the\
    \ experiment measure leaf length and width together with area of clipped leaves\
    \ using a leaf area meter. Calibrate the\nnon-destructive method applying a regression\
    \ equation to the data pairs.\n2.\nDry matter: At the end of the experiment, measure\
    \ aboveground dry matter by clipping the plants with scissors and dry them for\
    \ 24 hours at\n105 °C in an oven.\nJournal of Visualized Experiments\nwww.jove.com\n\
    Copyright © 2017  Creative Commons Attribution-NonCommercial-NoDerivs 3.0 Unported\n\
    License\nAugust 2017 |  126  | e56251 | Page 12 of 21\n3.\nStomata conductance:\
    \ Measure stomata conductance with a leaf porometer. Before measurement, keep\
    \ the device for at least one hour in\nthe climate chamber to allow sensors equilibrate\
    \ with ambient conditions and calibrated the device each time when ambient settings\
    \ in the\nclimate chamber are changed. Take measurements from at least three leaves\
    \ per plant.\nRepresentative Results\nExample results are presented for root segmentation\
    \ based on RGB and HS imaging. For spectral imaging an example of high resolution\
    \ water\nmapping is provided. Finally results are shown that demonstrate the scientific\
    \ context where image based root data are applied.\nRGB based root measurement\n\
    Figure 8 shows an RGB root image time series of sugar beet cultivar Ferrara. The\
    \ images reveal some artefacts from inhomogeneous\nillumination of the rhizoboxes,\
    \ with brighter areas along the left side and different brightness at the overlapping\
    \ area between top and bottom\nimages.\n \nFigure 8: Root growth time series from\
    \ the RGB imaging.\n \nPictures show the sugar beet cultivar Ferrara at different\
    \ days after sowing (DAS). The images show some artefacts due to non-homogeneous\n\
    illumination at the left side of the image and between top and bottom images.\
    \ Scale bars, 2 cm. Please click here to view a larger version of this\nfigure.\n\
    Figure 9 provides details on root segmentation based on color thresholding for\
    \ cultivar Ferrara at day after sowing (DAS) 35. As a reference\n(Figure 9A),\
    \ a binary image is used where all roots were manually tracked with a Graphic\
    \ Tablet. The time required for manual tracking of the\nentire, fully developed,\
    \ dense sugar beet root system was around four hours. Figure 9B gives a detailed\
    \ view on a selected area at the top of\nthe image where old lateral roots are\
    \ present. Here several root axes are not classified by the color threshold. At\
    \ the bottom (Figure 9C) on the\ncontrary, where white young roots are predominant,\
    \ the color based segmentation properly classifies all root axes. The binarized\
    \ root system\n(Figure 9D) shows a black area at the left side from the illumination\
    \ artefact which was defined as exclusion region before running quantitative\n\
    analysis. Figure 9E shows the corresponding pixel histograms of selected features\
    \ (roots vs. soil) for the red channel of the RGB image from\nFerrara at DAS 35.\
    \ The root pixels (blue color) clearly show three peaks corresponding to bright\
    \ young laterals, dark old laterals and tap root.\nThe overlap between the old\
    \ laterals and the soil background is very strong, leading to unclassified root\
    \ axes (cf. Figure 9B).\nJournal of Visualized Experiments\nwww.jove.com\nCopyright\
    \ © 2017  Creative Commons Attribution-NonCommercial-NoDerivs 3.0 Unported\nLicense\n\
    August 2017 |  126  | e56251 | Page 13 of 21\n \nFigure 9: Root segmentation using\
    \ a color threshold.\n \n(A) Manually segmented root system using a Graphic Tablet,\
    \ (B) area with poorly segmented old root axes in the top and (C) properly\nsegmented\
    \ young axes in the bottom of the image, and (D) binary image obtained from color\
    \ based thresholding. (E) Pixel histograms for\nselected features of the RGB image.\
    \ Roots are represented by the blue bars with different root types indicated;\
    \ soil is represented by the red\nbars. Scale bars in A and D, 2 cm; scale bars\
    \ in B and C, 1 cm. Please click here to view a larger version of this figure.\n\
    The resulting total visible root length quantified for the manually segmented\
    \ reference image is 1534.1 cm, while the automatized, color based\nsegmentation\
    \ gives a total root length of 1427.6 cm.\nGreyscale images from UV-illumination\
    \ do not provide an advantage in the case shown here and performed worse compared\
    \ to color\nthresholding (root length: 1679.7 cm). Old roots could not be segmented,\
    \ and there was more noise in the image, probably due to lower light\nintensity\
    \ of the UV lamps. However, in case of young roots with high auto-fluorescence\
    \ and a bright background substrate, UV-illumination can\nstill be an option as\
    \ shown by an image obtained from another experiment where sand was used as background\
    \ substrate (Figure 10).\nJournal of Visualized Experiments\nwww.jove.com\nCopyright\
    \ © 2017  Creative Commons Attribution-NonCommercial-NoDerivs 3.0 Unported\nLicense\n\
    August 2017 |  126  | e56251 | Page 14 of 21\n \nFigure 10: UV illumination to\
    \ visualize roots on bright background.\n \nExample from a durum wheat root system\
    \ growing in a rhizobox filled with quartz sand. The rhizobox is imaged with illumination\
    \ for (A) UV light\nand (B) fluorescent (day) light. Scale bars, 2 cm. Please\
    \ click here to view a larger version of this figure.\nHSI based root measurements\n\
    Figure 11 provides the mean spectra for three root ROIs (old and young lateral,\
    \ tap root) and two soil ROIs (top and bottom of rhizobox).\n \nFigure 11: Mean\
    \ spectra of root and soil.\n \nSpectra from regions of interest (ROIs) on the\
    \ root (three root types) and in the soil (top and bottom of the rhizobox). The\
    \ ROIs are selected to\ndetermine an optimum segmentation criterion between root\
    \ and soil. Please click here to view a larger version of this figure.\nJournal\
    \ of Visualized Experiments\nwww.jove.com\nCopyright © 2017  Creative Commons\
    \ Attribution-NonCommercial-NoDerivs 3.0 Unported\nLicense\nAugust 2017 |  126\
    \  | e56251 | Page 15 of 21\nIt is evident that the tap and young lateral roots\
    \ differ substantially from the background in intensity of most spectral bands.\
    \ For the old laterals\nthe intensity differences are much lower. A feature that\
    \ can be inferred visually is the different slope of the spectrum around water\
    \ absorption\nregion (1450 nm). Here the slope of root spectra is higher compared\
    \ to soil spectra. Furthermore a change of tap and young lateral spectra in the\n\
    region around 1100 nm can be identified that does not occur in the old laterals.\n\
    Figure 12A shows the result from the search algorithm identifying a spectral ratio\
    \ with strongest foreground-background contrast. The ratio\nof spectra at 1476\
    \ nm to 1076 nm provides the best separation between roots and soil. The resulting\
    \ histogram of root foreground and soil\nbackground pixels is shown in Figure\
    \ 12B. Although there is some overlap, most pixels are clearly separated from\
    \ the soil background. Fitting a\nbimodal Gaussian curve through the histogram\
    \ and using Bhattacharyya distance for quantification, a value of 7.80 is obtained.\
    \ A value higher\n3.0 indicates strong image contrast allowing reliable separation28.\n\
    \ \nFigure 12: Difference in reflectance between root foreground and soil background\
    \ for different spectral band ratios and pixel\nhistogram at spectral ratio used\
    \ for segmentation.\n \n(A) Bright colors (yellow) show high contrast between\
    \ foreground and background, dark colors (blue) show low contrast. The first 15\
    \ bands have\nbeen removed because of noise. The red lines indicate the band ratio\
    \ with highest contrast. (B) Pixel histogram of roots (blue) and soil (red) at\n\
    segmentation spectral ratio. Blue bars represent the root and red bars the soil.\
    \ The intensity value corresponds to the ratio of spectral band 160\nto spectral\
    \ band 49. Please click here to view a larger version of this figure.\nJournal\
    \ of Visualized Experiments\nwww.jove.com\nCopyright © 2017  Creative Commons\
    \ Attribution-NonCommercial-NoDerivs 3.0 Unported\nLicense\nAugust 2017 |  126\
    \  | e56251 | Page 16 of 21\nThe binary image (Figure 13) is created by applying\
    \ a global intensity threshold of the identified spectral ratio at a value of\
    \ 1.008 calculated from\nthe histogram distance27. Analysis of root length of\
    \ this image gives a total length of 1557.3 cm which represents an error of only\
    \ 1.5% compared\nto the manually tracked reference image.\n \nFigure 13: Binary\
    \ image of the root system of sugar beet cultivar Ferrara.\n \nThe image is obtained\
    \ by applying a global spectral threshold. Scale bar (bottom left corner), 2 cm.\
    \ Please click here to view a larger version of\nthis figure.\nAlthough root segmentation\
    \ has improved using spectral information compared to color based information,\
    \ the main intention of HS imaging is\nanalysis of chemometric image properties.\
    \ This is exemplified via mapping the water content of a rhizobox image.\nFigure\
    \ 14A shows the mean spectra of the compartments in the calibration rhizobox (cf.\
    \ Figure 7) filled with soil of different water content.\nThe shape of spectra\
    \ is similar between the compartments, i.e. here a spectral ratio does not necessarily\
    \ provide a more stable classification\ncriterion. Thus intensity at a single\
    \ spectral band (1680 nm), where the average difference between adjacent water\
    \ contents is maximized, is\nidentified as best separating criterion. The resulting\
    \ pixel histograms for this spectral wavelength are shown in Figure 14B.\nJournal\
    \ of Visualized Experiments\nwww.jove.com\nCopyright © 2017  Creative Commons\
    \ Attribution-NonCommercial-NoDerivs 3.0 Unported\nLicense\nAugust 2017 |  126\
    \  | e56251 | Page 17 of 21\n \nFigure 14: Spectral features for water content\
    \ calibration.\n \n(A) Mean spectra of nine water compartments from the calibration\
    \ rhizobox with different water contents; (B) Pixel histograms for the water\n\
    compartments at band 216 where average distance between neighboring compartment\
    \ is maximum. Please click here to view a larger version of\nthis figure.\nThe\
    \ relation of the average pixel intensity at 1680 nm and the measured water content\
    \ is shown in Figure 15.\n \nFigure 15: Relation of spectral reflectance and volumetric\
    \ water content.\n \nThe figure shows data pairs of measured water content and\
    \ spectral reflectance with empirical curves (linear and exponential) fit to the\
    \ data\nexcluding the highest water contents (red triangles). Please click here\
    \ to view a larger version of this figure.\nDifferentiation of higher water contents\
    \ from spectral intensity becomes difficult. A significant regression (either\
    \ linear or exponential) with high\nR2 can be fit to water contents up to around\
    \ 0.30 cm3 cm-3. Wetter soil conditions cannot be reliably predicted by the intensity\
    \ value. Similar\nbehavior of an exponential relation between reflectivity and\
    \ water content with a decreasing response to water contents higher 0.30 cm3 cm-3\n\
    was also found in other studies30.\nA rhizobox image with fine mapping of water\
    \ content is shown in Figure 16. Four aspects have to be remarked. First, a region\
    \ of lower water\ncontent can be seen in the rooted parts of the rhizobox. Second,\
    \ strongest depletion is concentrated in the vicinity to single root axes. Third,\n\
    depletion zones also occur where no root axes are visible on the surface, indicating\
    \ regions where roots are hidden in soil. Fourth, water\nmapping without further\
    \ image-processing results in a patchy appearance due to the aggregated soil.\
    \ This can indicate inhomogeneous water\ncontent distribution at the aggregate\
    \ scale, but also surface morphology effect on image quality. Chemometric image-processing\
    \ techniques are\nan option to overcome such morphological effects in spectral\
    \ images31, but are not implemented so far in the Matlab scripts used here.\n\
    Journal of Visualized Experiments\nwww.jove.com\nCopyright © 2017  Creative Commons\
    \ Attribution-NonCommercial-NoDerivs 3.0 Unported\nLicense\nAugust 2017 |  126\
    \  | e56251 | Page 18 of 21\n \nFigure 16: Water content mapping on a rhizobox.\n\
    \ \nThe dark blue colours represent regions of high water content, green to red\
    \ areas show regions with low water content. The plant root is overlaid\non the\
    \ image in black. Scale bar (bottom left corner), 2 cm. Please click here to view\
    \ a larger version of this figure.\nApplication examples\nFigure 17 relates quantitative\
    \ root traits from image analysis with aboveground measurements.\nJournal of Visualized\
    \ Experiments\nwww.jove.com\nCopyright © 2017  Creative Commons Attribution-NonCommercial-NoDerivs\
    \ 3.0 Unported\nLicense\nAugust 2017 |  126  | e56251 | Page 19 of 21\n \nFigure\
    \ 17: Typical application examples for root data.\n \n(A) and (B) show root information\
    \ used for aboveground-belowground plant characterization in a phenotyping context.\
    \ (A) represents root growth\nfrom the sugar beet cultivar Ferrara, (B) compares\
    \ six rhizobox grown sugar beet cultivars using leaf-to-root area ratio (data\
    \ from one replicate).\n(C) and (D) are functional relations between traits as\
    \ found in plant physiological research. (C) shows the influence of leaf-to-root\
    \ area ratio on\ndry matter production and (D) the relation of root surface area\
    \ to stomata conductance. Please click here to view a larger version of this figure.\n\
    Figure 17A and 17B are relevant for phenotyping focusing on comprehensive aboveground\
    \ and belowground plant characterization. Figure 17A\nshows root growth of sugar\
    \ beet cultivar Ferrara (cf. Figure 8 for images). Expansion of the root system\
    \ indicates the capacity of a cultivar to\nexplore the soil volume in a given\
    \ time span of the vegetation period. Figure 17B shows leaf-to-root surface area\
    \ ratio of six sugar beet cultivars,\nproviding a descriptor for the balance between\
    \ plant supply (root) and demand (leaf).\nFigures 17C and 17D give examples for\
    \ functional relations of interest in physiological research. In Figure 17C leaf-to-root\
    \ surface area ratio is\nrelated to dry matter formed during the experiment, indicating\
    \ the predominant role of the assimilating surface as a limiting factor for dry\
    \ matter\naccumulation. The lack of significance in spite of a comparatively high\
    \ R2 is related to the low number of paired data (n=6) used here. Figure\n17D\
    \ reveals that cultivars with higher root surface area (improved uptake) have\
    \ an average higher stomata conductance over the course of the\nexperiment. The\
    \ higher root area apparently sustains water extraction, thereby prolonging stomata\
    \ opening.\nDiscussion\nThe protocols provide two complementary approaches for\
    \ soil grown root system imaging. A critical step for reliable experimental results\
    \ is\nfilling of the rhizoboxes that has to ensure an even and homogeneous substrate\
    \ layer at the front glass to provide tight root-soil contact at the\nobservation\
    \ window and avoid air gaps. This is the main reason to use comparatively fine\
    \ sieved soil of < 2 mm: Larger aggregates result in\nhigher surface morphology\
    \ at the observation window with voids between aggregates. Besides a higher risk\
    \ of root tip dehydration, this also\nrequires more complex image processing techniques\
    \ for water mapping31.\nModifications of the protocol therefore focus on improved\
    \ and quick filling of rhizoboxes. Currently filling time is about 30 minutes\
    \ per box.\nFurthermore use of rhizoboxes with two glass windows for imaging from\
    \ both sides and modifications to optimize illumination homogeneity for\nbetter\
    \ RGB images are tested. Further hardware extension might also consider integration\
    \ of planar optodes32 as well as capacitance imaging33\ninto the rhizobox system.\
    \ This however is beyond current upgrading activities.\nSoftware modifications\
    \ focus on automatic image registration to fuse the top and bottom RBG images34.\
    \ For hyperspectral imaging advanced\nunsupervised feature extraction approaches28\
    \ as well as more sensitive supervised target detection methods such as SVMs35\
    \ are tested.\nThereby the hyperspectral data potentially allow for the assessment\
    \ of multiple soil, rhizosphere and root properties36. Furthermore it is\nintended\
    \ to develop a (semi)automatized software for rhizobox root images based on a\
    \ modified version of Root System Analyzer37 to quantify\nmorphological (length,\
    \ diameter, surface) as well as architectural traits (branching frequency, branching\
    \ angles).\nThe main limitation of the protocol compared to 3D imaging approaches\
    \ is the restriction to the surface visible root and rhizosphere properties.\n\
    However it has been demonstrated that the visible root traits are a reliable proxy\
    \ for the whole root system21. The rhizobox technique is easily\ncombined with\
    \ traditional destructive sampling (washing) at the end of dynamic growth imaging\
    \ in order to validate the relation of visible vs. total\nroot system traits.\
    \ As this relation might vary among species21, destructive sampling is recommended\
    \ to ensure reliable inference from visible\ntraits for any new phenotyping series\
    \ with a different crop species.\nJournal of Visualized Experiments\nwww.jove.com\n\
    Copyright © 2017  Creative Commons Attribution-NonCommercial-NoDerivs 3.0 Unported\n\
    License\nAugust 2017 |  126  | e56251 | Page 20 of 21\nThe key advantage of the\
    \ protocol presented here is the combination of realistic growing conditions (soil),\
    \ relatively high potential throughput for\nthe temporally resolved RGB imaging\
    \ and inference on root functionality (e.g. water uptake) via the chemometric\
    \ root and rhizosphere data from\nhyperspectral imaging. Thereby the methods overcomes\
    \ inference restrictions in high throughput seedling and non-soil root imaging\
    \ methods14,\nwhile it partially allows deep phenotyping insights into functional\
    \ processes with less experimental complexity and higher throughput compared to\n\
    advanced 3D methods15.\nIn upcoming experiments the protocol will be used to study\
    \ the effect of mycorrhiza on root system development and functionality of legumes\
    \ as\nwell as for phenotyping root characteristics of cover crop species in relation\
    \ to soil structure, nitrogen and carbon cycling.\nDisclosures\nThe authors have\
    \ nothing to disclose.\nAcknowledgements\nThe authors acknowledge funding from\
    \ the Austrian Science Fund FWF via the Project Number P 25190-B16 (The roots\
    \ of drought resistance).\nEstablishment of the hyperspectral imaging infrastructure\
    \ was supported financially by the Federal Government of Lower Austria (Land\n\
    Niederösterreich) via the project K3-F-282/001-2012. Additional funding for the\
    \ sugar beet experiment was received from AGRANA Research\n& Innovation Center\
    \ GmbH (ARIC). The authors thank Craig Jackson for technical support during the\
    \ experiment and English correction of\nthe manuscript. We also acknowledge Markus\
    \ Freudhofmaier who contributed to establishment the RGB imaging setup and Josef\
    \ Schodl for\nconstruction of the rhizobox mounting.\nReferences\n1.\nKutschera,\
    \ L. Wurzelatlas mitteleuropäischer Ackerunkräuter und Kulturpflanzen. DLG-Verlags-GmbH,\
    \ Frankfurt am Main (1960).\n2.\nKenrick, P., & Strullu-Derrien, C. The origin\
    \ and early evolution of roots. Plant Physiol. 166, 570-580 (2014).\n3.\nFranklin,\
    \ J., Serra-Diaz, J.M., Syphard, A.D., & Regan, H.M. Global change and terrestrial\
    \ plant community dynamics. PNAS. 113, 3725-3734\n(2016).\n4.\nMacDonald, G.K.,\
    \ Bennett, E.M., Potter, P.A., & Ramankutty, N. Agronomic phosphorus imbalances\
    \ across the world's croplands. PNAS. 108,\n3086-3091 (2011).\n5.\nVörösmarty,\
    \ C.J., Green, P., Salisbury, J., & Lammers, R.B. Global water resources: vulnerability\
    \ from climate change and population growth.\nScience. 289, 284 (2000).\n6.\n\
    Lobell, D.B., Cassman, K.G., & Field, C.B. Crop yield gaps: their importance,\
    \ magnitudes, and causes. Annu. Rev. Environ. Resour. 34,\n179-204 (2009).\n7.\n\
    Angus, J.F., & Van Herwaarden, A.F. Increasing water use and water use efficiency\
    \ in dryland wheat. Agron. J. 93, 290-298 (2001).\n8.\nLassaletta, L., Billen,\
    \ G., Grizzetti, B., Anglade, J., & Garnier, J. 50 year trends in nitrogen use\
    \ efficiency of world cropping systems: the\nrelationship between yield and nitrogen\
    \ input to cropland. Environ. Res. Lett. 9(10), 105011 (2014).\n9.\nLynch, J.P.\
    \ Roots of the second green revolution. Aust. J Bot. 55, 493-512 (2007).\n10.\
    \ Comas, L.H., Becker, S.R., Von Mark, V.C., Byrne, P.F., & Dierig, D.A. Root\
    \ traits contributing to plant productivity under drought. Front. Plant\nSci.\
    \ 4, 442 (2013).\n11. Metcalfe, D.B. et al. A method for extracting plant roots\
    \ from soil which facilitates rapid sample processing without compromising\nmeasurement\
    \ accuracy. New Phytol. 174, 697-703 (2007).\n12. Kutschera, L., Lichtenegger,\
    \ E., & Sobotik, M. Wurzelatlas der Kulturpflanzen gemäßigter Gebiete mit Arten\
    \ des Feldgemüsebaues. DLG-\nVerlag, Frankfurt am Main (2009).\n13. Gioia, T.\
    \ et al. GrowScreen-PaGe, a non-invasive, high-throughput phenotyping system based\
    \ on germination paper to quantify crop\nphenotypic diversity and plasticity of\
    \ root traits under varying nutrient supply. Funct. Plant Biol. 44, 76-93 (2017).\n\
    14. Watt, M. et al. A rapid, controlled-environment seedling root screen for wheat\
    \ correlates well with rooting depths at vegetative, but not\nreproductive, stages\
    \ at two field sites. Ann. Bot. 112, 447-455 (2013).\n15. Fiorani, F., & Schurr,\
    \ U. Future scenarios for plant phenotyping. Annu. Rev Plant Biol. 64, 267-291\
    \ (2013).\n16. Metzner, R. et al. Direct comparison of MRI and X-ray CT technologies\
    \ for 3D imaging of root systems in soil: potential and challenges for\nroot trait\
    \ quantification. Plant Methods. 11, 1 (2015).\n17. Choat, B., Badel, E., Burlett,\
    \ R., Delzon, S., Cochard, H., & Jansen, S. Non-invasive measurement of vulnerability\
    \ to drought induced\nembolism by X-ray microtomography. Plant Physiol.  170,\
    \ 273-282 (2015).\n18. Metzner, R. et al. Direct comparison of MRI and X-ray CT\
    \ technologies for 3D imaging of root systems in soil: potential and challenges\
    \ for\nroot trait quantification. Plant Methods. 11, 1 (2015).\n19. Le Marié,\
    \ C., Kirchgessner, N., Marschall, D., Walter, A., & Hund, A. Rhizoslides: paper-based\
    \ growth system for non-destructive, high\nthroughput phenotyping of root development\
    \ by means of image analysis. Plant Methods. 10, 1 (2014).\n20. Bengough, A.G.\
    \ et al. Gel observation chamber for rapid screening of root traits in cereal\
    \ seedlings. Plant Soil . 262, 63-70 (2004).\n21. Nagel, K.A. et al. GROWSCREEN-Rhizo\
    \ is a novel phenotyping robot enabling simultaneous measurements of root and\
    \ shoot growth for\nplants grown in soil-filled rhizotrons. Funct. Plant Biol.\
    \ 39, 891-904 (2012).\n22. Price, A.H. et al. Upland rice grown in soil-filled\
    \ chambers and exposed to contrasting water-deficit regimes: I. Root distribution,\
    \ water use\nand plant water status. Field Crops Res. 76, 11-24 (2002).\n23. Vadez,\
    \ V. Root hydraulics: the forgotten side of roots in drought adaptation. Field\
    \ Crops Res. 165, 15-24 (2014).\n24. Dane, J.H., & Hopmans, J.W. Pressure plate\
    \ extractor. In Dane, J.H., Topp, G.C. (Eds) Methods of soil analysis. Part 4.\
    \ Physical methods.\nSSSA Inc., Madison, Wisconsin, USA, 688-690 (2002).\n25.\
    \ Wösten, J.H.M., Pachepsky, Y.A., & Rawls, W.J. Pedotransfer functions: bridging\
    \ the gap between available basic soil data and missing soil\nhydraulic characteristics.\
    \ J. Hydrol. 251, 123-150 (2001).\nJournal of Visualized Experiments\nwww.jove.com\n\
    Copyright © 2017  Creative Commons Attribution-NonCommercial-NoDerivs 3.0 Unported\n\
    License\nAugust 2017 |  126  | e56251 | Page 21 of 21\n26. Passioura, J.B. The\
    \ perils of pot experiments. Funct. Plant Biol. 33, 1075-1079 (2006).\n27. Dorrepaal,\
    \ R., Malegori, C., & Gowen, A. Tutorial: Time series hyperspectral image analysis.\
    \ J. Near Infrared Spec. 24, 89-107 (2016).\n28. Kim, D.M. et al. Highly sensitive\
    \ image-derived indices of water-stressed plants using hyperspectral imaging in\
    \ SWIR and histogram analysis.\nScie rep. 5, (2015).\n29. Humplík, J.F., Lazár,\
    \ D., Husičková, A., & Spíchal, L. Automated phenotyping of plant shoots using\
    \ imaging methods for analysis of plant\nstress responses-a review. Plant Methods.\
    \ 11, 29 (2015).\n30. Lobell, D.B., & Asner, G.P. Moisture effects on soil reflectance.\
    \ Soil Sci. Soc. Am. J. 66, 722-727 (2002).\n31. Esquerre, C., Gowen, A.A., Burger,\
    \ J., Downey, G., & O'Donnell, C.P. Suppressing sample morphology effects in near\
    \ infrared spectral\nimaging using chemometric data pre-treatments. Chemometr.\
    \ Intell. Lab. 117, 129-137 (2012).\n32. Williams, P.N., et al. Localized flux\
    \ maxima of arsenic, lead, and iron around root apices in flooded lowland rice.\
    \ Environ Sci. Technol. 48,\n8498-8506 (2014).\n33. Cseresnyés, I., Takács, T.,\
    \ Végh, K.R., Anton, A., & Rajkai, K. Electrical impedance and capacitance method:\
    \ a new approach for detection of\nfunctional aspects of arbuscular mycorrhizal\
    \ colonization in maize. Eur. J Soil Biol. 54, 25-31 (2013).\n34. Brown, M., &\
    \ Lowe, D.G. Automatic panoramic image stitching using invariant features. Int.\
    \ J. Comput. Vision. 74, 59-73 (2007).\n35. Jiang, Y., Li. C., & Takeda, F. Nondestructive\
    \ detection and quantification of blueberry bruising using near-infrared (NIR)\
    \ hyperspectral\nreflectance imaging. Scientific Reports. 6, 35679 (2016).\n36.\
    \ Chang, C.-W., Laird, D.A., Mausbach, M.J., & Hurburgh, C.R. Near-infrared reflectance\
    \ spectroscopy-principal components regression\nanalyses of soil properties. Soil\
    \ Sci. Soc. Am. J. 65, 480-490 (2001).\n37. Leitner, D., Felderer, B., Vontobel,\
    \ P., & Schnepf, A. Recovering root system traits using image analysis exemplified\
    \ by two-dimensional\nneutron radiography images of lupine. Plant Physiol. 164\
    \ (1), 24-35. (2014).\n"
  inline_citation: '>'
  journal: Journal of visualized experiments
  limitations: '>'
  pdf_link: https://www.jove.com/pdf/56251/rgb-spectral-root-imaging-for-plant-phenotyping-physiological
  publication_year: 2017
  relevance_score1: 0
  relevance_score2: 0
  title: 'RGB and Spectral Root Imaging for Plant Phenotyping and Physiological Research:
    Experimental Setup and Imaging Protocols'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1016/j.ifacol.2018.08.052
  analysis: '>'
  authors:
  - Kuo-Chih Tung
  - Chao-Yin Tsai
  - Hey-Chi Hsu
  - Yung-Huei Chang
  - Chau-Shang Chang
  - Suming Chen
  citation_count: 8
  full_citation: '>'
  full_text: '>

    Skip to main content Skip to article Journals & Books Search Register Sign in
    Brought to you by: University of Nebraska-Lincoln View PDF Download full issue
    Outline Abstract Keywords References Cited by (9) IFAC-PapersOnLine Volume 51,
    Issue 17, 2018, Pages 5-9 Evaluation of Water Potentials of Leafy Vegetables Using
    Hyperspectral Imaging Author links open overlay panel Kuo-Chih Tung, Chao-Yin
    Tsai, Han-Chun Hsu, Yung-Huei Chang, Cheng-Hou Chang, Suming Chen Show more Add
    to Mendeley Share Cite https://doi.org/10.1016/j.ifacol.2018.08.052 Get rights
    and content Abstract To effectively and precisely manage crop production is important
    to meet increasing demands of high quality and safe agricultural products. In
    this study, evaluation of water stress in terms of water potentials of leafy vegetables
    using hyperspectral imaging technology was conducted for the future development
    of an agri-robotic system in greenhouses. The leafy vegetable Fengjing Pakchoi
    was cultivated under water stress treatments in a phytotron; both water potential
    and hyperspectral images were measured. The Modified Partial Least Squares Regression
    (MPLSR) with a correlation coefficient of 0.826 was successfully developed to
    determine the water potentials of leaves using hyperspectral imaging. Uneven distribution
    of water potentials on leaves was illustrated and discussed. Water stress which
    reflected irrigation status was visualized and compared by pseudocolor contour
    figures. This study had established a basis for the subsequent development of
    an agri-robotic system for automation and precision irrigation in greenhouses.
    Previous article in issue Next article in issue Keywords Hyperspectral ImagingWater
    StressWater PotentialLeafy VegetablePrecision Irrigation View PDF References Chen
    et al., 2008 Chen C.T., Chen S., Wang C.Y., Yang I.C., Hsiao S.C., Tsai C.Y. Evaluation
    of nitrogen content in cabbage seedlings using hyper-spectral images Sensing and
    Instrumentation for Food Quality and Safety, 2 (2) (2008), pp. 97-102 CrossRefView
    in ScopusGoogle Scholar Chang et al., 1998 Chang W.H., Chen S., Tsai C.C. Development
    of an universal algorithm for use of NIR in estimation of soluble solids in fruits
    juices Transactions of the ASAE, 41 (6) (1998), pp. 1739-1745 View in ScopusGoogle
    Scholar Chen and Li, 2001 Chen, S. and Li, M.T. (2001). Multispectral imaging
    of chlorophyll content for vegetable status monitoring. In: Fruit, Nut and Vegetable
    Production Engineering, Proceedings of the 6th International Symposium held in
    Potsdam 2001, 603-608. Potsdam, Germany, Institute of Agricultural Engineering
    Bornim e. V. (ATB). Google Scholar Chen and et al., 2002 Chen, S., Lin, Y.C. and
    Yang, I.C. (2002). Evaluation of internal quality of papaya using near-infrared
    technology. In “Proceedings of International Symposium on Automation and Mechatronics
    of Agricultural and Bioproduction systems (ISMAB 2002), 388-392. Chiayi, Taiwan
    National Chiayi University. Google Scholar Hsiao et al., 2010 Hsiao S.C., Chen
    S., Yang I.C., Chen C.T., Tsai C.Y., Chuang Y.K., Wang F.J., Chen Y.L., Lin T.S.,
    Lo Y.M. Evaluation of plant seedling water stress using dynamic fluorescence index
    with blue LED-based fluorescence imaging Computers and Electronics in Agriculture,
    72 (2) (2010), pp. 127-133 View PDFView articleView in ScopusGoogle Scholar Hsu
    and et al., 2018 Hsu, H.C., Chen, S., Tsai, C.Y. and Chang, Y.H. (2018). Development
    of Phalaenopsis Flowering Quality Prediction Models. In “Proceedings of the 9th
    International Symposium on Machinery and Mechatronics for Agricultural and Bio-systems
    Engineering (ISMAB 2018), P-SE8. Jeju, Korea, Jeju KAL Hotel. Google Scholar Kacira
    and Ling, 2001 Kacira M., Ling P.P. Design and development of an automated and
    non-contact sensing system for continuous monitoring of plant health and growth
    Transactions of the ASAE, 44 (4) (2001), pp. 989-996 View in ScopusGoogle Scholar
    Kuo, 2009 Kuo, W.R. (2009). Influence of cell size and seedling age on seedling
    quality and plant growth and crops model establish of Pak-Choi. Ph.D. dissertation.
    National Chung-Hsin University, Department of Bio-Industrial Mechatronics Engineering,
    Taichung, Taiwan. Google Scholar Liao et al., 2002 Liao T.S., Weng J.H., Liu R.J.
    Effects of leaf water potential on photosynthesis and seasonal variation in leaf
    water potential of six subalpine plants in tatachia area Quarterly Journal of
    Chinese Forestry, 35 (2) (2002), pp. 163-170 View in ScopusGoogle Scholar Saito
    et al., 1998 Saito Y., Kanoh M., Hatakw K., Kawahara T.D., Nomura A. Investigation
    of laser-induced fluorescence of several natural leaves for application to lidar
    vegetation monitoring Appl. Optics, 37 (3) (1998), pp. 431-437 View in ScopusGoogle
    Scholar Yang and et al., 2006 Yang, I.C., Chen, S., Hsiao, S.C., Chen, C.T., Chen,
    B.Y., Chiou, J.H. and Wang, C.Y. (2006). Water physiological index for plant seedlings
    using hyperspectral images. In “Proceedings of the Third International Symposium
    on Machinery and Mechatronics for Agricultural and Bio-systems Engineering (ISMAB
    2006), 119-124. Seoul, Korea, Korean Society for Agricultural Machinery. Google
    Scholar Yang and et al., 2012 Yang, I.C., Chen, S., Huang, J.S., Pan, P.J., Tsai,
    C.Y. and Chuang, Y.K. (2012). Evaluation of Nitrate Concentration in Leafy Vegetable
    using Spectral Imaging Techniques. In “Proceedings of the 6th International Symposium
    on Machinery and Mechatronics for Agricultural and Bio-systems Engineering (ISMAB
    2012), Paper No. E2-11, Jeonju, Korea, Chonbuk National University. Google Scholar
    Yang et al., 2014 Yang I.C., Hsieh K.W., Tsai C.Y., Huang Y.I., Chen Y.L., Chen
    S. Development of an automation system for greenhouse seedling production management
    using radio-frequency-identification and local remote sensing techniques Engineering
    in Agriculture, Environment and Food, 7 (1) (2014), pp. 52-58 View PDFView articleCrossRefView
    in ScopusGoogle Scholar Zhang et al., 2012 Zhang Q., Li Q., Zhang G. Rapid Determination
    of Leaf Water Content using VIS/NIR Spectroscopy Analysis with Wavelength Selection
    Spectroscopy: An International Journal, 27 (2012), pp. 93-105 CrossRefView in
    ScopusGoogle Scholar Cited by (9) Estimation of plant water content in cut chrysanthemum
    using leaf-based hyperspectral reflectance 2024, Scientia Horticulturae Show abstract
    Comparison of various approaches for estimating leaf water content and stomatal
    conductance in different plant species using hyperspectral data 2022, Ecological
    Indicators Citation Excerpt : However, these vegetation indices were based on
    only a few bands, and a large amount of information contained in hyperspectral
    data was not utilized. For this reason, multivariate analyses has been applied
    frequently in recent years, including partial least squares regression (PLSR)
    (Diago et al., 2014; Rapaport et al., 2015; Tung et al., 2018), support vector
    regression (SVR) (Das et al., 2017; Neinavaz et al., 2017) and artificial neural
    network (ANN) (Neinavaz et al., 2017). The species used in previous respective
    studies were mainly crops (wheat, rice, soybean, and corn) and some fruit trees
    (grapes and apples) under well-timed irrigation. Show abstract Non-destructive
    optical sensing technologies for advancing the egg industry toward Industry 4.0:
    A review 2023, Comprehensive Reviews in Food Science and Food Safety Detection
    of Water Content in Lettuce Canopies Based on Hyperspectral Imaging Technology
    under Outdoor Conditions 2022, Agriculture (Switzerland) NONDESTRUCTIVE QUANTITATIVE
    ANALYSIS OF WATER POTENTIAL OF TOMATO LEAVES USING ONLINE HYPERSPECTRAL IMAGING
    SYSTEM 2022, Applied Engineering in Agriculture Identifying individual nutrient
    deficiencies of grapevine leaves using hyperspectral imaging 2021, Remote Sensing
    View all citing articles on Scopus View Abstract © 2016, IFAC (International Federation
    of Automatic Control) Hosting by Elsevier Ltd. Part of special issue 6th IFAC
    Conference on Bio-Robotics BIOROBOTICS 2018: Beijing, China, 13–15 July 2018 Edited
    by Man Zhang Download full issue Other articles from this issue Development of
    a Navigation System for a Smart Farm 2018 H. Gan, W.S. Lee View PDF Variable Fertilizer
    Recommendation by Image-based Grass Growth Status 2018 S.O. Chung, …, Y.J. Kim
    View PDF Development of a Robot for Harvesting Strawberries 2018 Andreas De Preter,
    …, Josse De Baerdemaeker View PDF View more articles Recommended articles Article
    Metrics Citations Citation Indexes: 9 Captures Readers: 34 View details About
    ScienceDirect Remote access Shopping cart Advertise Contact and support Terms
    and conditions Privacy policy Cookies are used by this site. Cookie settings |
    Your Privacy Choices All content on this site: Copyright © 2024 Elsevier B.V.,
    its licensors, and contributors. All rights are reserved, including those for
    text and data mining, AI training, and similar technologies. For all open access
    content, the Creative Commons licensing terms apply.'
  inline_citation: '>'
  journal: IFAC-PapersOnLine
  limitations: '>'
  pdf_link: null
  publication_year: 2018
  relevance_score1: 0
  relevance_score2: 0
  title: Evaluation of Water Potentials of Leafy Vegetables Using Hyperspectral Imaging
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1117/12.2325500
  analysis: '>'
  authors:
  - Tiebiao Zhao
  - Alexander Koumis
  - Haoyu Niu
  - Dong Wang
  - YangQuan Chen
  citation_count: 20
  full_citation: '>'
  full_text: '>

    This website uses cookies to provide you with a variety of services and to improve
    the usability of our website. By using the website, you agree to the use of cookies
    in accordance with our Privacy Policy. Close Sign In View Cart Help    CONFERENCE
    PROCEEDINGS PAPERS PRESENTATIONS JOURNALS EBOOKS ADVANCED SEARCH > Home > Proceedings
    > Volume 10780 > Article 23 October 2018 Onion irrigation treatment inference
    using a low-cost hyperspectral scanner Tiebiao Zhao, Alexander Koumis, Haoyu Niu,
    Dong Wang, YangQuan Chen Author Affiliations +     Proceedings Volume 10780, Multispectral,
    Hyperspectral, and Ultraspectral Remote Sensing Technology, Techniques and Applications
    VII; 107800D (2018) https://doi.org/10.1117/12.2325500 Event: SPIE Asia-Pacific
    Remote Sensing, 2018, Honolulu, Hawaii, United States ARTICLE FIGURES & TABLES
    REFERENCES CITED BY     Abstract Many studies have shown that hyperspectral measurements
    can help monitor crop health status, such as water stress, nutrition stress, pest
    stress, etc. However, applications of hyperspectral cameras or scanners are still
    very limited in precision agriculture. The resolution of satellite hyperspectral
    images is too low to provide the information in the desired scale. The resolution
    of either field spectrometer or aerial hyperspectral cameras is fairly high, but
    their cost is too high to be afforded by growers. In this study, we are interested
    in if the flow-cost hyperspectral scanner SCIO can serve as a crop monitoring
    tool to provide crop health information for decision support. In an onion test
    site, there were three irrigation levels and four types of soil amendment, randomly
    assigned to 36 plots with three replicates for each treatment combination. Each
    month, three onion plant samples were collected from the test site and fresh weight,
    dry weight, root length, shoot length etc. were measured for each plant. Meanwhile,
    three spectral measurements were made for each leaf of the sample plant using
    both a field spectrometer and a hyperspectral scanner. We applied dimension reduction
    methods to extract low-dimension features. Based on the data set of these features
    and their labels, several classifiers were built to infer the field treatment
    of onions. Tests on validation dataset (25 percent of the total measurements)
    showed that this low-cost hyperspectral scanner is a promising tool for crop water
    stress monitoring, though its performance is worse than the field spectrometer
    Apogee. The traditional field spectrometer yields the best accuracy as high as
    above 80%, whereas the best accuracy of SCIO is around 50%. © (2018) COPYRIGHT
    Society of Photo-Optical Instrumentation Engineers (SPIE). Downloading of the
    abstract is permitted for personal use only. Citation Download Citation Tiebiao
    Zhao, Alexander Koumis, Haoyu Niu, Dong Wang, and YangQuan Chen "Onion irrigation
    treatment inference using a low-cost hyperspectral scanner", Proc. SPIE 10780,
    Multispectral, Hyperspectral, and Ultraspectral Remote Sensing Technology, Techniques
    and Applications VII, 107800D (23 October 2018); https://doi.org/10.1117/12.2325500
    ACCESS THE FULL ARTICLE ORGANIZATIONAL Sign in with credentials provided by your
    organization. Organizational Username Organizational Password INSTITUTIONAL Select
    your institution to access the SPIE Digital Library. SELECT YOUR INSTITUTION PERSONAL
    Sign in with your SPIE account to access your personal subscriptions or to use
    specific features such as save to my library, sign up for alerts, save searches,
    etc. PERSONAL SIGN IN No SPIE Account? Create one PURCHASE THIS CONTENT SUBSCRIBE
    TO DIGITAL LIBRARY 50 downloads per 1-year subscription Members: $195 Non-members:
    $335 ADD TO CART 25 downloads per 1 - year subscription Members: $145 Non-members:
    $250 ADD TO CART PURCHASE SINGLE ARTICLE Includes PDF, HTML & Video, when available
    Members: $17.00 Non-members: $21.00 ADD TO CART PROCEEDINGS 7 PAGES DOWNLOAD PAPER
    SAVE TO MY LIBRARY GET CITATION CITATIONS Cited by 6 scholarly publications. Explore
    citations on Lens.org Advertisement Advertisement RIGHTS & PERMISSIONS Get copyright
    permission  KEYWORDS Principal component analysis Scanners Spectroscopy Cameras
    Sensors Agriculture Calibration Show All Keywords RELATED CONTENT UAV data reliability
    improvements based on multifunctional GCPs Proceedings of SPIE (June 07 2019)
    Improving the detection of cocoa bean fermentation related changes using... Proceedings
    of SPIE (May 05 2017) The remote sensing data from your UAV probably isn''t scientific,...
    Proceedings of SPIE (May 08 2017) ARES a new reflective emissive imaging spectrometer
    for terrestrial... Proceedings of SPIE (October 22 2004) The growth forecasting
    model for apple tree based on ground... Proceedings of SPIE (November 09 2012)
    Convex reduction of calibration charts Proceedings of SPIE (January 17 2005) Subscribe
    to Digital Library Receive Erratum Email Alert Access provided by Univ. of Nebraska-Lincoln
    Site Map Home Conference Papers Conference Presentations Journals eBooks About
    Subscriptions Information for Authors Proceedings Authors Journal Authors eBook
    Authors Information for Reviewers Reviewer Guidelines Reviewer Training Program
    Information for Librarians Resources Subscriptions Contact & Support TECHNICAL
    SUPPORT spiedlsupport@spie.org CUSTOMER SERVICE +1 360 676 3290 Hours: 8:00 am
    to 5:00 pm PST Help Center | Contact Us Connect SPIE Privacy Policy | Terms of
    Use © 2024 SPIE'
  inline_citation: '>'
  journal: ''
  limitations: '>'
  pdf_link: null
  publication_year: 2018
  relevance_score1: 0
  relevance_score2: 0
  title: Onion irrigation treatment inference using a low-cost hyperspectral scanner
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1094/pdis.1999.83.5.404
  analysis: '>'
  authors:
  - Laura Mugnai
  - A. Graniti
  - Giuseppe Surico
  citation_count: 505
  full_citation: '>'
  full_text: '>

    brought to you by Univ of Nebraska Search My Cart Login Skip main navigation Plant
    Disease Home About Submit Journals Books Publisher’S Home Previous Next OPEN Open
    Access license Esca (Black Measles) and Brown Wood-Streaking: Two Old and Elusive
    Diseases of Grapevines L. Mugnai , A. Graniti , and G. Surico Affiliations Published
    Online:23 Feb 2007https://doi.org/10.1094/PDIS.1999.83.5.404 PDF TOOLS SHARE Details
    Figures Literature Cited Related Vol. 83, No. 5 May 1999 Subscribe ISSN:0191-2917
    e-ISSN:1943-7692 Metrics Downloaded 3,845 times See more details Referenced in
    2 patents 215 readers on Mendeley 376 376 Total citations 83 Recent citations
    n/a Field Citation Ratio 4.93 Relative Citation Ratio Article History Issue Date:
    25 Jan 2008 Published: 23 Feb 2007 Pages: 404-418 Information © 1999 The American
    Phytopathological Society PDF download The American Phytopathological Society
    (APS) 3285 Northwood Circle, Suite 100, St. Paul, MN 55121 USA +1.651.454.7250
    +1.651.454.0766 APS Information For Authors For Subscribers Help & About Us Contact
    Us APS Home Accessibility Links & Resources Scope Impact Permissions Terms & Conditions
    Privacy Policy © 2024 The American Phytopathological Society. Powered by Atypon®
    Literatum.'
  inline_citation: '>'
  journal: Plant disease
  limitations: '>'
  pdf_link: null
  publication_year: 1999
  relevance_score1: 0
  relevance_score2: 0
  title: 'Esca (Black Measles) and Brown Wood-Streaking: Two Old and Elusive Diseases
    of Grapevines'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1016/j.biosystemseng.2012.08.009
  analysis: '>'
  authors:
  - D. J. Mulla
  citation_count: 1224
  full_citation: '>'
  full_text: '>

    Skip to main content Skip to article Journals & Books Search Register Sign in
    Brought to you by: University of Nebraska-Lincoln View PDF Download full issue
    Outline Highlights Nomenclature 1. Introduction 2. Remote sensing applications
    in agriculture 3. Knowledge gaps for remote sensing in precision agriculture Acknowledgement
    References Show full outline Cited by (1287) Figures (3) Tables (4) Table 1 Table
    2 Table 3 Table 4 Biosystems Engineering Volume 114, Issue 4, April 2013, Pages
    358-371 Special Issue: Sensing in Agriculture Review Twenty five years of remote
    sensing in precision agriculture: Key advances and remaining knowledge gaps☆ Author
    links open overlay panel David J. Mulla Show more Add to Mendeley Share Cite https://doi.org/10.1016/j.biosystemseng.2012.08.009
    Get rights and content Precision agriculture dates back to the middle of the 1980''s.
    Remote sensing applications in precision agriculture began with sensors for soil
    organic matter, and have quickly diversified to include satellite, aerial, and
    hand held or tractor mounted sensors. Wavelengths of electromagnetic radiation
    initially focused on a few key visible or near infrared bands. Today, electromagnetic
    wavelengths in use range from the ultraviolet to microwave portions of the spectrum,
    enabling advanced applications such as light detection and ranging (LiDAR), fluorescence
    spectroscopy, and thermal spectroscopy, along with more traditional applications
    in the visible and near infrared portions of the spectrum. Spectral bandwidth
    has decreased dramatically with the advent of hyperspectral remote sensing, allowing
    improved analysis of specific compounds, molecular interactions, crop stress,
    and crop biophysical or biochemical characteristics. A variety of spectral indices
    now exist for various precision agriculture applications, rather than a focus
    on only normalised difference vegetation indices. Spatial resolution of aerial
    and satellite remote sensing imagery has improved from 100''s of m to sub-metre
    accuracy, allowing evaluation of soil and crop properties at fine spatial resolution
    at the expense of increased data storage and processing requirements. Temporal
    frequency of remote sensing imagery has also improved dramatically. At present
    there is considerable interest in collecting remote sensing data at multiple times
    in order to conduct near real time soil, crop and pest management. Highlights
    ► Rapid advances in remote sensing for precision agriculture have occurred. ►
    Satellite imagery has improved in spatial resolution, return visit frequency and
    spectral resolution. ► Aerial hyperspectral imagery has revolutionized precision
    agriculture. ► Ground based sensors have been developed for on-the-go monitoring
    of crop and soil characteristics. ► The future challenge is to develop approaches
    that provide customized management for individual plants. Previous article in
    issue Next article in issue Nomenclature ALI advanced land imager AVIRIS airborne
    visible/infrared imaging spectrometer B blue DVI difference vegetation index EO
    1 earth observing 1 EROS earth resources observation and science EVI enhanced
    vegetation index G green GDVI green difference vegetation index GNDVI green normalised
    difference vegetation index GOSAVI green optimised soil adjusted vegetation index
    GPS global positioning system GRVI green red vegetation index GSAVI green soil
    adjusted vegetation index HyspIRI hyperspectral infrared imager INSEY in season
    estimated yield IRS Indian remote sensing LAI leaf area index LED light emitting
    diode LiDAR light detection and ranging MCARI modified chlorophyll absorption
    in reflectance index MSAVI modified soil adjusted vegetation index MSS multispectral
    scanning system N nitrogen NASA National Aeronautics and Space Administration
    NDI normalised difference index NDVI normalised difference vegetation index NG
    normalised green NGNDVI normalised green normalized difference vegetation index
    NIR near infrared NR normalised red NSI nitrogen sufficiency index OMNBR optimal
    multiple narrow band reflectance OSAVI optimised soil adjusted vegetation index
    PNSI plant nitrogen spectral index PSSR pigment specific simple ratio R red RI
    response index RVI ratio vegetation index SPAD soil plant analysis development
    SPOT système pour l''observation de la terre SR8 simple ratio 8 TCARI transformed
    chlorophyll absorption in reflectance index TM thematic mapper 1. Introduction
    Precision agriculture is one of the top ten revolutions in agriculture (Crookston,
    2006), although it has only been practiced commercially since the 1990''s. Over
    one-third of US Midwestern farmers already practice some form of precision agriculture.
    Precision agriculture generally involves better management of farm inputs such
    as fertilisers, herbicides, seed, fuel (used during tillage, planting, spraying,
    etc.) by doing the right management practice at the right place and the right
    time. Whereas large farm fields under conventional management receive uniform
    applications of fertilisers, irrigation, seed, etc., with precision agriculture,
    these fields can be divided into management zones that each receives customised
    management inputs based on varying soil types, landscape position, and management
    history. Precision agriculture offers to improve crop productivity and farm profitability
    through improved management of farm inputs (Larson & Robert, 1991; Zhang, Wang,
    & Wang, 2002), leading to better environmental quality (Mulla, 1993; Mulla et
    al., 2002; Mulla, Perillo, & Cogger, 1996; Tian, 2002). Other benefits perceived
    by farmers include more precise hybrid selection, rental agreements that are better
    aligned with actual soil productivity, better matching of fertiliser applications
    to crop yield potential, lower chemical bills and fuel costs, and reduced compaction.
    Benefits to society include creation of high technology jobs (computer hardware,
    computer software, machinery guidance, soil and crop sensors, information management,
    decision support systems), and mitigation of environmental pollution arising from
    over-application of nitrogen and phosphorus fertiliser. Precision agriculture
    uses intensive data and information collection and processing in time and space
    to make more efficient use of farm inputs, leading to improved crop production
    and environmental quality (Harmon et al., 2005). Precision agriculture is beginning
    to emphasise spatial-temporal data analysis and management rather than spatial
    data analysis and management alone (Mamo, Malzer, Mulla, Huggins, & Strock, 2003;
    Miao, Mulla, Randall, Vetsch, & Vintila, 2009; Varvel, Wilhelm, Shanahan, & Schepers,
    2007). Crop yield and response to N fertiliser varies significantly across years
    in response to changes in climate (Bakhsh, Jaynes, Colvin, & Kanwar, 2000), just
    as it varies significantly across the landscape in response to variations in soil
    type and landscape features. Precision agriculture involves both data collection/analysis
    and information management, as well as technological advances in computer processing,
    field positioning, yield monitoring, remote sensing, and sensor design (Mulla
    & Schepers, 1997). More than 30% of the growth in US agribusiness (jobs, sales,
    exports, etc.) in the future is expected to come from further adoption of precision
    agriculture by farmers (Whipker & Akridge, 2006), including growth in demand for
    both information management services and technological advances such as global
    positioning system (GPS) autosteer guidance (e.g. Real Time Kinetic technology),
    variable rate irrigation, fertiliser and sprayer controllers, robotics, and real
    time decision making based on sensor networks and remote sensing. Adoption rates
    are also significant in Australia, Japan, Canada and Europe, specifically in Germany,
    Sweden, France, Spain, Denmark and the UK. Globally, there is little documented
    information about rates of adoption for precision agriculture in the developing
    world. Mondal and Basu (2009) state that countries such as Argentina, Brazil,
    China, India and Malaysia have begun to adopt precision agriculture. Precision
    agriculture is also widely used in the vineyards of Chile. The farms of the future
    are likely to be managed with much greater spatial and temporal resolution than
    they are with present approaches to precision agriculture. In Chilean vineyards,
    each grape vine receives an individually customised fertiliser prescription that
    varies with soil type, landscape position and hybrid. It is not unrealistic to
    expect that crops on modern US farms of the future will be managed plant-by-plant,
    a huge advance over farming by soil approaches of the past. This approach will
    require massive data collection and analysis on a scale not considered feasible
    today, involving stationary or mobile sensors that can measure characteristics
    of individual plants in real time. Sensors of the future could be based on satellites
    (Bausch & Khosla, 2010), airplanes (Goel et al., 2003; Haboudane, Miller, Pattey,
    Zarco-Tejada, & Strachan, 2004; Haboudane, Miller, Tremblay, Zarco-Tejada, & Dextraze,
    2002; Miao, Mulla, Randall, Vetsch, & Vintila, 2007), unmanned aerial vehicles
    (Berni, Zarco-Tejada, Suárez, & Fereres, 2009; Herwitz et al., 2004), tractors
    (Adamchuk, Hummel, Morgan, & Upadhyaya, 2004; Long, Engel, & Siemens, 2008), or
    attached to mobile robots (Astrand & Baerveldt, 2002) to record weed densities,
    crop height, leaf reflectance, moisture status and other properties important
    for decisions about fertilizer and pest management. These sensors must be robust,
    run on renewable energy sources, and be able to relay information using wireless
    networks (O''Shaughnessy and Evett, 2010; Wang, Zhang, & Wang, 2006) to computers
    that can perform data mining procedures and make complex management recommendations.
    These recommendations can be transmitted to computers and controllers in the field
    that are capable of varying the rates of irrigation, fertilisers, and herbicides
    at fine spatial resolution, if not plant-by-plant. 2. Remote sensing applications
    in agriculture Remote sensing applications in agriculture are based on the interaction
    of electromagnetic radiation with soil or plant material. Typically, remote sensing
    involves the measurement of reflected radiation, rather than transmitted or absorbed
    radiation. Remote sensing refers to non-contact measurements of radiation reflected
    or emitted from agricultural fields. The platforms for making these measurements
    include satellites, aircraft, tractors and hand-held sensors. Measurements made
    with tractors and hand-held sensors are also known as proximal sensing, especially
    if they do not involve measurements of reflected radiation. In addition to reflectance,
    transmittance and absorption, plant leaves can emit energy by fluorescence (Apostol
    et al., 2003) or thermal emission (Cohen, Alchanatis, Meron, Saranga, & Tsipris,
    2005). Thermal remote sensing for water stress in crops is based on emission of
    radiation in response to temperature of the leaf and canopy, which varies with
    air temperature and the rate of evapotranspiration. The amount of radiation reflected
    from plants is inversely related to radiation absorbed by plant pigments, and
    varies with the wavelength of incident radiation. Plant pigments such as chlorophyll
    absorb radiation strongly in the visible spectrum from 400 to 700 nm (Pinter et
    al., 2003), particularly at wavelengths such as 430 (blue or B) and 660 (red or
    R) nm for chlorophyll a and 450 (B) and 650 (R) nm for chlorophyll b. Other plant
    pigments such as anthocyanins and carotenoids are also important (Blackburn, 2007).
    In contrast, plant reflectance is high in the near infrared (NIR 700–1300 nm)
    region as a result of leaf density and canopy structure effects. This sharp contrast
    in reflectance behaviour between the red and NIR portions of the spectrum is the
    motivation for development of spectral indices that are based on ratios of reflectance
    values in the visible and NIR regions (Sripada, Heiniger, White, & Weisz, 2006).
    These spectral indices are often used to assess various attributes of plant canopies,
    such as leaf area index (LAI), biomass, chlorophyll content or N content. The
    amount of radiation reflected by bare soils is affected primarily by soil moisture
    and organic matter content, but also by clay minerals and calcium carbonate or
    iron oxides (Thomasson, Sui, Cox, & Al–Rajehy, 2001; Viscarra Rossel, Walvoort,
    McBratney, Janik, & Skjemstad, 2006). Each soil constituent has a specific spectral
    region where reflectance is strongest (Ben-Dor, 2010), and a specific spectral
    signature. Bare soil and crop canopies are often both present in a remotely sensed
    image, and the mixture of two spectral signatures often confounds the interpretation
    of reflectance data (Fig. 1). Spectral unmixing algorithms (Huete & Escadafal,
    1991), derivative spectra (Demetriades-Shah, Steven, & Clark, 1990) or spectral
    indices that adjust for soil effects (Haboudane et al., 2002, 2004) are often
    used to isolate information about plant characteristics when the reflectance is
    affected by both sources. Download : Download full-size image Fig. 1. Reflectance
    signatures of dry or wet soil in comparison to reflectance signatures of a Russet
    Burbank potato canopy with low or high rates of N fertiliser application. Remote
    sensing applications in agriculture are typically classified according to the
    type of platform for the sensor, including satellite, aerial, and ground based
    platforms. These platforms and their associated imaging systems can be differentiated
    based on the altitude of the platform, the spatial resolution of the image, and
    the minimum return frequency for sequential imaging. Spatial resolution affects
    the area of the smallest pixel that can be identified. As spatial resolution improves,
    the area of the smallest pixel decreases, and the homogeneity of soil or crop
    characteristics within that pixel increases. Poor spatial resolution implies large
    pixels with increased heterogeneity in soil or plant characteristics. Return frequency
    is important for assessment of temporal patterns in soil or plant characteristics.
    The availability of remote sensing images from satellite and aerial platforms
    is often severely limited by cloud cover (Moran, Inoue, & Barnes, 1997), whereas
    ground based remote sensing is less affected by this limitation. Remote sensing
    applications in agriculture have focused on a wide range of endeavours (Adamchuk
    et al., 2004; Moran et al., 1997; Pinter et al., 2003). These include crop yield
    and biomass (Shanahan et al., 2001; Yang, Everitt, Bradford, & Escobar, 2000),
    crop nutrient and water stress (Bastiaanssen, Molden, & Makin, 2000; Clay, Kim,
    Chang, Clay, & Dalsted, 2006; Cohen et al., 2005; Moller et al., 2007; Tilling
    et al., 2007), infestations of weeds (Lamb & Brown, 2001; Thorp & Tian, 2004),
    insects and plant diseases (Seelan, Laguette, Casady, & Seielstad, 2003), and
    soil properties such as organic matter, moisture and clay content, and pH (Christy,
    2008), or salinity (Corwin & Lesch, 2003). 2.1. Soil sensing in precision agriculture
    Precision agriculture started during the mid 1980''s with two contrasting philosophies.
    The first was exemplified by the “farming by soil” school (Larson & Robert, 1991).
    This school promoted the use of soil sampling and customised management of farm
    inputs by soil mapping unit. The second was exemplified by the “Soil Sampling
    Management Zone” school (Mulla, 1991, 1993; Mulla & Bhatti, 1997; Mulla, Bhatti,
    Hammond, & Benson, 1992), which later became known as “site-specific crop management”.
    Management zones are relatively homogeneous sub-units of farm fields that can
    each be managed with a different, but uniform customised management practice.
    This school became very popular when field comparisons of uniform versus variable
    fertiliser applications showed that there was considerable variability at scales
    finer than soil mapping units (Mulla et al., 1992). Bhatti, Mulla, and Frazier
    (1991) were the first to demonstrate that Landsat remote sensing had significant
    capabilities for estimating spatial patterns in soil organic matter, soil phosphorus
    and crop yield potential for use in precision agriculture applications. A third
    approach to precision agriculture began to emerge in the early 1990''s (Hummel,
    Gaultney, & Sudduth, 1996), known as proximal soil sensing. This approach was
    based on continuous real-time sensing of spatial variations in soil properties
    using sensors mounted on tractors. The first application of this approach was
    for soil organic matter sensing (Shonk, Gaultney, Schulze, & Van Scoyoc, 1991)
    based on reflectance from multiple light emitting diode (LED) sensors emitting
    radiation at 660 nm. The sensor was very accurate if calibrated for individual
    soil catenas, but was affected by variations in soil moisture. Sudduth and Hummel
    (1993) developed a portable NIR sensor which could simultaneously be used to estimate
    soil organic matter content and soil moisture content. Other related technology
    was developed by Christy (2008), allowing simultaneous measurements of soil organic
    matter content, soil moisture, soil pH, soil carbon and soil phosphorus, potassium,
    and calcium. A major breakthrough in precision agriculture occurred when Carter,
    Rhoades, and Chesson (1993) introduced continuous real-time, non-contact proximal
    sensing of soil apparent electrical conductivity using non-invasive electromagnetic
    induction with the Geonics EM-38 (Geonics Ltd., Mississauga, Ontario, Canada).
    Soil electrical conductivity measurements with the EM-38 have been used to map
    spatial patterns in soil salinity (Corwin & Lesch, 2003), soil clay content (Doolittle,
    Sudduth, Kitchen, & lndorante, 1994) and soil moisture content (Sudduth et al.,
    2005). These patterns are often used to define management zones. 2.2. Satellite
    remote sensing Satellites have been used for remote sensing imagery in agriculture
    (Table 1) since the early 1970''s (Bauer & Cipra, 1973; Doraiswamy, Moulin, Cook,
    & Stern, 2003; Jewel, 1989) when Landsat 1 (originally known as Earth Resources
    Technology Satellite 1) was launched in 1972. Multispectral Scanner System (MSS)
    sensors on Landsat 1 collected imagery in the green, red and two infrared bands
    at a spatial resolution of 80 m and a return frequency of 18 days. Landsat 1 was
    initially used by Bauer and Cipra (1973) to classify Midwestern US agricultural
    landscapes into maize or soybean fields with an overall accuracy of 83%. Landsat
    5 was launched in 1984 and collected Thematic Mapper (TM) imagery at a spatial
    resolution of 30 m in the blue, green, red, near infrared, and three infrared
    (including thermal) bands. France launched a comparable satellite (système pour
    l''observation de la terre (SPOT) 1) in 1986, which collected 20 m imagery with
    a return frequency of up to six days in the green, red and near infrared frequencies.
    Jewel (1989) used four images collected between February and September in East
    Anglia, UK to distinguish cereal crops, field crops, grassland and forest land
    with an accuracy of 88%. India launched the Indian Remote Sensing (IRS-1A) satellite
    in 1988, with coverage in the blue, green, red and NIR bands at a spatial resolution
    of 72 m. Panigrahy and Sharma (1997) used reflectance in the red and NIR bands
    collected on four dates between October and March to classify agricultural landscapes
    in India into rice or rice–potato cropping systems with 95% accuracy. Table 1.
    Satellite remote sensing platforms and their spectral or spatial resolution, return
    frequency, and suitability for precision agriculture (PA). P refers to purple,
    B to blue, G to green, R to red, IR to infrared, NIR to near infrared, MIR to
    mid infrared, TIR to thermal infrared. Suitability class L refers to low, M to
    medium and H to high. Satellite (year) Spectral bands (spatial resolution) Return
    frequency (d) Suitability for PA Landsat 1 (1972) G, R, two IR (56 × 79 m) 18
    L AVHRR (1978) R, NIR, two TIR (1090 m) 1 L Landsat 5 TM (1984) B, G, R, two NIR,
    MIR, TIR (30 m) 16 M SPOT 1 (1986) G, R, NIR (20 m) 2–6 M IRS 1A (1988) B, G,
    R, NIR (72 m) 22 M ERS-1 (1991) Ku band altimeter, IR (20 m) 35 L JERS-1 (1992)
    L band radar (18 m) 44 L LiDAR (1995) VIS (vertical RMSE 10 cm) N/A H RadarSAT
    (1995) C-band radar (30 m) 1–6 M IKONOS (1999) Panchromatic, B, G, R, NIR (1–4
    m) 3 H SRTM (2000) X-band radar (30 m) N/A M Terra EOS ASTER (2000) G, R, NIR
    and 6 MIR, 5 TIR bands (15–90 m) 16 M EO-1 Hyperion (2000) 400–2500 nm, 10 nm
    bandwidth (30 m) 16 H QuickBird (2001) Panchromatic, B, G, R, NIR (0.61–2.4 m)
    1–4 H EOS MODIS (2002) 36 bands in VIS-IR (250–1000 m) 1–2 L RapidEye (2008) B,
    G, R, red edge, NIR (6.5 m) 5.5 H GeoEye-1 (2008) Panchromatic, B, G, R, NIR1,
    NIR2 (1.6 m) 2–8 H WorldView-2 (2009) P, B, G, Y, R, red edge, NIR (0.5 m) 1.1
    H These applications of remote sensing in conventional agriculture soon led to
    applications in precision agriculture. The first application of remote sensing
    in precision agriculture occurred when Bhatti et al. (1991) used Landsat imagery
    of bare soil to estimate spatial patterns in soil organic matter content, which
    were then used as auxiliary data along with ground based measurements to estimate
    spatial patterns in soil phosphorus and wheat grain yield (Mulla, 1997). The spatial
    resolution of Landsat, SPOT and IRS satellites is fairly coarse (20–30 m) for
    current applications in precision agriculture. Efforts were subsequently started
    to design satellite imaging systems that had the higher spatial resolution and
    quicker revisit cycles required for precision agriculture (Table 1). IKONOS was
    launched in 1999 by Satellite Imaging Corp, Magnolia, TX, USA in partnership with
    Lockheed Martin, Bethesda, MD, USA. IKONOS collected 4 m resolution imagery in
    the blue, green, red and near infrared bands at a return frequency of up to 5
    days. Seelan et al. (2003) used IKONOS images to identify N deficiencies in sugarbeet,
    fungicide performance efficiency in wheat and field sites that had inadequate
    artificial drainage in wheat. In 2001, DigitalGlobe, Longmont, CO, USA launched
    a satellite named QuickBird with capabilities similar to IKONOS. QuickBird had
    a revisit frequency of 1–3 days and collected imagery in the blue, green, red
    and near infrared at a spatial resolution of 0.6–2.4 m. Bausch and Khosla (2010)
    showed that QuickBird estimates of normalised green normalised difference vegetation
    index (NGNDVI) were strongly correlated with spatial patterns in nitrogen sufficiency
    in irrigated maize. García Torres, Peña-Barragán, López-Granados, Jurado-Expósito,
    and Fernández-Escobar (2008) showed that QuickBird images of olive orchards in
    Spain could be used to estimate areas of olive plantations, numbers of trees,
    and spatial patterns in projected area of tree canopies, and olive yields. These
    two satellites have steadily gained a substantial base of commercial subscribers
    interested in precision agriculture applications, in stark contrast to older satellite
    technology such as Landsat or SPOT. The next major breakthrough in satellite remote
    sensing for precision agriculture was the five-satellite constellation developed
    by the RapidEye, Brandenburg_an_der_Havel, Germany in 2008 (Table 1). RapidEye
    satellites provide daily coverage for any location on the globe, and collect data
    with a 6.5 m spatial resolution. RapidEye is the first satellite to provide imagery
    in the chlorophyll sensitive red-edge region of the spectrum (690–730 nm), along
    with the more traditional blue, green, red and near infrared reflectance. In 2008,
    GeoEye, Herndon, VA, USA launched a commercial satellite designed to provide services
    similar to RapidEye. The GeoEye 1 satellite has a return visit frequency of less
    than three days, and collects data at from 40 to 60 cm spatial resolution in the
    blue, green, red and near infrared bands. One of the main uses for GeoEye 1 imagery
    is providing Google Earth maps that are available through the Internet. This has
    revolutionised the ability to visualise land use patterns around the world. DigitalGlobe
    launched the WorldView 2 satellite in 2009, which collects imagery at 50 cm resolution
    with a 1 day revisit cycle. WorldView 2 is significantly more advanced than DigitalGlobe''s
    QuickBird satellite, as WorldView 2 collects imagery in the standard blue, green,
    red, and near infrared bands, as well as bands in the purple (450–480 nm), yellow,
    red-edge and a second near infrared frequency range. Several trends are apparent
    in satellite based remote sensing (Table 1). Firstly, the spatial resolution of
    imaging systems has improved from 80 m with Landsat to sub-metre resolution with
    GeoEye and WorldView. Secondly, the return visit frequency has improved from 18
    days with Landsat to 1 day with WorldView. Thirdly, the number of spectral bands
    available for analysis has improved from four bands (bandwidths greater than 60
    nm) with Landsat to eight or more bands (bandwidths greater than 40 nm) with WorldView.
    Hyperspectral imaging systems such as Hyperion on the National Aeronautics and
    Space Administration (NASA) earth observing 1 (EO 1) satellite provided even greater
    spectral resolution, with imaging from 400 to 2500 nm in 10 nm increments. As
    the spatial and spectral resolution of satellite imagery has improved, the suitability
    of using reflectance data from these platforms for precision agriculture applications
    has increased (Table 1). The most appropriate spatial and spectral resolution
    for precision agriculture applications depends on factors such as crop management
    objectives, capacity of farm equipment to vary farm inputs, and farm unit area.
    Estimation of spatial patterns in crop biomass or yield requires better spatial
    and spectral resolution (1–3 m) than variable rate application of fertiliser (5–10
    m). Accuracy of variable rate application of fertiliser is often limited by fertiliser
    spreader delay times (Chan, Schueller, Miller, Whitney, & Cornell, 2004). Variable
    rate spraying of herbicides for spot weed control requires better spatial and
    spectral resolution (0.5–1 m) than variable rate irrigation (5–10 m). Larger commercial
    farms can often afford to pay for remote sensing data with higher spatial and
    spectral resolution than smaller farms in developing countries. Satellite and/or
    aerial imagery is frequently used to estimate spatial patterns in crop biomass
    (Yang et al., 2000) and potential crop yield (Doraiswamy et al., 2003) using the
    Normalised Difference Vegetation Index (NDVI). NDVI is calculated using reflectance
    ratios in the NIR and red portion of the spectrum (Rouse, Hass, Schell, & Deering,
    1973): (1) NDVI has several limitations, however, including potential interference
    from soil reflectance at low canopy densities and insensitivity to changes in
    leaf chlorophyll content in mature canopies with leaf area index values that exceed
    2 or 3 (Thenkabail, Smith, & De Pauw, 2000). The advent of crop combines equipped
    with yield monitors was a major advance in precision agriculture (Schueller &
    Bae, 1987; Stafford, Ambler, Lark, & Catt, 1996). Yield monitors provided fine
    scale resolution yield measurements across large spatial areas that could be used
    to improve the capacity of remote sensing to predict crop structural characteristics
    such as LAI, biomass, and yield. Many broadband spectral indices (Table 2) other
    than NDVI are available for use in precision agriculture (Miao et al., 2009; Sripada
    et al., 2006; Sripada, Schmidt, Dellinger, & Beegle, 2008). These indices reflect
    two historical trends in remote sensing for crop characteristics; namely, the
    prediction of ratios of reflectance in the red (R) and NIR bands versus ratios
    in the green (G) and NIR bands. The normalised red (NR) index focuses on the portion
    of the spectrum where chlorophyll strongly absorbs radiation. In contrast, the
    normalised green (NG) index focuses on the portion of the spectrum where pigments
    other than chlorophyll (carotenoids, anthocyanins, xanthophylls) absorb radiation.
    Similarly, there are two forms of the ratio vegetation index (RVI), one that consists
    of the ratio of NIR to R reflectance, the other green red vegetation index (GRVI)
    that consists of the ratio of NIR to G reflectance. Two forms of the NDVI exist,
    one that involves NIR and R reflectance, the other green normalized difference
    vegetation index (GNDVI) involves NIR and G reflectance. The difference vegetative
    index (DVI) was developed using the difference between reflectance in the NIR
    and R bands to compensate for effects of soil reflectance (Tucker, 1979). Sripada
    et al. (2006) found that economically optimum N rate in corn was better correlated
    with green difference vegetation index (GDVI) (NIR − G) than DVI (NIR − R), and
    these indices that compensated for soil effects performed better than NIR and
    R ratio indices such as NDVI and RVI that did not compensate for soil effects.
    A wide range of other indices have been developed to compensate for soil effects,
    including soil adjusted vegetation index (SAVI), green soil adjusted vegetation
    index (GSAVI), optimised soil adjusted vegetation index (OSAVI), green optimised
    soil adjusted vegetation index (GOSAVI) and modified soil adjusted vegetation
    index (MSAVI). A comparison of NDVI and simple ratio (SR8) vegetation indices
    for an irrigated commercial Minnesota potato (Solanum tuberosum L.) farm is shown
    in Fig. 2. Spatial patterns in N stress are identified more accurately with the
    SR8 index than the NDVI index. Table 2. Multi-spectral broad-band vegetation indices
    available for use in precision agriculture. G refers to green reflectance, NIR
    to near infrared, and R to red reflectance. Index Definition Reference NG G/(NIR
    + R + G) Sripada et al., 2006 NR R/(NIR + R + G) Sripada et al., 2006 RVI NIR/R
    Jordan, 1969 GRVI NIR/G Sripada et al., 2006 DVI NIR − R Tucker, 1979 GDVI NIR
    − G Tucker, 1979 NDVI (NIR − R)/(NIR + R) Rouse et al., 1973 GNDVI (NIR − G)/(NIR
    + G) Gitelson et al., 1996 SAVI 1.5*[(NIR − R)/(NIR + R + 0.5)] Huete, 1988 GSAVI
    1.5*[(NIR − G)/(NIR + G + 0.5)] Sripada et al., 2006 OSAVI (NIR − R)/(NIR + R
    + 0.16) Rondeaux, Steven, & Baret, 1996 GOSAVI (NIR − G)/(NIR + G + 0.16) Sripada
    et al., 2006 MSAVI2 0.5*[2*(NIR + 1) − SQRT((2*NIR + 1)2 − 8*(NIR − R))] Qi, Chehbouni,
    Huete, Keer, & Sorooshian, 1994 Download : Download full-size image Fig. 2. Comparison
    between a) NDVI and b) SR8 spectral indices in a commercial Russet Burbank potato
    field. Moran et al. (1997) and Yao et al. (2010) summarised the major challenges
    for using satellite remote sensing for precision agriculture. Satellite imagery
    in the visible and NIR bands are limited to cloud free days, and are most usable
    when irradiance is relatively consistent across time. Only radar imagery collected
    using satellites or airplanes is unaffected by cloud cover. Other challenges include
    calibrating raw digital numbers to true surface reflectance, correcting imagery
    for atmospheric interferences and/or off-nadir view angles, and geo-rectifying
    pixels using GPS-based ground control locations. 2.3. Proximal remote sensing
    of crops for precision agriculture Given the limitations of satellite remote sensing
    for precision agriculture, there has been significant interest in proximal remote
    sensing techniques to assess crop growth and crop stress (Table 3). Proximal remote
    sensing involves sensors mounted on tractors, spreaders, sprayers or irrigation
    booms. Proximal sensing allows real time site specific management of fertiliser,
    pesticides or irrigation. The foundation for a transition from remote sensing
    to proximal sensing based assessment of crop status was established by Schepers,
    Francis, Vigil, and Below (1992), who used a Minolta soil plant analysis development
    (SPAD) meter to measure leaf greenness (chlorophyll) in maize crops at the silking
    stage under a range of applied N fertiliser rates. SPAD meter readings of leaf
    reflectance at 650 and 940 nm were found to be correlated with applied rate of
    N fertiliser as well as independent measurements of leaf N concentration. Schepers
    et al. (1992) suggested that proximal chlorophyll readings could be used to estimate
    N stress in maize by referencing the SPAD readings for stressed crops with the
    readings in a reference strip that received adequate rates of N fertiliser. Chlorophyll
    content of crop leaves is strongly affected by crop N status, but can also be
    affected to a lesser degree by other factors, such as crop variety and growth
    stage, pest infestations, water stress, and nutrient deficiencies other than N.
    Table 3. Innovations in remote and proximal leaf sensing in precision agriculture.
    Year Innovation Citation 1992 SPAD meter (650, 940 nm) used to detect N deficiency
    in corn Schepers et al., 1992 1995 Nitrogen sufficiency indices Blackmer & Schepers,
    1995 1996 Optical sensor (671, 780 nm) used for on-the-go detection of variability
    in plant nitrogen stress Stone et al., 1996 2002 Yara N sensor Link et al., 2002,
    TopCon industries 2002 GreenSeeker (650, 770 nm) Raun et al., 2002, NTech industries
    2004 Crop Circle (590, 880 nm or 670, 730, 780 nm) Holland et al., 2004, Holland
    scientific 2002 CASI hyperspectral sensor based index measurements of chlorophyll
    Haboudane et al., 2002, 2004 2002 MSS remote sensing of ag fields with UAV Herwitz
    et al., 2004 2003 Fluorescence sensing for N deficiencies Apostol et al., 2003
    Blackmer and Schepers (1995) introduced the concept of a nitrogen sufficiency
    index (NSI) to assess the degree of N stress in maize. The NSI was defined as
    the ratio of SPAD meter greenness readings for crops in a given field location
    relative to SPAD readings for the same crop in a well-fertilised reference strip
    with no N deficiencies. NSI values less than 0.95 were used to indicate areas
    with N stress that required additional N fertiliser. Varvel, Schepers, and Francis
    (1997) showed that SPAD meters and NSI values could be used for in-season correction
    of N deficiency in maize. Bausch and Duke (1996) showed that the SPAD meter could
    be replaced with a boom-mounted radiometer to estimate spatial patterns in NIR/G
    ratio and NSI across an irrigated maize field based on comparisons with a well-fertilised
    reference strip. They observed that this approach could detect N deficiencies
    in the V6 growth stage (Ritchie, Hanway, & Benson, 1993, p. 21), but results were
    confounded by interference with reflectance patterns from bare soil. Stone et
    al. (1996) measured spectral radiance in the red (671 nm) and NIR (780 nm) bands
    in wheat with a sensor mounted on a mobile lawn tractor. They used these data
    to estimate a spectral index known as the plant nitrogen spectral index (PNSI),
    which was the absolute value of the inverse of NDVI. Results showed that PNSI
    was strongly correlated with crop N uptake. Sensor readings were used to vary
    N fertiliser rates using an algorithm that increased exponentially with PNSI values
    (Solie, Raun, Whitney, Stone, & Ringer, 1996). This was the beginning of technology
    to variably apply N fertiliser “on-the-go” in response to proximal crop sensing,
    and was the basis for commercial development of the GreenSeeker NDVI active sensor
    marketed by NTech Industries, Ukiah, CA, USA in 2001. Raun et al. (2002) subsequently
    developed a seven step response index (RI)-based algorithm to estimate crop N
    fertiliser needs for maize and wheat based on in-season sensing of crop reflectance
    relative to check plots with no added fertiliser and reference plots with sufficient
    fertiliser. This algorithm accounted for both season-to-season temporal variability
    in crop growth using the concept of in-season estimated yield (INSEY) as well
    as within-field spatial variability in N supply. Algorithms for estimating potential
    crop yield and N uptake are available for many crops and locations around the
    world (Shanahan, Kitchen, Raun, & Schepers, 2008). The RI is estimated as the
    ratio of NDVI values in the crop relative to those in a reference strip with sufficient
    fertiliser. Link, Panitzki, and Reusch (2002) and Reusch, Link, and Lammel (2002)
    developed a tractor based passive sensor to determine crop N status based on NDVI.
    This was originally known as the Hydro-N sensor, but has since become known as
    the Yara-N sensor (Yara, Olso, Norway) (Table 3). A version of the Yara-N sensor
    is also available that uses active sensors (Link & Reusch, 2006), which reduces
    the errors caused by varying cloud cover, and allows the tractor operator to work
    at night. Holland, Schepers, Shanahan, and Horst (2004) developed an active crop
    sensor known as Crop Circle (Table 3). This sensor initially used reflectance
    in the green and NIR bands to estimate crop N deficiencies. The rationale behind
    using green rather than red reflectance with Crop Circle was that as crop LAI
    increases beyond 2.0, the green NDVI is more sensitive to changes in chlorophyll
    concentration and potential crop yield than NDVI (Gitelson, Kaufmann, & Merzlyak,
    1996; Shanahan et al., 2001; Sripada et al., 2006, 2008). This overcomes the limitation
    of using the GreenSeeker sensor at advanced crop growth stages. Solari, Shanahan,
    Ferguson, Schepers, and Gitelson (2008) used the Crop Circle sensor to show that
    N deficiencies could be better predicted using a green chlorophyll index defined
    as (NIR880/VIS590) − 1 in comparison with the green NDVI. Sripada et al. (2008)
    showed that the performance of spectral indices could be improved using ratios
    with the corresponding index values in reference strips receiving sufficient N
    fertiliser. Kitchen et al. (2010) and Scharf et al. (2011) showed that producers
    using the Crop Circle sensor could reduce N fertiliser applications by making
    in-season correction, while increasing crop yield and farm profitability. One
    limitation of the chlorophyll meter, GreenSeeker, Yara N and Crop Circle sensors,
    however, is that they cannot directly estimate the amount of N fertiliser needed
    to overcome crop N stress (Samborski, Tremblay, & Fallon, 2009). To overcome this,
    scientists have conducted comparisons of sensor readings with readings in reference
    strips receiving sufficient N fertiliser (Blackmer & Schepers, 1995; Kitchen et
    al., 2010; Raun et al., 2002; Sripada et al., 2008). They have used these data
    to develop N fertiliser response functions that relate sensor readings to the
    amount of N fertiliser needed to overcome crop N stress (Scharf et al., 2011).
    Even with this approach, reference strips with adequate fertiliser have to be
    strategically placed in representative soils and landscapes because yield response
    to N fertiliser exhibits significant spatial variability across production fields
    (Mamo et al., 2003). Also, reference strips have limitations for other crops like
    wheat (subject to lodging) and potato (subject to excessive vine growth at the
    expense of tuber growth). 2.4. Hyperspectral remote sensing in precision agriculture
    Hyperspectral remote sensing collects reflectance data over a wide spectral range
    at small spectral increments (typically 10 nm). It provides the ability to investigate
    spectral response of soils and vegetated surfaces in narrow spectral bands (10
    nm wide) across a wide spectral range. This is not possible with multispectral
    imaging that traditionally collects reflectance data in broadbands (greater than
    40 nm wide) centred in the B, G, R and NIR regions of the spectrum. When collected
    across large spatial extents at fine spatial resolution, hyperspectral imaging
    provides powerful insight into the spatial and spectral variability in reflectance
    for a bare or vegetated surface. This information is traditionally visualised
    using a three-dimensional hyperspectral data cube, with two spatial dimensions
    (x,y) and one spectral dimension (wavelength). An example of a hyperspectral data
    cube is shown in Fig. 3 for a commercial potato field in Minnesota, USA. The field
    shows significant spatial and spectral variability in reflectance. Download :
    Download full-size image Fig. 3. Hyperspectral data cube for a commercial Russet
    Burbank potato field in Minnesota. The face of the cube is a red–green–blue image
    of the same area shown in Fig. 2. The first hyperspectral sensor was the airborne
    visible/infrared imaging spectrometer (AVIRIS), launched in 1987. This sensor
    provides continuous imagery from 380 to 2500 nm in bands that have a spectral
    resolution of 10 nm and a spatial resolution of 20 m. The satellite based Hyperion
    sensor, launched aboard EO-1 by NASA in 2000, has hyperspectral imaging capabilities
    similar to AVIRIS. Hyperspectral imagery collected by EO-1 Hyperion via the advanced
    land imager (ALI) sensor continues to be collected and is available for public
    use through the US Geological Survey, Center for Earth Resources Observation and
    Science (EROS). Datt, Jupp, McVicar, and Van Niel (2003) showed that ALI hyperspectral
    data could be used to more accurately predict spatial patterns in rice yield grown
    in Australia with derivative indices and red edge position in comparison with
    predictions based on NDVI. Miglani, Ray, Pandey, and Parihar (2008) showed that
    20 hyperspectral bands from ALI were necessary for agricultural remote sensing
    studies in the Meerut district of India. Wu, Wang, Niu, Gao, and Wu (2010) showed
    that vegetative indices based on red edge reflectance from hyperspectral ALI data
    could be used to accurately estimate canopy chlorophyll content and leaf area
    index for a broad range of agricultural crops in China. An aerial hyperspectral
    imaging system, the compact airborne spectrographic imager (CASI), has also been
    widely used (Haboudane et al., 2002, 2004). There are also hand-held or boom-mounted
    hyperspectral and multispectral imaging systems, including the CropScan (CropScan
    Inc, Rochester, MN, USA) sensor. Hyperspectral imaging differs from multispectral
    imaging in the continuity, range and spectral resolution of bands. In theory,
    it offers the capability of sensing a wide variety of soil and crop characteristics
    simultaneously, including moisture status, organic matter, nutrients, chlorophyll,
    carotenoids, cellulose, leaf area index and crop biomass (Goel et al., 2003; Haboudane
    et al., 2002; Zarco-Tejada et al., 2005). Specific wavelengths are most sensitive
    to each type of soil or crop characteristic. A red band centred at 687 nm is sensitive
    to crop leaf area index and biomass, while a near infrared band centred at 970
    nm is sensitive to crop moisture status (Thenkabail, Lyon, & Huete, 2010). Further
    examples of linking specific soil and crop characteristics with reflectance are
    given for 33 hyperspectral bands by Thenkabail et al. (2010). In contrast, multispectral
    imaging is often limited to analysis of single broadband combinations such as
    NDVI, which become insensitive to chlorophyll and other plant characteristics
    at LAI values exceeding 3.0 (Thenkabail et al., 2000), and are strongly interfered
    with by bare soil reflectance at low LAI values. Thenkabail et al. (2000) showed
    that hyperspectral data can be used to construct three general categories of predictive
    spectral indices, including 1) optimal multiple narrow band reflectance indices
    (OMNBR), 2) narrow band NDVI, and 3) SAVI. Only two to four narrow bands were
    needed to describe plant characteristics with OMNBR. The greatest information
    about plant characteristics in OMNBR includes the longer red wavelengths (650–700
    nm), shorter green wavelengths (500–550 nm), red-edge (720 nm), and two NIR (900–940
    nm and 982 nm) spectral bands. The information in these bands is only available
    in narrow increments of 10–20 nm, and is easily obscured in broad multispectral
    bands that are available with older satellite imaging systems. The best combination
    of two narrow bands in NDVI-like indices was centred in the red (682 nm) and NIR
    (920 nm) wavelengths, but varied depending on the type of crop (corn, soybean,
    cotton or potato) as well as the plant characteristic of interest (LAI, biomass,
    etc.). Advanced statistical methods for chemometric analysis of reflectance spectra
    have been used to interpret hyperspectral remote sensing data, including partial
    least squares (Lindgren, Geladi, & Wold, 1994; Viscarra Rossel et al., 2006),
    principal components analysis (Geladi, 2003), and pattern classification and recognition
    techniques (Stuckens, Coppin, & Bauer, 2000), including object oriented (Frohn,
    Reif, Lane, & Autrey, 2009) and decision tree (Wright & Gallant, 2007) classification
    techniques. Partial least squares (PLS) regression is perhaps more powerful than
    principal components analysis (PCA) in that PLS (like PCA) not only identifies
    factors that describe spectral variance, but also eliminates spectral bands that
    contain redundant information (Alchanatis & Cohen, 2010). Jain, Ray, Singh, and
    Panigrahy (2007) explored hyperspectral remote sensing for identification of N
    stress in potatoes grown in India. They used three techniques to identify bands
    that were optimal for detection of N stress, namely; 1) lambda–lambda plots, 2)
    principal component analysis, and 3) discriminant analysis. Lambda–lambda plots
    involve calculating, for example, the coefficient of determination (r2) for leaf
    N content at all hyperspectral reflectance bands. A graph of r2 for all possible
    combinations of band 1 on the x-axis and band 2 on the y-axis results in a lambda–lambda
    plot. The lambda–lambda plot is useful for identifying which combinations of two
    bands contain redundant information about N stress. Spectral bands or narrow band
    indices should be selected with low r2 to eliminate redundancy and maximise information
    about crop characteristics (such as N stress). Principal component analysis was
    used by Jain et al. (2007) to identify which combinations of bands account for
    a majority of the variance in crop reflectance characteristics. This technique
    is used to eliminate hyperspectral bands that do not contain useful information
    about the crop characteristics of interest. Stepwise discriminant analysis uses
    a ratio of treatment sums of squares to total sums of squares to find spectral
    regions with distinctly different mean values of reflectance. A variety of narrow
    band hyperspectral indices (Table 4) are available for use in precision agriculture
    (Haboudane et al., 2002, 2004; Li et al., 2010; Miao et al., 2007, 2009). Many
    of these have the same form as broadband spectral indices (Table 1), but differ
    in that the reflectance bands for hyperspectral indices are narrow (10–20 nm wide)
    bands centred around a single specific wavelength. These indices variously respond
    to canopy or leaf scale effects of leaf area index, chlorophyll, specific pigments,
    or nitrogen stress. Simple ratios (SR) 1 through 7 and normalized difference indices
    (NDI) 1 through 3 typically respond to leaf level changes in chlorophyll. In contrast,
    NDVI responds to canopy scale changes in leaf area index and chlorophyll. GNDVI,
    modified chlorophyll absorption in reflectance index (MCARI), transformed chlorophyll
    absorption in reflectance index (TCARI), MCARI2, OSAVI, and MSAVI respond to canopy
    scale changes in chlorophyll, with the latter two indices being designed to compensate
    for soil reflectance effects. PSSRa and PSSRb were designed specifically to respond
    to changes in chlorophyll a and chlorophyll b, respectively. New hyperspectral
    indices are continuously being tested and developed (Li et al., 2010) using techniques
    involving lambda–lambda plots where reflectance signatures are compared for all
    possible combinations of two reflectance bands. Table 4. Hyperspectral narrow-band
    vegetation indices available for use in precision agriculture. R refers to reflectance
    at the wavelength (nm) in subscript. NIR refers to near infrared reflectance.
    Index Definition Reference Greenness index (G) R554/R677 Smith, Adams, Stephens,
    & Hick, 1995 SR1 NIR/red = R801/R670 Daughtry, Walthall, Kim, de Colstoun, & McMurtrey,
    2000 SR2 NIR/green = R800/R550 Buschman & Nagel, 1993 SR3 R700/R670 McMurtrey,
    Chappelle, Kim, Meisinger, & Corp, 1994 SR4 R740/R720 Vogelmann, Rock, & Moss,
    1993 SR5 R675/(R700*R650) Chappelle at al., 1992 SR6 R672/(R550*R708) Datt, 1998
    SR7 R860/(R550*R708) Datt, 1998 DI1 R800 − R550 Buschman & Nagel, 1993 NDVI (R800
    − R680)/(R800 + R680) Lichtenthaler, Lang, Sowinska, Heisel, & Mieh, 1996 Green
    NDVI (GNDVI) (R801 − R550)/(R800 + R550) Daughtry et al., 2000 PSSRa R800/R680
    Blackburn, 1998 PSSRb R800/R635 Blackburn, 1998 NDI1 (R780 − R710)/(R780 − R680)
    Datt, 1999 NDI2 (R850 − R710)/(R850 − R680) Datt, 1999 NDI3 (R734 − R747)/(R715
    + R726) Vogelmann et al., 1993 MCARI [(R700 − R670) − 0.2(R700 − R550)](R700/R670)
    Daughtry et al., 2000 TCARI 3*[(R700 − R670) − 0.2*(R700 − R550)(R700/R670)] Haboudane
    et al., 2002 OSAVI (1 + 0.16)(R800 − R670)/(R800 + R670 + 0.16) Rondeaux et al.,
    1996 TCARI/OSAVI Haboudane et al., 2002 TVI 0.5*[120*(R750 − R550) − 200*(R670
    − R550)] Broge & Leblanc, 2000 MCARI/OSAVI Zarco-Tejada, Miller, Morales, Berjón,
    & Agüera, 2004 RDVI (R800 − R670)/SQRT(R800 + R670) Rougean & Breon, 1995 MSR
    (R800/R670 − 1)/SQRT(R800/R670 + 1) Chen, 1996 MSAVI 0.5[2R800 + 1 − SQRT((2R800
    + 1)2 − 8(R800 − R670))] Qi et al., 1994 MTVI 1.2*[1.2*(R800 − R550) − 2.5*(R670
    − R550)] Haboudane et al., 2004 MCARI2 Haboudane et al., 2004 Potential applications
    of hyperspectral remote sensing in precision agriculture have recently been reviewed
    by Yao et al. (2010). These applications include 1) bare soil imaging for management
    zone delineation, 2) weed mapping, 3) crop N stress detection, 4) crop yield mapping,
    and 5) pest and disease detection. Perhaps of greatest interest for precision
    agriculture is using hyperspectral remote sensing for variable rate, in-season
    management of nitrogen fertiliser based on spatial patterns in chlorophyll content.
    Wu, Han, Niu, and Dong (2010) used hyperspectral data from the Hyperion EO-1 satellite
    to study chlorophyll content in a variety of agricultural canopy types in China,
    including flax, chestnuts, corn, bamboo, potato, pine, saccharose and tea. Chlorophyll
    content of leaves were estimated using a variety of vegetation indices derived
    from red edge reflectance bands located at 705 and 750 nm. The MCARI/OSAVI705
    index performed better than all other vegetation indices evaluated, with an r2
    value of 0.71. Wu, Wang et al. (2010) estimated chlorophyll content of maize in
    China using Hyperion hyperspectral reflectance data. The Enhanced Vegetation Index
    (EVI) was more accurate (r2 = 0.81) at predicting maize chlorophyll contents than
    MSAVI or NDVI. 3. Knowledge gaps for remote sensing in precision agriculture Rapid
    advances in remote sensing for precision agriculture have occurred over the last
    twenty five years. Satellite imagery has improved in spatial resolution, return
    visit frequency and spectral resolution. Aerial hyperspectral imagery has revolutionised
    the ability to distinguish multiple crop characteristics, including nutrients,
    water, pests, diseases, weeds, biomass and canopy structure. Ground-based sensors
    have been developed for on-the-go monitoring of crop and soil characteristics
    such as N stress, water stress, soil organic matter and moisture content. Precision
    farming has progressed through many stages. It began with farming by soil and
    progressed to site-specific crop management based on grid sampling and management
    zones. More recently there has been increasing emphasis on real-time on-the-go
    monitoring with ground based sensors. The challenge for the future is to develop
    precision farming approaches that can provide customized management of farm inputs
    for individual plants. There is a significant potential in precision agriculture
    for combining archived remote sensing data with real-time data for improved agricultural
    management (Thenkabail, 2003). Historical archives of satellite remote sensing
    data are available at many locations for Landsat, SPOT, IRS, IKONOS, and QuickBird.
    These data typically include reflectance in the B, G, R and NIR bands, at spatial
    resolutions of from 0.6 to 30 m spatial resolution. Images at a fixed location
    could be analysed across multiple crop growth stages, seasons and years in order
    to identify relatively homogeneous sub-regions of fields that differ from one
    another in leaf area index, NDVI, and potential yield. Auxiliary data at these
    same sites, including crop yield maps, digital elevation models and soil series
    maps could be combined with historical remote sensing data to identify potential
    management zones where precision agricultural input operations can be implemented.
    Real time remote sensing with high spatial and spectral resolution satellites
    such as EO-1 Hyperion or the upcoming (2016) NASA Hyperspectral Infrared Imager
    (HyspIRI) satellite (or comparable data collected with aerial platforms) could
    then be used for real time precision agricultural decision making and to refine
    the location of management zones identified using historical imaging and auxiliary
    data. With this in mind, there are several needs for future research in precision
    farming. These include the following: • More emphasis is needed on chemometric
    or spectral decomposition/derivative methods of analysis since spatial and spectral
    resolution of hyperspectral sensing systems are now adequate for most precision
    agriculture applications • Sensors are needed for direct estimation of nutrient
    deficiencies without the use of reference strips • Spectral indices should continue
    to be developed that simultaneously allow assessment of multiple crop characteristics
    (e.g. LAI, biomass, etc.) and stresses (e.g. water and N; weeds and insects, etc.)
    • Historical archives of satellite remote sensing data at moderate to high spatial
    resolution and traditional spectral resolution should be integrated with real-time
    remote sensing data at high spatial and spectral resolution for improved decision
    making in precision agriculture. Acknowledgement Support by the USDA-BARD fund
    through Research Grant Award No. IS-4255-09 is acknowledged. The assistance of
    Mr. Tyler Nigon in preparing figures is acknowledged. References Adamchuk et al.,
    2004 V.I. Adamchuk, J.W. Hummel, M.T. Morgan, S.K. Upadhyaya On-the-go soil sensors
    for precision agriculture Computers and Electronics in Agriculture, 44 (2004),
    pp. 71-79 View in ScopusGoogle Scholar Alchanatis and Cohen, 2010 V. Alchanatis,
    Y. Cohen Spectral and spatial methods of hyperspectral image analysis for estimation
    of biophysical and biochemical properties of agricultural crops. Ch. 13 P.S. Thenkabail,
    J.G. Lyon, A. Huete (Eds.), Hyperspectral remote sensing of vegetation, CRC Press,
    Boca Raton, FL (2010), p. 705 Google Scholar Apostol et al., 2003 S. Apostol,
    A.A. Viau, N. Tremblay, J.-M. Briantais, S. Prasher, L.-E. Parent, et al. Laser-induced
    fluorescence signatures as a tool for remote monitoring of water and nitrogen
    stresses in plants Canadian Journal of Remote Sensing, 29 (2003), pp. 57-65 CrossRefView
    in ScopusGoogle Scholar Astrand and Baerveldt, 2002 B. Astrand, A.-J. Baerveldt
    An agricultural mobile robot with vision-based perception for mechanical weed
    control Autonomous Robots, 13 (2002), pp. 21-35 View in ScopusGoogle Scholar Bakhsh
    et al., 2000 A. Bakhsh, D.B. Jaynes, T.S. Colvin, R.S. Kanwar Spatio-temporal
    analysis of yield variability for a corn-soybean field in Iowa Transactions of
    the ASAE, 43 (1) (2000), pp. 31-38 View in ScopusGoogle Scholar Bastiaanssen et
    al., 2000 W.G.M. Bastiaanssen, D.J. Molden, I.W. Makin Remote sensing for irrigated
    agriculture: examples from research and possible applications Agricultural Water
    Management, 46 (2000), pp. 137-155 View PDFView articleView in ScopusGoogle Scholar
    Bauer and Cipra, 1973 Bauer, M. E., & Cipra, J. E. (1973). Identification of agricultural
    crops by computer processing of ERTS MSS data. LARS Technical Reports. Paper 20.
    http://docs.lib.purdue.edu/larstech/20. W. Lafayette, IN: Purdue Univ. Google
    Scholar Bausch and Duke, 1996 W.C. Bausch, H.R. Duke Remote sensing of plant nitrogen
    status in corn Transactions of the ASAE, 39 (1996), pp. 1869-1875 View in ScopusGoogle
    Scholar Bausch and Khosla, 2010 W.C. Bausch, R. Khosla QuickBird satellite versus
    ground-based multi-spectral data for estimating nitrogen status of irrigated maize
    Precision Agriculture, 11 (2010), pp. 274-290 CrossRefView in ScopusGoogle Scholar
    Ben-Dor, 2010 E. Ben-Dor Characterization of soil properties using reflectance
    spectroscopy. Ch. 22 P.S. Thenkabail, J.G. Lyon, A. Huete (Eds.), Hyperspectral
    remote sensing of vegetation, CRC Press, Boca Raton, FL (2010), p. 705 Google
    Scholar Berni et al., 2009 J.A.J. Berni, P.J. Zarco-Tejada, L. Suárez, E. Fereres
    Thermal and narrowband multispectral remote sensing for vegetation monitoring
    from an unmanned aerial vehicle IEEE Transactions on Geoscience and Remote Sensing,
    47 (2009), pp. 722-738 View in ScopusGoogle Scholar Bhatti et al., 1991 A.U. Bhatti,
    D.J. Mulla, B.E. Frazier Estimation of soil properties and wheat yields on complex
    eroded hills using geostatistics and thematic mapper images Remote Sensing of
    Environment, 37 (1991), pp. 181-191 View PDFView articleView in ScopusGoogle Scholar
    Blackburn, 1998 G.A. Blackburn Quantifying chlorophylls and carotenoids at leaf
    and canopy scales: an evaluation of some hyperspectral approaches Remote Sensing
    of Environment, 66 (3) (1998), pp. 273-285 View PDFView articleView in ScopusGoogle
    Scholar Blackburn, 2007 G.A. Blackburn Hyperspectral remote sensing of plant pigments
    Journal of Experimental Botany, 58 (2007), pp. 855-867 View in ScopusGoogle Scholar
    Blackmer and Schepers, 1995 T.M. Blackmer, J.S. Schepers Use of a chlorophyll
    meter to monitor nitrogen status and schedule fertigation for corn Journal of
    Production Agriculture, 8 (1995), pp. 56-60 CrossRefView in ScopusGoogle Scholar
    Broge and Leblanc, 2000 N.H. Broge, E. Leblanc Comparing prediction power and
    stability of broadband and hyperspectral vegetation indices for estimation of
    green leaf area index and canopy chlorophyll density Remote Sensing of Environment,
    76 (2000), pp. 156-172 Google Scholar Buschman and Nagel, 1993 C. Buschman, E.
    Nagel In vivo spectroscopy and internal optics of leaves as a basis for remote
    sensing of vegetation International Journal of Remote Sensing, 14 (1993), pp.
    711-722 Google Scholar Carter et al., 1993 L.M. Carter, J.D. Rhoades, J.H. Chesson
    Mechanization of soil salinity assessment for mapping ASAE Paper no. 931557 ASAE,
    St. Joseph, MI, USA (1993) Google Scholar Chan et al., 2004 C.W. Chan, J.K. Schueller,
    W.M. Miller, J.D. Whitney, J.A. Cornell Error sources affecting variable rate
    application of nitrogen fertilizer Precision Agriculture, 5 (2004), pp. 601-616
    CrossRefView in ScopusGoogle Scholar Chappelle et al., 1992 E.W. Chappelle, M.S.
    Kim, J.E. McMurtrey III Ratio analysis of reflectance spectra (RARS): an algorithm
    for the remote estimation of the concentrations of chlorophyll a, chlorophyll
    b and carotenoids in soybean leaves Remote Sensing of Environment, 39 (3) (1992),
    pp. 239-247 View PDFView articleView in ScopusGoogle Scholar Chen, 1996 J. Chen
    Evaluation of vegetation indices and modified simple ratio for boreal applications
    Canadian Journal of Remote Sensing, 22 (1996), pp. 229-242 CrossRefView in ScopusGoogle
    Scholar Christy, 2008 C.D. Christy Real-time measurement of soil attributes using
    on-the-go near infrared reflectance spectroscopy Computers and Electronics in
    Agriculture, 61 (2008), pp. 10-19 View PDFView articleView in ScopusGoogle Scholar
    Clay et al., 2006 D.E. Clay, K.-I. Kim, J. Chang, S.A. Clay, K. Dalsted Characterizing
    water and nitrogen stress in corn using remote sensing Agronomy Journal, 98 (2006),
    pp. 579-587 CrossRefView in ScopusGoogle Scholar Cohen et al., 2005 Y. Cohen,
    V. Alchanatis, M. Meron, Y. Saranga, J. Tsipris Estimation of leaf water potential
    by thermal imagery and spatial analysis Journal of Experimental Botany, 56 (2005),
    pp. 1843-1852 CrossRefView in ScopusGoogle Scholar Corwin and Lesch, 2003 D.L.
    Corwin, S.M. Lesch Application of soil electrical conductivity to precision agriculture:
    theory, principles, and guidelines Agronomy Journal, 95 (2003), pp. 455-471 View
    in ScopusGoogle Scholar Crookston, 2006 K. Crookston A top 10 list of developments
    and issues impacting crop management and ecology during the past 50 years Crop
    Science, 46 (2006), pp. 2253-2262 CrossRefView in ScopusGoogle Scholar Datt, 1998
    B. Datt Remote sensing of chlorophyll a, chlorophyll b, chlorophyll a+b and total
    carotenoid content in eucalyptus leaves Remote Sensing of Environment, 66 (2)
    (1998), pp. 111-121 View PDFView articleView in ScopusGoogle Scholar Datt, 1999
    B. Datt Visible/near infrared reflectance and chlorophyll content in eucalyptus
    leaves International Journal of Remote Sensing, 20 (14) (1999), pp. 2741-2759
    View in ScopusGoogle Scholar Datt et al., 2003 B. Datt, D. Jupp, T. McVicar, T.
    Van Niel Time series analysis of EO-1 Hyperion data for yield estimation at an
    agricultural site Geoscience and Remote Sensing Symposium IGARSS Proceedings IEEE
    International, 1 (2003), pp. 564-566 View in ScopusGoogle Scholar Daughtry et
    al., 2000 C.S.T. Daughtry, C.L. Walthall, M.S. Kim, E.B. de Colstoun, J.E. McMurtrey
    III Estimating corn leaf chlorophyll concentration from leaf and canopy reflectance
    Remote Sensing of Environment, 74 (2000), pp. 229-239 View PDFView articleView
    in ScopusGoogle Scholar Demetriades-Shah et al., 1990 T.H. Demetriades-Shah, M.D.
    Steven, J.A. Clark High resolution derivative spectra in remote sensing Remote
    Sensing of Environment, 33 (1990), pp. 55-56 View in ScopusGoogle Scholar Doolittle
    et al., 1994 J.A. Doolittle, K.A. Sudduth, N.R. Kitchen, S.J. lndorante Estimating
    depths to claypans using electromagnetic induction methods Journal of Soil and
    Water Conservation, 49 (1994), pp. 572-575 View in ScopusGoogle Scholar Doraiswamy
    et al., 2003 P.C. Doraiswamy, S. Moulin, P.W. Cook, A. Stern Crop yield assessment
    from remote sensing Photogrammetric Engineering and Remote Sensing, 69 (2003),
    pp. 665-674 View in ScopusGoogle Scholar Frohn et al., 2009 R. Frohn, M. Reif,
    C. Lane, B. Autrey Satellite remote sensing of isolated wetlands using object-oriented
    classification of LANDSAT-7 data Wetlands, 29 (2009), pp. 931-941 CrossRefGoogle
    Scholar García Torres et al., 2008 L. García Torres, J.M. Peña-Barragán, F. López-Granados,
    M. Jurado-Expósito, R. Fernández-Escobar Automatic assessment of agro-environmental
    indicators from remotely sensed images of tree orchards and its evaluation using
    olive plantations Computers and Electronics in Agriculture, 61 (2008), pp. 179-191
    View PDFView articleView in ScopusGoogle Scholar Geladi, 2003 P. Geladi Chemometrics
    in spectroscopy. Part 1. Classical chemometrics Spectrochimica Acta Part B, 58
    (2003), pp. 767-782 View PDFView articleView in ScopusGoogle Scholar Gitelson
    et al., 1996 A.A. Gitelson, Y.J. Kaufmann, M.N. Merzlyak Use of a green channel
    in remote sensing of global vegetation from EOS-MODIS Remote Sensing of Environment,
    58 (1996), pp. 289-298 View PDFView articleView in ScopusGoogle Scholar Goel et
    al., 2003 P.K. Goel, S.O. Prasher, J.A. Landry, R.M. Patel, R.B. Bonnell, A.A.
    Viau, et al. Potential of airborne hyperspectral remote sensing to detect nitrogen
    deficiency and weed infestation in corn Computers and Electronics in Agriculture,
    38 (2003), pp. 99-124 View PDFView articleView in ScopusGoogle Scholar Haboudane
    et al., 2004 D. Haboudane, J.R. Miller, E. Pattey, P.J. Zarco-Tejada, I.B. Strachan
    Hyperspectral vegetation indices and novel algorithms for predicting green LAI
    of crop canopies: modeling and validation in the context of precision agriculture
    Remote Sensing of Environment, 90 (2004), pp. 337-352 View PDFView articleView
    in ScopusGoogle Scholar Haboudane et al., 2002 D. Haboudane, J.R. Miller, N. Tremblay,
    P.J. Zarco-Tejada, L. Dextraze Integrated narrow-band vegetation indices for prediction
    of crop chlorophyll content for application to precision agriculture Remote Sensing
    of Environment, 81 (2002), pp. 416-426 View PDFView articleView in ScopusGoogle
    Scholar Harmon et al., 2005 T. Harmon, C. Kvien, D. Mulla, G. Hoggenboom, J. Judy,
    J. Hook, et al. Precision agriculture scenario P. Arzberger (Ed.), NSF workshop
    on sensors for environmental observatories, World Tech. Evaluation Center, Baltimore,
    MD, USA (2005) Google Scholar Herwitz et al., 2004 S.R. Herwitz, L.F. Johnson,
    S.E. Dunagan, R.G. Higgins, D.V. Sullivan, J. Zheng, et al. Imaging from an unmanned
    aerial vehicle: agricultural surveillance and decision support Computers and Electronics
    in Agriculture, 44 (2004), pp. 49-61 View PDFView articleView in ScopusGoogle
    Scholar Holland et al., 2004 K.H. Holland, J.S. Schepers, J.F. Shanahan, G.L.
    Horst Plant canopy sensor with modulated polychromatic light D.J. Mulla (Ed.),
    Proc. 7th intl. conf. precision agriculture. (CD-ROM), Univ. Minnesota, Minneapolis,
    MN (2004) Google Scholar Huete, 1988 A. Huete A soil adjusted vegetation index
    (SAVI) Remote Sensing of Environment, 25 (1988), pp. 295-309 View PDFView articleView
    in ScopusGoogle Scholar Huete and Escadafal, 1991 A.R. Huete, R. Escadafal Assessment
    of biophysical soil properties through spectral decomposition techniques Remote
    Sensing of Environment, 35 (1991), pp. 149-159 View PDFView articleView in ScopusGoogle
    Scholar Hummel et al., 1996 J.W. Hummel, L.D. Gaultney, K.A. Sudduth Soil property
    sensing for site-specific crop management Computers and Electronics in Agriculture,
    14 (1996), pp. 121-136 View PDFView articleView in ScopusGoogle Scholar Jain et
    al., 2007 N. Jain, S.S. Ray, J.P. Singh, S. Panigrahy Use of hyperspectral data
    to assess the effects of different nitrogen applications on a potato crop Precision
    Agriculture, 8 (2007), pp. 225-239 CrossRefView in ScopusGoogle Scholar Jewel,
    1989 N. Jewel An evaluation of multi-date SPOT data for agriculture and land use
    mapping in the United Kingdom International Journal of Remote Sensing, 10 (1989),
    pp. 939-951 Google Scholar Jordan, 1969 C.F. Jordan Derivation of leaf area index
    from quality of light on the forest floor Ecology, 50 (1969), pp. 663-666 CrossRefGoogle
    Scholar Kitchen et al., 2010 N.R. Kitchen, K.A. Sudduth, S.T. Drummond, P.C. Scharf,
    H.L. Palm, D.F. Roberts, et al. Ground-based canopy reflectance sensing for variable-rate
    nitrogen corn fertilization Agronomy Journal, 102 (2010), pp. 71-84 CrossRefView
    in ScopusGoogle Scholar Lamb and Brown, 2001 D.W. Lamb, R.B. Brown Remote-sensing
    and mapping of weeds in crops Journal of Agricultural Engineering Research, 78
    (2001), pp. 117-125 View PDFView articleView in ScopusGoogle Scholar Larson and
    Robert, 1991 W.E. Larson, P.C. Robert Farming by soil R. Lal, F.J. Pierce (Eds.),
    Soil management for sustainability, Soil and Water Conserv. Soc, Ankeny, IA, USA
    (1991), pp. 103-112 View in ScopusGoogle Scholar Li et al., 2010 F. Li, Y. Miao,
    S.D. Hennig, M.L. Gnyp, X. Chen, L. Jia, et al. Evaluating hyperspectral vegetation
    indices for estimating nitrogen concentration of winter wheat at different growth
    stages Precision Agriculture, 11 (2010), pp. 335-357 CrossRefGoogle Scholar Lichtenthaler
    et al., 1996 H.K. Lichtenthaler, M. Lang, M. Sowinska, F. Heisel, J.A. Mieh Detection
    of vegetation stress via a new high resolution fluorescence imaging system Journal
    of Plant Physiology, 148 (1996), pp. 599-612 View PDFView articleView in ScopusGoogle
    Scholar Lindgren et al., 1994 F. Lindgren, P. Geladi, S. Wold Kernal based PLS
    regression; cross-validation and application to spectral data Journal of Chemometrics,
    8 (1994), pp. 377-389 CrossRefView in ScopusGoogle Scholar Link and Reusch, 2006
    A. Link, S. Reusch Implementation of site-specific nitrogen application-status
    and development of the YARA N-sensor NJF seminar 390, precision technology in
    crop production implementation and benefits, Norsk Jernbaneforbund, Stockholm,
    Sweden (2006), pp. 37-41 CrossRefGoogle Scholar Link et al., 2002 A. Link, M.
    Panitzki, S. Reusch Hydro N-sensor: tractor-mounted remote sensing for variable
    nitrogen fertilization P.C. Robert (Ed.), Precision agriculture [CD-ROM]. Proc.
    6th int. conf. on precision agric, ASA, CSSA, and SSSA, Madison, WI, USA (2002),
    pp. 1012-1018 Google Scholar Long et al., 2008 D.S. Long, R.E. Engel, M.C. Siemens
    Measuring grain protein concentration with in-line near infrared reflectance spectroscopy
    Agronomy Journal, 100 (2008), pp. 247-252 View in ScopusGoogle Scholar Mamo et
    al., 2003 M. Mamo, G.L. Malzer, D.J. Mulla, D.J. Huggins, J. Strock Spatial and
    temporal variation in economically optimum N rate for corn Agronomy Journal, 95
    (2003), pp. 958-964 View in ScopusGoogle Scholar McMurtrey et al., 1994 J.E. McMurtrey
    III, E.W. Chappelle, M.S. Kim, J.J. Meisinger, L.A. Corp Distinguish nitrogen
    fertilization levels in field corns (Zea mays L.) with actively induced fluorescence
    and passive reflectance measurements Remote Sensing of Environment, 47 (1994),
    pp. 36-44 View PDFView articleView in ScopusGoogle Scholar Miao et al., 2007 Y.
    Miao, D.J. Mulla, G.W. Randall, J.A. Vetsch, R. Vintila Predicting chlorophyll
    meter readings with aerial hyperspectral remote sensing for in-season site-specific
    nitrogen management of corn J.V. Stafford (Ed.), Precision agriculture ''07, Wageningen
    Acad. Publ, The Netherlands (2007), pp. 635-641 View in ScopusGoogle Scholar Miao
    et al., 2009 Y. Miao, D.J. Mulla, G. Randall, J. Vetsch, R. Vintila Combining
    chlorophyll meter readings and high spatial resolution remote sensing images for
    in-season site-specific nitrogen management of corn Precision Agriculture, 10
    (2009), pp. 45-62 CrossRefView in ScopusGoogle Scholar Miglani et al., 2008 A.
    Miglani, S. Ray, R. Pandey, J. Parihar Evaluation of EO-1 Hyperion data for agricultural
    applications Journal of Indian Society of Remote Sensing, 36 (2008), pp. 255-266
    CrossRefView in ScopusGoogle Scholar Moller et al., 2007 M. Moller, V. Alchanatis,
    Y. Cohen, M. Meron, J. Tsipris, A. Naor, et al. Use of thermal and visible imagery
    for estimating crop water status of irrigated grapevine Journal of Experimental
    Botany, 58 (2007), pp. 827-838 View in ScopusGoogle Scholar Mondal and Basu, 2009
    P. Mondal, M. Basu Adoption of precision agriculture technologies in India and
    in some developing countries: scope, present status and strategies Progress in
    Natural Science, 19 (2009), pp. 659-666 View PDFView articleView in ScopusGoogle
    Scholar Moran et al., 1997 M.S. Moran, Y. Inoue, E.M. Barnes Opportunities and
    limitations for image-based remote sensing in precision crop management Remote
    Sensing of Environment, 61 (1997), pp. 319-346 View PDFView articleView in ScopusGoogle
    Scholar Mulla, 1991 D.J. Mulla Using geostatistics and GIS to manage spatial patterns
    in soil fertility G. Kranzler (Ed.), Automated agriculture for the 21st century,
    ASAE, St. Joseph, MI, USA (1991), pp. 336-345 Google Scholar Mulla, 1993 D.J.
    Mulla Mapping and managing spatial patterns in soil fertility and crop yield P.
    Robert, W. Larson, R. Rust (Eds.), Soil specific crop management, ASA, Madison,
    WI, USA (1993), pp. 15-26 Google Scholar Mulla, 1997 D.J. Mulla Geostatistics,
    remote sensing and precision farming A. Stein, J. Bouma (Eds.), Precision agriculture:
    Spatial and temporal variability of environmental quality. Ciba foundation symposium
    210, Wiley, Chichester, UK (1997), pp. 100-119 View in ScopusGoogle Scholar Mulla
    and Bhatti, 1997 D.J. Mulla, A.U. Bhatti An evaluation of indicator properties
    affecting spatial patterns in N and P requirements for winter wheat yield J.V.
    Stafford (Ed.), Precision agriculture ''97: Spatial variability in soil and crop,
    Vol. 1, BIOS Sci. Publ, Oxford, UK (1997), pp. 145-154 Google Scholar Mulla et
    al., 1992 D.J. Mulla, A.U. Bhatti, M.W. Hammond, J.A. Benson A comparison of winter
    wheat yield and quality under uniform versus spatially variable fertilizer management
    Agriculture, Ecosystems & Environment, 38 (1992), pp. 301-311 View PDFView articleView
    in ScopusGoogle Scholar Mulla et al., 2002 D.J. Mulla, P. Gowda, W.C. Koskinen,
    B.R. Khakural, G. Johnson, P.C. Robert Modeling the effect of precision agriculture:
    pesticide losses to surface waters. Ch. 20 E. Arthur, A. Barefoot, V. Clay (Eds.),
    Terrestrial field dissipation studies. ACS symp. ser. no. 842, ACS, Washington,
    DC, USA (2002), pp. 304-317 CrossRefGoogle Scholar Mulla et al., 1996 D.J. Mulla,
    C.A. Perillo, C.G. Cogger A site-specific farm-scale GIS approach for reducing
    groundwater contamination by pesticides Journal of Environmental Quality, 25 (1996),
    pp. 419-425 CrossRefView in ScopusGoogle Scholar Mulla and Schepers, 1997 D.J.
    Mulla, J.S. Schepers Key processes and properties for site-specific soil and crop
    management F.J. Pierce, E.J. Sadler (Eds.), The state of site specific management
    for agriculture, ASA/CSSA/SSSA, Madison, WI, USA (1997), pp. 1-18 Google Scholar
    O''Shaughnessy and Evett, 2010 S.A. O''Shaughnessy, S.R. Evett Developing wireless
    sensor networks for monitoring crop canopy temperature using a moving sprinkler
    system as a platform Applied Engineering in Agriculture, 26 (2010), pp. 331-341
    View in ScopusGoogle Scholar Panigrahy and Sharma, 1997 S. Panigrahy, S.A. Sharma
    Mapping of crop rotation using multidate Indian remote sensing satellite digital
    data ISPRS Journal of Photogrammetry and Remote Sensing, 52 (1997), pp. 85-91
    View PDFView articleView in ScopusGoogle Scholar Pinter et al., 2003 P.J. Pinter
    Jr., J.L. Hatfield, J.S. Schepers, E.M. Barnes, M.S. Moran, C.S.T. Daughtry, et
    al. Remote sensing for crop management Photogrammetric Engineering and Remote
    Sensing, 69 (2003), pp. 647-664 View in ScopusGoogle Scholar Qi et al., 1994 J.
    Qi, A. Chehbouni, A.R. Huete, Y.H. Keer, S. Sorooshian A modified soil vegetation
    adjusted index Remote Sensing of Environment, 48 (1994), pp. 119-126 View PDFView
    articleView in ScopusGoogle Scholar Raun et al., 2002 W.R. Raun, J.B. Solie, G.V.
    Johnson, M.L. Stone, R.W. Mullen, K.W. Freeman, et al. Improving nitrogen use
    efficiency in cereal grain production with optical sensing and variable rate application
    Agronomy Journal, 94 (2002), pp. 815-820 View in ScopusGoogle Scholar Reusch et
    al., 2002 S. Reusch, A. Link, J. Lammel Tractor-mounted multispectral scanner
    for remote field investigation P.C. Roberts (Ed.), Proc. of the 6th int. conf.
    on precision agriculture and other precision resources management, ASA, CSSA,
    and SSSA, Madison, WI, USA (2002), pp. 1385-1393 Google Scholar Ritchie et al.,
    1993 Ritchie, S. W., Hanway, J. J., & Benson, G. O. (1993). How a corn plant develops.
    Iowa State University. CES Special Report No. 48. Google Scholar Rondeaux et al.,
    1996 G. Rondeaux, M. Steven, F. Baret Optimization of soil-adjusted vegetation
    indices Remote Sensing of Environment, 55 (1996), pp. 95-107 View PDFView articleView
    in ScopusGoogle Scholar Rougean and Breon, 1995 J.L. Rougean, F.M. Breon Estimating
    PAR absorbed by vegetation from bidirectional reflectance measurements Remote
    Sensing of Environment, 51 (1995), pp. 375-384 Google Scholar Rouse et al., 1973
    J.W. Rouse Jr., R.H. Hass, J.A. Schell, D.W. Deering Monitoring vegetation systems
    in the great plains with ERTS Proceedings 3rd Earth Resources Technology Satellite
    (ERTS) symposium, Vol. 1, NASA SP-351, NASA, Washington, DC, USA (1973), pp. 309-317
    Google Scholar Samborski et al., 2009 S.M. Samborski, N. Tremblay, E. Fallon Strategies
    to make use of plant sensors-based diagnostic information for nitrogen recommendations
    Agronomy Journal, 101 (2009), pp. 800-816 View in ScopusGoogle Scholar Scharf
    et al., 2011 P.C. Scharf, D.K. Shannon, H.L. Palm, K.A. Sudduth, S.T. Drummond,
    N.R. Kitchen, et al. Sensor-based nitrogen applications out-performed producer-chosen
    rates for corn in on-farm demonstrations Agronomy Journal, 103 (2011), pp. 1683-1691
    CrossRefView in ScopusGoogle Scholar Schepers et al., 1992 J.S. Schepers, D.D.
    Francis, M. Vigil, F.E. Below Comparison of corn leaf nitrogen concentration and
    chlorophyll meter readings Communications in Soil Science and Plant Analysis,
    23 (1992), pp. 2173-2187 CrossRefView in ScopusGoogle Scholar Schueller and Bae,
    1987 J.K. Schueller, Y.H. Bae Spatially attributed automatic combine data acquisition
    Computers and Electronics in Agriculture, 2 (1987), pp. 119-127 View PDFView articleView
    in ScopusGoogle Scholar Seelan et al., 2003 S.K. Seelan, S. Laguette, G.M. Casady,
    G.A. Seielstad Remote sensing applications for precision agriculture: a learning
    community approach Remote Sensing of Environment, 88 (2003), pp. 157-169 View
    PDFView articleView in ScopusGoogle Scholar Shanahan et al., 2008 J.F. Shanahan,
    N.R. Kitchen, W.R. Raun, J.S. Schepers Responsive in-season nitrogen management
    for cereals Computers and Electronics in Agriculture, 61 (2008), pp. 51-62 View
    PDFView articleView in ScopusGoogle Scholar Shanahan et al., 2001 J.F. Shanahan,
    J.S. Schepers, D.D. Francis, G.E. Varvel, W.W. Wilhelm, J.M. Tringe, et al. Use
    of remote sensing imagery to estimate corn grain yield Agronomy Journal, 93 (2001),
    pp. 583-589 CrossRefView in ScopusGoogle Scholar Shonk et al., 1991 J.L. Shonk,
    L.D. Gaultney, D.G. Schulze, G.E. Van Scoyoc Spectroscopic sensing of soil organic
    matter content Transactions of the ASAE, 34 (1991), pp. 1978-1984 View in ScopusGoogle
    Scholar Smith et al., 1995 R.C.G. Smith, J. Adams, D.J. Stephens, P.T. Hick Forecasting
    wheat yield in a Mediterranean-type environment from the NOAA satellite Australian
    Journal of Agricultural Research, 46 (1995), pp. 113-125 View in ScopusGoogle
    Scholar Solari et al., 2008 F. Solari, J. Shanahan, R. Ferguson, J. Schepers,
    A. Gitelson Active sensor reflectance measurements of corn nitrogen status and
    yield potential Agronomy Journal, 100 (2008), pp. 571-579 CrossRefView in ScopusGoogle
    Scholar Solie et al., 1996 J.B. Solie, W.R. Raun, R.W. Whitney, M.L. Stone, J.D.
    Ringer Optical sensor based field element size and sensing strategy for nitrogen
    Transactions of the ASAE, 39 (1996), pp. 1983-1992 View in ScopusGoogle Scholar
    Sripada et al., 2006 R.P. Sripada, R.W. Heiniger, J.G. White, R. Weisz Aerial
    color infrared photography for determining late-season nitrogen requirements in
    corn Agronomy Journal, 97 (2006), pp. 1443-1451 Google Scholar Sripada et al.,
    2008 R.P. Sripada, J.P. Schmidt, A.E. Dellinger, D.B. Beegle Evaluating multiple
    indices from a canopy reflectance sensor to estimate corn N requirements Agronomy
    Journal, 100 (2008), pp. 1553-1561 CrossRefView in ScopusGoogle Scholar Stafford
    et al., 1996 J.V. Stafford, B. Ambler, R.M. Lark, J. Catt Mapping and interpreting
    the yield variation in cereal crops Computers and Electronics in Agriculture,
    14 (1996), pp. 101-119 View PDFView articleView in ScopusGoogle Scholar Stone
    et al., 1996 M.L. Stone, J.B. Solie, W.R. Raun, R.W. Whitney, S.L. Taylor, J.D.
    Ringer Use of spectral radiance for correcting in-season fertilizer nitrogen deficiencies
    in winter wheat Transactions of the ASAE, 39 (1996), pp. 1623-1631 View in ScopusGoogle
    Scholar Stuckens et al., 2000 J. Stuckens, P.R. Coppin, M.E. Bauer Integrating
    contextual information with per-pixel classification for improved land cover classification
    Remote Sensing of Environment, 71 (2000), pp. 282-296 View PDFView articleView
    in ScopusGoogle Scholar Sudduth and Hummel, 1993 K.A. Sudduth, J.W. Hummel Soil
    organic matter, CEC, and moisture sensing with a portable NIR spectrophotometer
    Transactions of the ASAE, 36 (1993), pp. 1571-1582 View in ScopusGoogle Scholar
    Sudduth et al., 2005 K.A. Sudduth, N.R. Kitchen, W.J. Wiebold, W.D. Batchelor,
    G.A. Bollero, D.G. Bullock, et al. Relating apparent electrical conductivity to
    soil properties across the north-central USA Computers and Electronics in Agriculture,
    46 (2005), pp. 263-283 View PDFView articleView in ScopusGoogle Scholar Thenkabail,
    2003 P.S. Thenkabail Biophysical and yield information for precision farming from
    near-real-time and historical Landsat TM images International Journal of Remote
    Sensing, 24 (2003), pp. 2879-2904 View in ScopusGoogle Scholar Thenkabail et al.,
    2010 P.S. Thenkabail, J.G. Lyon, A. Huete Hyperspectral remote sensing of vegetation
    and agricultural crops: knowledge gain and knowledge gap after 40 years of research.
    Ch. 28 P.S. Thenkabail, J.G. Lyon, A. Huete (Eds.), Hyperspectral remote sensing
    of vegetation, CRC Press, Boca Raton, FL (2010), p. 705 Google Scholar Thenkabail
    et al., 2000 P.S. Thenkabail, R.B. Smith, E. De Pauw Hyperspectral vegetation
    indices and their relationships with agricultural crop characteristics Remote
    Sensing of Environment, 71 (2000), pp. 158-182 View PDFView articleView in ScopusGoogle
    Scholar Thomasson et al., 2001 J.A. Thomasson, R. Sui, M.S. Cox, A. Al–Rajehy
    Soil reflectance sensing for determining soil properties in precision agriculture
    Transactions of the ASAE, 44 (2001), pp. 1445-1453 View in ScopusGoogle Scholar
    Thorp and Tian, 2004 K.R. Thorp, L.F. Tian A review on remote sensing of weeds
    in agriculture Precision Agriculture, 5 (2004), pp. 477-508 View in ScopusGoogle
    Scholar Tian, 2002 L. Tian Development of a sensor-based precision herbicide application
    system Computers and Electronics in Agriculture, 36 (2002), pp. 133-149 View PDFView
    articleView in ScopusGoogle Scholar Tilling et al., 2007 S.K. Tilling, G.J. O''Leary,
    J.G. Ferwerda, S.D. Jones, G.J. Fitzgerald, D. Rodriguez, et al. Remote sensing
    of nitrogen and water stress in wheat Field Crops Research, 104 (2007), pp. 77-85
    View in ScopusGoogle Scholar Tucker, 1979 C.J. Tucker Red and photographic infrared
    linear combinations for monitoring vegetation Remote Sensing of Environment, 8
    (1979), pp. 127-150 View PDFView articleGoogle Scholar Varvel et al., 1997 G.E.
    Varvel, J.S. Schepers, D.D. Francis Ability for in-season correction of nitrogen
    deficiency in corn using chlorophyll meters Soil Science Society of America Journal,
    61 (1997), pp. 1233-1239 CrossRefView in ScopusGoogle Scholar Varvel et al., 2007
    G.E. Varvel, W.W. Wilhelm, J.F. Shanahan, J.S. Schepers An algorithm for corn
    nitrogen recommendations using a chlorophyll meter based sufficiency index Agronomy
    Journal, 99 (2007), pp. 701-706 CrossRefView in ScopusGoogle Scholar Viscarra
    Rossel et al., 2006 R.A. Viscarra Rossel, D.J.J. Walvoort, A.B. McBratney, L.J.
    Janik, J.O. Skjemstad Visible, near infrared, mid infrared or combined diffuse
    reflectance spectroscopy for simultaneous assessment of various soil properties
    Geoderma, 131 (2006), pp. 59-75 View PDFView articleView in ScopusGoogle Scholar
    Vogelmann et al., 1993 J.E. Vogelmann, B.N. Rock, D.M. Moss Red edge spectral
    measurements from sugar maple leaves International Journal of Remote Sensing,
    14 (1993), pp. 1563-1575 CrossRefView in ScopusGoogle Scholar Wang et al., 2006
    N. Wang, N. Zhang, M. Wang Wireless sensors in agriculture and food industry—recent
    development and future perspective Computers and Electronics in Agriculture, 50
    (2006), pp. 1-14 View PDFView articleCrossRefView in ScopusGoogle Scholar Whipker
    and Akridge, 2006 L.D. Whipker, J.D. Akridge Precision agricultural services dealership
    survey results Staff paper Dept. Agricultural Economics, Purdue University, W.
    Lafayette, IN, USA (2006) Google Scholar Wright and Gallant, 2007 C. Wright, A.
    Gallant Improved wetland remote sensing in Yellowstone National Park using classification
    trees to combine TM imagery and ancillary environmental data Remote Sensing of
    Environment, 107 (2007), pp. 582-605 View PDFView articleView in ScopusGoogle
    Scholar Wu et al., 2010a C. Wu, X. Han, Z. Niu, J. Dong An evaluation of EO-1
    hyperspectral Hyperion data for chlorophyll content and leaf area index estimation
    International Journal of Remote Sensing, 31 (2010), pp. 1079-1086 CrossRefView
    in ScopusGoogle Scholar Wu et al., 2010 C. Wu, L. Wang, Z. Niu, S. Gao, M. Wu
    Nondestructive estimation of canopy chlorophyll content using Hyperion and Landsat/TM
    images International Journal of Remote Sensing, 31 (2010), pp. 2159-2167 CrossRefView
    in ScopusGoogle Scholar Yang et al., 2000 C. Yang, J.H. Everitt, J.M. Bradford,
    D.E. Escobar Mapping grain sorghum growth and yield variations using airborne
    multispectral digital imagery Transactions of the ASAE, 43 (2000), pp. 1927-1938
    View in ScopusGoogle Scholar Yao et al., 2010 H.L. Yao, L. Tang, Tian, R.L. Brown,
    D. Bhatnagar, T.E. Cleveland Using hyperspectral data in precision farming applications.
    Ch. 25 P.S. Thenkabail, J.G. Lyon, A. Huete (Eds.), Hyperspectral remote sensing
    of vegetation, CRC Press, Boca Raton, FL (2010), p. 705 CrossRefView in ScopusGoogle
    Scholar Zarco-Tejada et al., 2005 P. Zarco-Tejada, A. Berjón, R. López-Lozano,
    J. Miller, P. Martín, V. Cachorro, et al. Assessing vineyard condition with hyperspectral
    indices: leaf and canopy reflectance simulation in a row-structured discontinuous
    canopy Remote Sensing of Environment, 99 (2005), pp. 271-287 View PDFView articleView
    in ScopusGoogle Scholar Zarco-Tejada et al., 2004 P.J. Zarco-Tejada, J.R. Miller,
    A. Morales, A. Berjón, J. Agüera Hyperspectral indices and model simulation for
    chlorophyll estimation in open-canopy tree crops Remote Sensing of Environment,
    90 (2004), pp. 463-476 View PDFView articleView in ScopusGoogle Scholar Zhang
    et al., 2002 N. Zhang, M. Wang, N. Wang Precision agriculture: a worldwide overview
    Computers and Electronics in Agriculture, 36 (2002), pp. 113-132 View PDFView
    articleView in ScopusGoogle Scholar Cited by (1287) Tackling sustainable development
    goals through new space 2024, Project Leadership and Society Show abstract Economic
    and environmental benefits of digital agricultural technologies in crop production:
    A review 2024, Smart Agricultural Technology Show abstract Effects of different
    nitrogen fertilization systems on crop yield and nitrogen use efficiency – Results
    of a field experiment in southern Germany 2024, Heliyon Show abstract Quantifying
    canopy nitrogen of Aman rice utilizing multi-temporal unmanned aerial systems
    2024, Remote Sensing Applications: Society and Environment Show abstract Application
    of precision agriculture technologies in Central Europe-review 2024, Journal of
    Agriculture and Food Research Show abstract Optical remote sensing of crop biophysical
    and biochemical parameters: An overview of advances in sensor technologies and
    machine learning algorithms for precision agriculture 2024, Computers and Electronics
    in Agriculture Show abstract View all citing articles on Scopus ☆ Developed from
    a presentation at AGRI-SENSING 2011 – International Symposium on Sensing in Agriculture
    in Memory of Dahlia Greidinger, Haifa, Israel. View Abstract Copyright © 2012
    IAgrE. Published by Elsevier Ltd. All rights reserved. Part of special issue Special
    Issue: Sensing Technologies for Sustainable Agriculture Edited by Victor Alchanatis,
    Yafit Cohen Download full issue Other articles from this issue Field partition
    by proximal and remote sensing data fusion April 2013 Daniela De Benedetto, …,
    Rosanna Tamborrino View PDF Spatial–spectral processing strategies for detection
    of salinity effects in cauliflower, aubergine and kohlrabi April 2013 Ronit Rud,
    …, Victor Alchanatis View PDF Examination of the Bowen ratio energy balance technique
    for evapotranspiration estimates in screenhouses April 2013 Uri Dicken, …, Josef
    Tanny View PDF View more articles Recommended articles Article Metrics Citations
    Citation Indexes: 1217 Patent Family Citations: 1 Policy Citations: 14 Captures
    Readers: 2191 Mentions References: 1 Social Media Shares, Likes & Comments: 1
    View details About ScienceDirect Remote access Shopping cart Advertise Contact
    and support Terms and conditions Privacy policy Cookies are used by this site.
    Cookie settings | Your Privacy Choices All content on this site: Copyright © 2024
    Elsevier B.V., its licensors, and contributors. All rights are reserved, including
    those for text and data mining, AI training, and similar technologies. For all
    open access content, the Creative Commons licensing terms apply.'
  inline_citation: '>'
  journal: Biosystems Engineering
  limitations: '>'
  pdf_link: null
  publication_year: 2013
  relevance_score1: 0
  relevance_score2: 0
  title: 'Twenty five years of remote sensing in precision agriculture: Key advances
    and remaining knowledge gaps'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1016/j.compag.2010.02.007
  analysis: '>'
  authors:
  - Sindhuja Sankaran
  - Ashish Mishra
  - Reza Ehsani
  - Cristina E. Davis
  citation_count: 983
  full_citation: '>'
  full_text: '>

    Skip to main content Skip to article Journals & Books Search Register Sign in
    Brought to you by: University of Nebraska-Lincoln View PDF Download full issue
    Outline Abstract Keywords 1. Introduction 2. Molecular techniques of plant disease
    detection 3. Spectroscopic and imaging techniques for disease detection 4. Profiling
    of plant volatile organic compounds for disease detection 5. Future directions
    6. Summary and conclusions References Show full outline Cited by (947) Figures
    (1) Tables (6) Table 1 Table 2 Table 3 Table 4 Table 5 Table 6 Computers and Electronics
    in Agriculture Volume 72, Issue 1, June 2010, Pages 1-13 Review A review of advanced
    techniques for detecting plant diseases Author links open overlay panel Sindhuja
    Sankaran a, Ashish Mishra a, Reza Ehsani a, Cristina Davis b Show more Add to
    Mendeley Share Cite https://doi.org/10.1016/j.compag.2010.02.007 Get rights and
    content Abstract Diseases in plants cause major production and economic losses
    in agricultural industry worldwide. Monitoring of health and detection of diseases
    in plants and trees is critical for sustainable agriculture. To the best of our
    knowledge, there is no sensor commercially available for real-time assessment
    of health conditions in trees. Currently, scouting is most widely used mechanism
    for monitoring stress in trees, which is an expensive, labor-intensive, and time-consuming
    process. Molecular techniques such as polymerase chain reaction are used for the
    identification of plant diseases that require detailed sampling and processing
    procedure. Early information on crop health and disease detection can facilitate
    the control of diseases through proper management strategies such as vector control
    through pesticide applications, fungicide applications, and disease-specific chemical
    applications; and can improve productivity. The present review recognizes the
    need for developing a rapid, cost-effective, and reliable health-monitoring sensor
    that would facilitate advancements in agriculture. It describes the currently
    used technologies that can be used for developing a ground-based sensor system
    to assist in monitoring health and diseases in plants under field conditions.
    These technologies include spectroscopic and imaging-based, and volatile profiling-based
    plant disease detection methods. The paper compares the benefits and limitations
    of these potential methods. Previous article in issue Next article in issue Keywords
    Plant diseasesImaging techniquesSpectroscopyVolatile profilingGC–MS 1. Introduction
    Plant diseases cause major production and economic losses in agriculture and forestry.
    For example, soybean rust (a fungal disease in soybeans) has caused a significant
    economic loss and just by removing 20% of the infection, the farmers may benefit
    with an approximately 11 million-dollar profit (Roberts et al., 2006). It is estimated
    that the crop losses due to plant pathogens in United Stated result in about 33
    billion dollars every year. Of this, about 65% (21 billion dollars) could be attributed
    to non-native plant pathogens (Pimentel et al., 2005). Some of the diseases caused
    by introduced pathogenic species are chestnut blight fungus, Dutch elm disease,
    and huanglongbing citrus disease (Pimentel et al., 2005, Li et al., 2006). The
    bacterial, fungal, and viral infections, along with infestations by insects result
    in plant diseases and damage. There are about 50,000 parasitic and non-parasitic
    plant diseases of plants in United States (Pimentel et al., 2005). Upon infection,
    a plant develops symptoms that appear on different parts of the plants causing
    a significant agronomic impact (López et al., 2003). Many such microbial diseases
    with time spread over a larger area in groves and plantations through accidental
    introduction of vectors or through infected plant materials. Another route for
    the spread of pathogens is through ornamental plants that act as hosts. These
    plants are frequently sold through mass distribution before the infections are
    known. An early disease detection system can aid in decreasing such losses caused
    by plant diseases and can further prevent the spread of diseases. After the onset
    of plant disease symptoms, the presence of disease in plants is verified using
    disease detection techniques. Presently, the plant disease detection techniques
    available are enzyme-linked immunosorbent assay (ELISA), based on proteins produced
    by the pathogen, and polymerase chain reaction (PCR), based on specific deoxyribose
    nucleic acid (DNA) sequences of the pathogen (Prithiviraj et al., 2004, Das, 2004,
    Li et al., 2006, Saponari et al., 2008, Ruiz-Ruiz et al., 2009, Yvon et al., 2009).
    In spite of availability of these techniques, there is a demand for a fast, sensitive,
    and selective method for the rapid detection of plant diseases. Disease detection
    techniques can be broadly classified into direct and indirect methods. Fig. 1
    summarizes some of these methods of disease detection. An advanced plant disease
    detection technique can provide rapid, accurate, and reliable detection of plant
    diseases in early stages for economic, production, and agricultural benefits.
    Download : Download full-size image Fig. 1. Methods of plant disease detection.
    In the present paper, advanced techniques of ground-based disease detection that
    could be possibly integrated with an automated agricultural vehicle are reviewed.
    In ground-based disease detection studies, both field-based and laboratory-based
    experiments are discussed in this paper. The field-based studies refer to studies
    that involve spectral data collection under field conditions, whereas laboratory-based
    studies refer to data collection under laboratory conditions. The laboratory-based
    experiments provide strong background knowledge (such as the experimental protocol
    and statistical algorithm for classification) for the field-based applications.
    This paper describes two approaches taken to detect plant diseases. The first
    approach involves the application of spectroscopic and imaging techniques for
    disease detection, whereas the second approach describes the application of volatile
    organic metabolites as possible biomarkers for disease detection. These two approaches
    were selected as they could be easily integrated with an agricultural vehicle
    for a fast, reliable, and real-time plant disease monitoring for disease control
    and management. The early detection of plant diseases (before the onset of disease
    symptoms) could be a valuable source of information for executing proper pest
    management strategies and disease control measures to prevent the development
    and the spread of diseases. 2. Molecular techniques of plant disease detection
    In recent years, molecular techniques of plant disease detection have been well
    established. The sensitivity of the molecular techniques refers to the minimum
    amount of microorganism that can be detected in the sample. López et al. (2003)
    reported that the sensitivity of the molecular techniques for detecting bacteria
    ranged from 10 to 106 colony forming units/mL. The commonly used molecular techniques
    for disease detection are ELISA and PCR (PCR and real-time PCR). Other molecular
    techniques include immunoflourescence (IF), flow cytometry, fluorescence in situ
    hydridization (FISH), and DNA microarrays. In the ELISA-based disease detection,
    the microbial protein (antigen) associated with a plant disease is injected into
    an animal that produces antibodies against the antigen. These antibodies are extracted
    from the animal''s body and used for antigen detection with a fluorescence dye
    and enzymes. In presence of the disease-causing microorganism (antigen), the sample
    would fluoresce, thus confirming the presence of a particular plant disease. In
    PCR-based disease detection, the genetic material (DNA) of the disease-causing
    microorganism is extracted, purified, and amplified before performing the gel
    electrophoresis. The presence of a specific band in gel electrophoresis confirms
    the presence of the plant-disease causing organism. Different types of immunological
    and PCR techniques are described by López et al. (2003). There are number of studies
    on disease detection using the molecular techniques. Efforts are ongoing to improve
    the efficiency of these techniques. Table 1 summarizes few studies on plant disease
    detection using molecular techniques. López et al. (2003) reviewed the various
    molecular techniques used for detecting pathogenic viruses and bacteria in plants.
    Their review paper elaborates the molecular methods of plant disease detection,
    including different types of PCR and ELISA-based techniques. Schaad and Frederick
    (2002), and Henson and French (1993) described the applications of PCR technique
    for the diagnosis of plant diseases. Alvarez (2004) reported that there are about
    97 commercially available immunodiagnostic test kits for the detection of bacterial
    pathogens in plants. Table 1. Examples of some studies on plant disease detection
    using molecular techniques. Plant/Trees Pathogen Type Molecular method Reference
    Grapevine Xylella fastidiosa Bacteria PCR, ELISA Minsavage et al. (1994) Onion
    Sclerotium cepivorum Fungi PCR Anwar Haq et al. (2003) Olive Pseudomonas savastanoi
    pv. savastanoi. Bacteria PCR, Hybridization Bertolini et al. (2003) Sweet orange
    Candidatus Liberibacter asiaticus. Bacteria PCR Das (2004) Sweet orange Candidatus
    Liberibacter asiaticus, Ca. L. americanus, Ca. L. africanus Bacteria PCR Teixeira
    et al. (2005) Citrus Candidatus Liberibacter Bacteria PCR Li et al. (2006) Citrus
    Xylella fastidiosa, Methylobacterium mesophilicum Bacteria PCR Lacava et al. (2006)
    Citrus Citrus tristeza virus Virus PCR, ELISA Saponari et al. (2008) Sweet orange
    Candidatus Liberibacter asiaticus Bacteria Isothermal, chimeric primer-initiated
    amplification of nucleic acids + cycling probe technology Urasaki et al. (2008)
    Rice Burkholderia glumae Bacteria Fluorescence PCR Fang et al. (2009) Potato Candidatus
    Liberibacter solanacearum Bacteria PCR Li et al. (2009a) Citrus Citrus leaf blotch
    virus Virus PCR Ruiz-Ruiz et al. (2009) Tomato Pepino mosaic virus Virus PCR,
    ELISA Gutiérrez-Aguirre et al. (2009) Almond Candidatus Phytoplasma prunorum Bacteria
    PCR Yvon et al. (2009) Some of the limitations of the molecular techniques are
    that they are time-consuming and labor-intensive, and require an elaborate procedure,
    especially during sample preparation (collection and extraction) to obtain reliable
    and accurate results on plant disease detection. In addition, these techniques
    require consumable reagents that must be tailored to detect each specific pathogen
    (e.g. sequence-specific primers for PCR). The molecular techniques could be used
    as robust tool to ensure the presence of plant diseases, but cannot be used as
    a preliminary screening tool for processing large number of plant samples due
    to the time involved in the process. Thus, spectroscopic techniques can be potential
    method for rapid detection of plant diseases. In the present review paper, molecular
    methods of plant disease detection are not discussed in detail as a number of
    review papers are available in the literature. 3. Spectroscopic and imaging techniques
    for disease detection Recent developments in agricultural technology have lead
    to a demand for a new era of automated non-destructive methods of plant disease
    detection. It is desirable that the plant disease detection tool should be rapid,
    specific to a particular disease, and sensitive for detection at the early onset
    of the symptoms (López et al., 2003). The spectroscopic and imaging techniques
    are unique disease monitoring methods that have been used to detect diseases and
    stress due to various factors, in plants and trees. Current research activities
    are towards the development of such technologies to create a practical tool for
    a large-scale real-time disease monitoring under field conditions. Various spectroscopic
    and imaging techniques have been studied for the detection of symptomatic and
    asymptomatic plant diseases. Some the methods are: fluorescence imaging (Bravo
    et al., 2004, Moshou et al., 2005, Chaerle et al., 2007), multispectral or hyperspectral
    imaging (Moshou et al., 2004, Shafri and Hamdan, 2009, Qin et al., 2009), infrared
    spectroscopy (Spinelli et al., 2006, Purcell et al., 2009), fluorescence spectroscopy
    (Marcassa et al., 2006, Belasque et al., 2008, Lins et al., 2009), visible/multiband
    spectroscopy (Yang et al., 2007, Delalieux et al., 2007, Chen et al., 2008), and
    nuclear magnetic resonance (NMR) spectroscopy (Choi et al., 2004). Hahn (2009)
    reviewed multiple methods (sensors and algorithms) for pathogen detection, with
    special emphasis on postharvest diseases. The spectroscopic and imaging techniques
    could be integrated with an autonomous agricultural vehicle that can provide information
    on disease detection at early stages to control the spread of plant diseases.
    This technology can also be applied to identify stress levels and nutrient deficiencies
    in plants. In regard to plant disease detection, significant research is ongoing
    on the prospective of this technology from last few decades. Spectroscopic technology
    has been successfully applied for plant stress detection such as water-stress
    detection and nutrient-stress detection. In addition, there have also been significant
    applications for monitoring the quality of postharvest fruits and vegetables.
    Some of the commonly used spectroscopic and imaging techniques are described in
    the following sections. Table 2, Table 3 summarize few studies on plant disease
    detection using spectroscopic and imaging techniques. Some postharvest applications
    have also been discussed in this paper, as the knowledge on statistical models
    and methodology for data collection for postharvest applications is transferrable
    for real-time plant disease detection. Table 2. Examples of studies on plant disease
    detection using spectroscopic techniques. Plant Disease/Damage Statistical Methods
    Optimum spectral range Reference Fluorescence Spectroscopy Citrus Citrus canker
    – 452, 685 and 735 nm Belasque et al. (2008)  Visible and Infrared Spectroscopy
    Rice Infested with brown planthopper (Nilaparvata luge) – 737–925 nm Yang and
    Cheng (2001) Wheat Powdery mildew and take-all disease Analysis of variance, correlation
    and regression analysis 490780, 510780, 5161300 and 5401300 nm Graeff et al. (2006)
    Rice Brown planthopper and leaffolder infestation Linear regression models 426
    nm Yang et al. (2007) Kiwifruit Gray mold, Sclerotinia rot Principal component
    analysis – Costa et al. (2007) Wheat Yellow rust Regression – Huang et al. (2007)
    Tomato Leaf miner damage – 800 to 1100 nm, 1450 and 1900 nm Xu et al. (2007) Grapevine
    Grapevine leafroll disease Discriminant analysis 752, 684 and 970 nm Naidu et
    al. (2009)  Nuclear Magnetic Resonance (NMR) Spectroscopy Catharanthus roseus
    (ornamental plant) Phytoplasmas causing yellowing disease Principal component
    analysis – Choi et al. (2004) Table 3. Examples of studies on plant disease detection
    using imaging techniques. Plant Disease/Damage Statistical Methods Optimum spectral
    range Reference Wheat Scab (Fusarium head blight) Step discrimination and discriminant
    analysis 568, 715 nm (550, 605, 623, 660, 697 and 733 nm) Delwiche and Kim (2000)
    Tomato Late blight disease Minimum noise fraction transformation and spectral
    angle mapping-based classification 700–750 nm, 750–930 nm, 950–1,030 nm, and 1,040–1,130
    nm Zhang et al., 2003, Zhang et al., 2005 Wheat Yellow rust, nutrient deficiency
    Self-organizing map neural network, quadratic discriminant analysis 680, 725 and
    750 nm Moshou et al., 2005, Moshou et al., 2006 Wheat Yellow rust Regression analysis
    – Huang et al. (2007) Grapefruit (fruit) Citrus canker Principal component analysis
    553, 677, 718 and 858 nm Qin et al. (2008) Vidalia sweet onions Sour skin disease
    Image analysis 1,150–1,280 nm Wang et al. (2009) Sweet orange Blue mold, Browning
    rot Difference in reflectance 540 and 680 nm Sighicelli et al. (2009) 3.1. Fluorescence
    spectroscopy Fluorescence spectroscopy refers to a type of spectroscopic method,
    where the fluorescence from the object of interest is measured after excitation
    with a beam of light (usually ultraviolet spectra). For the last twenty years,
    the laser-induced fluorescence has been used for vegetative studies, such as to
    monitor stress levels and physiological states in plants (Belasque et al., 2008).
    Two types of fluorescence: (i) blue-green fluorescence in about 400–600 nm range,
    and (ii) chlorophyll fluorescence in about 650–800 nm range, are produced by green
    leaves. The fluorescence spectroscopy can be utilized to monitor nutrient deficiencies,
    environmental conditions based stress levels, and diseases in plants (Cerovic
    et al., 1999, Belasque et al., 2008). Belasque et al. (2008) employed fluorescence
    spectroscopy to detect stress caused by citrus canker (bacterial disease caused
    by Xanthomonas citri–X. axonopodis pv. citri) and mechanical injury. A portable
    fluorescence spectroscopy system was taken to the greenhouse and the measurement
    probe was placed 2 mm above the leaf (attached to greenhouse plants) for collecting
    data from different samples during the period of study (60 days). The spectral
    data were further processed and analyzed in the laboratory. A 532 nm 10 mW excitation
    laser was used for excitation and ratios between fluorescence at different wavelengths
    were employed to monitor the stress caused by bacterial infection. The samples
    of leaves collected from the field (detached leaves) as well as leaves from greenhouse
    plants (attached leaves) were analyzed using the system. The three ratios used
    were: (i) ratio between fluorescence intensity at 452 and 685 nm, (ii) ratio between
    fluorescence intensity at 452 nm and 735 nm, and (iii) ratio between fluorescence
    intensity at 685 nm and 735 nm. Fluorescence of citrus leaves was monitored for
    60 days under four different conditions: leaves with no stress, leaves with mechanical
    stress, leaves with disease, and leaves with disease and mechanical stress. The
    studies reported the potential of fluorescence spectroscopy for disease detection
    and discrimination between the mechanical and diseased stress. A similar approach
    was taken to detect water stress and differentiate citrus canker leaves from variegated
    chlorosis leaves (Marcassa et al., 2006). The above studies could classify healthy
    from citrus canker-affected leaves, but were unable to identify water stress and
    distinguish between variegated chlorosis and citrus canker-infected leaves. The
    authors did not yet present any statistical analysis to evaluate the ability of
    the technique to discriminate or classify different plant conditions. Lins et
    al. (2009) conducted field experiments to discriminate citrus canker-stressed
    leaves from chlorosis-infected (caused by Xylella fastidiosa bacteria) and healthy
    leaves. In addition, they conducted leaf detachment experiments to monitor effect
    of time (up to 12 h) on fluorescence of detached leaves using fluorescence spectroscopy.
    In their study, two indices/figures of merit were used to assess the difference
    between healthy and citrus canker-infected leaves. In spite of having a clear
    discrimination between the healthy and citrus canker-infected leaves, the citrus
    canker-affected leaves showed similar fluorescence output as that of chlorosis-affected
    leaves under field condition. The paper reported that one of the indices (figure
    of merit-1) was less influenced by the leaf detachment time (1–12 h) than the
    other (figure of merit-2). The above report recommended the application of a range
    of spectral data rather than fluorescence alone for a reliable discrimination
    results, and further work needs to be done to classify different plant conditions
    using statistical tools. Methods such as principal component analysis (PCA), discriminant
    analysis, and neural network-based classification algorithms can be applied to
    analyze the results obtained from fluorescence spectroscopy. Methods such as PCA,
    parallel factor analysis, cluster analysis, partial least square (PLS) regression,
    and Fischer''s linear discriminant analysis (LDA) can be applied for classifying
    fluorescent spectrometric data having two or more classes (Guimet, 2005). 3.2.
    Visible and infrared spectroscopy Similar to fluorescence spectroscopy, visible
    and infrared spectroscopy have been used as a rapid, non-destructive, and cost-effective
    method for the detection of plant diseases. It is a fast-developing technology
    used for varied applications (Ramon et al., 2002, Delwiche and Graybosch, 2002,
    Pontius et al., 2005, Gomez et al., 2006, Zhang et al., 2008a, Zhang et al., 2008b,
    Guo et al., 2009, Sundaram et al., 2009). Studies have also been conducted on
    the detection of stress, injury, and diseases in plants using this technology
    (Polischuk et al., 1997, Spinelli et al., 2006, Naidu et al., 2009). The visible
    and infrared regions of the electromagnetic spectra are known to provide the maximum
    information on the physiological stress levels in the plants (Muhammed, 2002,
    Muhammed, 2005, Xu et al., 2007) and thus, some of these wavebands specific to
    a disease can be used to detect plant diseases (West et al., 2003), even before
    the symptoms are visible. In general, visible spectroscopy is used for disease
    detection in plants in combination with infrared spectroscopy (Malthus and Madeira,
    1993, Bravo et al., 2003, Huang et al., 2004, Larsolle and Muhammed, 2007). Spinelli
    et al. (2006) assessed the near infrared (NIR)-based technique for detecting fire
    blight disease in the asymptomatic pear plants under greenhouse conditions. The
    NIR technique did not exhibit potential for classifying infected plants from that
    of healthy ones, while electronic nose system showed a better potential to classify
    diseased plants. The authors reported that the possible reason for the inability
    of the NIR based technique to distinguish diseased from healthy plants could be
    due to a very small leaf scan area (2 mm2 in this study). The authors recommended
    that a multidimensional image analysis could provide more information on the diseased
    plants rather than a smaller field of view. This signifies that the spectroscopy-based
    imaging techniques could be more robust in disease identification at early stages
    in plant diseases than spectroscopic methods alone. Purcell et al. (2009) investigated
    the application of NIR spectroscopy for the determination and rating of sugarcane
    resistance against Australian sugarcane disease, Fiji leaf gall. The leaf samples
    from the cane stalks were analyzed with a Fourier transform (FT)-NIR instrument
    in 2–4 days after the sugarcane stalks were removed. The signal in the spectral
    range of 11,000–4000 cm−1 was procured. Principal component analysis and PLS-based
    statistical methods were used to analyze the data. The second derivative of the
    signal in the spectral range was also determined to verify if the signal is better
    represented the disease for analysis. The authors reported that the PLS-based
    method was effective in predicting the disease rating in sugarcane. The data analysis
    procedure used for the classification of postharvest food products can be applicable
    for plant disease detection. Thus, the knowledge from one application (on statistical
    algorithm, data processing, experimental protocol, etc.) can be transferred to
    other possible applications. For example, Sirisomboon et al. (2009) used visible
    spectra along with NIR spectra (600–1100 nm) to identify defective pods during
    soybean processing. In addition to PCA, soft independent modeling of class analogy
    (SIMCA) and PLS-discriminant analysis were used to classify the groups. The authors
    reported that the SIMCA-based model was able to discriminate different groups
    of soybean better than the PLS-based model. Naidu et al. (2009) used leaf spectral
    reflectance to identify viral infection (under field conditions) in grapevines
    (Vitis vinifera L.) that cause grapevine leafroll disease. A portable spectrometer
    was used to collect reflectance data from each leaf of the plant using a plant-probe
    attachment device having a leaf clip. In addition to the green, near infrared,
    and mid infrared region of the spectra, vegetative indices were used to assess
    the applicability of spectral reflectance in identifying the disease. Discriminant
    analysis was performed to classify the infected leaves with and without symptoms
    with that of non-infected leaves. The different categories of leaves could be
    clearly differentiated with improved accuracies when both the vegetative indices
    and individual reflectance bands were used. A maximum of 75% accuracy was achieved
    in the study. Huang and Apan (2006) collected hyperspectral data using portable
    spectrometer under field conditions to detect Sclerotinia rot disease in celery.
    PLS regression analysis was performed to analyze the spectral reflectance data.
    The first and second derivatives were estimated to test their effectiveness in
    reducing the root mean square error during the validation of the developed model.
    It was reported that the raw data-based model produced lower root mean square
    errors than the first and second derivatives. The authors also stated that the
    reflectance in the visible and infrared range from 400 to 1300 nm were sufficient
    in acquiring similar results as that of entire spectra (400–2500 nm). The cross-validation
    results using raw, first derivative, and second derivative data provided a prediction
    error of 11–13%. Chen et al. (2008) investigated the application of hyperspectral
    reflectance to identify cotton canopy infected with Verticillium wilt. The data
    were collected using a portable spectroradiometer under field conditions and it
    was analyzed in the laboratory. The authors reported that among the visible and
    infrared spectra, the first derivative of the infrared spectra in the wavelength
    range between 731 and 1317 nm were most effective in predicting the Verticillium
    wilt in cotton canopy accurately based on the developed models. Other sensitive
    regions for prediction of infection severity levels were found to be from 780
    to 1300 nm and the first derivative of the spectra from 680 to 760 nm. Yang et
    al. (2007) studied brown planthoppers and leaf-folder infestations in rice plants.
    The infested conditions of the plants were ranked and efforts were made to identify
    the extent of infestations using spectroscopic reflectance (350–2400 nm) data
    collected under field conditions. The results indicated that the spectral range
    from 426 to 1450 nm showed the maximum correlation intensity. The changes in spectral
    properties were low in visible and ultraviolet (UV) range, whereas the infrared
    region (740–2400 nm) yielded the maximum change in spectral signature. Delalieux
    et al. (2007) used hyperspectral reflectance data (350–2500 nm) to detect apple
    scab caused by Venturia inaequalis. The study involved the identification of infected
    trees and selection of wavelengths best suited for classifying the infected leaves
    from those of the healthy leaves. The spectral data were analyzed using methods
    as LDA, logistic regression analysis (for each wavelength), partial least squares
    logistic discriminant analysis (PLS-LDA), and tree-based modeling for classifying
    the infected and healthy leaves. The paper reported that the spectral features
    from 1350 to 1750 nm and 2200 to 2500 nm were effective for the classification
    of the infected leaves from healthy leaves at early stages, whereas 580–660 nm
    and 688–715 nm were effective in identifying infected leaves at their developed
    stages of infection. Among the statistical methods, logistic regression analysis,
    PLS-LDA, and tree-based modeling were preferred for classification. The authors
    recommended PLS-LDA and tree-based modeling methods as they are simpler, and less
    computationally- and time-intensive. Kobayashi et al. (2001) utilized multispectral
    radiometer and airborne multispectral scanner for the identification of panicle
    blast in rice. The spectral range for airborne multispectral scan was selected
    based on ground experiments. The four spectral bands of 400–460 nm, 490–530 nm
    or 530–570 nm, 650–700 nm, and 950–1100 nm were utilized for scanning (instantaneous
    field of view = 2.5 mrad, ground resolution = 0.94 m at 300 m height). The magnitude
    of reflectance ratios (R470/R570, R520/R675, and R570/R675) decreased with an
    increase in frequency of panicle blast occurrence. Wang et al. (2002) used PLS
    and artificial neural network (ANN) models on the visible-IR reflectance data
    for classifying damaged soybean seeds. The authors reported that the ANN yielded
    higher overall as well as individual-class classification accuracies than PLS
    models. Various studies have used different methods/models for the classification
    of diseases/conditions of plants based on spectral data. For an instance, Roggo
    et al. (2003) utilized eight classification models (linear discriminant analysis,
    k-nearest neighbors, soft independent modeling of class analogy, discriminant
    partial least squares (DPLS), procrustes discriminant analysis (PDA), classification
    and regression tree, probabilistic neural network, and learning vector quantization-based
    neural network) for qualitative determination of sugarbeet. They found that SIMCA,
    DPLS, and PDA yielded the highest classification accuracies that those of other
    models. Wu et al. (2008) used PCA-based back-propagation neural network (BPNN)
    model and PLS wavelength-based BPNN for detection of Botrytis cinerea-affected
    eggplant leaves prior to the visibility of symptoms under laboratory conditions.
    The BPNN model yielded a maximum of 85% classification accuracy for predicting
    fungal infections. In addition to the statistical models for classification, many
    spectroscopy-based studies use different vegetative indices for evaluating the
    change in spectral reflectance at different plant conditions (diseased or healthy
    plant). Some of the vegetative indices are summarized in Table 4. Table 4. Vegetative
    indices used in spectroscopic studies for disease detection. Vegetative Index
    Estimation Reference Disease index (fD) (specific for individual study) Moshou
    et al. (2005) Normalized difference vegetation index (NDVI) Yang and Cheng (2001),
    Bravo et al. (2004), Yang et al. (2007), Naidu et al. (2009) Green normalized
    difference vegetation index (Green NDVI) Yang et al. (2007) Water Band Index (IWB)
    Xu et al. (2007) Soil-adjusted vegetation index (SAVI) Yang et al. (2007) L =
    0.5 Other indices Yang et al. (2007) Photochemical reflectance index (PRI) Huang
    et al. (2007), Naidu et al. (2009) Red-edge vegetation stress index (RVSI) Naidu
    et al. (2009) Modified chlorophyll (a and b) absorption in reflectance index (MCARI)
    Naidu et al. (2009) Visible atmospherically resistance index (VARI) Naidu et al.
    (2009) Water Index (WI) Naidu et al. (2009) I: Fluorescence intensity; R: Reflectance.
    3.3. Fluorescence imaging The change in blue-green fluorescence and chlorophyll
    florescence of the plants upon ultraviolet excitation could provide the status
    of physiological condition of the plant (Belasque et al., 2008). Fluorescence
    imaging is an advancement of fluorescence spectroscopy, where fluorescence images
    (rather than single spectra) are obtained using a camera. A xenon or halogen lamp
    is used as a UV light source for fluorescence excitation, and the fluorescence
    at specific wavelengths are recorded using the charge-coupled device (CCD)-based
    camera system (Bravo et al., 2004, Lenk and Buschmann, 2006, Chaerle et al., 2007,
    Lenk et al., 2007). The regions of electromagnetic spectra that are commonly used
    for fluorescence imaging are blue (440 nm), green (520–550 nm), red (690 nm),
    far red (740 nm), and near infrared (800 nm) (Lenk and Buschmann, 2006, Chaerle
    et al., 2007). Lenk et al. (2007) described the multispectral fluorescence and
    its possible application in monitoring fruit quality, photosynthetic activities,
    tissue structures, and disease symptoms in plants; and the basic instrumentation
    required. The chlorophyll fluorescence imaging can be an effective tool in monitoring
    leaf diseases (Chaerle et al., 2004, Scharte et al., 2005, Lenk et al., 2007).
    Chaerle et al. (2007) used blue-green fluorescence to evaluate the effectiveness
    of this technique in observing the development of tobacco mosaic virus (TMV) infection
    in tobacco plants. A temporal effect of TMV infection on the fluorescence (blue-green
    and chlorophyll fluorescence) of infected plants was observed. The reflectance
    image at 550 and 800 nm were acquired and considered as the reference images.
    The authors reported an increase in blue, green, and chlorophyll fluorescence
    after about 40–55 h upon inoculation of TMV. The fluorescence imaging demonstrated
    a visible difference between the infected and non-infected leaves in short period
    of time (50 h) in comparison to the reference images (14 days for visible symptoms
    of infection). Bravo et al. (2004) used fluorescence imaging for detecting yellow
    rust in winter wheat. They acquired two fluorescence images: a background image
    without the xenon lamp source and a fluorescence image with the xenon lamp source
    during the experiments. The fluorescence image utilized for the analysis was obtained
    by subtracting fluorescence image from the background image. The fluorescence
    was measured at 450, 550, 690, and 740 nm. The authors stated that the difference
    between the fluorescence at 550 and 690 nm were higher in the diseased portion
    of the leaves, while it was very low for healthy regions of the leaves. Quadratic
    discriminant analysis (QDA) was utilized to differentiate the healthy from the
    infected plants. Results indicated that though the methods was not effective in
    differentiating the healthy from mildly infected plants, QDA could classify healthy
    and diseased plants with an accuracy of 71% and 96%, respectively. Moshou et al.
    (2005) investigated the applicability of hyperspectral reflectance imaging in
    combination with multispectral fluorescence imaging through sensor fusion to detect
    yellow rust (Puccinia striiformis) disease of winter wheat. The hyperspectral
    imaging was performed under ambient condition in winter wheat plots, whereas fluorescence
    images were procured upon UV-excitation. The authors reported that when the sensor
    information from the fluorescence and multispectral imaging were combined, QDA-based
    classification accuracy of the healthy plants improved from 71–90% to 97%. The
    classification accuracy of the diseased plants and healthy plants further improved
    to 98.7% and 99.4%, respectively, when the self-organizing map (SOM)-based neural
    network was used for the plant classification. The above studies indicate the
    possibility for using imaging techniques for disease identification. The imaging
    techniques are an improvement over spectroscopic techniques as these methods acquire
    spectral information over a larger area and provide three-dimensional spectral
    information in the form of images. 3.4. Hyperspectral imaging In recent years,
    hyperspectral imaging is gaining considerable interest for its application in
    precision agriculture (Okamoto et al., 2009). In the hyperspectral imaging, the
    spectral reflectance of each pixel is acquired for a range of wavelengths in the
    electromagnetic spectra. The wavelengths may include the visible and infrared
    regions of the electromagnetic spectra. The hyperspectral imaging is similar to
    multispectral imaging, the difference being a broader range of wavelengths (more
    number of spectral bands) being scanned for each pixel in the hyperspectral imaging.
    The resulting information is a set of pixel values (intensity of the reflectance)
    at each wavelength of the spectra in the form of an image. Hyperspectral imaging
    is often used for monitoring the quality of food products (Kim et al., 2001, Kim
    et al., 2002, Mehl et al., 2004, Yao et al., 2005, Lee et al., 2005, Tallada et
    al., 2006, Gowen et al., 2007, Mahesh et al., 2008, Sighicelli et al., 2009).
    Aleixos et al. (2002) used multispectral imaging of citrus fruits to assess the
    quality of the fruits for developing a machine vision system. Gowen et al. (2007)
    reviewed the application of hyperspectral imaging for food quality control and
    food safety applications. The authors discussed the components of hyperspectral
    imaging system, different image processing techniques, and various applications
    in food quality and safety. Some of the major challenges in hyperspectral imaging-based
    plant disease detection are the selection of disease-specific spectral band and
    selection of statistical classification algorithm for a particular application,
    which depends on the data acquisition set-up under field conditions. For an example,
    Lu (2003), Xing and Baerdemaeker (2005), Xing et al. (2005), Nicolaï et al. (2006)
    and ElMasry et al. (2008) used hyperspectral imaging for the detection of bruises
    in apples and acquired different results. Lu (2003) reported that 1000 nm to 1340
    nm were best for bruise detection, whereas Xing et al. (2005) and ElMasry et al.
    (2008) reported bands within range 558–960 nm were suitable for the identification
    of bruises in apple. Blasco et al. (2007) applied multi-spectral computer vision
    using non-visible (ultraviolet, IR, and fluorescence) and visible multiple spectra
    for citrus sorting. The anthracnose was classified better with NIR images (86%),
    whereas green mold was more accurately classified with fluorescence imaging (94%).
    The stem-end injury was classified up to 100% using the ultraviolet spectra in
    this study. This study showed the utilization of hyperspectral bands for detecting
    different aspects of a single problem. Similarly, the hyperspectral imaging could
    be used for detecting different features within a plant to identify diseases.
    Each spectral region provides unique information about the plant. For instance,
    the reflectance at visible wavelength provides the information on the leaf pigmentations
    while, reflectance at infrared wavelength provides the physiological condition
    of the plant (Huang et al., 2007). Much attention has been drawn towards utilizing
    this technology for the plant disease detection for precision agriculture-based
    applications. Bravo et al. (2003) investigated the application of visible-NIR
    hyperspectral imaging for the early detection of yellow rust disease (Puccinia
    striiformis) in winter wheat. A discrimination model was developed using quadratic
    discriminant analysis for the classification of diseases from the healthy plants.
    The classification model yielded about 92–98% classification accuracy while classifying
    diseased plants. Similarly, Moshou et al. (2004) utilized a spectrograph to acquire
    spectral images from 460 to 900 nm to detect yellow rust in wheat. Statistical
    techniques such as QDA, SOM-, and multilayer perceptrons (MLP)-based artificial
    neural networks were used to classify the diseased from healthy wheat plants.
    Information from four wavebands, namely 543, 630, 750, and 861 nm were used for
    the classification models. The classification accuracies based on QDA and neural
    network (MLP) for the discriminating individual healthy plants were 92.0% and
    98.9%, and diseased plants were 97.8% and 99.4%, respectively. The study indicated
    a possibility of using this technology for early detection of diseases such as
    yellow rust in field conditions. Shafri and Hamdan (2009) used air-borne hyperspectral
    imaging for the detection of ganoderma basal stem rot disease in oil palm plantations.
    The authors used various vegetative indices and red edge techniques to classify
    the diseased from healthy plantations. The reported classification accuracies
    using different methods ranged from 73 to 84%. The results indicated that an aerial
    hyperspectral imaging could be used for disease detection and management of plantations
    in large scale. Qin et al. (2009) obtained hyperspectral images in the wavelength
    range 450–930 nm to detect citrus canker and other damages to Ruby red grapefruit.
    A spectral information divergence (SID)-based classification method yielded about
    96% classification accuracy for discriminating the diseased, damaged, and healthy
    fruits. Similarly, Lee et al. (2008) investigated the applicability of aerial
    hyperspectral imaging for the detection of greening in citrus plantation. Efforts
    were made to identify citrus greening in tree canopies using hyperspectral image,
    by classifying the image with spectral angle mapping (SAM) and spectral feature
    fitting (SFF) classification techniques (ENVI program). The authors were not able
    to identify the diseased canopies with high classification accuracies due to a
    large variability within the data. 3.5. Other imaging techniques The other imaging
    techniques that can used for detecting plant diseases are infrared thermography,
    terahetz spectroscopy, NMR spectroscopy, and X-ray imaging. As these techniques
    are not cost-effective, the present paper provides an overview of these methods
    and does not discuss them in detail. Infrared thermography refers to an imaging
    technique that utilizes the thermal energy of the infrared band and transforms
    the procured information into a visible image. Infrared thermography similar to
    other imaging techniques can be used for non-destructive monitoring of physiological
    status of plants (Chaerle et al., 1999, Chaerle et al., 2001). Lenthe et al. (2007)
    used infrared thermography to examine the possible relationship between the leaf
    microclimate and fungal diseases in wheat fields. Although microclimate can be
    determined from infrared thermography, direct diseased leaf area identification
    could not be established. Chaerle et al. (2003) and Chaerle and Van Der Straeten
    (2000) reviewed the application of imaging techniques in agronomy and stress detection.
    They reported that the stomatal changes in the leaves of the plants upon pathogen
    infection could be monitored by thermography (e.g. hydrogen peroxide produced
    by Pseudomonas syringae induces stomata in the leaves to close). Similarly, local
    temperature changes due to plant defense mechanisms against diseases can also
    help in monitoring plant diseases. Tobacco leaves produces salicylic acid (promoting
    thermal and stomatal change) that can be monitored using thermography. Other studies
    include presymptomatic detection of cucumber downy mildew- Pseudoperonospora cubensis
    (Lindenthal et al., 2005, Oerke et al., 2005, Oerke et al., 2006), fungal infection
    by Cercospora beticola in sugarbeet (Chaerle et al., 2004), and Brassica napus
    infection with Phoma lingam (Lamkadmi et al., 1996) among others. In recent years,
    terahertz (THz) frequencies (0.1–10 THz) are being utilized for measuring the
    water content in leaves. The water stress can be observed by utilizing this frequency,
    as terahertz frequency is absorbed greatly by water molecules (Hadjiloucas et
    al., 2009). Nuclear magnetic resonance and X-ray-based imaging techniques can
    also be used for detecting infections, different types of stress, and other health
    conditions in trees/fruits (Goodman et al., 1992, Williamson et al., 1992, Karunakaran
    et al., 2004, Pearson and Wicklow, 2006). Goodman et al. (1992) used NMR microscopic
    imaging for identification of the fungal pathogen Botrytis cinerea in red raspberry.
    Narvankar et al. (2009) applied X-ray imaging to identify fungal infections in
    wheat. The authors employed statistical discriminant models and ANN to classify
    the images of the wheat kernels. Statistical classifiers, especially the Mahalanobis
    discriminant classifier performed better (92–99% accuracy) than the ANN-based
    classification. 4. Profiling of plant volatile organic compounds for disease detection
    The volatile organic compounds (VOC) released by plants and trees contribute about
    two-thirds of the total VOC emissions present in the atmosphere (Guenther, 1997).
    There are number of factors that affect the volatile metabolic profile of a plant
    or tree. The VOCs released by the plants depend on various physico-chemical factors
    such as humidity, temperature, light, soil condition, and fertilization, as well
    as biological factors such as growth and developmental stage of the plant, insects,
    and presence of other herbs (Vallat et al., 2005, Vuorinen et al., 2007). The
    physico-chemical factors either directly or indirectly affect the physiological
    condition of the plant, thereby influencing the VOC profile of the plant. These
    plant volatiles in turn influence their relationship between the plants and other
    organisms including pathogens (Vuorinen et al., 2007). For example, acetaldehyde
    is released by the leaves of young poplar trees are controlled by the transfer
    of ethanol to leaves through transpiration (Kreuzwieser et al., 2001). Dudareva
    et al. (2006) reviewed a range of plant volatiles released by the plants due to
    biotic and abiotic interactions. Some of the commonly found secondary plant volatiles
    are terpeniods, volatile fatty acids (such as trans-2-hexenal, cis-3-hexenol and
    methyl jasmonate), phenylpropanoids and benzenoids, and amino acid volatiles (such
    as aldehydes, alcohols, esters, acids, and nitrogen- and sulfur-containing volatiles
    derived from amino acids). The abiotic and biotic stresses can result in a change
    in the volatile profile of the plants that can be utilized for the plant disease
    detection. Cevallos-Cevallos et al. (2009) reported that the compounds (extracted
    from leaves) such as hesperidin, naringenin, and quercetin present in the leaves
    could be used as a biomarker to identify huanglongbing diseases in citrus trees.
    The volatiles of these compounds could be tested in the atmosphere near the citrus
    plantations to detect the presence of huanglongbing disease. Tholl et al. (2006)
    reviewed practical methods to study the plant volatiles suitable for various applications.
    The authors described the methods for VOC sampling and analysis for in-situ experiments
    as well as some for field experiments. The focus of the present paper is towards
    the application of plant VOC profile monitoring for detecting diseases in plants.
    The VOCs released by the plants change when the plant is infected with a disease
    due to change in its physiology. These emissions are expected to vary from the
    VOCs released under normal plant health conditions. This technology could facilitate
    the detection of plant diseases in real-time, thereby preventing the spread of
    plant diseases. Such techniques will provide agricultural and financial benefits
    for the growth and development of our economy. The volatile metabolic gas profile
    analysis has been evaluated by few researchers (Vuorinen et al., 2007, Laothawornkitkul
    et al., 2008, Li et al., 2009b) to identify plant diseases. Studies have been
    performed in natural/field conditions (Vuorinen et al., 2007, Staudt and Lhoutellier,
    2007, Laothawornkitkul et al., 2008) and controlled environments/in situ (Li et
    al., 2009b). A handful of studies have been performed to detect diseases or infections
    in postharvest fruits/vegetables (Prithiviraj et al., 2004, Li et al., 2009b).
    The two common methods used for assessing the profile of volatile metabolites
    released by plants are using gas chromatography (GC)-based and electronic nose
    system-based techniques. The following sections describe the studies performed
    on plant disease analysis using these two techniques. 4.1. Electronic nose system
    An electronic nose system consists of a series of gas sensors that are sensitive
    to a range of organic compounds. As each sensor has specific sensitivities, the
    sensitivities of a series of sensors could be used to discriminate different compounds
    present in the atmosphere. Electronic nose systems have been used for multiple
    applications. They have been used to determine food quality (Evans et al., 2000,
    Di Natale et al., 2001, Zhang et al., 2008a, Zhang et al., 2008b), identify diseases
    in humans (Gardner et al., 2000, Lin et al., 2001, Dragonieri et al., 2007), and
    detect microorganisms in food products (Falasconi et al., 2005, Rajamäki et al.,
    2006, Balasubramanian et al., 2008, Concina et al., 2009) among others. The application
    of electronic nose systems for identifying plant diseases is relatively new domain
    for its application. Li et al. (2009b) used a Cyranose® 320 (an array of 32 conducting
    polymer-based sensors) to detect postharvest fungal disease in blueberries in
    a controlled environment. Blueberries were disinfected with ethanol to eliminate
    any naturally present fungal spores and bacteria. Once the blueberries were rinsed
    with distilled water to remove residual ethanol, they were inoculated with spore
    suspensions of three fungal species: Botrytis cinerea, Colletotrichum gloeosporioides,
    and Alternaria spp. that cause gray mold, anthracnose, and Alternaria fruit rot
    in postharvest blueberries, respectively. The berries were placed in a 500 mL
    bottle and headspace gases were tested using Cyranose® 320. GC–MS (Gas chromatography–mass
    spectroscopy) analysis was also performed to identify specific compounds that
    could be related to fungal diseases. Principal component analysis plots indicated
    a clear delineation between the control (fresh berries) and berries with fungal
    infections. The berries with C. gloeosporioides could be distinctively differentiated
    from the other groups, though there was some overlap in the VOC profiles of the
    berries infected with B. cinerea and Alternaria spp. The authors suggested that
    as B. cinerea and Alternaria spp. mainly infect the same region (stem scar region)
    of blueberry fruit that might have resulted in a similar VOC profile. When linear
    Bayesian classifier was used, the study found that the type I error for classifying
    infections caused by B. cinerea, C. gloeosporioides, and Alternaria spp. were
    18%, 11%, and 13%, respectively. In addition, PCA results on GC–MS data (relative
    concentration of VOCs with respect to the class) indicated that styrene, 1-methyl-2-(1-methylethyl)
    benzene, eucalyptol, undecane, 5-methyl-2-(1-methylethyl)-2-cyclohexen-1-one,
    and thujopsene contributed to the classification of the four groups (three diseases
    and one healthy). The research work described above demonstrates the potential
    for applying VOC profiling-based technique for non-destructive detection of plant
    diseases. Laothawornkitkul et al. (2008) evaluated the potential of plant volatile
    signature for pest and disease monitoring in cucumber, pepper, and tomato plants.
    Similar to Li et al. (2009b), an electronic nose system and GC–MS were used to
    identify and distinguish the volatiles released by the plants under different
    conditions. The authors used Bloodhound® ST214 electronic nose (an array of 14
    conducting polymer-based sensors with one sensor as a reference) for determining
    sensors’ responses to VOCs released by the plant leaves in experiments conducted
    in a greenhouse. The healthy pepper plant VOC profile was compared to that of
    wounded pepper plant; the healthy cucumber plant VOC profile was compared to that
    of wounded and spider mite-infested cucumber plant; and healthy tomato plant VOC
    profile was compared to that of wounded, mildew-infected, and hornworm infested
    tomato plant. Statistical methods such as PCA, discriminant function analysis
    (DFA), and cluster analysis were utilized to analyze the data to classify healthy
    plants from the unhealthy ones. The profile of VOCs released by three different
    plants (as determined using electronic nose) was distinctly different when the
    data were analyzed using DFA model. Similarly, the VOC profile of wounded and
    healthy plants could be clearly discriminated using DFA and cluster analysis techniques.
    When the VOC profile of healthy, wounded, and spider-mite infested cucumber plants
    as determined by electronic nose and GC–MS were compared, the different groups
    were distinctively separable. The gases that might have contributed to the variation
    in the electronic nose sensor responses were identified using GC–MS analysis.
    Similar results were obtained for VOC profile analysis of tomato plants. The authors
    stated that the electronic nose results were comparable to the GC–MS data, facilitating
    a portable means of detecting VOC profile for plant disease monitoring under field
    conditions. Zhang and Wang (2007) applied PEN2 electronic nose system (Win Muster
    Airsense Analytics Inc., Germany) consisting of an array of 10 metal oxide-based
    sensors for measuring the profile of VOCs released from wheat damaged with age
    and insects. The authors were able to classify the different categories of wheat
    grains using PCA and LDA techniques. Spinelli et al. (2006) evaluated the near
    infrared and electronic nose system-based techniques to detect fire blight (asymptomatic
    stage) in pear plants. It was reported that the electronic nose system was able
    to provide a distinct olfactory signature required to identify the disease. The
    disease could be detected as early as 6 days after the infection. The study indicated
    that electronic nose system could be used as effective tool for the early diagnosis
    of the plant disease under natural conditions. Markom et al. (2009) used an electronic
    nose system to detect basal stem rot disease in oil palm plantation during field
    experiments. The authors reported that two principal components based on PCA were
    able to account for 99.32% variability in the data, and MLP-based artificial neural
    network could classify infected from healthy trees with high accuracy. The above
    studies revealed the prospective of the electronic nose-based VOC monitoring systems
    in conjunction with advanced statistical techniques for detecting different stress
    and health conditions in plants. This indicates that the profile of volatile metabolites
    released by plants could be used as a disease-monitoring tool for early and rapid
    detection of plant diseases. 4.2. GC–MS The GC–MS is commonly used technique for
    a qualitative as well as quantitative analysis of volatile metabolites released
    by plants/trees in different environmental and physiological conditions. The GC–MS
    studies have been performed to evaluate the change in volatiles caused by bacterial
    or fungal infection in various food products (Table 5). Table 5. Examples of studies
    on disease detection in vegetables and fruits using GC–MS. Plant/Fruit/Vegetable
    Cause of disease No. of VOCs Statistical Methods Classification accuracy (%) Reference
    Timber Serpula lacrymans (dry rot fungus) and Coniophora puteana (cellar fungus)
    12–15 – – Ewen et al. (2004) Onion bulbs Erwinia carotovora ssp. carotovora, Fusarium
    oxysporum and Botrytis allii 25 – – Prithiviraj et al. (2004) Potato tubers Phytophthora
    infestans, Pythium ultimum and Botrytis cinerea 32 Discriminant analysis 13–100
    Lui et al. (2005) Carrots Botrytis cinerea, Erwinia carotovora subsp. carotovora,
    Aspergillus niger and Fusarium avenaceum 39 Discriminant analysis 30–90 Vikram
    et al. (2006) Mango Lasiodiplodia theobromae (stem-end rot) and Colletotrichum
    gloeosporioides (anthracnose), 35 Discriminant analysis 33–88 Moalemiyan et al.
    (2007) Prithiviraj et al. (2004) assessed the variability in the volatiles released
    from onion bulbs infected with bacterial (Erwinia carotovora causing soft rot)
    and fungal species (Fusarium oxysporum and Botrytis allii causing basal and neck
    rots) using HAPSITE, commercial portable GC–MS instrument. The study indicated
    that 25 volatile compounds (among the 59 consistently detected compounds) released
    from onion can be used to identify the disease based on VOC profiling. Although
    no statistical analyses were performed to determine the discriminatory ability
    of an algorithm in classifying the VOC profiles for disease detection, model development
    and software development were recommended for the purpose. Similar studies on
    potato tubers inoculated with Erwinia carotovora subsp. carotovora, E. carotovora
    subsp. atroseptica, Pythium ultimum, Phytophthora infestans, or Fusarium sambucinum
    using solid phase microextraction (SPME) fiber along with GC-flame ionization
    detector (FID) indicated the potential of the VOC profiling for disease detection
    (Kushalappa et al., 2002). The amount of volatiles increased with an increase
    in disease severity. A BPNN model was applied to classify the volatile metabolite
    profiles with respect to the diseases. The gas retention time of the volatile
    compounds (GC feature) was used as the input data and two hidden layers were used
    for cross-validation. The cross-validation probabilities (using BPNN) were >67%
    (67–75%) for all groups except potato tubers infected with Phytophthora infestans.
    Unlike other studies, this study did not determine the specific compounds that
    resulted in VOC peaks in the FID. Lui et al. (2005) inoculated potato tubers with
    Phytophthora infestans, Pythium ultimum, or Botrytis cinerea and analyzed the
    VOC profile using GC–MS. The compounds in the headspace of the potatoes were identified
    and their abundance in terms of peak area was determined. Stepwise discriminant
    analysis was performed using the 32 compounds that were consistently present in
    the headspace and mass ions from the MS data as the input. The developed discriminant
    analysis models categorized the diseases with a classification accuracy of 13–100%.
    Comparing studies conducted by Lui et al. (2005) and Kushalappa et al. (2002),
    BPNN-based classification provided higher classification accuracy than discriminant
    analysis based models. However, the results may be highly sensitive to experimental
    conditions, diseases, and type of fruit or vegetable. Vuorinen et al. (2007) utilized
    VOC emission pattern of silver birch to determine whether the plants were damaged
    by larvae (herbivore arthropod Epirrita autumnata), infected with pathogenic leaf
    spot (Marssonina betulae) or if they were healthy. The VOCs were collected from
    pathogen-inoculated leaves, herbivore-damaged leaves, and undamaged leaves from
    the top of the branches as well as undamaged detached twigs. Different plant conditions
    produced specific patterns of VOCs. The herbivore damaged leaves released VOCs
    such as methylsalicylate, linalool, etc., especially after 72 h of feeding. It
    was also reported that higher quantities of (Z)-ocimene and (E)-β-ocimene were
    released from the pathogen-infected twigs than from the control twigs. Though
    simple statistical methods as t-test and ANOVA were performed in the study, a
    detailed discussion on the statistical results was absent from the paper. Staudt
    and Lhoutellier (2007) evaluated the VOC release profile of the damaged and undamaged
    leaves of holm oak tree infested by gypsy moth larvae. The researchers stated
    that the leaves released linalool, homoterpene (E)-4, 8-dimethyl-1,3,7-nonatriene,
    germacrene D, â-caryophyllene, and several other sesquiterpenes upon days of caterpillar
    growth on the leaves. These gases were not present in the VOCs released by the
    control plants. Moalemiyan et al., 2006, Moalemiyan et al., 2007 employed VOC
    profiling to detect fungal diseases (Lasiodiplodia theobromae causing stem-end
    rot and Colletotrichum gloeosporioides causing anthracnose) in mangoes. Discriminant
    analysis models were used to classify the groups using the gaseous metabolite
    profile and mass ions. Though the methods showed potential for detecting fungal
    diseases, the classification accuracy of the models needs to be further increased
    to make it a feasible method for postharvest disease detection. 5. Future directions
    Recent reports in the literature support the notion that both volatile profiling
    and changes in spectral reflectance can be used for non-invasive field monitoring
    of plant diseases. Plants and trees release volatile organic compounds (VOCs)
    as a result of the metabolic activities taking place within its shoots, leaves,
    flowers, or fruits. The VOC profile of each plant differs significantly based
    on its physiological condition and the species. Various factors influence the
    profile of VOCs from a particular plant or tree, which may include changes in
    plant metabolism as a result of environmental changes, the age of plant, developmental
    stage of a plant, effect of stress on plants, and the presence of disease/herbivore
    in a plant. One of the biggest challenges in the utilization of plant gaseous
    metabolites as an indicator for the presence of plant diseases is the natural
    variation in the VOC profile within plant species. The variation in VOCs released
    by plants may mask the changes due to the stress and the presence of diseases.
    Therefore, there is a need to identify distinct volatile biomarker specific for
    a particular plant and disease that would be different from the VOCs produced
    due to an environmental or nutrient stress. For practical applications, development
    of a robust and reliable system for real-time monitoring of plant diseases is
    required. Similar to VOC profile of the plants, the environmental conditions affect
    the spectral reflectance from the object (Griffin and Burke, 2003). Therefore,
    there is a need to identify suitable approach to overcome this problem. The possible
    way to overcome this problem could be identification of wavelength range or index
    that is not only sensitive to a specific plant disease but also is least affected
    by the changes in the environmental condition. It is feasible to incorporate the
    imaging and VOC profiling techniques into an autonomous robot as these techniques
    are well established for other industrial applications. Once these techniques
    are well established for a specific disease detection application, these methods
    can be integrated with an autonomous agricultural vehicle for real-time monitoring
    for plant diseases. The overall comparisons of three major techniques are summarized
    in Table 6. Table 6. Comparison of various types of plant disease detection. Characteristics
    Molecular techniques Imaging and spectroscopic techniques VOCs profiling-based
    techniques Accuracy of the method - Molecular techniques are presently the most
    accurate method for plant disease detection. - The accuracy of imaging and spectroscopic
    techniques is plant and disease specific. - Accuracy is currently unknown, as
    this method is in the developmental stages and has been utilized in recent years.
    - Efforts are ongoing to make molecular methods more reliable and simpler as well
    as develop molecular detection kits for field applications. However, it is difficult
    to develop kits for all diseases. They are usually focused towards commonly found
    and harmful diseases. - Higher the visible symptoms, better is the accuracy of
    the technique. Nevertheless, the non-visible regions of spectra can be utilized
    for improving the accuracy of the method. - Identification of disease-specific
    biomarker volatiles (most challenging step) can improve the accuracy significantly.  Cost
    - Moderately expensive. Quite often: is labor intensive and requires specific
    instrumentation. - Expensive, especially if techniques as hyperspectral imaging
    are used. Fewer the wave bands used, cheaper will be the instrument. - The cost
    of technique depends on the desired accuracy for VOC profiling. - Trained personnel
    are also required for careful handing of samples and results. - Require computers/laptops
    for data analysis. - The cost can range depending on the detector required for
    biomarker identification.  Applicability for rapid detection - Speed depends on
    the samples required to be analyzed, number of personnel, and equipments and materials.
    - The focus on the development of this technique is due to its ability for rapid
    detection. - The technique shows the potential for rapid plant disease detection.
    - The technique is not fast for a huge amount of samples.  Applicability for field
    work/Ruggedness - Field kits are being developed. However, it is difficult to
    develop kits for all diseases. - Moderately ruggedness. The ruggedness of the
    spectrometer or the scanner depends on the base on which the sensor is mounted.
    - Moderately rugged, depending on the detector used for sensing VOCs. - The field
    kits are rugged, but require good accuracy for reliable results.  Speed of detection
    - May require 24 - 48 h for reliable results. - Once this technique is established,
    may require minutes for disease detection. - This method may require significantly
    less time, if proven as an effective method for a particular disease. -Molecular
    kits are faster. -The speed depends on the computational speed of the computer
    as well as speed of the scanner. - Speed would depend on the detector speed and
    computational speed.  Others aspects - One of the limitations of this technique
    is that it is difficult to automate the process for rapid detection. -This method
    can be automated or disease detection can be performed through remote operation
    easily. - Selection of biomarker is a critical step for determining the applicability
    of this technique. - Requires personnel for monitoring plant disease by this method.
    -This method can be used as preliminary screening of diseases, so that fewer samples
    can be confirmed by molecular technique. -Once established this method can be
    automated with a robotic vehicle for plant disease detection. - The methods in
    combination with other methods as molecular detection can be effective in rapid
    detection of plant diseases. 6. Summary and conclusions The present paper reviews
    and summarizes some of the non-invasive techniques that have been used for plant
    disease detection. The two major categories for non-invasive monitoring of plant
    diseases are: (i) spectroscopic and imaging techniques, and (ii) volatile organic
    compounds profiling-based technique for recognizing plant diseases. The spectroscopic
    and imaging techniques include fluorescence spectroscopy, visible-IR spectroscopy,
    fluorescence imaging, and hyperspectral imaging. The VOC profile-based disease
    detection involves using electronic nose or GC–MS based volatile metabolite analysis
    released by healthy and diseased plants as a tool for identifying diseases. Some
    of the challenges in these techniques are: (i) the effect of background data in
    the resulting profile or data, (ii) optimization of the technique for a specific
    plant/tree and disease, and (iii) automation of the technique for continuous automated
    monitoring of plant diseases under real world field conditions. The review suggests
    that these methods of disease detection show a good potential with an ability
    to detect plant diseases accurately. The spectroscopic and imaging technology
    could be integrated with an autonomous agricultural vehicle for reliable and real-time
    plant disease detection to achieve superior plant disease control and management.
    References Aleixos et al., 2002 N. Aleixos, J. Blasco, F. Navarrón, E. Moltó Multispectral
    inspection of citrus in real-time using machine vision and digital signal processors
    Computers and Electronics in Agriculture, 33 (2) (2002), pp. 121-137 View PDFView
    articleView in ScopusGoogle Scholar Alvarez, 2004 A.M. Alvarez Integrated approaches
    for detection of plant pathogenic bacteria and diagnosis of bacterial diseases
    Annual Review of Plant Pathology, 42 (2004), pp. 339-366 View in ScopusGoogle
    Scholar Anwar Haq et al., 2003 M. Anwar Haq, H.A. Collin, A.B. Tomsett, M.G. Jones
    Detection of Sclerotium cepivorum within onion plants using PCR primers Physiological
    and Molecular Plant Pathology, 62 (3) (2003), pp. 185-189 Google Scholar Balasubramanian
    et al., 2008 S. Balasubramanian, S. Panigrahi, C.M. Logue, C. Doetkott, M. Marchello,
    J.S. Sherwood Independent component analysis-processed electronic nose data for
    predicting Salmonella typhimurium populations in contaminated beef Food Control,
    19 (3) (2008), pp. 236-246 View PDFView articleView in ScopusGoogle Scholar Belasque
    et al., 2008 L. Belasque, M.C.G. Gasparoto, L.G. Marcassa Detection of mechanical
    and disease stresses in citrus plants by fluorescence spectroscopy Applied Optics,
    47 (11) (2008), pp. 1922-1926 View in ScopusGoogle Scholar Bertolini et al., 2003
    E. Bertolini, R. Penyalver, A. García, J.M. Quesada, M. Cambra, A. Olmos, M.M.
    López Highly sensitive detection of Pseudomonas savastanoi pv. savastanoi in asymptomatic
    olive plants by nested-PCR in a single closed tube Journal of Microbiological
    Methods, 52 (2003), pp. 261-266 View PDFView articleView in ScopusGoogle Scholar
    Blasco et al., 2007 J. Blasco, N. Alexios, J. Gómez, E. Moltó Citrus sorting by
    identification of the most common defects using multispectral computer vision
    Journal of Food Engineering, 83 (3) (2007), pp. 384-393 View PDFView articleView
    in ScopusGoogle Scholar Bravo et al., 2003 C. Bravo, D. Moshou, J. West, A. McCartney,
    H. Ramon Early disease detection in wheat fields using spectral reflectance Biosystems
    Engineering, 84 (2) (2003), pp. 137-145 View PDFView articleView in ScopusGoogle
    Scholar Bravo et al., 2004 Bravo, C., Moshou, D., Oberti, R., West, J., McCartney,
    A., Bodria, L., Ramon, H., 2004. Foliar disease detection in the field using optical
    sensor fusion. Agricultural Engineering International: the CIGR Journal of Scientific
    Research and Development, Manuscript FP 04 008, Vol. VI. December 2004. Google
    Scholar Cerovic et al., 1999 Z.G. Cerovic, G. Samson, F. Morales, N. Tremblay,
    I. Moya Ultraviolet-induced fluorescence for plant monitoring: present state and
    prospects Agronomie, 19 (1999), pp. 543-578 CrossRefGoogle Scholar Cevallos-Cevallos
    et al., 2009 J.M. Cevallos-Cevallos, R. Rouseff, J.I. Reyes-De-Corcuera Untargeted
    metabolite analysis of healthy and Huanglongbing-infected orange leaves by CE-DAD
    Electrophoresis, 30 (2009), pp. 1-8 Google Scholar Chaerle et al., 1999 L. Chaerle,
    W.V. Caeneghem, E. Messens, H. Lamber, M. Van Montagu, D. Van Der Straeten Presymptomatic
    visualization of plant–virus interactions by thermography Nature Biotechnology,
    17 (1999), pp. 813-816 View in ScopusGoogle Scholar Chaerle and Van Der Straeten,
    2000 L. Chaerle, D. Van Der Straeten Imaging techniques and the early detection
    of plant stress Trends in Plant Science, 5 (11) (2000), pp. 495-501 View PDFView
    articleView in ScopusGoogle Scholar Chaerle et al., 2001 L. Chaerle, F. De Boever,
    M. Van Montagu, D. Van Der Straeten Thermographic visualization of cell death
    in tobacco and Arabidopsis Plant, Cell and Environment, 24 (1) (2001), pp. 15-25
    View in ScopusGoogle Scholar Chaerle et al., 2003 L. Chaerle, K. Hulsen, C. Hermans,
    R.J. Strasser, R. Valcke, M. Höfte, D. Van Der Straeten Robotized time-lapse imaging
    to assess in-plant uptake of phenylurea herbicides and their microbial degradation
    Physiologia Plantarium, 118 (2003), pp. 613-619 View in ScopusGoogle Scholar Chaerle
    et al., 2004 L. Chaerle, D. Hagenbeek, E. De Bruyne, R. Valcke, D. Van Der Straeten
    Thermal and chlorophyll-fluorescence imaging distinguish plant–pathogen interactions
    at an early stage Plant and Cell Physiology, 45 (2004), pp. 887-896 View in ScopusGoogle
    Scholar Chaerle et al., 2007 L. Chaerle, S. Lenk, D. Hagenbeek, C. Buschmann,
    D. Van Der Straeten Multicolor fluorescence imaging for early detection of the
    hypersensitive reaction to tobacco mosaic virus Journal of Plant Physiology, 164
    (3) (2007), pp. 253-262 View PDFView articleView in ScopusGoogle Scholar Chen
    et al., 2008 Chen, B., Wang, K., Li, S., Wang, J., Bai, J., Xiao, C., Lai, J.,
    2008. Spectrum characteristics of cotton canopy infected with verticillium wilt
    and inversion of severity level. In IFIP International Federation for Information
    Processing, Volume 259; Computer and Computing Technologies in Agriculture, vol.
    2, Daoliang Li, Springer, Boston, pp. 1169–1180. Google Scholar Choi et al., 2004
    Y.H. Choi, E.C. Tapias, H.K. Kim, A.W.M. Lefeber, C. Erkelens, J.T.J. Verhoeven,
    J. Brzin, J. Zel, R. Verpoorte Metabolic discrimination of Catharanthus roseus
    leaves infected by phytoplasma using 1H-NMR spectroscopy and multivariate data
    analysis Plant Physiology, 135 (2004), pp. 2398-2410 CrossRefGoogle Scholar Concina
    et al., 2009 I. Concina, M. Falasconi, E. Gobbi, F. Bianchi, M. Musci, M. Mattarozzi,
    M. Pardo, A. Mangia, M. Careri, G. Sberveglieri Early detection of microbial contamination
    in processed tomatoes by electronic nose Food Control, 20 (10) (2009), pp. 873-880
    View PDFView articleView in ScopusGoogle Scholar Costa et al., 2007 G. Costa,
    M. Noferini, G. Fiori, F. Spinelli Innovative application of non-destructive techniques
    for fruit quality and disease diagnosis Acta Horticulturae, 753 (1) (2007), pp.
    275-282 CrossRefView in ScopusGoogle Scholar Das, 2004 A.K. Das Rapid detection
    of Candidatus Liberibacter asiaticus, the bacterium associated with citrus Huanglongbing
    (Greening) disease using PCR Current Science, 87 (9) (2004), pp. 1183-1185 View
    in ScopusGoogle Scholar Delalieux et al., 2007 S. Delalieux, J. van Aardt, W.
    Keulemans, E. Schrevens, P. Coppin Detection of biotic stress (Venturia inaequalis)
    in apple trees using hyperspectral data: Non-parametric statistical approaches
    and physiological implications European Journal of Agronomy, 27 (1) (2007), pp.
    130-143 View PDFView articleView in ScopusGoogle Scholar Delwiche and Kim, 2000
    S.R. Delwiche, M.S. Kim Hyperspectral imaging for detection of scab in wheat Proceedings
    of SPIE, 4203 (2000), pp. 13-20 View in ScopusGoogle Scholar Delwiche and Graybosch,
    2002 S.R. Delwiche, R.A. Graybosch Identification of waxy wheat by near-infrared
    reflectance spectroscopy Journal of Cereal Science, 35 (1) (2002), pp. 29-38 View
    PDFView articleView in ScopusGoogle Scholar Di Natale et al., 2001 C. Di Natale,
    A. Macagnano, E. Martinelli, R. Paolesse, E. Proietti, A. D’Amico The evaluation
    of quality of post-harvest oranges and apples by means of an electronic nose Sensors
    and Actuators B: Chemical, 78 (1–3) (2001), pp. 26-31 View PDFView articleView
    in ScopusGoogle Scholar Dragonieri et al., 2007 S. Dragonieri, R. Schot, B.J.A.
    Mertens, S. Le Cessie, S.A. Gauw, A. Spanevello, O. Resta, N.P. Willard, T.J.
    Vink, K.F. Rabe, E.H. Bel, P.J. Sterk An electronic nose in the discrimination
    of patients with asthma and controls Journal of Allergy and Clinical Immunology,
    120 (4) (2007), pp. 856-862 View PDFView articleView in ScopusGoogle Scholar Dudareva
    et al., 2006 N. Dudareva, F. Negre, D.A. Nagegowda, I. Orlova Plant volatiles:
    recent advances and future perspectives Critical Reviews in Plant Sciences, 25
    (2006), pp. 417-440 CrossRefView in ScopusGoogle Scholar ElMasry et al., 2008
    G. ElMasry, N. Wang, C. Vigneault, J. Qiao, A. ElSayed Early detection of apple
    bruises on different background colors using hyperspectral imaging LWT Food Science
    and Technology, 41 (2) (2008), pp. 337-345 View PDFView articleView in ScopusGoogle
    Scholar Evans et al., 2000 P. Evans, K.C. Persaud, A.S. McNeish, R.W. Sneath,
    N. Hobson, N. Magan Evaluation of a radial basis function neural network for the
    determination of wheat quality from electronic nose data Sensors and Actuators
    B: Chemical, 69 (3) (2000), pp. 348-358 View PDFView articleView in ScopusGoogle
    Scholar Ewen et al., 2004 R.J. Ewen, P.R.H. Jones, N.M. Ratcliffe, P.T.N. Spencer-Phillips
    Identification by gas chromatography-mass spectrometry of the volatile organic
    compounds emitted from the wood-rotting fungi Serpula lacrymans and Coniophora
    puteana, and from Pinus sylvestris timber Mycology Research, 108 (7) (2004), pp.
    806-814 View PDFView articleView in ScopusGoogle Scholar Falasconi et al., 2005
    M. Falasconi, E. Gobbi, M. Pardo, M. Della Torre, A. Bresciani, G. Sberveglieri
    Detection of toxigenic strains of Fusarium verticillioides in corn by electronic
    olfactory system Sensors and Actuators B: Chemical, 108 (1–2) (2005), pp. 250-257
    View PDFView articleView in ScopusGoogle Scholar Fang et al., 2009 Y. Fang, L.H.
    Xu, W.X. Tian, Y. Huai, S.H. Yu, M.M. Lou, G.L. Xie Real-time fluorescence PCR
    method for detection of Burkholderia glumae from rice Rice Science, 16 (2) (2009),
    pp. 157-160 View PDFView articleView in ScopusGoogle Scholar Gardner et al., 2000
    J.W. Gardner, H.W. Shin, E.L. Hines An electronic nose system to diagnose illness
    Sensors and Actuators B: Chemical, 70 (1–3) (2000), pp. 19-24 View PDFView articleView
    in ScopusGoogle Scholar Gomez et al., 2006 A.H. Gomez, Y. He, A. Garcia Pereira
    Non-destructive measurement of acidity, soluble solids and firmness of Satsuma
    mandarin using Vis/NIR spectroscopy techniques Journal of Food Engineering, 77
    (3) (2006), pp. 313-319 View PDFView articleView in ScopusGoogle Scholar Goodman
    et al., 1992 B.A. Goodman, B. Williamson, A. Chudek Non-invasive observation of
    the development of fungal infection in fruit Protoplasma, 166 (1992), pp. 107-109
    View in ScopusGoogle Scholar Gowen et al., 2007 A.A. Gowen, C.P. O’Donnell, P.J.
    Cullen, G. Downey, J.M. Frias Hyperspectral imaging—an emerging process analytical
    tool for food quality and safety control Trends in Food Science & Technology,
    18 (12) (2007), pp. 590-598 View PDFView articleView in ScopusGoogle Scholar Graeff
    et al., 2006 S. Graeff, J. Link, W. Claupein Identification of powdery mildew
    (Erysiphe graminis sp. tritici) and take-all disease (Gaeumannomyces graminis
    sp. tritici) in wheat (Triticum aestivum L.) by means of leaf reflectance measurements
    Central European Journal of Biology, 1 (2006), pp. 275-288 CrossRefView in ScopusGoogle
    Scholar Griffin and Burke, 2003 M.K. Griffin, H.K. Burke Compensation of hyperspectral
    data for atmospheric effects Lincoln Laboratory Journal, 14 (1) (2003), pp. 29-54
    View in ScopusGoogle Scholar Guenther, 1997 A. Guenther Seasonal and spatial variations
    in natural volatile organic compound emissions Ecological Applications, 7 (1)
    (1997), pp. 34-45 View in ScopusGoogle Scholar Guimet, 2005 Guimet, F., 2005.
    Olive oil characterization using excitation-emission fluorescence spectroscopy
    and three-way methods of analysis. Ph.D. thesis, Rovira i Virgili University,
    Spain. Google Scholar Guo et al., 2009 Guo, T.T., Guo, L., Wang, X.H., Li, M.,
    2009. Application of NIR spectroscopy in classification of plant species. In:
    International Workshop on Education Technology and Computer Science, Wuhan, Hubei,
    China, vol. 3, pp. 879–883. Google Scholar Gutiérrez-Aguirre et al., 2009 I. Gutiérrez-Aguirre,
    N. Mehle, D. Delić, K. Gruden, R. Mumford, M. Ravnikar Real-time quantitative
    PCR based sensitive detection and genotype discrimination of Pepino mosaic virus
    Journal of Virological Methods, 162 (1–2) (2009), pp. 46-55 View PDFView articleView
    in ScopusGoogle Scholar Hadjiloucas et al., 2009 Hadjiloucas, S., Walker, G.C.,
    Bowen, J.W., Zafiropoulos, A., 2009. Propagation of errors from a null balance
    terahertz reflectometer to a sample''s relative water content. Journal of Physics:
    Conference Series, Sensors & their Applications XV 178, 012012, 1–5. Google Scholar
    Hahn, 2009 F. Hahn Actual pathogen detection: Sensors and algorithms—a review
    Algorithms, 2 (2009), pp. 301-338 CrossRefView in ScopusGoogle Scholar Henson
    and French, 1993 J.M. Henson, R. French The polymerase chain reaction and plant
    disease diagnosis Annual Review of Plant Pathology, 31 (1993), pp. 81-109 CrossRefView
    in ScopusGoogle Scholar Huang and Apan, 2006 J.F. Huang, A. Apan Detection of
    Sclerotinia rot disease on celery using hyperspectral data and partial least squares
    regression Journal of Spatial Science, 51 (2) (2006), pp. 129-142 CrossRefView
    in ScopusGoogle Scholar Huang et al., 2004 M.Y. Huang, W.H. Huang, L.Y. Liu, Y.D.
    Huang, J.H. Wang, C.H. Zhao, A.M. Wan Spectral reflectance feature of winter wheat
    single leaf infested with stripe rust and severity level inversion Transactions
    of the CSAE, 20 (1) (2004), pp. 176-180 Google Scholar Huang et al., 2007 W. Huang,
    D.W. Lamb, Z. Niu, Y. Zhang, L. Liu, J. Wang Identification of yellow rust in
    wheat using in-situ spectral reflectance measurements and airborne hyperspectral
    imaging Precision Agriculture, 8 (2007), pp. 187-197 CrossRefView in ScopusGoogle
    Scholar Karunakaran et al., 2004 C. Karunakaran, D.S. Jayas, N.D.G. White Identification
    of wheat kernels damaged by the red flour beetle using X-ray images Biosystems
    Engineering, 87 (3) (2004), pp. 267-274 View PDFView articleView in ScopusGoogle
    Scholar Kim et al., 2001 M.S. Kim, Y.R. Chen, P.M. Mehl Hyperspectral reflectance
    and fluorescence imaging system for food quality and safety Transactions of the
    ASAE, 44 (3) (2001), pp. 721-729 View in ScopusGoogle Scholar Kim et al., 2002
    M.S. Kim, A.M. Lefcourt, K. Chao, Y.R. Chen, I. Kim, D.E. Chan Multispectral detection
    of fecal contamination on apples based on hyperspectral imagery: Part I. Application
    of visible and near–infrared reflectance imaging Transactions of the ASAE, 45
    (6) (2002), pp. 2027-2037 View in ScopusGoogle Scholar Kobayashi et al., 2001
    T. Kobayashi, E. Kanda, K. Kitada, K. Ishiguro, Y. Torigoe Detection of rice panicle
    blast with multispectral radiometer and the potential of using airborne multispectral
    scanners Phytopathology, 91 (3) (2001), pp. 316-323 View in ScopusGoogle Scholar
    Kreuzwieser et al., 2001 J. Kreuzwieser, F.J.M. Harren, L.J.J. Laarhoven, I. Boamfa,
    S. Lintel-Hekkertb, U. Scheerera, C. Hüglina, H. Rennenberga Acetaldehyde emission
    by the leaves of trees–correlation with physiological and environmental parameters
    Physiologia Plantarum, 113 (2001), pp. 41-49 View in ScopusGoogle Scholar Kushalappa
    et al., 2002 A.C. Kushalappa, L.H. Lui, C.R. Chen, B. Lee Volatile fingerprinting
    (SPMEGC-FID) to detect and discriminate diseases of potato tubers Plant Disease,
    86 (2002), pp. 131-137 View in ScopusGoogle Scholar Lacava et al., 2006 P.T. Lacava,
    W.B. Li, W.L. Araújo, J.L. Azevedo, J.S. Hartung Rapid, specific and quantitative
    assays for the detection of the endophytic bacterium Methylobacterium mesophilicum
    in plants Journal of Microbiological Methods, 65 (2006), pp. 535-541 View PDFView
    articleView in ScopusGoogle Scholar Lamkadmi et al., 1996 Z. Lamkadmi, M.A. Esnault,
    M. Le Normand Characterization of a 23 kDa polypeptide induced by Phoma lingam
    in Brassica napus leaves Plant Physiology and Biochemistry, 34 (4) (1996), pp.
    589-598 View in ScopusGoogle Scholar Laothawornkitkul et al., 2008 J. Laothawornkitkul,
    J.P. Moore, J.E. Taylor, M. Possell, T.D. Gibson, C.N. Hewitt, N.D. Paul Discrimination
    of plant volatile signatures by an electronic nose: a potential technology for
    plant pest and disease monitoring Environmental Science and Technology, 42 (2008),
    pp. 8433-8439 CrossRefView in ScopusGoogle Scholar Larsolle and Muhammed, 2007
    A. Larsolle, H.H. Muhammed Measuring crop status using multivariate analysis of
    hyperspectral field reflectance with application to disease severity and plant
    density Precision Agriculture, 8 (1–2) (2007), pp. 37-47 CrossRefView in ScopusGoogle
    Scholar Lee et al., 2005 Lee, K.J., Kang, S., Kim, M.S., Noh, S.H., 2005. Hyperspectral
    imaging for detecting defect on apples. ASABE Paper No. 053075, 2005 ASAE Annual
    International Meeting, Tampa, FL, 17–20 July, 2005. Google Scholar Lee et al.,
    2008 W.S. Lee, R. Ehsani, L.G. Albrigo Citrus greening disease (Huanglongbing)
    detection using aerial hyperspectral imaging The Proceedings of the 9th International
    Conference on Precision Agriculture, July 20–23, 2008, Denver, CO (2008) Google
    Scholar Lenk and Buschmann, 2006 S. Lenk, C. Buschmann Distribution of UV-shielding
    of the epidermis of sun and shade leaves of the beech (Fagus sylvatica L.) as
    monitored by multi-colour fluorescence imaging Journal of Plant Physiology, 163
    (12) (2006), pp. 1273-1283 View PDFView articleView in ScopusGoogle Scholar Lenk
    et al., 2007 S. Lenk, L. Chaerle, E.E. Pfündel, G. Langsdorf, D. Hagenbeek, H.K.
    Lichtenthaler, D. Van Der Straeten, C. Buschmann Multispectral fluorescence and
    reflectance imaging at the leaf level and its possible applications Journal of
    Experimental Botany, 58 (4) (2007), pp. 807-814 View in ScopusGoogle Scholar Lenthe
    et al., 2007 J.H. Lenthe, E.C. Oerke, H.W. Dehne Digital infrared thermography
    for monitoring canopy health of wheat Precision Agriculture, 8 (1–2) (2007), pp.
    15-26 CrossRefView in ScopusGoogle Scholar Li et al., 2006 W. Li, J.S. Hartung,
    L. Levy Quantitative real-time PCR for detection and identification of Candidatus
    Liberibacter species associated with citrus Huanglongbing Journal of Microbiological
    Methods, 66 (1) (2006), pp. 104-115 View PDFView articleView in ScopusGoogle Scholar
    Li et al., 2009a W. Li, J.A. Abad, R.D. French-Monar, J. Rascoe, A. Wen, N.C.
    Gudmestad, G.A. Secor, I.M. Lee, Y. Duan, L. Levy Multiplex real-time PCR for
    detection, identification and quantification of ‘Candidatus Liberibacter solanacearum’
    in potato plants with zebra chip Journal of Microbiological Methods, 78 (1) (2009),
    pp. 59-65 View PDFView articleView in ScopusGoogle Scholar Li et al., 2009b Li,
    C., Krewer, G., Kays, S. J., 2009b. Blueberry postharvest disease detection using
    an electronic nose. ASABE Paper No. 096783, ASABE Annual International Meeting,
    Reno, NV, June 21–June 24, 2009. Google Scholar Lin et al., 2001 Y.J. Lin, H.R.
    Guo, Y.H. Chang, M.T. Kao, H.H. Wang, R.I. Hong Application of the electronic
    nose for uremia diagnosis Sensors and Actuators B: Chemical, 76 (1–3) (2001),
    pp. 177-180 View PDFView articleView in ScopusGoogle Scholar Lindenthal et al.,
    2005 M. Lindenthal, U. Steiner, H.W. Dehne, E.-C. Oerke Effect of downy mildew
    development on transpiration of cucumber leaves visualized by digital infrared
    thermography Phytopathology, 95 (3) (2005), pp. 233-240 View in ScopusGoogle Scholar
    Lins et al., 2009 E.C. Lins, J. Belasque Junior, L.G. Marcassa Detection of citrus
    canker in citrus plants using laser induced fluorescence spectroscopy Precision
    Agriculture, 10 (2009), pp. 319-330 CrossRefView in ScopusGoogle Scholar López
    et al., 2003 M.M. López, E. Bertolini, A. Olmos, P. Caruso, M.T. Gorris, P. Llop,
    R. Penyalver, M. Cambra Innovative tools for detection of plant pathogenic viruses
    and bacteria International Microbiology, 6 (2003), pp. 233-243 View in ScopusGoogle
    Scholar Lu, 2003 R. Lu Detection of bruises on apples using near-infrared hyperspectral
    imaging Transactions of the ASAE, 46 (2) (2003), pp. 523-530 View in ScopusGoogle
    Scholar Lui et al., 2005 L. Lui, A. Vikram, H. Hamzehzarghani, A.C. Kushalappa
    Discrimination of three fungal diseases of potato tubers based on volatile metabolic
    profiles developed using GC/MS Potato Research, 48 (2005), pp. 85-96 View in ScopusGoogle
    Scholar Mahesh et al., 2008 S. Mahesh, A. Manickavasagan, D.S. Jayas, J. Paliwal,
    N.D.G. White Feasibility of near-infrared hyperspectral imaging to differentiate
    Canadian wheat classes Biosystems Engineering, 101 (1) (2008), pp. 50-57 View
    PDFView articleView in ScopusGoogle Scholar Malthus and Madeira, 1993 T.J. Malthus,
    A.C. Madeira High resolution spectroradiometry: spectral reflectance of field
    bean leaves infected by Botrytis fabae Remote Sensing of Environment, 45 (1993),
    pp. 107-116 View PDFView articleView in ScopusGoogle Scholar Marcassa et al.,
    2006 L.G. Marcassa, M.C.G. Gasparoto, J. Belasque Junior, E.C. Lins, F. Dias Nunes,
    V.S. Bagnato Fluorescence spectroscopy applied to orange trees Laser Physics,
    16 (5) (2006), pp. 884-888 View in ScopusGoogle Scholar Markom et al., 2009 M.A.
    Markom, A.Y. Md Shakaff, A.H. Adom, M.N. Ahmad, Wahyu Hidayat, A.H. Abdullah,
    N. Ahmad Fikri Intelligent electronic nose system for basal stem rot disease detection
    Computers and Electronics in Agriculture, 66 (2) (2009), pp. 140-146 View PDFView
    articleView in ScopusGoogle Scholar Mehl et al., 2004 P.M. Mehl, Y.R. Chen, M.S.
    Kim, D.E. Chan Development of hyperspectral imaging technique for the detection
    of apple surface defects and contaminations Journal of Food Engineering, 61 (1)
    (2004), pp. 67-81 View PDFView articleView in ScopusGoogle Scholar Minsavage et
    al., 1994 G.V. Minsavage, C.M. Thompson, D.L. Hopkins, R.M.V.B.C. Leite, R.E.
    Stall Development of a polymerase chain reaction protocol for detection of Xylella
    fastidiosa in plant tissue Phytopathology, 84 (1994), pp. 456-461 View in ScopusGoogle
    Scholar Moalemiyan et al., 2006 M. Moalemiyan, A. Vikram, A.C. Kushalappa, V.
    Yaylayan Volatile metabolite profiling to detect and discriminate stem-end rot
    and anthracnose diseases of mango fruits Plant Pathology, 55 (2006), pp. 792-802
    CrossRefView in ScopusGoogle Scholar Moalemiyan et al., 2007 M. Moalemiyan, A.
    Vikram, A.C. Kushalappa Detection and discrimination of two fungal diseases of
    mango (cv. Keitt) fruits based on volatile metabolite profiles using GC/MS Postharvest
    Biology and Technology, 45 (2007), pp. 117-125 View PDFView articleView in ScopusGoogle
    Scholar Moshou et al., 2004 D. Moshou, C. Bravo, J. West, S. Wahlen, A. McCartney,
    H. Ramon Automatic detection of ‘yellow rust’ in wheat using reflectance measurements
    and neural networks Computers and Electronics in Agriculture, 44 (3) (2004), pp.
    173-188 View PDFView articleView in ScopusGoogle Scholar Moshou et al., 2005 D.
    Moshou, C. Bravo, R. Oberti, J. West, L. Bodria, A. McCartney, H. Ramon Plant
    disease detection based on data fusion of hyper-spectral and multi-spectral fluorescence
    imaging using Kohonen maps Real-Time Imaging, 11 (2) (2005), pp. 75-83 View PDFView
    articleView in ScopusGoogle Scholar Moshou et al., 2006 D. Moshou, C. Bravo, S.
    Wahlen, J. West, A. McCartney, J. De Baerdemaeker, H. Ramon Simultaneous identification
    of plant stresses and diseases in arable crops using proximal optical sensing
    and self-organising maps Precision Agriculture, 7 (3) (2006), pp. 149-164 CrossRefView
    in ScopusGoogle Scholar Muhammed, 2002 H.H. Muhammed Using hyperspectral reflectance
    data for discrimination between healthy and diseased plants, and determination
    of damage-level in diseased plants IEEE: Proceedings of the 31st Applied Imagery
    Pattern Recognition Workshop (2002), pp. 49-54 View in ScopusGoogle Scholar Muhammed,
    2005 H.H. Muhammed Hyperspectral crop reflectance data for characterizing and
    estimating fungal disease severity in wheat Biosystems Engineering, 91 (1) (2005),
    pp. 9-20 View PDFView articleView in ScopusGoogle Scholar Naidu et al., 2009 R.A.
    Naidu, E.M. Perry, F.J. Pierce, T. Mekuria The potential of spectral reflectance
    technique for the detection of Grapevine leafroll-associated virus-3 in two red-berried
    wine grape cultivars Computers and Electronics in Agriculture, 66 (2009), pp.
    38-45 View PDFView articleView in ScopusGoogle Scholar Narvankar et al., 2009
    D.S. Narvankar, C.B. Singh, D.S. Jayas, N.D.G. White Assessment of soft X-ray
    imaging for detection of fungal infection in wheat Biosystems Engineering, 103
    (1) (2009), pp. 49-56 View PDFView articleView in ScopusGoogle Scholar Nicolaï
    et al., 2006 B.M. Nicolaï, E. Lötze, A. Peirs, N. Scheerlinck, K.I. Theron Non-destructive
    measurement of bitter pit in apple fruit using NIR hyperspectral imaging Postharvest
    Biology and Technology, 40 (1) (2006), pp. 1-6 View PDFView articleView in ScopusGoogle
    Scholar Oerke et al., 2005 E.C. Oerke, M. Lindenthal, P. Fröhling, U. Steiner
    Digital infrared thermography for the assessment of leaf pathogens J.V. Stafford
    (Ed.), Precision Agriculture ‘05, Wageningen University Press, Wageningen, The
    Netherlands (2005), pp. 91-98 View in ScopusGoogle Scholar Oerke et al., 2006
    E.C. Oerke, U. Steiner, H.W. Dehne, M. Lindenthal Thermal imaging of cucumber
    leaves affected by downy mildew and environmental conditions Journal of Experimental
    Botany, 57 (9) (2006), pp. 2121-2132 CrossRefView in ScopusGoogle Scholar Okamoto
    et al., 2009 H. Okamoto, Y. Suzuki, T. Kataoka, K. Sakai Unified hyperspectral
    imaging methodology for agricultural sensing using software framework Acta Horticulturae,
    824 (2009), pp. 49-56 CrossRefView in ScopusGoogle Scholar Pearson and Wicklow,
    2006 T.C. Pearson, D.T. Wicklow Detection of kernels infected by fungi Transactions
    of the ASABE, 49 (4) (2006), pp. 1235-1245 View in ScopusGoogle Scholar Pimentel
    et al., 2005 D. Pimentel, R. Zuniga, D. Morrison Update on the environmental and
    economic costs associated with alien-invasive species in the United States Ecological
    Economics, 52 (3) (2005), pp. 273-288 View PDFView articleView in ScopusGoogle
    Scholar Polischuk et al., 1997 V.P. Polischuk, T.M. Shadchina, T.I. Kompanetz,
    I.G. Budzanivskaya, A. Sozinov Changes in reflectance spectrum characteristic
    of Nicotiana debneyi plant under the influence of viral infection Archives of
    Phytopathology and Plant Protection, 31 (1) (1997), pp. 115-119 CrossRefView in
    ScopusGoogle Scholar Pontius et al., 2005 J. Pontius, R. Hallett, M. Martin Assessing
    hemlock decline using visible and near-infrared spectroscopy: indices comparison
    and algorithm development Applied Spectroscopy, 59 (6) (2005), pp. 836-843 CrossRefView
    in ScopusGoogle Scholar Prithiviraj et al., 2004 B. Prithiviraj, A. Vikram, A.C.
    Kushalappa, V. Yaylayam Volatile metabolite profiling for the discrimination of
    onion bulbs infected by Erwinia carotovora ssp. carotovora, Fusarium oxysporum
    and Botrytis allii European Journal of Plant Physiology, 110 (2004), pp. 371-377
    View in ScopusGoogle Scholar Purcell et al., 2009 D.E. Purcell, M.G. O''Shea,
    R.A. Johnson, S. Kokot Near-infrared spectroscopy for the prediction of disease
    rating for Fiji leaf gall in sugarcane clones Applied Spectroscopy, 63 (4) (2009),
    pp. 450-457 CrossRefView in ScopusGoogle Scholar Qin et al., 2008 J. Qin, T.F.
    Burks, M.S. Kim, K. Chao, M.A. Ritenour Citrus canker detection using hyperspectral
    reflectance imaging and PCA-based image classification method Sensing and Instrumentation
    for Food Quality and Safety, 2 (2008), pp. 168-177 CrossRefView in ScopusGoogle
    Scholar Qin et al., 2009 J. Qin, T.F. Burks, M.A. Ritenour, W.G. Bonn Detection
    of citrus canker using hyperspectral reflectance imaging with spectral information
    divergence Journal of Food Engineering, 93 (2) (2009), pp. 183-191 View PDFView
    articleView in ScopusGoogle Scholar Rajamäki et al., 2006 T. Rajamäki, H.L. Alakomi,
    T. Ritvanen, E. Skyttä, M. Smolander, R. Ahvenainen Application of an electronic
    nose for quality assessment of modified atmosphere packaged poultry meat Food
    Control, 17 (1) (2006), pp. 5-13 View PDFView articleView in ScopusGoogle Scholar
    Ramon et al., 2002 H. Ramon, J. Anthonis, E. Vrindts, R. Delen, J. Reumers, D.
    Moshou, K. Deprez, J. De Baerdemaeker, F. Feyaerts, L. Van Gool, R. De Winne,
    R. Van den Bulcke Development of a weed activated spraying machine for targeted
    application of herbicides Aspects of Applied Biology, 66 (2002), pp. 147-164 Google
    Scholar Roberts et al., 2006 Roberts, M.J., Schimmelpfennig, D., Ashley, E., Livingston,
    M., Ash, M., Vasavada, U., 2006. The value of plant disease early-warning systems.
    Economic Research Service No. 18, United States Department of Agriculture. Google
    Scholar Roggo et al., 2003 Y. Roggo, L. Duponchel, J.P. Huvenne Comparison of
    supervised pattern recognition methods with McNemar''s statistical test: application
    to qualitative analysis of sugar beet by near-infrared spectroscopy Analytica
    Chimica Acta, 477 (2) (2003), pp. 187-200 View PDFView articleView in ScopusGoogle
    Scholar Ruiz-Ruiz et al., 2009 S. Ruiz-Ruiz, S. Ambrós, M. Carmen Vives, L. Navarro,
    P. Moreno, J. Guerri Detection and quantification of Citrus leaf blotch virus
    by TaqMan real-time RT-PCR Journal of Virological Methods, 160 (1–2) (2009), pp.
    57-62 View PDFView articleView in ScopusGoogle Scholar Saponari et al., 2008 M.
    Saponari, K. Manjunath, R.K. Yokomi Quantitative detection of Citrus tristeza
    virus in citrus and aphids by real-time reverse transcription-PCR (TaqMan®) Journal
    of Virological Methods, 147 (1) (2008), pp. 43-53 View PDFView articleView in
    ScopusGoogle Scholar Schaad and Frederick, 2002 N.W. Schaad, R.D. Frederick Real-time
    PCR and its application for rapid plant disease diagnostics Canadian Journal of
    Plant Pathology, 24 (3) (2002), pp. 250-258 CrossRefView in ScopusGoogle Scholar
    Scharte et al., 2005 J. Scharte, H. Schön, E. Weis Photosynthesis and carbohydrate
    metabolism in tobacco leaves during an incompatible interaction with Phytophthora
    nicotianae Plant, Cell and Environment, 28 (2005), pp. 1421-1435 CrossRefView
    in ScopusGoogle Scholar Shafri and Hamdan, 2009 H.Z.M. Shafri, N. Hamdan Hyperspectral
    imagery for mapping disease infection in oil palm plantation using vegetation
    indices and red edge techniques American Journal of Applied Sciences, 6 (6) (2009),
    pp. 1031-1035 View in ScopusGoogle Scholar Sighicelli et al., 2009 M. Sighicelli,
    F. Colao, A. Lai, S. Patsaeva Monitoring post-harvest orange fruit disease by
    fluorescence and reflectance hyperspectral imaging ISHS Acta Horticulturae, 817
    (2009), pp. 277-284 CrossRefView in ScopusGoogle Scholar Sirisomboon et al., 2009
    P. Sirisomboon, Y. Hashimoto, M. Tanaka Study on non-destructive evaluation methods
    for defect pods for green soybean processing by near-infrared spectroscopy Journal
    of Food Engineering, 93 (2009), pp. 502-512 View PDFView articleView in ScopusGoogle
    Scholar Spinelli et al., 2006 F. Spinelli, M. Noferini, G. Costa Near infrared
    spectroscopy (NIRs): Perspective of fire blight detection in asymptomatic plant
    material Proceeding of 10th International Workshop on Fire Blight, Acta Horticulturae,
    704 (2006), pp. 87-90 CrossRefView in ScopusGoogle Scholar Staudt and Lhoutellier,
    2007 M. Staudt, L. Lhoutellier Volatile organic compound emission from holm oak
    infested by gypsy moth larvae: evidence for distinct responses in damaged and
    undamaged leaves Tree Physiology, 27 (2007), pp. 1433-1440 CrossRefView in ScopusGoogle
    Scholar Sundaram et al., 2009 J. Sundaram, C.V. Kandala, C.L. Butts Application
    of near infrared (NIR) spectroscopy to peanut grading and quality analysis: Overview
    Sensing and Instrumentation for Food Quality and Safety, 3 (3) (2009), pp. 156-164
    CrossRefView in ScopusGoogle Scholar Tallada et al., 2006 Tallada, J.G., Nagata,
    M., Kobayashi, T., 2006. Detection of bruises in strawberries by hyperspectral
    Imaging. ASABE Paper No. 063014, 2006 ASABE Annual International Meeting, Portland,
    Oregon, 9–12 July 2006. Google Scholar Teixeira et al., 2005 D.C. Teixeira, J.L.
    Danet, S. Eveillard, E.C. Martins, W.C.J. Junior, P.T. Yamamoto, S.A. Lopes, R.B.
    Bassanezi, A.J. Ayres, C. Saillard, J.M. Bové Citrus huanglongbing in São Paulo
    State, Brazil: PCR detection of the ‘Candidatus’ Liberibacter species associated
    with the disease Molecular and Cellular Probes, 19 (2005), pp. 173-179 View in
    ScopusGoogle Scholar Tholl et al., 2006 D. Tholl, W. Boland, A. Hansel, F. Loreto,
    U.S.R. Röse, J.P. Schnitzler Practical approaches to plant volatile analysis The
    Plant Journal, 45 (2006), pp. 540-560 View in ScopusGoogle Scholar Urasaki et
    al., 2008 N. Urasaki, S. Kawano, H. Mukai, T. Uemori, O. Takeda, T. Sano Rapid
    and sensitive detection of “Candidatus Liberibacter asiaticus” by cycleave isothermal
    and chimeric primer-initiated amplification of nucleic acids Journal of General
    Plant Pathology, 74 (2008), pp. 151-155 CrossRefView in ScopusGoogle Scholar Vallat
    et al., 2005 A. Vallat, H. Gu, S. Dorn How rainfall, relative humidity and temperature
    influence volatile emissions from apple trees in situ Phytochemistry, 66 (2005),
    pp. 1540-1550 View PDFView articleView in ScopusGoogle Scholar Vikram et al.,
    2006 A. Vikram, L.H. Lui, A. Hossain, A.C. Kushalappa Metabolic fingerprinting
    to discriminate diseases of stored carrots Annals of Applied Biology, 148 (2006),
    pp. 17-26 CrossRefView in ScopusGoogle Scholar Vuorinen et al., 2007 T. Vuorinen,
    A.M. Nerg, L. Syrjälä, P. Peltonen, J.K. Holopainen Epirrita autumnata induced
    VOC emission of silver birch differ from emission induced by leaf fungal pathogen
    Arthropod–Plant Interactions, 1 (2007), pp. 159-165 CrossRefGoogle Scholar Wang
    et al., 2002 D. Wang, M.S. Ram, F.E. Dowell Classification of damaged soybean
    seeds using near-infrared spectroscopy Transactions of the ASAE, 45 (6) (2002),
    pp. 1943-1948 View in ScopusGoogle Scholar Wang et al., 2009 Wang, W., Thai, C.,
    Li, C., Gitaitis, R., Tollner, E.W., Yoon, S.C., 2009. Detecting of sour skin
    diseases in Vidalia sweet onions using near-infrared hyperspectral imaging. In:
    2009 ASABE Annual International Meeting, Reno, NV, Paper No. 096364. Google Scholar
    West et al., 2003 J.S. West, C. Bravo, R. Oberti, D. Lemaire, D. Moshou, H.A.
    McCartney The potential of optical canopy measurement for targeted control of
    field crop disease Annual Review of Phytopathology, 41 (2003), pp. 593-614 View
    in ScopusGoogle Scholar Williamson et al., 1992 B. Williamson, B.A. Goodman, J.A.
    Chudek Nuclear magnetic resonance (NMR) micro-imaging of ripening red raspberry
    fruits New Phytologist, 120 (1992), pp. 21-28 CrossRefView in ScopusGoogle Scholar
    Wu et al., 2008 D. Wu, L. Feng, C. Zhang, Y. He Early detection of Botrytis cinerea
    on eggplant leaves based on visible and near-infrared spectroscopy Transactions
    of the ASABE, 51 (3) (2008), pp. 1133-1139 View in ScopusGoogle Scholar Xing and
    Baerdemaeker, 2005 J. Xing, J.D. Baerdemaeker Bruise detection on ‘Jonagold’ apples
    using hyperspectral imaging Postharvest Biology and Technology, 37 (2) (2005),
    pp. 152-162 View PDFView articleView in ScopusGoogle Scholar Xing et al., 2005
    J. Xing, C. Bravo, P.T. Jancsók, H. Ramon, J.D. Baerdemaeker Detecting bruises
    on ‘golden delicious’ apples using hyperspectral imaging with multiple wavebands
    Biosystems Engineering, 90 (1) (2005), pp. 27-36 View PDFView articleView in ScopusGoogle
    Scholar Xu et al., 2007 H.R. Xu, Y.B. Ying, X.P. Fu, S.P. Zhu Near-infrared spectroscopy
    in detecting leaf miner damage on tomato leaf Biosystems Engineering, 96 (4) (2007),
    pp. 447-454 View PDFView articleView in ScopusGoogle Scholar Yang and Cheng, 2001
    C.M. Yang, C.H. Cheng Spectral characteristics of rice plants infested by brown
    planthoppers Proceedings of the National Science Council, Republic of China. Part
    B, Life Sciences, 25 (3) (2001), pp. 180-186 View in ScopusGoogle Scholar Yang
    et al., 2007 C.M. Yang, C.H. Cheng, R.K. Chen Changes in spectral characteristics
    of rice canopy infested with brown planthopper and leaffolder Crop Science, 47
    (2007), pp. 329-335 CrossRefView in ScopusGoogle Scholar Yao et al., 2005 Yao,
    H., Hruska, Z., DiCrispino, K., Brabham, K., Lewis, D., Beach, J., Brown, R.L.,
    Cleveland, T.E., 2005. Differentiation of fungi using hyperspectral imagery for
    food inspection. ASAE Paper No. 053127, 2005 ASAE Annual International Meeting,
    Tampa, FL, 17–20 July 2005. Google Scholar Yvon et al., 2009 M. Yvon, G. Thébaud,
    R. Alary, G. Labonne Specific detection and quantification of the phytopathogenic
    agent ‘Candidatus Phytoplasma prunorum’ Molecular and Cellular Probes, 23 (5)
    (2009), pp. 227-234 View PDFView articleView in ScopusGoogle Scholar Zhang et
    al., 2008a C. Zhang, Y. Shen, J. Chen, P. Xiao, J. Bao Nondestructive prediction
    of total phenolics, flavonoid contents, and antioxidant capacity of rice grain
    using near-infrared spectroscopy Journal of Agricultural and Food Chemistry, 56
    (18) (2008), pp. 8268-8272 CrossRefView in ScopusGoogle Scholar Zhang et al.,
    2008b H. Zhang, M. Chang, J. Wang, S. Ye Evaluation of peach quality indices using
    an electronic nose by MLR, QPST and BP network Sensors and Actuators B: Chemical,
    134 (1) (2008), pp. 332-338 View PDFView articleView in ScopusGoogle Scholar Zhang
    and Wang, 2007 H. Zhang, J. Wang Detection of age and insect damage incurred by
    wheat, with an electronic nose Journal of Stored Products Research, 43 (2007),
    pp. 489-495 View PDFView articleView in ScopusGoogle Scholar Zhang et al., 2003
    M. Zhang, Z. Qin, X. Liu, S.L. Ustin Detection of stress in tomatoes induced by
    late blight disease in California, USA, using hyperspectral remote sensing International
    Journal of Applied Earth Observation and Geoinformation, 4 (2003), pp. 295-310
    View PDFView articleView in ScopusGoogle Scholar Zhang et al., 2005 M. Zhang,
    Z. Qin, X. Liu Remote sensed spectral imagery to detect late blight in field tomatoes
    Precision Agriculture, 6 (6) (2005), pp. 489-508 CrossRefView in ScopusGoogle
    Scholar Cited by (947) Recent advances in hydrogel microneedle-based biofluid
    extraction and detection in food and agriculture 2024, Biosensors and Bioelectronics
    Show abstract Hyperspectral imaging coupled with machine learning for classification
    of anthracnose infection on mango fruit 2024, Spectrochimica Acta - Part A: Molecular
    and Biomolecular Spectroscopy Show abstract Multi-task learning model for agricultural
    pest detection from crop-plant imagery: A Bayesian approach 2024, Computers and
    Electronics in Agriculture Show abstract Detection of oilseed rape clubroot based
    on low-field nuclear magnetic resonance imaging 2024, Computers and Electronics
    in Agriculture Show abstract Revisiting the role of sulfur in crop production:
    A narrative review 2024, Journal of Agriculture and Food Research Show abstract
    Identification of spectral ranges that contribute to phytoplasma detection in
    apple trees – A step towards an on-site method 2023, Spectrochimica Acta - Part
    A: Molecular and Biomolecular Spectroscopy Show abstract View all citing articles
    on Scopus View Abstract Copyright © 2010 Elsevier B.V. All rights reserved. Recommended
    articles Plant leaf diseases detection and auto-medicine Internet of Things, Volumes
    1–2, 2018, pp. 67-73 Channamallikarjuna Mattihalli, …, Adugna Necho View PDF Detection
    and differentiation between potato (Solanum tuberosum) diseases using calibration
    models trained with non-imaging spectrometry data Computers and Electronics in
    Agriculture, Volume 167, 2019, Article 105056 Damian Bienkowski, …, Roy Neilson
    View PDF Hyperspectral imaging for classification of healthy and gray mold diseased
    tomato leaves with different infection severities Computers and Electronics in
    Agriculture, Volume 135, 2017, pp. 154-162 Chuanqi Xie, …, Yong He View PDF Show
    3 more articles Article Metrics Citations Citation Indexes: 909 Patent Family
    Citations: 1 Policy Citations: 12 Captures Readers: 1447 Social Media Shares,
    Likes & Comments: 20 View details About ScienceDirect Remote access Shopping cart
    Advertise Contact and support Terms and conditions Privacy policy Cookies are
    used by this site. Cookie settings | Your Privacy Choices All content on this
    site: Copyright © 2024 Elsevier B.V., its licensors, and contributors. All rights
    are reserved, including those for text and data mining, AI training, and similar
    technologies. For all open access content, the Creative Commons licensing terms
    apply.'
  inline_citation: '>'
  journal: Computers and electronics in agriculture
  limitations: '>'
  pdf_link: null
  publication_year: 2010
  relevance_score1: 0
  relevance_score2: 0
  title: A review of advanced techniques for detecting plant diseases
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1016/j.compag.2022.106973
  analysis: '>'
  authors:
  - Maxime Ryckewaert
  - Daphné Héran
  - Thierry Simonneau
  - Florent Abdelghafour
  - Romain Boulord
  - Nicolas Saurin
  - Daniel C. Moura
  - Silvia Mas-Garcia
  - Ryad Bendoula
  citation_count: 6
  full_citation: '>'
  full_text: '>

    403 Forbidden Code: AccessDenied Message: Access Denied RequestId: 5VP8XXTKMJCZVK32
    HostId: aRkg2cMVKIxv+yj8yZMCadtgbnpy02hF+hwdA3925Wte4HMJEjtubh/whkN/WQDYG5NpD6B8oKs='
  inline_citation: '>'
  journal: Computers and electronics in agriculture
  limitations: '>'
  pdf_link: http://manuscript.elsevier.com/S0168169922002903/pdf/S0168169922002903.pdf
  publication_year: 2022
  relevance_score1: 0
  relevance_score2: 0
  title: 'Physiological variable predictions using VIS–NIR spectroscopy for water
    stress detection on grapevine: Interest in combining climate data using multiblock
    method'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1016/j.rse.2011.10.007
  analysis: '>'
  authors:
  - Pablo J. Zarco‐Tejada
  - Victoria González-Dugo
  - J.A.J. Berni
  citation_count: 685
  full_citation: '>'
  full_text: '>

    Skip to main content Skip to article Journals & Books Search Register Sign in
    Brought to you by: University of Nebraska-Lincoln View PDF Download full issue
    Outline Abstract Keywords 1. Introduction 2. Materials and methods 3. Results
    4. Discussion 5. Conclusions Acknowledgments References Show full outline Cited
    by (710) Figures (14) Show 8 more figures Tables (3) Table 1 Table 2 Table 3 Remote
    Sensing of Environment Volume 117, 15 February 2012, Pages 322-337 Fluorescence,
    temperature and narrow-band indices acquired from a UAV platform for water stress
    detection using a micro-hyperspectral imager and a thermal camera Author links
    open overlay panel P.J. Zarco-Tejada, V. González-Dugo, J.A.J. Berni Show more
    Add to Mendeley Share Cite https://doi.org/10.1016/j.rse.2011.10.007 Get rights
    and content Abstract The remote detection of water stress in a citrus orchard
    was investigated using leaf-level measurements of chlorophyll fluorescence and
    Photochemical Reflectance Index (PRI) data, seasonal time-series of crown temperature
    and PRI, and high-resolution airborne imagery. The work was conducted in an orchard
    where a regulated deficit irrigation (RDI) experiment generated a gradient in
    water stress levels. Stomatal conductance (Gs) and water potential (Ψ) were measured
    over the season on each treatment block. The airborne data consisted on thermal
    and hyperspectral imagery acquired at the time of maximum stress differences among
    treatments, prior to the re-watering phase, using a miniaturized thermal camera
    and a micro-hyperspectral imager on board an unmanned aerial vehicle (UAV). The
    hyperspectral imagery was acquired at 40 cm resolution and 260 spectral bands
    in the 400-885 nm spectral range at 6.4 nm full width at half maximum (FWHM) spectral
    resolution and 1.85 nm sampling interval, enabling the identification of pure
    crowns for extracting radiance and reflectance hyperspectral spectra from each
    tree. The FluorMOD model was used to investigate the retrieval of chlorophyll
    fluorescence by applying the Fraunhofer Line Depth (FLD) principle using three
    spectral bands (FLD3), which demonstrated that fluorescence retrieval was feasible
    with the configuration of the UAV micro-hyperspectral instrument flown over the
    orchard. Results demonstrated the link between seasonal PRI and crown temperature
    acquired from instrumented trees and field measurements of stomatal conductance
    and water potential. The sensitivity of PRI and Tc–Ta time-series to water stress
    levels demonstrated a time delay of PRI vs Tc–Ta during the recovery phase after
    re-watering started. At the time of the maximum stress difference among treatment
    blocks, the airborne imagery acquired from the UAV platform demonstrated that
    the crown temperature yielded the best coefficient of determination for Gs (r2
    = 0.78; p < 0.05) and Ψ (r2 = 0.34; p < 0.001). Among the narrow-band indices
    calculated, the PRI515 index (reference band = 515 nm) obtained better results
    than PRI570, with r2 = 0.59 (p < 0.01) for Gs, and r2 = 0.38 (p < 0.001) for Ψ.
    The BGI1 index calculated from the blue (R400) and green (R550) bands resulted
    on the highest significance levels (p < 0.001) for both Gs (r2 = 0.62) and Ψ (r2
    = 0.49). Out of the structural indices assessed, RDVI, MTVI1 and TVI showed greater
    sensitivity for Gs (r2 = 0.6; p < 0.01) and Ψ (p < 0.001) than NDVI. Chlorophyll
    fluorescence calculated from the micro-hyperspectral imagery with the FLD3 method
    tracked stress levels, obtaining r2 = 0.67 (p < 0.05) with stomatal conductance,
    and r2 = 0.66 (p < 0.001) with water potential. The work presented in this manuscript
    demonstrates the feasibility of thermal, narrow-band indices and fluorescence
    retrievals obtained from a micro-hyperspectral imager and a light-weight thermal
    camera on board small UAV platforms for stress detection in a heterogeneous tree
    canopy where very high resolution is required. Highlights ► Water stress was investigated
    using a micro-hyperspectral imager on board an UAV. ► A link between PRI and crown
    temperature was demonstrated over the entire season. ► Seasonal variation of PRI
    and Tc-Ta demonstrated a time delay of PRI during recovery. ► Best indicators
    of stress were crown Tc, F (FLD method) and the BGI1 index. ► It demonstrates
    the F retrieval using micro-hyperspectral imagers on board UAVs. Previous article
    in issue Next article in issue Keywords Stress detectionHyperspectralChlorophyll
    fluorescenceUAVHigh resolutionThermal 1. Introduction Water deficits occur in
    plants when evaporative demand exceeds the supply of water in the soil (Slatyer,
    1967). It has long been found that short-term water deficits may affect growth
    processes (Hsiao et al., 1976), and therefore early detection of water stress
    is important. Water stress also induces stomatal closure, which reduces the transpiration
    rate, thus decreasing evaporative cooling and increasing leaf temperature. The
    increase in leaf and canopy temperatures was first suggested in the 1960s as a
    method of tracking water stress using thermal infrared thermometers (Fuchs and
    Tanner, 1966, Idso et al., 1978, Idso et al., 1981, Jackson, 1982, Jackson, Idso,
    Reginato and Ehrler, 1977, Jackson, Reginato and Idso, 1977, Jackson et al., 1981,
    Tanner, 1963). More recently, Sepulcre-Cantó et al., 2006, Sepulcre-Cantó et al.,
    2007 demonstrated that high-resolution airborne thermal imagers flown over orchard
    crops detected small canopy temperature differences linked to water stress levels.
    Later, Berni et al. (2009a) generated maps of tree canopy conductance (Gc) in
    orchards by applying a model based on canopy temperature estimated from high resolution
    airborne imagery, using as inputs net radiation and aerodynamic resistance as
    a function of wind speed and canopy structure. Nevertheless, monitoring of plant
    water status is critical not only for early detection of stress, but also to enable
    the application of deficit irrigation (DI) techniques (Fereres and Soriano, 2007)
    with the degree of precision needed. Generally, when DI methods are correctly
    applied in many fruit tree species, yield and fruit size are not affected (Girona,
    2002), while some quality parameters are increased and water is saved (Crisosto
    et al., 1994, Fereres and Soriano, 2007, Girona et al., 2003, Mills et al., 1994).
    Even though canopy temperature is considered reliable as a proxy for plant water
    status monitoring (Jackson, 1982), there are physiological and remote sensing
    operational issues that support the development of new water-stress sensitive
    indices based on the visible and near infrared spectral regions (Suárez et al.,
    2009, Suárez et al., 2010). On the physiology side, in some crop plants the diurnal
    patterns of stomatal conductance are such that the relationships between canopy
    temperature and stress levels are not clear-cut. This is the case of citrus trees
    in semi-arid areas, where high vapor pressure deficits induce a continuous decline
    in leaf conductance from the early morning hours, even when trees are well supplied
    with water (Fereres et al., 1979, Hall et al., 1975, Villalobos et al., 2008).
    The level of stomatal conductance thus interacts with the evaporative demand and
    internal water status of the tree to determine tree canopy temperature. On the
    operational side, monitoring of large agricultural fields of tree and vineyard
    crops, generally planted in grids and therefore affected by soil background and
    shadows, requires high spatial resolution and short revisit periods (Berni et
    al., 2009b). The satellite thermal imagery currently available is limited to Landsat
    TM and ASTER sensors, yielding 120 m and 90 m, respectively. In such cases, monitoring
    of water stress is potentially suitable for regional scales only when canopy heterogeneity
    is accounted for (Moran et al., 1994). Nevertheless, modeling methods conducted
    with DART 3D simulation for orchards demonstrated the large effects due to soil
    and shadow components on the aggregated thermal pixel as a function of planting
    grid and soil temperature variations (Sepulcre-Cantó et al., 2009), making it
    difficult to monitor stress levels even for the extreme conditions in discontinuous
    orchards. Two pre-visual indicators of water stress proposed in the literature
    are the Physiological Reflectance Index (PRI) (Gamon et al., 1992), an index sensitive
    to the epoxidation state of the xanthophyll cycle pigments and to photosynthetic
    efficiency, serving as a proxy for water stress detection (Peguero-Pina et al.,
    2008, Suárez et al., 2009, Suárez et al., 2010, Suarez et al., 2008, Thenot et
    al., 2002), and the solar-induced chlorophyll fluorescence emission (Flexas et
    al., 2000, Flexas et al., 2002, Flexas et al., 1999, Moya et al., 2004) due to
    the link demonstrated between steady-state chlorophyll fluorescence and stomatal
    conductance. Although PRI was initially proposed as an indicator of the de-epoxidation
    state of the xanthophyll pigments and related to photosynthesis, recent studies
    demonstrate the sensitivity of this index for vegetation stress detection (Peguero-Pina
    et al., 2008, Suárez et al., 2009, Suárez et al., 2010, Suarez et al., 2008, Thenot
    et al., 2002). Therefore, PRI could be used for water stress detection as an alternative
    to thermal measurements, enabling the use of high spatial resolution capabilities
    that are more difficult in the thermal region. The other pre-visual water stress
    indicator is chlorophyll fluorescence, as several studies demonstrated its link
    with photosynthesis and other plant physiological processes (Krause and Weis,
    1984, Larcher, 1994, Lichtenthaler, 1992, Lichtenthaler and Rinderle, 1988, Papageorgiou,
    1975, Schreiber and Bilger, 1987, Schreiber et al., 1994). Steady-state chlorophyll
    fluorescence (Fs) has received less attention than other fluorescence measures,
    but its potential as a physiological indicator of stress using remote sensing
    methods has been recently emphasized (Soukupová et al., 2008), along with increasing
    scientific interest during the past five years. Nevertheless, retrieval of the
    fluorescence signal is very challenging since the contribution to the radiance
    signal is estimated to be about 2–3%. Several methods have been reported to extract
    the fluorescence signal at the leaf and canopy levels (Meroni et al., 2004, Meroni,
    Picchi, et al., 2008, Meroni et al., 2009, Meroni, Rossini, et al., 2008, Moya
    et al., 2004), which demonstrated the feasibility of fluorescence retrieval using
    the O2-A band feature. Additional experiments conducted at 0.065 nm FWHM resolution
    using ratios between the 757 nm (out) and 760 nm (in) bands (Pérez-Priego et al.,
    2005) showed good diurnal relationships between fluorescence and water stress
    levels at the canopy scale. Nevertheless, little work has been conducted for validation
    purposes at the airborne scale due to the lack of appropriate imagery at high
    spatial and spectral resolutions. Recent work (Zarco-Tejada et al., 2009) applied
    the in-filling method to 1 nm FWHM multispectral imagery acquired over peach,
    orange and olive orchards for water and nutrient stress detection. A thorough
    review of fluorescence detection methods can be found in Meroni et al. (2009),
    where the methodologies for fluorescence retrieval as a function of the type of
    instrument and number of bands available are discussed. Along these research objectives,
    a recent study assessed the impact of spectral sensor configurations on the Fraunhofer
    Line Depth (FLD) retrieval accuracy (Damm et al., 2011). A modeling work was used
    to study the effects of the spectral sampling interval, spectral resolution, signal
    to noise ratio, and spectral shift on the accuracy of the Fs retrievals using
    three FLD methods available. Results indicated the superior performance of the
    FLD3 method, the critical impact of the signal to noise ratio of the instrument
    used, and the feasibility for F retrievals with sensor configurations of 5 nm
    spectral resolution and small sampling intervals. Although PRI, fluorescence and
    canopy temperature have been proposed for water stress detection, their use has
    not been assessed over an entire season. In addition, the sensitivity of both
    temperature and PRI measured at the tree crown level needs further study, including
    an assessment for a new index formulation for PRI using the 515 nm wavelength
    as a reference band (Hernández-Clemente et al., 2011). The research reported here
    used continuous leaf and crown measurements of temperature and PRI during a citrus
    experiment to assess the seasonal variations in water stress levels. In addition,
    a micro-hyperspectral imager and a thermal camera were installed on board an unmanned
    aerial vehicle (UAV), and the imagery used to extract pure crown temperature,
    radiance and reflectance spectra to estimate chlorophyll fluorescence, visible
    ratios and structural indices for water stress detection. The Vegetation Fluorescence
    Canopy Model (FluorMOD) (Miller et al., 2004), a linked leaf model FluorMODleaf
    (Pedrós et al., 2004, Pedrós et al., 2008), and a canopy model FluorSAIL (Verhoef,
    2004) were used to simulate canopy fluorescence and scattered radiance. Although
    the model requires further validation and refinement, FluorMOD was used as a tool
    for understanding the effects of the spectral bandwidth of the airborne sensor
    used to image the orchard for the retrieval of fluorescence through the FLD method.
    2. Materials and methods Field measurements were carried out during the 2010 irrigation
    season (from June through October) in a commercial citrus orchard, including leaf
    stomatal conductance (Gs), water potential (Ψ), and continuous point measurements
    of crown temperature and PRI. High resolution thermal and hyperspectral imagery
    was collected over the citrus orchard in September 2010 to assess the sensitivity
    of vegetation indices and canopy temperature for water stress detection. 2.1.
    Field experiments and airborne campaigns 2.1.1. Field data collection The study
    was carried out in 2010 in two 0.6-ha plots of orange and mandarin trees in a
    commercial orchard located near La Campana, Seville (Spain) (37.8°N, 5.4°W). The
    orange trees (Citrus sinensis L. cv. Powell) were planted in 1997 in a 7 m × 4
    m grid (358 trees/ha) in deep alluvial soil with a loam to sandy-loam texture.
    The mandarin (Citrus reticulata Blanco cv. Clemenvilla) orchard was planted in
    1997 in a 7 m × 3 m grid. The climate in the area is Mediterranean, characterized
    by warm, dry summers and cool, wet winters, with an average annual rainfall and
    ETo (Penman–Monteith) of around 550 and 1300 mm, respectively. Four irrigation
    treatments were set up: i) farmer irrigation management (computed according to
    commercial practices); ii) 100% ET, where irrigation was scheduled to satisfy
    full (100%) ET requirements (estimated as crop evapotranspiration); iii) Regulated
    Deficit Irrigation (RDI1), with a deficit irrigation period (dates are shown in
    Table 1), where only 37% ET was applied; and iv) RDI2, similar to RDI1, but where
    the level of water application during the deficit irrigation period was 50% ET.
    Crop evapotranspiration was estimated as a crop coefficient (adapted to local
    conditions), and ETo was calculated from meteorological data provided by an automatic
    weather station located 10 km from the orchard. Each treatment was applied to
    individual plots of 12 trees and repeated four times. Table 1 lists the treatments,
    irrigation periods and depths, ground data collection and harvest and imagery
    acquisition dates for the orchard used in this study. Over the growing season,
    a Scholander pressure bomb (PWSC Model 3000, Soilmoisture Equipment Corp., CA,
    USA) was used to measure xylem water potential (Ψ) weekly or biweekly around noon
    on 4 selected trees per treatment. Stomatal conductance was measured on 12 trees
    using a leaf porometer (model SC-1, Decagon Devices, Inc., Pullman, WA, USA) at
    the time of the flights. On the same day, the number of water potential measurements
    was increased to a total of 40 monitored trees, representing a wide range of water
    stress conditions. Table 1. Summary of each study site, ground data collected,
    and imagery acquisition dates. The treatments under RDI had a withheld period
    (no irrigation) followed by a re-watering period until their stem water potential
    was equal to the control. Species Treatments Irrigation strategy Withheld period
    Irrigation dose Continuous monitoring During flights (09/14) Mandarin Field Sustained
    Ψ, Gs 100ET Full requirements 100% ET Leaf and canopy PRI, Tc, Ψ, Gs RDI1 Regulated
    06/23 to 08/31 37% ET during RDI period, later: 100% ET Leaf and canopy PRI, Tc,
    Ψ, Gs RDI2 Regulated 06/23 to 08/31 50% ET during RDI period, later: 100% ET Ψ,
    Gs Orange Field Sustained Ψ, Gs Ψ 100ET Full requirements 100% ET Tc, Ψ, Gs Ψ,
    Gs RDI1 Regulated 06/23 to 09/15 37% ET during RDI period, later: 100% ET Tc,
    Ψ, Gs Ψ, Gs RDI2 Regulated 06/23 to 09/15 50% ET during RDI period, later: 100%
    ET Ψ, Gs Ψ Leaf chlorophyll fluorescence measurements made under natural light
    conditions were conducted using the Pulse-Amplitude-Modulated Fluorometer PAM-2100
    (Heinz Walz GMBH, Effeltrich, Germany), measuring steady-state Fs fluorescence
    on 8 selected trees, 30 leaves/tree. Fluorescence measurements were conducted
    at three times over the course of the day from 9.00 h until 15:00 h local time
    in order to monitor the diurnal variation of Fs for well-watered and water-stressed
    trees. Leaf PRI measurements calculated as (R570 − R531) / (R531 + R570) (Suárez
    et al., 2009, Suárez et al., 2010, Suarez et al., 2008) were conducted on 4 mandarin
    trees (two trees under 100% ET irrigation treatment, and two RDI1 water-stressed
    trees), measuring each date 30 leaves/tree with a PlantPen instrument (Photon
    Systems Instruments, Brno, Czech Republic) for a total of 9 days from June until
    late September. Leaf PRI measurements were conducted between 11.00 h and 12.00
    h local time on each date. In addition to the single-date measurements conducted
    for water potential, stomatal conductance, steady-state chlorophyll fluorescence,
    and leaf PRI, a total of 8 trees were instrumented with IRR-P thermal sensors
    (22° half-angle FOV) (Apogee, UT, USA) and 4 canopy PRI sensors (25° FOV) (SKR
    1800, Skye Instruments, Powyd, UK), acquiring continuous thermal and PRI crown
    data (calculated as (R570 − R531) / (R570 + R531)) from May 2010 throughout the
    entire season in the mandarin and orange orchards. The multispectral Skye sensors
    were installed in tandem with the IRR-P thermal sensors, both targeting the same
    crown spots and acquiring at 530 and 570 nm bands with a 10 nm FWHM bandwidth.
    An additional PRI sensor was installed in the field for continuous measurement
    of downwelling irradiance using a cosine diffuser. The measurements were acquired
    at a rate of 1/s and were aggregated to store the mean value at 5-minute intervals
    in dataloggers installed in the field (model CR10X, Campbell Sci., UT, USA). Air
    temperature (Ta) data were measured continuously in the field with a Vaisala Weather
    Transmitter (model WXT510, Vaisala Oyj, Helsinki, Finland) installed in the study
    site 1 m above the trees. The single-band infrared temperature (IRT) sensors covered
    the 6.5-14 μm range, and were assessed both in the laboratory and under natural
    sun conditions to characterize the IRT response to diurnal temperature variation
    (Sepulcre-Cantó et al., 2006), yielding errors within the accuracy limits of the
    instrument, ± 0.4 °C, over a 5 °C to 40 °C range. All upwelling and downwelling
    instruments were calibrated in the laboratory using a uniform calibration body
    (integrating sphere, CSTM-USS-2000C Uniform Source System, LabSphere, NH, USA)
    at two different levels of illumination. Additionally, a radiance calibration
    was conducted at noon twice on each of the four upwelling PRI sensors using three
    lambertian panels of 2% (black), 50% (gray) and 98% reflectance (white) (LabSphere,
    NH, USA). The aim was to ensure a proper radiance calibration over the season
    and to test the linearity of the instruments under natural light conditions. 2.1.2.
    Airborne campaigns An unmanned aerial vehicle (UAV) platform for remote sensing
    research was developed at the Laboratory for Research Methods in Quantitative
    Remote Sensing (QuantaLab, IAS-CSIC, Spain) to carry a payload with thermal and
    hyperspectral imaging sensors (Berni, Zarco-Tejada, Suarez and Fereres, 2009,
    Zarco-Tejada et al., 2008). The UAV consisted of a 5-m wingspan fixed-wing platform
    capable of carrying a 3 kg payload for 1.5 h endurance at 13.5 kg take-off weight
    (TOW) (Viewer, ELIMCO, Seville, Spain). The UAV was controlled by an autopilot
    for autonomous flight (AP04, UAV Navigation, Madrid, Spain) to follow a flight
    plan using waypoints. The autopilot consists of a dual CPU controlling an integrated
    Attitude Heading Reference System (AHRS) based on a L1 GPS board, 3-axis accelerometers,
    yaw rate gyros and a 3-axis magnetometer (Berni et al., 2009b). Communication
    with the ground was conducted through a radio link where position, attitude and
    status data were transmitted at 20 Hz frequency; this also acted as a communication
    link for the operation of remote sensing hyperspectral and thermal cameras on
    board the UAV. The hyperspectral imager installed on board the UAV was a micro-hyperspectral
    camera (Micro-Hyperspec VNIR model, Headwall Photonics, MA, USA) flown in the
    spectral mode of 260 bands at 1.85 nm/pixel at 12-bit radiometric resolution,
    yielding an FWHM of 3.2 nm with a 12-micron slit, and 6.4 nm with a 25-micron
    slit. Data acquisition and storage on board the UAV was set to 50 fps, and integration
    time was 18 ms. The current system operated by QuantaLab-IAS-CSIC (Spain) is capable
    of acquiring 320 bands in the 400-1000 nm region, although the campaign described
    here was flown with 260 bands in the 400–885 nm region due to storage and data
    rate limitations at the time of the campaign. The 8-mm optics focal length yielded
    an IFOV of 0.93 mrad, an angular FOV of 50°, obtaining a swath of 522 m at 53
    × 42 cm resolution, resampled to 40 cm for a flight conducted at 575 m AGL altitude
    and 75 km/h ground speed. The airborne campaign over the orchard consisted on
    flightlines acquired in the solar plane at 11.00 am local time on September 14th
    2010, acquiring both hyperspectral and thermal imagery. The hyperspectral imager
    was radiometrically calibrated using coefficients derived from measurements made
    with a calibrated uniform light source (integrating sphere, CSTM-USS-2000C Uniform
    Source System, LabSphere, NH, USA) at four different levels of illumination and
    six different integration times. Hyperspectral imagery was atmospherically corrected
    using the total incoming irradiance at 1 nm intervals simulated with the SMARTS
    model developed by the National Renewable Energy Laboratory, US Department of
    Energy (Gueymard, 1995, Gueymard, 2001) using aerosol optical depth measured at
    550 nm with a Micro-Tops II sunphotometer (Solar LIGHT Co., Philadelphia, PA,
    USA) collected in the study areas at the time of the flights. SMARTS computes
    clear sky spectral irradiance, including direct beam, circumsolar, hemispherical
    diffuse, and total on a tilted or horizontal plane for specified atmospheric conditions.
    The algorithms were developed to match the output from the MODTRAN complex band
    models within 2%, but using aerosol optical depth as input. The spectral resolution
    is 0.5 nm for the 280–400 nm region, 1 nm for the 400–1750 nm, and 10 nm for 1750–4000
    nm spectral regions. This radiative transfer model has been previously used in
    other studies to perform the atmospheric correction of narrow-band multispectral
    imagery, such as in Berni, Zarco-Tejada, Suarez and Fereres, 2009, Suárez et al.,
    2010. The output irradiance at 0.5 and 1 nm spectral bandwidth from SMARTS has
    been used as a reference irradiance spectra for solar energy studies (Gueymard
    et al., 2002) and available at http://www.nrel.gov/ (Gueymard, 2005). An inertial
    measuring unit (IMU) installed on board the UAV synchronized with the hyperspectral
    imager was used to ortho-rectify the imagery using PARGE (ReSe Applications Schläpfer,
    Wil, Switzerland) (Fig. 1a). The orchard study site used for field data collection
    can be seen in Fig. 1b. The high resolution hyperspectral imagery acquired over
    the orchard enabled single tree identification for field validation purposes (Fig.
    1c), successfully separating pure crown from shaded and sunlit soil reflectance.
    Each single pure tree crown from the entire orchard was identified using automatic
    object-based crown-detection algorithms, enabling the extraction of average crown
    radiance (Fig. 2a) and reflectance (Fig. 2b) for the 260 spectral bands acquired
    over the entire orchard. Each extracted crown was labeled as a function of the
    water stress treatment block (Fig. 3a), and each single crown spectrum was used
    for the analysis conducted through crown-level vegetation index calculation (Fig.
    3c). Download : Download high-res image (2MB) Download : Download full-size image
    Fig. 1. Hyperspectral flight line acquired with the micro-hyperspectral imager
    on board the unmanned aerial vehicle (UAV) yielding 40 cm resolution and 260 spectral
    bands at 6 nm FWHM (a), observing the orchard study site used for field data collection
    (b) and the single tree identification due to the high resolution imagery acquired
    (c). Download : Download high-res image (199KB) Download : Download full-size
    image Fig. 2. Sample extraction of the mean crown radiance (a) and reflectance
    (b) for the 260 spectral bands at 6 nm FWHM acquired over the orchard. Download
    : Download high-res image (857KB) Download : Download full-size image Fig. 3.
    Sixteen experimental irrigation blocks designed for well-watered (100%ET) and
    regulated deficit irrigation (RDI) schemes used for pure crown radiance and reflectance
    extraction (a) from the micro-hyperspectral imagery acquired at 40 cm resolution
    and 260 bands at 6 nm FWHM (c). The same experimental field was imaged using a
    high resolution thermal camera acquiring at 40 cm pixel size (b), enabling the
    extraction of pure tree crown temperature from each irrigation block (d). The
    two central trees of each irrigation treatment block (a total of 32 trees) plus
    8 additional selected trees (40 trees in total) were used for water potential
    measurements conducted on the date of the airborne flight over the orange study
    site, September 14, 2010. The data extracted from each single crown using the
    hyperspectral reflectance imagery were used to calculate indices related to: i)
    epoxidation state of the xanthophyll cycle (EPS); ii) chlorophyll a + b concentration;
    iii) blue/green/red ratio indices; iv) carotenoid concentration; and v) tree crown
    structure. The xanthophyll pigment indices were the Photochemical Reflectance
    Index (PRI) calculated with the 570 nm band as a reference (PRI570) (Gamon et
    al., 1992) and with the 515 nm band as a reference (PRI515) shown to minimize
    structural effects (Hernández-Clemente et al., 2011). The chlorophyll a + b indices
    consisted of the R750/R710 (ZM) (Zarco-Tejada et al., 2001), Vogelmann (VOG1 =
    R740/R720) (Vogelmann et al., 1993), and the family of indices based on the CARI
    index (TCARI = 3 * [(R700 − R670) − 0.2 * (R700 − R550) * (R700/R670)]) normalized
    by OSAVI ((1 + 0.16) * (R800 − R670) / (R800 + R670 + 0.16)) in the form suggested
    by Haboudane et al. (2002) (TCARI/OSAVI). The blue/green/red ratio indices consisted
    of the Greenness index G (R550/R670), blue/green indices (BGI1 = R400/R550; BGI2
    = R450/R550) (Zarco-Tejada et al., 2005) and blue/red indices (BRI1 = R400/R690;
    BRI2 = R450/R690), and the Lichtenthaler index (LIC3 = R440/R740) (Lichtenhaler
    et al., 1996). Other indices related to carotenoid concentration were calculated,
    including the R520/R500, R515/R570, and R515/R670 (see Meggio et al., 2010, Hernández-Clemente
    et al., 2011, Zarco-Tejada et al., 2005, for a full review of these indices).
    Structural indices were calculated to assess if changes in the tree crown structure
    due to water stress could be captured by NDVI (R800 − R670) / (R800 + R670) (Rouse
    et al., 1974), (Rougean and Breon, 1995), and other ratios such as the simple
    ratio SR (R800/R670) (Jordan, 1969), MSR ( ) (Chen, 1996), the OSAVI index, the
    triangular vegetation index TVI = 0.5 ∗ [120 ∗ (R750 − R550) − 200 ∗ (R670 − R550)]
    and the modified triangular index MTVI1 = 1.2 ∗ [1.2 ∗ (R800 − R550) − 2.5 ∗ (R670
    − R550)] (see Haboudane et al., 2004, for a complete review of structural indices
    developed for robust estimation of LAI in crops). Radiance spectra for each single
    tree (Fig. 4a), later used for fluorescence retrieval at each tree crown using
    the 760 nm O2-A in-filling method, were extracted (Fig. 4b) observing a total
    of 15 spectral bands within the O2-A feature. Radiance difference and ratio indices
    based on the in (L762 nm) and out bands (L747 nm; L780 nm), the integral of the
    oxygen absorption between bands 747–780 nm, the curvature index (Zarco-Tejada
    et al., 2000), and the FLD methods using two (FLD2) and three (FLD3) spectral
    bands were applied to the hyperspectral imagery to estimate the fluorescence signal.
    A full review of methods to estimate the fluorescence signal using FLD and different
    spectral fitting methods can be found in Meroni et al. (2010). Download : Download
    high-res image (521KB) Download : Download full-size image Fig. 4. Tree crown
    radiance spectra extracted from the 40 validation trees of the experiment at 40
    cm resolution (a) used for fluorescence quantification with the 760 nm O2-A FLD
    in-filling method. A total of 15 spectral bands at 6.4 nm FWHM within the O2-A
    feature were acquired (b). The study area was also imaged with a thermal camera
    to derive surface temperature for each single crown under study (Fig. 3b). The
    thermal camera used was the Miricle 307 (Thermoteknix Systems Ltd., Cambridge,
    UK) equipped with a 14.25 mm f1.3 lens, connected to a computer via USB 2.0 protocol.
    The image sensor was a Focal Plane Array (FPA) based on uncooled microbolometers
    with a resolution of 640x480 pixels and a spectral response in the range of 8-12
    μm, yielding a 25 μm pixel size. The camera delivered uncalibrated 14-bit digital
    raw images that were stored on board. Radiometric calibration was conducted in
    the laboratory using blackbodies under varying target and ambient temperatures
    to develop radiometric calibration algorithms. The sensor implemented an internal
    calibration for non-uniformity correction (NUC). Thermal images from the study
    area were acquired at 40 cm pixel resolution, enabling the retrieval of pure crown
    average temperature from each tree under study (Fig. 3d). Atmospheric correction
    methods were applied to the thermal imagery based on the MODTRAN radiative transfer
    model to obtain surface temperature. Local atmospheric conditions were determined
    by air temperature, relative humidity and barometric pressure measurements at
    the time of flight using a portable weather station (Model WXT510, Vaisala, Finland)
    and were used as input into MODTRAN. Atmospheric correction methods conducted
    with single-band thermal cameras were shown to provide successful estimation of
    vegetation surface temperature (Berni et al., 2009b). 2.2. Modeling the fluorescence
    retrieval with FluorMOD The standard retrieval of chlorophyll fluorescence through
    the in-filling method uses the canopy radiance (L) acquired from fluorescing (v)
    and non-fluorescing (n) targets in (i) and out (o) of the oxygen feature found
    at 760.5 nm, defined as Liv, Lin, Lov, Lon, respectively, to calculate the reflectance
    (R) and fluorescence (F) signals (Eqs. (1), (2)). (1) (2) This method was successfully
    tested at the leaf and canopy levels (Meroni et al., 2004, Meroni, Picchi, et
    al., 2008, Meroni, Rossini, et al., 2008, Moya et al., 2004) and also using subnanometer
    resolution at the canopy level for stress detection (Pérez-Priego et al., 2005).
    The application of this methodology at the image level (Maier et al., 2002, Zarco-Tejada
    et al., 2009) requires modeling approaches to understand the effects of the instrument
    spectral resolution and pixel size when aggregating fluorescing and non-fluorescing
    targets. The effects of the atmosphere are critical for the correct estimation
    of the absolute fluorescence signal. This is important because both the radiance
    extracted from pure tree crowns and the irradiance spectra are needed to calculate
    F, therefore being critical in multi-temporal or diurnal airborne campaigns under
    changing atmospheric conditions. In this study, the F retrieval for each tree
    crown was conducted under constant atmospheric conditions for all the monitored
    trees, playing the atmospheric effects a lower role. The feasibility for estimating
    fluorescence with the hyperspectral imagery acquired as part of this study was
    assessed using the linked leaf-canopy fluorescence model developed as part of
    the FluorMOD project (Miller et al., 2004). FluorMODleaf (Pedrós et al., 2004)
    is a leaf fluorescence and reflectance model linked to FluorSAIL (Verhoef, 2004),
    a canopy reflectance and fluorescence model that simulates the fluorescence signal
    at the canopy level (detailed information on the linked leaf-canopy models can
    be found in Zarco-Tejada et al., 2006). In particular, the FluorMOD model was
    used in this study to assess the fluorescence retrieval FLD3 in-filling method
    (bands in L762 nm; out L747 nm and L780 nm) as a function of the spectral bandwidth
    of the hyperspectral instrument flown over the study sites in this study (see
    Zarco-Tejada et al., 2009, for simulations conducted to assess index sensitivity
    for fluorescence retrieval). A thorough modeling study conducted for a wide range
    of sensor configurations and FLD methods can be reviewed in Damm et al. (2011),
    which assessed the feasibility for F estimation as a function of the spectral
    sampling interval, spectral resolution, signal to noise ratio, and the spectral
    shift of the instrument used. The inputs required to run the leaf and canopy model
    (Table 2) are the number of layers in PROSPECT (N); chlorophyll a + b content
    in μg/cm2 (Cab); water equivalent thickness in cm (Cw); dry matter content in
    μg (Cm); fluorescence quantum efficiency (Fi); leaf temperature in °C (T); species
    temperature dependence (S); and stoichiometry of PSII to PSI reaction centers
    (Sto). The canopy model requires the viewing zenith angle in degrees (Vza), relative
    azimuth angle in degrees (Raz), canopy leaf area index (LAI), hot spot parameter
    (h), and leaf inclination distribution function (LIDF). Table 2. FluorMOD model
    inputs used in this study to assess the sensitivity of reflectance indices through
    atmospheric, leaf and canopy inputs. Parameters Fi, Cab and LAI were varied randomly
    within the range indicated in the table. Atmospheric parameters Atmospheric File
    FLUORMOD30V23.MEP Irradiance PAR dependence parameters: PARb = 0.0035; PARre =
    0.005 Visibility 23 km Solar zenith angle 30° Viewing zenith angle 0° Relative
    azimuth angle 0° Leaf inputs N 1.8 Fi 0.03–0.06 Cab 30–80 μg/cm2 T 30 °C Cw 0.025
    cm S Standard Cm 0.01 g/cm2 Sto 1.5 Canopy inputs Leaf Area Index (LAI) 2–4 LIDF
    parameter a − 0.5 LIDF parameter b − 0.5 Hot spot parameter 0.1 Soil spectrum
    Standard The model was used to generate synthetic spectra through random input
    parameters such as fluorescence quantum efficiency Fi (0.03–0.06), chlorophyll
    content Cab (30–80 μg/cm2), and leaf area index LAI (2–4). FluorMOD modeled the
    leaf reflectance and transmittance spectra, along with the simulated fluorescence
    radiance for each reflectance and transmittance signal. The canopy fluorescence
    radiance (F) at 1 nm resolution was then simulated for each set of inputs (Fig.
    5a), observing the canopy signal added to the canopy radiance as a function of
    the fluorescence amplitudes. The canopy radiance simulated at 1 nm resolution,
    which included the fluorescence effects (Fig. 5b), reproduced the peak depth at
    760 nm used for fluorescence retrieval through the in-filling method (Fig. 5c).
    The similar spectral shape encountered both in the FluorMOD canopy radiance simulation
    in the 400–885 nm region and in the airborne hyperspectral imagery (Fig. 6a) shows
    the effects on the depth at 760 nm as a function of bandwidth (1 nm for the FluorMOD
    simulation; 6.4 nm for the hyperspectral imager flown over the study sites) (Fig.
    6b). Download : Download high-res image (462KB) Download : Download full-size
    image Fig. 5. Simulated canopy fluorescence radiance (F) at 1 nm resolution (a)
    and the canopy radiance including the fluorescence effects (b) using FluorMOD.
    The spectral range between 755 and 770 nm shows the peak depth at the 760 nm region
    used for fluorescence retrieval methods (c). Download : Download high-res image
    (312KB) Download : Download full-size image Fig. 6. Canopy radiance spectra simulated
    with FluorMOD in the 400–885 nm region as compared against the airborne micro-hyperspectral
    radiance extracted from a pure tree crown (a). Effects on the radiance depth at
    the 760 nm region as a function of bandwidth (1 nm for the FluorMOD simulation;
    6.4 nm for the hyperspectral imager flown over the study sites) (b). The simulated
    canopy radiance spectra obtained with FluorMOD were spectrally resampled with
    a gaussian convolution to simulate the FWHM of the airborne hyperspectral imager.
    The 760 nm peak depth decreased as a function of bandwidth (Fig. 7), while still
    showing the feature as compared with the original 1 nm FWHM spectra. Such effects
    caused by the bandwidth were assessed by applying the FLD3 in-filling algorithm
    retrieval method to the FluorMOD simulated datasets. A comparison of the F retrieval
    as a function of the spectra bandwidth was conducted to assess if the 6.4 nm FWHM
    of the airborne hyperspectral imagery would enable retrieval of the fluorescence
    signal to allow the water stress detection sought in this study. The method to
    estimate the fluorescence signal from the FluorMOD simulated synthetic spectra
    consisted on the same FLD3 method applied to the airborne hyperspectral imagery,
    which used the in (L762 nm) and out bands (L747 nm; L780 nm) for the calculation.
    As previously indicated, the FLD3 method and others suitable depending on the
    spectral data available (number of bands and spectral bandwidth available) can
    be reviewed in Meroni et al. (2010). Download : Download high-res image (150KB)
    Download : Download full-size image Fig. 7. Canopy radiance spectra simulated
    with FluorMOD (dotted line), and spectrally resampled through gaussian convolution
    to simulate the FWHM of the airborne hyperspectral imager (6 nm). The 760 nm peak
    depth decreases as a function of bandwidth, yet still showing the feature as compared
    with the original 1 nm FWHM spectra. 3. Results 3.1. Modeling results conducted
    with FluorMOD The synthetic spectra simulated from FluorMOD for varying fluorescence
    emissions (Fi), chlorophyll concentration (Cab) and leaf area index values (LAI)
    showed good agreement for R (Eq. 1) (r2 = 0.99; p < 0.001) and F (Eq. 2) (r2 =
    0.84; p < 0.001) when calculated with 1 nm and 6 nm FWHM spectral resolution.
    The close relationship between the F signal calculated at 1 and 6 nm bandwidth
    (r2 = 0.84; p < 0.001) demonstrated that the 6 nm spectra would still capture
    the input fluorescence emission. The absolute error obtained when comparing the
    F signal retrieved with the FLD3 in-filling method for both spectral resolutions
    against the fluorescence radiance signal simulated at 1 nm resolution (Fig. 8)
    yielded RMSE values of 4.58% (for the 1 nm FWHM spectra) and 12.16% (for the 6
    nm FWHM spectra). The error increment obtained for the F retrieval (RMSE from
    4.58% to 12.16%) as a function of the spectral resolution used, and the overall
    coefficient of determination obtained when using 6 nm FWHM spectra (r2 = 0.75)
    suggests the potential retrieval of the fluorescence signal with larger spectral
    bandwidths and small sampling intervals when using the FLD3 method. Download :
    Download high-res image (202KB) Download : Download full-size image Fig. 8. Relationship
    obtained between the simulated FluorMOD fluorescence radiance and the fluorescence
    estimated (FLD3 method) from synthetic spectra at 1 nm (RMSE = 4.58%) and 6 nm
    FWHM (RMSE = 12.16%). RMSE values below 15% are found when using the spectral
    resolution (6.4 nm FWHM), sampling interval (1.85 nm) and signal to noise ratio
    (300:1 without binning) of the micro-hyperspectral imager used in this study.
    Further comparison between the estimated F signal through the FLD3 method and
    the FluorMOD inputs Fi, Cab and LAI showed agreement between F and Fi (r2 = 0.8;
    p < 0.001), and the lack of relationship between F and LAI (r2 = 0.01; p-value
    not significant), and between F and Cab (r2 = 0.05; p-value not significant).
    These results demonstrate that the F signal retrieval using the FLD3 method is
    not correlated with Cab and LAI. Moreover, it shows that a statistically significant
    relationship (p < 0.001) exists between fluorescence quantum efficiency and F
    estimation when conducted with 6 nm FWHM resolution spectra (12.16% RMSE). This
    is the spectral resolution of the airborne micro-hyperspectral imager used to
    fly over the sites in this study. 3.2. Experimental results 3.2.1. Leaf and crown
    measurement results The diurnal leaf measurements conducted with the PAM-2100
    fluorometer on attached leaves selected from well irrigated (100%ET) and deficit
    irrigation (RDI1) trees (Fig. 9a) showed lower steady-state fluorescence emission
    (Fs) for the water stressed trees during the experiment, as expected. The diurnal
    trend showed greater Fs differences between 100% ET and RDI1 in early morning
    than at noon. These results from citrus trees showing lower Fs values in RDI1
    vs 100% ET irrigation levels coincide with the ones obtained in similar experiments
    in other crops, such as in olive and peach orchards under stress (Pérez-Priego
    et al., 2005, Zarco-Tejada et al., 2009). Download : Download high-res image (208KB)
    Download : Download full-size image Fig. 9. (a) Diurnal mean leaf Fs values obtained
    with the PAM-2100 from trees under 100% ET (well-watered) and RDI (water-stressed)
    treatments (n = 30 per tree at each measuring time; error bars are the standard
    deviation); (b) mean leaf PRI measurements acquired from trees under 100% ET and
    RDI1 treatments over the course of the experiment, using the PlantPen instrument
    (n = 30 per tree at each measuring time; error bars are the standard deviation).
    PRI calculated as (R570 − R531) / (R570 + R530). The June–September time-series
    leaf PRI data (calculated as (R570 − R531) / (R531 + R570)) measured with the
    PlantPen instrument (Fig. 9b) show the seasonal trend for both 100% ET and RDI1
    trees. Maximum differences in leaf PRI were found in July and August, corresponding
    to the times of maximum water potential differences among treatments (− 0.98 and
    − 1.73 MPa for 100% ET and RDI1 trees, respectively). The leaf PRI time series
    data showed the stress and recovery periods at the beginning and end of the irrigation
    experiment, with higher leaf PRI values measured for RDI1 than for the 100%ET,
    as expected. The well irrigated 100% ET trees showed a decline in PRI values from
    June (PRI = 0.046) until mid-July (PRI = 0.028), even though the water potential
    measured on the same trees was nearly identical (Ψ = − 0.84 MPa in June, and Ψ
    = − 0.86 MPa in July). Nevertheless, leaf PRI values measured on stressed trees
    were always higher than PRI values measured on 100% ET trees, in agreement with
    the work conducted by Suarez et al. (2008, 2009, 2010) in citrus and olive orchards.
    The seasonal variation of leaf PRI measurements could be due to changes in the
    xanthophyll epoxidation state over the season, but also due to potential effects
    caused by chlorophyll a + b, carotenoid and anthocyanin concentration as a function
    of the water stress. The leaf-level results obtained for Fs and PRI measured on
    stressed and well-watered trees had the intention to demonstrate that the results
    later obtained at canopy level were not caused by structural effects driven by
    water stress, but related to the physiological condition measured at the leaf
    level. Results for the leaf PRI measurements obtained throughout the season are
    in agreement with canopy PRI, canopy Tc and the Tc–Ta data recorded with the Skye
    and Apogee sensors installed over 100% ET and RDI1 crowns (Fig. 10). The trends
    for PRI calculated as (R570 − R531) / (R570 + R531) and Tc–Ta measured at noon
    throughout the entire experiment demonstrate a similar seasonal pattern for both
    crown PRI and crown Tc–Ta on the RDI1 treatment (Fig. 10a). The time-series data
    indicate that both canopy PRI and Tc–Ta were coupled throughout the experiment,
    showing a maximum for both indicators at the time of the maximum stress (Ψ = −
    1.73 MPa; Tc–Ta = 5 K; PRI = − 0.05), starting a recovery at the beginning of
    August when both Tc–Ta and PRI decreased together until the re-watering phase
    in mid-September. Although the general pattern for both indicators seemed similar
    throughout the experiment (Fig. 10a), a delay is observed on the PRI trend as
    compared against Tc–Ta: during the re-watering phase the crown temperature reaches
    Tc–Ta = 0 while PRI still shows values that indicate stress levels (PRI = − 0.1).
    Therefore, the re-watering phase was first tracked by Tc–Ta, followed later by
    PRI. These results are consistent with the hypothesis that canopy temperature
    is linked to transpiration rates, and therefore is more short-term sensitive to
    water stress than PRI, which is linked to the epoxidation state of the xanthophyll
    cycle pigments. In addition to the indicated biochemical effects on leaf PRI,
    crown structural changes over the course of the season would also have a role
    on the canopy PRI trends observed during stress and on the re-watering phase.
    The seasonal trend observed in the continuous PRI data acquired for the March–November
    time frame corresponds as well with seasonal changes of irradiance, air temperature
    and vapor pressure deficit (VPD) levels. Download : Download high-res image (335KB)
    Download : Download full-size image Fig. 10. Seasonal trends for canopy PRI and
    Tc–Ta (K) for RDI1 (a) and 100% ET (b) treatments acquired at noon (data shown
    are mean values for 5-minute intervals from measurements acquired at a rate of
    1/s). PRI calculated as (R570 − R531) / (R570 + R531). A close look at the re-watering
    phase (Fig. 11) shows the behavior of canopy PRI and Tc–Ta acquired for two RDI1
    trees as compared against a 100% ET reference tree. The patterns found indicate
    that the canopy PRI values measured on RDI1 trees started to decline after re-watering
    began, intersecting the non-water stress baseline (100%ET) at mid November (Fig.
    11a). The agreement between Tc–Ta measured on reference (100%ET) and deficit RDI1
    trees (Fig. 11b) shows that the recovery after re-watering started was detected
    earlier than when using PRI as an indicator of water stress. By the end of October
    the Tc–Ta values for 100% ET and RDI1 were equal (Tc–Ta below 1 K). Download :
    Download high-res image (415KB) Download : Download full-size image Fig. 11. Canopy
    PRI (a) and Tc–Ta (K) (b) obtained at noon from the stressed (RDI1) and well-watered
    (100%ET) irrigated trees over the course of the experiment. Plots show higher
    PRI and Tc–Ta values for the stressed (RDI1) trees (data shown are mean values
    for 5-minute intervals acquired at a rate of 1/s). PRI calculated as (R570 − R531)
    / (R570 + R531). The general pattern for the Tc–Ta and PRI data acquired throughout
    the experiment varied when targeting well-watered trees (100%ET). In such case,
    the Tc–Ta and PRI range of variation acquired throughout the experiment on 100%
    ET trees was much narrower than the values measured on RDI trees due to the reduced
    stress levels and small variation of stress during the experiment on 100% ET trees
    (Tc–Ta below 2 K for the 100% ET trees as compared to Tc–Ta values up to 5 K on
    the stressed RDI1 trees) (Fig. 10b). Moreover, the Tc–Ta and PRI data acquired
    on well-watered trees showed values related to non-stress levels during the course
    of the experiment, with Tc–Ta below 2 K and PRI values close to PRI = − 0.15 at
    all times. This was due to the full ET irrigation doses applied which assured
    low water stress conditions throughout the experiment, as demonstrated by the
    water potential measurements conducted: mean Ψ = − 1.00 MPa; maximum Ψ = − 0.73
    MPa; minimum Ψ = − 1.27 MPa (while the variation of the RDI1 during the experiment
    ranged between Ψ = − 0.90 MPa and Ψ = − 2.18 MPa). The water potential data measured
    on 100% ET and RDI1 trees over the entire experiment were compared against crown
    temperature and PRI (Fig. 12) to assess the seasonal trends during stress and
    recovery phases. The mid-day Tc and PRI canopy values for the dates when water
    potential measurements were made show an agreement between Tc and canopy PRI (Fig.
    12a) and between water potential and PRI (Fig. 12b) for the RDI1 stressed trees.
    Therefore Figs. 12a and 12b show a similar trend for the remote sensing indicators
    (PRI, Tc) as compared with ground-measured water potential (Ψ). Nevertheless,
    Fig. 12b shows that the water potential decreases rapidly after re-watering (Ψ
    from − 1.7 MPa down to − 0.9 MPa in mid September) while canopy PRI decreased
    at lower rate over such re-watering phase. The data obtained on the well-watered
    trees (100%ET) showed a general lack of relationship between Tc and PRI (Fig.
    12c) and between water potential and canopy PRI (Fig. 12d), probably due to the
    lower gradient found on the water potential measurements conducted over the season
    on the well-watered trees. These figures showed that the seasonal crown PRI and
    Tc–Ta data tracked water potential levels during the experiment, yielding coefficients
    of determination for PRI vs Ψ of r2 = 0.45 (p < 0.001), and Tc–Ta vs Ψ of r2 =
    0.44 (p < 0.001). Download : Download high-res image (426KB) Download : Download
    full-size image Fig. 12. Trends obtained for Tc (K) and PRI (a, c) as compared
    against water potential Ψ (MPa) (b, d) for the entire experiment, showing stressed
    (RDI1) (a, b) and well-watered (100%ET) (c, d) treatments. PRI calculated as (R570
    − R531) / (R570 + R531). 3.2.2. Airborne hyperspectral and thermal imagery results
    The hyperspectral and thermal airborne flights were conducted on September 14,
    prior to the re-watering phase, and therefore at the time of the maximum stress
    differences among treatment blocks. Based on the leaf water potential measurements
    observed (Ψ ranging from − 0.5 to − 2 MPa), the hyperspectral and thermal imagery
    acquired should be able to detect the stress levels measured in the field at the
    time of the flights. The high spatial resolution obtained in both hyperspectral
    and thermal imagery (40 cm resolution in both cases) enabled the identification
    of pure crowns (Fig. 1, Fig. 3), enabling the comparison of tree-level water stress
    measurements and airborne-derived indices of stress. The pure-crown temperature
    data extracted from the thermal imagery, and the narrow-band indices calculated
    from the hyperspectral imagery based on xanthophyll pigment absorption, chlorophyll
    a + b, blue/green/red ratios, carotenoid content, and structural indices were
    compared against the stomatal conductance and water potential measured at the
    time of the flights (Table 3). The best relationship with Gs was found for crown
    temperature (r2 = 0.78; p < 0.05) (Fig. 13a). The reflectance indices calculated
    based on PRI formulations using R570 as the reference band (PRI570) (Gamon et
    al., 1992) and the new formulation by Hernández-Clemente et al. (2011) (band R515
    as reference to minimize structural canopy effects, PRI515) yielded better performance
    for PRI515 (r2 = 0.59; p < 0.01) than for PRI570 (p-value not significant) (Fig.
    13c for PRI515). This result confirms the findings by Hernández-Clemente et al.
    (2011) in forest canopies, which demonstrated the robustness of PRI515 to structural
    effects. Table 3. Coefficients of determination (r2) obtained through temperature,
    narrow-band indices and fluorescence retrieval methods conducted with the hyperspectral
    radiance imagery as compared against stomatal conductance (Gs) and water potential
    (Ψ) measured at the time of the flights. Airborne temperature, radiance and reflectance
    indices Stomatal conductance and water potential Gs Ψ Crown temperature (Tc) 0.78⁎
    0.34⁎⁎⁎ Reflectance indices Xanthophyll indices PRI570 0.37 0.37⁎⁎⁎ PRI515 0.59⁎⁎
    0.38⁎⁎⁎ Chlorophyll a + b indices ZM 0.26 0.02 VOG1 0.29 0.02 TCARI 0.52⁎ 0.54⁎⁎⁎
    TCARI/OSAVI 0.45 0.51 Blue/green/red ratio indices G 0.31 0.41⁎⁎⁎ BGI1 0.62⁎⁎⁎
    0.49⁎⁎⁎ BGI2 0.48⁎⁎ 0.43⁎⁎⁎ BRI1 0 0 BRI2 0 0.04 LIC3 0.34⁎ 0.23⁎⁎ Carotenoid
    indices R520/R500 0.49⁎⁎ 0.48⁎⁎⁎ R515/R570 0 0.05 R515/R670 0.23 0.35⁎⁎⁎ Structural
    indices NDVI 0.32 0.24⁎⁎ RDVI 0.61⁎⁎ 0.44⁎⁎⁎ SR 0.33 0.23⁎⁎ MSR 0.33 0.23⁎⁎ OSAVI
    0.52⁎ 0.4⁎⁎⁎ MTVI1 0.66⁎⁎ 0.49⁎⁎⁎ TVI 0.64⁎⁎ 0.47⁎⁎⁎  Fluorescence indices L747
    − L762 0.39 0.46⁎⁎⁎ L780 − L762 0.55 0.49⁎⁎⁎ L747/L762 0.05⁎ 0 L780/L762 0 0 ((L747
    + L780) / 2)-L762 0.49 0.49⁎⁎⁎ FLD2 (747; 762) 0.67⁎ 0.66⁎⁎⁎ FLD2 (780; 762) 0.67⁎
    0.66⁎⁎⁎ FLD3 (747; 762; 780) 0.67⁎ 0.66⁎⁎⁎ ∫ [747,780] 0.62 0.6⁎⁎⁎ Curvature index
    0.47⁎ 0.51⁎⁎⁎ ⁎ p < 0.05. ⁎⁎ p < 0.01. ⁎⁎⁎ p < 0.001. Download : Download high-res
    image (478KB) Download : Download full-size image Fig. 13. Relationships obtained
    between airborne indices and ground truth data for Gs vs Tc (K) (a), PRI515 (c)
    and F (FLD3) (e), and against water potential (Ψ, MPa) (b, d, f). The chlorophyll
    indices TCARI and TCARI/OSAVI showed sensitivity to stress levels (r2 = 0.52;
    p < 0.05 for TCARI), and the blue/green ratio BGI1 was highly significant (r2
    = 0.62; p < 0.001). The effects of water stress on the canopy structure were captured
    by structural indices such as RDVI (r2 = 061; p < 0.01), TVI (r2 = 0.64; p < 0.01)
    and MTVI (r2 = 0.66; p < 0.01). These results for the structural indices are consistent
    due to the expected effects of sustained water stress on crown density. The fluorescence
    retrieval conducted with the micro-hyperspectral imager showed that the best results
    were obtained for the FLD method using two and three bands (r2 = 0.67; p < 0.05
    for Gs) (Fig. 13e) as compared with radiance difference calculations and fluorescence
    integral methods. Radiance difference calculations L747 − L762 (r2 = 0.39; p-value
    not significant), L780 − L762 (r2 = 0.55; p-value not significant) and ((L747
    + L780) / 2)-L762 (r2 = 0.49; p-value not significant) demonstrated lower performance
    than FLD2 and FLD3 methods (r2 = 0.67; p < 0.05). The ratio L747/L762 and L780/L762
    were not related to the physiological measures Gs and Ψ (r2 = 0.05; r2 = 0, respectively;
    p-value not significant). The results obtained for the FLD2 and FLD3 methods were
    similar (r2 = 0.67 for both methods; p < 0.05), confirming the results presented
    in Damm et al. (2011) for instruments with short sampling intervals and FWHM around
    5 nm. The curvature index calculated using bands 675, 682 and 690 nm yielded lower
    relationships, but statistically significant, for Gs (r2 = 0.47; p < 0.05) and
    Ψ (r2 = 0.51; p < 0.001) than when using the FLD2 and FLD3 methods. The differences
    found in the coefficients of determination and the statistical significance between
    the remote sensing indicators of stress and Gs and Ψ (Table 3) are related to
    the stomatal regulation. The feedback of stomatal regulation on leaf water status
    has been observed in a number of cases, and results in the conservative behavior
    of water potential with increasing levels of water stress. In particular, this
    feedback mechanism between water potential and stomatal closure has been observed
    in deciduous trees (Fereres and Goldhamer, 1990) and in citrus (Fereres et al.,
    1979), and could affect the relationship between leaf water potential and other
    indicators of water stress. In particular, the relationships with water potential
    were highly significant for Tc (r2 = 0.34; p < 0.001) (Fig. 13b), PRI515 (r2 =
    0.38; p < 0.001) (Fig. 13d), while the BGI1 index (blue/green ratio) yielded the
    highest significance level (p < 0.001) for both Gs (r2 = 0.62) and Ψ (r2 = 0.49).
    The structural indices RDVI, MTVI1 and TVI, which obtained r2 = 0.6 (p < 0.01)
    for Gs, showed high significance with Ψ (p < 0.001). Nevertheless, NDVI showed
    no significance with Gs and weaker sensitivity to Ψ (r2 = 0.24; p < 0.01). Chlorophyll
    fluorescence FLD3 retrievals demonstrated successful sensitivity to water stress,
    obtaining high statistical significance for both Gs and Ψ (r2 = 0.66; p < 0.001)
    (Fig. 13f). The fluorescence retrievals obtained with the FLD3 method for the
    entire hyperspectral scene showed the spatial variability of the F signal from
    each single tree crown, and the differences detected between adjacent orchard
    fields (Fig. 14a). Within the experimental field, the fluorescence signal estimated
    from the two central trees of each treatment block was interpolated to generate
    a continuous fluorescence map of the experiment (Fig. 14b), enabling the visual
    comparison against the water potential map obtained from Ψ measurements conducted
    on each treatment (Fig. 14c). Download : Download high-res image (2MB) Download
    : Download full-size image Fig. 14. Crown-level chlorophyll fluorescence maps
    obtained with the FLD3 method for the entire hyperspectral scene (a). Visual comparison
    between the fluorescence map of the experimental study area calculated from the
    two central trees of each treatment block (b) and the water potential measurements
    obtained from each irrigation block (c). 4. Discussion Several studies highlight
    the requirements for high spectral resolution instruments for the successful retrieval
    of chlorophyll fluorescence using subnanometer radiance data at the leaf (Meroni
    & Colombo, 2006) and canopy levels (Pérez-Priego et al., 2005). These studies
    demonstrated with experimental data that subnanometer spectral resolution spectrometers
    enabled the detection of steady-state fluorescence emission using the O2-A absorption
    line for stress detection purposes. The interest on the very high spectral resolution
    was later supported in studies by Meroni et al. (2009, 2010) where a review on
    FLD and spectral fitting methods for the fluorescence retrieval as a function
    of the instrument configuration was conducted. Further, interest in spectral fitting
    methods as an alternative to FLD for F estimation with subnanometer spectral resolution
    increased under FLEX, FLuorescence EXplorer (European Space Agency, 2008), submitted
    to the European Space Agency (ESA) Earth Explorer program as a candidate algorithm
    for the scientific satellite mission concept. Along these efforts focused on the
    very high spectral resolution data, Zarco-Tejada et al. (2009) demonstrated that
    imaging chlorophyll fluorescence retrieval was feasible using 1 nm spectral resolution
    imagery acquired with a multispectral camera at 150 m altitude, using the 760.5
    (in) and 757.5 nm (out) bands for the quantification of the solar-induced fluorescence
    at 15 cm pixel resolution. Other critical issues such as the assessment of the
    potential atmospheric effects were also investigated by Guanter et al. (2010).
    Although these studies confirm the feasibility for fluorescence detection using
    very high spectral resolution data (under 1 nm FWHM), the operational issues related
    to the calibration and signal to noise ratio of the required instrument when acquiring
    at such narrow bandwidths may have important implications on the retrieval accuracy,
    cost and sensor availability for imaging purposes. In fact, these studies demonstrated
    the feasibility for fluorescence retrieval using very high spectral resolution
    (below 1 nm FWHM), but no published work using modeling and experimental data
    demonstrated the need for subnanometer radiance for accurate quantification of
    the fluorescence emission. The first modeling study assessing such requirements
    was recently published by Damm et al. (2011). In a modeling study using FluorSAIL3,
    they evaluated the F retrieval accuracy in response to the most relevant sensor
    properties, including the spectral sampling interval, spectral resolution, signal
    to noise, and the spectral shift, along with different fluorescence retrieval
    methods. This relevant study demonstrated that the spectral resolution is important
    for the retrieval accuracy (up to 40% error was estimated as a function of the
    spectral resolution of the instrument), but the spectral sampling interval caused
    12% error, and the spectral shift a 7% error. But more important, Damm et al.
    (2011) demonstrated that iFLD and FLD3 methods were able to retrieve the fluorescence
    signal when using lower spectral resolution (5 nm FWHM) and higher spectral sampling
    intervals (below 2.5 nm) with instruments with a minimum of 300:1 signal to noise
    ratio. These modeling results estimated an RMSE = 14% when a sensor configuration
    of 5 nm spectral resolution and a small sampling interval was used, and therefore
    are in agreement with the findings of this manuscript obtained with a micro-hyperspectral
    imager with 260 bands at 6 nm FWHM, 1.85 nm sampling interval (a total of 13 bands
    inside the O2-A feature), and a signal to noise ratio of 300:1 without binning
    to target pure crowns affected by water stress. Furthermore, Damm et al. (2011)
    and this study demonstrate that subnanometer spectral resolution is not a requirement
    for F retrieval using the FLD3 method when high signal to noise ratio and short
    sampling intervals are used with bandwidths ranging 4–6 nm FWHM. The work described
    in this manuscript used physiological indicators measured in the field, such as
    stomatal conductance and water potential, to assess if the fluorescence retrievals
    were in accordance with the expected stress levels of the experiment. The FLD3
    method was conducted at the crown level, therefore removing the effects of shadows
    and soil, and estimating the fluorescence signal from pure vegetation pixels.
    Fluorescence emission quantities estimated in this manuscript were in agreement
    with other published work by Meroni et al., 2009, Zarco-Tejada et al., 2009, Damm
    et al., 2011. Studies such this one conducted with very high spatial resolution
    hyperspectral imagery (below 1 m pixel size) are needed for better understanding
    of the fluorescence signal retrieved from pure and mixed vegetation pixels, as
    well as for validating the available methods for fluorescence estimation. The
    work conducted with high resolution airborne imagery to target pure vegetation
    pixels is a first step required for understanding the fluorescence signal retrieved
    from different species and canopy structures. This is critical for making progress
    on the fluorescence estimation conducted from medium resolution instruments over
    aggregated pixels which include mixed vegetation, soil and shadows. In addition,
    the lack of fluorescence simulation models valid for non-homogeneous canopies
    prevents the assessment of the retrieval accuracy for validation studies under
    important targets such as forestry areas and cash crops like vineyards and tree
    orchards. The development of a model appropriate for open canopies will serve
    the scientific community to evaluate if the fluorescence retrieval under varying
    viewing geometries, direct soil contributions and percentage cover is feasible,
    as well as to better understand the fluorescence retrieval from mixed pixels.
    Finally, seasonal and diurnal measurements conducted over instrument targets (trees,
    lysimeters, study sites) with dedicated point-sensors will advance the knowledge
    related to the seasonal patterns in physiological indices widely used, such as
    temperature and reflectance indices for physiological monitoring through photosynthetic
    pigment absorption such as chlorophyll content, xanthophylls, carotenoids and
    anthocyanins. The recent work conducted using unmanned aerial vehicles and micro-hyperspectral
    imagers for remote sensing research (Berni, Zarco-Tejada, Suarez and Fereres,
    2009, Zarco-Tejada et al., 2008) bring new possibilities for extensive validation
    and experimental studies to make critical progress on fluorescence retrieval methods
    using unprecedented submeter hyperspectral imagery. 5. Conclusions The work presented
    in this manuscript assessed thermal and multispectral domains for water stress
    detection in a citrus orchard. High resolution imagery acquired from a thermal
    camera and a micro-hyperspectral sensor on board an unmanned aerial vehicle enabled
    the identification of pure crowns, extracting the mean reflectance and temperature
    for individual trees where field measurements of stomatal conductance and water
    potential were measured. The experimental design comprised random blocks with
    full (100%ET), farmer irrigation method, and two deficit irrigation levels (RDI)
    offering a range of water stress levels. The time series acquired from regulated
    deficit treatments (RDI1) and well irrigated blocks (100%ET) treatment trees instrumented
    with thermal and PRI point sensors demonstrated that both Tc–Ta and PRI crown
    data were able to track the seasonal variation of stress and recovery at the end
    of the experiment. The time series data demonstrated a time delay in the sensitivity
    of PRI as compared to Tc–Ta variation. To ensure that PRI did not solely track
    crown structural variation over the course of the experiment, leaf-level PRI measurements
    were also acquired, demonstrating that leaf PRI data were also linked to water
    potential levels throughout the season. Nevertheless, leaf biochemical and canopy
    biophysical effects on PRI over the course of the season would also affect the
    PRI indices used to track water stress levels. The airborne flights conducted
    with a thermal camera and a micro-hyperspectral imager enabled water stress detection
    assessment by using crown temperature, narrow-band VIS–NIR formulations, and chlorophyll
    fluorescence. The simulation work conducted with the FluorMOD model for different
    spectral bandwidths demonstrated that the fluorescence signal retrieved through
    the FLD3 in-filling method was related to water potential and stomatal conductance
    measurements when 6 nm FWHM spectra was used. Among the different methods used
    to retrieve the fluorescence signal, including the radiance difference, the integral
    of the 760 nm peak, and the FLD2 and FLD3 methods, the sensitivity of fluorescence
    retrievals to water stress levels suggested that the FLD3 method using 747, 762
    and 780 nm bands was the best method with 6 nm FWHM and 1.85 nm sampling spectra.
    Among crown temperature, narrow-band indices, and fluorescence retrieval conducted
    from the airborne radiance spectra, the best indicators of water stress were crown
    temperature, chlorophyll fluorescence calculated with the FLD3 method, the PRI515
    index (reference band = 515 nm), which was more sensitive to water stress than
    PRI570 (reference band = 570 nm) as in Hernández-Clemente et al. (2011) in forest
    canopies. The BGI1 index calculated from the blue (R400) and green (R550) bands
    yielded the highest significance level (p < 0.001) for both Gs (r2 = 0.62) and
    Ψ (r2 = 0.49). Out of the structural indices assessed, RDVI, MTVI1 and TVI were
    related to Gs (p < 0.01), obtaining high significance with Ψ (p < 0.001), while
    NDVI showed no significance with Gs and a weak sensitivity to Ψ. Chlorophyll fluorescence
    calculated with the FLD3 method from the micro-hyperspectral imager demonstrated
    successful sensitivity to stress levels, yielding r2 = 0.67 (p < 0.05) with Gs,
    and r2 = 0.66 (p < 0.001) with water potential. The fluorescence estimations from
    the hyperspectral imagery were in agreement with ground measurements of fluorescence,
    which demonstrated lower values in water stressed trees. The work presented in
    this manuscript demonstrated the ability to track stress levels in a citrus crop
    using thermal and hyperspectral imagery acquired with an unmanned aerial vehicle,
    showing that crown temperature, the blue-green BGI1 index, and the chlorophyll
    fluorescence estimates were the best related to water stress. Results confirmed
    previous work that showed the link between PRI and Tc, and the superior performance
    of PRI515 vs PRI570. The use of lightweight micro-hyperspectral imagers and miniature
    thermal cameras on board UAV platforms will enable flexible and cost-effective
    data collection campaigns for precision agriculture and environmental applications
    in the near future. Acknowledgments Financial support from the Spanish Ministry
    of Science and Education (MEC) for the AGL2009-13105 and CONSOLIDER RIDECO (CSD2006-67)
    projects is gratefully acknowledged. M. Medina, D. Notario, A. Vera, A. Hornero,
    R. Romero, R. Gutierrez and P. Cidare are acknowledged for technical support during
    field and airborne campaigns. The editorial comments of E. Fereres are appreciated.
    References Berni, Zarco-Tejada, Sepulcre-Cantó, Fereres and Villalobos, 2009 J.A.J.
    Berni, P.J. Zarco-Tejada, G. Sepulcre-Cantó, E. Fereres, F.J. Villalobos Mapping
    canopy conductance and CWSI in olive orchards using high resolution thermal remote
    sensing imagery Remote Sensing of Environment, 113 (2009), pp. 2380-2388 View
    PDFView articleView in ScopusGoogle Scholar Berni, Zarco-Tejada, Suarez and Fereres,
    2009 J.A.J. Berni, P.J. Zarco-Tejada, L. Suarez, E. Fereres Thermal and narrow-band
    multispectral remote sensing for vegetation monitoring from an unmanned aerial
    vehicle IEEE Transactions on Geoscience and Remote Sensing, 47 (3) (2009), pp.
    722-738 View in ScopusGoogle Scholar Chen, 1996 J. Chen Evaluation of vegetation
    indices and modified simple ratio for boreal applications Canadian Journal of
    Remote Sensing, 22 (1996), pp. 229-242 CrossRefView in ScopusGoogle Scholar Crisosto
    et al., 1994 C.H. Crisosto, R.S. Johnson, J.G. Luza, G.M. Crisosto Irrigation
    regimes affect fruit soluble solids concentration and rate of water loss of “O''Henry”
    Peaches HortScience, 29 (10) (1994), pp. 1169-1171 CrossRefView in ScopusGoogle
    Scholar Damm et al., 2011 A. Damm, A. Erler, W. Hillen, M. Meroni, M.E. Schaepman,
    W. Verhoef, et al. Modeling the impact of spectral sensor configurations on the
    FLD retrieval accuracy of sun-induced chlorophyll fluorescence Remote Sensing
    of Environment, 115 (2011), pp. 1882-1892 View PDFView articleView in ScopusGoogle
    Scholar European Space Agency, 2008 European Space Agency ESA SP-1313/4 candidate
    earth explorer core missions—Reports for assessment: FLEX-FLuorescence EXplorer,
    ESA Communication Production Office, Noordwijk, The Netherlands (2008) http://esamultimedia.esa.int/docs/SP1313-4_FLEX.pdf
    available on line at Google Scholar Fereres et al., 1979 E. Fereres, G. Cruz-Romero,
    G.F. Hoffman, S.L. Rawlins Recovery of orange trees following severe water stress
    Journal of Applied Ecology, 16 (1979), pp. 833-842 CrossRefGoogle Scholar Fereres
    and Soriano, 2007 E. Fereres, M. Soriano Deficit irrigation for reducing agricultural
    water Use Journal of Experimental Botany, 58 (2007), pp. 147-159 View in ScopusGoogle
    Scholar Fereres and Goldhamer, 1990 E. Fereres, D.A. Goldhamer Deciduous fruit
    and nut trees B.A. Stewart, D.R. Nielsen (Eds.), Irrigation of Agricultural Crops,
    Agronomy, 30, ASA, CSSA, SSSA, Madison, WI (1990), pp. 987-1017 Google Scholar
    Flexas et al., 1999 J. Flexas, J.M. Escalona, H. Medrano Water stress induces
    different levels of photosynthesis and electron transport rate regulation in grapevines
    Plant, Cell & Environment, 22 (1999), pp. 39-48 View in ScopusGoogle Scholar Flexas
    et al., 2000 J. Flexas, J.M. Briantais, Z. Cerovic, H. Medrano, I. Moya Steady-state
    and maximum chlorophyll fluorescence responses to water stress in grapevine leaves:
    A new remote sensing system Remote Sensing of Environment, 73 (2000), pp. 282-297
    Google Scholar Flexas et al., 2002 J. Flexas, J.M. Escalona, S. Evain, J. Gulias,
    I. Moya, C.B. Osmond, et al. Steady-state chlorophyll fluorescence (Fs) measurements
    as a tool to follow variations of net CO2 assimilation and stomatal conductance
    during water-stress in C-3 plants Physiologia Plantarum, 114 (2) (2002), pp. 231-240
    View in ScopusGoogle Scholar Fuchs and Tanner, 1966 M. Fuchs, C.B. Tanner Infrared
    thermometry of vegetation Agronomy Journal, 58 (1966), pp. 297-601 View in ScopusGoogle
    Scholar Gamon et al., 1992 J.A. Gamon, J. Peñuelas, C.B. Field A narrow-wave band
    spectral index that tracks diurnal changes in photosynthetic efficiency Remote
    Sensing of Environment, 41 (1992), pp. 35-44 View PDFView articleView in ScopusGoogle
    Scholar Girona, 2002 J. Girona Regulated deficit irrigation in peach A global
    analysis, Acta Horticulturae, 592 (2002), pp. 335-342 CrossRefView in ScopusGoogle
    Scholar Girona et al., 2003 J. Girona, M. Mata, A. Arbonès, S. Alegre, J. Rufat,
    J. Marsal Peach tree response to single and combined regulated deficit irrigation
    regimes under shallow soils Journal of the American Society of Horticultural Sciences,
    128 (2003), pp. 432-440 CrossRefView in ScopusGoogle Scholar Guanter et al., 2010
    L. Guanter, L. Alonso, L. Gomez-Chova, M. Meroni, R. Preusker, J. Fischer Developments
    for vegetation fluorescence retrieval from spaceborne high resolution spectrometry
    in the O2-A and O2-B absorption bands Journal of Geophysical Research-Atmospheres,
    115 (2010) Google Scholar Gueymard, 1995 C.A. Gueymard SMARTS, a simple model
    of the atmospheric radiative transfer of sunshine: Algorithms and performance
    assessment Technical report no. FSEC-PF-270-95, Florida Solar Energy Center, Cocoa,
    FL (1995) Google Scholar Gueymard, 2001 C.A. Gueymard Parameterized transmittance
    model for direct beam and circumsolar spectral irradiance Solar Energy, 71 (5)
    (2001), pp. 325-346 View PDFView articleView in ScopusGoogle Scholar Gueymard
    et al., 2002 C.A. Gueymard, D. Myers, K. Emery Proposed reference irradiance spectra
    for solar energy systems testing Solar Energy, 73 (6) (2002), pp. 443-467 View
    PDFView articleView in ScopusGoogle Scholar Gueymard, 2005 C.A. Gueymard SMARTS
    code, version 2.9.5 user''s Manual solar consulting services (2005) http://www.nrel.gov/rredc/smarts/
    Online PDF document from Google Scholar Haboudane et al., 2002 D. Haboudane, J.R.
    Miller, N. Tremblay, P.J. Zarco-Tejada, L. Dextraze Integrated narrow-band vegetation
    indices for prediction of crop chlorophyll content for application to precision
    agriculture Remote Sensing of Environment, 84 (2002), pp. 416-426 View PDFView
    articleView in ScopusGoogle Scholar Haboudane et al., 2004 D. Haboudane, J.R.
    Miller, E. Pattey, P.J. Zarco-Tejada, I. Strachan Hyperspectral vegetation indices
    and novel algorithms for predicting green LAI of crop canopies: Modeling and validation
    in the context of precision agriculture Remote Sensing of Environment, 90 (3)
    (2004), pp. 337-352 View PDFView articleView in ScopusGoogle Scholar Hall et al.,
    1975 A.E. Hall, S.E. Camacho-B, M.R. Kaufmann Regulation of water loss by citrus
    leaves Physiologia Plantarum, 33 (1975), pp. 62-65 CrossRefView in ScopusGoogle
    Scholar Hernández-Clemente et al., 2011 R. Hernández-Clemente, R.M. Navarro-Cerrillo,
    L. Suárez, F. Morales, P.J. Zarco-Tejada Assessing structural effects on PRI for
    stress detection in conifer forests Remote Sensing of Environment, 115 (9) (2011),
    pp. 2360-2375 View PDFView articleView in ScopusGoogle Scholar Hsiao et al., 1976
    T.C. Hsiao, E. Fereres, E. Acevedo, D.W. Henderson Water stress and dynamics of
    growth and yield of crops, water and plant life: Problems and modern approaches,
    Springer (1976) Google Scholar Idso et al., 1978 S.B. Idso, R.D. Jackson, R.J.
    Reginato Extending the “degree day” concept of phenomenological development to
    include water stress effects Ecology, 59 (1978), pp. 431-433 CrossRefGoogle Scholar
    Idso et al., 1981 S.B. Idso, R.D. Jackson, P.J. Pinter, R.J. Reginato, J.L. Hatfield
    Normalizing the stress-degree-day parameter for environmental variability Agricultural
    and Forest Meteorology, 24 (1981), pp. 45-55 View PDFView articleView in ScopusGoogle
    Scholar Jackson, Reginato and Idso, 1977 R. Jackson, R. Reginato, S. Idso Wheat
    canopy temperature: A practical tool for evaluating water requirements Water Resources
    Research, 13 (1977), pp. 651-656 View in ScopusGoogle Scholar Jackson, Idso, Reginato
    and Ehrler, 1977 R.D. Jackson, S.B. Idso, R.J. Reginato, W.L. Ehrler Crop temperature
    reveals stress Crop Soils, 29 (1977), pp. 10-13 CrossRefView in ScopusGoogle Scholar
    Jackson et al., 1981 R.D. Jackson, S.B. Idso, R.J. Reginato, P.J. Pinter Jr. Canopy
    temperature as a crop water stress indicator Water Resources Research, 17 (1981),
    pp. 1133-1138 View in ScopusGoogle Scholar Jackson, 1982 R.D. Jackson Canopy temperature
    and crop water stress Advances in Irrigation, 1 (1982), pp. 43-85 View PDFView
    articleCrossRefGoogle Scholar Jordan, 1969 C.F. Jordan Derivation of leaf area
    index from quality of light on the forest floor Ecology, 50 (1969), pp. 663-666
    CrossRefGoogle Scholar Krause and Weis, 1984 G.H. Krause, E. Weis Chlorophyll
    fluorescence as a tool in plant physiology. II. Interpretation of fluorescence
    signals Photosynthesis Research, 5 (1984), pp. 139-157 View in ScopusGoogle Scholar
    Larcher, 1994 W. Larcher Photosynthesis as a tool for indicating temperature stress
    events E.D. Schulze, M.M. Caldwell (Eds.), Ecophysiology of photosynthesis, Springer,
    Berlin (1994), pp. 261-277 Google Scholar Lichtenthaler and Rinderle, 1988 H.K.
    Lichtenthaler, U. Rinderle The role of chlorophyll fluorescence in the detection
    of stress conditions in plants CRC Critical Reviews in Analytical Chemistry, 19
    (Suppl. 1) (1988), pp. 529-585 Google Scholar Lichtenthaler, 1992 H.K. Lichtenthaler
    The Kautsky effect: 60 years of chlorophyll fluorescence induction kinetics Photosynthetica,
    27 (1992), pp. 45-55 Google Scholar Lichtenhaler et al., 1996 H.K. Lichtenhaler,
    M. Lang, M. Sowinska, F. Heisel, J.A. Mieh Detection of vegetation stress via
    a new high resolution fluorescence imaging system Journal of Plant Physiology,
    148 (1996), pp. 599-612 Google Scholar Maier et al., 2002 S.W. Maier, K.P. Günther,
    M. Stellmes Remote sensing and modelling of solar induced fluorescence, 1st workshop
    on remote sensing of solar induced vegetation fluorescence Noordwijk, Netherlands
    (2002) Google Scholar Meggio et al., 2010 F. Meggio, P.J. Zarco-Tejada, L.C. Núñez,
    G. Sepulcre-Cantó, M.R. Gonzalez, P. Martin Grape quality assessment in vineyards
    affected by iron deficiency chlorosis using narrow-band physiological remote sensing
    indices Remote Sensing of Environment, 114 (2010), pp. 1968-1986 View PDFView
    articleView in ScopusGoogle Scholar Meroni et al., 2004 M. Meroni, R. Colombo,
    S. Cogliati High resolution leaf spectral signature for the detection of solar
    induced chlorophyll fluorescence Proceedings of the 2nd ESA workshop on remote
    sensing of solar induced vegetation fluorescence, Montreal, Canada, 17–19 November
    2004 (2004) Google Scholar Meroni and Colombo, 2006 M. Meroni, R. Colombo Leaf
    level detection of solar-induced chlorophyll fluorescence by means of a subnanometer
    resolution spectroradiometer Remote Sensing of Environment, 103 (2006), pp. 438-448
    View PDFView articleView in ScopusGoogle Scholar Meroni, Picchi, et al., 2008
    M. Meroni, V. Picchi, M. Rossini, S. Cogliati, C. Panigada, C. Nali, et al. Leaf
    level early assessment of ozone injuries by passive fluorescence and PRI International
    Journal of Remote Sensing, 29 (17) (2008), pp. 5409-5422 CrossRefView in ScopusGoogle
    Scholar Meroni, Rossini, et al., 2008 M. Meroni, M. Rossini, V. Picchi, C. Panigada,
    S. Cogliati, C. Nali, et al. Assessing steady-state fluorescence and PRI from
    hyperspectral proximal sensing as early indicators of plant stress: The case of
    ozone exposure Sensors, 8 (2008), pp. 1740-1754 CrossRefView in ScopusGoogle Scholar
    Meroni et al., 2009 M. Meroni, M. Rossini, L. Guanter, L. Alonso, U. Rascher,
    R. Colombo Remote sensing of solar-induced chlorophyll fluorescence: Review of
    methods and applications Remote Sensing of Environment, 113 (2009), pp. 2037-2051
    View PDFView articleView in ScopusGoogle Scholar Meroni et al., 2010 M. Meroni,
    L. Busetto, R. Colombo, L. Guanter, J. Moreno, W. Verhoef Performance of spectral
    fitting methods for vegetation fluorescence quantification Remote Sensing of Environment,
    114 (2010), pp. 363-374 (2010) View PDFView articleView in ScopusGoogle Scholar
    Miller et al., 2004 J.R. Miller, M. Berger, L. Alonso, Z. Cerovic, Y. Goulas,
    S. Jacquemoud, et al. Progress on the development of an integrated canopy fluorescence
    model, 2003 International Geoscience and Remote Sensing Symposium, IGARSS''03,
    vol. 1 (2004), pp. 601-603 Toulouse (France), 21–25 / 7 /2004. ISBN 0-7803-7929-2
    - 0-7803-7930-6 CrossRefGoogle Scholar Mills et al., 1994 T.M. Mills, M.H. Behboudian,
    P.Y. Tan Plant water status and fruit quality in “Braeburn” apples Horticultural
    Science, 29 (1994), pp. 1274-1278 CrossRefView in ScopusGoogle Scholar Moran et
    al., 1994 M. Moran, T. Clarke, Y. Inoue, A. Vidal Estimating crop water deficit
    using the relation between surface-air temperature and spectral vegetation index
    Remote Sensing of Environment, 49 (1994), pp. 246-263 View PDFView articleView
    in ScopusGoogle Scholar Moya et al., 2004 I. Moya, L. Camenen, S. Evain, Y. Goulas,
    Z.G. Cerovic, G. Latouche A new instrument for passive remote sensing 1. Measurements
    of sunlight-induced chlorophyll fluorescence Remote Sensing of Environment, 91
    (2004), pp. 186-197 View PDFView articleView in ScopusGoogle Scholar Papageorgiou,
    1975 G. Papageorgiou Chlorophyll fluorescence: An intrinsic probe of photosynthesis
    Govindjee (Ed.), Bioenergetics of photosynthesis, Academic Press, New York (1975),
    pp. 319-371 View PDFView articleView in ScopusGoogle Scholar Pedrós et al., 2004
    R. Pedrós, S. Jacquemoud, Y. Goulas, J. Louis, I. Moya A new leaf fluorescence
    model, 2nd international workshop on remote sensing of vegetation fluorescence,
    17–19 November Montreal, Canada (2004) Google Scholar Pedrós et al., 2008 R. Pedrós,
    I. Moya, Y. Goulas, S. Jacquemoud Chlorophyll fluorescence emission spectrum inside
    a leaf Photochemical and Photobiological Sciences, 7 (4) (2008), pp. 498-502 CrossRefView
    in ScopusGoogle Scholar Peguero-Pina et al., 2008 J.J. Peguero-Pina, F. Morales,
    J. Flexas, E. Gil-Pelegrín, I. Moya Photochemistry, remotely sensed physiological
    reflectance index and de-epoxidation state of the xanthophyll cycle in Quercus
    coccifera under intense drought Oecologia, 156 (1) (2008), pp. 1-11 CrossRefView
    in ScopusGoogle Scholar Pérez-Priego et al., 2005 O. Pérez-Priego, P.J. Zarco-Tejada,
    G. Sepulcre-Cantó, J.R. Miller, E. Fereres Detection of water stress in orchard
    trees with a high-resolution spectrometer through chlorophyll fluorescence in-filling
    of the O2-A band IEEE Transactions on Geoscience and Remote Sensing, 43 (2005),
    pp. 2860-2869 Google Scholar Rougean and Breon, 1995 J.-L. Rougean, F.M. Breon
    Estimating PAR absorbed by vegetation from bidirectional reflectance measurements
    Remote Sensing of Environment, 51 (1995), pp. 375-384 Google Scholar Rouse et
    al., 1974 Rouse, J. W., Haas, R. H., Schell, J. A., Deering, D. W., Harlan, J.
    C. (1974). Monitoring the vernal advancement and retrogradation (greenwave effect)
    of natural vegetation. NASA/GSFC Type III Final Report, Greenbelt, Maryland, p.
    371. Google Scholar Schreiber and Bilger, 1987 U. Schreiber, W. Bilger Rapid assessment
    of stress effects on plant leaves by chlorophyll fluorescence measurements J.D.
    Tenhunen, E.M. Catarino (Eds.), Plant response to stress, Springer-Verlag, Berlin,
    Germany (1987), pp. 27-53 CrossRefView in ScopusGoogle Scholar Schreiber et al.,
    1994 U. Schreiber, W. Bilger, C. Neubauer Chlorophyll fluorescence as a non-intrusive
    indicator for rapid assessment of in vivo photosynthesis E.D. Schulze, M.M. Caldwell
    (Eds.), Ecophysiology of photosynthesis, Ecological Studies, vol. 100, Springer,
    Berlin Heidelberg New York (1994), pp. 49-70 Google Scholar Sepulcre-Cantó et
    al., 2006 G. Sepulcre-Cantó, P.J. Zarco-Tejada, J.C. Jiménez-Muñoz, J.A. Sobrino,
    E. de Miguel, F.J. Villalobos Within-field thermal variability detection as function
    of water stress in Olea europaea L. orchards with high spatial remote sensing
    imagery Agricultural and Forest Meteorology, 136 (2006), pp. 31-44 View PDFView
    articleView in ScopusGoogle Scholar Sepulcre-Cantó et al., 2007 G. Sepulcre-Cantó,
    P.J. Zarco-Tejada, J.C. Jiménez-Muñoz, J.A. Sobrino, M.A. Soriano, E. Fereres,
    et al. Monitoring yield and fruit quality parameters in open-canopy tree crops
    under water stress. Implications for ASTER Remote Sensing of Environment, 107
    (2007), pp. 455-470 View PDFView articleView in ScopusGoogle Scholar Sepulcre-Cantó
    et al., 2009 G. Sepulcre-Cantó, P.J. Zarco-Tejada, J.A. Sobrino, J.A.J. Berni,
    J.C. Jiménez-Muñoz, J.P. Gastellu-Etchegorry Discriminating irrigated and rainfed
    olive orchards with thermal ASTER imagery and DART 3D simulation Agricultural
    and Forest Meteorology, 149 (2009), pp. 962-975 View PDFView articleView in ScopusGoogle
    Scholar Soukupová et al., 2008 J. Soukupová, L. Cséfalvay, O. Urban, M. Kosvancová,
    M. Marek, U. Rascher, et al. Annual variation of the steady-state chlorophyll
    fluorescence emission of evergreen plants in temperate zone Functional Plant Biology,
    35 (2008), pp. 63-76 View in ScopusGoogle Scholar Suarez et al., 2008 L. Suarez,
    P.J. Zarco-Tejada, G. Sepulcre-Cantó, O. Pérez-Priego, J.R. Miller, J.C. Jiménez-Muñoz,
    et al. Assessing canopy PRI for water stress detection with diurnal airborne imagery
    Remote Sensing of Environment, 112 (2008), pp. 560-575 View PDFView articleView
    in ScopusGoogle Scholar Suárez et al., 2009 L. Suárez, P.J. Zarco-Tejada, J.A.J.
    Berni, V. González-Dugo, E. Fereres Modelling PRI for water stress detection using
    radiative transfer models Remote Sensing of Environment, 113 (2009), pp. 730-744
    View PDFView articleView in ScopusGoogle Scholar Suárez et al., 2010 L. Suárez,
    P.J. Zarco-Tejada, V. González-Dugo, J.A.J. Berni, R. Sagardoy, F. Morales, et
    al. Detecting water stress effects on fruit quality in orchards with time-series
    PRI airborne imagery Remote Sensing of Environment, 114 (2010), pp. 286-298 View
    PDFView articleView in ScopusGoogle Scholar Slatyer, 1967 J.O. Slatyer Plant–water
    relationships Academic press, New York and London (1967) 366p Google Scholar Tanner,
    1963 C.B. Tanner Plant temperatures Agronomy Journal, 55 (1963), pp. 210-211 CrossRefGoogle
    Scholar Thenot et al., 2002 F. Thenot, M. Méthy, T. Winkel The photochemical reflectance
    index (PRI) as a water-stress index International Journal of Remote Sensing, 23
    (23) (2002), pp. 5135-5139 View in ScopusGoogle Scholar Verhoef, 2004 W. Verhoef
    (2005), Extension of SAIL to model solar-induced canopy fluorescence spectra,
    2nd international workshop on remote sensing of vegetation fluorescence, 17–19
    Nov Montreal, Canada (2004) Google Scholar Villalobos et al., 2008 F.J. Villalobos,
    L. Testi, M.F. Moreno-Perez Evaporation and canopy conductance of citrus orchard
    Agricultural Water Management, 96 (4) (2008), pp. 565-573 Google Scholar Vogelmann
    et al., 1993 J.E. Vogelmann, B.N. Rock, D.M. Moss Red edge spectral measurements
    from sugar maple leaves International Journal of Remote Sensing, 14 (1993), pp.
    1563-1575 CrossRefView in ScopusGoogle Scholar Zarco-Tejada et al., 2000 P.J.
    Zarco-Tejada, J.R. Miller, G.H. Mohammed, T.L. Noland, P.H. Sampson Chlorophyll
    fluorescence effects on vegetation apparent reflectance: II. Laboratory and airborne
    canopy-level measurements with hyperspectral data Remote Sensing of Environment,
    74 (3) (2000), pp. 596-608 View PDFView articleView in ScopusGoogle Scholar Zarco-Tejada
    et al., 2001 P.J. Zarco-Tejada, J.R. Miller, G.H. Mohammed, T.L. Noland, P.H.
    Sampson Scaling-up and model inversion methods with narrow-band optical indices
    for chlorophyll content estimation in closed forest canopies with hyperspectral
    data IEEE Transactions on Geoscience and Remote Sensing, 39 (7) (2001), pp. 1491-1507
    View in ScopusGoogle Scholar Zarco-Tejada et al., 2005 P.J. Zarco-Tejada, A. Berjón,
    R. López-Lozano, J.R. Miller, P. Marin, V. Cachorro, et al. Assessing vineyard
    condition with hyperspectral indices: Leaf and canopy reflectance simulation in
    a row-structured discontinuous canopy Remote Sensing of Environment, 99 (2005),
    pp. 271-287 View PDFView articleView in ScopusGoogle Scholar Zarco-Tejada et al.,
    2006 P.J. Zarco-Tejada, J.R. Miller, R. Pedrós, W. Verhoef, M. Berger FluorMODgui
    V3.0 — A graphic user interface for the leaf and canopy simulation of chlorophyll
    fluorescence Computers & Geosciences, 32 (5) (2006), pp. 577-591 View PDFView
    articleView in ScopusGoogle Scholar Zarco-Tejada et al., 2008 P.J. Zarco-Tejada,
    J.A.J. Berni, L. Suárez, E. Fereres A new era in remote sensing of crops with
    unmanned robots SPIE Newsroom (2008), 10.1117/2.1200812.1438 Google Scholar Zarco-Tejada
    et al., 2009 P.J. Zarco-Tejada, J.A.J. Berni, L. Suárez, G. Sepulcre-Cantó, F.
    Morales, J.R. Miller Imaging chlorophyll fluorescence from an airborne narrow-band
    multispectral camera for vegetation stress detection Remote Sensing of Environment,
    113 (2009), pp. 1262-1275 View PDFView articleView in ScopusGoogle Scholar Cited
    by (710) Cross-scale mapping of above-ground biomass and shrub dominance by integrating
    UAV and satellite data in temperate grassland 2024, Remote Sensing of Environment
    Show abstract Using only the red-edge bands is sufficient to detect tree stress:
    A case study on the early detection of PWD using hyperspectral drone images 2024,
    Computers and Electronics in Agriculture Show abstract Water availability and
    atmospheric dryness controls on spaceborne sun-induced chlorophyll fluorescence
    yield 2024, Remote Sensing of Environment Show abstract Potato late blight severity
    monitoring based on the relief-mRmR algorithm with dual-drone cooperation 2023,
    Computers and Electronics in Agriculture Show abstract Early detection of pine
    shoot beetle attack using vertical profile of plant traits through UAV-based hyperspectral,
    thermal, and lidar data fusion 2023, International Journal of Applied Earth Observation
    and Geoinformation Show abstract UAV-based remote sensing in orcha-forest environment;
    diversity of research, used platforms and sensors 2023, Remote Sensing Applications:
    Society and Environment Show abstract View all citing articles on Scopus View
    Abstract Copyright © 2011 Elsevier Inc. All rights reserved. Part of special issue
    Remote Sensing of Urban Environments Edited by Qihao Weng, Dale Quattrochi, Toby
    Carlson Download full issue Other articles from this issue Monitoring two decades
    of urbanization in the Poyang Lake area, China through spectral unmixing 15 February
    2012 Ryo Michishita, …, Bing Xu View PDF Experimental characterization and modelling
    of the nighttime directional anisotropy of thermal infrared measurements over
    an urban area: Case study of Toulouse (France) 15 February 2012 J.-P. Lagouarde,
    …, P. Mestayer View PDF Remote sensing of impervious surfaces in the urban areas:
    Requirements, methods, and trends 15 February 2012 Qihao Weng View PDF View more
    articles Recommended articles Article Metrics Citations Citation Indexes: 694
    Patent Family Citations: 1 Policy Citations: 1 Captures Readers: 1050 View details
    About ScienceDirect Remote access Shopping cart Advertise Contact and support
    Terms and conditions Privacy policy Cookies are used by this site. Cookie settings
    | Your Privacy Choices All content on this site: Copyright © 2024 Elsevier B.V.,
    its licensors, and contributors. All rights are reserved, including those for
    text and data mining, AI training, and similar technologies. For all open access
    content, the Creative Commons licensing terms apply.'
  inline_citation: '>'
  journal: Remote sensing of environment
  limitations: '>'
  pdf_link: null
  publication_year: 2012
  relevance_score1: 0
  relevance_score2: 0
  title: Fluorescence, temperature and narrow-band indices acquired from a UAV platform
    for water stress detection using a micro-hyperspectral imager and a thermal camera
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1016/j.tplants.2013.09.008
  analysis: '>'
  authors:
  - José Luís Araus
  - Jill E. Cairns
  citation_count: 1249
  full_citation: '>'
  full_text: '>

    Skip to main content Skip to article Journals & Books Search Register Sign in
    Brought to you by: University of Nebraska-Lincoln View PDF Download full issue
    Outline Highlights Keywords Why is phenotyping so important in the breeding pipeline?
    Field phenotyping Traits for phenotyping More than traits and tools: spatial variability
    and environmental monitoring Field phenotyping bottleneck Concluding remarks and
    future perspectives Acknowledgments References Show full outline Cited by (1186)
    Figures (4) Volume 19, Issue 1, January 2014, Pages 52-61 Review Field high-throughput
    phenotyping: the new crop breeding frontier Author links open overlay panel José
    Luis Araus 1, Jill E. Cairns 2 Show more Add to Mendeley Share Cite https://doi.org/10.1016/j.tplants.2013.09.008
    Get rights and content Highlights • Advances in field phenotyping are needed to
    capitalize on developments in genetics. • We present developments in field phenotyping
    platforms for crop breeding. • Platforms need more focus on environmental monitoring
    and capturing field variability. • Improvements in data management and use will
    spread the adoption of field platforms. Constraints in field phenotyping capability
    limit our ability to dissect the genetics of quantitative traits, particularly
    those related to yield and stress tolerance (e.g., yield potential as well as
    increased drought, heat tolerance, and nutrient efficiency, etc.). The development
    of effective field-based high-throughput phenotyping platforms (HTPPs) remains
    a bottleneck for future breeding advances. However, progress in sensors, aeronautics,
    and high-performance computing are paving the way. Here, we review recent advances
    in field HTPPs, which should combine at an affordable cost, high capacity for
    data recording, scoring and processing, and non-invasive remote sensing methods,
    together with automated environmental data collection. Laboratory analyses of
    key plant parts may complement direct phenotyping under field conditions. Improvements
    in user-friendly data management together with a more powerful interpretation
    of results should increase the use of field HTPPs, therefore increasing the efficiency
    of crop genetic improvement to meet the needs of future generations. Previous
    article in issue Next article in issue Keywords crop breedingphenotypingremote
    sensingspatial variabilitystress tolerance Why is phenotyping so important in
    the breeding pipeline? Crop production must double by 2050 to meet the predicted
    production demands of the global population [1]. However, achieving this goal
    will be a significant challenge for plant breeders because crop yields would have
    to increase at a rate of 2.4% per year, yet the average rate of increase is only
    1.3%, with yields stagnating in up to 40% of land under cereal production 2, 3.
    Extensive breeding and agronomic efforts over the past 50 years have been responsible
    for tripling cereal yields [4]. Continuing advances in the techniques available
    to breeders offer the potential to increase the rate of genetic improvement [5].
    Attempts to exploit new molecular tools to their full potential (Figure 1), particularly
    the ability to dissect the genetics of quantitative traits such as yield and stress
    tolerance 6, 7, 8, 9, 10, are limited by our ability to phenotype. However, plant
    breeders and farmers have been making selections based on phenotypes long before
    the discovery of DNA and molecular markers. The development of improved varieties
    relies on the ability to identify the best genetic variation for advancement.
    Breeding is essentially a numbers game: the more crosses and environments used
    for selection, the greater the probability of identifying superior variation.
    Plant breeders want to be able to phenotype large numbers of lines rapidly and
    accurately identify the best progeny. To meet future needs there is a need to
    increase breeding efficiency. Advances in high-throughput genotyping have provided
    fast and inexpensive genomic information. Low cost, high-throughput genotyping
    has paved the way for the development of large mapping populations and diversity
    panels of thousands of recombinant inbred lines for phenotyping [11]. Although
    molecular breeding strategies, such as marker-assisted recurrent selection (MARS)
    and genomic selection, place greater focus on selections based on genotypic information,
    they still require phenotypic data [12]. In genomic selection, phenotypes are
    not used for selection but are used to train a prediction model [13]; whereas
    in MARS, a single phenotyping cycle is used to identify markers for subsequent
    selection through generations. Similarly, phenotyping is necessary to identify
    promising events in transgenic studies 14, 15. Given that molecular breeding populations
    can include up to 5000 lines, the ability to accurately characterize all lines
    simultaneously is challenging [11]. Advances in phenotyping are likely to be essential
    to capitalize on developments in conventional, molecular, and transgenic breeding
    and ensure genetic improvement of crops for future food security. Download : Download
    full-size image Figure 1. (Upper) The four pillars of the crop breeding pipeline
    (environmental adaptation, phenotypic characterization, genetic diversity, and
    genetic information) and the implications of phenotyping. The importance of phenotyping
    is highlighted by its involvement in two of these pillars. (Lower left) Mapping
    field variability in a non-destructive manner implies the use of different methodological
    alternatives and its further integration. (Lower right) Diagram of the main categories
    of phenotyping techniques deployed over the life cycle of an annual seed crop.
    Types of data acquisition include: proximal sensing and imaging at frequent intervals,
    laboratory analyses of samples taken at specific intervals, and near-infrared
    spectroscopy (NIRS) of seed for oil or protein content during combine harvesting.
    Redrawn from [20]. High-throughput phenotyping In recent years, there has been
    increased interest in high-throughput phenotyping platforms (HTPPs) 16, 17. Most
    HTPPs, both those run by the big transnational seed companies and the most advanced
    public plant research institutions around the world, such as the Australian Plant
    Phenomics Facility (http://www.plantphenomics.org.au/), the European Plant Phenotyping
    Network (http://www.plant-phenotyping-network.eu/eppn/structure), and the USDA
    (http://www.nifa.usda.gov/nea/plants/pdfs/whitepaper_finalUSDA.pdf), (http://www.wheatgenetics.org/downloads/Projects/HTP_ProjectNarrative_20130219.pdf)
    are fully automated facilities in greenhouses or growth chambers with robotics,
    precise environmental control, and remote sensing techniques to assess plant growth
    and performance. However, low-cost HTPP approaches are now starting to be developed
    [18]. In this review, we examine the need for high-throughput field phenotyping,
    the current technical developments, and the factors that limit its implementation,
    together with the future avenues that will pave the way for its wide adoption
    in practical breeding. Field phenotyping Although HTPPs enable detailed, non-invasive
    information to be captured throughout the plant life cycle in a carefully controlled
    environment, quantitative trait loci and candidate genes identified within controlled
    environments have generally not translated into gains in grain yield in the field
    19, 20, 21. Field conditions are notoriously heterogeneous and the inability to
    control environmental factors makes results difficult to interpret. However, results
    from controlled environments are far removed from the situation plants will experience
    in the field and, therefore, are difficult to extrapolate to the field. The problems
    associated with controlled environments are well established 6, 22, 23 (Figure
    2). For example, the volume of soil available to roots within a pot is considerably
    smaller than in the field, thereby reducing the amount of water and nutrients
    available to plants 24, 25, 26. The soil environment plays a crucial role in plant
    growth and development and is difficult to simulate under controlled conditions
    [27]. Drought stress phenotyping is particularly challenging because declining
    soil moisture content is associated with increased mechanical impedance in the
    field, which is an effect that is difficult to replicate within pots [28]. Moreover
    plants in the field do not growth isolate but configuring a canopy. Varietal improvement
    has heavily relied on multilocation screening within the target environment [29].
    Here, plants experience a range of stresses throughout their life cycle. In many
    cases, the environmental characteristics are not monitored and, hence, are poorly
    understood. This further complicates the ability to mimic the field environment
    under controlled conditions. Phenotyping under field environmental conditions
    remains a bottleneck for future breeding advances 7, 10, 19, 30, 31. Besides the
    above considerations, the choice of phenotyping under controlled conditions versus
    field environments largely depends on the purpose of phenotyping and the heritability
    of the trait, together with the logistical considerations of collecting the data
    [10]. For example, there are no feasible spatial or temporal options for testing
    high atmospheric CO2 in the field [32]. Download : Download full-size image Figure
    2. Continuum of environments for drought-resistance screening. The control over
    environmental factors decreases from the use of growth chambers to the target
    population environment (TPE), whereas the correlation of performance with the
    target commercial environments increases. Rainout shelters are designed to protect
    a selected area of land against receiving precipitation so that an experimentally
    controlled drought stress can be imposed on that area. Redrawn from [24]. Traits
    for phenotyping The most successful traits for evaluation integrate in time (throughout
    the crop cycle) and space (at the canopy level) the performance of the crop in
    terms of capturing resources (e.g., radiation, water, and nutrients) and how efficiently
    these resources are used 19, 33. Different methodological approaches have been
    proposed to evaluate these traits in the field (Figure 1). Using the criteria
    proposed in [20] they can be summarized into three categories: (i) proximal (remote)
    sensing and imaging, (ii) laboratory analyses of samples, and (iii) near-infrared
    reflectance spectroscopy (NIRS) analysis in the harvestable part of the crop.
    Besides the choice of the most appropriate traits, it is also crucial to determine
    the key time(s) for their evaluation. Measuring these traits at more or less frequent
    intervals during the crop cycle together with the measurements of the harvestable
    components would be unfeasible (or at least impractical) and may even be negative
    in terms of the impact of the trait for breeding. Proximal (remote) sensing: different
    categories of sensors Remote sensing phenotyping methods are non-destructive,
    non-invasive approaches 20, 34, 35 based mostly on the information provided by
    visible/near-infrared (VIS-NIR) radiation reflected (or transmitted) and far-infrared
    (thermal) radiation emitted by the crop 36, 37, 38, 39, 40, 41. These methods
    are termed proximal in the sense that information is gathered ‘near’ the crop.
    Remote sensing techniques may be deployed in in situ screening for a wide range
    of breeding objectives, including yield potential, adaptation to abiotic (water
    stress, extreme temperatures, salinity) and biotic (susceptibility to pests and
    diseases) limiting conditions, and even quality traits. Many categories of traits
    may be measured under different environmental conditions using remote sensing
    approaches, ranging, for example, from green biomass through to photosynthetic
    transpirative gas exchange and on to quality traits or even to predict grain yield
    [39]. For example, the same authors [39] working with a set of 300 maize testcrosses
    grown under different water and temperature regimes reported that partial least
    square regression (PLSR) models from hyperspectral reflectance of maize explained
    up to 40% of the variation in grain yield in each trial, with a relative efficiency
    of selection of 0.88 and 0.68 using leaf and canopy reflectance, respectively.
    Moreover, strong agreement has been reported between remote sensing and imaging
    values of traits measured by HTPPs at the land and aerial levels, as well as through
    manual phenotyping approaches, with determination values ranging between 0.35
    and 0.82 in the case of cotton under different water regimes [42]. These results
    confirmed the ability of the phenotyping system to measure multiple traits rapidly
    and accurately. Concerning NIRS, it is already routinely used in breeding for
    a wide array of food and feed quality traits [43]. In fact, NIRS can be applied
    to drought or nutrient use efficiency screening, or other more general breeding/gene
    discovery objectives. The implementation in imaging formats of proximal sensing
    with VIS-NIR and far-infrared radiation has enabled the process of taking measurements
    to be upscaled: for example, from measuring a single plot to dissecting an entire
    trial composed of different plots, providing that the image has enough resolution
    (pixels). However, imaging speed is limited by post-processing, which may include
    image alignment, geometric and radiometric calibrations, atmospheric correction,
    automatic mosaicking, and algorithms for automatic image segmentation 44, 45.
    Proximal (remote) sensing and imaging techniques include different approaches.
    The approaches that are most implemented (feasible) for field phenotyping can
    be grouped into three different categories (see Box 1 for images): (i) VIS-NIR
    spectroradiometry (including multispectral and the even less developed hyperspectral
    imaging) [45], (ii) infrared thermometry and thermal imaging, and (iii) conventional
    digital photography (RGB color cameras). The first approach is undergoing rapid
    technical advances associated with the use of high-resolution full-range spectroradiometers
    that reach into the NIR region wavelengths around 2500 nm. This, together with
    the use of special adaptors with their own light source, enables such spectroradiometers
    to be used as field-portable NIRS devices, generating large amounts of data with
    a wide range of potential applications. Examples include the development of empirical
    models to assess specific photosynthetic characteristics related to radiation
    use efficiency [46], or to predict a complex trait such as grain yield [39], and
    the use of single spectroradiometrical indices to predict yield [41]. At the imaging
    level, hyperspectral sensors are being developed along similar lines, although
    it is not possible for them to carry their own light source (specifically for
    large-scale images), thus this may represent a limitation [44]. Nevertheless,
    hyperspectral imagery enables assessment of complex traits, such as canopy photosynthesis
    and fluorescence under natural sunlight conditions 45, 47. There are several software
    programs available to process information to extract phenotype data from images,
    including free options [10]. Box 1 Cameras for crop monitoring Different categories
    of imaging systems for remote sensing evaluation of vegetation are detailed below
    with examples of prototypes capable of being carried by UAPs of limited payload
    (Figure I). Download : Download full-size image Figure I. Examples of false-color
    images taken with different categories of cameras: (A) RGB/CIR, (B) multispectral,
    (C) hypespectral, and (D) thermal imaging. RGB/CIR cameras The combination of
    color infrared (CIR) and red, green, and blue light (called visible or RGB) imagery
    enables the estimation of green biomass (NDVI type of information). Miniaturization
    is advancing fast with cameras that weigh only 100 g and have spectral range bands
    in red, green, and NIR. Figure IA shows an image taken with a multispectral mono
    lens camera (ADC Lite) of three bands. Multispectral cameras Multispectral imagers
    are widely used for crop monitoring via remote sensing. They can acquire a limited
    number of spectral bands at once in the VIS-NIR regions. Besides vegetation indices
    for evaluating green biomass, multispectral imagers can be formulated to other
    different spectral indices targeting senescence evaluation, nutrient status, pigment
    degradation, photosynthetic efficiency, or water content [84]. Figure IB shows
    an image taken with a multispectral camera (miniMCA-6) of six lens. Hyperspectral
    visible and near-infrared imager The hyperspectral visible and near-infrared imager
    enables the acquisition of hundreds of images at once, covering the entire electromagnetic
    spectrum between the visible and the near-infrared regions in a continuous mode
    (wavelengths ranging from 400 to 900 nm). Other configurations cover the range
    from 1000 to 2500 nm. Therefore, it is possible to run empirical calibrations
    (like in a ‘NIRS mode’) against a wide and miscellaneous set of traits. Figure
    IC shows an image taken with a hyperspectral (Microhyperspec VNIR) camera. Long-wave
    infrared cameras or thermal imaging cameras Long-wave infrared cameras and thermal
    imaging cameras render infrared radiation in the range of μm as visible light.
    Potential use of thermal imaging in phenotyping includes predicting water stress
    in crops, disease, and pathogen detection in plants, evaluating the maturing of
    fruits and bruise detection in fruits and vegetables 50, 37, 85, 38. The low resolution
    of the imaging (current cameras are in the range of 640 × 500 pixels) may limit
    the use of such cameras from aerial platforms. Thermal images obtained from a
    UAP using this type of camera have a resolution in the range of 20–40 cm [41].
    Figure ID shows an image taken with a thermal (MIDAS) camera. For more information
    about imaging sensors, visit http://quantalab.ias.csic.es/pdf/. Conventional digital
    cameras (NDVI type work) Conventional digital cameras are low-cost instruments
    that enable, for example, plant cover (green biomass) or senescence to be estimated.
    Moreover, the software needed is usually freely available. A general limitation
    of spectroradiometrical approaches lies in the differences in plant architecture
    and developmental stage, together with the anisotropic characteristics of the
    leaf (mostly due to the leaf surface: roughness, trichomes, epicuticular waxes).
    These may negatively affect the estimation of traits (mostly of biochemical traits)
    by spectroradiometrical approaches [10]. The effect of leaf anisotropy is more
    evident in the remote sensing-based approaches that use reflected instead of transmitted
    radiation, which is the situation in the majority of systems. Moreover, care should
    be taken, for example, to standardize measures with plants at similar developmental
    stages and exhibiting a narrow range of variability in plant architecture, whereas
    sun elevation should also be taken into consideration because the majority of
    spectroradiometrical evaluations in the field use passive sensors. In the case
    of canopy temperature, variation in development and canopy architecture must be
    taken into account (e.g., plant height, soil covering, emerged spikes, leaf angle
    and size) when interpreting performance and selecting cooler breeding lines 48,
    49. This is in addition to the environmental variability (e.g., in light intensity,
    temperature, relative humidity, wind speed) and timing of measurements, which
    affects the accuracy of thermal measurements [50]. Digital photography is also
    a promising approach given the low cost of the sensor (i.e., a conventional camera)
    and access to free software for data processing that enables estimation of green
    biomass, soil cover, plant color 51, 52, or even agronomical components such as
    plant or inflorescence density. Moreover, alongside these approaches, other techniques
    are starting to be adopted for field phenotyping, such as the use of laser imaging
    detection and ranging (Lidar). This is an active remote sensing technique that
    uses Lidar sensors to directly measure the 3D distribution of plant canopies as
    well as subcanopy topography, thus providing high-resolution topographic maps
    and highly accurate estimates of vegetation height, cover, and canopy structure
    53, 54, 55. Furthermore, laser scanning and fluorescence enables evaluation of
    photosynthetic performance and has potential in areas such as plant pathology
    [56]. Field-based high-throughput phenotyping platforms By combining advances
    in remote sensing, aeronautics and high-performance, computing is paving the way
    for the development of field-based HTPPs. Recently, several platforms have been
    developed, ranging from ground-based to aerial systems (e.g., the Australian Plant
    Phenomics Facility, http://www.plantphenomics.org/hrppc/capabilities/technology).
    Ground-based HTPPs include modified vehicles equipped with a global positioning
    system (GPS) navigation device and sensors often referred to as ‘phenomobiles’.
    Different ‘phenomobiles’ have been developed within the past few years 20, 42,
    57, 58, 59, 60 (http://www.plant-phenotyping-network.eu/eppn/inra_diaphen). For
    example, in the case of cotton a system has been developed that carries four sets
    of sensors to measure canopy height, reflectance, and temperature simultaneously
    on four adjacent rows, enabling the collection of phenotypic data at a rate of
    0.84 ha h−1 [42]. The mounting of sensors (such as NIRS) on agricultural harvesters
    may also be included within the category of ‘phenomobiles’ 61, 62. Ground-based
    HTPPs enable data to be captured at the plot level and require little post-processing.
    However, this also limits the scale at which ground-based HTPPs can be used. Furthermore,
    simultaneous measurements of all plots within a trial are not possible with ground-based
    platforms.Aerial platforms are increasingly being considered as an alternative
    option to overcome limitations associated with ground-based HTPPs. Aerial HTPPs
    enable the rapid characterization of many plots within minutes. Initial aerial
    HTPPs used small airplanes (e.g., crop-dusting airplanes); however, this is costly
    and it is difficult to safely achieve the low speeds required for high-definition
    images at low altitude. The current generation of aerial HTPPs significantly varies
    in payload, initial costs, maintenance costs, and control. Recently developed
    alternatives include ‘phenotowers’ [63] and blimps [64]. However, this type of
    aerial HTPP has a maximum height of 50 m. Blimps are helium-filled balloons that
    can be held in a stationary position and have sensors mounted underneath. They
    can carry a heavy payload (several kilograms), enabling many sensors to be used
    concurrently; however, they require many people for control and considerable room
    for storage when inflated. Alternatives to blimps are unmanned aerial platforms
    (UAPs) such as polycopters (e.g., Ascending Technologies: http://www.asctec.de;
    MikroKopter: http://www.mikrokopter.de) and airplanes (see ‘Innovative agricultural
    technologies for sustainable intensification’ at the MAIZE Annual Report of the
    CGIAR Research Program: http://repository.cimmyt.org/xmlui/bitstream/handle/10883/3209/98018.pdf?sequence=1).
    Although the payload of UAPs is lower than blimps, they can generally carry up
    to 2 kg, enabling at least two sensors to be mounted for simultaneous image capture.
    UAPs enable greater flight control and autonomy and are becoming increasingly
    affordable. Unlike airplanes, polycopters can be maneuvered into a stationary
    position; however, advances in aeronautics and sensors now enable high-quality
    images to be obtained from unmanned airplanes. Furthermore, the autonomy and area
    covered by airplanes is larger and the risk of destruction by crashing lower than
    for polycopters. Most UAPs carry an RGB/CIR camera, together with a thermal-imaging
    sensor [and sometimes a conventional color (RGB) digital camera]. Replacing the
    RGB/CIR camera with a multispectral or hyperspectral imaging sensor increases
    the payload but opens up a huge range of new possibilities (Box 1). The software
    requirements for UAPs include programs to: (i) plan flight missions, (ii) gather
    the images, and (iii) extract the data for plots within the images. UAPs are controlled
    by an autopilot for autonomous flying; the ground control station and the UAP
    are radio linked, transmitting position, altitude, and status. The imager is operated
    from the ground station. Laboratory and NIRS analyses In addition to proximal
    sensing approaches, the analysis of plant samples, for example, the analysis of
    stable isotopes [65], may complement direct phenotyping under field conditions.
    When breeding for yield potential and adaption to abiotic stresses such as drought,
    carbon isotope discrimination (Δ13C) in dry matter is a promising tool that frequently
    exhibits high heritability and genetic correlation with yield 66, 67, 68, and
    has already been applied to breeding programs [69]. The use of grain Δ13C relies
    on a good understanding of tested populations and assumes no confounding of genotypic
    differences in phenology, anthesis biomass, pre-anthesis water use, and remobilization
    of stem carbohydrates 19, 66, 69. Whereas Δ13C is still an expensive tool for
    use in large-scale phenotyping, there are low cost surrogates (see next paragraph).
    In addition, if analyzed through the regular (mass spectrometry) technique, Δ13C
    can still be used on just the tails to complement HTPP approaches. Other traits
    that may be deployed as indicators of transpiration and, hence, of water use are
    the total minerals accumulated in transpiring organs [70]. NIRS is regularly deployed
    not only at the laboratory level but also in harvesting machinery to analyze grain
    characteristics. When used in harvesting machinery, this technique secures a broad
    distribution of measurements within plots and covers substantially larger amounts
    of plot material than analyses at the laboratory level using conventional sample-based
    methods 61, 62. In any case, the near-infrared spectrum captures physical and
    chemical characteristics of the samples, either of vegetative plant tissues or
    harvested seeds. By using calibration models, several traits can be determined
    on the basis of a single spectrum. Thus, NIRS is regularly used to analyze, for
    example, the protein, nitrogen, starch and oil content, grain texture, and grain
    weight of (intact) seeds 20, 61, 62, 71. However, the same spectrum may be used
    to develop prediction models for analyzing traits of potential interest for phenotyping
    for stress adaptation, such as Δ13C, mineral content, or the composition of other
    stable isotopes 34, 72, 73. Although the precision of these indirect estimations
    may be lower than those of direct analysis, the rapid, low-cost, and non-destructive
    nature of NIRS may justify its use, at least in the early generations of a breeding
    program, as a first screening approach when thousands of genotypes need to be
    evaluated. Although considerable advances have been made for evaluating the aerial
    parts of plants, roots are still hidden in terms of phenotyping, despite their
    importance in capturing resources for the crop. A broad overview of the different
    approaches proposed for root phenotyping under field conditions is set out in
    Box 2. Box 2 Phenotyping roots Roots are notoriously difficult to phenotype in
    the field 26, 86. Besides technical considerations, screening under field conditions
    is limited by significant soil environment–genotype interactions [87]. Traditional
    studies have focused on excavation techniques, from which root depth and root
    length density can be determined. Trenching is labor intensive and slow. Recently,
    the Australian Commonwealth Scientific and Industrial Research Organization (CSIRO)
    implemented a high-throughput soil-sampling system to evaluate the maximum root
    depth and distribution [86]. This system uses a hydraulic push press: 2–5 min
    per core and 200 cores (200 cm long) per day. The system is being used to assess
    the impact of root architecture traits on water uptake. To that end, continuous
    logging of soil water content (gypsum blocks) and canopy temperature is combined
    with root architecture. Another approach that has been proposed for use in graminaceous
    crops and that is less intensive in terms of the resources deployed is ‘shovelomics’
    [88]. Values for root architectural traits are derived from the visual scoring
    of roots, which includes in the case of maize (Zea mays), numbers, angles, and
    branching patterns of crown and brace roots. Several non-invasive (i.e., indirect)
    techniques have been proposed. These include, for example, electrical capacitance
    [89]. At the level of root imaging, ground-penetrating radar has been explored,
    but resolution limitations mean that it is still likely to be restricted to trees
    and woody plants 86, 90. The use of electrical resistance tomography, even if
    still mostly at the container level [91], is perhaps more promising for mapping
    soil moisture and root biomass in herbaceous crops in the field [92]. Other techniques
    such as magnetic resonance imaging are still restricted to use at the container
    level [63]. Root biomass and performance can also be assessed (indirectly) through
    the evaluation of shoot proxy traits. This is the case for the natural abundances
    of stable oxygen and deuterium isotopes in shoot water [93]. The increasing availability
    of laser analyzers is making such determination faster and less expensive than
    conventional mass spectrometry. Canopy temperature has been used for remote sensing
    of wheat (Triticum aestivum) lines with deeper roots [94]. In the same way, Δ13C
    in dry matter may also be a valuable indicator of differences in access to water
    by mature root systems 95, 96s. Shoot biomass may also be considered as an indirect
    indicator of root biomass and performance 86, 96. However, problems of reliance
    on indirect measures of root growth may be encountered under field conditions
    60, 86. More than traits and tools: spatial variability and environmental monitoring
    Earlier HTPP initiatives have largely focused on phenotyping and little emphasis
    has been placed on environmental monitoring and reducing error variances. The
    phenotyping environment plays a vital role in the quality of phenotypic data generated
    through experiments and, consequently, in the efficiency of breeding. Field variation
    increases error variances, thereby masking important genetic variation for key
    traits and reducing repeatability, regardless of the cost and precision of a phenotyping
    platform [74]. Spatial variation can be caused by several factors, including the
    soil, which is inherently heterogeneous even in relatively uniform experimental
    sites. HTTPs allow a larger number of genotypes to be phenotyped, thereby increasing
    the likelihood of soil variability masking genetic effects. In general, as the
    land requirement of an experiment increases the harder it becomes to find an area
    with minimum soil heterogeneity. Information on field variability can be incorporated
    into field designs by avoiding areas of high spatial variation [75]. The basic
    concept is to create homogeneous blocks in which the ‘noise’ factors are held
    constant, whereas the factor of interest (‘signal’) is allowed to vary. Earlier
    measurements of field variation relied on direct (i.e., destructive soil sampling)
    and subsequent laboratory analysis. However, advances in proximal and remote sensing
    technologies enable high-resolution mapping of spatial variability [76] (Figure
    1). Proximal sensors include cone penetrometers, which can be used to measure
    soil mechanical impedance and depth. However, measurements are time consuming
    and, therefore, soil penetrometers are of limited use for obtaining the necessary
    detail required to create field maps over large areas [28]. Apparent soil electrical
    conductivity is closely related to clay, water, and ionic content and electromagnetic
    surveys can be used to determine field gradients in soil texture 30, 60. Crop
    performance provides the best indicator of field variability. Imaging techniques
    in parallel with wireless sensor networks and geographical information systems
    will allow a more precise mapping and monitoring of, for example, spatial variability
    [77]. For example, aerial HTPPs that enable fast non-destructive GPS-linked measurements
    of biomass using the normalized difference vegetation index (NDVI) can be used
    to measure field variability either on a single variety planted in the off-season
    to develop subsequent planting maps or within experiments to build up performance
    maps to guide planting of the next season. Compared with proximal sensors of field
    variability (Figure 1), aerial HTPPs allow the rapid characterization of experimental
    blocks (less than 30 min for 1 ha plus data processing). Environmental variability
    inconsistently affects phenotypic observation over both space and time and must
    be accounted for in any statistical models that are used to estimate parameters
    of interest [10]. Spatial modeling is a key requirement because of the size of
    the trials, the time taken to collate traits, and the use of high-throughput phenotyping
    approaches. In that context, multitrait mixed modeling looks promising for the
    analysis of traits collected by aerial remote sensing platforms where multiple
    traits derived from the same procedure may produce correlated errors [26]. Linear
    models have long been the mainstay of quantitative genetic experiments and are
    the most commonly applied statistical approach to understanding phenotypic variation.
    However, they have inherent limitations when measurements are not adequately replicated
    and not normally distributed. In this regard, alternatives such as the Bayesian
    inference may overcome the limitations imposed by a maximum-likelihood approach
    [10]. In HTPPs, the implementation of environmental characterization is essential
    to facilitate data interpretation, meta-data analysis, and, in the case of drought
    phenotyping, understanding patterns of water availability [74]. Weather data are
    frequently sourced from nearby weather stations at the end of experiments; however,
    soil moisture is often not measured [75]. The need for environmental data is particularly
    pertinent in drought screening where knowledge of soil moisture availability is
    necessary to ensure that the field environment and the type of drought imposed
    are representative of the target environment [56]. Real-time information on soil
    moisture can be used to facilitate irrigation decisions, which is becoming increasingly
    important with increased climatic variability in the off-season when managed drought
    phenotyping is often conducted. The development of wireless sensor networks to
    characterize both climatic and soil moisture conditions should enable real-time
    monitoring of environmental conditions (Figure 3). Download : Download full-size
    image Figure 3. Summary of the different components of the breeding process where
    high-throughput phenotyping is involved. These include evaluation of key traits
    at the right moment, assessment of spatial variability, environmental characterization,
    and further integration of all the information. A better understanding of the
    stresses prevailing under the target conditions is still needed [78]. Managed
    Environment Facilities are becoming more important as they permit selection under
    controlled stress [60]. Controlling environmental conditions increases the accuracy
    of performance measurements and the attribution of phenotypic effects to individual
    traits and the underlying genetic makeup [79]. Field phenotyping bottleneck HTPPs
    have benefitted in recent years from the rapid progress that has been made in
    the development of a wide array of technologies including novel sensors, image
    analysis and modeling, robotics, and remote control and data mining. Previously,
    time was the largest limitation to phenotyping, but HTPPs now allow plot-level
    measurements within seconds. However, the bottleneck that may slow down the full
    implementation of these platforms is the management of the huge amount of information
    generated 10, 50. Two of the main limiting factors that need to be improved are:
    data management and use of bioinformatics to mine the volumes of phenotypic data,
    and the way in which modeling is used to incorporate genotypic, phenotypic, environmental,
    and management data 48, 80. Advanced analysis tools are required beyond even the
    usual statistical tools [20]. We do not even have a physical concept of what some
    of the numbers obtained by HTPPs mean in terms of plant or crop performance [10].
    Much of the data are just mathematical transformations of numbers, but perhaps
    some linear combination of them will, for reasons we do not yet understand, have
    some correlation with important traits such as leaf angle and planting density
    [21]. However, in the case of information generated through hyperspectral sensors,
    the generation of a set of indices, even of a miscellaneous nature, does not enable
    full advantage to be taken of the hundreds of wavelengths measured. In this regard,
    the ‘NIRS approach’, although it represents construction of a purely empirical
    model, might use the most relevant information regardless of whether it has a
    clear physiological meaning or not [7]. Moreover, such an approach might share
    with genomic selection the possibility of training a model by adding new sets
    of data periodically. Pyramiding all levels of information (different categories
    of traits measured at different times, spatial variability, environmental information)
    in a coherent manner requires the setting down of a strong modeling foundation
    based on a wide but deep understanding of the ecophysiological and genetic factors
    determining crop performance. Above all, more user-friendly post-processing of
    the raw data generated is needed. Improved software tools to optimize automation
    and speed up robust data analysis should support such a trend [81]. Concluding
    remarks and future perspectives The capacity for undertaking precision phenotyping,
    particularly under repeatable and representative growing conditions in the field,
    is lagging far behind the capacity to generate genomic information. This is constraining
    breeding advances. Developments (e.g., sensors, platforms, and analytical capability)
    in HTPPs have enabled these measurements to be made in situ; however, the integration
    of data is lagging behind. Field phenotyping of the appropriate traits, using
    low cost, easy-to-handle tools, should become an integral and key component in
    the breeding pipeline. Using technological advances with regard to phenotyping
    instrumentation should also go hand-in-hand with methods to characterize and control
    field site variation (for improving repeatability), adopting appropriate experimental
    designs, selection of the right traits, and, finally, proper integration of heterogeneous
    datasets, analysis, and application, including prediction models 8, 19, 21, 82,
    83. Efficient integration of all the components of the system is needed to pave
    the way for the adoption of field HTPPs in the near future. This includes more
    user-friendly data management combined with data gathering and processing. Acknowledgments
    The preparation of this article was supported by grants from the MAIZE CGIAR Research
    Program (to J.L.A. and J.E.C.) and the Spanish and Catalan projects AGL2010-20180
    and SGR2009-00327(J.L.A.). We thank Dr Pablo Zarco, Consejo Superior de Investigaciones
    Científicas (CSIC), Spain for providing some of the illustrations and Dr. L. Cabrera-Bosquet,
    Laboratoire d’Ecophysiologie des Plantes sous Stress Environnementaux (LEPSE),
    France for his suggestions on literature. References 1 D. Tilman, et al. Global
    food demand and the sustainable intensification of agriculture Proc. Natl. Acad.
    Sci. U.S.A., 108 (2011), pp. 20260-20264 CrossRefView in ScopusGoogle Scholar
    2 D.K. Ray, et al. Recent patterns of crop yield growth and stagnation Nat. Commun.,
    3 (2012), p. 1293 View in ScopusGoogle Scholar 3 D.K. Ray, et al. Yield trends
    are insufficient to double global crop production by 2050 PLoS ONE, 8 (2013),
    p. e66428 CrossRefView in ScopusGoogle Scholar 4 P.L. Pingali Green revolution:
    impacts, limits, and the path ahead Proc. Natl. Acad. Sci. U.S.A., 109 (2012),
    pp. 12302-12308 CrossRefView in ScopusGoogle Scholar 5 R.L. Phillips Mobilizing
    science to break yield barriers Crop Sci., 50 (2010), pp. S99-S108 Google Scholar
    6 A. Blum Plant Breeding for Water-limited Environments Springer (2011) Google
    Scholar 7 L. Cabrera-Bosquet, et al. High-throughput phenotyping and genomic selection:
    the frontiers of crop breeding converge J. Integr. Plant Biol., 54 (2012), pp.
    312-320 CrossRefView in ScopusGoogle Scholar 8 J.L. Araus, et al. Phenotyping
    maize for adaptation to drought Front. Physiol., 3 (2012), p. 305 Google Scholar
    9 R. Tuberosa Phenotyping for drought tolerance of crops in the genomics era Front.
    Physiol., 3 (2012), p. 347 Google Scholar 10 J.N. Cobb, et al. Next-generation
    phenotyping: requirements and strategies for enhancing our understanding of genotype–phenotype
    relationships and its relevance to crop improvement Theor. Appl. Genet., 126 (2013),
    pp. 867-887 CrossRefView in ScopusGoogle Scholar 11 M.D. McMullen, et al. Genetic
    properties of the maize nested association mapping population Science, 325 (2009),
    pp. 737-740 CrossRefView in ScopusGoogle Scholar 12 J.L. Jannick, et al. Genomic
    selection in plant breeding: from theory to practice Brief. Funct. Genomics, 9
    (2010), pp. 166-177 Google Scholar 13 A.J. Lorenz, et al. Genomic selection in
    plant breeding: knowledge and prospects Adv. Agron., 110 (2011), pp. 77-123 View
    PDFView articleView in ScopusGoogle Scholar 14 A.C.M. Gaudin, et al. Taking transgenic
    rice drought screening to the field J. Exp. Bot., 64 (2013), pp. 109-118 View
    in ScopusGoogle Scholar 15 C. Saint-Pierre, et al. Phenotyping transgenic wheat
    for drought resistance J. Exp. Bot., 63 (2012), pp. 1799-1808 CrossRefGoogle Scholar
    16 R.T. Furbank, M. Tester Phenomics – technologies to relieve the phenotyping
    bottleneck Trends Plant Sci., 16 (2011), pp. 635-644 View PDFView articleView
    in ScopusGoogle Scholar 17 F. Fiorani, U. Schurr Future scenarios for plant phenotyping
    Annu. Rev. Plant Biol., 64 (2013), pp. 17.1-17.25 Google Scholar 18 G.A. Pereyra-Irujo,
    et al. GlyPh: a low-cost platform for phenotyping plant growth and water use Funct.
    Plant Biol., 39 (2012), pp. 905-913 View in ScopusGoogle Scholar 19 J.L. Araus,
    et al. Breeding for yield potential and stress adaptation in cereals Crit. Rev.
    Plant Sci., 27 (2008), pp. 1-36 Google Scholar 20 J.W. White, et al. Field-based
    phenomics for plant genetics research Field Crops Res., 133 (2012), pp. 101-112
    View PDFView articleView in ScopusGoogle Scholar 21 Von Mogel, K.H. (2013) Taking
    the phenomics revolution into the field. CSA News March, 4–10 Google Scholar 22
    J.B. Passioura, J.F. Angus Improving productivity of crops in water-limited environments
    Adv. Agron., 106 (2010), pp. 37-75 View PDFView articleView in ScopusGoogle Scholar
    23 J.B. Passioura Phenotyping for drought tolerance in grain crops: when is it
    useful to breeders? Funct. Plant Biol., 39 (2012), pp. 851-859 View in ScopusGoogle
    Scholar 24 J.B. Passioura The perils of pot experiments Funct. Plant Biol., 33
    (2006), pp. 1075-1079 View in ScopusGoogle Scholar 25 H. Poorter, et al. Pot size
    matters: a meta-analysis of the effects of rooting volume on plant growth Funct.
    Plant Biol., 39 (2012), pp. 839-850 View in ScopusGoogle Scholar 26 M.P. Reynolds,
    et al. (Eds.), Physiological Breeding I: Interdisciplinary Approaches to Improve
    Crop Adaptation, CIMMYT (2012) 27 A.P. Whitmore, W.R. Whalley Physical effects
    of soil drying on roots and crop growth J. Exp. Bot., 60 (2009), pp. 2845-2857
    CrossRefView in ScopusGoogle Scholar 28 J.E. Cairns, et al. Influence of the soil
    physical environment on drought stress and its implications for drought research
    Field Crop Res., 121 (2011), pp. 303-310 View PDFView articleView in ScopusGoogle
    Scholar 29 J.E. Cairns, et al. Adapting maize production to climate change in
    sub-Saharan Africa Food Sec., 5 (2013), pp. 345-360 CrossRefView in ScopusGoogle
    Scholar 30 J.E. Cairns, et al. Dissecting maize productivity: ideotypes associated
    with grain yield under drought stress and well-watered conditions J. Integr. Plant
    Biol., 54 (2012), pp. 1007-1020 CrossRefView in ScopusGoogle Scholar 31 J.E. Cairns,
    et al. Maize production in a changing climate: impacts, adaptation, and mitigation
    strategies Adv. Agron., 114 (2012), pp. 1-58 View PDFView articleView in ScopusGoogle
    Scholar 32 R. Gleadow, et al. Crops for a future climate Funct. Plant Biol., 40
    (2013), pp. iii-vi View in ScopusGoogle Scholar 33 J.L. Araus, et al. Plant breeding
    and water stress in C3 cereals: what to breed for? Ann. Bot., 89 (2002), pp. 925-940
    View in ScopusGoogle Scholar 34 L. Cabrera-Bosquet, et al. NIRS-assessment of
    δ18O, nitrogen and ash content for improved yield potential and drought adaptation
    in maize J. Agric. Food Chem., 59 (2011), pp. 467-474 CrossRefView in ScopusGoogle
    Scholar 35 P. Monneveux, et al. Drought tolerance in potato (S. tuberosum L.):
    Can we learn from drought tolerance research in cereals? Plant Sci., 205–206 (2013),
    pp. 76-86 View PDFView articleView in ScopusGoogle Scholar 36 B. Berger, et al.
    High-throughput shoot imaging to study drought responses J. Exp. Bot., 61 (2010),
    pp. 3519-3528 CrossRefView in ScopusGoogle Scholar 37 R. Munns, et al. New phenotyping
    methods for screening wheat and barley for beneficial responses to water deficit
    J. Exp. Bot., 61 (2010), pp. 3499-3507 CrossRefView in ScopusGoogle Scholar 38
    R. Vadivambal, D.S. Jayas Applications of thermal imaging in agriculture and food
    industry – a review Food Bioprocess Technol., 4 (2011), pp. 186-199 CrossRefView
    in ScopusGoogle Scholar 39 V.S. Weber, et al. Prediction of grain yield using
    reflectance spectra of canopy and leaves in maize plants grown under different
    water regimes Field Crops Res., 128 (2012), pp. 82-90 View PDFView articleView
    in ScopusGoogle Scholar 40 S. Zia, et al. Infrared thermal imaging as a rapid
    tool for identifying water stress tolerant maize genotypes of different phenology
    J. Agron. Crop Sci., 199 (2013), pp. 75-84 View in ScopusGoogle Scholar 41 G.A.
    Lobos, et al. Wheat genotypic variability in grain yield and carbon isotope discrimination
    under Mediterranean conditions assessed by spectral reflectance J. Integr. Plant
    Biol. (2013) (in press) Google Scholar 42 P. Andrade-Sanchez, et al. Development
    and evaluation of a field-based high-throughput phenotyping platform Funct. Plant
    Physiol. (2013), 10.1071/FP13126 Google Scholar 43 C. Grieder, et al. Breeding
    maize as biogas substrate in Central Europe: II. Quantitative-genetic parameters
    for inbred lines and correlations with testcross performance Theor. Appl. Genet.,
    124 (2012), pp. 981-988 CrossRefView in ScopusGoogle Scholar 44 J.A. Bernie, et
    al. Thermal and narrow and multispectral remote sensing for vegetation monitoring
    from an unmanned aerial vehicle IEEE Trans. Geosci. Remote Sens., 47 (2009), pp.
    722-738 Google Scholar 45 P. Zarco-Tejada, et al. Relationships between net photosynthesis
    and steady-state chlorophyll fluorescence retrieved from airborne hyperspectral
    imagery Remote Sens. Environ., 136 (2013), pp. 247-258 View PDFView articleView
    in ScopusGoogle Scholar 46 S.P. Serbin, et al. Leaf optical properties reflect
    variation in photosynthetic metabolism and its sensitivity to temperature J. Exp.
    Bot., 63 (2012), pp. 489-502 CrossRefView in ScopusGoogle Scholar 47 P. Zarco-Tejada,
    et al. Spatial resolution effects on chlorophyll fluorescence retrieval in a heterogeneous
    canopy using hyperspectral imagery and radiative transfer simulation IEEE Geosci.
    Remote Sens. Lett., 10 (2013), pp. 937-941 View in ScopusGoogle Scholar 48 W.H.
    Maes, K. Steppe Estimating evapotranspiration and drought stress with ground-based
    thermal remote sensing in agriculture: a review J. Exp. Bot., 63 (2012), pp. 4671-4712
    CrossRefView in ScopusGoogle Scholar 49 G.J. Rebetzke, et al. Genomic regions
    for canopy temperature and their genetic association with stomatal conductance
    and grain yield in bread wheat (Triticum aestivum L.) Funct. Plant Biol., 40 (2012),
    pp. 14-33 Google Scholar 50 J.M. Costa, et al. Thermography to explore plant–environment
    interactions J. Exp. Bot., 64 (2013), pp. 3937-3949 CrossRefView in ScopusGoogle
    Scholar 51 J. Casadesús, et al. Vegetation indices derived from conventional digital
    cameras as selection criteria for wheat breeding in water-limited environments
    Ann. Appl. Biol., 150 (2007), pp. 227-236 CrossRefView in ScopusGoogle Scholar
    52 D.J. Mullan, M.P. Reynolds Quantifying genetic effects of ground cover on soil
    water evaporation using digital imaging Funct. Plant Biol., 37 (2010), pp. 703-712
    View in ScopusGoogle Scholar 53 M.A. Lefsky, et al. Lidar remote sensing for ecosystem
    studies BioScience, 52 (2002), pp. 19-30 View in ScopusGoogle Scholar 54 K. Omasa,
    et al. 3D lidar imaging for detecting and understanding plant responses and canopy
    structure J. Exp. Bot., 58 (2007), pp. 881-898 View in ScopusGoogle Scholar 55
    F. Hosoi, K. Omasa Estimating vertical plant area density profile and growth parameters
    of a wheat canopy at different growth stages using three-dimensional portable
    Lidar imaging ISPRS J. Photogram. Remote Sens., 64 (2009), pp. 151-158 View PDFView
    articleView in ScopusGoogle Scholar 56 C. Römer, et al. Robust fitting of fluorescence
    spectra for pre-symptomatic wheat leaf rust detection with support vector machines
    Comput. Electron. Agric., 79 (2011), pp. 180-188 View PDFView articleView in ScopusGoogle
    Scholar 57 J.M. Montes, et al. High-throughput non-destructive biomass determination
    during early plant development in maize under field conditions Field Crops Res.,
    121 (2011), pp. 268-273 View PDFView articleView in ScopusGoogle Scholar 58 U.
    Weiss, P. Biber Plant detection and mapping for agricultural robots using a 3D
    LIDAR sensor Robot. Auton. Syst., 59 (2011), pp. 266-273 CrossRefGoogle Scholar
    59 A. Comar, et al. A semi-automatic system for high throughput phenotyping wheat
    cultivars in-field conditions: description and first results Funct. Plant Biol.,
    39 (2012), pp. 914-924 View in ScopusGoogle Scholar 60 G.J. Rebetzke, et al. A
    multisite managed environment facility for targeted trait and germplasm phenotyping
    Funct. Plant Biol., 40 (2013), pp. 1-13 View in ScopusGoogle Scholar 61 J.M. Montes,
    et al. Novel throughput phenotyping platforms in plant genetic studies Trends
    Plant Sci., 12 (2007), pp. 433-436 View PDFView articleView in ScopusGoogle Scholar
    62 R.R. Mir, et al. Integrated genomics, physiology and breeding approaches for
    improving drought tolerance in crops Theor. Appl. Genet., 125 (2012), pp. 625-645
    CrossRefView in ScopusGoogle Scholar 63 U. Rascher, et al. Non-invasive approaches
    for phenotyping of enhanced performance traits in bean Funct. Plant Biol., 38
    (2011), pp. 968-983 View in ScopusGoogle Scholar 64 J.B. Losos Evolutionary biology
    for the 21st century PLoS Biol., 11 (2013), p. e1001466 CrossRefView in ScopusGoogle
    Scholar 65 S. Yousfi, et al. Combined use of δ13C, δ18O and δ15N tracks nitrogen
    metabolism and genotypic adaptation of durum wheat to salinity and water deficit
    New Phytol., 194 (2012), pp. 230-244 CrossRefView in ScopusGoogle Scholar 66 A.G.
    Condon, et al. Improving intrinsic water-use efficiency and crop yield Crop Sci.,
    42 (2002), pp. 122-131 View in ScopusGoogle Scholar 67 A.G. Condon, et al. Breeding
    for high water-use efficiency J. Exp. Bot., 55 (2004), pp. 2447-2460 View in ScopusGoogle
    Scholar 68 J.L. Araus, et al. Comparative performance of δ13C, δ18O and δ15N for
    phenotyping durum wheat adaptation to a dryland environment Funct. Plant Biol.,
    40 (2013), pp. 595-608 View in ScopusGoogle Scholar 69 G.J. Rebetzke, et al. Quantitative
    trait loci for carbon isotope discrimination are repeatable across environments
    and wheat mapping populations Theor. Appl. Genet., 118 (2008), pp. 123-137 CrossRefView
    in ScopusGoogle Scholar 70 L. Cabrera-Bosquet, et al. How yield relates to ash
    content, Δ13C and Δ18O in maize grown under different water regimes Ann. Bot.,
    104 (2009), pp. 1207-1216 CrossRefView in ScopusGoogle Scholar 71 G. Hacisalihoglu,
    et al. Near-infrared reflectance spectroscopy predicts protein, starch, and seed
    weight in intact seeds of common bean (Phaseolus vulgaris L.) J. Agric. Food Chem.,
    58 (2010), pp. 702-706 CrossRefView in ScopusGoogle Scholar 72 J.P. Ferrio, et
    al. Near infrared reflectance spectroscopy as a new surrogate analysis for Δ13C
    in mature kernels of durum wheat Austr. J. Agric. Res., 52 (2001), pp. 809-816
    View in ScopusGoogle Scholar 73 T. Kleinebecker, et al. Prediction of δ13C and
    δ15N in plant tissues with near-infrared reflectance spectroscopy New Phytol.,
    184 (2009), pp. 732-739 CrossRefView in ScopusGoogle Scholar 74 B. Masuka, et
    al. Deciphering the code: successful abiotic stress phenotyping for molecular
    breeding J. Integr. Plant Biol., 54 (2012), pp. 238-249 CrossRefView in ScopusGoogle
    Scholar 75 H.G. Jones Monitoring plant and soil water status: established and
    novel methods revisited and their relevance to studies of drought tolerance J.
    Exp. Bot., 58 (2007), pp. 119-130 View in ScopusGoogle Scholar 76 R. Gebbers,
    V.I. Adamchuk Precision agriculture and food security Science, 327 (2010), pp.
    828-831 CrossRefView in ScopusGoogle Scholar 77 W.S. Lee, et al. Sensing technologies
    for precision specialty crop production Comput. Electron. Agric., 74 (2010), pp.
    2-33 View PDFView articleView in ScopusGoogle Scholar 78 V.S. Weber, et al. Efficiency
    of managed-stress screening of elite maize hybrids under drought and low nitrogen
    for yield under rainfed conditions in Southern Africa Crop Sci., 52 (2012), pp.
    1011-1020 CrossRefView in ScopusGoogle Scholar 79 A. Blum Drought resistance –
    is it really a complex trait? Funct. Plant Biol., 38 (2011), pp. 753-757 View
    in ScopusGoogle Scholar 80 R. Pieruschka, H. Poorter Phenotyping plants: genes,
    phenes and machines Funct. Plant Biol., 39 (2012), pp. 813-820 View in ScopusGoogle
    Scholar 81 S. Fuentes, et al. Computational water stress indices obtained from
    thermal image analysis of grapevine canopies Irrig. Sci., 30 (2012), pp. 523-536
    CrossRefView in ScopusGoogle Scholar 82 F. Tardieu, R. Tuberosa Dissection and
    modelling of abiotic stress tolerance in plants Curr. Opin. Plant Biol., 13 (2010),
    pp. 206-212 View PDFView articleView in ScopusGoogle Scholar 83 B.P. Prasanna,
    et al. High-throughput and precision phenotyping for cereal breeding programs
    P.K. Gupta, R.K. Varshney (Eds.), Cereal Genomics II, Springer (2013), pp. 341-374
    (Chapter 13) CrossRefView in ScopusGoogle Scholar 84 M. Gutierrez, et al. Association
    of water spectral indices with plant and soil water relations in contrasting wheat
    genotypes J. Exp. Bot., 12 (2010), pp. 3291-3303 CrossRefView in ScopusGoogle
    Scholar 85 A. Walter, et al. Advanced phenotyping offers opportunities for improved
    breeding of forage and turf species Ann. Bot., 110 (2012), pp. 1271-1279 CrossRefView
    in ScopusGoogle Scholar 86 A.P. Wasson, et al. Traits and selection strategies
    to improve root systems and water uptake in water-limited wheat crops J. Exp.
    Bot., 63 (2012), pp. 3485-3498 CrossRefView in ScopusGoogle Scholar 87 P.J. Gregory,
    et al. Root phenomics of crops: opportunities and challenges Funct. Plant Biol.,
    36 (2009), pp. 922-929 View in ScopusGoogle Scholar 88 S. Trachsel, et al. Shovelomics:
    high throughput phenotyping of maize (Zea mays L.) root architecture in the field
    Plant Soil, 341 (2011), pp. 75-87 CrossRefView in ScopusGoogle Scholar 89 J. van
    Beem, et al. Estimating root mass in maize using a portable capacitance meter
    Agron. J., 90 (1998), pp. 566-570 CrossRefView in ScopusGoogle Scholar 90 T. Zenone,
    et al. Preliminary use of ground-penetrating radar and electrical resistivity
    tomography to study tree roots in pine forests and poplar plantations Funct. Plant
    Biol., 35 (2008), pp. 1047-1058 View in ScopusGoogle Scholar 91 M. Amato, et al.
    Multi-electrode 3D resistivity imaging of alfalfa root zone Eur. J. Agron., 31
    (2009), pp. 213-222 View PDFView articleView in ScopusGoogle Scholar 92 I. Srayeddin,
    C. Doussan Estimation of the spatial variability of root water uptake of maize
    and sorghum at the field scale by electrical resistivity tomography Plant Soil,
    319 (2009), pp. 185-207 CrossRefView in ScopusGoogle Scholar 93 J.L. Durand, et
    al. Ranking of the depth of water extraction by individual grass plants, using
    natural 18O isotope abundance Environ. Exp. Bot., 60 (2007), pp. 137-144 View
    PDFView articleView in ScopusGoogle Scholar 94 M.S. Lopes, M.P. Reynolds Partitioning
    of assimilates to deeper roots is associated with cooler canopies and increased
    yield under drought in wheat Funct. Plant Biol., 37 (2010), pp. 147-156 View in
    ScopusGoogle Scholar 95 J.L. Araus, et al. Breeding cereals for Mediterranean
    conditions: ecophysiological clues for biotechnology application Ann. Appl. Biol.,
    142 (2003), pp. 129-141 CrossRefGoogle Scholar 96 A. Elazab, et al. Root traits
    and δ13C and δ18O of durum wheat under different water regimes Funct. Plant Biol.,
    39 (2012), pp. 379-393 View in ScopusGoogle Scholar Cited by (1186) Enhancement
    of rice traits for the maintenance of the phosphorus balance between rice plants
    and the soil 2024, Current Plant Biology Show abstract Comparing and combining
    data-driven and model-driven approaches to monitor wheat green area index with
    high spatio-temporal resolution satellites 2024, Remote Sensing of Environment
    Show abstract Non-chemical weed management: Which crop functions and traits to
    improve through breeding? 2024, Crop Protection Show abstract Genomic selection
    in plant breeding: Key factors shaping two decades of progress 2024, Molecular
    Plant Show abstract Aerial phenotyping for sugarcane yield and drought tolerance
    2024, Field Crops Research Show abstract High-throughput phenotyping for terminal
    drought stress in chickpea (Cicer arietinum L.) 2024, Plant Stress Show abstract
    View all citing articles on Scopus View Abstract Copyright © 2013 Elsevier Ltd.
    All rights reserved. Recommended articles A Versatile Phenotyping System and Analytics
    Platform Reveals Diverse Temporal Responses to Water Availability in Molecular
    Plant, Volume 8, Issue 10, 2015, pp. 1520-1535 Noah Fahlgren, …, Ivan Baxter View
    PDF Estimation of plant height using a high throughput phenotyping platform based
    on unmanned aerial vehicle and self-calibration: Example for sorghum breeding
    European Journal of Agronomy, Volume 95, 2018, pp. 24-32 Pengcheng Hu, …, Bangyou
    Zheng View PDF Low-altitude, high-resolution aerial imaging systems for row and
    field crop phenotyping: A review European Journal of Agronomy, Volume 70, 2015,
    pp. 112-123 Sindhuja Sankaran, …, Mark J. Pavek View PDF Show 3 more articles
    Article Metrics Citations Citation Indexes: 1130 Policy Citations: 5 Captures
    Readers: 1800 Social Media Shares, Likes & Comments: 72 View details About ScienceDirect
    Remote access Shopping cart Advertise Contact and support Terms and conditions
    Privacy policy Cookies are used by this site. Cookie settings | Your Privacy Choices
    All content on this site: Copyright © 2024 Elsevier B.V., its licensors, and contributors.
    All rights are reserved, including those for text and data mining, AI training,
    and similar technologies. For all open access content, the Creative Commons licensing
    terms apply.'
  inline_citation: '>'
  journal: Trends in Plant Science
  limitations: '>'
  pdf_link: null
  publication_year: 2014
  relevance_score1: 0
  relevance_score2: 0
  title: 'Field high-throughput phenotyping: the new crop breeding frontier'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1016/j.compag.2018.02.016
  analysis: '>'
  authors:
  - Andreas Kamilaris
  - Francesc X. Prenafeta-Boldú
  citation_count: 2220
  full_citation: '>'
  full_text: '>

    Skip to main content Skip to article Journals & Books Search Register Sign in
    Brought to you by: University of Nebraska-Lincoln View PDF Download full issue
    Outline Highlights Abstract Keywords 1. Introduction 2. Methodology 3. Deep learning
    4. Deep learning applications in agriculture 5. Discussion 6. Conclusion Acknowledgments
    Appendix A. Applications of computer vision in agriculture and popular techniques
    used Appendix B. Applications of deep learning in agriculture Appendix C. Publicly-available
    datasets related to agriculture Research Data References Show full outline Cited
    by (2487) Figures (2) Tables (5) Table 1 Table 2 Table Table Table Computers and
    Electronics in Agriculture Volume 147, April 2018, Pages 70-90 Review Deep learning
    in agriculture: A survey Author links open overlay panel Andreas Kamilaris, Francesc
    X. Prenafeta-Boldú Show more Add to Mendeley Share Cite https://doi.org/10.1016/j.compag.2018.02.016
    Get rights and content Highlights • Survey on the deep learning technique applied
    in agriculture. • Detailed review of 40 relevant research papers. • Examining
    research area, technical details, data sources and performance achieved. • Deep
    learning offers high precision outperforming other image processing techniques.
    • Discussion on advanced deep learning models used in various agricultural problems.
    • Status, advantages, disadvantages and potential of deep learning in agriculture.
    • Potential future applications in agriculture using deep learning. Abstract Deep
    learning constitutes a recent, modern technique for image processing and data
    analysis, with promising results and large potential. As deep learning has been
    successfully applied in various domains, it has recently entered also the domain
    of agriculture. In this paper, we perform a survey of 40 research efforts that
    employ deep learning techniques, applied to various agricultural and food production
    challenges. We examine the particular agricultural problems under study, the specific
    models and frameworks employed, the sources, nature and pre-processing of data
    used, and the overall performance achieved according to the metrics used at each
    work under study. Moreover, we study comparisons of deep learning with other existing
    popular techniques, in respect to differences in classification or regression
    performance. Our findings indicate that deep learning provides high accuracy,
    outperforming existing commonly used image processing techniques. Previous article
    in issue Next article in issue Keywords Deep learningAgricultureSurveyConvolutional
    Neural NetworksRecurrent Neural NetworksSmart farmingFood systems 1. Introduction
    Smart farming (Tyagi, 2016) is important for tackling the challenges of agricultural
    production in terms of productivity, environmental impact, food security and sustainability
    (Gebbers and Adamchuk, 2010). As the global population has been continuously increasing
    (Kitzes et al., 2008), a large increase on food production must be achieved (FAO,
    2009), maintaining at the same time availability and high nutritional quality
    across the globe, protecting the natural ecosystems by using sustainable farming
    procedures. To address these challenges, the complex, multivariate and unpredictable
    agricultural ecosystems need to be better understood by monitoring, measuring
    and analyzing continuously various physical aspects and phenomena. This implies
    analysis of big agricultural data (Kamilaris et al., 2017b), and the use of new
    information and communication technologies (ICT) (Kamilaris et al., 2016), both
    for short-scale crop/farm management as well as for larger-scale ecosystems’ observation,
    enhancing the existing tasks of management and decision/policy making by context,
    situation and location awareness. Larger-scale observation is facilitated by remote
    sensing (Bastiaanssen et al., 2000), performed by means of satellites, airplanes
    and unmanned aerial vehicles (UAV) (i.e. drones), providing wide-view snapshots
    of the agricultural environments. It has several advantages when applied to agriculture,
    being a well-known, non-destructive method to collect information about earth
    features while data may be obtained systematically over large geographical areas.
    A large subset of the volume of data collected through remote sensing involve
    images. Images constitute, in many cases, a complete picture of the agricultural
    environments and could address a variety of challenges (Liaghat and Balasundram,
    2010, Ozdogan et al., 2010). Hence, imaging analysis is an important research
    area in the agricultural domain and intelligent data analysis techniques are being
    used for image identification/classification, anomaly detection etc., in various
    agricultural applications (Teke et al., 2013, Saxena and Armstrong, 2014, Singh
    et al., 2016). The most popular techniques and applications are presented in Appendix
    A, together with the sensing methods employed to acquire the images. From existing
    sensing methods, the most common one is satellite-based, using multi-spectral
    and hyperspectral imaging. Synthetic aperture radar (SAR), thermal and near infrared
    (NIR) cameras are being used in a lesser but increasing extent (Ishimwe et al.,
    2014), while optical and X-ray imaging are being applied in fruit and packaged
    food grading. The most popular techniques used for analyzing images include machine
    learning (ML) (K-means, support vector machines (SVM), artificial neural networks
    (ANN) amongst others), linear polarizations, wavelet-based filtering, vegetation
    indices (NDVI) and regression analysis (Saxena and Armstrong, 2014, Singh et al.,
    2016). Besides the aforementioned techniques, a new one which is recently gaining
    momentum is deep learning (DL) (LeCun et al., 2015, LeCun and Bengio, 1995). DL
    belongs to the machine learning computational field and is similar to ANN. However,
    DL is about “deeper” neural networks that provide a hierarchical representation
    of the data by means of various convolutions. This allows larger learning capabilities
    and thus higher performance and precision. A brief description of DL is attempted
    in Section 3. The motivation for preparing this survey stems from the fact that
    DL in agriculture is a recent, modern and promising technique with growing popularity,
    while advancements and applications of DL in other domains indicate its large
    potential. The fact that today there exists at least 40 research efforts employing
    DL to address various agricultural problems with very good results, encouraged
    the authors to prepare this survey. To the authors’ knowledge, this is the first
    such survey in the agricultural domain, while a small number of more general surveys
    do exist (Deng and Yu, 2014, Wan et al., 2014, Najafabadi et al., 2015), covering
    related work in DL in other domains. 2. Methodology The bibliographic analysis
    in the domain under study involved two steps: (a) collection of related work and
    (b) detailed review and analysis of this work. In the first step, a keyword-based
    search for conference papers or journal articles was performed from the scientific
    databases IEEE Xplore and ScienceDirect, and from the web scientific indexing
    services Web of Science and Google Scholar. As search keywords, we used the following
    query: [“deep learning”] AND [“agriculture” OR ”farming“] In this way, we filtered
    out papers referring to DL but not applied to the agricultural domain. From this
    effort, 47 papers had been initially identified. Restricting the search for papers
    with appropriate application of the DL technique and meaningful findings1, the
    initial number of papers reduced to 40. In the second step, the 40 papers selected
    from the previous step were analyzed one-by-one, considering the following research
    questions: 1. Which was the agricultural- or food-related problem they addressed?
    2. Which was the general approach and type of DL-based models employed? 3. Which
    sources and types of data had been used? 4. Which were the classes and labels
    as modeled by the authors? Were there any variations among them, observed by the
    authors? 5. Any pre-processing of the data or data augmentation techniques used?
    6. Which has been the overall performance depending on the metric adopted? 7.
    Did the authors test the performance of their models on different datasets? 8.
    Did the authors compare their approach with other techniques and, if yes, which
    was the difference in performance? Our main findings are presented in Section
    4 and the detailed information per paper is listed in Appendix B. 3. Deep learning
    DL extends classical ML by adding more “depth” (complexity) into the model as
    well as transforming the data using various functions that allow data representation
    in a hierarchical way, through several levels of abstraction (Schmidhuber, 2015,
    LeCun and Bengio, 1995). A strong advantage of DL is feature learning, i.e. the
    automatic feature extraction from raw data, with features from higher levels of
    the hierarchy being formed by the composition of lower level features (LeCun et
    al., 2015). DL can solve more complex problems particularly well and fast, because
    of more complex models used, which allow massive parallelization (Pan and Yang,
    2010). These complex models employed in DL can increase classification accuracy
    or reduce error in regression problems, provided there are adequately large datasets
    available describing the problem. DL consists of various different components
    (e.g. convolutions, pooling layers, fully connected layers, gates, memory cells,
    activation functions, encode/decode schemes etc.), depending on the network architecture
    used (i.e. Unsupervised Pre-trained Networks, Convolutional Neural Networks, Recurrent
    Neural Networks, Recursive Neural Networks). The highly hierarchical structure
    and large learning capacity of DL models allow them to perform classification
    and predictions particularly well, being flexible and adaptable for a wide variety
    of highly complex (from a data analysis perspective) challenges (Pan and Yang,
    2010). Although DL has met popularity in numerous applications dealing with raster-based
    data (e.g. video, images), it can be applied to any form of data, such as audio,
    speech, and natural language, or more generally to continuous or point data such
    as weather data (Sehgal et al., 2017), soil chemistry (Song et al., 2016) and
    population data (Demmers et al., 2012). An example DL architecture is displayed
    in Fig. 1, illustrating CaffeNet (Jia et al., 2014), an example of a convolutional
    neural network, combining convolutional and fully connected (dense) layers. Download
    : Download high-res image (101KB) Download : Download full-size image Fig. 1.
    CaffeNet, an example CNN architecture. Source: Sladojevic et al. (2016). Convolutional
    Neural Networks (CNN) constitute a class of deep, feed-forward ANN, and they appear
    in numerous of the surveyed papers as the technique used (17 papers, 42%). As
    the figure shows, various convolutions are performed at some layers of the network,
    creating different representations of the learning dataset, starting from more
    general ones at the first larger layers, becoming more specific at the deeper
    layers. The convolutional layers act as feature extractors from the input images
    whose dimensionality is then reduced by the pooling layers. The convolutional
    layers encode multiple lower-level features into more discriminative features,
    in a way that is spatially context-aware. They may be understood as banks of filters
    that transform an input image into another, highlighting specific patterns. The
    fully connected layers, placed in many cases near the output of the model, act
    as classifiers exploiting the high-level features learned to classify input images
    in predefined classes or to make numerical predictions. They take a vector as
    input and produce another vector as output. An example visualization of leaf images
    after each processing step of the CaffeNet CNN, at a problem of identifying plant
    diseases, is depicted in Fig. 2. We can observe that after each processing step,
    the particular elements of the image that reveal the indication of a disease become
    more evident, especially at the final step (Pool5). Download : Download high-res
    image (236KB) Download : Download full-size image Fig. 2. Visualization of the
    output layers images after each processing step of the CaffeNet CNN (i.e. convolution,
    pooling, normalization) at a plant disease identification problem based on leaf
    images. Source: Sladojevic et al. (2016). One of the most important advantages
    of using DL in image processing is the reduced need of feature engineering (FE).
    Previously, traditional approaches for image classification tasks had been based
    on hand-engineered features, whose performance affected heavily the overall results.
    FE is a complex, time-consuming process which needs to be altered whenever the
    problem or the dataset changes. Thus, FE constitutes an expensive effort that
    depends on experts’ knowledge and does not generalize well (Amara et al., 2017).
    On the other hand, DL does not require FE, locating the important features itself
    through training. A disadvantage of DL is the generally longer training time.
    However, testing time is generally faster than other methods ML-based methods
    (Chen et al., 2014). Other disadvantages include problems that might occur when
    using pre-trained models on datasets that are small or significantly different,
    optimization issues because of the models’ complexity, as well as hardware restrictions.
    In Section 5, we discuss over advantages and disadvantages of DL as they reveal
    through the surveyed papers. 3.1. Available architectures, datasets and tools
    There exist various successful and popular architectures, which researchers may
    use to start building their models instead of starting from scratch. These include
    AlexNet (Krizhevsky et al., 2012), CaffeNet (Jia et al., 2014) (displayed in Fig.
    1), VGG (Simonyan and Zisserman, 2014), GoogleNet (Szegedy et al., 2015) and Inception-ResNet
    (Szegedy et al., 2017), among others. Each architecture has different advantages
    and scenarios where it is more appropriate to be used (Canziani et al., 2016).
    It is also worth noting that almost all of the aforementioned models come along
    with their weights pre-trained, which means that their network had been already
    trained by some dataset and has thus learned to provide accurate classification
    for some particular problem domain (Pan and Yang, 2010). Common datasets used
    for pre-training DL architectures include ImageNet (Deng et al., 2009) and PASCAL
    VOC (PASCAL VOC Project, 2012) (see also Appendix C). Moreover, there exist various
    tools and platforms allowing researchers to experiment with DL (Bahrampour et
    al., 2015). The most popular ones are Theano, TensorFlow, Keras (which is an application
    programmer''s interface on top of Theano and TensorFlow), Caffe, PyTorch, TFLearn,
    Pylearn2 and the Deep Learning Matlab Toolbox. Some of these tools (i.e. Theano,
    Caffe) incorporate popular architectures such as the ones mentioned above (i.e.
    AlexNet, VGG, GoogleNet), either as libraries or classes. For a more elaborate
    description of the DL concept and its applications, the reader could refer to
    existing bibliography (Schmidhuber, 2015, Deng and Yu, 2014, Wan et al., 2014,
    Najafabadi et al., 2015, Canziani et al., 2016, Bahrampour et al., 2015). 4. Deep
    learning applications in agriculture In Appendix B, we list the 40 identified
    relevant works, indicating the agricultural-related research area, the particular
    problem they address, DL models and architectures implemented, sources of data
    used, classes and labels of the data, data pre-processing and/or augmentation
    employed, overall performance achieved according to the metrics adopted, as well
    as comparisons with other techniques, wherever available. 4.1. Areas of use Sixteen
    areas have been identified in total, with the popular ones being identification
    of weeds (5 papers), land cover classification (4 papers), plant recognition (4
    papers), fruits counting (4 papers) and crop type classification (4 papers). It
    is remarkable that all papers, except from Demmers et al., 2010, Demmers et al.,
    2012, Chen et al., 2014, were published during or after 2015, indicating how recent
    and modern this technique is, in the domain of agriculture. More precisely, from
    the remaining 37 papers, 15 papers have been published in 2017, 15 in 2016 and
    7 in 2015. The large majority of the papers deal with image classification and
    identification of areas of interest, including detection of obstacles (e.g. (Steen
    et al., 2016, Christiansen et al., 2016)) and fruit counting (e.g. (Rahnemoonfar
    and Sheppard, 2017, Sa et al., 2016)). Some papers focus on predicting future
    parameters, such as corn yield (Kuwata and Shibasaki, 2015) soil moisture content
    at the field (Song et al., 2016) and weather conditions (Sehgal et al., 2017).
    From another perspective, most papers (20) target crops, while few works consider
    issues such as weed detection (8 papers), land cover (4 papers), research on soil
    (2 papers), livestock agriculture (3 papers), obstacle detection (3 papers) and
    weather prediction (1 paper). 4.2. Data sources Observing the sources of data
    used to train the DL model at every paper, large datasets of images are mainly
    used, containing thousands of images in some cases, either real ones (e.g. (Mohanty
    et al., 2016, Reyes et al., 2015, Dyrmann et al., 2016a)), or synthetic produced
    by the authors (Rahnemoonfar and Sheppard, 2017, Dyrmann et al., 2016b). Some
    datasets originate from well-known and publicly-available datasets such as PlantVillage,
    LifeCLEF, MalayaKew, UC Merced and Flavia (see Appendix C), while others constitute
    sets of real images collected by the authors for their research needs (e.g. (Sladojevic
    et al., 2016, Bargoti and Underwood, 2016, Xinshao and Cheng, 2015, Sørensen et
    al., 2017)). Papers dealing with land cover, crop type classification and yield
    estimation, as well as some papers related to weed detection employ a smaller
    number of images (e.g. tens of images), produced by UAV (Lu et al., 2017, Rebetez
    et al., 2016, Milioto et al., 2017), airborne (Chen et al., 2014, Luus et al.,
    2015) or satellite-based remote sensing (Kussul et al., 2017, Minh et al., 2017,
    Ienco et al., 2017, Rußwurm and Körner, 2017). A particular paper investigating
    segmentation of root and soil uses images from X-ray tomography (Douarre et al.,
    2016). Moreover, some papers use text data, collected either from repositories
    (Kuwata and Shibasaki, 2015, Sehgal et al., 2017) or field sensors (Song et al.,
    2016, Demmers et al., 2010, Demmers et al., 2012). In general, the more complicated
    the problem to be solved, the more data is required. For example, problems involving
    large number of classes to identify (Mohanty et al., 2016, Reyes et al., 2015,
    Xinshao and Cheng, 2015) and/or small Variation among the classes (Luus et al.,
    2015, Rußwurm and Körner, 2017, Yalcin, 2017, Namin et al., 2017, Xinshao and
    Cheng, 2015), require large number of input images to train their models. 4.3.
    Data variation Variation between classes is necessary for the DL models to be
    able to differentiate features and characteristics, and perform accurate classifications.2
    Hence, accuracy is positively correlated with variation among classes. Nineteen
    papers (47%) revealed some aspects of poor data variation. Luus et al. (2015)
    observed high relevance between some land cover classes (i.e. medium density and
    dense residential, buildings and storage tanks) while Ienco et al. (2017) found
    that tree crops, summer crops and truck farming were classes highly mixed. A confusion
    between maize and soybeans was evident in Kussul et al. (2017) and variation was
    low in botanically related crops, such as meadow, fallow, triticale, wheat, and
    rye (Rußwurm and Körner, 2017). Moreover, some particular views of the plants
    (i.e. flowers and leaf scans) offer different classification accuracy than branches,
    stems and photos of the entire plant. A serious issue in plant phenology recognition
    is the fact that appearances change very gradually and it is challenging to distinguish
    images falling into the growing durations that are in the middle of two successive
    stages (Yalcin, 2017, Namin et al., 2017). A similar issue appears when assessing
    the quality of vegetative development (Minh et al., 2017). Furthermore, in the
    challenging problem of fruit counting, the models suffer from high occlusion,
    depth variation, and uncontrolled illumination, including high color similarity
    between fruit/foliage (Chen et al., 2017, Bargoti and Underwood, 2016). Finally,
    identification of weeds faces issues with respect to lighting, resolution, and
    soil type, and small variation between weeds and crops in shape, texture, color
    and position (i.e. overlapping) (Dyrmann et al., 2016a, Xinshao and Cheng, 2015,
    Dyrmann et al., 2017). In the large majority of the papers mentioned above (except
    from Minh et al. (2017)), this low variation has affected classification accuracy
    significantly, i.e. more than 5%. 4.4. Data pre-processing The large majority
    of related work (36 papers, 90%) involved some image pre-processing steps, before
    the image or particular characteristics/features/statistics of the image were
    fed as an input to the DL model. The most common pre-processing procedure was
    image resize (16 papers), in most cases to a smaller size, in order to adapt to
    the requirements of the DL model. Sizes of 256 × 256, 128 × 128, 96 × 96 and 60 × 60
    pixels were common. Image segmentation was also a popular practice (12 papers),
    either to increase the size of the dataset (Ienco et al., 2017, Rebetez et al.,
    2016, Yalcin, 2017) or to facilitate the learning process by highlighting regions
    of interest (Sladojevic et al., 2016, Mohanty et al., 2016, Grinblat et al., 2016,
    Sa et al., 2016, Dyrmann et al., 2016a, Potena et al., 2016) or to enable easier
    data annotation by experts and volunteers (Chen et al., 2017, Bargoti and Underwood,
    2016). Background removal (Mohanty et al., 2016, McCool et al., 2017, Milioto
    et al., 2017), foreground pixel extraction (Lee et al., 2015) or non-green pixels
    removal based on NDVI masks (Dyrmann et al., 2016a, Potena et al., 2016) were
    also performed to reduce the datasets’ overall noise. Other operations involved
    the creation of bounding boxes (Chen et al., 2017, Sa et al., 2016, McCool et
    al., 2017, Milioto et al., 2017) to facilitate detection of weeds or counting
    of fruits. Some datasets were converted to grayscale (Santoni et al., 2015, Amara
    et al., 2017) or to the HSV color model (Luus et al., 2015, Lee et al., 2015).
    Furthermore, some papers used features extracted from the images as input to their
    models, such as shape and statistical features (Hall et al., 2015), histograms
    (Hall et al., 2015, Xinshao and Cheng, 2015, Rebetez et al., 2016), Principal
    Component Analysis (PCA) filters (Xinshao and Cheng, 2015), Wavelet transformations
    (Kuwata and Shibasaki, 2015) and Gray Level Co-occurrence Matrix (GLCM) features
    (Santoni et al., 2015). Satellite or aerial images involved a combination of pre-processing
    steps such as orthorectification (Lu et al., 2017, Minh et al., 2017) calibration
    and terrain correction (Kussul et al., 2017, Minh et al., 2017) and atmospheric
    correction (Rußwurm and Körner, 2017). 4.5. Data augmentation It is worth-mentioning
    that some of the related work under study (15 papers, 37%) employed data augmentation
    techniques (Krizhevsky et al., 2012), to enlarge artificially their number of
    training images. This helps to improve the overall learning procedure and performance,
    and for generalization purposes, by means of feeding the model with varied data.
    This augmentation process is important for papers that possess only small datasets
    to train their DL models, such as (Bargoti and Underwood, 2016, Sladojevic et
    al., 2016, Sørensen et al., 2017, Mortensen et al., 2016, Namin et al., 2017,
    Chen et al., 2017). This process was especially important in papers where the
    authors trained their models using synthetic images and tested them on real ones
    (Rahnemoonfar and Sheppard, 2017, Dyrmann et al., 2016b). In this case, data augmentation
    allowed their models to generalize and be able to adapt to the real-world problems
    more easily. Transformations are label-preserving, and included rotations (12
    papers), dataset partitioning/cropping (3 papers), scaling (3 papers), transposing
    (Sørensen et al., 2017), mirroring (Dyrmann et al., 2016a), translations and perspective
    transform (Sladojevic et al., 2016), adaptations of objects’ intensity in an object
    detection problem (Steen et al., 2016) and a PCA augmentation technique (Bargoti
    and Underwood, 2016). Papers involving simulated data performed additional augmentation
    techniques such as varying the HSV channels and adding random shadows (Dyrmann
    et al., 2016b) or adding simulated roots to soil images (Douarre et al., 2016).
    4.6. Technical details From a technical side, almost half of the research works
    (17 papers, 42%) employed popular CNN architectures such as AlexNet, VGG16 and
    Inception-ResNet. From the rest, 14 papers developed their own CNN models, 2 papers
    adopted a first-order Differential Recurrent Neural Networks (DRNN) model, 5 papers
    preferred to use a Long Short-Term Memory (LSTM) model (Gers et al., 2000), one
    paper used deep belief networks (DBN) and one paper employed a hybrid of PCA with
    auto-encoders (AE). Some of the CNN approaches combined their model with a classifier
    at the output layer, such as logistic regression (Chen et al., 2014), Scalable
    Vector Machines (SVM) (Douarre et al., 2016), linear regression (Chen et al.,
    2017), Large Margin Classifiers (LCM) (Xinshao and Cheng, 2015) and macroscopic
    cellular automata (Song et al., 2016). Regarding the frameworks used, all the
    works that employed some well-known CNN architecture had also used a DL framework,
    with Caffe being the most popular (13 papers, 32%), followed by Tensor Flow (2
    papers) and deeplearning4j (1 paper). Ten research works developed their own software,
    while some authors decided to build their own models on top of Caffe (5 papers),
    Keras/Theano (5 papers), Keras/TensorFlow (4 papers), Pylearn2 (1 paper), MatConvNet
    (1 paper) and Deep Learning Matlab Toolbox (1 paper). A possible reason for the
    wide use of Caffe is that it incorporates various CNN frameworks and datasets,
    which can be used then easily and automatically by its users. Most of the studies
    divided their dataset between training and testing/verification data using a ratio
    of 80–20 or 90–10 respectively. In addition, various learning rates have been
    recorded, from 0.001 (Amara et al., 2017) and 0.005 (Mohanty et al., 2016) up
    to 0.01 (Grinblat et al., 2016). Learning rate is about how quickly a network
    learns. Higher values help avoid the solver being stuck in local minima, which
    can reduce performance significantly. A general approach used by many of the evaluated
    papers is to start out with a high learning rate and lower it as the training
    goes on. We note that learning rate is very dependent on the network architecture.
    Moreover, most of the research works that incorporated popular DL architectures
    took advantage of transfer learning (Pan and Yang, 2010), which concerns leveraging
    the already existing knowledge of some related task or domain in order to increase
    the learning efficiency of the problem under study by fine-tuning pre-trained
    models. As sometimes it is not possible to train a network from scratch due to
    having a small training data set or having a complex multi-task network, it is
    required that the network be at least partially initialized with weights from
    another pre-trained model. A common transfer learning technique is the use of
    pre-trained CNN, which are CNN models that have been already trained on some relevant
    dataset with possibly different number of classes. These models are then adapted
    to the particular challenge and dataset. This method was followed (among others)
    in Lu et al., 2017, Douarre et al., 2016, Reyes et al., 2015, Bargoti and Underwood,
    2016, Steen et al., 2016, Lee et al., 2015, Sa et al., 2016, Mohanty et al., 2016,
    Christiansen et al., 2016, Sørensen et al., 2017, for the VGG16, DenseNet, AlexNet
    and GoogleNet architectures. 4.7. Outputs Finally, concerning the 31 papers that
    involved classification, the classes as used by the authors ranged from 2 (Lu
    et al., 2017, Pound et al., 2016, Douarre et al., 2016, Milioto et al., 2017)
    up to 1000 (Reyes et al., 2015). A large number of classes was observed in Luus
    et al. (2015) (21 land-use classes) (Rebetez et al., 2016) (22 different crops
    plus soil) (Lee et al., 2015) (44 plant species) and (Xinshao and Cheng, 2015)
    (91 classes of common weeds found in agricultural fields). In these papers, the
    number of outputs of the model was equal to the number of classes respectively.
    Each output was a different probability for the input image, segment, blob or
    pixel to belong to each class, and then the model picked the highest probability
    as its predicted class. From the rest 9 papers, 2 performed predictions of fruits
    counted (scalar value as output) (Rahnemoonfar and Sheppard, 2017, Chen et al.,
    2017), 2 identified regions of fruits in the image (multiple bounding boxes) (Bargoti
    and Underwood, 2016, Sa et al., 2016), 2 predicted animal growth (scalar value)
    (Demmers et al., 2010, Demmers et al., 2012), one predicted weather conditions
    (scalar value) (Sehgal et al., 2017), one crop yield index (scalar value) (Kuwata
    and Shibasaki, 2015) and one paper predicted percentage of soil moisture content
    (scalar value) (Song et al., 2016). 4.8. Performance metrics Regarding methods
    used to evaluate performance, various metrics have been employed by the authors,
    each being specific to the model used at each study. Table 1 lists these metrics,
    together with their definition/description, and the symbol we use to refer to
    them in this survey. In some papers where the authors referred to accuracy without
    specifying its definition, we assumed they referred to classification accuracy
    (CA, first metric listed in Table 1). From this point onwards, we refer to “DL
    performance” as its score in some performance metric from the ones listed in Table
    1. Table 1. Performance metrics used in related work under study. No. Performance
    Metric Symbol Used Description 1. Classification Accuracy CA The percentage of
    correct predictions where the top class (the one having the highest probability),
    as indicated by the DL model, is the same as the target label as annotated beforehand
    by the authors. For multi-class classification problems, CA is averaged among
    all the classes. CA is mentioned as Rank-1 identification rate in (Hall et al.,
    2015) 2. Precision P The fraction of true positives (TP, correct predictions)
    from the total amount of relevant results, i.e. the sum of TP and false positives
    (FP). For multi-class classification problems, P is averaged among the classes.
    P = TP/(TP + FP) 3. Recall R The fraction of TP from the total amount of TP and
    false negatives (FN). For multi-class classification problems, R gets averaged
    among all the classes. R = TP/(TP + FN) 4. F1 score F1 The harmonic mean of precision
    and recall. For multi-class classification problems, F1 gets averaged among all
    the classes. It is mentioned as F-measure in (Minh et al., 2017). F1 = 2 * (TP * FP)/(TP + FP)
    5. LifeCLEF metric LC A scorea related to the rank of the correct species in the
    list of retrieved species 6. Quality Measure QM Obtained by multiplying sensitivity
    (proportion of pixels that were detected correctly) and specificity (which proportion
    of detected pixels are truly correct). QM = TP2/((TP + FP)(TP + FN)) 7. Mean Square
    Error MSE Mean of the square of the errors between predicted and observed values
    8. Root Mean Square Error RMSE Standard deviation of the differences between predicted
    values and observed values. A normalized RMSE (N-RMSE) has been used in (Sehgal
    et al., 2017) 9. Mean Relative Error MRE The mean error between predicted and
    observed values, in percentage 10. Ratio of total fruits counted RFC Ratio of
    the predicted count of fruits by the model, with the actual count. The actual
    count was attained by taking the average count of individuals (i.e. experts or
    volunteers) observing the images independently 11. L2 error L2 Root of the squares
    of the sums of the differences between predicted counts of fruits by the model
    and the actual counts 12. Intersection over Union IoU A metric that evaluates
    predicted bounding boxes, by dividing the area of overlap between the predicted
    and the ground truth boxes, by the area of their union. An average (Dyrmann et
    al., 2016b) or frequency weighted (Mortensen et al., 2016) IoU can be calculated
    13. CA-IoU, F1-IoU, P-IoU or R-IoU CA-IoU F1-IoU P-IoU R-IoU These are the same
    CA, F1, P and R metrics as defined above, combined with IoU in order to consider
    true/false positives/negatives. Used in problems involving bounding boxes. This
    is done by putting a minimum threshold on IoU, i.e. any value above this threshold
    would be considered as positive by the metric (and the model involved). Thresholds
    of 20% (Bargoti and Underwood, 2016), 40% (Sa et al., 2016) and 50% (Steen et
    al., 2016, Christiansen et al., 2016, Dyrmann et al., 2017) have been observedb
    a LifeCLEF 2015 Challenge. http://www.imageclef.org/lifeclef/2015/plant. b In
    Appendix B, where we list the values of the metrics used at each paper, we denote
    CA-IoU(x), F1-IoU(x), P-IoU(x) or R-IoU(x), where x is the threshold (in percentage),
    over which results are considered as positive by the DL model employed. CA was
    the most popular metric used (24 papers, 60%), followed by F1 (10 papers, 25%).
    Some papers included RMSE (4 papers), IoU (3 papers), RFC (Chen et al., 2017,
    Rahnemoonfar and Sheppard, 2017) or others. Some works used a combination of metrics
    to evaluate their efforts. We note that some papers employing CA, F1, P or R,
    used IoU in order to consider a model’s prediction (Bargoti and Underwood, 2016,
    Sa et al., 2016, Steen et al., 2016, Christiansen et al., 2016, Dyrmann et al.,
    2017). In these cases, a minimum threshold was put on IoU, and any value above
    this threshold would be considered as positive by the model. We note that in some
    cases, a trade-off can exist between metrics. For example, in a weed detection
    problem (Milioto et al., 2017), it might be desirable to have a high R to eliminate
    most weeds, but not eliminating crops is of a critical importance, hence a lower
    P might be acceptable. 4.9. Overall performance We note that it is difficult if
    not impossible to compare between papers, as different metrics are employed for
    different tasks, considering different models, datasets and parameters. Hence,
    the reader should consider our comments in this section with some caution. In
    19 out of the 24 papers that involved CA as a metric, accuracy was high (i.e.
    above 90%), indicating good performance. The highest CA has been observed in the
    works of Hall et al., 2015, Pound et al., 2016, Chen et al., 2014, Lee et al.,
    2015, Minh et al., 2017, Potena et al., 2016, Steen et al., 2016, with values
    of 98% or more, constituting remarkable results. From the 10 papers using F1 as
    metric, 5 had values higher than 0.90 with the highest F1 observed in Mohanty
    et al., 2016, Minh et al., 2017 with values higher than 0.99. The works of Dyrmann
    et al., 2016a, Rußwurm and Körner, 2017, Ienco et al., 2017, Mortensen et al.,
    2016, Rebetez et al., 2016, Christiansen et al., 2016, Yalcin, 2017 were among
    the ones with the lowest CA (i.e. 73–79%) and/or F1 scores (i.e. 0.558–0.746),
    however state of the art work in these particular problems has shown lower CA
    (i.e. SVM, RF, Naïve- Bayes classifier). Particularly in Rußwurm and Körner (2017),
    the three-unit LSTM model employed provided 16.3% better CA than a CNN, which
    belongs to the family of DL. Besides, the above can be considered as “harder”
    problems, because of the use of satellite data (Ienco et al., 2017, Rußwurm and
    Körner, 2017) large number of classes (Dyrmann et al., 2016a, Rußwurm and Körner,
    2017, Rebetez et al., 2016), small training datasets (Mortensen et al., 2016,
    Christiansen et al., 2016) or very low variation among the classes (Yalcin, 2017,
    Dyrmann et al., 2016a, Rebetez et al., 2016). 4.10. Generalizations on different
    datasets It is important to examine whether the authors had tested their implementations
    on the same dataset (e.g. by dividing the dataset into training and testing/validation
    sets) or used different datasets to test their solution. From the 40 papers, only
    8 (20%) used different datasets for testing than the one for training. From these,
    2 approaches trained their models by using simulated data and tested on real data
    (Dyrmann et al., 2016b, Rahnemoonfar and Sheppard, 2017) and 2 papers tested their
    models on a dataset produced 2–4 weeks after, with a more advanced growth stage
    of plants and weeds (Milioto et al., 2017, Potena et al., 2016). Moreover, 3 papers
    used different fields for testing than the ones used for training (McCool et al.,
    2017), with a severe degree of occlusion compared to the other training field
    (Dyrmann et al., 2017), or containing other obstacles such as people and animals
    (Steen et al., 2016. Sa et al. (2016) used a different dataset to evaluate whether
    the model can generalize on different fruits. From the other 32 papers, different
    trees were used in training and testing in Chen et al. (2017), while different
    rooms for pigs (Demmers et al., 2012) and chicken (Demmers et al., 2010) were
    considered. Moreover, Hall et al. applied condition variations in testing (i.e.
    translations, scaling, rotations, shading and occlusions) (Hall et al., 2015)
    while scaling for a certain range translation distance and rotation angle was
    performed on the testing dataset in Xinshao and Cheng (2015). The rest 27 papers
    did not perform any changes between the training/testing datasets, a fact that
    lowers the overall confidence for the results presented. Finally, it is interesting
    to observe how these generalizations affected the performance of the models, at
    least in cases where both data from same and different datasets were used in testing.
    In Sa et al. (2016), F1-IoU(40) was higher for the detection of apples (0.938),
    strawberry (0.948), avocado (0.932) and mango (0.942), than in the default case
    of sweet pepper (0.838). In Rahnemoonfar and Sheppard (2017), RFC was 2% less
    in the real images than in the synthetic ones. In Potena et al. (2016), CA was
    37.6% less at the dataset involving plants of 4-weeks more advanced growth. According
    to the authors, the model was trained based on plants that were in their first
    growth stage, thus without their complete morphological features, which were included
    in the testing dataset. Moreover, in Milioto et al. (2017) P was 2% higher at
    the 2-weeks more advanced growth dataset, with 9% lower R. Hence, in the first
    case there was improvement in performance (Sa et al., 2016), and in the last three
    cases a reduction, slight one in Rahnemoonfar and Sheppard, 2017, Milioto et al.,
    2017 but considerable in Potena et al. (2016). From the other papers using different
    testing datasets, as mentioned above, high percentages of CA (94–97.3%), P-IoU
    (86.6%) and low values of MRE (1.8–10%) have been reported. These show that the
    DL models were able to generalize well to different datasets. However, without
    more comparisons, this is only a speculation that can be figured out of the small
    number of observations available. 4.11. Performance comparison with other approaches
    A critical aspect of this survey is to examine how DL performs in relation to
    other existing techniques. The 14th column of Appendix B presents whether the
    authors of related work compared their DL-based approach with other techniques
    used for solving their problem under study. We focus only on comparisons between
    techniques used for the same dataset at the same research paper, with the same
    metric. In almost all cases, the DL models outperform other approaches implemented
    for comparison purposes. CNN show 1–8% higher CA in comparison to SVM (Chen et
    al., 2014, Lee et al., 2015, Grinblat et al., 2016, Pound et al., 2016), 41% improvement
    of CA when compared to ANN (Lee et al., 2015) and 3–8% higher CA when compared
    to RF (Kussul et al., 2017, Minh et al., 2017, McCool et al., 2017, Potena et
    al., 2016, Hall et al., 2015). CNN also seem to be superior than unsupervised
    feature learning with 3–11% higher CA (Luus et al., 2015), 2–44% improved CA in
    relation to local shape and color features (Dyrmann et al., 2016a, Sørensen et
    al., 2017), and 2% better CA (Kussul et al., 2017) or 18% less RMSE (Song et al.,
    2016) compared to multilayer perceptrons. CNN had also superior performance than
    Penalized Discriminant Analysis (Grinblat et al., 2016), SVM Regression (Kuwata
    and Shibasaki, 2015), area-based techniques (Rahnemoonfar and Sheppard, 2017),
    texture-based regression models (Chen et al., 2017), LMC classifiers (Xinshao
    and Cheng, 2015), Gaussian Mixture Models (Santoni et al., 2015) and Naïve-Bayes
    classifiers (Yalcin, 2017). In cases where Recurrent Neural Networks (RNN) (Mandic
    and Chambers, 2001) architectures were employed, the LSTM model had 1% higher
    CA than RF and SVM in Ienco et al. (2017), 44% improved CA than SVM in Rußwurm
    and Körner (2017) and 7–9% better CA than RF and SVM in Minh et al. (2017). In
    only one case, DL showed worse performance against another technique, and this
    was when a CNN was compared to an approach involving local descriptors to represent
    images together with KNN as the classification strategy (20% worse LC) (Reyes
    et al., 2015). 5. Discussion Our analysis has shown that DL offers superior performance
    in the vast majority of related work. When comparing the performance of DL-based
    approaches with other techniques at each paper, it is of paramount importance
    to adhere to the same experimental conditions (i.e. datasets and performance metrics).
    From the related work under study, 28 out of the 40 papers (70%) performed direct,
    valid and correct comparisons among the DL-based approach employed and other state-of-art
    techniques used to solve the particular problem tackled at each paper. Due to
    the fact that each paper involved different datasets, pre-processing techniques,
    metrics, models and parameters, it is difficult if not impossible to generalize
    and perform comparisons between papers. Thus, our comparisons have been strictly
    limited among the techniques used at each paper. Thus, based on these constraints,
    we have observed that DL has outperformed traditional approaches used such as
    SVM, RF, ANN, LMC classifiers and others. It seems that the automatic feature
    extraction performed by DL models is more effective than the feature extraction
    process through traditional approaches such as Scale Invariant Feature Transform
    (SIFT), GLCM, histograms, area-based techniques (ABT), statistics-, texture-,
    color- and shape-based algorithms, conditional random fields to model color and
    visual texture features, local de-correlated channel features and other manual
    feature extraction techniques. This is reinforced by the combined CNN + LSTM model
    employed in Namin et al. (2017), which outperformed a LSTM model which used hand
    crafted feature descriptors as inputs by 25% higher CA. Interesting attempts to
    combine hand-crafted features and CNN-based features were performed in Hall et
    al., 2015, Rebetez et al., 2016. Although DL has been associated with computer
    vision and image analysis (which is also the general case in this survey), we
    have observed 5 related works where DL-based models have been trained based on
    field sensory data (Kuwata and Shibasaki, 2015, Sehgal et al., 2017) and a combination
    of static and dynamic environmental variables (Song et al., 2016, Demmers et al.,
    2010, Demmers et al., 2012). These papers indicate the potential of DL to be applied
    in a wide variety of agricultural problems, not only those involving images. Examining
    agricultural areas where DL techniques have been applied, leaf classification,
    leaf and plant disease detection, plant recognition and fruit counting have some
    papers which present very good performance (i.e. CA > 95%, F1 > 0.92 or RFC > 0.9).
    This is probably because of the availability of datasets in these domains, as
    well as the distinct characteristics of (sick) leaves/plants and fruits in the
    image. On the other hand, some papers in land cover classification, crop type
    classification, plant phenology recognition and weed detection showed average
    performance (i.e. CA < 87% or F1 < 0.8). This could be due to leaf occlusion in
    weed detection, use of noise-prone satellite imagery in land cover problems, crops
    with low variation and botanical relationship or the fact that appearances change
    very gradually while plants grow in phenology recognition efforts. Without underestimating
    the quality of any of the surveyed papers, we highlight some that claim high performance
    (CA > 91%, F1-IoU(20) > 0.90 or RFC > 0.91), considering the complexity of the
    problem in terms of its definition or the large number of classes involved (more
    than 21 classes). These papers are the following: (Mohanty et al., 2016, Luus
    et al., 2015, Lee et al., 2015, Rahnemoonfar and Sheppard, 2017, Chen et al.,
    2017, Bargoti and Underwood, 2016, Xinshao and Cheng, 2015, Hall et al., 2015).
    We also highlight papers that trained their models on simulated data, and tested
    them on real data, which are (Dyrmann et al., 2016b, Rahnemoonfar and Sheppard,
    2017, Douarre et al., 2016). These works constitute important efforts in the DL
    community, as they attempt to solve the problem of inexistent or not large enough
    datasets in various problems. Finally, as discussed in Section 4.10, most authors
    used the same datasets for training and testing their implementation, a fact that
    lowers the confidence in the overall findings, although there have been indications
    that the models seem to generalize well, with only small reductions in performance.
    5.1. Advanced deep learning applications Although the majority of papers used
    typical CNN architectures to perform classification (23 papers, 57%), some authors
    experimented with more advanced models in order to solve more complex problems,
    such as crop type classification from UAV imagery (CNN + HistNN using RGB histograms)
    (Rebetez et al., 2016), estimating number of tomato fruits (Modified Inception-ResNet
    CNN) (Rahnemoonfar and Sheppard, 2017) and estimating number of orange or apple
    fruits (CNN adapted for blob detection and counting + Linear Regression) (Chen
    et al., 2017). Particularly interesting were the approaches employing the Faster
    Region-based CNN + VGG16 model (Bargoti and Underwood, 2016, Sa et al., 2016),
    in order not only to count fruits and vegetables, but also to locate their placement
    in the image by means of bounding boxes. Similarly, the work in (Dyrmann et al.,
    2017) used the DetectNet CNN to detect bounding boxes of weed instances in images
    of cereal fields. These approaches (Faster Region-based CNN, DetectNet CNN) constitute
    a very promising research direction, since the task of identifying the bounding
    box of fruits/vegetables/weeds in an image has numerous real-life applications
    and could solve various agricultural problems Moreover, considering not only space
    but also time series, some authors employed RNN-based models in land cover classification
    (one-unit LSTM model + SVM) (Ienco et al., 2017), crop type classification (three-unit
    LSTM) (Rußwurm and Körner, 2017), classification of different accessions of Arabidopsis
    thaliana based on successive top-view images (CNN + LSTM) (Namin et al., 2017),
    mapping winter vegetation quality coverage (Five-unit LSTM, Gated Recurrent Unit)
    (Minh et al., 2017), estimating the weight of pigs or chickens (DRNN) (Demmers
    et al., 2010, Demmers et al., 2012) and for predicting weather based on previous
    year’s conditions (LSTM) (Sehgal et al., 2017). RNN-based models offer higher
    performance, as they can capture the time dimension, which is impossible to be
    exploited by simple CNN. RNN architectures tend to exhibit dynamic temporal behavior,
    being able to record long-short temporal dependencies, remembering and forgetting
    after some time or when needed (i.e. LSTM). Differences in performance between
    RNN and CNN are distinct in the related work under study, as shown in Table 2.
    This 16% improvement in CA could be attributed to the additional information provided
    by the time series. For example, in the crop type classification case (Rußwurm
    and Körner, 2017), the authors mention, “crops change their spectral characteristics
    due to environmental influences and can thus not be monitored effectively with
    classical mono-temporal approaches. Performance of temporal models increases at
    the beginning of vegetation period”. LSTM-based approaches work well also for
    low represented and difficult classes, as demonstrated in Ienco et al. (2017).
    Table 2. Difference in performance between CNN and RNN. No. Application in Agriculture
    Performance Metric Difference in Performance Reference 1. Crop type classification
    considering time series CA, F1 Three-unit LSTM: 76.2% (CA), 0.558 (F1) CNN: 59.9%
    (CA), 0.236 (F1) Rußwurm and Körner (2017) 2. Classify the phenotyping of Arabidopsis
    in four accessions CA CNN + LSTM: 93% CNN: 76.8% Namin et al. (2017) Finally,
    the critical aspect of fast processing of DL models in order to be easily used
    in robots for real-time decision making (e.g. detection of weeds) was examined
    in McCool et al. (2017), and it is worth-mentioning. The authors have showed that
    a lightweight implementation had only a small penalty in CA (3.90%), being much
    faster (i.e. processing of 40.6 times more pixels per second). They proposed the
    idea of “teacher and student networks”, where the teacher is the more heavy approach
    that helps the student (light implementation) to learn faster and better. 5.2.
    Advantages of deep learning Except from improvements in performance of the classification/prediction
    problems in the surveyed works (see Sections 4.9 Overall performance, 4.11 Performance
    comparison with other approaches), the advantage of DL in terms of reduced effort
    in feature engineering was demonstrated in many of the papers. Hand-engineered
    components require considerable time, an effort that takes place automatically
    in DL. Besides, sometimes manual search for good feature extractors is not an
    easy and obvious task. For example, in the case of estimating crop yield (Kuwata
    and Shibasaki, 2015), extracting manually features that significantly affected
    crop growth was not possible. This was also the case of estimating the soil moisture
    content (Song et al., 2016). Moreover, DL models seem to generalize well. For
    example, in the case of fruit counting, the model learned explicitly to count
    (Rahnemoonfar and Sheppard, 2017). In the banana leaf classification problem (Amara
    et al., 2017), the model was robust under challenging conditions such as illumination,
    complex background, different resolution, size and orientation of the images.
    Also in the fruits counting papers (Chen et al., 2017, Rahnemoonfar and Sheppard,
    2017), the models were robust to occlusion, variation, illumination and scale.
    The same detection frameworks could be used for a variety of circular fruits such
    as peaches, citrus, mangoes etc. As another example, a key feature of the DeepAnomaly
    model was the ability to detect unknown objects/anomalies and not just a set of
    predefined objects, exploiting the homogeneous characteristics of an agricultural
    field to detect distant, heavy occluded and unknown objects (Christiansen et al.,
    2016). Moreover, in the 8 papers mentioned in Section 4.10 where different datasets
    were used for testing, the performance of the model was generally high, with only
    small reductions in performance in comparison with the performance when using
    the same dataset for training and testing. Although DL takes longer time to train
    than other traditional approaches (e.g. SVM, RF), its testing time efficiency
    is quite fast. For example, in detecting obstacles and anomaly (Christiansen et
    al., 2016), the model took much longer to train, but after it did, its testing
    time was less than the one of SVM and KNN. Besides, if we take into account the
    time needed to manually design filters and extract features, “the time used on
    annotating images and training the CNN becomes almost negligible” (Sørensen et
    al., 2017). Another advantage of DL is the possibility to develop simulated datasets
    to train the model, which could be properly designed in order to solve real-world
    problems. For example, in the issue of detecting weeds and maize in fields (Dyrmann
    et al., 2016b), the authors overcame the plant foliage overlapping problem by
    simulating top-down images of overlapping plants on soil background. The trained
    network was then capable of distinguish weeds from maize even in overlapping conditions.
    5.3. Disadvantages and limitations of deep learning A considerable drawback and
    barrier in the use of DL is the need of large datasets, which would serve as the
    input during the training procedure. In spite of data augmentation techniques
    which augment some dataset with label-preserving transformations, in reality at
    least some hundreds of images are required, depending on the complexity of the
    problem under study (i.e. number of classes, precision required etc.). For example,
    the authors in Mohanty et al., 2016, Sa et al., 2016 commented that a more diverse
    set of training data was needed to improve CA. A big problem with many datasets
    is the low variation among the different classes (Yalcin, 2017), as discussed
    in Section 4.3, or the existence of noise, in the form of low resolution, inaccuracy
    of sensory equipment (Song et al., 2016), crops’ occlusions, plants overlapping
    and clustering, and others. As data annotation is a necessary operation in the
    large majority of cases, some tasks are more complex and there is a need for experts
    (who might be difficult to involve) in order to annotate input images. As mentioned
    in Amara et al. (2017), there is a limited availability of resources and expertise
    on banana pathology worldwide. In some cases, experts or volunteers are susceptible
    to errors during data labeling, especially when this is a challenging task e.g.
    fruit count (Chen et al., 2017, Bargoti and Underwood, 2016) or to determine if
    images contain weeds or not (Sørensen et al., 2017, Dyrmann et al., 2017). Another
    limitation is the fact that the DL models can learn some problem particularly
    well, even generalize in some aspects as mentioned in Section 5.2, but they cannot
    generalize beyond the “boundaries of the dataset’s expressiveness”. For example,
    classification of single leaves, facing up, on a homogeneous background is performed
    in Mohanty et al. (2016). A real world application should be able to classify
    images of a disease as it presents itself directly on the plant. Many diseases
    do not present themselves on the upper side of leaves only. As another example,
    plant recognition in Lee et al. (2015) was noticeably affected by environmental
    factors such as wrinkled surface and insect damages. The model for counting tomatoes
    in Rahnemoonfar and Sheppard (2017) could count ripe and half-ripe fruits, however,
    “it failed to count green fruits because it was not trained for this purpose”.
    If an object size in a testing image was significantly less than that of a training
    set, the model missed the detection in Sa et al. (2016). Difficulty in detecting
    heavily occluded and distant objects was observed in Christiansen et al. (2016).
    Occlusion was a serious issue also in Hall et al. (2015). A general issue in computer
    vision, not only in DL, is that data pre-processing is sometimes a necessary and
    time-consuming task, especially when satellite or aerial photos are involved,
    as we saw in Section 4.4. A problem with hyperspectral data is their high dimensionality
    and limited training samples (Chen et al., 2014). Moreover, sometimes the existing
    datasets do not describe completely the problem they target (Song et al., 2016).
    As an example, for estimating corn yield (Kuwata and Shibasaki, 2015), it was
    necessary to consider also external factors other than the weather by inputting
    cultivation information such as fertilization and irrigation. Finally, in the
    domain of agriculture, there do not exist many publicly available datasets for
    researchers to work with, and in many cases, researchers need to develop their
    own sets of images. This could require many hours or days of work. 5.4. Future
    of deep learning in agriculture Observing Appendix A, which lists various existing
    applications of computer vision in agriculture, we can see that only the problems
    of land cover classification, crop type estimation, crop phenology, weed detection
    and fruit grading have been approximated using DL. It is interesting to see how
    DL would behave also in other agricultural-related problems listed in Appendix
    A, such as seeds identification, soil and leaf nitrogen content, irrigation, plants’
    water stress detection, water erosion assessment, pest detection, herbicide use,
    identification of contaminants, diseases or defects on food, crop hail damage
    and greenhouse monitoring. Intuitively, since many of the aforementioned research
    areas employ data analysis techniques (see Appendix A) with similar concepts and
    comparable performance to DL (i.e. linear and logistic regression, SVM, KNN, K-means
    clustering, Wavelet-based filtering, Fourier transform) (Singh et al., 2016),
    then it could be worth to examine the applicability of DL on these problems too.
    Other possible application areas could be the use of aerial imagery (i.e. by means
    of drones) to monitor the effectiveness of the seeding process, to increase the
    quality of wine production by harvesting grapes at the right moment for best maturity
    levels, to monitor animals and their movements to consider their overall welfare
    and identify possible diseases, and many other scenarios where computer vision
    is involved. In spite of the limited availability of open datasets in agriculture,
    In Appendix C, we list some of the most popular, free to download datasets available
    on the web, which could be used by researchers to start testing their DL architectures.
    These datasets could be used to pre-train DL models and then adapt them to more
    specific future agricultural challenges. In addition to these datasets, remote
    sensing data containing multi-temporal, multi-spectral and multi-source images
    that could be used in problems related to land and crop cover classification are
    available from satellites such as MERIS, MODIS, AVHRR, RapidEye, Sentinel, Landsat
    etc. More approaches adopting LSTM or other RNN models are expected in the future,
    exploiting the time dimension to perform higher performance classification or
    prediction. An example application could be to estimate the growth of plants,
    trees or even animals based on previous consecutive observations, to predict their
    yield, assess their water needs or avoid diseases from occurring. These models
    could find applicability in environmental informatics too, for understanding climatic
    change, predicting weather conditions and phenomena, estimating the environmental
    impact of various physical or artificial processes (Kamilaris et al., 2017a) etc.
    Related work under study involved up to a five-unit LSTM model (Minh et al., 2017).
    We expect in the future to see more layers stacked together in order to build
    more complex LSTM architectures (Ienco et al., 2017). We also believe that datasets
    with increasing temporal sequence length will appear, which could improve the
    performance of LSTM (Rußwurm and Körner, 2017). Moreover, more complex architectures
    would appear, combining various DL models and classifiers together, or combining
    hand-crafted features with automatic features extracted by using various techniques,
    fused together to improve the overall outcome, similar to what performed in Hall
    et al., 2015, Rebetez et al., 2016. Researchers are expected to test their models
    using more general and realistic dataset, demonstrating the ability of the models
    to generalize to various real-world situations. A combination of popular performance
    metrics, such as the ones mentioned in Table 1, are essential to be adopted by
    the authors for comparison purposes. It would be desirable if researchers made
    their datasets publicly available, for use also by the general research community.
    Finally, some of the solutions discussed in the surveyed papers could have a commercial
    use in the near future. The approaches incorporating Faster Region-based CNN and
    DetectNet CNN (Bargoti and Underwood, 2016, Chen et al., 2017, Rahnemoonfar and
    Sheppard, 2017) would be extremely useful for automatic robots that collect crops,
    remove weeds or for estimating the expected yields of various crops. A future
    application of this technique could be also in microbiology for human or animal
    cell counting (Chen et al., 2017). The DRNN model controlling the daily feed intake
    of pigs or chicken, predicting quite accurately the required feed intake for the
    whole of the growing period, would be useful to farmers when deciding on a growth
    curve suitable for various scenarios. Following some growth patterns would have
    potential advantages for animal welfare in terms of leg health, without compromising
    the idea animals’ final weight and total feed intake requirement (Demmers et al.,
    2010, Demmers et al., 2012). 6. Conclusion In this paper, we have performed a
    survey of deep learning-based research efforts applied in the agricultural domain.
    We have identified 40 relevant papers, examining the particular area and problem
    they focus on, technical details of the models employed, sources of data used,
    pre-processing tasks and data augmentation techniques adopted, and overall performance
    according to the performance metrics employed by each paper. We have then compared
    deep learning with other existing techniques, in terms of performance. Our findings
    indicate that deep learning offers better performance and outperforms other popular
    image processing techniques. For future work, we plan to apply the general concepts
    and best practices of deep learning, as described through this survey, to other
    areas of agriculture where this modern technique has not yet been adequately used.
    Some of these areas have been identified in the discussion section. Our aim is
    that this survey would motivate more researchers to experiment with deep learning,
    applying it for solving various agricultural problems involving classification
    or prediction, related to computer vision and image analysis, or more generally
    to data analysis. The overall benefits of deep learning are encouraging for its
    further use towards smarter, more sustainable farming and more secure food production.
    Acknowledgments We would like to thank the reviewers, whose valuable feedback,
    suggestions and comments increased significantly the overall quality of this survey.
    This research has been supported by the P-SPHERE project, which has received funding
    from the European Union’s Horizon 2020 research and innovation programme under
    the Marie Skodowska-Curie grant agreement No 665919. Appendix A. Applications
    of computer vision in agriculture and popular techniques used No. Application
    in Agriculture Remote sensing Techniques for data analysis 1. Soil and vegetation/crop
    mapping Hyperspectral imaging (satellite and airborne), multi‐spectral imaging
    (satellite), synthetic aperture radar (SAR) Image fusion, SVM, end-member extraction
    algorithm, co-polarized phase differences (PPD), linear polarizations (HH, VV,
    HV), distance-based classification, decision trees, linear mixing models, logistic
    regression, ANN, NDVI 2. Leaf area index and crop canopy Hyperspectral imaging
    (airborne), multi‐spectral imaging (airborne) Linear regression analysis, NDVI
    3. Crop phenology Satellite remote sensing (general) Wavelet-based filtering,
    Fourier transforms, NDVI 4. Crop height, estimation of yields, fertilizers'' effect
    and biomass Light Detection and Ranging (LIDAR), hyperspectral and multi-spectral
    imaging, SAR, red-edge camera, thermal infrared Linear and exponential regression
    analysis, linear polarizations (VV), wavelet-based filtering, vegetation indices
    (NDVI, ICWSI), ANN 5. Crop monitoring Satellite remote sensing (hyperspectral
    and multi-spectral imaging), NIR camera, SAR Stepwise discriminate analysis (DISCRIM)
    feature extraction, linear regression analysis, co-polarized phase differences
    (PPD), linear polarizations (HH, VV, HV, RR and RL), classification and regression
    tree analysis 6. Identification of seeds and reorganization of species Remote
    sensing in general, cameras and photo-detectors, hyperspectral imaging Principal
    component analysis, feature extraction, linear regression analysis 7. Soil and
    leaf nitrogen content and treatment, salinity detection Hyperspectral and multi-spectral
    imaging, thermal imaging Linear and exponential regression analysis 8. Irrigation
    Satellite remote sensing (hyperspectral and multi-spectral imaging), red-edge
    camera, thermal infrared Image classification techniques (unsupervised clustering,
    density slicing with thresholds), decision trees, linear regression analysis,
    NDVI 9. Plants water stress detection and drought conditions Satellite remote
    sensing (hyperspectral and multi-spectral imaging, radar images), thermal imaging,
    NIR camera, red-edge camera Fraunhofer Line Depth (FLD) principle, linear regression
    analysis, NDVI 10. Water erosion assessment Satellite remote sensing (optical
    and radar images), SAR, NIR camera Interferometric SAR image processing, linear
    and exponential regression analysis, contour tracing, linear polarizations (HH,
    VV) 11. Pest detection and management Hyperspectral and multi-spectral imaging,
    microwave remote sensing, thermal camera Image processing using sample imagery,
    linear and exponential regression analysis, statistical analysis, CEM nonlinear
    signal processing, NDVI 12. Weed detection Remote sensing in general, optical
    cameras and photo-detectors, hyperspectral and multi-spectral imaging Pixel classification
    based on k-means clustering and Bayes classifier, feature extraction techniques
    with FFT and GLCM, wavelet-based classification and Gabor filtering, genetic algorithms,
    fuzzy techniques, artificial neural networks, erosion and dilation segmentation,
    logistic regression, edge detection, color detection, principal component analysis
    13. Herbicide Remote sensing in general, optical cameras and photo-detectors Fuzzy
    techniques, discriminant analysis 14. Fruit grading Optical cameras and photo-detectors,
    monochrome images with different illuminations K-means clustering, image fusion,
    color histogram techniques, machine learning (esp. SVM), Bayesian discriminant
    analysis, Bayes filtering, linear discriminant analysis 15. Packaged food and
    food products – identification of contaminants, diseases or defects, bruise detection
    X-ray imaging (or transmitted light), CCD cameras, monochrome images with different
    illuminations, thermal cameras, multi-spectral and hyperspectral NIR-based imaging
    3D vision, invariance, pattern recognition and image modality, multivariate image
    analysis with principal component analysis, K-mean clustering, SVM, linear discriminant
    analysis, classification trees, K-nearest neighbors, decision trees, fusion, feature
    extraction techniques with FFT, standard Bayesian discriminant analysis, feature
    analysis, color, shape and geometric features using discrimination analysis, pulsed-phase
    thermography 16. Crop hail damage Multi-spectral imaging, polarimetric radar imagery
    Linear and exponential regression analysis, unsupervised image classification
    17. Agricultural expansion and intensification Satellite remote sensing in general
    Wavelet-based filtering 18. Greenhouse monitoring Optical and thermal cameras
    Linear and exponential regression analysis, unsupervised classification, NDVI,
    IR thermography Appendix B. Applications of deep learning in agriculture No. Agri
    Area Problem Description Data Used Classes and Labels Variation among Classes
    DL Model Used FW Used Data Pre-Processing Data augmentation Data for Training
    vs. Testing Performance Metric Used Value of Metric Used Comparison with other
    technique Ref. 1. Leaf classification Classify leaves of different plant species
    Flavia dataset, consisting of 1907 leaf images of 32 species with at least 50
    images per species and at most 77 images. 32 classes: 32 Different plant species
    N/A Author-defined CNN + RF classifier Caffe Feature extraction based on Histograms
    of Curvature over Scale (HoCS), shape and statistical features, use of normalized
    excessive green (NExG) vegetative index, white border doubling image size, segmentation
    N/A Same. (condition variations applied in testing: translations, scaling, rotations,
    shading and occlusions) CA 97.3% ± 0.6% Feature extraction (shape and statistical
    features) and RF classifier (91.2% ± 1.6%) Hall et al. (2015) 2. Leaf disease
    detection 13 different types of plant diseases out of healthy leaves Authors-created
    database containing 4483 images. 15 classes: Plant diseases (13), healthy leaves
    (1) and background images (1) N/A CaffeNet CNN Caffe Cropping, square around the
    leaves to highlight region of interest, resized to 256 × 256 pix, dupl. image
    removal Affine transform (translation, rotation), perspective transform, and image
    rotations. Same CA 96.30% Better results than SVM (no more details) Sladojevic
    et al. (2016) 3. Plant disease detection Identify 14 crop species and 26 diseases
    PlantVillage public dataset of 54,306 images of diseased and healthy plant leaves
    collected under controlled conditions. 38 class labels as crop-disease pairs N/A
    AlexNet, GoogleNet CNNs Caffe Resized to 256 × 256 pix., segmentation, background
    Information removal, fixed color casts N/A Same. Also tested on a dataset of downloaded
    images from Bing Image Search and IPM Images F1 0.9935 Substantial margin in standard
    benchmarks with approaches using hand-engineered features Mohanty et al. (2016)
    4. Classify banana leaves’ diseases Dataset of 3700 images of banana diseases
    obtained from the PlantVillage dataset. 3 classes: healthy, black sigatoka and
    black speckle N/A LeNet CNN deeplearning4j Resized to 60 × 60 pix., converted
    to grayscale N/A Same CA, F1 96+% (CA), 0.968 (F1) Methods using hand-crafted
    features not generalize well Amara et al. (2017) 5. Land cover classification
    Identify 13 different land-cover classes in KSC and 9 different classes in Pavia
    A mixed vegetation site over Kennedy Space Center (KSC), FL, USA (Dataset 1),
    and an urban site over the city of Pavia, Italy (Dataset 2). Hyperspectral datasets.
    13 different land-cover classes (Dataset 1), 9 land cover classes trees (Dataset
    2): Soil, meadow, water, shadows, different materials N/A Hybrid of PCA, autoencoder
    (AE), and logistic regression Developed by the authors Some bands removed due
    to noise N/A Same CA 98.70% 1% more precise than RBF-SVM Chen et al. (2014) 6.
    Identify 21 land-use classes containing a variety of spatial patterns UC Merced
    land-use data set. Aerial ortho-imagery with a 0.3048-m pixel resolution. Dataset
    compiled from a selection of 100 images/class. 21 land-use classes: Agricultural,
    airplane, sports, beach, buildings, residential, forest, freeway, harbor, parking
    lot, river etc. High relevance between medium density and dense residential, as
    well as between buildings and storage tanks Author-defined CNN + multiview model
    averaging Theano From RGB to HSV (hue-saturation-value) color model, resized to
    96 × 96 pix., creation of multiscale views Views flipped horizontally or vertically
    with a probability of 0.5 Same CA 93.48% Unsupervised feature learning (UFL):
    82–90% SIFT: 85% Luus et al. (2015) 7. Extract information about cultivated land
    Images from UAV at the areas Pengzhou County and Guanghan County, Sichuan Province,
    China. 2 classes: Cultivated vs. non-cultivated The cultivated land samples and
    part of forest land samples were easily confused Author-defined CNN N/A Orthorectification,
    image matching, linear land elimination, correct distortion, zoomed to 40 × 40
    pix. N/A Same CA 88–91% N/A Lu et al. (2017) 8. Land cover classification considering
    time series First dataset generated using a time series of Pléiades VHSR images
    at THAU Basin. Second dataset generated from an annual time series of 23 Landsat
    8 images acquired in 2014 above Reunion Island. 11 classes (dataset 1), 9 classes
    (dataset 2). Land cover classes such as trees, crops, forests, water, soils, urban
    areas, grasslands, etc. (Image object or pixel) Tree Crops, Summer crops and Truck
    Farming were classes highly mixed One-unit LSTM + RFF, One-unit LSTM + SVM Keras/Theano
    Multiresolution segmentation technique, feature extraction, pixel-wise multi-temporal
    linear interpolation, various radiometric indices calculated N/A Same CA, F1 First
    Dataset: 75.34% (CA), 0.7463 (F1) Second Dataset: 84.61% (CA), 0.8441 (F1) RF
    and SVM (best of both): First Dataset: 74.20% (CA), 0.7158 (F1) Second Dataset:
    83.82% (CA), 0.8274 (F1) Ienco et al. (2017) 9. Crop type classification Classification
    of crops wheat, maize, soybeans sunflower and sugar beet 19 multi-temporal scenes
    acquired by Landsat-8 and Sentinel-1A RS satellites from a test site in Ukraine.
    11 classes: water, forest, grassland, bare land, wheat, maize, rapeseed, cereals,
    sugar beet, sunflowers and soybeans. General confusion between maize and soybeans
    Author-defined CNN Developed by the authors Calibration, multi-looking, speckle
    filtering (3 × 3 window with Refined Lee algorithm), terrain correction, segmentation,
    restoration of missing data N/A Same CA 94.60% Multilayer perceptron: 92.7%, RF:
    88% Kussul et al. (2017) 10. Classification of crops oil radish, barley, seeded
    grass, weed and stump 36 plots at Foulum Research Center, Denmark containing oil
    radish as a catch crop and amounts of barley, grass, weed and stump. 352 patches
    in total. 7 classes: oil radish, barley, weed, stump, soil, equipment and unknown
    (pixel of the image) Coarse features (radish leafs and soil) were predicted quite
    well. Finer features (barley, grass or stump) not so much. Adapted version of
    VGG16 CNN Developed by the authors Resized to 1600 × 1600 pix. centered on the
    sample areas, division into 400 × 400 pix. patches Rotations 0, 90, 180 and 270
    degrees, flipped diagonally and same set of rotations Same CA, IoU 79% (CA), 0.66
    (IoU) N/A Mortensen et al. (2016) 11. Crop type classification considering time
    series A raster dataset of 26 SENTINEL 2A images, acquired between 2015 19 classes:
    corn, meadow, asparagus, rape, hop, summer oats, winter spelt, fallow, wheat,
    barley, winter rye, beans and others Some classes represent distinct cultivated
    crops, others (such as meadow, fallow, triticale, wheat, and rye) are botanically
    related. Three-unit LSTM TensorFlow Atmospherically corrected N/A Same CA, F1
    76.2% (CA), 0.558 (F1) CNN: 59.9% (CA), 0.236 (F1) Rußwurm and Körner (2017) 2016
    at Munich Germany. Shortwave infrared 1 and 2 bands were selected. SVM: 31.7 (CA),
    84.8% 0.317 (F1) 12. Crop type classification from UAV imagery Aerial images of
    experimental farm fields issued from a series of experiments conducted by the
    Swiss Confederation’s Agroscope research center. 23 classes: 22 different crops
    plus soil (pixel of the image) Lin and Simplex have very similar histograms CNN + HistNN
    (using RGB histograms) Keras Image segmentation N/A Same F1 0.90 (experiment 0),
    0.73 (experiment 1) CNN: 0.83 (experiment 0), 0.70 (experiment 1) HistNN: 0.86
    (experiment 0), 0.71 (experiment 1) Rebetez et al. (2016) 13. Plant recognition
    Recognize 7 views of different plants: entire plant, branch, flower, fruit, leaf,
    stem and scans LifeCLEF 2015 plant dataset, which has 91,759 images distributed
    in 13,887 plant observations. Each observation captures the appearance of the
    plant from various points of view: entire plant, leaf branch, fruit, stem scan,
    flower. 1000 classes: Species that include trees, herbs, and ferns, among others.
    Images of flowers and leaf scans offer higher accuracy than the rest of the views
    AlexNet CNN Caffe N/A N/A Same LC 48.60% 20% worse than local descriptors to represent
    images and KNN, dense SIFT and a Gaussian Mixture Model Reyes et al. (2015) 14.
    Root and shoot feature identification and localisation The first dataset contains
    2500 annotated images of whole root systems. The second hand-annotated 1664 images
    of wheat plants, labeling leaf tips, leaf bases, ear tips, and ear bases. 2 classes:
    Prediction if a root tip is present or not (first dataset) 5 classes: Leaf tips
    and bases, ear tips and bases, and negative (second dataset) N/A Author-defined
    CNN Caffe Image cropping at annotated locations 128 × 128 pix., resized to 64 × 64
    for use in the network N/A Same CA 98.4% (first dataset)97.3% (second dataset)
    Sparse coding approach using SIFT + SVM: 80–90% Pound et al. (2016) 15. Recognize
    44 different plant species MalayaKew (MK) Leaf Dataset which consists of 44 classes,
    collected at the Royal Botanic Gardens, Kew, England. 44 classes: Species such
    as acutissima, macranthera, rubra, robur f. purpurascens etc. N/A AlexNet CNN
    Caffe Foreground pixels extracted using HSV color space, image cropping within
    leaf area Rotation in 7 different orientations Same CA 99.60% SVM: 95.1%, ANN:
    58% Lee et al. (2015) 16. Identify plants from leaf vein patterns of white, soya
    and red beans 866 leaf images provided by INTA Argentina. Dataset divided into
    three classes: 422 images correspond to soybean leaves, 272 to red bean leaves
    and 172 to white bean leaves. 3 classes: Legume species white bean, red bean and
    soybean At soybean, informative regions are in the central vein. For white and
    red bean, outer and smaller veins are also relevant. Author-defined CNN Pylearn2
    Vein segmentation, central patch extraction N/A Same CA 96.90% Penalized Discriminant
    Analysis (PDA): 95.1% SVM and RF slightly worse Grinblat et al. (2016) 17. Plant
    phenology recognition Classify phenological stages of several types of plants
    purely based on the visual data Dataset collected through TARBIL Agro-informatics
    Research Center of ITU, for which over a thousand agrostations are placed throughout
    Turkey. Different images of various plants, at different phenological stages.
    9 classes: Different growth stages of plants, starting from plowing to cropping,
    for the plants wheat, barley, lentil, cotton, pepper and corn. (image segment)
    Appearances change very gradually and it is challenging to distinguish images
    falling into the growing durations that are in the middle of two successive stages.
    Some plants from different classes have similar color and texture distributions
    AlexNet CNN Developed by the authors Image segmentation Images are divided into
    large patches and features are extracted for each patch. 227 × 227 pix. patches
    are carved from the original images Same CA, F1 73.76 – 87.14 (CA), 0.7417 – 0.8728
    (F1) Hand crafted feature descriptors (GLCM and HOG) through a Naïve-Bayes classifier:
    68.97 – 82.41 (CA), 0.6931 – 0.8226 (F1) Yalcin (2017) 18. Classify the phenotyping
    of Arabidopsis in four accessions Dataset composed of sequences of images captured
    from the plants in different days while they grow, successive top-view images
    of different accessions of Arabidopsis thaliana. 4 classes: 4 different accessions
    of Arabidopsis: Genotype states SF-2, CVI, Landsberg (Ler) and Columbia (Col)
    Plants change in size rapidly during their growth, the decomposed images from
    the plant sequences are not sufficiently consistent CNN + LSTM Keras/Theano Camera
    distortion removal, color correction, temporal matching, plant segmentation through
    the GrabCut algorithm Image rotations by 90, 180 and 270 degrees around its center
    Same CA 93% Hand crafted feature descriptors + LSTM: 68% CNN: 76.8% Namin et al.
    (2017) 19. Segmentation of root and soil Identify roots from soils Soil images
    coming from X-ray tomography. 2 classes: Root or soil (pixel of the image) Soil/root
    contrast is sometimes very low Author-defined CNN with SVM for classification
    MatConvNet Image segmentation Simulated roots added to soil images Same QM 0.23
    (simulation) 0.57 (real roots) N/A Douarre et al. (2016) 20. Crop yield estimation
    Estimate corn yield of county level in U.S. Corn yields from 2001 to 2010 in Illinois
    U.S., downloaded from Climate Research Unit (CRU), plus MODIS Enhanced Vegetation
    Index. Crop yield index (scalar value) N/A Author-defined CNN Caffe Enhanced Vegetation
    Index (EVI), hard threshold algorithm, Wavelet transformation for detecting crop
    phenology N/A Same RMSE 6.298 Support Vector Regression (SVR): 8.204 Kuwata and
    Shibasaki (2015) 21. Mapping winter vegetation quality coverage considering time
    series Sentinel-1 dataset including 13 acquisitions in TOPS mode from October
    2016 to February 2017, with a temporal baseline of 12 days. Dual-polarization
    (VV + VH) data in 26 images. 5 classes: Estimations of the quality of vegetative
    development as bare soil, very low, low, average, high “Low” class intersects
    the temporal profiles of all the other classes multiple times. A misclassification
    rate exists between the “low” and “bare soil” classes Five-unit LSTM, Gated Recurrent
    Unit (GRU) Keras/Theano Intensity image gen., radiometrical calibration, temporal
    filtering for noise reduction, orthorectification into map coordinates, transformed
    to logarithm scale, normalized N/A Same CA, F1 99.05% (CA), 0.99 (F1) RF and SVM
    (best of both): 91.77% (CA), 0.9179 (F1) Minh et al. (2017) 22. Fruit counting
    Predict number of tomatoes in the images 24,000 synthetic images produced by the
    authors. Estimated number of tomato fruits (scalar value) N/A Modified Inception-ResNet
    CNN TensorFlow Blurred synthetic images by a Gaussian filter Generated synthetic
    128 × 128 pix. images to train the network, colored circles to simulate background
    and tomato plant/crops. Trained entirely on synthetic data and tested on real
    data RFC, RMSE 91% (RFC) 1.16 (RMSE) on real images, 93% (RFC) 2.52 (RMSE) on
    synthetic images ABT: 66.16% (RFC), 13.56 (RMSE) Rahnemoonfar and Sheppard (2017)
    23. Map from input images of apples and oranges to total fruit counts 71 1280 × 960
    orange images (day time) and 21 1920 × 1200 apple images (night time). Number
    of orange or apple fruits (scalar value) High variation in CA. For orange, dataset
    has high occlusion, depth variation, and uncontrolled illumination. For apples,
    data set has high color similarity between fruit/foliage CNN (blob detection and
    counting) + Linear Regression Caffe Image segmentation for easier data annotation
    by users, creation of bounding boxes around image blobs Training set partitioned
    into 100 randomly cropped and flipped 320 × 240 pix. sub-images Same (but different
    trees used in training and testing) RFC, L2 0.968 (RFC), 13.8 (L2) for oranges
    0.913 (RFC), 10.5 (L2) for apples Best texture-based regression model: 0.682 (RFC)
    Chen et al. (2017) 24. Fruit detection in orchards, including mangoes, almonds
    and apples Images of three fruit varieties: apples (726), almonds (385) and mangoes
    (1154), captured at orchards in Victoria and Queensland, Australia. Sections of
    apples, almonds and mangoes at the image (bounding box) Within class variations
    due to distance to fruit illumination, fruit clustering, and camera view-point.
    Almonds similar in color and texture to the foliage Faster Region-based CNN with
    VGG16 model Caffe Image segmentation for easier data annotation Flip, scale, flip-scale
    and the PCA augmentation technique presented in AlexNet Same F1-IoU (20) 0.904
    (apples) 0.908 (mango) 0.775 (almonds) ZF network: 0.892 (apples) 0.876 (mango)
    0.726 (almonds) Bargoti and Underwood (2016) 25. Detection of sweet pepper and
    rock melon fruits 122 images obtained from two modalities: color (RGB) and Near-Infrared
    (NIR). Sections of sweet red peppers and rock melons on the image (bounding box)
    Variations to camera setup, time and locations of data acquisition. Time for data
    collection is day and night, sites are different. Varied fruit ripeness. Faster
    Region-based CNN with VGG16 model Caffe Early/late fusion techniques for combining
    the classification info from color and NIR imagery, bounding box segmentation,
    pairwise IoU N/A Same (authors demonstrate by using a small dataset that the model
    can generalize) F1-IoU (40) 0.838 Conditional Random Field to model color and
    visual texture features: 0.807 Sa et al. (2016) 26. Obstacle detection Identify
    ISO barrel-shaped obstacles in row crops and grass mowing 437 images from authors''
    experiments and recordings, 1925 positive and 11,550 negative samples. Identify
    if a barrel-shaped object is present in the image (bounding box) N/A AlexNet CNN
    Caffe Resized to 114 × 114 pix., bounding boxes of the object created Various
    rotations at 13 scales, intensity of the object adapted Testing in different fields
    (row crops, grass mowing), containing other obstacles (people and animals) CA-IoU
    (50) 99.9% in row crops and 90.8% in grass mowing N/A Steen et al. (2016) 27.
    Detect obstacles that are distant, heavily occluded and unknown Background data
    of 48 images and test data of 48 images from annotations of humans, houses, barrels,
    wells and mannequins. Classify each pixel as either foreground (contains a human)
    or background (anomaly detection) N/A AlexNet and VGG CNNs Caffe Image cropping,
    resized by a factor of 0.75 N/A Same F1-IoU (50) 0.72 Local de-correlated channel
    features: 0.113 Christiansen et al. (2016) 28. Identification of weeds Classify
    91 weed seed types Dataset of 3980 images containing 91 types of weed seeds. 91
    classes: Different common weeds found in agricultural fields Similarity between
    some classes is very high (only slight differences in shape, texture, and color)
    PCANet + LMC classifiers Developed by the authors Image filter extraction through
    PCA filters bank, binarization and histograms’ counting N/A Same (also scaling
    for a certain range translation distance and rotation angle CA 90.96% Manual feature
    extraction techniques + LMC classifiers: 64.80% Xinshao and Cheng (2015) 29. Classify
    weed from crop species based on 22 different species in total. Dataset of 10,413
    images, taken mainly from BBCH 12–16 containing 22 weed and crop species at early
    growth stages. 22 classes: Different species of weeds and crops at early growth
    stages e.g. chamomile, knotweed, cranesbill, chickweed and veronica Variations
    with respect to lighting, resolution, and soil type. Some species (Veronica, Field
    Pancy) were very similar and difficult to classify Variation of VGG16 Theano-based
    Lasagne library for Python Green segmentation to detect green pixels, non-green
    pixels removal, padding added to make images square, resized to 128 × 128 pix.
    Image mirroring and rotation in 90 degree increments Same CA 86.2% Local shape
    and color features: 42.5% and 12.2% respectively Dyrmann et al. (2016a) 30. Identify
    thistle in winter wheat and spring barley images 4500 images from 10, 20, 30,
    and 50 m of altitude captured by a Canon PowerShot G15 camera. 2 classes: Whether
    the image contains thistle in winter wheat or not (Heatmap of classes is generated
    at the output) Small variations in some images depending on the percentage of
    thistles they contain DenseNet CNN Caffe Image cropping Random flip both horizontally
    and vertically, random transposing Same (extra tests for the case of winter barley)
    CA 97% Color feature-based Thistle-Tool: 95% Sørensen et al. (2017) 31. Weed segmentation
    for robotic platforms Crop/Weed Field Image Dataset (CW-FID), consists of 20 training
    and 40 testing images. A dataset of 60 top-down field images of a common culture
    (organic carrots) with the presence of intra-row and close-to-crop weeds. 2 classes:
    carrot plants and weeds (image region) N/A Adapted version of Inception-v3 + lightweight
    DCNN + set of K lightweight models as a mixture model (MixDCNN) TensorFlow Image
    up-sampling to 299 × 299 pix., NDVI-based vegetation masks, extracting regions
    based on a sliding window on the color image N/A Same (different carrot fields
    used for testing) CA 93.90% Feature extraction (shape and statistical features)
    and RF classifier: 85.9% McCool et al. (2017) 32. Automating weed detection in
    color images despite heavy leaf occlusion 1427 images from winter wheat fields,
    of which 18,541 weeds have been annotated, collected using a camera mounted on
    an all-terrain vehicle. Detect single weed instances in images of cereal fields
    (bounding box). A coverage map is produced. Large parts of the weeds overlap with
    wheat plants Based on DetectNet CNN (which is based on GoogLeNet CNN) Developed
    by the authors Resized to 1224 × 1024 pix. N/A Different field used for testing.
    This field has a severe degree of occlusion compared to the others IoU 0.64 N/A
    Dyrmann et al. (2017) 33. Crop/weed detection and classification Detecting sugar
    beet plants and weeds in the field based on image data 1969 RGB + NIR images captured
    using a JAI camera in nadir view placed on a UAV. Identify if an image patch belongs
    to weed or sugar beet (image region) N/A Author-defined CNN TensorFlow Separated
    vegetation/background based on NDVI, binary mask to describe vegetation, blob
    segmentation, resized to 64 × 64 pix., normalized and centered 64 even rotations
    Same (also generalized to a second dataset produced 2-weeks after, at a more advanced
    growth stage) P, R Dataset A: 97% (P), 98% (R) Dataset B: 99% (P), 89% (R) N/A
    Milioto et al. (2017) 34. Detecting and classifying sugar beet plants and weeds
    1600 4-channels RGB + NIR images captured before (700 images) and after (900 images)
    a 4-week period, provided by a multispectral JAI camera mounted on a BOSCH Bonirob
    farm robot. Identifies if a blob belongs to sugar beet crop, weeds or soil (image
    blob) N/A Author-defined CNN TensorFlow Pixel-wise segmentation between green
    vegetation and soil based on NDVI and light CNN, unsupervised dataset summariz.
    N/A Same (also generalized to a second dataset produced 4-weeks after, at a more
    advanced growth stage) CA 98% (Dataset A), 59.4% (Dataset B) Feature extraction
    (shape and statistical features) and RF classifier: 95% Potena et al. (2016) 35.
    Detecting and classifying weeds and maize in fields Simulated top-down images
    of overlapping plants on soil background A total of 301 images of soil and 8430
    images of segmented plants. The plants cover 23 different weed species and maize.
    Identifies if an image patch belongs to weed, soil or maize crop (image pixel)
    N/A Adapted version of VGG16 CNN Developed by the authors Image cropping in 800 × 800
    pix. Random scaling from 80 to 100% of original size, random rotations in one
    degree increments, varied hue, saturation and intensity, random shadows Tested
    on real images while trained on simulated ones CA, IoU 94% CA, 0.71 IoU (crops),
    0.70 IoU (weeds) 0.93 IoU (soil) N/A Dyrmann et al. (2016b) 36. Prediction of
    soil moisture content Predict the soil moisture content over an irrigated corn
    field Soil data collected from an irrigated corn field (an area of 22 sq. km)
    in the Zhangye oasis, Northwest China. Percentage of soil moisture content (SMC)
    (scalar value) N/A Deep belief network-based macroscopic cellular automata (DBN-MCA)
    Developed by the authors Geospatial interpolation for creation of soil moisture
    content maps, multivariate geostatistical approach for estimating thematic soil
    maps, maps converted to TIFF, resampled to 10-m res. N/A Same RMSE 6.77 Multi-layer
    perceptron MCA (MLP-MCA): 18% reduction in RMSE Song et al. (2016) 37. Animal
    research Practical and accurate cattle identification from 5 different races 1300
    images collected by the authors. 5 classes: Cattle races, Bali Onggole or Pasuruan,
    Aceh Madura and Pesisir N/A GLCM – CNN Deep Learning Matlab Toolbox GLCM features
    extraction (contrast, energy and homogeneity), saliency maps to accelerate feature
    extraction N/A Same CA 93.76% CNN without extra inputs: 89.68% Gaussian Mixture
    Model (GMM): 90% Santoni et al. (2015) 38. Predict growth of pigs 160 pigs, housed
    in two climate controlled rooms, four pens/room, 10 pigs/pen. Ammonia, ambient
    and indoor air temperature and humidity, feed dosage and ventilation measured
    at 6-minute intervals. Estimation of the weight of pigs (scalar value) N/A First-order
    DRNN Developed by the authors N/A N/A Tested on different rooms of pigs than the
    ones which were used for training MSE, MRE 0.002 (MSE) on same dataset), 10% (MRE)
    in relation to a controller N/A Demmers et al. (2012) 39. Control of the growth
    of broiler chickens Collecting data from 8 rooms, each room housing 262 broilers,
    measuring bird weight, feed amount, light intensity and relative humidity. Estimation
    of the weight of chicken (scalar value) N/A First-order DRNN Developed by the
    authors N/A N/A Tested on different rooms of chicken than the ones which were
    used for training MSE, MRE 0.02 (MSE), 1.8% (MRE) in relation to a controller
    N/A Demmers et al. (2010) 40. Weather prediction Predict weather based on previous
    year’s conditions Syngenta Crop Challenge 2016 dataset, containing 6490 sub-regions
    with three weather condition attributes from the years 2000 to 2015. Predicted
    values of temperature, precipitation and solar radiation (scalar value) N/A LSTM
    Keras N/A N/A Same N-RMSE, MRE 78% (Temperature), 73% (Precipitation), 2.8% (Solar
    Radiation) N-RMSE, 1–3% MRE in all categories N/A Sehgal et al. (2017) Appendix
    C. Publicly-available datasets related to agriculture No. Organization/Dataset
    Description of dataset Source 1. Image-Net Dataset Images of various plants (trees,
    vegetables, flowers) http://image-net.org/explore?wnid=n07707451 2. ImageNet Large
    Scale Visual Recognition Challenge (ILSVRC) Images that allow object localization
    and detection http://image-net.org/challenges/LSVRC/2017/#det 3. University of
    Arcansas, Plants Dataset Herbicide injury image database https://plants.uaex.edu/herbicide/
    http://www.uaex.edu/yard-garden/resource-library/diseases/ 4. EPFL, Plant Village
    Dataset Images of various crops and their diseases https://www.plantvillage.org/en/crops
    5. Leafsnap Dataset Leaves from 185 tree species from the Northeastern United
    States. http://leafsnap.com/dataset/ 6. LifeCLEF Dataset Identity, geographic
    distribution and uses of plants http://www.imageclef.org/2014/lifeclef/plant 7.
    PASCAL Visual Object Classes Dataset Images of various animals (birds, cats, cows,
    dogs, horses, sheep etc.) http://host.robots.ox.ac.uk/pascal/VOC/ 8. Africa Soil
    Information Service (AFSIS) dataset Continent-wide digital soil maps for sub-Saharan
    Africa http://africasoils.net/services/data/ 9. UC Merced Land Use Dataset A 21
    class land use image dataset http://vision.ucmerced.edu/datasets/landuse.html
    10. MalayaKew Dataset Scan-like images of leaves from 44 species classes. http://web.fsktm.um.edu.my/~cschan/downloads_MKLeaf_dataset.html
    11. Crop/Weed Field Image Dataset Field images, vegetation segmentation masks
    and crop/weed plant type annotations. https://github.com/cwfid/dataset https://pdfs.semanticscholar.org/58a0/9b1351ddb447e6abdede7233a4794d538155.pdf
    12. University of Bonn Sugar beets dataset for plant classification as well as
    localization and mapping. http://www.ipb.uni-bonn.de/data/ Photogrammetry, IGG
    13. Flavia leaf dataset Leaf images of 32 plants. http://flavia.sourceforge.net/
    14. Syngenta Crop Challenge 2017 2,267 of corn hybrids in 2,122 of locations between
    2008 and 2016, together with weather and soil conditions https://www.ideaconnection.com/syngenta-crop-challenge/challenge.php
    Research data for this article for download under the CC BY NC 3.0 licence Data
    for: Deep Learning in Agriculture: A Survey Survey on the deep learning technique
    applied in agriculture. Detailed review of 40 relevant research papers, examining
    research area and problem they focus on, technical details on deep learning models,
    sources of data, pre-processing and data augmentation techniques used, and… Dataset
    relatedwork_analysis_advanced.ods 36KB relatedwork_analysis_basic.ods 16KB View
    dataset on Mendeley Data Further information on research data References Amara
    et al., 2017 J. Amara, B. Bouaziz, A. Algergawy A Deep Learning-Based Approach
    for Banana Leaf Diseases Classification BTW workshop, Stuttgart (2017), pp. 79-88
    Google Scholar Bahrampour et al., 2015 Bahrampour, S., Ramakrishnan, N., Schott,
    L., Shah, M., 2015. Comparative study of deep learning software frameworks. arXiv
    preprint arXiv: 1511.06435. Google Scholar Bargoti and Underwood, 2016 Bargoti,
    S., Underwood, J., 2016. Deep Fruit Detection in Orchards. arXiv preprint arXiv:
    1610.03677. Google Scholar Bastiaanssen et al., 2000 W. Bastiaanssen, D. Molden,
    I. Makin Remote sensing for irrigated agriculture: examples from research and
    possible applications Agric. Water Manag., 46 (2) (2000), pp. 137-155 View PDFView
    articleView in ScopusGoogle Scholar Canziani et al., 2016 Canziani, A., Paszke,
    A., Culurciello, E., 2016. An Analysis of Deep Neural Network Models for Practical
    Applications. arXiv preprint arXiv: 1605.07678. Google Scholar Chen et al., 2017
    S.W. Chen, S.S. Shivakumar, S. Dcunha, J. Das, E. Okon, C. Qu, V. Kumar Counting
    apples and oranges with deep learning: a data-driven approach IEEE Rob. Autom.
    Lett., 2 (2) (2017), pp. 781-788 View in ScopusGoogle Scholar Chen et al., 2014
    Y. Chen, Z. Lin, X. Zhao, G. Wang, Y. Gu Deep learning-based classification of
    hyperspectral data IEEE J. Sel. Top. Appl. Earth Obs. Remote Sens., 7 (6) (2014),
    pp. 2094-2107 View in ScopusGoogle Scholar Christiansen et al., 2016 P. Christiansen,
    L.N. Nielsen, K.A. Steen, R.N. Jørgensen, H. Karstoft DeepAnomaly: combining background
    subtraction and deep learning for detecting obstacles and anomalies in an agricultural
    field Sensors, 16 (11) (2016), p. 1904 CrossRefView in ScopusGoogle Scholar Demmers
    et al., 2010 T.G. Demmers, Y. Cao, S. Gauss, J.C. Lowe, D.J. Parsons, C.M. Wathes
    Neural predictive control of broiler chicken growth IFAC Proc. Vol., 43 (6) (2010),
    pp. 311-316 View PDFView articleView in ScopusGoogle Scholar Demmers et al., 2012
    Demmers, T.G., Cao, Y., Parsons, D.J., Gauss, S., Wathes, C.M., 2012. Simultaneous
    monitoring and control of pig growth and ammonia emissions. IX International Livestock
    Environment Symposium (ILES IX). American Society of Agricultural and Biological
    Engineers, Valencia, Spain. Google Scholar Deng et al., 2009 Deng, J., Dong, W.,
    Socher, R., Li, L.J., Li, K., Fei-Fei, L., 2009. Imagenet: A large-scale hierarchical
    image database. IEEE Conference on Computer Vision and Pattern Recognition (CVPR).
    Miami, FL, USA, pp. 248–255. Google Scholar Deng and Yu, 2014 L. Deng, D. Yu Deep
    learning: methods and applications Found. Trends Signal Process., 7 (3–4) (2014),
    pp. 197-387 CrossRefGoogle Scholar Douarre et al., 2016 Douarre, C., Schielein,
    R., Frindel, C., Gerth, S., Rousseau, D., 2016. Deep learning based root-soil
    segmentation from X-ray tomography. bioRxiv, 071662. Google Scholar Dyrmann et
    al., 2017 Dyrmann, M., Jørgensen, R.N., Midtiby, H.S., 2017. RoboWeedSupport –
    Detection of weed locations in leaf occluded cereal crops using a fully convolutional
    neural network. 11th European Conference on Precision Agriculture (ECPA). Edinburgh,
    Scotland. Google Scholar Dyrmann et al., 2016a M. Dyrmann, H. Karstoft, H.S. Midtiby
    Plant species classification using deep convolutional neural network Biosyst.
    Eng., 151 (2016), pp. 72-80 View PDFView articleView in ScopusGoogle Scholar Dyrmann
    et al., 2016b Dyrmann, M., Mortensen, A.K., Midtiby, H.S., Jørgensen, R.N., 2016.
    Pixel-wise classification of weeds and crops in images by using a fully convolutional
    neural network. International Conference on Agricultural Engineering. Aarhus,
    Denmark. Google Scholar FAO, 2009 FAO How to Feed the World in 2050 Food and Agriculture
    Organization of the United Nations, Rome (2009) Google Scholar Gebbers and Adamchuk,
    2010 R. Gebbers, V.I. Adamchuk Precision agriculture and food security Science,
    327 (5967) (2010), pp. 828-831 CrossRefView in ScopusGoogle Scholar Gers et al.,
    2000 F.A. Gers, J. Schmidhuber, F. Cummins Learning to forget: Continual prediction
    with LSTM Neural Comput., 12 (10) (2000), pp. 2451-2471 View in ScopusGoogle Scholar
    Grinblat et al., 2016 G.L. Grinblat, L.C. Uzal, M.G. Larese, P.M. Granitto Deep
    learning for plant identification using vein morphological patterns Comput. Electron.
    Agric., 127 (2016), pp. 418-424 View PDFView articleView in ScopusGoogle Scholar
    Hall et al., 2015 D. Hall, C. McCool, F. Dayoub, N. Sunderhauf, B. Upcroft Evaluation
    of features for leaf classification in challenging conditions Winter Conference
    on Applications of Computer Vision (WACV), IEEE, Waikoloa Beach, Hawaii (2015),
    pp. 797-804 CrossRefView in ScopusGoogle Scholar Ienco et al., 2017 Ienco, D.,
    Gaetano, R., Dupaquier, C., Maurel, P., 2017. Land Cover Classification via Multi-temporal
    Spatial Data by Recurrent Neural Networks. arXiv preprint arXiv: 1704.04055. Google
    Scholar Ishimwe et al., 2014 R. Ishimwe, K. Abutaleb, F. Ahmed Applications of
    thermal imaging in agriculture—A review Adv. Remote Sens., 3 (3) (2014), p. 128
    CrossRefGoogle Scholar Jia et al., 2014 Y. Jia, E. Shelhamer, J. Donahue, S. Karayev,
    J. Long, R. Girshick, T. Darrell Caffe: Convolutional architecture for fast feature
    embedding Proceedings of the 22nd International Conference on Multimedia, ACM,
    Orlando, FL, USA (2014), pp. 675-678 CrossRefGoogle Scholar Kamilaris et al.,
    2017a A. Kamilaris, A. Assumpcio, A.B. Blasi, M. Torrellas, F.X. Prenafeta-Boldú
    Estimating the environmental impact of agriculture by means of geospatial and
    big data analysis: the case of Catalonia, From Science to Society, Springer, Luxembourg
    (2017), pp. 39-48 Google Scholar Kamilaris et al., 2016 A. Kamilaris, F. Gao,
    F.X. Prenafeta-Boldú, M.I. Ali Agri-IoT: A Semantic Framework for Internet of
    Things-Enabled Smart Farming Applications, 3rd World Forum on Internet of Things
    (WF-IoT), IEEE, Reston, VA, USA (2016), pp. 442-447 View in ScopusGoogle Scholar
    Kamilaris et al., 2017b A. Kamilaris, A. Kartakoullis, F.X. Prenafeta-Boldú A
    review on the practice of big data analysis in agriculture Comput. Electron. Agric.,
    143 (1) (2017), pp. 23-37 View PDFView articleView in ScopusGoogle Scholar Kitzes
    et al., 2008 J. Kitzes, M. Wackernagel, J. Loh, A. Peller, S. Goldfinger, D. Cheng,
    K. Tea Shrink and share: humanity''s present and future Ecological Footprint Philos.
    Trans. the Roy. Soc. London B: Biol. Sci., 363 (1491) (2008), pp. 467-475 CrossRefView
    in ScopusGoogle Scholar Krizhevsky et al., 2012 A. Krizhevsky, I. Sutskever, G.E.
    Hinton Imagenet classification with deep convolutional neural networks Adv. Neural
    Inform. Process. Syst. (2012), pp. 1097-1105 Google Scholar Kussul et al., 2017
    N. Kussul, M. Lavreniuk, S. Skakun, A. Shelestov Deep learning classification
    of land cover and crop types using remote sensing data IEEE Geosci. Remote Sens.
    Lett., 14 (5) (2017), pp. 778-782 View in ScopusGoogle Scholar Kuwata and Shibasaki,
    2015 Kuwata, K., Shibasaki, R., 2015. Estimating crop yields with deep learning
    and remotely sensed data. IEEE International Geoscience and Remote Sensing Symposium
    (IGARSS). Milan, Italy, pp. 858–861. Google Scholar LeCun and Bengio, 1995 Y.
    LeCun, Y. Bengio Convolutional networks for images, speech, and time series Handbook
    Brain Theory Neural Networks, 3361 (10) (1995) Google Scholar LeCun et al., 2015
    Y. LeCun, Y. Bengio, G. Hinton Deep learning Nature, 521 (7553) (2015), pp. 436-444
    CrossRefView in ScopusGoogle Scholar Lee et al., 2015 Lee, S.H., Chan, C.S., Wilkin,
    P., Remagnino, P., 2015. Deep-plant: Plant identification with convolutional neural
    networks. IEEE International Conference on Image Processing (ICIP). Quebec city,
    Canada, pp. 452–456. Google Scholar Liaghat and Balasundram, 2010 S. Liaghat,
    S.K. Balasundram A review: The role of remote sensing in precision agriculture
    Am. J. Agric. Biol. Sci., 5 (1) (2010), pp. 50-55 CrossRefView in ScopusGoogle
    Scholar Lu et al., 2017 H. Lu, X. Fu, C. Liu, L.G. Li, Y.X. He, N.W. Li Cultivated
    land information extraction in UAV imagery based on deep convolutional neural
    network and transfer learning J. Mountain Sci., 14 (4) (2017), pp. 731-741 CrossRefView
    in ScopusGoogle Scholar Luus et al., 2015 F.P. Luus, B.P. Salmon, F. van den Bergh,
    B.T. Maharaj Multiview deep learning for land-use classification IEEE Geosci.
    Remote Sens. Lett., 12 (12) (2015), pp. 2448-2452 View in ScopusGoogle Scholar
    Mandic and Chambers, 2001 D.P. Mandic, J.A. Chambers Recurrent Neural Networks
    for Prediction: Learning Algorithms, Architectures and Stability John Wiley, New
    York (2001) Google Scholar McCool et al., 2017 C. McCool, T. Perez, B. Upcroft
    Mixtures of lightweight deep convolutional neural networks: applied to agricultural
    robotics IEEE Rob. Autom. Lett., 2 (3) (2017), pp. 1344-1351 View in ScopusGoogle
    Scholar Milioto et al., 2017 Milioto, A., Lottes, P., Stachniss, C., 2017. Real-time
    blob-wise sugar beets vs weeds classification for monitoring fields using convolutional
    neural networks. Proceedings of the International Conference on Unmanned Aerial
    Vehicles in Geomatics. Bonn, Germany. Google Scholar Minh et al., 2017 Minh, D.H.,
    Ienco, D., Gaetano, R., Lalande, N., Ndikumana, E., Osman, F., Maurel, P., 2017.
    Deep Recurrent Neural Networks for mapping winter vegetation quality coverage
    via multi-temporal SAR Sentinel-1. arXiv preprint arXiv: 1708.03694. Google Scholar
    Mohanty et al., 2016 S.P. Mohanty, D.P. Hughes, M. Salathé Using deep learning
    for image-based plant disease detection Front. Plant. Sci., 7 (2016) Google Scholar
    Mortensen et al., 2016 Mortensen, A.K., Dyrmann, M., Karstoft, H., Jørgensen,
    R.N., Gislum, R., 2016. Semantic segmentation of mixed crops using deep convolutional
    neural network. International Conference on Agricultural Engineering. Aarhus,
    Denmark. Google Scholar Najafabadi et al., 2015 M.M. Najafabadi, F. Villanustre,
    T.M. Khoshgoftaar, N. Seliya, R. Wald, E. Muharemagic Deep learning applications
    and challenges in big data analytics J. Big Data, 2 (1) (2015), p. 1 View in ScopusGoogle
    Scholar Namin et al., 2017 Namin, S.T., Esmaeilzadeh, M., Najafi, M., Brown, T.B.,
    Borevitz, J.O., 2017. Deep Phenotyping: Deep Learning For Temporal Phenotype/Genotype
    Classification. bioRxiv, 134205. Google Scholar Ozdogan et al., 2010 M. Ozdogan,
    Y. Yang, G. Allez, C. Cervantes Remote sensing of irrigated agriculture: Opportunities
    and challenges Remote Sensing, 2 (9) (2010), pp. 2274-2304 CrossRefView in ScopusGoogle
    Scholar Pan and Yang, 2010 S.J. Pan, Q. Yang A survey on transfer learning IEEE
    Trans. Knowl. Data Eng., 22 (10) (2010), pp. 1345-1359 Google Scholar PASCAL VOC
    Project, 2012 PASCAL VOC Project. 2012. The PASCAL Visual Object Classes. Obtenido
    de http://host.robots.ox.ac.uk/pascal/VOC/. Google Scholar Potena et al., 2016
    C. Potena, D. Nardi, A. Pretto Fast and accurate crop and weed identification
    with summarized train sets for precision agriculture International Conference
    on Intelligent Autonomous Systems, Springer, Cham, Shanghai, China (2016), pp.
    105-121 Google Scholar Pound et al., 2016 Pound, M.P. et al., 2016. Deep Machine
    Learning provides state-of-the-art performance in image-based plant phenotyping.
    bioRxiv, 053033. Google Scholar Rahnemoonfar and Sheppard, 2017 M. Rahnemoonfar,
    C. Sheppard Deep count: fruit counting based on deep simulated learning Sensors,
    17 (4) (2017), p. 905 CrossRefView in ScopusGoogle Scholar Rebetez et al., 2016
    Rebetez, J. et al., 2016. Augmenting a convolutional neural network with local
    histograms—a case study in crop classification from high-resolution UAV imagery.
    European Symposium on Artificial Neural Networks, Computational Intelligence and
    Machine Learning. Bruges, Belgium. Google Scholar Reyes et al., 2015 A.K. Reyes,
    J.C. Caicedo, J.E. Camargo Fine-Tuning Deep Convolutional Networks for Plant Recognition
    CLEF (Working Notes), Toulouse (2015) Google Scholar Rußwurm and Körner, 2017
    M. Rußwurm, M. Körner Multi-temporal land cover classification with long short-term
    memory neural networks Int. Arch. Photogramm., Remote Sens. Spatial Inform. Sci.,
    42 (2017) Google Scholar Sa et al., 2016 I. Sa, Z. Ge, F. Dayoub, B. Upcroft,
    T. Perez, C. McCool Deepfruits: A fruit detection system using deep neural networks
    Sensors, 16 (8) (2016), p. 1222 CrossRefView in ScopusGoogle Scholar Santoni et
    al., 2015 M.M. Santoni, D.I. Sensuse, A.M. Arymurthy, M.I. Fanany Cattle race
    classification using gray level co-occurrence matrix convolutional neural networks
    Procedia Comput. Sci., 59 (2015), pp. 493-502 View PDFView articleView in ScopusGoogle
    Scholar Saxena and Armstrong, 2014 Saxena, L., Armstrong, L., 2014. A survey of
    image processing techniques for agriculture. Proceedings of Asian Federation for
    Information Technology in Agriculture, Australian Society of Information and Communication
    Technologies in Agriculture. Perth, Australia. Google Scholar Schmidhuber, 2015
    J. Schmidhuber Deep learning in neural networks: An overview Neural Networks,
    61 (2015), pp. 85-117 View PDFView articleView in ScopusGoogle Scholar Sehgal
    et al., 2017 Sehgal, G., Gupta, B., Paneri, K., Singh, K., Sharma, G., Shroff,
    G., 2017. Crop Planning using Stochastic Visual Optimization. arXiv preprint arXiv:
    1710.09077. Google Scholar Simonyan and Zisserman, 2014 Simonyan, K., Zisserman,
    A., 2014. Very deep convolutional networks for large-scale image recognition.
    arXiv preprint arXiv: 1409.1556. Google Scholar Singh et al., 2016 A. Singh, B.
    Ganapathysubramanian, A.K. Singh, S. Sarkar Machine learning for high-throughput
    stress phenotyping in plants Trends Plant Sci., 21 (2) (2016), pp. 110-124 View
    PDFView articleView in ScopusGoogle Scholar Sladojevic et al., 2016 S. Sladojevic,
    M. Arsenovic, A. Anderla, D. Culibrk, D. Stefanovic Deep neural networks based
    recognition of plant diseases by leaf image classification Comput. Intell. Neurosci.,
    2016 (2016) Google Scholar Song et al., 2016 X. Song, G. Zhang, F. Liu, D. Li,
    Y. Zhao, J. Yang Modeling spatio-temporal distribution of soil moisture by deep
    learning-based cellular automata model J. Arid Land, 8 (5) (2016), pp. 734-748
    CrossRefView in ScopusGoogle Scholar Sørensen et al., 2017 R.A. Sørensen, J. Rasmussen,
    J. Nielsen, R. Jørgensen Thistle Detection Using Convolutional Neural Networks
    EFITA Congress, Montpellier, France (2017) Google Scholar Steen et al., 2016 K.A.
    Steen, P. Christiansen, H. Karstoft, R.N. Jørgensen Using deep learning to challenge
    safety standard for highly autonomous machines in agriculture J. Imag., 2 (1)
    (2016), p. 6 CrossRefView in ScopusGoogle Scholar Szegedy et al., 2017 C. Szegedy,
    S. Ioffe, V. Vanhoucke, A.A. Alemi Inception-v4, Inception-ResNet and the Impact
    of Residual Connections on Learning AAAI (2017), pp. 4278-4284 View in ScopusGoogle
    Scholar Szegedy et al., 2015 Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed,
    S., Anguelov, D., Rabinovich, A., 2015. Going deeper with convolutions. IEEE Conference
    on Computer Vision and Pattern Recognition. Boston, MA, USA, pp. 1–9. Google Scholar
    Teke et al., 2013 Teke, M., Deveci, H.S., Haliloğlu, O., Gürbüz, S.Z., Sakarya,
    U., 2013. A short survey of hyperspectral remote sensing applications in agriculture.
    6th International Conference on Recent Advances in Space Technologies (RAST).
    IEEE, Istanbul, Turkey. Google Scholar Tyagi, 2016 A.C. Tyagi Towards a second
    green revolution Irrig. Drain., 65 (4) (2016), pp. 388-389 CrossRefView in ScopusGoogle
    Scholar Wan et al., 2014 Wan, J., Wang, D., Hoi, S.C., Wu, P., Zhu, J., Zhang,
    Y., Li, J., 2014. Deep learning for content-based image retrieval: A comprehensive
    study. Proceedings of the 22nd ACM International Conference on Multimedia. ACM,
    Orlando, FL, pp. 157–166. Google Scholar Xinshao and Cheng, 2015 Xinshao, W.,
    Cheng, C., 2015. Weed seeds classification based on PCANet deep learning baseline.
    IEEE Signal and Information Processing Association Annual Summit and Conference
    (APSIPA), pp. 408–415. Google Scholar Yalcin, 2017 Yalcin, H., 2017. Plant phenology
    recognition using deep learning: Deep-Pheno. 6th International Conference on Agro-Geoinformatics.
    Fairfax VA, USA. Google Scholar Cited by (2487) Economic and environmental benefits
    of digital agricultural technologies in crop production: A review 2024, Smart
    Agricultural Technology Show abstract MCCANet: A multispectral class-constraint
    attentional neural network for object detection in mining scenes 2024, Expert
    Systems with Applications Show abstract Cross-domain transfer learning for weed
    segmentation and mapping in precision farming using ground and UAV images 2024,
    Expert Systems with Applications Show abstract Achieving explainability for plant
    disease classification with disentangled variational autoencoders 2024, Engineering
    Applications of Artificial Intelligence Show abstract Rice disease segmentation
    method based on CBAM-CARAFE-DeepLabv3+ 2024, Crop Protection Show abstract Using
    UAVRS and deep learning to conduct resource surveys of threatened Tibetan medicinal
    plants in the Qinghai-Tibet Plateau 2024, Global Ecology and Conservation Show
    abstract View all citing articles on Scopus 1 A small number of papers claimed
    of using DL in some agricultural-related application, but they did not show any
    results nor provided performance metrics that could indicate the success of the
    technique used. 2 Classification accuracy is defined in Section 4.7 and Table
    1. View Abstract © 2018 Elsevier B.V. All rights reserved. Recommended articles
    Deep learning for plant identification using vein morphological patterns Computers
    and Electronics in Agriculture, Volume 127, 2016, pp. 418-424 Guillermo L. Grinblat,
    …, Pablo M. Granitto View PDF Deep learning models for plant disease detection
    and diagnosis Computers and Electronics in Agriculture, Volume 145, 2018, pp.
    311-318 Konstantinos P. Ferentinos View PDF Plant species classification using
    deep convolutional neural network Biosystems Engineering, Volume 151, 2016, pp.
    72-80 Mads Dyrmann, …, Henrik Skov Midtiby View PDF Show 3 more articles Article
    Metrics Citations Citation Indexes: 2167 Patent Family Citations: 3 Policy Citations:
    11 Captures Readers: 3246 Mentions References: 1 Social Media Shares, Likes &
    Comments: 20 View details About ScienceDirect Remote access Shopping cart Advertise
    Contact and support Terms and conditions Privacy policy Cookies are used by this
    site. Cookie settings | Your Privacy Choices All content on this site: Copyright
    © 2024 Elsevier B.V., its licensors, and contributors. All rights are reserved,
    including those for text and data mining, AI training, and similar technologies.
    For all open access content, the Creative Commons licensing terms apply.'
  inline_citation: '>'
  journal: Computers and electronics in agriculture
  limitations: '>'
  pdf_link: null
  publication_year: 2018
  relevance_score1: 0
  relevance_score2: 0
  title: 'Deep learning in agriculture: A survey'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.3390/rs9111110
  analysis: '>'
  authors:
  - Telmo Adão
  - Jonáš Hruška
  - Luís Pádua
  - José Rogério Fontenele Bessa
  - Emanuel Peres
  - Raul Morais
  - Joaquim J. Sousa
  citation_count: 770
  full_citation: '>'
  full_text: ">\nremote sensing  \nTechnical Note\nHyperspectral Imaging: A Review\
    \ on UAV-Based\nSensors, Data Processing and Applications for\nAgriculture and\
    \ Forestry\nTelmo Adão 1,2,*\nID , Jonáš Hruška 2, Luís Pádua 2\nID , José Bessa\
    \ 2, Emanuel Peres 1,2\nID ,\nRaul Morais 1,2\nID and Joaquim João Sousa 1,2\n\
    1\nInstitute for Systems and Computer Engineering, Technology and Science (INESC-TEC—Formerly\
    \ INESC\nPorto), 4200-465 Porto, Portugal; eperes@utad.pt (E.P.); rmorais@utad.pt\
    \ (R.M.); jjsousa@utad.pt (J.J.S.)\n2\nDepartment of Engineering, School of Sciences\
    \ and Technology, University of Trás-os-Montes e Alto Douro,\n5000-801 Vila Real,\
    \ Portugal; jonash@utad.pt (J.H.); luispadua@utad.pt (L.P.);\njmiguelbessa16@gmail.com\
    \ (J.B.)\n*\nCorrespondence: telmoadao@utad.pt; Tel.: +351-259-350-356\nReceived:\
    \ 20 September 2017; Accepted: 27 October 2017; Published: 30 October 2017\nAbstract:\
    \ Traditional imagery—provided, for example, by RGB and/or NIR sensors—has proven\
    \ to\nbe useful in many agroforestry applications. However, it lacks the spectral\
    \ range and precision\nto proﬁle materials and organisms that only hyperspectral\
    \ sensors can provide.\nThis kind of\nhigh-resolution spectroscopy was ﬁrstly\
    \ used in satellites and later in manned aircraft, which are\nsigniﬁcantly expensive\
    \ platforms and extremely restrictive due to availability limitations and/or\n\
    complex logistics. More recently, UAS have emerged as a very popular and cost-effective\
    \ remote\nsensing technology, composed of aerial platforms capable of carrying\
    \ small-sized and lightweight\nsensors. Meanwhile, hyperspectral technology developments\
    \ have been consistently resulting in\nsmaller and lighter sensors that can currently\
    \ be integrated in UAS for either scientiﬁc or commercial\npurposes. The hyperspectral\
    \ sensors’ ability for measuring hundreds of bands raises complexity\nwhen considering\
    \ the sheer quantity of acquired data, whose usefulness depends on both calibration\n\
    and corrective tasks occurring in pre- and post-ﬂight stages. Further steps regarding\
    \ hyperspectral\ndata processing must be performed towards the retrieval of relevant\
    \ information, which provides\nthe true beneﬁts for assertive interventions in\
    \ agricultural crops and forested areas. Considering\nthe aforementioned topics\
    \ and the goal of providing a global view focused on hyperspectral-based\nremote\
    \ sensing supported by UAV platforms, a survey including hyperspectral sensors,\
    \ inherent data\nprocessing and applications focusing both on agriculture and\
    \ forestry—wherein the combination of\nUAV and hyperspectral sensors plays a center\
    \ role—is presented in this paper. Firstly, the advantages\nof hyperspectral data\
    \ over RGB imagery and multispectral data are highlighted. Then, hyperspectral\n\
    acquisition devices are addressed, including sensor types, acquisition modes and\
    \ UAV-compatible\nsensors that can be used for both research and commercial purposes.\
    \ Pre-ﬂight operations and\npost-ﬂight pre-processing are pointed out as necessary\
    \ to ensure the usefulness of hyperspectral data\nfor further processing towards\
    \ the retrieval of conclusive information. With the goal of simplifying\nhyperspectral\
    \ data processing—by isolating the common user from the processes’ mathematical\n\
    complexity—several available toolboxes that allow a direct access to level-one\
    \ hyperspectral data\nare presented. Moreover, research works focusing the symbiosis\
    \ between UAV-hyperspectral for\nagriculture and forestry applications are reviewed,\
    \ just before the paper’s conclusions.\nKeywords:\nhyperspectral; UAS; UAV; hyperspectral\
    \ sensors; hyperspectral data processing;\nagriculture; forestry; agroforestry\n\
    Remote Sens. 2017, 9, 1110; doi:10.3390/rs9111110\nwww.mdpi.com/journal/remotesensing\n\
    Remote Sens. 2017, 9, 1110\n2 of 30\n1. Introduction\nRemote sensing relying on\
    \ unmanned aircraft systems (UAS), although an emerging ﬁeld of\napplication,\
    \ has been systematically applied for monitoring vegetation and environmental\
    \ parameters\naiming the optimization of agroforestry activities [1]. In this\
    \ context, UAS have become suitable to\nassess crops’ conditions by gathering\
    \ huge amounts of raw data that require further processing\nto enable a wide range\
    \ of applications, such as water status [2], vigor assessment [3], biomass\nestimation\
    \ [4] and disease monitoring [5]. Similarly, forestry and nature preservation\
    \ can also greatly\nbeneﬁt from the use of UAS technology, allowing inspection\
    \ of forestry operations [6], wildﬁre\ndetection [7], health monitoring [8] and\
    \ forest preservation [9].\nIn spite of the large number of successful works that\
    \ have been applied to agroforestry and related\nareas using low-cost passive\
    \ imagery sensors—such as visible (RGB) and near infrared (NIR)—many\napplications\
    \ require higher spectral ﬁdelity that only multispectral and hyperspectral [10–13]\
    \ sensors\ncan offer. Both of the referred spectral-based methods consist of the\
    \ acquisition of images where,\nfor each of the image’s spatially distributed\
    \ elements, a spectrum of the energy reaching the respective\nsensor is measured.\
    \ The main difference between them is the number of bands (also referred as\n\
    channels) and their width [14]. While multispectral imagery generally ranges from\
    \ 5 to 12 bands that\nare represented in pixels and each band is acquired using\
    \ a remote sensing radiometer, hyperspectral\nimagery consists of a much higher\
    \ band number—hundreds or thousands of them—arranged in\na narrower bandwidth\
    \ (5–20 nm, each). Figure 1 represents the differences between multi and\nhyperspectral\
    \ imaging, which rely on a spectroscopic approach that has been used for laboratorial\n\
    practices and in Astronomy for more than 100 years.\nRemote Sens. 2017, 9, 1110\
    \  \n2 of 31 \n \n1. Introduction \nRemote sensing relying on unmanned aircraft\
    \ systems (UAS), although an emerging field of \napplication, has been systematically\
    \ applied for monitoring vegetation and environmental \nparameters aiming the\
    \ optimization of agroforestry activities [1]. In this context, UAS have become\
    \ \nsuitable to assess crops’ conditions by gathering huge amounts of raw data\
    \ that require further \nprocessing to enable a wide range of applications, such\
    \ as water status [2], vigor assessment [3], \nbiomass estimation [4] and disease\
    \ monitoring [5]. Similarly, forestry and nature preservation can \nalso greatly\
    \ benefit from the use of UAS technology, allowing inspection of forestry operations\
    \ [6], \nwildfire detection [7], health monitoring [8] and forest preservation\
    \ [9]. \nIn spite of the large number of successful works that have been applied\
    \ to agroforestry and \nrelated areas using low-cost passive imagery sensors—such\
    \ as visible (RGB) and near infrared \n(NIR)—many applications require higher\
    \ spectral fidelity that only multispectral and hyperspectral \n[10–13] sensors\
    \ can offer. Both of the referred spectral-based methods consist of the acquisition\
    \ of \nimages where, for each of the image’s spatially distributed elements, a\
    \ spectrum of the energy \nreaching the respective sensor is measured. The main\
    \ difference between them is the number of bands \n(also referred as channels)\
    \ and their width [14]. While multispectral imagery generally ranges from \n5\
    \ to 12 bands that are represented in pixels and each band is acquired using a\
    \ remote sensing \nradiometer, hyperspectral imagery consists of a much higher\
    \ band number—hundreds or thousands \nof them—arranged in a narrower bandwidth\
    \ (5–20 nm, each). Figure 1 represents the differences \nbetween multi and hyperspectral\
    \ imaging, which rely on a spectroscopic approach that has been used \nfor laboratorial\
    \ practices and in Astronomy for more than 100 years. \n \nFigure 1. Spectrum\
    \ representation including: (A) Multispectral example, with 5 wide bands; and\
    \ (B) \nHyperspectral example consisting of several narrow bands that, usually,\
    \ extends to hundreds or \nthousands of them (image not drawn to scale, based\
    \ in [14]). \nIn fact, both multi- and hyperspectral imagery have the potential\
    \ to take data mining to a whole \nnew exploration level in many areas, including\
    \ food quality assessment [11] and agriculture [12]. For \ninstance, productivity\
    \ and stress indicators in both agricultural and forest ecosystems can be assessed\
    \ \nthrough photosynthetic light use efficiency quantification, which can be obtained\
    \ by measuring the \nphotochemical reflectance index (PRI) relying on narrowband\
    \ absorbance of xanthophyll pigments \nat 531 and 570 nm [15]. However, while\
    \ the higher spectral resolution present in hyperspectral data \nallows remote\
    \ sensing of narrowband spectral composition—also known as spectra, signature\
    \ or, \naccording to [16], spectral signature—multispectral data manifests itself\
    \ in larger intervals over the \nelectromagnetic spectrum, which does not enable\
    \ to reach the same level of detail. Thus, \nhyperspectral data has a better performance\
    \ profiling materials and respective endmembers due to \nits almost continuous\
    \ spectra. On the one hand, it covers spectral detail that might pass unnoticeable\
    \ \nin multispectral data due to its discrete and sparse nature. For example,\
    \ in Figure 2, since red-edge \n(RE, 670–780 nm) is not accessible through the\
    \ broadband sensor, leaf chlorophyll content, \nphenological state and vegetation\
    \ stress—which are parameters that manifest in that spectral range—\nFigure 1.\
    \ Spectrum representation including: (A) Multispectral example, with 5 wide bands;\
    \ and\n(B) Hyperspectral example consisting of several narrow bands that, usually,\
    \ extends to hundreds or\nthousands of them (image not drawn to scale, based in\
    \ [14]).\nIn fact, both multi- and hyperspectral imagery have the potential to\
    \ take data mining to a whole\nnew exploration level in many areas, including\
    \ food quality assessment [11] and agriculture [12].\nFor instance, productivity\
    \ and stress indicators in both agricultural and forest ecosystems can\nbe assessed\
    \ through photosynthetic light use efﬁciency quantiﬁcation, which can be obtained\
    \ by\nmeasuring the photochemical reﬂectance index (PRI) relying on narrowband\
    \ absorbance of xanthophyll\npigments at 531 and 570 nm [15]. However, while the\
    \ higher spectral resolution present in hyperspectral\ndata allows remote sensing\
    \ of narrowband spectral composition—also known as spectra, signature or,\naccording\
    \ to [16], spectral signature—multispectral data manifests itself in larger intervals\
    \ over the\nelectromagnetic spectrum, which does not enable to reach the same\
    \ level of detail. Thus, hyperspectral\ndata has a better performance proﬁling\
    \ materials and respective endmembers due to its almost\ncontinuous spectra. On\
    \ the one hand, it covers spectral detail that might pass unnoticeable in\nmultispectral\
    \ data due to its discrete and sparse nature. For example, in Figure 2, since\
    \ red-edge (RE,\nRemote Sens. 2017, 9, 1110\n3 of 30\n670–780 nm) is not accessible\
    \ through the broadband sensor, leaf chlorophyll content, phenological\nstate\
    \ and vegetation stress—which are parameters that manifest in that spectral range—cannot\
    \ be\nassessed. On the other hand, hyperspectral has the ability to discriminate\
    \ components that may be\nunwittingly grouped by multispectral bands (see, for\
    \ example, [17] for more details).\nRemote Sens. 2017, 9, 1110  \n3 of 31 \n \n\
    cannot be assessed. On the other hand, hyperspectral has the ability to discriminate\
    \ components that \nmay be unwittingly grouped by multispectral bands (see, for\
    \ example, [17] for more details). \n \nFigure 2. Broadband sensors’ inability\
    \ for accessing the spectral shift of the RE (670–780 nm) slope \nassociated with\
    \ leaf chlorophyll content, phenological state and vegetation stress, comparatively\
    \ to \nwide-range narrowband ones (re-edited from [18]). \nAlong with the resolution\
    \ improvement, the hyperspectral sensing approach also increases data \nprocessing\
    \ complexity, since such imagery ranges from hundreds to thousands of narrow bands\
    \ that \ncan be difficult to handle in real-time with reduced computational resources.\
    \ Besides, spectral \nsignatures can undergo through variations depending on light\
    \ exposure and atmospheric conditions, \nwhich is an issue that has been leading\
    \ the scientific community to propose processes for acquisition \n(to control\
    \ environmental conditions) and/or analysis methodologies (to correct the noise\
    \ resulting \nfrom environmental conditions). Such efforts allow accurately matching\
    \ spectral data and identifying \nmaterial compositions. \nThe first developments\
    \ of imaging spectrometry in remote sensing applications started using \nsatellites,\
    \ more specifically to support Landsat-1 data analysis through field spectral\
    \ measurements, \naccording to [19]. Studies were mostly regarded to mineral exploration\
    \ [20], but also landmine \ndetection [21], agroforestry and related areas [22].\
    \ Back then, hyperspectral imaging technology did \nnot have the supporting resources\
    \ to go mainstream because developments in electronics, computing \nand software\
    \ areas were required. Progress in the 1980s ended up to overcome technological\
    \ \nlimitations, opening the doors for the dissemination of this remote sensing\
    \ technique for earth \nmonitoring by the 1990s [23]. However, its development\
    \ is still considered an ongoing process [24]. \nCurrently, satellite capabilities\
    \ for wide spatial range covering along with the improvements that \nhave been\
    \ carried out regarding spatial and spectral resolution [25] have been allowing\
    \ the \ndevelopment of remote sensing works in—also but not limited to—agriculture,\
    \ forestry and related \nareas (e.g., [26–28]). Notwithstanding, long distances\
    \ relatively to earth surface raises recurrent \nproblems, according to [29].\
    \ For example, Pölönen et al. [30] pointed out that for conditions involving \n\
    cloudiness and short growing season, hyperspectral data acquired from traditional\
    \ platforms can \nbecome useless in some cases. Other issues include the high\
    \ cost of commercial satellite imagery, \nwhich only provide up to 30 cm resolution\
    \ [31]. Even recent technology such as Sentinel 2 provides \nup to 10 m resolution\
    \ in RGB and NIR [32], which is too coarse for some applications. For a better\
    \ \ninsight, considering a scenario with vines in which consecutive rows are parted\
    \ by 4 m, such imagery \nwould mix, at least, 2 rows with a significant portion\
    \ of soil. An alternative to satellites started to be \ndesigned by National Aeronautics\
    \ and Space Administration Jet Propulsion Laboratory (NASA/JPL) \nin 1983, with\
    \ the development of hyperspectral hardware, specific for aircrafts, resulting\
    \ in an \nFigure 2. Broadband sensors’ inability for accessing the spectral shift\
    \ of the RE (670–780 nm) slope\nassociated with leaf chlorophyll content, phenological\
    \ state and vegetation stress, comparatively to\nwide-range narrowband ones (re-edited\
    \ from [18]).\nAlong with the resolution improvement, the hyperspectral sensing\
    \ approach also increases data\nprocessing complexity, since such imagery ranges\
    \ from hundreds to thousands of narrow bands\nthat can be difﬁcult to handle in\
    \ real-time with reduced computational resources. Besides, spectral\nsignatures\
    \ can undergo through variations depending on light exposure and atmospheric conditions,\n\
    which is an issue that has been leading the scientiﬁc community to propose processes\
    \ for acquisition\n(to control environmental conditions) and/or analysis methodologies\
    \ (to correct the noise resulting\nfrom environmental conditions). Such efforts\
    \ allow accurately matching spectral data and identifying\nmaterial compositions.\n\
    The ﬁrst developments of imaging spectrometry in remote sensing applications started\
    \ using\nsatellites, more speciﬁcally to support Landsat-1 data analysis through\
    \ ﬁeld spectral measurements,\naccording to [19]. Studies were mostly regarded\
    \ to mineral exploration [20], but also landmine\ndetection [21], agroforestry\
    \ and related areas [22]. Back then, hyperspectral imaging technology did\nnot\
    \ have the supporting resources to go mainstream because developments in electronics,\
    \ computing\nand software areas were required. Progress in the 1980s ended up\
    \ to overcome technological limitations,\nopening the doors for the dissemination\
    \ of this remote sensing technique for earth monitoring by\nthe 1990s [23]. However,\
    \ its development is still considered an ongoing process [24]. Currently,\nsatellite\
    \ capabilities for wide spatial range covering along with the improvements that\
    \ have been\ncarried out regarding spatial and spectral resolution [25] have been\
    \ allowing the development of\nremote sensing works in—also but not limited to—agriculture,\
    \ forestry and related areas (e.g., [26–28]).\nNotwithstanding, long distances\
    \ relatively to earth surface raises recurrent problems, according to [29].\n\
    For example, Pölönen et al. [30] pointed out that for conditions involving cloudiness\
    \ and short growing\nseason, hyperspectral data acquired from traditional platforms\
    \ can become useless in some cases.\nOther issues include the high cost of commercial\
    \ satellite imagery, which only provide up to 30 cm\nresolution [31]. Even recent\
    \ technology such as Sentinel 2 provides up to 10 m resolution in RGB and\nNIR\
    \ [32], which is too coarse for some applications. For a better insight, considering\
    \ a scenario with\nRemote Sens. 2017, 9, 1110\n4 of 30\nvines in which consecutive\
    \ rows are parted by 4 m, such imagery would mix, at least, 2 rows with a\nsigniﬁcant\
    \ portion of soil. An alternative to satellites started to be designed by National\
    \ Aeronautics\nand Space Administration Jet Propulsion Laboratory (NASA/JPL) in\
    \ 1983, with the development\nof hyperspectral hardware, speciﬁc for aircrafts,\
    \ resulting in an Airborne Imaging Spectrometer\n(AIS). Later, in 1987, the airborne\
    \ visible/infrared imaging spectrometer (AVIRIS) [33] came out as a\nhigh quality\
    \ hyperspectral data provider that became popular among the scientiﬁc community\
    \ [19].\nHowever, besides the costs involved in the use of this solution, a certiﬁed\
    \ pilot for manning the\naerial vehicle and ﬂight-related logistics is required.\
    \ Lately, a remote sensing platform capable of\novercoming not only satellite\
    \ but also manned aircraft issues by bringing enhanced spectral and\nspatial resolutions,\
    \ operational ﬂexibility and affordability to the users is emerging: the UAS [34].\n\
    Together with specialized sensors, UAS are becoming powerful sensing systems [35]\
    \ that complement\nthe traditional sensing techniques rather than competing with\
    \ them [1]. According to Pádua et al. [1],\na UAS can be deﬁned as a power-driven\
    \ and reusable aircraft, operated without a human pilot on\nboard [36]. Usually,\
    \ it is composed of a UAV that, in turn, is capable of carrying remote sensing\
    \ devices.\nUAS can be remotely controlled or have a programmed route to perform\
    \ an autonomous ﬂight using\nthe embedded autopilot. Generally, it also requires\
    \ a ground-control station and communication\ndevices for carrying out ﬂight missions\
    \ [37]. Colomina and Molina [38] share a similar perspective\nby referring that\
    \ a UAV is usually referred to as the remotely piloted platform, whereas the UAS\
    \ is\nregarded as the platform and control segment. They also add that UAV and\
    \ UAS are somewhat used\ninterchangeably too. In what regards to hyperspectral\
    \ data handling, a set of steps can be followed [13]:\n(1) image acquisition;\
    \ (2) calibration; (3) spectral/spatial processing; (4) dimensionality reduction\
    \ and;\nﬁnally (5) computation related tasks (e.g., analysis, classiﬁcation, detection,\
    \ etc.). Similarly, in [39], ﬁle\nreduction and subsetting, spectral library deﬁnition\
    \ (e.g., made by selecting a portion in the image) and\nclassiﬁcation are pointed\
    \ out as valid operations to constitute a chain. Remote sensing, through the\n\
    combination of UAV and on-board hyperspectral sensors and relying in many of the\
    \ aforementioned\nsteps/operations, has been applied both to agriculture and forestry\
    \ (e.g., [40–42]). However, available\nworks are not so numerous when compared\
    \ with other platforms, since this is a relatively new research\nﬁeld. Even so,\
    \ they provide a proper demonstration of this approach’s potential.\nAll in all,\
    \ the main focus of this paper is, precisely, UAS-based remote sensing using hyperspectral\n\
    sensors, applied both in agriculture and forestry. The acquisition equipment designed\
    \ to be attached\nto UAVs is presented next, in Section 2. Then, Section 3 provides\
    \ a discussion towards the operations\nthat should be carried out before and after\
    \ ﬂight missions, as well as pre-processing data procedures\nfor image calibration.\
    \ Important approaches for data processing are reviewed in Section 4, speciﬁcally\n\
    data dimension, target detection, classiﬁcation and vegetation indices operations.\
    \ Supporting software\ntools and libraries are presented in Section 5. Applications\
    \ focusing the use of UAV’s and hyperspectral\nsensors in agriculture and forestry\
    \ are addressed in Section 6, right before some conclusions within\nSection 7.\
    \ To provide guidance along this paper’s reading, a glossary regarding the used\
    \ abbreviations\nand acronyms is listed in Appendix A.\n2. Hyperspectral Sensors\n\
    Independent of the aerial platform (Airborne, Satellite, UAV, etc.), sensors play\
    \ an important\nrole in data acquisition. According to [43], in which an extensive\
    \ work addressing hyperspectral\ntechnology can be found, there are four main\
    \ techniques for acquiring measurable data from a given\ntarget: by hyperspectral\
    \ imaging, multispectral imaging, spectroscopy and RGB imagery. The most\nsigniﬁcant\
    \ differences are synthetized in Table 1, which considers not only the comparison\
    \ carried\nout by [43] but also the vision of Sellar and Boreman [44], who stated\
    \ that imaging sensors for\nremote sensing can be divided into the method by which\
    \ they achieve (1) spatial discrimination and\n(2) spectral discrimination.\n\
    When compared with others, hyperspectral imaging sensors are effectively capable\
    \ of capturing\nmore detail in both spectral and spatial ranges. RGB imaging does\
    \ not provide spectral information\nRemote Sens. 2017, 9, 1110\n5 of 30\nbeyond\
    \ the visible spectrum, which is of high importance for characterizing chemical\
    \ and physical\nproprieties of a specimen. On the other hand, spectroscopy is\
    \ a proximity technology mainly used for\nsensing tiny areas (e.g., leaf spots),\
    \ aiming the acquisition of spectral samples without spatial deﬁnition.\nRegarding\
    \ multispectral imaging and in spite of its capability for sensing both spectral\
    \ and spatial\ndata, there is a lack of spectral resolution that is only surpassed\
    \ by hyperspectral imaging, as it was\npointed out in the previous section. Thereby,\
    \ hyperspectral sensing technology should be preferred\nwhen it comes to sense\
    \ chemical and physical properties of a specimen.\nTable 1.\nMain differences\
    \ between hyperspectral and multispectral imaging, spectroscopy and\nRGB imagery\
    \ (merging perspectives of [43,44]). A classiﬁcation based on a bullet rate (1–3)\
    \ was\nused to quantify both the spectral and spatial information associated to\
    \ each acquisition technique,\nin relative terms.\nSpectral Information\nSpatial\
    \ Information\nHyperspectral Imaging\n•••\n•••\nMultispectral Imaging\n••\n•••\n\
    Spectroscopy\n•••\n•\nRGB Imagery\n•\n•••\nIn what regards to the concept of hyperspectral\
    \ sensors, there are area detectors that have\nthe ability of quantifying acquired\
    \ light that results from the conversion of incident photons into\nelectrons [43].\
    \ Two types of sensors are prominently used to achieve such conversion: charge-coupled\n\
    device (CCD) and complementary metal-oxide-semiconductor (CMOS) sensors. Both\
    \ consist in an\narray of photodiodes that might be built using different materials,\
    \ as it is detailed in Figure 3.\nRemote Sens. 2017, 9, 1110  \n5 of 31 \nand\
    \ spatial data, there is a lack of spectral resolution that is only surpassed\
    \ by hyperspectral imaging, \nas it was pointed out in the previous section. Thereby,\
    \ hyperspectral sensing technology should be \npreferred when it comes to sense\
    \ chemical and physical properties of a specimen. \nTable 1. Main differences\
    \ between hyperspectral and multispectral imaging, spectroscopy and RGB \nimagery\
    \ (merging perspectives of [43,44]). A classification based on a bullet rate (1–3)\
    \ was used to \nquantify both the spectral and spatial information associated\
    \ to each acquisition technique, in relative \nterms. \n \nSpectral Information\n\
    Spatial Information \nHyperspectral Imaging \n••• \n••• \nMultispectral Imaging\
    \ \n•• \n••• \nSpectroscopy \n••• \n• \nRGB Imagery \n• \n••• \nIn what regards\
    \ to the concept of hyperspectral sensors, there are area detectors that have\
    \ the \nability of quantifying acquired light that results from the conversion\
    \ of incident photons into \nelectrons [43]. Two types of sensors are prominently\
    \ used to achieve such conversion: charge-coupled \ndevice (CCD) and complementary\
    \ metal-oxide-semiconductor (CMOS) sensors. Both consist in an \narray of photodiodes\
    \ that might be built using different materials, as it is detailed in Figure 3.\
    \ \n \nFigure 3. Materials involved in hyperspectral sensors fabrication (inspired\
    \ by [43]): Silicon (Si) is used \nfor acquiring ultraviolet, visible and shortwave\
    \ NIR regions; indium arsenide (InAs) and gallium \narsenide (GaAs) have a spectral\
    \ response between 900–1700 nm; indium gallium arsenide (InGaAs) \nextends the\
    \ previous range to 2600 nm; and mercury cadmium tellurium (MCT or HgCdTe) is\
    \ \ncharacterized by a large spectral range and high quantum efficiency that enables\
    \ reaching mid-\ninfrared region (about 2500 to 25,000 nm) and NIR region (about\
    \ 800–2500 nm). \nCCD and CMOS sensors are different mainly in the way they treat\
    \ incoming energy. On the one \nhand, CCD requires moving the electric charges\
    \ accumulated in the photodiodes into another place \nwherein the quantity of\
    \ charges can be measured. On the other hand, CMOS holds the photodetector \n\
    and readout amplifier integrated as a single part capable of converting the voltage\
    \ signal resulted \nfrom incoming electrons—converted photons—due to optically\
    \ intensive transistors placed \nadjacently to photodiode. This seems to be the\
    \ reason why CMOS technology is faster when acquiring \nand measuring light intensity.\
    \ However, it is more prone to noise and dark currents than CCD due \nto the on-chip\
    \ circuits used to transfer and amplify signals and as a result of lower dynamic\
    \ range \nand sensitivity, as it is explained by [43]. A dark current is a temperature-dependent\
    \ common \nphenomenon that contributes to introduce noise in a sensor’s reading\
    \ and that needs to be considered \nin calibration tasks, for correction purposes.\
    \ According to [45], such phenomenon can be generated \nby the Shockley–Read–Hall\
    \ (SRH) process—that considers band gap by an impurity in the lattice to \nFigure\
    \ 3. Materials involved in hyperspectral sensors fabrication (inspired by [43]):\
    \ Silicon (Si)\nis used for acquiring ultraviolet, visible and shortwave NIR regions;\
    \ indium arsenide (InAs) and\ngallium arsenide (GaAs) have a spectral response\
    \ between 900–1700 nm; indium gallium arsenide\n(InGaAs) extends the previous\
    \ range to 2600 nm; and mercury cadmium tellurium (MCT or HgCdTe) is\ncharacterized\
    \ by a large spectral range and high quantum efﬁciency that enables reaching mid-infrared\n\
    region (about 2500 to 25,000 nm) and NIR region (about 800–2500 nm).\nCCD and\
    \ CMOS sensors are different mainly in the way they treat incoming energy. On\
    \ the one\nhand, CCD requires moving the electric charges accumulated in the photodiodes\
    \ into another place\nwherein the quantity of charges can be measured. On the\
    \ other hand, CMOS holds the photodetector\nand readout ampliﬁer integrated as\
    \ a single part capable of converting the voltage signal resulted\nfrom incoming\
    \ electrons—converted photons—due to optically intensive transistors placed adjacently\n\
    to photodiode. This seems to be the reason why CMOS technology is faster when\
    \ acquiring and\nRemote Sens. 2017, 9, 1110\n6 of 30\nmeasuring light intensity.\
    \ However, it is more prone to noise and dark currents than CCD due to\nthe on-chip\
    \ circuits used to transfer and amplify signals and as a result of lower dynamic\
    \ range\nand sensitivity, as it is explained by [43]. A dark current is a temperature-dependent\
    \ common\nphenomenon that contributes to introduce noise in a sensor’s reading\
    \ and that needs to be considered\nin calibration tasks, for correction purposes.\
    \ According to [45], such phenomenon can be generated\nby the Shockley–Read–Hall\
    \ (SRH) process—that considers band gap by an impurity in the lattice to\nmake\
    \ the electron in transition pass through a new energy state—due to multiple factors,\
    \ which end\nup resulting in the so-called blemish pixels. Additional information\
    \ can be found in [15], in which is\npointed out that CCD-based sensors have higher\
    \ sensitivity regarding band data acquisition while,\non the other hand, high\
    \ grade CMOS have greater quantum efﬁciency in NIR.\nRegarding acquisition modes,\
    \ reference [43] categorizes them in four main ones (in fairly enough\naccordance\
    \ with [44,46,47]): point scanning (or whiskbroom), line scanning (or pushbroom),\
    \ plan\nscanning and single shot (Figure 4). While whiskbroom mode acquires all\
    \ the bands pixel by pixel by\nmoving the detector in the x-y space to store data\
    \ in a band-interleaved-by-pixel (BIP) cube, pushbroom\nmode proceeds similarly\
    \ but, instead of pixel-based scanning, an entire sequence of pixels forming\n\
    a line is acquired, which ends up by constituting a band-interleaved-by-line (BIL)\
    \ cube. Some other\npushbroom characteristics include compact size, low weight,\
    \ simpler operation and higher signal\nto noise ratio [10]. More comparisons between\
    \ pushbroom and whiskbroom modes are presented\nin [48]. Plane scanning mode builds\
    \ a band sequential (BSQ) cube constituted by several images taken\nat a time,\
    \ each one holding spectral data regarding a whole given x-y space. Finally, there\
    \ is a more\nrecent mode that acquires all of the spatial and spectral data at\
    \ once known as single shot. In [46],\nsnapshot imager seems to be related with\
    \ the referenced single shot mode inasmuch as it is presented\nas a device that\
    \ collects an entire data cube within a single integration period. Additionally,\
    \ some\nnoteworthy issues are pointed out for each acquisition mode. Whiskbroom\
    \ is a slow acquisition mode\nand pushbroom must use short enough time exposure\
    \ to avoid the risk of inconsistencies at the spectral\nband level (saturation\
    \ or underexposure). Plane scanning is not suitable for moving environments,\n\
    while single shot was reported as an under development technology that still lacks\
    \ support to higher\nspatial resolutions.\nRemote Sens. 2017, 9, 1110  \n6 of\
    \ 31 \nmake the electron in transition pass through a new energy state—due to\
    \ multiple factors, which end \nup resulting in the so-called blemish pixels.\
    \ Additional information can be found in [15], in which is \npointed out that\
    \ CCD-based sensors have higher sensitivity regarding band data acquisition while,\
    \ \non the other hand, high grade CMOS have greater quantum efficiency in NIR.\
    \ \nRegarding acquisition modes, reference [43] categorizes them in four main\
    \ ones (in fairly enough \naccordance with [44,46,47]): point scanning (or whiskbroom),\
    \ line scanning (or pushbroom), plan \nscanning and single shot (Figure 4). While\
    \ whiskbroom mode acquires all the bands pixel by pixel by \nmoving the detector\
    \ in the x-y space to store data in a band-interleaved-by-pixel (BIP) cube, \n\
    pushbroom mode proceeds similarly but, instead of pixel-based scanning, an entire\
    \ sequence of \npixels forming a line is acquired, which ends up by constituting\
    \ a band-interleaved-by-line (BIL) \ncube. Some other pushbroom characteristics\
    \ include compact size, low weight, simpler operation and \nhigher signal to noise\
    \ ratio [10]. More comparisons between pushbroom and whiskbroom modes are \npresented\
    \ in [48]. Plane scanning mode builds a band sequential (BSQ) cube constituted\
    \ by several \nimages taken at a time, each one holding spectral data regarding\
    \ a whole given x-y space. Finally, \nthere is a more recent mode that acquires\
    \ all of the spatial and spectral data at once known as single \nshot. In [46],\
    \ snapshot imager seems to be related with the referenced single shot mode inasmuch\
    \ as \nit is presented as a device that collects an entire data cube within a\
    \ single integration period. \nAdditionally, some noteworthy issues are pointed\
    \ out for each acquisition mode. Whiskbroom is a \nslow acquisition mode and pushbroom\
    \ must use short enough time exposure to avoid the risk of \ninconsistencies at\
    \ the spectral band level (saturation or underexposure). Plane scanning is not\
    \ suitable \nfor moving environments, while single shot was reported as an under\
    \ development technology that \nstill lacks support to higher spatial resolutions.\
    \ \n \nFigure 4. Hyperspectral data acquisition modes: (A) represents point scanning\
    \ or whiskbroom mode; \nin (B) presents line scanning or pushbroom mode; (C,D)\
    \ correspond to plane (or area) scanning and \nsingle shot modes, respectively\
    \ (adapted from [43]). \nThe combination of hyperspectral sensors with UAVs is\
    \ commonly made available through pre-\nbuilt systems that require dealing at\
    \ least with three parties: the sensor manufacturer, the UAV \nmanufacturer and\
    \ the party that provides system integration [15]. The list of available commercial\
    \ \nhyperspectral sensors is presented in Table 2. Beside market options, others\
    \ were developed in \nresearch initiatives (or projects). For example, in [49]\
    \ a hyperspectral sensor was developed weighing \n960 g, with support for capturing\
    \ 324 spectral bands (or half in the binned mode) between 361 and \n961 nm. In\
    \ [50], another sensor was proposed to deal with rice paddies cultivated under\
    \ water. It \nweighs 400 g and has a capturing range of 256 bands between 340\
    \ and 763 nm. In [51], a whiskbroom \nimager based on a polygon mirror and compact\
    \ spectrometers with a promising low-cost \napplicability is presented. Sellar\
    \ and Boreman [44] proposed a windowing approach, distinct from \nthe time-delay\
    \ integration technique used by some panchromatic imagers. Fabry-Perot \nFigure\
    \ 4. Hyperspectral data acquisition modes: (A) represents point scanning or whiskbroom\
    \ mode;\nin (B) presents line scanning or pushbroom mode; (C,D) correspond to\
    \ plane (or area) scanning and\nsingle shot modes, respectively (adapted from\
    \ [43]).\nThe combination of hyperspectral sensors with UAVs is commonly made\
    \ available through\npre-built systems that require dealing at least with three\
    \ parties: the sensor manufacturer, the UAV\nmanufacturer and the party that provides\
    \ system integration [15]. The list of available commercial\nhyperspectral sensors\
    \ is presented in Table 2. Beside market options, others were developed in research\n\
    initiatives (or projects). For example, in [49] a hyperspectral sensor was developed\
    \ weighing 960 g,\nRemote Sens. 2017, 9, 1110\n7 of 30\nwith support for capturing\
    \ 324 spectral bands (or half in the binned mode) between 361 and 961 nm.\nIn\
    \ [50], another sensor was proposed to deal with rice paddies cultivated under\
    \ water. It weighs 400 g\nand has a capturing range of 256 bands between 340 and\
    \ 763 nm. In [51], a whiskbroom imager based\non a polygon mirror and compact\
    \ spectrometers with a promising low-cost applicability is presented.\nSellar\
    \ and Boreman [44] proposed a windowing approach, distinct from the time-delay\
    \ integration\ntechnique used by some panchromatic imagers. Fabry-Perot interferometer\
    \ (FPI) hyperspectral imager\nwas alternatively developed by [30] as a Raman spectroscopy\
    \ device [52] behaving like a single shot\nimager, since it acquires the whole\
    \ 2D-plane at once. The data processing steps related with this sensor\nare described\
    \ in [53].\nPre- and post-ﬂight operations are required to reach level-one data,\
    \ i.e., spatially and spectrally\nreliable hyperspectral cubes, ready to use and\
    \ process. Next section is devoted to such operations.\nTable 2. List of hyperspectral\
    \ sensors (and respective characteristics) available for being coupled\nwith UAVs.\n\
    Manuf.\nSensor\nSpectral Range\n(nm)\nNo. Bands\nSpectral Resol.\n(nm)\nSpatial\
    \ Resol.\n(px)\nAcquis.\nMode\nWeight\n(g)\nBaySpec\nOCI-UAV-1000\n600–1000\n\
    100\n<5 b\n2048 d\nP\n272\nBrandywine\nPhotonics\nCHAI S-640\n825–2125\n260\n\
    5 c\n640 × 512\nP\n5000\nCHAI V-640\n350–1080\n256\n2.5 c\n640 × 512\nP\n480\n\
    5 c\n10 c\nCubert GmbH\nS 185—FIREFLEYE SE\n450–950\n125\n4 c\n50 × 50\nS\n490\n\
    S 485—FIREFLEYE XL\n355–750\n125\n4.5 c\n70 × 70\nS\n1200\n450–950\n550–1000\n\
    Q 285—FIREFLEYE QE\n450–950\n125\n4 c\n50 × 50\nS\n3000\nHeadwall\nPhotonics Inc.,\n\
    Fitchburg, MA,\nUSA\nNano HyperSpec\n400–1000\n270\n6 b\n640 d\nP\n1200 e\nMicro\
    \ Hyperspec\nVNIR\n380–1000\n775\n837\n923\n2.5 b\n1004 d\n1600 d\nP\n≤3900\n\
    HySpex\nVNIR-1024\n400–1000\n108\n5.4 c\n1024 d\nP\n4000\nMjolnir V-1240\n400–1000\n\
    200\n3 c\n1240 d\nP\n4200\nHySpex SWIR-384\n1000–2500\n288\n5.45 c\n384 d\nP\n\
    5700\nMosaicMill\nRikola\n500–900\n50 a\n10 b\n1010 × 1010\nS\n720\nNovaSol\n\
    vis-NIR microHSI\n400–800\n400–1000\n380–880\n120\n180\n150\n3.3 c\n680 d\nP\n\
    <450\nAlpha-vis micro HSI\n400–800\n350–1000\n40\n60\n10 c\n1280 d\nP\n<2100\n\
    SWIR 640 microHSI\n850–1700\n600–1700\n170\n200\n5 c\n640 d\nP\n3500\nAlpha-SWIR\
    \ microHSI\n900–1700\n160\n5 c\n640 d\nP\n1200\nExtra-SWIR microHSI\n964–2500\n\
    256\n6 c\n320 d\nP\n2600\nPhotonFocus\nMV1-D2048x1088-HS05-96-G2\n470–900\n150\n\
    10-12 b\n2048 × 1088\nP\n265\nQuest\nInnovations\nHyperea 660 C1\n400–1000\n660\n\
    -\n1024 d\nP\n1440\nResonon\nPika L\n400–1000\n281\n2.1 c\n900 d\nP\n600\nPika\
    \ XC2\n400–1000\n447\n1.3 c\n1600 d\nP\n2200\nPika NIR\n900–1700\n164\n4.9 c\n\
    320 d\nP\n2700\nPika NUV\n350–800\n196\n2.3 c\n1600 d\nP\n2100\nSENOP\nVIS-VNIR\
    \ Snapshot\n400–900\n380\n10 b\n1010 × 1010\nS\n720\nSPECIM\nSPECIM FX10\n400–1000\n\
    224\n5.5 b\n1024 d\nP\n1260\nSPECIM FX17\n900–1700\n224\n8 b\n640 d\nP\n1700\n\
    Surface Optics\nCorp., San\nDiego, CA, USA\nSOC710-GX\n400–1000\n120\n4.2 c\n\
    640 d\nP\n1250\nXIMEA\nMQ022HG-IM-LS100-NIR\n600–975\n100+\n4 c\n2048 × 8\nP\n\
    32\nMQ022HG-IM-LS150-VISNIR\n470–900\n150+\n3 c\n2048 × 5\nP\n300\nNote: a 380\
    \ in laboratory; b at FWHM; c by sampling; d Pushbroom length line (the other\
    \ dimension depends on\nsensor’s sweep distance); e without lens and global positioning\
    \ system (GPS); P—Pushbroom; S—Snapshot.\nRemote Sens. 2017, 9, 1110\n8 of 30\n\
    3. Operations Prior to Flight and Post-Acquisition Data Pre-Processing\nRegardless\
    \ of the platform from which hyperspectral data is acquired (airborne, satellite,\n\
    laboratory, etc.), its processing steps and methods are similar, with the exception\
    \ of the pre-processing\nstage, which raises some issues. For example, radiometric\
    \ noise is the prominent concern regarding\nUAS systems—mainly due to the light\
    \ conditions—while atmospheric noise needs to be also considered\nas a major source\
    \ of distortion when regarding satellite imagery. Therefore, it is very important\
    \ to\novercome such issues to obtain the proper conditions that will allow to\
    \ subsequently apply the proper\nset of common processing stages, oriented for\
    \ an intended outcome (for example, classiﬁcation or pixel\ndetection). Bioucas-Dias\
    \ [54] addresses some approaches for data restoration and spectral resolution\n\
    improvement that seem to be more suitable when applied to satellite imagery. Considering\
    \ this work’s\nfocus, calibration operations and methods for pre-processing UAS-based\
    \ hyperspectral imagery are\npresented next.\nBefore starting to acquire hyperspectral\
    \ data, all the hardware needs to be calibrated, including\nthe inertial measurement\
    \ unit (IMU) and the imager. In the latter, incoming light—under typical\nconditions—must\
    \ be managed by reducing or increasing lens aperture. Currently, the simplest\
    \ way of\nconverting the sensor digital numbers (DN) to reﬂectance is via relative\
    \ reﬂectance. In addition, [55]\npointed out the low quality of UAV georeferencing\
    \ and its negative impact, especially in pushbroom\nspectrometers. Indeed, navigation\
    \ grade GPS sensors do not facilitate hyperspectral pushbroom\nscanning on a UAV\
    \ [49]. The use of ground control points (GCPs) is absolutely necessary for improving\n\
    georeferencing. However, recent advances in direct georeferencing and imaging\
    \ technologies—like the\nintegrated global navigation satellite systems (GNSS)\
    \ and inertial navigation systems (INS)—enable\nprecise mapping using a minimal\
    \ number of GCPs.\nForeseeing radiometric calibration at the\npre-processing stage,\
    \ white references are placed on the ground, at least at four pixels wide and\n\
    preferably at 1 m2. Low-cost (and low-quality) calibration panels can be used\
    \ towards radiometric\nadjustments based on estimations that, however, cannot\
    \ beat the accuracy provided by spectralon\npanels. Recently, Headwall [56] launched\
    \ a VNIR E-series hyperspectral sensor with a built-in module\nfor radiometric\
    \ corrections, claiming that there is no need for placing such ground references.\
    \ Still,\nvalidation tests are required. IMU’s calibration should be performed\
    \ against the earth’s local magnetic\nﬁeld, otherwise the UAV’s orientation can\
    \ get compromised [15].\nAfter the hyperspectral data acquisition stage, some\
    \ pre-processing operations are required.\nDuan et al. [57] consider pre-processing\
    \ a mandatory prerequisite to extract quantitative information\nof the sensed\
    \ area. Hyperspectral data acquired by traditional platforms like satellites—whose\n\
    limitations were identiﬁed in [29]—and aircrafts is usually inﬂuenced by climate—among\
    \ others\nfactors pointed out by Pölönen [30]—and this hampers its use, especially\
    \ in precision agriculture,\nwhere information detail matters. On the other hand,\
    \ UAVs have the advantage of ﬂying closer to the\nearth’s surface wherein the\
    \ inﬂuence of atmosphere is not as signiﬁcant. For this reason, there is no\n\
    need for atmospheric corrections as it would be in traditional platforms. However,\
    \ low acquisition\nheight and unstable movement of the UAV, along with the viewing\
    \ angle and high inﬂuence of\nmicro-relief on illumination, make the pre-processing\
    \ operations more difﬁcult [58].\nThe need for radiometric and geometric corrections\
    \ [59] and spectral calibration [49] while\nusing UAV-carried hyperspectral sensors\
    \ to preserve acquired data scientiﬁc rigor was highlighted.\nIn addition, sensors\
    \ need to be recalibrated regularly. Regarding radiometric calibration, coefﬁcient\n\
    might be obtained in the laboratory to achieve conversion to radiance [59]. In\
    \ [49], optical integrating\nsphere USR-SR 2000S (Labsphere Inc., North Sutton,\
    \ NH, USA) with four electric current stabilized\nlight sources (labelled as SI\
    \ and INGAAS lamps) producing calibrated irradiance levels of traceable\nuncertainties\
    \ was used for radiometric correction purposes. Nevertheless, some factors—for\
    \ example,\nsensor’s transportation and installation—are likely to lead to calibration\
    \ loss that, in turn, results in a\nradiometric performance decreasing [57]. Such\
    \ phenomenon can be assessed by using targets of known\nreﬂectance in the ﬁeld\
    \ to later check data radiometric quality. For geometric corrections, reference\
    \ [49]\nsuggests triangulation transformation. Both radiometric and geometric\
    \ corrections can be done\nRemote Sens. 2017, 9, 1110\n9 of 30\nusing software\
    \ tools—whenever these are provided by the hyperspectral sensor’s manufacturer—,\n\
    which should georegister and convert raw DN data cubes to radiance. One of the\
    \ ways of achieving\ngeoregistration is to combine the external orientation data\
    \ gathered during the flight with sensor model—\ninterior orientation—and elevation\
    \ model. In [58], it is mentioned that most of available pre-processing\nsoftware\
    \ uses the exact IMU position and orientation. Presumably, to be able of using\
    \ IMUs on-board a\nUAV, a compromise between IMU weight and the UAV payload needs\
    \ to be found. Moreover, spectral\ncalibration needs be carried out by using standard\
    \ methodologies like Lucieer et al. [49] did, using\nopen-ray line source producing\
    \ sharp gas absorption features of well-known wavelengths [60]. These\npre-processing\
    \ operations result in corrected data, which allows for comparisons between different\n\
    time series and even data acquired by different hyperspectral sensors.\nQuality\
    \ assessment of hyperspectral data is a relevant topic for pre-processing [57].\
    \ An important\ncriterion for hyperspectral data quality characterization is the\
    \ signal-to-noise ratio (SNR). In [61], it was\nstated that quantitatively analyzing\
    \ hyperspectral data requires the precise evaluation of the SNR.\nEssentially,\
    \ for optimizing the use of data, high ratio is needed and, contrastingly, low\
    \ ratio must be\nremoved due to its negative effect on data.\nAccording to Bioucas-Dias\
    \ [54], signal correction/improvement ﬁts in a group of approaches\nidentiﬁed\
    \ as data fusion, found in works such as [62–64], that refers to the class of\
    \ methods capable\nof dealing with spectral and spatial data merging. Such methods\
    \ include restoration (i.e., noise\nreduction and spectral improvement), spatial\
    \ data fusion (for resolution enhancement based on\nsubpixel information), spatial-spectral\
    \ data fusion (refereeing to resolution improvement based on\nfusion of different\
    \ parts of a hyperspectral imaging (HSI) cube, considering a cubes’ different\
    \ bands)\nand multisource data fusion (resolution improvement considering more\
    \ than one data provider,\nfor example, satellites and UAVs).\nA ﬁnal remark on\
    \ this section goes to data storage related issues during the data acquisition\n\
    stage, mainly due to two reasons: on the one hand, (1) huge amounts of data are\
    \ generated with\nthe use of hyperspectral sensors and, on the other hand; (2)\
    \ UAVs’ have a limited payload, which\nimplies the use of a conﬁned number of\
    \ lightweight storage devices. To tackle these issues, authors\nin [65] proposed\
    \ methods regarding hyperspectral images captured on-board UAVs during mission\n\
    ﬂights. There is a pre-processing step they used to transform hyperspectral data\
    \ cubes into speech-like\nsignals. Afterwards, those signals undergo a compression\
    \ stage that processes them by means of a\nlinear prediction.\nAfter pre-processing\
    \ operations over acquired data, the next stage is to perform data processing\n\
    and analysis, which is addressed in the following section.\n4. Data Processing\
    \ and Analysis\nThis section focuses on approaches around hyperspectral data processing\
    \ and analysis—including\ntarget detection, classiﬁcation and vegetation indices\
    \ (VI) operations—which are usually carried out\nafter pre-processing operations\
    \ that handle radiometric, geometric or even atmospheric calibrations.\n4.1. Dimension\
    \ Reduction\nHyperspectral data pre-processing stage is usually followed by a\
    \ dimension reduction operation.\nFollowing this, Burger and Gowen [66] addressed\
    \ the importance of handling hyperspectral data\nmore efﬁciently to tackle dimensionality\
    \ issues that have a malign effect in computational processing\nin general, as\
    \ well as in approaches like neural networks (Hughes phenomenon), in particular\
    \ [67].\nAccording to the authors, there are some methods for compression (spatial\
    \ domain in image processing)\nand dimension reduction (reducing of hyperspectral\
    \ cubes’ dimensions) that aim to achieve efﬁcient\ndata handling: wavelet compression,\
    \ band selection and projection methods. Within the former,\nthere is the principal\
    \ component analysis (PCA) method to concentrate the spectral variance that\n\
    can be combined with others (like wavelet compression). Burger and Gowen [66]\
    \ highlighted the\nmaximum noise fraction (MNF) as a PCA-based method capable\
    \ of achieving good performance in\nRemote Sens. 2017, 9, 1110\n10 of 30\nclassiﬁcation\
    \ with low distortion rates, even better than the PCA alone [68,69]. Random projection\
    \ and\nindependent component analysis (ICA) are also mentioned as relevant projection\
    \ methods, along with\nthe multivariate curve resolution (MCR) analysis, which\
    \ aims to decompose mixed spectra into pure\ncomponents and corresponding concentrations.\
    \ In [54], dimension reduction problems belong to the\ndata fusion scope and are\
    \ handled by spectral data fusion approaches, in which reduction is achieved\n\
    by redundancy analysis.\n4.2. Target and Anomaly Detection\nEssentially, target/anomaly\
    \ detection consists in a binary classiﬁcation technique that labels\nevery pixel\
    \ in the hyperspectral cube as belonging to target/background or outlier/background,\n\
    respectively [70]. Due to some nuances establishing the speciﬁc goal of ﬁnding\
    \ a target/anomaly\namong data through the classiﬁcation of two classes, this\
    \ detection approach was detached from the\nclassiﬁcation methods that will be\
    \ addressed after this section. A graphical summary consisting of a\ntaxonomy\
    \ regarding target/anomaly detection is provided at the end of this subsection.\n\
    Manolakis and Shaw [71] have been bridging the gap between remote sensing and\
    \ signal\nprocessing by providing an extensive overview on the statistical tools\
    \ (mainly based on [72]) that can\nbe used to handle hyperspectral data concerning\
    \ pixels of interest. More speciﬁcally, they address\ntarget detection that refers\
    \ to identifying a speciﬁc material in the HSI cube. It involves the binary\n\
    hypothesis testing problem in which each pixel is assigned to a target or non-target\
    \ label. In this\ntask, the criterion is to maximize the detection probability\
    \ while keeping false alarms at a predeﬁned\ndesirable rate (also known as Neyman-Person\
    \ criterion [72]).\nReﬂectance spectra are stored in libraries and must then be\
    \ compared with the acquired data,\nafter conversion to reﬂectance and considering\
    \ some corrections related with distortions such as\natmospheric noise. The absence\
    \ of a priori information (libraries or the needed data to work with a\ntarget\
    \ reﬂectance) calls for an approach in which spectral signatures that differ from\
    \ the background\nare searched (anomaly detection).\nLikelihood ratio (LR) is\
    \ one of the most known approaches to check the target probability. It is\ngiven\
    \ by Equation (1):\n∆(x) = p( x | signal present)\np(x | signal absent )\n(1)\n\
    in which ∆(x) > η (threshold). The threshold that separates targets from non-targets\
    \ should be set\nto properly balance the probability of false alarms and detection.\
    \ Receiving operating characteristic\n(ROC) curves are useful to analyze such\
    \ a trade-off.\nWhenever there are unknown targets and background parameters,\
    \ a trick can be used: replacing\nunknown parameters in the LR by maximum likelihood\
    \ estimates. Thresholds should be automatically\nﬁgured out in practical applications\
    \ (i.e., without an operator’s intervention), enabling a spontaneous\ndetection.\
    \ To that end, Manolakis and Shaw [71] underline the importance of the constant\
    \ false alarm\nrate (CFAR) processor for dealing with misclassiﬁcations.\nIn [16],\
    \ the importance of choosing a good threshold to minimize the occurrence of missing\n\
    targets and false alarms is also highlighted. While a ROC provides the means to\
    \ get the threshold\nvariation involved in the detectors evaluation, Bayes and\
    \ Newman-Pearson criterions are suitable\nmethods for optimum threshold selection\
    \ in cases wherein the conditional densities used in LR\nratio calculus are completely\
    \ known. However, in most real cases, probability densities rely on\nunknown targets\
    \ and backgrounds. A widely used workaround is to replace unknown parameters\n\
    with maximum-likelihood estimates through a process known as generalized likelihood\
    \ ratio (GLR),\nfrom where adaptive detectors result. However, as the target class\
    \ is very small, a problem arises\nrelated with adaptive detectors: target density\
    \ parameters become difﬁcult to estimate. In practice,\ntarget detection should\
    \ rely on automatic threshold setters, considering that a high false alarm rate\
    \ has\nits computational costs. Detectors based on CFAR represent a key approach\
    \ to solve the referred issue\ninasmuch as they are immune to background variations\
    \ and noise, according to another Manolakis\nRemote Sens. 2017, 9, 1110\n11 of\
    \ 30\nand Shaw work [16]. After some performance considerations, they have proposed\
    \ guidelines to\ndesign good detection methods, dividing them into main classes:\
    \ full pixel and subpixel. Both will be\naddressed later in more detail.\nDetection\
    \ algorithms are many but their application depends on some factors, such as:\
    \ type of\nmodels used for spectral variability, pixel purity and models used\
    \ for describing mixed pixels. As for\nspectral variability, it is usually described\
    \ in the following forms:\n•\ngeometrically: uses a subspace of the spectra in\
    \ which the matrix deﬁning the variability\nof the subspace can be a spectra signatures\
    \ library (on data or even vectors), obtained from\nstatistical techniques;\n\
    •\nstatistically: spectral variability is described accordingly with probability\
    \ distribution models.\nCalculus such as mean vector and covariance matrix are\
    \ applied in different moments under a\nmultivariate normal distribution assumption.\
    \ Thus, variability can be measured from a uniform\ndistribution of the data space.\n\
    Manolakis and Shaw [71] reinforced that variations in the material surface, along\
    \ with factors\ninduced by atmospheric conditions, sensor noise, materials composition\
    \ and location (among\nothers) usually change spectra readings. Moreover, most\
    \ of the spectra readings acquired for real\napplications are likely to be random\
    \ due to the combination of certain variability factors, which makes\ndirect correlations\
    \ to spectral libraries—reﬂectance spectra collections measured from materials\
    \ of\nknown composition [73]—infeasible. According to Manolakis and Shaw, the\
    \ description of such\nstatistical variability is more suitable to be analyzed\
    \ using probabilistic models, which can include the\nfollowing approaches:\n•\n\
    Probability Density Models: this kind of models consist in a scatter set of the\
    \ reﬂectance values for\na range of spectral bands that aims to identify different\
    \ spectral classes in a scene using clustering\nalgorithms (e.g., k-means) and\
    \ classiﬁcation methods (e.g., color attribution);\n•\nSubspace models: are applied\
    \ to analyze the variability within an M-dimensional band space, from\na K-dimensional\
    \ set, where M < K. PCA is one of the approaches within this probabilistic model;\n\
    •\nLinear spectral mixing models: are used to estimate the composition of the\
    \ image’s pixels in\nthose cases wherein there are pixels composed of a small\
    \ number of unique spectral signatures\ncorresponding to different components\
    \ (endmembers).\nAs aforementioned, target detection methods can be classiﬁed\
    \ into the following fundamental\ntypes: full pixel and subpixel [16,71]. The\
    \ former refers to pure pixel that does not have “contaminating”\ninterference\
    \ from the background. On the other hand, sub-pixel methods are more challenging\
    \ since\nthey involve mixed spectra, corresponding to distinct materials.\nThere\
    \ are two main ways of analyzing mixed spectra: (1) using linear mixed models\
    \ (LMM) [72]\nthat assume that a pixel is constituted by a linear small set of\
    \ spectra known as endmembers (also in\nagreement with [16]); and (2) through\
    \ stochastic mixing models in which there is a randomness and\nindependency of\
    \ the endmember spectra.\nIt turns out that mixed spectra can be faced as spectral\
    \ unmixing problems. According to\nBioucas-Dias [54] spectral unmixing (see, for\
    \ example, [74,75]) purpose is to restore the ability of\nascertain materials,\
    \ i.e., to retrieve information of spectral endmembers and their abundances. Several\n\
    conditions can compromise that ability, such as light, intimate mixtures and the\
    \ spectral resolution of\nthe sensor itself. The general name for the mathematical\
    \ model that deals with this kind of issues is\nthe radiative transfer theory\
    \ (RTT). In the spectral unmixing scope, there are several approaches such\nas\
    \ linear unmixing (inverse problem formulation for ICA analysis, widely used in\
    \ the past decade),\npure pixel-based (which assumes the presence in the data\
    \ of one or more pure pixels per endmember),\nbased on non-pure pixels (endmembers\
    \ are inferred by ﬁtting a minimum volume simplex to data in\nthe case of lack\
    \ of pure pixels) and sparse regression unmixing (a recent method that demands\
    \ ground\nspectral libraries to ﬁnd the optimal subset of signatures that can\
    \ best model each pixel). Unmixing is\nassociated to target detection by convenience\
    \ but it can also be applied to classiﬁcation problems.\nRemote Sens. 2017, 9,\
    \ 1110\n12 of 30\nFor detection problems formulation, background only or background\
    \ and target constitute the\ncompeting hypothesis. Unknown parameters such as\
    \ the background covariance matrix have to\nbe estimated. Then, a generalized\
    \ likelihood ratio test (GLRT) approach [72] can be applied as an\nadaptive detector.\n\
    4.2.1. Full Pixel Detection\nUsually, the process for full pixel detection includes\
    \ clustering two groups of pixels separated\nby target and background. Then, a\
    \ LR (concept depicted on Figure 5) or a GLR approach is applied\nto decide if\
    \ a certain pixel falls in the target or in the background, by analyzing its position\
    \ relatively\nto some scalar boundary decision curve (scalar threshold). According\
    \ to [16], the use of normal\nprobability models lead to a better performance.\n\
    Remote Sens. 2017, 9, 1110  \n12 of 31 \n \nFor detection problems formulation,\
    \ background only or background and target constitute the \ncompeting hypothesis.\
    \ Unknown parameters such as the background covariance matrix have to be \nestimated.\
    \ Then, a generalized likelihood ratio test (GLRT) approach [72] can be applied\
    \ as an \nadaptive detector. \n4.2.1. Full Pixel Detection \nUsually, the process\
    \ for full pixel detection includes clustering two groups of pixels separated\
    \ \nby target and background. Then, a LR (concept depicted on Figure 5) or a GLR\
    \ approach is applied \nto decide if a certain pixel falls in the target or in\
    \ the background, by analyzing its position relatively \nto some scalar boundary\
    \ decision curve (scalar threshold). According to [16], the use of normal \nprobability\
    \ models lead to a better performance. \n \nFigure 5. LR detector approach, according\
    \ to [16]. A static method classifies a given spectrum as target \nor background,\
    \ depending on a threshold. \nTo address the problem of the overlapping background\
    \ and target classes that might lead to \nclassification errors, some approaches\
    \ are available: LR detectors and adaptive matched filters \n(AMF). The former\
    \ uses multivariate normal vectors that can be checked for a spectrum through\
    \ the \nprobability density function that considers a mean vector and a covariance\
    \ matrix. The design of a \nNeyman-Pearson detector can be made if the probability\
    \ density function is satisfied, for example, \nwith some matched filter like\
    \ Fisher’s linear discriminant, which enables the detection by using an \nautomatically\
    \ calculated threshold. Alternatively, an AMF approach can also be applied to\
    \ the same \nend. It uses a sample covariance matrix (from libraries or local\
    \ data) distribution, determined by \nRichmond [76] and it is focused on the normal\
    \ distribution of the background under the test “target \nabsent” hypothesis.\
    \ For target detection, Spectral Angle Mapper (SAM), Equation (2), can be used\
    \ as \na valid algorithm if the conditions comply with well separated distributions\
    \ and small dispersions. \nOptimal properties are not applicable here, accordingly\
    \ with Manolakis [71]. \nSAM = ∠(ݔ,ݕ)= arccos ቆݔ்ݕ\nห|ݔ|หห |ݕ!|หቇ \n(2) \nwhere\
    \ ݔ்ݕ is the dot product of vectors x and y. \n4.2.2. Subpixel Target Detection\
    \ \nIf it is known that the target of interest only occupies part of the pixel\
    \ (presence of mixed \nbackground), another set of approaches should be applied,\
    \ namely the unstructured and structured \nbackground models. \nUnstructured background\
    \ models are supposed to be used with backgrounds that include \nadditive noise,\
    \ multivariate normal distribution, mean 0 (forced) and a covariance matrix. The\
    \ \ncompeting hypothesis in this approach is shown in Equation (3): \n൜\nH0: x\
    \ = b (target absent)\nH1: x = Sα + b (target present) \n(3) \nFigure 5. LR detector\
    \ approach, according to [16]. A static method classiﬁes a given spectrum as target\n\
    or background, depending on a threshold.\nTo address the problem of the overlapping\
    \ background and target classes that might lead to\nclassiﬁcation errors, some\
    \ approaches are available: LR detectors and adaptive matched ﬁlters\n(AMF). The\
    \ former uses multivariate normal vectors that can be checked for a spectrum through\n\
    the probability density function that considers a mean vector and a covariance\
    \ matrix. The design of\na Neyman-Pearson detector can be made if the probability\
    \ density function is satisﬁed, for example,\nwith some matched ﬁlter like Fisher’s\
    \ linear discriminant, which enables the detection by using an\nautomatically\
    \ calculated threshold. Alternatively, an AMF approach can also be applied to\
    \ the same\nend. It uses a sample covariance matrix (from libraries or local data)\
    \ distribution, determined by\nRichmond [76] and it is focused on the normal distribution\
    \ of the background under the test “target\nabsent” hypothesis. For target detection,\
    \ Spectral Angle Mapper (SAM), Equation (2), can be used as\na valid algorithm\
    \ if the conditions comply with well separated distributions and small dispersions.\n\
    Optimal properties are not applicable here, accordingly with Manolakis [71].\n\
    SAM = ∠(x, y) = arccos\n\x12\nxTy\n||x||| |y!||\n\x13\n(2)\nwhere xTy is the dot\
    \ product of vectors x and y.\n4.2.2. Subpixel Target Detection\nIf it is known\
    \ that the target of interest only occupies part of the pixel (presence of mixed\n\
    background), another set of approaches should be applied, namely the unstructured\
    \ and structured\nbackground models.\nRemote Sens. 2017, 9, 1110\n13 of 30\nUnstructured\
    \ background models are supposed to be used with backgrounds that include additive\n\
    noise, multivariate normal distribution, mean 0 (forced) and a covariance matrix.\
    \ The competing\nhypothesis in this approach is shown in Equation (3):\n(\nH0\
    \ : x = b (target absent)\nH1 : x = Sα + b (target present)\n(3)\nwhere Sα corresponds\
    \ to a spectral signature subspace model, b is the background and x are the\n\
    testing pixels.\nIn the presence of such backgrounds, it is assumed that materials\
    \ are spread independently and\nidentically within a given pixel. According to\
    \ Manolakis [16], the design of a practical detector could\ninvolve merging the\
    \ GLR detector proposed by Kelly [77,78]—which includes the threshold to set\n\
    up the probability of detection (Pd) and the probability of false alarm (Pfa)—and\
    \ Reed and Yu [79]\napproach using a multivariate analysis of variance formulation.\
    \ Such merge results in the ability of\nestimating Mahalanobis distance of the\
    \ testing pixel, from background mean, which earns adaptability\nthrough CFAR\
    \ propriety. The author highlighted its usefulness for anomaly detection in hyperspectral\n\
    data applications (approach for spectral data with unknown target). Regarding\
    \ target detection, one\nmust consider that the amount of background is variable\
    \ in unstructured cases. Thereby, estimators\nrelying on variance—directly related\
    \ with the ﬁll factor of the target—can be used, such as adaptive\ncoherence cosine\
    \ (ACE) estimator [80,81]. On the other hand, structured background modelled by\n\
    a subspace models have, as the only source of randomness, additive noise with\
    \ unknown variance.\nManolakis et al. [16] proposed a GLRT detector [72,82,83],\
    \ relying in the substitution of likelihood ratio\nby maximum-likelihood estimates\
    \ of the unknown quantities. Its geometrical interpretation is also\nprovided\
    \ to help understanding criteria for ﬁtting testing pixels in the different models,\
    \ namely full\nlinear model (target plus background) and reduced model (background).\
    \ Conclusions regarding target\npresent/absent can be taken based on such ﬁtting.\n\
    For materials that overlap with each other making their spectral distinction difﬁcult,\
    \ a nonlinear\ndecision boundary can be used. Manolakis et al. [16] provided an\
    \ example on how to distinguish cars\nand trees overlapping in a scene. The plot\
    \ of two-band data as points in two-dimensional space with\nthe reﬂectance values\
    \ as coordinates gives origin to a couple of distinguishable data clusters related\n\
    with the evolved elements. According to the authors, this is the essence of multiple\
    \ spectra-band\ndata exploitation in remote sensing spectroscopy. However, both\
    \ UAS ﬂight altitudes and sensors’\nimproved spatial resolution should relieve\
    \ mixed spectra issues in tasks related with forestry and\nagriculture monitoring\
    \ and assessment.\nMeanwhile, other developments were made by Nasrabadi [70],\
    \ who addressed anomaly and\ntarget detection with recent statistical signal processing\
    \ and machine learning approaches. In spite of\nits experimental results being\
    \ around full-pixel targets, he claimed that the addressed methods can be\nextended\
    \ to sub-pixel. For such reason, this work was referred without being assigned\
    \ either to one\nor other targeting method. According the author, anomaly detection\
    \ aims the pattern recognition of\ndetected objects that stand out the cluttered\
    \ background. Along with some already mentioned anomaly\ndetectors, such as Reed-Xiaoli\
    \ (RX) [79] and subspace-based [84] detectors, others were highlighted as\nemerging\
    \ approaches, more speciﬁcally, Kernel RX [85]—non-linear version of RX detector\
    \ to deal with\nthe lack of Gaussian distribution behavior of clutter background,\
    \ which cannot be easily modelled\ndue to insufﬁcient training data and knowledge\
    \ about Gaussian mixtures—and support vector data\ndescription (SVDD) [86], which\
    \ is a classiﬁer capable of estimating support region for a given data set,\n\
    avoiding prior information of distribution. Anomalous change detection (ACD) was\
    \ deﬁned by [87] as\nan algorithm capable of suppressing environmental changes\
    \ to highlight materials transformation,\ngiving a couple of hyperspectral images.\
    \ Additionally, they provided comparison data between\nseveral ACD algorithms.\
    \ Regarding the target detection and besides spectral matched ﬁlter [88],\nmatched\
    \ subspace [82] and orthogonal subspace projection [89], also kernel-based target\
    \ detectors\nRemote Sens. 2017, 9, 1110\n14 of 30\n(proposed considering [90])—capable\
    \ of extending previous target detectors, thus enabling the analysis\nof nonlinear\
    \ features through kernels—and continuum fusion (CF) detectors (e.g., [91])—for\
    \ dealing\nwith the variability of target detection models parameters—were presented.\
    \ Additionally, theoretical\nbackground on sparse representation classiﬁers relying\
    \ on training data regarding all the classes\nis provided.\nStill concerned with\
    \ target detection gaps (Figure 6)—related with material discrimination in the\n\
    presence of pixel’s mixed spectra and the large number of false alarms outputted\
    \ by algorithms relying\non classical detection theory and physics-based signal\
    \ models—, false alarm mitigation (FAM) and\ntarget identiﬁcation (TID) algorithms\
    \ were recently developed and presented, after a set of introductory\nsubjects,\
    \ including spectral variability, subpixel targets modelling, likelihood detectors,\
    \ matched ﬁlters\nand ROC-based performance analysis [92]. While FAM [93] is considered\
    \ a promising approach to\ndeal with the aforementioned issue related with false\
    \ alarm rates, TID is useful to determine if a given\npixel within a certain detector\
    \ contains or not the target. The latter is also suitable for mixed spectral\n\
    problems, which are addressed by unmixing techniques and material identiﬁcation\
    \ through library\nspectra association. Typical approaches are inspired by existing\
    \ methods (e.g., [94–96]).\nRemote Sens. 2017, 9, 1110  \n14 of 31 \nintroductory\
    \ subjects, including spectral variability, subpixel targets modelling, likelihood\
    \ detectors, \nmatched filters and ROC-based performance analysis [92]. While\
    \ FAM [93] is considered a promising \napproach to deal with the aforementioned\
    \ issue related with false alarm rates, TID is useful to \ndetermine if a given\
    \ pixel within a certain detector contains or not the target. The latter is also\
    \ suitable \nfor mixed spectral problems, which are addressed by unmixing techniques\
    \ and material \nidentification through library spectra association. Typical approaches\
    \ are inspired by existing \nmethods (e.g., [94–96]). \n \nFigure 6. Target detection\
    \ overall summary organized by goal, approach and testing hypothesis. \nTerms\
    \ association is made through color code. Grey and white labels are related to\
    \ more than one \ngoal. For full-pixel detection, an adaptive matched filter (AMF),\
    \ continuum fusion and kernel-based \nalgorithms can be applied. Linear unmixing,\
    \ sparse regression and non-/pure pixel-based approaches \nregard to sub-pixel\
    \ detection (mixed material spectra cases). Anomaly detection, which is used to\
    \ \nrecognize patterns standing out from cluttered backgrounds, can be addressed\
    \ with approaches based \non Reed-Xiaoli (RX), support vector data description\
    \ (SVDD) and anomalous change detection (ACD). \nGrey and white labels constitute\
    \ the taxonomy for supporting statistical tools. Spectral angle mapper \n(SAM),\
    \ Mahalanobis distance and likelihood ratio (LR) aims to test if a pixel is a\
    \ target or not, \nconsidering a threshold to discriminate spectra of interest\
    \ from background. Such threshold should \nconsider a trade-off between false\
    \ alarm and probability detection (towards Neyman-Person criterion \nsatisfaction),\
    \ which can be analyzed through receiving operator characteristic (ROC) curves.\
    \ Common \noccurrences of probability densities relying in unknown targets and\
    \ backgrounds demand a \ngeneralized likelihood ratio (GLR) workaround—the basis\
    \ of adaptive detectors—consisting in \nreplacing unknown parameters by maximum\
    \ likelihood estimates. Constant false alarm rate (CFAR) \npromotes setting up\
    \ detectors immune to background variations and noise. False alarm mitigation\
    \ \n(FAM) and target identification (TID) are self-explanatory concepts regarding\
    \ to recent developments \nin algorithms. \nTo conclude this subsection devoted\
    \ to the targets’ detection within hyperspectral data, there \nare other works\
    \ that are worthy of being consulted [54] and some related references [71,97,98]\
    \ that \nmight complete and update some of the previously addressed approaches\
    \ as, for example, anomaly \ndetection (identification of pixels significantly\
    \ different from neighboring background in which no \nFigure 6. Target detection\
    \ overall summary organized by goal, approach and testing hypothesis.\nTerms association\
    \ is made through color code. Grey and white labels are related to more than one\n\
    goal. For full-pixel detection, an adaptive matched ﬁlter (AMF), continuum fusion\
    \ and kernel-based\nalgorithms can be applied. Linear unmixing, sparse regression\
    \ and non-/pure pixel-based approaches\nregard to sub-pixel detection (mixed material\
    \ spectra cases). Anomaly detection, which is used\nto recognize patterns standing\
    \ out from cluttered backgrounds, can be addressed with approaches\nbased on Reed-Xiaoli\
    \ (RX), support vector data description (SVDD) and anomalous change detection\n\
    (ACD). Grey and white labels constitute the taxonomy for supporting statistical\
    \ tools. Spectral angle\nmapper (SAM), Mahalanobis distance and likelihood ratio\
    \ (LR) aims to test if a pixel is a target or not,\nconsidering a threshold to\
    \ discriminate spectra of interest from background. Such threshold should\nconsider\
    \ a trade-off between false alarm and probability detection (towards Neyman-Person\
    \ criterion\nsatisfaction), which can be analyzed through receiving operator characteristic\
    \ (ROC) curves. Common\noccurrences of probability densities relying in unknown\
    \ targets and backgrounds demand a generalized\nlikelihood ratio (GLR) workaround—the\
    \ basis of adaptive detectors—consisting in replacing unknown\nparameters by maximum\
    \ likelihood estimates. Constant false alarm rate (CFAR) promotes setting\nup\
    \ detectors immune to background variations and noise. False alarm mitigation\
    \ (FAM) and target\nidentiﬁcation (TID) are self-explanatory concepts regarding\
    \ to recent developments in algorithms.\nRemote Sens. 2017, 9, 1110\n15 of 30\n\
    To conclude this subsection devoted to the targets’ detection within hyperspectral\
    \ data, there\nare other works that are worthy of being consulted [54] and some\
    \ related references [71,97,98] that\nmight complete and update some of the previously\
    \ addressed approaches as, for example, anomaly\ndetection (identiﬁcation of pixels\
    \ signiﬁcantly different from neighboring background in which no\nprior knowledge\
    \ is considered), signature-based target detection (a matched ﬁlter that ﬁnds\
    \ pixels\nrelying on prior spectra knowledge), sparse representation target detection\
    \ (classiﬁcation uses sparse\nrepresentation given by a short sample of target\
    \ and background libraries) and nonlinear detectors\n(machine learning applications).\n\
    4.3. Other Classiﬁcation Methods\nFor Manolakis and Shaw [71], classiﬁcation methods\
    \ consist of the assignment of pixels to classes\nor themes (also known as thermographic\
    \ maps). For instance, in land cover classiﬁcation tasks, the\nuser has to determine\
    \ classes by using training sets, spectral libraries and/or ground truth information,\n\
    considering a probability minimization of misclassiﬁcation as criteria.\nBurger\
    \ and Gowen [66] point out the availability of a wide set of classiﬁcation and\
    \ regression\nalgorithms, including unsupervised methods like k-nearest neighbor\
    \ and hierarchal clustering\nsupervised classiﬁcation such as partial least squares\
    \ discriminant and SAM. With regard to\nstatistical methods, [67] starts by explaining\
    \ that class discrimination must rely on some statistic\nmeasurement—like Bhattacharyya\
    \ distance [99]—in which there are typically involved class\nconditional density\
    \ functions, desirable for discrimination. Such functions have a mean value and\n\
    a covariance matrix associated. It turns out that those classes result from maximum\
    \ likelihood\nclassiﬁers—that can be applied through, for example, the minimum\
    \ distance to means, a Fischer’s\nlinear discriminant and a Gaussian classiﬁer—that\
    \ should be applied considering two main aspects:\nvariance behavior and spectra\
    \ correlation. According to [67], neural networks perform well on\nclassiﬁcation\
    \ but are demanding in terms of computation and training data sets. Feature extraction\n\
    for class discrimination might be achieved using one of two approaches: decision\
    \ boundary feature\nmatrix (DAFE) or decision boundary feature extraction (DBFE).\
    \ Finally, a data analysis paradigm was\nproposed as well as a concrete example\
    \ using a mall—located in Washington, District of Columbia\n(DC), USA—in which\
    \ the ﬁnal result is the discrimination of the scene’s elements, including roofs,\n\
    roads and grass.\nPlaza et al. [100] revised some alternative approaches to the\
    \ classical statistical analysis\n(e.g., [90,101–105]) and proposed some methods\
    \ based on support vector machines (SVM) and\nMarkov-based techniques. To perform,\
    \ SVMs rely on kernel functions that can be one of the following\nthree types:\
    \ Gaussian radial basis function (RBF), polynomial and based on SAM. They noticed\
    \ that\nwith a small number of training sets, more speciﬁcally 10, 20, 40, 60,\
    \ 80, and 100 pixels of a given class,\nrandomly extracted from a wider set, all\
    \ of the three kernel functions allowed the SVM approach to\nreach above 92% of\
    \ classiﬁcation accuracy with the 10-pixel sample. The full training sample (of\
    \ the\nwider set) did not increase this rate signiﬁcantly. Transductive SVM (TSVM)\
    \ was also explored by\nthe authors, who deﬁned it as an approach “based on speciﬁc\
    \ iterative algorithms, which gradually\nsearch the optimal discriminant hyperplane\
    \ in the feature space with a transductive process that\nincorporates unlabeled\
    \ samples in the training phase”. A comparison made between SVM and TSVM\nfrom\
    \ a sample obtained of a training samples subset, which considered some nuances—like\
    \ variables\nto control the error for misclassiﬁcation—was carried out and the\
    \ results for the TSVM approach were\nbetter, regarding the conditions speciﬁed\
    \ by the authors. Kernel-based classiﬁers related with spectral\n(e.g., Euclidian\
    \ [106]) and spatial (e.g., using means and standard deviations) domains were\
    \ then\npresented for a contextual information integration approach that leads\
    \ to better classiﬁcation results\nwhen compared to both of the aforementioned\
    \ approaches. Additionally, they proposed an enhanced\napproach based on extended\
    \ morphological proﬁles and Markov’s random ﬁelds, along with a method\nfor spectral\
    \ unmixing. A recent study [107] shows that hyperspectral image transductive classiﬁcation\n\
    is still being used, this time as an approach based on a co-training process to\
    \ manage spectral and\nRemote Sens. 2017, 9, 1110\n16 of 30\nspatial information.\
    \ Three kinds of classiﬁers (spectral, frequency-based and morphology-based spatial\n\
    proﬁle) belonging to imagery are ﬁrstly learned from the originally labelled part\
    \ of the input data.\nThen, an iterative co-training phase takes over wherein\
    \ classiﬁers are learned from imagery data.\nAlso, a separated set of classiﬁers\
    \ is used to predict unlabeled pixels. According to the authors, this\napproach\
    \ overcomes the accuracy of the ones found in the state-of-the-art referring to\
    \ the same class\nof classiﬁers.\nBioucas-Dias [54] agrees with the previous authors\
    \ by stating that the goal, underlying\nclassiﬁcation problems, is to attribute\
    \ labels to each pixel (e.g., [108,109]). They have enumerated\na set of techniques\
    \ that can be applied to classiﬁcation, including: feature mining (which, in turn,\n\
    is subdivided in feature extraction and selection approaches), supervised classiﬁcation\
    \ (to discriminate\nclasses of pixels based on, for example, SVM) and semi-supervised\
    \ classiﬁcation (enlargement of the\ntraining set composed by labelled samples\
    \ by considering unlabeled ones).\n4.4. Vegetation Indices\nVIs enable the analysis\
    \ of several proprieties in leaf area index (LAI) and the assessment of\nbiophysical,\
    \ physiological, or biochemical crop parameters. In [110], VIs were classiﬁed\
    \ as broad and\nnarrow bands, being the latter group considered more proper for\
    \ hyperspectral data [111]. Some\nof the addressed narrowband indices include\
    \ chlorophyll absorption ratio index (CARI), greenness\nindex (GI), greenness\
    \ vegetation index (GVI), modiﬁed chlorophyll absorption ratio index (MCARI),\n\
    modiﬁed normalized difference vegetation index (MNDVI), simple ratio (SR, including\
    \ narrowband\nvariants 1–4), transformed chlorophyll absorption ratio index (TCARI),\
    \ triangular vegetation index\n(TVI), modiﬁed vegetation stress ratio (MVSR),\
    \ modiﬁed soil-adjusted vegetation index (MSAVI)\nand PRI.\nIndeed, VIs have been\
    \ widely applied in hyperspectral data for several purposes [40,112–117].\nFor\
    \ example, Haboudane et al. [112] carried out a study to evaluate VIs sensitivity\
    \ to green LAI,\nand to modify some of them in order to enhance their responsivity\
    \ to LAI variations. Modiﬁed\nversions of TVI and MCARI popped out as the best\
    \ to predict green in LAI. Vineyard conditions\nassessment was addressed in [113],\
    \ pointing out the PRI as one of the most sensitives to carotenoids\nCx+c and\
    \ chlorophyll-carotenoid ratios Cab/Cx+c. TCARI combined with a broadband index\
    \ known\nas Optimized Soil-Adjusted Vegetation Index (OSAVI) was the most consistent\
    \ for estimating\nCab on aggregated and pure vine pixels. Later, 12 VIs assessment\
    \ was performed by Lin [114],\nin which TCARI/OSAVI combination was highlighted\
    \ as the best for chlorophyll estimation while,\nsimultaneously, resisting to\
    \ LAI variations.\nTCARI/MSAVI occupied the second place in that\nranking. In\
    \ [40], 3 years of UAV-acquired hyperspectral data over vineyard ﬁelds were used\
    \ to\ncarry out a study with VIs that led to the conclusion that the combination\
    \ of R515/R570 (sensitive\nto Cx+c) and TCARI/OSAVI (sensitive to Ca+b) narrow-band\
    \ indices are suitable for mapping\ncarotenoid concentration at the pure-vine\
    \ level. According to Liang et al. [115], PRI and, once again,\nTCARI/OSVAI, are\
    \ the most suitable indices for leaf chlorophyll content estimation. Regarding\
    \ canopy\nchlorophyll content estimation, SR and SR2 are at the top of their ranking.\
    \ In a recent work on rice [117],\nMSAVI is among the VIs that presented the strong\
    \ and signiﬁcant relationships with the LAI estimation\nat different phenological\
    \ stages. For more information in hyperspectral VIs, the fourteenth section of\n\
    the ﬁfth part of [116]—a book devoted to hyperspectral remote sensing of vegetation—is\
    \ available\nfor consultation.\nIn [12], a wide survey on optimal hyperspectral\
    \ narrow bands (between 400–2500 nm) to study\nvegetation and agricultural crop\
    \ biophysical and biochemical properties was presented in the form of\na table\
    \ containing sections regarding band classes, more speciﬁcally: blue, green, red,\
    \ RE, NIR, far near\ninfrared (FNIR), Early short-wave infrared (ESWIR) and Far\
    \ short-wave infrared (FSWIR).\nAlternatively to the presented hyperspectral data\
    \ processing, emerging approaches for dealing\nwith HSI complexity based on deep\
    \ learning (DL) are worthy to be referred. For example, in [118],\na framework\
    \ that joins dimension reduction and deep learning to allow hyperspectral image\n\
    Remote Sens. 2017, 9, 1110\n17 of 30\nclassiﬁcation based on spectral-spatial\
    \ features is proposed. Discriminant algorithms for spectral\nfeatures and convolutional\
    \ neural networks (CNN) to deal with spatial features are at the basis of this\n\
    proposal that is pointed out as an outperforming framework comparatively to commonly\
    \ used methods\nfor hyperspectral image classiﬁcation. For saliency detection\
    \ regarding to band selection in HSI,\na manifold ranking approach—that is also\
    \ extended to DL—is presented in [119]. The spectral-spatial\nresidual network\
    \ found in [120] consists of a supervised deep learning framework that is capable\
    \ of\ndiscriminating features from abundant spectral signatures and spatial contexts\
    \ in a HSI (provided\nas input and without the need for feature engineering).\
    \ In [121], both attribute proﬁle and DL\napproaches were merged with the goal\
    \ of classifying HIS. Proﬁling working together with CNN\nshowed better results\
    \ than using each of the involved approaches individually. Also, the need for\n\
    lighter network architectures and deep network types was highlighted. Even for\
    \ anomaly detection,\nCNN demonstrated to outperform classical methods such as\
    \ RX-based approaches [122].\nTo sum up this section, dimension reduction focuses\
    \ on data simpliﬁcation for computational\nperformance improvement while ensuring\
    \ information conservation. Target detection refers to the\nidentiﬁcation of some\
    \ particular feature of interest through imagery spectral proﬁle analysis using\n\
    pure inference statistics. Full pixel and sub-pixel methods are available for\
    \ different scenarios. Other\ntypes of classiﬁcation provide extensive analysis\
    \ and categorization of a whole scene. The machine\nlearning-based approaches\
    \ can be understood as general classiﬁcation since their black boxes provide\n\
    ﬂexible ways of classifying a scene and detecting particular features. For estimating\
    \ vegetation\nproperties and status, several indices are available. Emerging DL\
    \ approaches are also strongly\ncontributing to HSI processing with methods that\
    \ include dimension reduction, classiﬁcation and\nanomaly detection.\nTo deal\
    \ with the mathematical complexity entangled in pure statistical approaches, several\
    \ efforts\nhave been made towards the development of software and libraries focusing\
    \ on hyperspectral data\nprocessing. In the next section, several results of such\
    \ efforts are presented.\n5. Software and Libraries for Dealing with Hyperspectral\
    \ Data\nHandling, processing and analyzing hyperspectral data demands skilled\
    \ workmanship with\nadvanced knowledge in statistics, as it is evidenced in Section\
    \ 4. Thereby, professionals relying on\nremote sensing—for example farmers, foresters\
    \ or even code developers serving agriculture, forestry\nand related areas—are\
    \ required to hold that knowledge somehow, either by training courses or by\n\
    hiring external resources. To tackle with that situation, some entities have been\
    \ developing efforts\nto hide the mathematical complexity to those professionals.\
    \ In this subsection, a brief overview on\nsoftware tools and programming libraries\
    \ that represent such efforts will be presented.\nRegarding software tools, there\
    \ are some mature solutions that allow interacting with\nhyperspectral data and\
    \ that only demand awareness of the processes to carry out data analysis\nrather\
    \ than the inherent mathematical knowledge. For example, Earth Resource Data Analysis\
    \ System\n(ERDAS) [123] is a commercial and complex software with a graphical\
    \ user interface for manipulating\nnot only hyperspectral imagery—for which many\
    \ of the operations addressed in the previous\nsection, like supervised classiﬁcation,\
    \ are supported—but also optical panchromatic, multispectral,\nradio detection/direction\
    \ and ranging (RADAR) and light detection and ranging (LIDAR) data.\nAnother tool\
    \ is the Environment for Visualizing Images (ENVI) software [124], which combines\n\
    advanced image processing and proven geospatial technology to help in the extraction\
    \ of meaningful\ninformation from all kinds of data and therefore improves the\
    \ decision making process. Tactical\nHyperspectral Operations Resource (THOR)\
    \ is a special ENVI package that enables orthorectiﬁcation,\natmospheric corrections,\
    \ and target detection, among other operations, with data cubes. There is\nalso\
    \ ImageLab [125], which processes data from various spectroscopic imaging techniques,\
    \ such as\nsubmillimeter radiation (THz band), optical, ultraviolet-visible (UV-Vis),\
    \ infrared, Raman or mass\nspectrometry. Based on multivariate statistical methods,\
    \ it enables the user both to analyze and\nclassify acquired hyperspectral images\
    \ and to merge them with maps of physical properties and\nRemote Sens. 2017, 9,\
    \ 1110\n18 of 30\nhigh-resolution RGB photos. The convenient user interface gives\
    \ full control over the vast range\nof functions. EXPRESSO 13 [126] is the ﬂagship\
    \ software of Brandywine (a hyperspectral sensors\nmanufacturer). It consists\
    \ of real-time hyperspectral image processing and control with an intuitive\n\
    interface and provides all of the standard algorithms (e.g., k-means clustering,\
    \ matched ﬁltering\nand MNF transform). Finally, Spectronon [127] is another analysis\
    \ software that provides tools like\nhyperspectral classiﬁcation (e.g., based\
    \ on SAM and logistic regression) VIs determination, advanced\nvisualization tools\
    \ and support for user-written Python plugins. It is designed to deal with Resonon’s\n\
    spectral sensors. Next, available programming libraries for dealing with hyperspectral\
    \ data processing\nwill be addressed, including some application programming interfaces\
    \ (APIs) released by companies\nthat also released the aforementioned software\
    \ tools.\nIn fact, programming libraries, as it turns out, are in lesser numbers.\
    \ A free open-source option\nthat seems to be mature is the Spectral Python (SPy)\
    \ module [128], which is released under GNU\ngeneral public license (GPL). Documentation\
    \ seems to be well structured and validated by some\npublished works [79,99].\
    \ There is also Hyperspectral Python (HypPy) [129], which works with\nENVI ﬁle\
    \ format for images and it can be used along with other software, such as ENVI\
    \ software.\nAnother option is Hyperspectral Image Analysis Toolbox (HIAT) [130]\
    \ that consists in a collection\nof functions for analysis of hyperspectral and\
    \ multispectral data in Matlab environment. It provides\nprocessing methods like\
    \ discriminant analysis, principal components analysis, Euclidean distance or\n\
    maximum likelihood, but it seems not covered by developer support anymore [131].\
    \ MultiSpec [132]\nis a freeware processing system for analyzing multispectral\
    \ and hyperspectral images developed by\nLandgrebe (author of [67], for example).\
    \ Also, some of the addressed software tools provide libraries\nfor programmers.\
    \ For example, ENVI has a so-called interactive data language that is easy to\
    \ learn\nand to use, enabling scientists and professionals to make a softer hyperspectral\
    \ data handling. From\nErdas, a C/C++ development kit is available, too. Resonon\
    \ [127] also shares a programming interface\nin C++ for those who desire to control\
    \ hyperspectral imagers, available from the company. However,\nhyperspectral data\
    \ processing and analysis seem to not be supported by this API.\nJust like for\
    \ statistical-based hyperspectral data manipulation, some engines and libraries\n\
    (e.g., Tensorﬂow [133] and Theano [134]) that support the development of machine/deep\
    \ learning\napplications are available.\nThe next section presents a set of works\
    \ that combine UAVs, hyperspectral sensors and data\nanalysis, within the scope\
    \ of agriculture, forestry and related areas.\n6. Applications in Agriculture\
    \ and Forestry Areas\nIn this section, applications employing hyperspectral data\
    \ acquisition, processing and analysis\nfor areas related with farming and wild\
    \ vegetation management will be presented, with a special\nfocus on matters that\
    \ range from the earlier sowing tasks to post-crop stages, moving through the\n\
    estimation of parameters (e.g., carotenoid content, biomass and nitrogen) to disease\
    \ monitoring. Works\nare presented considering a clear division between agriculture,\
    \ forestry and agroforestry areas.\n6.1. Agriculture\nMethods for leaf carotenoid\
    \ content estimation in vineyards, using high resolution hyperspectral\nimagery\
    \ acquired from an UAV are presented in [40]. The atmospheric correction was conducted\n\
    using total incoming irradiance at 1 nm intervals, simulated with the simple model\
    \ of the atmospheric\nradiative transfer of sunshine (SMARTS) developed by the\
    \ National Renewable Energy Laboratory,\nUnites States of America (US) Department\
    \ of Energy (Gueymard, 1995, 2001). Radiative transfer\nmodels and scaling-up\
    \ methods were used to achieve estimations upon 2 years of hyperspectral\nimagery\
    \ with good results, although slightly less accurate than in [135], which is a\
    \ work with similar\nmeasuring purposes.\nPölönen et al. [30] used hyperspectral\
    \ Fabry-Perot and UAVs to estimate biomass and nitrogen.\nTheir approach was tested\
    \ in ﬁeld with plantations of wheat and barley. Pre-processing operations\nRemote\
    \ Sens. 2017, 9, 1110\n19 of 30\ninvolved laboratory calibration, spectral and\
    \ dark signal corrections. Feature extraction was done\nusing NDVI spectral index,\
    \ spectral unmixing and spatial features. Estimation was made using a\nmachine\
    \ learning approach that joins k-nearest neighbor (k-NN) for classiﬁcation and\
    \ training data\nacquired in a laboratory environment.\nCorresponding objectives\
    \ are pursued in [136] using a similar sensor for adverse meteorological\nconditions,\
    \ which represented a challenge regarding data processing. According to the authors,\n\
    varying illumination conditions caused signiﬁcant radiometric differences between\
    \ images. However,\ntheir radiometric correction was able to reduce grey values\
    \ variation in overlapping images from\n14–18% to 6–8%.\nIn [41], a multitemporal\
    \ analysis process of hydrological soil surface characteristics (H-SSC) was\n\
    applied to Mediterranean vineyards. It was capable of discriminating land classes\
    \ and translating\npossible evolutions to decision rules. Classiﬁcation consists\
    \ of correcting H-SSC class maps, previously\nderived from any monotemporal classiﬁcation\
    \ (maps are pixel or image-object-based), relying on the\ncomparison between expert\
    \ knowledge reﬂected on H-SSC possible evolutions (successors) and a\ngiven monotemporal\
    \ classiﬁcation. Mechanical and chemical interventions in ﬁeld are prone of being\n\
    detected with this approach.\nIn [49], the authors built their own hyperspectral-based\
    \ UAS that includes a 960 g hyperspectral\nsensor capable of capturing 324 spectral\
    \ bands (or half in the binned mode) between 361 and 961 nm, a\nmultirotor drone,\
    \ positional/orientation sensors and a power supply unit. Validation experiments\n\
    included the assessment of chlorophyll content and green biomass of pasture and\
    \ barley crop, mainly\nbased on calculus involving VIs.\nWater status of a lemon\
    \ orchard was investigated in [137] using ﬁeld data collection, i.e., leaf-level\n\
    measurements of chlorophyll ﬂuorescence and PRI data, seasonal time-series of\
    \ crown temperature\nand PRI under different regulated deﬁcit irrigation (RDI)\
    \ treatments. UAS—consisting in a UAV plus\nthermal and hyperspectral sensors—was\
    \ used to gather data for analyzing pure crown temperature,\nradiance and reﬂectance\
    \ spectra with the objective of estimate chlorophyll ﬂuorescence, visible ratios\n\
    and structural indices for water stress detection. Radiometric calibration was\
    \ made in relation\nto a calibrated unit light source while atmospheric calibration\
    \ was carried out by using SMARTS\nmodel. Indices-based measurements and FluorMOD\
    \ model plus FLD3 were applied for ﬂuorescence\nestimation, which was in agreement\
    \ with ground measurements.\nVerticillium wilt—which is a disease that affects\
    \ olive cultures in the way that it blocks the water\nﬂow at the vascular plant\
    \ level—was studied by [138] with the use of thermal imagery, chlorophyll\nﬂuorescence,\
    \ structural and physiological indices (xanthophyll, chlorophyll a + b, carotenoids\
    \ and\nblue/green/red B/G/R indices) calculated from multispectral and hyperspectral\
    \ data as early\nindicators of the infection’s presence and severity.\nIn [50],\
    \ chlorophyll densities estimation on rice paddies at low ﬂight altitudes was\
    \ the main\nconcern. A hyperspectral sensor was assembled to that end, capable\
    \ of reading 256 bands equally\nspaced between 340 and 763 nm. Comparisons of\
    \ the sensor readings to ground truth demonstrated\ngreat accuracy in the estimations\
    \ of chlorophyll density, more speciﬁcally at RE and NIR ranges.\nThe angular\
    \ effect over several VIs using UAVs and a hyperspectral sensor was studied in\
    \ [139]\nwith a focus on wheat. The so-called goniometer system uses a structure\
    \ for motion approach to\nassess pointing and position accuracy. As main conclusions,\
    \ the authors stated that their UAV-based\ngoniometer represents a useful mean-step\
    \ towards the development of correction techniques to\nattenuate the effects of\
    \ angular reﬂections on spectra.\nResearchers from National Lab and State University\
    \ of Idaho in the USA [140] presented several\ntests on their remote sensing system\
    \ that evaluates the inﬂuence of improved ﬂights on geometric\naccuracy, mosaicking\
    \ capabilities and ability to discriminate non-vegetation targets, grasses and\
    \ shrubs.\nUnsupervised classiﬁcation based on k-mean was used for exploring data\
    \ imagery acquired from\nthe ﬁeld and a matched ﬁlter based on SAM was applied\
    \ for supervised classiﬁcation of ground\nfeatures (e.g., Sandberg bluegrass and\
    \ bare soil). The former seems to support vegetation management\nRemote Sens.\
    \ 2017, 9, 1110\n20 of 30\nobjectives that rely on mapping shrub cover and distribution\
    \ patterns, while the latter performed\npoorly, highlighting the need of improving\
    \ supervised classiﬁcation procedures.\nA study demonstrating the relationship\
    \ between steady-state ﬂuorescence and net photosynthesis\nmeasured under natural\
    \ light ﬁeld conditions—both at the leaf and image levels—was carried out\nby\
    \ Zarco-Tejada [42], who used a 260-band hyperspectral sensor attached to an UAV\
    \ to perform tests\nin twelve production vineyards of Ribera del Duero (northern\
    \ Spain). Several tests for acquiring\nparameters on biochemical determination\
    \ of chlorophyll a + b, carotenoids and anthocyanins, while\nother parameters\
    \ (e.g., Leaf steady-state and dark-adapted ﬂuorescence) were collected on the\
    \ ground\nto be compared to imagery data from which ﬂorescence estimations were\
    \ taken by using the Fraunhofer\nLine Depth (FLD) principle. Results point out\
    \ to a connection between both.\nFocusing on wheat ﬁelds, Kaivosoja et al. [141]\
    \ exploited classiﬁed raster maps from hyperspectral\ndata to produce a work task\
    \ for a precision fertilizer application. Flight campaigns were carried out\n\
    in wheat ﬁelds (Finland) to then produce classiﬁed raster maps with biomass and\
    \ nitrogen contents\nestimation. Such maps were combined with historic data (e.g.,\
    \ yield maps) to generate proper task\nmaps for farm machinery. Some equations\
    \ relating nitrogen with biomass were used for statistical\npurposes. Despite\
    \ the potential usefulness of this kind of estimation practices, the authors stressed\
    \ out\nsome inaccuracies related with the hyperspectral data processing chain.\
    \ Perhaps ground measures\ntaken in sparser temporal data could contribute to\
    \ a more accurate classiﬁcation, thus improving\nthe results.\n6.2. Forestry\n\
    A method to derive 3D hyperspectral information from lightweight snapshot sensors\
    \ on board of\nUAVs for vegetation monitoring was proposed in [142], based on\
    \ a structure from motion approach\nthat results in a digital surface model (DSM)\
    \ as a representation of the 3D space linked to objects’\nreﬂectance. The used\
    \ sensor provides 125 bands of information the range of 450–950 nm and 21 cm of\n\
    resolution. Operations around radiometric calibration are extensively documented.\
    \ Since the center\nwavelengths and full width at half maximum (FWHM) were provided\
    \ by the manufacturer, spectral\ncalibration was not carried out.\nTo identify\
    \ the presence of bark beetle infestations on Norway’s spruce, Näsi et al. [143]\n\
    developed a new processing approach to analyze spectral characteristics for high\
    \ spatial resolution\nphotogrammetric and hyperspectral image data in a forested\
    \ environment. The used hyperspectral\nsensor—FPI—is different from most of the\
    \ others since it has stereoscopic capabilities, which suggest\nimproved accuracy\
    \ in point cloud gathering and further DSM production. The workﬂow for analysis\n\
    includes images’ correction according to laboratory calibrations, creation of\
    \ a 3D geometric model,\ndetermination of spectral image mosaics, identiﬁcation\
    \ of individual trees, spectral feature extraction\nand, ﬁnally, classiﬁcation\
    \ based on supervised k-NN [144]. For three color classes (healthy, infested,\n\
    dead), an overall accuracy of 76% was obtained, while 90% was achieved when using\
    \ 2 classes\n(healthy, dead).\nSmall tropical forests were the focus in [145],\
    \ that presents a work for the assessment of altimetry\naccuracy involving Bundle\
    \ Block Adjustment (BBA) with a couple of hyperspectral bands and\nGCPs. Conclusions\
    \ were: (1) ground control is needed to improve altimetry accuracy and (2) fewer\n\
    discrepancies were noticed for the GCPs placed in the image border rather than\
    \ the ones placed in\nits corners. Preliminary results showed a discrepancy of\
    \ around 40 cm in the Z coordinate, which is\nsufﬁcient for forestry applications.\n\
    6.3. Agroforestry\nSaari et al. [146] integrated Unmanned Aerial System Innovations\
    \ (UASI), which is a project\nthat aims to study how useful light weighted UAVs\
    \ can be in ﬁelds related with forestry or\nagriculture. They start off by pointing\
    \ out forestry requirements (e.g., tree height estimation and\nspecies identiﬁcation)\
    \ and crop monitoring applications (e.g., feedstock estimation and nitrogen status\n\
    Remote Sens. 2017, 9, 1110\n21 of 30\nassessment) as well as the requirements\
    \ of UASI systems (collaborative support for farmers or forest\nprofessionals).\
    \ They conclude that FPI is a suitable sensor to be used in the several tasks\
    \ concerning the\nsystem. This sensor was used to demonstrate the technical feasibility\
    \ of false color and hyperspectral\ndata in forest inventory and agriculture applications.\
    \ Later, this research group [147] focused in\nprecision agriculture with studies\
    \ on biomass estimation based on support vector regression machine.\nMulti-temporal\
    \ data and point clouds were their main data sources.\nSumming up, several works\
    \ ranging from vegetation status monitoring to disease detection\ndemonstrate\
    \ how versatile and useful hyperspectral remote sensing using UAVs can be for\
    \ both\nagriculture and forestry.\n7. Conclusions\nUAS are getting increasingly\
    \ popular in agricultural and forestry insofar as they represent a\ncost-effective\
    \ and readily available tool for surveying land and crops, with the purpose of\
    \ acquiring\ndata for further analysis and to support decision-making and management\
    \ processes. However, most\nof the sensors that are commonly applied to that end\
    \ (e.g., RGB and multispectral sensors) usually\nonly provide information on a\
    \ very limited number of bands and/or spectral ranges which might\nnot sufﬁce\
    \ some components that are part of a data set representing a scanned place, such\
    \ as a forest\nsection or a crop area.\nTo tackle this issue, hyperspectral sensors—commonly\
    \ used on satellites or manned aircraft a few\nyears ago—are getting redesigned\
    \ to be lighter and smaller and, thus, more suitable to be carried by\nUAVs for\
    \ earth surface surveying purposes, considering a wider spectral range and narrower\
    \ bands.\nSeveral of these sensors are commercially available and were presented\
    \ in Section 2, along with a few\nproposals based on scientiﬁc research.\nHyperspectral\
    \ sensors usually generate huge amounts of data since they retrieve spectra sets\n\
    composed of hundreds of bands across considerable spatial resolution images. Such\
    \ dimensionality\ndemands proper analysis and processing methods. The most important\
    \ ones were presented in\nSection 4, right before some software tools and programming\
    \ libraries that implement most of the\naddressed mathematical approaches. For\
    \ remote sensing professionals, land surveying technicians\nand programmers working\
    \ on applications for agroforestry and related areas, such tools may prove to\n\
    be relevant.\nWorks on agriculture and forestry areas involving UAVs and hyperspectral\
    \ sensors were reviewed,\nfocusing on their main purposes and general processing\
    \ and analysis approaches. Notwithstanding\nthe considerable number of applications,\
    \ they seem to be still scarce compared with applications\ninvolving UAVs and\
    \ other types of sensors, probably because of the high prices of high-resolution\n\
    spectroscopy that can compromise cost-effectiveness on applications around agroforestry\
    \ and related\nareas. Another reason for the low number of studies is the complexity\
    \ of data acquisition and analysis.\nA higher level of training is needed to acquire\
    \ the data. Additionally, some researchers [148] expect that\nhyperspectral sensors\
    \ will be applied only for research purposes. However, we refuse to agree with\
    \ that\nperspective due to the increasing number of market solutions that are\
    \ contributing to the wide spread\nof high-resolution spectroscopy devices. Moreover,\
    \ it is expected that the technological development of\nupcoming years can bring\
    \ smaller and more affordable devices, turning hyperspectral-based sensing\ninto\
    \ a mainstream approach for agriculture, forestry and related areas. Even knowing\
    \ there is still a\nlong way to go until UAS-based remote sensing using hyperspectral\
    \ becomes effectively affordable for\ncommon farmers and foresters, there is,\
    \ undoubtedly, a window of opportunity for the dissemination\nof business models\
    \ relying on regionalized and cost-effective services supply focusing on this\
    \ kind\nof survey and enabling more accurate decision-support tools. With this\
    \ in mind and following the\nproposal already presented in [149], future efforts\
    \ will be developed towards the identiﬁcation and\ndiscrimination of phytosanitary\
    \ issues affecting vineyards through hyperspectral-based remote sensing\ncarried\
    \ out using UAVs.\nRemote Sens. 2017, 9, 1110\n22 of 30\nAcknowledgments: This\
    \ work was ﬁnanced by the European Regional Development Fund (ERDF) through the\n\
    Operational Programme for Competitiveness and Internationalisation—COMPETE 2020\
    \ under the PORTUGAL\n2020 Partnership Agreement, and through the Portuguese National\
    \ Innovation Agency (ANI) as a part of project\n“PARRA—Plataforma integrAda de\
    \ monitoRização e avaliação da doença da ﬂavescência douRada na vinhA”\n(N◦ 3447)\
    \ and ERDF and North 2020—North Regional Operational Program, as part of project\
    \ “INNOVINE &\nWINE—Vineyard and Wine Innovation Platform” (NORTE-01-0145-FEDER-000038).\n\
    Author Contributions: The authors that form a multidisciplinary team acting in\
    \ informatics, earth sciences\nand electronics, provided a steady contribution\
    \ for this paper, each one focusing their respective areas of\nexpertise. Thereby,\
    \ Telmo Adão, Jonáš Hruška, Luís Pádua and Miguel Bessa carried out the research\
    \ related\nwith hyperspectral data processing, software tools and agroforestry\
    \ and related areas applications. Hyperspectral\nsensors as well as pre- and post-ﬂight\
    \ operations were addressed by Emanuel Peres, Raul Morais and Joaquim\nJoão Sousa\
    \ that also designed the paper and managed its development.\nConﬂicts of Interest:\
    \ The authors declare no conﬂict of interest.\nAppendix A\nACD\nAnomalous Change\
    \ Detection\nAIS\nAirborne Imaging Spectrometer\nAMF\nAdaptive Matched Filters\n\
    API\nApplication Programming Interface\nAVIRIS\nAirborne Visible/Infrared Imaging\
    \ Spectrometer\nBBA\nBundle Block Adjustment\nBIL\nBand-Interleaved-by-Line\n\
    BIP\nBand-Interleaved-by-Pixel\nBSQ\nBand Sequential\nCARI\nChlorophyll Absorption\
    \ Ratio Index\nCCD\nCharge-Coupled Device\nCF\nContinuum Fusion\nCFAR\nConstant\
    \ False Alarm Rate\nCMOS\nComplementary Metal-Oxide-Semiconductor\nCNN\nConvolutional\
    \ Neural Networks\nDAFE\nDecision Boundary Feature Matrix\nDBFE\nDecision Boundary\
    \ Feature Extraction\nDL\nDeep Learning\nDN\nDigital Numbers\nDSM\nDigital Surface\
    \ Model\nENVI\nENvironment for Visualizing Images\nERDAS\nEarth Resource Data\
    \ Analysis System\nESWIR\nEarly Short-Wave InfraRed\nFAM\nFalse Alarm Mitigation\n\
    FLD\nFraunhofer Line Depth\nFNIR\nFar Near InfraRed\nFPI\nFabry-Perot Interferometer\n\
    FSWIR\nFar Short-Wave InfraRed\nFWHM\nFull Width At Half Maximum\nGaAs\nGallium\
    \ Arsenide\nGCP\nGround Control Point\nGI\nGreenness Index\nGI\nGreenness Index\n\
    GLR\nGeneralized Likelihood Ratio\nGLRT\nGeneralized Likelihood Ratio Test\nGNSS\n\
    Global Navigation Satellite Systems\nGPL\nGeneral Public License\nGPS\nGlobal\
    \ Positioning System\nGVI\nGreenness Vegetation Index\nHIAT\nHyperspectral Image\
    \ Analysis Toolbox\nHSI\nHyperspectral Imaging\nRemote Sens. 2017, 9, 1110\n23\
    \ of 30\nH-SSC\nHydrological Soil Surface Characteristics\nHypPy\nHyperspectral\
    \ Python\nICA\nIndependent Component Analysis\nIMU\nInertial Measurement Unit\n\
    InAs\nIndium Arsenide\nInGaAs\nIndium Gallium Arsenide\nINS\nInertial Navigation\
    \ Systems\nk-NN\nk-Nearest Neighbor\nLIDAR\nLIght Detection And Ranging\nLMM\n\
    Linear Mixed Models\nLR\nLikelihood Ratio\nMCARI\nModiﬁed Chlorophyll Absorption\
    \ Ratio Index\nMCR\nMultivariate Curve Resolution\nMCT, HgCdTe\nMercury Cadmium\
    \ Tellurium\nmNDVI\nModiﬁed Normalized Difference Vegetation Index\nMNF\nMaximum\
    \ Noise Fraction\nMSAVI\nModiﬁed Soil-Adjusted Vegetation Index\nMVSR\nModiﬁed\
    \ Vegetation Stress Ratio\nNASA/JPL\nNational Aeronautics and Space Administration\
    \ Jet Propulsion Laboratory\nNDVI\nNormalized Difference Vegetation Index\nNIR\n\
    Near InfraRed\nNPCI\nNormalized Pigment Chlorophyll Index\nOSAVI\nOptimized Soil-Adjusted\
    \ Vegetation Index\nPCA\nPrincipal Component Analysis\nPd\nProbability of detection\n\
    Pfa\nProbability of false alarm\nPRI\nPhotochemical Reﬂectance Index\nRADAR\n\
    RAdio Detection/Direction And Ranging\nRBF\nRadial Basis Function\nRDI\nRegulated\
    \ Deﬁcit Irrigation\nRE\nRed-Edge\nRGB\nRed Green Blue\nROC\nReceiving Operating\
    \ Characteristic\nRTT\nRadiative Transfer Theory\nRX\nReed-Xiaoli\nSAM\nSpectral\
    \ Angle Mapper\nSi\nSilicon\nSMARTS\nSimple Model Of The Atmospheric Radiative\
    \ Transfer Of Sunshine\nSNR\nSignal-To-Noise Ratio\nSPy\nSpectral Python\nSR\n\
    Simple Ratio\nSRPI\nSimple Ratio Pigment Index\nSVDD\nSupport Vector Data Description\n\
    SVM\nSupport Vector Machines\nTCARI\nTransformed Chlorophyll Absorption Ratio\
    \ Index\nTHOR\nTactical Hyperspectral Operations Resource\nTHz\nsubmillimeter\
    \ radiation\nTID\nTarget IDentiﬁcation\nTSVM\nTransductive Support Vector Machines\n\
    TVI\nTriangular Vegetation Index\nUAS\nUnmanned Aircraft Systems\nUASI\nUnmanned\
    \ Aerial System Innovations\nUAV\nUnmanned Aerial Vehicle\nUV-Vis\nUltraviolet-Visible\n\
    VI\nVegetation Index\nVNIR\nVisible and Near-Infrared\nRemote Sens. 2017, 9, 1110\n\
    24 of 30\nReferences\n1.\nPádua, L.; Vanko, J.; Hruška, J.; Adão, T.; Sousa, J.J.;\
    \ Peres, E.; Morais, R. UAS, sensors, and data processing\nin agroforestry: A\
    \ review towards practical applications. Int. J. Remote Sens. 2017, 38, 2349–2391.\
    \ [CrossRef]\n2.\nPark, S.; Nolan, A.; Ryu, D.; Fuentes, S.; Hernandez, E.; Chung,\
    \ H.; O’Connell, M. Estimation of crop\nwater stress in a nectarine orchard using\
    \ high-resolution imagery from unmanned aerial vehicle (UAV).\nIn Proceedings\
    \ of the 21st International Congress on Modelling and Simulation, Gold Coast,\
    \ Australia,\n29 November–4 December 2015; pp. 1413–1419.\n3.\nPrimicerio, J.;\
    \ Gennaro, S.F. D.; Fiorillo, E.; Genesio, L.; Lugato, E.; Matese, A.; Vaccari,\
    \ F.P. A ﬂexible\nunmanned aerial vehicle for precision agriculture. Precis. Agric.\
    \ 2012, 13, 517–523. [CrossRef]\n4.\nBendig, J.; Yu, K.; Aasen, H.; Bolten, A.;\
    \ Bennertz, S.; Broscheit, J.; Gnyp, M.L.; Bareth, G. Combining\nUAV-based plant\
    \ height from crop surface models, visible, and near infrared vegetation indices\
    \ for biomass\nmonitoring in barley. Int. J. Appl. Earth Obs. Geoinf. 2015, 39,\
    \ 79–87. [CrossRef]\n5.\nCalderón, R.; Navas-Cortés, J.A.; Zarco-Tejada, P.J.\
    \ Early Detection and Quantiﬁcation of Verticillium Wilt\nin Olive Using Hyperspectral\
    \ and Thermal Imagery over Large Areas. Remote Sens. 2015, 7, 5584–5610.\n[CrossRef]\n\
    6.\nGetzin, S.; Wiegand, K.; Schöning, I. Assessing biodiversity in forests using\
    \ very high-resolution images and\nunmanned aerial vehicles. Methods Ecol. Evol.\
    \ 2012, 3, 397–404. [CrossRef]\n7.\nMerino, L.; Caballero, F.; Martínez-de-Dios,\
    \ J.R.; Maza, I.; Ollero, A. An Unmanned Aircraft System for\nAutomatic Forest\
    \ Fire Monitoring and Measurement. J. Intell. Robot. Syst. 2012, 65, 533–548.\
    \ [CrossRef]\n8.\nSmigaj, M.; Gaulton, R.; Barr, S.L.; Suárez, J.C. Uav-Borne\
    \ Thermal Imaging for Forest Health Monitoring:\nDetection of Disease-Induced\
    \ Canopy Temperature Increase. ISPRS Int. Arch. Photogramm. Remote Sens. Spat.\n\
    Inf. Sci. 2015, XL-3/W3, 349–354. [CrossRef]\n9.\nHorcher, A.; Visser, R.J. Unmanned\
    \ aerial vehicles: Applications for natural resource management and\nmonitoring.\
    \ In Proceedings of the 2004 Council on Forest Engineering (COFE) Conference:\
    \ “Machines and\nPeople, The Interface”, Hot Springs, AR, Canada, 27–30 April\
    \ 2004.\n10.\nCoulter, D.; Hauff, P.L.; Kerby, W.L. Airborne Hyperspectral Remote\
    \ Sensing. In Proceedings of the\nExploration 07: Fifth Decennial International\
    \ Conference on Mineral Exploration, Toronto, ON, Canada,\n9–12 September 2007;\
    \ pp. 375–386.\n11.\nQin, J.; Chao, K.; Kim, M.S.; Lu, R.; Burks, T.F. Hyperspectral\
    \ and multispectral imaging for evaluating food\nsafety and quality. J. Food Eng.\
    \ 2013, 118, 157–171. [CrossRef]\n12.\nThenkabail, P.S.; Gumma, M.K.; Teluguntla,\
    \ P.; Mohammed, I.A. Hyperspectral Remote Sensing of Vegetation\nand Agricultural\
    \ Crops. Photogramm. Eng. Remote Sens. 2014, 80, 697–723.\n13.\nPark, B.; Lu,\
    \ R. Hyperspectral Imaging Technology in Food and Agriculture; Food Engineering\
    \ Series; Springer:\nNew York, NY, USA, 2015; ISBN 978-1-4939-2836-1.\n14.\nMultispectral\
    \ vs.\nHyperspectral Imagery Explained.\nAvailable online:\nhttp://gisgeography.com/\n\
    multispectral-vs-hyperspectral-imagery-explained/ (accessed on 15 September 2017).\n\
    15.\nProctor, C.; He, Y. Workﬂow for Building A Hyperspectral Uav: Challenges\
    \ And Opportunities. ISPRS Int.\nArch. Photogramm. Remote Sens. Spat. Inf. Sci.\
    \ 2015, XL-1/W4, 415–419. [CrossRef]\n16.\nManolakis, D.; Marden, D.; Shaw, G.A.\
    \ Hyperspectral image processing for automatic target detection\napplications.\
    \ Linc. Lab. J. 2003, 14, 79–116.\n17.\nAVIRIS—Airborne Visible/Infrared Imaging\
    \ Spectrometer—Imaging Spectroscopy.\nAvailable online:\nhttps://aviris.jpl.nasa.gov/aviris/imaging_spectroscopy.html\
    \ (accessed on 9 October 2017).\n18.\nSahoo, R. Hyperspectral Remote Sensing (Sahoo’s\
    \ Report); Indian Agricultural Statistics Research Institute:\nNew Delhi, India,\
    \ 2013; pp. 848–859.\n19.\nGoetz, A.F. H. Three decades of hyperspectral remote\
    \ sensing of the Earth: A personal view. Remote Sens.\nEnviron. 2009, 113, S5–S16.\
    \ [CrossRef]\n20.\nSabins, F.F. Remote sensing for mineral exploration. Ore Geol.\
    \ Rev. 1999, 14, 157–183. [CrossRef]\n21.\nMaathuis, B.H.P.; van Genderen, J.L.\
    \ A review of satellite and airborne sensors for remote sensing based\ndetection\
    \ of mineﬁelds and landmines. Int. J. Remote Sens. 2004, 25, 5201–5245. [CrossRef]\n\
    22.\nTeke, M.; Deveci, H.S.; Halilo˘glu, O.; Gürbüz, S.Z.; Sakarya, U. A short\
    \ survey of hyperspectral remote\nsensing applications in agriculture. In Proceedings\
    \ of the 2013 6th International Conference on Recent\nAdvances in Space Technologies\
    \ (RAST), Istanbul, Turkey, 12–14 June 2013; pp. 171–176.\nRemote Sens. 2017,\
    \ 9, 1110\n25 of 30\n23.\nMather, P.M. (Ed.) TERRA-1: Understanding the Terrestrial\
    \ Environment, the Role of Earth Observations from\nSpace; CRC Press: Boca Raton,\
    \ FL, USA, 1992.\n24.\nLin, J.; Singer, P.W. China to Launch Powerful Civilian\
    \ Hyperspectral Satellite.\nAvailable online:\nhttp://www.popsci.com/china-to-launch-worlds-most-powerful-hyperspectral-satellite\
    \ (accessed on\n18 April 2017).\n25.\nMulla, D.J. Twenty ﬁve years of remote sensing\
    \ in precision agriculture: Key advances and remaining\nknowledge gaps. Biosyst.\
    \ Eng. 2013, 114, 358–371. [CrossRef]\n26.\nDatt, B.; McVicar, T.R.; Niel, T.G.V.;\
    \ Jupp, D.L.B.; Pearlman, J.S. Preprocessing EO-1 Hyperion hyperspectral\ndata\
    \ to support the application of agricultural indexes. IEEE Trans. Geosci. Remote\
    \ Sens. 2003, 41, 1246–1259.\n[CrossRef]\n27.\nMoharana, S.; Dutta, S. Spatial\
    \ variability of chlorophyll and nitrogen content of rice from hyperspectral\n\
    imagery. ISPRS J. Photogramm. Remote Sens. 2016, 122, 17–29. [CrossRef]\n28.\n\
    Clark, M.L.; Kilham, N.E. Mapping of land cover in northern California with simulated\
    \ hyperspectral\nsatellite imagery. ISPRS J. Photogramm. Remote Sens. 2016, 119,\
    \ 228–245. [CrossRef]\n29.\nZhang, N.; Wang, M.; Wang, N. Precision agriculture—A\
    \ worldwide overview. Comput. Electron. Agric. 2002,\n36, 113–132. [CrossRef]\n\
    30.\nPölönen, I.; Saari, H.; Kaivosoja, J.; Honkavaara, E.; Pesonen, L. Hyperspectral\
    \ imaging based biomass and\nnitrogen content estimations from light-weight UAV.\
    \ In Proceedings of the SPIE Remote Sensing, Dresden,\nGermany, 16 October 2013.\n\
    31.\nWorldView-3 WorldView-3 Satellite Sensor|Satellite Imaging Corp.\nAvailable\
    \ online: http://www.\nsatimagingcorp.com/satellite-sensors/worldview-3/ (accessed\
    \ on 19 April 2017).\n32.\nESA Spatial-Resolutions-Sentinel-2 MSI—User Guides—Sentinel\
    \ Online. Available online: https://earth.esa.\nint/web/sentinel/user-guides/sentinel-2-msi/resolutions/spatial\
    \ (accessed on 19 April 2017).\n33.\nAVIRIS—Airborne Visible/Infrared Imaging\
    \ Spectrometer. Available online: https://aviris.jpl.nasa.gov/\n(accessed on 1\
    \ August 2017).\n34.\nPajares, G. Overview and Current Status of Remote Sensing\
    \ Applications Based on Unmanned Aerial\nVehicles (UAVs). Photogramm. Eng. Remote\
    \ Sens. 2015, 81, 281–329. [CrossRef]\n35.\nAasen, H. The Acquisition of Hyperspectral\
    \ Digital Surface Models of Crops from UAV Snapshot Cameras.\nPh.D. Thesis, Universität\
    \ zu Köln, Köln, Germany, 2016.\n36.\nSullivan, J.M. Evolution or revolution?\
    \ The rise of UAVs. IEEE Technol. Soc. Mag. 2006, 25, 43–49. [CrossRef]\n37.\n\
    Pappalardo, J. Unmanned Aircraft “Roadmap” Reﬂects Changing Priorities.\nAvailable\
    \ online:\nhttp://www.nationaldefensemagazine.org/articles/2005/3/31/2005april-unmanned-aircraft-roadmap-\n\
    reﬂects-changing-priorities (accessed on 1 September 2017).\n38.\nColomina, I.;\
    \ Molina, P. Unmanned aerial systems for photogrammetry and remote sensing: A\
    \ review. ISPRS\nJ. Photogramm. Remote Sens. 2014, 92, 79–97. [CrossRef]\n39.\n\
    Bock, C.H.; Poole, G.H.; Parker, P.E.; Gottwald, T.R. Plant Disease Severity Estimated\
    \ Visually, by Digital\nPhotography and Image Analysis, and by Hyperspectral Imaging.\
    \ Crit. Rev. Plant Sci. 2010, 29, 59–107.\n[CrossRef]\n40.\nZarco-Tejada, P.J.;\
    \ Guillén-Climent, M.L.; Hernández-Clemente, R.; Catalina, A.; González, M.R.;\
    \ Martín, P.\nEstimating leaf carotenoid content in vineyards using high resolution\
    \ hyperspectral imagery acquired from\nan unmanned aerial vehicle (UAV). Agric.\
    \ For. Meteorol. 2013, 171–172, 281–294. [CrossRef]\n41.\nCorbane, C.; Jacob,\
    \ F.; Raclot, D.; Albergel, J.; Andrieux, P. Multitemporal analysis of hydrological\
    \ soil surface\ncharacteristics using aerial photos: A case study on a Mediterranean\
    \ vineyard. Int. J. Appl. Earth Obs. Geoinf.\n2012, 18, 356–367. [CrossRef]\n\
    42.\nZarco-Tejada, P.J.; Catalina, A.; González, M.R.; Martín, P. Relationships\
    \ between net photosynthesis and\nsteady-state chlorophyll ﬂuorescence retrieved\
    \ from airborne hyperspectral imagery. Remote Sens. Environ.\n2013, 136, 247–258.\
    \ [CrossRef]\n43.\nWu, D.; Sun, D.-W. Advanced applications of hyperspectral imaging\
    \ technology for food quality and safety\nanalysis and assessment: A review—Part\
    \ I: Fundamentals. Innov. Food Sci. Emerg. Technol. 2013, 19, 1–14.\n[CrossRef]\n\
    44.\nSellar, R.G.; Boreman, G.D. Classiﬁcation of imaging spectrometers for remote\
    \ sensing applications. Opt. Eng.\n2005, 44, 13602. [CrossRef]\nRemote Sens. 2017,\
    \ 9, 1110\n26 of 30\n45.\nCarrère, J.P.; Place, S.; Oddou, J.P.; Benoit, D.; Roy,\
    \ F. CMOS image sensor: Process impact on dark current.\nIn Proceedings of the\
    \ 2014 IEEE International on Reliability Physics Symposium, Waikoloa, HI, USA,\
    \ 1–5 June\n2014; pp. 3C.1.1–3C.1.6.\n46.\nHagen, N.; Kudenov, M.W. Review of\
    \ snapshot spectral imaging technologies. Opt. Eng. 2013, 52, 090901.\n[CrossRef]\n\
    47.\nUto, K.; Seki, H.; Saito, G.; Kosugi, Y.; Komatsu, T. Development of a Low-Cost\
    \ Hyperspectral Whiskbroom\nImager Using an Optical Fiber Bundle, a Swing Mirror,\
    \ and Compact Spectrometers. IEEE J. Sel. Top. Appl.\nEarth Obs. Remote Sens.\
    \ 2016, 9, 3909–3925. [CrossRef]\n48.\nFowler, J.E. Compressive pushbroom and\
    \ whiskbroom sensing for hyperspectral remote-sensing imaging.\nIn Proceedings\
    \ of the 2014 IEEE International Conference on Image Processing, Paris, France,\
    \ 27–30 October\n2014; pp. 684–688.\n49.\nLucieer, A.; Malenovský, Z.; Veness,\
    \ T.; Wallace, L. HyperUAS-Imaging Spectroscopy from a Multirotor\nUnmanned Aircraft\
    \ System: HyperUAS-Imaging Spectroscopy from a Multirotor Unmanned. J. Field Robot.\n\
    2014, 31, 571–590. [CrossRef]\n50.\nUto, K.; Seki, H.; Saito, G.; Kosugi, Y. Characterization\
    \ of Rice Paddies by a UAV-Mounted Miniature\nHyperspectral Sensor System. IEEE\
    \ J. Sel. Top. Appl. Earth Obs. Remote Sens. 2013, 6, 851–860. [CrossRef]\n51.\n\
    Uto, K.; Seki, H.; Saito, G.; Kosugi, Y.; Komatsu, T. Development of a Low-Cost,\
    \ Lightweight Hyperspectral\nImaging System Based on a Polygon Mirror and Compact\
    \ Spectrometers. IEEE J. Sel. Top. Appl. Earth Obs.\nRemote Sens. 2016, 9, 861–875.\
    \ [CrossRef]\n52.\nRozas, G.; Jusserand, B.; Fainstein, A. Fabry-Pérot-multichannel\
    \ spectrometer tandem for ultra-high\nresolution Raman spectroscopy. Rev. Sci.\
    \ Instrum. 2014, 85, 13103. [CrossRef] [PubMed]\n53.\nHonkavaara, E.; Hakala,\
    \ T.; Kirjasniemi, J.; Lindfors, A.; Mäkynen, J.; Nurminen, K.; Ruokokoski, P.;\
    \ Saari, H.;\nMarkelin, L. New light-weight stereosopic spectrometric airborne\
    \ imaging technology for high-resolution\nenvironmental remote sensing case studies\
    \ in water quality mapping. Int. Arch. Photogramm. Remote Sens.\nSpat. Inf. Sci.\
    \ 2013, 1, W1. [CrossRef]\n54.\nBioucas-Dias, J.M.; Plaza, A.; Camps-Valls, G.;\
    \ Scheunders, P.; Nasrabadi, N.; Chanussot, J. Hyperspectral\nRemote Sensing Data\
    \ Analysis and Future Challenges. IEEE Geosci. Remote Sens. Mag. 2013, 1, 6–36.\n\
    [CrossRef]\n55.\nHabib, A.; Xiong, W.; He, F.; Yang, H.L.; Crawford, M. Improving\
    \ Orthorectiﬁcation of UAV-Based\nPush-Broom Scanner Imagery Using Derived Orthophotos\
    \ From Frame Cameras. IEEE J. Sel. Top. Appl.\nEarth Obs. Remote Sens. 2017, 10,\
    \ 262–276. [CrossRef]\n56.\nPhotonics, Headwall VNIR. Available online: http://www.headwallphotonics.com/spectral-imaging/\n\
    hyperspectral/vnir (accessed on 2 April 2017).\n57.\nDuan, S.-B.; Li, Z.-L.; Tang,\
    \ B.-H.; Wu, H.; Ma, L.; Zhao, E.; Li, C. Land Surface Reﬂectance Retrieval from\n\
    Hyperspectral Data Collected by an Unmanned Aerial Vehicle over the Baotou Test\
    \ Site. PLoS ONE 2013, 8,\ne66972. [CrossRef]\n58.\nJakob, S.; Zimmermann, R.;\
    \ Gloaguen, R. The Need for Accurate Geometric and Radiometric Corrections\nof\
    \ Drone-Borne Hyperspectral Data for Mineral Exploration: MEPHySTo—A Toolbox for\
    \ Pre-Processing\nDrone-Borne Hyperspectral Data. Remote Sens. 2017, 9, 88. [CrossRef]\n\
    59.\nHruska, R.; Mitchell, J.; Anderson, M.; Glenn, N.F. Radiometric and Geometric\
    \ Analysis of Hyperspectral\nImagery Acquired from an Unmanned Aerial Vehicle.\
    \ Remote Sens. 2012, 4, 2736–2752. [CrossRef]\n60.\nChen, H.S. Remote Sensing\
    \ Calibration Systems: An Introduction; A. Deepak: Oakland, CA, USA, 1997;\nISBN\
    \ 978-0-937194-38-6.\n61.\nRichter, R.; Schlapfer, D.; Muller, A. Operational\
    \ Atmospheric Correction for Imaging Spectrometers\nAccounting for the Smile Effect.\
    \ IEEE Trans. Geosci. Remote Sens. 2011, 49, 1772–1780. [CrossRef]\n62.\nMendez-Rial,\
    \ R.; Calvino-Cancela, M.; Martin-Herrero, J. Accurate Implementation of Anisotropic\
    \ Diffusion\nin the Hypercube. IEEE Geosci. Remote Sens. Lett. 2010, 7, 870–874.\
    \ [CrossRef]\n63.\nQian, S.E.; Chen, G. Enhancing Spatial Resolution of Hyperspectral\
    \ Imagery Using Sensor’s Intrinsic\nKeystone Distortion. IEEE Trans. Geosci. Remote\
    \ Sens. 2012, 50, 5033–5048. [CrossRef]\n64.\nAlparone, L.; Wald, L.; Chanussot,\
    \ J.; Thomas, C.; Gamba, P.; Bruce, L.M. Comparison of Pansharpening\nAlgorithms:\
    \ Outcome of the 2006 GRS-S Data-Fusion Contest. IEEE Trans. Geosci. Remote Sens.\
    \ 2007, 45,\n3012–3021. [CrossRef]\nRemote Sens. 2017, 9, 1110\n27 of 30\n65.\n\
    Herrero, R.; Cadirola, M.; Ingle, V.K. Preprocessing and compression of Hyperspectral\
    \ images captured\nonboard UAVs. In Proceedings of the SPIE 9647, Unmanned/Unattended\
    \ Sensors and Sensor Networks\nXI; and Advanced Free-Space Optical Communication\
    \ Techniques and Applications, Toulouse, France,\n13 October 2015; p. 964705.\n\
    66.\nBurger, J.; Gowen, A. Data handling in hyperspectral image analysis. Chemom.\
    \ Intell. Lab. Syst. 2011, 108,\n13–22. [CrossRef]\n67.\nLandgrebe, D. Hyperspectral\
    \ image data analysis. IEEE Signal Process. Mag. 2002, 19, 17–28. [CrossRef]\n\
    68.\nDu, Q.; Raksuntorn, N. Hyperspectral image analysis using noise-adjusted\
    \ principal component transform.\nIn Proceedings of the SPIE Algorithms and Technologies\
    \ for Multispectral, Hyperspectral, and Ultraspectral\nImagery XII, Orlando, FL,\
    \ USA, 4 May 2006.\n69.\nChen, C. Comparison of principal components analysis\
    \ and minimum noise fraction transformation for\nreducing the dimensionality of\
    \ hyperspectral imagery. Geogr. Res. 2000, 163–178.\n70.\nNasrabadi, N.M. Hyperspectral\
    \ Target Detection: An Overview of Current and Future Challenges.\nIEEE Signal\
    \ Process. Mag. 2014, 31, 34–44. [CrossRef]\n71.\nManolakis, D.; Shaw, G. Detection\
    \ algorithms for hyperspectral imaging applications.\nIEEE Signal\nProcess. Mag.\
    \ 2002, 19, 29–43. [CrossRef]\n72.\nKay, S.M. Fundamentals of Statistical Signal\
    \ Processing; Prentice-Hall: Englewood Cliffs, NJ, USA, 1998.\n73.\nShippert,\
    \ P. Introduction to hyperspectral image analysis. Online J. Space Commun. 2003,\
    \ 3, 13.\n74.\nBioucas-Dias, J.M.; Plaza, A.; Dobigeon, N.; Parente, M.; Du, Q.;\
    \ Gader, P.; Chanussot, J. Hyperspectral\nUnmixing Overview: Geometrical, Statistical,\
    \ and Sparse Regression-Based Approaches. IEEE J. Sel. Top.\nAppl. Earth Obs.\
    \ Remote Sens. 2012, 5, 354–379. [CrossRef]\n75.\nKeshava, N.; Mustard, J.F. Spectral\
    \ unmixing. IEEE Signal Process. Mag. 2002, 19, 44–57. [CrossRef]\n76.\nRichmond,\
    \ C.D. Derived PDF of maximum likelihood signal estimator which employs an estimated\
    \ noise\ncovariance. IEEE Trans. Signal Process. 1996, 44, 305–315. [CrossRef]\n\
    77.\nKelly, E.J. An Adaptive Detection Algorithm. IEEE Trans. Aerosp. Electron.\
    \ Syst. 1986, AES-22, 115–127.\n[CrossRef]\n78.\nKelly, E.J. Adaptive Detection\
    \ in Non-Stationary Interference, Part III; MIT Lincoln Laboratory: Lexington,\
    \ MA,\nUSA, 1987.\n79.\nReed, I.S.; Yu, X. Adaptive multiple-band CFAR detection\
    \ of an optical pattern with unknown spectral\ndistribution. IEEE Trans. Acoust.\
    \ Speech Signal Process. 1990, 38, 1760–1770. [CrossRef]\n80.\nKraut, S.; Scharf,\
    \ L.L. The CFAR adaptive subspace detector is a scale-invariant GLRT. In Proceedings\n\
    of the Ninth IEEE Signal on Workshop on Statistical Signal and Array Processing,\
    \ Portland, OR, USA,\n14–16 September 1998; pp. 57–60.\n81.\nKraut, S.; Scharf,\
    \ L.L.; McWhorter, L.T. Adaptive subspace detectors. IEEE Trans. Signal Process.\
    \ 2001, 49,\n1–16. [CrossRef]\n82.\nScharf, L.L.; Friedlander, B. Matched subspace\
    \ detectors. IEEE Trans. Signal Process. 1994, 42, 2146–2157.\n[CrossRef]\n83.\n\
    Manolakis, D.; Siracusa, C.; Shaw, G. Hyperspectral subpixel target detection\
    \ using the linear mixing model.\nIEEE Trans. Geosci. Remote Sens. 2001, 39, 1392–1409.\
    \ [CrossRef]\n84.\nGoldberg, H.; Nasrabadi, N.M. A comparative study of linear\
    \ and nonlinear anomaly detectors for\nhyperspectral imagery.\nIn Proceedings\
    \ of the SPIE Algorithms and Technologies for Multispectral,\nHyperspectral, and\
    \ Ultraspectral Imagery XIII, Orlando, FL, USA, 9–13 April 2007; p. 656504.\n\
    85.\nKwon, H.; Nasrabadi, N.M. Kernel RX-algorithm: A nonlinear anomaly detector\
    \ for hyperspectral imagery.\nIEEE Trans. Geosci. Remote Sens. 2005, 43, 388–397.\
    \ [CrossRef]\n86.\nBanerjee, A.; Burlina, P.; Diehl, C. A support vector method\
    \ for anomaly detection in hyperspectral imagery.\nIEEE Trans. Geosci. Remote\
    \ Sens. 2006, 44, 2282–2291. [CrossRef]\n87.\nPieper, M.; Manolakis, D.; Truslow,\
    \ E.; Cooley, T.; Brueggeman, M.; Weisner, A.; Jacobson, J. Comparison of\nhyperspectral\
    \ change detection algorithms. In Proceedings of the SPIE Optical Engineering\
    \ + Applications,\nSan Diego, CA, USA, 9–13 August 2015; p. 96110Z.\n88.\nRobey,\
    \ F.C.; Fuhrmann, D.R.; Kelly, E.J.; Nitzberg, R. A CFAR adaptive matched ﬁlter\
    \ detector. IEEE Trans.\nAerosp. Electron. Syst. 1992, 28, 208–216. [CrossRef]\n\
    89.\nHarsanyi, J.C.; Chang, C.I. Hyperspectral image classiﬁcation and dimensionality\
    \ reduction: An orthogonal\nsubspace projection approach. IEEE Trans. Geosci.\
    \ Remote Sens. 1994, 32, 779–785. [CrossRef]\nRemote Sens. 2017, 9, 1110\n28 of\
    \ 30\n90.\nScholkopf, B.; Smola, A.J. Learning with Kernels: Support Vector Machines,\
    \ Regularization, Optimization, and\nBeyond; MIT Press: Cambridge, MA, USA, 2001;\
    \ ISBN 978-0-262-19475-4.\n91.\nSchaum, A. Continuum fusion: A theory of inference,\
    \ with applications to hyperspectral detection.\nOpt. Express 2010, 18, 8171–8181.\
    \ [CrossRef] [PubMed]\n92.\nManolakis, D.; Truslow, E.; Pieper, M.; Cooley, T.;\
    \ Brueggeman, M. Detection Algorithms in Hyperspectral\nImaging Systems: An Overview\
    \ of Practical Algorithms. IEEE Signal Process. Mag. 2014, 31, 24–33. [CrossRef]\n\
    93.\nDiPietro, R.S.; Manolakis, D.; Lockwood, R.B.; Cooley, T.; Jacobson, J. Hyperspectral\
    \ matched ﬁlter with\nfalse-alarm mitigation. Opt. Eng. 2012, 51, 16202. [CrossRef]\n\
    94.\nPieper, M.L.; Manolakis, D.; Truslow, E.; Cooley, T.; Brueggeman, M. False\
    \ alarm mitigation techniques for\nhyperspectral target detection. In Proceedings\
    \ of the SPIE Defense, Security, and Sensing, Baltimore, MD,\nUSA, 29 April–3\
    \ May 2013; p. 874304. [CrossRef]\n95.\nBurr, T.; Fry, H.; McVey, B.; Sander,\
    \ E.; Cavanaugh, J.; Neath, A. Performance of Variable Selection Methods\nin Regression\
    \ Using Variations of the Bayesian Information Criterion. Commun. Stat. Simul.\
    \ Comput. 2008,\n37, 507–520. [CrossRef]\n96.\nKeshava, N. Distance metrics and\
    \ band selection in hyperspectral processing with applications to material\nidentiﬁcation\
    \ and spectral libraries. IEEE Trans. Geosci. Remote Sens. 2004, 42, 1552–1565.\
    \ [CrossRef]\n97.\nMatteoli, S.; Diani, M.; Corsini, G. A tutorial overview of\
    \ anomaly detection in hyperspectral images.\nIEEE Aerosp. Electron. Syst. Mag.\
    \ 2010, 25, 5–28. [CrossRef]\n98.\nKwon, H.; Nasrabadi, N.M. A Comparative Analysis\
    \ of Kernel Subspace Target Detectors for Hyperspectral\nImagery. EURASIP J. Adv.\
    \ Signal Process. 2006, 2007, 29250. [CrossRef]\n99.\nRichards, J.A.; Jia, X.\
    \ Remote Sensing Digital Image Analysis: An Introduction; Springer: New York,\
    \ NY,\nUSA, 1990.\n100. Plaza, A.; Benediktsson, J.A.; Boardman, J.W.; Brazile,\
    \ J.; Bruzzone, L.; Camps-Valls, G.; Chanussot, J.;\nFauvel, M.; Gamba, P.; Gualtieri,\
    \ A.; et al. Recent advances in techniques for hyperspectral image processing.\n\
    Remote Sens. Environ. 2009, 113 (Suppl. S1), S110–S122. [CrossRef]\n101. Boser,\
    \ B.E.; Guyon, I.M.; Vapnik, V.N. A Training Algorithm for Optimal Margin Classiﬁers.\
    \ In Proceedings\nof the Fifth Annual Workshop on Computational Learning Theory,\
    \ New York, NY, USA, 27–29 July 1992;\npp. 144–152.\n102. Mercier, G.; Lennon,\
    \ M. Support vector machines for hyperspectral image classiﬁcation with spectral-based\n\
    kernels. In Proceedings of the 2003 IEEE International Conferences on Geoscience\
    \ and Remote Sensing\nSymposium, Toulouse, France, 21–25 July 2003; pp. 288–290.\n\
    103. Chi, M.; Bruzzone, L. Semisupervised Classiﬁcation of Hyperspectral Images\
    \ by SVMs Optimized in the\nPrimal. IEEE Trans. Geosci. Remote Sens. 2007, 45,\
    \ 1870–1880. [CrossRef]\n104. Kasetkasem, T.; Arora, M.K.; Varshney, P.K. Super-resolution\
    \ land cover mapping using a Markov random\nﬁeld based approach. Remote Sens.\
    \ Environ. 2005, 96, 302–314. [CrossRef]\n105. Chen, Y.; Wang, G.; Dong, S. Learning\
    \ with progressive transductive support vector machine. Pattern\nRecognit. Lett.\
    \ 2003, 24, 1845–1855. [CrossRef]\n106. Tadjudin, S.; Landgrebe, D. Classiﬁcation\
    \ of High Dimensional Data with Limited Training Samples.\nAvailable online: http://docs.lib.purdue.edu/ecetr/56/\
    \ (accessed on 20 March 2017).\n107. Appice, A.; Guccione, P.; Malerba, D. A novel\
    \ spectral-spatial co-training algorithm for the transductive\nclassiﬁcation of\
    \ hyperspectral imagery data. Pattern Recognit. 2017, 63, 229–245. [CrossRef]\n\
    108. Bandos, T.V.; Bruzzone, L.; Camps-Valls, G. Classiﬁcation of Hyperspectral\
    \ Images with Regularized Linear\nDiscriminant Analysis. IEEE Trans. Geosci. Remote\
    \ Sens. 2009, 47, 862–873. [CrossRef]\n109. Camps-Valls, G.; Marsheva, T.V. B.;\
    \ Zhou, D. Semi-Supervised Graph-Based Hyperspectral Image\nClassiﬁcation. IEEE\
    \ Trans. Geosci. Remote Sens. 2007, 45, 3044–3054. [CrossRef]\n110. Agapiou, A.;\
    \ Hadjimitsis, D.G.; Alexakis, D.D. Evaluation of Broadband and Narrowband Vegetation\
    \ Indices\nfor the Identiﬁcation of Archaeological Crop Marks. Remote Sens. 2012,\
    \ 4, 3892–3919. [CrossRef]\n111. Stagakis, S.; Markos, N.; Sykioti, O.; Kyparissis,\
    \ A. Monitoring canopy biophysical and biochemical\nparameters in ecosystem scale\
    \ using satellite hyperspectral imagery: An application on a Phlomis fruticosa\n\
    Mediterranean ecosystem using multiangular CHRIS/PROBA observations. Remote Sens.\
    \ Environ. 2010, 114,\n977–994. [CrossRef]\nRemote Sens. 2017, 9, 1110\n29 of\
    \ 30\n112. Haboudane, D.; Miller, J.R.; Pattey, E.; Zarco-Tejada, P.J.; Strachan,\
    \ I.B. Hyperspectral vegetation indices\nand novel algorithms for predicting green\
    \ LAI of crop canopies: Modeling and validation in the context of\nprecision agriculture.\
    \ Remote Sens. Environ. 2004, 90, 337–352. [CrossRef]\n113. Zarco-Tejada, P.;\
    \ Berjon, A.; Lopezlozano, R.; Miller, J.; Martin, P.; Cachorro, V.; Gonzalez,\
    \ M.; Defrutos, A.\nAssessing vineyard condition with hyperspectral indices: Leaf\
    \ and canopy reﬂectance simulation in a\nrow-structured discontinuous canopy.\
    \ Remote Sens. Environ. 2005, 99, 271–287. [CrossRef]\n114. Lin, P.; Qin, Q.;\
    \ Dong, H.; Meng, Q. Hyperspectral vegetation indices for crop chlorophyll estimation:\n\
    Assessment, modeling and validation. In Proceedings of the 2012 IEEE International\
    \ conferences on\nGeoscience and Remote Sensing Symposium, Munich, Germany, 22–27\
    \ July 2012; pp. 4841–4844.\n115. Liang, L.; Qin, Z.; Zhao, S.; Di, L.; Zhang,\
    \ C.; Deng, M.; Lin, H.; Zhang, L.; Wang, L.; Liu, Z. Estimating\ncrop chlorophyll\
    \ content with hyperspectral vegetation indices and the hybrid inversion method.\
    \ Int. J.\nRemote Sens. 2016, 37, 2923–2949. [CrossRef]\n116. Thenkabail, P.S.;\
    \ Lyon, J.G. Hyperspectral Remote Sensing of Vegetation; CRC Press: Boca Raton,\
    \ FL, USA, 2016;\nISBN 978-1-4398-4538-7.\n117. Din, M.; Zheng, W.; Rashid, M.;\
    \ Wang, S.; Shi, Z. Evaluating Hyperspectral Vegetation Indices for Leaf Area\n\
    Index Estimation of Oryza sativa L. at Diverse Phenological Stages. Front. Plant\
    \ Sci. 2017, 8. [CrossRef]\n[PubMed]\n118. Zhao, W.; Du, S. Spectral-Spatial Feature\
    \ Extraction for Hyperspectral Image Classiﬁcation: A Dimension\nReduction and\
    \ Deep Learning Approach. IEEE Trans. Geosci. Remote Sens. 2016, 54, 4544–4554.\
    \ [CrossRef]\n119. Wang, Q.; Lin, J.; Yuan, Y. Salient Band Selection for Hyperspectral\
    \ Image Classiﬁcation via Manifold\nRanking. IEEE Trans. Neural Netw. Learn. Syst.\
    \ 2016, 27, 1279–1289. [CrossRef] [PubMed]\n120. Zhong, Z.; Li, J.; Luo, Z.; Chapman,\
    \ M. Spectral-Spatial Residual Network for Hyperspectral Image\nClassiﬁcation:\
    \ A 3-D Deep Learning Framework. IEEE Trans. Geosci. Remote Sens. 2017, PP, 1–12.\
    \ [CrossRef]\n121. Aptoula, E.; Ozdemir, M.C.; Yanikoglu, B. Deep Learning With\
    \ Attribute Proﬁles for Hyperspectral Image\nClassiﬁcation. IEEE Geosci. Remote\
    \ Sens. Lett. 2016, 13, 1970–1974. [CrossRef]\n122. Li, W.; Wu, G.; Du, Q. Transferred\
    \ Deep Learning for Anomaly Detection in Hyperspectral Imagery.\nIEEE Geosci.\
    \ Remote Sens. Lett. 2017, 14, 597–601. [CrossRef]\n123. Hexagon Geospatial Erdas\
    \ Imagine® 2016 Product Features and Comparisons.\nAvailable online:\nhttp://www.hexagongeospatial.com/technical-documents/product-descriptions-2016/erdas-imagine-\n\
    2016-product-description (accessed on 9 October 2017).\n124. Harris Geospatial\
    \ ENVI Software Platform. Available online: http://www.harrisgeospatial.com/ (accessed\n\
    on 29 March 2017).\n125. Image Lab Software Bio-Rad. Available online: http://www.bio-rad.com/en-us/product/image-lab-\n\
    software (accessed on 29 March 2017).\n126. Brandywine Photonics Hyperspectral\
    \ Imaging and CMOS Image Sensors.\nAvailable online: http://\nbrandywinephotonics.com/\
    \ (accessed on 29 March 2017).\n127. Resonon Inc. SpectrononPro Manual (Release\
    \ 5.0). Available online: http://docs.resonon.com/spectronon/\npika_manual/SpectrononProManual.pdf\
    \ (accessed on 29 March 2017).\n128. Welcome to Spectral Python (SPy)—Spectral\
    \ Python 0.18 documentation. Available online: http://www.\nspectralpython.net/\
    \ (accessed on 29 March 2017).\n129. Jelmer Oosthoek Hyperspectral Python (HypPy).\
    \ Available online: https://www.itc.nl/personal/bakker/\nhyppy.html (accessed\
    \ on 29 March 2017).\n130. Rosario-Torres, S.; Arzuaga-Cruz, E.; Velez-Reyes,\
    \ M.; Jimenez-Rodriguez, L.O. An update on the MATLAB\nhyperspectral image analysis\
    \ toolbox. In Proceedings of the Defense and Security, Orlando, FL, USA,\n1 June\
    \ 2005; pp. 743–752.\n131. Isaac\nGerg\nMatlab\nHyperspectral\nToolbox.\nAvailable\n\
    online:\nhttps://github.com/isaacgerg/\nmatlabHyperspectralToolbox (accessed on\
    \ 29 March 2017).\n132. Landgrebe, D.; Biehl, L. An Introduction & Reference for\
    \ MultiSpec. Available online: ftp://bsa.bf.lu.lv/\npub/TIS/atteelu_analiize/MultiSpec/Intro9_11.pdf\
    \ (accessed on 29 March 2017).\n133. TensorFlow. Available online: https://www.tensorﬂow.org/\
    \ (accessed on 16 August 2017).\n134. Welcome—Theano 0.9.0 Documentation. Available\
    \ online: http://deeplearning.net/software/theano/\n(accessed on 16 August 2017).\n\
    Remote Sens. 2017, 9, 1110\n30 of 30\n135. Yamada, N.; Fujimura, S. Nondestructive\
    \ measurement of chlorophyll pigment content in plant leaves from\nthree-color\
    \ reﬂectance and transmittance. Appl. Opt. 1991, 30, 3964–3973. [CrossRef] [PubMed]\n\
    136. Honkavaara, E.; Saari, H.; Kaivosoja, J.; Pölönen, I.; Hakala, T.; Litkey,\
    \ P.; Mäkynen, J.; Pesonen, L. Processing\nand Assessment of Spectrometric, Stereoscopic\
    \ Imagery Collected Using a Lightweight UAV Spectral Camera\nfor Precision Agriculture.\
    \ Remote Sens. 2013, 5, 5006–5039. [CrossRef]\n137. Zarco-Tejada, P.J.; González-Dugo,\
    \ V.; Berni, J.A. J. Fluorescence, temperature and narrow-band indices\nacquired\
    \ from a UAV platform for water stress detection using a micro-hyperspectral imager\
    \ and a thermal\ncamera. Remote Sens. Environ. 2012, 117, 322–337. [CrossRef]\n\
    138. Calderón, R.; Navas-Cortés, J.A.; Lucena, C.; Zarco-Tejada, P.J. High-resolution\
    \ airborne hyperspectral\nand thermal imagery for early detection of Verticillium\
    \ wilt of olive using ﬂuorescence, temperature and\nnarrow-band spectral indices.\
    \ Remote Sens. Environ. 2013, 139, 231–245. [CrossRef]\n139. Burkart, A.; Aasen,\
    \ H.; Alonso, L.; Menz, G.; Bareth, G.; Rascher, U. Angular Dependency of Hyperspectral\n\
    Measurements over Wheat Characterized by a Novel UAV Based Goniometer. Remote\
    \ Sens. 2015, 7, 725–746.\n[CrossRef]\n140. Mitchell, J.J.; Glenn, N.F.; Anderson,\
    \ M.O.; Hruska, R.C.; Halford, A.; Baun, C.; Nydegger, N. Unmanned\naerial vehicle\
    \ (UAV) hyperspectral remote sensing for dryland vegetation monitoring. In Proceedings\n\
    of the 2012 4th Workshop on Hyperspectral Image and Signal Processing: Evolution\
    \ in Remote Sensing\n(WHISPERS), Shanghai, China, 4–7 June 2012; pp. 1–10.\n141.\
    \ Kaivosoja, J.; Pesonen, L.; Kleemola, J.; Pölönen, I.; Salo, H.; Honkavaara,\
    \ E.; Saari, H.; Mäkynen, J.; Rajala, A.\nA case study of a precision fertilizer\
    \ application task generation for wheat based on classiﬁed hyperspectral\ndata\
    \ from UAV combined with farm history data. In Proceedings of the SPIE Remote\
    \ Sensing, Dresden,\nGermany, 15 October 2013.\n142. Aasen, H.; Burkart, A.; Bolten,\
    \ A.; Bareth, G. Generating 3D hyperspectral information with lightweight\nUAV\
    \ snapshot cameras for vegetation monitoring: From camera calibration to quality\
    \ assurance. ISPRS J.\nPhotogramm. Remote Sens. 2015, 108, 245–259. [CrossRef]\n\
    143. Näsi, R.; Honkavaara, E.; Lyytikäinen-Saarenmaa, P.; Blomqvist, M.; Litkey,\
    \ P.; Hakala, T.; Viljanen, N.;\nKantola, T.; Tanhuanpää, T.; Holopainen, M. Using\
    \ UAV-Based Photogrammetry and Hyperspectral Imaging\nfor Mapping Bark Beetle\
    \ Damage at Tree-Level. Remote Sens. 2015, 7, 15467–15493. [CrossRef]\n144. Kotsiantis,\
    \ S.B. Supervised Machine Learning: A Review of Classiﬁcation Techniques. Informatica\
    \ 2007, 31.\n145. Berveglieri, A.; Tommaselli, A.M.G. Exterior Orientation of\
    \ Hyperspectral Frame Images Collected with\nUav for Forest Applications. ISPRS\
    \ Int. Arch. Photogramm. Remote Sens. Spat. Inf. Sci. 2016, XL-3/W4, 45–50.\n\
    [CrossRef]\n146. Saari, H.; Pellikka, I.; Pesonen, L.; Tuominen, S.; Heikkilä,\
    \ J.; Holmlund, C.; Mäkynen, J.; Ojala, K.; Antila, T.\nUnmanned Aerial Vehicle\
    \ (UAV) operated spectral camera system for forest and agriculture applications.\n\
    In Proceedings of the SPIE Remote Sensing for Agriculture, Ecosystems, and Hydrology\
    \ XIII, Prague,\nCzech Republic, 15 October 2011; Volume 8174.\n147. Honkavaara,\
    \ E.; Kaivosoja, J.; Mäkynen, J.; Pellikka, I.; Pesonen, L.; Saari, H.; Salo,\
    \ H.; Hakala, T.;\nMarklelin, L.; Rosnell, T. Hyperspectral Reﬂectance Signatures\
    \ and Point Clouds for Precision Agriculture\nby Light Weight Uav Imaging System.\
    \ ISPRS Ann. Photogramm. Remote Sens. Spat. Inf. Sci. 2012, 7, 353–358.\n[CrossRef]\n\
    148. Salamí, E.; Barrado, C.; Pastor, E. UAV Flight Experiments Applied to the\
    \ Remote Sensing of Vegetated\nAreas. Remote Sens. 2014, 6, 11051–11081. [CrossRef]\n\
    149. Adão, T.; Peres, E.; Pádua, L.; Hruška, J.; Sousa, J.J.; Morais, R. UAS-based\
    \ hyperspectral sensing methodology\nfor continuous monitoring and early detection\
    \ of vineyard anomalies. In Proceedings of the Small Unmanned\nAerial Systems\
    \ for Environmental Research, Vila Real, Portugal, 28–30 June 2017.\n© 2017 by\
    \ the authors. Licensee MDPI, Basel, Switzerland. This article is an open access\n\
    article distributed under the terms and conditions of the Creative Commons Attribution\n\
    (CC BY) license (http://creativecommons.org/licenses/by/4.0/).\n"
  inline_citation: '>'
  journal: Remote sensing (Basel)
  limitations: '>'
  pdf_link: https://www.mdpi.com/2072-4292/9/11/1110/pdf?version=1509505848
  publication_year: 2017
  relevance_score1: 0
  relevance_score2: 0
  title: 'Hyperspectral Imaging: A Review on UAV-Based Sensors, Data Processing and
    Applications for Agriculture and Forestry'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1109/sas54819.2022.9881337
  analysis: '>'
  authors:
  - Adduru U G Sankararao
  - P. Rajalakshmi
  - Sivasakthi Kaliamoorthy
  - Sunitha Choudhary
  citation_count: 2
  full_citation: '>'
  full_text: '>

    This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences Loading
    [MathJax]/extensions/MathZoom.js IEEE.org IEEE Xplore IEEE SA IEEE Spectrum More
    Sites Donate Cart Create Account Personal Sign In Browse My Settings Help Access
    provided by: University of Nebraska - Lincoln Sign Out All Books Conferences Courses
    Journals & Magazines Standards Authors Citations ADVANCED SEARCH Conferences >2022
    IEEE Sensors Application... Water Stress Detection in Pearl Millet Canopy with
    Selected Wavebands using UAV Based Hyperspectral Imaging and Machine Learning
    Publisher: IEEE Cite This PDF Adduru U G Sankararao; P. Rajalakshmi; Sivasakthi
    Kaliamoorthy; Sunitha Choudhary All Authors 2 Cites in Papers 251 Full Text Views
    Abstract Document Sections I. Introduction II. Experiment and Data Acquisition
    III. HSI Data Analysis IV. Results and Discussion V. Conclusion Authors Figures
    References Citations Keywords Metrics Abstract: The major bottleneck in plant
    phenotyping is the assessment of thousands of genotypes under field conditions,
    which can be accelerated through Unmanned Aerial Vehicle (UAV) based sensing.
    Phenotyping for complex traits such as abiotic stress (drought) adaptation can
    be explored more precisely through the rich spectral information acquired by Hyperspectral
    Imaging (HSI) sensors. HSI sensors can identify plant water stress early by observing
    the changes in canopy reflectance due to drought. This study used a UAV-based
    HSI sensor in the 400-1000 nm range to identify canopy water stress in the pearl
    millet crop. Five Machine learning-based Feature Selection (FS) methods were used
    to identify the top-ranked ten wavebands sensitive to canopy water stress. Wavelengths
    around 692, 714-716, 763-769, 774-882, 870, and 949 nm were repeatedly selected
    by two or more FS methods. The Recursive feature elimination method with the Support
    vector machine (SVM) classifier outperformed the other FS methods in selecting
    the best bands subset. SVM classifier with linear kernel on the selected bands
    could classify two water stress levels with 95.38% accuracy and early detect stress
    with 80.76% accuracy in the pearl millet canopy. This study will benefit the agriculture
    sector by accelerating crop phenotyping using UAV-based HSI. Published in: 2022
    IEEE Sensors Applications Symposium (SAS) Date of Conference: 01-03 August 2022
    Date Added to IEEE Xplore: 12 September 2022 ISBN Information: DOI: 10.1109/SAS54819.2022.9881337
    Publisher: IEEE Conference Location: Sundsvall, Sweden SECTION I. Introduction
    In recent years, the demand for food production in agriculture sector has been
    increasing with the rapid increase in the world’s population [1]. Due to a decrease
    in rainfall in the last decade, the farmers are forced to depend on groundwater
    to meet the irrigation requirements of the crop. Over the last decade, the speed
    of climatic changes has taken humanity by surprise. The agricultural scientists
    are working intensively to generate climate-smart crop varieties resilient to
    future climate scenarios like increased drought and heat periods. The major bottleneck
    in crop improvement is the assessment of thousands of genotypes under field conditions
    called plant phenotyping and mostly done visually to date. The traditional phenotyping
    methodologies (i.e., manual observations or laboratory assessments) are costlier,
    time-consuming, labor-intensive, destructive, and are frequently not standardized.
    Another drawback of these methods is that one requires the capacity to associate
    biological understanding with the monitored data, which is often missing. Many
    sensors have been developed to automate this process, but the current tools only
    deliver partly the traits required by agriculture scientists and are pretty expensive.
    UAV-based remote sensing is emerging quickly to accelerate crop phenotyping and
    has proven the potential to revolutionize agriculture [2], [3]. Till now, UAVs
    have been exploited in a variety of applications related to crop management by
    capturing high spatial and temporal resolution images by integrating mostly RGB
    cameras and partly multispectral cameras for yield and its attributing traits
    [3], [4]. However, phenotyping for complex traits of abiotic stress adaptation
    (drought and heat), like early detection of water stress can be explored more
    precisely through HSI sensors. HSI sensors acquire rich spectral information in
    the 400 nm to 2500 nm range, which is capable of identifying the changes in canopy
    water content which is crucial in predicting irrigation requirements that can
    have successful application in agriculture [5], [6]. Motivated by this, we used
    UAV-based hyperspectral imaging technology to detect water stress in the pearl
    millet crop. In [7], the authors observed that leaf reflectance in the visible
    and near-infrared spectrum is highly correlated to the leaf equivalent water thickness
    changes, and used hyperspec-tral (HS) regression indices for estimating the canopy
    water content. The canopy water status in maize [8], and different crop varieties
    [5] was studied using HS vegetation indices (VIs). [9] studied the use of various
    narrow-band VIs for detecting the combined effects of water and nitrogen stress
    in field-grown tomato crops. NIR water absorption features at 970 nm, 1200 nm,
    and the derivative spectra were used in [10] for canopy water content retrieval
    [10]. Near-range HSI was used in [6] to identify drought stress in maize plants
    by utilizing spectral similarity in the bands with high discriminating information.
    Airborne HSI was used in [11] to early identify water stress in corn at the farm
    level with three irrigation levels. Machine learning (ML) algorithms combined
    with complete and derivative spectra obtained from close-range HSI were employed
    in [12] for early drought stress detection in Bromus inermis. UAV-based RGB imaging
    and a CNN model were used in [4] to detect water-stressed areas in maize fields;
    however, early detection is not viable with RGB images. Different ML approaches
    such as random forest (RF), SVM, multilayer perceptron (MLP), and 2D CNN along
    with HSI were used in [13] for water stress diagnosis in potato plants. In [14],
    UAV-based HSI and CNNs were used to classify water stress in chickpea using the
    complete spectrum in the 400-1000 nm range. Most of the studies mentioned above
    used VIs for canopy water status analysis in different crops; however, the VIs,
    which focus only on specific bands, cannot capture changes in other bands caused
    due to drought stress, hence reducing the discrimination ability. Also, using
    the complete spectrum is computationally complex due to the high dimensionality
    of HSI data and requires more labeled samples [15]. Analyzing the selected water
    stress-sensitive bands instead of using the whole spectrum improves stress detection
    accuracy by avoiding irrelevant bands that may be susceptible to other factors
    (such as nutrients and diseases), and reduces the computational complexity and
    requirement for more labeled data. Six feature selection (FS) methods were used
    in [16] to reduce the dimensionality of HS data for classifying salt stress in
    different wheat genotypes. In [17], ensemble of different FS methods were used
    for HS band selection in grape leaves for nitrogen status detection. HS sensing
    and ML-based FS techniques were used in [18] for identifying optimal wavelengths
    to discriminate between the healthy and diseased peanut crop. In this study, we
    used different ML-based FS techniques for identifying the most effective wavelengths
    sensitive to canopy water stress, and the RF and SVM classifiers on the selected
    wavelengths for water stress classification in pearl millet using the HSI data
    captured from the UAV platform. Our study is the first attempt to present water-stress
    sensitive band selection and stress detection in pearl millet using UAV-based
    HS sensing to the best of our knowledge. The key contributions of this paper are:
    i) selecting the top-ranked wavebands sensitive to canopy water stress with different
    FS methods, ii) Early identification of canopy water stress, and iii) Different
    water stress levels classification in pearl millet. SECTION II. Experiment and
    Data Acquisition For this study, pearl millet is the target crop, and the water
    stress experiment was conducted from Feb to April 2021 at the Lysimetric facility
    [19] of the International Crops Research Institute for the Semi-Arid Tropics (ICRISAT),
    Hyderabad, India. The drought experiment consisted of two water treatments, i.
    well-watered (WW), ii. water-stressed (WS), shown in Fig. 1. Each treatment consisted
    of 350 genomic varieties, where WW treatment had four replications, and WS treatment
    had five replications, a total of 3150 genotypes. The plants were grown in plastic
    cylinders for precise water treatments and measurements. In each replication,
    the genotype placement was random, and the cylinders were closely placed to create
    real field conditions. For WW treatment, sufficient irrigation was given at regular
    intervals throughout the experiment, i.e., from sowing until harvesting. For WS
    treatment, the irrigation was withheld from the 30th day after sowing, and progressive
    water stress was observed. The soil moisture level measurements were taken by
    weighting the cylinders at regular intervals to observe the plants’ water utilization
    profiles. Fig. 1: Orthomosaic view of pearl millet drought stress experiment (well-watered
    (WW) and water-stressed (WS) plots). Show All The UAV-based HSI sensor system
    setup that was used for acquiring hyperspectral imaging data is shown in Fig.
    2, which consists of a Resonon’s Pika-L HSI sensor mounted on a DJI matrice-600
    Pro UAV. The HSI sensor is a push-broom scanner with 900 spatial channels and
    281 spectral channels in the 400-1000 nm range with 2.1 nm spectral resolution.
    The HS images of pearl millet were acquired on two dates: 25th March 2021 (12
    days after the irrigation withheld: Water stress level 1 (WS1)) and 31st March
    2021 (18 days after the irrigation withheld: Water stress level 2 (WS2)) for observing
    progressive water stress. For data collection, between 11 am and 1 pm was chosen,
    which is the suitable time for acquiring HS reflectance data. The images of the
    pearl millet canopy were acquired by flying the UAV at 25 m altitude with 4.0
    kmph speed, which gives around 0.9 cm pixel-level resolution. A 3m x 3m single-level
    homogeneous gray calibration panel with 36% reflectance (bordered black in Fig.
    1) was used for the reflectance calibration of HSI data cubes. SECTION III. HSI
    Data Analysis A. Data Analysis Pipeline The HSI data analysis pipeline for water
    stress classification is shown in Fig. 3. The HSI data collected during the flight
    is in raw data cubes consisting of unwanted components such as solar illumination,
    instrument response along with canopy reflectance. The radiance conversion and
    reflectance calibration were done to get absolute reflectance data of the canopy.
    Then the geometric calibrations of the data cubes were performed to obtain the
    geo-rectified images, which can now map to the locations in the field, after which
    we can select a region of interest [20]. Post these corrections, the spectral
    signatures in the HSI data cubes were smoothed using Savitzky-Golay filter [21]
    with a third-order polynomial and a window size of 13. The mean spectrum of the
    pearl millet canopy with different stress levels after Savitzky-Golay smoothing
    is shown in Fig. 4. After this step, the data labeling and data set creation was
    done, which is explained in Section III-B. Now comes the band selection step with
    different ML-based FS methods for selecting the top-ranked effective wavelengths
    sensitive to canopy water stress as explained in Section III-C. The top-ranked
    ten bands selected by the best performing FS method in the previous step were
    used to classify canopy water stress in the pearl millet using ML-based classifiers
    (SVM or RF). Fig. 2: Setup of the UAV-based HSI system. Show All Fig. 3: Data
    analysis pipeline for water stress classification. Show All B. Data Sets Creation
    Each of the collected HS data cubes has 2000 x 900 spatial pixels and 281 spectral
    channels (i.e., 2000 x 900 x 281). The canopy HSI data was designated into three
    classes, ie. Well-Watered (WW), water stress level 1 (WS1: acquired on 12th day
    after irrigation withheld), and water stress level 2 (WS2: acquired on 18th day
    after irrigation withheld). The normalized difference VI and transformed chlorophyll
    absorption reflectance index [22] were used to separate the background and mixed
    pixels from the canopy. The ground truth was created by manually labeling the
    canopy pixels corresponding to each of the water treatments. Two replications
    of each treatment/class were used to create training data (2x350 = 700 genotypes
    per class), and one replication was used to create test data (350 genotypes per
    class). Around 1840 samples per class for the train set and 1010 samples per class
    for the test set were created. The data set consists a total of 8550 samples,
    of which the train and test set splits are approximately 65% and 35%, respectively.
    Fig. 4: Mean spectrum of pearl millet canopy with different water stress levels.
    Show All C. Hyperspectral Band Selection and Classification HSI sensors provide
    rich spectral information in hundreds of narrow wavebands, which increases the
    information content, but high dimensional HSI data analysis is complex and challenging.
    Feature extraction and feature selection methods are widely applied to HSI data
    for dimensionality reduction by removing spectral redundancy [15]. The feature
    extraction methods transform the original high dimensional HSI data into a new
    low dimensional feature space, which changes the physical meaning of the original
    data. Whereas, Feature selection, well known as band selection (BS), reduces the
    dimensionality by selecting a subset of the most influential wavelengths for a
    specific task such as classification or anomaly detection [15]. BS methods preserve
    the physical meaning of the selected spectral bands keeping the original information
    as it is. Instead of using the whole spectral data, analysis on the selected top-ranked
    water stress-sensitive wavebands will improve the accuracy in stress detection,
    and also reduce the computational complexity and requirement for more labeled
    data. Also, using selected wavelengths will eliminate the possibility of using
    bands that are not water stress-sensitive but may be susceptible to other factors
    such as nutrients, diseases, etc. In this study for salient water-sensitive band
    selection, five ML-based FS methods from the scikit-learn library were used [23],
    which include a univariate FS method (SelectKBest using the Chi-square test),
    two FS methods using SelectFrom-Model (SFM), and two recursive feature elimination
    (RFE) methods. Both SFM and RFE require an external estimator to assign weights
    to the features; in this study, SVM with linear kernel and RF are the external
    estimators. RFE selects a desirable number of features by recursively removing
    less relevant features by considering smaller and smaller sets of features. The
    FS methods are compared with the classification accuracy of the SVM classifier
    with the linear kernel (hereafter called SVM for simplicity) on the top-ranked
    ten features selected by each method [18]. The band subset selected by the best
    performing FS method (with the highest classification accuracy) was used for further
    analysis, i.e., to classify canopy water stress in the pearl millet HSI data.
    On the selected band subset, SVM and RF classifiers are used to identify early
    water stress, and to classify different water stress levels in the canopy HSI
    data. SVM uses separating hyperplanes to maximize the margins between each class
    [24], whereas the RF employs ensemble-learning by combining multiple decision-tree-based
    classifiers [25]. For each of these classifiers, default hyperpa-rameters were
    used in this study. The usage of SVM and RF classifiers at different stages of
    the analysis is summarized in the Fig. 5. Fig. 5: Usage of classifiers at different
    stages of the analysis. Show All TABLE I: Canopy water-stress classification results
    on WS1-WS2 data with whole spectral bands. SECTION IV. Results and Discussion
    This study used HSI data of WS1 and WS2 classes to select top-ranked water-stress
    sensitive bands using different ML-based FS methods. The reason for using this
    is two folds: i) WS1 and WS2 are the data acquired of the same plots (WS plots)
    at different stress levels, which will be more appropriate for comparison. ii)
    the water-stressed plots canopy on the 18th day after irrigation withheld (WS2)
    will have more water stress that leads to more changes in canopy reflectance.
    The changes in canopy reflectance can be more accurately observed in the WS-sensitive
    wavebands. Further, using these selected water-stress sensitive bands will be
    efficient in classifying/early detecting canopy water stress in pearl millet.
    As explained in III-B, approximately 65% samples were used for training the models
    and 35% samples for testing. The classification accuracy was evaluated using the
    overall accuracy (OA), Precision, Recall, and F1-score as the performance metrics.
    The water stress classification accuracies on WS1-WS2 data with whole spectral
    bands using SVM with linear kernel and RF classifiers are shown in Table I. The
    performance of SVM and RF is almost the same on the whole spectral bands; however,
    SVM performed slightly better (95.59%). For this reason, the classification accuracy
    of SVM was used to compare different FS methods in selecting the best band subset
    sensitive to canopy water stress. TABLE II: Water-stress sensitive wavelengths
    selected by different FS methods on WS1-WS2 data. TABLE III: Water stress classification
    accuracies using SVM on selected bands by different FS methods. The top-ranked
    ten bands sensitive to water stress in pearl millet canopy selected with different
    ML-based FS methods are shown in Table II. From Table II, it is clear that the
    FS methods give a different subset of wavelengths depending on the type FS method
    and classification model used for assigning scores to the features. The wavelengths
    selected by the Chi-square test are limited to a narrow spectral region (763-783
    nm). Interestingly, SFM and RFE using the RF estimator identified similar wavelengths
    in four narrow waveband regions (688-692 nm, 765-769 nm, 774-882 nm, 870 nm) with
    somewhat different rankings. Several wavebands were repeatedly selected as top
    features by two or more FS methods around 692 nm, 714-716 nm, 763-769 nm, 774-882
    nm, 870 nm, and 949 nm regions. The bands around 765-769 nm, 776 nm, and 780 nm
    would be most influential to canopy water stress in pearl millet as at least three
    FS methods selected them. Using an ensemble of multiple FS methods will be recommended
    for optimal band selection of HSI data as the subset of wavelengths selected by
    different FS methods are different. TABLE IV: Different water stress levels classification
    accuracies (OA) using SVM on the selected bands by RFE-SVM. The water stress classification
    accuracies on WS1-WS2 data with the selected top-ranked band subsets by five FS
    methods using the SVM classifier are shown in Table III. It can be observed that
    the RFE FS method outperformed the other methods and achieved almost equal accuracies
    using the selected wavebands (95.38%) to that of using the full bands (95.59%)
    with the SVM classifier. The classification accuracy of the SVM classifier on
    the top 10 features selected by the RFE-SVM is the highest (95.38%) in classifying
    canopy water stress in pearl millet than using the band subsets selected by other
    FS methods. So RFE-SVM is the best performing FS method; we have used this band
    subset in further analysis, i.e., early water stress identification (WS1 canopy
    data), and also in classifying different water stress levels in the pearl millet
    canopy. Table IV shows the canopy water stress classification accuracies (OA)
    on different water stress classes (WW, WS1, WS2) using SVM and RF classifiers
    on the selected top-ranked bands with the RFE-SVM. Overall, the performance of
    SVM is better than that of the RF classifier with the selected bands. It can be
    observed that the canopy early water stress detection accuracy, i.e., classifying
    WS1 canopy from WW canopy, is 80.76%, which is less. This can be due to at the
    early stages of stress imposition, the changes in canopy reflectance of WS1 canopy
    would be less w.r.t that of WW canopy, as the plants try to use existing soil
    moisture content in the cylinders. The classification accuracy using both RF and
    SVM classifiers with the selected bands on WS1-WS2 data is the highest, i.e.,
    96.15% and 95.38% respectively, in classifying two stress levels in pearl millet
    canopy. Using the selected bands, the SVM could classify the canopy of three water
    stress classes (WW, WS1, WS2) with 77.04% accuracy. However, the SVM could classify
    WW-WS2 canopy data with moderate accuracy (89.95%) using the selected bands. This
    work will help identify early water stress in the pearl millet crop using only
    a few water-stress sensitive bands, enabling the agriculturalists to take measures
    well ahead before the stress causes damage to the crop. Also, the different water
    stress levels classification will help classify the field crops with the extent
    of stress so that precise irrigation can be supplied, saving water and time. SECTION
    V. Conclusion In this study, UAV-based hyperspectral sensing in the 400-1000 nm
    range was used to identify water stress in the pearl millet crop. Different ML-based
    feature selection methods were used to identify the top-ranked ten wavelengths
    sensitive to canopy water stress. Wavelengths around 692, 714-716, 763-769, 774-882,
    870, and 949 nm were repeatedly selected by at least two FS methods. The RFE-SVM
    method resulted in the best bands subset, on which the SVM and RF classifiers
    were used for early water stress detection and different stress levels classification
    in the pearl millet canopy. Using the SVM classifier with linear kernel on the
    selected wavebands, we could classify two water stress levels with 95.38% and
    early identify water stress with 80.76% accuracy in the pearl millet crop. This
    study will be helpful in the agriculture sector to find the irrigation requirements
    of crops and accelerate the phenotyping studies. Our future work will use an ensemble
    of different band selection methods to select optimal water-stress sensitive bands
    that can more accurately identify water stress in the crops. Authors Figures References
    Citations Keywords Metrics More Like This Gas identification by wavelet transform-based
    fast feature extraction and support vector machine from temperature modulated
    semiconductor gas sensors The 13th International Conference on Solid-State Sensors,
    Actuators and Microsystems, 2005. Digest of Technical Papers. TRANSDUCERS ''05.
    Published: 2005 Monitoring of Cigarette Smoking Using Wearable Sensors and Support
    Vector Machines IEEE Transactions on Biomedical Engineering Published: 2013 Show
    More IEEE Personal Account CHANGE USERNAME/PASSWORD Purchase Details PAYMENT OPTIONS
    VIEW PURCHASED DOCUMENTS Profile Information COMMUNICATIONS PREFERENCES PROFESSION
    AND EDUCATION TECHNICAL INTERESTS Need Help? US & CANADA: +1 800 678 4333 WORLDWIDE:
    +1 732 981 0060 CONTACT & SUPPORT Follow About IEEE Xplore | Contact Us | Help
    | Accessibility | Terms of Use | Nondiscrimination Policy | IEEE Ethics Reporting
    | Sitemap | IEEE Privacy Policy A not-for-profit organization, IEEE is the world''s
    largest technical professional organization dedicated to advancing technology
    for the benefit of humanity. © Copyright 2024 IEEE - All rights reserved.'
  inline_citation: '>'
  journal: ''
  limitations: '>'
  pdf_link: null
  publication_year: 2022
  relevance_score1: 0
  relevance_score2: 0
  title: Water Stress Detection in Pearl Millet Canopy with Selected Wavebands using
    UAV Based Hyperspectral Imaging and Machine Learning
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1016/j.tplants.2015.10.015
  analysis: '>'
  authors:
  - Arti Singh
  - Baskar Ganapathysubramanian
  - Soumik Sarkar
  citation_count: 659
  full_citation: '>'
  full_text: '>

    Skip to main content Skip to article Journals & Books Search Register Sign in
    Brought to you by: University of Nebraska-Lincoln View PDF Download full issue
    Outline Trends Keywords Plant Stress Phenotyping in Agriculture Phenotyping Data
    and ML ML-Enabled HTSP What is ML? Structure of a ML Process The Learning Process
    – Supervised versus Unsupervised The Modeling Objective – Generative versus Discriminative
    The Role of Preprocessing in ML-HTSP ML Approaches to ICQP Strategies for the
    Development of Efficient ML Applications in Plant Breeding Concluding Remarks
    and Outlook Acknowledgments Supplemental Information Resources References Show
    full outline Cited by (662) Figures (1) Tables (1) Table 1 Extras (1) Document
    Volume 21, Issue 2, February 2016, Pages 110-124 Feature Review Machine Learning
    for High-Throughput Stress Phenotyping in Plants Author links open overlay panel
    Arti Singh 1, Baskar Ganapathysubramanian 2, Asheesh Kumar Singh 1, Soumik Sarkar
    2 Show more Add to Mendeley Share Cite https://doi.org/10.1016/j.tplants.2015.10.015
    Get rights and content Under a Creative Commons license open access Trends High-throughput
    phenotyping (HTP) has unlocked new prospects for non-destructive field-based phenotyping.
    Autonomous, semi-autonomous, or manual platforms equipped with single or multiple
    sensors collect spatial and temporal data, resulting in massive amounts of data
    for analysis and storage. The enormous volume, variety, and velocity of HTP data
    generated by such platforms make it a ‘big data’ problem. Big data generated by
    these near real-time platforms must be efficiently archived and retrieved for
    analysis. The analysis and interpretation of these large datasets is quite challenging.
    Sophisticated data collection, storage, and processing are becoming ubiquitous,
    and newer areas of application are emerging constantly. One such relatively new
    domain is plant stress analytics. ML algorithms are a very promising approach
    for faster, more efficient, and better data analytics. ML being inherently multidisciplinary
    draws inspiration and utilizes concepts from probability theory, statistics, decision
    theory, optimization, and visualization. Most current applications of ML tools
    in plant sciences have focused on using a limited set of ML tools (SVM, ANN).
    A good understanding of which, when, and how various ML tools can be applied will
    be very informative to the plant community to leverage these ML tools. Advances
    in automated and high-throughput imaging technologies have resulted in a deluge
    of high-resolution images and sensor data of plants. However, extracting patterns
    and features from this large corpus of data requires the use of machine learning
    (ML) tools to enable data assimilation and feature identification for stress phenotyping.
    Four stages of the decision cycle in plant stress phenotyping and plant breeding
    activities where different ML approaches can be deployed are (i) identification,
    (ii) classification, (iii) quantification, and (iv) prediction (ICQP). We provide
    here a comprehensive overview and user-friendly taxonomy of ML tools to enable
    the plant community to correctly and easily apply the appropriate ML tools and
    best-practice guidelines for various biotic and abiotic stress traits. Previous
    article in issue Next article in issue Keywords high-throughput phenotypingmachine
    learningImagingplant breedingbiotic stressabiotic stress Plant Stress Phenotyping
    in Agriculture To meet the future demand of food, feed, fiber, and fuel, crop
    production must be doubled by 2050i Crop yields are limited inherently by plant
    stresses (biotic and abiotic), and plant breeders have protected yield from plant
    stress losses by incorporating resistance genes and developing more climatically-resilient
    cultivars. Plant breeders and researchers rely on plant phenotyping for accurate
    and precise trait collection and use of genetic tools to achieve their research
    goals. Plant phenotyping is defined as the application of methodologies and protocols
    to measure a specific trait, ranging from the cellular level to the whole plant
    or canopy level, related to plant structure and function [1]. Agriculture research
    programs phenotype large populations for several traits throughout the crop growth
    cycle. This challenge to phenotype multiple traits and large populations is exacerbated
    by the necessity of sampling multiple environments and growing replicated trials.
    Until recently, traditional methods of phenotyping have not kept pace with the
    available high-throughput genotyping tools. The bottleneck in phenotyping has
    driven intense efforts by the scientific community of agriculture researchers
    and engineers to adapt newer technologies in field phenotyping. A classic example
    is high-throughput phenotyping (HTP), which has unlocked new prospects for non-destructive
    field-based phenotyping in plants for a large number of traits including physiological,
    biotic (includes living factors such as fungi, bacteria, virus, insects, parasites,
    and weeds, etc.) and abiotic (includes non-living factors such as drought, flood,
    nutrient deficiency, and other environmental factors) stress traits 2, 3. Both
    ground and aerial HTP platforms, equipped with multiple sensors are being used
    in agriculture to measure multiple plant traits at varying growth stages rapidly,
    precisely, and accurately (Figure 1A, Key Figure). Examples of these HTP platforms
    include deployment in cotton (Gossypium hirsutum L.) [4], triticale (× Triticosecale
    Wittmack L.) [5], and maize (Zea mays L.) [6]. Recent advances in sensors for
    imaging plants 7, 8, ranging from remote sensing including spectroradiometry [9],
    Light Detection and Ranging (LIDAR) [10], visible to far-infrared [11], hyperspectral
    12, 13, 14, 15, thermal 16, 17, fluorescence 16, 18, and 3D laser scanning [19]
    to trichromatic (RGB) [20] imaging in conjunction with advanced autonomous vehicles,
    have truly opened up the possibility of high-throughput stress phenotyping (HTSP).
    Autonomous platforms such as unmanned aerial vehicles (UAVs) [21] and ground robots
    [22] equipped with multiple sensors can take pictures in near real-time of the
    entire experimental plot several times per day, or over the entire season from
    germination to maturity, resulting in massive amounts of data for analysis and
    storage. Making sense of all these collected data can be done effectively using
    ML tools (see the supplemental information online). It is important to emphasize
    that for ML tools data can be collected from complex, integrated imaging platforms
    or from simple(r) methods such as crowd-sourced cell phone images. Download :
    Download high-res image (976KB) Download : Download full-size image Figure 1.
    Key Figure: Machine Learning (ML) Tools for High-Throughput Stress Phenotyping
    (A) High-throughput stress phenotyping in soybean field at various growth stages
    and at different heights using aircraft, UAV, and UGV. (B) Identification, classification,
    quantification, and prediction (ICQP) of plant diseases in soybean. (C) ML algorithms
    used in ICQP of plant stresses. (D) Classification of ML algorithms into generative
    and discriminative. Abbreviations: ANN, artificial neural network; BC, Bayes classifier;
    BN, Bayesian network; BM, Boltzmann machine; CRF, conditional random field; CNN,
    convolutional neural network; DT, decision tree; DNN, deep neural network; GMM,
    Gaussian mixture models; GP, Gaussian process; HMM, hidden Markov model; HC, hierarchical
    clustering, ICA, independent component analysis; K-MC, K-means clustering; K-NN,
    k-nearest neighbor classifier; Lat DA, latent Dirichlet allocation, LDA, linear
    discriminant analysis; Lin R, linear regression; LR, logistic regression; MF,
    matrix factorization; NB, naïve Bayes; NLR, nonlinear regression; PCA, principal
    component analysis; RF, random forests; SOM, self-organizing map; SVM, support
    vector machine; UAV, unmanned aerial vehicle; UGV, unmanned ground vehicle. The
    objectives of this review are (i) to give an overview of work done in the field
    of plant stress phenotyping using ML in identification, classification, quantification,
    and prediction (ICQP); (ii) to give an overview of general issues in ML to develop
    a strategy for wider application and adaptability in agriculture; (iii) to contribute
    to a technical framework for the application of ML in plant breeding to solve
    practical problems, especially plant stress phenotyping using digital imaging;
    and (iv) to discuss the advantages and disadvantages of various ML algorithms
    in stress phenotyping with the aim of enabling further exploration of these tools
    for facilitating practical use in plant breeding. Phenotyping Data and ML The
    enormous volume, variety, velocity, and veracity of imaging and remote-sensing
    data generated by such real-time platforms represent a ‘big data’ problem. The
    data generated by these near real-time platforms must be efficiently archived
    and retrieved for analysis. Although the analysis and interpretation of such (image-based)
    big data are challenging, the ensuing possibilities that can impact on agricultural
    production make it a promising approach for HTP and HTSP. ML approaches present
    a scalable, modular strategy for data analysis, especially for the new application
    domain of ‘plant stress analytics’. Recent studies on HTSP using images obtained
    from UAV-based platforms to detect weeds in wheat (Triticum aestivum L.) [23],
    maize [21], and sunflower (Helianthus annuus L.) [24] using ML algorithms have
    paved a new path for better stress management practices on spatial and temporal
    basis. ML is an inherently multidisciplinary approach to data analysis that draws
    inspiration, and borrows heavily, from probability theory, statistics, decision
    theory, visualization, and optimization. ML approaches are typically useful in
    situations where large amounts of data are available, relating inputs (e.g., image
    data) to output quantities of interest (e.g., stress phenotypes). One of the major
    advantages of using ML approaches for plant breeders, pathologists, physiologists,
    and biologists is the opportunity to search large datasets to discover patterns
    and govern discovery by simultaneously looking at a combination of factors instead
    of analyzing each feature (trait) individually. This was previously a major bottleneck
    because the high dimensionality of individual images (coupled with the huge number
    of such images) makes them extremely difficult to analyze through classical techniques.
    Another key challenge is that the underlying processes for linking the inputs
    to the outputs are too complex to model mathematically. This is particularly the
    case for plant stress phenotyping, where it is challenging to efficiently model
    the holistic effect of genetic, agronomic, economic, meteorological, and human
    factor inputs on stress and, ultimately, yield. ML methods have been applied with
    spectacular results to similar problems [25] previously presumed to be impossible
    to model. Examples include numerous success stories in various domains ranging
    from computer vision (e.g., face recognition), speech processing (e.g., Google
    voice, Apple''s Siri) and natural language processing (e.g., IBM Watson), consumer
    predictive analytics (e.g., Netflix movie recommender system) to bioinformatics
    (e.g., personalized genomics, drug design, and genome annotation) [26], cell biology
    [27], and disease tissue classification in medicine 28, 29. The success of ML
    tools is attributed to their ability to identify a hierarchy of features and generalized
    trends from available data. These tools have also proved particularly adept at
    integrating disparate and often redundant data to draw coherent (and often non-intuitive)
    patterns for identification and quantification. Finally, current progress in ML
    has resulted in scalable, robust, and flexible software tools (R packages, Matlab
    toolboxes, and software packages such as Theano, Caffe for archetypal ML algorithms)
    30, 31, 32, 33 that make the application of ML to disparate disciplines straightforward.
    The advances have percolated into agricultural research, where there has been
    an increasing research effort to apply ML approaches in diverse species, such
    as horticultural crops and forest tree species. This has been driven in part by
    the increased investment by commercial companies and the decreasing cost of imaging/sensor
    platforms. ML-Enabled HTSP In light of these developments, it is clear that ML-enabled
    HTSP will benefit plant breeders, physiologists, entomologists, pathologists,
    extension workers, and farmers by allowing screening of different stresses in
    an accurate, precise, and speedy manner (Table 1). This will also directly enable
    the acceleration of the gene discovery process as well as the introduction of
    novel selection protocols for complex quantitative traits such as biotic and abiotic
    stresses and yield. ML-enabled HTSP will also enhance our understanding of pathogen–plant
    interactions [34] as well as the interaction of plants with other stresses. Table
    1. Examples of ML Approaches in Plant Species for Stress Phenotyping ML Algorithm
    Application in HTSP ML Algorithm Type Sensor Plant Species Trait(s) Phenotyped
    Stress Type Refs Identification SVM with a linear kernel Thermal and stereo visible
    light Tomato (Solanum lycopersicum L.) Powdery mildew Disease [31] Identification
    SAM Remote sensing Sugar beet (Beta vulgaris L.) Heterodera schachtii and Rhizoctonia
    solani Pest and disease [44] Identification None Preprocessing via segmentation
    Kinect RGB depth images Apple (Malus domestica Borkh.) Apple scab Disease [70]
    Identification SVM and Gaussian processes classifier (GPC) Visible and thermal
    images Spinach (Spinacia oleracea L.) Drought/water stress Abiotic stress [71]
    Identification Bayes factor and DAR Hyperspectral images Barley (Hordeum vulgare
    L.) Rust, net blotch, and powdery mildew Disease [11] Identification SVM Fluorescence
    imaging spectroscopy Citrus [Citrus sinensis (L.) Osbeck] Huanglongbing (HLB)
    Disease [36] Identification OBIA-based classification UAV-based RGB images and
    multispectral image Sunflower (Helianthus annuus L.) Weed Biotic stress [21] Identification
    None Preprocessing via segmentation RGB images Cotton (Gossypium hirsutum L.)
    Southern green stink bug, bacterial angular and Ascohyta blight Disease and insect
    [39] Identification SVM, linear kernel, quadratic kernel (QP), radial basis function
    (RBF), multilayer perceptron (MLP), and polynomial kernel RGB images Tomato Tomato
    yellow leaf curl virus and tomato yellow leaf curl disease Disease [40] Identification
    ANN variant RGB images Orchid (Phalaenopsis) Bacterial soft rot, Phythopthora
    black rot, bacterial brown spot Disease [42] Identification SVM UAV- and aircraft-based
    sensors Citrus Huanglongbing (HLB) Disease [37] Identification KNN, quadratic
    discriminant analysis (QDA), and linear discriminant analysis (LDA) Spectroradiometer
    Citrus Huanglongbing (HLB) Disease [43] Identification SViM Hyperspectral Tomato
    Water stress Drought [72] Identification Gaussian mixture model RGB images Wheat
    (Triticum aestivum L.) Wheat streak mosaic virus Disease [45] Identification SVM
    variant Scanned images Rice (Oryza sativa L.) Nitrogen, phosphorus, and potassium
    (NPK) stress Nutrient deficiency [73] Identification and classification HBBE,
    MLPNNs, LDA CCD images Chili pepper (Capsicum annuum L.) Aflatoxins Toxic metabolites
    [52] Identification and classification SVM Hyperspectral reflectance Sugar beet
    Cercospora leaf spot, sugar beet rust, and powdery mildew Disease [38] Identification
    and classification Linear discriminant analysis (LDA) and K-means RGB images Clover
    (Trifolium subterraneum L.) Ozone Pollution [53] Identification and classification
    Self-organizing map (SOM) RGB images Tomato Powdery mildew Disease [20] Identification
    and classification Bayesian classifier RGB images Tomato Powdery mildew Disease
    [20] Identification and classification Naïve Bayes (NB), simple logistic (SL),
    LibSVM (SVM), LibLINEAR (LINE), MLP (BNN), functional trees (FT), random forests
    (RF), classifier for generating a grafted C4.5 decision tree (J48) Hyperspectral
    images Oilseed rape (Brassica napus L.) Alternaria alternata, Alternaria brassicae,
    Alternaria brassicicola, and Alternaria dauci Disease [48] Classification SVM
    RGB images Arabidopsis (Arabidopsis thaliana L.) Salmonella bacteria Disease [49]
    Classification Random forest and SVM spatial matching kernel − − Stonefly larvae
    Insect [51] Classification k-NN and Bayesian classifier Fusion of RGB and multispectral
    image Sugar beet Uromyces betae, Cercospora beticola Disease [47] Classification
    Bayesian classifier RGB images Arabidopsis Salmonella bacteria Disease [50] Quantification
    SVM RGB images and spectral reflectance Tomato Leaf miner Insect [57] Quantification
    None Preprocessing via segmentation RGB images Chili pepper Yellow vein virus
    Disease [56] Quantification SVM and LDA Hyperspectral sensor and thermal images
    Olive Verticillium dahliae Disease [58] Prediction Dirichlet aggregation regression
    (DAR) Hyperspectral images Barley Drought Abiotic stress [46] Prediction SVM,
    generalized regression neural network (GRNN) Manual severity rating Rice Rice
    blast Disease [59] Prediction SVM Hyperspectral images Barley Drought Abiotic
    stress [60] What is ML? ML refers to a group of computerized modeling approaches
    that can learn patterns from the data so as to make automatic decisions without
    programming explicit rules. The main idea of ML is to effectively utilize experiences
    or example scenarios to discover underlying structures, similarities, or dissimilarities
    present in data to explain or classify a new experience or an example scenario
    properly. A key ability of ML tools is their ability to generalize trends and/or
    patterns from available data. There are a large number of choices of ML tools.
    It is important for an application expert to make a judicious choice on a specific
    ML method to deploy for his/her specific problem. We advocate that the practitioner
    should (carefully) down-select from the plethora of ML choices based on the type
    and amount of available data and problem formulation. In the context of plant
    stress phenotyping, we identify four distinct classes of problem formulation:
    (i) identification/detection, (ii) classification, (iii) quantification/estimation,
    and (v) prediction (Figure 1B,C). Furthermore, preprocessing steps such as dimension
    reduction, clustering, and segmentation can also be crucial for successful decision-making.
    Structure of a ML Process Typically, a large fraction of the dataset, known as
    the ‘training dataset’, that represents the entire population is used for calibrating
    the model. The remaining dataset is used to test the calibrated model, and is
    termed the ‘testing dataset’. The next step after training is to validate the
    learnt model on a new set of data (from different or same population). Once the
    accuracy and precision of the model is high enough, it can be used on a routine
    basis to identify, classify, quantify and predict particular stress features.
    We discuss this process in greater detail next, particularly focusing on clarifying
    the choice of ML tools to use based on two different points of view, namely the
    learning process (how are features learnt) and the modeling objective (what is
    being learnt). The Learning Process – Supervised versus Unsupervised The first
    point of view concerns whether or not the ML model is provided with the labels
    to the data it uses for model training. Here, a label is a trait (such as diseased
    plant or type of crop plant) that is associated with an image. For example, suppose
    the objective of a ML model is to distinguish between maize, soybean [Glycine
    max (L.) Merr.], and sunflower plants after collecting a large number of images.
    If the model is trained with a set of such images where each is labeled as soybean,
    maize or sunflower, the learning process is termed ‘supervised’. Alternatively,
    if the training images are provided without any label, the learning process is
    ‘unsupervised’. Note that although some ML tools can be trained either in a supervised
    or an unsupervised manner, some can be trained in both ways. With the supervised
    learning process, a model essentially tries to learn a map between the input dataset
    and the corresponding output labels. For the given example, it means that a model
    trained in a supervised manner learns how to map all the soybean examples to the
    soybean label, and so on. Support vector machines (SVM) and regular artificial
    neural networks (ANN) are among the prominent examples of supervised schemes.
    By contrast, an unsupervised method does not have specific output labels associated
    with input images. It identifies structures or features present in the images,
    such as the presence of tassels in maize, or the presence of trifoliate leaves
    in soybean. In many cases, the features identified in the unsupervised process
    may not be meaningful to a human user. Various clustering, mixture models, and
    dimension-reduction techniques fall under this category. Often ML models can be
    developed by using partly labeled data. This training scheme is known as ‘semi-supervised’
    learning. The Modeling Objective – Generative versus Discriminative A second point
    of view for ML method categorization is the modeling objective: whether the model
    being trained is to distinguish between two different data patterns or to be able
    to learn and generate similar patterns synthetically. In the context of the previous
    example, a maize and soybean plant can be distinguished based on the presence
    or absence of tassels or pods. A model developed with only this difference would
    be termed a ‘discriminative model’. Naturally, many supervised methods such as
    SVM and ANN fall under this category. However, such a model does not learn other
    features of the objects. Thus, a discriminative model that distinguishes a soybean
    plant from a maize plant based on the presence of tassels fails to differentiate
    between an image of a maize plant and that of sorghum [Sorghum bicolor (L.) Moench]
    plant. Therefore, a discriminative model is typically built for a predetermined
    specific task. On the other hand, a model that captures the overall data pattern
    such that it is able to generate synthetic images is known as a ‘generative model’.
    It follows that a single generative model can be useful for many decision tasks
    at the same time. Mixture models, hidden Markov models, and Boltzmann machines
    are prominent examples of generative models. Given a large volume of data, discriminative
    models usually perform better than generative models, especially for classification
    tasks, such as distinguishing images of soybean plants from a maize plant. However,
    generative models can achieve slightly better performance compared to discriminative
    ones with low training data volume. In addition, generative models tend to be
    more robust to overfitting issues (i.e., a model learns training data too well
    and performs very poorly for unseen test data). Figure 1D schematically illustrates
    the categorization of several ML methods into classes of generative versus discriminative,
    and supervised versus unsupervised. Although it seems that supervised models are
    more likely to be discriminative in nature, and generative models should not need
    output labels for training, there are examples of unsupervised discriminative
    models and supervised generative models. For example, the widely popular K-means
    clustering technique usually follows an unsupervised training scheme. Even so,
    it is not possible to generate new data examples reliably using only the cluster
    centers and groupings. Most of the unsupervised generative techniques can be learned
    in a supervised manner when the target class information is incorporated as one
    of the data features. Apart from such variations (as shown in Figure 1D), many
    of the ML tools have minor variations based on particular aspects such as underlying
    model structure (e.g., linear vs nonlinear) and training algorithm. The Role of
    Preprocessing in ML-HTSP The crucial step for the successful deployment of ML
    methods is careful preprocessing of the image data. There are multiple examples
    where a careful choice of preprocessing of the collected image datasets has resulted
    in substantial improvements in ML performance. Preprocessing can vary from very
    simple operations including image cropping, contrast enhancement, and removal
    of background to significantly more complex operations such as clustering and
    dimensionality reduction using principal component analysis (PCA). However, the
    overarching principle of preprocessing the data is ‘concentration of information’.
    That is, the original datasets may contain a large quantity of unnecessary or
    conflicting information that can result in poor ML performance. By preprocessing,
    the signal-to-noise ratio (ratio of useful to useless information) is improved.
    This directly enhances the ability of the ML model to easily recognize useful
    patterns or trends and to separate the data into appropriate classes. Preprocessing
    is the stage where domain knowledge is crucial. The domain expert identifies features
    in the image that are relevant or important for training the model. For example,
    the removal of background (soil, dirt, and tags, etc.) from the foreground to
    identify the plant canopy is generally a crucial step. Following this, a variety
    of image processing tools can be used to convert these raw datasets into a more
    relevant dataset that contains the extracted features. Examples of preprocessing
    operations include: (i) segmentation of images; (ii) contrast enhancement to detect
    edges; (iii) thresholding images into binary data; (iv) converting one image format
    into other [RGB to greyscale; RGB to hue saturation value (HSV)]; (v) de-noising
    images using filters [band-pass, low-pass, fast Fourier transform (FFT)]; (vi)
    extracting features at different scales using image transforms (FFT, wavelet transforms,
    Haar transforms, Hough transforms, Radon transforms); (vii) pixel-based classification;
    (viii) clustering of images into classes; and (ix) dimensionality reduction of
    images. Several of the ML tools discussed here can in fact be applied to these
    preprocessing stages. There are several examples of the utility of such preprocessing
    steps. For early site-specific weed management (ESSWM) in wheat, a UAV-based platform
    was equipped with a visible-range camera to capture ultra-high resolution images.
    Otsu''s thresholding method was then used to differentiate wheat crop plants from
    weeds [23]. In sunflower, a quadrocopter equipped with RGB and multispectral sensors
    was used to detect weeds to optimize herbicide application. A pixel-based classification
    approach was used for weed identification. Similarly, image segmentation 21, 24,
    35 followed by automatic object-based image analysis (OBIA) was used in sunflower
    and maize to identify spatial and spectrally consistent objects. ML Approaches
    to ICQP Identification of Stress Identification methods involve detection of a
    specific stress amid other potential stresses in the field. Here, preprocessing
    of image data is crucial. This is especially important for applications involving
    high-throughput imaging, where plant stressors (such as weeds, nutrient, disease,
    and insects) must be automatically identified. In the past, ML methods such as
    SVM, neural networks (NNs), kernel methods, and instance-based approaches have
    been used to detect various stresses. The SVM method has been used successfully
    in a variety of scenarios for stress identification in plants. SVM Methods SVM
    methods have been applied to a variety of plants for disease and stress identification.
    They are deployed in the citrus industry to contain citrus greening (caused by
    phloem-limiting bacteria), also known as Huanglongbing (HLB). Early identification
    is crucial for effectively controlling the spread of HLB. ML was used for the
    identification and estimation of HLB based on fluorescence imaging spectroscopy
    data of leaf samples [36]. The images were preprocessed (segmented) and the extracted
    features were used as an input to SVM. In another example, two aerial imaging
    platforms were compared for the identification of HLB diseases in an infected
    citrus orchard. An aircraft sensing platform equipped to capture hyperspectral
    images and a UAV platform equipped with a multiband imaging camera were used,
    and images obtained from both platforms were segmented and piped to a SVM classifier.
    Results showed that a (non-linear) SVM with kernel worked better than (linear)
    SVM, LDA, and QDA [37]. Similarly, in sugar beet (Beta vulgaris L.), early identification
    of three diseases, Cercospora leaf spot, leaf rust, and powdery mildew, was performed
    using SVM with a radial basis function as kernel [38]. The same idea was deployed
    in cotton to identify damage by green stink bug, bacterial angular blight, and
    Ascochyta blight using a SVM classifier [39], as well as in tomato (Solanum lycopersicum
    L.) to identify viruses: tomato yellow leaf curl virus and tomato yellow leaf
    curl disease [40]. SVM (combined with a Gaussian process classifier) was used
    for the automatic identification of soil moisture stress using remote visible
    and thermal images in spinach canopies, where the efficacy of using a combination
    of methods was explored. In another study, visible and thermal imaging were combined
    with depth information to automatically identify powdery mildew of tomato plants
    at an early growth stage using a SVM classifier kernel [31]. Variants of the SVM
    method have also proven to be useful for identification. In rice (Oryza sativa
    L.], the hierarchical identification of nutrient deficiency symptoms using scanned
    images was carried out using support vector feature selection (SVFS). Hierarchical
    identification was able to detect the NPK (nitrogen, phosphorus, and potassium)
    stress effectively with enhanced identification accuracy [41]. Artificial Neural
    Nets (ANN) and Variants Simple image processing, followed by ANN, was used for
    detecting and identifying three orchid seedling diseases: bacterial soft rot,
    bacterial brown spot, and Phytopthora black rot [42]. Discriminant Analysis Spectral
    reflectance data were recorded from healthy and HLB-infected citrus leaves, and
    various classifier methods (discriminative and supervised methods) were used to
    identify infected leaves using quadratic discriminant analysis (QDA), linear discriminant
    analysis (LDA), and k-nearest neighbor (k-NN) and soft independent modeling of
    class analogy (SIMCA) [43]. In sugar beets, hyperspectral canopy reflectance was
    used to identify stress symptoms instigated by beet cyst nematode and Rhizoctonia
    crown and root rot [44]. Gaussian Mixture Models Preprocessing followed by the
    application of Gaussian mixture models has been used to identify both biotic and
    abiotic stresses [45]. Canopy images were taken in a stressed wheat field, at
    differential levels of irrigation (abiotic stress) and inoculated with wheat streak
    mosaic virus (biotic stress). K-means Clustering and Variants Water and nutrient
    stress at the crop canopy level have been studied using hyperspectral images that
    were analyzed using simplex volume maximization (SiVM), an unsupervised clustering
    approach. The SiVM algorithm was found to be adept at detecting drought stress
    using hyperspectral images four days before the appearance of symptoms visible
    to the human eye. The unsupervised nature of SiVM also provided useful new insights
    into the data 11, 25. Dimensionality Reduction and Clustering The automatic extraction
    of hyperspectral signatures using the Bayes factor algorithm with Dirichlet-aggregation
    regression (DAR) resulted in rapid, reliable, and data-driven approach for phenotyping
    plants for both biotic and abiotic stresses [11]. In barley (Hordeum vulgare L.),
    the DAR algorithm was used for the presymptomatic prediction of drought stress
    at an early stage using hyperspectral images [46]. Self-Organizing Map (SOM) and
    Bayes Classifier Both supervised (Bayesian classifier) and unsupervised (SOM)
    ML approaches were used for segmenting diseased tomato plants. Diseased regions
    on the tomato canopy were identified using the preprocessed tomato images by a
    SOM model [20]. Classification of Stress Classification is an extension of identification;
    however, instead of identifying a particular stress amid different stresses, a
    classifier is used to classify stress into labeled classes on the basis of stress
    symptoms and signatures. Classification methods often include a preprocessing
    step, usually a segmentation step followed by the extraction of features that
    feed into some type of classifier. For instance, drought stress can be classified
    into: no stress, moderate stress, and heavy stress. Examples from various crops
    are presented below illustrating the use of classification algorithms in various
    stresses. ANN A combination of K-means clustering followed by ANN, using fused
    information from RGB and multispectral camera imaging, was used to develop a 3D
    model of leaves to differentiate the two sugar beet diseases, Cercospora beticola
    and Uromyces betae [47]. In another example, thermal and hyperspectral imaging
    were analyzed to identify and classify symptoms caused by three Alternaria species
    in the oilseed brassica. The majority of the available classifiers present in
    Weka (useful data-mining software in java) were tested, and eight classifiers
    were used to make comparisons. The back-propagation neural networks (BNNs) classification
    model displayed the highest prediction accuracy for classifying Alternaria species
    [48]. SVM A SVM-based method was used to classify healthy and unhealthy Arabidopsis
    plants on the basis of symptoms instigated by colonization of the human pathogen
    Salmonella Typhimurium [49]. The SVM model was comprehensively tested on 1200
    individual Arabidopsis plants with positive results [50]. In further work, classification
    error was reduced using SVMs compared to other ML methods such as decision trees
    and ANNs. The classification accuracy of three sugar beet diseases increased with
    increasing disease severity. This is especially true when hyperspectral reflectance-based
    vegetation indices were used with SVM for the automatic classification of disease
    severity of three sugar beet diseases (Cercospora leaf spot, leaf rust, and powdery
    mildew). Another example of the usefulness of SVM was the identification and classification
    of stonefly larvae from images. Haar random forest feature extraction, in combination
    with SVM classifier, was able to differentiate and classify stonefly larvae from
    other insect species [51]. LDA, K-Means, and Coupled Methods ML methods were used
    to classify the presence of aflatoxins, which are toxic compounds produced by
    fungus Aspergillus flavus and Aspergillus parasiticus [52]. Fluorescence (UV illumination)
    and reflectance (halogen excitations) were used as input data in this case. Preprocessing
    was performed to extract features using Guyon''s SVM-RFE, classical Fisher discriminant
    power, and PCA. These extracted features were used as inputs to classifiers such
    as LDA (linear discriminant analysis) and MLP. Another paper classified the RGB
    images into ‘healthy’ and ‘injured’ classes of clover plants that were exposed
    to varying level of ozone. Various pixel-classifying methods were compared such
    as LDA, K-means clustering, FPM-T2 (fit to a pattern multivariate image analysis
    combined with T2 statistics), and FPM-RSS (FPM combined with residual sum of squares
    statistics) [53]. Quantification of Stress There are fewer reports describing
    the use of ML approaches to quantify stresses, and this provides tremendous opportunities
    for plant scientists and breeders. Quantification methods are an extension of
    classification methods where each class is quantified on the basis of stress severity.
    In case of plant diseases, disease severity [54] can be used to quantify various
    diseases. For example, rust severity in wheat can be quantified on a scale of
    0–100% [55]. Quantification algorithms are usually best preceded by a preprocessing
    stage to separate foreground from background, edge detection, and contrast enhancement.
    A good example of the benefit of preprocessing of images for quantification is
    illustrated in [56] where color mapping (converting from native RGB to other non-native
    formats such as HSV) followed by segmentation was used to quantify disease severity
    of PHYVV (pepper huasteco yellow vein virus) on chili pepper (Capsicum annuum
    L.) plants. Examples from various other crops are presented next. SVM Leaf miner
    pest causes major losses in vegetable and ornamental plants. SVM applied to near-infrared
    spectral reflectance using spectrophotometer and digital leaf images of tomato
    plants of damaged leaves was used to successfully quantify damage degree (DD)
    into five levels [57]. Automatic detection method was used to detect and quantify
    Verticillium wilt (VM) on a large scale in olive using hyperspectral sensor and
    thermal camera mounted on aircraft. The spatial distribution of VM was assessed
    at field level and severity classes (0–4 rating scale quantified into 0–100% severity
    level) predicted by LDA and non-linear SVM methods. Both ML methods showed good
    results in detecting and quantifying VM severity in olives (Olea europaea L.)
    [58]. Prediction of Stress The prediction of plant stress at an early stage before
    it is visible to the human eye has substantial implications for the timely and
    cost-effective control of stress. There are very few reported activities on using
    ML for the prediction of stresses, making this the next big frontier for research
    efforts. This has tremendous implications for prescription farming and precision
    agriculture. SVM In predicting rice blast disease, SVM was used for the development
    of a weather-based prediction model [59]. The performance of the SVM-based approach
    was compared to the ANN variants; back-propagation neural network (BPNN) and generalized
    regression neural network (GRNN), and also to conventional multiple regression.
    The SVM-based approach outpaced all the three methods in cross-location and cross-year
    models, indicating their role in early forecasting of plant diseases. Other examples
    include the prediction of drought-induced stress in barley using hyperspectral
    images using an SVM variant, ordinal classification approach [60]. In barley for
    the presymptomatic detection of water stress, DAR algorithm was used on images
    obtained using hyperspectral camera. The DAR algorithm was efficient in predicting
    stress before symptoms were visible to human eye [46]. Strategies for the Development
    of Efficient ML Applications in Plant Breeding ML methods can play an extensive
    role in breeding for stress tolerance and for rapid phenotyping. These approaches
    can be used in decision-making for parent selection to use in hybridization schemes,
    and in generation advancement and selection. An example of an application using
    ICQP is presented below. Identification Use HTP platform [UAV, unmanned ground
    vehicle (UGV)] for taking images of breeding plots in plant stress nurseries,
    and yield tests. Perform image processing and apply ML algorithms. ML identifies
    which stress is present in each breeding plot. Classification Use ML approaches
    to classify stress in each breeding plot. For instance, determine if a genotype
    is resistant or susceptible to a particular stress. This information can be directly
    used in a breeding decision scheme to select stress resistance genotypes. Quantification
    Use ML approaches to quantify the stress. For example, quantification may be on
    a 0–100% scale of expression, such as percent infection severity. Use the information
    generated by ML approach through quantification to make selections to identify
    stress-resistant genotypes for further testing or commercialization. Prediction
    Use ML approaches on prior disease and weather data to make early stage prediction
    on the expression of stresses for breeding and selection decisions. In addition
    to plant stresses, advances have been made in analyzing other traits using ML
    to predict yield 61, 62, 63, biomass 64, 65, root traits 66, 67, and adaptation
    traits [68]. Concluding Remarks and Outlook ML tools provide a very powerful framework
    to assimilate data, and the utility of these tools is especially important considering
    current progress in HTP approaches that easily generate terabytes of data. Appropriate
    choice and usage of ML tools is crucial for obtaining the maximum possible benefits
    of these sophisticated approaches. This review provides a comprehensive overview
    of ML alongside best practices of using these ML tools to enable stress phenotyping
    (Box 1, Box 2). Using advanced ML tools for plant stress phenotyping is a very
    new area, with the plant community focusing on a small number of ML methods (such
    as SVM and ANN). As part of this review, we have identified several future avenues
    for using ML techniques that show tremendous promise but remain currently unutilized
    by the phenotyping community (see Outstanding Questions). Furthermore, the concepts
    discussed here can be applied to data collected across the spectrum of complexity
    and sophistication (from manually captured camera imaging to automated high-throughput
    imaging systems), as well as scale (from individual plant to plot to field). Box
    1 Key Take-Away Points for Practitioners Identification (i) A large variety of
    ML methods have been successfully applied to the disease identification problem.
    This is an area where preprocessing of images will be very useful. (ii) There
    are two ways to frame a disease identification problem for ML based on the amount
    of data available. (a) When statistically significant nominal (healthy) and diseased
    datasets are available, it is best to use supervised discriminative models that
    are trained to distinguish between these classes. (b) In the absence of a statistically
    significant amount of data (or unbalanced data, see next point below), the best
    approach is to learn the nominal model of the un-diseased plant (which is feasible
    due to the availability of data of the healthy plant) using unsupervised methods.
    Then simple outlier detection can be deployed to identify off-nominal (or diseased)
    cases. (iii) We strongly encourage practitioners to refrain from training disease
    identification models using very small datasets. It is especially important to
    be vigilant against unbalanced data for training where one state (usually, the
    healthy state) has much more data instances than the other diseased states.  Classification
    (i) We encourage the practitioner to ensure the statistical significance of the
    available dataset. (ii) Preprocessing of data is crucial, as is using domain knowledge.
    (iii) Current trends are to always use supervised methods, which are mostly discriminative.
    (iv) Be vigilant against the overfitting problem. A best practice is to always
    ensure that regularization option is turned on in any ML method. (v) It is important
    to note that these methods can only distinguish between known/trained classes.
    They cannot be deployed to identify unknown/untrained symptoms (so-called extrapolatory
    mode). (vi) We encourage practitioners to extract and report detection confidence
    out of the classifier.  Quantification (i) There are very few reported applications
    of ML for stress quantification, and this provides tremendous opportunities for
    plant scientists and breeders. Most current work formulates the quantification
    problem as a classification problem with finer resolution. (ii) Our recommendation
    is that unsupervised generative models can be very successful for quantification.
    This can also work with smaller datasets. The basic idea is to learn the nominal
    (healthy state) model. The severity of the diseased state is quantified as the
    distance/offset from this nominal state. (iii) We strongly recommend practitioners
    to explore the use of Bayesian networks, deep neural nets, and latent Dirichlet
    allocation for this class of problems.  Prediction (i) Most prediction applications
    of ML are limited to early detection of disease onset. (ii) Current phenotyping
    approaches can be extended to obtain time-varying traits. Here, more sophisticated
    models can be used with great utility. Examples include HMM methods, dynamic Bayesian
    networks, and recurrent neural networks. Box 2 Precision Phenotyping Using ML
    Algorithms in Agriculture: Best Practices Advances in technology have made HTSP
    feasible. Appropriate ML tools can be used for all four stages (stress identification,
    classification, quantification, and prediction). High-throughput image-based phenotyping
    of plant stress-related traits to complement high-throughput sequencing will assist
    in finding new genes and quantitative trait loci (QTLs) using linkage mapping
    and genome-wide association studies (GWAS) together with training genome-wide
    selection models for various plant stress traits [74]. Specifically, the high-throughput
    phenotypic information on a particular stress can be used in association with
    genotypic information by means of QTL 75, 76, GWAS 77, 78, or expression studies
    to bridge the genotype–phenotype gap. Relating time-series phenotypic data with
    time-series gene expression may provide novel insights into cellular mechanisms.
    Time-series image data 79, 80 obtained in experiments using HTP platforms such
    as UAVs and autonomous rovers (ground robots), integrated into a viable ML pipeline,
    will allow the study of the time-dependent gene turn-on and turn-off mechanisms
    and provide insight into the molecular basis of disease resistance. HTP can also
    be used for phenotyping different fields for the same stress to understand the
    spatiotemporal difference in the expression of stress. The big advantage of ML
    algorithms is that plant scientists can use them proficiently in stress identification,
    classification, quantification, and prediction using tools packaged in the graphical
    user interface (GUI) without knowing the underlying mathematical and computational
    complexities. We advocate the following best practices for maximizing the effectiveness
    of ML tools: ML for Practitioners It is useful to identify which type of ML method
    is best suited by triaging the ML methods based on amount of data available as
    well as the type of data (labeled vs unlabeled). Figure 1C,D will be beneficial
    for this purpose. Discriminative methods work better for labeled and large datasets,
    while generative methods work better for smaller datasets (both labeled and unlabeled).
    It may be worthwhile for practitioners to explore the use of generative unsupervised
    models as a means to identify latent features from datasets. This is an area that
    is relatively unexplored, but holds great promise. Preprocessing is where domain
    knowledge can be leveraged to improve the signal-to-noise ratio in the data. For
    ML methods that are classified as discriminative and supervised, the use of preprocessing
    before deploying ML tools is essential to substantially improve ML performance.
    In cases where it is difficult to translate domain knowledge into feature crafting,
    unsupervised preprocessing methods should be explored. This may be particularly
    useful for high-dimensional data such as hyperspectral data. The outlook for ML
    tools in agriculture is very promising. A key ingredient for successful large-scale
    application of ML is the seamless integration of data analytics within the data
    collection and curation pipeline. Such a computational ecosystem (that links data
    collection, data storage, and curation with ML-based data analytics) will open
    up tremendous opportunities to accelerate breeding and to solve foundational problems
    in genomics and predictive phenomics. Promising examples of this vision include
    the Integrated Analysis Platform (IAP) [69] and the i-Plant nitiativeii A crucial
    catalyst for such advances will be to foster multidisciplinary research teams
    such that advances in engineering, plant sciences, and informatics can be leveraged
    in a rational way. This review will enable such teams by providing a common language
    of communication related to ML tools. Outstanding Questions Can causal ML models,
    deployed on time-series of images, identify visual precursors to enable early
    detection of stress response? ML methods lead to data-driven discovery of non-intuitive
    patterns. How can these hierarchical patterns be visualized and then physiologically
    interpreted by domain scientists? Advanced supervised ML methods tend to require
    labeling a large volume of training data. Can methodologies such as mechanical
    turking, crowd sourcing, and gamification be used to create a large corpus of
    community-labeled data? Future phenotyping efforts will be characterized by heterogeneous
    (visual/non-visual), multiscale (plant/plot/field), asynchronous data collected
    by a variety of sensors connected via the internet of things (IOT). How to develop
    best practices for a robust, scalable, and integrated ML pipeline that enables
    seamless assimilation? The ICQP paradigm comprehensively characterizes the spectrum
    of problems in plant stress phenotyping, thus enabling the design and deployment
    of appropriate ML tools. How can this paradigm be applied to other problems in
    plant biology, such as physiogenetic drivers of yield, and soil microbiome–plant
    root interaction studies? Acknowledgments This work was supported by Iowa State
    University (ISU) and the Iowa Soybean Association. B.G. thanks the ISU Plant Sciences
    Institute for support. We are grateful to Dr P. Jayashankar and Ms J. Hicks for
    reviewing this article and Marcus Naik for helping with the development of figures.
    Supplemental Information Download : Download Word document (37KB) Resources i
    www.globalharvestinitiative.org/index.php/gap-report-gap-index/2013-gap-report/2013-gap-report-digital/
    ii www.iplantcollaborative.org/ References 1 M.E. Ghanem, et al. Physiological
    phenotyping of plants for crop improvement Trends Plant Sci., 20 (2014), pp. 139-144
    Google Scholar 2 D. Deery, et al. Proximal remote sensing buggies and potential
    applications for field-based phenotyping Agronomy, 4 (2014), pp. 349-379 CrossRefView
    in ScopusGoogle Scholar 3 J.W. White, et al. Field-based phenomics for plant genetics
    research Field Crops Res., 133 (2012), pp. 101-112 View PDFView articleView in
    ScopusGoogle Scholar 4 P. Andrade-Sanchez, et al. Development and evaluation of
    a field-based high-throughput phenotyping platform Funct. Plant Biol., 41 (2013),
    pp. 68-79 Google Scholar 5 L. Busemeyer, et al. BreedVision – a multi-sensor platform
    for non-destructive field-based phenotyping in plant breeding Sensors, 13 (2013),
    pp. 2830-2847 CrossRefView in ScopusGoogle Scholar 6 F. Liebisch, et al. Remote,
    aerial phenotyping of maize traits with a mobile multi-sensor approach Plant Methods,
    11 (2015), p. 9 CrossRefView in ScopusGoogle Scholar 7 L. Li, et al. A review
    of imaging techniques for plant phenotyping Sensors, 14 (2014), pp. 20078-20111
    CrossRefView in ScopusGoogle Scholar 8 A. Mutka, R. Bart Image-based phenotyping
    of plant disease symptoms Front. Plant Sci., 5 (2015), p. 734 View in ScopusGoogle
    Scholar 9 A. Mahlein, et al. Spectral signatures of sugar beet leaves for the
    detection and differentiation of diseases Precis. Agric., 11 (2010), pp. 413-431
    CrossRefView in ScopusGoogle Scholar 10 K. Omasa, et al. 3D lidar imaging for
    detecting and understanding plant responses and canopy structure J. Exp. Bot.,
    58 (2007), pp. 881-898 View in ScopusGoogle Scholar 11 M. Wahabzada, et al. Metro
    maps of plant disease dynamics-automated mining of differences using hyperspectral
    images PLoS ONE, 10 (2015), p. e0116902 CrossRefView in ScopusGoogle Scholar 12
    E. Bauriegel, et al. Early detection of Fusarium infection in wheat using hyper-spectral
    imaging Comput. Electron. Agric., 75 (2011), pp. 304-312 View PDFView articleView
    in ScopusGoogle Scholar 13 A-K. Mahlein, et al. Hyperspectral imaging for small-scale
    analysis of symptoms caused by different sugar beet diseases Plant Methods, 8
    (2012), p. 3 CrossRefView in ScopusGoogle Scholar 14 C.A. Berdugo, et al. Fusion
    of sensor data for the detection and differentiation of plant diseases in cucumber
    Plant Pathol., 63 (2014), pp. 1344-1356 CrossRefView in ScopusGoogle Scholar 15
    D. Ashourloo, et al. Evaluating the effect of different wheat rust disease symptoms
    on vegetation indices using hyperspectral measurements Remote Sens., 6 (2014),
    pp. 5107-5123 CrossRefView in ScopusGoogle Scholar 16 R. Calderón, et al. High-resolution
    airborne hyperspectral and thermal imagery for early detection of Verticillium
    wilt of olive using fluorescence, temperature and narrow-band spectral indices
    Remote Sens. Environ., 139 (2013), pp. 231-245 View PDFView articleView in ScopusGoogle
    Scholar 17 A. Prashar, et al. Infra-red thermography for high throughput field
    phenotyping in Solanum tuberosum PLoS ONE, 8 (2013), p. e65816 CrossRefView in
    ScopusGoogle Scholar 18 C. Rousseau, et al. High throughput quantitative phenotyping
    of plant resistance using chlorophyll fluorescence image analysis Plant Methods,
    9 (2013), p. 17 View in ScopusGoogle Scholar 19 S. Paulus, et al. Automated analysis
    of barley organs using 3D laser scanning: an approach for high throughput phenotyping
    Sensors, 14 (2014), pp. 12670-12686 CrossRefView in ScopusGoogle Scholar 20 D.L.
    Hernandez-Rabadan, et al. Integrating SOMs and a Bayesian classifier for segmenting
    diseased plants in uncontrolled environments Sci. World J., 2014 (2014), p. 214674
    View in ScopusGoogle Scholar 21 J.M. Pena, et al. Quantifying efficacy and limits
    of unmanned aerial vehicle (UAV) technology for weed seedling detection as affected
    by sensor resolution Sensors, 15 (2015), pp. 5609-5626 CrossRefView in ScopusGoogle
    Scholar 22 L. Emmi, et al. Configuring a fleet of ground robots for agricultural
    tasks M.A. Armada, al. et (Eds.), Advances in Intelligent Systems and Computing.
    ROBOT2013: First Iberian Robotics Conference, Springer (2014), pp. 505-517 CrossRefView
    in ScopusGoogle Scholar 23 J. Torres-Sánchez, et al. Multi-temporal mapping of
    the vegetation fraction in early-season wheat fields using images from UAV Comput.
    Electron. Agric., 103 (2014), pp. 104-113 View PDFView articleView in ScopusGoogle
    Scholar 24 J. Torres-Sanchez, et al. Configuration and specifications of an unmanned
    aerial vehicle (UAV) for early site specific weed management PLoS ONE, 8 (2013),
    p. e58210 CrossRefView in ScopusGoogle Scholar 25 C. Bauckhage, K. Kersting Data
    mining and pattern recognition in agriculture Künstl Intell., 27 (2013), pp. 313-324
    CrossRefView in ScopusGoogle Scholar 26 K.Y. Yip, et al. Machine learning and
    genome annotation: a match meant to be? Genome Biol., 14 (2013), p. 205 CrossRefView
    in ScopusGoogle Scholar 27 C. Sommer, D.W. Gerlich Machine learning in cell biology
    – teaching computers to recognize phenotypes J. Cell Sci., 126 (2013), pp. 5529-5539
    View in ScopusGoogle Scholar 28 I. Guyon, et al. Gene selection for cancer classification
    using support vector machines Mach. Learn., 46 (2002), pp. 389-422 View in ScopusGoogle
    Scholar 29 E.I. Zacharaki, et al. Classification of brain tumor type and grade
    using MRI texture and shape in a machine learning scheme Magn. Reson. Med., 62
    (2009), pp. 1609-1618 CrossRefView in ScopusGoogle Scholar 30 C. Ma, et al. Machine
    learning for big data analytics in plants Trends Plant Sci., 19 (2014), pp. 798-808
    View PDFView articleView in ScopusGoogle Scholar 31 S-e-A. Raza, et al. Automatic
    detection of diseased tomato plants using thermal and stereo visible light images
    PLoS ONE, 10 (2015), p. e0123262 CrossRefView in ScopusGoogle Scholar 32 J. Bergstra,
    et al. Theano: deep learning on gpus with python J. Mach. Learn. Res., 1 (2011),
    pp. 1-48 CrossRefGoogle Scholar 33 Y. Jia, et al. Caffe: convolutional architecture
    for fast feature embedding Proceedings of the 22nd ACM International Conference
    on Multimedia, ACM (2014), pp. 675-678 CrossRefGoogle Scholar 34 M. Kuska, et
    al. Hyperspectral phenotyping on the microscopic scale: towards automated characterization
    of plant-pathogen interactions Plant Methods, 11 (2015), p. 28 View in ScopusGoogle
    Scholar 35 J.M. Peña, et al. Weed mapping in early-season maize fields using object-based
    analysis of unmanned aerial vehicle (UAV) images PLoS ONE, 8 (2013), p. e77151
    CrossRefView in ScopusGoogle Scholar 36 C.B. Wetterich, et al. A comparative study
    on application of computer vision and fluorescence imaging spectroscopy for detection
    of Huanglongbing citrus disease in the USA and Brazil J. Spectrosc., 2013 (2013),
    pp. 1-6 CrossRefGoogle Scholar 37 F. Garcia-Ruiz, et al. Comparison of two aerial
    imaging platforms for identification of Huanglongbing-infected citrus trees Comput.
    Electron. Agric., 91 (2013), pp. 106-115 View PDFView articleView in ScopusGoogle
    Scholar 38 T. Rumpf, et al. Early detection and classification of plant diseases
    with support vector machines based on hyperspectral reflectance Comput. Electron.
    Agric., 74 (2010), pp. 91-99 View PDFView articleView in ScopusGoogle Scholar
    39 A. Camargo, J.S. Smith An image-processing based algorithm to automatically
    identify plant disease visual symptoms Biosyst. Eng., 102 (2009), pp. 9-21 View
    PDFView articleView in ScopusGoogle Scholar 40 U. Mokhtar, et al. Identifying
    two of tomatoes leaf viruses using support vector machine J.K. Mandal, al. et
    (Eds.), Information Systems Design and Intelligent Applications, Springer India
    (2015), pp. 771-782 CrossRefView in ScopusGoogle Scholar 41 L. Chen, et al. Identification
    of nitrogen, phosphorus, and potassium deficiencies in rice based on static scanning
    technology and hierarchical identification method PLoS ONE, 9 (2014), p. e113200
    CrossRefGoogle Scholar 42 K-Y. Huang Application of artificial neural network
    for detecting Phalaenopsis seedling diseases using color and texture features
    Comput. Electron. Agric., 57 (2007), pp. 3-11 View PDFView articleView in ScopusGoogle
    Scholar 43 S. Sankaran, et al. Visible-near infrared spectroscopy for detection
    of Huanglongbing in citrus orchards Comput. Electron. Agric., 77 (2011), pp. 127-134
    View PDFView articleView in ScopusGoogle Scholar 44 C. Hillnhütter, et al. Remote
    sensing to detect plant stress induced by Heterodera schachtii and Rhizoctonia
    solani in sugar beet fields Field Crops Res., 122 (2011), pp. 70-77 View PDFView
    articleView in ScopusGoogle Scholar 45 J.J. Casanova, et al. Development of a
    wireless computer vision instrument to detect biotic stress in wheat Sensors (Basel),
    14 (2014), pp. 17753-17769 CrossRefView in ScopusGoogle Scholar 46 K. Kersting,
    et al. Pre-symptomatic prediction of plant drought stress using dirichlet–aggregation
    regression on hyperspectral images Proceedings of the Twenty-Sixth AAAI Conference
    on Artificial Intelligence, AAAI Publications (2012), pp. 302-308 Google Scholar
    47 S. Bauer, et al. The potential of automatic methods of classification to identify
    leaf diseases from multispectral images Precision Agric., 12 (2011), pp. 361-377
    CrossRefView in ScopusGoogle Scholar 48 P. Baranowski, et al. Hyperspectral and
    thermal imaging of oilseed rape (Brassica napus) response to fungal species of
    the genus Alternaria PLoS ONE, 10 (2015), p. e0122913 CrossRefView in ScopusGoogle
    Scholar 49 M. Schikora, et al. An image classification approach to analyze the
    suppression of plant immunity by the human pathogen Salmonella Typhimurium BMC
    Bioinform., 13 (2012), p. 171 View in ScopusGoogle Scholar 50 M. Schikora, et
    al. Probabilistic classification of disease symptoms caused by Salmonella on Arabidopsis
    plants GI Jahrestagung, 2 (2010), pp. 874-879 View in ScopusGoogle Scholar 51
    N. Larios, et al. Haar random forest features and SVM spatial matching kernel
    for stonefly species identification Proceedings of the 2010 20th International
    Conference on Pattern Recognition, IEEE Computer Society (2010), pp. 2624-2627
    CrossRefView in ScopusGoogle Scholar 52 M. Ataş, et al. A new approach to aflatoxin
    detection in chili pepper by machine vision Comput. Electron. Agric., 87 (2012),
    pp. 129-141 View PDFView articleView in ScopusGoogle Scholar 53 O.M.O. Kruse,
    et al. Pixel classification methods for identifying and quantifying leaf surface
    injury from digital images Comput. Electron. Agric., 108 (2014), pp. 155-165 View
    PDFView articleView in ScopusGoogle Scholar 54 C. Bock, et al. Plant disease severity
    estimated visually, by digital photography and image analysis, and by hyperspectral
    imaging Crit. Rev. Plant Sci., 29 (2010), pp. 59-107 CrossRefView in ScopusGoogle
    Scholar 55 R.F. Peterson, et al. A diagrammatic scale for estimating rust intensity
    on leaves and stem of cereals Can. J. Res., 26c (1948), pp. 496-500 CrossRefGoogle
    Scholar 56 J.L. González-Pérez, et al. Color image segmentation using perceptual
    spaces through applets for determining and preventing diseases in chili peppers
    Afr. J. Biotechnol., 12 (2013), pp. 679-688 Google Scholar 57 D. Wu, C. Ma The
    support vector machine (SVM) based near-infrared spectrum recognition of leaves
    infected by the leafminers Innovative Computing Information and Control, 2006,
    IEEE (2006), pp. 448-451 Google Scholar 58 R. Calderón, et al. Early detection
    andq of verticillium wilt in olive using hyperspectral and thermal imagery over
    large areas Remote Sens., 7 (2015), p. 5584 CrossRefView in ScopusGoogle Scholar
    59 R. Kaundal, et al. Machine learning techniques in disease forecasting: a case
    study on rice blast prediction BMC Bioinformatics, 7 (2006), pp. 1-16 Google Scholar
    60 J. Behmann, et al. Ordinal classification for efficient plant stress prediction
    in hyperspectral data Int. Arch. Photogramm. Remote Sens. Spat. Inf. Sci., XL-7
    (2014), pp. 29-36 View in ScopusGoogle Scholar 61 J.G. Fortin, et al. Site-specific
    early season potato yield forecast by neural network in Eastern Canada Precision
    Agric., 12 (2011), pp. 905-923 CrossRefView in ScopusGoogle Scholar 62 A. Gonzalez-Sanchez,
    et al. Predictive ability of machine learning methods for massive crop yield prediction
    Span. J. Agric. Res., 12 (2014), p. 313 CrossRefView in ScopusGoogle Scholar 63
    A. Shekoofa, et al. Determining the most important physiological and agronomic
    traits contributing to maize grain yield through machine learning algorithms:
    a new avenue in intelligent agriculture PLoS ONE, 9 (2014), p. e97288 CrossRefView
    in ScopusGoogle Scholar 64 M. Golzarian, et al. Accurate inference of shoot biomass
    from high-throughput images of cereal plants Plant Methods, 7 (2011), p. 2 View
    in ScopusGoogle Scholar 65 T. Dube, et al. Intra-and-inter species biomass prediction
    in a plantation forest: testing the utility of high spatial resolution spaceborne
    multispectral RapidEye sensor and advanced machine learning algorithms Sensors,
    14 (2014), pp. 15348-15370 CrossRefView in ScopusGoogle Scholar 66 J. Cai, et
    al. RootGraph: a graphic optimization tool for automated image analysis of plant
    roots J. Exp. Bot. (2015), 10.1093/jxb/erv359 Published online July 29, 2015 Google
    Scholar 67 A.S. Iyer-Pascuzzi, et al. Imaging and analysis platform for automatic
    phenotyping and trait ranking of plant root systems Plant Physiol., 152 (2010),
    pp. 1148-1157 CrossRefView in ScopusGoogle Scholar 68 H. Khazaei, et al. The FIGS
    (focused identification of germplasm strategy) approach identifies traits related
    to drought adaptation in Vicia faba genetic resources PLoS ONE, 8 (2013), p. e63107
    CrossRefView in ScopusGoogle Scholar 69 R. Pieruschka, H. Poorter Phenotyping
    plants: genes, phenes and machines Funct. Plant Biol., 39 (2012), pp. 813-820
    View in ScopusGoogle Scholar 70 Y. Chéné, et al. On the use of depth camera for
    3D phenotyping of entire plants Comput. Electron. Agric., 82 (2012), pp. 122-127
    View PDFView articleView in ScopusGoogle Scholar 71 S.E. Raza, et al. Automatic
    detection of regions in spinach canopies responding to soil moisture deficit using
    combined visible and thermal imagery PLoS ONE, 9 (2014), p. e97612 CrossRefView
    in ScopusGoogle Scholar 72 C. Römer, et al. Early drought stress detection in
    cereals: simplex volume maximisation for hyperspectral image analysis Funct. Plant
    Biol., 39 (2012), p. 878 View in ScopusGoogle Scholar 73 D. Chen, et al. Dissecting
    the phenotypic components of crop plant growth and drought responses based on
    high-throughput image analysis Plant Cell, 26 (2014), pp. 4636-4655 View in ScopusGoogle
    Scholar 74 J.N. Cobb, et al. Next-generation phenotyping: requirements and strategies
    for enhancing our understanding of genotype-phenotype relationships and its relevance
    to crop improvement Theor. Appl. Genet., 126 (2013), pp. 867-887 CrossRefView
    in ScopusGoogle Scholar 75 N. Honsdorf, et al. High-throughput phenotyping to
    detect drought tolerance QTL in wild barley introgression lines PLoS ONE, 9 (2014),
    p. e97047 CrossRefView in ScopusGoogle Scholar 76 C.N. Topp, et al. 3D phenotyping
    and quantitative trait locus mapping identify core regions of the rice genome
    controlling root architecture Proc. Natl. Acad. Sci. U.S.A., 110 (2013), pp. E1695-E1704
    View in ScopusGoogle Scholar 77 A. Rasheed, et al. Genome-wide association for
    grain morphology in synthetic hexaploid wheats using digital imaging analysis
    BMC Plant Biol., 14 (2014), p. 128 View in ScopusGoogle Scholar 78 W. Yang, et
    al. Combining high-throughput phenotyping and genome-wide association studies
    to reveal natural genetic variation in rice Nat. Commun., 5 (2014), p. 5087 View
    in ScopusGoogle Scholar 79 W. Guo, et al. Automated characterization of flowering
    dynamics in rice using field-acquired time-series RGB images Plant Methods, 11
    (2015), p. 7 View in ScopusGoogle Scholar 80 L. Suárez, et al. Detecting water
    stress effects on fruit quality in orchards with time-series PRI airborne imagery
    Remote Sens. Environ., 114 (2010), pp. 286-298 View PDFView articleView in ScopusGoogle
    Scholar Cited by (662) Are unmanned aerial vehicle-based hyperspectral imaging
    and machine learning advancing crop science? 2024, Trends in Plant Science Show
    abstract The role of artificial intelligence in crop improvement 2024, Advances
    in Agronomy Show abstract Novel statistical time series data augmentation and
    machine learning based classification of unobtrusive respiration data for respiration
    Digital Twin model 2024, Computers in Biology and Medicine Show abstract Ameliorating
    the effects of multiple stresses on agronomic traits in crops: modern biotechnological
    and omics approaches 2024, Molecular Biology Reports Artificial intelligence models
    for validating and predicting the impact of chemical priming of hydrogen peroxide
    (H<inf>2</inf>O<inf>2</inf>) and light emitting diodes on in vitro grown industrial
    hemp (Cannabis sativa L.) 2024, Plant Molecular Biology Deciphering temporal growth
    patterns in maize: integrative modeling of phenotype dynamics and underlying genomic
    variations 2024, New Phytologist View all citing articles on Scopus Copyright
    © 2015 The Authors. Published by Elsevier Ltd. Recommended articles Quantifying
    time-series of leaf morphology using 2D and 3D photogrammetry methods for high-throughput
    plant phenotyping Computers and Electronics in Agriculture, Volume 135, 2017,
    pp. 222-232 Nan An, …, Cynthia Weinig View PDF Genomic Selection in Plant Breeding:
    Methods, Models, and Perspectives Trends in Plant Science, Volume 22, Issue 11,
    2017, pp. 961-975 José Crossa, …, Rajeev K. Varshney View PDF Lights, camera,
    action: high-throughput plant phenotyping is ready for a close-up Current Opinion
    in Plant Biology, Volume 24, 2015, pp. 93-99 Noah Fahlgren, …, Ivan Baxter View
    PDF Show 3 more articles Article Metrics Citations Citation Indexes: 610 Patent
    Family Citations: 2 Policy Citations: 1 Captures Readers: 1348 Social Media Shares,
    Likes & Comments: 26 View details About ScienceDirect Remote access Shopping cart
    Advertise Contact and support Terms and conditions Privacy policy Cookies are
    used by this site. Cookie settings | Your Privacy Choices All content on this
    site: Copyright © 2024 Elsevier B.V., its licensors, and contributors. All rights
    are reserved, including those for text and data mining, AI training, and similar
    technologies. For all open access content, the Creative Commons licensing terms
    apply.'
  inline_citation: '>'
  journal: Trends in Plant Science
  limitations: '>'
  pdf_link: http://www.cell.com/article/S1360138515002630/pdf
  publication_year: 2016
  relevance_score1: 0
  relevance_score2: 0
  title: Machine Learning for High-Throughput Stress Phenotyping in Plants
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1093/jxb/ert208
  analysis: '>'
  authors:
  - Erik H. Murchie
  - Tracy Lawson
  citation_count: 1372
  full_citation: '>'
  full_text: '>

    Advertisement Journals Books Issues More Content Submit Purchase Alerts About
    Journal of Experimental Botany This issue                      Plant Sciences
    and Forestry Books Journals Oxford Academic                                   Advanced
    Search Volume 64 Issue 13 October 2013 Article Contents Abstract The aim of this
    review What is chlorophyll fluorescence? Principles of chlorophyll fluorescence
    analysis Calculation of commonly used fluorescence parameters To dark adapt or
    not? Pitfalls and good practice for the fluorescence user Measuring the redox
    state of PSI Different applications of chlorophyll fluorescence Techniques for
    long-term and remote monitoring of chlorophyll fluorescence Concluding remarks
    References Comments (0) < Previous Next > JOURNAL ARTICLE Chlorophyll fluorescence
    analysis: a guide to good practice and understanding some new applications E.H.
    Murchie, T. Lawson Journal of Experimental Botany, Volume 64, Issue 13, October
    2013, Pages 3983–3998, https://doi.org/10.1093/jxb/ert208 Published: 03 August
    2013 PDF Split View Cite Permissions Share Abstract Chlorophyll fluorescence is
    a non-invasive measurement of photosystem II (PSII) activity and is a commonly
    used technique in plant physiology. The sensitivity of PSII activity to abiotic
    and biotic factors has made this a key technique not only for understanding the
    photosynthetic mechanisms but also as a broader indicator of how plants respond
    to environmental change. This, along with low cost and ease of collecting data,
    has resulted in the appearance of a large array of instrument types for measurement
    and calculated parameters which can be bewildering for the new user. Moreover,
    its accessibility can lead to misuse and misinterpretation when the underlying
    photosynthetic processes are not fully appreciated. This review is timely because
    it sits at a point of renewed interest in chlorophyll fluorescence where fast
    measurements of photosynthetic performance are now required for crop improvement
    purposes. Here we help the researcher make choices in terms of protocols using
    the equipment and expertise available, especially for field measurements. We start
    with a basic overview of the principles of fluorescence analysis and provide advice
    on best practice for taking pulse amplitude-modulated measurements. We also discuss
    a number of emerging techniques for contemporary crop and ecology research, where
    we see continual development and application of analytical techniques to meet
    the new challenges that have arisen in recent years. We end the review by briefly
    discussing the emerging area of monitoring fluorescence, chlorophyll fluorescence
    imaging, field phenotyping, and remote sensing of crops for yield and biomass
    enhancement. Chlorophyll fluorescence, field, imaging, phenotyping, photosynthesis,
    protocols, quantum efficiency. Issue Section: Review Paper The aim of this review
    Chlorophyll fluorescence is one of the most popular techniques in plant physiology
    because of the ease with which the user can gain detailed information on the state
    of photosystem II (PSII) at a relatively low cost. It has had a major role in
    understanding the fundamental mechanisms of photosynthesis, the responses of plants
    to environmental change, genetic variation, and ecological diversity. The aim
    of this review is to produce a guide to good practice in chlorophyll fluorescence
    analysis, and provide an introduction to and appreciation of some of the emerging
    technologies and new applications. Although we will provide a brief overview and
    explanation of the principles of chlorophyll fluorescence, we do not provide an
    in-depth review of the technique itself and the theory behind measurements, and
    we refer readers to several excellent reviews covering this (Krause and Weiss,
    1991; Maxwell and Johnson 2000; Adams et al., 2004; Logan et al 2007; Baker, 2008).
    The recently increased interest in the use of chlorophyll fluorescence techniques
    has been mainly due to research in crop improvement and in particular for the
    screening of desirable plant traits and linking genomic information with phenological
    responses (Baker and Rosenqvist, 2004; Furbank et al., 2009). As such there is
    great demand for protocols for rapid screening of photosynthesis that give high-resolution
    information regarding a plant’s status (often in relation to plant-based growth/development
    parameters and yield or stress; Montes et al., 2007; Furbank et al., 2009) and
    where a high number of measurements are required in a short time period. The choice
    of parameters that can be calculated from fluorescence data combined with the
    variety of instrumentation available can make it bewildering for the user. It
    is critical that the protocols used and parameters measured are appropriate for
    the particular individual study and the research questions asked, in order to
    ensure valid data are collected and the correct conclusion(s) drawn. The user
    is faced with an array of options including the type of measurement platform,
    instrument setting, the timing of a period of dark adaptation, and the conditions
    under which the plants are measured. Inexperience can lead to data that do not
    fully address the hypothesis being tested or that do not adequately cover the
    range of phenotypes that the plant is capable of expressing. In this review, we
    recognize the requirements for the use of this technique in the fields of ecology
    and agriculture and especially where measurements must be rapid. In addition,
    the development of new equipment such as monitoring fluorometers which are intended
    for automated long-term assessment of photosynthesis and chlorophyll fluorescence
    imaging for phenotypic screening has offered new opportunities. What is chlorophyll
    fluorescence? Chlorophyll within a leaf exists as pigment–protein complexes in
    PSII, PSI, and within the light-harvesting complexes (LHCs) associated with each
    of these reaction centres. Light energy absorbed by chlorophyll molecules can
    (i) drive photosynthesis (photochemistry); (ii) be re-emitted as heat; or (iii)
    be re-emitted as light (fluorescence) (Fig. 1). These three processes do not exist
    in isolation but rather in competition with each other. Thus the yield of chlorophyll
    fluorescence emission gives us valuable information about the quantum efficiency
    of photochemistry and heat dissipation. This is important for plant photosynthesis
    and ultimately productivity because photochemistry is used to provide energy and
    reducing power for CO2 assimilation. At room temperature, we assume the variations
    in the fluorescence signal arise from PSII only and we ignore emission from PSI
    largely because the signal does not make a significant contribution below 700nm
    (Butler, 1978; Pfündel, 1998; Baker, 2008) Fig. 1. Open in new tabDownload slide
    A simplified depiction of events in PSII that lead to identification of key parameters
    in fluorescence analysis. (A) A schematic figure showing electron transport within
    the PSII reaction centre complex. Energy absorbed by chlorophyll within the light-harvesting
    complex can be dissipated via photochemistry, by heat (non-photochemical quenching),
    or as fluorescence. The competition between these processes allows us to resolve
    the efficiency of PSII. (B) A typical fluorescence trace made on dark-adapted
    leaf material showing how Fo and Fm are formed. The measuring beam excites chlorophyll
    but is not of a sufficient intensity to induce electron transport through PSII
    (i.e. ‘charge separation’ when Pheo is reduced). This gives Fo, the minimal level
    of fluorescence, and reaction centres are said to be open. A brief saturating
    pulse of light results in the formation of the maximum possible yield of fluorescence,
    Fm. During this pulse reaction centres are effectively closed. (C) A schematic
    figure explaining the transfer of energy and electrons within PSII that result
    in open and closed centres and the formation of Fo and Fm states, respectively.
    The excited state P680* and subsequent transfer of an electron to the primary
    acceptor QA gives rise to a closed centre. QA– cannot accept another electron
    until it has passed its electron onto the next electron acceptor, QB. As chlorophyll
    fluorescence is a measure of re-emitted light (in the red wavebands) from PSII,
    naturally this means that any ambient light can interfere with the measurement
    of fluorescence and thus many early systems had to be used in darkness and/or
    highly controlled light environments. This issue was overcome by the development
    of modulating systems where the light used to induce fluorescence (the measuring
    beam) is applied at a known frequency (modulated) and the detector is set to measure
    at the same frequency (Schreiber et al., 1986). In this way the detector will
    only measure fluorescence that results from excitation by the measuring beam and
    will not permit interference from ambient light. The clear advantage of this is
    that measurements can be made without darkening the leaf. Non-modulated fluorescence
    has recently been re-gaining interest, and there are many devices available that
    offer the measurement of a number of parameters taken in the dark, for example
    by analysing fluorescence induction transients that occur during the application
    of a 1 s pulse from a state of darkness (Strasser et al., 2004). There is current
    interest in the use of small hand-held devices based on continuous fluorescence
    for screening, where key measurements can be made with great accuracy and speed.
    There is a plethora of parameters that are based on physical events within PSII
    which claim to give detailed structural and functional information about PSII
    activity, antenna size, and electron transport (Strasser et al., 2004). Such techniques
    are sensitive and are gaining support for use in crop phenotyping using simple
    parameters (Pask et al., 2012). However, the continued lack of empirical support
    for the more complex parameters restricts meaningful interpretation, and we urge
    caution. This contrasts with the large body of data that provides a sound physiological
    framework for the modulated technique. In this review, we only have the capacity
    to cover modulated fluorescence analysis. Principles of chlorophyll fluorescence
    analysis This section describes the biochemical events that occur within the thylakoid
    membrane that are relevant for understanding chlorophyll fluorescence analysis.
    It is intended to help the reader understand the principles, while a detailed
    explanation of the parameters is given in the next section. The state of reduction
    and oxidation (redox) state of key electron carriers is important when understanding
    the events that lead to changes in chlorophyll fluorescence, and this is described
    in Fig. 1. When light sufficient to drive photosynthesis is applied to a leaf
    after a period of darkness, there is a transient rise (usually for a few seconds)
    in the level of chlorophyll fluorescence that is usually the result of the reduction
    of electron carriers in the thylakoid membrane. The special chlorophyll in PSII,
    P680, ejects an electron derived from water splitting to the electron acceptor
    QA (a bound quinone) via the initial acceptor pheophytin. However, QA is not able
    to accept another electron from P680 until it has passed its electron to the next
    carrier, QB. In this state, the reaction centre is considered to be ‘closed’.
    Depending on the prevailing conditions such as light intensity or temperature
    (which affects the metabolic state), a greater or lesser proportion of reaction
    centres may be closed. Closure will inevitably cause a decline in quantum efficiency
    of PSII. Following the initial rise in fluorescence after the application of actinic
    light, the fluorescence signal then declines over a period of minutes, which is
    termed ‘quenching’ (Krause and Weis, 1991). Quenching of the fluorescence signal
    can arise from a combination of processes: first there is the light activation
    of the process of photosynthesis itself. In particular, key enzymes in the Calvin
    cycle require activation in order to achieve full activity (Buchanan and Balmer,
    2005), and metabolite pool sizes in the stroma and cytosol need to increase. From
    darkness at ambient temperatures, this process typically can take several minutes
    or longer, with a large amount of variation caused by species and environment.
    Another factor is the opening of stomata, which increases the availability of
    CO2 for Rubisco. Stomata tend to open and close an order of magnitude more slowly
    than photosynthetic events (Lawson et al., 2012). All of these processes provide
    an increased availability of sinks for the electrons derived from the light-dependent
    processes in the thylakoid and contribute to the quenching by the process of photosynthesis
    itself, and this is termed photochemical quenching. Secondly, on illumination,
    there is a rapid increase in the rate constant for heat dissipation of chlorophyll
    excitation energy, measured using a parameter termed non-photochemical quenching
    (NPQ). This is a photoprotective process that removes excess excitation energy
    within chlorophyll-containing complexes and prevents the likelihood of formation
    of damaging free radicals. This type of quenching competes with both fluorescence
    and photochemical quenching, and acts as a ‘safe’ mechanism for dissipating substantial
    levels of chlorophyll excitation energy, depending on the prevailing conditions
    and species (Demmig-Adams and Adams, 2006). The process of NPQ is regulated by
    the acidification of the thylakoid lumen due to the accumulation of protons in
    the thylakoid lumen (during linear and cyclic electron flow) that form a ΔpH (Horton
    et al., 1996, 2008; Ruban et al., 2012). It also involves the regulatory protein
    PsbS and the conversion of violaxanthin to zeaxanthin in the xanthophyll cycle
    (Li et al., 2002; Kiss et al., 2008; Murchie and Niyogi, 2011). Xanthophylls are
    carotenoids that play a critical part in NPQ (Demmig Adams, 1990): the conversion
    of violaxanthin to zeaxanthin takes place in the light following the activation
    of the enzyme violaxanthin de-epoxidase by the acidification of the thylakoid
    lumen (Yamamoto et al., 1999). Both protonation of PsbS and the formation of zeaxanthin
    result in conformational changes in PSII antenna that induce quenching of excitation
    energy in the antenna of PSII (Ruban et al., 2012). An overarching concept is
    that chlorophyll fluorescence analysis allows us to separate the components that
    make up all energy dissipation of chlorophyll in the thylakoid membrane. Early
    techniques for doing this involved applying chemicals such as herbicides that
    block electron transport in PSII (Krause et al., 1982; Horton and Hague, 1988)
    to remove photochemical quenching, thereby giving an indication of what photochemistry
    was before the application of the herbicide. Clearly this is not practical on
    a routine basis, and techniques were developed that involved the application of
    a brief (<1 s) very bright saturating flash of light that temporarily closes all
    PSII reaction centres for the duration of its application (Bradbury and Baker,
    1981; Quick and Horton, 1984). During the flash, the reaction centres are closed
    (see Fig. 1) and so the level of photochemical quenching is effectively zero and
    only non-photochemical processes will remain. The fundamental principle of the
    saturating flash/pulse is that fluorescence rises to a level corresponding to
    that which would exist without any photochemical quenching. Calculation of commonly
    used fluorescence parameters Figure 2 shows a ‘typical’ fluorescence trace of
    the type that are repeatedly used to simplify the principles of chlorophyll fluorescence
    and provide an explanation of how we can derive important information about the
    performance of PSII by comparing fluorescence levels whilst exposing the leaf
    to a combination of actinic lights (i.e. light that drives photochemistry and
    photosynthesis), darkness, and a series of saturating pulses. This is based around
    the principle of separating the photochemical and non-photochemical components.
    Fig. 2. Open in new tabDownload slide A stylized fluorescence trace of a typical
    experiment using dark-adapted leaf material to measure photochemical and non-photochemical
    parameters. This would be typical of an induction at high irradiance of ≥500 μmol
    m–2 s–1. A true ‘Kautsky’ effect would be measured at moderate illumination, for
    example <200 μmol m–2 s–1, where transients corresponding to induction of photosynthesis
    are revealed. Note that the ‘decay’ of Fo′ in the dark after switching off the
    actinic light would be accelerated by adding FR light to stimulate PSI activity.
    More explanation is given in the text. In the dark-adapted state (when all PSII
    centres are open and no NPQ is present), a ‘measuring light’ is switched on (Figs
    1, 2). This light is of an intensity too low to induce electron transport through
    PSII but high enough to elicit a minimum value for chlorophyll fluorescence, termed
    Fo. The measurement of Fo and its light-adapted equivalent Fo′ is fundamental
    to fluorescence analysis, and attention should be paid to the issues raised and
    recommendations in this review. Fo′ is measured immediately after switching off
    the actinic light, but accurate measurement is difficult: many instruments have
    the capacity to apply a weak far-red (FR) light to measure both Fo and Fo′ (typically
    a few seconds). FR light stimulates PSI, drawing electrons from PSII to ensure
    that QA remains fully oxidized during measurements. This is important since QA
    can be partially reduced in the dark by chlororespiration (see review by Peltier
    and Cournac, 2002). An alternative approach is to calculate Fo′: see below. Application
    of a saturating pulse to a dark-adapted leaf induces a maximum value of fluorescence
    by closing reaction centres. At this point, in a healthy non-stressed plant there
    is no NPQ because the material has been fully dark adapted; therefore, the maximal
    possible value for fluorescence, Fm, is recorded. The difference between Fo and
    Fm is the variable fluorescence, Fv. It has been shown theoretically and empirically
    that Fv/Fm gives a robust indicator of the maximum quantum yield of PSII chemistry
    (Butler, 1978; Genty et al., 1992). For unstressed leaves, the value of Fv/Fm
    is highly consistent, with values of ~0.83, and correlates to the maximum quantum
    yield of photosynthesis (Demmig and Björkman, 1987). The existence of any type
    of ‘stress’ that results in inactivation damage of PSII (often referred to as
    photoinhibition, see below) (Long et al., 1994) or the induction of sustained
    quenching (Demmig-Adams and Adams, 2006) results in a lowering of Fv/Fm. This
    has meant that measuring Fv/Fm following an appropriate period of dark adaptation
    has been used as one of the most common techniques for measuring ‘stress’ in leaves.
    If a sufficiently strong actinic light is now applied, we see an initial rise
    in fluorescence. This is then quenched as a result of the increasing competition
    with photochemical and non-photochemical events. The steady-state level of fluorescence
    in the light is termed, F′. Generally speaking, it may take several minutes or
    much longer (e.g. >20min) to achieve a steady state from a dark-adapted state.
    The application of a saturating pulse under actinic illumination transiently closes
    all the reaction centres and provides a value of maximal fluorescence in the light-adapted
    state, termed Fm′. Note that this is less than the dark-adapted Fm value due to
    the contribution of NPQ. If we have both dark-adapted and light-adapted measurements
    we can measure three key parameters. (i) The operating efficiency of PSII photochemistry,
    Fq′/Fm′ (Genty et al., 1989), is calculated from (Fm′–F′)/Fm′ (and does not require
    a dark-adapted measurement). This parameter is often termed ϕPSII or ΔF/Fm′ (Maxwell
    and Johnson, 2000; Baker, 2008). It gives the proportion of absorbed light that
    is actually used in PSII photochemistry (Genty et al., 1992) and can therefore
    be used to estimate the rate of electron transport through PSII with knowledge
    of light absorptance by the leaf and photosystems (which has technical difficulties
    associated with it, that are discussed below). Due to its simplicity of measurement
    Fq′/Fm′ is the most commonly measured and used light-adapted parameter. Fq′/Fm′
    can be broken down into two products, the level of photochemical quenching of
    PSII (Fq′/Fv′) and PSII maximum efficiency (Fv′/Fm′) (a parameter that describes
    the maximum operating efficiency in the light-adapted state, with any decrease
    in this parameter reflecting an increase in NPQ). (ii) The level of photochemical
    quenching of PSII, Fq′/Fv′ (often referred to as qP: Table 1) gives an indication
    of the proportion of reaction centres that are open. Some studies have used 1–Fq′/Fv′
    (or 1–qP) to denote the proportion of closed reaction centres (Huner et al., 1996,
    1998). It has also been used to indicate the onset of photoinhibition (Anderson
    et al., 1995) and in determining the level of photoprotective quenching of fluorescence
    (Ruban and Murchie, 2012). The relationship between Fq′/Fv′ and the fraction of
    open PSII reaction centres is not considered linear, so such interpretations should
    be made with care. The parameter qL [(Fq′/Fv′)/(Fo′/F′)] is considered a more
    accurate indicator of the PSII redox state (see Kramer et al., 2004; Baker, 2008).
    (iii) The level of NPQ (see Table 1) is the only measurement that requires knowledge
    of the dark-adapted values of Fo and Fm. Therefore, if the dark-adapted Fv/Fm
    value is substantially lower than 0.83, this value should be treated with caution
    and in particular NPQ in leaves with differing Fv/Fm values should not be compared.
    To dark adapt or not? A key question asked by many researchers is always ‘for
    how long should I dark-adapt my leaf?’. To answer this, the user must appreciate
    that NPQ contains different components as we explain below (Walters and Horton,
    1991; Horton et al., 1996). Switching off the actinic light allows us to re-measure
    the minimal level of fluorescence, Fo′. To obtain this accurately in a light-adapted
    leaf, we need to ensure that PSII is fully oxidized, and this can be achieved
    using a pulse of FR light. Figure 1 demonstrates that by applying regular saturating
    pulses we can follow the relaxation of Fm′ in the dark until it reaches its dark-adapted
    value again. Table 1.List of commonly used abbreviations and equationsNote that
    this is included to identify only the most common parameters, and we refer the
    reader to comprehensive reviews of Baker (2008) and Maxwell and Johnson (2000).
    Parameter Also known as Formula (see Fig. 2) Description Fv/Fm (Fm–Fo)/Fm Maximum
    quantum efficiency of PSII photochemistry. Fv′/Fm′ (Fm′–Fo′)/Fm′ Maximum efficiency
    of PSII photochemistry in the light, if all centres were open. Fq′/Fm′ ϕPSII,
    ΔF/Fm′ (Fm′–F′)/Fm′ PSII operating efficiency: the quantum efficiency of PSII
    electron transport in the light. Fq′/Fv′ qP (Fm′–F′)/(Fm′–Fo′) Photochemical quenching:
    relates PSII maximum efficiency to operating efficiency. Non-linearly related
    to proportion of PSII centres that are open. See qL. NPQ (Fm–Fm′)/Fm′ Non-photochemical
    quenching: estimates the rate constant for heat loss from PSII. qL (Fq′/Fv′)/(Fo′/F′)
    Estimates the fraction of open PSII centres. Open in new tab For advanced users,
    the kinetics of relaxation allows us to separate NPQ into different components
    that relax slowly or more quickly, depending on their origin. However, separation
    of these components is not trivial in the field (Murchie and Horton, 2007). The
    majority of NPQ is usually made up of high energy state quenching or qE that occurs
    via the mechanisms described above (Walters and Horton, 1991; Murchie and Horton,
    2007). Two other components exist: quenching caused by state transitions (qT)
    which refers to the migration of peripheral LHCIIs from PSII to PSI. This is normally
    associated with low light conditions and its significance in high light is thought
    to be small. Second photoinhibitory quenching (qI) is small at moderate and low
    light but becomes important at high saturating light levels. qI is often used
    to refer to any sustained quenching (i.e. is not removed by dark adaptation).
    Photoinhibition is usually assumed to arise from inactivation of PSII by photooxidation
    followed by a repair cycle, whereby PSII is partially disassembled and the damaged
    D1 protein is repaired by de novo synthesis and reassembled (Yokthongwattana and
    Melis, 2006; Sun et al., 2010). Long-lived quenching is also associated with the
    accumulation and retention of zeaxanthin (Demmig Adams et al., 2006; Horton et
    al., 2008). A rise in Fo is associated with photoinhibitory damage but not with
    zeaxanthin retention. Note that it is possible to use the changes in Fv′/Fm′ as
    an indicator of changes in NPQ as the two parameters will coincide non-linearly,
    but note also that it can be inaccurate at higher values of NPQ (e.g. Murchie
    et al., 1999). More accurately, changes in Fv′/Fm′ give an indication of the contribution
    NPQ makes to Fq′/Fm′. Pitfalls and good practice for the fluorescence user In
    practice, it is rarely possible or necessary to go through an entire dark–light–dark
    protocol as shown in Fig. 2. For example, in the field, it is common due to time
    constraints to perform one measurement within one saturating pulse with or without
    a dark adaptation period, in which case the user will need to extract as much
    useful information as possible from a limited set of data. The following section
    should help the user select the correct protocol to maximize the information obtained
    from their experiment and avoid some common pitfalls. To supplement this section,
    we have included several protocols at the end of this review that, if followed,
    would help the novice to understand the issues. Issues with the dark-adapted state
    One of the first questions that faces a user is ‘should I dark adapt? Clearly
    this depends on the objectives of the experiment and the time and equipment available.
    There is sometimes an assumption that dark adaptation is necessary to achieve
    the best results, but it must be decided first whether information on photoinhibition
    or sustained down-regulation of PSII is required or whether operational photosynthesis
    in the growth conditions is more important. Returning the leaf to a fully dark-adapted
    state (Fv/Fm value of ~0.83) is essential for studies of NPQ and for quenching
    analysis, if that is what is required. Some users prefer to use pre-dawn Fv/Fm
    values, and this is advisable if the experiment involves persistent, severe long-term
    suboptimal conditions such as drought. The presence of low pre-dawn Fv/Fm will
    indicate substantial photoinhibition or down-regulation of PSII. A good example
    would be the sustained dissipation of reaction centres in over-wintering evergreen
    plants (Demmig Adams and Adams, 2006) or severe drought stress (Flexas et al.,
    2002). Note that mild drought associated with stomatal closure will not by itself
    usually result in a substantial decline in Fv/Fm (for a review, see Baker and
    Rosenqvist, 2004). Diurnal photoinhibition where the Fv/Fm values recover more
    rapidly is common in many environments (Ogren, 1988; Demmig-Adams et al., 1989;
    Murchie et al., 1999). The best answer to this question is that it should be tested
    on the species under study using non-stressed control conditions by dark adaptation
    from a steady-state condition in the light and then frequent measurement every
    5–10min until a steady value of Fv/Fm is reached. In practice, if the plant is
    well adapted to its environment and temperatures are within an optimal range,
    20–30min should be sufficient to remove all qE and qT components. Any remaining
    sustained quenching is usually referred to as qI and, as mentioned, can be caused
    by photoinactivation (damage) to the D1 protein or a long-lived quenching state
    caused by retention of zeaxanthin. Inactivation of and damage to D1 results in
    an increase in Fo, but long-lived zeaxanthin quenching does not. The difficulties
    associated with measuring Fo and Fo′ are covered below. Here we deal with the
    measurements of Fo and Fm in the dark. Accurate measurements of Fo in the field
    are made difficult due to relaxation kinetics of the return to the dark-adapted
    state. When a leaf is placed in the dark, the movement of electrons in the thylakoid
    should cease almost immediately. However, NPQ ‘relaxes’ more slowly because the
    protective non-photochemical quenching processes remain active (such as zeaxanthin).
    Therefore, to discover the true maximum value of fluorescence, we need to allow
    the leaf to remain in the dark for a length of time sufficient for these processes
    to complete (i.e. NPQ to become zero). The length of this process depends on factors
    such as the state of de-epoxidation of the xanthophyll cycle; see above (Horton
    et al., 1996). Some devices provide a pulse of FR light for measuring Fo in a
    dark-adapted leaf to ensure that QA is fully oxidized, and this should be used
    where available. This can also be an issue if QA reduces due to reduction of plastoquinone
    by chlororespiration (Baker, 2008). Another pitfall at this state is avoiding
    charge separation in PSII; that is, inducing electron transport by using either
    a high measuring beam intensity or an overly high frequency of modulation. This
    can result in a false value of Fo. It is straightforward to adjust the measuring
    beam intensity: if it induces quenching or a rise in fluorescence when measuring
    a dark-adapted leaf, then consider lowering the intensity. During actinic or pulse
    application, it is necessary to have a high frequency of modulation to help reduce
    the effect of variation in the signal, but this is not recommended in the dark-adapted
    state. The frequency is often adjusted automatically by the device software during
    pulsing, but it is advisable to check the manufacturer’s instructions. The dark-adapted
    value of Fv/Fm is commonly used to assess plant ‘stress’, and has proved invaluable
    in many studies (e.g. Maxwell et al., 1994; Murchie et al., 1999), reflecting
    the high sensitivity of PSII to environmental stimuli, either directly or indirectly.
    However, its interpretation is not always straightforward, for a number of reasons.
    (i) First, the underlying cause of the decline cannot be assessed easily. The
    inactivation of PSII reaction centres leading to oxidative damage and removal
    of PSII reaction centres is usually associated with heat loss and reduction in
    Fv/Fm (rise in Fo). Caution must be applied here, however, because the optical
    properties of the leaf can change under certain stress conditions such as drought,
    meaning that the individual values of Fm and Fo may be a result of changes in
    leaf absorptance. Examples of optical properties under drought can be shown by
    the change in reflectance spectra (e.g. Babar et al., 2006). These errors are
    removed when the ratio Fv/Fm only is considered. (ii) It is often stated that
    a decline in Fv/Fm is evidence that the photosynthetic performance of the plant
    is compromised. This is not necessarily the case: Fv/Fm measures the intrinsic
    quantum yield of PSII, and as such it should correlate with the maximum quantum
    yield of photosynthetic gas exchange (CO2 or O2). However, the latter is measured
    by the linear portion of a light response curve (i.e. under low light-limiting
    conditions). It is therefore possible (and presumably relatively common) for a
    leaf to have a reduced Fv/Fm but no penalty to photosynthesis in high and saturating
    light conditions (Demmig-Adams and Adams, 2006; Murchie and Niyogi, 2011). For
    leaves that have undergone severe light stress, a reduction in both light-limited
    and light-saturated photosynthesis is possible. (iii) There may be a requirement
    for a sufficiently high light intensity to induce inactivation of PSII (Takahashi
    and Murata, 2008) before a difference in Fv/Fm is observed between treatments.
    (iv) Fv/Fm assesses the maximum quantum yield of PSII only. A site of stress in
    another part of the plant (e.g. roots) may not manifest itself as a change in
    Fv/Fm. This may seem an obvious statement, but it is included to prevent the assumption
    that fluorescence is a generic ‘plant stress detector’. Problems with measurements
    in the light Due to its ease of measurement, Fq′/Fm′ (also known as ϕPSII) is
    a highly popular measurement and has largely established itself as an accurate
    indicator of operational PSII efficiency in the light (Genty et al., 1992; Maxwell
    and Johnson, 2000; Baker, 2008). Some inaccuracies of the light pulse technique
    have been pointed out: for example, PSI can contribute to fluorescence when measurements
    are made above 700nm (e.g. Genty et al., 1990) and the existence of ‘multiple
    turnovers’ of PSII during the saturating pulse (Vernotte et al., 1979). However,
    these are now considered to be mostly small or rare partly due to high level of
    agreement between Fq′/Fm′ and the quantum yield of CO2 assimilation (Baker 2008).
    In the field, Fq′/Fm′ is an extremely useful parameter because it is possible
    to derive rates of PSII electron transport (although several caveats to this are
    discussed below). However, consideration must first be given to the factors that
    cause the values to change. First, it is highly dependent on the ambient light
    levels and can vary substantially with even a relatively small change in photosynthetically
    active radiation (PAR). Therefore, making measurements in the natural environment,
    one should interpret the data with this in mind by incorporating equipment that
    accurately measures PAR at the leaf surface. Alternative techniques have restricted
    measurements to periods of the day where PAR is known to be saturating for photosynthesis
    and electron transport (Murchie et al., 1999, 2002). Since Fq′/Fm′ directly measures
    the quantum yield of PSII electron transport it is possible to calculate the rate
    of electron transport directly using knowledge of absorbed PAR and the fraction
    of light intercepted by PSII and PSI. Determining absorption by the two photosystems
    is extremely difficult to quantify accurately, and users often make the assumption
    of equal absorption by both PSII and PSI (using a value of 0.5). Absorbed PAR
    can be relatively accurately determined using an integrating sphere or similar
    device, and this is highly recommended, although this type of measurement tends
    to be rare. Instead a value of 0.84 is often used and considered to be an average
    value of leaf absorption. Although these ‘standard values’ are usually tacitly
    assumed to be ‘constants’, the user is warned against comparison of leaf samples
    that are likely to have differing optical properties that will affect light absorption
    (or the same leaf undergoing stress treatment). For example, comparing electron
    transport rate (ETR) values in a drought-stressed leaf with a low turgor value
    with a control hydrated leaf is not appropriate. Leaf samples with different pigment
    contents or photosystem stoichiometry such as those that have undergone changes
    in light acclimation state (Walters et al., 2005; Anderson et al., 1995) may also
    suffer inaccuracies. Errors in measurements of Fo′ The measurement of Fo′ can
    be open to error if the FR light applied does not adequately oxidize QA and if
    the relaxation of NPQ causes Fo′ to increase rapidly after the actinic light has
    been switched off. A solution to this was presented by Oxborough and Baker (1997a)
    who suggested that Fo′ can be calculated from light-adapted measurements with
    knowledge of Fo and Fm, utilizing the quenching of Fm′ using the following equation
    (Equation 1). (1) Measuring the redox state of PSI It is becoming increasingly
    common to include measurements of the PSI redox state (Klughammer and Schrieber,
    1994) and directly compare them with measurements of Fq′/Fm′, measured as above.
    Some devices combine these measurements for simultaneous measurement. Cyclic electron
    flow around PSI affects the accumulation of ΔpH and has a role in photoprotection
    and regulation of the ‘redox poise’ of the thylakoid electron transport chain
    (Nandha et al., 2007; Johnson, 2011). As this has a role in determining PSII events,
    including NPQ, it is wise to assess briefly the role of these measurements here.
    This is achieved by monitoring the redox state of the reaction centre chlorophyll
    of PSI, P700, via absorbance in the near infrared (peak at 810–840nm) (Klughammer
    and Schreiber, 1994). Combining ϕPSII and ϕPSI measurements can be valuable (Johnson,
    2011). However, the same principles apply with measuring PSII ETR above: comparing
    PSII:PSI ETR ratios in contrasting leaves should be approached with great caution,
    and the difference between ETR of PSII and PSI cannot give the rate of cyclic
    electron transport without empirical correction for stoichiometry and light absorption.
    Different applications of chlorophyll fluorescence Relationship to CO2 assimilation
    In whole-leaf studies it is natural to extend the interpretation of chlorophyll
    fluorescence data to analyse its impact on photosynthetic rates of CO2 assimilation
    and, by inference, productivity of the plant or system in question. Under certain
    controlled circumstances, the Fq′/Fm′ measured by fluorescence is accurately correlated
    with rates of CO2 assimilation which has added extra interest to extend the possibilities
    of this technique and has led to advances in our understanding of photosynthetic
    regulation (Genty et al., 1989, 1990; Cornic, 1994). This relationship makes intuitive
    sense because the products of linear electron transport, ATP and NADPH, are used
    directly in photosynthetic carbon assimilation in known ratios. In C3 plants,
    this close correlation can be observed best when photorespiration is inhibited
    by lowering the partial pressure of oxygen to 2%. Why? The electron requirement
    for assimilation of one CO2 molecule in leaves where photorespiration is inhibited
    is four. This number will rise as the proportion of carbon flux through the photorespiratory
    pathway rises, for example as happens during stomatal closure (Wingler et al.,
    1999; Flexas et al., 2002). Therefore, whenever the electron requirement is altered,
    the relationship between Fq′/Fm′ and CO2 assimilation rate is also altered. Unfortunately,
    for field-based measurements, the number of factors that can cause this is high:
    stomatal closure (as mentioned below), temperature (this changes the relative
    rates of carboxylation and oxygenation in the leaf), abiotic stress (this results
    in an increased activity of alternative electron sinks such as the Mehler reaction
    and cyclic electron transport), leaf development, and shading. A common example
    given of this disconnect between Fq′/Fm′ and the CO2 assimilation rate is that
    of species in environments undergoing multiple stresses (Cheesman, 1991). In conclusion,
    this means that linearity is difficult to achieve unless tightly controlled conditions
    are used and care is taken when comparing samples in which the ratio of allocation
    between CO2 assimilation and other processes is known not to have changed. The
    relationship in C4 plants is much more easily achieved due to the suppression
    of photorespiration by the CO2-concentrating mechanism. Another point of error
    is the one mentioned above regarding the accurate measurement of ETR. Imaging
    of chlorophyll fluorescence Imaging of chlorophyll fluorescence is becoming increasingly
    popular as a screening (Barbagalo et al., 2003) and diagnostic tool (Baker, 2008),
    due mostly to the development of instrumentation (Oxborough, 2004), with many
    commercial instruments available through companies such as Photon Systems Instruments
    (Brno, Czech Republic); Walz (Effeltrich, Germany), and Technologica Ltd (Essex,
    UK), amongst others. Chlorophyll fluorescence imaging has also recently been incorporated
    into many phenotyping platforms for high-throughout phenotypic analysis. There
    are several advantages to imaging, and below we have explored some of these along
    with some examples of uses. Screening Chlorophyll fluorescence imaging allows
    multiple plants to be monitored at the same time under identical conditions, providing
    an ideal screening platform. Chlorophyll fluorescence directly relates to the
    rate of energy flow via the electron transport chain and therefore any perturbation
    that impacts on plant metabolism (e.g. pathogen infection) will impact on fluorescence
    parameters even if not directly linked to photosynthesis (Barbagallo et al., 2003).
    Examples of screening multiple plants include early detection of herbicide application
    (Barbagallo et al., 2003; Jin et al., 2011), nutrient deficiency (Mauromicale
    et al., 2006), drought stress (Rahbarian et al., 2011), identification of CO2-sensitive
    photorespiratory Arabidopsis thaliana mutants (Badger et al., 2009), and plants
    with improved photosynthesis and crop yield (Baker and Rosenqvist, 2004; Chaerle
    et al., 2007; Baker, 2008; Harbinson et al., 2012). Spatial and temporal heterogeneity
    An advantage of any imaging technique is the detailed spatial representation of
    the measured parameter, allowing the assessment of sample heterogeneity. Monitoring
    changes within such images provides additional temporal assessment of the measured
    parameter. Examples of spatial heterogeneity highlight the value and appeal of
    imaging, by drawing attention to the fact that ‘detection of symptoms’, or assessment
    of ‘reductions in a specific fluorescence parameter’ may well have been missed
    if a traditional fibre optic approach had been utilized, which is only capable
    of measuring a small area/proportion of the leaf. There are numerous examples
    of chlorophyll fluorescence imaging for detecting within-leaf or plant treatment
    effects, including the assessment of freezing tolerance and cold acclimation in
    Arabidopsis (e.g. Ehlert and Hincha, 2008), insect herbivory (e.g. Tang et al.,
    2006), leaf fungal infection (e.g. Scholes and Rolfe, 2009; McElrone et al., 2010),
    and the impact of ozone damage (Leipner et al., 2001; Aldea et al., 2006). Degrees
    of resolution Depending on instrumentation, images of chlorophyll fluorescence
    can be obtained at a range of resolutions. High-resolution images of stomatal
    guard cells have been used to determine efficiency and quenching parameters from
    individual chloroplasts (Baker et al., 2001; Fig. 3). The spread of disease and
    host–pathogen interactions has been monitored both spatially and temporarily at
    the leaf level using high-resolution images of NPQ and Fq′/Fm′ (Scholes and Rolfe,
    2008), while Aldea et al. (2006) illustrated fine-grain heterogeneity in mapping
    the spatial patterns of the production of reactive oxygen species (ROS) on PSII
    quantum efficiency following viral infection or ozone damage. A high-resolution
    microscope imaging system was used to show the impact of water stress and CO2
    concentration on guard cell photosynthetic efficiency in a range of different
    plant types by Lawson et al. (2003). A similar system has been used to detect
    the impact of heavy metals such as cadmium on the aquatic plant Lemna (Fig. 3)
    Three-dimensional chlorophyll fluorescence imaging has also been used in the detection
    of herbicide effects on a whole plant (Eguchi et al., 2008). Fig. 3. Open in new
    tabDownload slide (a) Images of steady-state fluorescence (F′) and (b) photosynthetic
    efficiency of PSII photochemistry (Fq′/Fm′) from 10cm2 leaf area enclosed in a
    chamber during simultaneous gas exchange measurements demonstrating the effect
    of patchy stomatal closure. Images were captured 5min after dropping the humidity
    rapidly from 80% to 20%. All other chamber conditions were maintained at 200 μmol
    m–2 s–1 PPFD, 400 mmol mol–1 [CO2], 2% [O2], and a temperature of 24 °C. (c) An
    example of chlorophyll fluorescence as a screening technique showing the detection
    of the effects of herbicide treatment on Fv/Fm of 1-week-old Arabidopsis plants
    growing on a 96-well plate (unpublished image of Technologica Ltd, with permission).
    (d) An Fq′/Fm′ image showing the heterogeneity of two Arabidopsis plants after
    10min acclimation to 300 μmol m–2 s–1 PPFD following induction of heterogeneity
    with 1h at a high light intensity of 1000 μmol m–2 s–1. (e) An image of Fv/Fm
    of the epidermis of an intact Tradescantia leaf showing the guard cell chloroplasts
    following the methods of Oxborough and Baker (1997b) taken with a high resolution
    microscope chlorophyll fluorescence imaging system (unpublished image of McAusland
    and Lawson). (f) Use of the chlorophyll fluorescence parameter Fq′/Fm′ to screen
    transgenic plants that have reduced levels of SBPase. The plant in the upper right
    and lower left have much greater reductions in SBPase than the other two plants.
    (g) Images of Fv/Fm taken after 20min dark adaption from three different varieties
    of wheat plants grown in the field, with different susceptibilities to rust. The
    middle images show a variety that is more susceptible to rust (unpublished image
    of Lawson and Driever). (h) A cut elder leaf illustrates the decrease in photosynthetic
    efficiency (Fq′/Fm′) with DCMU uptake via the petiole during transpiration. (i)
    High-resolution image of the effect of Cd on photosynthetic efficiency in the
    aquatic plant Lemna. The image was captured after stabilizing to 200 μmol m–2
    s–1 light after having been exposed to Cd for 1 d. The image on the left represent
    steady-state fluorescence (F′) while that on the right is a false-colour image
    of Fq′/Fm′. (Unless stated all images are unpublished data of TL.) Combined with
    other techniques The combination of chlorophyll fluorescence imaging with other
    measurement techniques and instrumentation can provide a unique research tool,
    that enables users to answer novel questions. For example, using chlorophyll fluorescence
    imaging with infra-red gas exchange (IRGA) techniques enables the user to correlate
    PSII photosynthetic efficiency directly to the IRGA-measured CO2 assimilation
    rate by eliminating photorespiration through the reduction of [O2] or increase
    in [CO2] within the chamber. For example, such calibration techniques have been
    instrumental in developing protocols and procedures to visualize patterns of CO2
    diffusion in leaves (Morison et al., 2005; Lawson and Morison, 2006), enabling
    the determination of gas fluxes within leaves of different species (Morison et
    al., 2007), taking into account the venation patterns of the leaf (Lawson and
    Morison, 2006) and the importance of fluxes on carbon gain (Pieruschka et al.,
    2005, 2006; Morison and Lawson, 2007). Control of the gas environment around the
    samples being imaged enables users to identify specific plants traits; for example,
    photorespiratory mutants were identified under a zero [CO2] environment, with
    plants maintained in an air-tight box with a layer of CO2-absorbing material on
    the bottom (Badger et al., 2009). Using a high-resolution microscope chlorophyll
    fluorescence imaging system, Lawson et al. (2002) employed a specially designed
    IRGA chamber to control [CO2] and [O2] as well as humidity, to show for the first
    time in intact green leaves that Calvin cycle activity was the major sink for
    guard cell photosynthetic electron transport. Using humidity as a driver of stomatal
    behaviour (which does not directly affect photosynthesis), the same authors also
    showed that the opening and closing of stomata is not linked to guard cell photosynthetic
    efficiency unless the closure reduces the internal CO2 concentration to which
    guard cell photosynthetic electron transport responded (Lawson et al. 2002). The
    combination of chlorophyll fluorescence imaging with other imaging technologies
    is also proving an extremely powerful tool in the development of large-scale phenotyping
    protocols and platforms. Although a full description of such phenotype imaging
    is beyond the scope of this review, the use of combined chlorophyll fluorescence
    imaging and thermography can supply critical information on photosynthetic rates
    in relation to stomatal behaviour (Chaerle et al., 2007) and, if performed under
    controlled conditions with appropriate calibrations, could provide an approach
    for imaging intrinsic water use efficiency (iWUE) (Lawson, 2009). Chlorophyll
    fluorescence imaging has also been combined with hyperspectral imaging for early
    detection of head blight disease in wheat (Bauriegel et al., 2011). The advantage
    of this combined system enables chlorophyll degradation and the impact of different
    diseases to be distinguished based on changes in photosynthetic efficiency and
    spectral signatures such as those used in remote sensing that assess vegetation
    status, such as the Normalized Difference Vegetation Index (NDVI). There are also
    a couple of disadvantages to imaging chlorophyll fluorescence relative to the
    use of a standard fibre optic system. The cost of the instruments tends to be
    greater than those of fibre optic fluorimeters (although inexpensive compared
    with buying several fluorimeters for measuring several plants simultaneously).
    Chlorophyll fluorescence imaging systems tend to require large banks of light-emitting
    diodes (LEDs) to ensure even actinic illumination and fully saturating pulses
    over the entire imaging area. This makes the instruments relatively large in size,
    and, in general, they are considered laboratory instruments and not portable systems,
    such as many of the hand-held devices. Having said this, several manufacturers
    have released field-based hand-held imaging systems (many of which are combined
    with IRGA instruments). For example, Walz extended its M-Series Imaging-PAM to
    include a MINI version for application in the field. This is a compact design,
    with high magnification and resolution, and can be mounted on their standard gas
    exchange equipment for dual measurements (http://www.walz.com/products/chl_p700/imaging-pam_ms/mini_version.html).
    Photon Systems Instruments (http://www.psi.cz/), also produce a number of portable
    leaf chamber imaging platforms, such as ‘FluorCam’ that is designed to attach
    to a range of standard gas exchange chambers produced by a number of commercial
    manufacturers. Customized fluorescence imaging systems are also available for
    large-scale scanning in the field, in which the lights and camera are enclosed
    in a cabinet (for dark-adapted measurements) and the entire system is on wheels
    (http://qubitsystems.com/plant-and-soil/z240-rover-fluorcam/), allowing it to
    move over crops collecting images. Large-scale measurements of chlorophyll fluorescence
    parameters are desirable and currently of great interest to researchers who use
    unmanned aerial vehicle (UAV)-based platforms for remote sensing (e.g. Zarco-Tejada
    et al., 2011); however, a discussion of these systems is beyond the scope of this
    review. Examination of the literature illustrates many examples of uses of chlorophyll
    fluorescence imaging either on its own or in combination with other instruments;
    however, due to space restrictions we have selected and illustrated only a of
    selection of them. The automation and incorporation of in-built algorithms in
    many commercial fluorimeters has led to an increase in their use. However, as
    with any technique, to obtain robust and meaningful results, a suitable protocol
    must be designed first (Scholes and Rolfe, 2009). The requirements for imaging
    are identical to those described above for use with any fluorometer. However,
    below we have outlined additional requirements that need to be followed in order
    to obtain meaningful results. As imaging is working on a relatively large illuminated
    surface, it is critical that the leaf or material of interest is held horizontal
    to the actinic and modulated lights in order to prevent heterogeneous illumination
    over different areas of the leaf. The material should also be held at the correct
    height relative to the light and camera in instruments that rely on in-built light
    calibrations (based on a distance) and do not provide a measurement of PAR at
    the measurement surface. Two elements are important for imaging chlorophyll fluorescence:
    the light source must provide even illumination over the entire surface of the
    imaged sample; and the light source must be capable of providing a saturating
    pulse over the entire imaging area that is of sufficient intensity to close the
    majority of PSII centres and provide a representative Fm′. Saturating pulses of
    ~2000 μmol m–2 s–1 are probably sufficient for dark-adapted Fm but may well be
    too low to provide a true Fm′ under high actinic illumination. Most commercial
    instruments provide between 4000 and 8000 μmol m–2 s–1. If you are working with
    C4 plants, you may need higher saturating pulses. Before purchasing an instrument,
    it is worthwhile determining the instrument’s capabilities in terms of the intensity
    of the saturating pulse and how even the illumination is over the sampling area.
    Another difference between imaging systems and fibre optic systems is how Fo′
    is determined, the value of which is required to calculate quenching parameters.
    Most fibre optic system incorporate LEDs that provide an FR pulse (see above).
    However, many commercial imaging systems rely on banks or panels of LEDs that
    provide the measuring beam and the actinic source, and they tend to be on one
    waveband and are therefore not capable of carrying out an FR pulse. Therefore,
    many imaging system calculate Fo′ using the mathematical algorithm developed by
    Oxborough and Baker (1997a) (Equation 1) The use of this method to estimate Fo′
    in situations where plants are stressed and may experience significant photoinhibition
    has been queried (Maxwell and Johnson, 2000). However, this is not valid, as the
    only requirements for the calculation of Fo′ to be accurate are: (i) that PSII
    centres are open at the point of measuring Fo; (ii) that there is no reversal
    of down-regulation between the measurements of Fo and Fm; and (iii) that there
    is no reversal of photoinhibition between the measurements of Fm′ and Fm (for
    further information, see Lawson et al., 2002; Oxborough, 2004). It is been argued
    that the calculation of Fo′ is actually more accurate than the measured value,
    due to the difficulty in measuring Fo′ (Lawson et al., 2002). Techniques for long-term
    and remote monitoring of chlorophyll fluorescence The field physiologist will
    usually need to relate measurements made over short time scales (seconds/minutes)
    to effects on growth and development that occur over weeks and months, which emphasizes
    the need for good experimental design. This is important for measurements of primary
    productivity. If we consider that the measurement of radiation use efficiency
    (RUE) of a plant canopy is weight of dry matter per unit radiation absorbed by
    the canopy, then to understand how cumulative short-term changes in photosynthesis,
    for example caused by mid-day depression of photosynthesis or canopy development,
    impact RUE we will need to quantify these processes on a daily basis (Black et
    al., 1995; Murchie et al., 1999). ‘Spot’ fluorescence measurements using hand-held
    equipment are quick to take but require high sampling frequency in order to integrate
    with environment flux, and it is difficult to take enough measurements to cover
    such growth periods or season-long periods, especially in inhospitable conditions.
    Limitations of single instruments can be caused by power supply and low numbers
    of measuring sensors. However, there are now devices available on the market that
    have been designed for long-term monitoring of fluorescence using the modulated
    technique described above, for example the Walz Monitoring PAM (Porcar-Castell
    et al., 2008). The design is modular, with a series of measuring heads, each containing
    the optics and light sources required for measurement of key parameters and connected
    physically to a data collection unit or a computer. It is possible to power the
    entire system using solar panels and upload the data remotely, requiring no user
    interaction except in cases where the leaf becomes dislodged. In practice, several
    measuring heads are deployed in vegetation and fixed to a leaf where they will
    remain until the user moves them. The head is capable of measuring F′ and, by
    applying saturating pulses, Fm′ as programmed. During the night period, the values
    of Fm′ and Fo′ become Fm and Fo, respectively. Although this system is limited
    by the inability to measure Fo′ effectively, it has already proved useful in studies
    assessing the annual variation in NPQ in a boreal forest (Porcar-Castell, 2011)
    and assessing changes in NPQ during development of rice canopies (E. Murchie,
    unpublished data). With development of systems that are less expensive and easier
    to deploy, this approach should prove invaluable to the field physiologist looking
    for ‘high-resolution’ data, especially where data can be uploaded remotely. Other
    approaches have analysed the remote sensing of ‘passive’ fluorescence by satellite
    or by platform, exploiting the gaps in the solar spectrum—Fraunhoffer lines—which
    correspond to the wavelengths at which emission of chlorophyll fluorescence occurs
    (Moya et al., 2004; Meroni et al., 2009). This is promising for some applications
    and offers the unique ability to assess photosynthesis continuously over large
    areas, although it clearly has severe limitations in comparison with the accuracy
    and precision of leaf-level measurements. Nevertheless, correlation of key drought-related
    parameters with chlorophyll fluorescence signal could be obtained using a UAV
    (Zarco-Tejada et al., 2012). Such passive techniques have the disadvantage of
    uneven illumination of the field of view and no saturating pulse. Laser-induced
    fluorescence transient (LIFT) is a technique that uses a laser to project an excitation
    beam (e.g. 100mm diameter in current devices) onto a target area of canopy. Fluorescence
    emission is collected using a telescope, filtered, and detected using a large
    photodiode. Data are processed in real time for an immediate, remote measurement
    of PSII yield and electron transport. This technique compares well with that made
    by routine fluorometry, and so far it has been used successfully for ecophysiological
    studies and remote sensing from distances of 5–50 m or more (Ananyev et al., 2005;
    Pieruschka et al., 2008, 2012; Malenovsky et al., 2009) and can provide spatial
    distribution of photosynthetic efficiency. This is a bespoke system, but LIFT
    hardware, protocols for fluorescence induction, fluorescence data analysis, sensing,
    and data processing are described in the literature (e.g. Ananyev et al., 2005).
    Concluding remarks This article provides an update on previous reviews on the
    technique of chlorophyll fluorescence. Inspired by the new applications of this
    technique in crop phenotyping and monitoring, we have covered the aspects of methodology
    the user should be aware of, along with some new and emerging variations. This
    technique lends itself remarkably well to the requirements of crop improvement:
    the rapid assessment with high throughput of measurements which produce data-rich
    results. In particular, we expect that the development of monitoring and remote
    fluorescence techniques should play a key part in the development of automated
    crop phenotyping techniques; so far this has yet to be seen. Common protocols
    for fluorescence analysis These are included to provide the user with some guidance
    for good practice and help to overcome some pitfalls in common situations. See
    Table 1 for a list of formulae. Usually devices will make calculations automatically,
    and the diligent user should compare these with the procedure below and refer
    to Fig. 2. A. Measurement of Fv/Fm (i) Dark-adapt leaf material for a minimum
    of 20min. This can be achieved using the manufacturer’s leaf clips or user-protocol
    (e.g. Pask et al., 2012). The leaf must be kept darkened continuously for the
    entire process of measuring Fv/Fm. (ii) Apply the fluorescence detector with the
    measuring beam off and ensure the reading is zero. (iii) Switch on the measuring
    beam. Check for quenching induced by the measuring beam and adjust the measuring
    beam intensity accordingly. Usually this is only necessary once for a given set
    of plants/plant material. (iv) Measure Fo (v) Apply saturating pulse, typically
    0.8 s at an intensity of at least 4000 μmol m–2 s–1. Attain Fm value. (vi) If
    possible check there is no quenching during the pulse. (vii) Good practice: use
    non-stressed plant material to check Fv/Fm of 0.81–0.83. B. To measure Fq′/Fm′
    (ϕPSII) and NPQ at a known light intensity (i) If following on from (A) above,
    apply the actinic light immediately after measurement of Fv/Fm. (ii) Good practice:
    ensure the material is at steady state. If using ambient light, ensure that the
    light intensity at the leaf surface is known and that it is stable during the
    measurement, in order that results have proper context. From the dark-adapted
    state, this will usually take a minimum of several minutes and should be monitored
    using the F′. From a non-dark adapted state using ambient light, it is advisable
    to wait until the F′ signal is stable. (iii) Apply saturating pulse. (iv) For
    NPQ it is essential to start with dark-adapted material (a measurement of Fo′
    is not required). Following the steps in (A) and (B) above, NPQ is calculated
    as in Table 1. C. To measure Fq′/Fv′ (qP) (i) As in (B), but a measurement or
    calculation of Fo′ is required. (ii) Following the saturating pulse, the actinic
    light is switched off and Fo′ measured after a few seconds. Accuracy is improved
    with the use of an FR light source to oxidize PSI, QA, and electron transport
    intermediates. (iii) An alternative method for Fo′ estimation is possible if the
    Fo has been previously calculated (see text). References Adams WW III Demmig-Adams
    B . 2004. Chlorophyll fluorescence as a tool to monitor plant response to the
    environment. In: Papageorgiou GC Govindjee, eds. Advances in photosynthesis and
    respiration, Vol. 19. Berlin: Springer, 583–604. Google Scholar Google Preview
    WorldCat COPAC  Aldea M Frank TD DeLucia EH . 2006. A method for quantitative
    analysis of spatially variable physiological processes across leaf surfaces. Photosynthesis
    Research90, 161–172. Google Scholar CrossrefPubMed WorldCat   Ananyev G Kolber
    ZS Klimov D Falkowski PG Berry JA Rascher U Martin R Osmond B . 2005. Remote sensing
    of heterogeneity in photosynthetic efficiency, electron transport and dissipation
    of excess light in Populus deltoides stands under ambient and elevated CO2 concentrations,
    and in a tropical forest canopy, using a new laser-induced fluorescence transient
    device. Global Change Biology11, 1195–1206. Google Scholar Crossref WorldCat   Anderson
    JM Chow WS Park YI . 1995. The grand design of photosynthesis: acclimation of
    the photosynthetic apparatus to environmental cues. Photosynthesis Research46,
    129–139. Google Scholar CrossrefPubMed WorldCat   Babar MA Reynolds MP van Ginkel
    M Klatt AR Raun WR Stone ML . 2006. Spectral reflectance indices as a potential
    indirect selection criteria for wheat yield under irrigation. Crop Science46,
    578–588. Google Scholar Crossref WorldCat   Badger MR Fallahi H Kaines S Takahashi
    S . 2009. Chlorophyll fluorescence screening of Arabidopsis thaliana for CO2 sensitive
    photorespiration and photoinhibition mutants. Functional Plant Biology36, 867–873.
    Google Scholar Crossref WorldCat   Baker NR . 2008. Chlorophyll fluorescence:
    a probe of photosynthesis in vivo. Annual Review of Plant Biology59, 89–113. Google
    Scholar CrossrefPubMed WorldCat   Baker NR Oxborough K . 2000. Carotenoids and
    antioxidants protect leaves from light. The Biochemist22, 19–24. Google Scholar
    WorldCat   Baker NR Oxborough K Lawson T Morison JIL . 2001. High resolution imaging
    of photosynthetic activities of tissues, cells and chloroplasts in leaves. Journal
    of Experimental Botany52, 615–621. Google Scholar CrossrefPubMed WorldCat   Baker
    NR Rosenqvist E . 2004. Applications of chlorophyll fluorescence can improve crop
    production strategies: an examination of future possibilities. Journal of Experimental
    Botany55, 1607–1621. Google Scholar CrossrefPubMed WorldCat   Barbagallo RP Oxborough
    K Pallett KE Baker NR . 2003. Rapid noninvasive screening for perturbations of
    metabolism and plant growth using chlorophyll fluorescence imaging. Plant Physiology132,
    485–493. Google Scholar CrossrefPubMed WorldCat   Bauriegel E Giebel A Geyer M
    Schmidt U Herppich WB . 2011. Early detection of Fusarium infection in wheat using
    hyper-spectral imaging. Computers and Electronics in Agriculture75, 304–312. Google
    Scholar Crossref WorldCat   Black CC Tu ZP Counce PA Yao PF Angelov MN . 1995.
    An integration of photosynthetic traits and mechanisms that can increase crop
    photosynthesis and grain production. Photosynthesis Research46, 169–175. Google
    Scholar CrossrefPubMed WorldCat   Bradbury M Baker NR . 1981. Analysis of the
    slow phases of the in vivo chlorophyll fluorescence induction curve—changes in
    the redox state of photosystem-II electron-acceptors and fluorescence emission
    from photosystem-I and photosystem-II. Biochimica et Biophysica Acta635, 542–551.
    Google Scholar CrossrefPubMed WorldCat   Buchanan BB Balmer Y . 2005. Redox regulation:
    a broadening horizon. Annual Review of Plant Biology56, 187–220. Google Scholar
    CrossrefPubMed WorldCat   Butler WL . 1978. Energy distribution in the photochemical
    apparatus of photosynthesis. Annual Review of Plant Physiology29, 457–478. Google
    Scholar Crossref WorldCat   Chaerle L Leinonen I Jones HG Van der Straeten D .
    2007. Monitoring and screening plant populations with combined thermal and chlorophyll
    fluorescence imaging. Journal of Experimental Botany58, 773–784. Google Scholar
    CrossrefPubMed WorldCat   Cheesman JM Clough BF Carter DR Lovelock CE Eong OJ
    Sim RG . 1991. The analysis of photosynthetic performance in leaves under field
    conditions—a case-study using Bruguiera mangroves. Photosynthesis Research29,
    11–22. Google Scholar PubMed WorldCat   Cornic G . 1994. Drought stress and high
    light effects on leaf photosynthesis. In: Baker NR Bowyer JR, eds. Photoinhibition
    of photosynthesis. Oxford: BIOS Scientific Publishers Ltd, 297–313. Google Scholar
    Google Preview WorldCat COPAC  Demmig B Björkman O . 1987. Photon yield of O2
    evolution and chlorophyll fluorescence characteristics at 77 K among vascular
    plants of diverse origins. Planta170, 489–504. Google Scholar CrossrefPubMed WorldCat   Demmig
    Adams B . 1990. Carotenoids and photoprotection in plants. A role for the xanthophyll
    zeaxanthin. Biochimica et Biophysica Acta1020, 1–24. Google Scholar Crossref WorldCat   Demmig-Adams
    B Adams WW Winter K Meyer A Schreiber U Pereira JS Kruger A Czygan FC Lange OL
    . 1989. Photochemical efficiency of photosystem-II, photon yield of O2 evolution,
    photosynthetic capacity, and carotenoid composition during the midday depression
    of net CO2 uptake in Arbutus unedo growing in Portugal. Planta177, 377–387. Google
    Scholar CrossrefPubMed WorldCat   Demmig-Adams B William W Adams I . 2006. Photoprotection
    in an ecological context: the remarkable complexity of thermal energy dissipation.
    New Phytologist172, 11–21. Google Scholar CrossrefPubMed WorldCat   Eguchi A Konishi
    A Hosoi F Omasa K . 2008. Three-dimensional chlorophyll fluorescence imaging for
    detecting effects of herbicide on a whole plant. In: Allen JF Gantt E Colbeck
    JH Osmond B, eds. Photosynthesis. Energy from the sun. 14th International Congress
    on Photosynthesis. Berlin: Springer, 577–580. Google Scholar Google Preview WorldCat
    COPAC  Ehlert B Hincha DK . 2008. Chlorophyll fluorescence imaging accurately
    quantifies freezing damage and cold acclimation responses in Arabidopsis leaves.
    Plant Methods4, 12. Google Scholar CrossrefPubMed WorldCat   Flexas J Bota J Escalona
    JM Sampol B Medrano H . 2002. Effects of drought on photosynthesis in grapevines
    under field conditions: an evaluation of stomatal and mesophyll limitations. Functional
    Plant Biology29, 461–467. Google Scholar Crossref WorldCat   Furbank RT von Caemmerer
    S Sheehy J Edwards G . 2009. C-4 rice: a challenge for plant phenomics. Functional
    Plant Biology36, 845–856. Google Scholar Crossref WorldCat   Genty B Briantais
    JM Baker NR . 1989. The relationship between the quantum yield of photosynthetic
    electron-transport and quenching of chlorophyll fluorescence. Biochimica et Biophysica
    Acta990, 87–92. Google Scholar Crossref WorldCat   Genty B Goulas Y Dimon B Peltier
    G Briantais JM Moya I . 1992. Modulation of efficiency of primary conversion in
    leaves, mechanisms involved at PS2. In: Murata N, ed. Research in photosynthesis,
    Vol. IV: Proceedings of IXth International Congress on Photosynthesis. Nagoya,
    JapanAugust 30–September 4, 603–610. Google Scholar Google Preview WorldCat COPAC  Genty
    B Wonders J Baker NR . 1990. Non-photochemical quenching of Fo in leaves is emission
    wavelength dependent—consequences for quenching analysis and its interpretation.
    Photosynthesis Research26, 133–139. Google Scholar CrossrefPubMed WorldCat   Harbinson
    J Prinzenberg AE Kruijer W Aarts MGM . 2012. High throughput screening with chlorophyll
    fluorescence imaging and its use in crop improvement. Current Opinion in Biotechnology23,
    221–226. Google Scholar CrossrefPubMed WorldCat   Horton P Hague A . 1988. Studies
    on the induction of chlorophyll fluorescence in isolated barley protoplasts. 4.
    Resolution of non-photochemical quenching. Biochimica et Biophysica Acta932, 107–115.
    Google Scholar Crossref WorldCat   Horton P Johnson MP Perez-Bueno ML Kiss AZ
    Ruban AV . 2008. Photosynthetic acclimation: does the dynamic structure and macro-organisation
    of photosystem II in higher plant grana membranes regulate light harvesting states?FEBS
    Journal275, 1069–1079. Google Scholar CrossrefPubMed WorldCat   Horton P Ruban
    AV Walters RG . 1996. Regulation of light harvesting in green plants. Annual Review
    of Plant Physiology and Plant Molecular Biology47, 655–684. Google Scholar CrossrefPubMed
    WorldCat   Huner NPA Maxwell DP Gray GR Savitch LV Krol M Ivanov AG Falk S . 1996.
    Sensing environmental temperature change through imbalances between energy supply
    and energy consumption: redox state of photosystem II. Physiologia Plantarum98,
    358–364. Google Scholar Crossref WorldCat   Huner NPA Oquist G Sarhan F . 1998.
    Energy balance and acclimation to light and cold. Trends in Plant Science3, 224–230.
    Google Scholar Crossref WorldCat   Jin Z Tian T Naeem MS Jilani G Zhang F Zhou
    W . 2011. Chlorophyll fluorescence responses to application of new herbicide ZJ0273
    in winter oilseed rape species. International Journal of Agriculture and Biology13,
    43–50. Google Scholar WorldCat   Johnson GN . 2011. Physiology of PSI cyclic electron
    transport in higher plants. Biochimica et Biophysica Acta1807, 384–389. Google
    Scholar CrossrefPubMed WorldCat   Kiss AZ Ruban AV Horton P . 2008. The PsbS protein
    controls the organization of the photosystem II antenna in higher plant thylakoid
    membranes. Journal of Biological Chemistry283, 3972–3978. Google Scholar CrossrefPubMed
    WorldCat   Klughammer C Schreiber U . 1994. An improved method, using saturating
    light-pulses, for the determination of photosystem I quantum yield via p700+ absorbency
    changes at 830 nm. Planta192, 261–268. Google Scholar Crossref WorldCat   Kramer
    DM Johnson G Kiirats O Edwards GE . 2004. New fluorescence parameters for the
    determination of Q(A) redox state and excitation energy fluxes. Photosynthesis
    Research79, 209–218. Google Scholar CrossrefPubMed WorldCat   Krause GH Vernotte
    C Briantais JM . 1982. Photo induced quenching of chlorophyll fluorescence in
    intact chloroplasts and algae resolution into 2 components. Biochimica et Biophysica
    Acta679, 116–124. Google Scholar Crossref WorldCat   Krause GH Weis E . 1991.
    Chlorophyll fluorescence and photosynthesis—the basics. Annual Review of Plant
    Physiology and Plant Molecular Biology42, 313–349. Google Scholar Crossref WorldCat   Lawson
    T . 2009. Guard cell photosynthesis and stomatal function. New Phytologist181,
    13–34. Google Scholar CrossrefPubMed WorldCat   Lawson T Kramer DM Raines CA .
    2012. Improving yield by exploiting mechanisms underlying natural variation of
    photosynthesis. Current Opinion in Biotechnology23, 215–220. Google Scholar CrossrefPubMed
    WorldCat   Lawson T Morison JIL . 2006. Visualising patterns of CO2 diffusion
    in leaves. New Phytologist169, 641–643. Google Scholar CrossrefPubMed WorldCat   Lawson
    T Oxborough K Morison JIL Baker NR . 2002. Responses of photosynthetic electron
    transport in stomatal guard cells and mesophyll cells in intact leaves to light,
    CO2 and humidity. Plant Physiology128, 52–62. Google Scholar CrossrefPubMed WorldCat   Lawson
    T Oxborough K Morison JIL Baker NR . 2003. The response of guard cell photosynthesis
    to CO2, O2, light and water stress in a range of species are similar. Journal
    of Experimental Botany54, 1743–1752. Google Scholar CrossrefPubMed WorldCat   Leipner
    J Oxborough K Baker NR . 2001. Primary sites of ozone-induced perturbations of
    photosynthesis in leaves: identification and characterization in Phaseolus vulgaris
    using high resolution chlorophyll fluorescence imaging. Journal of Experimental
    Botany52, 1689–1696. Google Scholar PubMed WorldCat   Li XP Muller-Moule P Gilmore
    AM Niyogi KK . 2002. PsbS-dependent enhancement of feedback de-excitation protects
    photosystem II from photoinhibition. Proceedings of the National Academy of Sciences,
    USA99, 15222–15227. Google Scholar Crossref WorldCat   Logan BA Adams WW Demmig-Adams
    B . 2007. Viewpoint: avoiding common pitfalls of chlorophyll fluorescence analysis
    under field conditions. Functional Plant Biology34, 853–859. Google Scholar Crossref
    WorldCat   Long SP Humphries S Falkowski PG . 1994. Photoinhibition of photosynthesis
    in nature. Annual Review of Plant Physiology and Plant Molecular Biology45, 633–662.
    Google Scholar Crossref WorldCat   Malenovsky Z Mishra KB Zemek F Rascher U Nedbal
    L . 2009. Scientific and technical challenges in remote sensing of plant canopy
    reflectance and fluorescence. Journal of Experimental Botany60, 2987–3004. Google
    Scholar CrossrefPubMed WorldCat   Mauromicale G Ierna A Marchese M . 2006. Chlorophyll
    fluorescence and chlorophyll content in field-grown potato as affected by nitrogen
    supply, genotype, and plant age. Photosynthetica44, 76–82. Google Scholar Crossref
    WorldCat   Maxwell C Griffiths H Young AJ . 1994. Photosynthetic acclimation to
    light regime and water-stress by the C-3-CAM epiphyte Guzmania monostachia—gas-exchange
    characteristics, photochemical efficiency and the xanthophyll cycle. Functional
    Ecology8, 746–754. Google Scholar Crossref WorldCat   Maxwell K Johnson GN . 2000.
    Chlorophyll fluorescence—a practical guide. Journal of Experimental Botany51,
    659–668. Google Scholar PubMed WorldCat   McElrone AJ Hamilton JG Krafnick J Aldea
    M Knepp RG DeLuica EH . 2010. Combined effects of elevated CO2 and natural climatic
    variation on leaf spot diseases of redbud and sweetgum trees. Environmental Pollution158,
    108–114. Google Scholar CrossrefPubMed WorldCat   Meroni M Rossini M Guanter L
    Alonso L Rascher U Colombo R Moreno J . 2009. Remote sensing of solar-induced
    chlorophyll fluorescence: review of methods and applications. Remote Sensing of
    Environment113, 2037–2051. Google Scholar Crossref WorldCat   Montes JM Melchinger
    AE Reif JC . 2007. Novel throughput phenotyping platforms in plant genetic studies.
    Trends in Plant Science12, 433–436. Google Scholar CrossrefPubMed WorldCat   Morison
    JIL Gallouët E Cornic G Herbin R Baker NR . 2005. Lateral diffusion of CO2 in
    leaves is not sufficient to support photosynthesis. Plant Physiology139, 254–266.
    Google Scholar CrossrefPubMed WorldCat   Morison JIL Lawson T . 2007. Does lateral
    gas diffusion in leaves matter?Plant, Cell and Environment30, 1072–1085. Google
    Scholar Crossref WorldCat   Morison JIL Lawson T Cornic G . 2007. Lateral CO2
    diffusion inside dicotyledonous leaves can be substantial: quantification in different
    light intensities. Plant Physiology145, 680–690. Google Scholar CrossrefPubMed
    WorldCat   Moya I Camenen L Evail S Goulas Cerovic ZG Latouche G Flexas J Ounis
    A . 2004. A new instrument for passive remote sensing 1. Measurements of sunlight-induced
    chlorophyll fluorescence. Remote Sensing of the Environment91, 186–197. Google
    Scholar Crossref WorldCat   Murchie EH Chen YZ Hubbart S Peng SB Horton P . 1999.
    Interactions between senescence and leaf orientation determine in situ patterns
    of photosynthesis and photoinhibition in field-grown rice. Plant Physiology119,
    553–563. Google Scholar CrossrefPubMed WorldCat   Murchie E Horton P . 2007. Toward
    C4 rice: learning from acclimation of photosynthesisin the C3 leaf. In: Sheehy
    JE Mitchell PL Hardy B, eds. Charting pathways to C4 rice. Los Banos, Philippines:
    International Rice Research Institute, 333–351. Google Scholar Google Preview
    WorldCat COPAC  Murchie EH Hubbart S Chen YZ Peng SB Horton P . 2002. Acclimation
    of rice photosynthesis to irradiance under field conditions. Plant Physiology130,
    1999–2010. Google Scholar CrossrefPubMed WorldCat   Murchie EH Niyogi KK . 2011.
    Manipulation of photoprotection to improve plant photosynthesis. Plant Physiology155,
    86–92. Google Scholar CrossrefPubMed WorldCat   Murchie EH Pinto M Horton P .
    2009. Agriculture and the new challenges for photosynthesis research. New Phytologist181,
    532–552. Google Scholar CrossrefPubMed WorldCat   Nandha B Finazzi G Joliot P
    Hald S Johnson GN . 2007. The role of PGR5 in the redox poising of photosynthetic
    electron transport. Biochimica et Biophysica Acta1767, 1252–1259. Google Scholar
    CrossrefPubMed WorldCat   Oxborough K . 2004. Imaging of chlorophyll a fluorescence:
    theoretical and practical aspects of an emerging technique for the monitoring
    of photosynthetic performance. Journal of Experimental Botany55, 1195–1205. Google
    Scholar CrossrefPubMed WorldCat   Oxborough K Baker NR . 1997. Resolving chlorophyll
    a fluorescence images of photosynthetic efficiency into photochemical and non-photochemical
    components—calculation of qP and Fv′/Fm′ without measuring Fo′. Photosynthesis
    Research54, 135–142. Google Scholar Crossref WorldCat   Oxborough K Baker NR .
    1997. An instrument capable of imaging chlorophyll alpha fluorescence from intact
    leaves at very low irradiance and at cellular and subcellular levels of organization.
    Plant, Cell and Environment20, 1473–1483. Google Scholar Crossref WorldCat   Pask
    AJD Pietragalla J Mullan Reynolds MP . eds. 2012. Physiological breeding II: a
    field guide to wheat phenotyping. Mexico, DF: International Wheat and Maize Improvement
    Centre (CIMMYT). Google Scholar Google Preview WorldCat COPAC  Peltier G Cournac
    L . 2002. Chlororespiration. Annual Review of Plant Biology53, 523–550. Google
    Scholar CrossrefPubMed WorldCat   Pfündel E . 1998. Estimating the contribution
    of Photosystem I to total leaf chlorophyll fluorescence. Photosynthesis Research56,
    185–195. Google Scholar Crossref WorldCat   Pieruschka R Klimov D Berry JA Osmond
    CB Rascher U Kolber ZS . 2012. Remote chlorophyll fluorescence measurements with
    the laser-induced fluorescence transient approach. Methods in Molecular Biology918,
    51–59. Google Scholar PubMed WorldCat   Pieruschka R Schurr U Jahnke S . 2005.
    Lateral gas diffusion inside leaves. Journal of Experimental Botany56, 857–864.
    Google Scholar CrossrefPubMed WorldCat   Pieruschka R Schurr U Jensen M Wolff
    WF Jahnke S . 2006. Lateral diffusion of CO2 from shaded to illuminated leaf parts
    affects photosynthesis inside homobaric leaves. New Phytologist169, 779–787. Google
    Scholar CrossrefPubMed WorldCat   Porcar-Castell A . 2011. A high-resolution portrait
    of the annual dynamics of photochemical and non-photochemical quenching in needles
    of Pinus sylvestris. Physiologia Plantarum143, 139–153. Google Scholar CrossrefPubMed
    WorldCat   Porcar-Castell A Pfuendel E Korhonen JFJ Juurola E . 2008. A new monitoring
    PAM fluorometer (MONI-PAM) to study the short- and long-term acclimation of photosystem
    II in field conditions. Photosynthesis Research96, 173–179. Google Scholar CrossrefPubMed
    WorldCat   Quick WP Horton P . 1984. Studies on the induction of chlorophyll fluorescence
    in barley protoplasts. 1. Factors affecting the observation of oscillations in
    the yield of chlorophyll fluorescence and the rate of oxygen evolution. Proceedings
    of the Royal Society B: Biological Sciences220, 361–370. Google Scholar Crossref
    WorldCat   Rahbarian R Khavari-Nejad R Ganjeali A Bagheri A Najafi F . 2011. Drough
    stress effects on photosynthesis, chlorophyll fluorescence and water relations
    in tolerant and susceptible chickpea (Cicer areietinum L.) genotypes. Acta Biologica
    Cracoviensia series Botanica53/1, 47–56. Google Scholar WorldCat   Ruban AV Johnson
    MP Duffy CDP . 2012. The photoprotective molecular switch in the photosystem II
    antenna. Biochimica et Biophysica Acta1817, 167–181. Google Scholar CrossrefPubMed
    WorldCat   Ruban AV Murchie EH . 2012. Assessing the photoprotective effectiveness
    of non-photochemical chlorophyll fluorescence quenching: a new approach. Biochimica
    et Biophysica Acta1817, 977–982. Google Scholar CrossrefPubMed WorldCat   Scholes
    JD Rolfe SA . 2009. Chlorophyll fluorescence imaging as tool for understanding
    the impact of fungal diseases on plant performance. Functional Plant Biology36,
    880–892. Google Scholar Crossref WorldCat   Schreiber U Schliwa U Bilger W . 1986.
    Continuous recording of photochemical and nonphotochemical chlorophyll fluorescence
    quenching with a new type of modulation fluorometer. Photosynthesis Research10,
    51–62. Google Scholar CrossrefPubMed WorldCat   Strasser RJ Tsimilli-Michael M
    Srivastava A . 2004. Analysis of the chlorophyll a fluorescence transient. In:
    Papageorgiou GC Govindjee, eds. Advances in photosynthesis and respiration , Vol.
    19. Berlin: Springer, 321–362. Google Scholar Google Preview WorldCat COPAC  Sun
    X Fu T Chen N Guo J Ma J Zou M Lu C Zhang L . 2010. The stromal chloroplast Deg7
    protease participates in the repair of photosystem II after photoinhibition in
    Arabidopsis. Plant Physiology152, 1263–1273. Google Scholar CrossrefPubMed WorldCat   Takahashi
    S Murata N . 2008. How do environmental stresses accelerate photoinhibition?Trends
    in Plant Science13, 178–182. Google Scholar CrossrefPubMed WorldCat   Tang JY
    Zielinski RE Zangerl AR Croft Arm Bernebaum Mr DeLuica EH . 2006. The differential
    effects of herbivory by first and fourth instars of Trichoplusia ni (Lepidoptera:
    Noctuidae) on photosynthesis in Arabidopsis thaliana. Journal of Experimental
    Botany57, 527–536. Google Scholar CrossrefPubMed WorldCat   Vernotte C Etienne
    AL Briantais JM . 1979. Quenching of photosystem-II chlorophyll fluorescence by
    the plastoquinone pool. Biochimica et Biophysica Acta545, 519–527. Google Scholar
    CrossrefPubMed WorldCat   Walters RG . 2005. Towards an understanding of photosynthetic
    acclimation. Journal of Experimental Botany56, 435–447. Google Scholar CrossrefPubMed
    WorldCat   Walters RG Horton P . 1991. Resolution of components of nonphotochemical
    chlorophyll fluorescence quenching in barley leaves. Photosynthesis Research27,
    121–133. Google Scholar CrossrefPubMed WorldCat   Wingler A Quick WP Bungard RA
    Bailey KJ Lea PJ Leegood RC . 1999. The role of photorespiration during drought
    stress: an analysis utilizing barley mutants with reduced activities of photorespiratory
    enzymes. Plant, Cell and Environment22, 361–373. Google Scholar Crossref WorldCat   Yamamoto
    HY Bugos RC Hieber AD . 1999. Biochemistry and molecular biology of the zanthophyll
    cycle. In: Frank HA Young AJK Britton G Cogdell RJ, eds. The photochemistry of
    carotenoids. Dordrecht: The Netherlands: Kluwer Academic Publishers, 293–303.
    Google Scholar Google Preview WorldCat COPAC  Yokthongwattana KAM Melis A . 2006.
    Photoinhibition and recovery in oxygenic photosynthesis: mechanism of a photosystem
    II damage and repair cycle. In: Demmig-Adams B Adams WIII Mattoo A, eds. Photoprotection,
    photoinhibition, gene regulation and environment. Dordrecht, The Netherlands:
    Springer, 175–191. Google Scholar Google Preview WorldCat COPAC  Zarco-Tejada
    PJ Gonzalez-Dugo V Berni JAJ . 2012. Fluorescence, temperature and narrow-band
    indices acquired from a UAV platform for water stress detection using a micro-hyperspectral
    imager and a thermal camera. Remote Sensing of Environment117, 322–337. Google
    Scholar Crossref WorldCat   © The Author [2013]. Published by Oxford University
    Press on behalf of the Society for Experimental Biology. All rights reserved.
    For permissions, please email: journals.permissions@oup.com Comments 0 Comments
    Add comment Advertisement CITATIONS 1.4k VIEWS 106,270 ALTMETRIC More metrics
    information Email alerts Article activity alert Advance article alerts New issue
    alert Receive exclusive offers and updates from Oxford Academic Recommended Chlorophyll
    fluorescence—a practical guide Kate Maxwell et al., Journal of Experimental Botany,
    2000 Phenotyping photosynthesis: yes we can Samuel H Taylor, Journal of Experimental
    Botany, 2024 Advances in field-based high-throughput photosynthetic phenotyping
    Peng Fu et al., Journal of Experimental Botany, 2022 The biogenesis and maintenance
    of photosystem II: recent advances and current challenges Josef Komenda et al.,
    The Plant Cell Effects on Photosystem II Function, Photoinhibition, and Plant
    Performance of the Spontaneous Mutation of Serine-264 in the Photosystem II Reaction
    Center D1 Protein in Triazine-Resistant Brassica napus L C. Sundby et al., Plant
    Phyisol, 1993 Atomic Force Microscope Based Indentation Techniques and Their Applications
    WANG Xiaomeng et al., Chinese Journal of High Pressure Physics Powered by Citing
    articles via Web of Science (1224) Google Scholar Latest Most Read Most Cited
    Nitric oxide, energy and redox-dependent responses to hypoxia Modelling metabolic
    fluxes of tomato stems reveals that nitrogen shapes central metabolism for defence
    against Botrytis cinerea Genome-wide association studies and transcriptomics reveal
    mechanisms explaining the diversity of wheat root responses to nutrient availability
    Aintegumenta And Redundant Aintegumenta-Like6 Are Required For Bract Outgrowth
    In Arabidopsis Molecular and genetic regulation of petal number variation in plants
    More from Oxford Academic Biological Sciences Plant Sciences and Forestry Science
    and Mathematics Books Journals About Journal of Experimental Botany Editorial
    Board Author Guidelines Contact Us Facebook Twitter YouTube Purchase Recommend
    to your Library Advertising and Corporate Services Journals Career Network Online
    ISSN 1460-2431 Print ISSN 0022-0957 Copyright © 2024 Society for Experimental
    Biology About Oxford Academic Publish journals with us University press partners
    What we publish New features  Authoring Open access Purchasing Institutional account
    management Rights and permissions Get help with access Accessibility Contact us
    Advertising Media enquiries Oxford University Press News Oxford Languages University
    of Oxford Oxford University Press is a department of the University of Oxford.
    It furthers the University''s objective of excellence in research, scholarship,
    and education by publishing worldwide Copyright © 2024 Oxford University Press
    Cookie settings Cookie policy Privacy policy Legal notice Oxford University Press
    uses cookies to enhance your experience on our website. By selecting ‘accept all’
    you are agreeing to our use of cookies. You can change your cookie settings at
    any time. More information can be found in our Cookie Policy. Cookie settings
    Accept all'
  inline_citation: '>'
  journal: Journal of experimental botany
  limitations: '>'
  pdf_link: https://academic.oup.com/jxb/article-pdf/64/13/3983/18043167/ert208.pdf
  publication_year: 2013
  relevance_score1: 0
  relevance_score2: 0
  title: 'Chlorophyll fluorescence analysis: a guide to good practice and understanding
    some new applications'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.3390/s18082674
  analysis: '>'
  authors:
  - Κωνσταντίνος Λιάκος
  - Patrizia Busato
  - Dimitrios Moshou
  - Simon Pearson
  - Dionysis Bochtis
  citation_count: 1386
  full_citation: '>'
  full_text: ">\nsensors\nReview\nMachine Learning in Agriculture: A Review\nKonstantinos\
    \ G. Liakos 1, Patrizia Busato 2, Dimitrios Moshou 1,3, Simon Pearson 4 ID\nand\
    \ Dionysis Bochtis 1,* ID\n1\nInstitute for Bio-Economy and Agri-Technology (IBO),\
    \ Centre of Research and\nTechnology—Hellas (CERTH), 6th km Charilaou-Thermi Rd,\
    \ GR 57001 Thessaloniki, Greece;\nk.liakos@certh.gr (K.G.L.); dmoshou@auth.gr\
    \ (D.M.)\n2\nDepartment of Agriculture, Forestry and Food Sciences (DISAFA), Faculty\
    \ of Agriculture,\nUniversity of Turin, Largo Braccini 2, 10095 Grugliasco, Italy;\
    \ patrizia.busato@unito.it\n3\nAgricultural Engineering Laboratory, Faculty of\
    \ Agriculture, Aristotle University of Thessaloniki,\n54124 Thessaloniki, Greece\n\
    4\nLincoln Institute for Agri-food Technology (LIAT), University of Lincoln, Brayford\
    \ Way, Brayford Pool,\nLincoln LN6 7TS, UK, spearson@lincoln.ac.uk\n*\nCorrespondence:\
    \ d.bochtis@certh.gr; Tel.: +30-2310-498210\nReceived: 27 June 2018; Accepted:\
    \ 7 August 2018; Published: 14 August 2018\n\x01\x02\x03\x01\x04\x05\x06\a\b\x01\
    \n\x01\x02\x03\x04\x05\x06\a\nAbstract: Machine learning has emerged with big\
    \ data technologies and high-performance computing\nto create new opportunities\
    \ for data intensive science in the multi-disciplinary agri-technologies\ndomain.\
    \ In this paper, we present a comprehensive review of research dedicated to applications\n\
    of machine learning in agricultural production systems. The works analyzed were\
    \ categorized in\n(a) crop management, including applications on yield prediction,\
    \ disease detection, weed detection\ncrop quality, and species recognition; (b)\
    \ livestock management, including applications on animal\nwelfare and livestock\
    \ production; (c) water management; and (d) soil management. The ﬁltering\nand\
    \ classiﬁcation of the presented articles demonstrate how agriculture will beneﬁt\
    \ from machine\nlearning technologies. By applying machine learning to sensor\
    \ data, farm management systems are\nevolving into real time artiﬁcial intelligence\
    \ enabled programs that provide rich recommendations\nand insights for farmer\
    \ decision support and action.\nKeywords: crop management; water management; soil\
    \ management; livestock management; artiﬁcial\nintelligence; planning; precision\
    \ agriculture\n1. Introduction\nAgriculture plays a critical role in the global\
    \ economy. Pressure on the agricultural system will\nincrease with the continuing\
    \ expansion of the human population. Agri-technology and precision\nfarming, now\
    \ also termed digital agriculture, have arisen as new scientiﬁc ﬁelds that use\
    \ data\nintense approaches to drive agricultural productivity while minimizing\
    \ its environmental impact.\nThe data generated in modern agricultural operations\
    \ is provided by a variety of different sensors that\nenable a better understanding\
    \ of the operational environment (an interaction of dynamic crop, soil,\nand weather\
    \ conditions) and the operation itself (machinery data), leading to more accurate\
    \ and faster\ndecision making.\nMachine learning (ML) has emerged together with\
    \ big data technologies and high-performance\ncomputing to create new opportunities\
    \ to unravel, quantify, and understand data intensive processes\nin agricultural\
    \ operational environments. Among other deﬁnitions, ML is deﬁned as the scientiﬁc\
    \ ﬁeld\nthat gives machines the ability to learn without being strictly programmed\
    \ [1]. Year by year, ML applies\nin more and more scientiﬁc ﬁelds including, for\
    \ example, bioinformatics [2,3], biochemistry [4,5],\nSensors 2018, 18, 2674;\
    \ doi:10.3390/s18082674\nwww.mdpi.com/journal/sensors\nSensors 2018, 18, 2674\n\
    2 of 29\nmedicine [6–8], meteorology [9–11], economic sciences [12–14], robotics\
    \ [15,16], aquaculture [17,18],\nand food security [19,20], and climatology [21].\n\
    In this paper, we present a comprehensive review of the application of ML in agriculture.\n\
    A number of relevant papers are presented that emphasise key and unique features\
    \ of popular\nML models. The structure of the present work is as follows: the\
    \ ML terminology, deﬁnition, learning\ntasks, and analysis are initially given\
    \ in Section 2, along with the most popular learning models and\nalgorithms. Section\
    \ 3 presents the implemented methodology for the collection and categorization\
    \ of\nthe presented works. Finally, in Section 4, the advantages derived from\
    \ the implementation of ML in\nagri-technology are listed, as well as the future\
    \ expectations in the domain.\nBecause of the large number of abbreviations used\
    \ in the relative scientiﬁc works, Tables 1–4 list\nthe abbreviations that appear\
    \ in this work, categorized to ML models, algorithms, statistical measures,\n\
    and general abbreviations, respectively.\nTable 1. Abbreviations for machine learning\
    \ models.\nAbbreviation\nModel\nANNs\nartiﬁcial neural networks\nBM\nbayesian\
    \ models\nDL\ndeep learning\nDR\ndimensionality reduction\nDT\ndecision trees\n\
    EL\nensemble learning\nIBM\ninstance based models\nSVMs\nsupport vector machines\n\
    Table 2. Abbreviations for machine learning algorithms.\nAbbreviation\nAlgorithm\n\
    ANFIS\nadaptive-neuro fuzzy inference systems\nBagging\nbootstrap aggregating\n\
    BBN\nbayesian belief network\nBN\nbayesian network\nBPN\nback-propagation network\n\
    CART\nclassiﬁcation and regression trees\nCHAID\nchi-square automatic interaction\
    \ detector\nCNNs\nconvolutional neural networks\nCP\ncounter propagation\nDBM\n\
    deep boltzmann machine\nDBN\ndeep belief network\nDNN\ndeep neural networks\n\
    ELMs\nextreme learning machines\nEM\nexpectation maximisation\nENNs\nensemble\
    \ neural networks\nGNB\ngaussian naive bayes\nGRNN\ngeneralized regression neural\
    \ network\nKNN\nk-nearest neighbor\nLDA\nlinear discriminant analysis\nLS-SVM\n\
    least squares-support vector machine\nLVQ\nlearning vector quantization\nLWL\n\
    locally weighted learning\nMARS\nmultivariate adaptive regression splines\nMLP\n\
    multi-layer perceptron\nMLR\nmultiple linear regression\nMOG\nmixture of gaussians\n\
    OLSR\nordinary least squares regression\nSensors 2018, 18, 2674\n3 of 29\nTable\
    \ 2. Cont.\nAbbreviation\nAlgorithm\nPCA\nprincipal component analysis\nPLSR\n\
    partial least squares regression\nRBFN\nradial basis function networks\nRF\nrandom\
    \ forest\nSaE-ELM\nself adaptive evolutionary-extreme learning machine\nSKNs\n\
    supervised kohonen networks\nSOMs\nself-organising maps\nSPA-SVM\nsuccessive projection\
    \ algorithm-support vector machine\nSVR\nsupport vector regression\nTable 3. Abbreviations\
    \ for statistical measures for the validation of machine learning algorithms.\n\
    Abbreviation\nMeasure\nAPE\naverage prediction error\nMABE\nmean absolute bias\
    \ error\nMAE\nmean absolute error\nMAPE\nmean absolute percentage error\nMPE\n\
    mean percentage error\nNS\nnash-sutcliffe coefﬁcient\nR\nradius\nR2\ncoefﬁcient\
    \ of determination\nRMSE\nroot mean squared error\nRMSEP\nroot mean square error\
    \ of prediction\nRPD\nrelative percentage difference\nRRMSE\naverage relative\
    \ root mean square error\nTable 4. General abbreviations.\nAbbreviation\nAUS\n\
    aircraft unmanned system\nCd\ncadmium\nFBG\nﬁber bragg grating\nHSV\nhue saturation\
    \ value color space\nK\npotassium\nMC\nmoisture content\nMg\nmagnesium\nML\nmachine\
    \ learning\nNDVI\nnormalized difference vegetation index\nNIR\nnear infrared\n\
    OC\norganic carbon\nRb\nrubidium\nRGB\nred green blue\nTN\ntotal nitrogen\nUAV\n\
    unmanned aerial vehicle\nVIS-NIR\nvisible-near infrared\n2. An Overview on Machine\
    \ Learning\n2.1. Machine Learning Terminology and Deﬁnitions\nTypically, ML methodologies\
    \ involves a learning process with the objective to learn from\n“experience” (training\
    \ data) to perform a task. Data in ML consists of a set of examples. Usually,\n\
    an individual example is described by a set of attributes, also known as features\
    \ or variables. A feature\ncan be nominal (enumeration), binary (i.e., 0 or 1),\
    \ ordinal (e.g., A+ or B−), or numeric (integer, real\nSensors 2018, 18, 2674\n\
    4 of 29\nnumber, etc.). The performance of the ML model in a speciﬁc task is measured\
    \ by a performance\nmetric that is improved with experience over time. To calculate\
    \ the performance of ML models and\nalgorithms, various statistical and mathematical\
    \ models are used. After the end of the learning process,\nthe trained model can\
    \ be used to classify, predict, or cluster new examples (testing data) using the\n\
    experience obtained during the training process. Figure 1 shows a typical ML approach.\n\
    Sensors 2018, 18, x FOR PEER REVIEW   \n4 of 31 \n \nmetric that is improved with experience over time. To calculate the performance of ML models and \n\
    algorithms,  various  statistical  and  mathematical  models  are  used.  After \
    \ the  end  of  the  learning \nprocess, the trained model can be used to classify, predict, or cluster new examples (testing data) \n\
    using the experience obtained during the training process. Figure 1 shows a typical ML approach. \n\
    \ \nFigure 1. A typical machine learning approach. \nML tasks are typically classified into different broad categories depending on the learning type \n\
    (supervised/unsupervised), \nlearning \nmodels \n(classification, \nregression, \n\
    clustering, \nand \ndimensionality reduction), or the learning models employed to implement the selected task. \n\
    2.2. Tasks of Learning \nML tasks are classified into two main categories, that is, supervised and unsupervised learning, \n\
    depending on the learning signal of the learning system. In supervised learning, data are presented \n\
    with example inputs and the corresponding outputs, and the objective is to construct a general rule \n\
    that maps inputs to outputs. In some cases, inputs can be only partially available with some of the \n\
    target  outputs  missing  or  given  only  as  feedback  to  the  actions  in \
    \ a  dynamic  environment \n(reinforcement learning). In the supervised setting, the acquired expertise (trained model) is used to \n\
    predict the missing outputs (labels) for the test data. In unsupervised learning, however, there is no \n\
    distinction between training and test sets with data being unlabeled. The learner processes input data \n\
    with the goal of discovering hidden patterns. \n2.3. Analysis of Learning \nDimensionality reduction (DR) is an analysis that is executed in both families of supervised and \n\
    unsupervised  learning  types,  with  the  aim  of  providing  a  more  compact, \
    \ lower‐dimensional \nrepresentation of a dataset to preserve as much information as possible from the original data. It is \n\
    usually performed prior to applying a classification or regression model in order to avoid the effects \n\
    of dimensionality. Some of the most common DR algorithms are the following: (i) principal component \n\
    analysis [22], (ii) partial least squares regression [23], and (iii) linear discriminant analysis [24]. \n\
    2.4. Learning Models \nThe presentation of the learning models in ML is limited to the ones that have been implemented \n\
    in works presented in this review. \n2.4.1. Regression \nRegression constitutes a supervised learning model, which aims to provide the prediction of an \n\
    output variable according to the input variables, which are known. Most known algorithms include \n\
    linear regression and logistic regression [25], as well as stepwise regression [26]. Also, more complex \n\
    regression  algorithms  have  been  developed,  such  as  ordinary  least  squares \
    \ regression  [27], \nmultivariate  adaptive  regression  splines  [28],  multiple \
    \ linear  regression,  cubist  [29],  and  locally \nestimated scatterplot smoothing [30]. \n\
    Figure 1. A typical machine learning approach.\nML tasks are typically classiﬁed\
    \ into different broad categories depending on the learning type\n(supervised/unsupervised),\
    \ learning models (classiﬁcation, regression, clustering, and dimensionality\n\
    reduction), or the learning models employed to implement the selected task.\n\
    2.2. Tasks of Learning\nML tasks are classiﬁed into two main categories, that\
    \ is, supervised and unsupervised learning,\ndepending on the learning signal\
    \ of the learning system. In supervised learning, data are presented\nwith example\
    \ inputs and the corresponding outputs, and the objective is to construct a general\
    \ rule that\nmaps inputs to outputs. In some cases, inputs can be only partially\
    \ available with some of the target\noutputs missing or given only as feedback\
    \ to the actions in a dynamic environment (reinforcement\nlearning). In the supervised\
    \ setting, the acquired expertise (trained model) is used to predict the\nmissing\
    \ outputs (labels) for the test data. In unsupervised learning, however, there\
    \ is no distinction\nbetween training and test sets with data being unlabeled.\
    \ The learner processes input data with the\ngoal of discovering hidden patterns.\n\
    2.3. Analysis of Learning\nDimensionality reduction (DR) is an analysis that is\
    \ executed in both families of supervised\nand unsupervised learning types, with\
    \ the aim of providing a more compact, lower-dimensional\nrepresentation of a\
    \ dataset to preserve as much information as possible from the original data.\
    \ It is\nusually performed prior to applying a classiﬁcation or regression model\
    \ in order to avoid the effects of\ndimensionality. Some of the most common DR\
    \ algorithms are the following: (i) principal component\nanalysis [22], (ii) partial\
    \ least squares regression [23], and (iii) linear discriminant analysis [24].\n\
    2.4. Learning Models\nThe presentation of the learning models in ML is limited\
    \ to the ones that have been implemented\nin works presented in this review.\n\
    2.4.1. Regression\nRegression constitutes a supervised learning model, which aims\
    \ to provide the prediction of an\noutput variable according to the input variables,\
    \ which are known. Most known algorithms include\nlinear regression and logistic\
    \ regression [25], as well as stepwise regression [26]. Also, more complex\nregression\
    \ algorithms have been developed, such as ordinary least squares regression [27],\
    \ multivariate\nSensors 2018, 18, 2674\n5 of 29\nadaptive regression splines [28],\
    \ multiple linear regression, cubist [29], and locally estimated scatterplot\n\
    smoothing [30].\n2.4.2. Clustering\nClustering [31] is a typical application of\
    \ unsupervised learning model, typically used to\nﬁnd natural groupings of data\
    \ (clusters). Well established clustering techniques are the k-means\ntechnique\
    \ [32], the hierarchical technique [33], and the expectation maximisation technique\
    \ [34].\n2.4.3. Bayesian Models\nBayesian models (BM) are a family of probabilistic\
    \ graphical models in which the analysis is\nundertaken within the context of\
    \ Bayesian inference. This type of model belongs to the supervised\nlearning category\
    \ and can be employed for solving either classiﬁcation or regression problems.\n\
    Naive bayes [35], gaussian naive bayes, multinomial naive bayes, bayesian network\
    \ [36], mixture\nof gaussians [37], and bayesian belief network [38] are some\
    \ of the most prominent algorithms in\nthe literature.\n2.4.4. Instance Based\
    \ Models\nInstance based models (IBM) are memory-based models that learn by comparing\
    \ new examples\nwith instances in the training database. They construct hypotheses\
    \ directly from the data available,\nwhile they do not maintain a set of abstractions,\
    \ and generate classiﬁcation or regression predictions\nusing only speciﬁc instances.\
    \ The disadvantage of these models is that their complexity grows with\ndata.\
    \ The most common learning algorithms in this category are the k-nearest neighbor\
    \ [39], locally\nweighted learning [40], and learning vector quantization [41].\n\
    2.4.5. Decision Trees\nDecision trees (DT) are classiﬁcation or regression models\
    \ formulated in a tree-like\narchitecture [42]. With DT, the dataset is progressively\
    \ organized in smaller homogeneous subsets\n(sub-populations), while at the same\
    \ time, an associated tree graph is generated. Each internal node\nof the tree\
    \ structure represents a different pairwise comparison on a selected feature,\
    \ whereas each\nbranch represents the outcome of this comparison. Leaf nodes represent\
    \ the ﬁnal decision or prediction\ntaken after following the path from root to\
    \ leaf (expressed as a classiﬁcation rule). The most common\nlearning algorithms\
    \ in this category are the classiﬁcation and regression trees [43], the chi-square\n\
    automatic interaction detector [44], and the iterative dichotomiser [45].\n2.4.6.\
    \ Artiﬁcial Neural Networks\nArtiﬁcial neural networks (ANNs) are divided into\
    \ two categories; “Traditional ANNs” and\n“Deep ANNs”.\nANNs are inspired by the\
    \ human brain functionality, emulating complex functions such as\npattern generation,\
    \ cognition, learning, and decision making [46]. The human brain consists of billions\n\
    of neurons that inter-communicate and process any information provided. Similarly,\
    \ an ANN as a\nsimpliﬁed model of the structure of the biological neural network,\
    \ consists of interconnected processing\nunits organized in a speciﬁc topology.\
    \ A number of nodes are arranged in multiple layers including\nthe following:\n\
    1.\nAn input layer where the data is fed into the system,\n2.\nOne or more hidden\
    \ layers where the learning takes place, and\n3.\nAn output layer where the decision/prediction\
    \ is given.\nSensors 2018, 18, 2674\n6 of 29\nANNs are supervised models that\
    \ are typically used for regression and classiﬁcation problems.\nThe learning\
    \ algorithms commonly used in ANNs include the radial basis function networks\
    \ [47],\nperceptron algorithms [48], back-propagation [49], and resilient back-propagation\
    \ [50]. Also, a large\nnumber of ANN-based learning algorithms have been reported,\
    \ such as counter propagation\nalgorithms [51], adaptive-neuro fuzzy inference\
    \ systems [52], autoencoder, XY-Fusion, and supervised\nKohonen networks [53],\
    \ as well as Hopﬁeld networks [54], multilayer perceptron [55], self-organising\n\
    maps [56], extreme learning machines [57], generalized regression neural network\
    \ [58], ensemble neural\nnetworks or ensemble averaging, and self-adaptive evolutionary\
    \ extreme learning machines [59].\nDeep ANNs are most widely referred to as deep\
    \ learning (DL) or deep neural networks\n(DNNs) [60]. They are a relatively new\
    \ area of ML research allowing computational models that\nare composed of multiple\
    \ processing layers to learn complex data representations using multiple\nlevels\
    \ of abstraction. One of the main advantages of DL is that in some cases, the\
    \ step of feature\nextraction is performed by the model itself. DL models have\
    \ dramatically improved the state-of-the-art\nin many different sectors and industries,\
    \ including agriculture. DNN’s are simply an ANN with\nmultiple hidden layers\
    \ between the input and output layers and can be either supervised, partially\n\
    supervised, or even unsupervised. A common DL model is the convolutional neural\
    \ network (CNN),\nwhere feature maps are extracted by performing convolutions\
    \ in the image domain. A comprehensive\nintroduction on CNNs is given in the literature\
    \ [61]. Other typical DL architectures include deep\nBoltzmann machine, deep belief\
    \ network [62], and auto-encoders [63].\n2.4.7. Support Vector Machines\nSupport\
    \ vector machines (SVMs) were ﬁrst introduced in the work of [64] on the foundation\
    \ of\nstatistical learning theory. SVM is intrinsically a binary classiﬁer that\
    \ constructs a linear separating\nhyperplane to classify data instances. The classiﬁcation\
    \ capabilities of traditional SVMs can be\nsubstantially enhanced through transformation\
    \ of the original feature space into a feature space of\na higher dimension by\
    \ using the “kernel trick”. SVMs have been used for classiﬁcation, regression,\n\
    and clustering. Based on global optimization, SVMs deal with overﬁtting problems,\
    \ which appear\nin high-dimensional spaces, making them appealing in various applications\
    \ [65,66]. Most used SVM\nalgorithms include the support vector regression [67],\
    \ least squares support vector machine [68],\nand successive projection algorithm-support\
    \ vector machine [69].\n2.4.8. Ensemble Learning\nEnsemble learning (EL) models\
    \ aim at improving the predictive performance of a given statistical\nlearning\
    \ or model ﬁtting technique by constructing a linear combination of simpler base\
    \ learner.\nConsidering that each trained ensemble represents a single hypothesis,\
    \ these multiple-classiﬁer systems\nenable hybridization of hypotheses not induced\
    \ by the same base learner, thus yielding better results in\nthe case of signiﬁcant\
    \ diversity among the single models. Decision trees have been typically used as\
    \ the\nbase learner in EL models, for example, random forest [70], whereas a large\
    \ number of boosting and\nbagging implementations have been also proposed, for\
    \ example, boosting technique [71], adaboost [72],\nand bootstrap aggregating\
    \ or bagging algorithm [73].\n3. Review\nThe reviewed articles have been, on a\
    \ ﬁrst level, classiﬁed in four generic categories; namely, crop\nmanagement,\
    \ livestock management, water management, and soil management. The applications\
    \ of\nML in the crop section were divided into sub-categories including yield\
    \ prediction, disease detection,\nweed detection crop quality, and species recognition.\
    \ The applications of ML in the livestock section\nwere divided into two sub-categories;\
    \ animal welfare and livestock production.\nSensors 2018, 18, 2674\n7 of 29\n\
    The search engines implemented were Scopus, ScienceDirect and PubMed. The selected\
    \ articles\nregard works presented solely in journal papers. Climate prediction,\
    \ although very important for\nagricultural production, has not been included\
    \ in the presented review, considering the fact that ML\napplications for climate\
    \ prediction is a complete area by itself. Finally, all articles presented here\
    \ regard\nthe period from 2004 up to the present.\n3.1. Crop Management\n3.1.1.\
    \ Yield Prediction\nYield prediction, one of the most signiﬁcant topics in precision\
    \ agriculture, is of high importance\nfor yield mapping, yield estimation, matching\
    \ of crop supply with demand, and crop management to\nincrease productivity. Examples\
    \ of ML applications include in those in the works of [74]; an efﬁcient,\nlow-cost,\
    \ and non-destructive method that automatically counted coffee fruits on a branch.\
    \ The method\ncalculates the coffee fruits in three categories: harvestable, not\
    \ harvestable, and fruits with disregarded\nmaturation stage. In addition, the\
    \ method estimated the weight and the maturation percentage of the\ncoffee fruits.\
    \ The aim of this work was to provide information to coffee growers to optimise\
    \ economic\nbeneﬁts and plan their agricultural work. Another study that used\
    \ for yield prediction is that by\nthe authors of [75], in which they developed\
    \ a machine vision system for automating shaking and\ncatching cherries during\
    \ harvest. The system segments and detects occluded cherry branches with\nfull\
    \ foliage even when these are inconspicuous. The main aim of the system was to\
    \ reduce labor\nrequirements in manual harvesting and handling operations. In\
    \ another study [76], authors developed\nan early yield mapping system for the\
    \ identiﬁcation of immature green citrus in a citrus grove under\noutdoor conditions.\
    \ As all other relative studies, the aim of the study was to provide growers with\n\
    yield-speciﬁc information to assist them to optimise their grove in terms of proﬁt\
    \ and increased yield.\nIn another study [77], the authors developed a model for\
    \ the estimation of grassland biomass (kg dry\nmatter/ha/day) based on ANNs and\
    \ multitemporal remote sensing data. Another study dedicated\nto yield prediction,\
    \ and speciﬁcally to wheat yield prediction, was presented in another study [78].\n\
    The developed method used satellite imagery and received crop growth characteristics\
    \ fused with\nsoil data for a more accurate prediction. The authors of [79] presented\
    \ a method for the detection of\ntomatoes based on EM and remotely sensed red\
    \ green blue (RGB) images, which were captured by an\nunmanned aerial vehicle\
    \ (UAV). Also, in the work of [80], authors developed a method for the rice\n\
    development stage prediction based on SVM and basic geographic information obtained\
    \ from weather\nstations in China. Finally, a generalized method for agricultural\
    \ yield predictions, was presented in\nanother study [81]. The method is based\
    \ on an ENN application on long-period generated agronomical\ndata (1997–2014).\
    \ The study regards regional predictions (speciﬁcally in in Taiwan) focused on\
    \ the\nsupporting farmers to avoid imbalances in market supply and demand caused\
    \ or hastened by harvest\ncrop quality.\nTable 5 summarizes the above papers for\
    \ the case of yield prediction sub-category.\nSensors 2018, 18, 2674\n8 of 29\n\
    Table 5. Crop: yield prediction table.\nArticle\nCrop\nObserved Features\nFunctionality\n\
    Models/Algorithms\nResults\n[74]\nCoffee\nForty-two (42) color features in digital\n\
    images illustrating coffee fruits\nAutomatic count of coffee\nfruits on a coffee\
    \ branch\nSVM\nHarvestable:\n(1)\nRipe/overripe: 82.54–87.83%\nvisibility percentage\n\
    (2)\nSemi-ripe: 68.25–85.36%\nvisibility percentage\nNot harvestable:\n(1)\nUnripe:\
    \ 76.91–81.39%\nvisibility percentage\n[75]\nCherry\nColored digital images depicting\
    \ leaves,\nbranches, cherry fruits, and the background\nDetection of cherry\n\
    branches with full foliage\nBM/GNB\n89.6% accuracy\n[76]\nGreen citrus\nImage\
    \ features (form 20 × 20 pixels digital\nimages of unripe green citrus fruits)\n\
    such as coarseness, contrast, directionality,\nline-likeness, regularity, roughness,\n\
    granularity, irregularity, brightness,\nsmoothness, and ﬁneness\nIdentiﬁcation\
    \ of the number\nof immature green citrus\nfruit under natural\noutdoor conditions\n\
    SVM\n80.4% accuracy\n[77]\nGrass\nVegetation indices, spectral bands of red\n\
    and NIR\nEstimation of grassland\nbiomass (kg dry\nmatter/ha/day) for two\nmanaged\
    \ grassland farms\nin Ireland; Moorepark\nand Grange\nANN/ANFIS\nMoorepark:\n\
    R2 = 0.85\nRMSE = 11.07\nGrange:\nR2 = 0.76\nRMSE = 15.35\n[78]\nWheat\nNormalized\
    \ values of on-line predicted soil\nparameters and the satellite NDVI\nWheat yield\
    \ prediction\nwithin ﬁeld variation\nANN/SNKs\n81.65% accuracy\n[79]\nTomato\n\
    High spatial resolution RGB images\nDetection of tomatoes via\nRGB images captured\n\
    by UAV\nClustering/EM\nRecall: 0.6066\nPrecision: 0.9191\nF-Measure: 0.7308\n\
    Sensors 2018, 18, 2674\n9 of 29\nTable 5. Cont.\nArticle\nCrop\nObserved Features\n\
    Functionality\nModels/Algorithms\nResults\n[80]\nRice\nAgricultural, surface weather,\
    \ and soil\nphysico-chemical data with yield or\ndevelopment records\nRice development\
    \ stage\nprediction and yield\nprediction\nSVM\nMiddle-season rice:\nTillering\
    \ stage:\nRMSE (kg h−1 m2) = 126.8\nHeading stage:\nRMSE (kg h−1 m2) = 96.4\n\
    Milk stage:\nRMSE (kg h−1 m2) = 109.4\nEarly rice:\nTillering stage:\nRMSE (kg\
    \ h−1 m2) = 88.3\nHeading stage:\nRMSE (kg h−1 m2) = 68.0\nMilk stage:\nRMSE (kg\
    \ h−1 m2) = 36.4\nLate rice:\nTillering stage:\nRMSE (kg h−1 m2) = 89.2\nHeading\
    \ stage:\nRMSE (kg h−1 m2) = 69.7\nMilk stage:\nRMSE (kg h−1 m2) = 46.5\n[81]\n\
    General\nAgriculture data: meteorological,\nenvironmental, economic, and harvest\n\
    Method for the accurate\nanalysis for agricultural\nyield predictions\nANN/ENN\
    \ and\nBPN based\n1.3% error rate\nSensors 2018, 18, 2674\n10 of 29\n3.1.2. Disease\
    \ Detection\nDisease detection and yield prediction are the sub-categories with\
    \ the higher number of articles\npresented in this review. One of the most signiﬁcant\
    \ concerns in agriculture is pest and disease\ncontrol in open-air (arable farming)\
    \ and greenhouse conditions. The most widely used practice\nin pest and disease\
    \ control is to uniformly spray pesticides over the cropping area. This practice,\n\
    although effective, has a high ﬁnancial and signiﬁcant environmental cost. Environmental\
    \ impacts\ncan be residues in crop products, side effects on ground water contamination,\
    \ impacts on local\nwildlife and eco-systems, and so on. ML is an integrated part\
    \ of precision agriculture management,\nwhere agro-chemicals input is targeted\
    \ in terms of time and place. In the literature [82], a tool\nis presented for\
    \ the detection and discrimination of healthy Silybum marianum plants and those\n\
    infected by smut fungus Microbotyum silybum during vegetative growth. In the work\
    \ of [83], authors\ndeveloped a new method based on image processing procedure\
    \ for the classiﬁcation of parasites\nand the automatic detection of thrips in\
    \ strawberry greenhouse environment, for real-time control.\nThe authos of [84]\
    \ presented a method for detection and screening of Bakanae disease in rice seedlings.\n\
    More speciﬁcally, the aim of the study was the accurate detection of pathogen\
    \ Fusarium fujikuroi for\ntwo rice cultivars. The automated detection of infected\
    \ plants increased grain yield and was less\ntime-consuming compared with naked\
    \ eye examination.\nWheat is one of the most economically signiﬁcant crops worldwide.\
    \ The last ﬁve studies presented\nin this sub-category are dedicated to the detection\
    \ and discrimination between diseased and healthy\nwheat crops. The authors of\
    \ [85] developed a new system for the detection of nitrogen stressed,\nand yellow\
    \ rust infected and healthy winter wheat canopies based on hierarchical self-organizing\n\
    classiﬁer and hyperspectral reﬂectance imaging data. The study aimed at the accurate\
    \ detection of these\ncategories for a more effective usage of fungicides and\
    \ fertilizers according to the plant’s needs. In the\nnext case study [86], the\
    \ development of a system was presented that automatically discriminated\nbetween\
    \ water stressed Septoria tritici infected and healthy winter wheat canopies.\
    \ The approach used\nan least squares (LS)-SVM classiﬁer with optical multisensor\
    \ fusion. The authors of [87] presented a\nmethod to detect either yellow rust\
    \ infected or healthy wheat, based on ANN models and spectral\nreﬂectance features.\
    \ The accurate detection of either infected or healthy plants enables the precise\n\
    targeting of pesticides in the ﬁeld. In the work of [88], a real time remote sensing\
    \ system is presented\nfor the detection of yellow rust infected and healthy wheat.\
    \ The system is based on a self-organising\nmap (SOM) neural network and data\
    \ fusion of hyper-spectral reﬂection and multi-spectral ﬂuorescence\nimaging.\
    \ The goal of the study was the accurate detection, before it can visibly detected,\
    \ of yellow\nrust infected winter wheat cultivar “Madrigal”. Finally, the authors\
    \ of [89] presented a method for\nthe simultaneous identiﬁcation and discrimination\
    \ of yellow rust infected, and nitrogen stressed and\nhealthy wheat plants of\
    \ cultivar “Madrigal”. The approach is based on an SOM neural network and\nhyperspectral\
    \ reﬂectance imaging. The aim of the study was the accurate discrimination between\n\
    the plant stress, which is caused by disease and nutrient deﬁciency stress under\
    \ ﬁeld conditions.\nFinally, the author of [90] presented a CNN-based method for\
    \ the disease detection diagnosis based\non simple leaves images with sufﬁcient\
    \ accuracy to classify between healthy and diseased leaves in\nvarious plants.\n\
    Table 6 summarizes the above papers for the case of the disease detection sub-category.\n\
    Sensors 2018, 18, 2674\n11 of 29\nTable 6. Crop: disease detection table.\nAuthor\n\
    Crop\nObserved Features\nFunctionality\nModels/Algorithms\nResults\n[82]\nSilybum\
    \ marianum\nImages with leaf spectra\nusing a handheld visible\nand NIR spectrometer\n\
    Detection and\ndiscrimination between\nhealthy Silybum marianum\nplants and those\
    \ that are\ninfected by smut fungus\nMicrobotyum silybum\nANN/XY-Fusion\n95.16%\
    \ accuracy\n[83]\nStrawberry\nRegion index: ratio of\nmajor diameter to minor\n\
    diameter; and color\nindexes: hue, saturation,\nand intensify\nClassiﬁcation of\
    \ parasites\nand automatic detection\nof thrips\nSVM\nMPE = 2.25%\n[84]\nRice\n\
    Morphological and color\ntraits from healthy and\ninfected from Bakanae\ndisease,\
    \ rice seedlings,\nfor cultivars Tainan 11\nand Toyonishiki\nDetection of Bakanae\n\
    disease, Fusarium fujikuroi,\nin rice seedlings\nSVM\n87.9% accuracy\n[85]\nWheat\n\
    Hyperspectral reﬂectance\nimaging data\nDetection of nitrogen\nstressed, yellow\
    \ rust\ninfected and healthy\nwinter wheat canopies\nANN/XY-Fusion\nNitrogen stressed:\
    \ 99.63% accuracy\nYellow rust: 99.83% accuracy\nHealthy: 97.27% accuracy\n[86]\n\
    Wheat\nSpectral reﬂectance and\nﬂuorescence features\nDetection of water\nstressed,\
    \ Septoria tritici\ninfected, and healthy\nwinter wheat canopies\nSVM/LS-SVM\n\
    Four scenarios:\n(1)\nControl treatment, healthy and well\nsupplied with water:\
    \ 100% accuracy\n(2)\nInoculated treatment, with Septoria\ntritici and well supplied\
    \ with water:\n98.75% accuracy\n(3)\nHealthy treatment and deﬁcient water\nsupply:\
    \ 100% accuracy\n(4)\nInoculated treatment and deﬁcient\nwater supply: 98.7% accuracy\n\
    Sensors 2018, 18, 2674\n12 of 29\nTable 6. Cont.\nAuthor\nCrop\nObserved Features\n\
    Functionality\nModels/Algorithms\nResults\n[87]\nWheat\nSpectral reﬂectance\n\
    features\nDetection of yellow rust\ninfected and healthy\nwinter wheat canopies\n\
    ANN/MLP\nYellow rust infected wheat: 99.4% accuracy\nHealthy: 98.9% accuracy\n\
    [88]\nWheat\nData fusion of\nhyper-spectral reﬂection\nand multi-spectral\nﬂuorescence\
    \ imaging\nDetection of yellow rust\ninfected and healthy\nwinter wheat under\
    \ ﬁeld\ncircumstances\nANN/SOM\nYellow rust infected wheat: 99.4% accuracy\nHealthy:\
    \ 98.7% accuracy\n[89]\nWheat\nHyperspectral\nreﬂectance images\nIdentiﬁcation\
    \ and\ndiscrimination of yellow\nrust infected, nitrogen\nstressed, and healthy\n\
    winter wheat in\nﬁeld conditions\nANN/SOM\nYellow rust infected wheat: 99.92%\
    \ accuracy\nNitrogen stressed: 100% accuracy\nHealthy: 99.39% accuracy\n[90]\n\
    Generilized\napproach for various\ncrops (25 in total)\nSimple leaves images\n\
    of healthy and\ndiseased plants\nDetection and diagnosis\nof plant diseases\n\
    DNN/CNN\n99.53% accuracy\nSensors 2018, 18, 2674\n13 of 29\n3.1.3. Weed Detection\n\
    Weed detection and management is another signiﬁcant problem in agriculture. Many\
    \ producers\nindicate weeds as the most important threat to crop production. The\
    \ accurate detection of weeds is\nof high importance to sustainable agriculture,\
    \ because weeds are difﬁcult to detect and discriminate\nfrom crops. Again, ML\
    \ algorithms in conjunction with sensors can lead to accurate detection and\n\
    discrimination of weeds with low cost and with no environmental issues and side\
    \ effects. ML for\nweed detection can enable the development of tools and robots\
    \ to destroy weeds, which minimise\nthe need for herbicides. Two studies on ML\
    \ applications for weed detection issues in agriculture\nhave been presented.\
    \ In the ﬁrst study [91], authors presented a new method based on counter\npropagation\
    \ (CP)-ANN and multispectral images captured by unmanned aircraft systems (UAS)\
    \ for\nthe identiﬁcation of Silybum marianum, a weed that is hard to eradicate\
    \ and causes major loss on\ncrop yield. In the second study [92], the authors\
    \ developed a new method based on ML techniques\nand hyperspectral imaging, for\
    \ crop and weed species recognition. More speciﬁcally, the authors\ncreated an\
    \ active learning system for the recognition of Maize (Zea mayas), as crop plant\
    \ species\nand Ranunculus repens, Cirsium arvense, Sinapis arvensis, Stellaria\
    \ media, Tarraxacum ofﬁcinale,\nPoa annua, Polygonum persicaria, Urtica dioica,\
    \ Oxalis europaea, and Medicago lupulina as weed\nspecies. The main goal was the\
    \ accurate recognition and discrimination of these species for economic\nand environmental\
    \ purposes. In another study [93], the authors developed a weed detection method\n\
    based on SVN in grassland cropping.\nTable 7 summarizes the above papers for the\
    \ case of weed detection sub-category.\nTable 7. Crop: Weed detection table.\n\
    Author\nObserved Features\nFunctionality\nModels/Algorithms\nResults\n[91]\nSpectral\
    \ bands of\nred, green, and NIR\nand texture layer\nDetection and\nmapping of\n\
    Silybum marianum\nANN/CP\n98.87% accuracy\n[92]\nSpectral features\nfrom hyperspectral\n\
    imaging\nRecognition and\ndiscrimination of\nZea mays and\nweed species\nANN/one-class\n\
    SOM and\nClustering/one-class\nMOG\nZea mays: SOM = 100%\naccuracy MOG = 100%\n\
    accuracy\nWeed species: SOM =\n53–94% accuracy\nMOG = 31–98% accuracy\n[93]\n\
    Camera images of\ngrass and various\nweeds types\nReporting on\nperformance of\n\
    classiﬁcation\nmethods for grass\nvs. weed detection\nSVN\n97.9% Again Rumex\n\
    classiﬁcation6\n94.65% Urtica\nclassiﬁcation\n95.1% for mixed\nweed and mixed\n\
    weather conditions\n3.1.4. Crop Quality\nThe penultimate sub-category for the\
    \ crop category is studies developed for the identiﬁcation\nof features connected\
    \ with the crop quality. The accurate detection and classiﬁcation of crop quality\n\
    characteristics can increase product price and reduce waste. In the ﬁrst study\
    \ [94], the authors presented\nand developed a new method for the detection and\
    \ classiﬁcation of botanical and non-botanical\nforeign matter embedded inside\
    \ cotton lint during harvesting. The aim of the study was quality\nimprovement\
    \ while the minimising ﬁber damage. Another study [95] regards pears production\
    \ and,\nmore speciﬁcally, a method was presented for the identiﬁcation and differentiation\
    \ of Korla fragrant\npears into deciduous-calyx or persistent-calyx categories.\
    \ The approach applied ML methods with\nhyperspectral reﬂectance imaging. The\
    \ ﬁnal study for this sub-category was by the authors of [96],\nin which a method\
    \ was presented for the prediction and classiﬁcation of the geographical origin\
    \ for\nSensors 2018, 18, 2674\n14 of 29\nrice samples. The method was based on\
    \ ML techniques applied on chemical components of samples.\nMore speciﬁcally,\
    \ the main goal was the classiﬁcation of the geographical origin of rice, for\
    \ two\ndifferent climate regions in Brazil; Goias and Rio Grande do Sul. The results\
    \ showed that Cd, Rb, Mg,\nand K are the four most relevant chemical components\
    \ for the classiﬁcation of samples.\nTable 8 summarizes the above presented articles.\n\
    Table 8. Crop: crop quality table.\nAuthor\nCrop\nObserved Features\nFunctionality\n\
    Models/Algorithms\nResults\n[94]\nCotton\nShort wave infrared\nhyperspectral\n\
    transmittance images\ndepicting cotton along\nwith botanical and\nnon-botanical\
    \ types of\nforeign matter\nDetection and\nclassiﬁcation of common\ntypes of botanical\
    \ and\nnon-botanical foreign\nmatter that are embedded\ninside the cotton lint\n\
    SVM\nAccording to the\noptimal selected\nwavelengths,\nthe classiﬁcation\naccuracies\
    \ are over\n95% for the spectra\nand the images.\n[95]\nPears\nHyperspectral\n\
    reﬂectance imaging\nIdentiﬁcation and\ndifferentiation of Korla\nfragrant pears\
    \ into\ndeciduous-calyx or\npersistent-calyx categories\nSVM/SPA-SVM\nDeciduous-calyx\
    \ pears:\n93.3% accuracy\nPersistent-calyx pears:\n96.7% accuracy\n[96]\nRice\n\
    Twenty (20) chemical\ncomponents that were\nfound in composition of\nrice samples\
    \ with\ninductively coupled\nplasma mass spectrometry\nPrediction and\nclassiﬁcation\
    \ of\ngeographical origin of a\nrice sample\nEL/RF\n93.83% accuracy\n3.1.5. Species\
    \ Recognition\nThe last sub-category of crop category is the species recognition.\
    \ The main goal is the automatic\nidentiﬁcation and classiﬁcation of plant species\
    \ in order to avoid the use of human experts, as well as\nto reduce the classiﬁcation\
    \ time. A method for the identiﬁcation and classiﬁcation of three legume\nspecies,\
    \ namely, white beans, red beans, and soybean, via leaf vein patterns has been\
    \ presented in [97].\nVein morphology carries accurate information about the properties\
    \ of the leaf. It is an ideal tool for\nplant identiﬁcation in comparison with\
    \ color and shape.\nTable 9 summarizes the above study for the case of species\
    \ recognition sub-category.\nTable 9. Crop: Species recognition.\nAuthor\nCrop\n\
    Observed\nFeatures\nFunctionality\nModels/Algorithms\nResults\n[97]\nLegume\n\
    Vein leaf\nimages of white\nand red beans\nas well as and\nsoybean\nIdentiﬁcation\
    \ and\nclassiﬁcation of three\nlegume species:\nsoybean, and white\nand red bean\n\
    DL/CNN\nWhite bean: 90.2%\naccuracy\nRed bean: 98.3%\naccuracy\nSoybean: 98.8%\n\
    accuracy for ﬁve\nCNN layers\n3.2. Livestock Management\nThe livestock category\
    \ consists of two sub-categories, namely, animal welfare and livestock\nproduction.\
    \ Animal welfare deals with the health and wellbeing of animals, with the main\
    \ application\nof ML in monitoring animal behaviour for the early detection of\
    \ diseases. On the other hand, livestock\nproduction deals with issues in the\
    \ production system, where the main scope of ML applications is the\naccurate\
    \ estimation of economic balances for the producers based on production line monitoring.\n\
    Sensors 2018, 18, 2674\n15 of 29\n3.2.1. Animal Welfare\nSeveral articles are\
    \ reported to belong to the animal welfare sub-category. In the ﬁrst article [98],\n\
    a method is presented for the classiﬁcation of cattle behaviour based on ML models\
    \ using data collected\nby collar sensors with magnetometers and three-axis accelerometers.\
    \ The aim of the study was the\nprediction of events such as the oestrus and the\
    \ recognition of dietary changes on cattle. In the second\narticle [99], a system\
    \ was presented for the automatic identiﬁcation and classiﬁcation of chewing\n\
    patterns in calves. The authors created a system based on ML applying data from\
    \ chewing signals of\ndietary supplements, such as hay and ryegrass, combined\
    \ with behaviour data, such as rumination\nand idleness. Data was collected by\
    \ optical FBG sensors. In another study [100], an automated\nmonitoring system\
    \ based on ML was presented for animal behavior tracking, including tracking of\n\
    animal movements by depth video cameras, for monitoring various activities of\
    \ the animal (standing,\nmoving, feeding, and drinking).\nTable 10 summarizes\
    \ the features of the above presented articles.\n3.2.2. Livestock Production\n\
    The sub-category of livestock production regards studies developed for the accurate\
    \ prediction\nand estimation of farming parameters to optimize the economic efﬁciency\
    \ of the production system.\nThis sub-category consists of the presentation of\
    \ four articles, three with cattle production and one for\nhens’ eggs production.\
    \ In the work of [101], a method for the prediction of the rumen fermentation\n\
    pattern from milk fatty acids was presented. The main aim of the study was to\
    \ achieve the most\naccurate prediction of rumen fermentations, which play a signiﬁcant\
    \ role for the evaluation of diets for\nmilk production. In addition, this work\
    \ showed that milk fatty acids have ideal features to predict\nthe molar proportions\
    \ of volatile fatty acids in the rumen. The next study [102] was related to hen\n\
    production. Speciﬁcally, a method based on SVM model was presented for the early\
    \ detection and\nwarning of problems in the commercial production of eggs. Based\
    \ on SVM methods [103], a method for\nthe accurate estimation of bovine weight\
    \ trajectories over time was presented. The accurate estimation\nof cattle weights\
    \ is very important for breeders. The last article of the section [104] deals\
    \ with the\ndevelopment of a function for the prediction of carcass weight for\
    \ beef cattle of the Asturiana de los\nValles breed based on SVR models and zoometric\
    \ measurements features. The results show that the\npresented method can predict\
    \ carcass weights 150 days prior to the slaughter day. The authors of [105]\n\
    presented a method based on convolutional neural networks (CNNs) applied in digital\
    \ images for\npig face recognition. The main aim of the research was the identiﬁcation\
    \ of animals without the need\nfor radio frequency identiﬁcation (RFID) tags,\
    \ which involve a distressing activity for the animal, are\nlimited in their range,\
    \ and are a time-consuming method.\nTable 11 summarizes the features of the above\
    \ presented works.\n3.3. Water Management\nWater management in agricultural production\
    \ requires signiﬁcant efforts and plays a signiﬁcant\nrole in hydrological, climatological,\
    \ and agronomical balance.\nSensors 2018, 18, 2674\n16 of 29\nTable 10. Livestock:\
    \ animal welfare.\nAuthor\nAnimal Species\nObserved Features\nFunctionality\n\
    Models/Algorithms\nResults\n[98]\nCattle\nFeatures like grazing,\nruminating,\
    \ resting,\nand walking, which were\nrecorded using collar\nsystems with three-axis\n\
    accelerometer and\nmagnetometer\nClassiﬁcation of\ncattle behaviour\nEL/Bagging\
    \ with\ntree learner\n96% accuracy\n[99]\nCalf\nData: chewing signals\nfrom dietary\
    \ supplement,\nTifton hay, ryegrass,\nrumination, and idleness.\nSignals were\
    \ collected\nfrom optical FBG sensors\nIdentiﬁcation and\nclassiﬁcation of chewing\n\
    patterns in calves\nDT/C4.5\n94% accuracy\n[100]\nPigs\n3D motion data by using\n\
    two depth cameras\nAnimal tracking and\nbehavior annotation of the\npigs to measure\n\
    behavioral changes in\npigs for welfare and\nhealth monitoring\nBM: Gaussian Mixture\n\
    Models (GMMs)\nAnimal tracking: mean multi-object tracking\nprecision (MOTP) =\
    \ 0.89 accuracy behavior\nannotation: standing: control R2 = 0.94,\ntreatment\
    \ R2 = 0.97 feeding: control\nR2 = 0.86, treatment R2 = 0.49\nSensors 2018, 18,\
    \ 2674\n17 of 29\nTable 11. Livestock: livestock production table.\nAuthor\nAnimal\
    \ Species\nObserved Features\nFunctionality\nModels/Algorithms\nResults\n[101]\n\
    Cattle\nMilk fatty acids\nPrediction of rumen\nfermentation pattern from\nmilk\
    \ fatty acids\nANN/BPN\nAcetate:\nRMSE = 2.65%\nPropionate: RMSE = 7.67%\nButyrate:\
    \ RMSE = 7.61%\n[102]\nHens\nSix (6) features, which\nwere created from\nmathematical\
    \ models\nrelated to farm’s egg\nproduction line and\ncollected over a period\n\
    of seven (7) years.\nEarly detection and\nwarning of problems in\nproduction curves\
    \ of\ncommercial hens eggs\nSVM\n98% accuracy\n[103]\nBovine\nGeometrical relationships\n\
    of the trajectories of\nweights along the time\nEstimation of cattle\nweight trajectories\
    \ for\nfuture evolution with only\none or a few weights.\nSVM\nAngus bulls from\
    \ Indiana Beef Evaluation Program:\nweights 1, MAPE = 3.9 + −3.0%\nBulls from\
    \ Association of Breeder of Asturiana de\nlos Valles: weights 1, MAPE = 5.3 +\
    \ −4.4%\nCow from Wokalup Selection Experiment in\nWestern Australia: weights\
    \ 1, MAPE = 9.3 + −6.7%\n[104]\nCattle\nZoometric measurements\nof the animals\
    \ 2 to 222\ndays before the slaughter\nPrediction of carcass\nweight for beef\
    \ cattle 150\ndays before the slaughter\nday\nSVM/SVR\nAverage MAPE = 4.27%\n\
    [105]\nPigs\n1553 color images with\npigs faces\nPigs face recognition\nDNNs:\
    \ Convolutional\nNeural Networks (CNNs)\n96.7% Accuracy\nSensors 2018, 18, 2674\n\
    18 of 29\nThis section consists of four studies that were mostly developed for\
    \ the estimation of daily, weekly,\nor monthly evapotranspiration. The accurate\
    \ estimation of evapotranspiration is a complex process\nand is of a high importance\
    \ for resource management in crop production, as well as for the design\nand the\
    \ operation management of irrigation systems. In another study [106], the authors\
    \ developed a\ncomputational method for the estimation of monthly mean evapotranspiration\
    \ for arid and semi-arid\nregions. It used monthly mean climatic data of 44 meteorological\
    \ stations for the period 1951–2010.\nIn another study dedicated to ML applications\
    \ on agricultural water management [107], two scenarios\nwere presented for the\
    \ estimation of the daily evapotranspiration from temperature data collected\n\
    from six meteorological stations of a region during the long period (i.e., 1961–2014).\
    \ Finally, in another\nstudy [108], authors developed a method based on ELM model\
    \ fed with temperature data for the\nweekly estimation of evapotranspiration for\
    \ two meteorological weather stations. The purpose was\nthe accurate estimation\
    \ of weekly evapotranspiration in arid regions of India based on limited data\n\
    scenario for crop water management.\nDaily dew point temperature, on the other\
    \ hand, is a signiﬁcant element for the identiﬁcation of\nexpected weather phenomena,\
    \ as well as for the estimation of evapotranspiration and evaporation.\nIn another\
    \ article [109], a model is presented for the prediction of daily dew point temperature,\
    \ based\non ML. The weather data were collected from two different weather stations.\n\
    Table 12 summarizes the above papers for the case of the water management sub-category.\n\
    3.4. Soil Management\nThe ﬁnal category of this review concerns ML application\
    \ on prediction-identiﬁcation of\nagricultural soil properties, such as the estimation\
    \ of soil drying, condition, temperature, and moisture\ncontent. Soil is a heterogeneous\
    \ natural resource, with complex processes and mechanisms that are\ndifﬁcult to\
    \ understand. Soil properties allow researchers to understand the dynamics of\
    \ ecosystems\nand the impingement in agriculture. The accurate estimation of soil\
    \ conditions can lead to improved\nsoil management. Soil temperature alone plays\
    \ a signiﬁcant role for the accurate analysis of the\nclimate change effects of\
    \ a region and eco-environmental conditions. It is a signiﬁcant meteorological\n\
    parameter controlling the interactive processes between ground and atmosphere.\
    \ In addition, soil\nmoisture has an important role for crop yield variability.\
    \ However, soil measurements are generally\ntime-consuming and expensive, so a\
    \ low cost and reliable solution for the accurate estimation of soil\ncan be achieved\
    \ with the usage of computational analysis based on ML techniques. The ﬁrst study\
    \ for\nthis last sub-category is the work of [110]. More speciﬁcally, this study\
    \ presented a method for the\nevaluation of soil drying for agricultural planning.\
    \ The method accurately evaluates the soil drying,\nwith evapotranspiration and\
    \ precipitation data, in a region located in Urbana, IL of the United States.\n\
    The goal of this method was the provision of remote agricultural management decisions.\
    \ The second\nstudy [111] was developed for the prediction of soil condition.\
    \ In particular, the study presented the\ncomparison of four regression models\
    \ for the prediction of soil organic carbon (OC), moisture content\n(MC), and\
    \ total nitrogen (TN). More speciﬁcally, the authors used a visible-near infrared\
    \ (VIS-NIR)\nspectrophotometer to collect soil spectra from 140 unprocessed and\
    \ wet samples of the top layer of\nLuvisol soil types. The samples were collected\
    \ from an arable ﬁeld in Premslin, Germany in August\n2013, after the harvest\
    \ of wheat crops. They concluded that the accurate prediction of soil properties\n\
    can optimize soil management. In a third study [112], the authors developed a\
    \ new method based on a\nself adaptive evolutionary-extreme learning machine (SaE-ELM)\
    \ model and daily weather data for\nthe estimation of daily soil temperature at\
    \ six different depths of 5, 10, 20, 30, 50, and 100 cm in two\ndifferent in climate\
    \ conditions regions of Iran; Bandar Abbas and Kerman. The aim was the accurate\n\
    estimation of soil temperature for agricultural management. The last study [113]\
    \ presented a novel\nmethod for the estimation of soil moisture, based on ANN\
    \ models using data from force sensors on a\nno-till chisel opener.\nTable 13\
    \ summarizes the above papers for the case of soil management sub-category.\n\
    Sensors 2018, 18, 2674\n19 of 29\nTable 12. Water: Water management table.\nAuthor\n\
    Property\nObserved Features\nFunctionality\nModels/Algorithms\nResults\n[106]\n\
    Evapotranspiration\nData such as maximum,\nminimum, and mean\ntemperature; relative\n\
    humidity; solar radiation;\nand wind speed\nEstimation of monthly\nmean reference\n\
    evapotranspiration arid\nand semi-arid regions\nRegression/MARS\nMAE = 0.05\n\
    RMSE = 0.07\nR = 0.9999\n[107]\nEvapotranspiration\nTemperature data:\nmaximum\
    \ and minimum\ntemperature, air\ntemperature at 2 m height,\nmean relative humidity,\n\
    wind speed at 10 m height,\nand sunshine duration\nEstimation of daily\nevapotranspiration\
    \ for\ntwo scenarios (six regional\nmeteorological stations).\nScenario A: Models\n\
    trained and tested from\nlocal data of each Station\n(2). Scenario B: Models\n\
    trained from pooled data\nfrom all stations\n(1)\nScenario\nANN/ELM\n(2)\nScenario\n\
    ANN/GRNN\n(1)\nScenario A: RRMSE = 0.198 MAE =\n0.267 mm d−1 NS = 0.891\n(2)\n\
    Scenario B: RRMSE = 0.194 MAE =\n0.263 mm d−1 NS = 0.895\n[108]\nEvapotranspiration\n\
    Locally maximum and\nminimum air temperature,\nextraterrestrial radiation,\nand\
    \ extrinsic\nevapotranspiration\nEstimation of weekly\nevapotranspiration based\n\
    on data from two\nmeteorological\nweather stations\nANN/ELM\nStation A: RMSE =\
    \ 0.43 mm d−1\nStation B: RMSE = 0.33 mm d−1\n[109]\nDaily dew point\ntemperature\n\
    Weather data such as\naverage air temperature,\nrelative humidity,\natmospheric\
    \ pressure,\nvapor pressure,\nand horizontal global\nsolar radiation\nPrediction\
    \ of daily dew\npoint temperature\nANN/ELM\nRegion case A:\nMABE = 0.3240 ◦C\n\
    RMSE = 0.5662 ◦C\nR = 0.9933\nRegion case B:\nMABE = 0.5203 ◦C\nRMSE = 0.6709\
    \ ◦C\nR = 0.9877\nSensors 2018, 18, 2674\n20 of 29\nTable 13. Soil management\
    \ table.\nAuthor\nProperty\nObserved Features\nFunctionality\nModels/Algorithms\n\
    Results\n[110]\nSoil drying\nPrecipitation and\npotential\nevapotranspiration\
    \ data\nEvaluation of soil drying\nfor agricultural planning\nIBM/KNN and ANN/BP\n\
    Both performed with 91–94% accuracy\n[111]\nSoil condition\n140 soil samples from\
    \ top\nsoil layer of an arable ﬁeld\nPrediction of soil OC, MC,\nand TN\nSVM/LS-SVM\
    \ and\nRegression/Cubist\nOC: RMSEP = 0.062% & RPD = 2.20 (LS-SVM)\nMC: RMSEP\
    \ = 0.457% & RPD = 2.24 (LS-SVM)\nTN: RMSEP = 0.071% & RPD = 1.96 (Cubist)\n[112]\n\
    Soil temperature\nDaily weather data:\nmaximum, minimum,\nand average air\ntemperature;\
    \ global solar\nradiation; and\natmospheric pressure.\nData were collected for\n\
    the period of 1996–2005\nfor Bandar Abbas and for\nthe period of 1998–2004\nfor\
    \ Kerman\nEstimation of soil\ntemperature for six (6)\ndifferent depths 5, 10,\
    \ 20,\n30, 50, and 100 cm, in two\ndifferent in climate\nconditions Iranian regions;\n\
    Bandar Abbas and\nKerman\nANN/SaE-ELM\nBandar Abbas station:\nMABE = 0.8046 to\
    \ 1.5338 ◦C\nRMSE = 1.0958 to 1.9029 ◦C\nR = 0.9084 to 0.9893\nKerman station:\n\
    MABE = 1.5415 to 2.3422 ◦C\nRMSE = 2.0017 to 2.9018 ◦C\nR = 0.8736 to 0.9831 depending\
    \ on the depth\n[113]\nSoil moisture\nDataset of forces acting on\na chisel and\
    \ speed\nEstimation of soil\nmoisture\nANN/MLP and RBF\nMLP:\nRMSE = 1.27%\nR2\
    \ = 0.79\nAPE = 3.77%\nRBF:\nRMSE = 1.30%\nR2 = 0.80\nAPE = 3.75%\nSensors 2018,\
    \ 18, 2674\n21 of 29\n4. Discussion and Conclusions\nThe number of articles included\
    \ in this review was 40 in total. Twenty-ﬁve (25) of the presented\narticles were\
    \ published in the journal «Computer and Electronics in Agriculture», six were\
    \ published\nin the journal of «Biosystems Engineering», and the rest of the articles\
    \ were published to the\nfollowing journals: «Sensors», «Sustainability», «Real-Time\
    \ Imagining», «Precision Agriculture»,\n«Earth Observations and Remote Sensing»,\
    \ «Saudi Journal of Biological Sciences», «Scientiﬁc Reports»,\nand «Computers\
    \ in Industry». Among the articles, eight of them are related to applications\
    \ of ML\nin livestock management, four articles are related to applications of\
    \ ML in water management, four\nare related to soil management, while the largest\
    \ number of them (i.e., 24 articles) are related to\napplications of ML in crop\
    \ management. Figure 2 presents the distribution of the articles according to\n\
    these application domains and to the deﬁned sub-categories.\nSensors 2018, 18, x FOR PEER REVIEW \
    \  \n23 of 31 \n \n4. Discussion and Conclusions \nThe number of articles included in this review was 40 in total. Twenty‐five (25) of the presented \n\
    articles were published in the journal «Computer and Electronics in Agriculture», six were published \n\
    in the journal of «Biosystems Engineering», and the rest of the articles were published to the following \n\
    journals:  «Sensors»,  «Sustainability»,  «Real‐Time  Imagining»,  «Precision \
    \ Agriculture»,  «Earth \nObservations and Remote Sensing», «Saudi Journal of Biological Sciences», «Scientific Reports», and \n\
    «Computers in Industry». Among the articles, eight of them are related to applications of ML in \n\
    livestock management, four articles are related to applications of ML in water management, four are \n\
    related  to  soil  management,  while  the  largest  number  of  them  (i.e., \
    \ 24  articles)  are  related  to \napplications of ML in crop management. Figure 2 presents the distribution of the articles according \n\
    to these application domains and to the defined sub‐categories. \n \nFigure 2. Pie chart presenting the papers according to the application domains. \n\
    From the analysis of these articles, it was found that eight ML models have been implemented \n\
    in  total.  More  specifically,  five  ML  models  were  implemented  in  the \
    \ approaches  on  crop \nmanagement,  where  the  most  popular  models  were \
    \ ANNs  (with  most  frequent  crop  at  hand—\nwheat). In livestock management category, four ML models were implemented, with most popular \n\
    models  being  SVMs  (most  frequent  livestock  type  at  hand—cattle).  For \
    \ water  management  in \nparticular evapotranspiration estimation, two ML models were implemented and the most frequently \n\
    implemented  were  ANNs.  Finally,  in  the  soil  management  category,  four \
    \ ML  models  were \nimplemented, with the most popular one again being the ANN model. In Figure 3, the eight ML \n\
    models with their total rates are presented, and in Figure 4 and Table 14, the ML models for all studies \n\
    according to the sub‐category are presented. Finally, in Figure 5 and Table 15, the future techniques \n\
    that were used according to each sub‐category are presented (it is noting that the figure and table \n\
    provide the same information in different demonstration purposes). \n7%\n12%\n\
    20%\n22%\n8%\n8%\n3%\n10%\n10%\n19%\n61%\n10%\n10%\nLIVESTOCK\nCROP\nWATER\nSOIL\n\
    Animal welfare\nLivestock production\nYield prediction\nDisease detection\nWeed detection\n\
    Crop quality\nSpecies recognition\nWater management\nSoil management\nFigure 2.\
    \ Pie chart presenting the papers according to the application domains.\nFrom\
    \ the analysis of these articles, it was found that eight ML models have been\
    \ implemented in\ntotal. More speciﬁcally, ﬁve ML models were implemented in the\
    \ approaches on crop management,\nwhere the most popular models were ANNs (with\
    \ most frequent crop at hand—wheat). In livestock\nmanagement category, four ML\
    \ models were implemented, with most popular models being SVMs\n(most frequent\
    \ livestock type at hand—cattle). For water management in particular evapotranspiration\n\
    estimation, two ML models were implemented and the most frequently implemented\
    \ were ANNs.\nFinally, in the soil management category, four ML models were implemented,\
    \ with the most popular\none again being the ANN model. In Figure 3, the eight\
    \ ML models with their total rates are presented,\nand in Figure 4 and Table 14,\
    \ the ML models for all studies according to the sub-category are\nSensors 2018,\
    \ 18, 2674\n22 of 29\npresented. Finally, in Figure 5 and Table 15, the future\
    \ techniques that were used according to\neach sub-category are presented (it\
    \ is noting that the ﬁgure and table provide the same information in\ndifferent\
    \ demonstration purposes).\nSensors 2018, 18, x FOR PEER REVIEW   \n24 of 31 \n\
     \nFigure 3. Presentation of machine learning (ML) models with their total rate. \n\
     \nFigure 4. The total number of ML models according to each sub‐category of the four main categories. \n\
    \ \n \nFigure 3. Presentation of machine learning (ML) models with their total\
    \ rate.\nSensors 2018, 18, x FOR PEER REVIEW   \n24 of 31 \n \nFigure 3. Presentation of machine learning (ML) models with their total rate. \n\
     \nFigure 4. The total number of ML models according to each sub‐category of the four main categories. \n\
    \ \n \nFigure 4. The total number of ML models according to each sub-category\
    \ of the four main categories.\nSensors 2018, 18, 2674\n23 of 29\nTable 14. The\
    \ total number of ML models according to each sub-category of the four main categories.\n\
    ML Models Per Section\nCrop\nLivestock\nWater\nSoil\nModel\nYield\nPrediction\n\
    Disease\nDetection\nWeed\nDetection\nCrop\nQuality\nSpecies\nRecognition\nAnimal\n\
    Welfare\nLivestock\nProduction\nWater\nManagement\nSoil\nManagement\nBayesian\n\
    models\n1\n1\nSupport\nvector\nmachines\n3\n3\n1\n3\n3\n1\nEnsemble\nlearning\n\
    1\n1\nArtiﬁcial &\nDeep\nneural\nnetworks\n3\n6\n2\n1\n2\n4\n4\nRegression\n1\n\
    1\nInstance\nbased\nmodels\n1\nDecision\ntrees\n1\nClustering\n1\n1\nTotal\n8\n\
    9\n4\n4\n1\n3\n5\n5\n7\nSensors 2018, 18, x FOR PEER REVIEW   \n25 of 31 \n \n\
    Table 14. The total number of ML models according to each sub‐category of the four main categories. \n\
    ML Models Per Section \nModel \nCrop \nLivestock \nWater \nSoil   \nYield \nPrediction \n\
    Disease \nDetection \nWeed \nDetection \nCrop \nQuality \nSpecies \nRecognition \n\
    Animal \nWelfare \nLivestock \nProduction \nWater \nManagement \nSoil \nManagement \n\
    Bayesian \nmodels \n1 \n  \n  \n  \n  \n1 \n  \n  \n  \nSupport vector \nmachines \n\
    3 \n3 \n1 \n3 \n  \n  \n3 \n  \n1 \nEnsemble \nlearning \n  \n  \n  \n1 \n  \n\
    1 \n  \n  \n  \nArtificial & \nDeep neural \nnetworks \n3 \n6 \n2 \n  \n1 \n  \n\
    2 \n4 \n4 \nRegression \n  \n  \n  \n  \n  \n  \n  \n1 \n1 \nInstance based \n\
    models \n  \n  \n  \n  \n  \n  \n  \n  \n1 \nDecision trees \n  \n  \n  \n  \n\
      \n1 \n  \n  \n  \nClustering \n1 \n  \n1 \n  \n  \n  \n  \n  \n  \nTotal \n\
    8 \n9 \n4 \n4 \n1 \n3 \n5 \n5 \n7 \n \nFigure  5.  Data  resources  usage  according \
    \ to  each  sub‐category.  NDVI—normalized  difference \nvegetation index; NIR—near infrared. \n\
    Table 15. Data resources usage according to each sub‐category. \nFeature Collection \n\
    Feature \nTechnique \nCrop \nLivestock \nWater \nSoil \nYield \nPrediction \n\
    Disease \nDetection \nWeed \nDetection \nCrop \nQuality \nSpecies \nrecognition \n\
    Animal \nWelfare \nLivestock \nProduction \nWater \nManagement \nSoil \nManagement \n\
    Digital images \nand color \nindexes \n4 \n3 \n1 \n  \n1 \n1 \n1 \n  \n  \nNIR \n\
    1 \n1 \n1 \n  \n  \n  \n  \n  \n  \nNDVI \n1 \n  \n  \n  \n  \n  \n  \n  \n  \n\
    Data records \n2 \n2 \n  \n1 \n  \n2 \n4 \n4 \n4 \nSpectral \n  \n2 \n2 \n  \n\
      \n  \n  \n  \n  \nHyperspectral \n  \n4 \n1 \n2 \n  \n  \n  \n  \n  \nFluoresence \n\
      \n2 \n  \n  \n  \n  \n  \n  \n  \n \n \nFigure 5.\nData resources usage according\
    \ to each sub-category.\nNDVI—normalized difference\nvegetation index; NIR—near\
    \ infrared.\nTable 15. Data resources usage according to each sub-category.\n\
    Feature Collection\nCrop\nLivestock\nWater\nSoil\nFeature\nTechnique\nYield\n\
    Prediction\nDisease\nDetection\nWeed\nDetection\nCrop\nQuality\nSpecies\nrecognition\n\
    Animal\nWelfare\nLivestock\nProduction\nWater\nManagement\nSoil\nManagement\n\
    Digital\nimages and\ncolor\nindexes\n4\n3\n1\n1\n1\n1\nNIR\n1\n1\n1\nNDVI\n1\n\
    Data records\n2\n2\n1\n2\n4\n4\n4\nSpectral\n2\n2\nHyperspectral\n4\n1\n2\nFluoresence\n\
    2\nSensors 2018, 18, 2674\n24 of 29\nFrom the above ﬁgures and tables, we show\
    \ that ML models have been applied in multiple\napplications for crop management\
    \ (61%); mostly yield prediction (20%) and disease detection (22%).\nThis trend\
    \ in the applications distribution reﬂects the data intense applications within\
    \ crop and\nhigh use of images (spectral, hyperspectral, NIR, etc.). Data analysis,\
    \ as a mature scientiﬁc ﬁeld,\nprovides the ground for the development of numerous\
    \ applications related to crop management\nbecause, in most cases, ML-based predictions\
    \ can be extracted without the need for fusion of data from\nother resources.\
    \ In contrast, when data recordings are involved, occasionally at the level of\
    \ big data,\nthe implementations of ML are less in number, mainly because of the\
    \ increased efforts required for\nthe data analysis task and not for the ML models\
    \ per se. This fact partially explains the almost equal\ndistribution of ML applications\
    \ in livestock management (19%), water management (10%), and soil\nmanagement\
    \ (10%). It is also evident from the analysis that most of the studies used ANN\
    \ and SVM\nML models. More speciﬁcally, ANNs were used mostly for implementations\
    \ in crop, water, and soil\nmanagement, while SVMs were used mostly for livestock\
    \ management.\nBy applying machine learning to sensor data, farm management systems\
    \ are evolving into real\nartiﬁcial intelligence systems, providing richer recommendations\
    \ and insights for the subsequent\ndecisions and actions with the ultimate scope\
    \ of production improvement. For this scope, in the future,\nit is expected that\
    \ the usage of ML models will be even more widespread, allowing for the possibility\n\
    of integrated and applicable tools. At the moment, all of the approaches regard\
    \ individual approaches\nand solutions and are not adequately connected with the\
    \ decision-making process, as seen in other\napplication domains. This integration\
    \ of automated data recording, data analysis, ML implementation,\nand decision-making\
    \ or support will provide practical tolls that come in line with the so-called\n\
    knowledge-based agriculture for increasing production levels and bio-products\
    \ quality.\nAuthor Contributions: Writing-Original Draft Preparation, K.G.L.,\
    \ D.B. and P.B.; Methodology, D.M., S.P.\nand P.B.; Investigation, K.G.L. and\
    \ D.M.; Conceptualization D.B. and D.M.; Writing-Review & Editing, S.P.;\nSupervision,\
    \ D.B.\nFunding: This review work was partly supported by the project “Research\
    \ Synergy to address major challenges\nin the nexus: energy–environment–agricultural\
    \ production (Food, Water, Materials)”—NEXUS, funded by the\nGreek Secretariat\
    \ for Research and Technology (GSRT)—Pr. No. MIS 5002496.\nConﬂicts of Interest:\
    \ The authors declare no conﬂict of interest.\nReferences\n1.\nSamuel, A.L. Some\
    \ Studies in Machine Learning Using the Game of Checkers. IBM J. Res. Dev. 1959,\
    \ 44,\n206–226. [CrossRef]\n2.\nKong, L.; Zhang, Y.; Ye, Z.Q.; Liu, X.Q.; Zhao,\
    \ S.Q.; Wei, L.; Gao, G. CPC: Assess the protein-coding potential\nof transcripts\
    \ using sequence features and support vector machine. Nucleic Acids Res. 2007,\
    \ 35, 345–349.\n[CrossRef] [PubMed]\n3.\nMackowiak, S.D.; Zauber, H.; Bielow,\
    \ C.; Thiel, D.; Kutz, K.; Calviello, L.; Mastrobuoni, G.; Rajewsky, N.;\nKempa,\
    \ S.; Selbach, M.; et al. Extensive identiﬁcation and analysis of conserved small\
    \ ORFs in animals.\nGenome Biol. 2015, 16, 179. [CrossRef] [PubMed]\n4.\nRichardson,\
    \ A.; Signor, B.M.; Lidbury, B.A.; Badrick, T. Clinical chemistry in higher dimensions:\n\
    Machine-learning and enhanced prediction from routine clinical chemistry data.\
    \ Clin. Biochem. 2016,\n49, 1213–1220. [CrossRef] [PubMed]\n5.\nWildenhain, J.;\
    \ Spitzer, M.; Dolma, S.; Jarvik, N.; White, R.; Roy, M.; Grifﬁths, E.; Bellows,\
    \ D.S.; Wright, G.D.;\nTyers, M. Prediction of Synergism from Chemical-Genetic\
    \ Interactions by Machine Learning. Cell Syst. 2015,\n1, 383–395. [CrossRef] [PubMed]\n\
    6.\nKang, J.; Schwartz, R.; Flickinger, J.; Beriwal, S. Machine learning approaches\
    \ for predicting radiation therapy\noutcomes: A clinician’s perspective. Int.\
    \ J. Radiat. Oncol. Biol. Phys. 2015, 93, 1127–1135. [CrossRef]\n[PubMed]\n7.\n\
    Asadi, H.; Dowling, R.; Yan, B.; Mitchell, P. Machine learning for outcome prediction\
    \ of acute ischemic stroke\npost intra-arterial therapy. PLoS ONE 2014, 9, e88225.\
    \ [CrossRef] [PubMed]\nSensors 2018, 18, 2674\n25 of 29\n8.\nZhang, B.; He, X.;\
    \ Ouyang, F.; Gu, D.; Dong, Y.; Zhang, L.; Mo, X.; Huang, W.; Tian, J.; Zhang,\
    \ S. Radiomic\nmachine-learning classiﬁers for prognostic biomarkers of advanced\
    \ nasopharyngeal carcinoma. Cancer Lett.\n2017, 403, 21–27. [CrossRef] [PubMed]\n\
    9.\nCramer, S.; Kampouridis, M.; Freitas, A.A.; Alexandridis, A.K. An extensive\
    \ evaluation of seven machine\nlearning methods for rainfall prediction in weather\
    \ derivatives. Expert Syst. Appl. 2017, 85, 169–181.\n[CrossRef]\n10.\nRhee, J.;\
    \ Im, J. Meteorological drought forecasting for ungauged areas based on machine\
    \ learning: Using\nlong-range climate forecast and remote sensing data. Agric.\
    \ For. Meteorol. 2017, 237–238, 105–122. [CrossRef]\n11.\nAybar-Ruiz, A.;\nJiménez-Fernández,\
    \ S.;\nCornejo-Bueno, L.;\nCasanova-Mateo, C.;\nSanz-Justo, J.;\nSalvador-González,\
    \ P.; Salcedo-Sanz, S. A novel Grouping Genetic Algorithm-Extreme Learning Machine\n\
    approach for global solar radiation prediction from numerical weather models inputs.\
    \ Sol. Energy 2016, 132,\n129–142. [CrossRef]\n12.\nBarboza, F.; Kimura, H.; Altman,\
    \ E. Machine learning models and bankruptcy prediction. Expert Syst. Appl.\n2017,\
    \ 83, 405–417. [CrossRef]\n13.\nZhao, Y.; Li, J.; Yu, L. A deep learning ensemble\
    \ approach for crude oil price forecasting. Energy Econ. 2017,\n66, 9–16. [CrossRef]\n\
    14.\nBohanec, M.; Kljaji´c Borštnar, M.; Robnik-Šikonja, M. Explaining machine\
    \ learning models in sales predictions.\nExpert Syst. Appl. 2017, 71, 416–428.\
    \ [CrossRef]\n15.\nTakahashi, K.; Kim, K.; Ogata, T.; Sugano, S. Tool-body assimilation\
    \ model considering grasping motion\nthrough deep learning. Rob. Auton. Syst.\
    \ 2017, 91, 115–127. [CrossRef]\n16.\nGastaldo, P.; Pinna, L.; Seminara, L.; Valle,\
    \ M.; Zunino, R. A tensor-based approach to touch modality\nclassiﬁcation by using\
    \ machine learning. Rob. Auton. Syst. 2015, 63, 268–278. [CrossRef]\n17.\nLópez-Cortés,\
    \ X.A.; Nachtigall, F.M.; Olate, V.R.; Araya, M.; Oyanedel, S.; Diaz, V.; Jakob,\
    \ E.;\nRíos-Momberg, M.; Santos, L.S. Fast detection of pathogens in salmon farming\
    \ industry. Aquaculture\n2017, 470, 17–24. [CrossRef]\n18.\nZhou, C.; Lin, K.;\
    \ Xu, D.; Chen, L.; Guo, Q.; Sun, C.; Yang, X. Near infrared computer vision and\
    \ neuro-fuzzy\nmodel-based feeding decision system for ﬁsh in aquaculture. Comput.\
    \ Electron. Agric. 2018, 146, 114–124.\n[CrossRef]\n19.\nFragni, R.; Triﬁrò, A.;\
    \ Nucci, A.; Seno, A.; Allodi, A.; Di Rocco, M. Italian tomato-based products\n\
    authentication by multi-element approach: A mineral elements database to distinguish\
    \ the domestic\nprovenance. Food Control 2018, 93, 211–218. [CrossRef]\n20.\n\
    Maione, C.; Barbosa, R.M. Recent applications of multivariate data analysis methods\
    \ in the authentication of\nrice and the most analyzed parameters: A review. Crit.\
    \ Rev. Food Sci. Nutr. 2018, 1–12. [CrossRef] [PubMed]\n21.\nFang, K.; Shen, C.;\
    \ Kifer, D.; Yang, X. Prolongation of SMAP to Spatiotemporally Seamless Coverage\
    \ of\nContinental U.S. Using a Deep Learning Neural Network. Geophys. Res. Lett.\
    \ 2017, 44, 11030–11039.\n[CrossRef]\n22.\nPearson, K. On lines and planes of\
    \ closest ﬁt to systems of points in space. Lond. Edinb. Dublin Philos. Mag.\n\
    J. Sci. 1901, 2, 559–572. [CrossRef]\n23.\nWold, H. Partial Least Squares. In\
    \ Encyclopedia of Statistical Sciences; John Wiley & Sons: Chichester, NY, USA,\n\
    1985; Volume 6, pp. 581–591, ISBN 9788578110796.\n24.\nFisher, R.A. The use of\
    \ multiple measures in taxonomic problems. Ann. Eugen. 1936, 7, 179–188. [CrossRef]\n\
    25.\nCox, D.R. The Regression Analysis of Binary Sequences. J. R. Stat. Soc. Ser.\
    \ B 1958, 20, 215–242. [CrossRef]\n26.\nEfroymson, M.A. Multiple regression analysis.\
    \ Math. Methods Digit. Comput. 1960, 1, 191–203. [CrossRef]\n27.\nCraven, B.D.;\
    \ Islam, S.M.N. Ordinary least-squares regression. SAGE Dict. Quant. Manag. Res.\
    \ 2011, 224–228.\n28.\nFriedman, J.H. Multivariate Adaptive Regression Splines.\
    \ Ann. Stat. 1991, 19, 1–67. [CrossRef]\n29.\nQuinlan, J.R. Learning with continuous\
    \ classes. Mach. Learn. 1992, 92, 343–348.\n30.\nCleveland, W.S. Robust locally\
    \ weighted regression and smoothing scatterplots. J. Am. Stat. Assoc. 1979, 74,\n\
    829–836. [CrossRef]\n31.\nTryon, R.C. Communality of a variable: Formulation by\
    \ cluster analysis. Psychometrika 1957, 22, 241–260.\n[CrossRef]\n32.\nLloyd,\
    \ S.P. Least Squares Quantization in PCM. IEEE Trans. Inf. Theory 1982, 28, 129–137.\
    \ [CrossRef]\n33.\nJohnson, S.C. Hierarchical clustering schemes. Psychometrika\
    \ 1967, 32, 241–254. [CrossRef] [PubMed]\nSensors 2018, 18, 2674\n26 of 29\n34.\n\
    Dempster, A.P.; Laird, N.M.; Rubin, D.B. Maximum likelihood from incomplete data\
    \ via the EM algorithm.\nJ. R. Stat. Soc. Ser. B Methodol. 1977, 39, 1–38. [CrossRef]\n\
    35.\nRussell, S.J.; Norvig, P. Artiﬁcial Intelligence: A Modern Approach; Prentice\
    \ Hall: Upper Saddle River, NJ, USA,\n1995; Volume 9, ISBN 9780131038059.\n36.\n\
    Pearl, J. Probabilistic Reasoning in Intelligent Systems. Morgan Kauffmann San\
    \ Mateo 1988, 88, 552.\n37.\nDuda, R.O.; Hart, P.E. Pattern Classiﬁcation and\
    \ Scene Analysis; Wiley: Hoboken, NJ, USA, 1973; Volume 7,\nISBN 0471223611.\n\
    38.\nNeapolitan, R.E. Models for reasoning under uncertainty. Appl. Artif. Intell.\
    \ 1987, 1, 337–366. [CrossRef]\n39.\nFix, E.; Hodges, J.L. Discriminatory Analysis–Nonparametric\
    \ discrimination consistency properties.\nInt. Stat. Rev. 1951, 57, 238–247. [CrossRef]\n\
    40.\nAtkeson, C.G.; Moorey, A.W.; Schaalz, S.; Moore, A.W.; Schaal, S. Locally\
    \ Weighted Learning. Artif. Intell.\n1997, 11, 11–73. [CrossRef]\n41.\nKohonen,\
    \ T. Learning vector quantization. Neural Netw. 1988, 1, 303. [CrossRef]\n42.\n\
    Belson, W.A. Matching and Prediction on the Principle of Biological Classiﬁcation.\
    \ Appl. Stat. 1959, 8, 65–75.\n[CrossRef]\n43.\nBreiman, L.; Friedman, J.H.; Olshen,\
    \ R.A.; Stone, C.J. Classiﬁcation and Regression Trees; Routledge: Abingdon,\n\
    UK, 1984; Volume 19, ISBN 0412048418.\n44.\nKass, G.V. An Exploratory Technique\
    \ for Investigating Large Quantities of Categorical Data. Appl. Stat. 1980,\n\
    29, 119. [CrossRef]\n45.\nQuinlan, J.R. C4.5: Programs for Machine Learning; Morgan\
    \ Kaufmann Publishers Inc.: San Francisco, CA,\nUSA, 1992; Volume 1, ISBN 1558602380.\n\
    46.\nMcCulloch, W.S.; Pitts, W. A logical calculus of the ideas immanent in nervous\
    \ activity. Bull. Math. Biophys.\n1943, 5, 115–133. [CrossRef]\n47.\nBroomhead,\
    \ D.S.; Lowe, D. Multivariable Functional Interpolation and Adaptive Networks.\
    \ Complex Syst.\n1988, 2, 321–355.\n48.\nRosenblatt, F. The perceptron: A probabilistic\
    \ model for information storage and organization in the brain.\nPsychol. Rev.\
    \ 1958, 65, 386–408. [CrossRef] [PubMed]\n49.\nLinnainmaa, S. Taylor expansion\
    \ of the accumulated rounding error. BIT 1976, 16, 146–160. [CrossRef]\n50.\n\
    Riedmiller, M.; Braun, H. A direct adaptive method for faster backpropagation\
    \ learning: The RPROP\nalgorithm. In Proceedings of the IEEE International Conference\
    \ on Neural Networks, San Francisco, CA,\nUSA, 28 March–1 April 1993; pp. 586–591.\
    \ [CrossRef]\n51.\nHecht-Nielsen, R. Counterpropagation networks. Appl. Opt. 1987,\
    \ 26, 4979–4983. [CrossRef] [PubMed]\n52.\nJang, J.S.R. ANFIS: Adaptive-Network-Based\
    \ Fuzzy Inference System. IEEE Trans. Syst. Man Cybern. 1993,\n23, 665–685. [CrossRef]\n\
    53.\nMelssen, W.; Wehrens, R.; Buydens, L. Supervised Kohonen networks for classiﬁcation\
    \ problems.\nChemom. Intell. Lab. Syst. 2006, 83, 99–113. [CrossRef]\n54.\nHopﬁeld,\
    \ J.J. Neural networks and physical systems with emergent collective computational\
    \ abilities.\nProc. Natl. Acad. Sci. USA 1982, 79, 2554–2558. [CrossRef] [PubMed]\n\
    55.\nPal, S.K.; Mitra, S. Multilayer Perceptron, Fuzzy Sets, and Classiﬁcation.\
    \ IEEE Trans. Neural Netw. 1992, 3,\n683–697. [CrossRef] [PubMed]\n56.\nKohonen,\
    \ T. The Self-Organizing Map. Proc. IEEE 1990, 78, 1464–1480. [CrossRef]\n57.\n\
    Huang, G.-B.; Zhu, Q.-Y.; Siew, C.-K. Extreme learning machine: Theory and applications.\
    \ Neurocomputing\n2006, 70, 489–501. [CrossRef]\n58.\nSpecht, D.F. A general regression\
    \ neural network. IEEE Trans. Neural Netw. 1991, 2, 568–576. [CrossRef]\n[PubMed]\n\
    59.\nCao, J.; Lin, Z.; Huang, G. Bin Self-adaptive evolutionary extreme learning\
    \ machine. Neural Process. Lett.\n2012, 36, 285–305. [CrossRef]\n60.\nLeCun, Y.;\
    \ Bengio, Y.; Hinton, G. Deep learning. Nature 2015, 521, 436–444. [CrossRef]\
    \ [PubMed]\n61.\nGoodfellow, I.; Bengio, Y.; Courville, A. Deep Learning; MIT\
    \ Press: Cambridge, MA, USA, 2016; pp. 216–261.\n62.\nSalakhutdinov, R.; Hinton,\
    \ G. Deep Boltzmann Machines. Aistats 2009, 1, 448–455. [CrossRef]\n63.\nVincent,\
    \ P.; Larochelle, H.; Lajoie, I.; Bengio, Y.; Manzagol, P.-A. Stacked Denoising\
    \ Autoencoders: Learning\nUseful Representations in a Deep Network with a Local\
    \ Denoising Criterion Pierre-Antoine Manzagol.\nJ. Mach. Learn. Res. 2010, 11,\
    \ 3371–3408. [CrossRef]\nSensors 2018, 18, 2674\n27 of 29\n64.\nVapnik, V. Support\
    \ vector machine. Mach. Learn. 1995, 20, 273–297.\n65.\nSuykens, J.A.K.; Vandewalle,\
    \ J. Least Squares Support Vector Machine Classiﬁers. Neural Process. Lett. 1999,\n\
    9, 293–300. [CrossRef]\n66.\nChang, C.; Lin, C. LIBSVM: A Library for Support\
    \ Vector Machines. ACM Trans. Intell. Syst. Technol. 2013, 2,\n1–39. [CrossRef]\n\
    67.\nSmola, A. Regression Estimation with Support Vector Learning Machines. Master’s\
    \ Thesis, The Technical\nUniversity of Munich, Munich, Germany, 1996; pp. 1–78.\n\
    68.\nSuykens, J.A.K.; Van Gestel, T.; De Brabanter, J.; De Moor, B.; Vandewalle,\
    \ J. Least Squares Support Vector\nMachines; World Scientiﬁc: Singapore, 2002;\
    \ ISBN 9812381511.\n69.\nGalvão, R.K.H.; Araújo, M.C.U.; Fragoso, W.D.; Silva,\
    \ E.C.; José, G.E.; Soares, S.F.C.; Paiva, H.M. A variable\nelimination method\
    \ to improve the parsimony of MLR models using the successive projections algorithm.\n\
    Chemom. Intell. Lab. Syst. 2008, 92, 83–91. [CrossRef]\n70.\nBreiman, L. Random\
    \ Forests. Mach. Learn. 2001, 45, 5–32. [CrossRef]\n71.\nSchapire, R.E. A brief\
    \ introduction to boosting. In Proceedings of the IJCAI International Joint Conference\n\
    on Artiﬁcial Intelligence, Stockholm, Sweden, 31 July–6 August 1999; Volume 2,\
    \ pp. 1401–1406.\n72.\nFreund, Y.; Schapire, R.E. Experiments with a New Boosting\
    \ Algorithm. In Proceedings of the Thirteenth\nInternational Conference on International\
    \ Conference on Machine Learning, Bari, Italy, 3–6 July 1996; Morgan\nKaufmann\
    \ Publishers Inc.: San Francisco, CA, USA, 1996; pp. 148–156.\n73.\nBreiman, L.\
    \ Bagging Predictors. Mach. Learn. 1996, 24, 123–140. [CrossRef]\n74.\nRamos,\
    \ P.J.; Prieto, F.A.; Montoya, E.C.; Oliveros, C.E. Automatic fruit count on coffee\
    \ branches using\ncomputer vision. Comput. Electron. Agric. 2017, 137, 9–22. [CrossRef]\n\
    75.\nAmatya, S.; Karkee, M.; Gongal, A.; Zhang, Q.; Whiting, M.D. Detection of\
    \ cherry tree branches with full\nfoliage in planar architecture for automated\
    \ sweet-cherry harvesting. Biosyst. Eng. 2015, 146, 3–15. [CrossRef]\n76.\nSengupta,\
    \ S.; Lee, W.S. Identiﬁcation and determination of the number of immature green\
    \ citrus fruit in a\ncanopy under different ambient light conditions. Biosyst.\
    \ Eng. 2014, 117, 51–61. [CrossRef]\n77.\nAli, I.; Cawkwell, F.; Dwyer, E.; Green,\
    \ S. Modeling Managed Grassland Biomass Estimation by Using\nMultitemporal Remote\
    \ Sensing Data—A Machine Learning Approach. IEEE J. Sel. Top. Appl. Earth Obs.\n\
    Remote Sens. 2016, 10, 3254–3264. [CrossRef]\n78.\nPantazi, X.-E.; Moshou, D.;\
    \ Alexandridis, T.K.; Whetton, R.L.; Mouazen, A.M. Wheat yield prediction using\n\
    machine learning and advanced sensing techniques. Comput. Electron. Agric. 2016,\
    \ 121, 57–65. [CrossRef]\n79.\nSenthilnath, J.; Dokania, A.; Kandukuri, M.; Ramesh,\
    \ K.N.; Anand, G.; Omkar, S.N. Detection of tomatoes\nusing spectral-spatial methods\
    \ in remotely sensed RGB images captured by UAV. Biosyst. Eng. 2016, 146,\n16–32.\
    \ [CrossRef]\n80.\nSu, Y.; Xu, H.; Yan, L. Support vector machine-based open crop\
    \ model (SBOCM): Case of rice production in\nChina. Saudi J. Biol. Sci. 2017,\
    \ 24, 537–547. [CrossRef] [PubMed]\n81.\nKung, H.-Y.; Kuo, T.-H.; Chen, C.-H.;\
    \ Tsai, P.-Y. Accuracy Analysis Mechanism for Agriculture Data Using\nthe Ensemble\
    \ Neural Network Method. Sustainability 2016, 8, 735. [CrossRef]\n82.\nPantazi,\
    \ X.E.; Tamouridou, A.A.; Alexandridis, T.K.; Lagopodi, A.L.; Kontouris, G.; Moshou,\
    \ D.\nDetection of Silybum marianum infection with Microbotryum silybum using\
    \ VNIR ﬁeld spectroscopy.\nComput. Electron. Agric. 2017, 137, 130–137. [CrossRef]\n\
    83.\nEbrahimi, M.A.; Khoshtaghaza, M.H.; Minaei, S.; Jamshidi, B. Vision-based\
    \ pest detection based on SVM\nclassiﬁcation method. Comput. Electron. Agric.\
    \ 2017, 137, 52–58. [CrossRef]\n84.\nChung, C.L.; Huang, K.J.; Chen, S.Y.; Lai,\
    \ M.H.; Chen, Y.C.; Kuo, Y.F. Detecting Bakanae disease in rice\nseedlings by\
    \ machine vision. Comput. Electron. Agric. 2016, 121, 404–411. [CrossRef]\n85.\n\
    Pantazi, X.E.; Moshou, D.; Oberti, R.; West, J.; Mouazen, A.M.; Bochtis, D. Detection\
    \ of biotic and abiotic\nstresses in crops by using hierarchical self organizing\
    \ classiﬁers. Precis. Agric. 2017, 18, 383–393. [CrossRef]\n86.\nMoshou, D.; Pantazi,\
    \ X.-E.; Kateris, D.; Gravalos, I. Water stress detection based on optical multisensor\n\
    fusion with a least squares support vector machine classiﬁer. Biosyst. Eng. 2014,\
    \ 117, 15–22. [CrossRef]\n87.\nMoshou, D.; Bravo, C.; West, J.; Wahlen, S.; McCartney,\
    \ A.; Ramon, H. Automatic detection of “yellow rust”\nin wheat using reﬂectance\
    \ measurements and neural networks. Comput. Electron. Agric. 2004, 44, 173–188.\n\
    [CrossRef]\nSensors 2018, 18, 2674\n28 of 29\n88.\nMoshou, D.; Bravo, C.; Oberti,\
    \ R.; West, J.; Bodria, L.; McCartney, A.; Ramon, H. Plant disease detection\n\
    based on data fusion of hyper-spectral and multi-spectral ﬂuorescence imaging\
    \ using Kohonen maps.\nReal-Time Imaging 2005, 11, 75–83. [CrossRef]\n89.\nMoshou,\
    \ D.; Bravo, C.; Wahlen, S.; West, J.; McCartney, A.; De Baerdemaeker, J.; Ramon,\
    \ H. Simultaneous\nidentiﬁcation of plant stresses and diseases in arable crops\
    \ using proximal optical sensing and self-organising\nmaps. Precis. Agric. 2006,\
    \ 7, 149–164. [CrossRef]\n90.\nFerentinos, K.P. Deep learning models for plant\
    \ disease detection and diagnosis. Comput. Electron. Agric.\n2018, 145, 311–318.\
    \ [CrossRef]\n91.\nPantazi, X.E.; Tamouridou, A.A.; Alexandridis, T.K.; Lagopodi,\
    \ A.L.; Kashefi, J.; Moshou, D. Evaluation of\nhierarchical self-organising maps\
    \ for weed mapping using UAS multispectral imagery. Comput. Electron. Agric.\n\
    2017, 139, 224–230. [CrossRef]\n92.\nPantazi, X.-E.; Moshou, D.; Bravo, C. Active\
    \ learning system for weed species recognition based on\nhyperspectral sensing.\
    \ Biosyst. Eng. 2016, 146, 193–202. [CrossRef]\n93.\nBinch, A.; Fox, C.W. Controlled\
    \ comparison of machine vision algorithms for Rumex and Urtica detection in\n\
    grassland. Comput. Electron. Agric. 2017, 140, 123–138. [CrossRef]\n94.\nZhang,\
    \ M.; Li, C.; Yang, F. Classiﬁcation of foreign matter embedded inside cotton\
    \ lint using short wave\ninfrared (SWIR) hyperspectral transmittance imaging.\
    \ Comput. Electron. Agric. 2017, 139, 75–90. [CrossRef]\n95.\nHu, H.; Pan, L.;\
    \ Sun, K.; Tu, S.; Sun, Y.; Wei, Y.; Tu, K. Differentiation of deciduous-calyx\
    \ and persistent-calyx\npears using hyperspectral reﬂectance imaging and multivariate\
    \ analysis. Comput. Electron. Agric. 2017, 137,\n150–156. [CrossRef]\n96.\nMaione,\
    \ C.; Batista, B.L.; Campiglia, A.D.; Barbosa, F.; Barbosa, R.M. Classiﬁcation\
    \ of geographic origin of\nrice by data mining and inductively coupled plasma\
    \ mass spectrometry. Comput. Electron. Agric. 2016, 121,\n101–107. [CrossRef]\n\
    97.\nGrinblat, G.L.; Uzal, L.C.; Larese, M.G.; Granitto, P.M. Deep learning for\
    \ plant identiﬁcation using vein\nmorphological patterns. Comput. Electron. Agric.\
    \ 2016, 127, 418–424. [CrossRef]\n98.\nDutta, R.; Smith, D.; Rawnsley, R.; Bishop-Hurley,\
    \ G.; Hills, J.; Timms, G.; Henry, D. Dynamic cattle\nbehavioural classiﬁcation\
    \ using supervised ensemble classiﬁers. Comput. Electron. Agric. 2015, 111, 18–28.\n\
    [CrossRef]\n99.\nPegorini, V.; Karam, L.Z.; Pitta, C.S.R.; Cardoso, R.; da Silva,\
    \ J.C.C.; Kalinowski, H.J.; Ribeiro, R.; Bertotti, F.L.;\nAssmann, T.S. In vivo\
    \ pattern classiﬁcation of ingestive behavior in ruminants using FBG sensors and\n\
    machine learning. Sensors 2015, 15, 28456–28471. [CrossRef] [PubMed]\n100. Matthews,\
    \ S.G.; Miller, A.L.; PlÖtz, T.; Kyriazakis, I. Automated tracking to measure\
    \ behavioural changes in\npigs for health and welfare monitoring. Sci. Rep. 2017,\
    \ 7, 17582. [CrossRef] [PubMed]\n101. Craninx, M.; Fievez, V.; Vlaeminck, B.;\
    \ De Baets, B. Artiﬁcial neural network models of the rumen\nfermentation pattern\
    \ in dairy cattle. Comput. Electron. Agric. 2008, 60, 226–238. [CrossRef]\n102.\
    \ Morales, I.R.; Cebrián, D.R.; Fernandez-Blanco, E.; Sierra, A.P. Early warning\
    \ in egg production curves from\ncommercial hens: A SVM approach. Comput. Electron.\
    \ Agric. 2016, 121, 169–179. [CrossRef]\n103. Alonso, J.; Villa, A.; Bahamonde,\
    \ A. Improved estimation of bovine weight trajectories using Support Vector\n\
    Machine Classiﬁcation. Comput. Electron. Agric. 2015, 110, 36–41. [CrossRef]\n\
    104. Alonso, J.; Castañón, Á.R.; Bahamonde, A. Support Vector Regression to predict\
    \ carcass weight in beef cattle\nin advance of the slaughter. Comput. Electron.\
    \ Agric. 2013, 91, 116–120. [CrossRef]\n105. Hansen, M.F.; Smith, M.L.; Smith,\
    \ L.N.; Salter, M.G.; Baxter, E.M.; Farish, M.; Grieve, B. Towards on-farm pig\n\
    face recognition using convolutional neural networks. Comput. Ind. 2018, 98, 145–152.\
    \ [CrossRef]\n106. Mehdizadeh, S.; Behmanesh, J.; Khalili, K. Using MARS, SVM,\
    \ GEP and empirical equations for estimation\nof monthly mean reference evapotranspiration.\
    \ Comput. Electron. Agric. 2017, 139, 103–114. [CrossRef]\n107. Feng, Y.; Peng,\
    \ Y.; Cui, N.; Gong, D.; Zhang, K. Modeling reference evapotranspiration using\
    \ extreme learning\nmachine and generalized regression neural network only with\
    \ temperature data. Comput. Electron. Agric.\n2017, 136, 71–78. [CrossRef]\n108.\
    \ Patil, A.P.; Deka, P.C. An extreme learning machine approach for modeling evapotranspiration\
    \ using extrinsic\ninputs. Comput. Electron. Agric. 2016, 121, 385–392. [CrossRef]\n\
    109. Mohammadi, K.; Shamshirband, S.; Motamedi, S.; Petkovi´c, D.; Hashim, R.;\
    \ Gocic, M. Extreme learning\nmachine based prediction of daily dew point temperature.\
    \ Comput. Electron. Agric. 2015, 117, 214–225.\n[CrossRef]\nSensors 2018, 18,\
    \ 2674\n29 of 29\n110. Coopersmith, E.J.; Minsker, B.S.; Wenzel, C.E.; Gilmore,\
    \ B.J. Machine learning assessments of soil drying for\nagricultural planning.\
    \ Comput. Electron. Agric. 2014, 104, 93–104. [CrossRef]\n111. Morellos, A.; Pantazi,\
    \ X.-E.; Moshou, D.; Alexandridis, T.; Whetton, R.; Tziotzios, G.; Wiebensohn,\
    \ J.; Bill, R.;\nMouazen, A.M. Machine learning based prediction of soil total\
    \ nitrogen, organic carbon and moisture\ncontent by using VIS-NIR spectroscopy.\
    \ Biosyst. Eng. 2016, 152, 104–116. [CrossRef]\n112. Nahvi, B.; Habibi, J.; Mohammadi,\
    \ K.; Shamshirband, S.; Al Razgan, O.S. Using self-adaptive evolutionary\nalgorithm\
    \ to improve the performance of an extreme learning machine for estimating soil\
    \ temperature.\nComput. Electron. Agric. 2016, 124, 150–160. [CrossRef]\n113.\
    \ Johann, A.L.; de Araújo, A.G.; Delalibera, H.C.; Hirakawa, A.R. Soil moisture\
    \ modeling based on stochastic\nbehavior of forces on a no-till chisel opener.\
    \ Comput. Electron. Agric. 2016, 121, 420–428. [CrossRef]\n© 2018 by the authors.\
    \ Licensee MDPI, Basel, Switzerland. This article is an open access\narticle distributed\
    \ under the terms and conditions of the Creative Commons Attribution\n(CC BY)\
    \ license (http://creativecommons.org/licenses/by/4.0/).\n"
  inline_citation: '>'
  journal: Sensors (Basel)
  limitations: '>'
  pdf_link: https://www.mdpi.com/1424-8220/18/8/2674/pdf?version=1534247979
  publication_year: 2018
  relevance_score1: 0
  relevance_score2: 0
  title: 'Machine Learning in Agriculture: A Review'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1109/ingarss51564.2021.9791948
  analysis: '>'
  authors:
  - Adduru U G Sankararao
  - Gattu Priyanka
  - P. Rajalakshmi
  - Sunitha Choudhary
  citation_count: 1
  full_citation: '>'
  full_text: '>

    This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences Loading
    [MathJax]/extensions/MathMenu.js IEEE.org IEEE Xplore IEEE SA IEEE Spectrum More
    Sites Donate Cart Create Account Personal Sign In Browse My Settings Help Access
    provided by: University of Nebraska - Lincoln Sign Out All Books Conferences Courses
    Journals & Magazines Standards Authors Citations ADVANCED SEARCH Conferences >2021
    IEEE International India... CNN Based Water Stress Detection in Chickpea Using
    UAV Based Hyperspectral Imaging Publisher: IEEE Cite This PDF Adduru U G Sankararao;
    Gattu Priyanka; P. Rajalakshmi; Sunitha Choudhary All Authors 1 Cites in Paper
    149 Full Text Views Abstract Document Sections I. INTRODUCTION II. EXPERIMENT
    AND DATA ACQUISITION III. 3D-2D CNN MODEL FRAMEWORK IV. RESULTS AND DISCUSSION
    V. CONCLUSION Authors Figures References Citations Keywords Metrics Abstract:
    Water is an important agronomic input, which plays a vital role in the health
    and yield of the crop. Water deficiency results in abiotic stress, early detection
    of water stress help in recovering the health of the crop. Hyperspectral imaging
    (HSI) sensors acquire rich spectral information of the objects in hundreds of
    narrow bands, are capable of identifying the change in canopy water content, which
    is crucial in predicting irrigation requirements of the crop. Due to the wide
    field of coverages, short revisiting periods, and high spectral resolutions, Unmanned
    Aerial Vehicle (UAV) based HSI techniques are suitable in precision agriculture.
    In this paper, water stress detection in chickpea canopy is presented using hyperspectral
    (HS) images acquired from UAV. The drought classification was performed in two
    ways, i. by considering selected water-sensitive bands, and ii. by considering
    the whole spectral bands of the HS images. A 3D-2D convolutional neural network
    (CNN) model is used to classify well-watered canopy from water-stressed one, and
    its performance is compared with that of a Support Vector Machine (SVM) and a
    2D+1D CNN model in identifying water stress. We obtained the best classification
    accuracy of 95.44%, which shows the potential of HSI in successfully detecting
    water stress in chickpea. Published in: 2021 IEEE International India Geoscience
    and Remote Sensing Symposium (InGARSS) Date of Conference: 06-10 December 2021
    Date Added to IEEE Xplore: 13 June 2022 ISBN Information: DOI: 10.1109/InGARSS51564.2021.9791948
    Publisher: IEEE Conference Location: Ahmedabad, India SECTION I. INTRODUCTION
    Recently, the demand for food production is increasing with the rapid increase
    in the world’s population, hence there is a need for increasing the production
    in the agriculture sector [1]. The quantity and quality of crop production highly
    depend on the health of the crop, which is, in turn, depends on the soil nutrients,
    rainfall, etc. The decrease in rainfall in the last decade forcing the farmers
    to depend on groundwater to meet the irrigation requirements of the crop. Worldwide
    around 70% of the water is used for agriculture needs. The crop undergoes stress
    when it is not sufficiently irrigated, and it develops physiological changes under
    stress. The early detection of drought stress help in recovering the health of
    the crop. In plant phenotyping, agriculture scientists are working in developing
    new plant cultivars, which will be tolerant to stress conditions and produce high
    yields. But the challenge in phenotypic studies is the assessment of thousands
    of genetic lines under field conditions. The traditional methods used for stress
    identification and phenotypic studies are laborious, time-consuming, destructive,
    faulty, and not standardized. Different imaging techniques such as RGB, multispectral,
    HSI are effective in studying the behavior of crops under stress. However, the
    rich spectral information captured by HSI sensors in hundreds of narrow spectral
    bands is capable of identifying the change in canopy water content which is crucial
    in predicting irrigation requirements [2]. Due to the wide field of coverages,
    short revisiting periods, and high spatial resolutions, UAV-based imaging techniques
    are most suitable in precision agriculture [2]. Researchers found that Chickpea
    is more sensitive to drought, which significantly affects the health and yield
    [3]. Hence, we strongly feel that detection of water stress will help in finding
    the irrigation requirements, and hence useful to farmers and agriculture scientists.
    The authors in [4] used a CNN model to detect water-stressed areas in maize fields
    using UAV-based RGB images, but early detection is not possible with RGB images.
    In [5], authors developed two new vegetation indices (VI) for retrieving canopy
    water content in different crops. But, the VIs focus only on specific bands, are
    not capable of capturing changes in many bands caused due to drought stress, hence
    reducing the discrimination ability. In [6], authors used spectral similarity
    in specific bands with high discriminating information, to detect drought stress
    in maize plants using close range HSI. The authors in [7], used machine learning
    (ML) techniques like random forest algorithm, SVM, multi-layer perceptron (MLP),
    2D CNN for detecting water stress in potato plants using HS imagery. In [8], ML
    algorithms were integrated with full and derivative spectra for early detecting
    drought stress in Bromus inermis using close-range HSI. The bottleneck of traditional
    methods is the curse of dimensionality due to the high dimensionality of HSI data[9].
    Spectral-based dimensionality reduction techniques such as PCA, linear discriminant
    analysis, and independent component analysis, and pixel-based FE methods like
    neural networks, MLPs, SVM give unsatisfactory performance due to ignoring the
    spatial information [9], [10]. Fig. 1. Orthomosaic view of Chickpea experimental
    filed. Show All Recently, deep learning (DL) based techniques especially CNNs
    are widely used for analyzing remotely sensed HSI data. In DL, an end-to-end framework
    is developed, which takes the input HSI data, automatically does FE and classification,
    and outputs the results [10]. The 2D CNNs are not effective in classifying HSI
    data, since they extract only spatial discriminative features but not the spectral
    information [9]. 3D CNNs can extract the spectral-spatial features simultaneously
    from HSI data but with increased computational complexity. In [11], a hybrid (3D-2D)
    CNN model was proposed, in which the 3D convolutions learns joint spatial-spectral
    features and 2D convolutions learns more abstract spatial features from complex
    HSI data, and also it significantly reduces the computational complexity. Motivated
    by this, in this paper we use a 3D-2D CNN model to detect water stress in chickpea.
    To the best of our knowledge, this is the first attempt to present the water stress
    detection of chickpea with UAV-based hyperspectral images using a 3D-2D CNN model.
    SECTION II. EXPERIMENT AND DATA ACQUISITION For this study, the target crop is
    chickpea, and the experiment was conducted at Lysimetric facility [12] at the
    International Crops Research Institute for the Semi-Arid Tropics (ICRISAT), Hyderabad,
    India as shown in Fig. 1. The drought experiment consists of two water treatments,
    i. well-watered (WW), ii. water-stressed (WS). Each treatment consists of 26 genomes
    with 8 replications, a total of 208 lines per treatment. The chickpea plants were
    cultivated in plastic cylinders for precise water treatments. The cylinders were
    randomly distributed and closely placed to create real field conditions. For WW
    plants controlled irrigation was supplied throughout, whereas for WS plants the
    irrigation was withheld 30 days after sowing. The soil moisture measurements were
    taken by weighting the cylinders. To acquire data for this study, a Resonon’s
    Pika-L HSI camera mounted on a DJI matrice-600 Pro UAV was used as shown in Fig.
    2. The HSI camera acquires images in 400-1000 nm spectral range in 281 narrow
    bands, with a spectral resolution of 2.1 nm. The images were acquired by flying
    the UAV at 20 m altitude with 3.6 kmph speed, which gives around 0.7 cm pixel
    resolution. The flights were conducted around 11 am, which is a suitable time
    for acquiring HS reflectance. A 3m x 3m single-level gray calibration panel with
    36% reflectance was used for the reflectance calibration of HSI data. The collected
    HSI data cubes have 2000 x 900 spatial pixels. Post-flight, the radiometric and
    geometric calibrations of the data cubes were performed to get the geo-rectified
    images in absolute reflectance [13]. In Fig. 3, sample mean spectrum of the chickpea
    canopy is shown. Fig. 2. Setup of the UAV based HSI system. Show All Fig. 3. Sample
    mean spectrum of chickpea canopy. Show All SECTION III. 3D-2D CNN MODEL FRAMEWORK
    The architecture of the 3D-2D CNN (HybridSN) [11] model which is used for FE and
    classification of HSI data is shown in Fig. 4. Initially, PCA is applied along
    the spectral dimension of the HSI data cubes, to reduce the dimensionality by
    removing redundant information. The PCA reduced data cube is represented as X
    ∈ RMXNXB, where M, N, and B be the width, height, and the spectral dimension respectively.
    The data cube X is divided into small overlapping 3D patches, P ∈ RSXSXB, the
    labels of which are given by the labels of the corresponding center pixel. The
    patches consider spatial contextual information in a SXS neighborhood window around
    the center pixel. The CNN architecture consists of three 3D convolution layers,
    one 2D convolution layer, and three fully connected layers in the same order.
    It uses eight 3D kernels of size 3x3x7 in the first layer, sixteen 3D kernels
    of size 3x3x5 in the second layer, and 32 3D convolutions of size 3x3x3 in the
    third layer. On the reshaped output of the third layer, 64 2D convolution kernels
    of size 3×3×576 are applied. The 3D convolutions generate joint spectral-spatial
    features, and the 2D convolution generates more abstract spatial features. C =
    2 is used in the last dense layer, which is the number of water treatment classes.
    Fig. 4. 3D-2D CNN (HybridSN) model architecture [11]. Show All III-A. Data Sets
    Creation The normalized difference VI [14] was used to separate the background
    and mixed pixels from the canopy. The ground truth was created by manually labeling
    the pixels of the canopy corresponding to each water treatment. The available
    ground truth data was designated into 2 classes, ie. WW and WS. Two data sets
    were created i. by selecting 22 spectral bands which are directly water-sensitive
    (from 950 nm to 980 nm) and indirectly affected (530, 550, 570, 670, 675, 800
    nm) by drought stress [14], and ii. By considering the whole spectral bands of
    the HS images. The data samples were created by extracting 3D patches of dimension
    SxSxB from the HS images for both the data sets and the labels are given by the
    labels of the corresponding center pixels. Window size of S = 25 and principal
    components B=30 were used as in [11], whereas, for selected bands data set, B
    = 22 spectral bands were directly used. Out of 8 replications of both WW and WS
    treatments, 5 replications were used to create training data (5x26x2 = 260 lines),
    and 3 replications were used to create test data (3x26x2 = 156 lines). SECTION
    IV. RESULTS AND DISCUSSION In this study, the chickpea canopy of different genomics
    is classified as WW and WS, which is a binary classification problem. The weights
    were randomly initialized and the network was trained using back-propagation algorithm
    with the Adam optimizer by using the cross-entropy loss. The network was trained
    for 50 epochs using mini-batches of size 128. Simulation experiments were conducted
    on Intel(R) Xeon(R) Silver 4108 CPU workstation with the GTX 1080 GPU and 64 GB
    RAM. An optimal learning rate of 0.001 and weight decay of 1e−04 were chosen based
    on the classification outcomes. The HybridSN model was trained and tested on the
    selected bands and whole spectral bands data sets separately. The train set consists
    of 760 samples per class, and in the test set 950 samples per class. The accuracy
    and loss convergence of the model for 50 epochs during training on whole spectral
    bands data set are shown in Fig. 5. The water stress detection accuracy was evaluated
    using the Overall accuracy (OA), Precision, Recall, and F1-score as the performance
    metrics. Also, an SVM and a 2D+1D CNN [10] model were used to identify water stress,
    and the performances are compared with the HybridSN model. Table I. Water stress
    classification performance. Fig. 5. (left) Train accuracy (right) Train loss convergence
    with epochs for HybridSN. Show All As shown in Table 1, the classification accuracy
    of SVM is less on both the data sets in detecting water stress, as SVM considers
    only the spectral features but ignores the spatial features. The performance of
    the 2D+1D CNN model is better because it considers both spectral as well as spatial
    features in the neighborhood window. However, the 3D-2D CNN resulted in the highest
    classification performance (95.44%), since the 3D convolution layers learn joint
    spectral-spatial features, and the 2D convolution layer extracts more abstract
    spatial features. The performance of HybridSN in classifying water stress on whole
    spectral bands data (95.44%) is better compared to that of the selected bands
    data (88.07%). This can be due to, the selected water-sensitive bands may miss
    out some of the bands, which are directly or indirectly affected by the water
    stress. On the other hand, in the case of the whole spectral bands data set, the
    information in all spectral bands is taken into account by considering the first
    30 principal components. The 3D-2D CNN model could classify water-stressed chickpea
    (26 genotypes) canopy from that of well-watered with 95.44% accuracy, 0.957 precision,
    and 0.952 F1-score on the unseen test data, which indicates the potential of HSI
    and CNNs in efficiently detecting water stress in crops. In Fig. 6 the water stress
    classification map on an HS image generated using the trained HybridSN model is
    shown. There are few misclassifications, which may be due to the varied behavior
    of chickpea genomics under water stress. Fig. 6. (left) Ground truth map, (right)
    classification map of Chickpea; Red: WW, Green: WS. Show All SECTION V. CONCLUSION
    In this paper, the water stress detection in chickpea canopy of different genomics
    was studied using UAV-based hyperspectral imaging. We obtained classification
    accuracy of 95.44% in discriminating well-watered and water-stressed canopy using
    a 3D-2D CNN model on acquired canopy HS images. The results indicate the potential
    of HSI in successfully detecting water stress in chickpea. This study will be
    useful in finding the irrigation requirements of crops and will be helpful to
    farmers and agriculture scientists. The current work complements our ongoing efforts
    in developing standard operating procedures (SOP) for the use of UAV-based HSI
    in plant phenotyping in a standardized way. Authors Figures References Citations
    Keywords Metrics More Like This Prediction of Insufficient Accuracy for Human
    Activity Recognition using Convolutional Neural Network in Compared with Support
    Vector Machine 2022 5th International Conference on Contemporary Computing and
    Informatics (IC3I) Published: 2022 Self-powered Triboelectric Sensor with Data
    Classification Model based on Support Vector Machine and Convolutional Neural
    Network 2023 International Conference on Smart Electrical Grid and Renewable Energy
    (SEGRE) Published: 2023 Show More IEEE Personal Account CHANGE USERNAME/PASSWORD
    Purchase Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile Information
    COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help?
    US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow
    About IEEE Xplore | Contact Us | Help | Accessibility | Terms of Use | Nondiscrimination
    Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy Policy A not-for-profit
    organization, IEEE is the world''s largest technical professional organization
    dedicated to advancing technology for the benefit of humanity. © Copyright 2024
    IEEE - All rights reserved.'
  inline_citation: '>'
  journal: 2021 IEEE International India Geoscience and Remote Sensing Symposium (InGARSS)
  limitations: '>'
  pdf_link: null
  publication_year: 2021
  relevance_score1: 0
  relevance_score2: 0
  title: CNN Based Water Stress Detection in Chickpea Using UAV Based Hyperspectral
    Imaging
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1109/access.2018.2812999
  analysis: '>'
  authors:
  - Muhammad Jaleed Khan
  - Hamid Saeed Khan
  - Adeel Yousaf
  - Khurram Khurshid
  - Asad Abbas
  citation_count: 472
  full_citation: '>'
  full_text: '>

    This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org
    IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal
    Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln
    Sign Out All Books Conferences Courses Journals & Magazines Standards Authors
    Citations ADVANCED SEARCH Journals & Magazines >IEEE Access >Volume: 6 Modern
    Trends in Hyperspectral Image Analysis: A Review Publisher: IEEE Cite This PDF
    Muhammad Jaleed Khan; Hamid Saeed Khan; Adeel Yousaf; Khurram Khurshid; Asad Abbas
    All Authors 463 Cites in Papers 26416 Full Text Views Open Access Comment(s) Abstract
    Document Sections I. Introduction II. Hyperspectral Imaging III. Modern Applications
    of Hyperspectral Imaging IV. Conclusion Authors Figures References Citations Keywords
    Metrics Abstract: Over the past three decades, significant developments have been
    made in hyperspectral imaging due to which it has emerged as an effective tool
    in numerous civil, environmental, and military applications. Modern sensor technologies
    are capable of covering large surfaces of earth with exceptional spatial, spectral,
    and temporal resolutions. Due to these features, hyperspectral imaging has been
    effectively used in numerous remote sensing applications requiring estimation
    of physical parameters of many complex surfaces and identification of visually
    similar materials having fine spectral signatures. In the recent years, ground
    based hyperspectral imaging has gained immense interest in the research on electronic
    imaging for food inspection, forensic science, medical surgery and diagnosis,
    and military applications. This review focuses on the fundamentals of hyperspectral
    image analysis and its modern applications such as food quality and safety assessment,
    medical diagnosis and image guided surgery, forensic document examination, defense
    and homeland security, remote sensing applications such as precision agriculture
    and water resource management and material identification and mapping of artworks.
    Moreover, recent research on the use of hyperspectral imaging for examination
    of forgery detection in questioned documents, aided by deep learning, is also
    presented. This review can be a useful baseline for future research in hyperspectral
    image analysis. A hyperspectral image represented as a 3D cube with a point spectrum
    on the spectral cube illustrated at the spatial location (x,y). Published in:
    IEEE Access ( Volume: 6) Page(s): 14118 - 14129 Date of Publication: 12 March
    2018 Electronic ISSN: 2169-3536 DOI: 10.1109/ACCESS.2018.2812999 Publisher: IEEE
    SECTION I. Introduction This human eye is only able to see in a limited part of
    electro-magnetic spectrum and can distinguish between objects based on their different
    spectral responses in that narrow spectral range [1]. However, multispectral imaging
    sensors have been developed that are able to acquire an image in infrared and
    visible segments of electromagnetic spectrum. This allows material identification
    on the basis of their unique spectral sig-nature in a wide spectral range. Multispectral
    imaging exploits the property that each material has its own unique spectral signatures.
    Spectrum of a single pixel in a multispectral image provides information about
    its constituents and surface of the material. Multispectral imaging technology
    is being used for environment and land observation remote sensing in satellite
    and airborne systems since late 1960s [2]. Multispectral imaging systems acquire
    data in a small number of spectral bands by using parallel sensor arrays. Most
    of the multispectral imaging systems use three to six spectral bands with large
    optical band intervals, ranging from visible to near infrared regions of electromagnetic
    spectrum for scene observation. However, such low number of spectral bands is
    the limiting factor for discrimination of various materials. Recent developments
    in hyperspectral sensing during the past two decades has made it possible to acquire
    several hundred spectral bands of observational scene in a single acquisition.
    The increased spectral resolution of these hyperspectral images allow for detailed
    examination of land surfaces and different materials present in the observational
    scene, which was previously not possible with low spectral resolution of multispectral
    imaging scanners. Hyperspectral imaging (HSI) or imaging spectrometry [3] is a
    spectral sensing technique in which an object is photographed using several well
    defined optical bands in broad spectral range. It was originally implemented on
    satellite and airborne platforms for remote sensing applications but during last
    two decades, HSI has been applied to numerous applications including agricultural
    and water resources control [4], [5], military defense, art conservation and archeology
    [6], [7], medical diagnosis [8], [9], analyses of crime scene details [10], [11],
    document imaging [12], forensic medicine [13], food quality control [14], [15]
    and mineralogical mapping of earth surface [16]. This review details the fundamentals
    of hyperspectral imaging, discusses the common hyperspectral remote sensing terminologies
    and highlights the modern applications of hyperspectral imagery in the areas of
    food quality and safety assessment, medical diagnosis, precision agriculture,
    water resource management, forensic document examination, artwork authentication
    and defense and homeland security. SECTION II. Hyperspectral Imaging Hyperspectral
    images are characterized by their spatial as well as spectral resolution. The
    spatial resolution measures the geometric relationship of the image pixels to
    each other while the spectral resolution determines the variations within image
    pixels as a function of wavelength. A hyperspectral image has two spatial dimensions
    (Sx and Sy) and one spectral dimension ( S λ ). The hyperspectral data is represented
    in the form of a 3D hyperspectral data cube in Figure 1 using pseudo-colors in
    center. A point spectrum on the data cube at the spatial location (x,y) and an
    RGB image and a grayscale image rendered from the hyperspectral cube are also
    shown. Each slice of the cube along spectral dimension is called a band or channel.
    Table I shows the spatial and spectral resolution of the current airborne and
    space satellite imaging sensors. TABLE 1 Current Space Borne and Airborne Spectral
    Sensors Providing Data for Land Mapping FIGURE 1. (a) A hyperspectral image represented
    as a 3D cube. A point spectrum on the spectral cube is illustrated at the spatial
    location (x,y). (b) An RGB image and (c) a grayscale image rendered from the hyperspectral
    cube. Show All A. Spatial Resolution Spatial resolution can be defined as the
    smallest discernible detail in an image [17] which can be described as the measure
    of smallest object in an image that can be distinguished as a separate entity
    in the image. In practical situations clarity of the image is dictated by it spatial
    resolution, not the number of pixels in an image. Spatial characteristics of an
    image depend on the design of imaging sensor in terms of its field of view and
    its altitude [18]. A finite patch of the ground is captured by each detector in
    a remote imaging sensor. Spatial resolution is inversely proportional to the patch
    size. Smaller the size of the patch, higher the details that can be interpreted
    from the observed scene. B. Spectral Resolution Spectral resolution can be defined
    as the number of spectral bands and range of electromagnetic spectrum measured
    by the sensor. An imaging sensor might respond to a large frequency range but
    still have a low spectral resolution if it acquires a small number of spectral
    bands. On the contrary, if a sensor is sensitive to small frequency range but
    captures large number of spectral bands has high spectral resolution, due to its
    ability to distinguish between scene elements having close or similar spectral
    signatures [19]. Multispectral images have a low spectral resolution, thus unable
    to resolve finer spectral signatures present in the scene. HSI sensors acquire
    images in numerous contiguous and extremely narrow spectral bands in mid infrared,
    near infrared and visible segments of electromagnetic spectrum. This type of advance
    imaging system shows tremendous potential for material identification on the basis
    of their unique spectral signatures [2]. Spectrum of a single pixel in a hyperspectral
    image can give considerably more information about the surface of the material
    than a normal image. C. Temporal Resolution In hyperspectral remote sensing, the
    temporal resolution depends on the orbital characteristics of the imaging sensor.
    It is generally defined as the time needed by the sensor platform to revisit and
    obtain data from the exact same location [20]. Temporal resolution is said to
    be high if the revisiting frequency of the sensor platform for the exact same
    location is high and is said to be low if revisiting frequency is low. It is normally
    defined in days. D. Understanding Spectral Signatures Materials present on the
    surface of Earth absorb, transmit and reflect electromagnetic radiations from
    the sun in a unique way. Hyperspectral sensors allows us to measure all types
    of electromagnetic energy within a specified range as it interacts with materials,
    thus allowing us to observe the distinct features and changes on earth’s surface.
    Reflectance is the measure of electromagnetic energy bouncing back from a material’s
    surface. It is a ratio of reflected energy to incident energy as a function of
    wavelength [18]. Reflectance is 100% if all the light energy of specific wavelength
    striking the object is reflected back to the imaging sensor; on the other hand
    reflectance is 0% if the entire incident light of specific wavelength is absorbed
    by the object. In most practical cases reflectance values lie in the range [0,100].
    In a specified range of electromagnetic spectrum, the reflectance values of different
    materials present on the earth’s surface such as soil, forest, water and minerals
    can be plotted and compared. Such plots are labeled as spectral signatures or
    spectral response curves” [21]. Figure 2 demonstrates a general model of spectral
    signatures of different materials present on the earth’s surface. Remotely sensed
    images can be classified using these spectral signature plots, as each material
    present in an observed scene has its own unique spectral signature. The more the
    spectral resolution of an imaging sensor, the more classification information
    can be extracted from spectral signatures. Hyperspectral sensors have high spectral
    resolution than multispectral sensors and thus provide the ability to distinguish
    more subtle differences in a scene. Hyperspectral imagery has been utilized by
    geologists for mapping the land and water resources [16]. It is also utilized
    to map heavy metals and other hazardous wastes in historic and active mining areas.
    The spectral responses of green vegetation, dry bare soil, and clean water are
    compared graphically in Figure 3. It is observed that the reflectance curve for
    bare soil has fewer variations as compared to that of green vegetation. This is
    because of the fact that the factors that affect soil reflectance vary in a narrow
    range of electromagnetic spectrum. These factors include soil texture, presence
    of minerals such as iron, surface roughness and moisture content in soil [21].
    FIGURE 2. A generic scheme of HSI mapping of soil, vegetation and water. Show
    All FIGURE 3. Spectral response curves of soil, vegetation and water. Show All
    Spectral signatures of green vegetation have basins in the visible range of the
    spectrum that indicates the pigmentation in the tissues of the plant. Chlorophyll
    is the primary photosynthetic pigment in green vegetation [18], it absorbs strongly
    in red (670 nm) and blue (450 nm) regions called the chlorophyll absorption spectral
    bands. When a plant is under stress so that the chlorophyll growth is reduced,
    in such cases the amount of reflectance in red (670 nm) regions increases [18].
    The spectral response of water has distinctive characteristics of absorption of
    light in near infrared and beyond. Common factors affecting spectral response
    of water are the suspended sediments and increases in chlorophyll levels. In each
    case spectral response will be shifted accordingly showing the presence of suspended
    sediments or algae in water [22]. SECTION III. Modern Applications of Hyperspectral
    Imaging Hyperspectral imaging (HSI) is increasingly being used for a wide variety
    of commercial, industrial and military applications. In this section, we focus
    on the applications of HSI to food quality and safety, image guided surgery and
    medical diagnosis, remote sensing such as precision agriculture and water resource
    management, forensic examination such as document forgery detection and artwork
    authentication and defense and homeland security. A. Food Quality and Safety Assessment
    Due to the growing need for high efficiency and low production costs of food products,
    the food industry is facing numerous challenges such as ensuring the quality and
    safety of food products while avoiding liability issues. Food quality and safety
    is assessed by the examination of various physical, chemical and biological attributes
    of food. The traditional methods based on visual inspection and chemical and biological
    inspection of food are destructive, time consuming and also environmentally unfriendly
    in some cases. Technological advancements in instrumentation engineering and computer
    technology enabled efficient and faster assessment of food. Computer vision and
    machine learning based methods using color image processing have been successfully
    applied for assessment of external attributes of food [23]–[28]. These methods
    are unable to examine the internal characteristics of food because they lack the
    ability to capture broad spectral information. Near Infrared (NIR) spectroscopy
    helped overcome this limitation of machine vision based methods due to close relationship
    between food components and NIR spectra [29], [30]. However, NIR spectroscopy
    could not help in examination of heterogeneous materials due to the lack of ability
    to capture spatial information [31], [32]. Hyperspectral imagery contains rich
    amount of spectral as well as spatial information which makes HSI based methods
    well suited for assessment of food quality and safety [37]. Hyperspectral image
    analysis has been used for identification of defects [35], [36] and detection
    of contaminations [33], [34] in food items. Valenzuela et al. [38] employed visual
    and infrared (VIR) hyperspectral imaging to examine the firmness and solid content
    of blueberries. Prediction accuracy of 87% and 79% was obtained for firmness and
    solid content respectively. Huang et al. [39] determined mealiness of apple using
    VIR hyperspectral imaging, achieving classification accuracy of 82.5%. Huang et
    al. [40] employed Grey Level Co-occurrence Matrix (GLCM) and Gabor Filter to determine
    fat content between muscles in pork achieving a classification accuracy of 89%.
    HSI is also used to determine color distribution in salmon fillet [41]. Ivorra
    et al. [42] used NIR hyperspectral imaging to detect expired vacuum packed salmon,
    reaching a classification accuracy of 82.7%. In [43], Principal Component Analysis
    (PCA) and PLS-DA based classification model is presented for classification of
    oat and grout kernels in NIR hyperspectral images. The proposed method [43] achieved
    a high classification rate of almost 100% and thus, showed the efficacy of HSI
    as an industrial tool in food analysis. B. Medical Diagnosis Computed Tomography
    (CT) and Magnetic Resonance Imaging (MRI) have been traditionally used for clinical
    analysis. Paty et al. [121] compared the potential of MRI and CT for detection
    of multiple sclerosis (MS) during the evaluation of over 200 patients. Hovels
    et al. [122] used both CT and MRI diagnosis of lymph node metastases in prostate
    cancer. MRI yielded better results in clinical diagnosis. Over the past decades,
    modern spectral imaging techniques have proved their significance in medical imaging
    by providing added potential to medical experts at higher speed and accuracy.
    The optical characteristics of tissues provide valuable diagnostic information.
    Hyperspectral image analysis is being widely used for medical diagnosis due to
    its ability to provide real time images of biomarker information and spectral
    information of tissues. Besides diagnosis, HSI systems are also used in image
    guided surgery. Kumar et al. [44] proposed a PCA and Fourier Transform Infrared
    (FTIR) Spectroscopy based imaging system for diagnosis of breast cancer. FTIR
    was applied on histopathological specimens of breast cancer with various histological
    grades and spectral changes near carcinoma were reported. The data was analyzed
    using PCA. Prominent features were found in the 5882~6250nm band which could be
    used for cancer identification. The reflectance spectra of tongue were non-invasively
    measured and analyzed by Liu et al. [45] for tumor detection. Dicker et al. [86]
    distinguished between malignant and benign dermal tissue in the spectral domain
    in the routine H&E stained samples. In their findings, the spectral signatures
    differences could be seen if the section thickness and staining time are controlled.
    A melanoma lesion and interstitial areas are shown in grayscale representation
    in Figure 4. FIGURE 4. A grayscale representation of a melanoma lesion showing
    the transmission Spectra in the nuclear and interstitial areas. Show All Mitra
    et al. [46] scanned the biliary structure using both fluorescence and reflectance
    imaging for classification of different tissues and identification of the biliary
    anatomy. Fluorescence imaging provided dynamic information about movement and
    flow in the surgical ROI whereas the hyperspectral image information helped in
    identification of the bileduct shown in Figure 5. The hyperspectral information
    also allowed for safe exclusion of contaminant fluorescence in tissues which is
    not included in the biliary anatomy. FIGURE 5. The structure of biliary tissue.
    (b) HSI based classification of the biliary tissue types. Show All In [46], the
    biliary structure of tissues was scanned using fluorescence and reflectance imaging
    for identification of gall bladder diseases. Spectral analysis and image processing
    techniques were employed for identification of biliary anatomy and classification
    of tissues. Dynamic information of motion in the surgical region was provided
    by fluorescence imaging while hyperspectral imagery allowed for safe exclusion
    of contaminated fluorescence from tissues and provided valuable information for
    the identification of the bileduct. Campbell et al. [47] have proposed the use
    of Laparoscopic Partial Nephrectomy (LPN) for diagnosis of renal cortical tumors.
    Olweny et al. [48] used Digital Light Processing (DLP) based HSI for computer
    assisted LPN to characterize renal oxygenation. The clinical study was performed
    in eighteen patients. The proposed system was able to successfully characterize
    dynamic changes in renal oxygenation during LPN. C. Precision Agriculture Many
    studies have indicated that the world’s crop production needs to be doubled by
    the end 2050 due to the rapidly growing population in the world [49]. However,
    various studies have shown that the crop yields are no longer increasing at a
    rate to fulfill the growing population needs [50], [51]. Recent studies have also
    indicated that increasing crop yields without using more land for cultivation,
    is the most effective way for ensuring food security [52], [53]. Global poverty
    and undernourishment can directly be reduced by increasing crop production; moreover
    most of the poor and undernourished population consists of farmers themselves
    [54]. Zhang et al. [124] reviewed the state of the art deep learning techniques
    for representative feature extraction and scene understanding in remote sensing
    hyperspectral images, Traditionally crop monitoring for disease, water stress,
    nutrients and insect attack was carried out by manual visual inspection from the
    ground. These methods were limited by the fact that the visual symptoms often
    appear at later stages of disease, thus making it difficult to restore plant health.
    Advancement in airborne and ground based HSI methods has made possible the evaluation
    of crop stresses, analyzing soil and vegetation characteristics in a cost effective
    manner, thus replacing the traditional scouting methods. Drought stress is an
    important factor affecting crop yields. Chances of a successful crop can be highly
    increased by timely detection of water related stresses. High water level stresses
    are noticeable in variations in photosynthetic pigments. These changes lead to
    yellowish tint in crops, due to the increase reflectance of red wavelength. Unlike
    human eye, HSI sensors can detect these changes at earlier stages. Colombo et
    al. [55] indicated that changes in leaf equivalent water thickness (EWT) were
    responsible for changes in leaf reflectance in the visible and infrared spectrum.
    They stated that hyperspectral regression indices calculated from HSI were powerful
    tools for estimation of water content at leaf as well as at landscape level. Rascher
    et al. [56] used a portable HSI system and photochemical reflectance index to
    estimate water stress in leaves of tropical tress and observed the temporal effects
    of dehydrations on tree leaves. Rossini et al. [57] found that HSI is useful in
    detecting drought stress at farm level with corn. They showed that irrigation
    deficits can be accurately mapped well before drought stress affected the canopy
    structure. Deficiencies in nutrients and soil contamination cause various symptoms
    that can be assessed by HSI. Schuerger et al. [58] used HSI to observe zinc deficiency
    and toxicity for identification of chlorophyll levels relating to stress symptoms.
    They indicated that traditional direct sampling methods are much more costly than
    HSI. Dunagan et al. [59] analyzed mercury levels in mustard plants and found that
    spectral signatures were notably related to the contaminant levels. Osborne et
    al. [60] showed that biomass, yield under stress, nitrogen and phosphorous concentrations
    can be estimated by using HSI. Mahlein et al. [61] studied different development
    stages of diseased sugar beet leaves using HSI. Figure 6 shows spectral signatures
    of healthy as well as diseased sugar beet leaves. This study also showed that
    HSI has a great potential for analyzing plant diseases. FIGURE 6. Spectral signatures
    comparison of healthy and diseased sugar beet leaves. Show All Analysis of soil
    characteristics can play a vital role in increasing crop yields. Ben-Dor et al.
    [62] al successfully mapped vital characteristics of soil in a field scale experiment
    including moisture, soil organic matter and soil sanity. Gomez et al. [63] estimated
    the organic carbon content in soil with accuracy. Growth monitoring of crops has
    made it possible to forecast production. Liu et al. [87] improved winter wheat
    yield prediction using new spectral parameters. The fine classification technology
    in agriculture has also matured greatly. Figure 7 shows the HSI based fine classification
    of vegetable growing regions. FIGURE 7. HSI based fine classification of vegetable
    growing regions. Show All D. Water Resource and Flood Management Water is one
    of the most important resources available on Earth as is vital for survival of
    humanity. For this reason, managing the water resource efficiently, analyzing
    and monitoring the quality of water has attracted a lot of attention from the
    researchers [64]–[69]. Hyperspectral remote sensing technology has found enormous
    applications in water resource management. Accurate estimates of water resource
    parameters are possible by analyzing spatial, spectral and temporal variations
    in water bodies. Xingtang et al. [88] systematically introduced their research
    on key technologies related to robust hyperspectral water resource monitoring
    system in China. This work was used by Li [89] to estimate the suspended matter
    concentrations of Meiliang Bay of Taihu Lake using the CHRIS data as shown in
    Figure 8. The efficacy of flood detection and monitoring system is limited by
    their incapacity to get important information about water conditions from airborne
    and ground observatories in a timely manner. Recent improvements in remote sensing
    technology has improved the early flood warning system and vastly reduced the
    time of detection and reaction to flood events to a few hours [70]. US geological
    survey and NASA are incorporating space borne observations of rainfall resources,
    rivers and land topography into early warning systems with potential global applications
    [71]. Glaber and Reinartz [72] studied the optimal procedure for detection of
    flooded areas with remote sensing data. They investigated the erosive impact of
    floods, moisture content in flood plain areas, accumulation of sediments. Roux
    and Dartus [73] explored the flood hydrographs and estimated the river discharge
    from remotely sensed data. They optimized their model to minimize the error between
    system response and their proposed model to estimate the river discharge. Honkavaara
    et al. [128] presented various challenges regarding data processing faced by hyperspectral
    sensors in adverse meteorological conditions and proposed radiometric correction
    to minimize the effects of radiometric variations in varying illumination conditions.
    FIGURE 8. Distribution of the suspended matter concentration of Meiliang Bay of
    Taihu Lake. (a) LANDSAT TM image of Taihu Lake. (b) Estimation result using CHRIS
    data. Show All Hyperspectral remote sensing provides efficient and reliable information
    about water quality parameters which contain biochemical, hydro-physical and biological
    attributes [74]–[76]. HSI enable us to measure chlorophyll, turbidity and chemical
    oxygen demand and phosphorous in water resources. Chlorophyll content in water
    is extensively studied by hyperspectral remote sensing, which gives an estimate
    of algal level and hence water quality. Studies have been carried out for evaluation
    of ammonia changes for wetland [77], classifying different parameters of lakes
    [78], estuaries [79] and analyzing algal blooms [80]. Wetland mapping has played
    a significant role in order to enhance the quality of our ecosystem [81]. Hyperspectral
    imagery has helped in detailed understanding of vegetation characteristics of
    ecosystem. Extensive research studies have been carried out using remote sensing
    to explore the significance of acquiring timely data for monitoring and mapping
    aquatic vegetation [82], which is said to be an important aspect in ecosystem
    reconstruction and restoration. E. Forensic Document Examination Traditionally,
    forensic document experts and paleographers used chemical solution based methods
    to study the extrinsic and intrinsic components of the important historic documents
    [83]. This is due to the fact that the inks used on documents throughout the history
    were composed of diverse substances having distinct chemical and physical properties.
    All of these substances have their own unique way for reacting with different
    substrates depending upon the reaction environment. These chemical solution based
    methods helped in document analysis. But unfortunately these techniques were time
    consuming, sensitive to temperature changes and destructive in nature i.e. harms
    to the important documents were irreversible. To overcome such limitations, HSI
    has emerged as an effective non-destructive tool for improving readability [84],
    ink aging and forensic document analysis [13]. Hyperspectral document imaging
    works on the principle that each ink present in the document has its own unique
    spectral signature. Many mathematical tools that are being used in hyperspectral
    remote sensing can be used on hyperspectral document images for classification,
    improving legibility of extremely deteriorated text, ink aging and fraud detection.
    Moreover HSI is non-destructive, automated and environment insensitive tool for
    document examination. In hyperspectral document imaging, ink mismatch detection
    analysis provides important information to forensic document examiners to determine
    the authenticity of legal documents. Forgery, backdating and fraud can be detected
    using ink analysis of documents. HSI has been used for forensic document analysis
    in the past [106]–[108]. The HSI based techniques have had a significant impact
    on forgery detection as compared to the traditional techniques. Different inks
    were successfully classified after obliteration of the text in a document [106].
    Abbas et al. [85] proposed hyperspectral unmixing for discrimination between inks
    from different pens in a document. Recently, we have worked on a nondestructive
    automated forgery detection system, which was able to successfully discriminate
    between different visually similar inks taken from the publicly available UWA
    Writing Ink Hyperspectral Images (WIHSI) Database [85] with different number of
    inks and different mixing ratios (Combination A~H). Initially, we used Fuzzy C-Means
    Clustering (FCM) to differentiate two inks present in a multispectral document
    in different mixing ratios [129]. In our latest work, the state of the art deep
    learning technique, Convolutional Neural Network (CNN) has been employed for classification
    of spectral responses of ink pixels for forgery detection in hyperspectral document
    images. Figure 9 shows the final segmentation results of our proposed technique.
    98% classification accuracy was achieved which shows the high potential of HSI
    and deep learning in document forgery detection. FIGURE 9. Comparisons of ground
    truth images of documents with mixed inks and our final segmentation results.
    Show All F. Artwork Authentication The global art market is increasing rapidly
    over the past decades [90]. A 7% year on year increase in total sales of art and
    antiques was recorded in 2013 [91]. Most of these high value dealings were made
    using non-scientific expertise in art. Forensic testing was not used to assure
    authenticity of the traded object. However, only a limited number of artwork evaluations
    can be carried out by an experienced specialist. Foolproof evaluations can be
    carried out if supported by non-destructive scientific tests [92], [93]. Fourier
    Transform Infrared (FTIR), X-ray fluorescence, and Raman spectroscopy have been
    used previously for artwork authentication [94], [95]. HSI is proposed as a novel
    and non-destructive artwork examination method in the recent literature. HSI limits
    the number of invasive tests needed and provides more information from a sample.
    Several methods employing pigment analysis provided by HSI and classification
    techniques have been proposed in the recent literature [7], [96]–[100] for conservation
    and restoration of artworks such as paintings. These methods allow for identification
    of restored regions in paintings and distinguish them from the important regions
    in the original painting. Hyperspectral images captured in the infrared range
    also revealed useful features of painters such as preparatory drawings [101].
    Two forged paintings and the results of IR hyperspectral imaging and SVM classification
    proposed in [105] are illustrated in Figure 10. The broad spectral information
    provided by HSI combined with signal processing also allows for identification
    of the underlying material in artworks. Materials which are clearly visible in
    a specific band and obscured in the other bands are reflective within the same
    band and thus easily detectable by the HSI system [102]. The appropriate bands
    in the HSI data of historic texts and manuscripts allow for identification of
    inks and pigments for dating of manuscripts [103] and recovery of erased and overwritten
    scripts [104]. FIGURE 10. Two paintings with forgery. (a) Grid canvas and color
    coded pigments. (b-c) Forged Paintings with classification results. Show All G.
    Defence and Homeland Security The usage of HSI has quickly spread to various civilian
    applications and more recently to sectors of defense and homeland security [109].
    HSI is generally used as a counter-countermeasure for detection and recognition
    of camouflaged targets in military applications. HSI can easily detect strategic
    deployments in unpopulated areas such as forests, desserts and mountains, where
    targets such as military vehicles and mines are distinct from the background even
    if camouflaged. Anomaly detection methods [110]–[112] that use spectral information
    to differentiate between targets and background without any prior knowledge have
    gained significant popularity over the past few years. Yuen and Bishop [110] proposed
    an HSI based anomaly detection algorithms “MUF2”, which uses a multiple approach
    fusion methodology. Experiments were performed on images with crops, vegetation
    and bare soil from the Barrax dataset. An image from the Barrax dataset and the
    results of target detection using MUF2 algorithm are shown in Figure 11. An extremely
    high detection rate of 100% was achieved at a false alarm rate of 2× 10 −4 . Remote
    detection of small targets such as mines is a very challenging task. MUF2 algorithm
    [110] was also tested for detection of camouflaged land mines as shown in Figure
    12. Due to the very small area of the target in the images and noise in the dataset,
    60% detection accuracy was achieved at a false alarm rate of 3× 10 −3 . Suganthi
    and Korah [113] proposed an Artificial Neural Network (ANN) based technique for
    landmine detection and segmentation in infrared images. Letalick et al. [114]
    tested the possibility and feasibility of using multiple optical sensors and concluded
    that HSI has high potential in detection and recognition of semi-hidden, hidden
    and camouflaged landmines if prior knowledge of the spectral signature of the
    target. However, limited detection rate is achieved when landmines are completely
    hidden or camouflaged with vegetation. FIGURE 11. (a) A scene with crops and vegetation
    from Barrax HSI dataset, (b) Target detection using HSI based MUF2 anomaly detection
    algorithm. Show All FIGURE 12. Land mine detection using HSI based MUF2 algorithm.
    Show All Zhao et al. [123] proposed a sparse learning technique for hyperspectral
    anomaly detection, in which they employed dictionary based transformation of background
    features and iterative reweighting to exaggerate the differences between anomalies
    and background. Du et al. [125] proposed a hybrid sparsity and statistics anomaly
    detector to overcome the limitations of sparsity models in hyperspectral images
    containing spectral variability with limited endmembers. Discriminative metric
    learning method [126] and local geometric structure features [127] have also been
    used for hyperspectral anomaly detection in the recent literature. Thomas et al.
    [115] conducted a research on detection of grid patterns of landmines to improve
    the efficacy of landmine detection in LWIR hyperspectral imagery. Anomalies are
    detected using Dual Window based Eigen Separation Transform (DWEST) and pattern
    parameters are extracted. A pattern projection image is formed using the extracted
    parameters followed by pattern based reduction of false alarm rate. Higher detection
    probability at lower false alarm rate was noted which shows that the use of spatial
    pattern parameters in anomaly detection improves land mine detection [115]. Gagnon
    et al. [116] used hyperspectral image analysis to detect buried targets using
    a LWIR airborne hyperspectral camera. The temperature of disturbed soil over the
    buried target was found to be higher than the temperature of undisturbed soil
    around the target area. Classification techniques such as SVM and linear unmixing
    are used to distinguish between the targets and naturally hot areas. In the 21st
    century, development of state-of-the-art technologies for counterterrorism is
    one of the fastest growing demands. One of the significant ideas proposed for
    counterterrorism is detecting improvised explosive devices (IED). It is a technical
    challenge to directly detect explosives packed in airtight and light manner. Contrary
    to the direct detection of IEDs, cognitive methods use effective computing to
    analyze the contextual and body language, behavior, gestures, facial expressions
    and activity to assess the intent of a person. Mental stress is one of the key
    indicators of threat which is a short term induced neurological imbalance caused
    by any situation which involves a possible threat or danger. During neurological
    stress, the sympathetic nervous system induces adrenaline hormones to the blood
    triggers increase in blood flow to muscles and dilation of pupil. These unavoidable
    physiological changes during stress are detected as an indication of stress level
    using HSI [25]. Assessment of hemoglobin oxygenation using spectroscopic tuning
    is proposed in [26] and [27]. Figure 13 shows the oxy-hemoglobin levels of a person
    at different levels of stress. FIGURE 13. Results of stress detection by HSI based
    sensing of variations in blood oxygenation due to stress of different intensities.
    Show All SECTION IV. Conclusion Among remote sensing technologies, the role of
    hyperspectral imagery in the geo-observation, identification and detection of
    materials and estimation of physical parameters cannot be stated enough. Due to
    this very reason there is increasing number of airborne and spaceborne hyperspectral
    platforms based applications being researched. Recent advancements in sensor technologies
    have encouraged researchers to use hyperspectral imagery in many modern applications.
    Many mathematical tools and algorithms are being researched such as data fusion,
    hyperspectral unmixing, hyperspectral classification, anomaly detection and fast
    computing for efficient utilization of hyperspectral data. These mathematical
    tools can be used on hyperspectral data across many different applications. In
    general, this review focuses on the vast extent to which hyperspectral imaging
    has been used to increase and maintain the crop yields, managing water resources,
    assessment of food quality and safety, diagnosing diseases, authentication of
    artworks, forensic examination of questioned documents, detection of military
    targets and counterterrorism. Promising results have been found in the proposed
    automatic forgery detection system based on HSI and deep learning. Future research
    is being carried out for further improvement as well. This review can be a useful
    baseline for future research in hyperspectral image analysis. Authors Figures
    References Citations Keywords Metrics More Like This A Hardware Accelerator for
    Onboard Spatial Resolution Enhancement of Hyperspectral Images IEEE Geoscience
    and Remote Sensing Letters Published: 2021 Spatial Resolution Enhancement of Hyperspectral
    Images Using Unmixing and Binary Particle Swarm Optimization IEEE Geoscience and
    Remote Sensing Letters Published: 2014 Show More IEEE Personal Account CHANGE
    USERNAME/PASSWORD Purchase Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile
    Information COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION TECHNICAL INTERESTS
    Need Help? US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT
    Follow About IEEE Xplore | Contact Us | Help | Accessibility | Terms of Use |
    Nondiscrimination Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy Policy
    A not-for-profit organization, IEEE is the world''s largest technical professional
    organization dedicated to advancing technology for the benefit of humanity. ©
    Copyright 2024 IEEE - All rights reserved.'
  inline_citation: '>'
  journal: IEEE access
  limitations: '>'
  pdf_link: null
  publication_year: 2018
  relevance_score1: 0
  relevance_score2: 0
  title: 'Modern Trends in Hyperspectral Image Analysis: A Review'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.3389/fpls.2017.01111
  analysis: '>'
  authors:
  - Guijun Yang
  - Jiangang Liu
  - Chunjiang Zhao
  - Zhenhong Li
  - Yanbo Huang
  - Haiyang Yu
  - Bo Xu
  - Xiaodong Yang
  - Dan Zhu
  - Xiaoyan Zhang
  - Ruyang Zhang
  - Haikuan Feng
  - Xin Zhao
  - Zhenhai Li
  - Heli Li
  - Hao Yang
  citation_count: 442
  full_citation: '>'
  full_text: '>

    REVIEW

    published: 30 June 2017

    doi: 10.3389/fpls.2017.01111

    Frontiers in Plant Science | www.frontiersin.org

    1

    June 2017 | Volume 8 | Article 1111

    Edited by:

    Marcello Mastrorilli,

    Consiglio per la Ricerca in agricoltura

    e l’analisi dell’ Economia Agriaria

    (CREA), Italy

    Reviewed by:

    Bangyou Zheng,

    Commonwealth Scientiﬁc and

    Industrial Research Organisation

    (CSIRO), Australia

    Wei Guo,

    University of Tokyo, Japan

    *Correspondence:

    Chunjiang Zhao

    zhaocj@nercita.org.cn

    †These authors have contributed

    equally to this work.

    ‡Co-ﬁrst authors.

    Specialty section:

    This article was submitted to

    Crop Science and Horticulture,

    a section of the journal

    Frontiers in Plant Science

    Received: 09 April 2017

    Accepted: 08 June 2017

    Published: 30 June 2017

    Citation:

    Yang G, Liu J, Zhao C, Li Z, Huang Y,

    Yu H, Xu B, Yang X, Zhu D, Zhang X,

    Zhang R, Feng H, Zhao X, Li Z, Li H

    and Yang H (2017) Unmanned Aerial

    Vehicle Remote Sensing for

    Field-Based Crop Phenotyping:

    Current Status and Perspectives.

    Front. Plant Sci. 8:1111.

    doi: 10.3389/fpls.2017.01111

    Unmanned Aerial Vehicle Remote

    Sensing for Field-Based Crop

    Phenotyping: Current Status and

    Perspectives

    Guijun Yang 1, 2, 3 †‡, Jiangang Liu 1, 3 †‡, Chunjiang Zhao 1, 2, 3*, Zhenhong
    Li 4, Yanbo Huang 5,

    Haiyang Yu 1, 3, Bo Xu 1, 3, Xiaodong Yang 1, 2, Dongmei Zhu 6, Xiaoyan Zhang
    7,

    Ruyang Zhang 8, Haikuan Feng 1, Xiaoqing Zhao 1, Zhenhai Li 1, 2, Heli Li 1, 2
    and Hao Yang 1, 2

    1 Key Laboratory of Quantitative Remote Sensing in Agriculture of Ministry of
    Agriculture P. R. China, Beijing Research Center

    for Information Technology in Agriculture, Beijing, China, 2 National Engineering
    Research Center for Information Technology

    in Agriculture, Beijing, China, 3 Key Laboratory of Agri-informatics, Ministry
    of Agriculture, Beijing, China, 4 School of Civil

    Engineering and Geosciences, Newcastle University, Newcastle upon Tyne, United
    Kingdom, 5 Crop Reduction Systems

    Research Unit, United States Department of Agriculture-Agricultural Research Service,
    Stoneville, NC, United States, 6 Wheat

    Breeding Department, Institute of Agricultural Sciences for Lixiahe Region, Jiangsu,
    China, 7 National Center for Soybean

    Improvement, Nanjing Agricultural University, Nanjing, China, 8 Maize Research
    Center, Beijing Academy of Agriculture and

    Forestry Sciences, Beijing, China

    Phenotyping plays an important role in crop science research; the accurate and

    rapid acquisition of phenotypic information of plants or cells in different environments

    is helpful for exploring the inheritance and expression patterns of the genome
    to

    determine the association of genomic and phenotypic information to increase the

    crop yield. Traditional methods for acquiring crop traits, such as plant height,
    leaf

    color, leaf area index (LAI), chlorophyll content, biomass and yield, rely on
    manual

    sampling, which is time-consuming and laborious. Unmanned aerial vehicle remote

    sensing platforms (UAV-RSPs) equipped with different sensors have recently become

    an important approach for fast and non-destructive high throughput phenotyping
    and

    have the advantage of ﬂexible and convenient operation, on-demand access to data

    and high spatial resolution. UAV-RSPs are a powerful tool for studying phenomics
    and

    genomics. As the methods and applications for ﬁeld phenotyping using UAVs to users

    who willing to derive phenotypic parameters from large ﬁelds and tests with the
    minimum

    effort on ﬁeld work and getting highly reliable results are necessary, the current
    status and

    perspectives on the topic of UAV-RSPs for ﬁeld-based phenotyping were reviewed
    based

    on the literature survey of crop phenotyping using UAV-RSPs in the Web of ScienceTM

    Core Collection database and cases study by NERCITA. The reference for the selection

    of UAV platforms and remote sensing sensors, the commonly adopted methods and

    typical applications for analyzing phenotypic traits by UAV-RSPs, and the challenge
    for

    crop phenotyping by UAV-RSPs were considered. The review can provide theoretical

    and technical support to promote the applications of UAV-RSPs for crop phenotyping.

    Keywords: UAV, remote sensing, high-throughput, ﬁeld phenotyping, crop breeding

    Yang et al.

    High-Throughput Field-Based Phenotyping Using UAV

    INTRODUCTION

    Crop production must double by 2050 to meet the predicted

    production demands of the global population (Ray et al., 2013).

    The crop yield demands are predicted to increase by 2.4%

    annually, but the average rate of increase is only 1.3%, with

    yields stagnating in up to 40% of land under cereal production

    (Fischer and Edmeades, 2010). To ensure improved agricultural

    productivity, to adapt to the impacts of climate change, and to

    prevent the resistance of pests and diseases to control measures,

    scientists must better understand the connection between a

    plant’s observable characteristics (phenotype) and its genetic

    makeup (genotype). By establishing the connection between

    genotype and phenotype, it is possible to select high-yield stress-

    tolerant plants and improve agricultural production to satisfy the

    requirements of the growing human population (White et al.,

    2012; Li L. et al., 2014; Thorp et al., 2015). In the last two

    decades, gene sequencing of crops has proceeded at a rapid

    pace, but the translation of these data into the identiﬁcation

    of desirable traits is constrained by the lack of knowledge of

    the associated phenotypes (Furbank and Tester, 2011; Zaman-

    Allah et al., 2015). To relieve this bottleneck and to fully beneﬁt

    from the available genomic information, reliable, automatic,

    multifunctional, and high-throughput phenotyping platforms

    should be developed to oﬀer plant scientists new insight into

    all the aspects of living plants. In recent years, rapid high-

    throughput phenotyping platforms (HTPPs) have been discussed

    (Yang et al., 2013; Araus and Cairns, 2014), and most are

    fully automated facilities in greenhouses or growth chambers

    with precise environmental control. Although HTPPs enable the

    capture of detailed, non-invasive information throughout the

    plant life cycle, the results from controlled environments are

    distinct from the actual situations that plants will experience

    in the ﬁeld, making it diﬃcult to extrapolate the data to the

    ﬁeld.

    Abbreviations: AIC, Akaike information criterion; BGI2, Blue green pigment

    index2;

    BPN,

    Back

    propagation

    neural

    network;

    CAAC,

    Civil

    aviation

    administration of China; CARI, Chlorophyll absorption reﬂectance index; CCC,

    Crop canopy cover; CHM, Crop height model; CSI, Canopy structure index; DEM,

    Digital elevation model; DSM, Digital surface model; DVI, Diﬀerence vegetation

    index; EASA, European aviation safety agency; EVI, Enhanced vegetation index;

    FAA, Federal aviation administration; FBP, Field-based phenotyping; FBPPS,

    Field-based phenotyping platforms; GNDVI, Green normalized diﬀerence

    vegetation index; HTPPs, High-throughput phenotyping platforms; INS, Inertial

    navigation system; LAI, Leaf area index; LIDAR, Laser intensity direction and

    ranging; LNC, Leaf nitrogen concentration; MLR, Multivariate linear regression;

    NASA, National aeronautics and space administration; NDVI, Normalized

    diﬀerence vegetation index; NERCITA, National engineering research center for

    information technology in agriculture; NLI, Nonlinear index; OSAVI, Optimized

    soil-adjusted vegetation index; PLSR, Partial least squares regression; POS,

    Positioning and orientation system; PRI, Photochemical reﬂectance index; PSRI,

    Plant senescence reﬂectance index; PVI, Perpendicular vegetation index; RDVI,

    Renormalized diﬀerence vegetation index; RVI, Ratio vegetation index; SAR,

    Synthetic aperture radar; SAVI, Soil-Adjusted Vegetation Index; SLR, Stepwise

    linear regression; SMLR, Stepwise multiple linear regression; SR, Simple ratio;

    SVR, Support vector machines regression; TCARI, Transformed CAR Index;

    TD, Temperature diﬀerence; TVI, Triangular vegetation index; UAV, Unmanned

    aerial vehicle; UAV-RSP, Unmanned aerial vehicle remote sensing platforms; VDI,

    Vegetation drought index.

    Field-based phenotyping (FBP) is a critical component of crop

    improvement through genetics, as it is the ultimate expression

    of the relative eﬀects of genetic factors, environmental factors,

    and their interaction on critical production traits, such as yield

    potential and tolerance to abiotic/biotic stresses (Araus and

    Cairns, 2014; Neilson et al., 2015). FBP is increasingly recognized

    as the only approach capable of delivering the required

    throughput and an accurate description of trait expression

    in real-world cropping systems. The performance of breeding

    programs on crop yield and productivity must be evaluated under

    natural conditions (Gonzalez-Recio et al., 2014; Gonzalez-Dugo

    et al., 2015; Rahaman et al., 2015). Currently, the most commonly

    ﬁeld-based phenotyping platforms (FBPPs) use ground wheeled

    or aerial vehicles deploying multiple types of sensors to measure

    plant traits on a timescale of a few seconds per plot. For FBPPs

    based on ground vehicles, the process is time-consuming if there

    are too many plots needed to collect data (Zhang and Kovacs,

    2012). For example, more than 40 h were required to cover the

    20,000 plots with a single vehicle traveling at 2 km per h to

    measure traits on single rows (White et al., 2012). Using multiple

    vehicles and multiple sets of sensors to take measurements in

    all plots simultaneously would increase the costs (Zhang and

    Kovacs, 2012; Cobb et al., 2013). Moreover, FBPPs with ground

    vehicles cannot be used for cross-regional work due to the

    lack of maneuvrability. In the recent years, the cable-suspended

    ﬁeld phenotyping platform was developed for rapid and non-

    destructive estimation of crop traits. For the cable-suspend ﬁeld-

    based phenotyping platform, there’s advantages of safety, high

    precision, independent of soil conditions and minimal tactile

    interference of plants. However, as it has to be located at certain

    sites, the coverable area of cable-suspend ﬁeld phenotyping

    platform is relatively low, which limit its applications for the

    large-scale phenotyping (Kirchgessner et al., 2016). Some of these

    limitations can be addressed using satellite-based or aerial remote

    sensing approaches.

    Satellite imaging technologies have become an extremely

    useful tool for collecting data for various agricultural applications

    (Li L. et al., 2014; Sankaran et al., 2015b). However, the major

    limitations of using the currently available satellite sensors are

    the high cost, the lack of spatial resolution for the identiﬁcation

    of desirable traits, the risk of cloudy scenes and the long revisit

    periods (Issei et al., 2010; Gevaert et al., 2015). Alternatives based

    on manned airborne platforms have demonstrated capabilities

    for large-scale crop condition monitoring due to the high spatial

    and spectral resolutions of the sensors. However, in the case of

    breeding, and except for large seed companies, the high operating

    costs and the operational complexity have limited the use of

    these platforms to research activities (Chapman et al., 2014).

    Low-altitude and ﬂexible UAV-RSPs are an important, aﬀordable

    tool for crop phenotyping (Berni et al., 2009b; Liebisch et al.,

    2015)and precision agriculture (Hunt et al., 2005; Zhang and

    Kovacs, 2012; Ballesteros et al., 2014; Gomez-Candon et al., 2014;

    Candiago et al., 2015), and they provide a low-cost approach to

    meet the critical requirements of spatial, spectral, and temporal

    resolutions. In order to assess the precision and eﬃciency

    for ﬁeld-based phenotyping in small plots by diﬀerent remote

    sensing techniques, a direct comparison of three remote sensing

    Frontiers in Plant Science | www.frontiersin.org

    2

    June 2017 | Volume 8 | Article 1111

    Yang et al.

    High-Throughput Field-Based Phenotyping Using UAV

    approaches including UAV, proximal sensing, and satellite-based

    imagery was studied, which demonstrated that the UAV-based

    remote sensing performed best for acquiring canopy temperature

    and NDVI in breeding (Tattaris et al., 2016).Therefore, UAVs

    are becoming critical in crop phenotyping for high-throughput

    phenotyping of large numbers of plots and ﬁeld trials in a near

    real-time and dynamic manner. UAVs can be used to execute

    autonomous tasks through the use of radio remote control

    equipment and an auto-control system, which can be divided

    into several types according to the ﬂight mode (Sankaran et al.,

    2015b). Digital cameras, multispectral cameras, hyperspectral

    sensors, infrared thermal imagers, and light detection and

    ranging (LIDAR) are commonly deployed UAV-RSP sensors. The

    applications of these sensors for FBP include visible imaging for

    canopy surface modeling, crop height and biomass estimation

    (Mathews and Jensen, 2013; Diaz-Varela et al., 2014; Zarco-

    Tejada et al., 2014), visible–near-infrared spectroscopy to identify

    physiological status (Sugiura et al., 2005; Overgaard et al., 2010;

    Swain et al., 2010; Nigon et al., 2015), thermal imaging to detect

    water stress (Gonzalez-Dugo et al., 2013, 2014), LIDAR point

    cloud to measure plant ﬁne-scale geometric parameters with

    high precision (Wallace et al., 2012), and microwave images for

    estimating soil moisture and canopy structure parameters by

    combining diﬀerent spectral bands (Acevo-Herrera et al., 2010;

    Issei et al., 2010).

    The crop phenotype is an expression of the genotype

    and the environment in which it grows, including geometric

    traits (e.g., plant height, LAI, lodging, crop canopy cover),

    canopy spectral texture (spectral features), physiological traits

    (e.g., chlorophyll, biomass, pigment content, photosynthesis),

    abiotic/biotic stress indicators (e.g., stomatal conductance,

    canopy temperature diﬀerence, leaf water potential, senescence

    index), nutrients (nitrogen concentration, protein content), and

    yield. Diﬀerent methodological approaches based on spectra,

    canopy temperature, and visible light have been proposed to

    evaluate these traits in the ﬁeld (Araus and Cairns, 2014). The

    geometric traits of a crop can be estimated by building the digital

    surface model (DSM) or digital elevation model (DEM) and

    conducting image classiﬁcation analysis, which can be used to

    estimate the plant height, lodging area proportion, emergence,

    etc. (Hunt et al., 2005, 2010; Li J. W. et al., 2015). The absorption

    and reﬂectance characteristics of crops can be used to retrieve

    the physiological characteristics of a crop (Overgaard et al., 2010;

    Swain et al., 2010; Nigon et al., 2015). The canopy temperature

    is closely related to crop transpiration, which can reﬂect the leaf

    water potential, stomatal conductance, etc. under abiotic and

    biotic stress conditions. The combination of hyperspectral and

    thermal infrared data enables crop yield prediction (Berni et al.,

    2009b; Gonzalez-Dugo et al., 2015).

    This review considers the latest technological aspects of

    remote sensing from the state-of-the-art of UAVs to estimate

    plant phenotyping parameters at the ﬁeld-scale. The paper is

    organized as follows: (1) a literature survey of UAV remote

    sensing for ﬁeld-based crop phenotyping in the last decade,

    (2) an overview of low-altitude UAVs and deployed sensors,

    (3) advances and applications of UAV remote sensing in

    ﬁeld-based phenotyping, and (4) the limitations and future

    perspectives of UAV remote sensing for ﬁeld-based crop

    phenotyping.

    LITERATURE SURVEY

    There are 96 articles related to the keywords of “UAV,”

    “UAS,” “Drone,” “Unmanned Aerial Vehicle,” “Unmanned

    Aerial System,” “Unmanned Aircraft,” “Low Altitude Platform,”

    “Crop,” Plant,” “Crop breeding,” “Remote Sensing,” “Field-Based,”

    “Phenotyping,” and “Phenomics” in the Web of ScienceTM

    Core Collection Database (THOMSON REUTERSTM) until

    May 17, 2017. However, there are only six articles that

    explicitly include “Phenotyping” or “Phenomics” in the titles

    and keyword (Zaman-Allah et al., 2015; Gomez-Candon et al.,

    2016; Haghighattalab et al., 2016; Holman et al., 2016; Shi et al.,

    2016; Watanabe et al., 2017). The other literatures are closely

    related to crop phenotyping using UAV-RSPs but do not explicitly

    mention crop phenotype; the research focuses on one or more

    crop traits. The number of published articles for each year is

    shown in Figure 1A. There’s only one published articles during

    the period of 2005–2006. Most of the research focusing on ﬁeld-

    based crop phenotyping has been performed since 2007 and has

    rapidly increased each year. A total of 85 articles were published

    during the period of 2012–2017, accounting for 88.5% of the

    total literature related to FBP using UAV-RSPs. The citations

    of retrieved articles during the period of 2007–2017 are given

    in Figure 1B, showing that the number of citations from 2012

    to 2017 accounts for 94.4% of the total citations during that

    period. Considering the above literature statistics, ﬁeld-based

    crop phenotyping has become a research hotspot.

    The journals that published at least three articles related to

    the topic of this review paper are shown in Table 1. The journal

    with the greatest amount of related research ⟨⟨Remote Sensing⟩⟩

    published 17 articles, accounting for 17.7 % of all retrieved

    articles. The articles published in the journals of ⟨⟨Precision

    Agriculture⟩⟩ and ⟨⟨International Journal of Remote Sensing⟩⟩

    are 8 and 7, respectively. Most of the related articles have been

    published in journals focused on remote sensing and agriculture,

    which is consistent with the fact that the agricultural model and

    remote sensing technology are the core science and technology

    for FBP by UAV-RSP. The retrieved articles were statistically

    analyzed using the analytical tool “CiteSpace” (Chen, 2004), and

    an analysis of the keyword frequency is shown in Figure 2. The

    most frequently used keywords include “Precision agriculture,”

    “ unmanned aerial vehicle,” “UAV,” “Remote sensing,” and

    “vegetation index,” while “Phenotyping” and “Phenomics” were

    less frequently used. Even the research objectives of surveyed

    literatures focused on the crop growth monitoring, the crop

    phenotype includes numerous crop traits, such as traits related

    to the crop spectrum, structure, physiology, ecology, biotic stress,

    and abiotic stress (Pask et al., 2012). Thus, all the retrieved articles

    belonged to crop phenotyping by UAV-RSPs.

    Based on the above analysis, the development of UAV-RSPs

    for crop phenotyping has gradually become a hot topic and

    can provide theoretical and technical support for precision

    agriculture and crop breeding. In addition, there are rare reports

    Frontiers in Plant Science | www.frontiersin.org

    3

    June 2017 | Volume 8 | Article 1111

    Yang et al.

    High-Throughput Field-Based Phenotyping Using UAV

    FIGURE 1 | (A) Yearly literature count and (B) annual accumulated citation frequency
    for each article. The search was conducted on May 17, 2017.

    TABLE 1 | Relevant journals that have published more than three papers related

    to UAV remote sensing for ﬁeld-based crop phenotyping.

    Journals

    Numbers of papers

    Computers and electronics in agriculture

    3

    IEEE Journal of selected topics in applied earth

    observations and remote sensing

    3

    International journal of agricultural and

    biological engineering

    4

    International journal of applied earth

    observation and geoinformation

    3

    International journal of remote sensing

    7

    Journal of applied remote sensing

    5

    Plos one

    3

    Precision agriculture

    8

    Remote sensing

    17

    Sensors

    3

    The search was conducted on May 17, 2017.

    on FBP using UAV-RSPs in crop breeding (Issei et al., 2010;

    Torres-Sanchez et al., 2014, 2015). There is an urgent demand to

    develop strategies to rapidly and non-destructively acquire crop

    phenotypic data based on the current agricultural remote sensing

    technology. High-throughput ﬁeld-based crop phenotyping can

    relieve the bottleneck of “linking genotype and phenotype” to

    accelerate the eﬃciency of crop breeding.

    UAV PLATFORMS AND DEPLOYED

    SENSORS

    Overview of UAV-Based Phenotyping

    Platforms

    FBP using UAV-RSPs is based on an unmanned aircraft equipped

    with multiple sensors, using communication technology and

    GPS positioning technology to rapidly and non-destructively

    acquire high-resolution images about the crop canopy in the ﬁeld.

    Remote sensing retrieval models are then used for phenotyping

    ﬁeld trials after data processing (Sugiura et al., 2005; Li W.

    et al., 2016). The typical UAVs used for FBP include multi-

    rotors, helicopters, ﬁxed-wing, blimps and ﬂying wing (Table 2;

    Sankaran et al., 2015b) and are selected based on the purpose

    and budget. Blimps have the advantages of hovering ability,

    higher eﬀective loads and the ability of vertical take-oﬀ and

    landing; however, they are slow because of the large size,

    and their stability is poor under windy conditions, making it

    diﬃcult to obtain accurate information (Liebisch et al., 2015).

    Unmanned helicopters have the advantage of being able to take-

    oﬀ and land vertically, ﬂy sideways, and hover. The helicopter

    payload is larger than that of a multi-rotor UAV and can

    support large sensors, such as LIDAR. However, the complex

    operation, lack of free hover, high maintenance cost and noise

    limit the application of helicopters (Sugiura et al., 2005; Swain

    et al., 2010; Chapman et al., 2014). The ﬁxed-wing UAV is

    characterized by fast ﬂying velocity and long ﬂight time; however,

    the bottleneck for the ﬁxed-wing application of FBP is the lack

    of free hover ability and the image blur caused by higher speeds

    and altitudes (Herwitz et al., 2004; Link et al., 2013). Multi-

    rotor UAVs have the advantages of low cost, the ability to hover,

    low take-oﬀ and landing requirements and are most frequently

    used for FBP. However, the greatest limitations of multi-rotor

    UAVs are the relatively short ﬂight time, lower payload and

    the sensitivity to weather (Zhang and Kovacs, 2012; Pena et al.,

    2013; Uto et al., 2013; Nasi et al., 2015). Traditional UAV

    manufactured body materials are metals, such as aviation steel

    and aluminum (Colomina and Molina, 2014; Salami et al., 2014;

    Pajares, 2015). To reduce the UAV weight, enhance the body

    strength and prolong ﬂight time, a variety of lightweight, high-

    strength composite materials have been widely used, including

    glass ﬁber and carbon ﬁber, and have become the main alternative

    materials for the body of UAVs. For the engine, the UAV engines

    can be divided into two categories: oil and electric engine.

    The oil engines have the advantages of strong wind resistance

    and long working time, while there’re disadvantages of being

    bulky, producing big vibration and having poor reliability, which

    lead to the image blur (Xiang and Tian, 2011; Sankaran et al.,

    2015b). The electric engines have the advantages of safe, small

    vibration, easy to maintain and low cost, which make it become

    Frontiers in Plant Science | www.frontiersin.org

    4

    June 2017 | Volume 8 | Article 1111

    Yang et al.

    High-Throughput Field-Based Phenotyping Using UAV

    FIGURE 2 | Frequency of keywords usage within total searched articles. The bigger
    font size, the more high frequency of usage, same as circle size corresponding
    to

    each keyword.The different color line just show connections among keywords or
    searched papers, respectively.

    an important way for crop phenotyping by UAV; however, the

    short ﬂight endurance time and weak wind resistance limited its

    use for crop phenotyping at large scale. A series of propulsion

    systems with the advantages of small volume, low vibration

    and new energy sources have become available and have greatly

    enhanced the UAV payload space and capacity. Hale engines and

    low-altitude silent propulsion systems are necessary to satisfy

    the requirements of small- and medium-size UAVs (Verhoeven,

    2009).

    The UAV body, ﬂight control system, remote control, sensors

    and oil/electric energy are the minimum required components

    for a UAV-RSP; while the ground station that enables the ﬂight

    route planning and ﬂight parameters setting, is an optional tool.

    The ﬂight control system of a UAV is the core of the whole ﬂight

    process, including take-oﬀ, ﬂying in the air, executing tasks and

    recovery, and is one of the key technologies of a UAV system.

    Taking the UAV-RSP that was used for ﬁeld phenotyping in

    crop breeding by NERCITA in China for example to illustrate

    the components of a UAV-RSP (Figure 3). The route planning

    tool of a UAV can set the ﬂight height, ﬂight speed, ﬂight

    location and missions, and the ﬂight details are transmitted to the

    ﬂight control system through a data transceiver, which enables

    automatic take-oﬀ, the implementation of a default route, guided

    ﬂight, and automatic landing.

    Sensors Deployed by Small UAVs

    UAV platform equipped with visible light imaging sensors,

    spectral sensors, infrared thermal sensors, ﬂuorescence sensors,

    LIDAR et al. can obtain the color, texture, geometric contour of

    crops, which can be used to monitor plant height, LAI, biomass

    and other physiological traits of crops in diﬀerent growth stages

    (Zhang and Kovacs, 2012; Rahaman et al., 2015; Table 3). As the

    equipped sensors are restricted by the UAV’s payload capacity,

    which must meet the criteria of high precision, light weight, low

    power consumption and small size. Considering the cost, UAV

    payload and technological development of commercial products,

    digital camera (RGB), multispectral camera, infrared thermal

    imager, hyperspectral camera, LIDAR, three-dimensional camera

    and synthetic aperture radar (SAR) are the main sensors

    equipped by UAV-RSPs so far (Chapman et al., 2014; Sankaran

    et al., 2015b). The UAV-RSPs adopted by NERCITA were shown

    in Figure 4.

    Digital Camera

    UAVs equipped with digital cameras can quickly acquire

    grayscale or color images to estimate crop height, leaf angel

    distribution, LAI, lodging and leaf color et al. (Ballesteros et al.,

    2014; Bendig et al., 2014; Chapman et al., 2014). RGB camera

    is the most commonly deployed by UAV in crop phenotyping

    research. The sensor has the advantages of low cost, light weight,

    convenient operation, simple data processing, and relatively low

    working environment requirements. Data can be collected under

    both sunny and cloudy conditions, but exposure should be set

    on the basis of the weather conditions to avoid inadequate

    or excessive image exposure. Unfortunately, this method is

    insuﬃcient to accurately analyse crop phenotypic information for

    physiological traits due to the limitation of the less visible light

    bands.

    Frontiers in Plant Science | www.frontiersin.org

    5

    June 2017 | Volume 8 | Article 1111

    Yang et al.

    High-Throughput Field-Based Phenotyping Using UAV

    TABLE 2 | Typical types of UAVs used for ﬁeld-based crop phenotyping.

    Speciﬁcation

    Description

    Multi-rotor

    Helicopter

    Fixed-wing

    Blimps

    Flying wing

    Model

    DJIS1000+

    AXH-E230

    Bat-3

    CB3000

    Pathﬁnder-Plus

    Manufacturer

    DJI technology

    AVIX

    MLB Co.

    Beijing CSCA Co.

    AeroVironment

    Materials

    Carbon ﬁber, High strength

    performance engineered

    plastics

    Carbon ﬁber, aluminum

    alloy

    Carbon ﬁber,

    engineered plastics

    Kevlar ﬁbers, ﬁber

    optic, electrical cores

    Carbon ﬁber, Nomex, Kevlar, plastic

    sheeting, plastic foam

    Cost

    Low

    Medium

    Medium

    High

    very high

    Power/Motors

    Eight electric, 0.5 kw max each

    One BLDC motors

    Two-stroke engine

    One oil engine

    Eight (8) solar-electric, 1.5 kW max

    each

    Gross weight/kga

    6

    15

    56

    300

    318

    Payload capacity/kgb 7

    15

    9

    10

    67.5

    Speed/m s-1

    12

    23

    33

    15

    14

    Endurance/hc

    0.25

    0.8

    6

    12

    15

    Altitude ceiling/m

    500d

    3,000

    3,000

    120

    25,000

    aTotal weight with a battery; bThe payload including battery; cEndurance with
    maximum payload; dThe maximum ﬂight height in China (the ﬂight control system
    was restricted by the

    national regulations to set the ﬂight height lower than 500 m).

    FIGURE 3 | The components of a UAV adopted by NERCITA for ﬁeld phenotyping in
    crop breeding. (A) An eight-rotors UAV named DJI Spreading Wings S1000+;

    (B) DJI ﬂight control system named WOOKONG-M; (C) DJI Lightbridge 2 remote control;
    (D) Self-developed gimbal; (E) User interface of DJI Ground Station.

    Frontiers in Plant Science | www.frontiersin.org

    6

    June 2017 | Volume 8 | Article 1111

    Yang et al.

    High-Throughput Field-Based Phenotyping Using UAV

    TABLE 3 | Speciﬁcations and applications of typical UAV-deployed sensors.

    Type

    Model

    Weight (g)

    Spectral bands

    Wavelength

    range

    Applications

    Advantages

    Disadvantages

    References

    Digital

    camera

    Sony DSC-QX100

    179

    Red, Green, Blue

    –

    Leaf color, plant height,

    lodging, canopy cover,

    fraction of intercepted

    radiation, LAI, 3D structure,

    leaf angle distribution

    Low cost, light weight,

    convenient operation, simple

    data processing

    Image amplitude, low

    radiometric resolution,

    lack of proper calibration

    Samseemoung et al.,

    2012; Chapman et al.,

    2014; Torres-Sanchez

    et al., 2014; Guo et al.,

    2015

    Canon Ixus 110 IS RGB

    145

    Red, Green, Blue

    –

    Multispectral

    camera

    Tetracam ADC-Lite

    200

    Red, Green, NIR

    520∼920 nm

    Leaf nitrogen content, yield,

    LAI, chlorophyll, biomass,

    weed, emergence, spring

    stand

    Low cost, ﬂexibility

    Less bands, low spectral

    resolution and

    discontinuous spectrum

    Overgaard et al., 2010;

    Swain et al., 2010; Nasi

    et al., 2015; Sankaran

    et al., 2015a; Vega et al.,

    2015

    Tetracam MCA-6

    530

    6

    490∼920 nm

    Hyperspectral

    imager

    Cubert UHD185

    470

    125

    450–950

    Net photosynthesis, LAI,

    biomass, nitrogen,

    chlorophyll, yield, disease

    detection

    More bands, high spectral

    resolution, ability of imaging

    High cost, cumbersome

    data processing, sensitive

    to weather

    Zarco-Tejada et al., 2013;

    Nigon et al., 2015

    HySpex VNIR-1600

    4,600

    160

    400–1,000

    Micro-Hyperspec VNIR

    model

    700

    324

    380–1,000

    Thermal

    imager

    FLIR Thermovision

    A40M

    1,400

    –

    7.5–13 µm

    Canopy temperature,

    stomatal conductance,

    water potential

    Indirect determination of crop

    growth status under abiotic and

    biotic stress

    Sensitive to the weather,

    frequent calibration,

    difﬁcult to eliminate the

    inﬂuence of soil

    background

    Berni et al., 2009b;

    Torres-Sanchez et al.,

    2015

    LIDAR

    RIEGL VUX-1UAV

    3,500

    NIR

    –

    Plant height, biomass

    Rich point cloud information,

    Effective acquisition of high

    precision horizontal and vertical

    vegetation canopy structure

    parameters

    High cost, Large data

    processing

    Wallace et al., 2012;

    Wang et al., 2014

    Frontiers in Plant Science | www.frontiersin.org

    7

    June 2017 | Volume 8 | Article 1111

    Yang et al.

    High-Throughput Field-Based Phenotyping Using UAV

    The orthoimage or DSM/DEM is the ultimate product of

    aerial photography. For the digital images, as there’s signiﬁcant

    eﬀect of interior orientation elements and camera distortion

    on image quality, the inspection and distortion processing of

    images according to the camera models are required. Then the

    homogeneous treatment for images is needed to enable the

    consistency of brightness, grayscale, and texture among images.

    The second step is to match the images according to the feature

    points of each image, the scale-invariant feature transform

    (SIFT) and random sample consensus (RANSAC) algorithm

    were adopted to process and optimize images. Finally, as the

    UAV can’t acquire the images at large scale due to limitations

    of imaging devices and techniques, in order to evaluate the

    crop growth status throughout the study area, the orthoimage

    need to be generated using automatic splicing software, such

    as Photoscan, after aerial triangulation (Colomina and Molina,

    2014). As each pixel value of images can be calculated from the

    reﬂectance or radiance of speciﬁc bands, then the color indices

    can be extracted with high-resolution images acquired by UAV

    to identify the vegetation features (Holman et al., 2016; Du and

    Noguchi, 2017).

    Multispectral/Hyperspectral Imaging Sensor

    UAVs with spectral imaging sensors can obtain the spectral

    absorption and reﬂectance characteristics of crops, which can

    be used to monitor the crop planting area and crop growth,

    to evaluate the biological and physical characteristics of a crop,

    and to predict crop yield (Overgaard et al., 2010; Lebourgeois

    et al., 2012; Honkavaara et al., 2013; Candiago et al., 2015; Nigon

    et al., 2015). Multispectral and hyperspectral imaging sensors

    are the commonly deployed by UAV. Multispectral imaging

    sensors are deﬁned as hardware that are capable of sensing

    and recording radiation from invisible as well as visible parts

    of the electromagnetic spectrum, which have been widely used

    for crop phenotyping due to the advantages of low cost, fast

    frame imaging and high work eﬃciency; however, they are

    limited by the low number of bands, low spectral resolution,

    and discontinuous spectrum (Berni et al., 2009b; Issei et al.,

    2010; Overgaard et al., 2010; Diaz-Varela et al., 2014; Candiago

    et al., 2015). Hyperspectral imaging sensors are cameras that can

    obtain a large number of very narrow bands and continuous

    spectra. Compared with multispectral imagers, hyperspectral

    imagers have the advantages of more band information and

    higher spectral resolution and can accurately reﬂect the spectral

    characteristics of the crop in the ﬁeld and the spectral diﬀerences

    between crops (Zarco-Tejada et al., 2012, 2013; Colomina

    and Molina, 2014). In recent years, hyperspectral imaging has

    become a common way to acquire crop traits, such as crop

    water content, leaf nitrogen concentration, chlorophyll content,

    LAI, and other physical and chemical parameters, to facilitate

    crop yield prediction. Hyperspectral imaging technology is the

    future trend for crop phenotyping research using UAV-RSPs;

    however, the applicability of the physical inversion model based

    on hyperspectral remote sensing, the complex mechanisms of

    mixed spectral decomposition models for many kinds of ﬁeld

    components (crop, soil, etc.) and an element extraction method

    require further research (Overgaard et al., 2010; Thorp et al.,

    FIGURE 4 | The UAV-RSPs adopted by NERCITA for ﬁeld phenotyping in crop

    breeding. (A) A DJI Spreading Wings S1000+ equipped with hyperspectral

    imager (Cubert UHD185), thermal infrared imager (Optris PI400) and digital

    camera (Sony DSC-QX100); (B) A RIEGL RiCOPTER equipped with LIDAR

    (RIEGL VUX-1UAV) (Consent obtained from the individual for the publication).

    2015). The pre-processing of spectral images mainly contains

    the radiometric calibration, geometric correction, image fusion

    and image enhancement. Then the spectral reﬂectance can be

    extracted using software, such as ArcGis, ENVI, etc. to build

    vegetation indices for retrieving crop phenotypic traits (Nasi

    et al., 2015).

    Thermal Infrared Imaging Sensor

    Thermal infrared imaging sensors that using infrared detectors

    and an optical imaging lens to receive infrared radiation

    energy in the photosensitive element infrared detector can

    produce time series or single-time-point analysis based data,

    which have been widely used for crop growth monitoring and

    water stress detection (Gonzalez-Dugo et al., 2013, 2015). As

    the stomatal conductance, photosynthetic characteristics and

    transpiration rate are closely related to canopy temperature, the

    infrared thermal imaging technology can be used to determine

    the response of crops under stress conditions (Baluja et al.,

    2012). The conventional method for the determination of crop

    canopy temperature is using a handheld infrared thermometer,

    which is diﬃcult to perform in the crop canopy temperature

    under diﬀerent experimental conditions simultaneously, making

    it diﬃcult to compare the diﬀerence in canopy temperature

    between treatments because the crop canopy temperature

    changes over time. In addition, the selection of the area for

    measurement is subjective and random (Berni et al., 2009b).

    UAVs equipped with infrared thermal imagers can quickly

    and non-destructively acquire the crop canopy temperature,

    which can eﬀectively identify the temperature diﬀerences in

    the crop canopy under diﬀerent environmental conditions. The

    thermal sensitivity is generally less than 80 mK. However, as the

    canopy temperature is sensitive to the environmental conditions,

    eliminating the inﬂuence of background temperature, including

    the incoming solar radiation, the ambient air temperature and the

    wind speed, is required (Sugiura et al., 2007; Deery et al., 2014).

    The most commonly adopted methods for achieving the goal

    include using sheet backgrounds to eliminate the background

    temperature, determining the percentage of bare soil and covered

    leaves in each image (Jones et al., 2009), and masking the data

    over a known background temperature (Chapman et al., 2014).

    Frontiers in Plant Science | www.frontiersin.org

    8

    June 2017 | Volume 8 | Article 1111

    Yang et al.

    High-Throughput Field-Based Phenotyping Using UAV

    TABLE 4 | Typical applications of ﬁeld-based crop phenotyping by UAV-RSPs.

    UAV

    platform

    Sensors

    Crop

    Flight

    altitude

    Research

    objects

    Methods

    Indices

    Variables

    Best

    performance

    References

    Type

    Model

    Airborne

    LiDAR

    Leica ALS70

    Maize

    1,500 m

    Plant height estimation

    Image analysis

    Normalized point heights

    Plant height

    R2 = 0.79

    Li Z. et al., 2014; Li

    W. et al., 2015

    LAI estimation

    Beer–Lambert equation

    Laser intensities

    LAI

    R2 = 0.78

    Biomass estimation

    Structural equation

    modeling

    Crop height, LAI

    Aboveground

    biomass

    R2 = 0.82

    Hyperspectral

    camera

    AISA-Eagle

    Potato

    1,900 m

    Leaf N concentration

    detection

    Quantitative inversion

    model

    Nitrogen Sufﬁciency Index

    (NSI)

    Leaf N

    concentration

    R2* = 0.79

    Nigon et al., 2015

    Fixed-wing

    UAV

    Digital Camera

    Ricoh GXR A12

    Maize

    375 m

    Lodging estimation

    Image analysis

    RGB gray level, optimum

    features

    Lodging area

    about 99.7 %

    Li Z. et al., 2014

    Hyperspectral

    camera

    Micro-

    Hyperspec

    VNIR

    Vineyards

    575 m

    Estimation of net

    photosynthesis

    Fraunhofer Line Depth

    (FLD) principle based

    on three spectral bands

    FLD3 [Three bands for the in

    (L763 nm) and out bands

    (L750 nm; L780 nm)]

    Net

    photosynthesis

    R2 = 0.52

    Colomina and

    Molina, 2014

    Multispectral

    Camera

    Tetracam

    ADC-Lite

    Maize

    150 m

    Low-nitrogen stress

    detection and grain

    yield prediction

    Quantitative inversion

    model

    Normalized Difference

    Vegetation Index (NDVI),

    Canopy Structure Index

    (CSI)

    Yield

    R2 = 0.40

    Overgaard et al.,

    2010

    Multispectral

    Camera

    Canon S110 NIR

    Weed

    115 m

    Weed detection

    Image Analysis

    Three UAV bands and

    texture layer

    Silybum

    marianum (L.)

    overall

    accuracy of

    87.04%

    Tamouridou et al.,

    2017

    Multispectral

    Camera

    Tetracam MCA-6

    Peach

    150 m

    Mapping radiatio n

    interception

    Image Analysis,

    radiative transfermodel

    inversion

    NDVI

    fIPAR

    R2 = 0.85

    Guillen-Climent

    et al., 2012

    citrus

    R2 = 0.84

    Hyperspectral

    camera

    Micro-

    Hyperspec

    VNI

    Citrus

    575 m

    Water stress detection

    Quantitative inversion

    model

    Photochemical Reﬂectance

    Index (PRI)

    Stomatal

    conductance

    R2 = 0.59

    Zarco-Tejada et al.,

    2012

    Thermal

    Camera

    Miricle 307

    Crown temperature

    R2 = 0.78

    Flying wing

    Multispectral

    Camera

    DuncanTech

    MS3100

    Cherries

    6,400 m

    Agricultural surveillance

    and decision support

    Quantitative inversion

    model

    Pixels with channel 3

    (ch3)/Pixels with channel 2

    (ch2)

    Mature ratio

    R2 = 0.81

    Herwitz et al., 2004

    Helicopter

    Digital Camera

    Ricoh GR Digital

    III/IV

    Sorghum

    60 m

    Ground cover

    estimation

    Image Analysis

    –

    Ground cover

    R2 = 0.77

    Chapman et al.,

    2014

    Multispectral

    Camera

    Tetracam ADC

    Rice

    20 m

    Yield prediction

    Quantitative inversion

    model

    NDVI

    Yield

    R2 = 0.72

    Swain et al., 2010

    Total biomass

    estimation

    Biomass

    R2 = 0.75

    (Continued)

    Frontiers in Plant Science | www.frontiersin.org

    9

    June 2017 | Volume 8 | Article 1111

    Yang et al.

    High-Throughput Field-Based Phenotyping Using UAV

    TABLE 4 | Continued

    UAV

    platform

    Sensors

    Crop

    Flight

    altitude

    Research

    objects

    Methods

    Indices

    Variables

    Best

    performance

    References

    Type

    Model

    Multispectral

    Camera

    Tetracam

    Corn

    150–200

    m

    LAI and Chlorop hyll

    estimation

    Quantitative inversion

    model

    NDVI

    LAI

    R2 = 0.50

    Berni et al., 2009b

    MCA-6

    Olive,

    Peach

    TCARI/OSAVI

    Chlorophyll

    concentration

    R2 = 0.88

    Thermal

    Camera

    FLIR

    Thermovision

    A40M

    Olive

    1,000 m

    Mapping canopy

    conductance

    Energy balance model

    Canopy temperature

    Canopy

    conductance

    R2 = 0.61

    Berni et al., 2009a

    Multi-rotor

    UAV

    Digital Camera

    Digital

    photography

    camera PENTAX

    A40

    Onion

    40 m

    LAI estimation

    Image Analysis

    Canopy visual scores

    LAI

    R2 = 0.83

    Corcoles et al., 2013

    Digital Camera

    Panasonic

    Lumix GX1

    Barley

    50 m

    Plant height and

    biomass estimation

    Image Analysis

    Crop surface model

    Plant height

    R2 = 0.92

    Bendig et al., 2014

    Fresh

    biomass

    R2 = 0.81

    Dry biomass

    R2 = 0.82

    Digital Camera

    Aeryon Photo3S

    Soybean

    120 m

    Crop growth monitoring

    Image analysis

    –

    Lodgin

    –

    Zhang et al., 2014

    Multispectral

    Camera

    Tetracam

    ADC-Lite

    NDVI

    Fall

    armyworm

    Digital

    Camera/

    Multispectral

    Camrea

    Pentax Optio

    A40; Tetracam

    ADC

    Maize

    Onion

    25 m

    Green canopy cover

    and LAI estimation

    Quantitative inversion

    model

    VARIgreen

    Green canopy

    cover

    R2 = 0.94

    R2 = 0.96

    Ballesteros et al.,

    2014

    Digital

    Camera/

    Multispectral

    Camrea

    Olympus PEN

    E-PM1;

    Tetracam

    mini-MCA-6

    Maize,

    Sunﬂower

    and

    Wheat

    30 m

    Vegetation detection

    Object Based Image

    Analysis

    ExG and NDVI

    Crop

    classiﬁcation

    errors

    between 0%

    and 10%

    Torres-Sanchez

    et al., 2015

    Digital Camera

    Sony NEX 7

    Wheat

    45 m

    Growth monitoring

    Image Analysis

    Crop surface model

    Crop height

    R2 = 0.99

    Holman et al., 2016

    Digital Camera

    SONY

    ILCE-6000

    Wheat

    100 m

    Growth monitoring

    Image Analysis

    VDVI, NGBDI, GRRI, ExG

    Yield

    R2 = 0.94

    Du and Noguchi,

    2017

    Hyperspectral

    camera

    Developed

    256-band

    Hyperspectral

    Sensor

    Rice

    10 m

    Chlorophyll Density

    estimation

    Quantitative inversion

    model

    Red-edge (RE) and

    near-infrared (NIR) spectral

    Chlorophyll

    density

    R2 = 0.64

    Uto et al., 2013

    Hyperspectral

    camera

    Cubert UHD185

    Barley

    30 m

    Vegetation monitoring

    Quantitative inversion

    model

    BGI2

    Chlorophyll

    R2 = 0.52

    Aasen et al., 2015

    RDVI

    LAI

    R2 = 0.32

    RDVI

    Fresh

    biomass

    R2 = 0.29

    (Continued)

    Frontiers in Plant Science | www.frontiersin.org

    10

    June 2017 | Volume 8 | Article 1111

    Yang et al.

    High-Throughput Field-Based Phenotyping Using UAV

    TABLE 4 | Continued

    UAV

    platform

    Sensors

    Crop

    Flight

    altitude

    Research

    objects

    Methods

    Indices

    Variables

    Best

    performance

    References

    Type

    Model

    Hyperspectral

    Camera/

    Thermal

    Camera

    Micro-

    Hyperspec

    VNIR,

    Wheat

    345 m

    Physiological

    Conditions assessment

    Quantitative inversion

    model

    Modiﬁed soil-adjusted

    indices (MSAVI)

    Yield

    R2 = 0.31

    Gonzalez-Dugo

    et al., 2015

    FLIR SC655

    Quantitative inversion

    model

    Crop Water Stress Index

    (CWSI)

    Yield

    R2 = 0.53

    Information fusion of

    Multi-sources remote

    sensing

    CWSI, FLD, PRI

    Yield

    R2 = 0.77

    Multispectral

    Camera

    Tetracam

    ADC-Lite

    Sunﬂower

    75 m

    Phenotypic analysis

    Quantitative inversion

    model

    NDVI

    Yield

    R2 = 0.74

    Rosen et al., 2006

    Biomass

    R2 = 0.90

    Nitrogen

    content

    R2 = 0.96

    Multispectral

    Camera

    XNiteCanon

    SX230 NDVI

    Wheat

    100 m

    Crop growth monitoring

    Image analysis

    GNDVI

    Emergence

    R2 = 0.76

    Zhang et al., 2014

    Spring stand

    R2 = 0.74

    Multispectral

    Camera

    Tetracam

    miniMCA6

    Citrus

    100 m

    Huanglongbing (HLB)

    detection

    Quantitative inversion

    model

    NDVI, GNDVI, SAVI, NIR, R

    Classiﬁcation

    accuracy

    about 85%

    Garcia-Ruiz et al.,

    2013

    Multispectral

    Camera

    Tetracam

    ADC-lite

    Vineyard

    150 m

    Vineyard detection:

    mapping crop variability

    indices

    Image Analysis,

    quantitative inversion

    model

    NDVI

    Vineyard

    variability

    indices

    higher than

    95%,

    Comba et al., 2017

    *Coefﬁcient of determination (R2).

    Frontiers in Plant Science | www.frontiersin.org

    11

    June 2017 | Volume 8 | Article 1111

    Yang et al.

    High-Throughput Field-Based Phenotyping Using UAV

    As directly using the surface temperature of crop canopy for

    retrieving stomatal conductance or water potential is risky for the

    reason of inﬂuence soil pixels. In addition, canopy temperature

    on its own is not suﬃcient to derive stress, evapotranspiration or

    other similar parameters (Ortega-Farias et al., 2016). Therefore,

    it is needed to perform the whole energy balance, taking into

    account air temperature, wind speed, wind direction, etc. For the

    thermal infrared image processing, diﬀerent methods including

    eliminating all pixels outside the expected temperature range for

    the leaves and using automated thresholding algorithms such

    as the Otsu method have been adopted to automatically extract

    canopy temperature (Gonzalez-Dugo et al., 2013). However, the

    presence of mixed pixels (pixel containing signals from both

    soil and vegetation) is a big problem for heterogeneous canopy

    (Baluja et al., 2012). The inﬂuence of mixed soil pixels can be

    reduced with thermal infrared data fusion with RGB image.

    However, the data fusion for image pre-processing is consuming

    and subjective.

    LIDAR

    LIDAR is a surveying method that measures distance to a target

    with emitting laser light. It is an active remote sensing device

    that uses the laser as the transmitting light source and adopts

    the photoelectric detection method. LIDAR is composed of a

    transmitter, receiver, tracking frame and information processing

    module, which has the advantages of high point density, high

    spatial resolution, smaller and lighter than traditional microwave

    radar, and good performance for low-altitude detection (Wallace

    et al., 2012). As the emitted pulse interacts with the canopy

    portions of it are returned by diﬀerent elements, and the time

    delay between them provide the information about the horizontal

    and vertical canopy structure parameters. Simple LIDARs only

    measure ﬁrst and last returns, while full-waveform ones return

    the photon density for a range of time delays. The limitations of

    LIDAR include the high cost, narrow beam, large data processing,

    and laser pulse can be totally absorbed by water, which greatly

    aﬀect the popularity and application of LIDAR technology.

    LIDAR has been applied to estimate biomass and plant height

    of trees, and there are few applications of crop phenotyping

    using LIDAR (Ota et al., 2015). The methods used for extracting

    structural parameters in the forest are not suit for crop, because

    the plant height of crop is too low and the pattern of leaves

    aggregation was plant centered. Thus, it’s necessary to explore

    strategies for extracting crop structural parameters by LIDAR.

    SAR

    SAR is an imaging radar used for conducting coherent processing

    of the received echo in diﬀerent locations to obtain high-

    resolution data. SAR is a type of active microwave sensor that

    can be categorized into two types, focused and non-focused.

    SAR can obtain high-resolution radar images similar to optical

    images in very low visibility weather conditions and can work

    around the clock, which can be used for crop identiﬁcation,

    crop acreage monitoring, key crop trait estimation and yield

    prediction, providing strong technical support for large-scale

    crop growth monitoring by remote sensing (Rosen et al., 2006;

    Wang et al., 2014).

    In summary, UAVs deploy sensors with the advantages of

    ﬂexible and convenient operation, on-demand access to data and

    high spatial resolution as an important means to rapidly and

    non-destructively acquire ﬁeld-based crop phenotypes. However,

    because the remote sensing information from a single sensor

    is limited, combining multi-sensors to acquire and integrate

    data is necessary for ﬁeld-based crop phenotyping by UAV-

    RSPs. In addition, as the image quality can be inﬂuence by wind

    speed, ﬂight altitude and speed, sensor performance, aircraft

    vibration and image correction method etc., exploring strategies

    for acquiring images with high quality is necessary. The ability

    to eﬃciently process “big” remote sensing data acquired by UAV

    remains a challenge, as well as the ability to develop robust and

    fast algorithms according to the sensors used.

    Universal Data Processing Methods

    The pre-processing of remote sensing images is the basis for

    retrieving crop phenotype by UAV Remote Sensing. As there exist

    geometric and radiation distortion for remote sensing images,

    which were caused by the atmosphere, sensor characteristics,

    UAV attitude et al. Thus, it’s necessary to eliminate the geometric

    and radiation distortion before retrieving crop phenotype by

    remote sensing images. Geometric and radiometric correction

    are two basic pre-processing techniques for UAV remote sensing

    data.

    Geometric Correction

    There usually contains geometric deformation for the original

    images obtained by the UAV remote sensing platform due to

    the inﬂuence of the attitude and speed of UAV platform, the

    displacement of surface elevation model and the change of

    observed projection. Thus, the geometric correction of UAV

    remote sensing images is a prerequisite for subsequent data

    processing and analysis. The commonly adopted methods for

    geometric correction can be divided into two categories: (1)

    Geometric correction based on UAV POS Data (Yang et al., 2015);

    (2) Geometric correction based on high precision diﬀerential

    GPS (Saskia et al., 2017). The ground control points must be

    set for the traditional method, while the geometric correction

    can be achieved using low precision POS data of the UAV

    without setting ground points, which can improve the eﬃciency

    of UAV remote sensing images processing. DEM has been widely

    used in monitoring crop height and biomass, which usually

    can be generated with methods, such as moving surface ﬁtting,

    multi-faceted function and ﬁnite element method for DEM

    interpolation (Liang et al., 2013).

    Spectral Radiation Processing

    The electromagnetic energy received by the UAV deployed

    sensors is inconsistent with the physical reﬂectance or the

    spectral radiation brightness of the target due to the atmospheric

    conditions, the physical characteristics of the sensor, the sun’s

    position and the angle of measurement (Zhao et al., 2014).

    Therefore, in order to correctly reﬂect the spectral reﬂectance

    or radiation characteristics, radiation correction is required

    to eliminate or correct the various noise attached to the

    sensor’s output radiant energy in the process of remote sensing

    Frontiers in Plant Science | www.frontiersin.org

    12

    June 2017 | Volume 8 | Article 1111

    Yang et al.

    High-Throughput Field-Based Phenotyping Using UAV

    imaging. Spectral radiation calibration refers to the process

    of converting a digital number (DN) of images acquired by

    UAV deployed sensors into physical parameters (Liang, 2008),

    such as radiation brightness, reﬂectance or surface temperature,

    which includes relative calibration and absolute calibration.

    The commonly adopted reﬂectance conversion methods include

    linear regression model, ﬂat ﬁeld model, internal mean method,

    logarithmic residual model and dark target method et al. The

    atmospheric correction can be neglected as the atmosphere

    between the surface and the sensor has a weak inﬂuence

    on the radiation of the sensor entrance with the relatively

    low ﬂight attitude of micro-UAV (Hernandez-Lopez et al.,

    2012). The spectral reﬂectance or vegetation indices derived

    from hyperspectral images were inﬂuenced by the angular

    view of UAV-deployed sensors. Radiative transfer models can

    be act as useful tools for correcting angular inﬂuences over

    vegetated environments (Burkart et al., 2015). Spectral feature

    extraction is the process of the decomposition, reconstruction

    and selection of the spectral measurement, which can be divided

    into three categories, namely the statistical reduction method,

    the characteristic spectral line method and the spectral line

    method according to the characteristic expression formula (Li,

    2012). The statistical reduction method is the most widely used

    method for spectral feature extraction, which has the advantages

    of easy to operate and use, while there’s the disadvantage

    of lack of physical meaning. The commonly used statistical

    reduction methods include principal component analysis,

    wavelet transform, manifold learning and supervised correlation

    vector machine, support vector machine and discriminant

    analysis (Laliberte et al., 2011). The essence of the method is

    the decomposition, reorganization and selection of the celestial

    radiant energy in order to remove redundant noise, and convert

    the signal into the pattern easy to process in the subsequent

    application. The advantage of the feature spectrum method is

    that the good physical meaning, but it is often computationally

    intensive and ineﬃcient. The results lack of representation for the

    spectral characteristics when there’s more spectral times and less

    observation data. There’s also the advantage of strong physical

    meaning for the spectral line method, however, it’s sensitive to

    the spectral complexity and instrument calibration (Liang et al.,

    2013).

    Universal Modeling Methods

    The main adopted methods for crop phenotyping by UAV remote

    sensing include image analysis, physical model method, empirical

    statistic method and advanced data analysis method, such as

    machine learning (Liang et al., 2013; Bendig et al., 2015). As

    the modern imaging techniques can allow for the visualization

    of multi-dimensional and multi-parameter data, the high-

    resolution images acquired by UAV remote sensing platform

    have been used for estimating crop structure characteristics

    using image analysis method (Torres-Sanchez et al., 2015). The

    objected-based image analysis method works with groups of

    homogeneous and contiguous pixels, which can help to solve

    the problem that the spectral similarity of crop and weed

    pixels in early growth stages (Sankaran et al., 2015b). The

    general description of the procedure for image analysis include

    image acquisition, segmentation and classiﬁcation (Mathews,

    2014). Imaging analysis algorithms are the primary drivers for

    extracting statistical data to quantify the phenotype. Typical

    segmentation algorithms are based on a color model and

    threshold value (Li L. et al., 2014). In order to accelerate the

    working eﬃciency, the automatic object-based methods have

    been highlighted as the UAV can acquired massive image

    data. The thresholding OBIA algorithm is essential for the

    automatic vegetation classiﬁcation (Torres-Sanchez et al., 2015).

    As the physical inversion model, such as radiative transfer

    model, refer to complex problems of the leaf and canopy

    structure, radiation transmission, the combination of radiative

    transfer mechanism and spectral absorption characteristics of

    biochemical component is required to retrieve crop phenotype.

    For example, the PROSAIL model combined with spectral

    data were used for monitoring the LAI of wheat (Bendig

    et al., 2015). The crop phenotypic traits, such as crop canopy

    cover, LAI, chlorophyll content, plant nutrient, water content,

    biomass and yield et al., can be rapidly acquired using empirical

    statistical models with various vegetation indices. The commonly

    adopted empirical statistical methods for high-throughput ﬁeld

    phenotyping include multiple linear regression, partial least

    squares regression and stepwise linear regression (Richards,

    1990). Using advanced data analysis methods, such as principal

    component analysis (PCA), artiﬁcial neural network (ANN),

    support vector machine (SVM), and wavelet analysis (WA)

    et al., can be act as an important method to improve the

    prediction accuracy of the retrieval models. However, there’re

    disadvantages of the lack of explicit regression relations, the time-

    consuming calculation process, which greatly limit its eﬃciency

    and application scope (Zhao et al., 2014). The empirical statistical

    models are widely used and eﬀective in the research of UAV

    Remote Sensing for ﬁeld-based phenotyping according to the

    literature survey, but the applications were limited by the

    higher demand on practical surveying data and lack of physical

    meaning. For the machine learning, the obvious drawback is the

    lack of the ability to interpret data, which make it diﬃcult to

    exploit the advantages of machine learning.

    ADVANCES OF UAV REMOTE SENSING IN

    FIELD PHENOTYPING

    The crop phenotype is deﬁned as the physiological and

    biochemical characteristics and traits that are inﬂuenced by the

    genetic information of the crop and environmental factors, and it

    can be divided into diﬀerent levels, such as groups, individuals,

    organs, tissues and cells (Cobb et al., 2013; Yang et al., 2013;

    Araus and Cairns, 2014). The crop phenotype is closely related to

    crop production and crop breeding. Rapid and non-destructive

    acquisition of the phenotypic information of crops in the ﬁeld

    is an important prerequisite for studying the genetic inheritance

    law and accelerating the eﬃciency of large-scale crop breeding

    (Yang et al., 2013). The traditional methods for measuring

    crop traits, such as biomass, LAI and yield, depend on manual

    sampling, which is time consuming, ineﬃcient, and inaccurate

    (Berni et al., 2009b; Rahaman et al., 2015; Li W. et al., 2016).

    Frontiers in Plant Science | www.frontiersin.org

    13

    June 2017 | Volume 8 | Article 1111

    Yang et al.

    High-Throughput Field-Based Phenotyping Using UAV

    There are deﬁnite advantages for ﬁeld-based crop phenotyping

    based on UAV-RSPs, including high technical eﬃciency, low cost,

    suitability for complex ﬁeld environments, timely ﬁeld work,

    high-resolution data acquisition, rapid identiﬁcation of growth

    information, synchronous image acquisition, and high operating

    eﬃciency. UAV-RSPs have been widely used for ﬁeld-based

    crop phenotyping as an important tool for high-throughput

    phenotyping to assist crop research (Table 4). However, there’s

    still the lack of validation of ﬁeld-based phenotyping by

    UAV remote sensing with massive germplasm (over 1,000

    plots).

    Crop Geometric Traits

    Geometric traits, such as crop height (Bareth et al., 2016; Holman

    et al., 2016), vegetation cover fraction (Weiss and Baret, 2017;

    Yu et al., 2017), fraction of intercepted radiation (Guillen-

    Climent et al., 2014; Duan et al., 2017), LAI (Corcoles et al.,

    2013), lodging (Chapman et al., 2014), 3D structure (Aasen

    et al., 2015; Weiss and Baret, 2017), leaf angle distribution

    (Guo et al., 2015; McNeil et al., 2016), tiller densities (Du and

    Noguchi, 2017), and emergence (Sankaran et al., 2015a), can

    be rapidly obtained using the image analysis methods or the

    spectral and texture information in the images acquired by a

    UAV deployed imaging sensors (Tamouridou et al., 2017; Yu

    et al., 2017). The densiﬁed three-dimensional point clouds can

    be created using structure from motion (SFM) based on the

    images acquired by a UAV equipped with a digital camera

    (Turner et al., 2012; Holman et al., 2016). Then, the DSM and

    DEM are extracted to generate crop surface models (CSMs)

    (De Souza et al., 2017), which can be used for lodging area

    estimation (Chapman et al., 2014) and plant height monitoring

    (Li W. et al., 2016). The accuracy of plant height estimation

    using DSM and DEM can be signiﬁcant improved with the use

    of Real Time Kinematic (RTK) GPS (Xiong et al., 2017). The

    plant height of maize was estimated by UAV equipped a digital

    camera with the R2 and NRMSE of 0.88 and 6.40%, respectively

    (Li W. et al., 2016). In addition to estimating plant height using

    DEM generated by digital images, the point clouds acquired

    by LIDAR can also be used for estimating plant height. In

    NERCITA’s ongoing study, 69 (Inbred) and 104 (Hybrid) maize

    lines were selected for estimating plant height with UAV-based

    LIDAR. The determination coeﬃcients between the estimated

    maize height by LIDAR and measured plant height can reach

    to 0.94 in maize breeding (Figure 5), which showed a high

    accuracy for plant height estimation in breeding. Flowering

    dynamics act as an important phenotypic trait for paddy

    rice, which is time-consuming and labor-intensive by manual

    observation. The image analysis technique including scale-

    invariant feature transform descriptors and machine learning

    performed well for detecting ﬂowering panicles with RGB images

    (Guo et al., 2015). However, the applications of UAV for

    counting ﬂowering panicles haven’t been reported. Automated

    characterization of ﬂowering dynamics by UAV remote sensing

    at large-scale is essential for accelerating the breeding process.

    Thus, there’s still potential for wider applications of ﬁeld-

    based phenotyping by UAV with the advance of image

    analysis method, low-cost sensor and eﬀective image processing

    software.

    Classiﬁcation of remote sensing images is an important part of

    image feature analysis and can be used for leaf color monitoring

    and crop identiﬁcation (Geipel et al., 2014). Classiﬁcation

    methods can be divided into supervised and non-supervised

    classiﬁcation according to the level of user intervention required.

    Supervised classiﬁcation methods include maximum likelihood

    discriminant, neural network classiﬁcation, fuzzy classiﬁcation,

    minimum distance classiﬁcation and Fisher classiﬁcation, while

    unsupervised classiﬁcation methods include dynamic clustering,

    fuzzy clustering, hierarchical clustering and splitting (Zhao and

    Qian, 2004). Ground canopy cover (GCC) was recognized as

    an important parameter related to the crop photosynthesis and

    transpiration (Mullan and Reynolds, 2010). GCC is dynamic

    during the crop growth stages. GCC reduced as a result of

    leaf rolling or wilting under drought stress conditions (Sayed

    et al., 2012), which can be used for studying the response of

    crop varieties under abiotic/biotic stress. Thus, the dynamics

    of GCC over time have been regarded as one of the targeted

    phenotypic traits in crop breeding (Zaman-Allah et al., 2015;

    Yu et al., 2017). Ground canopy cover can be estimated by

    canopy reﬂectance, surface temperature and imagery (Booth

    et al., 2005; Rajan and Maas, 2009). For example, Champan

    acquired the GCC of sorghum with best linear unbiased

    prediction using a UAV with a digital camera and showed

    that the UAV-RSP has great potential for crop phenotyping in

    speciﬁc breeding plots (Chapman et al., 2014). As the accuracy

    of GCC estimation is relatively low using NDVI at early

    growth stage due to the inﬂuence of soil. The pixel-level data

    extracted from images with high resolution acquired by UAV

    performed better for GCC estimation (Sankaran et al., 2015b).

    The large amount of data acquired by UAV-RSPs deploying

    multi-source sensors can be rapidly and eﬃciently processed

    through machine learning, which has been widely used in the

    ﬁeld of crop phenotyping under stress conditions. Identiﬁcation,

    classiﬁcation, quantiﬁcation and prediction are the main steps for

    analyzing the physiological traits under conditions of biotic and

    abiotic stress based on machine learning (Zhao and Qian, 2004;

    Singh et al., 2016).

    LAI reﬂects the growth status of the crop population, and

    it is closely related to crop yield. Methods for estimating

    LAI by remote sensing include statistical models and optical

    models. Vegetation indices can be built after processing the

    spectral reﬂectance data acquired by UAV-based spectrometers

    using statistical methods to estimate LAI, such as Normalized

    Diﬀerence Vegetation Index (NDVI), Ratio Vegetation Index

    (RVI) and Perpendicular Vegetation Index (PVI). For example,

    the LAI in soybean breeding was estimated based on UAV-

    based hyperspectral by NERCITA, with the determination of

    coeﬃcients and RMSE for calibration model of 0.70 and 0.67,

    respectively, which showed a good precision (Lu et al., 2016).

    In addition to estimate LAI with statistical models based on

    vegetation indices, the radiation transmission model can also

    be used for LAI estimation. For example, the PROSAIL model

    combined with spectral data in the ﬁeld was used to estimate the

    LAI of wheat (Vega et al., 2015).

    Frontiers in Plant Science | www.frontiersin.org

    14

    June 2017 | Volume 8 | Article 1111

    Yang et al.

    High-Throughput Field-Based Phenotyping Using UAV

    FIGURE 5 | The estimation of plant height of summer maize. (A) Crop height model
    (CHM) from LIDAR in July 8, 2016 (red points indicates the measured sample

    points), (B) Validation of maize height from LIDAR.

    FIGURE 6 | The distribution of hyperspectral imaging in wheat breeding.

    Crop Phenotyping Related Vegetation

    Spectral Indices

    The absorption and reﬂection characteristics diﬀer between

    spectral bands in the crop leaves, with strong absorption in the

    visible band and strong reﬂection in the near-infrared band,

    providing the physical basis of crop growth monitoring by

    remote sensing. The reﬂection characteristics of crop leaves in

    diﬀerent bands can be acquired by the imaging spectrometer

    (Figure 6). A large number of vegetation indices can be

    constructed by the empirical treatment of spectral reﬂectance

    data at diﬀerent wavelengths, which can reﬂect the diﬀerence

    between the reﬂectance of visible light, near-infrared and soil

    background, indicating the crop growth status (Table 5). For

    example, the relationship between LAI and the normalized

    diﬀerence spectral index (NDSI) calculated from all possible two-

    band combinations was evaluated and showed that the NDSI

    consists of two sensitive bands and can be used to estimate LAI

    with high accuracy (Figure 7; Gao et al., 2016). The spectral

    characteristics of the crop canopy can be rapidly acquired by a

    UAV-RSP equipped with multispectral and hyperspectral sensors

    and can then be processed to build a vegetation index to monitor

    key crop traits, such as canopy cover, LAI, chlorophyll content,

    plant nutrients, water status, biomass and yield (Horler et al.,

    1983; Raun et al., 2001; Gutierrez et al., 2010). The vegetation

    indices built through the combination of spectra in the near-

    infrared and red channels, such as NDVI, RDVI, and GNDVI,

    can be used to monitor LAI and canopy cover (Danks et al.,

    1984; Curran, 1985). The vegetation indices composed of a

    combination of spectra in the red, blue and infrared channels,

    such as OSAVI, EVI, RVI, PVI, and DVI, can be used to estimate

    the chlorophyll content and leaf nitrogen content (Samseemoung

    et al., 2012; Nigon et al., 2015). The vegetation indices composed

    of a combination of spectra in the green and red channels,

    such as the red green ratio index, can be used to determine

    the carotenoid content. The vegetation indices built based on

    the diﬀerence between two or more spectral channels, such as

    DVI/EVI, which is sensitive to changes in the soil background,

    can be used for crop biomass monitoring. The vegetation

    Frontiers in Plant Science | www.frontiersin.org

    15

    June 2017 | Volume 8 | Article 1111

    Yang et al.

    High-Throughput Field-Based Phenotyping Using UAV

    TABLE 5 | Typical vegetation indices used for ﬁeld-based phenotyping with UAV
    platform.

    Vegetation index

    Formula

    Related crop traits

    References

    BGI2 (Blue Green Pigment

    Index 2)

    R450/R550

    LAI, chlorophyll

    Aasen et al., 2015

    CSI (Canopy Structure

    Index)

    2sSR−sSR2 +sWI2 WI = R900/R970

    SR = R800/R680

    Water

    Aasen et al., 2015

    DVI (Difference Vegetation

    Index)

    Rnir−Rred

    Nitrogen, chlorophyll

    Jordan, 1969

    EVI (Enhanced Vegetation

    Index)

    2.5(Rnir−Rred)/

    (Rnir+6Rred−7.5Rblue+1)

    Chlorophyll

    Huete et al., 1997

    GNDVI (Green Normalized

    Difference Vegetation Index)

    (Rnir−Rgreen)/(Rnir+Rgreen)

    LAI, chlorophyll, nitrogen, protein content, water

    content

    Gitelson et al., 1996; Garcia-Ruiz et al., 2013

    NDVI (Normalized Difference

    Vegetation Index)

    (R※nir−Rred)/(Rnir+Rred)

    LAI, yield, biomass

    Aasen et al., 2015; Zaman-Allah et al., 2015

    OSAVI (Optimized

    Soil-Adjusted Vegetation

    Index)

    1.16(R800−R670)/(R800+R670+0.16)

    Chlorophyll

    Gitelson et al., 1996; Berni et al., 2009b

    PRI (Photochemical

    Reﬂectance Index)

    (R570−R530)/(R570+R530)

    Chlorophyll, nitrogen, water

    Suarez et al., 2009

    PSRI (Plant Senescence

    Reﬂectance Index)

    (R680−R500)/R750

    Chlorophyll, nitrogen

    Gitelson et al., 1996

    PVI (Perpendicular

    Vegetation Index)

    (NIR−aR−b)/

    p

    1 + a2

    Chlorophyll

    Richardson and Wiegand, 1977

    RDVI (Renormalized

    Difference Vegetation Index)

    (R800 − R670)/

    p

    R800 − R670

    LAI, biomass, nitrogen

    Tucker, 1979

    RVI (Ratio Vegetation Index)

    Rnir/Rred

    Water content, yield, chlorophyll, nitrogen

    Rondeaux et al., 1996

    TCARI (Transformed CAR

    Index)

    3*[(R700−R670)−0.2*(R700−R550)

    *(R700/R670)]

    Chlorophyll

    PeÑUelas et al., 1993

    VDI(Vegetation Drought

    Index)

    (R970−R900)/(R970−R900)

    Water stress

    Suarez et al., 2009

    R※ means spectral reﬂectance.

    indices composed of the ratio between two or more spectral

    channels can indicate the diﬀerence between crop growth and

    crop cover. For example, RVI was used for CCC monitoring.

    Normalized diﬀerence vegetation indices, such as NDVI/RDVI,

    can reﬂect crop growth and nutrition. The combination of blue,

    red and near-infrared channels can eliminate the interference

    of atmospheric aerosols on vegetation indices, such as OSAVI,

    which can improve the accuracy of crop growth monitoring and

    yield prediction. There’re advantages of easy computation, low

    instrumental requirements for the empirical statistical analysis

    method based on vegetation index, while the limitation include

    the lack of crop physiological interpretation, and need to be

    empirically ﬁtted to each particular scenario. In addition to the

    empirical statistical method for crop phenotyping, the semi-

    mechanistic model, mechanism model and machine learning are

    also useful methods. However, the most adopted method for

    crop phenotyping by UAV remote sensing is mainly empirical

    statistical model.

    Crop Physiological Traits

    The reﬂectance of plant leaves in visible light is aﬀected by the

    contents of chlorophyll, carotene and lutein in the palisade tissue,

    whereas the reﬂectance of plant leaves in the near-infrared band is

    closely related to the cell structure. A large number of vegetation

    indices can be built after the empirical treatment of spectral

    information and can be used to estimate many biophysical

    properties, such as the chlorophyll, protein content, biomass,

    malnutrition, crop vigor and water status (Ma et al., 2001; Prasad

    et al., 2007). For example, the NDVI can reﬂect the eﬀect of

    background information on the canopy spectra to estimate crop

    vigor, biomass, and yield (Hall et al., 2003; Gao et al., 2016).

    GNDVI and NDWI were used to estimate the leaf chlorophyll

    content and water status, respectively, (Prasad et al., 2007; Lelong

    et al., 2008; Gonzalez-Dugo et al., 2014). The accuracy and

    reliability of the estimation of crop physiological traits were

    determined by the retrieval model. The most commonly used

    modeling and analysis method for crop phenotyping by remote

    sensing is regression analysis, including linear and nonlinear

    regression. Linear regression methods, including multivariate

    linear regression (MLR), stepwise linear regression (SLR), and

    PLSR, are simple and feasible (Capolupo et al., 2015) and have

    wide applications in quantitative analysis by remote sensing. For

    example, MLR was used to estimate crop biomass (Rosen et al.,

    2006; Swain et al., 2010), PLSR was used to estimate the LAI in

    soybean breeding (Lu et al., 2016), and SLR was used to estimate

    the leaf chlorophyll content (Berni et al., 2009b). However, the

    primary objection to linear regression methods is the lack of

    explanation of crop physiology. In recent years, using nonlinear

    regression methods, including principal component analysis,

    artiﬁcial neural network, support vector machine and wavelet

    Frontiers in Plant Science | www.frontiersin.org

    16

    June 2017 | Volume 8 | Article 1111

    Yang et al.

    High-Throughput Field-Based Phenotyping Using UAV

    FIGURE 7 | Coefﬁcient of determination (R2) between LAI and NDSI

    calculated from all possible two-band combinations at jointing and ﬂowering

    stages of wheat.

    analysis, data mining has been widely employed to associate

    hyperspectral information with physiological and biochemical

    crop parameters (Gong, 1999; Liang, 2005; Wang et al., 2008).

    However, because there is no explicit regression formula for

    these nonlinear regression models, it is diﬃcult to obtain a

    universal analysis model, and the calculation process is more

    time-consuming, which limits the eﬃciency and application of

    these methods. Intercepted photosynthetically active radiation

    (IPAR) act as an important indicator of photosynthesis and

    biomass accumulation, methods based optical remote sensing,

    such as 3D radiative transfer model, Forest Light Interaction

    Model (FLIGHT) have been adopted to study the fraction

    of photosynthetically active radiation intercepted (fIPAR) and

    absorbed (fAPAR). The high-resolution multi-spectral images

    acquired by UAV provide a rapid and non-destructive way for

    ﬁPAR and fAPAR estimation in recent years (Guillen-Climent

    et al., 2012).

    Biomass is an important indicator of crop growth, which

    can be used for crop monitoring and yield prediction. The

    sensors including multispectral camera, hyperspectral imager,

    LIDAR, combing the methods including empirical statistical

    analysis of vegetation indices, estimation based on net primary

    productivity, and crop growth model have been widely deployed

    for biomass estimation (Hunt et al., 2005; Swain et al., 2010;

    Wallace et al., 2012; Bendig et al., 2014). However, the method

    for the estimation of crop biomass by UAV remote sensing

    is mainly empirical statistical model. In order to improve the

    accuracy of biomass estimation, the vegetation indices combing

    plant height have been used for estimating crop biomass. For

    example, the plant height from crop surface model combing

    RNDVI were used for barley biomass estimation with the R2

    of 0.84, while the best performance of estimating biomass by

    single vegetation index got by GRVI and MGRVI with R2 of 0.60

    (Ota et al., 2015). In addition to the retrieval model with single

    FIGURE 8 | The relationship between plant height and aboveground biomass

    of soybean (from Lu et al., 2016; permissions for reproduction have been

    obtained from the copyright holders).

    vegetation index, the multiple regression model with several

    vegetation indices have also been adopted to estimate biomass,

    which showed good accuracy. For example, in NERCITA’s

    soybean breeding experiment, UAV-based hyperspectral remote

    sensing was used to estimate soybean biomass in 126 plots by

    NERCITA and provided a rapid and non-destructive method

    to estimate crop biomass under complex ﬁeld environments. As

    there is a good relationship between soybean plant height and

    biomass (Figure 8), the plant height combined vegetation indices

    acquired by a Cubert UHD 185 hyperspectral imager were used

    to build retrieval models using PLSR to estimate the soybean

    biomass of a massive germplasm. As the relationship between the

    canopy spectral characteristics and soybean biomass in diﬀerent

    growth stages showed signiﬁcant diﬀerences, the method of

    “segmentation modeling” was used to estimate soybean biomass

    under diﬀerent growth stages. The vegetation indices of OSAVI,

    R726 and NDVI705 were used to build a retrieval model to

    estimate the biomass in soybean breeding during the periods

    of ﬂowering and pod ﬁlling, with the determination coeﬃcient

    and RMSE of 0.71 and 0.39, respectively. While the RVI, VOG1,

    NDVI, and Ratio of green peak and red valley (R1) were used

    to build a retrieval model to estimate the biomass in soybean

    breeding during the periods of ﬁlling and ripening, with a

    determination coeﬃcient and RMSE of 0.70 and 0.38 (Figure 9;

    Lu et al., 2016).

    Crop Abiotic/Biotic Stress

    Plant

    physiology

    research

    under

    abiotic

    or

    biotic

    stress

    conditions usually focuses on the changes of physiological

    traits and biochemical substances and its agronomy mechanism.

    Stress factors, including water deﬁcit, low temperature, high

    temperature, high salinity, environmental pollution, pests and

    diseases, can have signiﬁcantly adverse eﬀects on crop growth

    (Zhao and Qian, 2004; Zarco-Tejada et al., 2012; Nigon et al.,

    2015). Studying the response of crops to diﬀerent stress

    conditions is important for crop cultivation and breeding.

    Frontiers in Plant Science | www.frontiersin.org

    17

    June 2017 | Volume 8 | Article 1111

    Yang et al.

    High-Throughput Field-Based Phenotyping Using UAV

    FIGURE 9 | The relationship between predicted and measured biomass in different
    growth stages. (A) The calibration and validation of biomass during the periods
    of

    ﬂowering and pod ﬁlling; (B) The calibration and validation of biomass during
    the periods of ﬁlling and ripening; from Lu et al. (2016); permissions for reproduction
    have

    been obtained from the copyright holders.

    As the membrane permeability of plant cells, the chlorophyll

    content, and peroxidase change under stress conditions, thus,

    some diseases can be detected by spectroscopy at early growth

    stage. For example, the UAV-based multi-band imaging sensor

    was deployed to acquire high-resolution aerial imaging for

    Huanglongbing (HLB) detection, which yielding that there’s

    signiﬁcant diﬀerence for the 710 nm spectral reﬂectance and

    the NIR-R index values between healthy and HLB-infected

    trees (Garcia-Ruiz et al., 2013). The vegetation indices can

    be extracted from images acquired by UAV to separate the

    healthy oil palm and those infested with Phellinus Noxius by

    visualization, analysis and identiﬁcation of image processing

    software, which provide a way for timely detection of pest or

    disease infections (Samseemoung et al., 2011). The weed can also

    be separated crops with UAV-deployed multispectral images. For

    example, the Silybum marianum (L.) Gaertn weed was classiﬁed

    using Maximum Likelihood classiﬁer (ML) with multispectral

    images acquired by a ﬁx-wing UAV. The overall accuracy of

    classiﬁcation rates can reach up to 87.04% (Tamouridou et al.,

    2017). As crop phenotypic information plays an important role

    in revealing the resistance of crops to stress, rapid phenotyping

    is essential for agricultural scientists to achieve their goals.

    Remotely sensed infrared canopy temperatures can provide an

    eﬃcient method for rapid, non-destructive monitoring of whole-

    plant response to water stress (Rashid et al., 1999; Gutierrez et al.,

    2010), which has been widely used to screen drought tolerance

    varieties. The evapotranspiration can be estimated with thermal

    infrared images under stress conditions (Grieder et al., 2015).

    The canopy temperature can also be used for predict crop yield

    at some occasions. For example, there was a signiﬁcant positive

    correlation between lower canopy temperature and higher yield

    under conditions of high temperature and drought (Reynolds

    et al., 2007). The stomatal conductance decreased and the leaf

    temperature increased with stoma closure under osmotic stress

    caused by excess salinity and high temperature, which can be

    used to estimate leaf water potential and stomatal conductance

    (Bowman and Strain, 1988; Wang et al., 2003).

    As the crop canopy temperature is related to photosynthesis,

    the canopy air temperature diﬀerence (TD), which is the ratio

    of the canopy temperature and air temperature, can be used to

    predict crop yield, for example, there is a signiﬁcant negative

    correlation between the TD and yield of hybrid sorghum potato

    (Chaudhuri and Kanemasu, 1982) and a signiﬁcant positive

    correlation between TD and wheat yield under water stress

    conditions (Rashid et al., 1999; Bellundagi et al., 2013). The

    water deﬁcit index obtained from thermal imaging data can

    Frontiers in Plant Science | www.frontiersin.org

    18

    June 2017 | Volume 8 | Article 1111

    Yang et al.

    High-Throughput Field-Based Phenotyping Using UAV

    be used to determine the water status of crop leaves and to

    estimate the stomatal conductance. The canopy temperature

    plays an important role in screening drought-resistant varieties

    by the International Maize and Wheat Improvement Centre

    (Reynolds et al., 1994). Approximately 60% of the variation of

    seed yield of diﬀerent wheat varieties can be explained by high

    temperature and drought conditions and canopy temperature,

    which are negatively correlated with the yield of wheat (Olivares-

    Villegas et al., 2007; Reynolds et al., 2007). Keep (2013) found

    a diﬀerence in canopy temperature between soybean varieties

    bred during the periods of 1920–2010, which was not aﬀected

    by the environment. In addition, there is a signiﬁcant negative

    correlation between canopy temperature and yield for 2 groups

    of ripe varieties (Keep, 2013).

    The conventional method of measuring the crop canopy

    temperature in the ﬁeld is using a handheld thermal imager,

    which is ineﬃcient. It is diﬃcult to synchronously measure

    agronomic characteristics in a large area within a short time

    using a handheld thermal imager, but a UAV equipped with

    a thermal imaging instrument can rapidly and easily acquire

    thermal imaging data for crop growth monitoring in large areas

    to indirectly monitor crop growth status. The use of UAVs

    equipped with thermal imagers to monitor the crop canopy

    temperature, stomatal conductance and leaf water status of

    wheat, maize and sorghum showed high accuracy compared with

    the data observed in the ﬁeld, while such indicators of cotton

    acquired by UAV-based thermal imagers showed lower accuracy

    (Berni et al., 2009b; Zarco-Tejada et al., 2012; Colomina and

    Molina, 2014).

    Crop Potential Yield Prediction and

    Nutrient Monitoring

    Crop yield, which is closely related to the development and

    diﬀerentiation of organs and the distribution and accumulation

    of photosynthetic products, is the core focus of crop science

    research. The traditional methods for crop yield estimation

    are the use of manual surveys or establishing the relationship

    between agronomic factors or climatic factors and crop yield

    using statistical analysis methods (Overgaard et al., 2010;

    Swain et al., 2010). Many observations and samplings in ﬁeld

    experiments are required to determine the parameters of the yield

    prediction model, which is laborious and time-consuming. As

    some factors are diﬃcult to quantify, it is diﬃcult to promote the

    use of these models due to the poor adaptability to diﬀerent areas.

    Yield prediction by remote sensing is deﬁned as building the

    relationship between the canopy spectra and crop yield based on

    the biological characteristics of crops for yield prediction using

    spectral data at diﬀerent crop growth stages (Swain et al., 2010).

    Improving the accuracy and adaptability of the yield estimation

    model is a prerequisite for the application of UAV remote sensing.

    Crop yield can be predicted by combining the plant physiological

    parameters with the vegetation indices. The commonly adopted

    plant physiological parameters and remote sensing parameters

    for building yield prediction models include the length of the

    growth period, chlorophyll content, LAI, aboveground biomass,

    spectral reﬂectance and vegetation indices (Filella et al., 1995).

    Crop yield can be predicted by constructing a remote sensing

    inversion model containing a variety of vegetation indices;

    however, the accuracy of crop prediction using the structural

    index is low due to the eﬀects of terminal water stress (Chaudhuri

    and Kanemasu, 1982). The canopy temperature, which is related

    to yield to a certain extent, and carotenoids pigment indices,

    such as the PRI and chlorophyll absorption reﬂectance index

    (CARI), are suited to screening complex traits, such as crop

    yield (Gonzalez-Dugo et al., 2015). For example, the wheat

    yield was predicted based on canopy temperature as low

    temperature increases the yield under adequate water supply

    and water limitation conditions (Olivares-Villegas et al., 2007).

    The chlorophyll content can also be used to predict crop yield

    because there is a relationship between the chlorophyll content

    and photosynthesis that is related to yield. The accuracy of yield

    prediction models improves with increasing number of modeling

    parameters; however, the yield prediction models using spectral

    reﬂectance characteristics and canopy temperature usually focus

    on 2∼3 bands and lack adaptability. Therefore, it is important to

    build crop yield prediction models that combine crop physiology

    and remote sensing parameters to improve the accuracy of yield

    prediction by UAV-RSP.

    In recent years, the spectral characteristics of components,

    such as plant chlorophyll, nitrogen and water, were identiﬁed,

    which enabled the estimation of the biochemical contents of

    crops by remote sensing and estimation of crop nutrition under

    diﬀerent environmental conditions (Swain et al., 2007; Wang

    et al., 2008). Leaf nitrogen concentration (LNC) is an important

    indicator of nitrogen (N) status for assessing dynamic regulation

    and predicting crop yield. Research progress of remote sensing

    technology for LNC estimation have been achieved in the past

    years. The adopted algorithms and vegetation indices for building

    remote sensing analytical models signiﬁcantly aﬀect the accuracy

    of ﬁeld phenotyping using UAV-RSPs. As models for phenotypic

    information analysis of massive cultivars in breeding plots using

    unmanned aerial vehicle remote sensing are sensitive to climate

    and soil conditions, developing strategies for LNC estimation

    for diﬀerent crops under diﬀerent environmental conditions

    is helpful for crop growth monitoring. In NERCITA’s study,

    four chemometric techniques, including stepwise multiple linear

    regression (SMLR), partial least squares regression (PLSR), back

    propagation neural network (BPN), and support vector machines

    regression (SVR), were adopted with 13 key spectral features to

    build LNC models. The results indicated that partial least squares

    regression (PLSR) and support vector machines regression (SVR)

    performed better than the other two methods, with R2 values in

    the calibration set of 0.82 and 0.81 and the normalized root mean

    square error (NRMSE) values in the validation set of 5.48 and

    5.94%, respectively (Li Z. et al., 2016).

    DISCUSSIONS

    UAV-RSPs and Deployed Sensors

    UAV remote sensing platforms have become an eﬀective way

    to rapidly acquire ground information, especially in the ﬁeld

    of crop growth monitoring. It is necessary to adjust the ﬂight

    altitude and ﬂight speed based on the actual conditions due

    Frontiers in Plant Science | www.frontiersin.org

    19

    June 2017 | Volume 8 | Article 1111

    Yang et al.

    High-Throughput Field-Based Phenotyping Using UAV

    to the complexity of the farmland environment. In contrast,

    the ﬂight speed and altitude must be lower to obtain detailed

    information about fruit growth in the bush (Mathews and Jensen,

    2013). Frequently used UAV-RSPs, especially multi-rotor UAVs,

    such as the quadcopter UAV model md4-1000, are unmanned

    gyroplanes. Gyroplanes have the advantages of adjustable ﬂight

    speed and height, the ability to take-oﬀ and land vertically,

    freedom from site condition restrictions, and suitability for the

    observation of precise farmland information (Hardin and Jensen,

    2011). The ﬂight altitude of multi-rotor UAVs ranges from 20 to

    100 m, guaranteeing that the spatial data resolution of the optical

    sensors can reach the centimeter level for accurate identiﬁcation

    of crop individuals. The ﬂight altitude ranges from 300 to 1,000

    m for most ﬁxed-wing UAVs, and the biggest problem for the

    ﬁxed-wing UAVs is that a minimum ﬂight speed before they

    stall is required. The operation of ﬁxed-wing UAVs is more

    complicated than that of multi-rotor UAVs, which make it more

    dangerous. The disadvantages limit the wide application of ﬁxed-

    wing UAVs for data acquisition in ﬁeld phenotyping. Most UAVs

    are equipped with automatic driving systems. The automatic

    adjustment of ﬂight height, position and attitude is conducted

    using GPS/INS and the pressure gauge mounted on the UAV,

    which can reduce the intensity of manual control and avoid the

    impact of human factors on ﬂight safety (Pajares, 2015). The

    payload can reach 3–5 kg for the most multi-rotor and ﬁxed-

    wing UAVs. Additionally, the UAV body must be larger when

    the payload exceeds 5 kg; it is necessary for the UAV to be

    equipped with an ejection frame at the specialized site for take-

    oﬀ and to conduct artiﬁcial judgment to open the parachute,

    which increases the complexity and diﬃculty of operating ﬁxed-

    wing UAVs. In general, multi-rotor UAVs are more stable and

    convenient and are more suitable as a platform for ﬁeld-based

    crop phenotyping. Nevertheless, the limited extension that rotary

    wings can cover by speed and autonomy is the problem for

    its application. In the future, multi-rotor UAVs will be able to

    provide more than 1 h of continuous ﬂight as battery technology

    matures.

    UAVs are currently equipped with optical sensors with

    wavebands ranging from visible light to near-infrared, such

    as multispectral sensors, conventional digital cameras, and

    hyperspectral sensors. The problems with sensors deployed by

    UAV-RSP are as follows: (1) the lack of sensors for ﬁeld-based

    crop phenotyping. The existing optical sensors are diﬃcult to use

    to obtain quantitative crop information and are usually employed

    for qualitative analysis. For example, an 8-bit storage format is

    used for imaging by the Tetracam ADC-lite camera, which can

    result in a very small change in spectral diﬀerence between crops

    and aﬀect the accuracy of the subsequent quantitative analysis.

    The commonly used digital cameras lack camera calibration and

    radiometric calibration, which can aﬀect the accuracy of the

    geometric parameter analysis. Unmanned airborne hyperspectral

    imaging, including linear push broom imaging and staring

    imaging, has gradually gained the attention of experts and

    scholars. The linear push broom imaging hyper-spectrometer

    is more mature, while the staring hyperspectral imager was

    developed for unstable platforms in the last 2 years. The biggest

    problem with the linear array push broom spectrometer is that

    it is diﬃcult to guarantee accurate geometric calibration. The

    spatial resolution of the spectrometer can reach the centimeter

    level, but the vibration of the UAV platform and dynamic jitter

    can cause obvious geometric distortion in the absence of high-

    precision positioning and orientation system (POS) or inertial

    navigation system (INS). The vibration can be reduced by a

    shock absorbers, or an active stabilization platform. However,

    it is diﬃcult for the geometric calibration accuracy to reach the

    centimeter level, which can seriously aﬀect the application of this

    type of sensor. Therefore, it is necessary to develop sensors to be

    deployed by micro-UAV for ﬁeld-based crop phenotyping. (2)

    The current sensor acquisition control system and UAV ﬂight

    control system are not integrated. Currently, the UAV and the

    deployed sensors are from diﬀerent manufacturers. Therefore,

    the ﬂight control system of the UAV does not provide an interface

    for the sensors, and the self-control system, acquisition and

    storage unit are equipped by the sensors without the interface

    and without a UAV ﬂight control system. It is necessary to

    dynamically control the sensors using the UAV ﬂight control

    system in the process of UAV remote sensing data acquisition to

    meet the needs of data acquisition and to avoid redundant data

    acquisition by the sensors.

    Airspace Regulations for the Application of

    UAVs

    The UAVs have the advantages of ﬂexible, real-time and non-

    destructive for crop phenotyping, however, UAVs must follow

    strict management rules to ensure their security as well as

    the sustainable development of the UAV aviation industry. As

    the ﬂight plan needs to be permitted by aviation regulators,

    which usually take more than 3 days in some countries. For

    example, permissions from more than 3 regulatory agencies,

    such as air force, civil aviation, police, are needed to conduct

    UAV ﬂight in China, which is time consuming. The ﬂight plan

    including the ﬂight time, ﬂight altitude UAV driver, ﬂying area

    and purpose of ﬂight etc. must be submitted. As the plan for

    the acquisition of UAV remote sensing information was usually

    scheduled based on the weather and crop growth stages, it’s hard

    to propose advanced declaration for conducting the research

    of ﬁeld phenotyping. In addition, the frequent ﬂight may be

    needed in the research, the repeated declarations are trouble.

    Here we present a summary of the main regulation for UAVs in

    diﬀerent countries. As one of the most developed countries in the

    aviation industry, the regulations of UAVs in the United States

    are in a relatively advanced position. UAVs were admitted to

    the National Aeronautics and Space Administration (NASA)

    in the United States in 1990, and UAV regulation found a

    balance between caution and openness by the Federal Aviation

    Administration (FAA) with the increase in the civilian UAV

    operating frequency. There are three types of UAVs that need

    to be supervised: public aircraft, civil aircraft, and model planes.

    The US FAA announced an online registration of commercial

    drones and small UAVs in 2016, with equal registration costs for

    recreational drones. The web version of the registration system

    was designed to reduce the time required for a large number

    of UAV operators to register commercial UAVs. Recently, the

    Frontiers in Plant Science | www.frontiersin.org

    20

    June 2017 | Volume 8 | Article 1111

    Yang et al.

    High-Throughput Field-Based Phenotyping Using UAV

    US FAA proposed a regulatory requirement that a UAV must

    be in sight of its operator, which limits the wide application of

    UAVs for large area crop surveys, long distance inspection of

    pipelines and delivery. To address this limitation, an air traﬃc

    management system was developed with the cooperation of

    NASA, companies, universities and government agencies to allow

    the operator to use a tracking system so that the UAV can ﬂy

    out of sight of the operator while avoiding sensitive areas, such

    as airports and crowded areas. The European Aviation Safety

    Agency (EASA) issued a notice of advanced system revision (A-

    NPA2015-10) named “the framework of the UAV operation rules

    and regulations” on July 30, 2015. The A-NPA provided a detailed

    operational regulatory framework with low risk proposed by

    EASA. The supervision by EASA was based on the performance

    and risk of UAVs, which can be divided into three categories:

    (1) open class (low risk); (2) franchise operation (medium risk);

    (3) validation class (high risk). The regulatory framework of

    EASA is based on the operational risk of the UAV. In addition to

    the regulations based on risk management, there are regulations

    based on certiﬁcation for UAVs, which are similar to those for

    manned spacecraft (Stöcker et al., 2017). The Civil Aviation

    Administration of China (CAAC) stipulates that institutions and

    individuals using UAVs must apply for specialized airspace based

    on the “General Aviation Flight Control Ordinance” and must

    obey ﬂight activity management rules to ensure ﬂight safety. The

    management level of production and the possession and use of

    UAVs greatly aﬀects the market size of UAV applications, which

    include UAV remote sensing and ﬁeld-based crop phenotyping.

    Methods and Accuracy of Field-Based

    Crop Phenotyping

    Methods for crop phenotype analysis from remote sensing

    include direct monitoring, image classiﬁcation, concurrent

    comparison, empirical statistics modeling, physical reversion

    modeling, machine learning, and time series analysis of remote

    sensing parameters (Singh et al., 2016; Virlet et al., 2017).

    However, the commonly adopted methods for crop phenotyping

    by UAV remote sensing technology are empirical statistical

    analysis at present. The other equally important methods for

    the analysis of remote sensing data haven’t been widely used in

    the research, only few articles present these methods for crop

    phenotyping by UAV. The statements based on literature survey

    and case study by NERCITA indicated that the high accuracy

    for estimating ﬁeld-based crop phenotypic traits can be attained,

    however, the high accuracy just can be attained in special

    occasions. The research that analyze LAI, canopy chlorophyll

    content and leaf nitrogen content using remote sensing data has

    been fully developed. The determination coeﬃcient of retrieval

    models can exceed 0.85 (Rosen et al., 2006; Berni et al., 2009b;

    Ballesteros et al., 2014; Bendig et al., 2014), indicating that

    the estimated phenotypic information is in good agreement

    with the measured values. The reason for the high accuracy is

    that the spectral characteristics of the leaves are related to the

    abovementioned indicators and can be used to directly reﬂect

    the growth information. Unfortunately, it’s hard to propose

    the universal models or general methods for retrieving crop

    phenotypic traits with good accuracy by remote sensing among

    diﬀerent types of crops so far.

    As the vegetation index is an important cause of the

    diﬀerences in remote sensing for retrieving crop phenotypic

    traits, the combination of spectral bands can aﬀect the retrieval

    accuracy. The retrieval accuracy of complex traits based on

    remote sensing in the surveyed literatures remains low. The

    determination coeﬃcient of retrieval models for predicting crop

    yield and biomass is usually less than 0.70 (Overgaard et al.,

    2010) due to the indirect relationship between remote sensing

    information and complex crop traits. Complex crop traits are

    inﬂuenced by the genome and environment, while the spectral

    reﬂectance and vegetation indices (e.g., NDVI, RVI) are indirectly

    related to these traits. Crop traits such as LAI and fraction of

    absorbed photosynthetically active radiation are more related

    to crop yield; however, it is diﬃcult to use crop traits directly

    related to spectral characteristics to predict crop yield due to the

    heterogeneity of the earth’s surface, the inﬂuence of crop type and

    environment, and the uncertainty of remote sensing extraction.

    The basic research ideas for ﬁeld-based crop phenotyping by

    UAV-RSP are similar, including retrieving key crop traits, such

    as crop structure, biochemical content, biomass, yield, lodging,

    diseases and pests, from remote sensing data (Sankaran et al.,

    2015b). Most retrieved crop traits are at the canopy scale and

    can indicate crop growth; however, there is a need to acquire

    physiological and ecological characteristics of individual plants

    and even organs that cannot be resolved by UAVs. Therefore,

    new sensors and physical reversion models are needed to

    synchronously monitor the key phenotypic information of crops

    at the micro and macro scales.

    Challenge for “Big” Data Processing

    Compared with the rapid development of sensor and hardware

    platforms, the eﬃciency and function of image processing are

    insuﬃcient, especially the rapid processing ability of software

    in the ﬁeld. In addition, large amounts of data acquired by

    hyperspectral imagers and LIDAR need to be processed (Zhao

    and Qian, 2004). As image processing for hyperspectral and

    LIDAR data is complex, there is an urgent need to develop

    software with the ability to perform high-speed and accurate

    image processing to improve the eﬃciency and accuracy of data

    processing. The data processing ﬂow is based on aerial remote

    sensing image processing for most existing UAV remote sensing

    processing software, without consideration of the specialized

    characteristics of UAV remote sensing. The aspects reﬂecting

    the diﬀerence between aerial remote sensing and UAV remote

    sensing include few ground control points, a lack of strict

    internal calibration parameters in the deployed sensors, and a

    lack of a high-precision POS system for UAV remote sensing,

    which prevents the existing aerial remote sensing processing

    system from being directly applied to UAV remote sensing data

    processing. Digital image processing software, such as Agisoft

    PhotoScan Professional Edition (Agisoft LLC, St. Petersburg,

    Russia) and Pixel4D (Lausanne Switzerland), which can be used

    for geometric correction and mosaicking, has rapidly developed

    in recent years; however, hyperspectral images and LIDAR data

    cannot be processed using commercial processing software due

    Frontiers in Plant Science | www.frontiersin.org

    21

    June 2017 | Volume 8 | Article 1111

    Yang et al.

    High-Throughput Field-Based Phenotyping Using UAV

    to the lack of a special module for remote sensing information

    analysis. The eﬃciency of data processing software must be

    improved to satisfy the requirements of rapid and accurate data

    processing and analysis.

    The

    geometric

    correction

    and

    radiometric

    calibration

    constitute the most demanding work for UAV remote sensing

    data processing, which is time-consuming. A mature remote

    sensing photogrammetry method was adopted for geometric

    correction, which requires many points matching the same

    name, point cloud generation and correction of ortho images.

    In addition, it is diﬃcult to batch process because the spectral

    and spatial resolution of each sensor is diﬀerent, which reduces

    the processing eﬃciency. It is necessary to develop UAV remote

    sensing output processing methods based on cloud computing

    or high-performance computing to process remote sensing data

    online and to avoid the low eﬃciency caused by data processing

    using stand-alone software. Additionally, there is a need to

    develop specialized analytical tools for sensors deployed in crop

    phenotyping research using UAV-RSPs for wide applications by

    crop breeders. The application of UAV-RSPs for ﬁeld-based crop

    phenotyping can promote the association analysis of genomes

    and phenotypes to improve crop breeding eﬃciency.

    CONCLUSION

    Field-based crop phenotyping by UAV-RSPs has become a hot

    research topic in recent years. Approximately 88.5% of the

    surveyed literature focused on ﬁeld phenotyping using UAV-

    RSPs was published in the last 5 years. The current status and

    perspectives of UAV-RSPs for FBP are follows:

    (1) UAV-RSP can be as a powerful tool for ﬁeld-based

    phenotyping

    with

    the

    advantages

    of

    high

    operation

    eﬃciency,

    low

    cost,

    suitability

    for

    complex

    ﬁeld

    environments, and high resolution. The multi-rotor UAV

    is the mostly adopted UAV-based phenotyping platform in

    the recent years. There’s potential for UAV-RSP acting as

    an alternative to the traditional methods for crop growth

    monitoring, yield prediction and variety selection. The

    digital camera, multispectral camera, hyperspectral camera,

    thermal infrared imager and LiDAR have been widely used

    to ﬁeld-based phenotyping. The adoption of multi-sensors

    coupled with advanced data analysis methods for retrieving

    crop phenotypic traits are the research hotspots in recent

    years.

    (2) The crop phenotype that can be acquired by UAV-RSP

    include, but are not limited to, geometric traits, canopy

    spectral texture, physiological traits, abiotic/biotic stress

    response, plant nutrition, and yield. Unfortunately, there is

    still a lack of validation for ﬁeld-based phenotyping by UAV

    with a large group of crop varieties. There exists diﬀerence

    for the accuracy of ﬁeld-based phenotyping using UAV

    remote sensing among phenotypic traits, which was caused

    by the variation of sensor type, climate, crop growth stages

    and crop type. Research focused on crop phenotypic traits

    that are directly related to the canopy spectral information

    has been conducted and has shown good accuracy under

    certain conditions, while there is low accuracy in the research

    on the non-destructive acquisition of complex traits that are

    indirectly related to the canopy spectral information.

    (3) The limiting factors for UAV-based ﬁeld phenotyping

    include the low capability of UAVs, the strict airspace

    regulations, the lack of methods for fast data processing

    and models for estimating complex traits under diﬀerent

    environmental conditions. Improving the performance of

    UAVs, reducing the cost of sensors, speeding up data

    processing and developing strategies for analyzing crop

    phenotype by remote sensing are future trends. Fortunately,

    it is expected that with the advancement of UAVs with larger

    payload and longer endurance, low-cost sensors, improved

    image processing methods for “Big” data, and eﬀective

    airspace regulations, there’s potential for wider applications

    about the UAV-based ﬁeld phenotyping.

    AUTHOR CONTRIBUTIONS

    GY, JL and CZ conducted the literature survey and drafted

    the article; HYu, BX, XY, DZ, XZhang, RZ, HF and XZhao

    provided the data and ﬁgures about the ﬁeld-based phenotyping

    by NERCITA; Zhenhong Li, HY, Zhenhai Li, HL and HYang gave

    valuable comments to the manuscript and carried out critical

    revisions. All authors gave ﬁnal approval for publication.

    ACKNOWLEDGMENTS

    This study was supported by the Natural Science Foundation

    of China (61661136003, 41471285, and 41471351), National

    key research and development program (2016YFD0300602),

    and the Special Funds for Technology innovation capacity

    building sponsored by the Beijing Academy of Agriculture and

    Forestry Sciences (KJCX20170423). Thanks to Guozheng Lu,

    Jibo Yue, etc. in the ﬁeld sampling collection. Thanks to all

    employees of Shandong Shengfeng soybean breeding group. We

    are grateful to the reviewers for their valuable comments and

    recommendations.

    REFERENCES

    Aasen, H., Burkart, A., Bolten, A., and Bareth, G. (2015). Generating 3D

    hyperspectral information with lightweight UAV snapshot cameras for

    vegetation monitoring: from camera calibration to quality assurance. Isprs

    J. Photogram. Remote Sensing 108, 245–259. doi: 10.1016/j.isprsjprs.2015.

    08.002

    Acevo-Herrera, R., Aguasca, A., Bosch-Lluis, X., Camps, A., Martinez-Fernandez,

    J., Sanchez-Martin, N., et al. (2010). Design and ﬁrst results of an UAV-

    Borne L-Band radiometer for multiple monitoring purposes. Remote Sensing

    2, 1662–1679. doi: 10.3390/rs2071662

    Araus, J. L., and Cairns, J. E. (2014). Field high-throughput phenotyping:

    the

    new

    crop

    breeding

    frontier.

    Trends

    Plant

    Sci.

    19,

    52–61.

    doi: 10.1016/j.tplants.2013.09.008

    Frontiers in Plant Science | www.frontiersin.org

    22

    June 2017 | Volume 8 | Article 1111

    Yang et al.

    High-Throughput Field-Based Phenotyping Using UAV

    Ballesteros, R., Ortega, J. F., Hernandez, D., and Moreno, M. A. (2014).

    Applications

    of

    georeferenced

    high-resolution

    images

    obtained

    with

    unmanned aerial vehicles. Part I: description of image acquisition and

    processing. Precision Agric. 15, 579–592. doi: 10.1007/s11119-014-9355-8

    Baluja, J., Diago, M. P., Balda, P., Zorer, R., Meggio, F., Morales, F., et al.
    (2012).

    Assessment of vineyard water status variability by thermal and multispectral

    imagery using an unmanned aerial vehicle (UAV). Irrig. Sci. 30, 511–522.

    doi: 10.1007/s00271-012-0382-9

    Bareth, G., Bendig, J., Tilly, N., Hoﬀmeister, D., Aasen, H., and Bolten, A. (2016).
    A

    Comparison of UAV- and TLS-derived plant height for crop monitoring: using

    polygon grids for the analysis of crop surface models (CSMs). Photogrammetrie

    Fernerkundung

    Geoinformation

    2016,

    85–94.

    doi:

    10.1127/pfg/2016/

    0289

    Bellundagi, A., Singh, G. P., Prabhu, K. V., Arora, A., Jain, N., Ramya, P.,

    et al. (2013). Early ground cover and other physiological traits as eﬃcient

    selection criteria for grain yield under moisture deﬁcit stress conditions

    in wheat (Triticum aestivum L.). Indian J. Plant Physiol. 18, 277–281.

    doi: 10.1007/s40502-013-0047-6

    Bendig, J., Bolten, A., Bennertz, S., Broscheit, J., Eichfuss, S., and Bareth,
    G.

    (2014). Estimating biomass of barley using crop surface models (CSMs)

    derived from UAV-Based RGB imaging. Remote Sensing 6, 10395–10412.

    doi: 10.3390/rs61110395

    Bendig, J., Yu, K., Aasen, H., Bolten, A., Bennertz, S., Broscheit, J., et al.

    (2015). Combining UAV-based plant height from crop surface models, visible,

    and near infrared vegetation indices for biomass monitoring in barley.

    Int. J. Appl. Earth Observ. Geoinformat. 39, 79–87. doi: 10.1016/j.jag.2015.

    02.012

    Berni, J. A. J., Zarco-Tejada, P. J., Sepulcre-Canto, G., Fereres, E., and Villalobos,

    F. (2009a). Mapping canopy conductance and CWSI in olive orchards using

    high resolution thermal remote sensing imagery. Remote Sens. Environ. 113,

    2380–2388. doi: 10.1016/j.rse.2009.06.018

    Berni, J. A. J., Zarco-Tejada, P. J., Suarez, L., and Fereres, E. (2009b). Thermal

    and narrowband multispectral remote sensing for vegetation monitoring from

    an unmanned aerial vehicle. IEEE Trans. Geosci. Remote Sensing 47, 722–738.

    doi: 10.1109/tgrs.2008.2010457

    Booth, D. T., Cox, S. E., Fiﬁeld, C., Phillips, M., and Williamson, N. (2005).
    Image

    analysis compared with other methods for measuring ground cover. Arid Land

    Res. Manag. 19, 91–100. doi: 10.1080/15324980590916486

    Bowman, W. D., and Strain, B. R. (1988). Physiological responses in two

    populations of Andropogon glomeratus Walter B.S.P. to short-term salinity.

    Oecologia 75, 78–82. doi: 10.1007/BF00378817

    Burkart, A., Aasen, H., Alonso, L., Menz, G., Bareth, G., and Rascher, U.

    (2015). Angular dependency of hyperspectral measurements over wheat

    characterized by a novel UAV based goniometer. Remote Sensing 7, 725–746.

    doi: 10.3390/rs70100725

    Candiago, S., Remondino, F., De Giglio, M., Dubbini, M., and Gattelli, M.

    (2015). Evaluating multispectral images and vegetation indices for precision

    farming applications from UAV images. Remote Sensing 7, 4026–4047.

    doi: 10.3390/rs70404026

    Capolupo, A., Kooistra, L., Berendonk, C., Boccia, L., and Suomalainen, J. (2015).

    Estimating plant traits of grasslands from UAV-acquired hyperspectral images:

    a comparison of statistical approaches. ISPRS Int. J. Geo Informat. 4, 2792–2820.

    doi: 10.3390/ijgi4042792

    Chapman, S., Merz, T., Chan, A., Jackway, P., Hrabar, S., Dreccer, M., et al.

    (2014). Pheno-Copter: a low-altitude, autonomous remote-sensing robotic

    helicopter for high-throughput ﬁeld-based phenotyping. Agronomy 4, 279–301.

    doi: 10.3390/agronomy4020279

    Chaudhuri, U. N., and Kanemasu, E. T. (1982). Eﬀect of water gradient on

    sorghum growth, water relations and yield. Can. J. Plant Sci. 62, 599–607.

    doi: 10.4141/cjps82-090

    Chen, C. M. (2004). Searching for intellectual turning points: progressive

    knowledge domain visualization. Proc. Natl. Acad. Sci. U.S.A. 101, 5303–5310.

    doi: 10.1073/pnas.0307513100

    Cobb, J. N., DeClerck, G., Greenberg, A., Clark, R., and McCouch, S.

    (2013).

    Next-generation

    phenotyping:

    requirements

    and

    strategies

    for

    enhancing our understanding of genotype-phenotype relationships and

    its relevance to crop improvement. Theor. Appl. Genet. 126, 867–887.

    doi: 10.1007/s00122-013-2066-0

    Colomina,

    I.,

    and

    Molina,

    P.

    (2014).

    Unmanned

    aerial

    systems

    for

    photogrammetry and remote sensing: a review. ISPRS J. Photogram. Remote

    Sensing 92, 79–97. doi: 10.1016/j.isprsjprs.2014.02.013

    Comba, L., Gay, P., Primicerio, J., and Aimonino, D. (2017). Vineyard detection

    from unmanned aerial systems images. Comput. Electron. Agric. 114, 78–87.

    doi: 10.1016/j.compag.2015.03.011

    Corcoles, J. I., Ortega, J. F., Hernandez, D., and Moreno, M. A. (2013). Use of
    digital

    photography from unmanned aerial vehicles for estimation of leaf area index in

    onion (Allium cepa L.) (Retracted article. See vol. 51, pg. 140, 2013). Eur. J.

    Agron. 45, 96–104. doi: 10.1016/j.eja.2012.11.001

    Curran, P. J. (1985). Principles of Remote Sensing Longman Scientiﬁc and Technical.

    London: ELBS.

    Danks, S. M., Evans, E. H., and Whittaker, P. A. (1984). Photosynthetic Systems:

    Structure: Function and Assembly. New York, NY: Wiley.

    Deery, D., Jimenez-Berni, J., Jones, H., Sirault, X., and Furbank, R. (2014).

    Proximal remote sensing buggies and potential applications for ﬁeld-based

    phenotyping. Agronomy 4, 349–379. doi: 10.3390/agronomy4030349

    De Souza, C. H. W., Lamparelli, R. A. C., Rocha, J. V., and Magalhaes, P. S. G.

    (2017). Height estimation of sugarcane using an unmanned aerial system (UAS)

    based on structure from motion (SfM) point clouds. Int. J. Remote Sensing 38,

    2218–2230. doi: 10.1080/01431161.2017.1285082

    Diaz-Varela, R. A., Zarco-Tejada, P. J., Angileri, V., and Loudjani, P. (2014).

    Automatic identiﬁcation of agricultural terraces through object-oriented

    analysis of very high resolution DSMs and multispectral imagery obtained

    from an unmanned aerial vehicle. J. Environ. Manag. 134, 117–126.

    doi: 10.1016/j.jenvman.2014.01.006

    Du, M. M., and Noguchi, N. (2017). Monitoring of wheat growth status

    and

    mapping

    of

    wheat

    yield’s

    within-ﬁeld

    spatial

    variations

    using

    color images acquired from UAV-camera system. Remote Sensing 9, 14.

    doi: 10.3390/rs9030289

    Duan, T., Zheng, B. Y., Guo, W., Ninomiya, S., Guo, Y., and Chapman, S. C.

    (2017). Comparison of ground cover estimates from experiment plots in cotton,

    sorghum and sugarcane based on images and ortho-mosaics captured by UAV.

    Funct. Plant Biol. 44, 169–183. doi: 10.1071/fp16123

    Filella, I., Serrano, L., Serra, J., and Penuelas, J. (1995). Evaluating Wheat
    Nitrogen

    Status with Canopy Reﬂectance Indices and Discriminant Analysis. Madison,

    WI, ETATS-UNIS: Crop Science Society of America.

    Fischer, R. A. T., and Edmeades, G. O. (2010). Breeding and cereal yield progress.

    Crop Science 50, S85–S98. doi: 10.2135/cropsci2009.10.0564

    Furbank,

    R.

    T.,

    and

    Tester,

    M.

    (2011).

    Phenomics

    -

    technologies

    to

    relieve

    the

    phenotyping

    bottleneck.

    Trends

    Plant

    Sci.

    16,

    635–644.

    doi: 10.1016/j.tplants.2011.09.005

    Gao, L., Yang, G., Yu, H., Xu, B., Zhao, X., Dong, J., et al. (2016).

    Retrieving winter wheat leaf area index based on unmanned aerial vehicle

    hyperspectral remote sensing. Trans. Chin. Soc. Agric. Eng. 32, 113–120.

    doi: 10.11975/j.issn.1002-6819.2016.22.016

    Garcia-Ruiz, F., Sankaran, S., Maja, J. M., Lee, W. S., Rasmussen, J., and Ehsani,

    R. (2013). Comparison of two aerial imaging platforms for identiﬁcation of

    Huanglongbing-infected citrus trees. Comput. Electron. Agric. 91, 106–115.

    doi: 10.1016/j.compag.2012.12.002

    Geipel, J., Link, J., and Claupein, W. (2014). Combined spectral and spatial

    modeling of corn yield based on aerial images and crop surface models

    acquired with an unmanned aircraft system. Remote Sensing 6, 10335–10355.

    doi: 10.3390/rs61110335

    Gevaert, C. M., Suomalainen, J., Tang, J., and Kooistra, L. (2015). Generation

    of spectral-temporal response surfaces by combining multispectral satellite

    and hyperspectral UAV imagery for precision agriculture applications.

    IEEE J. Select. Topics Appl. Earth Observ. Remote Sensing 8, 3140–3146.

    doi: 10.1109/JSTARS.2015.2406339

    Gitelson, A. A., Kaufman, Y. J., and Merzlyak, M. N. (1996). Use of a green channel

    in remote sensing of global vegetation from EOS-MODIS. Remote Sensing

    Environ. 58, 289–298. doi: 10.1016/S0034-4257(96)00072-7

    Gomez-Candon, D., De Castro, A. I., and Lopez-Granados, F. (2014). Assessing

    the accuracy of mosaics from unmanned aerial vehicle (UAV) imagery

    for precision agriculture purposes in wheat. Precision Agric. 15, 44–56.

    doi: 10.1007/s11119-013-9335-4

    Gomez-Candon, D., Virlet, N., Labbe, S., Jolivot, A., and Regnard, J. L. (2016).

    Field phenotyping of water stress at tree scale by UAV-sensed imagery: new

    Frontiers in Plant Science | www.frontiersin.org

    23

    June 2017 | Volume 8 | Article 1111

    Yang et al.

    High-Throughput Field-Based Phenotyping Using UAV

    insights for thermal acquisition and calibration. Precision Agric. 17, 786–800.

    doi: 10.1007/s11119-016-9449-6

    Gong, P. (1999). Inverting a canopy reﬂectance model using a neural network. Int.

    J. Remote Sensing 20, 111–122. doi: 10.1080/014311699213631

    Gonzalez-Dugo, V., Hernandez, P., Solis, I., and Zarco-Tejada, P. J. (2015).

    Using high-resolution hyperspectral and thermal airborne imagery to assess

    physiological condition in the context of wheat phenotyping. Remote Sensing

    7, 13586–13605. doi: 10.3390/rs71013586

    Gonzalez-Dugo, V., Zarco-Tejada, P. J., and Fereres, E. (2014). Applicability

    and limitations of using the crop water stress index as an indicator

    of water deﬁcits in citrus orchards. Agric. Forest Meteorol. 198, 94–104.

    doi: 10.1016/j.agrformet.2014.08.003

    Gonzalez-Dugo, V., Zarco-Tejada, P., Nicolas, E., Nortes, P. A., Alarcon,

    J. J., Intrigliolo, D. S., et al. (2013). Using high resolution UAV thermal

    imagery to assess the variability in the water status of ﬁve fruit tree

    species

    within

    a

    commercial

    orchard.

    Precision

    Agric.

    14,

    660–678.

    doi: 10.1007/s11119-013-9322-9

    Gonzalez-Recio, O., Coﬀey, M. P., and Pryce, J. E. (2014). On the value

    of the phenotypes in the genomic era. J. Dairy Sci. 97, 7905–7915.

    doi: 10.3168/jds.2014-8125

    Grieder, C., Hund, A., and Walter, A. (2015). Image based phenotyping during

    winter: a powerful tool to assess wheat genetic variation in growth response to

    temperature. Funct. Plant Biol. 42, 387–396. doi: 10.1071/Fp14226

    Guillen-Climent, M. L., Zarco-Tejada, P. J., Berni, J. A. J., North, P. R. J.,
    and

    Villalobos, F. J. (2012). Mapping radiation interception in row-structured

    orchards using 3D simulation and high-resolution airborne imagery acquired

    from a UAV. Precision Agric. 13, 473–500. doi: 10.1007/s11119-012-9263-8

    Guillen-Climent, M. L., Zarco-Tejada, P. J., and Villalobos, F. J. (2014).

    Estimating radiation interception in heterogeneous orchards using high spatial

    resolution airborne imagery. IEEE Geosci. Remote Sensing Lett. 11, 579–583.

    doi: 10.1109/Lgrs.2013.2284660

    Guo, W., Fukatsu, T., and Ninomiya, S. (2015). Automated characterization of

    ﬂowering dynamics in rice using ﬁeld-acquired time-series RGB images. Plant

    Methods 11, 14. doi: 10.1186/s13007-015-0047-9

    Gutierrez, M., Reynolds, M. P., Raun, W. R., Stone, M. L., and Klatt, A. R. (2010).

    Spectral water indices for assessing yield in elite bread wheat genotypes under

    well-irrigated, water-stressed, and high-temperature conditions. Crop Sci. 50,

    197–214. doi: 10.2135/cropsci2009.07.0381

    Haghighattalab, A., Perez, L. G., Mondal, S., Singh, D., Schinstock, D., Rutkoski,

    J., et al. (2016). Application of unmanned aerial systems for high throughput

    phenotyping of large wheat breeding nurseries. Plant Methods 12, 15.

    doi: 10.1186/s13007-016-0134-6

    Hall, A., Louis, J., and Lamb, D. (2003). Characterising and mapping vineyard

    canopy using high-spatial-resolution aerial multispectral images. Comput.

    Geosci. 29, 813–822. doi: 10.1016/S0098-3004(03)00082-7

    Hardin, P. J., and Jensen, R. R. (2011). Small-scale unmanned aerial vehicles
    in

    environmental remote sensing: challenges and opportunities. Gisci. Remote

    Sensing 48, 99–111. doi: 10.2747/1548-1603.48.1.99

    Hernandez-Lopez, D., Felipe-Garcia, B., Sanchez, N., Gonzalez-Aguilera, D.,

    and Gomez-Lahoz, J. (2012). Testing the radiometric performance of digital

    photogrammetric images: vicarious vs. laboratory calibration on the Leica

    ADS40, a Study in Spain. Photogrammetrie Fernerkundung Geoinformation

    2012, 557–571. doi: 10.1127/1432-8364/2012/0139

    Herwitz, S. R., Johnson, L. F., Dunagan, S. E., Higgins, R. G., Sullivan, D.

    V., Zheng, J., et al. (2004). Imaging from an unmanned aerial vehicle:

    agricultural surveillance and decision support. Comp. Electron. Agric. 44, 49–61.

    doi: 10.1016/j.compag.2004.02.006

    Holman, F. H., Riche, A. B., Michalski, A., Castle, M., Wooster, M. J., and

    Hawkesford, M. J. (2016). High throughput ﬁeld phenotyping of wheat plant

    height and growth rate in ﬁeld plot trials using UAV based remote sensing.

    Remote Sensing 8:1031. doi: 10.3390/rs8121031

    Honkavaara, E., Saari, H., Kaivosoja, J., Polonen, I., Hakala, T., Litkey, P.,
    et al.

    (2013). Processing and assessment of spectrometric, stereoscopic imagery

    collected using a lightweight UAV spectral camera for precision agriculture.

    Remote Sensing 5, 5006–5039. doi: 10.3390/rs5105006

    Horler, D. N. H., Dockray, M., and Barber, J. (1983). The red edge of plant leaf

    reﬂectance. Int. J. Remote Sensing 4, 273–288. doi: 10.1080/01431168308948546

    Huete, A. R., Liu, H. Q., Batchily, K., and Leeuwen, W. (1997). A comparison of

    vegetation indices over a global set of TM images for EOS-MODIS. Remote

    Sensing Environ. 59, 440–451. doi: 10.1016/s0034-4257(96)00112-5

    Hunt, E. R., Cavigelli, M., Daughtry, C. S. T., Mcmurtrey, J. E., and Walthall,
    C.

    L. (2005). Evaluation of digital photography from model aircraft for remote

    sensing of crop biomass and nitrogen status. Precision Agric. 6, 359–378.

    doi: 10.1007/s11119-005-2324-5

    Hunt, E. R., Hively, W. D., Fujikawa, S. J., Linden, D. S., Daughtry, C. S. T.,
    and

    McCarty, G. W. (2010). Acquisition of NIR-Green-Blue digital photographs

    from unmanned aircraft for crop monitoring. Remote Sensing 2, 290–305.

    doi: 10.3390/rs2010290

    Issei, H.-Y., Ishii, K., and Noguchi, N. (2010). Satellite and aerial remote sensing

    for production estimates and crop assessment. Environ. Control Biol. 48, 51–58.

    doi: 10.2525/ecb.48.51

    Jones, H. G., Serraj, R., Loveys, B. R., Xiong, L., Wheaton, A., and Price, A.
    H.

    (2009). Thermal infrared imaging of crop canopies for the remote diagnosis

    and quantiﬁcation of plant responses to water stress in the ﬁeld. Funct. Plant

    Biol. 36, 978–989. doi: 10.1071/fp09123

    Jordan, C. F. (1969). Derivation of leaf-area index from quality of light on the
    forest

    ﬂoor. Ecology, 50, 663–666. doi: 10.2307/1936256

    Keep, N. R. (2013). Characterization of Physiological Parameters in Soybean with

    Genetic Improvement in Seed Yield. Master of Science, Kansas state university.

    Kirchgessner, N., Liebisch, F., Yu, K., Pfeifer, J., Friedli, M., Hund, A., et
    al. (2016).

    The ETH ﬁeld phenotyping platform FIP: a cable-suspended multi-sensor

    system. Funct. Plant Biol. 44, 154–168. doi: 10.1071/F. P.16165

    Laliberte, A. S., Goforth, M. A., Steele, C. M., and Rango, A. (2011). Multispectral

    remote sensing from unmanned aircraft: image processing workﬂows and

    applications for rangeland environments. Remote Sensing 3, 2529–2551.

    doi: 10.3390/rs3112529

    Lebourgeois, V., Begue, A., Labbe, S., Houles, M., and Martine, J. F. (2012).
    A

    light-weight multi-spectral aerial imaging system for nitrogen crop monitoring.

    Precision Agric. 13, 525–541. doi: 10.1007/s11119-012-9262-9

    Lelong, C. C. D., Burger, P., Jubelin, G., Roux, B., Labbe, S., and Baret, F.
    (2008).

    Assessment of unmanned aerial vehicles imagery for quantitative monitoring

    of wheat crop in small plots. Sensors 8, 3557–3585. doi: 10.3390/s8053557

    Li, J. W., Zhang, F., Qian, X. Y., Zhu, Y. H., and Shen, G. X. (2015).

    Quantiﬁcation

    of

    rice

    canopy

    nitrogen

    balance

    index

    with

    digital

    imagery from unmanned aerial vehicle. Remote Sensing Lett. 6, 183–189.

    doi: 10.1080/2150704X.2015.1021934

    Li, L., Zhang, Q., and Huang, D. F. (2014). A review of imaging techniques for
    plant

    phenotyping. Sensors 14, 20078–20111. doi: 10.3390/s141120078

    Li, W., Niu, Z., Chen, H. Y., Li, D., Wu, M. Q., and Zhao, W. (2016). Remote

    estimation of canopy height and aboveground biomass of maize using high-

    resolution stereo images from a low-cost unmanned aerial vehicle system. Ecol.

    Indic. 67, 637–648. doi: 10.1016/j.ecolind.2016.03.036

    Li, W., Niu, Z., Huang, N., Wang, C., Gao, S., and Wu, C. Y. (2015).

    Airborne LiDAR technique for estimating biomass components of maize:

    a case study in Zhangye City, Northwest China. Ecol. Indic. 57, 486–496.

    doi: 10.1016/j.ecolind.2015.04.016

    Li, X. (2012). Feature extracting methods in spectrum data mining. Chin. Astron.

    Astrophys. 30, 94–105.

    Li, Z., Chen, Z., Wang, L., Liu, J., and Zhou, Q. (2014). Area extraction of maize

    lodging based on remote sensing by small unmanned aerial vehicle. Trans.

    Chin. Soc. Agric. Eng. 30, 207–213. doi: 10.3969/j.issn.1002-6819.2014.19.025

    Li, Z., Nie, C., Wei, C., Xu, X., Song, X., and Wang, J. (2016). Comparison of
    four

    chemometric techniques for estimating leaf nitrogen concentrations in winter

    wheat (Triticum Aestivum) based on hyperspectral features. J. Appl. Spectros.

    83, 240–247. doi: 10.1007/s10812-016-0276-3

    Liang, S. (2005). Quantitative Remote Sensing of Land Surfaces. New York, NY:

    Wiley.

    Liang, S. (2008). Advances in Land Remote Sensing: System, Modeling, Inversion

    and Application. New York, NY: Springer.

    Liang, S., Li, X., and Wang, J. (2013). Quantitative Remote Sensing: Concepts
    and

    Algorithms. Beijing: Science Press.

    Liebisch, F., Kirchgessner, N., Schneider, D., Walter, A., and Hund, A. (2015).

    Remote, aerial phenotyping of maize traits with a mobile multi-sensor

    approach. Plant Methods 11:9. doi: 10.1186/s13007-015-0048-8

    Frontiers in Plant Science | www.frontiersin.org

    24

    June 2017 | Volume 8 | Article 1111

    Yang et al.

    High-Throughput Field-Based Phenotyping Using UAV

    Link, J., Senner, D., and Claupein, W. (2013). Developing and evaluating

    an aerial sensor platform (ASP) to collect multispectral data for deriving

    management decisions in precision farming. Comp. Electron. Agric. 94, 20–28.

    doi: 10.1016/j.compag.2013.03.003

    Lu, G., Li, C., Yang, G., Yu, H., Zhao, X., and Zhang, X. (2016). Retrieving soybean

    leaf area index based on high imaging spectrometer. Soybean Sci. 35, 599–608.

    Ma, B. L., Dwyer, L. M., Carlos, C., Cober, E. R., and Morrison, M. J. et al.
    (2001).

    Early prediction of soybean yield from canopy reﬂectance measurements.

    Agron. J. 93, 1227–1234. doi: 10.2134/agronj2001.1227

    Mathews, A. J. (2014). Object-based spatiotemporal analysis of vine canopy vigor

    using an inexpensive unmanned aerial vehicle remote sensing system. J. Appl.

    Remote Sensing 8:17. doi: 10.1117/1.jrs.8.085199

    Mathews, A. J., and Jensen, J. L. R. (2013). Visualizing and quantifying

    vineyard canopy LAI using an unmanned aerial vehicle (UAV) collected high

    density structure from motion point cloud. Remote Sensing 5, 2164–2183.

    doi: 10.3390/rs5052164

    McNeil, B. E., Pisek, J., Lepisk, H., and Flamenco, E. A. (2016). Measuring leaf

    angle distribution in broadleaf canopies using UAVs. Agric. For. Meteorol. 218,

    204–208. doi: 10.1016/j.agrformet.2015.12.058

    Mullan, D. J., and Reynolds, M. P. (2010). Quantifying genetic eﬀects of ground

    cover on soil water evaporation using digital imaging. Funct. Plant Biol. 37,

    703–712. doi: 10.1071/Fp09277

    Nasi, R., Honkavaara, E., Lyytikainen-Saarenmaa, P., Blomqvist, M., Litkey, P.,

    Hakala, T., et al. (2015). Using UAV-Based photogrammetry and hyperspectral

    imaging for mapping bark beetle damage at tree-level. Remote Sensing 7,

    15467–15493. doi: 10.3390/rs71115467

    Neilson, E. H., Edwards, A. M., Blomstedt, C. K., Berger, B., Moller, B. L.,

    and Gleadow, R. M. (2015). Utilization of a high-throughput shoot imaging

    system to examine the dynamic phenotypic responses of a C-4 cereal crop

    plant to nitrogen and water deﬁciency over time. J. Exp. Bot. 66, 1817–1832.

    doi: 10.1093/jxb/eru526

    Nigon, T. J., Mulla, D. J., Rosen, C. J., Cohen, Y., Alchanatis, V., Knight, J.,

    et al. (2015). Hyperspectral aerial imagery for detecting nitrogen stress in two

    potato cultivars. Comp. Electron. Agric. 112, 36–46. doi: 10.1016/j.compag.2014.

    12.018

    Olivares-Villegas, J. J., Reynolds, M. P., and McDonald, G. K. (2007). Drought-

    adaptive attributes in the Seri/Babax hexaploid wheat population. Funct. Plant

    Biol. 34, 189–203. doi: 10.1071/Fp06148

    Ortega-Farias, S., Ortega-Salazar, S., Poblete, T., Kilic, A., Allen, R., Poblete-

    Echeverria, C., et al. (2016). Estimation of energy balance components over a

    drip-irrigated olive orchard using thermal and multispectral cameras placed

    on a helicopter-based unmanned aerial vehicle (UAV). Remote Sensing 8:18.

    doi: 10.3390/rs8080638

    Ota, T., Ogawa, M., Shimizu, K., Kajisa, T., Mizoue, N., Yoshida, S., et al. (2015).

    Aboveground biomass estimation using structure from motion approach

    with aerial photographs in a seasonal tropical forest. Forests 6, 3882–3898.

    doi: 10.3390/f6113882

    Overgaard, S. I., Isaksson, T., Kvaal, K., and Korsaeth, A. (2010). Comparisons
    of

    two hand-held, multispectral ﬁeld radiometers and a hyperspectral airborne

    imager in terms of predicting spring wheat grain yield and quality by means

    of powered partial least squares regression. J. Near Infr. Spectr. 18, 247–261.

    doi: 10.1255/jnirs.892

    Pajares, G. (2015). Overview and current status of remote sensing applications

    based on unmanned aerial vehicles (UAVs). Photogram. Eng. Remote Sensing

    81, 281–329. doi: 10.14358/PERS.81.4.281

    Pask, A. D., Pietragalla, J., Mullan, D. M., and Reynolds, M. P. (2012). Physiological

    Breeding II: A Field Guide to Wheat Phenotyping. Mexico City: CIMMYT.

    Pena, J. M., Torres-Sanchez, J., de Castro, A. I., Kelly, M., and Lopez-Granados,

    F. (2013). Weed mapping in early-season maize ﬁelds using object-based

    analysis of unmanned aerial vehicle (UAV) images. PLoS ONE 8:77151.

    doi: 10.1371/journal.pone.0077151

    PeÑUelas, J., Filella, I., Biel, C., Serrano, L., and SavÉ, R. (1993). The reﬂectance

    at the 950–970 nm region as an indicator of plant water status. Int. J. Remote

    Sensing 14, 1887–1905. doi: 10.1080/01431169308954010

    Prasad, B., Carver, B. F., Stone, M. L., Babar, M. A., Raun, W. R., and Klatt,
    A. R.

    (2007). Potential use of spectral reﬂectance indices as a selection tool for grain

    yield in winter wheat under great plains conditions. Crop Sci. 47, 1426–1440.

    doi: 10.2135/cropsci2006.07.0492

    Rahaman, M. M., Chen, D. J., Gillani, Z., Klukas, C., and Chen, M. (2015).

    Advanced phenotyping and phenotype data analysis for the study of plant

    growth and development. Front. Plant Sci. 6:15. doi: 10.3389/fpls.2015.00619

    Rajan, N., and Maas, S. J. (2009). Mapping crop ground cover using

    airborne

    multispectral

    digital

    imagery.

    Precision

    Agric.

    10,

    304–318.

    doi: 10.1007/s11119-009-9116-2

    Rashid, A., Stark, J. C., Tanveer, A., and Mustafa, T. (1999). Use of canopy

    temperature measurements as a screening tool for drought tolerance in spring

    wheat. J. Agron. Crop Sci. 182, 231–238. doi: 10.1046/j.1439-037x.1999.00335.x

    Raun, W. R., Solie, J. B., Johnson, G. V., Stone, M. L., Lukina, E. V.,

    Thomason, W. E., et al. (2001). In-season prediction of potential grain

    yield in winter wheat using canopy reﬂectance. Agron. J. 93, 131–138.

    doi: 10.2134/agronj2001.931131x

    Ray, D. K., Mueller, N. D., West, P. C., and Foley, J. A. (2013). Yield trends
    are

    insuﬃcient to double global crop production by 2050. PLoS ONE 8:e66428.

    doi: 10.1371/journal.pone.0066428

    Reynolds, M., Balota, M. M., Delgado, M. I. B., and Fischer, R. A. (1994).

    Physiological and Morphological Traits Associated with Spring Wheat Yield

    under Hot, Irrigated Conditions. [Workshop paper]. v. 21.

    Reynolds, M., Dreccer, F., and Trethowan, R. (2007). Drought-adaptive traits

    derived from wheat wild relatives and landraces. J. Exp. Bot. 58, 177–186.

    doi: 10.1093/jxb/erl250

    Richards, J. A. (1990). Computer processing of remotely-sensed images: an

    introduction. Earth Sci. Rev. 27, 392–394. doi: 10.1016/0012-8252(90)90075-7

    Richardson, A. J., and Wiegand, C. L. (1977). Distinguishing vegetation from soil

    background information. Photogram. Eng. Remote Sensing 43, 1541–1552.

    Rondeaux, G., Steven, M., and Baret, F. (1996). Optimization of soil-

    adjusted

    vegetation

    indices.

    Remote

    Sensing

    Environ.

    55,

    95–107.

    doi: 10.1016/0034-4257(95)00186-7

    Rosen, P. A., Hensley, S., Wheeler, K., Sadowy, G., Miller, T., Shaﬀer, S.,

    et al. (2006). “UAVSAR: a new NASA airborne SAR system for science and

    technology research,” in 2006 IEEE Conference on Radar (New York, NY), 8.

    doi: 10.1109/RADAR.2006.1631770

    Salami, E., Barrado, C., and Pastor, E. (2014). UAV ﬂight experiments applied

    to the remote sensing of vegetated areas. Remote Sensing 6, 11051–11081.

    doi: 10.3390/rs61111051

    Samseemoung, G., Jayasuriya, H. P. W., and Soni, P. (2011). Oil palm pest

    infestation monitoring and evaluation by helicopter-mounted, low altitude

    remote sensing platform. J. Appl. Remote Sensing 5:16. doi: 10.1117/1.3609843

    Samseemoung, G., Soni, P., Jayasuriya, H. P. W., and Salokhe, V. M. (2012).

    Application of low altitude remote sensing (LARS) platform for monitoring

    crop growth and weed infestation in a soybean plantation. Precision Agric. 13,

    611–627. doi: 10.1007/s11119-012-9271-8

    Sankaran, S., Khot, L. R., and Carter, A. H. (2015a). Field-based crop

    phenotyping:

    multispectral

    aerial

    imaging

    for

    evaluation

    of

    winter

    wheat emergence and spring stand. Comp. Electron. Agric. 118, 372–379.

    doi: 10.1016/j.compag.2015.09.001

    Sankaran, S., Khot, L. R., Espinoza, C. Z., Jarolmasjed, S., Sathuvalli, V. R.,

    Vandemark, G. J., et al. (2015b). Low-altitude, high-resolution aerial imaging

    systems for row and ﬁeld crop phenotyping: a review. Eur. J. Agron. 70,

    112–123. doi: 10.1016/j.eja.2015.07.004

    Saskia, G., Ruedi, B., and Daniel, F. (2017). Accuracy assessment of digital surface

    models from unmanned aerial vehicles’ imagery on glaciers. Remote Sensing

    9:186. doi: 10.3390/rs9020186

    Sayed, M. A., Schumann, H., Pillen, K., Naz, A. A., and Leon, J. (2012). AB-QTL

    analysis reveals new alleles associated to proline accumulation and leaf wilting

    under drought stress conditions in barley (Hordeum vulgare L.). BMC Genetics

    13:61. doi: 10.1186/1471-2156-13-61

    Shi, Y. Y., Thomasson, J. A., Murray, S. C., Pugh, N. A., Rooney, W.

    L.,

    Shaﬁan,

    S.,

    et

    al.

    (2016).

    Unmanned

    aerial

    vehicles

    for

    high-

    throughput phenotyping and agronomic research. PLoS ONE 11:e0159781.

    doi: 10.1371/journal.pone.0159781

    Singh, A., Ganapathysubramanian, B., Singh, A. K., and Sarkar, S. (2016). Machine

    learning for high-throughput stress phenotyping in plants. Trends Plant Sci. 21,

    110–124. doi: 10.1016/j.tplants.2015.10.015

    Stöcker, C., Bennett, R., Nex, F., Gerke, M., and Zevenbergen, J. (2017).

    Review of the current state of UAV regulations. Remote Sensing 9:459.

    doi: 10.3390/rs9050459

    Frontiers in Plant Science | www.frontiersin.org

    25

    June 2017 | Volume 8 | Article 1111

    Yang et al.

    High-Throughput Field-Based Phenotyping Using UAV

    Suarez, L., Zarco-Tejada, P. J., Berni, J. A. J., Gonzalez-Dugo, V., and Fereres,

    E. (2009). Modelling PRI for water stress detection using radiative transfer

    models. Remote Sensing Environ. 113, 730–744. doi: 10.1016/j.rse.2008.12.001

    Sugiura, R., Noguchi, N., and Ishii, K. (2005). Remote-sensing technology for

    vegetation monitoring using an unmanned helicopter. Biosys. Eng. 90, 369–379.

    doi: 10.1016/j.biosystemseng.2004.12.011

    Sugiura, R., Noguchi, N., and Ishii, K. (2007). Correction of low-altitude thermal

    images applied to estimating soil water status. Biosys. Eng. 96, 301–313.

    doi: 10.1016/j.biosystemseng.2006.11.006

    Swain, K. C., Jayasuriya, H. P. W., and Salokhe, V. M. (2007). Suitability of
    low-

    altitude remote sensing images for estimating nitrogen treatment variations in

    rice cropping for precision agriculture adoption. J. Appl. Remote Sensing 1:11.

    doi: 10.1117/1.2824287

    Swain, K. C., Thomson, S. J., and Jayasuriya, H. P. W. (2010). Adoption of an

    unmanned helicopter for low-altitude remote sensing to estimate yield and total

    biomass of a rice crop. Trans. Asabe 53, 21–27. doi: 10.13031/2013.29493

    Tamouridou, A. A., Alexandridis, T. K., Pantazi, X. E., Lagopodi, A. L.,

    Kasheﬁ, J., and Moshou, D. (2017). Evaluation of UAV imagery for mapping

    Silybum marianum weed patches. Int. J. Remote Sensing 38, 2246–2259.

    doi: 10.1080/01431161.2016.1252475

    Tattaris, M., Reynolds, M. P., and Chapman, S. C. (2016). A direct comparison

    of remote sensing approaches for high-throughput phenotyping in plant

    breeding. Front. Plant Sci. 7:1131. doi: 10.3389/fpls.2016.01131

    Thorp, K. R., Gore, M. A., Andrade-Sanchez, P., Carmo-Silva, A. E., Welch,

    S. M., White, J. W., et al. (2015). Proximal hyperspectral sensing and data

    analysis approaches for ﬁeld-based plant phenomics. Comp. Electron. Agric.

    118, 225–236. doi: 10.1016/j.compag.2015.09.005

    Torres-Sanchez, J., Lopez-Granados, F., and Pena, J. M. (2015). An automatic

    object-based method for optimal thresholding in UAV images: application for

    vegetation detection in herbaceous crops. Comp. Electron. Agric. 114, 43–52.

    doi: 10.1016/j.compag.2015.03.019

    Torres-Sanchez, J., Pena, J. M., de Castro, A. I., and Lopez-Granados, F.

    (2014). Multi-temporal mapping of the vegetation fraction in early-season

    wheat ﬁelds using images from UAV. Comp. Electron. Agric. 103, 104–113.

    doi: 10.1016/j.compag.2014.02.009

    Tucker, C. J. (1979). Red and photographic infrared linear combinations

    for

    monitoring

    vegetation.

    Remote

    Sensing

    Environ.

    8,

    127–150.

    doi: 10.1016/0034-4257(79)90013-0

    Turner, D., Lucieer, A., and Watson, C. (2012). An automated technique for

    generating georectiﬁed mosaics from ultra-high resolution unmanned aerial

    vehicle (UAV) imagery, based on structure from motion (SfM) point clouds.

    Remote Sensing 4, 1392–1410. doi: 10.3390/rs4051392

    Uto, K., Seki, H., Saito, G., and Kosugi, Y. (2013). Characterization of

    rice paddies by a UAV-mounted miniature hyperspectral sensor system.

    IEEE J. Select. Topics Appl. Earth Observ. Remote Sens. 6, 851–860.

    doi: 10.1109/Jstars.2013.2250921

    Vega, F. A., Ramirez, F. C., Saiz, M. P., and Rosua, F. O. (2015). Multi-temporal

    imaging using an unmanned aerial vehicle for monitoring a sunﬂower crop.

    Biosys. Eng. 132, 19–27. doi: 10.1016/j.biosystemseng.2015.01.008

    Verhoeven, G. J. J. (2009). Providing an archaeological bird’s-eye view - an overall

    picture of ground-based means to execute low-altitude aerial photography

    (LAAP)

    in

    archaeology.

    Archaeol.

    Prosp.

    16,

    233–249.

    doi:

    10.1002/

    arp.354

    Virlet, N., Sabermanesh, K., Sadeghi-Tehran, P., and Hawkesford, M. J. (2017).

    Field Scanalyzer: an automated robotic ﬁeld phenotyping platform for

    detailed crop monitoring. Funct. Plant Biol. 44, 143–153. doi: 10.1071/

    Fp16163

    Wallace, L., Lucieer, A., Watson, C., and Turner, D. (2012). Development of a

    UAV-LiDAR system with application to forest inventory. Remote Sensing 4,

    1519–1543. doi: 10.3390/rs4061519

    Wang, D., Zhou, Q., Chen, Z., and Liu, J. (2014). Research advances on crop

    identiﬁcation using synthetic aperture radar. Trans. Chin. Soc. Agric. Eng. 30,

    203–212. doi: 10.3969/j.issn.1002-6819.2014.16.027

    Wang, J., Zhao, C., and Huang, W. (2008). Foundation and Application of

    Quantitative Remote Sensing in Agriculture. Beijing: Science Press.

    Wang, W., Vinocur, B., and Altman, A. (2003). Plant responses to drought, salinity

    and extreme temperatures: towards genetic engineering for stress tolerance.

    Planta 218, 1–14. doi: 10.1007/s00425-003-1105-5

    Watanabe, K., Guo, W., Arai, K., Takanashi, H., Kajiya-Kanegae, H., Kobayashi,

    M., et al. (2017). High-throughput phenotyping of sorghum plant height

    using an unmanned aerial vehicle and its application to genomic prediction

    modeling. Front. Plant Sci. 8:421. doi: 10.3389/fpls.2017.00421

    Weiss, M., and Baret, F. (2017). Using 3D point clouds derived from UAV

    RGB imagery to describe vineyard 3D Macro- structure. Remote Sensing 9:17.

    doi: 10.3390/rs9020111

    White, J. W., Andrade-Sanchez, P., Gore, M. A., Bronson, K. F., Coﬀelt, T. A.,

    Conley, M. M., et al. (2012). Field-based phenomics for plant genetics research.

    Field Crops Res. 133, 101–112. doi: 10.1016/j.fcr.2012.04.003

    Xiang, H. T., and Tian, L. (2011). Development of a low-cost agricultural remote

    sensing system based on an autonomous unmanned aerial vehicle (UAV).

    Biosys. Eng. 108, 174–190. doi: 10.1016/j.biosystemseng.2010.11.010

    Xiong, X., Yu, L. J., Yang, W. N., Liu, M., Jiang, N., Wu, D., et al. (2017).
    A high-

    throughput stereo-imaging system for quantifying rape leaf traits during the

    seedling stage. Plant Methods 13:7. doi: 10.1186/s13007-017-0157-7

    Yang,

    G.,

    Li,

    C.,

    Yu,

    H.,

    Xu,

    B.,

    Feng,

    H.,

    Gao,

    L.,

    et

    al.

    (2015).

    UAV based multi-load remote sensing technologies for wheat breeding

    information acquirement. Trans. Chin. Soc. Agric. Eng. 31, 184–190.

    doi: 10.11975/j.issn.1002-6819.2015.21.024

    Yang, W. N., Duan, L. F., Chen, G. X., Xiong, L. Z., and Liu, Q. (2013). Plant

    phenomics and high-throughput phenotyping: accelerating rice functional

    genomics using multidisciplinary technologies. Curr. Opin. Plant Biol. 16,

    180–187. doi: 10.1016/j.pbi.2013.03.005

    Yu, K., Kirchgessner, N., Grieder, C., Walter, A., and Hund, A. (2017). An image

    analysis pipeline for automated classiﬁcation of imaging light conditions and

    for quantiﬁcation of wheat canopy cover time series in ﬁeld phenotyping. Plant

    Methods 13:15. doi: 10.1186/s13007-017-0168-4

    Zaman-Allah, M., Vergara, O., Araus, J. L., Tarekegne, A., Magorokosho, C.,

    Zarco-Tejada, P. J., et al. (2015). Unmanned aerial platform-based multi-

    spectral imaging for ﬁeld phenotyping of maize. Plant Methods 11:10.

    doi: 10.1186/s13007-015-0078-2

    Zarco-Tejada, P. J., Diaz-Varela, R., Angileri, V., and Loudjani, P. (2014). Tree

    height quantiﬁcation using very high resolution imagery acquired from an

    unmanned aerial vehicle (UAV) and automatic 3D photo-reconstruction

    methods. Eur. J. Agron. 55, 89–99. doi: 10.1016/j.eja.2014.01.004

    Zarco-Tejada, P. J., Gonzalez-Dugo, V., and Berni, J. A. J. (2012). Fluorescence,

    temperature and narrow-band indices acquired from a UAV platform for water

    stress detection using a micro-hyperspectral imager and a thermal camera.

    Remote Sensing Environ. 117, 322–337. doi: 10.1016/j.rse.2011.10.007

    Zarco-Tejada, P. J., Morales, A., Testi, L., and Villalobos, F. J. (2013). Spatio-

    temporal patterns of chlorophyll ﬂuorescence and physiological and structural

    indices acquired from hyperspectral imagery as compared with carbon ﬂuxes

    measured with eddy covariance. Remote Sensing Environ. 133, 102–115.

    doi: 10.1016/j.rse.2013.05.011

    Zhang, C. H., and Kovacs, J. M. (2012). The application of small unmanned

    aerial systems for precision agriculture: a review. Precision Agric. 13, 693–712.

    doi: 10.1007/s11119-012-9274-5

    Zhang, C., Walters, D., and Kovacs, J. M. (2014). Applications of low

    altitude

    remote

    sensing

    in

    agriculture

    upon

    farmers’

    requests–a

    case

    study

    in

    northeastern

    Ontario,

    Canada.

    PLoS

    ONE

    9:e112894.

    doi: 10.1371/journal.pone.0112894

    Zhao, C., and Qian, L. (2004). Comparative study of supervised and unsupervised

    classiﬁcation in remote sensing image. J. Henan Uni. 34, 90–93.

    Zhao, Z., Wang, Y., and Wang, C. (2014). Remote Sensing Image Processing. Beijing:

    Science Press.

    Conﬂict of Interest Statement: The authors declare that the research was

    conducted in the absence of any commercial or ﬁnancial relationships that could

    be construed as a potential conﬂict of interest.

    Copyright © 2017 Yang, Liu, Zhao, Li, Huang, Yu, Xu, Yang, Zhu, Zhang, Zhang,

    Feng, Zhao, Li, Li and Yang. This is an open-access article distributed under
    the

    terms of the Creative Commons Attribution License (CC BY). The use, distribution
    or

    reproduction in other forums is permitted, provided the original author(s) or
    licensor

    are credited and that the original publication in this journal is cited, in accordance

    with accepted academic practice. No use, distribution or reproduction is permitted

    which does not comply with these terms.

    Frontiers in Plant Science | www.frontiersin.org

    26

    June 2017 | Volume 8 | Article 1111

    '
  inline_citation: '>'
  journal: Frontiers in plant science
  limitations: '>'
  pdf_link: https://www.frontiersin.org/articles/10.3389/fpls.2017.01111/pdf
  publication_year: 2017
  relevance_score1: 0
  relevance_score2: 0
  title: 'Unmanned Aerial Vehicle Remote Sensing for Field-Based Crop Phenotyping:
    Current Status and Perspectives'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.3390/rs12162659
  analysis: '>'
  authors:
  - Bing Lu
  - Phuong D. Dao
  - Jiangui Liu
  - Yuhong He
  - Jiali Shang
  citation_count: 364
  full_citation: '>'
  full_text: ">\nremote sensing  \nReview\nRecent Advances of Hyperspectral Imaging\n\
    Technology and Applications in Agriculture\nBing Lu 1, Phuong D. Dao 1,2\n, Jiangui\
    \ Liu 3, Yuhong He 1,* and Jiali Shang 3\n1\nDepartment of Geography, Geomatics\
    \ and Environment, University of Toronto Mississauga,\n3359 Mississauga Road,\
    \ Mississauga, ON L5L 1C6, Canada; bing.lu@mail.utoronto.ca (B.L.);\nphuong.dao@mail.utoronto.ca\
    \ (P.D.D.)\n2\nSchool of the Environment, University of Toronto, 33 Willcocks\
    \ Street, Toronto, ON M5S 3E8, Canada\n3\nAgriculture and Agri-Food Canada, 960\
    \ Carling Avenue, Ottawa, ON K1A 0C6, Canada;\njiangui.liu@canada.ca (J.L.); jiali.shang@Canada.ca\
    \ (J.S.)\n*\nCorrespondence: yuhong.he@utoronto.ca\nReceived: 12 July 2020; Accepted:\
    \ 16 August 2020; Published: 18 August 2020\n\x01\x02\x03\x01\x04\x05\x06\a\b\x01\
    \n\x01\x02\x03\x04\x05\x06\a\nAbstract:\nRemote sensing is a useful tool for monitoring\
    \ spatio-temporal variations of crop\nmorphological and physiological status and\
    \ supporting practices in precision farming. In comparison\nwith multispectral\
    \ imaging, hyperspectral imaging is a more advanced technique that is capable\n\
    of acquiring a detailed spectral response of target features. Due to limited accessibility\
    \ outside of\nthe scientiﬁc community, hyperspectral images have not been widely\
    \ used in precision agriculture.\nIn recent years, diﬀerent mini-sized and low-cost\
    \ airborne hyperspectral sensors (e.g., Headwall\nMicro-Hyperspec, Cubert UHD\
    \ 185-Fireﬂy) have been developed, and advanced spaceborne\nhyperspectral sensors\
    \ have also been or will be launched (e.g., PRISMA, DESIS, EnMAP, HyspIRI).\n\
    Hyperspectral imaging is becoming more widely available to agricultural applications.\
    \ Meanwhile,\nthe acquisition, processing, and analysis of hyperspectral imagery\
    \ still remain a challenging research\ntopic (e.g., large data volume, high data\
    \ dimensionality, and complex information analysis). It is\nhence beneﬁcial to\
    \ conduct a thorough and in-depth review of the hyperspectral imaging technology\n\
    (e.g., diﬀerent platforms and sensors), methods available for processing and analyzing\
    \ hyperspectral\ninformation, and recent advances of hyperspectral imaging in\
    \ agricultural applications. Publications\nover the past 30 years in hyperspectral\
    \ imaging technology and applications in agriculture were\nthus reviewed.\nThe\
    \ imaging platforms and sensors, together with analytic methods used in\nthe literature,\
    \ were discussed. Performances of hyperspectral imaging for diﬀerent applications\n\
    (e.g., crop biophysical and biochemical properties’ mapping, soil characteristics,\
    \ and crop classiﬁcation)\nwere also evaluated. This review is intended to assist\
    \ agricultural researchers and practitioners to\nbetter understand the strengths\
    \ and limitations of hyperspectral imaging to agricultural applications\nand promote\
    \ the adoption of this valuable technology. Recommendations for future hyperspectral\n\
    imaging research for precision agriculture are also presented.\nKeywords: precision\
    \ agriculture; remote sensing; hyperspectral imaging; platforms and sensors;\n\
    analytical methods; crop properties; soil characteristics; classiﬁcation of agricultural\
    \ features\n1. Introduction\nThe global agricultural sector is facing increasing\
    \ challenges posed by a range of stressors,\nincluding a rapidly growing population,\
    \ the depletion of natural resources, environmental pollution,\ncrop diseases,\
    \ and climate change. Precision agriculture is a promising approach to address\
    \ these\nchallenges through improving farming practices, e.g., adaptive inputs\
    \ (e.g., water and fertilizer),\nensured outputs (e.g., crop yield and biomass),\
    \ and reduced environmental impacts. Remote sensing\nRemote Sens. 2020, 12, 2659;\
    \ doi:10.3390/rs12162659\nwww.mdpi.com/journal/remotesensing\nRemote Sens. 2020,\
    \ 12, 2659\n2 of 44\nis capable of identifying within-ﬁeld variability of soils\
    \ and crops and providing useful information for\nsite-speciﬁc management practices\
    \ [1,2]. There are two types of remote sensing technologies given the\nsource\
    \ of energy, passive (e.g., optical) and active remote sensing (e.g., LiDAR and\
    \ Radar). Passive\noptical remote sensing is usually further divided into two\
    \ groups based on the spectral resolutions\nof sensors, multispectral and hyperspectral\
    \ remote sensing [3]. Multispectral imaging is facilitated\nby collecting spectral\
    \ signals in a few discrete bands, each spanning a broad spectral range from tens\n\
    to hundreds of nanometers. In contrast, hyperspectral imaging detects spectral\
    \ signals in a series of\ncontinuous channels with a narrow spectral bandwidth\
    \ (e.g., typically below 10 nm); therefore, it can\ncapture ﬁne-scale spectral\
    \ features of targets that otherwise could be compromised [4].\nMultispectral\
    \ images (e.g., Landsat, Sentinel 2, and SPOT images) have been widely used in\n\
    agricultural studies to retrieve various crop and soil attributes, such as crop\
    \ chlorophyll content,\nbiomass, yield, and soil degradation [5–10]. However,\
    \ due to the limitations in spectral resolution,\nthe accuracy of the retrieved\
    \ variables is often limited, and early signals of crop stresses (e.g., nutrient\n\
    deﬁciency, crop disease) cannot be eﬀectively detected in a timely manner [11].\n\
    Hyperspectral\nimages (e.g., Hyperion, CASI, and Headwall Micro-Hyperspec) with\
    \ hundreds of bands can capture\nmore detailed spectral responses; hence, it is\
    \ more capable of detecting subtle variations of ground\ncovers and their changes\
    \ over time. Therefore, hyperspectral imagery can be used to address the\naforementioned\
    \ challenges and facilitate more accurate and timely detection of crop physiological\n\
    status [12,13]. Previous studies have also demonstrated the superior performance\
    \ of hyperspectral\nover multispectral images in monitoring vegetation properties,\
    \ such as estimating the leaf area\nindex (LAI) [14], discriminating crop types\
    \ [15], retrieving crop biomass [16], and assessing leaf\nnitrogen content [17].\
    \ Despite its outstanding performance, hyperspectral imaging has been utilized\n\
    comparatively less in operational agricultural applications in the past few decades\
    \ due to the high cost\nof the sensors and imaging missions, and various technical\
    \ challenges (e.g., low signal-to-noise ratio\nand large data volume) [18–21].\
    \ Although ground-based hyperspectral reﬂectance data can be quickly\nmeasured\
    \ using a spectroradiometer (e.g., ASD Field Spec, Analytical Spectral Devices\
    \ Inc., Boulder,\nCO, USA) and have been widely used for observing canopy- and\
    \ leaf-level spectral features [22–24],\nsuch ground-based measurements are limited\
    \ to a few numbers of ﬁeld sites, and they cannot capture\nspatial variability\
    \ across large areas. In contrast, hyperspectral imaging sensors are more convenient\
    \ to\nacquire spatial variability of spectral information across a region.\nIn\
    \ recent years, a wide range of mini-sized and low-cost hyperspectral sensors\
    \ have been developed\nand are available for commercial use, such as Micro- and\
    \ Nano-Hyperspec (Headwall Photonics Inc.,\nBoston, MA, USA), HySpex VNIR (HySpex,\
    \ Skedsmo, Skjetten, Norway), and FireﬂEYE (Cubert GmbH,\nUlm, Germany) [11,25].\
    \ These sensors can be mounted on manned or unmanned airborne platforms\n(e.g.,\
    \ airplanes, helicopters, and unmanned aerial vehicles (UAVs)) for acquiring hyperspectral\
    \ images\nand supporting various monitoring missions [13,26,27]. In addition,\
    \ new spaceborne hyperspectral\nsensors have been launched recently, such as the\
    \ DESIS—launched in 2018 [28]—and PRISMA—\nlaunched in 2019 [29]—or will be launched\
    \ in the next few years, such as EnMAP, with scheduled\nlaunching in 2020 [30,31].\
    \ Overall, increasingly more airborne or spaceborne hyperspectral images\nhave\
    \ become available, bringing unprecedented opportunities for better monitoring\
    \ of ground targets,\nespecially for better investigation of crop and soil variabilities\
    \ and supporting precision agriculture.\nTherefore, a literature search was performed\
    \ to examine if more research in using hyperspectral\nimaging for agricultural\
    \ purposes had been published in recent years. Both Web of Science and\nGoogle\
    \ Scholar were used for conducting the literature search with topics or keywords,\
    \ including\nhyperspectral, imaging, agriculture, or farming, and publication\
    \ over a 30-year time span (1990 to 2020).\nThe searched results were further\
    \ veriﬁed to ensure that each publication falls within the scope of\nhyperspectral\
    \ imaging for agriculture applications. It was found that there was an increasing\
    \ number\nof publications in recent years that used hyperspectral imaging for\
    \ agricultural applications (Figure 1).\nSubstantially more studies have been\
    \ published in the recent decade (e.g., 245 articles published in\n2011–2020)\
    \ than that in the previous one (e.g., 97 published in 2001–2010).\nRemote Sens.\
    \ 2020, 12, 2659\n3 of 44\nRemote Sens. 2020, 12, x FOR PEER REVIEW \n3 of 43\
    \ \n \n \nFigure 1. The number of publications that utilized hyperspectral imaging\
    \ for agriculture applications \n(by May 2020). \nThis review is designed to focus\
    \ on the acquisition, processing, and analysis of hyperspectral \nimagery for\
    \ different agricultural applications. The review is organized in the following\
    \ main aspects: \n(1) Hyperspectral imaging platforms and sensors, (2) methods\
    \ for processing and analyzing \nhyperspectral images, and (3) hyperspectral applications\
    \ in agriculture (Table 1). Regarding imaging \nplatforms, different types, including\
    \ satellites, airplanes, helicopters, fixed-wing UAVs, multi-rotor \nUAVs, and\
    \ close-range platforms (e.g., ground or lab based), have been used. These platforms\
    \ acquire \nimages with different spatial coverage, spatial resolution, temporal\
    \ resolution, operational \ncomplexity, and mission cost. It will be beneficial\
    \ to summarize various platforms in terms of these \nfeatures to support the selection\
    \ of the appropriate one(s) for different monitoring purposes. After \nraw hyperspectral\
    \ imagery is acquired, pre-processing is the step for obtaining accurate spectral\
    \ \ninformation. Several procedures need to be carried out during pre-processing\
    \ (usually implemented \nin a specialized remote sensing software), including\
    \ radiometric calibration, spectral correction, \natmospheric correction, and\
    \ geometric correction. Although these are standard processing steps for \nmost\
    \ satellite imagery, it still can be challenging to perform on many airborne hyperspectral\
    \ images \ndue to different technical issues (e.g., the requirement of high-accuracy\
    \ Global Positioning System \n(GPS) signals for proper geometric correction, the\
    \ measurement of real-time solar radiance for \naccurate spectral correction).\
    \ There are no standardized protocols for all sensors due to the limited \navailability\
    \ of hyperspectral imaging in the past and the fact that the new mini-sized and\
    \ low-cost \nhyperspectral sensors in the market are from different manufacturers\
    \ with varying sensor \nconfigurations. Various approaches have been used in previous\
    \ studies to address these challenges \n[12,19,32,33]. Therefore, it is essential\
    \ to review these approaches to support other researchers for \nmore accurate\
    \ and efficient hyperspectral image processing. After pre-preprocessing, such\
    \ as \ncalibration and correction, spectral information extraction (e.g., band\
    \ selection and dimension \nreduction) can be performed to further improve the\
    \ usability of the hyperspectral image. Techniques \nfor these procedures are\
    \ reviewed in this study. \n \nFigure 1. The number of publications that utilized\
    \ hyperspectral imaging for agriculture applications\n(by May 2020).\nThis review\
    \ is designed to focus on the acquisition, processing, and analysis of hyperspectral\n\
    imagery for diﬀerent agricultural applications. The review is organized in the\
    \ following main aspects:\n(1) Hyperspectral imaging platforms and sensors, (2)\
    \ methods for processing and analyzing\nhyperspectral images, and (3) hyperspectral\
    \ applications in agriculture (Table 1). Regarding imaging\nplatforms, diﬀerent\
    \ types, including satellites, airplanes, helicopters, ﬁxed-wing UAVs, multi-rotor\n\
    UAVs, and close-range platforms (e.g., ground or lab based), have been used. These\
    \ platforms\nacquire images with diﬀerent spatial coverage, spatial resolution,\
    \ temporal resolution, operational\ncomplexity, and mission cost. It will be beneﬁcial\
    \ to summarize various platforms in terms of these\nfeatures to support the selection\
    \ of the appropriate one(s) for diﬀerent monitoring purposes. After raw\nhyperspectral\
    \ imagery is acquired, pre-processing is the step for obtaining accurate spectral\
    \ information.\nSeveral procedures need to be carried out during pre-processing\
    \ (usually implemented in a specialized\nremote sensing software), including radiometric\
    \ calibration, spectral correction, atmospheric correction,\nand geometric correction.\
    \ Although these are standard processing steps for most satellite imagery,\nit\
    \ still can be challenging to perform on many airborne hyperspectral images due\
    \ to diﬀerent technical\nissues (e.g., the requirement of high-accuracy Global\
    \ Positioning System (GPS) signals for proper\ngeometric correction, the measurement\
    \ of real-time solar radiance for accurate spectral correction).\nThere are no\
    \ standardized protocols for all sensors due to the limited availability of hyperspectral\n\
    imaging in the past and the fact that the new mini-sized and low-cost hyperspectral\
    \ sensors in the\nmarket are from diﬀerent manufacturers with varying sensor conﬁgurations.\
    \ Various approaches have\nbeen used in previous studies to address these challenges\
    \ [12,19,32,33]. Therefore, it is essential to\nreview these approaches to support\
    \ other researchers for more accurate and eﬃcient hyperspectral\nimage processing.\
    \ After pre-preprocessing, such as calibration and correction, spectral information\n\
    extraction (e.g., band selection and dimension reduction) can be performed to\
    \ further improve the\nusability of the hyperspectral image. Techniques for these\
    \ procedures are reviewed in this study.\nRemote Sens. 2020, 12, 2659\n4 of 44\n\
    Table 1. Topics reviewed in this article.\nProcedures of Applying\nHyperspectral\
    \ Imagery\nImage Acquisition\nImage Processing and Analysis\nImage Applications\n\
    Review Focuses\nPlatforms:\n- Satellites\n- Airplanes\n- UAVs\n- Close-range platforms\n\
    Sensors:\n- EO-1 Hyperion\n- AVIRIS\n- CASI\n- Headwall Hyperspec etc.\nPre-processing:\n\
    - Geometric and radiometric\ncorrection etc.\n- Dimension reduction\n- Band selection\n\
    Analytical Methods:\n- Empirical regression\n- Radiative transfer modelling\n\
    - Machine learning and\ndeep learning\nSpeciﬁc Applications:\n- Estimating crop\
    \ biochemical and biophysical properties\n- Evaluating crop nutrient status\n\
    - Classifying imagery to identify crop types, growing stages,\nweeds/invasive\
    \ species, stress/disease\n- Retrieving soil moisture, fertility, and other physical\
    \ or\nchemical properties\nRemote Sens. 2020, 12, 2659\n5 of 44\nWith pre-processed\
    \ hyperspectral images, a robust and eﬃcient analytical method is required\nfor\
    \ analyzing the tremendous amount of information contained in the images (e.g.,\
    \ spectral, spatial,\nand textural features) and extracting target properties\
    \ (e.g., crop and soil characteristics). Previous\nstudies have used a suite of\
    \ analytical methods, including empirical regression (e.g., linear regression,\n\
    partial least square regression (PLSR), and multi-variable regression (MLR)),\
    \ radiative transfer\nmodelling (RTM, e.g., PROSPECT and PROSAIL), machine learning\
    \ (e.g., random forest (RF)),\nand deep learning (e.g., convolutional neural network\
    \ (CNN)) [34–37]. These methods have been\ndeveloped based on diﬀerent theories\
    \ and have diﬀerent operational complexity, computation eﬃciency,\nand performance\
    \ accuracy. Therefore, it is essential to review the strengths and limitations\
    \ of these\nmethods and help to choose the appropriate one(s) for speciﬁc research\
    \ purposes. Using hyperspectral\ninformation, researchers have investigated a\
    \ wide range of agricultural features. Some popular ones\ninclude crop water content,\
    \ LAI, chlorophyll and nitrogen contents, pests and disease, plant height,\nphenological\
    \ information, soil moisture, and soil organic matter content [11,38]. It will\
    \ also be valuable\nto review the performances of hyperspectral imaging in these\
    \ studies and further explore the potential\nof this technology for monitoring\
    \ other agricultural features. Lastly, challenges of using hyperspectral\nimaging\
    \ for precision agriculture, together with future research directions, are discussed.\
    \ A few\nprevious review articles have discussed some of these topics to some\
    \ extent [11,38,39]. More details\nand contributions of this review will be discussed\
    \ in each speciﬁc section. Overall, this review aims to\nexamine the main procedures\
    \ in collecting and utilizing hyperspectral images for diﬀerent agricultural\n\
    applications, to further understand the strengths and limitations of hyperspectral\
    \ technology, and to\npromote the faster adoption of this valuable technology\
    \ in precision farming.\n2. Hyperspectral Imaging Platforms and Sensors\nHyperspectral\
    \ sensors can be mounted on different platforms, such as satellites, airplanes,\n\
    UAVs, and close-range platforms, to acquire images with different spatial and\
    \ temporal resolutions.\nPlatforms used in the literature were identified and\
    \ summarized over the publication years, aiming to\nfind, if any, the platforms\
    \ that had been used more frequently in a specific time period, and the results\n\
    are shown in Figure 2. Airplanes have been the most widely used platforms for\
    \ hyperspectral imaging\nin agriculture (Figure 2). Approximately 30 articles\
    \ that used airplanes were published every five years\nstarting from 2001 (e.g.,\
    \ 27 publications in 2001–2005 and 38 in 2006–2010). In comparison, satellite-based\n\
    hyperspectral imaging has been used less frequently; approximately 20 or fewer\
    \ articles were published\nin all five-year periods. UAVs are popular platforms\
    \ for remote sensing and have been widely used in\nthe last decade for hyperspectral\
    \ imaging in agriculture (e.g., more than 20 publications in 2011–2015 and\n2016–2020).\
    \ Close-range platforms have been the most widely used in the last five years\
    \ (i.e., 2016–2020),\nwith 49 publications (Figure 2). The review in this section\
    \ is structured based on different platforms,\nincluding satellites, airplanes,\
    \ UAVs, and close-range platforms. In contrast to previous articles reviewing\n\
    hyperspectral platforms [20,38,39], the review in this section focuses more on\
    \ recent advancements of\nimaging platforms (e.g., UAVs, helicopters, and close\
    \ range) and their applications to precision farming\n(e.g., weed classification,\
    \ fine-scale evaluation of crop health, pests, and disease).\n2.1. Satellite-Based\
    \ Hyperspectral Imaging\nCompared with a large number of satellite-based multispectral\
    \ sensors (e.g., Landsat,\nSPOT, WorldView, QuickBird, Sentinel-2), there are\
    \ signiﬁcantly fewer hyperspectral sensors.\nEO-1 Hyperion, PROBA-CHRIS, and TianGong-1\
    \ [40] are a few examples of the available satellite\nhyperspectral sensors [20].\
    \ EO-1 Hyperion is the most widely used satellite-based hyperspectral\nsensor\
    \ for agriculture (e.g., more than 40 publications). It collects data in the visible,\
    \ near-infrared,\nand shortwave infrared ranges with a spectral resolution of\
    \ 10 nm and a spatial resolution of 30 m.\nMore sensor speciﬁcations of EO-1 Hyperion\
    \ are given in Table 2. The sensor was in operation\nfrom 2000 to 2017, which\
    \ corresponds to the period having more publications using satellite-based\nhyperspectral\
    \ imaging (e.g., 2006 to 2020 in Figure 2). The use of Hyperion data has been\
    \ reported in a\nRemote Sens. 2020, 12, 2659\n6 of 44\nvariety of agricultural\
    \ studies for monitoring diﬀerent crop and soil properties, including detecting\n\
    crop disease [41,42], estimating crop properties (e.g., chlorophyll, LAI, biomass)\
    \ [43–45], assessing crop\nresidues [46,47], classifying crop types [48], and\
    \ investigating soil features [49,50]. A few featured ones\ninclude Wu et al.\
    \ [45], who estimated vegetation chlorophyll content and LAI in a mixed agricultural\n\
    ﬁeld using Hyperion data and evaluated spectral bands that are sensitive to these\
    \ vegetation properties.\nCamacho Velasco et al. [48] used Hyperion hyperspectral\
    \ imagery and diﬀerent classiﬁcation algorithms\n(e.g., spectral angle mapper\
    \ and adaptive coherence estimator) for identifying ﬁve types of crops\n(e.g.,\
    \ oil palm, rubber, grass for grazing, citrus, and sugar cane) in Colombia. Gomez\
    \ et al. [49] predicted\nsoil organic carbon (SOC) using both spectroradiometer\
    \ data and a Hyperion hyperspectral image,\nand they found that using Hyperion\
    \ data resulted in a lower accuracy compared with results derived\nfrom spectroradiometer\
    \ data.\nRemote Sens. 2020, 12, x FOR PEER REVIEW \n6 of 43 \n \nFigure 2. Number\
    \ of publications that used different hyperspectral imaging platforms over time.\
    \ \n2.1. Satellite-Based Hyperspectral Imaging \nCompared with a large number\
    \ of satellite-based multispectral sensors (e.g., Landsat, SPOT, \nWorldView,\
    \ QuickBird, Sentinel-2), there are significantly fewer hyperspectral sensors.\
    \ EO-1 \nHyperion, PROBA-CHRIS, and TianGong-1 [40] are a few examples of the\
    \ available satellite \nhyperspectral sensors [20]. EO-1 Hyperion is the most\
    \ widely used satellite-based hyperspectral \nsensor for agriculture (e.g., more\
    \ than 40 publications). It collects data in the visible, near-infrared, \nand\
    \ shortwave infrared ranges with a spectral resolution of 10 nm and a spatial\
    \ resolution of 30 m. \nMore sensor specifications of EO-1 Hyperion are given\
    \ in Table 2. The sensor was in operation from \n2000 to 2017, which corresponds\
    \ to the period having more publications using satellite-based \nhyperspectral\
    \ imaging (e.g., 2006 to 2020 in Figure 2). The use of Hyperion data has been\
    \ reported in \na variety of agricultural studies for monitoring different crop\
    \ and soil properties, including detecting \ncrop disease [41,42], estimating\
    \ crop properties (e.g., chlorophyll, LAI, biomass) [43–45], assessing \ncrop\
    \ residues [46,47], classifying crop types [48], and investigating soil features\
    \ [49,50]. A few \nfeatured ones include Wu et al. [45], who estimated vegetation\
    \ chlorophyll content and LAI in a \nmixed agricultural field using Hyperion data\
    \ and evaluated spectral bands that are sensitive to these \nvegetation properties.\
    \ Camacho Velasco et al. [48] used Hyperion hyperspectral imagery and \ndifferent\
    \ classification algorithms (e.g., spectral angle mapper and adaptive coherence\
    \ estimator) for \nidentifying five types of crops (e.g., oil palm, rubber, grass\
    \ for grazing, citrus, and sugar cane) in \nColombia. Gomez et al. [49] predicted\
    \ soil organic carbon (SOC) using both spectroradiometer data \nand a Hyperion\
    \ hyperspectral image, and they found that using Hyperion data resulted in a lower\
    \ \naccuracy compared with results derived from spectroradiometer data \nStudies\
    \ have also been conducted to compare the performances of Hyperion hyperspectral\
    \ \nimagery with multispectral imagery for estimating crop properties or classifying\
    \ crop types. For \ninstance, Mariotto et al. [15] compared Hyperion hyperspectral\
    \ imagery with Landsat multispectral \nimagery for the estimation of crop productivity\
    \ and the classification of crop types. The authors \nreported better performances\
    \ of using hyperspectral imagery than using Landsat imagery for both \nresearch\
    \ purposes. Similarly, Bostan et al. [51] compared Hyperion hyperspectral imagery\
    \ with \nLandsat multispectral imagery for crop classification and also found\
    \ that higher classification \naccuracy can be achieved by using hyperspectral\
    \ imagery. \nFigure 2. Number of publications that used diﬀerent hyperspectral\
    \ imaging platforms over time.\nStudies have also been conducted to compare the\
    \ performances of Hyperion hyperspectral imagery\nwith multispectral imagery for\
    \ estimating crop properties or classifying crop types. For instance,\nMariotto\
    \ et al. [15] compared Hyperion hyperspectral imagery with Landsat multispectral\
    \ imagery for\nthe estimation of crop productivity and the classiﬁcation of crop\
    \ types. The authors reported better\nperformances of using hyperspectral imagery\
    \ than using Landsat imagery for both research purposes.\nSimilarly, Bostan et\
    \ al. [51] compared Hyperion hyperspectral imagery with Landsat multispectral\n\
    imagery for crop classiﬁcation and also found that higher classiﬁcation accuracy\
    \ can be achieved by\nusing hyperspectral imagery.\nRemote Sens. 2020, 12, 2659\n\
    7 of 44\nTable 2. Speciﬁcations of commonly used hyperspectral sensors [11,20,52–56].\n\
    Satellite-Based\nAirplane-Based\nUAV-Based *\nSensor\nHyperion\nPROBA-CHRIS\n\
    AVIRIS\nCASI\nAISA\nHyMap\nHeadwall\nHyperspec\nUHD\n185-Fireﬂy\nSpectral range\
    \ (nm)\n357–2576\n415–1050\n400–2500\n380–1050\n(CASI-1500)\n400–970\n(Eagle)\n\
    440–2500\n400–1000\n(VNIR)\n450–950\nNumber of spectral bands\n220\n19\n63\n224\n\
    288\n244\n128\n270 (Nano)\n324 (Micro)\n138\nSpectral Resolution (nm)\n10\n34\n\
    17\n10\n<3.5\n3.3\n15\n6 (Nano) 2.5\n(Micro)\n4\nOperational altitudes (km)\n\
    705 (swath 7.7 km)\n830 (swath 14 km)\n1–20\n<0.15\nSpatial resolution (m)\n30\n\
    17\n36\n1–20\n0.01–0.5\nTemporal resolution (days)\n16–30\n8\nDepends on ﬂight\
    \ operations (hours to days)\nOrganization\nNASA, USA\nESA, UK\nJet Propulsion\n\
    Laboratory,\nUSA\nItres,\nCanada\nSpecim,\nFinland\nIntegrated\nSpectronics,\n\
    Australia\nHeadwall\nPhotonics,\nUSA\nCubert GmbH,\nGermany\nNumber of publications\n\
    41\n9\n18\n22\n20\n12\n9\n6\n* UAV-based sensors typically can also be mounted\
    \ on airplanes for imaging.\nRemote Sens. 2020, 12, 2659\n8 of 44\nPROBA-CHRIS\
    \ is another commonly used satellite-based hyperspectral sensor that was launched\n\
    in 2001.\nSpeciﬁc studies, such as Verger et al. [57], utilized PROBA-CHRIS data\
    \ for retrieving\nLAI, the fraction of vegetation cover (fCover), and the fraction\
    \ of absorbed photosynthetically\nactive radiation (FAPAR) in an agricultural\
    \ ﬁeld. Antony et al. [58] identiﬁed three growth stages\nof wheat using multi-angle\
    \ PROBA-CHRIS images and found the optimal view angles for the\nidentiﬁcation.\
    \ Casa et al. [59] evaluated the performance of airborne Multispectral Infrared\
    \ Visible\nImaging Spectrometer (MIVIS) data and spaceborne PROBA-CHRIS data for\
    \ investigating soil texture,\nand they found that these two data have similar\
    \ performances, although the PROBA-CHRIS data have\na lower spatial resolution.\n\
    There are a few other satellite-based hyperspectral sensors that have not been\
    \ commonly used\nin an agricultural environment. For instance, Hyperspectral Imager\
    \ (HySI) is a hyperspectral sensor\nequipped on the Indian Microsatellite-1 (IMS-1)\
    \ launched in 2008 [60]. It collects spectral signals in the\nrange of 400–950\
    \ nm with a spatial resolution of 550 m at nadir [61]. HySI imagery has been used\
    \ to\nmap diﬀerent agricultural features, such as soil moisture and soil salinity\
    \ [62]. It has also been used for\ncrop classiﬁcation [63]. However, this data\
    \ has not been widely used in precision farming, which is\nprobably due to the\
    \ low spatial resolution and limited data availability. The Hyperspectral Imager\n\
    for the Coastal Ocean (HICO) is another spaceborne hyperspectral sensor that takes\
    \ images with a\nspectral range from 380 to 960 nm at a spatial resolution of\
    \ 90 m [64]. This sensor was mainly designed\nto sample the coastal ocean and\
    \ operated from 2009 to 2015.\nIn recent years, several spaceborne hyperspectral\
    \ sensors have been launched or scheduled for\nlaunching in the next few years.\
    \ For instance, the German Aerospace Center (DLR) Earth Sensing\nImaging Spectrometer\
    \ (DESIS), a hyperspectral sensor mounted on the International Space Station,\n\
    was launched in 2018 [65]. This sensor acquires images in the range from 400 to\
    \ 1000 nm with a spectral\nresolution of 2.5 nm and a spatial resolution of 30\
    \ m. The Hyperspectral Imager Suite (HISUI) is a\nJapanese hyperspectral sensor\
    \ that is also onboard the International Space Station [66]. It was launched\n\
    in 2019 and collects data in the range from 400 to 2500 nm with a spatial resolution\
    \ of 20 m and a\ntemporal resolution of 2 to 60 days [20]. Hyperspectral Precursor\
    \ and Application Mission (PRISMA)\nis an Italian hyperspectral mission with the\
    \ sensor launched in March 2019. Its spectral resolution is\n12 nm in the range\
    \ of 400-2500 nm (~250 bands in visible to shortwave infrared). Its hyperspectral\n\
    imagery has a spatial resolution of 30 and 5 m for the panchromatic band [67].\
    \ The Environmental\nMapping and Analysis Program (EnMAP) is a German hyperspectral\
    \ satellite mission that is still in\nthe development and production phase [68].\
    \ The EnMAP sensor will collect data from the visible to\nthe shortwave infrared\
    \ range with a spatial resolution of 30 m. It is planned to be launched in 2020.\n\
    The Spaceborne Hyperspectral Applicative Land and Ocean Mission (SHALOM) is a\
    \ joint mission by\nIsraeli and Italian space agencies, and the satellite is scheduled\
    \ to be launched in 2022 [69]. This sensor\nwill collect hyperspectral images\
    \ with a spatial resolution of 10 m in the spectral range of 400–2500 nm\nand\
    \ panchromatic images with a spatial resolution of 2.5 m [70]. HyspIRI is another\
    \ hyperspectral\nmission that is also at the study stage [71]. This sensor will\
    \ collect data in the 380 to 2500 nm range\nwith an interval of 10 nm and a spatial\
    \ resolution of 60 m.\nAlthough the actual PRISMA, EnMAP, and HyspIRI data are\
    \ not yet available, researchers\nhave simulated the images using other data and\
    \ tested the performance of the simulated images for\ninvestigating diﬀerent vegetation\
    \ and soil features. For instance, Malec et al. [72], Siegmann et al. [73],\n\
    and Locherer et al. [74] simulated EnMAP imagery using diﬀerent airborne or spaceborne\
    \ images and\napplied the simulated images for investigating diﬀerent crop and\
    \ soil properties. Bachmann et al. [75]\nproduced an image using the EnMAP’s end-to-end\
    \ simulation tool and examined the uncertainties\nassociated with spectral and\
    \ radiometric calibration. Castaldi et al. [76] simulated data of four\ncurrent\
    \ (EO-1 ALI and Hyperion, Landsat 8 Operational Land Imager (OLI), Sentinel-2\
    \ MultiSpectral\nInstrument (MSI)) and three forthcoming (EnMAP, PRISMA, and HyspIRI)\
    \ sensors using a soil spectral\nlibrary and compared their performance for estimating\
    \ soil properties. Castaldi et al. [77] used PRISMA\nRemote Sens. 2020, 12, 2659\n\
    9 of 44\ndata that were simulated with lab-measured spectral data for estimating\
    \ clay content and attempted to\nreduce the inﬂuence of soil moisture on the estimation\
    \ of clay.\nPrevious studies have conﬁrmed the good performance of satellite-based\
    \ hyperspectral sensors for\nstudying agricultural features; however, several\
    \ factors could potentially aﬀect the broad applications\nof these data in precision\
    \ farming, including the spatial resolution, temporal resolution, and data quality.\n\
    The detection and monitoring of many agricultural features, such as crop disease,\
    \ pest infestation,\nand nutrient status, require high spatial and temporal resolution.\n\
    Most of the satellite-based\nhyperspectral sensors have medium spatial resolutions,\
    \ such as 17 or 36 m for PROBA-CHRIS;\n30 m for Hyperion, PRISMA, and EnMAP, DESIS;\
    \ and 60 m for HyspIRI. Previous studies have\nindicated that such spatial resolutions\
    \ are not suﬃcient for precision farming applications [20,49].\nTo overcome such\
    \ limitations, researchers have attempted to pansharpen hyperspectral images,\
    \ aiming\nto improve spatial resolution [73,78–80]. Loncan et al. [81] also reviewed\
    \ diﬀerent pansharpening\nmethods for generating high-spatial resolution hyperspectral\
    \ images.\nTemporal resolution is another factor that could potentially limit\
    \ the applications of satellite-based\nhyperspectral images to precision agriculture.\
    \ Most of the satellite-based sensors have a long revisit\ncycle (e.g., typically\
    \ around two weeks), and thus early signals of crop stress (e.g., disease and\n\
    pest) may be missed. This limitation can be further aggravated by unfavorable\
    \ weather conditions\n(e.g., cloud contamination). Lastly, low data quality is\
    \ also an issue that can aﬀect the performance of\nsatellite-based hyperspectral\
    \ imaging for investigating agricultural features. A low signal-to-noise ratio\n\
    is a well-known issue of Hyperion data (e.g., in the shortwave infrared (SWIR)\
    \ range), which has aﬀected\nthe accuracy of retrieving diﬀerent agricultural\
    \ features [20]. For instance, Asner and Heidebrecht [82],\nGomez et al. [49],\
    \ and Weng et al. [83] found that the low signal-to-noise ratio inﬂuenced the\
    \ accuracies\nof estimating non-photosynthetic vegetation and soil cover, soil\
    \ organic matter, and soil salinity,\nrespectively. Future satellite-based hyperspectral\
    \ missions are expected to solve the data quality issue.\n2.2. Airplane-Based\
    \ Hyperspectral Imaging\nAirborne hyperspectral imaging has been widely used to\
    \ collect hyperspectral imagery for\ndiﬀerent monitoring purposes (e.g., for agriculture\
    \ or forestry). The ﬁrst hyperspectral sensor was an\nairborne visible/infrared\
    \ imaging spectrometer (AVIRIS) that was developed and utilized in 1987 [84].\n\
    It collects spectral signals in 224 bands in the visible to SWIR range (Table\
    \ 2). Researchers have applied\nAVIRIS data to help understand a wide range of\
    \ agricultural features, such as investigating vegetation\nproperties (e.g., yield,\
    \ LAI, chlorophyll, and water content) [85–88], analyzing soil properties [89],\n\
    evaluating crop health or identifying pest infestation [90–92], and mapping crop\
    \ area or agricultural\ntillage practices [93,94].\nBesides AVIRIS, the Compact\
    \ Airborne Spectrographic Imager (CASI), Hyperspectral Mapper\n(HyMap), and AISA\
    \ Eagle are also widely used airborne hyperspectral sensors (Table 2). For instance,\n\
    CASI images have been used for estimating crop chlorophyll content [95], investigating\
    \ crop cover\nfraction [96], classifying weeds [97], and delineating management\
    \ zones [2]. The HyMap imagery\nhas been applied to examining crop biophysical\
    \ and biochemical variables (e.g., LAI, chlorophyll and\nwater content) [98–100],\
    \ detecting plant stress signals [101], and investigating the spatial patterns\
    \ of\nSOC [102]. Regarding AISA Eagle imagery, Ryu et al. [35] and Cilia et al.\
    \ [103] used this data for\nestimating crop nitrogen content, and Ambrus et al.\
    \ [104] used it for estimating biomass.\nSeveral other airborne hyperspectral\
    \ sensors have also been used in previous studies. For instance,\nAVIS images\
    \ were used for investigating a range of vegetation characteristics (e.g., biomass\
    \ and\nchlorophyll) [105], Probe-1 hyperspectral images were used for investigating\
    \ crop residues [106],\nRDACS-H4 hyperspectral images were used for detecting\
    \ crop disease [34], AHS-160 hyperspectral\nsensor was used for mapping SOC [107],\
    \ the SWIR Hyper Spectral Imaging (HSI) sensor was used for\nestimating soil moisture\
    \ [108], the Pushbroom Hyperspectral Imager (PHI) was used for estimating\nwinter\
    \ wheat LAI [109], and airborne prism experiment (APEX) data were used for studying\
    \ the\nrelationship between SOC in croplands and the spectral signals [110].\n\
    Remote Sens. 2020, 12, 2659\n10 of 44\nMost of the aforementioned airborne hyperspectral\
    \ images have been acquired by airplanes at\nmedium to high altitude (e.g., 1–4\
    \ km altitude for CASI, 20 km for AVIRIS), and the acquired images\ngenerally\
    \ having high to medium spatial resolution, such as 4 m for CASI imagery, 5 m\
    \ for HyMap,\nand 20 m for AVIRIS [111–113]. Such spatial resolutions are appropriate\
    \ for mapping many crop and\nsoil features. However, image acquisition usually\
    \ needs to be scheduled months or even years in\nadvance, and ﬂight missions are\
    \ expensive [19]. Furthermore, for some speciﬁc applications, such as\ninvestigating\
    \ species-level or community-level features (e.g., identiﬁcation of weeds or early\
    \ signal\nof crop disease), images with very high spatial resolutions (e.g., sub-meter)\
    \ are preferred [114,115].\nIn addition, due to the unstable nature of airplanes\
    \ as imaging platforms, a gimbal or high-accuracy\ninertial measurement unit (IMU)\
    \ will be required to compensate for the orientation change of the\nairplanes\
    \ or recording the orientation information for subsequent image correction, respectively.\n\
    These factors limited the full application of airborne hyperspectral imaging in\
    \ precision agriculture.\nManned helicopters have also been used as platforms\
    \ for hyperspectral imaging and investigation\nof vegetation features [27,116].\
    \ Helicopters have more ﬂexible ﬂight heights (e.g., 100 m–2 km) than\nairplanes\
    \ and are capable of acquiring high-spatial-resolution images (e.g., sub-meter)\
    \ over large\nareas. An aviation company with a manned helicopter is generally\
    \ needed for the imaging task,\nwhich requires extra funding support and far advanced\
    \ pre-scheduling.\n2.3. UAV-Based Hyperspectral Imaging\nUAV has become a popular\
    \ platform in recent years for remote sensing data acquisition,\nespecially for\
    \ multispectral imaging using digital cameras or multispectral sensors. With the\
    \ increased\navailability of lightweight hyperspectral sensors, researchers have\
    \ experimented on mounting these\nsensors on UAVs to acquire high-spatial-resolution\
    \ hyperspectral imagery [19,117]. Diﬀerent types\nof UAVs, including multi-rotors,\
    \ helicopters, and ﬁxed wings, have been utilized in previous studies\n(Figure\
    \ 3). Compared with manned airplanes and helicopters, UAVs are capable of acquiring\
    \ high-\nspatial-resolution images with a much lower cost and have high ﬂexibility\
    \ in terms of scheduling a\nﬂight mission [118]. Several speciﬁc agricultural\
    \ applications of UAV-based hyperspectral imaging are\nsummarized in Table 3.\n\
    Remote Sens. 2020, 12, x FOR PEER REVIEW \n10 of 43 \nand 20 m for AVIRIS [111–113].\
    \ Such spatial resolutions are appropriate for mapping many crop and \nsoil features.\
    \ However, image acquisition usually needs to be scheduled months or even years\
    \ in \nadvance, and flight missions are expensive [19]. Furthermore, for some\
    \ specific applications, such as \ninvestigating species-level or community-level\
    \ features (e.g., identification of weeds or early signal \nof crop disease),\
    \ images with very high spatial resolutions (e.g., sub-meter) are preferred [114,115].\
    \ \nIn addition, due to the unstable nature of airplanes as imaging platforms,\
    \ a gimbal or high-accuracy \ninertial measurement unit (IMU) will be required\
    \ to compensate for the orientation change of the \nairplanes or recording the\
    \ orientation information for subsequent image correction, respectively. \nThese\
    \ factors limited the full application of airborne hyperspectral imaging in precision\
    \ agriculture. \nManned helicopters have also been used as platforms for hyperspectral\
    \ imaging and investigation of \nvegetation features [27,116]. Helicopters have\
    \ more flexible flight heights (e.g., 100 m–2 km) than \nairplanes and are capable\
    \ of acquiring high-spatial-resolution images (e.g., sub-meter) over large \n\
    areas. An aviation company with a manned helicopter is generally needed for the\
    \ imaging task, \nwhich requires extra funding support and far advanced pre-scheduling.\
    \  \n2.3. UAV-Based Hyperspectral Imaging \nUAV has become a popular platform\
    \ in recent years for remote sensing data acquisition, \nespecially for multispectral\
    \ imaging using digital cameras or multispectral sensors. With the \nincreased\
    \ availability of lightweight hyperspectral sensors, researchers have experimented\
    \ on \nmounting these sensors on UAVs to acquire high-spatial-resolution hyperspectral\
    \ imagery [19,117]. \nDifferent types of UAVs, including multi-rotors, helicopters,\
    \ and fixed wings, have been utilized in \nprevious studies (Figure 3). Compared\
    \ with manned airplanes and helicopters, UAVs are capable of \nacquiring high-spatial-resolution\
    \ images with a much lower cost and have high flexibility in terms of \nscheduling\
    \ a flight mission [118]. Several specific agricultural applications of UAV-based\
    \ \nhyperspectral imaging are summarized in Table 3. \n \nFigure 3. Hyperspectral\
    \ UAV systems used in previous agricultural studies. Figures were reproduced \n\
    with permission from the corresponding publishers: (a) MDPI [119], (b) MDPI [120],\
    \ (c) MDPI [121], \nand (d) SPIE [122]. \nTable 3. Example applications of UAV-based\
    \ hyperspectral imaging in agriculture. \nApplications \nPrevious \nStudies \n\
    Research Focuses \nEstimating LAI \nand chlorophyll \nYu et al. [37] \nEstimated\
    \ a range of vegetation phenotyping variables \n(e.g., LAI and leaf chlorophyll)\
    \ using UAV-based \nhyperspectral imagery and radiative transfer modelling. \n\
    (a) \n(b) \n(d) \n(c) \nFigure 3. Hyperspectral UAV systems used in previous agricultural\
    \ studies. Figures were reproduced\nwith permission from the corresponding publishers:\
    \ (a) MDPI [119], (b) MDPI [120], (c) MDPI [121],\nand (d) SPIE [122].\nRemote\
    \ Sens. 2020, 12, 2659\n11 of 44\nTable 3. Example applications of UAV-based hyperspectral\
    \ imaging in agriculture.\nApplications\nPrevious Studies\nResearch Focuses\n\
    Estimating LAI and\nchlorophyll\nYu et al. [37]\nEstimated a range of vegetation\
    \ phenotyping variables\n(e.g., LAI and leaf chlorophyll) using UAV-based\nhyperspectral\
    \ imagery and radiative transfer modelling.\nEstimating biomass\nHonkavaara et\
    \ al. [123]\nMounted a hyperspectral sensor and a consumer-level\ncamera on a\
    \ UAV for estimating biomass in a wheat and\na barley ﬁeld.\nYue et al. [124]\n\
    Utilized UAV-based hyperspectral images for estimating\nwinter wheat above-ground\
    \ biomass.\nEstimating nitrogen\ncontent\nPölönen et al. [125]\nUsed lightweight\
    \ UAVs for collecting hyperspectral\nimages and estimated crop biomass and nitrogen\
    \ content.\nKaivosoja et al. [126]\nApplied UAV-based hyperspectral imagery to\
    \ investigate\nbiomass and nitrogen contents in a wheat ﬁeld.\nAkhtman et al.\
    \ [127]\nUtilized UAV-based hyperspectral images for estimating\nnitrogen content\
    \ and phytomass in corn and wheat ﬁelds\nand monitored temporal variations of\
    \ these properties.\nEstimating water\ncontent\nIzzo et al. [128]\nEvaluated water\
    \ content in the commercial vineyard\nusing UAV-based hyperspectral images and\
    \ determined\nwavelengths sensitive to canopy water content.\nClassifying weeds\n\
    Scherrer et al. [129]\nClassiﬁed herbicide-resistant weeds in diﬀerent crop\n\
    ﬁelds (e.g., barley, corn, and dry pea) using both ground-\nand UAV-based hyperspectral\
    \ imagery.\nDetecting disease\nBohnenkamp et al. [119]\nUsed both ground- and\
    \ UAV-based hyperspectral images\nfor detecting yellow rust in wheat.\nVarious\
    \ lightweight hyperspectral sensors have been developed in recent years and can\
    \ be\nmounted on UAVs. Examples of sensors include the widely-used Headwall Micro-\
    \ and Nano-Hyperspec\nVNIR [12,13,26,128], UHD 185-Fireﬂy [53,130], the PIKA II\
    \ sensor [19,32], and the HySpex VNIR [25,131].\nThese hyperspectral sensors contain\
    \ more than 100 bands in the visible-near infrared spectral range\n(Table 2).\
    \ These sensors are small and compact (1–2 kg), thus they can be deployed quickly\
    \ on various\nmanned or unmanned remote sensing platforms. Previous studies conducted\
    \ by Adão et al. [11] and\nLodhi et al. [52] also compared and summarized various\
    \ lightweight hyperspectral sensors.\nA large number of factors need to be considered\
    \ in the application of UAV-based hyperspectral\nimaging, ranging from sensor\
    \ setup and data collection, to image processing. Saari et al. [122] tested\n\
    the feasibility of a UAV-based hyperspectral imaging system for agricultural and\
    \ forest applications\nand discussed several challenges regarding the imaging\
    \ technology (e.g., hardware requirements\nand system settings).\nAasen et al.\
    \ [132] focused on the calibration of images collected with a\nframe-based sensor\
    \ and discussed several challenges related to the use of UAV-based hyperspectral\n\
    imaging for vegetation and crop investigation (e.g., the payload of UAV, signal-to-noise\
    \ ratio, and\nspectral calibration). Habib et al. [120] attempted to perform orthorectiﬁcation\
    \ of UAV-acquired\npushbroom-based hyperspectral imagery with frame-based RGB\
    \ images over an agricultural ﬁeld.\nAdão et al. [11] reviewed applications of\
    \ UAV-based hyperspectral imaging in agriculture and forestry\nand listed several\
    \ hyperspectral sensors that can be mounted on UAVs. The authors also discussed\n\
    several challenges in collecting and analyzing UAV-based hyperspectral imagery,\
    \ such as radiometric\nnoise, the low quality of UAV georeferencing, and a low\
    \ signal-to-noise ratio.\nUAV-based hyperspectral imaging has become more popular\
    \ in recent years; therefore, it is critical to\nreview its strengths and limitations.\
    \ To explore more features of this technology, this section of the review\nis\
    \ not limited to agricultural applications alone. Different types of UAVs have\
    \ been used as hyperspectral\nimaging platforms, with the two most widely used\
    \ as multi-rotors [130,133,134] and ﬁxed-wing\nplanes [33,120,135]. Slow ﬂights\
    \ at low altitudes are preferred to achieve high-spatial-resolution\nhyperspectral\
    \ imagery with a high signal-to-noise ratio. Thus, a multi-rotor is more competitive\
    \ than\nRemote Sens. 2020, 12, 2659\n12 of 44\nﬁxed-wing planes for hyperspectral\
    \ imaging in terms of ﬂight operation. Speciﬁcally, the multi-rotor\nallows for\
    \ a low ﬂight altitude, ﬂexible ﬂight speed, and vertical takeoﬀ and landing,\
    \ while the\nﬁxed wing requires a minimum ﬂight altitude, speed, and, sometimes,\
    \ accessories for takeoﬀ and\nlanding (e.g., runway, launcher, and parachute).\
    \ A hyperspectral imaging system, which consists\nof a hyperspectral sensor, a\
    \ data processing unit, a GPS, and an IMU, has a considerable weight\n(e.g., 1–3\
    \ kg), thus bringing challenges to the payload capacity of the UAV system and\
    \ its battery\nendurance. The multi-rotors are generally powered by high-performance\
    \ batteries (e.g., LiPo), and most\nhave a short endurance (e.g., less than 20\
    \ min). The endurance can be as short as 3 min [12]. In contrast,\nmany ﬁxed-wing\
    \ UAVs are powered by fuel, thus having a much longer endurance (e.g., 1–10 h)\
    \ [19,135].\nHowever, these ﬁxed-wing planes are mostly large and heavy (e.g.,\
    \ a 5 m wingspan and 14 kg take-oﬀ\nweight) [135], and thus bring challenges to\
    \ the ﬂight operation. Using UAV, researchers need to consider\nthe UAV SWaP (size,\
    \ weight, and power), geographical coverage, time aloft, altitude, and other variables.\n\
    In addition to the challenges in building a UAV system and performing ﬂight operations,\
    \ researchers\nlikely need to apply for ﬂight permission from an aviation authority\
    \ (e.g., Special Flight Operations\nCertiﬁcate (SFOC) from Transport Canada),\
    \ and purchase suitable UAV ﬂight insurance [136]. UAV size\nand weight are essential\
    \ parameters to consider in these processes. Furthermore, the UAVs are required\n\
    to be visible during ﬂight missions, so that the pilot can maintain constant visual\
    \ contact with the\naircraft. This could create a major challenge when ﬂying over\
    \ a large area, a hilly area, or an area\nwith forests.\n2.4. Close-Range (Ground-\
    \ or Lab-Based) Hyperspectral Imaging\nClose-range hyperspectral imaging, including\
    \ ground (Figure 4a–c) or lab based (Figure 4d,e),\nis an emerging technology\
    \ in recent years, and it is capable of acquiring super-high-spatial-resolution\n\
    (e.g., cm or sub-cm level) hyperspectral imagery [137–139]. Therefore, this imaging\
    \ technology can\nbe used for investigating ﬁne-scale (e.g., leaf and canopy level)\
    \ vegetation features and thus greatly\nsupport the investigation of crop growing\
    \ status and detection of early signs of crop stress (e.g., disease,\nweeds, or\
    \ nutrition deﬁciency). Sensors are mounted on moving or static platforms (e.g.,\
    \ linear\nstages, scaﬀolds, or trucks) that can be deployed indoors or outdoors\
    \ for collecting images. Lamps\n(e.g., halogen lamp) or the sun are used as light\
    \ sources in these platforms, respectively.\nResearchers have utilized diﬀerent\
    \ types of platforms and hyperspectral sensors for collecting\nsuper-high-spatial-resolution\
    \ hyperspectral imagery to study diﬀerent agricultural features, as shown\nin\
    \ Table 4.\nTable 4. Example applications of close-range hyperspectral imaging\
    \ in previous studies.\nApplications\nPrevious Studies\nResearch Focuses\nInvestigating\n\
    biochemical\ncomponents\nFeng et al. [140]\nDesigned a hyperspectral imaging system\
    \ that consists of a\nHeadwall hyperspectral camera, a halogen lamp, a computer,\n\
    and a translation stage and used this system for taking images of\nrice leaves\
    \ to study leaf chlorophyll distribution.\nMohd Asaari et al. [141]\nMounted a\
    \ visible and near-infrared HIS camera in a\nhigh-throughput plant phenotyping\
    \ platform for evaluating\nplant water status and detecting early stage signs\
    \ of plant\ndrought stress.\nZhu et al. [142]\nInstalled a hyperspectral camera\
    \ and halogen lamp on a moving\nstage and used this imaging system for estimating\
    \ sugar and\nnitrogen contents in tomato leaves.\nDetecting crop\ndisease\nMorel\
    \ et al. [143]\nUsed a HySpex hyperspectral camera installed in a close-range\n\
    imaging system for investigating black leaf streak disease in\nbanana leaves.\n\
    Nagasubramanian et al. [144]\nIntegrated a Pika XC hyperspectral line imaging\
    \ scanner and\nhalogen illumination lamps for taking images of soybeans and\n\
    monitoring fungal disease.\nRemote Sens. 2020, 12, 2659\n13 of 44\nTable 4. Cont.\n\
    Applications\nPrevious Studies\nResearch Focuses\nIdentifying\nvegetation\nspecies\
    \ or\nweeds\nEddy et al. [139]\nMounted a hyperspectral sensor on a boom arm that\
    \ was\ninstalled on a truck for acquiring images at 1 m above the\nground and\
    \ applied the hyperspectral images to classifying\nweeds in diﬀerent crop ﬁelds.\n\
    Lopatin et al. [145]\nInstalled an AISA Eagle imaging spectrometer on a scaﬀold\
    \ at\nthe height of 2.5 m above ground, aiming to collect hyperspectral\nimagery\
    \ in a grassland area for classifying grassland species.\nPhenotyping\nBehmann\
    \ et al. [146]\nUtilized hyperspectral cameras and a close-range 3D laser\nscanner\
    \ that were mounted on a linear stage for collecting\nhyperspectral images and\
    \ 3D point models, respectively, and\nused these two datasets for generating hyperspectral\
    \ 3D plant\nmodels for better monitoring plant phenotyping features.\nMonitoring\
    \ soil\nproperties\nAntonucci et al. [147]\nAttempted to estimate copper concentration\
    \ in contaminated\nsoils using hyperspectral images that were acquired from a\n\
    lab-based spectral scanner.\nMalmir et al. [137]\nCollected close-range soil images\
    \ using Pika XC2 hyperspectral\ncamera that was mounted on a linear stage and\
    \ used the\nhyperspectral imagery for investigating soil macro- and\nmicro-elements.\n\
    Overall, the close-range hyperspectral imaging platform is capable of acquiring\
    \ super-high-\nspatial-resolution hyperspectral imagery that is critical for investigating\
    \ ﬁne-scale crop or soil features.\nThese features provide detailed information\
    \ about the plant’s biophysical and biochemical processes\nand how plants respond\
    \ to environmental stresses and diseases. However, the image collection and\n\
    processing also suﬀer from diﬀerent issues, such as uninformative variability\
    \ caused by the interaction\nof light with the plant structure (i.e., illumination\
    \ eﬀects), inﬂuences of shadows, and expanding\napplications of the platform to\
    \ a large scale [141,146]. Further research in these areas is warranted.\nRemote\
    \ Sens. 2020, 12, x FOR PEER REVIEW \n13 of 43 \n \nIdentifying \nvegetation \n\
    species or weeds \nEddy et al. [139] \nMounted a hyperspectral sensor on a boom\
    \ arm that \nwas installed on a truck for acquiring images at 1 m \nabove the\
    \ ground and applied the hyperspectral \nimages to classifying weeds in different\
    \ crop fields.  \nLopatin et al. [145] \nInstalled an AISA Eagle imaging spectrometer\
    \ on a \nscaffold at the height of 2.5 m above ground, aiming to \ncollect hyperspectral\
    \ imagery in a grassland area for \nclassifying grassland species. \nPhenotyping\
    \ \nBehmann et al. \n[146] \nUtilized hyperspectral cameras and a close-range\
    \ 3D \nlaser scanner that were mounted on a linear stage for \ncollecting hyperspectral\
    \ images and 3D point models, \nrespectively, and used these two datasets for\
    \ \ngenerating hyperspectral 3D plant models for better \nmonitoring plant phenotyping\
    \ features. \nMonitoring soil \nproperties \nAntonucci et al. \n[147] \nAttempted\
    \ to estimate copper concentration in \ncontaminated soils using hyperspectral\
    \ images that \nwere acquired from a lab-based spectral scanner.  \nMalmir et\
    \ al. [137] \nCollected close-range soil images using Pika XC2 \nhyperspectral\
    \ camera that was mounted on a linear \nstage and used the hyperspectral imagery\
    \ for \ninvestigating soil macro- and micro-elements. \nOverall, the close-range\
    \ hyperspectral imaging platform is capable of acquiring super-high-\nspatial-resolution\
    \ hyperspectral imagery that is critical for investigating fine-scale crop or\
    \ soil \nfeatures. These features provide detailed information about the plant’s\
    \ biophysical and biochemical \nprocesses and how plants respond to environmental\
    \ stresses and diseases. However, the image \ncollection and processing also suffer\
    \ from different issues, such as uninformative variability caused \nby the interaction\
    \ of light with the plant structure (i.e., illumination effects), influences of\
    \ shadows, \nand expanding applications of the platform to a large scale [141,146].\
    \ Further research in these areas \nis warranted. \n \nFigure 4. Close-range imaging\
    \ platforms used in previous studies. Figures were reproduced with \npermission\
    \ from corresponding publishers: (a) American Society for Photogrammetry and Remote\
    \ \nSensing (ASPRS), Bethesda, Maryland, asprs.org [139]; (b) SPIE [148]; (c)\
    \ Elsevier [138]; (d) Springer \nNature [144]; (e) Elsevier [149]. \nIn summary,\
    \ different hyperspectral imaging platforms, including satellites, airplanes,\
    \ \nhelicopters, UAVs, and close-range, have different advantages and disadvantages\
    \ for applications in \nprecision agriculture. Detailed comparisons of these platforms\
    \ for agricultural applications are \nshown in Table 5. In brief, satellite-based\
    \ systems provide images covering large areas but suffer from \n(a) \n(b) \n(c)\
    \ \n(d) \n(e) \nFigure 4. Close-range imaging platforms used in previous studies.\
    \ Figures were reproduced with\npermission from corresponding publishers: (a)\
    \ American Society for Photogrammetry and Remote\nSensing (ASPRS), Bethesda, Maryland,\
    \ asprs.org [139]; (b) SPIE [148]; (c) Elsevier [138]; (d) Springer\nNature [144];\
    \ (e) Elsevier [149].\nIn summary, diﬀerent hyperspectral imaging platforms, including\
    \ satellites, airplanes, helicopters,\nUAVs, and close-range, have diﬀerent advantages\
    \ and disadvantages for applications in precision\nagriculture. Detailed comparisons\
    \ of these platforms for agricultural applications are shown in\nTable 5. In brief,\
    \ satellite-based systems provide images covering large areas but suﬀer from medium\n\
    spatial resolution and limited data availability (e.g., a limited number of operating\
    \ sensors and long\nRemote Sens. 2020, 12, 2659\n14 of 44\nrevisit time). Airplane-\
    \ and helicopter-based imaging platforms acquire data with suitable spatial\n\
    coverage and resolution for most of the agricultural applications. However, they\
    \ are limited by\na high mission cost and scheduling challenges and thus are not\
    \ suitable for repeated monitoring.\nUAV-based systems are capable of acquiring\
    \ high-spatial resolution images repeatedly and have high\nﬂexibility. However,\
    \ they can only cover a small area due to the limited battery endurance and aviation\n\
    regulations. The close-range imaging systems are capable of obtaining super-high-spatial-resolution\n\
    images, but they can only be used at leaf or canopy levels. Therefore, the following\
    \ factors should be\ntaken into consideration when selecting a platform for a\
    \ speciﬁc research project: spatial resolution\nneeded for the study, ﬂight area\
    \ and ﬂight endurance, weight of the imaging system, platform payload\ncapacity,\
    \ ﬂight safety and regulations, operation ﬂexibility, and cost.\nTable 5. Comparison\
    \ of hyperspectral imaging platforms.\nSatellites\nAirplanes\nHelicopters\nFixed-Wing\n\
    UAVs\nMulti-Rotor\nUAVs\nClose-Range\nPlatforms\nExample\nPhotos\nRemote Sens.\
    \ 2020, 12, x FOR PEER REVIEW \n14 of 43 \n \nmedium spatial resolution and limited\
    \ data availability (e.g., a limited number of operating sensors \nand long revisit\
    \ time). Airplane- and helicopter-based imaging platforms acquire data with suitable\
    \ \nspatial coverage and resolution for most of the agricultural applications.\
    \ However, they are limited \nby a high mission cost and scheduling challenges\
    \ and thus are not suitable for repeated monitoring. \nUAV-based systems are capable\
    \ of acquiring high-spatial resolution images repeatedly and have \nhigh flexibility.\
    \ However, they can only cover a small area due to the limited battery endurance\
    \ and \naviation regulations. The close-range imaging systems are capable of obtaining\
    \ super-high-spatial-\nresolution images, but they can only be used at leaf or\
    \ canopy levels. Therefore, the following factors \nshould be taken into consideration\
    \ when selecting a platform for a specific research project: spatial \nresolution\
    \ needed for the study, flight area and flight endurance, weight of the imaging\
    \ system, \nplatform payload capacity, flight safety and regulations, operation\
    \ flexibility, and cost. \nTable 5. Comparison of hyperspectral imaging platforms.\
    \ \n \nSatellites \nAirplanes \nHelicopters \nFixed-\nWing \nUAVs \nMulti-\nRotor\
    \ \nUAVs \nClose-\nRange \nPlatforms \nExample \nPhotos \n \n(Photo: \nSwales\
    \ \nAerospace) \n \n \n \n \n(Photo: \nASPRS) \nOperational \nAltitudes \n400–700\
    \ \nkm \n1–20 km \n100 m–2 km \n<150 m \n<10 m \nSpatial \nCoverage \nVery large\
    \ \nMedium—\nlarge \nMedium \nSmall—\nmedium \nSmall \nVery small \ne.g., one\
    \ \nHyperion \nscene \ncovers 42 \nkm × 7.7 \nkm \nA 10-min flight/operation covers\
    \ \n~100 km2 \n~10 km2 \n~5 km2 \n~0.5 km2 \n~0.005 km2 \nSpatial \nResolution\
    \ \n20–60 m \n1–20 m \n0.1–1 m \n0.01–0.5 m \n0.0001–0.01 \nm \nTemporal \nResolution\
    \ \nDays to \nweeks \nDepends on flight operations (hours to days) \nFlexibility\
    \ \nLow (e.g., \nfixed \nrepeating \ncycles) \nMedium (e.g., limited by the \n\
    availability of aviation \ncompany) \nHigh \nOperational \nComplexity \nLow (Final\
    \ \ndata \nprovided \nto users) \nMedium (Depends on who \noperates the sensor,\
    \ users or \ndata vendors) \nHigh (users typically operate sensors \nand need\
    \ to set up hardware and \nsoftware properly) \nApplicable \nScales \nRegional—\n\
    global \nLandscape—regional \nCanopy—landscape \nLeaf—\ncanopy \nMajor \nLimiting\
    \ \nFactors \nWeather \n(e.g., rain \nand \nclouds) \nUnfavorable flight \nheight/speed,\
    \ unstable \nillumination conditions \nShort battery \nendurance (e.g., 10–30\
    \ \nmin), flight \nregulations \nPlatform \ndesign and \noperation \n(Photo: Swales\n\
    Aerospace)\nRemote Sens. 2020, 12, x FOR PEER REVIEW \n14 of 43 \n \nmedium spatial\
    \ resolution and limited data availability (e.g., a limited number of operating\
    \ sensors \nand long revisit time). Airplane- and helicopter-based imaging platforms\
    \ acquire data with suitable \nspatial coverage and resolution for most of the\
    \ agricultural applications. However, they are limited \nby a high mission cost\
    \ and scheduling challenges and thus are not suitable for repeated monitoring.\
    \ \nUAV-based systems are capable of acquiring high-spatial resolution images\
    \ repeatedly and have \nhigh flexibility. However, they can only cover a small\
    \ area due to the limited battery endurance and \naviation regulations. The close-range\
    \ imaging systems are capable of obtaining super-high-spatial-\nresolution images,\
    \ but they can only be used at leaf or canopy levels. Therefore, the following\
    \ factors \nshould be taken into consideration when selecting a platform for a\
    \ specific research project: spatial \nresolution needed for the study, flight\
    \ area and flight endurance, weight of the imaging system, \nplatform payload\
    \ capacity, flight safety and regulations, operation flexibility, and cost. \n\
    Table 5. Comparison of hyperspectral imaging platforms. \n \nSatellites \nAirplanes\
    \ \nHelicopters \nFixed-\nWing \nUAVs \nMulti-\nRotor \nUAVs \nClose-\nRange \n\
    Platforms \nExample \nPhotos \n \n(Photo: \nSwales \nAerospace) \n \n \n \n \n\
    (Photo: \nASPRS) \nOperational \nAltitudes \n400–700 \nkm \n1–20 km \n100 m–2\
    \ km \n<150 m \n<10 m \nSpatial \nCoverage \nVery large \nMedium—\nlarge \nMedium\
    \ \nSmall—\nmedium \nSmall \nVery small \ne.g., one \nHyperion \nscene \ncovers\
    \ 42 \nkm × 7.7 \nkm \nA 10-min flight/operation covers \n~100 km2 \n~10 km2 \n\
    ~5 km2 \n~0.5 km2 \n~0.005 km2 \nSpatial \nResolution \n20–60 m \n1–20 m \n0.1–1\
    \ m \n0.01–0.5 m \n0.0001–0.01 \nm \nTemporal \nResolution \nDays to \nweeks \n\
    Depends on flight operations (hours to days) \nFlexibility \nLow (e.g., \nfixed\
    \ \nrepeating \ncycles) \nMedium (e.g., limited by the \navailability of aviation\
    \ \ncompany) \nHigh \nOperational \nComplexity \nLow (Final \ndata \nprovided\
    \ \nto users) \nMedium (Depends on who \noperates the sensor, users or \ndata\
    \ vendors) \nHigh (users typically operate sensors \nand need to set up hardware\
    \ and \nsoftware properly) \nApplicable \nScales \nRegional—\nglobal \nLandscape—regional\
    \ \nCanopy—landscape \nLeaf—\ncanopy \nMajor \nLimiting \nFactors \nWeather \n\
    (e.g., rain \nand \nclouds) \nUnfavorable flight \nheight/speed, unstable \nillumination\
    \ conditions \nShort battery \nendurance (e.g., 10–30 \nmin), flight \nregulations\
    \ \nPlatform \ndesign and \noperation \nRemote Sens. 2020, 12, x FOR PEER REVIEW\
    \ \n14 of 43 \n \nmedium spatial resolution and limited data availability (e.g.,\
    \ a limited number of operating sensors \nand long revisit time). Airplane- and\
    \ helicopter-based imaging platforms acquire data with suitable \nspatial coverage\
    \ and resolution for most of the agricultural applications. However, they are\
    \ limited \nby a high mission cost and scheduling challenges and thus are not\
    \ suitable for repeated monitoring. \nUAV-based systems are capable of acquiring\
    \ high-spatial resolution images repeatedly and have \nhigh flexibility. However,\
    \ they can only cover a small area due to the limited battery endurance and \n\
    aviation regulations. The close-range imaging systems are capable of obtaining\
    \ super-high-spatial-\nresolution images, but they can only be used at leaf or\
    \ canopy levels. Therefore, the following factors \nshould be taken into consideration\
    \ when selecting a platform for a specific research project: spatial \nresolution\
    \ needed for the study, flight area and flight endurance, weight of the imaging\
    \ system, \nplatform payload capacity, flight safety and regulations, operation\
    \ flexibility, and cost. \nTable 5. Comparison of hyperspectral imaging platforms.\
    \ \n \nSatellites \nAirplanes \nHelicopters \nFixed-\nWing \nUAVs \nMulti-\nRotor\
    \ \nUAVs \nClose-\nRange \nPlatforms \nExample \nPhotos \n \n(Photo: \nSwales\
    \ \nAerospace) \n \n \n \n \n(Photo: \nASPRS) \nOperational \nAltitudes \n400–700\
    \ \nkm \n1–20 km \n100 m–2 km \n<150 m \n<10 m \nSpatial \nCoverage \nVery large\
    \ \nMedium—\nlarge \nMedium \nSmall—\nmedium \nSmall \nVery small \ne.g., one\
    \ \nHyperion \nscene \ncovers 42 \nkm × 7.7 \nkm \nA 10-min flight/operation covers\
    \ \n~100 km2 \n~10 km2 \n~5 km2 \n~0.5 km2 \n~0.005 km2 \nSpatial \nResolution\
    \ \n20–60 m \n1–20 m \n0.1–1 m \n0.01–0.5 m \n0.0001–0.01 \nm \nTemporal \nResolution\
    \ \nDays to \nweeks \nDepends on flight operations (hours to days) \nFlexibility\
    \ \nLow (e.g., \nfixed \nrepeating \ncycles) \nMedium (e.g., limited by the \n\
    availability of aviation \ncompany) \nHigh \nOperational \nComplexity \nLow (Final\
    \ \ndata \nprovided \nto users) \nMedium (Depends on who \noperates the sensor,\
    \ users or \ndata vendors) \nHigh (users typically operate sensors \nand need\
    \ to set up hardware and \nsoftware properly) \nApplicable \nScales \nRegional—\n\
    global \nLandscape—regional \nCanopy—landscape \nLeaf—\ncanopy \nMajor \nLimiting\
    \ \nFactors \nWeather \n(e.g., rain \nand \nclouds) \nUnfavorable flight \nheight/speed,\
    \ unstable \nillumination conditions \nShort battery \nendurance (e.g., 10–30\
    \ \nmin), flight \nregulations \nPlatform \ndesign and \noperation \nRemote Sens.\
    \ 2020, 12, x FOR PEER REVIEW \n14 of 43 \n \nmedium spatial resolution and limited\
    \ data availability (e.g., a limited number of operating sensors \nand long revisit\
    \ time). Airplane- and helicopter-based imaging platforms acquire data with suitable\
    \ \nspatial coverage and resolution for most of the agricultural applications.\
    \ However, they are limited \nby a high mission cost and scheduling challenges\
    \ and thus are not suitable for repeated monitoring. \nUAV-based systems are capable\
    \ of acquiring high-spatial resolution images repeatedly and have \nhigh flexibility.\
    \ However, they can only cover a small area due to the limited battery endurance\
    \ and \naviation regulations. The close-range imaging systems are capable of obtaining\
    \ super-high-spatial-\nresolution images, but they can only be used at leaf or\
    \ canopy levels. Therefore, the following factors \nshould be taken into consideration\
    \ when selecting a platform for a specific research project: spatial \nresolution\
    \ needed for the study, flight area and flight endurance, weight of the imaging\
    \ system, \nplatform payload capacity, flight safety and regulations, operation\
    \ flexibility, and cost. \nTable 5. Comparison of hyperspectral imaging platforms.\
    \ \n \nSatellites \nAirplanes \nHelicopters \nFixed-\nWing \nUAVs \nMulti-\nRotor\
    \ \nUAVs \nClose-\nRange \nPlatforms \nExample \nPhotos \n \n(Photo: \nSwales\
    \ \nAerospace) \n \n \n \n \n(Photo: \nASPRS) \nOperational \nAltitudes \n400–700\
    \ \nkm \n1–20 km \n100 m–2 km \n<150 m \n<10 m \nSpatial \nCoverage \nVery large\
    \ \nMedium—\nlarge \nMedium \nSmall—\nmedium \nSmall \nVery small \ne.g., one\
    \ \nHyperion \nscene \ncovers 42 \nkm × 7.7 \nkm \nA 10-min flight/operation covers\
    \ \n~100 km2 \n~10 km2 \n~5 km2 \n~0.5 km2 \n~0.005 km2 \nSpatial \nResolution\
    \ \n20–60 m \n1–20 m \n0.1–1 m \n0.01–0.5 m \n0.0001–0.01 \nm \nTemporal \nResolution\
    \ \nDays to \nweeks \nDepends on flight operations (hours to days) \nFlexibility\
    \ \nLow (e.g., \nfixed \nrepeating \ncycles) \nMedium (e.g., limited by the \n\
    availability of aviation \ncompany) \nHigh \nOperational \nComplexity \nLow (Final\
    \ \ndata \nprovided \nto users) \nMedium (Depends on who \noperates the sensor,\
    \ users or \ndata vendors) \nHigh (users typically operate sensors \nand need\
    \ to set up hardware and \nsoftware properly) \nApplicable \nScales \nRegional—\n\
    global \nLandscape—regional \nCanopy—landscape \nLeaf—\ncanopy \nMajor \nLimiting\
    \ \nFactors \nWeather \n(e.g., rain \nand \nclouds) \nUnfavorable flight \nheight/speed,\
    \ unstable \nillumination conditions \nShort battery \nendurance (e.g., 10–30\
    \ \nmin), flight \nregulations \nPlatform \ndesign and \noperation \nRemote Sens.\
    \ 2020, 12, x FOR PEER REVIEW \n14 of 43 \n \nmedium spatial resolution and limited\
    \ data availability (e.g., a limited number of operating sensors \nand long revisit\
    \ time). Airplane- and helicopter-based imaging platforms acquire data with suitable\
    \ \nspatial coverage and resolution for most of the agricultural applications.\
    \ However, they are limited \nby a high mission cost and scheduling challenges\
    \ and thus are not suitable for repeated monitoring. \nUAV-based systems are capable\
    \ of acquiring high-spatial resolution images repeatedly and have \nhigh flexibility.\
    \ However, they can only cover a small area due to the limited battery endurance\
    \ and \naviation regulations. The close-range imaging systems are capable of obtaining\
    \ super-high-spatial-\nresolution images, but they can only be used at leaf or\
    \ canopy levels. Therefore, the following factors \nshould be taken into consideration\
    \ when selecting a platform for a specific research project: spatial \nresolution\
    \ needed for the study, flight area and flight endurance, weight of the imaging\
    \ system, \nplatform payload capacity, flight safety and regulations, operation\
    \ flexibility, and cost. \nTable 5. Comparison of hyperspectral imaging platforms.\
    \ \n \nSatellites \nAirplanes \nHelicopters \nFixed-\nWing \nUAVs \nMulti-\nRotor\
    \ \nUAVs \nClose-\nRange \nPlatforms \nExample \nPhotos \n \n(Photo: \nSwales\
    \ \nAerospace) \n \n \n \n \n(Photo: \nASPRS) \nOperational \nAltitudes \n400–700\
    \ \nkm \n1–20 km \n100 m–2 km \n<150 m \n<10 m \nSpatial \nCoverage \nVery large\
    \ \nMedium—\nlarge \nMedium \nSmall—\nmedium \nSmall \nVery small \ne.g., one\
    \ \nHyperion \nscene \ncovers 42 \nkm × 7.7 \nkm \nA 10-min flight/operation covers\
    \ \n~100 km2 \n~10 km2 \n~5 km2 \n~0.5 km2 \n~0.005 km2 \nSpatial \nResolution\
    \ \n20–60 m \n1–20 m \n0.1–1 m \n0.01–0.5 m \n0.0001–0.01 \nm \nTemporal \nResolution\
    \ \nDays to \nweeks \nDepends on flight operations (hours to days) \nFlexibility\
    \ \nLow (e.g., \nfixed \nrepeating \ncycles) \nMedium (e.g., limited by the \n\
    availability of aviation \ncompany) \nHigh \nOperational \nComplexity \nLow (Final\
    \ \ndata \nprovided \nto users) \nMedium (Depends on who \noperates the sensor,\
    \ users or \ndata vendors) \nHigh (users typically operate sensors \nand need\
    \ to set up hardware and \nsoftware properly) \nApplicable \nScales \nRegional—\n\
    global \nLandscape—regional \nCanopy—landscape \nLeaf—\ncanopy \nMajor \nLimiting\
    \ \nFactors \nWeather \n(e.g., rain \nand \nclouds) \nUnfavorable flight \nheight/speed,\
    \ unstable \nillumination conditions \nShort battery \nendurance (e.g., 10–30\
    \ \nmin), flight \nregulations \nPlatform \ndesign and \noperation \nRemote Sens.\
    \ 2020, 12, x FOR PEER REVIEW \n14 of 43 \n \nmedium spatial resolution and limited\
    \ data availability (e.g., a limited number of operating sensors \nand long revisit\
    \ time). Airplane- and helicopter-based imaging platforms acquire data with suitable\
    \ \nspatial coverage and resolution for most of the agricultural applications.\
    \ However, they are limited \nby a high mission cost and scheduling challenges\
    \ and thus are not suitable for repeated monitoring. \nUAV-based systems are capable\
    \ of acquiring high-spatial resolution images repeatedly and have \nhigh flexibility.\
    \ However, they can only cover a small area due to the limited battery endurance\
    \ and \naviation regulations. The close-range imaging systems are capable of obtaining\
    \ super-high-spatial-\nresolution images, but they can only be used at leaf or\
    \ canopy levels. Therefore, the following factors \nshould be taken into consideration\
    \ when selecting a platform for a specific research project: spatial \nresolution\
    \ needed for the study, flight area and flight endurance, weight of the imaging\
    \ system, \nplatform payload capacity, flight safety and regulations, operation\
    \ flexibility, and cost. \nTable 5. Comparison of hyperspectral imaging platforms.\
    \ \n \nSatellites \nAirplanes \nHelicopters \nFixed-\nWing \nUAVs \nMulti-\nRotor\
    \ \nUAVs \nClose-\nRange \nPlatforms \nExample \nPhotos \n \n(Photo: \nSwales\
    \ \nAerospace) \n \n \n \n \n(Photo: \nASPRS) \nOperational \nAltitudes \n400–700\
    \ \nkm \n1–20 km \n100 m–2 km \n<150 m \n<10 m \nSpatial \nCoverage \nVery large\
    \ \nMedium—\nlarge \nMedium \nSmall—\nmedium \nSmall \nVery small \ne.g., one\
    \ \nHyperion \nscene \ncovers 42 \nkm × 7.7 \nkm \nA 10-min flight/operation covers\
    \ \n~100 km2 \n~10 km2 \n~5 km2 \n~0.5 km2 \n~0.005 km2 \nSpatial \nResolution\
    \ \n20–60 m \n1–20 m \n0.1–1 m \n0.01–0.5 m \n0.0001–0.01 \nm \nTemporal \nResolution\
    \ \nDays to \nweeks \nDepends on flight operations (hours to days) \nFlexibility\
    \ \nLow (e.g., \nfixed \nrepeating \ncycles) \nMedium (e.g., limited by the \n\
    availability of aviation \ncompany) \nHigh \nOperational \nComplexity \nLow (Final\
    \ \ndata \nprovided \nto users) \nMedium (Depends on who \noperates the sensor,\
    \ users or \ndata vendors) \nHigh (users typically operate sensors \nand need\
    \ to set up hardware and \nsoftware properly) \nApplicable \nScales \nRegional—\n\
    global \nLandscape—regional \nCanopy—landscape \nLeaf—\ncanopy \nMajor \nLimiting\
    \ \nFactors \nWeather \n(e.g., rain \nand \nclouds) \nUnfavorable flight \nheight/speed,\
    \ unstable \nillumination conditions \nShort battery \nendurance (e.g., 10–30\
    \ \nmin), flight \nregulations \nPlatform \ndesign and \noperation \n(Photo:\n\
    ASPRS)\nOperational\nAltitudes\n400–700 km\n1–20 km\n100 m–2 km\n<150 m\n<10 m\n\
    Spatial\nCoverage\nVery large\nMedium—large\nMedium\nSmall—medium\nSmall\nVery\
    \ small\ne.g., one\nHyperion scene\ncovers 42 km ×\n7.7 km\nA 10-min ﬂight/operation\
    \ covers\n~100 km2\n~10 km2\n~5 km2\n~0.5 km2\n~0.005 km2\nSpatial\nResolution\n\
    20–60 m\n1–20 m\n0.1–1 m\n0.01–0.5 m\n0.0001–0.01 m\nTemporal\nResolution\nDays\
    \ to weeks\nDepends on ﬂight operations (hours to days)\nFlexibility\nLow (e.g.,\
    \ ﬁxed\nrepeating cycles)\nMedium (e.g., limited by the\navailability of aviation\n\
    company)\nHigh\nOperational\nComplexity\nLow (Final data\nprovided to\nusers)\n\
    Medium (Depends on who\noperates the sensor, users or\ndata vendors)\nHigh (users\
    \ typically operate sensors and need\nto set up hardware and software properly)\n\
    Applicable\nScales\nRegional—\nglobal\nLandscape—regional\nCanopy—landscape\n\
    Leaf—canopy\nMajor\nLimiting\nFactors\nWeather (e.g.,\nrain and clouds)\nUnfavorable\
    \ ﬂight\nheight/speed, unstable\nillumination conditions\nShort battery endurance\
    \ (e.g.,\n10–30 min), ﬂight regulations\nPlatform\ndesign and\noperation\nImage\n\
    Acquisition\nCost\nLow to medium\nHigh (typically requires hiring\nan aviation\
    \ company to ﬂy)\nHigh (If need to cover a large area)\nNumber of\npublications\
    \ *\n59\n133\n3\n4\n38\n79\n* The number of publications was counted based on\
    \ which speciﬁc platform was used in each of the\nliterature reviewed.\n3. Methods\
    \ for Processing and Analyzing Hyperspectral Images\nHyperspectral images acquired\
    \ by diﬀerent platforms and sensors are typically provided in a\nraw format (e.g.,\
    \ digital numbers) that needs to be pre-processed (e.g., atmospheric, radiometric,\n\
    and spectral corrections) to retrieve accurate spectral information. Afterward,\
    \ diﬀerent approaches can\nbe used for analyzing the hyperspectral information\
    \ and investigating various agricultural features\nRemote Sens. 2020, 12, 2659\n\
    15 of 44\n(e.g., crop and soil properties). A few commonly used methods include\
    \ linear regression, advanced\nregression (e.g., PLSR), machine learning and deep\
    \ learning (e.g., RF, CNN), and radiative transfer\nmodelling (e.g., PROSPECT\
    \ and PROSAIL). Researchers have used one or more of these methods for\ninvestigations\
    \ of diﬀerent agricultural features. In this section, the review is arranged based\
    \ on the\ndiﬀerent methods used in the studies.\n3.1. Pre-Processing of Hyperspectral\
    \ Images\nTypical processing of hyperspectral imagery includes geometric correction,\
    \ orthorectiﬁcation,\nradiometric correction, and atmospheric correction. For\
    \ satellite- and airplane-based hyperspectral\nimages, the geometric and orthorectiﬁcation\
    \ correction are generally performed by data providers,\nand the radiometric and\
    \ atmospheric corrections can be done following standard image processing steps\n\
    available in remote sensing software. For UAV-based images, in contrast, the users\
    \ need to conduct\nthese processing steps and decide on appropriate processing\
    \ methods and associated parameters.\nFor instance, a digital elevation model\
    \ (DEM) and ground control points (GCPs) are usually needed\nfor performing the\
    \ orthorectiﬁcation and geometric correction [12]. If the sensor mounted on UAV\n\
    is pushbroom based, accurate sensor orientation information recorded by an IMU\
    \ will be needed\nfor these corrections, and the IMU needs to be integrated into\
    \ the UAV and well-calibrated [12,27].\nSoftware packages commonly used in previous\
    \ studies for performing these corrections on UAV-based\nhyperspectral images\
    \ include ENVI (Exelis Visual Information Solutions, Boulder, CO, USA) and\nPARGE\
    \ (ReSe Applications Schläpfer, Wil, Switzerland) [12,26,117].\nRadiometric correction\
    \ is conducted to convert image digital numbers to radiance using calibration\n\
    coeﬃcients that are provided by the sensor manufacturer [11]. These coeﬃcients\
    \ may need to be updated\nover time due to the degradation of spectral materials\
    \ used to construct the hyperspectral sensors.\nRegarding atmospheric correction,\
    \ although the UAVs are ﬂown at low altitudes, the signals acquired\nare still\
    \ subjective to the inﬂuence of various atmospheric absorptions and scatterings,\
    \ such as oxygen\nabsorption at 760nm; water absorption near 820, 940, 1140, 1380,\
    \ and 1880 nm; and carbon dioxide\nabsorption at 2010 and 2060 nm [12,13,26,150].\
    \ Therefore, atmospheric correction is critical for obtaining\ngood-quality spectral\
    \ information. However, Adão et al. [11] suggest that this process might be skipped\n\
    if the UAVs are operated close to the ground. Therefore, the application of atmospheric\
    \ correction will\ndepend on speciﬁc ﬂight missions and research purposes (e.g.,\
    \ ﬂight altitudes, if atmosphere-inﬂuenced\nspectral bands are needed). Software\
    \ or methods commonly used in previous studies for performing\natmospheric correction\
    \ on UAV-based hyperspectral images include the MODTRAN model (Spectral\nSciences\
    \ Inc.), ENVI FLAASH (L3Harris Geospatial), PCI Geomatica (PCI Geomatics Corporate),\n\
    SMARTS model (Solar Consulting Services), and empirical line correction [12,19,27,32,33,116].\n\
    Hyperspectral images typically have hundreds of bands, and many of them are highly\
    \ correlated.\nTherefore, dimension reduction is also an essential procedure to\
    \ consider in the pre-processing of\nhyperspectral imagery. Many previous studies\
    \ using hyperspectral imagery have discussed the\nchallenges of data redundancy\
    \ and have used diﬀerent methods for dimension reduction. For instance,\nMiglani\
    \ et al. [151] performed principal component analysis (PCA) on hyperspectral images\
    \ and\nindicated that 99% of the information could be explained in the ﬁrst 10\
    \ principal components.\nAmato et al. [152] discussed a few previous methods of\
    \ dimension reduction, such as PCA, minimum\nnoise fraction (MNF), and singular\
    \ value decomposition (SVD), and proposed a dimension reduction\nalgorithm based\
    \ on discriminant analysis for supervised classiﬁcation. Teke et al. [38] reviewed\n\
    several dimension reduction methods and summarized them based on transformation\
    \ techniques.\nThenkabail et al. [153] discussed the problems of high dimensionality\
    \ and listed a number of spectral\nbands that are more important for investigating\
    \ crop features. Sahoo et al. [4] reviewed diﬀerent\nmethods for dimension reduction,\
    \ such as PCA, uniform feature design (UMD), wavelet transforms,\nand artiﬁcial\
    \ neural networks (ANNs), and discussed their features of operation. Wang et al.\
    \ [154]\nproposed an auto-encoder-based dimensionality reduction method that is\
    \ a deep learning-based\napproach. Of these diﬀerent methods, the wavelet transform\
    \ is one of the most widely used ones for\nRemote Sens. 2020, 12, 2659\n16 of\
    \ 44\ndimension reduction. This technique decomposes a signal into a series of\
    \ scaled versions of the mother\nwavelet function and allows the variation of\
    \ the wavelet based on the frequency information to extract\nlocalized features\
    \ (e.g., local spectral variation) [155,156]. It has also been successfully used\
    \ for image\nfusion, feature extraction, and image classiﬁcation [156–158].\n\
    In addition to dimensionality reduction, band sensitivity analysis and band selection\
    \ have also\nbeen widely used in hyperspectral remote sensing to reduce the data\
    \ size by selecting only the bands\nthat are sensitive to the object of interest.\
    \ Diﬀerent algorithms have been proposed in previous studies\nfor band selection,\
    \ such as a fast volume-gradient-based method that is an unsupervised method and\n\
    removes the most redundant band successively based on the gradient of volume [159],\
    \ a column subset\nselection-based method that maximizes the volume of the selected\
    \ subset of columns (i.e., bands)\nand is robust to noisy bands [160], and a manifold\
    \ ranking-based salient band selection method that\nputs band vectors in manifold\
    \ space and selects a band-based ranking that can tackle the problem of\ninappropriate\
    \ measurement of the band diﬀerence [161]. With the sensitivity analysis, previous\
    \ studies\nhave identiﬁed spectral bands that are sensitive to diﬀerent crop properties,\
    \ for instance, ~515, ~550,\n~570, ~670, 700–740, ~800, and ~855 nm for investigating\
    \ chlorophyll content; ~405, ~515, ~570, ~705,\nand ~720 nm for evaluating nitrogen\
    \ status; ~970, ~1180, ~1245, ~1450, and ~1950 nm for assessing\nwater content;\
    \ ~682, ~855, ~910, ~970, ~1075, ~1245, ~1518, ~1725, and ~2260 nm for estimating\n\
    biomass; and ~550, ~682, ~855, ~1075, ~1180, ~1450, and ~1725 nm for crop classiﬁcation\
    \ [36,44,153,162].\nOverall, pre-processing is an essential step for improving\
    \ the quality of hyperspectral images and\npreparing for further data analysis.\
    \ After the pre-processing, the analytical methods to be discussed\nbelow can\
    \ be used for analyzing the hyperspectral information and investigating various\
    \ agricultural\nfeatures on the ground.\n3.2. Empirical Relationships\nLinear\
    \ regression is a widely used method for analyzing hyperspectral imagery and retrieving\n\
    target information (e.g., crop and soil properties). Both spectral reﬂectance\
    \ and vegetation indices can\nbe used as predictor variables in establishing a\
    \ linear relationship. For instance, using spectral bands,\nFinn et al. [108]\
    \ built linear regressions between ﬁeld-measured soil moisture data and the spectral\n\
    reﬂectance of collected hyperspectral imagery and identiﬁed bands that have stronger\
    \ correlations with\nsoil moisture. More studies have used vegetation indices\
    \ in the regression for a better performance as\nsome indices can enhance the\
    \ signal of targeted features and minimize the background noise. Some of\nthe\
    \ previous studies are shown in Table 6.\nTable 6. Selected previous studies utilized\
    \ linear regression and hyperspectral vegetation indices for\ninvestigating agricultural\
    \ features.\nApplications\nPrevious Studies\nResearch Focuses\nEstimating leaf\n\
    chlorophyll and\nnitrogen content\nOppelt and Mauser [105]\nUtilized the Chlorophyll\
    \ Absorption Integral (CAI), Optimized\nSoil-Adjusted Vegetation Index (OSAVI),\
    \ and hyperspectral\nNormalized Diﬀerence Vegetation Index (h NDVI) for estimating\n\
    leaf chlorophyll and nitrogen content from hyperspectral\nimagery and evaluated\
    \ the performance of each of the indices.\nWu et al. [45]\nTested a range of vegetation\
    \ indices (e.g., NDVI, Simple Ratio\n(SR), and Triangular Vegetation Index (TVI))\
    \ for retrieving\nvegetation chlorophyll content and LAI from Hyperion images\n\
    and determined the indices that produced high accuracies.\nCilia et al. [103]\n\
    Utilized the Double-peak Canopy Nitrogen Index (DCNI) and\nModiﬁed Chlorophyll\
    \ Absorption Ratio Index/Modiﬁed\nTriangular Vegetation Index 2 (MCARI/MTVI2)\
    \ for estimating\nnitrogen content, as well as the Transformed Chlorophyll\nAbsorption\
    \ in Reﬂectance Index (TCARI), MERIS Terrestrial\nChlorophyll Index (MTCI) and\
    \ Triangular Chlorophyll Index\n(TCI) for estimating leaf pigments.\nRemote Sens.\
    \ 2020, 12, 2659\n17 of 44\nTable 6. Cont.\nApplications\nPrevious Studies\nResearch\
    \ Focuses\nEstimating LAI and\nbiomass\nXie et al. [109]\nEvaluated a range of\
    \ vegetation indices, such as the modiﬁed\nsimple ratio index (MSR), NDVI, a newly\
    \ proposed index\nNDVI-like (which resembles NDVI), modiﬁed triangular\nvegetation\
    \ index (MTVI2), and modiﬁed soil adjusted vegetation\nindex (MSAVI) for estimating\
    \ winter wheat LAI from\nhyperspectral images.\nAmbrus et al. [104]\nTested the\
    \ NDVI and Red Edge Position (REP) for estimating\nﬁeld-scale winter wheat biomass.\n\
    Richter et al. [98]\nExamined a range of techniques (e.g., index-based empirical\n\
    regression, radiative transfer modelling, and artiﬁcial neural\nnetwork) for estimating\
    \ crop biophysical variables (e.g., LAI and\nwater content) in terms of operational\
    \ agricultural applications\nwith airborne Hymap data and discussed the unique\
    \ features of\neach technique.\nEstimating nitrogen\ncontent\nNevalainen et al.\
    \ [163]\nUtilized 28 published vegetation indices (e.g., Chlorophyll\nAbsorption\
    \ Ratio Index (CARI) and Normalized Diﬀerence Red\nEdge (NDRE)) for estimating\
    \ oat nitrogen and identiﬁed the\nbest-performing one.\nDetecting crop\ndisease\n\
    Huang et al. [164]\nExamined the performance of the photochemical reﬂectance\n\
    index (PRI) for estimating the disease index of wheat yellow rust\nusing canopy\
    \ reﬂectance data and then applied the regression\non an airborne hyperspectral\
    \ imagery for mapping the\ndisease-aﬀected areas.\nCopenhaver et al. [34]\nCalculated\
    \ a range of vegetation indices (e.g., NDVI and red\nedge position index) for\
    \ detecting crop disease and compared\nthe eﬀectiveness of these indices.\nEstimating\
    \ crop\nresidue cover\nGalloza and Crawford [47]\nUtilized the Normalized Diﬀerence\
    \ Tillage Index (NDTI) and\nCellulose Absorption Index (CAI), together with ALI,\
    \ Hyperion,\nand airborne hyperspectral (SpecTIR) data, for estimating crop\n\
    residue cover for conservation tillage application.\nCrop classiﬁcation\nThenkabail\
    \ et al. [44]\nUtilized both spectral bands and vegetation indices for\nclassifying\
    \ diﬀerent crop types and estimating vegetation\nproperties and evaluated the\
    \ performance diﬀerence of using\nvarious bands or indices.\nOverall, linear regression\
    \ has been commonly used for estimating a wide range of crop or soil\nproperties.\
    \ It is easy to establish, and most of the index-based regressions generated satisfactory\n\
    accuracies. However, there are several potential issues associated with this approach,\
    \ such as the large\nnumber of indices available and it is unknown which performs\
    \ better, regression may be very sensitive\nto data size and quality, and the\
    \ saturation problem of indices [36,165]. It is thus critical to consider\nthese\
    \ potential issues and adopt appropriate solutions when establishing linear regressions\
    \ with\nhyperspectral data. For instance, selecting appropriate vegetation indices\
    \ with targeted crop or soil\nvariables is recommended. Researchers have evaluated\
    \ a wide range of hyperspectral vegetation indices\nfor diﬀerent research purposes.\
    \ Haboudane et al. [166] examined 11 hyperspectral vegetation indices for\nestimating\
    \ crop chlorophyll content. Main et al. [167] investigated 73 vegetation indices\
    \ for estimating\nchlorophyll content in crop and savanna tree species. Peng and\
    \ Gitelson [168] tested 10 multispectral\nindices and 4 hyperspectral indices\
    \ for quantifying crop gross primary productivity. Croft et al. [169]\nanalyzed\
    \ 47 hyperspectral indices for estimating the leaf chlorophyll content of diﬀerent\
    \ tree species.\nZhou et al. [170] evaluated eight hyperspectral indices for estimating\
    \ the canopy-level wheat nitrogen\ncontent. Tong and He [165] evaluated 21 multispectral\
    \ and 123 hyperspectral vegetation indices for\ncalculating the grass chlorophyll\
    \ content at both the leaf and canopy scales. Yue et al. [171] examined\n54 hyperspectral\
    \ vegetation indices for estimating winter wheat biomass. Indices performed diﬀerently\n\
    Remote Sens. 2020, 12, 2659\n18 of 44\nin these studies; thus, it is suggested\
    \ to evaluate the top-performed ones in these studies and select the\none that\
    \ generates the highest accuracy.\nTo deal with issues of linear regression, advanced\
    \ regression, such as MLR and PLSR, has also\nbeen commonly used in previous research\
    \ for estimating crop and soil properties [172,173]. Compared\nwith linear regression,\
    \ the advanced regression models mostly use multiple predictor variables in the\n\
    model to achieve a higher accuracy. PLSR is one of the most widely used models\
    \ for investigating\ncrop properties using hyperspectral images, such as Ryu et\
    \ al. [35], Jarmer [99], Siegmann et al. [73],\nand Yue et al. [124] used PLSR\
    \ and hyperspectral images for estimating diﬀerent crop biophysical and\nbiochemical\
    \ variables (e.g., LAI, biomass, chlorophyll, content, fresh matter, and nitrogen\
    \ contents).\nThomas et al. [100] examined PLSR for retrieving the biogas potential\
    \ from hyperspectral images and\nevaluated the inﬂuence of imaging time on retrieval\
    \ accuracy. Regarding soil features, Gomez et al. [49],\nVan Wesemael et al. [107],\
    \ Hbirkou et al. [102], and Castaldi et al. [110] built a PLSR model for estimating\n\
    the SOC content using hyperspectral images. Zhang et al. [50] used PLSR for estimating\
    \ a wide range\nof soil properties (e.g., soil moisture, soil organic matter,\
    \ clay, total carbon, phosphorus, and nitrogen\ncontent) from hyperspectral imagery\
    \ and identiﬁed factors that may aﬀect the model accuracy\n(e.g., low signal-to-noise\
    \ ratio, spectral overlap of diﬀerent soil features). Casa et al. [59] used the\n\
    PLSR model and diﬀerent hyperspectral imagery for investigating soil textural\
    \ features and evaluated\nvarious factors (e.g., spectral range and resolution,\
    \ soil moisture, geolocation error) inﬂuencing the\nmodel performance.\nThe PLSR\
    \ model is implemented in Python and R [174,175] and is widely used in many research\n\
    areas, including forests [176], grasslands [177], and waters [178]. This model\
    \ performed well in diﬀerent\nstudies owning to its strengths in dealing with\
    \ a large number of inter-correlated predictor variables\n(i.e., by converting\
    \ them to a few non-correlated latent variables), addressing the data noise challenge,\n\
    and tackling the over-ﬁtting problem [171,179]. Diﬀerent techniques have also\
    \ been conﬁrmed to\nbe eﬃcient for improving the accuracy of the PLSR model, such\
    \ as incorporating diﬀerent types of\npredictor variables in the model (e.g.,\
    \ spectral bands, indices, textural variables), utilizing predicted\nresidual\
    \ error sum of squares (PRESS) statistics for determining the optimal number of\
    \ latent variables,\nand feature evaluation for selecting more important predictor\
    \ variables in the model [36]. It is thus\ncritical to carefully examine these\
    \ techniques for achieving the optimal model accuracy.\n3.3. Radiative Transfer\
    \ Modelling\nRadiative transfer modelling is a physically based approach that\
    \ uses physical laws to\nsimulate the interaction of electromagnetic radiation\
    \ with vegetation (e.g., reﬂection, transmission,\nand absorption) [180]. The\
    \ RTMs simulate vegetation spectra (e.g., leaf reﬂectance and transmittance)\n\
    using vegetation biophysical and biochemical properties (e.g., chlorophyll and\
    \ water contents) in\nthe forward mode, and for inversion of these variables from\
    \ spectral measurements in the inverse\nmode [181]. PROSAIL is one of the most\
    \ widely used RTMs. This model is an integration of the\nleaf-level PROSPECT model\
    \ and canopy-level SAIL model and is capable of simulating canopy\nreﬂectance\
    \ using leaf properties (e.g., chlorophyll and water contents), canopy structural\
    \ parameters\n(e.g., LAI and leaf angle), and soil reﬂectance [18].\nPROSAIL has\
    \ also been used in agricultural environments for investigating crop and soil\n\
    properties. For instance, Casa and Jones [182] inverted PROSAIL and a ray-tracing\
    \ canopy model\nwith spectroradiometer-measured hyperspectral reﬂectance data\
    \ and imaging spectrometer-acquired\nhyperspectral image data, respectively, for\
    \ estimating canopy LAI and evaluated factors inﬂuencing\nthe estimation accuracy\
    \ (e.g., the non-homogeneous surface caused by the crop row structure).\nRichter\
    \ et al. [98] utilized PROSAIL for estimating LAI, fCover, canopy chlorophyll,\
    \ and water content\nfrom hyperspectral images and compared its performance to\
    \ other methods (e.g., artiﬁcial neural\nnetwork). Richter et al. [183] applied\
    \ PROSAIL to investigate similar vegetation variables and analyzed\nthe accuracy\
    \ and eﬃciency of this method. Wu et al. [184] examined the sensitivity of vegetation\
    \ indices\nto vegetation chlorophyll content using simulated results from the\
    \ PROSPECT model and suggested\nRemote Sens. 2020, 12, 2659\n19 of 44\na few well-performed\
    \ indices. Locherer et al. [74] attempted to estimate vegetation LAI using the\n\
    PROSAIL model and multi-source hyperspectral images and tested several techniques\
    \ (e.g., diﬀerent\ncost functions and types of averaging methods) used for the\
    \ inversion process. Yu et al. [37] estimated\na range of vegetation phenotyping\
    \ variables (e.g., LAI and leaf chlorophyll) using hyperspectral\nimagery and\
    \ PROSAIL and examined the sensitivity of diﬀerent spectral ranges to the parameters\
    \ in\nthe PROSAIL model.\nCompared with the regression models discussed in previous\
    \ sections, the RTMs have been less\nused in the literature for investigating\
    \ agricultural features due mainly to their high model complexity\nand computational\
    \ intensity. For instance, a wide range of parameters need to be considered in\n\
    RTM (e.g., chlorophyll, carotenoids, water contents, leaf area index, leaf angles,\
    \ solar angles, and soil\nreﬂectance, along with other parameters, in the PROSAIL\
    \ model) and the users need to use diﬀerent\ntechniques (e.g., merit function,\
    \ look-up table) to facilitate the forward and inversion operations of\nthe model.\
    \ In addition, it costs much more computing time than the regression models to\
    \ achieve the\npredictions of target vegetation variables. However, it is also\
    \ well known that the regression models\ntend to be site and time speciﬁc and\
    \ are not readily transferable to other geographical regions or\ndiﬀerent times\
    \ over the site [166]. In contrast, RTM is a more transferable approach owning\
    \ to the\nfact that it is established based on physical laws and does not require\
    \ training data for rebuilding\nthe model. In addition, RTM is capable of estimating\
    \ a range of vegetation properties in one model,\nwhile regression models typically\
    \ can only estimate one variable [36,185].\n3.4. Machine Learning and Deep Learning\n\
    Machine learning algorithms, including support vector machine regression (SVM)\
    \ and RF,\nare powerful tools for analyzing hyperspectral information since they\
    \ can process a large number of\nvariables (e.g., spectral reﬂectance and vegetation\
    \ indices) eﬃciently [186]. Machine learning has been\nwidely used in the remote\
    \ sensing ﬁeld for estimating properties of ground features or classifying\ndiﬀerent\
    \ ground covers [36,114,187]. Researchers have also used diﬀerent machine learning\
    \ algorithms\nand hyperspectral images for agricultural applications. SVM has\
    \ been a commonly used algorithm\nin previous research for prediction or classiﬁcation\
    \ purposes. For instance, Honkavaara et al. [123]\nestimated crop biomass using\
    \ SVM and UAV-acquired hyperspectral imagery. Bostan et al. [51] utilized\nSVM\
    \ for classifying diﬀerent crop types and achieved high classiﬁcation accuracy.\
    \ Ran et al. [93]\nused KNN and SVM classiﬁers for investigating tillage practices\
    \ in agricultural ﬁelds and compared\ntheir performances. RF is another commonly\
    \ used algorithm for investigating agricultural features\nwith hyperspectral imagery.\
    \ For instance, Gao et al. [188] successfully classiﬁed weed and maize\nusing\
    \ RF and lab-based hyperspectral images. Using ground-based hyperspectral reﬂectance\
    \ data\nacquired by an ASD spectroradiometer, Siegmann and Jarmer [189] evaluated\
    \ the performance of\nRF, SVM, and PLSR for estimating crop LAI and conﬁrmed the\
    \ good performance of RF. Similarly,\nusing hyperspectral reﬂectance, Adam et\
    \ al. [190] attempted to detect maize disease with the RF model.\nOverall, machine\
    \ learning models generally have robust performances for investigating agricultural\n\
    features using hyperspectral imagery.\nDeep learning is a subset of machine learning\
    \ and extends machine learning by adding more\n“depth” (i.e., hierarchical representation\
    \ of the dataset) in the model [191,192]. It is a popular approach\nin recent\
    \ years for recognizing patterns in remote sensing images and thus for investigating\
    \ various\nground features. Deep learning has been commonly used in the remote\
    \ sensing ﬁeld for image\nclassiﬁcation, such as land cover classiﬁcation [193–195]\
    \ and the identiﬁcation of ground features\n(e.g., buildings) [196]. Deep learning\
    \ has also been applied to precision farming to solve complicated\nissues. Existing\
    \ studies are, for example, investigating the estimation of crop yield using CNN\n\
    and multispectral images together with climate data [197], plant disease detection\
    \ using CNN and\nsmartphone-acquired images [198], crop classiﬁcation using 3-D\
    \ CNN and multi-temporal multispectral\nimages [199], and classiﬁcation of agricultural\
    \ land cover using deep recurrent neural network and\nmulti-temporal SAR images\
    \ [200]. Kamilaris and Prenafeta-Boldú [191] reviewed applications of deep\nRemote\
    \ Sens. 2020, 12, 2659\n20 of 44\nlearning in agriculture and food production,\
    \ although not all studies used remote sensing images.\nSingh et al. [201] reviewed\
    \ a range of deep learning methods and their applications, speciﬁcally in plant\n\
    phenotyping. Up to now, deep learning has not been well explored for processing\
    \ and analyzing remote\nsensing images, especially hyperspectral images, for agricultural\
    \ applications. Considering the capacity\nof deep learning for studying feature\
    \ patterns in images and the rich information in hyperspectral\nimagery, the integration\
    \ of the two has a wide range of agricultural applications (e.g., crop classiﬁcation,\n\
    weed monitoring, crop disease detection, and plant stress evaluation). Further\
    \ research in these areas\nis warranted.\nMachine learning or deep learning is\
    \ capable of processing multi-source and multi-type data [202].\nFor instance,\
    \ besides multi-type remote sensing images (e.g., optical, thermal, LiDAR, and\
    \ Radar), other\nsources of data, such as weather, irrigation, and historical\
    \ yield information, can also be incorporated in\nthe modelling process for a\
    \ possibly better evaluation of targeted agricultural features [203]. Although\n\
    machine learning and deep learning models are powerful, it is also critical to\
    \ keep in mind that these\nmodels require large-quantity and high-quality training\
    \ samples to achieve robust performances [202].\nInsuﬃcient training datasets\
    \ or data with issues (e.g., data incompleteness, noise, and biases) may\ncause\
    \ undesired model performances.\nIn summary, diﬀerent analytical methods (e.g.,\
    \ linear regression, advanced regression,\nmachine learning and deep learning,\
    \ and RTM) have diﬀerent levels of complexity, performance,\nand transferability.\
    \ More detailed comparisons on these methods are listed in Table 7. Overall, linear\n\
    regression is the easiest method to use, and its performance is generally acceptable,\
    \ although this\nmethod can be highly inﬂuenced by the choice of predictor variables\
    \ and quality of the sample data.\nThe advanced regression (e.g., PLSR) mostly\
    \ performs better than the linear regression since it involves\nmultiple variables\
    \ in the model and is less sensitive to data noise. RTM (e.g., PROSAIL) is capable\
    \ of\nproducing multiple data products (e.g., chlorophyll, water, and LAI) with\
    \ reasonably high accuracies.\nOne essential advantage of this method is its high\
    \ transferability. However, this method has the highest\ncomplexity as it requires\
    \ a wide range of parameters and extensive programming. In terms of machine\n\
    learning, many algorithms, such as RF and SVM, are well established and mostly\
    \ performed well in\nprevious studies. Some programming and model adjustments\
    \ are needed for this method to achieve\noptimal performance. Deep learning is\
    \ a relatively new method and is increasingly popular in recent\nyears. Appropriate\
    \ model design and programming are critical for this approach. It also requires\
    \ a\nsubstantial amount of training data and computing resources to achieve a\
    \ good model performance.\nRemote Sens. 2020, 12, 2659\n21 of 44\nTable 7. Comparison\
    \ of diﬀerent analytical methods.\nMethods\nLinear Regression\nAdvanced Regression\n\
    Radiative Transfer\nModelling\nMachine Learning\nDeep Learning\nParameters typically\
    \ used\nin the model\n- One predictor\nvariable (e.g.,\nreﬂectance or\nvegetation\
    \ index)\n- Response variable\n(e.g., chlorophyll)\n- Multiple\npredictor variables\n\
    - Response variable\n- Parameters in the model\n(e.g., the number of\nlatent variables\
    \ in PLSR)\n- A wide range of\npredictor variables (e.g.,\nleaf biophysical and\n\
    biochemical properties)\n- Parameters in the model\n(e.g., absorption\ncoeﬃcients,\
    \ the\nrefractive index of leaf\nmaterial in PROSAIL)\n- Multiple\npredictor variables\n\
    - Response variable\n- Parameters in the\nmodel (e.g., number\nof trees in the\n\
    RF model)\n- Predictor variables\nas input layers\n- Sizes and weights\nof layers\n\
    - Number of layers\nfor calculating\nModel complexity\nLow\nMedium\nHigh\nMedium\n\
    High\nModel performance\nLow—high\n(depend on predictor\nvariable used)\nMedium—high\n\
    Medium—high\nMedium—high\nMedium—high\nTransferability in time and\ngeographical\
    \ location\nLow\nLow\nHigh\nLow\nHigh\nTypical agricultural\napplications\nPrediction\
    \ of agricultural variables (e.g., yield, LAI)\nPrediction of agricultural variables\n\
    Classiﬁcation of agricultural features\nApplication\nrecommendations\n- Test a\
    \ range of\npredictor variables\nand identify the best\nperformed one\n- Check\
    \ data noise in\nthe training samples\n- Involve diﬀerent types\nof variables\
    \ (e.g.,\nspectral and textural)\n- Check contributions of\nvariables to the model\n\
    - Tuning model\nparameters to achieve\noptimal performance\n- Collect a set of\n\
    vegetation biophysical\nand\nbiochemical parameters\n- Adjust the model to\nimprove\n\
    calculating eﬃciency\n- Involve diﬀerent\ntypes of variables\n(e.g., spectral\n\
    and textural)\n- Tuning model\nparameters to\nachieve\noptimal performance\n-\
    \ Optimize\nmodel conﬁgurations\n- Large size of\ntraining samples\nRemote Sens.\
    \ 2020, 12, 2659\n22 of 44\n4. Hyperspectral Applications in Agriculture\nHyperspectral\
    \ imaging has been used in agriculture for a wide range of purposes, including\n\
    estimating crop biochemical properties (e.g., chlorophyll, carotenoids, and water\
    \ contents) and\nbiophysical properties (e.g., LAI, biomass) for understanding\
    \ vegetation physiological status and\npredicting yield, evaluating crop nutrient\
    \ status (e.g., nitrogen deﬁciency), monitoring crop disease,\nand investigating\
    \ soil properties (e.g., soil moisture, soil organic matter, and soil carbon).\
    \ Previous\nstudies have also summarized some of the above-mentioned applications\
    \ of hyperspectral remote\nsensing in precision agriculture [4,84]. In this section,\
    \ we will thus focus more on recent hyperspectral\nstudies and summarize these\
    \ studies according to speciﬁc applications.\n4.1. Estimation of Crop Biochemical\
    \ and Biophysical Properties\nOne important hyperspectral application in agriculture\
    \ is monitoring crop conditions through\nthe retrieval of crop biochemical and\
    \ biophysical properties [8,99]. For instance, the leaf chlorophyll\ncontent is\
    \ an essential biochemical property inﬂuencing the vegetation photosynthetic capacity\
    \ and\ncontrolling crop productivity [99]. In previous studies, Oppelt and Mauser\
    \ [105] collected AVIS data\nto retrieve the chlorophyll and nitrogen contents\
    \ in a winter wheat ﬁeld. Similarly, Moharana and\nDutta [43] used Hyperion data\
    \ to estimate the contents of these two biochemical components in a rice\nﬁeld.\
    \ LAI, on the other hand, is a fundamental vegetation biophysical parameter and\
    \ is highly related\nto crop biomass and yield [98]. Previous studies have used\
    \ hyperspectral remote sensing to estimate\nthe LAI of diﬀerent crops, and some\
    \ of the example studies are shown in Table 8.\nTable 8. Selected previous studies\
    \ estimating LAI for diﬀerent crop types using hyperspectral images.\nCrops\n\
    Previous Studies\nResearch Focuses\nWinter wheat\nXie et al. [109]\nEstimated\
    \ canopy LAI in a winter wheat ﬁeld using airborne\nhyperspectral imagery and\
    \ proposed a new vegetation index for\nimproved estimation accuracy.\nSiegmann\
    \ et al. [73]\nRetrieved LAI of two wheat ﬁelds using EnMAP images and\nattempted\
    \ to pan-sharp the images aiming to improve the\nspatial resolution of LAI products.\n\
    Barley\nJarmer [99]\nRetrieved a range of canopy variables from barley, including\n\
    LAI, chlorophyll, water, and fresh matter content using HyMap\ndata and established\
    \ an eﬃcient approach for monitoring the\nspatial patterns of crop variables.\n\
    Rice\nYu et al. [37]\nInvestigated LAI, leaf chlorophyll content, canopy water\n\
    content, and dry matter content using UAV-based hyperspectral\nimagery, aiming\
    \ to understand the growing status of rice.\nMixed\nagricultural\nﬁelds\nRichter\
    \ et al. [98]\nEstimated crop LAI and water content with airborne HyMap\ndata\
    \ aiming to support operational agricultural practices (e.g.,\nirrigation management\
    \ and crop stress detection) in the context\nof the EnMap hyperspectral mission.\n\
    Wu et al. [45]\nEstimated chlorophyll content and LAI in a mixed agricultural\n\
    ﬁeld (e.g., corns, chestnuts trees, and tea plants) using Hyperion\ndata and identiﬁed\
    \ spectral bands and vegetation indices that\ngenerated the highest accuracy.\n\
    Verger et al. [57]\nEstimated LAI, fCover, and FAPAR in an agricultural site with\n\
    diﬀerent crops using PROBA-CHRIS data.\nLocherer et al. [74]\nEstimated LAI in\
    \ mixed crop ﬁelds using EnMAP data and\ncompared the result accuracy to that\
    \ of LAI estimation with\nairborne data.\nRemote Sens. 2020, 12, 2659\n23 of 44\n\
    In addition to the above-mentioned vegetation biochemical and biophysical properties,\
    \ crop water\ncontent is a critical parameter for revealing water stress. Richter\
    \ et al. [98] attempted to estimate the\nwater content in maize, sugar beet, and\
    \ winter wheat using airborne HyMap data. Moharana and\nDutta [204] investigated\
    \ the water stress in a rice ﬁeld and its variations using Hyperion images and\n\
    indicated that the remote sensing-estimated water content matched well with ﬁeld-observed\
    \ data.\nIzzo et al. [128] evaluated the water status in a commercial vineyard\
    \ using UAV-based hyperspectral\ndata and determined wavelengths sensitive to\
    \ the canopy water content. Sahoo et al. [4] discussed the\napplications of hyperspectral\
    \ remote sensing data for evaluating water features in crops and listed\nseveral\
    \ vegetation indices for calculating the water content.\nIt can be found from\
    \ the literature review that many previous studies have focused on estimating\n\
    the crop chlorophyll content, LAI, and water content using hyperspectral imagery,\
    \ while other\nimportant crop properties, such as carotenoids, that are sensitive\
    \ to plant stress are less explored.\nIn addition, crop production is inﬂuenced\
    \ by all of these vegetation properties (e.g., chlorophyll,\nwater, and LAI).\
    \ Besides investigating the spatial and temporal variations of each property,\
    \ it is also\ncritical to evaluate the relationships between these properties\
    \ and further understand how they aﬀect\ncrop growth and crop production.\nEstimating\
    \ crop biomass and forecasting yield are also important applications of remote\
    \ sensing,\nas they will contribute to the understanding of crop productivity\
    \ and implementing suitable\nmanagement measures [126]. Yue et al. [124] utilized\
    \ UAV-based hyperspectral images for estimating the\nabove-ground biomass of winter\
    \ wheat. Yang [205] and Mariotto et al. [15] utilized both multispectral\nand\
    \ hyperspectral data to estimate crop yield and found that the hyperspectral imagery-based\
    \ model\nperformed better. In addition, crop residues left in the ﬁeld are critical\
    \ materials protecting soil\nfrom water and wind erosion and inﬂuencing soil biochemical\
    \ processes. Previous studies, such as\nBannari et al. [106], Galloza and Crawford\
    \ [47], Bannari et al. [46], have used diﬀerent hyperspectral\nimages for the\
    \ estimation of crop residues on farmlands\nBeyond the estimation of crop biomass\
    \ and residue, one further research topic is investigating\nbioenergy (e.g., biogas),\
    \ which can be generated from the crop biomass. Thomas et al. [100] attempted\n\
    to estimate the amount of biogas that can be generated per unit of biomass using\
    \ airborne HyMap\ndata and achieved satisfactory results. Overall, hyperspectral\
    \ imagery has contributed greatly to the\nestimation of crop biomass, yield, and\
    \ other related features (e.g., bioenergy, crop residues). Since crop\nbiomass\
    \ and yield are highly aﬀected by agricultural practices (e.g., watering and nutrition\
    \ treatment),\ninvolving these practice data, together with hyperspectral imagery,\
    \ in the model can potentially\ngenerate better results. More research in this\
    \ area is warranted.\n4.2. Evaluating Crop Nutrient Status\nPrecision farming\
    \ involves evaluating the crop nutrient status and providing recommendations\n\
    on site-speciﬁc resource management according to crop needs [206]. Such an approach\
    \ is critical for\nimproving the resource use eﬃciency and reducing environmental\
    \ impacts [4,103]. Previous studies\nhave used hyperspectral images for estimating\
    \ the nitrogen content of diﬀerent crop types, as shown\nin Table 9.\nTable 9.\
    \ Selected previous studies estimating the nitrogen content for diﬀerent crop\
    \ types using\nhyperspectral images.\nCrop types\nPrevious Studies\nResearch Focuses\n\
    Corn\nAkhtman et al. [127]\nUsed UAV-based hyperspectral images for estimating\
    \ nitrogen\ncontent and phytomass in corn and wheat ﬁelds and monitored the\n\
    temporal variation of these properties.\nGoel et al. [207]\nCollected hyperspectral\
    \ images in a cornﬁeld with diﬀerent nitrogen\ntreatments and weed controls aiming\
    \ to evaluate to what extent the\nspectral signals can identify diﬀerent nitrogen\
    \ treatments, weed\ncontrols, or their interactions.\nRemote Sens. 2020, 12, 2659\n\
    24 of 44\nTable 9. Cont.\nCrop types\nPrevious Studies\nResearch Focuses\nCilia\
    \ et al. [103]\nEstimated nitrogen concentration and dry mass in an experimental\n\
    maize ﬁeld using airborne hyperspectral imagery, aiming to\nquantify the nitrogen\
    \ deﬁcit and provide a variable rate fertilization\nmap. The authors also suggested\
    \ a way to evaluate the minimum\namount of nitrogen to apply without reducing\
    \ crop yield and avoid\nexcessive fertilization.\nQuemada et al. [208]\nEvaluated\
    \ plant nitrogen status in a maize ﬁeld using airborne\nhyperspectral images and\
    \ developed nitrogen fertilizer\nrecommendations.\nWheat\nKoppe et al. [209]\n\
    Attempted to investigate wheat nitrogen status and aboveground\nbiomass using\
    \ hyperspectral and radar images and to evaluate\nspectral signatures of wheats\
    \ under diﬀerent nitrogen treatments.\nKaivosoja et al. [126]\nUsed UAV-based\
    \ hyperspectral imagery to investigate nitrogen\ncontent and absolute biomass\
    \ in a wheat ﬁeld and evaluated the\ndegree of nitrogen shortage on the date of\
    \ image acquisition. In this\nresearch, historical farming data, including a yield\
    \ map and a spring\nfertilization map, were used for estimating the optimal amount\
    \ of\nfertilizer to be applied in diﬀerent areas of the ﬁeld.\nCastaldi et al.\
    \ [210]\nEstimated nitrogen content in wheat using multi-temporal\nsatellite-based\
    \ multispectral and hyperspectral images and found\nthat the band selection aﬀected\
    \ estimation accuracy at diﬀerent\nphenological stages.\nRice\nMoharana and Dutta\
    \ [43]\nCollected Hyperion images for monitoring nitrogen and chlorophyll\ncontents\
    \ in rice and investigated the performance of diﬀerent\nspectral indices.\nRyu\
    \ et al. [35]\nUsed airborne hyperspectral images and multivariable analysis to\n\
    estimate nitrogen content in rice at the heading stage.\nZheng et al. [211]\n\
    Tried to monitor rice nitrogen status using UAV-based hyperspectral\nimages and\
    \ tested the performance of diﬀerent vegetation indices\nfor estimating the nitrogen\
    \ content.\nZhou et al. [212]\nEstimated leaf nitrogen concentration of rice using\
    \ close-range\nhyperspectral images and tested if the variations of the spatial\n\
    resolution of the imagery aﬀect the estimation accuracy.\nOther crops\n(i.e.,\
    \ barley,\npotato,\ncabbage,\ntomato,\nsugarcane,\nand cacao)\nNasi et al. [213]\n\
    Evaluated the performance of using airborne hyperspectral images\nand photogrammetric\
    \ features for estimating crop nitrogen content\nand biomass in a barley ﬁeld\
    \ and a grassland site, and examined if\nthe integration of spectral and plant\
    \ height information can improve\nthe estimation results.\nNigon et al. [214]\n\
    Examined nitrogen stress in potato ﬁelds using airborne\nhyperspectral imagery\
    \ and identiﬁed spectral indices that are\nsensitive to nitrogen content.\nChen\
    \ et al. [215]\nEstimated nitrogen content in cabbage seedlings using close-range\n\
    hyperspectral images and identiﬁed sensitive wavelengths for the\nestimation.\n\
    Zhu et al. [142]\nInvestigated soluble sugar, total nitrogen, and their ratio\
    \ in tomato\nleaves using close-range hyperspectral images and tested data\nfusion\
    \ analysis techniques for improving the investigation accuracy.\nMiphokasap and\n\
    Wannasiri [216]\nCollected Hyperion images for investigating spatial variations\
    \ of\nsugarcane canopy nitrogen concentration and attempted to identify\nthe nutrient\
    \ deﬁcient areas for corresponding treatments.\nMalmir et al. [217]\nAttempted\
    \ to evaluate nutrient status (e.g., nitrogen, phosphorus,\nand potassium) of\
    \ cacao leaves using close-range hyperspectral\nimages and examined inﬂuences\
    \ of band selection on the evaluation\naccuracy.\nRemote Sens. 2020, 12, 2659\n\
    25 of 44\nOverall, owing to the large amount of spectral information in hyperspectral\
    \ imagery, crop nutrient\nstatus can be evaluated with high accuracies, and a\
    \ corresponding fertilizer treatment plan can be\nproposed to achieve optimal\
    \ crop productions. However, it is also essential to keep in mind that there is\n\
    a wide range of factors, such as soil moisture, soil type, and topographic conditions,\
    \ that can impact crop\ngrowth and production. A more comprehensive treatment\
    \ plan that takes into consideration both the\ncrop nutrient status and other\
    \ inﬂuencing factors can make a greater contribution to crop production.\n4.3.\
    \ Classifying Imagery to Identify Crop Types, Growing Stages, Weeds/Invasive Species,\
    \ and Stress/Disease\nBesides quantifying crop properties, hyperspectral images\
    \ have also been used for classiﬁcation\npurposes, such as differentiating crop\
    \ types, identifying crop growing stages, classifying weeds or invasive\nspecies,\
    \ and detecting disease [218]. Examples of previous studies are shown in Table\
    \ 10. Diﬀerent\nagricultural land covers or crop types have diﬀerent spectral\
    \ characteristics; hence, hyperspectral\nimages can contribute greatly to the\
    \ classiﬁcation of these agricultural features.\nTable 10. Selected previous studies\
    \ for the classification of agricultural features using hyperspectral images.\n\
    Applications\nPrevious Studies\nResearch Focuses\nClassiﬁcation of\ncrop types\n\
    Camacho Velasco et al. [48]\nUtilized Hyperion data and diﬀerent classiﬁcation\
    \ algorithms\n(e.g., spectral angle mapper and adaptive coherence estimator)\n\
    for identifying ﬁve types of crops (e.g., oil palm, rubber, grass\nfor grazing,\
    \ citrus, and sugar cane) in Colombia.\nBostan et al. [51]\nClassiﬁed diﬀerent\
    \ crop and land cover types (e.g., maize,\ncotton, urban, water, barren rock,\
    \ and other crop types) using\nLandsat 8 multispectral and EO-1 Hyperion hyperspectral\n\
    images and indicated that hyperspectral imagery performed\nbetter than the multispectral\
    \ imagery.\nAmato et al. [152]\nAssessed the potential of PRISMA data for classifying\
    \ diﬀerent\nagricultural land uses (e.g., soybean, corn, and sugar beet) and\n\
    evaluated the contribution of spectral bands to image\nsegmentation and classiﬁcation.\n\
    Nigam et al. [91]\nPerformed crop classiﬁcation over homogeneous and\nheterogeneous\
    \ agriculture and horticulture areas with airborne\nAVIRIS images and assessed\
    \ crop health at the ﬁeld scale.\nSahoo et al. [4]\nReviewed a few previous studies\
    \ that used hyperspectral\nimages for classiﬁcation purposes and indicated the\
    \ robustness\nof hyperspectral imagery for classifying diﬀerent crop types and\n\
    diﬀerent crop phonological stages.\nOther\nclassiﬁcations\n(e.g., growth stages\n\
    and agricultural\ntillage practices)\nAntony et al. [58]\nApplied multi-angle\
    \ PROBA-CHRIS data for classifying\ndiﬀerent growth stages of wheat.\nRan et al.\
    \ [93]\nAttempted to detect agricultural tillage practices using\nhyperspectral\
    \ imagery with diﬀerent classiﬁcation models and\nidentiﬁed the best performing\
    \ one.\nTeke et al. [38]\nDiscussed the application of spectral libraries for\
    \ classiﬁcation\npurposes and listed several spectral libraries available\nworldwide.\
    \ The authors also indicated the limitations of using a\nspectral library, such\
    \ as the spectral varieties within the same\nspecies or land cover, and highlighted\
    \ the importance of having\ngeographically speciﬁc libraries\nWeed infestation\
    \ is a severe issue in agricultural ﬁelds and could substantially aﬀect crop growth\n\
    and yield. Identifying and mapping weeds in agricultural ﬁelds using remote sensing\
    \ will contribute\ngreatly to variable rate treatment in the ﬁelds [219]. Researchers\
    \ have utilized diﬀerent remote sensing\ndata and methods for weed mapping, as\
    \ shown in Table 11. Overall, the identiﬁcation of weeds\ntypically requires a\
    \ high spatial resolution since many weeds are small in size and mixed with crops.\n\
    Remote Sens. 2020, 12, 2659\n26 of 44\nUAV-based and close-range hyperspectral\
    \ imaging is capable of acquiring high-spatial-resolution\nimages, and thus has\
    \ high potential to contribute to weed detection.\nTable 11. Selected previous\
    \ studies for detecting weeds using diﬀerent hyperspectral imaging platforms.\n\
    Platforms\nPrevious Studies\nResearch Focuses\nAirborne\nGoel et al. [97]\nAttempted\
    \ to detect weed infestation in a cornﬁeld that\nhad diﬀerent nitrogen treatments\
    \ using airborne\nhyperspectral imagery and found the diﬀerent nitrogen\ntreatments\
    \ aﬀected the classiﬁcation accuracy of weed.\nKarimi et al. [220]\nPerformed\
    \ combinations of diﬀerent nitrogen treatment\nrates and weed management practices\
    \ in a cornﬁeld and\ntried to classify these combinations with airborne\nhyperspectral\
    \ images.\nClose range\nZhang et al. [221]\nDeveloped a close-range weed sensing\
    \ system using\nhyperspectral images for classifying tomato and weeds\nand tested\
    \ its performance in diﬀerent environments.\nEddy et al. [139]\nUsed a ground-based\
    \ hyperspectral imaging system for\nclassifying weeds in canola, pea, and wheat\
    \ crops and\nevaluated the applicability of this approach for real-time\ndetection\
    \ of weeds in the ﬁeld.\nEddy et al. [222]\nUsed hyperspectral image data as well\
    \ as secondary\nproducts with reduced bands to classify weeds and\nachieved good\
    \ accuracy.\nLiu et al. [223]\nClassiﬁed carrot and weeds using a ground-based\n\
    hyperspectral imaging system and evaluated the number\nof spectral bands needed\
    \ to achieve a good classiﬁcation\naccuracy.\nMultiple platforms\nScherrer et\
    \ al. [129]\nAttempted to classify herbicide-resistant weeds in\ndiﬀerent crop\
    \ ﬁelds (e.g., barley, corn, and dry pea) using\nboth ground- and UAV-based hyperspectral\
    \ imagery and\ndiscussed factors inﬂuencing classiﬁcation accuracy (e.g.,\ncrop\
    \ type, plant age, and illumination condition).\nReview studies\nLÓPEZ-Granados\
    \ [224]\nDiscussed the high potential of hyperspectral remote\nsensing images\
    \ for mapping weeds but also indicated\nthe limitations of this technology due\
    \ to the high cost of\ndata collection.\nMonitoring crop disease is highly important\
    \ to growers trying to reduce economic and yield\nlosses [38]. Hyperspectral imaging\
    \ collects signals at fine spectral resolutions (e.g., less than 10-nm\nintervals),\
    \ and thus can possibly detect early symptoms of crop disease and support timely\n\
    interventions [225].\nPrevious studies have used hyperspectral images for detecting\
    \ diseases in\ndiﬀerent types of groups (Table 12). Overall, hyperspectral signals\
    \ are sensitive to the variations of\ncrop growth status (e.g., caused by disease\
    \ or stress) and thus can indicate the occurrence of crop\ndisease or stress.\
    \ However, considering that crop status can be aﬀected by other factors (e.g.,\
    \ nutrient\ndeﬁciency), repeat imaging and analysis together with robust modelling\
    \ would be critical for accurate\nand timely detection of crop disease or stress.\n\
    Remote Sens. 2020, 12, 2659\n27 of 44\nTable 12. Selected previous studies for\
    \ detecting disease in diﬀerent crops using hyperspectral images.\nCrops\nPrevious\
    \ Studies\nResearch Focuses\nWheat\nBohnenkamp et al. [119]\nUsed both ground-\
    \ and UAV-based hyperspectral imaging\nplatforms for detecting yellow rust in\
    \ wheat and evaluated\nfactors inﬂuencing the detection (e.g., measurement distance,\n\
    spectral features to use).\nBauriegel et al. [226]\nTargeted the infestation of\
    \ wheat by Fusarium and attempted to\ndetect this disease using hyperspectral\
    \ remote sensing data, and\nconsequently suggested that farmers need to deal with\
    \ infected\ncrops separately from healthy crops.\nZhang et al. [227]\nAttempted\
    \ to detect the Fusarium head blight in winter wheat\nsimilarly using close-range\
    \ hyperspectral imaging and\nsuggested that this is a stable and feasible way\
    \ to monitor this\ndisease using low-altitude remote sensing.\nCorn\nCopenhaver\
    \ et al. [34]\nUsed airborne hyperspectral images to detect the signal of\nOstrinia\
    \ nubilalis in a cornﬁeld (e.g., via monitoring rate of plant\nsenescence) and\
    \ tested the performance of this approach\nthroughout the growing season.\nSoybean\n\
    Nagasubramanian et al. [144]\nTried to detect charcoal rot in soybeans using close-range\n\
    hyperspectral imaging and identiﬁed wavelength ranges that\nare sensitive to this\
    \ disease.\nSugarcane\nApan et al. [41]\nDetected sugarcane areas aﬀected by orange\
    \ rust disease using\nHyperion data and developed speciﬁc vegetation indices that\n\
    are sensitive to the disease.\nMustard\nDutta et al. [42]\nDelineated mustard\
    \ areas inﬂuenced by diseases using Hyperion\nimages and evaluated the performance\
    \ of diﬀerent indices.\nReview\nstudies\nLowe et al. [218]\nFocused on hyperspectral\
    \ imaging and reviewed some of its\napplications in detecting and classifying\
    \ crop disease and stress.\nThomas et al. [225]\nReviewed the contributions of\
    \ hyperspectral imaging to the\ndetection of plant disease and discussed diﬀerent\
    \ factors (e.g.,\nlight and wind) that may limit its wide applications.\nMahlein\
    \ et al. [228]\nReviewed previous studies using remote sensing for detecting\n\
    plant disease, but not limited to hyperspectral imaging.\n4.4. Retrieving Soil\
    \ Moisture, Fertility, and Other Physical or Chemical Properties\nAgricultural\
    \ soil properties, including soil moisture, soil organic matter, soil salinity,\
    \ and roughness,\nare important factors inﬂuencing crop growth and ﬁnal production\
    \ [7]. Hyperspectral remote sensing\ncan contribute greatly to the investigation\
    \ of these factors. For instance, estimating soil moisture is\none of the most\
    \ popular research topics. Finn et al. [108] estimated soil moisture at three\
    \ diﬀerent\ndepths using airborne hyperspectral images and linear regression and\
    \ discussed the contributions and\nlimitations of hyperspectral remote sensing\
    \ for soil moisture studies. Casa et al. [229] investigated\nsoil water, clay,\
    \ and sand contents using a fusion of CHRIS-PROBA images and soil geophysical\
    \ data.\nShoshany et al. [7] summarized four main approaches for estimating soil\
    \ moisture content: (1) Radar\ntechniques; (2) radiation balance and surface temperature\
    \ calculations; (3) reﬂectance in the visible,\nNIR, and SWIR ranges; and (4)\
    \ integrative methods using multiple spectral ranges. Although soil\nmoisture\
    \ can be estimated using optical remote sensing data, it is often aﬀected by the\
    \ plant ground\ncover. Integrating multi-type remote sensing data, e.g., SAR and\
    \ thermal data, can possibly generate\nmore accurate estimates.\nSOC is a critical\
    \ component of soil fertility, which highly controls both the growth and yield\
    \ of\ncrops. Hyperspectral data provide ﬁne spectral details that are critical\
    \ for the estimation of SOC content.\nPrevious studies have used hyperspectral\
    \ images collected by diﬀerent platforms for investigating\nSOC (Table 13). Overall,\
    \ hyperspectral imagery has a high potential for the estimation of soil organic\n\
    Remote Sens. 2020, 12, 2659\n28 of 44\nmatter and carbon. However, similar to\
    \ the evaluation of soil moisture, the investigation of soil organic\nmatter and\
    \ carbon can be highly inﬂuenced by vegetation cover. Therefore, collecting hyperspectral\n\
    images in non-growing seasons could be a solution.\nTable 13. Selected previous\
    \ studies for estimating soil organic carbon using hyperspectral images\nacquired\
    \ by diﬀerent platforms.\nPlatforms\nPrevious Studies\nResearch Focuses\nSatellites\n\
    Zhang et al. [50]\nUtilized EO-1 Hyperion images for estimating several soil\n\
    properties, including soil moisture, soil organic matter, total\ncarbon, total\
    \ phosphorus, total nitrogen, and clay content. The\nauthors also found the inﬂuence\
    \ of spectral resolution on the\nperformance of retrieval models.\nCasa et al.\
    \ [230]\nAssessed soil organic matter and soil texture at the ﬁeld scale\nusing\
    \ CHRIS-PROBA images and produced uniform soil zones\nfor supporting irrigation\
    \ management.\nAirplanes\nHbirkou et al. [102]\nAttempted to estimate SOC in agricultural\
    \ ﬁelds using airborne\nHyMap images and tested the inﬂuences of soil surface\n\
    conditions on the estimation, aiming to support soil\nmanagement in precision\
    \ farming.\nGedminas and Martin [231]\nTried to map soil organic matter using\
    \ airborne hyperspectral\nimagery in combination with topographic information\
    \ extracted\nfrom LiDAR image and evaluated the correlation between soil\norganic\
    \ matter and various spectral bands.\nCastaldi et al. [110]\nInvestigated the\
    \ relationship between SOC in croplands and\nspectral signals using a soil database\
    \ and then estimated SOC in\ntheir study sites using airborne hyperspectral imagery.\
    \ With this\napproach, the authors attempted to reduce the amount of new\ndata\
    \ collection in the ﬁeld or lab.\nVan Wesemael et al. [107]\nDiscussed the impacts\
    \ of vegetation cover on soil and the\nestimation of SOC from remote sensing data\
    \ and attempted to\nuse spectral unmixing techniques to estimate the fraction\
    \ of\nvegetation cover and then estimate the soil carbon content using\nthe residue\
    \ soil spectra.\nMultiple\nplatforms\nGomez et al. [49]\nEstimated SOC using both\
    \ lab-based hyperspectral reﬂectance\ndata and Hyperion image data and found that\
    \ using the\nlab-acquired reﬂectance data can generate more accurate results\n\
    than using the Hyperion data. At the same time, the Hyperion\ndata can generate\
    \ a SOC map that matches ﬁeld observations\nand thus can also be used for prediction.\n\
    Hyperspectral remote sensing data have also been used for estimating other soil\
    \ features, as shown\nin Table 14. It can be found from these studies that hyperspectral\
    \ images can be used for studying a\nwide range of soil features. Diﬀerent soil\
    \ features inﬂuence the spectral signals in diﬀerent bands and\nwith diﬀerent\
    \ magnitudes, while some of these inﬂuences may be spectrally overlapped. Therefore,\n\
    when investigating a speciﬁc soil feature, it is critical to collect a suitable\
    \ number of soil samples with\nother soil features generally controlled.\nRemote\
    \ Sens. 2020, 12, 2659\n29 of 44\nTable 14. Selected previous studies for investigating\
    \ diﬀerent soil features using hyperspectral images.\nSoil Features\nPrevious\
    \ Studies\nResearch Focuses\nSoil texture\nCasa et al. [59]\nInvestigated soil\
    \ texture using airborne MIVIS and spaceborne\nPROBA-CHRIS hyperspectral images\
    \ and discussed their\nperformance and limitation (e.g., lack of SWIR band).\n\
    Soil nitrogen\nSong et al. [232]\nUsed airborne hyperspectral images for evaluating\
    \ the impact of\nsoil nitrogen applications and variable-rate fertilization on\
    \ winter\nwheat growth. The authors also indicated that the variable-rate\nfertilization\
    \ in the ﬁeld could reduce the growing diﬀerence of\nwinter wheat caused by the\
    \ spatial variations of soil nitrogen.\nCopper\nconcentration\nAntonucci et al.\
    \ [147]\nAttempted to estimate in soil using lab-based hyperspectral\nmeasurement\
    \ and achieved good accuracy.\nPotassium\ncontent\nWang et al. [233]\nEvaluated\
    \ potassium content in cinnamon soil using close-range\nhyperspectral imaging\
    \ aiming to better understand soil fertility and\nindicated the good performance\
    \ of this approach when the\npotassium content is high (i.e., ≥ 100 mg/kg).\n\
    CO2 leaks\nMcCann et al. [234]\nDetected CO2 leaks from the soil by monitoring\
    \ vegetation stress\nsignals using multi-temporal hyperspectral images.\nIn summary,\
    \ hyperspectral imaging has been successfully applied to a wide range of agricultural\n\
    applications, as reviewed above, and summarized in Table 15.\nFuture research\
    \ directions are\nalso suggested.\nRemote Sens. 2020, 12, 2659\n30 of 44\nTable\
    \ 15. Hyperspectral applications in agriculture.\nPrevious Focuses\nSuggested\
    \ Future Research Directions\nCrop biochemical and biophysical properties\n- Leaf\
    \ area index\n- Chlorophyll content\n- Water content\n- Fraction of vegetation\
    \ cover\n- Fresh/dry biomass, crop residue\n- Yield\n- Vegetation properties related\
    \ to crop stress (e.g., carotenoids)\n- Relationships between diﬀerent properties\
    \ and how they\naﬀect crop growth\nCrop nutrient status\n- Nitrogen content\n\
    - Other nutrients (e.g., phosphorus, magnesium, and boron\netc.) that may limit\
    \ crop growth\n- Optimized treatment plan targeting diﬀerent limiting factors\n\
    Classiﬁcation\nClassiﬁcation of:\n- Crop types\n- Soil types\n- Growing stages\
    \ (i.e., crop phenological features)\nClassiﬁcation and detection of stressors:\n\
    - Weeds or invasive species\n- Disease/stress aﬀected areas\n- Improvement of\
    \ classiﬁcation methods (e.g., advanced\nalgorithms) for target features\n- Fusion\
    \ and application of multi-type and multi-temporal\nremote sensing data\n- Further\
    \ exploration of UAV and close-range imaging for\nbetter identiﬁcation of ﬁne-scale\
    \ signals\nSoil properties\n- Soil moisture\n- Soil organic matter\n- Soil salinity\n\
    - Soil roughness\n- Separation of spectral signals from soil and vegetation for\n\
    better assessing soil features\n- Fusion and application of multi-type remote\
    \ sensing data to\ncapture diﬀerent soil information\n- Further exploration of\
    \ close-range sensing for investigating\nsoil properties.\nAgro-ecosystem\n- Less\
    \ explored using hyperspectral image\n- Ecosystem services\n- Biodiversity\n-\
    \ Adverse eﬀects of agricultural practices on the environments\nRemote Sens. 2020,\
    \ 12, 2659\n31 of 44\n5. Conclusions and Recommendations\nHyperspectral imaging\
    \ has great potential for applications in agriculture, particularly precision\n\
    agriculture, owing to ample spectral information sensitive to diﬀerent plant and\
    \ soil biophysical and\nbiochemical properties. Multiple platforms, including\
    \ satellites, airplanes, UAVs, and close-range\nplatforms, have become more widely\
    \ available in recent years for collecting hyperspectral images with\ndiﬀerent\
    \ spatial, temporal, and spectral resolutions. These platforms also have diﬀerent\
    \ strengths and\nlimitations in terms of spatial coverage, ﬂight endurance, ﬂexibility,\
    \ operational complexity, and cost.\nThese factors need to be considered when\
    \ choosing imaging platform(s) for speciﬁc research purposes.\nFurther technological\
    \ developments are also needed to overcome some of the limitations, such as the\n\
    short battery endurance in UAV operations and high cost of hyperspectral sensors.\n\
    Diﬀerent analytical methods, such as linear regression, advanced regression, machine\
    \ learning,\ndeep learning, and RTM, have been explored in previous studies for\
    \ analyzing the tremendous amount\nof information in hyperspectral images for\
    \ investigating diﬀerent agricultural features. Previous\nstudies have mainly\
    \ used the regression approach, while more physically based methods, such as\n\
    RTM, have been less explored. Deep learning and eﬀective big-data analytics are\
    \ powerful tools for\nrecognizing patterns in remote sensing data. Together with\
    \ hyperspectral imagery, deep learning\nmodels have high potential to support\
    \ the monitoring of a wide range of agricultural features. Diﬀerent\nanalytical\
    \ methods have diﬀerent advantages and disadvantages, and thus it is critical\
    \ to compare\nthese methods for speciﬁc research (e.g., requirements of accuracy\
    \ and computing eﬃciency) and\nchoose an optimal approach. In addition, image\
    \ spectral information has been commonly used as\nvariables for prediction or\
    \ classiﬁcation tasks, while other information, such as texture, has been less\n\
    explored. Further, some other sources of data, such as weather, irrigation records,\
    \ and historical yield\ninformation, can also be used in some of the analytical\
    \ methods (e.g., machine learning and deep\nlearning) for better monitoring of\
    \ crop features. More research in these ﬁelds is also warranted.\nHyperspectral\
    \ imaging has been successfully applied in a wide range of agricultural applications,\n\
    including estimating crop biochemical and biophysical properties; evaluating crop\
    \ nutrient and stress\nstatus; classifying or detecting crop types, weeds, and\
    \ diseases; and investigating soil characteristics.\nPrevious studies have focused\
    \ on discussing one or two of the many factors impacting crop growth\nperformance\
    \ and productivity, and thus cannot evaluate crop status and growth-limiting factors\n\
    comprehensively. It is important to integrate these factors to achieve a better\
    \ understanding of their\ninter-relationships for optimal crop production and\
    \ environmental protection. Besides, previous studies\nusing hyperspectral imaging\
    \ have mainly targeted investigating crop growth, aiming to improve\ncrop yield,\
    \ while less research has focused on understanding the ecosystem side of crop\
    \ production\n(e.g., ecosystem services and biodiversity). Further research in\
    \ these areas is warranted.\nAuthor Contributions: Conceptualization, J.S., J.L.,\
    \ Y.H., B.L. and P.D.D.; methodology, B.L., P.D.D. and Y.H.;\ninvestigation, B.L.;\
    \ writing—original draft preparation, B.L.; writing—review and editing, P.D.D.,\
    \ J.S., J.L. and\nY.H.; project administration, J.S., J.L. and Y.H.; funding acquisition,\
    \ Y.H. All authors have read and agreed to the\npublished version of the manuscript.\n\
    Funding: This work was funded by the Natural Sciences and Engineering Research\
    \ Council of Canada (NSERC)\nunder Discovery Grant RGPIN-386183 to Professor Yuhong\
    \ He.\nConﬂicts of Interest: The authors declare no conﬂict of interest.\nAbbreviations\n\
    ALI\nAdvanced Land Imager\nAPEX\nAirborne Prism Experiment\nAVIS\nAirborne Visible\
    \ Near-Infrared Imaging Spectrometer\nAVIS\nAirborne Visible Near-Infrared Imaging\
    \ Spectrometer\nAVIRIS\nAirborne Visible/Infrared Imaging Spectrometer\nANN\n\
    Artiﬁcial Neural Networks\nCAI\nCellulose Absorption Index\nRemote Sens. 2020,\
    \ 12, 2659\n32 of 44\nCAI\nChlorophyll Absorption Integral\nCARI\nChlorophyll\
    \ Absorption Ratio Index\nCASI\nCompact Airborne Spectrographic Imager\nCHRIS\n\
    Compact High Resolution Imaging Spectrometer\nCNN\nConvolutional Neural Network\n\
    DEM\nDigital Elevation Model\nDESIS\nDlr Earth Sensing Imaging Spectrometer\n\
    DCNI\nDouble-Peak Canopy Nitrogen Index\nEnMAP\nEnvironmental Mapping And Analysis\
    \ Program\nFAPAR\nFraction Of Absorbed Photosynthetically Active Radiation\nfCover\n\
    Fraction Of Vegetation Cover\nGCPs\nGround Control Points\nHSI\nHyper Spectral\
    \ Imaging\nHySI\nHyperspectral Imager\nHICO\nHyperspectral Imager For The Coastal\
    \ Ocean\nHISUI\nHyperspectral Imager Suite\nHyspIRI\nHyperspectral Infrared Imager\n\
    HyMap\nHyperspectral Mapper\nh NDVI\nHyperspectral Normalized Diﬀerence Vegetation\
    \ Index\nPRISMA\nHyperspectral Precursor And Application Mission\nIMU\nInertial\
    \ Measurement Unit\nLAI\nLeaf Area Index\nMTCI\nMeris Terrestrial Chlorophyll\
    \ Index\nMNF\nMinimum Noise Fraction\nMCARI/MTVI2\nModiﬁed Chlorophyll Absorption\
    \ Ratio Index/Modiﬁed Triangular Vegetation Index 2\nMSR\nModiﬁed Simple Ratio\
    \ Index\nMSAVI\nModiﬁed Soil Adjusted Vegetation Index\nMTVI2\nModiﬁed Triangular\
    \ Vegetation Index\nMIVIS\nMultispectral Infrared Visible Imaging Spectrometer\n\
    MSI\nMultispectral Instrument\nMLR\nMulti-Variable Regression\nNDRE\nNormalized\
    \ Diﬀerence Red Edge\nNDTI\nNormalized Diﬀerence Tillage Index\nOLI\nOperational\
    \ Land Imager\nOSAVI\nOptimized Soil-Adjusted Vegetation Index\nPLSR\nPartial\
    \ Least Square Regression\nPRI\nPhotochemical Reﬂectance Index\nPRESS\nPredicted\
    \ Residual Error Sum Of Squares\nPCA\nPrincipal Component Analysis\nPHI\nPushbroom\
    \ Hyperspectral Imager\nRTM\nRadiative Transfer Modelling\nRF\nRandom Forest\n\
    REP\nRed Edge Position\nSWIR\nShortwave Infrared\nSR\nSimple Ratio\nSVD\nSingular\
    \ Value Decomposition\nSOC\nSoil Organic Carbon\nSHALOM\nSpaceborne Hyperspectral\
    \ Applicative Land And Ocean Mission\nSFOC\nSpecial Flight Operations Certiﬁcate\n\
    SVM\nSupport Vector Machine Regression\nTCARI\nTransformed Chlorophyll Absorption\
    \ In Reﬂectance Index\nTCI\nTriangular Chlorophyll Index\nTVI\nTriangular Vegetation\
    \ Index\nUMD\nUniform Feature Design\nUAV\nUnmanned Aerial Vehicle\nRemote Sens.\
    \ 2020, 12, 2659\n33 of 44\nReferences\n1.\nWeiss, M.; Jacob, F.; Duveiller, G.\
    \ Remote sensing for agricultural applications: A meta-review. Remote Sens.\n\
    Environ. 2020, 236, 111402. [CrossRef]\n2.\nLiu, J.; Miller, J.R.; Haboudane,\
    \ D.; Pattey, E.; Nolin, M.C. Variability of seasonal CASI image data products\n\
    and potential application for management zone delineation for precision agriculture.\
    \ Can. J. Remote Sens.\n2005, 31, 400–411. [CrossRef]\n3.\nJensen, J.R. Remote\
    \ Sensing of the Environment: An Earth Resource Perspective; Prentice Hall: Upper\
    \ Saddle\nRiver, NJ, USA, 2006.\n4.\nSahoo, R.N.; Ray, S.S.; Manjunath, K.R. Hyperspectral\
    \ remote sensing of agriculture. Curr. Sci. 2015, 108,\n848–859.\n5.\nAlonso,\
    \ F.G.; Soria, S.L.; Gozalo, J.C. Comparing two methodologies for crop area estimation\
    \ in Spain using\nLandsat TM images and ground-gathered data. Remote Sens. Environ.\
    \ 1991, 35, 29–35. [CrossRef]\n6.\nMcNairn, H.; Champagne, C.; Shang, J.; Holmstrom,\
    \ D.; Reichert, G. Integration of optical and Synthetic\nAperture Radar (SAR)\
    \ imagery for delivering operational annual crop inventories. ISPRS J. Photogramm.\n\
    2009, 64, 434–449. [CrossRef]\n7.\nShoshany, M.; Goldshleger, N.; Chudnovsky,\
    \ A. Monitoring of agricultural soil degradation by remote-sensing\nmethods: A\
    \ review. Int. J. Remote Sens. 2013, 34, 6152–6181. [CrossRef]\n8.\nHunt, E.R.;\
    \ Daughtry, C.S.T. What good are unmanned aircraft systems for agricultural remote\
    \ sensing and\nprecision agriculture? Int. J. Remote Sens. 2018, 39, 5345–5376.\
    \ [CrossRef]\n9.\nThenkabail, P.S. Biophysical and yield information for precision\
    \ farming from near-real-time and historical\nLandsat TM images. Int. J. Remote\
    \ Sens. 2003, 24, 2879–2904. [CrossRef]\n10.\nShang, J.; Liu, J.; Ma, B.; Zhao,\
    \ T.; Jiao, X.; Geng, X.; Huﬀman, T.; Kovacs, J.M.; Walters, D. Mapping spatial\n\
    variability of crop growth conditions using RapidEye data in Northern Ontario,\
    \ Canada. Remote Sens. Environ.\n2015, 168, 113–125. [CrossRef]\n11.\nAdão, T.;\
    \ Hruška, J.; Pádua, L.; Bessa, J.; Peres, E.; Morais, R.; Sousa, J. Hyperspectral\
    \ Imaging: A Review\non UAV-Based Sensors, Data Processing and Applications for\
    \ Agriculture and Forestry. Remote Sens. 2017,\n9, 1110. [CrossRef]\n12.\nLucieer,\
    \ A.; Malenovský, Z.; Veness, T.; Wallace, L. HyperUAS-imaging spectroscopy from\
    \ a multirotor\nunmanned aircraft system. J. Field Robot. 2014, 31, 571–590. [CrossRef]\n\
    13.\nGonzalez-Dugo, V.; Hernandez, P.; Solis, I.; Zarco-Tejada, P. Using High-Resolution\
    \ Hyperspectral and\nThermal Airborne Imagery to Assess Physiological Condition\
    \ in the Context of Wheat Phenotyping.\nRemote Sens. 2015, 7, 13586–13605. [CrossRef]\n\
    14.\nLee, K.; Cohen, W.B.; Kennedy, R.E.; Maiersperger, T.K.; Gower, S.T. Hyperspectral\
    \ versus multispectral data\nfor estimating leaf area index in four diﬀerent biomes.\
    \ Remote Sens. Environ. 2004, 91, 508–520. [CrossRef]\n15.\nMariotto, I.; Thenkabail,\
    \ P.S.; Huete, A.; Slonecker, E.T.; Platonov, A. Hyperspectral versus multispectral\n\
    crop-productivity modeling and type discrimination for the HyspIRI mission. Remote\
    \ Sens. Environ. 2013,\n139, 291–305. [CrossRef]\n16.\nMarshall, M.; Thenkabail,\
    \ P. Advantage of hyperspectral EO-1 Hyperion over multispectral IKONOS,\nGeoEye-1,\
    \ WorldView-2, Landsat ETM+, and MODIS vegetation indices in crop biomass estimation.\n\
    ISPRS J. Photogramm. 2015, 108, 205–218. [CrossRef]\n17.\nSun, J.; Yang, J.; Shi,\
    \ S.; Chen, B.; Du, L.; Gong, W.; Song, S. Estimating Rice Leaf Nitrogen Concentration:\n\
    Inﬂuence of Regression Algorithms Based on Passive and Active Leaf Reﬂectance.\
    \ Remote Sens. 2017, 9, 951.\n[CrossRef]\n18.\nDarvishzadeh, R.; Matkan, A.A.;\
    \ Ahangar, A.D. Inversion of a radiative transfer model for estimation of rice\n\
    canopy chlorophyll content using a lookup-table approach. IEEE J.-STARS 2012,\
    \ 5, 1222–1230. [CrossRef]\n19.\nHruska, R.; Mitchell, J.; Anderson, M.; Glenn,\
    \ N.F. Radiometric and geometric analysis of hyperspectral\nimagery acquired from\
    \ an unmanned aerial vehicle. Remote Sens. 2012, 4, 2736–2752. [CrossRef]\n20.\n\
    Transon, J.; d’Andrimont, R.; Maugnard, A.; Defourny, P. Survey of Hyperspectral\
    \ Earth Observation\nApplications from Space in the Sentinel-2 Context. Remote\
    \ Sens. 2018, 10, 157. [CrossRef]\n21.\nLodhi, V.; Chakravarty, D.; Mitra, P.\
    \ Hyperspectral Imaging System: Development Aspects and Recent\nTrends. Sens.\
    \ Imaging 2019, 20, 1–24. [CrossRef]\nRemote Sens. 2020, 12, 2659\n34 of 44\n\
    22.\nHatﬁeld, J.L.; Prueger, J.H. Value of Using Diﬀerent Vegetative Indices to\
    \ Quantify Agricultural Crop\nCharacteristics at Diﬀerent Growth Stages under\
    \ Varying Management Practices. Remote Sens. 2010, 2,\n562–578. [CrossRef]\n23.\n\
    Zhang, H.; Lan, Y.; Suh, C.P.C.; Westbrook, J.; Clint Hoﬀmann, W.; Yang, C.; Huang,\
    \ Y. Fusion of\nremotely sensed data from airborne and ground-based sensors to\
    \ enhance detection of cotton plants.\nComput. Electron. Agric. 2013, 93, 55–59.\
    \ [CrossRef]\n24.\nMahajan, G.R.; Pandey, R.N.; Sahoo, R.N.; Gupta, V.K.; Datta,\
    \ S.C.; Kumar, D. Monitoring nitrogen,\nphosphorus and sulphur in hybrid rice\
    \ (Oryza sativa L.) using hyperspectral remote sensing. Precis. Agric.\n2017,\
    \ 18, 736–761. [CrossRef]\n25.\nSkauli, T.; Goa, P.E.; Baarstad, I.; Loke, T.\
    \ A compact combined hyperspectral and polarimetric imager. In\nProceedings of\
    \ the Society of Photo-Optical Instrumentation Engineers, Stockholm, Sweden, 5\
    \ October 2006;\nDriggers, R.G., Huckridge, D.A., Eds.; SPIE-INT SOC Optical Engineering:\
    \ Bellingham, WA, USA, 2016;\nVolume 6395, pp. 44–51.\n26.\nZarco-Tejada, P.J.;\
    \ Suarez, L.; Gonzalez-Dugo, V. Spatial resolution eﬀects on chlorophyll ﬂuorescence\
    \ retrieval\nin a heterogeneous canopy using hyperspectral imagery and radiative\
    \ transfer simulation. IEEE Geosci.\nRemote Soc. 2013, 10, 937–941. [CrossRef]\n\
    27.\nLu, B.; He, Y.; Dao, P.D. Comparing the Performance of Multispectral and\
    \ Hyperspectral Images for Estimating\nVegetation Properties. IEEE J. STARS 2019,\
    \ 12, 1784–1797. [CrossRef]\n28.\nISS Utilization: MUSES-DESIS (Multi-User System\
    \ for Earth Sensing) with DESIS instrument. Available\nonline: https://directory.eoportal.org/web/eoportal/satellite-missions/content/-/article/iss-muses\
    \ (accessed on\n3 August 2020).\n29.\nPRISMA (Hyperspectral Precursor and Application\
    \ Mission). Available online: https://directory.eoportal.\norg/web/eoportal/satellite-missions/p/prisma-hyperspectral#launch\
    \ (accessed on 3 August 2020).\n30.\nSatellite Missions Database. Available online:\
    \ https://directory.eoportal.org/web/eoportal/satellite-missions\n(accessed on\
    \ 10 November 2019).\n31.\nEnMAP (Environmental Monitoring and Analysis Program).\
    \ Available online: https://directory.eoportal.org/\nweb/eoportal/satellite-missions/e/enmap\
    \ (accessed on 3 August 2020).\n32.\nMitchell, J.J.; Glenn, N.F.; Anderson, M.O.;\
    \ Hruska, R.C.; Halford, A.; Baun, C.; Nydegger, N. Unmanned\nAerial Vehicle (UAV)\
    \ hyperspectral remote sensing for dryland vegetation monitoring. In Proceedings\n\
    of the 2012 4th Workshop on Hyperspectral Image and Signal Processing: Evolution\
    \ in Remote Sensing\n(WHISPERS), Shanghai, China, 4–7 June 2012; pp. 1–10.\n33.\n\
    Zarco-Tejada, P.J.; Guillén-Climent, M.L.; Hernández-Clemente, R.; Catalina, A.;\
    \ González, M.R.; Martín, P.\nEstimating leaf carotenoid content in vineyards\
    \ using high resolution hyperspectral imagery acquired from\nan unmanned aerial\
    \ vehicle (UAV). Agric. Forest Meteorol. 2013, 171, 281–294. [CrossRef]\n34.\n\
    Copenhaver, K.; Hellmich, R.; Hunt, T.; Glaser, J.; Sappington, T.; Calvin, D.;\
    \ Carroll, M.; Fridgen, J. Use of\nspectral vegetation indices derived from airborne\
    \ hyperspectral imagery for detection of European corn\nborer infestation in Iowa\
    \ corn plots. J. Econ. Entomol. 2008, 101, 1614–1623.\n35.\nRyu, C.; Suguri, M.;\
    \ Umeda, M. Multivariate analysis of nitrogen content for rice at the heading\
    \ stage using\nreﬂectance of airborne hyperspectral remote sensing. Field Crops\
    \ Res. 2011, 122, 214–224. [CrossRef]\n36.\nLu, B.; He, Y. Evaluating Empirical\
    \ Regression, Machine Learning, and Radiative Transfer Modelling for\nEstimating\
    \ Vegetation Chlorophyll Content Using Bi-Seasonal Hyperspectral Images. Remote\
    \ Sens. 2019,\n11, 1979. [CrossRef]\n37.\nYu, F.; Xu, T.; Du, W.; Ma, H.; Zhang,\
    \ G.; Chen, C. Radiative transfer models (RTMs) for ﬁeld phenotyping\ninversion\
    \ of rice based on UAV hyperspectral remote sensing. Int. J. Agric. Biol. Eng.\
    \ 2017, 10, 150–157.\n38.\nTeke, M.; Deveci, H.S.; Haliloglu, O.; Gurbuz, S.Z.;\
    \ Sakarya, U. A short survey of hyperspectral remote\nsensing applications in\
    \ agriculture. In Proceedings of the 2013 6th International Conference on Recent\n\
    Advances in Space Technologies (RAST), Istanbul, Turkey, 12–14 June 2013; IEEE:\
    \ New York, NY, USA, 2013;\npp. 171–176.\n39.\nDale, L.M.; Thewis, A.; Boudry,\
    \ C.; Rotar, I.; Dardenne, P.; Baeten, V.; Pierna, J.A.F. Hyperspectral\nImaging\
    \ Applications in Agriculture and Agro-Food Product Quality and Safety Control:\
    \ A Review.\nAppl. Spectrosc. Rev. 2013, 48, 142–159. [CrossRef]\n40.\nTiangong/Shenzhou:\
    \ China’s Human Spaceﬂight Program/Tianzhou Cargo Spaceship. Available online:\n\
    https://directory.eoportal.org/web/eoportal/satellite-missions/t/tiangong (accessed\
    \ on 3 August 2020).\nRemote Sens. 2020, 12, 2659\n35 of 44\n41.\nApan, A.; Held,\
    \ A.; Phinn, S.; Markley, J. Detecting sugarcane ‘orange rust’ disease using EO-1\
    \ Hyperion\nhyperspectral imagery. Int. J. Remote Sens. 2004, 25, 489–498. [CrossRef]\n\
    42.\nDutta, S.; Bhattacharya, B.K.; Rajak, D.R.; Chattopadhayay, C.; Patel, N.K.;\
    \ Parihar, J.S. Disease detection in\nmustard crop using eo-1 hyperion satellite\
    \ data. J. Indian Soc. Remote 2006, 34, 325–330. [CrossRef]\n43.\nMoharana, S.;\
    \ Dutta, S. Spatial variability of chlorophyll and nitrogen content of rice from\
    \ hyperspectral\nimagery. ISPRS J. Photogramm. 2016, 122, 17–29. [CrossRef]\n\
    44.\nThenkabail, P.S.; Mariotto, I.; Gumma, M.K.; Middleton, E.M.; Landis, D.R.;\
    \ Huemmrich, K.F. Selection\nof Hyperspectral Narrowbands (HNBs) and Composition\
    \ of Hyperspectral Twoband Vegetation Indices\n(HVIs) for Biophysical Characterization\
    \ and Discrimination of Crop Types Using Field Reﬂectance and\nHyperion/EO-1 Data.\
    \ IEEE J. STARS 2013, 6, 427–439. [CrossRef]\n45.\nWu, C.; Han, X.; Niu, Z.; Dong,\
    \ J. An evaluation of EO-1 hyperspectral Hyperion data for chlorophyll content\n\
    and leaf area index estimation. Int. J. Remote Sens. 2010, 31, 1079–1086. [CrossRef]\n\
    46.\nBannari, A.; Staenz, K.; Champagne, C.; Khurshid, K. Spatial Variability\
    \ Mapping of Crop Residue Using\nHyperion (EO-1) Hyperspectral Data. Remote Sens.\
    \ 2015, 7, 8107–8127. [CrossRef]\n47.\nGalloza, M.S.; Crawford, M. Exploiting\
    \ multisensor spectral data to improve crop residue cover estimates\nfor management\
    \ of agricultural water quality. In Proceedings of the IEEE Geoscience and Remote\
    \ Sensing\nSociety Symposium, Vancouver, BC, Canada, 24–29 July 2011; IEEE: New\
    \ York, NY, USA, 2011; pp. 3668–3671.\n48.\nCamacho Velasco, A.; Vargas García,\
    \ C.A.; Arguello Fuentes, H. A comparative study of target detection\nalgorithms\
    \ in hyperspectral imagery applied to agricultural crops in Colombia. Revista\
    \ Tecnura 2016, 20,\n86–99. [CrossRef]\n49.\nGomez, C.; Rossel, R.A.V.; McBratney,\
    \ A.B. Soil organic carbon prediction by hyperspectral remote sensing\nand ﬁeld\
    \ vis-NIR spectroscopy: An Australian case study. Geoderma 2008, 146, 403–411.\
    \ [CrossRef]\n50.\nZhang, T.; Li, L.; Zheng, B. Estimation of agricultural soil\
    \ properties with imaging and laboratory spectroscopy.\nJ. Appl. Remote Sens.\
    \ 2013, 7, 73587. [CrossRef]\n51.\nBostan, S.; Ortak, M.A.; Tuna, C.; Akoguz,\
    \ A.; Sertel, E.; Ustundag, B.B. Comparison of classiﬁcation accuracy\nof co-located\
    \ hyperspectral & multispectral images for agricultural purposes. In Proceedings\
    \ of the 2016\nFifth International Conference on Agro-Geoinformatics (Agro-Geoinformatics),\
    \ Tianjin, China, 18–20 July\n2016; IEEE: New York, NY, USA, 2016; pp. 1–4.\n\
    52.\nLodhi, V.; Chakravarty, D.; Mitra, P. Hyperspectral Imaging for Earth Observation:\
    \ Platforms and Instruments.\nJ. Indian Inst. Sci. 2018, 98, 429–443. [CrossRef]\n\
    53.\nAasen, H.; Bolten, A. Multi-temporal high-resolution imaging spectroscopy\
    \ with hyperspectral 2D imagers -\nFrom theory to application. Remote Sens. Environ.\
    \ 2018, 205, 374–389. [CrossRef]\n54.\nJia, X.; Li, S.; Ke, S.; Hu, B. Overview\
    \ of spaceborne hyperspectral imagers and the research progress in\nbathymetric\
    \ maps. In Proceedings of the Second Target Recognition and Artiﬁcial Intelligence\
    \ Summit\nForum. International Society for Optics and Photonics, Shenyang, China,\
    \ 28–30 August 2019; SPIE-INT SOC\nOptical Engineering: Bellingham, WA, USA, 2020.\n\
    55.\nHeadwall Hyperspectral Sensors. Available online: https://www.headwallphotonics.com/hyperspectral-\n\
    sensors (accessed on 8 May 2020).\n56.\nPullanagari, R.R.; Kereszturi, G.; Yule,\
    \ I. Integrating Airborne Hyperspectral, Topographic, and Soil Data for\nEstimating\
    \ Pasture Quality Using Recursive Feature Elimination with Random Forest Regression.\
    \ Remote Sens.\n2018, 10, 1117. [CrossRef]\n57.\nVerger, A.; Baret, F.; Camacho,\
    \ F. Optimal modalities for radiative transfer-neural network estimation of\n\
    canopy biophysical characteristics: Evaluation over an agricultural area with\
    \ CHRIS/PROBA observations.\nRemote Sens. Environ. 2011, 115, 415–426. [CrossRef]\n\
    58.\nAntony, R.; Ray, S.S.; Panigrahy, S. Discrimination of wheat crop stage using\
    \ CHRIS/PROBA multi-angle\nnarrowband data. Remote Sens. Lett. 2011, 2, 71–80.\
    \ [CrossRef]\n59.\nCasa, R.; Castaldi, F.; Pascucci, S.; Palombo, A.; Pignatti,\
    \ S. A comparison of sensor resolution and calibration\nstrategies for soil texture\
    \ estimation from hyperspectral remote sensing. Geoderma 2013, 197, 17–26. [CrossRef]\n\
    60.\nKumar, A.S.K.; Samudraiah, D.R.M. Hyperspectral Imager Onboard Indian Mini\
    \ Satellite-1. In Optical\nPayloads for Space Missions; Qian, S., Ed.; John Wiley\
    \ & Sons: Hoboken, NJ, USA, 2015; Volume 6, pp. 141–160.\n61.\nIMS-1 (Indian Microsatellite-1).\n\
    Available online: https://directory.eoportal.org/web/eoportal/satellite-\nmissions/i/ims-1\
    \ (accessed on 31 March 2020).\n62.\nRaval, M.S. Hyperspectral Imaging: A Paradigm\
    \ in Remote Sensing. CSI Commun. 2014, 7, 7–9.\nRemote Sens. 2020, 12, 2659\n\
    36 of 44\n63.\nKhobragade, A.N.; Raghuwanshi, M.M. Contextual Soft Classiﬁcation\
    \ Approaches for Crops Identiﬁcation\nUsing Multi-sensory Remote Sensing Data:\
    \ Machine Learning Perspective for Satellite Images. In Artiﬁcial\nIntelligence\
    \ Perspectives and Applications; Springer: Cham, Switzerland, 2015; pp. 333–346.\n\
    64.\nHyperspectral Imager for the Coastal Ocean. Available online: http://hico.coas.oregonstate.edu/\
    \ (accessed on\n1 April 2020).\n65.\nKrutz, D.; Müller, R.; Knodt, U.; Günther,\
    \ B.; Walter, I.; Sebastian, I.; Säuberlich, T.; Reulke, R.; Carmona, E.;\nEckardt,\
    \ A.; et al. The Instrument Design of the DLR Earth SensingImaging Spectrometer\
    \ (DESIS). Sensors\n2019, 19, 1622. [CrossRef]\n66.\nISS Utilization: HISUI (Hyperspectral\
    \ Imager Suite). Available online: https://eoportal.org/web/eoportal/\nsatellite-missions/content/-/article/iss-utilization-hisui-hyperspectral-imager-suite-#launch\
    \ (accessed on 1\nApril 2020).\n67.\nPignatti, S.; Palombo, A.; Pascucci, S.;\
    \ Romano, F.; Santini, F.; Simoniello, T.; Umberto, A.; Vincenzo, C.;\nAcito,\
    \ N.; Diani, M.; et al. The PRISMA hyperspectral mission: Science activities and\
    \ opportunities for\nagriculture and land monitoring. In Proceedings of the 2013\
    \ IEEE International Geoscience and Remote\nSensing Symposium-IGARSS, Melbourne,\
    \ VIC, Australia, 21–26 July 2013; pp. 4558–4561.\n68.\nEnMap Hyperspectral Imager.\n\
    Available online:\nhttp://www.enmap.org/index.html (accessed on 1\nDecember 2019).\n\
    69.\nFeingersh, T.; Ben-Dor, E. SHALOM—A Commercial Hyperspectral Space Mission.\
    \ In Optical Payloads for\nSpace Missions; Qian, S.E., Ed.; John Wiley & Sons,\
    \ Ltd.: Hoboken, NJ, USA, 2015; pp. 247–263.\n70.\nPandey, P.C.; Manevski, K.;\
    \ Srivastava, P.K.; Petropoulos, G.P. The Use of Hyperspectral Earth Observation\n\
    Data for Land Use/Cover Classiﬁcation: Present Status, Challenges, and Future\
    \ Outlook. In Hyperspectral\nRemote Sensing of Vegetation, 2nd ed.; Thenkabail,\
    \ P.S., Lyon, J.G., Huete, A., Eds.; CRC Press: Boca Raton, FL,\nUSA, 2018; Volume\
    \ 4.\n71.\nHyspIRI Mission Study. Available online: https://hyspiri.jpl.nasa.gov/\
    \ (accessed on 1 August 2020).\n72.\nMalec, S.; Rogge, D.; Heiden, U.; Sanchez-Azofeifa,\
    \ A.; Bachmann, M.; Wegmann, M. Capability of Spaceborne\nHyperspectral EnMAP\
    \ Mission for Mapping Fractional Cover for Soil Erosion Modeling. Remote Sens.\
    \ 2015,\n7, 11776–11800. [CrossRef]\n73.\nSiegmann, B.; Jarmer, T.; Beyer, F.;\
    \ Ehlers, M. The Potential of Pan-Sharpened EnMAP Data for the Assessment\nof\
    \ Wheat LAI. Remote Sens. 2015, 7, 12737–12762. [CrossRef]\n74.\nLocherer, M.;\
    \ Hank, T.; Danner, M.; Mauser, W. Retrieval of Seasonal Leaf Area Index from\
    \ Simulated EnMAP\nData through Optimized LUT-Based Inversion of the PROSAIL Model.\
    \ Remote Sens. 2015, 7, 10321–10346.\n[CrossRef]\n75.\nBachmann, M.; Makarau,\
    \ A.; Segl, K.; Richter, R. Estimating the Inﬂuence of Spectral and Radiometric\n\
    Calibration Uncertainties on EnMAP Data Products—Examples for Ground Reﬂectance\
    \ Retrieval and\nVegetation Indices. Remote Sens. 2015, 7, 10689–10714. [CrossRef]\n\
    76.\nCastaldi, F.; Palombo, A.; Santini, F.; Pascucci, S.; Pignatti, S.; Casa,\
    \ R. Evaluation of the potential of the\ncurrent and forthcoming multispectral\
    \ and hyperspectral imagers to estimate soil texture and organic carbon.\nRemote\
    \ Sens. Environ. 2016, 179, 54–65. [CrossRef]\n77.\nCastaldi, F.; Palombo, A.;\
    \ Pascucci, S.; Pignatti, S.; Santini, F.; Casa, R. Reducing the Inﬂuence of Soil\n\
    Moisture on the Estimation of Clay from Hyperspectral Data: A Case Study Using\
    \ Simulated PRISMA Data.\nRemote Sens. 2015, 7, 15561–15582. [CrossRef]\n78.\n\
    Ghasrodashti, E.; Karami, A.; Heylen, R.; Scheunders, P. Spatial Resolution Enhancement\
    \ of Hyperspectral\nImages Using Spectral Unmixing and Bayesian Sparse Representation.\
    \ Remote Sens. 2017, 9, 541. [CrossRef]\n79.\nYang, J.; Li, Y.; Chan, J.; Shen,\
    \ Q. Image Fusion for Spatial Enhancement of Hyperspectral Image via Pixel\nGroup\
    \ Based Non-Local Sparse Representation. Remote Sens. 2017, 9, 53. [CrossRef]\n\
    80.\nZhao, Y.; Yang, J.; Chan, J.C. Hyperspectral Imagery Super-Resolution by\
    \ Spatial-Spectral Joint Nonlocal\nSimilarity. IEEE J. STARS 2014, 7, 2671–2679.\
    \ [CrossRef]\n81.\nLoncan, L.; Almeida, L.B.; Bioucas-Dias, J.M.; Briottet, X.;\
    \ Chanussot, J.; Dobigeon, N.; Fabre, S.; Liao, W.;\nLicciardi, G.A.; Simões,\
    \ M.; et al. Hyperspectral pansharpening: A review. IEEE Geosci. Remote Sens.\
    \ Mag.\n2015, 3, 27–46. [CrossRef]\n82.\nAsner, G.P.; Heidebrecht, K.B. Imaging\
    \ spectroscopy for desertiﬁcation studies: Comparing aviris and eo-1\nhyperion\
    \ in argentina drylands. IEEE Trans. Geosci. Remote 2003, 41, 1283–1296. [CrossRef]\n\
    Remote Sens. 2020, 12, 2659\n37 of 44\n83.\nWeng, Y.; Gong, P.; Zhu, Z. A Spectral\
    \ Index for Estimating Soil Salinity in the Yellow River Delta Region of\nChina\
    \ Using EO-1 Hyperion Data. Pedosphere 2010, 20, 378–388. [CrossRef]\n84.\nMulla,\
    \ D.J. Twenty ﬁve years of remote sensing in precision agriculture: Key advances\
    \ and remaining\nknowledge gaps. Biosyst. Eng. 2013, 114, 358–371. [CrossRef]\n\
    85.\nJacquemoud, S.; Baret, F.; Andrieu, B.; Danson, F.M.; Jaggard, K. Extraction\
    \ of vegetation biophysical\nparameters by inversion of the PROSPECT + SAIL models\
    \ on sugar beet canopy reﬂectance data. Application\nto TM and AVIRIS sensors.\
    \ Remote Sens. Environ. 1995, 52, 163–172. [CrossRef]\n86.\nGat, N.; Erives, H.;\
    \ Fitzgerald, G.J.; Kaﬀka, S.R.; Maas, S.J. Estimating sugar beet yield using\
    \ AVIRIS-derived\nindices. In Summaries of the 9th JPL Airborne Earth Science\
    \ Workshop. Unpaginated CD; Jet Propulsion Laboratory:\nPasadena, CA, USA, 2000.\n\
    87.\nEstep, L.; Terrie, G.; Davis, B. Crop stress detection using AVIRIS hyperspectral\
    \ imagery and artiﬁcial neural\nnetworks. Int. J. Remote Sens. 2004, 25, 4999–5004.\
    \ [CrossRef]\n88.\nCheng, Y.; Ustin, S.L.; Riano, D.; Vanderbilt, V.C. Water content\
    \ estimation from hyperspectral images and\nMODIS indexes in Southeastern Arizona.\
    \ Remote Sens. Environ. 2008, 112, 363–374. [CrossRef]\n89.\nPalacios-Orueta,\
    \ A.; Ustin, S.L. Remote Sensing of Soil Properties in the Santa Monica Mountains\
    \ I. Spectral\nAnalysis. Remote Sens. Environ. 1998, 65, 170–183. [CrossRef]\n\
    90.\nGat, N.;\nErives, H.;\nMaas, S.J.;\nFitzgerald, G.J. Application of low altitude\
    \ AVIRIS imagery\nof agricultural ﬁelds in the San Joaquin Valley,\nCA, to precision\
    \ farming.\nIn The 8th JPL\nAirborne Earth Science Workshop; Academia:\nPasadena,\
    \ CA, USA, 1999; pp. 145–150.\nAvailable\nonline: https://www.researchgate.net/publication/2434575_Application_Of_Low_Altitude_Aviris_Imagery_\n\
    Of_Agricultural_Fields_In_The_San_Joaquin_Valley_Ca_To_Precision_Farming (accessed\
    \ on 11 July 2020.).\n91.\nNigam, R.; Tripathy, R.; Dutta, S.; Bhagia, N.; Nagori,\
    \ R.; Chandrasekar, K.; Kot, R.; Bhattacharya, B.K.;\nUstin, S. Crop type discrimination\
    \ and health assessment using hyperspectral imaging. Curr. Sci. 2019, 116,\n1108–1123.\
    \ [CrossRef]\n92.\nShivers, S.W.; Roberts, D.A.; McFadden, J.P. Using paired thermal\
    \ and hyperspectral aerial imagery to quantify\nland surface temperature variability\
    \ and assess crop stress within California orchards. Remote Sens. Environ.\n2019,\
    \ 222, 215–231. [CrossRef]\n93.\nRan, Q.; Li, W.; Du, Q.; Yang, C. Hyperspectral\
    \ image classiﬁcation for mapping agricultural tillage practices.\nJ. Appl. Remote\
    \ Sens. 2015, 9, 97298. [CrossRef]\n94.\nShivers, S.W.; Roberts, D.A.; McFadden,\
    \ J.P.; Tague, C. Using Imaging Spectrometry to Study Changes in\nCrop Area in\
    \ California’s Central Valley during Drought. Remote Sens. 2018, 10, 1556. [CrossRef]\n\
    95.\nHaboudane, D.; Miller, J.R.; Tremblay, N.; Zarco-Tejada, P.J.; Dextraze,\
    \ L. Integrated narrow-band vegetation\nindices for prediction of crop chlorophyll\
    \ content for application to precision agriculture. Remote Sens. Environ.\n2002,\
    \ 81, 416–426. [CrossRef]\n96.\nLiu, J.; Miller, J.R.; Haboudane, D.; Pattey,\
    \ E.; Hochheim, K. Crop fraction estimation from casi hyperspectral\ndata using\
    \ linear spectral unmixing and vegetation indices. Can. J. Remote Sens. 2008,\
    \ 34, S124–S138.\n[CrossRef]\n97.\nGoel, P.K.; Prasher, S.O.; Landry, J.; Patel,\
    \ R.M.; Viau, A.A. Hyperspectral image classiﬁcation to detect weed\ninfestations\
    \ and nitrogen status in corn. Trans. ASAE 2003, 46, 539.\n98.\nRichter, K.; Hank,\
    \ T.; Mauser, W. Preparatory analyses and development of algorithms for agricultural\n\
    applications in the context of the EnMAP hyperspectral mission. In Proceedings\
    \ of the Remote Sensing\nfor Agriculture, Ecosystems, and Hydrology XII. International\
    \ Society for Optics and Photonics, Toulouse,\nFrance, 22 October 2010; pp. 782407–7824011.\n\
    99.\nJarmer, T. Spectroscopy and hyperspectral imagery for monitoring summer barley.\
    \ Int. J. Remote Sens. 2013,\n34, 6067–6078. [CrossRef]\n100. Thomas, U.; Philippe,\
    \ D.; Christian, B.; Franz, R.; Frédéric, M.; Martin, S.; Miriam, M.; Lucien,\
    \ H. Retrieving\nthe Bioenergy Potential from Maize Crops Using Hyperspectral\
    \ Remote Sensing. Remote Sens. 2013, 5,\n254–273.\n101. Mewes, T.; Franke, J.;\
    \ Menz, G. Spectral requirements on airborne hyperspectral remote sensing data\
    \ for\nwheat disease detection. Precis. Agric. 2011, 12, 795–812. [CrossRef]\n\
    102. Hbirkou, C.; Pätzold, S.; Mahlein, A.; Welp, G. Airborne hyperspectral imaging\
    \ of spatial soil organic carbon\nheterogeneity at the ﬁeld-scale. Geoderma 2012,\
    \ 175–176, 21–28. [CrossRef]\nRemote Sens. 2020, 12, 2659\n38 of 44\n103. Cilia,\
    \ C.; Panigada, C.; Rossini, M.; Meroni, M.; Busetto, L.; Amaducci, S.; Boschetti,\
    \ M.; Picchi, V.;\nColombo, R. Nitrogen Status Assessment for Variable Rate Fertilization\
    \ in Maize through Hyperspectral\nImagery. Remote Sens. 2014, 6, 6549–6565. [CrossRef]\n\
    104. Ambrus, A.; Burai, P.; Lénárt, C.; Enyedi, P.; Kovács, Z. Estimating biomass\
    \ of winter wheat using narrowband\nvegetation indices for precision agriculture.\
    \ J. Cent. Eur. Green Innov. 2015, 3, 13–22.\n105. Oppelt, N.; Mauser, W. Hyperspectral\
    \ monitoring of physiological parameters of wheat during a vegetation\nperiod\
    \ using AVIS data. Int. J. Remote Sens. 2004, 25, 145–159. [CrossRef]\n106. Bannari,\
    \ A.; Pacheco, A.; Staenz, K.; McNairn, H.; Omari, K. Estimating and mapping crop\
    \ residues cover\non agricultural lands using hyperspectral and IKONOS data. Remote\
    \ Sens. Environ. 2006, 104, 447–459.\n[CrossRef]\n107. Van Wesemael, B.; Tychon,\
    \ B.; Bartholomeus, H.; Kooistra, L.; van Leeuwen, M.; Stevens, A.; Ben-Dor, E.\
    \ Soil\nOrganic Carbon mapping of partially vegetated agricultural ﬁelds with\
    \ imaging spectroscopy. Int. J. Appl.\nEarth Obs. 2011, 13, 81–88.\n108. Finn,\
    \ M.P.; Lewis, M.D.; Bosch, D.D.; Giraldo, M.; Yamamoto, K.; Sullivan, D.G.; Kincaid,\
    \ R.; Luna, R.;\nAllam, G.K.; Kvien, C.; et al.\nRemote Sensing of Soil Moisture\
    \ Using Airborne Hyperspectral Data.\nGisci. Remote Sens. 2011, 48, 522–540. [CrossRef]\n\
    109. Xie, Q.; Huang, W.; Liang, D.; Chen, P.; Wu, C.; Yang, G.; Zhang, J.; Huang,\
    \ L.; Zhang, D. Leaf Area\nIndex Estimation Using Vegetation Indices Derived From\
    \ Airborne Hyperspectral Images in Winter Wheat.\nIEEE J. STARS 2014, 7, 3586–3594.\
    \ [CrossRef]\n110. Castaldi, F.; Chabrillat, S.; Jones, A.; Vreys, K.; Bomans,\
    \ B.; van Wesemael, B. Soil Organic Carbon Estimation\nin Croplands by Hyperspectral\
    \ Remote APEX Data Using the LUCAS Topsoil Database. Remote Sens. 2018,\n10, 153.\
    \ [CrossRef]\n111. Luo, S.; Wang, C.; Xi, X.; Zeng, H.; Li, D.; Xia, S.; Wang,\
    \ P. Fusion of Airborne Discrete-Return LiDAR and\nHyperspectral Data for Land\
    \ Cover Classiﬁcation. Remote Sens. 2016, 8, 3. [CrossRef]\n112. Mart, L.; Tard,\
    \ A.; Pal, V.; Arbiol, R. Atmospheric correction algorithm applied to CASI multi-height\n\
    hyperspectral imagery. Parameters 2006, 1, 4.\n113. AVIRIS Data—New Data Acquisitions.\
    \ Available online: https://aviris.jpl.nasa.gov/data/newdata.html\n(accessed on\
    \ 1 August 2020).\n114. Lu, B.; He, Y. Species classiﬁcation using Unmanned Aerial\
    \ Vehicle (UAV)-acquired high spatial resolution\nimagery in a heterogeneous grassland.\
    \ ISPRS J. Photogramm. 2017, 128, 73–85. [CrossRef]\n115. Casa, R.; Pascucci,\
    \ S.; Pignatti, S.; Palombo, A.; Nanni, U.; Harfouche, A.; Laura, L.; Di Rocco,\
    \ M.; Fantozzi, P.\nUAV-based hyperspectral imaging for weed discrimination in\
    \ maize. In Precision Agriculture ‘19; Staﬀord, J.V.,\nEd.; Wageningen Academic\
    \ Publishers: Wageningen, The Netherlands, 2019; pp. 24–35.\n116. Dao, P.D.; He,\
    \ Y.; Lu, B. Maximizing the quantitative utility of airborne hyperspectral imagery\
    \ for studying\nplant physiology: An optimal sensor exposure setting procedure\
    \ and empirical line method for atmospheric\ncorrection. Int. J. Appl. Earth Obs.\
    \ 2019, 77, 140–150. [CrossRef]\n117. Capolupo, A.; Kooistra, L.; Berendonk, C.;\
    \ Boccia, L.; Suomalainen, J. Estimating plant traits of grasslands\nfrom UAV-acquired\
    \ hyperspectral images: A comparison of statistical approaches. ISPRS Int. J.\
    \ Geo Inf. 2015,\n4, 2792–2820. [CrossRef]\n118. Lu, B.; He, Y. Optimal spatial\
    \ resolution of Unmanned Aerial Vehicle (UAV)-acquired imagery for species\nclassiﬁcation\
    \ in a heterogeneous grassland ecosystem. Gisci. Remote Sens. 2018, 55, 205–220.\
    \ [CrossRef]\n119. Bohnenkamp, D.; Behmann, J.; Mahlein, A. In-Field Detection\
    \ of Yellow Rust in Wheat on the Ground\nCanopy and UAV Scale. Remote Sens. 2019,\
    \ 11, 2495. [CrossRef]\n120. Habib, A.; Han, Y.; Xiong, W.; He, F.; Zhang, Z.;\
    \ Crawford, M. Automated Ortho-Rectiﬁcation of UAV-Based\nHyperspectral Data over\
    \ an Agricultural Field Using Frame RGB Imagery. Remote Sens. 2016, 8, 796.\n\
    [CrossRef]\n121. Honkavaara, E.; Saari, H.; Kaivosoja, J.; Pölönen, I.; Hakala,\
    \ T.; Litkey, P.; Mäkynen, J.; Pesonen, L. Processing\nand assessment of spectrometric,\
    \ stereoscopic imagery collected using a lightweight UAV spectral camera\nfor\
    \ precision agriculture. Remote Sens. 2013, 5, 5006–5039. [CrossRef]\n122. Saari,\
    \ H.; Pellikka, I.; Pesonen, L.; Tuominen, S.; Heikkila, J.; Holmlund, C.; Makynen,\
    \ J.; Ojala, K.; Antila, T.\nUnmanned Aerial Vehicle (UAV) operated spectral camera\
    \ system for forest and agriculture applications.\nIn Proceedings of the Remote\
    \ Sensing for Agriculture, Ecosystems, and Hydrology XIII. International Society\n\
    for Optics and Photonics, Prague, Czech Republic, 6 October 2011; Volume 8174.\n\
    Remote Sens. 2020, 12, 2659\n39 of 44\n123. Honkavaara, E.; Kaivosoja, J.; Mäkynen,\
    \ J.; Pellikka, I.; Pesonen, L.; Saari, H.; Salo, H.; Hakala, T.; Marklelin, L.;\n\
    Rosnell, T. Hyperspectral reﬂectance signatures and point clouds for precision\
    \ agriculture by light weight\nUAV imaging system. ISPRS Ann. Photogramm. Remote\
    \ Sens. Spat. Inf. Sci. 2012, 7, 353–358. [CrossRef]\n124. Yue, J.; Yang, G.;\
    \ Li, C.; Li, Z.; Wang, Y.; Feng, H.; Xu, B. Estimation of Winter Wheat Above-Ground\
    \ Biomass\nUsing Unmanned Aerial Vehicle-Based Snapshot Hyperspectral Sensor and\
    \ Crop Height Improved Models.\nRemote Sens. 2017, 9, 708. [CrossRef]\n125. Pölönen,\
    \ I.; Saari, H.; Kaivosoja, J.; Honkavaara, E.; Pesonen, L. Hyperspectral imaging\
    \ based biomass and\nnitrogen content estimations from light-weight UAV. In Proceedings\
    \ of the Remote Sensing for Agriculture,\nEcosystems, and Hydrology XV. International\
    \ Society for Optics and Photonics, Dresden, Germany, 16 October\n2013; p. 88870J.\n\
    126. Kaivosoja, J.; Pesonen, L.; Kleemola, J.; Pölönen, I.; Salo, H.; Honkavaara,\
    \ E.; Saari, H.; Mäkynen, J.; Rajala, A.\nA case study of a precision fertilizer\
    \ application task generation for wheat based on classiﬁed hyperspectral\ndata\
    \ from UAV combined with farm history data. In Proceedings of the SPIE Remote\
    \ Sensing, Dresden,\nGermany, 24–26 September 2013; pp. 1–11.\n127. Akhtman, Y.;\
    \ Golubeva, E.; Tutubalina, O.; Zimin, M. Application of hyperspectural images\
    \ and ground data\nfor precision farming. Geogr. Environ. Sustain. 2017, 10, 117–128.\
    \ [CrossRef]\n128. Izzo, R.R.; Lakso, A.N.; Marcellus, E.D.; Bauch, T.D.; Raqueno,\
    \ N.G.; van Aardt, J. An initial analysis of\nreal-time sUAS-based detection of\
    \ grapevine water status in the Finger Lakes Wine Country of Upstate\nNew York.\
    \ In Proceedings of the Autonomous Air and Ground Sensing Systems for Agricultural\
    \ Optimization and\nPhenotyping IV; International Society for Optics and Photonics:\
    \ Baltimore, MD, USA, 2019.\n129. Scherrer, B.; Sheppard, J.; Jha, P.; Shaw, J.A.\
    \ Hyperspectral imaging and neural networks to classify\nherbicide-resistant weeds.\
    \ J. Appl. Remote Sens. 2019, 13, 044516. [CrossRef]\n130. Yue, J.; Feng, H.;\
    \ Jin, X.; Yuan, H.; Li, Z.; Zhou, C.; Yang, G.; Tian, Q. A Comparison of Crop\
    \ Parameters\nEstimation Using Images from UAV-Mounted Snapshot Hyperspectral\
    \ Sensor and High-Deﬁnition Digital\nCamera. Remote Sens. 2018, 10, 1138. [CrossRef]\n\
    131. Dalponte, M.; Orka, H.O.; Gobakken, T.; Gianelle, D.; Naesset, E. Tree Species\
    \ Classiﬁcation in Boreal Forests\nwith Hyperspectral Data. IEEE Trans. Geosci.\
    \ Remote 2013, 51, 2632–2645. [CrossRef]\n132. Aasen, H.; Bendig, J.; Bolten,\
    \ A.; Bennertz, S.; Willkomm, M.; Bareth, G. Introduction and preliminary results\n\
    of a calibration for full-frame hyperspectral cameras to monitor agricultural\
    \ crops with UAVs. Int. Arch.\nPhotogramm. Remote Sens. Spat. Inf. Sci. 2014,\
    \ XL-7, 1–8. [CrossRef]\n133. Zhu, W.; Sun, Z.; Huang, Y.; Lai, J.; Li, J.; Zhang,\
    \ J.; Yang, B.; Li, B.; Li, S.; Zhu, K.; et al. Improving Field-Scale\nWheat LAI\
    \ Retrieval Based on UAV Remote-Sensing Observations and Optimized VI-LUTs. Remote\
    \ Sens.\n2019, 11, 2456. [CrossRef]\n134. Zhao, J.; Zhong, Y.; Hu, X.; Wei, L.;\
    \ Zhang, L. A robust spectral-spatial approach to identifying heterogeneous\n\
    crops using remote sensing imagery with high spectral and spatial resolutions.\
    \ Remote Sens. Environ. 2020,\n239, 111605. [CrossRef]\n135. Zarco-Tejada, P.J.;\
    \ González-Dugo, V.; Berni, J.A.J. Fluorescence, temperature and narrow-band indices\n\
    acquired from a UAV platform for water stress detection using a micro-hyperspectral\
    \ imager and a thermal\ncamera. Remote Sens. Environ. 2012, 117, 322–337. [CrossRef]\n\
    136. Lu, B.; He, Y.; Liu, H.H.T. Mapping vegetation biophysical and biochemical\
    \ properties using unmanned\naerial vehicles-acquired imagery. Int. J. Remote\
    \ Sens. 2018, 39, 5265–5287. [CrossRef]\n137. Malmir, M.; Tahmasbian, I.; Xu,\
    \ Z.; Farrar, M.B.; Bai, S.H. Prediction of soil macro- and micro-elements in\n\
    sieved and ground air-dried soils using laboratory-based hyperspectral imaging\
    \ technique. Geoderma 2019,\n340, 70–80. [CrossRef]\n138. Van de Vijver, R.; Mertens,\
    \ K.; Heungens, K.; Somers, B.; Nuyttens, D.; Borra-Serrano, I.; Lootens, P.;\n\
    Roldan-Ruiz, I.; Vangeyte, J.; Saeys, W. In-ﬁeld detection of Altemaria solani\
    \ in potato crops using\nhyperspectral imaging. Comput. Electron. Agric. 2020,\
    \ 168, 105106. [CrossRef]\n139. Eddy, P.R.; Smith, A.M.; Hill, B.D.; Peddle, D.R.;\
    \ Coburn, C.A.; Blackshaw, R.E. Hybrid segmentation -\nArtiﬁcial Neural Network\
    \ classiﬁcation of high resolution hyperspectral imagery for Site-Speciﬁc Herbicide\n\
    Management in agriculture. Photogramm. Eng. Remote Sens. 2008, 74, 1249–1257.\
    \ [CrossRef]\n140. Feng, H.; Chen, G.; Xiong, L.; Liu, Q.; Yang, W. Accurate Digitization\
    \ of the Chlorophyll Distribution\nof Individual Rice Leaves Using Hyperspectral\
    \ Imaging and an Integrated Image Analysis Pipeline.\nFront. Plant Sci. 2017,\
    \ 8, 1238. [CrossRef]\nRemote Sens. 2020, 12, 2659\n40 of 44\n141. Asaari, M.S.M.;\
    \ Mishra, P.; Mertens, S.; Dhondt, S.; Inzé, D.; Wuyts, N.; Scheunders, P. Close-range\n\
    hyperspectral image analysis for the early detection of stress responses in individual\
    \ plants in a\nhigh-throughput phenotyping platform. ISPRS J. Photogramm. 2018,\
    \ 138, 121–138. [CrossRef]\n142. Zhu, W.; Li, J.; Li, L.; Wang, A.; Wei, X.; Mao,\
    \ H. Nondestructive diagnostics of soluble sugar, total nitrogen\nand their ratio\
    \ of tomato leaves in greenhouse by polarized spectra–hyperspectra Introduction\
    \ to the pls\nPackage l data fusion. Int. J. Agric. Biol. Eng. 2020, 13, 189–197.\n\
    143. Morel, J.; Jay, S.; Féret, J.; Bakache, A.; Bendoula, R.; Carreel, F.; Gorretta,\
    \ N. Exploring the potential of\nPROCOSINE and close-range hyperspectral imaging\
    \ to study the eﬀects of fungal diseases on leaf physiology.\nSci. Rep. 2018,\
    \ 8, 1–13. [CrossRef] [PubMed]\n144. Nagasubramanian, K.; Jones, S.; Singh, A.K.;\
    \ Sarkar, S.; Singh, A.; Ganapathysubramanian, B. Plant disease\nidentiﬁcation\
    \ using explainable 3D deep learning on hyperspectral images. Plant Methods 2019,\
    \ 15, 98.\n[CrossRef] [PubMed]\n145. Lopatin, J.; Fassnacht, F.E.; Kattenborn,\
    \ T.; Schmidtlein, S. Mapping plant species in mixed grassland\ncommunities using\
    \ close range imaging spectroscopy. Remote Sens. Environ. 2017, 201, 12–23. [CrossRef]\n\
    146. Behmann, J.; Mahlein, A.; Paulus, S.; Dupuis, J.; Kuhlmann, H.; Oerke, E.;\
    \ Plümer, L. Generation and\napplication of hyperspectral 3D plant models: Methods\
    \ and challenges. Mach. Vis. Appl. 2016, 27, 611–624.\n[CrossRef]\n147. Antonucci,\
    \ F.; Menesatti, P.; Holden, N.M.; Canali, E.; Giorgi, S.; Maienza, A.; Stazi,\
    \ S.R. Hyperspectral Visible\nand Near-Infrared Determination of Copper Concentration\
    \ in Agricultural Polluted Soils. Commun. Soil\nSci. Plan. 2012, 43, 1401–1411.\
    \ [CrossRef]\n148. Wan, P.; Yang, G.; Xu, B.; Feng, H.; Yu, H. Geometric Correction\
    \ Method of Rotary Scanning Hyperspectral\nImage in Agriculture Application. In\
    \ Proceedings of the Conferences of the Photoelectronic Technology\nCommittee\
    \ of the Chinese Society of Astronautics, Beijing, China, 13–15 May 2014.\n149.\
    \ Yeh, Y.; Chung, W.; Liao, J.; Chung, C.; Kuo, Y.; Lin, T. Strawberry foliar\
    \ anthracnose assessment by\nhyperspectral imaging. Comput. Electron. Agric. 2016,\
    \ 122, 1–9. [CrossRef]\n150. Liu, Y.; Wang, T.; Ma, L.; Wang, N. Spectral calibration\
    \ of hyperspectral data observed from a\nhyperspectrometer loaded on an Unmanned\
    \ Aerial Vehicle platform.\nIEEE J. Sel.\nTop.\nAppl.\nEarth\nObs. Remote Sens.\
    \ 2014, 7, 2630–2638.\n151. Miglani, A.; Ray, S.S.; Pandey, R.; Parihar, J.S.\
    \ Evaluation of EO-1 hyperion data for agricultural applications.\nJ. Indian Soc.\
    \ Remote 2008, 36, 255–266. [CrossRef]\n152. Amato, U.; Antoniadis, A.; Carfora,\
    \ M.F.; Colandrea, P.; Cuomo, V.; Franzese, M.; Pignatti, S.; Serio, C.\nStatistical\
    \ Classiﬁcation for Assessing PRISMA Hyperspectral Potential for Agricultural\
    \ Land Use.\nIEEE J. STARS 2013, 6, 615–625. [CrossRef]\n153. Thenkabail, P.S.;\
    \ Gumma, M.K.; Teluguntla, P.; Mohammed, I.A. Hyperspectral remote sensing of\
    \ vegetation\nand agricultural crops. Photogramm. Eng. Remote Sens. J. Am. Soc.\
    \ Photogramm. 2014, 80, 697–709.\n154. Wang, Y.; Yao, H.; Zhao, S. Auto-encoder\
    \ based dimensionality reduction. Neurocomputing 2016, 184, 232–242.\n[CrossRef]\n\
    155. Hsu, P.; Tseng, Y.; Gong, P. Dimension Reduction of Hyperspectral Images\
    \ for Classiﬁcation Applications.\nGeogr. Inf. Sci. 2002, 8, 1–8. [CrossRef]\n\
    156. Abdolmaleki, M.; Fathianpour, N.; Tabaei, M. Evaluating the performance of\
    \ the wavelet transform in\nextracting spectral alteration features from hyperspectral\
    \ images. Int. J. Remote Sens. 2018, 39, 6076–6094.\n[CrossRef]\n157. Cao, X.;\
    \ Yao, J.; Fu, X.; Bi, H.; Hong, D. An Enhanced 3-D Discrete Wavelet Transform\
    \ for Hyperspectral\nImage Classiﬁcation. IEEE Geosci. Remote Soc. 2020, 1–5.\
    \ [CrossRef]\n158. Prabhakar, T.V.N.; Geetha, P. Two-dimensional empirical wavelet\
    \ transform based supervised hyperspectral\nimage classiﬁcation. ISPRS J. Photogramm.\
    \ 2017, 133, 37–45. [CrossRef]\n159. Geng, X.; Sun, K.; Ji, L.; Zhao, Y. A Fast\
    \ Volume-Gradient-Based Band Selection Method for Hyperspectral\nImage. IEEE Trans.\
    \ Geosci. Remote 2014, 52, 7111–7119. [CrossRef]\n160. Wang, C.; Gong, M.; Zhang,\
    \ M.; Chan, Y. Unsupervised Hyperspectral Image Band Selection via Column\nSubset\
    \ Selection. IEEE Geosci. Remote Soc. 2015, 12, 1411–1415. [CrossRef]\n161. Wang,\
    \ Q.; Lin, J.; Yuan, Y. Salient Band Selection for Hyperspectral Image Classiﬁcation\
    \ via Manifold Ranking.\nIEEE Trans. Neural Netw. Learn. Syst. 2016, 27, 1279–1289.\
    \ [CrossRef]\nRemote Sens. 2020, 12, 2659\n41 of 44\n162. Thenkabail, P.S.; Smith,\
    \ R.B.; De Pauw, E. Hyperspectral vegetation indices and their relationships with\n\
    agricultural crop characteristics. Remote Sens. Environ. 2000, 71, 158–182. [CrossRef]\n\
    163. Nevalainen, O.; Hakala, T.; Suomalainen, J.; Kaasalainen, S. Nitrogen concentration\
    \ estimation with\nhyperspectral LiDAR. ISPRS Ann. Photogramm. Remote Sens. Spat.\
    \ Inf. Sci. 2013, 2, 205–210. [CrossRef]\n164. Huang, W.; Lamb, D.W.; Niu, Z.;\
    \ Zhang, Y.; Liu, L.; Wang, J. Identiﬁcation of yellow rust in wheat using\nin-situ\
    \ spectral reﬂectance measurements and airborne hyperspectral imaging. Precis.\
    \ Agric. 2007, 8, 187–197.\n[CrossRef]\n165. Tong, A.; He, Y. Estimating and mapping\
    \ chlorophyll content for a heterogeneous grassland: Comparing\nprediction power\
    \ of a suite of vegetation indices across scales between years. ISPRS J. Photogramm.\
    \ 2017, 126,\n146–167. [CrossRef]\n166. Haboudane, D.; Tremblay, N.; Miller, J.R.;\
    \ Vigneault, P. Remote estimation of crop chlorophyll content using\nspectral\
    \ indices derived from hyperspectral data. IEEE T. Geosci. Remote 2008, 46, 423–437.\
    \ [CrossRef]\n167. Main, R.; Cho, M.A.; Mathieu, R.; O’Kennedy, M.M.; Ramoelo,\
    \ A.; Koch, S. An investigation into robust\nspectral indices for leaf chlorophyll\
    \ estimation. ISPRS J. Photogramm. 2011, 66, 751–761. [CrossRef]\n168. Peng, Y.;\
    \ Gitelson, A.A. Remote estimation of gross primary productivity in soybean and\
    \ maize based on\ntotal crop chlorophyll content. Remote Sens. Environ. 2012,\
    \ 117, 440–448. [CrossRef]\n169. Croft, H.; Chen, J.M.; Zhang, Y. The applicability\
    \ of empirical vegetation indices for determining leaf\nchlorophyll content over\
    \ diﬀerent leaf and canopy structures. Ecol. Complex. 2014, 17, 119–130. [CrossRef]\n\
    170. Zhou, X.; Huang, W.; Kong, W.; Ye, H.; Luo, J.; Chen, P. Remote estimation\
    \ of canopy nitrogen content in\nwinter wheat using airborne hyperspectral reﬂectance\
    \ measurements. Adv. Space Res. 2016, 58, 1627–1637.\n[CrossRef]\n171. Yue, J.;\
    \ Feng, H.; Yang, G.; Li, Z. A comparison of regression techniques for estimation\
    \ of above-ground\nwinter wheat biomass using near-surface spectroscopy. Remote\
    \ Sens. 2018, 10, 66. [CrossRef]\n172. Hansen, P.M.; Schjoerring, J.K. Reﬂectance\
    \ measurement of canopy biomass and nitrogen status in wheat crops\nusing normalized\
    \ diﬀerence vegetation indices and partial least squares regression. Remote Sens.\
    \ Environ.\n2003, 86, 542–553. [CrossRef]\n173. Nguyen, H.T.; Lee, B. Assessment\
    \ of rice leaf growth and nitrogen status by hyperspectral canopy reﬂectance\n\
    and partial least square regression. Eur. J. Agron. 2006, 24, 349–356. [CrossRef]\n\
    174. Pedregosa, F.; Varoquaux, G.; Gramfort, A.; Michel, V.; Thirion, B.; Grisel,\
    \ O.; Blondel, M.; Prettenhofer, P.;\nWeiss, R.; Dubourg, V.; et al. Scikit-learn:\
    \ Machine learning in Python. Mach. Learn. 2011, 12, 2825–2830.\n175. Mevik, B.;\
    \ Wehrens, R. Introduction to the PLS Package. Help Sect. “Pls” Package R Studio\
    \ Softw; R Found. Stat.\nComput.: Vienna, Austria, 2015; pp. 1–23.\n176. Asner,\
    \ G.P.; Martin, R.E.; Anderson, C.B.; Knapp, D.E. Quantifying forest canopy traits:\
    \ Imaging spectroscopy\nversus ﬁeld survey. Remote Sens. Environ. 2015, 158, 15–27.\
    \ [CrossRef]\n177. Kiala, Z.; Odindi, J.; Mutanga, O. Potential of interval partial\
    \ least square regression in estimating leaf area\nindex. S. Afr. J. Sci. 2017,\
    \ 113, 40–48. [CrossRef]\n178. Wang, Z.; Kawamura, K.; Sakuno, Y.; Fan, X.; Gong,\
    \ Z.; Lim, J. Retrieval of Chlorophyll-a and Total Suspended\nSolids Using Iterative\
    \ Stepwise Elimination Partial Least Squares (ISE-PLS) Regression Based on Field\n\
    Hyperspectral Measurements in Irrigation Ponds in Higashihiroshima, Japan. Remote\
    \ Sens. 2017, 9, 264.\n[CrossRef]\n179. Mehmood, T.; Ahmed, B. The diversity in\
    \ the applications of partial least squares: An overview. J. Chemometr.\n2016,\
    \ 30, 4–17. [CrossRef]\n180. Jacquemoud, S.; Baret, F. PROSPECT—A model of leaf\
    \ optical-properties spectra. Remote Sens. Environ. 1990,\n34, 75–91. [CrossRef]\n\
    181. Jacquemoud, S.; Bacour, C.; Poilve, H.; Frangi, J.P. Comparison of four radiative\
    \ transfer models to simulate\nplant canopies reﬂectance: Direct and inverse mode.\
    \ Remote Sens. Environ. 2000, 74, 471–481. [CrossRef]\n182. Casa, R.; Jones, H.G.\
    \ Retrieval of crop canopy properties: A comparison between model inversion from\n\
    hyperspectral data and image classiﬁcation. Int. J. Remote Sens. 2004, 25, 1119–1130.\
    \ [CrossRef]\n183. Richter, K.; Hank, T.; Atzberger, C.; Locherer, M.; Mauser,\
    \ W. Regularization strategies for agricultural\nmonitoring: The EnMAP vegetation\
    \ analyzer (AVA). In Proceedings of the 2012 IEEE International Geoscience\nand\
    \ Remote Sensing Symposium, Munich, Germany, 22–27 July 2012; pp. 6613–6616.\n\
    184. Wu, C.; Wang, L.; Niu, Z.; Gao, S.; Wu, M. Nondestructive estimation of canopy\
    \ chlorophyll content using\nHyperion and Landsat/TM images. Int. J. Remote Sens.\
    \ 2010, 31, 2159–2167. [CrossRef]\nRemote Sens. 2020, 12, 2659\n42 of 44\n185.\
    \ Darvishzadeh, R.; Atzberger, C.; Skidmore, A.; Schlerf, M. Mapping grassland\
    \ leaf area index with airborne\nhyperspectral imagery: A comparison study of\
    \ statistical approaches and inversion of radiative transfer\nmodels. ISPRS J.\
    \ Photogramm. 2011, 66, 894–906. [CrossRef]\n186. Breiman, L. Random forests.\
    \ Mach. Learn. 2001, 45, 5–32. [CrossRef]\n187. Were, K.; Bui, D.T.; Dick, O.B.;\
    \ Singh, B.R. A comparative assessment of support vector regression, artiﬁcial\n\
    neural networks, and random forests for predicting and mapping soil organic carbon\
    \ stocks across an\nAfromontane landscape. Ecol. Indic. 2015, 52, 394–403. [CrossRef]\n\
    188. Gao, J.; Nuyttens, D.; Lootens, P.; He, Y.; Pieters, J.G. Recognising weeds\
    \ in a maize crop using a random\nforest machine-learning algorithm and near-infrared\
    \ snapshot mosaic hyperspectral imagery. Biosyst. Eng.\n2018, 170, 39–50. [CrossRef]\n\
    189. Siegmann, B.; Jarmer, T. Comparison of diﬀerent regression models and validation\
    \ techniques for the\nassessment of wheat leaf area index from hyperspectral data.\
    \ Int. J. Remote Sens. 2015, 36, 4519–4534.\n[CrossRef]\n190. Adam, E.; Deng,\
    \ H.; Odindi, J.; Abdel-Rahman, E.M.; Mutanga, O. Detecting the Early Stage of\
    \ Phaeosphaeria\nLeaf Spot Infestations in Maize Crop Using In Situ Hyperspectral\
    \ Data and Guided Regularized Random\nForest Algorithm. J. Spectrosc. 2017, 2017,\
    \ 1–8. [CrossRef]\n191. Kamilaris, A.; Prenafeta-Boldú, F.X. Deep learning in\
    \ agriculture: A survey. Comput. Electron. Agric. 2018,\n147, 70–90. [CrossRef]\n\
    192. Yuan, Q.; Shen, H.; Li, T.; Li, Z.; Li, S.; Jiang, Y.; Xu, H.; Tan, W.; Yang,\
    \ Q.; Wang, J.; et al. Deep learning\nin environmental remote sensing: Achievements\
    \ and challenges. Remote Sens. Environ. 2020, 241, 111716.\n[CrossRef]\n193. Sharma,\
    \ A.; Liu, X.; Yang, X. Land cover classiﬁcation from multi-temporal, multi-spectral\
    \ remotely sensed\nimagery using patch-based recurrent neural networks. Neural\
    \ Netw. 2018, 105, 346–355. [CrossRef]\n194. Zhang, C.; Sargent, I.; Pan, X.;\
    \ Li, H.; Gardiner, A.; Hare, J.; Atkinson, P.M. Joint Deep Learning for land\n\
    cover and land use classiﬁcation. Remote Sens. Environ. 2019, 221, 173–187. [CrossRef]\n\
    195. Rezaee, M.; Mahdianpari, M.; Zhang, Y.; Salehi, B. Deep Convolutional Neural\
    \ Network for Complex Wetland\nClassiﬁcation Using Optical Remote Sensing Imagery.\
    \ IEEE J. STARS 2018, 11, 3030–3039. [CrossRef]\n196. Xu, Y.; Wu, L.; Xie, Z.;\
    \ Chen, Z. Building Extraction in Very High Resolution Remote Sensing Imagery\
    \ Using\nDeep Learning and Guided Filters. Remote Sens. 2018, 10, 144. [CrossRef]\n\
    197. Kuwata, K.; Shibasaki, R. Estimating crop yields with deep learning and remotely\
    \ sensed data. In Proceedings\nof the 2015 IEEE International Geoscience and Remote\
    \ Sensing Symposium (IGARSS), Milan, Italy, 26–31\nJuly 2015; pp. 858–861.\n198.\
    \ Mohanty, S.P.; Hughes, D.P.; Salathé, M. Using Deep Learning for Image-Based\
    \ Plant Disease Detection.\nFront. Plant Sci. 2016, 7, 1419. [CrossRef] [PubMed]\n\
    199. Ji, S.; Zhang, C.; Xu, A.; Shi, Y.; Duan, Y. 3D Convolutional Neural Networks\
    \ for Crop Classiﬁcation with\nMulti-Temporal Remote Sensing Images. Remote Sens.\
    \ 2018, 10, 75. [CrossRef]\n200. Ndikumana, E.; Ho Tong Minh, D.; Baghdadi, N.;\
    \ Courault, D.; Hossard, L. Deep Recurrent Neural Network\nfor Agricultural Classiﬁcation\
    \ using multitemporal SAR Sentinel-1 for Camargue, France. Remote Sens. 2018,\n\
    10, 1217. [CrossRef]\n201. Singh, A.K.; Ganapathysubramanian, B.; Sarkar, S.;\
    \ Singh, A. Deep Learning for Plant Stress Phenotyping:\nTrends and Future Perspectives.\
    \ Trends Plant Sci. 2018, 23, 883–898. [CrossRef]\n202. Chlingaryan, A.; Sukkarieh,\
    \ S.; Whelan, B. Machine learning approaches for crop yield prediction and\nnitrogen\
    \ status estimation in precision agriculture: A review. Comput. Electron. Agric.\
    \ 2018, 151, 61–69.\n[CrossRef]\n203. Song, X.; Zhang, G.; Liu, F.; Li, D.; Zhao,\
    \ Y.; Yang, J. Modeling spatio-temporal distribution of soil moisture\nby deep\
    \ learning-based cellular automata model. J. Arid Land 2016, 8, 734–748. [CrossRef]\n\
    204. Moharana, S.; Dutta, S. Estimation of water stress variability for a rice\
    \ agriculture system from space-borne\nhyperion imagery. Agr. Water Manag. 2019,\
    \ 213, 260–269. [CrossRef]\n205. Yang, C. Airborne Hyperspectral Imagery for Mapping\
    \ Crop Yield Variability. Geogr. Compass 2009, 3,\n1717–1731. [CrossRef]\n206.\
    \ Zimdahl, R.L. Six Chemicals That Changed Agriculture; Academic Press: Cambridge,\
    \ MA, USA, 2015.\nRemote Sens. 2020, 12, 2659\n43 of 44\n207. Goel, P.K.; Prasher,\
    \ S.O.; Landry, J.A.; Patel, R.M.; Bonnell, R.B.; Viau, A.A.; Miller, J.R. Potential\n\
    of airborne hyperspectral remote sensing to detect nitrogen deﬁciency and weed\
    \ infestation in corn.\nComput. Electron. Agric. 2003, 38, 99–124. [CrossRef]\n\
    208. Quemada, M.; Gabriel, J.; Zarco-Tejada, P. Airborne Hyperspectral Images\
    \ and Ground-Level Optical Sensors\nAs Assessment Tools for Maize Nitrogen Fertilization.\
    \ Remote Sens. 2014, 6, 2940–2962. [CrossRef]\n209. Koppe, W.; Laudien, R.; Gnyp,\
    \ M.L.; Jia, L.; Li, F.; Chen, X.; Bareth, G. Deriving winter wheat characteristics\n\
    from combined radar and hyperspectral data analysis. In Proceedings of the Geoinformatics,\
    \ Wuhan, China,\n28–29 October 2006; Remotely Sensed Data and Information. SPIE-INT\
    \ SOC Optical Engineering: Bellingham,\nWA, USA, 2006.\n210. Castaldi, F.; Castrignano,\
    \ A.; Casa, R. A data fusion and spatial data analysis approach for the estimation\
    \ of\nwheat grain nitrogen uptake from satellite data. Int. J. Remote Sens. 2016,\
    \ 37, 4317–4336. [CrossRef]\n211. Zheng, H.; Zhou, X.; Cheng, T.; Yao, X.; Tian,\
    \ Y.; Cao, W.; Zhu, Y. Evaluation of a uav-based hyperspectral\nframe camera for\
    \ monitoring the leaf nitrogen concentration in rice. In Proceedings of the IEEE\
    \ International\nSymposium on Geoscience and Remote Sensing IGARSS, Beijing, China,\
    \ 10–15 July 2016; pp. 7350–7353.\n212. Zhou, K.; Cheng, T.; Zhu, Y.; Cao, W.;\
    \ Ustin, S.L.; Zheng, H.; Yao, X.; Tian, Y. Assessing the Impact of Spatial\n\
    Resolution on the Estimation of Leaf Nitrogen Concentration Over the Full Season\
    \ of Paddy Rice Using\nNear-Surface Imaging Spectroscopy Data. Front. Plant Sci.\
    \ 2018, 9, 964. [CrossRef] [PubMed]\n213. Nasi, R.; Viljanen, N.; Kaivosoja, J.;\
    \ Alhonoja, K.; Hakala, T.; Markelin, L.; Honkavaara, E. Estimating Biomass\n\
    and Nitrogen Amount of Barley and Grass Using UAV and Aircraft Based Spectral\
    \ and Photogrammetric 3D\nFeatures. Remote Sens. 2018, 10, 1082. [CrossRef]\n\
    214. Nigon, T.J.; Mulla, D.J.; Rosen, C.J.; Cohen, Y.; Alchanatis, V.; Knight,\
    \ J.; Rud, R. Hyperspectral aerial imagery\nfor detecting nitrogen stress in two\
    \ potato cultivars. Comput. Electron. Agric. 2015, 112, 36–46. [CrossRef]\n215.\
    \ Chen, S.; Chen, C.; Wang, C.; Yang, I.; Hsiao, S. Evaluation of nitrogen content\
    \ in cabbage seedlings using\nhyper-spectral images. In Proceedings of the Optics\
    \ East, Boston, MA, USA, 9–12 September 2007; p. L7610.\n216. Miphokasap, P.;\
    \ Wannasiri, W. Estimations of Nitrogen Concentration in Sugarcane Using Hyperspectral\n\
    Imagery. Sustainability 2018, 10, 1266. [CrossRef]\n217. Malmir, M.; Tahmasbian,\
    \ I.; Xu, Z.; Farrar, M.B.; Bai, S.H. Prediction of macronutrients in plant leaves\
    \ using\nchemometric analysis and wavelength selection. J. Soil. Sediment. 2020,\
    \ 20, 249–259. [CrossRef]\n218. Lowe, A.; Harrison, N.; French, A.P. Hyperspectral\
    \ image analysis techniques for the detection and\nclassiﬁcation of the early\
    \ onset of plant disease and stress. Plant Methods 2017, 13, 80. [CrossRef]\n\
    219. Kingra, P.K.; Majumder, D.; Singh, S.P. Application of Remote Sensing and\
    \ Gis in Agriculture and Natural\nResource Management Under Changing Climatic\
    \ Conditions. Agric. Res. J. 2016, 53, 295. [CrossRef]\n220. Karimi, Y.; Prasher,\
    \ S.O.; McNairn, H.; Bonnell, R.B.; Dutilleul, P.; Goel, R.K. Classiﬁcation accuracy\
    \ of\ndiscriminant analysis, artiﬁcial neural networks, and decision trees for\
    \ weed and nitrogen stress detection in\ncorn. Trans. ASAE 2005, 48, 1261–1268.\
    \ [CrossRef]\n221. Zhang, Y.; Slaughter, D.C.; Staab, E.S. Robust hyperspectral\
    \ vision-based classiﬁcation for multi-season weed\nmapping. ISPRS J. Photogramm.\
    \ 2012, 69, 65–73. [CrossRef]\n222. Eddy, P.R.; Smith, A.M.; Hill, B.D.; Peddle,\
    \ D.R.; Coburn, C.A.; Blackshaw, R.E. Weed and crop discrimination\nusing hyperspectral\
    \ image data and reduced bandsets. Can. J. Remote Sens. 2014, 39, 481–490. [CrossRef]\n\
    223. Liu, B.; Li, R.; Li, H.; You, G.; Yan, S.; Tong, Q. Crop/Weed Discrimination\
    \ Using a Field Imaging Spectrometer\nSystem. Sensors 2019, 19, 5154. [CrossRef]\
    \ [PubMed]\n224. LÓPEZ-Granados, F. Weed detection for site-speciﬁc weed management:\
    \ Mapping and real-time approaches.\nWeed Res. 2011, 51, 1–11. [CrossRef]\n225.\
    \ Thomas, S.; Kuska, M.T.; Bohnenkamp, D.; Brugger, A.; Alisaac, E.; Wahabzada,\
    \ M.; Behmann, J.; Mahlein, A.\nBeneﬁts of hyperspectral imaging for plant disease\
    \ detection and plant protection: A technical perspective.\nJ. Plant Dis. Protect.\
    \ 2018, 125, 5–20. [CrossRef]\n226. Bauriegel, E.; Giebel, A.; Geyer, M.; Schmidt,\
    \ U.; Herppich, W.B. Early detection of Fusarium infection in\nwheat using hyper-spectral\
    \ imaging. Comput. Electron. Agric. 2011, 75, 304–312. [CrossRef]\n227. Zhang,\
    \ N.; Pan, Y.; Feng, H.; Zhao, X.; Yang, X.; Ding, C.; Yang, G. Development of\
    \ Fusarium head blight\nclassiﬁcation index using hyperspectral microscopy images\
    \ of winter wheat spikelets. Biosyst. Eng. 2019,\n186, 83–99. [CrossRef]\n228.\
    \ Mahlein, A.; Oerke, E.; Steiner, U.; Dehne, H. Recent advances in sensing plant\
    \ diseases for precision crop\nprotection. Eur. J. Plant Pathol. 2012, 133, 197–209.\
    \ [CrossRef]\nRemote Sens. 2020, 12, 2659\n44 of 44\n229. Casa, R.; Castaldi,\
    \ F.; Pascucci, S.; Basso, B.; Pignatti, S. Geophysical and Hyperspectral Data\
    \ Fusion\nTechniques for In-Field Estimation of Soil Properties. Vadose Zone J.\
    \ 2013, 12, vzj2012.0201. [CrossRef]\n230. Casa, R.; Castaldi, F.; Pascucci, S.;\
    \ Pignatti, S. Potential of hyperspectral remote sensing for ﬁeld scale soil\n\
    mapping and precision agriculture applications. Ital. J. Agron. 2012, 7, 43. [CrossRef]\n\
    231. Gedminas, L.; Martin, S. Soil Organic Matter Mapping Using Hyperspectral\
    \ Imagery and Elevation Data.\nIn IEEE Aerospace Conference Proceedings; IEEE:\
    \ Big Sky, MT, USA, 2019.\n232. Song, X.; Yan, G.; Wan, J.; Liu, L.; Xue, X.;\
    \ Li, C.; Huang, W. Use of airborne hyperspectral imagery to\ninvestigate the\
    \ inﬂuence of soil nitrogen supplies and variable-rate fertilization to winter\
    \ wheat growth.\nIn Proceedings of the SPIE, Florence, Italy, 11 October 2007.\n\
    233. Wang, W.; Li, Z.; Wang, C.; Zheng, D.; Du, H. Prediction of Available Potassium\
    \ Content in Cinnamon Soil\nUsing Hyperspectral Imaging Technology. Spectrosc.\
    \ Spect. Anal. 2019, 39, 1579–1585.\n234. McCann, C.; Repasky, K.S.; Lawrence,\
    \ R.; Powell, S. Multi–temporal mesoscale hyperspectral data of\nmixed agricultural\
    \ and grassland regions for anomaly detection. ISPRS J. Photogramm. 2017, 131,\
    \ 121–133.\n[CrossRef]\n© 2020 by the authors. Licensee MDPI, Basel, Switzerland.\
    \ This article is an open access\narticle distributed under the terms and conditions\
    \ of the Creative Commons Attribution\n(CC BY) license (http://creativecommons.org/licenses/by/4.0/).\n"
  inline_citation: '>'
  journal: Remote sensing (Basel)
  limitations: '>'
  pdf_link: https://www.mdpi.com/2072-4292/12/16/2659/pdf?version=1597839578
  publication_year: 2020
  relevance_score1: 0
  relevance_score2: 0
  title: Recent Advances of Hyperspectral Imaging Technology and Applications in Agriculture
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1186/s13007-017-0233-z
  analysis: '>'
  authors:
  - Amy Lowe
  - Nicola Harrison
  - A. P. French
  citation_count: 354
  full_citation: '>'
  full_text: ">\nLowe et al. Plant Methods  (2017) 13:80 \nDOI 10.1186/s13007-017-0233-z\n\
    REVIEW\nHyperspectral image analysis techniques \nfor the detection and classification\
    \ of the early \nonset of plant disease and stress\nAmy Lowe1,2,3* , Nicola Harrison3,4\
    \ and Andrew P French1,2 \nAbstract \nThis review explores how imaging techniques\
    \ are being developed with a focus on deployment for crop monitoring \nmethods.\
    \ Imaging applications are discussed in relation to both field and glasshouse-based\
    \ plants, and techniques \nare sectioned into ‘healthy and diseased plant classification’\
    \ with an emphasis on classification accuracy, early detec-\ntion of stress, and\
    \ disease severity. A central focus of the review is the use of hyperspectral\
    \ imaging and how this is \nbeing utilised to find additional information about\
    \ plant health, and the ability to predict onset of disease. A summary \nof techniques\
    \ used to detect biotic and abiotic stress in plants is presented, including the\
    \ level of accuracy associated \nwith each method.\nKeywords: Hyperspectral imaging,\
    \ Image analysis techniques, Vegetation Indices, Plant disease and stress, Early\
    \ \ndetection of stress, Hyperspectral image analysis\n© The Author(s) 2017. This\
    \ article is distributed under the terms of the Creative Commons Attribution 4.0\
    \ International License \n(http://creativecommons.org/licenses/by/4.0/), which\
    \ permits unrestricted use, distribution, and reproduction in any medium, \nprovided\
    \ you give appropriate credit to the original author(s) and the source, provide\
    \ a link to the Creative Commons license, \nand indicate if changes were made.\
    \ The Creative Commons Public Domain Dedication waiver (http://creativecommons.org/\n\
    publicdomain/zero/1.0/) applies to the data made available in this article, unless\
    \ otherwise stated.\nBackground\nThe reliable detection and identification of\
    \ plant dis-\nease and plant stress are a current challenge in agricul-\nture\
    \ [4, 5]. Standard existing methods of detection often \nrely on crop agronomists\
    \ manually checking the crop \nfor indicator signs that are already visible. Depending\
    \ on \nthe type of crop and the size of the crop area–which for \nmany commercial\
    \ crops is often very large–this method \nof monitoring plant health is both time\
    \ consuming and \ndemanding. Manual detection also relies on the dis-\nease or\
    \ stress exhibiting clearly visible symptoms, which \nfrequently manifest at middle\
    \ to late stages of infec-\ntion. Identification of the causal agent is through\
    \ either \nmanual detection or diagnostic tests [6]. Diseases usu-\nally start\
    \ in a small region on the foliage (e.g. Septoria \ntritici blotch (STB) of wheat\
    \ caused by the fungal patho-\ngen, Mycosphaerella graminicola; Apple scab caused\
    \ by \nVenturia inaequalis), which can be difficult to detect by \nvisual inspection\
    \ if the crop is large; however, the ability \nto identify the disease at this\
    \ early stage would provide \nan opportunity for early intervention to control,\
    \ pre-\nvent spread of infection, or change crop management \npractices before\
    \ the whole crop is infected or damaged. \nIdentifying crop areas affected by\
    \ disease could also \nlead to targeted application of chemicals. Such precision\
    \ \napproaches would result in the reduction of pesticide and \nherbicide usage,\
    \ with subsequent beneficial impact for \nthe environment, ecosystem services,\
    \ grower finances \nand the end consumer. Hence, there is a keen interest in \n\
    the agricultural and horticultural sector to replace this \nlargely manual process\
    \ with more automated, objec-\ntive, and sensitive approaches. Mahlein has discussed\
    \ \nthe literature on plant disease detection by imaging sen-\nsors. This includes\
    \ RGB, Multi spectral, Hyperspectral, \nthermal, Chlorophyll Fluorescence and\
    \ 3D sensors. One \nconclusion is that RGB and hyperspectral imaging are \npreferable\
    \ for identifying specific diseases [7].\nTo improve crop management and plant\
    \ health, sev-\neral avenues of research are focussing on the identifica-\ntion\
    \ of the onset of adverse stresses, ideally before visible \nsigns are present.\
    \ Image analysis techniques show much \npotential here as they represent non-invasive\
    \ and poten-\ntially autonomous approaches to detect biotic and abiotic \nOpen\
    \ Access\nPlant Methods\n*Correspondence:  psxal4@nottingham.ac.uk \n1 School\
    \ of Biosciences, University of Nottingham,  \nSutton Bonington LE12 5RD, UK\n\
    Full list of author information is available at the end of the article\nPage 2\
    \ of 12\nLowe et al. Plant Methods  (2017) 13:80 \nstress in plants. This is illustrated\
    \ in a recent review by \nSingh et  al. [8] which examines machine learning for\
    \ \nstress phenotyping, exploring literature on high through-\nput phenotyping\
    \ for stress identification, classification, \nquantification and prediction using\
    \ different sensors.\nImage analysis as a research field represents a host of\
    \ \ncomputational techniques which are able to extract infor-\nmation from digital\
    \ images. From a practical point of \nview, this means automatic processing of\
    \ carefully cap-\ntured images to produce a dataset of desired measure-\nments\
    \ from the images. The images themselves can come \nfrom a variety of sources,\
    \ from colour digital cameras or \nsmartphones, to more specialist cameras designed\
    \ to cap-\nture a variety of different information in the images. One \nsuch technological\
    \ advance here is hyperspectral imag-\ning, where cameras capture more than the\
    \ usual three \nbands of coloured light found in traditional digital imag-\ning.\
    \ This review will specifically focus on the subsequent \nanalysis approach known\
    \ as hyperspectral image analy-\nsis. This approach has recently become financially\
    \ acces-\nsible to a wide variety of users, due to falling technology \ncosts.\
    \ Analysis approaches are being developed which \nare enabling the Hyperspectral\
    \ imaging technologies to \nbe utilised for wider ranging applications. Hyperspectral\
    \ \nimaging uses high-fidelity colour reflectance information \nover a large range\
    \ of the light spectrum (beyond that of \nhuman vision), and thus has potential\
    \ for identifying sub-\ntle changes in plant growth and development.\nIn this\
    \ review, we provide an overview of hyperspec-\ntral imaging, and how it can be\
    \ utilised in laboratory and \nfield applications for the categorisation and recognition\
    \ \nof early stages of plant foliar disease and stress. Starting \nwith the background\
    \ theory and an overview of Hyper-\nspectral imaging technology, we then consider\
    \ some \nareas of application of the approach to plant and crop sci-\nences. Finally,\
    \ we discuss some practical concerns with \nthese approaches; an important aspect,\
    \ as such cameras \nare not yet typically provided as a turnkey solution for \n\
    crop monitoring, so care must be taken to collect satis-\nfactory data and provide\
    \ meaningful analysis and inter-\npretation before deployment of these technologies\
    \ can be \nimplemented in a commercial setting.\nColour digital imaging\nIn order\
    \ to understand the hyperspectral technology \nitself, it will be helpful to first\
    \ consider what a stand-\nard, non-hyperspectral colour digital image comprises.\
    \ \nWavelengths of light correspond to colour, with blue light \nhaving a central\
    \ wavelength of approximately 475  nm, \ngreen light 520  nm, and red light 650 \
    \ nm. A colour \nimage represents a composition of three broad wave-\nlength bands,\
    \ red, green and blue. Our eyes contain three \ntypes of cones, sensitive to blue,\
    \ green and red parts of \nthe spectrum, the cones each have a colour range and\
    \ \nthey are stimulated either strongly or weakly depending \non the light wavelengths\
    \ emitted. Combining the infor-\nmation from the three different kinds of cones\
    \ we recre-\nate a colour image in our brain. A digital image tries to \nemulate\
    \ the sensitivity of the cones, and a pixel stores the \nintegrated intensity\
    \ of either the blue, green, or red part \nof the light spectrum, dependant on\
    \ the filter type placed \nin front of the pixel.\nThe range of light captured\
    \ in a hyperspectral system \ncan also vary. The colour visible to the human eye\
    \ is a \nsmall range on the electromagnetic spectrum, ranging \nfrom 400 to 700 nm\
    \ (Fig. 1). The section of the spectrum \nthat is typically used for hyperspectral\
    \ imaging of plants \nranges from ultraviolet (UV) (starting at ~ 250 nm) up to\
    \ \nshort-wave infrared (SWIR, ~ 2500 nm). Cameras usually \ncapture a certain\
    \ sub-range, such as the visible and near \ninfrared range (VIS–NIR, 400–1300 \
    \ nm) or the SWIR \n(1300–2500  nm) or UV (250–400  nm) with the ranges \nbeing\
    \ combined in some sensors to increase the coverage \nof the spectrum.\nA colour\
    \ image, then, is an example of a 3-band multi-\nspectral image, where each band\
    \ records one of the three \ncolours, red, green and blue. It is common to have\
    \ more \nbands in a true multispectral image, perhaps sampling \nlight in the\
    \ infrared region of the spectrum too—that \nis, light with a wavelength over\
    \ 700  nm. Hyperspectral \nimages on the other hand typically contain hundreds\
    \ of \ncontiguous narrow wavelength bands over a spectral \nrange. The approach\
    \ produces a dense, information-rich \ncolour dataset, with enough spatial resolution\
    \ to have \nmany hundreds of data points (pixels) per leaf.\nFor plants and vegetation\
    \ the most useful wavelength \nranges to analyse are the visible range combined\
    \ with \nnear infrared range. This wavelength range can capture \nchanges in the\
    \ leaf pigmentation (400–700  nm) and \nmesophyll cell structure (700–1300 nm)\
    \ however to see \nchanges in the water content of a plant, extended ranges \n\
    are needed (1300–2500 nm) [9]. Severe dehydration, for \nexample, can affect the\
    \ leaf mesophyll structure which \nrelates to changes in the near infrared reflectance;\
    \ how-\never, minor drought stress does not usually have enough \nof an effect\
    \ to be detected [10].\nHyperspectral imaging technology\nThere are various hardware\
    \ approaches behind hyper-\nspectral imaging spectrometers, which means there\
    \ are \ndifferent ways that the image is captured. Examples of \noperation include\
    \ push broom, filter wheel, liquid crystal \ntunable filters amongst others [11].\
    \ In one example using \npush broom, the incoming light passes through a convex\
    \ \ngrating (or a prism) which separates the light into narrow \nwavelengths.\
    \ This separation is then recorded on a light \nPage 3 of 12\nLowe et al. Plant\
    \ Methods  (2017) 13:80 \nsensitive chip (similar to a standard digital camera).\
    \ A \npush broom device, has three components; the camera, a \nspectrometer and\
    \ a lens. This system simultaneously cap-\ntures a single spatial line of the\
    \ image, and the whole col-\nour spectrum range. Then the camera or object is\
    \ moved \nand the next line is captured (the broom is ‘pushed’ for-\nwards, hence\
    \ the name), effectively making the camera a \nline scanner, with the final image\
    \ being built up after the \nfull scan is complete. An alternative to push broom\
    \ is a \nsnapshot approach, where the entire image is captured \nat once. To date,\
    \ push broom technology has seen the \nmost use, but recent advances in snapshot\
    \ technology are \nincreasing the uptake and possibilities related to pheno-\n\
    typing and analysis.\nIn the rest of this review, we consider applications of\
    \ \nthe hyperspectral imaging technology and analysis, and \nhave categorised\
    \ the review into the following four sec-\ntions: (1) existing vegetation and\
    \ disease indices; (2) \napplications for the detection and classification of\
    \ healthy \nand diseased plants with disease classification; (3) quan-\ntifying\
    \ severity of disease; and (4) early stage detection of \nstress symptoms.\nWithin\
    \ these sections, we will consider both labora-\ntory-based imaging approaches,\
    \ and field-based remote \nsensing. As well as the obvious biological differences,\
    \ it \nis worth considering the impact of these environments \non the hyperspectral\
    \ image data itself. Laboratory-\nbased imaging occurs in a controlled environment\
    \ which \nincludes artificial light. Outdoor remote sensing data \nis often dependant\
    \ on ambient illumination, although \nthere are examples of systems using controlled\
    \ lighting \nfor outdoor hyperspectral imaging [12]. Using natural \nillumination,\
    \ namely the sun, means recognising that \nthere are atmospheric effects such\
    \ as the absorption and \nscattering of light. Other environmental factors that\
    \ can \ncontribute to a change in the spectral signatures are the \ninteraction\
    \ between cloud shadows and the object’s sur-\nface, time of day, specular reflections\
    \ and the presence \nof other objects that can reflect secondary illumination\
    \ \nonto the area of interest. As many of these effects are \ntime dependant,\
    \ successful use of a calibration reference \nmeans updating the referencing whenever\
    \ ambient illu-\nmination changes—this could be minute to minute in a \nnatural\
    \ illumination scenario. With controlled lighting \nthere are still problems;\
    \ light intensity challenges exist: \nthe inverse square law states that illumination\
    \ drops off \ninversely according to distance from the light source [13]. \nThis\
    \ means that uneven illumination can occur and the \ntype of light source chosen\
    \ needs careful consideration; \nit should not have high intensity peaks throughout\
    \ the \nspectrum or across the image plane.\nAnother potential difference between\
    \ laboratory and \nfield imaging is resolution. For aerial remote sensing data,\
    \ \nthe spatial resolution is typically in the range of meters \nper pixel, which\
    \ means the pixels will usually contain \nsignatures from more than one material\
    \ [14, 15]. A first \nstep in analysing this data is to consider this multi-mate-\n\
    rial problem, whereby pixels must be considered to con-\ntain mixed materials\
    \ (called ‘mixed pixels’) [16, 17], and \na spectral unmixing process must be\
    \ applied. In other \nwords, a single pixel may contain plant and soil, and algo-\n\
    rithms must be used to determine the appropriate mix. \nFig. 1 Electromagnetic\
    \ spectrum with the lower bar displaying visible and infra-red light\nPage 4 of\
    \ 12\nLowe et al. Plant Methods  (2017) 13:80 \nIn the laboratory, images can\
    \ typically be taken within \ncentimetres of the plant, and there may be many\
    \ pixels \nrepresenting even a single leaf or region of disease. In \nthese cases,\
    \ unmixing is generally not necessary.\nFurther consideration of these location-based\
    \ chal-\nlenges will be fully explored later in this review, but \nbefore we continue\
    \ let us consider why we wish to cap-\nture such hyperspectral information in\
    \ the first place.\nApplications for the detection and classification \nof healthy\
    \ and diseased plants\nIn this section, we will discuss a variety of techniques\
    \ \nused specifically for the detection of biotic stress in \nplants. Classification\
    \ techniques, that is, techniques that \nseparate the data into healthy and diseased\
    \ categories \nfor example, can be divided into two types: those that \nfocus\
    \ on a number of key wavelengths in the spectrum \nand those that use the entire\
    \ spectrum response. Further-\nmore, disease classification is discussed with\
    \ regards to \nthe identification of multiple diseases and detection of a \nspecific\
    \ disease.\nExisting vegetation and disease indices\nBefore hyperspectral imaging\
    \ devices were readily avail-\nable, researchers wishing to quantify effects based\
    \ on \ncolour information have used multispectral imaging, or \nhyperspectral,\
    \ point-source devices (such as spectroradi-\nometers which do not produce a spatial\
    \ image) to acquire \ncolour data. Hyperspectral devices do not in general \n\
    provide a point-and-click measurement. Instead, much \nonus is on the user to\
    \ develop the capture process. Once \nacquired, the resulting large numerical\
    \ datasets must be \nanalysed in order to provide useful information. A sen-\n\
    sible and simple way into such large datasets is to con-\nsider only a small number\
    \ of positions in the wavelength \nrange, looking at changes across conditions\
    \ at predeter-\nmined key points in the spectrum. Using this approach, \nwe can\
    \ also counter the effects of relative light changes by \nconsidering ratios of\
    \ data values. This involves the com-\nbination of two or more wavelengths, commonly\
    \ known \nas ‘indices’.\nTo interpret the data, a number of such indices have\
    \ \nbeen developed, through either pre-considered biologi-\ncal reasoning (e.g.\
    \ knowing that a particular wavelength \nrelates to properties in a particular\
    \ cell structure), or \ndue to limitations in the particular wavelengths avail-\n\
    able from the capture equipment (e.g. indices which are \nderived from satellite\
    \ multispectral remote sensing data \nmay only have had a limited number of wavelengths\
    \ avail-\nable). When applied to plant material, these indices are \nknown as\
    \ ‘vegetation indices’. Many different vegetation \nindices exist and each uses\
    \ a different set of wavelength \nmeasurements for describing physiological attributes\
    \ \nof vegetation, looking at either general properties of the \nplant, or at\
    \ specific parameters of its growth.\nOne of the most popular and widespread metrics\
    \ is the \nnormalised difference vegetation index (NDVI), which \nis used for\
    \ measuring the general health status of crops \n[18, 19]. It is calculated via\
    \ a simple ratio of near-IR and \nvisible light (see Table 1). NDVI has been used\
    \ for many \ndifferent purposes, for example, to detect stress caused \nby the\
    \ Sunn pest/cereal pest, Eurygaster integriceps Put. \n(Hemiptera: Scutelleridae),\
    \ in wheat [20]. Most of the \nindices are very specific and only work well with\
    \ the \ndatasets that they were designed for [21]. There are dis-\nease-centric\
    \ studies focused on creating disease indices \nfor detecting and quantifying\
    \ specific diseases [22], for \nexample, one study used leaf rust disease severity\
    \ index \n(LRDSI) with a 87–91% accuracy in detecting the leaf \nrust (Puccinia\
    \ triticina) in Wheat [23], however, to our \nknowledge, it has not been widely\
    \ tested. \nAnother commonly-used approach is to detect changes \nin the sudden\
    \ increase in reflectance at the red/near-\ninfrared border. This ‘red edge’ position\
    \ is a narrow sec-\ntion in the electromagnetic spectrum (690–740  nm) \nwhere\
    \ the visible spectrum ends and the near infrared \nstarts (Fig.  2). This section\
    \ has a large change in spec-\ntral response (derivative),for green plant material,\
    \ since \nchlorophyll strongly absorbs wavelengths up to around \n700  nm, and\
    \ hence the material has low reflectance in \nthis range, but it is strongly reflecting\
    \ the infrared (from \nabout 720 nm). Cho [24] describes a number of different\
    \ \nalgorithms that extract or detect the red edge. A disease \nindex based on\
    \ the red edge position has been used to \ndetect powdery mildew in wheat (Blumeria\
    \ graminis f. \nsp. Tritici), however it was not as accurate as Partial Least\
    \ \nSquares Regression (PLSR), a technique that uses a statis-\ntical approach\
    \ [25]. We will consider some of these statis-\ntical approaches further in this\
    \ review.\nClassification using a subset of selected wavelengths\nIn this section\
    \ we consider classification approaches that \nrely on sub sampling at particular\
    \ wavelengths from the \nfull spectrum. One difference with true multispectral\
    \ \ndata is that specific wavelengths can be manually or auto-\nmatically chosen\
    \ from anywhere in the captured range, \nwhere as multispectral data is limited\
    \ by the technology.\nAnalysis from “Background” section typically used \nindices\
    \ to calculate representative values using dis-\ncrete wavelengths at various\
    \ positions in the spectrum. \nOne such study involving a wheat field experiment\
    \ \nused normalised difference vegetation index (NDVI) \nresponse to eliminate\
    \ everything except the leaves from \nthe dataset, followed by a statistical approach\
    \ called an \nANCOVA (which measures statistical covariance) to \nidentify selected\
    \ wavelength bands, and then quadratic \nPage 5 of 12\nLowe et al. Plant Methods\
    \  (2017) 13:80 \ndiscriminant analysis (QDA) to classify the spectra \nbetween\
    \ healthy and diseased leaves (yellow rust) [26]. \nThis is representative of\
    \ a typical workflow in hyperspec-\ntral analysis: isolate (or segment) the parts\
    \ of the image \nof interest, then use a mathematical technique to identify \n\
    regions of the spectra likely to have predictive power, and \nfinally use those\
    \ spatial and spectral regions to learn a \nclassification approach. Using QDA,\
    \ the overall accuracy \nreached 92% with 4 wavebands [26].\nAn example of multi\
    \ layer perceptrons (MLP) is \ndescribed in Moshou [27], who aimed to detect yellow\
    \ \nrust in field-grown wheat using a spectrograph with the \nrange 460–900 nm\
    \ and a 20 nm spectral resolution. The \nspectrograph captured the images in the\
    \ field using a \nhandheld system. Then four significant wavelengths were \nselected.\
    \ The first two wavelengths were selected using \n‘variable selection’ which involved\
    \ comparing the wave-\nlengths using stepwise discriminant analysis and using\
    \ \nthe F-test. The second pair of wavelengths uses the NDVI \nwavelengths. The\
    \ neural network used by Moshou is a \nsimple architecture with four inputs, one\
    \ hidden layer \nconsisting of ten neurons and two outputs (healthy and \ndiseased).\
    \ The architecture is determined by the number \nof inputs, a selected amount\
    \ of hidden neurons and the \namount of outputs required. Trial and error can\
    \ be used \nto determine a suitable architecture. Moshou tried differ-\nent quantities\
    \ of neurons and selected the most efficient. \nThe classification accuracy reached\
    \ using this approach \nwas 98.9% for the healthy plants and 99.4% for the dis-\n\
    eased plants.\nThe MLP approach uses a simple architecture con-\nsisting of an\
    \ input, hidden layer(s) and the output. In \nmachine learning a new, more sophisticated\
    \ approach \ncalled deep learning is becoming popular. Deep learn-\ning refers\
    \ to artificial neural networks with a structure \nthat contains a lot of layers,\
    \ and during each layer neu-\nrons are able to implicitly represent features from\
    \ the \ndata and by doing this, more complex information can be \nobtained in\
    \ later layers, and image features are automati-\ncally determined by the network.\
    \ One specific example \nof a deep learning approach is convolutional neural net-\n\
    works (CNN). Whilst artificial neural networks (ANN) \nTable 1 A selection of vegetation\
    \ indices\nVI\nFormula\nReferences\nInformation\nNormalised difference vegetation\
    \ index (NDVI)\n(RNIR − RRED)/(RNIR + RRED)\nRRED ~ 680, RNIR ~ 800\n[50]\nRange:\
    \ − 1 to 1\nCommon range: 0.2–0.8\nBroadband\nRed edge NDVI\n(R750 − R705)/(R750\
    \ + R705)\n[50]\nRange: − 1 to 1\nTypical healthy range: 0.2 to 0.9\nNarrowband\
    \ (hyperspectral data)\nSimple ratio index (SRI)\nRNIR/RRED\nRRED ~ 680, RNIR\
    \ ~ 800\n[20]\nRange: 0 to > 30\nTypical healthy range: ~ 2–8\nBroadband\nPhotochemical\
    \ reflectance index (PRI)\n(R531 − R570)/(R531 + R570)\n[50]\n[51]\nRange: − 1\
    \ to 1\nTypical healthy range: − 0.2 to 0.2\nVegetation health prior to senescence\n\
    Plant senescence reflectance index (PSRI)\n(Red–Green)/NIR\n[50]\nRange: − 1 to\
    \ 1\nTypical healthy range: − 0.1 to 0.2\n>PSRI ~ canopy stress, onset of senescence,\
    \ fruit \nripening\nNormalised phaeophytinization index (NPQI)\n(R415 − R435)/(R415\
    \ + R435)\n[52]\nChlorophyll degradation\n0.56–1.41\nUnacidified and acidified\
    \ solutions [53]\nStructure Independent Pigment Index (SIPI)\n(R800 − R445)/(R800\
    \ + R680)\n[50]\n[51]\n[54]\nRange: 0–2\nTypical healthy range: 0.8–1.8\nGood\
    \ with canopy variety\nLeaf rust disease severity index (LRDSI)\n6.9 × (R605/R455)\
    \ − 1.2\n[23]\nAccuracy of 89% in study may vary with other data.\nFig. 2 A typical\
    \ healthy vegetation spectra (400–1000 nm) with the \nred edge section highlighted\
    \ in red (690–740 nm)\nPage 6 of 12\nLowe et al. Plant Methods  (2017) 13:80 \n\
    use neuron activation networks as their analogous model, \nCNNs are based on retinal\
    \ fields in the vision system. \nWhatever the approach, deep learning takes longer\
    \ to \ntrain and the architecture is more complex, however, \nwith the added complexity,\
    \ very impressive classification \nand recognition rates are achievable.\nDeep\
    \ learning has been applied to the problem of plant \ndisease detection. Mohanty\
    \ [28] used CNN’s to detect \n26 diseases over 14 crop species. A dataset consisting\
    \ \nof 54,306 colour images were used, 80% for training and \n20% for testing\
    \ on AlexNet and GoogLeNet (two popular \nversions of pretrained CNN’s). The accuracy\
    \ was 97.82% \nfor AlexNet and 98.36% for GoogLeNet using colour \nimages with\
    \ training from scratch (for transfer learning \nthe values are higher, 99.27\
    \ and 99.34% respectively). \nThey selected individual leaves with a homogenous\
    \ back-\nground. If the network is tested on images under different \nconditions\
    \ from the trained images the accuracy is 31.4% \n[28]. Sladojevic also used CNN’s\
    \ to detect 13 diseases \nacross various crop plants, including Apple (powdery\
    \ \nmildew, rust), pear (leaf spot), grapevine (wilt, mites, \npowdery mildew,\
    \ downey mildew) using 30,000 images \nwith an accuracy of 96.3% using CaffeNet\
    \ [29].\nThere are currently very few complete studies apply-\ning deep learning\
    \ to hyperspectral data, though this is \nan active research area. There are several\
    \ challenges that \nneed to be addressed in order to use hyperspectral data \n\
    for deep learning. The size of the hyperspectral data \nincluding the amount of\
    \ wavelengths would require a lot \nof processing time and power it would ideally\
    \ require a \ngraphics processing unit. The amount of hyperspec-\ntral wavelengths\
    \ would most likely include noise from \nspecific wavelengths. Also there needs\
    \ to be a sufficient \namount of data for the training/testing process along \n\
    with labelled data. There is also the possibility that the \nerror will be higher\
    \ than alternative approaches.\nOther non-deep learning approaches include Yuan\
    \ [30], \nusing Fishers Linear Discriminant Analysis with remote \nsensing data\
    \ to detect yellow rust and powdery mildew \nfor a wheat crop with an overall\
    \ accuracy of 93% with \nselected wavelength ranges (531, 570–654, 685–717 nm)\
    \ \nthat are significant for detecting differences between \npowdery mildew and\
    \ yellow rust diseases in these spec-\ntral reflectance ranges, resulting from\
    \ an independent t \ntest.\nSometimes data analysis approaches are combined \n\
    with simple image processing steps in order to add fea-\nture discrimination.\
    \ A family of image processing tech-\nniques called morphological operators can\
    \ be used to \nclean up binary (black and white) images. One such \ntechnique\
    \ is called erosion, whereby the foreground of \nan object is shrunk by turning\
    \ boundary pixels into back-\nground pixels. The opposite technique is called\
    \ ‘dilation’ \nand has the effect of enlarging the foreground object’s \nboundary.\
    \ They can be used together to fill in holes, or \nremove speckle noise (depending\
    \ on the order used) in \nbinary labelled data. One approach using this method\
    \ is \na study on cucumber leaf data, in this example, this tech-\nnique has been\
    \ used to analyse a different type of mildew; \ndowny mildew (Pseudoperonospora\
    \ cubensis). first prin-\nciple component analysis (PCA) is applied to reduce\
    \ the \nsize of the data and a binary image is produced, and then \nerosion and\
    \ dilation are used in a second step to enhance \nthe disease features. The accuracy\
    \ is 90% however only 20 \nsamples were used (10 healthy and 10 infected) [31].\
    \ This \nmethod is unlikely to work as well on other hyperspectral \nimages to\
    \ detect diseases unless the leaf data is similar \nand even then the results\
    \ are uncertain.\nHyperspectral imaging can also be combined with \nmicroscopy\
    \ to capture images at a higher resolution. \nBarley with different genotypes\
    \ has been studied at the \nmicroscopic level to see if spectral differences could\
    \ be \nidentified between the genotypes. Barley leaves were also \nanalysed from\
    \ both healthy and diseased plants, which \nhad been inoculated with Powdery Mildew\
    \ (B. graminis). \nResults showed there was a difference over time between \n\
    the healthy and inoculated leaves, except for those vari-\neties containing the\
    \ mildew locus o (mlo) gene, which \nprovides plant resistance to B. graminis.\
    \ In this study, \nthe spectral range was reduced to 420–830  nm due to \nthe\
    \ noise, then normalised and smoothed with Savitzky-\nGolay filter, and then SiVM\
    \ is used to find the extreme \nspectra followed by Dirichlet aggregation regression\
    \ for \nthe leaf trace [32].\nClassification using full spectrum data\nClassification\
    \ approaches aim to divide the data into a \nnumber of distinct classes. They\
    \ originate from a fam-\nily of statistical or machine learning techniques. One\
    \ \nsuch approach is quadratic discriminant analysis (QDA), \nwhich classifies\
    \ by using a covariance matrix, which com-\npares classes. The QDA method was\
    \ used in a study with \nAvocado plants, to examine the fungal disease Laurel\
    \ wilt \n(Raffaelea lauricola), using plants located both in the \nfield and glasshouse.\
    \ The QDA classification accuracy \nwas 94% [33]. It is possible of course to\
    \ use alternative \nmethods at each stage of the analysis pipeline. For exam-\n\
    ple, rather than use QDA, a decision tree approach (a \nmachine learning technique)\
    \ has been used and reached \n95% accuracy [33]. Choosing the correct approach\
    \ for the \ndata, as well as ensuring sufficient dataset size and qual-\nity,\
    \ is key. Such machine learning approaches represent \nan increasingly-common\
    \ set of classification and predic-\ntion algorithms. Machine learning approaches\
    \ train algo-\nrithms using a training dataset, with the aim of analysing \nand\
    \ predicting results from new, unseen data. Multilayer \nPage 7 of 12\nLowe et\
    \ al. Plant Methods  (2017) 13:80 \nperceptron’s (MLP) are an example of such\
    \ a technique. \nMLP’s are simple networks (called artificial neural net-\nworks)\
    \ that maps input data to an output. This process \nis based on biological understanding\
    \ of neuron activation \nnetworks where messages are fired between neurons. The\
    \ \ninput node connects to the output and it is updated using \nan activation\
    \ function and weights that can be optimised \nto produce the correct output (using\
    \ training data). This \nalgorithm requires prior knowledge (training data) there-\n\
    fore if the ‘disease spectra’ is unknown then this tech-\nnique will be unsuitable.\n\
    A third classification approach is to look at the spec-\ntral signatures by using\
    \ derivatives; this is when the \nunderlying pattern or change in data is analysed.\
    \ Second \norder (and above) derivatives are usually insensitive to \nchanges\
    \ in the illumination [15]; however they are sen-\nsitive to noise which hyperspectral\
    \ data typically suffers \nfrom, therefore ‘smoothing’ needs to be applied before\
    \ \nusing derivatives. Smoothing is a process that reduces \nthe difference between\
    \ individual pixel intensities and \nneighbouring pixels using forms of averaging\
    \ to create a \nsmoother signal. Two smoothing examples are Savitsky-\nGolay and\
    \ Gaussian filtering. Savitszky-Golay proposed \na method for smoothing noisy\
    \ data by fitting local poly-\nnomials to a sub set of the input data then evaluating\
    \ the \npolynomial at a single point to smooth the signal [34]. \nGaussian filtering\
    \ reduces noise by averaging the spec-\ntral data with a focus on the central\
    \ information using a \nGaussian-weighted kernel.\nHuang [35] tries to detect\
    \ Sclerotinia rot disease in Cel-\nery crops by using partial least squares regression\
    \ (PLSR) \nwith derivatives of first and second order. Partial least \nsquares\
    \ regression selects a small set of components. This \ntechnique is useful when\
    \ the predictors are collinear/\nhighly correlated, and it will reduce the risk\
    \ of overfit-\nting the data. The classification accuracy for Partial least \n\
    squares regression with the raw spectra is 88.92%, PLSR \nwith Savitzky-Golay\
    \ first derivative is 88.18% and PLRS \nwith second order derivative is 86.38%.\
    \ The accuracies \nare similar, with the second order derivative perform-\ning\
    \ slightly worse. Yuan [36] uses PLSR on Fisher’s linear \ndiscriminant analysis\
    \ (FLDA) to detect pest and disease \nin wheat. It produced a 60% accuracy for\
    \ aphid damage \nand a 92% accuracy for Yellow rust disease. In another \nstudy,\
    \ Zhang [37] used FLDA to detect powdery mildew \nin wheat (using a heavily damaged\
    \ leaf) with over 90% \naccuracy.\nDisease identification\nAs well as detecting\
    \ the presence of disease, another ave-\nnue of research is to distinguish between\
    \ different dis-\neases to identify specific pathogens. One such approach \nis\
    \ spectral information divergence classification. This \nmethod compares the divergence\
    \ between the observed \nspectra and a reference spectra (a library of spectra,\
    \ or \naverage spectra of interest from the data), where the \nsmaller the divergence\
    \ value then the more similar the \nspectra are, and if they are larger than a\
    \ set threshold \nthen they are not classified as the reference spectra [3]. \n\
    Spectral information divergence was used to detect can-\nker legions on citrus\
    \ fruit (grapefruits) where the spec-\ntral range of the data was 450–930 nm with\
    \ 92 bands and \n5.2 nm spectral resolution. Before analysing the data, a \npre-processing\
    \ step is applied by combining neighbour-\ning pixels to reduce the size by half.\
    \ Cankerous grape-\nfruits were compared with normal grapefruit and also \nwith\
    \ grapefruit showing other disease or damage symp-\ntoms including: greasy spot,\
    \ insect damage, melanose, \nscab and wind scar; this method resulted in 95.2%\
    \ clas-\nsification accuracy [38].\nQuantifying severity of disease\nAlong with\
    \ detecting and classifying disease, we may \nwish to record the effective amount\
    \ of disease, or its \nseverity. This approach does run into some particular \n\
    challenges. The amount of leaf damage and coverage \nfrom the disease can affect\
    \ the accuracy of the leaves \nbeing classified as healthy or diseased. Extreme\
    \ disease \ndamage can affect the appearance of leaves so detrimen-\ntally that\
    \ they may not be counted as plant material at all. \nStill, there are a number\
    \ of methods for estimating sever-\nity, and we present a selection of approaches\
    \ below.\nSpectral angle mapper (SAM) approaches match the \npixel spectra to\
    \ reference spectra to classify the pix-\nels by calculating the angle between\
    \ the spectra which \nare treated as n-dimensional vectors in space [2]. This\
    \ \ntechnique has been widely used with moderate success \nto classify hyperspectral\
    \ data, including plant diseases. \nYuhas studied the severity of Fusarium head\
    \ blight dis-\nease for wheat before harvesting. The hyperspectral data \nwas\
    \ in the range 400–1000 nm with a spectral resolution \nof 2.5 nm. SAM was used\
    \ to detect the amount of disease \nwith a classification accuracy of 87%. Two\
    \ experiments \nwith wheat plants were carried out, one in a glasshouse \nand\
    \ one in field. The plants were imaged over their devel-\nopmental stages from\
    \ inoculated to established infection. \nYuhas determined that just after infection,\
    \ the healthy \nand infected plants were not distinguishable because the \ninfection\
    \ had not yet established. However, when the \nhyperspectral data were examined\
    \ during the ripening \nstage, the wheat pigment composition changes, and the\
    \ \nhealthy plants then appear as diseased plants [39].\nMahlein [40] uses the\
    \ same technique to analyse sugar \nbeet diseases specifically Cerospora leaf\
    \ spot, pow-\ndery mildew and leaf rust. The range is 400–1000  nm \nwith 2.8 \
    \ nm spectral resolution and 0.19  mm spatial \nPage 8 of 12\nLowe et al. Plant\
    \ Methods  (2017) 13:80 \nresolution. The plants were analysed over a time period\
    \ \n(> 20 days) to monitor the different stages of each dis-\nease, and the leaves\
    \ were classified as healthy or dis-\neased. Cerospora leaf spot classification\
    \ accuracy varied \ndepending on the severity of the disease (89.01–98.90%), \n\
    powdery mildew accuracy varied between 90.18 and \n97.23%, and sugar beet rust\
    \ reached 61.70%, with no clas-\nsification before day 20 using SAM.\nRumpf et al.\
    \ [41] used the same dataset as Mahlein but \nwith different analysis approaches;\
    \ decision trees (DT), \nartificial neural networks (ANN) and support vector \n\
    machine (SVM). All approaches require prior knowledge, \nhowever once trained\
    \ have proven to be efficient. For \nexample, with Cerospora leaf spot the accuracy\
    \ for SVM \nis 97% (compared to DT 95% and ANN 96%); for Sugar \nbeet rust the\
    \ accuracy is 93% (DT 92%, ANN 95%); and \nfor Powdery mildew the accuracy is\
    \ 93% (DT 86%, ANN \n91%). Measuring the severity with leaf area coverage after\
    \ \nthe disease has covered 1–2% of the leaf the accuracy is \n62–68% and for\
    \ more than 10% leaf coverage the accu-\nracy is almost 100%. This demonstrates\
    \ that it is possi-\nble to use a variety of analysis methods on the same set\
    \ \nof hyperspectral data to elucidate different insights and \nachieve different\
    \ levels of accuracy—choice of technique \nis important. A list of common techniques\
    \ used to iden-\ntify specific diseases and the accuracy associated with \neach\
    \ is presented in Table 2.\nDetection of early stage stress symptoms\nThe ultimate\
    \ goal of such detection systems is to identify \nthe disease with a minimum of\
    \ physical changes to the \nplant. Identifying diseases or abiotic problems as\
    \ early \nas possible has obvious benefits. By using hyperspectral \ntechnology\
    \ in combination with appropriate analysis \nTable 2 Summary of techniques successfully\
    \ used to detect drought and diseases in plants\nH healthy, S stressed, D diseased\n\
    Technique\nPlant (stress)\nReferences\nAccuracy\nQuadratic discriminant analysis\
    \ (QDA)\nWheat (yellow rust)\nAvacado (laurel wilt)\n[26]\n[33]\n92%\n94%\nDecision\
    \ tree (DT)\nAvacado (laurel wilt)\nSugarbeet (cerospora leaf spot)\nSugarbeet\
    \ (powdery mildew)\nSugarbeet (leaf rust)\n[33]\n[41]\n95%\n95%\n86%\n92%\nMultilayer\
    \ perceptron (MLP)\nWheat (yellow rust)\n[27]\n98.9/99.4%\nH/D\nPartial least\
    \ square regression (PLSR)\n Raw\n Savitsky-Golay 1st derivative\n Savitsky-Golay\
    \ 2nd derviative\nCelery (sclerotinia rot)\n[35]\n88.92%\n88.18%\n86.38%\nPartial\
    \ least square regression (PLSR)\n Fishers linear determinant analysis\nWheat\
    \ (yellow rust)\nWheat (aphid)\nWheat (powdery mildew)\nWheat (powdery mildew)\n\
    [36]\n[37]\n92%\n60%\n90%\nFishers linear determinant analysis (FLDA)\nWheat (yellow\
    \ rust)\nWheat (powdery mildew)\n[30]\n93%\nErosion and dilation\nCucumber (downey\
    \ mildew)\n[31]\n90%\nSpectral angle mapper (SAM)\nSugarbeet (cerospora leaf spot)\n\
    Sugarbeet (powdery mildew)\nSugarbeet (leaf rust)\nWheat (head blight)\n[40]\n\
    [39]\n89.01–98.90%\n90.18–97.23%\n61.7%\n87%\nArtificial neural network (ANN)\n\
    Sugarbeet (cerospora leaf spot)\nSugarbeet (powdery mildew)\nSugarbeet (leaf rust)\n\
    [41]\n96%\n91%\n95%\nSupport vector machine (SVM)\nSugarbeet (cerospora leaf spot)\n\
    Sugarbeet (powdery mildew)\nSugarbeet (leaf rust)\nBarley (drought)\n[41]\n[45]\n\
    97%\n93%\n93%\n10 days before visible signs\nSpectral information divergence (SID)\n\
    Grapefruit (cankerous, normal, greasy spot. Insect damage, \nmelanose, scab, wind\
    \ scar)\n[38]\n95.2%\nSimplex volume maximisation\nSiVM with DAR\nBarley (drought)\n\
    Barley (drought)\n[44]\n[47]\n4 days before Vegetation Indices\n1.5wk Before \
    \ visible signs\nLSSVM\nWheat (drought)\n[46]\n86.6%(H)/76.3%(S)\nPage 9 of 12\n\
    Lowe et al. Plant Methods  (2017) 13:80 \nmethods, we can realistically hope to\
    \ identify stress \nsymptoms before a human observer.\nDrought can be a significant\
    \ problem for many crops \n[42], particularly as some plant species or varieties\
    \ do \nnot visibly indicate this stress for a period of time, and \nby this time,\
    \ the potential yield or quality of the crop may \nhave decreased because normal\
    \ plant developmental \nprocesses have been affected through the stress response.\
    \ \nThe definition of ‘drought’ can also vary from a little \nwater deprivation\
    \ to complete deprivation. Studies dis-\ncussed in this section have detected\
    \ the onset of drought \nbefore Vegetation Indices’ detected the drought and also\
    \ \ndays before visible signs appeared.\nOne technique in particular which has\
    \ become popu-\nlar for early detection of drought stress is simplex vol-\nume\
    \ maximisation (SiVM), which is a data clustering \ntechnique [43]. This technique\
    \ selects spectral signatures \nthat are samples of healthy and stressed plants,\
    \ and then \nclusters the data using these classes. When the signatures \nbecome\
    \ similar to a pre-learned sample signature then it \nis classified as such.\n\
    Romer [44] studied drought stress in a barley experi-\nment contained in a rainout\
    \ shelter and a corn experi-\nment grown in field. The technique used to detect\
    \ the \nstress was simplex volume maximisation, which is \nan unsupervised technique.\
    \ The spectrum range was \n400–900 nm, with 4 nm spectral resolution. During pre-\n\
    processing some wavelengths are removed due to noise \n(< 470 and > 750 nm). This\
    \ is a common occurrence with \nhyperspectral data due to insufficient light at\
    \ the end of \nthe spectrum range, and is especially common with lab-\nbased light\
    \ sources which may not generate much light in \nthese regions of the spectrum.\
    \ To reduce the size of the \ndata and to remove the background, a k-means cluster-\n\
    ing method was used to separate the data into a selected \nnumber of groups using\
    \ mean colour. SiVM is then com-\npared to four well known vegetation indices’—NDVI,\
    \ \nphotochemical reflectance index (PRI), red edge inflec-\ntion point (REIP)\
    \ and carotenoid reflectance index (CRI). \nFor the Barley data, reduced partial\
    \ water stress was \ndetected four days earlier with SiVM (day 9) than Vegeta-\n\
    tion Indices’ (day 13). For the plants with no water/com-\nplete drought conditions\
    \ the Vegetation Indices’ detected \nthe stress on day 8, one day faster than\
    \ SiVM, but they \nfailed to detect the stress for days 9 and 10; however \nSiVM\
    \ did reliably detect the stressed plants from day 9.\nBehmann also analysed drought\
    \ stress in barley using \nsupport vector machine (SVM). This algorithm is super-\n\
    vised and requires labelled training data, which in this \ncase is labelled as\
    \ drought or healthy. The data is pre-\nprocessed with k-means to reduce the size\
    \ of the data-\nset before analysis with SVM. The spectral range was \n430–890 \
    \ nm with a spectral resolution of 4  nm. Using \nthis approach, Behmann detected\
    \ drought stress on day \n6, with NDVI detecting a difference on day 16 [45].\n\
    Drought stress in wheat has been analysed by two com-\nbined techniques to try\
    \ and improve detection rates. \nMoshou [46] uses least squares support vector\
    \ machine \n(LSSVM) to try and detect drought stress. Wheat plants \nwere studied\
    \ in a glasshouse, and both spectral reflec-\ntance and fluorescence were analysed.\
    \ Fluorescence \ninvolves using high intensity light to excite a plant tis-\n\
    sue causing it to emit a different wavelength light, which \ncan be used to gain\
    \ additional biological insight. LSSVM \nneeded to be trained, and 846 data samples\
    \ were used for \nthis training, whilst 302 data samples were used for the \n\
    testing stage. For some techniques the size of the data-\nset and/or number of\
    \ wavelengths will determine the \ntime taken to analyse the data due to computation\
    \ time. \nTherefore, Moshou used six wavelengths—503, 545, 566, \n608, 860 and\
    \ 881 nm. The LSSVM attained 76.3% accu-\nracy for stress leaves and 86.6% accuracy\
    \ for healthy \nleaves. However, the study stated that by using a fusion \nLSSVM\
    \ model combining spectral and florescence fea-\ntures, the overall accuracy was\
    \ greater than 99%. Fluo-\nrescence is the measure of chlorophyll fluorescence\
    \ in the \nleaf to determine physiological changes.\nAccording to Kersting [47]\
    \ many of these techniques \nare difficult to use for non-machine learning or\
    \ data min-\ning experts because the hyperspectral data needs pre-\nprocessing\
    \ or adapting (i.e. finding the leaves or using \nselect wavelengths). In addition,\
    \ the other techniques \napart from [44] do not analyse lots of plants over several\
    \ \ndays. This is an important factor to consider for plant \nphenotyping when\
    \ there is a lot of data to analyse. Ker-\nsting claims to have the first Artificial\
    \ Intelligence tech-\nnique for drought stress prediction using hyperspectral\
    \ \ndata. A novel approach is developed which includes a \npredictive technique\
    \ for drought that does not adapt \nthe data or reduce the size. Kersting demonstrates\
    \ the \napproach in a Barley drought experiment with data col-\nlected over a\
    \ five-week period. The technique used \nis called Dirichlet aggregation regression\
    \ (DAR) and \nit is based on matrix factorisation. First Simplex Vol-\nume Maximisation\
    \ is used to find 50 spectral signatures \nfrom the data and classify them. Then,\
    \ latent Dirichlet \naggregation values are estimated before using a Gauss-\n\
    ian process over the values to find the drought levels \nper plant and per time\
    \ point. Finally, the process pre-\ndicts the drought-affected plants before there\
    \ are visible \nsigns. Based on a five-week barley experiment, predic-\ntion of\
    \ drought occurred 1.5  weeks before visible signs \nappeared. A comparison of\
    \ runtimes between SiVM and \nDAR was assessed and resulted in a runtime of 30 min\
    \ for \nparallelized SiVM, versus only several minutes using the \nDAR model.\
    \ This demonstrates that developing custom \nPage 10 of 12\nLowe et al. Plant\
    \ Methods  (2017) 13:80 \nanalysis techniques can outperform (either in compu-\n\
    tation time, required assumptions, ease of use, or final \naccuracy) the direct\
    \ application of existing approaches.\nHyperspectral data capture and software\n\
    Hyperspectral data is large in size, especially when mul-\ntiple plants are imaged\
    \ for several days. A scan of a sin-\ngle plant could easily be around a gigabyte\
    \ in size. If the \nwhole spectrum range is analysed then the process will \n\
    take considerably longer than selecting several wave-\nlengths to analyse. However,\
    \ there is a lot of informa-\ntion contained in the data, which could be valuable.\
    \ The \nresearcher must make decisions about how much spec-\ntral resolution to\
    \ use, and how much to discard. If your \ncamera collects 800 spectral bands,\
    \ you must ask your-\nself if you need all 800 or whether binning into 400 or\
    \ \n200 etc. bands is sufficient. This is analogous to using \nsomething like\
    \ JPEG compression for RGB images. This \ncompression creates smaller file sizes,\
    \ at the expense of \ndestroying image information permanently (particularly \n\
    colour information). Storing fewer spectral bands results \nin smaller file sizes,\
    \ and reduces the complexity of the \ndata analysis, at the expense of throwing\
    \ away potentially \nimportant colour properties. Polder et al. [48] explore the\
    \ \ncalibration and characterisation of spectrographs cap-\ntured using three\
    \ system set ups. The experiments look at \nthe different types of noise and signal-to-noise\
    \ ratio. The \nexperiments also determined that to an extent binning \ncan occur\
    \ without loss of information by calculating the \nresolution, the spectral range\
    \ and the amount of pixels.\nHyperspectral camera set‑up\nPrior to analysis, the\
    \ hyperspectral data needs to be cali-\nbrated to ensure the images produced are\
    \ adjusted due to \nthe colour of lighting present; the camera software may \n\
    have this option, but if it does not then the data can be \ncalibrated after it\
    \ is captured. The lighting is calibrated \nusing a known white balance target,\
    \ which is imaged \nby the camera system. This target will reflect a known \n\
    percentage of light over the spectrum, for example 99% \nacross the entire working\
    \ spectrum of the camera. Non-\nuniformity of illumination can be corrected for\
    \ by divid-\ning the observed data by the captured white balance \ndata [49].\
    \ Additionally, the system must be corrected for \nelectrical noise present from\
    \ the sensor in the absence of \nlight (called dark current). This is usually\
    \ carried out by \ntaking an image with the camera in the absence of any \nlight,\
    \ and using the resultant low-level noise readings to \nadjust future measures.\n\
    An important question is how often to carry out a \nwhite balance calibration.\
    \ In a lab setting, it may be \nappropriate to capture just one white balance\
    \ target per \nexperiment, assuming the lighting has reached an equi-\nlibrium\
    \ (i.e. the bulbs have fully warmed up). Outside the \nlab, however, lighting\
    \ is subject to much more variation. \nCloud cover, shadows and time of day can\
    \ dramatically \naffect the colour of the incoming light when outside and \nso\
    \ very regular white balance readings must be taken to \nensure accurate calibration.\
    \ Careful choice must also be \nmade about the time of day images are captured\
    \ on, and \nwhether to capture in overcast conditions versus direct \nsun (which\
    \ can cause problems with shadows and spec-\nular reflection—bright spots on the\
    \ plants reflecting the \nillumination source (i.e. the sun) directly). Evenness\
    \ of \nillumination should also be considered—does the sen-\nsor record a uniform\
    \ level of brightness across its spa-\ntial range? An effect called vignetting\
    \ can result in pixels \ntowards the edges of the lens appearing darker than those\
    \ \nin the centre.\nConclusions\nThere has been a significant increase in scientific\
    \ litera-\nture in recent years focusing on detecting stress in plants \nusing\
    \ hyperspectral image analysis. Plant disease detec-\ntion is a major activity\
    \ in the management of crop plants \nin both agriculture and horticulture. In\
    \ particular, detect-\ning early onset of stress and diseases would be beneficial\
    \ \nto farmers and growers as it would enable earlier inter-\nventions to help\
    \ mitigate against crop loss and reduced \ncrop quality. Hyperspectral imaging\
    \ is a non-invasive \nprocess where the plants are scanned to collect high-res-\n\
    olution data. The technology is becoming more popular \nsince the falling costs\
    \ of camera production have enabled \nresearchers and developers greater access\
    \ to this tech-\nnology. There are various techniques available to ana-\nlyse\
    \ the data to detect biotic and abiotic stress in plants, \nexamples of which\
    \ have been discussed in this review, \nwith a focus on the classification of\
    \ healthy and diseased \nplants, the severity of disease and early detection of\
    \ stress \nsymptoms.\nVegetation and disease indices are increasing in \nquantity\
    \ every year. Significant wavelengths combined \ntogether can indicate the health\
    \ or disease status occur-\nring within a specific species. Indices are valuable\
    \ for \ndetecting specific criteria for vegetation however; the \nindices are\
    \ selected with the datasets, species and con-\nditions favourable to the experiments\
    \ at that time. Some \nare more general in nature; NDVI, PRI and several other\
    \ \nVegetation Indices will work to find the general health \nof the plant. But\
    \ in general, it is harder to take an index \ndesigned for plant X and apply it\
    \ to a dataset for plant Y. \nThis is the motivation behind considering a larger\
    \ range \nof wavelengths over the spectrum, which has the poten-\ntial to yield\
    \ better results.\nPage 11 of 12\nLowe et al. Plant Methods  (2017) 13:80 \nAbbreviations\
    \ and glossary\nANN: Artificial neural network—neural networks with input vector\
    \ and output \nvectors (neurons/nodes) with one or multiple hidden layers of nodes,\
    \ where \nall of the layers are fully connected with weights and an activation\
    \ function; \nDT: Decision tree has a tree structure form and it is has decision\
    \ nodes and \nleaf nodes where the decision nodes have two or more branches and\
    \ the \nleaf nodes represent the classification. This is supervised and needs\
    \ training. \nThe decision rules can become complex as the tree depth increases;\
    \ Erosion \nand dilation: Erosion shrinks the foreground object by turning boundary\
    \ \npixels into background pixels if there are more background pixels connected\
    \ \n(neighbouring pixels) than foreground pixels. Dilation is the opposite and\
    \ \nenlarges the boundary pixels of the foreground object; FLDA: Fishers linear\
    \ \ndiscriminant analysis—project the feature space (n dataset) onto a subspace,\
    \ \ndimensionality reduction; MLP: Multilayer perceptron’s are feed forward \n\
    artificial neural networks (ANN).The MLP is supervised which means it needs \n\
    a training data set that is labelled [1]; PLSR: Partial least squares regression—\n\
    using linear regression to find the small set of variables from a large set of\
    \ \npredictors by finding the latent variables (covariance of the predictors and\
    \ \nvariables); QDA: Quadratic discriminant analysis classifies using a covariance\
    \ \nmatrix where each class has a unique matrix and therefore has different class\
    \ \ndensity probabilities; SAM: Spectral angle mapper matches the pixel spectra\
    \ \nto reference spectra to classify the pixels by calculating the angle between\
    \ the \nspectra which are n-dimensional vectors in space [2]; SID: Spectral information\
    \ \ndivergence compares the divergence between the observed spectra and the \n\
    reference spectra where the smaller the divergence value the similar the spec-\n\
    tra are and if they are larger than a threshold then they are not classified as\
    \ \nthe reference spectra [3]; SiVM: Simplex volume maximisation selects spectral\
    \ \nsignatures that are the furthest away from each other to maximise the volume\
    \ \n(for example healthy and diseased signatures). Once the signatures have been\
    \ \nselected the remaining signatures are assigned to the class they are similar\
    \ \nto; SVM: Support vector machine—machine learning process that takes data \n\
    and splits it into groups/classes based on the training labelled data; LSSVM:\
    \ \nLeast squares support vector machine; LRDSI: Leaf rust disease severity index;\
    \ \nRNIR: Reflectance at NIR (near infrared); RRED: Reflectance at red; Supervised:\
    \ \nRequires the known outcomes for a training dataset, with the training data\
    \ \nincluding inputs and the corresponding expected outputs; Unsupervised: \n\
    Only the input data is supplied and the training involves the technique learn-\n\
    ing the underlying structure of the data, there is no correct output; Machine\
    \ \nlearning: Training the technique to learn rather than using explicit instructions\
    \ \nand repeating the process until the objective is reached; RGB: A colour image\
    \ \nin the red, green and blue colour space; Multispectral: Several wavelengths\
    \ \nthat are typically from the visible and/or near infra-red range; Hyperspectral:\
    \ \nHundreds of contiguous narrow bands over a spectral range; Colour binning:\
    \ \nCombining wavelengths to reduce the number of wavebands and size of the \n\
    images; NMF: Non negative matrix factorisation.\nAuthors’ contributions\nAL, NH\
    \ and AF drafted the manuscript. All authors read and approved the \nmanuscript.\n\
    Author details\n1 School of Biosciences, University of Nottingham, Sutton Bonington\
    \ LE12 5RD, \nUK. 2 School of Computer Science, University of Nottingham, Jubilee\
    \ Campus, \nNottingham NG8 1BB, UK. 3 NIAB EMR, New Road, East Malling, Kent ME19\
    \ \n6BJ, UK. 4 Agriculture and Horticulture Development Board, Stoneleigh Park,\
    \ \nKenilworth, Warwickshire CV8 2TL, UK. \nAcknowledgements\nThe authors would\
    \ like to acknowledge AHDB for partly funding the work and \nNIAB East Malling\
    \ Research.\nCompeting interests\nThe authors declare that they have no competing\
    \ interests.\nAvailability of data and materials\nNot applicable.\nConsent for\
    \ publication\nNot applicable.\nEthics approval and consent to participate\nNot\
    \ applicable.\nFunding\nThe project is partly funded by Agriculture and Horticulture\
    \ Development \nBoard.\nPublisher’s Note\nSpringer Nature remains neutral with\
    \ regard to jurisdictional claims in pub-\nlished maps and institutional affiliations.\n\
    Received: 25 January 2017   Accepted: 3 October 2017\nReferences\n 1. \nGardner\
    \ MW, Dorling SR. Artificial neural networks (the multilayer \nperceptron)—a review\
    \ of applications in the atmospheric sciences. \nAtmos Environ. 1998;32:2627–36.\n\
    \ 2. \nYuhas RH, Goetz AF, Boardman JW. Discrimination among semi-arid land-\n\
    scape endmembers using the spectral angle mapper (SAM) algorithm. \nIn: Summaries\
    \ of the third annual JPL airborne geoscience workshop \n[Internet]. Pasadena,\
    \ CA: JPL Publication; 1992 [cited 2015 Nov 3]. p. \n147–9. http://ntrs.nasa.gov/archive/nasa/casi.ntrs.nasa.gov/19940012238.\n\
    pdf.\n 3. \nDu Y, Chang C-I, Ren H, Chang C-C, Jensen JO, D’Amico FM. New hyper-\n\
    spectral discrimination measure for spectral characterization. Opt Eng. \n2004;43:1777–86.\n\
    \ 4. \nSavary S, Ficke A, Aubertot J-N, Hollier C. Crop losses due to diseases\
    \ and \ntheir implications for global food production losses and food security.\
    \ \nFood Secur. 2012;4:519–37.\n 5. \nOerke E-C. Crop losses to pests. J Agric\
    \ Sci. 2006;144:31–43.\n 6. \nRiley MB, Williamson MR, Maloy O. Plant disease\
    \ diagnosis. Plant Health \nInstr. [Internet]. 2002 [cited 2015 Nov 17]. http://www.apsnet.org/\n\
    edcenter/intropp/topics/Pages/PlantDiseaseDiagnosis.aspx.\n 7. \nMahlein A-K.\
    \ Plant disease detection by imaging sensors–parallels and \nspecific demands\
    \ for precision agriculture and plant phenotyping. Plant \nDis. 2016;100:241–51.\n\
    \ 8. \nSingh A, Ganapathysubramanian B, Singh AK, Sarkar S. Machine learn-\ning\
    \ for high-throughput stress phenotyping in plants. Trends Plant Sci. \n2016;21:110–24.\n\
    \ 9. \nPeñuelas J, Filella I. Visible and near-infrared reflectance techniques\
    \ for \ndiagnosing plant physiological status. Trends Plant Sci. 1998;3:151–6.\n\
    \ 10. Satterwhite MB, Henley JP. Hyperspectral signatures (400 to 2500 nm) \n\
    of vegetation, minerals, soils, rocks, and cultural features: laboratory and \n\
    field measurements 1990.\n 11. Fong AY, Wachman E. Hyperspectral imaging for the\
    \ life sciences. Biopho-\ntonics Int. 2008;15:38.\n 12. Schut AGT, Ketelaars JJMH.\
    \ Monitoring grass swards using imaging spec-\ntroscopy. Grass Forage Sci. 2003;58:276–86.\n\
    \ 13. Saaty TL. Exploring the interface between hierarchies, multiple objectives\
    \ \nand fuzzy sets. Fuzzy Sets Syst. 1978;1:57–68.\n 14. Shaw GA, Burke HK. Spectral\
    \ imaging for remote sensing. Linc Lab J. \n2003;14:3–28.\n 15. Tsai F, Philpot\
    \ W. Derivative analysis of hyperspectral data. Remote Sens \nEnviron. 1998;66:41–51.\n\
    \ 16. Rajabi R, Ghassemian H. Unmixing of hyperspectral data using robust \nstatistics-based\
    \ NMF. In: 2012 Sixth international symposium on telecom-\nmunications (IST).\
    \ 2012. p. 1157–60.\n 17. Nascimento JMP, Bioucas Dias JM. Vertex component analysis:\
    \ a fast \nalgorithm to unmix hyperspectral data. IEEE Trans Geosci Remote Sens.\
    \ \n2005;43:898–910.\n 18. Rouse Jr JW. Monitoring the vernal advancement and\
    \ retrogradation \n(green wave effect) of natural vegetation. 1972 [cited 2016\
    \ Feb 29]. \nhttp://ntrs.nasa.gov/search.jsp?R=19730009607.\n 19. Lasaponara R,\
    \ Masini N. Detection of archaeological crop marks by using \nsatellite QuickBird\
    \ multispectral imagery. J Archaeol Sci. 2007;34:214–21.\nPage 12 of 12\nLowe\
    \ et al. Plant Methods  (2017) 13:80 \n 20. Genc H, Genc L, Turhan H, Smith SE,\
    \ Nation JL. Vegetation indices as \nindicators of damage by the sunn pest (Hemiptera:\
    \ Scutelleridae) to \nfield grown wheat. Afr J Biotechnol [Internet]. 2008 [cited\
    \ 2015 Nov 3];7. \nhttp://www.ajol.info/index.php/ajb/article/view/58347.\n 21.\
    \ Verrelst J, Koetz B, Kneubühler M, Schaepman M. Directional sensitivity \nanalysis\
    \ of vegetation indices from multi-angular Chris/PROBA data. In: \nISPRS commission\
    \ VII-term symposium [Internet]. 2006 [cited 2015 Nov \n3]. p. 677–83. http://www.isprs.org/proceedings/XXXVI/part7/\n\
    \ 22. Mahlein A-K, Rumpf T, Welke P, Dehne H-W, Plümer L, Steiner U, et al. \n\
    Development of spectral indices for detecting and identifying plant \ndiseases.\
    \ Remote Sens Environ. 2013;128:21–30.\n 23. Ashourloo D, Mobasheri MR, Huete\
    \ A. Developing two spectral disease \nindices for detection of wheat leaf rust\
    \ (Pucciniatriticina). Remote Sens. \n2014;6:4723–40.\n 24. Cho MA, Skidmore AK.\
    \ A new technique for extracting the red edge posi-\ntion from hyperspectral data:\
    \ the linear extrapolation method. Remote \nSens Environ. 2006;101:181–93.\n 25.\
    \ Cao X, Luo Y, Zhou Y, Fan J, Xu X, West JS, et al. Detection of powdery \nmildew\
    \ in two winter wheat plant densities and prediction of grain yield \nusing canopy\
    \ hyperspectral reflectance. In: Grosch R, editor. PLOS ONE. \n2015;10:e0121462.\n\
    \ 26. Bravo C, Moshou D, West J, McCartney A, Ramon H. Early disease \ndetection\
    \ in wheat fields using spectral reflectance. Biosyst Eng. \n2003;84:137–45.\n\
    \ 27. Moshou D, Bravo C, West J, Wahlen S, McCartney A, Ramon H. Automatic \n\
    detection of “yellow rust” in wheat using reflectance measurements and \nneural\
    \ networks. Comput Electron Agric. 2004;44:173–88.\n 28. Mohanty SP, Hughes D,\
    \ Salathe M. Using deep learning for image-based \nplant disease detection. ArXiv160403169\
    \ Cs [Internet]. 2016 [cited 2016 \nSep 12]. http://arxiv.org/abs/1604.03169.\n\
    \ 29. Sladojevic S, Arsenovic M, Anderla A, Culibrk D, Stefanovic D. Deep neural\
    \ \nnetworks based recognition of plant diseases by leaf image classifica-\ntion\
    \ [cited 2016 Sep 12]. http://downloads.hindawi.com/journals/cin/\naip/3289801.pdf.\n\
    \ 30. Yuan L, Zhang J, Zhao J, Du S, Huang W, Wang J. Discrimination of yellow\
    \ \nrust and powdery mildew in wheat at leaf level using spectral signatures.\
    \ \nIn: 2012 First international conference on agro-geoinformatics. 2012. p. \n\
    1–5.\n 31. Tian Y, Zhang L. Study on the methods of detecting cucumber downy \n\
    mildew using hyperspectral imaging technology. Phys Procedia. \n2012;33:743–50.\n\
    \ 32. Kuska M, Wahabzada M, Leucker M, Dehne H-W, Kersting K, Oerke E-C, \net\
    \ al. Hyperspectral phenotyping on the microscopic scale: towards auto-\nmated\
    \ characterization of plant-pathogen interactions. Plant Methods. \n2015;11:28.\n\
    \ 33. Sankaran S, Ehsani R, Inch SA, Ploetz RC. Evaluation of visible-near infrared\
    \ \nreflectance spectra of avocado leaves as a non-destructive sensing tool \n\
    for detection of laurel wilt. Plant Dis. 2012;96:1683–9.\n 34. Schafer RW. What\
    \ is a Savitzky-Golay filter?[lecture notes]. Signal Process \nMag IEEE. 2011;28:111–7.\n\
    \ 35. Huang J-F, Apan A. Detection of Sclerotinia rot disease on celery using\
    \ \nhyperspectral data and partial least squares regression. J Spat Sci. \n2006;51:129–42.\n\
    \ 36. Yuan L, Huang Y, Loraamm RW, Nie C, Wang J, Zhang J. Spectral analysis \n\
    of winter wheat leaves for detection and differentiation of diseases and \ninsects.\
    \ Field Crops Res. 2014;156:199–207.\n 37. Zhang J-C, Pu R, Wang J, Huang W, Yuan\
    \ L, Luo J. Detecting powdery \nmildew of winter wheat using leaf level hyperspectral\
    \ measurements. \nComput Electron Agric. 2012;85:13–23.\n 38. Qin J, Burks TF,\
    \ Ritenour MA, Bonn WG. Detection of citrus canker using \nhyperspectral reflectance\
    \ imaging with spectral information divergence. \nJ Food Eng. 2009;93:183–91.\n\
    \ 39. Bauriegel E, Giebel A, Geyer M, Schmidt U, Herppich WB. Early detection\
    \ \nof Fusarium infection in wheat using hyper-spectral imaging. Comput \nElectron\
    \ Agric. 2011;75:304–12.\n 40. Mahlein A-K, Steiner U, Hillnhütter C, Dehne H-W,\
    \ Oerke E-C. Hyperspec-\ntral imaging for small-scale analysis of symptoms caused\
    \ by different \nsugar beet diseases. Plant Methods. 2012;8:3.\n 41. Rumpf T,\
    \ Mahlein A-K, Steiner U, Oerke E-C, Dehne H-W, Plümer L. \nEarly detection and\
    \ classification of plant diseases with support vector \nmachines based on hyperspectral\
    \ reflectance. Comput Electron Agric. \n2010;74:91–9.\n 42. Passioura J. The drought\
    \ environment: physical, biological and agricul-\ntural perspectives. J Exp Bot.\
    \ 2007;58:113–7.\n 43. Thurau C, Kersting K, Bauckhage C. Yes we can: simplex\
    \ volume maxi-\nmization for descriptive web-scale matrix factorization. In: Proceedings\
    \ \nof 19th ACM international conference on information and knowledge \nmanagement\
    \ [Internet]. New York, NY: ACM; 2010 [cited 2015 Nov 3]. p. \n1785–8. http://doi.acm.org/10.1145/1871437.1871729.\n\
    \ 44. Römer C, Wahabzada M, Ballvora A, Rossini M, Panigada C, Behmann J, \net\
    \ al. Early drought stress detection in cereals: simplex volume maximisa-\ntion\
    \ for hyperspectral image analysis. Funct Plant Biol. 2012;39:878–90.\n 45. Behmann\
    \ J, Steinrücken J, Plümer L. Detection of early plant stress \nresponses in hyperspectral\
    \ images. ISPRS J Photogramm Remote Sens. \n2014;93:98–111.\n 46. Moshou D, Pantazi\
    \ X-E, Kateris D, Gravalos I. Water stress detection \nbased on optical multisensor\
    \ fusion with a least squares support vector \nmachine classifier. Biosyst Eng.\
    \ 2014;117:15–22.\n 47. Kersting K, Xu Z, Wahabzada M, Bauckhage C, Thurau C,\
    \ Roemer C, et al. \nPre-symptomatic prediction of plant drought stress using\
    \ dirichlet-aggre-\ngation regression on hyperspectral images. AAAI [Internet].\
    \ 2012 [cited \n2015 Nov 3]. https://www.aaai.org/ocs/index.php/AAAI/AAAI12/paper/\n\
    view/4932.\n 48. Polder G, van der Heijden GW, Keizer LP, Young IT. Calibration\
    \ and \ncharacterisation of imaging spectrographs. J Infrared Spectrosc. \n2003;11:193–210.\n\
    \ 49. Robles-Kelly A, Huynh CP. Imaging spectroscopy for scene analysis [Inter-\n\
    net]. Springer Science & Business Media; 2012 [cited 2016 Jan 19].\n 50. Vegetation\
    \ analysis: using vegetation indices in ENVI [Internet]. Exelis VIS \n[cited 2016\
    \ Jan 18]. http://www.exelisvis.com/Learn/WhitepapersDetail/\nTabId/802/ArtMID/2627/ArticleID/13742/Vegetation-Analysis-Using-\n\
    Vegetation-Indices-in-ENVI.aspx.\n 51. Sims DA, Gamon JA. Relationships between\
    \ leaf pigment content and \nspectral reflectance across a wide range of species,\
    \ leaf structures and \ndevelopmental stages. Remote Sens Environ. 2002;81:337–54.\n\
    \ 52. PEN¯UELAS J, Filella I, Lloret P, MUN¯OZ OZ, Vilajeliu M. Reflectance assess-\n\
    ment of mite effects on apple trees. Int J Remote Sens. 1995;16:2727–33.\n 53.\
    \ Barnes JD, Balaguer L, Manrique E, Elvira S, Davison AW. A reappraisal of \n\
    the use of DMSO for the extraction and determination of chlorophylls a \nand b\
    \ in lichens and higher plants. Environ Exp Bot. 1992;32:85–100.\n 54. Peñuelas\
    \ J, Baret F, Filella I. Semiempirical indices to assess carotenoids/\nchlorophyll\
    \ a ratio from leaf spectral reflectance. Photosynthetica \n1995;31:221–30.\n"
  inline_citation: '>'
  journal: Plant Methods
  limitations: '>'
  pdf_link: https://plantmethods.biomedcentral.com/track/pdf/10.1186/s13007-017-0233-z
  publication_year: 2017
  relevance_score1: 0
  relevance_score2: 0
  title: Hyperspectral image analysis techniques for the detection and classification
    of the early onset of plant disease and stress
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1016/j.rse.2013.07.031
  analysis: '>'
  authors:
  - Rocío Calderón
  - Juan A Navas‐Cortés
  - Carlos Lucena
  - Pablo J. Zarco‐Tejada
  citation_count: 338
  full_citation: '>'
  full_text: '>

    Skip to main content Skip to article Journals & Books Search Register Sign in
    Brought to you by: University of Nebraska-Lincoln View PDF Download full issue
    Outline Highlights Abstract Keywords 1. Introduction 2. Materials and methods
    3. Results and discussion 4. Conclusions Acknowledgments References Show full
    outline Cited by (352) Figures (12) Show 6 more figures Tables (3) Table 1 Table
    2 Table 3 Remote Sensing of Environment Volume 139, December 2013, Pages 231-245
    High-resolution airborne hyperspectral and thermal imagery for early detection
    of Verticillium wilt of olive using fluorescence, temperature and narrow-band
    spectral indices Author links open overlay panel R. Calderón, J.A. Navas-Cortés,
    C. Lucena, P.J. Zarco-Tejada Show more Add to Mendeley Share Cite https://doi.org/10.1016/j.rse.2013.07.031
    Get rights and content Highlights • Early detection of Verticillium wilt (VW)
    was investigated with remote sensing • Leaf data and airborne imagery correlated
    with physiology status due to the disease • Crown temperature (Tc-Ta, CWSI) were
    effective in detecting VW at early stages • Hyperspectral indices B, BG1, BR1
    and fluorescence detected VW at early stages • Structural indices (NDVI) and pigment
    indices were good only to assess damage Abstract Verticillium wilt (VW) caused
    by the soil-borne fungus Verticillium dahliae Kleb, is the most limiting disease
    in all traditional olive-growing regions worldwide. This pathogen colonizes the
    vascular system of plants, blocking water flow and eventually inducing water stress.
    The present study explored the use of high-resolution thermal imagery, chlorophyll
    fluorescence, structural and physiological indices (xanthophyll, chlorophyll a
    + b, carotenoids and blue/green/red B/G/R indices) calculated from multispectral
    and hyperspectral imagery as early indicators of water stress caused by VW infection
    and severity. The study was conducted in two olive orchards naturally infected
    with V. dahliae. Time series of airborne thermal, multispectral and hyperspectral
    imagery was acquired in three consecutive years and related to VW severity at
    the time of the flights. Concurrently to the airborne campaigns, field measurements
    conducted at leaf and tree-crown levels showed a significant increase in crown
    temperature (Tc) minus air temperature (Ta) and a decrease in leaf stomatal conductance
    (G) across VW severity levels, identifying VW-infected trees at early stages of
    the disease. Higher Tc − Ta and G values measured in the field were associated
    with higher VW severity levels. At leaf level, the reduction in G caused by VW
    infection was associated with a significant increase in the Photochemical Reflectance
    Index (PRI570) and a decrease in chlorophyll fluorescence (F). The airborne flights
    enabled the early detection of VW by using canopy-level image-derived airborne
    Tc − Ta, Crop Water Stress Index (CWSI) calculated from the thermal imagery, blue/blue–green/blue–red
    ratios (B/BG/BR indices) and chlorophyll fluorescence, confirming the results
    obtained in the field. Airborne Tc − Ta showed rising values with a significant
    increase of ~ 2 K at low VW severity levels, and was significantly correlated
    with G (R2 = 0.76, P = 0.002) and PRI570 (R2 = 0.51, P = 0.032). Early stages
    of disease development could be differentiated based on a CWSI increase as VW
    developed, obtaining a strong correlation with G (R2 = 0.83, P < 0.001). Likewise,
    the canopy-level chlorophyll fluorescence dropped at high VW severity levels,
    showing a significant increase as disease progressed. These results indicate the
    potentials of an early detection of V. dahliae infection and discrimination of
    VW severity levels using remote sensing. Indicators based on crown temperature
    such as CWSI, and visible ratios B/BG/BR as well as fluorescence were effective
    in detecting VW at early stages of disease development. In affected trees, the
    structural indices PRI, chlorophyll and carotenoid indices, and the R/G ratio
    were good indicators to assess the damage caused by the disease. Previous article
    in issue Next article in issue Keywords Stress detectionHyperspectralThermalFluorescenceHigh
    resolutionUAVPhysiological indicesVerticillium dahliae 1. Introduction Verticillium
    wilt (VW) of olive (Olea europea L.) trees, caused by the soil-borne fungus Verticillium
    dahliae Kleb., is the most limiting disease of this crop in all traditional olive-growing
    regions worldwide (Jiménez-Díaz et al., 2012, Tsror (Lahkim), 2011) and causes
    severe yield losses and tree mortality (Levin, Lavee, & Tsror, 2003). In Spain,
    the first reports of the disease, which was found to affect olive crops in the
    Guadalquivir valley, were documented in the early 1980s (Blanco-López, Jiménez-Díaz,
    & Caballero, 1984). However, in the last 15–20 years the disease has spread to
    affect newly established irrigated crops (Jiménez-Díaz et al., 2011, Sánchez-Hernández
    et al., 1998). Under field conditions, the first VW symptoms in irrigated olive
    trees growing in V. dahliae-infested orchards develop 18–24 months after plantation,
    depending on the density of pathogen propagules in the soil, the V. dahliae pathotype
    prevailing in the soil, the olive cultivar susceptibility and the environmental
    conditions (Levin et al., 2003, Navas-Cortés et al., 2008). In the Mediterranean
    region, over an annual cropping season, disease incidence and symptom severity
    typically increase from late autumn–early winter to spring and sharply decrease
    in summer, with no further development until the next autumn; this results in
    polyetic epidemics over several cropping seasons (Navas-Cortés et al., 2008).
    V. dahliae can be found in agricultural soils as resistant survival structures
    called ‘microsclerotia’ that are stimulated to germinate by root exudates (Schreiber
    & Green, 1963) and favorable soil environmental conditions, forming hyphae that
    penetrate into the plant roots and grow into their tissues until they reach the
    xylem vessels. The rapid upward spread of the pathogen in vascular tissues occurs
    primarily through conidia transported with the transpiration stream (Emechebe
    et al., 1975, Garber and Houston, 1966, Presley et al., 1966, Talboys, 1962).
    This enables the pathogen to spread throughout the aerial parts of its host within
    one growing season. The net effect of pathogen infection is a reduction in water
    flow that induces water stress and is thought to be mainly responsible for the
    vascular wilt syndrome caused by V. dahliae and other wilt pathogens (Ayres, 1978,
    DeVay, 1989, Van Alfen, 1989). Water stress in plants caused by either V. dahliae
    infection or drought-induced stomatal closure reduces the transpiration rate.
    In turn, this decreases evaporative cooling and increases leaf temperature. Early
    detection of water stress using remote sensing has been successfully achieved
    in the past using thermal infrared radiation (Idso et al., 1978, Idso et al.,
    1981, Jackson and Pinter, 1981, Jackson et al., 1977, Jackson et al., 1981). Thermal
    remote sensing of water stress has been fulfilled using spectrometers at ground
    level (Idso et al., 1981, Idso et al., 1978, Jackson et al., 1977, Jackson et
    al., 1981), thermal sensors at image level (Berni, Zarco-Tejada, Suárez and Fereres,
    2009, Cohen et al., 2005, Leinonen and Jones, 2004, Sepulcre-Cantó et al., 2006,
    Sepulcre-Cantó et al., 2007, Zarco-Tejada et al., 2012) and satellite thermal
    imagery (Sepulcre-Cantó et al., 2009). Working with hand-held infrared thermometers
    on herbaceous crops, Jackson and co-workers (Idso et al., 1978, Jackson et al.,
    1981) developed the Crop Water Stress Index (CWSI), which became a popular thermal-based
    stress indicator. The CWSI is based on the normalization of differences between
    canopy (Tc) and air temperature (Ta) with evaporative demand (by means of the
    vapor pressure deficit). Apart from the progress made in water-stress detection
    using the thermal region, the visible part of the spectrum has also been useful
    for early water stress detection. This involves using indices focused on bands
    located at specific wavelengths where photosynthetic pigments are affected by
    stress conditions. Two spectral indicators of water stress, spanning initial through
    severe disease symptoms, are widely used. One is the Photochemical Reflectance
    Index (PRI) (Gamon, Peñuelas, & Field, 1992). This index is sensitive to the epoxidation
    state of the xanthophyll cycle pigments and to photosynthetic efficiency, serving
    as a proxy for water stress detection (Peguero-Pina et al., 2008, Suárez et al.,
    2009, Suárez et al., 2010, Suárez et al., 2008, Thenot et al., 2002). Another
    indicator of water stress is solar-induced chlorophyll fluorescence emission (Flexas
    et al., 2000, Flexas et al., 1999, Flexas et al., 2002, Moya et al., 2004, Zarco-Tejada
    et al., 2009, Zarco-Tejada et al., 2012), because of the strong correlation found
    between steady-state chlorophyll fluorescence and the reduced assimilation caused
    by water stress conditions. The PRI has been used to assess pre-visual water stress
    at leaf level (Thenot et al., 2002, Winkel et al., 2002), at canopy level (Dobrowsky
    et al., 2005, Evain et al., 2004, Peguero-Pina et al., 2008, Sun et al., 2008)
    and using airborne imaging spectroscopy (Suárez et al., 2009, Suárez et al., 2010,
    Suárez et al., 2008). Chlorophyll fluorescence is associated with photosynthesis
    and other physiological processes, as demonstrated consistently in laboratory
    studies (e.g., Krause and Weis, 1984, Papageorgiu, 1975). Over the last five years,
    scientific interest in steady-state chlorophyll fluorescence (Fs) obtained under
    natural outdoor conditions has increased due to its potential development using
    remote sensing methods (Soukupová et al., 2008). Although the contribution of
    fluorescence to the vegetation''s radiance signal is estimated to be 2–3%, methods
    have been developed to extract the signal (Meroni et al., November 17-19 2004,
    Meroni, Picchi, et al., 2008, Meroni, Rossini, et al., 2008, Meroni et al., 2009,
    Moya et al., 2004), proving the feasibility of the fluorescence retrieval using
    the O2-A absorption feature at 760 nm. Remote sensing has been used to detect,
    monitor and quantify a range of diseases in different crops. Comprehensive reviews
    on the application of remote sensing to the detection of plant diseases are available
    (e.g., Barton, 2012, Hatfield and Pinter, 1993, Jackson, 1986, Nilsson, 1995,
    Sankaran et al., 2010, West et al., 2003). Most studies have focused on foliar
    pathogens in annual crops, where disease symptoms are mainly characterized by
    distinct color changes in the aerial parts of the plant. However, this technology
    also has shown potential for detecting root diseases in several crops (e.g., Raikes
    and Burpee, 1998, Reynolds et al., 2012, Wang et al., 2004). Canopy temperature
    has shown to be particularly useful to detect root impairment caused by soil-borne
    pathogens that lead to water stress symptoms, as mentioned above. In fact, Pinter
    et al. (1979) found foliar temperatures 3–4 °C higher than those of healthy plants
    in sugar beet and cotton. Other examples of the use of leaf temperature for the
    detection of diseases caused by soil-borne pathogens include beans infected with
    Fusarium solani, Pythium ultimum or Rhizoctonia solani (Tu & Tan, 1985); soybeans
    affected by brown stem rot caused by Phialophora gregata (Mengistu, Tachibana,
    Epstein, Bidne, & Hatfield, 1987); the flag leaf temperature of cereals with root
    and vascular diseases, such as barley infected by Pyrenophora graminea and wheat
    infected with Cephalosporium gramineum (Nilsson, 1995); and wheat with moderate
    take-all symptoms caused by Gaeumannomyces graminis var. tritici (Nilsson, 1991).
    Other approaches have included the use of multispectral and hyperspectral imagery,
    as well as airborne digital color or video imagery, to detect crop diseases. Multispectral
    imagery enabled the detection of head blight in winter wheat (Dammer, Möller,
    Rodemann, & Heppner, 2011), assessment of severity of soybean root rot (Wang et
    al., 2004) and to evaluate Rhizoctonia blight in creeping bentgrass (Raikes &
    Burpee, 1998). Hyperspectral canopy reflectance was used to quantify Rhizoctonia
    crown and root rot in sugar beet (Reynolds et al., 2012) and to detect the co-infection
    of sugar beet with this pathogen and the plant parasitic nematode Heterodera schachatii
    (Hillnhütter, Mahlein, Sikora, & Oerke, 2011) as well as Fusarium head blight
    in wheat (Bauriegel, Giebel, Geyer, Schmidt, & Herppich, 2011). Some research
    has been conducted on remote detection of diseases caused by V. dahliae. Nilsson
    (1995) reported that oilseed rape plants infected with V. dahliae exhibited leaf
    temperatures 5–8 °C higher than non-infected plants. Chen et al., 2008, Chen et
    al., 2011 reported the application of hyperspectral reflectance to identify cotton
    canopy affected by VW. They found that the spectral characteristics of infected
    plants changed gradually with the increase in the visible region with disease
    severity, while a reduction occurred in the near-infrared region. Yet, to our
    knowledge remote sensing physiological indices and fluorescence indicators have
    not been used to study olive tree diseases. The main objective of this research
    was to evaluate the use of high-resolution thermal imagery and physiological indices
    calculated from multispectral and hyperspectral imagery as indicators of VW infection
    and severity in olive orchards. Time series of airborne thermal, multispectral
    and hyperspectral imagery were acquired in three consecutive campaigns and related
    to VW severity at the time of the flight. The hypothesis is that thermal and hyperspectral
    indices acquired from the airborne imagery are sensitive to physiological changes
    induced by the infection and colonization by V. dahliae. 2. Materials and methods
    2.1. Study site description The experimental areas were located in Andalucia,
    in southern Spain, a region of Mediterranean climate characterized by warm and
    dry summers and cool and wet winters, with an average annual rainfall of over
    550 mm. Two study sites were selected in the Cordoba and Seville provinces, respectively,
    to account for differences in weather conditions, crop age and tree-crown size,
    olive cultivars with different reactions to VW and VW incidence and severity.
    The first study site was located in Castro del Rio (Cordoba province, Spain) (37°
    42′ 20″ N, 4° 30′ 45″ W) in a 7-ha commercial orchard planted in 2001 with the
    olive cultivar (cv.) Picual at a spacing of 6 × 4 m (Fig. 1a). Cv. Picual has
    been found to be highly susceptible to D and susceptible to ND V. dahliae, under
    controlled conditions in artificial inoculation tests (López-Escudero, del Rio,
    Caballero, & Blanco-López, 2004). The initial VW incidence (i.e., percentage of
    VW symptomatic trees) was estimated in 12%. The second study site was located
    in Utrera (Seville province, Spain) (37° 4′ 42″ N, 5° 50° 58″ W), in a 10-ha commercial
    orchard planted in 2006 with cv. Arbequina (Fig. 1b). Cv. Arbequina has been shown
    to be susceptible to D and moderately resistant to ND V. dahliae, under controlled
    conditions in artificial inoculation tests (López-Escudero et al., 2004). The
    olive trees were planted at a spacing of 6 × 3 m. The initial VW incidence was
    estimated in 30%. Both orchards were drip irrigated and managed using no-tillage
    practices; weed control was achieved with herbicide treatments between rows. Download
    : Download high-res image (350KB) Download : Download full-size image Fig. 1.
    Overview of the two study sites in southern Spain used in this study: (a) 7 ha
    commercial olive orchard in Castro del Rio (Cordoba province); and (b) 10-ha commercial
    olive orchard in Utrera (Seville province). 2.2. Verticillium wilt assessment
    Incidence and severity of VW symptoms were assessed in both plots in spring and
    summer of 2009, 2010 and 2011 in coincidence with airborne campaigns. Severity
    of the disease was assessed by visual observation of foliar symptoms in each individual
    tree and assessment on a 0 to 4 rating scale according to the percentage of foliage
    with disease symptoms, where: 0 = 0%, 0.2 and 0.5 = initial symptoms, 1 = 1 to
    33%, 2 = 34 to 66%, 3 = 67 to 100%, and 4 = dead plant. V. dahliae infection was
    confirmed in a sample from each experimental plot by isolating six stem fragments
    sampled from each of four young symptomatic branches per symptomatic tree as previously
    described (Navas-Cortés et al., 2008). Identification of V. dahliae isolates was
    based on the morphology of conidiophores and microsclerotia and confirmed by molecular
    typing through PCR assay using primers DB19/DB22/espdef01 (Mercado-Blanco, Rodríguez-Jurado,
    Parrilla-Araujo, & Jiménez-Díaz, 2003); this method yielded a polymorphic amplicon
    of 523 or 539 bp specific to V. dahliae. PCR amplification and gel electrophoresis
    were conducted as described previously (Mercado-Blanco et al., 2003). 2.3. Field
    measurements Leaf and near-canopy field measurements were conducted in the olive
    orchard located in Castro del Rio (Cordoba) during the summer of 2011 to take:
    a) diurnal measurements throughout the day to monitor the diurnal variation of
    crown temperature (Tc − Ta) and stomatal conductance (G) in trees covering a gradient
    in severity levels; and b) leaf and crown measurements at midday to monitor the
    variation along the VW severity levels of Tc − Ta, leaf chlorophyll fluorescence,
    leaf Photochemical Reflectance Index (PRI570) (Gamon et al., 1992) and leaf stomatal
    conductance (G). Eight trees showing different VW severity levels were selected
    to record pure crown temperature (Tc) with the objective of monitoring its diurnal
    variation. These measurements were conducted from 7:00 to 17:00 GMT at 5-minute
    intervals in two dataloggers (model CR10X, Campbell Sci., Logan, UT, USA) with
    infrared temperature (IRT) sensors (22° half-angle FOV) (model IRR-P, Apogee,
    Logan, UT, USA) placed 1 m above trees. The single-band infrared temperature (IRT)
    sensors covered the 6.5–14 μm range and were evaluated both in the laboratory
    and in field conditions to characterize the IRT response to diurnal temperature
    variation (Sepulcre-Cantó et al., 2006). The results yielded errors within the
    accuracy limits of the instrument (± 0.4 °C) over a 5° to 40 °C range. The instruments
    were calibrated in the laboratory using a uniform calibration body (integrating
    sphere, CSTM-USS-2000C Uniform Source System, LabSphere, NH, USA) at two different
    levels of illumination. This procedure has been reported to be successful in other
    studies focused on monitoring crown temperature as an indicator of water stress
    (Berni, Zarco-Tejada, Suárez and Fereres, 2009, Sepulcre-Cantó et al., 2006, Zarco-Tejada
    et al., 2012). Air temperature (Ta) and relative humidity (RH) were measured above
    the canopy with a portable weather station (Model WXT510, Vaisala, Finland) placed
    1 m above the canopy (approx. 6 m above the ground). In each of the eight monitored
    trees, leaf stomatal conductance was measured from 7:00 to 17:00 GMT at 2-hour
    intervals with a leaf porometer (model SC-1, Decagon Devices, Washington, DC,
    USA) to monitor the diurnal variation of crown stomatal conductance for the different
    VW severity levels. A total of five illuminated leaves per tree were measured
    at each time interval. In addition to the diurnal measurements conducted for temperature
    and stomatal conductance, 25 trees covering a gradient in severity levels from
    asymptomatic to severely affected trees were chosen to monitor the variation of
    Tc − Ta, leaf chlorophyll fluorescence, leaf PRI570 and leaf G between 10:00 and
    13:00 GMT on 27 and 28 July 2011. Leaf chlorophyll fluorescence measurements taken
    under natural sunlight conditions were conducted using the PAM-2100 Pulse-Amplitude
    Modulated Fluorometer (Heinz Walz GMBH, Effeltrich, Germany). This device measured
    steady-state Fs and Fm'' fluorescence parameters in 25 illuminated leaves per
    tree. Leaf PRI570 measurements calculated as (R570 − R531) / (R570 + R531) (Suárez
    et al., 2009, Suárez et al., 2010, Suárez et al., 2008, Zarco-Tejada et al., 2012)
    were taken in 25 illuminated leaves per tree with a PlantPen instrument custom
    designed to measure the R531 and R570 bands (Photon System Instrument, Brno, Czech
    Republic). Leaf G was measured in five illuminated leaves per tree with the leaf
    porometer previously used. 2.4. Airborne campaigns and remote sensing indices
    Imagery in the three years of experiments was acquired from both study sites using
    narrow-band multispectral, hyperspectral and thermal cameras. The multispectral
    and thermal cameras were used in airborne campaigns conducted twice per crop season
    in spring (April/May) and summer (July) of 2009 and 2010. In addition, the thermal
    camera was flown twice in June 2011. The multispectral and thermal imagery was
    always acquired at similar sun angles at 10:30 and 12:00 GMT respectively to minimize
    differences due to sun angle effects between airborne campaigns. Hyperspectral
    and thermal images were acquired from the Castro del Rio site on 23 June 2011
    at 9:00 GMT using a hyperspectral imager concurrently with the thermal camera
    operated in 2009 and 2010. The flights were conducted with two different unmanned
    aerial vehicles (UAVs) operated by the Spanish Laboratory for Research Methods
    in Quantitative Remote Sensing (Quantalab, IAS-CSIC, Spain) (Berni, Zarco-Tejada,
    Suárez and Fereres, 2009, Zarco-Tejada et al., 2008, Zarco-Tejada et al., 2012).
    The UAV used for the multispectral and thermal acquisition had a 2-m wingspan
    for a fixed-wing platform at 5.8 kg take-off weight (TOW) (mX-SIGHT, UAV Services
    and Systems, Germany) capable of 1-hour endurance. Hyperspectral images were acquired
    with a larger UAV with a 5-m wingspan for a fixed-wing platform having 13.5 kg
    take-off weight (TOW) (Viewer, ELIMCO, Seville, Spain) capable of 3-hour endurance.
    This larger platform was required when operating the hyperspectral imager due
    to the heavier payload. Both UAV platforms were controlled by an autopilot system
    (AP04, UAV Navigation, Madrid, Spain) that provided autonomous navigation based
    on coordinates programmed during the mission planning. The multispectral sensor
    consisted of a 6-band multispectral camera (MCA-6, Tetracam, Inc., California,
    USA) flying at 250 m above ground level (AGL). The camera was equipped with six
    independent image sensors and optics with 25-mm diameter filters of 10-nm full
    width at half-maximum (FWHM) bandwidth (Berni, Zarco-Tejada, Suárez and Fereres,
    2009, Zarco-Tejada et al., 2009). Image resolution was 2592 × 1944 pixels with
    10-bit radiometric resolution and an optical focal length of 8.4 mm, yielding
    an angular field of view (FOV) of 38.04° × 28.53° and a spatial resolution of
    20 cm at 250 m altitude (Fig. 2a). The band sets used in each study site included
    centered wavelengths at 450, 490, 530, 570, 670 and 800 nm. Download : Download
    high-res image (950KB) Download : Download full-size image Fig. 2. Multispectral
    scene (a) obtained with the multispectral camera on board the UAV platform at
    20-cm resolution, showing the Castro del Rio orchard study site (Córdoba province).
    (b) Automatic object-based crown detection applied to the multispectral imagery
    to identify pure olive crowns. Yellow square (a) shown in detail in (b). The hyperspectral
    imager (Micro-Hyperspec VNIR model, Headwall Photonics, MA, USA) was flown in
    2011 at Castro del Río site in the spectral mode with 260 bands at 1.85 nm/pixel
    at 12-bit radiometric resolution. It yielded a 3.2-nm FWHM with a 12-micron slit
    and a 6.4-nm FWHM with a 25-micron slit. Data acquisition and storage on board
    the UAV was set to 50 fps with 18-ms integration time. The 8-mm optical focal
    length yielded an IFOV of 0.93 mrad and an angular FOV of 49.82°, obtaining a
    swath of 522 m at 53 × 42 cm resolution, resampled to 40 cm (Fig. 3a) for a flight
    conducted at 550 m AGL altitude and 75 km/h ground speed (Zarco-Tejada et al.,
    2012). Download : Download high-res image (1MB) Download : Download full-size
    image Fig. 3. Hyperspectral scene (a) obtained with the hyperspectral imager on
    board the UAV platform at 40 cm resolution. Automatic object-based crown detection
    applied to the hyperspectral imagery to identify pure olive crowns (b). The methodology
    enabled the separation of pure olive crowns from shaded and sunlit soil reflectance,
    observing the effects of pixel aggregation (c). Yellow square (a) shown in detail
    in (b). The multispectral and hyperspectral images were radiometrically calibrated
    with a uniform light source system (integrating sphere, CSTM-USS-2000C Uniform
    Source System, LabSphere, NH, USA) at four different levels of illumination and
    six different integration times. Atmospheric correction was performed with the
    SMARTS simulation model developed by the National Renewable Energy Laboratory,
    US Department of Energy (Gueymard, 1995, Gueymard, 2001). This was done using
    aerosol optical depth measured at 550 nm with a Micro-Tops II sunphotometer (Solar
    LIGHT Co., Philadelphia, PA, USA). This radiative transfer model has been used
    in previous studies to perform the atmospheric correction of both narrow-band
    multispectral and hyperspectral imagery (Berni, Zarco-Tejada, Sepulcre-Cantó,
    Fereres and Villalobos, 2009, Berni, Zarco-Tejada, Suárez and Fereres, 2009, Suárez
    et al., 2010, Zarco-Tejada et al., 2012). A miniaturized inertial measurement
    unit (IMU) installed on board the UAV and synchronized with the hyperspectral
    imager acquired altitude data at 100 Hz frequency. The imagery was later orthorectified
    using PARGE software (ReSe Applications Schläpfer, Wil, Switzerland) (Fig. 3a).
    The mean radiance and reflectance spectra calculated for the six spectral bands
    obtained by the multispectral camera and the 260 spectral bands acquired by the
    hyperspectral imager were then used to calculate several spectral indices related
    to: i) tree crown structure; ii) epoxidation state of the xanthophyll cycle; iii)
    chlorophyll a + b concentration; iv) blue/green/red ratio indices; v) carotenoid
    concentration; vi) chlorophyll fluorescence and vii) spectral disease indices
    (Table 1). Table 1. Overview of the vegetation indices used in this study and
    their formulations. Vegetation indices Equation Reference Structural indices Normalized
    Difference Vegetation Index NDVI = (R800 − R670)/(R800 + R670) Rouse et al. (1974)
    Renormalized Difference Vegetation Index Rougean and Breon (1995) Optimized Soil-Adjusted
    Vegetation Index OSAVI = ((1 + 0.16)·(R800 − R670)/(R800 + R670 + 0.16)) Rondeaux
    et al. (1996) Triangular Vegetation Index TVI = 0.5·[120·(R750 − R550) − 200·(R670
    − R550)] Broge and Leblanc (2000) Modified Triangular Vegetation Index MTVI =
    1.2·[1.2·(R800 − R550) − 2.5·(R670 − R550)] Haboudane et al. (2004) Simple Ratio
    SR = R800/R670 Jordan (1969) Modified Simple Ratio Chen (1996) Xanthophyll indices
    Photochemical Reflectance Index (570) PRI570 = (R570 − R531)/(R570 + R531) Gamon
    et al. (1992) Photochemical Reflectance Index (515) PRI515 = (R515 − R531)/(R515
    + R531) Hernández-Clemente et al. (2011) Chlorophyll a+b indices RedEdge ZM =
    R750/R710 Zarco-Tejada et al. (2001) Vogelmann VOG1 = R740/R720 Vogelmann et al.
    (1993) Gitelson and Merzlyak indices GM1 = R750/R550 Gitelson and Merzlyak (1997)
    GM2 = R750/R700 Gitelson and Merzlyak (1997) Pigment Specific Simple Ratio Chlorophyll
    a PSSRa = R800/R675 Blackburn (1998) Pigment Specific Simple Ratio Chlorophyll
    b PSSRb = R800/R650 Blackburn (1998) Modified Chlorophyll-Absorption-Integral
    Laudien et al. (2003) Transformed Chlorophyll Absorption in Reflectance Index
    TCARI = 3·[(R700 − R670) − 0.2·(R700 − R550)·(R700/R670)] Haboudane et al. (2002)
    Transformed Chlorophyll Absorption in Reflectance Index/Optimized Soil-Adjusted
    Vegetation Index Haboudane et al. (2002) R/G/B indices Redness index R = R700/R670
    Gitelson et al. (2000) Greenness index G = R570/R670 This study Blue index B =
    R450/R490 This study Blue/green indices BGI1 = R400/R550 Zarco-Tejada et al. (2005)
    BGI2 = R450/R550 Zarco-Tejada et al. (2005) Blue/red indices BRI1 = R400/R690
    Zarco-Tejada et al. (2012) BRI2 = R450/R690 Zarco-Tejada et al. (2012) Lichtenhaler
    index LIC3 = R440/R740 Lichtenhaler et al. (1996) Carotenoid indices Structure-Intensive
    Pigment Index SIPI = (R800 − R445)/(R800 + R680) Peñuelas et al. (1995) Pigment
    Specific Simple Ratio Carotenoids PSSRc = R800/R500 Blackburn (1998) R520/R500
    R520/R500 Zarco-Tejada et al. (2012) R515/R570 R515/R570 Zarco-Tejada et al. (2012)
    R515/R670 R515/R670 Zarco-Tejada et al. (2012) Fluorescence FLD FLD3(747;762;780)
    Plascyk (1975) Maier et al. (2003) Zarco-Tejada et al. (2005) Plant disease index
    Healthy-index Mahlein et al. (2013) Crop water stress index CWSI Jackson et al.
    (1981) The chlorophyll fluorescence retrieval method used was based on the FLD
    principle (Plascyk, 1975) using three bands as in Maier et al. (2003) (see Zarco-Tejada
    et al., 2012 for fluorescence quantification in a citrus crop using this same
    hyperspectral imager). Previous results demonstrated the feasibility of retrieving
    the chlorophyll fluorescence signal using this hyperspectral imager (Zarco-Tejada
    et al., 2013, Zarco-Tejada et al., 2012). For this reason, the FLD principle could
    be applied to the hyperspectral imagery to estimate the fluorescence signal, using
    a total of three bands required for the FLD3 method, where the band inside the
    O2-A feature (the “in” wavelength indicates the radiance at L763 nm) and the radiances
    (L750 nm; L780 nm) determined at two wavelengths outside and on either side of
    the O2-A feature, referred to as the “out” bands. The thermal camera (MIRICLE
    307, Thermoteknix Systems Ltd, Cambridge, UK) installed on board the two UAVs
    operated in this study was flown over the experimental sites at altitudes ranging
    between 150 m and 250 m AGL in 2009 and 2010, and at 550 m AGL when flown together
    with the hyperspectral imager in 2011 in the morning (~ 9:00 GMT). This camera
    had a 14.25 mm f1.3 lens connected to a computer via a USB 2.0 protocol. The image
    sensor was a Focal Plane Array (FPA) based on uncooled microbolometers with a
    spectral range of 8–12 μm, yielding a 25 μm pixel size. The camera delivered raw
    images with a 640 × 480 pixel resolution and 14-bit at-sensor uncalibrated radiance.
    The camera was radiometrically calibrated in the laboratory using blackbodies
    at varying target and ambient temperatures to develop radiometric calibration
    algorithms along with an internal calibration for non-uniformity correction (NUC).
    Thermal images were acquired at 20 cm pixel resolution, enabling the retrieval
    of “pure crown” average temperature from each tree studied (Fig. 4a). Local atmospheric
    conditions were determined by air temperature, relative humidity and barometric
    pressure at the time of flight using a portable weather station (Model WXT510,
    Vaisala, Finland). Download : Download high-res image (979KB) Download : Download
    full-size image Fig. 4. Thermal scene (a) of the Castro del Rio site (Córdoba
    province) obtained with the thermal camera on board the UAV platform at 20-cm
    resolution, enabling pure olive crown identification (b). Automatic object-based
    crown detection applied to the thermal imagery to identify pure olive crowns (c).
    Yellow square (a) shown in detail in (b; c). The high-resolution imagery acquired
    over the orchards enabled single tree identification for field validation purposes
    (Fig. 4b), successfully separating pure crown from soil pixels (Fig. 3c). Each
    single pure tree crown in the entire orchard was identified using automatic object-based
    crown detection algorithms (Figs. 2b;3b;4c). The algorithms applied to the thermal,
    multispectral and hyperspectral imagery enabled calculation of mean temperature
    and multispectral and hyperspectral reflectance at pure-crown level for the entire
    scenes acquired with the unmanned vehicles. The Crop Water Stress Index (CWSI)
    was calculated for each single tree crown using the high-resolution airborne thermal
    imagery acquired as described in Berni, Zarco-Tejada, Sepulcre-Cantó, Fereres,
    and Villalobos (2009), with the inputs detailed in Table 2. Table 2. Inputs used
    to calculate the Crop Water Stress Index (CWSI) from high resolution airborne
    thermal imagery acquired in June 2011 in the Castro del Rio site. The CWSI was
    calculated as described in Berni et al. (2009a). Inputs Values 2 June 2011 15
    June 2011 Air temperature (°C) 22.93 29.58 Relative humidity (%) 30.31 30.14 Wind
    speed (m/s) 1 1 Wind measurement height (m) 5 5 Atmospheric pressure (kPa) 99.45
    99.60 Cloudiness 0.2 0.2 Latitude (°N) 37.7058 37.7058 Longitude (°E) − 4.5117
    − 4.5117 Altitude (m) 236 236 Solar time (decimal hour) 12.05 12.35 DOY 153 166
    Canopy temperature (°C) From image From image Canopy height (m) 4 4 Frontal LAI
    1 1 Canopy emissivity ε 0.98 0.98 2.5. Data analyses Field and airborne data and
    indices calculated were subjected to standard analysis of variance (ANOVA) using
    the general linear model (GLM) procedure of SAS 9.2 (SAS Institute Inc., NC, USA).
    The Dunnett''s two-tailed test was used to determine significant differences between
    asymptomatic trees and each of the disease severity levels at P < 0.05. 3. Results
    and discussion 3.1. Verticillium wilt symptom development VW symptoms developed
    extensively in both study sites from early autumn to early winter, reaching their
    maximum expression during the spring. In the Utrera study site, characterized
    by 3-year-old cv. Arbequina olive trees, the symptoms consisted mainly of an extensive
    early drop of infected leaves that were still green; in most cases, this caused
    a complete defoliation and necrosis of affected branches. In the more established
    Castro del Rio study site, characterized by 10-yr old cv. Picual olive trees,
    affected plants mainly exhibited a quick dieback of olive twigs and branches where
    leaves turned light brown, rolled back toward the abaxial side and dried up, but
    typically remained attached to the symptomatic shoots. In both experimental sites,
    if the first VW symptoms developed in the spring, the trees underwent flower mummification
    and necrosis of both inflorescences and leaves of affected shoots, which usually
    fell. The type of VW symptoms and temporal dynamics of VW epidemics observed in
    both study sites were similar to those described in olive orchards affected by
    VW in southern Spain (Navas-Cortés et al., 2008). In May 2009, 13.7 and 32.2%
    of trees were affected by VW in the Castro del Rio and Utrera study sites, respectively
    (Fig. 5a,c), with a mean disease severity in symptomatic trees of 1.26 and 1.19
    (0–4 rating scale), respectively. These figures were determined from 41.4% that
    showed initial disease severity (DS) symptoms (0 > DS ≤ 0.5), 37.5% had low disease
    severity symptoms (0.5 > DS ≤ 1.5), 12.7% had moderate disease severity symptoms
    (1.5 > DS ≤ 2.5) and 8.4% of symptomatic trees had severe (DS ≥ 3) disease symptoms
    at Castro del Rio. At Utrera, 32.7, 43.0, 17.7 and 6.6% of trees showed these
    same severity levels, respectively (Fig. 5). During the spring of 2009, the disease
    progressed in both study sites to reach a global incidence of 15.9 and 39.3% in
    summer at Castro del Rio and Utrera, respectively (Fig. 5b,d); however, a similar
    frequency of trees remained in the three severity classes indicated above. In
    the 2010 season, overall disease incidence increased to 17.3 and 44.7% at Castro
    del Rio and Utrera, respectively (Fig. 5b,d), but mean disease severity decreased
    to 1.10 and 1.05 in both sites, respectively. However, minor differences were
    observed between both sites and the two assessment dates regarding the frequency
    of affected trees in the three severity classes. The overall frequency of trees
    at Castro del Rio in the four severity classes ranged from initial (47.3–53.9%),
    to low (35.6–31.4%), moderate (7.8–1.1%) and severe (9.3–1.6%) disease symptoms
    (Fig. 5b,d). Download : Download high-res image (390KB) Download : Download full-size
    image Fig. 5. Frequency (%) of olive trees showing Verticillium wilt (VW) symptoms
    at the different severity values in Castro del Rio (Córdoba province) (a,b) and
    Utrera (Seville province) (c,d) study sites assessed in May and July of 2009 (a,c)
    and 2010 (b,d). VW severity was assessed by visual inspection of each individual
    tree using a 0–4 rating scale according to percentage of foliage with disease
    symptoms, where: 0 = 0%, IS = initial symptoms, 1 = 1 to 33%, 2 = 34 to 66%, 3
    = 67 to 100% and 4 = dead plant. Severity of disease symptoms was grouped in asymptomatic
    (DS = 0), initial (0.2 ≤ DS ≤ 0.5), low (1 ≤ DS ≤ 1.5), moderate (2 ≤ DS ≤ 2.5)
    and severe (3 ≤ DS ≤ 4) disease symptoms. 3.2. Field measurement results Diurnal
    crown measurements were conducted with the IRT sensors on trees selected to represent
    asymptomatic trees and those showing initial, low, moderate and severe disease
    symptoms. Results revealed that midday (i.e., 10:00 to 14:00 GMT) was the best
    time period to maximize differences in Tc − Ta values. In fact, Tc − Ta values
    at midday increased with the rise in disease severity level (Fig. 6), showing
    up to 7 K temperature differences between asymptomatic trees (DS = 0) and severely
    affected trees (DS ≥ 3). Moreover, Tc − Ta values were able to discriminate asymptomatic
    trees from those affected at early stages of disease development (DS ≤ 1.5), which
    showed Tc − Ta values from 1 to 2.5 K higher. These results showing lower Tc −
    Ta values in asymptomatic than in symptomatic diseased olive trees are in agreement
    with other studies. Thus, Nilsson (1995) reported higher leaf temperatures in
    oil seed plants infected with V. dahliae. The leaf stomatal conductance (G) data
    measured on the same trees consistently showed a decrease in stomatal conductance
    values as crown temperature and disease severity levels increased (Fig. 7). These
    results are in agreement with Berni, Zarco-Tejada, Suárez, and Fereres (2009)
    and Sepulcre-Cantó et al. (2006), who assessed the relationship between stomatal
    conductance and water stress levels due to deficit irrigation practices in olive
    trees using thermal sensors and a leaf porometer. A greater difference in stomatal
    conductance between healthy asymptomatic trees and VW-affected trees was recorded
    in the morning, with G differences up to 900 mmol/m2/s between trees with extreme
    DS values (i.e., DS = 0 vs. DS ≥ 3). These differences decreased to a maximum
    of 700 mmol/m2/s at midday and declined to 500 mmol/m2/s after sunset. In addition,
    our results showed that stomatal conductance was able to discriminate between
    healthy trees and those at early stages of disease development, which had G values
    at least 300–500 mmol/m2/s lower than those of healthy trees. Download : Download
    high-res image (239KB) Download : Download full-size image Fig. 6. Diurnal mean
    crown temperature (Tc − Ta) measured from 7:00 to 17:00 GMT at 5-minute intervals
    and obtained with the IRT sensors from trees showing different Verticillium wilt
    severity levels in the Castro del Rio site (Córdoba province) in the summer of
    2011. Download : Download high-res image (174KB) Download : Download full-size
    image Fig. 7. Diurnal mean leaf stomatal conductance G measured from 7:00 to 17:00
    GMT at 2-hour intervals and obtained with the leaf porometer from trees showing
    different Verticillium wilt severity levels (n = 5 per tree at each measuring
    time) in the Castro del Rio site (Córdoba province) in the summer of 2011. Data
    on crown temperature (Tc − Ta), leaf stomatal conductance (G), leaf PRI570 and
    fluorescence (Fs) acquired between 10:00 and 13:00 GMT in July 2011 were analyzed
    in trees with different VW severity levels (Fig. 8). Crown temperature data (Tc
    − Ta) measured at midday with IRT sensors in VW affected trees was significantly
    (P < 0.05) higher than that measured in asymptomatic trees, being highest for
    trees affected by severe VW symptoms (Fig. 8a). By contrast, stomatal conductance
    G showed a negative trend as VW severity increased, showing significant (P < 0.05)
    changes from asymptomatic trees at those showing moderate and severe symptoms
    (DS ≥ 2) (Fig. 8b). Moreover, PRI570 was lowest (P < 0.05) in asymptomatic trees,
    and increased steadily with the increase in VW severity (Fig. 8c). These results
    are consistent with that obtained by Suárez et al. (2008, 2009) in water-stressed
    trees. Leaf chlorophyll fluorescence measurements of Fs (Fig. 8d) showed a downward
    trend as VW severity level increased as previously found for trees under water
    stress (Pérez-Priego et al., 2005, Zarco-Tejada et al., 2009, Zarco-Tejada et
    al., 2012). Download : Download high-res image (339KB) Download : Download full-size
    image Fig. 8. Mean measurements of crown temperature (Tc − Ta) (a), leaf stomatal
    conductance (G) (b), leaf PRI570 (c) and leaf Fs (d) for every Verticillium wilt
    severity level. Analysis of variance of each index was conducted and asterisks
    indicate significant differences from the asymptomatic plants according to Dunnett''s
    two-tailed test at P < 0.05. Error bars indicate standard errors. Leaf-level measurements
    conducted for temperature, stomatal conductance, fluorescence and the PRI570 in
    healthy and VW symptomatic trees showed that Tc − Ta and PRI570 were sensitive
    to V. dahliae infection and subsequent fungal colonization of affected trees and
    not simply influenced by structural effects driven by water stress. However, leaf
    G showed significantly lower values than asymptomatic trees in those affected
    by moderate or severe VW symptoms, while no significant differences in leaf Fs
    existed due to V. dahliae infection (Fig. 8). 3.3. Airborne hyperspectral, multispectral
    and thermal imagery results 3.3.1. Tree crown temperature (Tc − Ta) and CWSI Crown
    temperature (Tc − Ta) extracted from the airborne thermal imagery in the summer
    of 2011 was compared against leaf stomatal conductance (G) and leaf PRI570 data
    measured in 25 trees affected by VW (Fig. 9). Crown temperature (Tc − Ta) was
    significantly and linearly correlated with both the decrease of leaf G (R2 = 0.76,
    P = 0.002; Fig. 9a) and the increase of PRI570 (R2 = 0.51, P = 0.032; Fig. 9b).
    Furthermore, leaf G showed an inverse linear correlation to the leaf PRI570 (R2
    = 0.52, P = 0.028; Fig. 9c). Crown temperature (Tc − Ta) tended to increase as
    VW severity level increased (Fig. 10). VW affected trees showed up to 2 K higher
    Tc − Ta than that measured in healthy asymptomatic trees and were consistent in
    all measurements taken in April and July in both study sites. Indeed, symptomatic
    trees showed significantly (P < 0.05) higher Tc − Ta values than asymptomatic
    trees at any disease severity level at Castro del Rio, or at low or higher disease
    severity at Utrera. These results showed similar trends as those presented in
    Fig. 8a, with significant (P < 0.05) increases in Tc − Ta at leaf and canopy levels.
    Download : Download high-res image (505KB) Download : Download full-size image
    Fig. 9. Relationship between crown temperature extracted from the thermal imagery
    and leaf stomatal conductance (G) (a) and leaf PRI570 measurements (b) taken on
    olive trees showing different Verticillium wilt severity levels, and relationship
    between leaf G and leaf PRI570 (c). Thermal imagery was obtained at 11:00 GMT
    on 15 June 2011 and leaf measurements were obtained between 10:00 and 13:00 GMT
    on 27 and 28 July 2011 from crowns with different VW severity levels in the Castro
    del Rio study site (Córdoba province). Error bars indicate standard errors. Download
    : Download high-res image (415KB) Download : Download full-size image Fig. 10.
    Mean measurements of crown temperature (Tc − Ta) for every Verticillium wilt severity
    level. Tc − Ta was calculated from thermal imagery obtained in summer of two consecutive
    years (2009 and 2010) for the two study sites, Castro del Rio (Córdoba province)
    (a, c) and Utrera (Seville province) (b, d). Analysis of variance was conducted
    and asterisks indicate significant differences from the asymptomatic plants according
    to Dunnett''s two-tailed test at P < 0.05. Error bars indicate standard errors.
    As expected, the CWSI estimated from the high-resolution airborne thermal imagery
    acquired on 2 June 2011 in the Castro del Rio site showed significantly (P < 0.05)
    lower values for asymptomatic trees, with an upward trend as VW severity level
    increased (Fig. 11a). CWSI derived from the thermal imagery on 15 June 2011 decreased
    linearly and significantly as a function of G obtained on 27 and 28 July 2011
    (R2 = 0.83; P < 0.001) (Fig. 11b). These results indicate that the CWSI obtained
    from high spatial resolution thermal imagery can be used to detect the lower transpiration
    rates induced by V. dahliae infection, as could be expected according to previous
    results (Berni, Zarco-Tejada, Sepulcre-Cantó, Fereres, & Villalobos, 2009) showing
    the usefulness of the CWSI as a water stress indicator. CWSI values estimated
    on the two different assessment dates in June 2011 were significantly (P < 0.05)
    lower for healthy trees than for those affected by the disease. At early stages
    of disease development (DS ≤ 1.5), CWSI ranged from 0.21 to 0.35 on 2 June 2011,
    and from 0.36 to 0.48 on 15 June 2011. At more advanced stages of VW development
    for trees affected by moderate or severe symptoms, CWSI values tended to increase,
    ranging from 0.35 to 0.76 on 2 June 2011 and from 0.48 to 0.71 on 15 June 2011.
    Download : Download high-res image (260KB) Download : Download full-size image
    Fig. 11. (a) Mean values of Crop Water Stress Index (CWSI) for every Verticillium
    wilt severity level on 2 June 2011 in the Castro del Rio study site (Córdoba province).
    Analysis of variance was conducted and asterisks indicate significant differences
    from the asymptomatic plants according to Dunnett''s two-tailed test at P < 0.05.
    Error bars indicate standard errors. (b) Relationship between leaf stomatal conductance
    (G) and the CWSI in trees with different VW severity levels. Leaf stomatal conductance
    measurements were obtained between 10:00 and 13:00 GMT on 27 and 28 July 2011
    and the CWSI was calculated from the thermal imagery obtained at 11:00 GMT on
    15 June 2011 in the Castro del Rio study site. Error bars indicate standard errors.
    3.3.2. Structural indices The effects of VW on the canopy structure were captured
    by structural indices such as the NDVI (Fig. 12a), RDVI, OSAVI, TVI, MTVI, SR
    and MSR, that showed higher values for asymptomatic trees except for TVI and MTVI
    which showed an increase at early stages of disease development. Thus, moderate
    and severe VW wilt symptoms induced significantly (P < 0.05) lower values of NDVI,
    OSAVI, SR and MSR indices than those estimated in asymptomatic trees (Table 3).
    Furthermore, TVI and MTVI showed an increase (P < 0.05) in trees showing initial
    symptoms (Table 3). These results demonstrate the consistency of structural indices
    as VW damage indicator due to the expected effects on crown density at moderate
    or advanced stages of disease development. Download : Download high-res image
    (559KB) Download : Download full-size image Fig. 12. Mean measurements of NDVI
    (a), PRI570 (b), PRI515 (c), TCARI (d), Blue index (B) (e), B/R index (BR1) (f),
    chlorophyll fluorescence FLD3 (g) and healthy-index (HI) (h) for every Verticillium
    wilt severity level. Analysis of variance of each index was conducted and asterisks
    indicate significant differences from the asymptomatic plants according to Dunnett''s
    two-tailed test at P < 0.05. Error bars indicate standard errors. Table 3. Sensitivity
    of hyperspectral indices to Verticillium wilt symptoms in olive trees. Vegetation
    indices were calculated from the hyperspectral imagery obtained on 23 July 2011
    in the Castro del Rio site (Córdoba province, Spain). Vegetation indices Fa Pa
    Severity of disease symptomsb I L M S Structural indices  NDVI 21.66 < 0.001 X
    X  RDVI 9.02 < 0.001 X  OSAVI 11.52 < 0.001 X X  TVI 7.80 < 0.001 X X  MTVI 7.27
    < 0.001 X X  SR 14.35 < 0.001 X X  MSR 16.49 < 0.001 X X Xanthophyll indices  PRI570
    2.98 0.0183  PRI515 11.30 < 0.001 X X Chlorophyll a + b indices  RedEdge 15.95
    < 0.001 X X  VOG1 22.56 < 0.001 X X  GM1 10.99 < 0.001 X X  GM2 13.93 < 0.001
    X X  PSSRa 14.70 < 0.001 X X  PSSRb 14.35 < 0.001 X X  mCAI 5.26 0.0003 X  TCARI
    6.72 < 0.001 X  TCARI/OSAVI 3.30 0.0105 X R/G/B indices  R 12.27 < 0.001  G 16.51
    < 0.001  B 16.01 < 0.001 X X X X  BG1 6.41 < 0.001 X X  BG2 2.25 0.0611  BR1 12.01
    < 0.001 X X X  BR2 13.68 < 0.001 X X X  LIC3 5.72 < 0.001 X Carotenoid indices  SIPI
    12.43 < 0.001 X X  PSSRc 9.73 < 0.001 X X  R520/R500 3.67 0.0055  R515/R570 3.08
    0.0152  R515/R670 14.06 < 0.001 Fluorescence index  FLD3 4.66 0.0010 X X Plant
    disease indices  HI 9.54 < 0.001 X X X a F statistic and P-value obtained from
    the standard analysis of variance (ANOVA). b Significant changes in vegetation
    indices from asymptomatic plants according to Dunnett''s two tailed test at P
    < 0.05 are indicated with X for initial (I) (0.2 ≤ DS ≤ 0.5), low (L) (1 ≤ DS
    ≤ 1.5), moderate (M) (2 ≤ DS ≤ 2.5) and severe (S) (3 ≤ DS ≤ 4) Verticillium wilt
    symptoms. 3.3.3. Physiological indices The revised xanthophyll indices were calculated
    based on PRI formulations using R570 as the reference band (PRI570) (Fig. 12b)
    and the new formulation using band R515 as a reference to minimize structural
    canopy effects, PRI515 (Fig. 12c). These indices showed an upward trend as VW
    severity level increased. The PRI515 index was more sensitive to VW than PRI570,
    and showed significantly (P < 0.05) lower values when trees were affected by moderate
    or severe symptoms (Table 3). This result confirms those obtained by Hernández-Clemente
    et al. (2011) in forest canopies and those of Stagakis, González-Dugo, Cid, Guillén-Climent,
    and Zarco-Tejada (2012) in orange and mandarin orchards, which demonstrated the
    robustness of the PRI515 to structural effects. Both, airborne-derived (Table
    3) and leaf-level PRI570 (Fig. 8c) showed similar positive trend with disease
    severity, however only at leaf-level resulted in significant differences between
    healthy and VW affected trees. The chlorophyll indices TCARI (Fig. 12d) and TCARI/OSAVI
    showed an upward trend at early stages of the disease, reaching a maximum of 0.058
    and 0.103 units at the low disease severity level, respectively, compared to 0.004
    (TCARI) and 0.007 (TCARI/OSARI) observed for healthy trees. These results could
    indicate a decrease in chlorophyll a + b content (Ca + b) at early stages of V.
    dahliae infection (reducing stomatal conductance and photosynthesis rate). At
    advanced stages of the disease, the TCARI and TCARI/OSAVI inverted their trends
    due to the sharp leaf area index (LAI) drop associated with VW severity, showing
    significantly (P < 0.05) lower values at severe disease symptoms with 0.022 and
    0.025 value drops between moderate and severely affected trees, respectively.
    The chlorophyll red edge index, VOG1, GM1, GM2, PSSRa and PSSRb showed significantly
    (P < 0.05) lower values on moderately and severely affected trees compared with
    values estimated on asymptomatic trees. The mCAI reached a significantly (P <
    0.05) higher value at trees showing initial symptoms but steadily decreased in
    trees affected by moderate and severe symptoms. The Greenness, red index and the
    blue/green ratio BG2 were not able to detect V. dahliae infection, since no significant
    (P > 0.05) changes were detectable when compared with healthy trees (Table 3).
    Interestingly, the blue index (Fig. 12e) could discriminate between healthy trees
    and those affected at any of the disease severity levels that reached significantly
    lower values (P < 0.05). Similarly, the blue/green ratio BG1 presented a significant
    (P < 0.05) decrease at early stages of disease development, but increased slightly
    at advanced stages, probably due to structural changes occurring in trees severely
    damaged by the pathogen. The blue/red ratios BR1 and BR2 showed downward trends
    with the increase in disease severity that resulted in significantly lower values
    at the initial, low and moderate symptom severity in BR1 (Fig. 12f) and low, moderate
    and severe in BR2. The LIC3 index showed a slightly decrease at early stages of
    the disease, followed by a significant (P < 0.05) increase on severely affected
    trees. The indices SIPI and PSSRc were inversely correlated with disease severity,
    showing significantly (P < 0.05) lower values at moderate and severe stages of
    disease development. The R520/R500, R515/R570, and R515/R670 ratios were not useful
    for the detection of VW as no significant differences were detected between asymptomatic
    and VW affected trees. The chlorophyll fluorescence signal estimated from the
    hyperspectral imagery with the FLD method showed a significant (P < 0.05) increase
    at initial and low stages of disease symptom severity (2.677 W·m− 2 μm− 1·sr−
    1), slightly decreasing to 2.019 W·m− 2·μm− 1·sr− 1 at the severe VW severity
    level (Fig. 12g). This result may indicate that the photosynthetic apparatus of
    the plant remains undamaged being able to dissipate the excess of energy by fluorescence
    that could not be maintained when the reduction in photosynthesis occurred at
    severely stressed plants, causing a decrease in the chlorophyll fluorescence rate.
    These results are in agreement with the studies conducted by Pérez-Priego et al.
    (2005) and Zarco-Tejada et al., 2009, Zarco-Tejada et al., 2012 in citrus and
    olive orchards under water stress conditions. Comparable results were obtained
    in airborne (Table 3) and leaf-derived chlorophyll fluorescence (Fig. 8d) that
    in both cases reached lower values in trees affected by moderate or severe symptoms.
    However, a significant (P < 0.05) increase in fluorescence occurred in trees at
    the early stage of disease development only at canopy level (Table 3). Finally,
    the health index (HI) developed to discriminate between healthy and diseased sugar
    beet leaves affected by different foliar pathogens showed in this study lower
    values (P < 0.05) as the VW disease severity level increases to low, moderate
    or severe symptoms, respectively (Table 3; Fig. 12h). 4. Conclusions The present
    study assessed remote sensing methods for early detection of Verticillium wilt
    in two olive orchards of different agronomic characteristics. It applied techniques
    based on the detection of the effects of V. dahliae infection and colonization
    on water flow that eventually cause water stress effects, assessed with thermal,
    multispectral and hyperspectral domains. It demonstrated that canopy temperature
    and physiological hyperspectral indices (i.e., PRI and chlorophyll fluorescence)
    are related with physiological stress caused by VW. Moreover, structural indices
    (i.e., NDVI) were more related to structural damage caused by VW. Field measurements
    showed large differences in temperature (Tc − Ta) and stomatal conductance (G)
    across VW severity levels, with higher Tc − Ta and lower G as severity level increased.
    This allowed identifying trees at the early stages of disease development. At
    leaf level, the reduction in transpiration and G caused by VW infection was associated
    with a significant (P < 0.05) increase in the PRI570 and a decrease in fluorescence.
    The flights conducted with thermal, multispectral and hyperspectral cameras enabled
    VW detection by using crown temperature (Tc − Ta; CWSI), assessing structural
    indices (NDVI, RDVI, OSAVI, TVI, MTVI, SR, MSR), the PRI515 index, chlorophyll
    indices (red edge, VOG1, GM1, GM2, PSSRa, PSSRb, mCAI, TCARI, TCARI/OSAVI), R/G/B
    indices (B, BG1, BR1, BR2, LIC3), carotenoid (SIPI and PSSRc), fluorescence, and
    the healthy index (HI). This study proved the potentials for the early detection
    of V. dahliae infection and discrimination among VW severity levels in olive crops
    using thermal, multispectral and hyperspectral imagery acquired with an unmanned
    aerial vehicle. Crown temperature, CWSI, B, BG1, BR1 and FLD3 were identified
    as the best indicators to detect VW at early stages of disease development, while
    NDVI, PRI515, HI, and chlorophyll and carotenoid indices proved to be good indicators
    to detect the presence of moderate to severe damage. Acknowledgments Financial
    support from the Spanish Ministry of Education and Science for project AGL2009-13105
    and from the Regional Government of Andalusia and the European Social Fund for
    project P08-AGR-03528 is gratefully acknowledged. R. Calderón is a recipient of
    research fellowship BES-2010-035511 from the Spanish Ministry of Education and
    Science. V. González-Dugo, J.A.J. Berni, D. Notario, A. Vera, A, Hornero, R. Romero
    and K. Gutierrez are acknowledged for their support during the field and airborne
    campaigns. M. Montes-Borrego, J.L. Trapero-Casas and G. León-Ropero are acknowledged
    for their technical support in Verticillium wilt assessments. References Ayres,
    1978 P.G. Ayres Water relations of diseased plants T.T. Kozlowski (Ed.), Water
    deficits and plant growth, Vol. 5, Academic Press, London, United Kingdom (1978),
    pp. 1-60 View PDFView articleGoogle Scholar Barton, 2012 C. Barton Advances in
    remote sensing of plant stress Plant and Soil, 354 (2012), pp. 41-44 CrossRefView
    in ScopusGoogle Scholar Bauriegel et al., 2011 E. Bauriegel, A. Giebel, M. Geyer,
    U. Schmidt, W.B. Herppich Early detection of Fusarium infection in wheat using
    hyper-spectral imaging Computers and Electronics in Agriculture, 75 (2011), pp.
    304-312 View PDFView articleView in ScopusGoogle Scholar Berni, Zarco-Tejada,
    Sepulcre-Cantó, Fereres and Villalobos, 2009 J.A.J. Berni, P.J. Zarco-Tejada,
    G. Sepulcre-Cantó, E. Fereres, F.J. Villalobos Mapping canopy conductance and
    CWSI in olive orchards using high resolution thermal remote sensing imagery Remote
    Sensing of Environment, 113 (2009), pp. 2380-2388 View PDFView articleView in
    ScopusGoogle Scholar Berni, Zarco-Tejada, Suárez and Fereres, 2009 J.A.J. Berni,
    P.J. Zarco-Tejada, L. Suárez, E. Fereres Thermal and narrow-band multispectral
    remote sensing for vegetation monitoring from an unmanned aerial vehicle IEEE
    Transactions on Geoscience and Remote Sensing, 47 (2009), pp. 722-738 View in
    ScopusGoogle Scholar Blackburn, 1998 G.A. Blackburn Spectral indices for estimating
    photosynthetic pigment concentrations: A test using senescent tree leaves International
    Journal of Remote Sensing, 19 (4) (1998), pp. 657-675 View in ScopusGoogle Scholar
    Blanco-López et al., 1984 M.A. Blanco-López, R.M. Jiménez-Díaz, J.M. Caballero
    Symptomatology, incidence and distribution of Verticillium wilt of olive trees
    in Andalucia Phytopathologia Mediterranea, 23 (1984), pp. 1-8 View in ScopusGoogle
    Scholar Broge and Leblanc, 2000 N.H. Broge, E. Leblanc Comparing prediction power
    and stability of broadband and hyperspectral vegetation indices for estimation
    of green leaf area index and canopy chlorophyll density Remote Sensing of Environment,
    76 (2000), pp. 156-172 Google Scholar Chen, 1996 J. Chen Evaluation of vegetation
    indices and modified simple ratio for boreal applications Canadian Journal of
    Remote Sensing, 22 (1996), pp. 229-242 CrossRefView in ScopusGoogle Scholar Chen
    et al., 2008 B. Chen, S.K. Li, K.R. Wang, J. Wang, F.Y. Wang, C.H. Xiao, et al.
    Spectrum characteristics of cotton canopy infected with Verticillium wilt and
    applications Agricultural Sciences in China, 7 (2008), pp. 561-569 View PDFView
    articleView in ScopusGoogle Scholar Chen et al., 2011 B. Chen, S. Li, K. Wang,
    G. Zhou, J. Bai Evaluating the severity level of cotton Verticillium using spectral
    signature analysis International Journal of Remote Sensing, 33 (2011), pp. 2706-2724
    Google Scholar Cohen et al., 2005 Y. Cohen, V. Alchanatis, M. Meron, Y. Saranga,
    J. Tsipris Estimation of leaf potential by thermal imagery and spatial analysis
    Journal of Experimental Botany, 56 (2005), pp. 1843-1852 CrossRefView in ScopusGoogle
    Scholar Dammer et al., 2011 K.H. Dammer, B. Möller, B. Rodemann, D. Heppner Detection
    of head blight (Fusarium ssp.) in winter wheat by color and multispectral image
    analyses Crop Protection, 30 (2011), pp. 420-428 View PDFView articleView in ScopusGoogle
    Scholar DeVay, 1989 J.E. DeVay Selection, characterization, pathogenicity and
    virulence of pectinase-deficient mutants of Verticillium albo-atrum E.C. Tjamos,
    C.H. Beckman (Eds.), Vascular wilt diseases of plants, Springer, Berlin, Germany
    (1989), pp. 197-217 CrossRefGoogle Scholar Dobrowsky et al., 2005 S.Z. Dobrowsky,
    J. Pushnik, P.J. Zarco-Tejada, S.L. Ustin Simple reflectance indices track heat
    and water stress induced changes in steady-state chlorophyll fluorescence at the
    canopy scale Remote Sensing of Environment, 97 (2005), pp. 403-414 Google Scholar
    Emechebe et al., 1975 A.M. Emechebe, C.L.A. Leaky, W.B. Banage Verticillium wilt
    of cacao in Uganda: Incidence and progress of infection in relation to time East
    African Agricultural and Forestry Journal, 41 (1975), pp. 184-186 Google Scholar
    Evain et al., 2004 S. Evain, J. Flexas, I. Moya A new instrument for passive remote
    sensing: 2. Measurement of leaf and canopy reflectance changes at 531 mm and their
    relationship with photosynthesis and chlorophyll fluorescence Remote Sensing of
    Environment, 91 (2004), pp. 175-185 View PDFView articleView in ScopusGoogle Scholar
    Flexas et al., 2000 J. Flexas, J.M. Briantais, Z. Cerovic, H. Medrano, I. Moya
    Steady-state and maximum chlorophyll fluorescence responses to water stress in
    grapevine leaves: A new remote sensing system Remote Sensing of Environment, 73
    (2000), pp. 282-297 Google Scholar Flexas et al., 2002 J. Flexas, J.M. Escalona,
    S. Evain, J. Gulias, I. Moya, C.B. Osmond, et al. Steady-state chlorophyll fluorescence
    (Fs) measurements as a tool to follow variations of net CO2 assimilation and stomatal
    conductance during water-stress in C-3 plants Physiologia Plantarum, 114 (2) (2002),
    pp. 231-240 View in ScopusGoogle Scholar Flexas et al., 1999 J. Flexas, J.M. Escalona,
    H. Medrano Water stress induces different levels of photosynthesis and electron
    transport rate regulation in grapevine Plant, Cell & Environment, 22 (1999), pp.
    39-48 View in ScopusGoogle Scholar Gamon et al., 1992 J.A. Gamon, J. Peñuelas,
    C.B. Field A narrow-wave band spectral index that tracks diurnal changes in photosynthetic
    efficiency Remote Sensing of Environment, 41 (1992), pp. 35-44 View PDFView articleView
    in ScopusGoogle Scholar Garber and Houston, 1966 R.H. Garber, B.R. Houston Penetration
    and development of Verticillium alboatrum in the cotton plant Phytopathology,
    56 (1966), pp. 1121-1126 Google Scholar Gitelson and Merzlyak, 1997 A.A. Gitelson,
    M.N. Merzlyak Signature analysis of leaf reflectance spectra: Algorithm development
    for remote sensing of chlorophyll International Journal of Remote Sensing, 18
    (1997), pp. 2691-2697 View in ScopusGoogle Scholar Gitelson et al., 2000 A.A.
    Gitelson, Y.Z. Yacobi, J.F. Schalles, D.C. Rundquist, L. Han, R. Stark, et al.
    Remote estimation of phytoplankton density in productive waters Archives in Hydrobiology
    — Special Issues in Advances in Limnology, 55 (2000), pp. 121-136 Google Scholar
    Gueymard, 1995 C.A. Gueymard SMARTS, a simple model of the atmospheric radiative
    transfer of sunshine: Algorithms and performance assessment Technical report no.
    FSEC-PF-270-95, Florida Solar Energy Center, Cocoa, FL (1995) Google Scholar Gueymard,
    2001 C.A. Gueymard Parameterized transmittance model for direct beam and circumsolar
    spectral irradiance Solar Energy, 71 (2001), pp. 325-346 View PDFView articleView
    in ScopusGoogle Scholar Haboudane et al., 2004 D. Haboudane, J.R. Miller, E. Pattey,
    P.J. Zarco-Tejada, I. Strachan Hyperspectral vegetation indices and novel algorithms
    for predicting green LAI of crop canopies: Modeling and validation in the context
    of precision agriculture Remote Sensing of Environment, 90 (3) (2004), pp. 337-352
    View PDFView articleView in ScopusGoogle Scholar Haboudane et al., 2002 D. Haboudane,
    J.R. Miller, N. Tremblay, P.J. Zarco-Tejada, L. Dextraze Integrated narrow-band
    vegetation indices for prediction of crop chlorophyll content for application
    to precision agriculture Remote Sensing of Environment, 84 (2002), pp. 416-426
    View PDFView articleView in ScopusGoogle Scholar Hatfield and Pinter, 1993 P.L.
    Hatfield, P.J. Pinter Remote sensing for crop protection Crop Protection, 12 (1993),
    pp. 403-413 View PDFView articleView in ScopusGoogle Scholar Hernández-Clemente
    et al., 2011 R. Hernández-Clemente, R.M. Navarro-Cerrillo, L. Suárez, F. Morales,
    P.J. Zarco-Tejada Assessing structural effects on PRI for stress detection in
    conifer forests Remote Sensing of Environment, 115 (2011), pp. 2360-2375 View
    PDFView articleView in ScopusGoogle Scholar Hillnhütter et al., 2011 C. Hillnhütter,
    A.K. Mahlein, R.A. Sikora, E.C. Oerke Remote sensing to detect plant stress induced
    by Heterodera schachtii and Rhizoctonia solani in sugar beet fields Field Crops
    Research, 122 (2011), pp. 70-77 View PDFView articleView in ScopusGoogle Scholar
    Idso et al., 1981 S.B. Idso, R.D. Jackson, P.J. Pinter, R.J. Reginato, J.L. Hatfield
    Normalizing the stress-degree-day parameter for environment variability Agricultural
    and Forest Meteorology, 24 (1981), pp. 45-55 View PDFView articleView in ScopusGoogle
    Scholar Idso et al., 1978 S.B. Idso, R.D. Jackson, R. Reginato Extending the “degree
    day” concept of phenomenological development to include water stress effects Ecology,
    59 (1978), pp. 431-433 CrossRefGoogle Scholar Jackson, 1986 R.D. Jackson Remote
    sensing of biotic and abiotic plant stress Annual Review of Phytopathology, 24
    (1986), pp. 265-287 CrossRefGoogle Scholar Jackson et al., 1977 R.D. Jackson,
    S.B. Idso, R.J. Reginato, W.L. Ehrler Crop temperature reveals stress Crop Soils,
    29 (1977), pp. 10-13 CrossRefView in ScopusGoogle Scholar Jackson et al., 1981
    R.D. Jackson, S.B. Idso, R.J. Reginato, P.J. Pinter Jr. Canopy temperature as
    a crop water stress indicator Water Resources Research, 17 (1981), pp. 1133-1138
    View in ScopusGoogle Scholar Jackson and Pinter, 1981 R.D. Jackson, P.J. Pinter
    Jr. Detection of water stress in wheat by measurement of reflected solar and emitted
    thermal IR radiation Spectral signatures of objects in remote sensing, Institut
    National de la Reserche Agronomique, Versalles, France (1981), pp. 399-406 Google
    Scholar Jiménez-Díaz et al., 2012 R.M. Jiménez-Díaz, M. Cirulli, G. Bubici, L.M.
    Jiménez-Gasco, P.P. Antoniou, E.C. Tjamos Verticillium wilt, a major threat to
    olive production: Current status and future prospects for its management Plant
    Disease, 96 (3) (2012), pp. 304-329 View in ScopusGoogle Scholar Jiménez-Díaz
    et al., 2011 R.M. Jiménez-Díaz, C. Olivares-García, B.B. Landa, M.M. Jiménez-Gasco,
    J.A. Navas-Cortés Region-wide analysis of genetic diversity in Verticillium dahliae
    populations infecting olive in southern Spain and agricultural factors influencing
    the distribution and prevalence of vegetative compatibility groups and pathotypes
    Phytopathology, 101 (2011), pp. 304-315 View in ScopusGoogle Scholar Jordan, 1969
    C.F. Jordan Derivation of leaf area index from quality of light on the forest
    floor Ecology, 50 (1969), pp. 663-666 CrossRefGoogle Scholar Krause and Weis,
    1984 G.H. Krause, E. Weis Chlorophyll fluorescence as a tool in plant physiology.
    II. Interpretation of fluorescence signals Photosynthesis Research, 5 (1984),
    pp. 139-157 View in ScopusGoogle Scholar Laudien et al., 2003 R. Laudien, G. Bareth,
    R. Doluschitz Analysis of hyperspectral field data for detection of sugar beet
    diseases Proceedings of the EFITA Conference, Debrecen, Hungary (2003), pp. 375-381
    Google Scholar Leinonen and Jones, 2004 I. Leinonen, H.G. Jones Combining thermal
    and visible imagery for stimulating canopy temperature and identifying plant stress
    Journal of Experimental Botany, 55 (2004), pp. 1423-1431 View in ScopusGoogle
    Scholar Levin et al., 2003 A.G. Levin, S. Lavee, L. Tsror Epidemiology of Verticillium
    dahliae on olive (cv. Picual) and its effects on yield under saline conditions
    Plant Pathology, 52 (2003), pp. 212-218 CrossRefView in ScopusGoogle Scholar Lichtenhaler
    et al., 1996 H.K. Lichtenhaler, M. Lang, M. Sowinska, F. Heisel, J.A. Mieh Detection
    of vegetation stress via a new high resolution fluorescence imaging system Journal
    of Plant Physiology, 148 (1996), pp. 599-612 Google Scholar López-Escudero et
    al., 2004 F.J. López-Escudero, C. del Rio, J.M. Caballero, M.A. Blanco-López Evaluation
    of olive cultivars for resistance to Verticillium dahliae European Journal of
    Plant Pathology, 110 (2004), pp. 79-85 View in ScopusGoogle Scholar Mahlein et
    al., 2013 A.K. Mahlein, T. Rumpf, P. Welke, H.W. Dehne, L. Plümer, U. Steiner,
    et al. Development of spectral indices for detecting and identifying plant diseases
    Remote Sensing of Environment, 128 (2013), pp. 21-30 View PDFView articleView
    in ScopusGoogle Scholar Maier et al., 2003 S.W. Maier, K.P. Günther, M. Stellmes
    Sun-induced fluorescence: A new tool for precision farming M. McDonald, J. Schepers,
    L. Tartly, T. van Toai, D. Major (Eds.), Digital imaging and spectral techniques:
    Applications to precision agriculture and crop physiology, ASA Special Publication
    (2003), pp. 209-222 Google Scholar Mengistu et al., 1987 A. Mengistu, H. Tachibana,
    A.H. Epstein, K.G. Bidne, J.D. Hatfield Use of leaf temperature to measure the
    effect of brown stem rot and soil moisture stress and its relation to yields of
    soybeans Plant Disease, 71 (1987), pp. 632-634 Google Scholar Mercado-Blanco et
    al., 2003 J. Mercado-Blanco, D. Rodríguez-Jurado, S. Parrilla-Araujo, R.M. Jiménez-Díaz
    Simultaneous detection of the defoliating and nondefoliating Verticillium dahliae
    pathotypes in infected olive plants by duplex, nested polymerase chain reaction
    Plant Disease, 87 (2003), pp. 1487-1494 View in ScopusGoogle Scholar Meroni et
    al., November 17-19 2004 M. Meroni, R. Colombo, S. Cogliati High resolution leaf
    spectral signature for the detection of solar induced chlorophyll fluorescence
    Proceedings of the 2nd ESA workshop on remote sensing of solar induced vegetation
    fluorescence. Montreal, Canada (November 17-19 2004) Meroni, Picchi, et al., 2008
    M. Meroni, V. Picchi, M. Rossini, S. Cogliati, C. Panigada, C. Nali, et al. Leaf
    level early assessment of ozone injuries by passive fluorescence and PRI International
    Journal of Remote Sensing, 29 (17–18) (2008), pp. 5409-5422 CrossRefView in ScopusGoogle
    Scholar Meroni et al., 2009 M. Meroni, M. Rossini, L. Guanter, L. Alonso, U. Rascher,
    R. Colombo Remote sensing of solar-induced chlorophyll fluorescence: Review of
    methods and applications Remote Sensing of Environment, 113 (2009), pp. 2037-2051
    View PDFView articleView in ScopusGoogle Scholar Meroni, Rossini, et al., 2008
    M. Meroni, M. Rossini, V. Picchi, C. Panigada, S. Cogliati, C. Nali, et al. Assessing
    steady-state fluorescence and PRI from hyperspectral proximal sensing as early
    indicators of plant stress: The case of ozone exposure Sensors, 8 (2008), pp.
    1740-1754 CrossRefView in ScopusGoogle Scholar Moya et al., 2004 I. Moya, L. Camenen,
    S. Evain, Y. Goulas, Z.G. Cerovic, G. Latouche A new instrument for passive remote
    sensing 1 Measurements of sunlight-induced chlorophyll fluorescence. Remote Sensing
    of Environment, 91 (2004), pp. 186-197 View PDFView articleView in ScopusGoogle
    Scholar Navas-Cortés et al., 2008 J.A. Navas-Cortés, B.B. Landa, J. Mercado-Blanco,
    J.L. Trapero-Casas, D. Rodríguez-Jurado, R.M. Jiménez-Díaz Spatiotemporal analysis
    of spread of infections by Verticillium dahliae pathotypes within a high tree
    density olive orchard in southern Spain Phytopathology, 98 (2008), pp. 167-180
    View in ScopusGoogle Scholar Nilsson, 1991 H.E. Nilsson Hand-held radiometry and
    IR-thermography of plant diseases in field plot experiments International Journal
    of Remote Sensing, 12 (1991), pp. 545-557 CrossRefView in ScopusGoogle Scholar
    Nilsson, 1995 H.E. Nilsson Remote sensing and image analysis in plant pathology
    Annual Review of Phytopathology, 15 (1995), pp. 489-527 View in ScopusGoogle Scholar
    Papageorgiu, 1975 G. Papageorgiu Chlorophyll fluorescence: An intrinsic probe
    of photosynthesis Govindjee (Ed.), Bioenergetics of photosynthesis, Academic Press,
    New York (1975), pp. 319-371 Google Scholar Peguero-Pina et al., 2008 J.J. Peguero-Pina,
    F. Morales, J. Flexas, E. Gil-Pelegrín, I. Moya Photochemistry, remotely sensed
    physiological reflectance index and de-epoxidation state of the xanthophyll cycle
    in Quercus under intense drought Oecologia, 156 (1) (2008), pp. 1-11 CrossRefView
    in ScopusGoogle Scholar Peñuelas et al., 1995 J. Peñuelas, F. Baret, I. Filella
    Semi-empirical indices to assess carotenoids/chlorophyll a ratio from leaf spectral
    reflectance Photosynthetica, 31 (1995), pp. 221-230 View in ScopusGoogle Scholar
    Pérez-Priego et al., 2005 O. Pérez-Priego, P.J. Zarco-Tejada, G. Sepulcre-Cantó,
    J.R. Miller, E. Fereres Detection of water stress in orchard trees with a high-resolution
    spectrometer through chlorophyll fluorescence in-filling of the O2-A band IEEE
    Transactions on Geoscience and Remote Sensing, 43 (2005), pp. 2860-2869 Google
    Scholar Pinter et al., 1979 P.J. Pinter, M.E. Stanghellini, R.J. Reginato, S.B.
    Idso, A.D. Jenkins, R.D. Jackson Remote detection of biological stresses in plants
    with infrared thermometry Science, 205 (1979), pp. 585-587 CrossRefView in ScopusGoogle
    Scholar Plascyk, 1975 J.A. Plascyk MK II Fraunhofer Line Dicsriminator (FLD-II)
    for airborne and orbital remote sensing of solar-stimulated luminescence Optical
    Engineering, 14 (4) (1975), pp. 339-346 View in ScopusGoogle Scholar Presley et
    al., 1966 J.T. Presley, H.R. Carns, E.E. Taylor, W.C. Schnathorst Movement of
    conidia of Verticillium albo-atrum in cotton plants Phytopathology, 56 (1966),
    p. 375 Google Scholar Raikes and Burpee, 1998 C. Raikes, L.L. Burpee Use of multispectral
    radiometry for assessment of Rhizoctonia blight in creeping bentgrass Phytopathology,
    88 (1998), pp. 446-449 View in ScopusGoogle Scholar Reynolds et al., 2012 G.J.
    Reynolds, C.E. Windels, I.V. MacRae, S. Laguette Remote sensing for assessing
    Rhizoctonia crown and root rot severity in sugar beet Plant Disease, 96 (2012),
    pp. 497-505 View in ScopusGoogle Scholar Rondeaux et al., 1996 G. Rondeaux, M.
    Steven, F. Baret Optimization of soil-adjusted vegetation indices Remote Sensing
    of Environment, 55 (1996), pp. 95-107 View PDFView articleView in ScopusGoogle
    Scholar Rougean and Breon, 1995 J.-L. Rougean, F.M. Breon Estimating PAR absorbed
    by vegetation from bidirectional reflectance measurements Remote Sensing of Environment,
    51 (1995), pp. 375-384 Google Scholar Rouse et al., 1974 J.W. Rouse, R.H. Haas,
    J.A. Schell, D.W. Deering, J.C. Harlan Monitoring the vernal advancement and retrogradation
    (green wave effect) of natural vegetation NASA/GSFC Type III Final Report, Greenbelt,
    Maryland (1974), p. 371 Google Scholar Sánchez-Hernández et al., 1998 M.E. Sánchez-Hernández,
    A. Ruiz-Dávila, A. Pérez de Algaba, M.A. Blanco-López, A. Trapero-Casas Occurrence
    and etiology of death of young olive trees in southern Spain European Journal
    of Plant Pathology, 104 (1998), pp. 347-357 View in ScopusGoogle Scholar Sankaran
    et al., 2010 S. Sankaran, A. Mishra, R. Ehsani, C. Davis A review of advanced
    techniques for detecting plant diseases Computers and Electronics in Agriculture,
    72 (2010), pp. 1-13 View PDFView articleView in ScopusGoogle Scholar Schreiber
    and Green, 1963 L.R. Schreiber, R.J. Green Jr. Effect of root exudates on germination
    of conidia and microsc1erotia of Verticillium albo-atrum inhibited by the soil
    fungistatic principle Phytopathology, 53 (1963), pp. 260-264 Google Scholar Sepulcre-Cantó
    et al., 2006 G. Sepulcre-Cantó, P.J. Zarco-Tejada, J.C. Jiménez-Muñoz, J.A. Sobrino,
    E. de Miguel, F.J. Villalobos Within-field thermal variability detection as function
    of water stress in Olea europea L. orchards with high resolution spatial remote
    sensing imagery Agricultural and Forest Meteorology, 136 (2006), pp. 31-44 View
    PDFView articleView in ScopusGoogle Scholar Sepulcre-Cantó et al., 2007 G. Sepulcre-Cantó,
    P.J. Zarco-Tejada, J.C. Jiménez-Muñoz, J.A. Sobrino, M.A. Soriano, E. Fereres,
    et al. Monitoring yield and fruit quality parameters in open-canopy tree crops
    under water stress. Implications for ASTER Remote Sensing of Environment, 107
    (2007), pp. 455-470 View PDFView articleView in ScopusGoogle Scholar Sepulcre-Cantó
    et al., 2009 G. Sepulcre-Cantó, P.J. Zarco-Tejada, J.A. Sobrino, J.A.J. Berni,
    J.C. Jiménez-Muñoz, J.P. Gastellu-Etchegorry Discriminating irrigated and rainfed
    olive orchards with thermal ASTER imagery and DART 3D simulations Agricultural
    and Forest Meteorology, 149 (2009), pp. 962-975 View PDFView articleView in ScopusGoogle
    Scholar Soukupová et al., 2008 J. Soukupová, L. Cséfalvay, O. Urban, M. Kosvancová,
    M. Marek, U. Rascher, et al. Annual variation of the steady-state chlorophyll
    fluorescence emission of evergreen plants in temperate zone Functional Plant Biology,
    35 (2008), pp. 63-76 View in ScopusGoogle Scholar Stagakis et al., 2012 S. Stagakis,
    V. González-Dugo, P. Cid, M.L. Guillén-Climent, P.J. Zarco-Tejada Monitoring water
    stress and fruit quality in an orange orchard under regulated deficit irrigation
    using narrow-band structural and physiological remote sensing indices ISPRS Journal
    of Photogrammetry and Remote Sensing, 71 (2012), pp. 47-61 View PDFView articleView
    in ScopusGoogle Scholar Suárez et al., 2009 L. Suárez, P.J. Zarco-Tejada, J.A.J.
    Berni, V. González-Dugo, E. Fereres Modelling PRI for water stress detection using
    radiative transfer models Remote Sensing of Environment, 113 (2009), pp. 730-740
    View in ScopusGoogle Scholar Suárez et al., 2010 L. Suárez, P.J. Zarco-Tejada,
    V. González-Dugo, J.A.J. Berni, R. Sagardoy, F. Morales, et al. Detecting water
    stress effects on fruit quality in orchards with time-series PRI airborne imagery
    Remote Sensing of Environment, 114 (2010), pp. 286-298 View PDFView articleView
    in ScopusGoogle Scholar Suárez et al., 2008 L. Suárez, P.J. Zarco-Tejada, G. Sepulcre-Cantó,
    O. Pérez-Priego, J.R. Miller, J.C. Jiménez-Muñoz, et al. Assessing canopy PRI
    for water stress detection with diurnal airborne imagery Remote Sensing of Environment,
    112 (2008), pp. 560-575 View PDFView articleView in ScopusGoogle Scholar Sun et
    al., 2008 P. Sun, A. Grignetti, S. Liu, R. Casacchia, R. Salvatori, F. Pietrini,
    et al. Associated changes in physiological parameters and spectral reflectance
    indices in olive (Olea europaea L.) leaves in response to different levels of
    water stress International Journal of Remote Sensing, 29 (6) (2008), pp. 1725-1743
    CrossRefView in ScopusGoogle Scholar Talboys, 1962 P.W. Talboys Systemic movement
    of some vascular pathogens Transactions of the British Mycological Society, 45
    (1962), pp. 280-281 Google Scholar Thenot et al., 2002 F. Thenot, M. Méthy, T.
    Winkel The photochemical reflectance index (PRI) as a water-stress index International
    Journal of Remote Sensing, 23 (23) (2002), pp. 5135-5139 View in ScopusGoogle
    Scholar Tsror (Lahkim), 2011 L. Tsror (Lahkim) Review: Epidemiology and control
    of Verticillium wilt on olive Israel Journal of Plant Sciences, 59 (2011), pp.
    59-69 Google Scholar Tu and Tan, 1985 J.C. Tu, C.S. Tan Infrared thermometry for
    determination of root rot severity in bean Phytopathology, 75 (1985), pp. 840-844
    Google Scholar Van Alfen, 1989 N.K. Van Alfen Reassessment of plant wilt toxins
    Annual Review of Phytopathology, 27 (1989), pp. 533-550 CrossRefGoogle Scholar
    Vogelmann et al., 1993 J.E. Vogelmann, B.N. Rock, D.M. Moss Red edge spectral
    measurements from sugar maple leaves International Journal of Remote Sensing,
    14 (1993), pp. 1563-1575 CrossRefView in ScopusGoogle Scholar Wang et al., 2004
    D. Wang, J.E. Kurle, C. Estevez de Jensen, J.A. Percich Radiometric assessment
    of tillage and seed treatment effect on soybean root rot caused by Fusarium spp.
    in central Minnesota Plant and Soil, 258 (2004), pp. 319-331 View in ScopusGoogle
    Scholar West et al., 2003 J.S. West, C. Bravo, R. Oberti, D. Lemaire, D. Moshou,
    H.A. McCartney The potential of optical canopy measurement for targeted control
    of field crop diseases Annual Review of Phytopathology, 41 (2003), pp. 593-614
    View in ScopusGoogle Scholar Winkel et al., 2002 T. Winkel, M. Méthy, F. Thénot
    Radiation use efficiency, chlorophyll fluorescence, and reflectance indices associated
    with ontogenic changes in water-limited Chenopodium quinoa leaves Photosynthetica,
    40 (2) (2002), pp. 227-232 View in ScopusGoogle Scholar Zarco-Tejada et al., 2005
    P.J. Zarco-Tejada, A. Berjón, R. López-Lozano, J.R. Miller, P. Marin, V. Cachorro,
    et al. Assessing vineyard condition with hyperspectral indices: Leaf and canopy
    reflectance simulation in a row-structured discontinuous canopy Remote Sensing
    of Environment, 99 (2005), pp. 271-287 View PDFView articleView in ScopusGoogle
    Scholar Zarco-Tejada et al., 2008 P.J. Zarco-Tejada, J.A.J. Berni, L. Suárez,
    E. Fereres A new era in remote sensing of crops with unmanned robots SPIE Newsroom
    (2008), 10.1117/2.1200812.1438 Google Scholar Zarco-Tejada et al., 2009 P.J. Zarco-Tejada,
    J.A.J. Berni, L. Suárez, G. Sepulcre-Cantó, F. Morales, J.R. Miller Imaging chlorophyll
    fluorescence from an airborne narrow-band multispectral camera for vegetation
    stress detection Remote Sensing of Environment, 113 (2009), pp. 1262-1275 View
    PDFView articleView in ScopusGoogle Scholar Zarco-Tejada et al., 2013 P.J. Zarco-Tejada,
    A. Catalina, M.R. González, P. Martín Relationships between net photosynthesis
    and steady-state chlorophyll fluorescence retrieved from airborne hyperspectral
    imagery Remote Sensing of Environment, 136 (2013), pp. 247-258 View PDFView articleView
    in ScopusGoogle Scholar Zarco-Tejada et al., 2012 P.J. Zarco-Tejada, V. González-Dugo,
    J.A.J. Berni Fluorescence, temperature and narrow-band indices acquired from a
    UAV for water stress detection using a hyperspectral imager and a thermal camera
    Remote Sensing of Environment, 117 (2012), pp. 322-337 View PDFView articleView
    in ScopusGoogle Scholar Zarco-Tejada et al., 2001 P.J. Zarco-Tejada, J.R. Miller,
    G.H. Mohammed, T.L.L. Notlamd, P.H. Sampson Scaling-up and model inversion methods
    with narrow-band optical indices for chlorophyll content estimation in closed
    forest canopies with hyperspectral data IEEE Transactions on Geoscience and Remote
    Sensing, 39 (2001), pp. 1491-1507 View in ScopusGoogle Scholar Cited by (352)
    Early detection of wilt in Cajanus cajan using satellite hyperspectral images:
    Development and validation of disease-specific spectral index with integrated
    methodology 2024, Computers and Electronics in Agriculture Show abstract Drones
    in vegetable crops: A systematic literature review 2024, Smart Agricultural Technology
    Show abstract Method for early diagnosis of verticillium wilt in cotton based
    on chlorophyll fluorescence and hyperspectral technology 2024, Computers and Electronics
    in Agriculture Show abstract Pixel-level regression for UAV hyperspectral images:
    Deep learning-based quantitative inverse of wheat stripe rust disease index 2023,
    Computers and Electronics in Agriculture Show abstract Detection of symptoms induced
    by vascular plant pathogens in tree crops using high-resolution satellite data:
    Modelling and assessment with airborne hyperspectral imagery 2023, Remote Sensing
    of Environment Show abstract Estimating the canopy chlorophyll content of winter
    wheat under nitrogen deficiency and powdery mildew stress using machine learning
    2023, Computers and Electronics in Agriculture Show abstract View all citing articles
    on Scopus View Abstract Copyright © 2013 Elsevier Inc. All rights reserved. Recommended
    articles Detection of Thrips Defect on Green-Peel Citrus Using Hyperspectral Imaging
    Technology Combining PCA and -Spline Lighting Correction Method Journal of Integrative
    Agriculture, Volume 13, Issue 10, 2014, pp. 2229-2235 Chun-wang DONG, …, Fei LIU
    View PDF Development of multi-disturbance bagging Extreme Learning Machine method
    for cadmium content prediction of rape leaf using hyperspectral imaging technology
    Spectrochimica Acta Part A: Molecular and Biomolecular Spectroscopy, Volume 279,
    2022, Article 121479 Jiehong Cheng, …, Lvhui Fu View PDF UAV based wilt detection
    system via convolutional neural networks Sustainable Computing: Informatics and
    Systems, Volume 28, 2020, Article 100250 L. Minh Dang, …, Hyeonjoon Moon View
    PDF Show 3 more articles Article Metrics Citations Citation Indexes: 340 Captures
    Readers: 540 Social Media Shares, Likes & Comments: 4 View details About ScienceDirect
    Remote access Shopping cart Advertise Contact and support Terms and conditions
    Privacy policy Cookies are used by this site. Cookie settings | Your Privacy Choices
    All content on this site: Copyright © 2024 Elsevier B.V., its licensors, and contributors.
    All rights are reserved, including those for text and data mining, AI training,
    and similar technologies. For all open access content, the Creative Commons licensing
    terms apply.'
  inline_citation: '>'
  journal: Remote Sensing of Environment
  limitations: '>'
  pdf_link: null
  publication_year: 2013
  relevance_score1: 0
  relevance_score2: 0
  title: High-resolution airborne hyperspectral and thermal imagery for early detection
    of Verticillium wilt of olive using fluorescence, temperature and narrow-band
    spectral indices
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1016/j.agwat.2015.01.020
  analysis: '>'
  authors:
  - Jorge Gago
  - Cyril Douthe
  - Rafael E. Coopman
  - Pedro Pablo Ferrer Gallego
  - Miquel Ribas‐Carbó
  - Jaume Flexas
  - José M. Escalona
  - H. Medrano
  citation_count: 396
  full_citation: '>'
  full_text: '>

    Skip to main content Skip to article Journals & Books Search Register Sign in
    Brought to you by: University of Nebraska-Lincoln View PDF Download full issue
    Outline Highlights Abstract Keywords 1. Introduction 2. UAVs applied to precision
    agriculture 3. Remote sensing of plant physiology from UAVs 4. UAVs aerial imagery
    5. Future perspectives and concluding remarks Acknowledgements References Show
    full outline Cited by (418) Figures (3) Tables (1) Table 1 Agricultural Water
    Management Volume 153, 1 May 2015, Pages 9-19 Review UAVs challenge to assess
    water stress for sustainable agriculture Author links open overlay panel J. Gago
    a, C. Douthe b, R.E. Coopman c, P.P. Gallego a, M. Ribas-Carbo b, J. Flexas b,
    J. Escalona b, H. Medrano b Show more Share Cite https://doi.org/10.1016/j.agwat.2015.01.020
    Get rights and content Highlights • Technological recent advances promote new
    reliable UAVs for precision agriculture. • UAVs can improve temporal and spatial
    sensing resolutions for water stress management. • Multi-spectral and thermal
    images from UAVs reflect water stress in several crop. • Easy and low-cost retrieving
    chlorophyll fluorescence from UAVs is an important challenge. Abstract Unmanned
    aerial vehicles (UAVs) present an exciting opportunity to monitor crop fields
    with high spatial and temporal resolution remote sensing capable of improving
    water stress management in agriculture. In this study, we reviewed the application
    of different types of UAVs using different remote sensors and compared their performance
    with ground-truth plant data. Several reflectance indices, such as NDVI, TCARI/OSAVI
    and PRInorm obtained from UAVs have shown positive correlations related to water
    stress indicators such as water potential (Ψ) and stomatal conductance (gs). Nevertheless,
    they have performed differently in diverse crops; thus, their uses and applications
    are also discussed in this study. Thermal imagery is also a common remote sensing
    technology used to assess water stress in plants, via thermal indices (calculated
    using artificial surfaces as references), estimates of the difference between
    canopy and air temperature, and even canopy conductance estimates derived from
    leaf energy balance models. These indices have shown a great potential to determine
    field stress heterogeneity using unmanned aerial platforms. It has also been proposed
    that chlorophyll fluorescence could be an even better indicator of plant photosynthesis
    and water use efficiency under water stress. Therefore, developing systems and
    methodologies to easily retrieve fluorescence from UAVs should be a priority for
    the near future. After a decade of work with UAVs, recently emerging technologies
    have developed more user-friendly aerial platforms, such as the multi-copters,
    which offer industry, science, and society new opportunities. Their use as high-throughput
    phenotyping platforms for real field conditions and also for water stress management
    increasing temporal and resolution scales could improve our capacity to determine
    important crop traits such as yield or stress tolerance for breeding purposes.
    Previous article in issue Next article in issue Keywords UAVsRemote sensingWater
    stressPrecision agricultureMulticoptersThermography 1. Introduction In general
    terms, agriculture consumes most of the world''s water resources (70%) (Gilbert,
    2012). At the same time, other industries are also increasing their water consumption
    and thus competing with food production. Current climate change predictions indicate
    increases in the frequency and intensity of drought periods in Mediterranean and
    semi-arid areas (Stocker et al., 2013). Globally, it is important to note that
    45% of the world''s food supply is produced on irrigated lands covering only 18%
    of cultivated areas (Döll and Siebert, 2002). This means that irrigation management
    is of crucial importance to optimize water use. Moreover, the predicted global
    food demand for 2050 indicates that crop production must double (Tilman et al.,
    2011). Increased crop production was strongly encouraged after World War II, resulting
    in the “Green Revolution” of the 60s. Now, a claim for a “Blue Revolution” seems
    to be occurring, focusing on agriculture''s environmental impacts and especially
    on optimizing water management to obtain the desired idea of “more crop per drop”
    (Beer et al., 2009). Thus, water efficiency is becoming more and more important
    for society. For example, the European Parliament recently introduced the requirement
    to sustainably “produce more with less” in agreement with the new EU research
    program “Horizon 2020” (Geoghegan-Quin, 2013). In this sense, precision agriculture
    appears to be a multidisciplinary approach capable of responding to the previous
    objectives. The American National Research Council defined this type of agriculture
    as “a management strategy that uses information technology to bring data from
    multiple sources to bear on decisions associated with crop production.” In fact,
    it involves all of the techniques and methods available in the new ICT (Information
    and Communications Technology) era, which can be used to retrieve useful information
    for managing crops while accounting for landscape heterogeneity and variability
    within and between fields (Lelong et al., 2008, Anderson and Gaston, 2013). However,
    interdisciplinary approaches will not be so easily realized; multi-disciplinary
    teams (experimental and computational scientists) will be required to integrate
    diverse data from multiple plant levels. Thus, a plant systems biology view will
    have to be used to scale this data up to an agricultural level (Fernie, 2012).
    For instance, most of the measurements used to characterize plant status are developed
    at the leaf level, while the improvement of agricultural management requires an
    up-scaling of this information to the canopy/field level. The characterization
    of one single plant is a time consuming, costly process; to carry out these types
    of characterizations for complete agricultural fields would be even more so (Berni
    et al., 2009a, Berni et al., 2009b, González-Dugo et al., 2012). Traditional remote
    sensing approaches place remote sensors on towers over crop fields (thermal imagery,
    multi and hyper-spectral cameras, fluorometers, etc.) where the main limitation
    is the fixed position from which data is collected. Another traditional remote
    sensing technique is the use of aircrafts or satellites where the temporal and
    spatial resolution significantly limits their usefulness for agricultural assessments
    (it is important to consider the highly dynamic changes in vegetation in relation
    to the environment) (Moya et al., 2004, Louis et al., 2005, Berni et al., 2009a,
    Anderson and Gaston, 2013, Jones, 2014). In this context, UAVs (unmanned aerial
    vehicles) and remote sensing come into play as useful tools because they are able
    to fill this important gap, coupled with aerial imagery and adequate computational
    efforts. Some studies have also been developed using different ground manned vehicles
    equipped with remote sensors at affordable costs, but these also present constraints
    since transporting the equipment to the monitoring areas reduces the swath mapping
    capability, and in some cases, their use is only available during crop harvesting
    (Lelong et al., 2008). In recent years, the use of UAVs for civilian purposes
    has begun to increase thanks to technological advances, cost reductions and the
    size of sensors related to the Global Position System (GPS), pre-programmed flights,
    IMUs (inertial movement units) and auto-pilots. In this sense, UAV technology
    can fill the gap of knowledge between the leaf and the canopy by improving both
    the spatial and the temporal resolution of the most common current remote sensing
    systems. Thirty years ago, a fleet of airborne imagery thermal scanners was envisioned
    to map thermal stress for water management purposes (Jackson et al., 1977, Berni
    et al., 2009b); now it seems like we are finally achieving this idea thanks to
    the emergence of UAV technologies. This review considers the latest remote sensing
    experiences obtained from different types of UAVs applied to agriculture and their
    potential ability to assess plant water status at the crop-scale. Additionally,
    it highlights the different remote sensing indices obtained from UAV technology
    and their ability to estimate plant physiological parameters. Finally, the future
    perspectives and potentials of UAVs are addressed. 2. UAVs applied to precision
    agriculture UAVs have historically been used principally for military purposes.
    After World War II they began to be used as targets or weapon reconnaissance platforms.
    Recently, other civilian purposes, such as agricultural management, have created
    an increased interest in them. In Table 1 we compiled all of the agronomy studies
    that have been published up until now which employed UAVs and remote sensing technologies
    compared with plant-truth data measurements. Types of UAVs and flight characteristics
    are also briefly mentioned (Table 1). Previously, the pioneering works of Herwitz
    et al., 2002a, Herwitz et al., 2002b, Herwitz et al., 2004 described the usefulness
    of UAVs to detect irrigation and fertilization abnormalities and fruit maturation
    of crops in agricultural fields. These NASA-funded projects used UAVs like the
    solar-powered Pathfinder-Plus (with a wing span of 36.3 m and a weight of 318
    kg), with a flying capacity of several hours, equipped with visible and multi-spectral
    cameras to acquire images (0.5 and 1 m/pixel, respectively) of a coffee plantation
    in Hawaii at 6400 m altitude. Another example of large fixed wing UAVs is the
    RCATS/APV-3 (also developed by NASA), which has been used to study vineyards in
    California (Johnson et al., 2003) (Table 1). In the last decade, technological
    advances have led to the development of micro-UAVs (less than 5 kg) mostly due
    to the reduction in weight and size of the sensors, and considerable increases
    in precision, such as inertial measurement units (IMUs) and the auto-pilots using
    GPS (Global Positioning Systems) (Berni et al., 2009a, Turner et al., 2012). Table
    1. Dataset compilation of studies using UAVs equipped with different remote sensing
    technologies for plant vigor and stress assessment and when it is available ground-truth
    plant measurements data. Type of UAVs employed and remote sensor, altitude of
    the flight, resolution of the images acquired, area covered and the correlation
    (R2) between remote data and measurements performed at ground level are shown.
    Reference UAV type Objective Camera Altitude (m) Res (cm/px) Area (Ha) Crop Herwitz
    et al. (2004) NASA''s solar-powered Pathfinder-Plus Slow-flying UAV for monitoring
    agricultural resources VIS 6400 50 1500 Coffee Multi-spectral 100 Johnson et al.
    (2003) RCTAS/APV-3 Unmanned aircraft Usefulness of UAVs for precision agriculture
    VIS and hyper-spectral nd 20 nd Grapevine Sugiura et al. (2005) Unmanned helicopter
    Aerial map of crop status Multi-spectral 30 1–7 nd Sugar beet Lelong et al. (2008)
    Powered parachute and motorized glider Wheat monitoring Multi-spectral 20–100
    10 0.26 Wheat Berni et al. (2009a) Unmanned helicopter Vegetation monitoring Multi-spectral
    150 20 0.17 Corn Olive Peach and olive Thermal 40 Berni et al. (2009b) Unmanned
    helicopter Map through CWSI and gc for irrigation scheduling Thermal 150 40 4
    Olive cv. Arbequino Zarco-Tejada et al. (2009) Unmanned helicopter Detect plant
    stress Thermal 150 m 40 nd Peach, orange and olive groves Multi-spectral 15 Olive
    Peach Turner et al. (2011) Multi-copter (8 engines) Algorithms to process and
    ortho-rectify UAV images Thermal 50 Up to 1 3 Grapevine Digital Up to 1 Multi-spectral
    Up to 1 Xiang and Tian (2011) Unmanned helicopter Development small UAV for agriculture
    surveillance Multi-spectral 60 5 0.13 Turf grass Baluja et al. (2012) Assess water
    stress variability in a commercial vineyard Thermal 200 30 5 Grapevine cv. Tempranillo
    Multi-spectral 10 González-Dugo et al. (2012) Unmanned helicopter Water stress
    detection in an almond orchard Thermal 150 12 Almond cv. Non-Pareil Almond cv.
    Monterey Primicerio et al. (2012) Multi-copter (6 engines) Monitoring crops Multi-spectral
    150 5.6 0.5 Grapevine Zarco-Tejada et al. (2012) Fixed-wing Detection of water
    stress Thermal 575 40 1.2 Orange cv. Powell and Mandarin Blanco cv. Clemenvilla
    Micro-hyperspectral González-Dugo et al. (2013) Fixed-wing Water stress detection
    in five fruit tree species Thermal 370 49 Almond Peach Lemon Orange Apricot Almond
    Peach Lemon Orange Apricot García-Ruiz et al. (2013) Multi-copter (6 engines)
    Identification of Huanglongbing-infected citrus trees Multi-spectral 100 5.45
    0.5 Orange Zarco-Tejada et al., 2013a, Zarco-Tejada et al., 2013b Fixed-wing Carotenoid
    estimations as proxy of plant stress Multi-spectral 150 15 ca. 7 Grapevine Micro-hyperspectral
    575 40 Gago et al. (2013) Multi-copter (6 engines) Water stress Thermal 15 2.5
    0.05 Grapevine Zarco-Tejada et al. (2013b) Fixed-wing Water stress Narrow-band
    multi-spectral 150 10 1.4 Grapevine Thermal 20 Reference Remote index gs Ψ [Car]
    LAI QN [Chl] F Herwitz et al. (2004) Visible imagerya Ch2/Ch3b Johnson et al.
    (2003) Visible imageryc Sugiura et al. (2005) NDVI and LAIc ns Lelong et al. (2008)
    NDVI 0.82 GNDVI 0.92 Berni et al. (2009a) NDVI 0.5 NDVI 0.88 TCARI/OSAVI 0.89
    Berni et al. (2009b) CWSI 0.91 0.82 Zarco-Tejada et al. (2009) Temperature 0.49
    Fairborne 0.57 Fairborne 0.52 Turner et al. (2011) Temperaturec NDVIc Xiang and
    Tian (2011) NDVIc Baluja et al. (2012) Tc − Ta 0.69 0.5 CWSI 0.68 0.5 IG 0.72
    0.5 I3 0.5 0.42 NDVI 0.75 0.68 TCARI/OSAVI 0.84 0.58 González-Dugo et al. (2012)
    Tc − Ta 0.59 0.82 0.66 0.74 Primicerio et al. (2012) NDVIc Zarco-Tejada et al.
    (2012) Temperature 0.78 0.34 PRI515 0.37 0.37 PRI570 0.59 0.38 TCARI 0.52 0.54
    BGI1 0.62 0.49 NDVI 0.32 0.24 RDVI 0.61 0.44 FLD3(747,762,780) 0.67 0.66 González-Dugo
    et al. (2013) Tc − Ta 0.67 0.92 0.48 0.27 0.64 CWSI 0.67 0.92 ns ns 0.64 García-Ruiz
    et al. (2013) NDVI, GNDVI, SAVI, NIR-R, G/R and NIR/Rd Zarco-Tejada et al., 2013a,
    Zarco-Tejada et al., 2013b R515/R570 0.48 TCARI/OSAVI 0.51 Gago et al. (2013)
    Temperature 0.85 IG 0.83 I3 0.78 CWSI 0.86 Zarco-Tejada et al. (2013b) NDVI 0.63
    0.34 RDVI 0.7 0.49 TCARI 0.14 0.13 TCARI/OSAVI 0.01 0.01 R700/R670 0.16 0.14 PRI
    0.49 0.53 PRInorm 0.81 0.82 Tc − Ta 0.74 0.95 CWSI 0.74 0.95 Image resolution:
    Res (cm/px), LAI (leaf area index measured at ground level), QN (crop mean nitrogen
    uptake per square meter), gs (stomatal conductance), Ψ (water potential), [car]
    (carotene concentration), [Chl] (chlorophyll concentration), F (chlorophyll fluorescence).
    ns: Not showed. nd: Not determined. a Aerial visible imagery used to distinguish
    outbreaks of guinea grass (Panicum maximum) and overall cover within coffee fields.
    b Spectral index derived from DuncanTech imagery correlated with percentage of
    mature berries from 7 different crop sites (R2 > 0.80). c No measurements at ground-truth
    plant level are shown. d Vegetation index focused into the identification of HGB
    bacteria infected citrus trees. Mainly two types of UAVs have been employed for
    agricultural management: helicopters and fixed wing airplanes (Sugiura et al.,
    2005, Berni et al., 2009a, Berni et al., 2009b, Xiang and Tian, 2011, Zarco-Tejada
    et al., 2012, Zarco-Tejada et al., 2013a) (Table 1). Both aerial platforms have
    several advantages and limitations. While unmanned helicopters have more complex
    flight systems, they offer lower flight altitudes and hover capacities (ability
    to maintain a stable position in flight) or low-speed flights. However, they are
    also able to cruise in any direction in the field and have no special requirements
    for take-off and landing, which could be critical in standard agricultural fields.
    Recently, it was published that the Pheno-copter UAV, a gas-based helicopter with
    a payload of 1.5 kg can fly for 30 min considerably improving the number of remote
    sensors able to equip at the same time and the length of the area studied (Chapman
    et al., 2014). The fixed-wing aircrafts offer more simple flight systems and longer
    durations, increasing their capacity to cover wider areas. However, their flight
    altitude is higher, thus reducing the image resolution. They are also not able
    to hover and require specific runways (Zarco-Tejada et al., 2012, Zarco-Tejada
    et al., 2013a). To meet the advanced requirements, in recent years a new aircraft
    platform appeared, the multi-copter (Table 1), whose flight characteristics are
    similar to the helicopters previously mentioned (Turner et al., 2012, Primicerio
    et al., 2012, Gago et al., 2013). Multi-copters were first designed as universal
    aerial platforms mainly dedicated to aerial film/photography with great stability
    and maneuverability and no take-off or landing runway requirements (Fig. 1A).
    However, compared to helicopters, these types of platforms have proved to be more
    user-friendly than the previous ones, allowing for an increase in the number of
    possible users as can be seen in the emergent market for professional and non-professional
    applications of the multi-copter (AR.Drone Parrot®, Mikrokopter®, MeCamAlwaysInnovating®,
    Amazon®). This could be an additional benefit because their prices are coming
    down and they could be operated by the farmers themselves to obtain data almost
    immediately, diagnose crop status, and then apply adapted water management as
    needed. Download : Download full-size image Fig. 1. (A) UAV-AirSci carbon fiber
    frame customized specifically for scientific purposes by UAVEurope® with electronic
    boards of Mikrokopter® flying above the experimental vineyard of the University
    of Balearic Islands (Spain), (B) index aerial false color image mosaick composition
    of the vineyard obtained from Canon XNite-ELPH110NDVI MaxMax© 16.1 Megapixel digital
    camera at 25 m altitude, (C) vineyard false color aerial thermal image composition
    obtained with the thermal radiocalibrated camera Gobi-384 Xenics©, (D) detail
    of the dry and wet artificial leaf references that can be observed in bright and
    dark colors, respectively. Usually, multi-copters are built out of light, resistant
    materials (such as carbon fiber, aluminum, glass fiber and kevlar) developed with
    couples of brushless motors running clockwise and counter-clockwise, respectively
    (4, 6 or 8 engines depending on the payload requirement). They are powered with
    lithium ion polymer batteries, and each motor can handle high amperes, for example
    ca. 20 A which promotes thrusts greater than 2200 g (Turner et al., 2011, Gago
    et al., 2013, García-Ruiz et al., 2013) (Fig. 1A). This power supports considerable
    payloads in these aircrafts (a six engine multi-copter can carry more than 1 kg),
    however, the flight time is, unfortunately, drastically reduced to 4–5 min, so
    multiple flights may be necessary to cover wider areas (Turner et al., 2012, Chapman
    et al., 2014). The type of UAV required will, thus, depend on the goal of the
    study or the end-product desired (Fig. 2, “Experimental design”). Download : Download
    full-size image Fig. 2. Workflow summary of the different components that must
    be considered for the use of UAVs in precision agriculture. This scheme is divided
    into 4 general tasks: experimental design (blue), data acquisition (green), data
    processing (red) and results/end products (yellow). (For interpretation of the
    references to color in this figure legend, the reader is referred to the web version
    of this article.) The different types of UAVs currently have several different
    advantages and limitations. Nevertheless, this technology could potentially revolutionize
    temporal and spatial agriculture and ecophysiology at a close range compared to
    the other more traditional methodologies (Anderson and Gaston, 2013), such as
    satellite imagery and manned flights (whose availability is limited by weather
    conditions, re-visit times and significant costs) (Turner et al., 2012). 3. Remote
    sensing of plant physiology from UAVs There is currently great interest in remote
    sensing technologies able to provide information about plant biophysical parameters
    and physiological status (Jones and Vaughan, 2010). However, the reliability of
    aerial remote sensing approaches must be assessed with plant-truth data (Fig.
    2, “Data acquisition”), e.g. with measurements related to plant growth and vigor
    (leaf area index (LAI), biomass, chlorophyll/carotene contents, plant water status
    (stomatal conductance (gs), and leaf water potential (Ψ)), (Lelong et al., 2008,
    Berni et al., 2009b, González-Dugo et al., 2012, González-Dugo et al., 2013, Zarco-Tejada
    et al., 2012, Gago et al., 2013). Imagery remote sensing technologies are mainly
    based on particular leaves and canopies’ wavelength reflectances in the visible
    range of the spectrum (RGB, red, green and blue), non-visible as IR (Infra-red)
    and the emission of far-IR (thermal). Also, several recent efforts have been conducted
    regarding sensing the fluorescence of chlorophylls as a more dynamic proxy of
    the electron transport rate (ETR) and gross primary production than previous reflectance
    indices (Jones and Vaughan, 2010, Frankenberg et al., 2011, Araus and Cairns,
    2014, Guanter et al., 2014). Another field of increased interest is related to
    the phenotyping of varieties and cultivars with improved capabilities. A plant''s
    phenotype is the interaction between its genetic background and the environment.
    In the recent years, important efforts have been made to develop facilities, sensing
    technologies and methodologies to obtain high-throughput phenotyping platforms
    to help plant breeders analyze the final results of their work (Araus and Cairns,
    2014). Also, it is important to bear in mind that it could be difficult to extrapolate
    results obtained under growth chamber conditions to real field culture conditions
    (Araus and Cairns, 2014); thus, phenotyping at field conditions is highly desirable.
    Nevertheless, the environment is highly heterogeneous, which probably will complicate
    the interpretation of the results even using all the new emergent technologies
    and platforms. It is expected that, in the near future, field phenotyping paired
    with biotechnological advances will result in high throughput data collection
    and analysis of relevant biophysical plant traits at the crop scale (Deery et
    al., 2014, Araus and Cairns, 2014). 3.1. Indices based on leaf/canopy reflectance
    Leaf reflectance can be used as an indicator of plant function because the light
    reflected depends directly on a leaf''s pigment composition (e.g. chlorophylls
    and xanthophyll), which can indeed reflect plants’ physiological status (Jones
    and Vaughan, 2010). Typically, vegetation indices are derived from reflectance
    bands based on RGB (red, green, blue) and IR and other narrow-wavelengths of the
    spectra (Fig. 3). The remote monitoring of these specific reflectances are commonly
    measured using visible, multi-spectral and hyper-spectral cameras (Table 1) (Jones
    and Vaughan, 2010, Baluja et al., 2012, Zarco-Tejada et al., 2012, Zarco-Tejada
    et al., 2013a, Zarco-Tejada et al., 2013b). The most employed index is most likely
    the normalized difference vegetation index (NDVI): where IR (infrared) is the
    reflectance in the near-infrared band (ca. 800 nm) and (R) in the red band (ca.
    680 nm), originally based on the satellite LandSat sensor bands for red and infrared.
    This index has commonly been used to detect plants and “greenness”, due to the
    elevated IR reflectance of chlorophylls, which are typically related to plant
    structural traits (Zarco-Tejada et al., 2012). Several studies have described
    the utility of UAVs equipped with multi-spectral cameras to examine the LAI through
    the NDVI index in herbaceous and woody crops such as wheat, corn and olive trees
    (Lelong et al., 2008, Berni et al., 2009a). Other indices have also recently been
    tested to obtain information related to plant physiological stress detection.
    Drought is still one of the most studied stress impulses since its potential implication
    for irrigation efficiency and scheduling is of utmost importance (Zarco-Tejada
    et al., 2012 and references therein). In the last 4 years, several works have
    appeared, mainly driven by Dr. Zarco-Tejada''s research group, focused on checking
    the different VIs (vegetation indices) acquired from the UAVs, and then comparing
    them to field collected plant physiological measurements. The optimized index
    transformed chlorophyll absorption in reflectance index/optimized soil-adjusted
    vegetation index (TCARI/OSAVI) was proposed as a more sensitive VIs to chlorophyll
    content and insensitive to other factors that could affect canopy reflectance,
    such as the reflectance from the soil, solar zenith angle and the vigor of the
    plant (using the leaf area index (LAI) as proxy) (Haboudane et al., 2002). This
    composite index is a ratio between the TCARI, which is highly sensitive to chlorophyll
    concentrations, but still affected by noise from the soil background, mostly at
    low chlorophyll concentrations, (Haboudane et al., 2002): Download : Download
    full-size image Fig. 3. Leaf spectral reflectance plus thermal band of the electromagnetic
    spectrum for the different bands employed in the generation of the vegetation
    indices NDVI (6 and 3 and 4), TCARI/OSAVI (1, 4, 5 and 6), PRI (1 and 2) and PRInorm
    (1, 2, 4, 5 and 6) and thermal indices as CWSI or IG (7). Center and bandwidth
    wavelength of the bands can differ depending of the equipment employed. The OSAVI
    was designed to avoid soil reflectance without previous knowledge about the moisture
    status and physical soil properties (Haboudane et al., 2002): Several studies
    also showed the performance of a narrow band index named PRI (photochemical reflectance
    index, R550 − R531/R550 + R531) related to the energy dissipation through the
    epoxidation state of the xanthophyll cycle pigments (Gamon et al., 1992). Recently,
    in vineyards Zarco-Tejada et al. (2013b) showed an improvement of the PRI index
    (photochemical reflectance index, R550 − R531/R550 + R531), the PRInorm, in relation
    to gs and Ψ for a daily course. The PRInorm = PRI/[RDVI·R700/R670], not only considers
    xanthophyll changes in concentration due to water stress (PRI), but also generates
    a normalization considering the chlorophyll content (thanks to the red edge index
    (R700/R670) that is sensitive to chlorophyll content) and canopy leaf area reduction
    (the RDVI, renormalized difference vegetation index, ) is sensitive to canopy
    structure) induced by stress (Zarco-Tejada et al., 2013b). Table 1 shows the vegetation
    indices obtained from UAVs and compares them to plant-truth data collected at
    the plant level in the fields. NDVI and TCARI/OSAVI were clearly related to the
    stem water potential (Ψstem) (R2 = 0.68) and gs (R2 = 0.84) in vineyards cv. Tempranillo
    (Baluja et al., 2012). However, in Citrus orchards NDVI and TCARI/OSAVI were less
    correlated with gs (R2 = 0.32 and 0.45) and Ψ (R2 = 0.24 and 0.51) (Zarco-Tejada
    et al., 2012). Indeed, “greenness” indices such as the NDVI are more related to
    plant vigor than the plant dynamic physiological status. This index might correlate
    well in crops where the biomass proportionally increases in parallel to photosynthesis,
    however, in other groups, such as the case of evergreen crop species, results
    were not so satisfactory (Peñuelas and Filella, 1998, Peng et al., 2011, Garbulsky
    et al., 2011, Marino et al., 2014). Other vegetation indices have also been tested
    (see Zarco-Tejada et al., 2012 for a complete description), showing higher correlations
    when narrow-band indices were associated with the xanthophyll cycle (PRI515) (R2
    = 0.59; p < 0.01 and 0.38; p < 0.001 for gs and Ψ, respectively). The blue/green
    index (R400/R550 bands) contrasted with both gs (R2 = 0.62; p < 0.001) and Ψ (R2
    = 0.49; p < 0.001, respectively). In grapevines, narrow-band reflectance indices
    such as the R515/R570 and the TCARI/OSAVI also showed correlation with xantophylls
    and the carotenoid content (R2 = 0.48; p < 0.01 and 0.51; p < 0.001, respectively)
    (Zarco-Tejada et al., 2013a) (Table 1). This is most likely due to their photoprotective
    roles in thermal dissipation and their ROS (reactive oxygen species) neutralization
    under stress conditions (Evain et al., 2004, Garbulsky et al., 2011). The previous
    mentioned new index, the PRInorm, showed an improved capacity for water stress
    detection (correlated with leaf gs and Ψ) in comparison with other greenness and
    structural indices (commonly are more insensitive to dynamic changes in vegetation);
    PRInorm obtained correlations coefficients similar to those obtained indices with
    thermography (Table 1, Zarco-Tejada et al., 2013b). Clearly, the interest in reflectance
    indices is to use them to scale-up to satellite imagery since the use of thermal
    imagery is constrained because of its poor resolution (100 m/pixel) which obtains
    mixed information from the plant and the background. 3.2. Indices based on leaf/canopy
    temperature Currently, one of the main assessments of plant stress via UAVs is
    naturally focused on plant water status, thus requiring the estimation of gs and
    Ψ at the leaf level since they are useful physiological water stress indicators
    (Medrano et al., 2002, González-Dugo et al., 2013). Thermal images are highly
    employed by UAVs to detect water stress in several crops, since drought promotes
    stomatal closure, reducing transpiration and evaporative cooling, while increasing
    leaf temperature. The development of miniature uncooled thermal sensors (with
    a spectral band range of 7–14 μm) has now been installed on small aircrafts to
    estimate crops’ surface temperature (Berni et al., 2009b, Gago et al., 2013).
    Thermal normalized indices (CWSI, IG and I3) were developed in the 70s and 80s
    to avoid the variability produced by environmental parameters affecting the relationship
    between stress and plant temperature (for detailed information Jones, 1999, Leinonen
    et al., 2006). As examples, the CWSI (crop water stress index) ranges from 0 to
    1 (values close to 1 are related to high levels of stress) (Idso et al., 1981),
    the IG directly increases with stomatal conductance and the I3 positively correlates
    with stomatal resistance (Jones, 1999, Leinonen et al., 2006), taking into account
    surface temperatures under wet and dry conditions as follows: (1) (2) (3) where
    Tcanopy is the surface temperature of the canopy and Twet and Tdry are reference
    surfaces that are completely wet or dry to simulate maximum and minimal leaf transpiration
    under the exposed environmental conditions. For more details about thermal indices,
    see Jones (1999) and Jones and Vaughan (2010). One of the main problems of thermal
    cameras is the reduced resolution provided by the microbolometer sensors (image
    resolution ranging from 320 × 240 to 640 × 480 pixels), increasing the problem
    of the “mixed-pixel value” where part of the temperature of the pixel comes from
    the background and not from the pure canopy, considerably reducing the quality
    of the data (Jones and Sirault, 2014). Another important consideration is the
    use of thermal cameras that integrate their own radiometric calibration system
    (Gago et al., 2013) or allow the radiometric calibration of the camera to be performed
    in the laboratory using blackbodies varying target and ambient temperature for
    the development of calibration algorithms (Zarco-Tejada et al., 2012). When meteorological
    data from the experimental site is available, gs can be estimated from aerial
    thermal images using the leaf energy balance (Monteith and Unsworth, 1990, Jones,
    1999). Alternative methodologies were published combining this model with dry
    and wet reference surfaces, highly useful to reduce the meteorological parameters
    required (Leinonen et al., 2006). The basic leaf energy balance equation (Eq.
    (4)) is: (4) where Tl and Ta are the canopy and air temperature (°C), rHR is the
    parallel resistance to heat and radiative transfer (s m−1), raw is the boundary
    layer resistance to water vapor (s m−1), rs is the stomatal resistance to water
    vapor (this resistance is assumed to be dominated mainly by stomata exchange),
    γ is the psychrometric constant (Pa K−1), Rni is the net isothermal radiation
    (Leinonen et al., 2006), p is the air density (kg m−3), cp is the air''s specific
    heat capacity (J kg−1 K−1), D is the vapor pressure deficit (Pa) and s is the
    slope of the curve of water vapor pressure related to the temperature (Pa C−1).
    Stomatal conductance, gs (gs = 1/rs), can be calculated by rearranging Eq. (5):
    (5) Combining leaf energy balance with thermal imagery to estimate the plant conductance
    (gc, canopy conductance considering the whole canopy instead of a leaf) can considerably
    improve crops water stress monitoring because it precisely defines plant water
    status (Flexas et al., 2002). This procedure avoids problems associated with thermal
    indices, such as the requirement of reference surfaces and normalization procedures
    necessary to calculate the vapor pressure deficit (VPD), which is site dependent
    and affects the CWSI estimation (Berni et al., 2009a). However, precise meteorological
    information is required (Leinonen et al., 2006) from different study sites. Several
    flight campaigns collected thermal indices of woody crops such as grapevines,
    olives, almonds, peaches, apricots, oranges and lemons in order to estimate plant
    physiological parameters (Berni et al., 2009a, Baluja et al., 2012, González-Dugo
    et al., 2012, González-Dugo et al., 2013, Gago et al., 2013) (Table 1). The CWSI
    showed a clear correlation with gs and Ψ for most of the studied crops, such as
    olives (R2 = 0.91 and 0.82; p < 0.001 respectively), grapevines (R2 = 0.86–0.68
    and 0.5), almonds (R2 = 0.67; p < 0.001 for Ψ), peaches and apricots (R2 = 0.92
    and 0.64; p < 0.001 for Ψ respectively). Meanwhile, no correlations were observed
    in orange and lemon orchards. In fact, only the difference between canopy temperature
    and air temperature (Tc − Ta) showed high correlations with Ψ in several woody
    crops, such as grapevines, almonds, peaches, lemons and apricots (R2 = 0.27–0.92)
    (González-Dugo et al., 2012, González-Dugo et al., 2013). Another study demonstrated
    that canopy conductance estimated using the leaf energy balance model (Jones,
    1999) in olive orchards, using the Tcanopy obtained from the UAV combined with
    other meteorological parameters obtained good correlation with leaf measured gs.
    Overall, UAVs applied to precision agriculture allow for the generation of spatially
    explicit crop-canopy map conductances (Berni et al., 2009a). 3.3. The challenge
    of measuring leaf chlorophyll fluorescence with UAVs Under determined conditions,
    NDVI and other vegetation indices reflect mostly the biomass and “greenness” of
    plants, even considering the fact that their sensitivity becomes weaker with increasing
    values of LAI beyond a threshold value (Carlson and Ripley, 1997). Other indices
    can track more dynamic traits and give us valuable information about the physiological
    status. Among these, the so-called photochemical reflectance index (PRI) reflects
    xanthophyll-dependent thermal dissipation of excess energy (Gamon et al., 1990,
    Evain et al., 2004). While this parameter can inform us on the efficiency of photosynthetic
    activity (Garbulsky et al., 2011), it is in fact an indirect proxy (actually,
    it reflects precisely the importance of the fraction of absorbed energy which
    is not used in photosynthesis, but rather dissipated). Therefore, some authors
    have proposed to re-name it back to its original descriptor, Physiological (not
    photochemical) reflectance index (Evain et al., 2004)). Instead, chlorophyll fluorescence
    has proven to be a more direct indicator of photosynthesis (Flexas et al., 2000,
    Moya et al., 2004). Since some types of UAVs can be highly maneuverable, they
    can fly extremely close to leaves, presenting one of the most exciting opportunities
    that has recently emerged in the remote sensing field, the measurement of leaf
    chlorophyll a fluorescence. First, this dynamic physiological phenomenon can be
    used to estimate several parameters that may serve as diagnostic tools to assess
    the light energy partitioning at the photosystem II level during water stress
    (Flexas et al., 2002). For instance, ETR can be linearly related to photosynthesis
    in C3 plants after a suitable calibration (considering photorespiration) (McAusland
    et al., 2013). A down-regulation of ETR caused by water stress can be remotely
    sensed using suitable instruments like laser-based fluorometers (Flexas et al.,
    2000, Moya et al., 2004). This occurs precisely when water stress intensifies
    to the extent that further stomatal closure results in decreased rather than increased
    water use efficiency (Flexas et al., 2002, Medrano et al., 2002). However, compared
    to optical reflectance studies, data using this methodology is still scarce (Zarco-Tejada
    et al., 2009, Zarco-Tejada et al., 2012), probably because of a need for better
    engineering efforts to improve technological characteristics such as miniaturization
    of the sensors, battery capabilities, etc. Hence, an exciting challenge for the
    future will be the development of this technology coupled with thermal imagery,
    which could lead to measurements of water use efficiency (WUE) using images of
    field conditions. Recently, McAusland et al. (2013) developed a system combining
    fluorescence and thermal imagery to estimate WUE in Arabidopsis grown under controlled
    conditions. Perhaps a limitation to implement this technique for remote sensing
    studies on broader areas, like those achievable with UAVs, is the fact that the
    retrieval of most chlorophyll parameters requires a light-saturating photosystem
    II, for which an intense and focalized beam is necessary. Using laser sources
    to develop this beam may allow for an increase in the measuring distance, but
    at the expense of increasing danger. Therefore, there is a limit for the so-called
    active fluorosensing in terms of remote sensing. However, Flexas et al. (2002)
    showed that a simple fluorescence parameter, the steady state chl. fluorescence
    (Fs), which does not require saturating pulses for its measurement, strongly and
    consistently correlated with net CO2 assimilation and accurately tracked the water
    stress-induced declines of photosynthesis provided that some conditions were fixed
    (e.g. under saturating light). Field studies describing the retrieval of solar
    induced chlorophyll fluorescence from UAVs are now available, although they are
    very scarce and limited to few crops, using a micro-hyperspectral imager (Micro-Hyperspec
    VNIR model, Headwall Photonics, USA) and the 760 nm O2-A band in-filling method
    (Zarco-Tejada et al., 2009, Zarco-Tejada et al., 2012). Still, there is a lack
    of information on this topic, probably due to the scarcity and exclusivity of
    instruments and all the modeling required to fulfill this purpose. Combining this
    technology with thermal cameras for the estimation of canopy conductance could
    be an exciting challenge for phenotyping cultivars that are drought resistant
    and/or more efficient in their water use. On the other hand, solar induced chlorophyll
    fluorescence has recently been globally mapped using satellite-based sensors (Frankenberg
    et al., 2011, Joiner et al., 2013), demonstrating the usefulness of this approach
    to track changes in crop productivity (Guanter et al., 2014). However, the problem
    of satellite-based measurements is obviously their large pixel size, which makes
    them ineffective to monitor most types of field crops. Demonstration of their
    feasibility and their correspondence with ground-based estimates of photosynthesis
    and primary productivity strongly encourage the need to develop equivalent measuring
    systems mountable on UAVs. This would allow for adjustments to almost any requirement
    in terms of precision and pixel size, which would constitute an outstanding achievement
    and versatile tool for monitoring and managing crops under water limited conditions.
    4. UAVs aerial imagery UAVs greatest advantage is the reduced altitude of their
    flight compared to other aerial platforms, which greatly improves the image''s
    resolution. However, their disadvantage is that they require more flights to cover
    large areas due to their reduced flight time. As Turner et al. (2012) explained,
    a micro-UAV flying 50 m high with a camera under a standard configuration will
    acquire terrain images of 50 m × 40 m, thus, more than 150 images are needed to
    cover 2 ha. As for the multi-copters, to increase the area covered, several flights
    are required and their batteries must be changed. One of the main constraints
    of UAVs aerial imaging technology is the usual problem of the lack of the proper
    camera location information needed to correct aerial images. In addition, the
    manual management of a large number of images is very time consuming and data
    processing can be highly complex (Fig. 2, “Data processing”). To solve this bottleneck,
    several authors have used the structure from motion (SfM) combined with ground
    control points (GCPs) to generate precise digital terrain models (DTM) (Turner
    et al., 2012, Westoby et al., 2012, Fonstad et al., 2013). For instance, Turner
    et al. (2012) proposed an automated methodology to geometrically rectify and mosaic
    the large volume of images obtained from Antarctic moss beds using a multi-copter
    based on SfM geo-referencing with GCPs. This process generates arbitrary three
    dimensional point clouds that can be transformed into real world coordinates using
    the GCPs, which creates a digital terrain model DTM with accuracies of ca. 10–15
    cm. Recently, other authors suggested the use of SfM combined with GCPs mostly
    using low-cost or open-source software (Photosynth-SynthExport®, MeshLab®, JAG3D®)
    to produce digital elevation models with horizontal and vertical precision in
    centimetrical ranges which could almost compare to airborne LiDAR models, but
    with reduced economic, labor and expertise costs (Westoby et al., 2012, Fonstad
    et al., 2013). 5. Future perspectives and concluding remarks More efforts are
    required to make these technologies more user-friendly and available for all types
    of end-users, covering different interests for a precise crop assessment. Interestingly,
    the industry is reacting to the increased interest in this field, and sharing
    this vision of user friendly tools for all types of end-users in agriculture.
    For example, three clear examples of this new business trend could include DroneMapper
    Aerial Imagery Processing, GIS Services (http://www.dronemapper.com/), an on-line
    web service specialized in the generation of geo-referenced ortho-mosaics and
    DEMs from aerial images, and the PulsePod project (http://pulsepod.io), a low-cost,
    long-term hardware for real time environmental measurements to obtain in-field
    data to improve decision assessment that could be combined with UAVs information.
    Compared to conventional platforms (such as manned aircrafts and satellites),
    UAVs present several advantages: they fly at lower altitudes, increasing images’
    spatial resolution and they cost less, allowing for higher monitoring frequencies.
    Thus, UAVs can fill the gap between other more traditional remote sensing aerial
    platforms. These characteristics will most likely improve the capabilities of
    precision agriculture, in terms of crop''s development and biotic and abiotic
    stress management, converting them into an important tool for precision agriculture
    (Fig. 2, “Results/end products”). Remote sensing indices are currently being tested
    and improved to propose proxies that reflect crops’ physiological status under
    changing environmental conditions. These remote-sensing physiological estimations,
    coupled with UAVs flying capacity could allow for a more user-friendly tool for
    plant diagnostics. Indeed, as previously stated, they can be used to determine
    plant water status for several crop species. An exciting scientific-technical
    challenge will be to combine this technology with an approach that would allow
    us to estimate the chlorophyll a fluorescence as a proxy for WUE at the crop-scale.
    UAVs can also be used to identify or compare physiological parameters of several
    varieties or transgenic lines. Thus, UAVs capacity for phenotyping could identify
    promising events, which could later determine, through physiology and molecular
    techniques, improved breeds of crops to ensure future global food security (Araus
    and Cairns, 2014). Finally, UAVs equipped with remote sensors appear to be a very
    cost-efficient approach, taking into account the high performance of the sensors,
    data acquisition and their high flexibility (Lelong et al., 2008). Moreover, considerable
    cost reductions in UAVs multi-copter technology and remote sensing can be expected
    in the coming years thanks to the open source electronic community. UAVs are clearly
    highly useful and adapted tools for precision agriculture and water irrigation
    management (Turner et al., 2011, Gago et al., 2013). Increases in monitoring could
    allow for further crop management, perhaps, even in combination with ground sensors
    or smartphone Apps, not only for crop productivity, but also for crop quality.
    Acknowledgements This work was supported by the National Plan, Spain, contracts
    BFU2011-23294 (J. Flexas, J. Gago and M. Ribas-Carbo) and Xunta de Galicia (Spain)
    post-doctoral contracts (Plan I2C, J. Gago), and finally the project AGL2011-30408/C04-01CICYT-FEDER
    financed by the Spanish government (H. Medrano and J. Escalona). References Anderson
    and Gaston, 2013 K. Anderson, K.J. Gaston Lightweight unmanned aerial vehicles
    will revolutionize spatial ecology Front. Ecol. Environ., 11 (3) (2013), pp. 138-146
    CrossRefView in ScopusGoogle Scholar Araus and Cairns, 2014 J.L. Araus, J.E. Cairns
    Field high-through put phenotyping: the new crop breeding frontier Trends Plant
    Sci., 19 (1) (2014), pp. 52-61 View PDFView articleView in ScopusGoogle Scholar
    Baluja et al., 2012 J. Baluja, M.P. Diago, P. Balda, R. Zorer, F. Meggio, F. Morales,
    J. Tardaguila Assessment of vineyard water status variability by thermal and multispectral
    imagery using an unmanned aerial vehicle (UAV) Irrig. Sci., 30 (6) (2012), pp.
    511-522 CrossRefView in ScopusGoogle Scholar Beer et al., 2009 C. Beer, P. Ciais,
    M. Reichstein, D. Baldocchi, B.E. Law, D. Papale, J.F. Soussana, C. Ammann, N.
    Buchmann, D. Frank, D. Gianelle, I.A. Janssens, A. Knohl, B. Köstner, E. Moors,
    O. Roupsard, H. Verbeeck, T. Vesala, C.A. Williams, G. Wohlfahrt Temporal and
    among-site variability of inherent water use efficiency at the ecosystem level
    Global Biogeochem. Cycles, 23 (GB2018) (2009), pp. 1-13, 10.1029/2008GB003233
    Google Scholar Berni et al., 2009a J.A.J. Berni, P.J. Zarco-Tejada, G. Sepulcre-Cantó,
    E. Fereres, F. Villalobos Mapping canopy conductance and CWSI in olive orchards
    using high resolution thermal remote sensing imagery Remote Sens. Environ., 113
    (11) (2009), pp. 2380-2388 View PDFView articleView in ScopusGoogle Scholar Berni
    et al., 2009b J.A.J. Berni, P.J. Zarco-Tejada, L. Suárez, E. Fereres Thermal and
    narrowband multispectral remote sensing for vegetation monitoring from an unmanned
    aerial vehicle Geosci. Remote Sens. IEEE Trans., 47 (3) (2009), pp. 722-738, 10.1109/TGRS.2008.2010457
    View in ScopusGoogle Scholar Chapman et al., 2014 S.C. Chapman, T. Merz, A. Chan,
    P. Jackway, S. Hrabar, M.F. Dreccer, E. Holland, B. Zheng, T.J. Ling, J. Jimenez-Berni
    Pheno-copter: a low-altitude, autonomous remote-sensing robotic helicopter for
    high-throughput field-based phenotyping Agronomy, 4 (2014), pp. 279-301 CrossRefGoogle
    Scholar Carlson and Ripley, 1997 T.N. Carlson, D.A. Ripley On the relation between
    NDVI, fractional vegetation cover, and leaf area index Remote Sens. Environ.,
    62 (1997), pp. 242-252 View in ScopusGoogle Scholar Deery et al., 2014 D. Deery,
    J. Jiménez-Berni, H. Jones, X. Siraul, R. Furbank Proximal remote sensing buggies
    and potential applications for field-based phenotyping Agronomy, 4 (2014), pp.
    279-301, 10.3390/agronomy4020279 Google Scholar Döll and Siebert, 2002 P. Döll,
    S. Siebert Global modeling of irrigation water requirements Water Resour. Res.,
    38 (4) (2002), 10.1029/2001WR000355 8-1-8-10 Google Scholar Evain et al., 2004
    S. Evain, J. Flexas, I. Moya A new instrument for passive remote sensing: 2. Measurement
    of leaf and canopy reflectance changes at 531 nm and their relationship with photosynthesis
    and chlorophyll fluorescence Remote Sens. Environ., 91 (2) (2004), pp. 175-185
    View PDFView articleView in ScopusGoogle Scholar Fernie, 2012 A.R. Fernie Grand
    challenges in plant systems biology: closing the circle(s) Front. Plant Sci.,
    3 (2012), p. 35, 10.3389/fpls.2012.00035 View in ScopusGoogle Scholar Flexas et
    al., 2000 J. Flexas, J.M. Briantais, Z. Cerovic, H. Medrano, I. Moya Steady-state
    and maximum chlorophyll fluorescence responses to water stress in grapevine leaves:
    a new remote sensing system Remote Sens. Environ., 73 (3) (2000), pp. 283-297
    View PDFView articleView in ScopusGoogle Scholar Flexas et al., 2002 J. Flexas,
    J.M. Escalona, S. Evain, J. Gulías, I. Moya, C.B. Osmond, H. Medrano Steady-state
    chlorophyll fluorescence (Fs) measurements as a tool to follow variations of net
    CO2 assimilation and stomatal conductance during water-stress in C3 plants Physiol.
    Plant., 114 (2002), pp. 231-240 View in ScopusGoogle Scholar Fonstad et al., 2013
    M.A. Fonstad, J.T. Dietrich, B.C. Courville, J.L. Jensen, P.B. Carbonneau Topographic
    structure from motion: a new development in photogrammetric measurement Earth
    Surf. Process. Landf., 38 (2013), pp. 421-430, 10.1002/esp.3366 View in ScopusGoogle
    Scholar Frankenberg et al., 2011 C. Frankenberg, J.B. Fisher, J. Worden, G. Badgley,
    S.S. Saatchi, J. Lee, G.C. Toon, A. Butz, M. Jung, A. Kuze, T. Yokota New global
    observations of the terrestrial carbon cycle from GOSAT: patterns of plant fluorescence
    with gross primary productivity Geophys. Res. Lett., 38 (2011), p. L17706, 10.1029/2011GL048738
    View in ScopusGoogle Scholar Gago et al., 2013 J. Gago, S. Martorell, M. Tomás,
    A. Pou, B. Millán, J. Ramón, M. Ruiz, R. Sánchez, J. Galmés, M.A. Conesa, J. Cuxart,
    J. Tardáguila, M. Ribas-Carbó, J. Flexas, H. Medrano, J.M. Escalona High-resolution
    aerial thermal imagery for plant water status assessment in vineyards using a
    multicopter-RPAS First Conference of the International Society for Atmospheric
    Research using Remotely-piloted Aircraft, (ISARRA), Palma de Mallorca, Spain (2013)
    Google Scholar Gamon et al., 1992 J.A. Gamon, J. Peñuelas, C.B. Field A narrow-waveband
    spectral index that tracks diurnal changes in photosynthetic efficiency Remote
    Sens. Environ., 41 (1) (1992), pp. 35-44 View PDFView articleView in ScopusGoogle
    Scholar Gamon et al., 1990 J.A. Gamon, C. Field, B. Bilger, W. Björkman, O. Fredeen,
    A.L.J. Peñuelas Remote sensing of the xanthophyll cycle and chlorophyll fluorescence
    in sunflower leaves and canopies Oecologia, 85 (1) (1990), pp. 1-7 View in ScopusGoogle
    Scholar Garbulsky et al., 2011 M.F. Garbulsky, J. Peñuelas, J.A. Gamon, Y. Inoue,
    I. Filella The photochemical reflectance index (PRI) and the remote sensing of
    leaf, canopy and ecosystem radiation use efficiencies; a review and meta-analysis
    Remote Sens. Environ., 115 (2011), pp. 281-297 View PDFView articleView in ScopusGoogle
    Scholar García-Ruiz et al., 2013 F. García-Ruiz, S. Sankaran, J.M. Maja, W.S.
    Lee, J. Rasmussen, R. Ehsani Comparison of two aerial imaging platforms for identification
    of Huanglongbing-infected citrus trees Comput. Electron. Agric., 91 (2013), pp.
    106-115 View PDFView articleView in ScopusGoogle Scholar Geoghegan-Quin, 2013
    M. Geoghegan-Quin Role of Research & Innovation in Agriculture. European Commission-SPEECH/13/505
    (2013) http://europa.eu/rapid/press-release_SPEECH-13-505_en.htm Google Scholar
    Gilbert, 2012 N. Gilbert Water under pressure Nature, 483 (2012), pp. 256-257
    CrossRefView in ScopusGoogle Scholar González-Dugo et al., 2012 V. González-Dugo,
    P. Zarco-Tejada, J.A. Berni, L. Suárez, D. Goldhamer, E. Fereres Almond tree canopy
    temperature reveals intra-crown variability that is water stress-dependent Agric.
    Forest Meteorol., 154 (2012), pp. 156-165 View PDFView articleView in ScopusGoogle
    Scholar González-Dugo et al., 2013 V. González-Dugo, P. Zarco-Tejada, E. Nicolás,
    P.A. Nortes, J.J. Alarcón, D.S. Intrigliolo, E. Fereres Using high resolution
    UAV thermal imagery to assess the variability in the water status of five fruit
    tree species within a commercial orchard Precis. Agric., 14 (6) (2013), pp. 660-678
    CrossRefView in ScopusGoogle Scholar Guanter et al., 2014 L. Guanter, Y. Zhang,
    M. Jung, J. Joiner, M. Voigt, J. Berry, C. Frankenberg, A.R. Huete, P. Zarco-Tejada,
    J. Leeh, M.S. Morani, G. Ponce-Campos, C. Beer, G. Camps-Vallsk, N. Buchman, D.
    Gianelle, K. Klumpp, A. Cescattio, J.M. Baker, T.J. Griffis Global and time-resolved
    monitoring of crop photosynthesis with chlorophyll fluorescence Proc. Natl. Acad.
    Sci U. S. A. (2014), 10.1073/pnas.1320008111 Google Scholar Haboudane et al.,
    2002 D. Haboudane, J.R. Miller, N. Tremblay, P.J. Zarco-Tejada, L. Dextraze Integrated
    narrow-band vegetation indices for prediction of crop chlorophyll content for
    application to precision agriculture Remote Sens. Environ., 81 (2) (2002), pp.
    416-426 View PDFView articleView in ScopusGoogle Scholar Herwitz et al., 2002a
    S.R. Herwitz, J.G. Leung, R.G. Higgins, S.E. Dunagan, J.C. Arvesen Remote command-and-control
    of imaging payloads using commercial off-the-shelf technology International Geoscience
    and Remote Sensing Symposium, IGARSS 2002, IEEE, Toronto (2002), 10.1109/IGARSS.2002.1026755
    Google Scholar Herwitz et al., 2002b S.R. Herwitz, L.F. Johnson, J.C. Arvesen,
    J.G. Leung, S.E. Dunagan Precision agriculture as a commercial application for
    solar-powered unmanned aerial vehicles V.A. Reston, L.F. Johnson, D.F. Bosch,
    D.C. Williams, B.M. Lobitz (Eds.), AIAA''s 1st Technical Conference and Workshop
    on Unmanned Aerial Vehicles, American Institute of Aeronautics and Astronautics
    Inc. (2002) (Paper 2002-3404) Google Scholar Herwitz et al., 2004 S.R. Herwitz,
    L.F. Johnson, S.E. Dunagan, R.G. Higgins, D.V. Sullivan, J. Zheng, B.M. Lobitz,
    J.G. Leunge, B.A. Gallmeyer, M. Aoyagi, R.E. Slye, J.A. Brass Imaging from an
    unmanned aerial vehicle: agricultural surveillance and decision support Comput.
    Electron. Agric., 44 (1) (2004), pp. 49-61 View PDFView articleView in ScopusGoogle
    Scholar Idso et al., 1981 S.B. Idso, R.D. Jackson, P.J. Pinter Jr., R.J. Reginato,
    J.L. Hatfield Normalizing the stress-degree-day parameter for environmental variability
    Agric. Meteorol., 24 (1981), pp. 45-55 View PDFView articleView in ScopusGoogle
    Scholar Jackson et al., 1977 R.D. Jackson, R.J. Reginato, S.B. Idso Wheat canopy
    temperature: a practical tool for evaluating water requirements Water Resour.
    Res., 13 (3) (1977), pp. 651-656 View in ScopusGoogle Scholar Johnson et al.,
    2003 L.F. Johnson, S. Herwitz, S. Dunagan, B. Lobitz, D. Sullivan, R. Sly Collection
    of ultra-high spatial and spectral resolution image data over California vineyards
    with a small UAV Proceedings, Int’l Symposium on Remote Sensing of Environment,
    Honolulu, HI, November 10–14 (2003) Google Scholar Joiner et al., 2013 J. Joiner,
    L. Guanter, R. Lindstrot, M. Voigt, A.P. Vasilkov, E.M. Middleton, K.F. Huemmrich,
    Y. Yoshida, C. Frankenber Global monitoring of terrestrial chlorophyll fluorescence
    from moderate-spectral-resolution near-infrared satellite measurements: methodology,
    simulations, and application to GOME-2 Atmos. Meas. Tech., 6 (2013), pp. 2803-3282
    CrossRefGoogle Scholar Jones, 1999 H.G. Jones Use of infrared thermometry for
    estimation of stomatal conductance as a possible aid to irrigation scheduling
    Agric. Forest Meteorol., 95 (3) (1999), pp. 139-149 View PDFView articleView in
    ScopusGoogle Scholar Jones and Vaughan, 2010 H.G. Jones, R.A. Vaughan Remote Sensing
    of Vegetation: Principles, Techniques, and Applications Oxford University Press
    (2010) Google Scholar Jones, 2014 H.G. Jones Plants and Microclimate. A Quantitative
    Approach to Environmental Plant Physiology (3rd ed.), Cambridge University Press
    (2014) Google Scholar Jones and Sirault, 2014 H.G. Jones, X.R.R. Sirault Scaling
    of thermal images at different spatial resolution: the mixed pixel problem Agronomy,
    4 (2014), pp. 380-396, 10.3390/agronomy4030380 View in ScopusGoogle Scholar Leinonen
    et al., 2006 I. Leinonen, O.M. Grant, C.P.P. Tagliavia, M.M. Chaves, H.G. Jones
    Estimating stomatal conductance with thermal imagery Plant Cell Environ., 29 (8)
    (2006), pp. 1508-1518 CrossRefView in ScopusGoogle Scholar Lelong et al., 2008
    C.C. Lelong, P. Burger, G. Jubelin, B. Roux, S. Labbé, F. Baret Assessment of
    unmanned aerial vehicles imagery for quantitative monitoring of wheat crop in
    small plots Sensor, 8 (5) (2008), pp. 3557-3585, 10.3390/s8053557 View in ScopusGoogle
    Scholar Louis et al., 2005 J. Louis, A. Ounis, J.M. Ducruet, S. Evain, T. Laurila,
    T. Thum, M. Aurela, G. Wingsle, L. Alonso, R. Pedros, I. Moya Remote sensing of
    sunlight-induced chlorophyll fluorescence and reflectance of Scots pine in the
    boreal forest during spring recovery Remote Sens. Environ., 96 (1) (2005), pp.
    37-48 View PDFView articleView in ScopusGoogle Scholar Marino et al., 2014 G.
    Marino, E. Pallozzi, C. Cocozza, R. Tognetti, A. Giovannelli, C. Cantini, M. Centritto
    Assessing gas exchange, sap flow and water relations using tree canopy spectral
    reflectance indices in irrigated and rainfed Olea europaea L. Environ. Exp. Bot.,
    99 (2014), pp. 43-52 View PDFView articleView in ScopusGoogle Scholar McAusland
    et al., 2013 L. McAusland, P.A. Davey, N. Kanwal, N.R. Baker, T. Lawson A novel
    system for spatial and temporal imaging of intrinsic plant water use efficiency
    J. Exp. Bot., 64 (16) (2013), pp. 4993-5007 CrossRefView in ScopusGoogle Scholar
    Medrano et al., 2002 H. Medrano, J.M. Escalona, J. Bota, J. Gulías, J. Flexas
    Regulation of photosynthesis of C3 plants in response to progressive drought:
    stomatal conductance as a reference parameter Ann. Bot. Lond., 89 (7) (2002),
    pp. 895-905 View in ScopusGoogle Scholar Monteith and Unsworth, 1990 J.L. Monteith,
    M.H. Unsworth Principles of Environmental Physics Edward Arnold, London (1990),
    p. 291 Google Scholar Moya et al., 2004 I. Moya, L. Camenen, S. Evain, Y. Goulas,
    Z.G. Cerovic, G. Latouche, J. Flexas, A. Ounis A new instrument for passive remote
    sensing: 1. Measurements of sunlight-induced chlorophyll fluorescence Remote Sens.
    Environ., 91 (2) (2004), pp. 186-197 View PDFView articleView in ScopusGoogle
    Scholar Peng et al., 2011 Y. Peng, A.A. Gitelson, G. Keydan, D.C. Rundquist, W.
    Moses Remote estimation of gross primary production in maize and support for a
    new paradigm based on total crop chlorophyll content Remote Sens. Environ., 115
    (4) (2011), pp. 978-989 View PDFView articleView in ScopusGoogle Scholar Peñuelas
    and Filella, 1998 J. Peñuelas, I. Filella Visible and near-infrared reflectance
    techniques for diagnosing plant physiological status Trends Plant Sci., 3 (1998),
    pp. 151-156 View PDFView articleView in ScopusGoogle Scholar Primicerio et al.,
    2012 J. Primicerio, S.F. Di Gennaro, E. Fiorillo, L. Genesio, E. Lugato, A. Matese,
    F.P. Vaccari A flexible unmanned aerial vehicle for precision agriculture Precis.
    Agric., 13 (4) (2012), pp. 517-523 CrossRefView in ScopusGoogle Scholar Stocker
    et al., 2013 T.F. Stocker, D. Qin, G.K. Plattner, M. Tignor, S.K. Allen, J. Boschung,
    A. Nauels, Y. Xia, V. Bex, P.M. Midgley IPCC Climate Change 2013: The Physical
    Science Basis. Contribution of Working Group I to the Fifth Assessment Report
    of the Intergovernmental Panel on Climate Change Cambridge University Press, Cambridge,
    UK/New York, NY, USA (2013) Google Scholar Sugiura et al., 2005 R. Sugiura, N.
    Noguchi, K. Ishii Remote-sensing technology for vegetation monitoring using an
    unmanned helicopter Biosys. Eng., 90 (4) (2005), pp. 369-379 View PDFView articleView
    in ScopusGoogle Scholar Tilman et al., 2011 D. Tilman, C. Balzer, J. Hill, B.L.
    Befort Global food demand and the sustainable intensification of agriculture Proc.
    Natl. Acad. Sci. U. S. A., 108 (50) (2011), pp. 20260-20264 CrossRefView in ScopusGoogle
    Scholar Turner et al., 2011 D. Turner, A. Lucieer, C. Watson Development of an
    unmanned aerial vehicle (UAV) for hyper resolution vineyard mapping based on visible,
    multispectral, and thermal imagery Proceedings of 34th International Symposium
    on Remote Sensing of Environment (2011), p. 4 CrossRefGoogle Scholar Turner et
    al., 2012 D. Turner, A. Lucieer, C. Watson An automated technique for generating
    georectified mosaics from ultra-high resolution unmanned aerial vehicle (UAV)
    imagery, based on structure from motion (SfM) point clouds Remote Sens., 4 (5)
    (2012), pp. 1392-1410, 10.3390/rs4051392 View in ScopusGoogle Scholar Westoby
    et al., 2012 M.J. Westoby, J. Brasington, N.F. Glasser, M.J. Hambrey, J.M. Reynolds
    ‘Structure-from-Motion’ photogrammetry: a low-cost, effective tool for geosciences
    applications Geomorphology, 179 (2012), pp. 300-314 View PDFView articleView in
    ScopusGoogle Scholar Xiang and Tian, 2011 H. Xiang, L. Tian Development of a low-cost
    agricultural remote sensing system based on an autonomous unmanned aerial vehicle
    (UAV) Biosyst. Eng., 108 (2) (2011), pp. 174-190 View PDFView articleView in ScopusGoogle
    Scholar Zarco-Tejada et al., 2009 P.J. Zarco-Tejada, J.A.J. Berni, L. Suárez,
    G. Sepulcré-Cantó, F. Morales, J.R. Miller Imaging chlorophyll fluorescence with
    an airborne narrow-band multispectral camera for vegetation stress detection Remote
    Sens. Environ., 113 (2009), pp. 1262-1275 View PDFView articleView in ScopusGoogle
    Scholar Zarco-Tejada et al., 2012 P.J. Zarco-Tejada, V. González-Dugo, J.A. Berni
    Fluorescence, temperature and narrow-band indices acquired from a UAV platform
    for water stress detection using a micro-hyperspectral imager and a thermal camera
    Remote Sens. Environ., 117 (2012), pp. 322-337 View PDFView articleView in ScopusGoogle
    Scholar Zarco-Tejada et al., 2013a P.J. Zarco-Tejada, M.L. Guillén-Climent, R.
    Hernández-Clemente, A. Catalina, M.R. González, P. Martín Estimating leaf carotenoid
    content in vineyards using high resolution hyperspectral imagery acquired from
    an unmanned aerial vehicle (UAV) Agric. Forest Meteorol., 171 (2013), pp. 281-294
    View PDFView articleView in ScopusGoogle Scholar Zarco-Tejada et al., 2013b P.J.
    Zarco-Tejada, V. González-Dugo, L.E. Williams, L. Suárez, J.A.J. Berni, D. Goldhamer,
    E. Fereres A PRI-based water stress index combining structural and chlorophyll
    effects: assessment using diurnal narrow-band airborne imagery and the CWSI thermal
    index Remote Sens. Environ., 138 (2013), pp. 38-50 View PDFView articleView in
    ScopusGoogle Scholar Cited by (418) Drones in vegetable crops: A systematic literature
    review 2024, Smart Agricultural Technology Show abstract A robust model for diagnosing
    water stress of winter wheat by combining UAV multispectral and thermal remote
    sensing 2024, Agricultural Water Management Show abstract Combining machine learning
    algorithm and multi-temporal temperature indices to estimate the water status
    of rice 2023, Agricultural Water Management Show abstract Daily dynamic thresholds
    of different agricultural drought grades for summer maize based on the Vegetation
    Water Index 2023, Journal of Hydrology Show abstract Field identification of drought
    tolerant wheat genotypes using canopy vegetation indices instead of plant physiological
    and biochemical traits 2023, Ecological Indicators Show abstract Optimum sampling
    window size and vegetation index selection for low-altitude multispectral estimation
    of root soil moisture content for Xuxiang Kiwifruit 2023, Agricultural Water Management
    Show abstract View all citing articles on Scopus View Abstract Copyright © 2015
    Elsevier B.V. All rights reserved. Recommended articles Evaluating the Arc-SWAT2009
    in predicting runoff, sediment, and nutrient yields from a vineyard and an olive
    orchard in Central Italy Agricultural Water Management, Volume 153, 2015, pp.
    51-62 Marco Napoli, Simone Orlandini View PDF Relationships between thermal stratification
    in a secondarily treated wastewater reservoir that stores water for irrigation
    and filter clogging in the irrigation system Agricultural Water Management, Volume
    153, 2015, pp. 63-70 Ana Milstein, Mordehai Feldlite View PDF Effects of different
    drip irrigation regimes on saline–sodic soil nutrients and cotton yield in an
    arid region of Northwest China Agricultural Water Management, Volume 153, 2015,
    pp. 1-8 Ruoshui Wang, …, Shuqin Wan View PDF Show 3 more articles Article Metrics
    Citations Citation Indexes: 397 Policy Citations: 1 Captures Readers: 974 Social
    Media Shares, Likes & Comments: 36 View details About ScienceDirect Remote access
    Shopping cart Advertise Contact and support Terms and conditions Privacy policy
    Cookies are used by this site. Cookie settings | Your Privacy Choices All content
    on this site: Copyright © 2024 Elsevier B.V., its licensors, and contributors.
    All rights are reserved, including those for text and data mining, AI training,
    and similar technologies. For all open access content, the Creative Commons licensing
    terms apply.'
  inline_citation: '>'
  journal: Agricultural Water Management
  limitations: '>'
  pdf_link: null
  publication_year: 2015
  relevance_score1: 0
  relevance_score2: 0
  title: UAVs challenge to assess water stress for sustainable agriculture
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'

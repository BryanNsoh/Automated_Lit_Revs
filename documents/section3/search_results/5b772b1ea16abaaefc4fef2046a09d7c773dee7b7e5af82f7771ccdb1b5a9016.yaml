- analysis: '>'
  authors:
  - Lin S.
  - Lin W.
  - Wu K.
  - Wang S.
  - Xu M.
  - Wang J.Z.
  citation_count: '0'
  description: Sensor-generated time-series data now constitutes a significant and
    growing portion of the world's data due to the rapid proliferation of the Internet
    of Things (IoT). The transmission and storage of such voluminous data have emerged
    as enormous challenges. Data compression and reduction strategies have been instrumental
    in mitigating these challenges to some extent. However, they have exhibited limitations
    when applied to real-time IoT-based monitoring systems. This stems from their
    failure to adequately consider the stringent requirements of real-time data transmission
    and the continuous constant-value redundancy within periodic monitoring data.
    Consequently, we introduce a dedicated compression algorithm tailored specifically
    for time-series data within periodic IoT-based monitoring systems, namely Cocv.
    It takes advantage of the continuous constant-value repetition of the time-series
    data to compress data by discarding redundant data points. It can not only compress
    static batches of data but also dynamically compress data streams to improve system
    performance in real-time IoT-based monitoring systems. The offline Cocv outperforms
    traditional compressors on gas-leak monitoring data with a compression ratio of
    98.5%, maintaining a decent speed for both compression and decompression. In an
    actual IoT-based gas-leak monitoring system, the online Cocv improves handling
    capacity by 255%, reading speed by 728%, reduces bandwidth consumption by 94%,
    and storage space consumption by 98% compared to the original scheme.
  doi: 10.1016/j.iot.2023.101049
  full_citation: '>'
  full_text: '>

    "Skip to main content Skip to article Journals & Books Search Register Sign in
    Brought to you by: University of Nebraska-Lincoln View PDF Download full issue
    Outline Highlights Abstract Keywords 1. Introduction 2. Related work 3. Offline
    compression algorithm for time-series data with continuous constant values 4.
    Online compression algorithm for time-series data with continuous constant values
    5. Experimental results and discussion 6. Conclusion and future work Declaration
    of competing interest Acknowledgments Data availability References Show full outline
    Figures (11) Show 5 more figures Tables (4) Table 1 Table 2 Table 3 Table 4 Internet
    of Things Volume 25, April 2024, 101049 Research article Cocv: A compression algorithm
    for time-series data with continuous constant values in IoT-based monitoring systems
    Author links open overlay panel Shengsheng Lin a, Weiwei Lin a b, Keyi Wu c, Songbo
    Wang a, Minxian Xu d, James Z. Wang e Show more Add to Mendeley Share Cite https://doi.org/10.1016/j.iot.2023.101049
    Get rights and content Highlights • Time-series data in monitoring systems maintain
    constant values for extended periods. • Utilize the constant-value redundancy
    that exists in time series to compress data. • Dynamic compression of data streams
    by dropping redundant data points. • Improve Iot-based monitoring system performance
    by dynamic data compression. Abstract Sensor-generated time-series data now constitutes
    a significant and growing portion of the world’s data due to the rapid proliferation
    of the Internet of Things (IoT). The transmission and storage of such voluminous
    data have emerged as enormous challenges. Data compression and reduction strategies
    have been instrumental in mitigating these challenges to some extent. However,
    they have exhibited limitations when applied to real-time IoT-based monitoring
    systems. This stems from their failure to adequately consider the stringent requirements
    of real-time data transmission and the continuous constant-value redundancy within
    periodic monitoring data. Consequently, we introduce a dedicated compression algorithm
    tailored specifically for time-series data within periodic IoT-based monitoring
    systems, namely Cocv. It takes advantage of the continuous constant-value repetition
    of the time-series data to compress data by discarding redundant data points.
    It can not only compress static batches of data but also dynamically compress
    data streams to improve system performance in real-time IoT-based monitoring systems.
    The offline Cocv outperforms traditional compressors on gas-leak monitoring data
    with a compression ratio of 98.5%, maintaining a decent speed for both compression
    and decompression. In an actual IoT-based gas-leak monitoring system, the online
    Cocv improves handling capacity by 255%, reading speed by 728%, reduces bandwidth
    consumption by 94%, and storage space consumption by 98% compared to the original
    scheme. Previous article in issue Next article in issue Keywords Compression algorithmInternet
    of thingsTime-series dataContinuous constant valuesGas-leak monitoring systems
    1. Introduction Thanks to the rapid proliferation of the Internet of Things (IoT)
    [1], [2], time-series applications have increasingly widespread, such as smart
    agriculture [3], anomaly detection [4], underwater wireless monitoring [5], and
    so on. In these IoT applications, monitoring systems are a class of systems with
    real-time transmission of monitoring data to obtain the latest status of monitored
    objects. Take the gas-leak monitoring system as an example [6], [7]. The gas-leak
    monitoring sensors laid in individual pipelines generate monitoring data points
    every few seconds, and these huge data generated day and night need to be transferred
    to the cloud server for processing and finally stored in time series database
    (TSDB). Huge network transmission bandwidth, server handling capacity, and disk
    storage space are required in this process. Therefore, how to reduce the cost
    of time-series data storage and transmission has become one of the concerns in
    the community. Data compression serves as an effective way to mitigate the costs
    associated with the storage of time-series data, including both general-purpose
    and time-series-purpose compression techniques [8], [9]. However, data compression
    methods are primarily designed for the application at the end of storage (e.g.,
    TSDB), as exemplified in Fig. 1(a). More specifically, a batch of collected static
    data would be compressed via a designated algorithm and then stored in the TSDB
    [10], [11]. While this approach effectively minimizes disk space utilization,
    the transmission bandwidth consumption between IoT system modules remains restricted.
    To reduce the bandwidth consumption in the IoT system, data reduction solutions
    have been promoted in recent years [12]. Data reduction represents a technique
    aimed at preprocessing and reducing data prior to transmission, thereby reducing
    the frequency of communication within the IoT system. However, most existing data
    reduction techniques are implemented at the gateway or sensor side. These solutions
    are typically targeted at non-time-sensitive tasks, where the server allows the
    edge devices to accumulate a batch of data and then compress it before transferring
    it to the cloud server [13]. However, for systems like gas-leak monitoring systems,
    each data point needs to be transmitted in real-time to obtain timely status updates
    for the monitored object. Therefore, the real-time data transmission requirements
    of such systems constrain the application of existing data reduction techniques
    at the edge. Additionally, it is essential to note that time series values within
    IoT-based monitoring systems tend to exhibit prolonged periods of slow change.
    For instance, in the context of gas leak monitoring, the values often persist
    at a constant 0 for extended durations, as gas leaks are relatively infrequent
    occurrences. Consequently, the data remain stationary for extended intervals,
    indicating the presence of a significant amount of redundant information. Regrettably,
    existing compression algorithms do not fully exploit this characteristic, thereby
    failing to optimize the compression ratio for such data. The literature [14] noticed
    this feature and utilized it to reduce the data transmission time between the
    server and gateway, but its usefulness is still limited in the gas-leak monitoring
    system due to the real-time data transmission requirements. As a result, the existing
    compression and data reduction methods still have shortcomings for gas-leak monitoring
    systems. In this work, we propose a compression algorithm specifical for time-series
    data with continuous constant values (Cocv) in IoT-based monitoring systems to
    fill the gaps. It takes full account of the continuous constant-value redundancy
    that exists in monitoring data and achieves compression by discarding superfluous
    redundant points in the data stream, as shown in Fig. 1(b). Cocv is available
    in offline and online versions, where the offline version can compress static
    batch data to achieve an extreme compression rate, and the online version can
    be applied to IoT-based monitoring systems to compress dynamic data streams in
    real-time. Specifically, compression with online Cocv is a dynamic and continuous
    process on the server side, rather than on the edge side in the previous studies.
    For instance, a data point will be recorded and discarded by the server when it
    is considered redundant to be compressed, so that it does not need to be transferred
    to TSDB and the users. This improvement can significantly reduce transmission
    frequency and bandwidth consumption, and thus greatly improve the performance
    of the entire application. Further, by pre-reducing the number of redundant points,
    other compression techniques or compressors can be overlaid on the storage side
    to achieve the ultimate compression ratio. Our experimental results show that
    offline Cocv outperforms the traditional compression algorithm, and the application
    of online Cocv greatly improves the gas-leak monitoring system’s performance.
    To summarize, the main contributions of this paper are as follows: Download :
    Download high-res image (475KB) Download : Download full-size image Fig. 1. Comparison
    of the data flows in the IoT-based monitoring systems with different setups. •
    We propose a specialized compression algorithm for time-series data with continuous
    constant values, achieved by discarding superfluous redundant data points. • We
    mathematically prove that the proposed algorithm satisfies many desirable properties,
    including a high compression ratio, high computational efficiency, and lossless
    compression, when compressing periodic time-series data. • We further refine the
    initially designed algorithm to an online version capable of operating on the
    server side. This adaptation has been successfully implemented in the IoT-based
    gas-leak monitoring system, leading to significant improvements in performance.
    • Extensive experimental results based on both real-world and synthetic datasets
    show the proposed offline algorithm outperforms the traditional compression algorithm,
    and the application of its online version greatly improves the gas-leak monitoring
    system’s performance. The remainder of this paper is organized as follows: In
    Section 2, we conduct a comprehensive review of the related literature and present
    our findings. In Section 3, we introduce the offline Cocv algorithm and prove
    its desirable properties mathematically. Then in Section 4, we refine the offline
    Cocv to the online Cocv capable of operating on actual IoT-based monitoring systems.
    In Section 5, the detailed offline and online experiments of Cocv is presented.
    Finally, our work is summarized in Section 6. 2. Related work Numerous research
    scholars have dedicated considerable effort to advancing the development of compression
    algorithms and data reduction techniques in recent decades [8], [12]. To distinguish
    our work effectively, we will provide a comprehensive overview of related research.
    General and time-series compression algorithms. Traditional general-purpose compressors
    are characterized by compression algorithms based on dictionary coding [15], [16],
    which rely on the identification of shared identical segments within the data.
    Examples of such compressors include Gzip [17], Snappy [18], Lz4 [19], and Zstd
    [20]. Lossless compression of time-series data capitalizes on the distinctive
    features of time-series data for enhanced compression efficiency. Notable examples
    of dictionary-based compressors incorporating time-series properties are A-Lzss
    [21] and D-Lzw [22]. Additionally, Drh [23] and Sprintz [24] are sequential algorithms
    designed to compress time series data, employing a sequential combination of fundamental
    compression techniques, including Huffman coding [25], Delta coding [26], Run-length
    coding [27], among others. In recent years, machine learning techniques have also
    been explored for time series compression [28], [29], [30]. Dzip [31] stands out
    as a time series lossless compressor that employs deep neural networks [32] in
    conjunction with window prediction techniques. It endeavors to train a corresponding
    prediction model for the data slated for compression and subsequently retains
    the prediction error through arithmetic coding [33], thereby achieving lossless
    compression of time series data. While these data compression algorithms have
    made significant advancements in recent years, they have not been specifically
    tailored to address the characteristics of data, such as those found in gas leak
    monitoring, which exhibit a multitude of redundant data points. In contrast, Cocv
    capitalizes on precisely this attribute, accomplishing data compression by discarding
    superfluous redundant data points. Data reduction techniques in IoT systems. The
    application of data reduction methods in IoT systems has proven its significance
    over the years [34], [35], [36]. It is worth noting that existing data reduction
    techniques typically operate at the edge of IoT systems, with the primary goal
    of conserving sensor energy and reducing data transmission overhead [37], [38],
    [39]. For instance, in wireless sensor networks (WSN) within the context of IoT
    [40], energy efficiency is a paramount concern due to the limited energy resources
    of sensor nodes. Consequently, numerous data reduction techniques for sensor nodes
    [41], [42], [43] have been developed, encompassing aggregation-based and compression-based
    methods. Additionally, several data reduction techniques are employed at the sensor
    level to reduce data transmission overhead [44], [45]. It is noteworthy that these
    methods often operate in scenarios where sensors can continuously collect data
    before central compression and reporting, which is not feasible in the context
    of gas leak monitoring. In gas leak scenarios, sensors must promptly report their
    latest status to the server to ensure safety, with no opportunity to accumulate
    data for later transmission. In this context, dynamic data stream reduction executed
    at the server side, as opposed to the traditional approach, holds significant
    promise. However, to the best of our knowledge, such methods are currently lacking,
    creating a gap in the domain of data reduction techniques within IoT systems.
    In summary, Cocv distinguishes itself from existing compression algorithms and
    data reduction techniques by offering a compression algorithm for time-series
    data streams that excels in reducing redundant data points. The offline version
    of Cocv can be employed as a static compression algorithm for batch data compression.
    Simultaneously, the online version of Cocv facilitates dynamic data compression
    on the server side, effectively bridging the gap in data reduction techniques
    at the server level. 3. Offline compression algorithm for time-series data with
    continuous constant values In this section, we first introduce the overview of
    Cocv for the offline version and then give the definitions of required notations
    and specific algorithm design. At the last, we prove its excellent properties,
    including high compression rate, low computational complexity, and lossless compression
    when compressing periodic time-series data. 3.1. Overview of offline Cocv Using
    a formal notation [8], time series can be defined as: (1) where is the number
    of data points and is denoted as a time-series data point, of which is the timestamp
    and is the value. A time series can be sliced into multiple sequence segments.
    For such a sequence segment: (2) if , satisfy: (3) then we classify this segment
    as a continuous constant-value segment (CCS). In the case of an extended CCS,
    there exists significant redundancy within its data, allowing for a more concise
    representation. To be precise, it can be characterized by its start time, fixed
    interval, end time, and constant value, which can be used to reconstruct the same
    CCS. We observe that the complete description of the entire segment is inherently
    contained in the first, second, and last data points of the segment. Thus, theoretically,
    a CCS can be entirely represented using only these three data points. As shown
    in Fig. 2, the overview process of offline Cocv is described. During the compression
    process, superfluous redundant points are deduplicated, and only the segment’s
    1st, 2nd, and last data points are retained. In this way, we can achieve the compression
    of time-series data with CCSs. During the decompression process, the necessary
    information of the CCS (i.e., start time, fixed interval, end time, and constant
    value) is obtained from the 1st, 2nd, and last data points. And then the discarded
    data points can be recalculated back through them. Theoretically, the more the
    number and length of CCSs in a time-series data sequence, the better the compression
    ratio will be obtained. Download : Download high-res image (313KB) Download :
    Download full-size image Fig. 2. The overview process of offline Cocv compression
    and decompression. Table 1. The notations of offline Cocv. Symbol Description
    Uncompressed time-series data stream Compressed time-series data stream Decompressed
    time-series data stream Current data point to be compressed, and its timestamp
    and value Front data point that was compressed, and its timestamp, value, times
    it has appeared consecutively, and the time interval Signal of system error or
    outage (e.g., −2) Pointer to the current data point when decompressing Time interval
    of the current data stream The th data point in the compressed data stream, and
    its timestamp and value 3.2. Notations and algorithm design Download : Download
    high-res image (415KB) Download : Download full-size image Table 1 exhibits the
    notations in the offline Cocv. Algorithm 1 demonstrates the main process of offline
    Cocv, which accepts an uncompressed time-series data stream and outputs a compressed
    time-series data stream . Offline Cocv first initializes to an empty array, and
    initializes , , , to , , , respectively. Line 1 of offline Cocv iterates through
    each data point in the time-series data stream . In line 2 of the algorithm, if
    and , then it means that a CCS is found and the front point is in the middle of
    the segment, thus compression can be performed. Therefore, line 3 of the algorithm
    discards the original front point and performs self-increment to record the length
    of the CCS. Line 4 implies that the current point is not in the CCS. In lines
    5–7 of the algorithm, if , then it means that the original front point is the
    end of the previous CCS, so it needs to be pushed into the compressed data stream
    . In lines 8–10, the current point is pushed into the compressed data stream ,
    and the value of , , , is updated to find the next CCS again. In lines 13–14,
    after the iteration of the time-series data stream is completed, if , then it
    means that the last point of the data stream is just the end of the last CCS,
    so that point is pushed into the compressed data stream. Algorithm 1 finally returns
    the compressed time-series data stream and ends. Download : Download high-res
    image (461KB) Download : Download full-size image Algorithm 2 shows the main process
    of decompression of offline Cocv, which accepts the compressed time-series data
    stream and outputs the decompressed time-series data stream . It first initializes
    pointer to 0. In lines 1 and 2 of the algorithm, if the length of the time-series
    data stream is less than or equal to , then it means that there must be no CCS
    in this data stream (according to Eq. (2), the minimum length of a CCS is ) and
    can directly return without decompression. In lines 4 and 5 of the algorithm,
    the difference between the timestamps of the 1th and 0th data points is recorded
    as , and these two points are directly pushed into the decompressed result stream
    . In line 6 of the algorithm, the first to the penultimate data point in the compressed
    time-series data stream is traversed. In lines 7 and 8 of the algorithm, if the
    next data point is not equal to the value of the current data point, or its timestamp
    difference modulo is not equal to , then it means that the next data point is
    not an endpoint of a CCS, so it is directly pushed into the decompression result
    data stream . Lines 9–13 imply that the next point and the current point are the
    endpoints of a CCS, so the original discarded data points can be recalculated
    through and the information of these two points. Line 16 of the algorithm recalculates
    the new . Algorithm 2 finally returns the decompressed time-series data stream
    and ends. 3.3. Desirable properties Offline Cocv exhibits desirable properties,
    including high compression rate, low computational complexity, and lossless compression,
    when compressing periodic time-series data. We will prove it in the following.
    Theorem 1 Offline Cocv exhibits a high compression ratio applicable to periodic
    time-series data featuring a substantial number of CCSs. Proof of Theorem 1 To
    better describe the compression ratio, we define the compression score here: (4)
    For a time series, we define as the total length of the series, as the number
    of CCSs inside the time series that satisfy Eq. (3), as the average length of
    these CCSs, and as the total proportion of discontinuous points that not in those
    CCSs. For the CCSs with a regular interval, the first segment will be compressed
    to 3 data points, while the other segments that follow will be compressed to 2
    points. Therefore, we have: (5) And then the compression score for this time series
    can be expressed as: (6) In addition, the identity of the total points number
    for the CCSs can be described as: (7) Substituting it into Eq. (6), we have: (8)
    After simplifying it, we have: (9) When the length of this time series tends to
    infinity, i.e., tends to infinity small, we have: (10) and (11) When compressing
    periodic time-series data characterized by a significant count of CCSs, specifically
    exhibiting a low value of and a substantial , the Cocv compression method demonstrates
    remarkable efficiency in achieving substantial compression ratios. Theorem 2 Offline
    Cocv exhibits low computational complexity. Proof of Theorem 2 In Algorithm 1,
    lines 2–11 handle the data points within the time-series data stream with an upper
    complexity bound of . However, line 1 of the algorithm traverses the time-series
    data stream denoted as , resulting in a complexity of for lines 1–12 collectively.
    Lines 13–15 involve only simple operations and have a constant complexity of .
    Therefore, the overall complexity of Algorithm 1 is determined by , which can
    be equivalently expressed as . Turning to Algorithm 2, lines 11–14 represent the
    most computationally intensive portion. The complexity of lines 11–14 is tied
    to the length of the CCS and is expressed as . This complexity scales relative
    to the length of the CCS. If we denote the average CCS length as , then . Additionally,
    line 6 of the algorithm has a complexity of , equivalently , while the remaining
    lines exhibit constant complexity, i.e., . Consequently, the overall complexity
    of Algorithm 2 can be expressed as . By combining Eqs. (4), (10), we establish
    that is proportional to , implying that the complexity of Algorithm 2 scales as
    . The compression and decompression algorithms of offline Cocv exhibit a computational
    complexity of each. This linear relationship with the length of the time-series
    data sequence indicates that both compression and decompression operations have
    low computational demands. Theorem 3 Offline Cocv constitutes a lossless compressor
    applicable to periodic time-series data. Proof of Theorem 3 A time-series sequence
    can be partitioned into two distinct components: CCSs with a length greater than
    2 and discrete data points not belonging to these segments. In the context of
    regular interval time-series sequences, it is theoretically possible to compress
    all CCSs into just two discrete endpoints, with the exception of the first segment,
    which requires compression to three points. Simultaneously, all discrete points
    outside of a CCS remain unaltered. Consequently, the original data transforms
    into a sequence of discrete points devoid of any initial CCSs. However, in the
    extreme case of time-series sequences featuring irregular intervals, it is conceivable
    that discrete points might coincide exactly with the endpoints of nonexistent
    CCSs. In such instances, during the decompression process, these particular discrete
    data points will be erroneously interpreted as endpoints of CCSs, inadvertently
    reintroducing non-existent CCSs. In this scenario, offline Cocv cannot be considered
    strictly lossless compression, as it cannot ensure the consistency of the decompressed
    data with the original data. Nevertheless, this can be construed as a linear interpolation
    to compensate for missing information in practical IoT-based systems, thereby
    exerting no significant impact on the system’s operational information. When dealing
    with time-series data characterized by fixed equal intervals, Cocv can indeed
    guarantee lossless compression and decompression. Each segment generated by the
    offline Cocv decompression algorithm unquestionably originates from a CCS in the
    original data. This guarantees the lossless compression attribute of offline Cocv
    in cases where the time-series sequence to be compressed adheres to a fixed, equal
    time interval. In summary, offline Cocv has the properties of high compression
    rate, low computational complexity, and lossless compression applicable to periodic
    time-series data. 4. Online compression algorithm for time-series data with continuous
    constant values Offline Cocv demonstrates remarkable compression capabilities
    for offline data, but the objective of this research extends beyond solely mitigating
    disk storage overhead for continuous constant-value-type time-series data. It
    also aims to enhance the overall performance of IoT-based monitoring systems,
    encompassing aspects such as handling capacity, data reading time, and bandwidth
    consumption. Consequently, we refine offline Cocv into an online iteration, tailored
    to fulfill the demands of real-time compression within IoT-based monitoring systems.
    It is noteworthy that the implementation of online Cocv will reside on the system
    server side. We take the gas-leak monitoring system as an example to first introduce
    the overall architecture and features of the IoT-based monitoring systems and
    then describe the improved online Cocv compression algorithm. 4.1. Architecture
    of IoT-based monitoring system As shown in Fig. 3, a typical gas-leak monitoring
    system comprises a multitude of sensors, a centralized or distributed server,
    and a TSDB. Each sensor collects gas-leak monitoring information from the gas
    pipe at regular intervals (e.g., every 10 s) and uploads it to the server. The
    server accepts and analyzes the data uploaded by these sensors. If the data exhibits
    abnormality, an early warning notification would be sent to the users. TSDB accepts
    the processed data from the server and stores it on the disk. Users query the
    monitoring data through the server to query the data stored in TSDB. Usually,
    the data streams transmitted between different components would consume huge communication
    bandwidth and occupy a huge handling capacity of the server before the system
    architecture was optimized. Download : Download high-res image (308KB) Download
    : Download full-size image Fig. 3. A typical architecture of an IoT-based gas-leak
    monitoring system and its optimized data streams compressed by Cocv. After being
    optimized by Cocv, the compressed data streams in the IoT-based monitoring system
    are also shown in Fig. 3, including the data streams transmitted between the server,
    TSDB, and users. Specifically, a data point will be recorded and discarded by
    the server when it is considered redundant to be stored, so that it does not need
    to be transferred to TSDB. Similarly, only a small amount of reduced data needs
    to be transferred when the users query and the server access the data. The data
    would be restored by the low-complexity decompression algorithm of Cocv, which
    might be a process that will be much faster than reading large amounts of raw
    data directly. In that way, the server’s handling capacity, users’ reading time,
    TSDB’s disk consumption, and bandwidth consumption will gain significant improvements.
    Nonetheless, there exist three challenges within the gas-leak monitoring system
    that preclude the direct application of offline Cocv: (1) Parallel Data Arrival:
    Due to parallelization, data from multiple sensors may arrive simultaneously.
    Consequently, the algorithm necessitates refinement to enable concurrent compression
    of multiple time series. (2) Sensor Stability: The stability of individual sensors
    cannot be assured. Each sensor may abruptly go offline due to hardware or network
    issues. To address this concern, Cocv requires the integration of a sensor offline
    monitoring module, enhancing the overall system’s data integrity. It is worth
    noting that this module is optional; the algorithm can still function correctly
    without it, albeit at the cost of missing sensor offline information. (3) Server
    Stability: Similarly, the stability of the server cannot be guaranteed. The server
    may experience downtime at any given moment, leading to a disruption in the Cocv
    algorithm, resulting in significant information loss. Consequently, online Cocv
    must incorporate mechanisms to recover lost information following server interruption
    and restart. To accommodate these three challenges, the optimized online compression
    algorithm will be introduced in the next section. Notably, the corresponding decompression
    algorithm is directly derived from Algorithm 2, but it is crucial to emphasize
    that the compressed data from each sensor necessitates separate decompression.
    Table 2. The notations of online Cocv. Symbol Description Set of sensors and its
    sensor Uncompressed time-series data stream Compressed time-series data stream
    Decompressed time-series data stream Current data point of the sensor to be compressed,
    and its timestamp and value Front data point of sensor that was compressed, and
    its timestamp, value, times it has appeared consecutively, and the time interval
    from the previous point Signal of system error or outage (e.g., −2) Signal of
    sensor offline (e.g., −1) Current system time Fixed interval to detect sensor
    offline Pointer to the current data point of sensor when decompressing Time interval
    of the current data stream of sensor The th data point of sensor that was compressed,
    and its timestamp and value 4.2. Notations and algorithm design Download : Download
    high-res image (545KB) Download : Download full-size image Table 2 exhibits the
    notations in the online Cocv. Algorithm 3 shows the main process of online Cocv,
    which accepts the sensor set and the uncompressed time-series data stream , and
    then outputs the compressed time-series data stream . In line 1 of the algorithm,
    each sensor in the sensor set is traversed. In line 2 of the algorithm, if , then
    it means that the sensor is not initialized, so line 3 initializes it. Line 4
    of the algorithm indicates that sensor has been initialized, which further indicates
    that the server has been offline previously. Therefore, lines 5 and 6 of the algorithm
    push the former information into the time-series data stream and reinitialize
    the information of the sensors. It should be noted that the information of , ,
    , can be stored after the server going offline with the help of persistence techniques
    of Redis [46] or other persistence techniques. The sensor offline detection in
    line 9 is an optional module and is described in the description of Algorithm
    4. Lines 10–26 of Algorithm 3 essentially exhibit a comparable compression process
    to that of lines 1–15 in Algorithm 1. Specifically, this involves the identification
    and removal of redundant data points within CCSs. They differ in that Algorithm
    3 distinguishes which sensor the current data point belongs to, thus enabling
    parallelized compression of multiple time series. Download : Download high-res
    image (313KB) Download : Download full-size image Algorithm 4 shows the main process
    of the sensor offline detection algorithm, which accepts the sensor set and the
    fixed interval to detect the sensor offline, and outputs the offline monitoring
    data stream to Algorithm 3. In line 1 of the algorithm, the thread sleeps for
    to wait for the detection. In lines 2–4 of the algorithm, a new thread is executed
    to monitor the sensor’s offline status after each sleep for . In line 5 of the
    algorithm, each sensor in the sensor set is traversed. In lines 6 and 7 of the
    algorithm, if the front data timestamp exceeds now or the last data point is offline,
    then it means that the sensor is offline now, so it sends the offline information
    of this sensor to the stream . 5. Experimental results and discussion The performance
    of Cocv is evaluated by experimenting with real data sets and simulated generated
    data in this section. 5.1. Experimental setup 5.1.1. Comparison algorithm The
    following comparison algorithms are employed to assess the performance of Cocv.
    These algorithms consist of four general-purpose compressors, one sequential time-series
    compressor, and one neural network-based compression technique. Gzip [17]: A lossless
    compression algorithm built on the Deflate methodology. It typically offers a
    high compression ratio at the expense of slower compression speeds. Snappy [18]:
    A lossless compression algorithm designed for rapid compression with an acceptable
    compression ratio. Lz4 [19]: A lossless compression algorithm optimized for swift
    compression and decompression operations. Zstd [20]: A compression algorithm employing
    Finite State Entropy (FSE), enabling the adjustment of compression levels from
    −7 (fastest speed) to 22 (highest compression ratio). Delta [26]: Utilizes double
    delta coding on timestamps to compress time-series data. Dzip [31]: A lossless
    compression algorithm that incorporates deep neural networks and window prediction
    techniques. Cocv_Zstd: A variant of Cocv, which involves applying the Zstd compression
    algorithm after Cocv. This approach has the potential to achieve an even more
    remarkable compression ratio. 5.1.2. Evaluation metrics The following defined
    metrics are employed to evaluate the performance of the proposed algorithm in
    this paper: Compression Score: This metric quantifies the compression ratio. (12)
    Compression Speed: This metric measures the compression speed. (13) Decompression
    Speed: This metric evaluates the decompression speed. (14) Handling Capacity:
    This metric gauges the server’s capability to process sensor data uploads per
    unit of time. (15) Reading Speed: This metric measures user retrieval speed. (16)
    Bandwidth Consumption: This metric assesses the bandwidth consumption between
    the server and TSDB. (17) Storage Consumption: This metric quantifies the TSDB
    storage space usage. (18) 5.1.3. Dataset Real Data: We obtained real data from
    a gas-leak monitoring company in China, including measurements from 100 gas-leak
    monitoring sensors over a period of one month. The information of this dataset
    is recorded in Table 3. Synthetic Data: To better evaluate the performance of
    Cocv, simulated data is also employed. We generated 399 data files in which the
    rate of discontinuous points rises from 0 to 0.5 and the average length of CCSs
    rises from 4 to 1000, with each data file containing 864,000 data points. Table
    3. The information of the real gas-leak monitoring data. Size of origin data (kB)
    Total number of points Number of CCSs Average length of CCSs 121,082 8,242,285
    40,700 201 5.1.4. Experimental environment The experiments in this section were
    performed on a CentOS server configured with Intel(R) Xeon(R) Gold 5218 CPU @
    2.30 GHz, 256 GB RAM, along with TSDB service (10,000 transactions per second)
    and Redis components [46]. The experimentation process involved the simulation
    of a gas-leak monitoring system as illustrated in Fig. 3. This simulation entailed
    the deployment and utilization of 100 gas-leak monitoring sensors. 5.2. Experimental
    result of offline Cocv Fig. 4 illustrates the compression performance of the offline
    Cocv algorithm and several comparative algorithms when applied to real gas-leak
    monitoring data. The findings demonstrate that offline Cocv attains a top-tier
    compression ratio, surpassing conventional general-purpose compression algorithms
    such as Gzip, Lz4, and Snappy by a significant margin, all while maintaining a
    reasonable compression speed. Zstd, benefiting from the novel finite-state entropy
    technique, also achieves commendable results in terms of compression ratio and
    compression speed. In the case of Delta, which serves as a sequential compression
    algorithm designed for time-series data, it fails to achieve a favorable compression
    ratio for this particular data type. This may be attributed to Delta’s necessity
    to store each data point even after size reduction, resulting in minimal space
    savings in comparison to the substantial redundancy present in the data. Concerning
    Dzip, a deep learning data compression framework, it likewise attains an almost
    ideal compression ratio. Nonetheless, questions persist regarding its practical
    applicability due to its unsatisfactory compression and decompression speed. This
    drawback arises from the considerable time required for training a matching model
    tailored to the data intended for compression. Download : Download high-res image
    (323KB) Download : Download full-size image Fig. 4. Compression performance of
    offline Cocv and other algorithms on the real data collected from a Chinese gas-leak
    monitoring company. Overall, Cocv achieves a near-optimal compression ratio while
    maintaining a decent compression and decompression speed that meets practical
    needs compared with these algorithms. In addition, by stacking Cocv and Zstd,
    a more extreme compression ratio can be achieved without much speed loss. Not
    only Zstd but also any other algorithms can be overlaid with the Cocv algorithm
    to achieve higher compression ratios according to the actual requirement. The
    results of Fig. 5 show the effect of the compression ratio of offline Cocv and
    other compared algorithms as the rate of discontinuous points and the average
    length of CCSs change. Fig. 6 shows the effect of the compression ratio of offline
    Cocv as the rate of discontinuous points and the average length of CCSs change
    simultaneously. It can be found that as the rate of discontinuous points decreases
    and the average length of CCSs increases, the compression score of offline Cocv
    increases, while the other compared algorithms remain the same or only increase
    a little. Specifically, Cocv will outperform most of the comparison algorithms
    when the rate of discontinuous points is below 10% and the average length of continuous
    segments exceeds 100. Therefore, Cocv can perform satisfactorily in the face of
    time-series data with obvious constant-value continuity, such as gas-leak monitoring
    data, temperature sensing data, disk usage, and other time-series data with abundant
    continuous-constant values. Download : Download high-res image (447KB) Download
    : Download full-size image Fig. 5. Compression score of offline Cocv and other
    comparison algorithms on the synthetic data. Download : Download high-res image
    (431KB) Download : Download full-size image Fig. 6. Compression score of offline
    Cocv with different rates of discontinuous points (rise from 0% to 50%) and average
    length of continuous segments (rise from 4 to 1000). 5.3. Experimental result
    of online Cocv We have applied the enhanced online Cocv methodology to an actual
    IoT-based gas-leak monitoring system, which comprises a TSDB with a maximum write
    capacity of 10,000 transactions per second (TPS) and a Redis component. The performance
    improvements resulting from the implementation of online Cocv are presented in
    Table 4. Notably, the online Cocv solution has demonstrated substantial enhancements
    in various aspects of the system’s performance, encompassing handling capacity,
    reading speed, bandwidth consumption, and storage consumption. Table 4. The improvement
    achieved by the online Cocv over the original scheme. Empty Cell Handling capacity
    Reading speed Bandwidth consumption Storage consumption Original Scheme 9036 269,982
    9036 8,242,285 Online Cocv 32,102 2,235,499 479 12,3621 Improve 255% 728% 94%
    98% Download : Download high-res image (571KB) Download : Download full-size image
    Fig. 7. The evaluation of IoT-based monitoring systems’ performance with various
    system configurations: (i) Synchronous Single-Threading Mode (Sync_ST), (ii) Asynchronous
    Single-Threading Mode (Async_ST), and (iii) Asynchronous Multithreading Mode (Async_MT).
    Furthermore, Fig. 7 provides a detailed illustration of the performance outcomes
    under different system configurations. In a synchronous setup, online Cocv exhibits
    a remarkable 108 increase in handling capacity and a 6 enhancement in reading
    speed compared to the original scheme. Importantly, it maintains nearly constant
    bandwidth consumption while achieving a substantial 98% reduction in storage consumption.
    This observed performance gain is primarily attributed to the synchronous mode’s
    predominant network bandwidth bottleneck, where Cocv’s impact on bandwidth consumption
    remains relatively consistent with the original scheme. Nevertheless, substantial
    improvements are observed in other performance metrics. Conversely, when operating
    in asynchronous mode, the system bottleneck shifts to the single-threaded CPU.
    Under these conditions, online Cocv enhances the handling capacity by 58%, reading
    speed by 722%, reduces bandwidth consumption by 97%, and lowers storage consumption
    by 98% compared to the original scheme. In pursuit of optimizing system performance,
    IoT-based systems generally opt for asynchronous multi-threaded operation. In
    this mode, the original approach experiences a bottleneck in the write speed of
    the TSDB, while the online Cocv approach encounters a bottleneck in CPU execution
    speed. Consequently, online Cocv yields substantial improvements, including a
    255% increase in handling capacity, a 728% improvement in reading speed, a 94%
    reduction in bandwidth consumption, and a 98% decrease in storage consumption
    when compared to the original scheme. As a result, online Cocv emerges as a powerful
    tool for significantly enhancing the performance of IoT-based monitoring systems.
    Consequently, it is evident that both offline Cocv and online Cocv exhibit satisfactory
    performance. Offline Cocv yields exceptional compression ratios and high compression
    speeds when applied to offline batch data. Moreover, the utilization of online
    Cocv in IoT-based monitoring systems leads to a significant enhancement in performance.
    6. Conclusion and future work In this paper, we propose Cocv, a compression algorithm
    for time-series data with continuous constant values in IoT-based monitoring systems.
    Cocv is designed to improve the performance of IoT-based monitoring systems by
    reducing redundancy in the time-series data. Cocv satisfies many desirable properties,
    including a high compression ratio, high computational efficiency, and lossless
    compression for time-series data with a regular time interval. In the offline
    scenario, Cocv achieves a compression ratio of 98.5%, which substantially outperforms
    the traditional general-purpose compressors. In the online scenario of a periodic
    IoT-based gas-leak monitoring system, Cocv improves handling capacity by 255%,
    reading speed by 728%, reduces bandwidth consumption by 94%, and storage space
    consumption by 98% compared to the original scheme. In future work, we aspire
    to extend Cocv to non-periodic IoT-based monitoring systems, aiming to enhance
    the practical effectiveness of Cocv. Furthermore, exploring the application of
    Cocv on the sensor side is also a promising direction worth investigating. Declaration
    of competing interest The authors declare that they have no known competing financial
    interests or personal relationships that could have appeared to influence the
    work reported in this paper. Acknowledgments This work is supported by National
    Natural Science Foundation of China (620721878), Guangdong Special Project for
    Marine Economy Development, China (GDNRC[2022]17), Guangzhou Development Zone
    Science and Technology Project, China (2021GH10), and Major Key Project of PCL,
    China (PCL2021A09). Data availability Data will be made available on request.
    References [1] Apat H.K., Nayak R., Sahoo B. A comprehensive review on Internet
    of Things application placement in Fog computing environment Internet Things,
    23 (2023), Article 100866, 10.1016/j.iot.2023.100866 URL https://www.sciencedirect.com/science/article/pii/S2542660523001890
    View PDFView articleView in ScopusGoogle Scholar [2] Laghari A.A., Wu K., Laghari
    R.A., Ali M., Khan A.A. A review and state of art of Internet of Things (IoT)
    Arch. Comput. Methods Eng. (2021), pp. 1-19 CrossRefGoogle Scholar [3] Al-Qurabat
    A.K.M., Mohammed Z.A., Hussein Z.J. Data traffic management based on compression
    and MDL techniques for smart agriculture in IoT Wirel. Pers. Commun., 120 (3)
    (2021), pp. 2227-2258 CrossRefView in ScopusGoogle Scholar [4] Wu W., He L., Lin
    W., Su Y., Cui Y., Maple C., Jarvis S. Developing an unsupervised real-time anomaly
    detection scheme for time series with multi-seasonality IEEE Trans. Knowl. Data
    Eng., 34 (9) (2022), pp. 4147-4160, 10.1109/TKDE.2020.3035685 View in ScopusGoogle
    Scholar [5] Jawad G.A.M., Al-Qurabat A.K.M., Idrees A.K. Maximizing the underwater
    wireless sensor networks’ lifespan using BTC and MNP5 compression techniques Ann.
    Telecommun. (2022), pp. 1-21 Google Scholar [6] Meribout M. Gas leak-detection
    and measurement systems: Prospects and future trends IEEE Trans. Instrum. Meas.,
    70 (2021), pp. 1-13, 10.1109/TIM.2021.3096596 Google Scholar [7] Dong L., Qiao
    Z., Wang H., Yang W., Zhao W., Xu K., Wang G., Zhao L., Yan H. The gas leak detection
    based on a wireless monitoring system IEEE Trans. Ind. Inform., 15 (12) (2019),
    pp. 6240-6251, 10.1109/TII.2019.2891521 View in ScopusGoogle Scholar [8] Chiarot
    G., Silvestri C. Time series compression survey ACM Comput. Surv., 55 (10) (2023),
    10.1145/3560814 Google Scholar [9] Jayasankar U., Thirumal V., Ponnurangam D.
    A survey on data compression techniques: From the perspective of data quality,
    coding schemes, data type and applications J. King Saud Univ. - Comput. Inf. Sci.,
    33 (2) (2021), pp. 119-140, 10.1016/j.jksuci.2018.05.006 View PDFView articleView
    in ScopusGoogle Scholar [10] Wang C., Qiao J., Huang X., Song S., Hou H., Jiang
    T., Rui L., Wang J., Sun J. Apache IoTDB: A time series database for IoT applications
    Proc. ACM Manag. Data, 1 (2) (2023), 10.1145/3589775 Google Scholar [11] Xiao
    J., Huang Y., Hu C., Song S., Huang X., Wang J. Time series data encoding for
    efficient storage: A comparative analysis in apache IoTDB Proc. VLDB Endow., 15
    (10) (2022), pp. 2148-2160, 10.14778/3547305.3547319 View in ScopusGoogle Scholar
    [12] Pioli L., Dorneles C.F., de Macedo D.D., Dantas M.A. An overview of data
    reduction solutions at the edge of IoT systems: a systematic mapping of the literature
    Computing (2022), pp. 1-23 CrossRefGoogle Scholar [13] Saeedi I.D.I., Al-Qurabat
    A.K.M. Perceptually important points-based data aggregation method for wireless
    sensor networks Baghdad Sci. J., 19 (4) (2022), p. 0875 CrossRefGoogle Scholar
    [14] Sari K., Riasetiawan M. The implementation of timestamp, bitmap and RAKE
    algorithm on data compression and data transmission from IoT to cloud 2018 4th
    International Conference on Science and Technology (ICST) (2018), pp. 1-6, 10.1109/ICSTC.2018.8528698
    Google Scholar [15] Ziv J., Lempel A. A universal algorithm for sequential data
    compression IEEE Trans. Inform. Theory, 23 (3) (1977), pp. 337-343 View in ScopusGoogle
    Scholar [16] Ziv J., Lempel A. Compression of individual sequences via variable-rate
    coding IEEE Trans. Inform. Theory, 24 (5) (1978), pp. 530-536 View in ScopusGoogle
    Scholar [17] Jean-loup G., Mark A. The gzip home page (2003) https://www.gzip.org/,
    accessed September 16, 2023 Google Scholar [18] Steinar H.G. Snappy — A fast compressor/decompressor
    (2015) http://google.github.io/snappy/, accessed September 16, 2023 Google Scholar
    [19] Yann C. lz4/lz4: Extremely fast compression algorithm (2017) https://github.com/lz4/lz4/,
    accessed September 16, 2023 Google Scholar [20] Yann C. Zstandard - Real-time
    data compression algorithm (2017) https://facebook.github.io/zstd/, accessed September
    16, 2023 Google Scholar [21] Pope J., Vafeas A., Elsts A., Oikonomou G., Piechocki
    R., Craddock I. An accelerometer lossless compression algorithm and energy analysis
    for IoT devices 2018 IEEE Wireless Communications and Networking Conference Workshops
    (WCNCW) (2018), pp. 396-401, 10.1109/WCNCW.2018.8368985 View in ScopusGoogle Scholar
    [22] Le T.L., Vo M.-H. Lossless data compression algorithm to save energy in wireless
    sensor network 2018 4th International Conference on Green Technology and Sustainable
    Development (GTSD), IEEE (2018), pp. 597-600 CrossRefView in ScopusGoogle Scholar
    [23] Mogahed H.S., Yakunin A.G. Development of a lossless data compression algorithm
    for multichannel environmental monitoring systems 2018 XIV International Scientific-Technical
    Conference on Actual Problems of Electronics Instrument Engineering (APEIE), IEEE
    (2018), pp. 483-486 CrossRefGoogle Scholar [24] Blalock D., Madden S., Guttag
    J. Sprintz: Time series compression for the internet of things Proc. ACM Interact.
    Mob. Wearable Ubiquitous Technol., 2 (3) (2018), pp. 1-23 CrossRefGoogle Scholar
    [25] Huffman D.A. A method for the construction of minimum-redundancy codes Proc.
    IRE, 40 (9) (1952), pp. 1098-1101 View in ScopusGoogle Scholar [26] Suel T. Delta
    compression techniques Encyclopedia of Big Data Technologies, Vol. 63 (2019) Google
    Scholar [27] Hardi S., Angga B., Lydia M., Jaya I., Tarigan J. Comparative analysis
    run-length encoding algorithm and fibonacci code algorithm on image compression
    Journal of Physics: Conference Series, Vol. 1235, IOP Publishing (2019), Article
    012107 CrossRefView in ScopusGoogle Scholar [28] Zheng Z., Zhang Z. A temporal
    convolutional recurrent autoencoder based framework for compressing time series
    data Appl. Soft Comput., 147 (2023), Article 110797, 10.1016/j.asoc.2023.110797
    URL https://www.sciencedirect.com/science/article/pii/S1568494623008153 View PDFView
    articleView in ScopusGoogle Scholar [29] Feng H., Ma R., Yan L., Ma Z. Spatiotemporal
    prediction based on feature classification for multivariate floating-point time
    series lossy compression Big Data Res., 32 (2023), Article 100377, 10.1016/j.bdr.2023.100377
    URL https://www.sciencedirect.com/science/article/pii/S2214579623000102 View PDFView
    articleView in ScopusGoogle Scholar [30] Mao Y., Cui Y., Kuo T.-W., Xue C.J. Accelerating
    general-purpose lossless compression via simple and scalable parameterization
    Proceedings of the 30th ACM International Conference on Multimedia (2022), pp.
    3205-3213 CrossRefView in ScopusGoogle Scholar [31] Goyal M., Tatwawadi K., Chandak
    S., Ochoa I. DZip: Improved general-purpose loss less compression based on novel
    neural network modeling 2021 Data Compression Conference (DCC), IEEE (2021), pp.
    153-162 CrossRefView in ScopusGoogle Scholar [32] He K., Zhang X., Ren S., Sun
    J. Deep residual learning for image recognition Proceedings of the IEEE Conference
    on Computer Vision and Pattern Recognition (2016), pp. 770-778 Google Scholar
    [33] Witten I.H., Neal R.M., Cleary J.G. Arithmetic coding for data compression
    Commun. ACM, 30 (6) (1987), pp. 520-540 View in ScopusGoogle Scholar [34] Zhang
    C., Miao Y., Xie Q., Guo Y., Du H., Jia X. Privacy-preserving deduplication of
    sensor compressed data in distributed fog computing IEEE Trans. Parallel Distrib.
    Syst., 33 (12) (2022), pp. 4176-4191, 10.1109/TPDS.2022.3179992 View in ScopusGoogle
    Scholar [35] Gao Y., Chen L., Han J., Wu G., Liu S. Similarity-based deduplication
    and secure auditing in IoT decentralized storage J. Syst. Archit., 142 (2023),
    Article 102961, 10.1016/j.sysarc.2023.102961 URL https://www.sciencedirect.com/science/article/pii/S1383762123001406
    View PDFView articleView in ScopusGoogle Scholar [36] de Oliveira M.A., da Rocha
    A.M., Puntel F.E., Cavalheiro G.G.H., et al. Time series compression for IoT:
    A systematic literature review Wirel. Commun. Mob. Comput., 2023 (2023) Google
    Scholar [37] Correa J.D.A., Pinto A.S.R., Montez C. Lossy data compression for
    IoT sensors: A review Internet Things, 19 (2022), Article 100516 View PDFView
    articleView in ScopusGoogle Scholar [38] Sadri A.A., Rahmani A.M., Saberikamarposhti
    M., Hosseinzadeh M. Data reduction in fog computing and internet of things: A
    systematic literature survey Internet Things (2022), Article 100629 View PDFView
    articleView in ScopusGoogle Scholar [39] Al-Qurabat A.K.M., Abou Jaoude C., Idrees
    A.K. Two tier data reduction technique for reducing data transmission in IoT sensors
    2019 15th International Wireless Communications & Mobile Computing Conference
    (IWCMC), IEEE (2019), pp. 168-173 CrossRefGoogle Scholar [40] Al-Qurabat A.K.M.,
    Abdulzahra S.A. An overview of periodic wireless sensor networks to the internet
    of things IOP Conference Series: Materials Science and Engineering, Vol. 928,
    IOP Publishing (2020), Article 032055 View in ScopusGoogle Scholar [41] Nedham
    W.B., Al-Qurabat A.K.M. An improved energy efficient clustering protocol for wireless
    sensor networks 2022 International Conference for Natural and Applied Sciences
    (ICNAS), IEEE (2022), pp. 23-28 CrossRefView in ScopusGoogle Scholar [42] Abdulzahra
    S.A., Al-Qurabat A.K.M., Idrees A.K. Compression-based data reduction technique
    for IoT sensor networks Baghdad Sci. J., 18 (1) (2021), p. 0184 CrossRefGoogle
    Scholar [43] Al-Qurabat A.K.M., Abdulzahra S.A., Idrees A.K. Two-level energy-efficient
    data reduction strategies based on SAX-LZW and hierarchical clustering for minimizing
    the huge data conveyed on the internet of things networks J. Supercomput. (2022),
    pp. 1-47 View in ScopusGoogle Scholar [44] Chowdhury M.R., Tripathi S., De S.
    Adaptive multivariate data compression in smart metering Internet of Things IEEE
    Trans. Ind. Inform., 17 (2) (2020), pp. 1287-1297 Google Scholar [45] Xu Y., Li
    Y., Zhang Q., Yang Z. Age-optimal hybrid temporal-spatial generalized deduplication
    and ARQ for satellite-integrated internet of things IEEE Internet Things J. (2022)
    Google Scholar [46] Salvatore S. Redis is an in-memory database that persists
    on disk (2009) https://github.com/redis/redis/, accessed September 16, 2023 Google
    Scholar Cited by (0) View Abstract © 2023 Elsevier B.V. All rights reserved. Recommended
    articles Edge AI for Internet of Energy: Challenges and perspectives Internet
    of Things, Volume 25, 2024, Article 101035 Yassine Himeur, …, Abbes Amira View
    PDF LoRaWAN end device disaggregation and decomposition by means of lightweight
    virtualization Internet of Things, Volume 25, 2024, Article 101033 Emiliano Sisinni,
    …, Paolo Ferrari View PDF A statistical Markov-based password strength meter Internet
    of Things, Volume 25, 2024, Article 101057 Binh Le Thanh Thai, Hidema Tanaka View
    PDF Show 3 more articles Article Metrics Captures Readers: 5 View details About
    ScienceDirect Remote access Shopping cart Advertise Contact and support Terms
    and conditions Privacy policy Cookies are used by this site. Cookie settings |
    Your Privacy Choices All content on this site: Copyright © 2024 Elsevier B.V.,
    its licensors, and contributors. All rights are reserved, including those for
    text and data mining, AI training, and similar technologies. For all open access
    content, the Creative Commons licensing terms apply."'
  inline_citation: '>'
  journal: Internet of Things (Netherlands)
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: 'Cocv: A compression algorithm for time-series data with continuous constant
    values in IoT-based monitoring systems'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Jayamala R.
  - Oliver A.S.
  - Jayanthi J.
  - Nithya N.
  citation_count: '0'
  description: Wireless Sensor Networks (WSN) track and record environmental changes
    using sensor nodes. When designing sensors, consider antenna type, components,
    memory, lifespan, security, computing power, communication protocol, energy consumption,
    etc. Wireless sensor networks (WSN) are ad hoc. This network links tiny sensor
    nodes that share few resources (both severely constrained at the node level).
    This paper proposed a Secure and Fast Real-Time (SFRT) Routing Protocol, which
    is used to secure real-time data transmissions in WSN. The proposed method not
    only increases the reliability of WSN but also offers a more robust solution in
    case a sensor node link fails. Discarding packets, launching a denial-of-service
    attack, using black holes, launching a selective forwarding attack, and flooding
    the network with hello packets are some proposed security measures. It maintains
    high packet throughput in the presence of malicious nodes while using little energy.
    Simulations have helped examine recommended safety measures. The unique approach
    outperformed state-of-the-art methods in the NS2 simulation in all relevant metrics,
    including network longevity, packet delivery rate, energy efficiency, network
    throughput, and end-to-end delivery latency. Most current methods necessitate
    multiple retransmissions before success is declared, increasing data transmission
    costs by 5% compared to the best approach. The proposed method is highlighted
    for its ability to increase network lifetime by 20% and reduce the total delay
    by 30%.
  doi: 10.17559/TV-20230617000742
  full_citation: '>'
  full_text: '>

    "english Prijava i registracija  Početna O Hrčku Časopisi Za uredništva Za autore
    Tehnički vjesnik, Vol. 31 No. 2, 2024. Izvorni znanstveni članak https://doi.org/10.17559/TV-20230617000742
    Enhanced Secured and Real-Time Data Transmissions in Wireless Sensor Networks
    using SFRT Routing Protocol R. Jayamala ; Department of Computer Science and Engineering,
    University College of Engineering (BIT Campus), Anna University Trichirappalli
    A. Sheryl Oliver ; Department of Computational Intelligence, SRM Institute of
    Science and Technology, Chennai J. Jayanthi ; Department of Computer Science and
    Engineering, Sona College of Technology, Salem Nithya N. ; Department of CSE,
    K. Ramakrishnan College of Engineering Puni tekst: engleski pdf 1.241 Kb str.
    420-425 preuzimanja: 0 citiraj Sažetak Wireless Sensor Networks (WSN) track and
    record environmental changes using sensor nodes. When designing sensors, consider
    antenna type, components, memory, lifespan, security, computing power, communication
    protocol, energy consumption, etc. Wireless sensor networks (WSN) are ad hoc.
    This network links tiny sensor nodes that share few resources (both severely constrained
    at the node level). This paper proposed a Secure and Fast Real-Time (SFRT) Routing
    Protocol, which is used to secure real-time data transmissions in WSN. The proposed
    method not only increases the reliability of WSN but also offers a more robust
    solution in case a sensor node link fails. Discarding packets, launching a denial-of-service
    attack, using black holes, launching a selective forwarding attack, and flooding
    the network with hello packets are some proposed security measures. It maintains
    high packet throughput in the presence of malicious nodes while using little energy.
    Simulations have helped examine recommended safety measures. The unique approach
    outperformed state-of-the-art methods in the NS2 simulation in all relevant metrics,
    including network longevity, packet delivery rate, energy efficiency, network
    throughput, and end-to-end delivery latency. Most current methods necessitate
    multiple retransmissions before success is declared, increasing data transmission
    costs by 5% compared to the best approach. The proposed method is highlighted
    for its ability to increase network lifetime by 20% and reduce the total delay
    by 30%. Ključne riječi end-to-end delay; packet delivery; secure and fast real-time
    routing protocol; security; throughput; wireless sensor networks Hrčak ID: 314830
    URI https://hrcak.srce.hr/314830 Datum izdavanja: 29.2.2024. Posjeta: 0 * 2021
    © Portal hrvatskih znanstvenih i stručnih časopisa - Hrčak Izjava o pristupačnosti
    | Politika privatnosti | Kontakt accessibility"'
  inline_citation: '>'
  journal: Tehnicki Vjesnik
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Enhanced Secured and Real-Time Data Transmissions in Wireless Sensor Networks
    using SFRT Routing Protocol
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Baskaran T.S.
  - Veeraprakashkumar C.
  citation_count: '0'
  description: Healthcare is a critical sector where timely and accurate predictions
    can save lives and improve the quality of care. Traditional healthcare systems
    often lack the ability to process vast amounts of patient data efficiently. To
    address this, IoT technology is harnessed for seamless data collection and integration,
    facilitating real-time updates to a central database. The challenge lies in harnessing
    this data effectively to predict health conditions. The diversity of patient data,
    including Medical IDs, pulse rates, medical reports, and symptoms, requires sophisticated
    algorithms to extract meaningful insights. Moreover, the accuracy and reliability
    of predictions are vital to ensure patient safety. This paper presents the design
    of an Internet of Things (IoT)-based healthcare prediction system utilizing the
    Normalized Patch Generative Adversarial Network (NP-GAN) based Fruit Fly Optimization
    (FFO) algorithm. The proposed system aims to predict health conditions based on
    patient data, including Medical ID, pulse rate, medical reports, and symptoms.
    Through seamless integration of IoT technologies and AI algorithms, the system
    enables real-time monitoring and predictive analysis, enhancing patient care and
    medical decision-making. The system collects patient data including Medical ID,
    pulse rate measurements, medical reports, and reported symptoms. IoT devices facilitate
    real-time data transmission to the central database. Raw data undergoes preprocessing,
    including normalization and sequence alignment. Textual medical reports are transformed
    into numerical vectors using techniques like word embeddings. Features such as
    pulse rate trends, symptom sequences, and medical report patterns are extracted
    from the preprocessed data, providing valuable insights for prediction using NP-GAN.
    The RCNN algorithm, combining recurrent and convolutional layers, is employed
    for its ability to capture temporal dependencies and spatial patterns in data.
    The network learns to associate pulse rate trends, symptoms, and medical information
    for accurate predictions. The RCNN model is trained using historical patient data
    and validated using FFO to optimize hyperparameters and prevent overfitting. Real-time
    patient data is continuously fed into the trained RCNN-FFO model, which predicts
    potential health issues. Alerts are generated for medical professionals if anomalies
    or concerning patterns are detected. The system performance is assessed using
    metrics like accuracy, precision, recall, and F1-score. Continuous feedback and
    retraining improve prediction accuracy over time.
  doi: null
  full_citation: '>'
  full_text: '>'
  inline_citation: '>'
  journal: International Journal of Intelligent Systems and Applications in Engineering
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Design of IoT-Based Wearables for Health Care Prediction Using Normalized-Patch
    Gan Based Fruit Fly Optimization
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Fu W.
  - Peng Q.
  - Hu C.
  citation_count: '0'
  description: In high-speed railway operational monitoring network systems targeting
    railway infrastructure as its monitoring objective, there is a wide variety of
    sensor types with diverse operational requirements. These systems have varying
    demands on data transmission latency and network lifespan. Most of the previous
    research focuses only on prolonging network lifetime or reducing data transmission
    delays when designing or optimizing routing protocols, without co-designing the
    two. In addition, due to the harsh operating environment of high-speed railways,
    when the network changes dynamically, the traditional routing algorithm generates
    unnecessary redesigns and leads to high overhead. Based on the actual needs of
    high-speed railway operation environment monitoring, this paper proposes a novel
    Double Q-values adaptive model combined with the existing reinforcement learning
    method, which considers the energy balance of the network and real-time data transmission,
    and constructs energy saving and delay. The two-dimensional reward avoids the
    extra overhead of maintaining a global routing table while capturing network dynamics.
    In addition, the adaptive weight coefficient is used to ensure the adaptability
    of the model to each business of the high-speed railway operation environment
    monitoring system. Finally, simulations and performance evaluations are carried
    out and compared with previous studies. The results show that the proposed routing
    algorithm extends the network lifecycle by 33% compared to the comparison algorithm
    and achieves good real-time data performance. It also saves energy and has fewer
    delays than the other three routing protocols in different situations.
  doi: 10.3390/s23177393
  full_citation: '>'
  full_text: '>

    "This website uses cookies We use cookies to personalise content and ads, to provide
    social media features and to analyse our traffic. We also share information about
    your use of our site with our social media, advertising and analytics partners
    who may combine it with other information that you’ve provided to them or that
    they’ve collected from your use of their services. Consent Selection Necessary
    Preferences Statistics Marketing Show details                 Deny Allow selection
    Allow all     Journals Topics Information Author Services Initiatives About Sign
    In / Sign Up Submit   Search for Articles: Sensors All Article Types Advanced   Journals
    Sensors Volume 23 Issue 17 10.3390/s23177393 Submit to this Journal Review for
    this Journal Propose a Special Issue Article Menu Academic Editors Anabela Oliveira
    Goncalo Jesus Subscribe SciFeed Recommended Articles Related Info Links More by
    Authors Links Article Views 770 Table of Contents Abstract Introduction Motiviation
    System Profile and Overall Scheme Model and Methodology of the Adaptive Protocol
    Performance Comparison and Validation Conclusions Author Contributions Funding
    Data Availability Statement Acknowledgments Conflicts of Interest References share
    Share announcement Help format_quote Cite question_answer Discuss in SciProfiles
    thumb_up Endorse textsms Comment first_page settings Order Article Reprints Open
    AccessArticle Energy-Saving Adaptive Routing for High-Speed Railway Monitoring
    Network Based on Improved Q Learning by Wei Fu *, Qin Peng and Canwei Hu Key Laboratory
    of Industrial Internet of Things and Network Control, Ministry of Education, Chongqing
    University of Posts and Telecommunications, Chongqing 400065, China * Author to
    whom correspondence should be addressed. Sensors 2023, 23(17), 7393; https://doi.org/10.3390/s23177393
    Submission received: 13 July 2023 / Revised: 13 August 2023 / Accepted: 21 August
    2023 / Published: 24 August 2023 (This article belongs to the Special Issue IoT
    and Wireless Sensor Network in Environmental Monitoring Systems) Download keyboard_arrow_down     Browse
    Figures Review Reports Versions Notes Abstract In high-speed railway operational
    monitoring network systems targeting railway infrastructure as its monitoring
    objective, there is a wide variety of sensor types with diverse operational requirements.
    These systems have varying demands on data transmission latency and network lifespan.
    Most of the previous research focuses only on prolonging network lifetime or reducing
    data transmission delays when designing or optimizing routing protocols, without
    co-designing the two. In addition, due to the harsh operating environment of high-speed
    railways, when the network changes dynamically, the traditional routing algorithm
    generates unnecessary redesigns and leads to high overhead. Based on the actual
    needs of high-speed railway operation environment monitoring, this paper proposes
    a novel Double Q-values adaptive model combined with the existing reinforcement
    learning method, which considers the energy balance of the network and real-time
    data transmission, and constructs energy saving and delay. The two-dimensional
    reward avoids the extra overhead of maintaining a global routing table while capturing
    network dynamics. In addition, the adaptive weight coefficient is used to ensure
    the adaptability of the model to each business of the high-speed railway operation
    environment monitoring system. Finally, simulations and performance evaluations
    are carried out and compared with previous studies. The results show that the
    proposed routing algorithm extends the network lifecycle by 33% compared to the
    comparison algorithm and achieves good real-time data performance. It also saves
    energy and has fewer delays than the other three routing protocols in different
    situations. Keywords: high-speed rail; wireless monitoring system; routing; Q-learning;
    lifetime; latency 1. Introduction With the rapid development of high-speed railway
    (HSR) networks, higher requirements have been placed on the safety and stability
    of high-speed trains, and the train operating environment is directly related
    to the safety of high-speed trains in transit. Ways to quickly find and solve
    basic faults is the focus of HSR systems around the world, and high-speed train
    operation environment monitoring is an important guarantee for railway safety
    operations [1]. The safety of high-speed railway systems can be significantly
    improved through real-time monitoring and inspection. The high-speed railway operation
    environment monitoring system includes the railway infrastructure monitoring system,
    the high-speed railway natural disaster and foreign body intrusion monitoring
    system, the EMU on-board dynamic monitoring system, and the EMU operation and
    maintenance management system. At present, the wired communication network adopted
    by these monitoring systems has been verified to be stable and reliable [2,3].
    However, the high-speed railway operating environment is complex, and the high
    cost of wired network is not conducive to large-scale deployment of the global
    high-speed railway monitoring system, and the complex terrain is inconvenient
    for wired network maintenance [4,5,6,7]. The development and maturity of wireless
    sensor network technology provides more efficient and reliable, low-cost, easy-to-implement
    and maintain, high-tech means for the field of high-speed train operation environment
    monitoring. The use of wireless systems to monitor the operating environment of
    high-speed railways can realize large-scale deployment along the railway, ensure
    the breadth and accuracy of data collection, and monitor the condition of slopes,
    tunnels, roadbeds, bridges, and other facilities, which can effectively meet the
    needs of high-speed trains. The need for comprehensive monitoring of the operating
    environment reduces the cost of train operating environment testing and is suitable
    for large-scale deployment and long-term online monitoring in key areas and remote
    areas along the high-speed railway. However, the energy resources of wireless
    devices are strictly limited. The greatest challenge in wireless sensor networks
    is determining a way to conserve energy, and the amount of time that the network
    lasts is a good measure of teh quality of its performance [8,9]. In order to ensure
    the real-time performance of high-speed railway operating environment monitoring
    information and the energy utilization efficiency of the network system, a protocol
    that adapts to the characteristics of the high-speed railway operating environment
    monitoring network is needed to efficiently utilize the limited energy resources
    of the network system and provide more long-term energy efficiency [10]. The increase
    in communication distance increases the energy consumption of some nodes and shortens
    the network life. Each protocol chooses to increase the number of forwarding hops
    to achieve a balance of energy consumption, and the overall energy consumption
    is evenly distributed to more nodes to avoid premature death of some nodes. But
    the increase in hop count inevitably increases the delay of information transmission,
    which is bad news for the high-speed railway monitoring network [11,12]. In fact,
    it is difficult to guarantee the real-time performance of the network and its
    maximum lifespan at the same time. Extending the lifespan and increasing the number
    of hops results in a large delay and affects the service quality of the monitoring
    network. To this end, in the intelligent high-speed railway monitoring system.
    The information in the network can be divided into several parts: receiving, transmitting,
    processing, state evaluation and prediction, and control decision-making. Generally
    speaking, the transmission of data along the shortest path can minimize the energy
    consumption of the network, but this approach introduces the problem of unbalanced
    energy consumption. The energy consumption of the sensor device closer to the
    sink node is faster, which is the so-called energy hole phenomenon [13,14,15].
    This phenomenon destroys the balance of energy consumption among nodes, affects
    the life of the network, and also has a negative impact on the real-time performance
    of data transmission, hindering the normal service of the network system. Therefore,
    in addition to minimizing the network energy consumption, the energy consumption
    balance among network nodes should also be considered when designing the routing
    algorithm to extend the life of the network system. Therefore, when designing
    a routing protocol for a high-speed railway operation environment monitoring network,
    it is necessary to minimize and balance network energy consumption while reducing
    data transmission delay so as to improve real-time performance and network energy
    utilization, and prolong network service life. Therefore, the goal of this paper
    is to look into ways in which a high-speed railway operation environment monitoring
    network can use an adaptive routing method to meet the needs of different services
    [16,17]. Table 1 introduces some typical existing studies and evaluates them in
    terms of optimization goals, adoption methods, network structures, and advantages
    and disadvantages. Most of the research is aimed at improving the lifetime of
    network systems, and the strategies to maximize network lifetime can be divided
    into deployment optimization, data processing, and protocol design. Among them,
    routing protocol design optimization is a more effective and widely used strategy,
    and protocol design can be divided into single-hop, multi-hop, and clustering
    methods. However, for a typical linear network such as a high-speed railway operating
    environment monitoring network, it is obviously more appropriate to use a multi-hop
    routing protocol. In some studies, the network lifetime is extended by minimizing
    the total network energy consumption (MTECR). However, its shortcomings are also
    obvious. As mentioned above, the problem of unbalanced network energy consumption
    while minimizing energy consumption leads to network energy holes, resulting in
    the premature death of some nodes, which affects the service life of the network.
    In addition, some other research focuses on balancing the energy consumption of
    nodes in the network, such as MVECR and AUMRP, and proves that their balancing
    scheme based on the residual energy of nodes is more effective for prolonging
    the network lifetime. Table 1. Existing methods and their characteristics. To
    the best of our knowledge, there are few studies on the co-optimization of lifetime
    and delay for high-speed railway operational environmental monitoring networks.
    Traditional routing algorithms cannot ensure stable transmission services in dynamic
    environments because they cannot cope with network dynamics and voids. The maintaining
    of global routing information incurs great overhead, and the complex structure
    also reduces the efficiency of the current high-speed railway linear monitoring
    network. These issues are addressed in this article. 2. Motiviation Power supply
    and grid maintenance for high-speed rail operating lines are very difficult. With
    the development and maturity of wireless sensor network technology, high-speed
    train operation provides more efficient, reliable, and low-cost solutions in the
    field of environmental monitoring and detection, and then implements high-tech
    manual maintenance. Experts have conducted a lot of in-depth research on the coordination
    of the routes of the plane network, but less on the coordination of the high-speed
    railway network. If there is a general problem with the existing routing protocols,
    it is their lack of applicability to monitoring regional environments. There are
    many types of sensors in high-speed rail systems. Various sensors vary widely
    in terms of latency, transfer rate, data volume, etc. Inspired by the above requirements
    and the existing work, this paper proposes a heterogeneous network data aggregation
    model and adaptive routing algorithm for high-speed railway monitoring network
    based on reinforcement learning. The overall framework of the backbone routing
    communication protocol for high-speed railway state monitoring wireless sensor
    network is depicted in Figure 1, consisting of four components: Figure 1. Overall
    scheme of adaptive routing protocol for high-speed railway monitoring network
    based on reinforcement learning. Communication structure and data feature analysis,
    encompassing the analysis of node energy information, monitoring device characteristics,
    monitoring functional requirements, and data features; Analysis of monitoring
    targets and requirements, including aspects such as operational environment, track
    service status, and OCS (Overhead Catenary System) system status; Aggregation
    strategy and intelligent routing modeling, constructing an adaptive multi-objective
    optimization model based on the lifecycle and transmission delay requirements
    of different network objects; Adaptive routing algorithm, developing separate
    lifecycle and real-time evaluation models for monitoring tasks, dynamically adjusting
    multi-hop transmission paths to ensure the network fulfills both lifecycle and
    real-time requirements for various tasks simultaneously. The main contributions
    of this paper can be summarized as follows: A lossless data aggregation transmission
    model for HSR networks is proposed, which can effectively reduce the amount of
    data in the network and reduce the energy consumption of data transmission; A
    Double-Q-value model based on data aggregation is proposed. Forn the two Q values,
    we consider the data aggregation degree, the remaining energy level, the link
    strength, the distance from the node to the sink, and the forwarding delay to
    consider the network lifetime and the real-time performance of data forwarding.
    The defined reward function can capture the dynamic changes in the network in
    real time and achieve dynamic control of the entire network with less overhead;
    An adaptive energy-saving routing algorithm based on Double-Q-values is proposed
    to classify HSR network devices according to their real-time requirements and
    life cycle requirements. An adaptive control algorithm is adopted for different
    business priorities. It meets the real-time requirements of the HSR network and
    prolongs the network’s life and improves service quality. The work arrangement
    of this paper is as follows. Section 3 presents the typical structure of the high-speed
    railway monitoring network as well as the analysis of node requirements and introduces
    the data aggregation scheme. Section 4 describes in detail the proposed demand-aware
    energy-saving routing algorithm based on Q-learning. Section 5 discusses and analyzes
    the performance metrics of the proposed routing protocol through simulation experiments.
    The conclusions are summarized in Section 6. 3. System Profile and Overall Scheme
    The system involved in this paper consists of the following four parts: Structure
    and characteristics of communication; Keeping track of objects and requirements;
    Policy of aggregation and intelligent routing design; Algorithm for adaptive routing.
    3.1. Communication Structure and Characteristics The high-speed train operating
    environmental monitoring system based on the wireless sensor network is simply
    called HSR-N, which is used for the completion, replenishment, or replacement
    of the transmission high-speed train operating environmental monitoring system.
    The proposed wireless sensor network can be roughly considered a linear network.
    In HSR-N, its monitoring areas are wide and varied, and different monitoring targets
    have great differences. Therefore, relevant parameters and network technologies
    need to be designed for specific monitoring targets. With limited network energy,
    HSR-N needs an energy-efficient transmission protocol that meets its requirements.
    3.2. Monitoring Objects and Requirements The monitoring objects of the railway
    infrastructure monitoring system mainly include bridges, tunnels, roadbeds, contact
    networks, and rails. Obviously, different infrastructures have different monitoring
    challenges and requirements. For instance, in the health monitoring of bridges,
    the system needs to use high-precision sensors to monitor bridge structural cracks,
    deformations, and other conditions. Due to the non-maintainable nature of the
    internal structure of bridges, this requires bridge monitoring sensors to have
    a longer lifespan, with maintenance intervals preferably on a monthly basis. On
    the other hand, due to the slow changes in bridge structures, monitoring data
    does not require real-time updates. Therefore, bridge monitoring sensors have
    lower real-time requirements. Similar to bridges, rails, roadbeds, and tunnels
    have similar monitoring requirements, but their maintenance is relatively easier.
    Therefore, the lifespan requirements for sensors for the latter three are not
    as strict as those for bridges. Monitoring the contact network requires the use
    of temperature or strain sensors. Since the contact network is a vital component
    of the railway electrification system and directly affects train safety, sensors
    of this kind need to upload monitoring data promptly and have higher real-time
    requirements. Based on practical project experience, this article categorizes
    the lifecycle requirements of monitoring equipment with maintenance cycles of
    one day, one week, and more than one month into three levels: low, medium, and
    high. Similarly, the real-time requirements of monitoring equipment with data
    sending frequencies higher than once every 10 min, between 10 min and 1 h, and
    more than 1 h are divided into three levels: high, medium, and low. Some monitoring
    objects and their corresponding characteristics are shown in Table 2. The real-time
    requirements and life cycle requirements of monitoring objects are different.
    We conduct a brief evaluation of their different functional requirements to provide
    support for the following work. The evaluation is mainly allocated based on the
    urgency of the data and the amount of data. For data types with high real-time
    requirements, we provide higher real-time evaluation to reduce delay; for periodic
    data with low real-time requirements, we base our calculations on the way the
    data are set up; the aggregation processing is designed to provide the network
    with a longer life cycle [26,27,28]. Table 2. Monitoring objects and characteristics.
    3.3. Aggregation Policy and Intelligent Routing Design For most of the monitoring
    requirements of chronic changes, we only need to collect their data periodically
    and analyze it, while some monitoring requires only a large number of repeated
    measurements as the train passes by. For these data with low real-time requirements,
    we consider data aggregation on the transmission path to reduce the transmission
    burden of nodes to achieve the purpose of saving energy and prolonging the network
    life cycle. A lossless data aggregation model is adopted in this study. This means
    that the original data can be reconstructed by the sink node from the received
    aggregated data packets without any damage or loss of data. The data aggregation
    model is expressed as follows: 𝐷𝐴{ 𝑄 𝑡 𝑖 (𝑛)}={ 𝑈 𝑡 𝑚 × log 2 (𝐷 𝑃 𝑖 (𝑛)+1) 0
    𝑖 𝑓 0<𝐷 𝑃 𝑖 (𝑛) 𝑖 𝑓 𝐷 𝑃 𝑖 (𝑛)=0. (1) The data aggregation model is defined in
    this paper. The data buffer area of each sensor is partitioned, and each sensor
    maintains storage areas of multiple data types. For the same type of data, when
    the real-time requirement is low, the sensor performs data aggregation before
    forwarding to optimize the data volume. When a packet of data type t is transmitted
    in the network, each node transmits to the next hop after the interval  𝑆 𝐼 𝑡
    . Obviously, the longer the waiting time for data aggregation, the greater the
    delay for the data packet to reach the sink node. It can be seen from Table 2
    that different types of sensors have different real-time requirements for data.
    Therefore, in the design of routing protocols, the real-time requirements of different
    nodes need to be considered when energy-saving design is carried out [29,30].
    This is explained in Section 4. The aggregation process design is shown in Figure
    2 and model parameters are listed in Table 3. Figure 2. Data aggregation transmission
    model. Table 3. Aggregation model parameters. If the sensor node  𝑆 𝑖 is the next
    hop selected by  𝑆 𝑗 , 𝑆 𝑘 , and  𝑆 𝑙 , the  𝑡1 -type aggregated data packets  AD
    𝑡1 j (𝑛) from the node  𝑆 𝑗 and the  𝑡1 -aggregated data packets  AD 𝑡1 k (𝑛)
    of the  𝑆 𝑘 node are stored together with the  𝑡1 data packets  OD 𝑡1 i (𝑛) observed
    by the  𝑆 𝑖 node from the surrounding environment. After aggregating into data
    packets  AD 𝑡1 i (𝑛) in the  𝑡1 data type queue  Q 𝑡1 i (𝑛) of node  𝑆 𝑖 , they
    are sent to the next hop node  𝑆 𝑝 of the  𝑡1 type. Similarly, the  𝑡2 type data
    packets  AD 𝑡 k 2(𝑛) from nodes  𝑆 𝑘 and  𝑆 𝑙 ,  AD 𝑡2 l (𝑛) is in the  𝑡2 data
    of node  𝑆 𝑖 . The data packets  AD 𝑡2 i (𝑛) are aggregated in the type queue  Q
    𝑡2 i (𝑛) and sent to the next-hop node  𝑆 𝑞 of type  𝑡2 . After this aggregation
    process, the data of the same type is first aggregated and sent to the next-hop
    node with the same data type until the data packet is sent to the sink node to
    complete the aggregation and transmission of the data. 3.4. Adaptive Routing Algorithm
    In the aggregation model described in Section 3.3, the aggregated data of each
    sensor node are sent to the optimal next-hop node, and the next-hop node selection
    is determined by the Q-learning adaptive algorithm proposed in this paper (see
    Section 4). The adaptive routing algorithm consists of three parts: (1) The sending
    node selects the node with the highest priority in the Q routing table to send
    the data packet; (2) The receiving node feeds back the reward value information
    to the sending node according to the received data packet; (3) The sending node
    accepts the reward value information and updates its Q routing table. 4. Model
    and Methodology of the Adaptive Protocol Q-learning is a model-free reinforcement
    learning algorithm whose core is the Q-value and reward [31]. In order to maximize
    the network life cycle and meet the functional requirements of various types of
    sensors, this section presents an adaptive communication routing algorithm based
    on improved Q-learning, as shown in Figure 3. Figure 3. Double-Q-value adaptive
    algorithm framework. The algorithm first defines dual Q-values using energy balance
    and real-time data transmission as metrics. It then introduces an adaptive weighting
    factor to optimize the design based on the requirements of the business. Next,
    it constructs reward models for energy saving and latency, and finally updates
    the Q-values based on the rewarded data [32]. The parameters and definitions used
    in this section are shown in Table 4. Table 4. Protocol parameters and definitions.
    4.1. Energy Model Nodes adopt a periodic sleep/active work mode. The main energy
    consumption of nodes can be divided into two parts: Energy consumption in an active
    mode. We use  𝜔 𝑎 , which denotes the energy consumption rate in this mode. Energy
    consumption when nodes send and receive data. We adopt the typical WSN energy
    consumption model to calculate the energy consumption of sending, receiving, and
    aggregated data, which is given by Equations (2)–(4), respectively. 𝐸 𝑇 (𝑙)={
    𝑙× 𝐸 𝑒𝑙𝑒𝑐 +𝑙× 𝜀 𝑓𝑠 × 𝑑 2 ,𝑑< 𝑑 0 , 𝑙× 𝐸 𝑒𝑙𝑒𝑐 +𝑙× 𝜀 𝑚𝑝 × 𝑑 4 ,𝑑≥ 𝑑 0 , (2) 𝐸 𝑅
    (𝑙)=𝑙× 𝐸 𝑒𝑙𝑒𝑐 , (3) 𝐸 𝐷 (𝑙)=𝑙× 𝐸 𝑒𝑐 , (4) where  𝐸 𝑒𝑙𝑒𝑐 represents the node’s
    energy consumption when sending, and  𝑑 0 represents the distance between nodes.
    When  𝑑< 𝑑 0 , the node energy consumption is in the normal loss mode; when  𝑑>
    𝑑 0 , the node energy consumption is gradually reduced;  𝜀 𝑓𝑠 and  𝜀 𝑎𝑚𝑝 represent
    the energy at different distances;  𝐸 𝑒𝑐  is the energy expended for computation;
    l is the length of the data frame. 4.2. Double-Q-Value Learning Model The Q-learning
    algorithm is a value function-based algorithm in RL, and for any finite Markov
    decision process, Q-learning can find an optimal policy. Q-learning involves an
    agent, a set of states S, and a set of actions A. By performing actions in the
    environment that cause the agent to move from one state to another, the action
    in a particular state is rewarded. That is,  𝑄(𝑠,𝑎)  is the expected reward for
    performing action a( 𝑎𝑖𝑛𝐴 ) in state s( 𝑠𝑖𝑛𝑆 ) at a given time [33]. The algorithm
    used in this study is shown in Figure 4. Figure 4. Application of double-Q-learning
    algorithm in transmission between nodes. 4.3. Figures, Tables and Schemes 4.3.1.
    State and Action In the proposed double-Q-value learning model for high-speed
    railway wireless monitoring network routing, adjacent nodes exchange routing information
    in a cooperative way to ensure that nodes in the network can dynamically follow
    network changes and reduce the burden of maintaining the global routing table
    [34]. We define a sensor node’s node set S, action  𝑎𝑖𝑛𝐴 , and action state set
    A as follows when it sends a specific type of data to the next hop node: 𝑆={ 𝑠
    1 , 𝑠 2 ,···, 𝑠 𝑛 }, 𝐴={ 𝐴 1 , 𝐴 2 ,···, 𝐴 𝑛 }, 𝐴 𝑖 ={ 𝑎 𝑗 = 𝑠 𝑗 | 𝑠 𝑗 ∈ 𝐹 𝑠𝑖
    }, (5) where n is node number and  𝐹 𝑠𝑖  is the set of forwarding nodes of node  𝑠
    𝑖 . 4.3.2. Initialization of the Double-Q-Values In Q-learning, the forwarding
    of data between nodes uses a Q-table to find the best action, where the Q-value
    is the expectation of nodes when forwarding [35]. In the double Q-value model
    designed in this paper, the action value functions are divided into life cycle
    functions and real-time functions  𝑄 𝐿  and  𝑄 𝑇 .  𝑄 𝐿  consists of three parts:
    data aggregation degree, node energy status, and link strength. The first part
    aims to increase the aggregability of forwarded data packets and reduce the data
    size to reduce the energy loss caused by data transmission. The second part avoids
    selecting energy. Nodes with low values are forwarded, and the third part aims
    to reduce communication overhead and save energy.  𝑄 𝑇  consists of two parts:
    the number of hops reaching the sink node and the forwarding delay estimation,
    both of which aim to ensure the real-time performance of the data packet reaching
    the sink node. As shown in (6), double-Q-values are initialized as a weighted
    sum of the probabilities of their respective parts. 𝑄 𝐿 (𝑠,𝑎)=𝐷𝐴(𝑠,𝑎)+ 𝐸 𝑎 𝑠 +
    𝐿 𝑎 𝑠 , 𝑄 𝑇 (𝑠,𝑎)=𝑑(𝑎,sin𝑘)+ 𝑇 𝑎 𝑠 , (6) where  𝐷𝐴(𝑠,𝑎)  denotes the degree to
    which node s aggregates data to the node indicated by its action a;  𝐸 𝑎 𝑠  is
    the remaining energy of the node pointed to by action a. The link strength between
    node s and the node pointed to by action a is represented by  𝐿 𝑠 𝑎 .  𝑑(𝑎,𝑠𝑖𝑛𝑘)  is
    the distance between the node indicated by action a and the sink.  𝑇 𝑎 𝑠  is forwarding
    time from node s to the node pointed to by its action a. Before starting, the
    Q-values are initialized only by the initial energy and the distance to the sink,
    and other parameters are updated after running. 4.3.3. Double Q-Value Update In
    this paper,  𝑄 𝐿,𝑇 (𝑠,𝑎)  defines the possibility of state s acting a and provides
    various types of businesses with a Q-table based on their business requirements,
    which is defined as follows: 𝑄 𝐿,𝑇 (𝑠,𝑎)= ⎡ ⎣ ⎢ ⎢ ⎢ ⎢ ⎢ 𝑄 𝑡1 𝐿,𝑇 (𝑠,𝑎) 𝑄 𝑡2 𝐿,𝑇
    (𝑠,𝑎) ⋮ 𝑄 𝑡𝑛 𝐿,𝑇 (𝑠,𝑎) ⎤ ⎦ ⎥ ⎥ ⎥ ⎥ ⎥ . (7) Among them,  𝑡 1 − 𝑡 𝑛  is the business
    type,  𝑄 𝐿  is the life cycle measurement of an action, and  𝑄 𝑇  is the real-time
    measurement of an action. When a node selects the optimal next hop in its Q-table
    to send a packet, it obtains a reward from the receiving node and updates its
    Q-value accordingly. The new Q-value is (8), 𝑄 𝐿,𝑇 (𝑠,𝑎)=𝑄(𝑠,𝑎)+𝛼{ 𝑅 L,𝑇 −𝛾·𝑄(𝑠,𝑎)},
    (8) where  𝛼  is the learning rate and  𝛾  is the discount factor for the future
    reward. 4.3.4. Explore Strategies Usually, action selection relies only on the
    highest Q value, but this fixed selection can become stuck in a local optimum.
    To achieve this, we use an epsilon-greedy algorithm that makes it possible to
    escape local optima with partial probability. 𝑎 ∗ |s={ argmax𝑄(𝑠,𝑎) 𝑎𝑛𝑦𝑎𝑐𝑡𝑖𝑜𝑛𝑎
    𝑤𝑖𝑡ℎ𝑝𝑟𝑜𝑏𝑎𝑏𝑙𝑖𝑡𝑦1−𝜖 𝑤𝑖𝑡ℎ𝑝𝑟𝑜𝑏𝑎𝑏𝑙𝑖𝑡𝑦𝜖 . (9) 4.3.5. Future Rewards In this stage, rewards
    are given for the action performed in the previous step, which can be divided
    into three situations. (1) The node receiving data packets is not the sink node,
    and the energy level is normal. We assign each component of double-Q-values its
    own reward scheme, calculated as follows: 𝐷 𝐴 𝑛𝑜𝑟 = ⎧ ⎩ ⎨       𝑄 𝑡 𝑠 ′
    (𝑛) 𝐴 𝐷 𝑡 𝑠 ′ (𝑛) −1 𝑟 max 𝐷𝐴 𝑖𝑓 𝑄 𝑡 𝑠 ′ (𝑛) 𝐴 𝐷 𝑡 𝑠 ′ (𝑛) −1< 𝑟 max 𝐷𝐴 𝑒𝑙𝑠𝑒 𝑄
    𝑡 𝑠 ′ (𝑛) 𝐴 𝐷 𝑡 𝑠 ′ (𝑛) −1> 𝑟 max 𝐷𝐴 , (10) 𝐸 𝑛𝑜𝑟 = 𝐸 𝑠 ′ 𝑟 / 𝐸 𝑠 ′ 𝑖 , (11) 𝐿
    𝑠 ( 𝑠 𝑖 , 𝑠 𝑗 )= Re 𝑐 𝑠 𝑖 𝑝 Re 𝑐 𝑠 𝑗 𝑜𝑏 , Re 𝑐 𝑠 𝑗 𝑜𝑏 = ⌈ 𝑝 𝑟 (𝑑) 𝑝 𝑟 ( 𝑑 0 )
    ⌉ 𝑑𝑏 =−10𝜌log( 𝑑 𝑑 0 )+ 𝑋 𝑑𝑏 , 𝐿 𝑛𝑜𝑟 = 𝑙 𝑠 (𝑠, 𝑠 ′ ), (12) 𝑟𝑎𝑑𝑣=𝑑(𝑠,𝑠𝑖𝑛𝑘)−𝑑( 𝑠
    ′ ,𝑠𝑖𝑛𝑘), 𝑟𝑎𝑑 𝑣 𝑎𝑣𝑔 = ∑ 𝑛 𝑖=1 |𝑟𝑎𝑑 𝑣 𝑖 |/𝑛, 𝐴 𝑛𝑜𝑟 =𝑟𝑎𝑑𝑣/𝑟𝑎𝑑 𝑣 𝑎𝑣𝑔 . (13) 𝑇 𝑛𝑜𝑟
    =𝑇(𝑠, 𝑠 ′ )/ 𝑇 𝑎𝑣𝑔 (14) (2) The receiving node is  𝑠𝑖𝑛𝑘 . The reward is a constant  𝑅
    𝑠  when the chosen action sends the data packet to the sink node. 𝑅= 𝑅 𝑠 . (15)
    (3) The receiving node is not sink, and the energy level is lower than the average
    energy of network nodes. In order to maintain the performance and life of the
    network, we suggest not assigning the node the function of forwarding data when
    the energy level is too low to ensure that the basic monitoring service of the
    network is normal [36,37]. Therefore, we offer a negative reward to avoid packets
    from the neighbor nodes. 𝑅=− 𝑅 𝑒 . (16) Based on the above definition, corresponding
    to the double-Q-values, the future reward should also be divided into two parts
    to offer different rewards for its life cycle and real-time performance. At the
    same time, in order to avoid increasing the probability of forwarding to nodes
    far away from the sink, it is necessary to provide a discount value to the reward.
    Rewards  𝑅 𝐿  and  𝑅 𝑇  for state s are calculated as follows: 𝑅 𝐿 = ⎧ ⎩ ⎨  
      𝛼 𝑙 × 𝑅 𝐷𝐴 + 𝛽 𝑙 × 𝑅 𝐸 + 𝛾 𝑙 × 𝑅 𝐿 𝑅 𝑠 − 𝑅 𝑒 𝑠 ′ ≠𝑠𝑖𝑛𝑘 𝑠 ′ =𝑠𝑖𝑛𝑘 𝐸 𝑠 ′ 𝑖𝑠𝑙𝑜𝑤
    , (17) 𝑅 𝑇 = ⎧ ⎩ ⎨     𝛼 𝑡 × 𝑅 𝐴 + 𝛽 𝑡 × 𝑅 𝑇 𝑅 𝑠 − 𝑅 𝑒 𝑠 ′ ≠𝑠𝑖𝑛𝑘 𝑠 ′ =𝑠𝑖𝑛𝑘
    𝐸 𝑠 ′ 𝑖𝑠𝑙𝑜𝑤 . (18) 4.4. Adaptive Routing Protocol Based on Double-Q-Values In
    order to meet different business needs, this section proposes an adaptive weighting
    scheme based on the proposed double-Q-value model and the principles of maximizing
    network lifetime and adaptively meeting the functional requirements of various
    types of sensors, trying to consider both energy saving and delay reduction. Two
    methods are used to adapt to different business objectives. The multi-objective
    function formula is as follows: max𝑄=max( 𝛼 𝑤 × 𝑄 𝐿 +(1− 𝛼 𝑤 )× 𝑄 𝑇 ), (19) where  𝛼
    𝑤  is a business adaptive weighting factor used to adjust the weight of a life
    cycle and real-time goals. As shown in Table 2, different services in the system
    have different requirements for life cycle and real-time performance. When the
    real-time performance requirement of the monitoring object is low, that is, the
    frequency of the device sending data is less than once an hour, it means that
    the object has higher requirements for the continuity of data transmission. The
    adaptive weight factor increases with the improvement of life requirements; and
    when the real-time requirement of the monitored object is high, that is, the frequency
    of the device sending data is higher than once every 10 min, the algorithm assigns
    priority to meeting its real-time requirements. Therefore, the design of the adaptive
    weight factor is as follows: in this formula, low, medium, and high values are
    0.2, 0.5, and 0.8. 𝛼 𝑤 = ⎧ ⎩ ⎨                       log(𝜂×(
    𝐷 𝑠 𝑙 𝐷 𝑠 𝑡 / )) log(𝜂×max( 𝐷 𝑠 𝑙 𝐷 𝑠 𝑡 / )) 0.5×log(𝜂×( 𝐷 𝑠 𝑙 𝐷 𝑠 𝑡 / )) log
    max( 𝐷 𝑠 𝑙 𝐷 𝑠 𝑡 / ) + 0.5×1 1+ 𝑒 ( 𝐷 𝑠 𝑙 − 𝐷 𝑠 𝑡 )× 𝐷 𝑠 𝑡 (𝜉−( 𝐷 𝑠 𝑙 − 𝐷 𝑠 𝑡
    )× 𝐷 𝑠 𝑡 ) 1 1+ 𝑒 ( 𝐷 𝑠 𝑙 − 𝐷 𝑠 𝑡 )× 𝐷 𝑠 𝑡 (𝜉−( 𝐷 𝑠 𝑙 − 𝐷 𝑠 𝑡 )× 𝐷 𝑠 𝑡 ) 𝐷 𝑠 𝑡
    =2 𝐷 𝑠 𝑡 =0.5 𝐷 𝑠 𝑡 =0.8 , (20) where the life cycle demand amplification factor  𝜂  and
    the real-time demand amplification factor  𝜉  are defined as follows: 𝜂= max 𝐷
    𝑠 𝑙 max 𝐷 𝑠 𝑡 0< 𝐷 𝑠 𝑙 <1,0< 𝐷 𝑠 𝑡 <0.5, (21) 𝜉=max( 𝐷 𝑠 𝑡 − 𝐷 𝑠 𝑙 ) 0< 𝐷 𝑠 𝑙
    <1,0.5< 𝐷 𝑠 𝑡 <1. (22) 5. Performance Comparison and Validation In this section,
    we compare and analyze the performance of the proposed Double Q-value Adaptive
    Aggregation Routing Protocol (DQAAR) in terms of energy consumption, network lifetime,
    transmission delay, and data retransmission energy loss. At present, there is
    little research on multi-objective optimization of high-speed railway wireless
    sensor network delay and life cycle. Due to MATLAB’s powerful computational capabilities
    and rich reinforcement learning toolbox, the improved Q-learning algorithm proposed
    in this paper can be easily implemented. Therefore, this paper uses MATLAB R2018b
    to realize the simulation environment and compares it with the other three excellent
    routing protocols [38]. They are MTECR, AUMRP, and MVECR. 5.1. Parameters Configuration
    In this study, the node communication energy consumption adopts the space energy
    loss model, and the simulation parameter configuration is shown in Table 5. Table
    5. Aggregation model parameters. The initial energy of the sensor nodes involved
    in this paper is  0.5𝑗 , and the energy of  𝑠𝑖𝑛𝑘  nodes is unlimited. According
    to the node types and business requirements in Table 1, the network model is constructed
    proportionally to verify the performance of the adaptive routing model in this
    paper. In the comparative analysis before, we introduced a few concepts about
    performance indicators. (1) FND (the time at which the first node dies); (2) HND
    (time when half of the nodes die); (3) CP Index (Comprehensive Performance Index);
    the utility of a high-speed railway monitoring network is determined by its life
    cycle and real-time performance. In this paper, we build a complete evaluation
    model for life cycle and real-time performance: U=𝜆× 𝐿 max(𝐿) +(1−𝜆) min(𝑇) 𝑇
    . (23) In the table, U is the comprehensive performance index, L is the life cycle,
    and T is the delay. 5.2. Results and Discussion In order to verify the effectiveness
    of the adaptive routing protocol proposed in this paper, we first verify the effect
    of extending the network life cycle of each protocol, and then simulate environmental
    changes and different application scenarios by changing some system parameters.
    Several aspects, such as extending the comprehensive efficiency index, are compared
    with the three routing protocols mentioned above, which verifies the superiority
    of DQAAR. 5.2.1. Lifetime Evaluation Figure 5 shows the change in the number of
    surviving nodes for each routing protocol with the network running time. For the
    high-speed railway monitoring network, the main task is to collect as much on-site
    information as possible to ensure the safety of railway operation, so we first
    focus on the life cycle of the network. Figure 5a shows that DQAAR has a longer
    running time than MTECR, MVECR, and AUMRP under the same conditions. Because MTECR
    only pays attention to the overall energy loss of the network and does not care
    about the energy balance of the network, ithe death time of each node occurs in
    about 1000 s. MTECR, MVECR, and AUMRP impose some constraints on the overall energy
    consumption balance of the network, but while prolonging the death time of the
    first node, they also cause a large area of low-energy nodes to die in the network
    around 1500 s.The DQAAR proposed in this paper delays the death time of the first
    node in the network to about 2000 s, and then there is no continuous death of
    large-scale nodes, but a relatively slow trend is maintained. This is because
    DQAAR offers dynamic rewards based on data aggregation while paying attention
    to the balanced use of network energy, and each node learns the best next-hop
    node. Efficient data aggregation paths greatly reduce the amount of data transmitted
    over the network, which greatly delays node death times. Figure 5b shows the FND
    and HND data of the four routing protocols, respectively. The FND and HND of the
    worst-performing MTECR are 985 and 2024, respectively, and the AUMRP data of FND
    are only 1565 and 2155, although it is effective. The node death time is delayed,
    but the process from the death of the first node to the death of half of the nodes
    is not very slow. The FND and HND of the DQAAR proposed in this paper are 1982
    and 3016, respectively. It can be seen that DQAAR provides better answers in terms
    of balancing network energy consumption and improving network life. Figure 5.
    Protocol life cycle, FND and HND performance. 5.2.2. Latency Time Figure 6 shows
    the real-time performance of DQAAR and the three protocols mentioned above. MTECR
    achieves the best real-time performance with an average latency of 1780 ms, but
    this is due to its advantage of reducing hop count at the expense of lifetime.
    In the initial stage of the network, DQAAR is in the parameter adjustment stage
    with significant delays. After a period of learning, its real-time performance
    is greatly improved, which is not much different from MTECR. AUMPR and MVECR excessively
    pursue the balance of energy consumption between nodes and achieve node energy
    balance by increasing the number of link hops. Long link hops greatly increase
    system latency. Figure 6. Delay performance of each protocol. Compared with the
    other three routing protocols, the DQAAR delay in the stable operation stage has
    better stability performance. That is to say, the initial high delay is caused
    by the exploration behavior of DQAAR. In the stable operation stage, the real-time
    performance of DQAAR far exceeds that of MVECR and AUMRP, achieving good real-time
    performance. 5.2.3. Scenario Analysis Case 1 verifies the impact of network size
    changes on its performance and the performance of each routing protocol. Among
    them, a single data packet on the network data = 200 bits. Figure 7 shows the
    performance of the life cycle, delay, and overall energy efficiency of each routing
    protocol when the distance from the head end to the end of the network changes
    from d = 100 m to d = 500 m. Figure 7a shows that with the increase in the network
    range, the energy balance of the network system is destroyed, which also causes
    the life cycle of each routing protocol to decrease significantly with the increase
    in d, but MTECR, AUMRP, MTECR, MVECR and DQAAR have better performance in extending
    the network life cycle. This is because MTECR minimizes the overall energy consumption
    of the network as an optimization goal, and the number of link hops is significantly
    reduced compared to the other three algorithms. This may lead to the emergence
    of local hotspots in the network, which may affect the entire network lifecycle.
    When the network range is expanded to 500 m, its lifetime is still about 30% higher
    than the worst performing MTECR. Figure 7b shows the delay performance of each
    routing protocol as the network range increases, and the time for each routing
    protocol data packet to reach the sink node gradually increases as the communication
    distance increases. Among them, MVECR and AUMRP lack the constraints on the delay,
    which leads to the rapid increase in the delay when the distance increases, and
    DQAAR reduces the delay through dynamic learning so that the network can obtain
    good real-time performance. In order to obtain better real-time performance, MTECR
    reduces the number of hops of data packet forwarding in the network, which greatly
    increases the energy consumption and shortens the network life. Figure 7. Performance
    of each protocol in Scenario 1. Obviously, the DQAAR proposed in this paper is
    ahead of AUMRP, MTECR, and MVECR in energy efficiency. When the network range
    is small, the life cycle of AUMRP and MVECR is close to that of DQAAR, and their
    comprehensive energy efficiency is also close to that of DQAAR. The life cycle
    index and delay index of the network system using each protocol are shown in Figure
    8 and Figure 9. Figure 8. System lifetime utility of each protocol in Scenario
    1. Figure 9. System delay utility of each protocol in Scenario 1. Case 2 verifies
    the impact of changes in the amount of data in the network on its performance
    and the performance of the four routing protocols. Among them, the network range
    is d = 200 m. Figure 10 shows the network life cycle, delay and comprehensive
    energy efficiency level of the DQAAR proposed in this paper and the other three
    routing protocols (AUMRP, MVECR, and MTECR) when the single data packet size of
    the network node changes from Data = 100 bit to Data = 600 bit. As shown in Figure
    10a, an increase in the amount of data in the network is accompanied by a rapid
    decrease in its life cycle, because the sending and receiving of data consumes
    the most energy in sensor nodes. MVECR pays too much attention to the energy consumption
    balance of each node in the network, but it increases its total energy consumption,
    and the life cycle has a disadvantage compared with AUMRP. The DQAAR transmission
    path planning based on data aggregation effectively reduces the amount of data
    in the network and thus prolongs the life cycle of the network, and its performance
    is higher than the other three routing protocols. The delay of the network system
    using DQAAR is smaller than that using AUMRP and MVECR but slightly larger than
    that using MTECR, and the delay increases with the increase in data volume, which
    is caused by the increase in transmission time caused by the increase in data
    volume. Data latency increases. Also, as the amount of data increases, the trend
    of delay growth for DQAAR is not as fast as it is for AUMRP and MVECR. This shows
    that the data transmission delay is reduced enough by the data aggregation strategy
    used in this paper to make up for the time it takes to aggregate the data. It
    can be seen in Figure 10c that DQAAR can effectively reduce the amount of data
    when the amount of data in the network increases, while the delay does not cause
    a significant change. Its comprehensive energy efficiency is much greater than
    that of the other three routing protocols. The cycle and delay maintain stable
    performance with the increase in data volume.The lifetime index and delay index
    of the network system using each protocol are shown in Figure 11 and Figure 12.
    Figure 10. Performance of each protocol in Scenario 2. Figure 11. System lifetime
    utility of each protocol in Scenario 2. Figure 12. System delay utility of each
    protocol in Scenario 2. Finally, the simulation verification results can be summarized
    into the following three points: (1) Compared with AUMRP, the life of the network
    system using DQAAR is improved to a certain extent, and both MVECR and MTECR are
    improved to a certain extent, which effectively prolongs the dead time of the
    first node in the network system. It ensures the balance of network energy consumption
    and allows the longer survival of nodes with heavy loads in the network when the
    energy level is low to ensure the monitoring quality of the network. (2) In the
    high-speed railway monitoring system, the life cycle of the network and the delay
    of data transmission are both important performance indicators, and the single-objective
    network optimization algorithm is difficult to meet the actual needs. The adaptive
    routing algorithm based on double-Q-values proposed in this paper can effectively
    improve the network life and obtain good real-time performance. The comprehensive
    energy efficiency index is used to evaluate the routing protocol and verify the
    superiority of DQAAR in these two aspects. (3) The design of the adaptive operator
    and Q-value in this paper comes from the business requirements of each sensor
    in the high-speed railway monitoring network system. In different application
    scenarios, the adaptive operator and Q-value can be designed differently. This
    ensures the multi-scene adaptability of the adaptive model based on double Q-values
    established in this paper. 6. Conclusions In this paper, we propose a Double-Q-value-based
    adaptive routing algorithm (DQAAR) for the business requirements of high-speed
    railway monitoring network systems. The proposed method is different from most
    of the existing methods and offers contributions described below. First, we propose
    a Double-Q-value model based on data aggregation. For the two Q-values, we consider
    the data aggregation degree, the remaining energy level, the link strength, the
    distance from the node to the sink, and the forwarding delay to consider the network
    lifetime and the real-time performance of data forwarding. The defined reward
    function can track the network’s changes in real time and keep the whole thing
    under control with less work. Second, an adaptive weight is proposed based on
    the different requirements of each service for network lifetime and real-time
    performance. This makes the algorithm proposed in this paper better able to adapt
    to different situations. Finally, the algorithm proposed in this paper is verified
    in different scenarios. The results show that DQAAR is better than AUMRP and MVECR
    in achieving network energy balance and prolonging network life, and its real-time
    performance is also better than that of these two routing protocols. Compared
    with MTECR, although the routing protocol proposed in this paper is slightly insufficient
    in real-time performance, it is far better than MTECR in extending network life.
    From the point of view of overall energy efficiency, the DQAAR that is proposed
    in this paper is a lot better than other routing protocols. Author Contributions
    Conceptualization, W.F.; methodology, Q.P. and C.H.; software, Q.P.; formal analysis,
    W.F.; investigation, Q.P. and C.H.; data curation, Q.P.; writing—original draft
    preparation, Q.P. and C.H.; writing—review and editing, W.F.; project administration,
    W.F.; funding acquisition, W.F. All authors have read and agreed to the published
    version of the manuscript. Funding This research was funded by the National Key
    R&D Program of China (2021YFF3203200). Data Availability Statement The data presented
    in this study are available in the article. Acknowledgments Here, I would like
    to express my special gratitude to Shihua Tong for his valuable feedback on paper
    editing. Conflicts of Interest The authors declare no conflict of interest. References
    Zhang, D.; Li, G.; Zheng, K.; Ming, X.; Pan, Z.-H. An Energy-Balanced Routing
    Method Based on Forward-Aware Factor for Wireless Sensor Networks. IEEE Trans.
    Ind. Inform. 2014, 10, 766–773. [Google Scholar] [CrossRef] Paine, B.M.; Polmanter,
    S.R.; Ng, V.T.; Kubota, N.T.; Ignacio, C.R. Lifetesting GaN HEMTs with Multiple
    Degradation Mechanisms. IEEE Trans. Device Mater. Reliab. 2015, 15, 486–494. [Google
    Scholar] [CrossRef] Kuawattanaphan, R.; Champrasert, P.; Aramkul, S. A Novel Heterogeneous
    Wireless Sensor Node Deployment Algorithm With Parameter-Free Configuration. IEEE
    Access 2018, 6, 44951–44969. [Google Scholar] [CrossRef] Zhai, W. Vehicle-Track
    Coupled Dynamics; Springer: Singapore, 2020; pp. 17–20. ISBN 978-981-32-9282-6.
    [Google Scholar] Song, Y.; Wang, Z.; Liu, Z.; Wang, R. A Spatial Coupling Model
    to Study Dynamic Performance of Pantograph-Catenary with Vehicle-Track Excitation.
    Mech. Syst. Signal Process. 2021, 151, 107336. [Google Scholar] [CrossRef] Duan,
    F.; Song, Y.; Gao, S.; Liu, Y.; Chu, W.; Lu, X.; Liu, Z. Study on Aerodynamic
    Instability and Galloping Response of Rail Overhead Contact Line Based on Wind
    Tunnel Tests. IEEE Trans. Veh. Technol. 2023, 72, 7211–7220. [Google Scholar]
    [CrossRef] Miyamoto, T.; Ishida, H.; Matsuo, M. Running Safety of Railway Vehicle
    as Earthquake Occurs. Rep. RTRI 1997, 38, 117–122. [Google Scholar] Li, X.; Liu,
    W.; Xie, M.; Liu, A.; Zhao, M.; Xiong, N.N.; Zhao, M.; Dai, W. Differentiated
    Data Aggregation Routing Scheme for Energy Conserving and Delay Sensitive Wireless
    Sensor Networks. Sensors 2018, 18, 2349. [Google Scholar] [CrossRef] Ma, X.; Dong,
    H.; Liu, X.; Jia, L.; Xie, G.; Bian, Z. An Optimal Communications Protocol for
    Maximizing Lifetime of Railway Infrastructure Wireless Monitoring Network. IEEE
    Trans. Ind. Inform. 2018, 14, 3347–3357. [Google Scholar] [CrossRef] Lin, J.;
    Ma, L.; Cui, J. A frequency-domain convolutional neural network architecture based
    on the frequency-domain randomized offset rectified linear unit and frequency-domain
    chunk max pooling method. IEEE Access 2020, 8, 98126–98155. [Google Scholar] [CrossRef]
    Zhang, J.; Hu, P.; Xie, F.; Long, J.; He, A. An Energy Efficient and Reliable
    In-Network Data Aggregation Scheme for WSN. IEEE Access 2018, 6, 71857–71870.
    [Google Scholar] [CrossRef] Aslam, N.; Xia, K.; Hadi, M.U. Optimal Wireless Charging
    Inclusive of Intellectual Routing Based on SARSA Learning in Renewable Wireless
    Sensor Networks. IEEE Sens. J. 2019, 19, 8340–8351. [Google Scholar] [CrossRef]
    Kaur, M.; Munjal, A. Data aggregation algorithms for wireless sensor network:
    A review. Ad Hoc Netw. 2020, 100, 102083. [Google Scholar] [CrossRef] Li, Z.;
    Liu, Y.; Liu, A.; Wang, S.; Liu, H. Minimizing Convergecast Time and Energy Consumption
    in Green Internet of Things. IEEE Trans. Emerg. Top. Comput. 2020, 8, 797–813.
    [Google Scholar] [CrossRef] Shobana, M.; Sabitha, R.; Karthik, S. Cluster-Based
    Systematic Data Aggregation Model (CSDAM) for Real-Time Data Processing in Large-Scale
    WSN. Wirel. Pers. Commun. 2020, 117, 2865–2883. [Google Scholar] [CrossRef] Ullah,
    I.; Youn, H.Y. Efficient data aggregation with node clustering and extreme learning
    machine for WSN. J. Supercomput. 2020, 76, 10009–10035. [Google Scholar] [CrossRef]
    Zhang, J.; Lin, Z.; Tsai, P.W.; Xu, L. Entropy-driven data aggregation method
    for energy-efficient wireless sensor networks. Inf. Fusion 2020, 56, 103–113.
    [Google Scholar] [CrossRef] Younis, O.; Fahmy, S. HEED: A Hybrid, Energy-Efficient,
    Distributed Clustering Approach for Ad Hoc Sensor Networks. IEEE Trans. Mob. Comput.
    2004, 3, 366–379. [Google Scholar] [CrossRef] Li, Y.; Guo, L.; Prasad, S.K. An
    Energy-Efficient Distributed Algorithm for Minimum-Latency Aggregation Scheduling
    in Wireless Sensor Networks. In Proceedings of the 2010 IEEE 30th International
    Conference on Distributed Computing Systems, Genoa, Italy, 21–25 June 2010; pp.
    827–836. [Google Scholar] Weng, C.; Chen, C.; Chen, P.; Chang, K. Design of an
    Energy-efficient Cross-layer Protocol for Mobile Ad Hoc Networks. IET Commun.
    2013, 7, 217–228. [Google Scholar] [CrossRef] Kacimi, R.; Dhaou, R.; Beylot, A.L.
    Load Balancing Techniques for Lifetime Maximizing in Wireless Sensor Networks.
    Ad Hoc Netw. 2013, 11, 2172–2186. [Google Scholar] [CrossRef] Thiriveni, G.V.;
    Ramakrishnan, M. Distributed Clustering Based Energy Efficient Routing Algorithm
    for Heterogeneous Wireless Sensor Networks. Indian J. Sci. Technol. 2016, 9, 217–228.
    [Google Scholar] [CrossRef] Ma, X.P.; Dong, H.H.; Li, P.; Jia, L.M.; Liu, X.;
    Qin, Y.; Tang, J.Q. Adaptive Optimization of Multi-Hop Communication Protocol
    for Linear Wireless Monitoring Networks on High-Speed Railways. IEEE Trans. Intell.
    Transp. Syst. 2019, 20, 2313–2327. [Google Scholar] [CrossRef] Zhu, F.; Wei, J.
    An Energy-Efficient Unequal Clustering Routing Protocol for Wireless Sensor Networks.
    Int. J. Distrib. Sens. Netw. 2019, 15, 155014771987938. [Google Scholar] [CrossRef]
    Jesudurai, S.A.; Senthilkumar, A. An Improved Energy Efficient Cluster Head Selection
    Protocol Using the Double Cluster Heads and Data Fusion Methods for IoT Applications.
    Cogn. Syst. Res. 2019, 57, 101–106. [Google Scholar] [CrossRef] Liu, X.; Yu, J.;
    Zhang, W.; Tian, H. Low-energy dynamic clustering scheme for multi-layer wireless
    sensor networks. Comput. Electr. Eng. 2021, 91, 107093. [Google Scholar] [CrossRef]
    Maivizhi, R.; Yogesh, P. Q-learning based routing for in-network aggregation in
    wireless sensor networks. Wirel. Netw. 2021, 27, 2231–2250. [Google Scholar] [CrossRef]
    Nguyen, P.D.; Kim, L.W. Sensor System: A Survey of Sensor Type, Ad Hoc Network
    Topology and Energy Harvesting Techniques. Electronics 2021, 10, 219. [Google
    Scholar] [CrossRef] Nikseresht, M.R.; Mollamotalebi, M. Providing a CoAP-based
    technique to get wireless sensor data via IoT gateway. Comput. Commun. 2021, 172,
    155–168. [Google Scholar] [CrossRef] Osamy, W.; Salim, A.; Khedr, A.M.; El-Sawy,
    A.A. IDCT: Intelligent Data Collection Technique for IoT-Enabled Heterogeneous
    Wireless Sensor Networks in Smart Environments. IEEE Sens. J. 2021, 21, 21099–21112.
    [Google Scholar] [CrossRef] Wang, Y.; Sun, G.; Yang, G.; Ding, X. XgBoosted Neighbor
    Referring in Low-Duty-Cycle Wireless Sensor Networks. IEEE Internet Things J.
    2020, 8, 3446–3461. [Google Scholar] [CrossRef] Panchal, A.; Singh, R.K. EEHCHR:
    Energy Efficient Hybrid Clustering and Hierarchical Routing for Wireless Sensor
    Networks. Ad Hoc Netw. 2021, 12, 102692. [Google Scholar] [CrossRef] Xiao, X.;
    Zhao, M. Routing optimization strategy of IoT awareness layer based on improved
    cat swarm algorithm. Neural Comput. Appl. 2021, 34, 3311–3322. [Google Scholar]
    [CrossRef] Yao, B.; Gao, H.; Chen, Q.; Li, J. Energy-Adaptive and Bottleneck-Aware
    Many-to-Many Communication Scheduling for Battery-Free WSNs. IEEE Internet Things
    J. 2020, 8, 8514–8529. [Google Scholar] [CrossRef] Yun, W.K.; Yoo, S.J. Q-Learning-Based
    Data-Aggregation-Aware Energy-Efficient Routing Protocol for Wireless Sensor Networks.
    IEEE Access 2021, 9, 10737–10750. [Google Scholar] [CrossRef] Zaraket, E.; Murad,
    N.M.; Yazdani, S.S.; Rajaoarisoa, L.; Ravelo, B. An overview on low energy wake-up
    radio technology: Active and passive circuits associated with MAC and routing
    protocols. J. Netw. Comput. Appl. 2021, 190, 103140. [Google Scholar] Maivizhi,
    R.; Yogesh, P. Fuzzy routing for in-network aggregation in wireless sensor networks.
    Peer-Peer Netw. Appl. 2022, 15, 592–611. [Google Scholar] [CrossRef] Zhu, T.;
    Li, J.; Gao, H.; Li, Y. Data Aggregation Scheduling in Battery-Free Wireless Sensor
    Networks. IEEE Trans. Mob. Comput. 2022, 21, 1972–1984. [Google Scholar] [CrossRef]
    Disclaimer/Publisher’s Note: The statements, opinions and data contained in all
    publications are solely those of the individual author(s) and contributor(s) and
    not of MDPI and/or the editor(s). MDPI and/or the editor(s) disclaim responsibility
    for any injury to people or property resulting from any ideas, methods, instructions
    or products referred to in the content.  © 2023 by the authors. Licensee MDPI,
    Basel, Switzerland. This article is an open access article distributed under the
    terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/).
    Share and Cite MDPI and ACS Style Fu, W.; Peng, Q.; Hu, C. Energy-Saving Adaptive
    Routing for High-Speed Railway Monitoring Network Based on Improved Q Learning.
    Sensors 2023, 23, 7393. https://doi.org/10.3390/s23177393 AMA Style Fu W, Peng
    Q, Hu C. Energy-Saving Adaptive Routing for High-Speed Railway Monitoring Network
    Based on Improved Q Learning. Sensors. 2023; 23(17):7393. https://doi.org/10.3390/s23177393
    Chicago/Turabian Style Fu, Wei, Qin Peng, and Canwei Hu. 2023. \"Energy-Saving
    Adaptive Routing for High-Speed Railway Monitoring Network Based on Improved Q
    Learning\" Sensors 23, no. 17: 7393. https://doi.org/10.3390/s23177393 Note that
    from the first issue of 2016, this journal uses article numbers instead of page
    numbers. See further details here. Article Metrics Citations No citations were
    found for this article, but you may check on Google Scholar Article Access Statistics
    Article access statistics Article Views 29. Dec 8. Jan 18. Jan 28. Jan 7. Feb
    17. Feb 27. Feb 8. Mar 18. Mar 0 1000 250 500 750 For more information on the
    journal statistics, click here. Multiple requests from the same IP address are
    counted as one view.   Sensors, EISSN 1424-8220, Published by MDPI RSS Content
    Alert Further Information Article Processing Charges Pay an Invoice Open Access
    Policy Contact MDPI Jobs at MDPI Guidelines For Authors For Reviewers For Editors
    For Librarians For Publishers For Societies For Conference Organizers MDPI Initiatives
    Sciforum MDPI Books Preprints.org Scilit SciProfiles Encyclopedia JAMS Proceedings
    Series Follow MDPI LinkedIn Facebook Twitter Subscribe to receive issue release
    notifications and newsletters from MDPI journals Select options Subscribe © 1996-2024
    MDPI (Basel, Switzerland) unless otherwise stated Disclaimer Terms and Conditions
    Privacy Policy"'
  inline_citation: '>'
  journal: Sensors
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Energy-Saving Adaptive Routing for High-Speed Railway Monitoring Network
    Based on Improved Q Learning
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Rodrigues V.F.
  - da Rosa Righi R.
  - da Costa C.A.
  - Zeiser F.A.
  - Eskofier B.
  - Maier A.
  - Kim D.
  citation_count: '1'
  description: 'Purpose: Smart cities that support the execution of health services
    are more and more in evidence today. Here, it is mainstream to use IoT-based vital
    sign data to serve a multi-tier architecture. The state-of-the-art proposes the
    combination of edge, fog, and cloud computing to support critical health applications
    efficiently. However, to the best of our knowledge, initiatives typically present
    the architectures, not bringing adaptation and execution optimizations to address
    health demands fully. Methods: This article introduces the VitalSense model, which
    provides a hierarchical multi-tier remote health monitoring architecture in smart
    cities by combining edge, fog, and cloud computing. Results: Although using a
    traditional composition, our contributions appear in handling each infrastructure
    level. We explore adaptive data compression and homomorphic encryption at the
    edge, a multi-tier notification mechanism, low latency health traceability with
    data sharding, a Serverless execution engine to support multiple fog layers, and
    an offloading mechanism based on service and person computing priorities. Conclusions:
    This article details the rationale behind these topics, describing VitalSense
    use cases for disruptive healthcare services and preliminary insights regarding
    prototype evaluation.'
  doi: 10.1007/s12553-023-00753-3
  full_citation: '>'
  full_text: '>

    "Your privacy, your choice We use essential cookies to make sure the site can
    function. We also use optional cookies for advertising, personalisation of content,
    usage analysis, and social media. By accepting optional cookies, you consent to
    the processing of your personal data - including transfers to third parties. Some
    third parties are outside of the European Economic Area, with varying standards
    of data protection. See our privacy policy for more information on the use of
    your personal data. Manage preferences for further information and to change your
    choices. Accept all cookies Skip to main content Advertisement Log in Find a journal
    Publish with us Track your research Search Cart Home Health and Technology Article
    Digital health in smart cities: Rethinking the remote health monitoring architecture
    on combining edge, fog, and cloud Original Paper Published: 27 April 2023 Volume
    13, pages 449–472, (2023) Cite this article Download PDF Health and Technology
    Aims and scope Submit manuscript Vinicius Facco Rodrigues, Rodrigo da Rosa Righi
    , Cristiano André da Costa, Felipe André Zeiser, Bjoern Eskofier, Andreas Maier
    & Daeyoung Kim  2222 Accesses 3 Citations 3 Altmetric Explore all metrics Abstract
    Purpose Smart cities that support the execution of health services are more and
    more in evidence today. Here, it is mainstream to use IoT-based vital sign data
    to serve a multi-tier architecture. The state-of-the-art proposes the combination
    of edge, fog, and cloud computing to support critical health applications efficiently.
    However, to the best of our knowledge, initiatives typically present the architectures,
    not bringing adaptation and execution optimizations to address health demands
    fully. Methods This article introduces the VitalSense model, which provides a
    hierarchical multi-tier remote health monitoring architecture in smart cities
    by combining edge, fog, and cloud computing. Results Although using a traditional
    composition, our contributions appear in handling each infrastructure level. We
    explore adaptive data compression and homomorphic encryption at the edge, a multi-tier
    notification mechanism, low latency health traceability with data sharding, a
    Serverless execution engine to support multiple fog layers, and an offloading
    mechanism based on service and person computing priorities. Conclusions This article
    details the rationale behind these topics, describing VitalSense use cases for
    disruptive healthcare services and preliminary insights regarding prototype evaluation.
    Similar content being viewed by others RETRACTED ARTICLE: A Review and State of
    Art of Internet of Things (IoT) Article 14 July 2021 A survey on security challenges
    in cloud computing: issues, threats, and solutions Article 28 February 2020 Energy
    efficiency in cloud computing data centers: a survey on software technologies
    Article 30 August 2022 1 Introduction Over the last few years, the health sector
    has understood that the Internet can be an essential support instrument in searching
    for a better quality of life and better conditions for patient care [1, 2]. Among
    other advantages associated with using the Internet in the health field, the analysis
    and processing of data in real-time through remote servers have been highlighted.
    An efficient model capable of providing storage and processing of applications
    over the Internet is the concept of cloud computing [2]. This model can be described
    as a service provided by large data centers that offer part of their infrastructure
    - hardware and software - to third parties (companies and individuals) and public
    organizations. Once these customers purchase this type of service, they will have
    computing resources with increasing capacity without the need for significant
    financial capital investments to acquire, maintain and manage such resources.
    Cloud computing is the primary support to enable the Internet of Things (IoT)
    applications. IoT environments are composed of hundreds or thousands of devices
    that constantly generate requests for collected data to be later analyzed. In
    the context of Healthcare 4.0 [3], the Internet of Health Things (IoHT) represents
    the spread of IoT devices applied to e-health applications [4]. This process naturally
    generates heavy requests sent to a central processing server, flooding that server’s
    network and requiring computational power that a single computer would often not
    be able to supply [5]. Here, cloud computing can be used as a processing medium
    for IoT scenarios to leverage its scalability and pay-as-you-go model. However,
    sending requests from an IoT device to a cloud server adds network latency overhead
    to the communication that cannot be accepted in some cases. For example, we can
    cite some e-health scenarios, such as those addressing remote electrocardiogram
    (ECG), where data collecting and processing times are critical to the correct
    system functioning. We often cannot wait for a message to be sent, processed in
    the cloud, and returned, as the time involved in these procedures can influence
    essential aspects of time-critical applications [5, 6]. Furthermore, even with
    a highly scalable cloud computing environment, scaling it to serve many requests
    would result in additional power consumption. Fig. 1 Comparison between traditional
    (a) strategies for health monitoring and VitalSense (b). Applications can access
    health services from anywhere Full size image To allow better scalability of IoT
    systems, it is necessary to design new architectures and solutions that allow
    handling many devices and requests simultaneously, maintaining the Quality of
    Service (QoS) [7]. Aligned with this sentence, fog computing expands the services
    offered by the traditional cloud model to be closer to the data generators  [8,
    9]. Also, edge computing enters here to enable some processing and decision support
    precisely on the network’s border, i.e., close to the IoT device itself. Computing
    in fog or edge has as its main characteristics low latency, better support to
    collect the geographic distribution of data, and mobility over a large number
    of nodes in the network. Thus, with predominantly wireless access, we have the
    execution of applications in real-time and more significant support for device
    heterogeneity. Data read by the sensors is collected, processed, and stored in
    a temporary database instead of delivered to the cloud, avoiding round-trip delays
    in network traffic. A combination of cloud, fog, and the edge is especially pertinent
    to provide an architecture to answer healthcare and pandemic research, such as
    the case of Coronavirus disease (COVID-19) [10]. More significantly, we are entering
    a period where long-COVID-19 research is mainstream. The purpose is to continuously
    monitor the vital signs of those contaminated by the virus beforehand [11]. In
    remote health monitoring, most vital sign monitoring systems follow a generalized
    three-tier architecture composed of sensing devices, fog gateways, and the cloud
    [12] (see Fig. 1(a)). By analyzing the current initiatives in the literature,
    they do not address all issues concomitantly as follows: (i) person’s traceability
    and privacy, both in terms of historical view of vital signs or places visited
    in a smart city; (ii) artificial intelligence to execute health services proactively,
    generating value for end-users, in addition to hospitals and public sector; (iii)
    state-of-the-art mechanisms to address QoS, elastic processing capability and
    an efficient and scalable message notification system. In this context, this article
    introduces VitalSense as a novel smart city architecture that combines edge, fog,
    and cloud to manage historical health data of citizens, acting primarily in the
    fight against COVID-19. Figure 1(b) demonstrates the VitalSense approach, where
    we rely on a hierarchical fog topology and a distributed computing engine distributed
    along with the three involved tiers. Hospitals, individuals through wearables,
    homes, and certain places in cities would rely on sensors and readers so that
    vital signs and geolocation data are collected to serve as input to health services.
    The outcome brings benefits both to the public sector and to own citizens of the
    smart city. In VitalSense, for example, we envisage that the system can proactively
    call an ambulance to a particular person’s home, taking into account the AI-based
    processing of historical vital sign data. Also, real-time historical data allows
    us to generate dashboards to verify the degree of spread of the SARS-CoV-2 (severe
    acute respiratory syndrome coronavirus 2) virus through the places that a particular
    person has visited and analyze the effectiveness of quarantine actions. Although
    using a traditional composition of edge, fog, and cloud, our contributions appear
    in how we handle each infrastructure level. In detail, our addition to the literature
    is a remote health monitoring architecture that explores: Adaptive data compression
    and homomorphic encryption in the edge; A multi-tier notification mechanism; Low
    latency health traceability with data sharding; Serverless execution elasticity
    engine involving multiple fog layers with an offloading mechanism based on service
    and person computing priorities; Live geographical-based dashboards for data visualization.
    The remaining of this article first introduces the related work in Section 2.
    Here, we provide literature discussion, highlighting research opportunities not
    covered up to this moment. Second, Section 3 presents the VitalSense Model, describing
    its architecture, processes, and algorithms. Third, Section 4 is in charge of
    discussing health services and use cases. This section shows health services for
    the future, and how they match with the edge, fog, and cloud architecture proposed.
    Finally, Section 5 concludes the article, detaching our achievements to improve
    citizens’ quality of life worldwide. 2 Related work This section introduces the
    main articles in the literature on the remote health monitoring scope, describing
    their main characteristics (Table 1). Following, Section 2.1 describes in detail
    each article, and Section 2.2 discusses the main findings. 2.1 State of the art
    The current state-of-the-art presents several articles focusing on remotely monitoring
    patients’ vital signs. In general, cloud computing is commonly employed in such
    solutions combined with edge or fog [12,13,14,15,16,17,18,19,20,21]. Nevertheless,
    some explore different strategies without employing cloud [22, 23]. Sicari et
    al. [22] propose a quarantine home monitoring system composed of IoT sensors and
    Global Positioning System (GPS) tracking. The first goal is to collect and analyze
    vital signs according to predefined thresholds generating alerts. In addition,
    the system performs GPS monitoring to track if the patient moves outside its quarantine
    area. The proposal does not focus on any QoS parameter and relies only on the
    Internet and Global System for Mobile communication (GSM) networks. Li et al.
    [14] propose a remote monitoring system that tracks respiratory rate deterioration
    for patients with COVID-19. The authors introduce a non-invasive respiratory rate
    estimation technique using WiFi. It transmits data to the cloud for patient monitoring
    and triggering alerts. Rahman et al. [13] propose a framework to collect and analyze
    physiological data from patients remotely. The system employs wearable sensors
    and a smartphone running the developed application to collect, process, and post
    data to the cloud. In addition, the system uses the location of each patient according
    to their address. The patient must manually initiate the collection and analysis
    process according to a defined protocol. Al Bassam et al. [15] propose a wrist
    wearable device equipped with temperature, oxygen saturation (SpO2), heart rate,
    and sound sensors providing remote data to monitor and manage potential COVID-19
    infected patients. The strategy uses a microcontroller to send data to a cloud
    back-end. According to the readings, the system can generate Email and Short Message/Messaging
    Service (SMS) alarms. In addition, a mobile application allows data visualization
    from tracked patients. Paganelli et al. [16] present a conceptual architecture
    for remote monitoring of patients with COVID-19. The architecture considers data
    acquisition from users at home and in medical wards. The authors define a three-tier
    architecture in which mobile and static gateways connect the IoT layer with a
    data distribution layer through a message broker network. The architecture comprises
    an IoT kit composed of a micro-controller and radio transceiver to connect to
    the closest gateway. Rahmani et al. [23] propose a smart gateway at the network’s
    edge to collect, process, and transmit data to the cloud. It provides several
    services, including compression, filtering, security, data analysis, and fusion.
    The main goal is to generate notifications, prioritize critical data, and decrease
    the data volume, thus reducing latency when sending data to the cloud. Moving
    patients change the base gateway according to the coverage. Sahu et al. [12] propose
    a three-tier architecture for vital sign monitoring. The authors employ a microcontroller
    unit (MCU) wired to several body sensors. It extracts data from them and transmits
    it to a smartphone application through Bluetooth. The application can provide
    data analysis and alarms for sensor measurements. The system can also send data
    to a cloud server using an Internet connection; however, the main focus of the
    proposal is the local processing and alarms. Sangeetha et al. [19] propose a remote
    health monitoring system for rural areas comprising medicine delivery using drones.
    The strategy consists of a smartphone acquiring data from health sensors and uploading
    it to a cloud server through the Internet. Data analytics services process data
    in the cloud and generate alerts when it identifies abnormalities. Depending on
    the severity, caregivers, doctors, or ambulance services can be alerted. Mukherjee
    et al. [17] propose a edge-fog-cloud framework for IoHT that predicts patients
    conditions and generates alerts. They developed a workflow that collects data
    from a body area network (BAN) using an edge device and forwards data to fog nodes.
    Notifications and further processing take place only when fog processing identifies
    abnormalities. Chudhary and Sharma [18] propose a fog-cloud framework for IoHT
    comprising four layers: data collection, fog, cloud, and application. Fog nodes
    process data locally to provide faster response time while re-transmitting data
    to the cloud when local processing is not required. In turn, the application layer
    provides an interface for users to access processed data from both the cloud and
    fog layers. Aziz et al. [21] propose a real-time monitoring system to track blood
    pressure and body temperature from remote patients. The solution relies on GSM
    connectivity to send alerts to a remote server when the sensors’ readings violate
    pre-defined thresholds. Then, the back-end server relays the messages to the Doctor’s
    mobile phone. In addition, the system attaches GPS data to the alerts so that
    the medical team can send an ambulance if it is the case. Priambodo and Kadarina
    [20] detail a COVID-19 patient remote monitoring to track the patient’s SpO2,
    heart rate, and location. A smartphone acts as a gateway to collect data from
    sensors, attach identification and GPS information, and then transmit it to a
    remote server. In turn, the remote server employs Logstash, Elasticsearch, and
    Kibana for data processing so doctors can analyze patients’ data. Table 1 Comparison
    among studies proposing remote monitoring systems to track patients parameters:
    body temperature (BT), blood pressure (BP), blood oxygen saturation (SpO2), heart
    rate (HR), respiratory rate (RR), heart rate variability (HRV), and electrocardiogram
    (ECG) Full size table 2.2 Discussion As Table 1 shows, most articles focus on
    vital sign monitoring in general [12, 13, 17, 19, 21, 23] or patient with COVID-19
    monitoring [14,15,16, 20, 22]. Commonly, they aim at monitoring vital signs such
    as: (i) body temperature (BT); (ii) blood pressure (BP); (iii) blood oxygen saturation
    (SpO2); (iv) heart rate (HR); (v) respiratory rate (RR); (vi) heart rate variability
    (HRV); and (vii) electrocardiogram (ECG). IoT plays a critical role in these strategies
    as they rely on small, mobile sensor devices. In addition, most authors employ
    different computing levels in their solutions, combining edge or cloud technologies
    with IoT devices. Although beneficial, fog computing appears in only two articles
    [17, 18] as a solution to improve the performance of such systems. Solutions can
    benefit from closer data processing units the fog provides, improving response
    time. Critical applications from the healthcare domain require fast processing,
    and excessive delays can compromise their purpose. Current literature lacks a
    proposal exploring fog in such scenarios to improve response time for critical
    situations. That leads to the current research that combines fog with IoT, edge,
    and cloud to improve response time. 3 The VitalSense model VitalSense aims to
    provide a large-scale real-time health monitoring system for smart cities. Its
    main characteristic relies on employing fog and edge to deliver close data processing
    for patients and health administrators. It also employs the cloud for data aggregation
    and analysis. As data processing is at the fog and edge, users benefit from a
    fast response time that is critical for medical applications. The use of remote
    health monitoring can significantly improve the delivery of health services to
    the population. In traditional health care, patients visit a medical facility
    for periodic health checks or to treat health issues. Such a scenario shows the
    reactiveness of the public healthcare system that requires a patient’s action
    of a sudden problem to deliver health services. VitalSense offers a proactive
    approach to delivering health services, regardless of the patient’s actions. Aside
    from vital sign monitoring, VitalSense also comprises people’s motion tracking.
    Real-time location systems (RTLS) [24] can integrate the architecture by injecting
    people tracking information at the edge of the architecture. RTLS improves the
    understanding of movement patterns and exposure to risk locations by providing
    indoor and outdoor positioning information. Currently, there are several RTLS
    technologies for different objectives depending on the required precision, including
    Radio-Frequency Identification (RFID), Ultrawideband (UWB), and GPS. VitalSense
    relies on RFID city portals that can track when a person accesses or leaves a
    particular region. Data acquired from portals generate information that can support
    several services. For instance, crowd monitoring is crucial for pandemic monitoring
    and hazard control. Tracking people’s movements from region to region helps monitor
    their exposure to potential harm. Therefore, the public administration can take
    action beforehand when critical situations are prone to happen. With concepts
    such as the IoT, Big Data, and Industry 4.0 (I4.0) [25] becoming ubiquitous in
    industries, including e-health ones, the exponential growth of temporal data generated
    by IoT sensors is likely to continue. This data is vital for the companies; analyzing
    it and acting upon the results can optimize production quality, save energy, and
    improve the quality of life for end-user citizens. However, when analyzing such
    large amounts of data, we have a trend of stressing the computer and the network.
    In this context, by selecting more efficient transfer protocols, an IoT-based
    application can significantly increase performance. As the article exposes, when
    designing data traffic in a smart city, we can deal with excessive network traffic
    that we could easily avoid if the middleware only sends the number of data points
    needed. In summary, we perceived in the scientific literature that today there
    is no existing solution capable of optimizing IoT data traffic effortlessly while
    achieving a lossless data representation. Usually, approaches compress data on
    the server side while decompressing it on the client side. This idea suffers from
    calibrating the overhead regarding compression and decompression activities and
    the possible gains in transmission time, in addition to modifications mainly on
    the client side. Our proposal for data compression resides at the edge. The main
    idea is to send vital sign data to the fog in accordance with the person’s status
    and the subscribed services. For example, we can send data to the fog more frequently
    for babies or the elderly. Also, if at the edge we detect some health complication
    (such as the data collected is outside predefined thresholds for a particular
    vital sign type) or if a specific person has a chronic disease or recovering from
    medical treatment, we can maintain a high frequency on edge-fog data transmission.
    However, healthy and mid-age people can work with higher transmission periods
    without compromising the detection of health problems. It is important to note
    that the transmission frequency is adapted per person, being dynamic along with
    the functioning of the architecture. 3.1 Architecture I4.0 recently brought several
    IoT sensors to the real world that hospitals can now employ in health services,
    called Healthcare 4.0. VitalSense relies on those concepts to build an architecture
    capable of collecting patients’ data regardless of location. Figure 2 presents
    VitalSense architecture composed of three layers: edge, fog, and cloud. Individuals
    at the network’s edge wear off-the-shelf health sensors to monitor their vital
    signs during daily activities. VitalSense introduces Edge Controllers to capture
    data from sensors providing data processing, transmission, and feedback. Edge
    Controllers are devices placed close to sensors capable of reaching them to extract
    data. For instance, an Edge Controller can be either a smartphone or a single
    board computer installed at the user’s house. Fig. 2 Traditional fog architecture
    a versus VitalSense’s architecture design b employing edge, fog, and cloud Full
    size image At the fog layer, geographically distributed fog nodes offer a near
    data processing infrastructure. Fog nodes provide several health services providing
    notifications for Edge Controllers and producing reports to public administrators.
    In contrast to Edge Controllers, which do not communicate with one another, fog
    nodes can exchange data and offload data processing [26]. In addition, fog nodes
    form a hierarchy tree in which parent nodes aggregate information from child nodes
    to produce region knowledge. Finally, the cloud layer provides a central platform
    that aggregates data from the entire deployment. Cloud services employ a more
    robust infrastructure for the deep analysis of data. In addition, health administrators
    have a broader view of several regions at the cloud layer. That allows solutions
    capable of identifying risk zones and outbreaks of diseases at their earliest.
    VitalSense can scale its services using cloud infrastructure for resource elasticity.
    Therefore, it supports a growing architecture where more fog nodes can be integrated
    into the solution. When deploying the VitalSense architecture, some technologies
    can guarantee data security and QoS. Dedicated network links can provide private
    networks to allow end-to-end communication between the architecture modules. Besides,
    private networks provide more reliable communication channels improving QoS. The
    use of Multi-Protocol Label Switching (MPLS) [27] and Software-Defined Wide Area
    (SD-WAN) [28] network can support QoS when working on a shared network environment.
    Fog providers can employ such technologies at the network level to provide dynamic
    QoS strategies according to needs. 3.1.1 Edge layer The edge layer comprises several
    sensors collecting data from people and the environment. These sensors can monitor
    vital signs and transmit them to the VitalSense. Individuals can wear a sensor
    to monitor several health parameters during daily activities. Wireless technology
    allows data extraction and collection without requiring the individual to offload
    the data manually. VitalSense places the Edge Controller module in this layer
    responsible for data collection. Such a module also provides data pre-processing
    before transmitting it to the upper layers, allowing close service provisioning
    to the users through generating alerts for both users and the upper layers. Managing
    personal data is always challenging regarding privacy in the IoT world. Currently,
    the General Data Protection Regulation 1 (GPDR) defines several criteria to enhance
    individuals’ control and rights over their data. VitalSense addresses that by
    proposing a robust network topology that places the Edge Collectors as entry points
    directly connected to the sensors. Thus, it can provide data encryption services
    at the network’s border protecting the users’ data. In particular, this layer
    employs asymmetric cryptography (RSA 2048) to transfer data to the fog. In addition,
    VitalSense does not collect identifying information and only transmits anonymized
    data into the system. Upon registering to use the system, VitalSense requires
    the subject to consent to processing their data. VitalSense generates a unique
    hash code for each individual to label the data without transmitting identification
    information along with it. Figure 3 details the edge layer operation including
    the Edge Controller architecture. At the bottom, the Edge Controller provides
    a sensor middleware able to connect to sensors via three different strategies:
    (i) subscribe to data streams; (ii) collect data using sensors APIs; (iii) or
    pull data from vendor applications. The middleware provides raw data from sensors
    to the data processing module. Data coming from sensors flow into two different
    parallel phases. First, Edge Controllers must prepare the data before it can be
    transmitted to the fog. In this phase, the module filters, aggregates, compresses
    and encrypts several data samples. On the one hand, filtering, aggregation, and
    compression reduce the amount of data, improving network performance. On the other
    hand, encryption ensures data protection. Fig. 3 Edge layer architecture. The
    sensor middleware collects data from sensors supporting different interfaces.
    Data is then processed and transmitted to the fog, while local processing can
    generate notifications Full size image During the second phase, the Edge Controller
    generates notifications employing lightweight services. It analyses raw data samples
    employing prediction, correlation, and classification algorithms. The notification
    module generates notifications based on the output of the services. Depending
    on the Edge Controller’s hardware, it can perform notification actions such as
    turning an LED on, popping up a message on the screen, or sending a message to
    a network service. The Edge Controller connection with the fog layer occurs in
    a two-way publish-subscribe model. First, the Edge Controller publishes data to
    the fog through an Message Queuing Telemetry Transport (MQTT) server to which
    fog nodes subscribe. Second, the Edge Controller subscribes to data streams from
    the fog to listen for notifications. The connection protocol between these layers
    occurs through a handshake process. Edge Controllers do not know which fog node
    they should connect. Fog nodes firstly reach Edge Controllers to inform a new
    connection. The Fog Connector module handles the new connection and connects to
    the notification MQTT server from this particular fog node. Therefore, once a
    fog node connects to read data, the Edge Controller also listens for notifications
    from this new fog node. 3.1.2 Fog layer The fog layer comprises several geographically
    distributed nodes (fog nodes) responsible for processing data from the edge and
    providing services for both edge and cloud layers. Fog nodes form the core of
    the architecture since they process data from sensors by applying different algorithms
    for data analysis. Results from such analysis can generate notifications to either
    edge or cloud components. In addition, fog nodes reside near the edge of the network,
    which reduces communication delay improving response time. Figure 4 depicts a
    fog node architecture and the modules that compose it. Fog nodes provide two different
    platforms for data processing: (i) serverless functions; and (ii) container pool.
    Different from the cloud, the resources are more limited in the fog. Therefore,
    resource sharing is challenging in such a solution, given that a fog node processes
    data from multiple users simultaneously. Serverless provides a quick way of executing
    computing tasks in shared resources. However, some tasks might require more computing
    time than others and suffer from timeout limitations of serverless platforms.
    VitalSense proposes the combination of both serverless and a container pool to
    execute tasks. The container pool can support data processing for tasks requiring
    increased time. The Data Orchestrator is responsible for choosing each solution
    according to resource consumption and availability. Fig. 4 Fog layer architecture.
    Data is received from many Edge Collectors to be analyzed and processed by different
    services. Fog nodes can generate notifications according to the service and analysis
    processing Full size image VitalSense proposes a network topology where fog nodes
    are organized in a hierarchical structure. Each fog node can subscribe to one
    parent and several child nodes to receive three types of messages: (i) notifications;
    (ii) service data; and (iii) data offload. A given fog node can subscribe to notifications
    from its child nodes and generate new alert messages aggregating data from multiple
    sources. In turn, service data regards messages containing resulting computation
    from particular services. The Data Analysis module comprises several services
    which produce an output that is published in the MQTT server. Both parent and
    child nodes can subscribe to receive service data and use the information in their
    local processing. A particular fog node has limited resources which may lead to
    an overloaded situation according to the number of users. In such cases, the Fog
    Connector can forward data for processing to a parent node. The Request Manager
    decides whether resources are available, informing the Fog Connector in which
    direction requests should flow. In case of offload needs, the Fog Connector publishes
    data to the MQTT server, which the parent node consumes data for processing. Fig.
    5 Dashboard for map visualization and navigation according to vital sign measurements
    out of normality: a shows a broader view of a city, while b zooms in on a particular
    region of interest Full size image Besides the parent/child topology, fog nodes
    can also connect to brother nodes. Brother nodes are the physically closer nodes
    from a particular fog node. The communication channel is important to migrate
    a user session when the user is moving from one region to another. Therefore,
    brother nodes can perform a handoff strategy so the system can maintain the user
    track and history. Privacy and security is also an important issue when handling
    patients’ data. Fog nodes generate an RSA 2048 key pair to enable data encryption
    at the edge layer. Edge Controllers use the public key to encrypt data, while
    fog nodes use the private key to decrypt it. In addition, VitalSense employs homomorphic
    encryption [29] algorithms at this layer which guarantees that all data flowing
    in the system is secure. Raw data can be transferred to third-party services and
    public clouds, which can perform arithmetic computations with the data without
    accessing them. These services cannot see the actual data and need to request
    a fog node to decrypt the result of their computation. 3.1.3 Cloud layer The cloud
    layer is the data aggregator from the entire architecture. It connects to the
    fog nodes on the top of the hierarchy to receive notifications and aggregated
    data. The cloud combines data from all sources providing a broader overview of
    the architecture. Global analysis is possible at this layer through data prediction
    and classification algorithms. Applications can use cloud features to generate
    critical insights for public administrators. Dashboards, views, and graphs are
    examples of real-time applications that can monitor regions. Besides, data reports
    can provide a valuable understanding of patterns and risk regions based on data
    processed at the fog. Figure 5 demonstrates a data visualization dashboard at
    cloud layer. The dashboard can show regions concentrating abnormalities on measurements
    of a particular vital sign. Figure 5 demonstrates a broader view of the city of
    Porto Alegre, showing red circles in regions where several individuals present
    fever. In turn, Fig. 5b shows the same dashboard but zooming in on a particular
    region where the concentration is high. The public administrator can visualize
    the number of individuals and their position in that particular region. Such a
    dashboard can help decision-making by the public administrator that can proactively
    act to mitigate the risks for the population. 3.1.4 Network organization Figure
    6 depicts VitalSense’s network organization. The interconnection between sensors,
    Edge Controllers, fog nodes, and cloud forms a hybrid star-mesh topology. At the
    border, Personal Area Networks (PAN) comprise the patient’s sensors connected
    to an Edge Controller to produce data. Alternatively, sensors can form a short-range
    network in which a master node collects its data to transmit to the Edge Controller.
    Wireless technology, such as Bluetooth and WiFi, are predominant at this layer.
    However, an Ethernet connection between the master node and the Edge Controller
    is also possible. As an entry point to the system, the Edge Controllers live close
    enough to PANs while connecting to fog nodes in Local Area Networks (LAN). Each
    Edge Controller connects to a single fog node, and they can change according to
    the Edge Controller’s mobility. Mobile Edge Controllers change their fog node
    over time according to network proximity. Mobility is only possible when employing
    WiFi and 5 G technology to connect the fog. When employing Ethernet technology,
    Edge Controllers are fixed at houses, hospitals, stores, and others. Fiber at
    this layer can provide a secure and private connection to the fog, supporting
    high rate and low latency data transmission. Fig. 6 Network topology Full size
    image At the fog, a hierarchical mesh network topology builds the path to the
    cloud providing low latency services to the edge. Fog nodes closer to the edge
    connect to Edge Controllers to consume data and provide services. These fog nodes
    can also connect to several neighboring fog nodes according to physical and network
    proximity. Moving Edge Controllers can only change to one of the neighbors, and
    the neighboring allows handoff between the fog nodes involved in the process.
    Additionally, fog nodes can connect either to a parent node or the cloud. Parent
    fog nodes allow data processing offloading if a particular fog node is overloaded.
    Further, parent fog nodes comprise physical regions providing specific services
    for a particular region they monitor. The physical distribution of fog nodes and
    their network topology should be guided by urban segmentation (districts, cities,
    and others). The granularity of this segmentation is flexible according to the
    needs. For instance, it is possible for a particular case distributing one fog
    node per district connected to a parent fog node of a city. Districts with higher
    populational density can have multiple fog nodes or even dedicated fog nodes for
    hospitals. Regardless of the granularity, the topology still respects VitalSense’s
    network topology. 3.2 Information naming service and data distribution Data management
    in the IoT world is one of the many challenges fog computing solutions face [30].
    Cloud-like systems traditionally employ centralized data storage solutions that
    require devices to transmit a high volume of data through the Internet (Fig. 7a).
    IoT devices can produce a massive amount of data sending it to the cloud at the
    cost of high latency. Health services that request this data also suffer from
    the same latency penalties. Fog computing addresses this drawback by allowing
    local data storing in fog nodes that are closer to the devices. Such a strategy
    comprises a distributed data storing solution in which data is scattered among
    several fog nodes (Fig. 7b). That makes data management complex since a particular
    device can move and change fog nodes on-the-fly. In such cases, fetching data
    from this particular device requires the system to lookup up its data in many
    locations. Fig. 7 Data distribution strategies: a traditional cloud-like systems
    in which the cloud centralizes the data; and b fog strategy scattering the data
    among several nodes Full size image VitalSense employs a data traceability strategy
    that offers two main features: user location tracking and faster data lookup.
    As users can move and connect to different fog nodes, their data can be scattered
    across several servers, imposing challenges to retrieve data from a given period.
    Therefore, we propose a new component called Information Naming Service (INS)
    placed in the cloud to maintain data track. The INS registers all handshake events
    edge-fog and handoff events fog-fog components perform. Therefore, it can track
    changes in the network topology and determine in which particular nodes data from
    a given device is stored. Each device has an Edge Controller registered in the
    INS. Edge Controllers have unique IDs which they inform fog nodes in the handshake
    process. Therefore, at each handshake and handoff process, fog nodes register
    in the INS the operation. The INS implements a naming system similar to the Internet
    DNS allowing queries given a particular ID. Figure 8 depicts a sequence diagram
    showing the operations that occur between Edge Controllers, fog nodes, and the
    INS. Fig. 8 Data storing and accessing sequence diagram using the INS to locate
    the data Full size image To access data from a device, the VitalSense queries
    the device ID in the INS. It can provide a specific time window to filter a target
    period. The INS provides the entries describing the device’s path and the time
    assigned for each fog node. Therefore, HealthStack can directly access the data
    in the fog nodes for further processing. For instance, we can employ sharding
    [31] techniques so HealthStack can access the node with the highest data volume
    or the closest node to fetches the data. When deploying a distributed data storage
    system, administrators should take several aspects into account [30]. Data sharding
    addresses several aspects, such as fault tolerance, scalability, and data distribution.
    However, there are others one should also consider: security, privacy, data dissemination,
    and data replication. 3.3 Distributed service processing VitalSense supports several
    services at the fog layer distributed among several nodes. The same service runs
    at different levels, enabling process offloading from one node to another. In
    other words, a particular fog node may offload a data sample to a different node
    to process the request. Data offloading is essential when a particular node is
    overwhelmed by too many requests that degrade its performance. Figure 9 presents
    the load distribution model performed by the Request Manager component of the
    fog nodes. The Request Receiver (1) decides where to process incoming requests
    according to user and service priorities and the prediction computed by a machine
    learning model in the Predictor Model (2). This particular module predicts how
    long the service execution will take to complete. Then, it delegates requests
    to the current node (3) in case it would not exceed the timeout or to the upper
    node (4) in case it would exceed. While the machine learning model is still learning
    services behavior, the prediction may not be completely accurate, especially in
    the first few executions. That may execute the request on the node but exceed
    the timeout for the first requests. Therefore, as we aim to ensure reliability
    if the execution exceeds the timeout, execution is re-executed on the upper node
    to benefit from unlimited processing capabilities. It is essential to mention
    that fog nodes are heterogeneous. Each has its model, enabling them to learn their
    particular behavior. Fig. 9 Request Manager responsible for processing and offloading
    requests: (1) decides where to process incoming requests based on predictions
    (2), and then it delegates requests to the current node (3) or the upper node
    (4) Full size image After executing the request, the Request Executor stores its
    duration so the Predictor Model can use this information to predict how long future
    executions will take to finish. Recent duration samples have a higher impact on
    predictions. Request parameters and inputs should also be stored in the database,
    as duration may vary depending on the input. In case of resources on the node
    are overloaded, and connection with the upper node is inaccessible, the Request
    Executor adds incoming requests to a queue. The task queue ensures no request
    will be discarded and reliability for time-sensitive services. If local resources
    become available again, the Request Executor executes queued requests locally.
    When the upper node is accessible again, but local resources are still overloaded,
    the Process Offloader vertically offloads requests to it. Depending on the workload
    of upper nodes, all nodes may be overloaded, and the Request Managers recursively
    offload them until it reaches the cloud. In this case, the request is processed
    without a time limit, executing with unlimited processing capabilities provided
    by cloud vendors. There are two types of priorities that the Request Receiver
    needs to consider when deciding which requests are the most important: (i) user
    priority; and (ii) service priority. Priorities impact the decision of the layer
    (closest fog node or parent fog nodes of the hierarchy) where the system should
    execute requests. The primary goal is to execute requests in the closest fog node
    whenever possible, resulting in low-latency responses because of the physical
    proximity between the edge devices and the node. All requests can be executed
    on the closest fog node when it has many computing resources available, regardless
    of the priority. On the other hand, low-priority requests should be offloaded
    to parent fog nodes when the platform is experiencing high usage peaks and when
    the closest fog node is overloaded. User priority is essential when specific users
    should receive more attention than others, such as elderly people or groups in
    risky situations in the health field, that should have their requests executed
    with the lowest possible latency. The latter is related to the priority of the
    service itself, as specific services may be more critical than others. It is important
    to highlight that user priority is dynamic and is received on the request payload,
    as a person with health problems may become healthier after some time, and further
    requests should indicate lower priorities. The service priority is typically static
    and does not change over time unless the service is re-deployed or the priority
    is globally reconfigured and, for this reason, is fetched from the database. The
    Request Receiver module is responsible for combining both information on a single
    numeric value. It combines both values and computes a rank value, as detailed
    in Fig. 10. Critical services with high user priority can be the first to run
    on the closest fog node. In contrast, requests for low-priority services with
    low-priority users are more feasible to execute on parent fog nodes like the cloud.
    In summary, the rule to combine both values is to sum both priorities, while the
    ranking is this final result. Fig. 10 Ranking combining both service and user
    priorities, with intense colors representing the most important requests Full
    size image 4 Deployment and use cases This section explores application use cases
    that can leverage VitalSense capabilities. In addition, we demonstrate how to
    deploy the architecture from a bottom-up point of view. 4.1 Architecture deployment
    instance Figure 11 presents each architecture module’s deployment, including infrastructure
    aspects. The deployment base regards the IoT devices at the individual’s house.
    The target person wears a wrist device, such as a smartwatch, that monitors several
    vital signs. The Edge Collector can be deployed either in a single-board computer
    at the individual’s home or on his smartphone. Therefore, it can reach the smartwatch
    to extract data using either WiFi or Bluetooth. An Internet connection using a
    Modem/Router enables communication with the fog network from edge to fog. Virtual
    Private Network (VPN) and MPLS technologies can guarantee this connection’s privacy
    and performance, ensuring QoS in data transmission. Fig. 11 Example of a VitalSense’s
    architecture deployment in a smart city Full size image The network comprises
    several links among fog nodes distributed over the city at the fog. For instance,
    one can deploy a fog node server in public utility poles, network racks, shops,
    markets, hospitals, and others. The main requirement is that the network infrastructure
    for these fog nodes provides performance guarantees, using VPN and MPLS as an
    example. This infrastructure is the same when connecting the fog with the cloud.
    Therefore, the end of the infrastructure is the cloud data centers, which also
    connect to the Internet providing its endpoints to fog nodes. In addition, user
    applications can connect to the cloud Services using their public Internet connection
    likewise standard services and websites. VitalSense supports the development of
    several services to run at all levels of the architecture. Different data types
    are available depending on the level from which applications benefit. Applications
    may vary from dashboards to prediction algorithms to generate alerts. The following
    sections describe different use cases. 4.2 Risk exposure control Figure 12 represents
    a risk exposure management system where the user can monitor the time of exposure
    to risk regions in a time frame. It consists of path monitoring that crosses location
    data with risk region classifications. Each zone can be classified depending on
    health parameters from users in each region. In addition, the public health system
    and the patients themselves can report to the system their current status. Machine
    learning techniques can classify each region by combining different data sources.
    Depending on the case, a high-risk region can mean a different thing. For instance,
    an infectious disease monitoring system can report exposure time to the disease
    and the potential for contraction. Another example is a hazard exposure system
    that can track and alert users to avoid crossing a specific area due to a gas
    leak or fire. Fig. 12 Risk exposure control system Full size image Besides providing
    alerts directly to users, such a system also provides valuable information to
    the public administrators. For instance, dashboards built on top of the information
    show the real-time status of several regions. In regions where risks are increasing,
    administrators can take proactive actions to mitigate potential threats to the
    population. In addition, they can generate public alerts to the population according
    to how the situation in specific regions degrades. When the system detects a leak
    of toxic solutions or airborne diseases, it can automatically isolate the area.
    At the same time, the public emergency department gets alerts asking for proactive
    aid. Being proactive in such scenarios can significantly improve health assistance
    services. 4.3 Proactive service delivery Figure 13 demonstrates a proactive service
    delivery in which a hospital dispatches an ambulance when receiving a proactive
    alert from the fog. In this scenario, a user wears a heart monitoring sensor providing
    data to the system. The Edge Controller collects the data in real-time and forwards
    samples to the fog. A real-time analysis service processes the data performing
    predictions to identify possible cardiac failures. The fog notifies the public
    health system of an upcoming emergency. Thus, the closest available ambulance
    can answer the call and proactively attend to the patient in its own home. Fig.
    13 Proactive ambulance attendance Full size image Although the figure presents
    a specific case for heart monitoring, such a service works for several data types.
    For instance, the same service works for fall detection of the elderly or leak
    detection of toxic substances. It can generate complex predictions for entire
    regions when combining data from numerous sensors, including multiple locations.
    Multiple users reporting increasing fever and cough in a particular region can
    indicate a disease outbreak. The use of predictions in health services can mitigate
    public health crises or even prevent people from exposing themselves to dangerous
    situations. In addition to providing alerts to the public health system, the user
    can also receive notifications about hazards or health crises. Therefore, users
    can also proactively seek medical assistance in advance. Combined with the previous
    service, the user can receive real-time alerts when entering predicted risk regions.
    4.4 Public health control dashboard Fig. 14 Dashboard condensing several patient
    data into a single panel by region in real-time. The map allows zoom in and out
    of specific regions Full size image The presentation of clinical data summarized
    in a single panel or dashboard is increasingly in evidence. They are tools that
    use visual representations of data to allow a lower load of cognitive processing.
    Therefore, they increase the speed and accuracy of decision-making. Visual representations
    facilitate the identification of trends, patterns, or abnormalities in a given
    database compared to data analysis without a structure [32]. Figure 14 demonstrates
    what a dashboard would look like condensing several patient data into a single
    panel. Collecting sensor data makes it possible to monitor entire regions, including
    detecting the most critical regions and problems. Also, it is possible to present
    the current status of the region’s vital signs and zoom in on micro-regions according
    to a specific parameter. Although the panel presents data from several individuals,
    it is possible to navigate data from specific patients, for example. Such dashboards
    may be available at different levels, including for the health provider or the
    government with data aggregation. The design used for the visual resources in
    a dashboard must seek a balance between visual complexity and the usefulness of
    the information. Essentially, dashboards should be tailored to the intended purpose
    and the end-user, considering their analytical skills and level of knowledge.
    The patient’s perspective needs to be repeatedly emphasized. The presentation
    of data in graphs should be the choice when comparing, grouping, or recognizing
    patterns in the information [33]. In other situations, tables should be the choice
    when there is a need to evaluate specific values [33]. Due to the complexity,
    one should avoid the presentation of information in formulas and fractions. Other
    details, such as the presentation of specific values with the same number of decimal
    places and the same scale on their axes of the graphs, must also be observed to
    avoid biases in the interpretation of the information displayed. Using color schemes
    helps draw attention to results that indicate an area of concern, such as increased
    body temperature or decreased blood oxygenation. The colors green or blue, yellow
    or orange, and red should preferably be chosen to sequentially indicate the risk
    or severity of a physiological abnormality [34]. Gray color alerts can indicate
    system problems during the recovery of elements that make up the information to
    be visualized. Noteworthy, clinical indicators of a health condition must be based
    on scientific evidence and be recognized in national guidelines [35]. In addition
    to the different indicative colors, the system can notify the user with alert
    services to indicate that certain data is outside predetermined limits. Alert
    services can be designed to generate links to help the user make a decision, such
    as providing the option to call an emergency service or a specialized service,
    send a message or email to the responsible doctor with details of the condition,
    or even to seek information about why the alert was issued. 5 Discussion and preliminary
    experiments VitalSense is a solution developed as part of two research projects:
    MinhaHistoriaDigital (MyDigitalHistory) and MinhaSaudeDigital ( MyDigitalHealth),
    which focus on public health issues in Brazil. The main goal of the current research
    is to develop and deploy the infrastructure in the city of Porto Alegre, Rio Grande
    do Sul, Brazil. This section introduces the initial experiments and considerations
    regarding the development and deployment of VitalSense. Section 5.1 presents preliminary
    experiments using Sharding to test the performance of the data distribution strategy.
    Following, Section 5.2 introduces the primary IoT devices available in the market
    to monitor vital signs. 5.1 Data distribution efficiency using sharding We performed
    preliminary experiments to validate the model’s data distribution efficiency using
    Sharding in a Docker-based infrastructure to individualize processing on a single
    computer. The host configuration consists of an Intel Core i7 Hexa-core 2.6 GHz,
    16GB of DDR4 Dual-Channel 2667 MHz RAM, and an SSD with a read and write rate
    of 3200 MB/s and 2200 MB/sec, respectively. We employed MongoDB as a database
    that implements Sharding straightforwardly and efficiently. As shown in Fig. 15,
    as it is a requirement to use sharding in MongoDB, we added a configuration server
    to the model that stores the metadata of the location of records in the structure.
    Fig. 15 Evaluation methodology using two Sharding instances Full size image We
    established two preliminary scenarios to validate the model’s efficiency using
    Sharding (with two nodes) compared to a centralized database. The first scenario
    performs a search using a filter by the server in the query. In the second, the
    query was performed without filtering, returning the entire database. Both scenarios
    consider a database with over 2 million records from which we retrieve a sample
    of data in 10 different executions. Figure 16 presents the results for both scenarios.
    Fig. 16 Response time when querying data from the database with and without Sharding
    Full size image Preliminary results show that employing Sharding leads to an improvement
    of approximately 20% in the query response time. The proximity factor with the
    data is not applicable in the experiments since the instances run in the same
    machine; otherwise, it would bring even more advantages to Sharding in a real
    distributed scenario. With Sharding, results show an average response time of
    1.36 and 1.38 s (with a standard deviation of 0.1350 and 0.0919 s) in the first
    and second scenarios. Without Sharding, the response time is 1.66 and 1.78 s (with
    a standard deviation of 0.1430 and 0.1751 s) for the first and second scenarios.
    In the experiments with Sharding, the search time of all records in both nodes
    or a single node is practically the same. Due to the data distribution among several
    servers, the query runs concurrently, distributing the workload. The preliminary
    experiments show the advantages of distributing data among several fog nodes instead
    of centralizing them in the cloud. In addition to improving response time when
    querying data, it also enhances the performance of the whole network by not forwarding
    data from all sensors up to the cloud. Furthermore, applications can request data
    from the Fog infrastructure and benefit from faster data transmission since the
    Fog is closer to the application than the cloud. 5.2 Directions on vital sign
    monitoring Currently, we are witnessing a rise in IoT solutions for self-health
    monitoring. Each day new devices are available in the market so everyone can buy
    and monitor their vital signs using smartphone applications. IoT devices constitute
    the basis of vital sign remote monitoring systems, providing health data from
    individuals in real-time. The lack of this information can compromise the feasibility
    of the solutions since they depend on patient health data extraction. Nowadays,
    several solutions propose specific monitoring devices that are slowly becoming
    off-the-shelf products available for everyone. Although numerous devices are available,
    they are not entirely tailored to support a massive monitoring system. Their primary
    focus is to provide information to whom is wearing the device through proprietary
    smartphone applications. In addition, most devices equip only a few sensors, which
    may require patients to wear more than one device for remote health monitoring.
    Table 2 Devices details: Respiratory Rate (RR); Heart Rate (HR); Heart Rate Variability
    (HRV); Body temperature (BT); and Oxygen Saturation (SpO2) Full size table Wearing
    several devices is acceptable when the individual is already a patient who can
    stay at home for remote monitoring after already identifying a medical condition.
    However, when focusing on proactive health monitoring, it is not feasible for
    individuals to wear several devices during daily activities. Daily health monitoring
    should be seamless from the patient’s point of view. It should not impose discomfort
    and restrictions on individuals’ activities. That is only possible through devices
    equipped with several sensors at once. Therefore, individuals can only wear a
    unique device, such as a smartwatch or smart band. Thus, this device can support
    several communication protocols to provide data from several sensors in a standard
    format. To assess the availability of such devices, we performed research in the
    market looking for candidate personal health monitoring devices to integrate the
    VitalSense model. We evaluated 149 devices, including smartwatches, smart bands,
    and smart rings, analyzing the sensors they equip, security features, API availability,
    and communication protocols. We ruled out all devices with only one or two sensors
    since we focus on devices that support a broad set of sensors. Table 2 compares
    40 resulting smart IoT devices that equip several vital sign sensors. The table
    shows that heart rate and SpO2 sensors are the most common among the devices.
    Besides, only seven devices provide all vital signs sensors, representing 4.7%
    of the entire set of 149 devices. Although several devices are available, just
    a few support a complete set of sensors, demonstrating a lack of devices for vital
    sign remote monitoring solutions. Future research should focus intensely on this
    topic since it can limit the potential o vital sign remote health monitoring solutions.
    VitalSense works with edge, fog, and cloud computing, bringing an idea of districts
    where fog nodes operate. In other words, our architecture was first planned to
    cover urban areas. However, we can extend this coverage area to rural areas by
    adopting technological requirements. In our understanding, power supply and Internet
    communication are the most expressive problems in agricultural areas. Some strategies
    could be taken to aggregate them, such as: (i) we can use battery-based IoT wearables
    devices to collect vital signs; (ii) we can use long-range radio frequency technologies.
    For both cases, LoRa and LoRaWAN appear as one of the best initiatives to connect
    rural areas. LoRa and LoRaWAN define a Low Power Wide Area (LPWA) networking protocol
    designed to wirelessly connect battery-operated devices to the Internet in regional,
    national, or global networks. Moreover, this duet targets critical IoT requirements
    such as bi-directional communication, end-to-end security, mobility, and localization
    services. Considering the device scope, we have a battery duration of up to 10
    years today. Considering the network viewpoint, the LoRaWAN data rate ranges from
    0.3 kbit/s to 50 kbit/s per channel. This bandwidth is entirely acceptable for
    transferring vital sign data of a family. For Example, Fig. 17 illustrates JSON
    data with a person’s vital signs where the whole message has less than 200 bytes.
    Fig. 17 Example of a JSON data packet representing vital sign collection of a
    person Full size image 6 Final remarks We envisage that AI, edge/fog, geolocation-based
    sharding, resource elasticity, and data compression will support the new vision
    of smart health cities. VitalSense aims to provide benefits for the following
    group of users: (i) citizens, who will have their data monitored and will receive
    alerts regarding possible problems in their vital signs, as well as alerts regarding
    the spread of diseases in places in the city and, in particular, those frequently
    visited by the individual in question; (ii) public managers, who will have a real-time
    macro view of specific and historical population data, being able to direct public
    policies for certain groups of people or districts of the city; (iii) hospital
    managers with access to municipal data regarding the management and prediction
    of the spread of COVID-19 can allocate teams and request public funds in advance
    to increase the chances that human lives are saved. The model introduces several
    contributions spread throughout the document: Employment of data compression and
    homomorphic encryption at the edge (Sections 3.1.1 and 3.1.2); A multi-tier notification
    mechanism (Sections 3.1.1, 3.1.2, and 3.1.3); Low latency health traceability
    with data sharding (Section 3.2); Serverless engine, container elasticity, and
    process offloading mechanism (Section 3.3); Live geographical-based dashboards
    for data visualization (Section 3.1.3). In addition to the aforementioned technical
    contributions, it is essential to outline some social contributions and how the
    authors see the healthcare future. We envisage a collection of AI-based latency-oriented
    services seemingly incorporated into the citizens’ daily lives, bringing a novel
    set of notifications, dashboards, and integration among people, communities, hospitals,
    and the public sector. In this scope, VitalSense is a deployment possibility to
    enable digital healthcare monitoring truly. Below we present some healthcare scenarios
    in which we can live in the short and mid-term: Analyzing a person’s vital signs,
    a hospital or clinic can send a vehicle to the house of a possible patient, as
    it is predicted that they are feeling unwell and may die soon; I want to go to
    the supermarket, and I am trying to decide which one to go to and which would
    be safer. I can see the citizens tracking information, people who have/had COVID-19,
    and if they have frequented that establishment; Analyzing vital signs data from
    different city neighborhoods and seeing that the situation is worsening with event
    prediction, a hospital (or more than one) can prepare human resources and physical
    infrastructure beforehand to receive new patients; We can analyze which type of
    disease occurs more frequently in a given scenario. In detail, we can explore
    trends and disease seasonality to get insights like this: the older the age group,
    the higher the incidence of this particular disease; It is also possible to apply
    public health policies personalized by districts and neighborhoods, given that
    there is a higher incidence of a certain disease. Using people’s tracking data,
    the public sector can check whether the lockdown works; By getting data on a smart
    city scale, we can identify areas with worsening mental health of post-COVID-19
    patients, such as anxiety and depression crises due to the loss of family members.
    Thus, the government can assist them by indicating therapeutic follow-up/medical
    consultation; Citizens can be alerted about personal or family health problems
    and receive information about their community. VitalSense is a solution in development
    as part of two projects: MinhaHistoriaDigital (MyDigitalHistory) and MinhaSaúdeDigital
    (MyDigitalHealth). They focus on the public health area in Brazil and are supported
    by development agencies in that country. Privacy is a primary concern in such
    a scenario, so the VitalSense hash strategy is based on the GPDR. We are basing
    the model’s decisions on the regulation and are currently working on this front.
    Future work comprises the end-to-end deployment of the three levels. Although
    we have preliminary results, to the best of our knowledge, we are the first to
    explore internal novelties in the layers and think about interconnections between
    them. Data availability Not Applicable. Code availability Not Applicable. Notes
    https://gdpr.eu/ References Philip NY, Rodrigues JJPC, Wang H, Fong SJ, Chen J.
    Internet of things for in-home health monitoring systems: Current advances, challenges
    and future directions. IEEE J Sel Areas Commun. 2021;39(2):300–10. https://doi.org/10.1109/JSAC.2020.3042421.
    Article   Google Scholar   Rekha G, Yashaswini J. In: Tyagi, A.K., Abraham, A.,
    Kaklauskas, A. (eds.) Industry 4.0: A Revolution in Healthcare Sector via Cloud,
    Fog Technologies; 2022. pp. 321–335. Springer, Singapore. https://doi.org/10.1007/978-981-16-6542-4_16.
    Tortorella GL, Fogliatto FS, Mac Cawley Vergara A, Vassolo R, Sawhney R. Healthcare
    4.0: trends, challenges and research directions. Prod Plan Control. 2020;31(15),
    1245–1260. da Costa CA, Pasluosta CF, Eskofier B, da Silva DB, da Rosa Righi R.
    Internet of health things: Toward intelligent vital signs monitoring in hospital
    wards. Artif Intell Med. 2018;89:61–9. https://doi.org/10.1016/j.artmed.2018.05.005.
    Article   Google Scholar   Shukla S, Hassan MF, Tran DC, Akbar R, Paputungan IV,
    Khan MK. Improving latency in Internet-of-Things and cloud computing for real-time
    data transmission: a systematic literature review (SLR). Clust Comput. 2021;3.
    https://doi.org/10.1007/s10586-021-03279-3. Buschmann P, Shorim MHM, Helm M, Bröring
    A, Carle G. Task allocation in industrial edge networks with particle swarm optimization
    and deep reinforcement learning. In: Proceedings of the 12th International Conference
    on the Internet of Things. IoT 2022, pp. 239–247. Association for Computing Machinery,
    New York, NY, USA (2023). https://doi.org/10.1145/3567445.3571114. Rodrigues VF,
    Righi RdR, da Costa CA, Antunes RS. Smart hospitals and iot sensors: Why is qos
    essential here? J Sens Actuator Netw. 2022;11(3). https://doi.org/10.3390/jsan11030033.
    Aazam M, Zeadally S, Harras KA. Fog computing architecture, evaluation, and future
    research directions. IEEE Commun Mag. 2018;56(5):46–52. https://doi.org/10.1109/MCOM.2018.1700707.
    Article   Google Scholar   Tuli S. Ai and co-simulation driven resource management
    in fog computing environments. SIGMETRICS Perform Eval Rev. 2023;50(3):16–9. https://doi.org/10.1145/3579342.3579347.
    Article   Google Scholar   Parimala Devi M, Raja GB, Gowrishankar V, Sathya T.
    In: Chakraborty C, Banerjee A, Garg L, Rodrigues JJPC. (eds.) IoMT-Based Smart
    Diagnostic/Therapeutic Kit for Pandemic Patients; 2020. pp. 141–165. Springer,
    Singapore. https://doi.org/10.1007/978-981-15-8097-0_6. Dong Y, Yao Y-D. Iot platform
    for covid-19 prevention and control: A survey. IEEE Access. 2021;9:49929–41. https://doi.org/10.1109/ACCESS.2021.3068276.
    Article   Google Scholar   Sahu ML, Atulkar M, Ahirwal MK, Ahamad A. Vital sign
    monitoring system for healthcare through iot based personal service application.
    Wirel Pers Commun. 2022;122(1):129–56. https://doi.org/10.1007/s11277-021-08892-4.
    Article   Google Scholar   Rahman MJ, Morshed BI, Harmon B, Rahman M. A pilot
    study towards a smart-health framework to collect and analyze biomarkers with
    low-cost and flexible wearables. Smart Health. 2022;23:100249. https://doi.org/10.1016/j.smhl.2021.100249.
    Li F, Valero M, Shahriar H, Khan RA, Ahamed SI. Wi-covid: A covid-19 symptom detection
    and patient monitoring framework using wifi. Smart Health. 2021;19:100147. https://doi.org/10.1016/j.smhl.2020.100147.
    Al Bassam N, Hussain SA, Al Qaraghuli A, Khan J, Sumesh EP, Lavanya V. Iot based
    wearable device to monitor the signs of quarantined remote patients of covid-19.
    Informatics in Medicine Unlocked. 2021;24: 100588. https://doi.org/10.1016/j.imu.2021.100588.
    Paganelli AI, Velmovitsky PE, Miranda P, Branco A, Alencar P, Cowan D, Endler
    M, Morita PP. A conceptual iot-based early-warning architecture for remote monitoring
    of covid-19 patients in wards and at home. Internet of Things. 2021;100399. https://doi.org/10.1016/j.iot.2021.100399.
    Mukherjee A, Ghosh S, Behere A, Ghosh SK, Buyya R. Internet of health things (ioht)
    for personalized health care using integrated edge-fog-cloud network. J Ambient
    Intell Humaniz Comput. 2021;12:943–59. Article   Google Scholar   Chudhary R,
    Sharma S. Fog-cloud assisted framework for heterogeneous internet of healthcare
    things. Procedia Computer Science. 2021;184, 194–201. https://doi.org/10.1016/j.procs.2021.03.030.
    The 12th International Conference on Ambient Systems, Networks and Technologies
    (ANT) / The 4th International Conference on Emerging Data and Industry 4.0 (EDI40)
    / Affiliated Workshops. Sangeetha D, Rathnam MV, Vignesh R, Chaitanya JS, Vaidehi
    V. In: Vijayakumar, V., Neelanarayanan, V., Rao, P., Light, J. (eds.) MEDIDRONE—A
    Predictive Analytics-Based Smart Healthcare System; 2020. pp. 19–33. Springer,
    Singapore. https://doi.org/10.1007/978-981-32-9889-7_2. Priambodo R, Kadarina
    TM. Monitoring self-isolation patient of covid-19 with internet of things. In:
    2020 IEEE International Conference on Communication, Networks and Satellite (Comnetsat);
    2020. pp. 87–91. https://doi.org/10.1109/Comnetsat50391.2020.9328953. Aziz K,
    Tarapiah S, Ismail SH, Atalla S. Smart real-time healthcare monitoring and tracking
    system using gsm/gps technologies. In: 2016 3rd MEC International Conference on
    Big Data and Smart City (ICBDSC); 2016. pp. 1–7. https://doi.org/10.1109/ICBDSC.2016.7460394.
    Sicari S, Rizzardi A, Coen-Porisini A. Home quarantine patient monitoring in the
    era of covid-19 disease. Smart Health. 2022;23:100222. https://doi.org/10.1016/j.smhl.2021.100222.
    Rahmani AM, Gia TN, Negash B, Anzanpour A, Azimi I, Jiang M, Liljeberg P. Exploiting
    smart e-health gateways at the edge of healthcare internet-of-things: A fog computing
    approach. Futur Gener Comput Syst. 2018;78:641–58. https://doi.org/10.1016/j.future.2017.02.014.
    Article   Google Scholar   Kamel Boulos MN, Berry G. Real-time locating systems
    (rtls) in healthcare: a condensed primer. Int J Health Geogr. 2012;11(1):1–8.
    Article   Google Scholar   Xu X, Lu Y, Vogel-Heuser B, Wang L. Industry 4.0 and
    industry 5.0-inception, conception and perception. J Manuf Syst. 2021;61:530–5.
    Article   Google Scholar   Chabi Sika Boni AK, Hablatou Y, Hassan H, Drira K.
    Distributed deep reinforcement learning architecture for task offloading in autonomous
    iot systems. In: Proceedings of the 12th International Conference on the Internet
    of Things. IoT 2022; 2023. pp. 112–118. Association for Computing Machinery, New
    York, NY, USA. https://doi.org/10.1145/3567445.3567454. Xiao X, Hannan A, Bailey
    B, Ni LM. Traffic engineering with mpls in the internet. IEEE Netw. 2000;14(2):28–33.
    https://doi.org/10.1109/65.826369. Article   Google Scholar   Yang Z, Cui Y, Li
    B, Liu Y, Xu Y. Software-defined wide area network (sd-wan): Architecture, advances
    and opportunities. In: 2019 28th International Conference on Computer Communication
    and Networks (ICCCN); 2019. pp. 1–9. https://doi.org/10.1109/ICCCN.2019.8847124.
    Alloghani M, Alani MM, Al-Jumeily D, Baker T, Mustafina J, Hussain A, Aljaaf AJ.
    A systematic review on the status and progress of homomorphic encryption technologies.
    J Inf Secur Appl. 2019;48:102362. https://doi.org/10.1016/j.jisa.2019.102362.
    Moysiadis V, Sarigiannidis P, Moscholios I. Towards distributed data management
    in fog computing. Wirel Commun Mob Comput. 2018;2018. Abdelhafiz BM, Elhadef M.
    Sharding database for fault tolerance and scalability of data. In: 2021 2nd International
    Conference on Computation, Automation and Knowledge Management (ICCAKM); 2021.
    pp. 17–24. https://doi.org/10.1109/ICCAKM50778.2021.9357711. Rouhani S, Zamenian
    S. An architectural framework for healthcare dashboards design. J Healthc Eng.
    2021;2021, 1964054. https://doi.org/10.1155/2021/1964054. Simpson SH. Creating
    a data analysis plan: What to consider when choosing statistics for a study. Can
    J Hosp Pharm. 2015;68(4):311–7. https://doi.org/10.4212/cjhp.v68i4.1471. Article   MathSciNet   Google
    Scholar   Caroline Gonçales P, Pinto Júnior D, de Oliveira Salgado P, Machado
    Chianca TC. Relationship between risk stratification, mortality and length of
    stay in a emergency hospital. Invest Educ Enferm. 2015;33(3):424–431. https://doi.org/10.17533/udea.iee.v33n3a05.
    Ghazisaeidi M, Safdari R, Torabi M, Mirzaee M, Farzi J, Goodini A. Development
    of performance dashboards in healthcare sector: Key practical issues. Acta informatica
    medica : AIM : journal of the Society for Medical Informatics of Bosnia & Herzegovina :
    casopis Drustva za medicinsku informatiku BiH. 2015;23(5):317–21. https://doi.org/10.5455/aim.2015.23.317-321.
    Article   Google Scholar   Download references Acknowledgements The authors would
    like to thank the following Brazilian Agencies for supporting this work: the Research
    Support Foundation of the Rio Grande do Sul State (FAPERGS, processes 19/2551–0001340-0
    and 21/2551–0000118-6); Coordination for the Improvement of Higher Education Personnel
    (CAPES, financial code 001); National Council for Scientific and Technological
    Development (CNPq, grant numbers 309537/2020–7 and 305263/2021–8). Funding This
    work was supported by the following Brazilian agencies: the Research Support Foundation
    of the Rio Grande do Sul State (FAPERGS, processes 19/2551–0001340-0 and 21/2551–0000118-6);
    Coordination for the Improvement of Higher Education Personnel (CAPES, financial
    code 001); National Council for Scientific and Technological Development (CNPq,
    grant numbers 309537/2020–7 and 305263/2021–8). Author information Authors and
    Affiliations Applied Computing Graduate Program, Universidade do Vale do Rio dos
    Sinos (UNISINOS), São Leopoldo, Brazil Vinicius Facco Rodrigues, Rodrigo da Rosa
    Righi & Cristiano André da Costa Friedrich-Alexander-Universität Erlangen-Nürenberg
    (FAU), Erlangen, Germany Felipe André Zeiser & Bjoern Eskofier Korea Advanced
    Institute of Science and Technology (KAIST), Daejeon, South Korea Andreas Maier
    Contributions All authors contributed to the study conception and design. In particular,
    Rodrigo Righi and Vinicius Facco worked in the VitalSense technologies. Cristiano
    da Costa and Bjoern Eskofier focused on reviewing the Related Work section, also
    detailing the open gaps in the literature. Daeyoung Kim revised the modules composition
    of the Edge, Fog and Cloud architectures. Andreas Mayer focused on analyzing information
    in Section 4, where we present the Deployment and Use Cases. All authors contributed
    to final modifications in the article, including more details in Corresponding
    author Correspondence to Rodrigo da Rosa Righi. Ethics declarations Competing
    interests Not Applicable. Additional information Publisher''s Note Springer Nature
    remains neutral with regard to jurisdictional claims in published maps and institutional
    affiliations. Rights and permissions Springer Nature or its licensor (e.g. a society
    or other partner) holds exclusive rights to this article under a publishing agreement
    with the author(s) or other rightsholder(s); author self-archiving of the accepted
    manuscript version of this article is solely governed by the terms of such publishing
    agreement and applicable law. Reprints and permissions About this article Cite
    this article Rodrigues, V.F., da Rosa Righi, R., da Costa, C.A. et al. Digital
    health in smart cities: Rethinking the remote health monitoring architecture on
    combining edge, fog, and cloud. Health Technol. 13, 449–472 (2023). https://doi.org/10.1007/s12553-023-00753-3
    Download citation Received 22 February 2023 Accepted 06 April 2023 Published 27
    April 2023 Issue Date June 2023 DOI https://doi.org/10.1007/s12553-023-00753-3
    Share this article Anyone you share the following link with will be able to read
    this content: Get shareable link Provided by the Springer Nature SharedIt content-sharing
    initiative Keywords Digital health Smart city Remote health monitoring Internet
    of things Fog computing Edge computing Use our pre-submission checklist Avoid
    common mistakes on your manuscript. Sections Figures References Abstract Introduction
    Related work The VitalSense model Deployment and use cases Discussion and preliminary
    experiments Final remarks Data availability Code availability Notes References
    Acknowledgements Funding Author information Ethics declarations Additional information
    Rights and permissions About this article Advertisement Discover content Journals
    A-Z Books A-Z Publish with us Publish your research Open access publishing Products
    and services Our products Librarians Societies Partners and advertisers Our imprints
    Springer Nature Portfolio BMC Palgrave Macmillan Apress Your privacy choices/Manage
    cookies Your US state privacy rights Accessibility statement Terms and conditions
    Privacy policy Help and support 129.93.161.222 Big Ten Academic Alliance (BTAA)
    (3000133814) - University of Nebraska-Lincoln (3000134173) © 2024 Springer Nature"'
  inline_citation: '>'
  journal: Health and Technology
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: 'Digital health in smart cities: Rethinking the remote health monitoring
    architecture on combining edge, fog, and cloud'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Anees T.
  - Habib Q.
  - Al-Shamayleh A.S.
  - Khalil W.
  - Obaidat M.A.
  - Akhunzada A.
  citation_count: '4'
  description: The Web of Things is an improvement on the Internet of Things (IoT)
    that incorporates smart objects into both the web architecture (application) and
    the internet (network). WoT applications are inescapable in residential homes
    and communities. The intent behind WoT applications is to increase sustainable
    development for reducing resource consumption. The Web of Things (WoT) aims to
    create a decentralized Internet of Things. Edge computing addresses IoT computing
    demands by reducing the escalation in resource congestion situations. In edge
    computing data is placed closed to the end users which diverts computation load
    from the centralized data centers. Furthermore, the dispersed structure balances
    network traffic and minimizes traffic peaks in IoT networks. Therefore, resulting
    in reducing transmission delays between edge servers and end users which improves
    response times for real-time WoT applications. Low battery supply to nodes with
    enough power resources can increase the lifespan of the individual nodes by moving
    processing and communication overhead from the nodes. This paper integrates WoT
    and edge computing and compares their functionalities. In addition, it demonstrates
    how edge computing enhances WoT performance and concentrates on transmission,
    storage, and computation aspects. Furthermore, for performance evaluation it categorizes
    edge computing based on different architectures. Moreover, the challenges of Web
    of Things and edge computing have been discussed in terms of bandwidth, latency,
    energy, and cost. Finally, advantages of the Web of Things and edge computing
    have been discussed.
  doi: 10.3390/su15075983
  full_citation: '>'
  full_text: '>

    "This website uses cookies We use cookies to personalise content and ads, to provide
    social media features and to analyse our traffic. We also share information about
    your use of our site with our social media, advertising and analytics partners
    who may combine it with other information that you’ve provided to them or that
    they’ve collected from your use of their services. Consent Selection Necessary
    Preferences Statistics Marketing Show details                 Deny Allow selection
    Allow all    Journals Topics Information Author Services Initiatives About Sign
    In / Sign Up Submit   Search for Articles: Sustainability All Article Types Advanced   Journals
    Sustainability Volume 15 Issue 7 10.3390/su15075983 Submit to this Journal Review
    for this Journal Propose a Special Issue Article Menu Academic Editors Torsten
    Reimer Julia Rayz Subscribe SciFeed Recommended Articles Related Info Link More
    by Authors Links Article Views 2111 Citations 6 Table of Contents Abstract Introduction
    Review of WoT and Edge Computing Integration of Wot and Edge Computing Challenges
    and Advantages of Edge Computing and WoT Future Challenges Conclusions and Future
    Remarks Author Contributions Funding Institutional Review Board Statement Informed
    Consent Statement Data Availability Statement Conflicts of Interest References
    share Share announcement Help format_quote Cite question_answer Discuss in SciProfiles
    thumb_up Endorse textsms Comment first_page settings Order Article Reprints Open
    AccessArticle The Integration of WoT and Edge Computing: Issues and Challenges
    by Tayyaba Anees 1, Qaiser Habib 1, Ahmad Sami Al-Shamayleh 2, Wajeeha Khalil
    3, Muath A. Obaidat 4 and Adnan Akhunzada 5,* 1 Department of Software Engineering,
    School of Systems and Technology, University of Management and Technology, Lahore
    54770, Pakistan 2 Department of Networks and Cybersecurity, Faculty of Information
    Technology, Al-Ahliyya Amman University, Amman 19328, Jordan 3 Department of Computer
    Science and Information Technology, Peshawar Campus, University of Engineering
    and Technology, Peshawar 25000, Pakistan 4 Department of Computer Science, City
    University of New York, New York, NY 10019, USA 5 College of Computing & IT, University
    of Doha for Science and Technology, Doha 24449, Qatar * Author to whom correspondence
    should be addressed. Sustainability 2023, 15(7), 5983; https://doi.org/10.3390/su15075983
    Submission received: 6 February 2023 / Revised: 15 March 2023 / Accepted: 16 March
    2023 / Published: 30 March 2023 (This article belongs to the Special Issue The
    Application of Communication Technology in Smart Residential Communities) Download
    keyboard_arrow_down     Browse Figures Review Reports Versions Notes Abstract
    The Web of Things is an improvement on the Internet of Things (IoT) that incorporates
    smart objects into both the web architecture (application) and the internet (network).
    WoT applications are inescapable in residential homes and communities. The intent
    behind WoT applications is to increase sustainable development for reducing resource
    consumption. The Web of Things (WoT) aims to create a decentralized Internet of
    Things. Edge computing addresses IoT computing demands by reducing the escalation
    in resource congestion situations. In edge computing data is placed closed to
    the end users which diverts computation load from the centralized data centers.
    Furthermore, the dispersed structure balances network traffic and minimizes traffic
    peaks in IoT networks. Therefore, resulting in reducing transmission delays between
    edge servers and end users which improves response times for real-time WoT applications.
    Low battery supply to nodes with enough power resources can increase the lifespan
    of the individual nodes by moving processing and communication overhead from the
    nodes. This paper integrates WoT and edge computing and compares their functionalities.
    In addition, it demonstrates how edge computing enhances WoT performance and concentrates
    on transmission, storage, and computation aspects. Furthermore, for performance
    evaluation it categorizes edge computing based on different architectures. Moreover,
    the challenges of Web of Things and edge computing have been discussed in terms
    of bandwidth, latency, energy, and cost. Finally, advantages of the Web of Things
    and edge computing have been discussed. Keywords: Web of Things; edge computing
    1. Introduction The internet has grown to be a crucial medium for online communication
    nowadays. On the other hand, small embedded servers are now readily available
    thanks to decades of research into the technology of a small web server. Web services
    in particular have shown to be crucial for developing interactive applications
    on the internet nowadays. Smart components with embedded web servers are readily
    added into an existing website as web resources. Reusing current web standards
    and technology to connect the online and offline worlds is only logical. In light
    of this, a study application views IoT as part of the Web of Things (WoT). With
    the help of smart devices, existing web technologies may be improved and repurposed
    to provide new apps and services, flexibility, personalization, and high productivity.
    In brief, WoT allows the devices to speak the same language in order to be able
    to communicate and interact with one another, which is distinct from the standard
    IoT approach that assigns the device an ordinary IP address and permits the device
    to connect to the internet and work online more freely. A collection of web services
    may be located, labeled, and utilized according to the WoT idea. By expanding
    web-only services from the network world to the online world and worldwide services,
    it therefore broadens the spectrum of traditional web services. Additionally,
    WoT is actually an ecosystem of services that aims to arrange various service
    kinds in a helpful manner to make them more intelligent and human-centered. The
    internet has grown to be a crucial medium for online communication nowadays. Consumers
    may now choose from a variety of smart devices, including voice-activated smart
    speakers, smart plugs, smart lighting, smart sensors, smart door locks, and more.
    IoT and smart cities are mutually inseparable since the idea of a smart city is
    built on the integration of IoT technologies. Data about numerous facets of residents’
    life can be collected via IoT devices such as sensors and cameras. For IoT applications
    (smart transportation, smart grid, smart city, etc.), a more delicate scenario
    develops, meaning that extremely quick response times are not negotiable and should
    not be satisfied with conventional cloud computing-based services. A summarized
    previous effort, current work, and a fully integrated approach to the IoT and
    edge were presented [1,2,3,4,5,6,7]. On an edge network, near to the user, edge
    computing combines computation and data storage [8,9,10,11,12,13,14,15]. When
    we compare edge computing and cloud computing, edge computing will transfer data
    and computation to network edge which can considerably reduce the latency in message
    transfers [12]. The greater amount of site visitors can be lowered since the threshold
    compute node areas are in the direction of end users. Redirecting visitors from
    overloaded nodes to free nodes can improve response times for WoT applications
    in comparison to similar cloud computing services. The success of the Internet
    of Things and cloud services needs edge computing. In edge computing, data computation
    occurs partially at the network edge which reduces burden on the cloud. Edge computing
    is used to reduce latency, battery life problems, bandwidth costs, privacy and
    security issues [8]. Security and privacy are very important concerns for sustainable
    development of smart homes and residential communities. Over-the-counter, computing
    may also send calculations and overhead communication from limited battery nodes
    or power to nearby nodes with significant electrical resources. By doing this,
    the limited battery nodes lifespan can be increased, hence extending the WoT community’s
    existence. The paper is divided into multiple sections: we briefly go through
    the fundamental ideas of edge computing and the Web of Things (WoT) and talk about
    how the two technologies could be combined in Section 2. The integration of the
    web of things and edge computing are discussed in Section 3; we have presented
    an edge computing based WoT architecture as well. In Section 4, the challenges
    and advantages of WoT and edge computing have been outlined. In Section 5, future
    challenges have been discussed. In Section 6, the conclusion of the paper has
    been presented. 2. Review of WoT and Edge Computing In this part, the fundamental
    ideas of edge computing and the Web of Things (WoT) have been explored and discussed
    including how the two technologies could be combined. Further, working of different
    authors on Web of Things is discussed in Table 1. 2.1. Web of Things The use of
    web-based technologies to access information and document services gave rise to
    the Web of Things (WoT). Every physical thing in World of Warcraft has a digital
    equivalent known as a “Virtual Object” or “Web Object” [16]. These items may be
    accessed through the HTTP (Hypertext Transfer Protocol) protocol by using the
    RESTful API, which is based on the REST (Representational State Transfer) property.
    An OWL-based semantic specification, a REST API to access its features and operations,
    and an HTML or JSON representation of the web object are all possible. There are
    three ways how online material is incorporated into the web: first, directly hosted
    on a hardware; second, embedded; and third, webserver. An embedded device with
    only 200 bytes of RAM and 7 KB of code may operate the web server with clever
    configuration [17]. A web server integrated into a gateway device or a cloud service
    can be used to control the physical content of non-convertible goods. The gateway
    device in these applications transforms traffic to HTTP into a virtual object
    identification. Figure 1 depicts these three referral techniques. The Index contains
    a summary of online integrated technology authorization [18]. Applications in
    WoT communicate with objects using the RESTful API and the HTTP standard protocol.
    Figure 1. An Overview of WoT Model. As a result, the document is simple to retrieve,
    usable in online applications, and compatible with already existing web resources
    [17]. By highlighting sensory abilities and reviving the global open market, it
    encourages the development of cyber-physical services and added value [19]. WoT
    effectively transforms the outside world into a collection of online software
    resources. Table 1. Important information of papers along with citation of papers
    on Web of Things. 2.2. Integration Pattern for Connecting Things to Web 2.2.1.
    Direct Integration The straightforward model is a straightforward integration
    paradigm in which the gadget is directly exposed into the Web of Things API, which
    is beneficial for reasonably capable devices with TCP/IP and HTTP capabilities
    and direct internet connectivity (e.g., Wi-Fi cameras). For home network devices
    that might need to employ NAT or TCP tunneling to disconnect firewalls, this pattern
    might be challenging. It also exposes the gadget to risks to its security on the
    internet as shown in Figure 2. Figure 2. Direct Integration Pattern. 2.2.2. Gateway
    Integration For devices having applications that can utilize the HTTP server directly
    and use the gateway to integrate them with the web, the gateway integration paradigm
    can be helpful. Figure 3 shows that this pattern was beneficial for devices using
    PAN network technologies, such as Bluetooth or ZigBee offline, or devices with
    low power. All varieties of IoT devices that are already connected to the web
    may be integrated via the gateway. Figure 3. Gateway Integration. 2.2.3. Cloud
    Integration In the cloud integration paradigm, a cloud server serving as a distant
    gateway is given access to the Web of Things API, and the device converses with
    the server in the background via a separate protocol. This strategy is helpful
    for several devices that need to be integrated centrally throughout a wide region
    as shown in Figure 4. Figure 4. Cloud Integration. 2.3. Edge Computing The management,
    processing, and distribution of data from billions of devices worldwide is changing
    as a result of edge computing. End-to-End computing systems are still being propelled
    by the explosive expansion of Internet of Things (IoT) devices and new applications
    that demand real-time processing capability. End-to-End computing systems can
    create or support real-time applications such as video processing and analytics,
    driverless cars, artificial intelligence, and robots more quickly thanks to quick
    network technologies such as 5G wireless. At the most fundamental level, using
    computers eliminates the reliance on location and puts counting and data storage
    closer to the devices where it is gathered. This makes sure that data, especially
    real-time data, is free of latency problems that could affect the performance
    of an application. Additionally, by lowering the quantity of data that has to
    be processed in a central or cloud-based environment, organizations may save money
    by processing locally. In response to the growing number of Internet of Things
    (IoT) devices that connect to the internet in order to access the cloud and recover
    data, edge computing can be very helpful. Additionally, a lot of IoT devices produce
    a lot of data when they are in use. In Table 2, we have mentioned several works
    related to the Internet of Things and the Web of Things. Mostly, authors have
    found that interoperability due to heterogeneity is the biggest problem for IoT
    and WoT environments, which can be solved mainly by using different standards.
    In our opinion, there is a need to develop more open standards for IoT and WoT.
    Additionally, there is a need to find out more solutions for interoperability
    in these environments due to the expected extensive use of IoT in the upcoming
    future. Furthermore, there is a need to work more on interoperability issues where
    edge computing is used as less research has been published on edge computing.
    Table 2. Important information of papers along with citation of paper. Edge computing
    ia used by many people these days. We have mentioned the most significant works
    related to Edge Computing in In Table 3. Table 3. Work of different authors on
    edge computing. 2.3.1. Edge Computing Architecture Using computer resources outside
    of traditional and cloud data centers, edge computing is a technology that allows
    work to be completed near to where data is produced and where actionable analytics
    can be carried out deeper. Engineers can develop applications by utilizing and
    controlling computing resources situated in distant locations, such as factories,
    shops, warehouses, hotels, distribution centers, or automobiles because it substantially
    reduces latencies, lowers demands on network bandwidth, increases privacy of sensitive
    information, and enables operations even when networks are disrupted. More nodes
    could be needed to transfer application functionality to the edge. The following
    are some of the essential elements of the edge ecosystem. 2.3.2. Cloud It can
    be a repository for applications, and it could be a public or private cloud. These
    clouds host and distribute software necessary to organize and control the numerous
    edge zones. These cloud workloads will communicate with edge workloads, local
    workloads, and device workloads. All the data those other nodes require may come
    from and be stored in the cloud. 2.3.3. Edge Device A tablet is a unique gadget
    with a built-in computer. Peripherals such as small manufacturing machinery, ATMs,
    smart cameras, or autos might be the subject of interesting research. This gadget
    often has constrained computational capabilities owing to financial reasons. End-to-end
    devices frequently have 1 or 2 cores, 128 MB of RAM, and maybe 1 GB of permanent
    local memory ARM or x86 class CPUs. Although they have great power, peripherals
    are the same as they are now. 2.3.4. Edge Node Any device or edge server that
    can utilize a computer is referred to as an edge node. On Android gadgets, including
    Android tablets and Android telephones, we put in force aspect. IoT edge nodes
    perform three responsibilities: they get hold of statistics from IoT nodes, perform
    semantic analysis, and supply data to cloud servers. For communique, it uses Socket
    and the MQTT (MQ Telemetry Transport) purchaser, and for semantic reasoning, it
    makes use of the Jena framework. There are two working modes for it: the first
    mode entails the brink nodes storing the ontology domestically; the second mode
    entails the brink nodes using an HTTP request to obtain the ontology from the
    remote Ontology Repository Server, which may additionally transmit any or all
    of the ontology. Figure 5 depicts the brink nodes’ procedure. These nodes first
    wait for RDF (Resource Description Framework) facts from IoT nodes, then use the
    nearby repository to seek up the ontology or make an HTTP name to the semantic
    server. They then perform the analysis and simultaneously transfer the statistics
    to the cloud server. Figure 5. Workflow to Edge Node. 2.3.5. Edge Cluster/Server
    An edge server is a computer which is situated in a distant office, such as a
    factory, retail space, hotel, or some financial institution. Typically, industrial
    PCs or rack computers are used to construct terminals and servers. End-to-end
    servers with 8, 16, or more processing cores, 16 GB of memory, and hundreds of
    GB of local storage have been very typical. Business operations and shared resources
    are supported by an end-to-end cluster or server. 2.3.6. Edge Gateway An edge
    gateway is often an edge cluster or server that offers services for network tasks
    such protocol compilation, termination networking, tunneling, security systems,
    or wireless connections in addition to being able to handle corporate duties and
    shared services. Edge ports are frequently distinct from peripheral devices, even
    if certain edge devices can perform limited network functions or act as gateways.
    IoT sensors are static devices without built-in or computer memory that gather
    and transmit data to the edge or cloud. This makes it impossible to ship containers.
    2.3.7. Edge Computing Implementation Edge computing has concentrated on creating
    edge computational models in order to make use of the aforementioned structure.
    The first two patterns generally resolve the following: Hierarchical Model: The
    edge structure is divided into categories, defining resources and functions based
    on distance, considering that edge/cloudlet servers might be utilized by end users
    in various locations. As a result, the hierarchical model must specify the edge
    computing network’s topology. Numerous studies on the hierarchical model have
    been conducted. In [48] for instance, a phased paradigm using Mobile edge computing
    (MEC) servers and cloud infrastructure was developed. Because the MEC enables
    them to meet their computational and storage demands, mobile users in this model
    may access the services they have requested. Tong, L., Y. Li, and W. Gao in [49]
    has proposed a cloud-based methodology that may be utilized to deliver the required
    loads for mobile users. In this concept, the terminal servers are utilized in
    conjunction with a regional edge cloud that is constructed as a tree configuration
    and used cloudlet servers at the network edge. The computing capabilities of peripheral
    servers may be reconstructed to handle heavy loads by adopting this design procedure
    [50]. Software Defined Model: Additionally, maintaining IoT and edge computing
    will be quite challenging given that hundreds of apps with millions of users and
    end devices have been involved. IT management complexity may be successfully addressed
    by Software Defined Networking (SDN) [51,52,53,54]. The SDN model has been the
    subject of several research projects. For example, in [53], the capabilities of
    MEC systems with software-defined systems provide a suitable software model. Costs
    related to management and administration might be decreased in this way as mentioned
    by Du, P. and A. Nakao in [54]. In order to merge the capabilities of MEC systems
    with software-defined systems, a special software model should be proposed. Management
    and administrative costs might be decreased in this way. Authors in [55] presented
    a cutting-edge operating system that strengthens network and service platforms
    by utilizing freely accessible open-source technologies. Salman, O., et al. in
    [56] planned to combine three novel ideas: Network Functions Virtualization, Software
    Defined Networking (SDN), and MEC. The system may then be scaled up to support
    IoT deployments anywhere while achieving the highest MEC performance on the mobile
    network. Lin, T., et al. in [57] offer the creation of intelligent applications
    within the Software Defined Virtual infrastructure of the smart edge frameworks,
    which may be utilized to facilitate the creation of a broad variety of distributed
    network resources and applications. 3. Integration of Wot and Edge Computing We
    have discussed WoT integration and edge computing capabilities in this section.
    We compared the functionality of the WoT and the edge computing in order to demonstrate
    how edge computing enhances WoT performance. We have also concentrated on transmission,
    storage, and computation aspects. 3.1. Overview The Thing Description (TD) proxy
    format, which is based on JSON, must be handled and parsed by the user. The information
    model and the format’s output in JSON-LD compliant can be processed using either
    JSON libraries or a JSON-LD processor. In addition to facilitating semantic processing,
    such as interpreting RDF triples, anticipating semantics, and completing tasks
    based on ontological terms, the usage of JSON-LD processors in TD processing can
    provide greater freedom. TD is an example (i.e., it discusses each item, not just
    certain sorts of objects) and goes beyond the standard (web) language. There may
    be other representations of objects such as HTML-based user interfaces, just business
    visualizations, or non-web presentations in closed programs. However, at least
    one TD presentation is necessary in order to qualify. Interacting with a particular
    object using WoT Thing Description, which is a standardized and understandable
    machine format, enables interaction between all the different IoT platforms, such
    as biological systems. A Thing directory that manages the list of available objects
    and often keeps track of their TD representation can also help with this. A Web
    of Things can be created by connecting the definitions of things in WoT with other
    objects and other online resources. To reflect the Network-to-Network interface,
    or WoT Interface of a Thing, items must be handled in the network system components
    using a software stack. Nothing may also serve as a synopsis of the apparent business.
    Providing a single WoT Object Description with an integrated set of visual business
    capabilities is one design choice. When a composition is quite complicated, its
    TD may relate to Sub Things that are arranged hierarchically inside the composition.
    Only broad information and possibly all-encompassing capabilities have been present
    in the main TD, which serves as an entrance point. This makes it possible to gather
    together some elements of More Complex Things. Figure 6 interprets the Data Analysis
    and Monitoring using IoT and edge computing technology. In addition to hierarchical
    structures, constraints also apply to broad connections between objects and other
    resources. Link types describe how items are connected, such as a switch that
    controls a light or a room that is motion-activated. Figure 6. Data Analysis and
    Monitoring using IoT edge computing Technology. In general, Web linkages between
    items allow people and machines to browse the Web of Mediators, which can serve
    as proxies for objects, with the Mediator having a definition for a WoT Thing
    that is similar to the original Thing but points to the WoT Interface made available
    by the Mediator. Mediators can design a new item in the Multiple Items offered
    or enhance existing items with additional skills, thus creating a real company.
    Since Mediators have WoT Thing definitions and a WoT interface, they seem to consumers
    as Objects, and as a consequence, they will not be shown in Objects in the form
    of a horizontal device such as the Web. Identity in WoT object descriptions should
    allow for several TDs to represent the same distinctive item or specific visible
    business. With the customer, items can be grouped together to enable Thing-to-Thing
    communication. Usually, the conductor can be included into the software component,
    which also utilizes the Object behavior. This may use a Thing to specify the customer
    conductor configuration. IoT sensors are collecting big data that are expected
    to grow exponentially every year. Using edge computing allows businesses to simplify
    and accelerate analytics and obtain the right information at the right time, as
    shown in Figure 6. All IoT application ranges, including the tool level, the limitation
    level, and the cloud level, adhere to WoT standards. This encourages common place
    connections with APIs in all relevant ranges and enables a variety of integration
    models, such as cloud computing, or more specifically, a connected cloud, as well
    as Thing-to-Thing, Thing-to-Gateway, Thing-to-Cloud, and Gateway-to-Cloud. In
    IoT applications, PC structures for two or more carrier providers. Figure 7 represents
    the edge computing-based WoT architecture. An embedded device with sensors and
    actuators that connects the mobile business, where Things are housed, however,
    was not required by WoT; it can be on an IoT device directly, an edge device such
    as a gateway, or the cloud. A typical deployment project is one in which local
    networks cannot be accessed through the internet because of a firewall or IPv4
    Network Address Translation (NAT) devices. WoT allows for intermediaries between
    Things and Consumers in order to address this problem. Figure 7. Edge computing-based
    WoT Architecture. 3.2. WoT Performance Demands 3.2.1. Transmission The sum of
    the transmission time and the processing time may be used to determine the overall
    reaction time. IoT devices often continually produce vast volumes of data, but
    they only have a few computational uses [58]. In fact, considerable network delays
    are undesirable and cannot satisfy Quality of Service (QoS) standards. Vehicle-to-Vehicle
    and Vehicle-to-Infrastructure communication are two specific examples. Response
    times should also be very fast when it comes to issues with public safety and
    requirements for first responders. For real-time data collecting and analysis
    applications, edge computing provides conventional cloud components that offer
    several dispersed computer nodes close to end users [4]. In addition, edge computation
    nodes have a sufficient processing capability to meet IoT requirements. Therefore,
    IoT application requirements can employ edge computing’s quick transmission time
    rather than the delays in typical cloud services such as Amazon Cloud or Google
    Cloud. 3.2.2. Storage IoT was a fantastic source of data, as it was not already
    a significant component of large-scale data generation. IoT must thus load huge
    data at the edge or into cloud storage. However, faster upload times are an advantage
    of edge storage uploads [59]. It was a challenge to guarantee the integrity, information
    protection, anonymization, denial, and renewal of the original data since edge
    nodes work for many businesses [60,61]. Additionally, edge nodes’ storage capacity
    is constrained and cannot be compared to cloud data centers’ huge and long-term
    storage capacities. The complexity of data management is further increased by
    the usage of several edge nodes, which have been integrated when data has been
    required. 3.2.3. Computation Numerous IoT devices have limited computing and power
    capabilities, making it impossible to execute complicated computations locally.
    The majority of the time, IoT devices merely gather data and transmit it to robust
    Computing Nodes for processing and analysis. Measuring the edge computing capability
    was a challenging task because edge nodes’ processing power was constrained. However,
    IoT needs can be completely addressed even with low processing power requirements
    for IoT devices, particularly in real-time applications with edge nodes. Edge
    nodes also lower IoT device power consumption by loading computational tasks.
    That developed an issue for IoT. Thing Descriptions’ (TDs) capacity to offer an
    abstract interface was one of the Web of Things’ most potent characteristics.
    When device capabilities, device suppliers, or new computer capabilities are made
    available, this abstraction might not change. Affordances may or may not be equivalent
    to the physical entity described by the same TD. A software simulation of a TD-compliant
    device is referred to as a Virtual Object. The majority of the time, these inputs
    will be related to data streams that, when analyzed by Artificial Intelligence
    (AI), will enable that program to imitate the characteristics, operations, and
    events that would typically be given by a real-world physical device. In a straightforward
    scenario, software may decipher data from a new door sensor product and imitate
    the behaviors, characteristics, and events that the older device supported. With
    this feature, consuming software may protect itself against the assault of bringing
    new devices into the ecosystem and remain unmodified. The original item description
    will still serve as the interface definition in the consuming program. If the
    situation is more complicated, software can handle the data stream to simulate
    a real device. These Virtual Objects make it possible to upgrade the capturing
    hardware, in this example, a video camera, without having to fully rebuild the
    program that was designed to use the Thing’s original description. As seen in
    Figure 8, dataflow may also be utilized to allow fresh descriptions of objects
    alongside older ones and to imitate several Virtual Entities. It will be much
    easier for device owners to maintain their software and hardware if they can utilize
    existing Thing Descriptions as an abstraction for Virtual Objects. Figure 8. Edge
    Computing based WoT Architecture. Use software emulation to provide support for
    earlier descriptions of objects on modern devices. Offer innovative, potent multipurpose
    gadgets that can handle a variety of Things’ Descriptions. Let older and newer
    versions of devices coexist in a device. Protect current software from modifications.
    4. Challenges and Advantages of Edge Computing and WoT The Web of Things and edge
    computing have several challenges and advantages. These challenges and advantages
    of WoT and edge computing have been covered in this section. 4.1. Challenges of
    Web of Things 4.1.1. Search and Discovery of Smart Things The search and discovery
    of Smart Things is a significant issue confronting the World Wide Web, examining
    a huge number of web pages. As a result, the great notion of locating Things becomes
    extremely impractical when searching by reading HTML pages with links. Because
    objects are made up of location-based information, often switch between different
    contexts, and have wordy HTML submissions, searching for them is far more difficult
    than searching for documents. Compared to typical web pages, the key is smaller.
    Recent advancements in semantic description, such as Micro formats, which may
    be integrated with HTML presentations, will undoubtedly assist to improve the
    perception of the services offered by Web Objects [62,63]. It might be necessary
    to inform any person or organization of the existence, capabilities, and details
    of the desired web service. For instance, in order to negotiate a shared objective
    to establish a new group in accordance with specific requirements, objects need
    to know the identities of smart objects and web services in their environment.
    To WoT, search engines are crucial. According to [62], there are primarily two
    methods for developing a search engine. The push approach involves pushing active
    sensor results to the search engine, which then uses the information to address
    queries proactively. In the smart object-based crowdsourcing environment, this
    approach cannot scale. It can only be applied to systems with a few devices. As
    an alternative, the pull approach has the search engine send pertinent data to
    the sensor only after receiving the user’s query. Although this approach can be
    scaled up, it is valued for its precision and promptness. Here, our attention
    is on the latter. More crowdfunding than ever before is being supported by the
    web and smart object integration. The internet offers a lot of the web-based services
    and information found in the physical world. More services may be beneficial and
    convenient for users, but WoT is not a search engine’s worst nightmare. With the
    massive amount of web content created every day and the mass search of Web2.0,
    search engines are not an easy task, let alone the mass search of Web3.0 created
    by trillions of smart objects. A search engine that enables looking for physical
    world services that meet specific criteria will also be the main service for WoT.
    Static or slowly changing content written by humans rules the conventional web.
    WoT’s content is constantly evolving because smart items are generated automatically
    [64]. As a result, searching for frequently changing content will be supported
    by the WoT search engine. This is the main issue because the search engine is
    built on the premise that most web content changes gradually and that updating
    its index infrequently is sufficient. With many devices in the physical world
    operating at a frequency of minutes or seconds, this is not possible for WoT.
    However, some web resources or services are only useful at specific times. Future
    installations will also be produced dynamically depending on the situation. Web
    services for resources might need to be dynamically searched for and retrieved
    in real time. The dynamics of WoT, which are brought about by features such as
    the movement and connectivity of intelligent objects, make this issue even more
    challenging. Real-time information searching and real-time web service discovery
    are supported by the WoT search engine. On this subject, some ground-breaking
    work has been performed. The web infrastructure that already exists can be used
    to support the publishing of sensor and entity data, as demonstrated by Ostermaier,
    B., et al. [65]. The authors examine and improve current methods (such as Wang,
    H., et al. [66], Tan, C.C., et al. [67], Yap, K.-K., V. Srinivasan, and M. Motani
    [68], etc.). In their work [68], the authors proposed an architecture and system
    capable of rapidly searching physical objects. They noted that emerging technology
    trends such as smart textiles, smart paints, RFID tags, smart dust, and HP’s Memory
    Spot suggest that a broad range of physical objects will soon be equipped with
    small devices having fundamental communication and processing capabilities. 4.1.2.
    Data Inconsistency The current state of the IoT generally demonstrates that a
    large number of devices are producing real-time data through their interactions.
    Following the conversion to WoT, a justification for processing the supplied data
    has been explained. It provides a set of three IoT devices to demonstrate the
    overall scenario. Every IoT device produces data, which Reasoner will have access
    to. IoT Device 1, the first of these devices, produces static data, but IoT Devices
    2 and 3 provide data that are incompatible. The IoT network protocol gathers all
    of this data, which are then analyzed by a suitable device, such as a smartphone,
    computer, or router, and then converted and incorporated into WoT. After being
    updated by an RDF identifier, the data produced by the IoT device will be converted
    to the Semantic Web. Then, Reasoner may receive this data, which is already provided
    as triplets in accordance with Semantic Web standards. In the end, Reasoner provides
    consumers with results via a website or another web-based means. The facts, however,
    are not always accurate; frequently, they display negativity. When portrayed as
    being challenging to grasp, incompatible data is described as data that is delivered
    in an ambiguous context. The weight of this information on the choice may change
    significantly as a result of this ambiguity, which might provide contradictory
    or inconsistent results. Contradicting information arises when two separate sources
    give conflicting information, yet one of them is essential. That was forced into
    an unstoppable pattern that is unable to provide a clear sequence for various
    data sources as a result of the proliferation of IoT applications. As a result,
    managing the contradictory data produced by various IoT sources can be the largest
    problem. The right conversion protocol that enables Reasoners to analyze this
    data is currently absent, although there are instances where Reasoners can function
    with fixed data from a single source if it goes over the full network of IoT devices.
    Otherwise, it can result in inconsistent results for the user or possibly harm
    the machine on which it is installed. Therefore, it is crucial for end users to
    fix data errors in WoT [69]. 4.1.3. Security The development of proper authorization
    procedures is required to prevent data leakage or poor performance on shared WoT
    resources since security is a key concern for the IoT and WoT domains [64]. However,
    it is crucial to make a distinction between platform access control and object
    access control. In regard to the first function, WoT uses contemporary web technology
    to authenticate users when they enter the platform; content visibility can also
    be automatically changed [28]. The latter now only has two visible levels (public
    or private); however, it is possible to identify which subscription policy has
    the strongest characters. The access policy for the Thing, in contrast, is specified
    in its TD. The current version of the W3C WoT has established a number of authorization
    models, including token-based models, for restricted access to the topic. Data
    encryption is crucial, but security best practices and robust user, device, service,
    and application authentication mechanisms were also required. 4.1.4. IoT Protocol
    There is a significant gap between IoT transactions and advances that continue
    to emphasize the need for covert layers that freely interact with core IoT technologies
    to ease the curve and improve service development boost overall sustainability
    and developer learning. The numerous device and version suppliers that are available
    can be helped by the abstraction layers. IoT devices are in danger when security
    issues are discovered since they are frequently hacked and may not be able to
    change their software [70]. Utilizing device ports that are software upgradeable,
    as opposed to working on hardware-delayed devices, can help achieve this goal
    and offer superior security. In truth, gateways can make use of device drivers,
    but this raises the issue of which drivers will be necessary for each individual
    device and will need the usage of common APIs by drivers to meet IoT standards.
    4.1.5. Identity Verification As part of end-to-end security and trust management,
    identity verification is crucial for devices, users, apps, and services. It cannot
    be presumed that WoT users are real or capable of authenticating, unlike typical
    web application users. As a result, developing techniques for validating metadata,
    such as the existence of data, the position of a certain sensor, and many other
    identifiers, will be necessary for trust management to know your customer’s needs.
    Well-known brands, stringent testing procedures, and even the availability of
    a big number of individuals in terms of reputation management can serve as the
    foundation for this trust. In [71], the authors offer a threat analysis for IP
    packet fragmentation attacks against the 6LoWPAN adaption layer and suggest a
    mitigation method that uses time stamps and dots appended to fragment IDs to thwart
    such attacks. For instance, to ensure present and future compatibility with other
    web-based software applications, Chen, G., et al. [72] depend on open data portability
    protocols such as OData, oEmbed, OpenID17, and OAuth18. Only specific groups are
    permitted to use certain online services. An authentication proxy between users
    and smart objects, the Social Access Controller (SAC) prototype, is implemented
    by Guinard et al. [73]. Access control between objects cannot be handled by UN-based
    approaches, which can only handle access control between persons and things. It
    is anticipated that a universal yet dispersed access control system would allow
    for interdependent behavior while protecting the owners’ privacy. 4.1.6. Resilience
    We will need to focus on resilience as the usage of WoT based applications grows,
    and services will need to keep up with demand. Hardware or software malfunctions,
    such as relevant updates, may prevent or cause some mistakes. Services must be
    designed to withstand breakdowns, including the capability of implementing the
    proper corrective actions when sensory reading has been acknowledged to be impractical.
    Resilience may also be put to the test by cyber threats from adversarial nations.
    To combat this, considerable attention will need to be paid to fixing security
    weaknesses, diligent observation of fraudulent activity, and the implementation
    of strong countermeasures such as security devices. 4.1.7. Things and Avatars
    Usually, more data than the raw data sensor can offer was needed for applications
    and services. Data must also be contextualized within the context of other sources.
    Regulatory systems must also contextually translate their acts into actions for
    the contractor. WoT must be able to simulate the actual world at various production
    levels, allowing for free, competitive marketplaces for services at each level.
    Because items in World of Warcraft are not just linked gadgets, items may have
    one or more avatars or presentations. Access control and data management regulations,
    as well as ownership, detailed descriptions, and services, are all features of
    avatars. The avatar can also be accessible via web technologies and has a URI.
    Avatars assist in developing software and services that mix data from several
    sources with varying degrees of output. 4.1.8. Smart Searches Intelligent goal-based
    searches will have more chances to open service standards. Additionally, the procedure
    begins as it usually does when the user enters a search string. Using an easy-to-use
    interface tailored to a particular aim, search engines utilize six-way rules to
    identify targets, extract pertinent search parameters, and lead them to registered
    services. These specialized services may make further service requests as necessary,
    but in order to appear on the search engine results page, they must be able to
    deliver results in under a second. Be aware that the user can access a particularly
    challenging question in the results by clicking on a link or symbol. This enables
    users to receive time-consuming chores as out-of-band alerts. 4.1.9. Legal Implications
    Legal implications might be the customer paying for services that are free or
    inexpensive. Since the contract is set up between the service provider and the
    customer for premium services, it can be reversed. There could be disagreement
    on the test technique with regard to trust and reference. As WoT raises the likelihood
    of accidents, the insurance sector may be in disarray. 4.2. Advantages of Web
    of Things 4.2.1. Current Open Ecosystem There are many of ways to use already-developed
    languages such as JavaScript, data input techniques such as Efficient XML Interchange
    (EXI) and JSON, metadata and data formatting tools such as those created by Open
    Data group, as well as protocols such as HTTP and the Web. These were only a few
    secrets: for instance, utilizing driver’s devices on gateways that employ the
    IoT protocol, JavaScript may be used directly to interface with IoT sensors and
    actuators in the browser, whether they are in the cloud or at the network’s edge.
    These devices operate the forum and show web settings. This can be performed with
    ease on smartphones and tablets, and operating systems such as iOS and Android
    already offer native APIs for Bluetooth or Near-Field Communication (NFC) access
    to onboard sensors and proximity devices. In the future, this work may combine
    APIs with different protocols, such as MQTT (MQ Telemetry Transport) and CoAP
    (Constraint Application Protocol). Other devices nearby can be notified via Low
    Power Bluetooth [74]. 4.2.2. Home Hubs Another alternative to hosting services
    are home hubs. Nowadays, most individuals have a hub at home that serves as a
    Wi-Fi hotspot for high-speed internet access. It is likely that these gadgets
    will evolve into platforms for offering IoT home gadget services. These centers
    must include open standards that allow consumers to install service with any provider
    they choose if they are to have the best chance of success. Portal devices that
    can be placed close to the home will also be necessary to access IoT devices outside
    of the hub. A key component of a smart home is the ability of residential facilities
    and household appliances to communicate with one another thanks to the “ECHONET
    Lite” protocol. An HTTP message interpreter can be used by WoT clients to connect
    to the ECHONET Lite Web API application. Supporting transparent communication
    between WoT consumers and non-WoT devices that use the HTTP protocol as a transport
    protocol, such as the ECHONET Lite Web API device, may be desired for the WoT
    standard as shown in Figure 9. Figure 9. Home WoT System Architecture. Configuration
    by the user of the device before starting to use the service ○ The user of the
    device logs in to the server of the “Household Management Service Provider” with
    which the user has a contract. ○ The user specifies the lighting, air conditioning,
    and security sensor operating modes for when the user is away from home, when
    the user returns home, and when the specified time has elapsed after the user
    returned home. When the device user leaves home ○ The user of the device accesses
    the server of the “Home Management Service Provider” using a smartphone and informs
    the server that the user is about to leave the home. ○ The server updates the
    operating modes of the lighting, air conditioning, and security sensor according
    to the configuration entered by the user during the time when the user is away
    from home. ○ The server reads the operating modes of the lighting, air conditioning,
    and security sensor and informs the user’s smartphone about these operating modes.
    4.2.3. Cloud Platforms Platforms built on the cloud may be planned to expand flexibly
    as platform loads increase. One illustration is the Cloud Foundry-based open-source
    design forum and service naming which can allow using Node-RED and be transmitted
    to the naming cloud through this forum. Service owners may create security guidelines
    that take access control, static flow analysis, and robust monitoring into consideration.
    4.2.4. Standard Vocabularies and Repository A standard method for identifying
    the links supplied by services and the websites are necessary in the free market
    for services. A helpful analogy for organizing Linux packages is that of a tree,
    where each package contains its own name, version number, and declaration of the
    names and spacing of the other packages it depends on. However, how can you promote
    the reuse of metadata and data words and support current repositories that developers
    can browse and search, where they are encouraged to post brand-new phrases. 4.2.5.
    Monetizing It goes without saying that generating a positive environment such
    as this requires monetizing a service. This will require vendor-neutral open standards
    for web-scale ecosystems. The Web Payments Interest Group, which the W3C has created,
    aims to eliminate web requests from payment systems. In reality, this can take
    the form of one-time fees, recurring charges, charges for individual usage, or
    non-discriminatory procedures for providing particular users or groups of users
    accesses to a particular service. The basis for legally enforceable agreements
    between service providers and customers may be found in contract law, which is
    essentially the same across the board. These agreements can apply to policies
    that provide data owners choice over how the data is used and for what reasons
    in addition to payment systems. 4.2.6. Cyber Physical Systems In order to accomplish
    common system objectives such as regulating traffic on city highways, keeping
    a comfortable climate in huge buildings, and monitoring close to the smart grid
    for power supply, the network-physical system really controls the sensor and actuator
    lock. To fulfil the demands for low latency and tight connection across several
    actuators, control of such systems must be extended to the edge of the network
    and represented at multiple output levels. As a result, protocols will have to
    be modified to account for latency and vibration requirements, and it is possible
    that the service layer will have to transfer QoS requirements to the network layer.
    Furthermore, as latency may be less important than process intensity, different
    output levels may have different needs. 4.3. Challenges of Edge Computing 4.3.1.
    Bandwidth High bandwidth can speed up transmission times from a latency standpoint,
    especially for huge data such as videos [75,76]. We can set up access to wireless
    bandwidth with short-term transmission so that we can transfer data to the edge.
    On the other hand, operating on the edge can dramatically reduce latency compared
    to working in the cloud if the workload can be managed there. Additionally, the
    bandwidth between the edge and the cloud is preserved. As an illustration, practically
    all data in a smart home setting may be handled at the doorstep using Wi-Fi or
    other high-speed communication techniques. Additionally, the shorter transmission
    increases the transmission’s dependability. However, even if the transmission
    distance cannot be decreased since the edge can meet the computing need, the data
    is processed sooner at the edges, and the download data size is significantly
    decreased. To considerably minimize the quantity of data in the case of smart
    cities, it has been advised to analyze photographs before downloading. Particularly
    when using the carrier’s data infrastructure, it helps conserve the user’s bandwidth.
    Globally speaking, bandwidth is preserved in both scenarios and is available for
    use by other domains to upload and download data. Therefore, we must determine
    if a high-bandwidth connection is required and what speeds are appropriate given
    the constraint. Additionally, in order to avoid concurrency and latency, there
    were some needs to consider the available computing capacity and bandwidth consumption
    in order to precisely calculate the workload allocation for each layer. Users
    write their own code and deploy it on the cloud while using cloud computing. Where
    computing will take place in the cloud must be decided by the cloud provider.
    Users have little to no understanding of how the program functions. One benefit
    of cloud computing is that the user can see right through the infrastructure.
    Many calculations can be carried out at the edge rather than a central cloud,
    as described in edge computing [77]. 4.3.2. Latency One of the most crucial performance
    testing measures, particularly for collaborative apps and services, is latency
    [78,79,80,81]. Advanced computational capabilities are offered by cloud servers.
    They are capable of completing complicated tasks quickly, including speech recognition
    and picture processing. The computation time is not, however, constrained by the
    delay. Real-time application/interaction behavior can be significantly impacted
    by long-term WAN latency [81,82]. Workload should be properly minimized at a neighboring
    layer with adequate processing power at the network’s edge in order to avoid delays.
    Instead of uploading all the pictures, for instance, in the case of a smart city,
    phones can be utilized to process the local photographs first and transmit the
    information that might be lost back to the cloud. The front edge will be processed
    considerably more quickly due to the sheer volume of photos and their size. A
    close-up strategy might not, however, always be the best choice. In order to locate
    the appropriate layer, there is a need to consider instructions on how to utilize
    the application. It would be preferable to upload the image to a nearby door or
    tiny center if the user is playing a game because the phone counting gadget is
    already in use. 4.3.3. Energy Batteries are a crucial component of every network.
    Edge loading work might be viewed as a technique for the final seam construction
    [83,84] with therefore more energy-efficient to relax all of the burden (or a
    portion of it) at the edges rather than depending on it, given a particular workload.
    The right balance between the computer’s power use and transmission capacity is
    crucial. Generally speaking, it must first consider the workload’s advantages.
    If there is no network signal [85], transmission capacity will also depend on
    the size of the data and the available bandwidth. Only when the airpath is shorter
    than utilizing the local computer do we prefer to employ edge computing. However,
    the overall power consumption should equal the total cost of energy for each layer
    employed if we are interested in the edge compute process as a whole rather than
    simply the endpoints [81,86]. A local and transmission cost calculator may be
    used to estimate the power consumption of each layer for the final point layer.
    The precise assignment plan can alter in this situation. For instance, the workload
    is continually being uploaded to the top tier because the local data center layer
    is busy. Multi-step transmission can greatly improve performance as compared to
    terminal computing, but it also consumes more power. 4.3.4. Cost From the perspective
    of service providers, such as YouTube, Amazon, and others, edge computing allows
    them to operate with the least amount of latency and power, which can enhance
    their performance and user experience. They may therefore handle the same unit
    of labor while making more money. For instance, it may position a popular film
    on the edge of the building layer based on the preferences of numerous residents.
    You might be released from this task and given an extremely challenging one on
    the edge of the city floor. The overall sum may be raised. The investment made
    by the service provider was equal to what it costs to build and maintain each
    layer’s materials. Providers may impose fees on customers depending on location
    data in order to maximize the value of each layer’s location data. To ensure service
    provider profitability and user approval, new cost models need to be updated.
    4.4. Advantages of Edge Computing 4.4.1. Distributed Computing A distributed computer
    in a distant data center might utilize the application just as much as one in
    a central data center; hence, edge infrastructure must constantly be accurately
    assessed. 4.4.2. Security and Accessibility Companies may integrate technological
    and physical security by integrating with single-premise applications in the data
    center, creating a virtual barrier around resources. Edge computing transforms
    the security landscape by demanding the same network and mobile security models
    on remote servers in order to track location and traffic patterns. Given that
    using a computer may need access to a very large number of devices, IT teams will
    need to clearly map user access privileges. 4.4.3. Backup The data generating
    environment is often what drives the end-to-end computing approach. When selecting
    how to secure these assets, network bandwidth needs will be just as crucial as
    storage media concerns since it might not be practical to create a backup across
    the network. 4.4.4. Data Accumulation Data is a crucial corporate asset, and if
    it is not collected and managed properly, it could eventually pose new problems
    and potentially lead to debt. Both data access and storage are crucial, and both
    require network integration as a component of the data lifecycle. 4.4.5. Control
    and Management Although edge zones in an organization, private cloud, or even
    public cloud might be flexible, managers and controllers must adhere to the same
    procedures and guidelines wherever they can. The new orchestration tools should
    enable enterprises to manage apps without hindrance, regardless of location. 4.4.6.
    Scale The scope of everything the IT team performs expands as more highly connected
    devices are added to the edge. In the end, edge computing is increasingly used
    across all computer domains, including computation, networking, storage, management,
    security, authorization, and more. When putting apps on the network, business
    owners need to be aware of this edge: measure the impact of edge on anything IT-related,
    not only as additional distant gear. 5. Future Challenges The integration of the
    Internet of Things (IoT) and edge computing presents several current and future
    challenges, including: Data Management: Handling the massive amounts of data generated
    by IoT devices and ensuring their timely and efficient processing at the edge
    is a major challenge [86]. Security: Ensuring the security of IoT devices and
    the data they generate is a critical challenge, as these devices are often vulnerable
    to hacking and cyber-attacks [87,88,89]. Another problem is that the integration
    of smart things into the standard Internet introduces additional security challenges
    because the majority of Internet technologies and communication protocols were
    not designed to support Internet of Things [90]. Interoperability: Ensuring interoperability
    between different IoT devices and edge computing systems is a challenge, as it
    requires standardization and common protocols [91]. Scalability: Scaling edge
    computing systems to meet the demands of growing IoT networks is a challenge,
    as it requires efficient resource utilization and effective management [92]. Latency:
    Reducing latency in IoT networks and edge computing systems is a challenge, as
    it requires efficient data processing and communication [93]. Energy Efficiency:
    Ensuring energy efficiency in IoT devices and edge computing systems is a challenge,
    as it requires energy-saving algorithms and strategies [94]. Integration with
    Cloud Computing: Integrating edge computing with cloud computing is a challenge,
    as it requires seamless communication and coordination between these two systems
    [77,95,96]. Cost Effectiveness: Ensuring cost-effectiveness in IoT and edge computing
    systems is a challenge, as it requires efficient resource utilization and effective
    cost management [97]. Searching resources in WoT is also a big challenge, especially
    dynamic searching and intent based searching [63]. Many physical objects (Things)
    are connected to the internet and are accessible through a web interface, and
    efficient searching of Things is required as there is a significant increase in
    IoT devices [98]. Searching of suitable Things from billions of device is also
    difficult because of multiple Things performing the same functionality, but some
    devices are near to the user or free at some time which can respond more accurately
    and efficiently which depends upon the selection of the right Thing [99]. These
    challenges highlight the need for ongoing research and development in the fields
    of WoT and edge computing to overcome these obstacles and advance the integration
    of these technologies. Implementing edge in WoT presents open research challenges.
    There is heterogeneity in the computing and communication technologies used in
    WoT-based edge computing. Communication technologies may be heterogeneous in terms
    of data transfer rate, transmission distance, and bandwidth, whereas computing
    platforms may have a variety of operating systems and hardware architectures.
    The need to create software solutions that can be applied in various environments
    is one of the challenges of edge computing. Because different applications are
    deployed in edge devices, this problem is very important. In order to facilitate
    the execution of workloads concurrently on various levels of hardware, programmers
    should create a programming model for edge nodes that is supported by task-level
    and data-level parallelism. Use a language that supports hardware heterogeneity
    as a second factor. Different devices and sensors connect to and communicate with
    the edge server and each other in this heterogeneous environment using different
    communication protocols. Due to the unique interfaces on these devices, particular
    communication protocols are needed. In order to facilitate communication between
    these heterogeneous devices in the WoT, standard protocols and interfaces should
    be developed since different vendors produce various types of devices in the WoT.
    The quick development of new devices makes it difficult to develop standard protocols
    and interfaces in WoT. The provision of resources and services at the hardware
    and software levels anywhere, at any time for the WoT subscription is included
    in the availability in the WoT-based edge computing environment. Due to the unique
    interfaces on these devices, particular communication protocols are needed. In
    order to facilitate communication between these heterogeneous devices in the WoT,
    standard protocols and interfaces should be developed since different vendors
    produce various types of devices in the WoT. The quick development of new devices
    makes it difficult to develop standard protocols and interfaces in the WoT. We
    have discussed most significant open challenges and guidelines for future in Table
    4. Table 4. Open Challenges and Guidelines. Ensuring the availability of resources
    and services for WoT-based edge computing environments, anytime and anywhere,
    is a crucial aspect. Availability, which encompasses the mean time between failures,
    the probability of failure, and the mean time to recovery, is essential in providing
    hardware and software resources and services to WoT subscribers. However, addressing
    the challenge of maintaining availability for the increasing WoT population is
    a complex research area. One way to improve availability is to enhance the mean
    time between failures while reducing both the mean time to recovery and the probability
    of failure. In the context of the Web of Things (WoT), numerous devices capable
    of generating data are connected through a network and send vast quantities of
    raw data to the edge device. For edge devices, it is computationally challenging
    to analyze such large data. Risks to security are also connected to this. It is
    advisable to carry out pre-processing of data at the gateway level to eliminate
    noise/low quality data, detect events, and ensure privacy protection. A higher
    layer will receive the processed data to provide additional services in the future.
    However, this process is not without its share of issues. To ensure privacy and
    security, applications operating on edge devices should not have access to this
    raw data. Therefore, during data pre-processing, data details should be eliminated.
    Hiding the specifics of the captured data, however, might affect how usable the
    data is. The amount of raw data that should be filtered is another issue, as many
    applications cannot produce accurate results using such data. Because data does
    not cross the network, edge computing has a positive impact on cybersecurity.
    The network is, however, exposed by the extremely dynamic environment at the network
    edge. The fact that different devices are interconnected in WoT creates a variety
    of security risks. The data presented to these applications should be in an encrypted
    or concealed format, as numerous edge applications execute there. Otherwise, anyone
    can access the open data and use them for illicit purposes. For instance, if a
    home is wired to the Internet of Things, personal information such as health records
    can be taken. The issue here is how to maintain the service without jeopardizing
    privacy. The raw data should not be visible to applications running on edge devices.
    Before it reaches the edge device, personal information can be removed. However,
    edge nodes should be equipped with security measures that are more robust. High
    latency will be impacted by a crowded network, weak signal, and a slow router.
    Additionally, new techniques for gauging latency are needed. Based on data size,
    evaluate the effectiveness of storing RDF data in various forms. If the RDF data
    has a different structure, finding the same format has a different level of efficiency.
    Consequently, a more intricate measurement could be carried out using the RDF
    data structure. To use a large data set for our scalability experiments, consider
    the future exponential growth of WoT. Everything around us, including a refrigerator,
    an oven, a bed, a table, and even a pencil, will eventually become intelligent
    WoT devices. Future studies may examine the best way to assign tasks and the performance-enhancing
    criteria. For the sake of optimization, it was also necessary to determine how
    to divide the RDF data, rules, and ontology. The edge computing paradigm’s parallel
    execution of reasoning tasks will speed up processing and enhance performance.
    The correlation between transfer speed, reasoning speed, and storage speed determines
    the degree of improvement. The performance improvement might eventually peak at
    steady state if the relationship between these rates is fixed. Performance will
    also be improved by adding more edge nodes. Future research should focus on finding
    the best way to divide up RDF rules and data. 6. Conclusions and Future Remarks
    IoT is the next significant internet potential. It is more about the connection
    or interaction between intelligent things (i.e., things and people). Furthermore,
    all intelligent entities must be able to communicate freely. Thus, WoT has emerged
    as the dominant trend supporting the growth of IoT. Web of Things applications
    are an essential part in residential smart homes and smart communities. They provide
    necessary services which are required for increasing sustainable development of
    smart residential communities and for reducing their resource consumption. In
    this paper, WoT and edge computing integration have been discussed. It provides
    an overview of the functionality of WoT and edge computing as well as the impact
    of edge computing (i.e., storage, transmission, and computational aspects) to
    enhance WoT applications overall performance. Moreover, edge computing has the
    capabilities to handle real-time massive communications and computation. In contrast,
    cloud computing approaches have also been reviewed. Edge computing has the potential
    to lower down the transmission latency between end users and edge servers, leading
    to better response times for real-time WoT-based applications compared to cloud
    computing. WoT will be certainly essential to people’s lives in the future as
    smart cities and communities are all based on it; ; however, WoT faces several
    challenges (i.e., search and discovery of smart things, data inconsistency, security
    and identity verification, scalability, interoperability, etc.) that have been
    argued. Additionally, the battery life of restricted nodes can be increased by
    decreasing the cost of moving data and moving computers, as well as by enhancing
    communication between nodes with limited battery capacity, and nodes with crucial
    power increase the lifespan of the overall IoT systems. The bulk of future IoT
    applications may be implemented using web technologies, which are widely used
    and provide all the flexibility and functionality required, including real-time
    messaging, security, interoperability, and discovery. Author Contributions Conceptualization,
    T.A. and Q.H.; methodology, A.A., M.A.O. and W.K.; software, T.A. and Q.H.; validation,
    A.S.A.-S. and A.A.; formal analysis, T.A. and W.K.; investigation, M.A.O. and
    A.A.; resources, W.K.; data curation, M.A.O. and A.S.A.-S.; writing—original draft
    preparation, Q.H.; writing—review and editing, A.A., M.A.O. and W.K.; visualization,
    A.S.A.-S. and Q.H.; supervision, T.A. All authors have read and agreed to the
    published version of the manuscript. Funding This research received no external
    funding. Institutional Review Board Statement Not applicable. Informed Consent
    Statement Not applicable. Data Availability Statement Not applicable. Conflicts
    of Interest The authors have no conflict of interest. References Corcoran, P.;
    Datta, S.K. Mobile-edge computing and the internet of things for consumers: Extending
    cloud computing and services to the edge of the network. IEEE Consum. Electron.
    Mag. 2016, 5, 73–74. [Google Scholar] [CrossRef] Vallati, C.; Virdis, A.; Mingozzi,
    E.; Stea, G. Mobile-edge computing come home connecting things in future smart
    homes using LTE device-to-device communications. IEEE Consum. Electron. Mag. 2016,
    5, 77–83. [Google Scholar] [CrossRef] Dastjerdi, A.V.; Buyya, R. Fog computing:
    Helping the Internet of Things realize its potential. Computer 2016, 49, 112–116.
    [Google Scholar] [CrossRef] Georgakopoulos, D.; Jayaraman, P.P.; Fazia, M.; Villari,
    M.; Ranjan, R. Internet of Things and edge cloud computing roadmap for manufacturing.
    IEEE Cloud Comput. 2016, 3, 66–73. [Google Scholar] [CrossRef] Jutila, M. An adaptive
    edge router enabling internet of things. IEEE Internet Things J. 2016, 3, 1061–1069.
    [Google Scholar] [CrossRef] Sabella, D.; Vaillant, A.; Kuure, P.; Rauschenbach,
    U.; Giust, F. Mobile-edge computing architecture: The role of MEC in the Internet
    of Things. IEEE Consum. Electron. Mag. 2016, 5, 84–91. [Google Scholar] [CrossRef]
    Chiang, M.; Zhang, T. Fog and IoT: An overview of research opportunities. IEEE
    Internet Things J. 2016, 3, 854–864. [Google Scholar] [CrossRef] Shi, W.; Cao,
    J.; Zhang, Q.; Li, Y.; Xu, L. Edge computing: Vision and challenges. IEEE Internet
    Things J. 2016, 3, 637–646. [Google Scholar] [CrossRef] Frankston, B. Mobile-Edge
    Computing versus The Internet?: Looking beyond the literal meaning of MEC. IEEE
    Consum. Electron. Mag. 2016, 5, 75–76. [Google Scholar] [CrossRef] Garcia Lopez,
    P.; Montresor, A.; Epema, D.; Datta, A.; Higashino, T.; Iamnitchi, A.; Barcellos,
    M.; Felber, P.; Riviere, E. Edge-Centric Computing: Vision and Challenges. ACM
    SIGCOMM Comput. Commun. Rev. 2015, 45, 37–42. [Google Scholar] [CrossRef] [Green
    Version] Mao, Y.; You, C.; Zhang, J.; Huang, K.; Letaief, K.B. A survey on mobile
    edge computing: The communication perspective. IEEE Commun. Surv. Tutor. 2017,
    19, 2322–2358. [Google Scholar] [CrossRef] [Green Version] Yu, W.; Liang, F.;
    He, X.; Hatcher, W.G.; Lu, C.; Lin, J.; Yang, X. A Survey on the Edge Computing
    for the Internet of Things. IEEE Access 2017, 6, 6900–6919. [Google Scholar] Li,
    H.; Shou, G.; Hu, Y.; Guo, Z. Mobile edge computing: Progress and challenges.
    In Proceedings of the 2016 4th IEEE International Conference on Mobile Cloud Computing,
    Services and Engineering (MobileCloud), Oxford, UK, 29 March–1 April 2016. [Google
    Scholar] Mach, P.; Becvar, Z. Mobile edge computing: A survey on architecture
    and computation offloading. IEEE Commun. Surv. Tutor. 2017, 19, 1628–1656. [Google
    Scholar] [CrossRef] [Green Version] Hatcher, W.G.; Booz, J.; McGiff, J.; Lu, C.;
    Yu, W. Edge Computing Based Machine Learning Mobile Malware Detection. 2017. Available
    online: https://www.google.com.hk/search?q=Edge+computing+based+machine+learning+mobile+malware+detection&ei=hNIXZJnlE7S6seMPys-EgAU&ved=0ahUKEwiZt-7_x-n9AhU0XWwGHconAVAQ4dUDCA4&uact=5&oq=Edge+computing+based+machine+learning+mobile+malware+detection&gs_lcp=Cgxnd3Mtd2l6LXNlcnAQA0oECEEYAFAAWABg_AVoAHABeACAAW6IAW6SAQMwLjGYAQCgAQKgAQHAAQE&sclient=gws-wiz-serp
    (accessed on 27 February 2023). Christophe, B.; Boussard, M.; Lu, M.; Pastor,
    A.; Toubiana, V. The web of things vision: Things as a service and interaction
    patterns. Bell Labs Tech. J. 2011, 16, 55–61. [Google Scholar] [CrossRef] Duquennoy,
    S.; Grimaud, G.; Vandewalle, J.-J. The web of things: Interconnecting devices
    with high usability and performance. In Proceedings of the 2009 International
    Conference on Embedded Software and Systems, Hangzhou, China, 25–27 May 2009;
    IEEE: Piscataway, NJ, USA, 2009. [Google Scholar] Ngu, A.H.; Gutierrez, M.; Metsis,
    V.; Nepal, S.; Sheng, Q.Z. IoT middleware: A survey on issues and enabling technologies.
    IEEE Internet Things J. 2016, 4, 1–20. [Google Scholar] [CrossRef] Stirbu, V.
    Towards a restful plug and play experience in the web of things. In Proceedings
    of the 2008 IEEE International Conference on Semantic Computing, Santa Monica,
    CA, USA, 4–7 August 2008; IEEE: Piscataway, NJ, USA, 2008. [Google Scholar] Baraković,
    S.; Baraković Husić, J.; Maraj, D.; Maraj, A.; Krejcar, O.; Maresova, P.; Melero,
    F.J. Quality of life, quality of experience, and security perception in web of
    things: An overview of research opportunities. Electronics 2020, 9, 700. [Google
    Scholar] [CrossRef] Niwarlangga, A.C.; Candra, M.Z.C. Application framework for
    semantic web of things. In Proceedings of the 2020 7th International Conference
    on Advance Informatics: Concepts, Theory and Applications (ICAICTA), Online, 8–9
    September 2020; IEEE: Piscataway, NJ, USA, 2020. [Google Scholar] Datta, S.K.;
    Bonnet, C. Advances in web of things for IoT interoperability. In Proceedings
    of the 2018 IEEE International Conference on Consumer Electronics-Taiwan (ICCE-TW),
    Taichung, Taiwan, 19–21 May 2018; IEEE: Piscataway, NJ, USA, 2018. [Google Scholar]
    Kamilaris, A.; Pitsillides, A.; Prenafeta-Bold, F.X.; Ali, M.I. A Web of Things
    based eco-system for urban computing-towards smarter cities. In Proceedings of
    the 2017 24th International Conference on Telecommunications (ICT), Limassol,
    Cyprus, 3–5 May 2017; IEEE: Piscataway, NJ, USA, 2017. [Google Scholar] Younan,
    M.; Khattab, S.; Bahgat, R. From the wireless sensor networks (WSNs) to the Web
    of Things (WoT): An overview. J. Intell. Syst. Internet Things 2021, 4, 56–68.
    [Google Scholar] [CrossRef] Cimmino, A.; Poveda-Villalón, M.; García-Castro, R.
    eWoT: A semantic interoperability approach for heterogeneous iot ecosystems based
    on the web of things. Sensors 2020, 20, 822. [Google Scholar] [CrossRef] [Green
    Version] Premkumar, M.; Ashokkumar, S.R.; Mohanbabu, G.; Jeevanantham, V.; Jayakumar,
    S. Security behavior analysis in web of things smart environments using deep belief
    networks. Int. J. Intell. Netw. 2022, 3, 181–187. [Google Scholar] [CrossRef]
    Parwej, F.; Akhtar, N.; Perwej, Y. An empirical analysis of web of things (WOT).
    Int. J. Adv. Res. Comput. Sci. 2019, 10, 32–40. [Google Scholar] [CrossRef] Sciullo,
    L.; Gigli, L.; Trotta, A.; Di Felice, M. WoT Store: Managing resources and applications
    on the web of things. Internet Things 2020, 9, 100164. [Google Scholar] [CrossRef]
    Vanden Hautte, S.; Moens, P.; Van Herwegen, J.; De Paepe, D.; Steenwinckel, B.;
    Verstichel, S.; Ongenae, F.; Van Hoecke, S. A dynamic dashboarding application
    for fleet monitoring using semantic web of things technologies. Sensors 2020,
    20, 1152. [Google Scholar] [CrossRef] [PubMed] [Green Version] Pastor-Vargas,
    R.; Tobarra, L.; Robles-Gómez, A.; Martin, S.; Hernández, R.; Cano, J. A wot platform
    for supporting full-cycle iot solutions from edge to cloud infrastructures: A
    practical case. Sensors 2020, 20, 3770. [Google Scholar] [CrossRef] Marsh-Hunn,
    D.; Trilles, S.; González-Pérez, A.; Torres-Sospedra, J.; Ramos, F. A Comparative
    Study in the Standardization of IoT Devices Using Geospatial Web Standards. IEEE
    Sensors J. 2020, 21, 5512–5528. [Google Scholar] [CrossRef] Vresk, T.; Čavrak,
    I. Architecture of an interoperable IoT platform based on microservices. In Proceedings
    of the 2016 39th International Convention on Information and Communication Technology,
    Electronics and Microelectronics (MIPRO), Opatija, Croatia, 30 May–3 June 2016;
    IEEE: Piscataway, NJ, USA, 2016. [Google Scholar] Trilles, S.; Calia, A.; Belmonte,
    Ó.; Torres-Sospedra, J.; Montoliu, R.; Huerta, J. Deployment of an open sensorized
    platform in a smart city context. Futur. Gener. Comput. Syst. 2017, 76, 221–233.
    [Google Scholar] [CrossRef] Huang, C.Y.; Wu, C.H. Design and implement an interoperable
    Internet of Things application based on an extended OGC sensorthings API Standard.
    In Proceedings of the The International Archives of the Photogrammetry, Remote
    Sensing and Spatial Information Sciences, Prague, Czech Republic, 12–19 July 2016.
    [Google Scholar] Trilles, S.; Torres-Sospedra, J.; Belmonte, Ó.; Zarazaga-Soria,
    F.J.; González-Pérez, A.; Huerta, J. Development of an open sensorized platform
    in a smart agriculture context: A vineyard support system for monitoring mildew
    disease. Sustain. Comput. Inform. Syst. 2020, 28, 100309. [Google Scholar] [CrossRef]
    Kotsev, A.; Schleidt, K.; Liang, S.; Van der Schaaf, H.; Khalafbeigi, T.; Grellet,
    S.; Lutz, M.; Jirka, S. Extending INSPIRE to the Internet of Things through SensorThings
    API. Geosciences 2018, 8, 221. [Google Scholar] [CrossRef] [Green Version] Kotsev,
    A.; Minghini, M.; Tomas, R.; Cetl, V.; Lutz, M. From spatial data infrastructures
    to data spaces—A technological perspective on the evolution of European SDIs.
    ISPRS Int. J. Geo-Inf. 2020, 9, 176. [Google Scholar] [CrossRef] [Green Version]
    Granell, C.; Kamilaris, A.; Kotsev, A.; Ostermann, F.O.; Trilles, S. Internet
    of things. In Manual of Digital Earth; Springer Singapore: Singapore, 2020; pp.
    387–423. [Google Scholar] Trilles, S.; Luján, A.; Belmonte, Ó.; Montoliu, R.;
    Torres-Sospedra, J.; Huerta, J. SEnviro: A sensorized platform proposal using
    open hardware and open standards. Sensors 2015, 15, 5555–5582. [Google Scholar]
    [CrossRef] [Green Version] Cao, K.; Liu, Y.; Meng, G.; Sun, Q. An overview on
    edge computing research. IEEE Access 2020, 8, 85714–85728. [Google Scholar] [CrossRef]
    Porambage, P.; Okwuibe, J.; Liyanage, M.; Ylianttila, M.; Taleb, T. Survey on
    multi-access edge computing for internet of things realization. IEEE Commun. Surv.
    Tutor. 2018, 20, 2961–2991. [Google Scholar] [CrossRef] [Green Version] Sha, K.;
    Yang, T.A.; Wei, W.; Davari, S. A survey of edge computing-based designs for IoT
    security. Digit. Commun. Netw. 2020, 6, 195–202. [Google Scholar] [CrossRef] Ahmed,
    E.; Rehmani, M.H. Mobile Edge Computing: Opportunities, Solutions, and Challenges;
    Elsevier: Amsterdam, The Netherlands, 2017; pp. 59–63. [Google Scholar] Pan, J.;
    McElhannon, J. Future edge cloud and edge computing for internet of things applications.
    IEEE Internet Things J. 2017, 5, 439–449. [Google Scholar] [CrossRef] Premsankar,
    G.; Di Francesco, M.; Taleb, T. Edge computing for the Internet of Things: A case
    study. IEEE Internet Things J. 2018, 5, 1275–1284. [Google Scholar] [CrossRef]
    [Green Version] Liu, Y.; Peng, M.; Shou, G.; Chen, Y.; Chen, S. Toward edge intelligence:
    Multiaccess edge computing for 5G and Internet of Things. IEEE Internet Things
    J. 2020, 7, 6722–6747. [Google Scholar] [CrossRef] Hamdan, S.; Ayyash, M.; Almajali,
    S. Edge-computing architectures for internet of things applications: A survey.
    Sensors 2020, 20, 6441. [Google Scholar] [CrossRef] Jararweh, Y.; Doulat, A.;
    AlQudah, O.; Ahmed, E.; Al-Ayyoub, M.; Benkhelifa, E. The future of mobile cloud
    computing: Integrating cloudlets and mobile edge computing. In Proceedings of
    the 2016 23rd International Conference on Telecommunications (ICT), Thessaloniki,
    Greece, 16–18 May 2016; IEEE: Piscataway, NJ, USA, 2016. [Google Scholar] Tong,
    L.; Li, Y.; Gao, W. A hierarchical edge cloud architecture for mobile computing.
    In Proceedings of the IEEE INFOCOM 2016-The 35th Annual IEEE International Conference
    on Computer Communications, San Francisco, CA, USA, 10–14 April 2016; IEEE: Piscataway,
    NJ, USA, 2016. [Google Scholar] Ahmed, E.; Akhunzada, A.; Whaiduzzaman, M.; Gani,
    A.; Ab Hamid, S.H.; Buyya, R. Network-Centric Performance Analysis of Runtime
    Application Migration in Mobile Cloud Computing. Simul. Model. Pract. Theory 2015,
    50, 42–56. [Google Scholar] [CrossRef] Wang, G.; Zhao, Y.; Huang, J.; Wang, W.
    The controller placement problem in software defined networking: A survey. IEEE
    Netw. 2017, 31, 21–27. [Google Scholar] [CrossRef] Zhu, D.; Yang, X.; Zhao, P.;
    Yu, W. Towards effective intra-flow network coding in software defined wireless
    mesh networks. In Proceedings of the 2015 24th International Conference on Computer
    Communication and Networks (ICCCN), Las Vegas, NV, USA, 3–6 August 2015; IEEE:
    Piscataway, NJ, USA, 2015. [Google Scholar] Jararweh, Y.; Doulat, A.; Darabseh,
    A.; Alsmirat, M.; Al-Ayyoub, M.; Benkhelifa, E. SDMEC: Software defined system
    for mobile edge computing. In Proceedings of the 2016 IEEE international conference
    on cloud engineering workshop (IC2EW), Berlin, Germany, 4–8 April 2016; IEEE:
    Piscataway, NJ, USA, 2016. [Google Scholar] Du, P.; Nakao, A. Application specific
    mobile edge computing through network softwarization. In Proceedings of the 2016
    5th IEEE International Conference on Cloud Networking (Cloudnet), Pisa, Italy,
    3–5 October 2016; IEEE: Piscataway, NJ, USA, 2016. [Google Scholar] Manzalini,
    A.; Crespi, N. An edge operating system enabling anything-as-a-service. IEEE Commun.
    Mag. 2016, 54, 62–67. [Google Scholar] [CrossRef] Salman, O.; Elhajj, I.; Kayssi,
    A.; Chehab, A. Edge computing enabling the Internet of Things. In Proceedings
    of the 2015 IEEE 2nd World Forum on Internet of Things (WF-IoT), Milan, Italy,
    14–16 December 2015; pp. 603–608. [Google Scholar] Lin, T.; Park, B.; Bannazadeh,
    H.; Leon-Garcia, A. Demo abstract: End-to-end orchestration across SDI smart edges.
    In Proceedings of the 2016 IEEE/ACM Symposium on edge computing (SEC), Washington,
    DC, USA, 27–28 October 2016; IEEE: Piscataway, NJ, USA, 2016. [Google Scholar]
    Bonomi, F.; Milito, R.; Natarajan, P.; Zhu, J. Fog computing: A platform for internet
    of things and analytics. In Big Data and Internet of Things: A Roadmap for Smart
    Environments; Springer: Berlin/Heidelberg, Germany, 2014; pp. 169–186. [Google
    Scholar] Jiang, H.; Shen, F.; Chen, S.; Li, K.-C.; Jeong, Y.-S. A secure and scalable
    storage system for aggregate data in IoT. Futur. Gener. Comput. Syst. 2015, 49,
    133–141. [Google Scholar] [CrossRef] Hossain, M.M.; Fotouhi, M.; Hasan, R. Towards
    an analysis of security issues, challenges, and open problems in the internet
    of things. In Proceedings of the 2015 IEEE world congress on services, New York,
    NY, USA, 27 June–2 July 2015; IEEE: Piscataway, NJ, USA, 2015. [Google Scholar]
    Yang, X.; Wang, T.; Ren, X.; Yu, W. Survey on improving data utility in differentially
    private sequential data publishing. IEEE Trans. Big Data 2017, 7, 729–749. [Google
    Scholar] [CrossRef] Guinard, D.; Trifa, V.; Wilde, E. A resource oriented architecture
    for the web of things. In Proceedings of the 2010 Internet of Things (IOT), Tokyo,
    Japan, 29 November–1 December 2010; IEEE: Piscataway, NJ, USA, 2010. [Google Scholar]
    Faheem, M.R.; Anees, T.; Hussain, M. The Web of Things: Findability Taxonomy and
    Challenges. IEEE Access 2019, 7, 185028–185041. Available online: https://ieeexplore.ieee.org/abstract/document/8935107
    (accessed on 27 February 2023). [CrossRef] Sardar, R.; Anees, T. Web of Things:
    Security Challenges and Mechanisms. IEEE Access 2021, 9, 31695–31711. [Google
    Scholar] [CrossRef] Ostermaier, B.; Römer, K.; Mattern, F.; Fahrmair, M.; Kellerer,
    W. A real-time search engine for the web of things. In Proceedings of the 2010
    Internet of Things (IOT), Tokyo, Japan, 29 November–1 December 2010; IEEE: Piscataway,
    NJ, USA, 2010. [Google Scholar] Wang, H.; Tan, C.C.; Li, Q. Snoogle: A search
    engine for pervasive environments. IEEE Trans. Parallel Distrib. Syst. 2009, 21,
    1188–1202. [Google Scholar] [CrossRef] [Green Version] Tan, C.C.; Sheng, B.; Wang,
    H.; Li, Q. Microsearch: When search engines meet small devices. In Proceedings
    of the Pervasive Computing: 6th International Conference, Pervasive 2008, Sydney,
    Australia, 19–22 May 2008; Springer: Berlin/Heidelberg, Germany, 2008. [Google
    Scholar] Yap, K.-K.; Srinivasan, V.; Motani, M. Max: Human-centric search of the
    physical world. In Proceedings of the 3rd international conference on Embedded
    networked sensor systems, San Diego, CA, USA, 2–4 November 2005; pp. 166–179.
    [Google Scholar] Blanco, J.M.; Ge, M.; Pitner, T. Modeling Inconsistent Data for
    Reasoners in Web of Things. Procedia Comput. Sci. 2021, 192, 1265–1273. [Google
    Scholar] [CrossRef] Schneier, B. The internet of things is wildly insecure-and
    often unpatchable. Schneier Secur. 2014, 6. Available online: https://www.wired.com/2014/01/theres-no-good-way-to-patch-the-internet-of-things-and-thats-a-huge-problem/
    (accessed on 27 February 2023). Kim, H. Protection against packet fragmentation
    attacks at 6LoWPAN adaptation layer. In Proceedings of the 2008 International
    conference on convergence and hybrid information technology, Daejeon, Republic
    of Korea, 28–30 August 2008; IEEE: Piscataway, NJ, USA, 2008. [Google Scholar]
    Chen, G.; Yau, N.; Hansen, M.; Estrin, D. Sharing Sensor Network Data; UCLA: Center
    for Embedded Network Sensing: Los Angeles, CA, USA, 2007. [Google Scholar] Guinard,
    D.; Trifa, V. Towards the web of things: Web mashups for embedded devices. In
    Proceedings of the Workshop on Mashups, Enterprise Mashups and Lightweight Composition
    on the Web (MEM 2009), Madrid, Spain, 20 April 2009. [Google Scholar] Lin, X.;
    Andrews, J.G.; Ghosh, A.; Ratasuk, A. An overview of 3GPP device-to-device proximity
    services. IEEE Commun. Mag. 2014, 52, 40–48. [Google Scholar] [CrossRef] [Green
    Version] Greenberg, A.; Hamilton, J.; Maltz, D.A.; Patel, P. The Cost of a Cloud:
    Research Problems in Data Center Networks; ACM: New York, NY, USA, 2008; pp. 68–73.
    [Google Scholar] Armbrust, M.; Fox, A.; Griffith, R.; Joseph, A.D.; Katz, R.;
    Konwinski, A.; Lee, G.; Patterson, D.; Rabkin, A.; Stoica, I. A view of cloud
    computing. Commun. ACM 2010, 53, 50–58. [Google Scholar] [CrossRef] [Green Version]
    Alam, Q.; Malik, S.U.; Akhunzada, A.; Choo, K.-K.R.; Tabbasum, S.; Alam, M. A
    Cross Tenant Access Control (CTAC) Model for Cloud Computing: Formal Specification
    and Verification. IEEE Trans. Inf. Forensics Secur. 2016, 12, 1259–1268. [Google
    Scholar] [CrossRef] Jackson, K.R.; Ramakrishnan, L.; Muriki, K.; Canon, S.; Cholia,
    S.; Shalf, J.; Wasserman, H.J.; Wright, N.J. Performance analysis of high performance
    computing applications on the amazon web services cloud. In Proceedings of the
    2010 IEEE Second International Conference on Cloud Computing Technology and Science,
    Indianapolis, IN, USA, 30 November–3 December 2010; IEEE: Piscataway, NJ, USA,
    2010. [Google Scholar] Li, A.; Yang, X.; Kandula, S.; Zhang, M. CloudCmp: Comparing
    public cloud providers. In Proceedings of the 10th ACM SIGCOMM conference on Internet
    measurement, Melbourne, Australia, 1–30 November 2010. [Google Scholar] Wadhwa,
    H.; Aron, R. TRAM: Technique for Resource Allocation and Management in Fog Computing
    Environment. J. Supercomput. 2022, 78, 667–690. [Google Scholar] [CrossRef] Hussain,
    S.M.; Wahid, A.; Shah, M.A.; Akhunzada, A.; Khan, F.; ul Amin, N.; Arshad, S.;
    Ali, I. Seven Pillars to Achieve Energy Efficiency in High-Performance Computing
    Data Centers. In Recent Trends and Advances in Wireless and IoT-Enabled Networks;
    Springer International Publishing: Cham, Switzerland, 2019. [Google Scholar] Satyanarayanan,
    M. Mobile computing: The next decade. ACM SIGMOBILE Mob. Comput. Commun. Rev.
    2011, 15, 2–10. [Google Scholar] [CrossRef] Miettinen, A.P.; Nurminen, J.K. Energy
    efficiency of mobile clients in cloud computing. In Proceedings of the 2nd USENIX
    Workshop on Hot Topics in Cloud Computing (HotCloud 10), Boston, MA, USA, 22–25
    June 2010. [Google Scholar] Chun, B.-G.; Ihm, S.; Maniatis, P.; Naik, M.; Patti,
    A. Clonecloud: Elastic execution between mobile device and cloud. In Proceedings
    of the Sixth Conference on Computer Systems, Alzburg, Austria, 10–13 April 2011.
    [Google Scholar] Ding, N.; Wagner, D.; Chen, X.; Pathak, A.; Hu, Y.C.; Rice, A.
    Characterizing and modeling the impact of wireless signal strength on smartphone
    battery drain. ACM SIGMETRICS Perform. Eval. Rev. 2013, 41, 29–40. [Google Scholar]
    [CrossRef] [Green Version] Ma, M.; Wang, P.; Chu, C.-H. Data management for internet
    of things: Challenges, approaches and opportunities. In Proceedings of the 2013
    IEEE International Conference on Green Computing and Communications and IEEE Internet
    of Things and IEEE Cyber, Physical and Social Computing, Beijing, China, 20–23
    August 2013; IEEE: Piscataway, NJ, USA, 2013. [Google Scholar] Toor, A.; ul Islam,
    S.; Sohail, N.; Akhunzada, A.; Boudjadar, J.; Khattak, H.A.; Din, I.U.; Rodrigues,
    J.J. Energy and Performance Aware Fog Computing: A Case of DVFS and Green Renewable
    Energy. Future Gener. Comput. Syst. 2019, 101, 1112–1121. [Google Scholar] [CrossRef]
    Khan, M.T.; Akhunzada, A.; Zeadally, S. Proactive Defense for Fog-to-Things Critical
    Infrastructure. IEEE Commun. Mag. 2022, 60, 44–49. [Google Scholar] [CrossRef]
    Khan, W.Z.; Rafique, W.; Haider, N.; Hakak, S.; Imran, M. Internet of Everything:
    Enabling Technologies, Applications, Security and Challenges. 2022. Available
    online: https://www.techrxiv.org/articles/preprint/Internet_of_Everything_Enabling_Technologies_Applications_Security_and_Challenges/21341796
    (accessed on 27 February 2023). Mosenia, A.; Jha, N.K. A comprehensive study of
    security of internet-of-things. IEEE Trans. Emerg. Top. Comput. 2016, 5, 586–602.
    [Google Scholar] [CrossRef] Noura, M.; Atiquzzaman, M.; Gaedke, M. Interoperability
    in internet of things: Taxonomies and open challenges. Mob. Netw. Appl. 2019,
    24, 796–809. [Google Scholar] [CrossRef] [Green Version] Gupta, A.; Christie,
    R.; Manjula, R. Scalability in internet of things: Features, techniques and research
    challenges. Int. J. Comput. Intell. Res. 2017, 13, 1617–1627. [Google Scholar]
    Shukla, S.; Hassan, M.F.; Tran, D.C.; Akbar, R.; Paputungan, I.V.; Khan, M.K.
    Improving latency in Internet-of-Things and cloud computing for real-time data
    transmission: A systematic literature review (SLR). Clust. Comput. 2021, 1–24.
    [Google Scholar] [CrossRef] Liu, C.H.; Fan, J.; Branch, J.W.; Leung, K.K. Toward
    QoI and energy-efficiency in Internet-of-Things sensory environments. IEEE Trans.
    Emerg. Top. Comput. 2014, 2, 473–487. [Google Scholar] [CrossRef] Botta, A.; De
    Donato, W.; Persico, V.; Pescapé, A. Integration of cloud computing and internet
    of things: A survey. Futur. Gener. Comput. Syst. 2016, 56, 684–700. [Google Scholar]
    [CrossRef] Haghi Kashani, M.; Rahmani, A.M.; Jafari Navimipour, N. Quality of
    Service-Aware Approaches in Fog Computing. Int. J. Commun. Syst. 2020, 33, e4340.
    [Google Scholar] [CrossRef] Febrer, N.; Folkvord, F.; Lupiañez-Villanueva, F.
    Cost-effectiveness assessment of internet of things in smart cities. Front. Digit.
    Health 2021, 3, 662874. [Google Scholar] [CrossRef] [PubMed] Faheem, M.R.; Anees,
    T.; Hussain, M. Development of a Novel Ranking Mechanism and Search Engine in
    Web of Things; OSF: Galesburg, IL, USA, 2022. [Google Scholar] Faheem, M.R.; Anees,
    T.; Hussain, M. Keywords and Spatial Based Indexing for Searching the Things on
    Web. KSII Trans. Internet Inf. Syst. 2022, 16, 1489–1515. [Google Scholar] Ahmed,
    E.; Gani, A.; Sookhak, M.; Ab Hamid, S.H.; Xia, F. Application optimization in
    mobile cloud computing: Motivation, taxonomies, and open challenges. J. Netw.
    Comput. Appl. 2015, 52, 52–68. [Google Scholar] [CrossRef] Yang, R.; Yu, F.R.;
    Si, P.; Yang, Z.; Zhang, Y. Integrated blockchain and edge computing systems:
    A survey, some research issues and challenges. IEEE Commun. Surv. Tutor. 2019,
    21, 1508–1532. [Google Scholar] [CrossRef] Khan, W.Z.; Aalsalem, M.Y.; Khan, M.K.;
    Arshad, Q. Data and privacy: Getting consumers to trust products enabled by the
    Internet of Things. IEEE Commun. Surv. Tutor. 2019, 8, 35–38. [Google Scholar]
    [CrossRef] Hussein, N.; Nhlabatsi, A. Living in the Dark: MQTT-Based Exploitation
    of IoT Security Vulnerabilities in ZigBee Networks for Smart Lighting Control.
    IoT 2022, 3, 450–472. [Google Scholar] [CrossRef] Al-Roomi, M.; Al-Ebrahim, S.;
    Buqrais, S.; Ahmad, I. Cloud computing pricing models: A survey. Int. J. Grid
    Distrib. Comput. 2013, 6, 93–106. [Google Scholar] [CrossRef] Bertolli, C.; Buono,
    D.; Mencagli, G.; Torquati, M.; Vanneschi, M.; Mordacchini, M.; Nardini, F.M.
    Resource discovery support for time-critical adaptive applications. In Proceedings
    of the 6th International Wireless Communications and Mobile Computing Conference,
    Caen, France, 28 June–2 July 2010. [Google Scholar] Kientopf, K.; Raza, S.; Lansing,
    S.; Güneş, M. Service Management Platform to Support Service Migrations for IoT
    Smart City Applications. In Proceedings of the 2017 IEEE 28th Annual International
    Symposium on Personal, Indoor, and Mobile Radio Communications (PIMRC), Montreal,
    QC, Canada, 8–13 October 2017; pp. 1–5. [Google Scholar] Kirci, P. Ubiquitous
    and Cloud computing: Ubiquitous computing. In Resource Management and Efficiency
    in Cloud Computing Environments; IGI Global: Hershey, PA, USA, 2017; pp. 1–32.
    [Google Scholar] Ahmed, E.; Gani, A.; Khan, M.K.; Buyya, R.; Khan, S.U. Seamless
    application execution in mobile cloud computing: Motivation, taxonomy, and open
    challenges. J. Netw. Comput. Appl. 2015, 52, 154–172. [Google Scholar] [CrossRef]
    Li, X.; Liu, S.; Wu, F.; Kumari, S.; Rodrigues, J.J. Privacy preserving data aggregation
    scheme for mobile edge computing assisted IoT applications. IEEE Internet Things
    J. 2018, 6, 4755–4763. [Google Scholar] [CrossRef]  Disclaimer/Publisher’s Note:
    The statements, opinions and data contained in all publications are solely those
    of the individual author(s) and contributor(s) and not of MDPI and/or the editor(s).
    MDPI and/or the editor(s) disclaim responsibility for any injury to people or
    property resulting from any ideas, methods, instructions or products referred
    to in the content.  © 2023 by the authors. Licensee MDPI, Basel, Switzerland.
    This article is an open access article distributed under the terms and conditions
    of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/).
    Share and Cite MDPI and ACS Style Anees, T.; Habib, Q.; Al-Shamayleh, A.S.; Khalil,
    W.; Obaidat, M.A.; Akhunzada, A. The Integration of WoT and Edge Computing: Issues
    and Challenges. Sustainability 2023, 15, 5983. https://doi.org/10.3390/su15075983
    AMA Style Anees T, Habib Q, Al-Shamayleh AS, Khalil W, Obaidat MA, Akhunzada A.
    The Integration of WoT and Edge Computing: Issues and Challenges. Sustainability.
    2023; 15(7):5983. https://doi.org/10.3390/su15075983 Chicago/Turabian Style Anees,
    Tayyaba, Qaiser Habib, Ahmad Sami Al-Shamayleh, Wajeeha Khalil, Muath A. Obaidat,
    and Adnan Akhunzada. 2023. \"The Integration of WoT and Edge Computing: Issues
    and Challenges\" Sustainability 15, no. 7: 5983. https://doi.org/10.3390/su15075983
    Note that from the first issue of 2016, this journal uses article numbers instead
    of page numbers. See further details here. Article Metrics Citations Crossref   6
    Web of Science   4 Scopus   4 Google Scholar   [click to view] Article Access
    Statistics Article access statistics Article Views 29. Dec 8. Jan 18. Jan 28.
    Jan 7. Feb 17. Feb 27. Feb 8. Mar 18. Mar 0 500 1000 1500 2000 2500 For more information
    on the journal statistics, click here. Multiple requests from the same IP address
    are counted as one view.   Sustainability, EISSN 2071-1050, Published by MDPI
    RSS Content Alert Further Information Article Processing Charges Pay an Invoice
    Open Access Policy Contact MDPI Jobs at MDPI Guidelines For Authors For Reviewers
    For Editors For Librarians For Publishers For Societies For Conference Organizers
    MDPI Initiatives Sciforum MDPI Books Preprints.org Scilit SciProfiles Encyclopedia
    JAMS Proceedings Series Follow MDPI LinkedIn Facebook Twitter Subscribe to receive
    issue release notifications and newsletters from MDPI journals Select options
    Subscribe © 1996-2024 MDPI (Basel, Switzerland) unless otherwise stated Disclaimer
    Terms and Conditions Privacy Policy"'
  inline_citation: '>'
  journal: Sustainability (Switzerland)
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: 'The Integration of WoT and Edge Computing: Issues and Challenges'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Chaudhary M.
  - Goyal N.
  - Benslimane A.
  - Awasthi L.K.
  - Alwadain A.
  - Singh A.
  citation_count: '11'
  description: The development of underwater wireless sensor networks (UWSNs) has
    attracted great interest from many researchers and scientists to detect and monitor
    unfamiliar underwater domains. To achieve this goal, collecting data with an underwater
    network of sensors is primordial. Moreover, real-time information transmission
    needs to be achieved through efficient and enabling technologies for node deployment
    and data collection in UWSN. The Internet of Things (IoT) helps in real-time data
    transmission, and it has great potential in UWSN, i.e., the Internet of Underwater
    Things (IoUT). The IoUT is a modern communication ecosystem for undersea things
    in marine and underwater environments. Intelligent boats and ships, automatic
    maritime transportation, location and navigation, undersea discovery, catastrophe
    forecasting, and avoidance, as well as intelligent monitoring and security are
    all intertwined with the IoUT technology. In this article, the enabling technologies
    of UWSN along with several fundamental key aspects are scrupulously explained.
    The study aims to inquire about node deployment and data collection strategies,
    and then encourages researchers to lay the groundwork for new node deployment
    and advanced data collection techniques that enable effective underwater communication
    techniques. Besides different types of communication media, applications of UWSNs
    are also part of this article. Various existing data collection protocols based
    on the deployment models are simulated using network simulator (NS 2.30) to analyze
    and compare the performance of state-of-the-art techniques.
  doi: 10.1109/JIOT.2022.3218766
  full_citation: '>'
  full_text: '>

    "This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org
    IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal
    Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln
    Sign Out All Books Conferences Courses Journals & Magazines Standards Authors
    Citations ADVANCED SEARCH Journals & Magazines >IEEE Internet of Things Journal
    >Volume: 10 Issue: 4 Underwater Wireless Sensor Networks: Enabling Technologies
    for Node Deployment and Data Collection Challenges Publisher: IEEE Cite This PDF
    Monika Chaudhary; Nitin Goyal; Abderrahim Benslimane; Lalit Kumar Awasthi; Ayed
    Alwadain; Aman Singh All Authors 14 Cites in Papers 1070 Full Text Views Abstract
    Document Sections I. Introduction II. Node Deployment in UWSN III. Data Collection
    Approaches/Techniques IV. Applications V. Performance Evaluation Show Full Outline
    Authors Figures References Citations Keywords Metrics Abstract: The development
    of underwater wireless sensor networks (UWSNs) has attracted great interest from
    many researchers and scientists to detect and monitor unfamiliar underwater domains.
    To achieve this goal, collecting data with an underwater network of sensors is
    primordial. Moreover, real-time information transmission needs to be achieved
    through efficient and enabling technologies for node deployment and data collection
    in UWSN. The Internet of Things (IoT) helps in real-time data transmission, and
    it has great potential in UWSN, i.e., the Internet of Underwater Things (IoUT).
    The IoUT is a modern communication ecosystem for undersea things in marine and
    underwater environments. Intelligent boats and ships, automatic maritime transportation,
    location and navigation, undersea discovery, catastrophe forecasting, and avoidance,
    as well as intelligent monitoring and security are all intertwined with the IoUT
    technology. In this article, the enabling technologies of UWSN along with several
    fundamental key aspects are scrupulously explained. The study aims to inquire
    about node deployment and data collection strategies, and then encourages researchers
    to lay the groundwork for new node deployment and advanced data collection techniques
    that enable effective underwater communication techniques. Besides different types
    of communication media, applications of UWSNs are also part of this article. Various
    existing data collection protocols based on the deployment models are simulated
    using network simulator (NS 2.30) to analyze and compare the performance of state-of-the-art
    techniques. Published in: IEEE Internet of Things Journal ( Volume: 10, Issue:
    4, 15 February 2023) Page(s): 3500 - 3524 Date of Publication: 10 November 2022
    ISSN Information: DOI: 10.1109/JIOT.2022.3218766 Publisher: IEEE Funding Agency:
    SECTION I. Introduction The widespread adoption of the wireless sensor network
    (WSN) in various application areas and the speedy development of the sensor technology
    have encouraged the development of the underwater WSN (UWSN) in the oceans. Just
    like underground, sensor nodes, and vehicles are deployed under the water for
    environmental monitoring. The ability to physically distribute devices while sensing
    and monitoring them opens up new opportunities to observe and act on both above
    and below the Earth [1]. UWSN is emerging as an enabling technology for aquatic
    applications and exploration. At the same time, UWSN and terrestrial WSN both
    share some common properties, such as wireless connectivity, whereas, at the same
    time, share many points of difference too, like medium, bandwidth, mobility, etc.
    As a result of these differences, new specialized protocols and methods for working
    in underwater networks are required [2]. UWSN is being deployed for a wide range
    of marine applications, such as natural disaster prevention, oceanographic data
    collection, pollution or environmental monitoring, weather recording, navigation,
    and enemy attack protection. The applicability of Internet of Things (IoT) for
    underwater communication combined to form Internet of Underwater Things (IoUT)
    as shown in Fig. 1. IoUT emerged as an influential tool for real-time underwater
    communication. IoUT is helpful in environmental assessment, assistance in various
    activities, such as water exploration and accident prevention. The IoUT is defined
    as the network of smart interconnected underwater objects. Implementation areas
    of IoUT are environmental monitoring, underwater exploration, disaster prevention,
    and military [3]. As compare to the customary monitoring approaches, to deploy
    sensor nodes in the aquatic environment and also monitoring through the IoUT can
    effectively increase the environmental monitoring capabilities. The IoUT is a
    new revolution for the Blue Economy sector, offering the capacity to discern,
    automate, and transmit information in marine and ocean environments using minimal
    technologies similar to those used in conventional IoT. It necessitates unique
    underwater functionalities that are at the heart of the created system. An extensive
    research in IoUT has been conducted and tests for a variety of applications, including
    underwater athletics, amusement, and ecotourism. FunDive is a revolutionary wearable
    technology for divers developed under the EC EASME ARCHEO-SUB that allows for
    real-time tracking of the swimmers’ positions and medical conditions. It requires
    only two components one is a small undersea sensor and other is an aquatic tablet.
    An acoustical modem, aquatic networking, and data compression circuitry, also
    a battery system, are all housed in the compact underwater sensor node. A specific
    application is installed on the table that is connected to the node. Divers can
    use the system to converse underwater, locate themself, and navigate to locations
    of interest. Sensors are deployed at sea bed, transfer the data toward sea surface
    nodes by horizontal or vertical links. This data in real time is transferred to
    on-shore station using IoUT. Moreover, IoUT evolved as a promising network system
    having interconnected underwater devices used to improve speed of data collection
    and other QoS for the system. The future directions for implementing IoUT handling
    big data in terms of electrical conductivity, dissolved oxygen, and temperature
    in an underwater environment through ROVs and portable UWSNs [4]. Fig. 1. IoUT.
    Show All The UWSN architecture includes both static and mobile nodes. A static
    sensor unit is usually placed on the sea floor and connected to a sink unit. In
    mobility assisted network, sensor nodes can travel freely, that results in dynamic
    network topology. The mobile nodes need mainly two transceivers for increasing
    the data collection capacity of the network. These can be ROVs, AUVs, and sea
    gliders. The ROVs can be submerged robots, ships, and also submarines. Since the
    communication is sent directly to the ROVs, sensors with large amounts of data
    and close to the ROVs can use radio communication, while sensors with small data
    transmission or far away from the ROVs can use acoustic channels [5]. A. Motivation
    and Significance Some deadly disasters, like Tsunamis are caused by the movement
    of tectonic plates in the oceans. Although it cannot be stopped now, prior knowledge
    of these disasters can save many lives. This encourages us to uncover these catastrophes
    so that effective and preventive measures can be taken in advance. By deploying
    UWSN, one can think of a future time when there will be more control over all
    underwater activities. Hence, this research helps in exploring numerous areas
    of application or possibilities under the water also. It will also help to prevent,
    or at least mitigate, further loss of natural habitat life. This control will
    be gained by deploying such sensors underwater to sense the danger and inform
    us in time. Here, one critical aspect is that exploration of the ocean or aqueous
    is not an easy task. Researchers from academia and industry are trying to make
    use of technological advancements in WSN to replace the traditional ocean exploration
    methods. Hence, a reliable and efficient communication system is the need of the
    hour to unravel the unknown. The availability of modern sensor node technologies
    and the rapid growth of UWSNs has enforced the essential requirement to assure
    that attention is expanding every year because of their compatibility and extensive
    applications in various domains. B. Organization This survey aims to offer the
    readers comprehensive insights of UWSN and the in-depth knowledge of node deployment
    and data collection in UWSN. To the best of our knowledge, there is no survey
    covering both the broad range of node deployment and data collection methods with
    UWSN fundamentals. This work’s primary focus is to broaden the horizons of potentials
    related to underwater exploration and familiarize the existing node deployment
    technique, their advantage and disadvantages so that effective strategies providing
    maximum coverage with the minimum number of nodes to conceive future applications.
    Along with it, survey targets at examining the difficulties with the existing
    scheme of data collection. The problem in the current scenario of data collection
    can be avoided and providing real-time underwater communication. To boldly and
    explicitly illustrate the contributions in this article are as follows. This article
    enable the readers with a robust and coherent understanding of UWSN terminologies.
    Also, motivation for researchers to work in this emerging area is depicted by
    stating various applications. Meticulously demonstration of node deployment, with
    the taxonomy of existing models and the comparative analysis based on various
    parameters is presented. The challenges of node deployment with upcoming issues
    are also discussed. Detailed analysis of UWSN’s data collection approaches that
    are prerequisites for effective communication in almost all the applications with
    taxonomy based on intermediate or forwarding node is discussed. Table I summarizes
    and compares the recent existing survey with the proposed survey. In this table,
    various existing study are compared on the basis of different parameters focusing
    on node deployment and data collection field that are important for many applications.
    TABLE I Comparative Analysis of the Proposed Study With Recent Surveys in UWSN
    The remainder of this article is organized as follows. This survey consists of
    a total of seven sections. The communication techniques in UWSN is discussed in
    Section II. The node deployment techniques with their comparison are discussed
    in Section III. Data collection methods with literature are presented in Section
    IV. UWSN applications are summarized in Section V. The performance comparison
    of some of the existing data collection techniques is compared and analyzed in
    Section VI. Section VII presented the future challenges in IoUT and outcomes of
    the study. In the end, the conclusion is presented in Section VII. C. Communication
    Techniques in UWSN UWSN is that vast area with different fields and avenues for
    research, such as the design of efficient routing protocols, node localization
    techniques for data capturing, node deployment strategies for better coverage,
    communication protocols, and different communication mediums. For better sensing
    and surveillance schemes in UWSN, i.e., to acquire data timely, it is required
    to understand ocean environments’ complexities. Underwater acoustic communication
    is an important part of underwater data collection. To achieve high communication
    speeds and high data rates, the system transmits multiple channels simultaneously
    and is based on a modulation system that uses cable connections called orthogonal
    frequencies multiplexing. This allows researchers to output hundreds of bits at
    a time [11]. In UWSN, we have three existing approaches and an advanced approach
    called magnetic induction (MI) for underwater communication [12]. These are as
    follows. The very first technology used was electromagnetic (EM) waves, i.e.,
    radio frequency (RF) that is popular for communication over short ranges with
    the high data rate. The optical signal technique is used under the water to attain
    large bandwidth and high data rate [13]. Most widely used technology is acoustic
    communication used for the longest-range communication under the water. Additionally,
    we have another approach: MI communication based on time-varying magnetic wave.
    Currently, research in this communication field is of great interest for many
    researchers [14]. It can address the issues of dynamic channel conditions and
    the larger antenna size due to using EM wave. MI-based underwater communications
    possess numerous encouraging and exclusive features, such as channel behavior,
    minor signal propagation delay, adequately long communication range with high
    bandwidth, and underwater stealth operations [15]. Opposite to terrestrial or
    ground-based wireless communication, RF signals behavior is different or not respondent
    below the water [16]. Underwater communication channels are dynamic in nature
    depending upon the action to varying depths inside water. At some areas, the communication
    medium is dense along with more salinity of water, with it, even the high-frequency
    RF signals face an increased attenuation [17]. EM communication with low-frequency
    signals needs a large sized antenna that is impractical in the underwater sensor
    network. Table II shows the comparison of different mediums of communication used
    in UWSN based on various parameters [18]. Despite many benefits of using an acoustic
    medium in an underwater environment for communication, the speed is slow compared
    to other mediums. These communication patterns are chosen based on different situations
    like the distance between the surface buoy and deployed nodes like for small distance
    underwater communications, optical, and magnetic field signals are appropriate
    to use [19]. Long-distance underwater communication is attained using acoustic
    signals. Here, these communication mediums explained in detail. TABLE II Comparison
    of Different Mediums of Communication Used in UWSN Acoustic Medium: United States
    settled the first underwater audio communication setup using a single sideband
    (SSB) suppressed carrier amplitude modulation between 8 and 15 kHz carrier frequencies
    [20]. This is one of the most preferred signals used in numerous underwater applications,
    because of its absorption characteristic in an aqueous environment. However, data
    transmission is slow in acoustic communication as compared to other mediums. Due
    to the low absorption characteristic, signals travel at more extended range [21].
    Despite the fact that acoustic waves are used for long-distance communication,
    it cannot provide high-bandwidth signals. Based on signal propagation distance,
    acoustic waves are categorized as very short, short, medium, long, and very long
    distances. The acoustic channel model described by Stojanovic [18] where the path
    loss characterizes acoustic signals that depends on the distance among sender
    and receiver. The attenuation or path loss over the distance d and frequency f
    is given by A(d,f)= A 0 d k a (f) d (1) View Source where A 0 is a normalizing
    constant, a(f) is the absorption coefficient, and k is spreading factor. The acoustic
    path loss (in dB) is given by using the following equation: 10logA(d,f)/ A o =k.10logd+d.10loga(f).
    (2) View Source The first part in (3.2) denotes the spreading loss, and the second
    part shows the absorption loss. The factor k in the first part represents the
    geometry of propagation. Its commonly used values according to different shapes
    are k=2 for spherical, and k=1 for cylindrical spreading. Using Thorp’s formula,
    the absorption coefficient can be presented by the equation 10loga(f)= 0.11 f
    2 1+ f 2 +44 f 2 4100+ f 2 +2.75⋅ 10 −4 f 2 +0.003. (3) View Source It gives a(f)
    in dB/km for f in kHz. This equation works for frequencies above a few hundred
    Hz, and if the frequencies are lower then, the equation can be 10loga(f)=0.002
    f 2 1+ f 2 +0.11 f 2 4100+ f 2 +0.011 f 2 . (4) View Source The sea’s ambient
    noise is usually exhibited by four sources: 1) shipping; 2) turbulence; 3) thermal
    noise; and 4) waves. Ambient noise sources can be defined by Gaussian statistics
    and continuous power spectral density. Coates [19] gave the empirical formula
    to provide the four noise components’ power spectral density in dB per Hz as a
    frequency function in kHz 10log N t (f)= 10log N sh (f)= 10log N w (f)= 10log
    N th (f)= 17−30logf 40+20(s−0.5)+26logf −60log(f+0.03) 50+7.5 w 0.5 +20logf−40log(f+0.4)
    −15+20logf (5) (6) (7) (8) View Source where N t is turbulence noise, N sh is
    shipping noise, N w is wave noise, and N th is thermal noise. Here, w is the speed
    of wind measured in meter per second, and s is the shipping factor having value
    from 0 to 1. The overall power spectral density of the ambient noise is determined
    by N(f)= N t (f)+ N sh (f)+ N w (f)+ N th (f). (9) View Source Electro-Magnetic
    Medium: This communication medium is recognized at a higher bandwidth. Whereas,
    high attenuation causes constraint to affect the quality of the communicated signal
    considerably. In these big antennas of approximately 0.5 m is needed, affecting
    the design complexity and cost [23]. Extensive research work has been conceded
    regarding RF frequencies, but sea water conductivity affects it from the high
    losses. Also, in sea water 4 mhos/m is considered as the average conductivity,
    i.e., two orders higher than fresh water conductivity. Because of this, absorption
    loss increases at high frequencies [24]. The absorption coefficient of sea water,
    i.e., α_seawater is related to conductivity as a_seawater=√πfμσ (10) View Source
    where f is the operating frequency in kHz, σ the water conductivity, and μ the
    permeability. Opposite to it, the absorption coefficient of freshwater, i.e.,
    α_freshwater is fundamental frequency independent and calculated by α_freshwater≈
    σ 2 π ϵ − − √ . (11) View Source Here, ϵ is the permittivity defined. Therefore,
    RF communication is better in fresh water. However, it needs a huge sized antenna
    that is not feasible under the water. Optical Medium: This offers a high data
    rate transmission, but scattering and absorption affect signal strength and accuracy
    [25]. The optical medium possesses many explicit characteristics during communication
    at different frequencies over distinct ranges with a diverse underwater medium.
    Schirripa et al. [26] stated that with advanced bandwidth, optical communications
    could provision progressive data rates with comparatively lower acoustic or RF
    communication latency. However, an optical medium can never totally oust the acoustic
    communication. Scattering and absorption are two mechanisms that damage the light
    propagation in water and deteriorate optical medium use in underwater communication.
    The propagation in water of collimated light is described by the attenuation coefficient
    c ( λ ). Where c ( λ ) is wavelength function parameter. As described by Xu [27],
    this is a summation of term a ( λ ) (absorption coefficient) and b ( λ ) (scattering
    coefficient) c(λ)=a(λ)+b(λ). (12) View Source The variation in the values of a
    ( λ ) and b ( λ ) comes due to different water types along with fluctuating wavelength
    as shown in Table VI. There can be different water types in underwater communications
    [28], such as pure sea water, clean ocean water, coastline ocean water, and turboid
    harbor water. Here, distinct values of chlorophyll concentration C illustrate
    different types of water. So, the coefficient for absorption a ( λ ) and scattering
    b ( λ ) will be a(λ)= b(λ)= [ a w (λ)+0.06 a c (λ) C 0.65 ] ×{1+0.2exp[−0.014(λ−440)]}
    0.30 550 λ C 0.62 (13) (14) View Source where a w shows the pure water absorption
    coefficient and a c is a nondimensional quantity. Here, chlorophyll concentration
    C, (in mg/m3) is used as the open parameter. The experimental values of these
    coefficients are depicted in Table III. TABLE III Values for Different Types of
    Water TABLE IV UWSN Node Deployment Protocols Properties Comparison TABLE V Summary
    of Data Collection Approaches Based on Existing Methods TABLE VI Simulation Parameters
    MI: This highly efficient communication medium based on a time-varying magnetic
    field is newly used to transmit information between different ends. Due to this
    property, it exhibits exceptionally reliable and steady channel performance, with
    minor multipath fading, high bandwidth, high communication range, and small-size
    coil antennas requirement. Akylidz et al. [29] examined that the standard and
    most used acoustic waves while promising longer communication ranges in underwater
    communication exhibit long propagation delay and unpredictable and irregular channel
    behavior. UWSN is a broad research area with many fields, such as node deployment,
    data collection, data aggregation, data fusion, underwater communication, localization
    of nodes, etc. As data collection is used in almost every application of UWSN,
    it needs significant attention. In the next section, the existing data collection
    techniques proposed by many researchers are discussed. SECTION II. Node Deployment
    in UWSN A substantial amount of research has concentrated on node deployment algorithms
    as they are of utmost importance for every part of UWSN. To improve packet delivery
    ratio (PDR), most research aims for maximum coverage and high network connectivity
    with the fewest required nodes and energy consumption [30]. UWSN networks are
    more prone to issues, such as the mobility of deployed nodes, high latency, 3-D
    deployment, and communication delays related to the deployment of sensor nodes
    in particular monitored areas. Along with the assurance of coverage and connectivity,
    node deployment also aims to reduce energy consumption. The advancement in extensive
    deployments of UWSN is intended to monitor large zones of oceanic water. A. Node
    Deployment Introduction The deployment of nodes is one of the fundamental concerns
    in UWSN [31]. The node deployment problem can be indicated as having a designated
    area D a to be covered and N number of sensors. The main concern is determining
    how to locate these N sensor nodes to set up a UWSN that meets the system requirements
    and its capability to discover relevant events happening in designated area D
    a . Here, node deployment may directly affect node (sensor/sink) locations their
    connections and availability. UWSN in some conditions provides a 3-D domain, where
    all the objects are in constant motion. As a result, node deployment, which is
    a costly task in these harsh aquatic environments becomes challenging [32]. There
    are substantial topological changes as deployed nodes are free to float in water.
    It is assumed that numerous homogeneous underwater sensor nodes having limited
    capabilities are submerged into the sea area to monitor environmental changes
    and record useful ecological changes in the form of data, as shown in Fig. 2.
    Fig. 2. Typical node deployment scenario. Show All Several researchers are focusing
    on node deployment issues in UWSN over the past few years [33]. In AUV-aided data
    collection, the sensor nodes’ deployment information plays a critical role as
    nodes have to communicate with AUVs. The AUVs can navigate using the node location
    information (in some cases already known), to stop near a sensor to gather data.
    The deployed sensor nodes are examined as static or fixed nodes because nodes
    are anchored to the ocean floor or sea bed [35]. For sensor node deployment, network
    topology also plays an essential role in almost all issues, such as communication
    performance of a network, power consumption, and reliability with fault tolerance
    proficiencies. B. Node Deployment Related Work Sensor network deployment techniques
    are essential for any network, as stated by Deif and Gadallah [36]. The placement
    of nodes may directly affect their locations, connection, and availability of
    the network. The node deployment algorithms for UWSN are divided into three main
    categories: 1) self-adjustment; 2) static; and 3) movement assisted [37], as shown
    in Fig. 3. Further, these algorithms have different schemes or techniques. Fig.
    3. Taxonomy of node deployment algorithms in UWSN. Show All In static or fixed
    node deployment arrangement, all the nodes are static even next to the initial
    deployment under the water. The deployed sensor nodes are either linked with surface
    buoys through the fins or anchored at the ocean bottom surface but must be considered
    to have fixed places. This type of deployment can also be categorized further
    into regular and random deployment. In self-adjustment deployment, as clear from
    the name, nodes are autonomous and can adjust according to the depths by automatically
    using floating buoys or determining some desired positions by using mobile sensors.
    These algorithms can also be further classified based on coverage, i.e., uniform
    and nonuniform coverage deployment algorithms. Some mobile sensor nodes under
    the water that monitor the designated region come under the category of movement-assisted
    deployment to cooperate with other sensors to accomplish various patrolling, controlling,
    and monitoring activities. In movement-assisted deployment, sensor nodes mobility
    is considered, it is initiated mainly by water current or water drift with other
    marine animal movements. The two main varying parameters over different deployments
    types are mobility and density in underwater sensor networks [38]. It can be static,
    semi-mobile, and mobile. Every individual node is attached to the docks or anchored
    buoys or placed at the seafloor in static. In the semi-mobile network, nodes are
    suspended from the buoys positioned by any ship and are temporary but then left
    on that place from hours to any long-time durations. To obtain a satisfactory
    network performance, a flexible deployment technique is required. The node deployment
    scheme considers factors such as type of nodes, i.e., homogeneous or heterogeneous,
    deployment objectives regarding area coverage, computation complexity at the node
    or at the surface buoy, energy consumption, etc. Many researchers have proposed
    different node deployment techniques to achieve the objectives of maximum coverage
    and connectivity. Liu et al. [39] devised a distributed, virtual forces-based
    node deployment algorithm (DABVF), to enhance network coverage. A mobility model
    that contemplates node density, node mobility, and node residual energy with efficiency
    is recognized to ameliorate the node mobility process during the node deployment
    procedure. Ding et al. [40] anticipated with double coverage scheme to solve the
    premature sensor failure caused by extreme energy consumption. It is based on
    mobile node deployment in UWSN. Jiang et al. [41] propounded a node deployment
    algorithm having connected dominating set (DBCDS). This algorithm consists of
    freely mobile nodes to solve the deployment problem. A comparison with existing
    procedures is made for UWSNs that cannot recover the system coverage, high network
    connectivity, and underwater communication optimization with the movement energy
    consumption during deployment. The drawback in this methodology is that sometimes
    it does not effectively address node mobility, that is a key issue in UWSN. Su
    and Wang [42] presented the chaotic particle swarm optimization algorithm. With
    the experimental outcomes, the authors contributed that this technique could effectively
    increase the convergence speed and network coverage. Kim et al. [43] devised an
    adaptive triangular system regulating sensor distribution depending upon the communication
    performance variation below the water. For predicting the distance among sensors,
    a performance surface model is employed by approximating the communication efficiency
    founded of spatio-temporal environment issues. Therefore, UWSNs used with adaptive
    triangular implementation algorithms can reach the maximum communication speed
    at the optimal number of nodes. The mechanism for coping with delays in real-time
    communication has to be improved in this technique. Li et al. [44] considered
    the mobile sensor nodes deployment problem in a self-adaptation arrangement if
    all nodes are permitted to traverse spontaneously in the space. Traditional virtual
    force algorithm (VFA) is nominated as a reference for its ease and distributed
    implementation for 3-D area. Authors introduced the concept of additional equilibrium
    force and central gravitation to make the deployment more obtainable and reasonable.
    Various test cases and algorithms are applied to evaluate the performance of the
    proposed improvement, namely, coverage ratio and homogeneous degree. The main
    drawback in this approach is that it is ineffective for fast data gathering applications,
    since communication delays are not factored into the equation while transmitting
    data. Yu et al. [45] presented a Pigeon-based scheme (PSA) for UWSN to reduce
    the limitations of coverage, connectivity, network deployment, network reliability,
    and energy consumption. The sink node first finds out its single hop nodes and
    maximizes network coverage in its region in this algorithm. Other single hop nodes
    split the network into various layers and also form a cluster for every layer.
    There can be improvement in this technique is that cluster head (CH) can use sleep
    wake-up scheduling to manage the energy problem. Almutairi and Mahfoudh [46] designed
    an underwater 3-D self-distributed deployment algorithm based on virtual forces
    (UW-DVFA). This work’s main goal is to expanse the random network deployment in
    the 3-D region to guarantee full coverage area and high connectivity of the network.
    This process guarantees the maximum coverage area and connectivity in the network.
    The drawback in this technique is that the authors mainly targeted to expand the
    randomly deployed network in 3-D area. Pompili et al. [23] considered triangular
    grid positioning of sensors for underwater communication as the pioneering effort
    and originated important geometric properties. For example, take the general scenario
    of sensor nodes with identical sensing range r . This technique is for a 2-D rectangular
    area with the least number of sensor nodes and deploying every node at the grid’s
    vertices, as shown in Fig. 4. By adjusting distance D within nodes (side of the
    equilateral triangles), the coverage rate can increase and can achieve full coverage.
    It is also mathematically proved, when D=√3r , the overlapping areas can be minimized
    and the maximum coverage can be attained. Fig. 4. Triangular-grid node deployment.
    Show All However, it requires a comparatively large number of sensor nodes. To
    overcome this problem, authors framed a function to find the required least number
    of sensors required to be deployed to maximize the coverage area for sensing.
    Yan et al. [25] for improving the coverage area and to handle energy-related problem
    proposed a growth ring style uneven node depth-adjustment self-deployment optimization
    algorithm (GRSUNDSOA). The improvement scope in this technique is that authors
    should also considered the mobility of nodes in mobile-assisted UWSN. Jiang et
    al. [114] proposed guaranteed full connectivity node deployment (GFCND) method
    along with the location dispatch based on command nodes (LDBCNs) algorithm. This
    algorithm considers that deployment strategies for UWSN should provide full connecting
    systems and also achieves the location correction of commonly sensor nodes, including
    sink and command nodes. The main advantage of these algorithms is that it provides
    a comparatively large coverage percentage and a fully connected network. The drawback
    in this technique is that it does not work much on collision avoidance of deployed
    sensor nodes. Gola and Gupta [115] designed an efficient node deployment technique
    for enhancing coverage and connectivity (END-ECC) that works for the main objective
    of node deployment that is for better coverage and connectivity. In this technique,
    the entire network is mainly separated into three layers that is top layer, middle
    layer, and last is bottom layer. The proposed END-ECC algorithm comprises of three
    phase, namely, root selection, formation of tree structure, and in the end calculation
    of the depth of different deployed nodes. This technique provides improved coverage
    and connectivity. The main concern in this technique is that it does not solves
    the problem of coverage overlapping. C. Node Deployment Challenges Due to the
    peculiar underwater communication characteristics, there are many deployment issues
    for UWSN, i.e., significantly different from WSN. Hence, for scalable and better
    node deployment in UWSN, the challenges are listed as follows. Deployment: The
    deployment of wireless sensor nodes is the base for all kinds of communication
    in the network, in such a way that it could cover maximum region. It should be
    performed with lots of care and attention as it is considered sparser in the networks
    under the water and environment is completely different. Communication Stability:
    It is totally dependent on the communication mediums, such as acoustic, optical,
    and EM, that are used for all types of operation and communication and their characteristics.
    Robustness: Nodes in the network are not stable as the water current keeps on
    shifting and sensor nodes used for many specific applications keep on moving from
    their locations. Spatial Correlation: UWSNs are sparser in deployment so spatial
    correlation in aqueous networks is less likely to happen due to the highly distant
    sensor nodes of the network. Expenditure: The sensor node that are used under
    the water are bit expensive comparatively due to extra requirements to work under
    critical aqueous environment. Power Requirements: UWSN imposes high power consumption
    due to complex processing signals and underwater parameters imposed by ocean or
    sea. For a better understanding of node deployment protocol properties, an overview
    is presented in Table IV. SECTION III. Data Collection Approaches/Techniques When
    we talk about optimizing any wireless network, attention should focus on efficient
    ways of accomplishing data on the application layer. For achieving this, techniques
    need to be found, which reduces the amount of communication data to reduce power
    consumption. Some useful methods are required to manage collected data from different
    sensor nodes [56]. These approaches include data collection, data compression,
    data fusion, data forwarding, data dissemination, and data aggregation, as shown
    in Fig. 5. Fig. 5. Phases in data collection. Show All Data collection from UWSNs
    is vital for many applications, including collecting sensing data from different
    deployed sensor nodes [57]. Data compression is a technique of packing data, eliminating
    redundant information, data fusion that combines heterogeneous data to more abstract
    information or events, and data aggregation as a particular class of data fusion
    covering the local preprocessing of homogeneous data to usable information sets
    [58]. UWSN consists of numerous autonomous sensor nodes to employ aggregation
    and forwarding of data so that aggregated data could reach the node designated
    as the sink node. After establishing such networks, the main challenges are high
    cost, operational energy, and memory, limited lifetime of a sensor and communication
    range. When this aggregator node gathers the recognized information from neighboring
    nodes, it will process and ultimately transmit it to the sink [59]. Data aggregation
    protocols within the application layer offer promising capabilities for reducing
    the amount of data payload [60]. In UWSNs, the sensed data from a particular area
    can be directed toward the sink node either directly, i.e., in hop-by-hop or transported
    via multiple hops. But all the sensed data does not always make sense, which means
    that it is unnecessary and redundant. Hence, sensed data must be aggregated or
    concise at intermediate sensor nodes by adopting suitable data fusion techniques.
    Data fusion provides many facilities like it reduces many collisions that can
    occur because of the large amount of data that can come and create colossal traffic,
    which helps stop getting data from malicious nodes as data is first aggregated.
    It also helps in making many other data related decision [61]. A. Data Collection
    Data collection is a significantly hot research area compared to data forwarding,
    data fusion, and aggregation in UWSNs. It is because if accurate data (nonmalicious
    data) is collected from a reliable node (nonmalicious node), only it can process
    and utilized efficiently. In UWSN, numerous nodes are connected and arrayed with
    other surrounding nodes to collect the sensing data and forward it to the surface
    node. The surface/sink nodes act as the processing system of UWSN [62]. The nodes
    communicate using a high-speed optical communication or acoustic communication
    system under the water also IoUT is also used when data needs to be send to onshore
    stations. The IoUT is an evolving communication environment dedicated to communication
    aquatic objects in the marine and aquatic environment. The IoUT technology is
    closely linked to smart ships and shipping, coastal and ocean intelligence, automatic
    transportation, location and navigation, underwater mining, disaster prediction,
    and prevention, as well as research monitoring and security. IoUT affects many
    types of people ranging from a small Scientific Observatory to a medium-sized
    port for international trade at sea. In UWSN, some efficient algorithms have been
    proposed not only for adequate data collection properties, such as seawater salinity,
    temperature, and pressure but also for marine environmental monitoring. Recently,
    underwater pollution monitoring is successfully done in many projects by deploying
    UWSN. In the future, it can also be utilized to real-time monitor the projects
    for seismic, military, and volcanic activities which is a challenging task till
    now due to nonavailability of efficient data collection strategies [63]. Many
    researchers have explored the data collection methods and techniques, and they
    have explained some challenges faced during data collection phase. There are many
    challenges for collecting data under the water, out of which some of the main
    challenges in UWSNs are as follows. The underwater acoustic channel quality varies
    with time. It will depend on many underwater circumstances such as temperature,
    weather condition, pressure, and salinity of the water [64]. Communication synchronization
    among AUVs and different dispersed underwater sensor nodes with efficient route
    planning. The AUV movement speed is affected by many issues, such as water flow,
    pressure, hurdles, etc. Storage can also be a matter of concern, as most data
    gathering method run on a cloud. Because of the distant cloud position from the
    data source nodes, communicating it would result in high energy consumption. Localization
    accuracy affects data collection in UWSNs. UWSNs have highly dynamic topologies.
    In UWSNs, frequent changes in the network topology occur that strongly affect
    the marine communication. There are mainly three methods to collect sensed data
    from deployed sensor nodes multihop, AUV aided, and hybrid [65]. Previously, most
    data collection schemes were based on the multihop data collection method. But
    after technology enhancement over time, many researchers perform AUV-aided data
    collection and got improved results. Many researchers recently adopt an improved
    scheme that associates multihop mechanisms with AUV-aided data collection, known
    as the hybrid data collection scheme. This scheme shows the enhancements as it
    combines the features of multihop and AUV-aided data gathering method. The advantage
    of multihop methods is that the total communication delays are shorter than those
    by AUV-aided data collection. This is due to the fact that the speed of sound
    is faster than AUV speed [66]. However, the problem of unbalanced energy consumption
    is countered by the multihop method. This problem occurs because sensors in the
    neighborhood of the sink node deplete the energy faster, and consequently, drain
    the energy rapidly compared to other nodes. Hence, relay nodes serving as the
    intermediate nodes become inefficient over time because of rapid energy utilization
    by neighbor nodes [67]. After that, this energy depletion problem causes frequent
    disconnections in an extensive network. It is commonly termed as energy hole problem
    around the sink node. In AUV data collection, the sensor nodes are generally armed
    with the acoustic communication modules under the water. The AUV needs to navigate
    the sensor nodes’ proximity to achieve the data due its limited communication
    range [68]. This approach’s benefit comes from the fact that the AUV need not
    visit all the nodes or monitoring areas every time. Here, it is considered to
    divide the network into clusters having CHs and gateway nodes to transfer data
    between clusters. The other nodes will forward the sensed data to the CH directly
    or through multiple hops. Hence, AUVs have to visit only the CH for data collection,
    and this approach would shorten the traveling distance and time [69]. The nodes
    communicate point-to-point using a high-speed optical communication or acoustic
    communication system. All the sensors have a diversity of sensing capabilities,
    including size, cameras, pressure, and water temperature. B. Data Collection Related
    Work In the recent past, some excellent schemes for data collection have been
    developed for UWSNs by researchers. The main problem to be solved is identifying
    a path with minimal data collection cost within an appropriate range [70]. The
    data collection methods are classified into three categories of multihop, AUV
    aided, and hybrid methods, as shown in Fig. 6. Fig. 6. Taxonomy of UWSN data collection
    methods. Show All Multihop Data Collection: Xie et al. [71] designed a vector-based
    forwarding (VBF) protocol, which is one of the fundamental protocols where packets
    are forwarded between the sources and target through a fixed virtual pipeline.
    But it is not suitable for the sparse network. The protocol does not work well
    when mobility is high. Nicolaou et al. [72] presented the forwarding protocol
    based on hop-by-hop vector (HH-VBF) to overcome this problem. It increases the
    possibility of finding a node in the pipeline. This protocol works does not well
    when the network has void regions. The multihop data transmission can be hierarchical,
    grid-based, and grouped or clustered network structure that works well in the
    deep sea, but not in the shallow sea. Hwang and Kim [73] devised a directional
    flooding protocol (DFR) to route the packets for the increase in reliability.
    It is used when communication links are more prone to packet loss. But the protocol
    faces a problem when there is no node near to the sink means in the void regions.
    AUV-Aided Data Collection: AUV-assisted data collection is more convenient according
    to some recent developments because AUVs balance the sensor’s power consumption
    and simplify the network’s design. Chen and Lin [74] devised a mobicast protocol
    that avoids the low efficiency of the network. In this, sensors form a 3-D geographic
    region near all AUV under the water called 3-D ZOR. This is a very effective technique
    but sometime the delay get increased as the network get denser with a high number
    of nodes. Han et al. [75] depicted the PNCS-GHA method, where AUV collects data
    based on probabilistic neighborhoods. In AUV-assisted underwater protocol (AURP),
    multiple AUVs are utilized as the relay nodes for collecting data packets from
    gateway nodes to get data reached sink node. Here, each gateway node is liable
    for collecting data from underwater deployed sensor nodes. Thus, sink nodes and
    gateways should repeatedly broadcast their interest in gathering data. Further,
    this data is utilized by other sensor nodes to choose the next hop to visit by
    minimizing the path length. In AUV-PN, AUV is used to visit the identified areas
    for collecting the aggregated data in cluster-based networks. AUV partitions the
    deployed network using Voronoi criteria and further moves into the network with
    already decided lawn-mower pattern to disseminate the collected data. The problem
    of void region is not effectively handeled by this AUV-based technique. Li et
    al. [76] devised a cognitive technique for acoustic transmission, known as dolphin-aware
    data transmission (DAD-Tx) using multiple hops in UWSN. Noncollaborative sensing
    and simplified modeling of dolphins’ activities motivated authors to propose a
    probabilistic method for capturing the stochastic characteristics similar to communications
    among dolphins’. Authors have formulated the DAD-Tx optimization problem for maximizing
    the throughput. According to Hollinger et al. [77] during data collection by AUVs,
    it needs to sail into the sensor’s vicinity (equipped with the acoustic communication
    modules) to acquire the data correctly with limited communication range. Therefore,
    to gather the data from UWSN with AUV-assistance is referred to as a communication-constrained
    data collection (CC-DCP). This method does not work well in an area where sensor
    communication excellence contrasts amid sensor nodes that results in probabilistic
    neighborhoods of dissimilar dimensions. Lasheng et al. [78] proposed a subtree
    merging-based data collection algorithm (SMDC) that utilizes more sensor nodes
    to continuously sense and collect data, especially in a given area. Chang and
    Shih [79] proposed data collection using a docking station to deal with the limited
    power of the AUV and minimizes the length of routes and the overall time of the
    AUVs. However, acoustic transmission leads to a considerable propagation delay
    such that it is quite challenging to plan the tour path of AUVs. Faigl and Hollinger
    [80] devised an efficient approach to collect data from sensor nodes deployed
    in oceans autonomously. In this, each sensor node is equipped with modules for
    wireless communication ability and recover data remotely. This is the most convenient
    method but, due to the lack of the communication technology available in UWSN
    like optical or wireless acoustic modems, its tough to collect data without a
    mobile underwater vehicle. Another optimization technique is to use a self-organizing
    map (SOM) to deal with the TSP problem. SOM can be helpful to solve those problems
    where target locations are not explicitly prescribed. Jea et al. [81] proposed
    in earliest times, the algorithm for load balancing that balances the services
    by the number of sensor nodes. Authors had considered multiple mobile elements
    for purposes of data collection. Yan et al. [82] developed a solution for energy-efficient
    AUV-assisted UWSN data collection strategy. A novel two-stage solution is suggested
    by the authors. In the first stage, sensors relay physical data at a short range
    data collector with multihop acoustic communication. The designated AUV regularly
    visit to recover data through high-speed visible light communication in the second
    stage. Su et al. [83] proposed a new coordination method for data gathering using
    AUV in sparsely distributed UWSN. Bölöni et al. [84] depicted the explanation
    and exploration of algorithms for scheduling data communication with an application-dependent
    value in UWSN. Authors have described that it is quite possible to explore more
    efficient scheduling strategies. These types of strategies allow the sensors to
    acoustically transfer the digests of sensed information so that the Value of Information
    (VoI) conveyed is maximized. MacMohan and Plaku [85] considered the limited energy
    resources of an AUV in underwater communications. To manage this issue, they effectively
    plan a collision-free and dynamically attainable trajectory that empowers the
    AUV to achieve many targets while reducing the distance traveled and accrued penalty.
    The success of this technique is derived from combining sampling-based motion
    planning with PC-TSP solvers. Vasilescu et al. [86] presented a novel platform
    for UWSN to monitor long-term environment monitoring. Nodes’ point-to-point communication
    using a high-speed optical system integrated with the TinyOS for broadcasting
    using an acoustic protocol. Favaro et al. [87] devised U-Fetch, having two levels
    coordinated access where head nodes retrieve data from neighbors nodes to send
    whole data toward mobile sink in bunches through a contention-free link. Hybrid
    Data Collection: et al. [88] presented node cooperation (NC) scheme for the surface
    node data collection efficiency increase, by using the fact that UW nodes can
    overhear the transmission by neighbors as compared to traditional automatic-repeat-request
    (ARQ) protocol. Ahmad et al. [89] proposed AUV-aided energy-efficient routing
    method (AEERP), where AUV follows the preidentified elliptical trajectory in every
    cycle. These sensors can be categorized into two types as gateway nodes and other
    member nodes. Gateways are only meant to communicate with AUV and are also selected
    based on nearness to AUV trajectory and residual energy levels. Han et al. [90]
    devised stratification-based data gathering (SDCS) for 3-D UWSNs where the network
    is divided into two layers based on the Ekman Drift Model to reduce consumption
    of energy. The Ekman layer (upper layer), faces great water speed and thereby
    follows the water flow. Whereas, at a lower layer, the speed of water current
    is less so nodes at this layer are assumed as relatively static. A neighbor density
    clustering-based AUV data collection technique is used at this layer for data
    gathering. By engaging various data gathering schemes at different layers, the
    benefits of AUV-aided data gathering and multihop transmission method get combined
    to reduce energy consumption and improve the network lifetime. Cheng and Li [91]
    presented the algorithm for data gathering through sensors (DGS) in which authors
    have depicted the way to identify the data importance level without domain knowledge
    so that only necessary data is forwarded. It reduces the latency of essential
    data. All the existing techniques for different data collection methods are discussed
    in Table V. SECTION IV. Applications UWSN comprises several modules, such as sensors
    and vehicles positioned in a precise aquatic region to accomplish collaborative
    tracking and data gathering applications [104]. Some of the applications areas
    of UWSN is broadly classified into three categories, such as monitoring, tracking,
    and actuating applications [105]. Here, the applications of IoUT are broadly categorized
    according to the application areas, as shown in Fig. 7. Water Quality Monitoring:
    The existing habitats living below the water are highly conscious of water quality
    because it is the most significant factor affecting their life. Ocean Health Monitoring:
    IoUT can be used for monitoring of natural habitat living under the water like
    fishes, etc. This particularly mentions the underwater network established for
    monitoring the marine lives and the attributes and properties to have a healthy
    life. Sports: With the development of IoUT, the number of UWSN applications has
    increased such as sports. Much of the work focuses on the biomechanical investigation
    of swimming with the help of inertial sensors deployed under the water. Many modern
    uses of bearing inertial sensors (accelerometers, gyroscopes, and magnetometers)
    to evaluate swimming biomechanics [116]. Oil Leakage Monitoring: The spillage
    of oil origins harmful effects on marine life. UWSN can help to monitor the oil
    spill thickness in water, helpful in the cleaning process. Underwater Resources
    Exploration: The concept of IoUT can be used to locate lost resources in water
    with the help of UWSN architecture. In addition, the exploration of natural resources,
    such as metals, minerals, and corals can be benefitted with help of IoUT. This
    application area includes various natural resources exploration so that the crust
    available below the water surface or some other existing resources can be explored
    [106]. Preanalysis of Earthquake or Tsunami: Natural disaster can come at any
    time and place, so same is the case with the aqua environment. These disaster
    recovery or prevention is one of the crucial applications of IoUT. UWSN can be
    deployed to generate early warnings for these natural emergencies of earthquake
    and tsunami. Preanalysis of Flood Occurrence: It may happen instantly and frequently
    also. As there is no particular method from which it can be reduced hence only
    the early detection or alerts for the floods is the ultimate solution to safeguard
    many lives, including marine life [98]. Mines Detection: There is a requirement
    to localize or find out the hidden mines under the water to utilize the natural
    resources like oil mines, which are precious natural resources that can be found
    deep under the water [107]. Rivals Submarine Detection: IoUT with the help of
    UWSN can be used to position or localization and further target submarines by
    using acoustic signals for communication. This leads to protection from attacks
    that can occur on the submarine in the water [4]. Border Area Protection: In naval
    force surveillance, there exist large applications of UWSN where human deployment
    reduction will be the benefit during detection and avoidance of enemy attack for
    the protection of border areas [108]. Ship Wreckage Protection: Due to underwater
    conditions like erosion or rust, metal fustigation limits ships’ lifetime nearly
    up to 30 years [109]. Hence, the parts of the body of ships can be reiterated
    or used as raw material called ship wrecking or ship recycling. Navigation from
    such an area can be identified by using UWSN [110]. Fig. 7. Classification of
    UWSN application areas. Show All SECTION V. Performance Evaluation Specific data
    collection algorithms are compared based on their performance, which comes under
    the three classifications as multihop, AUV assisted, and hybrid data collection.
    Although there exist numerous qualities of service parameters to analyze the protocol
    but related to the data collection algorithm comparison, authors have taken three
    main parameters, such as energy consumption, PDR, and network lifetime. Average
    Energy Consumption (AEC): AEC is calculated as the total energy consumed ( E total
    ) for a node while forwarding data packets ( P sent ) once in each round AEC=
    E total P sent . (15) View Source PDR: PDR is denoted as the ratio of data packets
    effectively received ( P rec ) by the sink/receiver node to the packets actually
    sent ( P sent ) by all nodes deployed in the designated region PDR= P rec P sent
    . (16) View Source Network Lifetime: Network lifetime is the elapsed time till
    the first node dies in the deployed network. Also, lesser the energy consumption
    per transmission implies more of the network lifetime NL= 1 AEC . (17) View Source
    The different existing data collection protocols are executed on the network simulator
    NS-2.30 all-in-one due to its real-time results, freeware, and open-source properties.
    Simulation is conducted for every protocol in multiple runs, and the average is
    taken for comparison. The simulation parameters considered are according to 3-D
    architectural environment of UWSN, and some of the other simulation parameters
    considered are also concise in Table VI. A. Case I In a multihop scenario, data
    collection techniques are compared w.r.t. QoS parameters as energy consumption
    and packet delivery ratio. The energy consumption is compared in multihop data
    collection techniques, such as VBF [71], HH-VBF [72], and PBR [94]. The total
    energy consumed in the network was significantly less than 36% in the case of
    HH-VBF than VBF and PBR, as in HH-VBF more suitable paths can be found as the
    number of nodes increased from 100 to 500, hence less energy is consumed for communication
    between nodes as shown in Fig. 8. Fig. 8. Energy consumption versus number of
    nodes. Show All The PDR ratio is compared in different multihop data collection
    techniques, such as VBF, HH-VBF, and DUCS [92]. When the number of nodes is 100,
    packet can be lost due to distant positioning of the number of node so PDR is
    less but when the number of nodes increased to 400 or 500, the PDR is also enhanced
    in HH-VBF as with the improving node density, nodes falling in its routing pipe
    also increases with a fixed transmission range radius. Ultimately, more nodes
    got qualified for packet forwarding leads to a rise in PDR as shown in Fig. 9.
    In a network, when the density of nodes increases. It is good to note that the
    PDR increases continuously with increased nodes because more the intermediate
    nodes, less the packet drop, and more the delivery ratio. The PDR is 35% higher
    in HH-VBF compared to VBF and 30 % higher in DUCS. HH-VBF also considers traffic
    density factor, so its performance is far better. It will expressively enhance
    the robustness for packet delivery in sparse networks by improving the data delivery
    ratio. Fig. 9. PDR versus number of nodes. Show All B. Case II In an AUV-assisted
    scenario, data collection techniques are compared w.r.t. QoS parameters as energy
    consumption and packet delivery ratio. Now, the energy consumption is compared
    between PNCS-GHA [75], DGS-AUV [111], and PDO-DC [96] in AUV-aided data collection
    algorithms as plotted in Fig. 10. The unit energy consumption falls with the growing
    number of sensor nodes from 100 to 500. Fig. 10. Energy consumption versus number
    of nodes. Show All In the PDO-DC algorithm, the sleep scheduling algorithm is
    introduced; hence nodes need not to continuously sense for data forwarding. Nodes
    only consumes energy while getting into awake condition and need to transfer the
    data to nearby node or AUVs. Hence less energy is consumed, i.e., 18% less from
    DGS-AUV and 12% less from PNCS-GHA. The PDR is compared between DGS-AUV, PNCS-GHA,
    and SEDG [112]. Here, the PDR ratio in PNCS-GHA is comparatively 6% higher than
    the DGS-AUV and 31% SEDG as analyzed from Fig. 11. Fig. 11. PDR versus number
    of nodes. Show All As in PNCS-GHA, when the number of nodes increased, such as
    400 or 500, the AUV is engaged to move according to the defined path for data
    collection from probabilistic neighborhoods as a large number of nodes are present
    in the path with increased number of nodes. The collected data is forwarded to
    the target. C. Case III In a hybrid scenario, data collection techniques are compared
    w.r.t. QoS parameters. The energy consumption, PDR, and network lifetime are compared
    between AEERP [89], SDCS [90], and DGS [91], the hybrid approaches as depicted
    in Fig. 12. Fig. 12. Energy consumption versus number of nodes. Show All Here,
    it is visible from the graph that the unit energy consumption varies rapidly with
    an increasing number of nodes. Graph results also verify that the energy consumed
    in the SDCS algorithm is 13% less than DGS, whereas it is 31% lesser than the
    AEERP scheme. When the number of nodes increased from 100 to 500, node density
    increase which in turn decreases the average communication distance between the
    nodes. When we have the number of nodes to 500 then node density is maximum and
    the parallel nodes provide data to the nearby sink nodes only, and maximum nodes
    can remain in the sleep stage for a long duration. The PDR ratio is also compared
    between AEERP, DGS, and SDCS. As clear from Fig. 13 that PDR is increasing with
    the increase in the number of nodes. Typically, when the number of nodes is 500,
    i.e., dense network, the higher the packet forwarding rate will be. The performance
    comparison shown in graph depicts that SDCS performs 22% better than AEERP and
    9% better than DGS. It is due to the fact that in SDCS, weight judgment practice
    is performed at every hop for analyzing forwarding probability of data packets.
    Also, it is noticeable that the PDR increases continuously with the rise in the
    number of nodes because more the intermediate sensor nodes, less the packet drop,
    and more the delivery ratio. Fig. 13. PDR versus number of nodes. Show All The
    network lifetime is compared between SDCS, DGS, and AEERP as depicted in Fig.
    14. The lifetime period of SDCS is 40% higher than the DGS algorithm and 34% higher
    than the AEERP method, and it is increasing as the number of nodes is increasing.
    This is because, in the SDCS algorithm, the sleep wake-up system is used to reduce
    the load on nodes, hence when the number of nodes are 500, i.e., maximum, only
    nodes which are part of communication are awake which reduces the energy consumption
    and improves the network lifetime. Every node may enter into the sleep mode and
    get activated again in the next round when it has data packages to forward. So
    it enhances the overall lifetime period of the network. Fig. 14. Network lifetime
    versus number of nodes. Show All SECTION VI. Future Challenges and Learning Outcomes
    The IoUT has an impact on a wide range of sizes, from a tiny scientific instrument
    to a medium-sized seaport to worldwide oceanic traffic. IoUT’s network architecture
    is inherently heterogeneous, and it must be durable enough to operate in severe
    settings. Some possible future directions are listed as follows. Competing Communication:
    There is need for exploration of more adequate communication channel in harsh
    aquatic conditions. Along with this combined networking scenarios, i.e., optical
    and MI together as the acoustic channel, can achieve higher flexibility in bandwidth
    with higher data rates and reduced power. Handling of Voluminous and Real-Time
    Data: There are some critical applications such as natural, oil spills, and territory
    surveillance from enemy that requires real-time support via an early warning.
    Also there are many oceanic applications that produces or consumes large amount
    of data, for that integration of UWSNs and big data is one of the recent trends.
    But in UWSNs, big data processing faces many challenges like real-time analytics,
    hardware limitations, and visualization that are major research issues. Coherent
    Node Arrangements: Deployments of large underwater networks helps fast and unfailing
    delivery of data. So, networking solutions needs to be find out that work for
    efficient and reliable underwater data collection. AUV Focused Path Planning:
    Dynamic path planning for AUV-assisted localization techniques is still required
    so that, AUV can dynamically adjust its path for providing enough information
    to unvisited nodes so that node deployment and data collection can be done easily
    from those nodes. Pragmatic Architecture: A more realistic model having insights
    regarding the design of 3-D UWSN should take into account the mobility of sensor
    nodes under harsh and critical underwater conditions. Scrimping Deployments: Ever
    since underwater sensors are expensive in terms of cost, so the deployment algorithms
    for mobile anchor nodes should be proposed and investigated for reducing costs
    in deep water scenarios as well. Explicit Localization of Nodes: For efficient
    and accurate localization, location information of sensors is required in many
    processes, such as routing, data collection, fault tolerance, etc. This field
    requires more productive and effective research. The learning outcome through
    this study is that this manuscript offers insights into and depths of UWSN, which
    is a vast field in and of itself. This study offers a solid foundation for UWSN
    node deployment and node deployment field. There are well-known terrestrial technologies,
    which function well in the IoT, typically are inadequate for underwater applications,
    has been one of the critical problems preventing further developments in the IoUT
    domain. A lot of research has been done in UWSN and more is to be done in the
    upcoming years, driven by a wealth of theoretical and practical challenges. The
    continuously developing the underwater communication technology will have a great
    impact on the fish industry, oil industry and other transportation system as well
    as provide impact in the environment. SECTION VII. Conclusion The sagacity of
    underwater data collection could not be possible before the emergence of WSN and
    accomplished through expensive as well as tough wired networks deployment. UWSN
    provided those enabling technologies for radical change in various real-time underwater
    monitoring and surveillance applications. UWSN is that a small or large network
    that consist of a number of sensor nodes to perform various activities of sensing
    or controlling underwater activities. IoUT is a new class of IoT and is defined
    as a network of interconnected intelligent underwater objects. IoUT expected enables
    various practical applications, such as environmental monitoring, underwater research,
    and disaster prevention. Among these applications, IoUT is recognized as a technical
    capability. Underwater wireless sensor to support IoUT concept for smart city
    development networks became an efficient communications network. Underwater sensors
    can also be installed in AUVs installed underwater to monitor and research underwater
    minerals. The ultimate goal of this article is to encourage research fellowship
    to lay the foundations for the development of advanced node distribution schemes
    and data collection techniques with efficient underwater communication. It will
    ultimately help for effective networking for enhanced monitoring and ocean exploration
    applications. In this survey article, authors have summarized several fundamental
    and critical aspects of UWSN. As data collection is used in almost every practical
    application of UWSN, it needs significant attention. Hence, the focus of research
    is data collection in UWSN that starts with node deployment, which is of three
    different types, i.e., self-adjusting, static, and movement assisted. For collecting
    reliable and purposeful data, sensor nodes need to be deployed effectively and
    then collect data efficiently and promptly. In this, data collection methods are
    divided and represented into mainly three type’s multihop, AUV aided, and hybrid
    methods. State-of-the-art about data collection in UWSN along with node deployment
    techniques and algorithms is also analyzed. This manuscript might serve as a resource
    for future work on UWSN node deployment, data collection and for the IoUT. Authors
    Figures References Citations Keywords Metrics More Like This Data Collection in
    Studies on Internet of Things (IoT), Wireless Sensor Networks (WSNs), and Sensor
    Cloud (SC): Similarities and Differences IEEE Access Published: 2022 Weighted
    Connected Vertex Cover Based Energy-Efficient Link Monitoring for Wireless Sensor
    Networks Towards Secure Internet of Things IEEE Access Published: 2021 Show More
    IEEE Personal Account CHANGE USERNAME/PASSWORD Purchase Details PAYMENT OPTIONS
    VIEW PURCHASED DOCUMENTS Profile Information COMMUNICATIONS PREFERENCES PROFESSION
    AND EDUCATION TECHNICAL INTERESTS Need Help? US & CANADA: +1 800 678 4333 WORLDWIDE:
    +1 732 981 0060 CONTACT & SUPPORT Follow About IEEE Xplore | Contact Us | Help
    | Accessibility | Terms of Use | Nondiscrimination Policy | IEEE Ethics Reporting
    | Sitemap | IEEE Privacy Policy A not-for-profit organization, IEEE is the world''s
    largest technical professional organization dedicated to advancing technology
    for the benefit of humanity. © Copyright 2024 IEEE - All rights reserved."'
  inline_citation: '>'
  journal: IEEE Internet of Things Journal
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: 'Underwater Wireless Sensor Networks: Enabling Technologies for Node Deployment
    and Data Collection Challenges'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Preethiya T.
  citation_count: '0'
  description: In recent years, internal air quality has been a significant health
    and safety concern. This research presents a low-cost WSN system for carbon dioxide
    monitoring in a complex indoor environment. An MQ135 gas sensor, an Arduino Pro
    Mini, an ESP8266 Wi-FiWi-Fi module, and an AMS1117 voltage regulator are involved
    in this prototype. This sensor system is designed to monitor and detect carbon
    dioxide levels in real-time and offer timely air quality notifications. This prototype
    measures the amount of carbon dioxide gas in an indoor setting regularly. The
    goal of this prototype is to demonstrate improved real-time data transmission
    of air quality. Experiments in a typical high carbon dioxide atmosphere have been
    undertaken to support and build a warning system. Aside from that, we have an
    E-Mail alert System. That is, if the CO2 level exceeds the threshold value, a
    message is promptly sent to the reporter.
  doi: 10.1063/5.0114704
  full_citation: '>'
  full_text: '>

    "All Content AIP Publishing Portfolio AIP Conference Proceedings                              Advanced
    Search | Citation Search Univ Nebraska Lincoln Lib Sign In HOME BROWSE FOR AUTHORS
    FOR ORGANIZERS ABOUT Volume 2523, Issue 1 30 January 2023 RECENT ADVANCEMENT IN
    MECHANICAL ENGINEERING AND INDUSTRIAL MANAGEMENT 24–25 June 2021 Chennai, India
    REFERENCES RESEARCH ARTICLE| JANUARY 30 2023 Web-based cost-effective indoor air
    pollutants monitoring in real-time T. Preethiya Author & Article Information AIP
    Conf. Proc. 2523, 020148 (2023) https://doi.org/10.1063/5.0114704 Split-Screen
    PDF Share Tools In recent years, internal air quality has been a significant health
    and safety concern. This research presents a low-cost WSN system for carbon dioxide
    monitoring in a complex indoor environment. An MQ135 gas sensor, an Arduino Pro
    Mini, an ESP8266 Wi-FiWi-Fi module, and an AMS1117 voltage regulator are involved
    in this prototype. This sensor system is designed to monitor and detect carbon
    dioxide levels in real-time and offer timely air quality notifications. This prototype
    measures the amount of carbon dioxide gas in an indoor setting regularly. The
    goal of this prototype is to demonstrate improved real-time data transmission
    of air quality. Experiments in a typical high carbon dioxide atmosphere have been
    undertaken to support and build a warning system. Aside from that, we have an
    E-Mail alert System. That is, if the CO2 level exceeds the threshold value, a
    message is promptly sent to the reporter. Topics Sensors, Data processing, Air
    pollution REFERENCES 1.A. Chaturvedi and L. Shrivastava, “IOT Based Wireless Sensor
    Network for Air Pollution Monitoring”, IEEE 9th International Conference on Communication
    Systems and Network Technologies (CSNT), 2020, pp. 78–81. Google Scholar  2.Kavi
    Kumar Khedo and Vishwakarma Chikhooreeah, “Low-Cost Energy-Efficient Air Quality
    Monitoring System Using Wireless Sensor Network”, DOI: https://doi.org/10.5772/intechopen.70138,
    2017. Google Scholar  3.T. Preethiya, A.Muthukumar and S.Durairaj, “Energy-efficient
    clustering and multipath routing for mobile wireless sensor network using game
    theory”, International Journal of communication systems, 33 (7) (2020), pp.1–18.
    Google Scholar  4.T. Preethiya, A.Muthukumar and S.Durairaj, “Double Cluster Head
    Heterogeneous Clustering for Optimization in Hybrid Wireless Sensor Network”,
    Wireless Personal Communications, Wireless Personal Communications, 110 (4) (2019),
    pp.1751–1768. https://doi.org/10.1007/s11277-019-06810-3 Google ScholarCrossref   5.T. Preethiya,
    A. Muthukumar and S. Durairaj, “Secured Transmission in Double Clustered Heterogeneous
    Mobile Wireless Sensor Network”, 3C Tecnologia, 2020, pp.51–67. Google Scholar  6.T. Preethiya,
    A.Muthukumar and S.Durairaj, “Providing Secured Data Aggregation in Mobile Wireless
    Sensor Network”, In proceedings of 4ᵗʰ IEEE International Symposium on Robotics
    and Manufacturing Automation, 2018, pp. 1–6. Google ScholarCrossref   7.T. Preethiya
    and S. Durairaj, “Analysis of network performance of mobile WSN using game theory”,
    2016 International Conference on Emerging Trends in Engineering, Technology and
    Science (ICETETS), 2016, pp. 1–4, Google ScholarCrossref   8.T. Preethiya and
    G. Santhi, “Enhancement of lifetime using fuzzy-Based clustering approach in WSN”,
    2014 International Conference on Electronics and Communication Systems (ICECS),
    2014, pp. 1–5, doi: https://doi.org/10.1109/ECS.2014.6892813. Google ScholarCrossref   9.Silviu
    C. Folea and George Mois, “A Low-Power Wireless Sensor for Online Ambient Monitoring”,
    IEEE Sensors Journal, 2015, pp. 742–749. Google Scholar  10.Ke Hu, Vijay Sivaraman,
    Blanca Gallego Luxan, and Ashfaqur Rahman, “Design and Evaluation of a Metropolitan
    Air Pollution Sensing System”, IEEE Sensors Journal, 2015, pp. 1–1 Google Scholar  11.C. Peng,
    K. Qian and C. Wang, “Design and Application of a VOC Monitoring System Based
    on a ZigBee Wireless Sensor Network”, Sensors Journal, IEEE, 15(4), 2015, pp 2255–2268.
    https://doi.org/10.1109/JSEN.2014.2374156 Google ScholarCrossref   12.J.-Y. Kim,
    C.-H. Chu, and S.-M. Shin, “ISSAQ: An Integrated Sensing Systems for Real-Time
    Indoor Air Quality Monitoring,” Sensors Journal, IEEE, 14(12), pp 4230–4244. https://doi.org/10.1109/JSEN.2014.2359832
    Crossref   13.Abdul Hadi Nograles H.1, Agbay, and Christopher Paolo D.2, “Low-Cost
    Internet Based Wireless Sensor Network for Air Pollution Monitoring using Zigbee
    Module”, IEEE Sensors Conference, 2014, pp. 310–314. Google Scholar  14.Petros Spachos,
    and Dimitrios Hantzinakos, “Real-Time Indoor Carbon Dioxide Monitoring through
    Cognitive Wireless Sensor Networks”, Sensors Journal IEEE, 2015, PP. 1–9. Google
    Scholar  15.S. Mansour, N. Nasser, L. Karim and A. Ali, “Wireless Sensor Network-based
    air quality monitoring system”, 2014 International Conference on Computing, Networking
    and Communications (ICNC), 2014, pp. 545–550, doi: https://doi.org/10.1109/ICCNC.2014.6785394.
    Google ScholarCrossref   16.Murugan, S., Ganesh Babu TR, and C. Srinivasan. “Underwater
    Object Recognition Using KNN Classifier.” International Journal of MC Square Scientific
    Research 9, no. 3 (2017): 48–52. https://doi.org/10.20894/IJMSR.117.009.003.007
    Google ScholarCrossref   17.Suresh Kumar D, Jagadeesh Kannan R. Reinforcement
    learning-based controller for adaptive workflow scheduling in multi-tenant cloud
    computing. The International Journal of Electrical Engineering & Education. January
    2020. doi: https://doi.org/10.1177/0020720919894199 Google Scholar  This content
    is only available via PDF. PDF © 2023 Author(s). View Metrics Citing Articles
    Via Google Scholar Publish with us - Request a Quote! Sign up for alerts Most
    Read Most Cited Phytochemical analysis of bioactive compounds in ethanolic extract
    of Sterculia quadrifida R.Br. Siswadi Siswadi, Grace Serepina Saragih Numerical
    simulation of various Reynold’s number fluid flow around a cylinder using DualSPHysics
    Exa Heydemans, Jessica Sjah, et al. Design of a 100 MW solar power plant on wetland
    in Bangladesh Apu Kowsar, Sumon Chandra Debnath, et al. Online ISSN 1551-7616
    Print ISSN 0094-243X Resources For Researchers For Librarians For Advertisers
    Our Publishing Partners  Explore Journals Physics Today Conference Proceedings
    Books Special Topics Publishers pubs.aip.org About User Guide Contact Us Register
    Help Privacy Policy Terms of Use Connect with AIP Publishing Facebook LinkedIn
    Twitter YouTube © Copyright 2024 AIP Publishing LLC"'
  inline_citation: '>'
  journal: AIP Conference Proceedings
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Web-Based Cost-Effective Indoor Air Pollutants Monitoring in Real-Time
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Baucas M.J.
  - Spachos P.
  - Gregori S.
  citation_count: '0'
  description: In recent years, healthcare systems have included the Internet of Things
    (IoT) technology in their services, such as in remote patient monitoring systems.
    Wearable IoT devices can provide information regarding the patient's health that
    are accurate and time-sensitive. However, vulnerabilities are evident as more
    IoT devices connect to the network. For healthcare services, the security of patient
    data is an issue. At the same time, with real-time data transmissions, the network
    runs into manageability concerns. In this work, we propose a private blockchain-based
    Wireless Body Area Network (WBAN) platform to aid wearable IoT devices in healthcare
    services. We chose this blockchain technology due to its strengths in security.
    Then, we enable a distributive architecture using WBANs to introduce a decentralized
    configuration that can ensure privacy among wearable IoT devices within the network.
    To evaluate the feasibility of the proposed platform in terms of latency and throughput,
    we conducted experiments with several wearable IoT devices. The results show that
    integrating a WBAN to create a fog server improves the network performance with
    an increasing number of IoT devices and packet size. Also, the blockchain showed
    its ability to address security threats in healthcare services. We evaluate our
    proposed platform through a performance test and a STRIDE threat model, and we
    prove its feasibility in improving the security and manageability of wearable
    IoT devices in healthcare.
  doi: 10.1109/ICC45041.2023.10278610
  full_citation: '>'
  full_text: '>

    "This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org
    IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal
    Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln
    Sign Out All Books Conferences Courses Journals & Magazines Standards Authors
    Citations ADVANCED SEARCH Conferences >ICC 2023 - IEEE International... Private
    Blockchain-Based Wireless Body Area Network Platform for Wearable Internet of
    Thing Devices in Healthcare Publisher: IEEE Cite This PDF Marc Jayson Baucas;
    Petros Spachos; Stefano Gregori All Authors 60 Full Text Views Abstract Document
    Sections I. Introduction II. Related Works III. Platform Design IV. Results and
    Discussion V. Conclusions Authors Figures References Keywords Metrics Abstract:
    In recent years, healthcare systems have included the Internet of Things (IoT)
    technology in their services, such as in remote patient monitoring systems. Wearable
    IoT devices can provide information regarding the patient''s health that are accurate
    and time-sensitive. However, vulnerabilities are evident as more IoT devices connect
    to the network. For healthcare services, the security of patient data is an issue.
    At the same time, with real-time data transmissions, the network runs into manageability
    concerns. In this work, we propose a private blockchain-based Wireless Body Area
    Network (WBAN) platform to aid wearable IoT devices in healthcare services. We
    chose this blockchain technology due to its strengths in security. Then, we enable
    a distributive architecture using WBANs to introduce a decentralized configuration
    that can ensure privacy among wearable IoT devices within the network. To evaluate
    the feasibility of the proposed platform in terms of latency and throughput, we
    conducted experiments with several wearable IoT devices. The results show that
    integrating a WBAN to create a fog server improves the network performance with
    an increasing number of IoT devices and packet size. Also, the blockchain showed
    its ability to address security threats in healthcare services. We evaluate our
    proposed platform through a performance test and a STRIDE threat model, and we
    prove its feasibility in improving the security and manageability of wearable
    IoT devices in healthcare. Published in: ICC 2023 - IEEE International Conference
    on Communications Date of Conference: 28 May 2023 - 01 June 2023 Date Added to
    IEEE Xplore: 23 October 2023 ISBN Information: Electronic ISSN: 1938-1883 DOI:
    10.1109/ICC45041.2023.10278610 Publisher: IEEE Conference Location: Rome, Italy
    SECTION I. Introduction Healthcare industries have started introducing more complex
    and compact technologies into their services [1]. One of the most popular approaches
    is integrating the Internet of Things (IoT) through wearable devices for monitoring
    and diagnosing their patients [2]. However, there is a caveat in the private patient
    data that these, mainly wireless, technologies collect and transmit [3]. Proper
    network security is required to keep this information secure. Due to its high
    volume, the manageability of the data within the network is also an issue. Most
    medical centers use more than one technology or service for effective diagnosis
    and continuous patient monitoring [4]. Therefore, there is a need for a better
    means of securing and managing patient data. In this work, we propose a blockchain-based
    Wireless Body Area Network (WBAN) platform to address the security and manageability
    issues in wearable IoT devices in healthcare. We use private blockchain technology
    to address these security issues for its strengths in keeping data tamperproof
    and harder to modify with its decentralized properties. We also use a WBAN architecture
    to rearrange the network structure under more manageable and distributive conditions.
    This structure can reduce the issues in data congestion for easier process reallocation
    and load management. We evaluate the proposed platform through experimentation
    with smartwatches, smart-phones, and wearable prototypes. The organization of
    the rest of the paper is as follows: We discuss the related works in Section II.
    In Section III, we introduce our platform and present the components we used to
    construct and test it, and we highlight the different motivations and our choices
    to implement the proposed design. In Section IV, we discuss the experimental results
    and insights. In Section V are the conclusions of this work. SECTION II. Related
    Works Healthcare industries have adopted wearable IoT devices into their services
    [5]. A popular approach is the remote patient monitoring systems. With this service,
    medical centers can manage their physical resources better and observe patients
    without being present in a clinic [6]. Healthcare centers provide a wireless wearable
    IoT device for the patient to enable this monitoring system. The technology is
    low-cost and compact to keep the service affordable and modular. As a result,
    these devices are not optimized for complex processes. Also, these devices need
    to be worn by patients frequently to ensure constant monitoring [7]. However,
    wearable IoT devices in healthcare deal with private patient data. If left unprotected,
    these data transmissions are prone to malicious attacks [8]. Hence, the data also
    needs to be kept secure. In this work, we use blockchain technology to create
    a platform that addresses this security issue. A blockchain is a data structure
    composed of cryptographically linked blocks [9]. It is known for its immutable
    and decentralized architecture. As a result, blockchains can ensure that information
    is harder to modify with multiple control nodes with authority over the network.
    Also, its decentralized structure allows several backup locations to become more
    tamperproof. Blockchains have built-in protocols for efficient automation, making
    it a sustainable option instead of simpler authentication and security schemes.
    There are two main classifications of blockchains; public and private [10]. These
    two fundamental types are mainly classified based on how they grant access to
    the device. Conventional public blockchains use a trustless consensus protocol
    via proof-of-work (PoW) to authenticate their users. It provides a complex algorithm
    that requires processing power from the user to complete before being given access.
    A conventional private blockchain uses a trusted protocol [11]. Instead of using
    PoW, most implementations hold a ledger that identifies its authorized devices.
    In [12], they proposed a decoupled private blockchain approach for regulating
    the user data within an edge IoT-based healthcare monitoring. Another example
    is in [13]. They presented a blockchain implementation that leverages edge computing
    creating fast data processing for healthcare applications. Our design differs
    by emphasizing a fog-based and distributive approach. We elected to use a conventional
    private blockchain due to the expected devices in our platform. Since wearable
    devices in IoT-based healthcare are usually low-cost, they will not have the processing
    capabilities to do PoW [14]. Therefore, we use a pre-defined ledger of trusted
    devices within the blockchain. This choice saves power consumption, which is crucial
    for these wearable devices. Another difference in our design is that we incorporate
    WBAN technology with our blockchain approach to improve the overall design structure.
    A WBAN is a type of network that scopes a small area, which is usually around
    a person [15]. Although it cannot support a large-scale service due to capacity
    issues, it can create an exclusive network that limits those that can access it.
    As a result, it offloads processes to a local server for pre-processing [12].
    Also, it can keep the information exclusive to each group of users. We chose to
    use this type of network for its potential contributions to the manageability
    and security of the overall healthcare network. With the WBAN, we add local servers
    to its architecture [16]. As a result, the distributive fog-based structure minimizes
    the network congestion caused by overloading the cloud server. Also, it reduces
    the total number of endpoints connected to the server, which lessens the network
    traffic and improves the manageability of the overall IoT service. In [17], they
    proposed an IoT-based system for automated health monitoring and surveillance
    in response to the impact of the pandemic on in-person check-ups. Another proposed
    design is in [6]. Their framework is a fog-centric implementation aiming to improve
    the monitoring of body vitals in the health and fitness industry. These works
    focus on remotely locating a fog device around a cluster of users for their implementations,
    while the designs aimed more at its analytical capabilities than its security.
    Our proposed platform is also fog-centric. However, the proposed platform differs
    by having the fog servers closer to each user and creating a better exclusive
    network through the WBAN. Also, we incorporate a private blockchain to reinforce
    the network''s security. The proposed design focuses on providing better data
    protection for wearable IoT devices in healthcare. SECTION III. Platform Design
    The following sections highlight our proposed design and its components. Fig.
    1: Network architecture and hierarchy of our proposed platform. Show All A. Overview
    We propose a blockchain-based WBAN platform to address security and manageability
    issues. The proposed design combines a private blockchain and a WBAN architecture
    to create a system that regulates the data for the patient. By utilizing the tamperproof
    and decentralized capabilities of the blockchain, we implement a security administrator
    for the network. Also, we keep the data and devices exclusive to the user by taking
    the limiting scope and unique architecture of the WBAN. As a result, patient information
    is secure while the overarching healthcare service is more manageable. We design
    our platform to be small-scale to reflect a minimal approach to addressing the
    issues presented in this work. A diagram showing the network architecture and
    hierarchy of the proposed platform is in Fig. 1. The assigned central server manages
    all the wearable IoT devices of the patient. Our design uses an Android smartphone
    device that serves as the fog server and regulates all the data for the patient.
    It will be the only device communicating with the central server. This hierarchy
    establishes a mini WBAN around the patient, with the smartphone as the local fog
    server. Also, we placed the private blockchain within the fog device. The fog
    server will treat it as a hyperledger that authorizes data transmissions from
    trusted wearable IoT devices. The communication parameters of the proposed approach
    are WiFi 2.4GHz and socket programming. A diagram showing the data flow within
    the platform as the wearable IoT devices send data to the cloud server is in Fig.
    2. First, wearable IoT devices initiate the data transmission to the fog server.
    Each local server confirms if the source is trusted using the private blockchain.
    If the fog authorizes the data, it forwards the information to the cloud for storage.
    Otherwise, the data is not received, and users do not gain access. B. Components
    Our proposed platform has three main components; the cloud server, the fog device,
    and the edge devices. First, the cloud server is used mainly for storage which
    will house all the data from each patient. It represents the healthcare center
    where all data is collected. We used a standard personal computer with an Intel®
    Core™ i7-6500U CPU @ 2.59 GHz processor as the main server. It also contains a
    copy of the blockchain for cross-referencing data and verifying sources. Fig.
    2: Logic flow diagram of the platform as edge device sends data to the cloud server.
    Show All Due to its programmability and processing power, we used an LG Nexus
    5 smartphone for the fog server. The phone uses an Android SDK 4.4 API 19 KitKat
    as its operating system, which is a popular OS and available to more than 98%
    of Android-based smartphones. Along with its vast open-source library, we wrote
    a script that manages the data between the wearable IoT devices and the fog server.
    We programmed the private blockchain using Python. It is a chain class composed
    of block classes/objects linked cryptographically by hashing an instance of the
    previous block and storing it as a variable on the current block. The server that
    holds the private blockchain will initialize it by generating a base block containing
    a list of device IDs allowed to transmit and access the data within the cloud
    server. Other variables initialized along each block are an ID, a list of transactions,
    and a timestamp of its generation. We placed the private blockchain in the fog
    device to regulate the connecting wearable IoT devices and handle the incoming
    and outgoing data. It contains a function that will check the IDs of each data
    transmission. Then, it confirms if the source is a trusted device. The server
    denies the transaction if the data source is unregistered within the blockchain.
    Otherwise, it authorizes the data transmission and stores the received information
    in its database. Also, it records the transaction within its ledger to keep a
    historical record. For the edge devices, we used a combination of Raspberry Pi
    3 B''s and Samsung Galaxy Watch 4''s to provide the data simulating the collected
    patient information. Each IoT device is programmed to transmit data to the local
    server to simulate a physiological sensor monitoring a patient. The fog device
    then verifies the user against the ledger in the blockchain. If authorized, it
    permits the data transaction. Finally, the database within the cloud server stores
    the data. SECTION IV. Results and Discussion We conducted experiments to investigate
    and evaluate the feasibility of our design in terms of security and manageability.
    A. Experimental Design and Testbed We examined the feasibility of our proposed
    platform under small-scale conditions. Aiming for large-scale conditions presents
    challenges in evaluating our approach. It requires more hardware and measurements
    to do the simulations. When modelling large-scale applications, there is a need
    for more data sources to represent the system effectively. Also, evaluating a
    design with the maximum requirements can make benchmarking more difficult due
    to wearable technologies upgrading frequently. A small-scale approach makes it
    easier to establish a minimum benchmark in addressing the issues presented by
    this work. The testbed has a central cloud server using the personal computer
    to receive the transmitted data. Then, around it will be Android phones representing
    the fog devices. These devices will function as local servers. They will regulate
    the data from edge devices. We connected each smartphone to a pair of data sources
    to simulate this part of the network. These sources are a Raspberry Pi and a Samsung
    Galaxy Watch 4. We arbitrarily chose this arrangement to represent a user having
    a wearable IoT device providing their physiological data. To examine the feasibility
    of this platform in terms of manageability, we focused on latency and throughput.
    We use these variables as the metrics for discussion. We compare our configuration
    with a network architecture that removes our fog component. Instead, it has IoT
    devices send data directly to the cloud. This configuration represents the standard
    structure of a cloud-centric network. Its cloud server will serve as the focal
    point of operations. Also, the smartwatches and the Pis will be the edge devices
    that provide data to the cloud and subscribe to its services. We moved the private
    blockchain to the cloud since the fog is not in this configuration. We compare
    these configurations when managing three users, as shown in Fig. 3. The trade-off
    between these is control and potential security over process reallocation and
    server workload. The cloud-based implementation focuses all of its resources in
    the cloud, keeping data aggregated into one space. Although this helps centralize
    data collection and security, it forces the cloud to be the only server that manages
    and secures its data. The fog-based implementation enables process reallocation
    and distribution of workload across the network. However, adding local servers
    reduces the control and security over the data from the cloud. That is why we
    proposed using blockchain technology and its distributive and immutable design
    to compensate for and potentially improve it in the fog-based IoT network. Fig.
    3: Two configurations, (a) a standard cloud-based IoT and (b) our proposed fog-based
    IoT. Show All B. Security Evaluation This platform aims to address the security
    of wearable IoT devices in healthcare. To evaluate our design, we use a modelling
    methodology to analyze it. The model that we chose to use is STRIDE. It is a threat
    model that analyzes the strengths and weaknesses of a design against six categories
    [18]. These categories are: i) Spoofing, ii) Tampering, iii) Repudiation, iv)
    Information Disclosure, v) Denial of Service, and vi) Elevation of Privilege.
    We selected this model because it can identify vulnerabilities and highlight risks
    in the design [19]. Also, the threats used by this model are well-known sources
    of security and manageability issues of IoT-based services in healthcare, education,
    home, and vehicles [20]. Therefore, by evaluating our design against this model,
    we can further support the feasibility of our platform. The following enumerates
    our analysis using STRIDE: Spoofing - It is the process of impersonating an authorized
    user to access the network. This malicious attack exposes architecture vulnerabilities
    making user information not secure. Our platform can use the blockchain to hide
    user data behind an encrypted wall. It will protect the data from leaks cryptographically.
    Also, with the WBAN architecture, the range of detecting the network is small.
    Since the radius of its scope covers the area around the person, the malicious
    attacker would have to stand next to them to request access. This design provides
    a defence against spoofed users by only considering connecting devices within
    a very close range. With the private blockchain keeping the ledger secure and
    the WBAN having a small scope, our platform presents good defences against spoofing.
    Also, our design reduces the likelihood of tampering by connecting devices already
    filtered by the fog. However, this is not absolute protection against this threat.
    Therefore, future iterations can include more methods that reinforce the security
    of user information around the fog. An option is adding a second level of encryption
    to make access requests more complex. Tampering - It is the process of changing
    the contents of a data structure without authorization. Users who have access
    to the network can transmit data to the fog device. As previously discussed, our
    platform has the means to defend against spoofing. Obtaining access to the network
    is harder. Also, the server can detect unauthorized changes due to the tamperproof
    private blockchain. This advantage makes the data within the network immutable
    and secures it against these threats. As a result, it is more difficult to modify
    the data. Also, due to the fog, our architecture is decentralized. Therefore,
    it can detect tampering earlier. As a result, the central server is better protected
    from these attacks. Therefore, our platform has a built-in defence against tampering
    due to the private blockchain. Further iterations could also include a detection
    layer for faster response times against this attack. Repudiation - It is the state
    where the data structure can verify transactions within it. Exchange within the
    network is repudiated if the destination is confirmed. With our platform, repudiation
    is made possible with the blockchain. It is the one that will check all data transactions
    between the Android device and the Pis. Again, the central server defended better
    with earlier detection along the hierarchy. This design further improves the manageability
    of the network by reducing the number of vulnerabilities that can reach the server.
    Therefore, it can verify if all the information going in and out of the WBAN is
    authorized. As a result, changing any information within these transactions will
    be easier to catch with the blockchain. Information Disclosure - The most sensitive
    data that need protection is user information. The blockchain relies on these
    to authorize devices that attempt to communicate within the WBAN. This threat
    analysis exposes a vulnerability in the design. Further reinforcement of the network
    ledger is required to protect this information. Like the analysis from the spoofing
    threat, future iterations could include a better means of keeping this data structure
    secure. Denial of Service (DoS) - It is an attack where a network is rendered
    unable to function. This service failure is due to an overwhelming number of devices
    attempting to access it. Since the platform uses a WBAN, its area is limited,
    which naturally reduces the entry points of location-based DoS attacks. Also,
    this keeps the central server safe by limiting the endpoints that talk to the
    cloud. However, malicious attackers can still impersonate known devices. As a
    result, the network is still vulnerable. Although not absolute, our design can
    defend against this threat around the fog. Therefore, future interactions can
    implement rate limiters for the Android device to reinforce it. This addition
    ensures that incoming access requests are regulated. Elevation of Privilege -
    Our current design only recognizes two privilege levels. The device is either
    allowed access or not. Only the blockchain can decide which user is allowed access.
    Therefore, tampering with this list is the only way a malicious account can elevate
    its privilege. Based on our previous analysis of tampering and spoofing, our design
    shows promise in its defences against tampering. The only means of changing the
    blockchain is to overwrite it before the network initializes the application.
    Therefore, we can deny unauthorized changes to keep the ledger secure against
    unwanted elevation of privilege while the application runs. Future iterations
    can include a protocol that only allows changes to the list of authorized users
    through validated patches from the central server. C. Throughput and Latency Evaluation
    The first evaluation was for the throughput and latency of our design under small-scale
    conditions. As mentioned, we had two configurations. The first is our platform
    which uses a fog-based IoT network. Next is the control variable with a standard
    cloud-based IoT network arrangement. Each architecture was tested by having the
    devices send data to the server for one minute. We obtained the average latency
    by measuring the instantaneous response time of the cloud for each packet sent.
    There were multiple iterations of each measurement where the user count varied
    from 1, 3, and 5. To evaluate the throughput, we tested different sizes of the
    packets in each iteration at 128, 256, 512, and 1024 bytes of data. A diagram
    comparing the response average time of the cloud server to each configuration
    at varying numbers of users and data sizes is in Fig. 4. According to the experimental
    results, the platform yielded lower latencies with our fog configuration. This
    behaviour means that the cloud server is more responsive to the fog configuration
    than the standard cloud as more devices connect. As a result, our proposed design
    shows potential for alleviating manageability concerns within the network regarding
    latency. In terms of increasing data sizes, the average response time of our configuration
    was lower. A plot showing a closer analysis of the throughput using the iteration
    with five users is in Fig. 5. When the size of the transmitted data increased,
    our configuration performed better by showing little change in the response time.
    However, the standard cloud server jumps in this value with the change in packet
    size. Compared to the cloud configuration, ours was better at catering to increasing
    data sizes. This trend shows that more data can be allowed in each transmission.
    Therefore, our design can optimize the network architecture. Also, providing space
    for encrypting methods reinforces the security of the data within the packet.
    With these observations, we can see that our configuration shows the potential
    alleviating some manageability concerns of the network in terms of throughput
    as the volume of transmitted data increases. Overall, the results show how our
    proposed fog configuration for the platform improves the ability to scale the
    IoT network regarding latency and throughput. Fig. 4: Server response time comparison
    of fog and cloud configurations with varying numbers of users and packet size.
    Show All Fig. 5: Server response time comparison of fog and cloud configurations
    with varying data sizes for the five user iterations. Show All D. Discussion Overall,
    the private blockchain shows great defences regarding security against most of
    the threats in this model. The platform data is immutable to a certain degree
    because of the blockchain. It is secure unless there is direct tampering in the
    application. Also, the WBAN can mitigate most location-based attacks due to its
    limited area scope. The network can detect unknown users because it grants access
    through the blockchain. Also, it can limit the amount of data being disclosed
    by creating levels of access to keep sensitive data written and protected. With
    the cryptographical capabilities of blockchain technology, keeping data secure
    and tamperproof makes it convenient. Based on the experiments, introducing the
    fog device via the Android phone shows the potential alleviating manageability
    concerns of the network in terms of latency and throughput. With an intermediary
    medium that preprocesses the data before it reaches the server, we can reduce
    the number of endpoints that the network needs to manage. With lesser end-points,
    there is an improvement in the latency and throughput of the network. Also, the
    volume of data is less likely to overwhelm the server. As for security, these
    attacks are less likely to reach the central server with another defence layer
    that detects these threats earlier. Also, we can add measures that increase the
    data flow security of the network with a more capable processing point. As a result,
    it limits the need for processes that overwhelm edge devices and disrupt data
    collection. Therefore, we can see through these tests and evaluations that using
    the blockchain with the WBAN architecture is feasible in terms of security and
    manageability. SECTION V. Conclusions We proposed a platform to improve the security
    and manageability of wearable IoT devices in healthcare. To reinforce the network,
    we elected to integrate a private blockchain. It makes data secure and immutable
    using its tamperproof and decentralized structure. Meanwhile, to improve the manageability
    of wearable IoT devices in healthcare, we used the architecture of WBANs. This
    design choice introduces a fog layer to the network. As a result, we can reallocate
    processes to a local server, which reduces the overall strain on the main. We
    evaluated the feasibility of this design in terms of security and manageability.
    First, we used a STRIDE threat model to investigate how secure is our blockchain-based
    platform. The results show how integrating private blockchains and WBANs into
    the platform can address the threats provided by the evaluation. Then, we tested
    its latency and throughput to prove if it makes the IoT network more manageable.
    Our fog-based IoT network, created by integrating the WBAN architecture, was compared
    against a standard cloud-based configuration. The results revealed improved manageability
    in our design with better performance based on server response time and data overhead
    regulation. Authors Figures References Keywords Metrics More Like This Energy
    Consumption Minimization With Throughput Heterogeneity in Wireless-Powered Body
    Area Networks IEEE Internet of Things Journal Published: 2021 Remote Authentication
    Schemes for Wireless Body Area Networks Based on the Internet of Things IEEE Internet
    of Things Journal Published: 2018 Show More IEEE Personal Account CHANGE USERNAME/PASSWORD
    Purchase Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile Information
    COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help?
    US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow
    About IEEE Xplore | Contact Us | Help | Accessibility | Terms of Use | Nondiscrimination
    Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy Policy A not-for-profit
    organization, IEEE is the world''s largest technical professional organization
    dedicated to advancing technology for the benefit of humanity. © Copyright 2024
    IEEE - All rights reserved."'
  inline_citation: '>'
  journal: IEEE International Conference on Communications
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Private Blockchain-Based Wireless Body Area Network Platform for Wearable
    Internet of Thing Devices in Healthcare
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - He P.
  - Zhu Z.
  - Wang X.
  - Zhang C.
  - Yuan W.
  - Hao J.
  citation_count: '0'
  description: A power-system protection device built using Internet-of-Things (IoT)
    technologies in an intelligent environment. IoT supports electrical and physical
    parameters monitoring. One of the characteristics that must be checked is electricity
    usage from electronic gadgets. It is a complex problem to design energy-efficient
    IoT methods. IoT gets more complicated because of its vast size, and current wireless
    sensor network approaches cannot be used directly to IoT. Information gathering
    on the area is monitored by intelligent cellular terminals, intelligent security
    tools, and other multi-source sensing equipment. That is the foundation for the
    combined analysis and evaluation of security risk extensive data by cloud computing
    and edge computing. The IoT-based Power safety tools management (IoT-PSTM) system
    has been developed to integrate it into intelligent settings, such as smart homes
    or smart cities, to safeguard electrical equipment. It is meant to increase power
    security by quickly disconnecting in failure events such as leaking current. The
    system allows for real-time monitoring and alerting of events using a sophisticated
    data-concentration architecture communication interface. The goal is to progress
    and merge several technologies technically and integrate them into a personal
    safety system to increase security, preserve their availability, eliminate mistakes,
    and reduce the time required for scheduled or ad hoc interventions. Real-time
    data transmission, instant data processing from diverse sources, local intelligence
    in low-power embedded systems, interaction with many on-site users, sophisticated
    user interfaces, portability, and wearability are the main difficulties for the
    research project. This article offers a comprehensive explanation of the design
    and execution of the proposed system and the test findings. The results denote
    the higher performance of the suggested IoT-PSTM system with IoT module and enhanced
    performance of 94.7%.
  doi: 10.13052/dgaej2156-3306.3847
  full_citation: '>'
  full_text: '>

    "Distributed Generation & Alternative Energy Journal River Publishers Journals
    View All Issues Editorial Team Author Guidelines About Submissions Contact Search
    Register Login Home / Archives / 2023: Vol 38 Iss 4 / Articles Research on Supervision
    System of Power Safety Tools and Equipment Based on Internet of Things Technology
    Ping He State Grid Nanjing Power Supply Company, Nanjing 210019, Jiangsu, China
    Zhengyi Zhu State Grid Nanjing Power Supply Company, Nanjing 210019, Jiangsu,
    China Xuyan Wang State Grid Nanjing Power Supply Company, Nanjing 210019, Jiangsu,
    China Can Zhang State Grid Nanjing Power Supply Company, Nanjing 210019, Jiangsu,
    China Wei Yuan State Grid Nanjing Power Supply Company, Nanjing 210019, Jiangsu,
    China Junhua Hao Yijiahe Technology Co., Ltd, Nanjing 210012, China DOI: https://doi.org/10.13052/dgaej2156-3306.3847
    Keywords: Power safety, IoT, equipment, electrical system, cloud computing Abstract
    A power-system protection device built using Internet-of-Things (IoT) technologies
    in an intelligent environment. IoT supports electrical and physical parameters
    monitoring. One of the characteristics that must be checked is electricity usage
    from electronic gadgets. It is a complex problem to design energy-efficient IoT
    methods. IoT gets more complicated because of its vast size, and current wireless
    sensor network approaches cannot be used directly to IoT. Information gathering
    on the area is monitored by intelligent cellular terminals, intelligent security
    tools, and other multi-source sensing equipment. That is the foundation for the
    combined analysis and evaluation of security risk extensive data by cloud computing
    and edge computing. The IoT-based Power safety tools management (IoT-PSTM) system
    has been developed to integrate it into intelligent settings, such as smart homes
    or smart cities, to safeguard electrical equipment. It is meant to increase power
    security by quickly disconnecting in failure events such as leaking current. The
    system allows for real-time monitoring and alerting of events using a sophisticated
    data-concentration architecture communication interface. The goal is to progress
    and merge several technologies technically and integrate them into a personal
    safety system to increase security, preserve their availability, eliminate mistakes,
    and reduce the time required for scheduled or ad hoc interventions. Real-time
    data transmission, instant data processing from diverse sources, local intelligence
    in low-power embedded systems, interaction with many on-site users, sophisticated
    user interfaces, portability, and wearability are the main difficulties for the
    research project. This article offers a comprehensive explanation of the design
    and execution of the proposed system and the test findings. The results denote
    the higher performance of the suggested IoT-PSTM system with IoT module and enhanced
    performance of 94.7%. Downloads Author Biographies Ping He, State Grid Nanjing
    Power Supply Company, Nanjing 210019, Jiangsu, China Ping He (1981.01–), who received
    a bachelor’s degree from Wuhan University of water resources and electric power
    in 2002, is now the deputy director of the operation and maintenance department
    of Nanjing power supply company of State Grid. Her research interests include
    smart grid, power system automation, etc. Zhengyi Zhu, State Grid Nanjing Power
    Supply Company, Nanjing 210019, Jiangsu, China Zhengyi Zhu (1987.10–), who received
    a doctorate from Shandong University in 2018, is now an engineer in the operation
    and maintenance department of State Grid Nanjing power supply company. His research
    interests include smart grid, power Internet of things, energy Internet, etc.
    Xuyan Wang, State Grid Nanjing Power Supply Company, Nanjing 210019, Jiangsu,
    China Xuyan Wang (1982.10–), who received a master’s degree from Newcastle University
    in 2007, is now a senior engineer in the operation and maintenance department
    of State Grid Nanjing power supply company. His research interests include smart
    grid, distribution automation, etc. Can Zhang, State Grid Nanjing Power Supply
    Company, Nanjing 210019, Jiangsu, China Can Zhang (1989.10–), who obtained a master’s
    degree from Zhejiang University in 2014, is now an engineer in the operation and
    maintenance department of State Grid Nanjing power supply company. His research
    interests include intelligent distribution network, intelligent operation inspection
    of distribution network, etc. Wei Yuan, State Grid Nanjing Power Supply Company,
    Nanjing 210019, Jiangsu, China Wei Yuan (1991.05–), who obtained a bachelor’s
    degree from Southeast University in 2014, is now an engineer in the operation
    and maintenance department of State Grid Nanjing power supply company. His research
    interests include intelligent distribution network, intelligent operation inspection
    of distribution network, etc. References Zhang, J., Fu, J., Hao, H., Fu, G., Nie,
    F., and Zhang, W. (2020). Root causes of coal mine accidents: Characteristics
    of safety culture deficiencies based on accident statistics. Process Safety and
    Environmental Protection, 136, 78–91. Utne, I. B., Rokseth, B., Sørensen, A. J.,
    and Vinnem, J. E. (2020). Towards supervisory risk control of autonomous ships.
    Reliability Engineering & System Safety, 196, 106757. Manogaran, G., Saravanan,
    V., and Hsu, C. H. (2021). Information-Centric Content Management Framework for
    Software-Defined Internet of Vehicles Towards Application Specific Services. IEEE
    Transactions on Intelligent Transportation Systems. Qu, J., He, L., Tang, N.,
    and Lee, C. K. (2020). Wireless power transfer using domino-resonator for 110-KV
    power grid online monitoring equipment. IEEE Transactions on Power Electronics,
    35(11), 11380–11390. Nguyen, T., Liu, B. H., Nguyen, N., Dumba, B., and Chou,
    J. T. (2021). Smart Grid Vulnerability and Defense Analysis Under Cascading Failure
    Attacks. IEEE Transactions on Power Delivery, 1–1. Kuthadi, V. M., Selvaraj, R.,
    Baskar, S., Shakeel, P. M., and Ranjan, A. (2021). Optimized Energy Management
    Model on Data Distributing Framework of Wireless Sensor Network in IoT System.
    Wireless Personal Communications, 1–27. https://doi.org/10.1007/s11277-021-08583-0
    Zhang, X., Manogaran, G., and Muthu, B. (2021). IoT enabled an integrated system
    for green energy into smart cities. Sustainable Energy Technologies and Assessments,
    46, 101208. Gao, J., Wang, H., and Shen, H. (2020, May). Smartly handling renewable
    energy instability in supporting a cloud datacenter. In 2020 IEEE international
    parallel and distributed processing symposium (IPDPS) (pp. 769–778). IEEE. Amudha,
    G. (2021). ACDS—Assisted Cooperative Decision-Support for Reliable Interaction
    based Navigation Assistance for Autonomous Vehicles. Microprocessors and Microsystems,
    104241. Yılmaz, İ. H., Mwesigye, A., and Göksu, T. T. (2020). Enhancing the overall
    thermal performance of a large aperture parabolic trough solar collector using
    wire coil inserts. Sustainable Energy Technologies and Assessments, 39, 100696.
    Amudha, G., and Narayanasamy, P. (2018). Distributed location and trust-based
    replica detection in wireless sensor networks. Wireless Personal Communications,
    102(4), 3303–3321. Sharma, P., Shankar, A., and Cheng, X. (2021). Reduced PAPR
    Model Predictive Control based FBMC/OQAM signal for NB-IoT paradigm. International
    Journal of Machine Learning and Cybernetics, 1–15. Shanmugam, L., Mani, P., and
    Joo, Y. H. (2020). Stabilisation of event-triggered-based neural network control
    system and its application to wind power generation systems. IET Control Theory
    & Applications, 14(10), 1321–1333. Gunasekaran, N., Thoiyab, N. M., Muruganantham,
    P., Rajchakit, G., and Unyong, B. (2020). Novel global robust stability analysis
    results for dynamical delayed neural networks under parameter uncertainties. IEEE
    Access, 8, 178108–178116. Collazos, J. D., Gaona-García, E. E., Gaona-García,
    P. A., Montenegro, M. C. E., and Gómez-Acosta, A. (2020, June). Prediction model
    for energy consumption and generation based on artificial neural networks. In
    2020 15th Iberian Conference on Information Systems and Technologies (CISTI) (pp.
    1–6). IEEE. Khamparia, A., Singh, S. K., Luhach, A. K., and Gao, X. Z. (2020).
    Classification and analysis of users review using different classification techniques
    in an intelligent e-learning system. International Journal of Intelligent Information
    and Database Systems, 13(2–4), 139–149. Indukuri, C. L., and Kottursamy, K. (2021).
    Advanced Accident Avoiding, Tracking, and SOS Alert System Using GPS Module and
    Raspberry Pi. In Artificial Intelligence Techniques for Advanced Computing Applications
    (pp. 167–178). Springer, Singapore. Billah, M. F. R. M., Saoda, N., Gao, J., and
    Campbell, B. (2021, May). BLE Can See A Reinforcement Learning Approach for RF-based
    Indoor Occupancy Detection. In Proceedings of the 20th International Conference
    on Information Processing in Sensor Networks (co-located with CPS-IoT Week 2021)
    (pp. 132–147). Do, D. T., Van Nguyen, M. S., Nguyen, T. N., Li, X., and Choi,
    K. (2020). Enabling multiple power beacons for the uplink of noma-enabled mobile
    edge computing in wirelessly powered IoT. IEEE Access, 8, 148892–148905. Abouloula,
    K., Ou-Yassine, A., Krit, S. D., and Elhoseny, M. (2021). Artificial Intelligence–Based
    Methods of Financial Time Series for Trading Experts in a Relational Database
    to Generate Decisions. In the Internet of Everything and Big Data (pp. 101–114).
    CRC Press. Choi, C., Esposito, C., Wang, H., Liu, Z., and Choi, J. (2018). Intelligent
    power equipment management based on distributed context-aware inference in smart
    cities. IEEE Communications Magazine, 56(7), 212–217. Liu, Y. (2019, October).
    The Influence of Smart Grid on Electric Power Automation. In International Conference
    on Advanced Intelligent Systems and Informatics (pp. 1036–1043). Springer, Cham.
    Hashim, M. S., Yong, J. Y., Ramachandaramurthy, V. K., Tan, K. M., Mansor, M.,
    and Tariq, M. (2021). Priority-based vehicle-to-grid scheduling for minimization
    of power grid load variance. Journal of Energy Storage, 39, 102607. Fan, M., and
    Zhang, X. (2019). Consortium blockchain-based data aggregation and regulation
    mechanism for smart grid. IEEE Access, 7, 35929–35940. Li, L., Ren, X., Yang,
    Y., Zhang, P., and Chen, X. (2018). Analysis and recommendations for onshore wind
    power policies in China. Renewable and Sustainable Energy Reviews, 82, 156–167.
    Marten, A. K., Akmatov, V., Sørensen, T. B., Stornowski, R., Westermann, D., and
    Brosinsky, C. (2018). Kriegers flak-combined grid solution: coordinated cross-border
    control of a meshed HVAC/HVDC offshore wind power grid. IET Renewable Power Generation,
    12(13), 1493–1499. Mao, D., Gao, Z., and Wang, J. (2019). An integrated algorithm
    for evaluating plug-in electric vehicle’s impact on the state of power grid assets.
    International Journal of Electrical Power & Energy Systems, 105, 793–802. Rafique,
    S. F., Shen, P., Wang, Z., Rafique, R., Iqbal, T., Ijaz, S., and Javaid, U. (2018).
    Global power grid interconnection for sustainable growth: concept, project and
    research direction. IET Generation, Transmission & Distribution, 12(13), 3114–3123.
    Mao, D., Tan, J., and Wang, J. (2020). Location planning of PEV fast charging
    station: an integrated approach under traffic and power grid requirements. IEEE
    Transactions on Intelligent Transportation Systems, 22(1), 483–492. Hayakawa,
    N., Maeno, Y., and Kojima, H. (2018). Fault current limitation coordination in
    electric power grid with superconducting fault current limiters. IEEE Transactions
    on Applied Superconductivity, 28(4), 1–4. Zecchino, A., and Marinelli, M. (2018).
    Analytical assessment of voltage support via reactive power from new electric
    vehicles supply equipment in radial distribution grids with voltage-dependent
    loads. International Journal of Electrical Power & Energy Systems, 97, 17–27.
    Ilyushin, P. V. (2018). Analysis of the specifics of selecting relay protection
    and automatic (RPA) equipment in distributed networks with auxiliary low-power
    generating facilities. Power Technology and Engineering, 51(6), 713–718. He, Y.,
    Xiong, W., Yang, B., Yang, H. Y., Zhou, J. F., Cui, M. L., and Li, Y. (2021).
    Combined game model and investment decision-making of power grid-distributed energy
    system. Environment, Development, and Sustainability, 1–24. Ding, L., Shi, Y.,
    He, C., Dai, Q., Zhang, Z., Li, J., and Zhou, L. (2021). How does the satisfaction
    of solar PV users enhance their trust in the power grid?-Evidence from PPAPs in
    rural China. Energy, Sustainability and Society, 11(1), 1–19. Adetokun, B. B.,
    and Muriithi, C. M. (2021). Impact of integrating large-scale DFIG-based wind
    energy conversion system on the voltage stability of weak national grids: a case
    study of the Nigerian power grid. Energy Reports, 7, 654–666. Babu, D. V., Saravanan,
    V., Kumar, P., and Singh, S. (2015). Automated robotic receptionist with embedded
    touch screen. Journal of Chemical and Pharmaceutical Sciences, 415–417. Xue, M.,
    Al-Turjman, F., and Saravanan, V. (2021). A Labor Safety Performance and Involvement
    of Workers in Accident Reduction and Prevention. Aggression and Violent Behavior,
    101560. Yu, L., Nazir, B., and Wang, Y. (2020). Intelligent power monitoring of
    building equipment based on Internet of Things technology. Computer Communications,
    157, 76–84. Abdulla, A. I., Abdulraheem, A. S., Salih, A. A., Sadeeq, M. A., Ahmed,
    A. J., Ferzor, B. M., …and Mohammed, S. I. (2020). Internet of things and smart
    home security. Technol. Rep. Kansai Univ, 62(5), 2465–2476. PDF HTML Published
    2023-05-18 How to Cite He, P. ., Zhu, Z. ., Wang, X. ., Zhang, C. ., Yuan, W.
    ., & Hao, J. . (2023). Research on Supervision System of Power Safety Tools and
    Equipment Based on Internet of Things Technology. Distributed Generation &Amp;
    Alternative Energy Journal, 38(04), 1223–1254. https://doi.org/10.13052/dgaej2156-3306.3847
    More Citation Formats Issue 2023: Vol 38 Iss 4 Section Articles Special Issue     Proposals
    for special issues should be sent to specialissues@riverpublishers.com along with
    a rationale for how the topic fits with the scope of the Journal. Proposals with
    guest editors who have not previously published in the Journal will most likely
    be unsuccessful. Proposals sent directly to the editors of the Journal will be
    immediately rejected. River Publishers series in Power and Distributed Generation
    & Alternative Energy Journal ISSN: 2156-6550 (Online Version) ISSN: 2156-3306
    (Print Version) Call for Papers Machine Learning in Energy Optimization for New
    Energy Solutions August Energy Newsletter Our latest Energy newsletter is now
    available, giving updates on all our latest publications, expert interviews, and
    news in the area of energy. Hybrid Journal Submission Subscription Indexed in:
    CABI The IET – Inspec Database University of Bremen – E-Lib Bremen ProQuest EBSCO
    Scopus Ei Compendex/Engineering village"'
  inline_citation: '>'
  journal: Distributed Generation and Alternative Energy Journal
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Research on Supervision System of Power Safety Tools and Equipment Based
    on Internet of Things Technology
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Seo D.
  - Jung K.
  - Roh H.
  - Kim S.
  - Oh S.
  citation_count: '0'
  description: 'Industrial IoT is a key field of the 4th Industrial Revolution and
    wireless network technology is essential to support strict industrial requirements.
    Industrial wireless networks have reliable and real-time data transmission as
    the main requirement, and to achieve this, the network exploits two schemes: routing
    graph generation which calculates the data forwarding paths of each node, and
    scheduling, which allocates the communication time and frequency resources of
    each node. However, since conventional scheduling approaches allocate resources
    for all the calculated graphs, specific paths including routes close to the sink
    are used more redundantly. This phenomenon leads to unnecessary resource wastage
    and poor scalability in the industrial environment where the number of equipment
    used increases. To mitigate these problems, we propose a shared path-based scheduling
    scheme for efficient resource management and scalability improvement by setting
    the frequently overlapping sections of data flows as resource-sharing paths. The
    proposed scheme designates the resource sharing path and allocates resources for
    the shared path in consideration of network statuses, such as congestion and reliability.
    Simulation results show the proposed scheme is effective in terms of scalability
    and resource efficiency compared to traditional scheduling.'
  doi: 10.1109/ACCESS.2023.3284754
  full_citation: '>'
  full_text: '>

    "This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org
    IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal
    Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln
    Sign Out All Books Conferences Courses Journals & Magazines Standards Authors
    Citations ADVANCED SEARCH Journals & Magazines >IEEE Access >Volume: 11 High-Efficiency
    Resource Allocation Scheme Introducing the Concept of Resource Sharing Paths in
    Industrial IoT Publisher: IEEE Cite This PDF Dongyeong Seo; Kwansoo Jung; Hakgyun
    Roh; Sangdae Kim; Seungmin Oh All Authors 270 Full Text Views Open Access Comment(s)
    Under a Creative Commons License Abstract Document Sections I. Introduction II.
    Related Work III. Proposed Scheme IV. Performance Evaluation V. Conclusion Authors
    Figures References Keywords Metrics Abstract: Industrial IoT is a key field of
    the 4th Industrial Revolution and wireless network technology is essential to
    support strict industrial requirements. Industrial wireless networks have reliable
    and real-time data transmission as the main requirement, and to achieve this,
    the network exploits two schemes: routing graph generation which calculates the
    data forwarding paths of each node, and scheduling, which allocates the communication
    time and frequency resources of each node. However, since conventional scheduling
    approaches allocate resources for all the calculated graphs, specific paths including
    routes close to the sink are used more redundantly. This phenomenon leads to unnecessary
    resource wastage and poor scalability in the industrial environment where the
    number of equipment used increases. To mitigate these problems, we propose a shared
    path-based scheduling scheme for efficient resource management and scalability
    improvement by setting the frequently overlapping sections of data flows as resource-sharing
    paths. The proposed scheme designates the resource sharing path and allocates
    resources for the shared path in consideration of network statuses, such as congestion
    and reliability. Simulation results show the proposed scheme is effective in terms
    of scalability and resource efficiency compared to traditional scheduling. Resource
    Sharing Path based Superframe Scheduling with improved resource utilization by
    considering network reliability. Published in: IEEE Access ( Volume: 11) Page(s):
    63821 - 63833 Date of Publication: 09 June 2023 Electronic ISSN: 2169-3536 DOI:
    10.1109/ACCESS.2023.3284754 Publisher: IEEE Funding Agency: SECTION I. Introduction
    Industrial IoT (IIoT) is a key part of Industry 4.0. IIoT aims to provide accurate
    and fast process handling such as process monitoring and control, operation optimization,
    and automation of maintenance [1], [2], [3], [4], [5], [6]. In particular, today’s
    industrial sites with IIoT must successfully implement remote monitoring and control,
    which is the core of automation. This requires industrial networks providing high
    reliability and real-time [7], [8], [9], [10]. Industrial networks have more strict
    requirements for reliability and real-time than consumer IoT. For example, in
    mission-critical areas such as chemical, gas, oil, and security, various data
    containing industrial information must successfully reach its destination within
    the appropriate time required by the application. To achieve this, reliable network
    operation techniques are required [11], [12]. Early industrial networks provided
    a high level of reliability by applying wired networks connecting industrial equipment
    through cabling. Nowadays, the development of wireless technology has provided
    communication quality that can partially replace wired networks with problems
    such as cabling and maintenance. ISA 100.11a, Zigbee, WIA-PA, WirelessHART are
    industrial wireless network technologies that are being applied in industrial
    sites [13], [14], [15], [16]. Especially WirelessHART, is one of the most widely
    used technologies in the practical industry, and it is the first international
    standard for the industrial wireless protocol (IEC 62591) that solves the problems
    of cabling for industrial automation in a wireless manner [17]. The Industrial
    Wireless Network (IWN), represented by WirelessHART in this study, is specialized
    for remote monitoring and control, which is the core of process automation applied
    to IIoT. Field devices (sensor, actuator), gateways, and a network manager (NM)
    that organizes and manages the entire network form a mesh-type wireless sensor
    network [18]. This type of IWN is operated by a schedule-based communication approach
    in which a central NM configures an ideal routing path from the source device
    to the destination device and allocates communication resources based on the configured
    path, which is divided into time and channel. The routing path is constructed
    based on information including signal strength and neighbor of each device managed
    by the NM. At this point, the path between source and destination is configured
    in the form of a graph, providing high reliability by redundancy that allows data
    to be transmitted through an alternate path even if an error occurs in the primary
    path. Based on the graph route, the NM schedules the transmission/receiving of
    data by allocating fixed resources within the form of a superframe divided into
    time-slot and channel offset for all inter-device links. When scheduling, it also
    uses a redundancy policy that allocates resources for retransmission in case of
    failure on each link and resources for alternative routes in advance. This supports
    reliable and real-time communication by mitigating problems such as collisions
    due to signal interference and path failures. In this manner, IWN scheduling approaches
    enable process planning to meet the various requirements of applications. However,
    fixed resource allocation scheduling, which focuses on achieving reliability and
    real-time, faces several resource utilization efficiency issues due to the restricted
    radio resources with unlicensed bandwidth (ISM Band, 2.4 GHz). This leads to limitations
    in network scalability, energy consumption, and other performance aspects. First,
    when the network is stable with extremely low errors (e.g. channel interference,
    path failure), the high redundancy policies (retransmissions, backup paths) result
    in wasted resources that are not actually utilized [19]. In addition, data collected
    from field devices deployed in different areas use each graph routes for transmission
    to the destination. Therefore, certain paths, such as those close to a gateway
    (sink), become hot spots and are used quite redundantly [20]. Even if some sections
    of the routing graph used to transmit different data are overlapping, since resources
    are fixedly allocated for each data flow, resource utilization in these sections
    becomes more inefficient due to the high redundancy. Therefore, while a typical
    scheduling-based communication provides industrial processes with the aim of reliability
    and real-time transmission, it is limited in supporting sensitive real-time applications
    and scalability in today’s industrial environments with massive deployment of
    various types of devices due to resource efficiency issues. In this paper, we
    introduce the concept of resource sharing paths to mitigate the resource efficiency
    issues associated with the high redundancy policy of existing IWN systems. A resource
    sharing path (RSP) is a Section where there are many overlapping paths between
    each graph that data collected from different devices are used to transmit to
    the final destination. It is a logical path that allows each device to share the
    resources allocated at scheduling and utilize them for transmission. Instead of
    the conventional scheduling method that allocates fixed resources based on the
    End-to-End graph route of each data flow, the proposed scheme defines RSP by considering
    the number of data flows (traffic) and link stability in the high overlapping
    Section and resets the graph to a hierarchical route. Also, the communication
    resources required in this RSP are decreased and allocated according to the network
    stability (link status), and the allocated resources are utilized so that each
    data flow can share them, thereby reducing the waste of wireless resources and
    improving the efficiency of resource usage. The remainder is organized as follows:
    In Section II, we introduce the background of the existing IWN technology and
    related works, and in Section III, we describe the proposed resource sharing path-based
    scheduling in detail. Then, the performance evaluation through simulation is shown
    in Section IV, and Finally, we conclude this paper with a review and discussion
    of future works in Section V. SECTION II. Related Work In this section, we describe
    the background of IWN represented by WirelessHART, focusing on routing and scheduling,
    which are the core of IWN. We also review related literature that adopts the WirelessHART
    to meet the various requirements of the industry. A. Background of WirelessHART
    WirelessHART is designed to operate in the ISM (Industry-Science-Medical) bandwidth
    (2.4 GHz) based on the IEEE 802.15.4 physical layer and uses a TDMA (Time Division
    Multiple Access) based MAC (Medium Access Control) protocol that utilizes frequency
    diversity by categorizing into multiple channels between 11 and 26 [21]. Network
    devices classified as network manager (NM), security manager, gateway, access
    point, field device, router, and handheld device form a wireless sensor network
    with a mesh-type topology. In particular, the NM is responsible for centrally
    configuring and managing the network, including network formation and configuration,
    routing path construction and management, communication scheduling, communicable
    channel management, and network diagnostics. The core function of the NM is to
    configure routing paths and allocate communication resources based on the paths
    to provide an ideal schedule for reliable and real-time communication. The NM
    receives reports containing neighbor table information and RSL (Received Signal
    Level) information from each field device periodically to configure routing paths.
    Routing paths can be categorized into paths for source routing and graph routing.
    Source routing uses a single fixed path between the source and the destination
    among the routes in the graph assembled by the NM, and is mainly used for route
    diagnostics because there is no backup in case of path failure. Graph routing
    considers multi-paths for each route from a source device to a destination. This
    is to establish backup paths in case of path failure of the End-to-End primary
    path, providing redundancy through graph routing to ensure the required level
    of reliability. WirelessHART primarily uses graph routing for the transmission
    of industrial data to provide reliability through redundancy. TABLE 1 Summary
    of Notation NM uses the Time Slotted Channel Hopping (TSCH) mechanism to schedule
    communications based on graph paths. The TSCH-based medium access control (MAC)
    protocol uses TDMA and channel hopping to schedule communications into a structure
    called a superframe that divides the radio resource into time and frequency channel
    domains. The time domain of the superframe is divided into time-slot units, like
    the TDMA mechanism, and the frequency domain is divided into 15 available channel
    offsets. The superframe schedule is organized so that each data can be transmitted
    or received in a different slot. All transmissions and receptions on links between
    devices within the primary and alternate paths of a routing graph, identified
    by graph ID, are assigned to the superframe structure. Only a pair of devices
    are allowed to communicate within each time-slot, and superframes are scheduled
    to allow channel hopping based on channel conditions, mitigating issues such as
    collisions and path fading due to interference. It also provides redundancy by
    allocating a time-slot for retransmission in case of transmission failure on each
    link of the primary path to increase reliability. B. Literature Review IWNs are
    typically planned by operators and have various requirements for different industries,
    such as reliability, low latency, and energy efficiency. Therefore, reasonable
    and efficient routing and scheduling strategies are required. WirelessHART networks
    are being evaluated as a feasible solution for IWNs. However, since the WirelessHART
    standard does not provide specific algorithms for constructing optimal routing
    paths and schedules, they remain as open challenges and many related studies are
    ongoing. Han et al. in [22], constructing a reliable graph and scheduling is proposed
    by defining (k,m)-reliability (k: incoming degree, m: outgoing degree). To reduce
    delay and energy consumption, devices with less hop count from the gateway are
    prioritized and reflected in the graph route configuration. Based on routing graph,
    a scheduling method is proposed. For the backup path, a parallel superframe twice
    as long as the main path is configured to improve the schedulability of main path.
    They improved reliability and scalability, but there are limitations due to increased
    delay in case of path failure by constructing a longer length superframe. In [23],
    graph path-based scheduling with a focus on reliability was proposed. In scheduling,
    constraints such as time-slot sequence with application needs, time-slot conflict
    avoidance, and channel interference avoidance were considered. In addition, high
    reliability is provided by using allocating retransmission slots for all links
    at the hop level. However, this method causes delay due to high resource occupancy
    and wastes network resources, making it difficult to support real-time and scalability.
    Reference [24] proposed superframe scheduling considering resource efficiency
    and energy consumption based on the constraints of [23]. Based on the End-to-End
    graph route, slots for hop-level retransmission are allocated, but data packets
    are aggregated on overlapping graph routes. This resulted in extending the lifespan
    of the network by reducing resources allocated to superframes and reducing energy
    consumption. However, since this method is applicable only when the size of aggregated
    data can be accommodated in one slot, it is difficult to apply in terms of scalability
    where a large number of devices are deployed. The above works are based on centralized
    network management under the WirelessHART standard, where the NM schedules communication
    based on graph paths. Recently, to improve the inflexibility of the centralized
    approach, decentralized networks that allow each device to actively set up routing
    and scheduling have been addressed. An Orchestra scheduling is proposed that allows
    each node in a wireless mesh network to schedule autonomously in [25]. It is a
    scheme for autonomous TSCH and RPL (Routing Protocol for Low power and Lossy Networks)
    [26], which constructs a graph based on link cost, node attributes, and status
    information. Each device schedules traffic classified as TSCH MAC, RPL routing,
    and application within a slotframe. The orchestra is low-overhead and flexible,
    but not compatible with other centralized approaches, and limited in real-time
    support as all devices use the same length slotframe. [27] proposed a distributed
    solution in which field devices autonomously schedule. Each node maintains a Ranked
    routing table between parent-child nodes by calculating a cost function called
    ETX (Expected Transmission Count) based on (Received Signal Strength). Based on
    the routing graph, three types of slotframes are generated: synchronization, routing,
    and application, similar to [25], and then combine into a single schedule. Conflicting
    slots are admitted by priority. Though this work has the advantage of flexibility,
    it remains limited in real-time and reliability due to collision and not considering
    multichannel. In DistributedHART [28], real-time scheduling at the local level
    is proposed to improve the high overhead and resource waste of centralized WirelessHART.
    Based on the conflict-avoiding graph route in [29], each device generates an EDF
    (Earliest Deadline First) based Time-Window schedule. Although it reduces resource
    waste and provides scalability through dynamic scheduling, there are limitations
    such as high collision probability when the flow is heavy and hard to integrate
    with traditional WirelessHART networks. WirelessHART-based IWN studies have shown
    that a centralized NM can design optimal routing and scheduling based on devices’
    information to support the reliability and real-time. Distributed methods are
    being studied to improve network scalability, resource efficiency, and energy
    consumption, but they have a trade-off in terms of performance such as reliability
    and delay due to compatibility with existing systems and collision problems. In
    this study, we propose a RSP-based resource allocation scheme that supports application
    requirements while considering compatibility with existing IWNs to mitigate the
    issues including resource efficiency, network scalability, and energy efficiency
    due to high redundancy policy. SECTION III. Proposed Scheme In this section, we
    introduce the concept of a specific communication path, defined as a resource
    sharing path (RSP), for sections where data flows are frequently overlapped considering
    the industrial monitoring application of WirelessHART network. Based on RSP, we
    propose a highly efficient resource allocation scheme that allows each data flows
    to share the allocated resources in consideration of network stability when scheduling.
    A. RSP: Resource Sharing Path The network manager (NM) of WirelessHART plays a
    key role in configuring the routing path of the network and organizing the communication
    schedule based on the routes. The industrial process information sensed by each
    field device is collected through a mesh network topology to the gateway device
    as a sink where the network manager (NM) is located, as shown in Figure 1. The
    network manager analyzes the collected information based on the plant backbone,
    including controllers and application hosts, to process the automation process.
    The industrial data generated by each device at periodic cycles have an End-to-End
    data flow that is delivered to the destination device based on the routing path
    and communication schedule initially set by the NM. Each data flow has its own
    routing path, and overlap may occur in some sections. In particular, the denser
    the devices are or the closer they are to the gateway, the more frequently overlap,
    resulting in the hot-spot problem, as shown in the example. It makes it hard to
    support performance including scalability, and real-time of the WirelessHART network
    using a schedule-based communication approach. FIGURE 1. Example of Data Flows
    in WirelessHART Network including Hot-spot. Show All To handle this issue, sections
    in the traditional End-to- End path of each data flow, where path overlapping
    occurs frequently are designated as RSPs. In these sections, the redundant resources
    (e.g. retransmission, backup paths) are hierarchically divided into general paths
    and RSPs so that each data flow can share and utilize them. Figure 2 shows a simplified
    example of how data collected from different devices are forwarded and scheduled
    to the destination gateway in the conventional and proposed approaches. FIGURE
    2. A Simple Example of RSP-based Scheduling. Show All The data collected from
    each A, B, and C device is forwarded in the path set by NM (Flow 1: A→D→G , Flow
    2: B→D→G , Flow 3: C→D→G ) as shown in Figure 2(a). In this case, each data flow
    is scheduled for communication through a fixed resource allocation in a superframe,
    which is divided into time slots and channel offsets based on paths. Each data
    flow in the example has a link with an overlapping path D→G . In conventional
    scheduling, each data flow is scheduled by allocating time slots for retransmission
    in consideration of failed transmissions based on paths, without considering overlapping
    paths. As shown in Figure 2(b), at the time of TS 6, device D schedules transmission
    on TS 6 (Primary) and TS 7 (Retry) for Flow 1 on the path to G. Flow 2 schedules
    transmission on TS 8 ∼ 9, and Flow 3 schedules transmission on TS 10 ∼ 11, respectively.
    When such scheduling is repeated, the redundant resources allocated for retry
    are not utilized if each data flow is sent without error on the primary link.
    Though not shown in the example, if the redundancy resources allocated for the
    backup path are also considered, the unutilized resources will be much increased.
    In the proposed scheme, the Section where the transmission path of different data
    flows overlaps is designated as a RSP and each data flow in the RSP shares and
    utilizes the allocated communication resources. In other words, instead of transmitting/receiving
    only at fixed time slots and channel offsets for each data flow, it shares the
    allocated communication resources for each data flow in the RSP Section where
    many overlaps occur. In the scheduling example in Figure 2(c), device D transmits
    the data of flows 1 ∼ 3 stored in the general path schedule at TS 6 in order from
    TS 6 ∼ 8, and if any data transmission failure occurs, retransmission is performed
    within TS 9 ∼ 11. Since there is less error when the network is stable, the schedule
    period can be reduced by not allocating some of the TS 9 ∼ 11 that were allocated
    for redundancy, or resources can be allocated for additional data flows to achieve
    gains in terms of real-time and scalability. B. Delegated Intelligent Router for
    RSP-Based Scheduling The devices that form a WirelessHART network have routing
    capabilities that enable them to contribute to the formation and maintenance of
    the network. In general, since all network devices support routing functions,
    a separate router may not be required, but deploying an additional router has
    the advantage of improving performance in terms of network expansion and device
    power efficiency. Therefore, WirelessHART defines a router component with a simple
    forwarding role. For scheduling communication in RSP, the proposed scheme defines
    a Delegated Intelligent Router (DIR) device that dynamically schedules packets
    to be transmitted based on the existing allocated communication resources of field
    devices or existing router devices in the corresponding section. Devices operating
    as a DIR perform local scheduling so that packets of each data flow are transmitted/received
    in order of short deadline within the allocated time slots in the superframe.
    In the current centralized scheduling approach of WirelessHART, the NM designates
    transmissions/receptions within fixedly allocated slots. For example, as shown
    in Figure 3, packets of process data type stored in the buffer of the sender in
    the order of T1 ∼ T4 are transmitted to the receiver in a fixedly allocated slot
    for transmission of each packet (D1: TS4, D2: TS0, D3: TS2, D4: TS6). In addition,
    retransmission of each packet is considered and retried in case of failure in
    the allocated slot (D4: TS7). FIGURE 3. RSP Scheduling in DIR based on WirelessHART
    Protocol Stack. Show All In the proposed scheme, the device in the RSP path (DIR)
    manages the buffer with a deadline Priority-based Round Robin (PRR) scheduling
    scheme [30] for stored packets. The allocated slots are shared and data flows
    using the same link try to transmit in the buffer order (D1: TS0, D2: TS1, D3:
    TS2, D4: TS3). In this case, if there is a transmission error, the packet is retried
    through the remaining shared slots (D4: TS5). By applying the proposed method,
    it is possible to statistically reduce the remaining unused shared slots and reschedule
    them to shorter interval superframes, instead of transmitting packets only in
    fixedly allocated slots per data flow, thus providing real-time process application.
    In addition, it can be utilized to schedule additional data flows, providing flexible
    scalability. The operation of DIR is based on the table information of the Network
    Layer and Data link layer, where the routing and scheduling functions are performed
    by referring to the WirelessHART protocol stack as shown in the lower part of
    Figure 3. The network manager disseminates routing and scheduling information
    of each data flow to related devices when designing a network in consideration
    of application requirements. Network devices maintain route table, graph table,
    neighbor table, superframe table, and link table containing such information.
    Devices within the RSP selected according to link redundancy operate as DIR, synthesize
    information from various tables, and apply scheduling to share allocated resources
    for data flows in the corresponding section. C. RSP-Based Scheduling with Hierarchical
    Graph Route The central NM periodically receives and lists information such as
    received signal level (RSL) and neighboring nodes from all network devices, and
    creates a network graph based on them. The Graph route corresponding to each data
    flow has a unique Graph_ID and consists of a primary path and a back-up path to
    provide path redundancy in case of path failure. Each device checks the Graph_ID
    and neighbor information set in the graph table to provide reliable transmission
    through graph routing to the destination. In the proposed scheme, graph routing
    is also considered, but the Section where some paths of data flows with different
    Graph_IDs overlap is set as a resource sharing path (RSP), and in this section,
    hierarchical graph routing that distinguishes the RSP and normal path is applied
    to efficiently schedule up-link communication in terms of resource utilization.
    RSP is configured in the form of a single link or graph route in consideration
    of the number of data flows (traffic) passing through the Section where overlap
    occurs. At this time, a Section in which the number of different data flows passing
    through the total traffic exceeds a certain threshold is set as RSP. This is in
    consideration of the constraint that the communication of process data should
    not exceed 30% of the bandwidth according to the WirelessHART standard, and considering
    the possibility of network performance degradation due to increased network congestion
    if the number of slots is exceeded. In addition, since the path established by
    RSP must be reliable enough to communicate by sharing resources, the RSP path
    is maintained by utilizing the network’s path reliability, which is calculated
    in the resource allocation procedure described later (Section III-D). The devices
    in the RSP are defined as Delegated Intelligent Routers (DIRs), which operate
    to communicate based on a superframe schedule that shares the allocated resources,
    and transmit/receive buffered packets in slots shared through RSP-based schedule,
    rather than transmitting only a specified data flow in fixed slots. Figure 4 illustrates
    an example of the proposed superframe scheduling based on hierarchical graph routes
    with RSP compared to the typical WirelessHART scheduling. Figure 4(a) is a wireless
    mesh type network topology consisting of an Access Point (AP) device connected
    to a gateway and field devices ( A∼G ) for industrial monitoring (Uplink) with
    the AP as the destination. Devices D, F, and G are the source nodes of data flows
    (f1 ∼ f3) and use the initial graph route created by the NM to transmit the collected
    data to the destination AP. At this time, the traditional WirelessHART configures
    a primary path and a backup path to provide path redundancy. In WirelessHART,
    primary and alternate paths are configured to provide path redundancy, and even
    data flows using some of the same paths can have different Graph_IDs. In other
    words, the End-to-End graph route of D→ AP has some of the same paths as the graph
    routes of F→ AP and G→ AP ( D→A→ AP, D→B→ AP), but the Graph_IDs are different.
    This means that the D→ AP Section overlaps with some routes used by different
    data flows. The superframe scheduling result considering retransmission and backup
    paths of typical WirelessHART is shown in Figure 4(b). For simplicity, this example
    schedules each End-to-End data flow within a single superframe, assuming all devices
    have the same scan rate. For each data flow, the dark-colored slots are reserved
    for the primary path and the light-colored slots are allocated for the backup
    path. In addition, retransmission slots are allocated for each data flow to account
    for failures, and packets are sent/received according to the fixed time slot and
    channel offset. FIGURE 4. Comparison of RSP-based Scheduling with Hierarchical
    Graph Route and Typical WirelessHART. Show All Figure 4(c) shows a proposed hierarchical
    graph route with RSP and the result of superframe scheduling based on it. Instead
    of establishing an End-to-End graph route from D, F, and G to the AP, the NM sets
    up a hierarchical routing path that is divided into an RSP graph route, which
    is the path where the overlap occurs, and a normal graph route before the overlap
    section. Devices A, B, and D in the RSP Section operate as DIRs. Each source device
    (D, F, G) performs normal transmissions to the RSP initiation point, and the RSP
    route is configured to share allocated resources with the DIR devices so that
    each data flow shares them. The scheduling for such routes is based on the premise
    of meeting the deadlines required by industrial applications, and resources are
    allocated first for the devices farthest from the AP. In other words, as shown
    in the figure, data flows heading to DIR are scheduled first based on D device
    (DIR) where RSP starts (TS0 ∼ TS7), and the DIR devices in the RSP utilize shared
    resources to transmit data stored in buffers. At the time of TS8, the data flows
    are different but the transmission paths used are the same, hence these paths
    are set to RSP. The DIRs in the RSP are operated to share the resources of TS8
    ∼ TS21 allocated for each data flow. As described above, the RSP-based schedule
    allows each data flow to share the allocated resources, but if the network is
    stable and error-free, there will be a lot of wasted resources that are not utilized
    for transmission. The following Section describes an efficient resource allocation
    scheme for RSP-based scheduling that considers this resource waste problem. D.
    Resource Allocation for RSP The proposed RSP-based scheduling allows devices to
    share resources for graph routes with overlapping data flows. Assuming no communication
    errors, the transmission of each data flow will be completed early, leaving the
    redundant resources allocated for retransmission and backup paths unutilized among
    the reserved resources in the superframe. But this is an extremely positive scenario
    and redundant resources still need to be allocated to cover failures. Therefore,
    a reasonable resource allocation strategy is needed to reduce the highly-occupied
    redundant resources and effectively utilize the allocated resources. Therefore,
    in this proposed scheme, the network reliability is calculated and the schedule
    is adjusted to reduce the redundant resources that will not be utilized in the
    RSP path. It aims to increase resource efficiency while maintaining reliability
    and improving real-time performance. To achieve these goals, the resource allocation
    procedure considering network reliability is as follows. 1) Link Reliability Each
    device maintains a probability of link reliability with its neighbors in a link
    table, as shown in Equation 1, and periodically shares this information with the
    NM. P v i represents the link reliability with neighbor node i associated with
    device v . When a transmission is successful over the link, Pv is incremented,
    and when it fails, it is aged to a default value of P init . P v i ={ P v i_old
    +(1−P v i_old )⋅ P init ,onsuccessfullink P v i_old ⋅ P init ,onlinkfailure, (1)
    View Source 2) RSP Reliability The NM periodically shares the link reliability
    probability of each link among devices and the graph route information used for
    data flows in the RSP with the DIR devices. The DIR device quantifies each path
    reliability probability in the graph table for each data flow within the RSP based
    on the link reliability probability. At this time, the data flow’s path reliability
    probability ( P F ) of the primary and backup paths is calculated as shown in
    Equation 2, considering graph routing. The RSP reliability probability for the
    RSP path ( P RSP )is finally derived using Equation 3. P F in Equations 2 and
    3 represents the probability of reliability for the path that the data flow traverses,
    respectively. P v primary_i in Equation 2 represents the reliability probability
    of link i in the primary path, and for each link, the product of the number of
    links k to the destination is used to calculate the reliability probability for
    the primary path in the graph route. Likewise, P v backup_i in Equation 3 represents
    the reliability probability of a link to calculate the reliability probability
    for the backup path. Then, using Equation 4, the P RSP is derived, which is the
    probability of reliability for the RSP route. P RSP is calculated by averaging
    the path reliability of the primary and backup paths in the RSP. P F_primar y
    n P F_backu p n P RS P n = ∏ i=1 k (1−(1−P v primary_i ) 2 ), = ∏ i=1 k (1−(1−P
    v backup_i ) 2 ), = P F_primar y n +∑ P F_backu p n NumberofTotalRouteinRSP ,
    (2) (3) (4) View Source 3) Reducing Allocated Resources If the computed RSP reliability
    probability is above a set value, the DIR device determines that the graph route
    is stable and applies scheduled communication within the RSP. At this time, the
    calculated RSP reliability probability is periodically feedback to the NM to reduce
    the allocated shared resources within the RSP as shown in Equation 5. SRO (Shared
    Resources Occupancy) represents the shared resource occupancy in the schedule,
    r( P RSP ) is the ratio to the reduction of shared resources based on P RSP ,
    and θ is the network reliability index. The indicator function determines a certain
    reliability probability range, and if RSP satisfies the reliability, the shared
    resources are reduced. SR O new =SR O old −r( P RS P n )⋅ 1 [ θ a , θ b ] ( P
    RS P n ),0<θ<1. (5) View Source Figure 5 shows RSP-based scheduling with improved
    resource utilization by considering network reliability. In this example, if the
    reliability probability value of the calculated RSP ( P RSP )is greater than or
    equal to 95% ([ θ a =95, θ b =∞ )), 30% ( r( P RSP ) )of resources are reduced;
    if it is between 85% and 95% ([ θ a =85, θ b =95 )), 20% are reduced; and if it
    is between 75% and 85% ([ θ a =75, θ b =85 )), 10% are reduced. Otherwise ([ θ
    a =0, θ b =75 )), no resource occupancy reduction is applied and feedback is given
    to the NM to allocate all redundancy resources as traditional. When the network
    is stable, slot allocations can be reduced by nearly 30% to support faster period
    schedules with fewer resources. FIGURE 5. RSP-Based Resource Efficient Superframe
    Schedule with Network Reliability. Show All Algorithms 1 and 2 show the hierarchical
    resource sharing path configuration and the resource allocation procedure based
    on it, considering the network context described above. Table 1 explains the notation
    used in them. Algorithm 1 Construction of Hierarchical Graph With RSP Input: graph
    G(V,E),F,R Output: Hierarchical graph route G ′ ( V ′ , E ′ ), F ′ , R ′ 1: //
    G(V,E) is the original graph 2: for each data flow f n ∈F do 3: // * Configure
    RSP routes 4: for each network device v i ∈V in graph G(V,E) do 5: for each link
    e i ∈V in graph G(V,E) do 6: e.numofFlows( v i , e i ) ; // Calculate overlap
    ratio (Traffic) 7: e.linkReliability( v i , e i ) ; // Calculate each links reliability
    8: if ( e.numofFlolws≥D F TH & e.linkReliability≥ P RSP ) then 9: add v i to RSP_
    V ′ ; add e i to RSP_ E ′ ; 10: else 11: RSP_ V ′ =RSP_ V ′ −{ v i } , RSP_ E
    ′ =RSP_ E ′ −{ e i } ; 12: end if 13: N_ V ′ =V−RSP_ V ′ , N_ E ′ =E−RSP_ E ′
    ; //Normal Paths 14: end for 15: end for 16: // * Construct Hierarchical Graph
    Route 17: for each network device v ′ i ∈RSP_ V ′ do 18: vDI R i ← v ′ i ; 19:
    V ′ =N_ V ′ ∪RSP_ V ′ ; 20: for each link e ′ i ∈RSP_ E ′ do 21: F ′ n =( f ′
    n−N ∪ f ′ n−RSP ) , π ′ n =( π ′ n−N ∪ π ′ n−RSP ) , 22: R ′ n ←{ π ′ 1 , π ′
    2 ,…, π ′ n } , E ′ =N_ E ′ ∪RSP_ E ′ ; 23: end for 24: G ′ ( V ′ , E ′ )←re_constructHierarchicalGraph(
    F ′ , R ′ ) ; 25: end for 26: end for 27: return G ′ ( V ′ , E ′ ) // Hierarchical
    network graph for RSP Algorithm 2 Reduction Resource Allocation With RSP Input:
    graph G ′ ( V ′ , E ′ ), F ′ , R ′ ,S Output: Resource reduced Schedule R S ′
    // Q is the Priority-based Round Robin (PRR) Queue 2: while Q is not empty do
    // * Applying the RSP-based superframe 4: for each data flow f ′ n ∈ F ′ do for
    all link e ′ i ∈ E ′ in graph G ′ ( V ′ , E ′ ) do 6: S ′ n ←S.scheduleLink(i,t
    s i , e ′ i , f ′ n , r n ) ; end for 8: for each network device v ′ i ∈ V ′ in
    graph G ′ ( V ′ , E ′ ) do P v i ←v.link_Reliability( e ′ i ) 10: for each graph
    route π ′ n ∈ R ′ do if ( v ′ i s_type==DIR ) then 12: P F n ←f.flow_Reliability(
    f ′ n , π ′ n ) ; P RS P n ←R.rsp_Reliability( P F n ) ; 14: end if end for 16:
    end for // * Reducing Shared Resource Occupancy (SRO) 18: if ( P RS P n ≥ P init
    ) then R S ′ n ←S.SRO( S ′ n ) ; 20: //(ex. reduce 10%, 20%, 30% depend on P RSP
    ) return R S ′ n ; 22: else return S ′ n ; 24: end if end for 26: end while As
    shown in Algorithm 1, the NM establishes the original network graph G(V,E) during
    the initial network configuration phase. As the network is operated, each device
    and NM computes the flow count and link reliability of each link in the original
    graph. With this information, if the number of data flows passing through the
    links of a particular graph increases above a specific value ( D F TH ), the reliability
    of that path is calculated together and selected as an RSP graph route ( RSP_
    V ′ ,RSP_ E ′ ). The final RSP graph route is composed of a hierarchical route
    graph ( G ′ ( V ′ , E ′ ) ), which is divided into RSP routes and normal routes
    ( N_ V ′ ,N_ E ′ ). At this time, each data flow ( F ′ n ) and the routes ( R
    ′ n ) that form the graph are also reconfigured to construct a hierarchical graph
    that includes RSP. Algorithm 2 shows a resource-efficient scheduling procedure
    based on RSP routes. The original superframes schedule ( S ) is updated based
    on RSP routes to allow each DIR device to share resources in the RSP section.
    At this time, each device and the DIR devices maintain network reliability values.
    To enable resource-efficient scheduling that reduces the initial fixed allocated
    resources, the unutilized allocated resources are reduced based on the calculated
    network reliability. Based on the schedule with reduced allocated resources (
    R S ′ ), each device utilizes the shared slots according to the queue scheduling
    policy instead of transmitting a defined data flow in a fixed allocated slot.
    The proposed scheme that improves resource utilization by considering network
    conditions enables scheduling with shorter periods that support data flow with
    lower latency. In addition, unallocated sets of time slots and channel offsets
    are available to support data flow from other devices. SECTION IV. Performance
    Evaluation The main focus of the proposed scheme is to efficiently allocate communication
    resources in the scheduling to reduce waste while effectively supporting the requirements
    of industrial applications. Therefore, we categorized the performance evaluation
    criteria of reliability, real-time, energy efficiency, scalability, and resource-efficiency
    required for industrial wireless networks. The performance evaluation is based
    on an environment where the topology shown on the right side of Figure 6 is expanded
    in consideration of the actual industrial process environment where field devices
    are connected in a wireless mesh network and periodically transmit process monitoring
    information to the gateway where the network manager is located. FIGURE 6. Example
    of Simulation Topology. Show All In order to evaluate the performance, the NS-3
    simulator [31] is used to build the network topology and set up the components
    used in the network and transmission as shown in Table 2. It is considered an
    environment where packets are transmitted from sensor nodes to a destination gateway,
    through a partial mesh network with a repeated topology. We examined the performance
    by varying the number of devices deployed in the network (default: 64) and the
    number of published data flows (default: 24). The reliability index, which represents
    the average reliability of an arbitrary link in the topology, is set to 75%, 85%,
    and 95%, with 10 iterations of evaluation. The superframe is set to 100 time slots
    and the number of available channel offsets is assumed 4. The duration of each
    time slot is set to 10 milliseconds as specified in the WirelessHART standard,
    and the power consumed in a time slot is calculated by separating the states of
    the device (transmit, receive, listen, idle). To calculate the path reliability
    of the proposed scheme, Pinit is set to 0.95. Since the proposed scheme is considering
    compatibility with the current WirelessHART network, the WirelessHART standard
    scheduling and a related study based on the standard, centralized Graph Route
    Based Superframe Scheduling (GBR) [23], were compared with the proposed scheme.
    TABLE 2 Simulation Environments First, we analyze the performance of the proposed
    scheme in terms of reliability of data transmission, real-time, and energy efficiency,
    which are the main requirements for industrial wireless networks. The data generated
    by the sensor devices must be successfully transmitted to the gateway where the
    network manager is located. At the same time, the real-time requirement should
    be satisfied by transmitting the data within the time limit specified by the application.
    In addition, efficient energy consumption is one of the important goals since
    the energy efficiency of battery-powered devices affects the network’s lifetime.
    Figure 7 shows the results of these network performance evaluations. FIGURE 7.
    Network performance for reliability, real-time, and energy efficiency. Show All
    Figure 7(a) shows the reliability evaluation result. Path reliability means the
    average success rate of packet delivery on each link when a superframe schedule
    is generated based on the graph route. By varying the average success rate of
    each link in the superframe to 75%, 85%, and 95%, we measured path reliability
    and found that the results were generally similar to the link status. Since the
    proposed scheme configures a hierarchical graph route and shares resources for
    each data flow in that section, it shows a relatively high level of path reliability
    by utilizing shared resources that enable failure resilience. Then, Figure 7(b)
    shows the Packet Delivery Rate (PDR) of the data from the source successfully
    arriving at the destination through the End-to-End path based on this path reliability
    variation. In typical WirelessHART and GBS, each data is attempted to be transmitted
    only on the link that is fixedly allocated within the superframe. Therefore, if
    the packet transmission fails in the slot timing for transmission, retransmission,
    and alternate route in one superframe cycle, the packet fails to reach the destination.
    However, in the proposed scheme, the resources for each data is shared, so even
    if a failure occurs, the delivery success rate is higher because the resources
    of the path defined by RSP are shared. The proposed scheme maintains the highest
    reliability even when the average link reliability is as low as 75%. GBS has a
    higher delivery success rate than typical WirelessHART because it allocates relatively
    more communication resources for hop-level retransmission, but it is still less
    reliable than the proposed scheme because it only transmits each data through
    fixedly allocated resources. Figure 7(c) shows the average delay for each data
    flow to reach its destination as link reliability is varied. Each data flow has
    a different number of hops in the End-to-End path, and the difference in latency
    is caused by the scheduling policy. The total latency of each scheduled data flow
    to reach the destination is the lowest in the proposed scheme. Unlike the fixed
    scheduling of each data flow in the current WirelessHART, the proposed scheme
    allows the resources in the RSP route to be shared and utilized through the DIR
    devices. Thus, the overall latency is reduced by utilizing shared resources based
    on network reliability and reducing the number of unutilized time-slots. In this
    way, the real-time requirements of the application are met within one cycle. GBS
    allocates additional resources at the hop-level, and like typical WirelessHART,
    the overall latency is high because each data flow is transmitted in a fixed allocated
    slot. Figure 7(d) and (e) show the network energy efficiency results with varying
    data flow and link reliability, respectively. Each device communicates by checking
    the link options (transmit, receive, listen, idle) assigned to it in the superframe.
    Generally, the energy consumption tends to increase as the number of data flows
    is higher. The proposed scheme shows a 25% reduction in energy consumption compared
    to GBS by reducing the number of resources allocated to a superframe when the
    network is stable, thereby reducing the power consumed in that slots. In addition,
    retries are caused by retransmissions and alternate routes according to the network
    status, so overall energy consumption is high, but the proposed scheme shows the
    lowest energy consumption by sharing and reducing the allocated communication
    resources. In the following, the network performance is evaluated in terms of
    resource efficiency (Figure 8) and scalability (Figure 9) in industrial wireless
    networks, which are the main issues that the proposed scheme aims to improve.
    The proposed scheme shares the resources allocated in the scheduling of RSP with
    overlapped paths of each data flows and reduces the resource adaptively based
    on the network reliability. FIGURE 8. Network Performance for Resource-efficiency.
    Show All FIGURE 9. Network Performance for Scalability. Show All Figure 8(a) shows
    the resource occupancy in a superframe as the reliability of the links varies.
    There is no change in resource occupancy in the scheduling of conventional approaches
    because they allocate fixed resources in a superframe regardless of the link status.
    The proposed scheme adaptively reduces the redundantly allocated resources when
    the link is relatively stable, resulting in a lower resource occupancy rate compared
    to other techniques. This shows that the proposed scheme has better resource utilization
    while maintaining high reliability. Figures 8(b) and (c) show the resource occupancy
    rate performances as the number of devices and data flows are varied, assuming
    that the network is stable with 95% reliability of the links. In all methods,
    the communication resources allocated in the superframe schedule tend to increase
    as the number of devices and data flows increases. GBS has the highest resource
    occupancy due to the redundant resource allocation for hop-level retransmission.
    The proposed scheme has lower resource occupancy ratio compared to other methods
    by reducing the number of fixed radio resources allocated for redundancy. This
    means that the adaptive resource allocation for RSP considering the network conditions
    enables to reduce the waste of radio resources that are unutilized for actual
    transmission. Figure 9(a) and (b) show the Schedulability performance results
    as a measure of network scalability. Schedulability refers to the ratio of data
    flows that can be scheduled within a superframe. We evaluated Schedulability performance
    as the number of devices in the network and the number of data flows varied, considering
    the average link status of the network to be 95% stable. All methods are able
    to schedule all data flows within a superframe up to 80 devices. However, GBS
    and conventional WirelessHART are unable to accommodate data flows from more devices
    than the proposed scheme. The proposed scheme can accommodate about 30% more data
    flows than the existing WirelessHART. Likewise, when comparing the schedulability
    according to the change in the number of data flows, the proposed method is able
    to schedule about 30% more data flows in a superframe than the comparison methods.
    The performance evaluation shows that the proposed scheme is able to effectively
    support the reliability, real-time, and energy efficiency requirements of industrial
    wireless networks while reducing the waste of unutilized communication resources
    in scheduling. In addition, the proposed scheme can support a higher level of
    network scalability by enabling resource allocation for additional data flows.
    SECTION V. Conclusion In this paper, we discussed industrial wireless networks,
    which are the foundation of Industrial IoT. In particular, we focused on WirelessHART,
    an industry standard that provides reliable and stable communication based on
    low-power operation, to effectively support industrial requirements. As WirelessHART
    is compatible with existing wired industrial systems and has high flexibility
    and market share, it has been evaluated as a feasible solution in practical factory
    automation environments and is applied broadly. However, The current high redundancy
    policy of WirelessHART scheduling, which fixedly allocates resources for retransmissions
    and alternate routes based on the routing graph without considering the network
    status, causes waste of unutilized resources and limits network performance such
    as energy efficiency, real-time, and especially scalability. In this paper, we
    defined a resource sharing path (RSP) as a region where some paths of different
    data flows overlap, and the resources allocated in the scheduling of this path
    can be shared. The centralized network manager configures schedules that adaptively
    reduce redundant allocated resources by reflecting path reliability for RSPs.
    Among the graph paths, the Delegated Intelligent Router (DIR) hierarchically separates
    resource-sharing paths and normal paths to implement RSP-based scheduling. The
    performance evaluation through simulation shows that the proposed scheme reduces
    the resource occupancy by about 20% to 30% while maintaining reliability compared
    to the existing methods. In terms of energy efficiency, it consumes up to 25%
    less energy than others, and in terms of real-time, it has the lowest total latency
    for each data flow to be transmitted within the schedule. It also has the schedulability
    to accommodate a larger number of devices and data flows than typical WirelessHART.
    These results imply that the proposed approach can be applied in industrial IoT
    to support networks with a wider range of massive industrial equipment, or to
    enable process monitoring with shorter cycle times. Consequently, the RSP-based
    resource-efficient scheduling scheme is able to improve the real-time, scalability,
    and energy-efficiency performance while maintaining a high level of reliability.
    In future work, we extend this work to consider scheduling optimization that could
    reliably support industrial wireless networks with deployed mobile devices. Authors
    Figures References Keywords Metrics More Like This A Cascading Redundancy Approach
    for Dependable Real-Time Systems 2009 15th IEEE International Conference on Embedded
    and Real-Time Computing Systems and Applications Published: 2009 Compositional
    Verification for Hierarchical Scheduling of Real-Time Systems IEEE Transactions
    on Software Engineering Published: 2013 Show More IEEE Personal Account CHANGE
    USERNAME/PASSWORD Purchase Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile
    Information COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION TECHNICAL INTERESTS
    Need Help? US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT
    Follow About IEEE Xplore | Contact Us | Help | Accessibility | Terms of Use |
    Nondiscrimination Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy Policy
    A not-for-profit organization, IEEE is the world''s largest technical professional
    organization dedicated to advancing technology for the benefit of humanity. ©
    Copyright 2024 IEEE - All rights reserved."'
  inline_citation: '>'
  journal: IEEE Access
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: High-Efficiency Resource Allocation Scheme Introducing the Concept of Resource
    Sharing Paths in Industrial IoT
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Kabir F.
  - Megías D.
  - Araghi T.K.
  citation_count: '0'
  description: As the world is embracing the new era of smart technologies and the
    development of IoT equipment, such as smart grid and metering systems, a significant
    concern related to the privacy and security of user’s confidential information
    is forming rapidly. Many of the existing solutions are still suffering from plenty
    of time and power consumption, and security vulnerabilities. Secure data aggregation
    in smart metering systems is still a challenging task due to a plethora of attainable
    cyber and physical attacks. This paper presents the novel WaterCrypt technique
    based on reversible watermarking and Paillier encryption that significantly reduces
    the battery consumption of resource constrained smart meters by introducing a
    unique Encryption Server as well as making use of the homomorphic encryption properties
    to secure real time data transmission. In addition, the reversible watermarking
    technique used in the protocol guarantees the integrity and authenticity of data.
    The experimental results show that the proposed scheme offers a privacy friendly,
    secure data transmission and aggregation solution in smart metering systems in
    a cost effective manner.
  doi: 10.1007/978-981-19-9331-2_47
  full_citation: '>'
  full_text: '>

    "Your privacy, your choice We use essential cookies to make sure the site can
    function. We also use optional cookies for advertising, personalisation of content,
    usage analysis, and social media. By accepting optional cookies, you consent to
    the processing of your personal data - including transfers to third parties. Some
    third parties are outside of the European Economic Area, with varying standards
    of data protection. See our privacy policy for more information on the use of
    your personal data. Manage preferences for further information and to change your
    choices. Accept all cookies Skip to main content Advertisement Log in Find a journal
    Publish with us Track your research Search Cart Proceedings of International Conference
    on Information Technology and Applications pp 547–556Cite as Home Proceedings
    of International Conference on Information Technology and Applications Conference
    paper WaterCrypt: Joint Watermarking and Encryption Scheme for Secure Privacy-Preserving
    Data Aggregation in Smart Metering Systems Farzana Kabir, David Megías & Tanya
    Koohpayeh Araghi  Conference paper First Online: 19 May 2023 252 Accesses Part
    of the book series: Lecture Notes in Networks and Systems ((LNNS,volume 614))
    Abstract As the world is embracing the new era of smart technologies and the development
    of IoT equipment, such as smart grid and metering systems, a significant concern
    related to the privacy and security of user’s confidential information is forming
    rapidly. Many of the existing solutions are still suffering from plenty of time
    and power consumption, and security vulnerabilities. Secure data aggregation in
    smart metering systems is still a challenging task due to a plethora of attainable
    cyber and physical attacks. This paper presents the novel WaterCrypt technique
    based on reversible watermarking and Paillier encryption that significantly reduces
    the battery consumption of resource constrained smart meters by introducing a
    unique Encryption Server as well as making use of the homomorphic encryption properties
    to secure real time data transmission. In addition, the reversible watermarking
    technique used in the protocol guarantees the integrity and authenticity of data.
    The experimental results show that the proposed scheme offers a privacy friendly,
    secure data transmission and aggregation solution in smart metering systems in
    a cost effective manner. Keywords IoT Smart home Smart meter Paillier cryptography
    Reversible watermarking Data aggregation Access provided by University of Nebraska-Lincoln.
    Download conference paper PDF 1 Introduction A smart meter is automated equipment
    installed in smart home for calculating the energy consumption of various commodities
    such as gas, water, and electricity [12]. It receives pricing information and
    load forecasting from the utility company while displaying all the information
    in the in-home-display (IHD) [1]. A smart metering system can be defined as the
    infrastructure between smart meters and different remote entities such as users,
    utility service providers, and data aggregators, taking advantage of different
    communication technologies like ZigBee or Wi-Fi [2, 10], as shown in Fig. 1. Metering
    data is collected from each smart meter very frequently and aggregated before
    being sent to the service provider/control center. Data exchange between endpoints
    is vulnerable to security and safety threats, as well as the risk of malicious
    attacks. Data can be transferred from the smart home appliances to the SM using
    the home area network and to the utility center through a wide area network. A
    large amount of information generated by SMs provides the opportunity for service
    providers to monitor and control power utilities in a real time manner [7]. Fig.
    1 Smart metering system Full size image Illegally compromising a smart meter can
    cause a huge financial or personal damaging effect [9]. To deal with all possible
    threats related to smart metering systems, several security technologies and different
    privacy preserving schemes are being developed. However, due to the limitation
    of computing power of smart meters, cryptographic algorithms, such as Homomorphic
    Encryption (HE) are unable to execute heavy computational tasks. Data hiding methods,
    like digital watermarking, ensure the integrity and authenticity of the content
    with lightweight computational operations. Watermarking-based aggregation schemes,
    on the other hand, cannot provide a high level of security and are vulnerable
    to various attacks [5]. Considering the limitations of existing watermarking and
    cryptographic schemes, we present a novel P2DA scheme, WaterCrypt, to mitigate
    the risk of confidential information leakage based on reversible digital watermarking
    and Paillier homomorphic encryption. In the proposed scheme, a unique encryption
    server has been introduced in order to perform HE and preserve data confidentiality
    against security breaches to reduce energy consumption in smart meters. The rest
    of the paper is organized as follows. Sections 2 and 3 are assigned to related
    works and the overview of the proposed scheme respectively. System performance
    evaluation and experimental results are described in Sect. 4. Finally, the conclusion
    and future work are discussed in Sect. 5. 2 Related Works This section is aimed
    to provide a general overview of the smart meter security measures, existing issues,
    possible attacks, and some approaches proposed to face the challenges in this
    area. In 2021, Mohammadali and Haghighi [8] proposed a novel homomorphic privacy
    preserving protocol (called NHP3) for data aggregation to support multi category
    aggregations. It supports batch verifications as well as multi-dimensional aggregations
    where the Paillier cryptosystem is used. This scheme is focused on cyber-attacks,
    but possible physical attacks are not investigated by the authors. Also, applying
    Paillier encryption in smart meters may cause computational complexity. In 2022,
    Yang Ming et al. [6] proposed a P2DA scheme that applies lightweight symmetric
    homomorphic technology and elliptic curve signature to accomplish efficiency.
    It resists common attacks, such as: collision, modification, and replay attacks.
    However, different physical attacks were not proven to be fully prevented. In
    2017, Ni et al. [10] introduced a new security model to formally define the misbehavior
    of hacked collectors and proposed a P2DA scheme to achieve end-to-end security
    and high efficient communication in smart grids using HE. In their proposal, the
    authors have not considered an operation center to detect dishonest behaviors
    which is necessary for a strong privacy-preserving protocol. Chen and Xiong [3]
    proposed a privacy protection method for WSN using wavelet dual watermarking to
    prevent tampering or packet loss and significantly provide data integrity in SMs.
    Since the proposed scheme uses two different watermarking techniques simultaneously,
    time delay and cost effectiveness need to be further analyzed. Recently, in 2022,
    Wang et al. [13] proposed the idea of combining digital watermarking and asymmetric
    encryption for a privacy preserving scheme in smart grids. The sensitive data
    is encrypted using the public key and is hidden in the collected readings using
    digital watermarks. The proposed method ensures secure end-to-end confidentiality.
    However, in their scheme, the data are distorted, since the watermarking scheme
    is not reversible. 3 Overview of the Proposed Scheme 3.1 System Model In the proposed
    scheme, a residential area with multiple smart homes is considered, where multiple
    SMs are used. The usage data is recorded in the SMs periodically. The entire system
    consists of four entities: (1) Smart Meters (SMs), (2) Encryption server (ES),
    (3) Data Aggregator (DA), and (4) Control Center (CC). SM is responsible for embedding
    the watermark in the original data and sending to the ES. ES encrypts the watermarked
    data and sends it back to SM. Before sending the data to DA, SMs preprocess it
    (e.g. pseudorandom number-based encryption). After receiving data from all the
    SMs, DA aggregates the watermarked encrypted data and sends it to CC eventually.
    CC decrypts and extracts the total consumption data after verification and stores
    it for future analysis. 3.2 Threat Model An attacker can be an internal or external
    entity [8]. An attacker can try to gain unauthorized access to SM data for various
    dishonest purposes. We denote the attacker as \\(A\\), where he/she may attempt
    the following attacks: Eavesdropping: \\(A\\) can eavesdrop on the transmission
    channel between the system entities to access daily lifestyle and behavior of
    the user for crime purposes. Man-in-the middle attack (MitM): \\(A\\) can intercept
    the messages sent between the system entities to retrieve, discard, or modify
    the SM data. Replay attack: \\(A\\) can perform replay attacks on the network
    to resend, replay or delay an SM’s report maliciously. Masquerading attack: An
    external \\(A\\) can pretend to be an internal entity to gain unauthorized access
    to the system data. Impersonation: \\(A\\) may impersonate one or a group of SMs
    to send fake data on behalf of non-compromised SMs to the CC. False data injection
    (FDI): There might be physical attacks with the purpose of inserting a malicious
    node or injecting malicious codes for compromising the SM. 3.3 Proposed Scheme
    The proposed scheme consists of several parts which take place in the four components
    of the system model. 3.3.1 Initialization It is assumed that the entire residential
    area has n SMs. The number of SM (n) is assumed to be odd. If n is not odd, it
    is always possible to break it into two odd numbers. The reason behind considering
    n to be odd is explained further, at the end of this section. Considering m time
    frames, each smart meter (SMi) generates data, dij at each time period tj, where
    i = 1, 2, 3 ... n and j = 1, 2, 3, ..., m. In the proposed scheme, we consider
    the data consumption to be generated every half an hour (30 min). At each tj,
    each SM generates three pseudorandom numbers using three different seeds called
    Seedi1, Seedi2, and Seedi3. These pseudorandom numbers are denoted as Rij1, Rij2,
    and Rij3, respectively. We employ a pseudorandom number generator (PRNG) to generate
    them using a key (Kr). SM shares Rij1, Rij2, and Rij3 only with ES, DA and CC
    respectively. CC generates a public and private key pair (PK, SK) for Paillier
    encryption and decryption [11]. SK is completely unknown to any other entities
    but CC. The watermark W is generated based on a cryptographic hash function, more
    precisely the Secure Hash Algorithm-2 (SHA-2). This HASH function uses a secret
    key (Kw) generated by SM and the timestamp, tj as: Hj ← HASH (Kw, tj). The watermark
    is generated using the following formula: W = H1 ⊕ H2 ⊕ H3 ⊕ …. ⊕ Hm, where W
    is converted to binary, and m bits of the binary watermark (Wj) are used for embedding
    into the SM data in m time-frames. 3.3.2 Protocol Phases The WaterCrypt protocol
    consists of five phases that take place in the different entities of the system.
    The framework is as shown in Fig. 2. Fig. 2 Protocol of the WaterCrypt scheme
    Full size image Phase 1 in SM: The least significant bit (LSB) is used for embedding
    one bit of the watermark to the original data generated at each SMi. We obtain
    the watermarked data d''ij by multiplying di with 2, and then adding Wj to the
    LSB bit. A pseudorandom number, Rij3, is added to d′ij and then Rij1 encrypts
    data using XOR. SM sends the watermarked encrypted data, Eij to the ES. Phase
    2 in ES: ES decrypts Eij using Rij1. Then it generates the cipher text Pij by
    applying the Paillier encryption. For secure communication, Rij1 is again encrypted
    to Pij using XOR. ES sends back the result P′ij to the SM. Phase 3 in SM: SM performs
    an XOR operation using Rij1 to decrypt the data and obtain Pij. Finally, it encrypts
    Pij again using Rij2 before sending it to DA. Phase 4 in DA: DA receives the watermarked
    encrypted data, P′ij from all the n SMs and performs the decryption using Rij2.
    Then it aggregates all P′′ij together using a simple addition in the encrypted
    domain. This aggregated data Qj (∑P′′ij) is transferred to the CC. Phase 5 in
    CC: CC decrypts Qj using the private key (SK) for obtaining Vj (∑d′′ij). CC then
    subtracts ∑Rij3 from Vj to obtain V′j (∑d′ij). The watermark is then validated
    by comparing the LSB of V′j and Wj. If they are not equal, it is assumed that
    the data was tampered and is declined immediately. If the LSB is correct, CC extracts
    the watermark and retrieves the sum of real usage data, Dj (∑dij). Note that the
    LSB of the d′ij after data embedding is equal to Wj. Therefore, d′i is even if
    the Wj = 0 and odd if Wj = 1. When aggregating n different d′ij, if all of them
    are odd, and n is also odd, the final result will be odd as well. If Wj = 0, all
    d′ij are even and the sum d′ij will also be even. Hence, the LSB of the aggregated
    data will be equal to the watermark bit as long as n is odd. Therefore, without
    loss of generality, we assume that either n is odd, or we split the SMs into two
    groups with an odd number Footnote 1 of SMs. 4 Experimental Results and Performance
    Evaluation We assess the performance of the proposed WaterCrypt scheme by calculating
    the total computational cost of the initialization process and the time of data
    processing at each phase described in Sect. 3. 4.1 Computational Time For this
    experiment, we have used real data sets of energy consumption readings for a sample
    of 5,567 London households that took part in the UK Power Networks led Low Carbon
    London project in 2014 [4]. The experiments have been carried out on the platform
    11th Gen Intel(R) Core(TM) i3-1125G4 @ 2.00 GHz running Microsoft Windows 10 Pro
    with 8 GB of memory. The Python language is used for the programming. For Paillier
    cryptography, we have used the built-in library python-Paillier (phe 1.5.0). Table
    1 shows the computational times of various phases for each timestamp. It can be
    clearly seen that, even though, the initialization is a little bit longer, the
    operations in various phases are very fast. The overall computational overhead
    is significantly lower in our scheme comparing with other existing schemes. In
    addition, WaterCrypt outperforms the existing works in terms of accuracy. Due
    to the use of reversible watermarking, the summation of the energy consumption
    data of an area is achieved accurately at CC. Table 1 Computational time of different
    phases Full size table Comparing the proposed WaterCrypt scheme with Wang’s joint
    scheme [13], WaterCrypt clearly shows better performance in terms of availability
    of data by using reversible watermarking. The issue of the resource limitation
    of SM devices is also resolved by employing an encryption server. In [13], the
    authors used direct watermarking, which led the scheme to have data distortion,
    whereas the proposed reversible watermarking scheme shows no distortion at all.
    4.2 Security and Privacy Analysis In the proposed protocol, the SM embeds the
    watermark and, later on, encrypts it using a pseudorandom number to maintain proper
    confidentiality. ES cannot retrieve the watermarked data as it does not have access
    to Rij3. The DA does not have access to the private key (PK) and neither to Rij3.
    CC has no access to an individual user’s fine grained data. To ensure the integrity
    of the user data, we use reversible watermarking, which can successfully recover
    the original data. The watermarked data in encrypted, so that the original data
    cannot be manipulated by the adversary, not even by a compromised ES, DA or CC.
    The seeds are different for all SM, which acts as an authentication parameter
    of each SM to make it easy to verify the authenticity of data at every phase.
    The user identity remains absolutely anonymous since all the data for all users
    is undetectable. Therefore, an attacker will not be able to determine any information
    about the user behavior or life style. Table 2 shows the comparison of our proposed
    protocol with other related work in terms of security and privacy. Table 2 Security
    and privacy comparison Full size table 4.3 Comparative Threat Analysis As shown
    in Table 3, all the six types of attacks mentioned in Sect. 3.2 are prevented
    by the proposed WaterCrypt scheme. Comparing it with the related works mentioned
    in Sect. 2, it can be clearly seen that WaterCrypt is superior in terms of attack
    detection and prevention. Table 3 Threat analysis Full size table Since data is
    encrypted with pseudorandom numbers, an eavesdropper would never access the plaintext
    data. In the proposed protocol, the timestamp prevents replay attacks, since the
    pseudorandom numbers Rij3 change every timestamp. This means that the decryption
    of replayed data will be wrong and the decrypted data will typically have an impossible
    value. Masquerading is also prevented in the proposed scheme, since data in every
    communication channel is encrypted with different seeds. Only the sender and receiver
    have the right seeds for decrypting real data. If an attacker tries to send fake
    data on behalf of an internal entity, the pseudorandom number must be used and
    the watermark bit must be verified. Man-in-the-middle attacks can be detectable
    and avoided by preventing the access of the attacker to the private key of CC
    and the related seeds to encrypt plaintext data in each path. Furthermore, the
    proposed scheme adds an extra degree of protection by watermarking the data while
    transferring them to prevent false data injection attacks. As it can be seen,
    the proposed scheme can countermeasure all the threats mentioned in Table 3, while
    in Wang et al. [13] model can only resist the eavesdropping (E) and Replay (R)
    attacks. Mohammadali et al. [8] countermeasures E and I, while Ni et al.‘s model
    [10] is robust against E and R. In Ming et al. [6], also just MitM and R can be
    prevented, but the proposed scheme is robust against all investigated threats
    mentioned in Table 3. This specification, in addition to speed and accuracy of
    the proposed scheme, makes it a good candidate to be replaced with all related
    works mentioned in Table 3. 5 Conclusion and Future Work This paper presents the
    novel WaterCrypt scheme for privacy preserving data aggregation based on reversible
    watermarking and Paillier encryption. An LSB-based reversible watermarking approach
    is used to preserve the integrity of the user fine grained data. Considering that
    HE can provide well-grounded security to the data in one hand, and the limited
    computational capability of SMs on the other hand, we introduced another entity
    in the system: encryption server. As a substitution of digital signatures for
    authentication, simple PRNG is employed to make the protocol more lightweight.
    The WaterCrypt protocol provably protects the system from various attacks such
    as eavesdropping, replay, man-in-the-middle, impersonation, and masquerading.
    Physical attacks like false data injection are also taken into consideration.
    Moreover, the computational time is significantly small. Using reversible watermarking,
    the WaterCrypt protocol performs better than other recent P2DA schemes. After
    analyzing the security and privacy requirements and evaluating performance, it
    can be concluded that we have successfully implemented a suitable and secure P2DA
    scheme for resource-constrained smart metering systems. For future work, the focus
    will be on high frequency smart meters where the usage data are generated very
    frequently (e.g., every few seconds or once a minute). We aim to employ reversible
    watermarking using difference expansion for this kind of smart metering systems.
    Notes 1. It is always possible to write an even n as the sum of two odd numbers,
    e.g. n = 41 + 41, or n = 100 = 51 + 49. References Asghar MR, Dán G, Miorandi
    D, Chlamtac I (2017) Smart meter data privacy: a survey. IEEE Commun Surv Tutor
    19(4):2820–2835 Article   Google Scholar   Burunkaya M, Pars T (2017) A smart
    meter design and implementation using ZigBee based wireless sensor network in
    smart grid. In: Paper presented at the 2017 4th international conference on electrical
    and electronic engineering (ICEEE), pp 158–162 Google Scholar   Chen Q, Xiong
    M (2016) Dual watermarking based on wavelet transform for data protection in smart
    grid. In: Paper presented at the 2016 3rd international conference on information
    science and control engineering (ICISCE), pp 1313–1316 Google Scholar   DataStore
    L (2018) Smartmeter energy consumption data in london households Google Scholar   Kabir
    F, Qureshi A, Megıas D (2021) A study on privacy-preserving data aggregation techniques
    for secure smart metering system Google Scholar   Ming Y, Li Y, Zhao Y, Yang P
    (2022) Efficient privacy-preserving data aggregation scheme with fault tolerance
    in smart grid. Secur Commun Netw Google Scholar   Moghaddass R, Wang J (2017)
    A hierarchical framework for smart grid anomaly detection using large-scale smart
    meter data. IEEE Trans Smart Grid 9(6):5820–5830 Article   Google Scholar   Mohammadali
    A, Haghighi MS (2021) A privacy-preserving homomorphic scheme with multiple dimensions
    and fault tolerance for metering data aggregation in smart grid. IEEE Trans Smart
    Grid 12(6):5212–5220 Article   Google Scholar   Nateghizad M, Erkin Z, Lagendijk
    RL (2016) An efficient privacy-preserving comparison protocol in smart metering
    systems. EURASIP J Inf Secur 2016(1):1–8 Google Scholar   Ni J, Zhang K, Lin X,
    Shen XS (2017) Balancing security and efficiency for smart metering against misbehaving
    collectors. IEEE Trans Smart Grid 10(2):1225–1236 Article   Google Scholar   Paillier
    P (1999) Public-key cryptosystems based on composite degree residuosity classes.
    In: Paper presented at the international conference on the theory and applications
    of cryptographic techniques, pp 223–238 Google Scholar   Sun Y, Lampe L, Wong
    VW (2017) Smart meter privacy: exploiting the potential of household energy storage
    units. IEEE Internet Things J 5(1):69–78 Article   Google Scholar   Wang S-X,
    Chen H-W, Zhao Q-Y, Guo L-Y, Deng X-Y, Si W-G et al (2022) Preserving scheme for
    user’s confidential information in smart grid based on digital watermark and asymmetric
    encryption. J Central South Univ 29(2):726–740 Article   Google Scholar   Download
    references Acknowledgements The authors acknowledge the funding obtained by the
    RTI2018-095094-B-C22 “CONSENT” and PID2021-125962OB-C31 “SECURING” projects granted
    by the Spanish Ministry of Science and Innovation. The first author also acknowledges
    the predoctoral grant PRE2019-091465 by the Spanish Ministry of Science and Innovation.
    Author information Authors and Affiliations Internet Interdiscipinary Institute
    (IN3), Center for Cybersecurity Research of Catalonia (CYBERCAT), Universitat
    Oberta de Catalunya, Rambla del Poblenou, 154, 08018, Barcelona, Spain Farzana
    Kabir, David Megías & Tanya Koohpayeh Araghi Corresponding author Correspondence
    to Farzana Kabir . Editor information Editors and Affiliations Institute of Management
    Sciences, Peshawar, Pakistan Sajid Anwar School of Mathematical and Computer Science,
    Heriot-Watt University, Dubai, United Arab Emirates Abrar Ullah University of
    Lisbon, Lisbon, Portugal Álvaro Rocha University Institute of Lisbon (ISCTE),
    Lisbon, Portugal Maria José Sousa Rights and permissions Reprints and permissions
    Copyright information © 2023 The Author(s), under exclusive license to Springer
    Nature Singapore Pte Ltd. About this paper Cite this paper Kabir, F., Megías,
    D., Araghi, T.K. (2023). WaterCrypt: Joint Watermarking and Encryption Scheme
    for Secure Privacy-Preserving Data Aggregation in Smart Metering Systems. In:
    Anwar, S., Ullah, A., Rocha, Á., Sousa, M.J. (eds) Proceedings of International
    Conference on Information Technology and Applications. Lecture Notes in Networks
    and Systems, vol 614. Springer, Singapore. https://doi.org/10.1007/978-981-19-9331-2_47
    Download citation .RIS.ENW.BIB DOI https://doi.org/10.1007/978-981-19-9331-2_47
    Published 19 May 2023 Publisher Name Springer, Singapore Print ISBN 978-981-19-9330-5
    Online ISBN 978-981-19-9331-2 eBook Packages Intelligent Technologies and Robotics
    Intelligent Technologies and Robotics (R0) Share this paper Anyone you share the
    following link with will be able to read this content: Get shareable link Provided
    by the Springer Nature SharedIt content-sharing initiative Publish with us Policies
    and ethics Download book PDF Download book EPUB Sections Figures References Abstract
    Introduction Related Works Overview of the Proposed Scheme Experimental Results
    and Performance Evaluation Conclusion and Future Work Notes References Acknowledgements
    Author information Editor information Rights and permissions Copyright information
    About this paper Publish with us Discover content Journals A-Z Books A-Z Publish
    with us Publish your research Open access publishing Products and services Our
    products Librarians Societies Partners and advertisers Our imprints Springer Nature
    Portfolio BMC Palgrave Macmillan Apress Your privacy choices/Manage cookies Your
    US state privacy rights Accessibility statement Terms and conditions Privacy policy
    Help and support 129.93.161.222 Big Ten Academic Alliance (BTAA) (3000133814)
    - University of Nebraska-Lincoln (3000134173) © 2024 Springer Nature"'
  inline_citation: '>'
  journal: Lecture Notes in Networks and Systems
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: 'WaterCrypt: Joint Watermarking and Encryption Scheme for Secure Privacy-Preserving
    Data Aggregation in Smart Metering Systems'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Cai M.
  - Wang S.
  - Wu C.
  citation_count: '0'
  description: Aiming at the research of real-time data transmission and multi-scale
    image decomposition of embedded optical sensor array, the principle, method and
    fusion strategy of multi-sensor image fusion are studied comprehensively, thoroughly
    and systematically by combining the imaging characteristics of source image with
    multi-scale geometric analysis tools using machine learning algorithm. A new quality
    scalable video image coding framework is also proposed in this paper, which is
    implemented by a multi-scale online dictionary learning algorithm based on structured
    sparse video signals. For the purpose of different types of images and image fusion,
    a new high quality scalable video image coding framework based on machine learning
    algorithm is proposed on the basis of comprehensive analysis of prior information
    such as imaging mechanism of image sensor and imaging characteristics of source
    image. A multi-scale online dictionary learning algorithm based on machine learning
    for sparse video signal structure is proposed. Through the hierarchical structure
    of wavelet decomposition, the searching domain of online learning is optimized
    to a hierarchical sparse block, and its sparse representation coefficients are
    obtained by using machine learning sparse coding idea. The real-time data transmission
    of embedded optical sensor array based on machine learning and multi-scale image
    decomposition algorithm proposed in this paper have good fusion performance, which
    is of great significance for further research and engineering application of image
    fusion technology.
  doi: 10.1007/s11042-020-09847-w
  full_citation: '>'
  full_text: '>

    "Your privacy, your choice We use essential cookies to make sure the site can
    function. We also use optional cookies for advertising, personalisation of content,
    usage analysis, and social media. By accepting optional cookies, you consent to
    the processing of your personal data - including transfers to third parties. Some
    third parties are outside of the European Economic Area, with varying standards
    of data protection. See our privacy policy for more information on the use of
    your personal data. Manage preferences for further information and to change your
    choices. Accept all cookies Skip to main content Log in Find a journal Publish
    with us Track your research Search Cart Home Multimedia Tools and Applications
    Article Research on real-time data transmission and multi-scale video image decomposition
    of embedded optical sensor array based on machine learning Published: 06 October
    2020 Volume 81, pages 41407–41427, (2022) Cite this article Download PDF Access
    provided by University of Nebraska-Lincoln Multimedia Tools and Applications Aims
    and scope Submit manuscript Mingxin Cai , Shanshan Wang & Chao Wu  314 Accesses
    1 Citation Explore all metrics Abstract Aiming at the research of real-time data
    transmission and multi-scale image decomposition of embedded optical sensor array,
    the principle, method and fusion strategy of multi-sensor image fusion are studied
    comprehensively, thoroughly and systematically by combining the imaging characteristics
    of source image with multi-scale geometric analysis tools using machine learning
    algorithm. A new quality scalable video image coding framework is also proposed
    in this paper, which is implemented by a multi-scale online dictionary learning
    algorithm based on structured sparse video signals. For the purpose of different
    types of images and image fusion, a new high quality scalable video image coding
    framework based on machine learning algorithm is proposed on the basis of comprehensive
    analysis of prior information such as imaging mechanism of image sensor and imaging
    characteristics of source image. A multi-scale online dictionary learning algorithm
    based on machine learning for sparse video signal structure is proposed. Through
    the hierarchical structure of wavelet decomposition, the searching domain of online
    learning is optimized to a hierarchical sparse block, and its sparse representation
    coefficients are obtained by using machine learning sparse coding idea. The real-time
    data transmission of embedded optical sensor array based on machine learning and
    multi-scale image decomposition algorithm proposed in this paper have good fusion
    performance, which is of great significance for further research and engineering
    application of image fusion technology. Similar content being viewed by others
    A New Image-Fusion Technique Based on Blocked Sparse Representation Chapter ©
    2014 Design and development of compressed video sensing technique using shuffled
    sailfish optimization algorithm Article 23 February 2024 A multi-level residual
    reconstruction based image compressed sensing recovery scheme Article 21 May 2019
    1 Introduction Machine learning means that the system improves its performance
    according to experience. Machine learning is one of the most active and potential
    fields in artificial intelligence. In the past 30 years, machine learning research
    has made unprecedented progress. On September 14, 2001, Dennis DeCoste, a scientist
    at NASA’s Jet Propulsion Laboratory in California, pointed out that machine learning
    is playing an increasingly supportive role in every stage of scientific research,
    and that this field will achieve steady and rapid development and make greater
    contributions to science in the coming years. From their evaluation of machine
    learning, we can see the research value of machine learning. Many embedded vision
    applications use only one image sensor to monitor one direction, such as the front
    of the car. The image sensor can detect, classify and track objects. However,
    since only one sensor is used, the distance from the object in the image cannot
    be measured. Data acquisition is the basic means to obtain information. Compared
    with the traditional data acquisition system, the sensor signal collected in the
    field is transmitted by wireless mode, which has the advantages of not being affected
    by geographical environment, climate and time [10, 22]. With the help of wireless
    transmission means, it has the advantages of low cost of engineering cost and
    human resources, no geographical influence on data transmission, high reliability
    and maintenance-free. In recent years, with the development of science and technology,
    especially the development of communication technology, computer technology and
    sensor technology, the application of remote acquisition technology in the field
    of bridge health monitoring makes it possible for people to monitor bridge in
    real-time, remote and automatic way [13, 14, 21]. The bridge long-distance medullary
    measurement system involves sensors, structural mechanics, computers, communications
    and other multi-disciplinary and multi-disciplinary fields, and is a hot research
    field in the international frontier. Since 1980s, foreign countries have begun
    to study this field, and have made some achievements and been applied in practice.
    In general, the adaptive method first detects the edge of the image and uses the
    edge information to represent the original function optimally [4, 5, 11]. The
    Bandlet transform proposed by Pennec E.L. and Mallats., which is the main representative
    for the two-dimensional piecewise smooth function with singular curves. In contrast,
    the non-adaptive representation of multi-scale geometric analysis of images does
    not require prior knowledge of the geometric characteristics of the image itself
    [3, 26]. It is represented by Ridgelet transform and Curvelet transform proposed
    by CandesE.J. Donoho D.L., ContourIet transform proposed by Vetterli M. For multivariable
    functions with linear singularities, Ridgelet transform has the best approximation
    performance; for two-dimensional piecewise smooth functions with singular curves
    [23, 28]. In 2006, Cunha A.L. et al. proposed another MGA tool with translation
    invariance, non-downsampling Contourlet transform. NSCT uses non-downsampling
    filter banks to decompose the scale and direction of the image [8, 27]. The translation
    invariance makes NSCT have better application prospects in image denoising, image
    enhancement, image fusion and other fields. Scale geometry analysis of images
    is a very cutting-edge research area, and the theory and algorithm are still developing.
    However, the preliminary results obtained in the field of image processing (including
    image enhancement, image denoising, image compression and edge detection) have
    left a deep impression on people. With the deepening of research, multi-scale
    geometric analysis tools must become a powerful tool in many image processing
    fields [2, 12, 16]. Wireless sensor network is a distributed network with embedded
    structure. It is accompanied by sensor technology and embedded computing. With
    the continuous development of computer and communication technology, a multi-disciplinary
    theory and technology has gradually developed. Wireless sensor networks can be
    deployed randomly in any environment [6, 9, 25]. Collaborative real-time detection,
    perception and acquisition of environmental object information in the distributed
    area can be achieved. In addition, a new quality scalable video image coding framework
    is proposed, which is implemented by using multi-scale online dictionary learning
    algorithm based on structured sparse video signals. On the basis of analysis and
    research, Fengwen designs a simple communication protocol and verifies it simply.
    2 Related work 2.1 Embedded technology Embedded system mainly includes tailorable
    hardware, embedded operating system and special software on this operating system.
    The most important part of hardware is embedded processor, so it is necessary
    for us to understand embedded processor and embedded operating system. Embedded
    system is defined as an application-centered, computer-based, software and hardware
    tailorable, suitable for application systems, with strict requirements on function,
    reliability, cost, volume and function [19]. Why to use embedded system? In addition
    to the consideration of product size, cost and other factors, there are performance
    reasons for choosing embedded system: unlike general-purpose computers, its hardware
    and software mainly consider efficient design, tailoring, removing redundancy,
    achieving higher performance in the same silicon chip area, which also makes it
    more competitive in the choice of processors. In addition, because embedded systems
    and specific applications are organically integrated, its upgrade and replacement
    are synchronized with specific products, so embedded system products have a long
    life cycle. Software in embedded system is usually solidified in read-only memory,
    instead of using disk as the carrier, and can be replaced at will. So the life
    cycle of application software in embedded system is as long as that of embedded
    products [7, 15]. Among them microcontroller, DSP (Digital Signal Processing),
    ARM and so on are commonly used. As a result of a large number of new technologies,
    changes in the internal system structure (generally Harvard structure), the use
    of pipeline technology, improve the parallel processing capacity of processors,
    provide online simulation (generally using J1AG interface), and also integrate
    a large number of peripheral interfaces in the chip, greatly enhancing the function
    of the system and reducing the size of the hardware platform. Low-end 8-bit microcontroller
    has more and more integrated functions, smaller and smaller package, and the system
    clock frequency has been greatly improved. In high-end 32-bit CPU, besides the
    ×86 series, which we are all familiar with, ARM and DSP are the most widely used
    in our country. Several typical processors are compared as shown in Table 1. Table
    1 Comparison of several typical processors Full size table 2.2 Digital image representation
    and processing Digital image digital image refers to a two-dimensional function
    which is sampled and quantized. The amplitude is quantized by equal distance rectangular
    mesh sampling, and can be expressed by a two-dimensional matrix. If we define
    a digital image as a digital representation of an object, then the pixel is a
    discrete unit, and the quantized gray level is a digital quantity. The three steps
    of acquisition, sampling and quantization constitute the process of image digitization,
    that is, the process of forming a digital image. The results are actually a matrix.
    There are generally two main representations of digital images: (1) Array representation
    of gray image: If an image f(x, y) is sampled, the resulting digital image has
    M rows and N columns. Now, the value of coordinates (x, y) becomes discrete. In
    order to express clearly and conveniently, these discrete coordinates are integrated.
    In this way, the coordinate value of the origin is (x, y) = (0, 0). The next coordinate
    value along the first line of the image is represented by (x, y) = (0, 1). However,
    it does not mean the actual physical coordinates of the image sampling. Expressions
    such as formula (1) $$ f\\left(x,y\\right)=\\left[\\begin{array}{cccc}f\\ \\left(0,0\\right)&
    f\\ \\left(0,1\\right)& \\dots & f\\ \\left(0,N-1\\right)\\\\ {}f\\ \\left(1,0\\right)&
    f\\ \\left(1,1\\right)& \\dots & f\\ \\left(1,N-1\\right)\\\\ {}f\\ \\left(N-1,0\\right)&
    f\\ \\left(N-1,1\\right)& \\dots & f\\ \\left(N-1,N-1\\right)\\end{array}\\right]
    $$ (1) Each element in an image array is a discrete pixel value In digital image
    processing, array N and gray level G are generally taken as integer powers of
    2, that is, N = 2n and G = 2 m. For general laboratory video images, N takes 256
    or 512, gray G 64 to 256, which can meet the needs of image processing. Let number
    b be the number of bits needed to store digital images. $$ b=M\\times N\\times
    K $$ (2) K is the relation of gray scale G: G = 2k. When M = N, the upper form
    becomes $$ b={N}^2\\times K $$ (3) (2) Binary image representation. In image processing,
    in order to reduce the amount of calculation, grayscale images are often converted
    into binary image processing. The so-called binary image has only two black and
    white gradations, that is, the pixel gradation is not 1 or 0. For example, a text
    image whose digital image can be represented by a matrix of 1 bit per pixel. Binary
    images can also be represented by some special methods, such as chain codes, which
    are suitable for representing binary images consisting of straight lines and curves,
    and describing the boundary contours of images. The chain code ratio matrix can
    save a lot of bits. 2.3 Extensible video coding framework based on machine learning
    Machine learning is actually an application-driven discipline, and its fundamental
    driving force is to be able to better solve more practical problems. Therefore,
    the successful application of machine learning in practical problems has become
    an important measure of the progress of machine learning research. At present,
    some successful applications of machine learning include speech recognition, computer
    vision, biological monitoring, accelerating the progress of experimental scientific
    research and so on. Application-driven discipline characteristics drive the research
    of machine learning to develop continuously. There are endless learning paradigms
    for different problems in machine learning. Traditional video coding frameworks
    can meet the quality requirements of independent coding for a single video stream.
    However, using the same multimedia information at different bit rates can better
    adapt to heterogeneous network environments, that is, for the same video sequence,
    different video quality can be obtained under different network conditions. The
    scalable video coding framework achieves one-time coding and compression of video
    data, and decodes the compressed bitstream with multiple frame rates, spatial
    resolution or video quality, so as to meet the application requirements of different
    bandwidth and equipment terminals [1, 20, 24]. When the network bandwidth is small,
    the basic video information of video sequence as the basic layer transmits at
    a lower bit rate, and decides whether to transmit additional video information
    in the enhancement layer to improve the video frame quality according to the actual
    network environment. In this way, most terminals with network connections can
    use multimedia information with appropriate bit streams, regardless of the requirements
    of the original stream [29]. The goal of the scalable video coding standard is
    that the encoded high-quality video stream contains one or more sub-streams, and
    the decoding complexity and reconstruction quality of any sub-stream are similar
    to the existing single-scale coding framework. Although transmitting two or more
    single-layer bitstreams in the same way will lead to higher bit rates, it can
    also achieve the same functions as scalable video bitstreams. On the contrary,
    because the encoding method based on Scalable predictive structure improves the
    encoding efficiency, and the traditional video coding standards have a good support
    for time scalability. However, the idea of scalable coding still has its advantages.
    Firstly, the video source only needs to encode once with the highest resolution
    and frame rate required. It can intercept any bit stream to obtain the video resolution
    and frame rate suitable for the current heterogeneous network environment [17,
    18]. Secondly, the scalable quality of video coding conforms well to the idea
    of non-uniform error protection. For the basic layer of video information, it
    is more important to protect the key information to ensure error repair, while
    the high-frequency image information which has less impact on the visual quality
    can be selected according to the terminal and channel conditions to ensure the
    robustness of video transmission. Therefore, with the widespread use and emergence
    of mainstream video coding frameworks, scalable expansion naturally attracts people’s
    attention. How to achieve scalable characteristics within acceptable complexity
    and obtain similar reconstruction quality with single-scale coding frameworks
    is the focus of research. Figure 1 is a two-tier coding framework, which outlines
    the main idea of scalable time, space and quality. Scalable video coding framework
    is an interlayer dependent structure. Among them, the time scalability is realized
    by a scalable frame prediction structure, which assigns different time levels
    to the video frames. When the network bandwidth is small, the frames with higher
    levels in the enhancement layer are automatically discarded, so as to reduce the
    frame rate for better playback quality. As reference frame management is implemented
    in AVC, different from it, frames generated in scalable B frame prediction structure
    can be referred to by other frames. Spatial scalability is achieved by up-down
    sampling filtering and inter-layer prediction. The basic layer is sampled from
    the original video stream downstream, while the enhancement layer is recovered
    from the basic layer based on inter-layer prediction technology. Quality scalability
    is achieved by reducing the quantization step. Traditional coarse-grained quality
    classification firstly roughens the coefficients to form the base-level video
    stream, then subtracts the original coefficients from the roughened coefficients
    to get the residual, and finely quantizes the residual into the enhanced-level
    video stream, and so on. In order to solve the problem that the rate control can
    not be handled flexibly, the Medium-granularity quality hierarchical coding is
    proposed, which can flexibly balance the drift caused by the asynchronization
    of coding and decoding in the motion compensation prediction cycle and the coding
    efficiency of the hierarchical prediction. Fig. 1 Scalable extended image coding
    framework Full size image 3 Multi-scale image analysis based on embedded real-time
    data transmission 3.1 Function and structure of the system The functions of the
    whole system need not only large amount of arithmetic operations, such as image
    processing operations, but also complex external interface communication control.
    This requires reasonable division in the design of the system, giving full play
    to the advantages of fast hardware processing of the FPGA (Field-Programmable
    Gate Array) and flexible and efficient algorithm design of the DSP Builder. These
    functions (tasks) can be summarized into two categories: one is control functions,
    including image acquisition interface, SDRAM (synchronous dynamic random-access
    memory) controller, LCD (Liquid Crystal Display) display interface; the other
    is data conversion and processing functions, including image data processing,
    simple and large number of operations. Considering the speed, power consumption,
    flexibility, development cycle, cost and other factors of the system, the functions
    of the system are divided as follows: video capture control, image processing
    algorithm and video display control. The functional diagram of the video image
    processing system is shown in Fig. 2. Fig. 2 Function map of video image processing
    system Full size image The core of the system is the FPGA device. The peripheral
    devices and chips include: video capture board, LCD screen and SDRAM chip. The
    overall structure of the system is shown in Fig. 3. Fig. 3 System overall structure
    block diagram Full size image As can be seen from the above figure, the main work
    of the system is on the device of the FPGA. After the hardware environment is
    built, it generally does not need to be changed. If the application environment
    changes, it only needs to load the required algorithm module on the FPGA, so it
    can be very flexible to implement new applications. There are six modules in the
    FPGA: 1) Video capture controller module; 2) 12C configuration module of image
    sensor; 3) (3) 30-bit RGB module for RAW data conversion; 4) Multi-port SDRAM
    controller module; 5) LCD controller and data request module; 6) 12C configuration
    module of LCD chip; 7) Image processing and recognition algorithm module. Workflow
    of the system: First, the camera and LCD screen are connected to the development
    board. After the system is powered on, the image sensor and LCD display chip will
    be configured by the 12C configuration module of the image sensor under the control
    of SCLK clock through SDATA serial bus. Video capture controller module sends
    25 MHz main clock of image sensor to image sensor, and receives data flow and
    control signal sent back by sensor at the same time. The collected data are sent
    to RAW data conversion 30-bit RGB module, and then the RGB components of 320 image
    data per row are sent to 3 RAMs respectively. Then it is sent to the multi-port
    SDRAM controller module to form a complete frame buffer. Removed from the SDRAM
    device in which data can be sent to the image processing and recognition module
    processing. Finally, the LCD controller and the data request module send data
    requests to the multi-port SDRAM controller module, and the results of image algorithm
    processing are converted in parallel and in series and displayed on the LCD screen.
    3.2 Configuration module of image sensor The register read-write operation of
    MT9M011 image sensor is transmitted by two-wire serial bus. I2C bus is a two-wire
    bus used to connect IC devices. It transmits information between devices connected
    to the bus through SDATA (Serial Data Line) and SCLK (Serial Clock Line), and
    identifies each device according to its address. In the process of data transmission,
    it is necessary to confirm the beginning and end of data transmission. As a slave
    device of serial bus, image sensor is controlled by SCLK driven by main device
    of serial bus. Configuration data is transmitted through SDATA. Before instantiating
    the I2C controller, it is necessary to provide a clock that meets the I2C standard.
    The clock input of the module is a 50 MHz clock provided by the development board,
    and the clock of the I2C controller is 20KHz, which is obtained by 50 MHz clock
    frequency division. Before and after the start of transmission, SCLK signals should
    be kept at a high level. The starting condition START and STOP of I2C are completed
    by SCLK and SDATA. A 1-bit register SCLK is added to Verilog HDL code to generate
    START and STOP conditions. Before STAT, after STOP, SCLK = I, after START condition,
    before STOP condition, SCLK = 0. Figure 4 shows the configuration flow of the
    controller to the image sensor. Fig. 4 I2C controller flow chart for CMOS sensor
    register configuration Full size image The image sensor configuration data is
    stored in the lookup table (LUT_DATA). The LUT_DATA data is 16 bits, including
    the register address of the sensor and the register data (DATA). A total of 17
    registers are configured. The configuration is to write the values of the registers
    one by one, and the register index code is LUT_INDEX. Each register configuration
    is divided into three states, which are represented by mSetup_ST. State 1: Prepare
    data, merge 8-bit slave device address with LUT_DATA to 24-bit data mI2C_DATA,
    set mI2C_GO to 1, and start I2C transmission; State 2: Detecting the end of transmission
    signal. If the end of transmission is detected, but the ACK signal step is normal,
    return to the first step and send data again. If the end of transmission is detected
    and the ACK signal is normal, then enter the third step. State 3: Add the register
    index LUT_INDEX to 1 to prepare for the next data transmission. The internal register
    for configuring the image sensor is shown in Fig. 5. Fig. 5 Configuring the internal
    register of the image sensor Full size image 3.3 Processing of image frame buffer
    Because the amount of image data needed to be stored in video acquisition is too
    large, we use MT48LC4M3282 of Micron Company to synchronize SDRAM. The SDRAM includes
    four BANK zones, the main frequency clock is 100 MHz, and the storage capacity
    is 16Mbit. SDRAM controller provides synchronous command interface and sequential
    logic control for SDRAM devices according to the operation characteristics of
    SDRAM. The interface schematic diagram of SDRAM controller is shown in Fig. 6.
    Fig. 6 Interface schematic diagram of SDRAM controller Full size image (1) Interface
    signals communicating with the main equipment: REF_CLK is the system clock signal,
    RESET_N is the system reset signal, ADDR [22:0] is the address line (the SDRAM
    consists of four banks, ADDR [22:20] is the selected address of the bank chip,
    ADDR [19:0] is the storage address in each bank), DATAIN [15:0] and DATAOUT [15:0]
    are the input and output data bus. (2) Interface signals communicating with SDRAM
    devices: SA [11:0] is a 12-bit address line. In reading and writing operations,
    the address line is multiplexed into row address and column address, BA [1:0]
    is page address, CS_N [1:0] is chip selection signal, CKE is clock enabling signal,
    RAS_N, CAS_N and WE_N are command control signals, DQM [I:0] is SDRAM data mask,
    DQ [15:0] is bidirectional data line. In order to facilitate the caching of high-speed
    images and subsequent image processing algorithms, a four-port SDRAM controller
    is designed based on the above basic SDRAM controller. This multi-port controller
    can be easily applied to different image processing algorithms to facilitate the
    implementation of high-speed image processing. 4 Scalable image coding based on
    machine learning algorithm for multi-scale spatiotemporal online dictionary learning
    A scalable video coding framework based on machine learning multi-scale online
    dictionary algorithm is proposed by using sparse inter-group structure of video
    signal: inter-layer sparse and inter-group sparse. Through the non-downsampling
    wavelet transform of the original video frame, a multi-scale dictionary is learned
    from the feature set to maintain the sparse inter-layer structure of the video
    image. The search domain of machine learning sparse coding is optimized into blocks
    with sparse hierarchical structure. Meanwhile, the sparse representation coefficients
    of the basic layer and the sub-dictionaries of the lowest frequency subband have
    a set of sparse characteristics. In addition, this chapter also introduces cross-layer
    decomposition and reconstruction algorithms. It can be proved that the reconstructed
    quality can be guaranteed by an upper bound estimation error, that is to say,
    high frequency information can be obtained by atomic prediction of the selected
    low frequency atomic dictionary. Random gradient descent method is used to optimize
    the expected cost in online dictionary learning based on machine learning, and
    its performance is better than that of the algorithm. The machine learning algorithm
    can acquire scalable quality by learning multi-scale dictionary pairs. 4.1 Hierarchical
    multiscale dictionary construction There are similar structures and textures between
    consecutive frames of video sequences, and these redundant information usually
    appears at the same scale or at different scales. Given a frame group Fh of a
    video sequence, the frame group is divided into high resolution key frame XH and
    downsampled non-key frame ZL. XH and ZL are coded and decoded by standard coder.
    At the decoder end, the high resolution key frames are decomposed by wavelet transform,
    and the multi-scale dictionary is learned in the wavelet coefficient domain. High-resolution
    \\( {\\hat{X}}_{hl} \\) is recovered from \\( {\\hat{Z}}_L \\) by scalable super-resolution
    reconstruction with specific SNR values. The scalable super-resolution reconstruction
    problem can be defined as the following energy minimization problem: $$ f\\left({\\alpha}_L^d,{X}_H\\right)\\mathit{\\arg}\\
    \\mathit{\\min}\\frac{1}{2}\\sum \\limits_d{\\left\\Vert {W}_A{Z}_L-{D}_L^d{\\alpha}_L^d\\right\\Vert}_2^2+\\lambda
    \\sum \\limits_d\\left\\Vert {\\alpha}_L^d\\right\\Vert +\\sum \\limits_{l=2}^k{\\left\\Vert
    {D}_{Hl}^d{\\alpha}_L^d-{W}_A{X}_H\\right\\Vert}_2^2 $$ (4) The first item in
    the formula is the sparse representation of the sum of errors for each subband.
    In order to maintain the sparsity of coefficients, the number of sparse constraints
    of the second term must be small enough. The third term in the formula represents
    the reconstruction error of each layer and is used to ensure that the enhancement
    layer can be recovered within acceptable errors. The non-downsampled two-dimensional
    discrete wavelet transform is used to decompose the high-resolution keyframe into
    four sub-bands, namely low-frequency sub-band, horizontal sub-band, vertical sub-band
    and oblique sub-band. Each sub-band contains a K scale. For all 3 K high frequency
    sub-band wavelet coefficients, the sample image blocks in each direction are intercepted
    from the same position and size. The training sample set \\( {T}_L^i,{T}_{Hl}^i,i=1,2,3,l=1,\\dots,
    k-1 \\) is obtained. For the lowest frequency subband in each direction, the subdictionary
    \\( {D}_L^i \\) and the corresponding representation coefficient \\( {\\alpha}_L^i
    \\) are obtained by sparse coding. When the low-resolution image block \\( {\\hat{Z}}_{ij}
    \\) is represented by the sub-dictionary of the low-resolution molecular band
    and the representation error is zero, the high-resolution image block \\( {\\hat{x}}_{ij}
    \\) can be obtained by multiplying the representation coefficient alpha αHd by
    the corresponding high-resolution sub-dictionary. Therefore, the objective of
    the reconstruction problem is to minimize the slippage error: $$ \\mathit{\\arg}\\
    \\underset{D_L^i,{\\alpha}_L^i}{\\min }{\\left\\Vert {W}_A{Z}_L-{D}_L^i{\\alpha}_L^i\\right\\Vert}_F^2
    $$ (5) Online learning algorithm has less computational complexity than K-SVD
    algorithm, so online learning algorithm is introduced into dictionary training.
    By training high frequency training set \\( {T}_{Hi}^i,i=1,2,3 \\), the high frequency
    sub-dictionary and coefficient \\( {\\alpha}_L^i \\)of layer k-1 are obtained.
    $$ {D}_{Hl}^i,i={T}_{Hl}^i{\\alpha}_L^{i\\dagger}\\approx {T}_{Hl}^i{\\alpha}_L^{iT}{\\left({\\alpha}_L^i{\\alpha}_L^{iT}\\right)}^{-1}
    $$ (6) The superscripts †, T and-1 represent pseudo-inverse, transpose and inverse
    operations respectively. Assuming that the high and low frequency sub-bands have
    the same representation coefficients on the corresponding sub-dictionaries, in
    order to establish the relationship between the high and low frequency sub-bands,
    and consistent with the wavelet basis of the learning module, the first-order
    non-downsampling wavelet decomposition is applied to the low resolution image.
    Three-directional high-frequency wavelet subbands are used as sparse dictionary
    base \\( {D}_L^i \\) for training low-frequency pictures. The expression coefficient
    \\( {\\alpha}_L^i \\) is obtained by traditional orthogonal matching pursuit method.
    The reconstruction series r is determined by the network bandwidth and is less
    than or equal to the decomposition series K. The high frequency subband of layer
    i can be expressed as: $$ {\\hat{X}}_{Hl}^i={D}_{Hl}^i{\\alpha}_H^i\\approx {D}_{Hl}^i{\\alpha}_L^i
    $$ (7) The low-frequency synthesized sub-band restores the complete video frame
    of the layer by inverse wavelet transform, and the image will participate in the
    reconstruction of the next layer as the low-frequency layer of the next layer.
    The sparse scalability of multiscale dictionaries is shown in Fig. 7. Fig. 7 Sparse
    extensibility of multiscale Dictionaries Full size image Online dictionary learning
    directly optimizes the approximate expected cost. Compared with traditional batch
    gradient descent based learning algorithm, online dictionary learning has lower
    algorithm complexity and memory occupancy. Therefore, a multi-scale online learning
    dictionary is constructed by an online dictionary learning algorithm. In the framework
    of the video coding system, the expected cost of each optimized target bit of
    dictionary learning is minimized: $$ f\\left(D,{\\alpha}_L\\right)=\\mathit{\\min}{E}_x\\left[\\frac{1}{2}{\\left\\Vert
    {W}_A{Z}_L-{D}_L^i{\\alpha}_L^i\\right\\Vert}_2^2+\\lambda c\\left(\\alpha L\\right)\\right]i=1,2,3
    $$ (8) Dictionary training is divided into two processes. In the phase of solving
    sparse coding coefficients, the Cholesky decomposition of LARS-Lasso problem is
    used to solve the problem. $$ {\\alpha}_t\\triangleq \\min \\frac{1}{2}{\\left\\Vert
    {x}_t-{D}_{t-1}\\alpha \\right\\Vert}_2^2+\\lambda {\\left\\Vert \\alpha \\right\\Vert}_1
    $$ (9) In the dictionary updating stage, the dictionary atoms are updated sequentially
    by using the first-order projection stochastic gradient descent algorithm until
    convergence: $$ {D}_{t-1}=\\prod \\limits_c\\left[{D}_t-{\\delta}_t{\\nabla}_Dl\\left({x}_t,{D}_t\\right)\\right]
    $$ (10) 4.2 Progressive dictionary learning Since the reconstructed scalable framework
    contains more prior knowledge, the reconstructed framework is used as the next-level
    reference framework for atomic updates of the dictionary. Considering that the
    stochastic gradient descent method can receive training samples in real time,
    the online learning algorithm can directly intercept the 3D video blocks in the
    reconstructed video frame of the current layer to increase the training sample
    set. Given the enhancement layer T1 to TK, the original dictionary of time layer
    TK is \\( {x}_1^k,{x}_2^k,\\dots, {x}_{\\theta}^k,{T}_K \\) is Dk − 1, and the
    updating of the learning dictionary of this layer is based on the current training
    samples and the previous learning dictionary. Unlike the batch gradient descent
    method, the online learning algorithm randomly selects a sample KT and updates
    the dictionary based on the sample rather than the whole training set: $$ {D}_L^k={D}_L^{k-1}-{\\gamma}_t{\\nabla}_Dl\\left({D}_L^{k-1},{x}_t^{k-1}\\right)
    $$ (11) Its cost function is defined as: $$ l\\left({D}_L^{k-1},{x}_t^{k-1}\\right)=\\frac{1}{2}{\\left\\Vert
    {x}_t^{k-1}-{D}_L^{k-1}{\\alpha}_i\\right\\Vert}_2^2+\\lambda {\\left\\Vert \\alpha
    \\right\\Vert}_1 $$ (12) Figure 8 is a progressive dictionary learning module
    based on random gradient descent method. By connecting the high and low frequency
    images \\( \\hat{X_h^{LF}} \\) and \\( \\hat{X_h^{LF}} \\)from the same position
    along the trajectory direction, a set of three-dimensional training samples is
    obtained. \\( \\hat{X_h^{LF}} \\) is the interpolation version of downsampling
    reference frame \\( {\\hat{X}}_h \\), and \\( \\hat{X_h^{LF}} \\)is the residual
    between \\( {\\hat{X}}_h \\)and \\( \\hat{X_h^{LF}} \\). Fig. 8 Progressive dictionary
    learning based on stochastic gradient descent method Full size image The high
    frequency component \\( {x}_i^{HF} \\) of the image block xi can be predicted
    by the sparse representation coefficient alpha of the sample image block \\( {x}_i^{HF}
    \\) on the dictionary αand its corresponding high frequency dictionaryDL. The
    reconstructed image block \\( {x}_i^h \\) is obtained by adding \\( {x}_i^{HF}
    \\) and \\( {x}_i^{HF} \\). The dictionary Dk − 1 obtained from rough layer training
    contains priori information from low time level T0 to Tk-1. Based on the training
    samples obtained from the increasing decoding layer, the dictionary learning algorithm
    can adapt to the changes of video playback, and the previously learned dictionary
    can provide more prior knowledge than the current reference frame. 5 Experimental
    analysis Under Windows system, the processor Intel (R) core (TM) i5 is tested
    by MATLAB software. Firstly, the performance of various image decomposition and
    reconstruction tools in image fusion is discussed. All images are decomposed into
    three levels. In DWT and DWFT algorithms, “db4” wavelet filter is used. In the
    NSCT algorithm, the scale decomposition filter uses the “maxflat” filter and the
    directional decomposition filter uses the “dmaxflat” filter. In the CNT algorithm
    and the NSCT algorithm, the directional decomposition series from the roughest
    scale to the finest scale are”2, 3, 3′. Three groups of source images with periodontal
    features were used for fusion experiments (all images are 256 × 256 in size and
    256 in gray level). The fusion performance of the image edge gradient information
    is used for objective evaluation. Figure 9 shows the results of different fusion
    algorithms. Table 2 shows the performance comparison of different fusion algorithms.
    The experimental results show that the fusion algorithm mi (I1, I2, f) is effective,
    time-consuming and has the best performance. Fig. 9 Performance comparison data
    of multi-focus images Full size image Table 2 Performance comparison data of multi-focus
    images. Full size table While CT2 divides the frequency band by a certain window
    function in frequency domain and decomposes the image by FFT, so there is no Gibbs
    effect. The fusion image with good visual effect can also be obtained by using
    CT2 algorithm. Through careful comparison, it can be found that image fusion algorithms
    using MGA tools such as CT1, CT2 and NSCT can obtain better quality fusion images,
    especially for targets such as road and house edges with strong directionality.
    This is because targets such as road and house edges have abundant singularity
    information of curves or straight lines, and MGA can well characterize the contour
    of such curves or straight lines, so that better fusion effect can be obtained.
    Performance comparison data of infrared and visible images was shown in Fig. 10.
    Fig. 10 Performance comparison data of infrared and visible images Full size image
    Fig. 11 Performance comparison data of remote sensing images Full size image Performance
    comparison data of remote sensing images was shown in Fig. 11. From the experimental
    data in Fig. 11, Tables 2, 3 and 4, it can be seen that DWT and CNT fusion algorithms
    have low fusion performance. The NSCT algorithm has the highest MI and Q values.
    The table NSCT fusion algorithm can extract more fusion information from the source
    image and preserve the edge information of the source image as much as possible.
    This is in good agreement with the above analysis. From the perspective of fusion
    performance, we can rank the fusion performance of various fusion algorithms as
    follows (qualitative analysis), The comparison and explanation of different specific
    methods are shown below, from formula 13 to formula 15. $$ NSCT>\\left\\{\\begin{array}{c}
    DW\\mathrm{F}T\\\\ {} CT1\\\\ {} CT2\\end{array}\\right\\}>\\left\\{\\begin{array}{c}
    DW T\\\\ {} CNT\\end{array}\\right\\} $$ (13) Table 3 Performance comparison data
    of infrared and visible images Full size table Table 4 Performance comparison
    data of remote sensing images Full size table Because NSCT and DWFT do not need
    to downsample and up-sample the image in the process of image decomposition and
    reconstruction, the size of each sub-band image obtained by NSCT and DWFT is the
    same as that of the source image. It is easier to find the corresponding relationship
    between each sub-band image and between each sub-band image and the source image,
    thus facilitating the formulation of fusion rules to a certain extent. In DWT,
    there exists a low frequency subband coefficient and three corresponding directional
    subband coefficients (horizontal, vertical and diagonal) for each scale of Lye-1
    pixel, so there is a good correspondence between subband coefficients on the same
    scale. The “coarse” scale image is obtained by downsampling the previous scale
    image, so the coefficients corresponding relationship between scales is more complex.
    After scale decomposition, CNT decomposes the image in direction, and when direction
    decomposition, the downsampling operation is not simply to downsample in horizontal
    and vertical directions, but to downsample the image using a more complex sampling
    matrix, so the relationship between the coefficients of sub-bands at all levels
    obtained by CNT decomposition is more complex. Similarly, CTI divides the image
    into sub-bands by overlapping smoothing and then Ridgelet transform. CT2 divides
    the image into sub-bands by using window function with certain direction in frequency
    domain. Therefore, the corresponding relationship between sub-band image coefficients
    obtained by CTl and CT2 decomposition is more complex, which also affects the
    formulation of fusion rules to a certain extent. Based on the above analysis,
    we rank the image decomposition and reconstruction tools as follows from the corresponding
    relationship between sub-band coefficients after image decomposition or from the
    ease of making fusion rules (qualitative analysis): $$ \\left\\{\\begin{array}{c}
    NSCT\\\\ {} DWFT\\end{array}\\right\\}> DWT>\\left\\{\\begin{array}{c} CT1\\\\
    {} CT2\\\\ {} CNT\\end{array}\\right\\} $$ (14) Because both DWT and CNT use filter
    banks to decompose images in discrete domain, and there are still downsampling
    operations, both DWT and CNT have faster operation speed. In contrast, DWFT and
    NSCT also use filter banks to decompose images in discrete domain, but the size
    of images at all levels or scales is the same, so they have slower operation speed
    than DWT and CNT. CT2 divides the frequency band directly in the frequency domain
    and decomposes the image with FFT, so it has a faster operation speed. From the
    implementation process of CT1, we can see that the implementation of CT1 is more
    complex, especially needs Ridgelet transform, so its operation speed is the slowest.
    Based on the above analysis, we can sort the image decomposition and reconstruction
    tools as follows from the point of view of operation speed (qualitative analysis):
    $$ \\left\\{\\begin{array}{c} DWT\\\\ {} CT2\\\\ {} CNT\\end{array}\\right\\}>\\left\\{\\begin{array}{c}
    DWFT\\\\ {} NSCT\\end{array}\\right\\}> CT1 $$ (15) From the above analysis, it
    can be concluded that NSCT not only has good fusion performance, but also has
    obvious correspondence among sub-band images, which facilitates the implementation
    of fusion operation, and also has a faster operation speed. Therefore, NSCT is
    a better image fusion tool. Of course, if the direction decomposition of the image
    can further improve the speed of operation, NSCT is bound to have great potential
    in the field of image fusion. 6 Conclusion Multi-sensor image fusion technology
    has developed rapidly, and has become an important technology in image understanding,
    computer vision and other fields. By synthesizing complementary and redundant
    information among different images, a more comprehensive and accurate image description
    of the scene can be obtained. A new quality scalable video image coding framework
    is also proposed in this paper, which is implemented by a multi-scale online dictionary
    learning algorithm based on structured sparse video signals. Through the hierarchical
    structure of wavelet decomposition, the search domain of online learning is optimized
    into blocks with hierarchical sparseness. The proposed cross-scale decomposition
    and reconstruction can predict high frequency information from the sub-dictionary
    atoms of the low frequency dictionary. The reconstruction quality can be guaranteed
    by an upper bounded estimation error. At the same time, when using wavelet transform
    to analyze image, only limited direction information can be obtained, and the
    direction of image edge can not be accurately described. In the past, machine
    learning has made unprecedented development, and the research team of machine
    learning has been growing, and a series of important research results have been
    achieved. However, machine learning is an application-driven discipline. Studying
    machine learning from the perspective of application field can not only better
    solve practical problems in application, but also enrich the theoretical system
    of machine learning and promote the development of machine learning research.
    Exploring how to combine new mathematical methods such as fuzzy, clustering, and
    neural networks with multi-scale geometric analysis tools, combined with human
    visual characteristics to formulate a more complete and reasonable decomposition
    strategy to achieve intelligence and self-adaptation, is also worthy of further
    study direction. References Al-Ariki HD, Swamy MN (2017) A survey and analysis
    of multipath routing protocols in wireless multimedia sensor networks [J]. Wirel
    Netw 23(6):1823–1835 Article   Google Scholar   Arun KS, Govindan VK (2015) Optimizing
    visual dictionaries for effective image retrieval [J]. Int J Multimed Inf Retr
    4(3):165–185 Article   Google Scholar   Barmpoutis A (2013) Tensor body: real-time
    reconstruction of the human body and avatar synthesis from RGB-D [J]. IEEE Trans
    Cybern 43(5):1347–1356 Article   Google Scholar   Cho SG, Yoshikawa M, Ding M,
    Takamatsu J, Ogasawara T (2019) Machine-learning-based hand motion recognition
    system by measuring forearm deformation with a distance sensor array [J]. Int
    J Intell Robot Applic 3(4):418–429 Article   Google Scholar   Choi, Lee, Jun (2015)
    SPEED-MAC: speedy and energy efficient data delivery MAC protocol for real-time
    sensor network applications [J]. Wirel Netw 21(3):883–898 Article   Google Scholar   Goh
    H, Thome N, Cord M et al (2017) Learning deep hierarchical visual feature coding
    [J]. IEEE Trans Neural Netw Learn Syst 25(12):2212–2225 Article   Google Scholar   Han
    M, Liu X, Pu H, Zhao L, Wang K, Xu D (2020) Real-time online optimal control of
    current-fed dual active bridges based on machine learning [J]. J Power Electron
    20(1):43–52 Article   Google Scholar   Li L, Li S, Fu Y (2014) Learning low-rank
    and discriminative dictionary for image classification [J]. Image Vis Comput 32(10):814–823
    Article   Google Scholar   Li F, Sheng J, Zhang SY (2017) Laplacian sparse dictionary
    learning for image classification based on sparse representation [J]. Front Inf
    Technol Electron Eng 18(11):1795–1805 Article   Google Scholar   Liu Q, Chang
    Y, Jia X (2013) A hybrid method of CSMA/CA and TDMA for real-time data aggregation
    in wireless sensor networks [J]. Comput Commun 36(3):269–278 Article   Google
    Scholar   Mertens F, Lobanov A (2015) Wavelet-based decomposition and analysis
    of structural patterns in astronomical images [J]. Astron Astrophys 574(10):10782–10789
    Google Scholar   Mohammadi MR, Fatemizadeh E, Mahoor MH (2014) PCA-based dictionary
    building for accurate facial expression recognition via sparse representation
    [J]. J Vis Commun Image Represent 25(5):1082–1092 Article   Google Scholar   Passieux
    JC, Bugarin F, David C, Périé JN, Robert L (2015) Multiscale displacement field
    measurement using digital image correlation: application to the identification
    of elastic properties [J]. Exp Mech 55(1):121–137 Article   Google Scholar   Rezaie-Balf
    M, Kisi O, Chua LHC (2019) Application of ensemble empirical mode decomposition
    based on machine learning methodologies in forecasting monthly pan evaporation
    [J]. Nord Hydrol 50(1–2):498–516 Article   Google Scholar   SnowFort: An Open
    Source Wireless Sensor Network for Data Analytics in Infrastructure and Environmental
    Monitoring [J]. IEEE Sensors Journal, 2014, 14(12):4253–4263. Srinivas M, Naidu
    RR, Sastry CS, Mohan CK (2015) Content based medical image retrieval using dictionary
    learning [J]. Neurocomputing 168(C):880–895 Article   Google Scholar   Sun Y,
    Sudo K, Taniguchi Y (2016) Visual concept detection of web images based on group
    sparse ensemble learning [J]. Multimed Tools Appl 75(3):1409–1425 Article   Google
    Scholar   Wang D, Kong S (2014) A classification-oriented dictionary learning
    model: explicitly learning the particularity and commonality across categories
    [J]. Pattern Recogn 47(2):885–898 Article   MATH   Google Scholar   Wen B, Ravishankar
    S, Bresler Y (2015) Structured Overcomplete Sparsifying transform learning with
    convergence guarantees and applications [J]. Int J Comput Vis 114(2–3):137–167
    Article   MathSciNet   MATH   Google Scholar   Xiang S, Meng G, Wang Y, Pan C,
    Zhang C (2015) Image Deblurring with coupled dictionary learning [J]. Int J Comput
    Vis 114(2–3):248–271 Article   MathSciNet   MATH   Google Scholar   Xie H, Liu
    H, Seneviratne LD et al (2014) An optical tactile Array probe head for tissue
    palpation during minimally invasive surgery [J]. IEEE Sensors J 14(9):3283–3291
    Article   Google Scholar   Xing L, Schreibmann E, Levy D et al (2017) Multiscale
    Image Registration [J]. Math Bioscie Eng (Online) 3(2):389–418 MathSciNet   MATH   Google
    Scholar   Yang Y (2017) Top-down visual saliency via joint CRF and dictionary
    learning [J]. IEEE Trans Pattern Anal Mach Intell 39(3):576–588 Article   Google
    Scholar   Yang G, Xiao M, Zhang S (2013) Data aggregation scheme based on compressed
    sensing in wireless sensor network.[J]. J Netw 8(1):556–561 Google Scholar   Yang
    YB, Zhu QH, Mao XJ, Pan LY (2015) Visual feature coding for image classification
    integrating dictionary structure [J]. Pattern Recogn 48(10):3067–3075 Article   Google
    Scholar   Ye H, Strunz K (2018) Multi-scale and frequency-dependent modeling of
    electric power transmission lines [J]. IEEE Trans Power Deliv 33(1):32–41 Article   Google
    Scholar   Yeh CH, Kang LW, Chiou YW, Lin CW, Fan Jiang SJ (2014) Self-learning-based
    post-processing for image/video deblocking via sparse representation [J]. J Vis
    Commun Image Represent 25(5):891–903 Article   Google Scholar   Zheng J, Jiang
    Z, Chellappa R (2016) Cross-view action recognition via transferable dictionary
    learning [J]. IEEE Trans Image Process 25(6):2542–2556 Article   MathSciNet   MATH   Google
    Scholar   Zhou J, Semenovich D, Sowmya A, Wang J (2014) Dictionary learning framework
    for fabric defect detection [J]. J Text Inst 105(3):223–234 Article   Google Scholar   Download
    references Author information Authors and Affiliations Collage of Computer Science,
    Northeastern University, Shenyang, 110169, China Mingxin Cai, Shanshan Wang &
    Chao Wu Corresponding author Correspondence to Mingxin Cai. Additional information
    Publisher’s note Springer Nature remains neutral with regard to jurisdictional
    claims in published maps and institutional affiliations. Rights and permissions
    Reprints and permissions About this article Cite this article Cai, M., Wang, S.
    & Wu, C. Research on real-time data transmission and multi-scale video image decomposition
    of embedded optical sensor array based on machine learning. Multimed Tools Appl
    81, 41407–41427 (2022). https://doi.org/10.1007/s11042-020-09847-w Download citation
    Received 05 May 2020 Revised 29 July 2020 Accepted 09 September 2020 Published
    06 October 2020 Issue Date December 2022 DOI https://doi.org/10.1007/s11042-020-09847-w
    Share this article Anyone you share the following link with will be able to read
    this content: Get shareable link Provided by the Springer Nature SharedIt content-sharing
    initiative Keywords Embedded Sensor Data transmission Spatiotemporal online dictionary
    learning Multi-scale image Machine learning Use our pre-submission checklist Avoid
    common mistakes on your manuscript. Sections Figures References Abstract Introduction
    Related work Multi-scale image analysis based on embedded real-time data transmission
    Scalable image coding based on machine learning algorithm for multi-scale spatiotemporal
    online dictionary learning Experimental analysis Conclusion References Author
    information Additional information Rights and permissions About this article Advertisement
    Discover content Journals A-Z Books A-Z Publish with us Publish your research
    Open access publishing Products and services Our products Librarians Societies
    Partners and advertisers Our imprints Springer Nature Portfolio BMC Palgrave Macmillan
    Apress Your privacy choices/Manage cookies Your US state privacy rights Accessibility
    statement Terms and conditions Privacy policy Help and support 129.93.161.222
    Big Ten Academic Alliance (BTAA) (3000133814) - University of Nebraska-Lincoln
    (3000134173) © 2024 Springer Nature"'
  inline_citation: '>'
  journal: Multimedia Tools and Applications
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Research on real-time data transmission and multi-scale video image decomposition
    of embedded optical sensor array based on machine learning
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Zhang A.
  - Sun M.
  - Wang J.
  - Li Z.
  - Cheng Y.
  - Wang C.
  citation_count: '1'
  description: In the industrial environment, the data transmission of Wireless Sensor
    Networks (WSNs) usually has strict deadline requirements. Improving the reliability
    and real-time performance of data transmission has become one of the critical
    issues in WSNs research. One of the main methods to improve the network performance
    of WSNs is to schedule the transmission process. An effective scheduling algorithm
    can meet the requirements of a strict industrial environment for network performance,
    which is of great research significance. Aiming at the problem of concurrent data
    transmission in WSNs, a real-time data transmission scheduling algorithm based
    on deep Q-learning is proposed. The algorithm comprehensively considers the influence
    of the remaining deadline, remaining hops, and unassigned time-slot nodes in the
    data transmission process, defines the reward function and action selection strategy
    of Q-learning, and guides the system state information transfer process. At the
    same time, deep learning and Q-learning are combined to solve the problem of disaster
    maintenance caused by the large scale of the system state. A multi-layer Stacked
    Auto Encoder (SAE) network model establishes the state-action mapping relationship,
    and the Q-learning algorithm updates it. Finally, according to the trained SAE
    network model, the data transmission scheduling strategy of the system in different
    states is obtained. The network performance of the proposed data transmission
    scheduling algorithm is analyzed and evaluated by simulation experiments. The
    simulation results show that compared with the commonly used heuristic algorithms,
    the proposed algorithm improves real-time performance and can better meet the
    data transmission requirements of high reliability and real-time WSNs.
  doi: 10.3390/electronics11121877
  full_citation: '>'
  full_text: '>

    "This website uses cookies We use cookies to personalise content and ads, to provide
    social media features and to analyse our traffic. We also share information about
    your use of our site with our social media, advertising and analytics partners
    who may combine it with other information that you’ve provided to them or that
    they’ve collected from your use of their services. Consent Selection Necessary
    Preferences Statistics Marketing Show details                 Deny Allow selection
    Allow all   Journals Topics Information Author Services Initiatives About Sign
    In / Sign Up Submit   Search for Articles: Electronics All Article Types Advanced   Journals
    Electronics Volume 11 Issue 12 10.3390/electronics11121877 Submit to this Journal
    Review for this Journal Propose a Special Issue Article Menu Academic Editor Sotirios
    K. Goudos Subscribe SciFeed Recommended Articles Related Info Link More by Authors
    Links Article Views 1276 Citations 1 Table of Contents Abstract Introduction System
    Model Proposed Algorithm Simulation Results Conclusions Author Contributions Funding
    Data Availability Statement Conflicts of Interest References share Share announcement
    Help format_quote Cite question_answer Discuss in SciProfiles thumb_up Endorse
    textsms Comment first_page settings Order Article Reprints Open AccessArticle
    Real-Time Data Transmission Scheduling Algorithm for Wireless Sensor Networks
    Based on Deep Q-Learning by Aiqi Zhang , Meiyi Sun , Jiaqi Wang , Zhiyi Li , Yanbo
    Cheng and Cheng Wang * School of Electronic Engineering, Beijing University of
    Posts and Telecommunications, Beijing 100876, China * Author to whom correspondence
    should be addressed. Electronics 2022, 11(12), 1877; https://doi.org/10.3390/electronics11121877
    Submission received: 30 April 2022 / Revised: 8 June 2022 / Accepted: 10 June
    2022 / Published: 15 June 2022 (This article belongs to the Section Microwave
    and Wireless Communications) Download keyboard_arrow_down     Browse Figures Versions
    Notes Abstract In the industrial environment, the data transmission of Wireless
    Sensor Networks (WSNs) usually has strict deadline requirements. Improving the
    reliability and real-time performance of data transmission has become one of the
    critical issues in WSNs research. One of the main methods to improve the network
    performance of WSNs is to schedule the transmission process. An effective scheduling
    algorithm can meet the requirements of a strict industrial environment for network
    performance, which is of great research significance. Aiming at the problem of
    concurrent data transmission in WSNs, a real-time data transmission scheduling
    algorithm based on deep Q-learning is proposed. The algorithm comprehensively
    considers the influence of the remaining deadline, remaining hops, and unassigned
    time-slot nodes in the data transmission process, defines the reward function
    and action selection strategy of Q-learning, and guides the system state information
    transfer process. At the same time, deep learning and Q-learning are combined
    to solve the problem of disaster maintenance caused by the large scale of the
    system state. A multi-layer Stacked Auto Encoder (SAE) network model establishes
    the state-action mapping relationship, and the Q-learning algorithm updates it.
    Finally, according to the trained SAE network model, the data transmission scheduling
    strategy of the system in different states is obtained. The network performance
    of the proposed data transmission scheduling algorithm is analyzed and evaluated
    by simulation experiments. The simulation results show that compared with the
    commonly used heuristic algorithms, the proposed algorithm improves real-time
    performance and can better meet the data transmission requirements of high reliability
    and real-time WSNs. Keywords: real-time; data transmission; deep Q-learning; Wireless
    Sensor Networks 1. Introduction Wireless Sensor Networks (WSNs) are wireless network
    systems composed of several small autonomous devices called sensor nodes distributed
    in space according to specific requirements. The function of the sensor node is
    to transmit the data to the base station or the destination node through sensing
    and collecting the ambient information, such as sound vibration, pressure, temperature,
    light intensity, and so on. With the development of wireless communication technology
    and the progress made over time, WSNs have been applied more and more widely in
    the field of information, involving many important fields such as environmental
    monitoring, urban management, industrial and agricultural automation, intelligent
    transportation, and military [1]. In recent years, WSNs have successfully replaced
    wired networks and been adopted in the industrial field due to simple deployment,
    low maintenance cost, and high flexibility [2]. However, the characteristics of
    wireless communication determine that interference and conflict inevitably exist
    in the process of data transmission, and data packets may be lost or delayed beyond
    their expected deadline [3]. Due to the importance of timing, packets produced
    in industrial environments often have strict deadlines. In order to achieve the
    reliability of data transmission, a feasible method is to use the Medium Access
    Control (MAC) protocol based on Time Division Multiple Access (TDMA) to eliminate
    the interference in the network. Furthermore, it can improve the probability of
    transmitting the packet to the destination node before the deadline. TDMA is widely
    used in wireless network communication because it is easy to implement and avoids
    data collision. The application of WSNs in the industrial environment should ensure
    that strict timing requirements are met and improve the reliability and real-time
    performance of message forwarding between sensor nodes [4]. Therefore, how to
    improve the reliability and real-time performance of data transmission in WSNs
    has become an important research topic in WSNs. The scheduling algorithm is one
    of the main methods and key technologies to improve wireless network reliability
    and real-time performance. Effective scheduling algorithms can realize the improvement
    of network technology and make it meet the requirements of WSNs environment with
    strict deadlines. Traditional scheduling algorithms are mostly heuristic scheduling
    algorithms, such as Earliest Deadline First (EDF) [5] or BSSA algorithm [6]. As
    the WSNs data transmission scheduling problem is proven to be an NP hard problem
    [7,8], in recent years, researchers have turned their attention to introducing
    Machine Learning (ML) methods into WSNs. Many new algorithms were proposed in
    combination with ML methods in multiple aspects of WSNs [9]. In the design and
    research of WSNs, the research on functional requirements can be summarized into
    the following aspects according to the research direction of WSNs and the association
    among all directions: energy sensing and real-time routing, node clustering and
    data aggregation, event detection and query processing, localization and object
    positioning, and media access control protocol. (1) Routing protocol and energy
    perception Research on routing protocols in WSNs is a hot field to solve quality-of-service
    (QoS)-related problems. Therefore, routing protocols must consider various challenges,
    such as energy consumption, fault tolerance, scalability, and data coverage. Traditionally,
    routing problems in WSNs can be abstracted as graph 𝐺=(𝑉,𝐸) , where V represents
    the set of all nodes in the network and E represents the bidirectional communication
    edge connecting nodes. The routing problem can be defined as the process of finding
    the least-cost path from the source vertex to the destination vertex through the
    model graph G. Reinforcement learning is used to propose a routing protocol based
    on the gradient to learn and find routes that exhaust node energy in a balanced
    way [10]. Alternatively, learn from previous routing decisions and adapt to the
    traffic importance of information transmission to cope with unpredictable topology
    changes and challenges of energy constraints [11]. (2) Node clustering and data
    aggregation In WSNs constrained by energy resources, it is ineffective to transmit
    all data directly to the receiver. A practical solution is to pass the data to
    a local aggregator (called a cluster head) that aggregates the data from all the
    sensors in its cluster and transmits it to the receiver, often saving energy for
    the nodes. How to select the best node as the cluster head among local sensors
    is always a trending research topic. In addition to the famous LEACH clustering
    mechanism, the CHEF cluster head election mechanism of fuzzy logic is also used
    to reduce the collection and calculation overhead and extend the life of the sensor
    network. Recently, some researchers proposed a clustering protocol based on a
    support vector, which can effectively allocate sensor nodes to the nearest cluster
    using machine learning methods, reduce energy consumption, and make better use
    of resources [12]. Cluster head selection methods combined with machine learning
    algorithms can reduce energy consumption and enhance the network life cycle. A
    role-free clustering algorithm based on the Q-learning algorithm is proposed to
    make each node have the ability to act as a cluster head node by combining the
    Q-learning algorithm with some dynamic network parameters [13]. (3) Event detection
    and query processing Event detection and query processing in WSNs is considered
    a functional requirement for any large-scale sensor network. Monitoring content
    in WSNs can be divided into three categories: event-driven, continuous-driven,
    or query-driven. How to design effective event detection and query processing
    solutions has been the focus of many researchers in WSNs. The most straightforward
    technique is to provide strict thresholds for perceived phenomena and alert system
    administrators to any violations. However, in the recent use of WSNs, event and
    query processing units are often complex and require more than predetermined thresholds.
    In this regard, many researchers have made improvements and proposed their algorithms
    and solutions. For example, a new event detection algorithm is proposed in the
    wireless network where sensor nodes are randomly deployed in space [14]. In an
    environment with strict execution time requirements, a WSNs data flow analysis
    framework based on deep learning is proposed [15], which can obtain reasonable
    and accurate query analysis results within the deadline. In recent years, the
    appearance of wireless network physical systems needs to support the real-time
    query of the physical environment through wireless sensor networks. To address
    this requirement, a real-time query scheduling algorithm (RTQS) is proposed in
    [16], which is a new conflict-free transmission scheduling method for real-time
    queries in wireless sensor networks. (4) Localization and object positioning Localization
    is the process of determining the geographic coordinates of network nodes and
    components. Considering that the operation of most sensor networks is usually
    based on location, the position perception of sensor nodes is an essential function
    [17]. While it is possible to achieve position awareness of sensor nodes by using
    Global Positioning System (GPS) hardware in each node, this approach is not economically
    feasible in most large systems. In addition, GPS services may not be available
    in some observable environments. Relative position measurement is sufficient in
    some scenarios. However, the position of the sensor node can be sensed using the
    absolute position of the node because the relative position can be converted to
    the absolute position [18]. To enhance the performance of proximity-based positioning,
    additional measurements depending on distance, angle, or a combination of them
    can be used. Distance measurements can be obtained by utilizing various techniques
    such as RSSI, TOA, and TDOA. In addition, the angle of the received signal can
    be measured using a compass or special smart antenna [19]. (5) Media access control
    protocol In WSNs, many sensors work together to perform data transfer tasks efficiently.
    Therefore, designing MAC protocols for WSNs presents different challenges than
    typical wireless networks, as well as energy consumption and latency challenges
    [20]. In addition, WSNs must control the duty cycle of nodes in data transmission
    scheduling, which is beneficial to saving energy. Therefore, the MAC protocol
    used in WSNs must be modified to support sensor nodes to carry out data transmission
    and receiving tasks effectively. MAC protocols proposed in WSNs include TDMA-based
    MAC protocol [21], variable/burst traffic hybrid CSMA/TDMA iQueue-MAC protocol
    [22], probabilistic polling MAC protocol (PP-MAC), energy collection MAC protocol
    (EH-MAC), ERI-MAC protocol, etc. [23]. (6) Reinforcement learning Reinforcement
    learning is a kind of effective decision-making method, which can find the best
    or nearly the best strategy for an agent. However, reinforcement learning is generally
    applicable to the case of small system space or limited network topology. When
    the system complexity is high or the data latitude is high, reinforcement learning
    methods have problems such as dimension disaster and insufficient memory. Starting
    from the topology of WSNs, this paper considers the scheduling problem of data
    transmission in the case of concurrent data, at which time the general reinforcement
    learning method has been difficult to solve. At this point, the deep reinforcement
    learning method combining the powerful information perception ability of deep
    learning and the decision-making ability of reinforcement learning is a new research
    idea. This paper takes an industrial WSNs environment as the research object.
    The real-time data transmission scheduling method is studied to improve the reliability
    and real-time performance of WSNs. Based on the topology structure of WSNs, a
    real-time data transmission scheduling algorithm based on deep Q-learning is proposed
    to solve the problem of concurrent data transmission scheduling in WSNs. A Q-learning
    model was established to comprehensively consider the influences of communication
    constraints and interference between nodes in WSNs, remaining deadline of transmission
    data, remaining hop count, and other factors on data transmission to the destination
    node. By using the reinforcement learning method to determine the sensor nodes
    for data transmission in each time slot, the deep learning method combined with
    experience playback is used to perceive the mapping relationship between system
    state and behavior. Q-learning is used to update the mapping relationship between
    state and behavior, so as to realize the learning of data transmission scheduling
    strategy. An effective data transmission scheduling algorithm is obtained. The
    network performance of this algorithm is simulated and compared with other existing
    algorithms to verify its effectiveness. The main contributions of this paper are
    listed as follows: To solve the problem of concurrent data transmission in WSNs,
    a real-time data transmission scheduling algorithm based on deep Q-learning is
    proposed in this paper. (1) The algorithm comprehensively considers the influence
    of remaining cutoff time, remaining hop count, and unallocated time slot nodes
    in data transmission, defines the reward function and action selection strategy
    of Q-learning, and guides the process of system state information transfer. (2)
    To solve the disaster maintenance problem caused by large-scale system states,
    deep learning and Q-learning are combined, and a multi-layer Stacked Auto Encoder
    (SAE) network model is used to establish the state-action mapping relationship.
    The mapping relationship is updated by the Q-learning algorithm. (3) According
    to the trained SAE network model, the data transmission scheduling strategy of
    the system in different states is obtained, and the simulation results show that
    the strategy is effective. The remainder of this paper is organized as follows.
    In Section 2, the system model of WSNS is presented. The network model, Q-learning
    model, and deep-Q network (DQN) model in this paper are given. In Section 3, the
    optimal action selection strategy, reward mechanism, and state-behavior description
    network are described, and the proposed algorithm is presented in detail. In Section
    4, the simulation results are discussed. Finally, Section 5 draws the conclusion.
    2. System Model At the beginning of this section, we first explain the definition
    of the symbols used later in Table 1. Table 1. Definition of the symbols. 2.1.
    Network Model M sensor nodes and one base station node form a wireless sensor
    network with a known topology. As shown in Figure 1, BS is the base station or
    the destination node, while others are sensor nodes. The sensor nodes periodically
    generate data with different strict deadlines and send it to the base station
    node through data transmission between nodes. The entire network topology can
    be represented by a directed graph 𝐺(𝑉,𝐸, 𝐸 ′ ) . V represents the set of vertices
    of all sensor nodes. E represents the set of all communication links, 𝑒𝑎   
        represents node e sends data to node a, which is called the parent node
    of e. 𝐸 ′ represents the set of all interference edges. Interference edge 𝑎𝑏 
           means that the transmission of node a will interfere with the transmission
    of b, and similarly, the transmission of node b will also interfere with the transmission
    of a. Figure 1. Communication topology of WSNs. Sensor nodes periodically generate
    data, and data transmission is carried out according to a time slot. The data
    packet 𝑃 𝑖 generated by i-th node 𝑣 𝑖 can be expressed as 𝑃 𝑖 =( 𝑇 𝑖 , 𝐻 𝑖 , 𝐷
    𝑖 , 𝜙 𝑖 ) (1) where 𝑇 𝑖 is the packet generation cycle, 𝐷 𝑖 is the packet transfer
    cutoff time, 𝜙 𝑖 is the routing path of the packet, 𝐻 𝑖 represents the total hops
    from the source node to the sink node. The unit of 𝑇 𝑖 and 𝐷 𝑖 are represented
    by the number of time slots. Generally, 𝑇 𝑖 is greater than 𝐻 𝑖 to ensure the
    transmission time required for packets. At any time slot t, the packet contains
    three attributes, which are 𝐶 𝑖 , ℎ 𝑖 , 𝑡 𝑖 . 𝐶 𝑖 indicates the node where the
    data packet resides ( 𝐶 𝑖 ∈ 𝜙 𝑖 ), ℎ 𝑖 indicates the number of hops remaining
    when data are transmitted from the current node to the destination node ( 0< ℎ
    𝑖 ≤ 𝐻 𝑖 ), 𝑡 𝑖 indicates the number of time slots contained in the remaining cutoff
    time of the packet ( 0< 𝑡 𝑖 ≤ 𝑇 𝑖 ). For the data in the process of transmission
    in WSNs, if the data state is 𝑡 𝑖 > ℎ 𝑖 , it means that the data can be transmitted
    to the destination theoretically. If the next time slot is allocated by the system
    for data transfer, the remaining time of the current data transfer status and
    the remaining hops are reduced by one and the data are transmitted to the next
    node. Otherwise, the remaining time of the data transfer status is reduced by
    one. When 𝑡 𝑖 =0 , node 𝑣 𝑖 will generate new data and start to wait for transmission
    scheduling. The initial remaining time 𝑡 𝑖 = 𝑇 𝑖 and the initial remaining hop
    number ℎ 𝑖 = 𝐻 𝑖 . In order to consider the practical applications, the following
    assumptions are assumed: (1) The sensor node cannot transmit and receive data
    at the same time or receive data from more than one node at the same time; (2)
    The node that receives multiple data selects at most one data packet for data
    transmission in each time slot; (3) The data generated periodically by the source
    node has a strict cut-off time limit, and the cut-off time is equal to the data
    generation cycle; (4) In the process of data transmission, if the deadline is
    exceeded, the data will be directly discarded because it has become invalid; (5)
    The probability of success of wireless communication transmission will be affected
    by physical factors such as transmission power, encoding mode, and modulation
    scheme. This paper assumes that if the data are arranged for transmission, the
    probability of success is 1. 2.2. Q-Learning Model The data transmission scheduling
    in WSNs mainly solves the problem of deciding which nodes are scheduled for transmission
    in each time slot. The transmission status and the location of data need to be
    considered. The Q-learning model of WSNs data transmission scheduling problem
    can be represented by (𝑆,𝐴,𝜋,𝑅) . S is the state space, representing the state
    set of all data in WSNs. A is the action space, representing the action set of
    WSNs. 𝜋 is the learning strategy of the agent, and represents the slot allocation
    of WSNs data transmission. R is the agent’s reward, indicating the feedback of
    the agent’s action in the current time slot. (1) System space model The state
    space of the whole WSNs consists of the current state of data generated by all
    nodes in the network, which can be expressed as 𝑆={ 𝑠 1 , 𝑠 2 ,……, 𝑠 𝑀−1 , 𝑠 𝑀
    } . The current state of data generated by any node is 𝑠 𝑖 ={ 𝐶 𝑖 , 𝑡 𝑖 , ℎ 𝑖
    } . Thus, the size of the current state space of data generated by any node is
    𝑇 𝑖 ( 𝐻 𝑖 ) 2 . The size of the state space of the entire system can be expressed
    as ∏ 𝑖=1 𝑀 𝑇 𝑖 ( 𝐻 𝑖 ) 2 . In WSNs, all possible situations of nodes conducting
    data transmission scheduling in each time slot constitute the action space of
    the system, which can be expressed as 𝐴={ 𝑎 1 , 𝑎 2 ,…, 𝑎 𝑀−1 , 𝑎 𝑀 } . For the
    data generated by any node in the current time slot, if the data are transmitted,
    the corresponding action 𝑎 𝑖 is 1; otherwise, it is 0. Regardless of WSNs sensor
    node transmission constraints and assumptions, the maximum movement space of the
    whole system is 2 𝑀 in theory. Thus, the size of the system can be expressed as
    the product of the size of the state space and the size of the action space. In
    such an ample system space, reinforcement learning cannot get an effective scheduling
    strategy. The introduction of deep reinforcement learning can be a good solution
    to the time slot allocation and network control problems of large-scale systems.
    (2) Value function model The goal of reinforcement learning is to achieve mapping
    strategy from environment state to action 𝜋:𝑆→𝐴 . The Q-learning algorithm can
    be regarded as a random expression of value iteration algorithm. Value iteration
    can be expressed by action value function. 𝑉 𝜋 (𝑠) is used to represent the action
    value function of state s performing action a to the next state 𝑠 ′ with probability
    𝑃( 𝑠 ′ |𝑠,𝑎) in the next time slot under strategy 𝜋 . 𝑉 𝜋 (𝑠)= max 𝑎∈𝐴 [𝑅( 𝑠 ′
    |𝑠,𝑎)+𝛾 ∑ 𝑠 ′ ∈𝑠 𝑃( 𝑠 ′ |𝑠,𝑎) 𝑉 𝜋 ( 𝑠 ′ )] (2) where 𝑃( 𝑠 ′ |𝑠,𝑎) represents the
    transition probability that the system performs action a in state s and turns
    to state 𝑠 ′ . 𝑅( 𝑠 ′ |𝑠,𝑎) represents the average reward for state transitions.
    𝛾 is the discount factor, 𝛾∈(0,1) , which reflects the impact of future income
    on the current state. The optimal strategy is to obtain the execution action that
    maximizes the value function. The optimal strategy 𝜋 ∗ (𝑠) can be expressed as
    follows: 𝜋 ∗ (𝑠)=arg 𝑉 ∗(𝜋) (𝑠)= argmax 𝑎∈𝐴 [𝑅( 𝑠 ′ |𝑠,𝑎)+𝛾 ∑ 𝑠 ′ ∈𝑆 𝑃( 𝑠 ′ |𝑠,𝑎)
    𝑉 𝜋 ( 𝑠 ′ )] (3) In the Q-learning model, the Q value update of the system is
    defined as follows: 𝑄 𝑡 ( 𝑠 𝑡 ,𝑎)=(1−∂) 𝑄 𝑡 ( 𝑠 𝑡 ,𝑎)+∂[𝑅( 𝑠 ′ |𝑠,𝑎)+𝛾 ∑ 𝑠 ′ ∈∈𝑆
    𝑃( 𝑠 ′ |𝑠,𝑎) max 𝑎∈𝐴 𝑄 𝑡 ( 𝑠 ′ |𝑠,𝑎)] (4) where ∂∈(0,1) is the learning rate factor.
    The larger ∂ is, the more the system learning process depends on the reward function
    and the value function. The smaller ∂ is, the more the system relies on the accumulated
    learning experience, and the slower the learning rate. The Q-learning algorithm
    maximizes the system utility by calculating and updating the Q value, but 𝑃( 𝑠
    ′ |𝑠,𝑎) is usually unknown, and in the Q-learning algorithm, 𝑅(𝑠,𝑎)+ ∑ 𝑠 ′ ∈𝑠
    𝑃( 𝑠 ′ |𝑠,𝑎) max 𝑎∈𝐴 𝑄 𝑡 ( 𝑠 ′ |𝑠,𝑎) can be directly replaced by an unbiased estimate
    constructed from the current transformation 𝑅 𝑡+1 + max 𝑓∈𝐴 𝑄( 𝑠 𝑡+1 , 𝑎 𝑡 ) ,
    so as to obtain the final Q The value function updates the formula as: 𝑄 𝑡 ( 𝑠
    𝑡 ,𝑎)←(1−∂) 𝑄 𝑡 ( 𝑠 𝑡 ,𝑎)+∂[𝑅( 𝑠 ′ |𝑠,𝑎)+𝛾 max 𝑎∈𝐴 𝑄 𝑡 ( 𝑠 ′ |𝑠,𝑎)] (5) 2.3. DQN
    Network Model The role of the neural network in the DQN network model is to realize
    the supervised learning of WSNs. The general method constructs two Q networks,
    in which the experience pool provides training samples, the loss function is determined
    by the target Q value and the calculated Q value, and then the gradient is calculated,
    using the stochastic gradient descent method (SGD) updates the parameter W and
    the bias b. The DQN network model is shown in Figure 2. Figure 2. DQN network
    topology. Two networks with the same structure but different parameters are established
    in Figure 2 [24]. One network uses the latest parameters to calculate and predict
    the Q value, and the other network uses the parameters before a certain time to
    update the Q value. This can ensure the stability of the target Q value for a
    period of time, reduce the correlation between the current Q value and the target
    Q value to a certain extent, and make the performance of the algorithm more stable.
    The experience pool is also known as experience replay. Its role is not only to
    solve the problem of data correlation but also to provide learning samples. A
    memory bank is established at the beginning of the learning and training process.
    The state, action, reward, and the state of the next time slot after executing
    the current action are stored in the experience pool. Each time a neural network
    is trained, a certain amount of memory data is randomly sampled in batches from
    the experience pool. At the same time, when the experience pool is full, the new
    memory will overwrite the old memory, thus disrupting the order of the original
    data and further weakening the relevance of the data. 3. Proposed Algorithm In
    this section, the algorithm is divided into three parts: optimal action selection
    strategy, reward mechanism, and state-behavior description network. We describe
    the above three parts in Section 3.1, Section 3.2 and Section 3.3, respectively.
    Finally, the overall flow of the algorithm is given in Section 3.4. 3.1. Optimal
    Action Selection Strategy The optimal action selection strategy is used to determine
    the node-set to send. Firstly, the strategy selects the best action for the current
    time slot by exploring the development strategy. Secondly, based on the node where
    the action is located, the most urgent and non-conflicting node-set is constructed.
    (1) Explore development strategies In the process of systematic learning and trial
    and error, it is necessary to balance the relationship between exploration and
    development. The general 𝜀−𝑔𝑟𝑒𝑑𝑑𝑦 strategy is prone to the problem of too fast
    convergence. Development under the condition of insufficient exploration will
    cause the learning process to be too short and the learning results to be seriously
    deviated. Based on the 𝜀−𝑔𝑟𝑒𝑑𝑑𝑦 strategy, this algorithm introduces the Metropolis
    criterion in the simulated annealing algorithm into the execution action selection
    of the exploration and development strategy. Meanwhile, it can be seen from the
    Q learning model that the state space of the whole system explosively expands
    with the increase of the number of nodes, which requires relatively long learning
    times to achieve the ideal training effect. Therefore, segmented exploration and
    development processes are adopted to acquire state and behavior. In the early
    stages of DQN network learning, actions are randomly selected and saved to the
    experience pool before the experience pool is full. Then, based on the exploration
    probability 𝜀 𝑡 , the action selection begins to gradually balance the exploration
    and development process, which can better solve the problem of too fast convergence.
    The exploration probability 𝜀 𝑡 is defined as follows: 𝜀 𝑝 =exp[ −| max 𝑎 0 ∈𝐴
    𝑎_𝑣𝑎𝑙𝑢𝑒(𝑠, 𝑎 0 )| 𝐾 𝑇 𝑘 ] (6) 𝜀 𝑡 =max{ 𝜀 min , 𝜀 𝑝 } (7) 𝜀 𝑝 is the exploration
    probability after the simulated annealing algorithm is introduced, where max𝑎_𝑣𝑎𝑙𝑢𝑒(𝑠,
    𝑎 0 ) is the maximum output value after the state-action mapping in the deep neural
    network, and 𝑎 0 is the action corresponding to the maximum output. 𝑇 is a fixed
    value, 𝐾 is a coefficient, satisfying 𝐾= 𝜆 𝑒 , 𝜆∈(0,1) . e is the number of learning
    times. As the number of learning times increases, the value of 𝐾 𝑇 𝑘 will become
    smaller and smaller, and the value of 𝜀 𝑝 will also become smaller and smaller,
    and the entire exploration process will tend to be stable. 𝜀 min is the given
    minimum exploration probability, which is the lower bound of exploration, 𝜀 𝑡
    is the final exploration probability of the current time slot, and it is the maximum
    value of 𝜀 𝑝 and 𝜀 min . When the best action is selected, to utilize the network’s
    transmission capacity as much as possible, other nodes are selected for concurrent
    transmission. The process is mainly based on the conflict interference matrix
    and the urgency of the data. (2) Concurrent node sets based on the most urgent
    data Although each time slot allows multiple nodes to transmit data, there are
    transmission conflicts between child nodes with the same parent node, and two
    sensor nodes with interference edges cannot perform transmission tasks simultaneously.
    In this algorithm, the deep neural network mapping relation is used to determine
    the most urgent data, and the node where the data resides is the most urgent node.
    Then, other transmission nodes are dynamically selected to construct the most
    urgent non-conflicting node-set and transmit the selected data from the node.
    Definition 1. A conflict interference matrix is used to represent the matrix of
    the conflicted relationship between nodes, where the row number and column number
    respectively represent the number of the corresponding sensor node. If there is
    conflict or interference between nodes, the corresponding matrix element is represented
    by 1; otherwise, it is represented by 0. The conflict interference matrix MC is
    constructed based on the WSNs topology, as shown in Figure 3 is the conflict interference
    matrix based on Figure 1. Figure 3. Conflict interference matrix. Definition 2.
    Data urgency indicates the urgency of data to be sent in a certain time slot,
    represented by ui. It is related to the number of remaining hops hi and the remaining
    deadline ti. The data urgency can be expressed as follows: 𝑢 𝑖 = ℎ 𝑖 /( 𝑡 𝑖 ∗(
    𝑡 𝑖 − ℎ 𝑖 )) (8) The steps to determine the concurrent node set are as follows:
    Step 1: Construct the conflict interference matrix, determine the most urgent
    node N by the best action, and add this node to the concurrent node-set; Step
    2: Add the node (excluding node N) with column coordinates corresponding to the
    value of 0 in the n-th row of matrix MC to the list to be transmitted; Step 3:
    Calculate the urgency of other data on the network. If the node with the highest
    urgency is in the list to be transmitted, add the node to the concurrent node-set.
    Then, remove the node from the list to transfer. If the data are not in the list
    to be transmitted, ignore the data and repeat Step 3. Step 4: If the list to be
    transmitted is not empty, continue step 3 until the list to be transmitted is
    empty and obtain the final concurrent node-set based on the most urgent data.
    Taking Figure 1 and Figure 3 as an example, assuming the current time slot, the
    data 𝑑𝑎𝑡𝑎_𝑔 generated by node g are selected as the most urgent data through the
    exploration and development strategy, and the node where the data 𝑑𝑎𝑡𝑎_𝑔 are currently
    located is b. In step 1, it is determined that node b is added to the concurrent
    node-set. In step 2 and the conflict interference matrix, nodes d, e, i, j, k,
    l, and m are added to the list to be transmitted. In step 3, calculate the data
    state urgency evaluation ct generated by other nodes except the data generated
    by node g, select the data with the highest evaluation value and the node where
    the data are currently located in the transmission list, and add the node to the
    concurrent node-set. Assuming that the node is j, update the transmission queue
    and remove nodes e, i, j, and m. Continue to select the node with the most urgent
    data in the list to be transmitted to join the concurrent node-set and update
    the list to be transmitted. Repeat step 3 until the list to be transmitted is
    empty, then the final of concurrent node-set {𝑏,𝑑,𝑗,𝑘,𝑙} can be obtained. 3.2.
    Reward Mechanism The establishment of the reward function in this section considers
    two factors: the immediate reward of real-time data allocated to the time slot
    and the influence of other data not allocated to the time slot. Instant reward
    r reflects the current priority of the data by considering the remaining time
    of the node and the number of hops remaining for all the data allocated by the
    time slot. The function 𝑅 𝐿 is defined to represent the impact of other data flows
    that are not allocated to time slots at the current time. When the current time
    slots are allocated, the more packets of other data flows are lost, the closer
    the data distance to the discarded state is, and the greater 𝑅 𝐿 is. The reward
    function is shown as 𝑅=𝑟+ 𝑅 𝐿 (9) where r represents the instant reward value
    of all packets allocated to time slots. The instant reward value of each data
    packet allocated to time slots consists of the remaining time of the packet and
    the remaining hops. The smaller the remaining time is, the longer the remaining
    hops are, and the larger the r is, the higher the priority of the current packet
    is. Immediate rewards are defined as follows: 𝑟= ∑ 𝑖=1 𝑛 𝛽 𝑖 ⋅( 𝑘 1 ⋅ ℎ 𝑖 𝑡 𝑖
    + 𝑘 2 ⋅ 1 𝑡 𝑖 − ℎ 𝑖 +1 ) (10) where 𝑡 𝑖 ≥ ℎ 𝑖 , and n represents the number of
    packets to obtain slot assignments. If data i are transmitted in the current time
    slot and arrives at the destination node, the reward is enhanced, 𝛽 𝑖 ∈[1,1.5)
    , otherwise 𝛽 𝑖 =1 . 𝑘 1 , 𝑘 2 satisfies 𝑘 1 >0, 𝑘 2 <1 , and 𝑘 1 + 𝑘 2 =1 . Obviously,
    r is inversely proportional to the remaining packet cutoff time 𝑡 𝑖 and is directly
    proportional to the remaining hop number ℎ 𝑖 of the packet. Both ℎ 𝑖 / 𝑡 𝑖 and
    𝑡 𝑖 − ℎ 𝑖 can reflect the degree of urgency of data. ℎ 𝑖 / 𝑡 𝑖 reflects the degree
    of urgency of data through ratio relationship without considering the influence
    of actual remaining time slots. 𝑡 𝑖 − ℎ 𝑖 reflects the influence of actual remaining
    time slots. 𝑅 𝐿 is the reward function of behavior, which reflects the negative
    reward. When the system is in state 𝑠 𝑖 and performs an action to enter the next
    state 𝑠 𝑖+1 , it is assumed that among all data packets in the system, 𝐿 𝑖0 data
    packets meet the transmission state of 𝑡 𝑖 − ℎ 𝑖 =−1 , 𝐿 𝑖1 data packets meet
    the transmission state of 𝑡 𝑖 − ℎ 𝑖 =0 , and 𝐿 𝑖2 data packets meet the transmission
    state of 𝑡 𝑖 − ℎ 𝑖 =1 . 𝑅 𝐿 =−( 𝜌 1 𝐿 𝑖0 + 𝜌 2 𝐿 𝑖1 + 𝜌 3 𝐿 𝑖2 ) (11) where 𝐿
    𝑖0 , 𝐿 𝑖1 , and 𝐿 𝑖2 are defined as above, 𝜌 1 , 𝜌 2 , and 𝜌 3 are relevant discount
    parameters, satisfying 0< 𝜌 1 , 𝜌 2 , 𝜌 3 <1 , 𝜌 1 > 𝜌 2 > 𝜌 3 , and 𝜌 1 + 𝜌 2
    + 𝜌 3 =1 . The final reward function is expressed as follows: 𝑅= ∑ 𝑖=1 𝑛 𝛽 𝑖 ⋅(
    𝑘 1 ⋅ ℎ 𝑖 𝑡 𝑖 + 𝑘 2 ⋅ 1 𝑡 𝑖 − ℎ 𝑖 +1 )−( 𝜌 1 𝐿 𝑖0 + 𝜌 2 𝐿 𝑖1 + 𝜌 3 𝐿 𝑖2 ) (12)
    The partial separation and combination of reward parameters and reward factors
    allow the reward function to adjust the external weight. The behavior of the whole
    system is determined by the initial state of the data flow and the reward function
    of the behavior. The system can converge to the ideal equilibrium point in a given
    environment. 3.3. State-Behavior Description Network The deep neural network is
    a kind of neural network containing multiple hidden layers, each of which can
    perform the nonlinear transformation on the output of the previous layer. Therefore,
    compared with a shallow layer network, a deep neural network has more excellent
    expression ability and can learn more complex function relations in a more compact
    and concise way. The Stacked Auto Encoder (SAE) deep neural network consists of
    multiple layers of sparse autoencoder neural networks. The general idea of the
    training process is unsupervised pre-training and supervised fine-tuning. In this
    network, in the unsupervised training stage, the hidden feature representation
    learned by the previous layer of autoencoders is used as the input of the latter
    layer of autoencoders. The training process of the parameters of each layer will
    keep the parameters of other layers fixed. After the above-mentioned pre-training
    process is completed, in the supervised fine-tuning stage, using the previously
    trained parameters as the initial value of the network, the parameters can also
    be adjusted, and then continue to train the neural network. This algorithm adopts
    the multi-layer stacked self-encoding deep neural network model to train and realize
    the mapping relationship between the system state and behavior, which can quickly
    obtain the optimal decision-making behavior. The structure of the SAE model is
    shown in Figure 4. The input layer of the model corresponds to the state information
    of the system, and the number of neurons in the input layer is 3⋅𝑀 . The input
    vector is composed of the current transmission state of the data generated by
    all nodes of the WSNs, including the node where the data are currently located,
    the remaining hops, and the remaining deadline. All input vectors are denoted
    as 𝑖𝑛𝑝𝑢𝑡=[ 𝑐 1 … 𝑐 𝑀 ℎ 1 … ℎ 𝑀 𝑡 1 … 𝑡 𝑀 ] . The output layer represents the action
    selection information of the model, and each output corresponds to each node to
    generate data in the system as the evaluation of the most urgent data in the next
    time slot, so the number of neurons in the output layer is M. The output vector
    is 𝑜𝑢𝑡𝑝𝑢𝑡=[ 𝑎 1 … 𝑎 𝑀 ] . The hidden layer is multi-layered, and the number of
    neurons in each layer is related to the number of sensor nodes in the network.
    Figure 4. SAE network topology. The neurons of the hidden layer in the SAE model
    are activation functions used for the nonlinear transformation of the input information.
    Common activation functions include ReLU function, sigmoid function, and tanh
    function. The nonlinear sigmoid function has a large signal gain in the central
    area and relatively small signal gain on both sides, which has a good effect on
    the feature space mapping of the signal. The activation function of this algorithm
    selects the sigmoid function. The loss function of the overall sample during the
    training process is denoted as 𝐿(𝑊,𝑏) . 𝐿(𝑊,𝑏)= 1 𝑁 ∑ 𝑖=1 𝑁 𝑙(𝑊,𝑏) (13) where
    𝑁 is the total number of input samples, 𝑙(𝑊,𝑏) is the loss function of a single
    sample, and the calculation expression of 𝑙(𝑊,𝑏) is as follows: 𝑙(𝑊,𝑏)= ⎧ ⎩ ⎨
      1 2 ( 𝑞 𝑒𝑣𝑎𝑙 − 𝑞 𝑡𝑔𝑡 ) 2 ,| 𝑞 𝑒𝑣𝑎𝑙 − 𝑞 𝑡𝑔𝑡 |≤1 | 𝑞 𝑒𝑣𝑎𝑙 − 𝑞 𝑡𝑔𝑡 |− 1 2 ,      𝑜𝑡ℎ𝑒𝑟𝑤𝑖𝑠𝑒
    (14) where 𝑞 𝑒𝑣𝑎𝑙 represents the calculated Q value, and 𝑞 𝑡𝑔𝑡 represents the
    target Q value. When the forward propagation process is over, the parameter W
    and the bias b are updated using the gradient descent method. 3.4. Proposed Algorithm
    Description The proposed real-time data transmission scheduling algorithm based
    on deep Q-learning (RS-DQL) comprehensively considers the influences of communication
    constraints and interference between sensor nodes in WSNs, the remaining cutoff
    time, and the variation of the remaining hop count in the process of data transmission
    and scheduling. It uses deep neural networks to evaluate state-action mapping
    relationships and is updated by Q-learning methods. In addition, the empirical
    replay was introduced to reduce data relevance and adapt to the randomness of
    the training process. The idea of RS-DQL algorithm is as follows: Firstly, the
    data transmission and communication interference model of WSNs is constructed
    to determine the concurrent node-set based on the most urgent data. The Q-learning
    algorithm is used to acquire partial state transfer information (including the
    current state, the action to be performed, the reward to be obtained, and the
    next state) and store it into the experience pool after a certain time slot. This
    process does not train the SAE network model. After a period of time, samples
    are extracted from the experience pool and combined with the DQN network model
    for supervised training of the SAE network. In the process of network model learning
    and training, the system gradually rewards the actions with less packet loss for
    data transmission to achieve an approximate optimal scheduling algorithm. The
    scheduling algorithm flow of RS-DQL is shown in Figure 5. Firstly, before the
    experience pool is full, the SAE network model randomly selects actions. The Q-learning
    algorithm learns a part of the state and action data based on the selected actions.
    After the experience pool is full, the SAE network is gradually trained. Its parameters
    are updated with supervision during the learning process. When the system shifts
    to the hidden state, the SAE network recommends the system’s actions in this state,
    performs the actions, updates the Q value network, etc. Repeat the learning process
    until the loss function reaches the target accuracy or the expected number of
    training sessions. Finally, the data transmission scheduling of the system is
    carried out by the state-action mapping in the trained SAE network model. Figure
    5. Flow chart of the RS-DQL algorithm. The process description of the real-time
    data transmission scheduling algorithm based on deep Q-learning can be obtained
    from the above system model and scheduling strategy. However, this algorithm studies
    the scheduling problem of multiple concurrent data transmission in WSNs. How to
    allocate data transmission tasks in each time slot is related to behavior acquisition
    and training effect in the process of deep Q-learning. According to the exploration
    and development strategy, the most urgent data are first determined as the current
    time slot execution action a. Based on the most urgent data and system status,
    multiple data that can execute the transmission task simultaneously in the current
    time slot are determined. Add a to the waiting queue, and then select the data
    that do not conflict with all data transmission in the waiting queue according
    to the degree of urgency. The data that do not conflict with other data transmission
    in the waiting queue are selected repeatedly until the maximum amount of data
    transmission is reached. The state process of system state information is guided
    by action strategy. SAE network model establishes the mapping relationship between
    states and actions. Finally, the DQN network model is used for training to obtain
    the final node scheduling strategy. The specific algorithm description is shown
    in Algorithm 1. Algorithm 1 RS-DQL algorithm 1: Randomly initialize the parameters,
    import the WSNs environment, 𝑒𝑝𝑖𝑠𝑜𝑑 𝑒 1 =1  2: for episode = 1 to M do 3:    Initialize
    the current state s, time slot number T, 𝑒𝑝𝑖𝑠𝑜𝑑 𝑒 2 =1  4:    while  𝑒𝑝𝑖𝑠𝑜𝑑 𝑒
    2 <𝑇 , do 5:       Action 𝑎 is determined according to the exploration and development
    strategy, and it is added to the transmission waiting queue L 6:       Add the
    remaining theoretically reachable data (𝑡≥ℎ ) without conflicting data transmissions,
    𝑤=100, 𝑎 1 =−1  7:       if  𝐿 ′ is not empty do 8:         Take data 𝑖 in turn
    from 𝐿 ′ and calculates ℎ 𝑖 /( 𝑡 𝑖 ⋅( 𝑡 𝑖 − ℎ 𝑖 ))  9:         if  ℎ 𝑖 /( 𝑡 𝑖
    ⋅( 𝑡 𝑖 − ℎ 𝑖 ))<𝑤  and   𝑡 𝑖 ≥ ℎ 𝑖 , do 10:           𝑎 1 =𝑖, 𝑤= ℎ 𝑖 /( 𝑡 𝑖 ⋅(
    𝑡 𝑖 − ℎ 𝑖 ))  11:        else return to step 7 12:      end if 13:        if  𝑎
    1 >0 do 14:           Add  𝑎 1 to queue L, and return to Step 6 15:        else
    Determine the transmission queue L 16:        end if 17:       Perform the action
    a, calculate the reward R, and move to the next state 𝑠 ′  18:      Put  (𝑠,𝑎,𝑟,
    𝑠 ′ ) into the experience pool 19:      if The experience pool is full do 20:        Enter
    the learning process and calculate 𝑞 𝑒𝑣𝑎𝑙 , 𝑞 𝑡𝑔𝑡 , 𝑙𝑜𝑠𝑠  21:        if Current
    loss is minimum do 22:            Update loss and store the network parameter
    model 23:        end if 24:         𝑠= 𝑠 ′ , 𝑒𝑝𝑖𝑠𝑜𝑑 𝑒 2 +=1  25:      end if 26:    end
    while 27:    if Loss meets the accuracy requirements do 28:      break 29:    end
    if 30:     𝑒𝑝𝑖𝑠𝑜𝑑 𝑒 1 +=1  31: end for 32: The training is completed and the final
    SAE network parameter model is obtained 33: The node scheduling strategy was obtained
    by importing WSNs environment and SAE network parameter model 4. Simulation Results
    The simulation experiment considers the network performance of WSNs data packets
    with different random deadlines for transmission scheduling. The objective is
    to minimize the number of lost packets (that is, the number of packets that are
    discarded when the remaining deadline is less than the remaining hop count during
    data transmission). In the simulation experiment, a long time slot is taken to
    analyze and compare the number of lost packets in this time slot for convenient
    comparison. Other parameters of the simulation are shown in Table 2. Table 2.
    Simulation parameters. The real-time data transmission scheduling algorithm based
    on deep Q-learning is named the RS-DQL algorithm. There are two algorithms for
    comparison, including the classical EDF algorithm and an enhanced dynamic multi-priority
    data scheduling algorithm (EDP algorithm) [25]. The idea of the EDF algorithm
    is the earliest deadline first. The transmission queue of each time slot system
    is composed of multiple non-conflicting nodes with the shortest deadline. The
    idea of the EDP algorithm is to divide priority queues for data characteristics
    in the system, such as emergency data and periodic data. In the same queue, the
    priority of data transmission is determined according to the relationship between
    the remaining time of the current transmission state of different data and the
    remaining hop number. This chapter analyzes the network performance comparison
    between the RS-DQL algorithm and the other two algorithms under different conditions
    such as data deadline and the number of network nodes. In Table 3, the network
    topology of the simulation experiment is based on the communication interference
    diagram of WSNs sensor nodes in Figure 1. The data generation cycle of each sensor
    node is randomly set as 1.5 to 3.5 times the total hop number of sensor nodes.
    Therefore, small multiples represent short packet cutoff time, and large multiples
    represent long packet cutoff time. As shown in the table, the performance of the
    RS-DQL algorithm is significantly better than the other two algorithms, followed
    by the EDP algorithm. The scheduling performance of the EDF algorithm is nearly
    half of that of the RS-DQL algorithm, and it is the worst among the feasible algorithms.
    Table 3. Average number of lost packets for different algorithms. Figure 6 considers
    the changes in packet loss of the three algorithms as the size of the data generation
    cycle of the sensor node is an integer multiple of the total hop number of the
    node. In WSNs, the generation period of sensor node data is increased by 1.5 to
    4.5 times the total hop count of the node. As the data generation period lengthens,
    the packet loss of the three algorithms decreases. The performance of the EDP
    algorithm is poor before 2.5 times, and is basically the same as the RS-DQL algorithm
    after 2.5 times. When the multiple is 4, the number of packets lost by EDP and
    RS-DQL is 0. However, the RS-DQL algorithm has the best performance and is more
    stable in the whole process. EDP algorithm has the largest variation with the
    increase in the data generation cycle. In contrast, the EDF algorithm has the
    lowest overall performance. Figure 6. The number of lost packets as the data generation
    period increases. Figure 7 considers the changes of packet loss of the three algorithms
    as the number of sensor nodes increases from 5 to 25 in the case that the data
    generation cycle in WSNs is 3 times the total hop number between sensor nodes
    and destination nodes. As the number of nodes increases, the performance of the
    EDP algorithm is similar to the RS-DQL algorithm. Although the EDP algorithm has
    a good advantage when the data generation cycle of sensor nodes is a large integer
    multiple of the total hop number of data transmission, such as 3 times or more,
    the RS-DQL algorithm is still superior to EDP algorithm in overall network performance.
    The number of loss packets of the EDF algorithm is always high. When the data
    generation cycle is an integer multiple of the total hop number, the disadvantage
    of the EDF algorithm will be magnified. Therefore, the EDP and RS-DQL algorithms
    are better than the EDF algorithm. Figure 7. The number of lost packets as the
    sensor node increases. Figure 8 considers the changes of packet loss of the three
    algorithms in WSNs as the number of nodes gradually increases from 5 to 25. At
    this point, the generation period of sensor node data is a random value between
    1.5 times and 3.5 times the total node hops. As the number of nodes increases,
    the number of lost packets of the EDF algorithm changes almost linearly. However,
    the EDP algorithm is not stable. With the increase of sensor nodes to 20, the
    increase of packet loss of this algorithm is significantly more than the other
    two algorithms. This indicates that the algorithm has inferior performance in
    WSNs with a large number of nodes and random deadlines. The RS-DQL algorithm is
    stable, and the number of lost packets is always the smallest, and the increase
    rate of lost packets is relatively stable. Figure 8. The number of lost packets
    under random data generation period. It is worth noting that although the simulation
    results in this paper are based on the topology in Figure 1, the strategies proposed
    in this paper are also applicable to other structures. When the topology structure
    of the network changes, the conflict interference matrix of Figure 3 needs to
    be calculated according to the topology structure. Then, the network is retrained
    according to the process in Section 3.4, and the algorithm proposed in this paper
    can be used in the new topology after the training is completed. The RS-DQL algorithm
    proposed in this paper obtains the most urgent data through the state-behavior
    description relationship of neural network in its Q-learning part. According to
    the network topology and data urgency, the concurrent node set based on the most
    urgent data is determined, so as to obtain the optimal action selection strategy.
    In the reward function formulation part, the goal is to transmit as much data
    as possible in WSNs to the destination node within its deadline. Consider the
    influence of factors such as communication constraints between nodes, data remaining
    deadline and remaining hops, and give reward and punishment feedback after the
    agent performs the action. In the deep learning part, a DQN network model is built.
    The SAE network model is used to establish the mapping relationship between state
    and behavior. The data transmission slot scheduling strategy of sensor nodes is
    obtained through DQN network model training. 5. Conclusions This paper mainly
    studies the data transmission scheduling strategy in WSNs. It proposes a real-time
    data transmission scheduling algorithm for WSNs based on deep Q-learning in the
    case of parallel data transmission in wireless sensor networks. The proposed algorithm
    solves the data transmission scheduling problem of WSNs with strict deadlines
    and minimizes the number of lost packets. The deep Q-learning method is introduced
    into the field of WSNs, and its network performance is improved and optimized.
    However, there are still problems to be studied in the future. The construction
    and training of deep learning model is very critical and challenging. Although
    the SAE network model built in this paper can improve the network performance
    of WSNs after training, the DQN network model used is relatively simple. In the
    follow-up research, we can consider optimizing the DQN network model, and there
    is more research work for the setting of relevant parameters. In addition, the
    simulation experiment part of this paper was realized by simulation on the computer
    side. It uses a relatively ideal network environment, which deviates from the
    characteristics of the actual application scenario. In the future, hardware equipment
    can be used to further improve the simulation part. Author Contributions Conceptualization,
    C.W. and A.Z.; software, A.Z. and M.S.; validation, Z.L. and Y.C.; data curation,
    A.Z., M.S. and Y.C.; writing—original draft preparation, A.Z. and J.W.; writing—review
    and editing, M.S. and C.W.; project administration and funding acquisition, C.W.
    All authors have read and agreed to the published version of the manuscript. Funding
    This work was supported by the National Key R&D Program of China (2017YFC0804400,
    2017YFC0804405) and the Beijing–Tianjin–Hebei collaborative innovation community
    construction project (19240407D). Data Availability Statement The data presented
    in this study are available on request from the corresponding author. The data
    are not publicly available due to privacy. Conflicts of Interest The authors declare
    no conflict of interest. References Yick, J.; Mukherjee, B.; Ghosal, D. Wireless
    sensor network survey. Comput. Netw. 2008, 52, 2292–2330. [Google Scholar] [CrossRef]
    Niu, J.; Cheng, L.; Gu, Y.; Shu, L.; Das, S.K. R3E: Reliable Reactive Routing
    Enhancement for Wireless Sensor Networks. IEEE Trans. Ind. Inform. 2013, 10, 784–794.
    [Google Scholar] [CrossRef] Mohamed, K.; Nader, M. Real-time scheduling for wireless
    networks with random deadlines. In Proceedings of the 2017 IEEE 13th International
    Workshop on Factory Communication Systems, Trondheim, Norway, 31 May–2 June 2017;
    pp. 1–9. [Google Scholar] Gungor, V.C.; Hancke, G.P. Industrial Wireless Sensor
    Networks: Challenges, Design Principles, and Technical Approaches. IEEE Trans.
    Ind. Electron. 2009, 56, 4258–4265. [Google Scholar] [CrossRef] [Green Version]
    Rym, C.; Sebastien, B.; Mohamed, A. Exploitation of the EDF Scheduling in the
    Wireless Sensors Networks. Int. J. Meas. Technol. Instrum. Eng. 2011, 1, 14–27.
    [Google Scholar] Oh, H.; Azad, M. A Big Slot Scheduling Algorithm for the Reliable
    Delivery of Real-Time Data Packets in Wireless Sensor Networks; Springer: New
    Delhi, India, 2016. [Google Scholar] Saifullah, A.; Xu, Y.; Lu, C.; Chen, Y.X.
    Real-Time Scheduling for WirelessHART Networks. In Proceedings of the 2010 31st
    IEEE Real-Time Systems Symposium, San Diego, CA, USA, 30 November–3 December 2010;
    pp. 150–159. [Google Scholar] Akkaya, K.; Demirbas, M.; Aygun, R.S. The impact
    of data aggregation on the performance of wireless sensor networks. Wirel. Commun.
    Mob. Comput. 2008, 8, 171–193. [Google Scholar] [CrossRef] Kadam, K.; Srivastava,
    N. Application of machine learning (reinforcement learning) for routing. In Proceedings
    of the Wireless Sensor Networks (WSNs) International Symposium on Physics & Technology
    of Sensors, Pune, India, 7 March 2012; pp. 349–352. [Google Scholar] Brar, G.S.;
    Rani, S.; Chopra, V.; Malhotra, R.; Song, H.; Ahmed, S.H. Energy Efficient Direction-Based
    PDORP Routing Protocol for WSN. IEEE Access 2016, 4, 3182–3194. [Google Scholar]
    [CrossRef] Arroyo-Valles, R.; Alaiz-Rodriguez, R.; Guerrero-Curieses, A.; Cid-Sueiro,
    J. Q-Probabilistic Routing in Wireless Sensor Networks. In Proceedings of the
    International Conference on Intelligent Sensors, Sensor Networks and Information,
    Melbourne, Australia, 3 December 2007; pp. 1–6. [Google Scholar] Khan, F.; Memon,
    S.; Jokhio, S.H. Support vector machine based energy aware routing in wireless
    sensor networks. In Proceedings of the International Conference on Robotics &
    Artificial Intelligence, Islamabad, Pakistan, 1–2 November 2016; pp. 1–4. [Google
    Scholar] Forster, A.; Murphy, A.L. CLIQUE: Role-Free Clustering with Q-Learning
    for Wireless Sensor Networks. In Proceedings of the IEEE International Conference
    on Distributed Computing Systems, Montreal, Canada, 22–26 June 2009; pp. 441–449.
    [Google Scholar] Zhang, P.; Nevat, I.; Peters, G.; Xiao, G.; Pink, T.H. Event
    Detection in Wireless Sensor Networks in Random Spatial Sensors Deployments. IEEE
    Trans. Signal Proces. 2015, 63, 6122–6135. [Google Scholar] [CrossRef] Lee, K.S.;
    Lee, S.R.; Kim, Y.; Lee, C.G. Deep learning–based real-time query processing for
    wireless sensor network. Int. J. Distrib. Sens. Netw. 2017, 13, 1550147717707896.
    [Google Scholar] [CrossRef] [Green Version] Chipara, O.; Lu, C.; Roman, G.C. Real-Time
    Query Scheduling for Wireless Sensor Networks. IEEE Trans. Comput. 2013, 62, 1850–1865.
    [Google Scholar] [CrossRef] [Green Version] Hossain, A.; Soh, W.S. A survey of
    calibration-free indoor positioning systems. Comput. Commun. 2015, 66, 1–13. [Google
    Scholar] [CrossRef] Wang, J.; Ghosh, R.K.; Das, S.K. A survey on sensor localizatio.
    J. Control. Theory Appl. 2010, 8, 2–11. [Google Scholar] [CrossRef] Nasipuri,
    A.; Li, K. A directionality based location discovery scheme for wireless sensor
    networks. In Proceedings of the 1st ACM International Workshop on Wireless Sensor
    Networks and Applications, New York, NY, USA, 28 September 2002; pp. 105–111.
    [Google Scholar] Chu, Y.; Mitchell, P.D.; Grace, D. ALOHA and Q-Learning based
    medium access control for Wireless Sensor Networks. In Proceedings of the International
    Symposium on Wireless Communication Systems, Paris, France, 28–31 August 2012;
    pp. 511–515. [Google Scholar] Hoesel, L.; Havinga, P. A TDMA-based MAC protocol
    for WSNs. International Conference on Embedded Networked Sensor Systems. In Proceedings
    of the 2nd International Conference on Embedded Networked Sensor Systems, Baltimore,
    MD, USA, 3–5 November 2004; pp. 303–304. [Google Scholar] Zhuo, S.; Song, Y.Q.;
    Wang, Z.; Luís, A. A Traffic Adaptive Multi-channel MAC Protocol with Dynamic
    Slot Allocation for WSNs. IEEE Trans. Mob. Comput. 2016, 15, 1600–1613. [Google
    Scholar] [CrossRef] Kosunalp, S. MAC Protocols for Energy Harvesting Wireless
    Sensor Networks: Survey. ETRI J. 2015, 37, 804–812. [Google Scholar] [CrossRef]
    Mnih, V.; Kavukcuoglu, K.; Silver, D.; Rusu, A.A.; Veness, J.; Bellemare, M.G.;
    Graves, A.; Riedmiller, M.; Fidjeland, A.K.; Ostrovski, G.; et al. Human-level
    control through deep reinforcement learning. Nature 2015, 518, 529–533. [Google
    Scholar] [CrossRef] [PubMed] Wang, Y.; Sheng, Z. An Enhanced Dynamic Priority
    Packet Scheduling Algorithm in Wireless Sensor Networks. In Proceedings of the
    International Conference on Computer Modeling and Simulation, Cambridge, UK, 6–8
    April 2016; pp. 311–316. [Google Scholar]  Publisher’s Note: MDPI stays neutral
    with regard to jurisdictional claims in published maps and institutional affiliations.  ©
    2022 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open
    access article distributed under the terms and conditions of the Creative Commons
    Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/). Share
    and Cite MDPI and ACS Style Zhang, A.; Sun, M.; Wang, J.; Li, Z.; Cheng, Y.; Wang,
    C. Real-Time Data Transmission Scheduling Algorithm for Wireless Sensor Networks
    Based on Deep Q-Learning. Electronics 2022, 11, 1877. https://doi.org/10.3390/electronics11121877
    AMA Style Zhang A, Sun M, Wang J, Li Z, Cheng Y, Wang C. Real-Time Data Transmission
    Scheduling Algorithm for Wireless Sensor Networks Based on Deep Q-Learning. Electronics.
    2022; 11(12):1877. https://doi.org/10.3390/electronics11121877 Chicago/Turabian
    Style Zhang, Aiqi, Meiyi Sun, Jiaqi Wang, Zhiyi Li, Yanbo Cheng, and Cheng Wang.
    2022. \"Real-Time Data Transmission Scheduling Algorithm for Wireless Sensor Networks
    Based on Deep Q-Learning\" Electronics 11, no. 12: 1877. https://doi.org/10.3390/electronics11121877
    Note that from the first issue of 2016, this journal uses article numbers instead
    of page numbers. See further details here. Article Metrics Citations Crossref   1
    Scopus   1 Web of Science   1 Google Scholar   [click to view] Article Access
    Statistics Article access statistics Article Views 29. Dec 8. Jan 18. Jan 28.
    Jan 7. Feb 17. Feb 27. Feb 8. Mar 18. Mar 0 500 1000 1500 For more information
    on the journal statistics, click here. Multiple requests from the same IP address
    are counted as one view.   Electronics, EISSN 2079-9292, Published by MDPI RSS
    Content Alert Further Information Article Processing Charges Pay an Invoice Open
    Access Policy Contact MDPI Jobs at MDPI Guidelines For Authors For Reviewers For
    Editors For Librarians For Publishers For Societies For Conference Organizers
    MDPI Initiatives Sciforum MDPI Books Preprints.org Scilit SciProfiles Encyclopedia
    JAMS Proceedings Series Follow MDPI LinkedIn Facebook Twitter Subscribe to receive
    issue release notifications and newsletters from MDPI journals Select options
    Subscribe © 1996-2024 MDPI (Basel, Switzerland) unless otherwise stated Disclaimer
    Terms and Conditions Privacy Policy"'
  inline_citation: '>'
  journal: Electronics (Switzerland)
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Real-Time Data Transmission Scheduling Algorithm for Wireless Sensor Networks
    Based on Deep Q-Learning
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Vanitha M.
  - Akash N.
  - Vikas P.
  - Kumar J.D.
  citation_count: '0'
  description: IoT technologies let non-computer devices act smartly and collaborate.
    They present many challenges and necessitate specialised standards and communication
    protocols. This includes Zigbee, a low-power, short-range, energy-efficient network,
    and LoRa, a long-range network with comparable energy efficiency. ZigBee and LoRa
    parameters are thoroughly analysed. The thesis suggests clustering star-based
    LoRa networks to conserve energy. The thesis has three goals. Analyze IoT communication
    parameters and factors to meet application QoS requirements. Real-time data transmission
    requires more complex, scalable IoT architecture. Conventional IoT architectures
    are unsuitable for real-time applications that require timely data transmission
    to avoid casualties. Appropriate and cost-effective technologies are needed as
    IoT applications grow. IoT applications' two most significant aspects are network
    efficiency and energy conservation. Since many parameters affect communications,
    Canonical Correlation Analysis (CCA) has been adopted to identify primary and
    secondary significant factors in the LoRa network. Bayesian Belief Nets (BBNs)
    are applied to determine the cause of low network efficiency and predict values
    of independent variables for the suitable scenario. This motivates us to introduce
    the multi-hop clustering concept in LoRa technology to reduce the overall energy
    consumption in LoRa networks. One of the big problems is handling the deluge of
    data generated by IoT devices. Hence, a proposal to develop algorithms for pre-collection
    data packet aggregation in LoRa technology. We propose a data packet aggregation
    scheme for LoRa networks and compare it with existing equivalent algorithms. We
    also present a scalable energy-conserving architecture for Wireless Body Area
    Network (WBAN) based on the MANET-LoRa framework by applying a data aggregation
    scheme.
  doi: 10.1109/ICECA55336.2022.10009631
  full_citation: '>'
  full_text: '>

    "This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org
    IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal
    Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln
    Sign Out All Books Conferences Courses Journals & Magazines Standards Authors
    Citations ADVANCED SEARCH Conferences >2022 6th International Confer... An Effective
    Approach on Clustering and Data Aggregation for the application of Internet of
    Things in Long Range Networks Publisher: IEEE Cite This PDF M. Vanitha; Akash
    N; Panjagala Vikas; Dhinesh Kumar J All Authors 53 Full Text Views Abstract Document
    Sections I. Introduction II. MANET IoT Architecture III. Proposed MANET IoT Architecture
    IV. Results and Discussions V. Conclusion Authors Figures References Keywords
    Metrics Abstract: IoT technologies let non-computer devices act smartly and collaborate.
    They present many challenges and necessitate specialised standards and communication
    protocols. This includes Zigbee, a low-power, short-range, energy-efficient network,
    and LoRa, a long-range network with comparable energy efficiency. ZigBee and LoRa
    parameters are thoroughly analysed. The thesis suggests clustering star-based
    LoRa networks to conserve energy. The thesis has three goals. Analyze IoT communication
    parameters and factors to meet application QoS requirements. Real-time data transmission
    requires more complex, scalable IoT architecture. Conventional IoT architectures
    are unsuitable for real-time applications that require timely data transmission
    to avoid casualties. Appropriate and cost-effective technologies are needed as
    IoT applications grow. IoT applications'' two most significant aspects are network
    efficiency and energy conservation. Since many parameters affect communications,
    Canonical Correlation Analysis (CCA) has been adopted to identify primary and
    secondary significant factors in the LoRa network. Bayesian Belief Nets (BBNs)
    are applied to determine the cause of low network efficiency and predict values
    of independent variables for the suitable scenario. This motivates us to introduce
    the multi-hop clustering concept in LoRa technology to reduce the overall energy
    consumption in LoRa networks. One of the big problems is handling the deluge of
    data generated by IoT devices. Hence, a proposal to develop algorithms for pre-collection
    data packet aggregation in LoRa technology. We propose a data packet aggregation
    scheme for LoRa networks and compare it with existing equivalent algorithms. We
    also present a scalable energy-conserving architecture for Wireless Body Area
    Network (WBAN) based on the MANET-LoRa framework by applying a data aggregation
    scheme. Published in: 2022 6th International Conference on Electronics, Communication
    and Aerospace Technology Date of Conference: 01-03 December 2022 Date Added to
    IEEE Xplore: 16 January 2023 ISBN Information: DOI: 10.1109/ICECA55336.2022.10009631
    Publisher: IEEE Conference Location: Coimbatore, India SECTION I. Introduction
    Internet of things is a system consisting of embedded devices capable of sensing
    environments and sending data via network technology without human intervention.
    As most objects are getting connected in this system, it has been forecasted that
    by 2030 more than 25.4 billion IoT devices will be interconnected at a global
    scale. According to the IDC report, it is estimated that the amount of data created
    by IoT devices would have reached 73.1 ZB (zettabytes) by 2025. With IoT growing
    faster, network technologies are also evolved day by day. IoT has been involved
    in various applications such as smart healthcare, smart parking, smart wearables,
    smart agriculture, smart cities, industrial automation, smart transportation,
    and smart grid. MANET embraces its characteristics of self-organization, self-healing
    network, and the ability to work in less network facilitated areas. MANET nodes
    that can freely move in the environment. It is eminent that a Wireless sensor
    network (WSN) is the heart core technology of IoT for data collection; however,
    WSN devices are restricted with limited power and memory consumption. As MANET
    systems focus on the opting best path to route the data (network discovery), WSN
    emphasizes efficient energy consumption of nodes. Hence, it is not exaggerated
    to say that the interconnection of MANET and WSN with IoT infrastructure properties
    opens a new paradigm in MANET-IoT systems [1]. MANETs are is used in Military
    sector, Rescue operation, Intelligent transport system. A MANET-IoT system is
    the junction of MANET, WSN, and the Internet of Things [2]. The IoT application''s
    performance is relayed on the network parameters. Also, some aspects have to be
    considered to develop an efficient IoT application, like scalable architecture,
    security, integrity, real-time data processing, and better quality of services
    (QoS). Better quality of service (QoS) indicates controlled data traffic and ensures
    the good performance of critical applications with limited network capacity by
    managing packet loss and reducing latency and jitters in the network connection.
    QoS is measured with bandwidth (throughput), latency (delay), jitter (variance
    in latency), and error rate. Extensive work has been done for better QoS in IoT
    applications whereas analysis of network parameters and QoS for LoRa (Long Range)
    technology is very limited. Maintain a good trade-off between IoT applications
    and energy efficiency with LoRa technology [2]. When devices have more data packets
    to transfer, chances are getting high of more congestion and traffic in the network.
    There is a need of controlling data traffic mechanisms in LoRa networks for good
    quality metrics like less delay, high through, high PDR, and less energy consumption.
    SECTION II. MANET IoT Architecture While each Internet of Things application is
    unique, the foundation for each architecture, as well as the fundamental data
    process flow, appears some-what similar [5]. The design objective of IoT architecture
    is to reuse functional components of architecture if possible. The basic high-level
    M2M (Machine to Machine) IoT architecture was developed by The European Telecommunications
    Standards Institute (ETSI) in 2012. Figure 1 presents the ETSI M2M High-Level
    Architecture. Fig 1. ETSI M2M high-level architecture [3] Show All This architecture
    displays functional groups that are related to physical infrastructure and combines
    a topological view with a functional view [3]. Additionally, this architecture
    also incorporates a view of the system as a whole. (For example, M2M devices and
    gateways) This architecture primarily defines two different domains, the first
    of which is the network domain, the second of which is the device domain, and
    the third of which is the gateway domain. When attempting to differentiate the
    capabilities of the physical layer and those of the access network, there is a
    thin conceptual line that separates these two domains. This line can be thought
    of as a boundary. In the context of the Internet of Things, the device and gateway
    categories refer to the physical components of the network, such as actuators
    and sensors. These devices are equipped with the capacity to connect to the network
    domain in either a direct or indirect fashion, depending on whether or not an
    M2M gateway is utilized. In a similar vein, machine-to-machine (M2M) devices that
    are connected to an M2M area network have the capacity to connect to the network
    domain by way of the M2M gateway. A network domain is comprised of numerous components,
    including an access network, a core network, M2M service capabilities, M2M application
    capabilities, an M2M management function, and a network management function. The
    foundation for sub-networks to share information is laid by core networks. Its
    primary functions are to ease authentication and aggregation of connections [5].
    The core network acts as a conduit for information flow between distinct sub-networks.
    The access network is responsible for connecting M2M devices to the core network.
    Examples of access networks are LAN, fiber optic, Ethernet, and Wi-Fi. M2M service
    capabilities work differently for both domain devices, gateway domains, and network
    domains [5]. These service capabilities ensure the reachability of devices to
    the network and their scheduling information and configuration management for
    the device and gateway domain. In the network domain, service capabilities provide
    an open interface, mutual authentication, and security to M2M applications. Also,
    the M2M management and network management functions provide additional benefits
    to access network and core network like- fault management, authentication, bootstrap
    function, and security for credentials. Conventional architectures of the internet
    of things have been found to be unsuitable for real-time applications that require
    critical data to be transmitted in a timely manner in order to prevent casualties.
    Real-time applications include things like the industrial applications of the
    internet of things and smart transportation systems, for example. As a result,
    there is a requirement for an additional middle layer in order to ensure that
    data communication is both smooth and quick [4]. In this paper, a MANET-IoT architecture
    for an Internet of Things network is proposed. This architecture involves adding
    an additional MANET layer somewhere in the middle of the IoT architecture. A mobile
    ad hoc network (MANET) is a wireless network that can self-organize and connect
    itself to other nodes in a distributed system on demand. Each device that participates
    in a MANET has the ability to freely migrate from one point to another in any
    direction. They are able to form a network with their smart devices by connecting
    them to one another, and they can send data to another device. Leveraging these
    functionalities in the proposed architecture, it is assumed that mobile devices
    play the role of the sink. These devices act like overlays in the architecture
    that seek data from the sensing layer. Data collecting paths of MDSs and data
    collecting applications need to be choose then only satisfaction in data collecting
    has been achieved. The path travels by MDSs and its speed on this only data gathering
    delay always depends. To improve better data gathering delay increase number of
    MDSs exactly one MSD is needed. The Proposed architecture can be mapped with the
    conventional IoT reference model and ETSI M2M high-level architecture as sensing
    layer in the proposed architecture is mapped in the device and gateway domain
    where sensor nodes and actuators sense data and send them to elected coordinator
    nodes(gateways). Further, the coordinator nodes connect to the mobile sink via
    the access network. For varied purposes, these mobile sinks can also be considered
    edge devices at the core of the network for fast data processing. Mobile sinks
    play a dual duty because they need to receive the data from the sensor nodes and
    then provide it to the Gateway after performing a straightforward data aggregation.
    We assume that mobile sinks only aggregate locally when they are physically near
    an aggregation point and receive the raw data. Figure 2 present Network topology
    for mobile sink between Fig. 2: Network topology for mobile sink Show All SECTION
    III. Proposed MANET IoT Architecture Figure 3 illustrates the proposed architecture,
    which contains a total of four layers. The base layer of the architecture is composed
    of two layers: the member node layer and the coordinator node layer. The following
    is an explanation of how communication works within the framework that has been
    proposed. Sensor nodes and member nodes are responsible for the generation of
    data. All of the network''s nodes, including the coordinator node, are responsible
    for transmitting data to it [7]. At the MANET layer, the coordinator node performs
    any necessary preprocessing before transferring the data to a mobile data sink.
    Mobile sink sends data to cloud after performing data. Analytics. Fig 3. Small
    scale architecture for MANET-IoT systems Show All i) Construction of MANET IoT
    Architecture It is assumed that there are ‘M’ homogeneous nodes located within
    a sensing area that is N×N in size (M1, M2…… Mn). [6] Intelligent relay devices
    denoted with the letter ‘P’ are tasked with the duty of maintaining connectivity
    between the member nodes denoted with the letter ‘M.’ These components are known
    as coordinators in the industry. The ‘Q’ gateways, which are the data collection
    points in the area of interest, are connected to the relays that are being discussed
    here. It''s possible that the ‘Q’ gateways can move around. The following procedures
    need to be carried out in order to build the Internet of Things networks: The
    phase of advertisement: The process of constructing a communication network begins
    with the phase of advertisement. During this phase, the gateway nodes each send
    their individual node identifier (ID) as well as their respective coordinates
    [8]. Introduction of the clustering technique in order to identify the coordinator
    nodes: The K-means methodology states that the nodes that are the most remote
    from the centre of the cluster are the ones that should be considered to be the
    cluster''s coordinators. The connection phase: During this phase, the member nodes
    of the network will connect to the relay nodes (coordinator) in their range based
    on the communication range of all of the nodes in the network (Node range) [9].
    The fourth and final step involves the establishment of communication between
    the coordinator nodes. Connecting the coordinator nodes to the gateway devices
    constitutes the fifth and final step in the process. Within the scope of this
    discussion, it is presumed that the capability of communicating is proportional
    to the individual range of each device. ii) Canonical Correlation Analysis Fig
    4. Canonical correlation analysis with three predictors and four criterion variables
    Show All CCA was carried out making use of the aforementioned three variables
    as predictors in order to evaluate the multivariate shared relationship that exists
    between the two variable sets (i.e., LoRa and network performance parameters)
    [9]. This was done in order to determine whether or not there is a significant
    correlation between the two sets of variables. This was done in order to find
    out whether or not there is a significant correlation between the two sets of
    variables, and this was the result of that investigation. When dealing with a
    situation involving smart parking, we make it a point to take into account the
    NLOS environment for the purpose of explanation. Following the analysis, three
    functions were generated, each of which had a squared canonical correlation (R
    2 c) value of either 0.9827, 0.37123, or 1.1274, and these values were determined
    for each successive function. Both the Wilks'' =.00946 criterion and the F(15,177.08)=52.06
    p.001 test demonstrated that there were differences between all of the functions
    that were statistically significant. When using a r 2 metric, deducting 1 from
    1 produces the full model effect size. This is because Wilks'' stands for the
    variance that cannot be explained by the model. Therefore, the r 2 type effect
    size for the set of three canonical functions was.99, which indicates that the
    full model explained a significant portion, approximately 99%, of the variance
    that was shared between the variable sets [9]. This was indicated by the fact
    that the full model had a value of.99 for the r 2 type effect size. This was indicated
    by the fact that the full model had a value of.99 for the r 2 type effect size.
    iii) Bayesian Belief Nets (BBN''s) Bayesian Belief Nets, also referred to as BBNs,
    are a specific kind of graphical model that consists of nodes and edges that serve
    as direct connections between the nodes in the network. BBN''s are used to respond
    to probabilistic queries about the variable involved, called inferences. These
    variables can be discrete or continuous, and in our article, we focused on continuous
    variables. Various methods are available to find the significant relationship
    among variables like rank correlation and Pearson''s coefficient; however, we
    used CCA to visualize the relationship among variables. After getting significant
    associations among independent and dependent variables, we try to determine the
    cause of low network efficiency and predict values of independent variables for
    the suitable scenario. The steps that need to be taken in order to produce BBN
    are briefly summarised as follows in this abbreviated version of the process:
    It is possible to quantify the nodes of a BBN as continuous univariate random
    variables, and the arcs can be interpreted as the parent-child relationship that
    exists between the nodes; Collect data from this structure in order to produce
    a sizeable sample file, and then use the data that is contained within the sample
    file in order to construct conditional probability tables for a discretized version
    of the continuous BBN. This will be done using the data that was collected from
    this structure. Utilize the tool to quickly update the discretized BBN as well
    as acquire a graphical representation of the network. Fig 5. A BBN on 4 variables
    Show All First, we present a queuing model for the uplink bandwidth allocation
    scheme that will be used moving forward. The queuing model is created with the
    help of network calculus, and it plays an essential role in determining the attributes
    that will be used in the uplink scheduling scheme [13]. We first introduce the
    queuing model that is used to analyze the impact of the scheduling scheme in terms
    of power consumption, signal load and delay. Assuming the size of the LTE subframe
    as 1ms and packet arrival flow as ‘R’, enter into a long sleep mode or short sleep
    mode. However at any specific time ‘t’ not more than rb/s will be supported in
    a long run where ‘b’ is the burst tolerance and ‘r’ is the rate (units of data
    per time frame). When two buffers go empty i.e., the downlink queue becomes empty,
    then the user equipment enters into a sleep mode two possibilities may happen.
    Either the UE may enter into a long sleep mode or short sleep mode [12]. In order
    to compute the individual performance metrics for a linear set of equations, it
    is necessary to deduce the steady state probability vector for the Markov chain
    after it has been established that the individual sub matrices for the independent
    assumption have been computed. iv) Fuzzy Interference System Decisions are able
    to be reached with the aid of fuzzy logic and rules based on the format ‘IF-Then,’
    in addition to the connectors ‘OR’ and ‘AND’. In order to accomplish this goal,
    fuzzy inference systems are utilized. [15]. The Mamdani fuzzy inference system
    is used in this section to create a fuzzy inference system (FIS) for selecting
    network parameters in order to achieve high network efficiency across a variety
    of LoRa network-using scenarios. The goal of this section is to maximize the amount
    of data that can be transmitted over LoRa networks. We take into account the following
    four fuzzy input variables in order to make an accurate prediction of the performance
    of the network: energy consumption (EC), packet delivery ratio (PDR), throughput
    (TP), and delay (D) (NE). After that, the ‘NE’ that had been obtained was utilized
    so that appropriate network parameters in LoRa networks could be fine-tuned using
    the obtained information. LoRa communicates using a network that only requires
    one hop and operates using a star-of-star topology. Single-hop communication allows
    LoRa EDs to send data to gateways within their range; however, this results in
    redundant transmission and a high amount of energy consumption [16]. As a result,
    in order to make the LoRa network more energy efficient, we are investigating
    the possibility of utilizing clustering and multihop communication. The random
    placement of end nodes in clusters that are organized in accordance with the communication
    range of the gateway node is taken into account by our algorithm. Because only
    a certain number of end nodes must be connected to a gateway node, the cluster
    is not limited by this requirement. According to the research that has been conducted
    up until now, major concerns in LoRa networks include energy consumption and throughput
    [17], while extending network coverage is a primary goal [18]. The behaviour of
    LoRa, on the other hand, makes it appear as though there is no limit on the number
    of gateways. Despite this, we can''t deny the fact that gateway devices have a
    higher price tag than LoRa end devices. Because of this, we evaluate the performance
    of LoRa networks based on whether or not they have the ideal number of LoRa gateways
    and compare it to the performance of LoRa networks based on whether or not they
    have the ideal number of LoRa devices. Numerous patients are affected with chronic
    diseases, and the number is increasing day by day. Sometimes, hospitalization
    is costly, and one needs to monitor health while working or performing everyday
    activities. Therefore, WBAN is a solution for the problem mentioned above. However,
    to develop a robust and effective WBAN, the underlying constraints impact the
    implementation decisions. In WBAN, miniature sensor devices are installed in,
    on, or off patients'' bodies by which biosignals can be forwarded to healthcare
    providers wirelessly. The healthcare providers then observe, diagnose and prescribe
    the patients without being physically present [20]. Biosignals are records of
    the biological evert of living beings that are measured continuously. These signals
    include heart-beat, blood pressure, body temperature, glucose level, electroencephalogram
    (EEG), electrocardiogram (ECG), electro-oculography (EOG), and much more [21].
    The proposed communication architecture also incorporates the data aggregation
    and data fusion scheme to conserve energy in transmitting packets containing bio-signals
    at each layer. Urgent and non-urgent data packets are also classified and transmitted
    to the upper layer to avoid data expedition at the sensor level and restrain extra
    computational overhead on the edge layer while processing the data packets further.
    v) Proposed Architecture or WBSAN Fig 6. Proposed architecture of WBSAN Show All
    Figure 6 presents the proposed architecture of wireless body area sensor network.
    In order to design a scalable BSN and healthcare platform, LoRa technology could
    be a suitable candidate to transmit crucial health care data. We must therefore
    consider the performances of LoRa and the proper deployment for LoRa networks.
    As LoRa is interference-free and transmits packets up to long-range, LoRa can
    conserve transmitting energy [19]. In this paper, we propose to deploy LoRa end
    devices (physiological sensors) and LoRa gateways at the lower layer. LoRa end
    devices send data to their nearby gateways after applying redundant fusion or
    aggregation function (sum, min, max, avg). The gateway layer classifies data packets
    as urgent and non-urgent based on a threshold value [23]. These urgent and non-urgent
    data packets again get transmitted to the upper layers (Edge Server or Cloud).
    We also suggest deploying a mobile ad hoc network (MANET) layer as an overlay.
    Since LoRa technology has a small throughput and is constrained, the MANET layer
    works here as the computing component [26]. As MANETs are not heavily constrained,
    they can be exploited to execute pre-processing and feature selection algorithms.
    MANET nodes are allowed to wander freely as the network topology constantly changes
    because MANETs are self-configuring, self-healing networks flexible infrastructure
    [12], [19]. Therefore, MANETs have been proposed to support local decision algorithms
    for determining emergencies and abnormal and life-threatening variations of the
    medical parameter. At the MANET layer, buffer aggregation is applied to reduce
    the network energy. Aggregated packets are sent to the cloud layer where cooperative
    fusion is applied to take an appropriate decision on time [25]. Both types of
    urgent and non-urgent data packets are immediately transferred to the MANET layer.
    MANET layer already performs feature selection algorithm based on collected data
    to select most significant health signals. These variables are checked within
    the limits of the threshold sensor values for detecting any anomaly. If the threshold
    value of the sensor is crossed and is also the most significant health factor
    of the patient, then the packet''s status is maintained as urgent. Otherwise,
    it is converted to a non-urgent status. The MANET layer is also responsible for
    executing the data aggregation scheme. The urgent and non-urgent data packets
    are buffered temporarily at this layer [28]. The most significant features are
    selected and transmitted to this layer and then combined to provide a decision
    about the disease. SECTION IV. Results and Discussions The effectiveness of the
    proposed algorithms is evaluated and contrasted with that of a protocol referred
    to as clustering-based layered approach, which was described in [20]. In this
    method, the author joined the gateway by clustering nodes together according to
    their RSSI values. We can say that our clustering is K-Medoid-based because, in
    our proposed algorithms, we establish clustering based on the ‘K-Medoid’. Based
    on the sensing range of end nodes and gateways, nodes will join their neighbourhood
    cluster gateway. In other words, nodes will join their cluster according to the
    cluster gateway''s location in relation to them. With the exception of SF 6, we
    use the exact same parameter settings for LoRa as were described in [25]. Figure
    7 presents the results of various algorithmic analyses regarding energy consumption.
    It is clear that the algorithm suggested in [20] required a greater amount of
    energy in order to run than the other three algorithms. Due to the absence of
    multi-hop communication, the direct flow algorithm has a higher overall energy
    requirement than the algorithms that we have proposed. We implement clustering
    in a conventional LoRa network that has the optimum number of gateways. This causes
    the devices to get connected to the gateway in the most efficient way possible
    and ensures that a single ED transmits a single data packet. As a result, the
    algorithms that we have proposed have a better performance than the algorithm
    that is in [20] and the traditional LoRa star topology (Direct flow) because they
    take the route that is the shortest from ED to GW. Fig 7. Effect of increasing
    node density on all four algorithms'' energy dissipation Show All Figure 8 illustrates
    the energy consumption trade-off between proposed work and existing work in [25].
    It can be seen that our proposed architecture for WBSAN consumes less energy than
    the existing method. In method [25] authors transmitted urgent packets to the
    upper layer and dropped every non-urgent packet. In contrast, we transmit every
    data packet (both urgent and non-urgent) to the upper layer. Figures 9 and 10
    present the energy consumption while transmitting only urgent data packets with
    data aggregation ratio 1 and 3 respectively at the MANET layer. Fig 8. Total number
    of data packets transmitted Show All Fig 9. Urgent data packet transmitted with
    aggregation ratio=1 Show All Fig 10. Urgent data packet transmitted with aggregaion
    ratio=3 Show All Fig. 11. Non-urgent data packet transmitted with aggregation
    ratio=5 Show All Figure 11 present the energy consumption while transmitting only
    non-urgent data packets with data aggregation ratios 5 at the MANET layer. Our
    novelty lies in choosing a compression value that enables transmission of non-urgent
    packets that would facilitate keeping historical records of patients for future
    reference. SECTION V. Conclusion The spreading factor is the most important independent
    parameter in a LoRa network; on the other hand, energy consumption and delay are
    factors that depend on each other. The spreading factor can be optimized with
    the help of CCA. BBN is utilized to determine the overall efficiency of a network
    by analyzing the significant parameters present in a given environment. This is
    accomplished through the use of a given environment. It has been determined that
    each user and service provider is capable of making the optimal decision regarding
    the value of the SF, BW, and CR parameters in order to achieve the highest possible
    level of network efficiency in a particular IoT application. This conclusion was
    reached after it was determined that each user and service provider is capable
    of making the optimal decision regarding the value of the parameters. We have
    reached the conclusion that a strategy that is based on clusters can be used for
    a long-distance network in order to achieve both a high data rate and a low level
    of energy consumption. This was our finding after coming to the conclusion that
    a strategy that is based on clusters can be used. The proposed algorithm is analyzed
    and evaluated in comparison to other algorithms that have been developed in the
    past, such as the Me-cat algorithm, conventional LoRa, and clustering LoRa, in
    terms of the amount of energy that is lost by each of them. The research indicates
    that the proposed algorithm achieves results that are superior to those obtained
    by Me-cat, conventional LoRa, and clustering LoRa. On the other hand, conventional
    LoRa has a relatively high requirement for the amount of energy transmitted. Authors
    Figures References Keywords Metrics More Like This Energy Consumption Minimization
    With Throughput Heterogeneity in Wireless-Powered Body Area Networks IEEE Internet
    of Things Journal Published: 2021 Power allocation strategies to minimize energy
    consumption in wireless body area networks 2011 Annual International Conference
    of the IEEE Engineering in Medicine and Biology Society Published: 2011 Show More
    IEEE Personal Account CHANGE USERNAME/PASSWORD Purchase Details PAYMENT OPTIONS
    VIEW PURCHASED DOCUMENTS Profile Information COMMUNICATIONS PREFERENCES PROFESSION
    AND EDUCATION TECHNICAL INTERESTS Need Help? US & CANADA: +1 800 678 4333 WORLDWIDE:
    +1 732 981 0060 CONTACT & SUPPORT Follow About IEEE Xplore | Contact Us | Help
    | Accessibility | Terms of Use | Nondiscrimination Policy | IEEE Ethics Reporting
    | Sitemap | IEEE Privacy Policy A not-for-profit organization, IEEE is the world''s
    largest technical professional organization dedicated to advancing technology
    for the benefit of humanity. © Copyright 2024 IEEE - All rights reserved."'
  inline_citation: '>'
  journal: 6th International Conference on Electronics, Communication and Aerospace
    Technology, ICECA 2022 - Proceedings
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: An Effective Approach on Clustering and Data Aggregation for the application
    of Internet of Things in Long Range Networks
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Priyadarsini K.
  - Chandana S.L.
  - Samaniego S.S.C.
  - Chaudhary M.G.
  - Vekariya V.
  - Chaturvedi A.
  citation_count: '0'
  description: With the increase in number of devices enabled the Internet of Things
    (IoT) communication with the centralized cloud computing model. With the implementation
    of the cloud computing model leads to increased Quality of Service (QoS). The
    cloud computing model provides the edge computing technologies for the real-time
    application to achieve reliability and security. Edge computing is considered
    the extension of the cloud computing technology involved in transfer of the sensitive
    information in the cloud edge to increase the network security. The real-time
    data transmission realizes the interaction with the high frequency to derive improved
    network security. However, with edge computing server security is considered as
    sensitive privacy information maintenance. The information generated from the
    IoT devices are separated based on stored edge servers based on the service location.
    Edge computing data is separated based in edge servers for the guaranteed data
    integrity for the data loss and storage. Blockchain technologies are subjected
    to different security problem for the data integrity through integrated blockchain
    technologies. This paper developed a Voted Blockchain Elliptical Curve Cryptography
    (VBECC) model for the millimetre wave application. The examination of the blockchain
    model is evaluated based on the edge computing architecture. The VBECC model develop
    an architectural model based Blockchain technology with the voting scheme for
    the millimetre application. The estimated voting scheme computes the edge computing
    technologies for the estimation of features through ECC model. The VBECC model
    computes the security model for the data transmission in the edge computing-based
    millimetre application. The experimental analysis stated that VBECC model uses
    the data security model ~8% increased performance than the conventional technique.
  doi: 10.17762/ijcnis.v14i3.5577
  full_citation: '>'
  full_text: '>

    "Register Login About Current Archives Copyrights Form Announcements Contacts
    Privacy Statement Abstracting/ Indexing Article processing charge Search HOME
    ARCHIVES VOL. 14 NO. 3 (2022) RESEARCH ARTICLES Intelligent Mobile Edge Computing
    Integrated with Blockchain Security Analysis for Millimetre-Wave Communication
    Article Sidebar PDF Published: Dec 23, 2022 Updated: 2022-12-23 Versions: 2022-12-23
    (2) 2022-12-23 (1) DOI: https://doi.org/10.17762/ijcnis.v14i3.5577 Keywords: Elliptical
    Curve Cryptography, Edge Computing, Blockchain, Voting scheme, Cloud Computing
    Main Article Content Priyadarsini K Department of Data Science and Business Systems,
    School of Computing, College of Engineering and Technology, SRM Institute of Science
    and Technology, Kattankulathur, Chennai- 603203, Tamil Nadu, India Sri Lakshmi
    Chandana Assistant Professor, Department of Electronics and Communication Engineering,
    Prasad V Potluri Siddhartha Institute of Technology, Kanuru, Vijayawada, Andhra
    Pradesh, India Severo Simeón Calderón Samaniego  Professor, Universidad Peruana
    los Andes, Perú, South America Dr. Megha Gupta Chaudhary Assistant Professor,
    Department of Physics, SRM Institute of Science and Technology NCR Campus, Delhi-NCR
    Campus, Ghaziabad, Uttar Pradesh, India Dr. Vipul Vekariya  Dean and Principal,
    Faculty of Engineering & Technology, Parul University, Vadodara, Gujarat, India
    Mr. Abhay Chaturvedi Associate Professor, Department of Electronics and Communication
    Engineering, GLA University, Mathura, Uttar Pradesh- 281406, India Abstract  With
    the increase in number of devices enabled the Internet of Things (IoT) communication
    with the centralized cloud computing model. With the implementation of the cloud
    computing model leads to increased Quality of Service (QoS). The cloud computing
    model provides the edge computing technologies for the real-time application to
    achieve reliability and security. Edge computing is considered the extension of
    the cloud computing technology involved in transfer of the sensitive information
    in the cloud edge to increase the network security. The real-time data transmission
    realizes the interaction with the high frequency to derive improved network security.
    However, with edge computing server security is considered as sensitive privacy
    information maintenance. The information generated from the IoT devices are separated
    based on stored edge servers based on the service location. Edge computing data
    is separated based in edge servers for the guaranteed data integrity for the data
    loss and storage. Blockchain technologies are subjected to different security
    problem for the data integrity through integrated blockchain technologies. This
    paper developed a Voted Blockchain Elliptical Curve Cryptography (VBECC) model
    for the millimetre wave application. The examination of the blockchain model is
    evaluated based on the edge computing architecture. The VBECC model develop an
    architectural model based Blockchain technology with the voting scheme for the
    millimetre application. The estimated voting scheme computes the edge computing
    technologies for the estimation of features through ECC model. The VBECC model
    computes the security model for the data transmission in the edge computing-based
    millimetre application. The experimental analysis stated that VBECC model uses
    the data security model ~8% increased performance than the conventional technique.
    Article Details How to Cite K, P. ., Chandana, S. L. ., Samaniego, S. S. C. .,
    Chaudhary, D. M. G. ., Vekariya, D. V. ., & Chaturvedi, M. A. . (2022). Intelligent
    Mobile Edge Computing Integrated with Blockchain Security Analysis for Millimetre-Wave
    Communication. International Journal of Communication Networks and Information
    Security (IJCNIS), 14(3), 110–122. https://doi.org/10.17762/ijcnis.v14i3.5577
    More Citation Formats Issue Vol. 14 No. 3 (2022) Section Research Articles This
    work is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike
    4.0 International License. Make a Submission QUICK MENU Editorial List Focus and
    Scope Author Guidelines Publication Ethics Open Access Policy Peer Review Process
    Online Submission Contact Abstracting/ Indexing Current Issue e-ISSN: 2073-607X
    p-ISSN: 2076-0930 Frequency: 4 Issue Per Year Nature: Online and Print Language
    of Publication: English Funded By: UK Zhende Publishing Information For Authors
    Keywords Deep Learning passive DNS Big Data 6G machine learning M1FP Cyber security
    NP-hard COVID -19 lung infection Data Partitioning"'
  inline_citation: '>'
  journal: International Journal of Communication Networks and Information Security
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Intelligent Mobile Edge Computing Integrated with Blockchain Security Analysis
    for Millimetre-Wave Communication
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Halubanza B.
  - Phiri J.
  - Nyirenda M.
  - Nkunika P.O.Y.
  - Kunda D.
  citation_count: '2'
  description: The world has been devastated by locust outbreaks since time immemorial.
    However, due to climate change, there has been an increase in instances of the
    spread of locusts around the world. This trend keeps on causing havoc to crops,
    pastures and livelihoods. This study focused on African migratory locust (Locusta
    migratoria migratoriodes) and Red locust (Nomadacris septemfasciata) species that
    are prevalent in the study area. Managing locust invasions in Sikaunzwe Agricultural
    Camp in Kazungula District of Zambia is faced with pest identification challenges.
    Elocust3, an early warning system, provided by Food and Agriculture Organisation
    (FAO) doesn’t have an automatic locust identification facility. Artificial Intelligence
    has not been exploited to full capacity in locust management due to lack of a
    consistent monitoring system in southern and central Africa regions. An automatic
    identification of both Locusta migratoria and Nomadacris septemfasciata using
    Convolution Neural Network (CNN) Single-Stage object detection MobileNet version
    2 quantised model was used in the study. A custom dataset was used to train, test
    and validate the model using images collected from the study area. The dataset
    is composed of 1700 images captured using a Nikon D5300 camera in various light
    and background conditions and each image was annotated using Labelimg software.
    The results from the study shows that the model is able to identify Locusta migratoria
    and Nomadacris septemfasciata with an average precision of 91% and 85% respectively.
    The results are considered to be satisfactory despite the low quantised resources
    used in the study.
  doi: 10.1007/978-3-031-09073-8_43
  full_citation: '>'
  full_text: '>

    "Your privacy, your choice We use essential cookies to make sure the site can
    function. We also use optional cookies for advertising, personalisation of content,
    usage analysis, and social media. By accepting optional cookies, you consent to
    the processing of your personal data - including transfers to third parties. Some
    third parties are outside of the European Economic Area, with varying standards
    of data protection. See our privacy policy for more information on the use of
    your personal data. Manage preferences for further information and to change your
    choices. Accept all cookies Skip to main content Advertisement Log in Find a journal
    Publish with us Track your research Search Cart Computer Science On-line Conference
    CSOC 2022: Cybernetics Perspectives in Systems pp 490–501Cite as Home Cybernetics
    Perspectives in Systems Conference paper Detection of Locusta migratoria and Nomadacris
    septemfasciata (Orthoptera: Acrididae) Using MobileNet V2 Quantized Convolution
    Neural Network, Kazungula, Zambia Brian Halubanza , Jackson Phiri , Mayumbo Nyirenda
    , Phillip O. Y. Nkunika & Douglas Kunda   Conference paper First Online: 05 July
    2022 693 Accesses 1 Citations Part of the book series: Lecture Notes in Networks
    and Systems ((LNNS,volume 503)) Abstract The world has been devastated by locust
    outbreaks since time immemorial. However, due to climate change, there has been
    an increase in instances of the spread of locusts around the world. This trend
    keeps on causing havoc to crops, pastures and livelihoods. This study focused
    on African migratory locust (Locusta migratoria migratoriodes) and Red locust
    (Nomadacris septemfasciata) species that are prevalent in the study area. Managing
    locust invasions in Sikaunzwe Agricultural Camp in Kazungula District of Zambia
    is faced with pest identification challenges. Elocust3, an early warning system,
    provided by Food and Agriculture Organisation (FAO) doesn’t have an automatic
    locust identification facility. Artificial Intelligence has not been exploited
    to full capacity in locust management due to lack of a consistent monitoring system
    in southern and central Africa regions. An automatic identification of both Locusta
    migratoria and Nomadacris septemfasciata using Convolution Neural Network (CNN)
    Single-Stage object detection MobileNet version 2 quantised model was used in
    the study. A custom dataset was used to train, test and validate the model using
    images collected from the study area. The dataset is composed of 1700 images captured
    using a Nikon D5300 camera in various light and background conditions and each
    image was annotated using Labelimg software. The results from the study shows
    that the model is able to identify Locusta migratoria and Nomadacris septemfasciata
    with an average precision of 91% and 85% respectively. The results are considered
    to be satisfactory despite the low quantised resources used in the study. Keywords
    Artificial intelligence Deep learning eLocust3 Migratory Locust Red Locust Locusta
    migratoria Nomadacris septemfasciata Access provided by University of Nebraska-Lincoln.
    Download conference paper PDF 1 Introduction The world has been devasted by outbreaks
    of Locusts since time immemorial. Humans have suffered through the loss of crops
    and vegetation thereby leading to hunger and threats on food security. Locusts
    are a group of certain species of short horned grasshoppers with large hind legs
    in the family acrididae that display solitary and gregarious phases [1,2,3]. The
    difference between locusts and grasshoppers lies in the manner they respond to
    high densities. There are several species of locusts which include, African migratory
    locust (Locusta migratoria migratoriodes), Brown locust (Locustana pardalina),
    Red locust (Nomadacris septemfasciata), Desert locust (Schistocerca gragaria)
    among others. According to [4], locusts and other pests can cause an equivalent
    of 30% to 40% loses of the world’s food production. Eight million people, mostly
    in Africa were affected by the desert locust outbreak with the damage to crops
    estimated at more than 80% between 2003 and 2005 [1, 5]. Central and southern
    Africa has not been spared from Locust invasions [6] as evidenced by countries
    such as Zambia, Namibia and Botswana which were among the African countries in
    the region that were recently affected by the African Migratory locust (Locusta
    migratoria migratorioides) [7]. Southern, Western and Central regions of Zambia
    rank the worst affected regions with a serious invasion reported in Mwandi and
    Sesheke districts (Western Province) [8]. Urgent Humanitarian assistance was hence
    needed for the 88,700 affected households in Zambia as a result of the destruction
    of an estimated 47,000 hectares of land in December, 2020 [8]. Food security is
    cardinal to human survival and anything that threatens it contributes to loss
    of livelihood. The government of the republic of Zambia in conjunction with other
    stakeholders such as the Food and Agricultural Organisation (FAO) have instituted
    measures to cab the spread of locusts [8]. Concerted efforts by local and international
    organisations are crucial for timely management of locust invasion [9]. Among
    such measures include aerial spraying in the affected areas and community sensitisation
    [8]. Managing locust invasions by the ministry of agriculture in Sikaunzwe Agricultural
    Camp in Kazungula District of Zambia faces a lot of challenges. Physical identification
    of pests is sometimes difficult since the staff and the local community at times
    fail to correctly identify locust species due to human error [10]. Elocust3, an
    early warning system provided by FAO, doesn’t have an automatic locust identification
    facility but instead depends on the expert knowledge of the locust management
    team. The above challenges have necessitated the need to find better ways of using
    technology to mitigate the impact on the community’s main source of livelihood.
    Emerging technologies such as Artificial intelligence (AI) have not been exploited
    to full capacity in locust management in southern and central Africa due to poor
    locust monitoring systems in the region [7]. This research is therefore aimed
    at designing a deep learning model based on AI for automatic identification of
    locusts. According to [11], deep learning has been used in image recognition projects
    and is also a powerful too in Natural Language Processing. It consists of multiple
    layers and is used to discover relationships in data sets. Deep learning has been
    instrumental in the design of computer vision algorithms in agriculture in areas
    such as crop disease detection. 1.1 MobileNet V2 Quantised Most machine learning
    models are too big to be deployed in an edge device such as mobile phones and
    microcontrollers as well as other small devices [12, 13]. Using the cloud to store
    data and the model has not yielded much help as doing so still poses a challenge
    of accessibility. Edge devices have a problem accessing the cloud services for
    object detection due to inconsistencies in internet bandwidth [14]. Data security
    has also been reported as a challenge when using the cloud services since data
    does not reside on the mobile phone or any other edge device [12, 15, 16]. For
    applications whose operations are critical, zero-latency is normally demanded
    for and using a cloud storage for object detection through an API does not guarantee
    zero latency [17,18,19]. There are various model optimization techniques that
    could enable machine learning models to run on resource constrained devices and
    among such tools is model quantization. Quantization is a technique that is used
    to deploy machine learning models in devices that are resource constrained [20].
    The model sizes are reduced by limiting the precision formats supported by TensorFlow
    Lite tools. Most machine learning models use float32 and quantization enables
    the use of slightly lighter formats such as float16 and int8 [21]. The rate at
    which a model detects objects if directly related or corelated to the type of
    format that is used in the model. Mobile Fig. 1 shows MobileNet Version 2 building
    block. Fig. 1. MobileNet Version 2 building block [22] Full size image 2 Related
    Works [23] proposes the design of “a vision-based counting and recognition system
    for flying insects in intelligent agriculture”. A sticky trap was used to capture
    six species of insects since it is difficult to take images of insects in motion.
    A Convolution Neural Networks (CNN) object detection model called You Only Look
    Once (YOLO) was used for insect detection and coarse counting while Support Vector
    Machine (SVM) was used for insect classification and fine counting. A promising
    result was achieved showing an accuracy of 92.5% and 90.18% for counting and classification
    respectively. [24] proposed the use of Convolutional Neural Network to automatically
    identify locusts. The drone is equipped with a high-resolution camera and a pesticide
    tank whose contents are only spread on automatically identified locust swarms
    thereby using chemicals effectively. [25] created a model that employs the use
    of CNN to detect grasshoppers in real time using a mobile phone device without
    internet connection. Residual Network (ResNet) architecture was used and it incorporates
    the upload of images to the cloud storage for further analysis. [10] used CNN
    model to identify various crop insects through multifaceted feature extraction.
    Regional Proposal network was proposed for generation of small windows which ultimately
    increased model prediction accuracy and accelerated computations. The results
    from the study showed an improvement in model performance as compared to traditional
    classification algorithms. [26] proposed the use of Fast and faster CNN models
    to detect desert locusts. An average of 83% was achieved using VGG16 architecture
    as compared to AlexNet, ResNet and VGG19 architectures. [27] predicted locust
    distribution using Recurrent Neural Networks (RNN). The FAO dataset was used and
    the obtained results shows a precision of 60% and recall of 81%. [28] developed
    a semi-automatic machine learning model to detect two types of locust species
    namely O. decorus asiaticus and L. migratoria manilensis and their associated
    instars. The segmentation method used to extract the body parts for locusts was
    GrabCut. Results from the study gave an accuracy of 96.1% when used on polynomial
    kernel function. 3 Methodology The study is proposing an automatic identification
    of both African Migratory Locust (Locusta migratoria) and Red Locust (Nomadacris
    septemfasciata) using Convolution Neural Network (CNN) Single-Stage object detection
    (SSD) MobileNet version 2 model. A custom dataset was used to train, test and
    validate the model using images collected from the study area. MobileNet V2 approach
    was used in the study since it improves the mobile model’s performance on multiple
    tasks [29]. According to [30] MobileNet V2 is an improvement of MobileNet V1 and
    uses depthwise and \\( 1\\times1 \\) pointwise convolution layers. The neural
    network architecture optimization is achieved through the utilization of linear
    bottleneck layers. 3.1 Dataset Three members of the research team visited Sikaunzwe
    Agricultural camp plains of Kazungula District in Zambia on 1st December, 2021
    and high-quality images were captured for the period of three days. Since some
    locusts were too mobile and difficult to capture, the team with the help of cattle
    headers captured live insects which were kept in transparent bottle jars. The
    images of insects were later captured using a Nikon D5300 Camera and each image
    was geo tagged. The captured insects where subjected to more image shootouts with
    a view of collecting as much images as possible. Various conditions such as light
    intensity, foreign background details and various angles of image capturing were
    applied. The distance of the camera from the insects was restricted to a maximum
    of 50 cm. Bing search engine was also used to search for an additional AML and
    RL images from the internet so as to increase images for validation purposes.
    A further search from Kaggle community grasshopper images was conducted and only
    images that fall into one of the two classes were added to the custom dataset.
    The locusts captured from the internet were identified and categorized by a member
    of the team who is an entomology expert. Fig. 2. Red Locust. Photo: B. Halubanza.
    Full size image The red locusts strive well in grasslands plains that are seasonally
    flooded. Their presence is restricted to one generation per year and eggs are
    normally laid at the beginning of the rain season [1] (Fig. 2). Fig. 3. African
    Migratory Locust. Photo: B. Halubanza. Full size image AML on the other hand have
    a narrow ecological requirement despite having a large distribution among the
    various species of locusts and grasshoppers. Light soils and wet grasslands are
    ideal for AML breeding. The locust population swells in dry seasons after experiencing
    unusual heavy rains the previous years. 3.2 Data Pre-processing Physical annotation
    of images was done for all the images in the dataset using Labelimg. Labelimg
    is an open-source software for data annotation. Data was categorized in two classes
    namely African Migratory Locust and Red Locust and each image was annotated using
    a rectangular bounding box in PASCAL VOC format. Bounding boxes were further checked
    for accuracy as well as ensuring that they were free from foreign objects. Any
    images that had wrongly aligned bounding boxes were rectified and images that
    were either not clear or captured from a long distance were also filtered out
    of the dataset. The above processes are important when coming up with a dataset
    which is of high quality. This process took a period of seven days and a total
    of 1700 images formed the dataset distributed as follows; 1410 images for training
    and 290 images for testing. Of the total images, 1135 constitute the AML and 565
    the red locust. A custom dataset using images captured in the study area was ideal
    taking into consideration that the mobile application was going to be used by
    farmers and agricultural camp officers in the same area. Labelimg generated an
    Xml file for each image which was later converted to csv file using a Python Script.
    The csv files were later converted to train.record and text.record files (Fig.
    4). Fig. 4. Shows annotated image of an African Migratory Locust. Full size image
    3.3 Model Training Single Short Detector (SSD) MobileNet V2 quantised model was
    used to train the custom dataset. Google Collab, an online notebook platform,
    was adopted due to its high processing power (Graphic Processing Unit) and storage
    capacity. The model training learning rate was 0.4. The learning rate hyperparameter
    controls how fast the model is adapting to the problem, and it is traditionally
    between 0.00 and 1.00. To increase the learning rate, data augmentation was used.
    This entails replicating of images using a library in TensorFlow and this allows
    the model to be trained on more images without the need to provide additional
    images to the training dataset. 80% of the dataset was used to train the model.
    After the model training was complete, a frozen inference graph (.pb file) was
    generated for testing purposes. 4 Results Model validation was performed on live
    locust images and the model accuracy was averaging 85% for red locust and 91%
    for AML (Figs. 5 and 6). Fig. 5. AML image detection Full size image Fig. 6. Red
    Locust image detection Full size image Fig. 7. AML detection by Webcam Full size
    image The model was further validated on the video that was captured in December
    2020 during the AML invasion in the study area and the model accuracy was on average
    91% as shown in Fig. 8. Results from a video showing red locust invasion indicated
    an average accuracy of 92 as shown in Fig. 9. Fig. 8. AML detection on the video
    Full size image Fig. 9. Red Locust detection on the video Full size image 5 Conclusion
    The study’s aim was to design a CNN model using MobileNet v2 quantised to detect
    Locusta migratoria and Nomadacris septemfasciata in Sikaunzwe agricultural camp
    plains of Kazungula district in Zambia. This was a solution to the problem of
    insect pest identification challenges faced by both the ministry of agriculture
    staff and the community. The results from the study clearly indicates the model’s
    capability of automatically identifying the two locust species. The experimental
    results show that it is faster and accurate to detect locusts using deep learning
    methods as compared to experiments from other researchers that have been reviewed
    with an average precision of 91% and 85% for Locusta migratoria and Nomadacris
    septemfasciata respectively. The research team intends to further validate the
    model by creating a mobile application that will be used by staff and farmers
    in real time to identify locusts in the study area. This study contributes by
    fine tuning a CNN model that can be used to detect both stationary and Realtime
    locusts. The model is also optimized to be incorporated on any standard mobile
    device for detection of the two locust species that are found in the study area.
    The study also presents a new dataset that can be used by other researchers to
    come up with new algorithms. Furthermore, future researchers can improve upon
    the study by developing new algorithms that can be used to further augment the
    images in the dataset so as to increase the dataset. It is also recommended that
    insect classification be more detailed so that the output can consider the detection
    of various growth stages of locusts. References Latchininsky, A.V.: Locusts and
    remote sensing: a review. J. Appl. Remote Sens. 7(1), 075099 (2013) Article   Google
    Scholar   Joshi, M.J., Raj, V.P., Solanki, C.B., Vaishali, V.B.: Desert locust
    (Schistocera gregaria F.) outbreak in Gujarat (India). Agricult. Food E-Newslett.
    2(6), 691–693 (2020) Google Scholar   Dominy, N.J., Fannin, L.D.: The sluggard
    has no locusts: from persistent pest to irresistible icon. People Nat. 3(3), 542–549
    (2021) Article   Google Scholar   Gay, P.E., Lecoq, M., Piou, C.: The limitations
    of locust preventive management faced with spatial uncertainty: exploration with
    a multi-agent model. Pest Manag. Sci. 76(3), 1094–1102 (2020) Article   Google
    Scholar   Latchininsky, A.V., Sivanpillai, R.: Locust habitat monitoring and risk
    assessment using remote sensing and GIS technologies. In: Ciancio, A., Mukerji,
    K. (eds.) Integrated Management of Arthropod Pests and Insect Borne Diseases,
    pp. 163–188. Springer, Dordrecht (2010). https://doi.org/10.1007/978-90-481-8606-8_7
    Sharma, A.: Locust control management: moving from traditional to new technologies
    – an empirical analysis. Entomol. Ornithol. Herpetol. 4, 141 (2014). https://doi.org/10.4172/2161-0983.1000141
    Article   Google Scholar   Klein, I., Oppelt, N., Kuenzer, C.: Application of
    remote sensing data for locust research and management—a review. Insects 12(3),
    233 (2021) Article   Google Scholar   Chomba, G, Chanda, M, FAO steps up response
    to Zambia’s locust invasion, Reliefweb; https://reliefweb.int/report/zambia/fao-steps-response-zambia-s-locust-[,25-09-2020.
    Accessed 19 Feb 2021 Toleubayev, K., Jansen, K., van Huis, A.: Locust control
    in transition: the loss and reinvention of collective action in post-Soviet Kazakhstan.
    Ecol. Soc. 12(2) (2007) Google Scholar   Xia, D., Chen, P., Wang, B., Zhang, J.,
    Xie, C.: Insect detection and classification based on an improved convolutional
    neural network. Sensors 18(12), 4169 (2018) Article   Google Scholar   He, K.,
    Zhang, X., Ren, S., Sun, J.: Deep residual learning for image recognition. In:
    Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,
    pp. 770–778 (2016). https://doi.org/10.1109/CVPR.2016.90) Gorospe, J., Mulero,
    R., Arbelaitz, O., Muguerza, J., Antón, M.Á.: A generalization performance study
    using deep learning networks in embedded systems. Sensors 21(4), 1031 (2021) Article   Google
    Scholar   Wang, Z., et al.: Evolutionary multi-objective model compression for
    deep neural networks. IEEE Comput. Intell. Mag. 16(3), 10–21 (2021) Google Scholar   Ghosh,
    A.M., Grolinger, K.: Deep learning: Edge-cloud data analytics for IoT. In: 2019
    IEEE Canadian Conference of Electrical and Computer Engineering (CCECE), pp. 1–7.
    IEEE, May 2019 Google Scholar   Gupta, R., Saxena, D., Singh, A.K.: Data security
    and privacy in cloud computing: concepts and emerging trends. arXiv preprint arXiv:2108.09508
    (2021) Butt, U.A., et al.: A review of machine learning algorithms for cloud computing
    security. Electronics 9(9), 1379 (2020) Article   Google Scholar   Xu, P., Goteng,
    G.L., He, Y.: Modelling cloud service latency and availability using a deep learning
    strategy. Expert Syst. Appl. 182, 115121 (2021) Article   Google Scholar   Popescu,
    D., Zilberman, N., Moore, A.: Characterizing the impact of network latency on
    cloud-based applications’ performance (2017) Google Scholar   Shukla, S., Hassan,
    M., Tran, D.C., Akbar, R., Paputungan, I.V., Khan, M.K.: Improving latency in
    Internet-of-Things and cloud computing for real-time data transmission: a systematic
    literature review (SLR). Cluster Comput. 1–24 (2021). https://doi.org/10.1007/s10586-021-03279-3
    Han, S., Mao, H. and Dally, W.J.: Deep compression: Compressing deep neural networks
    with pruning, trained quantization and huffman coding. arXiv preprint arXiv:1510.00149
    (2015) Ma, H., et al.: Quantization Backdoors to Deep Learning Models. arXiv preprint
    arXiv:2108.09187 (2021) Towards Data Science. https://ai.googleblog.com/2018/04/mobilenetv2-next-generation-of-on.html).
    Accessed 28 Feb 2022 Zhong, Y., Gao, J., Lei, Q., Zhou, Y.: A vision-based counting
    and recognition system for flying insects in intelligent agriculture. Sensors
    18(5), 1489 (2018) Article   Google Scholar   Neha, H.C., Munavalli, J.R.: Automated
    real-time locust management using artificial intelligence. Int. J. Eng. Appl.
    Sci. Technol. 5(4), 133–138 (2020). http://www.ijeast.com. ISSN No. 2455-2143
    Chudzik, P., et al.: Mobile real-time grasshopper detection and data aggregation
    framework. Sci. Rep. 10(1), 1–10 (2020) Article   Google Scholar   Kumar, K.S.,
    Abdul Rahman, A.: Early detection of locust swarms using deep learning. In: Patnaik,
    S., Yang, X.-S., Sethi, I.K. (eds.) Advances in Machine Learning and Computational
    Intelligence. AIS, pp. 303–310. Springer, Singapore (2021). https://doi.org/10.1007/978-981-15-5243-4_27
    Chapter   Google Scholar   Samil, H.M.O.A., Martin, A., Jain, A.K., Amin, S.,
    Kahou, S.E.: Predicting Regional Locust Swarm Distribution with Recurrent Neural
    Networks. arXiv preprint arXiv:2011.14371 (2020) Shuhan, L.U., Ye, S.J.: Using
    an image segmentation and support vector machine method for identifying two locust
    species and instars. J. Integr. Agricult. 19(5), 1301–1313 (2020) Article   Google
    Scholar   Sandler, M., Howard, A., Zhu, M., Zhmoginov, A., Chen, L.C.: Mobilenetv2:
    Inverted residuals and linear bottlenecks. In: Proceedings of the IEEE Conference
    on Computer Vision and Pattern Recognition, pp. 4510–4520 (2018) Google Scholar   Le,
    A.D., Pham, D.A., Pham, D.T. and Vo, H.B.: AlertTrap: a study on object detection
    in remote insects trap monitoring system using on-the-edge deep learning platform.
    arXiv preprint arXiv:2112.13341 (2021) Download references Acknowledgments The
    authors hereby acknowledge the immense help received from Scholarship funders
    - International Development Research Centre (IDRC) and Swedish International Development
    Cooperation Agency (SIDA); Scholarship Programme - Artificial Intelligence for
    Development (AI4D) Africa Scholarship Fund Manager - Africa Center for Technology
    Studies (ACTS); and lastly but not the least Mulungushi University for staff grant
    assistance. Author information Authors and Affiliations Computer Science Department,
    University of Zambia, Lusaka, Zambia Brian Halubanza, Jackson Phiri & Mayumbo
    Nyirenda Biology Department, University of Zambia, Lusaka, Zambia Phillip O. Y.
    Nkunika ZCAS University, Lusaka, Zambia Douglas Kunda Corresponding author Correspondence
    to Brian Halubanza . Editor information Editors and Affiliations Faculty of Applied
    Informatics, Tomas Bata University in Zlin, Zlin, Czech Republic Radek Silhavy
    Rights and permissions Reprints and permissions Copyright information © 2022 The
    Author(s), under exclusive license to Springer Nature Switzerland AG About this
    paper Cite this paper Halubanza, B., Phiri, J., Nyirenda, M., Nkunika, P.O.Y.,
    Kunda, D. (2022). Detection of Locusta migratoria and Nomadacris septemfasciata
    (Orthoptera: Acrididae) Using MobileNet V2 Quantized Convolution Neural Network,
    Kazungula, Zambia. In: Silhavy, R. (eds) Cybernetics Perspectives in Systems.
    CSOC 2022. Lecture Notes in Networks and Systems, vol 503. Springer, Cham. https://doi.org/10.1007/978-3-031-09073-8_43
    Download citation .RIS.ENW.BIB DOI https://doi.org/10.1007/978-3-031-09073-8_43
    Published 05 July 2022 Publisher Name Springer, Cham Print ISBN 978-3-031-09072-1
    Online ISBN 978-3-031-09073-8 eBook Packages Intelligent Technologies and Robotics
    Intelligent Technologies and Robotics (R0) Share this paper Anyone you share the
    following link with will be able to read this content: Get shareable link Provided
    by the Springer Nature SharedIt content-sharing initiative Publish with us Policies
    and ethics Download book PDF Download book EPUB Sections Figures References Abstract
    Introduction Related Works Methodology Results Conclusion References Acknowledgments
    Author information Editor information Rights and permissions Copyright information
    About this paper Publish with us Discover content Journals A-Z Books A-Z Publish
    with us Publish your research Open access publishing Products and services Our
    products Librarians Societies Partners and advertisers Our imprints Springer Nature
    Portfolio BMC Palgrave Macmillan Apress Your privacy choices/Manage cookies Your
    US state privacy rights Accessibility statement Terms and conditions Privacy policy
    Help and support 129.93.161.222 Big Ten Academic Alliance (BTAA) (3000133814)
    - University of Nebraska-Lincoln (3000134173) © 2024 Springer Nature"'
  inline_citation: '>'
  journal: Lecture Notes in Networks and Systems
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: 'Detection of Locusta migratoria and Nomadacris septemfasciata (Orthoptera:
    Acrididae) Using MobileNet V2 Quantized Convolution Neural Network, Kazungula,
    Zambia'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Jazaeri S.S.
  - Jabbehdari S.
  - Asghari P.
  - Haj Seyyed Javadi H.
  citation_count: '18'
  description: 'Software defined networks and the Internet of Things (IoT) are two
    major and emerging developments in networking that have much in common and their
    survival depends on each other. Software Defined Networking (SDN) is one of the
    5G enabling innovations that can help design complex, manageable, cost-effective
    and adaptable networks. On the other hand, Edge Computing (EC) will do automatic
    analytical computing on data from sensors, network switches, or other devices
    instead of waiting for data to be returned to a centralized data store. The IoT
    also requires a decentralized Internet, as the demand for real-time data analysis
    is growing and centralized processing systems are being overrun. So, it is necessary
    to provide a solution to encompass the advantages of EC, IoT and SDN simultaneously,
    as an integrated platform. In this research, after presenting a brief explanation
    about the key points of the SDN, IoT, EC and related concepts, and recent articles
    in this regard are investigated. This systematic literature review (SLR) study
    focuses on different frameworks and platforms that meet the mentioned requirements
    by considering the advantages of integrating EC, SDN, and IoT technologies. This
    platform provides centralized management of heterogeneous devices and architectures
    and supports the problem of resource limitations in IoT. The short output of this
    literature contains the following: (1) presenting a summary of review studies
    and research articles in this area which have been published from 2013 till 2021;
    (2) providing some key technical questions; (3) presenting some different technical
    classifications to categorizing the characteristics and features of EC and SDN
    in IoT; (4) discussing the key challenges; (5) Presenting future directions for
    research and open issues.'
  doi: 10.1007/s10586-021-03311-6
  full_citation: '>'
  full_text: '>

    "Your privacy, your choice We use essential cookies to make sure the site can
    function. We also use optional cookies for advertising, personalisation of content,
    usage analysis, and social media. By accepting optional cookies, you consent to
    the processing of your personal data - including transfers to third parties. Some
    third parties are outside of the European Economic Area, with varying standards
    of data protection. See our privacy policy for more information on the use of
    your personal data. Manage preferences for further information and to change your
    choices. Accept all cookies Skip to main content Log in Find a journal Publish
    with us Track your research Search Cart Home Cluster Computing Article Edge computing
    in SDN-IoT networks: a systematic review of issues, challenges and solutions Published:
    11 June 2021 Volume 24, pages 3187–3228, (2021) Cite this article Download PDF
    Access provided by University of Nebraska-Lincoln Cluster Computing Aims and scope
    Submit manuscript Seyedeh Shabnam Jazaeri, Sam Jabbehdari, Parvaneh Asghari &
    Hamid Haj Seyyed Javadi  1891 Accesses 16 Citations Explore all metrics Abstract
    Software defined networks and the Internet of Things (IoT) are two major and emerging
    developments in networking that have much in common and their survival depends
    on each other. Software Defined Networking (SDN) is one of the 5G enabling innovations
    that can help design complex, manageable, cost-effective and adaptable networks.
    On the other hand, Edge Computing (EC) will do automatic analytical computing
    on data from sensors, network switches, or other devices instead of waiting for
    data to be returned to a centralized data store. The IoT also requires a decentralized
    Internet, as the demand for real-time data analysis is growing and centralized
    processing systems are being overrun. So, it is necessary to provide a solution
    to encompass the advantages of EC, IoT and SDN simultaneously, as an integrated
    platform. In this research, after presenting a brief explanation about the key
    points of the SDN, IoT, EC and related concepts, and recent articles in this regard
    are investigated. This systematic literature review (SLR) study focuses on different
    frameworks and platforms that meet the mentioned requirements by considering the
    advantages of integrating EC, SDN, and IoT technologies. This platform provides
    centralized management of heterogeneous devices and architectures and supports
    the problem of resource limitations in IoT. The short output of this literature
    contains the following: (1) presenting a summary of review studies and research
    articles in this area which have been published from 2013 till 2021; (2) providing
    some key technical questions; (3) presenting some different technical classifications
    to categorizing the characteristics and features of EC and SDN in IoT; (4) discussing
    the key challenges; (5) Presenting future directions for research and open issues.
    Similar content being viewed by others A Survey on Software-Defined Networks and
    Edge Computing over IoT Chapter © 2019 Resource optimization in edge and SDN-based
    edge computing: a comprehensive study Article 08 February 2024 Toward integrating
    software defined networks with the Internet of Things: a review Article 07 September
    2021 1 Introduction With the increased demands for smart devices, many delay-sensitive
    IoT technologies, such as industrial automation, face recognition, and online
    gaming, have arisen and drawn the interest of many researchers. [1, 2] IoT is
    the 3rd generation of the Internet that is supposed to bind billions of heterogeneous
    devices in an intelligent manner [3]. To obtain information through the measurement,
    collection, transmission, analysis, and distribution of data on large and small
    objects, control systems are needed to manage multiple networks for the further
    evolution of IoT. In fact, researchers believe that objects (like 75 billion devices)
    are going to more linked to the Internet than individuals by 2025 [4]. With the
    advancement of the IoT, it is necessary to pay attention to how they interact
    and use within separate networks and with many heterogeneous measuring devices.
    Additionally, network connectivity requirements, for IoT or smart environments
    vary in the type and size of packet data, bandwidth, applications and different
    levels of fault tolerance in existing networks [5, 6]. To overcome these problems
    and allow more systems to communicate with great range of devices new advances
    for example, edge computing (EC) and software-defined networking (SDN) are required
    for gaining improvement in IoT services [7]. SDN is a technology that can respond
    to present IoT requirements with regard to heterogeneity and flexibility as well
    as providing centralized control and an overall view of the whole network [8].
    SDN also isolates the control capability from the data forwarding and sets the
    network operation parameters for the controller known as the control plane. Centralized
    control optimizes and adjusts the network effectively and dynamically, whilst
    still ensuring interoperability across heterogeneous IoT networks. This centralized
    control plane can be a trusted architecture for the IoT network, for example,
    smart home applications block unauthorized users from accessing smart devices.
    There are many researches for solving the problem of integrating IoT with different
    networking approaches which use the advantages of SDN [9]. In cloud computing
    environments, tens of billions of devices are placed at the edge of network and
    also computations are done by the end-user (EU) devices which their processor
    speeds are exponentially increasing during the time. The EC has a lot of variation
    e.g., cloudlet [10], fog computing [11], mobile EC [12]. EC provides motion support,
    position awareness, extremely low delay, and proximity to the user [13]. These
    highlights make EC reasonable for numerous applications like industrial automation,
    virtual reality, real-time traffic monitoring, building automation, data analysis,
    and many other cases with massive computing [14]. The remainder of this paper
    is structured as follows: Motivation is explained in “Motivation”. In “Structure
    of SDN-EC-IoT technologies” the structure of SDN-EC-IoT technologies is explained.
    “Research selection method” provides a research selection method applied in this
    study. The associated work is mentioned in “Related work” which includes recent
    review studies and research articles. Summary and insights present in “Summary
    and Insights”. Also, this section presents different technical taxonomy for the
    role of EC and SDN in IoT to classify its characteristics and features. In “Discussion
    and open issues”, the studied EC-SDN-IoT architectures are discussed and analyzed
    systematically as an exploration of new challenges and open issues in this area.
    Finally, “Conclusion” presents the conclusion as well as the study limitations
    in this field. 2 Motivation Next-generation of IoT networks should have the option
    to meet the fundamental prerequisites of latency, energy consumption, bandwidth
    and continuous mobility [11]. Recently, IoT applications have used distributed
    smart EC systems instead of clustered cloud computing solutions. Also, distributed
    EC solutions are introduced at the edge of the network where information is generated
    and suitable for real-time service. New technological tendencies bring recognition
    and intelligence to IoT technologies, architecture, standards, protocols, data
    attainment, and analysis, all with a business, industrial, or social purpose [15].
    Since many different systems become integrated, the IoT should face complex interoperability
    challenges with seamless movements of devices and data for creating real-time
    and cross-domain services. Nevertheless, a lack of stable performance and the
    variety of devices available damage the promised interoperability. Distinctive
    IoT applications may run at the same time and share the same resources of network.
    Conventional architecture for IoT network is not adaptable and productive sufficient
    to handle expansive sums of IoT information. This may cause the congestion of
    IoT networks [16]. Therefore, some of the challenges in this regard can be mentioned
    as follows: Due to the variety of IoT devices and the need for accessing the Internet,
    different access points (APs) are considered in IoT networks [9]. Therefore, it
    is impossible to determine the appropriate locations for a limited number of clouds
    among countless applications. With the increasing and dynamic demand for resources
    in IoT networks, resource management issues such as resource allocation and resource
    planning will become more complex than in the past [17]. Choosing dynamic routing
    routes to avoid network congestion as well as optimizing resource usage is not
    an easy task due to the heterogeneity of IoT resources and mobile devices. Also,
    data streams should be routed to other existing clouds depending on the state
    of the dynamic network [18]. Due to the importance of reliability issues, integrated
    service delivery can be considered for increasing fault-tolerant in IoT systems
    [19]. Due to the different types of infrastructures, such as clouds, fog, edge,
    and mobile cloud, the challenge of how to manage a flexible and efficient network
    has remained an important issue that should be addressed [20]. The use of SDN
    technology makes it possible to overcome these challenges in SDN-EC-IoT and allows
    for integrated network management, efficient, scalable, seamless and cost-effective
    manner. [9]. By using SDN, IoT devices requests can be intelligently managed and
    also, control plane manages and transfers computational loads to the cloud [21].
    Most of the recent studies have examined SDN-EC-IoT networks constraints from
    different angles and focused on interaction and collaboration between the edge
    and cloud. However, in this article, we examine SDN-EC-IoT networks with a different
    perspective in terms of architecture as well as expressing the advantages and
    limitations that were raised so far besides the opportunities and open issues
    in this regard. The key contribution to this systematic review are highlighted
    as follows: (1) Presenting a summary of review studies and research articles in
    this area which have been published from 2013 till 2021. (2) Providing some key
    technical questions. (3) Presenting some different technical classifications to
    categorizing the characteristics and features of EC and SDN in IoT. (4) Providing
    a discussion of the major problems. (5) Outlining future directions for study
    and open issues. 3 Structure of SDN-EC-IoT technologies This section discusses
    the key technologies that are used for efficient SDN-EC-IoT networks. These technologies
    are explained separately and details of their combination are provided. In addition,
    the structure of the integration of EC and SDN technology in IoT is presented.
    IoT is focused on a wide range of smart devices with diverse connectivity and
    network features. So, it needs a lot of data storage and processing. Sensors are
    gathering data from the physical domain. These data are then used by IoT applications
    such as smart transport, hospitals, precision farming, monitoring videos, and
    so on to deliver desirable services for end customers. As IoT devices are generally
    characterized by limited memory and computing resources, IoT applications typically
    use the cloud and its services to store and process data [1]. Figure 1 depicts
    different types of IoT technologies, since IoT has several models the researchers
    have named them based on technologies during development and innovation. Fig.
    1 Different types of IoT technologies Full size image SDN is a new paradigm that
    creates a dynamic network structure by separating the data plane and control plane
    [21]. It is the responsibility of the control plane to decide on new incoming
    network traffic flows and a part of the network that is referred to as the data
    plane that is responsible for forwarding traffic. A centralized controller and
    distributed forwarding devices or switches are usually included in the SDN. The
    controller links and communicates with network devices using a standard interface,
    such as the OpenFlow protocol [22]. The SDN makes the system more flexible and
    scalable which makes it considered as part of all the systems that have just been
    developed. As shown in Fig. 2, there are three main components in an SDN-IoT architecture:
    the controllers, the data planes, and the application layer. Network architecture
    aspect describes how a networking and processing framework should be used to integrate
    open software-based systems and commodity networking hardware through splitting
    the control plane from the data plane and define application layer components
    for IoT. SDN-IoT networks use dynamic operating modes that adaptive to constrained
    IoT networks and it depends on their controller mode instructions including central,
    distributed, or hybrid modes [8]. SDN also enhances control applications, providing
    the ability to manage data sharing and delivery. This is particularly useful where
    edge computing is applied, third-party applications and edge networks are enabled
    when distinguishing network and data links. SDN facilitates efficient and scalable
    internal operations through a variety of data platforms and smooth management
    of delivery, installation, and operation for third parties. [23]. Fig. 2 IoT’s
    behaviors by SDN Concept Full size image To analyze the data, SDN helps generate
    big data from theory to reality. SDN technology allows companies to create very
    large networks and easily manage them using standard equipment. SDN also helps
    quickly collect and analyze data. Software-based networks can be used as a big
    data infrastructure. Large data processing software requires architecture with
    agility, multitasking, and central management features, and SDN seems to be able
    to meet these needs, in addition to solving these problems. Security, control,
    and management of internet-connected devices will be enhanced if SDN capabilities
    are employed [24]. Recently, IoT technology made great progress towards the mainstream
    of applications [17]. SDN is also considered as a trigger for further development
    in IoT network and it can provide opportunities for flexible IoT [25]. Studies
    show SDN can easily solve many long-standing drawbacks of conventional IoT, such
    as system control, automation environment, security problems [26]. However, there
    are still barriers need further progress to respond to how to optimize network
    by SDN-IoT network’s control plane boost service efficiencies and minimize network
    costs. At the moment, SDN-IoT controllers have deployed on IoT gate away from
    IoT devices [27]. IoT platforms are more complex than simply connecting devices
    to the network and they are always associated with various technical and functional
    problems. As the number of devices grows (more than the number of vendors), networks
    are getting more complicated, more difficult to control and more vulnerable to
    security threats. The integration of EC and SDN has contributed to a solution
    to many of the problems and uncertainties facing the IoT service industry. Using
    EC on open-source platforms and SDN management, cause simplifying implementations
    of reliability, real-time and secure operations with the benefit of increasing
    the number of linked entities and useful data that items generate in IoT. [28].
    On the other hand, edge computing (EC) may be a model that points to supply cloud
    services counting capacity, computing, and handling at the edge of networks one
    or two hops from the end-user. This innovation presents a way of moving from the
    centralized tremendous data centers to the dispersed cloud units with constrained
    capabilities [10]. Deploying the EC in any network accomplishes different benefits
    counting picking up a better system bandwidth, diminishing the communication latency,
    giving away for data offloading, and presenting novel service to the network [26].
    SDN is a technology that''s able to back the move of information between edge
    nodes and cloud datacenters. The presentation of EC and SDN innovations can effortlessly
    support mobility and administration of the network [8]. In an introductory caution
    framework, these edge nodes incorporate administrations for getting information
    through sensors, sifting the input data flow, collecting the measured values,
    and sending the data to the \"alert trigger\" which is another benefit that EC
    is done. So, an EC layer can offload noteworthy traffic from the DC and core networks,
    it improves QoE, and enables location awareness, low latency for time-sensitive
    or real-time applications [29]. In this paper, the architectural structure of
    the integration of EC and SDN technology in the IoT is considered, since the requirement
    for data administration is a vital discrepancy between IoT administration and
    conventional network administration [30]. Conventional network innovations need
    the profundity of in-service investigation that''s accessible within the current
    era of network observing applications. For the IoT, gathering, analyzing, and
    uploading data is the matter and SDN gives the network adaptability to incorporate
    a wide scope of situations. Also, SDN with the capability to handle data subscriptions
    and distribution makes support oversee applications. The integration of EC and
    SDN provides a way to deal with many of the issues and complexities of IoT networks
    [31]. As a motivational example, Fig. 3 is a schema for EC-SDN-IoT architecture
    which includes different sections: Fig. 3 The overall view of EC-SDN-IoT structure
    Full size image As shown in Fig. 3, three layers are observed: (1) IoT access
    layer, (2) EC layer, and (3) Cloud Computing layer: (1) IoT access layer: Things,
    sensors or users with large internet access and sensors can calculate different
    parameters (e.g. barometric pressure, humidity, temperature, and other environmental
    factors) and users can also use online app solutions through interconnected devices
    like smartphones. [6]. (2) EC layer: At the EC layer, edge nodes serve gateways
    and data capture facilities capable of operating on raw data, e.g. in real-time
    data analysis, data visualization, simple analytics, data compression and buffering,
    and real-time data filtering. This layer is where cloud services are delivered
    and transmitted to end users and computers. This is the primary reason why the
    EC is also known as ubiquitous computing. (3) Cloud computing layer: This layer
    contains cloud could come from various providers which can be used for lengthy
    storage and operations for data analysis at the application level, which is usually
    less time-sensitive. There are many services in this layer such as cloud processing
    [32]. The EC-SDN-IoT architecture shown in Fig. 3 offers the following improvements
    such as: Improve performance of applications: Local data processing in edge nodes
    at the EC layer along with end-users or end-devices instead of cloud computing
    layers can be used as a way to reduce delay and response time and therefore raise
    QoS of applications [27]. Minimizing energy consumption: Fast development of the
    number of IoT and users that are connected to the Internet always accompanied
    by the request for maximum energy efficiency. It is possible to unload tasks from
    end-devices to edge nodes. This truth makes a difference to diminish energy consumption
    [21]. Location awareness service: As a result of EC architecture, end-user’s data
    like their location, status of network, mobility, behavior, and environment can
    be tracked to be rendered efficient services. This ensures the needs and preferences
    of end-users for the quality of experience (QoE). [17]. Reduce network’s traffic:
    At the edge of computing, nodes can filter out nonessential data and only collect
    key data which requirements to be transferred to the cloud computing layer, afterward
    receive, store and process them [22]. Simplify load balancing approaches: The
    EC has presented novel features of transfer services like migration services between
    the cloud computing layer and EC layer to help load balancing on requests by improving
    computing power at edge nodes in comparison with conventional and intensive computing.
    [27, 33]. 4 Research selection method This part provides a review focused on the
    SLR method [34] as a research study evaluation for the classification of integration
    EC and SDN technologies in IoT. Figure 4 shows a principle for selecting the studies
    through inclusion/exclusion phases. Fig. 4 Selection considerations and assessment
    process for academic papers Full size image The used inclusion process steps for
    selecting the final mapping studies are as follows [35]: Researches published
    online from 2013 to 2021. Researches on benefits of integration EC and SDN technology
    in IoT networks. Researches which offered effective technical methods in EC-SDN-IoT
    networks. The applied exclusion process steps on the articles are as follows:
    Researches which are presented as book chapters, short articles, and white papers.
    Researches which are not presented in the English language. Researches did not
    pass a peer-reviewed process. This article gives wide answers to the subsequent
    technical questions (Qi) about the objectives of this research [34]: Q1: Why SDN
    is vital for IoT Networks? Q2: What are the advantages of EC in IoT Networks?
    Q3: Where SDN meets EC architecture? Q4: What are EC challenges for the IoT Network?
    After bringing up the technical questions (Qi) and selecting the papers by the
    mentioned methodology, and given the number of published studies, we just examine
    the journal articles and conference papers referred to in the WoS and ISI proceedings
    as relevant and peer-reviewed articles for EC in SDN-IoT. Finally, the 74 articles
    were considered for further assessment to answer the provided technical questions
    that are responded in “Discussion and open issues”. The papers that have been
    studied in this article can be classified into three groups according to their
    objectives including new frameworks, designing new architectures, and purpose
    of routing and data transferring techniques which are depicted in Fig. 5. Academic
    papers published by major scientific publishers on article citations and methodologies,
    including Elsevier, IEEE, Springer, ACM, Wiley, as well as other publishers (Fig.
    6b). Papers that provide new frameworks Papers aimed at designing new architecture
    Papers with the purpose of routing and data transferring techniques in the network
    Fig. 5 Distribution of the research papers over the purpose in selected papers
    Full size image Fig. 6 a Analyzed published articles in SDN-IoT and EC-SDN-IoT
    networks based on year, b The percentage of selected articles base on publication
    Full size image Extracting taxonomy and classification in which the property and
    component are specified is fully defined and described in “Summary and Insights”.
    The analysis of the proposed EC-SDN-IoT frameworks on the basis of the date of
    publication is shown in Fig. 6a. It shows that most of the selected papers are
    published between 2017 and 2021 and only 23 of the 74 selected papers are published
    before 2017; it is highlighted that the citations to this systematic review are
    new. 5 Related work Due to the popularity of using EC in IoT networks, many studies
    have been conducted in this field. This section presents two groups of related
    works on different aspects of EC, SDN and IoT networks including (1) recent review
    studies, and (2) recent research studies. It should be noted that the taxonomies
    that have been provided based on reviewing the articles in this section are presented
    in detail in “Summary and Insights”. 5.1 Recent review studies In recent years,
    there have been several surveys based on various factors of virtualization using
    SDN and cloud computing for the IoT, as well as edge computing for IoT [8, 26,
    36,37,38,39], and fog computing [28, 32, 40, 41]. There are some surveys on the
    integration of EC computing, SDN, and IoT technologies. Hence, with a different
    view of this issue that has examined by considering several aspects such as architecture,
    virtualization, requirements, and standards, we motivate to systematically review
    the selected related articles to obtain a new achievement in the integration of
    SDN, IoT, and the Edge computing called EC-SN-IoT. Instead of presenting the explanations
    about the related review in a textual format, we present a summary that includes
    the authors’ name, publication year, research directions or potential solutions,
    limitations and opportunities of the related review studies in Table 1. Table
    1 Recent Survey Articles related to EC-SDN-IoT Full size table 5.2 Recent research
    studies Recently, a number of articles have presented different architectures
    for the integration of SDN and IoT technologies, and in some of them, the subject
    of cloud computing, fog computing, and edge computing have been examined that
    some of them are described in this section. A brief comparison between the studied
    articles is presented in Table 2. Table 2 An Overview of recent proposed frameworks
    for implementing edge computing in SDN-based IoT Full size table In [47], an innovative
    method was proposed for fog node implementation and routing in SDN-based wireless
    networks for IoT systems. The SOSW model computes the optimal positions for fog
    nodes using singular-value decomposition (SVD) and QR factorization with column
    pivoting linear algebra methods on the network''s traffic matrix. In [48], an
    architecture was proposed for using in today''s IoT ecosystem. Each tier of the
    SD-DRFC framework''s task and functionality is thoroughly clarified. The SD-DRFC
    architecture is then used to present and model a use case using the iFogSim simulator.
    Latency, Network Usage, Cost, and Energy Consumption were QoS parameters used
    to assess the utility of the presented SD-DRFC structure. In [49], the authors
    discussed the characteristics of IoT data, developments in IoT network architectures,
    certain issues in IoT data analysis, and some proposed solutions. They also considered
    software-defined edge computing as a potential architecture for meeting the special
    requirements of IoT data analysis. The authors presented an experiment on data
    anomaly detection in this architecture, with results demonstrating that the approach
    is accurate and feasible. In [50], the authors concentrated on the infrastructure
    configuration and implementation of a 5G open networking (ON) solution, the methodology
    of SDN/NFV-based 5G and IoT, and how AI/ML interacts with and learns from 5G/IoT.
    This interaction is referred to as SDN-based 5G/IoT Network AI or AI-enabled SDN-based
    5G/IoT Network. This article discussed a number of industries that have been raised
    by using AI/ML/DL strategies to serve as a tool or as an assistant to improve
    the other industries. In [7], an adaptive optimization technique that is focused
    on the Salp Swarm Optimization Algorithm (SSOA) was suggested by introducing the
    chaotic mapping to increase the efficiency of the optimizer. The algorithm automatically
    determines the optimum number of controllers and the optimum relation between
    switches and controllers in a large-scale SDN. In this research, cost and delay
    problems of controller placement were focused on. The chaotic SSA was designed
    to find the optimum number of controllers as well as the optimum location of switches
    and controllers to minimize delays and costs. It increases efficiency and avoids
    local optimization. In [9], a method was proposed for optimizing the replacement
    of clusters (cloud tasks) to reduce the average delay of access using SDN, adaptable
    and customizable management of clusters in IoT in terms of queue processing complexity
    in excessive SDN-based access points. Initially, an EOPA 1 was introduced as a
    benchmark. The RNOPA 2 was proposed, which adapted to the mobile IoT and their
    traffic load is managed dynamically. To do this, each access point functions as
    a server queue that adopts an effective ranking mechanism. The simulation results
    show that RNOPA reports are very close to the EOPA method in terms of access delay.
    In [10], The SDN software and hardware switch model was contrasted with an observational
    approach for comparing the performance of software and hardware switches. A unite
    queuing model was proposed to improve performance in SDN. The unit queuing model
    is an analytical method for engineers to forecast delay, packet loss, and SDN
    performance. The existing SDN queuing models focus on the analysis of the efficiency
    of software switches, while the proposed approach initially provides a joined
    analysis of software and hardware switches. In [11], a framework for determining
    and predicting the number of SDN controllers based on the Software Reliability
    Growth Models (SRGM) model was proposed that can model the random process of bug
    emergence in open source SDN controllers. In this research, the SRGM framework
    focuses on various applications for managing SDN-driven networks. In this study,
    guidelines are provided for network operators to decide on using the controller
    software in the operating environment based on the need for network application
    reliability that reveals its benefits in the software quality assurance phase.
    In [12], a framework was proposed for the structure of the IoT, which uses the
    edge computation layer for fog nodes. The framework uses the SDN with the central
    controller and the OpenFlow distributed switches. These switches have minimal
    storage and memory capacities. The network works on the basis of a data unloading
    algorithm (load distribution) that assigns any computing and computational tasks
    to certain OpenFlow switches that use idle resources. The approach described has
    several advantages for the IoT such as reducing delay and increasing resource
    efficiency. Experimental results in the testing environment to assess the proposed
    method show that the proposed method has achieved high efficiency in terms of
    delay and resource utilization. In [13], the SDN framework called SDN-based framework
    for the heterogeneous IoT (SHIoT) was proposed to resolve some of the challenges.
    SHIoT relies on a set of choices to determine end-user requests and defines an
    SDN controller for categorizing scheduling at the task level. Moreover, the Lagrange
    relaxation theory is used to optimize the routing mechanism. The implementation
    of the proposed method shows that SHIoT can support high-density networks and
    adds great benefits to older networks without SDN. Its goal is to make the transparent
    link between the user interface layer and other lower-level layers to enhance
    user convenience, which reduces the complexity of the lower levels. In [45], a
    new bulk level mechanism (BLLC) was proposed considering one of the network unresolved
    challenges that include the way of updating the network securely with fewer resources.
    The main idea is to categorize control commands for new flows and update the network
    from destination to source. First, update trees are created for all new flows
    according to the network status and compatibility features. Then the new rules
    are packaged in an updated tree and they become a UBCP package. Experiments show
    the feasibility and effectiveness of the proposed method. The simulation results
    in the self-organized testing environment with the Matlab simulator show that
    BLLC reduces link costs by an average of 68% and the update time increases by
    an average of 10%. In [14], because the current level of the single-control plane
    is on the remote IoT gateways and can create bottlenecks with the continuous growth
    of IoT and applications, a two-level hierarchical control system (master and slave)
    has been established to solve this issue. A SCPS 3 has also been suggested to
    maximize control performance. In the end, several experiments were used to assess
    the efficiency of the proposed Matlab technique. The results of comparisons with
    other approaches show that the proposed method reduces the critical delay of controlling
    IoT by approximately 30.56%. In [18], a traffic-aware QoS routing model in IoT
    is suggested based on the SDIoT software. The proposed method extracts single
    attributes of SDN such as flow-centric nature and network flexibility to establish
    the quality of service required by each flow in the network. There are two types
    of routing service quality (1) delay-sensitive and (2) missing-sensitive for incoming
    packets from the final devices in the network. The first one addresses the provision
    of delay-sensitive services and the second is sensitive to the missing flows and
    aims to increase network performance. A greedy method based on Yen’s K-shortest
    paths algorithm is proposed to calculate the optimal forward path according to
    the quality of service required by each packet. The findings of the simulation
    indicate that the proposed approach reduces the quality of service by 13–15 percent
    (with AttMpls topology) and 37–39 percent with 2000 network flows through Goodnet
    topology compared to LARAC, SPD, and MRC methods. In [21], a multi-protocol edge-based
    architecture called Muppet 4 was proposed for use on the IoT with large-scale
    and automated services. Muppet is a switch based on a P4 that the difficult parts
    integrate among the communication tools of IoT with different protocols. The switches
    are networked over IP, support wide-area use, and are managed for scalability
    using SDN control. Muppet combines the advantages of local peer-to-peer and cloud
    computing methods, while it does not have its disadvantages. Using SDN architecture
    has enhanced the capabilities of peer-to-peer modes thus retaining low delays
    and low power consumption. Besides the second application guarantees the continuous
    operation of the IoT service even if the SDN controller coordinator node is broken.
    Existing networks often encounter problems such as the complexity of control protocols
    and the network between large numbers of smart devices [22]. These barriers create
    significant constraints on the use of Internet services for objects from different
    providers on a network. In [22], SDN/NFV is not only seen as a key innovation
    in new technology and services but also is considered as a new model of network
    structure that measures the needs of the IoT. In this article, an application
    was developed for slicing end-to-end network segments to estimate the needs of
    using the IoT from different providers besides improving an IoT service when being
    outside the community. In this architecture, three applications were built on
    top of the SDN controller. Based on evaluating the proposed method, all implementation
    was performed in Mininet and POX. Simulation results show that networks can be
    slice in a variety of ways. The proposed method guarantees the smooth and continuous
    operation of the IoT even if a node is damaged under the SDN controller''s coordinator.
    In [17], new software-defined hybrid architecture is proposed for integrating
    with the IoT, which is a basic technology for smart environments. This architecture
    combines the superstructure of SDN with a real-time distributed network framework
    with optimization for self-configuration, self-management, and self-compatibility
    and provides error-free and efficient communication for many heterogeneous tools.
    The new SDN architecture combines IoT to support the new generation of IoT. In
    the proposed architecture, OpenFlow switches (OF) are used, which are capable
    of supporting traffic services in accordance with the characteristics of the flow
    combination between the old networks and SDNs. In [46], The proposed architecture
    is a complete framework for IoT device networks that provides resource allocation
    strategies with cellular network optimization focused on SDN. Given that configuration
    management, resource allocation, and network communication patterns are very difficult
    in cellular networks, SDN plays an important role in the control of such heterogeneous
    networks, so that the SDN model can be extended to various levels of the cellular
    network. In [1], the UbiFlow architecture was proposed that provides efficient
    flow control and urban mobility management using distributed SDN controllers.
    Proposed architecture indicates the IoT network is clustered into small networks
    distributed by the physical SDN controller. In each section, IoT devices may connect
    to different access points and requests various data. In [25], a framework for
    managing and controlling called SDIoT was proposed. The data is gathered from
    sensors in the IoT bridge. Then the gathered information is sent to the SDSec
    controller for control in terms of security. Access is given with only one approved
    device. SDN controller and stored in the SDStore module determine authentication
    and permission controls via the data obtained for routing and controlling tactics
    [7]. In [19] a novel software-defined application was suggested that facilitates
    a dynamic and flexible infrastructure for communication in 5G-IoT, based on the
    SoftAir 5G system architecture as an improvement way for efficient data transmissions.
    To do so, SoftAir separates the control plane and data plane from a software-defined
    wireless architecture and enables effective coordination between millimeter interface
    (mmWave) remote radios (RRHs) for IoT access. Then a creative architecture of
    SD-GWs and SoftAir local IoT controllers has been launched to conveniently handle
    the large range of IoT applications and the heterogeneity of IoT systems. Table
    2 depicts a comparison and evaluation of various proposed methods of, SDN-IoT
    network research in terms of purpose, implementation methods, advantages, and
    disadvantages in their scheme. One of the questions that researchers, especially
    students, always face with is which simulator is recommended for SDN-IoT simulation.
    Here is a comparison of simulation methods according to the reviewed articles
    to help choose the simulation environment. As Fig. 7 illustrates the considerations
    show that the most popular simulator and emulator is in this context Mininet,
    because it is used in both simulation and emulations. Fig. 7 Statistical comparison
    of simulation environments in the reviewed articles Full size image Since different
    architectures have been provided for SDN-IT, each of which has a specific purpose.
    Among the most important of them: fine-grain policies management, distributed
    traffic classification, resource management, mobility support, traffic offloading,
    mobility management, and policy control. We thoroughly reviewed the articles''
    objective (e.g., QoS enhancement) and attributes (e.g., scalability), and summarized
    them in Table 3. Also, Table 4 depicts the main objectives of architecture solutions
    for SDN-based IoT [8, 28]. For example, using SDN technologies, in particular
    controllers, solves issues such as IoT management, preservation, control and cooperation.
    Also, data upload support is another essential SDN feature [68]. Table 3 Overall
    classification of features and objectives of cited papers in the domain of EC-SDN-IoT
    architecture Full size table Table 4 The main objectives of architecture solutions
    for SDN-based IoT Full size table Increasing the performance of implementing Edge
    Computing in SDN-Based IoT is one of the most important objectives in the described
    papers. In addition, increasing the QoS/QoE and its scalability are investigated
    in some studies. Supporting heterogeneity, resource management, and reliability
    are highlighted in these papers. The selected articles in Table 2 have checked
    the parameters of implementing Edge Computing in SDN-Based IoT frameworks. The
    obtained results are explained in “Recent research studies” and Fig. 8. It shows
    that the performance, QoS/QoE, scalability, and heterogeneity support are the
    most beneficial parameters that are described by researchers in proposed frameworks
    for EC-SDN-IoT. Fig. 8 a The percentages of EC-SDN-IoT parameters, b Analysis
    of Parameters in frameworks for EC-SDN-IoT Full size image According to the proposed
    architectures and studies conducted in research, the role of SDN in improving
    some factors such as scalability, resource management and traffic engineering
    in IoT networks is undeniable. In Fig. 9, a statistical analysis of the impact
    of using SDN in IoT network architecture is illustrated. It shows using SDN in
    IoT networks has the highest role in traffic management of about 50% of cited
    papers. As is presented, the impact of SDN on the scalability of IoT networks
    is undeniable. Also, about 20% of the reviewed articles considered the role of
    SDN in managing IoT networks to be effective. Fig. 9 Statistical analysis of the
    impact of using SDN in IoT network architecture Full size image 6 Summary and
    insights In this research, we reviewed, highlighted, and reported recent developments
    of EC techniques including cloudlets, fog computing, and mobile edge computing,
    also SDN technology according to measuring their effect on IoT. Based on the review,
    we found that in research, the focus is more on transferring and storing data
    from IoT devices resources at edge nodes, performing analysis and then returning
    the results to IoT nodes. In essence, the benefits of EC, as the best solution
    to meet the computing needs of IoT, such as using edge node to reduce response
    time in IoT applications, to balance network traffic, reduce transmission delay,
    and increase the lifespan of IoT devices and prevent congestion on IoT networks.
    We explored the role of SDN and EC technologies in IoT networks and organize items
    in taxonomies to help researchers and give them a deeper view of architecture.
    In the following, we will explain the different parts of this architecture and
    the features of each part in more detail below, and we will point out the advantages
    of each of the technologies. Topics in this section are listed below: Role of
    EC in IoT Role of SDN in IoT networks IoT and QoS improvement techniques Edge
    Frameworks for SDN-IoT 6.1 Role of EC in IoT IoT, as the 3rd generation of the
    Internet [12], is supposed to bind a vast number of different types of devices
    that are not homogeneous. This massive volume of connected devices has caused
    many restrictions on the structure and design of the system. These challenges
    include [45, 102]: Wide area network coverage Heterogeneous devices and various
    standards of communication supported High reliability Security and privacy Interaction
    and integration with other communication networks Scheduling restrictions for
    some applications A load of traffic To solve these challenges to achieve higher
    operational efficiency and conveniently attach to this large number of devices,
    there is a need for new technologies to provide services to the IoT. These technologies
    include EC and software-defined network (SDN) [18]. Figure 10 highlights the features
    and mentioned recent advances in EC technologies regarding the assessment of their
    effect on IoT. We devise a technical taxonomy to show the role of EC in IoT to
    classify its characteristics and features. Besides, it enumerates computational
    platforms, applications, service level objectives computing nodes, network characteristics,
    data type, and access technologies used in EC on IoT networks. Computational platforms:
    Fig. 10 The taxonomy of different aspects of the EC role in IoT Full size image
    - Cloud computing: Cloud computing has become a prominent paradigm of computing
    and IT service delivery. The concept behind the cloud is to lease data equipment
    from the cloud to pay for the services delivered. The cloud offered three major
    services: SaaS (Software as a Service), PaaS (Platform as a Service) and IaaS
    (Infrastructure as a Service) [102]. - Mobile EC: A middle level, between end-devices
    and the farther cloud, comprising of purpose-built servers, APs, 5 or base stations.
    This offers quick to get to cloud services and added advantage of offloading the
    network/cloud framework, likely incapable to maintain the developing request for
    mass ICT administrations. [31] - Fog computing: Fog computing may be a shape of
    EC that is appropriate for IoT systems. Fog computing presents a novel computing
    paradigm as an expansion to cloud computing and ready to supply processing, computing,
    capacity capabilities, and other cloud administrations to communication nodes
    within the region of the dispersed Fog nodes. Fog computing is suggested as a
    complement of cloud computing, that bringing computational means into nearness
    to end clients [103]. - Cloudlets: Cloudlets are considered as miniature clouds
    and situated at the middle layer of the end-device, cloudlet, and hierarchical
    cloud system. Basically, cloudlets are intended for stretching out cloud-based
    administrations to mobile device clients and can supplement MCC [9]. - Mobile
    Ad hoc cloud: In spite of the comprehensive essence of MCC, the lack of infrastructure
    or cloud computing paradigm has always focused on scenarios that are not appropriate.
    An ad hoc mobile network comprises nodes that form an impermanent and dynamic
    network via routing and transportation protocols. This is a configuration of a
    network that is typically decentralized [41]. - Hybrid computing model: In this
    model, the cloud and fog meet up and are made accessible to the systems. In this
    model, the cloud presents virtualized computing, capacity, and resources for networks.
    while the fog quickly planning to use the fixed and flexible computing resources
    found at the edge of networks to develop the processing capacity. It gives clients
    to have better control over a virtualized structure, and joining the capacities
    from particular kinds of cloud propagation are fulfilled through standardized
    or dedicated innovation. [41] Applications: application categories currently use
    in EC. - Computational offloading: Computational offloading decomposes the optimization
    problem into a series of sub-problems, and solves them together in an online and
    distributed manner. The analysis shows that a trade-off between performance and
    offloading cost should be considered. - Collaborative computing: There are three
    methods for the cooperation of nodes in EC, Collaboration methods such as clustering,
    P2P-based node interaction, and master-slave-based nodal collaboration. - Cluster:
    Nodes at the edge may preserve a similar execution environment by creating a cluster
    between them on the basis of their position or homogeneity. In clustering among
    nodes, there are two ways for making cluster-based collaboration of edge nodes,
    static formed clusters (scalability is difficult to implement) and dynamically
    formed clusters (relies on the resource required and the performance of edge nodes).
    - Peer to peer: In EC, cooperation between P2P 6 and nodes are so common. Collaboration
    in P2P tends to be flat or hierarchical. Also, via collaboration in P2P, in addition
    to the fact that virtual computing is common among nodes, the processed output
    from one node is displayed as input to another node, but also instances. Reinforcing
    fog nodes in P2P collaboration is very simple and nodes can be reused. However,
    reliability and access control prevail over P2P node collaboration. - Master-slave:
    In EC, during each operation, through master-slave-based nodal collaboration,
    the operator shift to the master edge node from the slave edge node, reads order
    information, and releases additional information. The salve edge node sends a
    task requirement to the master edge node based on the task attributes in standby
    mode. In general, features, resource management, processing load, and data flow
    are controlled by the master edge node. Also, a combination network can be created
    in an EC environment with a master-slave approach using clustering and P2P-based
    node interaction. [32]. - Memory replication: IoT applications based on integrated
    edge cloud mobile networks can scale the needs of computing and storage to support
    the provision of various intensive resource services. Despite this potential,
    the sheer number of IoT devices is limiting mobile networks in response to the
    edge cloud, as the mobile network''s radio interface is accessible due to its
    scalability, uplinks access, and data transfer methods to support large numbers.
    The devices that are replicating their memory with edge cloud at the same time
    become the main bottleneck [16]. - Content delivery: CDN is a dispensed network
    covered by the current network infrastructure and consists of several data centers
    that provide content to end-users with high access and high-efficiency services.
    CDN can provide a wide range of content providers, such as web objects, social
    networks, and live streaming media. Edge DC (data center), which has storage resources
    distributed on the edge of the network, are natural entities for storing content.
    In addition to storing simple content, DC at Edges can take full advantage of
    computing resources to further process stored local content and provide the best
    service to users. Beyond the CDN, EC can also optimize web-based applications
    using its knowledge of network conditions and user conditions (e.g., network status
    and computing load) [39]. - Online caching: The caching problem involves two steps:
    content delivery and cache placement. Many works have been done on how to update
    the cache in the placement phase. Although, updating the rules of caching are
    more efficient at the delivery stage, online caching [104]. Similarly, by placing
    a service, cache data on edge nodes will also greatly minimize data recovery times
    relative to relying exclusively on the central data store [41]. Service level
    objectives: Various service-level strategies in the area of IoT and EC are classified
    into different categories [9]: - Latency management: This is an important issue
    for IoT-based smart applications. To achieve QoS, and the delay-sensitive IoT
    application (e.g., online games and intelligent transportation) need a substrate
    alternative such as EC which will ensure timely service delivery. High computational,
    connectivity (service), and network latencies contribute to high latency in IoTs
    and cloud. The ability to provide minimal network, service, and computation latencies
    for real-time applications is a critical requirement of IoT [105]. - Cost management:
    Using proportional platforms to activate EC requires the creation of infrastructure,
    which includes rapid investment and expenses. To optimize and minimize the overall
    cost of the network, most of the costs associated with network nodes must be consciously
    planned and managed. In this regard, creating the optimal number of nodes in the
    right conditions can significantly reduce CAPEX and OPEX cost also by arranging
    edge nodes can minimize OPEX cost [71, 106]. - Network management: Utilize EC
    features to manage connections, congestion, and virtualization in IoT networks
    is one of the service level objectives. - Application management: Application
    management is applied for programming management features such as programming
    and scaling. - Data management: As a vast number of IoT devices are required to
    generate significant volumes of data that must be handled on time. Efficient data
    storage and management systems shall be considered in the EC. The transfer and
    collection of data generated by IoT is also an important issue in data management.
    - Power management: IoT systems and energy-efficient technologies in the EC are
    attractive. A billion IoT nodes require sensitive operating systems that support
    a variety of applications that use power extraction to avoid scalability, cost
    reduction, and frequent battery replacement [9]. Network characteristics: These
    include the benefits that EC provides for IoT networks, such as proximity to end
    users, dense geographical distribution, low latency response time, location awareness,
    improve QoS, and support heterogeneity [28]. Computing node: - Servers: Edge servers
    are geographically dispersed and deployed in very typical areas, such as highways,
    bus stations, parks and shopping malls. Like lightweight cloud servers, these
    edge servers are virtualized and have storage, computing and networking facilities.
    Edge servers have been considered by many jobs as the primary functional component
    of EC. - Networking devices: Devices such as gateway routers, switches, decoders,
    in addition to their conventional network operations such as routing, packet forwarding,
    analog-to-digital signal transfer, will serve as possible infrastructure for EC.
    In certain cases, network systems are equipped with some resources, including
    data processors, expandable main and secondary memory, programming platforms,
    etc. Also, separate from usual network devices, various dedicated network devices
    have been used as smart gateways, IoT Hub was introduced as edge nodes. - Cloudlets:
    Cloudlets are situated at the middle layer of the end device as a micro-cloud
    and are known to be part of the cloud hierarchy. In general, cloudlets were signed
    to expand cloud-based technology to mobile device users and will complement mobile
    cloud computing. In certain examples, cloudlets are referred to as edge nodes.
    Cloud-based EC is strongly virtualized and can accommodate a vast range of end
    devices simultaneously. - Base stations: Base stations are one of the most important
    components for unified communication and data signal processing in mobile and
    wireless networks. In surveys, traditional base stations are fitted with special
    edge data computing capability. - Vehicles: Mobile vehicles or parked on the edge
    of the network may serve as edge nodes. Vehicles, as edge nodes, may form a distributed
    and very scalable edge systems [107]. However, the contentious issue of maintaining
    privacy and error tolerance will be very difficult provided QoS in such an environment
    [108]. Data type: One of the main problems in calculating the edge is that even
    cloud computing has not been able to meet the applications that deal with different
    types of data. This type of data can be widely classified based on delay sensitivity.
    - Hard real-time data: Missing a deadline is an utter failure of the system and
    cannot tolerate. - Firm real-time data: Occasional deadline may be tolerated but
    may degrade the level of operation of the system. The validity of the result is
    zero after the deadline. - Soft real-time data: The utility of the result deteriorates
    beyond its time limit, as a result of that degrades the system’s QoS. - Non-real-time
    data: Delay-tolerant applications can be in a class of non-real-time data [ 27
    ]. Access technologies: IoT devices are sending the captured data to the locally
    accessible Edge server for analysis. These devices connect with advanced operating
    systems through wireless networking technologies such as Wi-Fi and cell networks,
    including 3G, 4G and 5G, or wired technologies such as Ethernet. These network
    architectures differ in terms of data rate, propagation range and a variety of
    compatible devices. However, the wireless networking infrastructure is not as
    reliable as wired technology. Wireless networks offer simplicity and versatility
    to users running their applications on the Edge Server [102]. Resource type: The
    initial action to determine the advantages of an edge approach is to decide about
    the types of services that can be best handled than a centralized framework. One
    of the benefits of using edge architectures is a decrease in response time, which
    can be optimal if sufficient connectivity services are given and utilized. Energy
    is a resource that is influenced by the amount of data computing, interacting,
    saving and processing that is occurring [109]. EC standards: The EC standards
    include approved documents for technologies EC such as mist computing, OpenFog
    reference architecture, and multi-access EC, with focusing on setting up the service
    using the edge [110]. - Multi-access EC: It offers cloud computing capabilities
    to third party Application Service Providers (ASPs) at the edge of the network
    and its features considered and covered cloud services at the edge within RAN
    in 5G and 6G, latency-sensitive applications, fault-tolerance, data classification,
    and traffic dissemination. An ISG is organized in ETSI released GS MEC-IEG 006
    standard for Multi-access EC in 2017. - OpenFog reference architecture: The document
    approved the OpenFog reference architecture standards by the IEEE Standards Association
    (IEEE-SA) as the official standard in 2018. Also, the document listed important
    aspects of fog computing including resource awareness and monitoring, localized
    control and processing, orchestration, and multi-tenant and analytics and virtualization.
    - Mist computing: According to the document, Mist computing is a lightweight,
    primary mode of fog computing that occurs at the edge of the network. Mist computing
    uses microcomputers and microcontrollers to serve fog computing nodes and delivers
    unified (cloud computing facilities. NIST''s Mist Computing Criteria in Special
    Publication 500-325 in 2018. In comparison, the capabilities that have been increased
    and included mobility to help minimize lag, improve performance, minimal link
    connection, and maintain privacy. 6.2 Role of SDN in IoT Networks SDN can virtualize
    IoT networks affordably and perform bandwidth allocations and automated re-adjustments
    to enhance performance and maintain bandwidth. By providing a plug-and-play device
    configuration, SDN can make the management of the most sophisticated networks
    easy. By identifying and mitigating threats through an integrated security application,
    SDN can ensure reliability and provide access control to the advantage of enhanced
    traffic transparency at the edge of the networks. SDN benefits from integrated
    management of all information and communications technology resources with the
    policy-driven management from a large number of data centers and EC devices [68].
    These resources include the integration of lifecycle management and virtual machines,
    containers, and mirror files. The South band controller interfaces provide centralized
    control of sensors, terminals, connectivity units, IoT gateways and other equipment
    [111]. Figure 11 depicts our provided taxonomy of the role of SDN in IoT networks
    in terms of system components, network architecture components, operational modes,
    and opportunities, functionality at the edge, applications do, mains, and main
    attributes of SDN-IoT. In the following, we will go into more detail about this
    taxonomy. Network architecture components: It has been shown and explained in
    Fig. 2. Operational modes: The operating modes of IoT networks based on SDN can
    be ordered into three modes: central, distributed, and hybrid control. Fig. 11
    Taxonomy of role of SDN in IoT networks Full size image In central control mode:
    For how traffic control is done using an SDN controller, flow rules apply. In
    this case, all actions performed by SDN nodes and controllers are performed and
    controlled by the SDN controller. Distributed control mode: The SDN controller
    does not direct the SDN nodes. This control mode is close to conventional delivery
    networks that are self-organizing. Hybrid control mode: The SDN controller does
    not control the SDN nodes completely. Instead, it specifies only the rules of
    general policy, not all the rules of flow. SDN information components, SDN wireless
    nodes use their intelligence to forward packets and process flow-level processing.
    [108] Opportunities: Networks may rely on a range of heterogeneous wireless network
    architectures that face various challenges in fulfilling the QoS specifications
    for different services. Traditional networks cannot cope with the growing demands
    of a highly competitive network environment. By comparison, the unified design
    of scalable SDN facilitates a complex network environment and minimizes logistical
    overhead. SDN-based load balancing can help manage traffic loads in order to allow
    optimal use of the services available on SDN networks. The SDN programmability
    function can allow fast and automated network setup. SDN also provides network
    service providers the ability to incorporate network elements in the form of applications
    [112]. Functionality at the edge: There are some approaches based on SDN-oriented
    solutions that ensure effective edge-IoT network data gathering from sensors/actuators,
    data aggregation and disaggregation, and admission monitoring. Flow and network
    monitoring: The global network can be easily tracked with SDN when adding an adequate
    monitoring module. Network monitoring in SDN can be achieved in two ways: (1)
    by polling the controller and by disclosing switches as long as there is a difference
    in the actions of the network; (2) by monitoring the flow to reduce connectivity
    costs on the network. There are optimization approaches that are used to add device
    polling requests and responses to optimize the cost of communication while allowing
    the monitoring of the global view of networks. Admission monitoring: The SDN network
    computing flow aggregation management mechanism is used to refine the admission
    control when evaluating the buffer space and bandwidth available on the network.
    Therefore, several of the designs proposed also consume less space in the buffer
    space by controlling the reception and collection of data. This feature helps
    to integrate the traffic of billions of devices [96]. Data aggregation\\disaggregation:
    A significant factor to consider in IoT edge networks is also the proper data
    aggregation process. For example, heterogeneous data are obtained by a single
    aggregator, but it should be possible to retrieve the original data from the aggregate.
    The SDN-based estimation and traffic processing model are used for efficient data
    aggregation. There are two problems: the integration of traffic flows and the
    disaggregation of the main aggregate flows [93]. Application domains: Mobile access
    network: SDN-based radio resource control assigns personnel to small base stations.
    Macro base stations (BS) are able to devote sufficient resources to small scale
    BSs before they boost performance and QoS within the hands-offs while taking into
    account the accessibility of users/vehicles within the network. Wireless access
    network: Mobility is one of the most critical problems for cellular networks.
    Therefore, wireless networks that are supported by SDN-IoT, can be improved in
    terms of scalability and reliability. Dynamic flow installation: Implementation
    of protective flow in IoT using SDN. The strategy dynamically follows the basic
    criteria of the software and implements the traffic rules necessary to enhance
    the efficiency of the network. Therefore, before the actual delivery of the packages
    from the devices, the devices enforce the requisite adjustments to the traffic
    laws. Because the program actively enforces streaming rules on switches, closed
    delivery delays can be significantly reduced. Scalable IoT communications: SDN
    architecture facilitates flexible and effective IoT connectivity when combining
    data delivery facilities as well as network versatility. Rule-caching in the mobile
    network: The SDN-based caching function is given in mobile networks when considering
    the mobility of nodes in the network. The memory manager is located on the SDN
    systems and is suitable for storing the rules. But the cache manager saves the
    rules specified by the centralized controller and changes the rules before the
    memory is stored [16, 113]. Main attitudes of SDN-IoT: Agility and flexibility:
    The heterogeneity and versatility of various smart things is a problem that needs
    to be answered for the efficient adoption of IoT. When the software requirement
    is modified, if each device has to be reprogrammed at the device level, the response
    time to the changing environment will increase. It is also important to extend
    the infrastructure such that the associated network specifications can be scalable
    and reprogrammable. SDN offers network engineers with the ability to rapidly meet
    evolving market needs. It is planned to reduce the time required to reconfigure
    the transport layer and the network. SDN, with its agility and elasticity, seems
    to be a promising strategy for performing in giant IoT networks [114]. Manageability:
    Network maintenance is an important aspect in handling the large collection of
    IoT devices and the enormous volume of data they produce. As a result, adequate
    infrastructure is required to spread the load balancing and minimize network congestion
    to distribute and monitor the traffic flow in the network. SDN-based technology
    can be used to control the IoT network, including load balancing, accurate transport
    and bandwidth utilization [33, 115]. Scalability: IoT networks need to be able
    to easily scale to meet the demands of transferring hundreds or thousands of servers
    from current cloud infrastructure to networks of tens or even hundreds of thousands
    of nodes. This scaling creates challenges in addressing, routing, and density
    control. The use of SDN technology can ensure scalability and respond to hazardous
    conditions such as high computational load on the main controller. Configurability:
    SDN enables innovation to improve network configuration via three sources: controller,
    switch, and host nodes. As an interface between the protocol controller and switch
    acts Openflow. In addition, the dynamic reconfiguration in the interconnection
    network is used as a solution to cope with connection problems in IoT networks.
    Heterogeneity: IoT devices, several sensors and actuators, which are interconnected
    at the edge of the network are intrinsically heterogeneous. Therefore, despite
    such heterogeneity, it is important to provide adequate hardware so that the systems
    can communicate with each other and share information in an automated manner.
    SDN-based architectures are widely used for managing device and network heterogeneity.
    IoT features in SDN-IoT: The following benefits describe IoT features in SDN-IoT
    networks: Dynamic and self-adapting: IoT devices and programs must be able to
    respond quickly to evolving content and behave in compliance with their operating
    situation, user content or responsive environment. Self-configuring: IoT systems
    can be adjustable so that several devices may operate together to have a particular
    purpose. IoT devices can be configured infrastructure, network setup, and download
    the latest version of the software with minimal or manual by users. Interoperable
    communication protocols: IoT devices may support some of the collaborative networking
    protocols and may also be able to connect with the infrastructure with other devices.
    Unique identity: Each IoT system is assigned a unique identification (e.g., IP
    or URl). Integrated information network: IoT devices are detectable by other devices
    and/or networks may identify themselves (and their features) to other devices
    or user applications. IoT systems are typically situated on the information network,
    which helps them to connect and share data with other networks and devices. Context-awareness:
    On the basis of the information measured by physical and environmental parameters,
    the sensor nodes acquire knowledge of the comprehensive field. After that, the
    decision reached by the sensor nodes is informed of that. Intelligent decision-making
    capability: This is a crucial built-in variable for every IoT device. This function
    boosts the energy efficiency of the wide-area network. Using this function, multiple
    sensor nodes will communicate to make a final decision [116]. SDN standards: SDN
    standards have been developed by the Community of Open Development Institutions
    and Industry Consortiums, including ETSI, IETF, ONF, 3GPP and IEEE. Standard technology,
    analytics, and critical SDN components are included in each model and are defined
    as follows: Openflow: OpenFlow is the first standard communication interface specified
    between an SDN architecture''s control and forwarding layers. OpenFlow enables
    physical and virtual network devices such as switches and routers to directly
    access and use the forwarding plane (hypervisor-based). In this standard, concepts
    such as southbound communication, interoperability, and VM mobility are considered.
    OVSDB: Open vSwitch is an open-source software switch built-in virtualized server
    environments to be used as a vSwitch (virtual switch). A vSwitch forwards traffic
    on the same physical host between various virtual machines (VMs), and even forwards
    traffic between VMs and the physical network. OVSDB is the database used to configure
    OVS instances for the purpose of (RFC 7047). Significances are mentioned in this
    standard include northbound communication, fault-tolerance, VM mobility, security
    and privacy, and authentication. REST API: The Floodlight, for example, has a
    Northbound API focused on REST, the REST rules and design patterns for the SDN
    Northbound API in a fully RESTful way (representational state transfer). These
    standard covered issues such as southbound communication, interoperability, and
    VM mobility [117]. OF-CONFIG: The standard configuration and management protocol
    for the OpenFlow switch is known as OF-CONFIG and is a companion protocol to OpenFlow.
    Features that considered and covered enumerate OpenFlow switch communication,
    flexible innovation, interoperability, security and privacy, and VM mobility [118].
    6.3 IoT and QoS improvement techniques Improvement of techniques leads to provide
    agility and flexibility to deal with mobility, scalability, and QoS in IoT [119].
    So, from a different point of view, the classification of QoS improvement techniques
    in IoT provides and shows in Fig. 12. These techniques are divided into two categories
    improvement techniques by modifying the architecture and by modifying the algorithmic
    foundations. Different characteristics, design methods, networking models, network
    hierarchy, in-network processing, QoS complexity are included in modifying the
    architecture techniques. Modifying algorithmic foundations requires algorithms
    that are used to solve IoT problems. IoT devices are heterogeneous and vary in
    computing capacity, access to the network, and battery life. Despite their differences,
    IoT applications have major problems that need to be addressed in specific areas
    by appropriate methods. For example, planning area, optimization, flow control,
    and coverage algorithms are widely used in IoT for purposes such as resource access,
    networking, collaboration, and management [120]. Fig. 12 Improvement techniques
    in IoT Full size image Generally, there are two major design methods for network
    architecture: (1) an evolutionary approach; and (2) a clean slate strategy. The
    evolutionary strategy is bringing increasing improvements to the new network infrastructure
    in order to recreate as many modules as possible from existing networking technologies.
    From this point of view, IoT may be seen as an expanded architecture that has
    developed from the Internet. In comparison to a clean slate strategy help the
    unlimited network to redesign in the existing configuration. This means that in
    order to overcome next generation network problems, new technologies and protocols
    can be extended according to various design criteria, such as: Autonomous network
    architecture: Automated networks are not linked to public networks, although in
    practice there are a variety of such implementations. Ubiquitous network architecture:
    IoT device networks are part of the platform. Registered users would have access
    to information provided by smart object networks through the Internet portal,
    either directly from the system or via intermediary services. Application-layer
    overlay network architecture: Related to sensor networks, IoT''s most popular
    configuration is to gather data from millions of nodes. Service-oriented network
    architecture: Heterogeneity is the most distinctive aspect of IoT, which also
    involves a number of sub-networks implementing various networking technologies
    [34]. Operational architectures: Operational architectures are considered into
    two categories event-based and time-based Architecture. If a particular event
    occurs in an event-based architecture, the operating data can be moved. On the
    other hand, it occurs at a fixed time interval. [36]. 6.4 Edge framework based
    for SDN-IoT EC is a model that seeks to set up cloud services, such as storage,
    computing, and network edge processing, with one or two hops away from the end-user
    [121]. EC manages computing data, software and facilities outside cloud storage
    and at the edge of the network. Content and technology developers may use edge
    computing systems by delivering applications close to customers. EC capabilities
    provide high bandwidth, relatively low latency, and real-time access to information
    that many programs need on the network. EC enables new services for organizations
    and customers [16]. EC technologies include location services, virtual reality,
    visual monitoring and caching of data. EC has the same characteristics as cloud
    computing. The EC distinguished features that made it special are as mentioned
    below [14]: Mobility management Awareness of the situation Proximity Content awareness
    Heterogeneity The EC platform compared to the traditional network has four advantages
    [16]: EC addresses the need for applications to have fast and real-time performance.
    Due to increased local storage capacity, EC is very convenient for collecting
    and organizing data. Because a significant volume of IoT data is sent to data
    centers for processing, the cost of network operations would be increased needlessly
    and the use of EC could minimize it. Using EC makes network management reliable.
    Edge computing (EC) frameworks: Edge computing solves the problem of limited resources
    by bringing computing to close IoT devices. Currently, some state-of-the-art edge
    computing frameworks for EC-SDN-IoT architectures are listed below in Table 5
    [122]. Table 5 EC Frameworks for EC-SDN-IoT Full size table 7 Discussion and open
    issues In this section, based on the studies reviewed in different sections of
    this article, we have reviewed and summarized the challenges of this issue from
    two perspectives: challenges in EC and challenges of EC-SDN-IoT networks, and
    finally we have answered the technical questions raised in “Research selection
    method”. The last part of this section expresses future direction works need to
    be considered. 7.1 Challenges in EC Since IoT technology is so commonly used,
    EC tends to be a requirement for many applications. In order to better describe
    the EC architecture, open standards and the fast implementation of IoT systems
    should be considered. EC is emerging as an approach for network architecture and
    it can provide better performance against traditional cloud applications without
    the need for initial implementation [140]. However, in EC, computational nodes
    are heterogeneous and distributed. It is important to consider the increasing
    computing capabilities in edge devices. Since EC is not a substitution for cloud
    computing, on the contrary, they are compatible paradigms that must be used simultaneously.
    In addition, edge-based services must cope with different facets of constrained
    environments. In addition to the complexities of technology, there are several
    critical problems, such as mobility, restricted capacity and computing capital
    in edge applications, heterogeneity, scalability, efficiency, protection and privacy
    issues. Via analyzing the features of EC from a structural, service-oriented,
    and security perspective, we enumerate the challenges as follows in Fig. 13, [19,
    20, 25, 46, 105, 112, 141, 142]: Structure Fig. 13 Challenges in edge computing
    Full size image Coordination of services and orchestration: EC services must also
    communicate with cloud servers. A collection of communication and orchestration
    criteria is needed for three levels of architecture. The relationship between
    edge and central cloud servers and the interface between clouds should be controlled
    by the intermediate network layer. Service-oriented structure: Considering the
    infrastructure itself rather than its place for conventional IP-based activities,
    it is difficult to handle communications between clients and servers. These services
    may only be located on multiple local servers or they may be partly on local servers
    and partly in a centralized cloud. Designing a service-oriented system that can
    handle all the complexities is crucial. Soft state: System mode must be changed
    at any time, so events may occur when data enters the system to reach eventual
    consistency. Therefore, the device is still going to be slow. EC platforms may
    not always take into account the availability of local networks, which varies
    from its cloud peers running on hard-core and permanent data. The soft state tolerates
    even more complicated circumstances and must help the dropping process of the
    end-user. Integrated service delivery: An alternative to mobility would be the
    connecting of the EC infrastructure. In order to achieve centralized service delivery,
    multiple service providers are required. The transition structures are often known
    to be multi-tenancy on the local cloud. Selection of suitable computational nodes:
    In EC, computing nodes are spread around the edge of the network and maybe either
    simulated or shared. In this case, it is necessary to define suitable strategies,
    measure inter-node coordination and provide efficient resources [143]. Service
    • Large-scale application: Most edge nods are a rich resource for networks. Since,
    developing a large-scale application in resource-limiting nodes is not as easy
    as conventional data centers. In this case, the potential application platform
    needs to be introduced to develop the distributed application at the edge. The
    service level agreement: SLA in EC is also affected by several variables, such
    as service rate, energy usage, application features, data flow, network status,
    so it''s hard to specify in a specific scenario. As a consequence, in terms of
    service provider requirements and service level objectives (SLOs), it is important
    to provide a good architecture and retain the simple QoS at the edge. Distribution
    policies and computing: Calculate distribution policies and computing services
    between IoT / sensors, edge, and Cloud infrastructure needs to be specified Security
    aspects Security mechanism: The achievement of security frameworks for data-driven
    integration may have a huge effect on EC QoS. Vulnerability to security attacks:
    since EC is built over conventional networking components; it is extremely vulnerable
    to security attacks. Privacy in distributed paradigm: Reliable access to services
    and privacy in a largely dispersed paradigm such as the EC is difficult to ensure
    [144]. In addition to the above, service scalability, the ultimate challenges
    of QoE users, content awareness, mobility support, performance metrics are very
    important for real-time EC and coping with them. [141, 145, 146]. 7.2 Challenges
    of EC-SDN-IoT networks The new approach for meeting the new IoT criteria, such
    as high-density traffic management, a wide number of processing connections, maximum
    traffic processing and low-time processing, is to disperse the processing of IoT
    analytics from the central data center to micro data centers and small data centers
    on the edge of the network (EC), known as EC-IoT [3]. Therefore, the analytical
    distribution of IoT, network and storage databases eliminates the problems by
    creating a scalable model. So, lightweight computing resources, closer to the
    edge network, are required. In addition, close collaboration between the IoT analysis
    platform, the SDN platform and the cloud infrastructure is required to ensure
    the effective delivery of IoT and the usage of network resources [5]. In the context
    of IoT, routing between two devices cannot be modified due to an uncontrollable
    route. Conventional data transfer approaches are often not in accordance with
    real needs. While some preliminary work focuses on the transition of compatibility
    and enhancement of results across networks, these methods do not address big data
    communications needs, characteristics of the industrial network and network topology.
    New challenges associated with the transfer of IoT data have been raised. Given
    that the interaction between Cloud and EC seems like an exciting architecture.
    However, both EC and SDN have not yet reached their maximum potential to be able
    to handle all of the potential uses and management practices mentioned. This immaturity
    is caused by several factors, but the most important are: [141] Demands are changing
    quickly, and even more standard domains like IaaS (Infrastructure as a Service)
    are emerging. It is not possible to incorporate SDN into existing networks simply
    by using SDN-enabled network equipment. Needs become more complex. Investing in
    hardware is expensive, so hardware equipped with SDN cannot reach the required
    level of capability and deployment. As the current framework of the network cope
    with challenges, the new architecture has to accommodate a vast amount of data
    at various levels between devices. There are clustered routing algorithms or cluster-based
    IoT transmission methods that are unable to adapt to various degrees of delay
    and rapid internet-based decision-making. Improved methods of data transfer based
    on the current network infrastructure, such as SDN and EC, should also be proposed.
    7.3 Answer to technical questions In this section, we respond to questions raised
    in “Research selection method” based on review studied as follows: • Q1: Why SDN
    is vital to IoT networks? Since SDN is based on scalable and intelligent network
    management, it can eliminate complex connectivity requirements at the edge, such
    as orchestration, service discovery and provisioning. With the resource-limited
    existence of IoT devices and the rise in the number of IoT devices over time,
    SDN is becoming a crucial control technology for such a large network. SDN uses
    unified network control to redirect network traffic from source to destination.
    IoT devices can also be handled effectively using SDN. • Q2: What are the advantages
    of EC in IoT networks? The EC has multiple advantages. Second, EC will greatly
    decrease the volume of data required to be transmitted to the cloud, thus reducing
    transmission costs, reducing latency and improving the quality of service. Second,
    EC avoids the core processing environment and eliminates significant bottlenecks
    and SPF. EC is made up of several heterogeneous edge modules. EC will offer offloading
    services near resource-limited IoT devices requiring continuous contact between
    IoT and edge infrastructure. • Q3: Where SDN meets EC architecture? As SDN has
    been one of the key choices for setting up the edge service due to its widespread
    deployment. SDN is a functional edge deployment approach that guarantees high
    flexibility and manageability by separating control and data planes. The SDN control
    mechanism will reduce the complexity of the EC design and deployment by offering
    a modern mechanism for networking and effective simultaneous resource management.
    In EC, the generated traffic must be routed to the server to meet the service
    needs of the device. Since SDN is based on versatile and intelligent network management,
    it can eliminate dynamic connectivity requirements at the edge of the network,
    such as provisioning, service discovery and setup. Unlike conventional networks
    that rely on distributed network elements management, SDN uses the OpenFlow protocol
    for scalable network infrastructure management. • Q4: What are EC challenges for
    the IoT network? Providing network-wide edge nodes eliminates the burden of clustered
    processing and overcomes the difficulties of IoT latency. EC also provides low-cost
    options for intensive work. The problem of resource limitation on IoT devices
    can be easily managed by moving resources closer to edge devices and using unified
    SDN control mechanisms. EC can minimize processing time and increase application
    performance; however, this technology has its disadvantages. Here are the six
    problems that the EC has generated for the network. Network bandwidth: When more
    data is processed on the edge and more data is stored on the edge, the bandwidth
    of the network increases. Distributed computing: An additional feature of computing,
    including the location on various networked networks, should be considered. Latency:
    By locating the measurements at the edge where the processing process is nearest
    to the data gathered, the delay of the program is minimized along with the delay
    of the decision. The less you shift the edge to the core means quicker reaction
    and improved results. Security: The EC forces companies to adopt the same network
    security models and physical security specifications for multiple remote servers.
    The challenge is to have safety footprints and traffic habits everywhere. Backup:
    Usually, there is a need for EC since disparate places are gathering vast volumes
    of data. Enterprises require an overall data management policy that will understand
    all of these data. Network bandwidth requirements may be almost as important as
    storage media concerns when determining how to secure these properties, as network
    backup does not make sense. Data accumulation: Data is a vital tool in business,
    and gathering data from different angles presents new obstacles and can create
    difficulties unless it is governed by current data protection regulations. Storage
    and access to data are very critical, all of which can be part of the data lifecycle
    of the network. 7.4 Open issues Current technologies are well-suited to IoT network
    problems, but may not perform as well in decentralized environments such as EC
    systems, which are expected to meet IoT application’s needs. EC still has to solve
    various technical problems to be fully pervasive. In this section, these challenges
    are categorized and explained with a deeper insight into the complexities related
    to the practical implementation of EC in IoT networks. To overcome the technical
    problem and provide a solution using the programmable network approach is offered
    by SDN. In spite of the potential vision of SDN, EC and IoT, numerous critical
    inquire about challenges stay to be handled by future investigation endeavors.
    So, in Fig. 14 we presented open issues in SDN-EC-IoT infrastructure in three
    categories, standardization, implementation, and techniques/ requirements. Fig.
    14 Open issues in SDN-EC-IoT infrastructure Full size image Based on reviews,
    appropriate strategies to determine an efficient communication and synchronization
    between different elements of the Internet of Things, cloud and edge elements,
    planning policies, shared information security, interaction, cognition, self-test,
    adjustability, dynamism, usability, flexibility, interoperability, and compatibility
    of edge applications with other different technologies are required. In our points
    of view and according to the studies done, future direction works need to consider
    the cases mentioned as follows: Standardization of the EC-SDN-IoT due to differences
    in infrastructure will require extensive review. Improving several performance
    metrics such as reducing energy consumption and response time to significantly
    improve the QoS in IoT networks compared to traditional approaches. Developing
    standards and protocols for the wireless SDN is essential. Meeting the challenges
    to guarantee QoE of traffic explosion is exponentially considerable in IoT. The
    needs of ultra-low latency applications and the critical conditions that require
    technologies that can meet them should be considered. Caching management due to
    stored information in the distributed IoT computing/processing environment in-network
    will be increasingly required. Considering the Need to design an architecture
    for EC that can be used dynamically for edge computational power to overcome battery
    and performance limitations. Improving the decision-making process and make sure
    a more balanced load distribution between the edge nodes in EC-SDN-IoT will be
    more focused. Various data offloading mechanisms and flow classification in SDN-IoT
    networks can be useful in this way. 8 Conclusion According to increasing the number
    and variety of IoT devices, IoT networks are open to security risks and increased
    management complexity. Also, regarding the explosion of data collected and transmitted
    over IoT networks, it should take a short time to react to a large number of data
    and require powerful computing resources and large storage space. On the other
    hand, edge computing (EC) as an automated analytical computation and emerging
    approach to network architecture can provide better performance to traditional
    cloud applications by pushing the relevant data processing and storage attributes
    closer to the source of data generation and where the device is located. Furthermore,
    as SDN is based on versatile and intelligent network operation, it can minimize
    complex connectivity needs at the edge and provide efficient administration, unified
    control, virtualization, resource management and programmability for effective
    IoT deployment. The convergence of SDN, edge computing and IoT will also provide
    a powerful framework for the advantage of all of them. This paper suggests an
    optimized SDN-EC-IoT platform that uses network resource virtualization to provide
    resources for heterogeneous IoT devices and provides for optimal infrastructure
    setup and management. These key principles provide new opportunities to introduce
    the innovative applications and combine an automatic and adaptive network platform,
    which facilitates network management and protects the quality of the user experience.
    One of the most important issues in this field is providing services with adequate
    QoS support which is still a challenging problem in IoT. This review study describes
    novel cooperative frameworks that exploit the synergies between SDN, and EC in
    IoT networks. Also, different technical taxonomies were provided to classify the
    role, characteristics and features of EC and SDN in IoT networks. We present an
    exploratory query-based SLR approach in 139 studies conducted between 2013 and
    2021. Finally, we analyzed 74 studies focusing on the use of EC and SDN in IoT
    environments and compared their technical aspects. Moreover, some provided technical
    questions about the necessity, importance, and benefits of using this structure
    were answered and the main challenges such as issues related to network bandwidth,
    latency, security, backup, data accumulation and distributed computing issues
    were comprehensively explained. Finally, future research directions and open issues
    related to standardization, implementation, techniques and requirements were presented
    in detail. Notes Enumeration-based optimal placement algorithm. Ranking-based
    near-optimal placement algorithm. Slave controller placement strategy. Multi-protocol
    processing at the edge for IoT. Access points. Peer to Peer. References D. Wu,
    D. I. Arkhipov, E. Asmare, Z. Qin, and J. A. McCann: UbiFlow: mobility management
    in urban-scale software defined Iot. In: IEEE Conference on Computer Communications,
    2015. Jazaeri, S., Berangi, R.: Survey present and future visions of internet
    of things (IoT). Sci. J. Res. 8(7), 8–14 (2016) Google Scholar   Munoz, R., Vilalta,
    R., Yoshikane, N., Casellas, R., Martınez, R., Tsuritani, T., Morita, I.: Integration
    of IoT, transport SDN, and edge/cloud computing for dynamic distribution of IoT
    analytics and efficient use of network resources. J. Lightwave Technol. 36(7),
    1420–1429 (2018) Article   Google Scholar   Janna, A.: The Internet of Things
    will Thrive by 2025. Pew Research Center, Washington, DC (2014) Google Scholar   Tayyaba,
    S.K., SherAfzalKhan, N., Naeem, W.: Software-defined networks (SDNs) and internet
    of things (IoTs): a qualitative prediction for 2020. IJACSA Int. J. Adv. Comput.
    Sci. Appl. 7(12), 385–404 (2016) Google Scholar   Gupta, B.B., Quamara, M.: An
    overview of internet of things (IoT): architectural aspects, challenges, and protocols.
    Concurr. Comput. 32, 1–24 (2018) Google Scholar   Ateya, A.A., Muthanna, A., Vybornova,
    A., Algarni, A.D.: Chaotic salp swarm algorithm for SDN multi-controller networks.
    Eng. Sci. Technol. Int. J. 22(4), 1001–1012 (2019) Google Scholar   H. Zemrane,
    Y. Baddi, and A. Hasbi, \"SDN-based solutions to Improve IoT: Survey. In: IEEE,
    pp. 588–593, 2018. Zhao, L., Sun, W., Shi, Y., Liu, J.: Optimal placement of cloudlets
    for access delay minimization in SDN-based internet of things networks. IEEE Internet
    Things J. 5(2), 1334–1344 (2018) Article   Google Scholar   Singh, D., Ng, B.,
    Lai, Y., Lin, Y., Seah, W.K.G.: Modelling software-defined networking: software
    and hardware switches. J. Netw. Comput. Appl. 122, 24–36 (2018) Article   Google
    Scholar   Vizarreta, P., Trivedi, K., Helvik, B., Heegaard, P., Blenk, A., Kellerer,
    W., Machuca, C.M.: Assessing the maturity of SDN controllers with software reliability
    growth models. IEEE Trans. Netw. Serv. Manag. 15, 1–15 (2018) Article   Google
    Scholar   A. Khakimov, A. A. Ateya, A. Muthanna: IoT-Fog based system structure
    with SDN enabled. In: Proceedings of ACM Woodstock conference, Amman, Jordan,
    2018. Tran, H., Tran, D., Nguyen, L., Ha, Q., Tong, V.: SHIOT: a novel SDN-based
    framework for the heterogeneous internet of things. Informatica 42, 313–323 (2018)
    Article   Google Scholar   Ren, W., Sun, Y., Luo, H., Guizani, M.: A novel control
    plane optimization strategy for important nodes in SDN-IoT networks. IEEE Internet
    of Things J. 6, 1–14 (2018) Google Scholar   Jazaeri, S., Berangi, R.: Study the
    challenges of using and development of 5G networks. Sci. J. 8(7), 13–19 (2016)
    Google Scholar   Porambage, P., Okwuibe, J., Liyanage, M., Ylianttila, M., Taleb,
    T.: Survey on multi-access edge computing for internet of things realization.
    IEEE Commun. Surv. Tutor. 20, 1–32 (2018) Article   Google Scholar   Lee, A.,
    Wang, X., Nguyen, H., Ra, I.: A hybrid software defined networking architecture
    for next-generation IoTs. KSII Trans. Internet Inf. Syst. 12(2), 932–945 (2018)
    Google Scholar   Saha, N., Bera, S., Misra, S.: Sway: traffic-aware QoS routing
    in software-defined IoT. IEEE Trans. Emerg. Top. Comput. 9, 1–12 (2018) Google
    Scholar   Oquendo, L.T., Lin, S.C., Akyildiz, I.F., Pla, V.: Software-defined
    architecture for QoS-aware IoT deployments in 5G systems. Ad Hoc Netw. 93, 1–11
    (2019) Google Scholar   Shi, W., Cao, J., Zhang, Q., Li, Y., Xu, L.: Edge computing:
    vision and challenges. IEEE Internet of Things J. 3(5), 637–646 (2016) Article   Google
    Scholar   Uddin, M., Mukherjee, S., Chang, H., Lakshman, T.V.: SDN-based multi-protocol
    edge switching for IoT service automation. IEEE J. Sel. Areas Commun. 36, 1–11
    (2018) Article   Google Scholar   D. Sinh, L. Le, B. P. Lin, and L. Tung: SDN/NFV—A
    new approach of deploying network infrastructure for IoT. In: The 27th Wireless
    and Optical Communications Conference (WOCC2018), 2018. Okay, F.Y., Ozdemir, S.:
    Routing in Fog-Enabled IoT Platforms: A Survey and an SDN-based Solution. IEEE
    Int. Things J. 5, 4871–4889 (2018) Article   Google Scholar   Qureshi, K.N., Hussain,
    R., Jeon, G.: A distributed software defined networking model to improve the scalability
    and quality of services for flexible green energy internet for smart grid systems.
    Comput. Electr. Eng. 84, 106634 (2020) Article   Google Scholar   Jararweh, Y.,
    Al-Ayyoub, M., Darabseh, A., Benkhelifa, E., Vouk, M., Rindos, A.: SDIoT: a software
    defined based internet of things framework. J. Ambient Intell. Humaniz. Comput.
    6(4), 453–461 (2015) Article   Google Scholar   ZadaKhan, W., Ahmed, E., Hakak,
    S., Yaqoob, I., Ahmed, A.: Edge computing: sa survey. Future Gener. Comput. Syst.
    97, 1–45 (2019) Google Scholar   Sun, X., Ansari, N.: Latency aware workload offloading
    in the cloudlet network. IEEE Commun. Lett. 21, 1–4 (2017) Article   Google Scholar   Salman,
    O., Elhajji, I., Chehab, A., Kayssi, A.: IoT survey: an SDN and fog computing
    perspective. Comput. Netw. 143, 221–246 (2018) Article   Google Scholar   Salman,
    C., Andrew, C.J., Ian, T., Zhiming, Z., Vlado, S.: Monitoring self-adaptive applications
    within edge computing frameworks: a state-of-the-art review. J. Syst. Softw. 136,
    19–38 (2018). https://doi.org/10.1016/j.jss.2017.10.033 Article   Google Scholar   Sun,
    X., Ansari, N.: EdgeIoT: mobile edge computing for the internet of things. IEEE
    Commun. Mag. 54(12), 22–29 (2016) Article   Google Scholar   A. Ahmed and E. Ahmed:
    A survey on mobile edge computing. In: 10th International Conference on Intelligent
    Systems and Control (ISCO), 2016. Bellavista, P., Berrocal, J., Corradi, A., Das,
    S.K.: A survey on fog computing for the Internet of Things. Pervasive Mob. Comput.
    52, 71–99 (2019) Article   Google Scholar   Montazerolghaem, A.: Software-defined
    load-balanced data center: design, implementation and performance analysis. Clust.
    Comput. (2020). https://doi.org/10.1007/s10586-020-03134-x Article   Google Scholar   Asghari,
    P., Rahmani, A.M., Javadi, H.H.S.: Service composition approaches in IoT: a systematic
    review. J. Netw. Comput. Appl. 120, 61–77 (2018) Article   Google Scholar   Asghari,
    P., Rahmani, A.M., Javadi, H.H.S.: Internet of things applications: a systematic
    review. J. Comput. Netw. (2019). https://doi.org/10.1016/j.comnet.2018.12.008
    Article   Google Scholar   Rafique, W., Qi, L., Yaqoob, I., Imran, M., Rasool,
    R., Dou, W.: Complementing IoT services through software defined networking and
    edge computing: a comprehensive survey. IEEE Commun. Surv. Tutor. 22, 1–45 (2020)
    Article   Google Scholar   Alonso, R.S., Sitton-Candanedo, I., Rodrıguez-Gonz´alez,
    S., Garc´ıa, O., Prieto, J.: Software-Defined Networks and Edge Computing over
    IoT, pp. 289–301. Springer, Cham (2019) Google Scholar   Singh, A., Payal, A.,
    Bharti, S.: Review a walkthrough of the emerging IoT paradigm: visualizing inside
    functionalities, key features, and open issues. J. Netw. Comput. Appl. 143, 111–151
    (2019) Article   Google Scholar   Zhao, Y., Wang, W., Li, Y., ColmMeixner, C.,
    Tornatore, M., Zhang, J.: Edge computing and networking: a survey on infrastructures
    and applications. IEEE Access 7, 101213–101230 (2019) Article   Google Scholar   Javadzadeh,
    G., Rahmani, A.M.: Fog computing applications in smart cities: a systematic survey.
    Wireless Netw. 26(2), 1433–1457 (2020) Article   Google Scholar   Yousefpour,
    A., Fung, C., Nguyen, T., Kadiyala, K., Jalali, F., Niakanlahiji, A., Kong, J.,
    Jue, J.P.: All one needs to know about fog computing and related edge computing
    paradigms: a complete survey. J. Syst. Archit. 98, 1–42 (2019) Article   Google
    Scholar   Pratim Ray, P., Kumar, N.: SDN/NFV architectures for edge-cloud oriented
    IoT: a systematic review. Comput. Commun. 169, 129–153 (2021) Article   Google
    Scholar   Shah, S.D.A., Gregory, M.A., Li, S.: Cloud-native network slicing using
    software defined networking based multi-access edge computing: a survey. IEEE
    Access 9, 10903–10924 (2021). https://doi.org/10.1109/ACCESS.2021.3050155 Article   Google
    Scholar   Wang, A., Zha, Z., Guo, Y., Chen, S.: Software-defined networking enhanced
    edge computing: a network-centric survey. IEEE 107(8), 1500–1519 (2019) Article   Google
    Scholar   Ren, W., Sun, Y., Luo, H., Guizani, M.: BLLC: a batch-level update mechanism
    with low cost for SDN-IoT Networks. IEEE Internet of Things J. 6, 1–13 (2018)
    Google Scholar   S. K. Tayyaba, M. A. Shah: 5G cellular network integration with
    SDN: challenges, Issues and beyond. In: 2017 International Conference on Communication,
    Computing and Digital Systems (C-CODE), 2017. Ibrar, M., Wang, L., Muntean, G.M.,
    et al.: SOSW: scalable and optimal nearsighted location selection for fog node
    deployment and routing in SDN-based wireless networks for IoT systems. Ann. Telecommun.
    (2021). https://doi.org/10.1007/s12243-021-00845-z Article   Google Scholar   Ahammad,
    I., Khan, M.A.R., Salehin, Z.: Software-defined dew, roof, fog and cloud (SD-DRFC)
    framework for IoT ecosystem: the journey, novel framework architecture, simulation,
    and use cases. SN Comput Sci. (2021). https://doi.org/10.1007/s42979-02 Article   Google
    Scholar   D.Wu, X.Xiaofeng, N.Xiang, F.Bin, D.Hanhui, H.Zeng and Q.Zhijin: Software-defined
    edge computing: a new architecture paradigm to support IoT data analysis. ArXiv
    abs/2104.11645, 2021. Lin, B.S.P.: Toward an AI-enabled SDN-based 5G & IoT network.
    Netw. Commun. Technol. 5(2), 1–7 (2021) Google Scholar   Fouad, H., Mahmoud, N.M.,
    Issawi, M.S.E., et al.: Distributed and scalable computing framework for improving
    request processing of wearable IoT assisted medical sensors on pervasive computing
    system. Comput. Commun. 151, 257–265 (2020) Article   Google Scholar   Cicconetti,
    C., Conti, M., Passarella, A.: A decentralized framework for serverless edge computing
    in the internet of things. IEEE Trans Netw. Serv. Manag. (2020). https://doi.org/10.1109/tnsm.2020.3023305
    Article   Google Scholar   Bi, Y., Han, G., Lin, C., Deng, Q., Guo, L., Li, F.:
    Mobility support for fog computing: an SDN approach. IEEE Commun. Mag. 56(5),
    53–59 (2018) Article   Google Scholar   R. Vilalta, A. Mayoral, D. Pubill, R.
    Casellas, R. Martínez, J. Serra, C. Verikoukis, R. Muñoz: End-to-end SDN orchestration
    of IoT services using an SDN/NFV-enabled edge node. In: Optical Fiber Communication
    Conference Anaheim, California, 2016. E. Municio, N. Balemans, S, Latré, J. Marquez-Barja:
    Leveraging distributed protocols for full end-to-end softwarization in IoT networks.
    In: Consumer Communications and Networking Conference, CCNC IEEE, NY, USA, 2020.
    Das, R.K., Ahmed, N., Hazel Pohrmen, F., Kumar Maji, A., Saha, G.: 6LE-SDN: an
    edge-based software-defined network for internet of things. IEEE Internet of Things
    J. 7(8), 7725–7733 (2020) Article   Google Scholar   Qafzezi, E., Bylykbashi,
    K., Ikeda, M., Matsuo, K.: Coordination and management of cloud, fog and edge
    resources inSDN-VANETs using fuzzy logic: a comparison study for two fuzzy-based
    systems. Internet Things 11, 100169 (2020) Article   Google Scholar   Thorat,
    P., Singh, S., Bhat, A., LakshmiNarasimhan, V., Jain, G.: SDN-enabled IoT: ensuring
    reliability in IoT networks through software defined networks. In: Towards Cognitive
    IoT Networks, pp. 33–53. Springer, Cham (2020) Chapter   Google Scholar   Shi,
    Y., Wong, J., Jacobsen, H., Zhang, Y., Chen, J.: Topic-oriented bucket-based fast
    multicast routing in SDN-like publish/subscribe middleware. IEEE Access 8, 89741–89756
    (2020) Article   Google Scholar   Raikar, M.M., Meena, S.M., Mulla, M.M.: Software
    defined internet of things using lightweight protocol. Proc. Comput. Sci. 171,
    1409–1418 (2020). https://doi.org/10.1016/j.procs.2020.04.151 Article   Google
    Scholar   ShubhaRao, V., Dakshayini, M.: An SDN-based strategy for reliable data
    transmission in mobile wireless sensor networks. In: Sustainable Cognitive Computing,
    EAI/Springer Innovations in Communication, pp. 87–96. Springer, Cham (2019) Google
    Scholar   Xu, S., Wang, X., Yang, G., Ren, J., Wang, S.: Routing optimization
    for cloud services in SDN-based internet of things with TCAM capacity constraint.
    J. Commun. Netw. 22(2), 145–158 (2020) Article   Google Scholar   E. O. Zaballa,
    D. Franco, M. Aguado, and M. S. Berger: Next-generation SDN and fog computing:
    a new paradigm for SDN-based edge computing. ACM Classification 2012-Computer
    systems organization—Cloud computing, p. 9:1–9:8, 2020. A. Tariq, R. Asif Rehman,
    B. Kim: Energy efficient priority aware forwarding in SDN enabled named data internet.
    In: 2020 International Conference on Electronics, Information, and Communication
    (ICEIC), Barcelona, Spain, 2020. J. Zhang, W. Ma, Y. Li, H. Xue, M. Zha, C. Han
    and S. Bi: Low-energy edge computing resource deployment algorithm based on particle
    swarme. In: The 10th International Conference on Computer Engineering and Networks,
    Singapore, Springer, 2020, pp. 1557--1564. Yang, S., Xu, K., Cui, L., Ming, Z.,
    Chen, Z., Ming, Z.: EBI-PAI: towards an efficient edge-based IoT platform for
    artificial intelligence. IEEE Internet Things J. (2020). https://doi.org/10.1109/JIOT.2020.3019008
    Article   Google Scholar   Lv, Z., Qiao, L.: Optimization of collaborative resource
    allocation for mobile edge computing. Comput. Commun. 161, 19–27 (2020). https://doi.org/10.1016/j.comcom.2020.07.022
    Article   Google Scholar   Z. Yongdong: Managing the IoT: edge computing and SDN.
    ICT Insights, vol. 20, 2016. Balasubramanian, V., Aloqaily, M., Reisslein, M.:
    An SDN architecture for time sensitive industrial IoT. Comput. Netw. (2021). https://doi.org/10.1016/j.comnet.2020.107739
    Article   Google Scholar   Hakiri, A., Berthou, P., Gokhale, A., Abdellatif, S.:
    Publish/subscribe enabled software defined networking for efficient and scalable
    IoT communications. IEEE Commun. Mag. 53(9), 48–54 (2015) Article   Google Scholar   X.
    Jin, L. E. Li, L. Vanbever, and J. Rexford: Softcell: scalable and flexible cellular
    core network architecture. In: Proceedings of the Ninth ACM Conference on Emerging
    Networking Experiments and Technologies, Santa Barbara, CA, USA, 2013. R. Kumar
    Das, A. Kumar Maji, G. Kumar Maji: SD-6LN: improved existing iot framework by
    incorporating SDN approach. In: International Conference Innovative Computing
    and Communications, 1165, 2020. Romero-Gázquez, J.L., Bueno-Delgado, M.V.: Software
    architecture solution based on SDN for an industrial IoT scenario. Wirel. Commun.
    Mob. Comput. 12, 2018 (2018) Google Scholar   A. Hakiri, B. Sellami, S. Ben Yahia
    and P. Berthou: A SDN-based IoT architecture framework for efficient energy management
    in smart buildings. In: Global Information Infrastructure and Networking Symposium
    (GIIS), Tunis, Tunisia, 2020. Municio, E., Marquez-Barja, J., Latré, S., Vissicchio,
    S.: Whisper: programmable and flexible control on industrial IoT networks. Sensors
    18(11), 4048 (2018) Article   Google Scholar   T. Suzuki, S. Kim, Y. Koyasako,
    J. Kani, and J. Terada: Application-oriented optical transmission control for
    computationally efficient edge computing. In: 2020 IEEE 17th Annual Consumer Communications
    & Networking Conference (CCNC), Las Vegas, NV, USA, 2020. A. Darabseh, M. Al-Ayyoub,
    Y. Jararweh, E. Benkhelifa, M. Vouk and A. Rindos: SDStorage: a software defined
    storage experimental framework.In: IEEE International Conference on Cloud Engineering,
    vol. Tempe, no. AZ, pp. 341–346, 2015. Alenezi, M., Almustafa, K., Meerja, K.A.:
    Cloud based SDN and NFV architectures for IoT infrastructure. Egypt. Inform. J.
    20, 1–10 (2019) Article   Google Scholar   Jacquenet, C., Boucadair, M.: A software
    defined approach to IoT networking. ZTE Commun. 1, 1–12 (2016) Google Scholar   T.
    Theodorou and L. Mamatas: CORAL-SDN: a software-defined networking solution for
    the internet of things. In: EEE Conference on Network Function Virtualization
    and Software Defined Networks (NFV-SDN), Nov 2017. Oliveira, B.T., Gabriel, L.B.,
    Margi, C.B.: TinySDN: enabling multiple controllers for software-defined wireless
    sensor networks. IEEE Lat. Am. Trans. 13, 3690–3696 (2015) Article   Google Scholar   Hamed,
    R., Rizk, M., Mokhtar, B.: IoTManager: concerns-based SDN management framework
    for IoT networks. Adv. Intell. Syst. Comput. 1252(3), 153–167 (2021) Google Scholar   Akyildiz,
    I.F., Wang, P., Lin, S.: SoftAir: a software defined networking architecture for
    5G wireless system. Comput. Netw. 85, 1–18 (2015) Article   Google Scholar   Pentikousis,
    K., Wang, Y., Hu, W.: Mobileflow: toward software-defined mobile networks. IEEE
    Commun. Mag. 51(7), 44–53 (2013) Article   Google Scholar   X. Jin, E. Li, L.
    Vanbever, and J. Rexford: Cellsdn: software-defined cellular core networks. Techinical
    Report, Princeton university, 2013. Tomovic, S., Yoshigoe, K., Maljevic, I., Radusinovic,
    I.: Software-defined fog network architecture for IoT. Wireless Pers. Commun.
    92(1), 181–196 (2017) Article   Google Scholar   A. Gudipati, D. Perry, L. E.
    Li, S. Katti: SoftRAN: software defined radio access network. In: the Second ACM
    SIGCOMM Workshop on Hot Topics in Software Defined Networking, Hong Kong, China,
    2013 Haque, I., Nurujjaman, M., Harms, J., Abu-Ghazaleh, N.: SDSense: an agile
    and flexible SDN-based framework for wireless sensor networks. IEEE Trans. Veh.
    Technol. 68, 1866–1876 (2019) Article   Google Scholar   Wang, H., Chen, S., Xu,
    H., Ai, M., Shi, Y.: SoftNet: a software defined decentralized mobile network
    architecture toward 5G. IEEE Network 29, 16–22 (2015) Article   Google Scholar   L.
    Galluccio, S. Milardo, G. Morabito, and S. Palazzo: SDN-WISE: design, prototyping
    and experimentation of a stateful SDN solution for WIreless SEnsor networks. In:
    IEEE Conference on Computer Communications (INFOCOM), pp. 513–521, 2015. D. Gante,
    M. Aslan, and Matrawy: Smart wireless sensor network management based on software-defined
    networking. In: 27th Biennial Symposium, 2014. Duan, Y., Li, W., Fu, X., Luo,
    Y., Yang, L.: A methodology for reliability of WSN based on software defined network
    in adaptive industrial environment. IEEE/CAA J. Autom. Sin. 5(1), 74–82 (2018)
    Article   Google Scholar   S. Das and S. Sahni: Network topology optimization
    for data aggregation. In: Proceedings of IEEE/ACM International Symposium on Cluster,
    Cloud and Grid Computing (CCGrid), p. 493–501, May 2014. Z. Su, T. Wang, Y. Xia,
    and M. Hamdi: FlowCover: low-cost flow monitoring scheme in software defined networks.
    In: IEEE GLOBECOM, p. 1956–1961, Dec. 2014. Y. Liu, Y. Li, Y. Wang, A. V. Vasilakos,
    and J. Yuan: Achieving efficient and fast update for multiple flows in software-defined
    networks. In: ACM SIGCOMM workshop on Distributed cloud computing, p. 77–82, NY,
    2014. J. Huang, Y. He, Q. Duan, Q. Yang, and W. Wang: Admission control with flow
    aggregation for QoS provisioning in software-defined network. In: The IEEE GLOBECOM,
    vol. TX, p. 1182–1186, Dec. 2014. A. Hakiri and A. Gokhale: Rethinking the design
    of LR-WPAN IoT systems with software-defined networking. In: Proceedings of the
    12th Annual International Conference on Distributed Computing in Sensor Systems,
    May 2016. Li, Y., Su, X., Ding, A.Y., Lindgren, A., Liu, X., Prehofer, C., Riekki,
    J., Rahmani, R., Tarkoma, S., Hui, P.: Enhancing the internet of things with knowledge-driven
    software-defined networking technology: Future perspectives. Sensors 20(12), 1–20
    (2020) Article   Google Scholar   Mukherjee, B., Pappu, S.I., Islam, M.J., Acharjee,
    U.K.: An SDN based distributed IoT network with NFV implementation for smart cities.
    In: ICONCS 2020, pp. 539–552. Springer, Cham (2020). https://doi.org/10.1007/978-3-030-52856-0_43
    Chapter   Google Scholar   Antonić, A., Marjanović, M., Pripuziić, K., Zarko,
    I.P.: A mobile crowd sensing ecosystem enabled by CUPUS: cloud-based publish/subscribe
    middleware for the internet of things. Future Gener. Comput. Syst. 56, 607–622
    (2017) Article   Google Scholar   M.Bonanni, F.Chiti, R.Fantacci, L.Pierucci,
    \"Dynamic Control Architecture Based on Software Defined Networking for the Internet
    of Things\" Future Internet, vol. 13, no. 5, p. https://doi.org/10.3390/fi13050113,
    2021. Hassan, N., Gillani, S., Ahmed, E., Yaqoob, I., Imran, M.: The role of edge
    computing in internet of things. IEEE Commun. Mag. 56, 1–12 (2018) Article   Google
    Scholar   Naranjo, P.G., Pooranian, Z., Shamshirband, S., Abawajy, J.H., Conti,
    M.: Fog over virtualized IoT: new opportunity for context-aware networked applications
    and a case study. Appl. Sci. 7(12), 1325 (2017) Article   Google Scholar   Wang,
    H., Zhang, X., Zhang, Y., Wang, L., Yang, J., Wang, W.: A survey on mobile edge
    networks: convergence of computing, caching and communications. IEEE Access 5,
    6757–6779 (2017) Article   Google Scholar   Shukla, S., Hassan, M.F., Tran, D.C.,
    et al.: Improving latency in internet-of-things and cloud computing for real-time
    data transmission: a systematic literature review (SLR). Clust. Comput. (2021).
    https://doi.org/10.1007/s10586-021-03279-3 Article   Google Scholar   Fan, Q.,
    Ansari, N.: On cost aware cloudlet placement for mobile edge computing. IEEE/CAA
    J. Autom. Sin. 6(4), 926–937 (2019). https://doi.org/10.1109/JAS.2019.1911564
    Article   MathSciNet   Google Scholar   Wang, X., Wang, C., Zhang, J., Zhou, M.,
    Jiang, C.: Improved rule installation for real-time query service in software-defined
    internet of vehicles. IEEE Trans. Intell. Trans. Syst. 18(2), 225–235 (2017).
    https://doi.org/10.1109/TITS.2016.2543600 Article   Google Scholar   Hou, X.,
    Li, Y., Chen, M., Wu, D., Jin, D., Chen, S.: Vehicular fog computing: a viewpoint
    of vehicles as the infrastructures. IEEE Trans. Veh. Technol. 65(6), 3860–3873
    (2016) Article   Google Scholar   Toczé, K., Tehrani, S.N.: A taxonomy for management
    and optimization of multiple resources in edge computing. Wirel. Commun. Mob.
    Comput. 2018, 1–23 (2018) Article   Google Scholar   European telecommunications
    standards institute industry specifications group. mobile-edge computing-mec metrics
    best practice and guidelines. http://www.etsi.org/deliver/etsi-gs/MEC-IEG/001099/004/0
    (2019). Accessed on September 28, 2019 Kiani, F.: A survey on management frameworks
    and open challenges in IoT. Wirel. Commun. Mobile Comput. 2018, 1–33 (2018) Article   Google
    Scholar   Yaqoob, I., Ahmad, I., Ahmed, E., Gani, A., Imran, M., Guizani, N.:
    Overcoming the key challenges to establishing vehicular communication: is SDN
    the answer? IEEE Commun. Mag. 55, 128–134 (2017) Article   Google Scholar   Dong,
    M., Li, H., Ota, K., Xiao, J.: Rule caching in SDN-enabled mobile access networks.
    IEEE Netw. 29(4), 40–45 (2015) Article   Google Scholar   Liu, J., Li, Y., Chen,
    M., Dong, W., Jin, D.: Software-defined internet of things for smart urban sensing.
    IEEE Commun. Mag. 53(9), 55–63 (2015) Article   Google Scholar   Kim, H., Feamster,
    N.: Improving network management with software defined networking. IEEE Commun.
    Mag. 51(2), 114–119 (2013) Article   Google Scholar   S.Sebastian, P.P.Ray: Development
    of IoT invasive architecture for complying with health of home. I3CS, vol. Shillong,
    p. 79–83, 2015. [Online]. Available: https://datatracker.ietf.org/doc/html/draft-li-sdnrg-design-restapi-02.
    [Online]. Available: https://opennetworking.org/wp-content/uploads/2013/02/of-config1dot0-final.pdf.
    Pan, J., McElhannon, J.: Future edge cloud and edge computing for internet of
    things applications. IEEE Internet Things J. 5, 1–11 (2017) Google Scholar   G.
    Deng, K. Wang; An information framework of creating a smart city through internet
    of things. In: IEEE Symposium on Computers and Communications (ISCC), 2018. iofog,
    2019. https://iofog.org/. [Online]. F.Liu, G.Tang, Y.Li, Z.Cai, X.Zhang ,and T.Zhou,
    \"A Survey on Edge Computing Systems and Tools,\" Computer Science Distributed,
    Parallel, and Cluster Computing. arXiv:1911.02794 (cs), p. 24, Nov 2019. Eclipse
    Kura, 2018, https://www.eclipse.org/kura/ [Online]. Cord, 2018, https://www.opennetworking.org/cord.
    [Online]. Apache edgent, 2018, http://edgent.apache.org. [Online]. https://www.opnfv.org/wp-content/uploads/sites/12/2017/09/OPNFV_VCO_Oct17.pdf,
    [Online]. Y. Xiong, Y. Sun, L. Xing, and Y. Huang: Extend cloud to edge with kubeedge.
    In: IEEE/ACM Symposium on Edge Computing (SEC 2018), p. 373–377, 2018. OpenEdge:
    extend cloud computing, data and service seamlessly to edge devices [Online].
    Available: https://www.crunchbase.com/organization/openedge [Online]. Azure IoT
    Edge, extend cloud intelligence and analytics to edge devices. [Online]. Available:
    https://github.com/Azure/iotedge [Online]. EdgeX, the Open Platform for the IoT
    Edge. [Online]. Available: https://www.edgexfoundry.org/ [Online]. Akraino Edge
    Stack. [Online]. Available: https://www.lfedge.org/projects/akraino/ [Online].
    NVIDIA EGX Edge Computing Platform: Real-Time AI at the Edge. [Online]. Available:
    https://www.nvidia.com/en-us/data-center/products/egx/ [Online]. AWS IoT Greengrass:
    Bring local compute, messaging, data caching, sync, and ML inference capabilities
    to edge devices. [Online]. Available: https://aws.amazon.com/greengrass/ [Online].
    Google Cloud IoT: Unlock business insights from your global device network with
    an intelligent IoT platform.” [Online]. Available: https://cloud.google.com/solutions/iot/
    [Online]. Arship: a robust delivery mechanism for organizations who want to embrace
    containers as the new unit of infrastructure delivery at scale. Available: https://www.airshipit.org/
    [Online]. StarlingX: is a complete cloud infrastructure software stack for the
    edge used by the most demanding applications in industrial IOT, telecom, video
    delivery and other ultra-low latency use cases. Available: https://www.starlingx.io/
    [Online]. Wang, N., Varghese, B., Matthaiou, M., Nikolopoulos, D.S.: Enorm: a
    framework for edge node resource management . IEEE Trans. Serv .Comput. (2017).
    https://doi.org/10.1109/TSC.2017.2753775 Article   Google Scholar   M. Körner,
    T. M. Runge, A. Panda, S. Ratnasamy, and S. Shenker: Open carrier interface: An
    open source edge computing framework. In: Proc. Workshop Netw. Emerg. Appli. Technol,
    Budapest, Hungary, 2018. B.Varghese, N.Wang, J.Li, and D.S.Nikolopoulos, \"Edge-as-a-service:
    Towards distributed cloud architectures,\" arXiv preprint. arXiv:1710.10090, 2017.
    Liu, J., Wan, J., Zeng, B., Wang, Q., Song, H., Qiu, M.: A scalable and quick-response
    software defined vehicular network assisted by mobile edge computing. IEEE Commun.
    Mag 55(7), 94–100 (2017) Article   Google Scholar   CihatBaktir, A., Ozgovde,
    A., Ersoy, C.: How can edge computing benefit from software-defined networking:
    a survey use cases & future directions. IEEE Commun. Surv. Tutor. 19, 1–35 (2017)
    Google Scholar   Yang, X., Shu, L., Chen, J., Ferrag, M.A., Wu, J., Nurellari,
    E., Huang, K.: A survey on smart agriculture: development modes, technologies,
    and security and privacy challenges. IEEE/CAA J. Autom. Sin. 8(2), 273–302 (2021)
    Article   Google Scholar   Mihovska, A., Sarkar, M.: Smart connectivity for internet
    of things (IoT) applications. In: New Advances in the Internet of Things, pp.
    105–118. Springer, Cham (2018) Chapter   Google Scholar   Zhou, M., Fortino, G.:
    Security and trust issues in fog computing: a survey. Future Gener. Comput. Syst.
    88, 16–27 (2018) Article   Google Scholar   Khairi, S., Raouyane, B., Bellafkih,
    M.: Novel QoE monitoring and management architecture with eTOM for SDN-based 5G
    networks. Clust. Comput. 23, 1–12 (2020). https://doi.org/10.1007/s10586-018-02903-z
    Article   Google Scholar   Wang, X., Ning, Z., Zhou, M., Hu, X., Wang, L., Hu,
    B., Kwok, R.Y.K., Guo, Y.: A privacy-preserving message forwarding framework for
    opportunistic cloud of things. IEEE Internet Things J. 5(6), 5281–5295 (2018)
    Article   Google Scholar   Download references Author information Authors and
    Affiliations Department of Computer Engineering, North Tehran Branch, Islamic
    Azad University, Tehran, Iran Seyedeh Shabnam Jazaeri & Sam Jabbehdari Department
    of Computer Engineering, Central Tehran Branch, Islamic Azad University, Tehran,
    Iran Parvaneh Asghari Department of Mathematics and Computer Science, Shahed University,
    Tehran, Iran Hamid Haj Seyyed Javadi Corresponding author Correspondence to Parvaneh
    Asghari. Additional information Publisher''s Note Springer Nature remains neutral
    with regard to jurisdictional claims in published maps and institutional affiliations.
    Rights and permissions Reprints and permissions About this article Cite this article
    Jazaeri, S.S., Jabbehdari, S., Asghari, P. et al. Edge computing in SDN-IoT networks:
    a systematic review of issues, challenges and solutions. Cluster Comput 24, 3187–3228
    (2021). https://doi.org/10.1007/s10586-021-03311-6 Download citation Received
    29 July 2020 Revised 16 May 2021 Accepted 25 May 2021 Published 11 June 2021 Issue
    Date December 2021 DOI https://doi.org/10.1007/s10586-021-03311-6 Share this article
    Anyone you share the following link with will be able to read this content: Get
    shareable link Provided by the Springer Nature SharedIt content-sharing initiative
    Keywords Internet of things (IoT) Software-defined networking (SDN) Edge computing
    Systematic review Use our pre-submission checklist Avoid common mistakes on your
    manuscript. Sections Figures References Abstract Introduction Motivation Structure
    of SDN-EC-IoT technologies Research selection method Related work Summary and
    insights Discussion and open issues Conclusion Notes References Author information
    Additional information Rights and permissions About this article Advertisement
    Discover content Journals A-Z Books A-Z Publish with us Publish your research
    Open access publishing Products and services Our products Librarians Societies
    Partners and advertisers Our imprints Springer Nature Portfolio BMC Palgrave Macmillan
    Apress Your privacy choices/Manage cookies Your US state privacy rights Accessibility
    statement Terms and conditions Privacy policy Help and support 129.93.161.222
    Big Ten Academic Alliance (BTAA) (3000133814) - University of Nebraska-Lincoln
    (3000134173) © 2024 Springer Nature"'
  inline_citation: '>'
  journal: Cluster Computing
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: 'Edge computing in SDN-IoT networks: a systematic review of issues, challenges
    and solutions'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Deng H.
  citation_count: '2'
  description: The appearance of complex and biomedical and competitive-based information
    applications, sports, and other fields with zero-can remote sensors. These areas'
    junctions were reflected and shown in the methods and applications used for assembly,
    measurement, and identification of specific central parts determined by the human
    body. These policies have been proven in various biomedical and sports applications,
    including diagnostics, recovery, real-time viewing, and implementation of competitors'
    progress domains. But the two uses have only been described in two areas of study
    (biomedicine and sports), with the comparative application being sufficient in
    both, with minor discretion or modification. To speak with the contemporaneity
    of jobs, have been looking at specific documents that have been scattered over
    the last six years. In this exciting situation, this review's central criterion
    is to demonstrate the bulk of the sensor composites and the excellent sensor that
    focuses on their use and reference, to the disruption of others, without significantly
    looking at an express system or strategy.
  doi: 10.1016/j.micpro.2020.103697
  full_citation: '>'
  full_text: '>

    "Skip to main content Skip to article Journals & Books Search Register Sign in
    Brought to you by: University of Nebraska-Lincoln View PDF Download full issue
    Cited by (2) Microprocessors and Microsystems Volume 81, March 2021, 103697 RETRACTED:
    Real-Time monitoring of Athletes training data based on wireless sensors Author
    links open overlay panel Hongtao Deng Show more Add to Mendeley Share Cite https://doi.org/10.1016/j.micpro.2020.103697
    Referred to by Retraction notice to the articles published in the Special issue
    Embedded Processors from “Microprocessors and Microsystems” Microprocessors and
    Microsystems, Volume 101, September 2023, Pages 104902 View PDF This article has
    been retracted: please see Elsevier Policy on Article Withdrawal (http://www.elsevier.com/locate/withdrawalpolicy).
    This article has been retracted at the request of the Editor-in-Chief. Significant
    similarities were noticed post-publication between this special issue article
    and other published sources. There is an indication that attempts have been made
    to disguise the copying using automated paraphrasing. Subsequent to acceptance
    of these special issue papers by the responsible guest editor, Sundhararajan Mahalingam,
    the integrity and rigor of the peer-review process of the Special Issue were investigated
    and confirmed to fall beneath the high standards expected by Microprocessors &
    Microsystems. Due to a configuration error in the editorial system, unfortunately
    neither the Editor in Chief nor the designated Handling Editors received these
    papers for approval as per the journal’s standard workflow. Previous article in
    issue Next article in issue View PDF Cited by (2) Exploring competitive sports
    technology development: using a MCDM model 2023, Journal of Physical Education
    and Sport Low-Resolution Face Recognition and Sports Training Action Analysis
    Based on Wireless Sensors 2023, Journal of Circuits, Systems and Computers View
    Abstract © 2020 Elsevier B.V. All rights reserved. Part of special issue Embedded
    multi/manycore processors for ml/dl in medical cyber physical systems Edited by
    Francesco Leporati, Sundhararajan Mahalingam, Imed Ben Dhaou, Tomasz Rak View
    special issue Recommended articles No articles found. Article Metrics Citations
    Citation Indexes: 2 Captures Readers: 11 View details About ScienceDirect Remote
    access Shopping cart Advertise Contact and support Terms and conditions Privacy
    policy Cookies are used by this site. Cookie settings | Your Privacy Choices All
    content on this site: Copyright © 2024 Elsevier B.V., its licensors, and contributors.
    All rights are reserved, including those for text and data mining, AI training,
    and similar technologies. For all open access content, the Creative Commons licensing
    terms apply."'
  inline_citation: '>'
  journal: Microprocessors and Microsystems
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Real-Time monitoring of Athletes’ training data based on wireless sensors
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Clarkson L.
  - Williams D.
  - Seppälä J.
  citation_count: '15'
  description: Real-time monitoring can improve the performance assessment of tailings
    dams by reducing the laborious component of data collection while streamlining
    the analysis process. When planning and installing instrumentation, the challenge
    exists where if nothing goes wrong, the question is asked whether too much instrumentation
    is installed, where on the other hand if a failure occurs, the question is asked
    as to why more investment was not made to prevent it from occurring. This paper
    identifies the monitoring system requirements, assesses the cost of historical
    tailings dam failures (Mt Polley and Fundão), assesses the cost of a real-time
    monitoring system to suit the instrumentation that was in place at time of failure
    of those dams (including standpipe and vibrating wire piezometers, digital inclinometers,
    and flow meters), and suggests ways to extract more value from individual instruments
    to full monitoring system integration.
  doi: 10.1080/17499518.2020.1740280
  full_citation: '>'
  full_text: '>

    "Access provided by University of Nebraska, Lincoln Log in  |  Register Cart Home
    All Journals Georisk: Assessment and Management of Risk for Engineered Systems
    and Geohazards List of Issues Volume 15, Issue 2 Real-time monitoring of tailings
    dams Search in:                                        This Journal                                                                                Anywhere                                                                  Advanced
    search Georisk: Assessment and Management of Risk for Engineered Systems and Geohazards
    Volume 15, 2021 - Issue 2 Submit an article Journal homepage Full access 649 Views
    6 CrossRef citations to date 0 Altmetric Listen Articles Real-time monitoring
    of tailings dams Luke Clarkson , David Williams & Jaakko Seppälä Pages 113-127
    | Received 10 Sep 2019, Accepted 05 Mar 2020, Published online: 13 Mar 2020 Cite
    this article https://doi.org/10.1080/17499518.2020.1740280 In this article ABSTRACT
    1. Introduction 2. Current practice 3. Financial 4. Implementation 3. Conclusion
    Disclosure statement References Full Article Figures & data References Citations
    Metrics Reprints & Permissions View PDF View EPUB ABSTRACT Real-time monitoring
    can improve the performance assessment of tailings dams by reducing the laborious
    component of data collection while streamlining the analysis process. When planning
    and installing instrumentation, the challenge exists where if nothing goes wrong,
    the question is asked whether too much instrumentation is installed, where on
    the other hand if a failure occurs, the question is asked as to why more investment
    was not made to prevent it from occurring. This paper identifies the monitoring
    system requirements, assesses the cost of historical tailings dam failures (Mt
    Polley and Fundão), assesses the cost of a real-time monitoring system to suit
    the instrumentation that was in place at time of failure of those dams (including
    standpipe and vibrating wire piezometers, digital inclinometers, and flow meters),
    and suggests ways to extract more value from individual instruments to full monitoring
    system integration. KEYWORDS: Remote sensingreal-time monitoringtailings damriskgeotechnicalmining
    Previous article View issue table of contents Next article 1. Introduction Tailings
    dam operation is becoming an increasingly scrutinised practice as the mining industry
    progresses toward a more sustainable future. Failure of these structures can present
    in many different forms, and can exhibit significant consequence to the social,
    environmental, and economic risks that are linked to its existence. An assessment
    of the current standing of the industry in terms of both practice and regulation
    has been undertaken by the author, with a critical flaw of practice identified
    as the lack of consistent, real-time, and online tailings dam monitoring. This
    presents a major risk in the understanding of tailings dam performance where the
    low frequency of manual data collection and interpretation, is far slower the
    time taken for dam failure to progress; with respect to identifying failure, these
    readings could be considered as redundant measures. The ability for instrumentation
    and monitoring to foresee deterioration of slopes is becoming more available with
    improving technologies. Further, there has not been a single tailings dam failure
    in history that, in hindsight, was not proven to have been predictable with the
    information available (Davies, Martin, and Lighthall 2000). The severe consequences
    and risk of tailings dam failure globally demand improvement in how practitioners
    understand and monitor the performance of the dam without complacency and putting
    people’s lives and the environment at risk. With opportunities to predict tailings
    dam failure existing alongside a continued tailings dam failure rate, the industry
    has an immediate responsibility to advance their understanding and mitigate the
    risk of failure. As technology is now more readily available, it is important
    to understand how to effectively and efficiently apply this in the mining environment.
    Tailings dams do not contribute to the revenue of the operation yet can severely
    deplete this revenue should there be a failure. An evaluation of effective costs
    can be used to justify different levels of monitoring programs, identify areas
    of optimisation in the instrumentation use (such as overlapping with environmental
    monitoring), whilst always appropriately understanding the key geotechnical risk
    areas. While static liquefaction has become a topic of interest in recent years,
    the focus in mitigating the risk associated with this has been on design considerations
    of potential strength reductions, operational control and planning, and material
    characterisation for susceptibility to liquefaction and to understand pre-consolidation
    stresses. From Klohn Crippen Berger ( 2019), it is stated that “much of the risk
    depends on the in-situ stress regime, which is difficult to measure and monitor”.
    Considering the speed of static liquefaction occurrence, and the current inability
    of monitoring systems to identify conditions preceding static liquefaction, real-time
    monitoring is anticipated to be a beneficial step in the right direction to significantly
    increase the frequency of monitoring, more readily understand developing conditions
    in the tailings dam structure, and in turn develop further knowledge on the phenomena
    and ways that the risk can be mitigated. 2. Current practice Two-thirds of surveyed
    tailings dam practitioners agree that the frequency of instrumentation reading
    as mandated through acts, regulations, or guidelines, is insufficient to capture
    the initiation and progression of different failure types. A number of areas for
    improvement in the management and regulation of tailings dam monitoring techniques
    were identified as, but not limited to: Rigid, prescriptive requirements driven
    by regulation do not have the flexibility to adequately address the unique conditions
    at each site; Ongoing monitoring and operator refreshers/audits should be undertaken
    to avoid complacency; There is value in establishing a structured, systematic
    response plan to mitigate human error in stressful situations; Greater specification
    by regulations is required on the frequency of monitoring; Benchmarked monitoring
    standards based on global learnings should be communicated: “you don’t know what
    you don’t know”; It is not enough to mandate the frequency of readings, alone.
    There needs to be an understanding of the response of each instrument and integration
    between them; and With a telemetry device, we can obtain a better understanding
    of the initiation and progression of a potential failure. Hui, Charlebois, and
    Sun ( 2017) reviewed the state of practice through personal experience and consultation
    with over 40 industry stakeholders. This unveiled three key state of practices:
    “Most tailings dams will undergo routine visual surface inspection and limited
    instrumentation monitoring”. This is often manual, infrequent, conducted by junior
    (relatively less experienced) staff, limited by the risk of manually reading instrumentation
    in poor weather conditions, and subject to human error; “Manual readings and data
    processing can require substantial person hours that may result in delays of up
    to a few days before behavioural trends can be identified”; and “Some monitoring
    techniques can only provide information over a very limited period of time to
    monitor surface deformation”. Avella ( 1993) assessed the practices of 30 countries
    in terms of the frequency of different instrumentation readings. Clarkson and
    Williams ( 2019) supplemented this list with information from more recent guidelines,
    acts, and regulations, acknowledging the significance of the frequency of instrumentation
    reading from two perspectives: It must be frequent enough to allow identification
    and assessment of the initiation and progression of failure; and It cannot be
    overly frequent so as to become uneconomical or drive a complacent culture. The
    real-time, online monitoring solution reduces the laborious element of instrumentation
    reading, contributing a significant amount to reducing the risk of hazardous access,
    infrequent information collection, and complacent cultures. Aligned with the intent
    of this paper, the frequencies of common instrumentation readings (manual or automated),
    described during normal operation are presented in Table 1. It is observed that
    75% of these common instruments or monitoring techniques have a real-time solution
    available on the market. Most often, those instruments linked to a data logger
    on the surface (which with new technologies, are clearly the majority) have the
    ability to be automated through a networked, instrumentation system. It is observed
    that those without real-time solutions comprise visual observation, industry experts,
    or survey practices. Table 1. Frequency of reading for different types of instrumentation
    (adapted from Avella 1993). Download CSVDisplay Table 2.1. Instrumentation system
    A modern real-time slope instrumentation system generally comprises the following
    four key components: Sensor nodes which consist of instruments and a data logger;
    Communication network for sensor nodes; Base station with an external communication
    modem; and Information system for storing and displaying the data. There are other
    elements that are anticipated to be useful for application in a tailings dam application,
    such as repeaters and aggregators. Repeaters are a form of intermediate “connecting”
    sensor node not directly connected to an instrument, used for such purposes as
    avoiding physical obstacles to the data transmission onsite, seen in Tang and
    Cheung ( 2011), and aggregators are a tool used to “reduce the number of transmissions
    of sensor nodes, and hence minimising the overall power consumption”, in Al-Karaki,
    Ul-Mustafa, and Kamal ( 2004). While relevant, the detail of these components
    is not discussed in this paper as they contribute more to the logistics of data
    collection and transmission process onsite, than to the monitoring approach. 2.1.1.
    Sensor nodes The items listed in Table 1 define instruments that can be employed,
    as well as their suitability for integration into the real-time system. It is
    noted that most of the instruments measure the changes in electrical properties … which
    are then converted to give ground displacement, distortion, or groundwater pressure,
    as appropriate. The changes in these electric properties are usually brought about
    by variations in magnetic field, natural frequency, electric resistance or conductivity
    due to displacement or elongation of the embedded elements of the instrument.
    (Tang and Cheung 2011) It is this electrical property (whether transmitted by
    analog or digital) that allows the instrument’s signal to be collected by a data
    logger. Together, the instrument and data logger are connected by means of a cable
    in order to make a sensor node. For instruments such as inclinometers or extensometers,
    a multiplexing system is used to connect the data logger to different anchor depths,
    detailed by Tang and Cheung ( 2011). There are a number of different types of
    data loggers, distinguished primarily by their data transmission method, input
    format, and power source. Data loggers can be provided with or without data transmission,
    which refers to the WiFi, General Packet Radio Service (GPRS, mobile data, 2G/3G/4G,
    etc.), Long Range (LoRa) technologies, that act as the medium by which information
    is transmitted. For tailings dams, cell networks are preferred because they are
    both cost efficient and reliable for the purpose. Where cell network is not available
    (remote mine sites), the practical alternative is satellite communications, followed
    by LoRa. However, with the rise of autonomous and remotely operated vehicles on
    mine sites, the availability of communication technologies is increasing with
    varied opinion at time of this paper as to the preferred method forward. Data
    loggers can either be single sensor input, or multi-channel input. Further, inputs
    can either be analog, or digital. Traditionally, instruments would have been set
    up as analog. For example, inclinometer tubes would have up to 30 cables to different
    downhole increments in order to collect data. As technology advances, the digital
    solution instead sees a single cable returning the data from all increments. This
    makes it easier to handle multiple sensors when the data is digital, hence gaining
    more value from both the sensor and data logger. A digital sensor can record two
    different types of reading (e.g. pH and temperature, or conductivity and temperature),
    or multiple readings of the same type (e.g. inclinometer). The power source can
    vary, and is often dependent on the locality of the data logger, climate/weather
    conditions of the site, and redundancy of the instrumentation system (should the
    power source fail). Sources include battery, solar, and mains powered data loggers.
    It is anticipated that the majority of instruments can be retrofitted to an online
    system. This is dependent on the type of data, type of sensor, which will, in
    turn, inform the data logger that is used. Standard 4–20 mA analog sensors can
    be adapted, and it would be expected that all digital sensors can be adapted.
    2.1.2. Sensor networks For tailings dams, it should be expected that a number
    of sensor nodes are installed at different locations. In order to streamline the
    collection of data from the different sensor nodes, a sensor network is set up.
    This network may link by cabled and wireless connections such as Wi-Fi, Bluetooth,
    or ZigBee. A comparison between different connections is presented in Table 2.
    The variety of sensors present in a tailings dam system will typically introduce
    a heterogeneous sensor network. It is noted that in the context of a tailings
    dam and operational practicality, the “optimal operational range” and “battery
    life” are deemed significant considerations in ensuring a reliable and connected
    system. Table 2. Comparison of common IEEE wireless protocols, from Tang and Cheung
    ( 2011). Download CSVDisplay Table In the sensor network, the path of the information
    gathered from the sensors is controllable and in consideration of the extent of
    network required within a tailings dam, must be considered in order to ensure
    resilience in the case of failure of individual nodes. This path is referred to
    as the network topology. A comparison of network topologies is presented in Table
    3. Table 3. Network topology types (adapted from Tang and Cheung 2011 and McGrath
    and Scanaill 2013). Display Table 2.1.3. Base station A base station is the main
    data logger, which “typically acts as a gateway between sensor nodes and the end
    user” (from McGrath and Scanaill 2013) by leveraging its greater computational,
    energy, and communication resources to transmit data. Two primary elements comprise
    a data logger: a small computer (for data processing) and an external communication
    modem. A Wide Area Network (WAN) is typically adopted in the external communication
    model for transmission between the data logger and the end user, while a backup
    is stored in the case of any disruption in transfer. The WAN can either be land-based
    datalines, or wireless mobile services. The risks and opportunities of different
    communication methods are summarised in Table 4. With the exception of GSM technology,
    current mobile telemetry services usually route the data packets through the Internet
    between the base station and remote data server to minimise operating costs. (Tang
    and Cheung 2011) Table 4. Summary of land-based dataline and mobile services (adapted
    from Tang and Cheung 2011). Download CSVDisplay Table Power consumption of the
    external communications modem is usually the primary risk associated with this
    setup. If remote, the data logger is usually accompanied by a rechargeable battery
    and solar panel, and employs techniques such as only turning on at scheduled transmission
    times in order to preserve power, see Tang and Cheung ( 2011). For data transmission
    on remote sites that do not have mobile coverage or WiFi available, satellite
    data communication is an option. Satellite data communication is more expensive,
    both in terms of the hardware (approximately 1.5 times the cost) and the data
    transmission costs (approximately 2–3 times the cost). The conditions at different
    sites should also be considered in terms of the operation of the equipment. For
    example, the temperature range (both extremes), network and power source interruptions
    and interference, degree of remoteness, and other environmental conditions such
    as humidity, wind, corrosion susceptibility, and lightning/ thunder. These conditions
    can typically be accounted for in the specifications of different systems, and
    as such, it is recommended that these risks are recognised at the early stage.
    Protection systems do exist to retrofit at a later stage, however, these systems
    also cost money and are likely to be identified once the damage has already occurred.
    In the Technical Fact Sheets/Technical Specifications/Technical Data Sheets that
    accompany the equipment, acceptable ranges for the equipment are often provided
    to indicate suitability for operational conditions. For other considerations,
    such as animal damage (livestock rubbing) and theft, local controls are likely
    required. 2.1.4. Information system The information and sensor systems should
    be considered equally critical: if one is not reliable and operational, the other
    could be considered near redundant. If the engineers, site operators, or management
    cannot easily and quickly gain an understanding of tailings dam health, the system
    can be considered flawed. There are a number of elements that can be addressed
    to improve the quality of the Information System: User Interface (UI), or what
    the user sees and interacts with, for manipulation and dissemination of data;
    Automated alarm criteria linked to a response/ alert system; Web-based applications
    to allow access to many users at the same time; Enterprise database for storing
    large volumes of data captured and facilitating remote back-up; and Information
    security controls. User Interface. The User Interface is the main tool in the
    information system that the geotechnical engineer will query for analysis, reporting,
    and communication. With this in mind, there are key features that should be offered
    in the UI, as a minimum: The ability to query historical and current data trends
    of individual (and multiple) instruments installed in the mine. This should be
    available through both raw data and graphical means; A front-and-centre preview
    of where and what level of alarm is triggering onsite; Customisable reporting
    functions, including current health, reading trends over the nominated time period,
    and reading trends since installation; and Forecasting of trends based on user-selected
    regression (for example, if the user is expecting the water level to continue
    rising in a linear fashion since it first started rising 1 day ago). General UI
    design should also be addressed, including the importance of guided action, clarity,
    and user forgiveness in the design. These three elements are identified in particular,
    where it is encouraged that the UI is considered in a stressed scenario where
    deterioration is actively occurring, the engineer has mine management on their
    shoulder, and it is this UI that is facilitating the decision that determines
    safety of both the mine and its personnel; Does the engineer have the tools at
    their ready disposal to make the most informed decision possible? Web-based applications.
    The provision and integration of web-based applications have two primary benefits:
    Allows access to many users at the same time; and Allows access to users from
    many different spatial areas. Onsite, and particularly in alignment with the TARP,
    different personnel require access and visibility at the same time. For example,
    the control room supervisor may embed the monitoring system as a parallel tool
    alongside other mine operations, while at the same time the geotechnical engineer
    may seek to access and monitor the systems to analyse historical and predicted
    measurement trends. For international organisations or service providers, the
    global time zone difference can be leveraged for 24/7 monitoring and analysis.
    The value of the information is reiterated; if the information cannot be accessed,
    critical decisions and monitoring cannot be made. As such, the fundamental criteria
    are recommended as unimpeded access to the Information System at all times. Automatic
    alarm criteria linked to a response/alert system. In geotechnical monitoring,
    critical points of measurement at which point the performance of the dam is at
    such a state that prompts action outside of normal operation should be advertised
    via alarms. Fundamentally linked to the Trigger Action Response Plan (TARP) approach,
    the trigger levels inform short term behaviour and are established based on either
    previous or modelled performance (see section 4.1). With the metrics being recorded
    in the Information System, this then becomes the logical place to embed the system
    that searches for a trigger, confirms the trigger, and distributes the warning
    to the nominated persons. The warning could be an instruction to evacuate, or
    to take different measures that can work to mitigate the consequence/interrupt
    the deterioration before failure occurs. This provides reassurance to the mine
    operator that even if the software is not being monitored 24/7 for any sign of
    change, the automation will provide sufficient warning. Enterprise database. In
    any monitoring system, individual readings or scans do not typically automatically
    overwrite the previous reading. This is because there is an inherent value in
    leveraging previous performance as an indicator for future behaviour. In order
    to do this, a reliable and capable database is required for storing large volumes
    of captured data, and facilitating remote back-up. 3. Financial 3.1. Cost of recent
    failures A study published by Bowker and Chambers ( 2015), recognised that the
    frequency, severity, and cost of tailings dam failures is increasing. Particular
    findings of the research identified an un-fundable economic consequence associated
    with failure between 2010 and 2020; 11 catastrophic failures are predicted at
    an estimated cost of $6 billion, paralleled by 12 serious failures at an additional
    $1 billion. These losses are “uninsurable”, and represent “what had been spent
    on remediation, compensation for damages or assigned as a value for actual socio
    economic and natural resources loss”, in Bowker and Chambers ( 2015). These figures
    present an average cost of $545 million for catastrophic failures, an $83 million
    for serious failures. There is no organized industry attempt to pool these losses
    in the context of a risk management loss prevention program, and no political
    jurisdiction issuing permits is large enough to prefund a low frequency high consequence
    loss of this scale. The inevitable result is either government pays or the damages
    go unremediated. (Bowker and Chambers 2015) Reflective of performance, financial
    health, prospects for growth, and reputation of the company as linked to investor
    confidence, the stock price of a mining operator is often a reference point in
    assessing the consequence of any tailings dam failure. An assessment of the change
    in stock price for mining operators following recent, significant failures over
    the previous ten years is presented in Table 5. Table 5. Major tailings dam failure
    consequences. Download CSVDisplay Table Occurrence of tailings dam failures have
    also been linked, from Davies and Martin ( 2009), to the cyclicity of the global
    copper and gold prices. It is stated that there is a relationship between the
    peak in commodity prices and the occurrence of failures, with an anecdotal offset
    of approximately two years between the two. As Davies and Martin ( 2009) describe,
    this relationship is ascribed to: Peaking prices drives peaking production, rushing
    design and construction and compromising quality/safety standards; Attractive
    employment market entices employee turnover; Development of resources in high
    risk areas is seen as viable; Post-boom normalisation of operations induces pressures
    on cost cutting; There is a use of inappropriate designs adopted from “similar”
    situations; Independent review is challenged, suspected to be to avoid the associated
    time delays and cost. With an underlying, dependable monitoring system describing
    the current performance and historical reliability of the tailings dam structure,
    the influence of external factors can be mitigated. Modelling and design can be
    readily validated using real data, and performance based monitoring and response
    is readily available. It is the funding allocated to identify and mitigate risks
    in the tailings facility that presents challenges; often, justification for expenditure
    on these structures that do not generate a profit for the organisation is challenged,
    delayed, and reduced. The industry need not segregate safety from finances, entirely;
    however, investment is required in ensuring that the systems in place are functional,
    practical, and reporting on the true performance of the dam structure. Hence,
    research and development into optimising systems, increasing understanding, and
    empowering integrated site teams to be intrinsically linked to the performance
    of their structure is essential. 3.2. Cost of instrumentation New technologies
    and systems are making real-time, online monitoring systems economically viable.
    A collaborator in this research, EHP Environment Ltd., provides modern solutions
    for real-time online monitoring. An overlapping opportunity was identified with
    a number of their solutions, such as pore pressure monitoring, water flow, quality,
    and level, as well as the directly related inclinometer for both horizontal and
    vertical measurements. For a single Ground Monitoring Station, which comprises
    a data logger with a mobile (4G) modem, and solar power system costs approximately
    $5,000 AUD (€3,000 EUR, $3,400 USD at time of this research). One to four sensors
    (piezometers/inclinometers) are typically connected to this data logger. An estimated
    cost to fully monitor the instruments described in the Fundão and Mt Polley investigation
    reports is presented in Table 6. An approximate, typical cost for instruments
    and data loggers is presented as below. This is provided based on typical instrument
    cost in the UK and Europe: Standpipe Piezometers, $1,000 – $1,150 AUD (€600 –
    €700 Euro); Vibrating Wire Piezometers, $1,150 – $1,350 AUD (€700 – €800 Euro,
    including data logger but not including portable readout unit); Digital Inclinometers,
    $2,550 – $10,050 AUD (€300 per metre, plus assembly); and Flow Meters, $500 –
    $650 AUD (€300 – €400, excluding ultrasonic). Table 6. Estimated cost of instrumentation
    for different dam structures. Download CSVDisplay Table It is important to note
    that this exercise is not undertaken to suggest that a real-time monitoring programme
    would have changed historical events, but rather to utilise the data and information
    available from existing mines and case examples. It is suggested that the usefulness
    of real-time data in predicting events is not yet known, however without exploring
    the option it shall remain as an unknown. Data for the quantity of instrumentation
    is sourced from Cleary Gottlieb Steen ( 2016) and Province of British Columbia
    ( 2019). Considering the costs described, Table 7 suggests the estimated cost
    for full real-time monitoring of the two tailings dam examples. Table 7. Estimated
    costs for implementation of a real-time instrumentation system at example dams.
    Download CSVDisplay Table 4. Implementation In both literature and practice regarding
    tailings dam monitoring, it is clear that there is no “one size fits all” solution
    for dam instrumentation quantity and location. The objectives of monitoring, however,
    are consistent throughout (and described further in ANCOLD ( 1976) and Fell et
    al. ( 2015)): To provide confirmation of design assumptions and prediction of
    performance during the construction phase and initial filling of the reservoir;
    To provide during the operation phase of the life of the dam an early warning
    of the development of unusual and potentially unsafe trends in behaviour; To provide
    data on behaviour of dams which may not conform with accepted modern criteria
    and warrant continuous and close monitoring as a guide to the urgency for introduction
    of remedial/stabilising works or other measures; During raising or remedial/stabilizing
    works, which may need to be carried out with the storage full, close monitoring
    of structural/seepage behaviour is warranted to ensure that the additional loading
    introduced by the new works is applied in a manner which will not adversely affect
    the safety of the dam; To satisfy legal obligations of the duty of care; and To
    provide data to allow developments in dam engineering: through better measurement
    of properties. In order to achieve these objectives, a systematic approach should
    be followed when implementing the monitoring system to ensure that every instrument’s
    purpose, tying seamlessly into alert levels and action plans, is realised (from
    Marr ( 2014)): Identify what questions need answering; Identify what measurements
    can and should be made; Design appropriate monitoring system; Plan installation,
    calibration, maintenance, and data management; Prepare and update budget; Procure,
    test, install and verify instruments; Calibrate and maintain instruments and readouts;
    Collect, process and evaluate data; Interpret and report results quickly; and
    Take action when required. Real-time monitoring’s predominant geotechnical benefit
    is from two perspectives. Looking forward, the provision of real-time data presents
    an improved opportunity to identify potentially unsafe trends in behaviour, early.
    This information can then inform a response to repair or evacuate, in either case
    improving the opportunity to reduce the consequence of deterioration or failure.
    Looking backward, the record of data which is centrally stored and near void of
    human error in data entry/ plot generation presents an improved opportunity for
    back-analysis to understand the current performance of the dam in relation to
    the design, and also represents a dataset of measurements that are within the
    performance limits of the dam: the “safe and stable” envelope. 4.1. Establishing
    baseline triggers for real-time monitoring For new mining projects or when an
    existing mine introduces a new monitoring technology/ technique, it is necessary
    to establish reliable targets to monitor performance against. Importantly, “the
    monitoring programme must be developed with a clear sense of purpose, which will
    dictate how the accumulated data are interpreted and reported”, in Hawley and
    Cunning ( 2017). “Interpretation of data from monitoring systems typically involves
    looking for changes from the expected norms”, in Hawley and Cunning ( 2017). The
    challenge is then presented of what the “expected norm” appears as for each unique
    mine; what is acceptable, and what is not? Challenged by the lack of existing
    case studies at the mine, the approach is recommended to be generalised and conservative
    until a sufficient set of data is gathered and can inform the original estimates.
    There are three approaches that can be utilised to gain a better understanding
    of the “expected norm”, prior to gathering any data: Design analysis – modelling.
    Design analysis – back-analysis of past collapses; and Generic advice and regionally
    documented TARP levels. 4.1.1. Design analysis – modelling It is rare that a tailings
    dam will not have been appropriately planned and assessed using geotechnical software
    to theoretically indicate the safety and stability of the structure, prior to
    construction. Slope stability and seepage models are generated, with the structure
    modified in both short and long term cases to achieve an acceptable Factor of
    Safety or Probability of Failure. Depending on the software used, static or dynamic
    analysis can also be undertaken in undesirable scenarios to understand how the
    tailings dam will perform in extreme or adverse circumstances. For example, seismic
    analyses can be undertaken by applying a horizontal acceleration to the entire
    structure to ensure that the Factor of Safety remains above (typically) 1.1. The
    magnitude of horizontal acceleration is based on the seismicity of the region
    and applies in the short term, however, in sensitivity testing the seismic analysis:
    what is the magnitude of horizontal acceleration that sees the Factor of Safety
    drop below 1.1, or even below equilibrium? Should an anomalous event occur (anecdotally
    it is often the anomalous events, or a combination of these events, that precedes
    failure), what magnitude of seismicity triggers different actions? The modelling
    can inform this, in the first case. Similarly for simulation of slope instability
    and phreatic surface rise/fall: modelling can assess the rate of movement and
    the water level (including cases such as high water, gradual drawdown, and rapid
    drawdown), to inform actions that should be taken when slope and piezometer monitoring,
    respectively, reach these levels. In theory, a number of trigger levels can then
    be established based on design analysis to present a baseline estimate as presented
    in Figure 1. Figure 1. Baseline estimate of trigger levels as indicated by design
    analysis. Display full size 4.1.2. Design analysis – back-analysis of past failures/stable
    slopes In particular consideration of the unique site characteristics, but remembering
    that no two failures are ever the same, an assessment of past failures can be
    undertaken to understand behaviour and traits of potential failure. In some areas,
    the directly applicable monitoring data (such as slope deformation velocity) may
    not be available. However, collating related data such as survey prisms, visual
    observations of cracking/ bulging in different areas, and/ or anomalous seepage
    exiting the batter face are recommended to be collated to contribute to understanding
    of failure mechanisms. Further, any historical monitoring data that was collected
    for stable slopes and areas contributes to the “safe” envelope for failure mechanisms.
    By compiling data from different instruments alongside visual observations, a
    holistic view of the performance and behaviour of slopes, to the extent allowed
    by information available, can be determined. Considering that in the majority
    of cases, real-time monitoring is not yet available, it is anticipated that interpolation
    between the slope movement velocity values, for example, will be at a broad scale
    and relatively unreliable dependent on the frequency of readings (e.g. real-time
    monitoring trigger values compared against once-weekly survey pickups). However,
    there may be instances where for existing mines, a slope stability radar was brought
    in to monitor a critical slope: the data of such proving valuable in an understanding
    of the performance of the slope. A theoretical example of the back-analysis information
    compiled against the design analysis is presented in Figure 2. In this hypothetical
    scenario, and by combining visual observations with available data, it is observed
    that the piezometer TARP triggers are reasonable as they stand, however, opportunity
    exists to refine the slope movement velocity trigger. Where visual observations
    identify deterioration at a lower movement velocity, a more conservative yet reasonable
    approach would be to lower the Level 1 trigger (which often prompts inspection/
    a higher degree of monitoring in the area) to the level at which signs of deterioration
    were observed. This is appropriate as a starting point until a better understanding
    of behaviour can be ascertained. Figure 2. Baseline estimate of trigger levels
    as indicated by back-analysis. Display full size 4.1.3. Generic advice and regionally
    documented TARP levels When undertaking a risk assessment, the likelihood of occurrence
    is often informed by the probability of occurrence over a certain timeframe (e.g.
    “The event will probably occur in most circumstances”). This likelihood rating
    is supplemented by the experience of an appropriate cross-section of the workforce
    that are related to the task, where the probability of occurrence is informed
    by its actual occurrence in previous cases at the mine or elsewhere (e.g. asking
    the question “How many times have you seen this happen before?”). It is worthwhile
    considering regionally similar characteristics; although not directly representative,
    they can provide heightened understanding when compared against pure assumption/
    estimation. From this point, the unique characteristics of site can be compared
    against the regional, again refining the understanding of the risk and in turn
    improving the management and mitigation. It is recognised that some trigger levels
    will be site specific purely as a result of the design reliance, such as allowable
    piezometric levels or seepage flow rates. In these cases, the design analysis
    or back-analysis should be more heavily relied on. However, for other cases including
    but not limited to slope movement velocity, seismicity, foundation settlement,
    and water quality, the value of shared knowledge in the tailings community is
    reiterated. The broader sample space of case studies available improves the ability
    for the community to assess potential risks to their unique sites and learn from
    things that have gone well/ not so well in the past. The uniqueness of different
    sites is always acknowledged, albeit the opportunity to educate based on the experience
    of others (and to repay the favour) inevitably reduces the risk associated with
    experiencing an event onsite for the first time and either being unprepared or
    missing the indicators of failure entirely. The hypothetical is continued in Figure
    3, where a similar slope was documented and published to have experienced substantial
    deterioration at a slope movement velocity lower than that indicated by design
    analysis (8 mm/hr). Figure 3. Baseline estimate of trigger levels as indicated
    by regional documentation. Display full size 4.2. Integration between instruments
    There are two opportunities that exist for integration of instrumentation measurements.
    Firstly, by visually representing the measurements in a centralised system, the
    simplicity of design benefits the ability to understand and react to what the
    data is describing. Secondly, integrating cause-and-effect measurements can both
    improve the operator’s understanding and extract greater value from each individual
    instrument. 4.2.1. Centralised monitoring data For many tailings dam structures,
    the size and complexity of the monitoring system warrant consideration of an integrated
    geotechnical monitoring system. These systems enable (adapted from Hawley and
    Cunning ( 2017), GroundProbe ( 2019) and EHP Environment ( 2019)): Real-time data
    acquisition and processing of multiple instrumentation systems; The ability to
    issue alerts and alarms; Monitoring data can be stored in a central location and
    queried by authorised users at any time, from anywhere in the world; The saving
    and backup of measurement data on secured servers; Automatic operational control
    over monitoring stations; Increased monitoring programme reliability while reducing
    data acquisition and processing costs; Measurement and data transmission interval
    changes remotely; Current and historical data interpretation, allowing interaction
    of any data along with the timescale; and Customisable reports comparing data
    from different instrumentation types. With the tools available to digitise and
    streamline monitoring data, operators also have the ability to not only reduce
    the time taken to manage and interpret the data, but also increase the time allowed
    for critical analysis and understanding of the performance of their structure.
    4.2.2. Cause-and-effect instrumentation While there are limited published case
    studies at time of this research, it is theorised that using different instruments
    in conjunction with one another can aid in the whole-of-structure understanding,
    as opposed to looking at instruments in isolation. The rise and availability of
    centralised monitoring data systems present the opportunity to compare instrumentation
    in this respect to understand two- and three-dimensional behaviour with ease.
    A major contributor to this ease arises from direct analysis of automatically
    plotted data as opposed to sifting through columns of raw data. It is recommended
    that case studies are explored into the magnitude of relationships between different
    instrumentation, with such theories including, but not limited to: A change in
    piezometric levels has an influence on slope stability (batter and toe movement
    measurements, crest settlement); A change in piezometric levels has an influence
    on foundation settlement; Increased flow rate/ changed water quality suggests
    internal erosion activities upstream of the monitoring point; Seepage rate increases
    with an increase in reservoir level (particularly after first filling); Operational
    and environmental influence on different instrumentation, for example: Precipitation
    – phreatic surface and seepage flow rates; Excavation – slope stability; Tailings
    deposition rate – consolidation; Rate of rise – foundation settlement and slope
    stability; Other surrounding works/environmental influence; and/ or Foundation
    pore pressure on slope toe vertical displacement (heave/blowout). 3. Conclusion
    As with all technology and systems that see rapid development, the accessibility
    and cost of the solution improves in parallel. The appropriate next step for tailings
    dam monitoring is to minimise the need for laborious manual readouts of instrumentation,
    instead transitioning to an automated, real-time solution. This works for the
    betterment of cost, time and resource availability, which can instead be redirected
    to visual observations of the dam, interpretation of pre-generated data representations,
    and updating/activation of risk management plans. The technology is seen through
    the four primary components of the instrumentation system: sensor nodes (instruments
    and data logger), communication network between sensor nodes, base station with
    an external communication modem, and an information system for storing and displaying
    the data. For each component, there are multiple layers of solutions available
    to tailor to site specific needs, including protocols and topology related to
    optimal operational range, battery life, and system contingency, amongst others.
    It is not necessary for operators to understand the complexities of the systems
    to meticulous degrees; it can be argued that technology design focused on functionality,
    usability and user experience should be a priority in a field where rapid decision
    making and safety critical response is required. The value of this response in
    mitigating the consequence of failure was discussed. The monetary cost of recent
    failures, quantified in terms of their stock price, social impact (compensation),
    and environmental impact (remediation), were observed to be in the range of $750M
    to $56B, or otherwise contributing to eventual bankruptcy of the responsible organisation.
    For the case studies available, the instrumentation that was installed in the
    dam, retrofitted with a hypothetical real-time monitoring system saw systems worth
    approximately $400,000 to $500,000. The ability for a real-time monitoring system
    to provide sufficient warning to save lives, environmental damage, and reduce
    other consequential losses presents a defendable case for this investment. When
    looking to implement a real-time monitoring system, it is necessary to establish
    reliable targets to monitor performance against. Without previous data, this can
    be difficult, hence three methods are proposed as a preliminary option until further
    data and hence understanding can be gained. These include design analysis in the
    form of either modelling or back-analysis of past failures/stable slopes, or making
    reference to generic advice and regionally documented TARP levels. Opportunities
    also exist to extract more value from individual instruments, to full monitoring
    system integration. In relatively undocumented areas to date, but theorised to
    hold immense potential, centralising monitoring data and investigating the value
    of cause-and-effect instrumentation both take a holistic approach to the monitoring
    system. The two approaches seek to gain multiple benefits from a single instrument,
    multiplied again when considering a system of instruments, in turn improving the
    cost-benefit of the geotechnical monitoring system. By not only considering these
    elements, but also ensuring to document and share information throughout the learning
    and development process, the community of tailings dam practitioners can progress
    together toward a safer future. Disclosure statement No potential conflict of
    interest was reported by the author(s). References ABC. 2010. Toxic Sludge Victims
    Offered $7.6m. Accessed June 2, 2019. https://www.abc.net.au/news/2010-10-19/toxic-sludge-victims-offered-76m/2303678.  Google
    Scholar Al-Karaki, J. N., R. Ul-Mustafa, and A. E. Kamal. 2004. “Data Aggregation
    in Wireless Sensor Networks – Exact and Approximate Algorithms.” 2004 Workshop
    on High Performance Switching and Routing, 241–245. Phoenix, AZ: HPSR.  Google
    Scholar Amnesty International. 2017. A Breach of Human Rights: The Human Rights
    Impacts of the Mount Polley Mine Disaster. British Columbia. Accessed June 1,
    2019. https://www.amnesty.ca/news/breach-human-rights-human-rights-impact-mount-polley-mines-disaster-british-columbia.  Google
    Scholar ANCOLD. 1976. Guidelines for Dam Instrumentation and Monitoring Systems.
    Australian National Committee on Large Dams.  Google Scholar Avella, S. 1993.
    “An Analysis of a Worldwide Status for Monitoring and Analysis of Dam Deformation.”
    Masters thesis, University of New Brunswick.  Google Scholar Bowker, L. N., and
    D. M. Chambers. 2015. The Risk, Public Liability, & Economics of Tailings Storage
    Facility Failures. Accessed April 21, 2019. http://csp2.org/files/reports/Bowker%20%26%20Chambers%20-%20Risk-Public%20Liability-Economics%20of%20Tailings%20Storage%20Facility%20Failures%20%E2%80%93%2023Jul15.pdf.  Google
    Scholar Calleja, N. P. 2013. Philex Agrees to Pay in Full P1.034B Fine for Mine
    Spill. Accessed June 2, 2019. https://business.inquirer.net/107843/philex-agrees-to-pay-in-full-p1-3-b-fine-for-mine-spill.  Google
    Scholar The Catholic Bishops Conference of the Philippines – National Secretariat
    for Social Action, Justice and Peace [CBCP-NASSA], Climate Change Congress of
    the Philippines [CCCP], Philippine Misereor Partnership Inc. [PMPI] and it Northern
    Luzon Cluster, Peace Foundation, Inc., Pambansang Kaisahan ng mga Magbubukid ng
    Pilipinas [PKMP], Katribu Ingigenous Peoples’ Partylist, Cordillera Peopels Alliance
    [CPA], Caritas Baguio, Community Volunteer Missioners [CVM]. 2012. The Philex
    Mine Tailings Spill of 2012: An Independent Fact-Finding Mission Report. Accessed
    June 1, 2019. https://file.ejatlas.org/docs/ATM_cFinal_FFM_Philex_Report_2Oct_2012FINAL_REPORT.pdf.  Google
    Scholar Clarkson, L., and D. Williams. 2019. “Critical Review of Tailings Dam
    Monitoring Best Practice.” International Journal of Mining, Reclamation and Environment.
    doi:10.1080/17480930.2019.1625172.  Web of Science ®Google Scholar Cleary Gottlieb
    Steen & Hamilton LLP, Vale S.A., BHP Billiton Brasil Ltda. & Samarco Mineração
    S.A. 2016. The Fundão Tailings Dam Investigation. Appendix E – Samarco Field Monitoring
    Data.  Google Scholar Davies, M., and T. Martin. 2009. “Mining Market Cycles and
    Tailings Dam Incidents.” Proceedings of the 13th International Conference on Tailings
    and Mine Waste, Banff, Alberta.  Google Scholar Davies, M., D. Martin, and P.
    Lighthall. 2000. Mine Tailings Dams – When Things Go Wrong [Internet]. https://www.researchgate.net/publication/237818800_MINE_TAILINGS_DAMS_HEN_THINGS_GO_WRONG.  Google
    Scholar EHP Environment. 2019. EHP-Dataservice. Accessed June 17, 2019. https://www.ehpenvironment.com/en/dataservice/.  Google
    Scholar Fell, R., P. MacGregor, D. Stapledon, G. Bell, and M. Foster. 2015. Geotechnical
    Engineering of Dams. 2nd ed. CRC Press/Balkema. Leiden, Netherlands.  Google Scholar
    GroundProbe. 2019. Geoexplorer. Accessed June 17, 2019. https://www.groundprobe.com/product/geoexplorer/.  Google
    Scholar Hawley, M., and J. Cunning. 2017. Guidelines for Mine Waste Dump and Stockpile
    Design. Australia: CSIRO Publishing. Clayton, Victoria.  Google Scholar Hui, S.,
    L. Charlebois, and C. Sun. 2017. “Real-time Monitoring for Structural Health,
    Public Safety, and Risk Management of Mine Tailings Dams.” Canadian Journal of
    Earth Sciences 55 (3): 221–229. doi: 10.1139/cjes-2017-0186  Web of Science ®Google
    Scholar Klohn Crippen Berger (KCB). 2018. Static Liquefaction and Strength Loss
    in Tailings Dams. Accessed November 30, 2019. https://www.klohn.com/blog/static-liquefaction-strength-loss-tailings-dams/.  Google
    Scholar Marr, W. A. 2014. “Geotechnical Instrumentation and Monitoring.” Presented
    at the Iowa Section of ASCE and SEDC Geotechnical Conference, Iowa, April 10.  Google
    Scholar McGrath, M. J., and C. N. Scanaill. 2013. “Sensor Network Topologies and
    Design Considerations.” In Sensor Technologies, edited by M. J. McGrath, C. N.
    Scanaill, and D Nafus, 79–95. Berkeley, CA: Apress.  Google Scholar Province of
    British Columbia. 2019. Report on Mount Polley Tailings Storage Facility Breach,
    Appendix F – Instrumentation and Monitoring.  Google Scholar Robinson, R. 2009.
    Karamken Dam Break Information. Accessed June 2, 2019. http://www.sric.org/enr/docs/2009-09-07_KaramkenDamBreak.pdf.  Google
    Scholar Roche, C., K. Thygesen, and E. Baker. 2017. Mine Tailings Storage: Safety
    is No Accident. A Rapid Response Assessment.. UN Environment, GRID-Arendal. Nairobi
    and Arendal.  Google Scholar Samarco. n.d. “Samarco.” Accessed May 18, 2019. https://www.samarco.com/en/a-samarco/.  Google
    Scholar Tang, C. S. C., and S. P. Y. Cheung. 2011. Review of Real-time Data Transmission
    Systems for Slope Instrumentation. GEO Report No. 262. Geotechnical Engineering
    Office, The Government of the Hong Kong Special Administrative Region.  Google
    Scholar WISE Uranium Project. 2014. The Kolontár Red Mud Dam Failure (Hungary).
    Accessed June 2, 2019. http://www.wise-uranium.org/mdafko.html.  Google Scholar
    WISE Uranium Project. 2018. The Mount Polley Tailings Dam Failure (Canada). Accessed
    June 1, 2019. http://www.wise-uranium.org/mdafmp.html?_sm_au_=iVVZT1n0kS71QHTH.  Google
    Scholar WISE Uranium Project. 2019. Chronology of Major Tailings Dam Failures.
    Accessed June 2, 2019. http://www.wise-uranium.org/mdaf.html.  Google Scholar
    YLE. 2012. Talvivaara Waste Water Leaks into Environment. Accessed June 1, 2019.
    https://yle.fi/uutiset/osasto/news/talvivaara_waste_water_leaks_into_environment/6363459.  Google
    Scholar Download PDF X Facebook LinkedIn Email Share   Related research  People
    also read Recommended articles Cited by 6 Critical review of tailings dam monitoring
    best practice Luke Clarkson et al. International Journal of Mining, Reclamation
    and Environment Published online: 17 Jun 2019 Catalogue of real-time instrumentation
    and monitoring techniques for tailings dams Luke Clarkson et al. Mining Technology
    Published online: 23 Jan 2021 Catalogue of example instrumentation and monitoring
    systems for tailings dams in Australia Luke Clarkson et al. Mining Technology
    Published online: 22 Mar 2021 View more Information for Authors R&D professionals
    Editors Librarians Societies Open access Overview Open journals Open Select Dove
    Medical Press F1000Research Opportunities Reprints and e-prints Advertising solutions
    Accelerated publication Corporate access solutions Help and information Help and
    contact Newsroom All journals Books Keep up to date Register to receive personalised
    research and resources by email Sign me up Copyright © 2024 Informa UK Limited
    Privacy policy Cookies Terms & conditions Accessibility Registered in England
    & Wales No. 3099067 5 Howick Place | London | SW1P 1WG     Cookies Button About
    Cookies On This Site We and our partners use cookies to enhance your website experience,
    learn how our site is used, offer personalised features, measure the effectiveness
    of our services, and tailor content and ads to your interests while you navigate
    on the web or interact with us across devices. By clicking \"Continue\" or continuing
    to browse our site you are agreeing to our and our partners use of cookies. For
    more information seePrivacy Policy CONTINUE"'
  inline_citation: '>'
  journal: Georisk
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Real-time monitoring of tailings dams
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Li H.
  - Pei L.
  - Liao D.
  - Zhang M.
  - Xu D.
  - Wang X.
  citation_count: '4'
  description: 'Crowdsourcing application, deemed as a key evolution on the way to
    vehicular networking, has great potential to provide real-time services. However,
    existing cloud-based vehicular networking cannot support real-time data transmission
    with wasting massive bandwidth resources. This paper studies the crowdsourcing
    application in edge-assistant vehicular networking. To improve the real-time demand
    of data transmission, we propose the E-node of that owns the learning and semantic
    analysis abilities. Then we analyze two data transmission scenarios of crowdsourcing
    for collected data: road map uploading, traffic accident and traffic flow. On
    the other hand, to address the privacy leakages in the process of data aggregation
    and data distribution, we separately design time-tolerance anonymous privacy protection
    algorithm and k − 1 location-offset privacy protection algorithm. Finally, we
    conduct extensive experiments to verify the effectiveness of our proposed privacy
    protection algorithms, including time delay, offset probability, privacy leakage
    probability and accuracy.'
  doi: 10.1007/s11235-020-00666-w
  full_citation: '>'
  full_text: '>

    "Your privacy, your choice We use essential cookies to make sure the site can
    function. We also use optional cookies for advertising, personalisation of content,
    usage analysis, and social media. By accepting optional cookies, you consent to
    the processing of your personal data - including transfers to third parties. Some
    third parties are outside of the European Economic Area, with varying standards
    of data protection. See our privacy policy for more information on the use of
    your personal data. Manage preferences for further information and to change your
    choices. Accept all cookies Skip to main content Log in Find a journal Publish
    with us Track your research Search Cart Home Telecommunication Systems Article
    Achieving privacy protection for crowdsourcing application in edge-assistant vehicular
    networking Published: 08 May 2020 Volume 75, pages 1–14, (2020) Cite this article
    Download PDF Access provided by University of Nebraska-Lincoln Telecommunication
    Systems Aims and scope Submit manuscript Hui Li, Lishuang Pei, Dan Liao, Ming
    Zhang , Du Xu & Xiong Wang  330 Accesses 3 Citations Explore all metrics Abstract
    Crowdsourcing application, deemed as a key evolution on the way to vehicular networking,
    has great potential to provide real-time services. However, existing cloud-based
    vehicular networking cannot support real-time data transmission with wasting massive
    bandwidth resources. This paper studies the crowdsourcing application in edge-assistant
    vehicular networking. To improve the real-time demand of data transmission, we
    propose the E-node of that owns the learning and semantic analysis abilities.
    Then we analyze two data transmission scenarios of crowdsourcing for collected
    data: road map uploading, traffic accident and traffic flow. On the other hand,
    to address the privacy leakages in the process of data aggregation and data distribution,
    we separately design time-tolerance anonymous privacy protection algorithm and
    k − 1 location-offset privacy protection algorithm. Finally, we conduct extensive
    experiments to verify the effectiveness of our proposed privacy protection algorithms,
    including time delay, offset probability, privacy leakage probability and accuracy.
    Similar content being viewed by others Privacy-friendly spatial crowdsourcing
    in vehicular networks Article 01 June 2017 A Survey on Service Migration Strategies
    for Vehicular Edge Computing Chapter © 2022 Privacy-Aware Service Migration for
    Edge Computing in Urban Cities Chapter © 2019 1 Introduction Connected vehicles
    are typically equipped with smart devices such as high-definition cameras, traffic
    recorders, communications devices and other sensors to provide driving safety
    and reduce crashes [1]. In recent years, with the continuous increase of connected
    vehicles [2], crowdsourcing application [3, 4] of vehicular networking is rising.
    In crowdsourcing application, vehicles actively collect traffic or safety data,
    such as road map updating, traffic accident and vehicle congestion. It is different
    from the traditional collection method. The traditional collection method may
    require specialized equipment and personnel to do these tedious collection tasks,
    spending a lot of manpower, material and financial resources. Moreover, in terms
    of timeliness, crowdsourcing application can provide more real-time services than
    traditional collection method. The vehicular environment is complex and changeable.
    For example, the road map may be updating due to road repair, or traffic accidents
    may occur due to driver errors. Therefore, there exists a certain delay in collecting
    data by traditional collection method. However, by using crowdsourcing, vehicles
    can collect these sudden changes of traffic data at anytime and anywhere. Nowadays,
    crowdsourcing has extensive application prospect in vehicular networking. However,
    it relies on the real-time data collection between large amounts of vehicles.
    While the collected data carrier is usually high-resolution image from connected
    vehicle [5], which takes up a lot of bandwidth [6]. If the existing cloud-based
    vehicular networking [7, 8] (as shown in Fig. 1a) is used for data transmission,
    a lot of valuable wireless bandwidth resources are consumed, and the real-time
    performance of data transmission cannot be guaranteed. Because the collected data
    is transmitted to the cloud servers of core network through the RSUs, base stations
    and switches. After data is processed in cloud servers, the data needs to be returned
    in the original way (also pass through the switches, base stations and RSUs),
    and finally is sent to vehicles. This results all data going through a long link
    to the remote cloud servers, which wastes bandwidth resources and leads to a large
    time delay. Fortunately, the concept of edge-assistant vehicular networking [9]
    is introduced to solve the problems of real-time transmission and resource saving.
    The architecture of edge-assistant vehicular networking is shown in Fig. 1b. Fig.
    1 Cloud-based versus edge-assistant vehicular networking Full size image Compared
    with the cloud-based vehicular networking architecture, the edge-assistant vehicular
    networking architecture has one more edge layer, which is between the cloud layer
    and vehicles. But the edge layer is closer to the vehicle side than cloud layer.
    For convenience, RSUs or base stations are typically deployed as edge nodes [10].
    The edge nodes have much more computing and storage power than traditional RSUs
    or base stations. Therefore, the edge node has certain data preprocessing capability,
    in addition to the basic functions of data storage and forwarding. The preprocessing
    capability accelerates the process of data transmission. In edge-assistant vehicular
    networking, the computation-intensive/time-intensive tasks [11] are relegated
    to the edge layer, so that large number of simple and tedious data processing
    tasks can be completed directly at edge nodes and no longer rely on the remote
    servers (in the cloud). Therefore, large amounts of data do not need to be transmitted
    to the remote serves. It ensures the real-time of data processing, and reduces
    the load of link bandwidth. In this paper, the crowdsourcing application is applied
    in the edge-assistant vehicular networking architecture. We employ crowdsourcing
    to collect three kinds of data: road map updating, traffic accident and traffic
    flow. Considering the direction transmission of collected data, we analyze two
    scenarios of data transmission for crowdsourcing application: data aggregation
    and data distribution. Then, to further improve the real-time demand of data transmission,
    we enhance the edge node, called E-node. The E-node is endowed with learning ability
    and semantic analysis function. It is used to handle the distribution and aggregation
    of collected data. However, the E-node is honest-but-curious in reality. There
    exists location privacy disclosure in data transmission. When collected data is
    uploaded to E-node for data aggregation, the location information must be included
    so that the collected data is valuable. The location information is very likely
    the position of vehicle that has been passed. Therefore, the E-node can guess
    that the vehicle once appeared at a certain position by analyzing the location
    information. In the process of data distribution, when a vehicle is interested
    in the data of that happened at a particular location (where the vehicle may arrive
    in future), the vehicle will request the data from E-node. Then, the E-node can
    guess where the vehicle is going. If the E-node is compromised to malicious attacker
    and revealing the location privacy of vehicle, it can lead to serious consequences,
    such as threats to the property and life of driver. It also discourages more users
    from participating in crowdsourcing applications. To solve the threat of privacy
    disclosure, this paper respectively designs privacy protection mechanisms in the
    process of data aggregation and data distribution. Therefore, our goal is to address
    the problems of efficiency and privacy protection in data transmission, further
    promoting the crowdsourcing application of vehicular networking. The main contributions
    of this paper are as follows: To improve the real-time demand of data transmission,
    we propose the E-node of that owns the learning and semantic analysis abilities.
    Applied E-node in crowdsourcing application of edge-assistant vehicular networking,
    we analyze two data transmission scenarios for three collected data: road map
    uploading, traffic accident and traffic flow. We analyze the privacy leakages
    in the process of data aggregation and data distribution, and propose privacy
    attack models respectively. For data aggregation, we design the time-tolerance
    anonymous (TTA) privacy protection algorithm to protect vehicular location privacy.
    For data distribution, we design k − 1 location-offset (KLO) privacy protection
    algorithm. The rest of this paper is organized as follows. Firstly, we review
    related works in Sect. 2. Then we design the E-node and analyze two data transmission
    scenarios in crowdsourcing application in Sect. 3. Section 4 shows the privacy
    attack models for data transmission. Section 5 gives the detailed description
    of privacy protection algorithms. The simulation environment and results are given
    in Sect. 6. Finally, we conclude the paper in Sect. 7. 2 Related work In this
    section, we present some existing works about edge computing and crowdsourcing
    application in vehicular networking. 2.1 Edge computing in vehicular networking
    With the continuous increase of connected vehicles, the amount of collected data
    is also increasing [12, 13]. This leads to the challenges of cloud-based vehicular
    networking architecture, such as latency, bandwidth costs, security and privacy.
    Thus, edge computing has emerged in the vehicular networking [14, 15] in recent
    years, and edge-assistant vehicular networking architecture is proposed. Edge
    computing enables data to be processed near the vehicle, reducing the need to
    transfer data back and forth between vehicles and cloud servers. Thus, the edge
    computing is undoubtedly a good solution to solve the time delay problem. In addition,
    edge nodes are generally distributed in RSUs or other access points [16]. This
    allows data to be distributed processing, and further exploits the advantages
    of edge computing. Thus, to meet the low latency and resource optimization, massive
    researchers have devoted themselves to applying edge computing in vehicular networking.
    In [17], combing the software-defined network (SDN) [18] with edge computing,
    the authors addressed the problem of VANET V2V offloading. A vehicular edge computing
    (VEC) system was proposed in literature [19]. Then the authors optimized the computing
    and communication resources in VEC system. The work in [20] considered the vehicle
    environment of that includes multi-edge computing nodes. Then the cost of video
    streaming providers (VSP) was optimized by a cost-effective resource sharing scheme
    in mobile edge computing environment. However, the above works only applied the
    edge computing in vehicular networking. Then they studied other problems (e.g.
    resources) in edge-assistant vehicular networking. Nevertheless, the research
    on the edge nodes in the edge-assistant vehicular networking was relatively simple.
    How to the edge nodes process data in combination with actual traffic business
    is required. Therefore, this paper designs the enhanced edge node with the ability
    to mark and learn the collected data, so as to quickly deal with various business
    service requirements in vehicular networking. 2.2 Crowdsourcing application As
    the emerging crowdsourcing can find possible solutions to problems by gathering
    opinions and information from the crowd (e.g. usually people, objects or entities
    on an individual level) [21], crowdsourcing has been received extensive attentions
    from vehicular networking [22, 23]. In crowdsourcing application of vehicular
    networking, the crowdsourced data are collected by vehicles, including road conditions,
    congestion, traffic accident and so on. These crowdsourced data can be utilized
    for decision-making, improving traffic intelligence and safety. For example, in
    paper [24], using the crowdsourced positioning data obtained from GPS of smartphones
    on vehicles, users could track their desired vehicle. The crowdsourcing was used
    to detect environmental road features (e.g., potholes on multi-lane roads) in
    [25]. To improve the transport safety, Gurdit [26] employed the crowdsourcing
    technique to realize the road surface monitoring with better accuracy. Using the
    crowdsourced big trace data, the authors in [27] generated the lane-based intersection
    maps automatically. From the above crowdsourcing application in vehicular networking,
    we can see that the crowdsourcing involves the voluntary principle of large number
    of vehicle users, and then the crowdsourced data can be collected in large numbers.
    However, the existing crowdsourcing application of vehicular networking pays little
    attention to the issue of privacy leakage. Only by protecting the privacy of vehicle
    users can the further development of crowdsourcing application be better promoted.
    2.3 Privacy preserving Much efforts about privacy preserving have been directed
    towards vehicular networking. Some existing literature researches [28] deployed
    the privacy protection mechanisms in edge nodes. Vehicle must send real location
    information to edge node so that the edge node can implement the location privacy
    protection. However, we cannot guarantee that the edge nodes are completely reliable.
    Therefore, in crowdsourcing application, it is not advisable to directly deploy
    the privacy protection mechanism to edge node. Nowadays, some researches have
    considered that the edge node is honest but curious. They have explored the way
    of pseudonyms for vehicle crowdsensing by using the fog/edge computing technology.
    For example, Wei et al. [29] proposed a privacy-preserving fog-based protocol.
    The protocol realized the properties, including mutual authentication, strong
    user anonymity, forward privacy, de-synchronization resilience and non-deniability.
    In [30], the authors designed a privacy preserving reputation management scheme.
    It could not exposing exact values while effectively handling malicious participants.
    Through considering synthetically with information confidentiality, mutual authenticity,
    integrity, privacy, and anonymity, the authors in [31] enhanced security in data
    transmission of vehicular crowdsensing-based road surface condition monitoring
    system. Li et al. [32] addressed the security threats in fog-assisted vehicular
    crowdsensing system. The security aspects included driver authentication, data
    confidentiality, driver anonymity, traceability and false report filtering. However,
    these existing privacy preserving schemes focus on the identity privacy of drivers.
    For the collected data in vehicular crowdsourcing application, the location privacy
    is also very important. Therefore, this paper analyzes the possible leakage of
    location privacy in data collection and data distribution of crowdsourcing application,
    and designs privacy protection algorithms. 3 Enhanced edge node for data transmission
    To improve real-time demand of data transmission, this section first describes
    E-node in detail. Then, by using E-node, we analyzes two data transmission scenarios
    in crowdsourcing application of vehicular networking. The Table 1 shows the involved
    symbols in this paper. Table 1 Notations table Full size table 3.1 E-node As we
    all known, the use of edge node to participate in data transmission of vehicular
    networks has been accepted by various existing researches [33]. In this paper,
    to guarantee the real-time demand of data transmission in crowdsourcing, we have
    enhanced the edge node, called E-node. E-node is an upgrade from an RSU or base
    station. In addition to the basic abilities of storage and forwarding, E-node
    has some extended abilities of computing, semantic analysis and learning. By tagging
    data types or location information, the E-node can quickly process and forward
    collected data. Since storage and forwarding are the basic capabilities of E-node,
    this paper does not explain the storage and forwarding capabilities, but only
    the computing, semantic analysis and learning capabilities. 3.1.1 Computing In
    this paper, the E-node has certain computing ability for processing computation-intensive/time-intensive
    tasks that do not to be uploaded to the remote cloud servers. This solves the
    problem of low latency. 3.1.2 Semantic analysis As shown in Fig. 2, there exists
    some points of interest (POIs) in the coverage of each E-node. The coverage is
    represented by S. These POIs are generally the locations where vehicles like to
    collect or request data. For example, when an E-node receives the collected data,
    it first analyzes that which POI the collected data belongs to. Then the collected
    data is stored in different spaces according to the POI locations: POI \\( \\in
    \\)S and POI \\( \\notin \\)S. Second, depending on the type of collected data,
    the data is refined again and stored by category: {D1 = road map updating, D2 = traffic
    accident, D3 = traffic flow}. Fig. 2 The E-node Full size image Thus, the E-node
    conducts semantic analysis basing on the POI information and the type of collected
    data. This facilitates the fast retrieval, processing and forwarding for collected
    data. 3.1.3 Learning By semantic analysis, we can know that there are two types
    for the POI of collected data: POI \\( \\in \\)S and POI \\( \\notin \\)S in an
    E-node. For the collected data in POI \\( \\in \\)S, the E-node stores collected
    data by category. However, for the collected data in POI \\( \\notin \\)S, the
    E-node first learns the POI request frequency. Then the E-node stores the data
    of that has high POI request frequency. Of course, the E-node needs to forward
    the collected data (in POIs \\( \\notin \\)S) to another corresponding E-node.
    By continuous learning of POI request frequency, the feedback time of collected
    data can be greatly accelerated. For example, assume that the collected data is
    in an E-node1 (the coverage is S1). However, the collected data happens in POI2,
    and the POI2 belongs to another E-node2 (the coverage is S2). That is, POI2\\(
    \\notin \\) S1 and POI2\\( \\in \\) S2. If the POI2 request frequency is very
    high in E-node1, it means that many vehicles request the collected data about
    POI2 when they enter in coverage S1. Assume that E-node has no learning ability.
    Then the E-node1 does not store the collected data of POI2. Therefore, each time
    a request is made for POI2, E-node1 first requests data from E-node2, and then
    feeds back to vehicle. This leads to a lot of time spent doing the simple and
    tedious request-tasks. However, this paper endows E-node with learning ability.
    Then E-node1 can record the request frequency of POI2 and finds that POI2 request
    frequency is very high. Thus, E-node1 stores and updates the collected data of
    POI2 in advance. Once a vehicle requests the collected data of POI2, it directly
    feeds back to vehicle, which greatly reduces the response time. 3.2 Data transmission
    in crowdsourcing When a vehicle executes a driving path, the driver thinks most
    about whether the driving path is unobstructed and safe. Therefore, this paper
    considers these three kinds of collected data (D1, D2, and D3) as crowdsourced
    data for crowdsourcing application in edge-assistant vehicular networking. Moreover,
    these three kinds of collected data have the highest incidence in vehicular networking.
    3.2.1 Road map updating (D1) The road environment where vehicles are driving is
    very complex. For example, because of road maintenance, the road is not allowed
    to pass or the road driving direction changes (such as previously two-way driving,
    now only one-way driving). And the traffic signs on the road may be changed because
    of traffic control, so that at some intersections which are allowed to turn left
    can’t turn left now. Therefore, a variety of unexpected factors lead to the changes
    of road map. If the road map is not updating in time, it will bring trouble to
    the vehicle in the navigation route and seriously affect user’s driving experience.
    Therefore, we need to adopt crowdsourcing application to collect such data as
    road map updating. 3.2.2 Traffic accident (D2) Due to the large number of vehicles,
    the traffic accident rate of vehicles is very high. Once there is a traffic accident,
    the most direct impact is to bring traffic congestion, making the traffic inconvenience.
    To avoid the expansion of the scope of traffic congestion, it is necessary to
    inform other vehicles to change the route and try to avoid driving on the road
    where the traffic accident occurs. Therefore, it is necessary to collect the data
    of traffic accident by adopting crowdsourcing application. 3.2.3 Traffic flow
    (D3) Traffic flow is an important data in traffic management. For example, we
    can manage the interval time of traffic lights according to the traffic flow at
    different time points. In addition, by knowing the information of traffic flow,
    vehicles can effectively plan their routes and avoid congestion in advance. Therefore,
    this paper collects the data of traffic flow. According to user tolerance for
    time delay of receiving different data, these three kinds of collected data have
    different time tolerance levels, as shown in Table 2. T is the maximum time tolerance
    of user experience. Here, σ1, σ2 and σ3 are the tolerance coefficients for these
    three kinds of collected data respectively. The relationship between the tolerance
    coefficients is as follows. Table 2 Time tolerance for collected data Full size
    table $$ 1 > \\sigma_{1} > \\sigma_{2} > \\sigma_{3} > 0 $$ Based on the above
    characteristics of collected data, we analyze two data transmission scenarios
    between vehicles and E-nodes: data aggregation and data distribution. A. Data
    aggregation The process of data aggregation between the vehicles and E-nodes is
    shown in Fig. 3. For an E-node, data aggregation comes from two aspects: one is
    the data uploaded by vehicles; the other is the data transmitted from other E-nodes.
    In crowdsourcing application, each vehicle is equipped with multiple intelligent
    devices, such as high-definition cameras, sensors, or driving data recorders.
    When a vehicle enters in a coverage Si of E-nodei, the vehicle collects data using
    intelligent devices. According to the time tolerance of collected data, the vehicle
    uploads the collected data at time t (0 < t < σiT). Fig. 3 Data aggregation Full
    size image However, in time t, vehicle may be out of the coverage Si and enter
    in another coverage Sj of E-nodej. Then, the vehicle uploads the collected data
    that happened in coverage Si to the E-nodej. And the E-nodej forwards the collected
    data to E-nodei. Thus, for an E-node, the collected data may be not happened in
    itself coverage. In a word, data aggregation of E-node comes from two aspects.
    When the collected data is gathered at E-node, E-node needs to conduct fusion
    processing according to the attributes (e.g. location, type) of collected data.
    B. Data distribution In this paper, we consider the scenario of data distribution,
    where E-node distributes collected data to vehicles, as shown in Fig. 3. We divide
    the data distribution into two categories: the periodic active distribution (as
    described in black lines) and required active distribution (as described in red
    lines). 3.2.4 Periodic active distribution When a vehicle enters a coverage S
    of an E-node, it has the right to know the traffic information of S, including
    whether the road map has been updated, whether there is a traffic accident, and
    how the traffic flow is. Therefore, the E-node needs to periodically broadcast
    the collected data that happened in coverage S. In addition, according to user
    own requirements, the vehicle can selectively receive the data that user wants,
    but not all the data is received. 3.2.5 Required active distribution According
    to the destination of driving path, vehicle generally wants to know the traffic
    condition of driving path in advance, such as whether it is crowded or not. Thus,
    the vehicle will request the traffic situation for a future location according
    to its own demand. For example, as shown in Fig. 4, when a target vehicle (the
    red vehicle) enters a coverage S1 of E-node1, the driver cares about the traffic
    condition of the location l that he/she will arrive at a certain time in future.
    And the location l is not in the coverage S1 of E-node1, but in another coverage
    S2 of E-node2. Thus, if the E-node1 has the collected data of location l, it directly
    sends the collected data to vehicle. Otherwise, it requests the collected data
    of location l from E-node2 and then forwards to vehicle. Fig. 4 Data distribution
    Full size image The difference between periodic active distribution and required
    active distribution is: the periodic active distribution is a kind of behavior
    that E-node must send collected data, and its behavior is periodic. While the
    required active distribution is the behavior of collected data sent by E-node
    according to user needs. 4 Privacy attack model In edge-assistant vehicular networking,
    the E-node is assumed to be honest-but-curious. It may be interested in collecting
    vehicular privacy, such as location privacy or identity privacy. Therefore, this
    section analyzes the issue of privacy disclosure for the data transmission (data
    aggregation and data distribution) in crowdsourcing. 4.1 Data aggregation attack
    model Vehicle needs to upload collected data to E-node for data aggregation. These
    collected data are mainly about road map updating (road repair, traffic jam, traffic
    light change, etc.), traffic accident and traffic flow. The collected data must
    contain the location of its occurrence. If the specific location of collected
    data is not informed, the collected data is worthless for users. However, when
    a vehicle uploads the collected data, it’s natural to assume that the vehicle
    is in the right location for the collected data to happen. Therefore, directly
    uploading collected data reveals the location of vehicles. For example, a vehicle
    U is located at location li. And a traffic accident has been occurred at location
    li. Then the vehicle U collects and uploads the data Msg(li) to E-node. If the
    location li is sensitive to the vehicle U, the location privacy of vehicle is
    violated. However, no matter where or when, as long as vehicle U uploads Msg(li),
    we can consider that the vehicle U once appeared in location li. It makes no sense
    to protect where collected data happens. Therefore, our goal is to prevent the
    E-node from knowing exactly where vehicle is, but not the location of collected
    data. 4.2 Data distribution attack model From the process of periodic active distribution
    in Sect. 3.2, we can get that no location or identity information is involved.
    Therefore, the periodic active distribution does not bring privacy leakage. However,
    the process of required active distribution may result in location privacy disclosure.
    For the required active distribution, the vehicle explicitly requests the data
    of a certain location form E-node. Moreover, the location of requested data and
    vehicle location are not covered by the same E-node. For example, a vehicle is
    in the coverage Si of E-nodei. But the vehicle wants to request the collected
    data Msg(lj) that has happened in location lj. The location lj is in the coverage
    area Sj of E-nodej. If no protection measures are taken, the E-nodei takes it
    for granted that the vehicle will appear at location lj in the future. Thus, vehicular
    location can be inferred and the location privacy is leaked. For protecting the
    location privacy in the process of required active distribution, we hide the request
    location in multiple POIs. 5 Algorithm design To thwart the location privacy threats
    mentioned above, we design the TTA privacy protection algorithm for data aggregation
    attack, and KLO privacy protection algorithm for required active distribution
    in this section. 5.1 Time tolerance-anonymous privacy protection algorithm To
    protect location privacy in the process of data aggregation, we design a novel
    algorithm. It is called as TTA algorithm, as shown in Algorithm 1. When a target
    vehicle U collects a data Msg(l0) that is happened in location l0, TTA algorithm
    takes two major measures to cut off the relationship between vehicle identity
    VID and location l0. The vehicle U does not immediately upload the collected data
    Msg(l0) to E-node. Instead, it determines the time tolerance of Msg(l0). Within
    the time tolerance σiT, Msg(l0) is uploaded to E-node. The collected data Msg(l0)
    is not uploaded by the vehicular identity VID, but by a group identity GID anonymously.
    Therefore, how to generate a vehicular group and obtain group identity GID is
    the key point for our TTA algorithm. First, within the time σiT, we record all
    the vehicles that passed the location l0 and get a vehicular set {u1, u2, u3,
    …, um}. In means that m vehicles have passed the location l0. As shown in Fig.
    5, the red vehicle represents the target vehicle U, and the green vehicles represent
    other vehicles passing through the location l0. Then we initialize the vehicular
    group G′ = {u1, u2, u3, …, um}. In this paper, we set the anonymous degree of
    vehicle privacy protection as p. Thus, the initial group G′ will be updated to
    the final group G. The final group G has p vehicles. Of course, the target vehicle
    U must be included in final group G. In this way, vehicle U is hidden in group
    G. If anonymous degree p is large, it indicates a good hiding effect of vehicle
    U. The size of p is set according to the user requirements for privacy protection.
    Fig. 5 Generate vehicular group Full size image If the number of vehicles in the
    initial group G′ is larger than p (that is, m ≥ p), TTA algorithm randomly selects
    p vehicles from the initial group G′, including the target vehicle U. Then we
    get to the final group G = {u1, u2, u3, …, up}. Otherwise (when m < p), the TTA
    algorithm needs to select other p–m vehicles and adds them into the initial group
    G′. How to select these p–m vehicles? First, we construct a region A centered
    on l0 and σiTv as a radius, as shown the red circle in Fig. 5. The v is the common
    average speed of vehicle. Theoretically, a vehicle does not move out of the range
    A in time σiT. This way can reduce attacker to eliminate some impossible vehicles
    and make the probability of guessing the target vehicle is 1/p. Assume that the
    location l0 is in the coverage S1 of an E-node1. Thus, TTA algorithm selects these
    p–m vehicles (recorded as {u1′, u2′, u3′, …, up–m′}) from the region R = S1 ∩
    A(l0, σiTv). Moreover, these p–m vehicles do not belong to the initial group G′.
    As shown in Fig. 5, the yellow vehicles represent these p–m vehicles. Then we
    add these p–m vehicles into the initial group G′ and get the final group G. We
    generate a group identity GID for the group G. $$ G = \\left\\{ {\\begin{array}{*{20}l}
    {\\{ u_{1} ,u_{2} , \\ldots ,u_{p} \\} } \\hfill & {m \\ge p} \\hfill \\\\ {\\{
    u_{1} ,u_{2} , \\ldots ,u_{m} ,u_{1} '',u_{2} '', \\ldots ,u_{p - m} ''\\} } \\hfill
    & {m < p} \\hfill \\\\ \\end{array} } \\right. $$ (1) Who uploads the data Msg(l0)
    by using group identity GID? In this paper, TTA algorithm randomly selects a vehicle
    as a leader from group G. Due to randomness, the leader is not necessarily the
    target vehicle U. Moreover, there are two kinds of locations for the selected
    leader. The location of leader and location l0 are in the same coverage area S1
    of E-node1. As shown the solid arrow in Fig. 5, the leader directly uploads Msg(l0)
    to E-node1. The location of leader and location l0 are in different coverage areas.
    Here, the location l0 belongs to the S1 of E-node1, while the leader is in the
    Si of E-nodei. As shown the dotted arrow in Fig. 5, the leader first uploads the
    collected data Msg(l0) to E-nodei. After receiving Msg(l0), E-nodei resolves the
    location l0 from Msg(l0) and the POIl0 which l0 belongs to. According to the request
    probability of POIl0, E-nodei chooses whether to store the collected data Msg(l0).
    Final, Msg(l0) is forwarded to E-node1. Algorithm 1 describes the pseudo code
    of TTA algorithm. 5.2 K − 1 location-offset privacy protection algorithm To protect
    vehicular request location lr in the process of required active distribution,
    we proposed KLO algorithm. The main idea of KLO algorithm is that the target vehicle
    U does not directly request the collected data Msg(lr) of location lr from E-node.
    It blurs the location lr in the corresponding POI, called as POIlr. Then the KLO
    algorithm selects other k − 1 POIs, which have the same or similar offset probability
    with POIlr. Thus, vehicle U requests k collected data {Msg(POIlr), Msg(POI1),
    Msg(POI2), …, Msg(POIk−1)} from E-node. These k collected data have the same request
    content but different locations. In this way, the E-node cannot guess the true
    request location lr of vehicle. Therefore, how to select other k − 1 POIs is the
    key point for KLO algorithm. Assume that there are Q POIs ({POIlr, POI1, POI2,
    …, POIi, …., POI} and Q > k). Next, we discuss how to use the way of normal distribution
    to select k − 1 POIs from these Q POIs. And the k − 1 POIs and POIlr have the
    same or similar offset probability, so as to maximize the offset probability entropy
    between them. A. The normal distribution function set N(u, σ) First, a normal
    distribution function set N(u, σ) is constructed between Q − 1 POIs {POI1, POI2,
    …, POIi, …., POIQ−1} and POIlr, where u is the expected value and σ is the standard
    deviation. In this paper, the distance between POIs is used as expected value,
    and the angle between POIs is used as standard deviation. Since the standard deviation
    is a value of 0–1, we needs to normalize the angel. Without considering the directivity
    of POIs, the following formula (2) is adopted to normalize the angle. $$ \\sigma
    { = |}\\theta | / 9 0^{ \\circ } $$ (2) where the θ is the actual angle between
    POIs, and the σ is the normalized angle, 0 < σ < 1. Thus, we construct the normal
    distribution set N(u, σ). $$ N(u,\\sigma ) = \\left\\{ {N\\left( {u_{1} ,\\sigma_{1}
    } \\right),N\\left( {u_{2} ,\\sigma_{2} } \\right), \\ldots ,N\\left( {u_{i} ,\\sigma_{i}
    } \\right), \\ldots ,N\\left( {u_{Q - 1} ,\\sigma_{Q - 1} } \\right)} \\right\\}\\quad
    i = 1,2, \\ldots ,Q - 1 $$ (3) Here, the ui is the distance between POIi and POIlr.
    While the σi is the normalized angle between POIi and POIlr. B. The offset probability
    For a normal distribution, we know that 68% of the area under the normal distribution
    function is within one standard deviation of the expected value [34]. Thus, we
    use this phenomenon to define the offset probability. And the selected k − 1 POIs
    have the same or similar offset probability with POIlr. For each normal distribution
    N(ui, σi) in set N(u, σ), the density function is written as formula (4). $$ \\varphi_{{r_{i}
    ,\\sigma_{i} }} (x) = \\frac{1}{{\\sqrt {2\\pi } \\sigma_{i} }}e^{{ - \\frac{{(x
    - r_{i} )^{2} }}{{2\\sigma_{i}^{2} }}}} $$ (4) Then we calculate the average distance
    between Q − 1 POIs {POI1, POI2, …, POIi, …., POIQ−1} and POIlr. $$ \\overline{u}
    { = }\\frac{{u_{1} + u_{2} + \\cdots + u_{i} + \\cdots + u_{Q - 1} }}{Q - 1} $$
    (5) And the average value of normalized angle between Q − 1 POIs and POIlr is
    written as formula (6). $$ \\overline{\\sigma } { = }\\frac{{\\sigma_{1} + \\sigma_{2}
    + \\cdots + \\sigma_{i} + \\cdots + \\sigma_{Q - 1} }}{Q - 1} $$ (6) According
    to the 68% property of distribution function, the degree of offset between POIi
    and POIlr is mainly distributed between \\( \\overline{u} - \\overline{\\sigma
    } \\) and \\( \\overline{u} { + }\\overline{\\sigma } \\). Thus, the offset probability
    \\( P_{{ < POI_{i} ,POI_{lr} > }} \\) between POIi and POIlr is defined as formula
    (7). $$ \\begin{aligned} P_{{ < POI_{i} ,POI_{lr} > }} & = P(\\overline{u} - \\overline{\\sigma
    } < x < \\overline{u} + \\overline{\\sigma } ) \\\\ & = \\int_{{\\overline{u}
    - \\overline{\\sigma } }}^{{\\overline{u} + \\overline{\\sigma } }} {\\varphi_{{u_{i}
    ,\\sigma_{i} }} (x)} dx \\\\ \\end{aligned} $$ (7) C. The maximum entropy of offset
    probability Using the formula (7), we can get the corresponding Q − 1 offset probabilities
    between Q − 1 POIs and POIlr, {\\( P_{{ < POI_{1} ,POI_{lr} > }} ,P_{{ < POI_{2}
    ,POI_{lr} > }} , \\ldots ,P_{{ < POI_{i} ,POI_{lr} > }} ,P_{{ < POI_{Q - 1} ,POI_{lr}
    > }} \\)}. By sorting these Q − 1 offset probabilities, we select the largest
    k − 1 offset probabilities. Thus, the corresponding k − 1 POIs have the same or
    similar deviation probability with POIlr, which is close to 68%. Considering an
    extreme condition of that the selected k − 1 POIs have the same distance and normalized
    angel with POIlr, the maximum offset probability is maximized, where each offset
    probability is equal to 68%. D. The KLO algorithm In this paper, by adopting the
    method of normal distribution to determine offset probability, we design the KLO
    algorithm, as shown in Algorithm 2. It is worth mentioned that the premise of
    the KLO algorithm is that any location should be included in a POI. Assume that
    a target vehicle U is at location l0, and requests the collected data Msg(lr)
    about location lr. While the location l0 and lr are in different coverage areas
    of E-nodes. Here, we introduce how the KLO algorithm protects the location lr.
    Suppose that location l0 is in the coverage area S1 of E-node1. And the location
    lr is in another coverage area Si of E-nodei. First, the target vehicle U extends
    the location lr to a large area A, which of course must contain the location lr.
    Then vehicle U sends the region A to E-node1. And E-node1 returns all POIs of
    region A to vehicle U. The vehicle U calculates the number of POIs (num.(POI)).
    If the num.(POI) is less than 2 k, the range of region A is modified by the formula
    of A = 2 k/num. (POI) *A, until num.(POI) is greater than 2 k. Set the variable
    Q = num. (POI). We get these Q POIs {POIlr, POI1, POI2, …, POIi, …., POIQ-1}.
    By using the formula (3), we construct the normal distribution set {N(u1, σ1),
    N(u2, σ2), …, N(ui, σi), …, N(uQ-1, σQ-1)} and compute Q − 1 offset probabilities
    {\\( P_{{ < POI_{1} ,POI_{l0} > }} ,P_{{ < POI_{2} ,POI_{l0} > }} , \\)\\( \\ldots
    ,P_{{ < POI_{i} ,POI_{l0} > }} ,P_{{ < POI_{Q - 1} ,POI_{l0} > }} \\)}. From the
    Q − 1 offset probabilities, the KLO algorithm selects k − 1 POIs {POI1, POI2,
    …., POIk-1} with maximum entropy of offset probability. Thus, the target U requests
    k messages, which have the same request content and k different locations, passing
    through E-node1 and E-nodei. Then the E-nodei and E-node1 response the k collected
    data {Msg(POIlr), Msg(POI1), Msg(POI2), …, Msg(POIk-1)}to vehicle U in turn. Algorithm
    2 describes the pseudo code of KLO algorithm. 6 Simulation and results In this
    section, the effectiveness of our proposed vehicular networking architecture and
    privacy protection algorithms are conducted by evaluating the system time, probability
    of privacy leakage and accuracy. We first describes the simulation environment.
    Then, we analyzes simulation results. 6.1 Simulation environment In our simulations,
    we use OPNET to construct vehicular networking environment, on a PC equipped with
    an Intel Core i7-8086 K @4.0 GHz processor and 16G of RAM. The built-in protocols
    of OPNET (e.g. AODV, DHCP) is ensure data transmission. To identify the efficiency
    of our proposed vehicular networking architecture, we compare it with the cloud-based
    vehicular networking architecture in [7] and edge-assistant vehicular networking
    architecture in [11]. It’s worth mentioning that the biggest difference between
    the edge-assistant vehicular networking architecture [11] and our proposed architecture
    lies in the edge node. Compared with the existing edge node of edge-assistant
    vehicular networking architecture in [11], the edge node of our proposed architecture
    is enhanced with more advanced performance, owning the semantic analysis and learning
    capabilities. In our simulation, we label the cloud-based vehicular networking
    architecture in [7], edge-assistant vehicular networking architecture in [11]
    and our proposed architecture as vehicular networking 1, vehicular networking
    2 and vehicular networking 3 respectively. In our experiment, the service provider
    (SP) in vehicular networking is honest-but curious so that we consider it as the
    attacker. However, there exists edge node in vehicular networking 2 and vehicular
    networking 3. Thus, both edge nodes and SP are considered as attackers in vehicular
    networking 2 and vehicular networking 3. Then we simulate that there are 200 vehicles
    (including the target vehicle U) to complete the crowdsourcing work of data collection
    and request in each vehicular networking. To better present the performance of
    privacy protection, we simulate the two scenarios: data aggregation and data distribution.
    For the scenario of data aggregation, vehicle U respectively collects three types
    of data {D1 = road map updating, D2 = traffic accident, D3 = traffic flow} in
    each vehicular networking. For the scenario of data distribution, the vehicle
    U makes 6 requests {Request1, Request2, Request3, Request4, Request5, Request6}.
    Generally, the data delay of more than 2 s seriously affects user service experience.
    Thus, our experiment sets the T as 2 s. The tolerance coefficients are set to
    0.8, 0.6 and 0.4, respectively. Thus, the data delay is limited between in 0.8
    and 1.6 s, which is accepted by users and relevant to real user life. In addition,
    to reduce the simulation time, the anonymity degree is set to 10 for both data
    aggregation and data distribution. Table 3 shows all the simulation parameters
    in detail. Table 3 Simulation parameters Full size table 6.2 Simulation results
    A. System time for vehicular networking Figure 6 shows the system time in terms
    of data transaction number under different vehicular networking. Here, data transaction
    includes the data aggregation and data distribution between 200 vehicles. The
    system time basically increases with the data transaction number in each vehicular
    networking. However, it shows the worst performance in vehicular networking 1.
    Because the data transaction involves SP in vehicular networking 1. This is time
    consuming. Fig. 6 System time under different vehicular networking Full size image
    By comparing the vehicular networking 2 with vehicular networking 3, we can get
    that vehicular networking 3 works better than vehicular networking 2 when the
    data transaction number is large than 850. In vehicular networking 3, since the
    collected data is stored and processed by classification, the advantage in system
    response time cannot be shown when the data volume is small. However, when the
    amount of data is large, the way of data classification storage and processing
    by E-node becomes more and more obvious. Therefore, our proposed vehicular networking
    with E-node is very suitable for large amounts of data. In fact, in the era of
    Big Data, the amount of data is increasing, and our proposed vehicular networking
    is more in line with the development of society. B. Privacy protection for data
    aggregation For data aggregation, we simulate the time delay and probability of
    privacy leakage in our experiment. To protect user privacy in the process of data
    aggregation, our experiment applies the TTA algorithm in vehicular networking
    3. The pri-LBS [11] algorithm is applied in vehicular networking 2 while the PAU
    [7] algorithm is in vehicular networking 1. Figure 7 shows the time delay for
    three kinds of collected data collected by target vehicle U. There is no difference
    in time delay of collecting three kinds of collected data using pri-LBS and PAU
    algorithms. However, the PAU has the largest data delay, about 1.5 s. While the
    pri-LBS performs best, about 0.5 s. For the TTA algorithm, as we uploads data
    within the time tolerance range, different kinds of collected data have different
    time delays. The larger the tolerance coefficient, the greater the time delay.
    Thus, TTA does not perform as well as pri-LBS in terms of time delay. However,
    a certain amount of time is sacrificed for better privacy protection in TTA, as
    shown in Fig. 8. Fig. 7 Time delay for different data aggregation Full size image
    Fig. 8 Privacy leakage using different privacy preserving algorithms for data
    aggregation Full size image Figure 8 describes the probability of identity privacy
    leakage when vehicle U uploads data Msg(l0) in different vehicular networking.
    For vehicular networking 1, the PAU is deployed in SP. And vehicle U directly
    uploads data Msg(l0) to SP. Thus, SP can guess that vehicle U once appeared in
    l0 with probability 100%. For vehicular networking 2, the pri-LBS is deployed
    in edge node. The vehicle U first directly uploads data Msg(l0) to edge node.
    The edge node implements pri-LBS privacy protection method. Then Msg(l0) is anonymously
    uploaded to SP by edge node. Therefore, for the edge node in pri-LBS, it is also
    possible to guess that vehicle U once appeared in l0 with probability 100%. However,
    the probability of privacy leakage is reduced to 10%–20% for the SP in pri-LBS.
    The best privacy protection method is our TTA algorithm. By using TTA algorithm,
    the probability of privacy leakage is reduced to less than 10% for both edge node
    and SP. C. Privacy protection for data distribution For data distribution, we
    simulate the offset probability, privacy leakage probability and accuracy in our
    experiment. To protect user privacy in the process of data distribution, our experiment
    applies the KLO algorithm in vehicular networking 3. The pri-LBS and PAU algorithms
    are also applied in vehicular networking 2 and vehicular networking 1 respectively.
    In KLO algorithm, the target vehicle U requests Msg(lr) of location lr at location
    l0.The location l0 and lr are not in the same coverage area of one edge node.
    Therefore, to protect the location lr, we need to select other 9 (k − 1) locations.
    The offset probabilities between the 9 locations and location lr are shown in
    Fig. 9. The offset probability is basically close to the reference value of 0.68.
    Thus, the offset probability entropy obtained by KLO algorithm is maximized. Fig.
    9 The offset probability for KLO Full size image By using different privacy preserving
    algorithms, Fig. 10 shows the probability of privacy leakage for 6 requests of
    vehicle U. Like the data aggregation in Fig. 8, the probability of privacy disclosure
    is 100% for both the SP in PAU and the edge node in pri-LBS, which cannot guarantee
    the privacy protection of vehicles. However, for the SP in pri-LBS, the probability
    of privacy leakage decreases to about 0.1. For the SP and edge node in vehicular
    networking 3, the probability of privacy leakage is reduced to 10% or even lower
    due to the adoption of KLO algorithm. Therefore, it performs best in our KLO algorithm.
    Fig. 10 Privacy leakage using different privacy preserving algorithms for data
    distribution Full size image Although both pri-LBS and KLO can achieve the same
    privacy protection for the attackers (edge node or SP), the service accuracy in
    KLO is higher, as shown in Fig. 11. Both pri-LBS and PAU sacrifice certain service
    quality in exchange for corresponding privacy protection. The service accuracy
    in pri-LBS is about 80%, while the accuracy of KLO is more than 95%. Therefore,
    in the process of required active distribution, our proposed KLO algorithm can
    guarantee both the quality of service and privacy protection. Fig. 11 Service
    accuracy for data distribution Full size image 7 Conclusion In this paper, we
    study the crowdsourcing application in edge-assistant vehicular networking. First,
    considering three kinds of collected data of road map updating, traffic accident
    and traffic flow in vehicular networking, we discuss two data transmission scenarios:
    data aggregation and data distribution. To improve the real-time demand of data
    transmission, this paper enhances the edge node and study the enhanced edge node
    how to work. Then the privacy threats of that exist in the process of data aggregation
    and data distribution are proposed. And we design the TTA and KLO privacy protection
    algorithms to achieve privacy requirements for data aggregation and data distribution.
    The experimental results confirm that the enhanced edge node is more suitable
    for edge-assistant vehicular networking, and the proposed protection algorithms
    are more efficient and secure. In future work, we will consider more privacy-sensitivity
    features (e.g. anonymous degree, average distance, etc.), and strengthen experiment
    to prove the efficacy of privacy protection. Furthermore, we shall explore the
    privacy-preserving mechanism by using dynamic vehicle pseudonyms instead of fixed
    vehicle IDs. References Yang, K., Menendez, M., & Guler, S. (2019). Implementing
    transit signal priority in a connected vehicle environment with and without bus
    stops. Transportmetrica B-Transport Dynamics,7(1), 423–445. Google Scholar   Automotive
    Industry Trends. (2019). IoT connected smart cars vehicles. http://www.businessinsider.com/internet-of-things-connected-smart-cars.
    Accessed 10 Nov 2019. Rodrigues, F., Henrickson, K., & Pereira, F. (2019). Multi-output
    gaussian processes for crowdsourced traffic data imputation. IEEE Transactions
    on Intelligent Transportation Systems,20(2), 594–603. Google Scholar   He, Z.,
    Cao, J., Liu, X. (2015). High quality participant recruitment in vehicle-based
    crowdsourcing using predictable mobility. In INFCOM (pp. 2542–2559). Zhang, P.,
    Hu, C., Chen, D., et al. (2018). ShiftRoute: achieving location privacy for map
    services on smartphones. IEEE Transactions on Vehicular Technology,67(5), 4527–4538.
    Google Scholar   Jiang, D., Wang, W., Shi, L., et al. (2018). A compressive sensing-based
    approach to end-to-end network traffic reconstruction. IEEE Transactions on Network
    Science and Engineering,5(3), 1–12. Google Scholar   Feng, X., & Wang, L. (2019).
    PAU: Privacy assessment method with uncertainty consideration for cloud-based
    vehicular networks. Future Generation Computer Systems,96, 368–375. Google Scholar   Md,
    W., Mehdi, S., Abdullah, G., et al. (2014). A survey on vehicular cloud computing.
    Journal of Network and Computer Applications,40, 325–344. Google Scholar   Lee,
    S., Lee, J., & Cho, H. (2018). A study of mobile edge computing system architecture
    for connected car media services on highway. KSII Transactions on Internet and
    Information Systems,12(12), 5669–5684. Google Scholar   Jiang, D., Huo, L., Lv,
    Z., et al. (2018). A joint multi-criteria utility-based network selection approach
    for vehicle-to-infrastructure networking. IEEE Transactions on Intelligent Transportation
    Systems,19(10), 3305–3319. Google Scholar   Zhou, L., Yu, L., Du, S., et al. (2019).
    Achieving differentially private location privacy in edge-assistant connected
    vehicles. IEEE Internet of Things Journal,6, 1–10. Google Scholar   Jiang, D.,
    Wang, Y., Lv, Z., et al. (2020). Big data analysis-based network behavior insight
    of cellular networks for industry 4.0 applications. IEEE Transactions on Industrial
    Informatics, 16(2), 1–9. Google Scholar   Jiang, D., Huo, L., & Song, H. (2018).
    Rethinking behaviors and activities of base stations in mobile cellular networks
    based on big data analysis. IEEE Transactions on Network Science and Engineering,1(1),
    1–12. Google Scholar   Le, T., & Hu, R. (2018). Mobility-aware edge caching and
    computing in vehicle networks: a deep reinforcement learning. IEEE Transactions
    on Vehicular Technology,67(11), 10190–10203. Google Scholar   Feng, J., Liu, Z.,
    Wu, C., et al. (2017). AVE: Autonomous vehicular edge computing framework with
    ACO-based scheduling. IEEE Transactions on Vehicular Technology,66(12), 10660–10675.
    Google Scholar   Gu, B., Chen, Y., Liao, H., et al. (2018). A distributed and
    context-aware task assignment mechanism for collaborative mobile edge computing.
    Sensors,18(8), 1–17. Google Scholar   Huang, C., Chiang, M., Dao, D., et al. (2018).
    V2V data offloading for cellular network based on the software defined network
    (SDN) inside mobile edge computing (MEC) architecture. IEEE Access,6, 17741–17755.
    Google Scholar   Jiang, D., Huo, L., & Li, Y. (2018). Fine-granularity inference
    and estimations to network traffic for SDN. PLoS ONE,13(5), 1–23. Google Scholar   Sun,
    J., Gu, Q., Zheng, T., et al. (2019). Joint communication and computing resource
    allocation in vehicular edge computing. International Journal of Distributed Sensor
    Networks,15(3), 1–13. Google Scholar   Nguyen, T., Nguyen, V., Pham, A., et al.
    (2018). Cost-effective resource sharing in an internet of vehicles-employed mobile
    edge computing environment. Symmetry,10(11), 1–19. Google Scholar   Shailsh, C.,
    Naik, R., & Jose, J. (2019). Crowdsourcing-based traffic simulation for smart
    freight mobility. Simulation Modelling Practice and Theory,95, 1–15. Google Scholar   Ali,
    K., Al-Yaseen, D., Ejaz, A., et al. (2012). CrowdITS: Crowdsourcing in intelligent
    transportation systems. In Wireless communications and networking conference (WCNC)
    (pp. 3307–3311). Misra, A., Gooze, A., Watkins, K., et al. (2014). Crowdsourcing
    and its application to transportation data collection and management. Transportation
    Research Record,2414, 1–8. Google Scholar   Metlo, S., Memon, M., Shaikh, F.,
    et al. (2019). Crowdsource based vehicle tracking system. Wireless Personal Communications,106(4),
    2387–2405. Google Scholar   Andrew, F., Kumar, B., Chen, J., et al. (2017). Multi-lane
    pothole detection from crowdsourced undersampled vehicle sensor data. IEEE Transactions
    on Mobile Computing,16(12), 3417–3430. Google Scholar   Gurdit, S., Divya, B.,
    & Sanieev, S. (2017). Smart patrolling: An efficient road surface monitoring using
    smartphone sensors and crowdsourcing. Pervasive and Mobile Computing,40, 71–88.
    Google Scholar   Yang, X., Tang, U., Niu, L., et al. (2018). Generating lane-based
    intersection maps from crowdsourcing big trace data. Transportation Research Part
    C-Emerging Technologies,89, 168–187. Google Scholar   Kang, J., Yu, R., Huang,
    X., et al. (2018). Privacy-preserved pseudonym scheme for fog computing supported
    internet of vehicles. IEEE Transactions on Intelligent Transportation Systems,19(8),
    2627–2637. Google Scholar   Wei, J., Wang, X., Li, N., et al. (2018). A privacy-preserving
    fog computing framework for vehicular crowdsensing networks. IEEE Access,6, 43776–43784.
    Google Scholar   Ma, L., Liu, X., Pei, Q., et al. (2019). Privacy-preserving reputation
    management for edge computing enhanced mobile crowdsensing. IEEE Transactions
    on Services Computing,12(5), 786–799. Google Scholar   Basudan, S., Lin, X., &
    Sankaranarayanan, K. (2017). A privacy-preserving vehicular crowdsensing-based
    road surface condition monitoring system using fog computing. IEEE Internet of
    Things Journal,4(3), 772–782. Google Scholar   Li, M., Zhu, L., & Lin, X. (2019).
    Privacy-preserving traffic monitoring with false report filtering via fog-assisted
    vehicular crowdsensing. IEEE Transaction on Services Computing, 99, 1–11. Google
    Scholar   Onieva, J., Rios, R., Roman, R., et al. (2019). Edge-assisted vehicular
    networks security. IEEE Internet of Things Journal,68(5), 8038–8045. Google Scholar   Li,
    L., & Wang, F. (2010). Probability and mathematical statistics (pp. 26–34). Beijing:
    Chemical Industry Press. Google Scholar   Download references Acknowledgements
    This research was partially supported by the Project on Public Safety Risk Prevention
    and Control and Emergency Technical Equipment (2018YFC0831002), Sichuan science
    and technology program (2019YFG0206), National Natural Science Foundation of China
    (61971105), Fundamental Research Funds for the Central Universities (ZYGX2019J004,
    ZYGX2019J125). Author information Authors and Affiliations Key Lab of Optical
    Fiber Sensing and Communications (Ministry of Education), University of Electronic
    Science and Technology of China, No. 2006 Xiyuan Road, hi-tech West District,
    Chengdu, Sichuan, China Hui Li, Lishuang Pei, Dan Liao, Ming Zhang, Du Xu & Xiong
    Wang Chengdu Research Institute, University of Electronic Science and Technology
    of China, Chengdu, China Hui Li, Dan Liao & Ming Zhang Corresponding author Correspondence
    to Ming Zhang. Additional information Publisher''s Note Springer Nature remains
    neutral with regard to jurisdictional claims in published maps and institutional
    affiliations. Rights and permissions Reprints and permissions About this article
    Cite this article Li, H., Pei, L., Liao, D. et al. Achieving privacy protection
    for crowdsourcing application in edge-assistant vehicular networking. Telecommun
    Syst 75, 1–14 (2020). https://doi.org/10.1007/s11235-020-00666-w Download citation
    Published 08 May 2020 Issue Date September 2020 DOI https://doi.org/10.1007/s11235-020-00666-w
    Share this article Anyone you share the following link with will be able to read
    this content: Get shareable link Provided by the Springer Nature SharedIt content-sharing
    initiative Keywords Crowdsourcing Vehicular networking Edge-assistant Privacy
    protection Use our pre-submission checklist Avoid common mistakes on your manuscript.
    Sections Figures References Abstract Introduction Related work Enhanced edge node
    for data transmission Privacy attack model Algorithm design Simulation and results
    Conclusion References Acknowledgements Author information Additional information
    Rights and permissions About this article Advertisement Discover content Journals
    A-Z Books A-Z Publish with us Publish your research Open access publishing Products
    and services Our products Librarians Societies Partners and advertisers Our imprints
    Springer Nature Portfolio BMC Palgrave Macmillan Apress Your privacy choices/Manage
    cookies Your US state privacy rights Accessibility statement Terms and conditions
    Privacy policy Help and support 129.93.161.222 Big Ten Academic Alliance (BTAA)
    (3000133814) - University of Nebraska-Lincoln (3000134173) © 2024 Springer Nature"'
  inline_citation: '>'
  journal: Telecommunication Systems
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Achieving privacy protection for crowdsourcing application in edge-assistant
    vehicular networking
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Yang X.
  - Shu L.
  - Huang K.
  - Li K.
  - Huo Z.
  - Wang Y.
  - Wang X.
  - Lu Q.
  - Zhang Y.
  citation_count: '9'
  description: 'Solar insecticidal lamps Internet of Things (SIL-IoTs) is a novel
    physical agricultural pest control implement, which is an emerging paradigm that
    extends Internet of Things technology towards Solar Insecticidal Lamp (SIL). SIL-IoTs
    is composed of SIL nodes with functions of preventing and controlling of agricultural
    migratory pests with phototaxis feature, which can be deployed over a vast region
    for the purpose of ensuring pests outbreak area location, reducing pesticide dosage
    and monitoring agricultural environmental conditions. SIL-IoTs is widely used
    in agricultural production, and a number of studies have been conducted. However,
    in most current research projects, fault diagnosis has not been taken into consideration,
    despite the fact that SIL-IoTs faults have an adverse influence on the development
    and application of SIL-IoTs. Based on this background, this research aims to analyze
    the characteristics and challenges of fault diagnosis in SIL-IoTs, which naturally
    leads to a great number of open research issues outlined afterward. Firstly, an
    overview and state-of-art of SIL-IoTs were introduced, and the importance of fault
    diagnosis in SIL-IoTs was analyzed. Secondly, faults of SIL nodes were listed
    and classified into different types of Wireless Sensor Networks (WSNs) faults.
    Furthermore, WSNs faults were classified into behavior-based, time-based, component-based,
    and area affected-based faults. Different types of fault diagnosis algorithms
    (i.e., statistic method, probability method, hierarchical routing method, machine
    learning method, topology control method, and mobile sink method) in WSNs were
    discussed and summarized. Moreover, WSNs fault diagnosis strategies were classified
    into behavior-based strategies (i.e., active type and positive type), monitoring-based
    strategies (i.e., continuous type, periodic type, direct type, and indirect type)
    and facility-based strategies (i.e., centralized type, distributed type and hybrid
    type). Based on above algorithms and strategies, four kinds of fault phenomena:
    1) abnormal background data, 2) abnormal communication of some nodes, 3) abnormal
    communication of the whole SIL-IoTs, and 4) normal performance with abnormal behavior
    actually were introduced, and fault diagnosis tools (i.e., Sympathy, Clairvoyant,
    SNIF and Dustminer) which were adapted to the mentioned fault phenomena were analyzed.
    Finally, four challenges of fault diagnosis in SIL-IoTs were highlighted, i.e.,
    1) the complex deployment environment of SIL nodes, leading to the fault diagnosis
    challenges of heterogeneous WSNs under the condition of unequal energy harvesting,
    2) SIL nodes task conflict, resulting from the interference of high voltage discharge,
    3) signal loss of continuous area nodes, resulting in the regional link fault,
    and 4) multiple failure situations of fault diagnosis. To sum up, fault diagnosis
    plays a vital role in ensuring the reliability, real-time data transmission, and
    insecticidal efficiency of SIL-IoTs. This work can also be extended for various
    types of smart agriculture applications and provide fault diagnosis references.'
  doi: 10.12133/j.smartag.2020.2.2.202005-SA002
  full_citation: '>'
  full_text: '>

    "欢迎您访问《智慧农业（中英文）》官方网站！ English 网站首页 期刊介绍 编委会 投稿指南 期刊订阅 业务合作 下载中心 联系我们 Smart Agriculture
    ›› 2020, Vol. 2 ›› Issue (2): 11-27.doi: 10.12133/j.smartag.2020.2.2.202005-SA002
    • 专题--农业传感器与物联网 • 上一篇    下一篇 太阳能杀虫灯物联网故障诊断特征分析及潜在挑战 杨星1, 舒磊1,2(), 黄凯1, 李凯亮1, 霍志强2,
    王彦飞1, 王心怡1, 卢巧玲1, 张亚成1    1.南京农业大学 工学院，江苏 南京 210031 2.英国林肯大学 工学院，林肯 LN67TS 收稿日期:2020-05-12
    修回日期:2020-05-29 出版日期:2020-06-30 基金资助: 南京农业大学人才引进科研启动经费(77H0603);南京农业大学2019年国家级大学生创新创业训练计划项目(201910307098K)
    作者简介:杨 星（1992－），男，硕士，研究方向为农业物联网。E-mail：harryyangx@gmail.com。 通信作者: Characteristics
    Analysis and Challenges for Fault Diagnosis in Solar Insecticidal Lamps Internet
    of Things YANG Xing1, SHU Lei1,2(), HUANG Kai1, LI Kailiang1, HUO Zhiqiang2, WANG
    Yanfei1, WANG Xinyi1, LU Qiaoling1, ZHANG Yacheng1    1.College of Engineering,
    Nanjing Agricultural University, Nanjing 210031, China 2.School of Engineering,
    University of Lincoln, Lincoln, LN67TS, U. K. Received:2020-05-12 Revised:2020-05-29
    Online:2020-06-30 在线阅读 2500 知网下载  本地下载 962 摘要/Abstract 摘要： 太阳能杀虫灯物联网（SIL-IoTs）是一种基于农业场景与物联网技术的新型物理农业虫害防治工具，通过无线传输太阳能杀虫灯组件状态数据，用户可后台实时查看太阳能杀虫灯运行状态，具有杀虫计数、虫害区域定位、辅助农情监测等功能。但随着SIL-IoTs快速发展与广泛应用，故障诊断难和维护难等矛盾日益突出。基于此，本研究首先阐述了SIL-IoTs的结构和研究现状，分析了故障诊断的重要性，指出了故障诊断是保障其可靠性的主要手段。接着介绍了目前太阳能杀虫灯节点自身存在的故障及其在无线传感网络（WSNs）中的体现，并进一步对WSNs中的故障进行分类，包括基于行为、基于时间、基于组件以及基于影响区域的故障四类。随后讨论了统计方法、概率方法、层次路由方法、机器学习方法、拓扑控制方法和移动基站方法等目前主要使用的WSNs故障诊断方法。此外，还探讨了SIL-IoTs故障诊断策略，将故障诊断从行为上分为主动型诊断与被动型诊断策略，从监测类型上分为连续诊断、定期诊断、直接诊断与间接诊断策略，从设备上分为集中式、分布式与混合式策略。在以上故障诊断方法与策略的基础上，介绍了后台数据异常、部分节点通信异常、整个网络通信异常和未诊断出异常但实际存在异常四种故障现象下适用的WSNs故障诊断调试工具，如Sympathy、Clairvoyant、SNIF和Dustminer。最后，强调了SIL-IoTs的特性对故障诊断带来的潜在挑战，包括部署环境复杂、节点任务冲突、连续性区域节点无法传输数据和多种故障诊断失效等情形，并针对这些潜在挑战指出了合理的研究方向。由于SIL-IoTs为农业物联网中典型应用，因此本研究可扩展至其它农业物联网中，并为这些农业物联网的故障诊断提供参考。
    关键词: 太阳能杀虫灯, 无线传感网络, 农业物联网, 故障诊断, 虫害 Abstract: Solar insecticidal lamps Internet
    of Things (SIL-IoTs) is a novel physical agricultural pest control implement,
    which is an emerging paradigm that extends Internet of Things technology towards
    Solar Insecticidal Lamp (SIL). SIL-IoTs is composed of SIL nodes with functions
    of preventing and controlling of agricultural migratory pests with phototaxis
    feature, which can be deployed over a vast region for the purpose of ensuring
    pests outbreak area location, reducing pesticide dosage and monitoring agricultural
    environmental conditions. SIL-IoTs is widely used in agricultural production,
    and a number of studies have been conducted. However, in most current research
    projects, fault diagnosis has not been taken into consideration, despite the fact
    that SIL-IoTs faults have an adverse influence on the development and application
    of SIL-IoTs. Based on this background, this research aims to analyze the characteristics
    and challenges of fault diagnosis in SIL-IoTs, which naturally leads to a great
    number of open research issues outlined afterward. Firstly, an overview and state-of-art
    of SIL-IoTs were introduced, and the importance of fault diagnosis in SIL-IoTs
    was analyzed. Secondly, faults of SIL nodes were listed and classified into different
    types of Wireless Sensor Networks (WSNs) faults. Furthermore, WSNs faults were
    classified into behavior-based, time-based, component-based, and area affected-based
    faults. Different types of fault diagnosis algorithms (i.e., statistic method,
    probability method, hierarchical routing method, machine learning method, topology
    control method, and mobile sink method) in WSNs were discussed and summarized.
    Moreover, WSNs fault diagnosis strategies were classified into behavior-based
    strategies (i.e., active type and positive type), monitoring-based strategies
    (i.e., continuous type, periodic type, direct type, and indirect type) and facility-based
    strategies (i.e., centralized type, distributed type and hybrid type). Based on
    above algorithms and strategies, four kinds of fault phenomena: 1) abnormal background
    data, 2) abnormal communication of some nodes, 3) abnormal communication of the
    whole SIL-IoTs, and 4) normal performance with abnormal behavior actually were
    introduced, and fault diagnosis tools (i.e., Sympathy, Clairvoyant, SNIF and Dustminer)
    which were adapted to the mentioned fault phenomena were analyzed. Finally, four
    challenges of fault diagnosis in SIL-IoTs were highlighted, i.e., 1) the complex
    deployment environment of SIL nodes, leading to the fault diagnosis challenges
    of heterogeneous WSNs under the condition of unequal energy harvesting, 2) SIL
    nodes task conflict, resulting from the interference of high voltage discharge,
    3) signal loss of continuous area nodes, resulting in the regional link fault,
    and 4) multiple failure situations of fault diagnosis. To sum up, fault diagnosis
    plays a vital role in ensuring the reliability, real-time data transmission, and
    insecticidal efficiency of SIL-IoTs. This work can also be extended for various
    types of smart agriculture applications and provide fault diagnosis references.
    Key words: solar insecticidal lamp, Wireless Sensor Networks, agricultural Internet
    of Things, fault diagnosis, insect disaster 中图分类号:  S237 引用本文 杨星, 舒磊, 黄凯, 李凯亮,
    霍志强, 王彦飞, 王心怡, 卢巧玲, 张亚成. 太阳能杀虫灯物联网故障诊断特征分析及潜在挑战[J]. 智慧农业（中英文）, 2020, 2(2): 11-27.
    YANG Xing, SHU Lei, HUANG Kai, LI Kailiang, HUO Zhiqiang, WANG Yanfei, WANG Xinyi,
    LU Qiaoling, ZHANG Yacheng. Characteristics Analysis and Challenges for Fault
    Diagnosis in Solar Insecticidal Lamps Internet of Things[J]. Smart Agriculture,
    2020, 2(2): 11-27. 使用本文 0     /   收藏文章 0 /   推荐 导出引用管理器 EndNote|Ris|BibTeX 链接本文:
    http://www.smartag.net.cn/CN/10.12133/j.smartag.2020.2.2.202005-SA002                http://www.smartag.net.cn/CN/Y2020/V2/I2/11
    参考文献 相关文章 9 Metrics      本文评价 摘要 参考文献 相关文章 Metrics 本文评价 回顶部 ISSN 2096-8094    CN
    10-1681/S 邮发代号：80-834 国外代号：C9452 主管：中华人民共和国农业农村部 主办：中国农业科学院农业信息研究所 地址：北京市海淀区中关村南大街12号中国农业科学院农业信息研究所
    邮编：100081 电话：010-82109657 E-mail：smartag@caas.cn 京ICP备09089781号-37"'
  inline_citation: '>'
  journal: Smart Agriculture
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Characteristics analysis and challenges for fault diagnosis in solar insecticidal
    lamps internet of things
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Xin W.
  - Jiang Z.
  - Lin G.
  - Yu D.
  citation_count: '3'
  description: In recent years, the rapid advancements in Internet of Things boost
    the utilization of Wireless Sensor Network (WSN). Through WSN, a huge amount of
    various kinds of data can be acquired from different environments, which further
    facilitate us to harness the world we live. However, the error-prone and unpredictable
    natures of wireless links significantly impair the quality of data transmission
    and the utility of acquired data in WSN. Therefore, to solve this crucial problem,
    this paper focuses on data access control and hybrid transmission control of WSN.
    Based on the mathematical models of the two control operations, an intractable
    optimization problem is first formulated with numerous considerations, including
    data utility, energy consumption, network stability and data loss rate. Because
    of the complexity and intractability of the originally formulated problem, a Lyapunov
    function-based network optimization theory is utilized to transform and decompose
    it into three relatively simple subproblems. Stochastic Data Scheduling Mechanism
    (SDSM) is designed based on the solutions to the three subproblmes. The optimality
    and implementation of SDSM are also analyzed. Finally, the performance of SDSM
    is demonstrated through extensive evaluations.
  doi: 10.1109/ACCESS.2020.2982868
  full_citation: '>'
  full_text: '>

    "This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org
    IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal
    Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln
    Sign Out All Books Conferences Courses Journals & Magazines Standards Authors
    Citations ADVANCED SEARCH Journals & Magazines >IEEE Access >Volume: 8 Stochastic
    Optimization of Data Access and Hybrid Transmission in Wireless Sensor Network
    Publisher: IEEE Cite This PDF Wei Xin; Zhongbai Jiang; Guoxin Lin; Duli Yu All
    Authors 1 Cites in Paper 474 Full Text Views Open Access Comment(s) Under a Creative
    Commons License Abstract Document Sections I. Introduction II. Related Work III.
    Wireless Sensor Network Model IV. Optimization Problem Formulation V. Problem
    Transformation & Decomposition Show Full Outline Authors Figures References Citations
    Keywords Metrics Abstract: In recent years, the rapid advancements in Internet
    of Things boost the utilization of Wireless Sensor Network (WSN). Through WSN,
    a huge amount of various kinds of data can be acquired from different environments,
    which further facilitate us to harness the world we live. However, the error-prone
    and unpredictable natures of wireless links significantly impair the quality of
    data transmission and the utility of acquired data in WSN. Therefore, to solve
    this crucial problem, this paper focuses on data access control and hybrid transmission
    control of WSN. Based on the mathematical models of the two control operations,
    an intractable optimization problem is first formulated with numerous considerations,
    including data utility, energy consumption, network stability and data loss rate.
    Because of the complexity and intractability of the originally formulated problem,
    a Lyapunov function-based network optimization theory is utilized to transform
    and decompose it into three relatively simple subproblems. Stochastic Data Scheduling
    Mechanism (SDSM) is designed based on the solutions to the three subproblmes.
    The optimality and implementation of SDSM are also analyzed. Finally, the performance
    of SDSM is demonstrated through extensive evaluations. Stochastic Data Scheduling
    Mechanism in Wireless Sensor Networks. Published in: IEEE Access ( Volume: 8)
    Page(s): 62273 - 62285 Date of Publication: 23 March 2020 Electronic ISSN: 2169-3536
    DOI: 10.1109/ACCESS.2020.2982868 Publisher: IEEE Funding Agency: CCBY - IEEE is
    not the copyright holder of this material. Please follow the instructions via
    https://creativecommons.org/licenses/by/4.0/ to obtain full-text articles and
    stipulations in the API documentation. SECTION I. Introduction Nowadays, Wireless
    Sensor Networks (WSN) are widely utilized in the Internet of Things (IoT) [1].
    They are able to collect and provide a large amount of data from various critical
    environments, including human bodies, cities, forests and underwater. Benefiting
    from the collected and provided data, real-time monitoring and intelligent controls
    can be achieved to further provide great convenience for all aspects of our lives.
    However, the error-prone and fragile wireless link is the bottleneck of WSN which
    greatly influences its performance of data transmission. Moreover, the unpredictable
    nature of wireless link also exerts significant pressure on making real-time and
    optimal decisions for the control operations of WSN. The utility of collected
    data is therefore greatly degraded. Consequently, transmitting data with high
    quality and achieving high data utility are still challenging in WSN. To address
    the above challenges, this paper focuses on two essential control operations of
    WSN including data access control and hybrid transmission control. Data access
    control is mainly responsible to determine the amount of data entered into WSN
    based on current network status and the utility of collected data. It also prevents
    the accessed data from overwhelming network transmission capability. Hybrid transmission
    control decides the amount of data transmitted through various and heterogeneous
    transmission links in real time, with the considerations of energy consumption,
    network stability and data loss rate. Even though WSN have attracted a lot of
    attentions of academia in recent years, there are still two major aspects which
    are not fully researched. The data access and hybrid transmission are seldom jointly
    researched and optimized. It results in a serious imbalance between data utility
    and network stability. Moreover, because of the error-prone and unpredictable
    natures of wireless links in WSN, it is difficult to perform optimal data access
    control to admit the appropriate amount of data into WSN. These natures also make
    great challenge for hybrid transmission control to establish an efficient and
    effective data scheduling algorithm over numerous kinds of wireless links. Because
    of the limitation of implemented optimization method and theory, current researches
    of data access and transmission in WSN mainly focus on a few considerations. Moreover,
    the derived mechanisms are not scalable and extensible. If more considerations
    and constraints are incorporated, the performance of the mechanisms will be greatly
    degraded. Therefore, jointly optimizing data access and transmission with numerous
    considerations and providing an optimization method which can be easily extended
    are still problematic in WSN. Motivated by the above two aspects, careful investigation
    of WSN is conducted in this paper and Stochastic Data Scheduling Mechanism (SDSM)
    is proposed. The main contributions of this paper are presented in brief as follows:
    A general network model of WSN is researched and mathematical models of data access
    and hybrid transmission are established. Based on the established models, an intractable
    optimization problem is formulated with multiple considerations, including data
    utility, energy consumption, network stability and data loss rate. The Lyapunov
    function-based network optimization theory is introduced to transform and decompose
    the originally formulated problem into three simple subproblems, i.e. data access
    control problem, hybrid transmission control problem and intermediate computation
    problem. Such transformation and decomposition make the original problem tractable
    and scalable. By solving the three problems, SDSM is designed which is composed
    of four components. The optimality and implementation analyses of SDSM are also
    presented. The performance of SDSM is evaluated through extensive simulations.
    The evaluation results demonstrate that SDSM is able to improve the utility of
    collected data, reduce energy consumption and maintain the network stability of
    WSN. The rest of this paper is organized as follows. Section II briefly reviews
    related work. Section III establishes the mathematical models of WSN. Section
    IV formulates the optimization problem based on the established WSN models. Section
    V performs the transformation and decomposition for the formulated optimization
    problem and three subproblems are derived. Section VI designs SDSM to solve the
    three subproblems. Optimality and implementation analyses of SDSM are also provided.
    Section VII evaluates the performance of SDSM. Section VIII concludes this paper.
    SECTION II. Related Work Recently, data transmission in WSN has received increasing
    attentions. Considering sensors are always energy-limited, numerous valuable researches
    [2]–[5] perform the joint optimization of data transmission and energy consumption
    with different concerns. Zhang et al. [2] focus on the situation where charging
    vehicle is used to provide power for sensors. A three-stage method is proposed
    to optimize the uplink route of data and the travel path of charging vehicle.
    Fitzgerald et al. [3] concentrate on multiple-sink aggregation problem with the
    assistance of fog computing. Several algorithms are proposed to optimize total
    energy usage, per-node energy usage and transmission throughput. Farhan et al.
    [4] propose a long hop algorithm for WSN. This algorithm makes optimization on
    energy consumption by preferentially transmitting the data packets with with long
    distance. Shukla et al. [5] analyze the data transmission of WSN. An algorithm
    called Smart Pinging Without Groups is proposed to detect traffic hotspot and
    reduce energy consumption. Routing mechanism also makes great influence on data
    transmission efficiency. Therefore, a lot of researches [1], [6]–[9] concentrate
    on optimizing routing algorithms and protocols in WSN. Kumar and Vidyarthi [1]
    propose an energy efficient routing mechanism for WSN in software defined networking
    architecture. Particle swarm optimization method is utilized to reduce energy
    consumption and elongate the lifetime of sensors. Benaddy et al. [6] propose a
    multipath routing algorithm to increase the reliability of data transmission.
    The transmission distance and energy consumption are also considered. Jiang [7]
    optimize a WSN routing protocol, i.e. LEACH protocol, using ant colony algorithm
    and particle swarm algorithm. The optimized LEACH protocol is able to balance
    the tradeoff between data transmission and energy consumption. Lai and Wang [8]
    research the broadcast data dissemination problem of WSN in IoT systems. Opportunistic
    routing is employed and Receiver Negotiation Opportunity Broadcast protocol is
    proposed which improves the trustworthiness and efficiency of data transmission.
    Qiu et al. [9] propose a multi-gradient routing protocol for WSN to support different
    traffic patterns, which is evaluated on real-world testbeds and achieves lower
    transmission delay. Besides the above achievements about data transmission in
    WSN, Li et al. [10], Yue et al. [11] and Le and Vo [12] respectively propose data
    reconstruction algorithm, data fusion algorithm and data compression algorithm
    to improve the transmission efficiency. Shukla et al. [13] and Majumdar et al.
    [14] pay their attention to data packets in WSN. The problems of packet allocation
    and packet size are researched. Baharudin et al. [15] propose a frequency control
    mechanism for cognitive radio-based WSN. Xu et al. [16] study the transmission
    of multimedia data in WSN. A highly distributed algorithm is proposed to support
    smooth data collection and coordinated data dissemination. Rezaei et al. [17]
    exploit the wireless powered communication in IoT which is composed of base stations
    and sensor nodes. The secrecy throughput of sensors is optimized by the proposed
    max-min fair and proportional fair algorithms. One of the networking method of
    WSN is to organize numerous sensor nodes into a cluster and select a cluster head
    to manage the cluster and forward collected data. Similar with data transmission,
    energy consumption is also an important consideration in sensor cluster. Therefore,
    energy-saving cluster head selection mechanisms are proposed in [18] and [19].
    Meanwhile, how to organize sensor nodes into a cluster has a great impact on the
    performance of WSN. Numerous researches have been conducted based on traffic load
    analysis [20], network stability [21] and compressed data gathering [22], etc.
    Because of the popularity of WSN, it is also researched in terms of networking
    method [23], network coverage [24], information security [25], [26], privacy protection
    [27], source localization [28] and fog computing [29]. Based on the above review
    of related work, we find out many achievements have been realized for WSN with
    different concentrations. However, few of them attempts to jointly optimize data
    access and hybrid transmission in real time. Moreover, a scalable optimization
    theory tailored toward WSN is also seldom researched. SECTION III. Wireless Sensor
    Network Model This section first presents an overview of WSN. Then the mathematical
    models of WSN are established, including data access model and hybrid transmission
    model. A. Overview of Wireless Sensor Network The WSN considered in this paper
    is shown as in Figure 1. All the sensors include two platforms, i.e. data collection
    platform and data transmission platform. Data collection platform is responsible
    to collect data from surroundings. The data transmission platform is used to transmit
    the collected data to data processing center. The intermediate network connects
    data processing center and sensors through numerous routers and gateways. In WSN,
    the connections between sensors and gateways are established by wireless links
    and the ones between routers and gateways by wired links. It is obvious that the
    bottleneck of WSN is the wireless links of sensors because of their error-prone
    and fragile natures compared with wired links. Therefore, in this paper, we focus
    on the sensors and their wireless links to improve the performance of WSN. The
    mathematical models of data access in sensors and hybrid transmission of sensors’
    wireless links will be established in following sections. FIGURE 1. Overview of
    wireless sensor network. Show All B. Data Access Model The data access model is
    shown as in Figure 2. In this paper, we assume the WSN operates in slotted time.
    The sensors in WSN is denoted as a set N={1,2,⋯n} . At time slot t, the amount
    of data collected by sensor i(i∈N) is denoted as C i (t) which is counted in bit.
    It is worth noting that since the data collection process performed by different
    sensors in various environments are different, we do not assume C i (t) to have
    any statistical features or obey any stochastic process. Meanwhile, because of
    the limitation of data collection capability of sensor, we set the maximum value
    of C i (t) as C i max . It is immediate that 0≤ C i (t) ≤ C i max , i∈N . FIGURE
    2. Data access model. Show All In WSN, data processing center always expects the
    sensors to access and transmit as more data as possible. However, because data
    transmission capability of wireless links in WSN is limited, accessing too much
    data into WSN will definitely result in serious data congestion problem. Therefore,
    it is necessary to perform the data access control to adjust the amount of data
    entered into WSN. Based on the above considerations, we denote the amount of accessed
    data as A i (t) . Then we also have 0≤ A i (t)≤ C i (t) , i(i∈N) . C. Hybrid Transmission
    Model The hybrid transmission model is shown as in Figure 3. The amount of data
    transmitted to data processing center by sensor i(i∈N) is denoted as D i (t) .
    To facilitate data transmission in WSN, sensors are able to utilize numerous different
    wireless transmission approaches to perform data transmission, such as WiFi, microwave
    technology and millimeter-wave technology. Because different transmission approaches
    have different transmission characteristic, such as transmission bandwidth and
    rate, hybrid transmission control is therefore necessary to schedule the data
    backlogged in sensors over these transmission approaches. FIGURE 3. Hybrid transmission
    model. Show All The utilized transmission approaches are denoted as set M={1,2,⋯m}
    . The amount of data transmitted through approach j(j∈M) in sensor i(i∈N) is denoted
    as D ij (t) . It is obvious that D i (t)= ∑ j∈M D ij (t) . Meanwhile, the transmission
    capacity of transmission approach j(j∈M) in sensor i(i∈N) at time slot t is denoted
    as R ij (t) . The maximum value of R ij (t) is R ij max . Considering the error-prone
    and fragile nature of wireless links, we further denotes the data loss rate of
    transmission approach j(j∈M) in sensor i(i∈N) at time slot t as L ij (t) . Therefore,
    we have D ij (t)≤ R ij (t) L ij (t) . SECTION IV. Optimization Problem Formulation
    This section formulates the optimization problem based on the above established
    models. The considerations of energy consumption, data utility and network stability
    are also incorporated. A. Optimization Objective In WSN, accessing and transmitting
    large amount of information will be beneficial for fine-grained environment monitoring
    and controlling. However, it is also worth noting that too much data is also redundant.
    Therefore, the utility of the amount of data normally has diminishing returns
    property. Based on this consideration, we employ logarithmic function to depict
    the utility of accessed data, which is shown as follows: U( A i ¯ ¯ ¯ ¯ ¯ )=δln(
    A i ¯ ¯ ¯ ¯ ¯ +γ) View Source where δ and γ are positive constants; z ¯ ¯ ¯ denotes
    time-averaged value which is calculated as z ¯ ¯ ¯ = lim T→∞ 1 T ∑ t=0 T−1 z(t)
    . B. Constraints for Optimization Problem As for the data transmission in WSN,
    the first important constraint is to maintain the network stability of WSN and
    prevent the amount of backlogged data from unlimited growth. That is, we need
    to maintain the stability of sensors’ transmission queues as follows: Q i (t+1)=max[
    Q i (t)− D i (t),0]+ A i (t+1) (1) View Source where max[x,y]=x if x>y and y otherwise.
    In this paper, we define the stability of transmission queue as follows: lim T→∞
    sup 1 T ∑ t=0 T−1 Q i (t)<∞ (2) View Source Meanwhile, since the sensors are always
    placed at hard-to-reach environments. It is difficult to provide the sensors with
    permanent power sources. Therefore, sensors are always energy-limited. In this
    context, it is also necessary to establish a constraint about energy consumption.
    In general, the energy consumption of sensors’ network interface includes two
    parts. The one is consumed by the establishment and maintenance of data transmission
    links. This energy consumption is always a constant and it relates to the hardware
    and communication protocols, which is beyond the research scope of this paper.
    The other one is consumed by data transmission. We assume that transmitting one
    bit of data through transmission approach j(j∈M) in sensor i(i∈N) will consume
    a unit energy P ij . Then at time slot t , the total energy consumed by data transmission
    in sensor i(i∈N) through transmission approach j(j∈M) is W ij (t)= P ij ⋅ D ij
    (t) . Based on the above analysis, the energy consumption constraint can be formulated
    as follows: W ij ¯ ¯ ¯ ¯ ¯ ¯ ¯ ¯ ≤ W ij max ,j∈M View Source This constraint indicates
    that the time-averaged value of energy consumption of transmission approach j(j∈M)
    in sensor i(i∈N) should not be larger than the maximum value W ij max . C. Problem
    Formulation Based on the above analysis, now we formulate the initial optimization
    problem for WSN as follows: max A i (t), D i (t), D ij (t)  ∑ i∈N U( A i ¯ ¯ ¯
    ¯ ¯ ) s.t.  lim T→∞ sup 1 T ∑ t=0 T−1 Q i (t)<∞,i∈N W ij ¯ ¯ ¯ ¯ ¯ ¯ ¯ ¯ ≤ W ij
    max ,i∈N, j∈M 0≤ C i (t)≤ C i max ,i∈N 0≤ A i (t)≤ C i (t),i∈N D ij (t)≤ R ij
    (t) L ij (t),i∈N, j∈M (3) View Source In problem (3), the optimization objective
    means to maximize the utility of accessed data. The first constraint is to prevent
    the amount of accessed data from overwhelming transmission capacity so as to ensure
    the network stability of WSN. The second constraint is to maintain the data transmission
    consumption less than the pre-set maximum value. However, the problem (3) is difficult
    to solve because it contains numerous factors, such as energy consumption, queue
    stability, data access and hybrid transmission. These factors tightly correlate
    with each other. The intricate relationships between these correlated factors
    essentially make great trouble to derive optimal solutions for problem (3). Therefore,
    it is necessary to perform problem transformation and decomposition so as to derive
    optimal solutions. SECTION V. Problem Transformation & Decomposition This section
    performs transformation and decomposition for the initially formulated optimization
    problem. Three subproblems are derived which can be solved easily. A. Problem
    Transformation According to the Lyapunov function-based network optimization theory
    [30], the optimization objective of problem (3) is a nonlinear function of time-averaged
    value A i (t)(i∈N) . Therefore, we first need to establish an intermediate variable
    a i (t)(i∈N) which satisfies a i ¯ ¯ ¯ ¯ ≤ A i ¯ ¯ ¯ ¯ ¯ . With the help of a
    i (t) , the optimization objective of problem (3) can be transformed as ∑ i∈M
    U[ a i (t)] . Then we need to establish two virtual queues to perform transformation
    for the two constraints, i.e. W ij ¯ ¯ ¯ ¯ ¯ ¯ ¯ ¯ ≤ W ij max and a i ¯ ¯ ¯ ¯
    ≤ A i ¯ ¯ ¯ ¯ ¯ , where i∈N and j∈M . The built virtual queues are shown as follows:
    G ij (t+1)= H i (t+1)= max[ G ij (t)− W ij max ,0]+ W ij (t) max[ H i (t)− A i
    (t),0]+ a i (t) View Source The virtual queues transform the original constraints
    into queue stability constraints. Specifically, the constraints W ij ¯ ¯ ¯ ¯ ¯
    ¯ ¯ ¯ ≤ W ij max and a i ¯ ¯ ¯ ¯ ≤ A i ¯ ¯ ¯ ¯ ¯ can be held through maintaining
    the stability of G ij (t) and H i (t) , respectively. The proof is given as follows
    using the example of H i (t) . Proof:We can derive the following inequality from
    virtual queue H i (t) : H i (t+1)− H i (t)≥ a i (t)− A i (t) View Source Then
    we substitute positive integer values into variable t as follows: H i (1)− H i
    (0)≥ H i (2)− H i (1)≥ H i (T)− H i (T−1)≥ a i (0)− A i (0) a i (1)− A i (1) ⋮
    a i (T−1)− A i (T−1) View Source By summing the above inequalities and dividing
    by variable T , we can derive the following inequality: 1 T [ H i (T)− H i (0)]≥
    1 T [ ∑ t=0 T−1 a i (t)− ∑ t=0 T−1 A i (t)] View Source Let T→∞ . Then we can
    further obtain the following inequality: lim T→∞ 1 T [ H i (T)− H i (0)]≥ a i
    ¯ ¯ ¯ ¯ − A i ¯ ¯ ¯ ¯ ¯ View Source Conventionally, the initial queue length H
    i (0) is 0 or a bounded constant. Therefore, from the above inequality, it can
    be derived that the constraint a i ¯ ¯ ¯ ¯ ≤ A i ¯ ¯ ¯ ¯ ¯ is held when lim T→∞
    1 T H i (T)=0 . From the definition of queue stability, it is obvious that lim
    T→∞ sup 1 T ∑ t=0 T−1 H i (t)<∞ indicates lim T→∞ 1 T H i (T)=0 . That is, if
    the queue H i (T) is stable, then the constraints a i ¯ ¯ ¯ ¯ ≤ A i ¯ ¯ ¯ ¯ ¯
    can be held. Based on the problem (3) and the above transformations, now we obtain
    a new optimization problem which is shown as follows: max A i (t), a i (t) D i
    (t), D ij (t)  ∑ i∈N U( a i (t)) s.t.  lim T→∞ sup 1 T ∑ t=0 T−1 Q i (t)<∞,i∈N
    lim T→∞ sup 1 T ∑ t=0 T−1 H i (t)<∞,i∈N  lim T→∞ sup 1 T ∑ t=0 T−1 G ij (t)<∞,i∈N,
    j∈M  0≤ C i (t)≤ C i max ,i∈N  0≤ a i (t)≤ A i (t),i∈N  0≤ A i (t)≤ C i (t),i∈N  D
    ij (t)≤ R ij (t) L ij (t),i∈N, j∈M (4) View Source It is worth noting that the
    intricate relationships between the numerous factors considered in this paper
    are clarified in the form of queue lengths with the help of virtual queues H i
    (t)(i∈N) and G i (t)(i∈N,j∈M) and the intermediate variable a i (t)(i∈N) . The
    difficulty of designing problem solution is therefore reduced a lot. Such phenomenon
    also indicates that we are able to add more consideration factors and constraints
    into the original optimization problem (3) without the concern of mathematical
    intractability. Therefore, the analysis and optimization method implemented in
    this paper is of high scalability. B. Problem Decomposition Now we further decompose
    the optimization problem (4). The Lyapunov function is established as follows:
    L(t)= 1 2 ∑ i∈N ∑ j∈M { [ Q i (t)] 2 + [ H i (t)] 2 + [ G ij (t)] 2 } (5) View
    Source L(t) provides a holistic view of the queue stability. If one of the queues
    is unstable and becomes long, L(t) will increase accordingly. Only when all the
    queues become short, L(t) will decrease. Therefore, to solve the transformed problem
    (4), it is important to control L(t) at a small value. Meanwhile, decreasing L(t)
    is equivalent to minimize the increase of L(t) at each time slot. Based on such
    consideration, we further establish the Lyapunov drift function as follows: ΔL(t)=L(t+1)−L(t)
    (6) View Source Considering the optimization objective of transformed problem
    (4), we further formulate the drift-minus-objective function to simultaneously
    maximize the utility of accessed data and maintaining the stability of all queues.
    The drift-minus-objective function is shown as follows: ΔL(t)−V ∑ i∈N U( a i (t))
    (7) View Source where V is a positive variable. It is used to balance the tradeoff
    between data utility and queue stability. Intuitively, when the value of V becomes
    large, the utility of data is attached more importance and queue lengths will
    become longer correspondingly. On the contrary, when the value of V becomes small,
    queue stability is more important compared with the utility of data. To minimize
    the value of drift-minus-objective, its upper bound is first calculated as follows:
    ΔL(t)−V ∑ i∈N U( a i (t))≤ 1 2 B − ∑ i∈N [ H i (t) A i (t)− Q i (t) A i (t)] −
    ∑ i∈N ∑ j∈M [ Q i (t) D i (t)− G ij (t) W ij (t)+ G ij (t) W ij max ] − ∑ i∈N
    {VU[ a i (t)]− H i (t) a i (t)} (8a) (8b) (8c) View Source where B= ∑ i∈N ∑ j∈M
    [(1+ P 2 ij ) ( R ij max ) 2 +3 ( C i max ) 2 + ( W ij max ) 2 ]. View Source
    Then the following three subproblems can be derived from (8a), (8b) and (8c),
    respectively. Data access control problem max A i (t)  ∑ i∈N [ H i (t) A i (t)−
    Q i (t) A i (t)] s.t. 0≤ A i (t)≤ C i (t),i ∈N (9) View Source Hybrid transmission
    control problem max A i (t), D ij (t)  ∑ i∈N [ Q i (t) D i (t)− G ij (t) W ij
    (t)+ G ij (t) W ij max ] s.t. 0≤ D ij (t)≤ R ij (t) L ij (t),i∈N, j∈M D i (t)=
    ∑ j∈M D ij (t),i∈N, j∈M (10) View Source Intermediate calculation problem max
    a i (t)  ∑ i∈N {VU[ a i (t)]− H i (t) a i (t)} s.t. 0≤ a i (t)≤ A i (t),i∈N (11)
    View Source It is obvious that the above three subproblems are relatively simple
    and can be solved independently. Utilizing the solutions to these subproblems,
    the original problem (3) can be solved. SECTION VI. Stochastic Data Scheduling
    Mechanism In this section, SDSM is designed to solve the decomposed three subproblems.
    The optimality and implementation analyses of SDSM are also presented. A. SDSM
    Design The overview of SDSM is shown as in Figure 4. SDSM is composed of four
    components, including data access component, hybrid transmission component, intermediate
    calculation component and iteration component. Data access component is responsible
    for determining the amount of data to be accessed by sensors. Mathematically,
    it solves the subproblem (9) and obtain the optimal value of A i (t) . Hybrid
    transmission component solves subproblem (10) and derives the optimal value of
    D i (t) and D ij (t) . In physical sense, this component determines the amount
    of data to be transmitted through transmission approach j(j∈M) in sensor i(i∈N)
    at each time slot. Intermediate calculation component is used to solve the subproblem
    (11) and calculate the intermediate variable a i (t) so as to assist other components
    in making decisions. Iteration component updates the queue lengths of Q i (t)(i∈N)
    , H i (t)(i∈N) and G ij (t)(i∈N,j∈M) . FIGURE 4. The overview of SDSM. Show All
    During the operation of SDSM, the data access component, hybrid transmission component
    and intermediate calculation component first take queue lengths of present time
    slot as input and conduct their algorithms to obtain outputs. Then these outputs
    will further change queue lengths through iteration component. The changed queue
    lengths will then be used by the other three components to repeat their algorithms
    at next time slot. The detailed algorithms employed by data access component,
    hybrid transmission component and intermediate calculation component will be presented
    in following sections. B. Data Access Algorithm The subproblem (9) is used to
    determine the amount of accessed data at time slot t . This problem can be easily
    solved as follows: A i (t)={ C i (t), 0, if  H i (t)> Q i (t) otherwise, i∈N (12)
    View Source Equation (12) indicates that when H i (t)> Q i (t) , the amount of
    data backlogged at sensor i(i∈N) is small. Therefore, the sensor is able to access
    more data. The detailed data access algorithm is shown as in Algorithm 1. The
    complexity of Algorithm 1 is O(N) . Algorithm 1 Data Access Algorithm Show All
    C. Hybrid Transmission Algorithm Considering W ij (t)= P ij D ij (t) and W ij
    max is a constant, the optimization objective of subproblem (10) can be rewritten
    as follows: ∑ i∈N [ Q i (t) D i (t)− G ij (t) P ij D ij (t)] View Source This
    problem is difficult and complex because of the coupled variables D i (t) and
    D ij (t) . To solve this problem, we first assume that D i (t) is a determined
    variable and D ij (t) is unknown at time slot t . Then we have the following problem:
    min D ij (t)  ∑ j∈M G ij (t) P ij D ij (t) s.t.  D i (t)= ∑ j∈M D ij (t),i∈N,
    j∈M (13) View Source The problem (13) gives critical insight into allocating the
    data among transmission approaches j∈M in sensor i∈N . The solution of problem
    (13) can be formulated as follows: Allocate the data in sensor i∈N to the transmission
    approach j∈M with the shortest queue length G ij (t) . The above solution can
    also be presented mathematically as follows: D ij (t)={ D i (t), 0, if j=arg min
    j∈M [ G ij (t)] otherwise, i∈N (14) View Source Based on the above solution, the
    subproblem (10) can be rewritten as follows: max D i (t)  ∑ i∈N Q i (t) D i (t)−
    G i j ∗ (t) P i j ∗ D i j ∗ (t) s.t. 0≤ D ij (t)≤ R ij (t) L ij (t),i∈N, j∈M View
    Source where j ∗ =arg min j∈M [ G ij (t)] . This problem can be solved as follows:
    D i (t)={ min[ R i j ∗ (t) L i j ∗ (t), Q i (t)], 0, if  Q i (t)> G i j ∗ (t)
    otherwise (15) View Source The detailed hybrid transmission algorithm is shown
    as in Algorithm 2. The complexity of Algorithm 2 is O(N) . Algorithm 2 Hybrid
    Transmission Algorithm Show All D. Intermediate Calculation Algorithm We first
    formulate an auxiliary function based on the optimization objective of subproblem
    (11) as follows: f(x)=Vδln(x+γ)− H i x View Source The first and second order
    derivatives of f(x) are calculated as follows: f ′ (x)= f ′′ (x)= V+γ x+γ − H
    i − Vγ (x+γ) 2 View Source At first, f ′′ (x)<0 . It suggests that f ′ (x) is
    a monotonic decreasing function. So there is only one root of the equation f ′
    (x)=0 in interval x∈(−r,+∞) . The root is x r =Vδ/ H i −γ . Then we can conclude
    that function f(x) arrives at its maximum value when x= x r . Based on the above
    analysis, to solve the subproblem (11), we only need to let a i (t)=Vδ/ H i (t)−γ
    . The detailed intermediate calculation algorithm is shown as in Algorithm 3.
    The complexity of Algorithm 3 is O(N) . Algorithm 3 Intermediate Calculation Algorithm
    Show All E. Optimality Analysis The optimality of SDSM is analyzed in terms of
    time-averaged utility of data and network stability. Three important conclusions
    are also obtained, including utility conclusion, stability conclusion and tradeoff
    conclusion. 1) Optimality of Utility We first assume there exists a feasible control
    mechanism Ω which performs control operations on A i (t) , D i (t) , D ij (t)
    and a i (t) . Under these control operations, mechanism Ω has the following properties:
    A Ω i (t)− D Ω i (t)≤ a Ω i (t)− A Ω i (t)≤ W Ω ij (t)− W ij,Ω max (t)≤ ∑ i∈N
    U Ω ( a i (t))≥ ε,i∈N ε,i∈N ε,i∈N, j∈M ∑ i∈N U i max −ε View Source where ε is
    a positive real number and ∑ i∈N U i max is the maximum utility of data. Based
    on the above four properties of control mechanism Ω , the inequality (8) is reformulated
    as follows: ΔL(t)−V ∑ i∈N U( a i (t))≤ B 2 −V ∑ i∈N ( U i max −ε) View Source
    Substitute t=0,1,2,⋯,T into the above inequality and sum the derived inequalities.
    Then let T→∞ , we have the following inequality. ∑ i∈N U i max − ∑ i∈N U( a i
    (t)) ¯ ¯ ¯ ¯ ¯ ¯ ¯ ¯ ¯ ¯ ¯ ¯ ¯ ¯ ¯ ¯ ¯ ¯ ¯ ≤ B+2ε 2V (16) View Source From the
    inequality (16), we can draw the utility conclusion as follows: The difference
    between the maximum utility and the achievable utility of data will be less than
    B+2ε 2V . Meanwhile, the difference between the maximum utility and achievable
    utility is inversely proportional to the parameter V . When V becomes large, the
    utility of data will become better. 2) Optimality of Network Stability A similar
    assumption is made that a feasible control mechanism ω performs control operations
    on A i (t) , D i (t) , D ij (t) and a i (t) . Under these control operations,
    mechanism ω has the following properties: A ω i (t)≤ a ω i (t)≤ W ω ij (t)≤ ∑
    i∈N U ω ( a i (t))= D ω i (t)−ε,i∈N A ω i (t)−ε,i∈N W ij,ω max (t)−ε,i∈N, j∈M
    ∑ i∈N U ∗ i View Source where ∑ i∈N U ∗ i is the achieved utility of data under
    control mechanism ω . Based on the above four properties of control mechanism
    ω , the inequality (8) is reformulated as follows: ΔL(t)−V ∑ i∈N U( a i (t))≤
    1 2 B −V ∑ i∈N ∑ j∈M [ Q i (t)+ G ij (t)+ H i (t)]−V ∑ i∈N U ∗ i (17) View Source
    Substitute t=0,1,2,⋯,T into the above inequality and sum the derived inequalities.
    Then let T→∞ , we can derive the inequality as follows: ∑ i∈N ∑ j∈M [ Q i (t)
    ¯ ¯ ¯ ¯ ¯ ¯ ¯ ¯ ¯ ¯ ¯ ¯ + G ij (t) ¯ ¯ ¯ ¯ ¯ ¯ ¯ ¯ ¯ ¯ ¯ ¯ ¯ + H i (t) ¯ ¯ ¯ ¯
    ¯ ¯ ¯ ¯ ¯ ¯ ¯ ¯ ] ≤ B 2ε + V ε ∑ i∈N [ U i max − U ∗ i ] (18) View Source From
    the inequality (18), we can draw the stability conclusion as follows: The time-averaged
    queue lengths of Q i (t) , G ij (t) and H i (t)(i∈N,j∈M) are proportional to the
    parameter V . That is when V becomes large, the network stability will be decreased.
    Moreover, combining the utility conclusion with stability conclusion, we can obtain
    the tradeoff conclusion as follows: The parameter V is able to balance the tradeoff
    between the utility of data and network stability. Specifically, a large V will
    improve the utility of data and impair the network stability. On the contrary,
    a small V will be positive for network stability but negative for the utility
    of data. Meanwhile, the utility conclusion and stability conclusion also suggest
    that performing control operations to minimize the inequality (8) is able to maintain
    the network stability and maximize the utility of data. F. Implementation Analysis
    The implementation method and working procedure of SDSM is shown in Figure 5.
    Considering the two platforms of sensors, i.e. collection platform and transmission
    platform, the three algorithms of SDSM should be divided into two parts to be
    efficiently conducted by sensors. The first part is conducted by collection platform
    which includes data access algorithm. The second part is conducted by transmission
    platform which includes hybrid transmission algorithm and intermediate calculation
    algorithm. Meanwhile, the queue lengths of Q i (t) , G ij (t) and H i (t)(i∈N,j∈M)
    should also be maintained by the two platforms. Combining with the algorithm partition,
    the Q i (t)(i∈N) is recommended to be maintained by collection platform and G
    ij (t) and H i (t)(i∈N,j∈M) by transmission platform. FIGURE 5. Working procedure
    of SDSM. Show All Based on the above implementation method, the working procedure
    of SDSM at each time slot is illustrated as follows: Queue Length Initialization:
    Sensors initialize their queue lengths including Q i (t) , G ij (t) and H i (t)
    , where i∈N,j∈M . Data Access Control: The data collection platform of sensor
    (i∈N) first collects data from monitored environment. Then data access component
    takes Q i (t) and H i (t) as inputs to perform the Algorithm 1, i.e. data access
    algorithm. Finally, the collected data is transmitted to transmission platform.
    The amount of the transmitted data is A i (t) . In this step, a signaling overhead
    is consumed by acquiring the value of H i (t) from transmission platform. Hybrid
    Transmission Control: After receiving the data from collection platform, the hybrid
    transmission component in transmission platform takes Q i (t) , H i (t) and G
    ij (t) as inputs to perform the Algorithm 2, i.e. hybrid transmission algorithm.
    Then the received data is allocated over various transmission approaches and transmitted
    to data processing center according to D i (t) and D ij (t) . In this step, a
    signaling overhead is consumed by acquiring the value of Q i (t) . Intermediate
    Calculation: Intermediate calculation component in transmission platform conducts
    Algorithm 3, i.e. intermediate calculate algorithm, to calculate the intermediate
    variable a i (t) . Iteration: Based on the outputs of the three algorithms, the
    two platforms update the queue lengths they maintained and repeat the above procedure
    again at next time slot. From the above working procedure, it can be concluded
    that two signaling overheads are consumed during the working procedure of SDSM
    at each time slot. SECTION VII. Performance Evaluation The performance of SDSM
    is evaluated in this section through extensive simulations. During the simulations,
    the simulated WSN is composed of 400 sensors. We assume the process of data collection
    obeys to Poisson process and the average data collection rate of sensor is set
    as 900kb/ s . Each of the sensor employs three kinds of transmission approach,
    including WiFi, microwave technology and millimeter wave technology. In this paper,
    the transmission rates of the three transmission approach are set as 600kb/ s
    , 1.2Mb/ s and 100Mb/ s , respectively. The average data loss rates are correspondingly
    set as 5%, 10% and 80%. It is worth noting that the transmission rates and data
    loss rates are actually different in various communication environment. However,
    researching on the exact expression of transmission rates and data loss rates
    of different transmission approach is beyond the scope of this paper. Meanwhile,
    setting these parameters as constants is enough to evaluate the performance of
    SDSM. Therefore, we mainly perform the simulations using the relatively simple
    parameter settings to presents the performances of SDSM. It is also worth noting
    that the accurate and complex expressions of these parameters are also compatible
    with SDSM. Based on the similar consideration, δ and γ are set as 1. We first
    examine the effects of parameter V on the performance of SDSM, in terms of average
    queue length and average utility of data. During the simulations, the energy constraints
    of the employed transmission approaches are set as 5× 10 5 . The simulation results
    are shown as in Figure 6. Figure 6 first presents that the average queue length
    increases as V increases. Specifically, when V is less than 2500, the average
    queue length is growing rapidly. Then when V becomes larger than 2500, the average
    queue length almost remains stable and only increases with a small degree. In
    Figure 6, the average utility presents similar increase pattern with average queue
    length. With the increase of parameter V , average utility also increases. It
    increases fast when V is less than 2500 and almost remains stable when V is larger
    than 2500. From Figure VII, we can also observe that the increased V is positive
    for average utility but is negative for the network stability. Such phenomenon
    is coincident with the optimality analysis in Section VI-E. Therefore, the parameter
    V provides an efficient method to balance the tradeoff between network stability
    and average utility. Based on the above simulation results, we set V=1000 in the
    following simulations. This is because when V=1000 , the average utility can be
    improved a lot without great increment of average queue length. FIGURE 6. The
    effects of parameter V . Show All Figure 7 shows the effect of energy constraint
    on data transmission, queue length and average utility. As for the data transmission,
    it can be observed that the amount of total transmitted data increases with the
    increment of energy constraint. Meanwhile, the amount of transmitted data through
    microwave technology and WiFi first achieve monotonically increment with the increase
    of energy constraint and finally remains stable. The amount of transmitted data
    through millimeter wave technology arrives at its maximum value when energy constraint
    is about 1.1× 10 6 . Then it decreases a lot when energy constraint is in the
    interval [1.1× 10 6 ,3.6× 10 6 ] . Finally, it remains stable, too. Among the
    three transmission approaches, microwave technology has the largest amount of
    transmitted data and millimeter wave technology has the least. This is because
    millimeter wave technology has the highest transmission rate and highest data
    loss rate. The two features will greatly impair the network stability. Therefore,
    to maintain network stability, SDSM is prefer to utilize microwave technology
    which has higher reliability than millimeter wave technology and higher transmission
    rate than WiFi. As for the average queue length, it can be observed from Figure
    7 that it decreases with the increase of energy constraint. This is because with
    the increase of energy constraint, SDSM acquire higher transmission capability.
    The amount of backlogged data at each sensor is reduced. The average queue length
    consequently decreases. Figure 7 also shows that the average utility of data increases
    with the growth of energy constraint. This is because the increased energy constraint
    result in the increment of data transmission rate. It further leads to the increased
    amount of accessed data. Therefore, the average utility increases. FIGURE 7. The
    effects of energy constraint. Show All To further evaluate the performance of
    SDSM, we compare SDSM with Greedy Control Mechanism (GSM) and Congestion Control
    Mechanism (CCM). GCM accepts all of the collected data and transmits the data
    using the transmission approach with the shortest queue. CCM continuously detects
    network congestion [31]. When congestion is detected, the sensor will not access
    any data until the congestion is alleviated. The average queue lengths of the
    three mechanisms are compared in Figure 8. It can be observed that SDSM has the
    shortest average queue length and GCM has the longest. This is because SDSM performs
    the controls on both data access and data transmission. Therefore, it is able
    to maintain the queue length at a low level. As for GCM, it accesses all of the
    data without the consideration of the queue length and data transmission rate.
    Therefore, GCM’s average queue length is the longest. Meanwhile, CCM only reduces
    the amount of accessed data when congestion is detected. It cannot efficiently
    schedule the data over the transmission approaches. FIGURE 8. The comparison of
    average queue lengths. Show All The average utilities of the SDSM, GCM and CCM
    are compared in Figure 9. It can be observed GCM achieves the best average utility
    because it accesses all of the data. SDSM has the lowest average utility. This
    is because SDSM accepts the least amount of data. However, combined with Figure
    8, we can find out that GCM and CCM improve their average utilities with a serious
    impairment of queue stability. Specifically, GCM and CCM only improve their average
    utilities about 8.3% and 6.9% compared with SDSM. But their average queue lengths
    are increased about 127.7% and 72.3%. FIGURE 9. The comparison of average utilities.
    Show All The comparison of utility efficiencies of the three mechanisms are presented
    in Figure 10. The utility efficiency is measured by the average utility divided
    by the average amount of accessed data. It can be observed that the utility efficiency
    of SDSM is the best. GCM and CCM achieve the similar utility efficiency. This
    is because SDSM incorporate the considerations of data utility and queue stability
    when it performs the control operations. Therefore, it is able to access the appropriate
    and optimal amount of data so as to increase the achieved utility without the
    great increment of queue length. However, the other two mechanisms fail to incorporate
    such considerations. Even though they are able to access much more data, they
    cannot improve the data utility significantly and also lead to data congestions
    in sensors. FIGURE 10. The comparison of utility efficiencies. Show All Figure
    11 presents the comparison of energy consumptions between the three mechanisms.
    It can be observed that the SDSM consumes the least amount of energy and GCM consumes
    the most. This is because the SDSM performs the control operations with the constraint
    of energy consumption. It is able to transmit the data in a more efficient way.
    However, GCM and CCM make the data transmission decisions only based on the present
    queue lengths which is not sufficient to reduce their energy consumptions. FIGURE
    11. The comparison of energy consumptions. Show All Based on the above performance
    evaluations, it can be concluded that SDSM is able to reduce the average queue
    lengths and energy consumption. In terms of average utility, though SDSM cannot
    achieve the same performance with GCM and CCM, the utility efficiency of SDSM
    is the best. Therefore, the overall performance of SDSM is better than the other
    two mechanisms. Meanwhile, SDSM is cost-efficient in terms of data utility and
    energy consumption. SECTION VIII. Conclusion This paper focuses on the wireless
    links of sensors to improve the performance of WSN. Based on data access control
    and hybrid transmission control, we first formulate a mathematically intractable
    optimization problem. The problem incorporates the considerations of data utility,
    network stability, energy consumption and data loss rate. Then it is further transformed
    and decomposed into three subproblems through a Lyapunov function-based network
    optimization theory. SDSM is designed to solve the three subproblems which is
    composed of four components. Finally, the performance of SDSM is evaluated and
    it is also compared with GCM and CCM to demonstrate its superiority. Authors Figures
    References Citations Keywords Metrics More Like This Energy consumption optimization
    with Ichi Taguchi method for Wireless Sensor Networks 2014 2nd International Conference
    on Electronic Design (ICED) Published: 2014 An optimization model for the energy
    consumption of clustering protocol in wireless sensor networks 2013 Ninth International
    Conference on Natural Computation (ICNC) Published: 2013 Show More IEEE Personal
    Account CHANGE USERNAME/PASSWORD Purchase Details PAYMENT OPTIONS VIEW PURCHASED
    DOCUMENTS Profile Information COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION
    TECHNICAL INTERESTS Need Help? US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732
    981 0060 CONTACT & SUPPORT Follow About IEEE Xplore | Contact Us | Help | Accessibility
    | Terms of Use | Nondiscrimination Policy | IEEE Ethics Reporting | Sitemap |
    IEEE Privacy Policy A not-for-profit organization, IEEE is the world''s largest
    technical professional organization dedicated to advancing technology for the
    benefit of humanity. © Copyright 2024 IEEE - All rights reserved."'
  inline_citation: '>'
  journal: IEEE Access
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Stochastic optimization of data access and hybrid transmission in wireless
    sensor network
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Zhang B.
  - Wu Y.
  - Yu L.
  - Wang X.
  citation_count: '0'
  description: Wireless Sensor Networks have been applied in many fields such as environment
    monitoring, health care and smart home, but interference between concurrent transmissions
    may have impact on network performance. To reduce interference and enhance spatial
    reuse, multi-channel design is considered and appropriate scheduling algorithms
    is used. Most of previous works aim at reduce network latency and heighten network
    throughput. However, considering only these factors for industrial environments
    with deadline does not guarantee that some data flow will be transmitted to the
    destination node before the deadline. In this paper, we propose a flow-based channel
    and time slot scheduling algorithm (FCTS) which enables real-time data transmission
    by jointly considering channel assignment and time slot allocation. In the first
    stage, we perform channel allocation according to network interference collision
    model and the interference relationship of concurrent transmission to minimize
    the total number of network conflicts; in the second stage, we rely on data flow
    urgency degree and spatial reuse to assign the transmission slots for the data
    flow. Finally, the simulation results show that the proposed algorithm can achieve
    real-time data transmission and better network performance than compared algorithm.
  doi: 10.1109/SmartIoT.2019.00011
  full_citation: '>'
  full_text: '>

    "This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org
    IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal
    Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln
    Sign Out All Books Conferences Courses Journals & Magazines Standards Authors
    Citations ADVANCED SEARCH Conferences >2019 IEEE International Confe... Flow-Based
    Channel and Timeslot Co-Scheduling for Real-Time Data Aggregation in MWSNs Publisher:
    IEEE Cite This PDF Benhong Zhang; Yongzhao Wu; Lei Yu; Xiaoqian Wang All Authors
    124 Full Text Views Abstract Document Sections I. Introduction II. System Model
    and Problem Formulation III. Flow-Based Channel and Timeslot Co-Scheduling IV.
    Evaluation V. Conclusion Authors Figures References Keywords Metrics Abstract:
    Wireless Sensor Networks have been applied in many fields such as environment
    monitoring, health care and smart home, but interference between concurrent transmissions
    may have impact on network performance. To reduce interference and enhance spatial
    reuse, multi-channel design is considered and appropriate scheduling algorithms
    is used. Most of previous works aim at reduce network latency and heighten network
    throughput. However, considering only these factors for industrial environments
    with deadline does not guarantee that some data flow will be transmitted to the
    destination node before the deadline. In this paper, we propose a flow-based channel
    and time slot scheduling algorithm (FCTS) which enables real-time data transmission
    by jointly considering channel assignment and time slot allocation. In the first
    stage, we perform channel allocation according to network interference collision
    model and the interference relationship of concurrent transmission to minimize
    the total number of network conflicts; in the second stage, we rely on data flow
    urgency degree and spatial reuse to assign the transmission slots for the data
    flow. Finally, the simulation results show that the proposed algorithm can achieve
    real-time data transmission and better network performance than compared algorithm.
    Published in: 2019 IEEE International Conference on Smart Internet of Things (SmartIoT)
    Date of Conference: 09-11 August 2019 Date Added to IEEE Xplore: 14 November 2019
    ISBN Information: DOI: 10.1109/SmartIoT.2019.00011 Publisher: IEEE Conference
    Location: Tianjin, China SECTION I. Introduction Data aggregation is a fundamental
    operation in multi-channel wireless sensor networks (MWSNs) applications including
    some monitoring, health care and smart home [1]. In these applications, some nodes
    periodically send data to sink node, which needs to satisfy the maximization data
    collection rate and the minimization data delay. Data aggregation allows information
    or metric-related data to be aggregated and sent to the destination node, which
    reduces the amount of unnecessary retransmissions. In addition, interference between
    concurrent transmissions of data can cause severe performance degradation in wireless
    sensor networks (WSNs). Therefore, it is a very effective approach to reduce interference
    and increase spatial reuse through resource allocation. There are two primary
    factors in the data aggregation process: 1) improve resource allocation efficiency,
    and 2) reduce transmission delay. In MWSNs [2]–[3], adjacent node allocates different
    channel resources to reduce interference and increase the number of concurrent
    transmissions. However, due to the lack of channel resources, it is challenging
    to study channel allocation protocols with better network performance. In addition,
    it is also very difficult to have different channel nodes to eliminate interference
    and reduce network transmission delay in a dedicated time slot according to the
    TDMA protocol. The problem of insufficient channels has been widely researched.
    Channel assignment is presented to allocate channels to network nodes which aim
    to make each node gets optimal channel in the global networks [4]–[7]. Regret
    matching algorithm [8] considers the efficiency of network nodes while occupying
    different channels, and the complexity is high in order to switch to a more efficient
    channel for data transmission in the next time slot. In [9], the authors propose
    a MinMax channel allocation strategy to achieve data aggregation by minimizing
    the number of maximum conflicts of network nodes. TMCP [10] constructs the network
    structure into several subtrees that do not interfere with each other, and each
    subtree allocates different channel resources for data transmission. Cooperative
    scheduling of channel and time slot resources has become a hot research topic
    [11–12]. In [13], it is proposed to minimize the length of the network schedule
    by constructing a data collection tree and studying a channel time slot allocation
    method. Resource allocation scheme to minimize the number of channel switching
    proposed in [14]. In addition, the scheme first greedily completes the time slot
    allocation and then completes the channel allocation which is studied in [15].
    In MWSNs, most existing studies [10] [13] [16] [17] reduce network collisions
    by allocating different channels to all receiving nodes in the network, but there
    is no better consideration of channel allocation to reduce the total interference
    and time slot allocation to increase real-time and fairness of the network transmission.
    After the resources allocation, if a node cannot successfully transmit data relative
    to its generation period for some reason, which can make these data meaningless,
    and it will continue to occupy the time slot, which will result in wasting network
    resources and reducing the number of concurrent transmissions. Therefore, real-time
    resources allocation protocol is the focus of research in MWSNs. In this paper,
    we propose a flow-based channel and time slot co-scheduling algorithm (FCTS).
    Our contributions are summarized as follows. Table I List of Symbols. We propose
    a step-by-step resource allocation protocol that simplifies the complexity of
    the MWSNs scheduling problem and provides better network performance through channel
    and time slot co-scheduling. The proposed channel scheduling method minimizes
    the total number of network collisions by channel allocation based on the network
    interference collision model and the interference relationship of concurrent transmission.
    We design a time slot allocation algorithm based on data flow urgency and spatial
    reuse to assign transmission time slots for data flow, which improve network real-time.
    And the simulation results validate the performance of our proposed algorithm.
    The structure of this paper is organized as follows. Section II introduces the
    network model and problem definition. Section III proposes flow-based channel
    and time slot allocation algorithm for data collection in multi-channel wireless
    sensor networks. Section IV describes simulation environment and the performance
    of the proposed algorithm is evaluated by extensive simulations and experiments.
    Finally, Section V concludes this paper. SECTION II. System Model and Problem
    Formulation In this section, we analyze the model of multi-channel wireless sensor
    networks (MWSNs), and formulate multichannel and slot scheduling problems. We
    will summarize the symbols in Table I. A. Network Model The network model used
    in this paper consists of multiple sensor nodes and one sink node for data aggregation.
    The initial network structure graph is a non-directional G=(V, E) , where V consists
    all sensor nodes within the network, and E represents the set of communication
    links ET and interference links EI between the sensor nodes. The transmission
    range of all nodes is R, each node has one half-duplex transceiver that allows
    the sensor node to transmit or receive data. Any link e=(u, v) in ET indicates
    that u is the parent of v, any link e=(u, v) in EI indicates an interference link
    from u to v. Each sensor node has at least one path to sink through neighbors
    within its communication range. We assume that the network routing topology is
    known. Due to the open nature of the wireless channel during data transmission,
    if adjacent transmitting nodes use the same channel and transmit data in the same
    time slot, then the data transmission may generate conflict and the corresponding
    receiver cannot receive data normally. There are K orthogonal channels in the
    network, and the channel number is defined as c h i (1 ≤i≤K) . Each sender occupies
    an available channel for data transmission. The receiver switches to the channel
    of the sender for data reception when transmitting data, and the sink has K radio
    transceiver, each radio can receive packets on an independent channel. Here, we
    consider the conflict model of the protocol. There are two types of conflicts
    including structural conflict and interference conflict. The structural conflict
    occurs when two nodes u and v send data to node s or u receives and transmits
    data simultaneously. The interference conflict occurs when two nodes u and v transmit
    data on the same channel chi and the receiver is within the transmission range
    of u and v. B. Problem Formulation In the link-based channel allocation scheme,
    each sender obtains a fixed channel to send data to the parent node. When the
    network is initialized, all transmitting nodes occupy the same channel and then
    perform channel allocation by calculating interference collisions. Actually, the
    network will have conflicts after channel and time slot allocation, but different
    nodes have independent resources to eliminate and avoid these conflicts. 1) Resources
    assignment problem: The simultaneous allocation of system resources requires a
    comprehensive consideration of the conflicts caused by all resource allocations,
    which makes the network conflict structure model very complex, so that the expected
    performance can be achieved by step-by-step research. Channel allocation is implemented
    by constructing a linkbased interference conflict graph Gc for reducing inter-node
    interference conflicts. Where Gc is generated on the basis of the network topology
    G=(V, E) , we can assume a linkbase conflict-graph, denoted by G c =(V − {s},  E
    c ) , that V−{s} consists of all senders as nodes, and Ec is the set of interference
    links between nodes. Given the channel conflict problem, the definition of the
    data transmission collision edge set is given: Definition 1:Ec is the set of conflicting
    edges between the nodes transmitting data. For ∀ n k ∈V,∀u,v∈V−{s} , if the receiving
    node nk is the neighbor of u,v respectively, when u,v are on the same channel
    and send data at the same time, a collision will occur at nk. Then the conflicting
    edges set Ec composed of (u, v) is: E c ={(u, v)| n k  ∈N(u)∩ n k  ∈N(v)∩ ch (u)=ch
    (v), ∀u, v∈V−{s}} (1) View Source For example, Fig. 1(a) shows the network structure
    graph G, we use solid lines and dotted lines to indicate communication links and
    the interference links, respectively. Fig. 1(b) shows the interference conflict
    graph Gc, solid line indicates interference collision edge. Fig. 1. (a) Network
    structure graph G. (b) Interference conflict graph Gc. Show All The definition
    of the conflict value in the channel scheduling algorithm is established on interference
    conflict graph Gc. Definition 2: c u,v,c h i denotes collision value between nodes,
    indicating whether ∀v∈ N c (u) generates a co-channel collision with node u after
    allocating channel chi. The definition of c u,v,c h i is as follows: c u,v,c h
    i ={ 1, 0, v∈ N c (u)∩c h i (u)=c h i (v) otherwise (2) View Source where N c
    (u) is the set of neighbor nodes of node u in graph Gc, then calculate the number
    of node u collision values as: C(u, c h i )= ∑ v N c (u) c u,v,c h i (3) View
    Source Although channel allocation minimizes the total interference conflict of
    the network, there are still residual interference and structural conflicts. Then,
    the schedule conflict graph is constructed on the original network structure graph
    in which the channel is allocated, and finally the data flow transmission is completed
    by the slot scheduling. 2) Flow-based scheduling problem: If time slot is assigned
    to each node in the global network scale, some nodes fail to transmit data in
    the current time slot and the time slot resources are wasted. Therefore, we consider
    allocating time slots for the nodes where the data flow is located and transmitting
    the most urgent data flow preferentially, which improve the reliability of data
    flow transmission. At the same time, the secondary data flow that does not conflict
    is transmitted to improve the efficiency of network space reuse. We consider data
    flow based scheduling, and the related definitions of the data flow sets are as
    follows. Definition 3:The periodic flow set to be defined as F={ F 1 ,  F 2 ,…
    F m } , each flow F i =( T i ,  D i ,  φ i ) (4) View Source where Ti represents
    cycle of Fi, and Di represents its deadline from the source node to the sink,
    initial hypothesis D i = T i for each flow, φ i represents set of nodes in the
    data flow transmission path, and the path length | φ i | is the total number of
    hops of the data flow from the source node to the destination node. When the data
    flow is not scheduled for a long time, the transmission of the data flow becomes
    very urgent. In order to ensure that each data flow has the same scheduling opportunity
    and does not generate a long wait, the strategy in this paper is scheduled by
    calculating the urgency of the data flow. The definition of data flow urgency
    degree is as follows. Definition 4:uFi indicates the urgency of the data to be
    transmitted in time slots before the deadline. The minimum urgency is priority
    to transmit, by calculating the ratio of remaining deadline D i ´ and the remaining
    hops | φ i | for each flow. It is given by u Fi = D ′ i /| φ i |. (5) View Source
    Each data flow updates the current characteristics at the beginning of the next
    time slot, that is, when the data flow is transmitted in the current time slot,
    the corresponding remaining deadline D i ´ and remaining hops | φ i | are reduced,
    and if the data flow is not transmitted in the current time slot, the remaining
    deadline D i ´ is no change, but the remaining hops | φ i | is reduced. SECTION
    III. Flow-Based Channel and Timeslot Co-Scheduling The proposed algorithm is divided
    into channel allocation that minimizes total network interference conflicts and
    time slot allocation for data aggregation with improves network throughput real-time.
    This section describes the basic mechanism and operational procedure of flow-based
    channel and timeslot co-scheduling (FCTS) algorithm. A. Channel Allocation Note
    that MWSNs usually have a moderate number of channels (e.g., 16 channels for WSNs
    based on IEEE 802.15.4) [9], and due to blacklisting, noisy environment may further
    reduce the number of available channels. Therefore, there is not enough channel
    to remove all interference using the previous algorithm. In such a situation,
    we assign channel based on the sender to minimize the total network conflicts.
    Since multichannel scheduling problem is NP-hard [13], we propose such a channel
    allocation algorithm to solve this problem. Execute the algorithm by constructing
    an interference conflict graph Gc, we first calculate the number of neighbor deg
    v ( G c ) of each nodes v∈V−{s} , a non-incremental sequence Seq is generated
    by the deg v ( G c ) of each node v. Then we assign the first available channel
    chi to the node v with the largest deg v (Gc), satisfying chi(v) is different
    from the neighbors N (v) in Gc. If there is no available channel, the node v does
    not allocate channel and continues to allocate channels to other nodes in the
    Seq. The unallocated node u is assigned a channel that satisfies the minimum network
    interference. By calculating the conflict value C(u, c h i ) of the unassigned
    node u on all channels, then we assign chi with the smallest conflict value C(u,
    c h i ) to node u. Finally, this process is repeated until all nodes are assigned
    channel. Algorithm 1 Channel assignment Input: G C =(V−{s},  E c ) , K orthogonal
    channels. Output: Channel assignment for every node u∈V . 1: Calculate the deg
    v ( G c ) of each nodes v in G c ; 2: Add deg v ( G c ) to a non-incremental Seq;
    3: for v with maximum deg v ( G c ) in Seq do 4: if no available channel then
    5: Temporarily not assigning channels; 6: else 7: Allocate an available channel
    chi(v) different from N(v) ; 8: end if 9: end for 10: for u with no channel assigned
    do 11: Calculate C(u, c h i ) of u on all channels; 12: Select chi with minimum
    C(u, c h i ) assigned to the node u; 13: end for Algorithm 1 shows the process
    of the channel allocation algorithm. The channel is assigned to the sender according
    to the proposed algorithm, Fig.2(a) shows the interference conflict graph Gc,
    node c does not allocate channel after all available channels have been allocated,
    by calculating the node conflict value on each channel C(c, c h 1 )=1,C(c, c h
    2 )=2 , and channel ch1 with the smallest conflict value C(c, c h 1 )=1 is selected
    and assigned to the node c described in Fig.2(b). Fig. 2. (a) Interference conflict
    graph Gc. (b) Channel resources are allocated to each node according to channel
    allocation scheme. Two channels are not sufficient to eliminate all interference
    conflict, but the goal aimed to minimize the total amount of conflicts. Show All
    B. Time Slot Assignment There are two reasons why channel allocation in WSNs cannot
    completely eliminate all interference conflicts. Firstly, the number of available
    channels is so limited that it does not eliminate all interference conflicts.
    Secondly, each node is equipped with half-duplex radio to prevent node from transmitting
    and receiving data simultaneously, or prevent receiving data from two transmitting
    nodes simultaneously. Therefore, there are still residual interference conflicts
    and structural conflicts that need to be resolved in the network. These conflicts
    are avoided by time slot allocation, that is, the transmission of any two collision
    links are assigned different time slots. The previous step assigns the channel
    to node to obtain network structure graph G ′ shown in Fig.3(a), and construct
    schedule conflict graph G s =( V s ,  E s ) based on G ′ according to the conflict
    graph construction rules. As the example in Fig.3(b), where Vs is the set of all
    packet sender, E s is the set of interference edge. There are interference edges
    between flow nodes that have transmission conflicts, including interference and
    structural conflicts. Then, the time slot allocation scheduling enables conflict-free
    data transmission on the Gs. For example, there is structural conflict between
    node e and f, i.e., (e, f)∈ E s , similarly, node c sends data affecting node
    a receiving packet from node d, i.e., (c, d)∈ E s . In this algorithm, Fi sent
    by the current network node is placed into γ(t) according to the urgency uFi at
    the beginning of each time slot. Then, the urgent Fi with minimum uFi is arranged
    to be transmitted in the current time slot. If there are two data flows with the
    same urgency, select the priority transmission with the smallest remaining deadline.
    Continue to search γ(t) to find the secondary urgency uFj that does not conflict
    with Fi in the current time slot for scheduling, and repeat this process until
    the entire Gs is accessed. If the packet arrives at the destination node, it is
    deleted in γ(t) . If there is a new packet, it is added to γ(t) . And update the
    parameters of Fi in γ(t) , continue to execute the time slot allocation in the
    next time slot, and finally generate a schedule. Algorithm 2 shows the mechanism
    of the scheduling algorithm. Algorithm 2 Timeslot scheduling Input: G s =( V s
    ,  E s ) , Fi. Output: return schedule when the flow is successfully scheduled.
    1: for slot =0 do 2: Calculate uFi of Fi; 3: Sort uFi to generate a ready list
    γ(t) ; 4: for Fi in γ(t) do 5: Transmit unmarked Fi of minimum uFi; 6: Mark Fi
    and adjacent nodes in Gs as scheduled; 7: Continue to search the unmarked Fj in
    γ(t) ; 8: end for 9: if Fi reaches the destination node then 10: Delete it from
    γ(t) ; 11: end if 12: Update the Fi in γ(t) ; 13: Slot++; 14: end for Take Fig.3(a)
    for example. The data flows sent by the network nodes has F 1 − F 6 , get the
    ready list γ(t)={ F 1 ,  F 4 ,  F 2 ,  F 3 ,  F 6 ,  F 5 } according to the order
    of uFi, so node a transmits most urgent F1 in the current time slot. We continue
    to search the next conflict-free secondary urgent F6, i.e., node f transmits F6
    in the current time slot, this process continues until the entire Gs is accessed.
    In this example, F 1 , F 6 in node a,f can be transmitted in the current time
    slot. Fig. 3. (a) Network structure graph G ′ (b) Schedule conflict graph Gs.
    Show All SECTION IV. Evaluation This section performs simulation experiments to
    evaluate the performance of the FCTS. We use Java to conduct simulations. In the
    simulation experiments, we deployed 50-120 nodes to represent 50-120 sensors in
    reality, including a sink node, and the transmission range of each sensor node
    is set to 75m. The nodes are randomly deployed in a 750 m ∗ 750m region, and the
    ratio of data generated by each node is selected from the interval [0, 1]. We
    compare the proposed algorithm FCTS with the greedy slot and channel resource
    allocation algorithm MinMax [9] and LBFA [13]. In the simulation, we focus on
    the throughput, i.e., the amount of data, of the proposed algorithm at various
    network sizes. To demonstrate the performance of the multichannel algorithm, the
    number of channels is set between 1 and 5 to compare channel utilization. In all
    experiments, the number of nodes in the network was set to 60, and the ratio of
    data randomly generated by each node was selected from the interval [0, 1]. In
    the simulation results, each plotted node represents the geometric mean of 100
    data. In the simulation, when Fi is transmitted to the destination node before
    the deadline, then Fi is called valid data, and the valid throughput is obtained
    by calculating the number of valid data. The remaining deadline of the current
    packet is normalized, that is, standard deviation to reflect whether the packet
    has been scheduled for a long time. The flow utility value χ Fi is calculated
    as the ratio of the remaining deadline D i ´ and period Ti after each packet transmitted
    to the destination node, is defined as χ Fi = D ′ i / T i . (6) View Source If
    the utility value χ Fi of each packet is within a certain range, it is judged
    whether the data scheduling is reliable under the promise of real-time by calculating
    the standard deviation SDflow. And standard deviation we have S D flow = ∑ i=1
    i=m ( χ Fi − χ F ¯ ¯ ¯ ¯ ¯ ¯ ) 2 − − − − − − − − − − − −  ⎷   , (7) View Source
    where χ F ¯ ¯ ¯ ¯ ¯ ¯ represents average utility value of m flow. Data flow standard
    deviation SDflow determines whether flow scheduling is reliable, and the smaller
    standard deviation reflects utility value χ Fi within a certain range, each data
    can allocate time slots fairly under the promise of real-time. The smaller the
    SDflow, the better real-time and reliability of the system. System with this metric
    can reduce special data loss in MWSNs. A. Throughput at different data rates Here,
    we show how the ratio of node-generated data affects the performance of our proposed
    algorithm. Fig.4 shows the network valid throughput of the node data rate range
    from 0.2 to 0.8, respectively, while the network size is 750 m ∗ 750m, the number
    of nodes is 60, and the number of channels K= 2. It is clear that FCTS is superior
    to other algorithms because the overall performance of network channel allocation
    and the concurrent transmission of data packets are considered in the FCTS, when
    the number of interferences in the network is reduced by channel allocation, more
    data transmissions can Fig. 4. The network throughput changing with the ratio
    of flow. Fig. 4. The network throughput changing with the ratio of flow. Show
    All B. Throughput at different number of channels In this section, we show how
    the number of channels affects the performance of our proposed algorithm. Fig.5
    shows the simulation results taking into account the valid throughput generated
    in a WSN with channel number from 1 to 5, when the network size is 750 m ∗ 750m
    , the number of nodes is 60, and the data rate of the node is 60%. In the figure,
    we can clearly see that the performance of the FCTS algorithm is more prominent
    and superior to other algorithms. Network throughput brought by FCTS, LBFA or
    MINMAX is correspondingly increased as the number of channels increases, as more
    channel resources allow more data flows to be transmitted concurrently. The throughput
    of the network tends to horizontal value when the number of channels is sufficient.
    This is because after the number of channels is sufficient, the interference collision
    in the network can be completely eliminated, and the increase of the channel does
    not affect the network performance. C. Reliability at different data rate In this
    section, we show how the data flow ratio of sensor nodes affects the standard
    deviation of our proposed algorithm. Fig. 5. The network throughput changing with
    the number of channels. Show All Fig. 6. SDflow changing with the ratio of flow
    Show All Fig.6 shows the simulation results for the standard deviation of the
    equalization values for the flow ratios range from 0.2 to 0.8, respectively, when
    the network size is 750 m ∗ 750m , the number of nodes is 60, and the number of
    channels is 2. In the figure, it is obvious that FCTS is lower than other algorithms,
    and it has good resource scheduling reliability under the promise of real-time.
    In addition, when the ratio of data flow increases, the SDflow of the FCTS LBFA
    or MINMAX algorithm increases correspondingly, this is because the network data
    transmission delay increases after the network becomes congested, and it is impossible
    to ensure that all data flows receive a reliable resource allocation. SECTION
    V. Conclusion In this paper, we propose flow-based channel and time slot co-scheduling
    algorithm (FCTS) for real-time data aggregation in MWSNs. We design a two phase
    algorithm to assign channels and slots to nodes. In the channel allocation phase,
    we aim to minimize the total number of network conflicts through channel allocation
    according to network interference collision. Then we consider data flow urgency
    degree and spatial reuse to assign the transmission slots for the data flow, which
    improve real-time of network data transmission. Extensive simulation results demonstrate
    that FCTS better performance with higher throughput and lower latency than the
    most recently related algorithms. ACKNOWLEDGEMENT This work was supported by NSFC
    under grants 61701005 and Domestic Visiting Research Project of Excellent Young
    Backbone Talents from Anhui Provincial Universities under grants gxgnfx2019009.
    Authors Figures References Keywords Metrics More Like This Research on Wireless
    Sensor Network Localization Method for Real-Time System 2023 China Automation
    Congress (CAC) Published: 2023 Distributed Channel Allocation Protocols for Wireless
    Sensor Networks IEEE Transactions on Parallel and Distributed Systems Published:
    2014 Show More IEEE Personal Account CHANGE USERNAME/PASSWORD Purchase Details
    PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile Information COMMUNICATIONS PREFERENCES
    PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help? US & CANADA: +1 800 678
    4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow About IEEE Xplore | Contact
    Us | Help | Accessibility | Terms of Use | Nondiscrimination Policy | IEEE Ethics
    Reporting | Sitemap | IEEE Privacy Policy A not-for-profit organization, IEEE
    is the world''s largest technical professional organization dedicated to advancing
    technology for the benefit of humanity. © Copyright 2024 IEEE - All rights reserved."'
  inline_citation: '>'
  journal: Proceedings - 2019 IEEE International Conference on Smart Internet of Things,
    SmartIoT 2019
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Flow-based channel and timeslot co-scheduling for real-time data aggregation
    in MWSNs
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Liang W.
  - Long J.
  - Weng T.H.
  - Chen X.
  - Li K.C.
  - Zomaya A.Y.
  citation_count: '58'
  description: 'In complex vehicular cyber physical systems (CPS) network environment,
    there exist trust-based recommendation schemes that could effectively filter most
    of the false data. Though, these schemes may exhaust vehicular network resources,
    including energy, computation ability, and storage, causing a network outage.
    To ensure real-time data transmission and security in a vehicular CPS network,
    a novel trust-based recommendation scheme (TBRS) is proposed in this research.
    The main contributions presented in this paper are as follows: (1) The isomerism
    of vehicular sensor nodes in CPS networks, where the differences of mobility between
    normal nodes and selfish/malicious nodes are analyzed. Besides, a trust model
    is designed based on delivery credibility and position intimacy of nodes. This
    model can adjust the weight coefficient of direct trust parameters, which can
    be utilized to analyze the secure and trustable tasks in data transmission, and
    (2) To address attacks caused by selfish/malicious nodes and sparsity issues of
    nodes in vehicular CPS, a secure filtering algorithm based on K-Nearest Neighbor
    (KNN) cooperative computing is proposed. The trust value is calculated by the
    proposed trust model. The cooperative computing-based filtering algorithm is utilized
    to filter false recommendation trust values from selfish/malicious nodes, which
    greatly reduces interference of selfish/malicious nodes on the performance of
    vehicular CPS network. The way of calculating trust value cooperatively and recommend
    trust value makes the TBRS model more secure and reliable than previous ones.
    Experimental results show that the TBRS scheme is superior to the existing schemes
    in terms of delivery rate, transmission delay and reliability. Besides, the resistance
    against illegal eavesdropping attacks has increased by an average of 32.53% when
    compared to other algorithms.'
  doi: 10.1016/j.future.2018.09.002
  full_citation: '>'
  full_text: '>

    "Skip to main content Skip to article Journals & Books Search Register Sign in
    Brought to you by: University of Nebraska-Lincoln View PDF Download full issue
    Outline Highlights Abstract Keywords 1. Introduction 2. Related work 3. TBRS model
    4. Performance analysis 5. Experiments and analysis 6. Conclusions and future
    work Acknowledgments References Vitae Show full outline Cited by (61) Figures
    (13) Show 7 more figures Tables (2) Table 1 Table 2 Future Generation Computer
    Systems Volume 92, March 2019, Pages 383-398 TBRS: A trust based recommendation
    scheme for vehicular CPS network Author links open overlay panel Wei Liang a,
    Jing Long b, Tien-Hsiung Weng c, Xuhui Chen a, Kuan-Ching Li c, Albert Y. Zomaya
    d Show more Add to Mendeley Share Cite https://doi.org/10.1016/j.future.2018.09.002
    Get rights and content Highlights • A trust model is designed based on node’s
    delivery credibility and position intimacy. • A secure filtering algorithm based
    on KNN cooperative computing is proposed. • The filtering algorithm greatly reduces
    interference of selfish/malicious nodes. • Our scheme is superior in various performances
    including ability against attacks. Abstract In complex vehicular cyber physical
    systems (CPS) network environment, there exist trust-based recommendation schemes
    that could effectively filter most of the false data. Though, these schemes may
    exhaust vehicular network resources, including energy, computation ability, and
    storage, causing a network outage. To ensure real-time data transmission and security
    in a vehicular CPS network, a novel trust-based recommendation scheme (TBRS) is
    proposed in this research. The main contributions presented in this paper are
    as follows: (1) The isomerism of vehicular sensor nodes in CPS networks, where
    the differences of mobility between normal nodes and selfish/malicious nodes are
    analyzed. Besides, a trust model is designed based on delivery credibility and
    position intimacy of nodes. This model can adjust the weight coefficient of direct
    trust parameters, which can be utilized to analyze the secure and trustable tasks
    in data transmission, and (2) To address attacks caused by selfish/malicious nodes
    and sparsity issues of nodes in vehicular CPS, a secure filtering algorithm based
    on K-Nearest Neighbor (KNN) cooperative computing is proposed. The trust value
    is calculated by the proposed trust model. The cooperative computing-based filtering
    algorithm is utilized to filter false recommendation trust values from selfish/malicious
    nodes, which greatly reduces interference of selfish/malicious nodes on the performance
    of vehicular CPS network. The way of calculating trust value cooperatively and
    recommend trust value makes the TBRS model more secure and reliable than previous
    ones. Experimental results show that the TBRS scheme is superior to the existing
    schemes in terms of delivery rate, transmission delay and reliability. Besides,
    the resistance against illegal eavesdropping attacks has increased by an average
    of 32.53% when compared to other algorithms. Previous article in issue Next article
    in issue Keywords Vehicular CPS networkCooperative computingKNNTrust model 1.
    Introduction With the rapid development and closely interactions of vehicular
    wireless sensor networks and Internet-of-Things (IoT), there are many critical
    issues addressed to Cyber Physical System (CPS). The communication among nodes
    in vehicular CPS is typically implemented routing pattern of “store–carry–forward”,
    which complex network issues such as network division and delay [1] can also be
    coped with. In a hostile environment, CPS can transmit messages in a special way,
    where each node can provide services for the network by utilizing its own limited
    resources. Generally, the information thief may pretend to be the selfish or malicious
    node in vehicular CPS and which poses a great threat to network security. Selfish
    nodes make full use of network resources and collect information, though make
    no contribution to the network. The received data will not be forwarded, discarded
    after being received unfortunately. The purpose of malicious nodes is to destroy
    normal operations of the network, always distributing false trust values in the
    network and earn trust from other nodes. In this case, the malicious nodes will
    receive data from other nodes and discard them once attained their purpose, which
    behavior will interrupt network operation. In the worst case, it may cause a network
    outage, limiting resources such as storage, energy and communication opportunities
    in CPS that will be even scarcer [2], [3], [4], [5]. In case that vehicular CPS
    is attacked by selfish or malicious nodes, there will be a serious security problem.
    So far, trust management has been widely used as a technology to improve the vehicular
    network security. In a complex vehicular CPS network, the trust model is a crucial
    metric to evaluate network security [6]. Recently, combining trust management
    with the mobile model has been widely exploited [7], [8], [9], [10], [11], [12].
    Traditional trust model of CPS can be classified into two models, the direct trust
    model and cooperative computing-based trust model. The former trust relationship
    adopts a signal decision on nodes, easily causing decision error, while the latter
    cooperates with other nodes and computes their trust values, utilized to select
    next hop in network communication. Due to its features, data transmission in vehicular
    self-organized network can be described as Fig. 1. It includes two different scenarios,
    expressway and urban road. There are some assumptions in this network. Most of
    vehicles equip GPS system and navigation system. So, the information such as location,
    speed and movement direction of all vehicular nodes in the network can be obtained
    through GPS system. Each vehicular node can get the current location of target
    node by specific location service. Besides, there is a unique ID for each vehicular
    node. Vehicular CPS network is a real-time collection of IDs of neighboring nodes,
    which will be updated periodically by broadcasting. This collection can be used
    to determine whether vehicular nodes exist near the current vehicular node. When
    some accidents occur, the collection of neighboring nodes can be used for data
    transmission. During data transmission, if the communication link is disconnected,
    the current vehicular node will store the data and start the timer. Firstly, it
    will repair the communication link. If the communication link is connected again
    within the setting time of the timer, data transmission will continue. Otherwise,
    the current vehicular node will return a failure to original node and wait restoration
    of the communication link. If restoration is successful, the data will continue
    to be transmitted. Otherwise, original node will select a new path for data transmission.
    In a self-organized vehicular CPS system, selfish nodes and malicious nodes always
    directly affect the security of controlled physical object. Due to the characteristics
    of vehicular CPS network, this work proposes to calculate the direct trust value
    based on the grey correlation analysis. By analyzing the mobility of nodes and
    the differences between normal nodes and the selfish/malicious nodes, the parameters
    of contact intimacy, delivery reliability and position intimacy are chosen as
    the multi-dimensional trust parameters to calculate the direct trust value. The
    grey correlation algorithm is used to adjust the weight coefficient in the calculation
    of the direct trust value. The accuracy of calculating the direct trust value
    is improved. The proposed scheme can improve the network performance when there
    are selfish/malicious nodes in the vehicular network. Download : Download high-res
    image (383KB) Download : Download full-size image Fig. 1. Data transmission in
    different scenarios: (a) Expressway scenario and (b) Urban road scenario. The
    remaining of this paper is organized as follows. Section 2 introduces related
    work of secure trust model. Section 3 depicts a secure trust model to improve
    delivery rate, reduce energy consumption and enhance resistance against illegal
    attacks, as well discusses the design of multiple dimensional parameters for vehicular
    CPS feature and node mobility. The inner relationship between various factors
    is analyzed by using grey correlation, whereas the weight coefficient is calculated
    and dynamically updated. In addition, the direct trust value is calculated. Performance
    analysis in terms of anonymity and security are discussed in Section 4, and experiments
    to evaluate indicators of delivery rate, transmission efficiency and security
    conducted are depicted in Section 5. Finally, conclusion remarks and items of
    future work are presented in Section 6. 2. Related work Mobile ad-hoc network
    (wireless self-organized network) has features of dynamical topology and open
    wireless media. Such networks are prone to many security vulnerabilities. Pirzada
    et al. [13] proposed a trustable communication model for ad-hoc networks. This
    model realizes secure data transmission via an encryption algorithm. It can enhance
    reliability and credibility of data transmission. In a mobile self-organized network,
    data transmission between nodes lacks centralized management, thus causing a security
    vulnerability. To avoid attacks from malicious nodes, Xia et al. [14] proposed
    a dynamical secure trust prediction model. This model evaluates the credibility
    of nodes based on historical behaviors of nodes. The future behavior predicted
    by fuzzy logical rules is extended. This model can recognize malicious nodes and
    resist their attacks. Besides, it has good superiority in delivery rate and data
    transmission delay. Due to the lack of centralized management, serious resource
    limitation and dynamical network variety, trust management becomes a challenging
    task. Wei et al. [15] provided a trust management scheme, which can greatly improve
    the throughput and partition delivery rate. The delay and overhead in data transmission
    are also promoted, where Chen et al. [16] proposed a trustable protocol based
    on Quality-of-Service (QoS), showing good performance in security and reliability.
    Since vehicular ad-hoc network is widely concerned, many researches are focused
    in this field. Movahedi et al. [17] conducted trust management in MANET. Nevertheless,
    this method is not suitable for dynamic environments with many high-speed nodes,
    like vehicles. The moving speed of vehicles always makes identity verification
    information unable to be processed effectively. Many asymmetrical encryption methods
    are used in a secure authentication scheme to avoid this issue. Chuang et al.
    [18] introduced an authentication scheme based on distributed trust expansion,
    suitable for vehicular network and has good anonymity and security. However, due
    to the selfish and malicious nodes, the security of mobile self-organized network
    greatly reduces. In this case, a self-adaptive strategy is required to deal with
    such a change. The ART method is proposed to detect and cope with malicious attacks
    [19] and can evaluate the trust of both data and vehicular nodes. It has good
    resistance against attacks, by comparing to the proposed method, since ART may
    cause communication overhead in ensuring security and reliability of the nodes.
    Buchegger et al. [20] proposed a trust-based secure protocol for a mobile self-organized
    network. It can detect abnormal behaviors in network. Moreover, the automatic
    isolation will start if selfish/malicious nodes are detected. Han et al. [21]
    proposed a high-efficient multi-dimensional trust model in an underwater acoustic
    sensor network to resist attacks. It analyzes trust issues in the network link,
    data transmission and nodes. The subjective trust value and target trust value
    of sensor nodes are calculated. Experiments show that this model has good performance
    in evaluation accuracy and energy consumption by comparing to other models. Though,
    it does not consider the case of malicious nodes. Shabut et al. [22] proposed
    a route optimization based on multidimensional trust evaluation model in mobile
    ad-hoc networks. A reliable optimized path between nodes is provided, and experiments
    show robustness and accuracy of the trust model. Bernabe et al. [23] proposed
    a multi-dimensional trust-aware access control system for the Internet of Things.
    It is a flexible trust-aware access model, where the traditional access control
    system-based trust model is extended. Besides, relationship among QoS of the network,
    secure trust and trust device are considered. The abovementioned researches involve
    trust management and secure authentication protocol in vehicular networks. In
    this research, a trust model that considers multiple trust attributes is proposed
    to enhance security. Due to the mobility of vehicular nodes, the communication
    link may be disconnected with frequency. Data transmission in vehicular networks
    is realized by node encountering, which makes the end-to-end path unstable. This
    scheme mainly aims at network with sparse nodes in areas of the network, as depicted
    next. (1) Large delay and low delivery rate. In CPS network, there is no fixed
    transmission link. That is, the communication way of “store–carry–forward” exists
    large delay in each stage. Besides, the vehicular CPS network is always in traffic
    environment, and the transmission link is not stable due to the mobility of nodes.
    Therefore, it causes large delay and low delivery rate. (2) Vulnerability. The
    unstable transmission link path alsocauses other unpredictable risks. If there
    exist selfish and malicious nodes, serious threats will be imposed on network
    security. Moreover, due to the mobility of nodes or number of vehicular nodes,
    sparse nodes will include in some areas. Based on above analysis, the crucial
    issue in CPS is to design and optimize the secure trustable model for sensitive
    data forwarding between nodes. Despite many trust models have been proposed, it
    is a big challenge to identify a secure trustable forwarding mechanism to eliminate
    or decrease the influence of selfish or malicious nodes on CPS security. In complex
    vehicular CPS, the physical layer consists of sensors, actuators, computational
    unit and communication network, as shown in Fig. 2. As the physical layer controls
    physical object, sensors can percept the change of physical object and transmit
    the measured value to computation unit. The computational unit communicates with
    other nodes and completes data exchange via the communication unit, and the acquired
    data will be integrated next. The results can support the understanding of the
    environment and adjust the decision next, which will be sent to the executor.
    Finally, the physical object is changed accordingly. Thus, a closed loop is realized
    [24]. In this work, we mainly focus on data forwarding algorithm at the network
    layer of vehicular CPS. At present, data forwarding algorithms in vehicular CPS
    system can be divided into three categories as follows. • Vehicular CPS data forwarding
    based routing algorithm. As a node encounters another node, it will forward its
    data packet to the encountered node, despite not determining whether the node
    is the optimal forwarding node. Wang et al. [25] proposed erasure coding-based
    routing (EBR), where data is divided into blocks and inserted into network. In
    CPS, data array can be reconfigured as the target node collects enough data blocks.
    In [26], it utilized randomly mobile ubiquitous LAN extensions (MULE) in the sparse
    network to collect data from nodes. • CPS prediction-based routing algorithm.
    History information is utilized to predict the optimal forwarding node, as it
    can improve the delivery rate and reduce resource consumption. History records
    of node encounter and access to some areas are utilized in MV algorithm to compute
    the probability, which is used to forward data selectively. Yang et al. [27] proposed
    context-aware routing (CAR) algorithm, in which a node can calculate the delivery
    probability to the target node and exchange the delivery probability periodically.
    • Plan-based routing algorithm. In some application scenarios, nodes move as planned.
    Whether a node forwards data is also determined by the plan, such as message ferry
    (MF) algorithm [28], where Ferry nodes provide service of forwarding data packet.
    These nodes are mobile and collect data packets from the source node. The abovementioned
    routing algorithms assume that all nodes are cooperative in data forwarding. Though,
    there are some selfish nodes and malicious nodes in CPS environments in practice
    that are not cooperative in data forwarding. Therefore, coordination mechanism
    between nodes is required to ensure data transmission. Researchers introduce trust
    model in CPS routing protocol to realize cooperation of nodes. In trust model,
    trust table is utilized to maintain transmission probability between various nodes
    and target nodes, and the transmission probability is obtained on basis of historical
    interaction information between nodes. Trust mechanism selects related attributes
    of nodes as evaluation parameters, such as residual energy, available cache, node
    activity and communication probability with target node. There are direct data
    and recommended data due to different ways to gain evaluation parameters. Interactive
    information by direct contact is direct data, while recommended data is historical
    interaction records provided by other nodes, such as a receipt. Download : Download
    high-res image (442KB) Download : Download full-size image Fig. 2. Diagram of
    vehicular CPS structure. There are mainly two types of trust model in vehicular
    CPS. The former one is based on direct trust between nodes [29], [30], while the
    latter combines direct trust with recommendation trusts. • Direct trust based
    vehicular network trust model. It assesses trust value between two nodes based
    on their direct interactions. In [31], researchers set operation environment and
    parameters of trust model by comparative analysis. It greatly improves routing
    performance and reduces trust bias. But direct trust does not combine with recommendation
    trust. The role of direct trust is ignored in the proposed method. Trust model
    in [32] determines attributes of nodes on basis of the way to acquire evaluation
    parameters. The accuracy of trust model is improved by using time series analysis
    to dynamically adjust weight coefficient of evaluation parameters. However, the
    impact of the inner relationship between various attributes on CPS is not considered.
    In [33], the impact of human movement law on CPS is analyzed. On this basis, it
    offers a thought of using the multi-dimensional attribute in modeling, though
    the drawback is not considering selfish and malicious nodes. Besides, cooperative
    computing between nodes is ignored yet. • Trust model based on a combination of
    direct trust and recommendation trust. At present, many mobility models in CPS
    utilize direct trust and recommendation trust to assess the credibility of other
    nodes. At present, several algorithms have been proposed to address issues of
    false recommendation in CPS. But, it is not so effective in reducing or eliminating
    the impact of misbehaved nodes. In [34], the trust value is calculated by combining
    direct trust with recommendation trust. Time degenerative factor and time limit
    are introduced in this method. After the interaction, the nodes will be monitored
    whether the feedback reflects practical interaction result. The drawback is that
    only one single trust attribute is considered, and performance of nodes is subject
    to successful interaction times. Most of abovementioned trust models depend on
    a single parameter to calculate trust value. Selfish and malicious nodes are not
    considered and the cooperation between nodes is ignored. In CPS, the combination
    of direct trust and recommendation trust is a popular way in trust modeling to
    resist attacks of selfish and malicious nodes. Besides, multi-dimensional attribute
    and cooperation between nodes should be considered in future trust model. The
    critical problem in the creation of trust model in CPS is as follows. The structure
    of trust model should be improved to enhance the feasibility and security of CPS.
    Besides, trust evaluation algorithm between nodes should be designed to improve
    accuracy and effectiveness. How to use network resources for effective data transmission
    should also be considered to improve the delivery rate and reduce network transmission
    delay. • Traditional trust model in CPS calculates direct trust value by using
    the single parameter. It cannot completely reflect network attribute. However,
    one-dimensional trust evaluation is not sufficient to measure trust values between
    nodes in the network. There are many attributes impacting network performance,
    such as packet loss, security level, delay and limit energy. Especially, the impaction
    is obvious when a node has two trust attributes with a big difference. In order
    to measure trust of nodes in the network, this work proposes a multi-dimensional
    trust evaluation model on basis of tradition trust evaluation mechanism. • In
    most of existing trust models, the impact of the inner relationship between trust
    attributes on trust value is not considered. A few trust models consider multiple
    factors in CPS, but it is only simple weighting operation on various attributes.
    These weight values are obtained by experience. It is too subjective and cannot
    accurately describe trust value between nodes. In this type of models, some nodes
    with high trust value may exist trust defect, which is hidden by simple trust
    fusion. Consequently, it poses potential trust threat on CPS. • In CPS network
    with selfish and malicious nodes, we should make data successfully be sent to
    sink node. Therefore, it is critical to improve the delivery rate and reduce data
    transmission delay with less energy consumption. 3. TBRS model 3.1. Multi-dimensional
    trust parameter design The creation of multi-dimensional trust model has considered
    the selection of multi-dimensional trust attributes. It can deter the selfish
    and malicious behavior in vehicular CPS network. Trust model based on one-dimensional
    attribute may be one-sided and cannot reflect the overall performance. The trust
    model considering multi-dimensional trust parameter can make up the defect [35],
    [36], [37], [38], [39], [40]. The state of nodes in the network can be divided
    into single pattern and encountering pattern. The former one relates to the state
    of the node itself (such as energy, storage, processing ability), whilst the latter
    one describes behavior when a node interacts with other nodes or participates
    in network transmission. This work selects two important attributes, energy and
    storage in a single pattern. In encountering pattern, contact intimacy, delivery
    reliability and position intimacy are selected. The definitions are as follows.
    Definition 1 Contact intimacy. It is the intimacy when a node directly interacts
    with Sink node. Sink node is the base station in CPS network model. It can communicate
    with all nodes in vehicular CPS network. The goal of normal nodes is to send data
    to Sink node. If a node has higher contact frequency with Sink node, the contact
    intimacy will be higher. That is, the probability of transmitting data from this
    node to the Sink node is higher, and vice versa. The contact intimacy is calculated
    by (1). (1) Here, denotes contact intimacy. is contact frequency with Sink and
    is contact frequency with other nodes. Definition 2 Delivery reliability. It is
    the reliability of transmitting the data packet. Higher frequency of packet loss
    demonstrates lower delivery reliability and vice versa. Selfish nodes and malicious
    nodes will drop the packets after receiving. The delivery reliability can help
    to distinguish normal nodes with selfish or malicious nodes, as calculated by
    (2). (2) Here, is delivery reliability. denotes the number of forwarded packets.
    represents the number of received packets. Definition 3 Position intimacy. It
    relates to the intimacy of position of the current node to that of Sink node.
    The nodes are persons with equipment. The movements possess characteristics of
    human behavior. When a node is closer to Sink node, the probability to encounter
    Sink node is higher. Therefore, it is more probably to transmit data packets successfully.
    The position intimacy can be calculated as follow. (3) where is position intimacy.
    represents the distance to Sink node, and is the perimeter of the communication
    area. Direct trust value is calculated on basis of contact intimacy, delivery
    reliability and position intimacy. In this work, multi-dimensional trust attributes
    are considered as basic parameters to create trust model, as well improves network
    performance from many aspects. 3.2. TBRS trust model design Recently, issues in
    vehicular CPS are widely concerned, including secure data forwarding. To address
    these issues, many scholars proposed the concept of trust model. This model can
    be used to select a suitable next hop for data forwarding. In this case, the efficiency
    of communication in CPS in improved. In this work, we propose a trust model based
    on grey correlation and cooperative computing, including three modules, trust
    calculation, recommended trust calculation and direct trust calculation, as shown
    in Fig. 3. The proposed trust model utilizes direct trust and recommendation trust.
    The total trust value is cooperatively computed by neighboring nodes. It can avoid
    fault caused by an independent decision. Generally, data is transmitted by contacting
    and cooperating with neighboring. The interaction between nodes will be regarded
    as criteria of selfish or malicious nodes. Some malicious nodes in CPS may pretend
    to be the normal nodes, and thus, the total trust value of TBRS model considers
    direct trust and recommendation trust, which can be calculated as (4). (4) Download
    : Download high-res image (253KB) Download : Download full-size image Fig. 3.
    The structure of TBRS trust model. Here, is the total trust value, and are normal
    nodes in network, where represents evaluating node and is evaluated node. is the
    total trust value of node to node j. T is direct trust value, and is recommended
    trust value. The vehicular network can be divided into inner-domain network and
    inter-domain network. In inner-domain network, the direct trust table and recommendation
    trust table in current domain are stored into the nodes. When a transaction request
    is submitted, the inner-domain nodes read the direct trust table. If the trust
    value of the trust object exists, the choice will use the direct trust value.
    Otherwise, the table of recommendation trust value is accessed to find a node
    as the recommendation node, which has direct trust relationship with the trust
    object. The choice is determined by the recommendation trust value. The trust
    value of inter-domain nodes is a sum of the direct trust value and the recommendation
    value. The trust agency in each domain maintains the inter-domain trust value.
    The calculation of total trust value in (4), and are the inner-domain and inter-domain
    weight coefficients. When the weight value of the inner domain, we have . Otherwise,
    . On basis of grey correlation analysis, we have . It represents that the total
    trust value is calculated when the inner-domain nodes and the inter-domain nodes
    have the same importance in the model. is calculated as (5). , and are respectively
    weight coefficients of contact intimacy, delivery reliability and position intimacy.
    We have . These factors have various impacts on the network. Moreover, it is critical
    to select an appropriate weight coefficient to calculate the trust value. In this
    work, we use grey correlation in the calculation of trust value, and it can effectively
    isolate malicious nodes and selfish nodes. Data packets will not be transmitted
    to these nodes. Thus, the security of CPS is greatly enhanced. (5) Contact intimacy,
    delivery reliability and position intimacy will be various at different time yet
    for different nodes. Grey correlation analysis determines impact of factors or
    contribution to the system by utilizing grey correlation degree. The grey correlation
    degree is a measure of relationship among various factors. If the trends of two
    factors are consistent, the correlation degree is high and vice versa. Additionally,
    grey correlation analysis is a method to measure correlation between factors by
    considering similarity or dissimilarity on the development trends of factors.
    It is widely used in many fields and there are lots of improvements on the traditional
    model proposed by Deng [41]. Moreover, due to its characteristics, grey correlation
    analysis is applicable to samples regardless of size and regularity. It is flexible
    and suitable for small sample prediction or prediction with part known and part
    unknown information. The useful information is extracted from small sample. The
    correlation between factors is founded in the random sequence of the system. thus,
    the running trend and regular can be described and monitored accurately. The use
    of grey correlation model is unnecessary to know the inner mechanism of the system.
    The basic idea is to determine the correlation degree between factors based on
    the similarity between their sequence curves. The similarity is higher, the correlation
    degree between factors is bigger. The steps of grey correlation analysis are stated
    as follows. Step 1: Determine the referenced sequence: it reflects the behavioral
    characteristic of trust model in CPS. In this work, we select as referenced data
    array. Step 2: Determine the comparative sequence: it includes all factors with
    impaction on system behavior. The time sequence of contact intimacy, delivery
    reliability and position intimacy are selected as the comparative sequence. (6)
    Here, , , are respectively contact intimacy, delivery reliability and position
    intimacy at time of k. Step 3: Compute grey correlation coefficient ( ) of referenced
    sequence and comparative sequence by using (7). (7) where is resolution ratio,
    ranging from 0 to 1. The minimum and the maximum difference of the second level
    are respectively denoted by (min) and (max). The absolute difference of each point
    on comparative sequence and the referenced sequence is denoted by (k). Step 4:
    Calculate correlation degree: it reflects the correlation between comparative
    sequence and referenced sequence at various times. The data is sparsely distributed
    and not suitable for overall comparison [42]. Therefore, it is necessary to transform
    correlation coefficients of every point at various times into a value. The correlation
    degree can be calculated as follows. (8) With the value of correlation degree,
    values of , , are also computed. (9) Grey correlation degree reflects various
    factors affecting network performance and distributes appropriate weight coefficient
    for direct trust value in the model. Here, we consider another case. When a sink
    node is destroyed, the connection between nodes will be also interrupted. Namely,
    a node cannot communicate with other nodes within the communication range. The
    roadside infrastructure is trustable. To ensure the message in the destroyed node
    be transmitted safely and rapidly, the vehicular CPS network will use the urgent
    communication mode. When the neighboring sink node receives the message, it will
    be transmitted to the nearest roadside infrastructure. The roadside infrastructure
    will further transmit the message to the processing center. The concrete steps
    are described as follows. Step 1: If a node fails to transmit a message to the
    destroyed node, an urgent response will be generated to determine the level of
    the event. The message is forwarded to the neighboring sink node. Step 2: After
    the neighboring sink node receives the message from node , it firstly determines
    the event level using the event function . (10) is the utility function. is the
    time attenuation of the event function, is the period between current time and
    the time of the event, is the parameter and used to adjust the ratio of and the
    utility value. The value of is determined by the performance of the vehicular
    network. As in (10), larger indicates higher urgent level of the event. When the
    utility values are the same, the larger value of shows higher urgent level, which
    will be processed preferentially. Step 3: If it is a normal event, it will turn
    to the related processing algorithm. If an important event occurs, Step 4 is activated.
    Step 4: The received message is transmitted to the nearest roadside infrastructure
    using the communication between vehicles. Step 5: The infrastructure receives
    the message and broadcasts it. In this case, other nodes will not receive a duplicate
    message. Step 6: The infrastructure sends the message from the neighboring sink
    node to the processing center. In vehicular CPS networks, sink node can improve
    its trust value by forwarding messages, whereas other nodes can increase the trust
    value by monitoring the sink node. As a neighboring sink node receives and forwards
    the message from the destroyed sink node, the nodes in the cluster that connect
    with the sink node could forward the message by using the interface query technology.
    It can monitor the forwarding behavior of other nodes when a sink node is destroyed
    and resist the malicious nodes from tampering the message. The proposed scheme
    can monitor node communication in vehicular network. So, when the sink node is
    destroyed, the proposed scheme can increase the direct trust value of the forwarding
    nodes. Recommendation trust value is calculated by evaluating node and neighboring
    node cooperatively. As node evaluates node , it will send request to its neighboring
    nodes. The neighboring nodes receive the request and send the trust value with
    node to node i. Node collects the trust values and integrates them to gain a total
    recommendation trust value , calculated by (11). (11) Here, R is a collection
    of recommended nodes. is an element in R. Node makes decision cooperatively with
    evaluating node i. T (t) is the trust value of node to at time t. T (t) is the
    trust value of node to at time t. Suppose CPS is a network topology with many
    mobile nodes. There is no fixed point-to-point path in vehicular CPS since the
    normal nodes are mobile, and thus, CPS network topology is not fixed. In this
    case, the performance of the network can be improved by cooperative computing
    with neighboring nodes, whereas nodes in vehicular CPS move independently. At
    the start, the distribution of nodes is sparse, and the interaction between nodes
    is only a few. If data transmission only depends on direct trust, the decision
    fault will increase, and therefore, cooperative computing is necessary. The next-hop
    node is determined by current node and its neighboring node. Fig. 4 shows the
    network topology. Fig. 4(a) is the current network topology at time . Node intends
    to evaluate node j, and it needs to collect recommendation trust from neighboring
    nodes, e.g.,  , and provide recommendation trust value for node i. At time , network
    topology changes due to movement of nodes. In Fig. 4(b), neighboring nodes send
    position change. At time , node and are neighbors of node i, despite it is not
    the case at time . Nodes and are not neighbors of at time , but opposite at time
    . Thus, the network topology and neighboring nodes for cooperative computing change
    over time. The trust model is used for trustable relationship and certificate
    verification. Trust model in vehicular CPS network is primarily used in data transmission
    in vehicular routing. The next hop is selected according to the trustable relationship
    between vehicular nodes. Besides, abnormal behavior of selfish/malicious nodes
    should be also detected to reduce transmission delay and increase delivery rate.
    There are three types of objects in trust model: evaluating node, evaluated node
    and recommendation node. Evaluating node carries data and makes a decision on
    selection of the next hop to forward data. Evaluated node is the next hop node.
    The recommendation node will offer information about evaluated node for the evaluating
    node. In trust evaluation, evaluating node will assess the evaluated node by totally
    considering the direct trust value and recommendation trust value. The concrete
    steps of trust model are illustrated as follows. Step 1: Data is collected from
    vehicular nodes. In most cases, vehicular entity sends the request. Entities and
    will return the requested content to after receiving the request. This is a complete
    data collection procedure. Supposing the neighboring nodes of are , , , …, . Node
    collects the direct trust data from its neighboring nodes to the evaluated node
    j. The trust value of evaluating node to a recommendation node relies not only
    on the historical data, but also the direct trust value. Direct trust value between
    nodes is established on basis of interaction history, and the value can be calculated
    according to its evaluating criterion. Download : Download high-res image (227KB)
    Download : Download full-size image Fig. 4. Network topology. Step 2: Behavior
    evaluation and decision module make a decision on the evaluated nodes and receive
    the feedback. In most trust models, the decision always chooses nodes with high
    trust value. But in some special cases, the evaluated nodes are sparse, and nodes
    with low trust value will be selected to make the data be transmitted to target
    node. For example, the malicious node as recommendation node will magnify the
    direct trust value for its purpose. To avoid this problem, the selection results
    will be further evaluated. Finally, the collected data will be filtered to eliminate
    the false recommended data from malicious nodes. Step 3: Trust data processing,
    namely trustable calculation, is the most important and complex module in trust
    model. It processes the collected data and returns the result to behavior evaluation
    and decision module. The filtered data is used to calculate the recommendation
    trust value. Step 4: The minimum trust value in the recommendation link is selected.
    The ratio of each trust value in total trust value is calculated. The minimum
    ratio will be chosen to calculate the comprehensive recommendation trust value.
    The recommendation trust value is returned to the calculation module for further
    computation. 3.3. Cooperative computing-based false recommendation filtering algorithm
    Selfish and malicious nodes affect the normal operation of vehicular CPS. Malicious
    nodes distribute false recommendation trust. It interferes with the calculation
    of recommendation trust value, causing fault decision. Thus, recognizing and filtering
    false recommendation of malicious nodes is an important strategy to optimize trust
    model. In this work, K-Nearest Neighbor (KNN) algorithm [43] is utilized to filter
    received recommendation trust and compute total recommendation trust value. The
    basic idea of KNN algorithm is to determine K samples in unknown objects with
    characteristics closest to that of known objects. The objects of KNN algorithm
    are neighbors of a determined sample. According to the distance between the sample
    and its neighbors, K neighbors will be selected and regarded as the same type
    with the sample. With some known classified objects, an insertion of a new object
    will first calculate its distances to all known objects. K objects with the minimum
    distances will be chosen as samples. The new object belongs to the classification
    of the most objects among K samples. The concrete steps of KNN algorithm are illustrated
    as follows. (1) Calculate distance. The distance of a given object between other
    objects in training set is calculated, (2) Find neighbors. The neighbors with
    the nearest distance to the given objects will be chosen, (3) Make a classification.
    The main classification of chosen K objects will be used to evaluate the classification
    of the given object. KNN algorithm is suitable for recommendation, whilst not
    used for classification. We only adopt original idea of KNN algorithm to seek
    K similar content to the given content and recommend it to evaluating node. When
    evaluating node requests to neighboring nodes for recommendation trust, normal
    nodes send true data and malicious nodes send false recommendation trust. There
    are two cases due to a feature of malicious nodes. When an evaluated node is a
    normal node, the malicious node executes BMA attack and sends a low false recommendation
    trust to evaluating node. When an evaluated node is malicious, the malicious node
    sends a high recommendation trust value of the evaluated node to the evaluating
    node. Both above cases show that malicious nodes always distribute a lower or
    higher false recommendation trust value. There are some differences between true
    recommendation trust value and false recommendation trust value. Firstly, it is
    necessary to distinguish the recommendation trust value. Since the number of malicious
    nodes is small in vehicular CPS, we firstly calculate sample center with KNN algorithm
    to filter the small part of the false recommendation. As result, majority of recommendation
    values are true. Hence, the sample center is close to the true recommendation,
    which can be regarded as a referenced sample. Fig. 5 is the distribution of true
    recommendation of normal vehicular nodes and false recommendation of malicious
    nodes in an ideal situation. KNN algorithm is utilized to filter false recommendation.
    Red point denotes the sample center. Fig. 5(a) is sample distribution when the
    evaluated node is normal. Red node is the average of all recommendation trust
    value, namely, the center of all points in two-dimensional space. When K=4, four
    nodes with the minimum Euclid distance from themselves to the red node will be
    selected to cooperatively compute the recommendation trust value. Recommendation
    trust values from other nodes will be regarded as a false recommendation and filtered.
    Fig. 5(b) represents sample distribution when the evaluated node is selfish or
    malicious. The true recommendation trust value is lower but false recommendation
    trust value is higher. When K=4, four nodes with the minimum Euclid distance will
    be selected to compute recommendation trust value. The concrete steps to calculate
    recommendation trust value are described as follows. Download : Download high-res
    image (132KB) Download : Download full-size image Fig. 5. KNN algorithm to filter
    the false recommendation trust. (a) Evaluated node is normal node and (b) Evaluated
    node is selfish node or malicious node. Step 1: Euclid distance is a criterion
    to select recommendation parameters. At 1 stage, it is initialized to the maximum
    value. Step 2: Malicious nodes always provide recommendation trust value with
    big difference to that of normal nodes. Majority nodes in vehicular CPS are normal.
    Thus, we choose the sample center as referenced sample. Suppose the collected
    recommendation trust values of node include ( , ), ( , ), …, ( ). The referenced
    sample is ( , ). Step 3: The distances from each recommendation trust values (
    , ), ( ),…, ( ) to sample center ( ) are calculated, denoted by , ,…, . Step 4:
    We select samples closest to the sample center ( , ) from collected ones and calculate
    the maximum distance, denoted by maxdist. Step 5: Each node with the distance
    to sample center less than maxdist (namely, maxdist) will participate in the calculation
    of recommendation trust value, respectively denoted by ( , ), ( , ), …, ( ). The
    collected recommendation values are filtered by KNN algorithm. In ideal situation,
    the remaining data will be true. We suppose the coordinates of the filtered recommendation
    data are { ,…, }, here ( , ), ( , ), …, ( ). The recommendation trust value is
    the average of the filtered recommendation. So, the delivery reliability of recommendation
    trust is calculated by (12). (12) Contact intimacy of recommendation trust is
    calculated by (13). (13) The recommendation trust value is calculated by (14).
    (14) Here, and are weight parameters, where . The values of and are determined
    by the importance of delivery reliability and contact intimacy. In this work,
    both the attributes are important. Therefore, we set . 3.4. Trust based data forwarding
    The vehicular CPS network aims at transmitting data to sink node in a secure way.
    In this work, a trust model is proposed to achieve this goal. The trust value
    is calculated cooperatively with the neighboring nodes of the current node, whilst
    data will be transmitted to the neighboring node with the largest recommendation
    trust value. This procedure can be divided into two parts: next-hop selection
    and data forwarding. The collection of nodes in CPS is denoted by , and the concrete
    steps are described as follows. The pseudo code of vehicular data forwarding is
    described in Table 1. Step 1: Node broadcasts message M_ to find neighboring nodes
    periodically. After receiving the ACK messages from nodes, it determines whether
    these nodes are within its communication range. The collection of neighboring
    nodes of node is denoted by . Table 1. Pseudo code of vehicular data forwarding.
    Step 2: Supposing that node encounters node at some time, it judges whether is
    Sink node. If so, it will forward data packet directly. Otherwise, the total trust
    value needs to be computed. It determines whether the data packet is forwarded
    to . Step 3: Node collects trust values from neighboring nodes. If is the largest,
    data packets will be forwarded. Otherwise, data packets will be transmitted to
    the neighboring node with the largest total recommendation trust value . Step
    4: Update the forwarding table if a new next-hop is selected and transmit data
    packet of node to the selected next-hop. Step 5: Steps 1–4 are repeated until
    the data packet is successfully transmitted to Sink node. As Sink node receives
    the data packet, it broadcasts a message to delete the redundancy of the received
    data packet. Step 6: The redundant data packets in all nodes will be deleted.
    Until now, the data forwarding completes. Let the vehicle nodes in network be
    moving. The path can be predesigned so that the vehicles can predict the traffic
    congestion situation. Firstly, a random node is selected. The calculation of initial
    direct trust value of vehicular node is closely related to the recommendation
    trust value. The recommendation trust value will affect the update of direct trust
    value, as (15). (15) represents the interaction times of recommendation trust
    node and node . illustrates there is no interaction between node and other nodes.
    In this case, the initial direct trust value is set as 0.5. The parameter indicates
    the accuracy of recommendation trust value. The higher the accuracy is, the larger
    the recommendation trust value will be. is calculated as (16). (16) is the standard
    deviation of recommendation trust value between the recommendation node and node
    . Let , we have . is the average recommendation trust value. is the number of
    recommendation nodes. When , the recommendation node is regarded as trustable
    in the current interaction. The recommendation trust value will add . Otherwise,
    it is not trustable and the recommendation trust value will reduce by . In this
    case, the trust value increases slowly and reduces rapidly. So, the nodes in vehicular
    network will be evaluated when the trust mechanism is unknown. Besides, the vehicular
    nodes move with the limitation of the road. It is not random. When the accuracy
    of an unknown node is high, it can pass the real-time security and trust authentication.
    4. Performance analysis 4.1. Anonymity In vehicular CPS, selfish nodes and malicious
    nodes pose a great threat to network security. Selfish nodes do not forward data
    packets, causing a decrease of delivery rate. Malicious nodes generate false recommendation
    trust value. In this case, a node transmits data to a wrong next-hop node, increasing
    routing overhead and prolongs delivery time. Usually, each data transmission cannot
    be related to the real identity of the node. Due to a node sending always a false
    name to authentic part, attackers cannot retrieve real identity of nodes if there
    is no anonymity stealing. Besides, they cannot trace real information about nodes.
    For attacks in the medium path, each authentication request adopts group broadcasting,
    which does not omit communication anonymity. In this work, the vehicular nodes
    are anonymized. Illegal attack nodes can be traced by communication records in
    authentication. Before data transmission, nodes need to be authenticated by an
    arbitrate node. In such authentication stage, the identity information is divided
    into several parts and distributed to several nodes. Real identity is related
    to false identity, and such relationship will be reserved in forthcoming authentication.
    If the attackers perform anonymity attacks and search resource in non-neighboring
    nodes, the credit evidence can still find the attack trace, which can be used
    to find the attack nodes by the third party. 4.2. Network security There are four
    parameters to evaluate the performance of vehicular CPS, respectively delivery
    rate, transmission delay, routing overhead, and security. Illegal attackers carry
    out attacks by deploying sensor nodes or capturing nodes in the network. Deployed
    nodes can pretend to be normal nodes in the network and steal confidential data
    or inject false data into the network. Besides, if the normal nodes are captured,
    the data stored in these nodes will be also stolen. The illegal attackers can
    send lots of false data by using these nodes, and rapidly exhausts network resources,
    such as energy, bandwidth, computation ability and storage. If being attacked,
    rapid restoration and authentication are required. In this section, we mainly
    analyze the security in terms of counterfeit, tampering and collusion attacks.
    • Resistance against counterfeit attacks. A node will send a data packet with
    its false name. Thus, other nodes cannot forge the false name of . Otherwise,
    it cannot pass the cooperative authentication. To forge the identity of is equal
    to an attack on SHA-1 hash function. • Resistance against tampering attacks. The
    encryption key is produced by regenerating code, whilst the authority of decryption
    is the limit, even the data sender cannot tamper the data. Besides, attackers
    know nothing about the key, and thus, it is unable to forge or tamper the content.
    The encryption key needs authentication of multiple network nodes. A single node
    authentication cannot tamper the content. • Vehicular CPS network is self-organized.
    Attackers can carry out collusion attacks. In this work, we divide sensitive information
    into blocks and make them be authenticated in nodes with high reliability, which
    reduces dependence on the third party. If the attackers intend to restore the
    secret, the polynomial ( ) with orders should be resolved. On basis of Lagrange’s
    interpolation, the attackers need to obtain enough interpolation values. That
    is, a successful attack requires to colluding with nodes. Generally, it is difficult
    to collude with huge number of nodes. In other words, the proposed scheme can
    restore secret even nodes are not cooperative. In vehicular CPS environment, a
    trust model can ensure better security. Download : Download high-res image (274KB)
    Download : Download full-size image Fig. 6. The structure of ONE [44]. 5. Experiments
    and analysis To evaluate the effectiveness of the proposed vehicular trust model,
    ONE simulator, a java based open-source simulator developed by Nokia research
    center in Finland [44] is utilized in experiments. The structure of ONE is shown
    as Fig. 6. It can simulate in various network scenarios, such as VDTN, RMRV, RCAR
    and AODV. The VDTN can make the delivery rate of data transmission be largest
    and reduce the transmission delay. It is regarded as criteria of delivery rate
    and delay. RMRV is based on scheduling strategy and can be used as comparative
    reference of prediction forwarding. RCAR is a forwarding strategy-based algorithm,
    which minimizes energy consumption and can be considered as a standard in energy
    consumption. AODV is a direct interactive trust model based on multi-dimensional
    trust, in which demonstrates the importance of multi-dimensional parameters to
    CPS, and therefore, it can be comparative to trust model [45], [46]. In this section,
    the number of selfish nodes and malicious in the simulated network is denoted
    by , and the evaluation metrics include delivery rate, transmission delay, routing
    overhead and security. The simulation parameters in experiments are set as Table
    2. Table 2. Vehicular network simulation parameters. Parameters Value Area 5 km
    3 km Movement speed of nodes 5 30 m/s Transmission speed 250 kB/s Number of nodes
    200 Number of selfish/malicious nodes 20/40 Cache 25 MB Communication radius of
    nodes 20 m Update period t of trust 3.5 s Movement model SPMBM 5.1. Packet loss
    evaluation In this section, we evaluate the packet loss rate for vehicular nodes.
    Here, three methods including ATSR [47], GPSR [48] and KNN are selected for evaluation.
    In ATSR routing protocol, only the nodes with good credibility are selected to
    forward messages to sink node. The nodes set a threshold to monitor the behaviors
    of the neighboring nodes. The trust values of the neighboring vehicular nodes
    are generated based on the credibility of a node. These trust values can be used
    to detect the credibility and recommendation trust recommendation of forwarding
    message. In GPSR protocol, a node sends a packet and then it waits until a neighboring
    node forwards the packet. If the packet is successfully forwarded, the node will
    store a trust value of the neighboring node, which can be used for routing decisions.
    While KNN can effectively filter the recommendation information in vehicular nodes,
    it can recognize the false information and malicious nodes in recommended vehicular
    nodes. Finally, the true recommendation information is determined. In KNN method,
    the network throughput can be effectively improved. In this section, we compare
    the packet loss and the mean packet latency of KNN, GPSR and ATSR. The result
    is shown in Fig. 7. In Fig. 7(a), when there is no malicious node, the packet
    loss is zero for three methods. With the increase of the malicious nodes, the
    packet loss rates increase accordingly. But the packet loss rates of GPSR and
    ATSR are greater than that of KNN. As GPSR and ATSR cannot recognize the malicious
    nodes, so the shortest routing path is selected for communication. If malicious
    nodes exist, the packet loss rates of both methods will obviously increase. KNN
    introduces the trust mechanism and selects the node with the largest trust value
    as the next hop. It can avoid malicious node participating in data forwarding.
    Therefore, the packet loss will be lower than the comparative methods. Fig. 7(b)
    shows the comparison result of mean packet latency. Due to the trust recommendation
    selection, KNN has good performance in mean packet latency. With the increase
    of vehicular nodes, the mean packet latency of GPSR and ATSR become larger. In
    ATSR, more vehicular nodes cause more messages of broadcasting the network topology.
    There are more collisions in packet transmission. So, the end-to-end latency increases
    accordingly. In GPSR, large number of vehicular nodes leads to redundancy in finding
    the optimal paths, which finally causes the increase of end-to-end latency. Download
    : Download high-res image (351KB) Download : Download full-size image Fig. 7.
    The evaluation of packet loss for vehicular nodes (a) The comparison of packet
    loss(%) (b) The comparison of mean packet latency (%). 5.2. Delivery rate As experiments,
    ONE simulator was selected for evaluations, where selfish nodes and malicious
    nodes will hinder normal operation of CPS. To evaluate the resistance against
    selfish nodes and malicious nodes, different ratio of selfish /malicious nodes
    and normal nodes are set in the network environment, and experimental results
    are compared to other algorithms for network performance evaluation purposes.
    In this experiment, two types of vehicular network models with 200 nodes were
    designed, and evaluations of delivery rate were performed in both models. One
    network has 20 selfish/malicious nodes and 180 normal nodes, and another one contains
    40 selfish/malicious nodes and 160 normal nodes, and the evaluation results are
    shown in Fig. 8(a) and (b). With increase of time and resource consumption, delivery
    rate of various routers decreases. At the initial stage, VDTN has the highest
    delivery rate, and decreases promptly due to rapid resource consumption. The proposed
    scheme adopts multi-dimensional parameters and considers various factors with
    impact on network performance. The trust value is calculated cooperatively with
    neighboring nodes. Besides, it can resist attacks of selfish nodes and malicious
    nodes. In Fig. 8(a), the proposed scheme has higher delivery rate by comparing
    to RMRV and RCAR. AODV utilizes direct trust, making a single trust decision with
    lower accuracy, leading to a lower delivery rate. As shown in Fig. 8(b), the delivery
    rate of all algorithms or models decreases with the increase of resource consumption,
    with . It is noted a dramatic decrease in VDTN, while the proposed algorithm depicts
    a high and relatively stable delivery rate. Download : Download high-res image
    (350KB) Download : Download full-size image Fig. 8. Comparison of delivery rate
    when (a) and (b) . 5.3. Transmission delay Transmission delay reflects the efficiency
    of data transmission, since data is expected to be rapidly transmitted to sink
    node with least transmission delay and minimal routing overhead. Firstly, we conduct
    experiments to evaluate transmission delay and the results are shown in Fig. 9.
    Fig. 9(a) and (b) are respectively average delay when and . At the initial stage,
    VDTN has the lowest average transmission delay. With the increase of simulation
    time, the average delay increases. The proposed scheme has the lowest average
    delay when compared to AODV, RMRV and RCAR. Moreover, RCAR depends on only one
    node moving to Sink node and transmitting data, incurring higher delay. The proposed
    scheme calculates trust value by reference to the current routing table, simplifies
    the decision and reduces transmission delay. Comparison of Fig. 9(a) and (b) shows
    that the average delay time will be larger with the increase of selfish nodes
    and malicious nodes. To evaluate the effects of vehicular speed on transmission
    delay, we simulate two scenarios. In the first scenario, we set the vehicular
    speed as 20 m/s–30 m/s (at expressway). Fig. 10(a) shows the relationship between
    the total transmission delay and vehicular speed with forward communication in
    expressway scenario. With different transmission hops of vehicular nodes, the
    total transmission delay becomes larger with the increase of speed. Higher speed
    makes the vehicular node move long distance to reach communication range of the
    neighboring vehicular nodes. More transmission hops increase the total delay.
    The relationship between the total transmission delay and the speed with backward
    communication in expressway scenario is shown in Fig. 10(b). The trends of both
    forward communication and backward communication are similar. It demonstrates
    TBRS algorithm could effectively address the disconnection of communication link
    during data transmission. Download : Download high-res image (349KB) Download
    : Download full-size image Fig. 9. Comparison of the average delay when (a) and
    (b) . Similarly, we set the speed as 5 m/s–15 m/s (within the speed range of urban
    traffic). The simulations of forward communication and backward communication
    are conducted, and the results are respectively shown in Fig. 10(c) and (d). Higher
    speed will also cause the increase of total delay. But due to the speed is much
    lower than that at expressway, the transmission hops will be less. So, the total
    transmission delay with forward and backward communications reduces by comparing
    to that at expressway. The experiments show the TBRS algorithm is more suitable
    for urban traffic environment. Download : Download high-res image (458KB) Download
    : Download full-size image Fig. 10. Relationship between the total transmission
    delay and vehicle number under various vehicle speeds. (a) Forward communication
    at expressway (b) Backward communication at expressway (c) Forward communication
    at urban road and (d) Backward communication at urban road. 5.4. Routing overhead
    Routing overhead is another indicator to evaluate transmission efficiency. It
    is compared to other four algorithms, as shown in Fig. 11 with and . RCAR is a
    single-copy routing algorithm, which routing overhead can be ignored. The proposed
    algorithm filters majority of selfish nodes and malicious nodes in the selection
    of next hop, and only those nodes with high trust value are selected as the next
    hops. Hence, it greatly reduces the routing overhead. The VDTN algorithm is flooding,
    where data packets will be transmitted to nodes contacted with the current node
    until successfully transmitted to the Sink node. Thus, VDTN has the highest routing
    overhead. As shown in Fig. 11(a) and (b), with the increase of , the routing overhead
    becomes larger, and thus, the increase of selfish/malicious nodes will directly
    cause larger routing overhead. In experiments, the performance of vehicular CPS
    decreases with the increase of selfish nodes and malicious nodes. Though, many
    experiments show that the proposed algorithm has less delay and overhead in a
    hostile environment. Besides, it has better performance in resistance against
    selfish nodes and malicious nodes. Download : Download high-res image (364KB)
    Download : Download full-size image Fig. 11. Comparison of vehicular routing overhead
    when (a) and (b) . 5.5. Security evaluation The vehicular CPS network is a new
    type of mobile network. Different to traditional network, it does not depend on
    any fixed fundamental facility and management center. The network connection and
    data transmission are realized by interactions among nodes and self-organization.
    Due to its self-organization and mobility of nodes, CPS network is vulnerable
    to be attacked. The malicious nodes will tamper routing information and the target
    node will receive the false information. If the malicious nodes perform attacks
    successfully, they can tamper the forwarded data packets for their purpose. In
    this work, we simulate the forgery attacks in the experiments, as well the routing
    information is tempered by adding the selfish/malicious nodes. So, the target
    node will receive the false routing information. The performance of the proposed
    model is evaluated next, in this section. The TBRS algorithm selects K recommendation
    trust values from the collected ones to calculate the recommendation trust value,
    and KNN algorithm is utilized to filter false recommendation first. The effectiveness
    of this algorithm depends on K value to some degree [49], [50]. If K is small,
    recommendations from neighboring nodes will be fewer, so there are fewer nodes
    for cooperative computing [51], causing lower accuracy of the decision. On the
    other hand, larger value of K makes recommendations with more false recommendation
    trust values. It also causes a decrease of decision accuracy. As extreme case,
    if K is equal to the number of all nodes in CPS, the sample result is the global
    optimal solution of neighboring nodes. Otherwise, the classification is a partial
    optimal solution of neighboring nodes. Hence, it is critical to determine the
    value of K. Usually, selection of K is not fixed due to the sparsity of network
    and can be adjusted and determined by experimentations. In this experiment, the
    number of vehicular nodes in network model is 200. The vehicular network performance
    affected by selection of K value is shown in Fig. 12. In the first case, we set
    , also noted that delivery rate is highest when K 7. In the second case, is set
    as 40, so delivery rate obviously decreases, staying highest when K 5. Thus, the
    values of K can be adjusted to be highest at different cases to achieve best network
    performance. In Fig. 12, as other conditions are the same, the increase of selfish
    and malicious nodes directly degrades the network performance. Download : Download
    high-res image (121KB) Download : Download full-size image Fig. 12. Influence
    of K value on delivery rate. Besides, N nodes within the area of R2 are deployed,
    where is downlink transmission range of user . The locations of nodes obey two-dimensional
    Poisson distribution. If the communication radius of node is , the probability
    of having nodes within range of hops is calculated as (17). (17) Here, . can be
    set as a probability no less than an expected value, . The number of stored nodes
    is a random variable, with the average value . Similar to algorithm in [52], as
    K is the optimal value, the probability of data eavesdropping in the TBRS algorithm
    can be calculated as (18). (18) In real data transmission of vehicular CPS, attack
    source may come from the intranet. Attackers may know about controlling algorithm,
    running parameters and evaluation algorithm. In this case, attackers will not
    only target at the sensor network, but also capture data packets in multiple networks.
    To avoid data packets being sent back to the network after being captured, designers
    will add some information into data packets, such as data collection time, the
    turn-on time of sensors. It could improve security and transmission efficiency
    of the data packet. As the validity of data packet is checked, the timestamp and
    collection position should also be verified, making the out-of-time data packets
    invalid. To address this type of security problems in vehicular CPS, attackers
    may record measurement value of normal data packets during a period and send it
    to the calculation unit. After receiving one or several periods of data packets,
    an index table can be created to determine whether there are the same packets.
    Calculation unit receives observed values from index table, and the randomness
    of average test length (ATL) can be used to resist illegal collusion attacks.
    ATL can be calculated by (19). (19) If the attacks are carried on calculation
    unit and sensor network, attackers can capture part of data and the controller
    cannot receive ATL observed value. In this case, observed values are sufficient
    to restore valid data. In case vehicular nodes are chosen as eavesdropping nodes,
    the attackers attempt to eavesdrop data packets by decryption. In this experiment,
    the download files are set as 500, and five illegal eavesdropping experiments
    are conducted, which results are shown in Fig. 13. Eavesdropping nodes are added
    in the TBRS algorithm and other comparative algorithms, we could observe that
    the VDTN has the largest probability to eavesdrop by and the TBRS scheme shows
    the lowest. By comparing with other algorithms, the TBRS algorithm has improved
    the resistance against illegal eavesdropping attacks of 32.53% in average. Download
    : Download high-res image (232KB) Download : Download full-size image Fig. 13.
    Comparison of eavesdropping success rate. 6. Conclusions and future work Traditional
    routing algorithms in vehicular CPS are unable to recognize characteristic of
    nodes and attacks in vehicular network, and thus, cannot meet the requirements
    of current data transmission in vehicular CPS. The existence of selfish nodes
    and malicious nodes causes a decrease of delivery rate, increase of network delay
    and poor resistance against attacks. To address these issues, we proposed in this
    paper a trust-based recommendation scheme (TBRS) for complex vehicular CPS networks,
    and main contributions are: (1) Selfish nodes and malicious nodes pose great security
    threat on data forwarding. This work makes use of grey correlation model and grey
    correlation analysis, where multi-dimensional parameters are considered. The weight
    coefficients of direct trustable nodes are reasonably distributed, which can be
    used to adjust the coefficient of the network state, and (2) Vehicular CPS may
    be attacked by selfish nodes and malicious nodes, as well affected by the sparsity
    of nodes. Therefore, cooperative computing of trust value is introduced in this
    work to recommend trustable neighboring nodes. Under abovementioned items, a cooperative
    computing-based recommendation trust algorithm is proposed, by collecting recommendation
    trusts from neighboring nodes, and KNN algorithm is utilized to filter false recommendation
    trusts from selfish nodes and malicious nodes next, yielding true recommendations
    for cooperative computing. In this case, data packets can be effectively transmitted
    to next suitable hop when the network is sparse or attacked by selfish nodes and
    malicious nodes. Experiments show that the TBRS algorithm is superior to other
    vehicular algorithms in delivery rate, transmission efficiency and security. Additionally,
    it can be applied to disaster relief communication, vehicle network, remote area
    communication, wild environment monitoring, among others. This work focused on
    the preliminary studies of trust model in complex vehicular CPS with selfish/malicious
    nodes. As future work, the inclusion and application of techniques in identity
    authentication to enhance security and time-efficiency of vehicular CPS will also
    be considered, as the key direction to realize data security in transmission of
    CPS, in the viewpoint of a node’s identity. Acknowledgments This work is supported
    by the National Science Foundation of China (Grant 61572188), Xiamen science and
    technology Foundation (Grant 3502Z20173035), Scientific Research Program of New
    Century Excellent Talents in Fujian Province University, Fujian Provincial Natural
    Science Foundation of China (Grant 2018J01570) and the CERNET Innovation Project
    (Grant NGII20170411). References [1] Hu X., Chu T.H., Chan H.C., Leung V.C. Vita:
    A crowdsensing-oriented mobile cyber-physical system IEEE Trans. Emerg. Top. Comput.,
    1 (2013), pp. 148-165 View in ScopusGoogle Scholar [2] D. Schneider, E. Armengaud,
    E. Schoitsch, Towards trust assurance and certification in cyber-physical systems,
    in: Proceedings of International Conference on Computer Safety, Reliability, and
    Security, Florence, Italy, 8-9 September 2014, pp. 180–191. Google Scholar [3]
    Francesco F., Alessandro F., Andrea M., Mariorosario P. An integrated simulation
    module for cyber-physical automation systems Sensors, 16 (2016), pp. 1-17 Google
    Scholar [4] Liang W., Ruan Z., Wang Y., Chen X. RESH: A secure authentication
    algorithm based on regeneration encoding self-healing technology in WSN J. Sensors,
    2 (2016), pp. 1-11 CrossRefGoogle Scholar [5] Liang W., Xie Y., Chen X., Hosam
    O., Chen X. A two-step MF signal acquisition method for wireless underground sensor
    networks Comput. Sci. Inf. Syst., 13 (2016), pp. 623-638 View in ScopusGoogle
    Scholar [6] B. Li, Y. Ma, T. Westenbroek, C. Wu, H. Gonzalez, C. Lu, Wireless
    routing and control: a cyber-physical case study, in: Proceedings of the 7th International
    Conference on Cyber-Physical Systems, Vienna, Austria, 11 - 14 April 2016, pp.
    32–41. Google Scholar [7] J. Huang, M.D. Seck, A. Gheorghe, Towards trustworthy
    smart cyber-physical-social systems in the era of internet of things, in: Proceedings
    of 2016 11th System of Systems Engineering Conference, Kongsberg, Norway, 12-16
    June 2016, pp. 1-6. Google Scholar [8] S.S. Guclu, D.T. Altilar, Uplink utilization
    with V2V2R communications in clustered vehicular networks, in: Proceedings of
    2014 4th International Conference on Wireless Communications, Vehicular Technology,
    Information Theory and Aerospace &Electronics Systems, Aalborg, Denmark, 13-15
    May 2014, pp. 1–5. Google Scholar [9] Fysarakis K., Hatzivasilis G., Manifavas
    C., Papaefstathiou I. RtVMF: A secure real-time vehicle management framework IEEE
    Pervasive Comput., 15 (2016), pp. 22-30 View in ScopusGoogle Scholar [10] Dua
    A., Kumar N., Bawa S. A systematic review on routing protocols for vehicular ad
    hoc networks Veh. Commun., 1 (2014), pp. 33-52 View PDFView articleView in ScopusGoogle
    Scholar [11] Kumar N., Rodrigues J.J., Lloret J., Dua A. Replication-aware data
    dissemination for vehicular ad hoc networks using location determination Mobile
    Netw. Appl., 20 (2015), pp. 251-267 CrossRefView in ScopusGoogle Scholar [12]
    Abboud K., Zhuang W. Stochastic modeling of single-hop cluster stability in vehicular
    ad hoc networks IEEE Trans. Veh. Technol., 65 (2016), pp. 226-240 View in ScopusGoogle
    Scholar [13] A.A. Pirzada, C. McDonald, Establishing trust in pure ad-hoc networks,
    in: Proceedings of the 27th Australasian conference on Computer science, Dunedin,
    New Zealand, 2004, pp. 47–54. Google Scholar [14] Xia H., Jia Z., Li X. Trust
    prediction and trust-based source routing in mobile ad hoc networks Ad Hoc Networks,
    11 (2013), pp. 2096-2114 View PDFView articleView in ScopusGoogle Scholar [15]
    Wei Z., Tang H., Yu R., Wang M., Mason P. Security enhancements for mobile ad
    hoc networks with trust management using uncertain reasoning IEEE Trans. Veh.
    Technol., 63 (2014), pp. 4647-4658 View in ScopusGoogle Scholar [16] Chen I.R.,
    Guo J., Cho J.H. Trust management in mobile ad hoc networks for bias minimization
    and application performance maximization Ad Hoc Networks, 19 (2014), pp. 59-74
    View PDFView articleView in ScopusGoogle Scholar [17] Movahedi Z., Hosseini Z.,
    Bayan F., Pujolle G. Trust-distortion resistant trust management frameworks on
    mobile ad hoc networks: A survey IEEE Commun. Surv. Tutor., 18 (2016), pp. 1287-1309
    View in ScopusGoogle Scholar [18] Chuang M.C., Lee J.F. TEAM: Trust-extended authentication
    mechanism for vehicular ad hoc networks IEEE Syst. J., 8 (2014), pp. 749-758 View
    in ScopusGoogle Scholar [19] Li W., Song H. ART: An attack-resistant trust management
    scheme for securing vehicular ad hoc networks IEEE Trans. Intell. Transp. Syst.,
    17 (2016), pp. 960-969 Google Scholar [20] S. Buchegger, A Robust Reputation System
    for Mobile Ad-hoc Networks EPFL IC Technical Report IC/2003/50, 2003. Google Scholar
    [21] Han G., Jiang J., Shu L., Guizani M. An attack-resistant trust model based
    on multidimensional trust metrics in underwater acoustic sensor network IEEE Trans.
    Mob. Comput., 14 (2015), pp. 2447-2459 View in ScopusGoogle Scholar [22] A.M.
    Shabut, K. Dahal, I. Awan, Z. Pervez, Route optimization based on multidimensional
    trust evaluation model in mobile ad hoc networks, in: Second International Conference
    on Information Security & Cyber Forensics, 2016, pp. 28-34. Google Scholar [23]
    Bernabe J.B., Bernabe J.B., Ramos J.L.H., Gomez A.F.S. TACIoT: Multidimensional
    trust-aware access control system for the internet of things Soft Comput., 20
    (2016), pp. 1763-1779 Google Scholar [24] B. Kantarci, Cyber-physical alternate
    route recommendation system for paramedics in an Urban area, in: Proceedings of
    Wireless Communications and Networking Conference, New Orleans, USA, 9-12 March
    2015, pp. 2155–2160. Google Scholar [25] Y. Wang, S. Jain, M. Martonosi, et al.
    Erasure-coding based routing for opportunistic networks, in: Proceedings of ACM
    SIGCOMM Workshop on Delay-Tolerant Networking, Philadelphia, PA, USA, 22-26 August
    2005, pp. 229-236. Google Scholar [26] G. Hatzivasilis, I. Papaefstathiou, C.
    Manifavas, Real-time management of railway CPS secure administration of IoT and
    CPS infrastructure, in: Proceedings of 2017 6th Mediterranean Conference on Embedded
    Computing (MECO), Bar, Montenegro, 11–15 June 2017, pp. 1–4. Google Scholar [27]
    Guo J., Yang L. CAR: Context-aware routing for vehicular ad hoc networks Int.
    J. Eng. Ind., 1 (2010), pp. 10-29 View in ScopusGoogle Scholar [28] V. Kavitha,
    E. Altman, Analysis and design of message ferry routes in sensor networks using
    polling models, in: Proceedings of International Symposium on Modeling and Optimization
    in Mobile, Ad Hoc and Wireless Networks, Avignon, France, 31 May- 4 June 2010,
    pp. 247-255. Google Scholar [29] Dua A., Kumar N., Bawa S., Rodrigues J.J. An
    intelligent context-aware congestion resolution protocol for data dissemination
    in vehicular ad hoc networks Mobile Netw. Appl., 20 (2015), pp. 181-200 CrossRefView
    in ScopusGoogle Scholar [30] Dua A., Kumar N., Bawa S. QoS-aware data dissemination
    for dense urban regions in vehicular ad hoc networks Mobile Netw. Appl., 20 (2015),
    pp. 773-780 CrossRefView in ScopusGoogle Scholar [31] Kumar N., Tyagi S., Deng
    D.-J. LA-EEHSC: Learning automata-based energy efficient heterogeneous selective
    clustering for wireless sensor networks J. Netw. Comput. Appl., 46 (2014), pp.
    264-279 View PDFView articleView in ScopusGoogle Scholar [32] M. Gharib, P. Lollini,
    A. Bondavalli, Towards an approach for analyzing trust in cyber-physical-social
    systems, in: Proceedings of 2017 12th System of Systems Engineering Conference,
    Waikoloa, Hawaii, 18-21 June 2017, pp. 1–6. Google Scholar [33] A. Louazani, S.M.
    Senouci, M.A. Bendaoud, Clustering-based algorithm for connectivity maintenance
    in vehicular ad-hoc networks, in: Proceedings of 2014 14th International Conference
    on Innovations for Community Services (I4CS), Reims, France, 4-6 June 2014, pp.
    34–38. Google Scholar [34] Y. Shi, An improved collaborative filtering recommendation
    method based on timestamp, in: Proceedings of 2014 16th International Conference
    on Advanced Communication Technology (ICACT), Pyeong Chang, South Korea, 16-19
    February 2014, pp. 784–788. Google Scholar [35] Kumar N., Rodrigues J.J., Chilamkurti
    N. Bayesian coalition game as-a-service for content distribution in internet of
    vehicles IEEE Internet Things J., 1 (2014), pp. 544-555 View in ScopusGoogle Scholar
    [36] Kumar N., Lee J.-H. Peer-to-peer cooperative caching for data dissemination
    in urban vehicular communications IEEE Syst. J., 8 (2014), pp. 1136-1144 View
    in ScopusGoogle Scholar [37] Kumar N., Chilamkurti N., Rodrigues J.J. Learning
    automata-based opportunistic data aggregation and forwarding scheme for alert
    generation in vehicular ad hoc networks Comput. Commun., 39 (2014), pp. 22-32
    View PDFView articleView in ScopusGoogle Scholar [38] G. Hatzivasilis, A. Theodoridis,
    E. Gasparis, C. Manifavas, I. Papaefstathiou, ULCL-An Ultra-Lightweight Cryptographic
    Library for Embedded Systems. PECCS, 2014, pp. 247-254. Google Scholar [39] G.
    Hatzivasilis, I. Papaefstathiou, C. Manifavas, N. Papadakis, A reasoning system
    for composition verification and security validation, in: Proceedings of 2014
    6th International Conference on New Technologies, Mobility and Security, Dubai,
    United Arab Emirates, 30 March - 2 April 2014, pp. 1–4. Google Scholar [40] G.
    Hatzivasilis, I. Papaefstathiou, C. Manifavas, ModConTR: A modular and configurable
    trust and reputation-based system for secure routing in ad-hoc networks, in: Proceedings
    of 2014 IEEE/ACS 11th International Conference on Computer Systems and Applications,
    Doha, Qatar, 10-13 November 2014, pp. 56–63. Google Scholar [41] Deng J. Introduction
    to grey system theory J. Grey Syst., 1 (1989), pp. 1-24 View in ScopusGoogle Scholar
    [42] Chen Y.Y., Chang G.L. A macroscopic signal optimization model for arterials
    under heavy mixed traffic flows IEEE Trans. Intell. Transp. Syst., 15 (2014),
    pp. 805-817 View in ScopusGoogle Scholar [43] Zhang S., et al. Efficient kNN classification
    with different numbers of nearest neighbors IEEE Trans. Neural Netw. Learn. Syst.
    (2017), pp. 1-12 Google Scholar [44] ONE simulator. http://www.cnblogs.com/dreamfactory/archive/2012/07/27/2612215.html.
    Google Scholar [45] Benamar M., Ahnana S., Saiyari F.Z. Study of VDTN routing
    protocols performances in sparse and dense traffic in the presence of relay nodes
    J. Mobile Multimedia, 10 (2014), pp. 78-93 View in ScopusGoogle Scholar [46] Hsieh
    Y.L., Wang K. A road-based QoS-aware multipath routing for urban vehicular ad
    hoc networks Global Communications Conference, IEEE Press, Anaheim (2012), pp.
    189-194 CrossRefGoogle Scholar [47] Zhou Y., Li L. A trust-aware and location-based
    secure routing protocol for WSN Appl. Mech. Mater. (2013), pp. 1931-1934 View
    in ScopusGoogle Scholar [48] M. Li, et al. An improved GPSR protocol based on
    stratification of traffic density, in: IEEE International Conference on Information
    and Automation IEEE, 2017, pp. 1162-1167. Google Scholar [49] K. Hu, W. Hsu, M.L.
    Lee, Utilizing users’ tipping points in E-commerce recommender systems, in: Proceedings
    of 2013 IEEE 29th International Conference on Data Engineering, Brisbane, Australia,
    8-12 April 2013, pp. 494–504. Google Scholar [50] S. Mohan, S. Bak, E. Betti,
    H. Yun, L. Sha, M. Caccamo, S3A: Secure system simplex architecture for enhanced
    security and robustness of cyber-physical systems, in: Proceedings of the 2nd
    ACM International Conference on High Confidence Networked Systems, Philadelphia,
    USA, 9-11 April 2013, pp. 65–74. Google Scholar [51] Li X., Qiao C., Yu X., Wagh
    A., Sudhaakar R., Addepalli S. Toward effective service scheduling for human drivers
    in vehicular cyber-physical systems IEEE Trans. Parallel Distrib. Syst., 23 (2012),
    pp. 1775-1789 View in ScopusGoogle Scholar [52] Bali R.S., Kumar N. Secure clustering
    for efficient data dissemination in vehicular cyber-physical systems Future Gener.
    Comput. Syst., 56 (2016), pp. 476-492 View PDFView articleView in ScopusGoogle
    Scholar Cited by (61) Hybrid collaborative filtering using matrix factorization
    and XGBoost for movie recommendation 2024, Computer Standards and Interfaces Show
    abstract Design automation system synchronization for cyber physical system with
    dynamic voltage and frequency scaling in industry 5.0 2024, Measurement: Sensors
    Show abstract Hot topics with decaying attention in social networks: Modeling
    and analysis of message spreading 2023, Physica A: Statistical Mechanics and its
    Applications Show abstract BEPHAP: A Blockchain-based Efficient Privacy-Preserving
    Handover Authentication Protocol with key agreement for Internet of Vehicles 2023,
    Journal of Systems Architecture Show abstract Blockchain-based recommender systems:
    Applications, challenges and future opportunities 2022, Computer Science Review
    Citation Excerpt : The main reason for this is the limited computational capacity
    of IoT and mobile devices, in conjunction with the power resources that blockchain
    tasks may require. Smart cities, smart homes [172] and autonomous vehicles 1u
    [173] have already attracted the interest of researchers on IoT and edge or fog
    computing. Current research focuses on optimizing the performance in the core
    tasks of each domain, and still relies on centralized or cloud based solutions
    for issues related to privacy, security, robustness and resilience to noise and
    attacks. Show abstract Emerging architecture for heterogeneous smart cyber-physical
    systems for industry 5.0 2021, Computers and Industrial Engineering Show abstract
    View all citing articles on Scopus Wei Liang is currently a full professor in
    School of Opto-Electronic and Communication Engineering, Xiamen University of
    Technology, China. He received Ph.D. in computing science from Hunan University
    (China) in 2013. His current research interests include steganography, real-time
    embedded systems, intellectual property protection, and field programmable gate
    arrays. Jing Long received her MS degree in College of Computer Science and Engineering,
    from Hunan University of Science and Technology (China) in 2012. Currently, she
    is a PhD student in College of Computer Science and Electronic Engineering, Hunan
    University (China). Her current research interests include hardware security and
    IP protection. Tien-Hsiung Weng is currently an associate professor in the Department
    of Computer Science and Information Engineering at Providence University, Taiwan.
    He received the PhD in Computer Science from University of Houston, Texas, USA.
    From 2010 to 2013, he was the department chair of Computer Science and Information
    Engineering at Providence University, Taiwan. His research interests include parallel
    programming model, performance measurement, and compiler analysis for code improvement.
    Xuhui Chen received his Ph.D. in computing science from Xi’an Jiao Tong University,
    China, in 2002. He was a Post-doctoral researcher in Arizona State University
    during 2013–2014. He is currently a professor in School of Opto-Electronic and
    Communication Engineering, Xiamen University of Technology, China. His current
    research interests include steganography, IPV6, intellectual property protection,
    and field programmable gate arrays. Kuan-Ching Li is a Distinguished Professor
    in the Department of Computer Science and Information Engineering, Providence
    University, Taiwan. He received distinguished and chair professorships from universities
    in China and other countries, and a recipient of awards and funding support from
    several agencies and high-tech companies. He has been actively involved in several
    major conferences and workshops in program/general/steering conference chairman
    positions and has organized numerous conferences on high-performance computing
    and computational science and engineering. Besides publishing numerous research
    papers and articles, he is co-author/co-editor of several technical professional
    books published by CRC Press/Taylor & Francis, Springer, McGraw-Hill and IGI Global.
    His research interests include Parallel and Distributed Processing, GPU/many-core
    computing, Big Data and Cloud. He is a member of the AAAS, a senior member of
    the IEEE, a life member of the TACC and a fellow of the IET. Albert Y. Zomaya
    is the Chair Professor of High Performance Computing & Networking in the School
    of Information Technologies, University of Sydney, and he also serves as the Director
    of the Centre for Distributed and High Performance Computing. Professor Zomaya
    published more than 550 scientific papers and articles and is author, co-author
    or editor of more than 20 books. He is the Founding Editor in Chief of the IEEE
    Transactions on Sustainable Computing and serves as an associate editor for more
    than 20 leading journals. Professor Zomaya served as an Editor in Chief for the
    IEEE Transactions on Computers (2011–2014). Professor Zomaya is the recipient
    of the IEEE Technical Committee on Parallel Processing Outstanding Service Award
    (2011), the IEEE Technical Committee on Scalable Computing Medal for Excellence
    in Scalable Computing (2011), and the IEEE Computer Society Technical Achievement
    Award (2014), and the ACM MSWIM Reginald A. Fessenden Award (2017). He is a Chartered
    Engineer, a Fellow of AAAS, IEEE, and IET. Professor Zomaya’s research interests
    are in the areas of parallel and distributed computing and complex systems. View
    Abstract © 2018 Elsevier B.V. All rights reserved. Part of special issue Special
    Issue on Smart Cyber-Physical Systems (sCPS): towards Pervasive Intelligence systems
    Edited by Flavia Delicato, Adnan Al-Anbuky, Kevin I-Kai Wang View special issue
    Recommended articles FPGA-based approximate calculation system of General Vector
    Machine Microelectronics Journal, Volume 86, 2019, pp. 87-96 Xuhui Yang, …, Kuan-Ching
    Li View PDF A fuzzy fully distributed trust management system in wireless sensor
    networks AEU - International Journal of Electronics and Communications, Volume
    70, Issue 1, 2016, pp. 40-49 Hossein Jadidoleslamy, …, Hossein Bahramgiri View
    PDF A secure privacy preserving deduplication scheme for cloud computing Future
    Generation Computer Systems, Volume 101, 2019, pp. 127-135 Yongkai Fan, …, Priyadarsi
    Nanda View PDF Show 3 more articles Article Metrics Citations Citation Indexes:
    55 Captures Readers: 49 View details About ScienceDirect Remote access Shopping
    cart Advertise Contact and support Terms and conditions Privacy policy Cookies
    are used by this site. Cookie settings | Your Privacy Choices All content on this
    site: Copyright © 2024 Elsevier B.V., its licensors, and contributors. All rights
    are reserved, including those for text and data mining, AI training, and similar
    technologies. For all open access content, the Creative Commons licensing terms
    apply."'
  inline_citation: '>'
  journal: Future Generation Computer Systems
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: 'TBRS: A trust based recommendation scheme for vehicular CPS network'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'

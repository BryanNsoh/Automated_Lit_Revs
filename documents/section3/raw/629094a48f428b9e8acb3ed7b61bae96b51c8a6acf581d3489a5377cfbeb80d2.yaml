- analysis: '>'
  authors:
  - Stumpe C.
  - Leukel J.
  - Zimpel T.
  citation_count: '0'
  description: Accurate and reliable predictions of biomass yield are important for
    decision-making in pasture management including fertilization, pest control, irrigation,
    grazing, and mowing. The possibilities for monitoring pasture growth and developing
    prediction models have greatly been expanded by advances in machine learning (ML)
    using optical sensing data. To facilitate the development of prediction models,
    an understanding of how ML techniques affect performance is needed. Therefore,
    this review examines the adoption of ML-based optical sensing for predicting the
    biomass yield of managed grasslands. We carried out a systematic search for English-language
    journal articles published between 2015-01-01 and 2022-10-26. Three coders screened
    593 unique records of which 91 were forwarded to the full-text assessment. Forty-three
    studies were eligible for inclusion. We determined the adoption of techniques
    for collecting input data, preprocessing, and training prediction models, and
    evaluating their performance. The results show (1) a broad array of vegetation
    indices and spectral bands obtained from various optical sensors, (2) an emphasis
    focus on feature selection to cope with high-dimensional sensor data, (3) a low
    reporting rate of unitless performance metrics other than R  2, (4) higher variability
    of R2 for models trained on sensor data of larger distance from the pasture sward,
    and (5) the need for greater comparability of study designs and results. We submit
    recommendations for future research and enhanced reporting that can help reduce
    barriers to the integration of evidence from studies.
  doi: 10.1007/s11119-023-10079-9
  full_citation: '>'
  full_text: '>

    "Your privacy, your choice We use essential cookies to make sure the site can
    function. We also use optional cookies for advertising, personalisation of content,
    usage analysis, and social media. By accepting optional cookies, you consent to
    the processing of your personal data - including transfers to third parties. Some
    third parties are outside of the European Economic Area, with varying standards
    of data protection. See our privacy policy for more information on the use of
    your personal data. Manage preferences for further information and to change your
    choices. Accept all cookies Skip to main content Log in Find a journal Publish
    with us Track your research Search Cart Home Precision Agriculture Article Prediction
    of pasture yield using machine learning-based optical sensing: a systematic review
    Open access Published: 28 September 2023 Volume 25, pages 430–459, (2024) Cite
    this article Download PDF You have full access to this open access article Precision
    Agriculture Aims and scope Submit manuscript Christoph Stumpe , Joerg Leukel &
    Tobias Zimpel   1336 Accesses Explore all metrics Abstract Accurate and reliable
    predictions of biomass yield are important for decision-making in pasture management
    including fertilization, pest control, irrigation, grazing, and mowing. The possibilities
    for monitoring pasture growth and developing prediction models have greatly been
    expanded by advances in machine learning (ML) using optical sensing data. To facilitate
    the development of prediction models, an understanding of how ML techniques affect
    performance is needed. Therefore, this review examines the adoption of ML-based
    optical sensing for predicting the biomass yield of managed grasslands. We carried
    out a systematic search for English-language journal articles published between
    2015-01-01 and 2022-10-26. Three coders screened 593 unique records of which 91
    were forwarded to the full-text assessment. Forty-three studies were eligible
    for inclusion. We determined the adoption of techniques for collecting input data,
    preprocessing, and training prediction models, and evaluating their performance.
    The results show (1) a broad array of vegetation indices and spectral bands obtained
    from various optical sensors, (2) an emphasis focus on feature selection to cope
    with high-dimensional sensor data, (3) a low reporting rate of unitless performance
    metrics other than R2, (4) higher variability of R2 for models trained on sensor
    data of larger distance from the pasture sward, and (5) the need for greater comparability
    of study designs and results. We submit recommendations for future research and
    enhanced reporting that can help reduce barriers to the integration of evidence
    from studies. Similar content being viewed by others Comparing methods to estimate
    perennial ryegrass biomass: canopy height and spectral vegetation indices Article
    Open access 09 July 2020 Characterization of portuguese sown rainfed grasslands
    using remote sensing and machine learning Article 27 July 2022 Remote sensing
    and machine learning applications for aboveground biomass estimation in agroforestry
    systems: a review Article 10 May 2023 Introduction Pastures account for about
    70% of the world’s agricultural land (Squires et al., 2018) and provide essential
    sources of high-quality forage for ruminants (Bouwman et al., 2005). Thus, pastures
    assume a key role in nourishing a growing global population with dairy and meat
    products (Henchion et al., 2017; Tripathi et al., 2018). Moreover, grasslands
    fulfill ecosystem services such as carbon storage and habitat conservation; hence,
    they help mitigate climate change and preserve biodiversity (O’Mara, 2012; Zhao
    et al., 2020). Pasture management is being challenged by increasing competition
    between forage and energy crops (Donnison & Fraser, 2016), land sealing due to
    infrastructure and housing, greater yield volatility due to climate change (Hopkins
    & Del Prado, 2007), and stronger constraints on fertilization (Buckley et al.,
    2016). Against this backdrop, accurate and reliable information about future pasture
    yields gains importance for agricultural management. These yield predictions can
    support the decision-making processes regarding fertilization, pest control, irrigation,
    stocking rates, and mowing. Overall, accurate yield predictions allow more efficient
    use of all inputs, resulting in less environmental impact and greater profits
    for farmers (Hedley, 2015; Kent Shannon et al., 2018). Machine learning-based
    optical sensing has become the prevailing approach to predictive modeling for
    pasture yields. In this approach, past observational data is analyzed to learn
    a mapping function between pasture characteristics and biomass at harvest. This
    function is used to predict the biomass for pasture characteristics obtained via
    sensors at a future time. Predictive modeling using machine learning (ML) takes
    advantage of significant improvements in technology for optical sensing (Adão
    et al., 2017; Zeng et al., 2020), enhanced availability of field data at different
    levels of granularity (Murphy et al., 2021), and greater performance of the underlying
    ML algorithms. The importance of MLbased optical sensing for pasture yield prediction
    is reflected in the high number of studies in recent years. Evidence for the effectiveness
    of ML-based predictive modeling has increased. The evidence concerns different
    grass species, such as perennial ryegrass (Lolium perenne) (Nguyen et al., 2022),
    signalgrass (Brachiaria) (Bretas et al., 2021), and clover (Trifolium pratense)
    (Li et al., 2021), and different types of optical sensors, including portable
    spectroradiometers (Murphy et al., 2022), sensors mounted on unmanned aerial vehicles
    (UAVs) (van der Merwe et al., 2020), and carried by satellites (Bretas et al.,
    2021). This variety converges with a broad set of ML techniques that developers
    can adopt. Developers must select techniques for the transformation of input data
    into features, the training of prediction models from past observations of input
    data and biomass, and the evaluation of the trained models on new observations.
    To inform these decisions on the development of prediction models, insights into
    the effectiveness of specific ML techniques are required. Notwithstanding the
    increased evidence base, the understanding of the effectiveness of specific ML
    techniques is still limited. Regarding the types of optical sensor data, a previous
    review found better performance for prediction models that were trained on in-field
    imagery compared to models that processed satellite data (Morais et al., 2021).
    However, about half of the included studies examined non-managed grasslands, such
    as steppe, semiarid grassland, bunchgrass, and shrub on drylands; hence, the finding
    cannot necessarily be generalized to prediction models for pasture yield. Two
    literature reviews focused on UAVs so that the results do not extend to models
    trained on data from field spectroradiometers and satellites (Bazzo et al., 2023;
    Lyu et al., 2022). Another review had a broader scope by including studies that
    collected non-optical sensor data (Murphy et al., 2021). One related review only
    provided aggregated information but no results at the study level (Subhashree
    et al., 2023). Collectively, the burgeoning field of pasture yield prediction
    using ML-based optical sensing calls for the assessment of current evidence to
    facilitate the development of prediction models. To address this need, we conducted
    a systematic review that is conceptually guided by the ML process. Specifically,
    the objectives are to: (1) determine the adoption of ML-based optical sensing
    in previous research examining yield prediction for pasture management, (2) collate
    the performance results, and (3) propose recommendations for future research and
    the reporting of studies. Method We conducted a systematic review of studies and
    report the results based on the PRISMA (Preferred Reporting Items for Systematic
    Reviews and Meta-Analyses) guidelines, where applicable (Moher et al., 2009).
    To ensure the reliability of the coding, three authors independently screened
    the identified records, assessed the full-text articles for eligibility, and extracted
    data from the selected studies. Eligibility criteria We included studies that
    applied machine learning on data obtained from optical sensing for predicting
    the yield of pastures, with yield defined as the current or future biomass of
    a specific pasture area, such as a plot, paddock, or field. The studies were required
    to report empirical results from the processing of real-world data. We focused
    on studies in refereed journals and written in English. The time interval of the
    past eight years (2015-01-01 through 2022-10-26) allowed us to assess studies
    that benefit from advances in ML and optical sensors in recent years, and thus
    have high relevance for research and practice. Studies were excluded if any of
    the following criteria were met: (1) dependent variable not related to a managed
    pasture but a different crop, nature conservation, biodiversity, or grassland
    coverage; (2) no prediction of yield but a different variable (e.g., nutrients,
    sward composition); (3) no predictive modeling but explanatory modeling or conceptual
    research; (4) no use of machine learning; (5) no processing of real-world data;
    and (6) no use of data from optical sensing (e.g., exclusively weather data).
    Information sources and search We identified articles through an automated search
    of journal articles published between January 1, 2015, and October 26, 2022. The
    search used the electronic database Scopus, which is the largest database of scientific
    literature and has larger coverage of peer-reviewed literature than the Web of
    Science (Mongeon & Paul-Hus, 2016; Singh et al., 2021; Thelwall & Sud, 2022).
    We designed the search query to cover the wide variety of terminology found in
    the literature. The search query had four concatenated components for pasture,
    yield, prediction, and machine learning. The pasture was represented as follows:
    (pasture* OR forage* OR grassland* OR *grass OR herbage* OR meadow*). Yield was
    covered by the following term: (yield OR biomass OR agb OR “herbage mass” OR “pasture
    mass” OR “grassland production” OR “forage production” OR quantity). The prediction
    component included different words as follows: (predict* OR assess* OR estimat*
    OR forecast*). Machine learning was represented by abstract terms and specific
    algorithms as follows: (“machine learning” OR “deep learning” OR “support vector”
    OR “random forest*” OR “neural network” OR “partial least square*” OR “predict*
    model*” OR “regression model”). Study selection We ensured the reliability of
    the study selection through the following procedure. We defined a codebook that
    provided the eligibility and exclusion criteria. The codebook was used in the
    screening phase by three authors who independently coded the first nine articles
    based on the title, abstract, and keywords. The coders met to compare their codes
    and resolve any conflicting codes through discussion. The coding commenced with
    the remaining articles. Once all articles were coded and discussed, we downloaded
    the full texts of the articles that passed the screening. The assessment of the
    full texts employed the same codebook and was organized in two rounds of coding
    and resolving disagreements. Data collection process The data collection for the
    included studies was carried out by the same three authors, who independently
    filled in an Excel spreadsheet form for 96 data items per article. The data items
    operationalize the conceptual framework described in the following section. All
    individual codes were compared in two rounds in which disagreements were resolved
    through discussion and consensus. Data items Figure 1 illustrates the conceptual
    model of the review based on the process of predictive modeling using machine
    learning. This process begins with the prediction problem and ends with the evaluated
    prediction model. The figure also denotes the principal data items that we collected
    during the review. Fig. 1 Process and principal data items for pasture yield prediction
    Full size image Forecasting the yield of pastures based on optical sensor data
    recorded during the vegetation period represents the prediction problem. Plant
    species are pasture plants that are cultivated and constitute the sward composition
    for which the prediction is made. Grazing indicates whether the pasture is grazed
    by animals or managed by machinery for forage conservation. Country denotes the
    location where the study was conducted. The process shown in Fig. 1 defines four
    phases, which we discuss in the following paragraphs. Data collection includes
    the creation of a data set by recording prediction-relevant data of the pasture
    vegetation and the observed yield at the time of harvest. Study conditions describe
    the number of fields, sample plots, and seasons for which these data were recorded.
    A sample plot is defined as the smallest partial area from which an independent
    sample of biomass is collected by cutting. Studies vary in the number of plots
    per field as well as in the size of plots, which usually range from 0.25 m2 to
    a handful of square meters. The input data can be classified into the following
    groups: vegetation indices calculated from spectral measurements (Xue & Su, 2017);
    spectral bands taken from imagery; textural features as properties of the surface
    calculated based on the Grey Level Co-occurrence Matrix (GLCM) method (Haralick
    et al., 1973); sward height above the ground; weather data (e.g., precipitation,
    temperature) (Yao et al., 2022); site data (e.g., soil type, angle); and agronomic
    data (e.g., fertilizer input, irrigation, grazing rotation, stocking rates, species
    selection, and pest and weed control) (Smit et al., 2008). Another classification
    of input data is based on the dichotomy of biotic and abiotic factors affecting
    plant growth (Lange et al., 2014). Biotic factors refer to living organisms, such
    as grazing animals, insects, microorganisms, and other plants that influence pasture
    production (Kallenbach, 2015; Klaus et al., 2013). Abiotic factors encompass non-living
    elements, such as soil composition, temperature, water supply, and global radiation
    that determine plant growth (Baldocchi et al., 2004; Sorkau et al., 2018). A sound
    knowledge of biotic factors, abiotic factors, and their complex interactions helps
    to develop effective prediction models, although the conceptual differences between
    explanatory and predictive modeling need to be considered (Shmueli, 2010). Optical
    sensors for gathering input data can be categorized as follows. In-field sensors
    operate near the ground and foremost include field spectroradiometers for obtaining
    reflectance data, such as vegetation indices and chlorophyll content of plants,
    but also laser scanners, such as LiDAR (Light Detection and Ranging), to create
    a 3D map of the pasture. Aerial sensors are mounted on an aircraft or unmanned
    aerial vehicle (UAV) to collect high-resolution imagery from a low flying height
    (Feng et al., 2021); they include hyperspectral, multispectral, and RGB cameras
    as well as thermal sensors and LiDAR sensors. Satellite remote sensing enables
    to record vegetation reflectance from the orbit. Data preprocessing is the second
    phase, which produces so-called features from the input data. Features represent
    characteristics of the empirical phenomenon on which a prediction model can be
    learned. Including all input data as features in the prediction model incurs the
    risk of learning from noise in the data and lacking in prediction performance.
    For this reason, feature selection provides different techniques for identifying
    smaller sets of features. The techniques are usually grouped into three categories
    (Chandrashekar & Sahin, 2014): (1) Filter-based techniques select features based
    on a metric calculated for each feature. For instance, correlation analysis can
    identify pairs of highly correlated features from which only one feature will
    be retained. Another technique is principal component analysis (PCA), which transforms
    a set of strongly correlated features into a smaller set. (2) Wrapper-based techniques
    remove one or more features from the initial set by iteratively training and evaluating
    alternative prediction models. For instance, backward elimination starts with
    the full set of features and removes features based on pvalues passing a specific
    threshold (in case of multiple linear regression). (3) Embedded techniques are
    specific to an ML algorithm. One example is Random Forests feature selection,
    which calculates the so-called feature importance metric and then removes features
    that do not pass a threshold for the metric. The third phase is model training
    in which example observations are used to learn a function that best maps a set
    of feature values to the corresponding observed yield; these examples are also
    referred to as input-output pairs. For estimating the mapping function, the field
    of supervised machine learning provides a large variety of ML algorithms. Frequently
    used algorithms for predicting pasture yields include Random Forests (RF) (Ho,
    1995), Artificial Neural Networks (ANN) (Bishop, 2006), and Support Vector Regression
    (SVR) (Drucker et al., 1996) but also different types of linear regression, such
    as ordinary least squares (OLS) and partial least squares (PLS) regression. All
    these algorithms require a sufficiently large training set that includes a number
    of examples. Model evaluation is the final phase, which assesses the prediction
    performance of a trained model. Because of the many design alternatives to choose
    from in the preceding phases, developers usually evaluate alternative prediction
    models through experiments in which one or more factors are manipulated. By conducting
    factorial experiments, developers can devise a variety of experimental conditions,
    gain insights into how the factors affect performance, and eventually identify
    the best-performing model. Irrespective of the experimental design, evaluation
    calls for testing the prediction model on new observations, thus observations
    that were not included in the training phase. The evaluation can be accomplished
    using cross-validation, a test set, or both techniques. In cross-validation (CV),
    the data set is iteratively divided into subsets for training and testing. For
    instance, k-fold CV divides the data set into k subsets (folds) of equal size,
    trains a model for each combination of k-1 folds, evaluates the model on the left-out
    fold, and reports the mean performance for all k models. In other words, in each
    iteration, one fold is left out of the training set. Another type of CV is leave-one-out,
    which trains the model using all but one observation and tests the model on the
    left-out observation. The training and testing must be repeated n times, with
    n standing for the total number of observations. Different from CV, a test set
    indicates a technique that uses a separate data set of new observations. Either
    technique can apply performance metrics to quantify the accuracy of predicted
    vis-á-vis observed yields. Metrics for yield predictions include, for instance,
    the coefficient of determination (R2), the root mean square error (RMSE), the
    normalized RMSE (NRMSE), and the mean absolute error (MAE). The report on prediction
    performance can be supplemented by information on so-called feature importance,
    i.e., a quantitative assessment of the extent to which individual features have
    contributed to the prediction performance. Various techniques are available for
    measuring importance, for example, by indicating how a specific performance metric
    would change in absolute or relative terms if the feature in question were removed.
    Other techniques specify importance as a percentage value, summing to 100% for
    all features. Such information is typically presented in column charts or placed
    in tabular appendices. Results Study selection Figure 2 shows the PRISMA flow
    chart of study selection. A total of 591 records were identified through database
    searching. We considered two additional studies that reported prediction models
    for pasture yield using optical sensing; the studies were listed in Scopus, but
    their records were not automatically retrieved. Of the 91 articles that were forwarded
    to the full-text assessment, 43 articles fulfilled the eligibility criteria, and
    these studies were included in the review. Fig. 2 PRISMA flow chart Full size
    image Table 1 shows an overview of the included studies. The most frequently studied
    plants were perennial ryegrass (14 studies, Lolium perenne), clover species (8,
    Trifolium), signalgrass (5, Brachiaria), and timothy (4, Phleum pratense). Twenty-five
    of the pastures were mechanically harvested, and the remaining pastures were grazed
    by animals. Twenty-two studies were conducted in Europe, nine in Australia, six
    in South America, and four in North America, whereas only each one study was carried
    out in Africa and Asia. Predictions were always made right before harvest or very
    near to that day, except for three studies that used prediction horizons of 13
    days (Schwieder et al., 2020), 38 days (Li et al., 2021), and 152 days (Hamada
    et al., 2021), respectively. Table 1 Overview of the studies (N = 43) Full size
    table Data collection Table 2 provides the number of fields, sample plots, and
    seasons, followed by the different types of input data. Almost half of the studies
    were limited to data from a single field. The number of sample plots ranged from
    only two to more than one thousand (mean: 114; median: 54; n = 35). Two-thirds
    of the studies collected data in one growing season, and every fifth study covered
    two seasons. Two studies even covered eight (Jaberalansar et al., 2017) and twelve
    seasons (Ali et al., 2017), respectively. Twothirds of the studies were conducted
    at research facilities and one-third on fields operated by farmers (not tabulated).
    Vegetation indices were processed as input data in 29 studies. The number of VIs
    spanned from one index in four studies to more than 20 indices in eight studies.
    Sward height was used in 19 studies and it was either measured by UAV (13 studies),
    rising plate meter (3), LiDAR (1), meter ruler (1), or satellite (1). Nineteen
    studies processed spectral bands, which exhibited large variability between 2
    and 2150 different bands. In three studies, vegetation indices were complemented
    with textural features. All other types of input data played a minor role. Specifically,
    five studies used weather data, two studies considered site data (e.g., soil type,
    elevation, slope, and aspect), and only one study integrated fertilizer input
    as agronomic data (Franceschini et al., 2022). No study learned a model based
    on biotic data. Table 3 summarizes the adoption of the different types of optical
    sensors. Fourteen studies obtained data from in-field sensors, which included
    spectroradiometers (12 studies). Twenty-four studies collected input data from
    cameras mounted on aerial vehicles; the cameras recorded RGB images (11 studies),
    multispectral images (13), and hyperspectral images (5). Thirteen studies retrieved
    image data from satellites, including Sentinel (9 studies), MODIS (3), PlanetScope
    (2), Landsat (1), PlanetDove (1), and WorldView (1). Table 2 Data collection in
    the included studies (N = 43) Full size table Table 3 Optical sensors used in
    the included studies (N = 43) Full size table Data preprocessing Table 4 reports
    the adoption of feature selection techniques and provides the number of features
    per study. Feature selection was present in 24 studies, and the most frequent
    techniques were correlation analysis (8 studies), PCA (8), and stepwise regression
    (4). The number of features ranged between 1 and 101, although eight studies did
    not report this information. On one hand, four studies spared out feature selection
    but collected sensor data for a single feature. On the other hand, 18 studies
    trained models from at least 10 different features. Table 4 Feature selection
    techniques and number of features in the included studies (N = 43) Full size table
    Model training Table 5 provides information about the adoption of 16 different
    ML algorithms. The most frequent algorithms were Random Forests (20 studies),
    PLS regression (13), OLS regression using a single predictor (10) or multiple
    predictors (8), and Support Vector Regression (8). The size of the training set
    was stated in 41 studies, which either reported the number of examples, a percentage
    value of the examples used, or both types of information (not tabulated). In 10
    studies, the prediction models were trained on less than 100 examples. Table 5
    Machine-learning algorithms in the included studies (N = 43) Full size table Model
    evaluation Experimental manipulation Table 6 shows the frequency of each manipulated
    factor. The most frequent factors were feature set (19 studies) and ML algorithm
    (17). The former studies compared the performance of prediction models using different
    combinations of features, such as vegetation indices, spectral bands, sward height,
    and weather features. Nine studies investigated alternative sensors (e.g., UAV
    versus satellite). Six further factors were only examined in one study each. The
    number of manipulated factors per study was either one (16 studies), two (15),
    or three (2), whereas no manipulation was present in ten studies. Table 6 Manipulated
    factors in the included studies (N = 43) Full size table Model assessment Table
    7 shows the adoption of cross-validation and test set as techniques for model
    assessment. Twelve studies were limited to cross-validation, and another 13 studies
    only used a test set including new observations. The remaining 18 studies applied
    both techniques. Table 7 Model assessment in the included studies (N = 43) Full
    size table We note that the application and reporting of cross-validation exhibit
    large variation by leaving out one fold (19 studies), one example (7), or one
    site (1) in the training phase, whereas four studies provided no information in
    that respect. Regarding the test set, 29 of the 31 studies reported its size as
    a percentage of the whole data set. The number of examples ranged between 10 and
    433. Six studies had very small test sets with at most 24 examples, but ten studies
    had much larger test sets with more than one hundred examples. Performance metrics
    Table 8 reveals that R2 was reported in all but five studies. Thirty studies provided
    the root mean square error in kg per ha. Unitless normalizations of the RMSE were
    present in 25 studies. This normalization was either based on the mean (11 studies),
    range (4), standard deviation (2), and interquartile range (1) of the observed
    yield, or its specification was missing (7). Table 8 Performance metrics reported
    in the included studies (N = 43) Full size table Performance by types of optical
    sensors The high adoption rate of the unitless R2 metric allowed us to collate
    performance results as shown in Fig. 3, which groups 41 prediction models by the
    types of optical sensors used. The R2 ranged between 0.42 and 0.90 in the satellite
    group, between 0.50 and 0.94 in the aerial sensors group, and between 0.62 and
    0.92 in the in-field sensors group. The range was even smaller for the few prediction
    models that complemented in-field data by satellite data (0.71 to 0.90) and UAV
    data (0.81 to 0.92), respectively. Similarly, the mean performance in the in-field
    (0.79) and aerial groups (0.77) was higher than for the satellite (0.67) group.
    Two studies that processed data from aerial sensors and satellites at the same
    time reported R2 values of 0.70 (Pereira et al., 2022) and 0.72 (Barnetson et
    al., 2021), respectively (not shown in Fig. 3). Fig. 3 R2 of 41 prediction models
    by the types of optical sensors used (dots with filling indicate R2 on the test
    set, dots without filling stand for cross-validation) Full size image Feature
    importance Seventeen studies provided information on the importance of features.
    As shown in Table 9, many different techniques have been adopted, including variable
    importance in projection (Chong & Jun, 2005) and increase in RMSE (Kuhn, 2008).
    Six studies reported on the importance but lacked a specification of the technique
    used. In fifteen studies, only features based on spectral data were assessed (which
    is consistent with the focus on spectral variables in the data collection). In
    one study, the highest feature importance was assigned to canopy height (Schucknecht
    et al., 2022), and another study found that the relative importance of three weather
    features was one third, while three vegetation indices contributed two thirds
    (Bretas et al., 2021). Table 9 Techniques for feature importance reported in the
    included studies (N = 43) Full size table Discussion This review examined the
    adoption of machine-learning techniques for pasture yield prediction using optical
    sensor data. We analyzed forty-three studies that have been published in journals
    between 2015-01-01 and 2022-10-26. This section discusses the principal findings
    of the review and draws implications for future research and the reporting of
    studies. We also discuss the limitations of our review. Data collection For assessing
    the reliability of a trained prediction model, the number of fields, plots, and
    seasons are important factors that determine the size of the training set. These
    numbers can provide indications of how far the temporal and spatial variability
    of pasture yields have been considered in the data collection. Yet, more than
    half of the studies were conducted in one season, which restricts the training
    data to specific weather and growing conditions. One-third of the studies were
    limited to data from one field in one season. Even in the latter group of studies,
    the number of sample plots exhibited an enormous span from 21 to 1080. The chances
    that a model will perform similarly in future seasons can be enhanced by training
    the model on multi-seasonal data of different fields in which many plots capture
    the in-field variability. However, this approach puts a burden on researchers
    and farmers because the required effort for data collection increases significantly.
    The restriction of many studies to a single field limits the applicability of
    the trained models to a local level; hence, conclusions about their prediction
    performance beyond the specific field cannot be drawn. Three approaches are feasible
    to develop global models. First, data from a larger number of fields from different
    regions can be collected to develop models from data of greater heterogeneity.
    Second, data representing biotic and abiotic factors can be integrated to represent
    a larger set of growing conditions, thereby incorporating these factors into the
    development. A third possibility is to train a global prediction model by integrating
    multiple local models, i.e., the reuse of training data from different local sources
    (Liu et al., 2022). The included studies do not inform developers about the minimum
    size of the training set to achieve a reasonable level of prediction performance.
    One study manipulated the size but it found only marginal effects on performance
    (Rosa et al., 2021). The results of our review highlight that little is known
    about how to specify the size of the training set. This finding points to the
    need for further examination of the relationship between the training set and
    prediction performance. A common theme in the studies is the application of features
    derived from optical data, namely VIs (29 studies), spectral bands (19), textures
    (19), and sward height (15). Most studies collected data from at least two different
    types and considered multiple input variables, either alternatively or supplementary.
    The focus is on exploiting the potential of optical sensing and techniques for
    transforming image data into variables that are associated with plant growth.
    Therefore, it is not surprising that the number of VIs (1 to 97), spectral bands
    (2 to 2150), and textures (8 to 32) varied considerably across studies. It is
    noteworthy that the most frequent approach for measuring the sward height was
    UAV, which has substituted the manual measurement using hand-held devices. Consistent
    with the large array of VIs, spectral bands, textures, and sward height variables
    collected in combination, the types of optical sensors used indicate comprehensive
    coverage of current sensor technologies. All other types of input data, such as
    weather data (5 studies), site data (2), and agronomic data (1) played a minor
    role. This finding is surprising in view of the fact that such data can be obtained
    with relatively little effort or are already available. For instance, the retrieval
    of weather data is facilitated by online portal and programming interfaces (Jaffrés,
    2019). Historic and current weather data specifically for agricultural purposes
    are offered by companies, national meteorological agencies, and agricultural departments
    (Farmers Guide, 2022). Site and agronomic data are increasingly recorded by farmers
    and processed in digital farm management information systems. These data represent
    a so far hardly exploited potential for supplementing the spectral data and thus
    for training even more accurate prediction models. Data preprocessing Given the
    often-high dimensionality of the optical input data used, the objective of data
    processing is to reduce the number of features derived from the input data. This
    dimensionality is foremost due to the large number of VIs and spectral bands in
    many studies. The results of our review provide evidence for the relevance of
    feature selection, which was present in more than half of the studies (it was
    not relevant for four studies that collected data for a single feature). Overall,
    the techniques used span across filter-based, wrapper-based, and embedded techniques,
    and reflect the variety of techniques available from the ML literature. In many
    studies, the number of features was effectively reduced without increasing the
    error of prediction. For instance, one study started with a set of 20 VIs and
    eventually selected one VI based on correlation analysis (Hamada et al., 2021).
    Another study considered 2150 different spectral bands obtained from a hand-held
    spectroradiometer and then performed stepwise regression using backward elimination
    to arrive at a linear model with only seven features (Zeng & Chen, 2018). Similarly,
    a study by Chiarito et al. (2021) applied a genetic algorithm to an initial set
    of 1024 spectral bands to choose a 13-feature model. Concerning the final set
    of features processed in the training phase, our review identified six studies
    in which the lack of feature selection led to models trained from at least 26
    features (Grüner et al., 2020; Karunaratne et al., 2020; Lussem et al., 2022;
    Näsi et al., 2018; Pranga et al., 2021; Schucknecht et al., 2022). For these studies,
    it might be possible that a model with fewer features exists that would perform
    similarly. Therefore, we recommend exploring the impact of feature selection on
    prediction performance when the model was trained on a large number of features
    derived from optical data. For studies that adopt a hypothetico-deductive approach
    to the model development, we suggest determining the relative importance of each
    feature and relating the results back to the model development. We also note that
    almost one-fifth of the studies provided no information on the number of features.
    Presenting complete information on the features included in the trained model
    would help assess the input data that necessarily must be collected and data that
    can be omitted. This information can effectively be reported in a table showing
    each feature along its unit of measurement and definition (Chen et al., 2021).
    In case the number of features exceeds the possibilities of a table, the information
    can be summarized by indicating the numbers per type of sensor as well as the
    initial and final numbers (Schulze-Brüninghoff et al., 2021). Model training The
    highest adoption rates were found for Random Forests, PLS regression, and OLS
    regression, whereas only four studies used Artificial Neural Networks. It is noteworthy
    that PLS regression was employed in 13 studies. PLS regression is a form of multiple
    linear regression in which the number of initially used independent variables
    can automatically be reduced by an in-built principal component analysis to a
    smaller set of features. Therefore, PLS regression appears specifically relevant
    for the training from spectral input data, while it still assumes linear relationships
    between the features and the pasture yield. However, two studies that compared
    the performance of PLS and MLR models reported conflicting results concerning
    the R2 metric (Askari et al., 2019; Borra-Serrano et al., 2019). Regarding the
    performance of linear vis-á-vis non-linear models, four studies found better performance
    for non-linear models, but three other studies came to the opposite conclusion.
    Overall, the results of our review suggest no evidence for the superiority of
    any group of learning algorithms. Forty studies stated the size of the training
    set, which varied greatly because of the different numbers of fields, sampling
    plots, and seasons between studies. This size must be seen in the context of the
    temporal and spatial variability of the specific pasture under study. If a prediction
    model is learned from too few observations that do not sufficiently represent
    this variability, the model will perform very differently for other test data.
    Our review identified two studies that had very small training sets of 32 (Näsi
    et al., 2018) and 36 observations (Li et al., 2021), respectively. Although no
    clear guidance is available for determining the minimum size required, it can
    give readers a hint about the reliability of the prediction model. Therefore,
    we suggest reporting complete and unequivocal information on the training and
    test sets used. The reporting should always include the absolute and relative
    numbers for each data set. For instance, this information can be visualized in
    a flow diagram that specifies the data processing (Murphy et al., 2022), or provided
    in a single sentence, such as the following: “the complete dataset was first divided
    into two parts in a 70:30 ratio (231 observations for the training dataset and
    99 observations for the test dataset)” (Da Silva et al., 2022, pp. 6039–6040).
    Moreover, any removal of observations throughout the preprocessing and learning
    phases should be justified, instead of generally referring to so-called outlier
    removal. Model evaluation Insights into the role of specific ML techniques for
    achieving high performance can be obtained from systematic testing of alternative
    models. The preferred method is the controlled experiment in which one or more
    factors are manipulated (33 of 43 studies). Our review identified feature sets,
    ML algorithms, and optical sensors as the most frequently used factors. The relevance
    of feature sets and sensors can be explained by the range of input data to capture
    the temporal and spatial variability of pasture yields. The evaluation should
    be conducted in a way that can mitigate the overfitting of a learned prediction
    model. A model is said to overfit if it fits well to the training set but exhibits
    much lower performance on new observations. For instance, it might be possible
    that a model that has been trained on a rich set of sensor data collected from
    several fields in different seasons will perform much worse for a different field
    or in a future season. To address the overfitting problem, cross-validation is
    appropriate for situations in which the total number of observations is insufficiently
    large to divide them into training and test sets. Different types of cross-validation
    are available, and they have been adopted in several ways. With respect to k-fold
    CV, the number of folds ranged between 3 and 20, with no study providing a rationale
    for the number chosen. This deficit also holds for the number of iterations of
    a CV; iterations were present in seven studies, and they spanned from only 5 to
    1000. Leave-one-out CV must be regarded as the weakest type of CV because it likely
    overstates the prediction performance for extremely small ratios of new observations,
    such as 1080:1 in one study (Sibanda et al., 2017). Almost three-fourths of the
    included studies assessed performance on a separate test set, instead of solely
    relying on cross-validation. Two studies stand out that trained models in one
    season (Togeiro de Alckmin et al., 2022) or two seasons (Murphy et al., 2022)
    to evaluate them in the subsequent season. Another study performed the evaluation
    on test data from a different field in the same season (de Oliveira et al., 2020).
    The size of the test set was most often stated explicitly in a table or text in
    the results section. For some articles, the size could be derived from a percentage
    value in relation to the entire data set. In seven other studies, the reporting
    in that respect was incomplete or inconsistent, but we could determine the number
    of observations through counting of dots shown in scatter plots. In a similar
    vein as for the training set, we recommend specifying the test procedure including
    the absolute and relative number of observations, any further data cleansing that
    led to the removal of observations, and the number of runs (if relevant). Regarding
    the reporting of performance metrics, our review provides three major findings
    that have implications for the interpretation of study results. The first finding
    is the relatively high adoption of the R2 (91%), followed by the RMSE (71%). Because
    R2 is a unitless metric, it can in principle help compare the performance of different
    models that predict the same type of pasture yield. Its interpretation is less
    dependent on the study context compared to the RMSE. The latter metric is more
    informative for farmers of the specific fields from which the observations had
    been collected and it can help assess how useful the prediction model is compared
    to current means of yield prediction. However, the RMSE cannot be used to compare
    models that have been trained on different observations. In other words, any claim
    about a proposed model that its RMSE would be smaller than that of a model proposed
    in previous research must be taken with great caution. In view of the duality
    of metrics that serve very different purposes, we contend that there is no reason
    not to report the R2 and RMSE. The second finding concerns the heterogeneity and
    ambiguity of the normalized RMSE. Given that the NRMSE was reported in more than
    half of the studies, this unitless metric might be used for comparing the results
    of similar studies. Unfortunately, we identified at least four different definitions,
    which render the comparison of results impossible. Only eleven studies reported
    the RMSE divided by the mean observed yield. This definition might be regarded
    as the ‘common’ meaning of the NRMSE, but seven studies provided no further details.
    This practice is questionable because readers might assume a definition that is
    different from the calculation done in the study. To make matters worse, the abstracts
    of 14 studies only indicated the NRMSE but not its exact definition. Moreover,
    different designations were used including NRMSE, nRMSE, relative RMSE (rRMSE),
    RRMSE, RMSE%, and RMSE with a percentage value. Taken together, our finding highlights
    the need for greater clarity in the reporting to avoid misinterpretations of the
    NRMSE. The third finding is the lack of consensus regarding the reporting of metrics
    to comprehensively describe prediction performance. The three most commonly used
    metrics (R2, RMSE, and NRMSE) were only reported in one-third of the studies.
    The frequencies of metrics such as MAE (10), Lin’s concordance correlation coefficient
    (2), Willmott’s d (2), and mean average percentage error (1) were negligible,
    although other literature has highlighted the usefulness of these supplementary
    metrics (Chai & Draxler, 2014; Willmott & Matsuura, 2005). Irrespective of the
    advantages and disadvantages of specific metrics, we recommend reporting a larger
    set of metrics, including but not limited to the R2, RMSE, and NRMSE. Because
    of the large heterogeneity in the reporting of metrics discussed above, our analysis
    of prediction performance by the types of optical sensors used was limited to
    the R2 metric reported for 41 prediction models from 36 studies. We found that
    the variability of R2 decreased for smaller distance from the pasture sward; thus,
    the largest variability was observed for models trained from satellite data and
    it decreased considerably for aerial sensors and in-field sensors. These results
    suggest that the higher spatial and temporal resolution of in-field imagery can
    make a difference in the training of effective models. Although the individual
    contribution of specific features to prediction performance can be determined
    using feature importance, this was the case in only 17 studies. All but two of
    these studies focused on features derived from spectral data. Therefore, there
    is yet little evidence for the roles of biotic versus abiotic features, including
    weather, site, and agronomic features. The results of previous studies using optical
    sensing do not inform us about the influence of such features on the accuracy
    of models. Opportunities exist to examine the supplementing roles of non-spectral
    features, especially of those features for which data collection is relatively
    easy or the data is already available from the farmers. Collectively, the results
    of our review also highlight challenges for prediction models to become less local
    and increasingly global. Especially the large differences of pastures regarding
    soil properties, weather conditions, and plant species make the development of
    generalizable prediction model challenging. The collection of data reflecting
    biotic and abiotic factors is not possible by remote sensing alone. To develop
    more globally applicable models, it is necessary to include data from complementary
    sources (e.g., weather stations, soil analysis, and farm management information
    systems). Limitations The results of this review should be understood in light
    of its limitations. The included studies varied greatly in the processing of input
    data and how prediction models were trained. Therefore, it was not possible to
    conduct in-depth comparisons of performance results, except for the types of optical
    sensors used. Another limitation of the review is due to the large heterogeneity
    of the reporting of performance metrics. This heterogeneity limited the number
    of studies for which performance results could be synthesized; this synthesis
    was only possible for the R2 but not for the NRMSE. Third, although our data collection
    involved three independent coders, all results presented in this review were bound
    to the information reported in the original studies (in a few cases, we contacted
    the authors to clarify the meaning of specific statements though). Conclusion
    This systematic review provides a comprehensive account of the application of
    ML for the prediction of pasture yield using optical sensor data. The results
    highlight the richness of techniques used for the collection and preprocessing
    of input data as well as the training and evaluation of prediction models. Our
    review also revealed some shortcomings in the assessment of prediction performance
    and the presentation of study designs and results. Specifically, we identified
    deficits in the reporting of feature sets and complete information on the training
    and test data, and a lack of consensus in the reporting of performance metrics.
    We suggest specific recommendations to enhance the uniformity and comparability
    of study results, which can then facilitate the integration of evidence on the
    role of specific ML techniques for accurate and reliable yield predictions of
    managed pastures. References Adão, T., Hruška, J., Pádua, L., Bessa, J., Peres,
    E., Morais, R., & Sousa, J. (2017). Hyperspectral imaging: A review on UAV-based
    sensors, data processing and applications for agriculture and forestry. Remote
    Sensing, 9(11), 1110. https://doi.org/10.3390/rs9111110. Article   Google Scholar   Ali,
    I., Cawkwell, F., Dwyer, E., & Green, S. (2017). Modeling managed grassland biomass
    estimation by using multitemporal remote sensing data—a machine learning approach.
    IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing,
    10(7), 3254–3264. https://doi.org/10.1109/JSTARS.2016.2561618. Article   Google
    Scholar   Askari, M. S., McCarthy, T., Magee, A., & Murphy, D. J. (2019). Evaluation
    of grass quality under different soil management scenarios using remote sensing
    techniques. Remote Sensing, 11(15), 1835. https://doi.org/10.3390/rs11151835.
    Article   Google Scholar   Baldocchi, D. D., Xu, L., & Kiang, N. (2004). How plant
    functional-type, weather, seasonal drought, and soil physical properties alter
    water and energy fluxes of an oak–grass savanna and an annual grassland. Agricultural
    and Forest Meteorology, 123(1–2), 13–39. https://doi.org/10.1016/j.agrformet.2003.11.006.
    Article   Google Scholar   Barnetson, J., Phinn, S., & Scarth, P. (2021). Climate-resilient
    grazing in the pastures of Queensland: An integrated remotely piloted aircraft
    system and satellite-based deep-learning method for estimating pasture yield.
    AgriEngineering, 3(3), 681–703. https://doi.org/10.3390/agriengineering3030044.
    Article   Google Scholar   Bazzo, C. O. G., Kamali, B., Hütt, C., Bareth, G.,
    & Gaiser, T. (2023). A review of estimation methods for aboveground biomass in
    grasslands using UAV. Remote Sensing, 15(3), 639. https://doi.org/10.3390/rs15030639.
    Article   Google Scholar   Bishop, C. M. (2006). Pattern recognition and machine
    learning. Springer. Borra-Serrano, I., de Swaef, T., Muylle, H., Nuyttens, D.,
    Vangeyte, J., Mertens, K., Saeys, W., Somers, B., Roldán-Ruiz, I., & Lootens,
    P. (2019). Canopy height measurements and non‐destructive biomass estimation of
    Lolium perenne swards using UAV imagery. Grass and Forage Science, 74(3), 356–369.
    https://doi.org/10.1111/gfs.12439. Article   Google Scholar   Bouwman, A. F.,
    van der Hoek, K. W., Eickhout, B., & Soenario, I. (2005). Exploring changes in
    world ruminant production systems. Agricultural Systems, 84(2), 121–153. https://doi.org/10.1016/j.agsy.2004.05.006.
    Article   Google Scholar   Bretas, I. L., Valente, D. S. M., Silva, F. F., Chizzotti,
    M. L., Paulino, M. F., D’Áurea, A. P., Paciullo, D. S., Pedreira, B. C., & Chizzotti,
    F. H. M (2021). Prediction of aboveground biomass and dry-matter content in Brachiaria
    pastures by combining meteorological data and satellite imagery. Grass and Forage
    Science, 76(3), 340–352. https://doi.org/10.1111/gfs.12517. Article   Google Scholar   Buckley,
    C., Wall, D. P., Moran, B., O’Neill, S., & Murphy, P. N. C. (2016). Farm gate
    level nitrogen balance and use efficiency changes post implementation of the EU
    Nitrates Directive. Nutrient Cycling in Agroecosystems, 104(1), 1–13. https://doi.org/10.1007/s10705-015-9753-y.
    Article   CAS   Google Scholar   Chai, T., & Draxler, R. R. (2014). Root mean
    square error (RMSE) or mean absolute error (MAE)? – arguments against avoiding
    RMSE in the literature. Geoscientific Model Development, 7(3), 1247–1250. https://doi.org/10.5194/gmd-7-1247-2014.
    Article   Google Scholar   Chandrashekar, G., & Sahin, F. (2014). A survey on
    feature selection methods. Computers & Electrical Engineering, 40(1), 16–28. https://doi.org/10.1016/j.compeleceng.2013.11.024.
    Article   Google Scholar   Chen, Y., Guerschman, J., Shendryk, Y., Henry, D.,
    & Harrison, M. T. (2021). Estimating pasture biomass using Sentinel-2 imagery
    and machine learning. Remote Sensing, 13(4), https://doi.org/10.3390/rs13040603.
    Chiarito, E., Cigna, F., Cuozzo, G., Fontanelli, G., Mejia Aguilar, A., Paloscia,
    S., Rossi, M., Santi, E., Tapete, D., & Notarnicola, C. (2021). Biomass retrieval
    based on genetic algorithm feature selection and support vector regression in
    Alpine grassland using ground-based hyperspectral and Sentinel-1 SAR data. European
    Journal of Remote Sensing, 54(1), 209–225. https://doi.org/10.1080/22797254.2021.1901063.
    Article   Google Scholar   Chong, I. G., & Jun, C. H. (2005). Performance of some
    variable selection methods when multicollinearity is present. Chemometrics and
    Intelligent Laboratory Systems, 78(1–2), 103–112. https://doi.org/10.1016/j.chemolab.2004.12.011.
    Article   CAS   Google Scholar   Da Silva, Y. F., Dos Reis, A., Sampaio Werner,
    A., Valadares, J. P. V., Campbell, R., Camargo Lamparelli, E. E. A., Magalhães,
    R., P. S. G., & Figueiredo, G. K. D. A (2022). Assessing the capability of MODIS
    to monitor mixed pastures with high-intensity grazing at a fine-scale. Geocarto
    International, 37(20), 6033–6051. https://doi.org/10.1080/10106049.2021.1926559.
    Article   Google Scholar   de Oliveira, R. A., Näsi, R., Niemeläinen, O., Nyholm,
    L., Alhonoja, K., Kaivosoja, J., Jauhiainen, L., Viljanen, N., Nezami, S., Markelin,
    L., Hakala, T., & Honkavaara, E. (2020). Machine learning estimators for the quantity
    and quality of grass swards used for silage production using drone-based imaging
    spectrometry and photogrammetry. Remote Sensing of Environment, 246, 111830. https://doi.org/10.1016/j.rse.2020.111830.
    Article   Google Scholar   de Oliveira, G. S., Marcato Junior, J., Polidoro, C.,
    Osco, L. P., Siqueira, H., Rodrigues, L., Jank, L., Barrios, S., Valle, C., Simeão,
    R., Carromeu, C., Silveira, E., de Castro Jorge, A., Gonçalves, L., Santos, W.,
    M., & Matsubara, E. (2021). Convolutional neural networks to estimate dry matter
    yield in a Guineagrass breeding program using UAV remote sensing. Sensors (Basel,
    Switzerland), 21(12), https://doi.org/10.3390/s21123971. De Rosa, D., Basso, B.,
    Fasiolo, M., Friedl, J., Fulkerson, B., Grace, P. R., & Rowlings, D. W. (2021).
    Predicting pasture biomass using a statistical model and machine learning algorithm
    implemented with remotely sensed imagery. Computers and Electronics in Agriculture,
    180, 105880. https://doi.org/10.1016/j.compag.2020.105880. Article   Google Scholar   Togeiro
    de Alckmin G., Kooistra, L., Rawnsley, R., & Lucieer, A. (2021). Comparing methods
    to estimate perennial ryegrass biomass: Canopy height and spectral vegetation
    indices. Precision Agriculture, 22(1), 205–225. https://doi.org/10.1007/s11119-020-09737-z.
    Togeiro de Alckmin G., Lucieer, A., Rawnsley, R., & Kooistra, L. (2022). Perennial
    ryegrass biomass retrieval through multispectral UAV data. Computers and Electronics
    in Agriculture, 193, 106574. https://doi.org/10.1016/j.compag.2021.106574. Donnison,
    I. S., & Fraser, M. D. (2016). Diversification and use of bioenergy to maintain
    future grasslands. Food and Energy Security, 5(2), 67–75. https://doi.org/10.1002/fes3.75.
    Article   PubMed   PubMed Central   Google Scholar   Dos Reis, A. A., Werner,
    J. P. S., Silva, B. C., Figueiredo, G. K. D. A., Antunes, J. F. G., Esquerdo,
    J. C. D. M., Coutinho, A. C., Lamparelli, R. A. C., Rocha, J. V., & Magalhães,
    P. S. G. (2020). Monitoring pasture aboveground biomass and canopy height in an
    integrated crop–livestock system using textural information from PlanetScope imagery.
    Remote Sensing, 12(16), 2534. https://doi.org/10.3390/RS12162534. Article   Google
    Scholar   Drucker, H., Burges, C. J. C., Kaufman, L., Smola, A., & Vapnik, V.
    (1996). Support Vector Regression Machines. In M. C. Mozer, M. Jordan, & T. Petsche
    (Eds.), Advances in neural information processing systems (Vol. 9). MIT Press.
    https://proceedings.neurips.cc/paper/1996/file/d38901788c533e8286cb6400b40b386d-Paper.pdf.
    Farmers Guide (2022). UK-wide weather station network provides data to aid agronomic
    decision making. https://www.farmersguide.co.uk/local-weather-data-aids-agronomic-decision-making/.
    Feng, L., Chen, S., Zhang, C., Zhang, Y., & He, Y. (2021). A comprehensive review
    on recent applications of unmanned aerial vehicle remote sensing with various
    sensors for high-throughput plant phenotyping. Computers and Electronics in Agriculture,
    182, 106033. https://doi.org/10.1016/j.compag.2021.106033. Article   Google Scholar   Franceschini,
    M. H. D., Becker, R., Wichern, F., & Kooistra, L. (2022). Quantification of grassland
    biomass and nitrogen content through UAV hyperspectral imagery—active sample selection
    for model transfer. Drones, 6(3), 73. https://doi.org/10.3390/drones6030073. Article   Google
    Scholar   Freitas, R. G., Pereira, F. R., Reis, D., Magalhães, A. A., Figueiredo,
    P. S. G., D., G. K. A.,do, & Amaral, L. R. (2022). Estimating pasture aboveground
    biomass under an integrated crop-livestock system based on spectral and texture
    measures derived from UAV images. Computers and Electronics in Agriculture, 198,
    Article 107122. https://doi.org/10.1016/j.compag.2022.107122. Geipel, J., Bakken,
    A. K., Jørgensen, M., & Korsaeth, A. (2021). Forage yield and quality estimation
    by means of UAV and hyperspectral imaging. Precision Agriculture, 22(5), 1437–1463.
    https://doi.org/10.1007/s11119-021-09790-2. Article   CAS   Google Scholar   Grüner,
    E., Astor, T., & Wachendorf, M. (2019). Biomass prediction of heterogeneous temperate
    grasslands using an SfM approach based on UAV imaging. Agronomy, 9(2), 54. https://doi.org/10.3390/agronomy9020054.
    Article   Google Scholar   Grüner, E., Wachendorf, M., & Astor, T. (2020). The
    potential of UAV-borne spectral and textural information for predicting aboveground
    biomass and N fixation in legume-grass mixtures. PLOS ONE, 15(6), e0234703. https://doi.org/10.1371/journal.pone.0234703.
    Article   CAS   PubMed   PubMed Central   Google Scholar   Hamada, Y., Zumpf,
    C. R., Cacho, J. F., Lee, D., Lin, C. H., Boe, A., Heaton, E., Mitchell, R., &
    Negri, M. C. (2021). Remote sensing-based estimation of advanced perennial grass
    biomass yields for bioenergy. Land, 10(11), 1221. https://doi.org/10.3390/land10111221.
    Article   Google Scholar   Haralick, R. M., Shanmugam, K., & Dinstein, I. (1973).
    Textural features for image classification. IEEE Transactions on Systems, Man,
    and Cybernetics, SMC-3(6), 610–621. https://doi.org/10.1109/TSMC.1973.4309314.
    Hedley, C. (2015). The role of precision agriculture for improved nutrient management
    on farms. Journal of the Science of Food and Agriculture, 95(1), 12–19. https://doi.org/10.1002/jsfa.6734.
    Article   CAS   PubMed   Google Scholar   Henchion, M., Hayes, M., Mullen, A.
    M., Fenelon, M., & Tiwari, B. (2017). Future protein supply and demand: Strategies
    and factors influencing a sustainable equilibrium. Foods, 6(7), https://doi.org/10.3390/foods6070053.
    Ho, T. K. (1995). Random decision forests. In Proceedings of 3rd International
    Conference on Document Analysis and Recognition (ICDAR) (pp. 278–282). IEEE. https://doi.org/10.1109/ICDAR.1995.598994.
    Hopkins, A., & Del Prado, A. (2007). Implications of climate change for grassland
    in Europe: Impacts, adaptations and mitigation options: A review. Grass and Forage
    Science, 62(2), 118–126. https://doi.org/10.1111/j.1365-2494.2007.00575.x. Article   CAS   Google
    Scholar   Jaberalansar, Z., Tarkesh, M., & Bassiri, M. (2017). Soil moisture index
    improves models of forage production in central Iran. Archives of Agronomy and
    Soil Science, 63(12), 1763–1775. https://doi.org/10.1080/03650340.2017.1296138.
    Article   Google Scholar   Jackman, P., Lee, T., French, M., Sasikumar, J., O’Byrne,
    P., Berry, D., Lacey, A., & Ross, R. (2021). Predicting key grassland characteristics
    from hyperspectral data. AgriEngineering, 3(2), 313–322. https://doi.org/10.3390/agriengineering3020021.
    Article   Google Scholar   Jaffrés, J. B. (2019). GHCN-Daily: A treasure trove
    of climate data awaiting discovery. Computers & Geosciences, 122, 35–44. https://doi.org/10.1016/j.cageo.2018.07.003.
    Article   Google Scholar   Kallenbach, R. L. (2015). Describing the dynamic: Measuring
    and assessing the value of plants in the pasture. Crop Science, 55(6), 2531–2539.
    https://doi.org/10.2135/cropsci2015.01.0065. Article   CAS   Google Scholar   Karunaratne,
    S., Thomson, A., Morse-McNabb, E., Wijesingha, J., Stayches, D., Copland, A.,
    & Jacobs, J. (2020). The fusion of spectral and structural datasets derived from
    an airborne multispectral sensor for estimation of pasture dry matter yield at
    paddock scale with time. Remote Sensing, 12(12), 2017. https://doi.org/10.3390/rs12122017.
    Article   Google Scholar   Kent Shannon, D., Clay, D. E., & Sudduth, K. A. (2018).
    An introduction to precision agriculture. In D. K. Shannon, D. E. Clay, & N. R.
    Kitchen (Eds.), Precision agriculture basics (pp. 1–12). John Wiley & Sons. https://doi.org/10.2134/precisionagbasics.2016.0084.
    Klaus, V. H., Kleinebecker, T., Prati, D., Gossner, M. M., Alt, F., Boch, S.,
    Gockel, S., Hemp, A., Lange, M., Müller, J., Oelmann, Y., Pašalić, E., Renner,
    S. C., Socher, S. A., Türke, M., Weisser, W. W., Fischer, M., & Hölzel, N. (2013).
    Does organic grassland farming benefit plant and arthropod diversity at the expense
    of yield and soil fertility? Agriculture Ecosystems & Environment, 177, 1–9. https://doi.org/10.1016/j.agee.2013.05.019.
    Article   Google Scholar   Kuhn, M. (2008). Building predictive models in R using
    the caret package. Journal of Statistical Software, 28(5), https://doi.org/10.18637/jss.v028.i05.
    Lange, M., Habekost, M., Eisenhauer, N., Roscher, C., Bessler, H., Engels, C.,
    Oelmann, Y., Scheu, S., Wilcke, W., Schulze, E. D., & Gleixner, G. (2014). Biotic
    and abiotic properties mediating plant diversity effects on soil microbial communities
    in an experimental grassland. PLOS ONE, 9(5), e96182. https://doi.org/10.1371/journal.pone.0096182.
    Article   CAS   PubMed   PubMed Central   Google Scholar   Li, K. Y., Burnside,
    N. G., Sampaio de Lima, R., Villoslada Peciña, M., Sepp, K., Yang, M. D., Raet,
    J., Vain, A., Selge, A., & Sepp, K. (2021). The application of an unmanned aerial
    system and machine learning techniques for red clover-grass mixture yield estimation
    under variety performance trials. Remote Sensing, 13(10), 1994. https://doi.org/10.3390/rs13101994.
    Liu, J., [Ji], Huang, J., Zhou, Y., Li, X., [Xuhong], Ji, S., Xiong, H., & Dou,
    D. (2022). From distributed machine learning to federated learning: A survey.
    Knowledge and Information Systems, 64(4), 885–917. https://doi.org/10.1007/s10115-022-01664-x.
    Article   Google Scholar   Lussem, U., Schellberg, J., & Bareth, G. (2020). Monitoring
    forage mass with low-cost UAV data: Case study at the Rengen Grassland Experiment.
    PFG – Journal of Photogrammetry Remote Sensing and Geoinformation Science, 88(5),
    407–422. https://doi.org/10.1007/s41064-020-00117-w. Article   Google Scholar   Lussem,
    U., Bolten, A., Kleppert, I., Jasper, J., Gnyp, M. L., Schellberg, J., & Bareth,
    G. (2022). Herbage mass, N concentration, and N uptake of temperate grasslands
    can adequately be estimated from UAV-based image data using machine learning.
    Remote Sensing, 14(13), 3066. https://doi.org/10.3390/rs14133066. Article   Google
    Scholar   Lyu, X., Li, X., [Xiaobing], Dang, D., Dou, H., Wang, K., & Lou, A.
    (2022). Unmanned aerial vehicle (UAV) remote sensing in grassland ecosystem monitoring:
    A systematic review. Remote Sensing, 14(5), 1096. https://doi.org/10.3390/rs14051096.
    Article   Google Scholar   Moher, D., Liberati, A., Tetzlaff, J., & Altman, D.
    G. (2009). Preferred reporting items for systematic reviews and meta-analyses:
    The PRISMA statement. Annals of Internal Medicine, 151(4), 264–269. https://doi.org/10.7326/0003-4819-151-4-200908180-00135.
    Article   PubMed   Google Scholar   Mongeon, P., & Paul-Hus, A. (2016). The journal
    coverage of web of Science and Scopus: A comparative analysis. Scientometrics,
    106(1), 213–228. https://doi.org/10.1007/s11192-015-1765-5. Article   Google Scholar   Morais,
    T. G., Teixeira, R. F., Figueiredo, M., & Domingos, T. (2021). The use of machine
    learning methods to estimate aboveground biomass of grasslands: A review. Ecological
    Indicators, 130, Article 108081. https://doi.org/10.1016/j.ecolind.2021.108081.
    Mundava, C., Schut, A. G. T., Helmholz, P., Stovold, R., Donald, G., & Lamb, D.
    W. (2015). A novel protocol for assessment of aboveground biomass in rangeland
    environments. The Rangeland Journal, 37(2), 157. https://doi.org/10.1071/RJ14072.
    Article   Google Scholar   Murphy, D. J., Murphy, M. D., O’Brien, B., & O’Donovan,
    M. (2021). A review of precision technologies for optimising pasture measurement
    on irish grassland. Agriculture, 11(7), 600. https://doi.org/10.3390/agriculture11070600.
    Article   Google Scholar   Murphy, D. J., O’ Brien, B., O’ Donovan, M., Condon,
    T., & Murphy, M. D. (2022). A near infrared spectroscopy calibration for the prediction
    of fresh grass quality on irish pastures. Information Processing in Agriculture,
    9(2), 243–253. https://doi.org/10.1016/j.inpa.2021.04.012. Article   Google Scholar   Näsi,
    R., Viljanen, N., Kaivosoja, J., Alhonoja, K., Hakala, T., Markelin, L., & Honkavaara,
    E. (2018). Estimating biomass and nitrogen amount of barley and grass using UAV
    and aircraft based spectral and photogrammetric 3D features. Remote Sensing, 10(7),
    1082. https://doi.org/10.3390/rs10071082. Article   Google Scholar   Nguyen, P.
    T., Shi, F., Wang, J., Badenhorst, P. E., Spangenberg, G. C., Smith, K. F., &
    Daetwyler, H. D. (2022). Within and combined season prediction models for perennial
    ryegrass biomass yield using ground- and air-based sensor data. Frontiers in Plant
    Science, 13, 950720. https://doi.org/10.3389/fpls.2022.950720. Article   PubMed   PubMed
    Central   Google Scholar   O’Mara, F. P. (2012). The role of grasslands in food
    security and climate change. Annals of Botany, 110(6), 1263–1270. https://doi.org/10.1093/aob/mcs209.
    Article   PubMed   PubMed Central   Google Scholar   Pereira, F. S., de Lima,
    J. P., Freitas, R. G., Reis, D., Amaral, A. A., Figueiredo, L., Lamparelli, G.
    K. D. A., R., & Magalhães, P. (2022). Nitrogen variability assessment of pasture
    fields under an integrated crop-livestock system using UAV, PlanetScope, and Sentinel-2
    data. Computers and Electronics in Agriculture, 193, Article 106645. https://doi.org/10.1016/j.compag.2021.106645.
    Pranga, J., Borra-Serrano, I., Aper, J., de Swaef, T., an, Ghesquiere, Quataert,
    P., Roldán-Ruiz, I., Janssens, I. A., Ruysschaert, G., & Lootens, P. (2021). Improving
    accuracy of herbage yield predictions in perennial ryegrass with UAV-based structural
    and spectral data fusion and machine learning. Remote Sensing, 13(17), 3459. https://doi.org/10.3390/rs13173459.
    Raab, C., Riesch, F., Tonn, B., Barrett, B., Meißner, M., Balkenhol, N., & Isselstein,
    J. (2020). Target-oriented habitat and wildlife management: Estimating forage
    quantity and quality of semi‐natural grasslands with Sentinel‐1 and Sentinel‐2
    data. Remote Sensing in Ecology and Conservation, 6(3), 381–398. https://doi.org/10.1002/rse2.149.
    Article   Google Scholar   Schucknecht, A., Seo, B., Krämer, A., Asam, S., Atzberger,
    C., & Kiese, R. (2022). Estimating dry biomass and plant nitrogen concentration
    in pre-alpine grasslands with low-cost UAS-borne multispectral data – a comparison
    of sensors, algorithms, and predictor sets. Biogeosciences, 19(10), 2699–2727.
    https://doi.org/10.5194/bg-19-2699-2022. Article   CAS   Google Scholar   Schulze-Brüninghoff,
    D., Wachendorf, M., & Astor, T. (2021). Remote sensing data fusion as a tool for
    biomass prediction in extensive grasslands invaded by L. polyphyllus. Remote Sensing
    in Ecology and Conservation, 7(2), 198–213. https://doi.org/10.1002/rse2.182.
    Article   Google Scholar   Schwieder, M., Buddeberg, M., Kowalski, K., Pfoch,
    K., Bartsch, J., Bach, H., Pickert, J., & Hostert, P. (2020). Estimating grassland
    parameters from Sentinel-2: A model comparison study. PFG – Journal of Photogrammetry
    Remote Sensing and Geoinformation Science, 88(5), 379–390. https://doi.org/10.1007/s41064-020-00120-1.
    Article   Google Scholar   Shmueli, G. (2010). To explain or to predict? Statistical
    Science, 25(3), https://doi.org/10.1214/10-STS330. Sibanda, M., Mutanga, O., Rouget,
    M., & Kumar, L. (2017). Estimating biomass of native grass grown under complex
    management treatments using WorldView-3 spectral derivatives. Remote Sensing,
    9(1), 55. https://doi.org/10.3390/rs9010055. Article   Google Scholar   Singh,
    V. K., Singh, P., Karmakar, M., Leta, J., & Mayr, P. (2021). The journal coverage
    of web of Science, Scopus and Dimensions: A comparative analysis. Scientometrics,
    126(6), 5113–5142. https://doi.org/10.1007/s11192-021-03948-5. Article   Google
    Scholar   Smit, H. J., Metzger, M. J., & Ewert, F. (2008). Spatial distribution
    of grassland productivity and land use in Europe. Agricultural Systems, 98(3),
    208–219. https://doi.org/10.1016/j.agsy.2008.07.004. Article   Google Scholar   Sorkau,
    E., Boch, S., Boeddinghaus, R. S., Bonkowski, M., Fischer, M., Kandeler, E., Klaus,
    V. H., Kleinebecker, T., Marhan, S., Müller, J., Prati, D., Schöning, I., Schrumpf,
    M., Weinert, J., & Oelmann, Y. (2018). The role of soil chemical properties, land
    use and plant diversity for microbial phosphorus in forest and grassland soils.
    Journal of Plant Nutrition and Soil Science, 181(2), 185–197. https://doi.org/10.1002/jpln.201700082.
    Article   CAS   Google Scholar   Squires, V. R., Dengler, J., Feng, H., & Hua,
    L. (Eds.). (2018). Grasslands of the world: Diversity, management and conservation.
    CRC PRESS. https://www.taylorfrancis.com/books/9781315156125. Subhashree, S. N.,
    Igathinathane, C., Akyuz, A., Borhan, M., Hendrickson, J., Archer, D., Liebig,
    M., Toledo, D., Sedivec, K., Kronberg, S., & Halvorson, J. (2023). Tools for predicting
    forage growth in rangelands and economic analyses—a systematic review. Agriculture,
    13(2), 455. https://doi.org/10.3390/agriculture13020455. Article   Google Scholar   Sun,
    S., Zuo, Z., Yue, W., Morel, J., Parsons, D., Liu, J., [Jian], Peng, J., Cen,
    H., He, Y., Shi, J., Li, X., [Xiaolong], & Zhou, Z. (2022). Estimation of biomass
    and nutritive value of grass and clover mixtures by analyzing spectral and crop
    height data using chemometric methods. Computers and Electronics in Agriculture,
    192, 106571. https://doi.org/10.1016/j.compag.2021.106571. Article   Google Scholar   Théau,
    J., Lauzier-Hudon, É., Aubé, L., & Devillers, N. (2021). Estimation of forage
    biomass and vegetation cover in grasslands using UAV imagery. PLOS ONE, 16(1),
    e0245784. https://doi.org/10.1371/journal.pone.0245784. Article   CAS   PubMed   PubMed
    Central   Google Scholar   Thelwall, M., & Sud, P. (2022). Scopus 1900–2020: Growth
    in articles, abstracts, countries, fields, and journals. Quantitative Science
    Studies, 3(1), 37–50. https://doi.org/10.1162/qss_a_00177. Article   Google Scholar   Thomson,
    A. L., Karunaratne, S. B., Copland, A., Stayches, D., McNabb, E. M., & Jacobs,
    J. (2020). Use of traditional, modern, and hybrid modelling approaches for in
    situ prediction of dry matter yield and nutritive characteristics of pasture using
    hyperspectral datasets. Animal Feed Science and Technology, 269, 114670. https://doi.org/10.1016/j.anifeedsci.2020.114670.
    Article   CAS   Google Scholar   Tripathi, A. D., Mishra, R., Maurya, K. K., Singh,
    R. B., & Wilson, D. W. (2018). Estimates for world population and global food
    availability for global health. In R. R. Watson, R. B. Singh, & T. Takahashi (Eds.),
    The role of functional food security in global health (pp. 3–24). Elsevier Science
    & Technology. https://doi.org/10.1016/B978-0-12-813148-0.00001-3. van der Merwe,
    D., Baldwin, C. E., & Boyer, W. (2020). An efficient method for estimating dormant
    season grass biomass in tallgrass prairie from ultra-high spatial resolution aerial
    imaging produced with small unmanned aircraft systems. International Journal of
    Wildland Fire, 29(8), 696. https://doi.org/10.1071/WF19026. Article   CAS   Google
    Scholar   Willmott, C. J., & Matsuura, K. (2005). Advantages of the mean absolute
    error (MAE) over the root mean square error (RMSE) in assessing average model
    performance. Climate Research, 30, 79–82. https://doi.org/10.3354/cr030079. Article   Google
    Scholar   Xue, J., & Su, B. (2017). Significant remote sensing vegetation indices:
    a review of developments and applications. Journal of Sensors, 2017, 1–17. https://doi.org/10.1155/2017/1353691.
    Yao, Z., Xin, Y., Yang, L., Zhao, L., & Ali, A. (2022). Precipitation and temperature
    regulate species diversity, plant coverage and aboveground biomass through opposing
    mechanisms in large-scale grasslands. Frontiers in Plant Science, 13, 999636.
    https://doi.org/10.3389/fpls.2022.999636. Article   PubMed   PubMed Central   Google
    Scholar   Zeng, L., & Chen, C. (2018). Using remote sensing to estimate forage
    biomass and nutrient contents at different growth stages. Biomass and Bioenergy,
    115, 74–81. https://doi.org/10.1016/j.biombioe.2018.04.016. Article   CAS   Google
    Scholar   Zeng, L., Wardlow, B. D., Xiang, D., Hu, S., & Li, D. (2020). A review
    of vegetation phenological metrics extraction using time-series, multispectral
    satellite data. Remote Sensing of Environment, 237, 111511. https://doi.org/10.1016/j.rse.2019.111511.
    Article   Google Scholar   Zhao, Y., Liu, Z., & Wu, J. (2020). Grassland ecosystem
    services: A systematic review of research advances and future directions. Landscape
    Ecology, 35(4), 793–814. https://doi.org/10.1007/s10980-020-00980-3. Article   Google
    Scholar   Zhou, Z., Morel, J., Parsons, D., Kucheryavskiy, S. V., & Gustavsson,
    A. M. (2019). Estimation of yield and quality of legume and grass mixtures using
    partial least squares and support vector machine analysis of spectral data. Computers
    and Electronics in Agriculture, 162, 246–253. https://doi.org/10.1016/j.compag.2019.03.038.
    Article   Google Scholar   Download references Acknowledgements This work was
    supported by the Federal Ministry of Food and Agriculture [grant: 28DE106A22],
    Germany. Funding Open Access funding enabled and organized by Projekt DEAL. This
    work was supported by the Federal Ministry of Food and Agriculture [grant: 28DE106A22],
    Germany. Author information Authors and Affiliations Department of Fundamentals
    of Agricultural Engineering, University of Hohenheim, Garbenstr. 9, 70599, Stuttgart,
    Germany Christoph Stumpe Department of Information Systems 2, University of Hohenheim,
    Schwerzstr. 35, 70599, Stuttgart, Germany Joerg Leukel & Tobias Zimpel Contributions
    Christoph Stumpe: Conceptualization, Methodology, Investigation, Writing – Original
    Draft. Joerg Leukel: Methodology, Investigation, Writing – Original Draft. Tobias
    Zimpel: Methodology, Investigation, Writing – Review & Editing. Corresponding
    author Correspondence to Christoph Stumpe. Ethics declarations Conflict of interest
    The authors declare that they have no conflict of interest. Additional information
    Publisher’s Note Springer Nature remains neutral with regard to jurisdictional
    claims in published maps and institutional affiliations. Rights and permissions
    Open Access This article is licensed under a Creative Commons Attribution 4.0
    International License, which permits use, sharing, adaptation, distribution and
    reproduction in any medium or format, as long as you give appropriate credit to
    the original author(s) and the source, provide a link to the Creative Commons
    licence, and indicate if changes were made. The images or other third party material
    in this article are included in the article’s Creative Commons licence, unless
    indicated otherwise in a credit line to the material. If material is not included
    in the article’s Creative Commons licence and your intended use is not permitted
    by statutory regulation or exceeds the permitted use, you will need to obtain
    permission directly from the copyright holder. To view a copy of this licence,
    visit http://creativecommons.org/licenses/by/4.0/. Reprints and permissions About
    this article Cite this article Stumpe, C., Leukel, J. & Zimpel, T. Prediction
    of pasture yield using machine learning-based optical sensing: a systematic review.
    Precision Agric 25, 430–459 (2024). https://doi.org/10.1007/s11119-023-10079-9
    Download citation Accepted 14 September 2023 Published 28 September 2023 Issue
    Date February 2024 DOI https://doi.org/10.1007/s11119-023-10079-9 Share this article
    Anyone you share the following link with will be able to read this content: Get
    shareable link Provided by the Springer Nature SharedIt content-sharing initiative
    Keywords Biomass Feature selection Grassland Herbage Random forests Remote sensing
    Use our pre-submission checklist Avoid common mistakes on your manuscript. Sections
    Figures References Abstract Introduction Method Results Discussion Conclusion
    References Acknowledgements Funding Author information Ethics declarations Additional
    information Rights and permissions About this article Advertisement Discover content
    Journals A-Z Books A-Z Publish with us Publish your research Open access publishing
    Products and services Our products Librarians Societies Partners and advertisers
    Our imprints Springer Nature Portfolio BMC Palgrave Macmillan Apress Your privacy
    choices/Manage cookies Your US state privacy rights Accessibility statement Terms
    and conditions Privacy policy Help and support 129.93.161.219 Big Ten Academic
    Alliance (BTAA) (3000133814) - University of Nebraska-Lincoln (3000134173) © 2024
    Springer Nature"'
  inline_citation: '>'
  journal: Precision Agriculture
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: 'Prediction of pasture yield using machine learning-based optical sensing:
    a systematic review'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Ikram R.M.A.
  - Hazarika B.B.
  - Gupta D.
  - Heddam S.
  - Kisi O.
  citation_count: '23'
  description: Accurate streamflow estimation is crucial for proper water management
    for irrigation, hydropower, drinking and industrial purposes. The main aim of
    this study to adopt new data preprocessing techniques (e.g., EMD, EEMD and EWT)
    to capture the data noise and to enhance the prediction accuracy of machine learning
    methods for streamflow estimation which is a challenging task in high-altitude
    basins due to the influence of many external climatic and geographical parameters.
    The prediction accuracy of support vector regression (SVR), twin support vector
    machine (T), extreme learning machine (ELM), asymmetric Huber loss function-based
    ELM (AHELM) and ε-insensitive Huber loss function-based ELM (ε-AHELM) methods
    are investigated in monthly streamflow prediction. Among the standalone methods,
    the ε-AHELM performs superior to the SVR, TSVR, ELM, and AHELM in streamflow prediction;
    improvements in root mean square error are 6.9%, 4.9%, 6% and 4.2%, respectively.
    The study outcomes reveal that the preprocessing methods considerably improve
    the prediction accuracy of the implemented standalone models. Among the data preprocessing
    techniques, it is found that the EWT outperforms the EMD and EEMD techniques by
    reducing the prediction errors in the best ε-AHELM, EMD-ε-AHELM and EEMD-ε-AHELM
    models by 68–61.3%, 64.7–63.4% and 59.4–58.6%, respectively. The overall results
    of the study recommend the use of EWT-ε-AHELM in streamflow estimation.
  doi: 10.1007/s00521-022-08163-8
  full_citation: '>'
  full_text: '>

    "Your privacy, your choice We use essential cookies to make sure the site can
    function. We also use optional cookies for advertising, personalisation of content,
    usage analysis, and social media. By accepting optional cookies, you consent to
    the processing of your personal data - including transfers to third parties. Some
    third parties are outside of the European Economic Area, with varying standards
    of data protection. See our privacy policy for more information on the use of
    your personal data. Manage preferences for further information and to change your
    choices. Accept all cookies Skip to main content Advertisement Log in Find a journal
    Publish with us Track your research Search Cart Home Neural Computing and Applications
    Article Streamflow prediction in mountainous region using new machine learning
    and data preprocessing methods: a case study Original Article Published: 27 December
    2022 Volume 35, pages 9053–9070, (2023) Cite this article Download PDF Access
    provided by University of Nebraska-Lincoln Neural Computing and Applications Aims
    and scope Submit manuscript Rana Muhammad Adnan Ikram, Barenya Bikash Hazarika,
    Deepak Gupta , Salim Heddam & Ozgur Kisi  809 Accesses 18 Citations 1 Altmetric
    Explore all metrics Abstract Accurate streamflow estimation is crucial for proper
    water management for irrigation, hydropower, drinking and industrial purposes.
    The main aim of this study to adopt new data preprocessing techniques (e.g., EMD,
    EEMD and EWT) to capture the data noise and to enhance the prediction accuracy
    of machine learning methods for streamflow estimation which is a challenging task
    in high-altitude basins due to the influence of many external climatic and geographical
    parameters. The prediction accuracy of support vector regression (SVR), twin support
    vector machine (T), extreme learning machine (ELM), asymmetric Huber loss function-based
    ELM (AHELM) and ε-insensitive Huber loss function-based ELM (ε-AHELM) methods
    are investigated in monthly streamflow prediction. Among the standalone methods,
    the ε-AHELM performs superior to the SVR, TSVR, ELM, and AHELM in streamflow prediction;
    improvements in root mean square error are 6.9%, 4.9%, 6% and 4.2%, respectively.
    The study outcomes reveal that the preprocessing methods considerably improve
    the prediction accuracy of the implemented standalone models. Among the data preprocessing
    techniques, it is found that the EWT outperforms the EMD and EEMD techniques by
    reducing the prediction errors in the best ε-AHELM, EMD-ε-AHELM and EEMD-ε-AHELM
    models by 68–61.3%, 64.7–63.4% and 59.4–58.6%, respectively. The overall results
    of the study recommend the use of EWT-ε-AHELM in streamflow estimation. Similar
    content being viewed by others Employing Machine Learning Algorithms for Streamflow
    Prediction: A Case Study of Four River Basins with Different Climatic Zones in
    the United States Article 11 September 2020 Stream Flow Forecasting of Poorly
    Gauged Mountainous Watershed by Least Square Support Vector Machine, Fuzzy Genetic
    Algorithm and M5 Model Tree Using Climatic Data from Nearby Station Article 25
    August 2018 Operational River Discharge Forecasting with Support Vector Regression
    Technique Applied to Alpine Catchments: Results, Advantages, Limits and Lesson
    Learned Article 09 September 2017 1 Introduction Streamflow plays a critical role
    in hydrology, climatology, dam construction, floods, droughts hazards, and water
    resources planning and management [18]; however, streamflow varies dramatically
    in both time and space, and its variation was most likely related to the climate
    change [2, 9, 16], making it difficult to be accurately estimated in the absence
    of direct in situ measurements [38]. From year to year, it is argued that in situ
    measurements of streamflow are fundamental for many hydrological applications
    [40], which are not available continuously in a large space [5]; consequently,
    the need for continuous knowledge of streamflow over time has motivated the use
    of different kinds of models. The high variation of streamflow in both space and
    time poses a major challenge to researchers for most water resource applications
    [17]. While great efforts have been devoted during the last few decades to provide
    a general framework and to ensure an accurate prediction of streamflow at different
    time scales based on assembling the major variables influencing its variation
    [37], the efficacy of such efforts is severely influenced by several factors among
    them the lack of continuous in situ measurements. In this context, further research
    works are needed to bring together the different component that governs the variation
    of streamflow into one overall framework for providing an effective modelling
    strategy [19]. Previous studies have suggested that accurate prediction of streamflow
    using a machine learning paradigm is possible and has been well recognized, and
    robust models have been proposed worldwide making the prediction of streamflow
    an evolving research area [28]. The accuracies of machine learning models depend
    upon knowledge of streamflow fluctuations and the important factors that impact
    streamflow both directly, e.g. precipitation (P), and indirectly, temperature
    and evapotranspiration, and thus understanding climate impacts on streamflow is
    necessary for strategic modelling framework. The success of machine learning models
    depends upon knowledge of the best selection of input variables [35], the use
    of appropriate models calibration [26], the best selection of relevant models
    parameters [28], and the good generalization capabilities [6]. Existing efforts
    to use machine learning for streamflow forecasting have done so by inferring streamflow
    measured at previous times lag as the relevant input variable; however, due to
    the high dependence between streamflow and precipitation [41] and the need for
    a significant amount of information to build robust models, the inclusion of precipitation
    as relevant input variable may contain additional information about streamflow
    [31], and these combinations, e.g., streamflow and precipitation are consistent
    in space and time [42], but nevertheless, according to what is already done, there
    is no single best combination of these two variables that can reliably forecast
    streamflow, while accurate forecasting of streamflow based solely on the certain
    number of streamflow lag time was also highly recognized. Niu and Feng [23] evaluated
    the extreme learning machine (ELM), support vector regression (SVR), Gaussian
    process regression (GPR), adaptive network-based fuzzy inference system (ANFIS)
    and the standard multilayer perceptron neural network (MLPNN) for daily streamflow
    forecasting at the Wu river in southwest China using only precipitation and streamflow
    measured at several times lag. Based on several performance metrics, it was shown
    that the GPR, SVR and ELM worked more accurately compared to the MLPNN and ANFIS,
    and the inclusion of the precipitation has helped in providing high forecasting
    accuracy. A complete forecasting approach was proposed by Saraiva et al. [34]
    for multistep ahead forecasting of daily streamflow at the Sobradinho reservoir,
    Brazil. The proposed approach combines simultaneously machine learning models,
    e.g., SVR and MLPNN, the preprocessing signal decomposition, e.g., discrete wavelet
    transform (DWT), and the bootstrap resampling method (BR), showing Haigh forecasting
    accuracy with Pearson correlation values (R) nearly equal to 0.999. Huang et al.
    [12] compared the long short-term memory networks deep learning (LSTM), ANFIS
    and the MLPNN models for hourly streamflow forecasting at the Maozhou and Pingshan
    rivers, China. The LSTM model was found to be more accurate exhibiting an NSE
    value of 0.976. Ribeiro et al. [27] compared ELM and Echo State Networks (ESNs)
    optimized using the bootstrap aggregation and the multi-objective optimization
    algorithm (MOO). Statistical results revealed that combining single models using
    bootstrap aggregation and MOO contributed significantly to the enhancement of
    models’ performances. Lin et al. [20] combined the ANN, the first-order difference
    (DF), and the LSTM in a single model called the DF-ANN-LSTM for hourly streamflow
    forecasting. It was demonstrated that the DF-ANN-LSTM was more accurate. Ahmed
    et al. [1] introduced a new modelling framework based on the combination of metaheuristics
    optimization algorithms (MOA) and the MLPNN model for monthly streamflow forecasting
    at the Nile River at the high Aswan dam, Egypt. From the obtained results, it
    was reported that the best forecasting accuracies were obtained using the MLPNN
    optimized using the nuclear reaction optimization (NRO) algorithm (MLPNN-NRO)
    exhibiting high performance metrics. Zhao et al. [43] assessed the utility of
    grey wolf optimizer (GWO) and improved GWO (IGWO) algorithms in improving the
    deep learning gated recurrent unit (GRU) model used for monthly streamflow forecasting
    at the Fenhe River, China. It is thus clear that recent advances in MOA algorithms
    development have improved the accuracies of several other machine learning models.
    In the same line of research, Riahi-Madvar et al. [30] demonstrated that modifying
    the training algorithm of the ANFIS model using MOA, e.g., particle swarm optimization
    (PSO), GWO, genetic algorithm (GA), firefly algorithm (FFA), and differential
    evolution (DE) could improve the daily, weekly, monthly and annual streamflow
    forecasting in the Karun River, Iran. Recently developed hybrid models based on
    MOA have further confirmed the utility of these approaches and the number of published
    papers has increased noticeably [3, 16, 25, 32]. For a more comprehensive list
    of models developed for streamflow forecasting, readers are referred to a large
    published papers over literature for a more extensive review in this field. The
    need to extend the set of proposed models over literature with respect to previous
    modelling strategies is one of the major motivations of the present study. The
    present work suggests that an ensemble of modelling frameworks can help in further
    improving the accuracies of machine learning applied for streamflow forecasting.
    In this paper, we propose new models for streamflow forecasting: twin support
    vector regression and its standard form, i.e., the SVR, standard extreme learning
    machine and two new extensions: the asymmetric Huber loss-based extreme learning
    machine and the ε-insensitive asymmetric Huber loss-based extreme learning machine
    for streamflow forecasting. The present study is conducted according to four modelling
    scenarios. First, the single models were applied and compared. Second, the four
    models were coupled to the empirical wavelet transform. Third, the empirical mode
    decomposition was used as preprocessing technique for signal decomposition and
    coupled with the machine learning models. Fourthly and finally, an improved version
    of the empirical mode decomposition was proposed, e.g., the ensemble empirical
    mode decomposition and combined with the machine learning models. The four scenarios
    were developed according to three input variables combination based on the inclusion
    of only the streamflow measured at the previous lag. 2 Case study In this study,
    the Upper Indus Basin located in Pakistan is selected as the case study area.
    This basin is selected due to its economical and geographical importance for Pakistan.
    As Pakistan is a developing country and country’s main GDP depends upon agriculture
    providing 70% of GDP. However, the agriculture sector needs a proper supply of
    water that mainly depends upon the Upper Indus Basin in Pakistan. In addition
    to the importance of agriculture, the world''s three big mountainous ranges, i.e.
    the Karakoram, Hindukush and Himalayas, surround this basin. Therefore, in this
    basin mainly water contribution is through snowfield and glacier melt. Hence,
    precise estimation of streamflow in this high-altitude basin becomes a challenging
    task due to many external climatic and geographical factors that influence it.
    UIB is also important for hydropower generation of the country because the biggest
    and first reservoir of the country, i.e. Tarbela Dam with 5000 MW electricity
    generation capacity, is also located downstream of this basin as shown in Fig.
    1. 95% of water released from the dam is used for irrigation purpose. Therefore,
    these points also give impute to the selection of the UIB for this study. Due
    to the key reservoir presence in this basin, this basin is also called the Tarblea
    catchment and it covers a drainage area of 165,400 km2 with a river length of
    1450 km. For the streamflow estimation, the Gilgit hydrologic station at a height
    of 1450 m is chosen. This station is located in the Gilgit subbasin of UIB. This
    subbasin is selected due to the location of the basin in the high-altitude region
    with a mean elevation of 4000 m. Therefore, snow-fed and other climatic parameters
    influence of streamflow are dominant in this basin. However, due to high altitude,
    installation and data recording for long time series of climatic parameters, i.e.
    temperature, precipitation, humidity, etc. are difficult in this region. Therefore,
    in this study, only monthly streamflow data of the selected station from 1976
    to 2007 was obtained from WAPDA, Pakistan. For analysis, obtained data are divided
    into training and testing datasets with a ratio of 75 and 25%, respectively. To
    tackle the influence of external parameters in form of data noise, decomposition
    techniques were also adopted in this study. Fig. 1 Study area Full size image
    3 Methods 3.1 SVR-based models Let the training samples are \\(\\left\\{ {x_{i}
    } \\right\\}_{i = 1}^{m} \\in R^{n} ,\\) where \\(m\\) indicates for the total
    number of samples. The input training samples are denoted by \\(x_{i} \\in R^{n}\\)
    and \\(y_{i} \\in R^{n}\\) denote the original output samples. Moreover, consider
    \\(A \\in R^{m \\times n}\\) as the training data which \\(i{\\text{th}}\\) row
    vector can be rewritten as \\(x_{i}^{t}\\) and \\(y = (y_{1,...} y_{m} )\\) indicates
    the observed values. 3.1.1 The SVR model SVR seeks a regression function \\(f(x)\\)
    by fitting the input samples \\(x \\in R^{n} ,\\) where \\(w \\in R^{n}\\) and
    \\(b \\in R\\) as: $$f(x) = w^{t} x + b$$ The primal problem of SVR can be stated
    as: $$\\begin{gathered} \\mathop {\\min }\\limits_{{w,b,\\xi ,\\xi^{*,} }} \\frac{1}{2}w^{t}
    w + C(e^{t} \\xi + e^{t} \\xi^{*} ), \\hfill \\\\ s.t.,y_{i} - (x_{i}^{t} w +
    b) \\le \\;\\varepsilon \\; + \\;\\xi_{i} ,\\;x_{i}^{t} w + b - y_{i} \\le \\;\\varepsilon
    \\; + \\;\\xi_{i}^{*} . \\hfill \\\\ \\end{gathered}$$ and $$\\xi_{i} \\ge 0,\\;\\xi_{i}^{*}
    \\ge 0\\;{\\text{for}}\\;i = 1,2,...,m.$$ (1) where, \\(C > 0,\\;e\\) and \\(\\varepsilon
    > 0\\) are the trade-off parameter, vector of ones and input parameters, respectively.
    \\(\\xi = \\;\\left( {\\xi_{1} ,...,\\xi_{m} } \\right)\\;^{t}\\) and \\(\\xi^{*}
    = \\;\\left( {\\xi_{1}^{*} ,...,\\xi_{m}^{*} } \\right)\\;^{t}\\) are the slack
    vectors. The decision regression function of SVR for any input sample \\(x \\in
    R^{n}\\) is: $$f(x) = \\;\\sum\\limits_{i = 1}^{m} {(\\alpha_{1i} - \\alpha_{2i}
    )k(x,x_{i} ) + b} .$$ where \\(\\alpha_{1}\\) and \\(\\alpha_{2}\\) are Lagrangian
    multipliers. 3.1.2 The TSVR model In TSVR, the up-bound and the down-bound regressor
    \\(f_{1} (x) = \\;K(x^{t} ,H^{t} )w_{1} + b_{1}\\) and \\(f_{2} (x) = \\;K(x^{t}
    ,H^{t} )w_{2} + b_{2}\\) can be determined for \\(x \\in R^{n}\\) by solving a
    pair of QPPs as: $$\\begin{gathered} \\min \\frac{1}{2}\\left\\| {y - e\\varepsilon_{1}
    - (K(H,H^{t} )w_{1} + eb_{1} } \\right\\|^{2} + C_{1} e^{t} \\xi , \\hfill \\\\
    {\\text{s}}.{\\text{t}}.,\\;y - (K(H,H^{t} )w_{1} + eb_{1} ) \\ge e\\varepsilon_{1}
    \\; - \\;\\xi ,\\;\\;\\xi \\ge 0 \\hfill \\\\ \\end{gathered}$$ (2) and $$\\begin{gathered}
    \\min \\frac{1}{2}\\left\\| {y - e\\varepsilon_{2} - (K(H,H^{t} )w_{2} + eb_{2}
    } \\right\\|^{2} + C_{2} e^{t} \\xi^{*} , \\hfill \\\\ {\\text{s}}.{\\text{t}}.,\\;(K(H,H^{t}
    )w_{2} + eb_{2} ) - y \\ge e\\varepsilon_{2} \\; - \\;\\xi^{*} ,\\;\\;\\xi^{*}
    \\ge 0. \\hfill \\\\ \\end{gathered}$$ (3) where \\(K = K(H,H^{t} )\\) of \\(m\\)
    order indicates the kernel matrix and the \\((i,j)^{th}\\) element may be defined
    as \\(K = K(H,H^{t} )_{ij} = k(x_{i} ,x_{j} ) \\in R\\) and \\(K = K(x,\\;H^{t}
    ) = (k(x,x_{1} )\\;,...,k(x,x_{m} )) \\in R^{m}\\) for a vector \\(x \\in R^{n}
    .\\) After applying Lagrange’s multiplies and further using the KKT conditions,
    the unknowns can be estimated as: $$\\left[ \\begin{gathered} \\omega_{1} \\hfill
    \\\\ b_{1} \\hfill \\\\ \\end{gathered} \\right] = \\;(Z^{t} Z + \\varepsilon
    I)^{ - 1} Z^{t} (r_{1} - \\alpha )$$ $$\\left[ \\begin{gathered} \\omega_{2} \\hfill
    \\\\ b_{2} \\hfill \\\\ \\end{gathered} \\right] = \\;(Z^{t} Z + \\varepsilon
    I)^{ - 1} Z^{t} (r_{2} + \\alpha^{*} )$$ where \\(G = \\;[K(Z,Z^{t} )\\;\\;\\;e]\\)
    and \\(\\varepsilon\\) is a small positive integer with value 0.001 and \\(I\\)
    is the identity matrix of suitable dimension. \\(\\varepsilon\\) and \\(I\\) are
    added to reduce the effect of ill-conditioning of \\(Z^{t} Z.\\) For a new sample,
    \\(x \\in R^{n}\\) the TSVR regressor can be obtained as: $$f(x) = \\;\\frac{1}{2}(f_{1}
    (x) + f_{2} (x))$$ (4) 3.2 ELM-based models Consider output layer as \\(w\\) can
    be determined by solving a system of linear equations, i.e., \\(w = H^{{\\dag
    }} y.H^{\\dag}\\) is called the Moore–Penrose generalized inverse of the matrix
    \\(H.\\) The hidden layer matrix, \\(H\\), can be expressed as: \\(H = \\left[
    {\\begin{array}{*{20}l} {P(a_{1} ,b_{1} ,x_{1} )} \\hfill & \\cdots \\hfill &
    {P(a_{L} ,b_{L} ,x_{1} )} \\hfill \\\\ \\cdot \\hfill & {} \\hfill & \\cdot \\hfill
    \\\\ \\cdot \\hfill & {} \\hfill & \\cdot \\hfill \\\\ {P(a_{1} ,b_{1} ,x_{m}
    )} \\hfill & {} \\hfill & {P(a_{L} ,b_{L} ,x_{m} )} \\hfill \\\\ \\end{array}
    } \\right]_{{m \\times L}}\\) Here, \\(P(a_{L} ,b_{L} ,x_{i} )\\) is called as
    the \\(l^{\\text{th}}\\) hidden layer node with reference to \\(x_{i}\\), where
    \\(a_{L} = (a_{L1} ,...,a_{Lm} )^{t}\\) is the weight vector and \\(b_{l}\\) indicates
    the bias to the hidden nodes. 3.2.1 The AHELM model The asymmetric Huber loss
    (AHL) function can be presented in the convenient form as: $$L_{H} (x) = x^{2}
    - (x - \\tau_{r} )_{ + }^{2} - ( - x - \\tau_{l} )_{ + }^{2} .$$ (5) where \\(\\tau_{l}
    ,\\tau_{r} > 0\\) are the input parameters. The primal problem of AHELM can be
    written as: $$\\mathop {\\min }\\limits_{{w \\in R^{l} }} D_{1} (w) = \\mathop
    {\\min }\\limits_{{w \\in R^{l} }} \\,\\,\\frac{1}{2}w^{t} w\\,\\, + \\,\\,\\frac{C}{2}\\left[
    {||Hw - y||^{2} - ||((Hw - y) - \\tau_{r} )_{ + } ||^{2} - ||( - (Hw - y) - \\tau_{l}
    )_{ + } ||^{2} } \\right]$$ (6) Further, after finding the gradient of \\(P_{1}
    (w)\\) and further equating to 0, we get: $$\\left( {\\frac{I}{C} + H^{t} H} \\right)w
    = H^{t} \\left[ {y + (Hw - y - \\tau_{r} )_{ + } - ( - Hw + y - \\tau_{l} )_{
    + } } \\right]$$ (7) The solution to the aforementioned problem (7) can be obtained
    by using the following simple iterative scheme: $$\\left( {\\frac{I}{C} + H^{t}
    H} \\right)w^{i + 1} = H^{t} \\left[ {y + (Hw^{i} - y - \\tau_{r} )_{ + } - (
    - Hw^{i} + y - \\tau_{l} )_{ + } } \\right],{\\text{for}}\\;i = 0,1, \\ldots .$$
    (8) 3.2.2 The ε-AHELM model The ε-insensitive AHL function can be written in a
    simplified structure as: $$L_{H}^{\\varepsilon } (x) = (x - \\varepsilon_{R} )_{
    + }^{2} - (x - (\\varepsilon_{r} + \\tau_{r} ))_{ + }^{2} + ( - x - \\varepsilon_{l}
    )_{ + }^{2} - ( - x - (\\varepsilon_{l} + \\tau_{l} ))_{ + }^{2}$$ (9) The primal
    problem of ε-insensitive AHL function can be stated as: $$\\begin{aligned} \\mathop
    {\\min }\\limits_{{w \\in R^{l} }} D_{2} (w) & = \\mathop {\\min }\\limits_{{w
    \\in R^{l} }} \\frac{1}{2}w^{t} w + \\frac{C}{2}[((Hw - y) - \\varepsilon_{r}
    e)_{ + }^{2} - ((Hw - y) - (\\varepsilon_{r} + \\tau_{r} )e)_{ + }^{2} \\\\ &
    \\quad + ( - (Hw - y) - \\varepsilon_{l} e)_{ + }^{2} - ( - (Hw - y) - (\\varepsilon_{l}
    + \\tau_{l} )e)_{ + }^{2} ] \\\\ \\end{aligned}$$ (10) After finding the gradient
    of \\(P_{2} (w)\\) and further equating it to 0, we obtain: $$\\begin{aligned}
    \\left( {\\frac{I}{C} + H^{t} H} \\right)w & = H^{t} \\left[ {y + \\frac{{(\\varepsilon_{l}
    - \\varepsilon_{r} )}}{2}e - \\frac{{|Hw - y - \\varepsilon_{r} e| - | - Hw +
    y - \\varepsilon_{l} e|}}{2}} \\right. \\\\ & \\quad + \\left. {(Hw - y - (\\varepsilon_{r}
    + \\tau_{r} )e)_{ + } - ( - Hw + y - (\\varepsilon_{l} + \\tau_{l} )e)_{ + } }
    \\right] \\\\ \\end{aligned}$$ (11) One can achieve the solution of (11) by using
    the simple iterative scheme [21]: $$\\begin{aligned} \\left( {\\frac{I}{C} + H^{t}
    H} \\right)w^{{i + 1}} & = H^{t} \\left[ {y + \\frac{{(\\varepsilon _{l} - \\varepsilon
    _{r} )}}{2}e - \\frac{{\\left| {Hw^{i} - y - \\varepsilon _{r} e} \\right| - \\left|
    { - Hw^{i} + y - \\varepsilon _{l} e} \\right|}}{2}} \\right. \\\\ & \\quad +
    (Hw^{i} - y - (\\varepsilon _{r} + \\tau _{r} )e)_{ + } \\\\ & \\quad - \\left.
    {( - Hw^{i} + y - (\\varepsilon _{l} + \\tau _{l} )e)_{ + } } \\right]\\;{\\text{for}}\\quad
    i{\\text{ = 0,1,}} \\ldots {\\text{.}} \\\\ \\end{aligned}$$ (12) 3.3 The EMD
    By combining EMD and Hilbert spectral analysis (HSA), the Hilbert–Huang transform
    (HHT) is generated [13]. HHT functions similarly to wavelet analysis, with the
    exception that HHT is a posteriori and its theoretical foundation is empirical.
    The intrinsic oscillatory modes extracted from a non-stationary signal are called
    intrinsic mode functions (IMFs), which are a collection of a few adaptive basis
    functions with an extra residual series. EMD [4,14] is used to sift the initial
    signal ''x(s'' in order to remove the true IMFs and residue r(s) [22, 29]. After
    decomposition of the original signal x(s) can be shown as the addition of IMFs
    and residual as: $$x(s) = \\sum\\limits_{i = 1}^{n} {M_{i} (s) + r_{n} (s)}$$
    (13) where \\(s\\) indicates the signal. \\(M_{i} (s)\\) is the sum of IMFs, and
    \\(r_{n} (s)\\) denotes the residual of the signal. 3.4 The EEMD The Ensemble
    EMD (EEMD) [39] methodology is a completely noise-assisted data analysis method
    that is used to overcome the drawbacks of EMD. It decomposes embedded oscillations
    at various scales into IMFs and a residual variable. They contain oscillations
    with very different amplitudes in a mode or oscillations with very similar amplitudes
    in dissimilar modes. This type of problem is called the mode-mixing problem (MMP).
    EEMD makes extensive advantage of the statistical properties of Gaussian white
    noise (GWN) to efficiently prevent EMD’s MMP. [24, 33]. EEMD follows the following
    procedure: Firstly, the GWN added signal is produced using: $$x^{j} (s) = x(s)
    + \\psi^{j}$$ (14) where \\(\\psi\\) indicates the GWN. After that, the GWT added
    signal is decomposed into IMFs and a residue as: $$x^{j} (s) = \\sum\\limits_{i
    = 1}^{n} {M_{i}^{j} (s) + r_{n}^{j} (s)}$$ (15) Equations (14) and (15) are reiterated,
    and finally, the average of the corresponding IMFs is considered. 3.5 The EWT
    EMD suffers from severe mode aliasing, making it simple to create false modal
    components. EWT is a signal-adaptive analysis technique that integrates the efficient
    wavelet transform with the adaptive benefits of EMD [7, 15]. The EWT is a three-step
    process. For any original time series signal, the steps of EWT are [11]: Step
    1 Determine the Fourier transform of the input signal that has been processed.
    Step 2 Detect the local maxima in the Fourier spectrum to segment the spectrum.
    Step 3 Sort the local maxima from highest to lowest in decreasing order. Step
    4 Define the segment bounds as the intersection of two subsequent maxima. Step
    5 To get a tight frameset, follow Meyer''s wavelet''s construction idea. Step
    6 Get the signal filters. 3.6 Proposed data preprocessing-based machine learning
    models In this section, we briefly discuss the data preprocessing-based machine
    learning models are discussed. Firstly, the raw streamflow data are passed through
    the preprocessing methods, i.e., EMD, EEMD and EWT. After that the preprocessed
    data is provided as an input to AHELM or ε-AHELM to generate 6 novel machine learning
    techniques. They are: a. EMD-AHELM—combination of EMD and AHELM models. b. EEMD-AHELM—combination
    of EEMD and AHELM models. c. EWT-AHELM—combination of EWT and AHELM models. d.
    EMD-ε-AHELM—combination of EMD and ε-AHELM models. e. EEMD-ε-AHELM—combination
    of EEMD and ε-AHELM models. f. EWT-ε-AHELM—combination of EWT and ε-AHELM models.
    4 Application and results 4.1 Experimental setup The viability of SVR, TSVR, ELM,
    AHELM and ε-AHELM methods combined with EMD, EEMD and EWT preprocessing techniques
    were investigated in the prediction of monthly streamflow. Three input combinations
    involving previous lags of streamflow were considered and the optimal inputs were
    decided to take into account correlations analysis (partial autocorrelation function).
    The schematic diagram of the proposed models is shown in Fig. 2. Qt-1, Qt-2, Qt-11
    and Qt-12 are the various input combinations indicating one-day lag, two days
    lag, eleven days lag and twelve days lag, respectively. These input combinations
    are decomposed using EMD, EEMD and EWT. The decomposed data are provided as an
    input to the SVR, TSVR, ELM, AHELM and ε-AHELM models, respectively. The studied
    methods were evaluated considering the following criteria: $${\\text{RMSE:}}\\;{\\text{root
    }}\\;{\\text{mean}}\\;{\\text{square}}\\;{\\text{error = }}\\sqrt {\\frac{1}{N}\\mathop
    \\sum \\limits_{i = 1}^{N} \\left[ {(S_{0} )_{i} - (S_{C} )_{i} } \\right]^{2}
    }$$ (16) $${\\text{MAE:}}\\;{\\text{mean}}\\;{\\text{absolute}}\\;{\\text{error
    = }}\\frac{1}{N}\\sum\\limits_{i = 1}^{N} {\\left| {(S_{0} )_{i} - (S_{C} )_{i}
    } \\right|}$$ (17) $$R^{2} :\\;{\\text{coefficient}}\\;{\\text{of}}\\;{\\text{determination}}
    = \\frac{{\\sum\\nolimits_{i = 1}^{N} {\\left[ {\\left( {\\left( {S_{0} } \\right)_{i}
    - \\left( {\\overline{S}_{0} } \\right)} \\right)\\left( {\\left( {S_{C} } \\right)_{i}
    - \\left( {\\overline{S}_{c} } \\right)} \\right)} \\right]} }}{{\\sum\\nolimits_{i
    = 1}^{N} {\\left[ {\\left( {\\left( {S_{c} } \\right)_{i} - \\left( {\\overline{S}_{c}
    } \\right)} \\right)\\left( {\\left( {S_{0} } \\right)_{i} - \\left( {\\overline{S}_{0}
    } \\right)} \\right)} \\right]} }}$$ (18) $${\\text{SMAPE:}}\\;{\\text{symmetric}}\\;{\\text{mean}}\\;{\\text{absolute}}\\;{\\text{percentage}}\\;{\\text{error}}
    = \\frac{1}{N}\\sum\\limits_{i = 1}^{N} {\\frac{{\\left| {\\left( {S_{0} } \\right)_{i}
    - \\left( {S_{C} } \\right)_{i} } \\right|}}{{\\left( {S_{0} } \\right)_{i} +
    \\left( {S_{C} } \\right)_{i} }}}$$ (19) where \\(S_{c} , S_{o} , \\overline{S}_{o}
    , N\\), respectively, indicate the calculated, observed, mean of the observed
    streamflows and data quantity. The experiments were performed in MATLAB (2020b)
    on a computer with 8 GB of RAM, Intel i7 processor with a 3.60 GHz clock speed.
    As per the selection of the kernel for SVR and TSVR, the nonlinear Gaussian kernel
    was considered which may be presented as: \\(k(x_{p} ,x_{q} )\\; = - \\;\\exp
    ( - \\mu \\,||x_{p} - \\;x_{q} ||^{2} )\\), where \\(x_{p} ,\\;x_{q}\\) denote
    any samples. The \\(C_{1} = C_{2} = C\\) and \\(\\mu\\) parameters of TSVR were
    chosen from a broad range of \\(\\left\\{ {\\;10^{ - 5} ,...,10^{5} } \\right\\}\\)
    and \\(\\left\\{ {\\;2^{ - 5} ,...,2^{5} } \\right\\}\\), respectively. On the
    other hand, the \\(\\ell\\) parameter of AHELM and ɛ-AHELM was considered from
    \\(\\left\\{ {\\;20,40,50,100,200,500} \\right\\}.\\) Moreover, for the AHELM
    and ɛ-AHELM models, the \\(\\varepsilon_{L}\\) and \\(\\varepsilon_{R}\\) parameters
    were considered from \\(\\left\\{ {0.001,0.01,0.1} \\right\\}\\). The \\(\\theta_{L}\\)
    and \\(\\theta_{R}\\) parameters were chosen from \\(\\left\\{ {0.1,0.3,0.5,0.7,0.9,1.1,1.3,1.5}
    \\right\\}\\). Additionally the maximum number of IMF considered was 2 for EMD-SVR,
    EMD-TSVR, EMD-AHELM and EMD-ɛ-AHELM. Also, for the proposed EEMD-SVR, EEMD-TSVR,
    EEMD-AHELM and EEMD-ɛ-AHELM, the signal-to-noise ratio (SNR) was fixed to 0.1,
    and a total number of iterations was considered as 500. The NR was fixed to 100.
    While implementing the proposed EWT-SVR, EWT-TSVR, EWT-AHELM and EWT-ɛ-AHELM,
    the inbuilt “ewt” function was used. Fig. 2 Flowchart of the study Full size image
    4.2 Results In Table 1, the training and testing outcomes of the implemented single
    machine learning methods are compared. In the table, three input combinations
    that were decided based on correlation analysis are also indicated. In each case,
    the models try to predict current streamflow (Qt) using previous data. It is clear
    from Table 1 that the input combinations involving full input data (Qt-1, Qt-2,
    Qt-11, Qt-12) provide the best accuracy in the testing stage; compared to 1st
    input combination (Qt-1, Qt-2), improvements in RMSE are 20.5%, 13.5%, 20.9%,
    10.3% and 11.6% for SVR, TSVR, ELM, AHELM and ɛ-AHELM, respectively. By applying
    TSVR, the prediction accuracy of the best SVR (considering the model with full
    input data) is improved by 2.2, 10.6, 29.6 and 4.8% with respect to RMSE, MAE,
    SMAPE and R2, respectively. The difference between single SVR and ELM seems to
    be marginal. Overall comparison of the implemented methods reveals that the ɛ-AHELM
    having the lowest RMSE, MAE and SMAPE and the highest R2 performs superior to
    the other models in the prediction of streamflow. Table 1 Single machine learning
    models—Gilgit Basin Full size table Table 2 compares the EMD-based machine learning
    methods in the prediction of streamflow. Similar to the previous application here
    also the input combination (Qt-1, Qt-2, Qt-11, Qt-12) gives the best accuracy
    in the testing stage; improvements in RMSE compared to 1st input combination (Qt-1,
    Qt-2) are 19.9%, 17.4%, 16.8%, 18.9% and 23.8% for ELM-SVR, ELM-TSVR, ELM-ELM,
    ELM-AHELM and ELM-ɛ-AHELM, respectively. The prediction performance of the best
    EMD-SVR with respect to RMSE, MAE, SMAPE and R2 is, respectively, improved by
    5.3, 13, 23.1 and 2.7%. EMD-ELM outperforms the EMD-SVR model. Combining EMD also
    provides parallel results to those of the single models. Among the EMD-based models,
    the EMD-ɛ-AHELM has lower RMSE, MAE and SMAPE and the highest R2 perform better
    than the other models in the prediction of streamflow. It is evident from the
    comparison of Tables 1 and 2, EMD conjunction slightly improves the single models’
    efficiency (considering the best models having the last input combination) with
    respect to RMSE and R2 statistics; however, considering MAE and SMAPE criteria,
    it deteriorates the models’ performances. This recommends the usage of several
    statistics for better model evaluation. If we use only RMSE and R2 or MAE and
    SMAPE, we may reach biased conclusions. Table 2 EMD-based machine learning models—Gilgit
    Basin Full size table Training and testing results of the EEMD-based machine learning
    methods are summed in Table 3 in the prediction of streamflow. Improvements in
    RMSE by applying the 3rd input combination (Qt-1, Qt-2, Qt-11, Qt-12) compared
    to 1st input combination (Qt-1, Qt-2), respectively, are 3.7%, 6.5%, 6.3%, 4.2%
    and 5.7% for ELM-SVR, ELM-TSVR, ELM-ELM, ELM-AHELM and ELM-ɛ-AHELM. Applying EEMD-TSVR
    improves the testing accuracy of the best EEMD-SVR by 11.2, 22.5, 40.2 and 1.8%
    with respect to RMSE, MAE, SMAPE and R2, respectively. Here also, EEMD-ELM performs
    superior to the EEMD-SVR model. Among the EEMD-based models, the EEMD-ɛ-AHELM
    has the lowest RMSE, MAE and SMAPE and the highest R2 in the prediction of streamflow.
    Comparison of EEMD-based and single models (compare Tables 1 and 3), EEMD conjunction,
    respectively, improves the single models’ accuracy with respect to RMSE, MAE and
    R2 statistics. Meanwhile, according to the SMAPE criterion, combining EEMD deteriorates
    the single models’ performances. Comparison with EMD (compare Tables 2 and 3)
    says that the EEMD considerably increases the models’ efficiency in streamflow
    prediction. However, SMAPE values of the SVR and ɛ-AHELM are slightly increased
    by implementing EEMD. Table 3 EEMD-based machine learning models—Gilgit Basin
    Full size table Table 4 reports the training and testing outcomes of the EWT-based
    machine learning methods in streamflow prediction with respect to RMSE, MAE, SMAPE
    and R2 criteria. Including the Qt-11 and Qt-12 in the input combination (3rd input
    combination) improves the models’ RMSE efficiency by 14.5%, 42.5%, 12.9%, 41.9%
    and 30.4% for EWT-SVR, EWT-TSVR, EWT-ELM, EWT-AHELM and EWT-ɛ-AHELM. By implementing
    EWT-TSVR, the testing accuracy of the best EWT-SVR by 55.4, 48.6, 52.1 and 3.9%
    with respect to RMSE, MAE, SMAPE and R2, respectively. EWT-ELM outperforms the
    EWT-SVR model. Among the EWT-based models, the EWT-ɛ-AHELM has the lowest RMSE,
    MAE and SMAPE and the highest R2 in the prediction of streamflow. Comparison of
    EEMD-based models with single models (compare Tables 1 and 4), EWT preprocessing
    method, respectively, improves the single models’ accuracy with respect to RMSE,
    MAE and R2 statistics. Here also, the SMAPE criterion says that combining EWT
    deteriorates the single models’ performances in some cases (see SVR and ELM models).
    Comparison with EMD (compare Tables 2 and 4) reveals that the EWT considerably
    improves the accuracy of the model. Moreover, combining EWT also improves the
    EEMD-based models’ accuracies (compare Tables 3 and 4). Table 4 EWT-based machine
    learning models—Gilgit Basin Full size table Time variation comparison of the
    best ɛ-AHELM-based models is made in Fig. 3 (Fig. 4). It is clearly seen that
    applying preprocessing methods improves the models’ accuracy and the EWT seems
    to be the best among the alternatives. This is also confirmed by the scatterplots
    provided in Fig. 5. Less scattered estimates are obtained by implementing preprocessing
    techniques, and EWT considerably improves the models’ efficiency. Figure 4 compares
    the EWT conjunction models in streamflow prediction. It is evident from the graphs
    that the EWT-ɛ-AHELM follows the observed streamflow values closer compared to
    the other models. This can be clearly seen from the scatterplots shown in Fig.
    6. Figure 7 illustrates the best ɛ-AHELM-based models on a Taylor diagram in which
    the models can be compared with respect to standard deviation, correlation and
    RMSE. It is apparent from the figure that the EWT-ɛ-AHELM having the highest correlation
    and the lowest RMSE and standard deviation is closer to the observed value compared
    to other models. This model was followed by the EEMD-ɛ-AHELM and EMD-ɛ-AHELM in
    prediction streamflow. It is clear from the violin diagrams given in Fig. 8 that
    the EWT-ɛ-AHELM has closer distribution to the observed one than the other models.
    Taylor and violin diagrams of the best EWT-based models are illustrated in Figs.
    9 and 10. The superiority of the EWT-ɛ-AHELM model in the prediction of streamflow
    can be observed from these graphs. Additionally, the computational time (in seconds)
    of the models is presented in Table 5. Table 5 also clearly shows the robustness
    of EWT-ɛ-AHELM model in the prediction of streamflow. Fig. 3 Time variation graphs
    of the observed and predicted streamflow by best ε-AHELM (ε-AHELM, EMD-ε-AHELM,
    EEMD-ε-AHELM, EWT-ε-AHELM)-based models in the test period using best input combination
    Full size image Fig. 4 Scatterplots of the observed and predicted streamflow by
    best ε-AHELM (ε-AHELM, EMD-ε-ahelm, EEMD-ε-AHELM, EWT-e-AHELM)-based models in
    the test period using best input combination Full size image Fig. 5 Time variation
    graphs of the observed and predicted streamflow by best EWT (EWT-SVR, EWT-TSVR,
    EWT-ELM, EWT-AHELM, EWT-ε-AHELM)-based models in the test period using best input
    combination Full size image Fig. 6 Scatterplots of the observed and predicted
    streamflow by best EWT (EWT-SVR, EWT-TSVR, EWT-ELM, EWT-AHELM, EWT-ε-AHELM)-based
    models in the test period using best input combination Full size image Fig. 7
    Taylor diagrams of the estimated streamflow by best e-AHELM (ε-AHELM, EMD-ε-AHELM,
    EEMD-ε-AHELM, EWT-ε-AHELM)-based models in the test period Full size image Fig.
    8 Violin diagrams of the estimated streamflow by best ε-AHELM (ε-AHELM, EMD-ε-AHELM,
    EEMD-ε-AHELM, EWT-ε-AHELM)-based models in the test period Full size image Fig.
    9 Taylor diagrams of the estimated streamflow by best EWT (EWT-SVR, EWT-TSVR,
    EWT-ELM, EWT-AHELM, EWT-ε-AHELM)-based models in the test period Full size image
    Fig. 10 Violin diagrams of the estimated streamflow by best EWT (EWT-SVR, EWT-TSVR,
    EWT-ELM, EWT-AHELM, EWT- ε-AHELM)-based models in the test period Full size image
    Table 5 Computational time of the reported models (in seconds) Full size table
    4.3 Discussion The aim of the presented study is to present new data preprocessing
    techniques to improve the accuracy of SVR, TSVR, ELM, AHELM and ɛ-AHELM methods
    in monthly streamflow estimation. The outcomes reveal that the standalone ɛ-AHELM
    improves the accuracy of the SVR, TSVR, ELM and AHELM methods by 9%, 4.9%, 6%
    and 4.2% with respect to RMSE, respectively. From the assessment criteria and
    graphical methods, it is observed that the best streamflow estimates are obtained
    from the EWT-ɛ-AHELM model and the use of EWT preprocessing method considerably
    improves the efficiency of machine learning models in streamflow estimation. Although
    the SVR has a high generalization ability, it is computationally very complex.
    Both SVR and ELM are highly sensitive to the outliers and due to this, they do
    not perform well with noisy data. However, the ELM is relatively faster and offers
    similar or better generalization accuracy compared to SVR. The novel methods,
    AHELM and ε-AHELM which are based on Huber loss reduce the effect of noises, and
    therefore, they provide superior accuracy in estimating the monthly streamflow
    which have a highly noisy structure [8]. Streamflow estimation is a challenging
    task in high-altitude basins due to the influence of many external climatic and
    geographical parameters in form of data noise. Therefore, to capture the data
    noise, data preprocessing techniques are adopted in this study to enhance the
    prediction accuracy of machine learning methods. EMD can automatically calculate
    the mode''s number, while a priori the number of modes is fixed for the EWT. The
    EMD generally overestimates the mode''s number. The major advantage of EMD over
    other conventional methods is that, unlike wavelet and Fourier transform, the
    basis functions of EMD can be derived directly from the data itself using a data-driven
    mechanism that does not require prior knowledge. Moreover, the basic advantage
    of EEMD over EMD is that EEMD can efficiently avoid the mode-mixing phenomenon.
    The EMD and EEMD-based hybrid models generally exhibit too many modes, which can
    be difficult to interpret at times. EWT can avoid these problems. Another advantage
    of EWT-based models over EMD and EEMD-based models is that they can be understood
    using the classic wavelet formalism [7]. Additionally, EMD and EEMD lack mathematical
    theory which is overcome by EWT. EWT also has a low computational cost than both
    EMD and EEMD [10]. For the low frequencies, interpreting outputs of EMD is difficult
    for the test signals. For a chirp signal, the EWT can catch the correct modes,
    while the EMD cannot. The EMD fails in chirp signals because its amplitude has
    no variation. The EWT can focus on the oscillating patterns and it is computationally
    faster than the EMD. On the other hand, the EWT can be failed if the input signal
    has two chirps and they overlap in both the frequency and time domains; in such
    cases, the EMD can handle it better [36]. 5 Concluding remarks The study investigated
    the efficiency of support vector regression, twin support vector machine, extreme
    learning machine, asymmetric Huber loss function-based extreme learning machine
    and ε-insensitive Huber loss function-based extreme learning machine, combined
    with three preprocessing methods (EMD, EEMD and EWT), in monthly streamflow estimation.
    Among the single models, the ε-insensitive Huber loss function-based extreme learning
    machine performed superior to the other models in streamflow estimation. The outcomes
    of the comparison revealed that the data preprocessing methods considerably improved
    the prediction accuracy of the implemented single models; improvements in root
    mean square errors of ε-insensitive Huber loss function-based ELM by implementing
    the EMD, EEMD and EWT are 9.2%, 21.2% and 68%, respectively. All the comparison
    criteria agree that the combination of EWT and ε-insensitive Huber loss function-based
    ELM performed superior to the other models in streamflow estimation. The main
    limitation of the present study is the use of data from one station. For future
    studies, more data from different climatic regions are needed to justify the efficiency
    of the proposed methods in streamflow estimation. The proposed combination methods
    can be compared with other machine learning methods such as ANN, ANFIS and deep
    learning and using different data preprocessing methods. References Ahmed AN,
    Van Lam T, Hung ND, Van Thieu N, Kisi O, El-Shafie A (2021) A comprehensive comparison
    of recent developed meta-heuristic algorithms for streamflow time series forecasting
    problem. Appl Soft Comput 105:107282. https://doi.org/10.1016/j.asoc.2021.107282
    Article   Google Scholar   Chen F, Chen Y, Bakhtiyorov Z, Zhang H, Man W, Chen
    F (2020) Central Asian river streamflows have not continued to increase during
    the recent warming hiatus. Atmos Res 246:105124. https://doi.org/10.1016/j.atmosres.2020.105124
    Article   Google Scholar   Christian K, Roy AF, Yudianto D, Zhang D (2021) Application
    of optimized support vector machine in monthly streamflow forecasting: using autocorrelation
    function for input variables estimation. Sustain Water Resour Manag 7(3):1–14.
    https://doi.org/10.1007/s40899-021-00506-y Article   Google Scholar   Deléchelle
    E, Lemoine J, Niang O (2005) Empirical mode decomposition: an analytical approach
    for sifting process. IEEE Signal Process Lett 12(11):764–767 Article   MATH   Google
    Scholar   de Souza GR, Merwade V, de Oliveira LFC, Viola MR, de Sá Farias M (2021)
    Regional flood frequency analysis and uncertainties: maximum streamflow estimates
    in ungauged basins in the region of Lavras, MG, Brazil. CATENA 197:104970. https://doi.org/10.1016/j.catena.2020.104970
    Article   Google Scholar   Gharib A, Davies EG (2021) A workflow to address pitfalls
    and challenges in applying machine learning models to hydrology. Adv Water Resour
    152:103920. https://doi.org/10.1016/j.advwatres.2021.103920 Article   Google Scholar   Gilles
    J (2013) Empirical wavelet transform. IEEE Trans Signal Process 61(16):3999–4010
    Article   MathSciNet   MATH   Google Scholar   Gupta D, Hazarika BB, Berlin M
    (2020) Robust regularized extreme learning machine with asymmetric Huber loss
    function. Neural Comput Appl 32(16):12971–12998 Article   Google Scholar   Han
    H, Hou J, Huang M, Li Z, Xu K, Zhang D, Bai G, Wang C (2020) Impact of soil and
    water conservation measures and precipitation on streamflow in the middle and
    lower reaches of the Hulu River Basin, China. CATENA 195:104792. https://doi.org/10.1016/j.catena.2020.104792
    Article   Google Scholar   Hosseinkhani H, Ohadia A (2017) Automobile gearbox
    compound faults detection based on empirical wavelet transform method. In: 2015
    7th international conference on accoustics and vibration (SPIN), pp 1–8. Sharif
    University of Technology, Iran Hsueh YM, Ittangihal VR, Wu WB, Chang HC, Kuo CC
    (2019) Fault diagnosis system for induction motors by CNN using empirical wavelet
    transform. Symmetry 11(10):1212 Article   Google Scholar   Huang X, Li Y, Tian
    Z, Ye Q, Ke Q, Fan D, Mao G, Chen A, Liu J (2021) Evaluation of short-term streamflow
    prediction methods in urban river basins. Phys Chem Earth Parts A/B/C 123:103027.
    https://doi.org/10.1016/j.pce.2021.103027 Article   Google Scholar   Huang NE,
    Wu Z (2008) A review on Hilbert–Huang transform: method and its applications to
    geophysical studies. Rev Geophys 46(2):1–23. https://doi.org/10.1029/2007RG000228
    Article   MathSciNet   Google Scholar   Huang NE, Shen Z, Long SR, Wu MC, Shih
    HH, Zheng Q, Liu H (1998) The empirical mode decomposition and Hilbert spectrum
    for nonlinear and nonstationary time series analysis. Proc R Soc A 545(1971):903–995
    Article   MATH   Google Scholar   Huan J, Cao W, Gu Y, Qin Y (2020) A hybrid model
    of empirical wavelet transform and extreme learning machine for dissolved oxygen
    forecasting. Int J Embedded Syst 13(1):9–17 Article   Google Scholar   Jiang Q,
    Qi Z, Tang F, Xue L, Bukovsky M (2020) Modeling climate change impact on streamflow
    as affected by snowmelt in Nicolet River Watershed, Quebec. Comput Electron Agric
    178:105756. https://doi.org/10.1016/j.compag.2020.105756 Article   Google Scholar   Kadir
    M, Fehri R, Souag D, Vanclooster M (2020) Exploring causes of streamflow alteration
    in the Medjerda River, Algeria. J Hydrol Reg Stud 32:100750. https://doi.org/10.1016/j.ejrh.2020.100750
    Article   Google Scholar   Li C, Fang H (2021) Assessment of climate change impacts
    on the streamflow for the Mun River in the Mekong Basin Southeast Asia: Using
    SWAT model. CATENA 201:105199. https://doi.org/10.1016/j.catena.2021.105199 Article   Google
    Scholar   Liu J, You Y, Zhang Q, Gu X (2021) Attribution of streamflow changes
    across the globe based on the Budyko framework. Sci Total Environ. https://doi.org/10.1016/j.scitotenv.2021.148662
    Article   Google Scholar   Lin Y, Wang D, Wang G, Qiu J, Long K, Du Y, Dai Y (2021)
    A hybrid deep learning algorithm and its application to streamflow prediction.
    J Hydrol. https://doi.org/10.1016/j.jhydrol.2021.126636 Article   Google Scholar   Mehta
    R, Vishwakarma VP and Rajpal N (2015) Lagrangian support vector regression based
    image watermarking in wavelet domain. In: 2015 2nd international conference on
    signal processing and integrated networks (SPIN), pp 854–859, IEEE, Piscataway
    Naik J, Satapathy P, Dash PK (2018) Short-term wind speed and wind power prediction
    using hybrid empirical mode decomposition and kernel ridge regression. Appl Soft
    Comput 70:1167–1188 Article   Google Scholar   Niu WJ, Feng ZK (2021) Evaluating
    the performances of several artificial intelligence methods in forecasting daily
    streamflow time series for sustainable water resources management. Sustain Cities
    Soc 64:102562. https://doi.org/10.1016/j.scs.2020.102562 Article   Google Scholar   Prasad
    R, Deo RC, Li Y, Maraseni T (2018) Soil moisture forecasting by a hybrid machine
    learning technique: ELM integrated with ensemble empirical mode decomposition.
    Geoderma 330:136–161 Article   Google Scholar   Qu J, Ren K, Shi X (2021) Binary
    Grey wolf optimization-regularized extreme learning machine wrapper coupled with
    the boruta algorithm for monthly streamflow forecasting. Water Resour Manag 35(3):1029–1045.
    https://doi.org/10.1007/s11269-021-02770-1 Article   Google Scholar   Revilla-Romero
    B, Beck HE, Burek P, Salamon P, de Roo A, Thielen J (2015) Filling the gaps: calibrating
    a rainfall-runoff model using satellite-derived surface water extent. Remote Sens
    Environ 171:118–131. https://doi.org/10.1016/j.rse.2015.10.022 Article   Google
    Scholar   Ribeiro VHA, Reynoso-Meza G, Siqueira HV (2020) Multi-objective ensembles
    of echo state networks and extreme learning machines for streamflow series forecasting.
    Eng Appl Artif Intell 95:103910. https://doi.org/10.1016/j.engappai.2020.103910
    Article   Google Scholar   Reis GB, da Silva DD, Fernandes Filho EI, Moreira MC,
    Veloso GV, de Souza Fraga M, Pinheiro SAR (2021) Effect of environmental covariable
    selection in the hydrological modeling using machine learning models to predict
    daily streamflow. J Environ Manag 290:112625. https://doi.org/10.1016/j.jenvman.2021.112625
    Article   Google Scholar   Ren Y, Suganthan PN, Srikanth N (2014) A novel empirical
    mode decomposition with support vector regression for wind speed forecasting.
    IEEE Trans Neural Netw Learn Syst 27(8):1793–1798 Article   MathSciNet   Google
    Scholar   Riahi-Madvar H, Dehghani M, Memarzadeh R, Gharabaghi B (2021) Short
    to long-term forecasting of river flows by heuristic optimization algorithms hybridized
    with ANFIS. Water Resour Manag 35(4):1149–1166. https://doi.org/10.1007/s11269-020-02756-5
    Article   Google Scholar   Usman M, Ndehedehe CE, Farah H, Manzanas R (2021) Impacts
    of climate change on the streamflow of a large river basin in the Australian tropics
    using optimally selected climate model outputs. J Clean Prod. https://doi.org/10.1016/j.jclepro.2021.128091
    Article   Google Scholar   Sammen SS, Ehteram M, Abba SI, Abdulkadir RA, Ahmed
    AN, El-Shafie A (2021) A new soft computing model for daily streamflow forecasting.
    Stoch Environ Res Risk Assess. https://doi.org/10.1007/s00477-021-02012-1 Article   Google
    Scholar   Santhosh M, Venkaiah C, Kumar DV (2018) Ensemble empirical mode decomposition
    based adaptive wavelet neural network method for wind speed prediction. Energy
    Convers Manag 168:482–493 Article   Google Scholar   Saraiva SV, de Oliveira Carvalho
    F, Santos CAG, Barreto LC, Freire PKDMM (2021) Daily streamflow forecasting in
    Sobradinho Reservoir using machine learning models coupled with wavelet transform
    and bootstrapping. Appl Soft Comput 102:107081. https://doi.org/10.1016/j.asoc.2021.107081
    Article   Google Scholar   Sikorska-Senoner AE, Quilty JM (2021) A novel ensemble-based
    conceptual-data-driven approach for improved streamflow simulations. Environ Modell
    Softw. https://doi.org/10.1016/j.envsoft.2021.105094 Article   Google Scholar   Singh
    GV (2016) Empirical wavelet transform & its comparison with empirical mode decomposition:
    a review. Int J Eng Res Technol (IJERT) ACMEE 4(15):1–5. https://doi.org/10.17577/IJERTCONV4IS15009
    Article   Google Scholar   Tyralis H, Papacharalampous G, Langousis A (2021) Super
    ensemble learning for daily streamflow forecasting: large-scale demonstration
    and comparison with multiple machine learning algorithms. Neural Comput Appl 33(8):3053–3068.
    https://doi.org/10.1007/s00521-020-05172-3 Article   Google Scholar   Wagena MB,
    Goering D, Collick AS, Bock E, Fuka DR, Buda A, Easton ZM (2020) Comparison of
    short-term streamflow forecasting using stochastic time series, neural networks,
    process-based, and Bayesian models. Environ Model Softw 126:104669. https://doi.org/10.1016/j.envsoft.2020.104669
    Article   Google Scholar   Wu Z, Huang NE (2009) Ensemble empirical mode decomposition:
    a noise-assisted data analysis method. Adv Adapt Data Anal 1(01):1–41 Article   Google
    Scholar   Xiang Z, Demir I (2020) Distributed long-term hourly streamflow predictions
    using deep learning—a case study for State of Iowa. Environ Model Softw 131:104761.
    https://doi.org/10.1016/j.envsoft.2020.104761 Article   Google Scholar   Zhang
    J, Gao G, Li Z, Fu B, Gupta HV (2020) Identification of climate variables dominating
    streamflow generation and quantification of streamflow decline in the Loess Plateau,
    China. Sci Total Environ 722:137935. https://doi.org/10.1016/j.scitotenv.2020.137935
    Article   Google Scholar   Zeng X, Schnier S, Cai X (2021) A data-driven analysis
    of frequent patterns and variable importance for streamflow trend attribution.
    Adv Water Resour 147:103799. https://doi.org/10.1016/j.advwatres.2020.103799 Article   Google
    Scholar   Zhao X, Lv H, Sang Y, Wei Y, Zhu X (2021) Enhancing robustness of monthly
    streamflow forecasting model using gated recurrent unit based on improved grey
    wolf optimizer. J Hydrol. https://doi.org/10.1016/j.jhydrol.2021.126607 Article   Google
    Scholar   Download references Author information Authors and Affiliations School
    of Economics and Statistics, Guangzhou University, Guangzhou, 510006, China Rana
    Muhammad Adnan Ikram Department of Computer Science and Engineering, Koneru Lakshmaiah
    Education Foundation, Vaddeswaram, Andhra Pradesh, 522302, India Barenya Bikash
    Hazarika Department of Computer Science and Engineering, National Institute of
    Technology, Arunachal Pradesh, Jote, 791112, India Deepak Gupta Faculty of Science,
    Agronomy Department, Hydraulics Division University, 20 Août 1955, Route El Hadaik,
    BP 26, Skikda, Algeria Salim Heddam Department of Civil Engineering, Technical
    University of Lübeck, 23562, Lübeck, Germany Ozgur Kisi Civil Engineering Department,
    Ilia State University, 0162, Tbilisi, Georgia Ozgur Kisi Corresponding author
    Correspondence to Deepak Gupta. Ethics declarations Conflict of interest The authors
    have no conflict of interest. Additional information Publisher''s Note Springer
    Nature remains neutral with regard to jurisdictional claims in published maps
    and institutional affiliations. Rights and permissions Springer Nature or its
    licensor (e.g. a society or other partner) holds exclusive rights to this article
    under a publishing agreement with the author(s) or other rightsholder(s); author
    self-archiving of the accepted manuscript version of this article is solely governed
    by the terms of such publishing agreement and applicable law. Reprints and permissions
    About this article Cite this article Ikram, R.M.A., Hazarika, B.B., Gupta, D.
    et al. Streamflow prediction in mountainous region using new machine learning
    and data preprocessing methods: a case study. Neural Comput & Applic 35, 9053–9070
    (2023). https://doi.org/10.1007/s00521-022-08163-8 Download citation Received
    02 September 2021 Accepted 06 December 2022 Published 27 December 2022 Issue Date
    April 2023 DOI https://doi.org/10.1007/s00521-022-08163-8 Share this article Anyone
    you share the following link with will be able to read this content: Get shareable
    link Provided by the Springer Nature SharedIt content-sharing initiative Keywords
    Streamflow prediction Extreme learning machine Empirical wavelet transform Empirical
    model decomposition Use our pre-submission checklist Avoid common mistakes on
    your manuscript. Associated Content Part of a collection: Computer Science SDG
    7: Affordable and Clean Energy Sections Figures References Abstract Introduction
    Case study Methods Application and results Concluding remarks References Author
    information Ethics declarations Additional information Rights and permissions
    About this article Advertisement Discover content Journals A-Z Books A-Z Publish
    with us Publish your research Open access publishing Products and services Our
    products Librarians Societies Partners and advertisers Our imprints Springer Nature
    Portfolio BMC Palgrave Macmillan Apress Your privacy choices/Manage cookies Your
    US state privacy rights Accessibility statement Terms and conditions Privacy policy
    Help and support 129.93.161.219 Big Ten Academic Alliance (BTAA) (3000133814)
    - University of Nebraska-Lincoln (3000134173) © 2024 Springer Nature"'
  inline_citation: '>'
  journal: Neural Computing and Applications
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: 'Streamflow prediction in mountainous region using new machine learning and
    data preprocessing methods: a case study'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Narvaez-Montoya C.
  - Mahlknecht J.
  - Torres-Martínez J.A.
  - Mora A.
  - Bertrand G.
  citation_count: '6'
  description: Seawater intrusion is among the world's leading causes of groundwater
    contamination, as salty water can affect potable water access, food production,
    and ecosystem functions. To explore such contamination sources, multivariate analysis
    supported by unsupervised learning tools has been used for decades to aid in water
    resource pattern recognition, clustering, and water quality data variability characterization.
    This study proposes a systematic review of these techniques applied for supporting
    seawater intrusion identification based on the Preferred Reporting Items for Systematic
    Reviews and Meta-Analyses (PRISMA) statement and subsequent bibliometric analysis
    of 102 coastal hydrogeological studies. The most relevant identified methods,
    including principal components analysis (PCA), hierarchical clustering analysis,
    K-means clustering, and self-organizing maps, are explained and applied to a case
    study. Although 74 % of the studies that applied dimensional reduction methods,
    such as PCA, associated most of the database variance with the salinization process,
    77 % of the studies that applied clustering methods associated at least one water
    sample cluster with the influence of seawater intrusion. Based on the review and
    a practical demonstration using the open-source R software platform, recommendations
    are made regarding data preprocessing, research opportunities, and publishing
    information necessary to replicate and validate the studies.
  doi: 10.1016/j.scitotenv.2022.160933
  full_citation: '>'
  full_text: '>

    "Skip to main content Skip to article Journals & Books Search Register Sign in
    Brought to you by: University of Nebraska-Lincoln View PDF Download full issue
    Outline Highlights Abstract Graphical abstract Keywords 1. Introduction 2. Background
    3. Material and methods 4. Results and discussion 5. Conclusions CRediT authorship
    contribution statement Declaration of competing interest Acknowledgments Data
    availability References Show full outline Cited by (6) Figures (11) Show 5 more
    figures Tables (3) Table 1 Table 2 Table 3 Extras (3) Download all Table S1 Table
    S2 Supplementary material for section S1 to section S6 Science of The Total Environment
    Volume 864, 15 March 2023, 160933 Review Seawater intrusion pattern recognition
    supported by unsupervised learning: A systematic review and application Author
    links open overlay panel Christian Narvaez-Montoya a, Jürgen Mahlknecht a, Juan
    Antonio Torres-Martínez a, Abrahan Mora b, Guillaume Bertrand c d Show more Share
    Cite https://doi.org/10.1016/j.scitotenv.2022.160933 Get rights and content Under
    a Creative Commons license open access Highlights • A database of hydrogeochemical
    studies in coastal aquifers was developed. • The reviewed techniques were explained
    and applied to a practical case. • R scripts for the reviewed techniques are presented.
    • Sixty-two percent of the reviewed studies did not report raw data. • TDS, EC,
    and TH are redundant variables if major ions are also used. Abstract Seawater
    intrusion is among the world''s leading causes of groundwater contamination, as
    salty water can affect potable water access, food production, and ecosystem functions.
    To explore such contamination sources, multivariate analysis supported by unsupervised
    learning tools has been used for decades to aid in water resource pattern recognition,
    clustering, and water quality data variability characterization. This study proposes
    a systematic review of these techniques applied for supporting seawater intrusion
    identification based on the Preferred Reporting Items for Systematic Reviews and
    Meta-Analyses (PRISMA) statement and subsequent bibliometric analysis of 102 coastal
    hydrogeological studies. The most relevant identified methods, including principal
    components analysis (PCA), hierarchical clustering analysis, K-means clustering,
    and self-organizing maps, are explained and applied to a case study. Although
    74 % of the studies that applied dimensional reduction methods, such as PCA, associated
    most of the database variance with the salinization process, 77 % of the studies
    that applied clustering methods associated at least one water sample cluster with
    the influence of seawater intrusion. Based on the review and a practical demonstration
    using the open-source R software platform, recommendations are made regarding
    data preprocessing, research opportunities, and publishing information necessary
    to replicate and validate the studies. Graphical abstract Download : Download
    high-res image (154KB) Download : Download full-size image Previous article in
    issue Next article in issue Keywords Coastal aquifersMachine learningMultivariateClusteringSalinization
    1. Introduction Anthropogenic activities and climate change have had significant
    negative impacts on the world''s water resources over the last 200 years, and
    these effects are expected to intensify (Amanambu et al., 2020; Burrell et al.,
    2020; Ferguson and Gleeson, 2012). This situation is magnified in coastal plain
    areas, which are home of 70 % of the world''s population (Alfarrah and Walraevens,
    2018). Many of these areas are located in arid and semi-arid climates with insufficient
    surface water resources, leading to a critical dependence on groundwater (Mianabadi
    et al., 2020; Vaux, 2011). Coastal areas with Mediterranean and tropical climates
    tend to increase surface water and groundwater use to meet their needs (Busico
    et al., 2018; Yin et al., 2021). However, groundwater overexploitation reduces
    freshwater outflow to the sea and represents an additional adverse effect in many
    coastal zones. Such exploitation causes seawater to migrate towards fresh groundwater
    resources, and the resulting water mixture is extracted by production wells used
    for public water supply, irrigation, or industry (Alfarrah and Walraevens, 2018).
    This constitutes a severe threat to coastal water supply systems and is one of
    the leading causes of groundwater contamination (Michael et al., 2017; Polemio
    and Zuffianò, 2020; Tully et al., 2019). Seawater intrusion has been identified
    in approximately 100 countries and regions around the world, and approximately
    32 % of coastal metropolitan cities are estimated to be threatened by it (Cao
    et al., 2021). Salty water associated with this source and other salinization
    phenomena, such as irrigation return flow or sewage system leakages, cause health
    problems, such as diarrheal diseases and issues related to hypertension, like
    stroke, heart attack, and preeclampsia. Similarly, saline water leads to the deterioration
    of water quality for irrigation purposes (Damonte and Boelens, 2019; Naser et
    al., 2017; Rakib et al., 2020; Tully et al., 2019). Thus, monitoring and understanding
    the natural and human relations in groundwater systems is essential for developing
    appropriate and sustainable management strategies for coastal aquifers (Lall et
    al., 2020; Michael et al., 2017). However, investigating groundwater requires
    multidisciplinary approaches that incorporate environmental, geological, physical,
    and social aspects and analyses of normally limited physical and chemical information
    (Díaz-Alcaide and Martínez-Santos, 2019; Michael et al., 2017). Analyses and models
    have been developed to determine the mechanisms underlying the seawater intrusion
    phenomenon (Cao et al., 2021; Enemark et al., 2019). However, hydrological processes
    are highly complex, dynamic, and non-linear at both spatial and temporal scales;
    therefore, local or regional studies are subject to great uncertainty (Kalteh
    et al., 2008; Rajabi et al., 2018). Consequently, one of the biggest challenges
    facing exploratory studies is to identify whether a sample of brackish water originates
    from seawater intrusion or another source of groundwater salinization, as shown
    in Fig. 1 (Abu-alnaeem et al., 2018; Mirzavand et al., 2020). From this perspective,
    authors have argued that a proper international tool platform based on hydrogeological
    data is urgently needed to verify the occurrence and influence of seawater intrusion
    (Cao et al., 2021). Download : Download high-res image (829KB) Download : Download
    full-size image Fig. 1. Coastal groundwater squeeze. (1) Groundwater overexploitation;
    (2) agricultural contamination; (3) urban sprawl and development; (4) aquaculture
    contamination; (5) land reclamation dredging and navigation; (6) mining contamination;
    (7) seawater intrusion; (8) connate saline water; (9) marine transgression; (10)
    sea spray; (11) episodic flooding; (12) evaporative concentration; (13) rocks
    dissolution; (14) salt filtering by clay; (15) irrigation return flow; and (16)
    effluents and spills. In this context, machine learning techniques have benefitted
    various complex studies in hydrological research (Bertrand et al., 2022; Rajoub,
    2020; Tahmasebi et al., 2020). While supervised techniques predict and optimize
    models based on known outputs, unsupervised techniques learn more about the internal
    dependencies among explanatory variables (Berry et al., 2020; Díaz-Alcaide and
    Martínez-Santos, 2019). Multivariate analysis supported by unsupervised machine
    learning tools has been used for decades to characterize the range and variability
    of environmental water tracers across broad temporal and spatial scales, and the
    number of studies using these tools is increasing exponentially (Gredilla et al.,
    2013; Sergeant et al., 2016). Although the unsupervised nature of these techniques
    does not enable direct identification of dynamic water processes, obtaining water
    quality patterns greatly supports the interpretation of various phenomena (Li
    et al., 2018; Wunderlin et al., 2001). Therefore, it is essential to review how
    these methods have been applied to hydrogeochemical data to identify patterns
    that help differentiate seawater intrusion from other sources. Such a review should
    permit the proposal for a typology of usable tools and their limitations based
    on the specific objectives and constraints of researchers. This bibliometric review
    study followed the Preferred Reporting Items for Systematic Reviews and Meta-Analysis
    (PRISMA) statement (Moher et al., 2009), which allowed the review to be conducted
    more objectively. This systematic review was based on a flow chart, and different
    restrictions where applied to limit the document search, extraction, and analysis.
    First, we searched for papers published from 2000 to 2022 (22 years) that applied
    unsupervised learning tools to analyze hydrochemical data on coastal aquifers
    presumably affected by seawater intrusion. Subsequently, the articles were filtered
    using predetermined rules to eliminate incorrect selections. Finally, the selected
    articles were analyzed to assess how unsupervised learning tools have been applied
    to support seawater intrusion pattern recognition. The objective was to provide
    a reference for researchers and professionals who wish to apply these methodologies
    to identify hydrogeochemical processes in coastal aquifers. A database was established
    to generate a range of available similar studies to which a specific approach
    can be compared. Additionally, the most appropriate identified methods applied
    to the La Paz (Mexico) coastal aquifer case and the reviewed tools were delivered
    using an open-source data science software. 2. Background 2.1. Seawater intrusion
    identification Seawater intrusion monitoring and assessment has been performed
    using four approaches: hydraulic head measurements, groundwater models, geophysical
    methods, and environmental tracer analysis (Cao et al., 2021; Werner et al., 2013).
    Hydraulic head measurements consider hydraulic gradient evaluations because landward
    gradients can reveal seawater intrusion susceptibility (Jasechko et al., 2020).
    However, hydraulic heads in the mixing zone are difficult to interpret owing to
    salinity; density variations occur at different elevations of an observed piezometer
    (Werner et al., 2013). In groundwater flow and transport models, multiple types
    of environmental data are integrated to numerically simulate variable density
    flow (Costall et al., 2020). Although such models are among the most complete
    approaches, the calibration stage can be tedious and time-consuming, and obtained
    results may be unsatisfactory (Carrera et al., 2010). Geophysical methods are
    used to map the subsurface groundwater salinity distribution in one, two, and
    three dimensions based on the differences in the electromagnetic properties of
    fresh and salty water (Werner et al., 2013). These methods also require calibration
    to differentiate the received signals from the lithological structure and salinity
    distribution (Cao et al., 2021). Environmental tracers, such as major ions, have
    been broadly recognized as valuable tools for determining seawater intrusion (Li
    et al., 2020; Mirzavand et al., 2020). Compared with other approaches, tracers
    rely on multivariate analysis and are used to describe the groundwater system;
    moreover, hydrochemical data are easy to obtain owing to their low test costs
    and the high demand for exploration (Liu et al., 2021). Major ions are analyzed
    at different sample points based on multiple bivariates and composite plots, such
    as Piper, Stiff, and Gibbs diagrams (Mirzavand et al., 2020). These tracers have
    concentrations higher than 5 mg/L and account for over 95 % of the total solute
    content (Poeter et al., 2020). Generally, terrestrial groundwater tends to be
    of the alkaline earth bicarbonate type, and the concentration of Ca2+ often exceeds
    that of Mg2+. Seawater has much higher concentrations of major ions (except for
    Ca2+ and HCO3−) and some minor ions than groundwater, and its water composition
    does not vary significantly at the global scale, because the long residence time
    in the ocean implies mixing and homogenization (Jiao and Post, 2019). The characteristics
    of groundwater from different coastal aquifers and standard seawater are listed
    in Table 1, and a Piper diagram of these data is shown in Fig. 2. Table 1. Median
    values of the chemical composition of different coastal aquifer case studies and
    standard seawater. Values in brackets show the variation range. Parameter La Paz
    (Mexico) - Alluvium Arid (Tamez-Meléndez et al., 2016) Göksu (Turkey) - Alluvium
    Mediterranean (Güner et al., 2021) Jaffna (Siri Lanka) Karstic Monsoon (Chandrajith
    et al., 2016) Shenzhen (China) Granite Monsoon (Shi et al., 2018) Standard Seawater
    (Jiao and Post, 2019) Chloride, Cl− (mg/L) 385 (54.5–2960) 141.2 (72–1597.6) 250
    (30–3500) 26.1 (4.1–3260) 19,804 Sodium, Na+ (mg/L) 137 (36.7–1080) 122.3 (19.5–880.1)
    130 (25–1500) 20.4 (4.2–1730) 11,033 Sulphate, SO42− (mg/L) 64.3 (7.9–490) 193.6
    (105.6–321.5) 49 (12–430) 29.5 (2.2–379.7) 2776 Magnesium, Mg2+ (mg/L) 39.5 (9.3–344)
    31.1 (13.4–125.6) 24 (1.9–220) 4.4 (0.3–225) 1314 Calcium, Ca2+ (mg/L) 104 (27.8–658)
    50.7 (15.8–136.4) 90 (7.6–660) 55.4 (1–214.8) 422 Potassium, K+ (mg/L) 4.1 (1.5–14)
    5.84 (2.4–34.5) 9.8 (0.9–44) 7.7 (0.7–61.8) 408 Bicarbonate, HCO3− (mg/L) 325
    (166–1290) 246.1 (77.8–453.7) 250 (92–601) 165 (0.6–611.2) 107 Nitrate, NO3− (mg/L)
    24.92 (0.7–216) 12.4 (12.1–13.3) 3.1 (1.8–26.1) 2.75 (0–26.5) – Total dissolved
    solids, TDS (mg/L) 1054 (348–5828) 554 (157–3941) 765 (221–6604) 279 (23–6760)
    36,000 pH 7.2 (6.8–8.3) 7.8 (7.5–8.2) 7.59 (6.8–8.2) 7.4 (4.6–7.9) 8.1 T (°C)
    29.7 (25–33.4) 20.9 (20.2–23.1) 30.5 (29.6–31.8) 23.4 (15.4–29.5) – Download :
    Download high-res image (978KB) Download : Download full-size image Fig. 2. Piper
    diagram for the different coastal aquifer case studies and seawater listed in
    Table 1. Tracer analysis encompasses many parameters in addition to the chemical
    composition, including biological, physical, and physicochemical parameters, such
    as temperature (T), pressure, density, electrical conductivity (EC), sampling
    position location, sampling date, sampling depth, and isotopic signatures, such
    as δ 2H (deuterium) and δ18O (oxygen-18) (Jiao and Post, 2019; Werner et al.,
    2013). Consequently, meaningful conclusions regarding water sources can only be
    made by combining the different parameter types. Exploring these multivariate
    data relationships is supported by the application of unsupervised learning techniques
    (Liu et al., 2021; Werner et al., 2013). For example, Table S1 shows multivariate
    data from the sampling campaign performed in August 2013 for the Mexican La Paz
    coastal aquifer (Section S1). The aquifer and database were analyzed by Tamez-Meléndez
    et al. (2016) and Torres-Martínez et al. (2021), who identified different salinization
    and nitrification sources supported by the multivariate analysis of hydrogeochemical
    and isotopic tracers. 2.2. Unsupervised pattern recognition in hydrogeology The
    spatial variability of water samples can provide insights into aquifer heterogeneity
    and connectivity; thus, a robust classification and association scheme is important
    for the characterization of hydrogeological systems (Güler et al., 2002). Multivariate
    analysis of the physical, chemical, and biological characteristics of water resources
    supported by unsupervised learning tools has been used for decades to characterize
    data, select meaningful variables, and recognize pattern data structures and trends
    (Gredilla et al., 2013; Sergeant et al., 2016). Unlike supervised methods, which
    aim to predict variables and optimize parameters based on known outputs, unsupervised
    techniques aim to delineate the underlying internal relationships of the features
    (Díaz-Alcaide and Martínez-Santos, 2019; Berry et al., 2020). In the absence of
    certainty about “real outputs” from the provenance of water samples, unsupervised
    methods are preferred for the broad identification of the latent features, because
    the output is not restricted to a specific response (Tahmasebi et al., 2020).
    Unsupervised pattern recognition techniques do not necessarily establish cause-and-effect
    relationships; they rather present information in a compact format as the first
    step in the complete analysis for generating hypotheses and performing hydrogeochemical
    data interpretation (Berry et al., 2020). Unsupervised techniques for pattern
    recognition have been commonly employed to analyze complex datasets and integrate
    environmental and pollution data (Fdez-Ortiz de Vallejuelo et al., 2011). These
    techniques apply mathematical methods to generate object data, graphical representations
    of the newly generated data, and interpretations of the resulting objects (Gredilla
    et al., 2013). These techniques can be divided into three main groups: (1) dimensional
    reduction methods (DRM), (2) cluster analysis (CA), and (3) artificial neural
    networks (ANN) (Fig. 3). Download : Download high-res image (467KB) Download :
    Download full-size image Fig. 3. Classification of pattern recognition techniques.
    DRM aims to limit n-dimensional information about objects to a set of reduced
    and more representative dimensions (Ayesha et al., 2020). In this manner, each
    observation can be graphically depicted in 2D or 3D plots that show the most relevant
    relations in the database. Principal component analysis (PCA) is the most commonly
    used method, and a full review of the most relevant methods can be found in Ayesha
    et al. (2020). CA techniques are the most widely used pattern recognition methods,
    and their objective is to assign observations to the same cluster based on the
    degree of similarity among the variables (properties) that characterize the observation
    (Gredilla et al., 2013). A full review of traditional and recent developments
    in CA techniques can be found in Saxena et al. (2017). Finally, the use of ANN
    has been increasing, and this method simulates the nervous system in human beings
    to create models for pattern recognition (Gredilla et al., 2013). The most popular
    method for multivariate analysis is the self-organizing map (SOM), which performs
    segmentation similar to CA and allows for a topological representation of the
    database. A review of general ANN for pattern recognition can be found in Abiodun
    et al. (2019). 3. Material and methods 3.1. Focused question and search strategy
    To delineate the type and methods of unsupervised learning techniques that have
    been used to identify seawater intrusion in coastal aquifers, this bibliometric
    review study follows the above-mentioned PRISMA statement (Moher et al., 2009).
    A systematic computerized literature search was conducted in May 2022 using Scopus
    and the Web of Science. The combination of three keywords [“seawater AND intrusion
    AND cluster”, or “seawater AND intrusion AND unsupervised”, or “seawater AND intrusion
    AND multivariate”, or “saltwater AND intrusion AND cluster”, or “saltwater AND
    intrusion AND unsupervised”, or “saltwater AND intrusion AND multivariate”] was
    used to search for original articles released from 2000 to 2022, based on the
    search fields of “keyword”, “abstract” and “title”. After obtaining raw data,
    articles were excluded based on the following criteria: duplicate studies, no
    DOI, papers published before 2021 that did not have any citations, analyses that
    did not consider major ions, articles in which the search keywords did not match
    unsupervised machine learning or multivariate methodologies applied for water
    quality, analyses that were not applied to groundwater, and full-text articles
    that were not written in English, Spanish, Portuguese, or French. 3.2. Data extraction
    and analysis The full text of the final papers selected for the analysis were
    assessed. General information on the article identification process, study case
    description, unsupervised learning application, and hydrogeochemical techniques
    was extracted. The data variables extracted for each section are shown in Table
    S2. If the articles did not specify the variable “climate”, then this variable
    was included based on the location of the study area and the Köppen climate classification
    (Cui et al., 2021). Furthermore, if the article did not specify the variable “surface
    of the study area”, then this variable was computed using QGIS software (v.3.26,
    QGIS Development Team, 2022) based on the study boundaries shown in the study
    area figure without considering the sea surface. Once the database was filled,
    a frequency analysis was performed for categorical variables of interest. Additionally,
    the ratios of “number of samples” to “surface area” (sample density per area)
    and “number samples” to “number of variables” (sample density per variable) were
    computed. If a study used different databases separately, then the databases were
    considered independent in the analysis. In parallel, the application of the most
    relevant unsupervised learning techniques was described and discussed. The methods
    were applied to the La Paz aquifer database (Table S1) for a practical demonstration
    using the open-source R studio software. 4. Results and discussion Fig. 4 illustrates
    the scheme of the methodology used. Of the 199 identified documents, 94 were excluded
    because they did not comply with the filtration characteristics detailed in the
    methodology section. Data extracted from the remaining 102 articles were analyzed
    (Table S2). 4.1. Bibliometric analysis 4.1.1. Research characteristics Most of
    the research articles belonged to the subject areas of environmental science (43
    %), earth and planetary sciences (29 %), and agricultural and biological sciences
    (11 %) (Fig. 5a). This associations related to the principal objective of the
    research studies, which was to explore the natural and anthropogenic processes
    of the study areas based on a physical context using an interdisciplinary approach.
    The three subject areas medicine (4 %), engineering (3 %), and social science
    (3 %) are associated with the studies focused on understanding the effect of groundwater
    processes on health and the social relationships of the study cases. Interestingly,
    although search keywords for computer science were included, no items were associated
    with this field. Download : Download high-res image (314KB) Download : Download
    full-size image Fig. 4. Flow chart of the literature search and identification
    process. Download : Download high-res image (823KB) Download : Download full-size
    image Fig. 5. Research characteristics. (a) Documents by Scopus subject area;
    (b) Study cases location and salinity (total dissolved solids; TDS < 600 mg/L
    can be considered as good water quality) (WHO, 2011). The areas investigated in
    the reviewed studies were located in 31 countries (Fig. 5b). The country with
    the greatest number of studies was India at 19, followed by Tunisia and China
    at ten and seven, respectively. Similar to the seawater intrusion phenomenon,
    problems in coastal aquifers are usually associated with overexploitation in arid
    and semi-arid climates where little groundwater recharge occurs (Parizi et al.,
    2019). Of the 102 studies, 32 were associated with this type of climate (Köppen
    classification) in Egypt, Saudi Arabia, Oman, Mexico, Tunisia, Iran, and Djibouti.
    However, this phenomenon has also been identified in countries with Mediterranean
    climate, such as Turkey, Greece, Morocco, Lebanon, and Italy. Similarly, countries
    with humid and subhumid climates and with greater water availability, such as
    Ghana, Bangladesh, India, Mozambique, and Thailand, also presented seawater intrusion
    concerns. Table 2. Data characteristics of the reviewed studies. Variable Mean
    Minimum Median Maximum Samples 403 9 59 30,809 Variables 14 5 12.5 31 Ratio sample/area
    (samples/km2) 90.56 0.0004 0.09 8100 Ratio sample/variable 13.38 0.75 4 669.76
    4.1.2. Research data Hydrochemical analyses in the reviewed studies were highly
    variable owing to differences in the biophysical and socioeconomic settings and
    sampling strategies. The most extensively analyzed area was in Morocco (710,850
    km2), with 542 samples analyzed for nine variables (Ez-zaouy et al., 2022), while
    the smallest area studied was a portion of Manukan Island in Malaysia (0.02 km2),
    with 162 samples analyzed for 13 variables (Aris et al., 2012). Thus, while the
    Morocco study had a sample density per area of 0.0004 samples/km2 and a sample
    density per variable of 30.11, the Manukan Island study had a sample density per
    area of 8100 samples/km2 and a sample density per variable of 12.46. From a performance
    perspective, the higher the number of samples and the higher the sample density
    per area, the better the analysis applied to the data sets (USGS, 2018). For multivariate
    analysis, the sample density per variable should be as large as possible, although
    there is no clear rule on the most relevant proportion (Knapp and Campbell-Heider,
    1989). Table S2 shows the number of samples, variables, sample density per area,
    and sample density per variable for each document, and Table 2 summarizes the
    102 studies. 4.2. Description of unsupervised learning techniques 4.2.1. Principal
    components analysis PCA is the most commonly used DRM for reducing larger sets
    of correlated variables into smaller and interpreting datasets regarding the variability
    of the information (Jolliffe and Cadima, 2016; Björklund, 2019; Ayesha et al.,
    2020). Principal components (PCs) are uncorrelated linear combinations of the
    original variables such that the sum of their explained variance is equal to that
    of the original variables. The variances of the PCs are eigenvalues, whereas the
    coefficients of the linear combinations are eigenvectors extracted from the covariance
    or correlation matrix of the data set (Olsen et al., 2012). Typically, a correlation
    matrix is used if the variables have different measurement scales to standardize
    the effects and no distributional assumptions are required (Jolliffe, 2002; Jolliffe
    and Cadima, 2016). In addition to the coefficients, the original variables are
    associated with the PCs using values between −1 and 1 “loadings”, representing
    each variable''s influence on each component. Values close to −1 or 1 indicate
    significant positive or negative influence, and values close to 0 indicate little
    influence (Jolliffe and Cadima, 2016). There are many ways to adapt the PCA method
    to achieve modified objectives or analyze data of different types (Jolliffe and
    Cadima, 2016). For instance, including categorical variables is possible with
    a generalization of the PCA method, called multiple correspondence analysis (MCA)
    (Audigier et al., 2017; Greenacre and Pardo, 2011). Another important adaptation
    is orthogonal rotation, which usually applies varimax criterion to simplify the
    interpretation of the previously computed PCs (Jolliffe and Cadima, 2016). The
    varimax rotation goal is to maximize the variance of the loadings within the components,
    thus making larger loadings even larger and smaller loadings even smaller, while
    preserving the cumulative variance of the components (Denis, 2020). The rotation
    idea is borrowed from factor analysis (FA), which consists of an array of multivariate
    statistical methods and is sometimes confused with the specific PCA concept (Jolliffe
    and Cadima, 2016; Marefat et al., 2019). Currently, statistical packages compute
    PCs using FA, which allows for rotation to be applied in the same software module
    (Ayesha et al., 2020; IBM, 2021; Minitab, 2022). In water research, the PCA method
    seeks to represent a set of multivariate observations in a lower data matrix arranged
    along interpretable axes corresponding to known environmental gradients (e.g.,
    warming water temperature and decreasing dissolved oxygen). With the variability
    aligned to the gradients, it is possible to determine which individual variables
    are responsible for the greatest observed variation in each axis. This helpful
    characteristic of PCA may assist monitoring programs by prioritizing limited resources
    by measuring variables that explain the majority of water quality regime variations
    (Sergeant et al., 2016). In general, the use of PCA in the reviewed studies was
    exploratory and, mainly determined the processes and variables that explained
    most of the variance in the aquifer samples. Additionally, four of these studies
    used PCA as a pre-processing step for some cluster methods (Table S2). In this
    manner, the database was reduced to the principal components and clusters were
    created using the PCs as new variables. PCA was applied in 77 of the 102 studies.
    In addition, one study applied MCA, and ten studies applied FA without specifying
    the extraction method (e.g., PCA, maximum-likelihood method, unweighted least-squares
    method); however, PCA is set by default in many software programs, such as SPSS
    and Minitab (IBM, 2021; Minitab, 2022). Of the 88 studies, 63 extracted PCs for
    analysis based on the Kaiser rule (eigenvalues >1) (Braeken, 2017), and 66 used
    varimax rotation. Seventy-nine studies associated the first component (PC1) or
    its equivalent in MCA with words and expressions related to the salinization process,
    including seawater intrusion, and five of these mentioned mixed salinization and
    anthropogenic influences (Table S2). Other expressions associated with PC1 were
    “natural processes”, “hardness”, “contamination sources”, and “dilution of groundwater”.
    On average, the variance of the first component of the 66 studies, with PC1 related
    to salinization, was 48 %. Variables with loadings >0.8 in PC1 were recorded for
    each study (Table S1). The most frequent variables in descending order were Cl−,
    Na+, electrical conductivity (EC), total dissolved solids (TDS), Mg2+, Ca2+, SO42−,
    K+, TH (total hardness), Br−, HCO3−, Sr2+, and salinity, which are typically involved
    in the salinization process (Jiao and Post, 2019). Two characteristics that may
    affect PCAs of coastal aquifers were identified: sample density per variable and
    the redundancy of variables. Table 2 shows that the sample density per variable
    of the studies had a median of 4. In the review, 17 out of 102 studies (14 out
    of 88 in PCA) used less than two samples per variable, and the most extreme study
    had a ratio of 0.75 (9 samples and 12 variables) (Kumar et al., 2020). Regarding
    the redundancy of variables, some have been identified as strongly correlated
    or highly linearly dependent on others in the form z = m·x + n·y + … + b (King
    and Jackson, 1999; Senawi et al., 2017). The variables salinity, TDS, and EC generally
    have very high correlations with each other and can be considered redundant. Moreover,
    TDS can also be considered redundant when all major ions are considered (e.g.,
    Celestino et al., 2018; Tiwari et al., 2019; Salem et al., 2021), because TDS
    can be understood as linear combination of these ions (sum). Similarly, TH can
    be interpreted as redundant (e.g., Gilabert-Alarcón et al., 2018; Sangadi et al.,
    2022), because it represents a linear combination of bivalent cations (Boyd et
    al., 2016). According to the above, 91 of the 102 studies used redundant variables
    (81 of 88 in PCA). To compare different methods of use, PCA was applied to the
    La Paz coastal aquifer database (Table S1). The correlation matrix gave the same
    weight to the variables and, considered all variables, excluding EC and TDS. Table
    3 shows the components and their loadings extracted based on the Kaiser rule (eigenvalues
    >1) and their varimax rotation when excluding EC and TDS. Fig. 6 shows a plot
    of the scores in the first two directions. PC1 had high loadings in EC, TDS, and
    major ions, the second had a good loading in NO3−, and the third component had
    moderate loadings in T, pH, and DO, which were associated with the salinization
    process, nitrification, and oxygen solubility change, respectively. The high affinity
    of PC1 with the major ions indicated the salinization process (the closer to −1
    or 1 the loading, the greater the affinity), nitrification based on the affinity
    of PC2 with NO3− variations; and oxygen solubility based on the affinity of PC3
    with T and DO, except with varimax rotation, in which pH loading was increased
    and T was reduced. Although the MCA method was applied in Hajji et al. (2020),
    this study was excluded from the comparison, since there were no defined categorical
    variables in the study case; however Section S2 provides documentation for its
    application. Table 3 shows the effects of variable redundancy on the PCA of La
    Paz. PC1 explained 62.8 % of the variance when all variables were considered,
    and EC and TDS could be considered redundant (R2 = 0.99). The variance of PC1
    decreased to 60 % when EC was removed from the analysis. In the third case, which
    did not consider EC or TDS, PC1 had a variance of 56.6 %. It should be noted that
    when considering TDS and EC, their loadings were 0.99 in PC1, indicating that
    the variance of the component was in the same direction as that of the variables.
    With the above, redundant variables artificially increased the apparent relevance
    of some processes and a significant loss of information did not occur when they
    were removed (Fig. 6). On the contrary, identifying and eliminating this class
    of variables increased the sample density per variable from 3.6 to 4.2. Regarding
    the application of the varimax rotation, the redistribution of the accumulated
    variance stands out, and it reduced the importance of the rotated PC1 and increased
    the variance in the other two. Fig. 6 shows the scores of the rotated PC1 and
    PC2, where the rotation of the data pattern to the new orthogonal basis was inferred.
    Table 3. Unrotated and varimax rotated factor loadings for the first three PCs
    with different variables in the La Paz database. Variable All Variables Without
    EC Without EC & TDS Without EC & TDS (varimax) PC1 PC2 PC3 PC1 PC2 PC3 PC1 PC2
    PC3 RPC1 RPC3 RPC2 T −0.18 −0.41 −0.62 −0.18 −0.41 −0.62 −0.19 −0.42 0.62 −0.03
    0.16 −0.75 pH −0.58 −0.28 0.52 −0.59 −0.26 0.52 −0.60 −0.24 −0.51 −0.40 −0.72
    0.00 DO −0.34 −0.56 0.61 −0.35 −0.56 0.61 −0.36 −0.54 −0.61 −0.05 −0.89 −0.08
    EC 0.99 −0.12 0.00 – – – – – – – – – Ca 0.92 −0.24 −0.13 0.91 −0.25 −0.13 0.91
    −0.27 0.12 0.92 0.23 −0.01 Mg 0.92 −0.20 −0.06 0.91 −0.22 −0.06 0.91 −0.24 0.04
    0.92 0.20 0.07 Na 0.89 0.10 0.18 0.89 0.08 0.18 0.89 0.07 −0.19 0.78 0.19 0.42
    K 0.82 −0.38 0.05 0.82 −0.4 0.05 0.82 −0.41 −0.07 0.92 −0.02 −0.01 HCO3 0.80 0.27
    0.16 0.80 0.25 0.16 0.80 0.24 −0.16 0.63 0.28 0.50 Cl 0.97 −0.19 −0.02 0.96 −0.21
    −0.02 0.96 −0.22 0.01 0.96 0.19 0.11 NO3 as N 0.47 0.72 0.20 0.48 0.70 0.2 0.49
    0.70 −0.19 0.16 0.42 0.75 SO4 0.88 0.02 0.14 0.88 0.00 0.14 0.88 −0.01 −0.15 0.81
    0.18 0.34 TDS 0.99 −0.06 0.04 0.99 −0.08 0.04 – – – – – – Variance 8.17 1.45 1.16
    7.20 1.43 1.16 6.22 1.42 1.16 5.31 1.80 1.70 % 63 % 11 % 9 % 60 % 12 % 10 % 57
    % 13 % 11 % 48 % 16 % 15 % Note: Factor loadings >0.6 are in bold. Download :
    Download high-res image (217KB) Download : Download full-size image Fig. 6. First
    two unrotated and varimax rotated direction scores for different numbers of variables
    in the La Paz database. 4.2.2. Hierarchical cluster analysis Hierarchical clustering
    (HCA) forms clusters by dividing data patterns using a divisive or agglomerative
    approach (Saxena et al., 2017). In the agglomerative approach, the first connections
    correspond to the closest pairs of objects based on Euclidean distance or other
    indicators. Subsequently, the initial groups are connected to the closest group
    based on their similarities through a linkage algorithm (e.g., complete-linkage
    or Ward''s-linkage), and the process is repeated until only one group remains
    (Strauss and von Maltitz, 2017; Székely and Rizzo, 2014). The results are presented
    in a dendrogram that shows the connection between the different group levels and
    the linkage distance regarding the samples (R-mode) or the variables (Q-mode).
    In general, for this and the other clustering methods, attributes are “normalized”
    (standardized) with functions such as the z-score to give all attributes appropriate
    and comparable importance (Bouguettaya et al., 2015). While this method can consider
    observations and variables at multiple levels of grouping, the disadvantage of
    HCA is that it is sensitive to noise and outliers (Saxena et al., 2017), although
    the most robust linkages (e.g., average and Ward''s) may help limit this effect
    (Bu et al., 2020). One application of HCA in hydrology is to depict correlation
    patterns among water samples, thus enabling a more rapid identification of the
    main hydrogeochemical processes than with the use of only descriptive statistics
    (Nogueira et al., 2019). Among the reviewed studies, 77 of 102 studies applied
    HCA in their analysis, 64 applied Q-mode, 25 applied R-mode, and 8 applied both
    Q- and R-mode. Of the 77 studies that applied HCA, 64 also applied PCA to interpret
    hydrogeochemical data as a complementary analysis, thus highlighting that HCA
    and PCA have a strong relationship. Studies that performed HCA (R-mode) showed
    similar variable associations of the hydrogeochemical processes obtained using
    the PCA method. As mentioned in Section 4.2.1, PCA was used in three studies to
    reduce the data dimensions before clustering through HCA (Table S2). Of the 60
    studies that applied the Q-mode, 45 related at least one cluster to the influence
    of seawater intrusion and one related at least one cluster to the influence of
    brackish/saltwater. Of the 25 studies that applied the R-mode, 20 related one
    variable cluster to seawater intrusion or other salinization sources. Ward''s-linkage
    was the preferred linkage algorithm in these studies. Of the 77 studies that applied
    HCA, 52 applied this linkage rule. Ward''s method is distinct from all other methods
    because it uses an analysis of variance approach to evaluate cluster distances
    (Sharma and Batra, 2019; Ward, 1963). Ward''s-linkage seems to perform significantly
    better than other clustering procedures based on empirical studies that compare
    the methods (Willett et al., 1998). Furthermore, three studies used complete linkage
    (Saxena et al., 2017), while the remaining did not specify a linkage method. According
    to the same trend, 56 studies established the distance criterion, in which the
    most used similarity measure was Euclidean distance in 54 studies. The other two
    distance criteria were Manhattan (Strauss and von Maltitz, 2017) and Pearson (Székely
    and Rizzo, 2014) (Table S2). The lack of information regarding the used linkage
    method and distance criterion can make it difficult to replicate and validate
    the results of the studies. As seen with PCA, TDS and EC can be removed from HCA
    clustering. When redundant, these variables give greater importance to a specific
    variance direction without adding new relevant information and removing them reduces
    the complexity of clustering (Fraiman et al., 2008; Mitra et al., 2002). To demonstrate
    this, Ward''s method of HCA with Euclidean distance was applied to the La Paz
    coastal aquifer database for the different sets of variables used in PCA, using
    the R script described in Section S3. Z-score standardization was used to assign
    the same weight to all variables, and four clusters were extracted. Fig. 7 shows
    that the dendrogram structure changed by a minor degree when EC or TDS were removed
    and the linkage distances were reduced. Clusters that did not consider EC or TDS
    were raised in the first two PCs in Fig. 8a to understand their relationship with
    the database. From the PCA, Cluster 1 (C1) had a minor salinization effect; C2
    and C4 had an intermediate effect, and C3 had the highest values in the PC1 direction.
    Regarding nitrification (PC2), the only cluster with higher values relative to
    others was C3. Fig. S2 shows the location of the sampling points indicating the
    cluster membership. Download : Download high-res image (675KB) Download : Download
    full-size image Fig. 7. Hierarchical clustering (HCA) dendrogram for different
    variables of the La Paz database. (a) All variables; (b) without electrical conductivity
    (EC); (c) without EC or total dissolved solids (TDS). Download : Download high-res
    image (328KB) Download : Download full-size image Fig. 8. Clustering without electrical
    conductivity (EC) or total dissolved solids (TDS) on the first component (PC1)
    vs. second component (PC2). (a) Hierarchical clustering (HCA); (b) k-means clustering;
    (c) fuzzy C-means; and (d) Self-organizing map (SOM) neural segmentation without
    EC or TDS. The PCA and HCA information, sample point location, and extended hydrogeochemical
    facies analysis of the groups in Section S3 indicates that C1 is associated with
    recharging groundwater, C2 is associated with seawater intrusion mixture, C3 is
    associated with terrestrial salinization, and C4 is associated with nitrate-polluted
    groundwater mixed with seawater intrusion. 4.2.3. K-means clustering K-means clustering
    uses a predefined number (K) of centroids to generate the best adjustment between
    these centroids and the input data through an iterative process (Saxena et al.,
    2017). In the first step, a few centroid points are randomly selected. Each data
    point is then assigned to the closest centroid. The next step is to update the
    centroids by calculating the central points of these newly formed clusters using
    the Euclidean distance. Subsequently, the last two steps are repeated until no
    object changes the cluster assignment (Bouguettaya et al., 2015). The results
    may vary because of the initial random location of the centroids. The algorithm
    can then be run multiple times to choose the best result based on the minimum
    value of the total sum of squares (TSS). The predefined number (K) of cluster
    centroids depends on the modeler criteria, although there are heuristic rules
    to infer the optimal number. The elbow criteria usually repeats the process by
    increasing the number of centroids, and optimal clusters are inferred by selecting
    the elbow of the curve between the distortion measurement and the number of centroids
    (Yuan and Yang, 2019). Similar to HCA, the disadvantage of this method is that
    it is sensitive to noise and outliers (Saxena et al., 2017). The fuzzy C-means
    (FCM) method is a modified form of the K-means method that uses fuzzy logic theory,
    in which objects can be partially assigned to multiple clusters (Mohammadrezapour
    et al., 2020). The proportion of membership to each cluster depends on the closeness
    of the data object to the centroids, and a fuzzy matrix describes this characteristic
    with “n” rows (objects) and “c” columns (clusters) (Izakian and Abraham, 2011).
    This partial assignment increases the expressiveness of the clustering analysis,
    thereby presenting a more comprehensive view of the relationships in the data
    (Stetco et al., 2015). To perform the segmentation, the fuzziness must be indicated
    through the fuzzy partition matrix exponent “m”, with m >1 (Saxena et al., 2017).
    Similar to K-means, centroids are located randomly and the best combination can
    be chosen by selecting the final TSS minimum value between multiple runs. Despite
    improvements in the conventional partitioning method, FCM is still sensitive to
    noise and outliers (Saxena et al., 2017). In hydrology, K-means and FCM have been
    used to depict associations between water samples and infer sources, which is
    similar to HCA (Mohammadrezapour et al., 2020). This review showed that K-means
    was used in two studies to identify groups for hydrogeochemical analysis (Table
    S2). In these studies, the analysis of the groups indicated the association of
    at least one group with the influence of seawater intrusion. The interpretation
    of the K-means results was used with complementary techniques, such as clustering
    PCA results by Celestino et al. (2018) and segmentation SOM results by Yin et
    al. (2021). FCM was applied by Güler et al. (2012), which enabled the identification
    of a cluster associated with seawater intrusion. Additionally, this study allowed
    the identification of transitional zones between the clusters through the georeferenced
    graphical representation of the fuzzy transitions. K-means was applied to the
    La Paz coastal aquifer database for different variables to test the method and
    to determine the influence of redundant variables. Z-score standardization was
    used to assign the same weight to all the variables, and four clusters were extracted.
    The algorithm was executed 100 times using the R script described in Section S3,
    and the result with the lowest TSS was selected. The sampling cluster assignation
    had the same results for all three cases: all variables were considered, EC was
    omitted, and EC and TDS were omitted. A fewer number redundant variables corresponded
    to a lower TSS (i.e., 598, 552, and 506 for the three cases, respectively). This
    highlights the redundancy of TDS and EC with other chemical parameters, which
    implies that they can be omitted. Clusters were raised in the first two main components
    (Fig. 8b), which generally preserves the same pattern as that observed in the
    HCA clustering results (Fig. 8a) but generates a different pattern in the three
    sample classifications (Lp-21, Lp-20, and Lp-43). Fig. S7 shows the location of
    the sampling points indicating the cluster membership. As an example of the fuzzy
    concept, FCM was applied to the La Paz coastal aquifer database without considering
    TDS or EC. Z-score standardization, four centroid clusters with 100 runs, and
    a fuzzy partition matrix exponent of m = 1.3 were set using the R script described
    in Section S4. The result with the lowest TSS was 502.17, and the fuzzy matrix
    was extracted as shown in Section S4. Fig. 8C shows the FCM cluster pattern on
    the two first PCs, in which samples that have been assigned with a proportion
    <90 % to a single cluster membership are marked as fuzzy. For instance, 77 % of
    the Lp-21 sample belongs to C2, 22 % belongs to C1, and <1 % is assigned between
    C3 and C4; 81 % of the Lp-30 sample belongs to C3, 17 % belongs to C2, and <2
    % is assigned between C1 and C4; and 76 % of Lp-47 belongs to C1, 20 % belongs
    to C2, and <4 % is assigned between C3 and C4. Fig. S8 shows the location of sampling
    points that indicate the fuzzy cluster membership. 4.2.4. Self-organizing map
    The SOM or Kohonen map is a specific type of ANN for visualizing and clustering
    high-dimensional data. It converts the non-linear statistical relationships between
    high-dimensional data into simple geometric relationships projected on a low-dimensional
    display, usually a regular two-dimensional grid of neurons (Kohonen, 2001; Wehrens
    and Kruisselbrink, 2018). The SOM neural network consists of an input and output
    layer (Kohonen layers). The input layer contains as many nodes as variables in
    the data set, whereas the output layer neurons are connected to every neuron from
    the input layer through adjustable weights or network parameters that form the
    weight vectors. The weight vectors constrain the reproduction of the input objects
    through the output layer in an ordered but not regular mesh that preserves the
    data topology (Kalteh et al., 2008; Wehrens and Kruisselbrink, 2018). After training,
    the input objects are assigned to the output layer neurons, and some neurons may
    not contain objects, thus increasing the difficulty of interpreting the SOM map.
    Reports have suggested that the map size should be varied to avoid as many empty
    neurons as possible since these do not represent the data pattern (Céréghino and
    Park, 2009; Li et al., 2018). The first and most important step in applying the
    SOM method is data gathering and standardization to prevent variables from having
    a higher impact than others, such as in clustering techniques. The second step
    consists of defining several neurons associated with the weight vectors; typically,
    the heuristic rule of is used, where m is the number of samples and w is the number
    of output layer neurons (Céréghino and Park, 2009; Yin et al., 2021). The initial
    values of the weight vectors of the neurons are established randomly. The next
    step is training, in which the weight vectors simultaneoulsly update their relative
    values for one input pattern and a neighborhood function. The neuron with the
    closest match to the presented input pattern is called the winner neuron or best-matching
    unit, and the next input pattern is used as the new target. It is recommended
    that the number of iterations be at least 500 times the number of neurons in the
    output layer. The last step is information extraction and visualization. Typically,
    a 2D projection of the final output neural mesh is used (Kalteh et al., 2008).
    From the perspective of water research, a trained SOM map is a valuable tool for
    visualizing the data and obtaining insights into the system under investigation,
    such as satellite imagery data classification, rainfall-runoff analysis, and water
    quality associations (Kalteh et al., 2008; Olkowska et al., 2014). This review
    found two studies that combined SOM with K-means and HCA clustering to visualize
    and cluster hydrogeochemical data (Nguyen et al., 2015). This visualization highlighted
    the patterns of each variable''s influence in 2D neuron maps and showed the sample
    clusters obtained in the SOM map projection. The combined methodologies permitted
    a better interpretation of the hydrogeochemical processes and identified at least
    one cluster associated with seawater intrusion. SOM was applied to the La Paz
    database. Z-score standardization was used to assign the same weight to all variables,
    and 35 neurons ( ) with an array of five columns and seven rows were used, while
    18,000 (35 × 500) iterations were set. The R script and additional parameters
    are described in Section S5. Fig. 9 shows the results of the final representative
    weight vectors and their neuron locations. In general, the patterns of the three
    analyses were very similar. In the upper right part, there were samples with the
    highest values of major elements, TDS and EC; in the bottom part, there were the
    samples with the highest DO and pH values; and in the middle left part, there
    were the samples with the lowest values of all variables. Neurons 26 and 31 showed
    the highest nitrate values, and EC and TDS were redundant in the analysis because
    the weight vectors of the major ions had the same pattern as EC and TDS, indicating
    that there was no new information when these variables were considered. Download
    : Download high-res image (641KB) Download : Download full-size image Fig. 9.
    Self-organizing map (SOM) grid for different numbers of variables of the La Paz
    database. (a) All variables; (b) without electrical conductivity (EC); (c) without
    EC or total dissolved solids (TDS). To provide a more robust interpretation of
    the results, HCA clustering was used with the neuron weight vector results when
    excluding EC and TDS (Ward''s method, Euclidian distance, and 5 clusters). The
    SOM grid map segmentation with clusters is presented in Fig. 10 with the mean
    results of TDS, NO3-N, and DO on the SOM grid. The neurons associated with the
    samples and neuron clusters are shown in Fig. 8c, and Fig. S9 shows the sampling
    point location, indicating the SOM code cluster membership. The clustering result
    and its interpretation are similar to those of HCA, K-means, and FCM. In contrast,
    SOM shows the internal structure of the groups and their relationship to topology.
    It should also be noted that five clusters are required to arrive at a segmentation
    similar to the other methods. When four clusters with the indicated SOM features
    were set, C2 and C3 belonged to the same group and Lp-47 sample formed a single
    cluster. Download : Download high-res image (1MB) Download : Download full-size
    image Fig. 10. Self-organizing map (SOM) grid of La Paz database: (a) Weight vector
    hierarchical clustering (HCA); (b) Total dissolved solids (TDS) mean value projections
    in the SOM grid; (c) HCO3−-N mean value projections in the SOM grid; (d) Dissolved
    oxygen (DO) mean value projections in SOM grid. 4.3. Seawater intrusion pattern
    recognition The reviewed unsupervised learning techniques were used to conduct
    exploratory analyses of the hydrogeochemical processes governing coastal groundwater
    quality. The PCA, MCA, and HCA (R-mode) techniques were used to associate hydrogeochemical
    processes based on the similarity and variance of the data variables. Grouping
    and segmentation techniques, such as SOM, HCA (Q-mode), K-means, and FCM, made
    it possible to assemble water samples with similar characteristics, mainly hydrogeochemical
    facies, which were associated with different sources, such as salinization from
    evaporation, seawater intrusion, or anthropogenic impacts, based on the support
    of different discrimination criteria. However, owing to their unsupervised nature,
    these techniques do not allow the clusters to be directly associated with the
    sources. It is undeniable that simplification of the databases and pattern recognition
    facilitated the interpretation of hydrogeological processes in each case study.
    Monitoring major ions as chemical tracers of environmental processes is of enormous
    importance because they account for 95 % of TDS (Poeter et al., 2020). In general,
    PCA also highlighted the relevance of the variance of these constituents in PC1.
    On average, the salinization process was the most relevant and explained 48 %
    of the data variance in the studies. Although it could be argued that there is
    a bias because major ions are always considered for sampling analysis, 22 studies
    with a PC1 average variance of 43 % considered at least 15 different variables,
    which is twice the number of major ions. Other variables that were highly relevant
    in PC1 when associated with salinization processes were F− (Askri et al., 2022),
    Fe (Awaleh et al., 2018; Galazoulas and Petalas, 2014; Kim et al., 2005), chemical
    oxygen demand (Wang et al., 2022), Sr (Hyung et al., 2021), Mn (Hyung et al.,
    2021), B (Güner et al., 2021), Se (Papazotos et al., 2020), Br (Sae-Ju et al.,
    2020), Cr (Galazoulas and Petalas, 2014), NH4+ (Salem et al., 2021), total viable
    count (Gokul et al., 2019), Li (Souid et al., 2018), As (Houssein et al., 2017),
    sodium adsorption ratio (Taşana et al., 2022), and seawater intrusion generalized
    index (Alameddine and Fadel, 2021). Table S2 shows other studies in which these
    variables were relevant to PC1. Because the greatest variance is in the direction
    of salinization, it can be understood that this process partially biases the formed
    clusters. For the case of La Paz, it can be seen in Fig. 8 that data clusters
    are partitioned in the directions of the first two principal components, although
    separation is more predominant by PC1. Although clusters appear to be effective,
    it should be noted that clusters methods are sensitive to “outliers” or “anomalies”
    (Saxena et al., 2017), such as Lp-47 (water recharge), Lp-40 (high salinity),
    and Lp-31 (high nitrate concentration) (Fig. 8a). These outlier observations are
    of great interest and should be identified because they can affect the interpretation
    of the related clusters. HCA and SOM present features against this because it
    is possible to identify the outliers in the dendrogram and SOM segmentation pattern,
    respectively. Another characteristic for differentiating groundwater groups is
    the optimal number of clusters. An average of 3.7 clusters was used in the studies
    that relate at least one group to seawater intrusion influence, and 91 % of these
    studies did not use a criterion for selecting the optimal number of clusters.
    As Pacheco Castro et al. (2018) stated, a hydrogeological sense should be used
    to select the final number of clusters, and the number should be increased until
    significance is observed. The most commonly used criteria for identifying seawater
    intrusion in the cluster results are associated with the chemical characteristics
    of seawater and its interaction with the aquifer. Associations were sought based
    on samples similar to seawater, such as those with high salinity values, high
    chlorine concentrations, and Na+-Cl− facies (Jiao and Post, 2019). The interaction
    between seawater and the solid aquifer matrix is also an indicator because when
    the sea wedge advances (seawater intrusion), reverse cation exchange may occur,
    in which Na+ is exchanged for Ca2+ in the signature of groundwater; however, when
    the wedge recedes (freshening), direct cation exchange occurs, with Ca+ exchanged
    for Na+ (Giménez-Forcada, 2010). These evolution trends are understood from different
    diagrams that have been developed over the years, such as Piper (Moreno Merino
    et al., 2021), Durov (Chadha, 1999), Stiff (Lee, 1998), and HFE-D (Giménez-Forcada,
    2010). Cation exchange in water samples can also be identified by comparing the
    excess and deficit of ions in the theoretical mixture of recharge water and seawater
    (fraction of seawater) through end-members (Nogueira et al., 2019; Papazotos et
    al., 2020). These discrimination techniques based on major ions appear to be effective
    in places where seawater intrusion is the main source of salinization. However,
    under arid and hyper-arid conditions, it is difficult to differentiate the sources
    of high salinization values with similar signatures (Sabarathinam et al., 2021).
    Apart from facies and tracers, the salt origin can be inferred by comparing the
    chemical and isotopic concentration ratios of groundwater samples and seawater,
    such as Na+/Cl−, Ca2+/Cl−, Mg2+/Ca2+, Ca2+/Mg2+, Cl−/HCO3−, (Jiao and Post, 2019;
    Lee and Song, 2007), Cl−/Br− (Bertrand et al., 2022), Cl−/Si (Sabarathinam et
    al., 2021), δ34S(SO42−) (Hyung et al., 2021; Kim et al., 2019), δ13C(Dissolved
    Inorganic Carbon), δ11B, B/Cl−, and 87Sr/ 86Sr (Awaleh et al., 2018). In addition,
    a more composited relationship based on major ions has been used to infer the
    influence of salinization intrusion, such as the Simpson ratio for evaluating
    the salinization degree and the chloro-alkaline index (CAI) for evaluating the
    degree of ion exchange (Ha et al., 2022; Wang et al., 2022). Depending on the
    major ions, the results obtained from the CAI and Simpson index reflect the results
    of different salinization sources, not only seawater intrusion. Overall, most
    of the reviewed studies used the Piper diagram and/or major ion relations as discriminant
    techniques, and only four studies included major ion ratios as inputs in the multivariate
    analysis (Table S2). In contrast, 20 articles used isotopes (mostly δ2H and δ18O)
    for analysis, of which only five included isotopes as inputs for multivariate
    analysis (only δ2H and δ18O) (Table S2). However, these two variables are related
    to water sources, which can be seawater, among others, and not directly related
    to salinization. The lithology of the study area is also a discriminating factor
    for salinization identification. The saturation indices of minerals based on thermodynamic
    and geochemical mass balances help to characterize groundwater influenced by different
    sources of mineralization, showing whether water is under- or oversaturated with
    respect to given minerals, such as halite, gypsum, calcite, and dolomite (Parkhurst
    and Appelo, 2013). Generally, the zone affected by seawater intrusion is undersaturated
    with respect to halite (Güler et al., 2012; Sabarathinam et al., 2021). Less complex
    techniques to compare the groundwater interaction with the solid matrix are the
    Gibbs diagram (Marandi and Shand, 2018) and Na-normalized diagrams (Gaillardet
    et al., 1999). The first compares water samples to the pattern of world water
    resources, thus indicating the influence of evaporites (along with seawater intrusion)
    and rock interactions with recharge water, while the second associates the water
    samples with different registered carbonates, silicates, and evaporite rock end
    members. In these three discriminant techniques, the influence of seawater intrusion
    can be confused with that of evaporation and evaporite mineral dissolution. Thus,
    the results should be compared with the lithologies of the study area to identify
    associations and discrepancies. Table S2 lists the studies that have used these
    techniques. Hydraulic characteristics are also important for interpreting hydrogeochemical
    data. Knowledge of flows, hydraulic gradients, and sample grid spatial configuration
    helps to identify the mineralization process to which water is subjected along
    flow lines. For instance, proximity to the coast is associated with the influence
    of seawater intrusion, such as in Hajji et al. (2020), El Yaouti et al. (2009),
    and Yik et al. (2012). In addition, when inland salinity is unclear, the hydraulic
    gradient, sea-level rise, and groundwater overexploitation may suggest associations
    with seawater intrusion extension (Ferguson and Gleeson, 2012). For instance,
    while the Red River delta aquifer (hydraulic gradients <10−4) in Vietnam has a
    seawater extension of hundreds of kilometers and salinization deposits from the
    Holocene seawater intrusion (Larsen et al., 2017), the Caplina/Concordia aquifer
    system (hydraulic gradients of the order of 10−2) in Peru/Chile has a seawater
    intrusion extension of approximately 10 km, which is mainly due to overexploitation
    (Narvaez-Montoya et al., 2022). This review identified four studies that used
    hydraulic conditions (distance to the coast, field slope, and hydraulic head)
    as inputs for unsupervised techniques (Table S2). It is necessary to continue
    including this type of variable in this class of studies since they present a
    meaningful value for the associations and interpretations of coastal hydrogeology.
    Even with an understanding of the study area, data, and unsupervised applied techniques,
    it is difficult to distinguish seawater intrusion from other phenomena with total
    confidence. Mechanisms that involve salty water of different origins from the
    sea or fossil seawater stored inside the aquifer can result in similar geochemical
    signatures, such as high concentrations of ions and alteration of facies through
    cation exchange. Therefore, data can be misinterpreted. In most studies, it is
    not assured that the water samples originate from seawater intrusion; rather,
    the samples are usually associated with this source. Apart from the environmental
    tracer and general hydraulic feature analysis, it is necessary to implement complementary
    studies, such as geophysical methods and numerical groundwater models, to understand
    this phenomenon. In this review, only eight case studies of this type were identified
    (Table S2). 4.4. Recommendations for unsupervised hydrogeochemistry data analysis
    Several aspects were identified that might be useful for researchers and professionals
    to improve the analysis using reviewed unsupervised techniques. Except for coastal
    hydrogeology, most of the recommendations to be adopted for water research are
    based on data analysis. For the preprocessing of raw data, TDS, EC, and TH can
    be considered redundant variables when used together and when major ions are considered,
    such as in the Laz Paz analysis example. The exclusion of these variables helps
    limit the complexity of the analysis by eliminating the multiplicity of the same
    effect without losing important information. However, the variables must be redundant;
    for instance, TDS and EC were not considered redundant in the study of Zhu et
    al. (2020) because their correlation coefficient was 0.73. To detect undesirable
    redundancies, tools for computing the correlation matrix and detecting linear
    dependencies are included in Section S7. Similarly, increasing the sample density
    per variable can improve the significance of the results of multivariate analysis.
    Multiple rules of thumb have been generated to designate the minimum value of
    this relationship, however, the values differ considerably (2:1 to 30:1) because
    these studies applied different multivariate techniques and different methodologies
    (Knapp and Campbell-Heider, 1989). Second, data should be standardized to assign
    the same weight to all meaningful variables. Most studies that performed standardization
    used the z-score, which consists of centering the variables with a mean of zero,
    scaling to unit variance, and retaining the magnitude proportions. Other methods
    for standardizing the variables can be found in Miuigan and Cooper (1988). Note
    that PCA does not require standardization to assign equal importance to the variables
    if the correlation matrix (by default) is used, because the raw data correlation
    matrix is equal to the standardized data correlation matrix (Jolliffe and Cadima,
    2016). Moreover, using logarithm transformations for preprocessing is not recommended
    since the reviewed techniques are exploratory and do not require distributional
    assumptions (Jolliffe, 2002; O''Hara and Kotze, 2010). Most environmental data,
    including geochemistry data, follow a skewed positive distribution (Andersson,
    2021; Govett et al., 1975). Log-transforming search strategies are usually used
    for normal distributions, although such transformations are not necessary, such
    as in Pacheco Castro et al. (2018). The reason for this is paradigmatic and unclear,
    although the transformation implies that the mechanisms are multiplicative on
    the scale of the raw data (Govett et al., 1975; O''Hara and Kotze, 2010), and
    which distorts the data''s internal relationships. Of the 102 studies, 21 transformed
    their data (20 %). Reproducibility of the results and further exploration of related
    hypotheses require access to raw data (Alsheikh-Ali et al., 2011). Although journals
    encourage the sharing of data and other useful materials related to research,
    such sharing does not occur in many cases. Only 39 of the 102 reviewed studies
    (38 %) provided the raw data for their analysis. These relevant data can be placed
    in the supporting material of studies, which generally permits multiple formats;
    moreover, data can be both shared and protected (through DOI''s) in ad-hoc repositories,
    such as Zenodo (Sicilia et al., 2017). Regarding the accessibility of unsupervised
    technique tools, there is no major problem in accessing different software, such
    as Minitab, SPSS, Stata/SE, and STATISTICA. However, the tools must be made available
    to the general public for reproducibility and validation. Furthermore, given that
    this research is applied to water resources, which are associated with the human
    right to access water and UN-Sustainable Development Goal 6 (clean water and sanitation),
    it is necessary to socialize raw data, methods, and results as best as possible.
    This work highlights the importance of sharing data and using open source software
    to validate, reproduce, and replicate the research. The techniques applied to
    the La Paz database were executed using open-source R Studio environment. R scripts
    and documentation for discriminant techniques, such as Piper, are provided in
    the Supplementary material. 4.5. Research opportunities Most studies have used
    several techniques independently to explore and interpret hydrogeochemical data.
    The integration of at least two techniques was identified in a few studies that
    integrated HCA and K-means with prior dimension reduction via PCA (e.g., Aris
    et al., 2012; Celestino et al., 2018; Hasan et al., 2021; Osiakwan et al., 2021)
    and that combined HCA or K-means with SOM to obtain clusters over the data topology
    (e.g., Nguyen et al., 2015; Yin et al., 2021). It is possible to continue integrating
    these techniques with other diagrams, thus creating new analysis strategies. Moreover,
    although unsupervised learning has a bias component because the modeler is the
    one who gives meaning to the results, the new techniques and procedures must be
    more objective and consider elements of the data, such as the variance and amount
    of data. One problem with interpreting cluster data is that when considering all
    variables, all processes are integrated; therefore, the mechanisms featuring the
    highest variance can overshadow the others. To solve this problem, Mora et al.
    (2021) used an HCA double clustering approach, whereby the HCA (R-mode) was first
    executed on the data, and each determined set of variable groups was associated
    with a hydrogeochemical process, such as salinization. Sample clusters were then
    formed from each group of variables (process) by applying HCA (R-mode) to the
    data. In this way, the samples were clustered according to an identified process,
    thus identifying the level of influence and associating different sources. One
    way to improve the strategy of sample clustering using a different process is
    to use PCA instead of HCA (R-mode) to determine the variables and infer the general
    process in the first stage. In this way, the variables are not only associated
    with a process, but clarity is also obtained based on the importance of the processes
    that lead to data variance. For instance, three relevant processes were identified
    in the La Paz case, and their variance contributions were calculated (salinization
    accounted for 62.8 % of the total variance, nitrate contamination accounted for
    6 %, and oxygen solubility change accounted for 5.6 %). Thus, three sets of HCAs
    (Q-mode) clusters can be generated with the most relevant variables of each component
    (highest loading). Exploring coastal hydrogeochemical data with alternatives to
    the reviewed techniques is possible. For instance, independent component analysis
    (ICA), a DRM, can be used instead of or parallel to traditional PCA. ICA extracts
    independent sources (directions) by exploring statistically independent patterns
    from the observations of an unknown linear mixture. This technique is more powerful
    than others based on uncorrelated components, such as PCA (Calabrese, 2019; Kano
    et al., 2004). Another DRM that can be used to reveal the global structure of
    hydrogeological datasets and is not based on linear relations but rather on probabilistic
    distributions, is T-stochastic neighbor embedding. This technique maximizes the
    relationship between the closest observations and minimizes the influence of the
    most distant observations (Ayesha et al., 2020). For novel clustering applications
    in coastal aquifers, model-based clustering can associate observations to multiple
    clusters since this method creates groups based on a mixture of component models
    (Fürnkranz et al., 2011); and density-based clustering can create clusters based
    on contiguous dense regions and identifying and eliminating the influence of “anomalies”
    in the data (Hahsler et al., 2019). Another cluster that can avoid the large influence
    of anomalies is K-medoids, in which an actual point (medoid) is used to represent
    the cluster center rather than the mean point as the center of a cluster (k-means)
    (Mannor et al., 2011). Another methodology that can be used to detect anomalies
    is insolation forest (Lesouple et al., 2021). Although the previously detailed
    methods may constitute the recognition pattern methodologies with multiple applications,
    cases with more complicated features use the ANN. SOM has been extensively used
    to identify internal relationships in hydrogeochemistry. However, other ANN present
    good alternatives to the Kohonen map. Adaptive resonance theory 2 is an unsupervised
    network that classifies samples based on their memory,which makes it possible
    to include new samples after training, classify existing clusters, or create new
    ones (Fan et al., 2008). Moreover, gas neural networks can be used to preserve
    data topology, such as SOM, but avoids empty neurons (Du, 2010). Another neural
    network that can be applied to reduce dimensions and extract the most relevant
    information from a database is an autoencoders (Fdez-Ortiz de Vallejuelo et al.,
    2011). In addition, graph neural networks can represent database interdependencies
    and non-linear relationships (Wu et al., 2021). Delimiting the seawater intrusion
    phenomenon as much as possible is of great importance because a misinterpretation
    can lead to incorrect decision-making regarding the management of the aquifer.
    As indicated in Section 4.3, hydrogeochemical and hydraulic variables could constitute
    relevant environmental gradients in the salinization process, although their use
    is still limited. It is necessary to continue advancing in the use of these variables
    and understanding their significance for seawater identification. Other variables
    that could be used and related to seawater intrusion are those associated with
    microplastics and stygofauna (groundwater fauna) (Li et al., 2021; Shapouri et
    al., 2016). On the other hand, the variables used in water research studies are
    a mixture of compositional data, which are part of a whole (e.g., chemical compounds)
    and non-compositional data (e.g., physical variables) (Herms et al., 2021). Generally,
    the compositional nature of some variables is analyzed using composite plots such
    as the Piper diagram (Section 2.1) after applying unsupervised techniques. The
    study of Boente et al. (2018) stated that applying the compositional data analysis
    (CoDa) approach for a complementary multivariate analysis could enable the exploration
    of relative enrichment spots and evaluation enrichment trends, thus complementing
    the results when the compositional nature is not considered. 5. Conclusions This
    work reviews how unsupervised learning has supported seawater intrusion pattern
    recognition in coastal aquifers worldwide over the last 22 years. PCA, the most
    frequently used DRM, enabled the identification of environmental gradients, among
    which the most relevant was associated with salinization and presented an average
    explained variance of 48 %. Meanwhile, HCA, K-means, FCM, and SOM facilitated
    the segmentation of samples into clusters, which were subsequently assigned to
    hydrochemical impacts and sources, thus delineating seawater intrusion. The application
    of the reviewed techniques to the La Paz case study enabled the visualization
    and comparison of their performances. It was shown that redundant variables, such
    as TH, EC, and TDS, do not provide new information and further complicate the
    analysis. On the other hand, the clustering methods and SOM applications did not
    show relevant changes in cluster patterns. However, HCA and SOM present advantages
    for outlier identification, while FCM represents transitional zones because it
    can assign samples to multiple clusters. Although the application of these methods
    has supported the identification of seawater intrusion, new techniques with greater
    precision for differentiating sources must be adopted. In addition to advancing
    pattern recognition techniques, the need to complement studies with other approaches,
    such as flow models and geophysical methods, was shown. By collecting information
    of a different nature, the phenomena of seawater intrusion can be better delimited
    spatially and temporally, which enables appropriate management. Furthermore, this
    review supports the idea that both journals and authors are responsible for uploading
    the necessary information to reproduce and validate studies. In addition to ensuring
    that access to information makes the studies reproducible, it also favors the
    socialization of information of general interest for water resources management.
    The following are the supplementary data related to this article. Download : Download
    Comma Separated Value file (4KB) Table S1. Location (UTM), depth to water (m)
    and physicochemical properties of sampled well water (all data is expressed in
    mg/l, except for pH (-), and temperature (°C). Download : Download spreadsheet
    (264KB) Table S2. Detailed analysis of selected 199 scientific articles for this
    review. Download : Download Word document (2MB) Supplementary material for section
    S1 to section S6 CRediT authorship contribution statement Herewith we state that
    all authors participated in the development of the manuscript. In the following
    an accurate and detailed description of their diverse contributions to the work:
    Christian Narvaez-Montoya: Initial idea and conceptualization, Data curation,
    Data analysis, Investigation, Writing-Original draft preparation, Visualization.
    Jürgen Mahlknecht: Supervision, Funding acquisition, Project administration, Reviewing
    and editing. Juan Antonio Torres-Martínez: Validation, Reviewing and editing.
    Abrahan Mora: Validation, Reviewing and editing. Guillaume Bertrand: Validation,
    Reviewing and editing. Declaration of competing interest The authors state that
    the submission of the manuscript implies that the work described has not been
    published previously, that it is not under consideration for publication elsewhere,
    that its publication is approved by all authors and tacitly or explicitly by the
    responsible authorities where the work was carried out, and that, if accepted,
    it will not be published elsewhere in the same form, in English or in any other
    language, including electronically without the written consent of the copyright
    holder. Acknowledgments We gratefully thank Consejo Nacional de Ciencia y Tecnología
    (CONACyT) (CVU: 1014283) and Tecnologico de Monterrey for providing scholarship
    and tuition to the lead author of the Ph.D. degree program. Symbols for the graphical
    abstract were obtained from the Integration and Application Network of the University
    of Maryland Center for Environmental Science (ian.umces.edu/symbols/). Data availability
    Data will be made available on request. References Abiodun et al., 2019 O.I. Abiodun,
    M.U. Kiru, A. Jantan, A.E. Omolara, K.V. Dada, A.M. Umar, et al. Comprehensive
    review of artificial neural network applications to pattern recognition IEEE Access,
    7 (2019), pp. 158820-158846, 10.1109/ACCESS.2019.2945545 View in ScopusGoogle
    Scholar Abu-alnaeem et al., 2018 M.F. Abu-alnaeem, I. Yusoff, T.F. Ng, Y. Alias,
    M. Raksmey Assessment of groundwater salinity and quality in Gaza coastal aquifer,
    Gaza Strip, Palestine: an integrated statistical, geostatistical and hydrogeochemical
    approaches study Sci. Total Environ., 615 (2018), pp. 972-989, 10.1016/j.scitotenv.2017.09.320
    View PDFView articleView in ScopusGoogle Scholar Alameddine and Fadel, 2021 G.R.I.
    Alameddine, M.El. Fadel Management of saltwater intrusion in data - scarce coastal
    aquifers: impacts of seasonality, water deficit, and land use Water Resour. Manag.
    (2021), pp. 5139-5153, 10.1007/s11269-021-02991-4 Google Scholar Alfarrah and
    Walraevens, 2018 N. Alfarrah, K. Walraevens Groundwater overexploitation and seawater
    intrusion in coastal areas of arid and semi-arid regions Water, 10 (2) (2018),
    p. 143, 10.3390/w10020143 View in ScopusGoogle Scholar Alsheikh-Ali et al., 2011
    A.A. Alsheikh-Ali, W. Qureshi, M.H. Al-Mallah, J.P.A. Ioannidis Public availability
    of published research data in high-impact journals PLoS ONE, 6 (9) (2011), Article
    e24357, 10.1371/journal.pone.0024357 View in ScopusGoogle Scholar Amanambu et
    al., 2020 A.C. Amanambu, O.A. Obarein, J. Mossa, L. Li, S.S. Ayeni, O. Balogun,
    et al. Groundwater system and climate change: present status and future considerations
    J. Hydrol., 589 (December 2019) (2020), Article 125163, 10.1016/j.jhydrol.2020.125163
    View PDFView articleView in ScopusGoogle Scholar Andersson, 2021 A. Andersson
    Mechanisms for log normal concentration distributions in the environment Sci.
    Rep., 11 (1) (2021), p. 16418, 10.1038/s41598-021-96010-6 View in ScopusGoogle
    Scholar Aris et al., 2012 A.Z. Aris, S.M. Praveena, M.H. Abdullah, M. Radojevic
    Statistical approaches and hydrochemical modelling of groundwater system in a
    small tropical island J. Hydroinf., 14 (1) (2012), pp. 206-220, 10.2166/hydro.2011.072
    View in ScopusGoogle Scholar Askri et al., 2022 B. Askri, A.T. Ahmed, R. Bouhlila
    Origins and processes of groundwater salinisation in Barka coastal aquifer, Sultanate
    of Oman Phys.Chem.Earth Parts A/B/C, 126 (2022), Article 103116, 10.1016/j.pce.2022.103116
    View PDFView articleView in ScopusGoogle Scholar Audigier et al., 2017 V. Audigier,
    F. Husson, J. Josse MIMCA: multiple imputation for categorical variables with
    multiple correspondence analysis Stat. Comput., 27 (2) (2017), pp. 501-518, 10.1007/s11222-016-9635-4
    View in ScopusGoogle Scholar Awaleh et al., 2018 M.O. Awaleh, T. Boschetti, Y.D.
    Soubaneh, Y. Kim, P. Baudron, A.D. Kawalieh, et al. Geochemical, multi-isotopic
    studies and geothermal potential evaluation of the complex Djibouti volcanic aquifer
    (republic of Djibouti) Appl. Geochem., 97 (August) (2018), pp. 301-321, 10.1016/j.apgeochem.2018.07.019
    View PDFView articleView in ScopusGoogle Scholar Ayesha et al., 2020 S. Ayesha,
    M.K. Hanif, R. Talib Overview and comparative study of dimensionality reduction
    techniques for high dimensional data Inform.Fusion, 59 (January) (2020), pp. 44-58,
    10.1016/j.inffus.2020.01.005 View PDFView articleView in ScopusGoogle Scholar
    Berry et al., 2020 M.W. Berry, M. Azlinah, B. Wah Yap Supervised and Unsupervised
    Learning for Data Science Springer Nature Switzerland, Switzerland (2020), 10.1007/978-3-030-22475-2
    Google Scholar Bertrand et al., 2022 G. Bertrand, E. Petelet-Giraud, L. Cary,
    R. Hirata, S. Montenegro, A. Paiva, et al. Delineating groundwater contamination
    risks in southern coastal metropoles through implementation of geochemical and
    socio-environmental data in decision-tree and geographical information system
    Water Res., 209 (2022), Article 117877, 10.1016/j.watres.2021.117877 View PDFView
    articleView in ScopusGoogle Scholar Björklund, 2019 M. Björklund Be careful with
    your principal components Evolution, 73 (10) (2019), pp. 2151-2158, 10.1111/evo.13835
    View in ScopusGoogle Scholar Boente et al., 2018 C. Boente, M.T.D. Albuquerque,
    A. Fernández-Braña, S. Gerassis, C. Sierra, J.R. Gallego Combining raw and compositional
    data to determine the spatial patterns of potentially toxic elements in soils
    Sci. Total Environ., 631–632 (2018), pp. 1117-1126, 10.1016/j.scitotenv.2018.03.048
    View PDFView articleView in ScopusGoogle Scholar Bouguettaya et al., 2015 A. Bouguettaya,
    Q. Yu, X. Liu, X. Zhou, A. Song Efficient agglomerative hierarchical clustering
    Expert Syst. Appl., 42 (5) (2015), pp. 2785-2797, 10.1016/j.eswa.2014.09.054 View
    PDFView articleView in ScopusGoogle Scholar Boyd et al., 2016 C.E. Boyd, C.S.
    Tucker, B. Somridhivej Alkalinity and hardness: critical but elusive concepts
    in aquaculture J. World Aquacult. Soc., 47 (1) (2016), pp. 6-41, 10.1111/jwas.12241
    View in ScopusGoogle Scholar Braeken, 2017 J. Braeken An empirical Kaiser criterion
    Psychol. Methods, 22 (3) (2017), pp. 450-466, 10.1037/met0000074 View in ScopusGoogle
    Scholar Bu et al., 2020 J. Bu, W. Liu, Z. Pan, K. Ling Comparative study of hydrochemical
    classification based on different hierarchical cluster analysis methods Int. J.
    Environ. Res. Public Health, 17 (24) (2020), 10.3390/ijerph17249515 Google Scholar
    Burrell et al., 2020 A.L. Burrell, J.P. Evans, M.G. De Kauwe Anthropogenic climate
    change has driven over 5 million km2 of drylands towards desertification Nat.
    Commun., 11 (1) (2020), p. 3853, 10.1038/s41467-020-17710-7 View in ScopusGoogle
    Scholar Busico et al., 2018 G. Busico, E. Cuoco, N. Kazakis, N. Colombani, M.
    Mastrocicco, D. Tedesco, K. Voudouris Multivariate statistical analysis to characterize/discriminate
    between anthropogenic and geogenic trace elements occurrence in the Campania Plain,
    Southern Italy Environ. Pollut., 234 (2018), pp. 260-269, 10.1016/j.envpol.2017.11.053
    View PDFView articleView in ScopusGoogle Scholar Calabrese, 2019 B. Calabrese
    Data reduction S. Ranganathan, M. Gribskov, K. Nakai, C. Schönbach (Eds.), Encyclopedia
    of Bioinformatics and Computational Biology, Academic Press, Oxford (2019), pp.
    480-485, 10.1016/B978-0-12-809633-8.20460-3 View PDFView articleGoogle Scholar
    Cao et al., 2021 T. Cao, D. Han, X. Song Past, present, and future of global seawater
    intrusion research: a bibliometric analysis J. Hydrol., 603 (PA) (2021), Article
    126844, 10.1016/j.jhydrol.2021.126844 View PDFView articleView in ScopusGoogle
    Scholar Carrera et al., 2010 J. Carrera, J.J. Hidalgo, L.J. Slooten, E. Vázquez-Suñé
    Computational and conceptual issues in the calibration of seawater intrusion models
    Hydrogeol. J., 18 (1) (2010), pp. 131-145, 10.1007/s10040-009-0524-1 View in ScopusGoogle
    Scholar Celestino et al., 2018 A.E.M. Celestino, D.A.M. Cruz, E.M.O. Sánchez,
    F.G. Reyes, D.V. Soto Groundwater quality assessment: an improved approach to
    K-means clustering, principal component analysis and spatial analysis: a case
    study Water (Switzerland), 10 (4) (2018), pp. 1-21, 10.3390/w10040437 Google Scholar
    Céréghino and Park, 2009 R. Céréghino, Y.-S. Park Review of the self-organizing
    map (SOM) approach in water resources: commentary Environ. Model Softw., 24 (8)
    (2009), pp. 945-947, 10.1016/j.envsoft.2009.01.008 View PDFView articleView in
    ScopusGoogle Scholar Chadha, 1999 D.K. Chadha A proposed new diagram for geochemical
    classification of natural waters and interpretation of chemical data Hydrogeol.
    J., 7 (5) (1999), pp. 431-439, 10.1007/s100400050216 View in ScopusGoogle Scholar
    Chandrajith et al., 2016 R. Chandrajith, S. Diyabalanage, K.M. Premathilake, C.
    Hanke, R. van Geldern, J.A.C. Barth Controls of evaporative irrigation return
    flows in comparison to seawater intrusion in coastal karstic aquifers in northern
    Sri Lanka: evidence from solutes and stable isotopes Sci. Total Environ., 548–549
    (2016), pp. 421-428, 10.1016/j.scitotenv.2016.01.050 View PDFView articleView
    in ScopusGoogle Scholar Costall et al., 2020 A.R. Costall, B.D. Harris, B. Teo,
    R. Schaa, F.M. Wagner, J.P. Pigois Groundwater throughflow and seawater intrusion
    in high quality coastal aquifers Sci. Rep., 10 (1) (2020), p. 9866, 10.1038/s41598-020-66516-6
    View in ScopusGoogle Scholar Cui et al., 2021 D. Cui, S. Liang, D. Wang Observed
    and projected changes in global climate zones based on Köppen climate classification
    Wiley Interdiscip. Rev. Clim. Chang., 12 (3) (2021), pp. 1-28, 10.1002/wcc.701
    Google Scholar Damonte and Boelens, 2019 G. Damonte, R. Boelens Hydrosocial territories,
    agro-export and water scarcity: capitalist territorial transformations and water
    governance in Peru''s coastal valleys Water Int., 44 (2) (2019), pp. 206-223,
    10.1080/02508060.2018.1556869 View in ScopusGoogle Scholar Denis, 2020 D. Denis
    Univariate, Bivariate, and Multivariate Statistics Using R: Quantitative Tools
    for Data Analysis and Data Science John Wiley & Sons, Boston, MA (2020) Google
    Scholar Díaz-Alcaide and Martínez-Santos, 2019 S. Díaz-Alcaide, P. Martínez-Santos
    Review: advances in groundwater potential mapping Hydrogeol. J., 27 (7) (2019),
    pp. 2307-2324, 10.1007/s10040-019-02001-3 View in ScopusGoogle Scholar Du, 2010
    K. Du Clustering: A Neural Network Approach, 23 (2010), pp. 89-107, 10.1016/j.neunet.2009.08.007
    View PDFView articleView in ScopusGoogle Scholar El Yaouti et al., 2009 F. El
    Yaouti, A. El Mandour, D. Khattach, J. Benavente, O. Kaufmann Salinization processes
    in the unconfined aquifer of Bou-Areg (NE Morocco): a geostatistical, geochemical,
    and tomographic study Appl. Geochem., 24 (1) (2009), pp. 16-31, 10.1016/j.apgeochem.2008.10.005
    View PDFView articleView in ScopusGoogle Scholar Enemark et al., 2019 T. Enemark,
    L.J.M. Peeters, D. Mallants, O. Batelaan Hydrogeological conceptual model building
    and testing: a review J. Hydrol., 569 (2019), pp. 310-329, 10.1016/j.jhydrol.2018.12.007
    View PDFView articleView in ScopusGoogle Scholar Ez-zaouy et al., 2022 Y. Ez-zaouy,
    L. Bouchaou, A. Saad, M. Hssaisoune, Y. Brouziyne, D. Dhiba, A. Chehbouni Morocco''s
    coastal aquifers: recent observations, evolution and perspectives towards sustainability
    Environ. Pollut., 293 (November 2021) (2022), Article 118498, 10.1016/j.envpol.2021.118498
    View PDFView articleView in ScopusGoogle Scholar Fan et al., 2008 J. Fan, Y. Song,
    M. Fei Neurocomputing ART2 Neural Network Interacting With Environment, 72 (2008),
    pp. 170-176, 10.1016/j.neucom.2008.02.026 View PDFView articleView in ScopusGoogle
    Scholar Fdez-Ortiz de Vallejuelo et al., 2011 S. Fdez-Ortiz de Vallejuelo, G.
    Arana, A. de Diego, J.M. Madariaga Pattern recognition and classification of sediments
    according to their metal content using chemometric tools. A case study: the estuary
    of Nerbioi-Ibaizabal River (Bilbao, Basque Country) Chemosphere, 85 (8) (2011),
    pp. 1347-1352, 10.1016/j.chemosphere.2011.07.054 View PDFView articleView in ScopusGoogle
    Scholar Ferguson and Gleeson, 2012 G. Ferguson, T. Gleeson Vulnerability of coastal
    aquifers to groundwater use and climate change Nat. Clim. Chang., 2 (5) (2012),
    pp. 342-345, 10.1038/nclimate1413 View in ScopusGoogle Scholar Fraiman et al.,
    2008 R. Fraiman, A. Justel, M. Svarc Selection of variables for cluster analysis
    and classification rules J. Am. Stat. Assoc., 103 (483) (2008), pp. 1294-1303,
    10.1198/016214508000000544 View in ScopusGoogle Scholar Fürnkranz et al., 2011
    J. Fürnkranz, P.K. Chan, S. Craw, C. Sammut, W. Uther, A. Ratnaparkhi, et al.
    Model-based clustering C. Sammut, G.I. Webb (Eds.), Encyclopedia of Machine Learning,
    Springer, US, Boston, MA (2011), pp. 686-689, 10.1007/978-0-387-30164-8_554 Google
    Scholar Gaillardet et al., 1999 J. Gaillardet, B. Dupré, P. Louvat, C.J. Allègre
    Global silicate weathering and CO2 consumption rates deduced from the chemistry
    of large rivers Chem. Geol., 159 (1–4) (1999), pp. 3-30, 10.1016/S0009-2541(99)00031-5
    View PDFView articleView in ScopusGoogle Scholar Galazoulas and Petalas, 2014
    E.C. Galazoulas, C.P. Petalas Application of multivariate statistical procedures
    on major ions and trace elements in a multilayered coastal aquifer: the case of
    the south Rhodope coastal aquifer Environ. Earth Sci., 72 (10) (2014), pp. 4191-4205,
    10.1007/s12665-014-3315-5 View in ScopusGoogle Scholar Gilabert-Alarcón et al.,
    2018 C. Gilabert-Alarcón, L.W. Daesslé, S.O. Salgado-Méndez, M.A. Pérez-Flores,
    K. Knöller, T.G. Kretzschmar, C. Stumpp Effects of reclaimed water discharge in
    the maneadero coastal aquifer, Baja California,Mexico Appl. Geochem., 92 (March)
    (2018), pp. 121-139, 10.1016/j.apgeochem.2018.03.006 View PDFView articleView
    in ScopusGoogle Scholar Giménez-Forcada, 2010 E. Giménez-Forcada Dynamic of sea
    water Interface using hydrochemical facies evolution diagram Ground Water, 48
    (2) (2010), pp. 212-216, 10.1111/j.1745-6584.2009.00649.x View in ScopusGoogle
    Scholar Gokul et al., 2019 M.S. Gokul, H.U. Dahms, K. Muthukumar, S. Henciya,
    T. Kaviarasan, R.A. James Multivariate drug resistance and microbial risk assessment
    in tropical coastal communities Hum. Ecol. Risk. Assess., 25 (5) (2019), pp. 1073-1095,
    10.1080/10807039.2018.1447361 View in ScopusGoogle Scholar Govett et al., 1975
    G.J.S. Govett, W.D. Goodfellow, R.P. Chapman, C.Y. Chork Exploration geochemistry—distribution
    of elements and recognition of anomalies J. Int. Assoc. Math. Geol., 7 (5–6) (1975),
    pp. 415-446, 10.1007/BF02080498 View in ScopusGoogle Scholar Gredilla et al.,
    2013 A. Gredilla, S.F. De Vall, J.M. Amigo, A.De Diego, J.M. Madariaga Unsupervised
    pattern-recognition techniques to investigate metal pollution in estuaries Trends
    Anal. Chem., 46 (2013), 10.1016/j.trac.2013.01.014 Google Scholar Greenacre and
    Pardo, 2011 M. Greenacre, R. Pardo Multiple correspondence analysis of a subset
    of response categories SSRN Electron. J. (2011), 10.2139/ssrn.847647 Google Scholar
    Güler et al., 2002 C. Güler, G.D. Thyne, J.E. McCray, K.A. Turner Evaluation of
    graphical and multivariate statistical methods for classification of water chemistry
    data Hydrogeol. J., 10 (4) (2002), pp. 455-474, 10.1007/s10040-002-0196-6 View
    in ScopusGoogle Scholar Güler et al., 2012 C. Güler, M.A. Kurt, M. Alpaslan, C.
    Akbulut Assessment of the impact of anthropogenic activities on the groundwater
    hydrology and chemistry in Tarsus coastal plain (Mersin, SE Turkey) using fuzzy
    clustering, multivariate statistics and GIS techniques J. Hydrol., 414–415 (2012),
    pp. 435-451, 10.1016/j.jhydrol.2011.11.021 View PDFView articleView in ScopusGoogle
    Scholar Güner et al., 2021 E.D. Güner, H.O. Cekim, G. Seçkin Determination of
    water quality assessment in wells of the Göksu Plains using multivariate statistical
    techniques Environ. Forensic, 22 (1–2) (2021), pp. 172-188, 10.1080/15275922.2020.1834025
    View in ScopusGoogle Scholar Ha et al., 2022 Q.K. Ha, T.D. Tran Ngoc, P. Le Vo,
    H.Q. Nguyen, D.H. Dang Groundwater in Southern Vietnam: understanding geochemical
    processes to better preserve the critical water resource Sci. Total Environ.,
    807 (2022), Article 151345, 10.1016/j.scitotenv.2021.151345 View PDFView articleView
    in ScopusGoogle Scholar Hahsler et al., 2019 M. Hahsler, M. Piekenbrock, D. Doran
    dbscan: fast density-based clustering with R J. Stat. Softw., 91 (1) (2019), 10.18637/jss.v091.i01
    Google Scholar Hajji et al., 2020 S. Hajji, G. Nasri, E. Boughariou, M. Bahloul,
    N. Allouche, S. Bouri Towards understanding groundwater quality using hydrochemical
    and statistical approaches: case of shallow aquifer of Mahdia-Ksour Essaf (Sahel
    of Tunisia) Environ. Sci. Pollut. Res., 27 (5) (2020), pp. 5251-5265, 10.1007/s11356-019-06982-2
    View in ScopusGoogle Scholar Hasan et al., 2021 M.N. Hasan, M.A.B. Siddique, A.H.M.S.
    Reza, R. Khan, M.A. Akbor, I.Bin Elius, et al. Vulnerability assessment of seawater
    intrusion in coastal aquifers of southern Bangladesh: water quality appraisals
    Environ.Nanotechnol.Monit.Manag., 16 (February) (2021), Article 100498, 10.1016/j.enmm.2021.100498
    View PDFView articleView in ScopusGoogle Scholar Herms et al., 2021 I. Herms,
    J. Jódar, A. Soler, L.J. Lambán, E. Custodio, J.A. Núñez, et al. Evaluation of
    natural background levels of high mountain karst aquifers in complex hydrogeological
    settings. A Gaussian mixture model approach in the Port del Comte (SE, Pyrenees)
    case study Sci. Total Environ., 756 (2021), Article 143864, 10.1016/j.scitotenv.2020.143864
    View PDFView articleView in ScopusGoogle Scholar Houssein et al., 2017 A. Houssein,
    W. Elmi, A. Zghibi Assessment of chemical quality of groundwater in coastal volcano-
    sedimentary aquifer of Djibouti, Horn of Africa J. Afr. Earth Sci., 131 (2017),
    pp. 284-300, 10.1016/j.jafrearsci.2017.04.010 Google Scholar Hyung et al., 2021
    T. Hyung, K. Sang, Y. Chung, V. Senapathi, S. Sekar, H. Eldin Groundwater decrease
    and contamination around subway tunnels in a coastal area of Busan City, Korea
    Environ. Earth Sci. (2021), 10.1007/s12665-021-09829-7 Google Scholar IBM, 2021
    IBM Factor Analysis Extraction (SPSS Statistics 25) Retrieved June 1, 2022, from
    (2021) https://www.ibm.com/docs/vi/spss-statistics/25.0.0?topic=analysis-factor-extraction
    Google Scholar Izakian and Abraham, 2011 H. Izakian, A. Abraham Fuzzy C-means
    and fuzzy swarm for fuzzy clustering problem Expert Syst. Appl., 38 (3) (2011),
    pp. 1835-1838, 10.1016/j.eswa.2010.07.112 View PDFView articleView in ScopusGoogle
    Scholar Jasechko et al., 2020 S. Jasechko, D. Perrone, H. Seybold, Y. Fan, J.W.
    Kirchner Groundwater level observations in 250,000 coastal US wells reveal scope
    of potential seawater intrusion Nat. Commun., 11 (1) (2020), p. 3229, 10.1038/s41467-020-17038-2
    View in ScopusGoogle Scholar Jiao and Post, 2019 J. Jiao, V. Post Coastal hydrogeology
    Paper Knowledge. Toward a Media History of Documents, vol. 5, Cambridge University
    Press (2019), 10.1017/9781139344142 Google Scholar Jolliffe, 2002 I.T. Jolliffe
    Principal component analysis for special types of data Principal Component Analysis,
    Springer-Verlag, New York (2002), pp. 338-372, 10.1007/0-387-22440-8_13 Google
    Scholar Jolliffe and Cadima, 2016 I.T. Jolliffe, J. Cadima Principal component
    analysis: a review and recent developments Philos. Trans. R. Soc. A Math. Phys.
    Eng. Sci., 374 (2065) (2016), p. 20150202, 10.1098/rsta.2015.0202 Google Scholar
    Kalteh et al., 2008 A.M. Kalteh, P. Hjorth, R. Berndtsson Review of the self-organizing
    map (SOM) approach in water resources: analysis, modelling and application Environ.
    Model. Softw., 23 (7) (2008), pp. 835-845, 10.1016/j.envsoft.2007.10.001 View
    PDFView articleView in ScopusGoogle Scholar Kano et al., 2004 M. Kano, S. Hasebe,
    I. Hashimoto, H. Ohno Evolution of multivariate statistical process control: application
    of independent component analysis and external analysis Comput. Chem. Eng., 28
    (2004), pp. 1157-1166, 10.1016/j.compchemeng.2003.09.011 View PDFView articleView
    in ScopusGoogle Scholar Kim et al., 2005 J.-H. Kim, R.-H. Kim, J. Lee, T.-J. Cheong,
    B.-W. Yum, H.-W. Chang Multivariate statistical analysis to identify the major
    factors governing groundwater quality in the coastal area of Kimje,South Korea
    Hydrol. Process., 19 (6) (2005), pp. 1261-1276, 10.1002/hyp.5565 View in ScopusGoogle
    Scholar Kim et al., 2019 R. Kim, J. Kim, J. Ryu, D. Koh Hydrogeochemical Characteristics
    of Groundwater Influenced by Reclamation, Seawater Intrusion, and Land Use in
    the Coastal Area of Yeonggwang, Korea, 23(4) (2019), pp. 603-619, 10.1007/s12303-018-0065-5
    View in ScopusGoogle Scholar King and Jackson, 1999 J.R. King, D.A. Jackson Variable
    selection in large environmental data sets using principal components analysis
    Environmetrics, 10 (1) (1999), pp. 67-77, 10.1002/(SICI)1099-095X(199901/02)10:1<67::AID-ENV336>3.0.CO;2-0
    View in ScopusGoogle Scholar Knapp and Campbell-Heider, 1989 T.R. Knapp, N. Campbell-Heider
    Numbers of observations and variables in multivariate analyses West. J. Nurs.
    Res., 11 (5) (1989), pp. 634-641, 10.1177/019394598901100517 View in ScopusGoogle
    Scholar Kohonen, 2001 T. Kohonen Self-Organizing Maps Retrieved from (2001) http://www.springer.de/phys/
    Google Scholar Kumar et al., 2020 P.J.S. Kumar, P. Jegathambal, B. Babu, A. Kokkat,
    E.J. James A hydrogeochemical appraisal and multivariate statistical analysis
    of seawater intrusion in point calimere wetland, lower Cauvery region, India Groundw.
    Sustain. Dev., 11 (October 2019) (2020), Article 100392, 10.1016/j.gsd.2020.100392
    View PDFView articleView in ScopusGoogle Scholar Lall et al., 2020 U. Lall, L.
    Josset, T. Russo A snapshot of the world''s groundwater challenges Annu. Rev.
    Environ. Resour., 45 (2020), pp. 171-194, 10.1146/annurev-environ-102017-025800
    View in ScopusGoogle Scholar Larsen et al., 2017 F. Larsen, L.V. Tran, H. Van
    Hoang, L.T. Tran, A.V. Christiansen, N.Q. Pham Groundwater salinity influenced
    by Holocene seawater trapped in incised valleys in the Red River delta plain Nat.
    Geosci., 10 (5) (2017), pp. 376-381, 10.1038/ngeo2938 View in ScopusGoogle Scholar
    Lee, 1998 T.-C. Lee LEEGRAM: a program for normalized stiff diagrams and quantification
    of grouping hydrochemical data Comput. Geosci., 24 (6) (1998), pp. 523-529, 10.1016/S0098-3004(98)00073-9
    View PDFView articleView in ScopusGoogle Scholar Lee and Song, 2007 J.Y. Lee,
    S.H. Song Groundwater chemistry and ionic ratios in a western coastal aquifer
    of Buan, Korea: implication for seawater intrusion Geosci. J., 11 (3) (2007),
    pp. 259-270, 10.1007/BF02913939 View in ScopusGoogle Scholar Lesouple et al.,
    2021 J. Lesouple, C. Baudoin, M. Spigai, J.-Y. Tourneret Generalized isolation
    forest for anomaly detection Pattern Recogn. Lett., 149 (2021), pp. 109-119, 10.1016/j.patrec.2021.05.022
    View PDFView articleGoogle Scholar Li et al., 2018 T. Li, G. Sun, C. Yang, K.
    Liang, S. Ma, L. Huang Using self-organizing map for coastal water quality classification:
    towards a better understanding of patterns and processes Sci. Total Environ.,
    628–629 (2018), pp. 1446-1459, 10.1016/j.scitotenv.2018.02.163 View PDFView articleView
    in ScopusGoogle Scholar Li et al., 2020 C. Li, X. Gao, S. Li, J. Bundschuh A review
    of the distribution, sources, genesis, and environmental concerns of salinity
    in groundwater Environ. Sci. Pollut. Res., 27 (33) (2020), pp. 41157-41174, 10.1007/s11356-020-10354-6
    View in ScopusGoogle Scholar Li et al., 2021 M. Li, M. Zhang, H. Rong, X. Zhang,
    L. He, P. Han, M. Tong Transport and deposition of plastic particles in porous
    media during seawater intrusion and groundwater-seawater displacement processes
    Sci. Total Environ., 781 (2021), Article 146752, 10.1016/j.scitotenv.2021.146752
    View PDFView articleView in ScopusGoogle Scholar Liu et al., 2021 Q. Liu, Z. Zhang,
    B. Zhang, W. Mu, H. Zhang, Y. Li, N. Xu Hydrochemical analysis and identification
    of open-pit mine water sources: a case study from the Dagushan iron mine in Northeast
    China Sci. Rep., 11 (1) (2021), p. 23152, 10.1038/s41598-021-02609-0 View in ScopusGoogle
    Scholar Mannor et al., 2011 S. Mannor, X. Jin, J. Han, X. Jin, J. Han, X. Jin,
    et al. K-medoids clustering C. Sammut, G.I. Webb (Eds.), Encyclopedia of Machine
    Learning, Springer, US, Boston, MA (2011), pp. 564-565, 10.1007/978-0-387-30164-8_426
    Google Scholar Marandi and Shand, 2018 A. Marandi, P. Shand Groundwater chemistry
    and the Gibbs diagram Appl. Geochem., 97 (2018), pp. 209-212, 10.1016/j.apgeochem.2018.07.009
    View PDFView articleView in ScopusGoogle Scholar Marefat et al., 2019 F. Marefat,
    A. Saeedian, S.H. Mozaffari, N. Khanlarzadeh, A. Kardoust, M. Mirzaei, J.A. Fatalaki
    Advancing quantitative methods in second language research Innov. Lang. Learn.
    Teach., 13 (3) (2019), pp. 299-302, 10.1080/17501229.2019.1566910 Google Scholar
    Mianabadi et al., 2020 A. Mianabadi, H. Derakhshan, K. Davary, S.M. Hasheminia,
    M. Hrachowitz A novel idea for groundwater resource management during megadrought
    events Water Resour. Manag., 34 (5) (2020), pp. 1743-1755, 10.1007/s11269-020-02525-4
    View in ScopusGoogle Scholar Michael et al., 2017 H.A. Michael, V.E.A. Post, A.M.
    Wilson, A.D. Werner Science, society, and the coastal groundwater squeeze Water
    Resour. Res., 53 (4) (2017), pp. 2610-2617, 10.1002/2017WR020851 View in ScopusGoogle
    Scholar Minitab, 2022 Minitab Enter your data for Factor Analysis (MINITAB 18)
    Retrieved June 1, 2022, from https://support.minitab.com/en-us/minitab/18/help-and-how-to/modeling-statistics/multivariate/how-to/factor-analysis/perform-the-analysis/enter-your-data/
    (2022) Google Scholar Mirzavand et al., 2020 M. Mirzavand, H. Ghasemieh, S.J.
    Sadatinejad, R. Bagheri An overview on source, mechanism and investigation approaches
    in groundwater salinization studies Int. J. Environ. Sci. Technol., 17 (4) (2020),
    pp. 2463-2476, 10.1007/s13762-020-02647-7 View in ScopusGoogle Scholar Mitra et
    al., 2002 P. Mitra, C.A. Murthy, S.K. Pal Unsupervised feature selection using
    feature similarity IEEE Trans. Pattern Anal. Mach. Intell., 24 (3) (2002), pp.
    301-312, 10.1109/34.990133 View in ScopusGoogle Scholar Miuigan and Cooper, 1988
    G.W. Miuigan, M.C. Cooper A study of standardization of variables in cluster analysis
    J. Classif., 204 (1988), pp. 181-204, 10.1007/BF01897163 Google Scholar Mohammadrezapour
    et al., 2020 O. Mohammadrezapour, O. Kisi, F. Pourahmad Fuzzy c-means and K-means
    clustering with genetic algorithm for identification of homogeneous regions of
    groundwater quality Neural Comput. & Applic., 32 (8) (2020), pp. 3763-3775, 10.1007/s00521-018-3768-7
    View in ScopusGoogle Scholar Moher et al., 2009 D. Moher, A. Liberati, J. Tetzlaff,
    D.G. Altman Preferred reporting items for systematic reviews and meta-analyses:
    the PRISMA statement PLoS Med., 6 (7) (2009), Article e1000097, 10.1371/journal.pmed.1000097
    View in ScopusGoogle Scholar Mora et al., 2021 A. Mora, J.A. Torres-Martínez,
    C. Moreau, G. Bertrand, J. Mahlknecht Mapping salinization and trace element abundance
    (including as and other metalloids) in the groundwater of north-central Mexico
    using a double-clustering approach Water Res., 205 (2021), Article 117709, 10.1016/j.watres.2021.117709
    View PDFView articleView in ScopusGoogle Scholar Moreno Merino et al., 2021 L.
    Moreno Merino, H. Aguilera, M. González-Jiménez, E. Díaz-Losada D-Piper, a modified
    piper diagram to represent big sets of hydrochemical analyses Environ. Model Softw.,
    138 (2021), Article 104979, 10.1016/j.envsoft.2021.104979 View PDFView articleView
    in ScopusGoogle Scholar Narvaez-Montoya et al., 2022 C. Narvaez-Montoya, J.A.
    Torres-Martínez, E. Pino-Vargas, F. Cabrera-Olivera, F.J. Loge, J. Mahlknecht
    Predicting adverse scenarios for a transboundary coastal aquifer system in the
    Atacama Desert (Peru/Chile) Sci. Total Environ., 806 (2022), Article 150386, 10.1016/j.scitotenv.2021.150386
    View PDFView articleView in ScopusGoogle Scholar Naser et al., 2017 A.M. Naser,
    L. Unicomb, S. Doza, K.M. Ahmed, M. Rahman, M.N. Uddin, et al. Stepped-wedge cluster-randomised
    controlled trial to assess the cardiovascular health effects of a managed aquifer
    recharge initiative to reduce drinking water salinity in southwest coastal Bangladesh:
    study design and rationale BMJ Open, 7 (9) (2017), pp. 1-11, 10.1136/bmjopen-2016-015205
    Google Scholar Nguyen et al., 2015 T.T. Nguyen, A. Kawamura, T.N. Tong, H. Amaguchi,
    N. Nakagawa, R. Gilbuena, D.Du. Bui Identification of spatio-seasonal hydrogeochemical
    characteristics of the unconfined groundwater in the red River Delta,Vietnam Appl.
    Geochem., 63 (2015), pp. 10-21, 10.1016/j.apgeochem.2015.07.009 View PDFView articleView
    in ScopusGoogle Scholar Nogueira et al., 2019 G. Nogueira, T.Y. Stigter, Y. Zhou,
    F. Mussa, D. Juizo Understanding groundwater salinization mechanisms to secure
    freshwater resources in the water-scarce city of Maputo, Mozambique Sci. Total
    Environ., 661 (2019), pp. 723-736, 10.1016/j.scitotenv.2018.12.343 View PDFView
    articleView in ScopusGoogle Scholar O''Hara and Kotze, 2010 R. O''Hara, J. Kotze
    Do not log-transform count data Nature Precedings (2010), 10.1038/npre.2010.4136.1
    Google Scholar Olkowska et al., 2014 E. Olkowska, B. Kudłak, S. Tsakovski, M.
    Ruman, V. Simeonov, Z. Polkowska Assessment of the water quality of Kłodnica River
    catchment using self-organizing maps Sci. Total Environ., 476–477 (2014), pp.
    477-484, 10.1016/j.scitotenv.2014.01.044 View PDFView articleView in ScopusGoogle
    Scholar Olsen et al., 2012 R.L. Olsen, R.W. Chappell, J.C. Loftis Water quality
    sample collection, data treatment and results presentation for principal components
    analysis – literature review and Illinois River watershed case study Water Res.,
    46 (9) (2012), pp. 3110-3122, 10.1016/j.watres.2012.03.028 View PDFView articleView
    in ScopusGoogle Scholar Osiakwan et al., 2021 G.M. Osiakwan, E.K. Appiah-Adjei,
    A.T. Kabo-Bah, A. Gibrilla, G. Anornu Assessment of groundwater quality and the
    controlling factors in coastal aquifers of Ghana: an integrated statistical, geostatistical
    and hydrogeochemical approach J. Afr. Earth Sci., 184 (August) (2021), Article
    104371, 10.1016/j.jafrearsci.2021.104371 View PDFView articleView in ScopusGoogle
    Scholar Pacheco Castro et al., 2018 R. Pacheco Castro, J. Pacheco Ávila, M. Ye,
    A. Cabrera Sansores Groundwater quality: analysis of its temporal and spatial
    variability in a karst aquifer Groundwater, 56 (1) (2018), pp. 62-72, 10.1111/gwat.12546
    View in ScopusGoogle Scholar Papazotos et al., 2020 P. Papazotos, E. Vasileiou,
    M. Perraki Elevated groundwater concentrations of arsenic and chromium in ultramafic
    environments controlled by seawater intrusion, the nitrogen cycle, and anthropogenic
    activities: the case of the Gerania Mountains, NE Peloponnese,Greece Appl. Geochem.
    (July) (2020), Article 104697, 10.1016/j.apgeochem.2020.104697 View PDFView articleView
    in ScopusGoogle Scholar Parizi et al., 2019 E. Parizi, S.M. Hosseini, B. Ataie-Ashtiani,
    C.T. Simmons Vulnerability mapping of coastal aquifers to seawater intrusion:
    review, development and application J. Hydrol., 570 (August 2018) (2019), pp.
    555-573, 10.1016/j.jhydrol.2018.12.021 View PDFView articleView in ScopusGoogle
    Scholar Parkhurst and Appelo, 2013 D.L. Parkhurst, C.A.J. Appelo Description of
    input and examples for PHREEQC version 3: a computer program for speciation, batch-reaction,
    one-dimensional transport, and inverse geochemical calculations Techniques and
    Methods (2013), 10.3133/tm6A43 Reston, VA Google Scholar Poeter et al., 2020 E.
    Poeter, Y. Fan, J. Cherry, W. Wood, D. Mackay Groundwater in Our Water Cycle:
    Getting to Know Earth''s Most Important Fresh Water Source The Groundwater Project,
    Ontario, Canada (2020), 10.21083/978-1-7770541-1-3 Google Scholar Polemio and
    Zuffianò, 2020 M. Polemio, L.E. Zuffianò Review of utilization management of groundwater
    at risk of salinization J. Water Resour. Plan. Manag., 146 (9) (2020), Article
    03120002, 10.1061/(ASCE)WR.1943-5452.0001278 View in ScopusGoogle Scholar Rajabi
    et al., 2018 M.M. Rajabi, B. Ataie-Ashtiani, C.T. Simmons Model-data interaction
    in groundwater studies: review of methods, applications and future directions
    J. Hydrol., 567 (September) (2018), pp. 457-477, 10.1016/j.jhydrol.2018.09.053
    View PDFView articleView in ScopusGoogle Scholar Rajoub, 2020 B. Rajoub Supervised
    and unsupervised learning Biomedical Signal Processing and Artificial Intelligence
    in Healthcare (2020), pp. 51-89, 10.1016/b978-0-12-818946-7.00003-2 (January)
    View PDFView articleView in ScopusGoogle Scholar Rakib et al., 2020 M.A. Rakib,
    J. Sasaki, H. Matsuda, S.B. Quraishi, M.J. Mahmud, M. Bodrud-Doza, et al. Groundwater
    salinization and associated co-contamination risk increase severe drinking water
    vulnerabilities in the southwestern coast of Bangladesh Chemosphere, 246 (2020),
    10.1016/j.chemosphere.2019.125646 Google Scholar Sabarathinam et al., 2021 C.
    Sabarathinam, H. Bhandary, A. Ali Strategies to characterize the geochemical interrelationship
    between coastal saline groundwater and seawater Environ. Earth Sci., 80 (18) (2021),
    p. 642, 10.1007/s12665-021-09924-9 View in ScopusGoogle Scholar Sae-Ju et al.,
    2020 J. Sae-Ju, S. Chotpantarat, T. Thitimakorn Hydrochemical, geophysical and
    multivariate statistical investigation of the seawater intrusion in the coastal
    aquifer at Phetchaburi Province, Thailand J. Asian Earth Sci., 191 (December 2018)
    (2020), Article 104165, 10.1016/j.jseaes.2019.104165 View PDFView articleView
    in ScopusGoogle Scholar Salem et al., 2021 Z.E.-S. Salem, K. Abdelrahman, S. Kováčiková,
    O.M. Badran Use of various statistical techniques to assess the vertical and lateral
    change in the groundwater chemistry of quaternary aquifer in an irrigated highly
    populated area J.King Saud Univ.Sci., 33 (7) (2021), Article 101556, 10.1016/j.jksus.2021.101556
    View PDFView articleView in ScopusGoogle Scholar Sangadi et al., 2022 P. Sangadi,
    C. Kuppan, P. Ravinathan Effect of Hydro-geochemical Processes and Saltwater Intrusion
    on Groundwater Quality and Irrigational Suitability Assessed by Geo-statistical
    Techniques in Coastal Region of eastern Andhra Pradesh, India 175 (2022) (December
    2021) Google Scholar Saxena et al., 2017 A. Saxena, M. Prasad, A. Gupta, N. Bharill,
    O.P. Patel, A. Tiwari, et al. A review of clustering techniques and developments
    Neurocomputing, 267 (2017), pp. 664-681, 10.1016/j.neucom.2017.06.053 View PDFView
    articleView in ScopusGoogle Scholar Senawi et al., 2017 A. Senawi, H.-L. Wei,
    S.A. Billings A new maximum relevance-minimum multicollinearity (MRmMC) method
    for feature selection and ranking Pattern Recogn., 67 (2017), pp. 47-61, 10.1016/j.patcog.2017.01.026
    View PDFView articleView in ScopusGoogle Scholar Sergeant et al., 2016 C.J. Sergeant,
    E.N. Starkey, K.K. Bartz, M.H. Wilson, F.J. Mueter A practitioner''s guide for
    exploring water quality patterns using principal components analysis and procrustes
    Environ. Monit. Assess., 188 (4) (2016), p. 249, 10.1007/s10661-016-5253-z View
    in ScopusGoogle Scholar Shapouri et al., 2016 M. Shapouri, L. Cancela da Fonseca,
    S. Iepure, T. Stigter, L. Ribeiro, A. Silva The variation of stygofauna along
    a gradient of salinization in a coastal aquifer Hydrol. Res., 47 (1) (2016), pp.
    89-103, 10.2166/nh.2015.153 View in ScopusGoogle Scholar Sharma and Batra, 2019
    S. Sharma, N. Batra Comparative study of single linkage, complete linkage, and
    ward method of agglomerative clustering 2019 International Conference on Machine
    Learning, Big Data, Cloud and Parallel Computing (COMITCon), IEEE (2019), pp.
    568-573, 10.1109/COMITCon.2019.8862232 Google Scholar Shi et al., 2018 X. Shi,
    Y. Wang, J.J. Jiao, J. Zhong, H. Wen, R. Dong Assessing major factors affecting
    shallow groundwater geochemical evolution in a highly urbanized coastal area of
    Shenzhen City, China J. Geochem. Explor., 184 (2018), pp. 17-27, 10.1016/j.gexplo.2017.10.003
    View PDFView articleView in ScopusGoogle Scholar Sicilia et al., 2017 M.-A. Sicilia,
    E. García-Barriocanal, S. Sánchez-Alonso Community curation in open dataset repositories:
    insights from Zenodo Procedia Comput.Sci., 106 (2017), pp. 54-60, 10.1016/j.procs.2017.03.009
    View PDFView articleView in ScopusGoogle Scholar Souid et al., 2018 F. Souid,
    B. Agoubi, F. Telahigue, A. Chahlaoui, A. Kharroubi Groundwater salinization and
    seawater intrusion tracing based on lithium concentration in the shallow aquifer
    of Jerba Island, southeastern Tunisia J. Afr. Earth Sci., 138 (2018), pp. 233-246,
    10.1016/j.jafrearsci.2017.11.013 View PDFView articleView in ScopusGoogle Scholar
    Stetco et al., 2015 A. Stetco, X.-J. Zeng, J. Keane Fuzzy C-means++: fuzzy C-means
    with effective seeding initialization Expert Syst. Appl., 42 (21) (2015), pp.
    7541-7548, 10.1016/j.eswa.2015.05.014 View PDFView articleView in ScopusGoogle
    Scholar Strauss and von Maltitz, 2017 T. Strauss, M.J. von Maltitz Generalising
    Ward''s method for use with Manhattan distances PLOS ONE, 12 (1) (2017), Article
    e0168288, 10.1371/journal.pone.0168288 View in ScopusGoogle Scholar Székely and
    Rizzo, 2014 G.J. Székely, M.L. Rizzo Partial distance correlation with methods
    for dissimilarities Ann. Stat., 42 (6) (2014), 10.1214/14-AOS1255 Google Scholar
    Tahmasebi et al., 2020 P. Tahmasebi, S. Kamrava, T. Bai, M. Sahimi Machine learning
    in geo- and environmental sciences: from small to large scale Adv.Water Resour.J.,
    142 (2020), 10.1016/j.advwatres.2020.103619 Google Scholar Tamez-Meléndez et al.,
    2016 C. Tamez-Meléndez, A. Hernández-Antonio, P. Gaona-Zanella, N. Ornelas-Soto,
    J. Mahlknecht Isotope signatures and hydrochemistry as tools in assessing groundwater
    occurrence and dynamics in a coastal arid aquifer Environ. Earth Sci., 75 (830)
    (2016), 10.1007/s12665-016-5617-2 Google Scholar Taşana et al., 2022 M. Taşana,
    Y. Demir, S. Taşan Groundwater quality assessment using principal component analysis
    and hierarchical Water Supply, 22 (3) (2022), pp. 3431-3447 0.2166/ws.2021.390
    Google Scholar Tiwari et al., 2019 A.K. Tiwari, A. Pisciotta, M. De Maio Evaluation
    of groundwater salinization and pollution level on Favignana Island, Italy Environ.
    Pollut., 249 (2019), pp. 969-981, 10.1016/j.envpol.2019.03.016 View PDFView articleView
    in ScopusGoogle Scholar Torres-Martínez et al., 2021 J.A. Torres-Martínez, A.
    Mora, J. Mahlknecht, D. Kaown, D. Barceló Determining nitrate and sulfate pollution
    sources and transformations in a coastal aquifer impacted by seawater intrusion—a
    multi-isotopic approach combined with self-organizing maps and a Bayesian mixing
    model J. Hazard. Mater., 417 (2021), Article 126103, 10.1016/j.jhazmat.2021.126103
    View PDFView articleView in ScopusGoogle Scholar Tully et al., 2019 K. Tully,
    K. Gedan, R. Epanchin-Niell, A. Strong, E.S. Bernhardt, T. BenDor, et al. The
    invisible flood: the chemistry, ecology, and social implications of coastal saltwater
    intrusion Bioscience, 69 (5) (2019), pp. 368-378, 10.1093/biosci/biz027 View in
    ScopusGoogle Scholar USGS, 2018 USGS Preparations for Water Sampling. Geological
    Survey Techniques and Methods (2018), 10.3133/tm9A1 book 9, chap. A1, 42 p. Reston
    Google Scholar Vaux, 2011 H. Vaux Groundwater under stress: the importance of
    management Environ. Earth Sci., 62 (1) (2011), pp. 19-23, 10.1007/s12665-010-0490-x
    View in ScopusGoogle Scholar Wang et al., 2022 H. Wang, Q. Yang, J. Liang Interpreting
    the salinization and hydrogeochemical characteristics of groundwater in Dongshan
    Island,China Mar. Pollut. Bull., 178 (2022), Article 113634, 10.1016/j.marpolbul.2022.113634
    View PDFView articleView in ScopusGoogle Scholar Ward, 1963 J.H. Ward Hierarchical
    grouping to optimize an objective function J. Am. Stat. Assoc., 58 (301) (1963),
    pp. 236-244, 10.1080/01621459.1963.10500845 View in ScopusGoogle Scholar Wehrens
    and Kruisselbrink, 2018 R. Wehrens, J. Kruisselbrink Flexible self-organizing
    maps in kohonen 3.0 J. Stat. Softw., 87 (7) (2018), 10.18637/jss.v087.i07 Google
    Scholar Werner et al., 2013 A.D. Werner, M. Bakker, V.E.A. Post, A. Vandenbohede,
    C. Lu, B. Ataie-Ashtiani, et al. Seawater intrusion processes, investigation and
    management: recent advances and future challenges Adv. Water Resour., 51 (2013),
    pp. 3-26, 10.1016/j.advwatres.2012.03.004 View PDFView articleView in ScopusGoogle
    Scholar WHO, 2011 WHO Guidelines for Drinking-water Quality (Fourth), Gutenberg,
    Malta (2011) Google Scholar Willett et al., 1998 P. Willett, J.M. Barnard, G.M.
    Downs Chemical similarity searching J. Chem. Inf. Comput. Sci., 38 (6) (1998),
    pp. 983-996, 10.1021/ci9800211 View in ScopusGoogle Scholar Wu et al., 2021 Z.
    Wu, S. Pan, F. Chen, G. Long, C. Zhang, P.S. Yu A comprehensive survey on graph
    neural networks IEEE Trans.Neural Netw.Learn.Syst., 32 (1) (2021), pp. 4-24, 10.1109/TNNLS.2020.2978386
    Google Scholar Wunderlin et al., 2001 D.A. Wunderlin, D. María Del Pilar, A. María
    Valeria, P.S. Fabiana, H.A. Cecilia, María De Los, B. Ángeles Pattern recognition
    techniques for the evaluation of spatial and temporal variations in water quality.
    A case study: Suquía River basin (Córdoba-Argentina) Water Res., 35 (12) (2001),
    pp. 2881-2894, 10.1016/S0043-1354(00)00592-3 View in ScopusGoogle Scholar Yik
    et al., 2012 C. Yik, M. Harun, S. Mangala, A. Hawa, B. Yahaya Delineation of temporal
    variability and governing factors influencing the spatial variability of shallow
    groundwater chemistry in a tropical sedimentary island J. Hydrol., 432–433 (2012),
    pp. 26-42, 10.1016/j.jhydrol.2012.02.015 View in ScopusGoogle Scholar Yin et al.,
    2021 Z. Yin, Q. Luo, J. Wu, S. Xu, J. Wu Identification of the long-term variations
    of groundwater and their governing factors based on hydrochemical and isotopic
    data in a river basin J. Hydrol., 592 (October 2020) (2021), Article 125604, 10.1016/j.jhydrol.2020.125604
    View PDFView articleView in ScopusGoogle Scholar Yuan and Yang, 2019 C. Yuan,
    H. Yang Research on K-value selection method of K-means clustering algorithm J,
    2 (2) (2019), pp. 226-235, 10.3390/j2020016 Google Scholar Zhu et al., 2020 H.
    Zhu, J. Zhou, H. Feng, H. Liu, H. Zhu, Z. Liu, et al. Influences of natural and
    anthropogenic processes on the groundwater quality in the Dagujia River basin
    in Yantai, China J.Water Supply: Res. Technol. - AQUA, 69 (2) (2020), pp. 184-196,
    10.2166/aqua.2019.113 View in ScopusGoogle Scholar Cited by (6) Application of
    the machine learning methods for GRACE data based groundwater modeling, a systematic
    review 2024, Groundwater for Sustainable Development Show abstract FlowSOM clustering
    – A novel pattern recognition approach for water research: Application to a hyper-arid
    coastal aquifer system 2024, Science of the Total Environment Show abstract Disentangling
    coastal groundwater level dynamics in a global dataset 2024, Hydrology and Earth
    System Sciences Identification of water pollution sources and analysis of pollution
    trigger conditions in Jiuqu River, Luxian County, China 2024, Environmental Science
    and Pollution Research Bibliometric Analysis of Spatial Technology for World Heritage:
    Application, Trend and Potential Paths 2023, Remote Sensing Research on Seawater
    Intrusion Suppression Scheme of Minjiang River Estuary 2023, International Journal
    of Environmental Research and Public Health © 2022 The Authors. Published by Elsevier
    B.V. Recommended articles Factors controlling groundwater salinization and hydrogeochemical
    processes in coastal aquifers from southern Spain Science of The Total Environment,
    Volume 580, 2017, pp. 50-68 M. Argamasilla, …, B. Andreo View PDF Identifying
    the characteristics and potential risk of seawater intrusion for southern China
    by the SBM-DEA model Science of The Total Environment, Volume 844, 2022, Article
    157205 Guiyao Xiong, …, Xiaobin Zhu View PDF A hydrogeochemical appraisal and
    multivariate statistical analysis of seawater intrusion in point calimere wetland,
    lower Cauvery region, India Groundwater for Sustainable Development, Volume 11,
    2020, Article 100392 P.J. Sajil Kumar, …, E.J. James View PDF Show 3 more articles
    Article Metrics Citations Citation Indexes: 3 Captures Readers: 37 View details
    About ScienceDirect Remote access Shopping cart Advertise Contact and support
    Terms and conditions Privacy policy Cookies are used by this site. Cookie settings
    | Your Privacy Choices All content on this site: Copyright © 2024 Elsevier B.V.,
    its licensors, and contributors. All rights are reserved, including those for
    text and data mining, AI training, and similar technologies. For all open access
    content, the Creative Commons licensing terms apply."'
  inline_citation: '>'
  journal: Science of the Total Environment
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: 'Seawater intrusion pattern recognition supported by unsupervised learning:
    A systematic review and application'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Santos R.P.D.
  - Beko M.
  - Leithardt V.R.Q.
  citation_count: '1'
  description: The evolution of the Internet of Things (IoT) devices for precision
    agriculture is directly linked to the needs and interests of humanity. These advances
    include migration to cloud computing, data engineering, and the democratization
    of tools. These changes allow for better management, data quality, security, and
    scalability, reducing operational costs. The objective of this research was to
    present a proposal for a data pre-processing package for meteorological stations
    classified as conventional. Among the main findings of this research is the need
    for data pre-processing for Machine Learning applications focused on precision
    irrigation, controlled by IoT devices; the use of data from conventional weather
    stations for Machine Learning applications; the availability of applications developed
    in Open Source repositories, and the proposal of a data pre-processing package
    to help professionals from different areas. The systematic review examined the
    various machine-learning applications for precision irrigation. Different models
    and mechanisms used to apply Machine Learning in precision irrigation projects
    were identified. In addition, we look at the challenges faced when using Machine
    Learning for precision irrigation, including the lack of data, the need for efficient
    data pre-processing, and the need to tune the model to get the best possible result.
    At the end of the article, we propose a data pre-processing package for conventional
    meteorological stations. This package includes normalization, noise removal, and
    outliers to improve the reliability of the input data.
  doi: 10.1109/CIoT57267.2023.10084899
  full_citation: '>'
  full_text: '>

    "This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org
    IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal
    Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln
    Sign Out All Books Conferences Courses Journals & Magazines Standards Authors
    Citations ADVANCED SEARCH Conferences >2023 6th Conference on Cloud ... Package
    Proposal for Data Pre-Processing for Machine Learning Applied to Precision Irrigation
    Publisher: IEEE Cite This PDF Rogério Pereira Dos Santos; Marko Beko; Valderi
    R. Q. Leithardt All Authors 2 Cites in Papers 94 Full Text Views Abstract Document
    Sections I. Introduction II. Materials and Methods III. Results and Proposal Considerations
    and Future Work Authors Figures References Citations Keywords Metrics Abstract:
    The evolution of the Internet of Things (IoT) devices for precision agriculture
    is directly linked to the needs and interests of humanity. These advances include
    migration to cloud computing, data engineering, and the democratization of tools.
    These changes allow for better management, data quality, security, and scalability,
    reducing operational costs. The objective of this research was to present a proposal
    for a data pre-processing package for meteorological stations classified as conventional.
    Among the main findings of this research is the need for data pre-processing for
    Machine Learning applications focused on precision irrigation, controlled by IoT
    devices; the use of data from conventional weather stations for Machine Learning
    applications; the availability of applications developed in Open Source repositories,
    and the proposal of a data pre-processing package to help professionals from different
    areas. The systematic review examined the various machine-learning applications
    for precision irrigation. Different models and mechanisms used to apply Machine
    Learning in precision irrigation projects were identified. In addition, we look
    at the challenges faced when using Machine Learning for precision irrigation,
    including the lack of data, the need for efficient data pre-processing, and the
    need to tune the model to get the best possible result. At the end of the article,
    we propose a data pre-processing package for conventional meteorological stations.
    This package includes normalization, noise removal, and outliers to improve the
    reliability of the input data. Published in: 2023 6th Conference on Cloud and
    Internet of Things (CIoT) Date of Conference: 20-22 March 2023 Date Added to IEEE
    Xplore: 03 April 2023 ISBN Information: ISSN Information: DOI: 10.1109/CIoT57267.2023.10084899
    Publisher: IEEE Conference Location: Lisbon, Portugal Funding Agency: SECTION
    I. Introduction We are currently going through what many call a perfect storm.
    We have large volumes of data generated worldwide, with wide variety and speed,
    which is precisely the definition of Big Data. We have algorithms capable of learning
    from data, processing power, and computational capacity. Machine Learning (ML)
    has existed for a few decades, as well as some of the statistical and mathematical
    techniques, but never in human history have we generated as much data as we are
    today [4]. We have never had as much computational capacity as we currently have,
    so we are experiencing a perfect storm. The Internet of Things (IoT) devices are
    at our disposal, with a lot of data being generated and excellent processing conditions
    [14]. Being able to extract information that we didn’t even imagine existed and
    being able to make correlations between this data makes us experience a true transformation.
    As these numbers increase and IoT technologies mature, the volume of published
    data will also increase [2]. Machine Learning is an applied science to extract
    information from data in an automated way and on a large scale; because of this,
    it is one of the rising fields of computer science, as it contributes to several
    different market segments. Due to the abundance of available data and the advent
    of ML to extract a large mass of data, it is possible to analyze this data through
    specific algorithms. ML algorithms are at the heart of the transformations we
    are experiencing. For this, there is an abundance of libraries, packages, and
    open-source software, that is, without costs for their use and study, so this
    scenario is an opportunity to contribute to the development and improvement of
    these tools [1]. The main component of an ML algorithm is a small piece of software
    that contains codes capable of preparing computers to do specific actions on their
    own. Creating a specific computer program and making it do something similar to
    what is done with an ML algorithm would demand a considerable amount of work,
    given the need to program each of the details of the process [5]. With ML, we
    can train an algorithm by presenting the data; depending on the data, the algorithm
    finds the patterns and then creates a piece of software exactly the predictive
    model. Then, new data are presented to this model, and it will be able to make
    the prediction; that is, if I had to build a program to make these predictions,
    we would have a lot of work and probably we would not get good results [7]. With
    ML, all this happens practically automatically, although there is work in pre-processing.
    Generally, data preprocessing boils down to extracting data from a given source
    and applying some process to convert this data; this is usually done with data
    engineering. In short, data engineering is a set of techniques and procedures
    for making data available in an appropriate and reliable format. This set of practices
    spans data engineering, mining, processing, acquisition, modeling, and management
    [3]. It is essential to understand that algorithms have different procedures when
    learning from data; therefore, before working with ML, we must define the best
    algorithm to work with according to the business problem to be analyzed. However,
    the ML theme is understood as a cycle that begins with data collection, analysis,
    and interpretation of information, enabling recommendations, application in the
    field, and better evaluation of results. Even so, new techniques can be applied;
    for example, we have the challenge of applications in Deep Learning (DL), which
    depends on the minimum of human interference in the presentation of data to the
    algorithm and is considered unsupervised learning [6]. A solution for building
    ML or DL models can be developed from scratch using a programming language or
    using a readymade framework where the main algorithms are already implemented.
    However, the large volume of information, especially with the characteristic of
    variety to be processed, has required new distributed and parallel computing solutions
    [5]. These combinations need to be integrated and pre-processed in order to be
    analyzed and evaluated, generating enough knowledge to support institutions, organizations,
    and farmers that make use of these technologies [3]. Today we have intelligent
    systems that use machine learning algorithms to control soil moisture, temperature,
    and water level in the context of precision agriculture. However, some algorithms,
    such as K-mean and SVM, have been facing overfitting problems and overcoming this
    problem, the KNearest Neighbor method has been indicated [10]. Machine learning
    has been shown to be accurate and consistent in training sets of completed projects.
    Among these learning techniques, the most used are neural networks, case-based
    reasoning, classification and regression trees, rule induction, genetic algorithms,
    and genetic programming, and their applications may vary according to the areas
    chosen for the training process of the algorithm [12]. The constant evolution
    of these technologies, whether implemented by hardware or software or combined,
    manage to achieve their goals and sustainability. But some solutions, despite
    contributing to the optimization of processes and tasks, still need stability
    and solidification, among other tools. In this sense, studies of machine learning
    algorithms can help in this process, which aims to predict the best practices
    in the management of water use in the field and control the large volume of data
    generated through wireless sensor networks [8]. Therefore, resorting to new technologies
    created and that have implemented machine learning resources tends to improve
    precision agriculture environments and becomes a trend on the world stage [9].
    Given the context, this work exclusively investigated Machine Learning applications
    and solutions available to solve the real problems of precision irrigation applied
    by IoT devices. In order to understand the demands and the current scenario, searches
    were carried out in electronic databases in order to identify their characteristics
    and applications. Understand the hardware and software relationships, as well
    as highlight the techniques and modeling used and the programming languages used
    for development [13]. Finally, present the ML models and verify the forms of pre-processing
    developed to strengthen the given proposal of the pre-processing package in favor
    of organizing the structures of the data generated by conventional meteorological
    stations. Also, instigate debates on open source packages for the programming
    language used, mainly for areas such as precision irrigation, which demand a specific
    configuration for reading data from meteorological stations and IoT sensors and
    actuators. Therefore, the work was divided into four sections in addition to this
    introduction and final considerations. In this article, Section 2 presents the
    materials and methods used in this review: data sources, filtering procedures,
    sorting of collected data and mapping of works, and development of pre-processing
    data package. Section 3 presents the research results; the proposed data pre-processing
    package is delivered. Finally, Section 4 presents final considerations and future
    work. SECTION II. Materials and Methods This section presents the classification
    procedures that describe the steps of the systematic review of the literature
    related to the investigated theme. This systematic review addresses recent projects
    and limits itself to presenting only Machine Learning applications aimed at precision
    irrigation practices, excluding proprietary use licenses. Therefore, in sections
    A, B, C, D and E, the research structure is presented, where a search string is
    elaborated, thus allowing the identification of the most relevant scientific works.
    Up to the definitions of the filtering procedures, the criteria for inclusion
    and exclusion of the publications, and, finally, the indications of the proposal
    for the development of a package in Python for pre-processing data in conventional
    meteorological stations. A. Search Protocol In this subsection, a search protocol
    is presented, as well as the data sources in which the most relevant publications
    are to be found. From these publications, those that exclusively address Machine
    Learning technologies aimed at precision irrigation practices by IoT devices are
    sought. The research was carried out between January and November 2022. In this
    sense, the works were identified by a search string applied to electronic data
    sources. The search string is as follows: (’’ machine learning’’ applied to ‘’precision
    irrigation’’). The definition of electronic data sources are: Google Scholar:
    https://scholar.google.com GitHub: https://github.com GitHub’s searchable database
    is considered an open-source software repository, and Google Scholar is a free
    and accessible search engine that organizes a variety of scientific and scholarly
    publication formats. After defining the search string and the data sources to
    be searched, the key terms corresponding to each search source were also created.
    Key terms are defined joins within the search string and separated by quotes.
    Table I presents the databases, the respective search strings, and the number
    of results obtained. Some tweaks within the Search Strings column are also presented.
    In the Google academic database line, exclusion attributes are added, and in the
    GitHub database lines, the search string was defined and applied by topic, as
    shown. In the scenario of Table I, the exclusion criteria was adopted according
    to the filtering procedures. However, 114 works were found in the GitHub repository,
    and the distribution of the tools found by languages adopted in their development
    are considered and presented, as shown in Table II. In addition, it is essential
    to highlight that machine learning algorithms that meet the requirements of the
    proposal of this review work need to be identified in their repositories. In this
    sense, only its distribution by a programming language is presented through the
    quantification of these works. Most of the implementations of the languages found
    in the works happen with Arduino and raspberry pi, their respective sensors and
    controllers. Displays databases, search strings, and results found. TABLE I Databases,
    Strings and Results B. Filtering Procedures After defining the search string in
    their databases, it was necessary to create and define the filtering procedures
    according to the inclusion and exclusion criteria. Inclusion criteria: The provisions
    of the included topics were any, and all ML works focused on precision irrigation
    that addresses or consist of open-source ML applications, also respecting the
    following conditions: Papers published between the years 2017 to 2022; Works only
    in the English language; Complete ML and open source work duly made available
    in repositories such as GitHub or equivalent; Source code of the software or application
    found on GitHub that has been updated at least once in the last six years from
    the date of its publication; Exclusion Criteria: Two exclusion criteria were defined,
    namely: Applications not related to ML and precision irrigation; Books and Games
    publication. TABLE II Distribution of Resources Or Language Applied At Work This
    systematic review includes ML applications available in the GitHub repository
    or similar, preferably with an associated scientific C. Data Collection Table
    III presents the quantification of the works found in their respective electronic
    databases. Three hundred twentysix (326) articles were identified in Google Scholar,
    and 114 works were distributed in the GitHub repository, ending with the identification
    of 440 publications. The sorting of works takes place by applying the filtering
    criteria. In this sense, after the filtering criteria, 307 works from the Google
    Scholar database and 114 works from the GitHub databases were excluded, thus excluding
    421 works. The works included are presented, of which 19 are from the Google database.
    Therefore, a new scenario is presented with 19 works corresponding to the proposal
    defined in the research objectives. TABLE III Research of Works Referring To the
    Years (2012 To 2022). After applying the filtering criteria, the 326 works found
    in Google Scholar are separated, and the topics of the abstracts and introduction
    are read. The intention was to filter the articles found that are related to the
    subject of Machine Learning and focused exclusively on precision irrigation solutions.
    It was also considered in the reading of the works the availability of the codes
    in the GitHub repository or similar. The 114 works found on GitHub are presented
    in table II. They will not be presented in table III, as they were not found in
    their repositories ML algorithm that can justify presentation and detail the work.
    D. Mapping of works The selected works were mapped and are detailed below; their
    reading can be done by indications such as: according to authors, title, models,
    techniques or library used, and a brief description of the work. Second [21],
    the work entitled: Field Deployment and Integration of Wireless Communication
    and Operation Support System for the Landscape Irrigation Runoff Mitigation System.
    Model, technique, or library used in the application: Scikit-learn and Regression.
    In this sense, a system was developed to support landscape irrigation in the quest
    to reduce runoff and water loss in the form of evaporation. The system aims to
    automate the precision irrigation process. It was designed based on the perception
    of multi-layer and implemented using a dedicated web server. The applied ML processes
    historical, environmental and temporal data and indicates the schedule of the
    best day to irrigate the researched crop. The author evaluates his research, but
    points out that more tests are needed to quantify water savings better. Second
    [22], the work entitled: A Smart Precision Irrigation and Monitoring System. Model,
    technique, or library used in the application: ML Azure. In this sense, a project
    of an irrigation system is presented here, with precision monitoring, involving
    technologies of the internet of things (IoT) and ML Azure. They were implemented
    using sensors to collect water level, temperature, and soil moisture data. Azure
    cloud services were used for real-time data analysis. The applications were made
    available in Web App and Mobile App format to provide the best support to the
    farmer. Facilitating the management and control of irrigation processes automatically.
    Second [23], the work entitled: Advancing IoT-based smart irrigation. Model, technique,
    or library used in the application: Regression. In this sense, this work resulted
    in a SWAMP platform being implemented with IoT-ML architecture. Allowing us to
    manage water in the irrigation process in a customizable way. From the connectivity
    between the data, the physical model, and the ML algorithm being unified in a
    single interface. The author considers the solution suitable for various soil,
    plant, and regional climate characteristics. However, it presents its results
    as research in progress and needs to present problems solved with the applied
    ML model. Second [24], the work entitled: Smart & green: An internet-of-things
    framework for intelligent irrigation. Model, technique, or library used in the
    application: Gradient Boosting. In this sense, in this work, the author proposes
    the use of a SmartGreen framework, which makes use of the functionalities of data
    monitoring, pre-processing, merging, synchronization, storage, and finally, performs
    the management of precision irrigation by predicting the soil moisture. According
    to the author, it is possible to reuse the codes for different sets or groups
    of crops, soils, and meteorological data sources. Therefore, the researched and
    applied ML techniques were used to solve the soil moisture prediction problem.
    Second [25], the work entitled: Soil Moisture and Rain Prediction Based Irrigation
    Controller for the Strawberry Farm of La Trinidad, Benguet. Model, technique,
    or library used in the application: Neural Network. In this sense, it was the
    development of a system that controlled the irrigation of the strawberry crop.
    Data is collected in real-time by soil moisture sensors and data from meteorological
    stations. The procedures used by automation controller systems have been shown
    to improve in the initial phase of crop growth and be effective in the water supply.
    According to the author, the ML model can be adopted for forecasting rainfall
    and automatic irrigation control. Second [26], the work entitled: IoT and machine
    learning approaches for automation of farm irrigation system. Model, technique,
    or library used in the application: SVM (Support Vector Machine) and SVR (Support
    Vector Regression. In this sense, the work presents an automated monitoring system
    for home gardens. The proposal was to present the models of ML Support Vector
    Machine (SVM) and Support Vector Regression (SVR). With quantitative bases of
    classification and prediction of the type of soil, culture, and amount of water
    required by the culture. This research was carried out in India. In addition to
    the tests applied by ML, the forms of connectivity by various types of IoT devices
    seek to ensure and improve the continuous flow of data and implemented activities.
    Second [27], the work entitled: Using machine learning methods to provision virtual
    sensors in sensor-cloud. Model, technique, or library used in the application:
    k-means. In this sense, this work seeks to explore the k-means algorithm to group
    the data of the physical sensors implemented with the sensing data collected.
    Before implementing the clustering algorithm, the linear regression method was
    applied to analyze the tendency of change of each physical sensor. In summary,
    the authors concluded that it was possible to use fewer physical sensors to provide
    the same services with better quality. The experimental results indicate that
    the approach was efficient and suitable for provisioning tasks with the indicated
    virtual sensors. Second [28], the work entitled: Implementation of precision soil
    and water conservation agriculture (PSWCA) through machine learning, cloud-enabled
    IoT integration, and wireless sensor network. Model, technique, or library used
    in the application: Decision tree, k-NN, SVM, and logistic regression. In this
    sense, a new methodology was presented in this work, allowing the integration
    of the Internet of Things (IoT) of wireless sensor networks with cloud applications.
    The proposal focuses on precision irrigation to improve soil conservation and
    accurate water application, applied through machine learning. Its operation happens
    with the data being captured in realtime and sent to the Raspberry Pi module.
    A machine learning algorithm was embedded in the Raspberry Pi module to predict
    the amount of water and fertilizer required by the plants and then released for
    punctual irrigation. According to the authors, it was observed that the ML technique
    used in the proposal reached the objectives and improved the amount of water and
    fertilizer applied compared with the traditional programmed and automatic irrigation.
    Second [29], the work entitled: Soil water content and actual evapotranspiration
    predictions using regression algorithms and remote sensing data. Model, technique,
    or library used in the application: Regression. In this sense, this work presents
    an ML model that can predict water management. Shapes are parameterized with vegetation
    indices, and regression algorithms are used to enable the management of precision
    irrigation to happen entirely remotely. For this, six regression algorithms were
    selected and compared with field data with the corn crop. The ML models were adjusted,
    and, according to the authors, the real potential of vegetation indices is demonstrated
    to provide information for the management of irrigated cultivation and reinforce
    the capacity of regression algorithms in this controlled environment of precision
    irrigation. Second [30], the work entitled: IoT-IIRS: Internet of Things based
    intelligent-irrigation recommendation system using machine learning approach for
    efficient water usage. Model, technique, or library used in the application: Scikit-learn
    regression tree, Classification, SVM. In this sense, an analysis system applied
    with ML was the primary building block proposed in this work. Sensors capture
    soil and environment data, are stored, and the regression tree algorithm is applied,
    making it possible to predict and contribute to precision irrigation. Past weather
    data is combined with real-time generated soil data and fed into the classification
    model. Then, the considered classifier system categorizes the data samples and
    verifies whether or not there is a need for irrigation at that time. According
    to the authors, in this way, the ML technique helps the farmer with the suggestion
    of precision irrigation for planting. The applied experimental results demonstrate
    that the SVM-based model outperforms other models in both datasets. Second [31],
    the work entitled: Comparison of Machine Learning Regression Models for Prediction
    of Soil Moisture with the use of Internet of Things Irrigation System Data. Model,
    technique, or library used in the application: Gradient Boosted Regression Tree
    (GBRT), Random Forest (RF), MLR, and Elastic Net Regression (ENR). In this sense,
    this work presents a prototype of a precision irrigation system based on IoT devices.
    Data were collected for half an hour a day, and for 55 days, they were stored
    in the cloud with the help of the ThingSpeak tool. Soil moisture values are estimated
    by applying different regression models, linear multiples, polynomials, support
    vectors, decision trees, and random regression applied to data collected by IoT
    devices. According to the authors, to examine whether the algorithms were successful,
    they were compared according to the coefficient of determination and the mean
    error criteria obtained. Finally, the random forest regression model was superior
    to other machine learning models for soil moisture estimation. The presented results
    also show that GBRT has outperformed the other tested methods. Second [32], the
    work entitled: An ai based irrigation and weather forecasting system utilizing
    lorawan and cloud computing technologies. Model, technique, or library used in
    the application: Wind Driven Optimization - Least Square Support Vector Machine.
    In this sense, this work presents an initial project of a precision irrigation
    system, which uses a ChirpStack open-source LoRaWAN network server and a processing,
    storage, management, and data integration structure as its leading technology.
    In order to predict the required irrigation using meteorological data. A new forecast
    model is also presented to predict the best climatic moments and suggest its application.
    According to the authors, the Wind Driven Optimization algorithm and Least Square
    Support Vector Machine were used in this experiment. The results are demonstrated
    and point out that the algorithm proposed in this research outperforms the Least
    Square Support Vector Machine algorithm currently widely used for weather forecasting,
    which can prove the effectiveness of the proposed algorithm. Second [33], the
    work entitled: Machine learning and soil humidity sensing: Signal strength approach.
    Model, technique, or library used in the application: SVR and Long Short-Term
    Memory (LSTM) neural network. In this sense, this work builds two ML models that
    are evaluated and compared, the SVR model and the LSTM model. Both models presented
    used the same data and were validated similarly. The main objective of building
    these models is the interpretation and accurate estimation of the relative humidity
    of the soil based on the intensity of the emitted or captured signal. The authors
    present the models and consider that they were used from 13,900 samples captured
    by two LoRaWAN Gateways and soil moisture data. They consider the application
    of the researched models to be favorable. Second [34], the work entitled: Modeling
    soil water content and reference evapotranspiration from climate data using the
    deep learning method. Model, technique, or library used in the application: CNC,
    LSTM, SVR. In this sense, a comparison research was developed between the ML models
    of Long Short-Term Memory (LSTM) to predict two pre-defined critical parameters
    of evapotranspiration. A Convolutional Neural Network (CNC) DL model overlays
    the LSTM model to investigate the performance of the CNC-LSTM model compared to
    the LSTM. Model performance is also compared against CNC and traditional machine
    learning algorithms such as Support Vector Regression (SVR) and Random Forest.
    The performance of the LSTM algorithm was also compared with the Random Forest,
    SVR, and CNN algorithms. According to the authors, the best performance of these
    algorithms was LSTM. The second-best performance was obtained with the CNC model.
    However, the RF model outperformed the SVR model among machine learning methods.
    Second [35], the work entitled: Modeling soil water content and reference evapotranspiration
    from climate data using the deep learning method. Model, technique, or library
    used in the application: LSTM. In this sense, a predictive system model is proposed
    in this work. It was developed for automatic precision irrigation programming
    using discrete actuators. An LSTM model was used to control soil, water, and atmosphere
    to evaluate and guarantee crop absorption. Thus minimizing water consumption and
    improving costs for precision irrigation. According to the authors, a heuristic
    method involving a sigmoid function was used, and a framework was also used to
    increase the computational efficiency of the scheduler. Second [36], the work
    entitled: IoT-Driven Model for Weather and Soil Conditions Based on Precision
    Irrigation Using Machine Learning. Model, technique, or library used in the application:
    Linear (LR) and non-linear K-nearest neighbor (KNN) logistic regression, classification
    and regression trees (CART), Gaussian naive Bayes (NB) and support vector machines
    (SVM)). In this sense, a system was proposed to predict the crop’s water requirement
    based on soil and climate conditions. Machine learning algorithms are applied,
    providing the ability to predict the need for precision irrigation. The data set
    from soil and climate conditions were captured by sensors and tested with six
    different machine-learning algorithms. Selected the best way to offer forecasts
    with greater efficiency for crop irrigation. According to the authors, the machine
    learning techniques used were linear logistic regression (LR) and non-linear K-nearest
    neighbor (KNN), classification and regression trees (CART), Gaussian naive Bayes
    (NB) and vector machines of support (SVM). In addition, they present the agricultural
    applications that are frequently applied with the SVM, K-nearest neighbor (KNN),
    and Gaussian naive Bayes (NB) algorithms and their results. Second [37], the work
    entitled: Water optimization technique for precision irrigation system using IoT
    and machine learning. Model, technique, or library used in the application: K-Nearest
    Neighbors (KNN), Gradient Boosting-based Tree (GBT), Long Short-Term Memory (LSTM).
    In this sense, the work proposes a hybrid precision irrigation system model. The
    same consists of K-Nearest Neighbors (KNN), Gradient Boosting-based Tree (GBT),
    and Long Short-Term Memory (LSTM) ML models, and their correlations are compared.
    The KNN model is implemented to gather information and detect the closest data.
    The GBT model was used to predict the actual values to be applied based on the
    observations of this research. Finally, the LSTM model was also used for time
    series forecasting in different forms of environmental observations. According
    to the authors, Spearman rank correlation was used to receive the values and correlate
    them with the real-time and applied time-series forecasts. Second [38], the work
    entitled: A Cloud Enabled Crop Recommendation Platform for Machine Learning-Driven
    Precision Farming. Model, technique, or library used in the application: K-Nearest
    Neighbors (KNN), Decision Tree (DT), Random Forest (RF), Extreme Gradient Boosting
    (XGBoost), and Support Vector Machine (SVM). In this sense, a new precision irrigation
    recommendation platform for crops, based on cloud ML, aims to help farmers to
    decide which times the crops need to be irrigated. In this sense, five predictive
    ML algorithms were compared - K-Nearest Neighbors (KNN), Decision Tree (DT), Random
    Forest (RF), Extreme Gradient Boosting (XGBoost), and Support Vector Machine (SVM).
    According to the authors, the ML algorithm was used to identify the best performers
    to build a recommendation platform. As a result, offer a cloud-based recommendation
    service to create a solution for precision agriculture. Second [39], the work
    entitled: Regional soil moisture prediction system based on Long Short-Term Memory
    network. Model, technique, or library used in the application: LSTM. Finally,
    a precision irrigation forecasting system was developed based on the climate and
    soil moisture dataset. Therefore, an open-source and meteorological dataset issued
    by the Copernicus Climate Change Service was used in this research. Data were
    captured daily on maximum and minimum air temperature, precipitation, and vapor
    pressure deficit. These data were used to feed the neural network model and predict
    soil moisture. A Short-Term Long Memory (LSTM) network model was designed and
    trained at scale, using data between 2011 and 2016. According to the authors,
    the LSTM model was compared with statistical forecasting techniques and a classic
    machine learning approach. Finally, [40] presents the results of a proposed low-cost
    irrigation monitoring system that can be an attractive solution for farmers, as
    they are easy to implement, do not require high acquisition or maintenance costs
    and can be accessible to users with low technical skills or with different levels
    of digital exclusion. E. Package Construction To build the package, the Python
    language was used with GitHub integration and available at the link https://github.com/rps-ifpr/station
    data, and Pypi, available at the link https://pypi.org/project/onestation The
    raw data from the conventional stations treated in this research are available
    on the Kaggle website at the link, https://www.kaggle.com/datasets/rogerioifpr/brazil-weatherconventional-stations-19612019,
    are meteorological data observed in conventional meteorological stations of the
    Institute Nacional de Meteorologia - INMET distributed in Brazilian territory
    from 1961 to 2019. The variables presented and treated in this research are Weather
    station code, Date, Time, Precipitation, Dry bulb temperature, Wet bulb temperature,
    Maximum temperature, Minimum temperature, Relative Humidity, Station Atmospheric
    Pressure, Atmospheric Pressure at Sea Level, Wind Direction, Wind Speed, Insolation,
    Cloudiness, Pitch Evaporation, Average Compensated Temperature, Average Relative
    Humidity and Average Wind Speed. SECTION III. Results and Proposal This section
    presents the results of works collected from the literature related to the subject
    of studies and a brief discussion about the ML works addressed in this work. The
    various applications and software found throughout this research are grouped as
    mentioned and presented in Tables II. Soon after, a proposal for a pre-processing
    package of data from meteorological stations will be presented to assist developers
    and those interested in applying ML for precision irrigation control by IoT devices.
    The proposal meets the needs of cleaning data in a complete and quality way for
    ML or DL models. Table II represents the works found in the GitHub repository
    that were not related to ML, only as irrigation solutions applied by software.
    The control of automation and IoT devices is mentioned in almost all works. But,
    it is essential to consider that the Python language has its prominence together
    with the C++ language, considering that most of the results are carried out by
    Arduino devices. In the survey, as presented in sub section 2 (D), it is observed
    that the repositories link was not given. Because 100% of the works researched
    in the total of 19 found do not have their open code or the source available in
    any repository, another consideration is that among the researched works, 95%
    need to clarify the code used in the construction but only apply the mathematical
    model. Making access difficult for developers and collaborators who could be improving
    or continuing the project. Also limited is the access of farmers who could have
    greater access to an application as a final product. Of the works raised, there
    are some particularities to be reported. It is considered that 30% of the results
    do not present the type of culture used in the application testing process, so
    it was decided to remove this topic from subsection 2(D). We also did not find
    ML prediction models applied in conjunction with data generated by IoT devices
    in real-time in 100 percent of the papers. As analyzed in this research, the works
    present their results but need to demonstrate how the data pre-processing was
    carried out at the beginning of the process. Implementing an ML algorithm to make
    predictions is possible even with improper data treatment. There is a glamor to
    the works presented, but it is essential to understand and maintain the data with
    adequate quality. Therefore, it needs to be clarified how the pre-processing of
    these data is carried out, it is also observed that the indications of the databases
    applied in their research are also found, and several non-conformities of the
    links indicated in their works were also found. In this sense, in the next section,
    we present a proposal for a library or data pre-processing package for conventional
    meteorological stations. A. Package Proposal Considering the growing trend of
    irrigation applications applied with current languages and IoT devices generating
    real-time data, this section will present a proposal for a pre-processing data
    package to assist developers and those interested in the application of ML aimed
    at precision irrigation and which makes use of data generated by conventional
    meteorological stations. Fig. 1. Onestation - Proposal model for pre-processing
    data package for conventional meteorological stations. Show All An implementation
    called one station to assist in preprocessing data generated by conventional weather
    stations for Machine Learning applied to precision irrigation. The pre-processing
    package facilitates data cleaning and transformation, as shown in (Fig.1). The
    data is collected and transmitted to the database. The package performs the cleaning
    and transformation of these data, preparing them for use in ML, which can be used
    for analysis and modeling aimed at precision irrigation. A basic object-oriented
    design with separate classes for data cleaning and additional class structure
    documentation is contained in the source files as presented in the source code
    available at https://github.com/rps-ifpr/station data and on Pypi at https://pypi.org/project/onestation.
    Data from the conventional stations used in this research are available at https://www.kaggle.com/datasets/rogerioifpr/brazil-weatherconventional-stations-19612019.
    Considerations and Future Work In this article, a systematic review of the literature
    on Machine Learning (ML) applications, preferably open source, aimed at precision
    irrigation practices applied by IoT devices, was carried out. Followed by a proposal
    for a pre-processing package of data from conventional meteorological stations
    for developers and professionals looking for ML applications aimed at precision
    irrigation. In this sense, works were selected, mapped, and presented that contribute
    to understanding applications and ML models for precision irrigation supported
    by IoT devices. Seeking to understand the data cleaning and treatment forms and
    the indications of the databases (datasets) used in developing the presented applications.
    To achieve the best understanding of this research, the mapping and detailing
    of the selected works were carried out according to subsection 2(D) of this research.
    This research study advances the understanding of ML applications aimed at precision
    irrigation and IoT devices. It is possible to conclude with the analysis of this
    study that most open-source ML algorithms are still under construction. The practices
    adopted by the authors were presented, pointing to the need to expand open-source
    ML applications and their advantages, thus improving the quality of production
    of ML applications aimed at precision irrigation, thus avoiding damage to water
    resources in agriculture. None of the applications presented their source code
    and were made available in repositories by the researched authors. All results
    were included in the research work itself. Future ML applications are expected
    to be open source and available in public repositories, such as GitHub or similar,
    enabling testing and improvements by the entire community involved. It is believed
    in the quality of software and open-source products aimed at precision irrigation,
    integrating real-time data generated by IoT devices. Finally, a proposal for a
    preprocessing package of data from conventional meteorological stations was presented.
    The package development results were presented; however, tests for the conclusions
    of this work still need to be completed. As an indication of future work, it is
    intended to test the developed package with data from automatic stations and integrate
    data generated by IoT devices. Improve data integration and communication between
    different IoT devices. Moreover, finally, understand how the presented package
    behaves in different ML or DL application models presenting real-time prediction.
    ACKNOWLEDGMENTS This work was supported by National Funds through the Fundação
    para a Ciência e a Tecnologia, I.P. (Portuguese Foundation for Science and Technology)
    by the Project “VALORIZA-Research Center for Endogenous Resource Valorization”
    under Grant UIDB/05064/2020. This research was partially funded by Fundação para
    a Ciência e a Tecnologia under Project UIDB/04111/2020. Authors Figures References
    Citations Keywords Metrics More Like This Internet of Things and Machine Learning
    based Intelligent Irrigation System for Agriculture 2022 5th International Conference
    on Contemporary Computing and Informatics (IC3I) Published: 2022 Automatic Medication
    Dispensing System using Machine Learning, Internet of Things and Cloud Computing
    2022 International Conference on Disruptive Technologies for Multi-Disciplinary
    Research and Applications (CENTCON) Published: 2022 Show More IEEE Personal Account
    CHANGE USERNAME/PASSWORD Purchase Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS
    Profile Information COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION TECHNICAL
    INTERESTS Need Help? US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT
    & SUPPORT Follow About IEEE Xplore | Contact Us | Help | Accessibility | Terms
    of Use | Nondiscrimination Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy
    Policy A not-for-profit organization, IEEE is the world''s largest technical professional
    organization dedicated to advancing technology for the benefit of humanity. ©
    Copyright 2024 IEEE - All rights reserved."'
  inline_citation: '>'
  journal: Proceedings - 2023 6th Conference on Cloud and Internet of Things, CIoT
    2023
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Package Proposal for Data Pre-Processing for Machine Learning Applied to
    Precision Irrigation
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Kang Y.
  - Chen P.
  - Cheng X.
  - Zhang S.
  - Song S.
  citation_count: '7'
  description: The accurate estimation of reference evapotranspiration (ETo) is a
    fundamental requirement for precision irrigation and regional water resource planning.
    In this regard, the application of the standard model, FAO-56 Penman–Monteith,
    is limited because of insufficient meteorological data. This study aims to improve
    the accuracy of ETo calculations in regions with scarce meteorological data. A
    hybrid model integrating two data preprocessing methods (variational mode decomposition
    (VMD) and Box–Cox transformation (BC)) into a support vector machine (SVM) model
    (VMD–BC–SVM) is proposed. The model estimates the daily ETo based on the meteorological
    data (1980–2019) of 10 stations in the Wei River Basin of China. The VMD method
    was employed to extract multiple intrinsic mode functions (IMFs) and eliminate
    non-stationarity. This is achieved by decomposing meteorological factors, which
    are further transformed by BC to alleviate skewness characteristics. The least
    absolute shrinkage and selection operator regression (LASSO) identifies the key
    driving modes from the transformed IMFs, which are used as the input of the SVM
    model. The VMD–BC–SVM estimation model framework based on decomposition–transformation–identification–estimation
    is proposed. The performance of each of the hybrid VMD–BC–SVM models was further
    compared with those of the standalone extreme learning machine (ELM) model and
    two empirical models (Hargreaves–Samani and Priestley–Taylor models). The results
    revealed that the hybrid models outperformed the single models. The VMD–BC–SVM
    model achieved higher accuracy compared with the other models. Specifically, the
    coefficient of correlation (R) and Nash–Sutcliffe efficiency coefficient (NSE)
    were both greater than 0.96. Furthermore, the mean absolute percentage error (MAPE)
    and root mean square error (RMSE) were less than 8.41% and 0.38 mm/d, respectively.
    In terms of the amount of information provided, the VMD–BC–SVM model is superior
    to empirical models in identifying high-dimensional and nonlinear information.
    Moreover, the estimation performance is more stable, and the level of uncertainty
    is lower. This study provides a novel approach for predicting ETo in regions with
    limited meteorological data.
  doi: 10.1016/j.agwat.2022.107882
  full_citation: '>'
  full_text: '>

    "Skip to main content Skip to article Journals & Books Search Register Sign in
    Brought to you by: University of Nebraska-Lincoln View PDF Download full issue
    Outline Highlights Abstract Keywords 1. Introduction 2. Materials and methods
    3. Results 4. Discussion 5. Conclusion Declaration of Competing Interest Acknowledgments
    Appendix A. Supplementary material Data availability References Show full outline
    Cited by (7) Figures (9) Show 3 more figures Tables (10) Table 1 Table 2 Table
    3 Table 4 Table 5 Table 6 Show all tables Extras (1) Supplementary material Agricultural
    Water Management Volume 273, 1 November 2022, 107882 Novel hybrid machine learning
    framework with decomposition–transformation and identification of key modes for
    estimating reference evapotranspiration Author links open overlay panel Yan Kang
    a b, Peiru Chen a, Xiao Cheng a, Shuo Zhang a, Songbai Song a b Show more Add
    to Mendeley Share Cite https://doi.org/10.1016/j.agwat.2022.107882 Get rights
    and content Highlights • A novel VMD-BC-SVM approach was proposed to estimate
    ETo. • VMD and Box-Cox were used to remove the non-stationarity and skewness of
    inputs. • LASSO regression was used to identify the key driving modes as optimal
    input. • VMD-BC-SVM model outperforms comparison models for estimation ETo. Abstract
    The accurate estimation of reference evapotranspiration (ETo) is a fundamental
    requirement for precision irrigation and regional water resource planning. In
    this regard, the application of the standard model, FAO-56 Penman–Monteith, is
    limited because of insufficient meteorological data. This study aims to improve
    the accuracy of ETo calculations in regions with scarce meteorological data. A
    hybrid model integrating two data preprocessing methods (variational mode decomposition
    (VMD) and Box–Cox transformation (BC)) into a support vector machine (SVM) model
    (VMD–BC–SVM) is proposed. The model estimates the daily ETo based on the meteorological
    data (1980–2019) of 10 stations in the Wei River Basin of China. The VMD method
    was employed to extract multiple intrinsic mode functions (IMFs) and eliminate
    non-stationarity. This is achieved by decomposing meteorological factors, which
    are further transformed by BC to alleviate skewness characteristics. The least
    absolute shrinkage and selection operator regression (LASSO) identifies the key
    driving modes from the transformed IMFs, which are used as the input of the SVM
    model. The VMD–BC–SVM estimation model framework based on decomposition–transformation–identification–estimation
    is proposed. The performance of each of the hybrid VMD–BC–SVM models was further
    compared with those of the standalone extreme learning machine (ELM) model and
    two empirical models (Hargreaves–Samani and Priestley–Taylor models). The results
    revealed that the hybrid models outperformed the single models. The VMD–BC–SVM
    model achieved higher accuracy compared with the other models. Specifically, the
    coefficient of correlation (R) and Nash–Sutcliffe efficiency coefficient (NSE)
    were both greater than 0.96. Furthermore, the mean absolute percentage error (MAPE)
    and root mean square error (RMSE) were less than 8.41% and 0.38 mm/d, respectively.
    In terms of the amount of information provided, the VMD–BC–SVM model is superior
    to empirical models in identifying high-dimensional and nonlinear information.
    Moreover, the estimation performance is more stable, and the level of uncertainty
    is lower. This study provides a novel approach for predicting ETo in regions with
    limited meteorological data. Previous article in issue Next article in issue Keywords
    Variational mode decompositionBox–Cox transformationSupport vector machineLeast
    absolute shrinkage and selection operatorWei River Basin 1. Introduction Reference
    evapotranspiration (ETo) is an essential variable for estimating crop water requirements
    and plays a key role in water resource management in irrigated areas (Paredes
    et al., 2018, Valle Júnior et al., 2020, Fan et al., 2021). The estimation methods
    for ETo include empirical formulae and measurement methods, which require personnel
    and equipment and have limitations and high costs (Gomariz-Castillo et al., 2017,
    Shirmohammadi-Aliakbarkhani and Saberali, 2020). Accordingly, the use of the empirical
    formula has become the main technique for estimating ETo. The United Nations Food
    and Agriculture Organization (FAO) has endorsed the FAO-56 Penman–Monteith (FAO-56P–M)
    model as the standard method for estimating ETo (Allen et al., 1998) that comprehensively
    considers the driving effect of various meteorological variables. However, the
    application of the FAO-56P–M model is limited by its high dependency on meteorological
    factors. Therefore, simplifying the ETo estimation is necessary using techniques,
    such as the Hargreaves–Samani (H–S) (Hargreaves et al., 1985), Priestly–Taylor
    (P–T) (Priestley et al., 1972), Makkink (Chen et al., 2018), and 48 Penman models
    (Qualls and Crago, 2020). However, the lack of meteorological data results in
    low model estimation accuracy and inadequate universality. Consequently, researchers
    have explored non-linear approaches to improve the estimation accuracy. Machine
    learning models have been broadly applied to ETo modeling (Ferreira and da Cunha,
    2020) in data-scarce regions. These models include neural networks (Abdullah et
    al., 2015, Feng et al., 2016, Antonopoulos and Antonopoulos, 2017), support vector
    machines (SVMs) (Kundu et al., 2016; Ehteram et al., 2019; Chia et al., 2020;
    Mohammadi and Mehdizadeh, 2020), and tree-based assembly models (Fan et al., 2018,
    Huang et al., 2019, Zhang et al., 2020, Wu et al., 2020). Wen et al. (2015) developed
    four input combination strategies based on temperature data. They constructed
    an SVM model to estimate ETo in the absence of meteorological data in arid areas.
    The accuracy of the model was found to be higher than those of the Priestley–Taylor
    and empirical models. The implementation of machine learning models in ETo estimation
    was investigated by Mohammadi and Mehdizadeh (2020). They also proved that SVM
    had excellent estimation accuracy when applied to three different climate stations
    in Iran (including arid, semi-arid, and humid regions) based on different types
    of meteorological combinations. Another study was conducted by Feng et al. (2017)
    to compare the performance of extreme learning machine (ELM) and generalized regression
    neural network (GRNN) models in estimating ETo with temperature-based data. The
    ELM model was found to provide slightly better estimates of ETo than the GRNN
    and Hargreaves models. Published articles in literature report that SVM and ELM
    are widely applied to ETo calculation, both yielding satisfactory estimates. In
    addition, the stability of the SVM structure enables it to be used as a fundamental
    model for developing different data processing methods. Researchers have developed
    many models for ETo estimation using different meteorological factors, indicating
    that ETo mainly depends on meteorological factors. However, the meteorological
    factors affecting ETo are complex, highly non-stationary, and seasonally irregular.
    Therefore, achieving satisfactory accuracy for daily ETo estimation using a single
    model with meteorological factors as inputs is difficult if collected data are
    not preprocessed. Over the last few years, hybrid models have received considerable
    attention because of their improved simulation ability in terms of ETo estimation.
    To reduce the complexity and non-stationarity of an original time series and improve
    estimation accuracy, many authors have introduced signal decomposition techniques
    (Feng et al., 2014; Gocić et al., 2015; Luan, 2017; Qasem et al., 2019). These
    methods include empirical mode decomposition (EMD) and wavelet transform (WT),
    which decompose meteorological data into a relatively stable sub-series and enhance
    the correlation between ETo and meteorological factors. The successful modeling
    results of these studies confirmed the suitability of decomposition techniques
    for enhancing machine learning models. Fu et al. (2021) proposed hybrid models
    for estimating the monthly ETo coupled with discrete WT (DWT), ensemble EMD (EEMD),
    and variational mode decomposition (VMD) to decompose ETo and extract the main
    variation features. Their proposed models ignored the non-stationarity and complexity
    of meteorological factors. The VMD-based model was found to have higher estimation
    accuracy than the DWT and EEMD (Fu et al., 2021). The VMD technology has achieved
    remarkable results in multidisciplinary fields (Guo et al., 2020; Sun and Zhao,
    2020; Feng et al., 2020; Li et al., 2021; Carvalho and de Assis de Souza Filho,
    2021). However, the technology has not been developed for daily ETo estimation
    by decomposing meteorological factors. It is a completely non-recursive signal
    decomposition method based on the frequency domain (Dragomiretskiy et al., 2014).
    Compared with EMD and WT techniques, VMD not only overcomes the endpoint effect
    and mode aliasing problems existing in EMD but also reduces the model test steps,
    improves the model accuracy, and does not require choosing a basis function as
    WD. The decomposition of meteorological factors using VMD not only solves the
    limitation of ETo estimation in data-scarce regions but also affects the use of
    non-stationary input factors in model estimation. Owing to the high non-stationarity
    and intrinsic complexity of meteorological factors, combining VMD methods to establish
    a hybrid estimation model without adequate meteorological data is highly desirable.
    Decomposition technology can effectively improve data stability (Song et al.,
    2021); however, it does not consider the influence of data symmetry and variance
    homogeneity on simulation accuracy. To resolve these problems, researchers have
    focused on data transformation methods. Amin et al. (2019) devised a model using
    data transformation methods and presented an extensive comparison to validate
    the impact of these methods. The results demonstrated that most data transformation
    methods improve model performance. The Box–Cox transformation (BC) has been widely
    applied to the field of signal science (Cai et al., 2021, Wang et al., 2021),
    hydrology frequency analysis, and calculations (Seong, 2014). However, no study
    on ETo estimation and meteorological factor transformation has ever been conducted.
    The BC method belongs to the family of power transformation methods (Box and Cox,
    1964). It not only improves data smoothness, symmetry, and the homogeneity of
    variance and retains the information of the original dataset but also enhances
    the correlation between meteorological factors and ETo. In view of its importance
    in hydroclimatic research, the reliable estimate and modeling of ETo using a series
    of new methods are highly preferred. The improvement of model performance to estimate
    ETo by creating hybrid models (such as those integrated with a decomposition technique)
    has been well demonstrated. Accordingly, the present study aims to incorporate
    the ability to model the daily ETo accurately using a hybrid data preprocessing
    technique combined with VMD and BC. The input variables of the models can affect
    their estimation accuracy. Some researchers have proposed using meteorological
    factors as model inputs to estimate ETo (Pammar et al., 2017; Feng et al., 2017;
    Chia et al., 2020). Fu et al. (2021) used the decomposition series of history
    ETo as input for machine learning. Meteorological elements are non-stationary
    and complex; however, the foregoing studies did not consider the decomposition
    of meteorological factors. Some scholars have proposed estimating ETo by considering
    all the modes (i.e., intrinsic mode functions (IMFs)) of decomposed meteorological
    factors as model input and achieved satisfactory results (Gocić et al., 2015,
    Qasem et al., 2019). Evidently, the input variable of the model is the foremost
    problem in ETo simulation; hence, it is a topic worthy of in-depth discussion.
    However, the driving effects of different modes of meteorological factors on ETo
    estimation have not been explored in the aforementioned research works. Whether
    some modes of meteorological factors have a more effective driving effect on ETo
    estimation than others remain to be further examined. This must be expected to
    avoid the overfitting risk of models and improve the estimation ability by introducing
    mode identification. Yu et al. (2022) identified the optimal feature after eliminating
    the redundant features using the least absolute shrinkage and selection operator
    (LASSO), which effectively reduces the model complexity. The LASSO regression,
    a variable selection method for nonnegative disturbance excitations (Sethi and
    Mittal, 2021), is a popular method for high-dimensional applications in machine
    learning. As such, LASSO can be used to identify the key driving modes of the
    decomposed meteorological factors in this study. The study is aims to achieve
    the following. 1) Decompose the meteorological factors into different modes (IMFs)
    using VMD and thus overcome the influence of highly non-stationary inputs on model
    estimation. 2) Normalize IMFs by employing BC to reduce the skewness of the meteorological
    factors. 3) Identify the optimal key modes (IMFs) of each meteorological factor
    as the SVM input using LASSO. 4) Develop a novel hybrid VMD–BC–SVM model incorporating
    “decomposition–transformation–identification–estimation” and test it using the
    daily meteorological factors collected from the Wei River Basin. 5) Evaluate the
    performance of VMD–BC–SVM by comparing it with single and empirical models using
    evaluation indices and a mutual information neural estimator (MINE). 2. Materials
    and methods 2.1. Study area and data This study is conducted in the Wei River
    Basin (China), which is the first tributary of the Yellow River. The basin has
    a trunk length of 818 km. It is located between 103.5° and 110.5°E and 33.5–37.5°N,
    covering an area of approximately 13.5 × 104 km2 (Chen et al., 2021). The basin
    is located in the transition zone between arid and semi-arid regions and has a
    continental monsoon climate. Because of topography, precipitation is unevenly
    distributed in space. Precipitation decreases from the southeast to the northwest
    (Xu et al., 2021) with an annual average of 500–800 mm; the surface evaporation
    is 700–1000 mm. The study was conducted in 10 meteorological stations from the
    national web with different geographical characteristics. Four stations (Wugong
    and Xiji stations in the mainstream district and Wuqi and Xifeng stations in the
    Jing River and Beiluo River) were used as representatives of each district to
    describe the modeling process in detail. Data from the other six stations were
    used to analyze the applicability of the models to the Wei River Basin. The locations
    of the meteorological stations were identified on the map shown in Fig. 1. Daily
    meteorological data were collected from the China Meteorological Data Network
    (http://data.cma.cn) from 1980 to 2019 (data points). These include the maximum,
    minimum, and mean temperatures (Tmax, Tmin and Tmean, respectively), relative
    humidity (RH), wind speed at a height of 10 m (u10), and sunshine duration (SSD).
    The datasets were measured and collected at the elevations of the meteorological
    stations and were representative of regional weather conditions. To determine
    partially missing meteorological data, the Lagrange interpolation method was used
    because of its robustness and capability to flexibly adjust data order (Prasopchingchana,
    2022). The datasets were classified into two parts: model training (1980–2007)
    and testing (2008–2019). Details of the stations are summarized in Table 1. Download
    : Download high-res image (218KB) Download : Download full-size image Fig. 1.
    Locations of meteorological stations in the study area. Table 1. Details and mean
    values of meteorological data for different stations from 1980 to 2019. ID Stations
    Longitude (N) Latitude (E) Elevation (m) Tmean (℃) Tmax (℃) Tmin (℃) U10 (m/s)
    SSD (h) RH (%) 53738 Wuqi 108°01′ 36°55′ 1331.4 8.27 16.21 2.01 1.41 6.77 60 53929
    Wugong 108°13′ 34°15′ 447.8 13.6 19.29 9.14 1.38 4.85 71 57016 Xiji 105°43′ 35°58′
    1916.5 6.01 13.13 0.42 1.90 6.33 65 53923 Xifeng 107°38′ 35°44′ 1421 9.46 14.49
    5.45 2.20 6.63 61 53942 Huajialing 105°01′ 35°23′ 2450.6 4.09 8.78 0.89 4.74 6.6
    70 53942 Luochuan 109°25′ 35°46′ 1159.8 10.05 15.95 5.05 2.05 6.79 61 53821 Huanxian
    107°18′ 36°34′ 1255.6 9.38 16.50 3.62 1.78 6.91 58 53929 Changwu 107°48′ 35°12′
    1206.5 9.57 15.66 4.49 2.13 5.66 68 53942 Baoji 107°08′ 34°21′ 612.4 14.4 19.15
    9.68 3.05 5.25 72 57016 Tianshui 105°45′ 34°35′ 1141.6 11.59 17.62 7.04 2.20 6.47
    66 2.2. Data preprocessing 2.2.1. Variational modal decomposition The VMD technique,
    an adaptive and completely non-recursive mode variational and signal processing
    method (Dragomiretskiy and Zosso, 2014), is an effective separation and frequency
    domain division of the intrinsic modal sequence. It is effective for obtaining
    the decomposition sequence to finally derive the optimal solution of a variational
    problem. In this study, each meteorological series, f(t), is adaptively decomposed
    into K IMFs to ensure that the decomposed sequence is a mode series with limited
    bandwidth and central frequency; the sum of the estimated bandwidths of each mode
    is minimum. The constraint condition is that the sum of all modes is equal to
    that of the original sequence. The corresponding constraint variational model
    is constructed as: (1) where is the set of decomposed modes; is the set of decomposed
    modal center frequencies; represents the convolution operator; is the partial
    derivative with respect to time t; and is the Dirac function. The quadratic penalty
    factor and Lagrange multiplier are introduced to solve the foregoing problems.
    The alternate direction multiplier iterative algorithm is used to search for the
    optimal solution, i.e., the saddle point of the Lagrange function. The decomposition
    of meteorological data through the VMD model can reduce the instability and volatility
    of the series as well as improve the correlation between meteorological factors
    and ETo. 2.2.2. Box-Cox transformation The BC method, a generalized power transformation
    technique (Box and Cox, 1964), estimates parameter λ by the maximum likelihood
    estimation or Bayesian method and then determines the data transformation form.
    The BC method can improve data independence, stationarity, and homogeneity of
    variance without losing the original sequence information. Then, it can transform
    the model into: (2) where y(λ) is the new variable after transformation, and a
    is the translated coefficient such that all components of the original variable,
    y, become positive. Because the maximum likelihood estimation method is simple
    and entails minimal calculation, this study uses this method to solve λ. The model
    input meteorological factors are transformed using BC according to the λ value,
    reducing the correlation between the unobtainable error and ETo. 2.3. Support
    vector machine The SVM model finds the best separation hyperplane in feature space
    such that the interval among the training sample points farthest from the plane
    is the largest. After the kernel method is introduced, SVM can deal with nonlinear
    problems (Essam et al., 2022). The model is based on the principle of minimizing
    structural risk and has satisfactory generalization ability. Let the training
    dataset be , where xi and yi indicate the ith input and output vectors, respectively.
    The SVM optimization can be expressed as: (3) (4) where C is the penalty factor;
    and are the slack variables; and is the insensitive loss coefficient. The Lagrange
    function was introduced to transform the optimization problem into a duality problem
    and then solve it; an SVM nonlinear mapping model was also obtained. The function
    is: (5) where αi is the Lagrange multiplier; K (x, xi) is the kernel function;
    and b is the bias coefficient. The radial basis kernel function (RBF) and the
    linear, polynomial, and sigmoid kernel functions are the four types of kernel
    functions commonly used. The linear kernel function is a special case of RBF.
    The polynomial and sigmoid kernel functions involve more parameters. The latter
    approximates the RBF under some parameters. In summary, the RBF is selected as
    the kernel function of the SVM in this study. 2.4. Proposed VMD–BC–SVM hybrid
    model This paper proposes a novel hybrid VMD–BC–SVM model based on a “decomposition–transformation–identification–estimation”
    framework to estimate the daily ETo; the flowchart is presented in Fig. 2. The
    VMD–BC–SVM model is developed as follows. ● Meteorological factors are decomposed
    into multiple modes (IMFs) employing VMD. ● All modes (IMFs) are normalized using
    BC. ● The key driving modes (IMFs) that are highly correlated with ETo are identified
    using LASSO regression. ● The proposed VMD–BC–SVM estimation model is developed
    with the identified key driving modes (IMFs) as the SVM model input. Download
    : Download high-res image (287KB) Download : Download full-size image Fig. 2.
    Overall flowchart of the study. 2.5. Empirical models for estimating ETo In this
    study, the ETo calculated from the FAO-56P–M model was used as the standard value,
    and the H–S (Hargreaves and Samani, 1985) and P–T (Priestley et al., 1972) empirical
    models are used for comparison. The specific calculation formulae are listed in
    Table 2. Table 2. Empirical models of reference evapotranspiration. Model Formula
    Input meteorological factors Penman-Monteith Tmax, Tmin, RH, SSD, u2 Hargreaves-Samani
    Tmax, Tmin Priestley-Taylor Tmax, Tmin, RH, SSD In Table 2, ETo,P–M, ETo,H–S and
    ETo,P–T (mm/d) are the ETo estimated by P–M, H–S, and P–T, respectively; is the
    slope of the saturation vapor pressure curve (kPa/°C); Rn is the net radiation
    (MJ/(m2/d)); Ra is the extraterrestrial radiation (MJ/(m2/d)); G is the soil heat
    flux, (MJ/(m2/d)); is the psychrometric constant (kPa/°C); Tmax, Tmin, and T are
    the maximum, minimum, and mean daily air temperatures (°C), respectively; U2 is
    the wind speed at a 2-m height (m/s); and es and ea are the saturation and actual
    vapor pressures (kPa), respectively. The study area includes arid and semi-arid
    regions; thus, the empirical coefficients, C and E, are set to 0.0023 and 0.5,
    respectively (Hargreaves and Samani, 1985). For comparison with the H–S and P–T
    models, the selected input combinations of meteorological factors are listed in
    Table 3. The study yielded two input combinations for daily ETo modeling at all
    stations: the combination of Tmax and Tmin and that of Tmax, Tmin, SSD, and RH.
    Table 3. Input combinations of meteorological factors for the studied models.
    Model Inputs Output models-2, H-S Tmax, Tmin ETo models-4, P-T Tmax, Tmin, RH,
    SSD ETo 2.6. Model performance evaluation 2.6.1. Mutual information neural estimator
    The MINE is optimized by a neural network (Ozdenizci and Erdogmus, 2021; Zbili
    and Rama, 2021) and can process random variables with arbitrary distributions
    in any dimension. Mutual information (MI) reveals the influence of internal implicit
    information, such as variables and simulation results, on model performance; however,
    MI has no clear upper limit. The closer the MI between the estimated and standard
    values to the information entropy of the standard value, the better the model
    estimation effect. The following expresses MI: (6) where P is the joint distribution,
    p(x, y), of X and Y; Q is the product of the edge distribution, , of X and Y;
    and function T is fitted by a neural network. The foregoing equation is regarded
    as a loss function, and the loss value reaches the maximum through gradient rise
    until convergence. The maximum value is the estimator of MI. 2.6.2. Evaluation
    indices Previous studies have evaluated the estimation accuracy of the model from
    the perspective of error through evaluation indices and rarely discussed model
    performance in terms of information. Therefore, the accuracy and performance of
    the models investigated for daily ETo estimations were evaluated using the following.
    The MI technology (Eq. (6)) and four commonly used evaluation metrics are combined:
    mean absolute percentage error (MAPE), Nash–Sutcliffe efficiency coefficient (NSE),
    coefficient of correlation (R), and root mean square error (RMSE). The MAPE and
    RMSE metrics were used to assess the actual situation of the estimated value error
    ranging [0, + ∞]. Small MAPE and RMSE values indicate improved model performance
    (Guo et al., 2021; Chen et al., 2022); models with MAPE and RMSE values that are
    less than 30% and 0.7, respectively, are excellent. The R and NSE metrics are
    generally used to evaluate the stability and model fitting effect. The closer
    their values are to 1, and when they exceed 0.6, the better the model fitting
    effect. These metrics can be expressed as: (7) (8) (9) (10) where and are the
    ith standard and estimated values of ETo, respectively; and are the averages of
    and , respectively; and N is the number of samples. 3. Results 3.1. Meteorological
    factor decomposition based on VMD The VMD method was used to decompose meteorological
    factors into a series of modes (IMFs) with different frequencies. The number of
    decomposition layers is known to be crucial to the accuracy of the model (Wen
    et al., 2019). In this study, the decomposition layer, K, was set to have 3–7
    layers in advance to determine the specific number of decomposition layers according
    to the fitting degree of the training period. The VMD–BC–SVM model selected six
    layers that outperformed the other layers at the Wugong station. Therefore, Tmax,
    Tmin, SSD, and RH were decomposed into six layers. The results are shown in Fig.
    3. The other stations adopted the same method to select the number of layers (Table
    5). The results showed that the effect was significant, although the workload
    was more complicated. Download : Download high-res image (1MB) Download : Download
    full-size image Fig. 3. Decomposition signal by VMD for meteorological factors
    at Wugong Station: (a) Tmax, (b) Tmin, (c) SSD, (d) RH. 3.2. Parameters of BC
    and key driving modes Each decomposed mode is normalized by BC. The values of
    the transformation parameter, λ (which determines the function type that the BC
    employs), are listed in Table 4. To demonstrate the effect of BC, normalization
    was adopted as the data processing method for comparison. Table 4. The transformation
    parameter λ values of each mode decomposed. Station Model Meteorological factors
    IMF1 IMF2 IMF3 IMF4 IMF5 IMF6 Wuqi VMD–BC–SVM-2 Tmax 1.00 1.09 1.06 1.05 1.11
    – Tmin 0.88 0.96 1.03 1.01 0.91 – VMD–BC–SVM-4 Tmax 0.97 1.08 1.05 1.03 1.04 1.19
    Tmin 0.86 0.95 1.04 1.03 1.01 1.06 RH 1.37 1.28 1.07 1.06 1.14 1.04 SSD 1.17 0.97
    1.01 1.02 1.05 1.15 Wugong VMD–BC–SVM-2 Tmax 0.87 1.08 1.07 1.05 1.00 Tmin 0.75
    1.01 1.06 1.02 0.93 VMD–BC–SVM-4 Tmax 0.87 1.07 1.07 1.06 1.03 1.02 Tmin 0.75
    0.99 1.05 1.03 1.03 1.05 RH 1.62 1.02 1.02 1.03 1.07 1.10 SSD 0.79 0.98 1.02 1.03
    1.07 1.06 Xiji VMD–BC–SVM-2 Tmax 0.94 1.09 1.05 1.05 1.14 – Tmin 1.02 1.06 1.01
    1.00 1.03 – VMD–BC–SVM-4 Tmax 0.94 1.09 1.05 1.05 1.14 – Tmin 1.02 1.06 1.01 1.00
    1.03 – RH 1.41 1.16 1.03 1.03 1.05 – SSD 2.56 1.01 1.05 1.05 1.13 – Xifeng VMD–BC–SVM-2
    Tmax 0.94 1.07 1.06 1.06 1.07 Tmin 0.86 1.14 1.11 1.08 1.00 VMD–BC–SVM-4 Tmax
    0.94 1.07 1.06 1.06 1.07 Tmin 0.86 1.14 1.11 1.08 1.00 RH 1.22 0.95 1.00 1.03
    1.05 SSD 1.46 1.18 1.05 1.04 1.06 The LASSO regression compresses the variable
    coefficients by constructing penalty functions such that some coefficients with
    small absolute values can be directly set to zero. These variables are deleted
    to achieve dimensionality reduction and parameter selection concurrently (Sethi
    and Mittal, 2021). The importance of each mode (i.e., IMF) and ETo at the four
    stations using the VMD–BC–SVM models is compared using heat maps. The regression
    coefficients that determine the importance of IMFs based on the input of the two
    and four factors are shown in Fig. 4, Fig. 5, respectively. The exact values of
    the regression coefficients can be found in the Excel spreadsheet provided as
    supplementary data. The key driving factors with a high regression coefficient
    as model inputs are beneficial for improving the model efficiency. The numbers
    of key driving modes and decomposition layers using different input combinations
    are summarized in Table 5. Download : Download high-res image (102KB) Download
    : Download full-size image Fig. 4. The importance between each mode (IMFs) and
    ETo (i.e. regression coefficients of LASSO) at four Stations (Models input Tmax
    and Tmin). Download : Download high-res image (145KB) Download : Download full-size
    image Fig. 5. The importance between each mode (IMFs) and ETo (i.e. regression
    coefficients of LASSO) at four Stations (Models input Tmax, Tmin, SSD and RH).
    Table 5. The decomposition layers and number of key driving modes at different
    station. Station Models Decomposition layers (K) The number of key driving modes
    (i.e. prediction factors) Wuqi VMD–BC–SVM-2 5 8 VMD–BC–SVM-4 6 21 Wugong VMD–BC–SVM-2
    5 8 VMD–BC–SVM-4 6 20 Xiji VMD–BC–SVM-2 5 7 VMD–BC–SVM-4 5 17 Xifeng VMD–BC–SVM-2
    5 10 VMD–BC–SVM-4 5 17 The regression coefficient based on the input of the two
    factors is shown in Fig. 4. The figure shows that the maximum and minimum temperatures
    are decomposed into five layers at each station. The number of selected modes
    is summarized in Table 5. All the modes were selected as inputs for Xifeng station.
    The lowest value of the regression coefficient among the 10 modes was IMF3Tmin
    (0.086), which can be viewed in the supplementary data. The lowest values in the
    selected modes of Wuqi, Wugong, and Xiji stations are 0.085 (IMF4Tmin), 0.085
    (IMF2Tmin), and 0.097 (IMF5Tmin), respectively. This indicates that the selection
    of a mode with regression coefficients exceeding 0.08 as the model input is more
    advantageous. Similarly, the lowest regression coefficients in the selected modes
    at Wuqi, Wugong, Xiji, and Xifeng stations were 0.022 (IMF3RH), 0.035 (IMF5RH),0.045
    (IMF4RH), and 0.022 (IMF4RH), respectively, as observed in Fig. 5. This indicates
    that IMFs with a value exceeding 0.02 can be used as a model input based on the
    four-factor model. 3.3. Estimated results of single model The RBF was used for
    the SVM model; was 0.01; and the penalty factor, C, and kernel function parameter,
    g, were 1 and 2, respectively. The activation function and number of hidden nodes
    of the ELM model for a training dataset were the sine function and 40, respectively.
    The simulation accuracies of the two-factor and four-factor single models are
    listed in Table 6, Table 7, respectively. Based on the results of the four stations,
    the MAPE ranges of the SVM-2 and ELM-2 models were 20.97% (Wugong)–23.77% (Wuqi)
    and 21.24% (Wugong)–25.18% (Wuqi), respectively. The R, NSE, and RMSE metrics
    indicate similar performance levels. The optimal MAPE for the SVM-4 model was
    12.51% (Wuqi). The results show that the simulation accuracy of the SVM is better
    than that of the ELM. The SVM model adopts the principle of structural risk minimization.
    It obtains a unique solution that compensates for the disadvantages of ELM, which
    has a low learning rate and easily falls into the local minimum. Table 6. Estimation
    evaluation of each model under Tmax and Tmin at four stations. Station Models
    Training Testing MAPE (%) R NSE RMSE (mm·d−1) MAPE (%) R NSE RMSE (mm·d−1) Wuqi
    ELM-2 27.98 0.907 0.823 0.69 25.18 0.917 0.841 1.03 SVM-2 26.54 0.905 0.818 0.69
    23.77 0.917 0.840 1.04 VMD–ELM-2 26.64 0.917 0.842 0.65 23.88 0.933 0.869 0.95
    VMD–SVM-2 23.38 0.922 0.850 0.63 21.74 0.936 0.877 0.93 BC–ELM-2 20.72 0.932 0.869
    0.59 19.23 0.939 0.882 0.88 BC–SVM-2 19.77 0.931 0.865 0.60 18.16 0.940 0.883
    0.89 VMD–BC–ELM-2 15.89 0.949 0.901 0.51 14.76 0.959 0.919 0.75 VMD–BC–SVM-2 14.49
    0.951 0.904 0.50 13.60 0.961 0.922 0.74 H-S 28.69 0.945 0.754 0.81 25.88 0.955
    0.794 0.77 Wugong ELM-2 20.62 0.938 0.880 0.56 21.24 0.939 0.880 0.86 SVM-2 20.19
    0.936 0.875 0.57 20.97 0.937 0.876 0.88 VMD–ELM-2 20.28 0.941 0.885 0.55 21.15
    0.941 0.881 0.85 VMD–SVM-2 17.77 0.946 0.894 0.52 19.60 0.942 0.885 0.82 BC–ELM-2
    15.65 0.956 0.915 0.47 16.57 0.957 0.915 0.73 BC–SVM-2 15.37 0.955 0.912 0.48
    16.13 0.956 0.913 0.74 VMD–BC–ELM-2 11.20 0.970 0.942 0.39 12.03 0.969 0.937 0.61
    VMD–BC–SVM-2 9.86 0.973 0.946 0.37 11.03 0.971 0.940 0.59 H-S 29.55 0.951 0.742
    0.82 30.81 0.945 0.736 0.88 Xiji ELM-2 21.67 0.930 0.865 0.55 24.51 0.930 0.857
    0.85 SVM-2 20.67 0.928 0.860 0.56 22.70 0.928 0.859 0.85 VMD–ELM-2 20.38 0.938
    0.880 0.52 23.36 0.939 0.873 0.79 VMD–SVM-2 17.58 0.943 0.889 0.50 21.01 0.941
    0.879 0.77 BC–ELM-2 16.67 0.947 0.897 0.48 18.40 0.948 0.894 0.74 BC–SVM-2 16.03
    0.946 0.893 0.49 17.15 0.947 0.895 0.74 VMD–BC–ELM-2 12.94 0.961 0.924 0.41 14.17
    0.962 0.921 0.63 VMD–BC–SVM-2 11.37 0.964 0.929 0.40 12.90 0.963 0.923 0.62 H-S
    19.98 0.959 0.870 0.54 21.09 0.960 0.868 0.58 Xifeng ELM-2 22.10 0.930 0.866 0.62
    21.66 0.926 0.856 0.98 SVM-2 21.53 0.928 0.861 0.63 21.16 0.923 0.852 1.00 VMD–ELM-2
    21.13 0.940 0.883 0.58 20.58 0.936 0.875 0.90 VMD–SVM-2 19.19 0.943 0.890 0.56
    19.61 0.937 0.877 0.89 BC–ELM-2 17.53 0.948 0.900 0.54 17.53 0.945 0.893 0.85
    BC–SVM-2 17.10 0.947 0.896 0.55 17.11 0.944 0.891 0.87 VMD–BC–ELM-2 12.16 0.967
    0.935 0.43 12.32 0.965 0.930 0.68 VMD–BC–SVM-2 11.00 0.969 0.939 0.42 11.62 0.965
    0.932 0.66 H-S 20.21 0.942 0.879 0.59 20.60 0.939 0.871 0.60 Note: The best-performing
    models are highlighted in bold at each station. Table 7. Estimation evaluation
    of each model under Tmax, Tmin, SSD and RH at four stations. Station Models Training
    Testing MAPE (%) R NSE RMSE (mm·d−1) MAPE (%) R NSE RMSE (mm·d-1) Wuqi ELM-4 16.88
    0.973 0.948 0.37 13.88 0.980 0.960 0.55 SVM-4 15.17 0.975 0.950 0.36 12.51 0.982
    0.963 0.53 VMD–ELM-4 18.47 0.969 0.938 0.40 15.73 0.974 0.948 0.59 VMD–SVM-4 11.56
    0.982 0.964 0.31 13.00 0.978 0.956 0.49 BC–ELM-4 12.11 0.981 0.963 0.31 10.45
    0.986 0.972 0.46 BC–SVM-4 11.07 0.982 0.964 0.31 9.52 0.987 0.974 0.45 VMD–BC–ELM-4
    10.56 0.979 0.958 0.33 10.24 0.984 0.966 0.48 VMD–BC–SVM-4 5.25 0.992 0.985 0.20
    8.41 0.984 0.967 0.38 P-T 17.03 0.963 0.904 0.51 16.00 0.974 0.919 0.45 Wugong
    ELM-4 13.54 0.978 0.957 0.33 14.21 0.978 0.955 0.51 SVM-4 12.81 0.979+ 0.957 0.33
    13.32 0.978 0.957 0.51 VMD–ELM-4 14.73 0.975 0.950 0.36 15.72 0.974 0.948 0.55
    VMD–SVM-4 8.52 0.988 0.977 0.24 13.78 0.976 0.952 0.45 BC–ELM-4 9.73 0.986 0.973
    0.26 10.33 0.985 0.971 0.41 BC–SVM-4 9.28 0.987 0.973 0.26 9.92 0.986 0.972 0.41
    VMD–BC–ELM-4 7.67 0.988 0.977 0.25 8.21 0.987 0.973 0.39 VMD–BC–SVM-4 4.10 0.997
    0.993 0.13 7.24 0.987 0.974 0.31 P-T 17.09 0.969 0.898 0.51 18.15 0.967 0.909
    0.52 Xiji ELM-4 13.66 0.979 0.959 0.30 15.15 0.981 0.955 0.47 SVM-4 11.94 0.981
    0.962 0.29 13.32 0.982 0.959 0.45 VMD–ELM-4 13.67 0.980 0.961 0.30 15.04 0.983
    0.957 0.46 VMD–SVM-4 6.39 0.994 0.988 0.17 13.28 0.984 0.961 0.35 BC–ELM-4 9.70
    0.986 0.973 0.25 10.53 0.988 0.970 0.38 BC–SVM-4 9.12 0.987 0.974 0.24 9.98 0.988
    0.971 0.38 VMD–BC–ELM-4 8.28 0.988 0.977 0.23 8.70 0.990 0.974 0.36 VMD–BC–SVM-4
    4.40 0.996 0.992 0.13 7.38 0.990 0.975 0.28 P-T 16.59 0.973 0.904 0.46 14.79 0.982
    0.919 0.42 Xifeng ELM-4 13.68 0.977 0.955 0.36 13.77 0.979 0.953 0.55 SVM-4 12.66
    0.978 0.956 0.35 12.58 0.980 0.957 0.53 VMD–ELM-4 15.59 0.972 0.944 0.40 14.25
    0.975 0.950 0.59 VMD–SVM-4 10.89 0.981 0.962 0.33 13.09 0.976 0.952 0.53 BC–ELM-4
    10.72 0.984 0.968 0.30 10.57 0.985 0.968 0.46 BC–SVM-4 10.00 0.984 0.969 0.30
    9.72 0.986 0.970 0.45 VMD–BC–ELM-4 8.54 0.986 0.973 0.28 8.55 0.987 0.973 0.43
    VMD–BC–SVM-4 5.06 0.994 0.988 0.18 7.59 0.988 0.973 0.35 P-T 22.11 0.945 0.874
    0.60 21.53 0.953 0.882 0.55 Note: The best-performing and empirical models are
    highlighted in bold at each station. 3.4. Estimated results of hybrid models To
    formulate hybrid models, meteorological factors were obtained by implementing
    VMD, BC transformation, and VMD–BC pre-processing. The results based on two-factor
    and four-factor inputs are summarized in Table 6, Table 7, respectively, and the
    errors are given in the bubble chart shown in Fig. 6. Download : Download high-res
    image (201KB) Download : Download full-size image Fig. 6. Error bubble charts
    of the estimated ETo for machine learning models: (a) models input Tmax and Tmin,
    (b) models input Tmax, Tmin, SSD and RH. Table 6, Table 7 indicate that VMD, BC,
    and VMD–BC can improve the estimation accuracy of the machine learning models.
    The performance of BC-based models was better than that of VMD-based models. The
    MAPE and RMSE ranges of the VMD–BC–SVM-2 model was 11.03% (Wugong)–13.6% (Wuqi)
    and 0.62% (Xiji)–0.74% (Wuqi), respectively. The R and NSE of the VMD–BC–SVM-2
    model was more than 0.96 and 0.92, respectively, in the four sites. Among the
    models for the four stations, the model trained at the Wuqi station had the worst
    performance. The VMD–BC–ELM-2 model had an acceptable estimation; the Wugong station
    had the highest accuracy (MAPE = 12.03%, R = 0.97, NSE = 0.94, and RMSE = 0.61 mm/d).
    The VMD–BC-based models are the best among all the models. The data processing
    technology based on the fusion of VMD and BC can effectively improve the nonlinear
    mapping relationship between meteorological factors and ETo. Moreover, it has
    better performance and is suitable for the Wei River Basin. Table 6 indicates
    that the four-factor machine learning models have a higher estimation accuracy
    than the other models. The absence of SSD and RH lead to the absence of key parts
    of the mapping relationship; hence, the contribution of SSD and RH to the estimation
    accuracy of the models is positive. The results of the single and VMD-based models
    do not considerably differ. For example, the MAPE of the SVM-4 and VMD-SVM-4 models
    at Wuqi station were 12.51% and 13.00%, respectively. This positive effect deteriorates
    when VMD is used, indicating that the decomposition of meteorological factors
    may be unstable. The MAPE of the BC-based model reaches 9.52% (Wuqi station),
    indicating that the use of BC transformation to obtain meteorological factors
    is effective for model estimation. Therefore, a combination of VMD and BC was
    considered to estimate the ETo. During the test in Wuqi station, the evaluation
    indices of the MAPE, R, NSE, and RMSE of the VMD–BC–SVM-4 and VMD–BC–ELM-4 models
    reached 8.41–10.24%, 0.984, 0.97, and 0.38–0.48 mm/d, respectively; these were
    slightly worse than the indices of the other three stations. Similarly, for the
    four-factor input, the model tested at Wugong station exhibited the best performance
    among the four stations. The simulation accuracy of the VMD–BC–SVM model was higher
    than that of the other models. In summary, the ranks of the studied models in
    terms of estimation accuracy were VMD–BC–SVM, VMD–BC–ELM, BC–SVM, BC–ELM, VMD–SVM,
    and VMD–ELM. To evaluate the performance of the single and hybrid models, MAPE
    and RMSE were presented using bubble charts. A comparison of the eight machine
    learning models is shown in Fig. 6. Among all the models, VMD–BC–SVM and VMD–BC–ELM
    showed satisfactory performance during training and testing. The bubble charts
    clearly illustrate that the VMD–BC–SVM-4 model had the smallest error; MAPE ranged
    from 7% to 9% and RMSE was less than 0.44 mm/d. The foregoing indicates that the
    hybrid models based on VMD–BC have superior estimates compared with the other
    machine learning models. 3.5. Comparative analysis with empirical model The performance
    indicators of machine learning and empirical models based on two-factor and four-factor
    inputs for estimating the daily ETo at the four meteorological stations are summarized
    in Table 6, Table 7, respectively. The results show that the VMD–BC–SVM and VMD–BC–ELM
    models generally outperform the H–S and P–T models at all meteorological stations.
    The computing performance of the hybrid VMD–BC–SVM-2 model was better than that
    of the H–S model because MAPE decreased from 30.81% to 11.03% during the testing
    stage at Wugong Station. Table 6 indicates that the computing performance of the
    hybrid VMD–BC–SVM-4 model is better than that of the P–T model; MAPE decreased
    from 18.15% to 7.24% at the Wugong station. Therefore, the VMD–BC–SVM and VMD–BC–ELM
    models can replace the H–S and P–T empirical models under the same meteorological
    input conditions, respectively. Moreover, the VMD–BC–SVM model performs better
    than the VMD–BC–ELM model. 3.6. Model performance analysis based on mutual information
    neural estimator The performance of the VMD–BC–SVM and empirical models is evaluated
    in terms of information. The MI between simulated results and standard values
    as well as the high-dimensional MI between multiple meteorological factors and
    ETo using the MINE are shown in Fig. 7 and summarized in Table 8. The figure and
    table similarly indicate that the performance of the VMD–BC–SVM model is better
    than that of the H–S and P–T models. Moreover, the MI (X; Ystd) of the four meteorological
    factors and ETo is approximately 1.67 (Xifeng)–1.83 (Xiji), and the MI of the
    two meteorological factors is 1.18 (Xifeng)–1.32 (Wuqi). The foregoing indicates
    that multiple meteorological factors can provide more information for ETo estimation.
    The performance of the four-factor VMD–BC–SVM and P–T models in terms of MI (Ysim;
    Ystd) is the best at all the stations (1.61–2.83), followed by the VMD–BC–SVM-2
    and H–S models (1.40–2.13). This indicates that a considerable amount of input
    data improves the accuracy of model simulation; this is consistent with the previous
    conclusion. In addition, the amount of information provided by the VMD–BC–SVM
    model exceeds that provided by the empirical formulae using the same input factors.
    The MI values of the VMD–BC–SVM-4 model are 2.60, 2.74, 2.83, and 2.71 at Wuqi,
    Wugong, Xiji, and Xifeng stations, respectively. These values are the closest
    to the information entropy of standard ETo (2.87, 2.75, 2.96, and 2.97, respectively).
    This indicates that the VMD–BC–SVM models can identify the information provided
    by meteorological factors. Moreover, the models have a strong ability to deal
    with high-dimensional and nonlinear information. The foregoing further shows that
    the structure and performance of machine learning models are superior to those
    of the H–S and P–T empirical models; this observation is consistent with the model
    performance resulting from the use of evaluation indices. The VMD–BC–SVM models
    are confirmed to have stable estimation performance. Download : Download high-res
    image (565KB) Download : Download full-size image Fig. 7. Mutual information estimation
    graphs: (a) Wuqi station, (b) Wugong station, (c) Xiji station, (d) Xifeng station.
    Table 8. Multiple meteorological factors and ETo estimates contain information
    from standard ETo. Station H (Ystd) 2 factors MI (X; Ystd) 4 factors MI (X; Ystd)
    H-S MI (Ysim; Ystd) VMD-BC-SVM-2 MI (Ysim; Ystd) P-T MI (Ysim; Ystd) VMD-BC-SVM-4
    MI (Ysim; Ystd) Wuqi 2.87 1.32 1.80 1.70 1.93 2.17 2.60 Wugong 2.75 1.24 1.75
    1.65 2.13 2.00 2.74 Xiji 2.96 1.31 1.83 1.80 2.05 2.37 2.83 Xifeng 2.97 1.18 1.67
    1.40 1.98 1.61 2.71 Note: Ystd, standard value of ET0; Ysim, simulated value of
    ET0; X, combination of meteorological factors; H(Ystd), information entropy of
    standard ET0 (denoted as Ystd); MI (X; Ystd), mutual information between X and
    Ystd; MI (Ysim; Ystd), mutual information between Ysim and Ystd. 3.7. Spatial
    distribution of evaluation indices of models To illustrate the universality of
    the proposed models, the spatial distribution of the evaluation indices at 10
    meteorological stations for the two-factor and four-factor models are shown in
    Fig. 8, Fig. 9, respectively. The specific evaluation indices for the other six
    stations are listed in Table 9, Table 10, respectively. In Fig. 8, the VMD–BC–SVM-2
    model is shown to be superior to the other machine learning models and the H–S
    empirical model at all stations. In Fig. 9, the hybrid VMD–BC–SVM-4 model exhibits
    a higher estimation accuracy than the P–T empirical model. By comparing Fig. 8,
    Fig. 9, the four-factor machine learning models are found to outperform the two-factor
    models. This indicates that the ETo in the Wei River Basin is significantly affected
    by meteorological factors, specifically temperature, SSD, and RH. Table 9 indicates
    that the estimation results of the VMD–BC–SVM-2 model at Huanxian, Changwu, Baoji,
    and Tianshui stations are better than those of the other two stations. The MAPE
    and RMSE values are less than 12% and 0.7 mm/d, respectively. The results listed
    in Table 10 indicate that high R and NSE values exceeding 0.99 and 0.97, respectively,
    were obtained; the MAPE and RMSE values were less than 8 and 0.4, respectively.
    In terms of spatial distribution, the VMD–BC–SVM models were significantly better
    than the other models in the Wei River Basin. This indicates that the VMD–BC data
    processing technology proposed in this paper can effectively improve the simulation
    performance of the SVM model. Overall, the VMD–BC–SVM models perform better than
    the H–S and P–T empirical models and can be used to estimate the ETo in the Wei
    River Basin even when meteorological data are scarce. Download : Download high-res
    image (450KB) Download : Download full-size image Fig. 8. Spatial distribution
    of evaluation indices for different models in Wei River Basin (Models input Tmax
    and Tmin): (a) MAPE, (b) R, (c) NSE, (d) RMSE. Download : Download high-res image
    (466KB) Download : Download full-size image Fig. 9. Spatial distribution of evaluation
    indices for different models in Wei River Basin (Models input Tmax, Tmin, SSD
    and RH): (a) MAPE, (b) R, (c) NSE, (d) RMSE. Table 9. Estimation evaluation of
    models under Tmax and Tmin at other six stations. Model Station MAPE (%) R NSE
    RMSE (mm·d−1) Station MAPE (%) R NSE RMSE (mm·d−1) SVM-2 Huajialing 31.23 0.88
    0.78 1.09 Changwu 21.82 0.92 0.85 0.98 VMD-SVM-2 31.03 0.90 0.81 0.98 20.71 0.93
    0.87 0.90 BC-SVM-2 23.06 0.92 0.85 0.90 16.71 0.95 0.90 0.81 VMD-BC-SVM-2 14.59
    0.96 0.91 0.67 11.04 0.97 0.94 0.62 H-S 33.23 0.87 0.71 0.80 23.75 0.94 0.81 0.68
    SVM-2 Luochuan 24.00 0.90 0.80 1.06 Baoji 19.81 0.94 0.87 0.91 VMD-SVM-2 23.16
    0.91 0.83 0.97 18.64 0.94 0.87 0.87 BC-SVM-2 20.00 0.92 0.85 0.93 15.76 0.96 0.91
    0.77 VMD-BC-SVM-2 14.52 0.95 0.89 0.75 11.42 0.97 0.93 0.65 H-S 23.75 0.92 0.87
    0.70 25.61 0.95 0.79 0.79 SVM-2 Huanxian 21.38 0.93 0.85 1.04 Tianshui 18.51 0.94
    0.87 0.85 VMD-SVM-2 18.96 0.94 0.88 0.91 17.01 0.94 0.88 0.79 BC-SVM-2 16.90 0.95
    0.89 0.90 14.90 0.95 0.90 0.73 VMD-BC-SVM-2 11.96 0.97 0.93 0.70 11.20 0.96 0.92
    0.62 H-S 19.01 0.96 0.88 0.58 23.11 0.95 0.76 0.71 Note: The best-performing model
    is highlighted in bold at each station. Table 10. Estimation evaluation of models
    under Tmax, Tmin, SSD and RH at other six stations. Model Station MAPE (%) R NSE
    RMSE (mm·d−1) Station MAPE (%) R NSE RMSE (mm·d−1) SVM-4 Huajialing 11.34 0.99
    0.97 0.42 Changwu 12.90 0.98 0.96 0.46 VMD-SVM-4 12.80 0.98 0.97 0.33 13.75 0.98
    0.95 0.43 BC-SVM-4 9.27 0.99 0.98 0.36 9.58 0.99 0.97 0.38 VMD-BC-SVM-4 7.74 0.99
    0.98 0.28 7.44 0.99 0.97 0.30 P-T 36.54 0.91 0.77 0.74 19.71 0.96 0.89 0.53 SVM-4
    Luochuan 11.94 0.98 0.95 0.56 Baoji 13.27 0.98 0.96 0.55 VMD-SVM-4 12.82 0.97
    0.94 0.48 13.80 0.98 0.95 0.47 BC-SVM-4 9.74 0.98 0.97 0.48 9.75 0.99 0.97 0.44
    VMD-BC-SVM-4 8.15 0.98 0.96 0.39 7.40 0.99 0.97 0.32 P-T 23.85 0.94 0.86 0.65
    14.29 0.98 0.94 0.38 SVM-4 Huanxian 11.42 0.98 0.96 0.54 Tianshui 11.06 0.98 0.96
    0.48 VMD-SVM-4 11.43 0.98 0.96 0.49 9.71 0.98 0.97 0.38 BC-SVM-4 9.25 0.99 0.97
    0.46 9.11 0.99 0.97 0.41 VMD-BC-SVM-4 7.50 0.99 0.97 0.36 6.53 0.99 0.98 0.30
    P-T 19.23 0.96 0.91 0.54 12.94 0.98 0.93 0.38 Note: The best-performing model
    is highlighted in bold at each station. 4. Discussion In recent decades, machine
    learning and empirical models have been proposed to improve the accuracy and effectiveness
    of ETo estimation (Niu and Feng, 2021). Kisi et al. (2019) estimated the monthly
    potential ETo in the Sistan and Baluchistan provinces. They found that the SVM
    model generated more accurate estimates than the adaptive neuro-fuzzy inference
    system model (ANFIS) and gene expression programming (GEP) method. Tejada et al.
    (2022) also revealed that the SVM and ELM models showed similar modeling performance,
    and their accuracy was superior to that of the empirical models given the same
    input requirements. In this study, the SVM and ELM generally exhibited similar
    performance in estimating the daily ETo for the two-factor and four-factors models.
    However, the performance of the SVM model is slightly better than that of the
    ELM model. The SVM model has a lower MAPE for all input combinations than the
    ELM model. The results of ELM optimization can be easily trapped in the local
    minimum owing to the random determination of hidden bias and input weights. The
    SVM can handle extremely complex problems by mapping inputs into feature spaces
    through kernel function transformation. Furthermore, SVM learning can be expressed
    as a convex optimization problem; it solves the problem wherein the global minimum
    value cannot be obtained by ELM. For highly complex meteorological data, in some
    cases, single machine learning models cannot provide satisfactory estimation accuracy.
    To resolve this, many researchers have proposed hybrid models that introduce data
    preprocessing techniques to machine learning models. Data decomposition has been
    widely used to develop estimation models. Pammar et al. (2017) attempted to explore
    hybrid modeling using DWT and support vector machine regression (SVR) for evaporation
    estimation. They proved that hybrid DWT–SVR models are superior to conventional
    SVR models. Rezaie-Balf et al. (2019) proposed a hybrid model combining EEMD and
    SVM to predict monthly evaporation. The overall results showed that the EEMD has
    satisfactory application prospects in complex time series prediction. The VMD
    is a more robust and adaptive data preprocessing method than WT and EMD; thus,
    VMD is used to extract effective features from meteorological series. A novel
    hybrid approach for daily ETo estimation using VMD to decompose the original meteorological
    factors into multiple modes (i.e., IMFs) is proposed in this study. The daily
    ETo estimation accuracy of VMD-based model-2 was slightly higher than those of
    the empirical models. This shows that the decomposed modes are more stable and
    less volatile than the original series; therefore, the VMD-based model is more
    accurate than the single machine learning model. The VMD method improves the ability
    of the model by reducing the non-stationarity of highly complex and strongly nonlinear
    meteorological data. However, the performance of VMD-based model-4 was worse than
    that of the single model. This indicates that the skewness of the data may have
    a negative influence on the model, although the VMD model decomposes the four
    meteorological factors into a relatively stable mode. The application of data
    transformation methods to meteorological data can potentially mitigate these problems.
    Zhang et al. (2017) investigated whether applying different transformations (i.e.,
    BC) affects the prediction. The study results show that BC leads to performance
    improvement in prediction models. The BC methods have been widely used in various
    research fields (Amin et al., 2019, Wang et al., 2021); however, the impact of
    BC methods on model performance has not been comprehensively explored in the field
    of evapotranspiration. This study proves that BC-based models are not only superior
    to the single model but also considerably better than the VMD-based models. As
    indicated by our investigation results, the BC method can improve the prediction
    performance; it is a power transformation method that reduces the correlation
    between the unobservable errors in meteorological data and ETo to a certain extent.
    The symmetry and variance of data and the strengthening of the correlation between
    meteorological factors and ETo are significantly improved by the BC method. Consequently,
    the accuracy of model simulation is significantly enhanced. The advantages of
    VMD-based and BC-based models are demonstrated in this study. A novel hybrid data
    processing technique (VMD–BC) was used to model the SVM model for the first time.
    The VMD method decomposes the meteorological factors into more stable modes (IMFs)
    to solve the impact of unstable sequences on the accuracy of model estimation.
    Furthermore, BC improved the symmetry and homogeneity of variance. In the datasets,
    VMD–BC–SVM is consistently foremost in terms of estimation accuracy, indicating
    that the VMD–BC–SVM model exhibits not only high accuracy but also stable performance.
    The reduction rates of MAPE for the best VMD–BC–SVM-4 models compared with those
    for the single SVM-4 models in this study (testing phase) were 34.9%, 45.6%, 44.6%,
    and 39.7% at Wuqi, Wugong, Xiji, and Xifeng stations, respectively (Table 7).
    Therefore, the hybrid models generated by coupling VMD–BC and SVM are highly desirable.
    When the same meteorological factors were used at the stations, the VMD–BC–SVM
    model performed better than the other machine learning models. This highlights
    the superiority of the VMD–BC–SVM model in dealing with complex and nonlinear
    relationships between ETo and driving meteorological factors. Hybrid VMD–BC data
    processing can achieve accurate signal separation and maintain time-varying characteristics.
    It can also improve homoscedasticity, normality, and additivity, which are suitable
    for the analysis of nonlinear and non-stationary signals. Therefore, the VMD–BC–SVM
    model is superior to the other methods. To the best of our knowledge, this hybrid
    data-processing technology (VMD–BC) has never been used in the field of ETo estimation.
    In this study, the extended method is applied to the field of ETo estimation to
    enrich existing knowledge. Previous research has solved the problem of non-stationary
    data using decomposed meteorological factors as model inputs (Luan, 2017, Qasem
    et al., 2019). However, the key driving effects of the decomposed modes (IMFs)
    of the meteorological factors on ETo estimation were not identified. It is considered
    in this study if some modes of the meteorological factors are more effective than
    the others for estimating ETo. The high-dimensional characteristics of the models
    render direct modeling complicated. Therefore, the use of effective statistical
    methods is necessary to select the key modes with high correlation and achieve
    data dimensionality reduction to improve the running efficiency of the model.
    To determine the key inputs of the model, the analysis of the relationship between
    predictors and response variables is important. In this study, LASSO regression
    was utilized to reduce the number of input variables and identify the key driving
    modes (i.e., prediction factors) of ETo. The LASSO regression is effective in
    reducing model complexity by decreasing the considerable variance caused by shrinking
    some coefficients to zero. The modes with regression coefficients exceeding 0.08
    could be used as inputs into the two-factor model. Similarly, a mode with regression
    coefficients exceeding 0.02 is selected as the four-factor model input. The corresponding
    analysis results are shown in Fig. 4, Fig. 5. The importance of each modal factor
    is determined by LASSO via compression estimation to select features with high
    regression coefficients as inputs to the model. This is the first time that LASSO
    has been introduced as the modal selection method for ETo prediction. The performance
    of the models was evaluated using multiple evaluation indices (Table 6, Table
    7); however, the impact of meteorological factors on model performance was not
    explored. The MINE can reflect the high-dimensional MI between multiple meteorological
    factors and ETo. It can also evaluate the model performance in terms of the amount
    of information (Fig. 7 and Table 8). The VMD–BC–SVM model simulation results provide
    better information than the H–S and P–T models (Fig. 7 and Table 8). The evaluation
    results of the other six station models (Fig. 8, Fig. 9; Table 9, Table 10) also
    proved the superiority of the VMD–BC–SVM model, indicating the model’s applicability
    to the research area. Thus, we propose the hybrid VMD–BC–SVM model as the best
    choice for estimating ETo in regions with scarce meteorological data. The estimation
    performance of the hybrid VMD–BC–SVM and VMD–BC–ELM models compared with those
    of the H–S and P–T empirical models was superior because of the ability of the
    machine learning models to map the ETo and meteorological factors better. The
    VMD–BC–SVM model performed better than the other machine learning models. Table
    7, Table 8 clearly indicate that the VMD–BC–SVM model achieves the best performance
    in terms of MAPE, R, RMSE, and NSE for all stations. Regardless of the input combinations,
    the VMD–BC–SVM model performs better than the corresponding empirical models.
    This study proves that the VMD–BC–SVM model can be used as an alternative to empirical
    models. 5. Conclusion An accurate estimation of the daily ETo is essential for
    efficient water resource management and optimal irrigation scheduling, particularly
    because of the limited applicability of the P–M model in regions where meteorological
    data are scarce. This paper proposes a hybrid VMD–BC–SVM model for improving the
    daily ETo estimation accuracy in data-scarce regions. The model is created by
    integrating two data preprocessing technologies (VMD and BC) and a modal selection
    method (LASSO) into the SVM. The VMD–BC–SVM models were validated using two input
    combinations; the two-factor and four-factor combinations were compared with those
    of the H–S and P–T empirical models for the Wei River Basin. The main conclusions
    are as follows. ● The hybrid models offer better accuracy and stability than the
    single and empirical models. Among them, the hybrid VMD–BC–SVM models yielded
    the best performance for daily ETo modeling and can be used to replace the empirical
    models in estimating the daily ETo in data-scarce regions. ● The VMD model is
    a robust and self-adaptive data preprocessing method that can be used to extract
    effective features from a series. The original meteorological factors were decomposed
    into different modes (IMFs) using VMD, thereby reducing the complexity and non-stationarity
    of the input meteorological factors. This study proves that VMD can improve model
    estimation. ● The BC method improves data smoothness, symmetry, and the homogeneity
    of variance while retaining the information of the original meteorological data.
    Therefore, BC can effectively reduce the skewness of the data and improve the
    estimation accuracy of the models. ● A novel hybrid data processing technique
    (VMD–BC) was developed to model the SVM. The integration of VMD and BC can achieve
    accurate signal decomposition while maintaining time-varying characteristics and
    further improving homoscedasticity, normality, and additivity. Thus, the VMD–BC
    model strengthens the convergence and mapping ability of the SVM model. The data
    preprocessing ability of hybrid VMD–BC improved the model performance more effectively
    than the single data preprocessing methods. ● The multiple high-dimensional modes
    generated by VMD can influence the operational efficiency of the model. To reduce
    this effect, the key driving modes were selected as the input of the model from
    the different IMFs of meteorological factors using LASSO. Consequently, not only
    is overfitting prevented but the complexity of the model is also reduced by removing
    some redundant features. The hybrid VMD–BC–SVM model developed for the semi-arid
    region of China may not be directly applicable to other climatic regions in the
    world. The recommendation for future research is that the application of the proposed
    data preprocessing technology (VMD–BC) can be transferable to other regions. In
    this study, the modes with high regression coefficients were selected as the model
    input using only the LASSO regression based on the penalty term. Future studies
    can explore the potential of various modal identification methods, such as the
    filter and wrapper methods. Most studies have focused on estimating ETo using
    less amounts of meteorological data. However, improving the prediction accuracy
    of ETo is also important. For this objective, a hybrid machine learning model
    may be investigated for managing future water resources. Declaration of Competing
    Interest The authors declare that they have no known competing financial interests
    or personal relationships that could have appeared to influence the work reported
    in this paper. Acknowledgments This research was funded by Science-Technology
    Plan Program of Water Conservancy Fund of Shaanxi Province, grant number 2019slkj-14,
    and National Natural Science Foundation of China under grant 5149222, 52079110.
    Sincere gratitude is extended to the editor and anonymous reviewers for their
    professional comments and corrections. Appendix A. Supplementary material Download
    : Download spreadsheet (13KB) Supplementary material . Data availability No data
    was used for the research described in the article. References Abdullah et al.,
    2015 S.S. Abdullah, M.A. Malek, N.S. Abdullah, O. Kisi, K.S. Yap Extreme learning
    machines: a new approach for prediction of reference evapotranspiration J. Hydrol.,
    527 (2015), pp. 184-195, 10.1016/j.jhydrol.2015.04.073 View PDFView articleView
    in ScopusGoogle Scholar Allen et al., 1998 R.G. Allen, L.S. Pereira, D. Raes,
    et al. Crop Evapotranspiration: Guidelines for Computing Crop Water Requirements.
    FAO Irrigation and Drainage Paper No. 56, FAO, Rome (1998) http://www.fao.org/3/X0490E/X0490E00.htm
    Google Scholar Amin et al., 2019 A. Amin, B. Shah, A.M. Khattak, F. Moreira, G.
    Ali, Á. Rocha, S. Anwar Cross-company customer churn prediction in telecommunication:
    a comparison of data transformation methods Int. J. Inf. Manag, 46 (2019), pp.
    304-319, 10.1016/j.ijinfomgt.2018.08.015 View PDFView articleView in ScopusGoogle
    Scholar Antonopoulos and Antonopoulos, 2017 V.Z. Antonopoulos, A.V. Antonopoulos
    Daily reference evapotranspiration estimates by artificial neural networks technique
    and empirical equations using limited input climate variables Comput. Electron.
    Agric., 132 (2017), pp. 86-96, 10.1016/j.compag.2016.11.011 View PDFView articleView
    in ScopusGoogle Scholar Box and Cox, 1964 Box, G.E.P. Cox, D.R., 1964. An analysis
    of transformations. Journal of the Royal Statistical Society: Series B(Methodological).
    26(2), 211–243.https://doi.org/10.1111/J.2517–6161.1964.TB00553.X. Google Scholar
    Cai et al., 2021 Z.W. Cai, X.L. Liu, W.W. Chen, Z. Sun, J. Ding A new wave crest
    distribution based on modified Box-Cox transformation and Rayleigh distribution
    Ocean Eng., 228 (2021), Article 108949, 10.1016/j.oceaneng.2021.108949 View PDFView
    articleView in ScopusGoogle Scholar Carvalho and de Souza Filho, F., 2021 T.M.N.
    Carvalho, de Assis de Souza Filho, F Variational mode decomposition hybridized
    with gradient boost regression for seasonal forecast of residential water demand
    Water Resour. Manag., 35 (10) (2021), pp. 3431-3445, 10.1007/s11269-021-02902-7
    View in ScopusGoogle Scholar Chen et al., 2022 H. Chen, P. Gnanamoorthy, Y. Chen,
    L.R. Mansaray, Q. Song, K. Liao, A. Shi, G. Feng, C. Sun Assessment and Inter-Comparison
    of Multi-Source High Spatial Resolution Evapotranspiration Products over Lancang-Mekong
    River Basin Southeast Asia. Remote. Sens., 14 (2022), p. 479, 10.3390/rs14030479
    Google Scholar Chen et al., 2018 N. Chen, Y. Zhang, C. Jin, A. Wang, D. Guan,
    L. Tian Intercomparison of three methods to estimate evapotranspiration over temperate
    meadow in Inner Mongolia: Penman-Monteith, Makkink and Priestley-Taylor equation
    Water Environ. J., 32 (4) (2018), pp. 500-507, 10.1111/wej.12347 View in ScopusGoogle
    Scholar Chen et al., 2021 X. Chen, Q. Quan, K. Zhang, J. Wei Spatiotemporal characteristics
    and attribution of dry/wet conditions in the Weihe River Basin within a typical
    monsoon transition zone of East Asia over the recent 547 years Environ. Model.
    Softw., 143 (2021), Article 105116, 10.1016/j.envsoft.2021.105116 View PDFView
    articleView in ScopusGoogle Scholar Chia et al., 2020 M.Y. Chia, Y.F. Huang, C.H.
    Koo Support vector machine enhanced empirical reference evapotranspiration estimation
    with limited meteorological parameters Comput. Electron. Agric., 175 (2020), Article
    105577, 10.1016/j.compag.2020.105577 View PDFView articleView in ScopusGoogle
    Scholar Dragomiretskiy and Zosso, 2014 K. Dragomiretskiy, D. Zosso Variational
    mode decomposition IEEE Trans. Signal Process., 62 (3) (2014), pp. 531-544, 10.1109/tsp.2013.2288675
    View in ScopusGoogle Scholar Ehteram et al., 2019 M. Ehteram, V.P. Singh, A. Ferdowsi,
    S.F. Mousavi, S. Farzin, H. Karami, N.S.B. Mohd, H.A. Afan, S.H. Lai, O. Kisi,
    M.A. Malek, A.N. Ahmed, A. El-Shafie An improved model based on the support vector
    machine and cuckoo algorithm for simulating reference evapotranspiration PLoS
    ONE, 14 (2019), 10.1371/journal.pone.0217499 Google Scholar Essam et al., 2022
    Y. Essam, Y.F. Huang, J.L. Ng, A.H. Birima, A.N. Ahmed, A. El-Shafie Predicting
    streamflow in Peninsular Malaysia using support vector machine and deep learning
    algorithms Sci. Rep., 12 (1) (2022), p. 3883, 10.1038/s41598-022-07693-4 View
    in ScopusGoogle Scholar Fan et al., 2021 J. Fan, L. Wu, J. Zheng, F. Zhang Medium-range
    forecasting of daily reference evapotranspiration across China using numerical
    weather prediction outputs downscaled by extreme gradient boosting J. Hydrol.,
    601 (2021), Article 126664, 10.1016/j.jhydrol.2021.126664 View PDFView articleView
    in ScopusGoogle Scholar Fan et al., 2018 J. Fan, W. Yue, L. Wu, F. Zhang, H. Cai,
    X. Wang, X. Lu, Y. Xiang Evaluation of SVM, ELM and four tree-based ensemble models
    for predicting daily reference evapotranspiration using limited meteorological
    data in different climates of China Agric. For. Meteorol., 263 (2018), pp. 225-241,
    10.1016/j.agrformet.2018.08.019 View PDFView articleView in ScopusGoogle Scholar
    Feng et al., 2014 Q. Feng, X. Wen, J. Li Wavelet analysis-support vector machine
    coupled models for monthly rainfall forecasting in arid regions Water Resour.
    Manag., 29 (4) (2014), pp. 1049-1065, 10.1007/s11269-014-0860-3 Google Scholar
    Feng et al., 2016 Y. Feng, N. Cui, L. Zhao, X. Hu, D. Gong Comparison of ELM,
    GANN, WNN and empirical models for estimating reference evapotranspiration in
    humid region of Southwest China J. Hydrol., 536 (2016), pp. 376-383, 10.1016/j.jhydrol.2016.02.053
    View PDFView articleView in ScopusGoogle Scholar Feng et al., 2017 Y. Feng, Y.
    Peng, N. Cui, D. Gong, K. Zhang Modeling reference evapotranspiration using extreme
    learning machine and generalized regression neural network only with temperature
    data Comput. Electron. Agric., 136 (2017), pp. 71-78, 10.1016/j.compag.2017.01.027
    View PDFView articleGoogle Scholar Feng et al., 2020 Z.-k Feng, W.-j Niu, Z.-y
    Tang, Z.-q Jiang, Y. Xu, Y. Liu, H.-r Zhang Monthly runoff time series prediction
    by variational mode decomposition and support vector machine based on quantum-behaved
    particle swarm optimization J. Hydrol., 583 (2020), Article 124627, 10.1016/j.jhydrol.2020.124627
    View PDFView articleView in ScopusGoogle Scholar Ferreira and da Cunha, 2020 L.B.
    Ferreira, F.F. da Cunha New approach to estimate daily reference evapotranspiration
    based on hourly temperature and relative humidity using machine learning and deep
    learning Agric. Water Manag., 234 (2020), Article 106113, 10.1016/j.agwat.2020.106113
    View PDFView articleView in ScopusGoogle Scholar Fu et al., 2021 T. Fu, X. Li,
    R. Jia, L. Feng A novel integrated method based on a machine learning model for
    estimating evapotranspiration in dryland J. Hydrol., 603 (2021), Article 126881,
    10.1016/j.jhydrol.2021.126881 View PDFView articleView in ScopusGoogle Scholar
    Gocić et al., 2015 M. Gocić, S. Motamedi, S. Shamshirband, D. Petković, S. Ch,
    R. Hashim, M. Arif Soft computing approaches for forecasting reference evapotranspiration
    Comput. Electron. Agric., 113 (2015), pp. 164-173, 10.1016/j.compag.2015.02.010
    View PDFView articleView in ScopusGoogle Scholar Gomariz-Castillo et al., 2017
    F. Gomariz-Castillo, F. Alonso-Sarría, F. Cabezas-Calvo-Rubio Calibration and
    spatial modelling of daily ET0 in semiarid areas using Hargreaves equation Earth
    Sci. Inform., 11 (3) (2017), pp. 325-340, 10.1007/s12145-017-0327-1 Google Scholar
    Guo et al., 2021 Guo, T., Song, S., Ma, W., 2021. Point and Interval Forecasting
    of Groundwater Depth Using Nonlinear Models. Water Resources Research. 57 (12),
    e2021WR030209.https://doi.org/10.1029/2021WR030209. Google Scholar Guo et al.,
    2020 T. Guo, S. Song, J. Shi, J. Li Groundwater Depth Forecasting Using Configurational
    Entropy Spectral Analyses with the Optimal Input Groundwater, 58 (5) (2020), pp.
    749-758, 10.1111/gwat.12968 View in ScopusGoogle Scholar Hargreaves and Samani,
    1985 G.H. Hargreaves, Z.A. Samani Reference crop evapotranspiration from temperature
    Appl. Eng. Agric., 1 (2) (1985), pp. 96-99 Google Scholar Huang et al., 2019 G.
    Huang, L. Wu, X. Ma, W. Zhang, J. Fan, X. Yu, W. Zeng, H. Zhou Evaluation of CatBoost
    method for prediction of reference evapotranspiration in humid regions J. Hydrol.,
    574 (2019), pp. 1029-1041, 10.1016/j.jhydrol.2019.04.085 View PDFView articleView
    in ScopusGoogle Scholar Kisi et al., 2019 O. Kisi, J. Piri, O. Mohammadrezapour
    Comparison of SVM, ANFIS and GEP in modeling monthly potential evapotranspiration
    in an arid region (Case study: Sistan and Baluchestan Province, Iran Water Supply,
    19 (2) (2019), pp. 392-403, 10.2166/ws.2018.084 Google Scholar Kundu et al., 2016
    S. Kundu, D. Khare, A. Mondal Future changes in rainfall, temperature and reference
    evapotranspiration in the central India by least square support vector machine
    Geosci. Front., 8 (3) (2016), pp. 583-596, 10.1016/j.gsf.2016.06.002 Google Scholar
    Li et al., 2021 F. Li, G. Ma, S. Chen, W. Huang An ensemble modeling approach
    to forecast daily reservoir inflow using bidirectional long- and short-term memory
    (Bi-LSTM), variational mode decomposition (VMD), and energy entropy method Water
    Resour. Manag., 35 (9) (2021), pp. 2941-2963, 10.1007/s11269-021-02879-3 View
    in ScopusGoogle Scholar Luan, 2017 Luan, C., 2017. Vacillations Analysis of Monthly
    Reference Crop Evapotranspiration Based on EMD Method. Proceedings of the 2017
    Asia-Pacific Computer Science and Application Conference. 69–74. Google Scholar
    Mohammadi and Mehdizadeh, 2020 B. Mohammadi, S. Mehdizadeh Modeling daily reference
    evapotranspiration via a novel approach based on support vector regression coupled
    with whale optimization algorithm Agric. Water Manag., 237 (2020), Article 106145,
    10.1016/j.agwat.2020.106145 View PDFView articleView in ScopusGoogle Scholar Niu
    and Feng, 2021 W.-j Niu, Z.-k Feng Evaluating the performances of several artificial
    intelligence methods in forecasting daily streamflow time series for sustainable
    water resources management Sustain. Cities Soc., 64 (2021), Article 102562, 10.1016/j.scs.2020.102562
    View PDFView articleView in ScopusGoogle Scholar Ozdenizci and Erdogmus, 2021
    O. Ozdenizci, D. Erdogmus Stochastic mutual information gradient estimation for
    dimensionality reduction networks Inf. Sci. (N. Y), 570 (2021), pp. 298-305, 10.1016/j.ins.2021.04.066
    View PDFView articleView in ScopusGoogle Scholar Pammar and Deka, 2017 L. Pammar,
    P.C. Deka Daily pan evaporation modeling in climatically contrasting zones with
    hybridization of wavelet transform and support vector machines Paddy Water Environ.,
    15 (4) (2017), pp. 711-722, 10.1007/s10333-016-0571-x View in ScopusGoogle Scholar
    Paredes et al., 2018 P. Paredes, D.S. Martins, L.S. Pereira, J. Cadima, C. Pires
    Accuracy of daily estimation of grass reference evapotranspiration using ERA-Interim
    reanalysis products with assessment of alternative bias correction schemes Agric.
    Water Manag., 210 (2018), pp. 340-353, 10.1016/j.agwat.2018.08.003 View PDFView
    articleView in ScopusGoogle Scholar Prasopchingchana, 2022 U. Prasopchingchana
    Direct numerical simulation of natural convection in a square cavity at high Rayleigh
    numbers via the Lagrange interpolating polynomial scheme Int. J. Therm. Sci.,
    172 (2022), Article 107276, 10.1016/j.asoc.2022.108676 View PDFView articleView
    in ScopusGoogle Scholar Priestley and Taylor, 1972 C.H.B. Priestley, R.J. Taylor
    On the assessment of surface heat ﬂux and evaporation using large-scale parameters
    Mon. Weather Rev., 100 (1972), pp. 81-92, 10.1175/1520-0493(1972)100<0081:OTAOSH>2.3.CO;2
    Google Scholar Qasem et al., 2019 S.N. Qasem, S. Samadianfard, S. Kheshtgar, S.
    Jarhan, O. Kisi, S. Shamshirband, K.-W. Chau Modeling monthly pan evaporation
    using wavelet support vector regression and wavelet artificial neural networks
    in arid and humid climates Eng. Appl. Comput. Fluid Mech., 13 (1) (2019), pp.
    177-187, 10.1080/19942060.2018.1564702 View in ScopusGoogle Scholar Qualls and
    Crago, 2020 R.J. Qualls, R.D. Crago Graphical interpretation of wet surface evaporation
    equations Water Resour. Res., 56 (10) (2020), 10.1029/2019wr026766 Google Scholar
    Rezaie-Balf et al., 2019 M. Rezaie-Balf, O. Kisi, L.H. Chua Application of ensemble
    empirical mode decomposition based on machine learning methodologies in forecasting
    monthly pan evaporation Hydrol. Res, 50 (2) (2019), pp. 498-516, 10.2166/nh.2018.050
    View in ScopusGoogle Scholar Seong, 2014 K.W. Seong Deriving a practical form
    of IDF formula using transformed rainfall intensities Hydrol. Process., 28 (2014),
    pp. 2881-2896, 10.1002/hyp.9806 View in ScopusGoogle Scholar Sethi and Mittal,
    2021 J.K. Sethi, M. Mittal An efficient correlation based adaptive LASSO regression
    method for air quality index prediction Earth Sci. Inform., 14 (4) (2021), pp.
    1777-1786, 10.1007/s12145-021-00618-1 View in ScopusGoogle Scholar Shirmohammadi-Aliakbarkhani
    and Saberali, 2020 Z. Shirmohammadi-Aliakbarkhani, S.F. Saberali Evaluating of
    eight evapotranspiration estimation methods in arid regions of Iran Agric. Water
    Manag., 239 (2020), Article 106243, 10.1016/j.agwat.2020.106243 View PDFView articleView
    in ScopusGoogle Scholar Song et al., 2021 C. Song, L. Yao, C. Hua, Q. Ni A water
    quality prediction model based on variational mode decomposition and the least
    squares support vector machine optimized by the sparrow search algorithm (VMD-SSA-LSSVM)
    of the Yangtze River, China Environ. Monit. Assess., 193 (6) (2021), pp. 193-363,
    10.1007/s10661-021-09127-6 View in ScopusGoogle Scholar Sun and Zhao, 2020 Z.
    Sun, M. Zhao Short-term wind power forecasting based on VMD decomposition, ConvLSTM
    networks and error analysis IEEE Access, 8 (2020), pp. 134422-134434, 10.1109/access.2020.3011060
    View in ScopusGoogle Scholar Tejada et al., 2022 A.T. Tejada, V.B. Ella, R.M.
    Lampayan, C.E. Reaño Modeling reference crop evapotranspiration using support
    vector machine (SVM) and extreme learning machine (ELM) in region IV-A, Philippines
    Water, 14 (5) (2022), p. 754, 10.3390/w14050754 View in ScopusGoogle Scholar Valle
    Júnior et al., 2020 L.C.G. Valle Júnior, T.M. Ventura, R.S.R. Gomes, S. de, J.
    Nogueira, A. de, F. Lobo, G.L. Vourlitis, T.R. Rodrigues Comparative assessment
    of modelled and empirical reference evapotranspiration methods for a brazilian
    savanna Agric. Water Manag., 232 (2020), Article 106040, 10.1016/j.agwat.2020.106040
    View PDFView articleView in ScopusGoogle Scholar Wang et al., 2021 D. Wang, J.
    Zhong, C. Li, Z. Peng Box-Cox sparse measures: a new family of sparse measures
    constructed from kurtosis and negative entropy Mech. Syst. Signal Process., 160
    (2021), Article 107930, 10.1016/j.ymssp.2021.107930 View PDFView articleView in
    ScopusGoogle Scholar Wen et al., 2015 X. Wen, J. Si, Z. He, J. Wu, H. Shao, H.
    Yu Support-vector-machine-based models for modeling daily reference evapotranspiration
    with limited climatic data in extreme arid regions Water Resour. Manag., 29 (9)
    (2015), pp. 3195-3209, 10.1007/s11269-015-0990-2 View in ScopusGoogle Scholar
    Wen et al., 2019 X. Wen, Q. Feng, R.C. Deo, M. Wu, Z. Yin, L. Yang, V.P. Singh
    Two-phase extreme learning machines integrated with the complete ensemble empirical
    mode decomposition with adaptive noise algorithm for multi-scale runoff prediction
    problems J. Hydrol., 570 (2019), pp. 167-184, 10.1016/j.jhydrol.2018.12.060 View
    PDFView articleView in ScopusGoogle Scholar Wu et al., 2020 T. Wu, W. Zhang, X.
    Jiao, W. Guo, Y.A. Hamoud Comparison of five Boosting-based models for estimating
    daily reference evapotranspiration with limited meteorological variables PLoS
    One, 15 (6) (2020), pp. 1-28, 10.1371/journal.pone.0235324 Google Scholar Xu et
    al., 2021 R. Xu, P. Gao, X. Mu, C. Gu Spatial-temporal change of actual evapotranspiration
    and the causes based on the advection–aridity model in the Weihe River Basin,
    China Wate, 13 (3) (2021), p. 303, 10.3390/w13030303 View in ScopusGoogle Scholar
    Yu et al., 2022 B. Yu, X. Wang, Y. Zhang, H. Gao, Y. Wang, Y. Liu, X. Gao RPI-MDLStack:
    predicting RNA-protein interactions through deep learning with stacking strategy
    and LASSO Appl. Soft Comput., 120 (2022), Article 108676, 10.1016/j.asoc.2022.108676
    View PDFView articleView in ScopusGoogle Scholar Zbili and Rama, 2021 M. Zbili,
    S. Rama A quick and easy way to estimate entropy and mutual information for neuroscience
    596443-596443 Front. Neuroinformatics, 15 (2021), 10.3389/FNINF.2021.596443 Google
    Scholar Zhang et al., 2017 F. Zhang, I. Keivanloo, Y. Zou Data transformation
    in cross-project defect prediction Empir. Softw. Eng., 22 (2017), pp. 3186-3218,
    10.1007/s10664-017-9516-2 View in ScopusGoogle Scholar Zhang et al., 2020 Y. Zhang,
    Z. Zhao, J. Zheng CatBoost: a new approach for estimating daily reference crop
    evapotranspiration in arid and semi-arid regions of Northern China J. Hydrol.,
    588 (2020), Article 125087, 10.1016/j.jhydrol.2020.125087 View PDFView articleView
    in ScopusGoogle Scholar Cited by (7) Interpretable hierarchical error correction
    GRU model for effective observation selection 2023, Applied Soft Computing Show
    abstract A review of the Artificial Intelligence (AI) based techniques for estimating
    reference evapotranspiration: Current trends and future perspectives 2023, Computers
    and Electronics in Agriculture Show abstract Design data decomposition-based reference
    evapotranspiration forecasting model: A soft feature filter based deep learning
    driven approach 2023, Engineering Applications of Artificial Intelligence Show
    abstract Estimation of daily reference evapotranspiration by hybrid singular spectrum
    analysis-based stochastic gradient boosting 2023, MethodsX Show abstract A novel
    multi-scale parameter estimation approach to the Hargreaves-Samani equation for
    estimation of Penman-Monteith reference evapotranspiration 2023, Agricultural
    Water Management Show abstract Evapotranspiration estimation using hybrid and
    intelligent methods 2023, Soft Computing View all citing articles on Scopus View
    Abstract © 2022 Elsevier B.V. All rights reserved. Recommended articles Influence
    of suspended solid particles on calcium carbonate fouling in dripper labyrinths
    Agricultural Water Management, Volume 273, 2022, Article 107890 Gustavo L. Muniz,
    …, José A. Frizzone View PDF Polythene mulch and potassium application enhances
    peanut productivity and biochemical traits under sustained salinity stress condition
    Agricultural Water Management, Volume 273, 2022, Article 107903 H.N. Meena, …,
    M.S. Meena View PDF Optimizing irrigation and fertilization frequency for greenhouse
    cucumber grown at different air temperatures using a comprehensive evaluation
    model Agricultural Water Management, Volume 273, 2022, Article 107876 Feng Qu,
    …, Xiaohui Hu View PDF Show 3 more articles Article Metrics Citations Citation
    Indexes: 7 Captures Readers: 12 View details About ScienceDirect Remote access
    Shopping cart Advertise Contact and support Terms and conditions Privacy policy
    Cookies are used by this site. Cookie settings | Your Privacy Choices All content
    on this site: Copyright © 2024 Elsevier B.V., its licensors, and contributors.
    All rights are reserved, including those for text and data mining, AI training,
    and similar technologies. For all open access content, the Creative Commons licensing
    terms apply."'
  inline_citation: '>'
  journal: Agricultural Water Management
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Novel hybrid machine learning framework with decomposition–transformation
    and identification of key modes for estimating reference evapotranspiration
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Sharma G.
  - Singh A.
  - Jain S.
  citation_count: '11'
  description: 'Precision agriculture aims to increase crop yield by employing an
    efficient resource management scheme, such as estimating irrigation requirements.
    Reference evapotranspiration (ET0), defined as the process of water loss from
    the soil and reference plant, is one of the indispensable components on which
    crop irrigation requirement depends. It is mainly calculated by using empirical
    models. However, these models require a large climate dataset that is sometimes
    unavailable in data-scarce regions. The present study focuses on the estimation
    of ET0 values by using three climate parameters as input variables i.e., minimum
    temperature (Tmin), maximum temperature (Tmax), and solar radiation (Rs). Moreover,
    to consider the effect of time-varying characteristics of the ET0 process, deep
    reinforcement learning (DRL) based ensemble approach, DeepEvap, is introduced
    to estimate ET0 values. The whole modeling procedure of the proposed ensemble
    model incorporates three phases. In phase I, the data preprocessing technique
    is performed on the meteorological data to clean the existing impurities as it
    affects the performance of any machine learning (ML) based approach. In phase
    II, four different deep neural network-based models are used to build the estimation
    model of ET0 and calculate the prediction results. In phase III, the DRL approach
    is used to ensemble the prediction results of these four models. The meteorological
    dataset of two stations of India: Ludhiana and Patiala, is selected to validate
    the proposed approach. The results of the conducted study depict that: (a) The
    proposed DeepEvap approach is competitive for ET0 prediction by achieving a coefficient
    of determination (R2) = 0.96. It significantly outperforms four baseline models;
    (b) The proposed technique also integrates four deep neural network models and
    works better than existing ensemble approaches.'
  doi: 10.1016/j.asoc.2022.109113
  full_citation: '>'
  full_text: '>

    "Skip to main content Skip to article Journals & Books Search Register Sign in
    Brought to you by: University of Nebraska-Lincoln View PDF Download full issue
    Outline Highlights Abstract Keywords 1. Introduction 2. Background 3. Problem
    formulation 4. Methodology 5. Experimental area and data description 6. Evaluation
    of model parameter 7. Results & discussion 8. Conclusion and future work CRediT
    authorship contribution statement Declaration of Competing Interest Acknowledgments
    References Show full outline Cited by (13) Figures (15) Show 9 more figures Tables
    (9) Table 1 Table 2 Table 3 Table 4 Table 5 Table 6 Show all tables Applied Soft
    Computing Volume 125, August 2022, 109113 DeepEvap: Deep reinforcement learning
    based ensemble approach for estimating reference evapotranspiration Author links
    open overlay panel Gitika Sharma, Ashima Singh, Sushma Jain Show more Add to Mendeley
    Share Cite https://doi.org/10.1016/j.asoc.2022.109113 Get rights and content Highlights
    • A DRL based approach, DeepEvap is proposed for daily prediction. • Daily prediction
    with limited climate data in data scarce conditions. • Diebold-Mariano Test is
    used to evaluate DeepEvap approach. • DeepEvap may assist agricultural practitioners
    for predicting crop evapotranspiration. Abstract Precision agriculture aims to
    increase crop yield by employing an efficient resource management scheme, such
    as estimating irrigation requirements. Reference evapotranspiration ( ), defined
    as the process of water loss from the soil and reference plant, is one of the
    indispensable components on which crop irrigation requirement depends. It is mainly
    calculated by using empirical models. However, these models require a large climate
    dataset that is sometimes unavailable in data-scarce regions. The present study
    focuses on the estimation of values by using three climate parameters as input
    variables i.e., minimum temperature ( ), maximum temperature ( ), and solar radiation
    ( ). Moreover, to consider the effect of time-varying characteristics of the process,
    deep reinforcement learning (DRL) based ensemble approach, DeepEvap, is introduced
    to estimate values. The whole modeling procedure of the proposed ensemble model
    incorporates three phases. In phase I, the data preprocessing technique is performed
    on the meteorological data to clean the existing impurities as it affects the
    performance of any machine learning (ML) based approach. In phase II, four different
    deep neural network-based models are used to build the estimation model of and
    calculate the prediction results. In phase III, the DRL approach is used to ensemble
    the prediction results of these four models. The meteorological dataset of two
    stations of India: Ludhiana and Patiala, is selected to validate the proposed
    approach. The results of the conducted study depict that: (a) The proposed DeepEvap
    approach is competitive for prediction by achieving a coefficient of determination
    ( ) = 0.96. It significantly outperforms four baseline models; (b) The proposed
    technique also integrates four deep neural network models and works better than
    existing ensemble approaches. Previous article in issue Next article in issue
    Keywords Reference evapotranspirationLimited climate dataDeep reinforcement learningDeep
    neural networkEnsemble learning 1. Introduction Water policy is among the most
    critical worldwide concerns that aim to regulate water consumption and determine
    the best strategies to avoid exploiting and squandering existing freshwater resources.
    India is a water-scarce country that is further exacerbated by the detrimental
    effects of climate change and a massive waste of water due to inadequate management
    and flawed pricing policies. Indian population covers 18% of the world’s population
    with 4% of total freshwater available globally and out of which 80% is consumed
    for agricultural purposes. Thus, water management in agriculture is always encouraged
    to meet the growing demand for food [1]. However, despite growing water scarcity,
    irrigation practice is still very inefficient in India. Therefore, it is necessary
    to design and implement irrigation practices to reduce the amount of irrigation
    water while sustaining or improving yield production. Agriculturists or irrigation
    engineers need to know the specific crop water requirement to obtain satisfactory
    crop yield, so that the right amount of irrigation water can be provided to avoid
    over or under irrigation [2]. Evapotranspiration (ET) is a significant factor
    that is used to determine the crop water requirement. It is the combined process
    of evaporation (water loss from the soil) and transpiration (water loss from plant
    stomata) that is influenced by climatic variables, crop traits, management techniques,
    and other environmental factors [3]. The necessity to study and understand evapotranspiration
    phenomena inspired the need to explore another comprehensive term known as reference
    evapotranspiration. Reference evapotranspiration is the amount of water evaporated
    from a reference surface, and it was proposed to measure atmospheric evaporative
    demand, irrespective of crop growth factors and management techniques [4], [5].
    The process of reference evapotranspiration is represented in Fig. 1. could simply
    be combined with crop coefficient of a particular crop to compute the value at
    any growth stage using following equation [6]. (1) Download : Download high-res
    image (292KB) Download : Download full-size image Fig. 1. Reference evapotranspiration
    . is a crucial part of the hydrological cycle and plays vital role in the sustainable
    water resource management [7], [8], [9]. The accurate estimation of evapotranspiration
    is a prerequisite for irrigation scheduling as well as for hydrological, climatological,
    and ecological research studies [10]. The quantification of process can be performed
    using direct methods such as methods based on vapor transfer (e.g., Bowen ratio
    and eddy covariance) or using water balance measurement technique (e.g., Lysimeters)
    [11]. Although these methods provide accurate estimation, their use is restricted
    due to technical complexities, expensive instrumentation, and laborious working
    process. The indirect method for calculation of involves empirical models based
    on meteorological data, which are considered as more appropriate approaches for
    real-life applications due to their various advantages over direct methods such
    as shorter time, lower cost, and easiness to use [12]. There are many existing
    empirical models that can be classified as mass transfer-based, radiation-based,
    temperature-based, and pan-evaporation-based [10]. However, their performance
    varies with the change in environmental conditions. Food Agriculture and Organization
    (FAO) has recommended FAO-56 Penman-Monteith (PM) as a reliable method to estimate
    that has been proved to provide consistent performance in different climate regions
    [13], [14], [15]. This method is accepted worldwide and used by agronomists, researchers,
    and irrigation engineers as a standard method for calculation. The main limitation
    that exists with the use of the FAO-56 PM equation is the extensive meteorological
    data required for the estimation of that is not always available for all locations,
    especially in developing countries like India [16]. Therefore, the development
    of a reliable, robust, and intelligent approach is required for estimating values
    using fewer meteorological datasets. The past few decades have experienced the
    development of various artificial intelligence (AI) based techniques to model,
    predict and optimize the process. These AI based techniques mainly include artificial
    neural network (ANN) based models e.g., multi-layer perceptron (MLP), radial basis
    function neural networks (RBF) and generalized regression neural networks (GRNN)
    [12], [17], [18], [19], [20], [21], genetic programming based models (GP) [22],
    [23], [24], [25], [26], tree based models e.g., random forest (RF) and M5 model
    tree (M5Tree) [21], [27], [28], [29], [30], kernal based models e.g., support
    vector machine (SVM) and least-squares support vector machine (LSSVM) [31], [32],
    [33], [34], [35] and other AI models such as multivariate adaptive regression
    splines (MARS) [33], [36], adaptive neuro-fuzzy inference system (ANFIS) [37],
    [38]. Although these AI-based techniques may provide reliable results, the main
    concern is that for a particular problem, different models produce different outputs
    [39], [40]. Ensemble learning is a technique that deals with other models to solve
    a specific problem [41]. It has been observed that an ensemble of different models
    results in improved forecasting accuracy and low error variance as compared to
    individual models [42], [43] and hence effective in real-world scenarios [44],
    [45]. However, as per the authors’ knowledge, very few works have been reported
    in the literature to model process using the ensemble learning technique. Weighted
    average based and stack-based ensembles are two prominent ensemble learning techniques
    [46]. Stack ensemble technique considers baseline models’s output as input features
    for another high-level model and trains it to generate the final output [40],
    [47]. The weighted average based ensemble approach calculates and combines the
    contribution weights of each baseline model to the final output by minimizing
    the mean square error (MSE) of ensemble outputs. However, these ensemble learning
    techniques suffer certain limitations. For example, stack-based ensemble technique
    is time-consuming, expensive to deploy, and does not perform better as compared
    to the best individual baseline model in some situations [48]. Also, in the weighted
    ensemble technique, the baseline models’s contribution weights remain the same
    and do not take into account the time-varying features of the input dataset (e.g.,
    climate dataset). Therefore, to overcome the stated limitations, this study proposes
    a novel ensemble technique based on the concept of DRL. It uses hybrid deep learning
    models as baseline models and agents of deep-Q-network (DQN) ensemble these models
    to ensure effective estimation of values. The novelties and contribution of this
    study are mentioned below: • A DRL based ensemble learning approach, DeepEvap
    is proposed for reference evapotranspiration estimation: An attempt is made to
    incorporate time varying characteristics of inputs by dynamically selecting models
    and to remove the static nature of ensemble techniques. Here, in DeepEvap approach,
    the DQN agent of DRL is trained to dynamically select the baseline model to predict
    the value for each specific input. These baseline models are based on convolution
    neural network (CNN) as follows: Convolution neural network-Long short term memory
    (CNN-LSTM), Convolution-Long Short Term Memory (Conv-LSTM), Convolution neural
    network-eXtreme Gradient Boosting (CNN-XGB), Convolution neural network-Support
    Vector Regression (CNN-SVR). • Use of limited input dataset to handle data-scarce
    situations: The conducted study also handles the data scarce situation and train
    the baseline models on the limited available datasets to efficiently estimate
    the process. , , and are proved to be prime data inputs for modeling and are easily
    available. Therefore, these parameters are provided as input to baseline models.
    • Comparison of existing stack-based ensemble and weighted average ensemble technique
    with proposed ensemble technique: DRL approach can become more intelligent via
    iterations and also can work in unknown dynamic environment of future climate
    data unlike stacked and weighted average ensemble approaches that use only historical
    data to predict the outcomes. The performance of the proposed DRL based ensemble
    technique is compared to the existing ensemble techniques: stack-based and weighted
    average based ensemble techniques to validate the proposed approach. Download
    : Download high-res image (276KB) Download : Download full-size image Fig. 2.
    Reinforcement learning. 2. Background DRL integrates a neural network with a reinforcement
    learning framework to help agents reach their targets. This learning technique
    is gaining popularity in many fields, especially dynamic decision-making systems.
    This technique is used to ensemble DL models to estimate values in the present
    study. This section presents the underlying theory to understand the proposed
    solution better. In particular, the overview of reinforcement learning is provided
    in Section 2.1, the introduction of Q learning is given in Section 2.2, and an
    illustration of Deep Q Network is presented in Section 2.3. 2.1. Reinforcement
    learning Reinforcement Learning (RL) is a paradigm of Machine Learning (ML) and
    works on the principle of dynamic programming that builds and trains algorithms
    using a reward and punishment strategy. It is different from other ML paradigms,
    so there is no need to provide an explicit recommendation to execute the task;
    instead, it solves the problem on its own. There exists set of states , set of
    actions , and reward in RL environment. The agent interacts with an environment
    and at time , perform an action , and move from state to a new state with some
    defined reward . The next action of the agent for the specific state is defined
    by policy function , which maps states and actions. The agent receives a reward
    for right actions and punishment for wrong actions. The main objective of RL is
    to identify the optimized policy that maximizes the discounted rewards by minimizing
    the punishment so that agent can take corrective action in the future for a particular
    state [49]. Mathematically, this process is formulated as Markov Decision Process
    (MDP) and represented as: (2) Here, is transition probability that can be described
    as the probability of state that move from one state to another state by taking
    an action . The value function for each state and action pair is the expected
    scalar reward in given state if agent performs an action , by following policy
    , and is mathematically represented as follows: (3) Here is reward function that
    defines the goals to be achieved by the agent. The optimal value function derived
    using the optimal policy provides the maximum reward achieved from all states
    by obeying the Bellman equation. This is given as follows. (4) The graphical representation
    of the reinforcement learning process is shown in Fig. 2. 2.2. Q learning Q-Learning
    is a value-based, model-free Reinforcement Learning algorithm that evaluates the
    quality of the action to be performed by agent-based on action-value function.
    It determines the value of being in a particular state and performing a particular
    action in that state. The basic Q learning version maintains a q-table containing
    values for each state–action pair. The two inputs: current state (s) and action
    (a), are provided to the Q function, and it returns reward as an output for that
    state–action pair. This Q value function satisfy Bellman equation and is represented
    as MDP as follows: (5) Here, is a discount factor that denotes the importance
    of future rewards compared to current rewards and ranges between 0 and 1. A discount
    factor of 0 means that the system prioritizes the current reward, whereas a value
    of 1 means that the system prioritizes future rewards. Initially, this function
    returns random fixed values before analyzing the environment. Afterward, with
    further analysis, the Q function provides a more accurate estimate of the value
    function for the action in the state . The Q function is constantly updating to
    provide the optimal value. The optimized policy can easily be obtained after obtaining
    the optimum Q value for each state–action pair, corresponding to the maximum value.
    This directs the agent on the optimum course of action to take in a particular
    condition . 2.3. Deep Q Network DQN is a reinforcement learning technique that
    combines deep neural networks and Q-Learning to enable RL to operate in complicated,
    high-dimensional, and dynamic environments [50]. The concept was first introduced
    to remove the shortcoming of Q learning, such as the curse of dimensionality caused
    by increased memory size for storing Q-table of a huge set of state–action and
    unrealistic amount of time required for exploring a large number of states to
    create Q-table [51]. It also removes the possibilities of overestimation due to
    the max operator present in the Q learning algorithms by using a neural network
    to approximate the Q value function [52]. DQN uses two strategies, namely, replay
    memory [53] and target network. In replay memory, the experience of the last time
    steps is collected using greedy policy and stored in memory with size . The primary
    objective of replay memory is to apply a set of experiences called a mini-batch
    to train neural networks that are selected randomly from replay memory to approximate
    the Q function. In target network the Q function is replaced by ,where represents
    parameters of network. This parameter is only updated after iterations to minimize
    the possibility of divergence as target value is kept constant for iterations.
    The target value can be given as follows: (6) The Loss is calculated using squared
    difference between the target and updated Q value and represented in Eq. (7).
    The Stochastic Gradient descent (SGD) is used to minimize the loss. (7) The value
    is updated by minimizing the mean square error in Bellman equation using Eq. (8)
    (8) where is the learning rate. 3. Problem formulation The process of prediction
    can be formulated as a mixed-integer nonlinear programming problem (MINLP) which
    consists of input data (climate parameters), a set of constraints followed by
    an objective function to predict the values. The input training data can be formulated
    as a tuple: , where , , and are the daily average minimum and maximum temperature
    and solar radiation. In any prediction problem, the actual observed value can
    be represented as: (9) where is the observed value, denotes the real value of
    true predicted function and is noise. In this study, Deep Learning (DL) models
    are used as prediction models that try to find the function closer to the true
    function . The main aim of the prediction model is to minimize the distance of
    predicted and actual values to reduce errors. The mean square error is the expected
    value of the square difference of predicted value from its true value . It can
    be mathematically represented as: (10) This MSE can be further decomposed to the
    sum of bias and variance present in the predicted function. Bias is defined as
    the difference between the expected value of to the true predicted function .
    The bias can be represented as: (11) Variance is calculated as average square
    deviation of from its expected value and mathematically represented as follows:
    (12) Now, MSE can be rewritten as sum of bias, variance and non-reducible error
    . (13) Because of the bias–variance issue, it is logical to balance bias and variance
    as optimization goals. Thus, the objective function for the stated problem can
    be formulated as: (14) The core of ensemble learning is to minimize bias and variance.
    Thus ensemble approach has been adopted to minimize the objective function. Four
    hybrid DL models, such as CNN-LSTM, Conv-LSTM, CNN-XGB, and CNN-SVR, act as the
    baseline models for the ensemble approach. 4. Methodology The framework of the
    methodology used to conduct the study is shown in Fig. 3. It includes three parts:
    prediction of by baseline models, ensembling baseline models using DRL, and prediction
    of the final output. This section elaborates on the proposed DRL-based ensemble
    prediction model. The Section 4.1 introduces the baseline models used to the predict
    values. The prediction of these models serves ensemble learning. In Section 4.2,
    the proposed Ensemble Approach using the DQN algorithm is discussed in detail.
    4.1. Baseline prediction models The selection of baseline models for the ensemble
    approach is critical. In the conducted study, ten AI regression algorithms and
    their hybrid versions with Convolution Neural Network (CNN) is explored. These
    algorithms belong to a different paradigm and have been proved effective in the
    context of modeling the evapotranspiration process, and regression problems in
    past studies. These algorithms are: Support Vector Regressor (SVR), eXtreme Gradient
    Boosting (XGBoost), Random Forest (RF), Artificial Neural network (ANN), Long
    Short-term memory (LSTM), CNN, CNN-LSTM, CNN-XGB, CNN-SVR, and CNN-RF. These algorithms
    are applied on the dataset used in the study and ranked in order of their performance
    as shown in Table 1. Among these algorithms, we have opted top 4 algorithms for
    ensemble techniques that provides higher performance than other models. Download
    : Download high-res image (1MB) Download : Download full-size image Fig. 3. Framework
    of proposed approach. Thus, the study uses four hybrid deep neural network models
    (CNN-LSTM, Conv-LSTM, CNN-XGB, and CNN-SVR) to construct baseline models for ensemble
    learning. Each hybrid deep neural network model use historical data to obtain
    the prediction result of . The principle of these baseline models is discussed
    in the following subsections. Table 1. Performance comparison of different AI
    algorithms. Model R2 RMSLE MSE Conv-LSTM 0.948262 0.001226 0.002502 CNN-XGB 0.943238
    0.001301 0.002745 CNN-SVR 0.942897 0.001294 0.002762 CNN-LSTM 0.93656 0.001432
    0.003068 LSTM 0.927483 0.001639 0.003507 CNN-RF 0.905995 0.002352 0.004534 ANN
    0.903026 0.002418 0.004558 XGB 0.894868 0.002714 0.004941 SVR 0.886865 0.002844
    0.005456 RF 0.877211 0.003142 0.005921 4.1.1. CNN-LSTM CNN-LSTM is a hybrid neural
    network model that integrates the layers of Convolutional Neural Networks(CNN)
    and long short-term memory (LSTM) into a single framework. This model was firstly
    proposed by Sainath et al. [54]. It has already been proven that relevant features
    improve the performance of LSTM. CNN algorithm is widely known to extract relevant
    features from input data. The architecture of CNN-LSTM consists of CNN layer,
    LSTM layer, and dense layer to produce the final output. The extracted relevant
    features from CNN layers are fed to corresponding LSTM layers. Finally, after
    performing temporal modeling, the output of the LSTM is passed to a fully connected
    layer to provide sequential output [55]. 4.1.2. Conv-LSTM Shi et al. [56] proposed
    convolution LSTM network firstly in 2015. It is a type of recurrent neural network
    (RNN). Its basic operation is identical to the LSTM model, except that the convolution
    operation instead of matrix operation is applied to determine the input to state
    and state to state transitions. At each iteration , LSTM cells receive input and
    output of hidden state. The convolution operation is performed to generate output
    and state update using input , the output of hidden state , the output state of
    current cell , and output state of the previous cell. 4.1.3. CNN-XGB CNN-XGB was
    proposed by Ren et al. [57] in 2017. CNN has been identified as the most potent
    and effective feature extraction mechanism. eXtreme Gradient Boosting (XGBoost)
    is a Gradient Boosting-based integrated learning technique that achieves accurate
    results through iterative computing of weak learners. It has been used in many
    research studies because of its high performance and efficiency. CNN-XGB hybrid
    model incorporates features of CNN and XGBoost model together into one framework.
    The architecture of this model consists of stacked CNN layers to automatically
    extract relevant features from the input data, and the XGBoost regressor replaces
    the final layer of the CNN network and utilizes the trainable features from CNN
    to perform regression analysis generate output. 4.1.4. CNN-SVR CNN-SVR, a hybrid
    deep neural network model, was firstly proposed by Niu et al. [58] in 2012. It
    integrates the synergy of two powerful DL and ML algorithms: CNN and Support Vector
    Machine (SVM). In this study, the architecture of the CNN-SVR model is designed
    by substituting the output layer of CNN with an SVR regressor. The output of the
    last layer of the CNN provides the estimated probability of input samples. An
    activation function calculates each output probability by taking a linear combination
    of output from the preceding layers. The SVR considers this output unit as a vector
    of input features to train the regressor model. Once trained, the SVR performs
    the regression job and makes new predictions on testing data based on extracted
    salient features by the CNN. 4.2. Ensemble approach based on DRL The downside
    of existing ensemble techniques is that the chosen solution is implemented to
    every time step, and thus it makes the combination of the baseline models invariant.
    However, distinct baseline models exhibit different accuracy rates for distinct
    observations. The predictions of each baseline model are unstable for all time
    steps. Therefore, a deep reinforcement learning-based framework is proposed to
    dynamically choose the best model for each time step to tackle this problem. There
    are five components of the constructed reinforcement learning framework: state,
    action, reward, agent, and environment. These components are described in the
    following subsections. 4.2.1. State The state-space for the defined problem is
    represented as observations of real-world environment parameters such as climate
    parameters used to estimate values. Here, only limited climate parameters are
    used to develop a technique that can handle data-scarce situations without compromising
    the prediction accuracy. The state is described as follows: (15) The abovementioned
    state includes three climate parameters : minimum temperature ( ), maximum temperature
    ( ), and, solar radiation ( ). All the state parameters are normalized to scale
    to remove the effect of amplitude. 4.2.2. Action The action space is the option
    of baseline models that the agent will select for estimating process. (16) In
    this case, there are four possible actions in terms of hybrid DL models such as
    for , for , for , and for model is performed. The selection of these actions that
    are to be performed by an agent is determined by a greedy policy. 4.2.3. Reward
    The aim of the reward design is to minimize the prediction error over all time
    steps. The reward for the action is calculated by observing the prediction error
    made by the selected hybrid DL model. If prediction error is minimum among all
    other models, the reward is positive; otherwise, a negative reward is awarded.
    The current action at time selects model from a set of ensembled models and the
    prediction result of the ensembled model is given as follows: (17) where f(t)
    is output of proposed ensembling approach for datapoint at time step by selecting
    model . Now, calculate the absolute prediction error of the prediction result
    from actual value as follows: (18) This prediction error is compared to the prediction
    error of the static selected model with minimum prediction error among all other
    models at time to design reward architecture. If the prediction error is the same
    as the error of the static selected model , then reward is positive otherwise
    negative. The mathematical representation of the reward function is given as follows:
    (19) The agent is trained to gradually select the optimum model for time step
    by following the direction of reward. 4.2.4. Agent The agent’s main objective
    is to develop an optimum policy that chooses actions to achieve maximum cumulative
    future rewards. It interacts with the environment using actions, rewards, and
    observations. In this research study, DQN is used as an agent to determine an
    action to select an optimal hybrid DL model using - greedy approach for the estimation
    of values. Download : Download high-res image (679KB) Download : Download full-size
    image Fig. 4. Flowchart of proposed approach. 4.2.5. Environment The reinforcement
    environment can be expressed as follows: (20) where S denotes a set of state-space,
    A denotes the action-space set, r indicates the reward function, and P indicates
    the transition probability of state. Algorithm 1 depicts the DQN based ensembling
    for prediction. The flowchart of the proposed approach is presented in Fig. 4.
    Download : Download high-res image (304KB) Download : Download full-size image
    5. Experimental area and data description The research study is conducted in the
    Ludhiana and Patiala stations of Punjab, India. Ludhiana station is situated between
    latitude and North and longitude and East at an altitude of 262 m. This station
    falls under a semi-arid tropical ecosystem, characterized by a significant amount
    of rainfall of 680 mm throughout the year, with dry and hot summers and cold winters.
    Patiala station is situated between latitude and North and longitude and East
    with an altitude of 351 m. This station also falls under a semi-arid tropical
    ecosystem, characterized by dry and hot summers and cold winter. The average annual
    rainfall is approximately 677 mm. Fig. 5 shows the location of these two stations.
    Daily meteorological inputs, e.g., minimum temperature , maximum temperature ,
    relative humidity , windspeed , sunshine hours , and solar radiation covering
    a period of 13 years (2003 to 2015) and 17 years (2000 to 2015) of Ludhiana station
    and Patiala station respectively, is retrieved from India meteorological department
    (IMD) Pune, India to evaluate the proposed technique. Table 2, Table 3 show the
    statistical observations of meteorological data of both stations. The cross-correlation
    among meteorological data of Ludhiana and Patiala station is provided in Table
    4. Download : Download high-res image (1MB) Download : Download full-size image
    Fig. 5. Study area. Table 2. Statistical observation of the meteorological data
    used in the study of Ludhiana station. Training dataset Testing dataset −1.6 34.5
    17.4 8.1 −0.2 −1.2 0.5 −1 31.2 17.9 8 −0.2 −1.2 0.5 7.8 46.2 29.8 7.5 −0.4 −0.6
    0.3 8.6 44.2 30.1 7.1 −0.4 −0.3 0.3 20.5 100 66.9 15.6 −0.7 0.04 0.2 23 100 67.4
    15.5 −0.7 0.03 0.2 0 3.3 1.1 0.6 0.9 0.7 0.6 0 3.2 1.1 0.6 0.9 0.6 0.6 3.6 30
    14.7 6.4 0.46 −1.1 0.4 4.2 28.4 15.2 6.52 0.5 −1.3 0.4 4.8 29.7 17.5 6.3 −0.1
    −0.91 0.4 4.8 29.5 17.7 6.3 −0.1 −0.97 0.4 0.6 9.5 3.8 1.9 0.4 −0.8 0.5 0.6 9.4
    3.8 1.9 0.4 −0.8 0.5 Table 3. Statistical observation of the meteorological data
    used in the study of Patiala station. Training dataset Testing dataset −2.1 31.4
    15.6 8.4 −0.3 −1.2 0.5 −2.6 29.6 15.7 8.3 −0.3 −1.2 0.5 7.4 48.0 30.2 7.8 −0.3
    −0.6 0.3 7.8 46.4 30.3 7.9 −0.5 −0.4 0.3 13.0 99.0 66.0 18.0 −0.6 −0.1 0.3 19.0
    99.0 66.1 18.5 −0.7 −0.1 0.3 0.0 8.6 1.4 1.3 1.1 1.3 0.9 0.0 7.2 1.4 1.3 1.0 1.0
    0.9 0.0 12.4 6.5 3.2 −0.7 −0.4 0.5 0.0 12.4 6.6 3.2 −0.7 −0.5 0.5 4.9 28.4 16.5
    5.9 −0.2 −0.8 0.4 4.9 28.3 16.5 5.9 −0.2 −0.8 0.4 0.6 13.2 4.0 2.4 0.9 0.3 0.6
    0.7 12.9 3.9 2.4 0.8 0.2 0.6 Table 4. Cross-correlation among meteorological variables
    and ET0 of Ludhiana and Patiala Station. Ludhiana station Patiala station 1 0.85
    −0.23 0.35 0.17 0.57 0.8 1 0.87 −0.44 0.12 0.34 0.67 0.8 0.85 1 −0.62 0.25 0.46
    0.76 0.9 0.87 1 −0.71 0.14 0.56 0.80 0.8 −0.2 −0.62 1 −0.16 −0.5 −0.57 −0.6 −0.44
    −0.712 1 −0.24 −0.50 −0.63 −0.7 0.35 0.25 −0.16 1 −0.07 0.17 0.5 0.12 0.14 −0.24
    1 0.05 0.14 0.5 0.17 0.46 −0.5 −0.07 1 0.86 0.5 0.34 0.56 −0.50 0.053 1 0.89 0.6
    0.57 0.76 −0.57 0.17 0.86 1 0.9 0.67 0.80 −0.63 0.14 0.89 1 0.8 0.77 0.87 −0.62
    0.48 0.54 0.86 1 0.77 0.83 −0.68 0.50 0.58 0.82 1 FAO-56 PM equation is used to
    compute values to obtain the benchmark dataset to compare the values estimated
    by proposed models. The conducted study considers limited climate parameters such
    as , , and to estimate values and then evaluate how close it can get to actual
    observations made by the FAO-56 PM equation. Fig. 6, Fig. 7 shows the seasonal
    variation in , and of Ludhiana and Patiala stations respectively. The meteorological
    dataset is preprocessed to transform the data into a useful and efficient format.
    Data preprocessing includes missing data treatment, outlier detection, and normalization.
    In this study, the mixgb package of R programming language [59], proposed by Deng
    et al., is used to handle missing values. Outlier detection is performed using
    the z-score method, whereas normalization of data is done using min–max scaler
    [60]. Download : Download high-res image (455KB) Download : Download full-size
    image Fig. 6. Seasonal variation of meteorological data of Ludhiana station. Download
    : Download high-res image (437KB) Download : Download full-size image Fig. 7.
    Seasonal variation of meteorological data of Patiala station. 6. Evaluation of
    model parameter Prediction accuracy is an essential parameter in the assessment
    of predictive models. In the study, five model performance evaluation metrics
    are employed in terms of mean square error (MSE), root means square log error
    (RMSLE), error variance score (EVS), Nash-Sutcliffe efficiency (NSE), and coefficient
    of determination (R2). Further, Diebold–Mariano (DM) test is also used to assess
    the predicting ability of the proposed ensemble technique. The mathematical representation
    of five performance evaluation metrics are as follows: (21) (22) (23) (24) where
    (mmd-1) is FAO-56 PM estimated or observed value , is the predicted value of for
    the th value of data point, is mean of observed value of and is the number of
    data points considered in the study. MSE is the mean of the squared difference
    between observed and estimated values and lies between 0 to . The lower MSE value
    shows that model makes better estimation. RMSLE calculates the root of squared
    differences between the log-transformed observed and predicted values of the model,
    and the optimal value of this metric is 0.0. Explained Variance Score (EVS) indicates
    how efficiently the given model can explain the variations in the dataset or measure
    the discrepancy between predicted and actual values. The value closer to 1.0 indicates
    that the model makes better predictions [61]. represents the degree of correlation
    between predicted values of by proposed models and observed values estimated by
    FAO-56 PM. NSE is widely used in hydrological modeling and determines the model’s
    accuracy for the actual observations. It ranges between 0 to 1, where a value
    closer to 1 represents the best quality of the model. 6.1. Diebold–Mariano test
    The standard evaluation metrics, such as MSE, R2, etc., are useful for comparing
    the performance of two models. However, these metrics cannot determine the significant
    difference in the prediction of two predictive models. Hypothesis testing is a
    statistical inference technique to determine the significant difference between
    the two predictive models by quantifying confidence levels. In the present study,
    Diebold–Mariano (DM) hypothesis test [62] is employed to assess the performance
    of the proposed DRL-based ensemble model. Let denotes the observed value and and
    denote the estimated value of by two predictive models for time series climate
    data. The objective is to determine if these two models are significantly different.
    The errors between observed and predicted values of these two models are defined
    as: (25) (26) where and denotes the error between observed and predicted values
    of model 1 and model 2 respectively. The loss function (L(E)) is used to determine
    the precision of each prediction. Two widely used loss functions are absolute
    deviation error (27) and squared error loss (28) Here is error of prediction of
    th input. In this study, to examine if one model predicts better than other model,
    equal accuracy hypothesis is tested. The null hypothesis for the study is (29)
    against the alternative hypothesis (30) Here, and denotes the loss functions of
    model 1 and model 2 respectively. Table 5. Performance comparison of baseline
    models for Ludhiana station. Models Train Empty Cell Test Empty Cell MSE R2 RMSLE
    EVS Empty Cell MSE R2 RMSLE EVS CNN-LSTM 0.003354 0.932629 0.001568 0.935775 0.003068
    0.936560 0.001432 0.940903 Conv-LSTM 0.002940 0.940930 0.001441 0.942152 0.002502
    0.948262 0.001226 0.948746 CNN-XGB 0.002943 0.940875 0.001389 0.941625 0.002745
    0.943238 0.001301 0.943425 CNN-SVR 0.003015 0.939441 0.001417 0.940024 0.002762
    0.942897 0.001294 0.944099 Table 6. Performance comparison of baseline models
    for Patiala Station. Models Train Empty Cell Test Empty Cell MSE R2 RMSLE EVS
    Empty Cell MSE R2 RMSLE EVS CNN-LSTM 0.003330 0.933110 0.001571 0.934357 0.002998
    0.938004 0.001408 0.938779 Conv-LSTM 0.002919 0.941369 0.001464 0.943999 0.002519
    0.947927 0.001241 0.949443 CNN-XGB 0.002813 0.943485 0.001384 0.943525 0.002829
    0.941516 0.001343 0.941733 CNN-SVR 0.003080 0.938126 0.001454 0.938807 0.002721
    0.943738 0.001285 0.945095 The null hypothesis states that the prediction accuracy
    of the two models is the same, whereas the alternative hypothesis states that
    the accuracy of the models varies. The DM test statistic can be formulated as
    follows: (31) Here, represents the variance of . The null hypothesis will be rejected
    for the present study if the DM test score is not in the range of [ 1.96, 1.96]
    at 5% confidence level. 7. Results & discussion This section analyzes the four
    baseline models’ performance using the meteorological dataset of Ludhiana and
    Patiala stations. Then, the estimation ability of the proposed DRL-based ensemble
    model is evaluated and compared to the baseline models’ estimation abilities using
    four performance metrics, i.e., MSE, , RMSLE, and EVS, followed by the Diebold–Mariano
    test. To further assess the performance of the proposed DeepEvap approach, the
    estimation results of alternative existing ensemble models (stacked and weighted
    ensemble models) are also added as a contrast. 7.1. Prediction of by baseline
    models The CNN-LSTM, Conv-LSTM, CNN-SVR, and CNN-XGB deep neural networks are
    evaluated in this section to observe the effectiveness of these models in prediction.
    The bar-graph representation of prediction results of these four baseline models
    for Ludhiana and Patiala stations is shown in Fig. 8. The performance comparison
    of these models for training and testing datasets is provided in Table 5, Table
    6 for Ludhiana and Patiala stations, respectively. The meteorological dataset
    of Ludhiana and Patiala station is divided into a training dataset (70%) and testing
    dataset (30%), 10% of the training dataset is further used as a validation set
    for the hyperparameter tuning process. The hyperparameters of these models, such
    as number of filters, learning rate, activation function, batch size, number of
    hidden nodes, number of epochs, etc., are selected using the random search algorithm
    of the Keras tuner library. Minimization of the mean square error (MSE) is the
    objective function during neural network training that represents the degree to
    which the neural network approximates the prediction. It is noteworthy that if
    these hyper-parameters are not selected carefully, the performance of these baseline
    models gets affected and can even lead to worst performance. However, this phenomenon
    helps in building more powerful ensemble model, since the baseline models with
    different hyper-parameters are naturally diverse. It can be observed from the
    Table 5, Table 6 that Conv-LSTM shows best overall prediction, with MSE, , RMSLE,
    and EVS values 0.002502 , 0.948262, 0.001226 , and 0.948746 for Ludhiana Station
    and 0.002519 , 0.947927, 0.001241 , and 0.949443 for Patiala Station respectively.
    According to experimental results, CNN-LSTM provide worst performance with MSE
    0.003354 to 0.003330 . Download : Download high-res image (495KB) Download : Download
    full-size image Fig. 8. Performance measures of baseline models of Ludhiana and
    Patiala station. It has been further noted that a single deep neural network is
    not capable of adequately estimating for different meteorological datasets. The
    primary reason for this could be that different deep neural networks have varied
    hidden layer structures, resulting in recognition abilities for different meteorological
    datasets. Therefore, a technique (e.g., ensemble learning) that can increase the
    model’s flexibility and resilience is required. In the following subsection, the
    performance of the proposed DeepEvap approach is discussed. 7.2. Results of proposed
    ensemble model This subsection provides the results of the proposed DRL-based
    ensemble model. The line graph represents the relationship between two sets of
    values, where one set is always dependent on the other. The line graph representation
    of prediction values over time by the proposed ensemble model versus actual values
    is shown in Fig. 9. It is evident from Fig. 9 that the proposed model can simulate
    the actual values of . In order to prove that the ensemble model shows better
    performance than baseline models, the proposed DRL-based ensemble model is compared
    to the CNN-LSTM model, the Conv-LSTM model, CNN-SVR model, and the CNN-XGB model.
    Table 7 shows the performance comparison of baseline models (CNN-LSTM, Conv-LSTM,
    CNN-SVR, and CNN-XGB) with the proposed model. Table 7. Performance comparison
    of the proposed dynamic ensemble method and baseline models. Station Models MSE
    R2 RMSLE EVS Ludhiana CNN-LSTM 0.003068 0.936560 0.001432 0.940903 Conv-LSTM 0.002502
    0.948262 0.001226 0.948746 CNN-SVR 0.002745 0.943238 0.001301 0.943425 CNN-XGB
    0.002762 0.942897 0.001294 0.944099 Proposed DeepEvap approach 0.001889 0.960948
    0.000909 0.961137 Patiala CNN-LSTM 0.002998 0.938004 0.001408 0.938779 Conv-LSTM
    0.002519 0.947927 0.001241 0.949443 CNN-SVR 0.002829 0.941516 0.001343 0.941733
    CNN-XGB 0.002721 0.943738 0.001285 0.945095 Proposed DeepEvap approach 0.001864
    0.961452 0.000880 0.962270 Table 8. Diebold–Mariano test of baseline models with
    proposed ensemble model. Model DM Statistics Empty Cell Ludhiana Patiala CNN-LSTM
    7.97 8.58 Conv-LSTM 6.85 6.75 CNN-XGB 7.10 6.88 CNN-SVR 7.10 7.82 Proposed DeepEvap
    approach – – Download : Download high-res image (640KB) Download : Download full-size
    image Fig. 9. Prediction results of: (a) Ludhiana station (b) Patiala station
    (left to right). Further to examine the effectiveness of the proposed DRL based
    ensemble model, the Diebold–Mariano test is conducted with these baseline models.
    This test is conducted to determine if there is a significant difference in the
    prediction performance of the two models. The detailed discussion of this model
    is presented in Section 6.1. Table 8 represents the DM statistics values using
    absolute deviation error as loss function. The results indicate that DM values
    of CNN-LSTM, Conv-LSTM, CNN-SVR, and CNN-XGB models are above the upper limits
    of 5% significance level. Thus the null hypothesis of the study: the prediction
    accuracy of two models is the same, is rejected. Table 7, Table 8 indicate that
    the proposed ensemble model (DeepEvap) substantially outperforms the baseline
    models and is significantly better than these models. For instance, the MSE, ,
    RMSLE, and EVS of proposed DeepEvap are 0.001889 , 0.960948, 0.000909 , and 0.961137
    respectively for Ludhiana station and the MSE, , RMSLE, and EVS of the proposed
    ensemble model are 0.001864 , 0.96145, 0.000880 , and 0.962269 respectively. The
    scatter plot of the baseline models and the proposed model is presented in Fig.
    10, Fig. 11 of Ludhiana and Patiala stations, respectively. The highest accordance
    with the 1:1 line is observed with the proposed ensemble model (DeepEvap). The
    examination of regression lines reveals that the slop value (“a”) and intercept
    value (“b”) of the proposed DeepEvap approach deviate slightly from their ideal
    values (a 1 and b 0) as compared to four baseline models. It shows that the proposed
    ensemble model is more reliable than the baseline models. Moreover, the study
    aims to minimize the objective function, i.e., MSE. It is clear from Table 5 that
    the proposed DeepEvap approach has achieved minimum MSE as compared to four baseline
    models. The MSE value of CNN-LSTM, Conv-LSTM, CNN-XGB, CNN-SVR, and proposed DeepEvap
    approach for Ludhiana station is 0.003068, 0.002502, 0.002745, 0.002761 and 0.001888
    respectively and for Patiala station MSE value of CNN-LSTM, Conv-LSTM, CNN-XGB,
    CNN-SVR and, proposed DeepEvap approach is 0.002998, 0.002518, 0.0028286, 0.002721,
    and 0.0018644 respectively. Download : Download high-res image (769KB) Download
    : Download full-size image Fig. 10. Scatter plot of baseline models and proposed
    ensemble model (DeepEvap) of Ludhiana station. Download : Download high-res image
    (775KB) Download : Download full-size image Fig. 11. Scatter plot of baseline
    models and proposed ensemble model (DeepEvap) of Patiala station. 7.3. Comparison
    with alternative ensemble approaches Deep Reinforcement Learning (DRL) works best
    in decision-making problems of a dynamic environment. An agent learns via repeated
    interactions with the environment to attain a goal. Such interaction generates
    information regarding the outcomes of the agent’s behavior and helps in improving
    the performance. The proposed ensemble technique uses a deep reinforcement approach
    to dynamically select models for prediction by interacting with the environment
    and incorporating the time varying input characteristics. However, other approaches
    such as weighted and stacked ensemble approaches are static and do not deploy
    time-varying environment characteristics. In this subsection, a comparative study
    is carried out to validate the effectiveness of the proposed DeepEvap approach.
    The Proposed model (PM), DeepEvap, is compared to the best baseline model and
    two existing ensemble approaches, weighted ensemble model (WM) and stacked ensemble
    model (SM). Table 9 summarizes the performance comparison of the proposed DeepEvap
    approach with the best baseline model, weighted ensemble, and stacked ensemble
    model. It can be gleaned from Table 9 that the presented DRL based ensemble model,
    DeepEvap improves the result by decreasing the MSE value of the best baseline
    model by 25%, weighted ensemble model by 22% and stacked ensemble model by 20%
    for Ludhiana station and Patiala station the MSE value is decreased by 26%, weighted
    ensemble model by 22% and stacked ensemble model by 19%. Fig. 12, Fig. 13 show
    the absolute prediction error of the weighted ensemble model, stacked ensemble
    model, and the proposed ensemble model of Ludhiana and Patiala station, respectively.
    It can be observed that the prediction error of the proposed ensemble model is
    lower than that of the other two ensemble models. Thus it shows the superiority
    of the proposed model over existing ensemble approaches. The heat map of Diebold
    Mariano test values for each pair of models used in the study is represented in
    Fig. 14(a) and (b) for both stations. Table 9. Performance comparison of best
    baseline model, weighted ensemble model, stacked ensemble model, and proposed
    ensemble model. Station Models MSE R2 RMSLE EVS Ludhiana Best baseline model 0.002502
    0.948262 0.001226 0.948746 Weighted ensemble model 0.002406 0.950257 0.001165
    0.950316 Stacked ensemble model 0.002365 0.951098 0.001142 0.952603 Proposed DeepEvap
    approach 0.001889 0.960948 0.000909 0.961137 Patiala Best baseline model 0.002519
    0.947927 0.001241 0.949443 Weighted ensemble model 0.002391 0.950558 0.001155
    0.950702 Stacked ensemble model 0.002296 0.952528 0.001109 0.952855 Proposed DeepEvap
    approach 0.001864 0.961452 0.000880 0.962270 Download : Download high-res image
    (462KB) Download : Download full-size image Fig. 12. Error detected in the estimation
    of of Ludhiana station by (a) Weighted ensemble model (b) Stacked ensemble model,
    (c) Proposed ensemble model (left to right). Download : Download high-res image
    (480KB) Download : Download full-size image Fig. 13. Error detected in the estimation
    of of Patiala station by (a) Weighted ensemble model (b) Stacked ensemble model,
    (c) Proposed ensemble model (left to right). It is observed from the heat map
    that for Ludhiana station, the pairs {CNN-SVR, CNN-XGB} and {SM, WM} have DM values
    in the range of [ 1.96,1.96]. Thus for these pairs, the null hypothesis cannot
    be rejected, i.e., no model is superior to each other. However, the remaining
    pairs of the models are significant at a 5% significance level. The DM values
    for pairs {SM, PM} and {WM, PM} are 4.9 and 5.5, respectively, which shows the
    significant difference in the prediction performance of the proposed DeepEvap
    approach, stacked and a weighted ensemble model. In Fig. 14(b), the heat map of
    the Patiala station shows that DM values for the pairs {Conv-LSTM, CNN-SVR}, {CNN-SVR,
    CNN-XGB}, {Conv-LSTM, WM} are in the range of [ 1.96,1.96] and thus null hypothesis
    for these pairs cannot be rejected. In other words, these models are not better
    than each other significantly. However, for all other pairs of models involved
    in the study, DM values show a significant difference in the prediction of values.
    The DM values for the pairs {SM, PM} and {WM, PM} are 5 and 5.3, respectively,
    and thus null hypothesis is rejected. The overall results of the Diebold–Mariano
    study demonstrate that prediction results obtained from the proposed ensemble
    model differ significantly from existing ensemble models and baseline models.
    Download : Download high-res image (529KB) Download : Download full-size image
    Fig. 14. Diebold–Mariano test: (a) DM values for Ludhiana station (b) DM values
    for Patiala station. This study examines the proposed DRL based ensemble approach,
    DeepEvap in respect to how this approach can predict values using , , and . Traore
    et al. [19] also used , , and as input set to predict using Multi-layer Perceptron
    (MLP) and achieve MSE value 0.770 . However, this study is able to achieve MSE
    value 0.001889 . Fan et al. explored different input combinations to model process
    and with combination , , and as input dataset, the 0.91 to 0.95 for different
    station was achieved. The proposed DeepEvap approach used in study has obtained
    0.96 for different dataset. This comparison reveals the usefulness of the proposed
    DeepEvap approach for modeling the process. 8. Conclusion and future work Predicting
    reference evapotranspiration with reasonable accuracy in data-scarce regions requires
    modeling the process using a limited dataset. This study proposes the DRL based
    ensemble model that uses , , and to model process. Four types of deep neural network
    models, including CNN-LSTM, Conv-LSTM, CNN-SVR, and CNN-XGB, act as baseline models
    for the proposed ensembling approach. The meteorological data of two stations:
    Ludhiana and Patiala of India, is used to conduct this study. The experimental
    results demonstrate that the proposed DRL ensemble model can effectively predict
    values with 0.96. Further, the proposed model is also superior to other existing
    ensemble models (weighted ensemble model and stacked ensemble model) and four
    base deep neural network models in terms of low mean square error and a high coefficient
    of determination. The proposed DRL ensemble model also incorporates time-varying
    input characteristics to remove the static nature of existing ensemble techniques
    by dynamically selecting baseline models for each specific input to predict .
    The following conclusion can be drawn from the conducted study: • The conducted
    study addresses the issue of unavailability of most of the meteorological parameters
    required to estimate values. The proposed DRL based ensemble model predicts values
    using , , and climate variables and achieve 0.96 and 0.0018 for both stations.
    • The proposed DRL-based ensemble model can efficiently integrate four deep neural
    network models (CNN-LSTM, Conv-LSTM, CNN-SVR, and CNN-XGB) and improve the prediction
    results of baseline models by minimizing the mean square error. • Although the
    proposed DRL ensemble approach provides closer performance to other existing ensemble
    approaches, the major aspect of the proposed ensemble approach is to implement
    an intelligent and coherent system that surmounts the state-of-art deep learning
    models and can work in an unknown dynamic environment (such as climate change)
    and provide reasonable accuracy using limited climate data. Thus, unlike other
    approaches that use only historical data to predict outcomes, the DRL approach
    can become more intelligent via iterations and work in an unknown dynamic environment
    of future climate data. • This model may assist irrigation engineers in regulating
    the irrigation water supply. The irrigation water requirement (IR) is the difference
    between the crop water requirement (ET) and the effective rainfall (Pe) as shown
    in the given formula: (32) An irrigation engineer utilizes ET to compute the available
    water in the soil. So, if it rains and fills the ground, there is no requirement
    for irrigation; otherwise, irrigation is needed. It helps irrigation engineers
    to determine when the plant will need water, even if the ground looks dry at the
    surface. The proposed approach provides values using less number of climate parameters
    that can help irrigation engineers to estimate irrigation requirements in data
    scarce situations. However, the proposed approach deserves further scrutiny to
    improve the practical application of the proposed model in the future. • The complexity
    of the proposed DRL based ensemble model can be decreased by embedding it into
    big data platforms, e.g., Hadoop can reduce the amount of elapsed time of the
    model. • The study uses meteorological data of semi-arid region stations. Another
    study can be conducted in the future for meteorological data of hyper-arid, arid,
    humid, and sub-humid regions to observe the generalized behavior of the proposed
    ensemble model. • Different sets of baseline models can be used to validate the
    performance of the proposed ensemble approach. CRediT authorship contribution
    statement Gitika Sharma: Conceptualization, Methodology, Simulation, Result analysis,
    Visualization, Writing – original draft. Ashima Singh: Investigation, Supervision.
    Sushma Jain: Investigation, Supervision. Declaration of Competing Interest The
    authors declare that they have no known competing financial interests or personal
    relationships that could have appeared to influence the work reported in this
    paper. Acknowledgments The authors acknowledge the help rendered by the Food Security
    Centre at Thapar Institute of Engineering and Technology. The authors also express
    their gratitude to the India Meteorological Department (IMD), Pune India, to provide
    the meteorological data of Ludhiana and Patiala stations. References [1] Dhawan
    V. Water and agriculture in India Background Paper for the South Asia Expert Panel
    During the Global Forum for Food and Agriculture, Vol. 28 (2017) Google Scholar
    [2] Kisi O. The potential of different ANN techniques in evapotranspiration modelling
    Hydrol. Process. Int. J., 22 (14) (2008), pp. 2449-2460 CrossRefView in ScopusGoogle
    Scholar [3] Singh V.P. Hydrologic Systems. volume i: rainfall-Runoff Modeling,
    Vol. 480 Prentice Hall, Englewood Cliffs New Jersey (1988) 1988 Google Scholar
    [4] Allen R.G., Pereira L.S., Raes D., Smith M., et al. Crop Evapotranspiration-Guidelines
    for Computing Crop Water Requirements-FAO Irrigation and Drainage Paper 56, Vol.
    300 Fao, Rome (1998), p. D05109 9 Google Scholar [5] Zotarelli L., Dukes M.D.,
    Romero C.C., Migliaccio K.W., Morgan K.T. Step by step calculation of the Penman-Monteith
    Evapotranspiration (FAO-56 Method) Institute of Food and Agricultural Sciences.
    University of Florida (2010) Google Scholar [6] Jensen M.E. Water consumption
    by agricultural plants Water deficits and plant growth. Volume II. Plant water
    consumption and response, Academic Press Inc, New York (1968), pp. 1-22 CrossRefGoogle
    Scholar [7] Cruz-Blanco M., Lorite I., Santos C. An innovative remote sensing
    based reference evapotranspiration method to support irrigation water management
    under semi-arid conditions Agricult. Water Manag., 131 (2014), pp. 135-145 View
    PDFView articleView in ScopusGoogle Scholar [8] Pereira L.S., Allen R.G., Smith
    M., Raes D. Crop evapotranspiration estimation with FAO56: Past and future Agricult.
    Water Manag., 147 (2015), pp. 4-20 View PDFView articleView in ScopusGoogle Scholar
    [9] Yassin M.A., Alazba A., Mattar M.A. Artificial neural networks versus gene
    expression programming for estimating reference evapotranspiration in arid climate
    Agricult. Water Manag., 163 (2016), pp. 110-124 View PDFView articleView in ScopusGoogle
    Scholar [10] Gocic M., Trajkovic S. Service-oriented approach for modeling and
    estimating reference evapotranspiration Comput. Electron. Agric., 79 (2) (2011),
    pp. 153-158 View PDFView articleView in ScopusGoogle Scholar [11] Ding R., Kang
    S., Li F., Zhang Y., Tong L., Sun Q. Evaluating eddy covariance method by large-scale
    weighing lysimeter in a maize field of northwest China Agricult. Water Manag.,
    98 (1) (2010), pp. 87-95 View PDFView articleView in ScopusGoogle Scholar [12]
    Ferreira L.B., da Cunha F.F., de Oliveira R.A., Fernandes Filho E.I. Estimation
    of reference evapotranspiration in Brazil with limited meteorological data using
    ANN and SVM–A new approach J. Hydrol., 572 (2019), pp. 556-570 View PDFView articleView
    in ScopusGoogle Scholar [13] Allen R.G., Clemmens A.J., Burt C.M., Solomon K.,
    O’Halloran T. Prediction accuracy for projectwide evapotranspiration using crop
    coefficients and reference evapotranspiration J. Irrig. Drain. Eng., 131 (1) (2005),
    pp. 24-36 View in ScopusGoogle Scholar [14] ASCE-EWRI The ASCE standardized reference
    evapotranspiration equation (2005), p. 213 Google Scholar [15] Xu J., Peng S.,
    Ding J., Wei Q., Yu Y. Evaluation and calibration of simple methods for daily
    reference evapotranspiration estimation in humid east China Arch. Agron. Soil
    Sci., 59 (6) (2013), pp. 845-858 CrossRefView in ScopusGoogle Scholar [16] Pandey
    P.K., Dabral P.P., Pandey V. Evaluation of reference evapotranspiration methods
    for the northeastern region of India Int. Soil Water Conserv. Res., 4 (1) (2016),
    pp. 52-63 View PDFView articleView in ScopusGoogle Scholar [17] Ladlani I., Houichi
    L., Djemili L., Heddam S., Belouz K. Estimation of daily reference evapotranspiration
    (ET 0) in the North of Algeria using adaptive neuro-fuzzy inference system (ANFIS)
    and multiple linear regression (MLR) models: a comparative study Arab. J. Sci.
    Eng., 39 (8) (2014), pp. 5959-5969 CrossRefView in ScopusGoogle Scholar [18] Petković
    D., Gocic M., Shamshirband S., Qasem S.N., Trajkovic S. Particle swarm optimization-based
    radial basis function network for estimation of reference evapotranspiration Theor.
    Appl. Climatol., 125 (3) (2016), pp. 555-563 CrossRefView in ScopusGoogle Scholar
    [19] Traore S., Luo Y., Fipps G. Deployment of artificial neural network for short-term
    forecasting of evapotranspiration using public weather forecast restricted messages
    Agricult. Water Manag., 163 (2016), pp. 363-379 View PDFView articleView in ScopusGoogle
    Scholar [20] Feng Y., Cui N., Zhao L., Hu X., Gong D. Comparison of ELM, GANN,
    WNN and empirical models for estimating reference evapotranspiration in humid
    region of Southwest China J. Hydrol., 536 (2016), pp. 376-383 View PDFView articleView
    in ScopusGoogle Scholar [21] Feng Y., Cui N., Gong D., Zhang Q., Zhao L. Evaluation
    of random forests and generalized regression neural networks for daily reference
    evapotranspiration modelling Agricult. Water Manag., 193 (2017), pp. 163-173 View
    PDFView articleView in ScopusGoogle Scholar [22] Kim S., Kim H.S. Neural networks
    and genetic algorithm approach for nonlinear evaporation and evapotranspiration
    modeling J. Hydrol., 351 (3–4) (2008), pp. 299-317 View PDFView articleView in
    ScopusGoogle Scholar [23] Kisi O. Fuzzy genetic approach for modeling reference
    evapotranspiration J. Irrig. Drain. Eng., 136 (3) (2010), pp. 175-183 View in
    ScopusGoogle Scholar [24] Traore S., Guven A. New algebraic formulations of evapotranspiration
    extracted from gene-expression programming in the tropical seasonally dry regions
    of west Africa Irrig. Sci., 31 (1) (2013), pp. 1-10 CrossRefView in ScopusGoogle
    Scholar [25] Gocić M., Motamedi S., Shamshirband S., Petković D., Ch S., Hashim
    R., Arif M. Soft computing approaches for forecasting reference evapotranspiration
    Comput. Electron. Agric., 113 (2015), pp. 164-173 View PDFView articleView in
    ScopusGoogle Scholar [26] Shiri J. Modeling reference evapotranspiration in island
    environments: assessing the practical implications J. Hydrol., 570 (2019), pp.
    265-280 View PDFView articleView in ScopusGoogle Scholar [27] Fan J., Yue W.,
    Wu L., Zhang F., Cai H., Wang X., Lu X., Xiang Y. Evaluation of SVM, ELM and four
    tree-based ensemble models for predicting daily reference evapotranspiration using
    limited meteorological data in different climates of China Agricult. Forest Meteorol.,
    263 (2018), pp. 225-241 View PDFView articleView in ScopusGoogle Scholar [28]
    Shiri J. Improving the performance of the mass transfer-based reference evapotranspiration
    estimation approaches through a coupled wavelet-random forest methodology J. Hydrol.,
    561 (2018), pp. 737-750 View PDFView articleView in ScopusGoogle Scholar [29]
    Fan J., Ma X., Wu L., Zhang F., Yu X., Zeng W. Light Gradient Boosting Machine:
    An efficient soft computing model for estimating daily reference evapotranspiration
    with local and external meteorological data Agricult. Water Manag., 225 (2019),
    Article 105758 View PDFView articleView in ScopusGoogle Scholar [30] Granata F.
    Evapotranspiration evaluation models based on machine learning algorithms—A comparative
    study Agricult. Water Manag., 217 (2019), pp. 303-315 View PDFView articleView
    in ScopusGoogle Scholar [31] Wen X., Si J., He Z., Wu J., Shao H., Yu H. Support-vector-machine-based
    models for modeling daily reference evapotranspiration with limited climatic data
    in extreme arid regions Water Resour. Manage., 29 (9) (2015), pp. 3195-3209 CrossRefView
    in ScopusGoogle Scholar [32] Shrestha N., Shukla S. Support vector machine based
    modeling of evapotranspiration using hydro-climatic variables in a sub-tropical
    environment Agricult. Forest Meteorol., 200 (2015), pp. 172-184 View PDFView articleView
    in ScopusGoogle Scholar [33] Kisi O., Parmar K.S. Application of least square
    support vector machine and multivariate adaptive regression spline models in long
    term prediction of river water pollution J. Hydrol., 534 (2016), pp. 104-112 View
    PDFView articleView in ScopusGoogle Scholar [34] Mehdizadeh S., Behmanesh J.,
    Khalili K. Using MARS, SVM, GEP and empirical equations for estimation of monthly
    mean reference evapotranspiration Comput. Electron. Agric., 139 (2017), pp. 103-114
    View PDFView articleView in ScopusGoogle Scholar [35] Tikhamarine Y., Malik A.,
    Souag-Gamane D., Kisi O. Artificial intelligence models versus empirical equations
    for modeling monthly reference evapotranspiration Environ. Sci. Pollut. Res.,
    27 (2020), pp. 30001-30019 CrossRefView in ScopusGoogle Scholar [36] Deo R.C.,
    Samui P., Kim D. Estimation of monthly evaporative loss using relevance vector
    machine, extreme learning machine and multivariate adaptive regression spline
    models Stoch. Environ. Res. Risk Assess., 30 (6) (2016), pp. 1769-1784 CrossRefView
    in ScopusGoogle Scholar [37] Tao H., Diop L., Bodian A., Djaman K., Ndiaye P.M.,
    Yaseen Z.M. Reference evapotranspiration prediction using hybridized fuzzy model
    with firefly algorithm: Regional case study in Burkina Faso Agricult. Water Manag.,
    208 (2018), pp. 140-151 View PDFView articleView in ScopusGoogle Scholar [38]
    Khosravi K., Daggupati P., Alami M.T., Awadh S.M., Ghareb M.I., Panahi M., Pham
    B.T., Rezaie F., Qi C., Yaseen Z.M. Meteorological data mining and hybrid data-intelligence
    models for reference evaporation simulation: A case study in Iraq Comput. Electron.
    Agric., 167 (2019), Article 105041 View PDFView articleView in ScopusGoogle Scholar
    [39] Nourani V., Elkiran G., Abdullahi J. Multi-station artificial intelligence
    based ensemble modeling of reference evapotranspiration using pan evaporation
    measurements J. Hydrol., 577 (2019), Article 123958 View PDFView articleView in
    ScopusGoogle Scholar [40] Martín J., Sáez J.A., Corchado E. On the suitability
    of stacking-based ensembles in smart agriculture for evapotranspiration prediction
    Appl. Soft Comput., 108 (2021), Article 107509 View PDFView articleView in ScopusGoogle
    Scholar [41] Tama B.A., Rhee K.-H. Tree-based classifier ensembles for early detection
    method of diabetes: an exploratory study Artif. Intell. Rev., 51 (3) (2019), pp.
    355-370 CrossRefView in ScopusGoogle Scholar [42] Qu Z., Zhang K., Mao W., Wang
    J., Liu C., Zhang W. Research and application of ensemble forecasting based on
    a novel multi-objective optimization algorithm for wind-speed forecasting Energy
    Convers. Manage., 154 (2017), pp. 440-454 View PDFView articleView in ScopusGoogle
    Scholar [43] Yang Z., Wang J. A combination forecasting approach applied in multistep
    wind speed forecasting based on a data processing strategy and an optimized artificial
    intelligence algorithm Appl. Energy, 230 (2018), pp. 1108-1125 View PDFView articleView
    in ScopusGoogle Scholar [44] Masih A. Application of ensemble learning techniques
    to model the atmospheric concentration of SO2 Glob. J. Environ. Sci. Manage.,
    5 (3) (2019), pp. 309-318 View in ScopusGoogle Scholar [45] Wang Y., Wang A.,
    Ai Q., Sun H. Ensemble based fuzzy weighted extreme learning machine for gene
    expression classification Appl. Intell., 49 (3) (2019), pp. 1161-1171 CrossRefGoogle
    Scholar [46] Chen C., Liu H. Dynamic ensemble wind speed prediction model based
    on hybrid deep reinforcement learning Adv. Eng. Inform., 48 (2021), Article 101290
    View PDFView articleGoogle Scholar [47] Cui S., Yin Y., Wang D., Li Z., Wang Y.
    A stacking-based ensemble learning method for earthquake casualty prediction Appl.
    Soft Comput., 101 (2021), Article 107038 View PDFView articleView in ScopusGoogle
    Scholar [48] Guo C., Liu M., Lu M. A dynamic ensemble learning algorithm based
    on K-means for ICU mortality prediction Appl. Soft Comput., 103 (2021), Article
    107166 View PDFView articleView in ScopusGoogle Scholar [49] Sutton R.S., Barto
    A.G., et al. Introduction To Reinforcement Learning, Vol. 135 MIT press Cambridge
    (1998) Google Scholar [50] Shi Y., Li W., Zhu L., Guo K., Cambria E. Stock trading
    rule discovery with double deep Q-network Appl. Soft Comput., 107 (2021), Article
    107320 View PDFView articleView in ScopusGoogle Scholar [51] Mnih V., Kavukcuoglu
    K., Silver D., Rusu A.A., Veness J., Bellemare M.G., Graves A., Riedmiller M.,
    Fidjeland A.K., Ostrovski G., et al. Human-level control through deep reinforcement
    learning Nature, 518 (7540) (2015), pp. 529-533 CrossRefView in ScopusGoogle Scholar
    [52] H. Van Hasselt, A. Guez, D. Silver, Deep reinforcement learning with double
    q-learning, in: Proceedings of the AAAI Conference on Artificial Intelligence,
    30 (2016). Google Scholar [53] Lin L.-J. Self-improving reactive agents based
    on reinforcement learning, planning and teaching Mach. Learn., 8 (3–4) (1992),
    pp. 293-321 View in ScopusGoogle Scholar [54] Sainath T.N., Vinyals O., Senior
    A., Sak H. Convolutional, long short-term memory, fully connected deep neural
    networks 2015 IEEE International Conference on Acoustics, Speech and Signal Processing
    (ICASSP), IEEE (2015), pp. 4580-4584 CrossRefView in ScopusGoogle Scholar [55]
    Naeem H., Bin-Salem A.A. A CNN-LSTM network with multi-level feature extraction-based
    approach for automated detection of coronavirus from CT scan and X-ray images
    Appl. Soft Comput., 113 (2021), Article 107918 View PDFView articleView in ScopusGoogle
    Scholar [56] Xingjian S., Chen Z., Wang H., Yeung D.-Y., Wong W.-K., Woo W.-c.
    Convolutional LSTM network: A machine learning approach for precipitation nowcasting
    Advances in Neural Information Processing Systems (2015), pp. 802-810 Google Scholar
    [57] Ren X., Guo H., Li S., Wang S., Li J. A novel image classification method
    with CNN-XGBoost model International Workshop on Digital Watermarking, Springer
    (2017), pp. 378-390 CrossRefView in ScopusGoogle Scholar [58] Niu X.-X., Suen
    C.Y. A novel hybrid CNN–SVM classifier for recognizing handwritten digits Pattern
    Recognit., 45 (4) (2012), pp. 1318-1325 View PDFView articleView in ScopusGoogle
    Scholar [59] Deng Y., Lumley T. Multiple imputation through XGBoost (2021) arXiv
    preprint arXiv:2106.01574 Google Scholar [60] Al Shalabi L., Shaaban Z. Normalization
    as a preprocessing engine for data mining and the approach of preference matrix
    2006 International Conference on Dependability of Computer Systems, IEEE (2006),
    pp. 207-214 CrossRefView in ScopusGoogle Scholar [61] Rosenthal G., Rosenthal
    J.A. Statistics and Data Interpretation for Social Work Springer publishing company
    (2011) Google Scholar [62] Chen H., Wan Q., Wang Y. Refined diebold-mariano test
    methods for the evaluation of wind power forecasting models Energies, 7 (7) (2014),
    pp. 4185-4198 CrossRefView in ScopusGoogle Scholar Cited by (13) Evaluation of
    TerraClimate gridded data in investigating the changes of reference evapotranspiration
    in different climates of Iran 2024, Journal of Hydrology: Regional Studies Show
    abstract Harnessing the power of transformers and data fusion in smart irrigation
    2024, Applied Soft Computing Show abstract A review of recent advances and future
    prospects in calculation of reference evapotranspiration in Bangladesh using soft
    computing models 2024, Journal of Environmental Management Show abstract Ensemble
    reinforcement learning: A survey 2023, Applied Soft Computing Show abstract A
    review of deep learning techniques used in agriculture 2023, Ecological Informatics
    Show abstract A review of the Artificial Intelligence (AI) based techniques for
    estimating reference evapotranspiration: Current trends and future perspectives
    2023, Computers and Electronics in Agriculture Show abstract View all citing articles
    on Scopus View Abstract © 2022 Elsevier B.V. All rights reserved. Recommended
    articles On the suitability of stacking-based ensembles in smart agriculture for
    evapotranspiration prediction Applied Soft Computing, Volume 108, 2021, Article
    107509 Juan Martín, …, Emilio Corchado View PDF Investigating the ability of deep
    learning on actual evapotranspiration estimation in the scarcely observed region
    Journal of Hydrology, Volume 607, 2022, Article 127506 Xiaoshu Wang, …, Xu-Sheng
    Wang View PDF An extreme learning machine approach for modeling evapotranspiration
    using extrinsic inputs Computers and Electronics in Agriculture, Volume 121, 2016,
    pp. 385-392 Amit Prakash Patil, Paresh Chandra Deka View PDF Show 3 more articles
    Article Metrics Citations Citation Indexes: 10 Captures Readers: 35 View details
    About ScienceDirect Remote access Shopping cart Advertise Contact and support
    Terms and conditions Privacy policy Cookies are used by this site. Cookie settings
    | Your Privacy Choices All content on this site: Copyright © 2024 Elsevier B.V.,
    its licensors, and contributors. All rights are reserved, including those for
    text and data mining, AI training, and similar technologies. For all open access
    content, the Creative Commons licensing terms apply."'
  inline_citation: '>'
  journal: Applied Soft Computing
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: 'DeepEvap: Deep reinforcement learning based ensemble approach for estimating
    reference evapotranspiration'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - El Mezouari A.
  - El Fazziki A.
  - Sadgal M.
  citation_count: '2'
  description: Given the growing scarcity and strong demand for water resources, the
    sustainability of water resource management requires an urgent policy of measures
    to ensure the rational use of these resources. The heterogeneous properties of
    groundwater systems are related to the dynamic temporal-spatial patterns that
    cause great difficulty in quantifying their complex processes, while good regional
    groundwater level forecasts are completely required for managing water resources
    to guarantee suitable support of water demands within any area. Water managers
    and farmers need intelligent groundwater and irrigation planning systems and effective
    mechanisms to benefit from the scientific and technological revolution, particularly
    the artificial intelligence engines, to enhance the water support in their water
    use planning practices. Therefore, this work aims to improve the groundwater level
    prediction based on the previous measures for better planning of hydraulic resource
    use. For this concern, the suggested method starts with data-preprocessing using
    the Principal Component Analysis method. Next, we validated the effectiveness
    of the hybrid artificial neural network, combined with an extended genetic algorithm
    for the hyperparameters and weight optimization, in predicting the groundwater
    levels in a selected monitoring well in California. The evaluation results have
    demonstrated the performance of the optimized ANN-GA model.
  doi: 10.2166/ws.2022.165
  full_citation: '>'
  full_text: '>

    "All Content All Journals This Journal                              Advanced Search
    Cart Register UNIVERSITY OF NEBRASKA Sign In ISSUES JOURNAL INFORMATION LIBRARIANS
    BOOKS ABOUT Select Language▼ Volume 22, Issue 5 1 May 2022 Previous Article Next
    Article Article Contents Abstract HIGHLIGHTS INTRODUCTION MATERIALS AND METHODS
    RESULTS AND DISCUSSION CONCLUSION CONFLICT OF INTEREST FUNDING DATA AVAILABILITY
    STATEMENT REFERENCES RESEARCH ARTICLE| APRIL 16 2022 A hybrid artificial neural
    network: An optimization-based framework for smart groundwater governance Asmae
    El Mezouari; Abdelaziz El Fazziki; Mohammed Sadgal Water Supply (2022) 22 (5):
    5237–5252. https://doi.org/10.2166/ws.2022.165 Article history Views PDF Share
    Tools Abstract Listen Given the growing scarcity and strong demand for water resources,
    the sustainability of water resource management requires an urgent policy of measures
    to ensure the rational use of these resources. The heterogeneous properties of
    groundwater systems are related to the dynamic temporal-spatial patterns that
    cause great difficulty in quantifying their complex processes, while good regional
    groundwater level forecasts are completely required for managing water resources
    to guarantee suitable support of water demands within any area. Water managers
    and farmers need intelligent groundwater and irrigation planning systems and effective
    mechanisms to benefit from the scientific and technological revolution, particularly
    the artificial intelligence engines, to enhance the water support in their water
    use planning practices. Therefore, this work aims to improve the groundwater level
    prediction based on the previous measures for better planning of hydraulic resource
    use. For this concern, the suggested method starts with data-preprocessing using
    the Principal Component Analysis method. Next, we validated the effectiveness
    of the hybrid artificial neural network, combined with an extended genetic algorithm
    for the hyperparameters and weight optimization, in predicting the groundwater
    levels in a selected monitoring well in California. The evaluation results have
    demonstrated the performance of the optimized ANN-GA model. HIGHLIGHTS Listen
    Smart Groundwater Governance Framework. Pertinent Data Extraction with Principal
    Component Analysis. The Artificial Neural Networks’ hyper-parameters optimization.
    The Artificial Neural Networks’ weights optimization. Improving the groundwater
    levels prediction is primordial to sustainable water management. Graphical Abstract
    Graphical Abstract VIEW LARGEDOWNLOAD SLIDE artificial neural networks, genetic
    algorithm, groundwater level prediction, knowledge extraction, principal component
    analysis, digitalwatercollection, digitalwatertechniques INTRODUCTION Listen In
    the last decades, groundwater has become the most important source of the freshwater
    serving of global water demands in the world. Hence, the availability of groundwater
    is the most crucial factor impacting socioeconomic development. Adding to that,
    given the climate changes nowadays, the impact of non-integrated water resources
    management is becoming a global problem all over the world, especially in countries
    characterized by overpopulation or intensive agricultural activities (Lall et
    al. 2020). In addition, domestic water needs, industrial and irrigation requirements
    increased the demand for groundwater. Therefore, desalination constitutes a primordial
    pillar for serving the increasing water demand for drinking, irrigation, and industries.
    However, desalination may deeply threaten the natural environment, according to
    Panagopoulos (2021a). For this reason, many studies are directed to develop safe
    desalination treatments (Panagopoulos 2021b, 2021c). Moreover, because of the
    important decrease in freshwater, the critical groundwater level monitoring allows
    consistent policies to decrease some constraints related to sustainable water
    management, like the water loss of pumping in wells dedicated to domestic water
    supply, aquifer compaction, and land surface subsidence (Guzy & Malinowska 2020).
    Likewise, many pieces of research have been conducted to study and detect the
    internal relationships between the hydrological and soil dynamics parameters or
    to model and evaluate the quality of water based on various Artificial Neural
    Networks, Adaptive Neuro-Fuzzy Inference Systems, and curve fitting (Alrashed
    et al. 2018a; Bahrami et al. 2019; Ghasemi et al. 2019; Moradikazerouni et al.
    2019; Safaei et al. 2019; Khosravi et al. 2021). However, systems allowing monitoring
    of groundwater levels, groundwater quality, and land subsidence are too expensive
    (Edwards & Guilfoos 2021). Consequently, groundwater level assessment is usually
    taken as a priority over controlling groundwater quality and land subsidence.
    In some previous research works, most of the hydrological studies rely on physical
    and conceptual models to detect and describe hydrological parameters, resulting
    from physical processes in the ground (Alrashed et al. 2018b; Karimipour et al.
    2018; Bagherzadeh et al. 2019; Karimipour et al. 2019; Peng et al. 2020; Giwa
    et al. 2021). However, some practical limitations related to extracting and gathering
    the data still exist. Furthermore, a new ensemble modeling framework that relies
    on spectral analysis, machine learning, and uncertainty analysis has been deployed
    by Sahoo et al. (2017) to study climate change, surface water flows, and irrigation
    activity relationships for a better understanding and prediction of the groundwater
    level change. The approach was applied to two aquifer systems that support production
    in agriculture in the United States, starting from selecting input data sets based
    on mutual information, genetic algorithms (GAs), and lag analysis, to using the
    selected data sets in a Multilayer Perceptron Artificial Neural Network architecture
    to simulate seasonal groundwater level change. The results show that the huge
    amounts of agricultural and hydrogeological data required for building and calibrating
    models for water resource management systems increase the complexity of their
    integration and sustainability. Recently, a multitude of researchers have conducted
    comparative studies on various machine learning algorithms in groundwater prediction,
    including Artificial Neural Networks (ANN) such as in Wen et al. (2017) where
    the results of the comparison show that the wavelet analysis combined with the
    Artificial Neural Network (WA-ANN) outperforms the basic ANN in terms of accuracy
    using different data samples, including groundwater level and climatic data. Furthermore,
    a study by Wunsch et al. (2021) focused on comparing different ANN architectures,
    such as Conventional Recurrent Artificial Neural Networks, especially the non-linear
    autoregressive networks with exogenous input (NARX) and famous deep learning ANN
    models like long short-term memory (LSTM) and convolutional neural networks (CNNs);
    in terms of efficiency and applying different training methods for an accurate
    prediction of groundwater level in the long term. The results showed that the
    NARX superficial neural networks might outperform the Deep Learning algorithms,
    specifically in dealing with limited training data, where they can exceed both
    LSTMs and CNNs. However, LSTMs and CNNs might compute more precisely with a larger
    dataset. In another context, regarding the importance of applying reliable and
    accurate models for the prediction of groundwater level beneath evolving climatic
    circumstances, a recent study in Müller et al. (2021) introduces the primordial
    hyperparameter optimization in boosting the performance of machine learning models.
    In this experiment, researchers conducted a comparative study to evaluate the
    performance of three methods for hyperparameter selection, especially a random
    sampling method, and two surrogate model-based algorithms. They applied these
    methods to four modern deep learning (deep ANN) computational models, and the
    empirical results generated from all trained models show that the optimization
    of the hyperparameters gives reasonable and accurate performance. Ordinarily,
    the basic backpropagation artificial neural networks (BP-ANN) are applied with
    random hyperparameters, and weight initialization resulting from the symmetry
    breaking. Nevertheless, the random initialization of the hyperparameters and weights
    for training the neural networks may lead to trapping in local minima and slow
    convergence. Thus, the basic ANN models used in previous studies are usually not
    enough for the satisfaction of the desired solution towards a reliable predictive
    model for anticipating the future change of available water to act more accurately.
    Hence, data extraction and optimization-based GAs could be used as the magic solution
    to overcome these issues and improve the performance and efficiency of the ANN
    algorithms. Therefore, this work presents an interesting data extraction and a
    hybrid machine learning optimization based predictive approach that enhances the
    groundwater level change prediction accuracy required for sustainable groundwater
    consumption planning; by improving the training of the ANN model and enhancing
    its efficiency, precision, and robustness. This method relies on artificial intelligence
    tools, especially the ANNs, combined with the GA for the hyperparameters and weight
    optimization, hydrological cycle knowledge, and data mining tools. The rest of
    this paper is organized as follows. Firstly, section 2 exposes the proposed framework''s
    architecture, the groundwater level, and depth measurement methods, and the different
    data processing and evaluation methods used in this study. Then, section 3 depicts
    the results of the proposed approach with a case study of groundwater level prediction
    in a well-monitoring station in California, US. Finally, this work ends with a
    concise conclusion and future perspectives. MATERIALS AND METHODS The suggested
    framework Listen The proposed framework, presented in Figure 1, intends to estimate
    and predict the groundwater surface level based on the depth to water surface
    change and other groundwater monitoring parameters that have been made by relying
    on hysterical groundwater level sensing in the sited wells to help in scheduling
    and pumping groundwater for industrial and irrigation use. The main goal of this
    component is therefore to facilitate the task for the water resource manager by
    ensuring an automatic estimation of the groundwater-surface level by predicting
    the water surface elevation based on the depth to water surface change and other
    relevant features extracted for selecting the appropriate predictive model, standing
    on the advances in data sensing, machine learning, and hyperparameter optimization
    tools. The principal components present in this framework are explained as follows:
    A data acquisition module that provides data on the wells, environment, and plots
    where the groundwater level data and reports are measured by direct manipulation
    in the well or sensed and saved automatically using other components like smart
    sensors, controllers, and storage devices. Figure 1 VIEW LARGEDOWNLOAD SLIDE The
    Proposed Framework’ Architecture. Figure 2 is a data processing flux that employs
    various ANNs implemented in anaconda-python; particularly the basic feedforward
    ANN, and two ANNs combined with the GA for hyperparameters and weights optimization;
    to predict the groundwater-surface level based on the depth to water surface change
    (DWS) retrieved from the sensed groundwater depths measurements, the configured
    installation depth (ID), and the relevant features extracted from the PCA; to
    model future fluctuations in the water surface level regarding the water stress
    and recharge in the monitoring well. The data extraction aims to select the relevant
    features suitable for the learning process based on the Principal Component Analysis
    method. So, the studied approaches are compared in terms of efficiency based on
    the evaluation metrics described in section 2.6 for selecting the best estimation
    model that would be involved in groundwater level change prediction and to study
    the impact of the integrated extended GA used for optimizing both the initial
    hyperparameters and weights of the initial ANN model in terms of precision. Figure
    2 VIEW LARGEDOWNLOAD SLIDE Data processing flux. In this paper, we included a
    decision-making process in Figure 3 for groundwater monitoring and planning, which
    was designed based on the depth measurement method, surface water elevation sensing,
    well station configuration, and the scheduling management model. The irrigation
    and water use plan can be made based on the availability of groundwater depending
    on the estimated water surface elevation by predicting the groundwater level change
    of the aquifer or the land surface relying on historical and forecast weather
    data. This integrated process performs different groundwater level predictions
    based on the monitoring well station and the reference point configuration. The
    optimization of water use and the historical experience allow the user to personalize
    and schedule groundwater use. The principal function of this process includes
    a decision-making aid for managing the groundwater in the different phases of
    exploitation and aligning the groundwater use with climatic changes, taking into
    account hydrological dynamics on the land surface. A case study of groundwater
    management will be carried out to show the benefits of this process and its practical
    improvements. Figure 3 VIEW LARGEDOWNLOAD SLIDE The predictive process. Groundwater
    level and depth measurement method Listen Groundwater is defined as the water
    that has infiltrated into the surface of the ground and formed aquifers. The groundwater
    level is generally observed through appropriate sensing instruments recognized
    as monitoring wells. Monitoring wells are wells including a small-bore under the
    ground, employed for groundwater level monitoring and water quality examination.
    Water-level control is a major way to understand groundwater changes in basins
    caused by recharge (precipitation, irrigation return, seepage from streams, etc.)
    and discharge (groundwater pumping, seepage to streams, etc.), to determine directions
    of groundwater movement and trends in groundwater storage, and to evaluate progress
    toward sustainable water resource management. Moreover, groundwater level monitoring
    concerns continuous or periodic measures depending on the user configuration.
    Continuous measuring is done using automatic water-level sensors that are involved
    in monitoring measurements in wells. Consequently, it provides a high-resolution
    record of water-level fluctuations that can accurately identify the effects of
    various stresses on the aquifer system and provide measurements of maximum and
    minimum water levels in aquifers (Taylor & Alley 2001). In addition, groundwater
    measurements are often taken using a conductivity switch that is grounded into
    a borehole through a flat steel or plastic cable and emits an acoustic signal
    when it touches the surface water. Thus, the depth from the surface to the groundwater
    can be simply measured, but it requires a manual application. Nowadays, automatic
    groundwater level measurements can be taken through KELLER data loggers that collect
    the data autonomously using a level sensor, connected to a microprocessor circuit
    with a battery and a storage device. The user can set the periods of measurements
    to be performed and stored at each time by the logger. This sleep mode saves the
    battery for up to ten years. Data is produced and delivered via a USB converter
    and Logger 5 software from KELLER. The groundwater level (GWL) is measured by
    the data loggers via the membrane in the submersible transmitter. However, the
    largest number of geohydrologists remain engaged in measuring the distance from
    the top of the borehole to the actual water surface level in the borehole (DWS),
    as shown in the graphical abstract. The depth to the water surface level is then
    calculated based on the water column using the formula as follows: (1) where ID
    is the total installation depth that can be set as a passive parameter in the
    data logger, and GWL represents the measured groundwater column. Hence, continuous
    monitoring may not only be the most convenient way to monitor fluctuations in
    groundwater levels during droughts and crucial stages when hydraulic pressures
    may change at very fast rates, but also when real-time measurements are required
    for water decision-making. Moreover, near-continuous data collection can be performed
    by using telecommunication or radio transmitter devices at the monitoring site.
    Artificial neural networks Listen ANNs are the most popular and powerful subfield
    of machine learning, including algorithms inspired by brain processing to help
    in decision-making (Schmidhuber 2015). A single-layer neural network that exports
    a single output has been denoted as the perceptron, according to Gupta (2013).
    Recently, many subjects have proved the efficiency of ANN algorithms for predicting
    the future state of the studied features in various fields. Evolutionary algorithms
    (EAs) Listen Hyperparameter tuning for machine learning processing is a challenging
    issue. Sometimes the obtained output may not be accurate due to the bad initialization
    of the parameters'' values instead of resulting from noisy data or a weak model.
    In fact, the optimization process is required to find the optimal value for each
    hyperparameter, maximizing the performance. Hence, according to Eiben & Smith
    (2003) many operation research (OR) researchers advise several optimization techniques
    such as evolutionary algorithms (EAs) for hyperparameter optimization. The main
    aspects of these optimization techniques are: Multimodal Optimization Multi-objective
    Optimization Constrained Optimization Combinatorial Optimization EAs are distinguished
    from traditional algorithms by their dynamic aspects related to their ability
    to evolve. The main characteristics of evolutionary algorithms can be summarized
    as: Population-Based: EAs intend to optimize any process where the initial solutions
    lead to bad results. This set of initial solutions from which better solutions
    are generated is called the population. Fitness-Oriented: the criteria measure
    that distinguishes each solution from another one is the fitness value, which
    is linked to each solution and calculated from a fitness function. The fitness
    value indicates how reliable the solution is. Variation-Driven: the updating operation
    of the current solutions happens whenever the current solutions do not satisfy
    the fitness function calculated. Hence the individual solutions are to evolve
    and undergo some variations to create new solutions that could meet the fitness
    criteria. Extended genetic algorithm for artificial neural networks optimization
    Listen The GA belongs to evolutionary algorithms and relies on random changes
    to evolve the current solutions to find suitable solutions. The GA approach is
    founded on Darwin''s theory of evolution, including a gradient descent by way
    of applying a slow, gradual process to make slight and slow changes in each generation
    until reaching the best solution. Each individual generated from the population
    is characterized by some properties represented by chromosomes (encoded properties)
    which can be adjusted (Do Crossover) or mutated (Do Mutation) or both, leading
    to a new generation of the population being better in terms of fitness. According
    to Gad (2018), the GA disposes of several operations performed for optimization.
    We have extended the GA for hyperparameters optimization described in Rowe & Colbourn
    (2003) by integrating a self-learning step (training) with a small subset of data
    in Figure 4, to avoid the problem of exponential complexity due to data training
    over many generations, and to improve the irritated weights in the fitness function
    to mimic the ability of a human to evolve its aspects before transmitting them
    to his children in the future generation. From the same perspective, we have integrated
    the self-learning step in Figure 5 into the GA for weight optimization proposed
    by Gad (2018). In the end, the selected solution could be trained with a choice
    between all records or a data subset depending on the dimension, the volume, the
    value of the data, and the power of the processing environment available. The
    main idea behind this proposition is the fact that training the ANN using the
    genetic algorithm with a subset of data optimizes the processing time and can
    overcome the problem of exponential complexity due to data training over many
    generations, which enhances the performance. While a past training of the selected
    solution might improve the efficiency of the model related to the quantity and
    quality of the data available, whether it is noisy or not, and related to the
    processing environment, whether it is powerful or not. Here the GA plays the role
    of initializing optimized hyperparameters and weights instead of random initialization.
    Figure 4 VIEW LARGEDOWNLOAD SLIDE The extended XGA structure for ANN’ hyperparameters
    optimization. Figure 5 VIEW LARGEDOWNLOAD SLIDE The extended XGA Structure for
    ANN weighs optimization. Performance measures Listen To evaluate the performance
    of the chosen predictive models, we adopted the following equations, the root
    mean square error (RMSE), the mean square error, the mean absolute error (MAE),
    and the r-squared accuracy: (2) where n is the number of records, is the actual
    prediction of instance i, and is the suitable output. It represents a type of
    general error measure. The precision is higher when the value of this error is
    lower. Perceive that the RMSE is estimated based on a similar scope as the resulting
    variable. In this matter, easy comparison between the RMSE of the predictive methods
    is sufficient to assess their performance when the output parameter is similar
    for all the predictive models. MAE is a measure that compares the errors between
    predicted and observed values describing the same phenomenon. The MAE is measured
    as: (3) R2 evaluates how much the data is near the adjusted regression course.
    It may describe both determination and multiple determination for both single
    and multiple regression as presented in the formula: (4) The R2 score is a measure
    of percentage varying between 0 and 100: 0 expresses that the interpreted variability
    in the resulting data predicted by the model around its average is null. 100 means
    that the predictive model displays properly all the interpretations of variability
    in predicted data around its average. Description of output and input variables
    Listen Concerning the available training data, the determination of training inputs
    was performed according to knowledge used by the water manager throughout the
    hydrological process and the groundwater availability estimation method, such
    as climatic data, water level, and the soil water state (depth reference point).
    Though additional factors may influence the prediction of groundwater level (such
    as prediction time, potential suspension of irrigation in the area, the internal
    hydrological processes, etc.), these determinants are sometimes not taken into
    consideration by the experts. This represents a limitation of this strategy. Thus,
    picking a suitable collection of factors is crucial for providing efficient predictive
    models. For this reason, the Principal Component Analysis (PCA) method will be
    applied to select the most important parameters. Principal component analysis
    approach Listen PCA is a systematic approach used in multivariate statistics,
    that aims to convert some correlated variables into new irrelative variables.
    These created variables are designated ‘principal components’, the axes they define
    as ‘main axes’, and the correlated linear forms are ‘main factors’. It affords
    an optimization of the set of variables by reducing information redundancy and
    improving relevancy (Guerrien 2003). According to Ringnér (2008) and Jolliffe
    (2002), the main purposes attempted by PCA are: The ‘optimal’ graphic illustration
    of individuals (lines), decreases the deformations of the point cloud, in a subspace
    E of dimension q(q<p). The graphical description of the variables in a subspace
    F by describing well the initial connections between these variables. The dimension
    decrease (compression), or approximation of X by an array of rank q(q<p). Case
    study: ground water level changes prediction Listen Due to the unavailability
    of data, we based our study on continuous groundwater level measurements in a
    dataset including daily and continuous time-series data collected from automatic
    recording instruments installed at many well sites in California and performed
    by the Department of Water Resources (CDWR 2019). The intervals between readings
    vary between 15 minutes and 1 hour. Some of the measures are delivered to the
    California Data Exchange Center. Nevertheless, most of the monitoring sites are
    controlled once every month or two, whenever measures are off-loaded from the
    data recorders and later finalized and published. The monitoring wells included
    in this dataset are located in Glenn, Butte, Glenn, Colusa, Modoc, Mendocino,
    Joaquin, Sacramento, San, Solano, Shasta, Solano, Tehama, Siskiyou, Tehama, Sutter,
    Yuba, and Yolo Counties. This dataset contains (1,048,576) records and includes
    about 12 variables necessary for the groundwater level estimation as shown in
    Table 1 and 2. The majority of the recorded data has a quality code of 1 or 2,
    which means, according to the definitions in Table 3, that the data is good for
    the study. Table 1 Dictionary of the dataset Column Type Label Description STATION  text  Station  Unique
    Station Identifier (database key). For most stations, this is the State Well Number  MSMT_DATE  timestamp  Water
    Level Measurement Date (PST)  Date/Time (in PST) when the groundwater level measurement
    was collected  WLM_RPE  numeric  RPE for a specific water level measurement record  Reference
    Point Elevation used to collect the groundwater level measurement  WLM_RPE_QC  numeric  WLM_RPE
    Quality Code  Quality Code for WLM_RPE measurement  WLM_GSE  numeric  GSE for
    a specific water level measurement record  Ground Surface Elevation at the well
    site  WLM_GSE_QC  numeric  WLM_GSE Quality Code  Quality Code for WLM_GSE measurement  RPE_WSE  numeric  RPE
    to WSE  Depth to the water surface in feet below the reference point  RPE_WSE_QC  numeric  RPE
    to WSE Quality Code  Quality Code for RPE_WSE measurement  GSE_WSE  numeric  GSE
    to WSE  Depth below ground surface or the Distance from the ground surface to
    the water surface in feet  GSE_WSE_QC  numeric  GSE to WSE Quality Code  Quality
    Code for GSE_WSE measurement  WSE  numeric  WS Elevation  Water Surface Elevation
    in feet above Mean Sea Level (NAVD88)  WSE_QC  numeric  WS Elevation Quality Code  Quality
    Code for WSE measurement  Table 3 Quality codes Quality Code Description Label
    Description 1  Good data  201  Data not recorded  10  Good measurement  255  No
    data exists  104bb  Records estimated  40  Fair measurement  120  Poor measurement  50  Unknown
    measurement quality  130  Estimate  60  Above rating – extrapolated above 2x highest
    measurement; unreliable extrapolation  15  Provisional measurement  70  Estimated
    data  150  Rating table extrapolated due to inadequate gauging information  71  Manual
    reading  151  Data missing  76  Reliable interpolation  170  Unreliable data  85  Flooded  2  Good
    quality edited data  –  –  Table 2 Dataset structure STATION MSMT_DATE WLM_RPE
    WLM_RPE_QC … GSE_WSE GSE_WSE_QC WSE WSE_QC 01N04E36Q001M  4/30/2005  9.1  1  …  15.154  1  −8.254  1  01N04E36Q001M  5/1/2005  9.1  1  …  15.148  1  −8.248  1  01N04E36Q001M  5/2/2005  9.1  1  …  15.143  1  −8.243  1  01N04E36Q001M  5/3/2005  9.1  1  …  15.158  1  −8.258  1  01N04E36Q001M  5/4/2005  9.1  1  …  15.154  1  −8.254  1  01N04E36Q001M  5/5/2005  9.1  1  …  15.119  1  −8.219  1  01N04E36Q001M  5/6/2005  9.1  1  …  15.114  1  −8.214  1  01N04E36Q001M  5/7/2005  9.1  1  …  15.122  1  −8.222  1  …  …  …   …  …  …  …  …  …  The
    groundwater level represents the major source of information about variations
    in groundwater storage and change in a basin, and how these are influenced by
    several forms of recharge (precipitation, infiltration from streams, irrigation
    return) and discharge (drainage to streams, groundwater use). In the present case
    study, we focus on predicting the groundwater level of 15 months ahead of the
    monitoring well station ‘12N02E21Q003M’ between 1/1/2021 and 9/29/2021, containing
    almost 271 days of the ANN models (basic and optimized using the extended genetic
    algorithms, XGA). Firstly, we analyzed the main components of the 12 parameters
    in the dataset presented in Table 1 to select the relevant set of parameters (seven
    relevant features in Table 4). Later, we performed predictions by applying supervised
    machine learning to the dataset in Python, using the Anaconda environment; over
    the records collected and estimated daily by experts at the USDA-Agricultural
    Research Service. Finally, we evaluated these models using several performance
    measures. Table 4 Dictionary of the relevant features Column Type Label Description
    STATION  text  Station  Unique station identifier (database key). For most stations,
    this is the state well number.  MSMT_DATE  timestamp  Water level measurement
    date (PST)  Date/time (in PST) the groundwater level measurement was collected  WLM_RPE  numeric  RPE
    for a specific water level measurement record  Reference point elevation used
    to collect the groundwater level measurement  WLM_GSE  numeric  GSE for a specific
    water level measurement record  Ground surface elevation at the well site  RPE_WSE  numeric  RPE
    to WSE  Depth to the water surface in feet below the reference point  GSE_WSE  numeric  GSE
    to WSE  Depth below the ground surface or the distance from the ground surface
    to the water surface in feet  WSE (target feature)  numeric  WS elevation  Water
    surface elevation in feet above mean sea level (NAVD88)  RESULTS AND DISCUSSION
    Listen In the current work, we intend to evaluate the impact of integrating hyperparameter
    and weight optimization on the prediction performance using an extended GA for
    optimizing the trained model''s hyperparameters and weights; and compare it to
    the basic ANN(MLP) model. To this aim, we tried to apply two extended optimizers
    based on the GA, which is one of the simplest random-based EAs, to the ANN (multilayer
    perceptron). The first one is used for the hyperparameter optimization to select
    the best ANN model, and the second one is applied to the resulting model from
    the hyperparameter optimizer for weight optimization. Data preprocessing: principal
    component analysis (variables analysis) Listen In the first step of this study,
    we adopted the PCA as a primary step in the preprocessing of the data to minimize
    the dimension of the set of variables employed in the linear regression and, therefore,
    decrease the trained parameters of the neural networks. Variable normalization
    (data reduction) Listen The data reduction in the PCA method aims to reduce heterogeneous
    variables, and it is required whenever the variables have several units of measurement
    and we want to assign equal importance to all features or whenever the dimension
    of the set of variables is very high. As in our case, we have heterogeneous variables,
    and we have proceeded to reduce them. There are several techniques applied to
    variable normalization, and the most commonly used one is to divide the values
    by the standard deviation implied in computing the Euclidean distance between
    individuals (5). Hence, the variables are reduced or centered. This computation
    allows more equitable role assignment (importance) to the whole variables (Duby
    & Robin 2006): (5) We computed a PCA of three components after the data normalization,
    and then we obtained the projection of the principal components'' inertia percentages
    in Figure 6, which shows that the first and second components explain over 83%
    of the variance and more. Thus, the choice of three principal components was enough
    to explain most of the variability in the data. The projection of the contributions
    of the variables to the principal components illustrates the correlation matrix
    of features and principal components that allows selecting the features that correlate
    strongly with the most informative principal components, explaining most of the
    variability in the data. It appears clearly, according to the analysis of this
    graphic, that the most relevant variables are those projected with great dependence
    on the first and second components and present in Table 4. In this case, the lightest
    and darkest colors represent the most relevant parameters, guaranteeing a better
    distribution of the eigenvalues. Hence, the variables that follow the same direction
    as the groundwater level (WSE) are those that have a positive correlation and
    are represented by the lightest colors in the first component. Consequently, the
    training variables are reduced from 12 to 7 while keeping the date and the station
    parameters required for the time series analysis. Figure 6 VIEW LARGEDOWNLOAD
    SLIDE PCA projection. Implementation Listen In this subdivision, we expose the
    retrieved outcomes after training and testing both methods in the data selected
    from the monitoring well station ‘12N02E21Q003M’. Then we calculated various error
    measures for the efficiency comparison. After picking the most important features,
    we made forecasts by employing various ANNs, basic and combined, with the GAs
    for hyperparameters and weights optimization (basic ANN-MLP, ANN-XGA(HPO), ANN-XGA-HPO(WO)
    with the configuration above, based on the same training features, training period
    (5229 rows), and test period (about nine months from January 2021 to September
    2021:271 days/ rows). Then we predicted the water surface elevation (WSE). For
    the evaluation, we have used the MSE as the loss function, the RMSE, the MAE,
    and the R2-accuracy as metrics. In the predictive basic ANN-MLP that we used in
    Figure 7, we implemented a sequential multi-layer perceptron model with a total
    number of neurons equal to 100. This model includes the rmsprop optimizer, an
    input layer of the relevant features, including a hidden layer with the activation
    function relu and 70 hidden units, a second hidden layer with the activation function
    relu and 29 hidden units, and an output layer (1 unit) with a linear activation
    function. Figure 7 VIEW LARGEDOWNLOAD SLIDE Artificial neural networks’ hyperparameters
    optimization. After training the extended GA mutation for the hyperparameter optimization
    of the ANN model using the R2-accuracy as a fitness function, the set of a random
    selection of hyperparameters present in Table 5 for the population initialization,
    and the configuration present in Table 6, over ten generations and five solutions
    per population, we have obtained the optimal solution (Optimized Artificial Neural
    Network: R2-accuracy up to 99.92%) with the configuration illustrated in Figure
    7: Table 5 Randomized hyperparameter of the population initialization and mutation
    Column Type Description Set of possible values nb_neurons  numeric  Number of
    neurons of hidden layers  [20, 50, 100, 200, 300, 700]  nb_layers  numeric  Number
    of hidden layers  [1, 2, 3, 4]  activation  text  Activation function (hidden)  [‘relu’,
    ‘elu’, ‘tanh’, ‘sigmoid’]  optimizer  text  Compilated optimizer  [‘rmsprop’,
    ‘adam’, ‘sgd’, ‘adagrad’, ‘adadelta’, ‘adamax’, ‘nadam’]  Table 6 Extended genetic
    algorithm (XGA-HPO)’ parameters Column Type Description Value nb_generations  numeric  Number
    of generations  10  nb_sol_per_pop  numeric  Number of solutions per population  5  Mutation_type  text  Mutation
    type  random  Crossover_type  text  Type of crossover  random  Fitness_function  numeric  Fitness
    function  R2-accuracy  Solutions_retain  numeric  Percentage of retaining of solutions
    after each generation  40  mutation_percent  numeric  Mutation percentage of the
    genes  20  After optimizing the hyperparameters for the initial feedforward neural
    network (ANN-XGA-HPO), we have performed an optimization of the weights using
    the second extended GA on the obtained solution using the configuration present
    in Table 7. Table 7 Extended genetic algorithm (XGA-WO)’ parameters Column Type
    Description Value nb_generations  numeric  Number of generations  10  nb_sol_per_pop  numeric  Number
    of solutions per population  5  Mutation_type  text  Mutation type  random  Crossover_type  text  Type
    of crossover  single point  Fitness_function  numeric  Fitness function  1/MSE  mutation_percent  numeric  Mutation
    percentage of the genes  10  Training the GA with ANNs using large data samples
    increases the complexity of the processing, leading to exploding computational
    time even with reduced dimension. Thus, when we try to train the ANN with all
    the station''s records present in the data set, it takes a very long processing
    time with an accuracy that is lower than training with specific station records,
    and it seems that the processing will not finish, especially with an increased
    number of generations. For these reasons, we have chosen to perform the training
    using small data sets and specific well station records. Figure 8 illustrates
    the different results generated by each model. The trends show that the ANN-XGA-HPO
    model (99.8%) with optimized hyperparameters is more precise than the basic ANN-MLP
    model (96.9%). Also, it is clearly shown that the predicted water surface elevation
    (WSE) in the studied well site using the ANN-HPO-WO model with optimized hyperparameters
    and weights is the most accurate and similar to the observed measurements, with
    an accuracy equal to (99.9%). Based on the curves, it seems that the amount of
    groundwater decreases significantly (discharge) with some increases (recharges)
    in the studied monitoring well in the period between May and September of 2021,
    which means that there is a critical need for water use optimization in the present
    and near future. Figure 8 VIEW LARGEDOWNLOAD SLIDE Prediction of the water surface
    elevation (in feet above the mean sea level) in the monitoring well station ‘12N02E21Q003M’
    located in California. In the comparison between predicted and observed values,
    the RMSE of the water surface elevation is lower for the ANN-XGA-HPO-WO model
    with both hyperparameters and weights optimization (0.423) than for the ANN-XGA-HPO
    model with only hyperparameters optimization (0.475), which is even lower than
    for the basic ANN-MLP model (2.343). The RMSE expresses the standard deviation
    of the residuals (errors) accumulated between observed and predicted values. In
    this case, both hyperparameters and weight optimization reduced the RMSE, and
    MAE errors, and increased the R2 accuracy. By analyzing the performance evaluation
    outputs shown in Table 8, it appears that after both the hyperparameters and weights
    optimization using the extended GA, the performance of the ANN model had been
    empowered and outperformed the basic ANN-MLP model. Hence, the optimized model
    is precise, with an accuracy equal to (99.9%), and is reliable for modeling groundwater
    fluctuations. Consequently, ANN models are very suitable for computing complex
    groundwater systems, because of their ability to detect complex and nonlinear
    relationships such as soil water dynamics, especially when we empower them with
    data reduction tools like the PCA and optimization techniques like the GA. Table
    8 Performance metrics output WSE Model RMSE MAE R2 accuracy ANN-MLP  2.343  2.239  0.969  ANN_XGA_HPO  0.475  0.409  0.998  ANN_XGA_HPO_WO  0.423  0.325  0.999  Conclusively,
    monitoring wells and predicting the groundwater level constitute an essential
    step for controlling the water status and use in agriculture and industries. Modern
    methods measure the groundwater level in the nap in various aquifers. Thus, new
    information technologies make it possible to forecast the water status and the
    environment to adjust the groundwater use plan to climate change. Spending on
    this material, given that it is strongly designed and with good interpretation
    of the curves, enables us to purpose and better plan water use in short and over
    a long period of time. CONCLUSION Listen Groundwater resources are exploited mostly
    by farmers to irrigate their plantations. Given the aggressive water demand and
    the drought related to climate change, a huge amount of groundwater is wasted
    because of evapotranspiration, which will drive resources to decrease rapidly.
    Moreover, smart groundwater monitoring and supervision policies represent a primordial
    issue to overcome critical exploitations of underground water obtained from aquifers
    in the agricultural regions. Thus, smart tools for measuring and predicting groundwater
    level and depth can also be helpful for irrigation planning and water use monitoring.
    Moreover, from the obtained results, we can deduce that by integrating optimization
    and reduction techniques like PCA and GA in the data selection, hyperparameter
    initialization, and weight boosting, we can enhance the performance of the ANN
    model. This paper introduces infrastructure for groundwater monitoring support
    through forecasting groundwater level changes, using an optimized ANN. The diversification
    of the data preprocessing using PCA, forecasting, and optimization techniques
    like the GA combined with ANNs would allow extracting a more suitable mechanism
    with high precision, for such precision-sensitive hydrological context towards
    a smart groundwater management system. In perspective, this work could be improved
    by the implementation of a mobile system that can help in remotely monitoring
    the groundwater, throughout the changes in the hydrological cycle and climatic
    changes. Moreover, the proposed predictive approach could be extended using other
    optimization techniques and deployed in large data processing environments like
    Hadoop and Spark. Thus, integrating smartphones, weather remote sensing power,
    Bigdata execution environment, to the suggested framework describes the future
    expanse of automation. Therefore, the self-regulation of groundwater management
    processes involving ground and environmental parameter sensing devices derived
    from the Internet of Things and artificial intelligence would support water use-related
    decisions and facilitate groundwater level extraction and monitoring. CONFLICT
    OF INTEREST Listen The authors declare no competing interests. FUNDING Listen
    This research was funded by the National Center for Scientific and Technical Research
    of Morocco. DATA AVAILABILITY STATEMENT Listen All relevant data are available
    from an online repository or repositories (https://data.cnra.ca.gov/dataset/continuous-groundwater-level-measurements).
    REFERENCES Alrashed A. A. A. A., Gharibdousti M. S., Goodarzi M., de Oliveira
    L. R., Safaei M. R. & Bandarra Filho E. P. 2018a Effects on thermophysical properties
    of carbon based nanofluids: experimental data, modelling using regression, ANFIS
    and ANN. International Journal of Heat and Mass Transfer 125, 920–932. Google
    Scholar  Alrashed A. A. A. A., Karimipour A., Bagherzadeh S. A., Safaei M. R.
    & Afrand M. 2018b Electro- and thermophysical properties of water-based nanofluids
    containing copper ferrite nanoparticles coated with silica: experimental data,
    modeling through enhanced ANN and curve fitting. International Journal of Heat
    and Mass Transfer 127, 406–415. Google Scholar  Bagherzadeh S. A., D''Orazio A.,
    Karimipour A., Goodarzi M. & Bach Q. V. 2019 A novel sensitivity analysis model
    of EANN for F-MWCNTs–Fe3O4/EG nanofluid thermal conductivity: outputs predicted
    analytically instead of numerically to more accuracy and less costs. Physica A:
    Statistical Mechanics and its Applications 521, 159–168. Google Scholar  Bahrami
    M., Akbari M., Bagherzadeh S. A., Karimipour A., Afrand M. & Goodarzi M. 2019
    Develop 24 dissimilar ANNs by suitable architectures & training algorithms via
    sensitivity analysis to better statistical presentation: measure MSEs between
    targets & ANN for Fe–CuO/Eg–Water nanofluid. Physica A: Statistical Mechanics
    and its Applications 519. https://data.cnra.ca.gov/dataset/continuous-groundwater-level-measurements/resource/84e02633-00ca-47e8-97ec-c0093313ddcd.
    Google Scholar  CDWR 2019 Continious Groundwater Level Measurements. California
    Department of Water Resources. https://data.cnra.ca.gov/dataset/periodic-groundwater-level-measurements%0Ahttps://data.ca.gov/dataset/continuous-groundwater-level-measurements.
    Duby C. & Robin S. 2006 Analyse en Composantes Principales. Institut National
    Agronomique, Paris-Grignon, p. 80. Google Scholar  Edwards E. C. & Guilfoos T.
    2021 The economics of groundwater governance institutions across the globe. Applied
    Economic Perspectives and Policy 43 (4), 1571–1594. Google Scholar  Eiben A. E.
    & Smith J. E. 2003 Introduction to Evolutionary Computing Genetic Algorithms.
    Natural Computing Series 45. Springer, Berlin, Heidelberg. Google ScholarCrossref   Gad
    A. F. 2018 Practical Computer Vision Applications Using Deep Learning with CNNs.
    Apress, Berkeley, CA. Google ScholarCrossref   Ghasemi A., Hassani M., Goodarzi
    M., Afrand M. & Manafi S. 2019 Appraising influence of COOH-MWCNTs on thermal
    conductivity of antifreeze using curve fitting and neural network. Physica A:
    Statistical Mechanics and its Applications 514, 36–45. Google Scholar  Giwa S.
    O., Sharifpur M., Goodarzi M., Alsulami H. & Meyer J. P. 2021 Influence of base
    fluid, temperature, and concentration on the thermophysical properties of hybrid
    nanofluids of alumina–ferrofluid: experimental data, modeling through enhanced
    ANN, ANFIS, and curve fitting. Journal of Thermal Analysis and Calorimetry 143
    (6), 4149–4167. Google Scholar  Guerrien M. 2003 L''intérêt de l''analyse en composantes
    principales (ACP) pour la recherche en sciences sociales. Cahiers des Amériques
    Latines 43, 181–192. Google Scholar  Gupta N. 2013 Artificial neural network.
    Network and Complex Systems 3 (1), 24–28. Google Scholar  Guzy A. & Malinowska
    A. A. 2020 State of the art and recent advancements in the modelling of land subsidence
    induced by groundwater withdrawal. Water (Switzerland) 12 (7), 2051. Google Scholar  Jolliffe
    I. T. 2002 Principal Component Analysis, Vol. 19862. Springer-Verlag, New York.
    Google Scholar  Karimipour A., Bagherzadeh S. A., Goodarzi M., Alnaqi A. A., Bahiraei
    M., Safaei M. R. & Shadloo M. S. 2018 Synthesized CuFe2O4/SiO2 nanocomposites
    added to water/EG: evaluation of the thermophysical properties beside sensitivity
    analysis & EANN. International Journal of Heat and Mass Transfer 127, 1169–1179.
    Google Scholar  Karimipour A., Bagherzadeh S. A., Taghipour A., Abdollahi A. &
    Safaei M. R. 2019 A novel nonlinear regression model of SVR as a substitute for
    ANN to predict conductivity of MWCNT-CuO/water hybrid nanofluid based on empirical
    data. Physica A: Statistical Mechanics and its Applications 521, 89–97. Google
    Scholar  Khosravi R., Rabiei S., Khaki M., Safaei M. R. & Goodarzi M. 2021 Entropy
    generation of graphene–platinum hybrid nanofluid flow through a wavy cylindrical
    microchannel solar receiver by using neural networks. Journal of Thermal Analysis
    and Calorimetry 145 (4), 1949–1967. Google Scholar  Lall U., Josset L. & Russo
    T. 2020 Annual review of environment and resources A snapshot of the world''s
    groundwater challenges. Annual Review of Environment and Resources 45, 171–194.
    Google Scholar  Moradikazerouni A., Hajizadeh A., Safaei M. R., Afrand M., Yarmand
    H. & Zulkifli N. W. B. M. 2019 Assessment of thermal conductivity enhancement
    of nano-antifreeze containing single-walled carbon nanotubes: optimal artificial
    neural network and curve-fitting. Physica A: Statistical Mechanics and its Applications
    521, 138–145. Google Scholar  Müller J., Park J., Sahu R., Varadharajan C., Arora
    B., Faybishenko B. & Agarwal D. 2021 Surrogate optimization of deep neural networks
    for groundwater predictions. Journal of Global Optimization 81 (1), 203–231. Google
    Scholar  Panagopoulos A. 2021a Energetic, economic and environmental assessment
    of zero liquid discharge (ZLD) brackish water and seawater desalination systems.
    Energy Conversion and Management 235, 113957. Google Scholar  Panagopoulos A.
    2021b Study and evaluation of the characteristics of saline wastewater (brine)
    produced by desalination and industrial plants. Environmental Science and Pollution
    Research 29 (16), 23736–23749. Google Scholar  Panagopoulos A. 2021c Techno-economic
    assessment of minimal liquid discharge (MLD) treatment systems for saline wastewater
    (brine) management and treatment. Process Safety and Environmental Protection
    146, 113957. Google Scholar  Peng Y., Parsian A., Khodadadi H., Akbari M., Ghani
    K., Goodarzi M. & Bach Q. V. 2020 Develop optimal network topology of artificial
    neural network (AONN) to predict the hybrid nanofluids thermal conductivity according
    to the empirical data of Al2O3 – Cu nanoparticles dispersed in ethylene glycol.
    Physica A: Statistical Mechanics and its Applications 549, 124015. Google Scholar  Ringnér
    M. 2008 What is principal component analysis? Nature Biotechnology 26 (3), 303–304.
    Google ScholarCrossref PubMed  Rowe R. C. & Colbourn E. A. 2003 Neural computing
    in product formulation. The Chemical Educator 8 (3), 1–81. Google Scholar  Safaei
    M. R., Hajizadeh A., Afrand M., Qi C., Yarmand H. & Zulkifli N. W. B. M. 2019
    Evaluating the effect of temperature and concentration on the thermal conductivity
    of ZnO-TiO2/EG hybrid nanofluid using artificial neural network and curve fitting
    on experimental data. Physica A: Statistical Mechanics and its Applications 519,
    209–216. Google Scholar  Sahoo S., Russo T. A., Elliott J. & Foster I. 2017 Machine
    learning algorithms for modeling groundwater level changes in agricultural regions
    of the U.S. Water Resources Research 53 (5), 3878–3895. Google Scholar  Schmidhuber
    J. 2015 Deep learning in neural networks: an overview. Neural Networks 61, 85–117.
    Google Scholar  Taylor C. J. & Alley W. M. 2001 Ground-water-level Monitoring
    and the Importance of Long-Term Water-Level Data, Vol. 1217. US Geological Survey
    Circular, pp. 1–68. Google Scholar  Wen X., Feng Q., Deo R. C., Wu M. & Si J.
    2017 Wavelet analysis-artificial neural network conjunction models for multi-scale
    monthly groundwater level predicting in an arid inland river basin, northwestern
    China. Hydrology Research 48 (6), 1710–1729. Google Scholar  Wunsch A., Liesch
    T. & Broda S. 2021 Groundwater level forecasting with artificial neural networks:
    a comparison of long short-term memory (LSTM), convolutional neural networks (CNNs),
    and non-linear autoregressive networks with exogenous input (NARX). Hydrology
    and Earth System Sciences 25 (3), 1671–1687. Google Scholar  © 2022 The Authors
    This is an Open Access article distributed under the terms of the Creative Commons
    Attribution Licence (CC BY-NC-ND 4.0), which permits copying and redistribution
    for non-commercial purposes with no derivatives, provided the original work is
    properly cited (http://creativecommons.org/licenses/by-nc-nd/4.0/). View Metrics
    Cited by Web Of Science (1) Google Scholar CrossRef (3) We recommend Assessment
    of the impact of socio-economic policies on groundwater consumption using a multi-agent-based
    modeling approach Reza Aghazadeh et al., Water Policy, 2024 Prediction and analysis
    of water resources demand in Taiyuan City based on principal component analysis
    and BP neural network Junhao Wu et al., Journal of Water Supply: Research and
    Technology - Aqua Investigation of quantitative and qualitative changes in groundwater
    of Ardebil plain using ensemble artificial intelligence-based modeling Ayda Sarreshtedar
    et al., Water Science and Technology: Water Supply, 2022 Sustainable management
    of a coupled groundwater–agriculture hydrosystem using multi-criteria simulation
    based optimisation Grundmann, Jens et al., Water Science and Technology, 2013
    114 Road traffic injury prevention: the role of artificial intelligence Maleeha
    Naseem et al., Inj Prev, 2022 553 The role of artificial intelligence in pediatric
    injuries-a scoping review Maleeha Naseem et al., Inj Prev, 2022 National learning
    systems to sustain and scale up delivery of quality healthcare: a conceptual framework
    Samantha R Lattof et al., Global Health, 2022 Ground zero for pandemic prevention:
    reinforcing environmental sector integration Sarah Helen Olson et al., Global
    Health, 2023 Powered by ISSN 1606-9749 EISSN 1607-0798 Cart Journals eBooks Open
    Access Collections Subscriptions Subscribe to Open Editorial Services Rights and
    Permissions Crossmark FAQ Contact us Sign Up for Our Mailing List IWA Publishing
    Republic – Export Building, Units 1.04 & 1.05 1 Clove Crescent London, E14 2BA,
    UK Telephone: +44 208 054 8208 Fax: +44 207 654 5555 IWAPublishing.com IWA-network.org
    IWA-connect.org Cookie Policy Terms & Conditions Privacy Site Map Get Adobe Acrobat
    Reader ©Copyright 2021 IWA Publishing This site uses cookies. By continuing to
    use our website, you are agreeing to our privacy policy. Accept"'
  inline_citation: '>'
  journal: Water Supply
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: 'A hybrid artificial neural network: An optimization-based framework for
    smart groundwater governance'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Christias P.
  - Mocanu M.
  citation_count: '5'
  description: Agricultural systems are constantly stressed due to higher demands
    for products. Con-sequently, water resources consumed on irrigation are increased.
    In combination with the climatic change, those are major obstacles to maintaining
    sustainable development, especially in a semi-arid land. This paper presents an
    end-to-end Machine Learning framework for predicting the potential profit from
    olive farms. The objective is to estimate the optimal economic gain while preserving
    water resources on irrigation by considering various related factors such as climatic
    conditions, crop management practices, soil characteristics, and crop yield. The
    case study focuses on olive tree farms located on the Hellenic Island of Crete.
    Real data from the farms and the weather in the area will be used. The target
    is to build a framework that will preprocess input data, compare the results among
    a group of Machine Learning algorithms and propose the best-predicted value of
    economic profit. Various aspects during this process will be thoroughly examined
    such as the bias-variance tradeoff and the problem of overfitting, data transforms,
    feature engineering and selection, ensemble methods as well as pursuing optimal
    resampling towards better model accuracy. Results indicated that through data
    preprocessing and resampling, Machine Learning algorithms performance is en-hanced.
    Ultimately, prediction accuracy and reliability are greatly improved compared
    to algorithms’ performances without the framework’s operation.
  doi: 10.3390/w13233461
  full_citation: '>'
  full_text: '>

    "This website uses cookies We use cookies to personalise content and ads, to provide
    social media features and to analyse our traffic. We also share information about
    your use of our site with our social media, advertising and analytics partners
    who may combine it with other information that you’ve provided to them or that
    they’ve collected from your use of their services. Consent Selection Necessary
    Preferences Statistics Marketing Show details                 Deny Allow selection
    Allow all     Journals Topics Information Author Services Initiatives About Sign
    In / Sign Up Submit   Search for Articles: Water All Article Types Advanced   Journals
    Water Volume 13 Issue 23 10.3390/w13233461 Submit to this Journal Review for this
    Journal Propose a Special Issue Article Menu Academic Editor Maria Mimikou Subscribe
    SciFeed Recommended Articles Related Info Link More by Authors Links Article Views
    3157 Citations 5 Table of Contents Abstract Introduction Methodology Case Study
    Results Discussion Conclusions Author Contributions Funding Institutional Review
    Board Statement Informed Consent Statement Data Availability Statement Acknowledgments
    Conflicts of Interest Appendix A References Altmetric share Share announcement
    Help format_quote Cite question_answer Discuss in SciProfiles thumb_up Endorse
    textsms Comment first_page settings Order Article Reprints Open AccessFeature
    PaperArticle A Machine Learning Framework for Olive Farms Profit Prediction by
    Panagiotis Christias * and Mariana Mocanu Faculty of Automatic Control and Computers,
    University Politehnica of Bucharest, 060042 Bucharest, Romania * Author to whom
    correspondence should be addressed. Water 2021, 13(23), 3461; https://doi.org/10.3390/w13233461
    Submission received: 26 October 2021 / Revised: 22 November 2021 / Accepted: 2
    December 2021 / Published: 6 December 2021 (This article belongs to the Special
    Issue Smart Water Solutions with Big Data) Download keyboard_arrow_down     Browse
    Figures Versions Notes Abstract Agricultural systems are constantly stressed due
    to higher demands for products. Consequently, water resources consumed on irrigation
    are increased. In combination with the climatic change, those are major obstacles
    to maintaining sustainable development, especially in a semi-arid land. This paper
    presents an end-to-end Machine Learning framework for predicting the potential
    profit from olive farms. The objective is to estimate the optimal economic gain
    while preserving water resources on irrigation by considering various related
    factors such as climatic conditions, crop management practices, soil characteristics,
    and crop yield. The case study focuses on olive tree farms located on the Hellenic
    Island of Crete. Real data from the farms and the weather in the area will be
    used. The target is to build a framework that will preprocess input data, compare
    the results among a group of Machine Learning algorithms and propose the best-predicted
    value of economic profit. Various aspects during this process will be thoroughly
    examined such as the bias-variance tradeoff and the problem of overfitting, data
    transforms, feature engineering and selection, ensemble methods as well as pursuing
    optimal resampling towards better model accuracy. Results indicated that through
    data preprocessing and resampling, Machine Learning algorithms performance is
    enhanced. Ultimately, prediction accuracy and reliability are greatly improved
    compared to algorithms’ performances without the framework’s operation. Keywords:
    Machine Learning; predictive modeling; data preprocessing; resampling; ensemble
    methods; irrigation management; olive tree farms 1. Introduction The agricultural
    sector faces great challenges today because of climatic changes. Global temperature
    is rising combined with inconsistent rainfall patterns and higher demands in yield
    outcome [1]. Agriculture consumes most (70%) of the water withdrawn [2], but the
    resulting productivity varies widely, even in similar climates, locations, and
    crops [3]. This wide variability in crop productivity under otherwise similar
    conditions demonstrates that agricultural management strategies [4,5] can contribute
    significantly to optimal yields. The key is good planning and, where possible,
    tailoring to the specific problem. Intensive agriculture, empirical production
    methods, and urban overpopulation are threatening the availability of global water
    resources. Better water resource management is essential along with optimization
    of cropping practices. In the face of increasing demand [6] and climate change
    [7], pressure [8,9] on agricultural systems is expected to increase and water
    scarcity will become an important constraint to sustainable development, especially
    in semi-arid regions [10,11]. Since their inception [12], irrigation decision
    support systems (IDSS) have aimed to enable “smart” water use, allowing water
    users to decouple water use from yields and thus pursue economic growth with a
    lower environmental footprint [13]. Traditionally, these systems create irrigation
    schedules based on deterministic models such as AquaCrop [14,15,16], IrrigaSys
    [17], or IRRINET [18], which are based on the FAO-56 method [19] to estimate crop
    yield response to temperature and water availability. Although many IDSS have
    been developed in the past [20], there is little evidence of widespread application
    [10]. This is because IDSS advice is of limited value, or perhaps completely irrelevant,
    as the weight in the decision rules is placed on water balances and is therefore
    far removed from the actual criteria relied upon by agronomists or farmers [21].
    The novelty of the present study lies in the exploitation of the interdependence
    among several important factors in the development of olive culture. Soil and
    climatic characteristics are important, and the protection of water resources
    must always be kept in mind, but the financial aspect comes into play and makes
    the difference. A reliable prediction of a farm’s profit is sought to help stakeholders
    make the best decision regarding their needs and priorities. The yield price is
    a fluid amount per year that depends on regional and global production as well
    as consumer demand [22,23,24,25,26]. A good or bad season in terms of weather
    can drive production or do the opposite. This means that even a high yield may
    prove unprofitable if olive oil prices are low that year and a low yield salutary
    if it ensures preparation for next season production. At the same time, costs
    must be considered. Trips to the farm are usually costly to apply management practices
    such as pruning [27]. Irrigation costs are significant as the price of water is
    trending upward and is expected to become more critical soon as demand increases
    and resources diminish and become polluted or insufficient [11]. The financial
    trends and the olive oil market tendency are out of the scope of this article,
    but the participating factors are combined into forming a powerful decision tool.
    Stochastic and more sophisticated decision approaches like fuzzy logic can enhance
    simplistic rule-based systems [28]. Although multiple criteria can participate,
    those methods reach a certain point and cannot further extract valuable interconnections
    among them, due to the probabilistic nature of the methodologies [28] Knowledge
    extraction and reliable prediction for future unseen scenarios are feasible when
    combining different (in scope) but relevant in interdependency variables. Training
    on historical data and prediction performance can be explored via Machine Learning
    methods to take advantage of relations among input historical data [29]. Machine
    Learning (ML) deals with algorithms that can extract valuable information from
    data [30]. It is a sub-field of Artificial Intelligence where those algorithms
    supported by proper information can drive better decisions in practical problems.
    Machine Learning is applied in everyday life problems and tasks such as text and
    image recognition, spam email filtering, and recommendation systems. They are
    very powerful when it comes to predictive analytics where they produce knowledge
    from statistical data to forecast unknown variables such as stock exchange prices,
    election results, and weather phenomena [31]. This paper is based upon previous
    work [28] where an irrigation decision set of strategies was examined. Our case
    study deals with olive farms on the island of Crete facing challenges like low
    water availability combined with high agricultural demand and extreme climatic
    droughts [32]. In the present study, non-similar data features will be combined
    such as climatic data, soil characteristics, and econometric information aiming
    to forecast the profit out of the produced crop yield. The challenge is to achieve
    accurate predictions on the profit while applying management practices and reserving
    irrigation water resources throughout the crop season. It is important to underline
    that for Machine Learning algorithms to perform at their best, thorough data analysis
    and preparation must take place initially [30]. Input variables preprocessing
    and the examination of their correlation and characteristics will be analyzed
    in the following sections. After the data are shaped accordingly, they will be
    supplied as the training set to a group of different Machine Learning algorithms.
    On top of the Machine Learning algorithms, ensemble methods will be applied to
    aggregate and enhance our estimation on prediction accuracy. The ultimate output
    prediction variable will be the profit outcome of the farm. This is calculated
    by subtracting irrigation and managements costs from the selling value of the
    olive yield produced. This research aims into forming a Machine Learning framework
    that will receive datasets related to various features specific to crop farms
    and then be able to analyze those data, perform preparation and analysis on them,
    choose the most useful features after examining their correlation and ultimately
    work on a set of given Machine Learning methods to produce the best prediction
    possible. It will combine cross-validation on the training sets along with sensitivity
    analysis on the parameters of the algorithms to adjust to the nature of the data
    as best as possible. 2. Methodology 2.1. Classification vs. Regression Our case
    study belongs to the category of supervised learning problems. This means that
    we had all values of the input predictors for each given output observation. The
    models we built tried to associate inputs with an output variable [33]. They trained
    with a dataset containing this information and then evaluated on how well they
    fit unknown input data. In supervised Machine Learning, training algorithms are
    classified into two major categories: Classification and Regression. Classification
    deals with categorical data and Regression refer to pure numerical data. This
    separation of nature in data can refer to input and output variables, but most
    of the time it characterizes the problem concerning the output variable [34].
    In a supervised learning problem, the utility of the predictive measure will point
    towards the choice of whether the output variable can be treated as categorical
    or numeric. That is, if the decision-maker can handle or translate easier a qualitative
    result, then classification will be the choice. There are of course cases when
    the specifics of the problem or the data we possess will not permit this kind
    of flexibility and the only way is either classification or regression. Classification
    is not so powerful in capturing fluctuations in numerical data. Therefore, regression
    is preferred for predictions in financial problems, as we will see in our Section
    3 [35,36,37,38,39]. 2.2. Causal Analysis and One-Hot Encoding Variables 2.2.1.
    One-Hot Encoding Some of the predictors we examine in a Machine Learning problem
    will be categorical. The categories can have a hierarchical or sequential meaning
    but having no interaction of that kind can also be the case. A best practice in
    favor of the algorithms’ performance is to alter those categorical values in a
    way that the magnitude or direction is shown in a numerical representation [40].
    When this kind of connection does not apply, the values are nominal and cannot
    be ordered (e.g., male-female, apple–orange–banana) [41]. The variables can then
    be decomposed into multiple binary-value columns [33,42]. Depending on the number
    of categorical values appearing in a predictor, new columns are added to the existing
    dataset. Each column will reflect the presence or absence of an attribute by the
    values 1 or 0. The process of generating those kinds of new dummy variables is
    referred to as one-hot encoding [42]. This technique is often used in smart agriculture
    because the data to be studied include climatic, soil, and crop characteristics.
    [43,44]. While this process can be beneficial and make regression models more
    interpretable [31], we need to be cautious and avoid multicollinearity in regression
    models [39,42]. If the predictors contain extreme outliers or abnormal values,
    then the regression models tend to be negatively influenced [45]. 2.2.2. The Dummy
    Variable Trap The Dummy variable trap is described as the case where some input
    variables are highly correlated and variable values can be implicitly predicted
    by the values of a correlated variable. Applying one-hot encoding to separate
    all possible values of an attribute can lead to a state known as the dummy variable
    trap [46,47]. The reason is that one variable is highly correlated with all other
    dummy variables since its value can be inferred with the help of the rest. Thus,
    as a good practice, models were implemented omitting one dummy variable from the
    map [46]. 2.3. The Problem of Overfitting. Bias and Variance The success of a
    predictive model lies in its ability to properly predict the output variable.
    Its source of knowledge is the datasets with past observations and measurements.
    The objective is that the model will be able to adapt to new unknown data. The
    term ‘properly’ includes both the model’s accuracy and precision. Accuracy and
    precision reflect the bias and variance which are generally two major conflicting
    concepts in any prediction process [34]. When algorithms attempt to predict output
    values, two unwanted situations are possible [33]: The model makes wrong assumptions.
    We are not referring to the obvious, i.e., we diagnose a patient to be ill when
    in fact he is healthy. Let us assume instead the case in which we ultimately predict
    that a loan candidate is not trustworthy just because her name is Jane. Those
    examples may derive from classification problems, but the key concept, which is
    also valid for regression, is that this case reveals the shortcoming of the algorithm
    in observing the relations between the predictors and the dependent variable,
    or maybe more importantly, in exposing a bad choice when choosing the group of
    predictors [47,48]. This is commonly referred to as underfitting [49]. Underfitting
    usually characterizes overly simple models. Simplicity refers not only to non-complex
    models but also to the omission of all the steps of manipulating and preparing
    data as discussed in our proposed framework. Additionally, mishandling data refers
    to non-treatment of outlier values and removal of useless or highly correlated
    features which do not add value to the output variable. The model is very sensitive
    to fluctuations in the observations we use during training. Inconsistency among
    the data may be due to noise or outliers, but it can also mean rare but anticipated
    behavior. The algorithm can become overly complex trying to capture the noise
    and all inconsistencies. The fact that it will succeed during training does not
    indicate that it will be effective when dealing with new unknown data. It will
    be apparent, especially after multiple training executions, that it will fail
    to generalize a successful predictive behavior against new data [50]. It will
    produce a spread on the estimated values compared to the actual observations.
    This is referred to as overfitting. The art in engineering a supervised learning
    model like in our case study is that while bias and variance coexist, we maintain
    focus on locating the ‘sweet’ spot where they both minimize to the best possible
    degree [51]. The bias-variance trade-off points to a major objective, that is
    try to minimize both [41]. The above highlights and underlines the necessity of
    intermediate steps in the modeling process which will help to choose the optimal
    alternative. These steps include splitting the available datasets and careful
    resampling which will be analyzed in the following sections. Many challenges occur
    in the process because when we try to lower bias, variance is increased and vice
    versa. 2.4. Dataset Splitting. Training and Test Sets 2.4.1. Training and Test
    Sets Modern predictive algorithms allow for configuring the process on how they
    will attempt to fit the data and proceed to predictions. This is accomplished
    by tweaking key variables on their mathematical formulations. This is called hyperparameter
    tuning and will be discussed in Section 2.8. To leverage a model’s performance
    and choose the optimal parameters we must experiment on known and unknown data
    and observe how well the algorithm adapts to existing knowledge, but also check
    if it behaves well on new data [52]. In almost every case, we do not have the
    luxury of testing our methods on new unseen data. The moment of truth will come
    when the model must be ready and complete to deal with new data challenges. The
    best way to prepare for that is by splitting the initial dataset into two subsets,
    the training, and the test dataset during building a model. Both sets come from
    our collected observations. The training set is fueling the algorithms process
    on learning the problem and the test set also referred to as holdout set is used
    to examine the performance on allegedly unknown information [47]. 2.4.2. Splitting
    Strategy The process of choosing the samples to participate in the datasets plays
    a major role in the quality of the model. A commonsense approach is to apply a
    random assignment of measurements into the two datasets. It is crucial though
    to maintain uniform sampling and include all observation cases in those two groups.
    Techniques that exploit dissimilarities in the data can lead to a more uniform
    data splitting [52]. Another popular method is stratified sampling. A percentage
    of attributes containing every possible output value is chosen, ensuring a smooth
    proportion of resulting measurements in training and test datasets [52,53]. A
    balanced distribution of observations is important in studies of crop yields.
    In addition, a large proportion of these data (usually three quarters) is retained
    for training purposes when the data set consists of a relatively small number
    of observations [54,55,56]. 2.4.3. Splitting Timing As we will discuss in the
    following section, a useful step in the framework was to perform transforms on
    the data while preparing them for the learning process. Splitting must have occurred
    before any of the data transformations were applied. This was to ensure that the
    performance of the algorithm be measured impartially and evaluated on data that
    were supposed to be unknown [52]. At the same time, no characteristics of the
    test dataset influenced the way we transformed the training dataset. Ultimately,
    the test set was used to assess our model’s performance without bias [57]. 2.5.
    Exploratory Data Analysis A very important stage during the predictive modeling
    process was the examination and preparation of our dataset before feeding it to
    the ML algorithms. It was the process of analyzing the information. The goal was
    to better understand the data or locate patterns, apply filtering or imputation,
    and ultimately make rightful adjustments to accommodate better adoption during
    their usage by the Machine Learning algorithms [46]. Some key stages that fell
    into data exploration and preprocessing were [58,59,60]: Descriptive Analysis.
    During this step, characteristics of the dataset were examined, such as dimensions,
    types of variables, and statistical summaries to get a view of the data. Visualizations.
    Plotting single and multiple variables values led to a better understanding of
    each feature and the relations among them. Cleaning. This involved duplicates
    removal, locating missing values, and techniques to fill in for missing data.
    Transforms. Data could be further processed or massaged without altering the quality
    or the patterns they convey. Altering the scales, examining their distributions,
    and readjusting were methods to better accommodate the algorithms with the structure
    of our information [61]. ○ Standardizing values was extremely useful because it
    provided a convenient way to compare values that were part of different distributions.
    A dataset is standardized when the input features are transformed to have a close
    to zero mean (or standard deviation close to 1). The effect was that the shape
    of the data was shifted to resemble a normal distribution. Standardization assists
    Machine Learning algorithms like k-nearest neighbors, linear regression, and support
    vector machines to build more robust models [46]. Standardization was performed
    by subtracting the mean (μ) from each observation (χ) and dividing the result
    by the standard deviation (σ) of the feature [62]. Z = χ−μ σ (1) ○ Scaling changes
    the values of a feature down to a specific range, usually [0, 1] [62]. Hence,
    the presence of outliers affects the scaling process [47]. It is most useful when
    the input variables exhibit numeric distances among each other. Transforming them
    to a common range can enhance Machine Learning algorithms execution [63]. ○ Power
    Transforms also attempted to remove skew in the data distributions towards a Gaussian
    shape. They used an exponential or logarithmic function to achieve that [63].
    Popular power transformations are Box-Cox (which operates on positive data groups
    only) and Yeo-Johnson [57,63]. ○ Regularization is an approach to treat poor performance
    caused by high collinearity among input variables [46]. The concept applied by
    regularization methods was to penalize increasing complexity during the modeling
    process, thus preventing overfitting. It was apparent that preprocessing like
    scaling and standardization was highly important for the regularization treatment
    because the values of the variables would be at comparable scales and ranges.
    Approaches include L1 regularization, L2 regularization, and dropout. Regularization
    is embedded in algorithms like Lasso, Ridge regression, and Elastic Net. Lasso
    and Elastic Net due to the nature of their penalizing mechanisms can be considered
    as methods that also perform auto feature selection, as described right below.
    ○ Feature Engineering and Selection. Having many feature variables which participate
    in the training process of a model is not always a road to success [57]. It may
    seem logical that the more inputs we possess (no matter the number of observations),
    the best prediction we can achieve. This is a misconception that requires attention
    in Machine Learning projects. Not every feature at our disposal can contribute
    to the predictive value of a model. Just the fact that we had historical information
    on it does not equate to usefulness. On the contrary, it may have a negative impact
    by causing, for example, unnecessary bias. Moreover, the collinearity among features
    was very important [57]. Collinear predictors have a negative impact on the modeling
    process most of the time [52]. Therefore, it was required that we (a) checked
    for predictors which did not contribute to the predictive power, (b) eliminated
    predictors which were highly correlated, and (c) constructed new appropriate ones
    if needed. A high association among variables was indicated by increased dependency.
    Importance existed both on the strength and direction of the association. There
    are methods for calculating dependency between discrete and continuous variables.
    Pearson’s χ2 Statistic, Cramer’s V Statistic, and Contingency Coefficient C [41]
    are very popular for examining discrete variables. Pearson’s coefficient determination
    is based on the mean and the standard deviation [41]. Therefore, the samples needed
    to have a Gaussian-or close distribution [64]. This is where transforms played
    a major role in preparing the data for analysis. Transforms were expected to help
    in the proposed framework because input variables describe different physical
    measures, which are quite dissimilar in ranges and values. 2.6. Resampling 2.6.1.
    Measuring Error The models we built were evaluated based on their prediction performance;
    but how could we properly assess a model’s performance? The prediction error was
    always a good point to observe. We have described in detail the danger of overfitting
    when constructing models. The challenge was to have low prediction error on training
    data, but also retain low error on new data [65]. True Prediction Error = Training
    Error+Testing (Generalization) Error (2) If we increased complexity and attempt
    to eliminate error on the training set, then it was almost certain that we would
    have a significant error rate on new data [48]. A prediction model is successful
    when it prevents overfitting. It is futile to wait and see how the model behaves
    on new information because at that point we need to have a robust model in our
    hands ready to perform well, rather than a model that anticipates unknown data
    to use them and improve afterward. 2.6.2. Resampling for Model Assessment Resampling
    during the training process was essential when trying to achieve good predictions
    because it helped in identifying which algorithms generalized well based on the
    observations we had. In Section 2.8, we will see that additionally, it greatly
    assisted hyperparameter tuning, the process when adjusting special parameters
    of the algorithms aiming for better results estimations. The core of all resampling
    methods is based on using a portion of the data for fitting (training) and reserving
    the rest for testing. Resampling is closely related to bias and variance. The
    more data are reserved for training the more biased the model will be. On the
    other side, holding out more data for testing increases variance [52,66]. Resampling
    is a critical process in all Machine Learning problems, especially those of an
    economic nature. The challenge is to support model selection without extreme time
    consumption and noise [67,68,69]. Using a training and test set is highly important
    while building a well-performing Machine Learning model as discussed in Section
    2.4. Those sets are discrete, they are produced early in the modeling process,
    and they must not be confused with the sets produced during the resampling process.
    Resampling deals with further experimentation performed on the observations of
    the training set to achieve a more accurate estimate of the model’s performance.
    Resampling methods operate like data splitting, but the purpose is to improve
    accuracy in estimating model performance [52]. Data are divided into several subsets
    which are used to fit the model, while the remaining are used to test the performance.
    The performance was evaluated by examining the error rate in predictions. This
    process was repeated multiple times and sequentially, but different divisions
    were performed. Eventually, every portion of the data was used to test each model.
    Data were divided in a way that throughout those iterations, the test sets were
    not overlapping. The results were aggregated and this summary (mean accuracy)
    led to a better overall estimation of the error rate in predictions [65]. 2.6.3.
    K-Fold Cross-Validation (CV) In this resampling technique, data are split into
    a set of k folds of equal amounts of samples. The first k-1 samples are used for
    fitting and the last for testing. The procedure is repeated k times, each time
    selecting and holding out the next fold. In the end, k different error estimates
    are combined to provide an average (mean accuracy), thus, a more objective estimate
    of the algorithm’s efficiency [33]. 2.6.4. Repeated K-Fold Cross-Validation (RCV)
    In k-fold cross-validation, different folds are produced. Each time a fold is
    produced (and the procedure is executed), different average scores will be noted
    due to the distribution of the individual scores. This is an unavoidable phenomenon
    causing noisy estimates [70]. Adjusting the value of k is one solution to remedy
    the noise, but as we will discuss more in Section 3.6, it can strongly expose
    the bias-variance trade-off [71]. Alternatively, k-fold cross-validation can be
    repeated n times and then examine the mean of the total of folds and repetitions.
    Each repeat is executed on the same split of a specific k-fold group [31]. Although
    it is computationally more expensive, it improves the estimate we get and leads
    to a less biased result [52,72]. 2.6.5. Nested Cross-Validation (NCV) This case
    involves two iteration sequences. Both are cross-validations, but the purpose
    is to apply cross-validation on each fold of the inner iteration. This kind of
    cross-validation is very useful when performing hyperparameter tuning on the learning
    algorithms [50]. As we will discuss further in Section 2.8, learning algorithms
    can be optimized by heuristic attempts on special parameters called hyperparameters
    [46]. By tweaking their values, we can adjust modeling and achieve better predictions
    because the algorithm is tailored to our specific dataset [73]. The evaluation
    of performance while tuning is done in conjunction with cross-validation and therefore
    nested cross-validation is preferred for this purpose. 2.6.6. Leave-One-Out Cross-Validation
    (LOOCV) It performs n splits where n is the number of samples. It resembles k-fold
    cross-validation, but the key difference is that it performs n multiple data splits.
    It is the case of k-fold cross-validation where k is the same as the sample size
    n. n is significantly greater than k for large datasets. The model in each iterative
    process uses n-1 samples for training in contrast to (k − 1) × n/k in k fold cross-validation
    [74]. Therefore, it is far more computationally intensive because the number of
    repetitions is higher. All samples’ combinations will participate in the training
    process, meaning that the error estimate is unbiased. Moreover, there is no randomness
    in the results because of the multiple exhaustive times the procedure is executed
    on the dataset [52]. 2.7. Machine Learning Algorithms 2.7.1. Algorithms in General
    Machine Learning algorithms’ purpose is to make predictions via models. They improve
    without explicit programming rules. Instead, they exploit historical information
    as knowledge experience [75]. Focus on the computational statistics field aims
    toward predictions using those methods. Machine Learning goes beyond the traditional
    statistical analysis because it examines all the aspects in the data, even anomalies,
    and outliers. Those are embraced in Machine Learning in contrast to statistical
    analysis, where the effort is put into eliminating them to shape a pure image
    of the data [29]. Taking into consideration all the characteristics in observations,
    a Machine Learning algorithm can become more efficient when dealing with new unseen
    data. 2.7.2. Parametric vs. Non-Parametric Modelling When the learning process
    makes use of a fixed set of parameters without considering the number of observations
    in hand, then it is referred to as a parametric model [29]. The algorithms consist
    of a specific form and the training process learns the best function coefficients
    to fit the data. Usually, they fail to generalize well and are appropriate for
    simple problems. Nevertheless, they are cheap to execute and require small numbers
    of observations. Non-parametric algorithms are not very strict in terms of their
    function mapping. They are more flexible and shape their functional form depending
    on the set of observations [29]. The models derived perform better on unseen data.
    This is when the ML model is said to generalize well [75]. Looking at the downfalls,
    they consume more computational resources, and the more the observations, the
    better they train. Something worth noting is that they are prone to overfitting
    when the model gets more complex [33]. In supervised learning, when predicting
    numeric output variables, we fall into the category of regression problems like
    the case we present. There is no one-fit-for-all solution for each regression
    problem. It is impossible to know what algorithms work well on each case until
    we test them. Some of the most popular regression algorithms are: Parametric or
    linear: Linear Regression Bayes Ridge Regression Ridge Regression LASSO regression
    Nonparametric or nonlinear: K-nearest Neighbors Regression Trees Support Vector
    Machines Regression We will test both simple and complex algorithms. It was interesting
    to explore which algorithms will behave best in a context with different inputs
    such as the olive yield profit we examine. Maybe results will prove that simple
    algorithms perform satisfactorily and are very close to more complex ones. In
    that case, they will be preferred because as a bonus, we get easier model interpretability
    and lower computational requirements [52]. 2.8. Hyperparameter Tuning In Section
    2.6, cross-validation advantages and importance during the modeling process were
    analyzed. In a scenario where we would only stick to data splitting into training
    and test sets (Section 2.4), when adjusting the hyperparameters of the learning
    algorithms, there is a possibility to overfit the test set while pursuing optimal
    prediction [74]. This is referred to as knowledge “leakage” into the evaluation
    metrics and is due to the multiple times the validation is performed by the same
    algorithm [52]. Therefore, the model fails to generalize well. Those special parameters
    place control over the complexity of the model to avoid overfitting [57]. Some
    practices used to produce a third validation set separate from the test set to
    remedy that situation [31]. Unfortunately, the existence of a third set greatly
    diminishes the training sample size. It is even more apparent in cases where the
    initial dataset is not large like our scenario. Cross-validation overcame this
    deficiency and the validation set was not necessary anymore [31]. Cross-validation
    was preferred when performing tuning not only to select the best hyperparameters
    but also for shaping preference over models [50,70]. Nevertheless, there was the
    risk of building an over-optimistic model because during the folds interchange,
    the same sub-dataset can be used both for the model selection and the hyperparameters
    tuning. To overcome this risk, nested cross-validation was a method of evaluating
    training models independently of the hyperparameter optimization [50]. The procedure
    was conducted within two cross-validation processes. Fitting was performed using
    one outer cross-validation and hyperparameter optimization was executed inside
    inner cross-validation [70]. Therefore, overfitting was prevented since the parameter
    exploration was limited to a specific subset of the data. The disadvantage was
    that the computational cost increased highly [76]. Grid search parameter tuning
    and random search parameter tuning are popular ways of experimenting on the values
    [52,57,58]. 2.9. Ensembling Ensemble methods were used to further improve the
    prediction accuracy of our model. The different results were aggregated to enhance
    performance. Prediction performance in a Machine Learning problem can be enhanced
    by combining multiple methods. This process is called ensembling [46]. Usually,
    a subset of the base model methods is exploited and combined with additional features
    from other methods to form an optimal solution. Ensemble methods take a longer
    time to execute than base methods. Frequently, faster base methods participate
    in ensembling like decision trees [77]. The hypothesis related to the ensemble
    is not a product of the base model hypothesizes. As a result, more flexibility
    during training is possible. Nonetheless, this hides the risk of overfitting which
    is undesired [77,78]. Ensemble algorithms tend to work better when there is diversity
    among the models combined, but the preference over efficient base algorithms is
    encouraged [79]. Popular ensemble algorithms include: Extreme Gradient Boosting
    Gradient Boosting Random Forests Extra Trees For a description of ensemble types,
    refer to Appendix A. 2.10. Performance Metrics Being able to accurately measure
    the performance of our algorithms was crucial for the model we delivered. For
    regression problems, certain performance metrics exist: Mean Absolute Error and
    Mean Squared Error. The mean absolute error (MAE) is a computationally simple
    regression error metric. The absolute value of the difference for every predicted
    and observed value is used to calculate the residual (difference between the predicted
    value and observed value) [42,80]. The equation is shown below: MAE = 1 n × ∑
    i =1 n | y i − y I ̂ | (3) The Mean Squared Error (MSE) squares those differences
    instead of calculating the absolute values [42,81]. Both MAE and MSE range from
    0 to positive infinity [81]. The mathematical formula is [46]: MSE = 1 n × ∑ i
    =1 n ( y i − y I ̂ ) 2 (4) In Equations (3) and (4), n refers to the number of
    observations, y to the observed values and  y ̂ to the predicted values. 3. Root
    Mean Squared Error (RMSE). It is the square root of the MSE [42,80]. It represents
    the sample standard deviation of the residuals. Practically, it reveals the degree
    of spread out among the residuals. It is often preferred over MSE because its
    units are the same as those of the output variable [80]. 4. R2 or coefficient
    of determination. R Squared and Adjusted R Squared are indication measures on
    how well the model fits the data [82,83]. It provides great insight when evaluating
    the training process but is also useful during the testing phase. Adjusted R2
    improves R2 in that it can describe better the avoidance of overfitting. R2 value
    tends to increase as the number of input features increases [84]. Adjusted R2
    remains unaffected by this phenomenon, but this poses a challenge when the features
    number is high in a modeling process [85]. R Squared values range from 0 to 1.
    Approaching towards 1 indicates a better fit [46]. The formula for R2 is [46]:
    R 2 = Sum of Squared Errors Total Sum of Squares =1− MSE Var(y) (5) R2 and RMSE
    are popular performance metrics for evaluating model performance in regression
    problems. Their combined evaluation proves useful in applications involving plantings
    and sensor networks [86,87,88]. 3. Case Study 3.1. Area of Study The island of
    Crete in Greece has a typical Mediterranean climate. Summers are usually dry with
    low precipitation. Olive tree farms are the major agricultural activity. Irrigation
    strategies are usually absent, and the number of water resources spent are based
    on the empirical knowledge of the farmers [28]. For our research, real data coming
    from olive farms in Crete were used. Specifically, data were gathered from municipalities
    of Heraklion, Crete, during the period 2000–2007. Soil characteristics were used
    in combination with temperature and precipitation records. Total yield records
    were examined along with irrigation amounts as well as water and olive prices
    to calculate the profit for a season. Modeling was conducted to enrich those historical
    records with information regarding the effect of applying irrigation patterns
    [28]. Based on soil and tree characteristics and the climate conditions, necessary
    humidity to keep the farm in productive development was defined. The water amount
    for irrigation was then distributed among various trips combinations throughout
    the season. Three irrigation events per season were examined as the maximum for
    a farm. Scenarios on reducing the irrigation events and applying management practices
    like pruning, diminish the cost of a crop season. The goal was to achieve the
    best yield possible by applying management practices and irrigation patterns,
    thus increasing profit (because expenses were reduced), while reserving water
    resources at the same time [28]. The dataset used in our framework contained the
    following input features and will be analyzed in more detail in Section 3.2 and
    Section 3.3: Management Practices Soil types Precipitation Relative irrigation
    (percentage concerning optimum irrigation amount estimated by the hydrological
    models [28]) Number of irrigation trips reduction The output variable was the
    profit (yield value–expenses) of the farm. Yield value depends on the oil price
    each year and the expenses depend on the trips to the farm, the amount and price
    of water for irrigation and the management practices applied [28]. The dataset
    contained 486 observations in total. 3.2. Classification, Regression and Binning
    Predictors In the preceding research work, the dependent variable was chosen to
    be the profit out of the yield produced [28]. It was treated as a qualitative
    variable. Possible cases were low, medium, and high profit. The three possible
    groups were designated by separating the observed outputs based on the numerical
    interval between the minimum and the maximum profit recorded. A more objective
    way for classifying each outcome to one of the three groups was to consider the
    ratio of the yield price to the production cost. Then we could assign a class
    referencing the position between the minimum and maximum ratio. The above approach
    was a classification, but we manually categorized a set of numerical values in
    favor of simplification. This could lead to the following pitfalls [52]: It could
    produce a model with lower performance. There would be a loss in prediction precision
    due to the fixed combinations of the possible outcome. The number of false positives
    could increase. It was very important to tailor the modeling choices according
    to the nature of the problem under study. The possibility of an increase in false
    positives was something we wanted to avoid. If a cultivation or irrigation practice
    was forecasted to produce high profit and eventually did not, then it could cause
    a catastrophic impact to the farmer because it may leave him with no resources
    for the next year’s preparation. Thus, a more complex model which performs better
    was preferable. Another thing was the utility of the prediction. A class, i.e.,
    ‘medium’ or ‘high’ profit would not assist a decision-maker that much. On the
    other hand, a numerical estimation of the profit seemed more beneficial especially
    when compared against the effort and the cost put on the farm. For those reasons,
    our case was treated as a regression problem and the dependent variable was the
    numeric profit out of the crop yield. 3.3. One-Hot and Label Encoding When examining
    our input data, the predictors which were qualitative were: Management practice
    with values of PH and PL (heavy pruning & light pruning) The soil type with values
    of Cl, SL, and LS (Clay, Sandy Loam, Loamy Sand) Precipitation with values of
    Dry, Normal, and Wet The soil type data were split into two separate columns,
    one for each possible type. Two columns out of the three soil types were kept
    avoiding the dummy variable trap. The management practice column needed no splitting
    since it contained two values. Precipitation values were divided into three ordinal
    numerical values: (0, 1, 2) representing dry, normal, and wet precipitation. Ultimately
    the experiment dataset consisted of the following columns: management.M1 soil_type.CL
    soil_type.SL precipitation relative_irrigation number_of_trips_reduction relative_profit_percentage
    3.4. Splitting The goal was to use enough data for training and capture the characteristics
    of the features. The percentage of the data which is left aside for testing is
    usually substantially smaller. The risk of losing more than we gain when maintaining
    holdout data increases when our total number of observations is low. Then, the
    chance of occurring bias increases because of the missing information which was
    not used during training [33,52]. When our total observations number is big then
    the training-test split does not have such an impact due to a more equal distribution
    among the characteristics. Caution needed to be addressed when deciding how to
    perform the split. The primary reason for an unsuccessful splitting is separating
    data in a non-homogeneous manner [57]. For instance, if a group of characteristics
    in the data was accumulated in the first observed rows and we formed the training
    set by retaining the first 70%, then the remaining would have no representative
    observations to test the model. Splitting in a completely random manner could
    be dangerous when characteristics were not evenly distributed among the observations.
    In our case, a stratified splitting was performed, thus carefully picking random
    portions of each category in the data [52,57]. This was because combinations of
    features values form our complete dataset; hence, specific sequences contained
    relations among the features’ possible values. For instance, the last portions
    of the record set had no information contained in the first portions of the dataset.
    An ordered split into training and test set would be unsuccessful because we would
    test our models based on information that was completely different from what we
    used to train them. When dealing with numeric predictions, the categorization
    of the information can be done artificially. A common way is to use the quartiles
    of the records. The purpose is to have roughly the same distribution frequency
    in both sets [57]. In Experiment 1 (Section 4), we used a 75–25% proportioning
    split into training and test sets for our ML algorithms testing. Initially, it
    was a random split and afterward a stratified split to check whether we get better
    behavior. R2 (optimal value is 1) and RMSE (optimal value is 0) were used as performance
    metrics to evaluate the results. 3.5. Data Analysis Pearson correlation was used
    to examine strong relations among input variables in Experiment 3 (Section 4).
    The threshold value to indicate high correlation was chosen to be 0.7. After removing
    high correlated features, transforms will be applied to the data and observe how
    algorithms behave. Scaling, Standardization, and Box-Cox power transforms were
    tested and it was checked if we noticed improvements. Standardization was applied
    on one-hot encoded features (management.PH, soil_type.CL, and soil_type_SL) to
    avoid performance degradation [46,89]. 3.6. Resampling 3.6.1. Choosing the Appropriate
    Resampling Method Basic cross-validation using the popular k values (5 and 10)
    is usually adopted to avoid complexity [70,72]. Is repeated cross-validation worth
    the extra complexity and computational burden? Combination tests on simulated
    data for a specific prediction algorithm (random forests) indicated that 10-fold
    CV offers less variance and bias than 5-fold CV; but repeated cross-validation
    outperforms basic cross-validation in all cases [90,91]. Resampling should receive
    special attention given that in our case, we are trying to aggregate knowledge
    from climatic and agricultural data together with financial information such as
    water and olive oil prices. This is done unconventionally, since the forecasts
    do not focus on time series data [92,93,94]. 3.6.2. Cross-Validation Parameters
    When mentioning cross-validation from now on, it will be referred to the training
    set produced after data splitting. The test (holdout) set was kept intact to be
    used on the models’ validation. Most of the examples in the literature favor cross-validation
    over data splitting, due to the fact of the different iterations and the participation
    of the same group samples in both training and testing [70,79,90,91]. In our approach,
    the holdout set produced with the methodology discussed in Section 3.4 was kept
    intact and used in the end for an as-realistic-as-possible test on unknown data.
    Resampling was applied to the training set produced after data splitting. The
    major question was what value of k is optimal. For high values of k, bias decreases
    because the size of the resampling fold sets gets closer to the training set size
    [52]. On the other hand, k-fold cross-validation can reveal high variance. For
    our purposes, we used repeated k-fold cross-validation. By repeating cross-validation
    [95,96], variance can decrease while maintaining bias at low levels. 3.6.3. Sensitivity
    Analysis on K Resampling methods can provide a clear image of how well the model
    can fit the data. On the other hand, sensitivity analysis examines the degree
    of change in the results when new information appears. Research may have shown
    that values of 5 or 10 are generally good for fold generation in cross-validation
    [33,52]. Those values balance the bias-variance trade-off while not requiring
    computationally intensive operations [72,91]. Further investigation should be
    conducted, though, to verify that a chosen value truly worked well for our specific
    problem and dataset [50]. We performed repeated tests on the same dataset to assess
    what the best values of k and n (number of repeats) were, for k-fold cross-validation
    and repeated cross-validation respectively. The training dataset generated in
    the first step was used initially with the same ML algorithm (linear regression),
    chosen at random as a reference point. We needed, though, a baseline to compare
    the results and realize which the best values were. This is also referred to as
    baseline performance [63]. We did not have access to data that was not yet to
    be seen and perform the tests, so the baseline derived from LOOCV which can provide
    the best possible estimates on the available data of the training set. It is computationally
    expensive especially as the dataset grows, but it was useful in the experiments
    to provide the baseline and compare the results from k cross-validations. The
    resulting mean accuracies from cross-validations which were close to the baseline
    pointed to the optimal value of k regarding our dataset. Fold values from 2 to
    40 competed for k cross-validation. A combination of fold values from 10 to 15
    and repeats from 10 to 20 were used for repeated k cross-validation. Therefore,
    the goal was not to choose the values which produced the absolute minimum mean
    accuracy, but those which exhibited the closest mean accuracy to the corresponding
    value of the baseline method. We used the root mean squared error as the measure
    of accuracy. The test harness approach took into consideration two more metrics:
    The median value of the cross-validation results. If the mean accuracy and the
    median are close values, it is a significant indication that the specific execution
    reflects the central tendency very well and without skewness [97]. The standard
    error. It is the measure that exhibits the deviation of the sample mean from the
    population mean. It was useful because it reflected the accuracy of the mean value
    in representing the data [80,98]. We observed the min and max values in the experiments’
    executions and if the preferred scenario had also a low standard error, it was
    chosen as the recommended one. After choosing the best values, a verification
    attempt followed to note how well the designated resampling behaved on other algorithms.
    Specifically, cross-validation was performed using other algorithms and again
    the results were compared with the baseline (LOOCV). Pearson correlation coefficient
    helped at that point to see if there was a strong correlation between each algorithm’s
    performance and the baseline performance. 3.7. Machine Learning Algorithms There
    is no one-fit-for-all solution for each regression problem. It is impossible to
    know which algorithms work well on our problem until we test them. Recent studies
    on Machine Learning for econometric prediction systems benefited from popular
    algorithms which we also exploited [99,100,101,102,103,104]. The algorithms which
    were used for this case study experiments were: Linear Regression Bayes Ridge
    Regression Ridge Regression LASSO Regression K-Nearest Neighbors CART Decision
    Trees Support Vector Machines Regression (SVMR) Ensembling experimentation will
    exploit: Extreme Gradient Boosting Gradient Boosting Random Forests Extra Trees
    3.8. Hyperparameter Tuning Exploration of the optimal hyperparameter values was
    executed within nested cross-validation to evaluate the tuning optimization. We
    used an exhaustive grid search for this process. It consisted of an inner 10-fold
    cross-validation and an outer cross-validation that was configured according to
    the optimal results indicated previously by the sensitivity analysis. 3.9. Performance
    Metrics Comparison and Choice The MAE is easy to interpret because it examines
    the absolute difference between the observations and the predictions. MSE and
    RMSE penalize bigger prediction errors. While we did not have outlier data in
    our case study, we chose RMSE to examine model accuracy due to the financial nature
    of our prediction goal. It is difficult to rely solely on RMSE (or MSE) as a metric
    for model evaluation because its values are shaped and depend on the specific
    regression task. That is why we also relied on R2 which reflected the generalization
    quality of the model by displaying the variance in the results [105]. It is worth
    pointing out that solely relying on R2 may not be a good practice because a high
    R2 value does not necessarily point to well-fit data [106]. Anscombe’s residual
    is an excellent reminder of this [107]. For that reason, we observed both RMSE
    and R2 when assessing model performance. 4. Results The computational process
    will be built on successive experiments. Each one will apply some of the practices
    (discussed in the previous sections), forming a chain towards enhancing the prediction
    results at the next experiment. The results of each experiment will determine
    which practices were applied to the interest of the modeling and mostly provide
    a fixed configuration for the experimentation of the next step. At all times,
    the purpose is to have an improvement in prediction as we progress and finally
    produce a framework that is tailored to our case study, proven to perform as well
    as possible. The list of experiments and their execution processes is: Fit the
    models based on the group of ML algorithms we chose. No data transform or algorithm
    tuning is performed without any further tweaking. The performance results after
    evaluating the algorithms on the test set are given in Table 1: Table 1. ML algorithms
    default training and testing. R2 train score refers to the coefficient of determination
    during training. The last two columns display metrics for the validation phase
    on the holdout set. The best test performance is given by SVMR algorithm. 2. The
    same process is repeated by performing stratified continuous splitting and the
    results are shown in Table 2. Table 2. ML algorithms training and testing after
    stratified splitting. Results are slightly improved across all algorithms. The
    best performance is given again by the SVMR algorithm. 3. Exploration of the nature
    of data will reveal feature correlations and distributions. Those will point to
    feature extractions and data transforms. Table 3 displays the Pearson correlation
    values between feature pairs. Table 3. Correlation of features. Only the upper
    right triangle of the table is displayed as it is symmetrical with the lower left
    triangle. The soil_type.CL column is highly correlated with management.M1. Therefore,
    the first one will be dropped from the feature set to see if it helps with model
    fitting. The models are refitted after the correlation processing and the results
    are shown in Table 4. Table 4. ML algorithms training and testing after correlated
    features exclusion. Results do not show improvement by leaving out the correlated
    column. The next steps will use the dataset as it was before the correlation filtering.
    4. Scaling, standardization, and a power transform (Box-Cox) are also applied
    to the dataset features to help the algorithms’ execution. The results are presented
    in Table 5. Table 5. ML algorithms training and testing with transforms application.
    SVMR is the best performing algorithm again. Among the transformations, standardization
    gives the best results, so this is the transform of choice for the next steps.
    5. In this and the following step, cross-validation experiments will be performed.
    Standardization is applied to the data before assessing cross-validation performance.
    Initially, cross-validation is executed on the training dataset with a default
    value of 10 as the number of folds. The results are sets of root mean squared
    errors. The boxplots in Figure 1 display cross-validation performance assessment
    for the algorithms under testing. Figure 1. ML algorithms performance estimations
    after cross-validation. Lasso gives the poorest observation. While cross-validation
    and regularization (adopted by LASSO) are techniques against overfitting, a parameter
    optimization on the regularization parameters might be necessary for LASSO to
    perform better [108,109]. But since the other algorithms exhibit better estimations,
    we will not dive into this. CART decision tree and Support Vector Regression Machines
    have the highest scores. This means that the resampling configuration provides
    confidence regarding those algorithms’ performance on unseen data. 6. Sensitivity
    analysis on values for k cross-validation is executed. Tests were performed on
    values of k in the integer range [2, 40]. As described in Section 3.6.3, the red
    lines display the optimal (baseline) results given by the LOOCV. In each execution,
    we observe (a) the blue lines which display the cross-validation root mean squared
    error (mean accuracy) and must be close to the red line, as well as (b) the yellow
    lines which show the median. Blue segments below the red line (ideal case) are
    considered pessimistic estimates and above the line optimistic estimates. The
    second case means overfitting [110]. The characteristics which point to the optimal
    k are (a) a small distance from the LOOCV mean and (b) a low standard error. From
    the execution table values and the line plot which are concentrated in Figure
    2, the optimal value for k is 38 with a mean accuracy score of 0.06605177. The
    difference from the LOOCV median is 0.01193512. The standard error ranges from
    0.00203894 to 0.00398050 throughout the experiments. For k = 38 the standard error
    mean is 0.00264908, a value near the minimum of the executions set. Figure 2.
    ML algorithms sensitivity analysis on cross-validation. The repeated kcross-validation
    experiment follows using fold values from 10 to 15 and repeats from 10 to 20.
    Results are displayed in Figure 3. The optimal values are 15 and 15 for k and
    repeats (n), respectively, with a mean accuracy score of 0.06692458. The difference
    from the LOOCV median is 0.01193512. The standard error ranges from 0.00048893
    to 0.00072511 throughout the experiments. For our candidate combination, the standard
    error is 0.00059127, very close to the minimum observation. Mean accuracy best
    scores are very close in cross-validation and repeated cross-validation, but standard
    error is significantly better in repeated cross-validation. These observations
    lead to a strong preference over the repeated cross-validation and will be used
    in the following phases. Figure 3. ML algorithms sensitivity analysis on repeated
    cross-validation. Lastly, Pearson correlation for all the regression methods will
    be examined to check whether the selected resampling method is expected to assess
    satisfactory all the models’ performances (Figure 4). The correlation is extremely
    high and positive indicating that our resampling strategy leads to reliable assessments
    for the Machine Learning algorithms. Figure 4. Correlation between LOOCV and RCV
    for all algorithms. The scores assessment distributions for the algorithms after
    RCV are shown in the boxplots of Figure 5. Figure 5. ML algorithms accuracy scores
    after optimized RCV. All algorithms except Lasso show improved performance reliability
    both in mean scores and standard error distributions. The performance estimation
    scores for all the algorithms after sensitivity analysis are shown in Table 6.
    Table 6. ML algorithms performance scores after optimized RCV. Sensitivity Analysis
    and the choice of repeated cross-validation made quite a difference for all algorithms
    except Lasso. SVMR and CART are the models which are likely to behave better on
    new unseen data according to the results. The fact that the values for CART and
    SVMR are a little worse after sensitivity analysis should not be misleading. Sensitivity
    analysis helped to shape a less biased estimation for these models on the specific
    dataset. 7. Support Vector Machines Regressor (SVMR) is the predominant algorithm
    as shown from earlier steps. Repeated cross-validation will help to improve its
    performance by tuning its hyperparameters. Exhaustive grid search will be used
    to achieve that, exploiting the optimal values of repeated cross-validation. The
    values exploration will be executed inside nested cross-validation of 10 folds.
    Standardization is applied on both the validation and the test sets. SVMR has
    three major hyperparameters for tweaking [111,112]. (A) Kernel. The kernel types
    that we will test are linear, poly, rbf, sigmoid. (B) The tolerance for the stopping
    criterion. The set that will be tested is: [0.000001, 0.00001, 0.0001, 0.001,
    0.01]. (C) The C regularization parameter. It represents how strict the algorithm
    will be when there are errors on fitting. The range to test is: [1, 1.5, 2, 2.5,
    3]. The optimal hyperparameter values were Kernel = rbf, tolerance = 0.000001
    and C = 1. The mean accuracy for these parameters is 0.057655 with a standard
    error: 0.006980. Table 7 displays the comparison of prediction scores of the SVMR
    algorithm on the training and the holdout dataset, before and after hyperparameter
    tuning. Table 7. SVMR performance before and after tuning. Hyperparameter tuning
    gave a very slight boost to the prediction score. It seems that hyperparameter
    optimization has a minimal contribution without forgetting its computational cost.
    The prediction score on the test dataset is just an indication of the algorithm’s
    performance. The major gain from this experiment step is that hyperparameter optimization
    provides stronger confidence for good performance on new unseen data. 8. In this
    step, we will experiment with ensemble methods. Extreme Gradient Boosting, Gradient
    Boosting, Random Forests, and Extra Trees are evaluated on the standardized dataset
    with repeated cross-validation (folds = 15, repeats = 15). The results are presented
    in Table 8. Table 8. Ensemble methods mean accuracy scores with RCV. Gradient
    Boosting gave the best accuracy, meaning it is expected to perform better on unseen
    data (compared to the rest). 9. Finally, hyperparameter tuning will be executed
    on Gradient Boosting to investigate if its performance can be further enhanced.
    N estimators are the hyperparameter to adjust and the default value used is 100
    [113]. Usually, if this number is increased, so is performance (at a computational
    cost) [113]. We will test the range: [50, 200]. This experiment using nested cross-validation
    showed that 50 was the best value with a mean accuracy of 0.051271 and a standard
    error of 0.006015, improving the scores with the default values. 10. Table 9 displays
    results for all the ensemble algorithms along with the tuned Gradient Boosting
    on the training and the holdout datasets. Table 10 shows the initial best performance
    from experiment 1 next to the best performance of the last experiment. Table 9.
    Ensemble methods and Tuned GB. Training and Testing scores. Table 10. Observations
    of improvement for experiments sequence. 5. Discussion Data preprocessing as shown
    in the initial experiment steps is quite useful. Stratified splitting and standardization
    improved the algorithms’ performance. It proved useful to split the data stratified,
    that is, to carefully select random parts of each category. This was necessary
    because our dataset consisted of combinations of features and therefore, certain
    sequences contained relationships between the possible values. A peculiarity of
    our dataset is that its last parts did not contain information that was included
    in the first parts, which required additional attention. On the contrary, the
    attempt for feature selection by correlation examination did not contribute towards
    improvement. Although calculations indicated that soil type and management practice
    should not co-participate in the model, it was proven false after training experiments.
    Outside the context of Machine Learning, an expert’s intuition would likely assert
    no relevance or dependence between these different variables, and this was confirmed
    by the framework. Sensitivity analysis on cross-validation brought out the usefulness
    of this procedure both for model selection and hyperparameter tuning. Both cross-validation
    and repeated cross-validation showed optimal performance with repetitions’ values
    different from those commonly used as quick defaults in other problems, thus highlighting
    the tailored approach of our framework. The results of the repeated cross-validation
    showed higher credibility, which is why it was selected for further steps. In
    general, Support Vector Machines Regression performed very well in each step,
    showing that it is a well-suited algorithm for this type of problem. Ultimately,
    ensembling gave the best results. One of the most interesting points during our
    experiments was the results shown in Table 9. Gradient Boosting had the lowest
    variation in the coefficients of determination studied between the training and
    test sets. Resampling had previously yielded the highest estimated accuracy, confirming
    the observation in Table 9. The other methods (which had lower mean estimated
    accuracy when resampling) showed large differences in the results between the
    two sets. This means that we cannot rely on them to perform as well on the new
    data as they did on the training data. The experiments sequence paid off. The
    prediction method of choice for our case study is Gradient Boosting with the n_estimators
    hyperparameter set to 50. We observed a 29.27% improvement in R2 and a 42.88%
    improvement in RMSE when testing our proposed model on the holdout dataset. This
    research work experimented with the cost of production, which depends heavily
    on the price of water. Under the current and foreseeable conditions of water stress,
    an increase in the price of water in agriculture is very realistic and will certainly
    affect profits, making the decision-making process in agriculture even more useful.
    In addition, the price of olive oil in the Mediterranean is adjusted every year
    and depends on production volumes, among other factors. A decision-making system
    supported by machine learning can reveal wise decisions under the circumstances
    that can help farmers survive a crisis. The importance of making the right decision
    will then be even greater because the sustainability of the agricultural economy
    and the preservation of water while protecting the environment are at stake [28].
    Recent studies have looked at machine learning to accommodate prediction mechanisms
    in smart agriculture and irrigation. They used climate and soil properties to
    predict crop production or weather-related events such as rainfall [43,44,101,114,115,116].
    Studies have also focused on financial objectives using only econometric historical
    observations [99,117,118,119]. Our work pioneers this approach by combining weather,
    biophysical, and economic data into an aggregate forecasting framework which is
    an under-researched area [99]. Its performance has been optimized by careful data
    preparation during the operation steps to get the best out of this contractual
    information. Another point worth noting is that we do not use historical financial
    time series, as is traditionally the case [117,120,121]. Instead, we associate
    each season’s water and olive oil prices with the tactics to follow depending
    on weather and operating conditions. Even though Deep Learning and neural networks
    are more powerful tools and are used in similar studies [43,44,55], they still
    lend themselves to more adaptive and real-time systems [122,123,124]. We chose
    to complement simpler methods of ML and improve them with a robust framework for
    preprocessing, resampling, and ensembling. 6. Conclusions In this paper, a Machine
    Learning framework for predicting financial profit for olive tree farms was presented.
    A group of algorithms was examined to test which performed best. The focus was
    placed on data preprocessing and resampling. The research successfully assisted
    the algorithms’ performance, provided correct assumptions on what model will perform
    well on new data, and tuned the algorithms in a way that suited best the case
    study dataset. Results showed significant improvement due to the steps proposed
    in the text. Future work involves investigating if the framework can adapt to
    different input by exploiting the combination of approaches in its toolset. Variations
    in input involve different crop types in the same geographical region (for example,
    citrus fruit trees in Greece or other Mediterranean areas), or olive crops in
    different geographical locations and climates. Moreover, factors like pesticide
    and fertilizer misuse–overuse can be considered because they also have a major
    impact on crop production quality and the pollution of groundwater. Hopefully,
    the framework will aid in the sustainability of agricultural production while
    contributing to the optimal conservation of water resources. Author Contributions
    Conceptualization, M.M.; Formal analysis, P.C.; Funding acquisition, M.M.; Methodology,
    P.C.; Software, P.C.; Supervision, M.M.; Validation, M.M.; Visualization, P.C.;
    Writing—original draft, P.C.; Writing—review & editing, M.M. All authors have
    read and agreed to the published version of the manuscript. Funding This research
    received no external funding. Institutional Review Board Statement Not applicable.
    Informed Consent Statement Not applicable. Data Availability Statement The dataset
    used in the experiments which are analyzed in the paper resides on GitHub: https://github.com/xristias/MDPI-Water-Smart-Water-Solutions-with-Big-Data/blob/main/dataset.xlsx
    (accessed on 4 December 2021). The python code developed to execute the experiments
    resides on GitHub: https://github.com/xristias/MDPI-Water-Smart-Water-Solutions-with-Big-Data/tree/main/experiments_code
    (accessed on 4 December 2021). Acknowledgments Special thanks to Ioannis Daliakopoulos
    at the Hellenic Mediterranean University for providing the dataset for experimentation.
    Conflicts of Interest The authors declare no conflict of interest. Appendix A
    The main ensemble types are [77,125]: Bagging: The term comes from Bootstrap Aggregating
    because those techniques are combined. It works by sampling random bootstrapped
    sub samples from the initial dataset. Afterwards, the algorithm picks the most
    robust sub model to form the predictor. Random Forests: There is a resemblance
    to Bootstrap Aggregation. Bagging is somehow predictable in behavior because although
    splitting is done, the algorithm has all the predictors at hand. In a random forest,
    multiple trees are produced but they are based on different predictors. This is
    a factor which contributes to crisper independence among the base models and leads
    to powerful aggregation and accurate predictions. The bottom line is that the
    base models must be as efficient and as diverse as possible. Boosting: The principle
    in boosting algorithms is to convert multiple weak training models into stronger
    ones. Weight values are attributed to the learners depending on their comparative
    performance. Higher values are attributed to false predicted cases. In the end,
    the weighted sum is used for the final prediction. Boosting differs from bagging
    in that it trains the learners sequentially, referencing the weighted line of
    data. Stacking: In stacking, weak base models are exploited but processed in parallel.
    A weakness of this approach is that each base model equally contributes to the
    ensemble regardless of how well it performs. They are often heterogeneous methods,
    meaning that the group of base learners consist of different algorithms. References
    Lehmann, J.; Coumou, D.; Frieler, K. Increased record-breaking precipitation events
    under global warming. Clim. Chang. 2015, 132, 501–515. [Google Scholar] [CrossRef]
    Aquastat FAO’s Information System on Water and Agriculture. Available online:
    https://www.fao.org/e-agriculture/news/aquastat-faos-global-information-system-water-and-agriculture
    (accessed on 4 December 2021). Brauman, K.A.; Siebert, S.; Foley, J.A. Improvements
    in crop water productivity increase water sustainability and food security—A global
    analysis. Environ. Res. Lett. 2013, 8, 24030. [Google Scholar] [CrossRef] Cuevas,
    J.; Daliakopoulos, I.N.; Del Moral, F.; Hueso, J.J.; Tsanis, I.K. A Review of
    Soil-Improving Cropping Systems for Soil Salinization. Agronomy 2019, 9, 295.
    [Google Scholar] [CrossRef] [Green Version] Ali, M.; Talukder, M. Increasing water
    productivity in crop production—A synthesis. Agric. Water Manag. 2008, 95, 1201–1213.
    [Google Scholar] [CrossRef] Fischer, G. Transforming the global food system. Nat.
    Cell Biol. 2018, 562, 501–502. [Google Scholar] [CrossRef] [PubMed] Betts, R.A.;
    Alfieri, L.; Bradshaw, C.; Caesar, J.; Feyen, L.; Friedlingstein, P.; Gohar, L.;
    Koutroulis, A.; Lewis, K.; Morfopoulos, C.; et al. Changes in climate extremes,
    fresh water availability and vulnerability to food insecurity projected at 1.5
    °C and 2 °C global warming with a higher-resolution global climate model. Philos.
    Trans. R. Soc. A Math. Phys. Eng. Sci. 2018, 376, 20160452. [Google Scholar] [CrossRef]
    [PubMed] WWAP. World Water Development Report Volume 4: Managing Water under Uncertainty
    and Risk; WWAP: Paris, France, 2012; Volume 1, ISBN 9789231042355. [Google Scholar]
    Koutroulis, A.; Grillakis, M.; Daliakopoulos, I.; Tsanis, I.; Jacob, D. Cross
    sectoral impacts on water availability at +2 °C and +3 °C for east Mediterranean
    island states: The case of Crete. J. Hydrol. 2016, 532, 16–28. [Google Scholar]
    [CrossRef] [Green Version] Giannakis, E.; Bruggeman, A.; Djuma, H.; Kozyra, J.;
    Hammer, J. Water pricing and irrigation across Europe: Opportunities and constraints
    for adopting irrigation scheduling decision support systems. Water Supply 2015,
    16, 245–252. [Google Scholar] [CrossRef] [Green Version] Christias, P.; Mocanu,
    M. Information Technology for Ethical Use of Water. In International Conference
    on Business Information Systems; Springer: Cham, Switzerland, 2019; pp. 597–607.
    [Google Scholar] [CrossRef] Labadie, J.W.; Sullivan, C.H. Computerized Decision
    Support Systems for Water Managers. J. Water Resour. Plan. Manag. 1986, 112, 299–307.
    [Google Scholar] [CrossRef] Gurría, A. Sustainably managing water: Challenges
    and responses. Water Int. 2009, 34, 396–401. [Google Scholar] [CrossRef] Paredes,
    P.; Wei, Z.; Liu, Y.; Xu, D.; Xin, Y.; Zhang, B.; Pereira, L. Performance assessment
    of the FAO AquaCrop model for soil water, soil evaporation, biomass and yield
    of soybeans in North China Plain. Agric. Water Manag. 2015, 152, 57–71. [Google
    Scholar] [CrossRef] [Green Version] Foster, T.; Brozović, N.; Butler, A.P.; Neale,
    C.M.U.; Raes, D.; Steduto, P.; Fereres, E.; Hsiao, T.C. AquaCrop-OS: An open source
    version of FAO’s crop water productivity model. Agric. Water Manag. 2017, 181,
    18–22. [Google Scholar] [CrossRef] Steduto, P.; Hsiao, T.C.; Raes, D.; Fereres,
    E. AquaCrop—The FAO Crop Model to Simulate Yield Response to Water: I. Concepts
    and Underlying Principles. Agron. J. 2009, 101, 426–437. [Google Scholar] [CrossRef]
    [Green Version] Simionesei, L.; Ramos, T.B.; Palma, J.; Oliveira, A.R.; Neves,
    R. IrrigaSys: A web-based irrigation decision support system based on open source
    data and technology. Comput. Electron. Agric. 2020, 178, 105822. [Google Scholar]
    [CrossRef] Mannini, P.; Genovesi, R.; Letterio, T. IRRINET: Large Scale DSS Application
    for On-farm Irrigation Scheduling. Procedia Environ. Sci. 2013, 19, 823–829. [Google
    Scholar] [CrossRef] [Green Version] Allen, R.G.; Pereira, L.S.; Raes, D.; Smith,
    M. Others Crop Evapotranspiration-Guidelines for Computing Crop Water Requirements-FAO
    Irrigation and Drainage Paper 56; FAO: Rome, Italy, 1998; Volume 300, p. 6541.
    [Google Scholar] Rinaldi, M.; He, Z. Decision Support Systems to Manage Irrigation
    in Agriculture. In Advances in Agronomy; Elsevier BV: Amsterdam, The Netherlands,
    2014; Volume 123, pp. 229–279. [Google Scholar] Car, N.J. USING decision models
    to enable better irrigation Decision Support Systems. Comput. Electron. Agric.
    2018, 152, 290–301. [Google Scholar] [CrossRef] Karipidis, P.; Tsakiridou, E.;
    Tabakis, N. The {Greek} olive oil market structure. Agric. Econ. Rev. 2005, 6,
    64–72. [Google Scholar] Mili, S. Market Dynamics and Policy Reforms in the EU
    Olive Oil Industry: An Exploratory Assessment. In Proceedings of the 98th Seminar,
    No. 10099, Chania, Greece, 29 June–2 July 2006. [Google Scholar] Fousekis, P.;
    Klonaris, S. Spatial Price Relationships in the Olive Oil Market of the Mediterranean.
    Agric. Econ. Rev. 2002, 3, 23–35. [Google Scholar] Tempesta, T.; Vecchiato, D.
    Analysis of the Factors that Influence Olive Oil Demand in the Veneto Region (Italy).
    Agriculture 2019, 9, 154. [Google Scholar] [CrossRef] [Green Version] García-González,
    D.L.; Aparicio, R. Research in Olive Oil: Challenges for the Near Future. J. Agric.
    Food Chem. 2010, 58, 12569–12577. [Google Scholar] [CrossRef] Skaggs, R.K.; Samani,
    Z. Farm size, irrigation practices, and on-farm irrigation efficiency. Irrig.
    Drain. 2005, 54, 43–57. [Google Scholar] [CrossRef] Christias, P.; Daliakopoulos,
    I.N.; Manios, T.; Mocanu, M. Comparison of Three Computational Approaches for
    Tree Crop Irrigation Decision Support. Mathematics 2020, 8, 717. [Google Scholar]
    [CrossRef] Russell, S.; Norvig, P. Artificial Intelligence: A Modern Approach,
    3rd ed.; Pearson: New York, NY, USA, 2010; ISBN 9780136042594. [Google Scholar]
    Deisenroth, M.P.; Faisal, A.A.; Ong, C.S. Mathematics for Machine Learning; Cambridge
    University Press (CUP): Cambridge, UK, 2020; p. 391. [Google Scholar] Müller,
    A.C.; Guido, S. Introduction to Machine Learning with Python: A Guide for Data
    Scientists, 1st ed.; O’Reilly Media: Sevastopol, CA, USA, 2016; ISBN 1449369413.
    [Google Scholar] Tsanis, I.K.; Koutroulis, A.G.; Daliakopoulos, I.N.; Jacob, D.
    Severe climate-induced water shortage and extremes in Crete. Clim. Chang. 2011,
    106, 667–677. [Google Scholar] [CrossRef] James, G.; Witten, D.; Hastie, T.; Tibshirani,
    R. Springer Texts in Statistics an Introduction to Statistical Learning-with Applications
    in R; Springer: Berlin, Germany, 2013; ISBN 9781461471370. [Google Scholar] Ziegel,
    E.R. The Elements of Statistical Learning. Technometrics 2003, 45, 267–268. [Google
    Scholar] [CrossRef] Cook, D.O.; Kieschnick, R.; McCullough, B. Regression analysis
    of proportions in finance with self selection. J. Empir. Financ. 2008, 15, 860–867.
    [Google Scholar] [CrossRef] Ruppert, D. Statistics and Finance: An Introduction.
    Technometrics 2005, 47, 244–245. [Google Scholar] Hunt, J.O.; Myers, J.N.; Myers,
    L.A. Improving Earnings Predictions and Abnormal Returns with Machine Learning.
    Account. Horizons 2021. [Google Scholar] [CrossRef] Huang, J.-C.; Ko, K.-M.; Shu,
    M.-H.; Hsu, B.-M. Application and comparison of several machine learning algorithms
    and their integration models in regression problems. Neural Comput. Appl. 2019,
    32, 5461–5469. [Google Scholar] [CrossRef] Bary, M.N.A. Robust regression diagnostic
    for detecting and solving multicollinearity and outlier problems: Applied study
    by using financial data. Appl. Math. Sci. 2017, 11, 601–622. [Google Scholar]
    [CrossRef] [Green Version] Leek, J. The Elements of Data Analytic Style; Leanpub:
    Victoria, BC, Canada, 2015; p. 93. [Google Scholar] Heumann, C.; Schomaker, M.
    Shalabh Introduction to Statistics and Data Analysis: With Exercises, Solutions
    and Applications in R; Springer International Publishing: Berlin, Germany, 2017;
    ISBN 9783319461625. [Google Scholar] Chen, L.-P. Practical Statistics for Data
    Scientists: 50+ Essential Concepts Using R and Python. Technometrics 2021, 63,
    272–273. [Google Scholar] [CrossRef] Jin, X.-B.; Yang, N.-X.; Wang, X.-Y.; Bai,
    Y.-T.; Su, T.-L.; Kong, J.-L. Hybrid Deep Learning Predictor for Smart Agriculture
    Sensing Based on Empirical Mode Decomposition and Gated Recurrent Unit Group Model.
    Sensors 2020, 20, 1334. [Google Scholar] [CrossRef] [PubMed] [Green Version] Shetty,
    S.A.; Padmashree, T.; Sagar, B.M.; Cauvery, N.K. Performance Analysis on Machine
    Learning Algorithms with Deep Learning Model for Crop Yield Prediction; Springer:
    Singapore, 2021; pp. 739–750. [Google Scholar] Blankmeyer, E. How Robust Is Linear
    Regression with Dummy Variables? Online Submiss. Available online: https://digital.library.txstate.edu/handle/10877/4105
    (accessed on 4 December 2005). Raschka, S.; Mirjalili, V. Python Machine Learning:
    Machine Learning & Deep Learning with Python, Scikit-Learn and TensorFlow 2, 3rd
    ed.; Packt Publishing: Birmingham, UK, 2019; ISBN 9781789955750. [Google Scholar]
    Gerón, A. Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow:
    Concepts, Tools, and Techniques to Build Intelligent Systems, 2nd ed.; O’Reilly
    Media, Inc.: Sevastopol, CA, USA, 2019; ISBN 9781492032649. [Google Scholar] Kubben,
    P.; Dumontier, M.; Dekker, A.L.A.J.; André, L.A.J. Fundamentals of Clinical Data
    Science, 1st ed.; Springer: London, UK, 2019; ISBN 978-3319997124. [Google Scholar]
    Fortmann-Roe, S. Understanding the Bias-Variance Tradeoff. Available online: http://scott.fortmann-roe.com/docs/BiasVariance.html
    (accessed on 4 December 2005). Cawley, G.C.; Talbot, N.L.C. On Over-fitting in
    Model Selection and Subsequent Selection Bias in Performance Evaluation. J. Mach.
    Learn. Res. 2010, 11, 2079–2107. [Google Scholar] VanderPlas, J. Python Data Science
    Handbook: Essential Tools for Working with Data; O’Reilly Media, Inc.: Sebastopol,
    CA, USA, 2016; ISBN 9781491912058. [Google Scholar] Kuhn, M.; Johnson, K. Applied
    Predictive Modeling; Springer Science Business Media: New York, NY, USA, 2013;
    p. 600. [Google Scholar] Mohri, M.; Rostamizadeh, A.; Talwalkar, A. (Eds.) Foundations
    of Machine Learning, 2nd ed.; MIT: Cambridge, MA, USA, 2018; Volume 3, ISBN 9780262039406.
    [Google Scholar] Sambasivam, G.; Opiyo, G.D. A predictive machine learning application
    in agriculture: Cassava disease detection and classification with imbalanced dataset
    using convolutional neural networks. Egypt. Inform. J. 2021, 22, 27–34. [Google
    Scholar] [CrossRef] De Luna, R.G.; Dadios, E.P.; Bandala, A.A.; Vicerra, R.R.P.
    Tomato Growth Stage Monitoring for Smart Farm Using Deep Transfer Learning with
    Machine Learning-based Maturity Grading. AGRIVITA J. Agric. Sci. 2020, 42, 24–36.
    [Google Scholar] [CrossRef] Balducci, F.; Impedovo, D.; Pirlo, G. Machine Learning
    Applications on Agricultural Datasets for Smart Farm Enhancement. Machines 2018,
    6, 38. [Google Scholar] [CrossRef] [Green Version] Kuhn, M.; Johnson, K. Feature
    Engineering and Selection: A Practical Approach for Predictive Models; CRC Press:
    Boca Raton, FL, USA, 2019; ISBN 9781351609470. [Google Scholar] Brownlee, J. Machine
    Learning Mastery with R; Brownlee Publishing: London, UK, 2016. [Google Scholar]
    Brownlee, J. Imbalanced Classification with Python: Better Metrics, Balance Skewed
    Classes, Cost-Sensitive Learning; Brownlee Publishing: London, UK, 2021. [Google
    Scholar] Datar, R.; Garg, H. Hands-On Exploratory Data Analysis with R; Packt:
    Birmingham, UK, 2019; ISBN 9781789804379. [Google Scholar] Yegnanarayana, B. Artificial
    neural networks for pattern recognition. Sadhana 1994, 19, 189–238. [Google Scholar]
    [CrossRef] Matloff, N. Statistical Regression and Classification: From Linear
    Models to Machine Learning; CRC Press: Boca Raton, FL, USA, 2017; ISBN 9781498710923.
    [Google Scholar] Liu, H. Feature Engineering for Machine Learning and Data Analytics;
    CRC Press: Boca Raton, FL, USA, 2018; ISBN 978-1491953242. [Google Scholar] Brownlee,
    J. Statistical Methods for Machine Learning; Brownlee Publishing: London, UK,
    2018; p. 291. [Google Scholar] Fortmann-Roe, S. Accurately Measuring Model Prediction
    Error. Available online: https://scott.fortmann-roe.com/docs/MeasuringError.html
    (accessed on 4 December 2021). Brain, D.; Webb, G.I. On The Effect of Data Set
    Size on Bias and Variance in Classification Learning. In Proceedings of the Fourth
    Australian Knowledge Acquisition Workshop (AKAW ’99), Sydney, Australia, 5–6 December
    1999; University of New South Wales: Sydney, Australia; pp. 117–128. Available
    online: https://www.bibsonomy.org/bibtex/2eb55c4bdfb45c25cad6b1c613e9ef74f/giwebb
    (accessed on 26 October 2021). Xiang, H.; Lin, J.; Chen, C.-H.; Kong, Y. Asymptotic
    Meta Learning for Cross Validation of Models for Financial Data. IEEE Intell.
    Syst. 2020, 35, 16–24. [Google Scholar] [CrossRef] Lin, W.-Y.; Hu, Y.-H.; Tsai,
    C.-F. Machine Learning in Financial Crisis Prediction: A Survey. IEEE Trans. Syst.
    Man Cybern. Part C Appl. Rev. 2012, 42, 421–436. [Google Scholar] [CrossRef] López
    de Prado, M. Advances in Financial Machine Learning: Lecture 7/10. SSRN Electron.
    J. 2018, 366. Available online: https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3266136
    (accessed on 14 October 2018). Krstajic, D.; Buturovic, L.J.; E Leahy, D.; Thomas,
    S. Cross-validation pitfalls when selecting and assessing regression and classification
    models. J. Cheminformatics 2014, 6, 70. [Google Scholar] [CrossRef] [Green Version]
    Tantithamthavorn, C.; Member, S.; McIntosh, S.; Hassan, A.E.; Matsumoto, K.; Member,
    S. An Empirical Comparison of Model Validation Techniques for Defect Prediction
    Models. IEEE Trans. Softw. Eng. 2016, 43, 1–18. [Google Scholar] [CrossRef] Rodríguez,
    J.D.; Pérez, A.; Lozano, J.A. Sensitivity Analysis of k-Fold Cross Validation
    in Prediction Error Estimation. IEEE Trans. Pattern Anal. Mach. Intell. 2010,
    32, 569–575. [Google Scholar] [CrossRef] Varma, S.; Simon, R. Bias in error estimation
    when using cross-validation for model selection. BMC Bioinform. 2006, 7, 91. [Google
    Scholar] [CrossRef] [PubMed] [Green Version] Scikit-Learn Developers 3.1. Cross-Validation:
    Evaluating Estimator Performance. Available online: https://scikit-learn.org/stable/modules/cross_validation.html
    (accessed on 30 April 2021). Machine Learning. Available online: https://en.wikipedia.org/wiki/Machine_learning
    (accessed on 4 December 2021). Wainer, J.; Cawley, G. Nested cross-validation
    when selecting classifiers is overzealous for most practical applications. Expert
    Syst. Appl. 2021, 182, 115222. [Google Scholar] [CrossRef] Opitz, D.W.; Maclin,
    R. Popular Ensemble Methods: An Empirical Study. J. Artif. Intell. Res. 1999,
    11, 169–198. [Google Scholar] [CrossRef] Zhou, Z.H. Ensemble Methods: Foundations
    and Algorithms; Chapman and Hall/CRC Press: Boca Raton, FL, USA; London, UK; New
    York, NY, USA, 2012; ISBN 9781439830055. [Google Scholar] Kuncheva, L.; Whitaker,
    C.J. Measures of Diversity in Classifier Ensembles and Their Relationship with
    the Ensemble Accuracy. Mach. Learn. 2003, 51, 181–207. [Google Scholar] [CrossRef]
    Matloff, N. Probability and Statistics for Data Science; CRC Press: Boca Raton,
    FL, USA, 2019; ISBN 9780367260934. [Google Scholar] Pascual, C. Tutorial: Understanding
    Linear Regression and Regression Error Metrics. (Hentet: 9 May 2021). Available
    online: https://www.dataquest.io/blog/understanding-regression-error-metrics/
    (accessed on 30 April 2021). Swalin, A. Choosing the Right Metric for Evaluating
    Machine Learning Models—Part 1 by Alvira Swalin USF-Data Science Medium. Available
    online: https://medium.com/usf-msds/choosing-the-right-metric-for-machine-learning-models-part-1-a99d7d7414e4
    (accessed on 30 April 2021). Scikit-Learn Metrics and Scoring: Quantifying the
    Quality of Predictions—Scikit-Learn 0.24.2 Documentation. Available online: https://scikit-learn.org/stable/modules/model_evaluation.html#regression-metrics
    (accessed on 30 April 2021). Westfall, P.H.; Arias, A.L. R-Squared, Adjusted R-Squared,
    the F Test, and Multicollinearity. In Understanding Regression Analysis; Chapman
    and Hall/CRC Press: Boca Raton, FL, USA, 2020; pp. 185–200. [Google Scholar] Karch,
    J. Improving on Adjusted R-Squared. Collabra Psychol. 2020, 6, 6. [Google Scholar]
    [CrossRef] Grömping, U. Variable importance in regression models. Wiley Interdiscip.
    Rev. Comput. Stat. 2015, 7, 137–152. [Google Scholar] [CrossRef] Gorgens, E.;
    Montaghi, A.; Rodriguez, L.C. A performance comparison of machine learning methods
    to estimate the fast-growing forest plantation yield based on laser scanning metrics.
    Comput. Electron. Agric. 2015, 116, 221–227. [Google Scholar] [CrossRef] Zhang,
    Y.; Yang, X.; Shardt, Y.A.W.; Cui, J.; Tong, C. A KPI-Based Probabilistic Soft
    Sensor Development Approach that Maximizes the Coefficient of Determination. Sensors
    2018, 18, 3058. [Google Scholar] [CrossRef] [Green Version] Takayama, K. Encoding
    Categorical Variables with Ambiguity. In Proceedings of the International Workshop
    NFMCP in conjunction with ECML-PKDD, Tokyo, Japan, 16 September 2019. [Google
    Scholar] Kuhn, M. Comparing the Bootstrap and Cross-Validation. Available online:
    http://appliedpredictivemodeling.com/blog/2014/11/27/08ks7leh0zof45zpf5vqe56d1sahb0
    (accessed on 30 April 2021). Kohavi, R. A Study of Cross-Validation and Bootstrap
    for Accuracy Estimation and Model Selection. Int. Jt. Conf. Artif. Intell. 1995,
    14, 1137–1145. [Google Scholar] Sujjaviriyasup, T.; Pitiruek, K. Agricultural
    product forecasting using machine learning approach. Int. J. Math. Anal. 2013,
    7, 1869–1875. [Google Scholar] [CrossRef] Thorp, K.R.; Batchelor, W.D.; Paz, J.O.;
    Kaleita, A.L.; DeJonge, K.C. Using Cross-Validation to Evaluate CERES-Maize Yield
    Simulations within a Decision Support System for Precision Agriculture. Trans.
    ASABE 2007, 50, 1467–1479. [Google Scholar] [CrossRef] [Green Version] Paul, M.;
    Vishwakarma, S.K.; Verma, A. Analysis of Soil Behaviour and Prediction of Crop
    Yield Using Data Mining Approach. In Proceedings of the 2015 International Conference
    on Computational Intelligence and Communication Networks CICN 2015, Jabalpur,
    India, 12–14 December 2015; Institute of Electrical and Electronics Engineers
    Inc.: Piscataway, NJ, USA, 2016; pp. 766–771. [Google Scholar] Molinaro, A.M.;
    Simon, R.; Pfeiffer, R.M. Prediction error estimation: A comparison of resampling
    methods. Bioinformatics 2005, 21, 3301–3307. [Google Scholar] [CrossRef] [Green
    Version] Kim, J.-H. Estimating classification error rate: Repeated cross-validation,
    repeated hold-out and bootstrap. Comput. Stat. Data Anal. 2009, 53, 3735–3745.
    [Google Scholar] [CrossRef] Brownlee, J. Repeated k-Fold Cross-Validation for
    Model Evaluation in Python. Available online: https://machinelearningmastery.com/repeated-k-fold-cross-validation-with-python/
    (accessed on 30 April 2021). Fan, J.; Li, R.; Zhang, C.-H.; Zou, H. Statistical
    Foundations of Data Science; CRC Press: Boca Raton, FL, USA, 2020; ISBN 978-1-466-51084-5.
    [Google Scholar] Storm, H.; Baylis, K.; Heckelei, T. Machine learning in agricultural
    and applied economics. Eur. Rev. Agric. Econ. 2019, 47, 849–892. [Google Scholar]
    [CrossRef] Mbunge, E.; Fashoto, S.G.; Mnisi, E.J. Machine learning approach for
    predicting maize crop yields using multiple linear regression and backward elimination.
    Int. J. Sci. Technol. Res. 2020, 9, 3804–3814. [Google Scholar] Vinciya, P.; Valarmathi,
    A. Agriculture Analysis for Next Generation High Tech Farming in Data Mining.
    Int. J. Adv. Res. Comput. Sci. Softw. Eng. 2016, 6, 2277. [Google Scholar] Chen,
    Y.-A.; Hsieh, W.-H.; Ko, Y.-S.; Huang, N.-F. An Ensemble Learning Model for Agricultural
    Irrigation Prediction. In Proceedings of the 2021 International Conference on
    Information Networking, Jeju Island, Korea, 13–16 January 2021; Volume 2021-Janua,
    pp. 311–316. [Google Scholar] Shahhosseini, M.; Hu, G.; Archontoulis, S.V. Forecasting
    Corn Yield with Machine Learning Ensembles. Front. Plant Sci. 2020, 11, 1120.
    [Google Scholar] [CrossRef] Trafalis, T.; Ince, H. Support vector machine for
    regression and applications to financial forecasting. In Proceedings of the IEEE-INNS-ENNS
    International Joint Conference on Neural Networks, IJCNN 2000, Neural Computing:
    New Challenges and Perspectives for the New Millennium, Como, Italy, 24–27 July
    2000; Volume 6, pp. 348–353. [Google Scholar] Miles, J. R Squared, Adjusted R
    Squared. In Wiley StatsRef: Statistics Reference Online; Wiley: Hoboken, NJ, USA,
    2014. [Google Scholar] Barrett, J.P. The coefficient of determination-some limitations.
    Am. Stat. 1974, 28, 19–20. [Google Scholar] Regression Models for Data… by Brian
    Caffo [PDF/iPad/Kindle]. Available online: https://leanpub.com/regmods (accessed
    on 5 August 2021). Ghojogh, B.; Crowley, M. The Theory behind Overfitting, Cross
    Validation, Regularization, Bagging, and Boosting: Tutorial. arXiv 2019, preprint.
    arXiv:1905.12787. [Google Scholar] Chen, D.; Hagan, M. Optimal use of regularization
    and cross-validation in neural network modeling. In Proceedings of the IJCNN’99,
    International Joint Conference on Neural Networks, Proceedings (Cat. No.99CH36339),
    Baltimore, MD, USA, 7–11 June 1992; Volume 2, pp. 1275–1280. [Google Scholar]
    Steyerberg, E. Overfitting and optimism in prediction models. In Statistics for
    Biology and Health; Springer: Cham, Switzerland, 2019; pp. 83–100. [Google Scholar]
    Sklearn.Svm.SVR—Scikit-Learn 1.0 Documentation. Available online: https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html
    (accessed on 25 September 2021). Koutsoukas, A.; Monaghan, K.J.; Li, X.; Huan,
    J. Deep-learning: Investigating deep neural networks hyper-parameters and comparison
    of performance to shallow methods for modeling bioactivity data. J. Cheminformatics
    2017, 9, 42. [Google Scholar] [CrossRef] [PubMed] Sklearn.Ensemble.GradientBoostingRegressor—Scikit-Learn
    1.0 Documentation. Available online: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html?highlight=gradientboostingregressor#sklearn.ensemble.GradientBoostingRegressor
    (accessed on 25 September 2021). Shakoor, T.; Rahman, K.; Rayta, S.N.; Chakrabarty,
    A. Agricultural production output prediction using Supervised Machine Learning
    techniques. In Proceedings of the 2017 1st International Conference on Next Generation
    Computing Applications, NextComp Mauritius, East Africa, Mauritius, 19–21 July
    2017; Institute of Electrical and Electronics Engineers Inc.: Piscataway, NJ,
    USA, 2017; pp. 182–187. [Google Scholar] Treboux, J.; Genoud, D. High Precision
    Agriculture: An Application of Improved Machine-Learning Algorithms. In Proceedings
    of the 2019 6th Swiss Conference on Data Science (SDS), Bern, Switzerland, 14
    June 2019; pp. 103–108. [Google Scholar] Liakos, K.G.; Busato, P.; Moshou, D.;
    Pearson, S.; Bochtis, D. Machine learning in agriculture: A review. Sensors 2018,
    18, 2674. [Google Scholar] [CrossRef] [PubMed] [Green Version] Sabu, K.M.; Kumar,
    T.M. Predictive analytics in Agriculture: Forecasting prices of Arecanuts in Kerala.
    Procedia Comput. Sci. 2020, 171, 699–708. [Google Scholar] [CrossRef] Yuan, C.Z.;
    San, W.W.; Leong, T.W. Determining Optimal Lag Time Selection Function with Novel
    Machine Learning Strategies for Better Agricultural Commodity Prices Forecasting
    in Malaysia. In Proceedings of the 2020 2nd International Conference on Information
    Technology and Computer Communications, Guangzhou, China, 23–25 June 2020; pp.
    37–42. [Google Scholar] Chen, Z.; Goh, H.S.; Sin, K.L.; Lim, K.; Chung, N.K.H.;
    Liew, X.Y. Automated Agriculture Commodity Price Prediction System with Machine
    Learning Techniques. Adv. Sci. Technol. Eng. Syst. J. 2021, 6, 376–384. [Google
    Scholar] [CrossRef] Lebrini, Y.; Benabdelouahab, T.; Boudhar, A.; Htitiou, A.;
    Hadria, R.; Lionboui, H. Farming systems monitoring using machine learning and
    trend analysis methods based on fitted NDVI time series data in a semi-arid region
    of Morocco. In Proceedings of the Remote Sensing for Agriculture, Ecosystems,
    and Hydrology XXI, Strasbourg, France, 21 October 2019; Volume 11149, p. 31. [Google
    Scholar] Ouyang, H.; Wei, X.; Wu, Q. Agricultural commodity futures prices prediction
    via long—And short-term time series network. J. Appl. Econ. 2019, 22, 468–483.
    [Google Scholar] [CrossRef] Tang, F.; Mao, B.; Fadlullah, Z.M.; Kato, N.; Akashi,
    O.; Inoue, T.; Mizutani, K. On Removing Routing Protocol from Future Wireless
    Networks: A Real-time Deep Learning Approach for Intelligent Traffic Control.
    IEEE Wirel. Commun. 2018, 25, 154–160. [Google Scholar] [CrossRef] Abroyan, N.
    Convolutional and recurrent neural networks for real-time data classification.
    In Proceedings of the 7th International Conference on Innovative Computing Technology
    INTECH 2017, Luton, UK, 16–18 August 2017; pp. 42–45. [Google Scholar] Lakshmanaprabu,
    S.K.; Mohanty, S.N.; S., S.R.; Krishnamoorthy, S.; Uthayakumar, J.; Shankar, K.
    Online clinical decision support system using optimal deep neural networks. Appl.
    Soft Comput. J. 2019, 81, 105487. [Google Scholar] [CrossRef] Aggarwal, C.C.;
    Sathe, S. Outlier Ensembles: An Introduction; Springer: Berlin, Germany, 2017;
    ISBN 9783319547657. [Google Scholar]   Publisher’s Note: MDPI stays neutral with
    regard to jurisdictional claims in published maps and institutional affiliations.  ©
    2021 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open
    access article distributed under the terms and conditions of the Creative Commons
    Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/). Share
    and Cite MDPI and ACS Style Christias, P.; Mocanu, M. A Machine Learning Framework
    for Olive Farms Profit Prediction. Water 2021, 13, 3461. https://doi.org/10.3390/w13233461
    AMA Style Christias P, Mocanu M. A Machine Learning Framework for Olive Farms
    Profit Prediction. Water. 2021; 13(23):3461. https://doi.org/10.3390/w13233461
    Chicago/Turabian Style Christias, Panagiotis, and Mariana Mocanu. 2021. \"A Machine
    Learning Framework for Olive Farms Profit Prediction\" Water 13, no. 23: 3461.
    https://doi.org/10.3390/w13233461 Note that from the first issue of 2016, this
    journal uses article numbers instead of page numbers. See further details here.
    Article Metrics Citations Crossref   5 Scopus   4 Web of Science   1 Google Scholar   [click
    to view] Article Access Statistics Article access statistics Article Views 5.
    Jan 15. Jan 25. Jan 4. Feb 14. Feb 24. Feb 5. Mar 15. Mar 25. Mar 0k 1k 2k 3k
    4k For more information on the journal statistics, click here. Multiple requests
    from the same IP address are counted as one view.   Water, EISSN 2073-4441, Published
    by MDPI RSS Content Alert Further Information Article Processing Charges Pay an
    Invoice Open Access Policy Contact MDPI Jobs at MDPI Guidelines For Authors For
    Reviewers For Editors For Librarians For Publishers For Societies For Conference
    Organizers MDPI Initiatives Sciforum MDPI Books Preprints.org Scilit SciProfiles
    Encyclopedia JAMS Proceedings Series Follow MDPI LinkedIn Facebook Twitter Subscribe
    to receive issue release notifications and newsletters from MDPI journals Select
    options Subscribe © 1996-2024 MDPI (Basel, Switzerland) unless otherwise stated
    Disclaimer Terms and Conditions Privacy Policy"'
  inline_citation: '>'
  journal: Water (Switzerland)
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: A machine learning framework for olive farms profit prediction
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Susilo A.S.
  - Karna N.
  - Mayasari R.
  citation_count: '3'
  description: Indonesia is an agricultural country that has a dependency on the horticulture
    sub-sector. Bok choy is included in the mustard greens group as one of the strategic
    products from the horticulture. The needs for mustard greens are getting higher.
    Based on Indonesia’s Central Statistics Agency data in 2019, the mustard beans
    production rate increased only 2.63% higher than in 2018. If it does not meet
    the desired supply, it opens the possibility of a lack of bok choy supply at the
    market, resulting in high potential price fluctuations. These conditions initiate
    relevant system research to help the farmer develop a bok choy crop reference
    guide, especially in the seeding phase. In reducing the limitations caused by
    the lack of science and knowledge in the farmer environment, the prediction model
    is the proposed outcome by considering the use of IoT mechanism that has widely
    developed. The model is based on a system that integrates IoT’s interest in the
    agriculture field, namely smart farm, for retrieving real-time data based on automatic
    control, MySQL database for storing data, and machine learning technique to establish
    the prediction model as the guide for the farmers to find appropriate parameters
    for planting bok choy. The prediction model performs using Python, a high-level
    popular programming language due to its ease and open source. Python interprets
    the bok choy growth dataset based on the irrigation system scenario from the integrated
    system with the relevant library of data preprocessing interest and the Decision
    Tree algorithm of the Scikit-learn library to train the model. The system conducts
    a series of machine learning phases to take the insight analysis needed to create
    a prediction model. The model performance metrics as the consideration in deciding
    the outcome model, which are accuracy and precision.
  doi: 10.1109/ICOIACT53268.2021.9563914
  full_citation: '>'
  full_text: '>

    "This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org
    IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal
    Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln
    Sign Out All Books Conferences Courses Journals & Magazines Standards Authors
    Citations ADVANCED SEARCH Conferences >2021 4th International Confer... Decision
    Tree-Based Bok Choy Growth Prediction Model for Smart Farm Publisher: IEEE Cite
    This PDF Aldi Sulthony Susilo; Nyoman Karna; Ratna Mayasari All Authors 3 Cites
    in Papers 211 Full Text Views Abstract Document Sections I. Introduction II. Literature
    Review III. Bok Choy Growth Prediction Model IV. The Evaluation of Classification
    Performance Metrics V. Prediction Model Testing Authors Figures References Citations
    Keywords Metrics Abstract: Indonesia is an agricultural country that has a dependency
    on the horticulture sub-sector. Bok choy is included in the mustard greens group
    as one of the strategic products from the horticulture. The needs for mustard
    greens are getting higher. Based on Indonesia''s Central Statistics Agency data
    in 2019, the mustard beans production rate increased only 2.63% higher than in
    2018. If it does not meet the desired supply, it opens the possibility of a lack
    of bok choy supply at the market, resulting in high potential price fluctuations.
    These conditions initiate relevant system research to help the farmer develop
    a bok choy crop reference guide, especially in the seeding phase. In reducing
    the limitations caused by the lack of science and knowledge in the farmer environment,
    the prediction model is the proposed outcome by considering the use of IoT mechanism
    that has widely developed. The model is based on a system that integrates IoT''s
    interest in the agriculture field, namely smart farm, for retrieving real-time
    data based on automatic control, MySQL database for storing data, and machine
    learning technique to establish the prediction model as the guide for the farmers
    to find appropriate parameters for planting bok choy. The prediction model performs
    using Python, a high-level popular programming language due to its ease and open
    source. Python interprets the bok choy growth dataset based on the irrigation
    system scenario from the integrated system with the relevant library of data preprocessing
    interest and the Decision Tree algorithm of the Scikit-learn library to train
    the model. The system conducts a series of machine learning phases to take the
    insight analysis needed to create a prediction model. The model performance metrics
    as the consideration in deciding the outcome model, which are accuracy and precision.
    Published in: 2021 4th International Conference on Information and Communications
    Technology (ICOIACT) Date of Conference: 30-31 August 2021 Date Added to IEEE
    Xplore: 20 October 2021 ISBN Information: DOI: 10.1109/ICOIACT53268.2021.9563914
    Publisher: IEEE Conference Location: Yogyakarta, Indonesia SECTION I. Introduction
    Indonesia is a developing country with a broad population segment that depends
    on their life in agriculture. The horticulture sector produces vegetable products,
    fruit plants, ornamental plants, and medicinal plants that can be traded. Based
    on data obtained from the Central Statics Agency in 2018, the number of farmers
    was around 33.1 million, and there were 10.1 million horticultural farmers [1].
    As a result of this population, agricultural was still one of the Indonesian economy
    pilars by contributing 14% of the GDP [2]. Besides helping the national income,
    the horticultural sector contributed to its export activities and food needs.
    Again, the farmers received the annual revenues sufficient for their lives. The
    other parties were involving as the supporting system in food supply distribution
    applied before being consumed by the communities. One of the leading agricultural
    commodities in Indonesia is bok choy. This plant is required as a supplementary
    food material in the household and industrial environment. Bok choy is considering
    as one of the plants classify in the mustard greens group. Along with the high
    demand resulting in potential supply and price fluctuations, the mustard greens
    production rate only increased by 2.63 % in 2019 over 2018 in the Central Statistics
    Agency of Indonesia data [3]. The public information also reinforced the Ministry
    of Agriculture data to state that there had been a fluctuation rate in the population
    of West Java province food consumption by day and year from 2013–2018 [4]. The
    fluctuation was caused by several factors, including weather sensitivity, limited
    resources (producers, planting knowledge, infrastructure, and land availability),
    the influence of fertilizer, and climate change. In maintaining the stability
    of bok choy commodity prices, an adequate supply of the finest quality of bok
    choy is needed. The specific observed parameter to analyze is the soil moisture
    as the growth-related factor to plant the bok choy. The production growth rate
    of the bok choy as one of the plants classified in mustard greens is still slightly
    increased. It may lead to a lack of supply if it is not comparable with the market''s
    availability. One of the issues is caused by the lack of fully-compiled science
    and knowledge. It is difficult for farmers to determine superior seed that impacts
    the quality and quantity of the bok choy. However, market demand for bok choy
    is still outstanding and necessary for household and industrial material cooking.
    Nowadays, the bok choy optimal seeding model is still unavailable as a reference
    guide for generating predictions to work in the farmer environment. The The objective
    is increasing the production, which offers to farmers environment as the main
    player in producing the best choice of bok choy seeding phases in increasing the
    possibility of optimal crops and open opportunities to maintain the availability
    of bok choy quality on the market. One of the facilities used to do suitable planting
    is the greenhouse. The greenhouse is an architecture to plant the bok choy following
    the desired optimal condition with a more attentive environment and minimize unwanted
    environmental factors. A classification approach of supervised machine learning
    technique applies to develop the model strengthen by the designated output label
    that manually inputs. The model development is conduct in an open-source Jupyter
    Notebook as it is interactive to the user to conclude the analysis of each machine
    learning phase. There are several procedures as references to perform the model
    testing. The train/test split procedure splits the dataset automatically and implements
    a decision tree algorithm to train the data. The evaluation of the model performance
    performs with three classification metrics, such as accuracy score, confusion
    matrix, and classification table that correlated to each other as the analysis
    to determine the prediction model''s quality. The model is saved to the local
    computer model for repeatedly implementing the model testing, which applies to
    the Pickle library''s given input. The research using the dataset adopted from
    an integrated system between IoT for retrieving data from research object, MySQL
    of unpublished undergraduate thesis and executive database dashboard as data storing
    management for knowldge discovery [5]–[7]. SECTION II. Literature Review The researchers
    have conducted various researches on the use of greenhouse to utilize the environment
    independently, including real-time monitoring and controlling greenhouse systems
    based on smart farm [8]. An IoT device is connected through a networks as an integrated
    system in retrieving real-time data is necessary. Raspberry Pi is used as an IoT
    device because it has an embedded wi-fi module and external instrument, such as
    sensors as supporting system. The soil moisture sensor is defined as calibrating
    the water dose value of greater than or equal to 15 % as the lower limit and lower
    than equal to 25 % defined as normal condition [9]. Whereas the optimum temperature
    is in a range of 20 – 25 degrees celcius [10]. The application of Raspberry Pi
    in the greenhouse as smart farm system implementation has been widely used by
    researcher [11] [12]. Users can perform data retrieval results for a prediction
    model to determine the best composition in producing optimal bok choy seeding
    crops. This method has been proven by several researchers who made a collection
    of observation in tomatoes and lettuce growth as it used for quality predictive
    models [13] [14]. The Raspberry Pi is retrieved data from the respective types
    of desired sensor monitoring and controlling and is automatically stored in the
    database. The platform is supported with the additional application of the database
    management system field, such as MySQL database. The designated raw data is divided
    into several groups. The group of data combines the dataset as the input for performing
    the prediction model. The integrated system of IoT and machine learning has also
    been explored by the scientist [15] [16]. A prediction model is generated using
    the machine learning technique in processing information from the available datasets.
    Machine Learning performs with the help of complementary libraries, such as Numpy,
    Pandas, Matplotlib, Seaborn, and Scikit-learn of Python programming language that
    has been widely used in the related field to build the learning systems in producing
    a desired model. SECTION III. Bok Choy Growth Prediction Model A. The Workflow
    of The Global System The proposed global workflow system is started from retrieving
    data stage with IoT mechanism, stores data in MySQL database, and develops the
    prediction model. The data is sensed by the IoT platform with the help of the
    four respective sensors, which categorized into the value of five attributes given
    are as follows: Webcam retrieves the picture of bok choy seeding period of the
    entire pot taken once a day at noon. DHT22 sensor retrieves the room humidity
    and temperature value. BH-1750 sensor retrieves the room light intensity value.
    YL-69 sensor retrieves the soil moisture value from each pot. The sensor retrieves
    real-time information based on the sensor''s ability taken in a greenhouse in
    the Buah Batu region, as seen in figure 1. The exception for the soil moisture
    outcome, because it has a different scenario based on the irrigation system, categorized
    into automatic and manual. The automated system is a process to provide water
    to the bok choy plant that has been programmed with relay help, which will irrigate
    automatically if the soil moisture detects the water amount in the observed plant
    is less than is needed. In contrast, the manual system is a process to deliver
    water to the bok choy plant by hand-operated, which is self-irrigate the plant
    based on the range of the time decides, 09.00 A.M. to 11.00 A.M., is the best
    time to irrigate the plants. The soil moisture value has been converted from a
    percentage to the categorical attributes at receiving data. The sensed data is
    sent to the Raspberry Pi 3B. The device gathers and stores the information that
    it retrieves based on the sensor placement. Fig. 1. The greenhouse is the plant
    placement Show All The sensed data is then sent through the localhost network
    automatically every ten minutes to the MySQL database as data management for complete
    store data. In the database, the sensed data is divided into six groups, which
    are: Camera''s group contains the picture''s path of the entire pot. Plant A''s
    group contains date-time and soil moisture value from the observed plant. Plant
    B''s group contains date-time and soil moisture value from the observed plant.
    Plant C''s group contains date-time and soil moisture value from the observed
    plant. Plant D''s group contains date-time and soil moisture value from the observed
    plant. Room Condition''s group contains date-time and greenhouse humidity, temperature,
    and light intensity value. These database contents are seen in figure 2. The database
    has been deployed to website hosting for monitoring purposes. The dataset''s scratch
    obtains from the MySQL database has been prepared by merge mechanism corresponds
    to each experimental plant group and the room condition group that performs in
    the database by using MySQL query. There will be two datasets generated as the
    input data to develop the prediction model based on the Excel file export mechanisms.
    The machine learning technique is implemented after the dataset file preparation
    phase, with a suitable machine learning algorithm, achieving the prediction model
    is seen in figure 3. B. The Classification Tree Scheme The tree is the process
    of performing the machine learning technique with a decision tree algorithm. The
    procedure involves importing the decision tree classifier function from the tree
    package of the scikit -learn library. The decision tree method is implemented
    in model training phase is shown in figure 4. The computer conducts the operation
    corresponds to the user''s applicable preference. The input value is a preferred
    choice of the parameter that corresponds to the procedure''s function. This application
    uses three approved parameter subjected to the table. Another parameter defined
    by none value is not executed. The algorithm is implemented to define the attributes
    value in each instances outcome corresponds to the designated label. It corresponds
    to three observed attributes, namely moist level, temperature, and irrigation
    level started by splitting the moist level by splitting the moist level based
    on the available categorical attributes. Fig. 2. The database overview as the
    data storing management. Show All Fig. 3. The proposed workflow of the creation
    of prediction model. Show All Low and high label does not split further as it
    defines the node''s final level with classification labelled. The normal value
    characterizes by a decision node called temperature, split into two other sub-nodes
    based on the attributes value, such as decision and leaf node. The value of less
    than equal to twenty-five is detailed by decision node splits into two other leaf
    nodes. The final level with classification labelled results in optimal and less
    optimal, respectively. The overview of the classification tree is shown in figure
    5. C. Dataset Preprocessing It is a procedure to load the dataset from the respective
    directory, including folder and file name. Two datasets were loaded simultaneously
    by using the Read Excel function of the Pandas library. The function''s content
    is possible to characterize each parameter based on the user''s interest corresponds
    to the variable of the related parameter. The choice of the applicable parameter
    are: Sheet name Parse dates Index column Three parameters is applied to develop
    the model as it performs the machine learning algorithm, also data visualization.
    This procedure also applies the drop not a value function that does not cover
    any parameter. The function has an objective to remove all the instances in a
    row that has no value. Fig. 4. The proposed design of the global workflow system.
    Show All D. Dataset The real-time groups of sensed data taken form the localhost
    MySQL database based on the previous project are a principal scratch of the dataset.
    It consists of six fundamental attributes divides into one string, three continuous
    attributes, one categorical attribute, one time-stamp attribute, and the entire
    pots picture. The attribute given are as follows: plant''s name serves in the
    form of string. Moist level from the various observed pot serves in the form of
    categorical attributes. The time-series serves in the form of time-stamp attributes.
    Greenhouse temperature serves in the form of continuous attributes. Greenhouse
    humidity serves in the form of continuous attributes. Fig. 5. The overview of
    the classification tree design. Show All greenhouse light intensity serves in
    the form of continuous attributes. The camera''s output retrieves in the form
    of of picture path destination folder. The raw data is retrieved from the respective
    sensors that have been previously discussed. One group of sensed data attributes
    is disabled for prediction model development, namely the camera''s output. The
    contents leave one string, three continuous attributes, one categorical attribute,
    and one time-stamp attribute. The groups of sensed data are available in the form
    of an Excel file extension. Those sensed data groups is processed through Microsoft
    Excel application added with additional attributes and its corresponding variable
    over number of observations. This merge data operation produces qualified dataset
    for the application. The additional attributes is including one continuous and
    two categorical attributes are as follows: The plant''s height serves in the form
    of continuous attributes. The irrigation level serves in the form of category
    attributes. The class serves in the form of categorical attributes. The dataset
    is separated based on the irrigation system scenario corresponds to the environmental
    and growth-related factor in the greenhouse, also the manually-input variable.
    There are two observed plants for each scenario. Plant A and plant B corresponds
    to Pakcoy 1 and Pakcoy 2, respectively. In contrast, Plant C and plant D corresponds
    to Pakcoy 3 and Pakcoy 4. Each scenario is also differentiated based on two types
    of irrigation levels. The clarification of the irrigation system distribution
    and its corresponding level information is shown in table 1. The dataset attributes
    are one index, four continuous attributes, three categorical attributes, and one
    time-stamp attribute. The time-series schedule represents in date-time format,
    greenhouse temperature represents in degree units, greenhouse humidity represents
    in percentage, and greenhouse light intensity represents in lux units. The moist
    level is a categorical condition based on the soil moisture value measurement
    convert from percentage data, as shown in table 2. The temperature has the stated
    condition by the range of the degrees is shown in table 3. Table I Distribution
    of the plants observation based on irrigation system. Manually parameter, plant''s
    height, represents in centimeter based on the ruler, irrigation level, and class
    in categorical value. The sensed data is taken in the range of ten minutes from
    4th of January 2021 to 15th of January 2021 at 08.00 A.M. to 2.20 P.M. The class
    located at the last column in the dataset corresponds to the label for every instances
    associated with the moist level. The table provides the corresponding type of
    the moist level, and the temperature value is shown in table 4. There are two
    datasets generated based on the irrigation system for developing the prediction
    model. The automatic irrigation scenario contains 805 instances and nine attributes.
    Like the automated irrigation scenario, the manual irrigation scenario has the
    same total of attributes. In contrast, the manual dataset has 789 instances. Then,
    the concatenating dataset is equalled to 1594 instances. The sample of the dataset
    is shown in table 5. Pakcoy is an indonesian name of bok choy. Table II Moist
    level condition of the dataset. SECTION IV. The Evaluation of Classification Performance
    Metrics The performance metrics evaluation based on the available type for the
    classification approach. The corresponding value is the label test data and the
    label predicts data based on the prediction made for the attributes of train data.
    The variety of classification metrics are: A. Confusion Matrix This metric is
    necessary to calculate other performance parameters in the classification table,
    such as accuracy, precision, Etc. The result generated form the Jupyter notebook
    does not give any remarkable information corresponds to the value. In creating
    a more straightforward interpretation to understand the outcome, the value is
    presented in a form of table. The visualization of the confusion matrix with a
    table is shown in table 6. The noticeable perception is to give attention that
    the left top of the table corresponds to the true positive value and the left
    below is related to the negative class. Table III Temperature condition of the
    dataset. Table IV The data class of the dataset. Table V The automatic irrigation
    dataset sample. The table means the classifier has correctly classified the total
    of positive and negative instances. This matrix informs the total instance for
    two-class in which is stated by the overview of the classifier''s prediction is
    discussed in the previous section. This type of confusion matrix is correlated
    with the perfect classifier performance. It is strengthened by the matrix''s pattern
    with no value correlated with the false positive and false negative. As confirmation,
    it is suitable to review the parameter correlation. The true positive rate expressed
    by the total of true positive instances divides by the total of positive instances
    equals one is to meet the criterion as a result is equal to one. False positive
    rate equals zero as there are no available false positive instances classified.
    Also, the precision equals one as the positive value has only the true positive
    value. B. Classification Report These metrics perform as the final analysis as
    the value derived from the confusion matrix is present is in figure 6. The performance
    parameter as the consideration in depending on the ideal prediction model is the
    accuracy and precision. Before reviewing the parameter based on the value derived
    from the confusion matrix, these metrics clarify that the noticed label is only
    two, namely optimal and less optimal, as it not clearly stated in the confusion
    matrix discussion section. The absence of not optimal is because there are not
    enough instances available in the dataset. The analysis of the corresponding parameter
    present in table 7. On the table''s content, each of the parameter calculation
    is derived. The accuracy outcome meets the perfect classifier case prerequisite
    requirement al it also clarifies the accuracy score that has been converted into
    the percentage. Either precision score or recall is also completing the qualification.
    Table VI The visualization of the confusion matrix table. Fig. 6. The overview
    of the classification report result. Show All SECTION V. Prediction Model Testing
    This stage is conducted to represent the model testing phase. The model testing
    is differentiated from the model testing phase because it is based on unseen instances.
    In completing the analysis, it defines by the number of attributes value. The
    defined Test Model function is used as it more comfortable to change the attribute
    value. As the introductory to use the function, the variable''s value corresponds
    to the attributes shown in table 8. The outcome generated by the variables is
    shown in figure 7. It shows that the result is less optimal class. When we differentiated
    each defined value, such as the moist level is high, Temperature is greater than
    twenty-seven, and the irrigation level is sufficient. The result is satisfied.
    However, in this project, the humidity, height, and light intensity are dismissed.
    In comparison with other labels, another unseen instances is observed, as seen
    in figure 8. The attributes value is started from the moist level with normal
    value, the temperature is less than twenty-five, and the irrigation level is sufficient.
    These unseen instance are not satisfied. The appropriate class, optimal is not
    shown. Although the classification report able to classify the optimal label,
    it concludes that the data used is insufficient to predict unseen instances. It
    is shown by the number of test data in a total of three-hundred and thirteen for
    the less optimal and inversely proportional to six for optimal label. Table VII
    The parameter calculation table. Table VIII An overview of the attributes value
    definition. Fig. 7. An overview of unseen instances prediction. Show All Fig.
    8. An overview of the second unseen instances prediction. Show All Authors Figures
    References Citations Keywords Metrics More Like This Design of Real-Time System
    Based on Machine Learning for Snoring and OSA Detection ICASSP 2022 - 2022 IEEE
    International Conference on Acoustics, Speech and Signal Processing (ICASSP) Published:
    2022 An integrated approach of Genetic Algorithm and Machine Learning for generation
    of Worst-Case Data for Real-Time Systems 2022 IEEE/ACM 26th International Symposium
    on Distributed Simulation and Real Time Applications (DS-RT) Published: 2022 Show
    More IEEE Personal Account CHANGE USERNAME/PASSWORD Purchase Details PAYMENT OPTIONS
    VIEW PURCHASED DOCUMENTS Profile Information COMMUNICATIONS PREFERENCES PROFESSION
    AND EDUCATION TECHNICAL INTERESTS Need Help? US & CANADA: +1 800 678 4333 WORLDWIDE:
    +1 732 981 0060 CONTACT & SUPPORT Follow About IEEE Xplore | Contact Us | Help
    | Accessibility | Terms of Use | Nondiscrimination Policy | IEEE Ethics Reporting
    | Sitemap | IEEE Privacy Policy A not-for-profit organization, IEEE is the world''s
    largest technical professional organization dedicated to advancing technology
    for the benefit of humanity. © Copyright 2024 IEEE - All rights reserved."'
  inline_citation: '>'
  journal: 'ICOIACT 2021 - 4th International Conference on Information and Communications
    Technology: The Role of AI in Health and Social Revolution in Turbulence Era'
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Decision Tree-Based Bok Choy Growth Prediction Model for Smart Farm
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'

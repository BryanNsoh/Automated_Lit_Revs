- DOI: https://doi.org/10.3390/s17092010
  analysis: '>'
  authors:
  - Gonçalo de Jesus
  - António Casimiro
  - Anabela Oliveira
  citation_count: 30
  full_citation: '>'
  full_text: '>

    sensors

    Article

    A Survey on Data Quality for Dependable

    Monitoring in Wireless Sensor Networks

    Gonçalo Jesus 1,*

    ID , António Casimiro 2,*

    ID and Anabela Oliveira 1,*

    1

    Hydraulics and Environment Department, LNEC, Lisbon 1700-066, Portugal

    2

    LaSIGE, Faculdade de Ciências, Universidade de Lisboa, Lisbon 1749-016, Portugal

    *

    Correspondence: gjesus@lnec.pt (G.J.); casim@ciencias.ulisboa.pt (A.C.); aoliveira@lnec.pt
    (A.O.)

    Received: 29 June 2017; Accepted: 31 August 2017; Published: 2 September 2017

    Abstract: Wireless sensor networks are being increasingly used in several application
    areas,

    particularly to collect data and monitor physical processes. Non-functional requirements,
    like

    reliability, security or availability, are often important and must be accounted
    for in the application

    development. For that purpose, there is a large body of knowledge on dependability
    techniques for

    distributed systems, which provide a good basis to understand how to satisfy these
    non-functional

    requirements of WSN-based monitoring applications. Given the data-centric nature
    of monitoring

    applications, it is of particular importance to ensure that data are reliable
    or, more generically,

    that they have the necessary quality. In this survey, we look into the problem
    of ensuring the

    desired quality of data for dependable monitoring using WSNs. We take a dependability-oriented

    perspective, reviewing the possible impairments to dependability and the prominent
    existing

    solutions to solve or mitigate these impairments. Despite the variety of components
    that may form a

    WSN-based monitoring system, we give particular attention to understanding which
    faults can affect

    sensors, how they can affect the quality of the information and how this quality
    can be improved

    and quantiﬁed.

    Keywords: wireless sensor networks; dependability; machine learning; monitoring;
    data quality;

    sensor fusion

    1. Introduction

    In order to increase the dependability of monitoring applications in wireless
    sensor network (WSN)

    settings, one must be aware that the quality of monitoring data can be affected
    by faults. In essence,

    there is a problem of data quality assurance, which can be faced taking two main
    perspectives: either

    by deploying dependability techniques to mask faults and enforce the reliability
    of the system or

    by enhancing the system with means to continuously assess and characterize the
    quality of data [1].

    In the former case, the system will not be aware of the quality of data, and hence,
    if a certain quality

    is needed, it must be enforced by design, conﬁning the effects of faults a priori.
    Considering sensors

    to be the main source of data, errors in sensing measurements are handled by procedures
    that are

    established based on a deep understanding of the characteristics of the sensors
    [2]. Missing readings

    may be handled by oversampling, and glitches, like outliers and noise, can be
    masked by averaging.

    In the latter case, given that the system can be aware of the quality of data
    at run-time, it is better

    suited to be used in environments where full knowledge of the operational conditions
    is not known

    in advance. In this case, mitigation techniques must be deployed to handle faults
    and data quality

    problems at run-time, for instance exploiting application semantics to determine
    appropriate data

    corrections and to regain the needed data quality. Given that no system can be
    built to exhibit 100%

    reliability, the two perspectives can be combined. In this paper, we take the
    latter perspective and

    consider that the quality of sensor data can be assessed, providing an indication
    of the overall system

    health, encompassing sensors, the wireless network and the processing tasks.

    Sensors 2017, 17, 2010; doi:10.3390/s17092010

    www.mdpi.com/journal/sensors

    Sensors 2017, 17, 2010

    2 of 23

    Assuring the quality of sensor data for a dependable operation is particularly
    challenging in

    some WSN-based monitoring applications. In fact, it is often the case that the
    sensors and the

    WSN are deployed in harsh environments and exposed to extreme physical conditions,
    thus being

    more likely affected by faults. The problem becomes critical when dependability
    is an important

    application requirement. For instance, in water-related information systems, inaccurate
    information in

    aquatic monitoring may lead to false warnings being issued or harmful situations
    not being detected

    early enough (e.g., ﬂoods or pollution events). As another example, WSNs are deployed
    in data

    centers for ﬂexible temperature monitoring and energy-efﬁcient control of air-cooling
    equipment [3,4].

    Therefore, ensuring the accuracy of collected data is also necessary for effectiveness
    reasons. In these

    examples, the operational conditions are typically hard to accurately predict,
    ensuring that the

    reliability of operations is often hard or costly, and the consequences of inaccurate
    sensor data collection

    can be severe.

    In this survey, we characterize and systematize existing solutions to dependable
    monitoring in

    WSNs by approaching them in two steps. In the ﬁrst step, we look at the root cause
    of dependability

    problems concerning the quality of sensor data, that is we identify and analyze
    several kinds of faults

    that may affect the system operation, in particular at the sensor and network
    levels, describing

    the speciﬁc effect on the sensor data and the relevant failure modes [5] that
    allow abstracting

    particular kinds of faults. When appropriate, we also refer to particular mitigation
    solutions to

    automatically adjust the sensors measurements according to each disturbance. Then,
    we provide a

    comprehensive overview of the solutions to achieve improved sensor data quality
    and dependable

    operation of WSN-based monitoring applications. In addition to detection and correction
    strategies,

    fault-tolerance strategies based on sensor data fusion procedures, exploiting
    the availability of

    redundant measurements or available modeling surrogates, are surveyed. However,
    there is a focus on

    works and solutions related to monitoring in aquatic environments, noting that
    these solutions are also

    applicable in many other contexts, but that the opposite might not be true, in
    particular concerning

    solutions that are not agnostic to the semantics of the monitored data.

    The remainder of the paper is organized as follows. Section 2 exposes a set of
    fundamental ideas

    related to the issue of data quality in WSNs, motivating the need for dependability,
    introducing the

    baseline architecture for a WSN-based monitoring system and referring to the main
    dependability

    strategies that may be employed. Section 3 describes the notion of data quality
    and the main aspects

    that may affect this quality during monitoring. Section 4 presents an overview
    of solutions for

    dependable sensor networks. We will conclude in Section 5, with a discussion of
    the possible results of

    the solutions mentioned herein.

    2. Overview of Key Issues

    2.1. Motivation

    Complex and powerful forecast systems are now able to predict environmental variables
    such as

    storm events with small errors, but they depend on a continuous ﬂow of conﬁrmation
    with real-time

    data for robustness. Real-time monitoring data, such as surface water elevation,
    ﬂow or water quality

    variables depend solely on the sensor hardware deployed in the physical environment
    (oceans, river,

    lakes, etc.) and its proper maintenance.

    The effectiveness of existing emergency warning and forecast procedures for natural
    and

    man-made hazardous events may be limited by several factors, including an often
    sparse and unreliable

    real-time observational network, the use of coarse-resolution prediction models
    and the reliance on

    traditional approaches to convey warning and forecast information.

    In spite of the vast research on the dependability of distributed systems, in
    particular on

    computational architectures/frameworks for reliable and timely operations, monitoring
    systems

    pose new challenges to dependability. The sensory and sensor network technologies,
    which are now

    becoming widely available, are subject to diverse hazards and are not sufﬁciently
    reliable and robust

    Sensors 2017, 17, 2010

    3 of 23

    against harsh exogenous and/or environmental factors. In this ﬁeld, there is still
    a lack of architectural,

    fault-tolerant and system management solutions, which are essential for dependable,
    robust remote

    monitoring, necessary for adequate water management.

    Ensuring the quality of monitoring data is fundamental to avoid false alarms or
    ignoring relevant

    data. However, because these sensors are located in the physical environment,
    they are constantly

    being subjected to factors that directly interfere with the data quality, such
    as potentially strong

    currents, debris accumulation and tough weather conditions. Consequently, there
    is a trust issue

    related to the collected data, which demands an extensive human intervention in
    terms of time and

    knowledge specialization, data validation tasks and periodic maintenance of sensors.
    To deal with this

    problem, it is necessary to continuously and automatically characterize the quality
    of collected data.

    Hence, the application of techniques based in the existence of redundancy at the
    data collection and

    data processing levels is a promising approach.

    2.2. Monitoring and Data Processing

    The process of environment monitoring requires sensor devices to be deployed within
    the system.

    These sensors will be the entities responsible for measuring the parameters of
    interest, like temperature,

    water level or salinity. A sensor essentially converts a physical quantity in
    its input to an electrical

    signal, produced as the output, which is usually proportional to the input. Further
    to the sensor itself,

    additional components are needed to perform signal processing functions, store
    measured values

    and communicate these values to other systems. It is hence usual to refer to these
    more complex

    components as smart sensors or intelligent sensors [6], typically interconnected
    to other smart sensors

    to form wireless sensor networks.

    For monitoring and control purposes, wireless sensor networks have become a subject
    of interest

    in recent years, mostly due to enormous advances in sensing and communication
    technology, which

    has fostered the use of smart sensors, with applications in many ﬁelds: (a) military
    applications;

    (b) environmental monitoring; (c) commerce; (d) human-centric applications; and
    (e) applications to

    robotics (Arampatzis et al. [7]). WSNs are formed by smart sensor nodes, and each
    sensor node may

    have several individual sensors, in which case they are said to be clustered.
    Information collected by

    sensor nodes is typically transmitted to a sink or controller node.

    After the sensors measurement step, performed usually through a WSN, there is
    another layer

    in the overall system that comprises the gathering and analysis of the measurements,
    including

    information fusion (Section 4). This phase is commonly referred to as data processing
    (see Figure 1).

    Our goal is to describe and enumerate the processes involved in each layer of
    the scheme in

    Figure 1. In a bottom-up perspective, the ﬁrst layer is the physical environment
    (it can also be deﬁned

    as the object or the event to be monitored), which can have a great inﬂuence on
    the measurements.

    Although there are many speciﬁc external factors related to perturbation events
    or objects in all of the

    different applications of WSNs, we decided to tackle the problems of the involved
    water body by ﬁrst

    enumerating well-known limitations of sensor devices in Section 3.2.

    On the second layer, we are considering that in terms of faults and validity issues,
    monitoring

    has two abstraction levels: the sensors and communication between them. Each level
    has a particular

    fault model, with faults arising from different sources (see Figure 2). We will
    explore these subjects in

    Sections 3.2 and 3.3 with the respective mitigation solutions.

    Finally, in order to centrally analyze all of the sensing information, a third
    layer appears in the

    system. In the data processing layer, it is possible to infer the quality of the
    gathered information,

    through fusion processes of redundant and related measurements, by multi-sensor
    fusion methods,

    or by expert-knowledge of the system model. In fact, this is where we can ultimately
    handle both

    sensor and network-level problems and apply the mitigation techniques identiﬁed
    already in Figure 2.

    These techniques will be addressed in Section 4.

    Sensors 2017, 17, 2010

    4 of 23

    No Faults

    Validity Model

    Fusion Output

    Quality Factor

    WSN

    Network

    Sensors

    Communication Faults

    Sensor Faults

    Fault Model

    Fault Model

    Validity Model

    Figure 1. Generic view of the WSN-based monitoring system.

    Sensor level

    Network level

    - sensor node crashes

    - message omissions

    - message delays

    - message corruption

    - auto-calibration

    - micro-processing

    - compensation

    - node redundancy

    - message retransmission

    - value estimation

    - integrity verification

    - random errors

    - calibration errors

    - loading errors

    - environmental errors

    - spurious readings

    Impairments

    Mitigation

    Figure 2. Sensor and WSN faults and mitigation solutions.

    2.3. Dependability Strategies

    When designing a fault-tolerant and dependable system, the typical means to deal
    with system

    errors and faults include error detection and error or fault recovery. In this
    context, endowing the

    system with redundant components can be instrumental to compensate existing errors
    or faults

    affecting some component.

    The affected component can be replaced in its tasks by the spare,

    redundancy component, which will ensure that the system function will continue
    to be provided.

    However, redundancy does not refer solely to having multiple similar components,
    which is a form of

    space redundancy. It is also possible to implement forms of redundancy in the
    time (e.g., repeating

    some action multiple times) and in the value domains (e.g., adding extra information)
    [8].

    Some examples of space redundancy include storing information in several disks,
    machines

    or data centers, having multiple nodes performing the same computation (either
    in parallel, called

    active replication, or with some nodes in stand-by mode, called passive replication),
    or sending a

    network message through multiple network paths. Time redundancy is typically explored
    in reliable

    Sensors 2017, 17, 2010

    5 of 23

    communication systems that retransmit messages when they suspect that these messages
    might have

    been lost in previous transmissions. Restarting an aborted transaction or a deadlocked
    computation

    are also examples of time redundancy. Finally, value redundancy is observed in
    data storage and

    communication systems that use error correcting codes associated with the stored
    or transmitted data,

    allowing the original information to be reconstructed when some bits or parts
    of the information

    become corrupted. To deal with malicious forms of information corruption, cryptographic
    signatures

    may be used.

    In the application of these concepts to sensor validation, [9] stated that there
    are two

    classical approaches that are widely used: (a) analytical redundancy and (b) hardware
    redundancy.

    Analytical redundancy uses mathematical relationships between measurements to
    predict or infer a

    sensor’s value. Two disadvantages of this approach are the possible inefﬁciency
    of the mathematical

    processes when we have a large number of sensors and the model complexity increases
    and the fact

    that the mathematical relationships can be very data speciﬁc, and a slight modiﬁcation
    may require

    signiﬁcant efforts to stabilize. Hardware redundancy is not always possible because
    of the costs

    implied by additional sensors and their installation and maintenance operations.

    The right approach to be used depends on several issues, like the assumed fault
    model, the

    criticality of the application, the cost or timeliness requirements. In some cases,
    several dependability

    techniques can be used in a single system to deal with different problems or to
    achieve the needed

    levels of assurance. This is particularly true in complex systems, like aquatic
    systems, in which

    different techniques can be applicable to mitigate faults in the sensing process
    and to handle WSN

    faults. Combinations of the solutions mentioned later in this survey (Section
    4.1) may thus be used in

    the design of a single system.

    3. Sensor Data Quality

    When the quality of sensor data is an important attribute for the dependability
    of the application,

    it becomes necessary to somehow express this quality, which can be done in various
    ways. Additionally,

    a priori knowledge about the possible causes of quality degradation, translated
    into faults and a

    corresponding fault model, is also relevant. It will enable a more accurate characterization
    of the quality

    of sensor data and the possibly of incorporating in the system some techniques
    to mitigate the effects

    of speciﬁc faults assumed in the fault model. These aspects are addressed in the
    following sections.

    3.1. Expressing Data Quality

    The interpretation and modeling of the available information into adequate theoretical

    frameworks is the main means to characterize the quality of the obtained sensor
    data. These qualitative

    interpretations of sensor data can become confusing when different authors introduce
    an array of

    terms for quality (the most generic), including:

    •

    Validity is typically employed when a determined requirement about the quality
    of data is

    available, against which it is possible to compare some quality measure and declare
    if the data

    are valid [1,10].

    •

    Conﬁdence is an attribute that may be elaborated from the continuous observation
    of sensor data,

    without the need for a quality requirement to be available. It is generally used
    when datasets are

    available and can be characterized in a probabilistic way, along with model ﬁtting
    or threshold

    deﬁnition techniques, to yield continuous or multi-level conﬁdence measures [11].

    •

    Reliability is a typical dependability attribute [12], expressing the ability
    of a system to provide

    the correct service (or the correct data, for that matter) over a period of time.
    The term data

    reliability in sensor networks is often considered when transmissions and/or communications

    may be subject to faults like omissions or a total crash [13,14].

    •

    Trustworthiness is mostly employed in connection with security concerns, namely
    when it

    is assumed that data can be altered in a malicious way. In the context of sensor
    networks,

    Sensors 2017, 17, 2010

    6 of 23

    it characterizes the degree to which it is possible to trust that sensor data
    have not been tampered

    with and have thus the needed quality [15].

    •

    Authenticity is also used, in particular in a security context, but to express
    the degree to which it is

    possible to trust the claimed data origin [16]. This is particularly important
    when the overall quality

    of the system or application depends on the correct association of some data to
    their producer.

    This terminology does contain other terms, including other aspects of data quality
    that are

    implicit and brieﬂy approached herein, such as timeliness, precision, tunability,
    completeness, usability,

    accuracy, throughput, affordability and reusability [17]. We will also describe
    herein the diverse

    typologies of data quality and how to obtain a quality parameter, either for each
    individual sensor

    or for the global system, according to several studies. Therefore, in terms of
    applicability, we must

    differentiate single-sensor validity from multi-sensor fusion validity, when several
    sensors exist and

    sensor fusion can be applied.

    In single-sensor situations, there are models or related information that allow
    reasoning about

    an individual sensor’s data quality without requiring other sensors’ data. The
    work in [18] tried

    to identify faulty situations (see Section 3.2) such as noise and outliers in
    chlorophyll concentration

    sensors deployed in lake water, by implementing different fault detection methods:

    •

    Rule-based methods that use expert knowledge about the variables that sensors
    are measuring to

    determine thresholds or heuristics with which the sensors must comply.

    •

    Estimation methods that deﬁne a “normal” behavior by considering spatial and temporal

    correlations from sensor data. A sensor reading is matched alongside its forecasted
    value to

    assess its validity.

    •

    Learning-based methods that deﬁne models for correct and faulty sensor measurements,
    using

    collected data for building the models.

    In the example from [18], all three methods were used to assert the correctness
    (or incorrectness)

    of the collected data, thus adopting a Boolean approach to quality characterization.
    However, the

    same methods may be employed in other ways, as a means to characterize quality
    in a step-wise or

    even continuous way. For instance, and still considering a single-sensor situation,
    [11] employed fuzzy

    logic rules to obtain a qualitative sense of a sensor’s validity based on its
    own historical behavior

    represented by a conﬁdence measure.

    In a multi-sensor situation, the quality of sensor measurements is characterized
    by using

    redundant or correlated data obtained from the different sensors. This redundancy
    allows for data

    fusion methods to be deployed at the network level, resulting in improved (fused)
    sensor data, as

    well as improved data quality characterization. Various quality-oriented network
    meta-models can be

    explored according to the application requirements. For instance, in [17], the
    data quality is calculated

    through the several nodes (and the sink) on the entire WSN structure.

    Sensor data fusion methods will be detailed in Section 4. As for the quality characterization
    process

    when data fusion is performed, the applicable methodology depends on the available
    information

    concerning the quality of individual sensor measurements. In fact, this information
    can also be used in

    the data fusion process itself.

    For instance, in [11], the approach relied on a statistical method (Parzen estimation
    of the

    probability density function) to determine the variance of sensors’ data and to
    calculate the average of

    the sensors, considering just the sensors with a high-quality standard in the
    data fusion process. If all

    sensors are producing high-quality data, then the fusion will also reach the highest
    possible quality.

    Otherwise, better results will be achieved when discarding sensor data with lower
    quality, rather than

    using these data in the fusion process.

    Another example can be found in [19], where reliability estimates are calculated
    for sensor data,

    using Bayesian networks or random forests to obtain reliability coefﬁcients, and
    then, these reliability

    estimates are used in a sensor fusion process to discard sources that are considered
    unreliable if the

    reliability estimate is below a deﬁned threshold.

    Sensors 2017, 17, 2010

    7 of 23

    Regarding the quantiﬁcation of data quality, the two main approaches consist of
    considering

    discrete quality classes or continuous quality values.

    In the discrete approach, it is possible to use binary classes, such as {valid,
    invalid} [20], or to use

    a multi-level class, like {verylow, low, high, veryhigh} [11]. These discrete
    classiﬁcations can be applied

    to each sensor (individual sensor data) or to the whole network of sensors (fused
    data).

    In the continuous approach, a conﬁdence level is usually derived, ranging in a
    well-deﬁned

    continuous interval (often [0, 1] or equivalently [0%, 100%]).

    Therefore, the validity of sensor

    information may not only have the values “true and” “false”, especially if one
    must process

    continuously-valued data [1,9]. For instance, a noisy sensor (internal or external
    noise) may deliver

    useful data within some error margin, but the quality of that data is lower than
    that from a non-noisy

    sensor. In a multi-sensor fusion application, the quality quantiﬁcation can be
    calculated using a

    cumulative association of each sensor quality coefﬁcient [21] or calculating the
    percentage of sensors

    used in the fusion against the sensors in the network.

    3.2. Sensor Level Faults

    In this subsection, we present a systematization of the main types of sensors
    and their

    characteristics, classifying the various data errors that may be produced by sensors.
    From the

    perspective of building modular dependable systems, what is interesting is to
    group the several

    possible faults and the consequent data errors into well-deﬁned sensor failure
    modes. We thus identify

    the relevant failure modes under which a sensor can fail and produce data with
    degraded quality.

    The focus herein is on the sensor level, whereas the next subsection addresses
    network level faults.

    Finally, we also focus on possible mitigation techniques to handle sensor faults.

    3.2.1. Sensor Characteristics

    We begin to dissect sensor faults by exploring the transducing processes, enumerating
    the different

    methods to convert the various physical effects into electric signals, as well
    as each one’s advantages

    and limitations. This enumeration is important to the survey, to understand the
    most basic origins of

    faults in sensors. The sensor material characteristics or the harshness of the
    environmental conditions

    lead to the production of a speciﬁc kind of fault. Some sensors strive to perceive
    an object that is

    moving in dusty environments, while others experience issues reading a correct
    level observation

    in ﬂuids. For instance, capacitive sensors present a considerable sensitivity
    and require low energy

    usage, making them an attractive choice for many areas, but as pointed out by
    [22], the response

    characteristics of these sensors are very nonlinear, and the offset capacitance
    is non-negligible and

    must be handled to correctly detect capacitance variations due to the applied
    pressure and to avoid

    errors. In summary, from a dependability perspective, it is important to distinguish
    sensors in terms of

    their operation and robustness to distinct environment conditions. When a sensor
    is highly sensitive,

    but frequently faulty, a redundancy solution must be considered, possibly using
    a sensor that offers

    the same sensitivity, but is more reliable.

    The main types of sensors according to the exploitation of displacement effects
    are

    the following [23]:

    •

    Resistance: Resistive sensors, also termed potentiometers, are based on an electromechanical

    instrument that transforms a mechanical variation, like a displacement, into an
    electrical signal

    capable of being monitored following conditioning;

    •

    Induction: Inductive sensors are primarily based on the principles of magnetic
    circuits and may

    be categorized as self-generating or passive;

    •

    Capacitance: Capacitive sensors depend on variations in capacitance in reply to
    physical changes.

    A capacitive level pointer uses the changes in the comparative permittivity among
    the plates;

    •

    Piezoelectricity: Piezoelectricity is the term used to determine the capacity
    of speciﬁc materials to

    create an electric charge that is relative to a directly applied mechanical pressure;

    Sensors 2017, 17, 2010

    8 of 23

    •

    Laser: Laser sensors compare changes in optical path length and in the wavelength
    of light, which

    can be determined with very little uncertainty. Laser sensors achieve a high precision
    in the

    length and displacement measurements, where the precision achieved by mechanical
    means is

    not enough;

    •

    Ultrasonic: Uses the time-of-ﬂight method as the standard for the use of ultrasound
    for monitoring

    purposes. A pulse of ultrasound is transmitted in a medium, reﬂecting when it
    reaches another

    medium, and the time from emission to recognition of the reﬂected pulsation is
    read;

    •

    Optical: Optical sensors encompass a variety of parts that use light as the means
    to convert

    kinetics into electrical signals, comprised mostly of two components: a main diffraction
    grating,

    representing the measurement standard (scale); and a detection system. What is
    detected is the

    position of one regarding the other;

    •

    Magnetic: A magnetic sensor is either triggered to function by a magnetic ﬁeld
    or the use of the

    ﬁeld that deﬁnes the properties of the sensor;

    In Table 1, a summary of the relative advantages and disadvantages of each of
    the described

    displacement effects is presented. The goal here is not to choose the best type
    of sensor, but to

    discriminate the strong and weak points of all of the types.

    Table 1. Advantages and disadvantages of the various displacement effects [23–25].

    Displacement Effects

    Advantages

    Disadvantages

    Resistance

    Versatile; inexpensive; easy-to-use; precise.

    Limited bandwidth; limited durability.

    Induction

    Robust; compact; not easily affected by

    external factors.

    A signiﬁcant part of the measurement is

    external, which must be well cleaned and

    calibrated.

    Capacitance

    Low-power consumption; non-contacting;

    resists shocks and intense vibrations;

    tolerant to high temperatures; high

    sensitivity over a wide temperature range.

    Short sensing distance; humidity in

    coastal/water climates can affect sensing

    output; not at all selective for its target;

    non-linearity problems.

    Piezoelectricity

    Ideal for use in low-noise measurement

    systems; high sensitivity; low cost; broad

    frequency range; exceptional linearity;

    excellent repeatability; small size.

    Cannot be used for static measurements;

    high temperatures cause a drop in internal

    resistance and sensitivity (characteristics

    vary with temperature).

    Laser

    Ideal for near real-time applications; low

    uncertainty and high precision in the

    measurements.

    Weather and visual paths affect the sensor

    when measuring distance or related

    variables.

    Ultrasonic

    Independent of the surface color or optical

    reﬂectivity of the sensing object; excellent

    repeatability and sensing accuracy;

    response is linear with distance.

    Requires a hard ﬂat surface; not immune to

    loud noise; slow measurements in

    proximity sensors; changes in the

    environment affect the response; targets

    with low density may absorb sound energy;

    minimum sensing distance required.

    Optical encoding

    Inherently digital (which makes the

    interface easy for control systems); fast

    measurements; long durability.

    Fairly complex; delicate parts; low

    tolerance to mechanical abuse; low

    tolerance to high temperatures.

    Magnetic

    Non-contacting; high durability; high

    sensitivity; small size; output is highly

    linear.

    Very sensitive to fabrication tolerances;

    calibration needed after installation.

    Beyond the limitations of the transducers, [26] explained other causes of measurement
    uncertainty

    and how only an estimation of the observed physical property can be given. When
    considering

    individual sensor measurements, the possible types of errors observed in measurement
    values can be

    classiﬁed as follows:

    •

    Random errors are described by an absence of repeatability in the readings of
    the sensor, for

    instance due to measurement noise. These errors tend to happen on a permanent
    basis, but have a

    stochastic nature;

    Sensors 2017, 17, 2010

    9 of 23

    •

    Systematic errors are described through consistency and repeatability in the temporal
    domain.

    There are three types of systematic errors at the sensor level:

    –

    Calibration errors result from errors in the calibration procedure, often in relation
    to

    linearization procedures;

    –

    Loading errors emerge when the intrusive nature of the sensor modiﬁes the measurand.

    Along with calibration errors, loading errors are caused by internal processes;

    –

    Environmental errors emerge when the sensor experiences the surrounding environment

    and these inﬂuences are not considered. In contrast with the previous two types
    of errors,

    environmental errors are due to external factors;

    •

    Spurious readings are non-systematic reading errors. They occur when some spurious
    physical

    occurrence leads to a measurement value that does not reﬂect the intended reality.
    For instance, a

    light intensity measurement in a room can provide the wrong value if obtained
    precisely when a

    picture of the room is taken and the camera ﬂash is triggered.

    3.2.2. Sensor Failure Modes

    The classiﬁcation presented above builds essentially on the persistence and nature
    of the

    observable value errors. An alternative way to acknowledge and to deal with the
    fact that sensor

    measurements are affected by uncertainties, which is commonly used when building
    modular

    distributed systems, is to identify relevant sensor failure modes. Independently
    of the several factors

    leading to a sensor fault and the consequent measurement error(s), the faulty
    behavior of the sensor

    component is observed through its interface, that is, through the values it produces.
    Therefore, a

    failure mode characterizes a certain deviating behavior, abstracting its causes
    and considering only the

    measurement values produced at the sensor interface.

    The main sensor failures modes, depicted in Figure 3, are the following [1]:

    1.

    Constant or offset failure mode: The observations continuously deviate from the
    expected value

    by a constant offset.

    2.

    Continuous varying or drifting failure mode: The deviation between the observations
    and the

    expected value is continuously changing according to some continuous time-dependent
    function

    (linear or non-linear).

    3.

    Crash or jammed failure mode: The sensor stops providing any readings on its interface
    or gets

    jammed and stuck in some incorrect value.

    4.

    Trimming failure mode: The observations are correct for values within some interval,
    but are

    modiﬁed for values outside that interval. Beyond the interval, the observation
    can be trimmed at

    the interval boundary or may vary proportionally with the expected value.

    5.

    Outliers failure mode: The observations occasionally deviate from the expected
    value, at random

    points in the time domain;

    6.

    Noise failure mode: The observations deviate from the expected value stochastically
    in the value

    domain and permanently in the temporal domain.

    (2)

    (3)

    (1)

    (4)

    (5)

    (6)

    Figure 3. Sensors’ failure modes. The faulty sensor output is represented with
    a ﬁlled line, whereas the

    real values are depicted with a dashed line.

    Sensors 2017, 17, 2010

    10 of 23

    Comparing this classiﬁcation of sensor failure modes with the classiﬁcation of
    sensor errors

    previously introduced, it is interesting to note the direct correspondence between
    the class of random

    errors and the noise failure mode and between the class of spurious errors and
    the outliers failure

    mode. The remaining four failure modes can be seen as specializations of the systematic
    errors class.

    3.2.3. Mitigation Techniques

    Regarding mitigation techniques to address faults and respective value errors,
    we make a

    separation between what can be done at the sensor level and what can be done at
    the distributed

    system level, namely within the application that uses the sensor data, possibly
    exploiting additional

    sources of information. Considering an individual sensor, it is possible to use
    dependability techniques

    to prevent or tolerate the occurrence of faults and achieve an improved behavior,
    possibly even

    removing some failure modes. This can be described as a “basic quality improvement”,
    and in

    what follows, we describe two basic techniques that are usually carried out to
    achieve this objective:

    calibration and measurand reconstruction. The general approaches for improving
    the quality of data

    in WSN monitoring applications are then covered in Section 4.

    Commonly, calibration is deﬁned as a test under speciﬁc conditions in which pre-determined

    known values of the measurand are given to the transducer and the corresponding
    outputs are

    recorded. In a formal way, calibration consists of deﬁning a function f (r, β)
    that, along with a set of

    selected device parameters β ∈ R, will translate real sensor output r to the intended
    output r*.

    Calibration actions are required every time a sensor is deployed in a different
    environment, as

    the physical measurement elements must be adjusted or even dedicated to the monitored
    device or

    process, providing at the start a reduction of measuring uncertainty and minimal
    interference with

    sensor functions. However, periodic calibrations are also needed, since during
    the operation, we can

    assist the change of conditions with respect to those known during the calibration
    process and to

    the impact of various external factors that could be absent in the laboratory
    calibration conditions.

    These factors can be the base cause of many errors and should hence be continuously
    re-evaluated.

    For instance, in aquatic sensors, offset and drifting errors are related to the
    accuracy range becoming

    unbalanced, which is solvable by recalibration. This is done off-ﬁeld (removing
    the sensor of the

    monitoring environment and recalibrating it in a container with water in controlled
    conditions), with

    potential data loss if no redundant way of collecting sensor data is available,
    and with re-deployment

    costs. It can also be done in the ﬁeld, which is a time-consuming task with sometimes
    difﬁcult

    conditions and, especially, exposing the calibration process to environmental
    factors that may affect the

    calibration accuracy.

    As alternatives to manual calibration, two generic options can be considered:
    factory sensor

    calibration, with the advantage of reducing the time consumption efforts of the
    initial manual process,

    but not completely eliminating the problems mentioned before; and auto or self-calibration,
    enabling

    sensors to monitor themselves and recalibrate using a reference. This latter option,
    which, being

    adaptive, is potentially better for dealing with varied and even unpredicted misbehavior,
    is designated

    as measurand reconstruction or sensor compensation.

    Auto-calibration refers to methods aimed at diminishing the effect of the disturbing
    parameters in

    the input/output features of sensors. Preferably, the transduced value must have
    a direct relation with

    the measurand, which should not be sensible to past information, interfering environmental
    factors,

    noise, error gain, etc. To try to compensate all of these disturbances, numerical
    techniques have to be

    used. These techniques are applied after the transformed signal has been quantiﬁed,
    through digital

    signal processing that must transform the sensor output signal (r*) into a corrected
    value ( ˆr*).

    Several auto-calibration techniques have been used with relative success, for
    instance exploiting

    statistical regression based on a priori knowledge [27] or artiﬁcial neural networks
    [28,29]. In the

    statistical regression approach, the goal is to determine the polynomial approximation
    to the

    characteristics of the sensor. In the artiﬁcial neural networks (ANN) approach,
    the inputs are the

    measurements, and the ideal outputs are the measurand. This model inversion is
    the reason why it is

    Sensors 2017, 17, 2010

    11 of 23

    called measurand reconstruction. Other machine-learning algorithms have also been
    applied, such

    as Kalman ﬁlters [30] and support vector machines [31], especially in order to
    overcome the ANN

    disadvantages: neural network training may not converge to the global optimum,
    and training may

    need to be repeated several times, which will be prejudicial with respect to the
    computational cost; and

    the poor generalization capabilities that may arise from insufﬁcient data, from
    over- or under-training

    or from under- or over-ﬁtting.

    3.3. Communication Faults in WSNs

    When connecting individual sensor nodes in a wireless sensor network, additional
    faults affecting

    sensor data can be introduced by the network. In this subsection, we focus on
    the main kinds of

    network faults that may affect the quality of sensor data in order to achieve
    a reliable network operation,

    speciﬁcally considering faults in the time domain and faults in the value domain.

    In the time domain, a crash, omission or delay faults could occur. Crash faults
    (for instance of the

    radio subsystem in a sensor node) lead to data absence and can only be mitigated
    with redundancy (e.g.,

    a dual-radio system). Omissions correspond to missing sensor readings due to lost
    messages. They can

    be prevented by enforcing communication reliability, for instance based on message
    retransmission.

    However, reliable communication protocols are not very common in WSNs due to the
    additional

    resources (namely energy) they require. Therefore, omissions do happen in sensor
    networks and for

    the most part emerge because of sensor failures and packet losses. Heavy packet
    loss and asymmetric

    links occur frequently in WSNs [32,33], for instance due to signal strength fading
    and intermittent or

    continuous environmental interference (e.g., wind or rain). Absent values inﬂuence
    the outcome of

    any query over sensor readings. The resulting inaccuracies can be critical as
    in in-network processing

    and aggregations [33–35]. Several solutions have been suggested to tolerate these
    types of errors such

    as masking lost values through redundant information or estimating using past
    values [34]. Although

    this problem has been studied and solved in many applications, one must be aware
    that it is impossible

    to fully avoid omissions. Finally, delay faults are only relevant when the correctness
    of the application

    depends on the timeliness of sensor data. This is typically the case in real-time
    control, where the

    temporal validity of sensor data is bounded [36]. Sensor data become useless after
    a certain amount of

    time due to not reﬂecting the present reality with sufﬁcient accuracy, possibly
    leading to system failures

    if used in the control process. Existing solutions to avoid timing failures are
    based on techniques from

    the real-time area, namely seizing the needed resources and using synchronized
    clocks to timestamp

    data and discard the outdated data. The existence of redundant sensor nodes can
    also be explored, to

    avoid missing important events.

    In the value domain, a communication fault is translated into a message corruption.

    However, communication protocols typically incorporate data integrity veriﬁcation
    mechanisms

    that allow the detection of corrupted messages, discarding those messages and
    hence transforming

    value faults into omission faults. Therefore, the only chance that received data
    do not correspond to

    what has been sent is when some part of the communication stack in the sending
    or receiving node

    (or both) is affected by an accidental fault not covered by the integrity veriﬁcation
    mechanisms or

    when it has been intentionally corrupted. In fact, WSNs and sensor nodes can be
    subject to attacks

    that may signiﬁcantly affect the quality of sensor data, among other consequences
    for the application.

    Therefore, in critical applications, it is important to deploy security techniques
    to avoid attacks or to

    mitigate their effects. These security techniques are, however, outside the scope
    of this survey.

    4. Solutions for Dependable Data Quality

    Several methods have been proposed in the literature to improve the quality of
    sensor data.

    Our focus is on solutions to mitigate the negative effects of faults on data quality.
    The ones that are

    applicable at the sensor level to mitigate data errors at the sensor interface
    have already been addressed

    in Section 3.2. In this section, we discuss what can be done at sink or processing
    nodes. We start

    by identifying and characterizing the three different forms of redundancy that
    may be explored for

    Sensors 2017, 17, 2010

    12 of 23

    dependable data quality. They are related to the available sources of information,
    to which data

    analysis and processing techniques can be applied: (a) single sensor data stream,
    (b) multi-sensor data

    streams or (c) multi-source data streams.

    Then,

    and given our focus on dependability aspects,

    we present a taxonomy for

    dependability-oriented data quality in WSNs. We identify the relevant dimensions
    to reason about

    dependable data quality, classifying the options within each of these dimensions.
    In this exercise,

    we introduce dependability-related categories concurring with the goal of estimating
    the quality of

    sensor data. In most cases, WSN-based monitoring systems address concerns (sometimes
    implicitly) of

    improving the quality of data, but not of estimating the achieved quality. The
    resulting systematization

    underlies the survey on concrete techniques for data processing, further ahead
    in the section.

    4.1. Exploiting Redundancy

    Redundancy is a fundamental dependability technique to achieve reliability, availability
    and even

    improved performance. Therefore, WSN applications naturally exploit the existence
    of multiple sensor

    nodes and the spatial redundancy they offer. In fact, if information relative
    to a certain environmental

    process is collected through several sensors, then it is possible to apply a range
    of data processing

    techniques to fuse the multiple data streams (from the different sensor nodes).
    This approach permits

    obtaining the resulting data with more quality, masking possible faults affecting
    data provided by

    some of the nodes. In sensor networks, it is also possible to exploit value redundancy
    [8] for improving

    the quality of data. This redundancy is offered, for instance, by environmental
    models describing the

    monitored dynamic process or setting limits to the static or dynamic attributes
    of this process. Finally,

    if sensor data from multiple sensor nodes cannot be correlated, then it is still
    possible to exploit a form

    of temporal redundancy. This temporal redundancy is intrinsic to continuous transmission,
    in a single

    ﬂow, of data samples that can be correlated over time.

    4.1.1. Spatial Redundancy

    The techniques aimed at exploiting spatial redundancy in WSN-based applications
    are known as

    sensor fusion techniques. Sensor fusion deals with sensor data from sensors in
    the same monitoring

    area. Through processes of comparison, combination and/or smart voting schemes,
    it may be

    possible to detect faulty behaviors, erroneous information and derive a corrected
    observation from the

    remaining (considered correct) data samples [37–39].

    Sensor fusion is realized by employing a collection of techniques, such as classical
    Bayesian,

    Dempster–Shafer inference, artiﬁcial neural networks and fuzzy logic. The less
    mature techniques

    are dominated by heuristic and ad hoc methods. The major algorithm categories
    and techniques are

    discussed in Sections 4.2.1 and 4.2.2.

    Sensor fusion is very useful in several situations, in particular in the following:
    (a) when some

    sensors measure correctly the intended phenomena, but others do not, due to failures;
    (b) when all

    sensors measure correctly, but some respond to a different phenomenology; (c)
    when the data of a

    sensor may be masked or counter measured with respect to one sensor, but not to
    another; (d) when

    one sensor may be blocked or unable to measure, but another sensor located elsewhere
    may have the

    correct data. In this case, the data from the sensor with the correct view may
    be combined with past

    information from the blocked sensor to update the overall measurements.

    The work in Reference [40] categorizes multi-sensor data fusion systems regarding
    what is

    observed by several sensors. Data fusion can take place:

    1.

    across sensors when several sensors observe the same variable; for instance, when
    the temperature

    of a particular object is monitored by a set of temperature sensors;

    2.

    across attributes when sensors observe several quantities related with one event;
    for instance,

    when measurements of water temperature and water conductivity are combined to
    deﬁne the

    water salinity;

    Sensors 2017, 17, 2010

    13 of 23

    3.

    across domains when sensors observe one speciﬁc attribute in several places. An
    example

    is when sensors in different places measure the temperature and the measured values
    are

    somehow correlated.

    4.

    across time when new readings are fused with past data. For example, historical
    information from

    a former calibration can be incorporated to make adjustments on current measurements.
    Note

    that this is a particular case that applies to systems with single sensors, which
    we speciﬁcally

    discuss later as a form of temporal redundancy.

    The work in Reference [41] provides a slightly different classiﬁcation of a multi-sensor
    data fusion

    system, which partially overlaps with the previous classiﬁcation. They consider
    that sensor fusion

    can be:

    1.

    competitive when every sensor conveys an autonomous reading of the same variable.
    The purpose

    of this type of fusion is to diminish the effects of uncertain and incorrect monitoring.

    Competitive fusion corresponds to sensor fusion across sensors, in the terminology
    of [40];

    2.

    cooperative when the data measured by many autonomous sensors is utilized to infer
    information

    that would not be accessible through each of the sensors. This corresponds to
    sensor fusion

    across attributes;

    3.

    complementary when sensors are not directly dependent, but might be merged with
    the

    speciﬁc goal of providing a more comprehensive view of what the network is trying
    to observe.

    Thus, complementary fusion can assist in solving the incompleteness problem. This
    category

    does not entirely match the categories by [40]; it is closer to sensor fusion
    across attributes, but

    the idea is not to extract information, but to complement it.

    From the above, it is clear that data fusion can take place in many ways and for
    different purposes,

    some of which are not speciﬁcally concerned with dependability issues, but rather
    functional issues.

    This is the case of cooperative sensor fusion, whose the objective is to derive
    new information rather

    than correcting the existing information.

    Unfortunately, sensor fusion is not always possible. For instance, when considering
    monitoring

    activities over a wide physical area, it may be better or even necessary (namely
    for cost-effectiveness

    reasons) to scatter the sensors in pre-identiﬁed points according to area dynamics
    expertise and local

    knowledge, to cover the most signiﬁcant events. For instance, this is often the
    case when monitoring

    water bodies [42], because of their typically large extension and the involved
    complex water dynamics,

    requiring expert knowledge when determining the deployment locations scattered
    to cover the highly

    variable environmental dynamics. Moreover, water monitoring usually requires costly
    sensors [43],

    which makes it infeasible to have more than one in a conﬁned area. Exploiting
    sensor fusion in these

    conditions is thus very hard or even impossible.

    Even when sensor fusion can be opted as an alternative for achieving increased
    dependability,

    there are a number of technical problems that may have to be addressed. For example,
    when monitoring

    environmental processes with fast dynamics, it may be necessary that all measurements
    are obtained

    at roughly the same time [37] so that they can be correlated. However, timing
    aspects are hard to

    deal with in distributed settings, and issues like network delays or incorrect
    clock synchronization of

    sensor nodes, if not accounted for during system design, can lead to incorrect
    data being produced

    by sensor fusion algorithms. Given the real-time nature of sensor data, there
    is a temporal validity

    interval during which the difference between the measured data value and the real
    value is acceptable

    for the application. After this temporal validity interval, data become outdated
    and must be discarded.

    Therefore, data should be timestamped as soon as they are collected, and the temporal
    validity interval

    must be known at design time. This will allow setting up mechanisms to discard
    outdated data.

    The clocks of the different nodes in the system must be synchronized and the precision
    (the maximum

    difference between all of the clocks) must also be known and taken into account
    when deciding

    whether some sensor data are already outdated. Dependable sensor fusion thus requires
    additional

    design efforts, to adapt the solution to the speciﬁc application characteristics
    and requirements.

    Sensors 2017, 17, 2010

    14 of 23

    4.1.2. Value Redundancy

    While sensor fusion relies on the physical (space) redundancy provided by the
    existence of several

    sensors, it is possible to consider data fusion [44,45] as an alternative approach.
    It does not require

    physically redundant sensor nodes, but relies on the value redundancy provided
    by extra information,

    obtained by other means. The notions of sensor fusion and (multi-sensor) data
    fusion are often used

    interchangeably. In fact, data fusion can be considered a generalization of sensor
    fusion, when data

    fusion is applied to multi-sensor data. Data fusion, in general, is related to
    the fusion of data, no matter

    its source, whereas sensor fusion (or multi-sensor data fusion) describes the
    use of more than one

    sensor in a multi-sensor system to enhance the accuracy of measured data or to
    handle missing data.

    The process of data fusion deals with the identiﬁcation, association, correlation,
    estimation and

    combination of spatially- and temporally-indexed data or information from numerous
    inputs with

    the speciﬁc goal of enhancing the analysis and understanding of this information.
    The techniques

    employed for data fusion are essentially the ones referred to for sensor fusion,
    which are discussed

    below. However, from a dependability perspective, it is important to note that
    data fusion opens new

    perspectives (in comparison to sensor fusion) regarding exploitable redundancy.
    We refer, in particular,

    to two forms of value redundancy that are exploitable with data fusion:

    •

    Signal analysis or analytical redundancy: This is used to monitor parameters such
    as frequency

    response, signal noise and amplitude change velocity among others [46]. It is
    a robust approach in

    the case of strange behavior in a controlled system. If there is a strong variability
    of a variable, then

    a sensor is categorized as faulty (or the system under monitoring has been altered).
    This necessarily

    requires some bounds to be established a priori, against which the parameters
    can be fused to

    perform the intended classiﬁcation.

    •

    Model-based redundancy: With the help of simulation/mathematical models of the
    monitored

    system, it is possible to obtain values to validate the measurements. The author
    in Reference [47]

    was a big promoter of this type of redundancy, where the system model calculates
    the measured

    variable, and then it, is compared to the sensor measurement.

    One potential difﬁculty in applying model-based redundancy is deﬁning relevant
    and accurate

    models. The problem becomes even more difﬁcult when these models characterize
    physical

    processes that change over time, which is often the case when monitoring environmental
    systems.

    Forecasting modeling techniques include simulation, estimation and syntactic methods
    [48]. Simulation

    is used when the physical characteristics to be measured can be accurately and
    predictably modeled.

    These models can be used in all types of scenarios, but most studies present examples
    based on

    terrestrial (indoor) applications [49], whereas the theme of the work herein concentrates
    on the

    complexity of the aquatic environment (e.g., water circulation). It is for this
    exact reason that current

    aquatic systems do not support real-time model-based data fusion [50]. Ideally,
    at run-time, a

    forecasting model represents a reference to validate the sensing data, which can
    also be applied

    for optimization and planning [51].

    4.1.3. Temporal Redundancy

    In WSN applications, sensor nodes continuously send new measurements of the monitored

    network, typically in a periodic way, to satisfy the temporal accuracy requirements
    of the application.

    The sequential measurements arriving at the sink or processing node constitute
    a time series

    to which data processing techniques can be applied with dependability objectives.
    In other words,

    if past measurements are considered historical data, then sensor fusion techniques
    can be applied to

    fuse the historical data with the current measurement. For instance, it is usual
    that noise reduction

    techniques are applied to single data streams, as a preliminary data enhancement
    step before any

    other data processing algorithms are applied. Outlier detection techniques [52]
    are also commonly

    applied to single data streams, detecting a faulty measurement when it deviates
    too much from the

    recent measurement history. Given the deviations caused by intrinsic noise and
    complex failure modes

    Sensors 2017, 17, 2010

    15 of 23

    affecting the transducing process [53], choosing the adequate margins to achieve
    accurate outlier

    detection is usually a difﬁcult problem. One approach to this problem is to use
    detection patterns

    rather than thresholds, applied to the incoming data stream. This approach allows
    detecting other

    phenomena, in addition to or instead of outliers [54]. Interestingly, outlier
    detection is a problem

    common to several areas including network intrusion, fraud detection, performance
    assessment and

    weather forecasting, among others [55].

    The identiﬁcation of outliers contributes to improving the data fusion processes
    and hence the

    quality of the resulting data. If performed by intermediate nodes, it may also
    contribute to enhancing

    the network performance by preventing the transmission of messages containing
    outliers (thus

    transforming outlier faults into omission faults, possibly a good strategy in
    systems with redundant

    information sources).

    We note that temporal redundancy and value redundancy strategies, as described
    here, can be

    combined with spatial redundancy in a single system.

    4.2. A Taxonomy for Dependability-Oriented Data Quality in WSNs

    To help the reader understanding the main dimensions, aspects and techniques that
    are related to

    the problem of achieving data quality and dependability in WSNs, we provide in
    Figure 4 a schema

    with a tree-like organization of the relevant taxonomy. Note that the redundancy
    approaches presented

    earlier serve as a base for the application of the techniques described ahead.

    Dependability-oriented

    data Quality in WSNs

    Goals

    Functions

    Techniques

    Quality estimation

    Quality improvement

    System state oriented

    System data oriented

    Unsupervised

    Supervised

    Fault detection

    Offset

    Drift

    Crash

    Trimm

    Outlier

    Noise

    Calibration

    Filtering

    Correction

    Reconstruction

    Statistical analysis

    Clustering

    PCA

    Inference

    Behavioural

    Bayesian inference

    Fuzzy logic

    Dempster-Shafer theory

    Artificial neural networks

    Rule-based/Decision-tree

    Random set theory

    Event algebra

    Kalman filtering

    Voting

    Figure 4. Schema of the categories of solutions for dependable WSNs.

    We consider three main dimensions that are relevant when addressing the problem
    of data quality

    and dependability improvement: goals to be achieved, functions to be performed
    and techniques to

    be applied.

    We identify two distinct goals. The ﬁrst consists of improving the quality of
    data, which is the

    most common in WSN applications that aim at satisfying non-functional requirements
    (often not

    explicitly speciﬁed), like reliable or safe operation. The second goal is less
    common. It consists of

    estimating the quality of data to enable assessing if non-functional requirements
    are satisﬁed. Although

    it may not be easy to explicitly deﬁne these requirements, the advantage is that
    it becomes possible to

    deﬁne mechanisms to mitigate the negative effects of deviations from the speciﬁcation.
    For instance,

    users can be notiﬁed that the application is not working properly, or the application
    may be stopped in

    a fail-safe state instead of performing some unsafe operation.

    Sensors 2017, 17, 2010

    16 of 23

    To meet these goals, it is necessary to execute speciﬁc functions, which we classify
    into two

    categories: state oriented and data oriented. State-oriented functions are meant
    to evaluate the health

    of system components, in particular sensors (or sensor nodes), on the assumption
    that this health is

    affected by faults. Several fault detection functions are thus considered, to
    deal with the different

    failure modes identiﬁed in Section 3.2. These functions are important to both
    improve and estimate

    the quality of data, respectively by providing information that allows differentiating
    good and bad

    information sources in sensor fusion processes and by allowing distinguishing
    the quality of results

    obtained with source components in different health conditions. Data-oriented
    functions include all

    those that are meant to process sensor data, namely (but not exclusively) to calibrate,
    ﬁlter, correct or

    reconstruct data that are affected by faults. Calibration performs an automatic
    adjustment of values,

    for instance to compensate the effect of an offset. Filtering can be used to remove
    outliers or noise

    effects. Correction allows modifying values, for instance when it is know that
    they are drifting from

    the real values or that they are trimmed. Reconstruction is helpful for instance
    when a value is missing

    or when it is removed due to being an outlier and a replacement value needs to
    be produced. All of

    these functions are meant to improve the quality of data, rather than estimating
    this quality. They can

    be combined with each other and also with state-oriented functions, for better
    results concerning data

    quality improvement.

    There is a vast range of techniques and speciﬁc algorithms that may be employed
    to process sensor

    data and perform the mentioned functions. In this survey, we go through the main
    ones, providing

    illustrating references, and considering the two broad categories of supervised
    and unsupervised

    techniques. No matter the function to which it contributes, when a technique requires
    model training

    and training datasets, it is characterized as a supervised learning technique.
    In this category, the

    constructed and trained models are used at run-time to classify data, estimate
    new values and correct

    existing data, among other. On the other hand, unsupervised techniques are characterized
    by directly

    inferring the possible relations between data, without the need for a correcting
    model output reference.

    In the following sections, we include examples to help the reader understanding
    that for a given

    problem involving data quality issues, it may be possible to use multiple solutions
    or techniques.

    For instance, in [56] Kreibich et al. present two solutions for the evaluation
    of sensor-fusion quality in

    an industrial WSN that suffers from temporary losses of data and interferences
    in data streams, using

    fuzzy logic and Dempster–Shafer theory. Moreover, the authors mention that other
    techniques could

    be used (such as Bayesian, Kalman ﬁlter, artiﬁcial neural network or voting fusion).

    4.2.1. Supervised Techniques

    Since data fusion is a concept that exists in works dated from the 1980s until
    now, many authors

    present data fusion taxonomies for detection, classiﬁcation and identiﬁcation
    algorithms [45,57–59].

    These are low-level processing algorithms that can be applied in sensor nodes
    of a WSN. The goals

    here are to detect if an object is present, to classify the object and to identify
    it as accurately as possible.

    Within the supervised techniques, we group the major algorithm categories into
    feature-based

    inference techniques and techniques based on behavioral models, as illustrated
    in the scheme

    of Figure 4.

    Feature-based inference techniques achieve information mapping through classiﬁcation
    or

    detection. An example is the use of statistical knowledge about an object or information
    about

    its features, as a means for its identiﬁcation.

    These techniques can be further partitioned into

    several classes. In the following paragraphs, we will refer to some of the most
    frequently-used

    techniques, namely parametric such as Bayesian inference, Dempster–Shafer evidential
    theory (DST)

    and Kalman ﬁlters, and artiﬁcial neural networks (ANN), which is a well-known
    information theoretic

    technique. We note that there are many other machine learning techniques that
    may be of use,

    such as entropy-measuring techniques, pattern recognition, parametric templates,
    ﬁgures of merit,

    whose description falls out of the scope of this survey (we refer the interested
    reader, for example, to

    Reference [45], for further details on feature-based methods for information fusion
    in sensor networks).

    Sensors 2017, 17, 2010

    17 of 23

    Bayesian inference techniques use likelihood models applied to collected data
    to make deductions

    about observed quantities and even gain insights about quantities that have not
    been observed.

    Bayesian inference is used to solve the problem of efﬁcient data gathering in
    sensor networks. The work

    in Reference [60] used this approach in a temperature and pressure sensor network
    composed of

    500 nodes, to solve the problem of missing data, and to infer that missing information.
    The work in

    Reference [61] used a Bayesian-network-based approach to detect global outliers
    in an environmental

    monitoring network. Bayesian inference is a computationally-complex process, in
    which learning the

    classiﬁcation model can be challenging, if there is a large number of correlations
    in the WSN.

    The difﬁculty and uncertainty included in integrating sets of data gathered from
    numerous sources

    promoted the development of alternatives to Bayesian inference. Among them, Dempster–Shafer

    theory (DST) has turned out to be one of the more considered [62,63], for the
    most part because of the

    fundamental Dempster’s combination rule [64]. The biggest beneﬁt of this method
    is the simplicity of

    consolidating possibly contradictory evidence, independently of whether it was
    collected as direct or

    indirect data. DST adapts better to the situations than the Bayesian approach
    as no former probabilities

    must be presumed regarding the potential node behavior, and acceptance of a theory
    does not deﬁne

    rejection of the contrasting proposition, which allows handling contradictory
    indications quantitatively.

    In addition, Reference [65] studied a DST approach to evaluate sensor nodes misbehavior.

    Kalman ﬁltering is a well-known estimation-based approach to solve data quality
    problems in

    WSNs. One recent example [66] presents an algorithm to correct rough and missing
    information

    grounded on Kalman ﬁltering to surpass the issue with querying faulty information
    and to enhance

    the exactness of data in a 1000-node WSN in a synthetic environment. Another example
    is presented

    in Reference [67], in the context of an aquatic monitoring application, in which
    Kalman ﬁltering was

    used with forecasting algorithms to assess the quality of the monitoring data
    series.

    Artiﬁcial neural networks (ANN) are hardware or software systems that need a training
    process

    consisting of mapping input information to target values or classes. The conversion
    of this input

    information into the yields is executed by artiﬁcial neurons that try to imitate
    the complicated, nonlinear

    and hugely parallel procedures that happen in natural sensory systems. ANNs have
    been used in WSNs

    for the most varied applications, many of which are related to fault-detection
    [68–70]. In consonance

    with the theme of the work herein, [71] presented an ANN-based approach to detect
    disaster events

    through an environmental sensor network. Additionally, [72] presents another ANN-based
    approach

    to detect biofouling events (thus, fault events) in an aquatic sensor network.

    The behavioral (cognitive-based) models group encompasses techniques that attempt
    to imitate

    and mechanize the decision-making procedures utilized by human analysts. These
    include event

    algebra, rule-based systems and fuzzy logic. The latter technique is the most
    studied and applied,

    which justiﬁes our particular attention to it.

    According to [73], fuzzy set theory allows for imprecise knowledge to be mathematically
    treated

    by making it easier to represent or classify system state variable information.
    The use of fuzzy

    associative memory (also known as production rules) allows a proposition to have
    a membership

    value in a given class ranging from zero (absolutely does not belong in the category)
    to one (absolutely

    belongs in the category). An expert speciﬁes the production rules and fuzzy sets
    that represent the

    characteristics of each input and output variable. Fuzzy data fusion application
    to WSNs has at least

    as much popularity as ANN-based fusion; therefore, its applications range from
    fault detection [74–76]

    to applications in industrial WSNs [77], the environment [78] and aquatic-related
    WSNs [79].

    There are some other mathematical approaches that have been developed in recent
    years, which

    include random set theory, conditional algebra and relational event algebra [48].

    Random set theory complements the existing theories of random vectors and of random
    functions

    serving as a mechanism for modeling observed phenomena, which are sets rather
    than precise points.

    It can be applied to incorporate ambiguous evidence (e.g., natural language reports
    and rules) and

    various expert system methods into multi-sensor estimation. Conditional event
    algebra refers to

    sets with one or more ﬁnitary operations deﬁned on it that satisfy a list of axioms,
    whose domain

    Sensors 2017, 17, 2010

    18 of 23

    consists of logical objects using a type of probabilistic calculus suited for
    contingency problems such

    as knowledge-based rules and contingent decision making. Relational event algebra
    is an extension

    of conditional event algebra where functions of probabilities formally representing
    single event

    probabilities represent actual relational events considering appropriately determined
    larger probability

    spaces, providing a systematic basis for solving problems involving pooling of
    evidence.

    4.2.2. Unsupervised Techniques

    There are several unsupervised data processing techniques (Figure 4), which serve,
    just

    like supervised techniques, to perform the needed functions in WSN-based monitoring
    systems,

    like detection, ﬁltering or correction.

    Various statistical analysis methods can be used as unsupervised techniques for
    data processing.

    For instance, the work in [80] resorts to statistical analysis to identify events,
    recognize observation

    errors and predict absent measurements in ecological WSNs. The proposed method
    requires learning

    statistical distributions of differences between measurements of a sensor and
    those of its neighbors,

    as well as between sequences of single-sensor measurements. According to the author,
    there is a

    large degree of spatiotemporal correlation in scalar physical variables, which
    provides a spectrum

    of oscillations between adjoining or successive readings with little differences.
    Based on successive

    readings, it is possible to learn their distribution and then detect outliers
    when a reading value is lower

    than a determined threshold, in the statistical signiﬁcance test.

    Clustering techniques are quite common in WSN-based applications. The general
    procedure

    is to integrate analogous information into groups with identical comportment.
    Data not belonging

    to these clusters or belonging to a smaller cluster would be considered outliers,
    if this is the goal.

    A simple and well-known clustering algorithm is the nearest neighbor, which associates
    the most

    similar measurements. For example, the approach was used by [81] to handle unsupervised
    outlier

    detection and, in particular, to identify global-wise outliers. Every node utilizes
    distance similitude

    to locally distinguish anomalous readings and transferring those readings to the
    nearby nodes for

    conﬁrmation. These nearby nodes will repeat this process until the entire network
    ultimately agrees

    on the overall anomalous readings. The downside of this method is the lack of
    scalability to large-scale

    networks. The most used method to measure the similarity between two data instances
    is the Euclidean

    distance. For instance, this is used in [82] in the context of target classiﬁcation
    in a multi-channel

    seismic network.

    The spectral decomposition-based approach aims at deﬁning standard behaviors in
    the data by

    utilizing principal component analysis (PCA). PCA allows decreasing the magnitude
    of an information

    set in which there are many interrelated variables, while holding as much as could
    be expected of the

    variety present in the set. The work in Reference [83] proposed a PCA-based method
    to address the

    data integrity arising from the imprecision triggered by faulty sensor nodes.
    The method requires a

    model of the standard behavior to be built a priori, by selecting appropriate
    principal components

    (PCs), and allows the detection of outliers.

    Voting methods are useful to fuse information from several sensors, particularly
    when applied to

    detection and classiﬁcation declarations from multiple sensors. These declarations
    are treated as votes,

    to which majority, plurality or decision-tree rules are applied to obtain a result
    that is more dependable

    than what would be obtained with a single sensor output [48]. This allows, for
    instance, masking false

    alarms when the sensors are used to detect the occurrence of some event, thus
    preventing premature

    reactions or countermeasures. In this sense, voting methods are also appropriate
    for fault-detection, to

    decide which node is the faulty one [84,85]. Finally, they are used in several
    other application contexts,

    such as WSN security [86] and sensor faults in on-body sensor networks [87].

    5. Conclusions

    Assuring the quality of sensor data is important in WSN-based monitoring applications.
    In the

    last decade, this dependability aspect has been explicitly or implicitly addressed
    in many works,

    Sensors 2017, 17, 2010

    19 of 23

    notably by exploiting the redundancy provided by the multiple sensor nodes typically
    existing in

    a WSN. Various speciﬁc problems need to be addressed when aiming at a dependable
    WSN-based

    monitoring solution, from ensuring the reliability of the transducing process
    to achieving a correct

    interpretation of data collected from several correlated sensors.

    In this paper, we present an encompassing perspective of the several facets of
    the problem,

    focusing on dependability aspects speciﬁc to individual sensors, to the network
    that interconnects

    the sensor nodes and the processing nodes and to the processing tasks that are
    performed within the

    processing nodes. This separation of concerns allows one to: (a) clearly expose
    the possible causes

    of data quality loss from the source to the ﬁnal output; (b) describe speciﬁc
    mitigation solutions;

    (c) provide a dependability perspective on what can be explicitly done to achieve
    improved data

    quality and assess this quality. Particular focus is given to the different forms
    of redundancy that may

    be exploited to achieve the dependability objectives: spatial, value and temporal
    redundancy. These are

    intrinsically related to the many sensor and data fusion techniques commonly employed,
    also surveyed

    in the paper. We provide many references on publications with theoretical and
    practical applications

    of the techniques, chosen to illustrate the multitude of options that are studied
    to solve directly or

    indirectly data quality problems. A speciﬁc outlook on data quality issues and
    open problems in water

    monitoring applications is ﬁnally given.

    Acknowledgments: This work was partially supported by the FCT, through the LASIGE
    Research Unit,

    Ref. UID/CEC/00408/2013, PhD Grant SFRH/BD/82489/2011 and by H2020 WADI—EC Grant
    Agreement

    No. 689239.

    Author Contributions: Anabela Oliveira was the main contributor to the section
    addressing data quality in

    aquatic environment monitoring and contributed to sections addressing sensor-speciﬁc
    aspects. António Casimiro

    was the main contributor to the sections related to dependability and redundancy
    aspects. Gonçalo Jesus was the

    main author of the survey.

    Conﬂicts of Interest: The authors declare no conﬂict of interest.

    References

    1.

    Brade, T.; Kaiser, J.; Zug, S. Expressing validity estimates in smart sensor applications.
    In Proceedings of the

    2013 26th International Conference on Architecture of Computing Systems (ARCS),
    Prague, Czech Republic,

    19–22 February 2013; pp. 1–8.

    2.

    Dietrich, A.; Zug, S.; Kaiser, J. Detecting external measurement disturbances
    based on statistical analysis for

    smart sensors. In Proceedings of the 2010 IEEE International Symposium on Industrial
    Electronics (ISIE),

    Bari, Italy, 4–7 July 2010; pp. 2067–2072.

    3.

    Rodriguez, M.; Ortiz Uriarte, L.; Jia, Y.; Yoshii, K.; Ross, R.; Beckman, P. Wireless
    sensor network for

    data-center environmental monitoring. In Proceedings of the 2011 Fifth International
    Conference on Sensing

    Technology (ICST), Palmerston North, New Zealand, 28 November–1 December 2011;
    pp. 533–537.

    4.

    Scherer, T.; Lombriser, C.; Schott, W.; Truong, H.; Weiss, B. Wireless Sensor
    Network for Continuous

    Temperature Monitoring in Air-Cooled Data Centers: Applications and Measurement
    Results. In Ad-hoc,

    Mobile, and Wireless Networks; Li, X.Y., Papavassiliou, S., Ruehrup, S., Eds.;
    Lecture Notes in Computer

    Science; Springer: Berlin/Heidelberg, Germany, 2012; Volume 7363, pp. 235–248.

    5.

    Cristian, F. Understanding Fault-Tolerant Distributed Systems. Commun. ACM 1991,
    34, 56–78.

    6.

    Yick, J.; Mukherjee, B.; Ghosal, D. Wireless sensor network survey. Comput. Netw.
    2008, 52, 2292–2330.

    7.

    Arampatzis, T.; Lygeros, J.; Manesis, S. A Survey of Applications of Wireless
    Sensors and Wireless Sensor

    Networks. In Proceedings of the 2005 IEEE International Symposium on Intelligent
    Control 13th Mediterrean

    Conference on Control and Automation, Limassol, Cyprus, 27–29 June 2005; pp. 719–724.

    8.

    Veríssimo, P.; Rodrigues, L.

    Distributed Systems for System Architects; Springer: New York, NY, USA,

    2001; p. 623.

    9.

    Ibargiengoytia, P.; Sucar, L.; Vadera, S. Real time intelligent sensor validation.
    IEEE Trans. Power Syst.

    2001, 16, 770–775.

    10.

    Rodger, J. Toward reducing failure risk in an integrated vehicle health maintenance
    system: A fuzzy

    multi-sensor data fusion Kalman ﬁlter approach for IVHMS. Expert Syst. Appl. 2012,
    39, 9821–9836.

    Sensors 2017, 17, 2010

    20 of 23

    11.

    Frolik, J.; Abdelrahman, M.; Kandasamy, P. A conﬁdence-based approach to the self-validation,
    fusion and

    reconstruction of quasi-redundant sensor data. IEEE Trans. Instrum. Meas. 2001,
    50, 1761–1769.

    12.

    Avizienis, A.; Laprie, J.C.; Randell, B.; Landwehr, C. Basic Concepts and Taxonomy
    of Dependable and

    Secure Computing. IEEE Trans. Dependable Secur. Comput. 2004, 1, 11–33.

    13.

    Zhang, D.; Zhao, C.; Liang, Y.; Liu, Z. A new medium access control protocol based
    on perceived data

    reliability and spatial correlation in wireless sensor network. Comput. Electr.
    Eng. 2012, 38, 694–702.

    14.

    Luo, H.; Tao, H.; Ma, H.; Das, S. Data Fusion with Desired Reliability in Wireless
    Sensor Networks.

    IEEE Trans. Parallel Distrib. Syst. 2011, 22, 501–513.

    15.

    Tang, L.; Yu, X.; Kim, S.; Gu, Q.; Han, J.; Leung, A.; La Porta, T. Trustworthiness
    analysis of sensor data in

    cyber-physical systems. J. Comput. Syst. Sci. 2013, 79, 383–401.

    16.

    Ayday, E.; Delgosha, F.; Fekri, F. Data Authenticity and Availability in Multihop
    Wireless Sensor Networks.

    ACM Trans. Sens. Netw. 2012, 8, doi:10.1145/2140522.2140523.

    17.

    Prathiba, B.; Sankar, K.J.; Sumalatha, V. Enhancing the data quality in wireless
    sensor networks—A review.

    In Proceedings of the IEEE International Conference on Automatic Control and Dynamic
    Optimization

    Techniques (ICACDOT), Pune, India, 9–10 September 2016; pp. 448–454.

    18.

    Sharma, A.; Golubchik, L.; Govindan, R. Sensor Faults: Detection Methods and Prevalence
    in Real-world

    Datasets. ACM Trans. Sens. Netw. 2010, 6, doi:10.1145/1754414.1754419.

    19.

    Nguyen, T.T.; Spehr, J.; Uhlemann, M.; Zug, S.; Kruse, R. Learning of lane information
    reliability for

    intelligent vehicles. In Proceedings of the 2016 IEEE International Conference
    on Multisensor Fusion and

    Integration for Intelligent Systems (MFI), Baden-Baden, Germany, 19–21 September
    2016; pp. 142–147.

    20.

    Golle, P.; Greene, D.; Staddon, J. Detecting and Correcting Malicious Data in
    VANETs. In Proceedings of the

    1st ACM International Workshop on Vehicular Ad Hoc Networks, Philadelphia, PA,
    USA, 1 October 2004;

    ACM: New York, NY, USA, 2004; pp. 29–37.

    21.

    Nimier, V. Supervised multisensor tracking algorithm. In Proceedings of the 9th
    European Signal Processing

    Conference, Island of Rhodes, Greece, 8–11 September 1998; pp. 1–4.

    22.

    Patra, J.; Chakraborty, G.; Meher, P. Neural-network-based robust linearization
    and compensation technique for

    sensors under nonlinear environmental influences. IEEE Trans. Circuits Syst. I
    Regul. Pap. 2008, 55, 1316–1327.

    23.

    Webster, J.; Eren, H. Measurement, Instrumentation, and Sensors Handbook, 2nd
    ed.; Spatial, Mechanical,

    Thermal, and Radiation Measurement; CRC Press: Boca Raton, FL, USA, 2014; p. 1640.

    24.

    De Silva, C. Control Sensors and Actuators; Prentice Hall: Upper Saddle River,
    NJ, USA, 1989.

    25.

    Tumanski, S. Sensors and Actuators—Control System Instrumentation; de Silva, C.W.,
    Ed.; CRC Press:

    Boca Raton, FL, USA, 2007; Volume 10.

    26.

    Mitchell, H. Multi-Sensor Data Fusion: An Introduction; Springer: Berlin/Heidelberg,
    Germany, 2007.

    27.

    Whitehouse, K.; Culler, D. Calibration As Parameter Estimation in Sensor Networks.
    In Proceedings of

    the 1st ACM International Workshop on Wireless Sensor Networks and Applications,
    Atlanta, GA, USA,

    28 September 2002; ACM: New York, NY, USA, 2002; pp. 59–67.

    28.

    Patra, J.; Meher, P.; Chakraborty, G. Development of Laguerre Neural-Network-Based
    Intelligent Sensors for

    Wireless Sensor Networks. IEEE Trans. Instrum. Meas. 2011, 60, 725–734.

    29.

    Rivera, J.; Carrillo, M.; Chacón, M.; Herrera, G.; Bojorquez, G. Self-Calibration
    and Optimal Response in

    Intelligent Sensors Design Based on Artiﬁcial Neural Networks. Sensors 2007, 7,
    1509.

    30.

    Barwicz, A.; Massicotte, D.; Savaria, Y.; Santerre, M.A.; Morawski, R.

    An integrated structure for

    Kalman-ﬁlter-based measurand reconstruction. IEEE Trans. Instrum. Meas. 1994,
    43, 403–410.

    31.

    Gubian, M.; Marconato, A.; Boni, A.; Petri, D. A Study on Uncertainty-Complexity
    Tradeoffs for Dynamic

    Nonlinear Sensor Compensation. IEEE Trans. Instrum. Meas. 2009, 58, 26–32.

    32.

    Ganesan, D.; Estrin, D.; Heidemann, J. Dimensions: Why do we need a new data handling
    architecture for

    sensor networks. ACM SIGCOMM Comput. Commun. Rev. 2003, 33, 143–148.

    33.

    Zhao, J.; Govindan, R.; Estrin, D.

    Computing aggregates for monitoring wireless sensor networks.

    In Proceedings of the First IEEE International Workshop on Sensor Network Protocols
    and Applications,

    Anchorage, AK, USA, 11 May 2003; pp. 139–148.

    34.

    Madden, S.; Franklin, M.; Hellerstein, J.; Hong, W. TAG: A Tiny Aggregation Service
    for Ad-hoc Sensor

    Networks. SIGOPS Oper. Syst. Rev. 2002, 36, 131–146.

    Sensors 2017, 17, 2010

    21 of 23

    35.

    Krishnamachari, L.; Estrin, D.; Wicker, S. The impact of data aggregation in wireless
    sensor networks.

    In Proceedings of the 22nd International Conference on Distributed Computing Systems
    Workshops,

    Vienna, Austria, 2–5 July 2002.

    36.

    Kopetz, H. Real-Time Systems: Design Principles for Distributed Embedded Applications;
    Real-Time Systems

    Series; Springer: NewYork, NY, USA, 2011.

    37.

    Marzullo, K. Tolerating Failures of Continuous-valued Sensors. ACM Trans. Comput.
    Syst. 1990, 8, 284–304.

    38.

    Koushanfar, F.; Potkonjak, M.; Sangiovanni-Vincentelli, A. In Proceedings of the
    2003 IEEE On-Line Fault

    Detection of Sensor Measurements, Toronto, ON, Canada, 22–24 October 2003; Volume
    2, pp. 974–979.

    39.

    Zhuang, P.; Wang, D.; Shang, Y. Distributed Faulty Sensor Detection. In Proceedings
    of the 2009 IEEE Global

    Telecommunications Conference, Honolulu, HI, USA, 30 November–4 December 2009;
    pp. 1–6.

    40.

    Boudjemaa, R.; Forbes, A. Parameter Estimation Methods for Data Fusion; NPL Report
    CMSC; National Physical

    Laboratory, Great Britain, Centre for Mathematics and Scientiﬁc Computing: Teddington,
    UK, 2004.

    41.

    Grime, S.; Durrant-Whyte, H. Data fusion in decentralized sensor networks. Control
    Eng. Pract. 1994, 2, 849–863.

    42.

    Baptista, A. Environmental Observation and Forecasting Systems. In Encyclopedia
    of Physical Science and

    Technology (Third Edition), Meyers, R.A., Ed.; Academic Press: New York, NY, USA,
    2003; pp. 565–581.

    43.

    Gomes, J.; Jesus, G.; Rodrigues, M.; Rogeiro, J.; Azevedo, A.; Oliveira, A. Managing
    a Coastal Sensors

    Network in a Nowcast-Forecast Information System. In Proceedings of the 2013 Eighth
    International

    Conference on Broadband and Wireless Computing, Communication and Applications
    (BWCCA),

    Compiegne, France, 28–30 October 2013; pp. 518–523.

    44.

    Brooks, R.; Iyengar, S. Multi-Sensor Fusion: Fundamentals and Applications with
    Software; Prentice-Hall, Inc.:

    Upper Saddle River, NJ, USA, 1998.

    45.

    Nakamura, E.; Loureiro, A.; Frery, A. Information Fusion for Wireless Sensor Networks:
    Methods, Models,

    and Classiﬁcations. ACM Comput. Surv. 2007, 39, doi:10.1145/1267070.1267073

    46.

    Worden, K.; Manson, G.; Fieller, N. Damage Detection using Outlier Analysis. J.
    Sound Vib. 2000, 229, 647–667.

    47.

    Isermann, R. Model-based fault-detection and diagnosis—Status and applications.

    Ann. Rev. Control

    2005, 29, 71–85.

    48.

    Klein, L. Sensor and Data Fusion: A Tool for Information Assessment and Decision
    Making; Press Monographs,

    Society of Photo Optical: Bellingham, WA, USA, 2004.

    49.

    Mendonca, R.; Santana, P.; Marques, F.; Lourenco, A.; Silva, J.; Barata, J. Kelpie:
    A ROS-Based Multi-Robot

    Simulator for Water Surface and Aerial Vehicles. In Proceedings of the 2013 IEEE
    International Conference

    on Systems, Man, and Cybernetics (SMC), Manchester, UK, 13–16 October 2013; pp.
    3645–3650.

    50.

    Choi, S.; Yuh, J.; Takashige, G. Development of the Omni Directional Intelligent
    Navigator. IEEE Rob.

    Autom. Mag. 1995, 2, 44–53.

    51.

    Crespi, A.; Ijspeert, A. Online optimization of swimming and crawling in an amphibious
    snake robot.

    IEEE Trans. Rob. 2008, 24, 75–87.

    52.

    Zhang, Y.; Meratnia, N.; Havinga, P. Outlier Detection Techniques for Wireless
    Sensor Networks: A Survey.

    IEEE Commun. Surv. Tutor. 2010, 12, 159–170.

    53.

    Durrant-Whyte, H. Sensor Models and Multisensor Integration. Int. J. Rob. Res.
    1988, 7, 97–113.

    54.

    Zoumboulakis, M.; Roussos, G.

    Escalation: Complex Event Detection in Wireless Sensor Networks.

    In Proceedings of the 2nd European Conference on Smart Sensing and Context (EuroSSC’07),
    Kendal, UK,

    23–25 October 2007; Springer: Berlin/Heidelberg, Germany, 2007; pp. 270–285.

    55.

    Chandola, V.; Banerjee, A.; Kumar, V. Anomaly Detection: A Survey. ACM Comput.
    Surv. 2009,

    41, doi:10.1145/1541880.1541882.

    56.

    Kreibich, O.; Neuzil, J.; Smid, R. Quality-based multiple-sensor fusion in an
    industrial wireless sensor

    network for MCM. IEEE Trans. Ind. Electron. 2014, 61, 4903–4911.

    57.

    Klein, L. Sensor and Data Fusion Concepts and Applications, 2nd ed.; Society of
    Photo-Optical Instrumentation

    Engineers (SPIE): Bellingham, WA, USA, 1999.

    58.

    Khaleghi, B.; Khamis, A.; Karray, F.; Razavi, S. Multisensor data fusion: A review
    of the state-of-the-art.

    Inf. Fusion 2013, 14, 28–44.

    59.

    Hall, D.; McMullen, S. Mathematical Techniques in Multisensor Data Fusion (Artech
    House Information Warfare

    Library); Artech House, Inc.: Norwood, MA, USA, 2004.

    Sensors 2017, 17, 2010

    22 of 23

    60.

    Hartl, G.; Li, B. infer: A Bayesian Inference Approach towards Energy Efﬁcient
    Data Collection in Dense

    Sensor Networks. In Proceedings of the 25th IEEE International Conference on Distributed
    Computing

    Systems (ICDCS 2005), Columbus, OH, USA, 6–10 June 2005; pp. 371–380.

    61.

    Janakiram, D.; Reddy, V.; Kumar, A. Outlier Detection in Wireless Sensor Networks
    using Bayesian Belief

    Networks. In Proceedings of the First International Conference on Communication
    System Software and

    Middleware (Comsware 2006), New Delhi, India, 8–12 January 2006; pp. 1–6.

    62.

    Zhao, W.; Fang, T.; Jiang, Y. Data Fusion Using Improved Dempster-Shafer Evidence
    Theory for Vehicle

    Detection.

    In Proceedings of the Fourth International Conference on Fuzzy Systems and Knowledge

    Discovery (FSKD 2007), Haikou, China, 24–27 August 2007; Volume 1, pp. 487–491.

    63.

    Konorski, J.; Orlikowski, R. Data-Centric Dempster-Shafer Theory-Based Selﬁshness
    Thwarting via Trust

    Evaluation in MANETs and WSNs.

    In Proceedings of the 2009 3rd International Conference on New

    Technologies, Mobility and Security (NTMS), Cairo, Egypt, 20–23 December 2009;
    pp. 1–5.

    64.

    Sentz, K.; Ferson, S.; Laboratories, S.N. Combination of Evidence in Dempster-Shafer
    Theory; Sandia National

    Laboratories: Albuquerque, NM, USA, 2002.

    65.

    Ahmed, M.; Huang, X.; Sharma, D. A Novel Misbehavior Evaluation with Dempster-shafer
    Theory in

    Wireless Sensor Networks. In Proceedings of the Thirteenth ACM International Symposium
    on Mobile Ad

    Hoc Networking and Computing (MobiHoc ’12), Hilton Head, SC, USA, 11–14 June 2012;
    ACM: New York,

    NY, USA, 2012; pp. 259–260.

    66.

    Zhu, R. Efﬁcient Fault-Tolerant Event Query Algorithm in Distributed Wireless
    Sensor Networks. IJDSN

    2010, doi:10.1155/2010/593849.

    67.

    Alferes, J.; Lynggaard-Jensen, A.; Munk-Nielsen, T.; Tik, S.; Vezzaro, L.; Sharma,
    A.; Mikkelsen, P.;

    Vanrolleghem, P. Validating data quality during wet weather monitoring of wastewater
    treatment plant

    inﬂuents. Proc. Water Environ. Fed. 2013, 2013, 4507–4520.

    68.

    Moustapha, A.; Selmic, R. Wireless Sensor Network Modeling Using Modiﬁed Recurrent
    Neural Networks:

    Application to Fault Detection. IEEE Trans. Instrum. Meas. 2008, 57, 981–988.

    69.

    Barron, J.; Moustapha, A.; Selmic, R. Real-Time Implementation of Fault Detection
    in Wireless Sensor

    Networks Using Neural Networks. In Proceedings of the Fifth International Conference
    on Information

    Technology: New Generations (ITNG 2008), Las Vegas, NV, USA, 7–9 April 2008; pp.
    378–383.

    70.

    Obst, O. Poster Abstract: Distributed Fault Detection Using a Recurrent Neural
    Network. In Proceedings

    of the 2009 International Conference on Information Processing in Sensor Networks
    (IPSN ’09),

    San Francisco, CA, USA, 13–16 April 2009; IEEE Computer Society: Washington, DC,
    USA, 2009; pp. 373–374.

    71.

    Bahrepour, M.; Meratnia, N.; Poel, M.; Taghikhaki, Z.; Havinga, P. Distributed
    Event Detection in Wireless

    Sensor Networks for Disaster Management. In Proceedings of the 2010 2nd International
    Conference on

    Intelligent Networking and Collaborative Systems (INCOS), Thessaloniki, Greece,
    24–26 November 2010;

    pp. 507–512.

    72.

    Archer, C.; Baptista, A.; Leen, T. Fault Detection for Salinity Sensors in the
    Columbia Estuary; Technical Report;

    Oregon Graduate Institute School of Science & Engineering: Hillsboro, OR, USA,
    2002.

    73.

    Klein, L.; Mihaylova, L.; El Faouzi, N.E. Sensor and Data Fusion: Taxonomy, Challenges
    and Applications.

    In Handbook on Soft Computing for Video Surveillance, 1st ed.; Pal, S.K., Petrosino,
    A., Maddalena, L., Eds.;

    Chapman & Hall/CRC: Boca Raton, FL, USA, 2012; Chapter 6.

    74.

    Shell, J.; Coupland, S.; Goodyer, E. Fuzzy data fusion for fault detection in
    Wireless Sensor Networks.

    In Proceedings of the 2010 UK Workshop on Computational Intelligence (UKCI), Colchester,
    UK,

    8–10 September 2010; pp. 1–6.

    75.

    Khan, S.; Daachi, B.; Djouani, K. Application of Fuzzy Inference Systems to Detection
    of Faults in Wireless

    Sensor Networks. Neurocomputing 2012, 94, 111–120.

    76.

    Manjunatha, P.; Verma, A.; Srividya, A. Multi-Sensor Data Fusion in Cluster based
    Wireless Sensor Networks

    Using Fuzzy Logic Method. In Proceedings of the IEEE Region 10 and the Third international
    Conference on

    Industrial and Information Systems (ICIIS 2008), Kharagpur, India, 8–10 December
    2008; pp. 1–6.

    77.

    Collotta, M.; Pau, G.; Salerno, V.; Scata, G. A fuzzy based algorithm to manage
    power consumption in

    industrial Wireless Sensor Networks. In Proceedings of the 2011 9th IEEE International
    Conference on

    Industrial Informatics (INDIN), Lisbon, Portugal, 26–29 July 2011; pp. 151–156.

    78.

    Su, I.J.; Tsai, C.C.; Sung, W.T. Area Temperature System Monitoring and Computing
    Based on Adaptive

    Fuzzy Logic in Wireless Sensor Networks. Appl. Soft Comput. 2012, 12, 1532–1541.

    Sensors 2017, 17, 2010

    23 of 23

    79.

    Castillo-Effer, M.; Quintela, D.; Moreno, W.; Jordan, R.; Westhoff, W. Wireless
    sensor networks for ﬂash-ﬂood

    alerting. In Proceedings of the Fifth IEEE International Caracas Conference on
    Devices, Circuits and Systems,

    Punta Cana, Dominican Republic, 3–5 November 2004; Volume 1, pp. 142–146.

    80.

    Bettencourt, L.; Hagberg, A.; Larkey, L.

    Separating the Wheat from the Chaff: Practical Anomaly

    Detection Schemes in Ecological Applications of Distributed Sensor Networks. In
    Distributed Computing in

    Sensor Systems; Aspnes, J., Scheideler, C., Arora, A., Madden, S., Eds.; Lecture
    Notes in Computer Science;

    Springer: Berlin/Heidelberg, Germany, 2007; Volume 4549, pp. 223–239.

    81.

    Branch, J.; Giannella, C.; Szymanski, B.; Wolff, R.; Kargupta, H. In-network outlier
    detection in wireless

    sensor networks. Knowl. Inf. Syst. 2013, 34, 23–54.

    82.

    Zubair, M.; Hartmann, K.

    Target classiﬁcation based on sensor fusion in multi-channel seismic

    network. In Proceedings of the 2011 IEEE International Symposium on Signal Processing
    and Information

    Technology (ISSPIT), Bilbao, Spain, 14–17 December 2011; pp. 438–443.

    83.

    Chatzigiannakis, V.; Papavassiliou, S.; Grammatikou, M.; Maglaris, B. Hierarchical
    Anomaly Detection in

    Distributed Large-Scale Sensor Networks. In Proceedings of the 11th IEEE Symposium
    on Computers and

    Communications (ISCC ’06), Sardinia, Italy, 26–29 June 2006; pp. 761–767.

    84.

    Gao, J.; Xu, Y.; Li, X. Online distributed fault detection of sensor measurements.
    Tsinghua Sci. Technol.

    2007, 12, 192–196.

    85.

    Abid, A.; Kachouri, A.; Kaaniche, H.; Abid, M. Quality of service in wireless
    sensor networks through a

    failure-detector with voting mechanism. In Proceedings of the 2013 International
    Conference on Computer

    Applications Technology (ICCAT), Sousse, Tunisia, 20–22 January 2013; pp. 1–5.

    86.

    Li, F.; Wu, J. A Probabilistic Voting-based Filtering Scheme in Wireless Sensor
    Networks. In Proceedings

    of the 2006 International Conference on Wireless Communications and Mobile Computing
    (IWCMC’06),

    Vancouver, BC, Canada, 3–6 July 2006; ACM: New York, NY, USA, 2006; pp. 27–32.

    87.

    Zappi, P.; Stiefmeier, T.; Farella, E.; Roggen, D.; Benini, L.; Troster, G. Activity
    recognition from on-body

    sensors by classiﬁer fusion: Sensor scalability and robustness.

    In Proceedings of the 3rd International

    Conference on Intelligent Sensors, Sensor Networks and Information (ISSNIP 2007),
    Melbourne, Australia,

    3–6 December 2007; pp. 281–286.

    c⃝ 2017 by the authors. Licensee MDPI, Basel, Switzerland. This article is an
    open access

    article distributed under the terms and conditions of the Creative Commons Attribution

    (CC BY) license (http://creativecommons.org/licenses/by/4.0/).

    '
  inline_citation: '>'
  journal: Sensors
  limitations: '>'
  pdf_link: https://www.mdpi.com/1424-8220/17/9/2010/pdf?version=1504340534
  publication_year: 2017
  relevance_score1: 0
  relevance_score2: 0
  title: A Survey on Data Quality for Dependable Monitoring in Wireless Sensor Networks
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.4081/jlimnol.2021.2011
  analysis: '>'
  authors:
  - Rocco Tiberti
  - Rossana Caroni
  - Massimiliano Cannata
  - Andrea Lami
  - Dario Manca
  - Daniele Strigaro
  - Michela Rogora
  citation_count: 11
  full_citation: '>'
  full_text: ">\nORIGINAL ARTICLE\nINTRODUCTION\nMonitoring the quality of surface\
    \ waters is compul-\nsory under current environmental policies, in particular\
    \ in\nEurope, under the EU Water Framework Directive (WFD;\nEuropean Commission,\
    \ 2000). The WFD requires the\nclassification of the ecological status of surface\
    \ waters\nwith an integrated approach based on several biological\nindicators\
    \ and physico-chemical and hydro-morphologi-\ncal variables. The principal aim\
    \ of the WFD is to protect\nand enhance the status of aquatic ecosystems in the\
    \ Eu-\nropean Union. Monitoring is a basic effort to assess the\npresent-day quality\
    \ of European waters, describe their\nevolution through time, and, ultimately,\
    \ assess the effects\nof the WFD and design mitigation options (Skeffington\n\
    et al., 2015). \nTraditionally, monitoring freshwaters involves field\nsampling\
    \ and subsequent laboratory work. Samples are\ncollected manually from selected\
    \ areas of the waterbody\nand times of the year. This conventional approach pro-\n\
    vides essential information on the water quality and the\nmain ecological processes.\
    \ However, this approach often\nfails to capture the fast-paced dynamics of many\
    \ biotic\nand abiotic processes because of low sampling frequency\n(Marcé et al.,\
    \ 2016). As an example, the conventional\nmonitoring of the trophic state of lakes\
    \ based on micro-\nscopic characterization of phytoplankton communities\nand chlorophyll-a\
    \ (Chl-a) extractions (Lorenzen, 1967;\nISO, 1992), due to its demanding field\
    \ work and labora-\ntory effort, is necessarily conducted at a low frequency\n\
    resolution. This kind of monitoring may be insufficient to\ndetect the short-lived,\
    \ but significant changes in the phy-\ntoplankton communities, e.g., rapid turnover\
    \ of phyto-\nplankton species, cyanobacterial increases, and bloom\nAutomated\
    \ high frequency monitoring of Lake Maggiore through in situ\nsensors: system\
    \ design, field test and data quality control\nRocco Tiberti,1 Rossana Caroni,1\
    \ Massimiliano Cannata,2 Andrea Lami,1 Dario Manca,1 Daniele Strigaro,2,3\nMichela\
    \ Rogora1*\n1National Research Council of Italy, Water Research Institute (CNR‐IRSA),\
    \ Largo Tonolli 50, 28922 Verbania, Italy; 2Institute of\nEarth Sciences, Department\
    \ of Environment, Construction and Design, University of Applied Sciences of Southern\
    \ Switzerland\n(SUPSI), Campus Mendrisio, Via Francesco Catenazzi 23, 6850 Mendrisio,\
    \ Switzerland; 3Department of Earth and Environmental\nSciences (DSTA), University\
    \ of Pavia, Via Ferrata 9, 27100 Pavia, Italy\nABSTRACT\nA high frequency monitoring\
    \ (HFM) system for the deep subalpine lakes Maggiore, Lugano and Como is under\
    \ development within\nthe EU INTERREG project SIMILE. The HFM system is designed\
    \ to i) describe often neglected but potentially relevant processes oc-\ncurring\
    \ on short time scale; ii) become a cost-effective source of environmental data;\
    \ and iii) strengthen the coordinated management\nof water resources in the subalpine\
    \ lake district. In this project framework, a first HFM station (LM1) consisting\
    \ of a monitoring buoy\nwas placed in Lake Maggiore. LM1 represents a pilot experience\
    \ within the project, aimed at providing the practical know-how needed\nfor the\
    \ development of the whole HFM system. To increase replicability and transferability,\
    \ LM1 was developed in-house, and conceived\nas a low-cost modular system. LM1\
    \ is presently equipped with solar panels, a weather station, and sensors for\
    \ water temperature, pH,\ndissolved oxygen, conductivity, and chlorophyll-a. In\
    \ this study, we describe the main features of LM1 (hardware and software) and\n\
    the adopted Quality Assurance/Quality Control (QA/QC) procedures. To this end,\
    \ we provide examples from a test period, i.e., the first\n9-months of functioning\
    \ of LM1. A description of the software selected as data management software for\
    \ the HFM system (IstSOS) is\nalso provided. Data gathered during the study period\
    \ provided clear evidence that coupling HFM and discrete sampling for QA/QC\n\
    controls is necessary to produce accurate data and to detect and correct errors,\
    \ mainly because of sensor fouling and calibration drift.\nThese results also\
    \ provide essential information to develop further the HFM system and shared protocols\
    \ adapted to the local environ-\nmental (i.e., large subalpine lakes) and technical\
    \ (expertise availability) context. The next challenge would be making HFM not\
    \ only a\nsource of previously unaffordable information, but also a cost-effective\
    \ tool for environmental monitoring.\nCorresponding author: michela.rogora@cnr.it\n\
    Key words: Water quality; chlorophyll; data management; sensors;\nSIMILE project.\n\
    Edited by: Diego Fontaneto, CNR-IRSA Water Research Institute,\nVerbania, Italy.\n\
    Received: 3 March 2021.\nAccepted: 19 April 2021.\nThis work is licensed under\
    \ a Creative Commons Attribution Non-\nCommercial 4.0 License (CC BY-NC 4.0).\n\
    ©Copyright: the Author(s), 2021\nLicensee PAGEPress, Italy\nJ. Limnol., 2021;\
    \ 80(2):2011\nDOI: 10.4081/jlimnol.2021.2011\nNon-commercial use only\ncurring\
    \ on short time scale; ii) become a cost-effective source of environmental data;\
    \ and iii) strengthen the coordinated management\nNon-commercial use only\ncurring\
    \ on short time scale; ii) become a cost-effective source of environmental data;\
    \ and iii) strengthen the coordinated management\nof water resources in the subalpine\
    \ lake district. In this project framework, a first HFM station (LM1) consisting\
    \ of a monitoring buoy\nNon-commercial use only\nof water resources in the subalpine\
    \ lake district. In this project framework, a first HFM station (LM1) consisting\
    \ of a monitoring buoy\nwas placed in Lake Maggiore. LM1 represents a pilot experience\
    \ within the project, aimed at providing the practical know-how needed\nNon-commercial\
    \ use only\nwas placed in Lake Maggiore. LM1 represents a pilot experience within\
    \ the project, aimed at providing the practical know-how needed\nfor the development\
    \ of the whole HFM system. To increase replicability and transferability, LM1\
    \ was developed in-house, and conceived\nNon-commercial use only\nfor the development\
    \ of the whole HFM system. To increase replicability and transferability, LM1\
    \ was developed in-house, and conceived\nas a low-cost modular system. LM1 is\
    \ presently equipped with solar panels, a weather station, and sensors for water\
    \ temperature, pH,\nNon-commercial use only\nas a low-cost modular system. LM1\
    \ is presently equipped with solar panels, a weather station, and sensors for\
    \ water temperature, pH,\ndissolved oxygen, conductivity, and chlorophyll-a. In\
    \ this study, we describe the main features of LM1 (hardware and software) and\n\
    Non-commercial use only\ndissolved oxygen, conductivity, and chlorophyll-a. In\
    \ this study, we describe the main features of LM1 (hardware and software) and\n\
    the adopted Quality Assurance/Quality Control (QA/QC) procedures. To this end,\
    \ we provide examples from a test period, \nNon-commercial use only\nthe adopted\
    \ Quality Assurance/Quality Control (QA/QC) procedures. To this end, we provide\
    \ examples from a test period, \n9-months of functioning of LM1. A description\
    \ of the software selected as data management software for the HFM system (IstSOS)\
    \ is\nNon-commercial use only\n9-months of functioning of LM1. A description of\
    \ the software selected as data management software for the HFM system (IstSOS)\
    \ is\nalso provided. Data gathered during the study period provided clear evidence\
    \ that coupling HFM and discrete sampling for QA/QC\nNon-commercial use only\n\
    also provided. Data gathered during the study period provided clear evidence that\
    \ coupling HFM and discrete sampling for QA/QC\nNon-commercial use only\ncontrols\
    \ is necessary to produce accurate data and to detect and correct errors, mainly\
    \ because of sensor fouling and calibration drift.\nNon-commercial use only\n\
    controls is necessary to produce accurate data and to detect and correct errors,\
    \ mainly because of sensor fouling and calibration drift.\nThese results also\
    \ provide essential information to develop further the HFM system and shared protocols\
    \ adapted to the local environ-\nNon-commercial use only\nThese results also provide\
    \ essential information to develop further the HFM system and shared protocols\
    \ adapted to the local environ-\n., large subalpine lakes) and technical (expertise\
    \ availability) context. The next challenge would be making HFM not only a\nNon-commercial\
    \ use only\n., large subalpine lakes) and technical (expertise availability) context.\
    \ The next challenge would be making HFM not only a\nNon-commercial use only\n\
    Non-commercial use only\nMonitoring the quality of surface waters is compul-\n\
    Non-commercial use only\nMonitoring the quality of surface waters is compul-\n\
    sory under current environmental policies, in particular in\nNon-commercial use\
    \ only\nsory under current environmental policies, in particular in\nEurope, under\
    \ the EU Water Framework Directive (WFD;\nNon-commercial use only\nEurope, under\
    \ the EU Water Framework Directive (WFD;\nEuropean Commission, 2000). The WFD\
    \ requires the\nNon-commercial use only\nEuropean Commission, 2000). The WFD requires\
    \ the\nclassification of the ecological status of surface waters\nNon-commercial\
    \ use only\nclassification of the ecological status of surface waters\nwith an\
    \ integrated approach based on several biological\nNon-commercial use only\nwith\
    \ an integrated approach based on several biological\nNon-commercial use only\n\
    source of previously unaffordable information, but also a cost-effective tool\
    \ for environmental monitoring.\nNon-commercial use only\nsource of previously\
    \ unaffordable information, but also a cost-effective tool for environmental monitoring.\n\
    42\nR. Tiberti et al.\nformation (Hunter et al., 2009; Stumpf et al., 2012; Song\n\
    et al., 2012; Tran Khac et al., 2018). \nIn general, all the processes occurring\
    \ over a temporal\nscale shorter than the sampling frequency may go unno-\nticed\
    \ in traditional monitoring programs (e.g., short-lived,\nextreme episodic, or\
    \ unpredictable events; Dubelaar et al.,\n2004; Banas et al., 2005; Itvánovics\
    \ et al., 2005; Stock-\nwell et al., 2020). Both trophic state indicators, and\
    \ single\nlimnological variables (e.g., temperature, pH, dissolved\noxygen) are\
    \ indicative of lake water quality and may con-\ntribute to identify conditions\
    \ favourable to -or indicative\nof- algal blooms development. For instance, summer\
    \ heat\nwaves may promote blooms of harmful cyanobacteria and\nother worrisome\
    \ taxonomic shifts (Wagner and Adrian,\n2009). Sudden changes in water temperature,\
    \ conductivity\nand dissolved oxygen can support the identification of up-\nwelling\
    \ events due to internal sexes, mixing episodes, in-\ntrusion of river waters\
    \ and the calculation of lake mixing\nand stratification indices (Read et al.,\
    \ 2011). Short term\nchanges in pH and dissolved oxygen may also help inves-\n\
    tigating inorganic carbon dynamics in lakes (Khan et al.,\n2020). Further, high\
    \ frequency limnological data, possibly\ngathered at different locations within\
    \ a lake, represent a\nvaluable resource for lake modelling (Laborde et al.,\n\
    2010; Pilotti et al., 2013).\nRecent advances in sensor technology can overcome\n\
    the drawbacks of conventional monitoring, giving the op-\nportunity to measure\
    \ an increasing number of limnologi-\ncal and ecological parameters at unprecedented\
    \ short\ntemporal intervals and also during adverse meteorological\nevents (Banas\
    \ et al., 2005; Johnson et al., 2007; Le Vu et\nal., 2011; Jennings et al., 2012;\
    \ Klug et al., 2012; Hamil-\nton et al., 2014; Meinson et al., 2016). Over the\
    \ past\ndecade, there has been a drastic increase in the use of au-\ntomated collection\
    \ of high-frequency data in scientific re-\nsearch and environmental monitoring\
    \ (Horsburgh et al.,\n2015). In addition, the installation of automated high fre-\n\
    quency monitoring (HFM) systems is often expected to\nbecome a cost-effective\
    \ monitoring tool, to cope with the\nscarcity of specialized personnel for field\
    \ and laboratory\nwork and to reduce the analytical costs (Le Vu et al.,\n2011).\
    \ A great impulse to the development of HFM sys-\ntems for European lakes came\
    \ from the COST Action\nNETLAKE (ES1201 - Networking Lake Observatories in\nEurope)\
    \ which prompted the establishment of a network\nof scientists, technologists,\
    \ managers, and stakeholders\nfocused on the application of sensor technology\
    \ for lake\nmonitoring (Marcé et al., 2016). The cooperative network\nGLEON (Global\
    \ Lake Ecological Observatory Network)\nalso supports sharing and interpreting\
    \ high resolution sen-\nsor data from lakes worldwide (Weathers et al., 2013).\
    \ An\nincreasing number of environmental authorities from all\naround the world\
    \ are integrating some HFM systems in\ntheir monitoring programmes (Le Vu et al.,\
    \ 2011; Bertone\net al., 2018), also to improve provision of high-quality\nfreshwater,\
    \ provision of food (aquaculture) and recreation\n(Marcé et al., 2016). A few\
    \ examples from Italy include\nthe HFM network deployed in 18 Sardinian reservoirs\n\
    used to identify the optimal depth for water withdrawal\nand to early detect the\
    \ development of algal blooms\n(Marcé et al., 2016); a monitoring system which\
    \ has been\ndeveloped in Lake Iseo, measuring the main thermal, ra-\ndiative,\
    \ and mechanical ﬂuxes on the lake surface (Pilotti\net al., 2013); and a high-frequency\
    \ monitoring of meteor-\nological parameters and water temperature at different\
    \ lo-\ncations in Lake Como as input to a three-dimensional\nhydrodynamic model\
    \ (Laborde et al., 2010).\nThe implementation of a HFM system is also pro-\njected\
    \ for the lakes of the so-called Insubric region (lakes\nMaggiore, Como, and Lugano)\
    \ and will be developed\nwithin the cross-border cooperation project SIMILE (Ital-\n\
    ian acronym for “Integrated monitoring system for knowl-\nedge, protection and\
    \ valorisation of the subalpine lakes\nand their ecosystems”). While the general\
    \ aim of SIMILE\nis to improve and optimize lake monitoring integrating\nconventional\
    \ monitoring, satellite data, in situ HFM data,\nand user-contributed georeferenced\
    \ data (Brovelli et al.,\n2020), specific aim of the HFM system is to make avail-\n\
    able high frequency data of basic limnological and mete-\norological parameters\
    \ in order to provide information on\nlake processes occurring over a short time\
    \ scale, such as\nalgal blooms, or weather-related episodic events. \nThe HFM\
    \ station LM1 was the first station developed\nwithin SIMILE (Fig. 1). In this\
    \ project framework, LM1\nrepresents a pilot experience, aimed at providing the\
    \ prac-\ntical know-how needed for the creation of the larger HFM\nsystem projected\
    \ in SIMILE. To enable the replicability\nand transferability of this first experience,\
    \ LM1 was con-\nceived as a low-cost modular system. Indeed, although\nfull-equipped\
    \ systems for HFM of water bodies are com-\nmercially available, their long-term\
    \ maintenance may be\ndifficult because the understanding of the hardware and\n\
    software components is often not an easy process. There-\nfore, an increasing\
    \ number of research groups are devel-\noping their own modular system independently\n\
    (Albaladejo et al., 2012; Tran Khac et al., 2018; Vitale et\nal., 2018): in-house\
    \ development provides the flexibility\nneeded to recover the system when malfunctioning\
    \ or\ndamages occur (Vitale et al., 2018) and to tweak its con-\nfiguration to\
    \ monitoring needs.\nIn this paper, we describe LM1 (software and hard-\nware\
    \ components, i.e., sensors, electronic devices, power\nsupply and transmission\
    \ systems), providing an example\nof a cost-effective and modular limnological\
    \ buoy for\nHFM. In addition, we used the first nine months of HFM\ndata to provide\
    \ examples of: i) field validation of sensor\ndata, comparing sensor readings\
    \ with in situ (multipara-\nmeter probe) and laboratory measurements; ii) the\
    \ most\nNon-commercial use only\njected for the lakes of the so-called Insubric\
    \ region (lakes\nNon-commercial use only\njected for the lakes of the so-called\
    \ Insubric region (lakes\nMaggiore, Como, and Lugano) and will be developed\n\
    Non-commercial use only\nMaggiore, Como, and Lugano) and will be developed\nNon-commercial\
    \ use only\nwithin the cross-border cooperation project SIMILE (Ital-\nNon-commercial\
    \ use only\nwithin the cross-border cooperation project SIMILE (Ital-\nian acronym\
    \ for “Integrated monitoring system for knowl-\nNon-commercial use only\nian acronym\
    \ for “Integrated monitoring system for knowl-\nedge, protection and valorisation\
    \ of the subalpine lakes\nNon-commercial use only\nedge, protection and valorisation\
    \ of the subalpine lakes\nand their ecosystems”). While the general aim of SIMILE\n\
    Non-commercial use only\nand their ecosystems”). While the general aim of SIMILE\n\
    is to improve and optimize lake monitoring integrating\nNon-commercial use only\n\
    is to improve and optimize lake monitoring integrating\nconventional monitoring,\
    \ satellite data, \nNon-commercial use only\nconventional monitoring, satellite\
    \ data, \nand user-contributed georeferenced data (Brovelli\nNon-commercial use\
    \ only\nand user-contributed georeferenced data (Brovelli\n2020), specific aim\
    \ of the HFM system is to make avail-\nNon-commercial use only\n2020), specific\
    \ aim of the HFM system is to make avail-\nNon-commercial use only\nthe drawbacks\
    \ of conventional monitoring, giving the op-\nNon-commercial use only\nthe drawbacks\
    \ of conventional monitoring, giving the op-\nportunity to measure an increasing\
    \ number of limnologi-\nNon-commercial use only\nportunity to measure an increasing\
    \ number of limnologi-\ncal and ecological parameters at unprecedented short\n\
    Non-commercial use only\ncal and ecological parameters at unprecedented short\n\
    temporal intervals and also during adverse meteorological\nNon-commercial use\
    \ only\ntemporal intervals and also during adverse meteorological\n, 2007; Le\
    \ Vu \nNon-commercial use only\n, 2007; Le Vu et\nNon-commercial use only\net\n\
    et al.\nNon-commercial use only\net al., 2012; Hamil-\nNon-commercial use only\n\
    , 2012; Hamil-\n, 2016). Over the past\nNon-commercial use only\n, 2016). Over\
    \ the past\ndecade, there has been a drastic increase in the use of au-\nNon-commercial\
    \ use only\ndecade, there has been a drastic increase in the use of au-\ntomated\
    \ collection of high-frequency data in scientific re-\nNon-commercial use only\n\
    tomated collection of high-frequency data in scientific re-\nsearch and environmental\
    \ monitoring (Horsburgh \nNon-commercial use only\nsearch and environmental monitoring\
    \ (Horsburgh \n2015). In addition, the installation of automated high fre-\nNon-commercial\
    \ use only\n2015). In addition, the installation of automated high fre-\nquency\
    \ monitoring (HFM) systems is often expected to\nNon-commercial use only\nquency\
    \ monitoring (HFM) systems is often expected to\nable high frequency data of basic\
    \ limnological and mete-\nNon-commercial use only\nable high frequency data of\
    \ basic limnological and mete-\norological parameters in order to provide information\
    \ on\nNon-commercial use only\norological parameters in order to provide information\
    \ on\nlake processes occurring over a short time scale, such as\nNon-commercial\
    \ use only\nlake processes occurring over a short time scale, such as\nalgal blooms,\
    \ or weather-related episodic events. \nNon-commercial use only\nalgal blooms,\
    \ or weather-related episodic events. \n43\nA high frequency monitoring system\
    \ for Lake Maggiore\ncommon source of errors in sensor data; and iii) the\nadopted\
    \ Quality Assurance and Quality Control proce-\ndures. This study mainly aimed\
    \ at developing a sound pro-\ntocol for HFM data collection, quality check, data\n\
    transmission, and storage within the SIMILE project. For\nthis reason, we have\
    \ focused on the approach adopted to\nget affordable HFM data, while the data\
    \ analysis will be\nthe subject of a later study within the SIMILE project\nonce\
    \ the whole data flow procedure will be established.\nThe information provided\
    \ by our study can be used in\nHFM monitoring of lakes to get affordable data,\
    \ to be in-\ntegrated into institutional monitoring programs of envi-\nronmental\
    \ agencies and research institutes.\nLAKE MAGGIORE, ITS MONITORING HISTORY\nAND\
    \ LONG-TERM DYNAMICS\nLake Maggiore is a large (surface area 213 km2; vol-\nume\
    \ 38.1 km3) and deep (370 m) subalpine lake located\nbetween Northern Italy and\
    \ Southern Switzerland (Fig.\n1). Its watershed (6,600 km2) is shared almost equally\
    \ be-\ntween the two countries while most of lake surface\n(~80%) lies in Italy.\
    \ Lake Maggiore has 33 inflows - main\ninflows are the Ticino and Toce Rivers\
    \ - and one outflow\n(Ticino River). Its theoretical water renewal time is 4.20\n\
    years. Lake level is controlled by the Miorina Dam to or-\ndinarily allow for\
    \ a 0.5 m difference between summer and\nwinter periods (Fenocchi et al., 2017).\n\
    Lake Maggiore has been regularly monitored on a\nmonthly base since 1978 with\
    \ the support of the Interna-\ntional Commission for the Protection of Swiss-Italian\
    \ Wa-\nters (CIPAIS; CNR-IRSA, 2019). Samples and measures\nwere taken at the\
    \ deepest point of the lake (Ghiffa station;\n45°58’30” N; 8°39’09” E). Since\
    \ 2019, a second moni-\ntoring site in Pallanza (100 m depth) has been included\
    \ in\nthe monitoring programme (Fig. 1). Monitoring at both\nstations include\
    \ 1) sampling for chemical and biological\nanalyses, and 2) a vertical profile\
    \ of temperature through\na multiparameter probe (Idronaut CTD304). Sampling for\n\
    chemical analyses involves the collection of 12 water\nsamples along the water\
    \ column at the Ghiffa station and\n3 samples at the Pallanza station. Samples\
    \ are routinely\nanalysed for the main chemical variables (pH, electrical\nconductivity,\
    \ alkalinity, major anions and cations, reactive\nand total phosphorus, ammonium,\
    \ total nitrogen, reactive\nsilica) at the water chemistry laboratory of the CNR\
    \ Water\nResearch Institute (CNR-IRSA) in Verbania using stan-\nFig. 1. LM1. a)\
    \ Description of the main components of LM1, parts in red are projected, not yet\
    \ present components. b) LM1 buoy. c)\nLocation of LM1 and of the long-term sampling\
    \ stations (white dots) in Lake Maggiore.\nNon-commercial use only\nanalyses,\
    \ and 2) a vertical profile of temperature through\nNon-commercial use only\n\
    analyses, and 2) a vertical profile of temperature through\na multiparameter probe\
    \ (Idronaut CTD304). Sampling for\nNon-commercial use only\na multiparameter probe\
    \ (Idronaut CTD304). Sampling for\nchemical analyses involves the collection of\
    \ 12 water\nNon-commercial use only\nchemical analyses involves the collection\
    \ of 12 water\nsamples along the water column at the Ghiffa station and\nNon-commercial\
    \ use only\nsamples along the water column at the Ghiffa station and\n3 samples\
    \ at the Pallanza station. Samples are routinely\nNon-commercial use only\n3 samples\
    \ at the Pallanza station. Samples are routinely\nanalysed for the main chemical\
    \ variables (pH, electrical\nNon-commercial use only\nanalysed for the main chemical\
    \ variables (pH, electrical\nconductivity, alkalinity, major anions and cations,\
    \ reactive\nNon-commercial use only\nconductivity, alkalinity, major anions and\
    \ cations, reactive\nand total phosphorus, ammonium, total nitrogen, reactive\n\
    Non-commercial use only\nand total phosphorus, ammonium, total nitrogen, reactive\n\
    Non-commercial use only\nsilica) at the water chemistry laboratory of the CNR\
    \ Water\nNon-commercial use only\nsilica) at the water chemistry laboratory of\
    \ the CNR Water\nResearch Institute (CNR-IRSA) in Verbania using stan-\nNon-commercial\
    \ use only\nResearch Institute (CNR-IRSA) in Verbania using stan-\nNon-commercial\
    \ use only\n44\nR. Tiberti et al.\ndard methods for freshwater samples (APHA,\
    \ AWWA,\nWEF 2012; APAT IRSA-CNR 2003). In addition, Chloro-\nphyll-a concentrations\
    \ are determined fluorometrically\n(Fluoroprobe BBE Moldaenke) in an integrated\
    \ sample\nthrough the 0-20 m layer. Integrated phytoplankton sam-\nples for biovolume\
    \ and density through the 0-20 m layer\nare also collected (CNR- IRSA, 2019).\n\
    Because of its long monitoring history, Lake Maggiore\nwas included in the Long-Term\
    \ Ecological Research Net-\nwork - LTER site “Southern Alpine Lakes” (LTER\n_EU_IT_008),\
    \ also comprising lakes Orta, Como, Iseo,\nand Garda. These lakes are located\
    \ south of the Alps, in\none of the most densely populated and urbanized areas\
    \ of\nEurope. They represent a strategic water supply for agri-\nculture, industry,\
    \ fishing, and civil use and are an impor-\ntant resource for recreation and tourism\
    \ (Salmaso and\nMosello, 2010). Long-term trends in trophic state and\nother chemical\
    \ and biological variables of the deep sub-\nalpine lakes have been assessed in\
    \ a series of synoptic\nstudies (Salmaso and Mosello, 2010; Rogora et al., 2018;\n\
    Salmaso et al., 2020).\nAccording to long-term monitoring data, the most rel-\n\
    evant changes in Lake Maggiore include oligotrophication\nand increased thermal\
    \ stability. Lake Maggiore has un-\ndergone oligotrophication since the 1980s\
    \ due to reduced\nexternal nutrient loads. The lake is presently oligo-\nmesotrophic,\
    \ with annual average total phosphorus con-\ncentration of 12-13 µg P L–1 (Rogora\
    \ et al., 2018). Trends\nof phytoplankton biomass and chlorophyll concentrations\n\
    confirmed the oligotrophication of the lake (Morabito et\nal., 2012). After the\
    \ last episode of complete mixing in\n2005-2006 due to exceptionally cold and\
    \ windy winter\nconditions (Ambrosetti and Barbanti, 1999), a tendency\ntowards\
    \ increasing stability of the water column and de-\ncreasing mixing depth has\
    \ been reported as an effect of\nclimate warming (Rogora et al., 2018). The effects\
    \ of cli-\nmate change on Lake Maggiore have been extensively de-\nscribed and\
    \ involve both the hydrodynamic and thermal\nfeatures of the lake (Fenocchi et\
    \ al., 2018) as well as its\ntrophic and oxygen status (Rogora et al., 2018) and\
    \ vari-\nous biological compartments (Morabito et al., 2012, 2018;\nNõges et al.,\
    \ 2017; Tanentzap et al., 2020). As regards\nphytoplankton, while nutrient inputs\
    \ were the main driv-\ners of its dynamics until the early 1990s, climatic factors\n\
    started to play an important role during the oligotrophi-\ncation phase (Morabito\
    \ et al., 2012).\nUntil present, monitoring of Lake Maggiore has been\nbased on\
    \ the conventional sampling methods described\nabove (CNR-IRSA 2019; Rogora et\
    \ al., 2018) and HFM\nhas been limited to meteorological and hydrological vari-\n\
    ables. However, recent evidence of the relevance of rapid\necological changes\
    \ and extreme meteorological events\nprompted the idea that more frequent limnological\
    \ data are\nneeded to describe and timely predict fast-paced processes\n(Morabito\
    \ et al., 2018), such as algal blooms in spring and\nsummer (Callieri et al.,\
    \ 2014; Tapolczai et al., 2015).\nTHE HFM SYSTEM\nHardware: the buoy, power supply,\
    \ sensors,\nand data transmission \nLM1 buoy is located in the Pallanza basin,\
    \ at about 50\nm from the shoreline (latitude N 45.92440°; longitude E\n8.54774°;\
    \ Fig. 1), anchored to three concrete blocks by\nsteel chains at a depth of about\
    \ 40 m. Two 50-Watt solar\npanels give electricity to a lead battery (50 A/h),\
    \ which\nsupplies all the power needed by the HFM system includ-\ning the electronic\
    \ control unit, the submerged sensors, the\nmeteorological station (model gmx501,\
    \ Gill Instruments,\nplaced on the top of the buoy), the system for data trans-\n\
    mission and a security signal light. \nAt present, LM1 is equipped with sensors\
    \ for water\ntemperature, pH, dissolved oxygen, conductivity, chloro-\nphyll-a\
    \ (Tab. 1). Sensors are held inside a stainless-steel\nguard placed 2.5 meters\
    \ beneath the lake surface; an ad-\nTab. 1. Characteristics of the sensors presently\
    \ installed on the LM1 buoy in Lake Maggiore.\nVariable                      \
    \          Sensor (manufacturer)              Measuring principle/technology \
    \              Range                      Resolution/accuracy\nTemperature*  \
    \                      PHEHT, C4E, OPTOD                NTC (Negative Temperature\
    \                        0-50°C                     0.01±0.5°C\n             \
    \                                 (Ponsel/Aqualabo)                      Coefficient)\
    \ thermistors\npH/Redox                              PHEHT (Ponsel/Aqualabo) \
    \        Combined electrode (pH/reference):           0-14                   \
    \       0.01±0.10\n                                                          \
    \                                         special glass, Ag/AgCl ref.,       \
    \                  \n                                                        \
    \                                           gelled electrolyte (KCl)         \
    \                      \nElectrical conductivity          C4E (Ponsel/Aqualabo)\
    \               Conductivity sensor with                             0-200 µS\
    \ cm–1                0.01±2.00 µS cm–1\n                                    \
    \                                                               4 electrodes (2\
    \ graphic, 2 platinum)            at 25°C                     \nDissolved oxygen\
    \                  OPTOD (Ponsel/Aqualabo)        Optical measure with luminescence\
    \            0-20 mg L–1              0.01±0.10 mg L–1\n                     \
    \                                                                            \
    \                                                                       (0-200%)\
    \                  \nChlorophyll-a                        Cyclops-7 (Turner design)\
    \          Fluorescence                                                0-50 µg\
    \ L–1                        <0.008±0.030 µg L–1\n*A NTC thermistor is included\
    \ in each of the Ponsel sensor (for pH, conductivity, and dissolved oxygen). In\
    \ our evaluation period we refer to these\ntemperature sensors. We plan to add\
    \ a thermistor chain with PT100 (Platinum resistance thermometers) to the buoy\
    \ (Fig. 1).\nNon-commercial use only\necological changes and extreme meteorological\
    \ events\nNon-commercial use only\necological changes and extreme meteorological\
    \ events\nprompted the idea that more frequent limnological data are\nNon-commercial\
    \ use only\nprompted the idea that more frequent limnological data are\nNon-commercial\
    \ use only\nmesotrophic, with annual average total phosphorus con-\nNon-commercial\
    \ use only\nmesotrophic, with annual average total phosphorus con-\n, 2018). Trends\n\
    Non-commercial use only\n, 2018). Trends\nof phytoplankton biomass and chlorophyll\
    \ concentrations\nNon-commercial use only\nof phytoplankton biomass and chlorophyll\
    \ concentrations\nconfirmed the oligotrophication of the lake (Morabito \nNon-commercial\
    \ use only\nconfirmed the oligotrophication of the lake (Morabito et\nNon-commercial\
    \ use only\net\n, 2012). After the last episode of complete mixing in\nNon-commercial\
    \ use only\n, 2012). After the last episode of complete mixing in\n2005-2006 due\
    \ to exceptionally cold and windy winter\nNon-commercial use only\n2005-2006 due\
    \ to exceptionally cold and windy winter\nconditions (Ambrosetti and Barbanti,\
    \ 1999), a tendency\nNon-commercial use only\nconditions (Ambrosetti and Barbanti,\
    \ 1999), a tendency\ntowards increasing stability of the water column and de-\n\
    Non-commercial use only\ntowards increasing stability of the water column and\
    \ de-\ncreasing mixing depth has been reported as an effect of\nNon-commercial\
    \ use only\ncreasing mixing depth has been reported as an effect of\net al.\n\
    Non-commercial use only\net al., 2018). The effects of cli-\nNon-commercial use\
    \ only\n, 2018). The effects of cli-\nmate change on Lake Maggiore have been extensively\
    \ de-\nNon-commercial use only\nmate change on Lake Maggiore have been extensively\
    \ de-\nscribed and involve both the hydrodynamic and thermal\nNon-commercial use\
    \ only\nscribed and involve both the hydrodynamic and thermal\nneeded to describe\
    \ and timely predict fast-paced processes\nNon-commercial use only\nneeded to\
    \ describe and timely predict fast-paced processes\n, 2018), such as algal blooms\
    \ in spring and\nNon-commercial use only\n, 2018), such as algal blooms in spring\
    \ and\net al.\nNon-commercial use only\net al., 2014; Tapolczai \nNon-commercial\
    \ use only\n, 2014; Tapolczai \nNon-commercial use only\nTHE HFM SYSTEM\nNon-commercial\
    \ use only\nTHE HFM SYSTEM\nHardware: the buoy, power supply, sensors,\nNon-commercial\
    \ use only\nHardware: the buoy, power supply, sensors,\nand data transmission\
    \ \nNon-commercial use only\nand data transmission \nLM1 buoy is located in the\
    \ Pallanza basin, at about 50\nNon-commercial use only\nLM1 buoy is located in\
    \ the Pallanza basin, at about 50\nm from the shoreline (latitude N 45.92440°;\
    \ longitude E\nNon-commercial use only\nm from the shoreline (latitude N 45.92440°;\
    \ longitude E\n8.54774°; Fig. 1), anchored to three concrete blocks by\nNon-commercial\
    \ use only\n8.54774°; Fig. 1), anchored to three concrete blocks by\nsteel chains\
    \ at a depth of about 40 m. Two 50-Watt solar\nNon-commercial use only\nsteel\
    \ chains at a depth of about 40 m. Two 50-Watt solar\n45\nA high frequency monitoring\
    \ system for Lake Maggiore\nditive sensor for chlorophyll-a concentration is placed\
    \ at\na depth of about 8 m. Each sensor is wire connected to the\nelectronic control\
    \ unit and waterproofed connectors. Fur-\nther sensors (for turbidity/TSS, phycocyanin\
    \ and phyco-\nerythrin, at 2.5 m depth; dissolved oxygen, at 30 m depth)\nand\
    \ a webcam have been added to LM1 in March 2021\n(i.e., after the study period);\
    \ a thermistor chain is planned\nto be added during the project.\nThe electronic\
    \ control unit is protected by a waterproof\nbox inside the buoy and is accessible\
    \ from outside the buoy\nby lifting a lid. The electronic control unit has been\
    \ specif-\nically designed for signal acquisition from the sensors, data\nstorage,\
    \ basic data elaboration and wireless transfer. The\nelectronic motherboard includes\
    \ a power supply board, a\nBeagle Back CPU board (Processor: AM335x 1GHz\nARM®\
    \ Cortex-A8), serial boards for sensor data acquisi-\ntion, high-resolution input\
    \ boards ADC, and boards for\nwireless communication and solar panel management.\
    \ \nSoftware: two tiers’ data storage using IstSOS \nThe CPU board support a Linux\
    \ system allowing the\nfollowing tasks:\n•\nLocal data storage (on USB support);\n\
    •\nReal/near real time data transfer through Ethernet,\n3G/GPRS modem or radio;\
    \ \n•\nElaboration/aggregation of local data and transfer of,\ne.g., daily report;\n\
    •\nRemote reconfiguration and software update. \nDuring the test period (December\
    \ 2019-September\n2020), raw data were stored in daily csv files at 1 min fre-\n\
    quency and transmitted via wireless connection to the\nCNR-IRSA server. These\
    \ data were used to assess differ-\nent aspects of the system functioning (e.g.,\
    \ sensor calibra-\ntion, remote and field controls, problems related to sensor\n\
    drift and fouling), and how to manage them. Furtherly,\ndata gathered during the\
    \ test period were used to test\nQuality Assurance/Quality Control (QA/QC) procedures\n\
    to be successively adopted in the whole HFM system. In\nparticular, data quality\
    \ issues will be implemented in Ist-\nSOS, the open-source data management software\
    \ selected\nfor the HFM system (Fig. 2). IstSOS was selected due to\nits specific\
    \ features specialized in hydro-climate data\nmanagement (Pozzoni et al., 2020;\
    \ Strigaro et al., 2019).\nIstSOS is a python implementation of the Sensor Obser-\n\
    vation Service standard (SOS) from the Open Geospatial\nConsortium (OGC), which\
    \ defines a web service interface\nto register and retrieve metadata and observations\
    \ of sen-\nsors using a standard protocols and formats, in order to\nincrease\
    \ the data consistency and interoperability. Among\nthe numerous features of IstSOS\
    \ (Cannata et al., 2015),\nnative support of data quality management is one of\
    \ the\nmost important for this application since it allows to de-\nvelop data\
    \ quality control procedures that associates ob-\nservations with quality index\
    \ (QI) that can be later used\nto filter or properly weight observations in subsequent\n\
    elaborations. In IstSOS each registered observation is\nstrictly bonded to a code\
    \ (QI) that identifies the latest\nquality check test performed and successfully\
    \ passed. The\ntests will be divided into 4 main categories:\n•\nTests performed\
    \ on raw data coming from the sensor;\n•\nChecks performed on aggregated data;\n\
    •\nStatistical tests on the time-series;\n•\nHuman driven tests and the final\
    \ ‘correct’ flag.\nFig. 2. Web interface of the data viewer of IstSOS showing\
    \ data flowing from LM1.\nNon-commercial use only\n•\nReal/near real time data\
    \ transfer through Ethernet,\nNon-commercial use only\n•\nReal/near real time\
    \ data transfer through Ethernet,\n•\nElaboration/aggregation of local data and\
    \ transfer of,\nNon-commercial use only\n•\nElaboration/aggregation of local data\
    \ and transfer of,\n•\nRemote reconfiguration and software update. \nNon-commercial\
    \ use only\n•\nRemote reconfiguration and software update. \nDuring the test period\
    \ (December 2019-September\nNon-commercial use only\nDuring the test period (December\
    \ 2019-September\n2020), raw data were stored in daily csv files at 1 min fre-\n\
    Non-commercial use only\n2020), raw data were stored in daily csv files at 1 min\
    \ fre-\nquency and transmitted via wireless connection to the\nNon-commercial\
    \ use only\nquency and transmitted via wireless connection to the\nConsortium\
    \ (OGC), which defines a web service interface\nNon-commercial use only\nConsortium\
    \ (OGC), which defines a web service interface\nto register and retrieve metadata\
    \ and observations of sen-\nNon-commercial use only\nto register and retrieve\
    \ metadata and observations of sen-\nsors using a standard protocols and formats,\
    \ in order to\nNon-commercial use only\nsors using a standard protocols and formats,\
    \ in order to\nincrease the data consistency and interoperability. Among\nNon-commercial\
    \ use only\nincrease the data consistency and interoperability. Among\nthe numerous\
    \ features of IstSOS (Cannata \nNon-commercial use only\nthe numerous features\
    \ of IstSOS (Cannata \nnative support of data quality management is one of the\n\
    Non-commercial use only\nnative support of data quality management is one of the\n\
    most important for this application since it allows to de-\nNon-commercial use\
    \ only\nmost important for this application since it allows to de-\nvelop data\
    \ quality control procedures that associates ob-\nNon-commercial use only\nvelop\
    \ data quality control procedures that associates ob-\nservations with quality\
    \ index (QI) that can be later used\nNon-commercial use only\nservations with\
    \ quality index (QI) that can be later used\nto filter or properly weight observations\
    \ in subsequent\nNon-commercial use only\nto filter or properly weight observations\
    \ in subsequent\nelaborations. In IstSOS each registered observation is\nNon-commercial\
    \ use only\nelaborations. In IstSOS each registered observation is\nstrictly bonded\
    \ to a code (QI) that identifies the latest\nNon-commercial use only\nstrictly\
    \ bonded to a code (QI) that identifies the latest\nNon-commercial use only\n\
    Non-commercial use only\n46\nR. Tiberti et al.\nThe quality check tests are performed\
    \ consequentially\nbased on an increasing level of quality evaluation. The\nIstSOS’s\
    \ web interface allows to register new QC tests,\nsuch as those proposed in this\
    \ work. Thanks to the light-\nweight of IstSOS and to the availability of a CPU\
    \ support\nand a Linux system, it will be possible to install IstSOS\ndirectly\
    \ on the monitoring buoys/platforms. It will act as\na local data storage system\
    \ dedicated to collect and serve\nraw data using standards and perform preliminary\
    \ quality\nchecks directly at the node before data are transmitted to\nthe data\
    \ warehouse. To this end, a standard communica-\ntion between two IstSOS instances\
    \ is enabled. The de-\nscribed two tiers’ data storage approach is depicted in\
    \ Fig.\n3. The general data flow is divided into a tier at sensor\nside (buoy)\
    \ and a tier at server side (data centre). At the\nbuoy, data are collected from\
    \ sensors and then checked\nfor range and step tests. After that, raw observations\
    \ and\nrelated QC codes are inserted into the IstSOS instance in-\nstalled at\
    \ the buoy. At a specific configurable time interval\n(suggested between 10 and\
    \ 30 mins), an algorithm re-\ntrieves raw data from IstSOS, performs quality checks,\n\
    aggregates and store resulting values with related quality\ncode back to IstSOS.\
    \ At user-defined interval data are then\ntransmitted from the buoy to the data\
    \ centre using selected\nprotocol (WiFi, LoRa, NBIoT, 4G) and SOS standard re-\n\
    quests to directly ingest them into the second tier IstSOS\ninstance. Instantly,\
    \ ingested observations are accessible\nfor intensive processing such as for example\
    \ the creation\nof reports, additional data validation tests, the calculation\n\
    of indicators, scientific analysis, alert notifications, fore-\ncast analysis\
    \ and client interfaces creation. This approach\npermits to locally store high\
    \ frequency data and commu-\nnicate aggregated data at an adequate frequency for\
    \ the\npurpose of the monitoring. However, high-frequency data\nare also transmitted\
    \ at fixed intervals (daily in the case of\nLM1 buoy) for raw data backup on a\
    \ local server. This so-\nlution reduces battery consumption, bandwidth usage\
    \ and\ntransmission costs.\nQUALITY ASSURANCE AND QUALITY\nCONTROL PROCEDURES\
    \ FOR SENSOR DATA\nBackground and definitions\nAlthough HFM by sensor networks\
    \ can provide many\nbenefits, sensors are susceptible to some inevitable levels\n\
    of failure, which can result in lost or poor-quality data\n(Campbell et al., 2013).\
    \ It may be therefore inappropriate\nto make HFM data available to the public/users\
    \ in their\nraw form before checking them, or without having taken\ncare of the\
    \ correct functioning of the entire HFM system.\nEstablishing proper QA/QC routines\
    \ guarantees that\nused/released data meet the expected quality standards\nand,\
    \ at the same time, provides data usage protection.\nQA/QC procedures are adopted\
    \ to minimize errors in data\nstreaming from the HFM system and to document the\n\
    overall quality of the data. QA and QC are closely related,\nbut they have distinct\
    \ meanings: in our specific context:\nwe define 1) QA as the procedures taken\
    \ to ensure that\nthe HFM system and its maintenance protocols are devel-\noped\
    \ in a way to minimize data loss, sensor errors and the\nneed of subsequent corrective\
    \ measures on data, and 2)\nQC as the procedures to test whether streaming data\
    \ meet\nthe expected quality standards including passing a series\nFig. 3. Data\
    \ flow from the monitoring system to server-side architecture.\nNon-commercial\
    \ use only\nof failure, which can result in lost or poor-quality data\nNon-commercial\
    \ use only\nof failure, which can result in lost or poor-quality data\n, 2013).\
    \ It may be therefore inappropriate\nNon-commercial use only\n, 2013). It may\
    \ be therefore inappropriate\nto make HFM data available to the public/users in\
    \ their\nNon-commercial use only\nto make HFM data available to the public/users\
    \ in their\nraw form before checking them, or without having taken\nNon-commercial\
    \ use only\nraw form before checking them, or without having taken\ncare of the\
    \ correct functioning of the entire HFM system.\nNon-commercial use only\ncare\
    \ of the correct functioning of the entire HFM system.\nEstablishing proper QA/QC\
    \ routines guarantees that\nNon-commercial use only\nEstablishing proper QA/QC\
    \ routines guarantees that\nused/released data meet the expected quality standards\n\
    Non-commercial use only\nused/released data meet the expected quality standards\n\
    and, at the same time, provides data usage protection.\nNon-commercial use only\n\
    and, at the same time, provides data usage protection.\nQA/QC procedures are adopted\
    \ to minimize errors in data\nNon-commercial use only\nQA/QC procedures are adopted\
    \ to minimize errors in data\nstreaming from the HFM system and to document the\n\
    Non-commercial use only\nstreaming from the HFM system and to document the\nNon-commercial\
    \ use only\nfor intensive processing such as for example the creation\nNon-commercial\
    \ use only\nfor intensive processing such as for example the creation\nof reports,\
    \ additional data validation tests, the calculation\nNon-commercial use only\n\
    of reports, additional data validation tests, the calculation\nof indicators,\
    \ scientific analysis, alert notifications, fore-\nNon-commercial use only\nof\
    \ indicators, scientific analysis, alert notifications, fore-\ncast analysis and\
    \ client interfaces creation. This approach\nNon-commercial use only\ncast analysis\
    \ and client interfaces creation. This approach\npermits to locally store high\
    \ frequency data and commu-\nNon-commercial use only\npermits to locally store\
    \ high frequency data and commu-\noverall quality of the data. QA and QC are closely\
    \ related,\nNon-commercial use only\noverall quality of the data. QA and QC are\
    \ closely related,\nbut they have distinct meanings: in our specific context:\n\
    Non-commercial use only\nbut they have distinct meanings: in our specific context:\n\
    we define 1) QA as the procedures taken to ensure that\nNon-commercial use only\n\
    we define 1) QA as the procedures taken to ensure that\nthe HFM system and its\
    \ maintenance protocols are devel-\nNon-commercial use only\nthe HFM system and\
    \ its maintenance protocols are devel-\noped in a way to minimize data loss, sensor\
    \ errors and the\nNon-commercial use only\noped in a way to minimize data loss,\
    \ sensor errors and the\nNon-commercial use only\nNon-commercial use only\n47\n\
    A high frequency monitoring system for Lake Maggiore\nof semi-automated QC tests\
    \ (see paragraph “QC proce-\ndures”) and an expert-based inspection. QC procedures\n\
    are necessary to make sure that field data measurements\nare right on (i.e., accurate),\
    \ reproducible (precise; consis-\ntent), and have a good estimate of their uncertainty.\
    \ As-\nsociate to proper QA protocols, QC is essential to produce\nreliable data.\
    \ \nErrors in high frequency long-term datasets primarily\noccur from sensor biofouling\
    \ and calibration shift; but er-\nrors may also occur for many other reasons (Wagner\
    \ et\nal., 2006). In Fig. 4 we provide some examples from LM1\nof the most common\
    \ types of error in hydrological and\nwater quality sensor data:\n•\nSkipped or\
    \ no-data values when there are gaps in the\ndata (Fig. 4a). \n•\nSensor drift,\
    \ occurring because electronic drift in sen-\nsors reading away from the instrument’s\
    \ calibration dur-\ning the period between calibrations (Fig. 4b). This may\n\
    also occur due to the aging of parts of the sensor, e.g.,\nmembrane aging or dye\
    \ degradation in oxygen sensors.\n•\nOut of range values, when data values are\
    \ beyond the\nrange of plausible values for the specific phenomenon\nbeing measured\
    \ (Fig. 4c). \n•\nSensor fouling due to biological growth (biofouling;\nFig. 4d)\
    \ or other residue build-up on the sensor be-\ntween maintenance visits (i.e.,\
    \ sensor cleaning), which\ncan produce erroneous values and data truncation, i.e.,\n\
    when data values are recorded at the reporting limit\nfor a sensor because its\
    \ maximum or minimum record-\ning level has been exceeded. \n•\nFailed sensor,\
    \ that is an error occurring when sensor\nfails (e.g., Chl-a sensor fails, and\
    \ the system records a\nvalue equal to 0; Fig. 4e). \n•\nIncorrect offset or calibration,\
    \ when data values are in\nerror by a constant value. \n•\nData value persistence,\
    \ when data show constant val-\nues that are recorded when a sensor becomes stuck\
    \ in\na single position or when a sensor fails and the data-\nlogger repeatedly\
    \ records the last measured value. \n•\nPower failure, when the power supply fails\
    \ to provide\nFig. 4. Example of pre-processed data series from LM1 with i) data\
    \ flags based on semi-automated quality control (see paragraph Semi-\nautomated\
    \ QC controls), ii) results of in situ and laboratory quality assurance measures\
    \ (see paragraph Is LM1 working well? Field\ncontrols and periodic reporting),\
    \ and iii) sensor cleaning dates (vertical grey lines). Red boxes highlight some\
    \ common sources of error:\na. missing data can occur for electric supply and\
    \ memory saturation issues; b. pH sensor underwent a drift, but it was recovered\
    \ by re-\ncalibration in July 2020; c. pH values not complying with the local\
    \ range criteria were flagged, but, in this case, they represent extreme\nbut\
    \ accurate values, as shown by their good match with QA measures; d. fouling is\
    \ a common source of error for Chl-a sensor and it\nbecomes clear if sensor values\
    \ decrease abruptly after sensor cleaning; if data reach the reporting limits\
    \ of the sensor, data truncation\ncan be observed; e. Chl-a sensor fails produced\
    \ anomalous zero values. \nNon-commercial use only\nerror by a constant value.\
    \ \nNon-commercial use only\nerror by a constant value. \n•\nData value persistence,\
    \ when data show constant val-\nNon-commercial use only\n•\nData value persistence,\
    \ when data show constant val-\nues that are recorded when a sensor becomes stuck\
    \ in\nNon-commercial use only\nues that are recorded when a sensor becomes stuck\
    \ in\na single position or when a sensor fails and the data-\nNon-commercial use\
    \ only\na single position or when a sensor fails and the data-\nlogger repeatedly\
    \ records the last measured value. \nNon-commercial use only\nlogger repeatedly\
    \ records the last measured value. \n•\nPower failure, when the power supply fails\
    \ to provide\nNon-commercial use only\n•\nPower failure, when the power supply\
    \ fails to provide\nNon-commercial use only\nNon-commercial use only\n48\nR. Tiberti\
    \ et al.\nthe required levels of power to a sensor resulting in\nsuspect measurements.\
    \ \n•\nAdverse site conditions, when conditions immediately\nsurrounding the sensor\
    \ are not representative of the\nsite (e.g., sediment build-up in a sensor cup,\
    \ ice build-\nup around a sensor).\nSince error accumulation can rapidly disrupt\
    \ data se-\nries, producing reliable HFM data requires that such errors\nare:\
    \ i) avoided, through appropriate QA procedures; ii)\nidentified, by correct QC\
    \ procedures; and iii) eventually\ncorrected through interactive editing to mitigate\
    \ for error\noccurrence (Mourad and Bertrand-Krajewski, 2002). In\nparticular,\
    \ QA and QC procedures are strictly intercon-\nnected, because the identification\
    \ of errors and function-\ning anomalies by QC procedures provide up to date\n\
    information to ensure the proper maintenance and func-\ntioning of the system.\
    \ Our QA/QC procedures include all\nthe calibration, performance verification,\
    \ and mainte-\nnance of LM1.\nQA procedures\nSensor calibration in laboratory\
    \ \nBefore installation, all the sensors underwent a labo-\nratory calibration.\
    \ Calibration of pH, conductivity and\noxygen sensors were done according to the\
    \ provision of\nthe manufacturers, using pH buffers and standard solu-\ntions.\
    \ The calibration of the chlorophyll sensors was per-\nformed using dilution series\
    \ of single-species cultures of\nChlorella sp. (Chlorophyta). We utilized two\
    \ different\nchlorophyll sensors, by the same manufacturer (Turner\nDesign), to\
    \ assess whether their performance was similar\nand hold common calibration coefficients.\
    \ The phyto-\nplankton culture was added to filtered lake water (What-\nman glass\
    \ fibre filters, GF/C with a nominal porosity of\nca. 1 µm) using 12 litres black\
    \ buckets, with non-reflec-\ntive linear surface. Five algal dilutions were used,\
    \ cover-\ning a Chl-a range of about 0-30 µg L–1. During\nmeasurements, Chl-a\
    \ sensors were held 1 cm beneath the\nsurface of the sample and an automatic mixer\
    \ used. Read-\nings were taken once the instruments had stabilized (after\nca.\
    \ 10 s). The sensors were rinsed and dried thoroughly\nbetween control (MilliQ\
    \ water and filtered lake water) and\ntest samples measurements. Sensor fluorescence\
    \ (F; in\nVolt) were plotted against Chl-a concentrations ([Chl-a];\nin µg L–1)\
    \ obtained by spectrophotometric reading after\nacetone extraction (APAT IRSA-CNR,\
    \ 2003). The sensors\nyielded a linear response up to the highest chlorophyll\n\
    concentration tested. However, performance of the two\nchlorophyll sensors differed\
    \ slightly, resulting in different\nregression equations: [Chl-a 1] = 7.01 F -\
    \ 0.3053, R2 =\n0.998; [Chl-a 2] = 11.421 F - 0.2078, R2 = 0.999. It is thus\n\
    evident that, when dealing with field fluorescent sensors,\neach chlorophyll sensor\
    \ needs to be calibrated individu-\nally. These regression equations were provisionally\
    \ set to\nconvert sensor readings into Chl-a concentrations, subject\nto confirmation\
    \ by field validation. \nIs LM1 working? Remote control\nAn operator oversees\
    \ controlling that LM1 is working\nand sending data properly on a daily basis.\
    \ This procedure\ngreatly limits the possibility of losing data but does not\n\
    allow it to detect malfunctioning in real time. To over-\ncome this problem, we\
    \ created an automated procedure\nto query LM1 every 10 minutes and to send an\
    \ email\nalarm message in case HFM data is not received by the\nserver associated\
    \ with LM1. Such alarm indicates that\nwireless transmission failed and does not\
    \ necessarily\nimply the loss of sensor data. If the problem is limited to\nthe\
    \ transmission system, data can be recovered from a\nlocal memory placed on LM1\
    \ exactly to fix this eventual\nproblem. However, if transmission fails because\
    \ power\nsupply problems or local memory saturation, data cannot\nbe recorded,\
    \ and a timely intervention may save a lot of\ndata. This system allows us to\
    \ intervene promptly, mini-\nmize the loss of data, and detect functioning problems.\n\
    Is LM1 working well? Field controls\nand periodic reporting\nThe correct functioning\
    \ of LM1 was assessed by pe-\nriodic field validations, to test the consistency\
    \ between\nsensor data and data from standard monitoring methods.\nTab. 2 provides\
    \ the activity-log of the field surveys to the\nLM1 buoy. Data from field and\
    \ laboratory measurements\nwere compared with sensor data in order to i) check\
    \ their\naccuracy; ii) recalibrate sensors, when necessary; iii) cor-\nrect sensor\
    \ data when possible.\nField surveys were planned approximately on a bi-\nmonthly\
    \ basis, unless urgent maintenance was required\n(e.g., based on remote controls).\
    \ However, to preserve one\nof the main advantages of HFM (i.e., keeping monitoring\n\
    costs low), we tried to reduce the number of field surveys\nwhen possible, e.g.,\
    \ in periods of low lake productivity\n(winter), when biofouling was likely to\
    \ be less severe and\nfrequent sensor cleaning unnecessary. \nTo check sensor\
    \ data accuracy and get information for\nsubsequent field surveys planning, HFM\
    \ data underwent\nperiodic reporting. A mechanism for periodic reporting is\n\
    an essential part of QA procedures (von Lehmde and Nel-\nson, 1977). A weekly\
    \ report was produced to provide an\neasy visualization of the comparison between\
    \ sensor data\nand conventional monitoring data. Each weekly report is\na description\
    \ of the dynamics of the HFM sensor data col-\nlected over the previous two weeks\
    \ (reporting period).\nThe core part of the reports is a comparison between sen-\n\
    sor data and QA data collected by conventional monitor-\ning methods (infrequent\
    \ in situ observations and\nNon-commercial use only\nwireless transmission failed\
    \ and does not necessarily\nNon-commercial use only\nwireless transmission failed\
    \ and does not necessarily\nimply the loss of sensor data. If the problem is limited\
    \ to\nNon-commercial use only\nimply the loss of sensor data. If the problem is\
    \ limited to\nthe transmission system, data can be recovered from a\nNon-commercial\
    \ use only\nthe transmission system, data can be recovered from a\nlocal memory\
    \ placed on LM1 exactly to fix this eventual\nNon-commercial use only\nlocal memory\
    \ placed on LM1 exactly to fix this eventual\nNon-commercial use only\nthe manufacturers,\
    \ using pH buffers and standard solu-\nNon-commercial use only\nthe manufacturers,\
    \ using pH buffers and standard solu-\ntions. The calibration of the chlorophyll\
    \ sensors was per-\nNon-commercial use only\ntions. The calibration of the chlorophyll\
    \ sensors was per-\nformed using dilution series of single-species cultures of\n\
    Non-commercial use only\nformed using dilution series of single-species cultures\
    \ of\nsp. (Chlorophyta). We utilized two different\nNon-commercial use only\n\
    sp. (Chlorophyta). We utilized two different\nchlorophyll sensors, by the same\
    \ manufacturer (Turner\nNon-commercial use only\nchlorophyll sensors, by the same\
    \ manufacturer (Turner\nDesign), to assess whether their performance was similar\n\
    Non-commercial use only\nDesign), to assess whether their performance was similar\n\
    and hold common calibration coefficients. The phyto-\nNon-commercial use only\n\
    and hold common calibration coefficients. The phyto-\nplankton culture was added\
    \ to filtered lake water (What-\nNon-commercial use only\nplankton culture was\
    \ added to filtered lake water (What-\nman glass fibre filters, GF/C with a nominal\
    \ porosity of\nNon-commercial use only\nman glass fibre filters, GF/C with a nominal\
    \ porosity of\nca. 1 µm) using 12 litres black buckets, with non-reflec-\nNon-commercial\
    \ use only\nca. 1 µm) using 12 litres black buckets, with non-reflec-\ntive linear\
    \ surface. Five algal dilutions were used, cover-\nNon-commercial use only\ntive\
    \ linear surface. Five algal dilutions were used, cover-\ning a Chl-a range of\
    \ about 0-30 µg L\nNon-commercial use only\ning a Chl-a range of about 0-30 µg\
    \ L\nproblem. However, if transmission fails because power\nNon-commercial use\
    \ only\nproblem. However, if transmission fails because power\nsupply problems\
    \ or local memory saturation, data cannot\nNon-commercial use only\nsupply problems\
    \ or local memory saturation, data cannot\nbe recorded, and a timely intervention\
    \ may save a lot of\nNon-commercial use only\nbe recorded, and a timely intervention\
    \ may save a lot of\ndata. This system allows us to intervene promptly, mini-\n\
    Non-commercial use only\ndata. This system allows us to intervene promptly, mini-\n\
    mize the loss of data, and detect functioning problems.\nNon-commercial use only\n\
    mize the loss of data, and detect functioning problems.\nIs LM1 working well?\
    \ Field controls\nNon-commercial use only\nIs LM1 working well? Field controls\n\
    and periodic reporting\nNon-commercial use only\nand periodic reporting\nThe correct\
    \ functioning of LM1 was assessed by pe-\nNon-commercial use only\nThe correct\
    \ functioning of LM1 was assessed by pe-\nriodic field validations, to test the\
    \ consistency between\nNon-commercial use only\nriodic field validations, to test\
    \ the consistency between\n49\nA high frequency monitoring system for Lake Maggiore\n\
    sampling, and laboratory analyses). Reports contain a\ngraphical representation\
    \ of the recent dynamics of sensor\ndata and an assessment of sensor data quality\
    \ based on\nsemi-automated QC procedures (see paragraph “Quality\ncontrols”),\
    \ their deviation from QA monitoring results,\nand an expert opinion on the data\
    \ quality and desirable\ntreatment for low-quality data (e.g., data correction\
    \ or\ndeletion). \nData validation in the field\nOnce placed in the field, sensors\
    \ should be checked\nfor calibration and, when necessary, re-calibrated. Accord-\n\
    ing to Wagner et al. (2006), field calibration is done by\nusing calibration standards\
    \ (i.e., solutions of known qual-\nity) during field visits. This procedure ensures\
    \ that sensor\nreadings are correct and provides necessary data for re-\ncalibration.\
    \ We periodically performed such calibration\nchecks to recalibrate the pH and\
    \ conductivity sensors\n(Tab. 1). For all the sensors, instead -or in addition\
    \ to- cal-\nibration standards, we used field data obtained from in\nsitu and\
    \ laboratory measurements (QA). This was done\nbecause i) we were particularly\
    \ interested in assessing the\nperformance of the sensors in the field and in\
    \ comparing\nthem to the methods conventionally used in Lake Mag-\ngiore monitoring;\
    \ ii) appropriate laboratory instrumenta-\ntion was available at the CNR IRSA,\
    \ such as Fluoroprobe\nfor Chl-a  determination.\nTab. 2. QA activity log for\
    \ LM1 station in Lake Maggiore. \nDate                            Time \nQA Procedures\
    \                                      LM1 maintenance and functioning\n     \
    \                                                              Cleaning      \
    \          Measures                          \n03/12/2019                  12:00\
    \                                                                            \
    \                    Starting LM1\n18/12/2019                  12:00         \
    \                                                                            \
    \           Electric interruption \n24/12/2019                  12:00        \
    \                                                                            \
    \            Electric problem fixed\n09/01/2020                  12:20       \
    \                     ✓                             ✓                        \
    \         \n16/01/2020                  09:52                                \
    \                            ✓                                 \n20/01/2020  \
    \                12:00                                                       \
    \     ✓                                 \n27/01/2019                  12:00  \
    \                          ✓                                                 \
    \                \n30/01/2020                  08:37                         \
    \                                   ✓                                 \n06/02/2020\
    \                  10:51                                                     \
    \       ✓                                 \n18/02/2020                  10:18\
    \                            ✓                             ✓                 \
    \                \n21/02/2020                  14:37                         \
    \                                   ✓                                 \n04/03/2020\
    \                  10:03                                                     \
    \       ✓                                 \n10/03/2020                  10:22\
    \                            ✓                             ✓                 \
    \                \n07/04/2020                  11:30                         \
    \   ✓                             ✓                                 \n23/04/2020\
    \                  11:47                            ✓                        \
    \     ✓                                 \n24/04/2020                  12:53  \
    \                          ✓                             ✓                   \
    \              \n29/04/2020                  11:44                           \
    \ ✓                             ✓                                 Installation\
    \ meteorological station\n06/05/2020                  11:40                  \
    \          ✓                             ✓                                 \n\
    14/05/2020                  09:27                                            \
    \                ✓                                 \n20/05/2020              \
    \    10:13                            ✓                             ✓        \
    \                         \n27/05/2020                  11:28                \
    \                                            ✓                               \
    \  \n03/06/2020                  10:37                            ✓          \
    \                   ✓                                 \n10/06/2020           \
    \       09:50                            ✓                             ✓     \
    \                            \n16/06/2020                  08:53             \
    \               ✓                             ✓                              \
    \   \n23/06/2020                  09:19                            ✓         \
    \                    ✓                                 \n30/06/2020          \
    \        10:17                            ✓                             ✓    \
    \                             \n02/07/2020                  07:50            \
    \                                                                            \
    \        Sensors removed for laboratory calibration\n08/07/2020              \
    \    08:07                            ✓                                      \
    \                           Sensors remitted\n21/07/2020                  11:39\
    \                            ✓                             ✓                 \
    \                \n05/08/2020                  09:15                         \
    \   ✓                             ✓                                 \n24/08/2020\
    \                  10:50                            ✓                        \
    \     ✓                                 In situ recalibration of chlorophyll sensor\n\
    31/08/2020                  11:25                            ✓               \
    \              ✓                                 In situ test for chlorophyll\
    \ sensor functioning\nNon-commercial use only\nNon-commercial use only\nQA Procedures\
    \                                      LM1 maintenance and functioning\nNon-commercial\
    \ use only\nQA Procedures                                      LM1 maintenance\
    \ and functioning\nNon-commercial use only\nNon-commercial use only\n03/12/2019\
    \                  12:00                                                     \
    \                                           Starting LM1\nNon-commercial use only\n\
    03/12/2019                  12:00                                            \
    \                                                    Starting LM1\nNon-commercial\
    \ use only\n18/12/2019                  12:00                                \
    \                                                                Electric interruption\
    \ \nNon-commercial use only\n18/12/2019                  12:00               \
    \                                                                            \
    \     Electric interruption \nNon-commercial use only\n24/12/2019            \
    \      12:00                                                                 \
    \                               Electric problem fixed\nNon-commercial use only\n\
    24/12/2019                  12:00                                            \
    \                                                    Electric problem fixed\n\
    Non-commercial use only\n                                \nNon-commercial use\
    \ only\n                                \nNon-commercial use only\n          \
    \                      \nNon-commercial use only\n                           \
    \     \nNon-commercial use only\n20/01/2020                  12:00           \
    \                                                 \nNon-commercial use only\n\
    20/01/2020                  12:00                                            \
    \                ✓\nNon-commercial use only\n✓                               \
    \  \nNon-commercial use only\n                                \nNon-commercial\
    \ use only\n                                                                \n\
    Non-commercial use only\n                                                    \
    \            \nNon-commercial use only\n30/01/2020                  08:37    \
    \                                                        \nNon-commercial use\
    \ only\n30/01/2020                  08:37                                    \
    \                        ✓\nNon-commercial use only\n✓                       \
    \          \nNon-commercial use only\n                                \nNon-commercial\
    \ use only\n06/02/2020                  10:51                                \
    \                            \nNon-commercial use only\n06/02/2020           \
    \       10:51                                                            ✓\nNon-commercial\
    \ use only\n✓\nNon-commercial use only\n                             \nNon-commercial\
    \ use only\n                             \nNon-commercial use only\nNon-commercial\
    \ use only\nNon-commercial use only\n21/02/2020                  14:37       \
    \                                                     \nNon-commercial use only\n\
    21/02/2020                  14:37                                            \
    \                \nNon-commercial use only\n04/03/2020                  10:03\
    \                                                            \nNon-commercial\
    \ use only\n04/03/2020                  10:03                                \
    \                            \nNon-commercial use only\n10/03/2020           \
    \       10:22                            \nNon-commercial use only\n10/03/2020\
    \                  10:22                            ✓\nNon-commercial use only\n\
    ✓                             \nNon-commercial use only\n                    \
    \         \nNon-commercial use only\nNon-commercial use only\n07/04/2020     \
    \             11:30                            \nNon-commercial use only\n07/04/2020\
    \                  11:30                            ✓\nNon-commercial use only\n\
    ✓\nNon-commercial use only\n23/04/2020                  11:47                \
    \            \nNon-commercial use only\n23/04/2020                  11:47    \
    \                        \nNon-commercial use only\nNon-commercial use only\n\
    24/04/2020                  12:53                            \nNon-commercial\
    \ use only\n24/04/2020                  12:53                            \nNon-commercial\
    \ use only\n29/04/2020                  11:44                            \nNon-commercial\
    \ use only\n29/04/2020                  11:44                            \n50\n\
    R. Tiberti et al.\nField measurements and laboratory analyses from\nstandard methods\
    \ were used to check sensor accuracy\nand, if needed, for sensor recalibration\
    \ in the field. Water\ntemperature was measured in situ by taking a vertical tem-\n\
    perature profile with a multiparameter probe (In-Situ\nSmarTroll MP). A 0.5 L\
    \ water sample was taken with a\nRuttner bottle at the sensor depth (2.5 m) for\
    \ laboratory\ndetermination of pH, conductivity and dissolved oxygen\n(Winkler’s\
    \ method). Additional 2.0 L water samples were\ntaken at the sensor depths (2.5\
    \ or 8 m; Fig. 1) for chloro-\nphyll-a determination using two methods:\n•\nfluorometric\
    \ determination by FluoroProbe (BBE\nMoldaenke, GmbH, Germany). Measures were\
    \ done\nwith a Workstation benchtop unit, using a 25 ml cu-\nvette of lake water\
    \ samples;\n•\nacetone extraction followed by spectrophotometric\nreading (method\
    \ APAT IRSA 9020; APAT IRSA-CNR\n2003). \nThe accuracy of the temperature, pH,\
    \ conductivity,\nand dissolved oxygen sensors was assessed comparing re-\nsults\
    \ from in situ and laboratory QA measures with sensor\ndata, i.e., average of\
    \ the last 30 measures after QA meas-\nure/sampling. For these sensors, we followed\
    \ the calibra-\ntion criteria of Wagner et al. (2006) to decide when sensor\n\
    recalibration was necessary. In such cases, calibration QA\nmeasures were used\
    \ as a reference to recalibrate the sen-\nsors. However, we usually observed a\
    \ good fit between\nsensor and QA measures and limited calibration problems\n\
    and periodic recalibrations using calibration standards\nwere sufficient to maintain\
    \ sensor data within the accept-\nable accuracy limits (e.g., ±0.3 mg L–1 for\
    \ oxygen con-\ncentration); a clear sensor drift was however observed for\nthe\
    \ pH sensor (Fig. 4b), needing sensor recalibration and\ndrift correction after\
    \ about six months of sensor operation.\nA possible problem related to the optical\
    \ oxygen sensor\nis dye degradation; however, during the nine -months op-\neration\
    \ period, we did not observe any deviation in the\noxygen sensor readings. \n\
    Because Chl-a sensors were calibrated and tested in\nlaboratory conditions, their\
    \ performance may differ in the\nfield with lake phytoplankton communities. In\
    \ addition,\nthere are two very common factors which may affect the\nlinear relationship\
    \ between fluorescence and Chl-a con-\ncentrations, producing significant deviations\
    \ between\nfield and laboratory measures: \n•\nthe so-called fluorescence quenching\
    \ (i.e., the depres-\nsion of the fluorescence signal in surface waters dur-\n\
    ing daylight and especially at noon), which is a\nubiquitous phenomenon in lakes\
    \ and oceans (Marra,\n1997); \n•\nphytoplankton community composition (Richardson\n\
    et al., 2010).\nBoth factors should be taken into account to recali-\nbrate the\
    \ sensor for field measurements, i.e., find an ac-\ncurate conversion factor for\
    \ raw sensor data (from Volts\nto Chl-a concentrations).\nConcerning quenching,\
    \ this mechanism produces a\ndaily cycle in fluorescence data which is regarded\
    \ as a\nconsequence of solar light photoinhibition on algal pho-\ntosynthetic\
    \ activity (McBride and Rose, 2018). As com-\nmonly reported in other HFM studies,\
    \ we have observed\nin our data the depressing effects of quenching on the flu-\n\
    orescence of Chl-a during midday hours. This pattern was\nmuch attenuated at a\
    \ greater depth (8 m; Fig. 5). In Fig.\n5, it can be observed that around the\
    \ time of sunrise (at\nhour 6:00) chlorophyll-a values from night values of\n\
    about 1.0-1.5 Volt sharply declined to daylight values of\n0.3-0.4 Volt, remaining\
    \ at low levels until crepuscular\ntime (sunset at hour 20:15), when values gradually\
    \ in-\ncreased again. \nNeglecting quenching may have disruptive conse-\nquences\
    \ on the interpretation of chlorophyll-a data series;\nwe therefore considered\
    \ the night surface measurements\nas the most indicative of chlorophyll-a concentration,\
    \ as\nsuggested in McBride and Rose (2018). To illustrate this\nissue, we used\
    \ the Chl-a data (in Volt) from the surface\nsensor (2.5 m) and we calculated\
    \ the average Chl-a con-\ncentrations in the 24 hours, or in the night immediately\n\
    following water sampling (using data from one hour\naround midnight); we used\
    \ only values recorded after\nsampling because of possible biofouling events (Fig.\
    \ 4d).\nWhether the field calibration was performed using the\ndaily or night\
    \ averages, this significantly changed the cal-\nibration parameters of the relationship\
    \ between fluores-\ncence (F; in Volt) and laboratory concentration ([Chl-a];\n\
    in µg L–1), i.e., [Chl-a] = 11.52 F + 0.42, R2 = 0.79 for the\ndaily averages;\
    \ [Chl-a] = 9.02 F + 0.22, R2 = 0.83 for the\nnight-time averages. The former\
    \ equation does not ac-\ncount for quenching, having a higher slope and worse\
    \ fit\nof the latter. Interestingly, accounting for quenching also\nprovided a\
    \ better concordance between the parameters of\nthe field calibration and the\
    \ laboratory calibration, run\nunder controlled experimental conditions i.e.,\
    \ [Chl-a] =\n7.01 F - 0.31, R2 = 0.998 (see paragraph “Sensor calibra-\ntion in\
    \ laboratory”). \nConcerning phytoplankton community composition,\nsensor measures\
    \ of chlorophyll-a by fluorometric determi-\nnation may produce an underestimation\
    \ of chlorophyll-a\nconcentrations when cyanobacteria are abundant (Bowling\n\
    et al., 2016), because chlorophyll-a fluorescence induction\nworks differently\
    \ for cyanobacteria and eukaryotic algae\n(Stirbet et al., 2019). We found a good\
    \ agreement between\nsensor data and chlorophyll-a concentrations measured by\n\
    laboratory extractions, likely because cyanobacteria have\nusually a low biomass\
    \ in Lake Maggiore (Fastner et al.,\n2016), as confirmed by Fluoroprobe data (Fig.\
    \ 6). Patterns\nobserved in the phytoplankton community over the study\nperiod\
    \ (December 2019 and September 2020; Fig. 6) have\nNon-commercial use only\ntime\
    \ (sunset at hour 20:15), when values gradually in-\nNon-commercial use only\n\
    time (sunset at hour 20:15), when values gradually in-\nNeglecting quenching may\
    \ have disruptive conse-\nNon-commercial use only\nNeglecting quenching may have\
    \ disruptive conse-\nquences on the interpretation of chlorophyll-a data series;\n\
    Non-commercial use only\nquences on the interpretation of chlorophyll-a data series;\n\
    we therefore considered the night surface measurements\nNon-commercial use only\n\
    we therefore considered the night surface measurements\nas the most indicative\
    \ of chlorophyll-a concentration, as\nNon-commercial use only\nas the most indicative\
    \ of chlorophyll-a concentration, as\nNon-commercial use only\nsors. However,\
    \ we usually observed a good fit between\nNon-commercial use only\nsors. However,\
    \ we usually observed a good fit between\nsensor and QA measures and limited calibration\
    \ problems\nNon-commercial use only\nsensor and QA measures and limited calibration\
    \ problems\nand periodic recalibrations using calibration standards\nNon-commercial\
    \ use only\nand periodic recalibrations using calibration standards\nwere sufficient\
    \ to maintain sensor data within the accept-\nNon-commercial use only\nwere sufficient\
    \ to maintain sensor data within the accept-\nfor oxygen con-\nNon-commercial\
    \ use only\nfor oxygen con-\ncentration); a clear sensor drift was however observed\
    \ for\nNon-commercial use only\ncentration); a clear sensor drift was however\
    \ observed for\nthe pH sensor (Fig. 4b), needing sensor recalibration and\nNon-commercial\
    \ use only\nthe pH sensor (Fig. 4b), needing sensor recalibration and\ndrift correction\
    \ after about six months of sensor operation.\nNon-commercial use only\ndrift\
    \ correction after about six months of sensor operation.\nA possible problem related\
    \ to the optical oxygen sensor\nNon-commercial use only\nA possible problem related\
    \ to the optical oxygen sensor\nis dye degradation; however, during the nine -months\
    \ op-\nNon-commercial use only\nis dye degradation; however, during the nine -months\
    \ op-\neration period, we did not observe any deviation in the\nNon-commercial\
    \ use only\neration period, we did not observe any deviation in the\nsuggested\
    \ in McBride and Rose (2018). To illustrate this\nNon-commercial use only\nsuggested\
    \ in McBride and Rose (2018). To illustrate this\nissue, we used the Chl-a data\
    \ (in Volt) from the surface\nNon-commercial use only\nissue, we used the Chl-a\
    \ data (in Volt) from the surface\nsensor (2.5 m) and we calculated the average\
    \ Chl-a con-\nNon-commercial use only\nsensor (2.5 m) and we calculated the average\
    \ Chl-a con-\ncentrations in the 24 hours, or in the night immediately\nNon-commercial\
    \ use only\ncentrations in the 24 hours, or in the night immediately\nfollowing\
    \ water sampling (using data from one hour\nNon-commercial use only\nfollowing\
    \ water sampling (using data from one hour\naround midnight); we used only values\
    \ recorded after\nNon-commercial use only\naround midnight); we used only values\
    \ recorded after\nsampling because of possible biofouling events (Fig. 4d).\n\
    Non-commercial use only\nsampling because of possible biofouling events (Fig.\
    \ 4d).\nWhether the field calibration was performed using the\nNon-commercial\
    \ use only\nWhether the field calibration was performed using the\n51\nA high\
    \ frequency monitoring system for Lake Maggiore\nFig. 6. Chlorophyll-a trend in\
    \ Lake Maggiore as recorded by the CYCLOPS-7 sensor (night-time mean hourly values)\
    \ and total chloro-\nphyll-a concentration provided by Fluoroprobe and by laboratory\
    \ extraction. The contributions of the main phytoplankton groups ac-\ncording\
    \ to Fluoroprobe are also shown.\nFig. 5. Daily cycle of chlorophyll-a value recorded\
    \ by the in-field CYCLOPS-7 sensors (surface sensor, at 2.5 m depth, and deep\
    \ sensor,\nat about 8.0 m depth) on sunny days in summer 2020. The readings of\
    \ the deep sensor are steadily around 0.8 Volt. \nNon-commercial use only\nNon-commercial\
    \ use only\nNon-commercial use only\nDaily cycle of chlorophyll-a value recorded\
    \ by the in-field CYCLOPS-7 sensors (surface sensor, at 2.5 m depth, and deep\
    \ sensor,\nNon-commercial use only\nDaily cycle of chlorophyll-a value recorded\
    \ by the in-field CYCLOPS-7 sensors (surface sensor, at 2.5 m depth, and deep\
    \ sensor,\nNon-commercial use only\nNon-commercial use only\nNon-commercial use\
    \ only\nNon-commercial use only\nat about 8.0 m depth) on sunny days in summer\
    \ 2020. The readings of the deep sensor are steadily around 0.8 Volt. \nNon-commercial\
    \ use only\nat about 8.0 m depth) on sunny days in summer 2020. The readings of\
    \ the deep sensor are steadily around 0.8 Volt. \n52\nR. Tiberti et al.\nfollowed\
    \ a dynamic typically observed in Lake Maggiore,\nwith a dominance of Bacillariophyta\
    \ during spring and\nearly summer, and a more diverse community during sum-\n\
    mer including Chlorophyta and Cyanobacteria (Morabito\net al., 2012). In August\
    \ 2020 a deviation between sensor\nand laboratory chlorophyll data was observed\
    \ and associ-\nated to an increase of phycoerythrin containing Cyanobac-\nteria,\
    \ detected and measured by the Fluoroprobe. The\nincrease of phycoerythrin might\
    \ be due to picocyanobac-\nteria (i.e., Synechococcus), since they usually became\n\
    abundant in late summer in Lake Maggiore (Callieri and\nPiscia, 2002). This condition\
    \ may suggest that sensor field\ncalibration and chlorophyll data interpretation\
    \ in Lake\nMaggiore require careful consideration because of its phy-\ntoplankton\
    \ community composition during summer peri-\nods. Performing frequent field sampling\
    \ and analysis of\nthe phytoplankton community composition could improve\nthe\
    \ comparison with sensor chlorophyll data, at least dur-\ning the first phase\
    \ of the HFM system running. Further,\nthe adoption of field sensors for the detection\
    \ of phyco-\ncyanin and phycoerythrin, as foreseen for the LM1 buoy,\nmay be crucial\
    \ to disentangle the contribute of different\nalgal groups on the overall signal\
    \ of the chlorophyll regis-\ntered by the field sensor. \nSensor cleaning\nSensor\
    \ fouling, in particular biofouling, is a major\nsource of errors in limnological\
    \ HFM systems. Fouling\noccurs because particulate matter, sediments, bacteria,\
    \ mi-\ncroalgae or larger organisms adhere to the surface of the\nsensors, of\
    \ their supports and cables, with possible inter-\nferences with data quality.\
    \ At some places and occasions,\nsensors may face actual short-term biofouling\
    \ effects, dis-\nrupting the quality of the measurements, sometimes in\nless than\
    \ a week. Unless autonomous and effective anti-\nfouling techniques are adopted,\
    \ a regular manual cleaning\nof the sensors is needed to assure the quality of\
    \ the data.\nHowever, this is likely to become the most laborious task\nrelated\
    \ to system maintenance (Laas et al., 2016). \nFor LM1, biofouling was a major\
    \ issue for the sensor\nfor chlorophyll-a, requiring frequent field visits to\
    \ the buoy\nfor sensor cleaning (Tab. 2). Even if fouling was observed\nonly for\
    \ the chlorophyll sensor, all sensors were cleaned\nwith the same frequency required\
    \ by the chlorophyll-a sen-\nsor, which was probably sufficient to avoid any fouling\n\
    problems for the other sensors. The minimum time elapsed\nbetween the last chlorophyll-a\
    \ sensor cleaning and the re-\ncurrence of the problem was less than two weeks,\
    \ but\nlonger recurrence times were usually observed. Evidence\nof fouling arises\
    \ from the observation of the data series,\nwhich show an abrupt decrease, just\
    \ after sensor cleaning\n(Fig. 4d). Until now, biofouling was addressed through\n\
    regular manual cleaning of the sensor surface and support\nand by data correction.\
    \ However, finding autonomous and\neffective anti-fouling systems is probably\
    \ a priority to re-\nduce the maintenance efforts and preserve one of the most\n\
    attractive advantages of automated monitoring systems,\ni.e., saving time and\
    \ personnel costs. \nSome techniques and technologies are available to re-\nduce\
    \ sensor fouling (Pires, 2010); they include using au-\ntomated mechanical cleaning\
    \ systems, antifouling paints\n(with active biocides such as copper), and active\
    \ systems\nbased on electro-mechanical vibration removing fouling\nmaterial from\
    \ the surface. However, antifouling paints are\nnot adapted to protect sensors’\
    \ sensitive parts (the inter-\nface between the measurement medium and the sensor\n\
    sensitive area), which should remain as much as possible\nunmodified, and the\
    \ power requirement of electro-me-\nchanical methods may be too high for HFM systems.\
    \ Up\nto now, standard methods to avoid and manage sensor\nfouling are not available.\
    \ It is likely that biofouling may\nbecome an even more pressing problem for meso-eu-\n\
    trophic lakes, such as lakes Como, Varese and Lugano.\nAn important step for the\
    \ creation of an efficient HFM\nsystem for the subalpine lakes is the creation\
    \ of standard\nantifouling protocols, which should be considered a pri-\nority\
    \ for our project. \nQC procedures\nSemi-automated QC controls\nAutomated QC controls\
    \ do not replace manual data\ninspection by experts which is ultimately needed\
    \ to take\nthe final decision on deletion or correction of erroneous\nor low-quality\
    \ data. However, automated QC represents\na necessary improvement. It ensures\
    \ consistency, re-\nduces human bias, and enables to cope with the huge\nflow\
    \ of data from HFM systems, which is incompatible\nwith manual QC methods historically\
    \ used by ecologists\n(Campbell et al., 2013). Automated QC control classifies\n\
    data according to mathematical or logical criteria. When\nthey do not meet such\
    \ criteria, data are not removed, but\nlabelled (or flagged) as suspicious, preserving\
    \ raw data\nunmanipulated (i.e., pre-processed data). The final deci-\nsion on\
    \ retaining, correcting, or deleting flagged data is\ntaken at the final data\
    \ editing. For example, extreme\nevents may produce extreme but accurate values\
    \ which\nmay be flagged for falling outside a certain range crite-\nrion (Fig.\
    \ 4c). \nMost automated quality control procedures are fo-\ncused on flagging\
    \ raw data values that do not meet one of\nseveral plausibility tests (Sheldon,\
    \ 2008; Lerner et al.,\n2011; Taylor and Loescher, 2013). Flagging erroneous or\n\
    suspicious values can require simple algorithms (e.g., sim-\nple range checks)\
    \ or more complicated techniques\n(Moatar et al., 2001; Hill et al., 2009; Fiebrich\
    \ et al.,\n2010). We provide an example of semi-automated QC\nprocedures based\
    \ on the package sensorQC (Read et al.,\nNon-commercial use only\nchanical methods\
    \ may be too high for HFM systems. Up\nNon-commercial use only\nchanical methods\
    \ may be too high for HFM systems. Up\nto now, standard methods to avoid and manage\
    \ sensor\nNon-commercial use only\nto now, standard methods to avoid and manage\
    \ sensor\nfouling are not available. It is likely that biofouling may\nNon-commercial\
    \ use only\nfouling are not available. It is likely that biofouling may\nbecome\
    \ an even more pressing problem for meso-eu-\nNon-commercial use only\nbecome\
    \ an even more pressing problem for meso-eu-\nNon-commercial use only\nSensor\
    \ fouling, in particular biofouling, is a major\nNon-commercial use only\nSensor\
    \ fouling, in particular biofouling, is a major\nsource of errors in limnological\
    \ HFM systems. Fouling\nNon-commercial use only\nsource of errors in limnological\
    \ HFM systems. Fouling\noccurs because particulate matter, sediments, bacteria,\
    \ mi-\nNon-commercial use only\noccurs because particulate matter, sediments,\
    \ bacteria, mi-\ncroalgae or larger organisms adhere to the surface of the\nNon-commercial\
    \ use only\ncroalgae or larger organisms adhere to the surface of the\nsensors,\
    \ of their supports and cables, with possible inter-\nNon-commercial use only\n\
    sensors, of their supports and cables, with possible inter-\nferences with data\
    \ quality. At some places and occasions,\nNon-commercial use only\nferences with\
    \ data quality. At some places and occasions,\nsensors may face actual short-term\
    \ biofouling effects, dis-\nNon-commercial use only\nsensors may face actual short-term\
    \ biofouling effects, dis-\nrupting the quality of the measurements, sometimes\
    \ in\nNon-commercial use only\nrupting the quality of the measurements, sometimes\
    \ in\nless than a week. Unless autonomous and effective anti-\nNon-commercial\
    \ use only\nless than a week. Unless autonomous and effective anti-\nfouling techniques\
    \ are adopted, a regular manual cleaning\nNon-commercial use only\nfouling techniques\
    \ are adopted, a regular manual cleaning\nof the sensors is needed to assure the\
    \ quality of the data.\nNon-commercial use only\nof the sensors is needed to assure\
    \ the quality of the data.\nHowever, this is likely to become the most laborious\
    \ task\nNon-commercial use only\nHowever, this is likely to become the most laborious\
    \ task\ntrophic lakes, such as lakes Como, Varese and Lugano.\nNon-commercial\
    \ use only\ntrophic lakes, such as lakes Como, Varese and Lugano.\nAn important\
    \ step for the creation of an efficient HFM\nNon-commercial use only\nAn important\
    \ step for the creation of an efficient HFM\nsystem for the subalpine lakes is\
    \ the creation of standard\nNon-commercial use only\nsystem for the subalpine\
    \ lakes is the creation of standard\nantifouling protocols, which should be considered\
    \ a pri-\nNon-commercial use only\nantifouling protocols, which should be considered\
    \ a pri-\nority for our project. \nNon-commercial use only\nority for our project.\
    \ \nQC procedures\nNon-commercial use only\nQC procedures\nSemi-automated QC controls\n\
    Non-commercial use only\nSemi-automated QC controls\n53\nA high frequency monitoring\
    \ system for Lake Maggiore\n2015) of the R statistical environment version 4.3.1\
    \ (R\nDevelopment Core Team, 2019). This package was devel-\noped by the United\
    \ States Geological Survey and specif-\nically designed for automated QC controls\
    \ for sensor data\n(Gries et al., 2014). Our semi-automated QC procedures\nprovide\
    \ for four plausibility tests. A flag is generated and\nassociated to the data\
    \ which do not meet the criteria (Tab.\n3) of the following tests:\n•\nglobal\
    \ range test: data are flagged unless they fall\nwithin valid regional lake ranges\
    \ or instrumental limits\n(whichever is more restrictive) (i.e., >MAXglobal and\n\
    <MINglobal, respectively representing the maximum\nand minimum plausible values\
    \ at a global level); we\nset MAXglobal and MINglobal based on instrumental\n\
    limits and literature data;\n•\nlocal range test: data are flagged unless they\
    \ fall within\nlocally valid site-specific ranges (i.e., >MAXlocal and\n<MINlocal,\
    \ respectively representing the maximum\nand minimum plausible values at a site-specific\
    \ level);\nwe set MAXlocal and MINlocal respectively equal to\nthe upper and lower\
    \ 95% Confidence Intervals of the\nsurface values recorded during the long-term\
    \ monitor-\ning campaign of Lake Maggiore at the Ghiffa sam-\npling station; \n\
    •\nstuck value test (or value persistence test): data are\nflagged if neighbouring\
    \ values differ by less than the\nresolution of the sensor for more than Nrep\
    \ repetitions,\nwhere Nrep is an arbitrary number of repeated data\nthat is considered\
    \ indicative of sensor stuck;\n•\nspike test or absolute deviation around median\
    \ test:\ndata are flagged when their absolute deviation around\nthe median value\
    \ calculated over the last w previous\nvalues is larger than 3 times their median\
    \ (i.e., median\nabsolute deviation - MAD> 3). \nVisual inspection of data and\
    \ manual QC editing\nMany sensor errors, such as sensor drift and fouling\nmay\
    \ swell the automated procedures but become evident\nwhen sensors undergo periodic\
    \ maintenance operations\n(i.e., cleaning) or sensor accuracy is tested, i.e.,\
    \ using cal-\nibration standards or field measures (see paragraph “Qual-\nity\
    \ assurance”). Automated QC can identify and flag po-\ntentially erroneous values.\
    \ However, there is also a need\nof choose and apply the appropriate data corrections\n\
    (Horsburgh et al., 2015). As stated above, to this aim, the\nattention and expertise\
    \ of field or data technicians are re-\nquired (Fiebrich et al., 2010). At this\
    \ stage, flags can be\nconveniently used to sort the data according to the criteria\n\
    for automated QC, which enables saving considerable\ntime. During the final editing,\
    \ data undergo visual inspec-\ntion. A readable graphic representation of HFM\
    \ data as-\nsociated to QA monitoring data (e.g., sensor cleaning\nevents, laboratory\
    \ measurements, etc.; Fig. 4) is therefore\nnecessary. \nIn Tab. 4 we provide\
    \ the logical scheme (i.e., articu-\nlated in a series of dichotomous questions)\
    \ that we used\nfor the final editing. It should be noted that at first data is\n\
    evaluated based on the results of automated QC controls\n(flagged data), but then\
    \ also non-flagged data are in-\nspected. Final editing provides for one of three\
    \ possible\nactions: retain data (for data that are considered accurate\nenough),\
    \ discard data (when data quality is considered too\nlow and correction methods\
    \ inapplicable), or correct (i.e.,\nsubtract/add a quantity to the raw sensor\
    \ value). The final\ndecision is often based on data accuracy as compared to\n\
    QA measurements, so that QA measurements should be\nfrequent enough to enable\
    \ such comparisons and provide\nguarantees about the quality of HFM data. Sensor\
    \ data are\nretained without any manipulations when they match the\ncalibration\
    \ standards or QA measures used to evaluate the\nsensor accuracy. A certain deviation\
    \ between sensor data\nand QA measures is however expected, but data can be\n\
    retained without corrections if they meet fixed quality\nstandard (Tab.4). \n\
    More sophisticated methods are needed to correct for\ni) calibration offset, ii)\
    \ sensor drift, and iii) sensor fouling\n(Wagner et al., 2006). Hereafter we describe\
    \ some meth-\nods to correct data. Being aware that these methods are\nnot representative\
    \ of the entire range of possible correc-\ntion methods. However, a full description\
    \ of these meth-\nods is out of the scopes of the present study. We just\nprovide\
    \ some examples of data correction from our study\nthat can be applied in similar\
    \ cases.\nTab. 3. Parameters of the semi-automated QC tests applied to the sensor\
    \ data from the LM1 buoy. \nSensor                                           Unit\
    \                                                       \nParameters of the QC\
    \ tests\n                                                                    \
    \                  MINGLOBAL  MAXGLOBAL   MINLOCAL    MAXLOCAL        NREP   \
    \             w               MAD\npH                                        \
    \                                                    3                  11   \
    \             7.37              9.01                 5                  60   \
    \               3\nTemperature                                    ˚C         \
    \                            0                  50                6.60       \
    \      23.00                5                  60                  3\nElectrical\
    \ conductivity at 25 °C     μS cm–1                                          \
    \      0                2000            135.84          166.68               5\
    \                  60                  3\nOxygen concentration               \
    \     mg L–1                                                   0             \
    \     20                9.17             12.28                5              \
    \    60                  3\nChlorophyll-a concentration           μg L–1     \
    \                                               0               34.43a       \
    \              0.03             34.43a                         3             \
    \     60                  3\naUpper instrument limit.\nNon-commercial use only\n\
    lated in a series of dichotomous questions) that we used\nNon-commercial use only\n\
    lated in a series of dichotomous questions) that we used\nfor the final editing.\
    \ It should be noted that at first data is\nNon-commercial use only\nfor the final\
    \ editing. It should be noted that at first data is\nevaluated based on the results\
    \ of automated QC controls\nNon-commercial use only\nevaluated based on the results\
    \ of automated QC controls\n(flagged data), but then also non-flagged data are\
    \ in-\nNon-commercial use only\n(flagged data), but then also non-flagged data\
    \ are in-\nNon-commercial use only\n•\nstuck value test (or value persistence\
    \ test): data are\nNon-commercial use only\n•\nstuck value test (or value persistence\
    \ test): data are\nflagged if neighbouring values differ by less than the\nNon-commercial\
    \ use only\nflagged if neighbouring values differ by less than the\nresolution\
    \ of the sensor for more than Nrep repetitions,\nNon-commercial use only\nresolution\
    \ of the sensor for more than Nrep repetitions,\nwhere Nrep is an arbitrary number\
    \ of repeated data\nNon-commercial use only\nwhere Nrep is an arbitrary number\
    \ of repeated data\nthat is considered indicative of sensor stuck;\nNon-commercial\
    \ use only\nthat is considered indicative of sensor stuck;\n•\nspike test or absolute\
    \ deviation around median test:\nNon-commercial use only\n•\nspike test or absolute\
    \ deviation around median test:\ndata are flagged when their absolute deviation\
    \ around\nNon-commercial use only\ndata are flagged when their absolute deviation\
    \ around\nthe median value calculated over the last w previous\nNon-commercial\
    \ use only\nthe median value calculated over the last w previous\nvalues is larger\
    \ than 3 times their median (\nNon-commercial use only\nvalues is larger than\
    \ 3 times their median (\nabsolute deviation - MAD> 3). \nNon-commercial use only\n\
    absolute deviation - MAD> 3). \nVisual inspection of data and manual QC editing\n\
    Non-commercial use only\nVisual inspection of data and manual QC editing\nMany\
    \ sensor errors, such as sensor drift and fouling\nNon-commercial use only\nMany\
    \ sensor errors, such as sensor drift and fouling\nspected. Final editing provides\
    \ for one of three possible\nNon-commercial use only\nspected. Final editing provides\
    \ for one of three possible\nactions: retain data (for data that are considered\
    \ accurate\nNon-commercial use only\nactions: retain data (for data that are considered\
    \ accurate\nenough), discard data (when data quality is considered too\nNon-commercial\
    \ use only\nenough), discard data (when data quality is considered too\nlow and\
    \ correction methods inapplicable), or correct (\nNon-commercial use only\nlow\
    \ and correction methods inapplicable), or correct (\nsubtract/add a quantity\
    \ to the raw sensor value). The final\nNon-commercial use only\nsubtract/add a\
    \ quantity to the raw sensor value). The final\ndecision is often based on data\
    \ accuracy as compared to\nNon-commercial use only\ndecision is often based on\
    \ data accuracy as compared to\nQA measurements, so that QA measurements should\
    \ be\nNon-commercial use only\nQA measurements, so that QA measurements should\
    \ be\nfrequent enough to enable such comparisons and provide\nNon-commercial use\
    \ only\nfrequent enough to enable such comparisons and provide\n54\nR. Tiberti\
    \ et al.\nCalibration offset occurs when sensor data deviate\nfrom QA measurements\
    \ by a constant; sensor data can be\ncorrected adding this constant and further\
    \ errors avoided\nthrough recalibration. To compensate for sensor drift, we\n\
    considered the difference, or deviation, between QA\nmeasures and sensor data.\
    \ Sensor data were estimated as\nthe mean value of the 60 measures (1 hour) taken\
    \ starting\nfrom 10 mins after QA measures, to avoid values tem-\nporarily affected\
    \ by QA procedures. Even if sensor drift\nmay follow different patterns, we assumed\
    \ it followed a\nstraight linear course with time. We therefore run a linear\n\
    regression between sensor deviation and time to correct\nfor sensor drift (Fig.\
    \ 7a and a’).\nSensor fouling was observed only for chlorophyll-a\nTab. 4. Line\
    \ of reasoning for the final HFM data editing. \n1.          Are the values under\
    \ inspection flagged according to at least one of the semi-automated Quality Control\
    \ criteria?                       \n             Yes                         \
    \                                                                            \
    \                                                                            \
    \                     go to 2\n             No                               \
    \                                                                            \
    \                                                                            \
    \                go to 12\n2.          Are the values flagged according to the\
    \ stuck value test?                                                          \
    \                                                       \n             YesNo \
    \                                                                            \
    \                                                                            \
    \                                        go to 3go to 4\n3.          Does data\
    \ inspection confirm sensor stuck?                                           \
    \                                                                            \
    \               \n             Yes                                           \
    \                                                                            \
    \                                                                            \
    \   DISCARD\n             No                                                 \
    \                                                                            \
    \                                                                          go\
    \ to 4\n4.          Are data values flagged according to the spike test?     \
    \                                                                            \
    \                                        \n             Yes                  \
    \                                                                            \
    \                                                                            \
    \                            go to 5\n             No                        \
    \                                                                            \
    \                                                                            \
    \                       go to 6\n5.          Is there a clear mechanism (ecological\
    \ or physical) explaining the spikes?                                        \
    \                                              \n             Yes            \
    \                                                                            \
    \                                                                            \
    \                                  go to 6\n             No                  \
    \                                                                            \
    \                                                                            \
    \                             DISCARD\n6.          Are data values flagged according\
    \ to the global range test?                                                  \
    \                                                            \n             Yes\
    \                                                                            \
    \                                                                            \
    \                                              go to 7\n             No      \
    \                                                                            \
    \                                                                            \
    \                                         go to 8\n7.          Are values at or\
    \ outside instrumental limits?                                               \
    \                                                                            \
    \          \n             Yes                                                \
    \                                                                            \
    \                                                                          DISCARD\n\
    \             No                                                             \
    \                                                                            \
    \                                                              go to 8\n8.   \
    \       Are values flagged according to the local range test?                \
    \                                                                            \
    \                            \n             Yes                              \
    \                                                                            \
    \                                                                            \
    \                go to 9\n             No                                    \
    \                                                                            \
    \                                                                            \
    \           go to 11\n9.          Are values outside local range because of sensor\
    \ drift or fouling?                                                          \
    \                                          \n             Yes                \
    \                                                                            \
    \                                                                            \
    \                              go to 10\n             No                     \
    \                                                                            \
    \                                                                            \
    \                          go to 11\n10.        Do sensor drift or fouling caused\
    \ data truncation at the instrumental limits?                                \
    \                                                   \n             Yes (remove\
    \ all data which can be affected by drift or fouling, also those data recorded\
    \ before the instrumental limits                DISCARD\n             were reached.\
    \ Then, recalibrate or clean the sensors)                                    \
    \                                                                            \
    \        \n             No (recalibrate or clean the sensors)                \
    \                                                                            \
    \                                                      CORRECT\n11.         The\
    \ match between sensor data and calibration standards/available Quality Assurance\
    \ (QA) measures is good enough?*                     \n             Yes      \
    \                                                                            \
    \                                                                            \
    \                                        RETAIN\n             No             \
    \                                                                            \
    \                                                                            \
    \                                  go to 12\n12.        Do values deviate from\
    \ QA measures by a constant?                                                 \
    \                                                                       \n   \
    \          Yes                                                               \
    \                                                                            \
    \                                                           CORRECT\n        \
    \     No                                                                     \
    \                                                                            \
    \                                                      go to 13\n13.        Do\
    \ values deviate from QA measures according to a recognizable pattern attributable\
    \ to sensor drift or fouling?                          \n             Yes    \
    \                                                                            \
    \                                                                            \
    \                                          go to 10\n             No (sensor should\
    \ be repaired or changed)                                                    \
    \                                                                            \
    \        DISCARD\n*Temperature error less than ±0.2ºC; EC error less than ±5 µS\
    \ cm–1; [O2] error less than 0.3 mg L–1; pH error less than 0.3 pH units; [Chl-a]\
    \ error less\nthan 15% the values recorded the night after the QA measures. Temperature,\
    \ EC, pH, and [O2] criteria are based on Wagner et al., 2006; the criterion\n\
    for [Chl-a] is based on personal observations of data accuracy. \nNon-commercial\
    \ use only\nNon-commercial use only\nAre the values flagged according to the stuck\
    \ value test?                                                                \
    \                                                 \nNon-commercial use only\n\
    Are the values flagged according to the stuck value test?                    \
    \                                                                            \
    \                 \nNon-commercial use only\nYesNo                           \
    \                                                                            \
    \                                                                            \
    \              go to 3go to 4\nNon-commercial use only\nYesNo                \
    \                                                                            \
    \                                                                            \
    \                         go to 3go to 4\nNon-commercial use only\nDoes data inspection\
    \ confirm sensor stuck?                                                      \
    \                                                                            \
    \    \nNon-commercial use only\nDoes data inspection confirm sensor stuck?   \
    \                                                                            \
    \                                                       \nNon-commercial use only\n\
    Yes                                                                          \
    \                                                                            \
    \                                                DISCARD\nNon-commercial use only\n\
    Yes                                                                          \
    \                                                                            \
    \                                                DISCARD\nNon-commercial use only\n\
    No                                                                           \
    \                                                                            \
    \                                                go to 4\nNon-commercial use only\n\
    No                                                                           \
    \                                                                            \
    \                                                go to 4\nNon-commercial use only\n\
    Are data values flagged according to the spike test?                         \
    \                                                                            \
    \                    \nNon-commercial use only\nAre data values flagged according\
    \ to the spike test?                                                         \
    \                                                                \nNon-commercial\
    \ use only\nYes                                                              \
    \                                                                            \
    \                                                            go to 5\nNon-commercial\
    \ use only\nYes                                                              \
    \                                                                            \
    \                                                            go to 5\nNon-commercial\
    \ use only\nNo                                                               \
    \                                                                            \
    \                                                            go to 6\nNon-commercial\
    \ use only\nNo                                                               \
    \                                                                            \
    \                                                            go to 6\nNon-commercial\
    \ use only\nIs there a clear mechanism (ecological or physical) explaining the\
    \ spikes?                                                                    \
    \                  \nNon-commercial use only\nIs there a clear mechanism (ecological\
    \ or physical) explaining the spikes?                                        \
    \                                              \nNon-commercial use only\nYes\
    \                                                                            \
    \                                                                            \
    \                                              go to 6\nNon-commercial use only\n\
    Yes                                                                          \
    \                                                                            \
    \                                                go to 6\nNon-commercial use only\n\
    No                                                                           \
    \                                                                            \
    \                                                DISCARD\nNon-commercial use only\n\
    No                                                                           \
    \                                                                            \
    \                                                DISCARD\nNon-commercial use only\n\
    Are data values flagged according to the global range test?                  \
    \                                                                            \
    \                \nNon-commercial use only\nAre data values flagged according\
    \ to the global range test?                                                  \
    \                                                            \nNon-commercial\
    \ use only\nYes                                                              \
    \                                                                            \
    \                                                            go to 7\nNon-commercial\
    \ use only\nYes                                                              \
    \                                                                            \
    \                                                            go to 7\nNon-commercial\
    \ use only\nNo                                                               \
    \                                                                            \
    \                                                            go to 8\nNon-commercial\
    \ use only\nNo                                                               \
    \                                                                            \
    \                                                            go to 8\nNon-commercial\
    \ use only\nAre values at or outside instrumental limits?                    \
    \                                                                            \
    \                                     \nNon-commercial use only\nAre values at\
    \ or outside instrumental limits?                                            \
    \                                                                            \
    \             \nNon-commercial use only\nYes                                 \
    \                                                                            \
    \                                                                            \
    \             DISCARD\nNon-commercial use only\nYes                          \
    \                                                                            \
    \                                                                            \
    \                    DISCARD\nNon-commercial use only\nNon-commercial use only\n\
    No                                                                           \
    \                                                                            \
    \                                                go to 8\nNon-commercial use only\n\
    No                                                                           \
    \                                                                            \
    \                                                go to 8\nNon-commercial use only\n\
    Are values flagged according to the local range test?                        \
    \                                                                            \
    \                    \nNon-commercial use only\nAre values flagged according to\
    \ the local range test?                                                      \
    \                                                                  \nNon-commercial\
    \ use only\nYes                                                              \
    \                                                                            \
    \                                                            go to 9\nNon-commercial\
    \ use only\nYes                                                              \
    \                                                                            \
    \                                                            go to 9\nNon-commercial\
    \ use only\nNo                                                               \
    \                                                                            \
    \                                                            go to 11\nNon-commercial\
    \ use only\nNo                                                               \
    \                                                                            \
    \                                                            go to 11\nNon-commercial\
    \ use only\nNon-commercial use only\nAre values outside local range because of\
    \ sensor drift or fouling?                                                   \
    \                                                 \nNon-commercial use only\n\
    Are values outside local range because of sensor drift or fouling?           \
    \                                                                            \
    \             \nNon-commercial use only\nYes                                 \
    \                                                                            \
    \                                                                            \
    \             go to 10\nNon-commercial use only\nYes                         \
    \                                                                            \
    \                                                                            \
    \                     go to 10\nNon-commercial use only\nNo                  \
    \                                                                            \
    \                                                                            \
    \                             go to 11\nNon-commercial use only\nNo          \
    \                                                                            \
    \                                                                            \
    \                                     go to 11\n55\nA high frequency monitoring\
    \ system for Lake Maggiore\nsensors, becoming evident after sensor cleaning (Fig.\
    \ 2d).\nThe removal of fouling by sensor cleaning (fouling end\npoint) results\
    \ in a shift of chlorophyll-a values, which pro-\nvides a measure of maximum fouling,\
    \ i.e., estimated as\nthe difference between the chlorophyll-a average values\n\
    12 hours before (ca. 720 points) and 12 hours (ca. 720\npoints) after cleaning.\
    \ The onset of fouling was estimated\nvisually (i.e., the time Chl-a data appeared\
    \ to begin drift-\ning upward). We assumed fouling to be linear, so the cor-\n\
    rection for fouling (the quantity to be subtracted from the\nraw Chl-a data) is\
    \ the linear interpolation between 0 at the\nestimated onset of fouling and the\
    \ maximum fouling at\nthe point of sensor cleaning (Fig. 7b).\nReleasing raw or\
    \ automatically corrected data from\nHFM systems may provide inaccurate baseline\
    \ data for\nenvironmental management, scientific, sanitary, and com-\nFig. 7.\
    \ a) Sensor drift correction using the parameters of the linear regression between\
    \ sensor deviation and time (a’). b) Sensor fouling\ncorrection. Blue dots, retained\
    \ values; red dots, discarded values affected by drift, fouling or sensor cleaning\
    \ operations (i.e., 10 mins\nbefore and after cleaning hour); green dots, corrected\
    \ values; moving averages of the values recorded in the previous 1 hour are provided;\n\
    empty triangles, laboratory pH measures; solid reversed triangle, sensor cleaning\
    \ date; red and green dashed lines (a’) regression lines\nbetween sensor a data\
    \ and time before and after correction.\nNon-commercial use only\n56\nR. Tiberti\
    \ et al.\nmunication purposes. This should be avoided by checking\nthe data before\
    \ release or, when data are released in real-\nor near-to-real-time, all the possible\
    \ source of errors and\ntheir effects on the flow of data should be clearly de-\n\
    scribed. \nTOWARDS A HFM NETWORK FOR LAKES\nIN THE INSUBRIC REGION \nNewly available\
    \ sensor technologies give the oppor-\ntunity of monitoring lakes at unprecedented\
    \ frequencies.\nHowever, HFM systems entails some difficulties related\nto the\
    \ complex technology of sensors and to the manage-\nment of a huge amount of data.\
    \ Depending on the local\ncontext (i.e., expertise availability), creating a functional\n\
    HFM network may present several difficulties, essentially\nrelated to the gap\
    \ in the technical know-how. LM1 should\nbe considered as a pilot experience to\
    \ start filling this\nknowledge gap. The first nine months of LM1 functioning\n\
    enabled us to test the advantages and shortcomings of\nHFM and will provide the\
    \ needed background to imple-\nment the rest of the HFM network in the Insubric\
    \ lakes\nMaggiore, Como and Lugano, none of which was previ-\nously subject to\
    \ in situ real-time monitoring. \nBased on this pilot experience, we highlight\
    \ four\nmajor issues for the development of an efficient HFM sys-\ntem at a regional\
    \ level:\nSensor data accuracy: positioning sensors and data ac-\nquisition must\
    \ be accompanied by shared QA/QC proce-\ndures, to produce accurate data and provide\
    \ reliable and\nconsistent information on lake water quality. \nValue for money:\
    \ frequent field surveys required for\nsensor maintenance (e.g., cleaning) may\
    \ undermine the\ncost-effectiveness of HFM (Garel et al., 2009; Le Vu et\nal.,\
    \ 2011). Reducing survey frequency is a major issue for\nthe implementation of\
    \ a long-term HFM of Insubric lakes,\nfor example, developing shared methods to\
    \ reduce foul-\ning.\nLong-term sustainability: LM1 hardware and software\nunderwent\
    \ several changes (e.g., changing/adding elec-\ntronic components, sensors, and\
    \ data transmission proto-\ncols) which have been possible because LM1 was\ndeveloped\
    \ in-house, having full access to all the hardware\nand software components. This\
    \ also increased replicabil-\nity and transferability of our experience within\
    \ and out-\nside the SIMILE project. \nData access: making raw, real time HFM\
    \ data avail-\nable to the public/users before validation may be inappro-\npriate,\
    \ even when users are provided with an alerting\nabout possible error sources.\
    \ Sound quality check and val-\nidation protocols are essential to provide useful\
    \ data to\nthe users. Within SIMILE the following strategy will be\nadopted, in\
    \ order to manage that data flow: data are auto-\nmatically checked in real-time\
    \ for soundness and gross-\nerror detection and are stored in the local istSOS\
    \ (on-\nbuoy) with an associated quality index. At specific time\nintervals, data\
    \ are aggregated and associated with a new\nquality index resulting from a number\
    \ of data checks, in-\ncluding those tested in the present study (e.g., step test,\n\
    local and global range tests). Successively, aggregated and\nquality checked data\
    \ are transmitted using the selected\ntransmission protocol to the data-centre\
    \ tier consisting of\nseveral Web services dedicated to data collection, protec-\n\
    tion and serving.\nThe present study provides essential indication for the\ninstallation\
    \ of a HFM system and for a shared QA/QC\nprocedures to guarantee the good functioning\
    \ of the sys-\ntem itself and a wise management of HFM data. A shared\ndata validation\
    \ protocol is still under development, based\non the results we gathered during\
    \ this study. The final pro-\ntocol should aim at reducing the validation time\
    \ to facili-\ntate public access to the data with controlled quality.\nCurrently,\
    \ taking advantage of the experience gained with\nLM1, a mooring platform equipped\
    \ with limnological\nsensors has been installed in Lake Lugano, and three\nbuoys\
    \ will be placed in different areas of Lake Como. \nACKNOWLEDGEMENTS\nThis work\
    \ was supported by SIMILE (ID: 523544),\nan Interreg Italian-Swiss project funded\
    \ by the European\nRegional Development Fund (ERDF). The Chlorella\nculture for\
    \ the Chl sensor calibration experiment was\nkindly provided by Roberta. Piscia\
    \ (CNR – IRSA, Ver-\nbania). We are grateful to Cristiana Callieri for her sup-\n\
    port during the laboratory work for sensor calibration.\nWe are also indebted\
    \ with Paola Giacomotti, Arianna\nOrrú and Gabriele Tartari for their assistance\
    \ during field\nsampling and chemical analysis. A great input to the de-\nvelopment\
    \ of HFM in Italian lakes (Maggiore and Orta)\ncame from the research community\
    \ of the NETLAKE\nand GLEON networks. We thank two anonymous re-\nviewers for\
    \ their helpful comments and suggestions on\nthe manuscript.\nREFERENCES\nAlbaladejo\
    \ C, Soto F, Torres R, Sánchez P, López JA, 2012. A\nlow-cost sensor buoy system\
    \ for monitoring shallow marine\nenvironments. Sensors 12:9613-9634. \nAmbrosetti\
    \ W, Barbanti L, 1999. Deep water warming in lakes:\nan indicator of climatic\
    \ change. J. Limnol. 58: 1-9. \nAPAT, IRSA-CNR, 2003. [Metodi analitici per le\
    \ acque. Manu-\nali e linee guida 29/2003].[Handbook in Italian]. APAT,\nIRSA-CNR.\n\
    APHA, AWWA, WEF, 2012. Standard Methods for the exami-\nnation of water and wastewater.\
    \ American Public Health As-\nsociation, Washington DC.\nNon-commercial use only\n\
    data validation protocol is still under development, based\nNon-commercial use\
    \ only\ndata validation protocol is still under development, based\non the results\
    \ we gathered during this study. The final pro-\nNon-commercial use only\non the\
    \ results we gathered during this study. The final pro-\ntocol should aim at reducing\
    \ the validation time to facili-\nNon-commercial use only\ntocol should aim at\
    \ reducing the validation time to facili-\ntate public access to the data with\
    \ controlled quality.\nNon-commercial use only\ntate public access to the data\
    \ with controlled quality.\nNon-commercial use only\nSensor data accuracy: positioning\
    \ sensors and data ac-\nNon-commercial use only\nSensor data accuracy: positioning\
    \ sensors and data ac-\nquisition must be accompanied by shared QA/QC proce-\n\
    Non-commercial use only\nquisition must be accompanied by shared QA/QC proce-\n\
    dures, to produce accurate data and provide reliable and\nNon-commercial use only\n\
    dures, to produce accurate data and provide reliable and\nconsistent information\
    \ on lake water quality. \nNon-commercial use only\nconsistent information on\
    \ lake water quality. \nValue for money: frequent field surveys required for\n\
    Non-commercial use only\nValue for money: frequent field surveys required for\n\
    ., cleaning) may undermine the\nNon-commercial use only\n., cleaning) may undermine\
    \ the\net al.\nNon-commercial use only\net al., 2009; Le Vu \nNon-commercial use\
    \ only\n, 2009; Le Vu \n, 2011). Reducing survey frequency is a major issue for\n\
    Non-commercial use only\n, 2011). Reducing survey frequency is a major issue for\n\
    the implementation of a long-term HFM of Insubric lakes,\nNon-commercial use only\n\
    the implementation of a long-term HFM of Insubric lakes,\nfor example, developing\
    \ shared methods to reduce foul-\nNon-commercial use only\nfor example, developing\
    \ shared methods to reduce foul-\nCurrently, taking advantage of the experience\
    \ gained with\nNon-commercial use only\nCurrently, taking advantage of the experience\
    \ gained with\nLM1, a mooring platform equipped with limnological\nNon-commercial\
    \ use only\nLM1, a mooring platform equipped with limnological\nsensors has been\
    \ installed in Lake Lugano, and three\nNon-commercial use only\nsensors has been\
    \ installed in Lake Lugano, and three\nbuoys will be placed in different areas\
    \ of Lake Como. \nNon-commercial use only\nbuoys will be placed in different areas\
    \ of Lake Como. \nNon-commercial use only\nACKNOWLEDGEMENTS\nNon-commercial use\
    \ only\nACKNOWLEDGEMENTS\nThis work was supported by SIMILE (ID: 523544),\nNon-commercial\
    \ use only\nThis work was supported by SIMILE (ID: 523544),\nan Interreg Italian-Swiss\
    \ project funded by the European\nNon-commercial use only\nan Interreg Italian-Swiss\
    \ project funded by the European\nRegional Development Fund (ERDF). The \nNon-commercial\
    \ use only\nRegional Development Fund (ERDF). The \n57\nA high frequency monitoring\
    \ system for Lake Maggiore\nBanas DP, Grillas I, Auby F, Lescuyer E, Coulet JC,\
    \ Moreteau\nJ, Millet B, 2005. Short time scale changes in underwater\nirradiance\
    \ in a wind exposed lagoon (Vaccarès Lagoon,\nFrance): efficiency of infrequent\
    \ field measurements of\nwater turbidity of weather data to predict irradiance\
    \ in the\nwater column. Hydrobiologia 551:3-16.\nBertone E, Burford M, Hamilton\
    \ D, 2018. Fluorescence probes\nfor real-time remote cyanobacteria monitoring:\
    \ A review of\nchallenges and opportunities. Water Res. 141:152-162.\nBowling\
    \ LC, Zamyadi A, Henderson RK, 2016. Assessment of\nin situ fluorometry to measure\
    \ cyanobacterial presence in\nwater bodies with diverse cyanobacterial populations.\
    \ Water\nRes. 105:22-33.\nBrovelli MA, Cannata M, Rogora M, 2020. SIMILE, a geospa-\n\
    tial enabler of the monitoring of Sustainable Development\nGoal 6 (Ensure availability\
    \ and sustainability of water for\nall). Int. Arch. Photogramm. Remote Sens. Spatial\
    \ Inf. Sci.\n42:4/W20.\nCallieri C, Piscia R, 2002. Photosynthetic efficiency\
    \ and sea-\nsonality of autotrophic picoplankton in Lago Maggiore after\nits recovery.\
    \ Freshwater Biol. 47:941-956. \nCallieri C, Bertoni R, Contesini M, Bertoni F,\
    \ 2014. Lake level\nfluctuations boost toxic cyanobacterial oligotrophic blooms.\n\
    PLoS ONE 9:e109526. \nCampbell JL, Rustad LE, Porter JH, Taylor JR, Dereszynski\
    \ EW,\nShanley JB, Gries C, Henshaw DL, Martin ME, Sheldon\nWE, Boose ER, 2013.\
    \ Quantity is nothing without quality:\nautomated QA/QC for streaming environmental\
    \ sensor data.\nBioScience 63:574-585.\nCannata M, Antonovic M, Molinari M, Pozzoni\
    \ M, 2015. Ist-\nSOS, a new sensor observation management system: soft-\nware\
    \ architecture and a real-case application for flood\nprotection. Geomat. Nat.\
    \ Haz. Risk 6:635-650.\nCNR-IRSA, 2019. [Ricerche sull’evoluzione del Lago Mag-\n\
    giore. Aspetti limnologici. Programma triennale 2016 –\n2018. Campagna 2018 e\
    \ rapporto triennale 2016-18].[Report\nin Italian]. Commissione Internazionale\
    \ per la protezione\ndelle acque italo-svizzere. 160 pp. \nDubelaar GBJ, Geerders\
    \ PJF, Jonker RR, 2004. High frequency\nmonitoring reveals phytoplankton dynamics.\
    \ J. Environ.\nMonit. 6:946−952.\nEuropean Commission, 2000. Council Directive\
    \ 2000/60/EC of\n23 October 2000 establishing a framework for Community\naction\
    \ in the field of water policy. Off. J. Eur. Commun.\nL327. p. 73.\nFastner J,\
    \ Abella S, Litt A, Morabito G, Voros L, Palffy K,\nStraile D, Kummerlin R, Matthews\
    \ D, Phillips G, Chorus I,\n2016. Combating cyanobacterial proliferation by avoiding\n\
    or treating inflows with high P load - experiences from eight\ncase studies. Aquat.\
    \ Ecol. 50:367-383.\nFenocchi A, Rogora M, Sibilla S, Dresti C, 2017. Relevance\
    \ of\ninflows on the thermodynamic structure and on the model-\ning of a deep\
    \ subalpine lake (Lake Maggiore, Northern\nItaly/Southern Switzerland). Limnologica\
    \ 63:42-56.\nFenocchi A, Rogora M, Sibilla S, Ciampittiello M, Dresti C,\n2018.\
    \ Forecasting the evolution in the mixing regime of a\ndeep subalpine lake under\
    \ climate change scenarios through\nnumerical modelling (Lake Maggiore, Northern\
    \ Italy/South-\nern Switzerland). Climate Dynam. 51:3521–3536.\nFiebrich CA, Morgan\
    \ CR, McCombs AG, Hall PKJ, McPherson\nRA, 2010. Quality assurance procedures\
    \ for mesoscale me-\nteorological data. J. Atmos. Ocean. Technol. 27:1565-1582.\n\
    Garel E, Nunes S, Neto J, Fernandes R, Neves R, Marques J,\nFerreira, 2009. The\
    \ autonomous Simpatico system for real-\ntime continuous water-quality and current\
    \ velocity monitor-\ning: examples of application in three Portuguese estuaries.\n\
    Geo-Mar. Lett. 29:331–341.\nGries C, Read JS, Winslow LA, Hanson PC, Weathers\
    \ KC,\n2014. Enabling innovative research by supporting the life\ncycle of high\
    \ frequency streaming sensor data in the Global\nLake Ecological Observatory Network\
    \ (GLEON). In: AGU\nFall Meeting Abstracts 2014.\nHamilton DP, Carey CC, Arvola\
    \ L, Arzberger P, Brewer C, Cole\nJJ, Gaiser E, Hanson PC, Ibelings BW, Jennings\
    \ E, Kratz\nTK, Lin FP, McBride CG, de Motta MD, Muraoka K, Nishri\nA, Qin B,\
    \ Read JS, Rose KC, Ryder E, Weathers KC, Zhu\nG, Trolle D, Brookes JD, 2014.\
    \ A global lake ecological ob-\nservatory network (GLEON) for synthesising high-fre-\n\
    quency sensor data for validation of deterministic ecological\nmodels. Inland\
    \ Waters 5:49-56.\nHill DJ, Minsker BS, Amir E, 2009. Real-time Bayesian anom-\n\
    aly detection in streaming environmental data. Water Re-\nsour. Res. 45:10.1029/2008WR006956.\n\
    Horsburgh JS, Reeder SL, Spackman Jones A, Meline J, 2015.\nOpen source software\
    \ for visualization and quality control\nof continuous hydrologic and water quality\
    \ sensor data. En-\nviron. Modell. Softw. 70:32-44.\nHunter PD, Tyler AN, Gilvear\
    \ DJ, Willby NJ, 2009. Using re-\nmote sensing to aid the assessment of human\
    \ health risks\nfrom blooms of potentially- toxic cyanobacteria. Environ.\nSci.\
    \ Technol. 43:2627-2633.\nISO, 1992. Water quality - Measurement of biochemical\
    \ param-\neters - Spectrometric determination of the chlorophyll-a con-\ncentration.\
    \ \nNorm \nISO \n10260:1992. \nInternational\nOrganization for Standardization\
    \ Publ., Geneva.\nItvánovics V, Honti M, Osztoics A, Shafik HM, Padisák J, Ya-\n\
    cobi Y, Eckert W, 2005. Continuous monitoring of phyto-\nplankton dynamics in\
    \ Lake Balaton (Hungary) using on-line\ndelayed fluorescence excitation spectroscopy.\
    \ Freshwater\nBiol. 50:1950-1970.\nJennings E, Jones S, Arvola L, Staehr PA, Gaiser\
    \ E, Jones ID,\nWeathers KC, Weyhenmeyer GA, Chiu CY, de Eyto E,\n2012. Effects\
    \ of weather-related episodic events in lakes: an\nanalysis based on high-frequency\
    \ data. Freshwater Biol.\n57:589-601.\nJohnson KS, Needoba JA, Riser SC, Showers\
    \ WJ, 2007. Chem-\nical sensor networks for the aquatic environment. Chem.\nRev.\
    \ 107:623-640.\nKhan H, Laas A, Marcé R, Obrador B, 2020. Major effects of\nalkalinity\
    \ on the relationship between metabolism and dis-\nsolved inorganic carbon dynamics\
    \ in lakes. Ecosystems 23:\n1566–1580.\nKlug JL, Richardson DC, Ewing HA, Hargreaves\
    \ BR, Samal\nNR, Vachon D, Pierson DC, Lindsey AM, O’Donnell DM,\nEffler SW, Weathers\
    \ KC, 2012. Ecosystem effects of a trop-\nical cyclone on a network of lakes in\
    \ Northeastern North\nAmerica. Environ. Sci. Technol. 46:11693-11701.\nLaas A,\
    \ de Eyto E, Pierson D, Jennings E, 2016. NETLAKE\nGuidelines for automatic monitoring\
    \ station development.\nTechnical report. NETLAKE COST Action ES1201. 58 pp.\n\
    Non-commercial use only\nA, Qin B, Read JS, Rose KC, Ryder E, Weathers KC, Zhu\n\
    Non-commercial use only\nA, Qin B, Read JS, Rose KC, Ryder E, Weathers KC, Zhu\n\
    Non-commercial use only\nautomated QA/QC for streaming environmental sensor data.\n\
    Non-commercial use only\nautomated QA/QC for streaming environmental sensor data.\n\
    Cannata M, Antonovic M, Molinari M, Pozzoni M, 2015. Ist-\nNon-commercial use\
    \ only\nCannata M, Antonovic M, Molinari M, Pozzoni M, 2015. Ist-\nSOS, a new\
    \ sensor observation management system: soft-\nNon-commercial use only\nSOS, a\
    \ new sensor observation management system: soft-\nware architecture and a real-case\
    \ application for flood\nNon-commercial use only\nware architecture and a real-case\
    \ application for flood\nprotection. Geomat. Nat. Haz. Risk 6:635-650.\nNon-commercial\
    \ use only\nprotection. Geomat. Nat. Haz. Risk 6:635-650.\nCNR-IRSA, 2019. [Ricerche\
    \ sull’evoluzione del Lago Mag-\nNon-commercial use only\nCNR-IRSA, 2019. [Ricerche\
    \ sull’evoluzione del Lago Mag-\ngiore. Aspetti limnologici. Programma triennale\
    \ 2016 –\nNon-commercial use only\ngiore. Aspetti limnologici. Programma triennale\
    \ 2016 –\n2018. Campagna 2018 e rapporto triennale 2016-18].[Report\nNon-commercial\
    \ use only\n2018. Campagna 2018 e rapporto triennale 2016-18].[Report\nin Italian].\
    \ Commissione Internazionale per la protezione\nNon-commercial use only\nin Italian].\
    \ Commissione Internazionale per la protezione\ndelle acque italo-svizzere. 160\
    \ pp. \nNon-commercial use only\ndelle acque italo-svizzere. 160 pp. \nDubelaar\
    \ GBJ, Geerders PJF, Jonker RR, 2004. High frequency\nNon-commercial use only\n\
    Dubelaar GBJ, Geerders PJF, Jonker RR, 2004. High frequency\nmonitoring reveals\
    \ phytoplankton dynamics. J. Environ.\nNon-commercial use only\nmonitoring reveals\
    \ phytoplankton dynamics. J. Environ.\nEuropean Commission, 2000. Council Directive\
    \ 2000/60/EC of\nNon-commercial use only\nEuropean Commission, 2000. Council Directive\
    \ 2000/60/EC of\n23 October 2000 establishing a framework for Community\nNon-commercial\
    \ use only\n23 October 2000 establishing a framework for Community\nG, Trolle\
    \ D, Brookes JD, 2014. A global lake ecological ob-\nNon-commercial use only\n\
    G, Trolle D, Brookes JD, 2014. A global lake ecological ob-\nservatory network\
    \ (GLEON) for synthesising high-fre-\nNon-commercial use only\nservatory network\
    \ (GLEON) for synthesising high-fre-\nquency sensor data for validation of deterministic\
    \ ecological\nNon-commercial use only\nquency sensor data for validation of deterministic\
    \ ecological\nmodels. Inland Waters 5:49-56.\nNon-commercial use only\nmodels.\
    \ Inland Waters 5:49-56.\nHill DJ, Minsker BS, Amir E, 2009. Real-time Bayesian\
    \ anom-\nNon-commercial use only\nHill DJ, Minsker BS, Amir E, 2009. Real-time\
    \ Bayesian anom-\naly detection in streaming environmental data. Water Re-\nNon-commercial\
    \ use only\naly detection in streaming environmental data. Water Re-\nsour. Res.\
    \ 45:10.1029/2008WR006956.\nNon-commercial use only\nsour. Res. 45:10.1029/2008WR006956.\n\
    Horsburgh JS, Reeder SL, Spackman Jones A, Meline J, 2015.\nNon-commercial use\
    \ only\nHorsburgh JS, Reeder SL, Spackman Jones A, Meline J, 2015.\nOpen source\
    \ software for visualization and quality control\nNon-commercial use only\nOpen\
    \ source software for visualization and quality control\nof continuous hydrologic\
    \ and water quality sensor data. En-\nNon-commercial use only\nof continuous hydrologic\
    \ and water quality sensor data. En-\nviron. Modell. Softw. 70:32-44.\nNon-commercial\
    \ use only\nviron. Modell. Softw. 70:32-44.\nHunter PD, Tyler AN, Gilvear DJ,\
    \ Willby NJ, 2009. Using re-\nNon-commercial use only\nHunter PD, Tyler AN, Gilvear\
    \ DJ, Willby NJ, 2009. Using re-\n58\nR. Tiberti et al.\nLaborde S, Antenucci\
    \ J P, Copetti D, Imberger J, 2010. Inflow\nintrusions at multiple scales in a\
    \ large temperate lake. Lim-\nnol. Oceanogr. 55:1301-1312.\nLerner B, Boose E,\
    \ Osterweil L, Ellison A, Clarke L, 2011.\nProvenance and quality control in sensor\
    \ networks, p. 98-\n103. In: M. Jones and C. Gries (eds.), Proceedings of the\n\
    Environmental Information Management Conference, Santa\nBarbara, University of\
    \ California.\nLe Vu B, Vincon-Leite B, Lemaire BJ, Bensoussan N, Calzas\nM, Drezen\
    \ C, Deroubaix JF, Escoffier N, Degres Y,\nFreissinet C, Groleau A, Humbert JF,\
    \ Paolini G, Prévot F,\nQuiblier C, Rioust E, Tassin B, 2011. High-frequency mon-\n\
    itoring of phytoplankton dynamics within the European\nwater framework directive:\
    \ application to metalimnetic\ncyanobacteria. Biogeochemistry 106:229-242.\nLorenzen\
    \ CJ, 1967. Determination of chlorophyll and phaeo-\nphytin Spectrophotometric\
    \ equations. Limnol. Oceanogr.\n12:343-346.\nMarra J, 1997. Analysis of diel variability\
    \ in chlorophyll fluo-\nrescence. J. Mar. Res. 55:767-784.\nMarcé R, George G,\
    \ Buscarinu P, Deidda M, Dunalska J, de\nEyto E, Flaim G, Grossart H, Istvanovics\
    \ V, Lenhardt M,\nMoreno-Ostos E, Obrador B, Ostrovsky I, Pierson DC, Po-\ntužák\
    \ J, Poikane S, Rinke K, Rodríguez-Mozaz S, Staehr\nPA, Šumberová K, Waajen G,\
    \ Weyhenmeyer GA, Weathers\nKC, Zion M, Ibelings BW, Jennings E, 2016. Automatic\n\
    high frequency monitoring for improved lake and reservoir\nmanagement. Environ.\
    \ Sci. Technol. 50:10780-10794.\nMcBride C, Rose KC, 2018. Automated high-frequency\
    \ monitor-\ning and research, p. 419-461. In: D.P. Hamilton, K.J. Collier,\nJ.M.\
    \ Quinn and C. Howard-Williams (eds.), Lake restoration\nhandbook: A New Zealand\
    \ perspective. Cham: Springer. \nMeinson P, Idrizaj A, Nõges P, Nõges T, Laas\
    \ A, 2016. Contin-\nuous and high-frequency measurements in limnology: his-\n\
    tory, applications, and future challenges. Environ. Rev.\n24:1-11.\nMorabito G,\
    \ Oggioni A, Austoni M, 2012. Resource ratio and\nhuman impact: How diatom assemblages\
    \ in Lake Maggiore\nresponded to oligotrophication and climatic variability. Hy-\n\
    drobiologia 698:47-60.\nMorabito G, Rogora M, Austoni M, Ciampittiello M, 2018.\n\
    Could the extreme meteorological events in Lake Maggiore\nwatershed determine\
    \ a climate-driven eutrophication\nprocess? Hydrobiologia 824:163–175.\nMourad\
    \ M, Bertrand-Krajewski JL, 2002. A method for auto-\nmatic validation of long\
    \ time series of data in urban hydrol-\nogy. Water Sci. Technol. 45:263-270.\n\
    Moatar F, Miquel J, Poirel A, 2001. A quality-control method\nfor physical and\
    \ chemical monitoring data. Application to\ndissolved oxygen levels in the river\
    \ Loire (France). J. Hy-\ndrol. 252:25-36.\nNõges T, Anneville O, Guillard J,\
    \ Haberman J, Järvalt A, Manca\nM, Morabito G, Rogora M, Thackeray SJ, Volta P,\
    \ Winfield\nIJ, Nõges P, 2017. Fisheries impacts on lake ecosystem\nstructure\
    \ in the context of a changing climate and trophic\nstate. J. Limnol. 77:1640.\n\
    Pilotti M, Valerio G, Leoni B, 2013. Data set for hydrodynamic\nlake model calibration:\
    \ A deep pre-alpine case. Water Re-\nsour. Res. 49:1–5.\nPires MD, 2010. Evaluation\
    \ fluorometers for the in situ moni-\ntoring of chlorophyll and/or cyanobacteria.\
    \ Deltares Report.\nProject 1203593-000. 17 pp.\nPozzoni M, Salvetti A, Cannata\
    \ M, 2020. Retrospective and\nprospective of hydro-met monitoring system in the\
    \ Canton\nTicino, Switzerland. Hydrol. Sci. J. Ahead-of-print 1-15. \nR Development\
    \ Core Team, 2019. R: A Language and Environ-\nment for Statistical Computing.\
    \ Version 3.5.2. R Foundation\nfor Statistical Computing, Vienna, Austria.\nRead\
    \ JS, Garner B, Pellerin B, Loken L, 2015. sensorQC.\nUSGS-R.\nRead JS, Hamilton\
    \ DP, Jones ID, Muraoka K, Winslow LA,\nKroiss R, Wu CH, Gaiser E, 2011. Derivation\
    \ of lake mixing\nand stratification indices from high-resolution lake buoy\n\
    data. Environ. Modell. Softw. 26:1325-1336.\nRichardson TL, Lawrenz E, Pinckney\
    \ JL, Guajardo RC, Walker\nEA, Paerl HW, MacIntyre HL, 2010. Spectral fluorometric\n\
    characterization of phytoplankton community composition\nusing the Algae Online\
    \ Analyser®. Water Res. 44:2461-\n2472.\nRogora M, Buzzi F, Dresti C, Leoni B,\
    \ Lepori F, Mosello R,\nPatelli M, Salmaso N, 2018. Climatic effects on vertical\n\
    mixing and deep-water oxygen content in the subalpine\nlakes in Italy. Hydrobiologia\
    \ 824:33-50.\nSalmaso N, Mosello R, 2010. Limnological research in the deep\n\
    southern subalpine lakes: synthesis, directions and perspec-\ntives. Adv. Oceanogr.\
    \ Limnol. 1:29-66.\nSalmaso N, Buzzi F, Capelli C, Cerasino L, Leoni B, Lepori\
    \ F,\nRogora M, 2020. Responses to local and global stressors in\nthe large southern\
    \ perialpine lakes: Present status and chal-\nlenges for research and management.\
    \ J. Great Lakes Res.\n46:752-766.\nSheldon WMJ, 2008. Dynamic, rule-based quality\
    \ control\nframework for real-time sensor data, p. 145-150. In: C. Gries\nand\
    \ M.B. Jones (eds.), Proceedings of the Environmental\nInformation Management\
    \ Conference: Sensor Networks.\nSkeffington RA, Halliday SJ, Wade AJ, Bowes MJ,\
    \ Loewenthal\nM, 2015. Using high-frequency water quality data to assess\nsampling\
    \ strategies for the EU Water Framework Directive.\nHydrol. Earth Syst. Sci. 19:2491-2504.\n\
    Song KS, Li L, Li S, Tedesco L, Li LH, Hall B, 2012. Hyper-\nspectral remote sensing\
    \ of total phosphorus (TP) in three\ncentral Indiana water supply reservoirs.\
    \ Water Air Soil Poll.\n223:1481-1502.\nStirbet A, Lazár D, Papageorgiou GC, 2019.\
    \ Chlorophyll a flu-\norescence in cyanobacteria: relation to photosynthesis,\
    \ p.\n79-130. In: A.K. Mishra, D.N. Tiwari and A.N. Rai (eds.)\nCyanobacteria.\
    \ Academic Press.\nStockwell JD, Doubek JP, Adrian R, et al., 2020. Storm impacts\n\
    on phytoplankton community dynamics in lakes. Glob.\nChange Biol. 26:2756-2784.\
    \ \nStrigaro D, Cannata M, Antonovic M, 2019. Boosting a weather\nmonitoring system\
    \ in low income economies using open and\nnon-conventional systems: Data quality\
    \ analysis. Sensors\n19:1185.\nStumpf RP, Wynne TT, Baker DB, Fahnenstiel GL,\
    \ 2012. Inter-\nannual variability of cyanobacterial blooms in Lake Erie.\nPLoS\
    \ One 7:e42444.\nTanentzap AJ, Morabito G, Volta P, Rogora M, Yan ND, Manca\n\
    M, 2020. Climate warming restructures an aquatic food web\nover 28 years. Glob.\
    \ Change Biol. 26:6852-6866.\nNon-commercial use only\nEA, Paerl HW, MacIntyre\
    \ HL, 2010. Spectral fluorometric\nNon-commercial use only\nEA, Paerl HW, MacIntyre\
    \ HL, 2010. Spectral fluorometric\ncharacterization of phytoplankton community\
    \ composition\nNon-commercial use only\ncharacterization of phytoplankton community\
    \ composition\nusing the Algae Online Analyser®. Water Res. 44:2461-\nNon-commercial\
    \ use only\nusing the Algae Online Analyser®. Water Res. 44:2461-\nRogora M, Buzzi\
    \ F, Dresti C, Leoni B, Lepori F, Mosello R,\nNon-commercial use only\nRogora\
    \ M, Buzzi F, Dresti C, Leoni B, Lepori F, Mosello R,\nNon-commercial use only\n\
    ing and research, p. 419-461. In: D.P. Hamilton, K.J. Collier,\nNon-commercial\
    \ use only\ning and research, p. 419-461. In: D.P. Hamilton, K.J. Collier,\nJ.M.\
    \ Quinn and C. Howard-Williams (eds.), Lake restoration\nNon-commercial use only\n\
    J.M. Quinn and C. Howard-Williams (eds.), Lake restoration\nhandbook: A New Zealand\
    \ perspective. Cham: Springer. \nNon-commercial use only\nhandbook: A New Zealand\
    \ perspective. Cham: Springer. \nMeinson P, Idrizaj A, Nõges P, Nõges T, Laas\
    \ A, 2016. Contin-\nNon-commercial use only\nMeinson P, Idrizaj A, Nõges P, Nõges\
    \ T, Laas A, 2016. Contin-\nuous and high-frequency measurements in limnology:\
    \ his-\nNon-commercial use only\nuous and high-frequency measurements in limnology:\
    \ his-\ntory, applications, and future challenges. Environ. Rev.\nNon-commercial\
    \ use only\ntory, applications, and future challenges. Environ. Rev.\nMorabito\
    \ G, Oggioni A, Austoni M, 2012. Resource ratio and\nNon-commercial use only\n\
    Morabito G, Oggioni A, Austoni M, 2012. Resource ratio and\nhuman impact: How\
    \ diatom assemblages in Lake Maggiore\nNon-commercial use only\nhuman impact:\
    \ How diatom assemblages in Lake Maggiore\nresponded to oligotrophication and\
    \ climatic variability. Hy-\nNon-commercial use only\nresponded to oligotrophication\
    \ and climatic variability. Hy-\nMorabito G, Rogora M, Austoni M, Ciampittiello\
    \ M, 2018.\nNon-commercial use only\nMorabito G, Rogora M, Austoni M, Ciampittiello\
    \ M, 2018.\nCould the extreme meteorological events in Lake Maggiore\nNon-commercial\
    \ use only\nCould the extreme meteorological events in Lake Maggiore\nwatershed\
    \ determine a climate-driven eutrophication\nNon-commercial use only\nwatershed\
    \ determine a climate-driven eutrophication\nPatelli M, Salmaso N, 2018. Climatic\
    \ effects on vertical\nNon-commercial use only\nPatelli M, Salmaso N, 2018. Climatic\
    \ effects on vertical\nmixing and deep-water oxygen content in the subalpine\n\
    Non-commercial use only\nmixing and deep-water oxygen content in the subalpine\n\
    lakes in Italy. Hydrobiologia 824:33-50.\nNon-commercial use only\nlakes in Italy.\
    \ Hydrobiologia 824:33-50.\nSalmaso N, Mosello R, 2010. Limnological research\
    \ in the deep\nNon-commercial use only\nSalmaso N, Mosello R, 2010. Limnological\
    \ research in the deep\nsouthern subalpine lakes: synthesis, directions and perspec-\n\
    Non-commercial use only\nsouthern subalpine lakes: synthesis, directions and perspec-\n\
    tives. Adv. Oceanogr. Limnol. 1:29-66.\nNon-commercial use only\ntives. Adv. Oceanogr.\
    \ Limnol. 1:29-66.\nSalmaso N, Buzzi F, Capelli C, Cerasino L, Leoni B, Lepori\
    \ F,\nNon-commercial use only\nSalmaso N, Buzzi F, Capelli C, Cerasino L, Leoni\
    \ B, Lepori F,\nRogora M, 2020. Responses to local and global stressors in\nNon-commercial\
    \ use only\nRogora M, 2020. Responses to local and global stressors in\nthe large\
    \ southern perialpine lakes: Present status and chal-\nNon-commercial use only\n\
    the large southern perialpine lakes: Present status and chal-\nlenges for research\
    \ and management. J. Great Lakes Res.\nNon-commercial use only\nlenges for research\
    \ and management. J. Great Lakes Res.\n59\nA high frequency monitoring system\
    \ for Lake Maggiore\nTapolczai K, Anneville O, Padisák J, Salmaso N, Morabito\
    \ G,\nZohary T, Tadonléké RD, Rimet F, 2015. Occurrence and\nmass development\
    \ of Mougeotia spp. (Zygnemataceae) in\nlarge, deep lakes. Hydrobiologia 745:17-29.\n\
    Taylor JR, Loescher HL, 2013. Automated quality control meth-\nods for sensor\
    \ data: a novel observatory approach. Biogeo-\nsciences 10:4957-4971.\nTran Khac\
    \ V, Hong Y, Plec D, Lemaire BJ, Dubois P, Saad M,\nVinçon-Leite B, 2018. An automatic\
    \ monitoring system for\nhigh-frequency measuring and real-time management of\n\
    cyanobacterial blooms in urban water bodies. Processes\n6:11.\nVitale AJ, Perillo\
    \ GE, Genchi SA, Arias AH, Piccolo M, 2018.\nLow-cost monitoring buoys network\
    \ tracking biogeochem-\nical changes in lakes and marine environments – a regional\n\
    case study. Pure Appl. Chem. 90:1631-1646.\nvon Lehmden DJ, Nelson C, 1977. Quality\
    \ assurance handbook\nfor air pollution measurement systems. Volume II. Ambient\n\
    air specific methods (No. PB-273518; EPA-600/4/77/027a).\nEnvironmental Protection\
    \ Agency, Research Triangle Park,\nNC: 346 pp.\nWagner C, Adrian R, 2009. Cyanobacteria\
    \ dominance: Quanti-\nfying the effects of climate change. Limnol. Oceanogr.\n\
    54:2460-2468.\nWagner RJ, Boulger RWJ, Oblinger CJ, Smith BA, 2006. Guide-\nlines\
    \ and standard procedures for continuous water-quality\nmonitors: station operation,\
    \ record computation, and data\nreporting. U.S. Geological Survey Techniques and\
    \ Methods\n1–D3, Reston: 51 pp.\nWeathers KC, Hanson PC,Arzberger P, Brentrup\
    \ J, Brookes J,\nCarey CC, Gaiser E, Gaiser E, Hamilton DP, Hong GS, Ibel-\nings\
    \ B, Istvánovics V, Jennings E, Kim B, Kratz T, Lin F\0P,\nMuraoka K, O’Reilly\
    \ C, Rose KC, Ryder E, Zhu G, 2013.\nThe Global Lake Ecological Observatory Network\n\
    (GLEON): the evolution of grassroots network science.\nLimnol. Oceanogr. Bull.\
    \ 22:71-73.\nNon-commercial use only\nThe Global Lake Ecological Observatory Network\n\
    Non-commercial use only\nThe Global Lake Ecological Observatory Network\n(GLEON):\
    \ the evolution of grassroots network science.\nNon-commercial use only\n(GLEON):\
    \ the evolution of grassroots network science.\nNon-commercial use only\nLimnol.\
    \ Oceanogr. Bull. 22:71-73.\nNon-commercial use only\nLimnol. Oceanogr. Bull.\
    \ 22:71-73.\n"
  inline_citation: '>'
  journal: Journal of Limnology
  limitations: '>'
  pdf_link: https://jlimnol.it/index.php/jlimnol/article/download/2011/1664
  publication_year: 2021
  relevance_score1: 0
  relevance_score2: 0
  title: 'Automated high frequency monitoring of Lake Maggiore through &lt;em&gt;in
    situ&lt;/em&gt; sensors: system design, field test and data quality control'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'

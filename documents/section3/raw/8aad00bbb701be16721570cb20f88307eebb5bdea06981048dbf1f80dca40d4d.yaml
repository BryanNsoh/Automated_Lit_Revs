- DOI: https://doi.org/10.1016/j.biosystemseng.2019.12.013
  analysis: '>'
  authors:
  - Andrés Villa‐Henriksen
  - Gareth Edwards
  - Liisa Pesonen
  - Ole Green
  - Claus Aage Grøn Sørensen
  citation_count: 203
  full_citation: '>'
  full_text: '>

    Skip to main content Skip to article Journals & Books Search Register Sign in
    Brought to you by: University of Nebraska-Lincoln View PDF Download full issue
    Outline Highlights Keywords 1. Introduction 2. Review methodology 3. IoT implementation
    in arable farming 4. Current and potential applications 5. Challenges and solutions
    6. Conclusions and future perspectives Acknowledgements References Show full outline
    Cited by (220) Figures (5) Tables (2) Table 1 Table 2 Biosystems Engineering Volume
    191, March 2020, Pages 60-84 Review Internet of Things in arable farming: Implementation,
    applications, challenges and potential Author links open overlay panel Andrés
    Villa-Henriksen a b, Gareth T.C. Edwards b, Liisa A. Pesonen c, Ole Green b d,
    Claus Aage Grøn Sørensen a Show more Add to Mendeley Share Cite https://doi.org/10.1016/j.biosystemseng.2019.12.013
    Get rights and content Under a Creative Commons license open access Highlights
    • The role of Internet of Things in arable farming is reviewed. • Internet of
    Things is leading arable farming to become data-driven. • Implementation and application
    are described in depth. • Challenges, corresponding solutions and potentials are
    discussed thoroughly. The Internet of Things is allowing agriculture, here specifically
    arable farming, to become data-driven, leading to more timely and cost-effective
    production and management of farms, and at the same time reducing their environmental
    impact. This review is addressing an analytical survey of the current and potential
    application of Internet of Things in arable farming, where spatial data, highly
    varying environments, task diversity and mobile devices pose unique challenges
    to be overcome compared to other agricultural systems. The review contributes
    an overview of the state of the art of technologies deployed. It provides an outline
    of the current and potential applications, and discusses the challenges and possible
    solutions and implementations. Lastly, it presents some future directions for
    the Internet of Things in arable farming. Current issues such as smart phones,
    intelligent management of Wireless Sensor Networks, middleware platforms, integrated
    Farm Management Information Systems across the supply chain, or autonomous vehicles
    and robotics stand out because of their potential to lead arable farming to smart
    arable farming. During the implementation, different challenges are encountered,
    and here interoperability is a key major hurdle throughout all the layers in the
    architecture of an Internet of Things system, which can be addressed by shared
    standards and protocols. Challenges such as affordability, device power consumption,
    network latency, Big Data analysis, data privacy and security, among others, have
    been identified by the articles reviewed and are discussed in detail. Different
    solutions to all identified challenges are presented addressing technologies such
    as machine learning, middleware platforms, or intelligent data management. Previous
    article in issue Next article in issue Keywords Smart farmingInternet of thingsWireless
    sensor networkFarm management information systemBig dataMachine learning 1. Introduction
    The global population and its food consumption are growing alarmingly quickly,
    while climate change effects are simultaneously complicating the challenge of
    ensuring food security in a sustainable manner (Godfray et al., 2010, Tilman et
    al., 2011). Data-driven agriculture is one of the main strategies and concepts
    proposed to increase production efficiently while decreasing its environmental
    impact (Foley et al., 2011). Data-driven technologies in general are quickly advancing
    with the development of the Internet of Things (IoT), and may become an important
    part of the future of farming (Brewster et al., 2017, Jayaraman et al., 2016,
    Verdouw, 2016, Wolfert et al., 2017). Smart Farming, also called Agriculture 4.0
    or digital farming (CEMA, 2017), is developing beyond the modern concept of precision
    agriculture, which bases its management practices on spatial measurements largely
    thanks to Global Positioning System (GPS) signals. Smart farming bases its management
    tasks also on spatial data but is enhanced with context-awareness and is activated
    by real-time events, improving the performance of hitherto precision agriculture
    solutions (Sundmaeker et al., 2016, Wolfert et al., 2017). Additionally, Smart
    Farming usually incorporates intelligent services for applying and managing Information
    and Communication Technologies (ICT) in farming, and allows transverse integration
    throughout the whole agri-food chain in regards to food safety and traceability
    (Sundmaeker et al., 2016). IoT is therefore a key technology in smart farming
    since it ensures data flow between sensors and other devices, making it possible
    to add value to the obtained data by automatic processing, analysis and access,
    and this leads to more timely and cost-effective production and management effort
    on farms. Simultaneously, IoT enables the reduction of the inherent environmental
    impact by real-time reaction to alert events such as weed, pest or disease detection,
    weather or soil monitoring warnings, which allow for a reduction and adequate
    use of inputs such as agrochemicals or water. IoT eases documentation and supervision
    of different activities as well as the traceability of products, improving the
    environmental surveying and control in farms by the appropriate authorities. The
    IoT concept was introduced by Kevin Ashton in 1999 in relation to linking Radio-Frequency
    Identification (RFID) for supply chains to the internet (Ashton, 2009), but has
    no official definition. It implies, however, the connection of a network of “things”
    to or through the internet without direct human intervention. “Things” can be
    any object with sensors and/or actuators that is uniquely addressable, interconnected
    and accessible through the world-wide computer network, i.e. the Internet. The
    application of IoT in agriculture is advantageous because of the possibility to
    monitor and control many different parameters in an interoperable, scalable and
    open context with an increasing use of heterogeneous automated components (Kamilaris,
    Gao, Prenafeta-Boldu, & Ali, 2016), in addition to the inevitable requirement
    for traceability. As a result of IoT, agriculture is becoming data-driven, i.e.
    making informed real-time decisions for managing the farm, reducing uncertainties
    and inefficiencies, and as a consequence reducing its environmental impact. The
    application of IoT in agriculture, also called Ag-IoT (Zhai, 2017), AIoT (Zou
    & Quan, 2017), or IoF meaning Internet of Farming (Alahmadi, Alwajeeh, Mohanan,
    & Budiarto, 2017) or Internet of Food and Farm (Sundmaeker et al., 2016, Verdouw
    et al., 2017), has received exponentially increasing attention in the scientific
    community (Fig. 1). Even though the publications are mainly dominated by Asian
    scientists (Talavera et al., 2017, Verdouw, 2016), in Europe several large scale
    international pilot projects, such as IoF2020 (Sundmaeker et al., 2016, Verdouw
    et al., 2017), AIOTI (Pérez-Freire & Brillouet, 2015), SmartAgriFood (Kaloxylos
    et al., 2012), SMART AKIS (Djelveh & Bisevac, 2016), or more recently SmartAgriHubs
    (Chatzikostas et al., 2019), are aiming to implement IoT technologies in the agricultural
    industry in Europe. Similar projects elsewhere include the Accelerating Precision
    Agriculture to Decision Agriculture (P2D) project in Australia (Zhang, Baker,
    Jakku, & Llewellyn, 2017), which complement additional major investments with
    the aim to help farmers convert to smart farming (Higgins et al., 2017, Pham and
    Stack, 2018). Download : Download high-res image (95KB) Download : Download full-size
    image Fig. 1. Number of publications per year retrieved from SCOPUS with the following
    searching criteria: (Internet of things OR IoT) AND (agriculture OR farming).
    Several reviews have been done on IoT in agriculture in the relatively short time
    period in which publications about the subject have emerged (Ray, 2017, Stočes
    et al., 2016, Talavera et al., 2017, Tzounis et al., 2017, Verdouw, 2016). In
    addition, review papers have been published with a focus on specific subjects
    related to IoT applied in agriculture, such as Big Data (Kamilaris et al., 2017,
    Wolfert et al., 2017), modelling (O''Grady & O''Hare, 2017), Wireless Sensor Networks
    (WSN) (Jawad, Nordin, Gharghan, Jawad, & Ismail, 2017), food supply chain (Ramundo,
    Taisch, & Terzi, 2016), Internet of Underground Things (Vuran, Salam, Wong, &
    Irmak, 2018), chemical wireless sensors (Kassal, Steinberg, & Murkovi, 2018),
    or Farm Management Information Systems (FMIS) (Fountas, Sørensen et al., 2015;
    Kaloxylos et al., 2012). However, to the authors'' knowledge, no existing review
    has focused on arable farming, which has specific characteristics and challenges
    that differ from those in a controlled environment, i.e. greenhouses, or permanent
    crops such as fruit orchards. Arable farming poses particular challenges due to:
    • much larger farm sizes, which affect the design of the sensor networks, the
    data processing, analysis and extrapolation of limited stationary sensor data,
    and the consequent decision making with regards to actuators, vehicle logistics,
    etc.; • the larger farm sizes also imply that spatial data has a central role
    in arable farming, affecting the data processing, decision making and precision
    machinery employed to address in-field variability not at plant level as in most
    permanent crops, but at subfield level with automatic recognition and actuation
    (Zude-Sasse, Fountas, Gemtos, & Abu-Khalaf, 2016); • greater use of mobile sensors
    and other devices on vehicles, which have specific challenges. While other cropping
    systems may also use sensors and devices on operating machinery, arable farming
    often requires a fleet of vehicles to operate in a co-ordinated fashion. This
    creates issues particularly regarding network infrastructure (Martínez, Pastor,
    Álvarez, & Iborra, 2016), e.g. connectivity to the cloud of moving things that
    rely mainly on mobile networks, or vehicle to implement communication, which implies
    real-time interoperability between machines and devices from different manufacturers
    (Peets, Mouazen, Blackburn, Kuang, & Wiebensohn, 2012); • larger amounts of heterogeneous
    spatial data generated at different rates and from very disparate sources: stationary
    sensors, moving vehicles and implements, satellites, data from web services, etc.,
    which need to be intelligently integrated; • highly varying and uncertain environmental
    conditions, as annual crops are more susceptible to weather changes and other
    external factors than permanent crops, which are more resilient mainly due to
    their deeper roots (Zude-Sasse et al., 2016), or crops in controlled environments.
    This obligates the IoT system to handle both spatial and temporal data, increasing
    the complexity of the data processing as well as the decisions based on the data
    collected. • more diverse types of field tasks per growing season in arable farming,
    from soil preparation and crop establishment, through highly varying plant nursing
    tasks, to coordinated harvest, which increase the complexity and also the risks.
    The IoT in agriculture is a fast-developing field, which can make reviews obsolete
    quickly. This challenge can be overcome by focussing a critical view on the general
    principles, main application areas and identify the limitations and challenges.
    Summarising, the aim of the paper is to provide an up to date novel analytical
    review of the role of IoT in arable farming, with the following specific objectives:
    • Provide an overview of the current situation of IoT technologies deployed in
    arable farming. Focussing on the current use of communication technologies and
    protocols, the generation and analysis of data, and IoT architectures. • Outline
    the different applications and capabilities of IoT in arable farming. • Investigate
    the main challenges encountered by IoT enabling technologies applied to arable
    farming. • Present key potential fields of application where IoT could be employed,
    as well as future directions of the current trends. The remaining part of this
    paper is structured as follows: Section 2 describes the methodology used in this
    review paper. Section 3 provides an overview of the state of the art of IoT technologies
    used in arable farming; Section 4 presents an outline of the current and potential
    IoT-based applications in arable farming; Section 5 discusses the challenges and
    solutions found in its implementation; and lastly, the review closes with Section
    6 in which future directions are summarised. 2. Review methodology In order to
    address the specific objectives identified above, the literature listing from
    the SCOPUS database of the last 11 years has been reviewed. More precisely, the
    timeframe investigated was from 1 January 2008 to 31 December 2018, selected as
    the whole period in which any literature about the subject turned up in the studied
    database. SCOPUS was selected as the primary literature source as it is a key
    peer-reviewed research literature database. The specific keywords used in the
    search criteria where: (Internet of Things OR IoT) AND (agriculture OR farming).
    To ease the searching process, the keywords needed to be present in at least the
    title, abstract, highlights or keywords. Additionally, the articles had to be
    published in English. Articles concerning greenhouse, livestock or permanent crops
    were excluded from the survey, as were supply chain related articles. However,
    issues concerning traceability at farm level were included. The survey was performed
    in a systematic manner following three steps (see Fig. 2): • Firstly, a list of
    1193 articles meeting the search criteria mentioned above was retrieved from the
    database. • In the second step, by reading the titles, any article that was clearly
    not related to arable farming was excluded, leaving a list of 293 articles. •
    In the last step, a second screening was made by reading the abstracts, where
    articles outside the focus of this review were omitted. After this step, 167 articles
    were studied in detail, from which 69 articles were considered relevant, 27 as
    partially relevant, while the rest were considered of little relevance. Relevance
    concerned mainly the connection of the article to the subject studied. The content
    of a relevant article directly addresses the application of an IoT technology
    in an arable farming scenario. A partially relevant article studies a certain
    IoT technology in agriculture in a broader sense. In the distinction made regarding
    little relevant articles included off-topic, lack of novelty, as well as non-peer-reviewed
    articles that lacked scientific rigour, e.g. ambiguous information or absence
    of materials or methods description. Download : Download high-res image (208KB)
    Download : Download full-size image Fig. 2. Reviewing procedure tree diagram.
    The final 167 articles studied included: 77 journal papers, 88 conference papers
    and 4 book chapters, of which 19 were review papers. The final list of articles
    was complemented with other publications that expanded on some of the IoT related
    subjects and technologies mentioned in the studied articles, and did not contain
    the specified keywords. These were found by a targeted search for specific subjects.
    Lastly, in each article from the final list a special focus was made on the IoT
    technologies employed, the applications, the challenges encountered and, finally,
    on potential future perspectives. 3. IoT implementation in arable farming IoT
    has recently been gaining momentum in the farming industry as it can fulfil the
    urgent necessity for interoperability across brands, scalability and traceability
    (Kamilaris et al., 2016). Different technologies are implemented as IoT is still
    evolving, adapting to a great diversity of uses. To cover the range of technologies,
    protocols, standards, etc. employed, this review is addressing the layers in the
    IoT architecture. Three layers normally describe the architecture of the IoT in
    the literature reviewed (Ferrández-Pastor et al., 2018, Khattab et al., 2016,
    Köksal and Tekinerdogan, 2018, Na and Isaac, 2016, Tzounis et al., 2017, Verdouw,
    2016), though some authors divide it into more layers (Ferrández-Pastor et al.,
    2016, Ramundo et al., 2016, Ray, 2017, Talavera et al., 2017, Wang et al., 2014),
    depending on their definitions. More than three layers can especially be relevant
    in IoT systems with edge or fog computing, where an edge/fog computing layer can
    be considered in between the device and network layers (Ferrández-Pastor et al.,
    2016). Even though the naming of the layers also varies depending on the author,
    there is nonetheless a general trend to divide the layers into device, network
    and application layers (Fig. 3). Thus, this has been the adapted structure in
    this review. The device layer consists of the physical objects (things) that are
    capable of automatic identification, sensing or actuation, and connection to the
    internet. The network layer communicates the data to a gateway (or proxy server)
    to the internet (cloud) by the use of communication protocols. And the application
    layer typically stores and facilitates access for the end-user to the processed/analysed
    information. Download : Download high-res image (222KB) Download : Download full-size
    image Fig. 3. IoT architecture represented by device, network and application
    layer, in which the middleware platform is not always present. The collected data
    experience diverse stages during their transition from sensors to cloud, interfaces,
    and occasionally actuators, and these stages have considerable influence on the
    technologies applied in an IoT context. Six main stages regarding data flow have
    been identified in the literature reviewed: sensing/perception, communication/transport/transfer,
    storage, processing, analytics, and actuation and display (Fig. 4). The order
    of the stages is different depending on the IoT setup employed and the computing
    techniques used, e.g. fog and edge computing processes the data before communicating
    it to the cloud, an example of its application in precision farming is given by
    Ferrández-Pastor et al. (2016); while cloud computing processes the data in the
    cloud, examples of this are given by Hernandez-Rojas, Mazon-Olivo, Novillo-Vicuña,
    and Belduma-Vacacela (2018) and Na and Isaac (2016). Nonetheless, sensing/perception
    is normally the first stage, where data are captured by sensors, then the data
    can follow different paths and does not necessarily go through all the steps listed.
    In summary, IoT data is identified to be gathered or generated through three main
    processes: machine generated, which come from sensing devices; process-mediated,
    i.e. commercial data coming from business processes; and human-sourced, recorded
    by humans and digitalised later on (Balducci, Impedovo, Informatica, & Moro, 2018).
    These different sources have an influence on how to process, analyse and use the
    data in IoT solutions, and this needs to be taken into account in the overall
    data acquisition planning process. Download : Download high-res image (171KB)
    Download : Download full-size image Fig. 4. Different agricultural data flows
    in arable farming. 3.1. Device layer As mentioned above, the device layer consists
    of the physical objects (things) that are capable of automatic identification,
    sensing or actuating, and providing connection to the internet. Sensor devices
    measure and collect one or more parameters automatically and transmit the data
    wirelessly to the cloud. And, when the devices become actuators, they generally,
    in turn, receive data from the cloud in order to activate or deactivate some mechanical
    component, e.g. a valve in an irrigation system. The device layer is also often
    called perception layer (Tzounis et al., 2017, Zou and Quan, 2017), sensing layer
    (Na and Isaac, 2016, Wang et al., 2014), or physical layer (Ramundo et al., 2016,
    Talavera et al., 2017). The devices are constituted of a transceiver, a microcontroller,
    an interfacing circuit and one or more sensors and/or actuators. The sensor measures
    a physical parameter, e.g. air temperature that is interpreted and transformed
    into an equivalent analogue signal, i.e. electric voltage or current, which is
    then converted by the interfacing circuit, i.e. Analogue-to-Digital Converter
    (ADC), into a corresponding digital format. Afterwards, the microcontroller, sometimes
    also in the form of microprocessors or single-board computers (Talavera et al.,
    2017), collects the data in digital format from one or more sensors through the
    ADC, and sends them to the transceiver, i.e. a wireless communication module,
    which communicates the data to a gateway. A comparison of microcontrollers and
    single-board computers used in IoT in agriculture has been made by Ray (2017).
    In the case of edge computing, the microcontroller or single-board computer processes
    the data from one or more sensors before communicating them, with the intention
    of, for example, reducing the amount of data to be transferred to the cloud and
    accelerating the data processing (Ferrández-Pastor et al., 2016, Sundmaeker et
    al., 2016). In fog computing the data are processed in the local area network
    level, i.e. in a fog node or IoT gateway (Ahmed, Abdalla et al., 2018, Ahmed,
    De et al., 2018, Ferrández-Pastor et al., 2018). When employing an actuator, the
    signal is received by the transceiver, communicated to the microcontroller, where
    it is then converted to analogue signal by a Digital-to-Analogue Converter (DAC),
    i.e. the interfacing circuit, or to a digital signal by a Digital-to-Digital Converter,
    and finally interpreted by the actuator, which acts in accordance to the signal
    received. In arable farming, when agricultural machinery data are used, i.e. data
    from sensors and devices mounted on tractors or other agricultural machinery,
    the data in digital format is normally collected and accessible through the Controller
    Area Network (CAN) bus in the machine, although in some cases some data are accessible
    through other ports (Oksanen et al., 2016, Peets et al., 2012). Machine and operator
    performance information is accessible through the Machine and Implement Control
    System (MICS) of the machine, which can also be accessed through the CAN bus data.
    MICS data are used to allow machinery operators and farm managers to monitor and
    potentially improve the efficiency of their machines, by employing e.g. smart
    alerts or recommendation systems (Pfeiffer & Blank, 2015). Global Navigation Satellite
    System (GNSS) data, e.g. Real Time Kinematics GPS (RTK-GPS), are often also available
    through the CAN bus port, which allows, among others, vehicle monitoring and dynamic
    optimised route planning Edwards et al., 2017, Villa-Henriksen et al., 2018. Many
    different sensors and actuators are employed in arable farming. The type of device
    used depends on the purpose of the system in addition to the technologies implemented
    in the system. And the number of devices is steadily increasing. The number of
    IoT device installations in farms is expected to increase globally from 30 million
    installations in 2015 to 75 million in 2020. Furthermore, data points generated
    per day and farm are expected to increase from 190000 in 2014 to over half a million
    by 2020 (Meola, 2016). It was also estimated that by 2018 there would be 10 billion
    IoT devices employed in agriculture. However, the great amount of data generated
    is often unused or underutilised (Bennett, 2015), e.g. in countries like Denmark
    with a relative high ICT adoption in farms, in 2016 only 2–5% of farmers worked
    actively with the data generated (SEGES, 2016). Even if data usage is still relatively
    low, it is expected to increase rapidly (Bennett, 2015, Wolfert et al., 2017,
    World Bank, 2017) An overview about how they are implemented for different purposes
    is presented in the Applications section. 3.2. Network layer The network layer
    communicates the data initially to an intermediary platform and eventually to
    the internet (cloud), and from there to, for example, employed actuators. When
    the data are transferred to the intermediary platform, it typically uses wireless
    communication technologies, for instance RFID, WSN with Zigbee, LoRa (Long Range),
    etc., and more recently Near-Field Communication (NFC) (Kassal et al., 2018, Sundmaeker
    et al., 2016, Tzounis et al., 2017, Verdouw, 2016). The intermediary platform
    is normally an internet gateway located in the vicinity of the connected devices,
    also including sometimes a proxy server, where the data are collected and occasionally
    processed in order to send the information further to the end user through the
    internet by the use of e.g. MQTT standards, or HTML or XMPP protocols. The use
    of Android smart devices or other operating systems is also increasing in popularity
    among agricultural applications, as they can be employed as a gateway for 3G and
    4G networks, and they frequently include other wireless communication technologies,
    e.g. Bluetooth, Wi-Fi, GPRS and NFC. They also automatically conform to communication
    standards and protocols, in which way interoperability is increased (Balmos et
    al., 2016, Ferrández-Pastor et al., 2016, Gao and Yao, 2016, Hernandez-Rojas et
    al., 2018, Villa-Henriksen et al., 2018). In addition, Android and other smart
    devices can include GNSS and RGB camera sensors, and can relatively easily be
    programmed for computing data and displaying Graphical User Interface (GUI) applications
    being able to straightforwardly update the software if necessary. In that manner,
    Android and similar smart devices are represented in all three IoT layers, i.e.
    sensing in the device layer, node or gateway in the network layer, and computing
    data and displaying GUI in the application layer. Furthermore, the automatic software
    updating possibilities of smart devices allow remote installation of updates with
    new functionalities, bug fixes, etc. and easily improve the interoperability of
    the system (Ferrández-Pastor et al., 2016). Many different wireless technologies
    have been applied for diverse purposes in agriculture, depending on economic,
    accessibility and capability factors. Jawad et al., 2017, Ray, 2017 and Tzounis
    et al. (2017) have presented good overviews of the specifications of wireless
    communication technologies implemented in IoT in an agricultural context, which
    have been here collected in Table 1 and complemented with information from other
    relevant articles (Alahmadi et al., 2017, Elijah et al., 2018, Kassal et al.,
    2018, Sinha et al., 2017, Sundmaeker et al., 2016). The great variety of technologies,
    standards and frequency bands used exposes the relevant interoperability and application
    challenges found when applying IoT technologies. Potential communication standards
    for smart farming can be classified into short-range and long-range according
    to their communication distance, which determines their specific usability in
    different requirement settings. This is particularly the case in arable farming,
    where mobile network accessibility can be an issue in many rural areas, and where
    large farm sizes limit the use of some wireless technologies due to their reduced
    communication distance and due to the necessity to replace/recharge device batteries
    on nodes over large areas. These issues are addressed in the challenges section
    later. Table 1. Wireless communication technologies (adapted from Jawad et al.,
    2017, Ray, 2017 & Tzounis et al. (2017)). Technology Standard(s) Frequency Data
    rates Range Power ANT+ ANT + Alliance 2.4 GHz 1 Mb s−1 30–100 m 1 mW Cognitive
    Radio IEEE 802.22 WG 54–862 MHz 24 Mb s−1 100 km 1 W Bluetooth (2.0, 2.1, 3.0)
    Bluetooth, IEEE 802.15.1 2400–2483.5 MHz 1–24 Mb s−1 10–100 m 0.1–1 W BLE IoT
    Inter-connect 2400–2483.5 MHz 1 Mb s−1 10 m 10–500 mW EDGE 3GPP GSM 850/1900 MHz
    384 kb s−1 26 km/10 km 3 W/1 W GPRS 3GPP GSM 850/1900 MHz 171 kb s−1 25 km/10
    km 2 W/1 W HSDPA/HSUPA 3GPP 850/1700/1900 MHz 0.73–56 Mb s−1 27 km/10 km 4 W/1
    W ISM/SRD860 IEEE 802.11 433 MHz, 863–870 MHz 200 kb s−1 50 m–2 km Very low LoRaWAN
    LoRaWAN 868/900 MHz, various 0.3–50 kb s−1 2–15 km Very low LR-WPAN IEEE 802.15.4
    (ZigBee) 868/915 MHz, 2.4 GHz 40–250 kb s−1 10–20 m Low LTE 3GPP 700–2600 MHz
    0.1–1 Gb s−1 28 km/10 km 5 W/1 W NB-IoT 3GPP Rel.13 180 kHz DL: 234.7 kb s−1 DI:
    204.8 kb s−1 Using LTE/4G base stations Low NFC ISO/IEC 13157 13.56 MHz 424 kb
    s−1 0.1–0.2 m 1–2 mW RFID Many standards 13.56 MHz 423 kb s−1 1 m 1 mW SigFox
    SigFox 908.42 MHz 10–1000 b s−1 30–50 km N/A THREAD IEEE 802.15.4 2400–2483.5
    MHz 251 kb s−1 11 m 2 mW Weightless-N/W Weightless SIG 700/900 MHz 0.001–10 Mb
    s−1 5 km 40 mW/4 W WiFi IEEE 802.11 a/c/b/d/g/n 2.4, 3.6, 5, 60 GHz 1 Mb s−1–6.75
    Gb s−1 20–100 m 1 W WiMAX IEEE 802.16 2 GHz–66 GHz 1 Mb s−1–1 Gb s−1 (Fixed) 50–100
    Mb s−1 <50 km N/A ZigBee IEEE 802.15.4 2400–2483.5 MHz 250 kb s−1 10 m (100m)
    1 mW Z-Wave Z-Wave 908.42 MHz 100 kb s−1 30 m 1 mW 2G (GSM) GSM, CDMA 865 MHz,
    2.4 GHz 50–100 kb s−1 Mobile network area Medium 3G & 4G UMTS, CDMA2000 865 MHz,
    2.4 GHz 0.2–100 Mb s−1 Mobile network area Medium 5Ga 3GPP, ITU IMT-2020 0.6–6
    GHz, 26, 28, 38, 60 GHz 3.5–20 Gb s−1 (peak rates 10–100 Gb s−1) Mobile network
    area Medium 6LoWPAN IEEE 802.15.4 908.42 MHz or 2400e2483.5 MHz 250 kb s−1 100
    m 1 mW a Not yet publicly available. A WSN is formed by pervasive devices called
    motes or sensor nodes, which integrate sensors and actuators that communicate
    wirelessly forming a spatial network (Hernandez-Rojas et al., 2018, Jawad et al.,
    2017, Tzounis et al., 2017). In a WSN, base stations act as gateways forwarding
    the data to the cloud. Different communication technologies support different
    network node architectures, e.g. star, tree or mesh. Depending on the application,
    different wireless communication technologies are employed in a WSN as each has
    different node architecture possibilities, data rates, ranges, standards, among
    others, with the use of ZigBee, LoRa, Bluetooth/BLE, WiFi and SigFox being relatively
    common in agriculture. In arable farming, BLE has for example been employed for
    soil and air monitoring and irrigation control (Hernandez-Rojas et al., 2018);
    ZigBee was used in a WSN for monitoring soil conditions and actuating an irrigation
    system (Mafuta et al., 2012) and crop monitoring (Zhai, 2017); and LoRa for air
    and water temperature of rice paddy fields (Tanaka, 2018) and smart irrigation
    control (Zhao, Lin et al., 2018, Zhao, Lucani et al., 2018). In order to cover
    larger distances, GPRS is appropriate and has been used for irrigation control
    (López-Riquelme et al., 2017), and for remote maintenance of machinery (Miettinen,
    Oksanen, Suomi, & Visala, 2006). GPRS, or other technologies, such as LTE, or
    3G/4G, are also commonly used at the gateway to transmit data to the cloud. Regarding
    other less common communication technologies used in WSNs, RFID can be integrated
    into a WSN too by connecting the RFID tag readers to a radio-frequency transceiver
    (Costa et al., 2013). Passive and active RFID technologies are used to a great
    extent in agricultural research and industry (Ruiz-Garcia & Lunadei, 2011), especially
    for animal production (e.g. Kamilaris et al., 2016), as well as vegetable or fruit
    product traceability (e.g. Kodali, Jain, & Karagwal, 2017); however, in arable
    farming only few examples have been found: e.g. RFID tags used for irrigation
    scheduling (Vellidis, Tucker, Perry, Kvien, & Bednarz, 2008), for agrochemical
    traceability (Peets, Gasparin, Blackburn, & Godwin, 2009), for vehicle monitoring
    (Sjolander, Thomasson, Sui, & Ge, 2011), and even on a prototype for soil temperature
    monitoring (Hamrita & Hoffacker, 2005). Regarding NFC, no concrete examples of
    NFC used in arable farming have been found in the literature reviewed. Finally,
    the latest generation of mobile communications, i.e. 5G, has higher data rates,
    large coverage areas, higher peak throughput, and also improved flexibility, which
    can open new possibilities and may solve some of the challenges encountered by
    many IoT solutions (Alahmadi et al., 2017, Marsch et al., 2016). 5G allows new
    options for monitoring rural areas with no previous infrastructure for Internet
    connection (Faraci, Raciti, Rizzo, & Schembra, 2018). 5G can also improve vehicle-to-vehicle
    or vehicle-to-anything communication in e.g. logistics solutions, due to its low
    latency and new frequency bands (Marsch et al., 2016). A challenge for the 5G
    networks will be the great increase in devices to support once IoT becomes a standard
    solution not only in agriculture, but also in any sphere of everyday life. 3.3.
    Application layer The application layer is crucial in an IoT context as it is
    this layer that actually adds value to the sensed and communicated data through
    directly controlling devices, supporting farmers'' decision making, etc. In this
    layer, several important services occur such as data storage, data analytics,
    data access through an appropriate Application Programming Interface (API), as
    well as possibly a user interfaced software application. The layer may also include
    middleware platforms that aid handling the heterogeneous cloud data improving
    interoperability. Data storage can be cloud based, i.e. on multiple servers, or
    more local based, where data are stored in different types of databases, depending
    on the application and design. Even if relational databases, such as Structured
    Query Language (SQL) databases (Gao and Yao, 2016, Goap et al., 2018, Ray, 2017,
    Wang et al., 2014), MySQL (Kaloxylos et al., 2014), or PostgreSQL (Mazon-Olivo,
    Hernández-Rojas, Maza-Salinas, & Pan, 2018) are employed in some of the reported
    applications in the reviewed articles, non-relational databases, such as Not only
    SQL (NoSQL), or also SPARQL, a semantic query language based database, are gaining
    attention due to their flexibility and scalability, especially when dealing with
    Big Data. Their ability to store and manage large amounts of heterogeneous data
    makes them suitable in many IoT agricultural contexts (Huang and Zhang, 2017,
    Kamilaris et al., 2017). Examples of NoSQL employed in agriculture are Cassandra
    (Huang & Zhang, 2017), Dynamo (Xian, 2017), HBase (Ray, 2017, Wang et al., 2014)
    and MongoDB (Martínez et al., 2016). An example of SPARQL has been given by Jayaraman
    et al. (2016). Data analytics can be achieved by cloud computing, where computer
    resources are managed remotely to analyse data, often Big Data, or by distributed
    computing, e.g. edge and fog computing. Cloud computing has the advantage that
    it provides high quality services that allow independent execution of multiple
    applications as if they were isolated, even if they are on the same platform,
    e.g. in data centres, which is especially relevant when dealing with Big Data
    (Hernandez-Rojas et al., 2018, Martínez et al., 2016, Tzounis et al., 2017). However,
    cloud computing techniques mostly rely on general purpose cloud providers that
    do not comply with specific agricultural service requirements (López-Riquelme
    et al., 2017) and can experience latency issues, which are not acceptable in IoT
    solutions where monitoring, control and analysis require fast performance (Ferrández-Pastor
    et al., 2018). Examples of application of cloud computing related to arable farming
    are given by Khattab et al., 2016, Na and Isaac, 2016 and López-Riquelme et al.
    (2017). Khattab et al. (2016) present an IoT architecture with a cloud-based back-end
    where weather and soil data are processed and analysed for automatic activation
    of irrigation and spraying actions. Na and Isaac (2016) describe a human-centric
    IoT architecture with a list of cloud services, such as language translation,
    data simplification or updated market price information. And López-Riquelme et
    al. (2017) use FIWARE components for a cloud service for smart irrigation tasks,
    focussing on the benefits of using FIWARE as cloud provider. Regarding Big Data
    analysis and Big Data in general in an agricultural context, Kamilaris et al.
    (2017) and Wolfert et al. (2017) respectively have performed exhaustive reviews
    on the subject. The use of IoT middleware platforms is gaining interest due to
    its potential for solving different challenges found in the application of IoT,
    especially interoperability. IoT middleware platforms try to simplify the complex
    communication through the cloud due to heterogeneity of devices, communications
    and networks, by using enablers like standardised APIs and protocols (Jayaraman
    et al., 2016, Martínez et al., 2016, O''Grady and O''Hare, 2017). Examples of
    these are HYDRA, UBIWARE, UBIROAD, UBIDOTS, SMEPP, SIXTH, Think Speak, SensorCloud,
    Amazon IoT and IBM IoT, with focus on context aware functionality; SOCRADES, GSN
    and SIRENA, with more focus on security and privacy; Aneka, WSO2, PubNub, SmartFarmNet
    and FIWARE, with a wider services-oriented approach; and projects like IoT-A,
    OpenIoT, or ArrowHead (Gill et al., 2017, Jayaraman et al., 2015, Jayaraman et
    al., 2016, Kamilaris et al., 2016, Martínez et al., 2016, Ray, 2017, Sundmaeker
    et al., 2016). Even if all these and more solutions are found in the IoT market,
    an intelligent middleware solution that addresses most issues observed in smart
    farming successfully is yet to be implemented (Jayaraman et al., 2016, Martínez
    et al., 2016, Sundmaeker et al., 2016). However, FIWARE (Ferreira et al., 2017,
    López-Riquelme et al., 2017, Martínez et al., 2016, Rodriguez et al., 2018) and
    SmartFarmNet (Ferrández-Pastor et al., 2018, Jayaraman et al., 2016) have been
    implemented effectively for precision and smart farming applications. In order
    to communicate data across platforms and IoT devices, ensuring interoperability,
    APIs are essential. These should adapt to evolving or new standards in order to
    ensure a longer life span, which may become a limitation if the APIs are not updated.
    It is through the APIs that data are made available for the IoT applications (e.g.
    Goap et al., 2018, Hernandez-Rojas et al., 2018). These services may include tracing,
    monitoring, event management, forecasting or optimisation for agricultural activities
    and products. These applications related to arable farming are described in the
    next section. 4. Current and potential applications Multiple applications can
    be derived from the implementation of IoT in arable farming. These applications
    can always be conceptualised into the three IoT layers described previously, and
    are not to be confused with the application layer. Elaborations of the reviewed
    articles show that the applications have been differentiated and categorised as
    follows: monitoring, documentation, forecasting and controlling. Monitoring refers
    to timely sensing of very diverse parameters and is mostly the initial point of
    entry for other applications. Documentation covers the storing of sampled data
    for later use in e.g. farm management or traceability of produce. Forecasting
    employs different sources of data through precisely designed analytic methods
    for predicting concrete events. And controlling is the result of active monitoring,
    where processed data are used to automatically activate and control actuators
    in a predefined manner. A summarising table collects all the IoT applications
    in arable farming described in this chapter (Table 2). Most IoT-based systems
    include at least two of these applications and isolated applications are seldom
    seen. In addition, special attention has been paid to FMIS and associated decision
    support to improve operations and production processes involving vehicle positioning
    analytics, optimisation and logistics, which are key elements in arable farming
    (Bochtis et al., 2011, Bochtis et al., 2014) and have consequently got a section
    of their own. Table 2. IoT applications in arable farming. Applications Examples
    References Monitoring Crop Leaf area index Bauer and Aschenbruck (2018) Plant
    height and leaf parameters Okayasu et al. (2017) Soil Moisture (Brinkhoff et al.,
    2017, Kodali and Sahu, 2016) Chemistry Kassal et al. (2018) Irrigation water pH
    and salinity Popović et al. (2017) Weather Air (T, atm and RH), rainfall, radiation,
    and wind speed and direction Yan et al. (2018) Remote sensing Estimating crop
    biomass and N content Näsi et al. (2018) Irrigation scheduling and plant disease
    detection Khanal et al. (2017) Machinery Vehicle position and yield data Oksanen
    et al. (2016) Machine performance (Miettinen et al., 2006, Pfeiffer and Blank,
    2015) Farm facilities Crop storage temperature and moisture levels (Green et al.,
    2009, Juul et al., 2015) Environment Nutrient leaching Burton et al. (2018) Contaminants
    Severino et al. (2018) Emissions Manap and Najib (2014) Documentation and traceability
    Machinery Field mapping Fountas, Sørensen et al., 2015 Yield mapping for fertilisation
    planning Lyle et al. (2014) Soil mapping for site-specific amendment measures
    (Godwin and Miller, 2003, McBratney et al., 2003) Remote sensing Mapping crop
    development (Khanal et al., 2017, Näsi et al., 2018, Viljanen et al., 2018) Mapping
    soil texture and residue coverage Khanal et al. (2017) Supply chain Agri-food
    traceability (Bochtis and Sørensen, 2014, Pesonen et al., 2014) Forecasting Machine
    learning models Forecasting max. and min. T at field level Aliev (2018) Estimating
    levels of P in the soil (Estrada-López et al., 2018) Forecasting soil moisture
    Goap et al. (2018) Plant disease forecasting (Aasha Nandhini et al., 2017, Jain
    et al., 2018) Predicting irrigation recommendations Goldstein et al. (2018) Frost
    prediction (Diedrichs et al., 2018, Moon et al., 2018) Forecast of harvest and
    fertilisation dates Viljanen et al. (2018) Classical models Soil moisture and
    contaminant dynamics forecasting for irrigation scheduling Severino et al. (2018)
    Fungal disease forecast in cereals (El Jarroudi et al., 2017, Mäyrä et al., 2018)
    Forecasting field trafficability and workability for field operations Edwards
    et al. (2016) DAISY soil-crop-atmosphere model Abrahamsen and Hansen (2000) RUSLE
    soil erosion model Renard et al. (1991) Controlling Irrigation Fully autonomous
    irrigation scheme Goap et al. (2018) Machinery Variable rate fertilisation Peets
    et al. (2012) Site-specific weed control Christensen et al. (2009) In-row cultivation
    in precision seeding Midtiby et al. (2018) Adaptive route planning in field operations
    (Edwards et al., 2017, Seyyedhasani and Dvorak, 2018, Villa-Henriksen et al.,
    2018) Autonomous vehicles & robots Operations of autonomous vehicles Bechar and
    Vigneault (2016) In-field obstacle detection Christiansen et al. (2016) 4.1. Monitoring
    Automatic monitoring is the obvious first step in IoT applied to agriculture.
    Strategically placed sensors can automatically sense and transmit data to the
    cloud for further documentation, forecasting or controlling applications. Sensors
    are used to monitor crop parameters such as leaf area index (e.g. Bauer & Aschenbruck,
    2018), plant height and leaf colour, size and shape (e.g. Okayasu et al., 2017);
    soil parameters such as soil moisture (e.g. Brinkhoff et al., 2017, Kodali and
    Sahu, 2016) or soil chemistry (e.g. Kassal et al., 2018); irrigation water parameters
    such as pH and salinity (e.g. Popović et al., 2017); or weather parameters such
    as air temperature, air pressure, air relative humidity, rainfall, radiation,
    wind speed and wind direction (e.g. Yan et al., 2018). In addition, remote sensing
    can also be employed, i.e. instead of sensors placed in the field they are installed
    on satellites or Unmanned Aerial Vehicles (UAV). However, these measurements mostly
    require some form of processing and interpretation as the values sampled are not
    directly related to the targeted parameters. An example of monitoring through
    remote sensing is the estimation of crop biomass and nitrogen content by the use
    of hyper- and multispectral images (Näsi et al., 2018), or the use of thermal
    remote sensing, which has been applied for e.g. irrigation scheduling or plant
    disease detection (Khanal, Fulton, & Shearer, 2017). Furthermore, agricultural
    machinery can also be remotely monitored, e.g. vehicle position and yield data
    (Oksanen et al., 2016), or machine performance (Miettinen et al., 2006). This
    is especially relevant with the increasing appearance of autonomous vehicles and
    robots in agriculture (Sundmaeker et al., 2016). Finally, at farm level the storage
    of crops can also be monitored to ensure the correct control of, for example,
    temperature and moisture, and avoid losses due to damage (Green et al., 2009,
    Juul et al., 2015). Environmental impact indicators should be integrated into
    farm monitoring applications, so that leaching (Burton, Dave, Fernandez, Jayachandran,
    & Bhansali, 2018), contaminants (Severino, D’Urso, Scarfato, & Toraldo, 2018)
    or emissions (Manap & Najib, 2014) are addressed too. 4.2. Documentation and traceability
    Collected operations and process data once stored can be used for documentation.
    Documentation is usually the natural application of monitored data but it must
    be noted that it can also include other types of sampled data, such as manually
    input or documentation of performed control actions (Sørensen, Pesonen, Bochtis,
    Vougioukas, & Suomi, 2011). The data are stored as raw data or as processed data
    at different levels. Documentation is essential for decision-making, controlling
    or analytics, and is an indispensable element in FMIS (Kaloxylos et al., 2014).
    Mapping is also a form of documentation where data are spatially projected onto
    a map. On-the-go sensors installed on vehicles and implements can be used for
    automated field mapping (Fountas, Sørensen et al., 2015), e.g. yield mapping used
    for later fertilisation planning (Lyle, Bryan, & Ostendorf, 2014), or soil mapping
    for site-specific amendment measures (Godwin and Miller, 2003, McBratney et al.,
    2003). Remote sensing can also be used for mapping crop development (Khanal et
    al., 2017, Näsi et al., 2018, Viljanen et al., 2018), or soil texture and residue
    coverage (Khanal et al., 2017). Remote sensing is becoming a popular tool for
    monitoring and mapping, but is yet to be proven feasible for all its potential
    applications. When documentation data sets extend beyond the farm level so that
    they can be traced throughout the supply chain, it is often referred as traceability
    and this notion is a key element in agri-food supply chain management as a measure
    to satisfy, for example, consumer demands (Bochtis and Sørensen, 2014, Pesonen
    et al., 2014). 4.3. Forecasting Forecasting is one of the fundamental functions
    for decision making that IoT brings to agriculture. Access to “real-time” data
    and historical data is used for forecasting events that require some form of action
    for managing successfully the crop or field operation. Therefore, both monitoring
    and documentation are important prerequisites for enabling forecasting. Forecasting
    is employed as preventive measures that require some action due to a predicted
    event, e.g. weeding, irrigating or harvesting. Machine learning and scientific
    modelling are examples of tools employed for forecasting. Different machine learning
    models have been employed, e.g. Artificial Neural Networks for forecasting maximum
    and minimum temperatures at field level (Aliev, 2018) or for estimating levels
    of phosphorus (P) in the soil (Estrada-López, Castillo-Atoche, Vázquez-castillo,
    & Sánchez-Sinencio, 2018); support vector regression method for forecasting soil
    moisture (Goap et al., 2018) or plant disease detection (Aasha Nandhini, Hemalatha,
    Radha, & Indumathi, 2017); gradient boosting for predicting irrigation recommendations
    (Goldstein, Fink, & Meitin, 2018); Bayesian networks and random forest for frost
    prediction (Diedrichs, Bromberg, Dujovne, Brun-laguna, & Watteyne, 2018); multiple
    linear regression and random forest in estimating yield and fertilisation requirements
    for forecasting harvest and fertilisation dates (Viljanen et al., 2018); or also
    for frost prediction using four different machine learning algorithms: decision
    tree, boosted tree, random forest, and regression (Moon, Kim, Zhang, & Woo, 2018).
    A rather different forecasting approach was employed by Jain, Sarangi, Bhatt,
    and Pappula (2018), where three different models, i.e. random forest, support
    vector machine and artificial neural network were used for forecasting diseases
    and at the same time for adaptive data collection from the network of nodes in
    order to reduce data traffic and energy consumption of the network. Summarising,
    IoT is allowing the sampling of large amounts of data, which can be employed as
    training data by the machine learning algorithms to build predictive mathematical
    models. Machine learning is opening new possibilities for effectively forecasting
    events in arable farming, which might change the very nature of decision making
    in agriculture. Scientific modelling has also been employed for forecasting in
    an IoT context, e.g. soil moisture dynamics and contaminant migration forecasting
    using soil sensor data and precipitation forecasts for irrigation scheduling (Severino
    et al., 2018); fungal disease forecast in winter wheat (El Jarroudi et al., 2017)
    and barley (Mäyrä, Ruusunen, Jalli, Jauhiainen, & Leiviskä, 2018); or forecasting
    field trafficability and workability for field operations (Edwards, White, Munkholm,
    Sørensen, & Lamandé, 2016). These modelling tools have an important role in agriculture
    as they are conscientiously developed and validated by the scientific community,
    and can forecast events for which machine learning models are very limited. There
    is also considerable potential for integrating existing and acknowledged modelling
    tools such as the soil-crop-atmosphere system model DAISY (Abrahamsen & Hansen,
    2000) or the soil erosion model RUSLE (Renard, Foster, Weesies, & Porter, 1991)
    into an IoT solution. Many of these solutions can make agriculture in general,
    and arable farming in particular, more resource efficient, e.g. through smart
    irrigation, as well as environmentally friendly, e.g. by smart pest and disease
    management. 4.4. Controlling In IoT, controlling is the result of active monitoring
    in an automated system, where the monitored variables are automatically adjusted
    to, for example, predefined thresholds. Forecasting can also play an important
    role in controlling. This is, for example, the case in smart irrigation systems,
    where irrigation is activated before drought damage in the crop is recognised,
    thus reducing yield losses. Goap et al. (2018) employed real-time sensing of soil
    moisture and soil temperature in combination with weather forecasts to control
    a fully autonomous irrigation scheme. Sensors on-the-go installed in tractors
    and implements can also be used to control e.g. variable rate fertilisation (Peets
    et al., 2012), site-specific weed control technologies (Christensen et al., 2009),
    or in-row cultivation controlled by plant patterns in precision seeding (Midtiby,
    Steen, & Green, 2018). Controlling is crucial in smart farming as it allows the
    automation of systems, especially considering the operations of autonomous vehicles
    and robots in the fields (Bechar & Vigneault, 2016), where site-specific actions
    and sensing-based safety systems will play an important role, e.g. for in-field
    obstacle detection for autonomous vehicles (Christiansen, Nielsen, Steen, Jørgensen,
    & Karstoft, 2016). 4.5. FMIS FMIS can be defined as systems that store and process
    farm-related collected data and provide decision supporting tools for farm management
    (Paraforos et al., 2016). FMIS assist farmers in the execution and documentation
    of farm activities, their evaluation and optimisation, as well as in strategic,
    tactical and operational planning of the farm operations (Kaloxylos et al., 2014).
    FMIS are consequently systems that can encapsulate all the applications previously
    described, and are vital elements in smart farm management. However, the adoption
    of FMIS targeted to the new IoT technologies is slow. A study published in 2015
    showed that most FMIS architectures used at that time had been designed in the
    1980s by researchers. This may explain why most FMIS currently have a structure
    and an architecture that is not suitable for distributed and service oriented
    decision support required for supporting precision agriculture and smart farming
    solutions, e.g. 75% of FMIS are still PC-based, and functionalities regarding
    traceability, quality assurance and agronomic best practice estimate are still
    missing or in their initial development stages in most commercial FMIS (Fountas,
    Sørensen et al., 2015). FMIS are key in smart farming and they should support
    automatic data acquisition, monitoring, documenting, planning and decision making
    (Köksal & Tekinerdogan, 2018). The latest research on IoT-based FMIS is expected
    to become part of the commercial FMIS available in the near future and will cover
    different needs across the supply chain and needs of IoT-based agriculture as
    a whole, as well as complying with standards ensuring interoperability between
    systems. In addition, decision support systems (DSS) are essential in dealing
    with Big Data and assisting the farm manager in management and decision making
    in tasks such as farm financial analysis, business processes or supply chain functions
    (Fountas, Carli et al., 2015, Kaloxylos et al., 2012). In order to design an up-to-date
    FMIS, it is beneficial to make preliminary use of dedicated system analysis methodologies,
    such as soft system methodologies (SSM), for identifying required changes and
    constraints and proposing solutions, followed by a later hard system modelling
    for designing the required specifications and components of the system (Sørensen
    et al., 2010, Fountas, Sørensen et al, 2015). It is also necessary to base FMIS
    on the cloud as it allows interconnection with diverse additional services (Kaloxylos
    et al., 2014). This development points out the inevitable need for standardisation
    of APIs in order to achieve interoperability among applications and services as
    part of the FMIS. New technologies such as distributed management systems can
    also enhance the capabilities of FMIS to a great extent (Fountas, Sørensen et
    al., 2015). Furthermore, the introduction of agricultural moving robots in the
    near future, as well as the wireless and automatic control and monitoring of agricultural
    machinery, also needs to be considered in the design and development of FMIS (Fountas,
    Sørensen et al, 2015, Paraforos et al., 2016). The future FMIS will also be capable
    of emulating farmers different work habits, as the system will automate certain
    tasks previously performed by farmers, which will require additional training
    (Sørensen et al., 2011). Consequently, it is important to provide supportive adoption
    and transition strategies for conventional farming to convert into smart farming
    (Köksal & Tekinerdogan, 2018). Examples of current FMIS employed in arable farming
    are offered by different technology providers: machine manufacturers, institutions
    or targeted private companies. Some manufacturers provide their own farm management
    tools, such as Agricultural Management Solutions (AMS) from John Deere, or Precision
    Land Management (PLM) from New Holland. Across brands some FMIS have a more local
    approach, e.g. the Dutch Akkerweb developed by Wageningen University and Research,
    while other commercial solutions have a global approach, e.g. 365FarmNet, Agworld
    or FarmWorks. 4.6. Vehicle navigation, optimisation and logistics Navigation systems
    are widely used in arable farming with the successful implementation of auto-steering
    systems in tractors and harvesters. However, IoT-based solutions are still in
    their early stages. IoT-based field operation monitoring (Oksanen et al., 2016)
    or monitoring of motor and machine performance (Pfeiffer & Blank, 2015) have been
    effectively implemented on harvesting operations. Commercial examples of agricultural
    telematics are Trimble''s Connected Farm, AGCO''s AgCommand, John Deer JDLink,
    New Holland''s PLM Connect or CLAAS’ telematics; however, they are all closed
    systems, which limits greatly the possibilities of the IoT technologies, especially
    interoperability (Oksanen, Piirainen, & Seilonen, 2015). Regarding optimised route
    planning, pre-planning harvest operations based on field data using simulation
    models can improve the harvest capacity of the vehicle or fleet saving working
    hours as well as fuel consumption (Bakhtiari et al., 2011, Bochtis and Sørensen,
    2009, Busato et al., 2007, Jensen et al., 2012, Zhou et al., 2014). However, field
    complexity and vehicle fleet size can become major hurdles for the algorithms
    employed (Seyyedhasani et al., 2019, Skou-Nielsen et al., 2017). The accessibility
    of field and harvest data can be eased by IoT technologies that allow automated
    data collection and sharing via common communication protocols and standards,
    in interoperable data formats, with compatible data model hierarchies; however,
    this is not always the case (Tzounis et al., 2017). IoT also allows cloud or fog
    computing to be employed to solve the high computational requirements of these
    route planning models (Seyyedhasani et al., 2019), even though the computing can
    also be achieved at the edge (Villa-Henriksen et al., 2018). Data communication
    costs, latency problems and unstable mobile connectivity may pose important challenges
    for route planning applications that rely only on cloud computing, making mobile
    edge computing more adequate and robust for these systems. Nevertheless, true
    IoT-based dynamic route planning is still in its infancy but gaining increasing
    attention, especially with the arrival of agricultural robots (Bechar and Vigneault,
    2016, Kayacan et al., 2015). Concerning its application, until recently, harvest
    logistics has employed field sampled data, i.e. boundaries, obstacles, gates,
    etc., to optimise the route of the vehicles involved in the operation statically
    (e.g. Bakhtiari et al., 2011, Jensen et al., 2012), where the complete routes
    of all vehicles are planned a priori. Nevertheless, these plans often do not comply
    with real-world challenges as they do not adapt to variating inputs, e.g. vehicle
    speed changes or in-field yield variations, or to unforeseen situations, e.g.
    machine breakdowns, eventual out of field delays, non-trafficable wet spots, undefined
    obstacles, etc. There is consequently the need to integrate route optimisation
    and operation logistics in IoT systems, where the optimisation can adapt dynamically
    to varying input and unforeseen events. It is only in the last few years that
    harvest logistics really started adapting dynamically to parameters such as vehicles''
    behaviour or in-field yield variations (Edwards et al., 2017, Seyyedhasani and
    Dvorak, 2018, Villa-Henriksen et al., 2018). Today, new possibilities for optimising
    infield operations arrive with the large amount of data available via internet,
    e.g. remote sensing data or other collected spatial data. These could be adaptive
    planning based on trafficability maps for reducing soil compaction or avoiding
    vehicles getting stuck in wet spots; or selective harvesting based on predicted
    grain quality maps, which is expected to increase the value of the crop harvested.
    5. Challenges and solutions When implementing IoT in arable farming, as well as
    in other contexts, diverse challenges limit or affect the performance of the systems
    employed. The challenges identified in the literature reviewed (Fig. 5) can indicate
    which areas need to be taken into account when designing an IoT-based system or
    point out areas that require further research. However, the results presented
    in the figure are indicative and do not necessarily describe the importance of
    the challenges included, especially because of the multiple applications and implementation
    designs that are conceivable in arable farming. Any of the challenges can become
    crucial in different setups, and are therefore described. In addition, all challenges
    can be related to or have consequences for other challenges. Download : Download
    high-res image (464KB) Download : Download full-size image Fig. 5. Percentage
    of challenges mentioned by the literature reviewed, divided by time periods and
    grouped in IoT layers. Interoperability, in general, is a major hurdle in the
    application of IoT. There are different dimensions related to it: technical, syntactical,
    semantic and organisational (Serrano et al., 2015, Veer and Wiles, 2008). Technical
    interoperability refers mostly to the communication protocols which affect the
    hardware and software components implemented. Syntactical interoperability is
    usually related to data formats, their syntax and encoding. Semantic interoperability
    concerns the interpretation of data contents, i.e. the meaning of the information
    exchanged. And organisational interoperability involves intercommunication of
    meaningful information across organisations regardless of information systems
    and infrastructures in a world-wide scale. As interoperability is such a generic
    term, in this section, technical interoperability has been addressed as part of
    the communication protocol challenge, syntactical and semantic interoperability
    have been included under the data heterogeneity challenge, and organisational
    interoperability have been described under the scalability challenge. 5.1. General
    challenges 5.1.1. Revenue and affordability Often the investment for establishing
    an IoT-based solution is high and as such challenging for small-scale farmers,
    while larger farms can more easily acquire IoT-based technologies when investing
    in new equipment (Brewster et al., 2017). The uncertainty regarding required costs,
    e.g. fuel or water allocations, and selling prices of the product give little
    margin for many farmers for investing in new technologies (Higgins et al., 2017).
    Trust plays an important role when investing in IoT systems, and relieving the
    perceived risks by demonstrating the revenues from their adoption is essential
    (Ferrández-Pastor et al., 2016, Jayashankar et al., 2018). For example, in Europe
    70% of all fertilising and spraying machinery is equipped with at least one precision
    agriculture technology, but only 25% of farmers actually use precision agriculture
    components on their farms (Say, Keskin, Sehri, & Sekerli, 2017). Technology providers
    need to increase the perceived value by demonstrating the financial return from
    IoT in order to diminish the perceived risk of adoption many farmers have. Technology
    providers need also to provide robust tools that are aligned with farmer needs
    and practices in order to gain acceptance and trust of IoT technologies. These
    technologies need to reduce the workload, assist in decision making and improve
    the efficiency of the targeted practice. Additionally, technology providers need
    to develop interoperable and flexible solutions that can easily be integrated
    and comply with accepted standards. Governments can also incentivise IoT adoption
    by policies and regulations, especially regarding documentation and traceability
    as ICT eases paperwork and bureaucracy. A reduction in the percentage of mentions
    regarding this challenge (see Fig. 5) could indicate that IoT is being more adopted
    in arable farming. In addition, IoT is likely to reshape the arable farming business.
    The implementation of monitoring and control of farming operations are generating
    substantial amounts of valuable data that are essential for the business of technology
    providers. The way farmers will dive into the data economy, i.e. connecting their
    data to work in vertical and horizontal networks beyond the farm, will have an
    effect on their business models, as well as on the business models of technology
    providers. The point of view of the farmer''s business regarding IoT has not been
    fully addressed in the literature reviewed and will require further investigation.
    5.1.2. Data heterogeneity The diverse data sources and sensor manufacturers imply
    use of different unit systems, data structures and nomenclatures in different
    data formats, which result in reduced syntactical and semantic interoperability
    among IoT environments. Sensor data can be encoded in binary, or represented in
    formats such as json, xml, text (e.g. csv), shapefile, or even proprietary formats.
    The heterogeneity of data types and formats can also affect the performance of
    a protocol employed for communicating the information. Furthermore, this challenge
    becomes critical in situations such as system integration or sharing data with
    other systems (e.g. FMIS), which could imply developing data conversion tools
    or even redesign of the IoT setup. The use of standardised formats can help with
    this challenge. Some attempts have been made at producing standards or standardised
    formats that cover the great heterogeneity of agricultural data, e.g. ISO 11783
    (ISOBUS) developed by the Agricultural Industry Electronics Foundation (AEF) for
    tractors and agricultural machinery, which is very relevant in arable farming
    (Fountas, Sørensen et al, 2015, Miettinen et al., 2006, Oksanen et al., 2015,
    Peets et al., 2012) or AgroXML developed by the Association for Technologies and
    Structures in Agriculture (KTBL) mainly for FMIS (Kaloxylos et al., 2014, Köksal
    and Tekinerdogan, 2018, O''Grady and O''Hare, 2017, Peets et al., 2012). These
    are now being integrated by the non-profit organisation AgGateway through the
    ADAPT framework and SPADE project for seamlessly communicating agricultural machinery
    data to FMIS, trying to enhance the existing standards and as a consequence improve
    interoperability (Brewster et al., 2017). A drawback of comprehensive data models,
    which try to describe all attributes of agricultural data, is that they become
    too cumbersome to handle in many applications. Finally, the use of middleware
    platforms applicable in smart farming, e.g. FIWARE or SmartFarmNet, can also reduce
    the problems caused by data heterogeneity (Ferrández-Pastor et al., 2018, Ferreira
    et al., 2017, O''Grady and O''Hare, 2017, Serrano et al., 2015). 5.1.3. Scalability
    and flexibility Organisational interoperability is a key element concerning scalability
    and flexibility (Serrano et al., 2015, Tzounis et al., 2017, Verdouw, 2016). Many
    of the systems described in the literature reviewed are centralised, closed, difficult
    to integrate in other existing platforms or difficult to implement on larger scales,
    different farming systems or geographical areas. They are also challenging to
    integrate beyond the farm level and across the supply chain in order to provide
    agri-food safety and traceability. The use of standardised dynamic protocols,
    such as SOAP protocol (cloud-based infrastructures with extensible ontologies
    that cover the broad and diverse agricultural production systems and environments),
    fast and reliable APIs (e.g. RESTful) and middleware platforms applicable for
    smart agriculture, such as FIWARE with its generic enablers, are tools that are
    employed to achieve organisational interoperability and make the system developed
    more scalable and flexible (Ferreira et al., 2017, López-Riquelme et al., 2017,
    O''Grady and O''Hare, 2017, Serrano et al., 2015). Service-Oriented Architectures
    (SOA) also bring possibilities to effectively integrate ecosystems through open
    and standardised interfaces, increasing organisational interoperability (Kaloxylos
    et al., 2014, Köksal and Tekinerdogan, 2018, Kruize et al., 2016, Pesonen et al.,
    2014, Sørensen and Bochtis, 2010). Scalability and flexibility may also refer
    to WSNs in the literature, to their capacity to support an increasing number of
    devices/nodes, with the network architecture, the gateway and protocols used being
    the main constrains (Elijah et al., 2018). This challenge has been considered
    under the network size challenge. 5.1.4. Robustness and fault tolerance Many different
    factors can affect the overall robustness and fault tolerance of a system. Robust
    wireless connectivity is an important limitation in many setups (Oksanen et al.,
    2016, Vuran et al., 2018). In the design of an IoT-based solution dealing with
    faults, errors and unforeseen events need to be taken into account in order to
    ensure the reliability of the system. Many of these issues are related to the
    other challenges presented here and can be handled at the device level, but also
    need to be thought of in the overall IoT system design (Ferreira et al., 2017,
    Ray, 2017). 5.1.5. Complexity The agricultural system is complex and can be challenging
    to work with. It is complex not only because of the multifaceted nature of the
    physical, chemical and/or biological processes in the soil-crop-air system, but
    also because of the technical complexity of hardware and software interacting
    with it. Depending on the novelty of the IoT technology implemented and the background
    of the developer and user, the systems can become more or less complex. For example,
    software and hardware incompatibilities can challenge its implementation and integration
    (Ferrández-Pastor et al., 2016), as well as many other challenges, e.g. the great
    field task diversity in arable farming, that can add complexity to the system.
    Technical knowledge can become a major hurdle for the implementation of IoT in
    farms, and it is therefore important that user-friendliness and plug-and-play
    basis have a high priority for the technology providers (Sundmaeker et al., 2016,
    Zou and Quan, 2017). Complexity should be an issue for the technology provider
    and not for the customer. In addition, the co-created development and implementation
    of IoT systems in agriculture by a multi-actor approach is needed to overcome
    the complexity at different levels of integrating IoT in agriculture. Good examples
    of this are the European Union supported research and development efforts through
    multi-actor large-scale pilot projects, such as IoF2020 (Sundmaeker et al., 2016,
    Verdouw et al., 2017), AIOTI (Pérez-Freire & Brillouet, 2015), SmartAgriFood (Kaloxylos
    et al., 2012), SMART AKIS (Djelveh & Bisevac, 2016), or more recently SmartAgriHubs
    (Chatzikostas et al., 2019). 5.1.6. Lack of products In the early stages of precision
    agriculture and IoT in agriculture, products that integrated agronomy and ICT
    engineering were lacking, which hindered their adoption (Ferrández-Pastor et al.,
    2016, Kitchen and Roger, 2007). The large scales and diversity of environments
    in arable farming can challenge the products used even more than in controlled
    environments, as they are to be modelled to describe larger areas, send information
    through larger distances and be exposed to harsher environments. Even if Figure
    5 shows lack of references in the last couple of years, it is still relevant for
    some applications, e.g. for in-situ real-time soil nutrient sensing is still a
    real challenge, especially regarding calibration (Bünemann et al., 2018, Marín-González
    et al., 2013). 5.2. Device layer challenges 5.2.1. Power consumption The use of
    wireless devices has major advantages over wired systems, as they are more economical
    to establish and can cover much wider areas. However, their power consumption,
    with limited battery life, is a major drawback of many wireless systems, and needs
    to be accounted for. This issue is so important that it is the main identified
    challenge in the literature reviewed (Fig. 5), especially for WSNs (Jawad et al.,
    2017, Tan and Panda, 2010). The large distances to cover in arable farming make
    wireless devices indispensable, and solutions to reduce their power consumption
    and/or extend their battery life are required. These solutions can include energy
    harvesting, low power consumption sensors and communication technologies or power
    efficient management. Energy harvesting techniques can include solar cells, micro
    wind turbines or other interesting solutions which have been well described by
    Tuna and Gungor (2016) and Jawad et al. (2017). The power consumption of the communication
    technologies and sensors employed are also to be considered in the design of the
    IoT solution as there are big differences between devices (Balmos et al., 2016,
    Hernandez-Rojas et al., 2018, Jawad et al., 2017). Choosing low power sensors
    and communication devices needs to be taken into account when designing the IoT
    system (Estrada-López et al., 2018). Low power wireless technologies, such as
    BLE, have low power consumption but also low communication range, while Wi-Fi
    has somewhat higher communication range, but much higher power consumption (Table
    1), however data rates and other parameters are important factors to consider
    too. ZigBee and LoRa have been identified as appropriate candidates for many farming
    applications (Jawad et al., 2017). Power efficient management techniques of WSNs
    include sleep/active schemes, e.g. duty-cycling algorithms (Ahmed, Abdalla et
    al., 2018, Ahmed, De et al., 2018, Alahmadi et al., 2017, Balmos et al., 2016,
    Dhall and Agrawal, 2018, Temprilho et al., 2018); data mitigation schemes, e.g.
    data aggregation (Abdel-basset, Shawky, & Eldrandaly, 2018) or data compression
    (Moon et al., 2018); energy-efficient routing schemes, e.g. mobile sinks by the
    use of UAVs (Bacco, Berton, Ferro et al., 2018, Bacco, Berton, Gotta et al., 2018,
    Uddin et al., 2018); and other combined solutions, e.g. LEACH, a cluster architecture
    with Time Division Multiple Access (TDMA) based MAC protocol and data aggregation
    scheme (Kamarudin, Ahmad, & Ndzi, 2016), or dynamic power management by combining
    sleep/active states with dynamic data rates schemes (Estrada-López et al., 2018).
    Jawad et al. (2017) have provided a good overview and description of WSN power
    efficient management techniques. Lastly, techniques such as edge computing may
    have higher power requirements on the device, making cloud computing more desirable
    if power consumption is a constraint in the projected IoT solution. On the other
    hand, mounting sensors and devices on agricultural vehicles and implements allows
    connection to the power supply of the vehicle and as a consequence eliminate power
    consumption as a limiting factor. The type of sensors that are mounted on vehicles
    and their implements is quite limited, being currently mainly camera-based (e.g.
    Midtiby et al., 2018, Steen et al., 2012). Nevertheless, there is for example
    potential in employing sensors on the coulters of seed-drills for mapping soil
    properties (Nielsen et al., 2017), or other on-the-go sensors for mapping soil
    or crop variations (Peets et al., 2012). 5.2.2. Harsh device environment The natural
    environment in which sensors and other devices are placed can greatly challenge
    their functionality and longevity. Harsh weather conditions, e.g. large temperature
    variations, intense rainfall or prolonged high humidity can cause water condensation
    inside devices and consequently provoke corrosion and short circuits (Bauer &
    Aschenbruck, 2018). Sensors and other devices situated close to the ground experience
    exposure to dust, mud, or even corrosive chemicals, e.g. agro-chemicals, which
    can seriously damage the performance of the device or cause its total failure
    (Aliev, 2018, Bauer and Aschenbruck, 2018). Underground chemical sensors are also
    exposed to soil chemical and biological processes that deteriorate the sensors
    and can mislead the measurements, requiring unfeasible maintenance and re-calibrations
    (Burton et al., 2018, Kassal et al., 2018). Choosing adequate casing that does
    not interfere with the functionality of the device and also tolerates the environment
    they are located in is essential in the design of the IoT system. Sensors are
    also developed for different conditions, and need to match the system''s minimum
    requirements. RFID tags have been reported to perform flawlessly under extreme
    conditions and environments (Costa et al., 2013, Ruiz-Garcia and Lunadei, 2011);
    however, RFID technology is quite limited in its applications in arable farming,
    and suitable sensors and communication devices are therefore primarily dependent
    on the application and design of the IoT system. 5.3. Network layer challenges
    5.3.1. Latency, throughput and rate The large amounts of data generated in IoT
    applications do not only cause problems regarding data storage or handling, but
    also latency problems that reduce the throughput of the network employed. In arable
    farming, latency problems can be of great importance in some IoT solutions, e.g.
    in WSNs where high latency implies higher power consumption of a node (López-Riquelme
    et al., 2017), or in dynamic optimised route planning in vehicle logistics, which
    requires rapid responses to deviations in the route plan (Villa-Henriksen et al.,
    2018). For reducing latency problems, fog and edge computing can be employed,
    as these computing techniques decrease latency and network congestion (Elijah
    et al., 2018, Ferrández-Pastor et al., 2018), e.g. data compression at the edge
    reduces the large volumes of data communicated through the network (Moon et al.,
    2018). In addition, the use of lightweight protocols can also reduce latency problems,
    e.g. LP4S for sensors (Hernández-rojas, Fernández-Caramés, Fraga-Lamas, & Escudero,
    2018), or MQTT messaging protocol, which has a faster throughput than HTTP and
    works well for bandwidth limited networks (Estrada-López et al., 2018). The communication
    rate is important to have in mind when planning the wireless communication technology
    to implement, e.g. 5G can handle high-rates, while SigFox or IEEE 802.15.4-based
    protocols are for low-rates (Bacco, Berton, Ferro et al., 2018, Bacco, Berton,
    Gotta et al., 2018, Jawad et al., 2017). The throughput of the network affects
    the communication rate, and the communication rate also influences the power consumption,
    which equally has to be carefully considered. Fast response to events is achieved
    by data processing techniques such as data merging (Tanaka, 2018), data compression
    (Zhao, Lin et al., 2018, Zhao, Lucani et al., 2018), or dynamic and complex event
    processing rules for conditioning input data and immediately acting accordingly
    (Mazon-Olivo et al., 2018). These processes can be on the cloud or at the edge,
    i.e. devices. Finally, test-bed analysis prior to implementation of the network
    can simulate communication rates and possible latency and throughput issues (Stewart,
    Stewart, & Kennedy, 2017). 5.3.2. Wireless link quality A low wireless link quality
    affects greatly the QoS of an IoT system as it ends in unreliable communication
    between nodes (Klaina, Alejos, Aghzout, & Falcone, 2018). This can be caused by
    multipath propagation (Ruiz-Garcia & Lunadei, 2011), background noise (Mazon-Olivo
    et al., 2018), routing problems, e.g. packet collision or limited band width (Jawad
    et al., 2017), or even by harsh environmental conditions, which affect the transceivers
    and the quality of the data transmitted (Elijah et al., 2018). Adequate design
    and testing of the network are crucial for avoiding or reducing this challenge.
    However, techniques such as channel access methods, e.g. TDMA, can improve the
    link quality by reducing packet collisions (Temprilho et al., 2018). Regarding
    testing, the calculation of signal strengths in real-time on the base station
    helps estimating the wireless link quality of a WSN when establishing the system
    (Klaina et al., 2018). Packet loss characterisation can also be used to assess
    the wireless link quality of a connection (Bacco, Berton, Ferro et al., 2018,
    Bacco, Berton, Gotta et al., 2018). Additionally, blind entity identification
    can also help estimating the wireless link quality of a network (Mukherjee, Misra,
    Raghuwanshi, & Mitra, 2018). 5.3.3. Communication range The different wireless
    communication technologies have very diverse ranges, which need to be accounted
    for when designing the IoT solution, together with other factors such as data
    rate, power consumption, communication protocols or costs (Table 1). In arable
    farming, due to the larger farm sizes and because of the employment of mobile
    sensors and devices on vehicles, this challenge becomes even more critical. Furthermore,
    relying on the approximate communication range of a wireless technology can be
    misleading, e.g. WiFi is often described to have 100 m range, but a test analysing
    the packet delivery ratio with respect to distance to gateway shows packet losses
    at ≥ 60 m (Giordano, Seitanidis, Ojo, Adami, & Vignoli, 2018), while in another
    test using WiField devices, 2.6 km range was claimed to be reached still having
    reliable internet connection (Brinkhoff et al., 2017). Testing the communication
    range is therefore important for some settings. In addition to the choice of wireless
    technology, network topology in WSNs, such as mesh topologies can also increase
    the communication range by using nodes to communicate with the central node (Ahmed,
    Abdalla et al., 2018, Ahmed, De et al., 2018). Reduced range due to obstacles
    or topography is addressed in the propagation losses challenge later. 5.3.4. Communication
    protocols Differences in communication protocols can cause technical interoperability
    issues, which can lead to connectivity and compatibility issues among the hardware
    and software employed (Stočes et al., 2016). Network protocols are separated into
    diverse layers forming a protocol stack, where tasks are divided into smaller
    steps (Suhonen, Kohvakka, Kaseva, Hämäläinen, & Hännikäinen, 2012). In the infrastructure
    layer, some wireless standards that define communication protocols are commonly
    used by different wireless technologies, e.g. IEEE 802.15.4, which is used by
    ZigBee or 6LowPAN among others, or 3GPP, which is used by GPRS, LTE or 5G among
    others (see Table 1). In the application layer, standards such as HTTP (Ahmed,
    Abdalla et al., 2018, Ahmed, De et al., 2018, Kaloxylos et al., 2014), MQTT (Ferrández-Pastor
    et al., 2016, Mazon-Olivo et al., 2018) or XMPP (Köksal & Tekinerdogan, 2018)
    are commonly used in IoT applications in arable farming. Adequate protocols are
    especially relevant and challenging in vehicle-to-vehicle communication, and crucial
    in arable farming. Different standards in different layers require careful planning
    of the whole IoT solution, as they are not always compatible and can also have
    an effect on the data formats used, or sensors and gateways employed (Hernandez-Rojas
    et al., 2018). Middleware platforms can ease the integration of diverse protocols
    and standards by offering enough abstraction levels so that this diversity is
    effectively managed (O''Grady and O''Hare, 2017, Tuna et al., 2017). Edge computing
    can also ease technical interoperability issues as a local computing layer is
    created to process data and create control rules before sending the data to the
    cloud (Ferrández-Pastor et al., 2016). 5.3.5. Network management Managing a WSN
    can imply battery change, software updates, calibration of sensors, replacement
    of devices and similar maintenance activities that can be very time-consuming.
    Smart mobile devices, e.g. smart phones, can make remote software updating possible,
    and can sometimes even be used for updating some other IoT devices (Ferrández-Pastor
    et al., 2016). Using energy efficient devices and communication techniques can
    also be employed to extend the battery life of devices (Jawad et al., 2017). Some
    sensors may require recalibrations with a certain periodicity, which has to be
    accounted for in the projected IoT solution (Kassal et al., 2018). Nonetheless,
    the management of the network is always to be considered when implementing IoT
    solutions in arable farming, where distances and number of devices/nodes can be
    vast. 5.3.6. Network size WSN configuration schemes have a maximum number of sensor
    nodes per gateway that the network can handle, i.e. the network size. According
    to the analysis of the reviewed literature, network size is being identified more
    often in the last two years (see Fig. 5), which seems to indicate new possibilities
    for exploiting the capabilities of WSNs. Network size depends on the wireless
    communication technology employed and can affect other parameters, such as data
    latency or scalability of the network (Balmos et al., 2016). Network topologies
    can also influence the network size and vary from simple star network (e.g. Hernandez-Rojas
    et al., 2018) to more advanced multi-hop mesh networks (Ahmed, Abdalla et al.,
    2018, Ahmed, De et al., 2018, Langendoen et al., 2006) that can increase the network
    size by using network nodes as relays to reach a central node and gateway. Optimisation
    algorithms have been used to find the best spatial distribution of WSN nodes,
    and therefore to assist in the optimisation of its network size (Abdel-basset
    et al., 2018). 5.3.7. Propagation losses Even though propagation losses can become
    a big problem for WSNs in application areas like fruit orchards and tree plantations,
    in arable farming hedges, trees, big rocks or sheds, as well as pronounced topography,
    like hills and valleys, can also block, diffract or scatter the signal reducing
    the communication range and causing data packet losses. Additionally, weather
    conditions can also degrade the wireless connectivity propagation of signals (Jawad
    et al., 2017, Kamarudin et al., 2016, Stewart et al., 2017). To avoid or reduce
    these problems, adequate planning of the location of the sensor nodes, the antenna
    height, the communication protocols and the network topology is necessary. Regarding
    network topologies, mesh networks compared to star networks can reduce propagation
    losses as well as increase communication range (Kamarudin et al., 2016, Ruiz-Garcia
    and Lunadei, 2011). Moreover, propagation modelling can help planning, reduce
    communication tests and ensure Quality of Service (QoS) for heterogeneous wireless
    networks (Jawad et al., 2017, Stewart et al., 2017, Kamarudin et al., 2016, Klaina
    et al., 2018, Ruiz-Garcia and Lunadei, 2011). 5.4. Application layer challenges
    5.4.1. Data analysis Data analysis can in some cases become an important challenge,
    especially when dealing with Big Data, which is data in such amounts, heterogeneity
    and complexity that they need new data management techniques for analysis (Wolfert
    et al., 2017). Agricultural Big Data are worthless unless analysed; however, analysis
    can be very challenging because of the volume, diversity, and quality (e.g. errors
    and duplications). This is especially challenging in arable farming, where larger
    amounts of heterogeneous data are generated at diverse rates and from very different
    sources. The literature reviewed show an increased identification of this challenge
    in the last two years compared with the previous 6 years (see Fig. 5). This evolution
    might be caused by increased access and use of agricultural Big Data in recent
    times (Kamilaris et al., 2017, Pham and Stack, 2018). Techniques for lowering
    data dimensionality can ease the analysis by applying feature reduction models,
    which reduce data size by eliminating unnecessary data dimensions (Sabarina &
    Priya, 2015). Cloud computing provides the flexibility and scalability necessary
    for Big Data analysis, where numerous users operate simultaneously with the large
    and complex datasets (Gill et al., 2017). Likewise, cloud platforms are perfect
    for storing such large amounts of data, where NoSQL databases can store and manage
    these large unstructured datasets (Kamilaris et al., 2017). The analysis of Big
    Data can potentially be used, for example, for policy-making, reducing environmental
    negative impact, improve food-safety, as well as improved farm management and
    production, benefiting the different stakeholders involved (Kamilaris et al.,
    2017, Wolfert et al., 2017). Another facet to data analysis is the growing use
    of machine learning techniques, which are being used for exploring Big Data and
    identifying important factors and their interrelationship that affect agricultural
    production systems like, for example, identifying diverse patterns (e.g. crop
    development stages, weeds or diseases) as part of machine vision systems (Bacco,
    Berton, Ferro et al., 2018, Bacco, Berton, Gotta et al., 2018, Reshma and Pillai,
    2018). In these cases, the model is built upon a sample of data, often called
    training data, whose size and quality directly affects the final model. Choosing
    the adequate approach for building the model with the available data is also essential
    for the success of the IoT solution. 5.4.2. Data security and privacy Even though
    data security and privacy do not constitute a high challenge in the literature
    reviewed, they are certainly major concerns for the farmers, i.e. the suppliers
    of data and also end-users of the technology developed, who have little trust
    in service providers'' use of data (Jayashankar et al., 2018, Zhang et al., 2017).
    Also, data ownership needs to be taken into consideration as raw data and processed
    data in IoT systems have different ownership and are accessible by different actors,
    affecting the necessary requirements for data security and privacy (Kaloxylos
    et al., 2014). Research and development focus has been on sensing, processing,
    controlling and computing, while less effort has been devoted to solving security
    threats, risks and privacy (Tuna et al., 2017). Other issues like cost effectiveness
    in, for example, cloud services are also affecting the security of the data, which
    eventually affects the whole privacy and security of the IoT solution, as low-cost
    services have lower security (Dhinari, Newe, Lewis, & Nizamani, 2017). Technology
    providers should prioritise data security and privacy in their business models.
    The availability of privacy and security technologies that are dynamic enough
    to support the vast numbers and variety of stakeholders, as well as the complexity
    of the network, is still a major challenge that needs to be overcome (Verdouw,
    2016). Many solutions are being employed to reduce data security and privacy issues
    in each of the IoT layers of the system, e.g. encryption algorithms, intrusion
    detection mechanisms, authentication, secure routing protocols, anonymisation,
    etc. (Tuna et al., 2017, Tzounis et al., 2017). Middleware platforms are employed
    to add a security layer between network and applications, which can include confidentiality,
    anonymity and security to the system (Rodriguez et al., 2018, Serrano et al.,
    2015, Tuna et al., 2017, Tzounis et al., 2017). Additionally, newer technologies
    such as blockchain are aiming to solve many of the challenges related to privacy
    and security as well as transparency of the IoT. In agriculture, it is mainly
    being applied in the food supply chain (Bermeo-Almeida et al., 2018). Blockchain
    make sense for IoT platforms where large amounts of confidential data are handled.
    5.4.3. Data quality and availability Some of the challenges previously described
    have a direct influence on data quality, e.g. propagation losses, wireless link
    quality, robustness and fault tolerance. Anomaly detection and similar methods
    have been employed to identify faulty data before analysis (Cadavid et al., 2018,
    Lyle et al., 2014). The poor quality of data or its limited availability can limit
    many applications that involve Big Data analytics, modelling and machine learning,
    which can affect or even compromise the success of some IoT solutions (Balducci
    et al., 2018, O''Grady and O''Hare, 2017, Wolfert et al., 2017). In these setups,
    and specifically in arable farming, many datasets are integrated from different
    sources and sensors, and the quality or scarcity of some data can become a major
    hurdle to overcome. Ensuring quality and availability of the data before starting
    such a project is required. Even if it is not always possible to gather all the
    data necessary to develop models, perform correct analytics or train machine learning
    algorithms, scientific assumptions (Severino et al., 2018), data augmentation
    (Diedrichs et al., 2018) or simulated data (Wolanin et al., 2019) are used to
    help or solve the encountered challenge. 5.4.4. Context-awareness (metadata) Context-awareness
    is an important and distinctive feature of Smart Farming as compared to Precision
    Farming, because it automatically includes descriptive data from e.g. fields,
    sensors, machines, i.e. metadata. Metadata can include information about the date
    and time, node identification number, data of calibration, height and position
    information, or even descriptive data about an experiment objective, field, machinery,
    crop genotype or soil information at the sensor placement (Jayaraman et al., 2015).
    Metadata about sensor nodes in the system are crucial for providing contextual
    information so that correct data analysis can be performed (Jayaraman et al.,
    2016, Ray, 2017). Context-awareness helps computing techniques to decide what
    data is to be analysed, and consequently easing the computations, and the lack
    of this data complicate data analysis substantially. This is especially relevant
    in arable farming, where the system has to handle both spatial and temporal data
    and make decisions based on the data collected. The use of standards, formats
    and middleware that support metadata is therefore important to have in mind during
    the planning of an IoT solution (Peets et al., 2009, Ray, 2017). Context-awareness
    facilitates new business models and strategies for data analytics and DSS software
    providers. 6. Conclusions and future perspectives A literature review of current
    and foreseeable IoT technologies and systems in arable farming was carried out.
    This has included an overview of the state of the art of IoT technologies, an
    outline of the current and potential applications, and a thorough description
    of the challenges and solutions. From this survey, the role smart mobile phones
    play is highlighted, especially Android devices, which are employed in different
    ways for a wide diversity of applications, due to their availability, connectivity,
    interoperability, programmable ease and computational power. The introduction
    of 5G networks in the near future will enhance the capabilities of smart mobile
    devices due to their enhanced performance. The intelligent management of WSN as
    well as the capabilities of improved communication technologies can also solve
    some of the challenges IoT-based solutions are experiencing. The role of middleware
    platforms and generic enablers are expected to gain acceptance and importance,
    as they can solve system integration issues and interoperability challenges. In
    general, regarding challenges, interoperability is a main challenge throughout
    the whole IoT architecture, where development and/or acceptance of standards and
    protocols is required to ease the issues encountered by many IoT implementations.
    Furthermore, challenges such as revenue and affordability of IoT systems, the
    power consumption of wireless devices, latency and throughput problems during
    data transfer, as well as the complexity of data analysis, and data privacy and
    security have been identified in the reviewed literature as of high importance,
    and academic research should direct their resources toward solving or reducing
    these issues. Technology developers need to ensure that the solutions create a
    real benefit for farmers and are available and applicable for both large and small
    producers. How IoT generated farm data will affect the business models of farmers
    requires further investigation as it is not fully addressed in the literature
    reviewed. The combination of intelligent power efficient systems with power harvesting
    technologies should guarantee longer battery-life of wireless devices. Computing
    data at the edge, i.e. on the devices, as well as lightweight protocols can reduce
    network latency and capacity/throughput problems. The emergence of Big Data is
    posing significant challenges for data analysis, as the complexity and heterogeneity
    of the huge data sets require the application of new analysis techniques beyond
    those traditionally used. Techniques such as lowering data dimensionality, cloud
    platforms and cloud computing, including machine learning algorithms, can help
    in this area and new innovative solutions are expected to be developed. Finally,
    technology producers have to guarantee privacy and security of the data handled
    throughout all the layers by employing different secure methods without compromising
    the user-friendliness of the solutions employed. Middleware platforms can help
    improving the privacy and security of IoT solutions, and techniques such as blockchain
    can assist with privacy and security problems of IoT platforms when dealing with
    Big Data. In the near future, interoperable and service-oriented FMIS that are
    integrated in the supply chain with intelligent analytic tools will take over
    some of the management and decision-making tasks of farmers and advisors, which
    will require training for farmers to adapt to this type of FMIS. Key decision
    support functions include farm financial analysis, business processes, or supply
    chain functions, which will gain importance with Big Data analytics. In addition,
    DSS for vehicle logistics will grow in importance as a way to optimise field operations
    using route planning and sensor-based site-specific applications. Finally, the
    introduction of autonomous vehicles and robotics in arable farming in the near
    future is expected to completely change arable farming operations and production
    praxes requiring fully adopted IoT capabilities. Acknowledgements This work was
    supported by the European Union''s Horizon 2020 research and innovation programme
    under grant agreement no. 731884, Internet of Food and Farm (IoF2020). References
    Aasha Nandhini et al., 2017 S. Aasha Nandhini, R. Hemalatha, S. Radha, K. Indumathi
    Web enabled plant disease detection system for agricultural applications using
    WMSN Wireless Personal Communications, 1–16 (2017), 10.1007/s11277-017-5092-4
    Google Scholar Abdel-basset et al., 2018 M. Abdel-basset, L.A. Shawky, K. Eldrandaly
    Grid quorum-based spatial coverage for IoT smart agriculture monitoring using
    enhanced multi-verse optimizer Neural Computing & Applications, 4 (2018), 10.1007/s00521-018-3807-4
    Google Scholar Abrahamsen and Hansen, 2000 P. Abrahamsen, S. Hansen Daisy : An
    open soil-crop-atmosphere system model Environmental Modelling & Software, 15
    (2000), pp. 313-330, 10.1016/S1364-8152(00)00003-7 View PDFView articleView in
    ScopusGoogle Scholar Ahmed, Abdalla et al., 2018 E.M.E. Ahmed, K.H.B. Abdalla,
    I.K. Eltahir Farm automation based on IoT 2018 International conference on computer,
    control, electrical, and Electronics engineering (ICCCEEE), IEEE (2018), pp. 1-4
    Google Scholar Ahmed, De et al., 2018 N. Ahmed, D. De, S. Member, I. Hussain Internet
    of Things (IoT) for smart precision agriculture and farming in rural areas IEEE
    Internet of Things Journal, 5 (6) (2018), pp. 4890-4899, 10.1109/JIOT.2018.2879579
    View in ScopusGoogle Scholar Alahmadi et al., 2017 A. Alahmadi, T. Alwajeeh, V.
    Mohanan, R. Budiarto Wireless sensor network with always best connection for internet
    of farming V. Mohanan, R. Budiarto, I. Aldmour (Eds.), Powering the Internet of
    Things with 5G networks, IGI Global, Hershey, PA, USA (2017), pp. 176-201, 10.4018/978-1-5225-2799-2.ch007
    View in ScopusGoogle Scholar Aliev, 2018 K. Aliev Internet of plants application
    for smart agriculture IJACSA - International Journal of Advanced Computer Science
    and Applications, 9 (4) (2018), pp. 421-429, 10.14569/IJACSA.2018.090458 View
    in ScopusGoogle Scholar Ashton, 2009 K. Ashton That “internet of things” Thing
    RFID Journal (2009, June) Retrieved from http://www.rfidjournal.com/articles/view?4986
    Google Scholar Bacco, Berton, Ferro et al., 2018 M. Bacco, A. Berton, E. Ferro,
    C. Gennaro, A. Gotta, S. Matteoli, et al. Smart farming : opportunities, challenges
    and technology enablers 2018 IoT vertical and topical summit on agriculture -
    tuscany (IOT tuscany), IEEE (2018), pp. 1-6, 10.1109/IOT-TUSCANY.2018.8373043
    View in ScopusGoogle Scholar Bacco, Berton, Gotta et al., 2018 M. Bacco, A. Berton,
    A. Gotta, L. Caviglione IEEE 802.15.4 air-ground UAV communications in smart farming
    scenarios IEEE Communications Letters, 22 (9) (2018), pp. 1910-1913, 10.1109/LCOMM.2018.2855211
    View in ScopusGoogle Scholar Bakhtiari et al., 2011 A. Bakhtiari, H. Navid, J.
    Mehri, D.D. Bochtis Optimal route planning of agricultural field operations using
    ant colony optimization Agricultural Engineering International: CIGR Journal,
    13 (4) (2011), pp. 1-16 Retrieved from http://www.cigrjournal.org/index.php/Ejounral/article/view/1939
    Google Scholar Balducci et al., 2018 F. Balducci, D. Impedovo, D. Informatica,
    A. Moro Machine learning applications on agricultural datasets for smart farm
    enhancement Machines, 6 (38) (2018), pp. 1-22, 10.3390/machines6030038 Google
    Scholar Balmos et al., 2016 A.D. Balmos, A.W. Layton, A. Ault, J.V. Krogmeier,
    D.R. Buckmaster Investigation of Bluetooth communications for low-power embedded
    sensor networks in agriculture Transactions of the ASABE, 59 (5) (2016), pp. 1021-1029,
    10.13031/trans.59.11173 View in ScopusGoogle Scholar Bauer and Aschenbruck, 2018
    J. Bauer, N. Aschenbruck Design and implementation of an agricultural monitoring
    system for smart farming In 2018 IoT Vertical and topical Summit on agriculture
    (pp. 1–6), IEEE, Tuscany, Italy (2018), 10.1109/IOT-TUSCANY.2018.8373022 Google
    Scholar Bechar and Vigneault, 2016 A. Bechar, C. Vigneault Agricultural robots
    for field operations: Concepts and components Biosystems Engineering, 149 (2016),
    pp. 94-111, 10.1016/j.biosystemseng.2016.06.014 View PDFView articleView in ScopusGoogle
    Scholar Bennett, 2015 J.M. Bennett Agricultural big Data : Utilisation to discover
    the Unknown and instigate practice change Farm Policy Journal, 12 (1) (2015),
    pp. 43-50 Retrieved from http://www.farminstitute.org.au/publications-1/farm-policy-journals/2015-autumn-from-little-data-big-data-grow/agricultural-big-data-utilisation-to-discover-the-unknown-and-instigate-practice-change
    CrossRefView in ScopusGoogle Scholar Bermeo-Almeida et al., 2018 O. Bermeo-Almeida,
    M. Cardenas-Rodriguez, T. Samaniego-Cobo, E. Ferruzola-Gómez, R. Cabezas-Cabezas,
    W. Bazán-Vera Blockchain in Agriculture : A systematic literature review 4th International
    conference, CITI 2018, proceedings, Springer, Guayaquil, Ecuador (2018), pp. 44-56,
    10.1007/978-3-030-00940-3 View in ScopusGoogle Scholar Bochtis et al., 2011 D.
    Bochtis, O. Green, C.G. Sørensen Spatio-temporal constrained planning software
    for field machinery Journal of Agricultural Machinery Science, 7 (4) (2011), pp.
    399-403 Retrieved from https://dergipark.org.tr/download/article-file/118933 Google
    Scholar Bochtis and Sørensen, 2009 D.D. Bochtis, C.G. Sørensen The vehicle routing
    problem in field logistics part I Biosystems Engineering, 104 (4) (2009), pp.
    447-457, 10.1016/j.biosystemseng.2009.09.003 View PDFView articleView in ScopusGoogle
    Scholar Bochtis and Sørensen, 2014 D. Bochtis, C.G. Sørensen Special issue: Operations
    management - operations management in bio-production systems Operations Management
    in Bio-Production Systems, 120 (2014), pp. 1-116 Retrieved from https://www.sciencedirect.com/journal/biosystems-engineering/vol/120/suppl/C
    View in ScopusGoogle Scholar Bochtis et al., 2014 D.D. Bochtis, C.G.C. Sørensen,
    P. Busato Advances in agricultural machinery management : A review Biosystems
    Engineering, 126 (2014), pp. 69-81, 10.1016/j.biosystemseng.2014.07.012 View PDFView
    articleView in ScopusGoogle Scholar Brewster et al., 2017 C. Brewster, I. Roussaki,
    N. Kalatzis, K. Doolin, K. Ellis IoT in agriculture: Designing a europe-wide large-scale
    pilot IEEE Communications Magazine, 55 (9) (2017), pp. 26-33, 10.1109/MCOM.2017.1600528
    View in ScopusGoogle Scholar Brinkhoff et al., 2017 J. Brinkhoff, J. Hornbuckle,
    W. Quayle, C.B. Lurbe, T. Dowling WiField , an IEEE 802 . 11-based agricultural
    sensor data gathering and logging platform Eleventh International conference on
    sensing technology (ICST) (2017) Google Scholar Bünemann et al., 2018 E.K. Bünemann,
    G. Bongiorno, Z. Bai, R.E. Creamer, G. De Deyn, R. De Goede, et al. Soil quality
    – a critical review Soil Biology and Biochemistry, 120 (February) (2018), pp.
    105-125, 10.1016/j.soilbio.2018.01.030 View PDFView articleView in ScopusGoogle
    Scholar Burton et al., 2018 L. Burton, N. Dave, R.E. Fernandez, K. Jayachandran,
    S. Bhansali Smart gardening IoT soil sheets for real-Time nutrient analysis Journal
    of the Electrochemical Society, 165 (8) (2018), pp. 3157-3162, 10.1149/2.0201808jes
    Google Scholar Busato et al., 2007 P. Busato, R. Berruto, C. Saunders Optimal
    field-bin locations and harvest patterns to improve the combine field Capacity
    : Study with a dynamic simulation model CIOSTA 07 001. Vol. IX. Agricultural engineering
    International: The CIGR ejournal (2007) Retrieved from https://ecommons.cornell.edu/handle/1813/10619
    Google Scholar Cadavid et al., 2018 H. Cadavid, W. Garzón, A. Pérez, G. López,
    C. Mendivelso, C. Ramírez Towards a smart farming Platform : From IoT-based crop
    sensing Colombian conference on computing CCC 2018, communications and information
    science CCIS, Vol. 885 (2018), pp. 237-251, 10.1007/978-3-319-98998-3 View in
    ScopusGoogle Scholar CEMA, 2017 CEMA Digital farming: What does it really mean?
    (2017) Retrieved March 22, 2018 http://cema-agri.org/sites/default/files/CEMA_Digital
    Farming - Agriculture 4.0_ 13 02 2017.pdf Google Scholar Chatzikostas et al.,
    2019 G. Chatzikostas, D. Matic, D. Van Damme, P. Rakers, J. Vangeyte, A. De Visscher,
    et al. Smart agri hubs D3.1 innovation experiment guidelines (2019) Retrieved
    from https://smartagrihubs.eu/Deliverables/pdfs/D3.1_IE Guidelines_final.pdf Google
    Scholar Christensen et al., 2009 S. Christensen, H.T. Søgaard, P. Kudsk, M. Nørremark,
    I. Lund, E.S. Nadimi, et al. Site-specific weed control technologies Weed Research,
    49 (2009), pp. 233-241, 10.1111/j.1365-3180.2009.00696.x View in ScopusGoogle
    Scholar Christiansen et al., 2016 P. Christiansen, L.N. Nielsen, K.A. Steen, R.N.
    Jørgensen, H. Karstoft DeepAnomaly : Combining background subtraction and deep
    learning for detecting obstacles and anomalies in an agricultural field Sensors,
    16 (1904) (2016), pp. 1-21, 10.3390/s16111904 Google Scholar Costa et al., 2013
    C. Costa, F. Antonucci, F. Pallottino, J. Aguzzi, D. Sarriá, P. Menesatti A review
    on agri-food supply chain Traceability by means of RFID Technology Food and Bioprocess
    Technology, 6 (2) (2013), pp. 353-366, 10.1007/s11947-012-0958-7 View in ScopusGoogle
    Scholar Dhall and Agrawal, 2018 R. Dhall, H. Agrawal An improved energy efficient
    duty cycling algorithm for IoT based precision agriculture Procedia Computer Science,
    141 (2018), pp. 135-142, 10.1016/j.procs.2018.10.159 View PDFView articleView
    in ScopusGoogle Scholar Dhinari et al., 2017 L.L. Dhinari, T. Newe, E. Lewis,
    S. Nizamani Cloud computing and Internet of Things fusion: Cost issues Eleventh
    International conference on sensing technology (ICST) (2017), pp. 2-7 Google Scholar
    Diedrichs et al., 2018 A.L. Diedrichs, F. Bromberg, D. Dujovne, K. Brun-laguna,
    T. Watteyne Prediction of frost events using machine learning and IoT sensing
    devices IEEE Internet of Things Journal, 5 (6) (2018), pp. 4589-4597, 10.1109/JIOT.2018.2867333
    View in ScopusGoogle Scholar Djelveh and Bisevac, 2016 S. Djelveh, V. Bisevac
    D3.7. Smart-AKIS policy gaps and briefs (2016) Retrieved from https://www.smart-akis.com/wp-content/uploads/2018/08/SmartAKIS_D3.7_Final.pdf
    Google Scholar Edwards et al., 2017 G.T.C. Edwards, J. Hinge, N. Skou-Nielsen,
    A. Villa-Henriksen, C.A.G. Sørensen, O. Green Route planning evaluation of a prototype
    optimised infield route planner for neutral material flow agricultural operations
    Biosystems Engineering, 153 (2017), pp. 149-157, 10.1016/j.biosystemseng.2016.10.007
    View PDFView articleView in ScopusGoogle Scholar Edwards et al., 2016 G. Edwards,
    D.R. White, L.J. Munkholm, C.G. Sørensen, M. Lamandé Modelling the readiness of
    soil for different methods of tillage Soil and Tillage Research, 155 (2016), pp.
    339-350, 10.1016/j.still.2015.08.013 View PDFView articleView in ScopusGoogle
    Scholar El Jarroudi et al., 2017 M. El Jarroudi, L. Kouadio, M. El Jarroudi, J.
    Junk, C. Bock, A.A. Diouf, et al. Improving fungal disease forecasts in winter
    wheat: A critical role of intra-day variations of meteorological conditions in
    the development of septoria leaf blotch Field Crops Research, 213 (August) (2017),
    pp. 12-20, 10.1016/j.fcr.2017.07.012 View PDFView articleView in ScopusGoogle
    Scholar Elijah et al., 2018 O. Elijah, S. Member, T.A. Rahman An overview of Internet
    of Things (IoT) and data analytics in Agriculture : Benefits and challenges IEEE
    Internet of Things Journal, 5 (5) (2018), pp. 3758-3773, 10.1109/JIOT.2018.2844296
    View in ScopusGoogle Scholar Estrada-López et al., 2018 J.J. Estrada-López, A.A.
    Castillo-Atoche, J. Vázquez-castillo, E. Sánchez-Sinencio Smart soil parameters
    estimation system using an autonomous wireless sensor network with dynamic power
    management strategy Sensors Journal, 18 (21) (2018), pp. 8913-8923, 10.1109/JSEN.2018.2867432
    View in ScopusGoogle Scholar Faraci et al., 2018 G. Faraci, A. Raciti, S. Rizzo,
    G. Schembra A 5G platform for unmanned aerial monitoring in rural areas: Design
    and performance issues IEEE international conference on network softwarization
    (NetSoft 2018) - technical sessions, Vol. 1, IEEE (2018), pp. 237-241, 10.1109/NETSOFT.2018.8459960
    Google Scholar Ferrández-Pastor et al., 2018 F.J. Ferrández-Pastor, J.M. García-Chamizo,
    M. Nieto-Hidalgo, J. Mora-Martínez Precision agriculture design method using a
    distributed computing architecture on Internet of Things context Sensors, 18 (1731)
    (2018), pp. 1-21, 10.3390/s18061731 Google Scholar Ferrández-Pastor et al., 2016
    F. Ferrández-Pastor, J. García-Chamizo, M. Nieto-Hidalgo, J. Mora-Pascual, J.
    Mora-Martínez Developing ubiquitous sensor network platform using Internet of
    Things: Application in precision agriculture Sensors, 16 (8) (2016), p. 1141,
    10.3390/s16071141 View in ScopusGoogle Scholar Ferreira et al., 2017 D. Ferreira,
    P. Corista, J. Gião, S. Ghimire, J. Sarraipa, R. Jardim-gonçalves Towards smart
    agriculture using FIWARE enablers 2017 International conference on engineering,
    technology and Innovation (ICE/ITMC), IEEE, Funchal, Portugal (2017), pp. 1544-1551,
    10.1109/ICE.2017.8280066 View in ScopusGoogle Scholar Foley et al., 2011 J.A.
    Foley, N. Ramankutty, K.A. Brauman, E.S. Cassidy, J.S. Gerber, M. Johnston, et
    al. Solutions for a cultivated planet Nature, 478 (7369) (2011), pp. 337-342,
    10.1038/nature10452 Retrieved from View in ScopusGoogle Scholar Fountas, Carli
    et al., 2015 S. Fountas, G. Carli, C.G. Sørensen, Z. Tsiropoulos, C. Cavalaris,
    A. Vatsanidou, et al. Farm management information systems: Current situation and
    future perspectives Computers and Electronics in Agriculture, 115 (2015), pp.
    40-50, 10.1016/j.compag.2015.05.011 View PDFView articleView in ScopusGoogle Scholar
    Fountas, Sørensen et al, 2015 S. Fountas, C.G. Sørensen, Z. Tsiropoulos, C. Cavalaris,
    V. Liakos, T. Gemtos Farm machinery management information system Computers and
    Electronics in Agriculture, 110 (2015), pp. 131-138, 10.1016/j.compag.2014.11.011
    View PDFView articleView in ScopusGoogle Scholar Gao and Yao, 2016 C. Gao, K.
    Yao The design and implementation of portable Agricultural microclimate data acquisition
    system based on android platform Proceedings - 2015 8th international symposium
    on computational intelligence and design, ISCID 2015, Vol. 1 (2016), pp. 210-213,
    10.1109/ISCID.2015.275 Google Scholar Gill et al., 2017 S.S. Gill, I. Chana, R.
    Buyya IoT based agriculture as a cloud and big data service Journal of Organizational
    and End User Computing, 29 (4) (2017), pp. 1-23, 10.4018/JOEUC.2017100101 View
    in ScopusGoogle Scholar Giordano et al., 2018 S. Giordano, I. Seitanidis, M. Ojo,
    D. Adami, F. Vignoli IoT solutions for crop protection against wild animal attacks
    2018 IEEE International conference on environmental engineering (EE), IEEE (2018),
    pp. 1-5, 10.1109/EE1.2018.8385275 View in ScopusGoogle Scholar Goap et al., 2018
    A. Goap, D. Sharma, A.K. Shukla, C.R. Krishna An IoT based smart irrigation management
    system using Machine learning and open source technologies Computers and Electronics
    in Agriculture, 155 (May) (2018), pp. 41-49, 10.1016/j.compag.2018.09.040 View
    PDFView articleView in ScopusGoogle Scholar Godfray et al., 2010 H.C.J. Godfray,
    J.R. Beddington, I.R. Crute, L. Haddad, D. Lawrence, J.F. Muir, et al. Food Security
    : The challenge of feeding 9 billion people Science, 327 (5967) (2010), pp. 812-818,
    10.1126/science.1185383 View in ScopusGoogle Scholar Godwin and Miller, 2003 R.J.
    Godwin, P.C.H. Miller A review of the technologies for mapping within-field variability
    Biosystems Engineering, 84 (4) (2003), pp. 393-407 View PDFView articleView in
    ScopusGoogle Scholar Goldstein et al., 2018 A. Goldstein, L. Fink, A. Meitin Applying
    machine learning on sensor data for irrigation recommendations : Revealing the
    agronomist''s tacit knowledge Precision Agriculture, 19 (3) (2018), pp. 421-444,
    10.1007/s11119-017-9527-4 View in ScopusGoogle Scholar Green et al., 2009 O. Green,
    E.S. Nadimi, V. Blanes-Vidal, R.N. Jørgensen, I.M.L. Drejer Storm, C.G. Sørensen
    Monitoring and modeling temperature variations inside silage stacks using novel
    wireless sensor networks Computers and Electronics in Agriculture, 69 (2009),
    pp. 149-157, 10.1016/j.compag.2009.07.021 View PDFView articleView in ScopusGoogle
    Scholar Hamrita and Hoffacker, 2005 T.K. Hamrita, E.C. Hoffacker Development of
    a “smart” wireless soil monitoring sensor prototype using RFID technology Applied
    Engineering in Agriculture, 21 (1) (2005), pp. 139-143, 10.13031/2013.17904 View
    in ScopusGoogle Scholar Hernández-rojas et al., 2018 D.L. Hernández-rojas, T.M.
    Fernández-Caramés, P. Fraga-Lamas, C.J. Escudero Design and practical evaluation
    of a family of lightweight protocols for heterogeneous sensing through BLE beacons
    in IoT telemetry applications Sensors, 18 (1) (2018), pp. 1-33, 10.3390/s18010057
    Google Scholar Hernandez-Rojas et al., 2018 D. Hernandez-Rojas, B. Mazon-Olivo,
    J. Novillo-Vicuña, G. Belduma-Vacacela IoT android gateway for monitoring and
    control a WSN M. Botto-Tobar, N. Esparza-Cruz, J. León-Acurio, N. Crespo-Torres,
    M. Beltrán-Mora (Eds.), CITT 2017: Technology trends, Communications in computer
    and information science, Vol. 798, Springer, Cham (2018), pp. 18-32, 10.1007/978-3-319-72727-1_2
    View in ScopusGoogle Scholar Higgins et al., 2017 V. Higgins, M. Bryant, A. Howell,
    J. Battersby Ordering adoption: Materiality, knowledge and farmer engagement with
    precision agriculture technologies Journal of Rural Studies, 55 (2017), pp. 193-202,
    10.1016/j.jrurstud.2017.08.011 View PDFView articleView in ScopusGoogle Scholar
    Huang and Zhang, 2017 J. Huang, L. Zhang The big data processing platform for
    intelligent agriculture AIP Conference Proceedings, 1864 (2017), 10.1063/1.4992850
    Google Scholar Jain et al., 2018 P. Jain, S. Sarangi, P. Bhatt, S. Pappula Development
    of an energy-efficient adaptive IoT gateway model for precision agriculture 2018
    global Internet of Things Summit (GIoTS), IEEE (2018), pp. 1-6, 10.1109/GIOTS.2018.8534553
    Google Scholar Jawad et al., 2017 H. Jawad, R. Nordin, S. Gharghan, A. Jawad,
    M. Ismail Energy-efficient wireless sensor networks for precision agriculture:
    A review Sensors, 17 (8) (2017), p. 1781, 10.3390/s17081781 View in ScopusGoogle
    Scholar Jayaraman et al., 2015 P.P. Jayaraman, D. Palmer, A. Zaslavsky, A. Salehi
    Addressing information processing needs of digital agriculture with OpenIoT platform
    I. Podnar Žarko, K. Pripužić, M. Serrano (Eds.), Interoperability and open-source
    solutions for the Internet of Things. Lecture notes in computer science, Vol.
    9001, Springer, Cham (2015), pp. 137-152, 10.1007/978-3-319-16546-2_11 View in
    ScopusGoogle Scholar Jayaraman et al., 2016 P.P. Jayaraman, A. Yavari, D. Georgakopoulos,
    A. Morshed, A. Zaslavsky Internet of Things platform for smart farming: Experiences
    and lessons learnt Sensors (Switzerland), 16 (11) (2016), pp. 1-17, 10.3390/s16111884
    View in ScopusGoogle Scholar Jayashankar et al., 2018 P. Jayashankar, S. Nilakanta,
    W.J. Johnston, P. Gill, R. Burres, W.J. Johnston IoT adoption in agriculture :
    The role of trust , perceived value and risk Journal of Business & Industrial
    Marketing, 33 (6) (2018), pp. 804-821, 10.1108/JBIM-01-2018-0023 View in ScopusGoogle
    Scholar Jensen et al., 2012 M.A.F. Jensen, D. Bochtis, C.G. Sorensen, M.R. Blas,
    K.L. Lykkegaard In-field and inter-field path planning for agricultural transport
    units Computers & Industrial Engineering, 63 (4) (2012), pp. 1054-1061, 10.1016/j.cie.2012.07.004
    View PDFView articleView in ScopusGoogle Scholar Juul et al., 2015 J.P. Juul,
    O. Green, R.H. Jacobsen Deployment of wireless sensor networks in crop storages
    Wireless Personal Communications, 81 (2015), pp. 1437-1454, 10.1007/s11277-015-2482-3
    View in ScopusGoogle Scholar Kaloxylos et al., 2012 A. Kaloxylos, R. Eigenmann,
    F. Teye, Z. Politopoulou, S. Wolfert, C. Shrank, et al. Farm management systems
    and the Future Internet era Computers and Electronics in Agriculture, 89 (2012),
    pp. 130-144, 10.1016/j.compag.2012.09.002 View PDFView articleView in ScopusGoogle
    Scholar Kaloxylos et al., 2014 A. Kaloxylos, A. Groumas, V. Sarris, L. Katsikas,
    P. Magdalinos, E. Antoniou, et al. A cloud-based farm management system: Architecture
    and implementation Computers and Electronics in Agriculture, 100 (2014), pp. 168-179,
    10.1016/j.compag.2013.11.014 Retrieved from View PDFView articleView in ScopusGoogle
    Scholar Kamarudin et al., 2016 L.M. Kamarudin, R.B. Ahmad, D.L. Ndzi Simulation
    and analysis of LEACH for wireless sensor networks in agriculture ammar zakaria
    and kamarulzaman Kamarudin mohamed Elshaikh Elobaid Said Ahmed, 21 (1) (2016),
    pp. 16-26 View in ScopusGoogle Scholar Kamilaris et al., 2016 A. Kamilaris, F.
    Gao, F.X. Prenafeta-Boldu, M.I. Ali Agri-IoT: A semantic framework for internet
    of Things-enabled smart farming applications 2016 IEEE 3rd world Forum on Internet
    of Things, WF-IoT 2016, 442–447 (2016), 10.1109/WF-IoT.2016.7845467 Google Scholar
    Kamilaris et al., 2017 A. Kamilaris, A. Kartakoullis, F.X. Prenafeta-Boldú A review
    on the practice of big data analysis in agriculture Computers and Electronics
    in Agriculture, 143 (January) (2017), pp. 23-37, 10.1016/j.compag.2017.09.037
    View PDFView articleView in ScopusGoogle Scholar Kassal et al., 2018 P. Kassal,
    M.D. Steinberg, I. Murkovi Chemical wireless chemical sensors and biosensors :
    A review Sensors and Actuators B, 266 (2018), pp. 228-245, 10.1016/j.snb.2018.03.074
    View PDFView articleView in ScopusGoogle Scholar Kayacan et al., 2015 E. Kayacan,
    E. Kayacan, H. Ramon, W. Saeys Towards agrobots : Identification of the yaw dynamics
    and trajectory tracking of an autonomous tractor Computers and Electronics in
    Agriculture, 115 (2015), pp. 78-87, 10.1016/j.compag.2015.05.012 View PDFView
    articleView in ScopusGoogle Scholar Khanal et al., 2017 S. Khanal, J. Fulton,
    S. Shearer An overview of current and potential applications of thermal remote
    sensing in precision agriculture Computers and Electronics in Agriculture, 139
    (2017), pp. 22-32, 10.1016/j.compag.2017.05.001 View PDFView articleView in ScopusGoogle
    Scholar Khattab et al., 2016 A. Khattab, A. Abdelgawad, A. Khattab Design and
    implementation of a cloud-based IoT scheme for precision agriculture 28th International
    Conference on Microelectronics, Vols. 10–14 (2016), 10.1109/ICM.2016.7847850 Google
    Scholar Kitchen and Roger, 2007 N.R. Kitchen, R.D. Roger Emerging technologies
    for real-time and integrated agriculture decisions Computers and Electronics in
    Agriculture, 61 (2007), pp. 1-3, 10.1016/j.compag.2007.06.007 Google Scholar Klaina
    et al., 2018 H. Klaina, A.V. Alejos, O. Aghzout, F. Falcone Narrowband characterization
    of near-ground radio Sensors, 18 (2428) (2018), pp. 1-15, 10.3390/s18082428 Google
    Scholar Kodali et al., 2017 R.K. Kodali, V. Jain, S. Karagwal IoT based smart
    greenhouse IEEE region 10 humanitarian technology conference 2016, R10-HTC 2016
    - proceedings (2017), 10.1109/R10-HTC.2016.7906846 Google Scholar Kodali and Sahu,
    2016 R.K. Kodali, A. Sahu An IoT based soil moisture monitoring on Losant platform
    Proceedings of the 2016 2nd International conference on contemporary computing
    and informatics, IC3I 2016 (2016), pp. 764-768, 10.1109/IC3I.2016.7918063 View
    in ScopusGoogle Scholar Köksal and Tekinerdogan, 2018 Ö. Köksal, B. Tekinerdogan
    Architecture design approach for IoT - based farm management information systems
    Precision Agriculture, 1–33 (2018), 10.1007/s11119-018-09624-8 Google Scholar
    Kruize et al., 2016 J.W. Kruize, J. Wolfert, H. Scholten, C.N. Verdouw, A. Kassahun,
    A.J.M. Beulens Original papers A reference architecture for farm software ecosystems
    Computers and Electronics in Agriculture, 125 (2016), pp. 12-28, 10.1016/j.compag.2016.04.011
    View PDFView articleView in ScopusGoogle Scholar Langendoen et al., 2006 K. Langendoen,
    A. Baggio, O. Visser Murphy loves potatoes: Experiences from a pilot sensor network
    deployment in precision agriculture Proceedings 20th IEEE International parallel
    & distributed processing symposium, IEEE, Rhodes Island, Greece (2006), pp. 1-8,
    10.1109/IPDPS.2006.1639412 Google Scholar López-Riquelme et al., 2017 J.A. López-Riquelme,
    N. Pavón-Pulido, H. Navarro-Hellín, F. Soto-Valles, R. Torres-Sánchez A software
    architecture based on FIWARE cloud for Precision Agriculture Agricultural Water
    Management, 183 (2017), pp. 123-135, 10.1016/j.agwat.2016.10.020 View PDFView
    articleView in ScopusGoogle Scholar Lyle et al., 2014 G. Lyle, B.A. Bryan, B.
    Ostendorf Post-processing methods to eliminate erroneous grain yield measurements:
    Review and directions for future development Precision Agriculture, 15 (4) (2014),
    pp. 377-402, 10.1007/s11119-013-9336-3 View in ScopusGoogle Scholar Mafuta et
    al., 2012 M. Mafuta, M. Zennaro, A. Bagula, G. Ault, H. Gombachika, T. Chadza
    Successful deployment of a wireless sensor network for precision agriculture in
    Malawi 3rd International conference on networked embedded systems for every application
    (NESEA), IEEE (2012), pp. 1-7 CrossRefGoogle Scholar Manap and Najib, 2014 H.
    Manap, M.S. Najib A DOAS system for monitoring of ammonia emission in the agricultural
    sector Sensors and Actuators B: Chemical, 205 (2014), pp. 411-415, 10.1016/j.snb.2014.08.080
    View PDFView articleView in ScopusGoogle Scholar Marín-González et al., 2013 O.
    Marín-González, B. Kuang, M.Z. Quraishi, M.A. Muñóz-García, A.M. Mouazen On-line
    measurement of soil properties without direct spectral response in near infrared
    spectral range Soil and Tillage Research, 132 (2013), pp. 21-29, 10.1016/j.still.2013.04.004
    View PDFView articleView in ScopusGoogle Scholar Marsch et al., 2016 P. Marsch,
    I.D. Silva, Ö. Bulakci, M. Tesanovic, S. Eddine, E. Ayoubi 5G radio access network
    architecture – design guidelines and key considerations IEEE Communications Magazine,
    54 (11) (2016), pp. 24-32, 10.1109/MCOM.2016.1600147CM View in ScopusGoogle Scholar
    Martínez et al., 2016 R. Martínez, J.Á. Pastor, B. Álvarez, A. Iborra A testbed
    to evaluate the fiware-based iot platform in the domain of precision agriculture
    Sensors (Switzerland), 16 (11) (2016), 10.3390/s16111979 Google Scholar Mäyrä
    et al., 2018 O. Mäyrä, M. Ruusunen, M. Jalli, L. Jauhiainen, K. Leiviskä Plant
    disease outbreak – prediction by advanced data analysis SNE Short Note, 28 (3)
    (2018), pp. 113-115, 10.11128/sne.28.sn.10431 Google Scholar Mazon-Olivo et al.,
    2018 B. Mazon-Olivo, D. Hernández-Rojas, J. Maza-Salinas, A. Pan Rules engine
    and complex event processor in the context of Internet of Things for precision
    agriculture Computers and Electronics in Agriculture, 154 (February) (2018), pp.
    347-360, 10.1016/j.compag.2018.09.013 View PDFView articleView in ScopusGoogle
    Scholar McBratney et al., 2003 A. McBratney, M. Mendonça Santos, B. Minasny On
    digital soil mapping Geoderma, 117 (1–2) (2003), pp. 3-52 Retrieved from http://linkinghub.elsevier.com/retrieve/pii/S0016706103002234
    View PDFView articleView in ScopusGoogle Scholar Meola, 2016 A. Meola Why IoT,
    big data & smart farming are the future of agriculture. Business Insider - Dec
    20, 2016 (2016) Retrieved from https://www.businessinsider.com/internet-of-things-smart-agriculture-2016-10?r=US&IR=T
    Google Scholar Midtiby et al., 2018 H.S. Midtiby, K.A. Steen, O. Green In row
    cultivation controlled by plant patterns Computers and Electronics in Agriculture,
    153 (July) (2018), pp. 62-68, 10.1016/j.compag.2018.07.037 View PDFView articleView
    in ScopusGoogle Scholar Miettinen et al., 2006 M. Miettinen, T. Oksanen, P. Suomi,
    A. Visala Fault diagnosis in agricultural machines ASABE International conference
    on automation technology for off-road equipment, ASABE, Bonn, Germany (2006),
    pp. 1-10 Retrieved from https://www.computoolable.com/AgF4.pdf Google Scholar
    Moon et al., 2018 A. Moon, J. Kim, J. Zhang, S. Woo Evaluating fi delity of lossy
    compression on spatiotemporal data from an IoT enabled smart farm Computers and
    Electronics in Agriculture, 154 (March) (2018), pp. 304-313, 10.1016/j.compag.2018.08.045
    View PDFView articleView in ScopusGoogle Scholar Mukherjee et al., 2018 A. Mukherjee,
    S. Misra, N.S. Raghuwanshi, S. Mitra Blind entity identification for agricultural
    IoT deployments Internet of Things Journal, 1–8 (2018), 10.1109/JIOT.2018.2879454
    Google Scholar Na and Isaac, 2016 A. Na, W. Isaac Developing a human-centric agricultural
    model in the IoT environment 2016 International Conference on Internet of Things
    and applications, IOTA 2016 (2016), pp. 292-297, 10.1109/IOTA.2016.7562740 View
    in ScopusGoogle Scholar Näsi et al., 2018 R. Näsi, N. Viljanen, J. Kaivosoja,
    K. Alhonoja, T. Hakala, L. Markelin, et al. Estimating biomass and nitrogen amount
    of barley and grass using UAV and aircraft based spectral and photogrammetric
    features Remote Sensing, 10 (7) (2018), p. 1082, 10.3390/rs10071082 1–32 View
    in ScopusGoogle Scholar Nielsen et al., 2017 S.K. Nielsen, L.J. Munkholm, M. Lamandé,
    M. Nørremark, N. Skou-Nielsen, G.T.C. Edwards, et al. Seed drill instrumentation
    for spatial coulter depth measurements Computers and Electronics in Agriculture,
    141 (2017), pp. 207-214 Google Scholar Okayasu et al., 2017 T. Okayasu, A.P. Hugroho,
    A. Sakai, D. Arita, T. Yoshinaga, R. Taniguchi, et al. Affordable field environmental
    monitoring and plant growth measurement system for smart agriculture Eleventh
    International conference on sensing technology (ICST) (2017), pp. 7-10 Google
    Scholar Oksanen et al., 2016 T. Oksanen, R. Linkolehto, I. Seilonen Adapting an
    industrial automation protocol to remote monitoring of mobile agricultural machinery:
    A combine harvester with IoT IFAC-PapersOnLine 49–16, Elsevier (2016), pp. 127-131
    View PDFView articleView in ScopusGoogle Scholar Oksanen et al., 2015 T. Oksanen,
    P. Piirainen, I. Seilonen Remote access of ISO 11783 process data by using OPC
    Unified Architecture technology Computers and Electronics in Agriculture, 117
    (2015), pp. 141-148, 10.1016/j.compag.2015.08.002 View PDFView articleView in
    ScopusGoogle Scholar O''Grady and O''Hare, 2017 M.J. O''Grady, G.M.P. O''Hare
    Modelling the smart farm Information Processing in Agriculture, 4 (3) (2017),
    pp. 179-187, 10.1016/j.inpa.2017.05.001 View PDFView articleView in ScopusGoogle
    Scholar Paraforos et al., 2016 D.S. Paraforos, V. Vassiliadis, D. Kortenbruck,
    K. Stamkopoulos, V. Ziogas, A.A. Sapounas, et al. A farm management information
    system using future internet Technologies IFAC-PapersOnLine, 49 (16) (2016), pp.
    324-329, 10.1016/j.ifacol.2016.10.060 View PDFView articleView in ScopusGoogle
    Scholar Peets et al., 2009 S. Peets, C.P. Gasparin, D.W.K. Blackburn, R.J. Godwin
    RFID tags for identifying and verifying agrochemicals in food traceability systems
    Precision Agriculture, 10 (5) (2009), pp. 382-394, 10.1007/s11119-009-9106-4 View
    in ScopusGoogle Scholar Peets et al., 2012 S. Peets, A.M. Mouazen, K. Blackburn,
    B. Kuang, J. Wiebensohn Methods and procedures for automatic collection and management
    of data acquired from on-the-go sensors with application to on-the-go soil sensors
    Computers and Electronics in Agriculture, 81 (2012), pp. 104-112, 10.1016/j.compag.2011.11.011
    View PDFView articleView in ScopusGoogle Scholar Pérez-Freire and Brillouet, 2015
    L. Pérez-Freire, L. Brillouet Smart farming and food safety Internet of Things
    applications - challenges for large scale implementations. AIOTI WG06 (2015) Retrieved
    from https://aioti.eu/wp-content/uploads/2017/03/AIOTIWG06Report2015-Farming-and-Food-Safety.pdf
    Google Scholar Pesonen et al., 2014 L.A. Pesonen, F.K. Teye, A.K. Ronkainen, M.O.
    Koistinen, J.J. Kaivosoja, P.F. Suomi, et al. Cropinfra - an Internet-based service
    infrastructure to support crop production in future farms Biosystems Engineering,
    120 (2014), pp. 92-101, 10.1016/j.biosystemseng.2013.09.005 View PDFView articleView
    in ScopusGoogle Scholar Pfeiffer and Blank, 2015 D. Pfeiffer, S. Blank Real-time
    operator performance analysis in agricultural equipment. Understanding unused
    potential and ways to improve from day to day 73rd International conference on
    agricultural engineering, LANDTECHNIK AgEng 2015 proceedings - innovations in
    agricultural engineering for efficient farming. Hannover, Germany (2015) Retrieved
    from https://www.researchgate.net/profile/Sebastian_Blank2/publication/283643214_Real-time_Operator_Performance_Analysis_in_Agricultural_Equipment/links/564c7d8e08aeab8ed5e9dcf4/Real-time-Operator-Performance-Analysis-in-Agricultural-Equipment.pdf
    Google Scholar Pham and Stack, 2018 X. Pham, M. Stack How data analytics is transforming
    agriculture Business Horizons, 61 (1) (2018), pp. 125-133, 10.1016/j.bushor.2017.09.011
    View PDFView articleView in ScopusGoogle Scholar Popović et al., 2017 T. Popović,
    N. Latinović, A. Pešić, Ž. Zečević, B. Krstajić, S. Djukanović Architecting an
    IoT-enabled platform for precision agriculture and ecological monitoring: A case
    study Computers and Electronics in Agriculture, 140 (2017), pp. 255-265, 10.1016/j.compag.2017.06.008
    View PDFView articleView in ScopusGoogle Scholar Ramundo et al., 2016 L. Ramundo,
    M. Taisch, S. Terzi State of the art of technology in the food sector value chain
    towards the IoT 2016 IEEE 2nd International forum on research and technologies
    for society and Industry leveraging a better tomorrow (RTSI), 1–6 (2016), 10.1109/RTSI.2016.7740612
    Google Scholar Ray, 2017 P.P. Ray Internet of Things for smart agriculture: Technologies,
    practices and future direction Journal of Ambient Intelligence and Smart Environments,
    9 (4) (2017), pp. 395-420, 10.3233/AIS-170440 View in ScopusGoogle Scholar Renard
    et al., 1991 K.G. Renard, G.R. Foster, G.A. Weesies, J.P. Porter Rusle: Revised
    universal soil loss equation Journal of Soil & Water Conservation, 46 (1) (1991),
    pp. 30-33 View in ScopusGoogle Scholar Reshma and Pillai, 2018 S.R.J. Reshma,
    A.S. Pillai Proceedings of the eighth International conference on soft computing
    and pattern recognition (SoCPaR 2016), 614(SoCPaR 2016) (2018), 10.1007/978-3-319-60618-7
    Google Scholar Rodriguez et al., 2018 M.A. Rodriguez, L. Cuenca, A. Ortiz FIWARE
    open source standard platform in smart farming - a review L.M. Camarinha-Matos,
    H. Afsarmanesh, Y. Rezgui (Eds.), Collaborative networks of cognitive systems
    19th IFIP WG 5.5 working conference on Virtual enterprises, PRO-VE 2018, Vol.
    534, Springer International Publishing, Cardiff, UK (2018), pp. 581-589, 10.1007/978-3-319-99127-6
    View in ScopusGoogle Scholar Ruiz-Garcia and Lunadei, 2011 L. Ruiz-Garcia, L.
    Lunadei The role of RFID in agriculture: Applications, limitations and challenges
    Computers and Electronics in Agriculture, 79 (1) (2011), pp. 42-50, 10.1016/j.compag.2011.08.010
    View PDFView articleView in ScopusGoogle Scholar Sabarina and Priya, 2015 K. Sabarina,
    N. Priya Lowering data dimensionality in big data for the benefit of precision
    agriculture Procedia Computer Science, 48 (C) (2015), pp. 548-554, 10.1016/j.procs.2015.04.134
    View PDFView articleView in ScopusGoogle Scholar Say et al., 2017 S.M. Say, M.
    Keskin, M. Sehri, Y.E. Sekerli Adoption of precision agriculture Technologies
    in developed and developing countries adoption of precision agriculture technologies
    A. Isman, S. Dündar (Eds.), International science and technology conference (ISTEC)
    (2017), pp. 41-49 Berlin, Germany. Retrieved from https://www.researchgate.net/publication/320908156_Adoption_of_Precision_Agriculture_Technologies_in_Developed_and_Developing_Countries
    Google Scholar SEGES, 2016 SEGES Præcisionsjordbrug i Danmark. Barriererapport:
    Identificering af udfordringer og forhold, der hæmmer udvikling, produktion og
    anvendelse af præcisionsjordbrugsteknikker i planteavlen (2016) Retrieved from
    file:///C:/Users/AgroIntelli AVH/Downloads/Barriärrapportpraecisionsjordbrug-i-danmark.pdf
    Google Scholar Serrano et al., 2015 M. Serrano, P. Barnaghi, F. Carrez, P. Cousin,
    O. Vermesan, P. Friess Internet of Things IoT semantic interoperability: Research
    challenges, best practices, recommendations and next steps (2015) Retrieved from
    http://www.eglobalmark.com/wp-content/uploads/2016/06/2015-03-IoT-Semantic-Interoperability-Research-Challenges-Best-Practices-Recommendations-and-Next-Steps.pdf
    Google Scholar Severino et al., 2018 G. Severino, G. D''Urso, M. Scarfato, G.
    Toraldo The IoT as a tool to combine the scheduling of the irrigation with the
    geostatistics of the soils Future Generation Computer Systems, 82 (2018), pp.
    268-273, 10.1016/j.future.2017.12.058 View PDFView articleView in ScopusGoogle
    Scholar Seyyedhasani and Dvorak, 2018 H. Seyyedhasani, J.S. Dvorak Dynamic rerouting
    of a fleet of vehicles in agricultural operations through a dynamic multiple depot
    vehicle routing problem representation Biosystems Engineering, 171 (2018), pp.
    63-77, 10.1016/j.biosystemseng.2018.04.003 View PDFView articleView in ScopusGoogle
    Scholar Seyyedhasani et al., 2019 H. Seyyedhasani, J.S. Dvorak, E. Roemmele Routing
    algorithm selection for field coverage planning based on field shape and fleet
    size Computers and Electronics in Agriculture, 156 (December 2018) (2019), pp.
    523-529, 10.1016/j.compag.2018.12.002 View PDFView articleView in ScopusGoogle
    Scholar Sinha et al., 2017 R.S. Sinha, Y. Wei, S.H. Hwang A survey on LPWA technology:
    LoRa and NB-IoT ICT Express, 3 (1) (2017), pp. 14-21, 10.1016/j.icte.2017.03.004
    View PDFView articleView in ScopusGoogle Scholar Sjolander et al., 2011 A.J. Sjolander,
    J.A. Thomasson, R. Sui, Y. Ge Wireless tracking of cotton modules. Part 2: Automatic
    machine identification and system testing Computers and Electronics in Agriculture,
    75 (1) (2011), pp. 34-43, 10.1016/j.compag.2010.09.015 View PDFView articleView
    in ScopusGoogle Scholar Skou-Nielsen et al., 2017 N. Skou-Nielsen, A. Villa-Henriksen,
    O. Green, G.T.C. Edwards Creating a statistically representative set of Danish
    agricultural field shapes to robustly test route planning algorithms Precision
    agriculture (ECPA) 2017, 8:2 (2017), pp. 615-619, 10.1017/S2040470017000188 Edinburgh
    View PDFView articleGoogle Scholar Sørensen and Bochtis, 2010 C.G. Sørensen, D.D.
    Bochtis Conceptual model of fleet management in agriculture Biosystems Engineering,
    105 (1) (2010), pp. 41-50 View PDFView articleView in ScopusGoogle Scholar Sørensen
    et al., 2010 C.G. Sørensen, S. Fountas, E. Nash, L. Pesonen, D. Bochtis, S.M.
    Pedersen, et al. Conceptual model of a future farm management information system
    Computers and Electronics in Agriculture, 72 (1) (2010), pp. 37-47, 10.1016/j.compag.2010.02.003
    View PDFView articleView in ScopusGoogle Scholar Sørensen et al., 2011 C.G. Sørensen,
    L. Pesonen, D.D. Bochtis, S.G. Vougioukas, P. Suomi Functional requirements for
    a future farm management information system Computers and Electronics in Agriculture,
    76 (2011), pp. 266-276, 10.1016/j.compag.2011.02.005 View PDFView articleView
    in ScopusGoogle Scholar Steen et al., 2012 K.A. Steen, A. Villa-Henriksen, O.R.
    Therkildsen, O. Green Automatic detection of animals in mowing operations using
    Thermal cameras Sensors, 12 (6) (2012), pp. 7587-7597, 10.3390/s120607587 View
    in ScopusGoogle Scholar Stewart et al., 2017 J. Stewart, R. Stewart, S. Kennedy
    Internet of Things - propagation modelling for precision agriculture applications
    Wireless telecommunications symposium (2017), 10.1109/WTS.2017.7943528 Google
    Scholar Stočes et al., 2016 M. Stočes, J. Vaněk, J. Masner, J. Pavlík Internet
    of Things (IoT) in agriculture -selected aspects AGRIS On-Line Papers in Economics
    and Informatics, 1 (1) (2016), pp. 83-88, 10.7160/aol.2016.080108 View in ScopusGoogle
    Scholar Suhonen et al., 2012 J. Suhonen, M. Kohvakka, V. Kaseva, T.D. Hämäläinen,
    M. Hännikäinen Communication protocols Low-power wireless sensor networks protocols,
    services and applications (1st ed.), Springer-Verlag, New York (2012), pp. 27-41,
    10.1007/978-1-4614-2173-3 Google Scholar Sundmaeker et al., 2016 H. Sundmaeker,
    C. Verdouw, S. Wolfert, L. Pérez Freire Internet of food and farm 2020 O. Vermesan,
    P. Friess (Eds.), Digitising the industry Internet of Things connecting the physical,
    digital and virtual worlds, Vol. 49, River Publishers, Gistrup, Denmark (2016),
    pp. 1689-1699, 10.1017/CBO9781107415324.004 Google Scholar Talavera et al., 2017
    J.M. Talavera, L.E. Tobón, J.A. Gómez, M.A. Culman, J.M. Aranda, D.T. Parra, et
    al. Review of IoT applications in agro-industrial and environmental fields Computers
    and Electronics in Agriculture, 142 (118) (2017), pp. 283-297, 10.1016/j.compag.2017.09.015
    View PDFView articleView in ScopusGoogle Scholar Tanaka, 2018 K. Tanaka Low delay
    data gathering method for rice cultivation management system IoT specialized outdoor
    communication procedure 2018 International conference on Information and computer
    technologies (ICICT), IEEE (2018), pp. 139-143, 10.1109/INFOCT.2018.8356857 View
    in ScopusGoogle Scholar Tan and Panda, 2010 Y.K. Tan, S.K. Panda Review of energy
    harvesting Technologies for sustainable wireless sensor network Y.K. Tan, W. Seah
    (Eds.), Sustainable wireless sensor networks, InTech, Rijeka, Croatia (2010),
    pp. 15-43, 10.5772/663 View in ScopusGoogle Scholar Temprilho et al., 2018 A.
    Temprilho, L. Nóbrega, P. Pedreiras, P. Gonçalves, S. Silva M2M communication
    stack for intelligent farming Global Internet of Things summit (GIoTS) (2018),
    10.1109/GIOTS.2018.8534560 Google Scholar Tilman et al., 2011 D. Tilman, C. Balzer,
    J. Hill, B.L. Befort Global food demand and the sustainable intensification of
    agriculture Proceedings of the national academy of sciences of the United States
    of America, Vol. 108 (2011), pp. 20260-20264, 10.1073/pnas.1116437108 View in
    ScopusGoogle Scholar Tuna and Gungor, 2016 G. Tuna, V.C. Gungor Energy harvesting
    and battery technologies for powering wireless sensor networks Industrial Wireless
    Sensor Networks, Elsevier Ltd (2016), 10.1016/B978-1-78242-230-3.00002-7 Google
    Scholar Tuna et al., 2017 G. Tuna, D.G. Kogias, V.C. Gungor, C. Gezer, E. Taşkın,
    E. Ayday A survey on information security threats and solutions for Machine to
    Machine (M2M) communications Journal of Parallel and Distributed Computing, 109
    (2017), pp. 142-154, 10.1016/j.jpdc.2017.05.021 View PDFView articleView in ScopusGoogle
    Scholar Tzounis et al., 2017 A. Tzounis, N. Katsoulas, T. Bartzanas, C. Kittas
    Internet of Things in agriculture, recent advances and future challenges Biosystems
    Engineering, 164 (2017), pp. 31-48, 10.1016/j.biosystemseng.2017.09.007 View PDFView
    articleView in ScopusGoogle Scholar Uddin et al., 2018 M.A. Uddin, A. Mansour,
    D. Le Jeune, M. Ayaz, el-H.M. Aggoune UAV-assisted dynamic clustering of wireless
    sensor networks for crop health monitoring Sensors, 18 (2) (2018), p. 555, 10.3390/s18020555
    View in ScopusGoogle Scholar Veer and Wiles, 2008 H. van der Veer, A. Wiles Achieving
    Technical interoperability - the ETSI approach ETSI white paper (2008) Retrieved
    from https://www.etsi.org/images/files/ETSIWhitePapers/IOP whitepaper Edition
    3 final.pdf Google Scholar Vellidis et al., 2008 G. Vellidis, M. Tucker, C. Perry,
    C. Kvien, C. Bednarz A real-time wireless smart sensor array for scheduling irrigation
    Computers and Electronics in Agriculture, 61 (1) (2008), pp. 44-50, 10.1016/j.compag.2007.05.009
    View PDFView articleView in ScopusGoogle Scholar Verdouw, 2016 C. Verdouw Internet
    of Things in agriculture CAB reviews: Perspectives in agriculture, veterinary
    science, Nutrition and Natural Resources, 11 (35) (2016), 10.1079/PAVSNNR201611035
    Google Scholar Verdouw et al., 2017 C. Verdouw, S. Wolfert, G. Beers, H. Sundmaeker,
    G. Chatzikostas IOF2020 : Fostering business and software ecosystems for large-scale
    uptake of IoT in food and farming The International tri-conference for precision
    agriculture in 2017 (2017), 10.5281/zenodo.1002903 Google Scholar Viljanen et
    al., 2018 N. Viljanen, E. Honkavaara, R. Näsi, T. Hakala, O. Niemeläinen, Kai
    A novel machine learning method for estimating biomass of grass swards using a
    photogrammetric canopy height model , images and vegetation indices captured by
    a drone Agriculture, 8 (5) (2018), p. 70, 10.3390/agriculture8050070 1–28 View
    in ScopusGoogle Scholar Villa-Henriksen et al., 2018 A. Villa-Henriksen, N. Skou-Nielsen,
    C.A.G. Sørensen, O. Green, G.T.C. Edwards, et al. Internet-based harvest fleet
    logistic optimisation P.W.G. Groot Koerkamp (Ed.), Proceedings of the European
    Agricultural Conference, 8-12 July, Wageningen, the Netherlands, Wageningen University
    and Research, Wageningen (2018), pp. 56-61, 10.18174/471679 Accessed 14 Jan 2020
    Google Scholar Vuran et al., 2018 M.C. Vuran, A. Salam, R. Wong, S. Irmak Internet
    of underground things in precision agriculture : Architecture and technology aspects
    Ad Hoc Networks, 81 (2018), pp. 160-173, 10.1016/j.adhoc.2018.07.017 View PDFView
    articleView in ScopusGoogle Scholar Wang et al., 2014 H.Z. Wang, G.W. Lin, J.Q.
    Wang, W.L. Gao, Y.F. Chen, Q.L. Duan Management of big data in the internet of
    Things in agriculture based on cloud computing Applied Mechanics and Materials,
    548–549 (2014), pp. 1438-1444, 10.4028/www.scientific.net/AMM.548-549.1438 View
    in ScopusGoogle Scholar Wolanin et al., 2019 A. Wolanin, G. Camps-valls, L. Gómez-chova,
    G. Mateo-garcía, C. Van Der Tol, Y. Zhang, et al. Remote Sensing of Environment
    Estimating crop primary productivity with Sentinel-2 and Landsat 8 using machine
    learning methods trained with radiative transfer simulations Remote Sensing of
    Environment, 225 (March) (2019), pp. 441-457, 10.1016/j.rse.2019.03.002 View PDFView
    articleView in ScopusGoogle Scholar Wolfert et al., 2017 S. Wolfert, L. Ge, C.
    Verdouw, M.J. Bogaardt Big data in smart farming – a review Agricultural Systems,
    153 (2017), pp. 69-80, 10.1016/j.agsy.2017.01.023 View PDFView articleView in
    ScopusGoogle Scholar World Bank, 2017 World Bank ICT in agriculture: Connecting
    smallholders to knowledge, networks, and institutions (updated ed) The World Bank
    Group, Washington DC (2017), 10.1596/978-1-4648-1002-2 Google Scholar Xian, 2017
    K. Xian Internet of Things online monitoring system based on cloud computing International
    Journal of Online and Biomedical Engineering, 13 (9) (2017), pp. 123-131, 10.3991/ijoe.v13i09.7591
    View in ScopusGoogle Scholar Yan et al., 2018 M. Yan, P. Liu, R. Zhao, L. Liu,
    W. Chen, X. Yu, et al. Field microclimate monitoring system based on wireless
    sensor network Journal of Intelligent and Fuzzy Systems, 35 (2) (2018), pp. 1325-1337,
    10.3233/JIFS-169676 View in ScopusGoogle Scholar Zhai, 2017 A.F. Zhai Optimization
    of agricultural production control based on data processing Technology of agricultural
    Internet of Things Italian Journal of Pure and Applied Mathematics, 38 (2017),
    pp. 243-252 View in ScopusGoogle Scholar Zhang et al., 2017 A. Zhang, I. Baker,
    E. Jakku, R. Llewellyn Accelerating precision agriculture to decision agriculture
    : The needs and drivers for the present and future of digital agriculture in Australia
    A cross-industry producer survey for the Rural R&D for Profit ‘Precision to Decision’
    (P2D) project, EP175936 (2017) Google Scholar Zhao, Lin et al., 2018 W. Zhao,
    S. Lin, J. Han, R. Xu, L. Hou Design and implementation of smart irrigation system
    based on LoRa 2017 IEEE globecom workshops (GC wkshps), IEEE, Singapore, Singapore
    (2018), pp. 1-6, 10.1109/GLOCOMW.2017.8269115 Google Scholar Zhao, Lucani et al.,
    2018 X. Zhao, D.E. Lucani, X. Shen, H. Wang Reliable IoT Storage : Minimizing
    bandwidth use in storage without newcomer nodes IEEE Communications Letters, 22
    (7) (2018), pp. 1462-1465, 10.1109/LCOMM.2018.2831669 View in ScopusGoogle Scholar
    Zhou et al., 2014 K. Zhou, A. Leck Jensen, C.G. Sørensen, P. Busato, D.D. Bothtis
    Agricultural operations planning in fields with multiple obstacle areas Computers
    and Electronics in Agriculture, 109 (2014), pp. 12-22, 10.1016/j.compag.2014.08.013
    View PDFView articleView in ScopusGoogle Scholar Zou and Quan, 2017 Y. Zou, L.
    Quan A new service-oriented grid-based method for AIoT application and implementation
    Modern Physics Letters B, 31 (19–21) (2017), p. 1740064, 10.1142/S0217984917400644
    View in ScopusGoogle Scholar Zude-Sasse et al., 2016 M. Zude-Sasse, S. Fountas,
    T.A. Gemtos, N. Abu-Khalaf Applications of precision agriculture in horticultural
    crops European Journal of Horticultural Science, 81 (2) (2016), pp. 78-90, 10.17660/eJHS.2016/81.2.2
    View in ScopusGoogle Scholar Cited by (220) Design of an IoT ultrasonic-vision
    based system for automatic fruit sorting utilizing size and color 2024, Internet
    of Things (Netherlands) Show abstract Antecedents of smart farming adoption to
    mitigate the digital divide – extended innovation diffusion model 2023, Technology
    in Society Show abstract Advancements in smart farming: A comprehensive review
    of IoT, wireless communication, sensors, and hardware for agricultural automation
    2023, Sensors and Actuators A: Physical Show abstract Review of artificial intelligence
    and internet of things technologies in land and water management research during
    1991–2021: A bibliometric analysis 2023, Engineering Applications of Artificial
    Intelligence Show abstract Effects of laser scanner quality and tractor speed
    to characterise apple tree canopies 2023, Smart Agricultural Technology Show abstract
    A federated authentication and authorization approach for IoT farming 2023, Internet
    of Things (Netherlands) Show abstract View all citing articles on Scopus © 2020
    The Authors. Published by Elsevier Ltd on behalf of IAgrE. Recommended articles
    Route planning evaluation of a prototype optimised infield route planner for neutral
    material flow agricultural operations Biosystems Engineering, Volume 153, 2017,
    pp. 149-157 Gareth T.C. Edwards, …, Ole Green View PDF Architecting user-centric
    internet of things for smart agriculture Sustainable Computing: Informatics and
    Systems, Volume 23, 2019, pp. 88-102 Akash Sinha, …, Prabhat Kumar View PDF Effect
    of velocity ratio on performance characteristics of an active-passive combination
    tillage implement Biosystems Engineering, Volume 191, 2020, pp. 1-12 Ganesh Upadhyay,
    Hifjur Raheman View PDF Show 3 more articles Article Metrics Citations Policy
    Citations: 5 Citation Indexes: 205 Captures Readers: 835 Mentions News Mentions:
    22 Social Media Shares, Likes & Comments: 3 View details About ScienceDirect Remote
    access Shopping cart Advertise Contact and support Terms and conditions Privacy
    policy Cookies are used by this site. Cookie settings | Your Privacy Choices All
    content on this site: Copyright © 2024 Elsevier B.V., its licensors, and contributors.
    All rights are reserved, including those for text and data mining, AI training,
    and similar technologies. For all open access content, the Creative Commons licensing
    terms apply.'
  inline_citation: '>'
  journal: Biosystems Engineering
  limitations: '>'
  pdf_link: null
  publication_year: 2020
  relevance_score1: 0
  relevance_score2: 0
  title: 'Internet of Things in arable farming: Implementation, applications, challenges
    and potential'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.53941/ijndi0101002
  analysis: '>'
  authors:
  - Fang Yao
  - Yulong Ding
  - Shengguang Hong
  - Shuang–Hua Yang
  citation_count: 27
  full_citation: '>'
  full_text: ">\nSurvey/review study\nA Survey on Evolved LoRa-Based Communication\n\
    Technologies for Emerging Internet of\nThings Applications\nFang Yao 1,3, Yulong\
    \ Ding 2,3,*, Shengguang Hong 2,4, and Shuang-Hua Yang 2,5,*\n1 The Ta-tech Company, Nanjing 210009, China\n\
    2 Shenzhen Key Laboratory of Safety and Security for Next Generation of Industrial Internet, Department of Electron-\n\
    ics and Information Engineering, Shenzhen University, Shenzhen 518060, China\n\
    3 Department  of  Computer  Science  and  Engineering,  Southern  University  of\
    \  Science  and  Technology,  Shenzhen\n518055, China\n4 The School of Computer Science and Technology, Harbin Institute of Technology, Harbin 150006, China\n\
    5 Department of Computer Science, University of Reading, West Berkshire RG6 6UR, United Kingdom\n\
    * Correspondence: dingyl@sustech.edu.cn ; Shuang-hua.yang@reading.ac.uk\nReceived: 17 September 2022\n\
    Accepted: 17 October 2022\nPublished: 22 December 2022\nAbstract: The concept of Internet of Things (IoT) greatly extends the coverage area that human being is\n\
    able to perceive, access, and even control. By connecting various “Things” to the Internet, the IoT makes\n\
    it possible to measure and manage the physical world as needed. As one of the most widely adopted Low\n\
    Power Wide Area network technologies, the Long-Range-Radio (LoRa) has the features of long range,\n\
    low  power,  and  robustness,  and  thus  plays  an  important  role  in  building\
    \  IoT  applications  where  IoT\nobjects are connected to the internet at affordable costs. Since the development of LoRa, many IoT appli-\n\
    cations have adopted LoRa and achieved success in the market. Currently, IoT technologies keep evolv-\n\
    ing towards different fields, giving rise to multifarious IoT applications including industrial IoT, smart\n\
    city IoT, healthcare IoT, and direct-to-satellite IoT. In the meantime, LoRa also keeps developing and\n\
    finding its position in various IoT applications either as a main or complementary player. The objective\n\
    of this survey is to (1) provide a fundamental understanding of the LoRa technology; (2) explore research\n\
    activities studying LoRa based communication systems for new IoT applications; and (3) demonstrate\n\
    how the LoRa technology works together with other technologies to deliver better IoT services to end\n\
    users.\nKeywords: internet of things; long range radio; low power wide area network\n\
     \n1. Introduction\nThe Internet of Things (IoT) refers to a set of technologies cooperating to network the physical world [1], and\n\
    aims to interconnect everything and enable proper processing on the collected data in order to support high-level\n\
    decision making. Early in 1999, Kevin Aston [2] used the term “Internet of Things” to describe a system using radio\n\
    frequency identification (RFID) to keep tracking and monitoring on goods in supply chain management. In his idea,\n\
    an object is possible to be automatically recognized, recorded and analyzed if it can be identified by machines. As\n\
    defined  by  ITU  (International  Telecommunication  Union)  [3],  an  IoT  system\
    \  consists  of  three  components:  the\ndevice,  IoT  and  thing.  The  device\
    \  is  “ a  piece  of  equipment  with  mandatory  capabilities  of  communication\
    \  and\noptional capabilities of sensing, actuation, data capture, data storage and data processing”. The IoT refers to “a global\n\
    infrastructure for the information society, enabling advanced services by interconnecting (physical and virtual) things\n\
    based on existing and evolving interoperable information and communication technologies”. The thing refers to “an\n\
    object of the physical world (physical things) or the information world (virtual things), which is capable of being\n\
    identified and integrated into communication networks”. A simplified IoT application is shown in Figure 1.\n\
    International Journal of Network Dynamics and Intelligence\n \nhttps://www.sciltp.com/journals/ijndi\n\
    A volcano (i.e. the Thing) cannot talk to human being until its characteristics is “translated” into a digital for-\n\
    mat by “Device”, e.g. a temperature sensor. Since it is not convenient to have personnel watch the sensor all day\n\
    long, it is necessary to have a way to transfer data to a remote site. Deploying a temperature sensor (i.e. devices with\n\
    optional capabilities) with a communication module (i.e. device with mandatory capabilities) which has connections\n\
    to the Internet is considered as a proper solution, namely IoT. The challenges of building an IoT system come from\n\
    the establishment of links between the network and the far-away physical devices, e.g. a refrigerator, an air condi-\n\
    tioner and a temperature/humidity sensor. Such devices usually work individually, generate a small volume of data,\n\
    and sometimes ask for low power consumption. For example, an electricity meter is installed in a metal cabinet in the\n\
    cellar of a house, and is able to report energy readings every 15 minutes. Each reporting consists of a four-byte meter\n\
    reading and a 13 bytes overhead [4]. Typically, a community has hundreds of meters in operation. Since meters are\n\
    installed in the cellar of house, deploying cables for meters to be connected to network may have difficulty and there-\n\
    fore, applying wireless communication seems to be a promising solution [4−6]. However, wireless communication is\n\
    prone to failures due to various factors, including building materials, interior structures of houses/buildings and other\n\
    radio systems coexisting in the same area [7]. To obtain better link budget, the narrow band (NB) wireless technol-\n\
    ogy is a preferable choice that outperforms the wide-band wireless technology in the processing gains and radio sen-\n\
    sitivity, and is usually summarized as the low power wide area network (LPWAN) technology [8].\n\
    As concluded in [9], typical LPWAN technologies include long range radio wide area network (LoRaWAN),\n\
    NB-IoT, SigFox, and Wi-Sun that are designed for connecting large number of low-cost, low power consumption\n\
    and low throughput end devices with large coverage areas. Generally, LoRaWAN and SigFox can achieve a conver-\n\
    gence area larger than 10 kilometers’ communication range [10]. NB-IoT makes use of the widely deployed base\n\
    stations to achieve city level coverage. Wi-Sun is an enterprise–grade mesh network technology [11]. Each of\n\
    the aforementioned technologies has its own characteristic for certain scenarios. For instance, LoRaWAN is suitable\n\
    for applications requiring low data rate, low power consumption, and feasible deployment regarding private or public\n\
    network access. SigFox is appropriate for applications asking for ultra-low data rate and power consumption. NB-IoT\n\
    is a low power consumption technology but requires public network access. Wi-Sun is good for smart city applica-\n\
    tions but needs complex network operation management.\nThis survey aims to (1) introduce the concept of LoRa techniques and provide a fundamental understanding of\n\
    LoRa communication; (2) explore research activities studying LoRa based IoT applications; and (3) demonstrate how\n\
    LoRa techniques working together with other technologies to deliver better services to end users in emerging IoT\n\
    application areas. Particularly, the research activities carried out to resolve LoRa communication issues for specific\n\
    IoT areas are studied, such as communication protocol, performance optimization, and application deployment. There\n\
    are lots of LoRa related survey papers made by researchers that summarize and discuss LoRa technologies. In [12]\n\
    authors made comparisons between LoRa and NB-IoT at issues of physical layer design, battery consumption, net-\n\
    work coverage, deployment model and cost. In [13,14], the authors provided a comprehensive survey for LoRa tech-\n\
    nique, including performance of modulation technology, Medium Access Control protocol design, LoRa security and\n\
    list of LoRa applications. Moreover, in [15], the LoRa technique was analyzed from down to top to show current\n\
    research effort on improving performance metrics related to LoRa. Compared with previous surveys, our contribu-\n\
    tion  is  to  summarize  the  use  of  LoRa  along  with  requirements  in  different\
    \  IoT  application  fields.  Continuously\nemerging IoT applications/fields are the major motivation in driving the evolvement of LoRa techniques, giving rise\n\
    to not only new enhancement and optimization at certain technical points, but also new paradigm of LoRa applica-\n\
    tion along with other technologies. As such, it is of great importance to review the LoRa research by taking it as an\n\
    important constituent part of the IoT applications.\nThe rest of this survey is organized as follows: Section 2 discusses characteristics of different IoT fields and\n\
    their requirements to LoRa technique. Section 3 introduces basic concept of LoRa radio communication and research\n\
    studies on LoRa modulation schemes and performance optimization. In Sections 4, 5, 6 and 7, the adoption of LoRa\n\
     \nThing\nDevice\nIoT\nService/Users\nFigure 1.  Example of an IoT application.\n\
    IJNDI, 2022, 1(1): 4−19. https://doi.org/10.53941/ijndi0101002\n \n5\ntechnique in different IoT areas, including industrial IoT, smart city IoT, direct-to-space IoT and healthcare IoT, is\n\
    reviewed and discussed. Conclusion about the development trend of LoRa in the concept of IoT is made in Section 8.\n\
    2. Iot and LoRa\nExactly speaking, the IoT is not an individual technology but a comprehensive concept covering tremendous\n\
    technologies and evolving with the development of information and communication technologies. The IoT is in fact\n\
    an evolution of mobile, embedded applications and everything that is connected to the internet [16], which generates\n\
    urgent needs for a new paradigm of data collection and processing. Furthermore, the IoT is an expansion of conven-\n\
    tional network technologies in a sense whose core concept is to build interconnections among “Things” and further\n\
    have the physical world networked.\nNowadays, more and more IoT related applications emerge as either new market spaces develop or existing\n\
    technologies upgrade, which pushes an evolution of IoT technologies in different fields. One feature of IoT applica-\n\
    tions is the diversity of communication requirements which is also the main difference between conventional com-\n\
    munications and IoT communications. In conventional applications, the Internet connected devices, such as comput-\n\
    ers, tablets, and mobile phones, are mainly controlled by humans with stable network connections, whereas in IoT\n\
    applications, the scope of devices connecting to the Internet are extended to every kind of devices, including sensors,\n\
    actuators and tags [17]. Development of the IoT contains not only conventional systems, but also comprehensive\n\
    interactions introduced by “Smart Objects” (e.g. sophisticated smart gadgets, smartphones, and smart vehicles) which\n\
    exhibit different degrees of intelligence in data processing and communication with conventional systems [18].\n\
    To be specific, the Video-on-Demand service is a typical application using conventional communication tech-\n\
    nologies. Video programs are pre-stored on servers, and TV terminals can request certain program from a server\n\
    nearby. The communication content is almost fixed and the traffic over communication links is predictable. Note that\n\
    the  entire  system  works  in  a  closed-loop  manner  as  insertion  of  new\
    \  programs,  increment  of  subscriptions,  and\ncapacity of networks are always under control. Using distributed sensors to help manage smart agriculture is a popu-\n\
    lar application of IoT. Various sensors connect to local edge servers to provide real-time sensory data critical to the\n\
    crops. The edge server makes decisions, e.g. irrigation or sowing, based on the received data. The source of data\n\
    comes from real-world, which means the major challenges imposed on IoT communications come from aspects of\n\
    data volume, variety, veracity and velocity [19].\nMany IoT applications require long range, low data rate, low energy consumption and cost effective wireless\n\
    communication [20]. As one of LPWAN technologies, the LoRa has the most technical advantages required by IoT\n\
    applications. Particularly,  the  open  design  (except  for  physical  layers)\
    \  feature  of  the  LoRa  provides  great   conve-\nnience for researchers and developers to study and use. In general, IoT applications requiring the involvement of\n\
    LoRa technique possess two common characteristics: wireless communication in difficult radio environment and low\n\
    data rate [21−23]. Difficult environment refers to interferences and long range communications that many IoT appli-\n\
    cations have to face when deploying networks. Low data rate means only IoT applications requiring small data can\n\
    adopt LoRa. In the following sections, the LoRa radio and representative IoT fields in which LoRa is a main or sup-\n\
    plementary player in building wireless communication links are selected and discussed to explore research activities\n\
    made for the use of LoRa. The typical IoT fields include industrial IoT, smart city IoT, healthcare IoT, agriculture\n\
    IoT, and DtS-IoT [17,24].\n3. LoRa Radio Communication\nLoRa is a narrowband communication technology patented by Semtech [25], and is a kind of physical layer\n\
    modulation  technologies  that  utilize  Chirp  (Compressed  High  Intensity  Radar\
    \  Pulse)  Spread  Spectrum  (CSS)  to\nachieve significant long communication range and robustness to interference on the premise of low power consump-\n\
    tion [26, 27], and this is also the key to make LoRa stay competitive compared with other LPWAN technologies. A\n\
    comparison between LoRa and other mainstream IoT wireless communication technologies is listed in [28−31].\n\
    The IoT wireless communication technologies listed in Table 1 can help end devices build links to networks.\n\
    However, such technologies can only be applicable to certain application fields due to their technology differences.\n\
    NB-IoT and SigFox can achieve long range communication, and are unsuitable for applications requiring use of local\n\
    area networks. This is because NB-IoT and SigFox establish direct links between end devices and operators’ net-\n\
    works (i.e. public networks). Wi-Fi and Bluetooth can provide relative high data rate and are suitable for multimedia\n\
    applications. As a trade-off, Wi-Fi and Bluetooth consume more energy compared with other technologies. ZigBee is\n\
    a low cost and low power consumption technology for short-range IoT applications, and thus has limited coverage. In\n\
    contrast,  LoRa  can  provide  dynamic  radio  coverage  for  large-scale  IoT\
    \  applications  which  require  long  lifetime,\nwhereas the main shortage of LoRa comes from its low data rate.\n\
     \nIJNDI, 2022, 1(1): 4−19. https://doi.org/10.53941/ijndi0101002\n \n6\nTable\
    \ 1    Comparison of wireless IoT communication technologies\nLoRa\nSigFox\nZigBee\n\
    Bluetooth\nWi-Fi\nNB-IoT\nTechnology\nProprietary PHY, Open MAC Proprietary\n\
    IEEE802.15.4 IEEE802.15.1\nIEEE802.11\n3GPP\nSpectrum\nUnlicensed band\nLicensed band\n\
    Frequency\nSub-GHz, 2.4 GHz\n862−928 MHz 2.4 GHz\n2.4 GHz\n2.4 GHz\n700−2100 MHz\n\
    Modulation\nCSS\nD-BPSK,GFSK DSS\nFHSS\nQPSK,BPSK,QAM BPSK QPSK\nRate\n0.018−37.5 kbps1\n\
    31.72−253.91 kbps2\n100 or 600 bps 250 kbps\n~2 Mbps\n11 Mbps\n54 Mbps\nor more\n\
    ~250 kbps\nBandwidth\n7.8−500 kHz,\n200−1600 kHz\n100 Hz, 600 Hz 2 MHz\n1 MHz\n\
    20 MHz, 40 MHz\n180 kHz\nCoverage\n1−10 km\n10−40 km\n~100 m\n~10 m\n~100 m\n\
    15 km\nDeployment\nStart, mesh\nOperator\nMesh\nMaster-slave, Mesh\nStar, Ad-hoc\n\
    Operator\nSecurity\nAES128\nAES128\nAES128\nSecure Simple Pairing,\nAES-CCM\n\
    TKIP, AES\nLTE security\nRx sensitivity3 −148 dBm\n−133 dBm\n−102 dBm\n−82 dBm\n\
    −90 dBm\n−114 dBm\nBattery life\n+10 years\n+10 years\n100−7000 days 1−7 days\n\
    0.1−5 days\n+10 years\n1    LoRa at Sub-1 GHz\n2    LoRa at 2.4 GHz\n3    Depend on configuration\n\
     \nApplication  scenarios  in  which  LoRa  outperforms  than  other  technologies\
    \  include  logistics  tracking,  assert\ntracking, smart agriculture, healthcare, etc. [32]. An important characteristic of these scenarios is uncertain communi-\n\
    cation range, which can be a few meters or up to a few kilometers. Excellent design of receiving sensitivity makes\n\
    LoRa capable of covering large area with limited power supply. On the contrary, it is clear that LoRa is not suitable\n\
    for high data rate applications whose major candidates are Wi-Fi or Bluetooth based technologies. Performance of\n\
    LoRa modem is configurable through a few parameters, which typically include: spreading factor (SF), bandwidth\n\
    (BW), and coding rate (CR) [33].\n● Spreading Factor (SF)\nSF represents the level that the spread spectrum algorithm works on each bit. The higher the SF is, the more\n\
    spreading code will be used for each bit. Consequently, the receiving sensitivity at the receiver side improves c. LoRa\n\
    supports SF ranges from 6 to 12.\n● Bandwidth (BW)\nBandwidth is directly related to the data rate. If a higher bandwidth is used, a higher data rate can be achieved at\n\
    the cost of reduced receiving sensitivity. In the contrary, a smaller bandwidth is helpful in obtaining better receiver\n\
    sensitivity, but data rate decreases accordingly. The BW option supported by LoRa ranges from 7.8 kHz to 500 kHz\n\
    (at Sub-1 GHz frequency band).\n● Error Correction Rate (ECR)\nCyclic error coding is employed as the forward error detection and correction scheme in the LoRa technology.\n\
    The higher the CR value is, the stronger capability of error correction can be achieved. However, additional overhead\n\
    is included in transmission which reduces effective user data rate. LoRa modem supports CR from 4/5 to 4/8. The\n\
    overhead ratio for different CR is shown in Table 2\n \n \nTable 2    Cyclic coding overhead\n\
    Coding Rate\nOverhead Ratio\nCyclic Coding Rate\n1\n1.25\n4/5\n2\n1.5\n4/6\n3\n\
    1.75\n4/7\n4\n2\n4/8\n \nLoRa  device  supports  various  data  rate  from  0.018\
    \  kbps  to  37.5  kbps.  Corresponding  receiving  sensitivity\nranges  from\
    \  −111  dBm  to  −148  dBm,  and  is  achieved  by  selecting  different  combinations\
    \  of  SF,  CR  and  BW.\nTable 3 listed below shows typical parameter settings and data rate achieved at 868 MHz.\n\
    IJNDI, 2022, 1(1): 4−19. https://doi.org/10.53941/ijndi0101002\n \n7\nAs stated in [34], LoRa can provide over 150 dB link budget for long range communication. When installed at\n\
    fixed position and configured with certain settings (14 dBm tx power, BW = 125 kHz, SF = 12), a LoRa gateway can\n\
    achieve 62% packet delivery rate at range of 15-30 km, 88% and 85% at range of 2 and 5 km. Regarding mobile sit-\n\
    uation, a reliable communication link can be established if relative speed is lower than 25 km/h. Significant packet\n\
    loss is observed when relative speed is close to or over 40 km/h. The test results show that LoRa modem is capable\n\
    of providing service in either stationary or mobile scenarios.\nIoT applications, such as environment monitoring, smart metering, plant monitoring, etc., require massive and\n\
    large deployment, but very few data payload which could be as small as one byte to indicate On or Off states. The\n\
    corresponding data report interval could be as slow as 1 packet/day or 1 packet/hour. The key point here is long range\n\
    communication and low power consumption. LoRa achieves this objective with the use of CSS. Since LoRa is a pro-\n\
    prietary technique, researchers mainly focus on performance study. Relevant proposals of physical layer optimiza-\n\
    tions are based on general principles of CSS. The important features of LoRa communication which receive wide\n\
    interests from industry sections are long range communication capability, robustness to interferences, and low power\n\
    consumption. Mroue et al. made an analytical study along with simulation work to explain and improve LoRa-based\n\
    BER (Bit Error Rate) expressions [35]. The proposed BER expression is more accurate compared with the conven-\n\
    tional error probability of CSS by introducing a few parameters such as symbol frequency, sampling frequency, sig-\n\
    nal-to-noise and implementation loss. In [36], mathematic expressions describing generation and demodulation of\n\
    LoRa signal were made. In addition, authors in [36] proposed a simplified filter design to reduce number of coeffi-\n\
    cients of digital filters in the baseband process at the receiver. Simulation results showed that the design can achieve\n\
    satisfactory performance of symbol error rate at a cost of slightly increment of SNR (Signal-to-Noise Ratio) loss.\n\
    As the LoRa technology may be used to collect sensory data in a dense network, its feature of the “orthogonal\n\
    spreading factor” is usually taken to provide simultaneous transmission capability, i.e. multiple communications are\n\
    allowed to happen simultaneously as long as they employ different spreading factors. However, such transmission\n\
    might be inaccurate since the achievement of “orthogonality” needs certain condition, i.e. the threshold of SIR (Signal-\n\
    to-Interference  Ratio).  In  [37],  authors  implemented  simulation  and  practical\
    \  experiments  to  determine  if  desired\nLoRa  communication  can  be  successfully\
    \  completed  at  the  presence  of  “ interfering  LoRa  signal”   with  different\n\
    spreading factors. The result showed that by average, a 16 dB co-channel rejection value should be satisfied to have\n\
    desired communication successfully completed. It is for the reason that the receiver takes the interfering LoRa signal\n\
    as a chirped waveform (a wide-band spectrum) and tries to look for a peak value to synchronize with the desired sig-\n\
    nal whose strength should be 16 dB higher than the interfering signal. This finding indicates that applying different\n\
    spreading factors may not be sufficient to build independent communication channels if interfering LoRa devices are\n\
    close to the receiver during communication.\nIn fact, LoRa is one de-factor standard of IoT technologies for long range communication where there might be\n\
    hundreds of meters or kilometers between a LoRa end device and a LoRa gateway. As a kind of NB wireless tech-\n\
    nologies, LoRa can achieve longer communication range than that of wideband wireless communication technolo-\n\
    gies, e.g. WiFi, and Bluetooth, with given transmission power (usually it is a mandatory requirement made by local\n\
    authority for radio usage at industrial scientific medical (ISM) band in different regions). However, there is a trade-off\n\
    between communication range and data rate. NB systems can support low data rate since a small bandwidth has limi-\n\
    tations in channel capacity according to Shannon-Hartley theorem [38]. Obviously, low data rate means a long radio\n\
    propagation time which results in high possibility of wireless conflicts between different radio communications. For\n\
    example, LoRa devices support receiving sensitivity low to −136 dBm when the spreading factor is 12, bandwidth is\n\
    125 kHz and nominal data rate is 293 bps. A short message whose length is tens of bytes may last for a few seconds\n\
    over the air, and this significantly increases the possibility of radio conflicts and interferences.\n\
    A dilemma of IoT applications is the use of NB radio systems to implement large scale and dense deployment,\n\
     \nTable 3    LoRa modem performance\nBW (kHz)\nSF\nCR\nData Rate (bps)\nReceiving\
    \ Sensitivity (dBm)\n125\n6\n4/5\n9380\n−118\n12\n4/5\n293\n−136\n62.5\n6\n4/5\n\
    4688\n−121\n12\n4/5\n146\n−139\n20.8\n6\n4/5\n1562\n−128\n12\n4/5\n49\n−144\n\
    10.4\n6\n4/5\n782\n−131\n12\n4/5\n24\n−147\nIJNDI, 2022, 1(1): 4−19. https://doi.org/10.53941/ijndi0101002\n\
     \n8\ne.g. utility meter reading, smart agriculture, and environment monitoring. Many research carried out at the physical\n\
    layer of LoRa-like modulation schemes focus on data rate improvement on the premise of keeping receiving sensi-\n\
    tivity at an acceptable level. Authors in [39] proposed a novel design of chirp transmitters and orthogonal hirp gener-\n\
    ators (OCGs) to support a wide range of spreading factors and bandwidth at a low cost. In addition, a phase-shifted\n\
    CSS (PS-CSS) was proposed to increase transmission rate by which a maximum of 33% improvement (spreading\n\
    factor is 6) was made compared to conventional CSS technologies.\nIn order to improve spectral efficiency and energy efficiency, alternative chirp spread spectrum techniques, in-\n\
    phase and quadrature CSS (IQCSS) and discrete chirp rate keying CSS (DCRK-CSS), were proposed in [40]. As\n\
    claimed by the authors, IQCSS can double throughputs compared with LoRa. DCRK-CSS can increase the through-\n\
    put up to 50% under certain conditions. The throughput optimization brought by the two schemes is obtained using\n\
    the same transmission power when compared with LoRa modulation, and this means less energy will be consumed as\n\
    shorter time is required to complete transmission. An idea of using index modulation (IM) in CSS was proposed in\n\
    [41]. Different from other techniques, using IM in CSS means multiple chirps are simultaneously transmitted which\n\
    allows more bits to be embedded in symbols. Consequently, the complexity of receiver design increases as it requires\n\
    more resources to detect and estimate data bits from a larger signal set. In order to reduce computational complexity,\n\
    a suboptimal detection algorithm was also proposed to analyze and locate desired data set in a recursive manner.\n\
    Although LoRa is a kind of proprietary technique, it mainly refers to the modulation scheme. Developers can\n\
    implement design or optimization for other layers of OSI models except for physical layers. Essentially, LoRa radio\n\
    provides wireless link for connecting devices. The medium ccess control (MAC) protocol, which is part of Link\n\
    Layer, is an important component as it is direactly related to the starting point of communication, which must take\n\
    various factors into consideration, e.g. the channel state, radio environment, acknowledgement, frequency usage and\n\
    traffic condition.\nAs  the  most  well-known  LoRa  communication  based  system,\
    \  LoRaWAN  has  been  adopted  worldwide.\nLoRaWAN defines the use of the ALOHA type medium access control method, which inevitably introduces packet\n\
    collision or packet loss. Early in 2016, Augustin et al [42] made simulations to study LoRaWAN MAC layer perfor-\n\
    mance. With given settings (100 LoRaWAN end devices, channel bandwidth = 125 kHz, coding rate = 4/5, pream-\n\
    ble = 6, payload range [1,58] bytes, packet arrival follows Poisson law), the obtained capacity usage is 18% of the\n\
    channel capacity, which is chosen to be the pure-ALOHA protocol. Corresponding link load is 0.48 at which around\n\
    60% of the packet transmission failed due to collisions. Due to the absence of channel detection algorithms, e.g.\n\
    CSMA in 802.11 standard, success rate of LoRaWAN MAC layer is very sensitive to the channel load as pure-\n\
    ALOHA.\nAuthors in [43] built a mathematical model to describe packet collision and packet loss in a LoRaWAN net-\n\
    work consisting of a number of LoRaWAN end devices and a LoRaWAN gateway. Probability of packet collision\n\
    increases in a LoRaWAN network as the increment of packet payload size or the value of spreading factor. Packet\n\
    loss has close relationship with duration of LoRaWAN uplink packet and LoRaWAN gateway delay (the packet loss\n\
    happens  when  the  gateway  is  sending  ACK  for  preceding  uplink  LoRaWAN\
    \  communication).  In  [44],  a  packet\nlatency model was built by taking packet collision probability and regulatory duty-cycle requirements into considera-\n\
    tion. LoRaWAN works on license free ISM band where radio activity is normally limited by local regulators dedi-\n\
    cated to the usage of transmitters. The MAC layer performance evaluation for LoRaWAN should include this limita-\n\
    tion as an important factor.\nRecently, LoRa has proposed a new modulation technique, i.e. the long-range frequency hopping spread spec-\n\
    trum (LR-FHSS), to further enhance long range capability and improve network capacity. The motivation for devel-\n\
    oping LR-FHSS is to remove limitations made by duty-cycle regional regulations [45]. Regional regulations strictly\n\
    define the period a radio can be active on a given channel. The number of terminals and data size for each transmis-\n\
    sion are also limited, which consequently reduces LoRaWAN network capacity. By the method of frequency hop-\n\
    ping, transmission is divided into a number of pieces and each piece is transmitted on different channels. As summa-\n\
    rized in [46], LR-FHSS works around limitations by intra-packet hopping to carry longer payload with slow data rate\n\
    in regions with restrictions on dwell time. Theoretical analysis shows that a 10 dB link budget improvement (about 3 ×\n\
    free-space transmission distance improvement) can be achieved under certain conditions (in the FCC region on the\n\
    915 MHz band) [46]. A 140× capacity improvement is possible to be achieved when comparing LR-FHSS with con-\n\
    ventional LoRa (SF12) communication [46]. LR-FHSS is compatible with LoRaWAN hardware and networks where\n\
    only software upgrading is needed. Such changes allow more and more applications previously restricted by LoRa\n\
    network capacity to achieve significant improvement and consolidate the application market of LoRa in long range\n\
    low data rate communication.\n4. Industry Iot and LoRa\nIJNDI, 2022, 1(1): 4−19. https://doi.org/10.53941/ijndi0101002\n\
     \n9\nConventionally industry related systems are isolated from public networks. Since the proposal of the fourth\n\
    industrial revolution (Industry 4.0), communication, autonomous and decentralized decisions with the aim of increas-\n\
    ing  industrial  efficiency,  productivity,  safety  and  transparency  have  become\
    \  a  new  system  design  purpose  [47].\nIndustrial IoT is a comprehensive topic referring to various disciplines. When it comes to wireless communication, a\n\
    strict requirement is proposed to the employed radio system: deterministic timing. Data communication in industry\n\
    systems usually has real-time timeliness requirements since failure of fulfilling the timing requirement may compro-\n\
    mise system performance or even cause dangers to human lives [48].\nNormal wireless systems utilize the ALOHA-like protocol, or the CSMA-CA algorithm to deal with channel\n\
    access and to implement interference avoidance. Channel access strategies based on randomness are not applicable in\n\
    Industry IoT because radio environment in industrial scenarios often suffer from various channel impairments such as\n\
    path loss, shadowing effect and unpredictable obstacles [49,50]. An idea of achieving deterministic behavior in wire-\n\
    less communication is to bound timing of transmission and receiving within a specified period, i.e. a slot. In [51],\n\
    authors proposed a modified time slotted channel hoping (TSCH) strategy for the use of the LoRaWAN MAC layer\n\
    to enable better frequency and code diversity on LoRaWAN end devices and network servers. In the evaluation test,\n\
    LoRaWAN end devices were allocated with different spreading factors and different channels. Data transmission was\n\
    not based on random access but started with synchronized signal by which packet conflicts on a channel can be elim-\n\
    inated. This method supports unconfirmed uplink communication only.\nTo achieve flexible communication in Industrial IoT, authors in [52] proposed a new MAC layer strategy to\n\
    support real-time data flow over LoRa based networks (RT-LoRa). RT-LoRa works with star topology in which a\n\
    sink node takes responsibility of synchronizing all end devices using regular beacon signals. End devices consist of\n\
    two types: the stationary node and mobile node. The stationary node is responsible for collecting sensory data whilst\n\
    the mobile node is allowed to move in the sensing area. In-network time is organized and bounded by cyclically\n\
    repeated superframe which mainly consists of beacon, contention access period (CAP) and contention free period\n\
    (CFP) .\nFeatures of RT-LoRa can be concluded as follows. (1) CAP and CFP contain a number of timeslot sets by\n\
    which duration of radio activities can be measured and strictly restricted within one or more slots, (2) In CAP, end\n\
    devices  use  Slotted-ALOHA  based  strategies  along  with  randomly  generated\
    \  3-tuple  parameters  (the  channel,\nspreading factor and time slot) to compete for channel accessing. The random parameters distribute channel usage by\n\
    which the success rate of communication increases. (3) In CFP, only end devices allocated in the current time slot is\n\
    allowed to communicate with the sink node, (4) QoS algorithm is provided in CFP to ensure reliability of communi-\n\
    cation at levels of normal, reliable and most reliable, (5) Radio channels are carefully allocated in each superframe to\n\
    fulfill requirements of duty-cycle under different regions.\nA similar real-time LoRa protocol was also proposed in [53] to achieve collision-free communication. Timing\n\
    in a LoRa network is divided into frames and further divided into a number of slots. On this basis, a real-time task\n\
    scheduling algorithm using logical slot indices is provided to regulate LoRa end device radio communication accord-\n\
    ing to the length of data packet, i.e. transmission time required for communication. With the help of modified Listen-\n\
    Before-Talk mechanism, the evaluation test confirmed that over 94% packet delivering rate is achievable although\n\
    high external interferences are present.\nIn the scenarios of Industrial IoT, LoRa techniques are usually employed to collect data generated on LoRa end\n\
    devices. Research studies mainly focus on how to ensure timeliness of wireless communication. Normally, commu-\n\
    nication in industry relies on cable connection (e.g. Ethernet, Field-bus, RS232/485), which has less concern about the\n\
    interference and latency. Wireless communication usually faces problems of performance degradation as it is easy to\n\
    be affected by interferences and packet conflicts. The LoRa technique has better performance on interference resis-\n\
    tance, but is heavily affected by packet conflicts due to low data rate. Therefore, a proper strategy to optimize wire-\n\
    less latency is quite important and of great needs, if LoRa is to be used in Industrial IoT. In this case, power con-\n\
    sumption issue is normally not of the highest priority.\n5. Smart City Iot and\
    \ LoRa\nDue to its requirement for massive and large-scale sensor deployment, it is common for smart city IoT to adopt\n\
    the LoRa technique. Although LoRa has long range communication capability, it has relatively low data rate which\n\
    affects overall system performance about network capacity, deployment density and power consumption. In [54],\n\
    authors studied the radio coverage issue of LoRa networks and concluded that (1) it is possible to achieve an 100%\n\
    packet delivery ratio up to 4 km range and 99% for over 4.8 km under certain conditions. In this case, a LoRaWAN\n\
    gateway is installed at the height of 30 m above ground, and (2) an empirical path loss model is proposed to deter-\n\
    mine LoRa link budget at frequency bands of 868 MHz and 433 MHz.\nIJNDI, 2022, 1(1): 4−19. https://doi.org/10.53941/ijndi0101002\n\
     \n10\nAlthough LoRa techniques provide desired radio performance for applications of large scale sensor deployment,\n\
    it is not easy to arrange such deployment as various technical parameters are involved in a LoRa based communica-\n\
    tion network, e.g. the spreading factor, frequency band, coding rate, distance and obstacle between LoRa end devices\n\
    and LoRa gateways. In [55], an optimal configuration scheme is provided to allocate appropriate spreading factors\n\
    and transmission power for every LoRa end device in a LoRaWAN network. The objective of the optimal configu-\n\
    ration scheme is to reduce probability of collisions and energy consumption. Two stages are adopted in the scheme.\n\
    At stage 1, each node tries to be allocated with a proper spreading factor by issuing communication to a gateway\n\
    using maximum transmission power, and this ensures that the spreading factor later allocated for an end device by the\n\
    gateway is sufficient to establish a LoRa radio link. At stage 2, the level of transmission power is further optimized\n\
    for an end device in order to save energy consumption on the premise of the reliable radio link. In [56], a compre-\n\
    hensive study on spreading factor allocation for LoRa based sensor nodes in dense network was studied, where an\n\
    overall consideration was taken for the use of spreading factors along with directly related parameters, e.g. the pay-\n\
    load size, packet error rate, ALOHA mechanism and duty-cycle requirement. Based on the distance between differ-\n\
    ent LoRa end devices and LoRa gateway, a suggestion about spreading factor allocation was given to improve deliv-\n\
    ery rate of overall network.\nIn [57], a LoRa-based mesh network was discussed to extend and enhance LoRa network coverage. LoRa radio\n\
    has long range capability, but is affected by deployment environment. Indoor obstacle can easily stop radio propaga-\n\
    tion, which is also a common issue for most wireless systems. Mesh networks enable each in-network LoRa device to\n\
    be a relay node to provide packet forward functionality for neighbor nodes which cannot directly reach a LoRa gate-\n\
    way. A similar idea can be found in [58] where a simplified AODV routing protocol was proposed to organize a\n\
    LoRa mesh network to cover areas that out the range of a single LoRaWAN gateway. A hierarchy-based energy effi-\n\
    cient routing protocol (HBEE) designed for the LoRa mesh network was proposed in [59]. In order to quickly build a\n\
    network structure, HBEE employs concurrent transmission to spread gateway information through the entire network.\n\
    Concurrent transmission means multiple LoRa network devices at the same level of a tree network forward data\n\
    packet using a synchronized way, which greatly reduces possibility of packet collision and minimizes network for-\n\
    mation time. Multi-path and multi-channel communication algorithms were used during the data collection stage that\n\
    further improves final data delivery rate. The experimental results obtained in [59] showed HBEE can achieve packet\n\
    reception rate of 95.7% and 89.8% during the network formation stage and normal operation stage, respectively.\n\
    Smart city IoT makes full use of LoRa capability of configurate radio range such that LoRa end devices located\n\
    at different positions can reach the sink node (e.g. the LoRa gateway) without modifying modulation schemes, which\n\
    is  normally  not  applicable  in  many  other  technologies.  Although  the  LoRaWAN\
    \  standard  is  a  successful  market\nexample in dealing with large scale sensor deployment, it faces the challenge of wireless packet collision, giving rise\n\
    to the requirement of reasonable configuration and optimization schemes. Moreover, severe radio environment may\n\
    affect wireless reception despite the fact that LoRa can achieve long range communication. Ad-hoc based mesh net-\n\
    works can provide flexible deployment options, and are particularly useful in smart city scenarios, see references [60−62].\n\
    6. Direct-to-satellite Iot and LoRa\nDtS-IoT is a very attractive IoT filed which extremely expands physical world connection from the Earth to the\n\
    space, and internet access is quite convenient in populated areas. However, DtS-IoT is not achievable at most areas\n\
    on the Earth. Satellite communication is the only solution to provide global coverage. DtS-IoT is a promising research\n\
    topic that helps address connectivity issues in certain scenarios, for example, disaster recovery scenarios of earth-\n\
    quakes, tsunamis and flooding [63]. Connectivity between ground networks (devices) and Low-Earth Orbit (LEO)\n\
    satellites can be achieved in two ways, indirect and direct (as shown in Figure 2 below). For those short range com-\n\
    munication systems, a ground based gateway is required to play as a relay to build mutual communication with satel-\n\
    lites. For long range wireless systems such as LoRa, it is possible to build direct links which make ground deploy-\n\
    ment more convenient and cost effective.\nIJNDI, 2022, 1(1): 4−19. https://doi.org/10.53941/ijndi0101002\n\
     \n11\nBased on existing LoRaWAN Class B mode, [64] proposed a scheme to utilize LEO satellites as LoRaWAN\n\
    beacon gateways to keep DtS-IoT connectivity. A LoRaWAN end device working with Class B mode keeps track-\n\
    ing beacon signals sent from LEO satellites and executing Ping-Response tasks as required, see Figure 3.\n\
     \n \nTime\nTime\n…\nBeacon duraƟon\nSleep duraƟon\n…\n…\n…\nBeacon period\nPing\
    \ duraƟon\nLoRaWAN \nClass B device\nLEO satellite/ \nLoRaWAN  gateway\nPing response\n\
    LoRaWAN\nClass B device\nBeacon period\nTime\nTime\nBeacon duration\nSleep duration\n\
    Ping duration\nPing response\nLEO satellite/\nLoRaWAN gateway\nFigure 3.  Work flow of DtS (Direct-To-Satellite) with LoRaWAN (LoRa wide area network) Class B device.\n\
     \nWhen LEO satellites moving around the Earth, if a satellite is out of range of LoRaWAN end device, the end\n\
    device will adjust the beacon detection window until next beacon from next satellite is captured. In [65], impact of\n\
    ionospheric scintillation was comprehensively studied to evaluate the limitations of LoRa communication in the use\n\
    of space-to-Earth satellite communications, while in [66] a trajectory-based LoRa radio uplink transmission policy\n\
    was studied to improve the success rate of direct connection from the LoRa end device to the satellite in space. The\n\
    policy takes various factors into consideration, e.g. the received signal strength indicator (RSSI) of LoRa beacons\n\
    from satellites, frequency shift of beacons (to determine the speed of satellite), and orbital parameters. The result\n\
    obtained from the analysis of these factors can be used for different transmission policies: plain trajectory, trajectory\n\
    random, trajectory skip and trajectory random. As authors stated, the proposed policy can at least duplicate the net-\n\
    work scalability compared with conventional LoRa communication methods.\nLoRa techniques used in space-ground communication are still in a pre-research stage but with very attractive\n\
    vision  [67].  Successful  links  established  between  LoRa  devices  and  satellites\
    \  can  make  IoT  globe  coverage  cost\neffective by removing ground station usage. However, there is a long way before this solution becomes mature as\n\
    extreme long range communication introduces research challenges in areas of modulation technique, antenna design,\n\
    signal processing, data coding, power management, uplink and downlink policies, interaction between satellites, etc.\n\
    [68−71].\n7. Healthcare Iot and LoRa\nApplications related to healthcare IoT are dedicated to the improvement of health care services and life quality\n\
    in social networks. Conventionally data collection for healthcare requires manual operations where service staffs need\n\
    to work with service receivers in a face-to-face manner. The LPWAN technology based wireless communication\n\
     \n(a)\n(b)\nLEO satellite/\nloT gateway\nLEO satellite/\nloT gateway\nGround\n\
    station\nLPWAN\nterminal\nLPWAN\nterminal\nFigure 2.  (a) Indirect links between ground-based network and LEO satellite; (b) Direct links between ground-based\n\
    network and LEO satellite.\nIJNDI, 2022, 1(1): 4−19. https://doi.org/10.53941/ijndi0101002\n\
     \n12\nchanges the service pattern by enabling data capture to be completed automatically and remotely even the service\n\
    receivers are in a mobile state. Long range and low power LoRa is an appropriate technique to address numerous\n\
    connectivity issues between doctors and patients in urban areas and portions of rural areas [72]. Authors in [72] pro-\n\
    posed an architecture integrated with the LoRa technique fog computation and satellite connectivity to construct a\n\
    healthcare service platform with the corresponding system diagram illustrated in Figure 4.\n\
     \n \nLoRa\nLoRa base\nstation\nLoRa\nDate base\nML model\nFigure 4.  System architecture for rural area network for healthcare IoT.\n\
     \nWhen sensor devices are activated from the sleep mode, the collected sensory data is sent to the always-on\n\
    LoRa gateway for processing by fog computing based machine learning models. As conventional Internet connec-\n\
    tion might be unavailable in rural areas, Low Earth Orbit Satellite connectivity can be employed to connect the local\n\
    system to the Internet by which doctors from anywhere of the world are able to keep monitoring on status of patients.\n\
    In [73] a hybrid and edge based healthcare system was proposed where wearable sensor were equipped on the\n\
    human body to take responsibility of monitoring health state and reporting to central system. The reporting can expe-\n\
    rience either of two communication paths, i.e. LoRa or Bluetooth, depending on the distance between sensors and\n\
    gateways. If a Bluetooth router is within effective range, health data will be sent to router and then forwarded to an\n\
    edge gateway. Otherwise, the LoRa radio link will be used to convey data to the edge gateway since LoRa can sup-\n\
    port larger coverage than Bluetooth. The edge gateway is in charge of implementing data processing and making\n\
    quick responses to situations. Functionalities such as data storage and data analysis are implemented later by a remote\n\
    cloud server. By combining short-range and long-range wireless communication technologies, data collection in a\n\
    hybrid system is more feasible and configurable. The system architecture is illustrated in Figure 5:\n\
     \n \nHealthcare   \ndevice\nEdge router\nHealthcare   \ndevice\nEdge router\n\
    LoRa\nLoRa\nEdge \ngateway\nCloud\nserver\n+ \n+ \nCloud\nserver\nEdge\nLoRa\n\
    LoRa\ngateway\nEdge router\nHealthcare\ndevice\nHealthcare\ndevice\nEdge router\n\
    Figure 5.  System architecture of hybrid healthcare IoT system.\n \nAdoption of LoRa in Healtcare IoT is an example of taking LoRa as a complementary technique to improve\n\
    user experience. Different from IoT fields such as smart city IoT and DtS-IoT, LoRa is not the major choice in\n\
    healthcare IoT, but can be an ideal solution for upgrading existing systems in order to provide better service.\n\
    IJNDI, 2022, 1(1): 4−19. https://doi.org/10.53941/ijndi0101002\n \n13\n8. Possible\
    \ Future Development of LoRa\nIoT is becoming more and more complicated compared with its initial version. Having devices complete tasks\n\
    of reporting sensory data and controlling actuators is an important part of IoT. However, the way of system organiza-\n\
    tion and the pattern of network operation are more and more diverse, due to expansion of application fields which\n\
    require advanced IoT technologies to improve existing systems, or build new systems for certain targets (e.g. com-\n\
    munication between low power ground-based devices and satellites). This motivates IoT to move deeply into appli-\n\
    cation scenarios to construct reasonable and efficient systems. In the meantime, technologies adopted in different IoT\n\
    application scenarios keep developing in different aspects, including new algorithms, system optimization, and sys-\n\
    tem integration. As a kind of low power wireless technologies, LoRa is usually taken by IoT applications to achieve\n\
    long range communication, which means that effectively integrating LoRa into different systems is one promising\n\
    future research direction in the development of LoRa. Possible topics on these issues may include but not limited to:\n\
    5G network and LoRa, edge computing and LoRa.\n8.1. 5G and LoRa\n5G network is becoming more and more popular due to its exciting features of massive machine-type commu-\n\
    nication (mMTC) supporting 1 million devices/km2, enhanced mobile broadband (eMBB) supporting less than 4 ms\n\
    latency, and ultra-reliable, low-latency communication (URLLC) supporting mission critical applications with less\n\
    than 0.5 ms latency [74]. In Industry 4.0 and its later version, mMTC and URLLC are often mentioned as 5G offers\n\
    significant performance improvement compared with conventional wireless access techniques (e.g. 3G/4G). Tradi-\n\
    tional industry applications adopt cabling systems to achieve reliable and low latency communication, which has\n\
    urgent requirements for wireless solutions. Applications such as real-time monitoring, industry-robotics, and remote\n\
    communication support require highly reliable and low latency wireless technologies to provide most convenience\n\
    when deploying system [75]. Combining the LoRa and 5G based gateway will be a focus of research. A random-\n\
    based MAC protocol is not suitable for LoRa to be used in these cases. A systematic re-design is needed for LoRa to\n\
    cooperate with 5G to achieve precise control by eliminating any uncertainty caused by interference or collisions. For\n\
    example, the concept of time sensitivity networking (TSN) over 5G has been proposed to enable reliable and deter-\n\
    ministic wireless communications between end devices and 5G networks [76−78]. The development of LoRa can be\n\
    taken as a reference to design TSN-like algorithms in order to make proper arrangement for (1) scheduling priority-\n\
    based uplink traffic, (2) ensuring downlink control signaling, and (3) managing network scalability.\n\
    8.2. Edge Computing and LoRa\nEdge computing is a familiar topic to researchers for the reason of rapid growth of IoT applications requiring\n\
    quick responses to the generated data, such as Vehicular Data Analytics, Smart Home, Video Stream Analytics and\n\
    Virtual Reality [79]. Conventionally cloud based computing is used to process information collected from different\n\
    locations, but has limitations in providing real-time responses for safety-critical and performance-sensitivity applica-\n\
    tions  due  to  unpredictable  latency  [80].  Edge  computing  proposes  a  new\
    \  computing  paradigm  by  migrating  data\ncomputation or storage to the network “edge” in order to mitigate the escalation in resource congestion at the central\n\
    computing unit [81]. In such a paradigm, an edge node is expected to not only exchange data between the local net-\n\
    work and the remote center, but also have capability on processing data received via multiple interfaces at the local\n\
    side. Many studies about LoRa related edge computing can be found from [82−87] that cover fields of medical care,\n\
    agriculture, block-chain, smart metering, smart city, artificial intelligence, etc. Note that LoRa can also be used in any\n\
    possible scenarios by cooperating with different hardware/algorithms. For example, in [86] authors proposed a sys-\n\
    tem integrated with edge/fog computing, where LoRa and deep learning algorithms were used to perform fall detec-\n\
    tion. And overcome the lack of network infrastructures at certain areas. In [87] LoRa and Bluetooth worked together\n\
    to build a low power smart city network (as shown in Figure 6) designed for collecting daily information such as\n\
    transportation state, health data, etc. The data is generated and sent to the LoRa edge gateway via short range Blue-\n\
    tooth, and then forwarded to the LoRa fog gateway via long range LoRa links. On the LoRa edge and fog gateway,\n\
    preliminary data processing will be implemented by which corresponding responses can be made at the local side and\n\
    the volume of data delivered to the Cloud can be minimized. A combination of LoRaWAN and Wi-Fi/Ethernet was\n\
    proposed in [88] to build an autonomous server which can process and store data even in the absence of internet con-\n\
    nectivity.\nIJNDI, 2022, 1(1): 4−19. https://doi.org/10.53941/ijndi0101002\n \n\
    14\nIt can be concluded that LoRa is quite popular as a data communication technique in many different edge com-\n\
    puting-based applications. However, as a pure physical layer communication technique, LoRa is in short of architec-\n\
    ture design to support diverse application requirements. An example solution is the LoRaWAN standard, but such a\n\
    strandard is insufficient as the deign purpose of LoRaWAN is for reporting data, rather than supporting local data\n\
    processing. In the future development, relevant research is needed to find out how to properly deploy and allocate\n\
    LoRa resource in the context of edge computing.\nIn general, it is reasonable to believe, there are two future promising development directions in LoRa, i.e. (1)\n\
    enhancement of LoRa communication efficiency, and (2) design of interaction mechanisms between LoRa and other\n\
    technologies/systems, where the enhancement on communication efficiency could be treated as a vertical develop-\n\
    ment direction. As a bottom communication technology, LoRa is often used to collect massively distributed device\n\
    data. Having data transmission deterministic and reliable is an important research topic in promoting LoRa for the use\n\
    of dense networks. Making LoRa collaborative could be treated as a horizontal development direction, where the\n\
    LoRa technique is expected to work together with different systems through proper integration.\n\
    9. Conclusions\nRapid development of IoT makes more and more application fields adopt LoRa to establish close links between\n\
    IoT objects and data processing systems. As one of LPWAN technologies, LoRa is particularly useful for network-\n\
    ing embedded and low-cost devices deployed in a wide area. As per characteristics of different IoT fields, the use of\n\
    LoRa technique may have different emphasis. In industry IoT like fields, interference robustness of LoRa along with\n\
    the specifically designed strategy for ensuring deterministic timing is the main point, which provides a reliable wire-\n\
    less communication link for industrial applications. For smart city IoT like fields, flexible radio configuration which\n\
    allows massive and large scale network deployment is the benefit brought by the LoRa technique. However, network\n\
    performance evaluation and optimization algorithms are needed to help LoRa based network to resolve packet con-\n\
    flict issues. DtS-IoT is a new area that makes use of long range communication capability to its maximum perfor-\n\
    mance. Challenges in this case require more study as existing research made for the LoRa technique may be insuffi-\n\
    cient. Healthcare IoT like fields demonstrate the use of the LoRa technique in associating with other systems or tech-\n\
    niques to improve service quality. In general, the LoRa technique is particularly important in building communica-\n\
    tion links for ubiquitous computing of IoT. Researches on further improving communication range and interference\n\
    resistance could become major focuses as they are the core factors of the LoRa technique. In the future development,\n\
    the LoRa technique can evolve towards directions of (1) efficient communication for stronger precise control capa-\n\
    bility, and (2) reasonable mechanism for better interaction with other systems.\n\
    Author Contributions:  Fang Yao: writing — original draft preparation; Yulong Ding, Shengguang Hong, and\n\
    Shuang-Hua Yang: writing — review, editing and visualization; Yulong Ding and Shuang-Hua Yang: super-\n\
    vision;  Yulong  Ding  and  Shuang-Hua  Yang:  project  administration;  Yulong\
    \  Ding  and  Shuang-Hua  Yang:\nfunding acquisition.\n \nLoRa \nFog\nCloud\n\
    server\nLoRa \nEdge\nLoRa \nEdge\nCloud\nserver\nLoRa\nFog\nLoRa\nEdge\nLoRa\n\
    Edge\nFigure 6.  A hybrid LoRa and Bluetooth city network.\nIJNDI, 2022, 1(1): 4−19. https://doi.org/10.53941/ijndi0101002\n\
     \n15\nFunding:  This  research  is  jointly  supported  by  the  National  Natural\
    \  Science  Foundation  of  China  (Grant  Nos.  92067109,\n61873119), Shenzhen Science and Technology Program (Grant No. ZDSYS20210623092007023), the Science and Technology\n\
    Planning Project of Guangdong Province (Grant No. 2021A0505030001), the Educational Commission of Guangdong Province\n\
    (Grant No. 2019KZDZX1018) and the Enterprise Expert Studio Program of JiangNing District (2020, Nanjing).\n\
    Conflicts of Interest:  The authors declare no conflict of interest. The funders had no role in the design of the study;\n\
    in the collection, analyses, or interpretation of data; in the writing of the manuscript; or in the decision to publish the\n\
    results.\nReferences\n Elijah, O.; Rahman, T. A.; Orikumhi, I.; et al. An overview of internet of things (IoT) and data analytics in agriculture: Benefits and\n\
    challenges. IEEE Internet Things J., 2018, 5: 3758−3773.\n1.\n A  shton,  K.  That \
    \ ‘ Internet  of  Things’  Things.  RFID  Journal,  2009.  Available  online: \
    \ http://www.itrco.jp/libraries/RFIDjournal-\nThat%20Internet%20of%20Things%20Thing.pdf. (accessed on 5 November 2022).\n\
    2.\n Serials Y: Global Information Infrastructure, Internet Protocol Aspects, and Next-Generation Networks. Recommendation ITU-Y Y.\n\
    2060,  2012.  Available  online:  https://kipdf.com/series-y-global-information-infrastructure-internet-protocol-aspects-and-next-ge_\n\
    5ae57e537f8b9ad98a8b4649.html. (accessed on 10 November 2022).\n3.\n SEMTECH. Real-world LoRaWANTM Network Capacity for Electrical Metering Applications. Semtech White Paper, 2017.Avail-\n\
    able  online:  https://cdn2.hubspot.net/hubfs/2507363/Semtech_Network_Capacity_White_Paper.pdf.\
    \  (accessed  on  10  November\n2022).\n4.\n de  Castro  Tomé,  M.;  Nardelli,\
    \  P.H.J.;  Alves,  H.  Long-range  low-power  wireless  networks  and  sampling\
    \  strategies  in  electricity\nmetering. IEEE Trans. Ind. Electron., 2019, 66: 1629−1637.\n\
    5.\n Magrin, D.; Centenaro, M.; Vangelista, L. Performance evaluation of LoRa networks in a smart city scenario. In 2017\
    \ IEEE Interna-\ntional  Conference  on  Communications  (ICC),  Paris,  France, \
    \ 21 –25  May  2017;  IEEE:  Paris,  2017;  pp.  1 –7.  doi:10.1109/ICC.\n2017.7996384\n\
    6.\n Huang, P.; Xiao, L.; Soltani, S.; et al. The evolution of MAC protocols in wireless sensor networks: A survey. IEEE\
    \ Commun. Surv.\nTutorials, 2013, 15: 101−120.\n7.\n Raza, U.; Kulkarni, P.; Sooriyabandara, M. Low power wide area networks: An overview. IEEE\
    \ Commun. Surv. Tutorials, 2017, 19:\n855−873.\n8.\n Farrell, S. Low-Power Wide Area Network (LPWAN) Overview. Internet Engineering Task Force (IETF), 2018. Available online:\n\
    https://www.rfc-editor.org/rfc/rfc8376.\n9.\n Tikhvinsky, V. LPWAN Narrowband Technologies (LoRaWAN, SigFox, etc. ) for M2M Networks and Internet of Things Design.\n\
    ITU Regional Forum on “Internet of Things, Telecommunication Networks and Big Data as basic infrastructure for Digital Econ-\n\
    omy” .  Russia:  Saint-Petersburg,  2018.  Available  online:  https://www.itu.int/en/ITU-T/Workshops-and-Seminars/20180604/Docu-\n\
    ments/V_Tikhvinskiy.pdf (accessed on 8 November 2022).\n10.\n ROHM. The Latest Technology Trends of Wi-SUN Wireless Communication Modules. ROHM Semiconductor, White Paper, 2021.\n\
    Available  online:  https://fscdn.rohm.com/en/products/databook/white_paper/module/power_module/specified_low_power/wi-sun-\n\
    han1_wp-e.pdf (accessed on 7 November 2022).\n11.\n Sinha, R.S.; Wei, Y.Q.; Hwang, S.H. A survey on LPWA technology: LoRa and NB-IoT. ICT\
    \ Express, 2017, 3: 14−21.\n12.\n Sun, Z.H.; Yang, H.Q.; Liu, K.; et al. Recent advances in LoRa: A comprehensive survey. ACM\
    \ Trans. Sens. Netw., 2022, 18: 67.\n13.\n Gkotsiopoulos,  P.;  Zorbas,  D.;  Douligeris,\
    \  C.  Performance  determinants  in  LoRa  networks:  A  literature  review. \
    \ IEEE  Commun.\nSurv. Tutorials, 2021, 23: 1721−1758.\n14.\n Li, C. N.; Cao, Z.C. LoRa networking techniques for large-scale and long-term IoT: A down-to-top survey. ACM\
    \ Comput. Surv.,\n2023, 55: 52.\n15.\n Sharma, N.; Shamkuwar, M.; Singh, I. The history, present and future with IoT. In Internet\
    \ of Things and Big Data Analytics for\nSmart Generation; Balas, V. ; Solanki, V. ; Kumar, R. ; et\
    \ al, Eds. ; Springer: Cham, 2019; pp. 27–51. doi:10.1007/978-3-030-04203-\n5_3\n\
    16.\n Goudos, S. K.; Dallas, P. I.; Chatziefthymiou, S.; et al. A survey of IoT key enabling and future technologies: 5G, mobile IoT,\n\
    sematic web and applications. Wireless Pers. Commun., 2017, 97: 1645−1675.\n17.\n\
     Savaglio,  C.;  Ganzha,  M.;  Paprzycki,  M.;  et  al.  Agent-based  internet\
    \  of  things:  State-of-the-art  and  research  challenges.  Future\nGener. Comput.\
    \ Syst., 2020, 102: 1038−1053.\n18.\n Glaroudis, D.; Iossifides, A.; Chatzimisios, P. Survey, comparison and research challenges of IoT application protocols for smart\n\
    farming. Comput. Netw., 2020, 168: 107037.\n19.\n Mekki, K.; Bajic, E.; Chaxel, F.; et\
    \ al. A comparative study of LPWAN technologies for large-scale IoT deployment. ICT\
    \ Express,\n2019, 5: 1−7.\n20.\n Adelantado,  F.;  Vilajosana,  X.;  Tuset-Peiro,\
    \  P.;  et  al.  Understanding  the  limits  of  LoRaWAN.  IEEE  Commun.  Mag., \
    \ 2017,  55:\n34−40.\n21.\n Devalal, S.; Karthikeyan, A. LoRa technology-an overview. In 2018\
    \ Second International Conference on Electronics, Communica-\ntion  and  Aerospace\
    \  Technology  (ICECA),  Coimbatore,  India,  29 –31  March  2018;  IEEE:  Coimbatore,\
    \  2018;  pp.  284 –290.\ndoi:10.1109/ICECA.2018.8474715\n22.\n Chaudhari, B. S.; Zennaro, M.; Borkar, S. LPWAN technologies: Emerging application characteristics, requirements, and design\n\
    considerations. Future Internet, 2020, 12: 46.\n23.\n Perwej, Y.; Haq, K.; Parwej, F.; et\
    \ al. The internet of things (IoT) and its application domains. Int. J. Comput.\
    \ Appl., 2019, 182:\n36−49.\n24.\n LoRa. Platform for IoT. Available online: https://www.semtech.com/lora/. (accessed on 15 November 2022).\n\
    25.\n Semtech Corporation. LoRa® and LoRaWAN®: A Technical Overview. Technical Paper, 2020. Available online: https://lora-devel-\n\
    opers.semtech.com/uploads/documents/files/LoRa_and_LoRaWAN-A_Tech_Overview-Downloadable.pdf (accessed on 13 Novem-\n\
    ber 2022).\n26.\nIJNDI, 2022, 1(1): 4−19. https://doi.org/10.53941/ijndi0101002\n\
     \n16\n Lavric, A.; Petrariu, A.I. LoRaWAN communication protocol: The new era of IoT. In 2018\
    \ International Conference on Develop-\nment  and  Application  Systems  (DAS), \
    \ Suceava,  Romania,  24– 26  May  2018;  IEEE:  Suceava,  2018;  pp.  74 –77.\n\
    doi:10.1109/DAAS.2018.8396074\n27.\n Jouhari, M.; Amhoud, E.M.; Saeed, N.; et\
    \ al. A survey on scalable LoRaWAN for massive IoT: Recent advances, potentials, and\n\
    challenges. arXiv preprint arXiv: 2202.11082, 2022. Available online: https://arxiv.org/pdf/2202.11082.pdf (accessed on 13 Novem-\n\
    ber 2022).\n28.\n Siddique, A.; Prabhu, B.; Chaskar, A.; et al. A review on intelligent agriculture service platform with LoRa based wireless sensor\n\
    network. Int. Res. J. Eng. Technol., 2019, 6: 2539−2542.\n29.\n Vejlgaard, B.; Lauridsen, M.; Nguyen, H.; et\
    \ al. Coverage and capacity analysis of Sigfox, LoRa, GPRS, and NB-IoT. In 2017\
    \ IEEE\n85th Vehicular Technology Conference (VTC Spring), Sydney, NSW, Australia, 04–07\
    \ June 2017; IEEE: Sydney, 2017; pp. 1–5.\ndoi:10.1109/VTCSpring.2017.8108666\n\
    30.\n Naik, N. LPWAN technologies for IoT systems: Choice between ultra narrow band and spread spectrum. In 2018\
    \ IEEE Interna-\ntional  Systems  Engineering  Symposium  (ISSE),  Rome,  Italy, \
    \ 01 –03  October  2018;  IEEE:  Rome,  2018;  pp.  1 –8.  doi:10.1109/\nSysEng.2018.8544414\n\
    31.\n Tsotsolas, N.; Komisopoulos, F.; Papadopoulos, P.; et al. An integrated LoRa-based IoT platform serving smart farming and agro-\n\
    logistics. Emerging Ecosystem-Centric Business Models for Sustainable Value Creation. IGI Global, 2022: 132−158.\n\
    32.\n SEMTECH.  SX1276/77/78/79 –137  MHz  to  1020  MHz  Low  Power  Long  Range\
    \  Transceiver.  2020.  Available  online:\nhttps://www.mouser.com/datasheet/2/761/sx1276-1278113.pdf (accessed on 4 November 2022).\n\
    33.\n Petäjäjärvi, J.; Mikhaylov, K.; Pettissalo, M.; et al. Performance of a low-power wide-area network based on LoRa technology:\n\
    Doppler robustness, scalability, and coverage. Int. J. Distrib. Sens. Netw. 2017, in press. doi:10.1177/1550147717699412\n\
    34.\n Mroue, H.; Nasser, A.; Parrein, B.; et al. Analytical and simulation study for LoRa modulation. In 2018\
    \ 25th International Confer-\nence on Telecommunications (ICT), Saint-Malo, France, 26–28\
    \ June 2018; IEEE: Saint-Malo, 2018; pp. 655–659. doi:10.1109/\nICT.2018.8464879\n\
    35.\n Pasolini, G. On the LoRa chirp spread spectrum modulation: Signal properties and their impact on transmitter and receiver architec-\n\
    tures. IEEE Trans. Wireless Commun., 2022, 21: 357−369.\n36.\n Croce, D.; Gucciardo, M.; Mangione, S.; et\
    \ al. Impact of LoRa imperfect orthogonality: Analysis of link-level performance. IEEE\n\
    Commun. Lett., 2018, 22: 796−799.\n37.\n Semtech Corporation. LoRa Modulation Basics. 2015.\n\
    38.\n Nguyen, T.T.; Nguyen, H.H.; Barton, R.; et al. Efficient design of chirp spread spectrum modulation for low-power wide-area net-\n\
    works. IEEE Internet Things J., 2019, 6: 9503−9515.\n39.\n de Almeida, I.B.F.; Chafii, M.; Nimr, A.; et\
    \ al. Alternative chirp spread spectrum techniques for LPWANs. IEEE Trans. Green\n\
    Commun. Netw., 2021, 5: 1846−1855.\n40.\n Hanif, M.; Nguyen, H.H. Frequency-shift chirp spread spectrum communications with index modulation. IEEE\
    \ Internet Things J.,\n2021, 8: 17611−17621.\n41.\n Augustin, A.; Yi, J. Z.; Clausen, T.; et\
    \ al. A study of LoRa: Long range & low power networks for the internet of things. Sensors,\n\
    2016, 16: 1466.\n42.\n Ferre,  G.  Collision  and  packet  loss  analysis  in\
    \  a  LoRaWAN  network.  In  2017  25th  European  Signal  Processing  Conference\n\
    (EUSIPCO),  Kos,  Greece,  28  August  2017 –02  September  2017;  IEEE:  Kos,\
    \  2017;  pp.  2586 –2590.  doi:10.23919/EUSIPCO.\n2017.8081678\n43.\n Sørensen, R.B.; Kim, D.M.; Nielsen, J.J.; et\
    \ al. Analysis of latency and MAC-layer performance for class a LoRaWAN. IEEE\
    \ Wire-\nless Commun. Lett., 2017, 6: 566−569.\n44.\n Boquet, G.; Tuset-Peiró, P.; Adelantado, F.; et\
    \ al. LR-FHSS: Overview and performance analysis. IEEE Commun. Mag., 2020, 59:\n\
    30−36.\n45.\n Semtech.  Application  note:  LR-FHSS  system  performance.  Available\
    \  online:https://lora-developers.semtech.com/library/product-\ndocuments/. (accessed on 8 Octomber 2022).\n\
    46.\n Boyes, H.; Hallaq, B.; Cunningham, J.; et al. The industrial internet of things (IIoT): An analysis framework. Comput.\
    \ Ind., 2018,\n101: 1−12.\n47.\n Bartolomeu, P.; Alam, M.; Ferreira, J.; et al. Supporting deterministic wireless communications in industrial IoT. IEEE\
    \ Trans. Ind.\nInf., 2018, 14: 4045−4054.\n48.\n Wang, W.B.; Capitaneanu, S.L.; Marinca, D.; et\
    \ al. Comparative analysis of channel models for industrial IoT wireless communica-\n\
    tion. IEEE Access, 2019, 7: 91627−91640.\n49.\n Foukalas, F.; Pop, P.; Theoleyre, F.; et\
    \ al. Dependable wireless industrial IoT networks: Recent advances and open challenges. In\n\
    2019  IEEE European  Test Symposium  (ETS),  Baden-Baden,  Germany,  27– 31  May\
    \ 2019; IEEE: Baden-Baden,  2019; pp.  1 –10.\ndoi:10.1109/ETS.2019.8791551\n\
    50.\n Rizzi, M.; Ferrari, P.; Flammini, A.; et al. Using LoRa for industrial wireless networks. In 2017\
    \ IEEE 13th International Workshop\non Factory Communication Systems (WFCS), Trondheim, Norway, 31\
    \ May 2017–02 June 2017; IEEE: Trondheim, 2017; pp. 1–4.\ndoi:10.1109/WFCS.2017.7991972\n\
    51.\n Leonardi, L.; Battaglia, F.; Lo Bello, L. RT-LoRa: A medium access strategy to support real-time flows over LoRa-based networks\n\
    for industrial IoT applications. IEEE Internet Things J., 2019, 6: 10812−10823.\n\
    52.\n Hoang, Q.L.; Jung, W.S.; Yoon, T.; et al. A real-time LoRa protocol for industrial monitoring and control systems. IEEE\
    \ Access,\n2020, 8: 44727−44738.\n53.\n Jörke, P.; Böcker, S.; Liedmann, F.; et\
    \ al. Urban channel models for smart city IoT-networks based on empirical measurements of LoRa-\n\
    links at 433 and 868 MHz. In 2017 IEEE 28th Annual International Symposium on\
    \ Personal, Indoor, and Mobile Radio Communi-\ncations (PIMRC), Montreal, QC, Canada, 08–13\
    \ October 2017; IEEE: Montreal, 2017; pp. 1–6. doi:10.1109/PIMRC.2017.8292708\n\
    54.\n Premsankar, G.; Ghaddar, B.; Slabicki, M.; et al. Optimal configuration of LoRa networks in smart cities. IEEE\
    \ Trans. Ind. Inf.,\n2020, 16: 7243−7254.\n55.\n Lavric, A. LoRa (long-range) high-density sensors for internet of things. J.\
    \ Sens., 2019, 2019: 3502987.\n56.\n Lee, H.C.; Ke, K.H. Monitoring of large-area IoT sensors using a LoRa wireless mesh network system: Design and evaluation. IEEE\n\
    Trans. Instrum. Meas., 2018, 67: 2177−2187.\n57.\n Almeida,  N.C.;  Rolle,  R.P.;\
    \  Godoy,  E.P.;  et  al.  Proposal  of  a  hybrid  LoRa  Mesh/LoRaWAN  network.\
    \  In  2020  IEEE\nInternational Workshop on Metrology for Industry 4. 0 & IoT, Roma, Italy, 03–05\
    \ June 2020; IEEE: Roma, 2020; pp. 702–707.\n58.\nIJNDI, 2022, 1(1): 4−19. https://doi.org/10.53941/ijndi0101002\n\
     \n17\ndoi:10.1109/MetroInd4.0IoT48571.2020.9138206\n Hong, S. G.; Yao, F.; Ding, Y. L.; et\
    \ al. A hierarchy-based energy-efficient routing protocol for LoRa-mesh network. IEEE\
    \ Internet\nThings J., 2022, 9: 22836−22849.\n59.\n Huh, H.; Kim, J.Y. LoRa-based mesh network for IoT applications. In 2019\
    \ IEEE 5th World Forum on Internet of Things (WF-IoT),\nLimerick, Ireland, 15–18\
    \ April 2019; IEEE: Limerick, 2019; pp. 524–527. doi:10.1109/WF-IoT.2019.8767242\n\
    60.\n Osorio, A.; Calle, M.; Soto, J. D.; et al. Routing in LoRaWAN: Overview and challenges. IEEE\
    \ Commun. Mag., 2020, 58: 72−76.\n61.\n Centelles, R. P.; Freitag, F.; Meseguer, R.; et\
    \ al. Beyond the star of stars: An introduction to multihop and mesh for LoRa and\n\
    LoRaWAN. IEEE Pervas. Comput., 2021, 20: 63−72.\n62.\n Fraire, J.A.; Céspedes, S.; Accettura, N. Direct-to-satellite IoT - a survey of the state of the art and future research perspectives. In\n\
    18th International Conference on Ad-Hoc Networks and Wireless on Ad-Hoc, Mobile, and\
    \ Wireless Networks, Luxembourg, Luxem-\nbourg, October 1–3, 2019; Springer: Luxembourg, 2019; pp. 241–258. doi:10.1007/978-3-030-31831-4_17\n\
    63.\n Fraire, J.A.; Henn, S.; Dovis, F.; et al. Sparse satellite constellation design for LoRa-based direct-to-satellite internet of things. In\n\
    GLOBECOM 2020 - 2020 IEEE Global Communications Conference, Taipei, China, 07–11\
    \ December 2020; IEEE: Taipei, China,\n2020; pp. 1–6. doi:10.1109/GLOBECOM42002.2020.9348042\n\
    64.\n Fernandez,  L.;  Ruiz-De-Azua,  J.  A.;  Calveras,  A.;  et  al.  Assessing\
    \  LoRa  for  satellite-to-earth  communications  considering  the\nimpact of ionospheric scintillation. IEEE\
    \ Access, 2020, 8: 165570−165582.\n65.\n Álvarez, G.; Fraire, J. A.; Hassan, K. A.; et\
    \ al. Uplink transmission policies for LoRa-based direct-to-satellite IoT. IEEE\
    \ Access,\n2022, 10: 72687−72701.\n66.\n Satellite Based LoRa Unlocks Europe-Wide IoT. White Paper, EchoStar Mobile. Available online: https://www.echostarmobile.com/\n\
    wp-content/uploads/2022/04/EchoStar_Mobile_White_Paper_compressed.pdf (accessed on 5 November 2022).\n\
    67.\n Ullah, M. A.; Mikhaylov, K.; Alves, H. Analysis and simulation of LoRaWAN LR-FHSS for direct-to-satellite scenario. IEEE\
    \ Wire-\nless Commun. Lett., 2022, 11: 548−552.\n68.\n Chaari, L.; Fourati, M.; Rezgui, J. Heterogeneous LoRaWAN & LEO satellites networks concepts, architectures and future direc-\n\
    tions. In 2019 Global Information Infrastructure and Networking Symposium (GIIS), Paris, France, 18–20\
    \ December 2019; IEEE:\nParis, 2019; pp. 1–6. doi:10.1109/GIIS48668.2019.9044966\n\
    69.\n Doroshkin, A. A.; Zadorozhny, A. M.; Kus, O. N.; et al. Experimental study of LoRa modulation immunity to Doppler effect in\n\
    CubeSat radio communications. IEEE Access, 2019, 7: 75721−75731.\n70.\n Colavolpe, G.; Foggi, T.; Ricciulli, M.; et\
    \ al. Reception of LoRa signals from LEO satellites. IEEE Trans. Aerosp. Electron.\
    \ Syst.,\n2019, 55: 3587−3602.\n71.\n Dimitrievski, A.; Filiposka, S.; Melero, F.J.; et\
    \ al. Rural healthcare IoT architecture based on low-energy LoRa. Int. J. Environ.\
    \ Res.\nPublic Health, 2021, 18: 7660.\n72.\n Wu, F.; Qiu, C.K.; Wu, T.Y.; et\
    \ al. Edge-based hybrid system implementation for long-range safety and healthcare IoT applications.\n\
    IEEE Internet Things J., 2021, 8: 9970−9980.\n73.\n Adebusola, J.A.; Ariyo, A.A.; Elisha, O.A.; et\
    \ al. An overview of 5G technology. In 2020 International Conference in Mathematics,\n\
    Computer  Engineering  and  Computer  Science  (ICMCECS),  Ayobo,  Nigeria,  18\
    \ –21  March  2020;  IEEE:  Ayobo,  2020;  pp.  1 –4.\ndoi:10.1109/ICMCECS47690.2020.240853\n\
    74.\n Rao, V.C.S.; Kumarswamy, P.; Phridviraj, M.S.B.; et al. 5G enabled industrial internet of things (IIoT) architecture for smart manu-\n\
    facturing. In Data Engineering and Communication Technology; Reddy, K.A.; Devi, B.R.; George, B.; et\
    \ al, Eds.; Springer: Singa-\npore, 2021; pp. 193–201. doi:10.1007/978-981-16-0081-4_20\n\
    75.\n Larrañaga, A.; Lucas-Estañ, M. C.; Martinez, I.; et al. Analysis of 5G-TSN integration to support industry 4.0. In 2020\
    \ 25th IEEE\nInternational Conference on Emerging Technologies and Factory Automation\
    \ (ETFA), Vienna, Austria, 08–11 September 2020;\nIEEE: Vienna, 2020; pp. 1111–1114. doi:10.1109/ETFA46521.2020.9212141\n\
    76.\n Nasrallah, A.; Thyagaturu, A.S.; Alharbi, Z.; et al. Ultra-low latency (ULL) networks: The IEEE TSN and IETF DetNet standards\n\
    and related 5G ULL research. IEEE Commun. Surv. Tutorials, 2019, 21: 88−145.\n\
    77.\n Gundall, M.; Huber, C.; Rost, P.; et al. Integration of 5G with TSN as prerequisite for a highly flexible future industrial automation:\n\
    Time synchronization based on IEEE 802.1AS. In IECON 2020 The 46th Annual Conference\
    \ of the IEEE Industrial Electronics\nSociety, Singapore, 18–21 October 2020; IEEE: Singapore, 2020; pp. 3823–3830. doi:10.1109/IECON43393.2020.9254296\n\
    78.\n Liu, F.; Tang, G. M.; Li, Y.; et al. A survey on edge computing systems and tools. Proc.\
    \ IEEE, 2019, 107: 1537−1562.\n79.\n Sarker, V.K. ; Queralta, J.P.; Gia, T.N.; et\
    \ al. A survey on LoRa for IoT: Integrating edge computing. In: 2019 Fourth International\n\
    Conference  on  Fog  and  Mobile  Edge  Computing  (FMEC),  Rome,  Italy,  10\
    \ –13  June  2019;  IEEE:  Rome,  2019;  pp.  295 –300.\ndoi:10.1109/FMEC.2019.8795313\n\
    80.\n Yu, W.; Liang, F.; He, X. F.; et al. A survey on the edge computing for the internet of things. IEEE\
    \ Access, 2018, 6: 6900−6919.\n81.\n Drăgulinescu, A.M.C.; Manea, A.F.; Fratu, O.; et\
    \ al. LoRa-based medical IoT system architecture and testbed. Wireless Pers Com-\n\
    mun, 2022, 126: 25−47.\n82.\n Gia, T.N.; Qingqing, L.; Queralta, J.P.; et al. Edge AI in smart farming IoT: CNNs at the edge and fog computing with LoRa. In\n\
    2019 IEEE AFRICON, Accra, Ghana, 25–27 September 2019; IEEE: Accra, 2019; pp. 1–6. doi:10.1109/AFRICON46755.2019.\n\
    9134049\n83.\n Hou, L.; Zheng, K.; Liu, Z. M.; et al. Design and prototype implementation of a blockchain-enabled LoRa system with edge comput-\n\
    ing. IEEE Internet Things J., 2021, 8: 2419−2430.\n84.\n Kumari, P.; Mishra, R.; Gupta, H.P.; et\
    \ al. An energy efficient smart metering system using edge computing in LoRa network. IEEE\n\
    Trans. Sustainable Comput. 2021, in press. doi:10.1109/TSUSC.2021.3049705\n85.\n\
     Queralta, J.P.; Gia, T.N.; Tenhunen, H.; et al. Edge-AI in LoRa-based health monitoring: Fall detection system with fog computing\n\
    and LSTM recurrent neural networks. In 2019 42nd International Conference on Telecommunications\
    \ and Signal Processing (TSP),\nBudapest, Hungary, 01–03 July 2019; IEEE: Budapest, 2019; pp. 601–604. doi:10.1109/TSP.2019.8768883\n\
    86.\n Ferreira, C.M.S.; Oliveira, R.A.R.; Silva, J.S. Low-energy smart cities network with LoRa and Bluetooth. In 2019\
    \ 7th IEEE Interna-\ntional Conference on Mobile Cloud Computing, Services, and\
    \ Engineering (MobileCloud), Newark, CA, USA, 04–09 April 2019;\nIEEE: Newark, 2019; pp. 24–29. doi:10.1109/MobileCloud.2019.00011\n\
    87.\n Barro, P.A.; Zennaro, M.; Pietrosemoli, E. TLTN – The local things network: On the design of a LoRaWAN gateway with autonomous\n\
    servers  for  disconnected  communities.  In  2019  Wireless  Days  (WD),  Manchester, \
    \ UK,  24 –26  April  2019;  IEEE:  Manchester,\n2019; pp. 1–4. doi:10.1109/WD.2019.8734239\n\
    88.\nIJNDI, 2022, 1(1): 4−19. https://doi.org/10.53941/ijndi0101002\n \n18\nCitation: Yao, F.; Ding, Y.; Hong, S.; et\
    \ al. A Survey on Evolved LoRa-Based Communication Technologies for Emerging Internet of\n\
    Things Applications. International Journal of Network Dynamics and Intelligence. https://doi.org/10.53941/ijndi0101002\n\
    Publisher’s Note: Scilight stays neutral with regard to jurisdictional claims in published maps and institutional affiliations.\n\
    Copyright: © 2022 by the authors. This is an open access article under the terms and conditions of the Creative Com-\n\
    mons Attribution (CC BY) license https://creativecommons.org/licenses/by/4.0/.\n\
    IJNDI, 2022, 1(1): 4−19. https://doi.org/10.53941/ijndi0101002\n \n19\n"
  inline_citation: '>'
  journal: International Journal of Network Dynamics and Intelligence
  limitations: '>'
  pdf_link: https://www.sciltp.com/journals/ijndi/article/download/112/52
  publication_year: 2022
  relevance_score1: 0
  relevance_score2: 0
  title: A Survey on Evolved LoRa-Based Communication Technologies for Emerging Internet
    of Things Applications
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.12731/2658-6649-2022-14-6-423-454
  analysis: '>'
  authors:
  - Gurjeet Singh
  - Naresh Kalra
  - Neetu Yadav
  - Ashwani Sharma
  - Manoj Saini
  citation_count: 16
  full_citation: '>'
  full_text: ">\n423\nSiberian Journal of Life Sciences and Agriculture, Том 14, №6,\
    \ 2022\nНАУЧНЫЕ ОБЗОРЫ И СООБЩЕНИЯ\n  \nSCIENTIFIC REVIEWS AND REPORTS\nDOI: 10.12731/2658-6649-2022-14-6-423-454\
    \ \nUDC 004:63\nSMART AGRICULTURE: A REVIEW\nGurjeet Singh, Naresh Kalra, Neetu\
    \ Yadav,                                                    \nAshwani Sharma,\
    \ Manoj Saini\nAgriculture is regarded as one of the most crucial sectors in guaranteeing\
    \ food \nsecurity. However, as the world’s population grows, so do agri-food demands,\
    \ \nnecessitating a shift from traditional agricultural practices to smart agriculture\
    \ \npractices, often known as agriculture 4.0. It is critical to recognize and\
    \ handle the \nproblems and challenges related with agriculture 4.0 in order to\
    \ fully profit from \nits promise. As a result, the goal of this research is to\
    \ contribute to the development \nof agriculture 4.0 by looking into the growing\
    \ trends of digital technologies in the \nfield of agriculture. A literature review\
    \ is done to examine the scientific literature \npertaining to crop farming published\
    \ in the previous decade for this goal. This \nthorough examination yielded significant\
    \ information on the existing state of digital \ntechnology in agriculture, as\
    \ well as potential future opportunities.\nKeywords: Smart Agriculture; Artificial\
    \ Intelligence; Machine Learning; IOT; \nEdge Computing; Fog Computing\nFor citation.\
    \ Gurjeet Singh, Naresh Kalra, Neetu Yadav, Ashwani Sharma, Manoj. \nSmart Agriculture:\
    \ A Review. Siberian Journal of Life Sciences and Agriculture, 2022, \nvol. 14,\
    \ no. 6, pp. 423-454. DOI: 10.12731/2658-6649-2022-14-6-423-454 \n1. Introduction\
    \ \n1.1. A worldwide dilemma of food security\nFood security is a multifaceted\
    \ notion that aims to eliminate hunger by \nassuring a steady supply of nutritious\
    \ food. It is defined by a four-pillar para-\ndigm, each of which is necessary\
    \ to provide food security [1]. Food security \nis becoming a severe global concern\
    \ as a result of anthropogenic factors such \nas rapid population expansion, urbanization,\
    \ industrialization, farmland loss, \nfreshwater scarcity, and environmental degradation.\
    \ This is due to the fact that \n424\nSiberian Journal of Life Sciences and Agriculture,\
    \ Vol. 14, №6, 2022\nthese factors have a direct impact on the agricultural industry,\
    \ which is the \nworld’s principal source of agri-food production. By 2050, it\
    \ is expected that \nthe global population will rise from 7.7 billion to 9.2 billion,\
    \ urban population \nwill rise by 66 percent, arable land will decline by approximately\
    \ 50 million \nhectares, global GHG emissions (source of CO 2 – promote crop disease\
    \ and \npest growth) will rise by 50 percent, agri-food production will decline\
    \ by 20%, \nand food demand will rise by 59 to 98 percent, posing an imminent\
    \ threat. To \nmeet rising food demands, agricultural practitioners around the\
    \ world will need \nto increase crop and livestock production to maximize agricultural\
    \ output. The \nemphasis of this review paper is crop farming, which includes\
    \ the production \nof both food and cash crops. \nA typical agri-food value chain\
    \ displaying three key stages in the production \nof agricultural products: pre-field\
    \ (pre-plantation stage), in-field (plantation and \nharvesting stage), and post-field\
    \ (post-harvesting stage). All of the stages are \nimportant in the value chain,\
    \ but in this examination, we will focus on the sec-\nond stage, in-field, which\
    \ includes numerous crop-growing operations such as \nploughing, sowing, spraying,\
    \ and harvesting, among others. Traditional agricul-\ntural approaches are now\
    \ used in these procedures, which are labor-intensive, \nrequire arable land,\
    \ time, and a significant quantity of water (for irrigation), and \nmake it difficult\
    \ to produce enough food [5]. A part of the problem is also due \nto the improper\
    \ application of pesticides and herbicides, as well as the misuse \nof available\
    \ technologies, both of which hurt crops and ultimately result in \nagricultural\
    \ waste [6]. These problems can be solved by combining advanced \ntechnologies\
    \ and computer-based applications that ensure higher crop yields, \nless water\
    \ use, better pesticide/herbicide use, and improved crop quality. This \nis where\
    \ the concept of smart agriculture comes into play.\n1.2. Smart Agriculture\n\
    Every industry is being revolutionized and reshaped by Industry 4.0. It’s a \n\
    strategic initiative that combines emerging disruptive digital technologies like\
    \ \nthe Internet of Things (IoT), big data and analytics (BDA), system integration\
    \ \n(SI), cloud computing (CC), simulation, autonomous robotic systems (ARS),\
    \ \naugmented reality (AR), artificial intelligence (AI), wireless sensor networks\
    \ \n(WSN), cyber-physical systems (CPS), digital twin (DT), and additive manu-\n\
    facturing (AM) to enable the digitization of the industry [7]. \nAgriculture 4.0,\
    \ also known as smart agriculture, smart farming or digital \nfarming [7], is\
    \ the next phase of industrial agriculture, fueled by the integra-\ntion of these\
    \ technologies in agriculture. Farmers can use smart agriculture to \naddress\
    \ a variety of agricultural food production concerns such as farm pro-\n425\n\
    Siberian Journal of Life Sciences and Agriculture, Том 14, №6, 2022\nductivity,\
    \ environmental impact, food security, crop losses, and sustainability. \nFarmers,\
    \ for example, can connect to farms remotely, regardless of location \nor time,\
    \ using IoT-enabled equipment based on WSNs to monitor and control \nfarm operations.\
    \ Drones outfitted with hyper spectral cameras can collect data \nfrom a variety\
    \ of sources on farmlands, while autonomous robots can assist \nor complete repetitive\
    \ chores on farms. Data analytics techniques can be used \nto examine the obtained\
    \ data, and computer programs can be utilized to help \nfarmers make decisions.\n\
    Similarly, smart agriculture can monitor and analyze a wide range of pa-\nrameters\
    \ related to environmental factors, weed control, crop production status, \nwater\
    \ management, soil conditions, irrigation scheduling, herbicides and pes-\nticides,\
    \ and controlled environment agriculture to increase crop yields, reduce \ncosts,\
    \ improve product quality, and maintain process inputs through the use of \nmodern\
    \ systems [8].\n1.3. Research Motivation and Contribution \nThe reason for writing\
    \ this assessment is that digital technologies in agri-\ncultural systems provide\
    \ new strategic solutions for increasing farm output ef-\nficiency and effectiveness.\
    \ Furthermore, digital transformation paves the door \nfor modern farming technologies\
    \ like vertical farming (hydroponics, aquapon-\nics, and aeroponics) to be used,\
    \ which has the potential to solve food security \nissues. However, there are\
    \ a number of issues and restrictions connected with \nthis change from a technological,\
    \ socioeconomic, and management perspective \nthat must be overcome in order to\
    \ fully realise the potential of agricultural 4.0 \n[9].A number of publications\
    \ [9–18] have examined developing trends in the \ndevelopment of agriculture 4.0\
    \ by offering concise information on essential \nuses, benefits, and research\
    \ problems of smart farming. These studies’ research \nfocuses on either explaining\
    \ more general technical aspects while focusing on \nonly one or a few digital\
    \ technologies, or improving agricultural supply chain \nperformance, or developing\
    \ an agriculture 4.0 definition, or achieving sustain-\nable agronomy through\
    \ precision agriculture, or proposing a smart farming \nframework. Nonetheless,\
    \ these studies do not include an explicit discussion of \nthe tools and techniques\
    \ utilized to construct various systems, as well as their \nmaturity level. There\
    \ are also few studies that look at the consequences of dig-\nital technology\
    \ in modern soilless farms including hydroponics, aquaponics, \nand aeroponics\
    \ (indoor/outdoor). As a result, in order to promote conversation \nin this field,\
    \ it is necessary to examine the emergence of agriculture 4.0 from \nmany angles.\
    \ This research seeks to provide a comprehensive overview of dig-\nital technologies\
    \ used in the second stage of the agricultural production value \n426\nSiberian\
    \ Journal of Life Sciences and Agriculture, Vol. 14, №6, 2022\nchain (in-field)\
    \ for various farm types as described in section 1.1. The study’s \nkey theoretical\
    \ contribution is the analysis and dissemination of the tools and \ntechniques\
    \ used, as well as the farm type, maturity level of produced systems, \nand potential\
    \ obstacles or inhibiting factors in agriculture 4.0 development. Re-\nsearchers\
    \ and agricultural practitioners will benefit from the review’s insights \nin\
    \ future study on agriculture 4.0. \n1.4. Paper organization \nThe following is\
    \ the structure of the paper after the introduction: \nSection 2 discusses the\
    \ methodology used to collect relevant literature; Sec-\ntion 3 then presents\
    \ the statistical results obtained after a general analysis of the \nselected\
    \ research studies; Section 4 then provides a detailed overview of the \ncore\
    \ technologies used in agricultural digitization; Section 5 then highlights the\
    \ \ntechnical and socio-economic roadblocks to digital integration in agriculture;\
    \ \nand finally, Section 6 outlines a discussion of the research questions.\n\
    2. Research Methodology \nA systematic literature review (SLR) is a technique\
    \ for organizing and iden-\ntifying research related to a specific topic [19].\
    \ SLR is used in this study to look \ninto the state of Industry 4.0 technologies\
    \ in the agricultural industry. Cases \nwhere the phrase ‘agricultural’ occurred\
    \ in the title, abstract, or keywords of \nan article with any of the ‘Industry\
    \ 4.0 technologies’ described in section 1.2 \nare specifically sought. A review\
    \ procedure is established prior to conducting \nthe SLR to ensure a transparent\
    \ and high-quality research process, which are \nthe features that distinguish\
    \ a systematic literature review [20]. By conducting \nthorough literature searches,\
    \ the review methodology also helps to reduce bias. \nThe creation of the research\
    \ questions, the defining of the search method, and \nthe specification of inclusion\
    \ and exclusion criteria are all part of this process. \nTo conduct SLR, this\
    \ paper uses a recommended reporting item for system-\natic reviews and meta-analysis\
    \ (PRISMA) approach. PRISMA is a minimum \ncollection of items based on evidence\
    \ that is used to guide the construction of \nsystematic literature reviews and\
    \ other meta-analyses [19].\n2.1. Review Protocol \nBefore doing the bibliographic\
    \ analysis, a review methodology is estab-\nlished to identify, analyze, and interpret\
    \ data that are relevant to the research \nfocus. To begin, research questions\
    \ are developed in order to provide insight \ninto the study of published studies\
    \ in the research area of interest from many \nperspectives. These are the questions\
    \ that must be addressed in the research. The \nsearch strategy is then created,\
    \ which aids in the identification of appropriate \n427\nSiberian Journal of Life\
    \ Sciences and Agriculture, Том 14, №6, 2022\nkeywords later in the search equation,\
    \ as well as the identification of relevant \ninformation sources, such as academic\
    \ databases and search engines that allow \naccess to vast amounts of digital\
    \ documentation. Science Direct, Scopus, and \nIEEE Xplore are three online research\
    \ archives that are utilized to find relevant \nstudies. Finally, boundaries are\
    \ created by predefining inclusion and exclusion \ncriteria for further inquiry\
    \ and content assessments of selected articles in order \nto narrow the search\
    \ results of each database.\n2.2. Evaluation Process \nIdentification, screening,\
    \ eligibility, and inclusion are the four stages of the \nliterature search process\
    \ that are evaluated. Consolidation is done for the re-\nmoval of duplicate items\
    \ in the identification step after initial metadata filtering \nby the use of\
    \ search expressions. After this phase, the number of publications is \nreduced.\
    \ The titles and abstracts of the papers are reviewed during the screening \n\
    stage, and the most relevant publications are chosen for integral reading. In\
    \ the \nthird stage, full-text screening of these papers is done to ensure that\
    \ they are \neligible for this paper’s goal.\n2.3. Threats to Validity \n(i) SLR\
    \ replication: Because the current search is confined to only three on-\nline\
    \ repositories, the provided SLR is vulnerable to risks to validity. \nAdditional\
    \ sources could potentially lead to the discovery of more pub-\nlications. Validity\
    \ can be regarded satisfactorily addressed because the SLR \nprocess is clearly\
    \ defined in sub-sections 2.1 and 2.2. However, it is possible \nthat slightly\
    \ different publications will be found if this SLR is replicated. This \nvariation\
    \ could be due to various personal choices made throughout the PRIS-\nMA screening\
    \ and eligibility phases, but it’s highly improbable that the overall \nresults\
    \ would alter.\n(ii)The search string used to discover the relevant papers covers\
    \ the entire \nspectrum of SLR; however it’s possible that some important studies\
    \ were over-\nlooked. More research may be found if more keywords and synonyms\
    \ in the \nsearch are included.\n3. Digitization Trends in Agriculture \nAlthough\
    \ the agriculture business is making significant progress in terms \nof digital\
    \ technology adoption, it is still lagging behind other industries such \nas healthcare,\
    \ manufacturing, mining, automotive, energy, and others [15]. The \ncrop farming\
    \ method considered while designing an application or framework \nis referred\
    \ to as the farm type. The farming method, for example, can be soil-\nbased or\
    \ soilless. Open-air fields (conventional outdoor agricultural farms) and \n428\n\
    Siberian Journal of Life Sciences and Agriculture, Vol. 14, №6, 2022\ngreenhouse\
    \ farms are included in the soil-based farming category (indoor). The \nsoilless\
    \ farming category, on the other hand, includes modern farming tech-\nniques such\
    \ as aquaponics, aeroponics, and hydroponics (mostly indoor). In \nthe recent\
    \ decade, autonomous robotics systems (including unmanned guided \nvehicles and\
    \ unmanned aerial vehicles (drones)), the internet of things, and \nmachine learning\
    \ appear to be the most commonly used technology in agricul-\nture. Agriculture’s\
    \ growing sectors include big data, wireless sensor networks, \ncyber-physical\
    \ systems, and digital twins. Furthermore, in contrast to indoor \nfarms, open\
    \ air farms are the most usually examined in research investigations. \nFew publications\
    \ exist for soilless farming systems (aquaponics, aeroponics, \nand hydroponics),\
    \ implying that these modern farming practices are still in \ntheir infancy. Similarly,\
    \ each use case’s services are identified and classified \ninto nine service categories:\
    \ I crop management, CM (estimation/harvesting \nperiod and seed plantation/prediction\
    \ of crop yield/ growth rate/harvesting/ \npollination/ spraying (fertilizer/\
    \ pesticide)); ii) crop quality management, CQM \n(fresh weight, green biomass,\
    \ height, length, width, leaf density, piment content \n(chlorophyll), and phytochemical\
    \ composition); iii) water and environmental \nmanagement, WEM (monitoring and\
    \ control of flow rate, water level, water \nquality (nutrients), temperature,\
    \ humidity, CO2, and weather forecasts, among \nother things); iv) irrigation\
    \ management, IM (water stress detection and sched-\nuling); v) farm management,\
    \ FM (monitoring of farm operations, tracking and \ncounting products, determining\
    \ production efficiency, financial analysis, energy \nconsumption analysis, technology\
    \ integration, and decision-making);\nPDM (pest and disease management) is a term\
    \ used to describe the man-\nagement of pests and diseases (pest identification\
    \ and disease detection) SM \n(Soil Management) vii) (moisture content, soil nutrients,\
    \ fertilizer needs and \napplication) WUVM (weed/unknown vegetation mapping, classification,\
    \ and \npesticide application) viii) weed and unwanted vegetation management FDC\
    \ \n(fruit detection and counting), and ix) \nThe role of various digital technologies\
    \ in smart farming is depicted in \nthese categories. Crop management characteristics\
    \ such as crop yield prediction, \ngrowth rate estimation, and harvesting period\
    \ evaluation are the most 4.0 in the \nprevious decade, whereas soil management,\
    \ fruit identification and counting, \nand crop quality management receive very\
    \ less attention. The European Union’s \nTRL scale, which divides system maturity\
    \ into three generic categories [21], is \nused to assess the technology readiness\
    \ level (TRL) of all use cases. The first \nlevel is conceptual, which corresponds\
    \ to European TRL 1–2 (use case is in \nconcept phase), the second level is prototype,\
    \ which corresponds to Europe-\n429\nSiberian Journal of Life Sciences and Agriculture,\
    \ Том 14, №6, 2022\nan TRL 3–6 (use case is functional even without all planned\
    \ features), and the \nthird level is deployed, which corresponds to European\
    \ TRL 7–9. (Use case \nis mature with all the possible functions). Each use case’s\
    \ TRL was produced \nin a few experiments. It has been noticed that smart agricultural\
    \ systems have \nmade little progress from the concept and prototype stages to\
    \ the commercial \nstage. The majority of use cases, for example, are still in\
    \ the prototype stage.\n4. Agriculture 4.0 enabling technologies \n4.1. Internet\
    \ of Things driven agricultural systems \nThe Internet of Things (IoT) is a network\
    \ of interconnected computing de-\nvices, sensors, appliances, and machines that\
    \ are all connected to the internet \nand have their own unique identities and\
    \ capacities for remote sensing and \nmonitoring [21]. Network layer (communication),\
    \ perception layer (hardware \ndevices), , middleware layer (device management\
    \ and interoperability), service \nlayer (cloud computing), application layer\
    \ (data integration and analytics), and \nend-user layer are the six layers of\
    \ the IoT reference architecture (user-inter-\nface). IoT devices on the physical\
    \ layer in the agricultural domain collect data \non environmental and crop characteristics\
    \ such as temperature, humidity, pH \nvalue, water level, leaf colour, fresh leaf\
    \ weight, and so on. The network layer is \nresponsible for transmitting this\
    \ information, and its architecture is determined \nby the field size, farm location,\
    \ and type of farming method. ZigBee, LoRa, and \nSigfox, for example, are widely\
    \ utilized and employed in outdoor fields because \nthey are less expensive, have\
    \ low energy consumption, and have a long trans-\nmission range [22, 23]. Bluetooth,\
    \ despite being a secure technology, is only \nemployed in indoor farms due to\
    \ its limited transmission range [22]. Due to its \nhigh costs and high energy\
    \ consumption, Wi-Fi is not a promising technology \nfor agricultural applications\
    \ [22]. On the other hand, RFID (radio frequency \nidentification) and NFC (near\
    \ field communication) technologies are increas-\ningly being used in agricultural\
    \ systems for product tracking [24]. For periodic \nmonitoring of environmental\
    \ and soil characteristics, GPRS or mobile commu-\nnication technology (2G, 3G,\
    \ and 4G) is utilized. Furthermore, HTTP, WWW, \nand SMTP are the most commonly\
    \ utilized communication protocols in agri-\ncultural contexts. Similarly, middleware\
    \ HYDRA and SMEPP are commonly \nused in agricultural systems to enable interoperability\
    \ and system security for \ntheir context-aware functionalities [25]. \nCloud\
    \ computing approaches are used in the service layer to store data. \nThis information\
    \ is then used on the application layer to create smart apps that \nfarmers, agriculture\
    \ experts, and supply chain professionals can use to improve \n430\nSiberian Journal\
    \ of Life Sciences and Agriculture, Vol. 14, №6, 2022\nfarm monitoring and productivity.\
    \ The use of IoT in agriculture is intended to \nprovide farmers with decision-making\
    \ tools and automation technologies that \nallow them to seamlessly integrate\
    \ knowledge, products, and services in order to \nincrease production, quality,\
    \ and profit. A slew of research have been conduct-\ned and presented on the incubation\
    \ of IoT concepts in the agricultural industry. \nThe development of IoT-based\
    \ agricultural systems has addressed a variety of \ntechnological and architectural\
    \ concerns. However, most of these technologies \nare now in the conceptual stage\
    \ or in prototype form (not commercial). Farm \nmanagement, irrigation control,\
    \ crop development, health monitoring, and dis-\nease detection are all priorities.\
    \ \nSome of these studies also explained how IoT is being used in current ag-\n\
    ricultural systems like vertical farming (soilless farming - aquaponics, hydro-\n\
    ponics, and aeroponics) and greenhouse farming (soil-based). Furthermore, the\
    \ \nmajority of studies have been focused on a single issue.\n4.2. Wireless sensor\
    \ networks in agriculture \nA wireless sensor network (WSN) is a technology that\
    \ is utilized in an Inter-\nnet of Things (IoT) system. It is defined as a collection\
    \ of spatially distributed \nsensors for monitoring environmental physical conditions,\
    \ temporarily storing \nobtained data, and transferring the information to a central\
    \ point [22]. A wire-\nless sensor network (WSN) for smart farming is made up\
    \ of multiple sensor \nnodes connected by a wireless connection module. These\
    \ nodes have a variety \nof skills that allow them to self-organize, self-configure,\
    \ and self-diagnose (for \nexample, processing, trans- mission, and feeling).\
    \ There are various varieties of \nWSNs, which are classified based on the environment\
    \ in which they are used. \nTWSNs (terrestrial wireless sensor networks), WUSNs\
    \ (wireless underground \nsensor networks), UWSNs (underwater wireless sensor\
    \ networks), WMSNs \n(wireless multimedia sensor networks), and MWSNs (mobile\
    \ wireless sensor \nnetworks) are a few examples [26]. TWSN and UWSN are commonly\
    \ utilized \nin agricultural applications. TWSN nodes are sensors that collect\
    \ data from \nthe environment and are located above ground. The second type of\
    \ WSN is \nWUSNs, which are WSNs with sensor nodes embedded in the soil. Lower\
    \ fre-\nquencies easily enter the soil in this environment, whereas higher frequencies\
    \ \nare severely attenuated [27]. Because of the limited communication radius,\
    \ the \nnetwork requires a larger number of nodes to cover a big area. Many research\
    \ \npublications on the use of WSN for various outdoor and indoor farm applica-\n\
    tions, such as irrigation management, water quality testing, and environmental\
    \ \nmonitoring, are accessible in the literature. The goal of these experiments\
    \ was \nto create WSN architectures that were simple, low-cost, energy-efficient,\
    \ and \n431\nSiberian Journal of Life Sciences and Agriculture, Том 14, №6, 2022\n\
    scalable. However, several aspects of WSNs, such as minimum maintenance, \nrobust\
    \ and fault-tolerant architecture, and interoperability, require more study. \n\
    4.3. Cloud computing in agriculture \nCloud computing (CC) is defined as a model\
    \ for enabling convenient, ubiq-\nuitous, on-demand network access to a shared\
    \ pool of configurable computing \nresources (e.g., networks, servers, storage,\
    \ applications, and services) that can \nbe rapidly provisioned and released with\
    \ minimal management effort or ser-\nvice provider interaction, according to the\
    \ National Institute of Standards and \nTechnologies (NIST) [28]. The datacenter\
    \ (hardware), infrastructure, platform, \nand application layers make up the primary\
    \ architecture of CC [29]. Each of \nthese layers corresponds to one of three\
    \ cloud service models: SaaS (software \nas a service), PaaS (platform as a service),\
    \ and IaaS (infrastructure as a service) \n(IaaS). In the agriculture sector,\
    \ cloud computing has gotten a lot of attention in \nthe last decade because it\
    \ provides: 1) low-cost storage for data collected from \nvarious domains via\
    \ WSNs and other preconfigured IoT devices, 2) large-scale \ncomputer systems\
    \ to make intelligent decisions by converting raw data into \nusable knowledge,\
    \ and 3) a secure platform for developing agricultural based \nIoT applications\
    \ [30]. \nCC is used to develop various agricultural applications in conjunction\
    \ with \nIoT and WSN. CC technology is also utilized to develop operational farm\
    \ man-\nagement systems (FMSs) that help farmers and farm managers monitor farm\
    \ \nactivities more efficiently. The traceability of agri-product quality is another\
    \ \narea of interest that is being investigated in global research [31]. However,\
    \ only \npreliminary research has been done to see if traceability complies with\
    \ food \nsafety and quality criteria. The usage of cloud-based agricultural systems\
    \ has \nthe potential to address issues such as rising food demand, pollution\
    \ from pes-\nticides and fertilizers, and the safety of agricultural products.\
    \ These FMSs, on \nthe other hand, lack the flexibility to offer run-time customization\
    \ in response \nto specific farmer needs. Furthermore, because most farm data\
    \ is fragmented \nand distributed, recording farm operations accurately in existing\
    \ FMSs systems \nis problematic [32].\n4.4. Edge/fog computing in agriculture\
    \ \nThe rapid expansion of IoT has resulted in an explosion of sensors and smart\
    \ \ndevices, creating massive amounts of data. The processing and analysis of\
    \ such a \nlarge volume of data in real time is difficult since it puts a strain\
    \ on the cloud serv-\ner and slows response times. When dealing with such a massive\
    \ data set, a cloud \nserver alone will not be able to offer real-time responses.\
    \ Furthermore, because \nIoT applications require a constant exchange of information\
    \ between devices and \n432\nSiberian Journal of Life Sciences and Agriculture,\
    \ Vol. 14, №6, 2022\nthe cloud, they are susceptible to network latency, making\
    \ CC unsuitable for these \napplications [23]. The introduction of the edge computing\
    \ idea has the potential \nto overcome the CC issues. This novel computing architecture\
    \ places computa-\ntional and storage resources (such as cloudlets or fog nodes)\
    \ closer to data sources \nlike mobile devices and sensors at the network’s edge.\
    \ This allows for real-time \nanalytics while maintaining data security on the\
    \ device [23]. Although edge com-\nputing has exciting potential for smart agriculture,\
    \ its applications in agricultural \nsystems are still in their infancy. As a\
    \ result, there are limited research studies in \nthis field. The majority of\
    \ the edge computing-based agricultural systems covered \nin these papers are\
    \ prototypes that solve a small number of challenges across a \nvariety of agricultural\
    \ disciplines. Interoperability and scalability issues haven’t \ngotten enough\
    \ attention so yet. Agricultural robots combine emerging technolo-\ngies such\
    \ as computer vision; wireless sensor networks (WSNs), satellite navi-\ngation\
    \ systems (GPS), artificial intelligence (AI), cloud computing (CC), and the \n\
    Internet of Things (IoT) to help farmers improve productivity and quality of ag-\n\
    ricultural products. AARS in smart farming can be mobile or fixed [33]. Mobile\
    \ \nAARS can move around the working field. Unmanned ground vehicles (UGVs) \n\
    and unidentified aerial vehicles (UAVs) are the two types of mobile AARSs, as\
    \ \ndiscussed in the following sections. \n4.5.1. Unmanned ground vehicles in\
    \ agriculture\nUnmanned ground vehicles (UGVs) are agricultural robots that work\
    \ with-\nout the use of a human operator on the ground. A platform for locomotive\
    \ ap-\nparatus and manipulator, navigation sensors, a supervisory control system,\
    \ an \ninterface for the control system, communication links for information exchange\
    \ \nbetween devices, and system architecture for integration between hardware\
    \ and \nsoftware agents are the main components of UGVs [34]. The control architec-\n\
    ture of a UGV can be remote-operated (controlled via an interface by a human \n\
    operator) or totally autonomous (operated without the use of a human control-\n\
    ler using artificial intelligence technology) [34]. Locomotive systems, likewise,\
    \ \ncan be based on wheels, tracks, or legs [34]. Legged robots are uncommon in\
    \ \nagriculture, despite their great terrain flexibility, inherent Omni directionality,\
    \ \nand soil protection. These robots, however, offer a disruptive locomotion\
    \ mech-\nanism for smart farms when paired with wheels (wheel-legged robots).\
    \ UGVs \nshould meet specific requirements, such as small size, maneuverability,\
    \ resil-\nience, efficiency, human-friendly interface, and safety, in addition\
    \ to the nec-\nessary features for infield operations, in order to improve crop\
    \ yields and farm \nproductivity. A 4WD locomotive system is used in the majority\
    \ of agricultural \nrobotic systems due to its ease of manufacture and control.\
    \ \n433\nSiberian Journal of Life Sciences and Agriculture, Том 14, №6, 2022\n\
    The disadvantage of 4WD is that terrains with stone elements and/or voids \nhave\
    \ a significant impact on the wheels [34]. As a result, other mechanisms, \nsuch\
    \ as legged or wheel-legged locomotive systems, should be investigated. \nAlthough\
    \ some robots include computer vision systems, most of these robots \nare designed\
    \ with a low-cost computer vision system, such as traditional RGB \ncameras, due\
    \ to the difficulties of establishing an accurate and dependable sys-\ntem that\
    \ can replace manual labour. Furthermore, the majority of the systems \nmentioned\
    \ above are still in the research phase, with no large-scale commer-\ncial application.\n\
    4.5.2. Unmanned aerial vehicles in agriculture \nUnmanned aerial vehicles (UAVs),\
    \ sometimes known as aerial robots, are \nplanes that do not have a human pilot\
    \ on board. There are many different types \nof UAVs [35] depending on the technology\
    \ used to fly (wing structure) and the \nlevel of autonomy. Fixed-wing (planes),\
    \ single-rotor (helicopter), hybrid system \n(vertical takeoff and landing), and\
    \ multi-rotor UAVs are examples of wing types \n(drone). Drones (multi-rotor technology),\
    \ which are raised and driven by four \n(quad-rotor) or six (hex-rotor) rotors,\
    \ have grown in popularity in the agricul-\nture sector because to their mechanical\
    \ simplicity in comparison to helicopters, \nwhich rely on a much more complex\
    \ plate control mechanism [36]. Similarly, \nUAVs can be tele-operated or tele-commanded,\
    \ depending on their autonomy \nlevel, with the pilot providing references to\
    \ each actuator of the aircraft to con-\ntrol it in the same way that an onboard\
    \ pilot would, or tele-commanded with the \naircraft relying on an automatic controller\
    \ on board to maintain a stable flight \n[35]. Agricultural UAVs with the right\
    \ sensors (vision, infrared, multispectral, \nand hyper spectral cameras, for\
    \ example) can collect data (vegetation, leaf area, \nand reflectance indexes)\
    \ from their fields to monitor dynamic changes in crops \nthat aren’t visible\
    \ from the ground [37]. Farmers can deduce information about \ncrop illnesses,\
    \ nutrient deficits, water level, and other agricultural growth char-\nacteristics\
    \ using this data. Farmers might plan possible cures using this knowl-\nedge (irrigation,\
    \ fertilization, weed control, etc.). \nThe majority of the systems mentioned\
    \ above are still in the research stage, \nwith no large-scale commercial use.\
    \ Other issues with these UAVs include bat-\ntery life and flight time [35]. Lithium-ion\
    \ batteries are currently in use because \ntheir capacity exceeds that of conventional\
    \ batteries. \nHowever, increasing the battery capacity increases the weight of\
    \ the drone, \nand research is currently underway to overcome this issue. \nFurthermore,\
    \ existing UAVs have complicated user interfaces that can only \nbe used by experts\
    \ to accomplish agricultural chores. People who are elderly \n434\nSiberian Journal\
    \ of Life Sciences and Agriculture, Vol. 14, №6, 2022\nor unfamiliar with UAV\
    \ technology will be able to control it more readily if \nthe user interface is\
    \ improved and made more human-centered with multimod-\nal feedback. \n4.6. Big\
    \ data and analytics in agriculture \nRapid advancements in IoT and CC technologies\
    \ have massively expanded \nthe amount of data available. Textual content (structured,\
    \ semi-structured, and un-\nstructured) and multimedia content (e.g., videos,\
    \ photos, and audio) are included \nin this data, also known as Big Data (BD)\
    \ [38]. Big data analytics is the practice \nof analyzing large amounts of data\
    \ to find hidden patterns, unknown relationships, \nmarket trends, client preferences,\
    \ and other important information (BDA). Big \ndata is usually classified into\
    \ five dimensions, each of which is represented by a V. \nThe concept of BD-driven\
    \ smart agriculture is very new, but its trend is \ngood because it has the potential\
    \ to make a dramatic change in the food supply \nchain and boost food security\
    \ through higher productivity. Agricultural big data \nis typically generated\
    \ from a variety of sources in agriculture, including ground \nsensors, aerial\
    \ vehicles, and ground vehicles equipped with special cameras and \nsensors; governmental\
    \ bodies in the form of reports and regulations; private \norganizations through\
    \ online web services; farmers in the form of knowledge \ngained through surveys;\
    \ and social media [39]. Depending on the agricultural \ndomain, the data can\
    \ be environmental (weather, climate, moisture level, etc.), \nbiological (plant\
    \ disease), or geospatial, and it comes in a variety of volumes, \nspeeds, and\
    \ formats [40]. The information is acquired and stored in a computer \ndatabase,\
    \ where it is analyzed using computer algorithms for seed characteris-\ntics,\
    \ weather patterns, soil attributes (such as pH or nutrient content), marketing\
    \ \nand trade management, consumer behaviour, and inventory management. In \n\
    agriculture, a range of strategies and tools are used to examine large data. The\
    \ \nmost often employed techniques include machine learning, cloud-based plat-\n\
    forms, and modelling and simulation. Machine learning technologies are used \n\
    to solve problems like prediction, clustering, and classification, while cloud\
    \ \nplatforms are utilized for large-scale data storage, preprocessing, and visual-\n\
    ization. There are still numerous potential areas where BDA can be used to \n\
    address various agricultural concerns that are not well covered in existing lit-\n\
    erature. For example, data-intensive greenhouses and indoor vertical farming \n\
    systems, quality control and health monitoring of crops in outdoor and indoor\
    \ \nfarms, genetic engineering, decision support platforms to help farmers design\
    \ \nindoor vertical farms, and scientific models for policymakers to help them\
    \ make \ndecisions about the physical ecosystem’s sustainability. Finally, the\
    \ majority of \nsystems are still in the prototype stage.\n435\nSiberian Journal\
    \ of Life Sciences and Agriculture, Том 14, №6, 2022\n4.7. Artificial intelligence\
    \ in agriculture \nArtificial intelligence (AI) is the study of theories and computer\
    \ systems that \ncan perform activities that need human intelligence, such as\
    \ sensory percep-\ntion and decision-making [41]. AI, particularly in the areas\
    \ of machine learning \n(ML) and deep learning (DL), is seen as one of the primary\
    \ forces driving the \ndigitization of agriculture when combined with CC, IoT,\
    \ and big data. These \ntechnologies have the potential to increase crop production,\
    \ harvesting, pro-\ncessing, and marketing in real time [42]. ML and DL algorithms\
    \ are being used \nto determine various parameters such as weed detection, yield\
    \ prediction, and \ndisease identification in a number of intelligent agricultural\
    \ systems. The fol-\nlowing two sub-sections go through these systems.\n4.7.1.\
    \ Machine learning in agriculture \nsupervised learning (linear regression, regression\
    \ trees, non-linear regres-\nsion, Bayesian linear regression, polynomial regression,\
    \ and support vector \nregression), and unsupervised learning (hierarchal clustering,\
    \ k-means cluster-\ning, neural networks (NN) anomaly detection, principal component\
    \ analysis, \nindependent component analysis, a-priori algorithm, and singular\
    \ value decom-\nposition (SVD)). Weed detection, Crop yield prediction, disease\
    \ and weather \nprediction (rainfall), soil properties estimation ( moisture content,\
    \ type, pH, \ntemperature, etc.), water management, fertilizer amount determination,\
    \ and \nlivestock production and management all use machine learning techniques\
    \ and \nalgorithms [2, 43]. According to the study of these publications, “crop\
    \ yield \nprediction” is an extensively researched area, with the most widely\
    \ utilized ML \napproaches to allow smart farming being linear regression [4],\
    \ neural network \n(NN), random forest (RF), and support vector machine (SVM)\
    \ [2]. \nThe presented use cases are still in the research phase, and no commercial\
    \ \nuse has been recorded as of yet. Furthermore, AI and machine learning ap-\n\
    proaches are found to be underutilized in greenhouse and indoor vertical farm-\n\
    ing systems, particularly hydroponics, aquaponics, and aeroponics. There are \n\
    only a handful publications that use machine learning techniques. To enable \n\
    digital farming, new methodologies such as federated learning and privacy \npreserving\
    \ methods are being developed in light of the digital transformation’s \ncyber-security\
    \ and data privacy problems [44]. These methods create machine \nlearning models\
    \ from local parameters rather than sharing private data samples, \nreducing security\
    \ concerns.\n4.7.2. Deep learning in agriculture \nDeep learning (DL) is an extension\
    \ of classical machine learning (ML) \nbecause extra “depth” (complexity) is added\
    \ to the model, it can accomplish \n436\nSiberian Journal of Life Sciences and\
    \ Agriculture, Vol. 14, №6, 2022\ndifficult tasks (predictions and classification)\
    \ extraordinarily well and quick-\nly. DL’s main benefit is feature learning,\
    \ which includes extracting features \n(high-level information) from big datasets\
    \ automatically [45]. Long short term \nmemory (LSTM) networks, convolutional\
    \ neural networks (CNNs), recurrent \nneural (RNN) networks, generative adversarial\
    \ networks (GANs), radial basis \nfunction networks (RBFNs), multilayer perceptron\
    \ (MLPs), feed-forward ar-\ntificial neural network (ANN), self-organizing maps\
    \ (SOMs), deep belief net-\nworks (DBNs), restricted Boltzmann machines (RBMs),\
    \ and autoencoders are \nexamples of deep learning algorithms Various sites [46]\
    \ provide a full overview \nof these methods, popular architectures, and training\
    \ systems. DL algorithms \nare commonly used in agriculture to solve problems\
    \ related to computer vision \napplications that aim to predict key parameters\
    \ such as crop yields, soil mois-\nture content, weather conditions, and crop\
    \ growth conditions; detect diseases, \npests, and weeds; and identify leaf or\
    \ plant species [47]. Computer vision is an \ninterdisciplinary field that has\
    \ exploded in popularity in recent years thanks to \nthe rise of CNNs. It provides\
    \ methods and techniques for accurately process-\ning digital images and allowing\
    \ computers to analyze and comprehend the vi-\nsual world [48]. CNNs, generally\
    \ is known as Convet and its derivatives, are \nthe most widely used deep learning\
    \ algorithms in agricultural applications. \nRegion-based CNNs (RCNN), Fast-RCNN,\
    \ Faster-RCNN, YOLO, and Mask-\nRCNN are some of the CNN variants, with the first\
    \ four being the most typi-\ncally used to address object detection issues. On\
    \ the other side, Mask-RCNN \nis utilized to overcome instance segmentation issues.\
    \ The reader can find a \nthorough explanation of these algorithms and their applications\
    \ in the exist-\ning bibliography [47]. Other DL approaches have been employed\
    \ in a few re-\nsearch. When it comes to datasets, the majority of deep learning\
    \ models are \ntrained on photographs, with only a few trained on sensor data\
    \ collected in the \nfield. This demonstrates that DL can be used on a wide range\
    \ of datasets. It’s \nalso worth noting that the majority of the research is focused\
    \ on outdoor farms, \nwith next-generation farms (environment-controlled) receiving\
    \ less attention. \nThough digital farming has the potential to be enabled by\
    \ DL, most systems \nare still in the prototype stage. Furthermore, the additional\
    \ obstacles created \nby cyber-security and privacy concerns necessitate the improvement\
    \ of current \ndeep learning and computer vision technologies.\n4.8. Agricultural\
    \ decision support systems \nA decision support system (DSS) is a smart system\
    \ that assists stakehold-\ners and potential users in making decisions in response\
    \ to specific needs and \nchallenges by offering operational responses based on\
    \ meaningful informa-\n437\nSiberian Journal of Life Sciences and Agriculture,\
    \ Том 14, №6, 2022\ntion retrieved from raw data, documents, personal knowledge,\
    \ and/or models \n[49]. Data-driven, model-driven, communication-driven, document-driven,\
    \ and \nknowledge-driven DSS are all possibilities. The following source [50]\
    \ lists the \nkey features of these DSSs. The volume of farming data has exploded\
    \ as a re-\nsult of the advent of agriculture 4.0. Platforms like agricultural\
    \ decision support \nsystems (ADSS) are necessary to convert this heterogeneous\
    \ data into practical \nknowledge in order to make evidence-based and precise\
    \ judgments about farm \nmanagement and facility layout [51]. ADSSs have gotten\
    \ a lot of interest in the \nagriculture industry over the last few years. A variety\
    \ of agricultural concerns, \nsuch as farm management, water management, and environmental\
    \ management, \nhave been addressed by a number of ADSSs. Most ADSSs have been\
    \ found \nto ignore expert knowledge, which is extremely useful since it enables\
    \ for the \nconstruction of systems that are tailored to the demands of the users.\
    \ Complex \nGUIs, insufficient re-planning components, a lack of prediction and\
    \ forecasting \nabilities, and a lack of ability to adjust to unpredictable and\
    \ dynamic elements \nare some of the other identified faults with some of these\
    \ ADDSs. It’s also worth \nnoting that all of the ADSSs are for outside agriculture\
    \ systems and are still in \ndevelopment. In comparison, the use of ADSS in indoor\
    \ soilless agriculture is \ncurrently underutilized.\n4.9. Agricultural cyber-physical\
    \ systems \nA cyber-physical system (CPS) is an automated distributed system that\
    \ inte-\ngrates physical processes with communication networks and computing infra-\n\
    structures [52], and it is one of the key technologies of Industry 4.0. There\
    \ are \nthree standard CPS reference architecture models: 5C, RAMI 4.0, and IIRA,\
    \ \nwhich may be found in full at the following source [53]. Among these, the\
    \ 5C \nis a well-known and widely used reference model. CPS takes advantage of\
    \ a \nnumber of existing technologies, including agent systems, IoT, CC, augmented\
    \ \nreality, big data, and machine learning (ML) [54]. Scalability, flexibility,\
    \ au-\ntonomy, reliability, resilience, safety, and security are all improved\
    \ as a result \nof its adoption.\nOne of the most difficult domains that can benefit\
    \ from CPS technology is \nagriculture. Agricultural cyber-physical systems (ACPSs)\
    \ combine advanced \nelectronic technology with agricultural infrastructure to\
    \ create integrated farm \nmanagement systems that interact with the physical\
    \ environment to keep crops \ngrowing at their best [55]. ACPSs collect high-accuracy\
    \ data regarding climate, \nsoil, and crops and utilize it to manage watering,\
    \ humidity, and plant health, \namong other things. For the management of various\
    \ services, a range of ACPSs \nhave been created; however, most of these systems\
    \ are still in the prototype and \n438\nSiberian Journal of Life Sciences and\
    \ Agriculture, Vol. 14, №6, 2022\nconceptual stages. Furthermore, the majority\
    \ of studies are for outdoor farms, \nwith only a few publications published on\
    \ soil-based greenhouse systems. There \nhas been no research on indoor soilless\
    \ agricultural methods. Since of its pro-\nspective applications in a variety\
    \ of fields, ACPSs have sparked a lot of academ-\nic interest; nevertheless, deploying\
    \ CPS models in real-world applications is \nstill a difficulty because it requires\
    \ the right hardware and software [56]. When \ndesigning ACPSs, special emphasis\
    \ should be paid to autonomy, robustness, and \nresilience in order to deal with\
    \ the unpredictable nature of the environment and \nthe unknown characteristics\
    \ of agricultural facilities. ACPSs are influenced by \na variety of factors,\
    \ including humans, sensors, robots, crops, and data.. ACPSs \nmust be properly\
    \ and extensively developed to provide a seamless operation \nwhile avoiding conflicts,\
    \ errors, and disturbances.\n4.10. Digital twins in agriculture \nA digital twin\
    \ (DT) is a dynamic virtual replica of a real-life (physical) \nobject that mimics\
    \ its behaviours and states across multiple stages of the ob-\nject’s lifecycle\
    \ by combining real-world data, simulation, and machine learning \nmodels with\
    \ data analytics to enable understanding, learning, and reasoning \n[57]. The\
    \ physical and virtual entities, the physical and virtual environments, \nthe\
    \ metrology, and realization modules that perform the physical to virtual and\
    \ \nvirtual to physical connection or twinning, the twinning and twinning rate,\
    \ and \nthe physical and virtual processes are all required for a complete description\
    \ of \nthe DT concept for any physical system [58]. Because of advancements in\
    \ tech-\nnology such as the Internet of Things, big data, wireless sensor networks,\
    \ and \ncloud computing, the DT concept has gained traction. This is due to the\
    \ fact that \nthese technologies enable real-time monitoring of physical twins\
    \ at high spatial \nresolutions using both small devices and distant sensing,\
    \ which generate ev-\ner-increasing data streams [21]. In comparison to other\
    \ fields, the notion of DT \nin agricultural applications is relatively new, with\
    \ the first references appearing \nin 2017; as a result, its added value has not\
    \ yet been thoroughly studied [21]. \nBecause of its reliance on natural circumstances\
    \ (temperature, soil, humidity), \nas well as the presence of living and non-living\
    \ physical twins (plants and an-\nimals), framing is a very complex and dynamic\
    \ realm (indoor farm buildings, \ngrow beds, outdoor agricultural fields, agricultural\
    \ machinery). \nNon-living physical twins interact directly or indirectly with\
    \ plants and \nanimals (living physical twins), posing more obstacles for DT in\
    \ agriculture, \nwhereas non-living physical twins are the focus of DT in other\
    \ domains such \nas manufacturing. The majority of research has been on open-air\
    \ agricultur-\nal systems. There is just one study that proposes DT for a soil-based\
    \ vertical \n439\nSiberian Journal of Life Sciences and Agriculture, Том 14, №6,\
    \ 2022\nfarming system and one study that implements DT for a soilless vertical\
    \ farm-\ning system (aquaponics). This could be due to the difficulty of designing\
    \ and \nmanaging modern farming systems. Furthermore, the majority of DTs are\
    \ still \nin the research phase, with no commercial deployment planned. Cost savings,\
    \ \ndisaster prevention, clearer decision making, and efficient management oper-\n\
    ations are all reported benefits of DT applications in agriculture, which can\
    \ be \napplied to a variety of agricultural subfields such as plant and animal\
    \ breeding, \naquaponics, vertical farming, cropping systems, and livestock farming.\
    \ While \nDT technology offers a lot of promise, achieving synchronization between\
    \ the \nreal and digital worlds is difficult. Due to the quirks of living physical\
    \ twins, \nthe intricacy of this procedure is magnified in agricultural settings.\
    \ As a result, \nagricultural DT should begin with micro-farms, which can then\
    \ be gradually up-\ngraded to a more intelligent and autonomous form by adding\
    \ more components.\n4.11. Roadblocks in digitization of agriculture industry \n\
    This section outlines a series of interconnected hurdles to a wider adoption of\
    \ \ndigital technologies in agriculture. Following a review of the literature,\
    \ 21 barri-\ners were found, which were divided into technical and socioeconomic\
    \ categories.\n4.12. Technical roadblocks \n•Interoperability: Data is regarded\
    \ as a critical component in the success of \nsmart systems. Agricultural data\
    \ is typically gathered from a variety of sources, \nincluding thousands of individual\
    \ farmlands, animal industries, and business ap-\nplications. Data can be in a\
    \ variety of formats, making data integration difficult. \nAs a result, after\
    \ systematic data collection, storage, processing, and knowledge \nmining, data\
    \ interoperability is critical to increasing the value of this widely \ndistributed\
    \ data [59]. Interconnected and interoperable devices are also required \nfor\
    \ successful communication between heterogeneous devices. The system’s in-\nteroperability\
    \ can be improved through cross-technology communication [60].\n•Standardization:\
    \ Standardization of devices is required to fully use digital \ntechnologies for\
    \ smart farming applications. Differences in output can occur \nas a result of\
    \ misinterpretation and changes over time. Device, application, and \nsystem interoperability\
    \ concerns can also be overcome by standardization [25].\n•Data quality: Data\
    \ quality, as well as data security, storage, and openness, \nare essential for\
    \ producing meaningful outcomes. Another impediment to the \nadoption of smart\
    \ farming technologies is the lack of decentralized data man-\nagement systems\
    \ [9]. Multiple actors’ willingness to exchange farm data is be-\ning harmed as\
    \ a result of this problem.\n•Hardware implementation: It is incredibly difficult\
    \ to establish a smart agri-\ncultural setup in large-scale open areas. This is\
    \ due to the fact that all hardware, \n440\nSiberian Journal of Life Sciences\
    \ and Agriculture, Vol. 14, №6, 2022\nincluding IoT devices, wireless sensor networks,\
    \ sensor nodes, machinery, and \nequipment, is directly exposed to harsh environmental\
    \ conditions such as heavy \nrainfall, extreme temperatures, extreme humidity,\
    \ high wind speeds, and a vari-\nety of other dangers that can destroy electronic\
    \ circuits or disrupt their normal \nfunctionality [61]. A possible answer is\
    \ to construct a sturdy and lasting casing \nfor all of the expensive devices\
    \ that can withstand real-world conditions [62].\n•Adequate power sources: Typically,\
    \ wireless gadgets used on farms func-\ntion for an extended period of time and\
    \ have a limited battery life. \nBecause replacing a battery in the event of a\
    \ failure is difficult, especially in \nopen-air farms where devices are strategically\
    \ located with limited access [61], a \nproper energy-saving system is required.\
    \ Low-power sensors and proper commu-\nnication management are two viable strategies\
    \ for reducing energy consumption \n[24, 63]. Other intriguing technologies to\
    \ eliminate the need for battery renewal by \nrecharging batteries using electromagnetic\
    \ waves include wireless power transfer \nand self-supporting wireless systems.\
    \ In most agricultural applications, however, \nlong-distance wireless charging\
    \ is required [9]. Another potential alternative is to \ncapture ambient energy\
    \ from rivers, fluid flow, vehicle movement, and the ground \nsurface using sensor\
    \ nodes; however the converted electrical energy is current-\nly restricted, necessitating\
    \ the need to enhance power conversion efficiency [64].\n•Reliability: The dependability\
    \ of devices, as well as the software applica-\ntions that run on them, is critical.\
    \ This is due to the fact that IoT devices must \ncollect and transmit data from\
    \ which judgments are made utilizing a variety of \nsoftware packages. Unreliable\
    \ sensing, processing, and transmission can result \nin erroneous monitoring data\
    \ reports, significant delays, and even data loss, all \nof which can have a negative\
    \ impact on agricultural system performance [25].\n •Adaptability: Agriculture\
    \ is a complicated, dynamic, and continuously \nchanging environment. As a result,\
    \ when building a system, it is critical for de-\nvices and applications to react\
    \ proactively with other entities in the face of un-\nknown and dynamic elements\
    \ in order to provide the required performance [65].\n•Robust wireless architectures:\
    \ Low-cost, wide-area coverage, enough net-\nworking flexibility, and high scalability\
    \ are all advantages of wireless networks \nand communication technologies. However,\
    \ in a dynamic agriculture environ-\nment, such as temperature swings, the movement\
    \ of live objects, and the ex-\nistence of impediments, dependable wireless connection\
    \ is a major difficulty. \nFor example, multipath propagation effects cause signal\
    \ strength oscillations, \nresulting in unstable connectivity and insufficient\
    \ data transmission [66]. These \nelements have an impact on the agricultural\
    \ system’s performance. As a result, \nrobust and fault-tolerant wireless architectures\
    \ with proper sensor node place-\n441\nSiberian Journal of Life Sciences and Agriculture,\
    \ Том 14, №6, 2022\nment, antenna height, network topology, and communication\
    \ protocols are re-\nquired, as well as low-maintenance wireless systems [11].\n\
    •Interference: Because of the extensive deployment of IoT devices and wire-\n\
    less sensor networks, another difficulty is wireless interference and quality\
    \ of \nservice degradation. Effective channel scheduling between heterogeneous\
    \ sens-\ning devices, cognitive radio-assisted WSNs, and upcoming networking prim-\n\
    itives like concurrent transmission [67] can all help to solve these problems.\
    \ \nBecause agriculture equipment are dispersed in indoor greenhouses, outdoor\
    \ \nfarmlands, underground locations, and even aquatic areas, cross-media com-\n\
    munication between underground, underwater, and air is also necessary for full\
    \ \nintegration of smart technologies [68].\n•Security and privacy: Because smart\
    \ agricultural systems are dispersed, \nthey are vulnerable to cyber-attacks such\
    \ as eavesdropping, data integrity, de-\nnial-of-service assaults, and other sorts\
    \ of disruptions that could jeopardize the \nsystem’s privacy, integrity, and\
    \ availability [69]. With various privacy-preserv-\ning techniques and federated\
    \ learning approaches, cyber-security is a funda-\nmental concern that needs to\
    \ be addressed in the context of smart farming [44].\n•Compatibility: in order\
    \ to meet the fragmentation and scalability standards, \nthe models or software\
    \ applications developed must be adaptable and able to \nrun on any equipment\
    \ in the agricultural system [13]. \n•Resource optimization: To boost farm profitability,\
    \ farmers need a resource op-\ntimization procedure to determine the ideal number\
    \ of IoT devices and gateways, \ncloud storage size, and volume of transmitted\
    \ data. Resource optimization is diffi-\ncult since farms vary in size and require\
    \ different types of sensors to assess different \nvariables [70]. Second, most\
    \ farm management systems do not support run-time \nchanges to match the demands\
    \ of individual farmers. To estimate adequate resource \nallocation, complicated\
    \ mathematical models and algorithms are necessary [32].\n•Scalability: Due to\
    \ technological improvements, the number of gadgets, \ngear, and sensors put on\
    \ farms is continually expanding. \nGateways, network applications, and back-end\
    \ databases should all be de-\npendable and scalable in order to serve these entities\
    \ [71].\n•Human-centered user interfaces: Existing agricultural software and gadgets\
    \ \nhave complicated user interfaces, which are limiting smart farming methods.\
    \ \nThe majority of graphical user interfaces are constructed in such a way that\
    \ \nonly specialists can use them to accomplish agricultural activities. By making\
    \ \nthe user interface more human-centered and providing multimodal feedback,\
    \ a \nbigger group of individuals will be able to use it to complete various agricul-\n\
    tural tasks [35].\n442\nSiberian Journal of Life Sciences and Agriculture, Vol.\
    \ 14, №6, 2022\n4.13. Socio-economic roadblocks \n•Gap between farmers and researchers:\
    \ Farmers’ engagement is critical to \nthe success of the agriculture industry’s\
    \ digitization. Agricultural specialists are \nfrequently unaware of the concerns\
    \ that farmers encounter during the agri-food \nproduction process, which smart\
    \ technologies could solve [16]. Furthermore, it \nis critical to completely comprehend\
    \ the nature of problems in order to create \nan appropriate smart solution. \n\
    As a result, bridging the gap between farmers, agricultural professionals, \n\
    and AI researchers is critical.\n•Expenses connected with smart systems: the costs\
    \ associated with adopt-\ning smart technology and systems are a major impediment\
    \ to the agriculture \nsector’s digitization. These expenses typically include\
    \ deployment, operation, \nand maintenance. Smart system deployment costs are\
    \ typically significant since \nthey include: I hardware installation, such as\
    \ autonomous robots and drones, \nWSNs, gateways, and base station infrastructure,\
    \ and ii) paying trained labour \nto do particular agricultural tasks [72]. Similarly,\
    \ subscriptions to centralized \nnetworks and software packages are necessary\
    \ to support data processing, con-\ntrol of IoT devices and equipment, and knowledge\
    \ exchange, which eventually \nraises operating expenses [73]. Even if service\
    \ providers occasionally provide \nfree subscription packages with limited capabilities,\
    \ storage capacity is limited. \nPeriodic maintenance is essential to ensure the\
    \ proper operation of the smart \nsystem, which adds to the total costs.\nEnvironmental,\
    \ ethical, and societal costs may also be connected with the \nadoption of smart\
    \ devices. Initiatives focusing on cooperative farming are need-\ned to overcome\
    \ cost-related roadblocks by providing: I support services for \nbetter cost management\
    \ and needed investments, and ii) hardware solutions to \ntransform conventional\
    \ equipment into smart farm-ready machinery to reduce \nhigh initial costs [73].\n\
    •Digital division: a lack of awareness of digital technology and their appli-\n\
    cations is another problem limiting the digitalization of the agriculture sector.\
    \ \nThe majority of farmers have no understanding what digital technologies are,\
    \ \nhow to install and utilize them, or which technology is appropriate for their\
    \ farm \nand matches their needs [14]. As a result, farmers must be educated on\
    \ current \nfarming technologies and processes. \nFurthermore, various tactics\
    \ are required to develop tools that use natural \nlanguage and are easily understood\
    \ by farmers with low levels of education [74]. \n•Return on investment: In agriculture,\
    \ like in other industries, the profit \nmargin is critical. When it comes to\
    \ implementing modern technologies, farm-\n443\nSiberian Journal of Life Sciences\
    \ and Agriculture, Том 14, №6, 2022\ners are concerned about the time it will\
    \ take to recoup their investment and the \ndifficulty in assessing the benefits\
    \ [12].\n•Building faith in the effectiveness of smart technology in agriculture\
    \ is \ndifficult, unlike in other disciplines, because many decisions influence\
    \ systems \nthat involve both living and non-living elements, and the results\
    \ can be difficult \nto reverse [16]. In addition, the lack of verification of\
    \ the influence of digital \ntools on farm productivity exacerbates the current\
    \ difficulties.\n•Legal frameworks: different regions and nations have distinct\
    \ legal frame-\nworks that influence the deployment of digital technologies in\
    \ agriculture, par-\nticularly in monitoring and agri-food supply [31]. Similarly,\
    \ laws governing \nresource allocation (spectrum for wireless devices), data privacy,\
    \ and security \ndiffer from country to country [31].\n•Connectivity infrastructure:\
    \ In most developing nations, connectivity in-\nfrastructure is poor, limiting\
    \ access to advanced digital technologies that could \nhelp turn data from disparate\
    \ sources into useful and actionable insights [10].\n4.14. Discussion \nThe goal\
    \ of this study was to describe the new digital technologies that are \nbeing\
    \ used in the agricultural industry in order to predict the future trajectories\
    \ \nof agriculture 4.0. Big data and analytics, wireless sensor networks, cyber-phys-\n\
    ical systems, and digital twins are among the technologies that have yet to be\
    \ \nfully explored in agriculture. This disparity could be due to the fact that\
    \ install-\ning advanced technologies with more complex processes can be costly,\
    \ at least \nin the early stages of their acceptance. The agricultural industry’s\
    \ development \nof these technologies is expected to speed up in the next years.\
    \ The findings of \nSLR also reveal that IoT is widely used in farms. This is\
    \ owing to the IoT’s di-\nverse capabilities, which include monitoring, tracking,\
    \ and tracing, agricultural \nmachinery, and precision agriculture [21]. One of\
    \ the key research aims within \nthe farm 4.0 techniques can be regarded to be\
    \ IoT. Nonetheless, when building \nan intelligent agricultural system, only a\
    \ few researches have examined data \nsecurity and dependability, scalability,\
    \ and interoperability. The outcomes of \nthe study also revealed that the majority\
    \ of use cases are still in the prototype \nstage. The reason for this could be\
    \ that most agricultural activities involve live \nsubjects, such as animals and\
    \ plants, or perishable products, and establish-\ning systems for living subjects\
    \ is more difficult than developing systems for \nnon-living human-made systems.\
    \ Another explanation could be that, due to the \ntrans-disciplinary character\
    \ of agriculture, it is a late adopter of technology. As a \nresult, in order\
    \ to construct intelligent systems, the agricultural community must \nbecome conversant\
    \ with all digital technologies. Finally, differences in plant/\n444\nSiberian\
    \ Journal of Life Sciences and Agriculture, Vol. 14, №6, 2022\ncrop species and\
    \ growth conditions complicate agricultural system digitaliza-\ntion [55]. In\
    \ contrast to indoor farms, the majority of the technologies created \nby SLR\
    \ are for open-air soil-based farms (soilless and soil-based). This is owing \n\
    to the complicated design and maintenance of indoor farms, particularly soilless\
    \ \nfarms, where the parameters and elements to be maintained are numerous (pH,\
    \ \nair temperature, humidity, etc.) [5]. However, by incorporating digital technol-\n\
    ogy and data-driven computer applications into indoor farms, a more reliable \n\
    control of the process can be attained. Furthermore, SLR reveals that insufficient\
    \ \nresearch is undertaken in three of the nine service areas described in section\
    \ 3 \n(soil management, fruit detection and counting, and crop quality management).\
    \ \nThis supports the notion that significant research and development is required\
    \ \nin some areas to ensure the successful digitization of the agriculture business\
    \ \nin both developed and developing countries. The agriculture ecosystem’s com-\n\
    plexity creates a set of interrelated hurdles that prevent full integration of\
    \ digital \ntechnology for agriculture 4.0 implementation. As a result, identifying\
    \ possible \nbottlenecks is critical in order to devise strategic strategies to\
    \ overcome them. \nThis research aims to figure out what these stumbling barriers\
    \ are. Following \nthe investigation, 21 barriers were found and characterized\
    \ on both a technical \nand socioeconomic level. These impediments are addressed\
    \ in section 5, which \noutlines what needs to be done on a bigger scale to digitize\
    \ the agricultural \neconomy. However, it is still unknown how much removing or\
    \ mitigating these \nhurdles aids in the successful integration of digital technologies.\
    \ \n4.16. Added value of agricultural digitization \nSeveral benefits that can\
    \ inspire framers and other actors to assist agriculture \nindustry digitization\
    \ have been discovered and outlined based on analysis. The \nbenefits described\
    \ here have the potential to increase farm productivity and im-\nprove product\
    \ quality, but they should not be viewed as a cure for the problems \nthat come\
    \ with smart agriculture [73]. \n•Improved agility: Farm operations can now be\
    \ more agile thanks to digital \ntechnologies. Farmers and agricultural professionals\
    \ can quickly respond to \nany anticipated changes in environmental and water\
    \ conditions using real-time \nsurveillance and forecasting technologies to save\
    \ crops [72].\n•Green process: By lowering the use of in-field fuel, nitrogen\
    \ fertilizers, \npesticides, and herbicides, digital technologies make farming\
    \ more ecologically \nfriendly and climate-resilient [75].\n•Resource efficiency:\
    \ By increasing the quantity and quality of agricultural \noutput while reducing\
    \ the use of water, energy, fertilizers, and pesticides, digital \nplatforms can\
    \ improve resource efficiency [3]. \n445\nSiberian Journal of Life Sciences and\
    \ Agriculture, Том 14, №6, 2022\n•Time and cost savings: By automating various\
    \ tasks such as harvesting, sow-\ning, or irrigation, managing the application\
    \ of fertilizers or pesticides, and sched-\nuling irrigation, digital technologies\
    \ provide significant time and cost savings [76].\n•Asset management: digital\
    \ technologies enable real-time observation of \nfarm holdings and equipment,\
    \ allowing for theft prevention, component re-\nplacement, and routine maintenance\
    \ [10].\n•Product safety: By eliminating fraud [17, 18] linked to adulteration,\
    \ coun-\nterfeiting, and artificial enhancement, digital technologies maintain\
    \ appropriate \nfarm output and ensure a safe and nutritious supply of agri-food\
    \ products [69].\n4.17. Considerations and future prospects \nThe agricultural\
    \ industry would see major benefits as a result of the planned \nmeasures. However,\
    \ the impediments identified in section 5 must be solved first \nin order to make\
    \ things sustainable for small and medium-scale growers. Some \nof the above hurdles\
    \ can be mitigated by awareness campaigns emphasizing the \nimportance of smart\
    \ agriculture at every level of the agricultural value chain and \nencouraging\
    \ novel techniques (such as gamification) to encourage stakeholders \nto take\
    \ an active role in the digital transformation [9]. Initiatives at the federal\
    \ \nlevel, grants and endowments, public-private collaborations, data transparency,\
    \ \nand regional research efforts can all help overcome potential hurdles. Finally,\
    \ \nwhen constructing a smart agriculture system, a roadmap can be used, starting\
    \ \nwith a basic architecture with few components and simpler functionality and\
    \ \ngradually adding components and functionality to develop a sophisticated sys-\n\
    tem with full digitization potential [21]. These issues can pave the road for\
    \ ag-\nriculture 4.0’s successful adoption. The use of explainable artificial\
    \ intelligence \nto monitor crop development, estimate crop biomass, evaluate\
    \ crop health, and \ncontrol pests and diseases is one of the future prospects\
    \ of digital technologies \nin smart agriculture. Explainable AI eliminates the\
    \ old black-box approach of \nmachine learning and allows for a better understanding\
    \ of the reasoning behind \nany given decision [15]. The use of common semantics\
    \ and ontologies to de-\nscribe big data, as well as the adoption of open standards,\
    \ has the potential to \naccelerate research and development in the field of smart\
    \ farming. Similarly, \n5G technology must be thoroughly investigated in order\
    \ to enable improved \nconnectivity and live streaming of crop data [6]. By executing\
    \ precise crop in-\nspections remotely, 5G technology will reduce internet costs\
    \ and enhance the \nentire user experience of farm management and food safety\
    \ [77]. It would also \nhelp to close the gap between stakeholders by keeping\
    \ them informed about \ncrop availability. Finally, blockchain can be used in\
    \ conjunction with IoT and \nother technologies to address data privacy and security\
    \ concerns [78]. \n446\nSiberian Journal of Life Sciences and Agriculture, Vol.\
    \ 14, №6, 2022\n4.18. Transition to Agriculture 5.0 \nThe agriculture sector has\
    \ traditionally had a breakthrough during industri-\nal revolutions. Agriculture\
    \ 4.0 offers significant potential to offset rising food \ndemands and prepare\
    \ for the future by reinforcing agricultural systems with \nWSN, IoT, AI, and\
    \ other technologies, as formally mentioned in preceding \nsections. While agricultural\
    \ 4.0 is still being implemented, agriculture 5.0 is \nalready being discussed.\
    \ \nAgriculture 5.0 builds on agriculture 4.0 by incorporating industry 5.0 prin-\n\
    ciples to provide healthy, affordable food while also ensuring that the environ-\n\
    ments on which life depends are not degraded [79]. Industry 4.0 focuses less \n\
    on the original principles of social fairness and sustainability and more on dig-\n\
    italization and AI-driven technologies for increasing efficiency and flexibility,\
    \ \nthe European Commission formally called for the Fifth Industrial Revolution\
    \ \n(industry 5.0) in 2021 [80]. Industry 5.0 adds to and expands on the industry\
    \ 4.0 \nconcepts by emphasizing human-centricity, sustainability, and resiliency\
    \ [81]. \nIt entails improving human-machine collaboration, decreasing environmental\
    \ \neffect through the circular economy, and designing systems with a high degree\
    \ \nof robustness to reach an ideal balance of efficiency and productivity. Among\
    \ \nthe enabling technologies of industry are cobots (collaborative robots), smart\
    \ \nmaterials with embedded bio-inspired sensors, digital twins, AI, energy efficient\
    \ \nand secure data management, renewable energy sources, and others 5.0[80].\n\
    Farm production efficiency and crop quality can be improved in agriculture \n\
    5.0 settings by delegating repetitive and boring activities to machines and those\
    \ \nthat need critical thinking to humans. For this reason, agricultural cyber\
    \ physical \ncognitive systems (CPCS) that observe/study the environment and conduct\
    \ ap-\npropriate actions, comparable to those established for the manufacturing\
    \ sector, \nshould be developed. This might include collaborative farm robots\
    \ that work in \nthe fields to aid crop growers with time-consuming operations\
    \ like seed sowing \nand harvesting. Similarly, digital twins in agriculture 5.0\
    \ can add substantial value \nby recognizing technical difficulties in agricultural\
    \ systems and resolving them \nmore quickly, detecting crop illnesses, and producing\
    \ more accurate crop output \nestimates. This demonstrates that agriculture 5.0\
    \ has the potential to pave the way \nfor climate-smart, sustainable, and resilient\
    \ agriculture, but it is still in its infancy. \n5. Conclusions \nConcerns about\
    \ global food security have heightened the demand for \nnext-generation industrial\
    \ farms and agricultural intensive production systems. \nDigital technologies,\
    \ such as those given by the Industry 4.0 programme, are at \n447\nSiberian Journal\
    \ of Life Sciences and Agriculture, Том 14, №6, 2022\nthe vanguard of this modern\
    \ agricultural period, providing a wide range of in-\nnovative solutions. Disruptive\
    \ technologies are being integrated into traditional \nagriculture systems by\
    \ scientists and researchers in order to boost crop yields, \ncut costs, reduce\
    \ waste, and sustain process inputs. This report includes an SLR \nthat discusses\
    \ the current state of various technologies in the agriculture sector. \nSeveral\
    \ findings are drawn, including the fact that big data and analytics inte-\ngration,\
    \ wireless sensor networks, cyber-physical systems, and digital twins in \nagriculture\
    \ are still in their infancy, with the majority of use cases still in the \nprototype\
    \ stage. Similarly, 21 technological and socioeconomic impediments \nare found\
    \ and categorized. These impediments must be identified and addressed \nif the\
    \ agriculture industry is to be digitalized. The report also identifies and \n\
    presents the additional value of digital technology in the agriculture industry.\
    \ \nOverall, this research contributes to the ongoing research on agricultural\
    \ 4.0. \nThe review’s principal restriction is twofold: first, only three online\
    \ reposito-\nries (Scopus, IEEE, and Science Direct) are considered for literature\
    \ searches, \nand second, new keywords and synonyms may return more papers. The\
    \ main \nconclusions are highly unlikely to alter in either scenario. Additional\
    \ research \ndatabases and areas can be considered for future study in order to\
    \ provide a \ncomplete overview of the agriculture industry in terms of digitization.\
    \ In addi-\ntion, papers focusing on agriculture 5.0 in general will be featured.\n\
    References\n1. F Schierhorn, M. Elferink, Global Demand for Food Is Rising. Can\
    \ We Meet \nIt? Harv Bus Rev, 2016, 7 (2017). https://hbr.org/2016/04/global-demand-for-\n\
    food-is-rising-can-we-meet-it\n2. Singh, G. Machine Learning Models in Stock Market\
    \ Prediction. International \nJournal of Innovative Technology and Exploring Engineering,\
    \ 2022, vol. 11, \nno. 3, pp. 18-28. https://doi.org/10.35940/ijitee.C9733.0111322\n\
    3. WK Mok, YX Tan, WN. Chen, Technology innovations for food security in \nSingapore:\
    \ A case study of future food systems for an increasingly natural re-\nsource-scarce\
    \ world, Trends Food Sci Technol, 2020, vol. 102, pp. 155–168, \nhttps://doi.org/10.1016/j.tifs.2020.06.013\n\
    4. Nagar, P., & Issar, G. S. Detection of outliers in stock market using regression\
    \ \nanalysis. International Journal of Emerging Technologies in Computational\
    \ and \nApplied Science, 2013. https://doi.org/10.5281/zenodo.6047417\n5. R Abbasi,\
    \ P Martinez, R. Ahmad, An ontology model to represent aquapon-\nics 4.0 system’s\
    \ knowledge, Inf Process Agric, 2021. https://doi.org/10.1016/J.\nINPA.2021.12.001\n\
    448\nSiberian Journal of Life Sciences and Agriculture, Vol. 14, №6, 2022\n6.\
    \ R Abbasi, P Martinez, R. Ahmad, An ontology model to support the automat-\n\
    ed design of aquaponic grow beds, Procedia CIRP, 2021, vol. 100, pp. 55–60, \n\
    https://doi.org/10.1016/j.procir.2021.05.009\n7. G Aceto, V Persico, A. Pescapé,\
    \ A Survey on Information and Communication \nTech- nologies for Industry 4.0:\
    \ State-of-the-Art, Taxonomies, Perspectives, \nand Challenges, IEEE Commun Surv\
    \ Tutorials, 2019. https://doi.org/10.1109/\nCOMST.2019.2938259\n8. B. Ozdogan,\
    \ A. Gacar, H. Aktas. Digital agriculture practices in the context of \nagriculture\
    \ 4.0. Journal of Economics, Finance and Accounting (JEFA), 2017, \nvol. 4, iss.\
    \ 2, pp. 184-191. https://doi.org/10.17261/pressacademia.2017.448\n9. Y Liu, X\
    \ Ma, L Shu, GP Hancke, AM. Abu-Mahfouz, From Industry 4.0 to Ag-\nriculture 4.0:\
    \ Current Status, Enabling Technologies, and Research Challenges, \nIEEE Trans\
    \ Ind Informatics, 2021, vol. 17, no. 6, pp. 4322-4334. https://doi.\norg/10.1109/TII.2020.3003910\n\
    10. F da Silveira, FH Lermen, FG. Amaral, An overview of agriculture 4.0 devel-\n\
    opment: Systematic review of descriptions, technologies, barriers, advantag-\n\
    es, and disadvantages, Comput Electron Agric 189 (2021) 106405, https://doi.\n\
    org/10.1016/J.COMPAG.2021.106405\n11. G Idoje, T Dagiuklas, M. Iqbal, Survey for\
    \ smart farming technologies: Chal-\nlenges and issues, Comput Electr Eng, 2021,\
    \ vol. 92, 107104. https://doi.\norg/10.1016/J.COMPELECENG.2021.107104\n12. J\
    \ Miranda, P Ponce, A Molina, P. Wright, Sensing, smart and sustain- able tech-\n\
    nologies for Agri-Food 4.0, Comput Ind, 2019, vol. 108, pp. 21–36. https://doi.\n\
    org/10.1016/J.COMPIND.2019.02.002 \n13. M Lezoche, H Panetto, J Kacprzyk, JE Hernandez,\
    \ Alemany Díaz MME. \nAgri-food 4.0: A survey of the supply chains and technologies\
    \ for the future \nagriculture, Comput Ind, 2020, vol. 117, 103187. https://doi.org/10.1016/J.\n\
    COMPIND.2020.103187\n14. Bhakta I, Phadikar S, Majumder K. State-of-the-art technologies\
    \ in precision \nagriculture: a systematic review. Journal of the Science of Food\
    \ and Agriculture, \n2019, vol. 99, no. 11. pp. 4878-4888. https://doi.org/10.1002/jsfa.9693\n\
    15. SO Araújo, RS Peres, J Barata, F Lidon, JC. Ramalho, Characterising the \n\
    Agriculture 4.0 Landscape — Emerging Trends, Challenges and Opportu-\nnities,\
    \ Agron, 2021, vol. 11, no. 4, 667. https://doi.org/10.3390/AGRONO-\nMY11040667\n\
    16. M Bacco, P Barsocchi, E Ferro, A Gotta, M. Ruggeri, The Digitisation of Agri-\n\
    culture: a Survey of Research Activities on Smart Farming, Array, 2019, 3–4, \n\
    100009. https://doi.org/10.1016/j.array.2019.100009\n449\nSiberian Journal of\
    \ Life Sciences and Agriculture, Том 14, №6, 2022\n17. Singh, G., & Nager, P.\
    \ A case Study on Nutek India Limited Regarding Deep \nFalling in Share Price.\
    \ Researchers World - Journal of Arts, Science & Com-\nmerce, 2012, vol. 3(2),\
    \ 3.\n18. Nager, P., & Singh, G. An Analysis of Outliers For Fraud Detection in\
    \ Indian \nStock Market. Researchers World - Journal of Arts, Science & Commerce,\
    \ 2012, \nvol. 3(4), 4.\n19. MJ Page, JE McKenzie, PM Bossuyt, I Boutron, TC Hoffmann,\
    \ CD Mulrow, et \nal., The PRISMA 2020 statement: An updated guideline for reporting\
    \ systematic \nreviews, BMJ, 2021, 372. https://doi.org/10.1136/BMJ.N71\n20. Ahmed\
    \ MA, Ahsan I, Abbas M. Systematic Literature Review: Ingenious \nSoftware Project\
    \ Management while narrowing the impact aspect. RACS ‘16: \nProceedings of the\
    \ International Conference on Research in Adaptive and Con-\nvergent Systems,\
    \ 2016, pp. 165–168. https://doi.org/10.1145/2987386.2987422\n21. C Pylianidis,\
    \ S Osinga, IN. Athanasiadis, Introducing digital twins to agricul-\nture, Comput\
    \ Electron Agric 184 (2021) 105942, https://doi.org/10.1016/J.\nCOMPAG.2020.105942\
    \ \n22. Shaikh ZA Aqeel-ur-Rehman, NA Shaikh, N Islam, An integrated framework\
    \ \nto de- velop context aware sensor grid for agriculture, Aust J Basic Appl\
    \ Sci, \n2010. \n23. W Shi, J Cao, Q Zhang, Y Li, L. Xu, Edge Computing: Vision\
    \ and Chal-\nlenges, IEEE Internet Things J 3, 2016, 637–646, https://doi.org/10.1109/\n\
    JIOT.2016.2579198\n24. A Tzounis, N Katsoulas, T Bartzanas, C. Kittas, Internet\
    \ of Things in agricul- \nture, recent advances and future challenges, Biosyst\
    \ Eng, 164, 2017, 31–48, \nhttps://doi.org/10.1016/J.BIOSYSTEMSENG.2017.09.007\n\
    25. VP Kour, S. Arora, Recent Developments of the Internet of Things in Agri-\
    \ cul-\nture: A Survey, IEEE Access 8, 2020, 129924–129957, https://doi.org/10.1109/\n\
    AC- CESS.2020.3009298\n26. MU Aftab, O Ashraf, M Irfan, M Majid, A Nisar, MA.\
    \ Habib, A Review Study \nof Wireless Sensor Networks and Its Security, Commun\
    \ Netw, 7, 2015, 172–179, \nhttps://doi.org/10.4236/cn.2015.74016\n27. X Yu, P\
    \ Wu, W Han, Z. Zhang, A survey on wireless sensor network infra-\nstructure for\
    \ agriculture, Comput Stand Interfaces, 1, 2013, 59–64, https://doi.\norg/10.1016/J.CSI.2012.05.001\n\
    28. Mell PM, Grance T. The NIST definition of cloud computing, 2011. https://doi.\n\
    org/10.6028/NIST.SP.800-145\n29. Alwada’n T. Cloud computing and multi-agent system:\
    \ monitoring and services. \n2018. \n450\nSiberian Journal of Life Sciences and\
    \ Agriculture, Vol. 14, №6, 2022\n30. X Shi, X An, Q Zhao, H Liu, L Xia, X Sun,\
    \ et al., State-of-the-art inter- net of \nthings in protected agriculture, Sensors\
    \ (Switzerland), 19, 2019, 1833, https://\ndoi.org/10.3390/s19081833\n31. J Wang,\
    \ H Yue, Z. Zhou, An improved traceability system for food quality assur-\nance\
    \ and evaluation based on fuzzy classification and neural network, Food Con-\n\
    trol, 79, 2017, 363–370, https://doi.org/10.1016/J.FOODCONT.2017.04.013\n32. S\
    \ Fountas, G Carli, CG Sørensen, Z Tsiropoulos, C Cavalaris, A Vatsanidou, et\
    \ \nal., Farm management information systems: Current situation and future per-\n\
    spectives, Comput Electron Agric, 115, 2015, 40–50, https://doi.org/10.1016/J.\n\
    COMPAG.2015.05.011\n33. A Bechar, C. Vigneault, Agricultural robots for field\
    \ operations: Concepts and \ncomponents, Biosyst Eng, 149, 2016, 94–111, https://doi.org/10.1016/J.BIO-\n\
    SYSTEMSENG.2016.06.014\n34. Gonzalez-De-Santos P, Fernández R, Sepúlveda D, Navas\
    \ E, Armada M. Un- \nmanned Ground Vehicles for Smart Farms. Agron - Clim Chang\
    \ Food Secur, \n2020. https://doi.org/10.5772/INTECHOPEN.90683\n35. J del Cerro,\
    \ CC Ulloa, A Barrientos, L. Rivas J de, Unmanned Aerial Vehicles in \nAgri- culture:\
    \ A Survey, Agron, 11, 2021, 203, https://doi.org/10.3390/AGRON-\nOMY11020203\n\
    36. Patel PN, Patel M, Faldu RM, Dave YR. Quadcopter for Agricultural Surveil-\n\
    lance, 2013.\n37. Sylvester G, Food and Agriculture Organization of the United\
    \ Nations., International \nTelecommunication Union. E-agriculture in action:\
    \ drones for agriculture n.d.:112. \n38. U Sivarajah, MM Kamal, Z Irani, V. Weerakkody,\
    \ Critical analysis of Big Data \nchallenges and analytical methods, J Bus Res,\
    \ 70, 2017, 263–286, https://doi.\norg/10.1016/J.JBUSRES.2016.08.001\n39. M Chi,\
    \ A Plaza, JA Benediktsson, Z Sun, J Shen, Y. Zhu, Big Data for Re- \nmote Sensing:\
    \ Challenges and Opportunities, Proc IEEE, 104, 2016, 2207–2219, \nhttps://doi.org/10.1109/JPROC.2016.2598228\
    \ \n40. K Tesfaye, K Sonder, J Caims, C Magorokosho, A Tarekegn, GT Kassie, et\
    \ al. \nTarget- ing drought-tolerant maize varieties in southern Africa: a geospatial\
    \ crop \nmodeling approach using big data, Int Food Agribus Manag Rev, 19, 2016.\
    \ \n41. R Sharma, SS Kamble, A Gunasekaran, V Kumar, A. Kumar, A system- atic\
    \ \nliterature review on machine learning applications for sustainable agri- culture\
    \ \nsupply chain performance, Comput Oper Res, 119, 2020, 104926, https://doi.\n\
    org/10.1016/J.COR.2020.104926\n42. T Talaviya, D Shah, N Patel, H Yagnik, M. Shah,\
    \ Implementation of artifi-\ncial intelli- gence in agriculture for optimisation\
    \ of irrigation and application \n451\nSiberian Journal of Life Sciences and Agriculture,\
    \ Том 14, №6, 2022\nof pesticides and herbicides, Artif Intell Agric, 4, 2020,\
    \ 58–73, https://doi.\norg/10.1016/J.AIIA.2020.04.002\n43. KG Liakos, P Busato,\
    \ D Moshou, S Pearson, D. Bochtis, Machine Learn- ing in \nAgriculture: A Review,\
    \ Sensors, 18, 2018, 2674, https://doi.org/10.3390/S18082674\n44. G Xu, H Li,\
    \ S Liu, K Yang, X. Lin, VerifyNet: Secure and Verifiable Federat-\ned Learning,\
    \ IEEE Trans Inf Forensics Secur, 15, 2020, 911–926, https://doi.\norg/10.1109/TIFS.2019.2929409\n\
    45. J. Schmidhuber, Deep Learning in Neural Networks: An Overview, Neural Net-\n\
    works, 61, 2014, 85–117, https://doi.org/10.1016/j.neunet.2014.09.003 \n46. Canziani\
    \ A, Paszke A, Culurciello E. An Analysis of Deep Neural Network \nModels for\
    \ Practical Applications, 2016. \n47. A Kamilaris, FX. Prenafeta-Boldu, Deep learning\
    \ in agriculture: A survey, \nComput Electron Agric, 147, 2018, 70–90, https://doi.org/10.1016/j.com-\n\
    pag.2018.02.016\n48. V Kakani, VH Nguyen, BP Kumar, H Kim, VR. Pasupuleti, A critical\
    \ review on \ncomputer vision and artificial intelligence in food industry, J\
    \ Agric Food Res, 2, \n2020, https://doi.org/10.1016/J.JAFR.2020.100033\n49. F\
    \ Terribile, A Agrillo, A Bonfante, G Buscemi, M Colandrea, A D’Antonio, et al.,\
    \ A \nWeb-based spatial decision supporting system for land management and soil\
    \ con-\nservation, Solid Earth 6 (2015) 903–928, https://doi.org/10.5194/SE-6-903-2015\n\
    50. A Felsberger, B Oberegger, G. Reiner, A Review of Decision Support Systems\
    \ \nfor Manufacturing Systems, Undefined, 2016. \n51. P Taechatanasat, L. Armstrong,\
    \ Decision Support System Data for Farmer De-\ncision Making, ECU Publ Post (2013)\
    \ 2014 . \n52. L Wang, M Törngren, M. Onori, Current status and advancement of\
    \ cyber- phys-\nical systems in manufacturing, J Manuf Syst, 37, 2015), 517–527,\
    \ https://doi.\norg/10.1016/J.JMSY.2015.04.008\n53. DGS Pivoto, LFF de Almeida,\
    \ R da Rosa Righi, JJPC Rodrigues, AB Lugli, \nAM. Al- berti, Cyber-physical systems\
    \ architectures for industrial internet of \nthings appli- cations in Industry\
    \ 4.0: A literature review, J Manuf Syst, 58, 2021, \n176–192, https://doi.org/10.1016/J.JMSY.2020.11.017\n\
    54. AF Jimenez, PF Cardenas, F Jimenez, A Canales, A. López, A cyber-physical\
    \ in-\ntelli- gent agent for irrigation scheduling in horticultural crops, Comput\
    \ Electron \nAgric, 178, 2020, 105777, https://doi.org/10.1016/J.COMPAG.2020.105777\n\
    55. A Selmani, H Oubehar, M Outanoute, A Ed-Dahhak, M Guerbaoui, A Lach- hab,\
    \ \net al., Agricultural cyber-physical system enabled for remote management of\
    \ \nsolar-powered precision irrigation, Biosyst Eng, 177, 2019, 18–30, https://doi.\n\
    org/10.1016/J.BIOSYSTEMSENG.2018.06.007\n452\nSiberian Journal of Life Sciences\
    \ and Agriculture, Vol. 14, №6, 2022\n56. A Nayak, RR Levalle, S Lee, SY. Nof,\
    \ Resource sharing in cyber-physical sys-\ntems: modelling framework and case\
    \ studies, 54, 2016, 6969–6983, https://doi.\norg/10.1080/00207543.2016.1146419\n\
    57. C Verdouw, B Tekinerdogan, A Beulens, S. Wolfert, Digital twins in smart farming,\
    \ \nAgric Syst, 189, 2021, 103046, https://doi.org/10.1016/J.AGSY.2020.103046\n\
    58. D Jones, C Snider, A Nassehi, J Yon, B Hicks, Characterising the Digital Twin:\
    \ \nA systematic literature review, CIRP J Manuf Sci Technol, 29, 2020, 36–52,\
    \ \nhttps://doi.org/10.1016/J.CIRPJ.2020.02.002\n59. S Aydin, MN. Aydin, Semantic\
    \ and syntactic interoperability for agricultural \nopen- data platforms in the\
    \ context of IoT using crop-specific trait ontologies, \nAppl Sci, 10, 2020, https://doi.org/10.3390/app10134460\n\
    60. Y He, J Guo, X. Zheng, From Surveillance to Digital Twin: Challenges and Re-\n\
    cent Advances of Signal Processing for Industrial Internet of Things, IEEE Signal\
    \ \nProcess Mag, 35, 2018, 120–129, https://doi.org/10.1109/MSP.2018.2842228\n\
    61. MS Farooq, S Riaz, A Abid, K Abid, MA. Naeem, A Survey on the Role of IoT\
    \ \nin Agriculture for the Implementation of Smart Farming, IEEE Access, 7, 2019,\
    \ \n156237–156271, https://doi.org/10.1109/ACCESS.2019.2949703\n62. A Villa-Henriksen,\
    \ GTC Edwards, LA Pesonen, O Green, CAG. Sørensen, In-\nternet of Things in arable\
    \ farming: Implementation, applications, challenges and \npotential, Biosyst Eng,\
    \ 191, 2020, 60–84, https://doi.org/10.1016/J.BIOSYSTE-\nMSENG.2019.12.013\n63.\
    \ HM Jawad, R Nordin, SK Gharghan, AM Jawad, M. Ismail, Energy-efficient \nwire-\
    \ less sensor networks for precision agriculture: A review, Sensors (Swit-\nzerland),\
    \ 17, 2017, 1781, https://doi.org/10.3390/s17081781\n64. L Sigrist, N Stricker,\
    \ D Bernath, J Beutel, L. Thiele, Thermoelectric Energy \nHarvesting from Gradients\
    \ in the Earth Surface, IEEE Trans Ind Electron, 67, \n2020, 9460–9470, https://doi.org/10.1109/TIE.2019.2952796\n\
    65. AR Yanes, P Martinez, R. Ahmad, Towards automated aquaponics: A re-\nview\
    \ on monitoring, IoT, and smart systems, J Clean Prod, 2020, https://doi.\norg/10.1016/j.jclepro.2020.121571\n\
    66. N Brinis, LA. Saidane, Context Aware Wireless Sensor Network Suitable \nfor\
    \ Preci- sion Agriculture, Wirel Sens Netw, 2016, https://doi.org/10.4236/\nwsn.2016.81001\n\
    67. M Zimmerling, L Mottola, S. Santini, Synchronous Transmissions in Low-Pow-\n\
    er Wireless: A Survey of Communication Protocols and Network Services, ACM \n\
    Comput Surv, 53 2021, https://doi.org/10.1145/3410159\n68. F Tonolini, F. Adib,\
    \ Networking across boundaries: Enabling wireless com-\nmunica- tion through the\
    \ water-air interface, SIGCOMM 2018 - Proc 2018 \n453\nSiberian Journal of Life\
    \ Sciences and Agriculture, Том 14, №6, 2022\nConf ACM Spec Interes Gr Data Commun,\
    \ 2018, 117–131, https://doi.\norg/10.1145/3230543.3230580\n69. L Chen, S Thombre,\
    \ K Jarvinen, ES Lohan, A Alen-Savikko, H Leppakoski, et al., Ro- \nbustness,\
    \ Security and Privacy in Location-Based Services for Future IoT: A Survey, \n\
    IEEE Access, 5, 2017, 8956–8977, https://doi.org/10.1109/ACCESS.2017.2695525\n\
    70. Y Njah, M. Cheriet, Parallel Route Optimization and Service Assurance in Ener-\n\
    gy- Efficient Software-Defined Industrial IoT Networks, IEEE Access, 9, 2021,\
    \ \n24682–24696, https://doi.org/10.1109/ACCESS.2021.3056931\n71. A Rajput, VB.\
    \ Kumaravelu, Scalable and sustainable wireless sensor networks \nfor agricultural\
    \ application of Internet of things using fuzzy c-means algorithm, \nSustain Comput\
    \ Informatics Syst, 22, 2019, 62–74, https://doi.org/10.1016/J.\nSUSCOM.2019.02.003\n\
    72. BB Sinha, R. Dhanalakshmi, Recent advancements and challenges of Internet\
    \ \nof Things in smart agriculture: A survey, Futur Gener Comput Syst, 126, 2022,\
    \ \n169–184, https://doi.org/10.1016/J.FUTURE.2021.08.006\n73. F Caffaro, E. Cavallo,\
    \ The effects of individual variables, farming system char-\nacter- istics and\
    \ perceived barriers on actual use of smart farming technologies: \nEvidence from\
    \ the piedmont region, northwestern Italy, Agric, 9, 2019, https://\ndoi.org/10.3390/AGRI-\
    \ CULTURE9050111 \n74. Mohit Jain, Pratyush Kumar, Ishita Bhansali, Q. Vera Liao,\
    \ Khai Truong, \nShwetak Patel. FarmChat: A Conversational Agent to Answer Farmer\
    \ Que-\nries. Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiq-\n\
    uitous Technologies, 2018, vol. 2, issue 4, article 170, pp 1–22. https://doi.\n\
    org/10.1145/3287048\n75. Mclaughlan B, Brandli J, Smith F. Toward Sustainable\
    \ High-Yield Agriculture \nvia Intelligent Control Systems, 2015. \n76. RK Kodali,\
    \ S Soratkal, L. Boppana, IOT based control of appliances, in: Pro-\nceeding -\
    \ IEEE Int Conf Comput Commun Autom ICCCA 2016, 2017, pp. \n1293–1297, https://doi.org/10.1109/CCAA.2016.7813918\n\
    77. Abbasi R, Reyes A, Martinez E, Ahmad R. Real-time implementation of digital\
    \ \ntwin for robot based production line n.d.:4–6. \n78. O Bermeo-Almeida, M Cardenas-Rodriguez,\
    \ T Samaniego-Cobo, E Ferruzo-\nla- Gómez, R Cabezas-Cabezas, W. Bazán-Vera, Blockchain\
    \ in Agriculture: A \nSystematic Literature Review, Commun Comput Inf Sci, 883,\
    \ 2018, 44–56, \nhttps://doi.org/10.1007/978-3-030-00940-3_4\n79. V Saiz-Rubio,\
    \ F. Rovira-Más, From Smart Farming towards Agriculture 5.0: \nA Review on Crop\
    \ Data Management, Agron, 10, 2020, 207, https://doi.\norg/10.3390/AGRONOMY10020207\n\
    454\nSiberian Journal of Life Sciences and Agriculture, Vol. 14, №6, 2022\n80.\
    \ X Xu, Y Lu, B Vogel-Heuser, L. Wang, Industry 4.0 and Industry 5.0 – Incep-\n\
    tion, conception and perception, J Manuf Syst, 61, 2021, 530–535, https://doi.\n\
    org/10.1016/J.JMSY.2021.10.006\n81. PKR Maddikunta, Q-V Pham, P B, N Deepa, K\
    \ Dev, TR Gadekallu, et al., In-\ndustry 5.0: A survey on enabling technologies\
    \ and potential applications, J Ind \nInf Integr, 2021, 100257, https://doi.org/10.1016/J.JII.2021.100257\n\
    DATA ABOUT THE AUTHORS\nGurjeet Singh, Associate Professor& Dean, Lords School\
    \ of Computer Ap-\nplications & IT\n \nLords University\n \nAlwar-Bhiwadi Highway,\
    \ Chikani, Alwar, 301028, Rajasthan\n \nresearch.gurjeet@gmail.com\nNaresh Kalra,\
    \ Deputy Registrar (Research), Faculty of Pharmacy\n \nLords University\n \nAlwar-Bhiwadi\
    \ Highway, Chikani, Alwar, 301028, Rajasthan\n \nnaresh.kalra@lordsuni.edu.in\n\
    Neetu Yadav, Associate Professor& Dean, Lords School of Social Sciences \n& Humanities\n\
    \ \nLords University\n \nAlwar-Bhiwadi Highway, Chikani, Alwar, 301028, Rajasthan\n\
    \ \nneetu.yadav@lordsuni.edu.in\nAshwani Sharma, Assistant Professor, Lords School\
    \ of Computer Applica-\ntions & IT\n \nLords University\n \nAlwar-Bhiwadi Highway,\
    \ Chikani, Alwar, 301028, Rajasthan\n \nashwani.sharma@lordsuni.edu.in\nAshwani\
    \ Sharma, Assistant Professor, Lords School of Computer Applica-\ntions & IT\n\
    \ \nLords University\n \nAlwar-Bhiwadi Highway, Chikani, Alwar, 301028, Rajasthan\n\
    \ \nmanoj.saini@lordsuni.edu.in \nПоступила 21.05.2022 \nReceived 21.05.2022\n\
    После рецензирования 21.06.2022 \nRevised 21.06.2022\nПринята 03.07.2022 \nAccepted\
    \ 03.07.2022\n"
  inline_citation: '>'
  journal: Siberian journal of life sciences and agriculture
  limitations: '>'
  pdf_link: http://discover-journal.ru/jour/index.php/sjlsa/article/download/657/260
  publication_year: 2022
  relevance_score1: 0
  relevance_score2: 0
  title: 'SMART AGRICULTURE: A REVIEW'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1016/j.jksuci.2021.09.015
  analysis: '>'
  authors:
  - Olivier Debauche
  - Saïd Mahmoudi
  - Pierre Manneback
  - Frédéric Lebeau
  citation_count: 10
  full_citation: '>'
  full_text: '>

    Skip to main content Skip to article Journals & Books Search Register Sign in
    Brought to you by: University of Nebraska-Lincoln View PDF Download full issue
    Outline Highlights Abstract Graphical abstract Keywords 1. Introduction 2. Related
    works 3. Methodology 4. Architectures 5. New trends 6. Towards Agriculture 5.0
    7. Conclusion Declaration of Competing Interest Acknowledgment References Show
    full outline Cited by (27) Figures (14) Show 8 more figures Tables (17) Table
    1 Table 2 Table 3 Table 4 Table 5 Table 6 Show all tables Journal of King Saud
    University - Computer and Information Sciences Volume 34, Issue 9, October 2022,
    Pages 7494-7514 Cloud and distributed architectures for data management in agriculture
    4.0 : Review and future trends Author links open overlay panel Olivier Debauche
    a b c, Saïd Mahmoudi a, Pierre Manneback a, Frédéric Lebeau b c Show more Add
    to Mendeley Share Cite https://doi.org/10.1016/j.jksuci.2021.09.015 Get rights
    and content Under a Creative Commons license open access Highlights • Cloud architectures
    used in Agriculture 4.0. • Distributed Architectures and Cloud Computing complements.
    • Strategies of association between Edge, Fog, Cloud. • New architectural and
    computing trends. Abstract The Agriculture 4.0, also called Smart Agriculture
    or Smart Farming, is at the origin of the production of a huge amount of data
    that must be collected, stored, and processed in a very short time. Processing
    this massive quantity of data needs to use specific infrastructure that use adapted
    IoT architectures. Our review offers a comparative panorama of Central Cloud,
    Distributed Cloud Architectures, Collaborative Computing Strategies, and new trends
    used in the context of Agriculture 4.0. In this review, we try to answer 4 research
    questions: (1) Which storage and processing architectures are best suited to Agriculture
    4.0 applications and respond to its peculiarities? (2) Can generic architectures
    meet the needs of Agriculture 4.0 application cases? (3) What are the horizontal
    development possibilities that allow the transition from research to industrialization?
    (4) What are the vertical valuations possibilities to move from algorithms trained
    in the cloud to embedded or stand-alone products? For this, we compare architectures
    with 8 criteria (User Proximity, Latency & Jitter, Network stability, high throughput,
    Reliability, Scalability, Cost Effectiveness, Maintainability), and analyze the
    advantages and disadvantages of each of them. Graphical abstract Download : Download
    high-res image (103KB) Download : Download full-size image Previous article in
    issue Next article in issue Keywords Agriculture 4.0Smart farmingSmart agricultureLambda
    architectureKappa architectureEdge computingFog computingMicro-service architectureData
    lakeData houseBlockchainOsmotic computingDew computing 1. Introduction Nowadays,
    the Internet of Things (IoT), also formerly named pervasive Internet, is present
    in all domains of our daily life and follows exponential growth. The number of
    connected devices is estimated at the horizon of 2022 at 42.5 billion and at the
    horizon of 2025 at 75.5 billion1. The global IP traffic is estimated to 333 ZB
    per month in 20222 with the need to store and treat this data (Carnevale et al.,
    2019). The European Commission has predicted that 18 billion of 29 billion connected
    devices will be related to the IoT in 2022 (Agency, 2020). Cisco in a white paper
    has announced that connected devices to the Internet will generate 850 ZB/year
    by 2021 (Cisco, 2018). It is difficult to precisely determine the number of connected
    devices on a world scale, but their number is about several billion. In addition,
    McKinsey Global Institute predicts a total economic impact of IoT and Edge Computing
    devices that will reach 11 trillion USD by 2025 (Manyika and Chui, 2015). In the
    sector of the agriculture, nearly 12 million agricultural sensors installed globally
    by 2023 with an increase of 20% annually, which is predicted by the Business Insider
    Intelligence Service (Meola, 2021). Moreover, the smart agriculture business was
    estimated at USD 13.8 billion in 2020 and is projected to reach USD 22 billion
    by 2025 at a Compound Annual Growth Rate (CAGR) of 9.8% (Meola, 2021). Within
    the IoT era, the type of clients is becoming increasingly lightweight. IoT devices
    and the network environment is gradually changing from high-speed wired networks
    to unstable wireless communication. Meanwhile, users'' demand IoT applications
    is also shifting to real-time and context-aware service provisioning, making the
    focus moving progressively from the cloud to the edge (Ren et al., 2017). The
    cloud is located within the Internet and is geographically centralized, is constituted
    of a few resourceful server nodes, and is inserted in multi hops in terms of distance
    among the clients (Munir et al., 2017). Cloud Computing (CC) is a paradigm widely
    available that offers benefits like minimal management effort, convenience, rapid
    elasticity, pay per use, ubiquity (Ai et al., 2018), easy maintenance, centralized
    management, and high server utilization (Shi et al., 2016). Furthermore, resources
    centralization implies an increase of average network latency, heavy bandwidth
    utilization, and high processing delay. Indeed, the tremendous amount of data
    handled in a unique server point can create congestion in the cloud servers and
    backhaul links (El-Sayed et al., 2017). Nevertheless, the rapid parallel development
    of the pervasive intelligent device, ubiquitous network, growth in popularity
    of virtual and augmented reality, self-driving vehicles, UAVs, social networks,
    networks applications, and services are not without consequences. As a matter
    of fact, the network bandwidth and speed limit performance and effectiveness of
    cloud computing especially for real-time and mission-critical applications cannot
    be guaranteed. Moreover, cloud computing can be hardly adapted or applied to various
    types of technologies and applications scenarios (Zhou et al., 2017). To address
    these issues, various extensions of central cloud computing have been proposed
    by industrial and academics to move computing and storage at the edge of the network
    close to users. Fog computing uses network elements between the central cloud
    and the edge of network and absolute edge elements such as microcontrollers close
    to sensors to process and store data with a distributed manner close to nodes.
    Whereas, with the developments of mobile devices, some new paradigms close to
    mobiles users have been proposed. For example, cloudlets or micro data centers
    are geographically implanted and accessible by means of Wi-Fi protocols; but,
    this approach does not always guarantee enough network quality. Manufacturers
    of cellular network equipment have proposed the Mobile Edge Computing (MEC) paradigm
    that associates fog servers with base stations to provide services to mobile devices.
    MEC associated with 5G allows to combine an ultra-low latency network with high
    available bandwidth, and processing resources accessible in the vicinity. The
    MEC original concept has been extended then to wireless networks and consequently
    renamed in “Multi-access Edge Computing” (Wang et al., 2020). Agriculture has
    previously undergone two waves of revolution. The first one was mechanization
    and the second was called the green revolution with genetic modifications (Saiz-Rubio
    and Rovira-Más, 2020). Since the late 1990s, the digital transformation of the
    agriculture in Agriculture 3.0 also called Precision Agriculture has begun with
    the integration of Geographical Information System (GIS), Global Positioning Systems
    (GPS), and the usage of sensors have invaded agriculture. They allowed the emergency
    of image processing, techniques using deep learning, and machine learning in the
    field of computer vision. This latter is implemented to discriminate weed, identify
    crops, detect diseases,…etc. The production of a large amount of data by agriculture
    3.0 has required the development of big data technologies to process them, reflecting
    important changes in various fields of research. Collected data must be recorded
    in a specific format in order to discover patterns, curate errors, eliminate duplicated
    or inconsistent data, or solve noise problems (Triantafyllou et al., 2019). Smart
    Farming also called Smart Agriculture or Agriculture 4.0 is a domain of IoT in
    full growth which bring innovative paths to improve the adaptability, the efficiency,
    and the resilience of the agriculture of production systems (Iaksch et al., 2021)
    boost competitiveness and profit (Triantafyllou et al., 2019), allocate resources
    reasonably, and avoid food waste (Zhai et al., 2020, Wolfert et al., 2017) thanks
    to the contribution of autonomous context awareness provided by sensors and the
    capability to execute autonomous or remote actions (Wolfert et al., 2017). Smart
    Farming displaces the strict application from the farm location to affect related
    fields such as decision making by farmers, biodiversity, supply chains management,
    food availability and quality, insurance, and research in environment and earth
    sciences,… Smart Farming is distinct from other domains of the Internet of Things
    (IoT) by the observation and action of biological objects (animals or plants).
    It differs from medical IoT by the fact that there are no issues related to privacy;
    but, the confidentiality of data is related to production processes. Like most
    areas of the IoT, Wireless Sensing and Actuating Network (WSAN) use Low-power
    and Lossy Network organized in hierarchical routing to collect data and actuate
    devices. Multi-path routing protocols can also be implemented to balance the data
    transfer load and conserve the energy of limited battery life, basic computational
    skills, unique communication identifier, and resources-constrained nodes. Due
    to the limited battery life, it is difficult and sometimes impossible to recharge
    or replace (Debauche et al., 2021). Moreover, energy-saving and ambient energy
    techniques must be applied to deal with the active and inactive operational time
    and schedule information transmission (Triantafyllou et al., 2019). To which objects
    can be added like connected agricultural vehicles, milking robots, Unmanned Aerial
    Vehicle (UAV) commonly known as drones, Unmanned Ground Vehicle (UGV) also called
    robots, mobile devices such as tablets used to encode punctual observations (Debauche
    et al., 2021), and external sources such as public geo-services (Triantafyllou
    et al., 2019). The use of IoT in agriculture 4.0 ranges from family farming as
    for example in India on a very small scale with a few low-cost sensors and actuators
    to very large scales with thousands of expensive commercial sensors and many connected
    agricultural pieces of machineries as in the American mid-west. Smart Farming
    is characterized as aforementioned by a wide variety of objects that can produce
    the highly contrasted amounts of data from few bytes/s to Gb/s. In addition, the
    availability of network protocols in rural areas to transmit this data impact
    also the type of architecture to implement. Applications need treatments in real-time
    and/or at a different time. The ”real-time” requirements are also very variable
    depending on the use case. For instance, remote control of drones requires reaction
    times of at most a few milliseconds while the Variable Rate Fertilizer (VRF) or
    Variable Spraying (VS) application aim to optimize nutrients and herbicides application
    respectively need reaction time in a range of few milliseconds to few seconds.
    The real-time processing for monitoring a herd of cattle is of the order of a
    few minutes to a few hours. The data retention time is very variable and is highly
    dependent on each use case. For example, UAVs produce tremendous quantities of
    images to transfer to the cloud in real-time where they must be quickly processed
    and stored. They can also be post-processed to extract additional data in batch
    processing. While UGVs images lose their value after processing and eventually
    actuating. However, if data is of a special, new or exceptional nature, it can
    be stored with a view, for example, to improving artificial intelligence algorithms.
    Other sensors transmit data only when anomalies are detected while others transmit
    at regular intervals a tiny amount of data. However, the adoption of Smart Farming
    is hampered by the lack of models to guide stakeholders on how to implement and
    to deploy dense and heterogeneous IoT-based monitoring systems and manage their
    interoperability (Triantafyllou et al., 2019). Commercial sensors are very expensive
    making it impossible for small farms to implement them (Garcia et al., 2020).
    In addition, two trends are currently opposed. That coming from the manufacturers
    of agricultural machinery who have developed their ecosystems and who want to
    extend the services offered to farmers by attracting them into the captive ecosystems
    in which they are locked. Furthermore, another trend is the development of open
    ecosystems in which farmers can preserve the ownership of their data and keep
    control of the processing carried out on this data and of their use. On one hand,
    farmers are therefore faced with a dilemma where they are in any case forced to
    use agricultural equipment that collects their data against their will; on the
    other hand, they want to keep control of their data collected through IoT sensors.
    Currently, it is difficult to predict which of these two trends will take precedence
    over the other or whether one of the two will coexist (Wolfert et al., 2017).
    In this context, both private and public researchers can either use generic commercial
    platforms offered by cloud players on which they have limited possibilities of
    adaptation or develop their own architecture on the basis of commercial or free
    bricks, but with much greater possibilities of adaptation. In this case, the choice
    is also delicate, and a bad evaluation of the constraints can jeopardize the research
    project. Due to the recent advances in big data, we present a survey that provides
    an overview of the state of the art regarding Smart Farming. It aims at summarizing
    parameters that condition the choice of architecture to collect, process, and
    store agricultural data. Since there is a wide variety of use cases, it is important
    to make an informed choice when it comes to architecture. In this way, we address
    the current gap in the literature with a review of cloud architecture used in
    Agriculture 4.0 to collect, process, and store data to enlighten the reader about
    the possible choices and the new trends that emerge. The rest of this paper is
    structured as follows: The second section is composed of two parts. In the first
    part, we summarize related previous review in the domain and their contributions,
    in order to contextualize our contribution to the literature. In the second part,
    we identify architectures implemented in Agriculture 4.0 use cases. In the third
    section, we describe the methodology used to identify papers, the conceptual framework
    used to analyze the literature, and the criteria used to compare the selected
    architectures. In the fourth section, we present architectures used to collect,
    process, and store data. We describe successively the cloud-centric architectures,
    the extension of cloud paradigm, the distributed architecture. In the fifth section,
    new trends and futures directions are presented. In the sixth section, we discuss
    the future evolution of Agriculture 4.0 to Agriculture 5.0. Finally, the last
    section concludes this paper with recommendations and perspectives. 2. Related
    works We begin our review by identifying the previous review realized in the field
    of Internet of Things applied to Smart Agriculture to take stock of the state
    of art and highlighting aspects that have not been explored at the present time.
    In this section, we focus to achieve two objectives. The first aims to position
    our work in relation to the existing literature. The second aims to identify architectures
    commonly used in the case of applications in Agriculture 4.0. 2.1. Previous reviews
    Reviewed papers presented in Table 1 were selected in the timeframe from January
    2017 to July 2021. The major contribution of each paper was extracted and highlighted
    to show our contribution to the literature. Table 1. Summary of previous review
    achieved on big data management in a context of Smart Farming. Major Contribution
    Reference Survey of agro-industrial and environmental solutions for monitoring,
    control, logistics, and prediction. (Talavera et al., 2017) Diagnosis and analysis
    of existing IoT deployments in regards to communication protocols. (Ray, 2017)
    Survey of IoT technologies in agriculture and highlighted the challenges going
    forward. (Tzounis et al., 2017) Identification of IoT challenges, its application
    in smart agriculture, and presentation of trends and technological innovation
    (Elijah et al., 2018) Review of IoT applications in Precision Agriculture, evaluation
    of previous contributions by researchers, and pathways to future innovation (Khanna
    and Kaur, 2019) Review of IoT deployment in protected agriculture, identification
    of its challenges, and prospection of the new research domain. (Shi et al., 2019)
    Review of existing IoT-based precision agriculture solutions for further achievement.
    (Ruan et al., 2019) Review, comparison, prospection, and challenges of wireless
    communication technologies applications in the field of Precision Agriculture.
    (Feng et al., 2019) Review, case study, and challenges of WSN in environmental
    behavior. (Shafi et al., 2019) Review, identification, challenges of current and
    future trends of IoT agriculture. (Ayaz et al., 2019) Survey of IoTbased agriculture,
    presentation of connection between IoT, big data, and cloud computing, regulation
    and policies of IoT, and its application in the field of agriculture. (Farooq
    et al., 2019) Survey of the use of UAVs, an overview of PA, and investigation
    of 20 UAV applications. (Radoglou-Grammatikis et al., 2020) Challenges of IoT-based
    agriculture architecture, a summary of existing surveys of smart agriculture.
    and classification of threats models, study, analysis of challenges and future
    works of security and privacy of green IoT-based agriculture. (Ferrag et al.,
    2020) Discuss the role of IoT and big data analysis in agriculture with an emphasis
    on the commercial status of applications and translational research outcomes.
    (Misra et al., 2020) resent different solutions to address IoT in arable farming
    challenges. (Villa-Henriksen et al., 2020) Systematic review presenting how IoT
    is used with smart farming (Navarro et al., 2020) Methodological review and analysis
    of IoT components and their applications in smart farming. (Debauche et al., 2021)
    Review of emerging technologies towards agriculture 4.0 and new pathways to agricultural
    practitioners. (Liu et al., 2020) Review, classification, presentation, comparison,
    and challenges of emerging technologies for IoT-based agriculture. (Friha et al.,
    2021) In the following paragraphs, we will draw a panoramic summary of the existing
    reviews during the past four years (2017–2021). In 2017, Ray (Ray, 2017) reviewed
    throughout his paper IoT applications and the challenges that have been faced
    while IoT deployment to improve farming. Talavera. et al. (Talavera et al., 2017)
    reviewed agro-industrial and environmental applications that are using the Internet
    of Things (IoT) for monitoring, control, logistics, and prediction. Tzounis et
    al. conducted a survey of IoT technologies in agriculture and the challenges that
    farmers face going forward (Tzounis et al., 2017). Elijah et al. identified the
    most encountered challenges in the field of IoT applications in smart agriculture
    and presented common trends for innovative ideas (Elijah et al., 2018). In 2019,
    Ayaz et al. provided a state-of-art about IoT-based architectures applied in agriculture
    and identified present and future trends in the same field of study (Ayaz et al.,
    2019). Farooq et al. presented the ingredients of IoT-based smart farming with
    used technologies that apply the utilization of network architecture and protocols;
    in addition to that, they provided an overview of the regulations and policies
    of the use of IoT in farming regarding security and privacy. They concluded their
    study by summarizing the main challenges encountered in this discipline (Farooq
    et al., 2019). Feng et al. provided an overview of the wireless communication
    technologies in the precision agriculture domain. They benchmarked the prospection
    and challenges of existing technologies with the regular communication time used
    (Feng et al., 2019). Shafi et al. conducted a literature review about IoT-based
    automation of agriculture along with Wireless Sensor Network (WSN). These authors
    presented a case study based upon two models: 1- a WSN to monitor real-time crop
    of health conditions, 2- system-base remote sensing imagery to classification
    between healthy and unhealthy yield (Shafi et al., 2019). In terms of agriculture
    protection, Shi et al. drew a panoramic review during the last decade to address
    the challenge and future works to further the research in the field of protected
    agriculture (Shi et al., 2019). Khanna et Kaur called into an evolutionary scenario
    to highlight the most significant impact of IoT in Precision Agriculture (PA).
    They evaluated the contribution of their predecessors and enhanced the challenges
    to open up a new direction of inspiration and innovation in IoT applied to PA
    (Khanna and Kaur, 2019). Ruan et al. reviewed literature works from 2009 to 2018
    to suggest new ideas for folks interested to conduct research in the field of
    agriculture IoT, infrastructures, data security, and data sharing (Ruan et al.,
    2019). In 2020, two studies have been carried out about 20 UAV applications that
    are devoted to either aerial crop monitoring processes or spraying tasks (Radoglou-Grammatikis
    et al., 2020) and about the dilemmas that researchers must overcome while deploying
    IoT in the green agriculture domain (Ferrag et al., 2020). Villa-Henriksen et
    al. identified different challenges encountered during the implementation of IoT
    in various applications and proposed different solutions to address them (Villa-Henriksen
    et al., 2020). Misra et al. discuss the role of IoT and big data analysis in Smart
    Farming (Misra et al., 2020). In 2021, a recent study conducted by Friha et al.
    hypothesize the use, application, classification, and comparison of the most developed
    emerging technologies such as Internet of Things (IoT), Unmanned Aerial Vehicles
    (UAV), Wireless Technologies, open-source IoT platforms, Software Defined Networking
    (SDN), Network Function Virtualization (NFV) technologies, cloud/fog computing,
    and middleware platforms (Friha et al., 2021). In the same year, Debauche et al.
    conducted a literature review to describe the main components of IoT and its applications
    in the field of Smart Farming (Debauche et al., 2021). 2.2. Platforms implemented
    in use cases We grouped applications into 4 categories: (1) Water Management in
    which we have aggregate all types of water use such as irrigation and watering
    animals. (2) Plant Disease and Pest groups all use cases in plant’s pathologies
    detection and treatment of plant pathologies (spraying of fungicides, pesticides,
    etc). (3) Crop Management brings together all the use cases relating to cropping
    operations: soil management (plowing, fertilizer application), sowing, weeding,
    and harvesting. (4) Livestock includes everything related to the breeding of farm
    animals (nutrition, behavior, diseases, treatments). Table 2 summarizes platform
    used to implement use cases in Smart Farming classified following our four categories.
    Table 2. Summary of cloud platforms, databases mentioned in Smart Farming reviews.
    Empty Cell Water Management Plant Diseases & Pest Crop Management Livestock Reference
    IoT platform Thingspeak x (Maureira et al., 2011) FIWARE x (Rodriguez et al.,
    2018) NETPIE x x (NECTEC, 2020) Ubidots x (Ubidots, 2021) SmartFarmNET x x (Jayaraman
    et al., 2016) Thinger.io x x (Luis Bustamante et al., 2019) Kaa IoT Platform x
    x (KaaIoT, 2021) IBM Watson IoT Platform x x x x (IBM, 2015) Microsoft Azure IoT
    Platform x x x (Microsoft, 2021b) AT&T M2X Cloud x (AT&T, 2021) Blynk x (Blynk,
    2021) MACQU x (Sigrimis et al., 2002) ERMES x (Granell et al., 2017) Agrocloud
    x x x (Kodati and Jeeva, 2019) CropInfra x (Pesonen et al., 2014) SensorCloud
    x (Corp, 2020) LoRaFarM x x x (Codeluppi et al., 2020)  Cloud platform Amazon
    Web Service x x x x (Amazon, 2021b) IBM Cloud x x x x (IBM, 2021) Microsoft Azure
    x x x x (Microsoft, 2021a) Integra x x (Souces and I., 2021)  Cloud Database DynamoDB
    x x x (Amazon, 2021) MongoDB Atlas x x x (Mongo, 2021) Firebase x x x (Google,
    2021) InfluxDB Cloud x x x (Influxdata, 2021)  Local Database MySQL x (Oracle,
    2021) SQLite x (SQLite, 2021) PostgreSQL/PostGIS x x (The PostgreSQL Global Development
    Group, 2021) Apache Cassandara x (Apache Software Foundation, 2021a) Apache Druid
    x x (Apache Software Foundation, 2021b) Garcia et al. give an overview on trends
    in Smart Irrigation in which they showed that data is stored in the database or
    in the cloud. On 151 reviewed papers, one uses Raspberry Pi, 18 databases, 53
    clouds, and 79 are self-developed or not mentioned (Garcia et al., 2020). Navarro
    et al. identified 21 Platforms used in 50 various use cases classified into 5
    categories: Artificial Intelligence, Big Data, Machine Learning, Computer Vision,
    and Other/Not Identified (Navarro et al., 2020). Jayaraman et al. present SmartFarmNet,
    an IoT platform offering effortless integration of sensors, supporting scalable
    data analytics, and proposing do-it-yourself tools to analyze and visualize data
    (Jayaraman et al., 2016). Codeluppi et al. describe LoRaFarM a general architecture
    modulated depending on the farm’s characteristics and requirements (Codeluppi
    et al., 2020). The monitoring of crops particularly more sensitive to them as
    saffron is crucial. The DIAS Architecture (Triantafyllou et al., 2019) uses different
    ground and leaf sensors to monitor the real-time 24/24 h cultivation process of
    saffron. This data is transmitted by LoRaWAN with IPv6 protocol and MQTT-SN protocol
    to FIWARE’s context broker. The broker manages all networking devices by means
    of sixteen types of messages exchanged following publish-subscribe model. The
    FIWARE NGSI API of oversees the consumption, subscription, and processing of all
    the information collected and its publication. Afterward, the data is stored and
    analyzed with a random forest algorithm which allows extracting information about
    the crop growth and health. Vegetation indexes: Normalized Difference Index (NDI),
    Excess Greenness Index (ExG) are calculated with PiX4D3 image processing tools.
    Object-based image analysis (OBIA) is used to recognize weeds or discriminate
    species. Finally, collected data are categorized and evaluated accordingly with
    vegetation index values, moisture level, and plant developing state by means of
    the Apache Spark framework for the Big Data analysis and Waikato Environment (WEKA)
    a framework specialized in data mining to produce reports and predictions. Decision-making
    is a very important task in the farmers’ activities but with the amount of data
    always increasing, they encounter difficulties on one hand to make proper decision
    about agricultural management and on the other hand translate this data into practical
    knowledge (Zhai et al., 2020). On the other hand, there is a need for platforms
    of the Agricultural Decision Support System (ADSS) to assist farmers to make precise
    decisions evidence-based. For example, Watson Decision Platform for Agriculture
    combines IBM Watson with IoT and Cloud Computing to detect crop disease from UAV
    images. It is also possible to optimize time for crop operations to obtain a better
    price on trading market. The second example is Digital Farming System4 takes advantage
    of computer vision, cloud computing, and AI to propose a better timing for corp
    operations, notify when a crop is infected by any disease. Smart Irrigation Decision
    Support System (SIDSS) is composed on one hand of a set of sensors and a weather
    station and on the other hand a DSS based on two machine learning algorithms.
    Partial Least Squares Regression (PLSR) to deduct unnecessary variables and Adaptive
    Neuro -Fuzzy Inference Systems (ANFIS) used to minimize estimated errors under
    a target threshold (Navarro-Hellin et al., 2016). SIDSS generates planning of
    water amount and time for irrigation. Multi-robot sense-act system (Conesa-Munoz
    et al., 2016) is a planner of aerial and ground vehicles which assign tasks to
    the most appropriate work units. A Harmony Search Algorithm is used to optimize
    plans for UAVs while meta heuristic is running for ground vehicles. 2.3. Analysis
    of previous literature The analysis of existing reviews about smart farming shows
    that applications use whether open source or commercial cloud architecture whether
    developing specific architecture responding to their aims or do not describe their
    storage and processing system. The latter represents more than half of the papers
    and means that some of the processing architectures remain unknown because they
    have never been specifically described and studied. Moreover, the fact that further
    development is being made in architecture may be the fact that commercial platforms
    do not fully address the needs of Agriculture 4.0. This brings us to our research
    questions and their respective motivation: 1. Which storage and processing architectures
    are best suited to Agriculture 4.0 applications and address its particularities?
    Motivation: On one hand generic architectures dedicated or not to IoT are able
    to address a large number of use cases but not specifically the needs of Agriculture
    4.0 exist. On the other hand, researchers develop architectures to address specific
    issues or requirements of use cases. The selection of an adapted architecture
    is crucial for the correct implementation of identified use cases. 2. Can generic
    architectures meet the needs of Agriculture 4.0 application cases? Motivation:
    Agriculture 4.0 has specific requirements described in the introduction section
    which cannot all be addressed by a single classical generic architecture. A comparison
    between the pros and the cons of major generic architecture in the context of
    agriculture 4.0 is important to highlight the choice during the conceptualization
    step. 3. What are the horizontal valuation possibilities that allow the transition
    from research to industrialization? Motivation: The use of architectural solutions
    which can be for example free of fees during the research phase but needs a reimplementation
    caused by license limitations, the cost of the license in the use cases budget,
    etc. The use of products in closed or semi-closed ecosystems is a barrier to the
    research valuation. 4. What are the vertical valuation possibilities to move from
    algorithms trained in the cloud to embedded or autonomous products? Motivation:
    The massive collection of data in the cloud allows to development of complex algorithms
    that need a large amount of computing resources to be elaborated. Afterward, they
    can be compressed, reduced, optimized in order to be deployed in embedded devices
    or divided and establish a collaboration between devices and computing resources
    such as cloud, fog, etc. In order to answer these questions, a review of the literature
    will make it possible to synthesize the different approaches currently used, to
    identify new trends and to consider new lines of research to be explored. 3. Methodology
    In order to address, our first and second research questions, we achieve a systematic
    review to identify generic architectures and combination of architectural elements
    used by researchers to implement concrete use cases. Moreover, we attempt also
    identify commercial products and existing services/ platforms used to implement
    projects in agriculture. 3.1. Systematic review methodology The research questions
    outlined at the end of the related work section has been addressed by combining
    keywords of the first group that refers to architectures (i.e. cloud architecture,
    distributed architecture, big data, Internet of Things, IoT) and of the second
    group contained keywords related to agriculture (i.e. agriculture, smart farming,
    food, agri-food, precision agriculture). Our methodology is based on 3 consecutive
    steps: literature identification, reading literature, and information extraction.
    During the first step, we have read and have collected individual papers based
    on the achieved of previous papers. We have reviewed and completed by a systematic
    survey of white literature (full articles and conference papers) from January
    2016 to December 2020. In addition, we targeted solely and exclusively papers
    written in English and focusing on architecture design have been considered. Our
    bibliographic review was limited to the last 5 years because the rapid development
    of IoT. The systematic review was retrieved from the following major bibliographic
    databases: Scopus (Elsevier), IEEE Xplore Digital Library, Wiley Online Library,
    ACM Digital Library, and Springer. These bibliographic databases have been chosen
    widely covering relevant bibliography and relevant advanced bibliometric features
    especially number of citation and relevant literature suggestion. From these databases
    1058 peer-reviewed articles were retrieved. After their screening 55 papers were
    classified relevant while remaining articles were considerate not relevant and
    therefore excluded from further reading and analysis. The high number of excluded
    papers is due to numerous papers describe i.e. conceptual or theoretic architectures
    which were never implemented, experimental architectures that have been the subject
    of a single article or that have never been proven by other research teams. We
    discard also papers that were not a directly related Big data and the agricultural
    sector. Table 3. Table 3. Keywords used for achieved the systematic review. Area
    Keywords Related concepts Agriculture Agriculture, Agricultural e-Agriculture
    Agri-Food Agribusiness Smart Farming Farming Precision Agriculture, Precision
    Farming  Internet of things IoT, Internet of Things, internet-of-things Big data
    Big Data Big Data Data Management Data Management Architecture Cloud Architecture,
    Distributed Architecture In a second step, we included English grey literature
    (reports, blogs, magazines, and web-items) into our review using Web of Science
    and Google Scholar. Table 4. We discarded papers that were written in other languages
    than English, Master and doctoral dissertation, and duplicated articles gathered
    from Google Scholar. Afterward, we have selected literature that has carefully
    been read in detail to extract relevant information of research questions. The
    extracted information was analyzed and summarized in a conceptual framework illustrated
    in the Fig. 1. Table 4. Sources of collected literature. Data source URL IEEE
    Xplore Digital Library https://ieeexplore.ieee.org Scopus https://www.scopus.com
    Springer https://link.springer.com/search Wiley Online Library https://onlinelibrary.wiley.com
    Google Scholar https://scholar.google.com Web of Science https://publons.com/publon
    ACM Digital Library https://dl.acm.org Download : Download high-res image (171KB)
    Download : Download full-size image Fig. 1. Conceptual framework of data processing.
    Three ways of treatment of data are possible. The first process data in real-time
    (left branch identified by (1) on Fig. 1), this one is generally not stored except
    eventually particular or exceptional data in order to enrich the training database
    of artificial intelligence algorithms. This way of data treatment is used for
    example by robots that inspect a crop, discover a pest, and then eliminate it.
    After intervention the value data is near null. The second way is a mixed way
    in which data must be processed as quickly as possible. This one addresses use
    cases where latency required must be comprised between few milliseconds to few
    seconds with data, which conserves a value during a certain period of time. This
    latter justifies its storage according to the use case data management plan that
    predicts the time after which the data will be aggregated and then deleted. This
    way in identified by (2) on Fig. 1. It addresses use cases where all data must
    be processed and then stored for eventual post-processing for example to estimate
    trends of parameters such as the milk quality, volume of palatable species available
    in a pasture. The third way is stored data theirs native format without transformation
    (Identified by (3) on Fig. 1). This way is implemented on use cases that do not
    require real time processing or use cases where the amount data is so important,
    which makes treatment impossible. In this latter case, data are consumed by micro
    services that sample data to exact knowledge. This way is also employed for data
    which have a low value or lose their value so quickly that there is no point in
    transforming them for long-term storage. For instance, a UGV identifies and eliminates
    a pest. The image of the insect is no longer relevant after its elimination. 3.2.
    Architecture comparison criteria In order to compare selected architectures, we
    chose to select 8 criteria:(1) User Proximity expresses the necessity to be close
    to the user. This criterion is important for applications where privacy and response
    time to query are critical. Attribute a value of one * when privacy is not crucial;
    ** when the proximity with user is desirable but not crucial for the development
    of the use case; *** when the user proximity is the corner stone of the application.
    (2) Latency & Jitter criterion describes the importance for the architecture to
    have a minimal latency and jitter. This criterion is particularly important for
    use cases where response time to query in quasi (real time) is required and/or
    time between data production and ingestion by the processing and storage architecture
    is essential. (3) Network stability criterion translate the necessity to have
    a stable network or if is interruption can be tolerated. Use a value of * if the
    use case implemented can tolerate the absence of network during few hours; **
    if few minutes of interruption are tolerable; *** is stability of the network
    is an essential element of the use case. (4) The high throughput criterion expresses
    the capability of the architecture to process quickly a wide amount of data arriving
    at high frequency; Use a value of * if the data arrive mostly at regular intervals;
    a value of ** if the data arrive in bursts, and *** if the data arrive continuously
    at high frequency ( 10 Hz). (5) Reliability is a criterion that expresses if the
    infrastructure is critical in other terms whether an interruption in infrastructure
    could cause loss of life or not. Attribute a weight of * if the data is not critical
    and potential damages caused by an interruption of the architecture are minors
    or null; ** if potential damageable but tolerable if they occur more than once
    a year; *** if the application cannot tolerate any interruption which would cause
    irreversible damage or loss of human life. (6) Scalability is a criterion that
    expresses the regularity of the evolution in terms of processing and storage during
    a period of one year. If the scalability must be achieved at most once a year
    use a weight of *; if the scalability is achieved at most twice a year use **;
    if the scalability must be achieved more than two times by year use a weight of
    ***. (7) Cost-Effectiveness criterion reflects the need to control infrastructure
    costs. This criterion is more important as the infrastructure is brought to evolve
    both in terms of scale and complexity. Use the weight of * if the project will
    remain in a relatively constant size and do not need to be scaled or dramatically
    modified; Use **, if the project evolves reasonably, i.e. should not undergo significant
    modification more than once a year. Use a weight of *** if the size of the project
    and/ or its complexity need a fine study of cost. (8) Maintainability criterion
    is directly linked to the sustainability of the project. If the sustainability
    of the project will not exceed two years to allocate a point of *; if the life
    of the project is between 2 and 5 years, assign a score of ** beyond 5 years,
    assign ***. 4. Architectures The numerous publications dealing with cloud architectures
    relating to Agriculture 4.0, summarized in Table 2, show that a great deal of
    effort has been devoted to solving a whole range of problems related to many use
    cases. Indeed, a universal and a unique architecture do not exist for IoT applications
    in Smart Agriculture which ensure all needs of all use cases. This is the reason
    why several researchers have proposed various architectures which address specific
    issues of generic architectures. The Fig. 2 gives a global overview on Agriculture
    4.0 organization. Download : Download high-res image (340KB) Download : Download
    full-size image Fig. 2. Global structure of IoT in Agriculture 4.0. 4.1. Central
    Cloud Architectures Central Cloud Architectures are based on two basic architectures
    that are associated or combined in order to form modern architectures. These two
    architectures are: Batch Architecture aims to process an entire dataset in an
    offline mode. For this type of architectures, as long as the processing of the
    dataset is not finished, it continues and produces results only when it has reached
    its end. Generally, the data is selected and distributed to different nodes in
    order to be processed more quickly. When all the treatments are achieved on all
    nodes, the results are sorted and aggregated to obtain a global output. This architecture
    is easily implemented, and the aggregation is done by a framework, but processing
    times can be long, and data extracted during the treatment cannot be processed
    before the end of the treatment in progress. Furthermore, it is possible to increment
    results of previous batch and produce a result that integrates treated data in
    progress. Sallah et al. used a batch architecture to update data within the AquaCrop
    model (FAO) embedded in R-environment in order to facilitate model calibration
    and validation, run and evaluate all fields in a single run (Sallah et al., 2019).
    Nolack Fote et al. presented an architecture to extract knowledge on the long
    term from data in Precision Livestock Farming (PLF) (Fote et al., 2020). Table
    5. Table 5. Pros and Cons of Batch Architecture. Pros Cons - Easy to implement
    and maintain. - Process only data previously stored in another form (file, database,
    etc). - Able to achieve long term treatments (several hours or days). - Processing
    cannot be modified before the end of the treatment. - Reprocessing of old data
    that are easy to achieve. - Results available only at the end of the treatment.
    Real-time Architecture also named Streaming Architecture processes data as it
    arrives, and results are progressively available by opposition to the batch architecture
    where it is not necessary to wait for the end of ingestion of all input data to
    obtain a result. The notion of real-time is strongly dependent on the analysis
    context with a processing time from a few milliseconds to a few minutes. Real-time
    architecture can be implemented in two different ways. On one hand with micro-batch
    in which a tiny amount of data is processed each n seconds and a result is obtained
    at the end of the treatment or on the other hand with a streaming approach in
    which each new data is immediately processed and output is quickly produced. This
    architecture is limited to data flow processing (Miloslavskaya and Tolstoy, 2016).
    Table 6. Table 6. Pros and Cons of Real-time Architecture. Pros Cons - Allow a
    rapid treatment of newly arrived data. - Not able to achieve processing on large
    size of the batch. - Batch processing can be emulated using micro batches but
    not all algorithms can be implemented. - Reprocessing of old data difficult to
    implement. - Easy to implement and maintain. - The need for real-time processing
    involves the use of an estimator rather than the precise values that would take
    too long to be calculated. Various data are produced by different fields or animals
    sensors, vehicles, and robots of the Agriculture 4.0. Afterward, this data must
    be on one hand stored in a raw state and processed in an offline way where long
    and complex treatments can be achieved. On the other hand, data can be processed
    before its storing with offline processing, streaming processing, or a combination
    of these ones. The storage time is extremely variable following the nature of
    the data and their loss of value over time. Offline processing is classically
    used to process images from UAVs, UGVs, or satellites, for example, to determine
    photosynthesis activity, evaluate the canopy development or stocks of palatable
    species available in a pasture, etc. While Streaming processing allows detecting
    anomalies in animals’ behaviors in real-time, or during agricultural operations
    such as the harvesting, disease and pest detection, weeds elimination. In these
    last cases, data is not stored because it quickly loses all value after its ingestion.
    Finally, a combination of the two previous ways i.e. Offline and Streaming processing
    is used to estimate real-time metrics and achieve complex treatments in an offline
    way at the same time. This approach is used by milking robots which detect anomalies
    in the production in real-time while the offline processing estimates the future
    production of each cow based on previous milking (Debauche et al., 2021). Lambda
    architectures are used in systems that need to process and expose quickly massive
    amounts of streaming data. This cloud architecture was proposed by Nathan Marz
    and James Warren (Marz and Warren, 2013) to handle tremendous quantities of data
    and resolve complex problems combining processing large volumes of data (Batch)
    while incorporating the most recent data processed in real-time processes (Singh
    et al., 2019). This architecture is generic, scalable, and fault-tolerant against
    hardware failures and human mistakes. The architecture is composed of three layers:
    (1) batch layer process very large quantities of data by batch; (2) speed layer
    which processes data in real-time and provides views based on the most recent
    data and (3) serving layer responding to queries. Data comes from either a data
    source or a message queue. This paradigm allows executing arbitrary queries over
    any real-time data and is particularly adapted for critical infrastructure and
    health systems (Diaz et al., 2016). Several implementations of Lambda Architecture
    in smart Environment management, big data storage and analytics can be found in
    (Villari et al., 2014). Among the criticisms that have been made against lambda
    architecture is the need to make twice the developments for the real-time branch
    and the batch branch. It is possible to perform a batch processing and in real
    time with flow processing is what the Kappa architecture described below does
    (Kreps, 2014). Fig. 3 Table 7. Download : Download high-res image (116KB) Download
    : Download full-size image Fig. 3. Lambda Architecture General Scheme. Table 7.
    Pros and Cons of Lambda Architecture. Pros Cons - Process data in real-time or
    in batch processing in separate ways. The reliability of two ways of treatment
    is most costly than other architectures if the two execute the same treatment.
    Among use cases in agriculture 4.0 using a lambda, we would like to highlight:
    Roukh et al. proposed WALLeSMART, a cloud platform based on lambda and specifically
    developed for Smart Farming. This platform implements Apache Kafka to store temporary
    data before their treatment. Apache Hadoop and the programming model Mapreduce
    is used for the batch processing while Apache Storm process data in realtime.
    The originality of this architecture is the coupling of a NoSQL database Apache
    Casandra and a SQL database, PostgreSQL where data is stored in the function of
    its nature. The GraphQL query language allows to querying databases. (Roukh et
    al., 2020, Roukh et al., 2020). Debauche et al. describe a lambda architecture
    for digital phenotyping (Debauche et al., 2020) and farm animals’ behaviors coupled
    with an Application Hosting Architecture based on Apache Mesos and Docker containerization
    to facilitate the deployment of various applications. An API interconnects and
    controls accesses between the Lambda Architecture and the Hosting Application
    Architecture. The Lambda architecture is based on Apache Beam to easily change
    the runner in the function of the technology evolution and improve its sustainability.
    Apache Druid is used to store time series data (Debauche et al., 2019) and metadata
    of data stored in the Datalake based on Apache Hadoop (Debauche et al., 2018).
    A variant of this architecture, named Unified Lambda architecture combines batch
    and stream pipelines which runs concurrently, and then the results are merged
    automatically (Siciliani, 2015). AllJoyn Lambda integrates AllJoyn a framework
    that offers: (1) proximal devices and applications discovering; (2) specific devices
    framework adapting; (3) transmission between devices with Bluetooth, Wi-Fi, etc.;
    (4) interoperability between operating systems; (5) efficient and secure data
    exchange through D-BUS (Villari et al., 2014). The Kappa architecture, proposed
    by Jay Kreps from LinkedIn (Kreps, 2014), simplifies the Lambda architecture by
    combining real-time and batch layers. This cloud architecture differs from the
    Lambda architecture by using a non-permanent storage system of data in an unchangeable
    log file such as system as Apache Spark or Apache Kafka, and consequently allow
    only storage for a limited time in order to allow an eventual reprocessing of
    these data. Batch and Speed Layers are also replaced by a stream processing engine.
    So, the Kappa Architecture is composed of two layers: streaming and serving layers
    and can be implemented with a publish-subscribe messaging like Apache Kafka, which
    facilitates data ingestion. Fig. 4. Download : Download high-res image (121KB)
    Download : Download full-size image Fig. 4. Kappa Architecture General Scheme.
    The main advantage of this architecture is its simplicity. It avoids having to
    maintain two separate code bases for the batch and speed layers. When processing
    on real-time and historical data are the same, a Kappa Architecture must be used.
    Fast Data Architecture is a variant of Kappa Architecture in which the data are
    no longer read from files but from an additional mechanism like Kafka that captures
    multiple streams combines them before being processed by the speed layer (Lakhe,
    2016). Persico et al. achieved a benchmark of Lambda and Kappa architectures and
    show that Lambda outperforms Kappa for social networks data (YFCC100M) processing
    (Persico et al., 2018). Table 8. Table 8. Pros and Cons of Kappa Architecture.
    Pros Cons - Very efficient for real-time processing thanks to in-memory processing.
    - Batch processing emulates thanks to micro-batch treated via the real-time way.
    - Optimized cost because allows real-time and batch processing. - Not able to
    process large batch size. - Must be finely tuned from data to obtain the best
    performances (Nkamla Penka et al., 2021). Other Architectures derived or inspired
    of the previous architectures have been developed to address specific problems
    such as (1) SMACK (Estrada and Ruiz, 2016) which attempts to propose an optimal
    architecture with fixed components; (2) Liquid (Fernandez et al., 2015) is an
    architecture which provide low latency, incremental processing, high available
    with isolated resource, and able to store high throughput data at low operational
    cost architecture; (3) Butterfly (Lakhe, 2016) proposes to unify batch, speed
    and serving layers in a unique platform in which data are organized as a collection
    of three types of abstractions; (4) Zeta (Scott, 2015) which integrates a lambda
    architecture with business aspect of the enterprise; (5) BRAID (Giebler et al.,
    2018) is a hybrid processing architecture where all coming data and configuration
    file of processing, and eventually processing results written back are stored
    in a shared storage; (6) IoT-a (Hausenblas, 2014) is composed of three blocks:
    Ad-hoc queries, a Database, and a Distributed File System; (7) Polystore (Meehan
    et al., 2016) implements a multiple database system PostgreSQL, SciDB and Accumulo
    because a database alone cannot store all types of data efficiently. Table 9.
    Table 9. Qualitative evaluation of cloud-centric architecture. Criterion Batch
    Stream Lambda Kappa User Proximity * * * * Latency & Jitter * * * * Network Stability
    * * * * High throughput *** *** *** *** Reliability *** *** *** *** Scalability
    *** *** *** *** Cost Effectiveness *** *** * ** Maintainability *** ** * ** The
    analysis of the literature achieved shows that two major generic architectures:
    Kappa and Lambda allows to address of various use cases and are widely implemented
    and proven in other domains of the Internet of Things. The Lambda is more expensive
    to implement than the Kappa because of the need to maintain two separate parallel
    processing branches for stream processing and batch processing. It is interesting
    if different processing are carried out on the two processing branches. Otherwise,
    a Kappa architecture with a single processing branch that processes both the streams
    and the data in batches is more appropriate in most cases because it is cheaper
    and easier to maintain because a single code performs both types of processing
    (stream and batch). Looking at our first two research questions, we observe that
    Lambda and Kappa cloud architectures are efficient but these architectures alone
    operating in central cloud cannot address, for example, use cases where very low
    latencies are required. They will have to be hybridized and completed to address
    these particular cases. Two possibilities are available to us. The first way consists
    in associating several specialized cloud platforms to make it possible to obtain
    greater genericity or at least to better cover a domain. The second consists of
    supplementing the cloud-centric architectures that we have just mentioned with
    other architectural elements in order to better address the specific needs of
    Agriculture 4.0. 4.2. Extension of the cloud paradigm With the increase of the
    amount of data produced by the myriad of connected things, the amount of data
    to process, to transfer by network, and to treat in the cloud computing have called
    into question the architecture of storage and data processing. To solve the problem,
    two ways have been proposed, the first is Multi-Cloud Computing, the objective
    of which is to ensure redundancy in order to improve latency. The second is the
    Federated Cloud with the aim of pooling resources for better use. Multi-Cloud
    Computing (MCC) (Manyika and Chui, 2015) is an extension of Cloud Computing paradigm
    where services are distributed on multi-clouds. In this architecture the workflow
    is distributed entirely in the cloud, data redundancy is also verified. One advantage
    of the MCC is the high recovery rate but it has the same disadvantages as Cloud
    Computing, along with complexity and portability issues. Kazim et al. proposed
    a framework to deliver IoT services and establish cooperation across multi-clouds.
    An authentication allows communicating cloud to authenticate each other cloud
    dynamically. While a service selects the best IoT service matching with user requirements
    among multiple clouds and taking into account the SLA parameters agreed between
    the user and the provider (Kazim et al., 2018). Federated Cloud (FC) aggregates
    resources of multiple cloud providers to improve users’ freedom and allows users
    to choose where they want to deploy their applications. A Federated cloud can
    be defined as a voluntary collaboration between heterogeneous cloud providers
    collaborating to share their own unused resources. Using a cloud federation helps
    to ensure service performance during load ups with resources borrowed from other
    clouds. In addition, the geographical dispersion of the installations makes it
    possible to migrate to another installation and to guarantee the service in case
    of breakdown. A unified interface allows to use it an easy consultation of the
    offered services. Finally, thanks to the dynamic distribution of the load, it
    is possible to bring the treatment closer to the user and consequently improve
    the Quality of Service (Assis and Bittencourt, 2016). Cloud federations include
    European Federated Cloud (Sipos et al., 2013), Massachusetts Open Cloud, Mosaic
    (Petcu et al., 2013), IEEE P2302, and Open stack Keystone. Drakos et al. described
    agINFA, a common research data infrastructure for agriculture, food and the environment
    using EGI Federated Cloud. This infrastructure allows to partner to share research
    infrastructure components, APIs, a registry of web-based information service and
    dataset for agriculture (Drakos et al., 2015). 4.3. Distributed architectures
    The post-cloud approaches allow to improve latency and jitter for immobile entities
    but do not provide an answer adapted for mobile devices and local awareness. The
    large amount of data generated at the edge has increased the speed of data transportation
    that is becoming the bottleneck for the cloud-based computing paradigms (Shi et
    al., 2016). Moreover, the treatment of data in the cloud does not offer any guarantees
    about privacy, on the response time and real-time actuation because the huge number
    of devices increases the latency and jitter. Moreover, the mobility of devices
    and power constraints makes the communicaion difficult with the cloud all the
    time (Botta et al., 2016, Zhou et al., 2017). The aim has been to bring data storage
    and processes data, filtering, and data analysis closer to data-producing objects
    to limit bandwidth consumption and relieve the cloud. Three major paradigms have
    been proposed to address these issues and bring cloud computing-like capabilities
    to the edge of the network. All these infrastructures manage mechanisms of Virtual
    Machine (VM) or containers migration and adjust if needed, the provisioning of
    capabilities where users are located. Moreover, the three paradigms allow the
    creation of federated infrastructures in which can coexist multiple edge infrastructures
    which can exchange information and services (Roman et al., 2018). 4.4. Elements
    of distributed architectures In order to always bring closer, the processing capacities
    of intermediate processing have been set up between connected objects and the
    cloud at the network level (Fog Computing) and at the level of telephony providers
    (Mobile Edge Computing). Fog Computing is a concept created by Cisco Systems and
    is an extension of the cloud computing paradigm (Munir et al., 2017) in which
    computation, storage and network services are provided between end devices and
    cloud/ classify and analyze the raw IoT data streams at near-edge and edge network
    level (Cisco, 2018). Fog nodes are either physical components such as gateways,
    switches, routers, servers etc. or virtual components such as virtualized switches,
    virtual machines, cloudlets, etc.; deployed following private, community, public
    or hybrid. Private nodes are reserved for a single organization, community nodes
    are used by a community, public nodes are dedicated to the general public, and
    hybrid mix the third previous modalities (Uehara, 2017). This paradigm allows
    to limit data transfer on cloud, reduce latency (Sethi and Sarangi, 2017), and
    jitter thanks to a three-tier architecture (Roman et al., 2018). In this hierarchical
    architecture, the analysis of local information is achieved at the low level and
    the coordination and global analysis are performed at the top level. The Fog Computing
    supports mobile devices (Sethi and Sarangi, 2017), response time in real-time
    or predictable latency (Lopez et al., 2015), bandwidth saving, an improving of
    security and resilience, scalability, multi-tenancy, advanced analytics, and automation
    (Byers, 2017), cost-effective services (Yang, 2017). Fog Computing allows also
    the federation of fog infrastructures in order to allow cooperation between multiple
    organizations (Roman et al., 2018). Furthermore, the architecture is optimized
    for a use case and applications which must run on them (Byers, 2017). Fog Computing
    differentiates from cloud computing mainly by the proximity with end-users at
    the edge of networks localized or distributed geographically consisting in many
    relatively less resourceful (Munir et al., 2017). In addition to network equipment,
    fog computing can also be carried out in cloudlets and micro data centers. Cloudlets
    were proposed to address the end-to-end responsiveness between mobile devices
    and associated clouds. Cloudlets (Mach and Becvar, 2017) are micro data center
    geographically deployed in vicinity of End Users. This mobility-enhanced small-scale
    cloud data center is composed of computers with high computation power which provide
    both computation resources and storage. Cloudlet is much more agile (highly dynamic
    provisioning) than cloud due to user mobility churning. The mobility of users
    implies the use of a virtual machine to rapidly instantiate compute-intensive
    and latency-intensive applications and migrate the offloaded services between
    different cloudlet in the function of the user mobility. Cloudlets must be firstly
    discovered, selected among several candidates before starting provisioning. At
    the end of the session, the instance is destroyed (Ai et al., 2018). Cloudlets
    are accessed by mobile user equipment via Wi-Fi imply a high latency caused by
    the network and switch between mobile network and Wi-Fi and by consequence Quality
    of Service (QoS) and Quality of Experience (QoE) are hard to fulfill (Mach and
    Becvar, 2017, Manyika and Chui, 2015). Moreover, Cloudlets cover usually a small
    region and do not offer any guarantee on ubiquitous computing and scalability
    in service (Manyika and Chui, 2015). MicroData Centers (MDCs) were proposed by
    Microsoft Research. It is designed to extend cloud data centers as cloudlets.
    MDCs are enclosures contemning all types of equipments (computing, storage, network)
    needed to provide a secure computing environment in order to run customs applications
    requiring low latency. MDCs are also well adapted to provide processing resources
    to end devices on battery or with limited computing capabilities. MDCs can be
    adapted in function network bandwidth and user needs thanks to certain flexibility
    in terms of latency and scalability of the capacity (Wang et al., 2020). Guardo
    et al. proposed a framework composed of two fog layers respectively filtering
    and aggregating data, and clustering analysis, actuation management, and alert.
    The framework aims to improve computational load balancing between fog and cloud
    in order to reduce the amount of data to transmit to the cloud, reduce the waiting
    time for the user (Guardo et al., 2018). Taneja et al. proposed a SmartHerd an
    IoT platform dedicated to smart dairy farming based on microservices and Fog-assisted.
    The IoT gateway received data from transceivers, archived data aggregation, preprocessing,
    classification, feature selection, send critical alerts to farmers, and transmit
    data to IBM Watson IoT platform via MQTT protocol. In the IBM Watson IoT platform,
    a broker picks up data and store them in a Cloudant NoSQL JSON Database. Python
    Virtual Machine and Java Virtual Machine were used as containers equivalent for
    microservices deployment at fog level (Taneja et al., 2019). Sharofidinov et al.
    described a 4 layers architecture (Sensors Layers, Fog Layer, Network/Cloud Layer,
    and Application Layer) based on LoRa to monitor and predict the state of a greenhouse
    from a random forest algorithm. In the Sensor Layer, sensors acquire temperature,
    soil and air humidity, CO2 rate, and illumination connected to TTGO LoRa32 (ESP32
    with LoRa Sx1276 chip) which are transmitted to the gateway by LoRa. At Fog Layer,
    preliminary analysis with Machine Learning algorithm, diagnosis of sensor status,
    and data compression are achieved. In the Network/Cloud Layer, compressed data
    are transmitted in order to be deeply analyzed and stored. Finally, in the Application
    Layer, analyzed data are converted in readable form to allows the monitoring and
    the control of the greenhouse (Sharofidinov et al., 2020). Table 10. Table 10.
    Pros and Cons of Fog Computing. Pros Cons - Fast response time in avoiding transmission
    of data to the cloud (Sharofidinov et al., 2020). - Failure or outage of the gateway
    can defeat thousands of devices. - The local storage and processing capabilities
    prevent data loss and outages when the Internet connectivity is limited (Sharofidinov
    et al., 2020). - The limited processing and memory capacities do not allow the
    deployment of algorithms requiring significant resources or the carrying out of
    long-term processing. - Sensitive data can be filtered locally. In this case,
    only the data model is moved in the cloud (Sharofidinov et al., 2020), and data
    validation, compression, and encryption. - Gateway at fog level ensure the compatibility
    between old and modern devices (Sharofidinov et al., 2020) and various protocols
    for communication. - Improve the resilience thanks to the decentralization of
    the treatment on network devices (Sharofidinov et al., 2020). Mobile Edge Computing
    (MEC) was proposed by ETSI and is deployed by telecommunication companies on the
    edge of the network, which is characterized by ultra-low latency and high bandwidth.
    (Roman et al., 2018, Zhou et al., 2017). At the very beginning, Mobile Edge Computing
    (MEC) aims to bring real-time, high-bandwidth, and low-latency access to dependent
    applications known as cloud computing capabilities; in addition to, information
    technology (IT) features of cloud computing. MEC is distributed at the edge of
    the network. In fact, a new class of cloud-native applications are easily accessible,
    because of the close position of Edge Computing to the end user and apps. Also,
    it allows network operators to open their environment to a new ecosystem. As a
    result of this significant change, MEC application can be used in LTE macro base
    stations (eNBs), 3G radio network controllers (RNCs), Wi-Fi access points, edge
    network routers, and enterprise edge servers. MEC platform contains two main hosting
    infrastructures. The first is formed by hardware resources and a high-resolution
    screen. The second is composed of manageable applications with numerous capabilities
    such as the application of virtualization manager and platform services (Zhou
    et al., 2017). An important challenge for the MEC is the VM migration that must
    optimize the tradeoff between migration gain and migration cost and select optimal
    location (Ai et al., 2018). Tran et al. investigated the collaborative Mobile
    Edge Computing in 5G Networks. MEC extends processing and storage resources at
    the edge of the Radio Access Network (RAN) while C-RAM is based on centralization
    of the base Station by means of the virtualization. Authors argue that both technologies
    are complementary in the 5G ecosystem (Tran et al., 2017). Fig. 5 Table 11. Download
    : Download high-res image (172KB) Download : Download full-size image Fig. 5.
    Mobile Edge Computing General Scheme. Table 11. Pros and Cons of MEC. Pros Cons
    - Reduces needs in connection, response time delay, the congestion of other parts
    of the network (Valecce et al., 2019). - Usable only for devices connected in
    Wi-Fi or 3GPP. - Use low level message from Wi-Fi to determine the location of
    each device (Location awareness) (Valecce et al., 2019). - MEC Server can be used
    as power open to applications and services (Valecce et al., 2019). Fan et al.
    combined MEC with data link management, combining with the industrial CAN bus
    characteristics to monitor water. Field Programmable Gate Arrays (FPGA) Altera
    implementing the AVALON bus was used to implement the system. Moreover, they propose
    a protocol to model random network disturbances and an online task offloading
    algorithm based on the monitoring of task execution (Fan and Gao, 2018). Valecce
    et al. proposed a 5G-robotics reference architecture for smart agriculture composed
    of UAV-Based Monitoring and connectivity, Machinery automation, and MEC Applications
    Server. UAVs/satellites capture high-resolution images during patrolling, which
    coupled with sensors data trigger a precise crop management. UAVs can also collect
    data or serve as a 5G mobile station. In field, image processing coupled with
    sensors data can be used for decision making. MEC allows to process gigabyte/s
    of data produced by autonomous vehicles and robots (Valecce et al., 2019). Table
    12. Table 12. Evaluation of distributed architecture with our criteria. Criterion
    Fog MEC User Proximity **(*) *** Latency & Jitter * * Network Stability *** **
    High throughput ** **(*) Reliability *** ** Scalability * * Cost Effectiveness
    ** ** Maintainability ** ** The development of fog computing and its counterpart
    for MEC wireless networks allow processing capabilities closer to users to improve
    response time but with lower computational capacities compared to the cloud. There
    are inherently two questions: Which association strategies to use between the
    cloud and the other levels of processing in the network? How to distribute the
    load between these different levels: local (Edge), network (Fog), and Cloud processing.
    4.5. Collaborative computing strategies In order to address, our fourth research
    question, we try to identify different possibilities to compose architectural
    elements. Indeed, different collaboration strategies between the different levels
    of data processing (cloud, fog, edge) can be considered depending on the particularities
    of the use cases. In the next paragraphs, we describe possibilities of collaboration
    between different treatment entries, and we illustrate each one with few examples.
    Edge-Cloud aims to connect devices directly with the cloud that performs data
    processing. This strategy is often used by UAVs and UGVs which preprocess data
    before its transfer to the cloud because image treatment needs processing power
    and storage capabilities. The default of this approach is that the delay of the
    whole process from data transfer via high throughput wireless or cellular protocol
    to the transmission of processing results cannot be guaranteed because of the
    fluctuation of data rates linked to wireless networks (Wang et al., 2020). The
    processing of data can be achieved in an online mode with a real-time data transmission
    and processing by a stream, Lambda, Kappa or derived architecture of these one.
    An offline strategy with a data transfer by means of a computer and Internet connection
    on the cloud after the UAV fly and processing with a Batch, a Lambda, or a Kappa
    architecture or a derived architecture of these one is also possible. This latter
    costly avoid data transmission and is suitable for monitoring crops or livestock
    that do not require direct action. Agriculture 4.0 uses in particular Unmanned
    Aerial Vehicles (UAVs) equipped with various sensors in order to improve the time
    of data collection, in reducing the cost of acquisition compared to traditional
    field phenotyping technologies. According to Tang et al., edge-cloud is majorly
    used in smart robots to reduce complexity (Tang et al., 2021). Indeed, the images
    of drones to be used must be orthorectified and assembled. These operations require
    significant resources in terms of computing power, and memory. All these collected
    data must be rapidly processed, analyzed, and visualized. Agroview (Ampatzidis
    et al., 2020) is a platform that developed a cloud and AI-based application to
    survey and assess the agriculture field, deployed on Amazon Web Services (AWS).
    A website allows the upload of images or existing orthomosaic, the consultation
    for each tree field e.g., number of trees, tree gaps count, area of the field,
    the average height of trees, canopy area, etc. The website also allows the stitching
    of an orthomosaic and the generation of a Digital Surface Model (DSM). A tree
    detection algorithm developed in C allows the detection of individual tree and
    tree gap, and estimate tree parameters such as height, canopy area, health/stress
    estimation. The pipeline of treatment uses a Faster R-CNN to detect the region
    of interest (ROI) and the ResNet101 network allows to detect trees and row orientation.
    Afterward, the Yolo classifier using Darknet19 was applied along each row of trees
    to obtain a more precise detection. Debauche et al. presented an Edge-Cloud architecture
    for the analysis of cattle behavior from 9-DOF IMU data sampled at 100 Hz and
    GPS location sampled at 0.5 Hz that is then processed with an algorithm proposed
    by (Andriamandroso et al., 2017) in batch processing (Debauche et al., 2019, Debauche
    et al., 2020). Popescu et al. proposed an integrated system UAV-WSN-IoT where
    WSN data is collected by UAVs before their transmission to the ground control
    station and afterward to the cloud (Popescu et al., 2020). Debauche et al. proposed
    an architecture for scientific research dedicated to honeybee Colony Collapse
    Disorder. In this architecture, data is compressed on LoPy at the edge level before
    its collection by the LoRaWan gateway and its transmission to the Lambda architecture
    in the cloud where it is processed (Debauche et al., 2018). Edge-Fog aims to connect
    devices directly with network components such as gateways, routers that perform
    data processing. The major benefits of this approach are an optimization of the
    bandwidth, a reduction of traffic and latency, a better privacy, and an improved
    security level (Badidi, 2020). Fog nodes collect, aggregate, filter, encrypt,
    compress, and process IoT data (Gupta et al., 2020). This way is used for example
    by milking robots where data are processed by a computer close the robot and can
    be viewed remotely by the farmer. 5G also promotes mobile edge computing (MEC).
    Debauche et al. presented an AI-IoT architecture for the deployment of Artificial
    intelligence algorithms and Internet of things services at fog level using docker
    containerization and Kubernetes orchestration. This architecture has been developed
    to automatically deploy AI algorithms after retraining when performances (accuracy,
    recall, precision) are improved (Debauche et al., 2020). Debauche et al. proposed
    a Multi-Agent System (MAS) deployed at edge level allowing to control abnormal
    data present in sensed data and eventually cure this data when it is possible.
    The MAS simultaneously manages pivot irrigation, plant diseases and pests'' detection,
    and their curation. The data is partially transmitted to the cloud to improve
    the detection of diseases and pests and retrain AI algorithms before their redeployment
    at the edge level (Debauche et al., 2020). Debauche et al. described a fog architecture
    in which a Gated Recursive Unit (GRU) algorithm is deployed on NVIDIA Jetson Nano
    for real-time poultry monitoring. GRU is simpler than LSTM algorithm. GRU is built
    to avoid varnish gradient problems. Periodically data is transmitted to the user
    interface implemented in NodeJS in the cloud (Debauche et al., 2020). Edge-Fog-Cloud
    is a paradigm in which data are partially processed in the fog and more complex
    treatments are achieved in the cloud. This way is used by wireless Sensor and
    Actuator Network (WSAN), which passes through a gateway that provides interconnection
    between the devices and the backhaul which transit then data to the cloud. However,
    the right balance between cloud and edge/fog computing is required (Badidi, 2020)
    based on available resources and whether or not the task is sensitive. Taneja
    et al. used a strategy Edge-Fog-Cloud to develop a detection system of lameness
    for cattle. The data from the pedometer is transmitted to the Fog node by means
    of a Long-Range proprietary protocol at 433 MHz on a distance of 2 km. Fog node
    stores in local database, preprocess and aggregates them. Fog node communicates
    with IBM Watson IoT Platform with MQTT protocol. Arriving data are picked up and
    stored in Cloudant NoSQL JSON database in IBM cloud. A mobile application synchronizes
    data with PouchDB, its local database via the REST API of Cloudant database when
    an Internet connection is available (Taneja et al., 2020). Alonso et al. presented
    Global Edge Computing Architecture (GECA), a modular tiered architecture (IoT
    Layer, Edge Layer, Business Solution Layer) to monitor dairy and feed grain state
    in real-time. In this architecture, a Distributed Ledger Technologies provides
    security from IoT Layer to Business Solution Layer. In the IoT layer, a set of
    agents call oracles to verify incoming data and afterward calculate hash of data
    with SHA-256 which is stored in the blockchain to verify the non-alteration of
    data. In parallel data is encrypted with the RSA algorithm and then sent to the
    Edge layer. The Edge Layer is responsible of the preprocessing of data and filters
    out data transmitted to the cloud. It enables also various data analyses. In the
    business Solution Layer, final storage, authentication, analysis for decision
    making is achieved. It provides also a knowledge base and APIs (Alonso et al.,
    2020). Edge-Edge is a paradigm in which devices interact to collaborate, exchange,
    and process data. The deployment of the 5G network allows the interconnection
    between UAVs and UGVs/ agricultural machinery (Tang et al., 2021). This high throughput
    network will allow to developping new collaboration between UAVs/ UGVs and agricultural
    machinery, for example, a drone will provide information to a harvester to avoid
    a non-desirable area of the field or avoid obstacles. A fleet of drones can also
    collaborate to coordinate their operations on the field between them of course
    subject to availability in rural areas, a transmission network with sufficient
    bandwidth and short-latency or capabilities to communicate between them in direct
    connection or in a mesh network. (Tang et al., 2021). Four cooperation strategies
    have been identified, two of which use the cloud, namely Fog-Cloud and Edge-Cloud.
    The other two remaing, do not involve the cloud; namely, Fog-Edge, and Edge-Edge
    cloud. The first two strategies complement the cloud to help us to address issues
    relating to production data and trade secrets, network congestion, and response
    times. The other two strategies do without the cloud and therefore assume that
    the devices/ vehicles have sufficient capacity to perform the processing. Despite
    these cooperation strategies between different levels of processing, some questions
    remain unanswered: How to store all the raw data when the data is so important
    that it would take colossal means to process it? What about security? How to organize
    the distribution of tasks between the edge, the fog, and the cloud? How to ensure
    operation and/ or treatment when network connections are intermittent or faulty?
    How to improve the maintainability of these architectures? These are the questions
    that the new trends that we describe in the next paragraph attempt to answer.
    5. New trends In this section, we present two emerging architectures not based
    on the batch or/and real-time architectures or their derivatives. Afterward, we
    describe Osmotic and Dew computing as two new paradigms, which allow us to respectively
    choose where the processing must be achieved and improve the user experience.
    New trends are additional elements that allow enriching the analysis of Section
    4 in order to address the third research question. The Microservices Architecture
    (MA) is a new system software design pattern that divides complex monolithic application
    in micro services dedicated for a single function. Microservice addresses defects
    of monolithic applications in which improving of service performance needs multiple
    deployment; a change in a function can affect all the monolith due to high dependencies
    between components; all the monolith uses a sole technology stack and development
    standards which limits possibilities to solve problems of physical heterogeneity.
    The advantages of this architecture are using a lightweight communication mechanism
    to interact between services with a minimal overload (Sun et al., 2017). The design
    proposed by (Sun et al., 2017) is composed of 8 microservices (Geo, Security,
    Tenant, Devices, Big Data, Automation, AI, and Application) and a core service
    coordinating. These services provide respectively: (1) Geo, a GIS layer to render
    data; (2) Security, user/group/role management, access control, administration,
    and authentication mechanism; (3) support for multiple IoT applications with a
    single core; (4) device plugins and communication protocols for sensing and actuating;
    (5) scalable persistence to store data; (6) process, analyze events and notify
    appropriate participant; (7) Artificial intelligence tools for IoT big data; (8)
    components to interact with client interfaces; (9) support for data exchanging
    by message with the devices. Authors argue that their approach is more flexible,
    scalable and platform-independent. Fig. 6 Table 13. Download : Download high-res
    image (189KB) Download : Download full-size image Fig. 6. Microservices Architecture
    General Scheme. Table 13. Pros and Cons of Microservices Architecture. Pros Cons
    - Fractionating of monoliths facilitates the maintainability and scalability of
    low coupled microservices. - Need to find microservice adapted with needs. - The
    discovery of micro-services allows the development new applications more easily
    than with monoliths. Fraction complex monolith is not easy. - More resilient,
    when a microservice is down, all others continue to function. Bixio et al. proposed
    a stream processing architecture event-driven based on proxy, adapter, and data
    processing microservices. This architecture extends the IoT platform Senseioty
    and using the Java OSGi framework (Bixio et al., 2020). The Data Lake Architecture
    (DLA) (Fang, 2015, Miloslavskaya and Tolstoy, 2016) enables the storage of large
    volumes of data of all types: raw data in its native format, structured, semi-structured,
    in a cost-effective manner. In this architecture, data is stored in its native
    format until it needs to process them by engines (Miloslavskaya and Tolstoy, 2016),
    which allows a fast transformation and refinement of stored data regardless of
    the amount of data stored. The architecture makes it possible to consume all types
    of data (logs, web services, database, files, etc.); different ingestion systems
    consume the data and then stored it in data repository. Once the data is stored,
    query systems can query the data lake. This architecture is considered in the
    corporate world as an evolution of existing architectures. The advantage of the
    Data Lake architecture is that it can easily and inexpensively store large amounts
    of data. It is particularly well suited to storing data in a typical format. In
    Enterprise Data Lakes are used; in addition to, data warehouses. Data lakes are,
    however, unsuitable for assessing data quality, data can be placed in data lakes
    without content control, and performance is also poorer than on specially designed
    and optimized infrastructures. The Lakehouse is a variant of the Data Lake where
    storages of data are generally achieved with Hadoop in the data lake is replaced
    by a distributed storage such as Amazon S3, Azure Blob Storage, Google Cloud Storage,
    and analysis are directly achieved by infrastructure managed by Cloud Service
    Providers such as Amazon Athena, EMR, or Databricks, Google Data proc, Azure HDInsight.
    The Fig. 7 provides a comparison between data lake and gatehouse structure. Download
    : Download high-res image (264KB) Download : Download full-size image Fig. 7.
    Data lake and Lakehouse General Scheme. It crucial in agriculture to explore datasets
    from different sources. The data lake is indicated to manage the complexity of
    agricultural ecosystems and centralized all data sources to find new correlations.
    (Madera et al., 2017). A data lake provides views based on metadata. It is nevertheless
    necessary to have advanced analysis tools for predictive modeling and statistical
    analysis. López et al. used a data lake to achieve the fusion of data from different
    domains in smart the agriculture context (López et al., 2020). Gallinucci et al.
    (Gallinucci et al., 2019, Gallinucci et al., 2020) present an innovative architecture
    3 tiers architecture, called Mo.Re.Farming (MOnitoring and REmote system for a
    more sustainable FARMING) based on a data lake using Apache Hadoop and storing
    structured, semi-structured, and unstructured raw data, and in which subsequent
    processing and enrichment activities are separated. An Operational Data Store
    (ODS) using PostgreSQL with PostGIS to stores structured and detailed data and
    address limitations of big data solutions in properly handling continuous field
    geographic data. Finally, a spatial cube enables Spatial OnLine Analytical Processing
    (SOLAP). Neves et al. described an architecture in which raw data is stored in
    a datalake. Then, ETLs transforms data to be storable in a database. The data
    is enriched thanks to a knowledge base and its exploration by data mining algorithms
    (machine learning). The result of processing is filtered to improve the quality
    of structured data (Neves and Cruvinel, 2020). Table 14. Table 14. Pros and Cons
    of Datalake/DataHouse. Pros Cons - Store the data in its raw form without transforming
    them immediately. - Availability of results depend of the ingesting speed by processing
    services. - Allow store massive low-value data without investing energy to transform
    and store them in a database. - Data analysis by sampling does not give exact
    results but is estimated. - Provides a solution to situations where the volume
    of data is so large that it can no longer be processed immediately - Data House
    may be limited by the services offered by cloud providers for data analysis. Osmotic
    Computing (OC) (Villari et al., 2016) is a new paradigm inspired by the chemical
    osmosis process that corresponds to a dynamic and bidirectional flow of microservices
    between cloud and edge. OC exploits container-based solution to allows an automatic
    deployment of portable, mobile, and cross-platform microservices between Edge
    and cloud levels (Villari et al., 2016). Osmotic computing introduces the concept
    of Micro Elements (MELS) which decouples user data and applications in Micro Services
    (MS) i.e. a docker container and Micro Data (MD) i.e. an entity self-explicative
    in JSON. MS associates one operating system (Micro Operation Service) with an
    application (Micro User Service) while MD associates a microservice configuration
    (Micro Operational Data) and User data (Micro User Data). These MELS can be deployed
    on Microcontrollers (MCU) or Multiprocessor (MPU) (Villari et al., 2017). Table
    15. Table 15. Pros and Cons of Osmotic Computing. Pros Cons - Micro Element (microservice  +
    micro dataset) easy to migrate between fog and cloud. - All datasets are not decomposable
    in micro dataset. The bidirectional migration of microservices between Edge and
    Cloud must, on one hand, avoid application breakdown and QoS degradation and on
    the other hand manage them dynamically, in high heterogeneously physical resources
    context, in the function of infrastructure and applications requirements (Villari
    et al., 2016). Carnevale et al. have applied osmotic computing to the Internet
    of Things by means of a distributed multi-agent system. Each agent is self-orchestrated,
    works independently, and manages the workflow as a composition of MELs. It monitors
    the overloading state of microservices by means of response time metric and decides
    to relocate them to another agent based on a Deep Reinforcement Learning algorithm
    or Time Series Analysis (Carnevale et al., 2019). Fig. 8, Fig. 9. Download : Download
    high-res image (119KB) Download : Download full-size image Fig. 8. Micro Element
    Structure. Download : Download high-res image (357KB) Download : Download full-size
    image Fig. 9. Osmotic Computing General Scheme. In an IoT context, OC allows to
    deploy lightweight micro services at edge level while complex micro services are
    deployed at fog/cloud level, and balance load between edge, fog, and cloud. (Maksimović,
    2018). Morshed et al. proposed to use OC to distribute Deep Learning across edge,
    cloud, and mobile edge in a holistic way (Morshed et al., 2017). However, Kaur
    et al. in their Osmotic Computing applications survey have identified the need
    of standardization in terms of infrastructure deployment and micro-services distribution.
    The orchestration is crucial to manage efficient services. Security remains an
    important challenge because the service migration is supported by different layers
    (Kaur et al., 2020). Dew Computing (DC) (Skala et al., 2015) allows to further
    improve response times by pushing from Central cloud to end-users, computing applications,
    data, and low-level services. Client microcomputers are used to store a part of
    the data locally in the background and to limit access to the cloud, reduce network
    dependency and drastically reduce processing cost (Skala et al., 2015). Dew computing
    is the additional piece of cloud computing. It is mainly composed of a wide range
    of heterogeneous devices and varied equipment ranging from smartphones to smart
    sensors (Wang, 2016). DC is highly and effectively capable in terms of scalability
    and ability to perform sophisticated operations and to process numerous applications
    and tools. Additionally, the equipment of DC is ad hoc programmable and self-adaptive.
    They have the qualifications to running the process within another process in
    a distributed way without a focal communication network (Skala et al., 2015).
    Applications running in the on-premises computers provide services to users and/or
    devices independently of the cloud but collaborating with cloud services (Wang,
    2016). DC can provide access web fraction without Internet connection (WiD), Storage
    in dew has a cloud copy (STiD), Local database has a cloud backup (DBiD), Software
    ownership and settings have a cloud copy (SiD), SDK and projects have a cloud
    copy (PiD), On-premises computer settings and data have a cloud copy (IaD), Other
    services (DiD) (Wang, 2016). The Fig. 10 presents the dew computing in the general
    scheme Cloud-Fog-Edge Computing. Table 16. Download : Download high-res image
    (84KB) Download : Download full-size image Fig. 10. Dew Computing General Scheme.
    Table 16. Pros and Cons of Dew Computing. Pros Cons - Allows access to a local
    copy of data when the connection is unavailable. - Replication of data is bandwidth-consuming.
    - Improve the reliability and the false tolerance. - Difficult to exploit if bandwidth
    is insufficient. Rajakaruna et al. presented a dew architecture based on a drone
    to retrieve and process data, manage WSN, and play the role of dew server. The
    drone communicates with sensors, and actuators with BLE protocol, collect, store
    data, and then when the drone is at the docking station it sends data to the cloud
    (Rajakaruna et al., 2018). Grovers et al. described a reliable and fault-tolerant
    architecture at 4 levels (edge, dew, fog, and cloud) in which sensed data is replicated
    at edge, fog and cloud level in order to take over the application’s control when
    a server is failed. In their architecture, dew servers are closed and linked with
    sensors producing data. The fault tolerance is ensured by mobile agents working
    as a resource exchanging the application and link-state information between us,
    and the network monitoring agent (Grover and Garimella, 2018). The Blockchain
    is a distributed digital ledger of transaction distributed maintained by a network
    of multiple computing nodes. This ledger can be deployed among the IoT nodes network
    (Bermeo-Almeida et al., 2018). In the blockchain, transactions namely blocks are
    managed by a specific software platform ensuring the data transmission, processing
    and storage, and its representation in a human-readable form allowing a consistent
    view and a consensus between the participants (Kamilaris et al., 2019). Different
    mechanisms of consensus whose two main ones are the “Proof of Work (PoW)” and
    the Proof of Stake (PoS). The PoW requires the solving of difficult computational
    tasks before validating transactions and the adding of the block in the blockchain.
    In this approach “miners” are in competition to be the first and obtain the rewards,
    which has an impact on the environment, need expending large a amount of computer
    and energy, and involves a risk of centralization. While the PoS approach, “validators”
    are randomly selected with a probability which depends on the amount of stake
    held. At the end of the validation process, it earns a fee. Other less used consensus
    mechanisms exist such as (1) Proof of Elapsed Time (PoET) in which each node generates
    a random wait time and goes to sleep for that specified duration; (2) Simplified
    Byzantine Fault Tolerance (SBFT), an improvement of Practical Byzantine Fault
    Tolerance (PBFT) specifically designed for blockchain in which each new block
    is maintained by a delegation of nodes with increasing authority. Each one uses
    the internal time to decide when actions must be done; (3) Proof of Authority
    (PoA) in which approved accounts process to the automated validation of transaction
    and blocks. Table 17. Table 17. Pros and Cons of Blockchain. Pros Cons - Data
    distributed (Alonso et al., 2020). - Energy consumption for the complex signature
    verification process can be important. - Immutable, durable, verifiable, secure,
    and transparent (Alonso et al., 2020). - Not adapted to store images, video. -
    Transactions P2P at low cost. The Fig. 11 shows the blockchain general scheme.
    Download : Download high-res image (251KB) Download : Download full-size image
    Fig. 11. Blockchain General Scheme. The block chain is mainly used in Agriculture
    to make the data of the supply chain transparent and open (Bermeo-Almeida et al.,
    2018) and ensure the complete traceability of the food chain from the fork to
    the plate. The block chain allows to record information about: (1) Transactions
    between provider and farmer as well as information relating to the crops, material
    and chemical products; (2) The farm, cultivation practices and management, animals
    feeding, and complementary information such as weather conditions, animals welfare,
    diseases, treatment, etc; (3) Information about factory and its equipment, the
    processing method, batch numbers but also financial transactions with producers
    and distributors; (4) Warehousing, storage conditions (temperature, humidity),
    methods of transport, transit time, and all financial transactions between the
    distributors and retailers; (5) food items information such as quantity available,
    quality, expiration date, time spent on the shelf or in the stock (Bermeo-Almeida
    et al., 2018, Kamilaris et al., 2019). The Fig. 12 shows an example of blockchain
    applied to an agri supply chain. Download : Download high-res image (112KB) Download
    : Download full-size image Fig. 12. Supply chain based on a blockchain. To a lesser
    extent, secured data storage, remote monitoring, and automation. The blockchain
    address some challenges of IoT such as decentralization, data anonymization, and
    security. Moreover, it allows faster and efficient operations, to improve reliability
    and scalability (Bermeo-Almeida et al., 2018). The analysis of new trends shows
    that: (1) Micro service architecture allows decomposing monoliths in microservices
    lowly coupled which makes it easier to maintain it while allowing other services
    to continue operating. Furthermore, this type of architecture is more resilient
    because if one of the services is down, the other services due to the weak coupling
    can continue to operate at least in a degraded mode. (2) Data Lake/DataHouse propose
    a new approach Load Transform Extract (LTE) where data are firstly stored in their
    original format, which are then transformed in order to extract information. This
    paradigm is particularly well adapted when the amount of data is so important
    that process all data is too costly. In this case, data can be sampled in order
    to obtain information. This paradigm is also well adapted if we want to conserve
    also raw data or complete a generic architecture, for example, to store data that
    will be processed in batch processing. (3) Osmotic Computing attempts to propose
    a solution to the repartition of workload between fog and cloud in decomposing
    treatments in microelements composed of a microservice associated with a micro
    dataset. The osmotic computing could also be associated with the micro service
    architecture to allow the distribution of instances of microservices at different
    levels of the network according to their respective load. (4) Dew Computing aims
    to replicate data near sensors or users to continue to store data or allows to
    continue to consult data when connection is intermittent. It allows improving
    the reliance of architectures on connection interruptions. (5) Blockchain provides
    an answer to authentication and security problems by making it possible in particular
    to verify that the data has not been altered or compromised. Nevertheless, it
    is not possible to store large amount of data such as high definitions images,
    or videos in the blockchain but hashes of datasets allowing to verify their authenticity
    well. 6. Towards Agriculture 5.0 According Myklevy et al., the world must improve
    the amount of food produced by 70% by 2050 to produce global food needs for a
    population (Mykleby et al., 2016) of 9.7 billion according to the Food and Agriculture
    Organization of the United Nations (FAO) (Zhang, 2016). To overcome these problems
    and contribute to achieve the second objective of 17 Sustainable Development Goals
    (SDGs) of the United Nations (UN) with a timeframe in the range 2015 to 2030,
    the concept of Agriculture 5.0 has been born (Martos et al., 2021). Agriculture
    5.0 aims to increase production sustainably while consuming fewer resources and
    taking care of the environment. This next wave of agricultural revolution will
    imply the use of robots integrating machine learning to compensate for the shortage
    of workers. Farm robots are drastically increasing productivity in improving the
    human labor workforce and can also harvest a more important volume faster than
    a human. Nevertheless, these early technologies are still too expensive for most
    farmers especially small farms (Saiz-Rubio and Rovira-Más, 2020). Fig. 13 show
    the coupling between Agriculture 4.0 and Agriculture 5.0 and their integration
    in the context of the agri-food supply chain, the Society 5.0 and 17 Sustainable
    Development Goals (SDGs) of United Nations (See Fig. 13). Download : Download
    high-res image (252KB) Download : Download full-size image Fig. 13. Integration
    of the Agriculture 5.0 in the context of the Society 5.0. 7. Conclusion Our review
    is boosted by four research questions dectitaed as follow: (1) Which storage and
    processing architectures are best suited to Agriculture 4.0 applications and address
    its particularities? (2) Can generic architectures meet the needs of Agriculture
    4.0 application cases? (3) What are the horizontal valuation possibilities that
    allow the transition from research to industrialization? (4) What are the vertical
    valuation possibilities to move from algorithms trained in the cloud to embedded
    or autonomous products?. The analysis of the literature shows that a multitude
    of architecture coexists. Nevertheless, the Lambada and Kappa architectures seem
    to emerge as generic architectures. These must generally be accompanied by complementary
    architectural components to address specific needs and be part of a storage and
    processing strategy in which the cloud architecture is a component of the chain
    or may also and more rarely be absent. The traditional centralized cloud computing
    will continue to remain an important part of computing systems (Ai et al., 2018),
    for sciences even if other paradigms appear. Indeed, cloud, fog, and edge computing
    complementary interact with each other to form a mutually beneficial and interdependent
    service continuum. Some functions are naturally more suitable or advantageous
    at a level than another in function of requirements in response time, computing,
    or latency tolerance. However, the cloud cannot be completely replaced by fog
    and edge computing because some computation-intensive tasks can only be processed
    at the cloud level, which has the computing power and storage capacities (Wang
    et al., 2020). In Agriculture 4.0, this is particularly the case for the processing
    of satellite images, the training of artificial intelligence algorithms such as
    Deep Convolutional Neural Network (DCNN). New trends make it possible to address
    various problems: (1) The Data lake/Data House offers a more economical alternative
    to massive cloud storage in databases. In this paradigm, all data are stored in
    a state and transform only when they are to be exploited. This approach is particularly
    interesting on one hand when all data are not exploited and on the other hand
    when a decision or an action is not expected immediately. Data lake also allows
    the fusion of agriculture data from various origins in different formats and granularity.
    (2) The blockchain provides solutions in particular to the security problems,
    the possibility of distributing data storage and ensuring the traceability of
    transactions in agrifood supply chains (3) As the literature has shown, Dew Computing
    can be placed in two different places in the network either as close as possible
    to the sensors to allow processing to continue during transmission interruptions
    or as close as possible to users in order to have a local copy of the data in
    order to be able to consult them offline. It should be noted, however, that for
    the second option, there are other means of local caching at the device level,
    for amounts of data of a few mega as those offered by Progressive Web Apps (PWA)
    by example. (4) Osmotic computing provides a solution to the question of how to
    distribute the load between the different processing levels (edge, fog, cloud).
    It uses the concept of microelement associating a microservice and its micro dataset.
    In addition, osmotic computing can also be associated with micro-service architectures.
    (5) The microservice architecture offers the possibility of decoupling the monolithic
    architectures into weakly coupled microservices. These services can be more easily
    associated, maintained, or evolved independently. The combination of these microservices
    makes it easier to develop new services for the end-user that are also easier
    and faster to evolve according to technological developments and needs. In addition,
    at the network level, the 5G network offers new possibilities in terms of Wireless
    Sensors and Actuators Network (WSAN), communication between machines, UAVs, and
    UGVs. Moreover, the coupling with MEC opens the field of processing close of end-users.
    The SDN/NFV Architecture allows to facilitate the design, and to improve the flexibility
    of network. Software-defined networking (SDN) allows decoupling transmission of
    data and network control functionality while Network function virtualization (NFV)
    abstracts transfer network and related network functions (Friha et al., 2021).
    Two trends in the use of processing architecture coexist, on the one hand, users
    of a paid or open source IoT platform, and on the other hand, users who develop
    specific architectures to implement particular use cases. From the point of view
    of transferability, we understand that it is easier for ready-made chargeable
    infrastructures and that it can be limited for turnkey open-source infrastructures
    where the type of license adopted may pose a problem. However, the sustainability
    of paid infrastructure is conditional on the development granted by the company
    that manages them and on its financial health. The development of architecture
    based on paid software bricks is facilitated but its durability is conditioned
    by the availability and the maintenance of these software bricks. As for transferability,
    it is linked to the acquisition of ad hoc licenses. The development of architecture
    using open source software bricks from foundations such as Apache Foundation makes
    it possible not to be limited by licenses but is dependent on developments and
    maintenance carried out by the community of developers. These software bricks
    can be abandoned by the community, the company that sponsors them, or the foundation
    that hosts them. The development of a sustainable architecture would go through
    an emancipation of software bricks which would make it possible to easily change
    them on the one hand when one of them disappears or if a new more efficient software
    brick appears. The deployment of 5G and satellite Internet will bring in a new
    player, which are the telecommunications companies that will be able to provide
    processing capacities and services as close as possible to users at the level
    of 5G antennas, which will impact processing architectures. The problem will then
    arise of interoperability between the networks of sensors and actuators with these
    new high-speed, low-latency networks. The new networks offered by the telecommunications
    companies will make it possible to offer new services or even to decouple the
    software from the hardware, which will make it possible to make the sensors and
    actuators interchangeable. This should make it possible to reduce the cost of
    the equipment and make it accessible to developing countries or areas not covered
    by traditional LPWAN and 3GPP networks. The impact of these new networks will
    have to be reviewed in the future to identify the new trends offered by 5G and
    satellite Internet. Declaration of Competing Interest The authors declare that
    they have no known competing financial interests or personal relationships that
    could have interfered with overall quality of the work reported in this paper.
    Acknowledgment This research is partially funded by Infortech and Numediart institutes.
    The authors would like to express their gratitude to Dr. Meryem Elmoulat for accepting
    to edit the writing of this paper and to Mr. Fabrice Nolack Fote for his help
    in the elaboration of the conceptual framework. References Agency, 2020 E.G. Agency
    Power-efficient positioning for THE Internet of Things – White Paper European
    GNSS Agency (2020), 10.2759/26127 Google Scholar Ai et al., 2018 Y. Ai, M. Peng,
    K. Zhang Edge computing technologies for internet of things: a primer Digital
    Commun. Networks, 4 (2018), pp. 77-86, 10.1016/j.dcan.2017.07.001 View PDFView
    articleView in ScopusGoogle Scholar Alonso et al., 2020 R.S. Alonso, I. Sittón-Candanedo,
    Óscar García, J. Prieto, S. Rodríguez-González An intelligent edge-iot platform
    for monitoring livestock and crops in a dairy farming scenario Ad Hoc Netw., 98
    (2020), Article 102047, 10.1016/j.adhoc.2019.102047 View PDFView articleView in
    ScopusGoogle Scholar Amazon, 2021 Amazon, 2021a. Amazon dynamodb. url:https://aws.amazon.com/fr/dynamodb/.
    Google Scholar Amazon, 2021b Amazon, 2021b. Amazon web services. url: https://aws.amazon.com/.
    Google Scholar Ampatzidis et al., 2020 Y. Ampatzidis, V. Partel, L. Costa Agroview:
    Cloud-based application to process, analyze and visualize uav-collected data for
    precision agriculture applications utilizing artificial intelligence Comput. Electron.
    Agricul., 174 (2020), Article 105457, 10.1016/j.compag.2020.105457 View PDFView
    articleView in ScopusGoogle Scholar Andriamandroso et al., 2017 A.L.H. Andriamandroso,
    F. Lebeau, Y. Beckers, E. Froidmont, I. Dufrasne, B. Heinesch, P. Dumortier, G.
    Blanchy, Y. Blaise, J. Bindelle Development of an open-source algorithm based
    on inertial measurement units (imu) of a smartphone to detect cattle grass intake
    and ruminating behaviors Comput. Electron. Agricult., 139 (2017), pp. 126-137,
    10.1016/j.compag.2017.05.020 View PDFView articleView in ScopusGoogle Scholar
    Apache Software Foundation, 2021a Apache Software Foundation, A., 2021a. Cassandra.
    url: https://cassandra.apache.org. Google Scholar Apache Software Foundation,
    2021b Apache Software Foundation, A., 2021b. Druid. url: https://druid.apache.org.
    Google Scholar Assis and Bittencourt, 2016 M.R. Assis, L.F. Bittencourt A survey
    on cloud federation architectures: identifying functional and non-functional properties
    J. Network Comput. Appl., 72 (2016), pp. 51-71, 10.1016/j.jnca.2016.06.014 View
    PDFView articleView in ScopusGoogle Scholar AT&T, 2021 AT&T, P., 2021. At&t continues
    to fuel growth of the internet of things with launch of new developer-friendly
    managed service. url: https://about.att.com/story/m2x_data_service_for_enterprise_developers.html.
    Google Scholar Ayaz et al., 2019 M. Ayaz, M. Ammad-Uddin, Z. Sharif, A. Mansour,
    E.H.M. Aggoune Internet-of-things (iot)-based smart agriculture: toward making
    the fields talk IEEE Access, 7 (2019), pp. 129551-129583, 10.1109/ACCESS.2019.2932609
    View in ScopusGoogle Scholar Badidi, 2020 E. Badidi Qos-aware placement of tasks
    on a fog cluster in an edge computing environment J. Ubiquitous Syst. Pervasive
    Networks, 13 (2020), pp. 11-19, 10.5383/JUSPN.13.01.002 Google Scholar Bermeo-Almeida
    et al., 2018 Bermeo-Almeida, O., Cardenas-Rodriguez, M., Samaniego-Cobo, T., Ferruzola-Gómez,
    E., Cabezas-Cabezas, R., Bazán-Vera, W., 2018. Blockchain in agriculture: A systematic
    literature review, in: International Conference on Technologies and Innovation,
    Springer. pp. 44–56. doi:10.1007/978-3-030-00940-3_4. Google Scholar Bixio et
    al., 2020 L. Bixio, G. Delzanno, S. Rebora, M. Rulli A flexible iot stream processing
    architecture based on microservices Information, 11 (2020), p. 565, 10.3390/info11120565
    Google Scholar Blynk, 2021 Blynk, 2021. Blynk iot platform: for businesses and
    developers. url:  https://blynk.io. Google Scholar Botta et al., 2016 A. Botta,
    W. De Donato, V. Persico, A. Pescapé Integration of cloud computing and internet
    of things: a survey Future Generat. Comput. Syst., 56 (2016), pp. 684-700, 10.1016/j.future.2015.09.021
    View PDFView articleView in ScopusGoogle Scholar Byers, 2017 C.C. Byers Architectural
    imperatives for fog computing: Use cases, requirements, and architectural techniques
    for fog-enabled iot networks IEEE Commun. Mag., 55 (2017), pp. 14-20, 10.1109/MCOM.2017.1600885
    View in ScopusGoogle Scholar Carnevale et al., 2019 L. Carnevale, A. Celesti,
    A. Galletta, S. Dustdar, M. Villari Osmotic computing as a distributed multi-agent
    system: the body area network scenario Internet of Things, 5 (2019), pp. 130-139,
    10.1016/j.iot.2019.01.001 View PDFView articleView in ScopusGoogle Scholar Cisco,
    2018 C. Cisco Cisco global cloud index: Forecast and methodology, 2016–2021 Cisco,
    San Jose (2018) Google Scholar Codeluppi et al., 2020 G. Codeluppi, A. Cilfone,
    L. Davoli, G. Ferrari Lorafarm: A lorawan-based smart farming modular iot architecture
    Sensors, 20 (2020), 10.3390/s20072028 url:  https://www.mdpi.com/1424-8220/20/7/2028
    Google Scholar Conesa-Munoz et al., 2016 J. Conesa-Muñoz, J. Valente, J. Del Cerro,
    A. Barrientos, A. Ribeiro A multi-robot sense-act approach to lead to a proper
    acting in environmental incidents Sensors, 16 (2016), p. 1269, 10.3390/s16081269
    View in ScopusGoogle Scholar Corp, 2020 Corp, P.H., 2020. Sensorcloud. url:  https://sensorcloud.com/.
    Google Scholar Debauche et al., 2018 O. Debauche, M. El Moulat, S. Mahmoudi, S.
    Boukraa, P. Manneback, F. Lebeau Web monitoring of bee health for researchers
    and beekeepers based on the internet of things Proc. Comput. Sci., 130 (2018),
    pp. 991-998, 10.1016/j.procs.2018.04.103 View PDFView articleView in ScopusGoogle
    Scholar Debauche et al., 2019 O. Debauche, S. Mahmoudi, A.L.H. Andriamandroso,
    P. Manneback, J. Bindelle, F. Lebeau Cloud services integration for farm animals’
    behavior studies based on smartphones as activity sensors J. Ambient Intell. Humanized
    Comput., 10 (2019), pp. 4651-4662, 10.1007/s12652-018-0845-9 View in ScopusGoogle
    Scholar Debauche et al., 2020 O. Debauche, S. Mahmoudi, M. Elmoulat, S.A. Mahmoudi,
    P. Manneback, F. Lebeau Edge ai-iot pivot irrigation, plant diseases, and pests
    identification Proc. Comput. Sci., 177 (2020), pp. 40-48, 10.1016/j.procs.2020.10.009
    View PDFView articleView in ScopusGoogle Scholar Debauche et al., 2020 O. Debauche,
    S. Mahmoudi, S.A. Mahmoudi, P. Manneback, J. Bindelle, F. Lebeau Edge computing
    and artificial intelligence for real-time poultry monitoring Proc. Comput. Sci.,
    175 (2020), pp. 534-541, 10.1016/j.procs.2020.07.076 View PDFView articleView
    in ScopusGoogle Scholar Debauche et al., 2020 O. Debauche, S. Mahmoudi, S.A. Mahmoudi,
    P. Manneback, J. Bindelle, F. Lebeau Edge computing for cattle behavior analysis
    2020 Second International Conference on Embedded & Distributed Systems (EDiS),
    IEEE (2020), pp. 52-57, 10.1109/EDiS49545.2020.9296471 View in ScopusGoogle Scholar
    Debauche et al., 2020 O. Debauche, S. Mahmoudi, S.A. Mahmoudi, P. Manneback, F.
    Lebeau A new edge architecture for ai-iot services deployment Proc. Comput. Sci.,
    175 (2020), pp. 10-19, 10.1016/j.procs.2020.07.006 View PDFView articleView in
    ScopusGoogle Scholar Debauche et al., 2020 O. Debauche, S.A. Mahmoudi, N. De Cock,
    S. Mahmoudi, P. Manneback, F. Lebeau Cloud architecture for plant phenotyping
    research Concurrency and Computation: Practice and Experience, 32 (2020), Article
    e5661, 10.1002/cpe.5661 View in ScopusGoogle Scholar Debauche et al., 2018 O.
    Debauche, S.A. Mahmoudi, S. Mahmoudi, P. Manneback Cloud platform using big data
    and hpc technologies for distributed and parallels treatments Proc. Comput. Sci.,
    141 (2018), pp. 112-118, 10.1016/j.procs.2018.10.156 View PDFView articleView
    in ScopusGoogle Scholar Debauche et al., 2021 O. Debauche, J.P. Trani, S. Mahmoudi,
    P. Manneback, J. Bindelle, S.A. Mahmoudi, A. Guttadauria, F. Lebeau Data management
    and internet of things: a methodological review in smart farming Internet of Things,
    14 (2021), Article 100378, 10.1016/j.iot.2021.100378 View PDFView articleView
    in ScopusGoogle Scholar Diaz et al., 2016 M. Díaz, C. Martín, B. Rubio State-of-the-art,
    challenges, and open issues in the integration of internet of things and cloud
    computing J. Network Comput. Appl., 67 (2016), pp. 99-117, 10.1016/j.jnca.2016.01.010
    View PDFView articleView in ScopusGoogle Scholar Drakos et al., 2015 Drakos, A.,
    Protonotarios, V., Manouselis, N., 2015. aginfra: a research data hub for agriculture,
    food and the environment. F1000Res. 4. doi:10.12688/f1000research.6349.2. Google
    Scholar El-Sayed et al., 2017 H. El-Sayed, S. Sankar, M. Prasad, D. Puthal, A.
    Gupta, M. Mohanty, C.T. Lin Edge of things: the big picture on the integration
    of edge, iot and the cloud in a distributed computing environment IEEE Access,
    6 (2017), pp. 1706-1717, 10.1109/ACCESS.2017.2780087 View in ScopusGoogle Scholar
    Elijah et al., 2018 O. Elijah, T.A. Rahman, I. Orikumhi, C.Y. Leow, M.N. Hindia
    An overview of internet of things (iot) and data analytics in agriculture: benefits
    and challenges IEEE Internet Things J., 5 (2018), pp. 3758-3773, 10.1109/JIOT.2018.2844296
    View in ScopusGoogle Scholar Estrada and Ruiz, 2016 Estrada, R., Ruiz, I., 2016.
    Big data smack: A guide to apache spark. Mesos, Akka, Cassandra, and Kafka. Google
    Scholar Fan and Gao, 2018 D. Fan, S. Gao The application of mobile edge computing
    in agricultural water monitoring system IOP Conference Series: Earth and Environmental
    Science, IOP Publishing (2018), p. 012015 CrossRefView in ScopusGoogle Scholar
    Fang, 2015 Fang, H., 2015. Managing data lakes in big data era: What’s a data
    lake and why has it became popular in data management ecosystem, in: 2015 IEEE
    International Conference on Cyber Technology in Automation, Control, and Intelligent
    Systems (CYBER), IEEE. pp. 820–824. doi:10.1109/CYBER.2015.7288049. Google Scholar
    Farooq et al., 2019 M.S. Farooq, S. Riaz, A. Abid, K. Abid, M.A. Naeem A survey
    on the role of iot in agriculture for the implementation of smart farming IEEE
    Access, 7 (2019), pp. 156237-156271, 10.1109/ACCESS.2019.2949703 View in ScopusGoogle
    Scholar Feng et al., 2019 X. Feng, F. Yan, X. Liu Study of wireless communication
    technologies on internet of things for precision agriculture Wireless Pers. Commun.,
    108 (2019), pp. 1785-1802, 10.1007/s11277-019-06496-7 View in ScopusGoogle Scholar
    Fernandez et al., 2015 Fernandez, R.C., Pietzuch, P.R., Kreps, J., Narkhede, N.,
    Rao, J., Koshy, J., Lin, D., Riccomini, C., Wang, G., 2015. Liquid: Unifying nearline
    and offline big data integration., in: CIDR, pp. 1–8. url:  http://hdl.handle.net/10044/1/23433.
    Google Scholar Ferrag et al., 2020 M.A. Ferrag, L. Shu, X. Yang, A. Derhab, L.
    Maglaras Security and privacy for green iot-based agriculture: review, blockchain
    solutions, and challenges IEEE Access, 8 (2020), pp. 32031-32053, 10.1109/ACCESS.2020.2973178
    View in ScopusGoogle Scholar Fote et al., 2020 F.N. Fote, A. Roukh, S. Mahmoudi,
    S.A. Mahmoudi, O. Debauche Toward a big data knowledge-base management system
    for precision livestock farming Proc. Comput. Sci., 177 (2020), pp. 136-142, 10.1016/j.procs.2020.10.021
    View PDFView articleView in ScopusGoogle Scholar Friha et al., 2021 O. Friha,
    M.A. Ferrag, L. Shu, L.A. Maglaras, X. Wang Internet of things for the future
    of smart agriculture: a comprehensive survey of emerging technologies IEEE CAA
    J. Autom. Sinica, 8 (2021), pp. 718-752, 10.1109/JAS.2021.1003925 View in ScopusGoogle
    Scholar Gallinucci et al., 2019 E. Gallinucci, M. Golfarelli, S. Rizzi A hybrid
    architecture for tactical and strategic precision agriculture C. Ordonez, I.Y.
    Song, G. Anderst-Kotsis, A.M. Tjoa, I. Khalil (Eds.), Big Data Analytics and Knowledge
    Discovery, Springer International Publishing, Cham (2019), pp. 13-23, 10.1007/978-3-030-27520-4_2
    View in ScopusGoogle Scholar Gallinucci et al., 2020 E. Gallinucci, M. Golfarelli,
    S. Rizzi Mo. re. farming: A hybrid architecture for tactical and strategic precision
    agriculture Data Knowl. Eng., 129 (2020), Article 101836, 10.1016/j.datak.2020.101836
    View PDFView articleView in ScopusGoogle Scholar Garcia et al., 2020 L. García,
    L. Parra, J.M. Jimenez, J. Lloret, P. Lorenz Iot-based smart irrigation systems:
    an overview on the recent trends on sensors and iot systems for irrigation in
    precision agriculture Sensors, 20 (2020), p. 1042, 10.3390/s20041042 View in ScopusGoogle
    Scholar Lopez et al., 2015 Garcia Lopez, P., Montresor, A., Epema, D., Datta,
    A., Higashino, T., Iamnitchi, A., Barcellos, M., Felber, P., Riviere, E., 2015.
    Edge-centric computing: Vision and challenges. doi:10.1145/2831347.2831354. Google
    Scholar Giebler et al., 2018 Giebler, C., Stach, C., Schwarz, H., Mitschang, B.,
    2018. Braid, in: Proceedings of the 7th International Conference on Data Science,
    Technology and Applications, pp. 294–301. doi:10.5220/0006861802940301. Google
    Scholar Google, 2021 Google, 2021. Firebase. url:  https://firebase.google.com/.
    Google Scholar Granell et al., 2017 Granell, C., Miralles, I., Rodríguez-Pupo,
    L.E., González-Pérez, A., Casteleyn, S., Busetto, L., Pepe, M., Boschetti, M.,
    Huerta, J., 2017. Conceptual architecture and service-oriented implementation
    of a regional geoportal for rice monitoring. ISPRS Int. J. Geo-Inform. 6. url:
    https://www.mdpi.com/2220-9964/6/7/191, doi:10.3390/ijgi6070191. Google Scholar
    Grover and Garimella, 2018 Grover, J., Garimella, R.M., 2018. Reliable and fault-tolerant
    iot-edge architecture, in: 2018 IEEE sensors, IEEE. pp. 1–4. doi:10.1109/ICSENS.2018.8589624.
    Google Scholar Guardo et al., 2018 E. Guardo, A. Di Stefano, A. La Corte, M. Sapienza,
    M. Scatà A fog computing-based iot framework for precision agriculture J. Internet
    Technol., 19 (2018), pp. 1401-1411, 10.3966/160792642018091905012 View in ScopusGoogle
    Scholar Gupta et al., 2020 M. Gupta, M. Abdelsalam, S. Khorsandroo, S. Mittal
    Security and privacy in smart farming: challenges and opportunities IEEE Access,
    8 (2020), pp. 34564-34584, 10.1109/ACCESS.2020.2975142 View in ScopusGoogle Scholar
    Hausenblas, 2014 Hausenblas, M., 2014. Internet of things architecture (iot-a)
    home page. url:  https://github.com/mhausenblas/iot-a.info. Google Scholar Iaksch
    et al., 2021 J. Iaksch, E. Fernandes, M. Borsato Digitalization and big data in
    smart farming–a review J. Manage. Anal., 8 (2021), pp. 333-349, 10.1080/23270012.2021.1897957
    View in ScopusGoogle Scholar IBM, 2015 IBM, 2015. Ibm watson iot platform. url:  https://internetofthings.ibmcloud.com/.
    Google Scholar IBM, 2021 IBM, 2021. Ibm cloud. url:  https://www.ibm.com/cloud.
    Google Scholar Influxdata, 2021 Influxdata, 2021. Infludb cloud. url:  https://www.influxdata.com/products/influxdb-cloud/.
    Google Scholar Souces and I., 2021 Integra Souces, I., 2021. Iot solution development
    services. url:  https://www.integrasources.com/iot-page/. Google Scholar Jayaraman
    et al., 2016 P.P. Jayaraman, A. Yavari, D. Georgakopoulos, A. Morshed, A. Zaslavsky
    Internet of things platform for smart farming: experiences and lessons learnt
    Sensors, 16 (2016), p. 1884, 10.3390/s16111884 View in ScopusGoogle Scholar KaaIoT,
    2021 KaaIoT, 2021. Ubidots. url:  https://docs.kaaiot.io/KAA/docs/current/Welcome/.
    Google Scholar Kamilaris et al., 2019 Kamilaris, A., Fonts, A., Prenafeta-Boldv́,
    F.X., 2019. The rise of blockchain technology in agriculture and food supply chains.
    Trends Food Sci. Technol. 91, 640–652. doi:10.1016/j.tifs.2019.07.034. Google
    Scholar Kaur et al., 2020 A. Kaur, R. Kumar, S. Saxena Osmotic computing and related
    challenges: a survey 2020 Sixth International Conference on Parallel, Distributed
    and Grid Computing (PDGC), IEEE (2020), pp. 378-383, 10.1109/PDGC50313.2020.9315757
    View in ScopusGoogle Scholar Kazim et al., 2018 M. Kazim, L. Liu, S.Y. Zhu A framework
    for orchestrating secure and dynamic access of iot services in multi-cloud environments
    IEEE Access, 6 (2018), pp. 58619-58633, 10.1109/ACCESS.2018.2873812 View in ScopusGoogle
    Scholar Khanna and Kaur, 2019 A. Khanna, S. Kaur Evolution of internet of things
    (iot) and its significant impact in the field of precision agriculture Comput.
    Electron. Agricul., 157 (2019), pp. 218-231, 10.1016/j.compag.2018.12.039 View
    PDFView articleView in ScopusGoogle Scholar Kodati and Jeeva, 2019 S. Kodati,
    S. Jeeva Smart agricultural using internet of things, cloud and big data Int.
    J. Innov. Technol. Exploring Eng. (IJITEE), 8 (2019), pp. 3718-3722, 10.35940/ijitee.J9671.0881019
    View in ScopusGoogle Scholar Kreps, 2014 Kreps, J., 2014. Questioning the lambda
    architecture. Online article, July 205. Google Scholar Lakhe, 2016 B. Lakhe Practical
    Hadoop migration: how to integrate your RDBMS with the Hadoop ecosystem and re-architect
    relational applications to NoSQL Apress (2016) Google Scholar Liu et al., 2020
    Y. Liu, X. Ma, L. Shu, G.P. Hancke, A.M. Abu-Mahfouz From industry 4.0 to agriculture
    4.0: current status, enabling technologies, and research challenges IEEE Trans.
    Industr. Inf., 17 (2020), pp. 4322-4334, 10.1109/TII.2020.3003910 Google Scholar
    López et al., 2020 I.D. López, J.F. Grass, A. Figueroa, J.C. Corrales A proposal
    for a multi-domain data fusion strategy in a climate-smart agriculture context
    Int. Trans. Oper. Res. (2020), 10.1111/itor.12899 Google Scholar Luis Bustamante
    et al., 2019 A. Luis Bustamante, M.A. Patricio, J.M. Molina Thinger. io: an open
    source platform for deploying data fusion applications in iot environments Sensors,
    19 (2019), p. 1044, 10.3390/s19051044 Google Scholar Mach and Becvar, 2017 P.
    Mach, Z. Becvar Mobile edge computing: a survey on architecture and computation
    offloading IEEE Commun. Surveys Tutorials, 19 (2017), pp. 1628-1656, 10.1109/COMST.2017.2682318
    View in ScopusGoogle Scholar Madera et al., 2017 Madera, C., Laurent, A., Rouge,
    T.L., Miralles, A., 2017. How can the data lake concept influence information
    system design for agriculture? In: 11th European conference dedicated to the future
    use of ICT in the agri-food sector, bioresource and biomass sector (EFITA 2017),
    pp. 181–182. Google Scholar Maksimović, 2018 M. Maksimović The role of osmotic
    computing in internet of things 2018 17th International Symposium INFOTEH-JAHORINA
    (INFOTEH), IEEE (2018), pp. 1-4, 10.1109/INFOTEH.2018.8345538 View in ScopusGoogle
    Scholar Manyika and Chui, 2015 Manyika, J., Chui, M., 2015. By 2025, internet
    of things applications could have $11 trillion impact. Insight Publications. Google
    Scholar Martos et al., 2021 V. Martos, A. Ahmad, P. Cartujo, J. Ordoñez Ensuring
    agricultural sustainability through remote sensing in the era of agriculture 5.0
    Appl. Sci., 11 (2021), p. 5911, 10.3390/app11135911 View in ScopusGoogle Scholar
    Marz and Warren, 2013 N. Marz, J. Warren Big Data: Principles and best practices
    of scalable real-time data systems Manning (2013) Google Scholar Maureira et al.,
    2011 M.A.G. Maureira, D. Oldenhof, L. Teernstra Thingspeak–an api and web service
    for the internet of things World Wide Web (2011) Google Scholar Meehan et al.,
    2016 J. Meehan, S. Zdonik, S. Tian, Y. Tian, N. Tatbul, A. Dziedzic, A. Elmore
    Integrating real-time and batch processing in a polystore 2016 IEEE High Performance
    Extreme Computing Conference (HPEC), IEEE (2016), pp. 1-7, 10.1109/HPEC.2016.7761585
    Google Scholar Meola, 2021 Meola, A., 2021. Smart farming in 2020: How iot sensors
    are creating a more efficient precision agriculture industry. url:  https://www.businessinsider.com/smart-farming-iot-agriculture?IR=T.
    Google Scholar Microsoft, 2021a Microsoft, 2021a. Azure. url:  https://azure.microsoft.com.
    Google Scholar Microsoft, 2021b Microsoft, 2021b. Azure iot. url:  https://azure.microsoft.com/en-us/overview/iot/.
    Google Scholar Miloslavskaya and Tolstoy, 2016 N. Miloslavskaya, A. Tolstoy Big
    data, fast data and data lake concepts Proc. Comput. Sci., 88 (2016), pp. 300-305,
    10.1016/j.procs.2016.07.439 View PDFView articleView in ScopusGoogle Scholar Misra
    et al., 2020 N. Misra, Y. Dixit, A. Al-Mallahi, M.S. Bhullar, R. Upadhyay, A.
    Martynenko Iot, big data and artificial intelligence in agriculture and food industry
    IEEE Internet Things J. (2020), 10.1109/JIOT.2020.2998584 Google Scholar Mongo,
    2021 Mongo, 2021. Mongodb atlas. url:  https://www.mongodb.com/en-us/cloud/atlas.
    Google Scholar Morshed et al., 2017 A. Morshed, P.P. Jayaraman, T. Sellis, D.
    Georgakopoulos, M. Villari, R. Ranjan Deep osmosis: holistic distributed deep
    learning in osmotic computing IEEE Cloud Comput., 4 (2017), pp. 22-32, 10.1109/MCC.2018.1081070
    View in ScopusGoogle Scholar Munir et al., 2017 A. Munir, P. Kansakar, S.U. Khan
    Ifciot: Integrated fog cloud iot: a novel architectural paradigm for the future
    internet of things IEEE Consumer Electron. Mag., 6 (2017), pp. 74-82, 10.1109/MCE.2017.2684981
    View in ScopusGoogle Scholar Mykleby et al., 2016 M. Mykleby, P. Doherty, J. Makower
    The New Grand Strategy: Restoring America’s Prosperity, Security, and Sustainability
    in the 21st Century St. Martin’s Press (2016) Google Scholar Navarro et al., 2020
    E. Navarro, N. Costa, A. Pereira A systematic review of iot solutions for smart
    farming Sensors, 20 (2020), p. 4231, 10.3390/s20154231 Google Scholar Navarro-Hellin
    et al., 2016 H. Navarro-Hellín, J. Martinez-del Rincon, R. Domingo-Miguel, F.
    Soto-Valles, R. Torres-Sánchez A decision support system for managing irrigation
    in agriculture Comput. Electron. Agricul., 124 (2016), pp. 121-131, 10.1016/j.compag.2016.04.003
    View PDFView articleView in ScopusGoogle Scholar NECTEC, 2020 NECTEC, 2020. Netpie
    - network platform for internet of everything. url:  https://netpie.io. Google
    Scholar Neves and Cruvinel, 2020 R.A. Neves, P.E. Cruvinel Model for semantic
    base structuring of digital data to support agricultural management 2020 IEEE
    14th International Conference on Semantic Computing (ICSC), IEEE (2020), pp. 337-340,
    10.1109/ICSC.2020.00067 View in ScopusGoogle Scholar Nkamla Penka et al., 2021
    J.B. Nkamla Penka, S. Mahmoudi, O. Debauche A new kappa architecture for iot data
    management in smart farming Proc. Comput. Sci. (2021) In press Google Scholar
    Oracle, 2021 Oracle, 2021. Mysql. url:  https://www.mysql.com. Google Scholar
    Persico et al., 2018 V. Persico, A. Pescapé, A. Picariello, G. Sperlí Benchmarking
    big data architectures for social networks data processing using public cloud
    platforms Future Gener. Comput. Syst., 89 (2018), pp. 98-109, 10.1016/j.future.2018.05.068
    View PDFView articleView in ScopusGoogle Scholar Pesonen et al., 2014 L.A. Pesonen,
    F.K.W. Teye, A.K. Ronkainen, M.O. Koistinen, J.J. Kaivosoja, P.F. Suomi, R.O.
    Linkolehto Cropinfra–an internet-based service infrastructure to support crop
    production in future farms Biosyst. Eng., 120 (2014), pp. 92-101, 10.1016/j.biosystemseng.2013.09.005
    View PDFView articleView in ScopusGoogle Scholar Petcu et al., 2013 D. Petcu,
    B. Di Martino, S. Venticinque, M. Rak, T. Máhr, G.E. Lopez, F. Brito, R. Cossu,
    M. Stopar, S. Šperka, et al. Experiences in building a mosaic of clouds J. Cloud
    Comput.: Adv., Syst. Appl., 2 (2013), pp. 1-22, 10.1186/2192-113X-2-12 View in
    ScopusGoogle Scholar Popescu et al., 2020 D. Popescu, F. Stoican, G. Stamatescu,
    L. Ichim, C. Dragana Advanced uav–wsn system for intelligent monitoring in precision
    agriculture Sensors, 20 (2020), p. 817, 10.3390/s20030817 View in ScopusGoogle
    Scholar Radoglou-Grammatikis et al., 2020 P. Radoglou-Grammatikis, P. Sarigiannidis,
    T. Lagkas, I. Moscholios A compilation of uav applications for precision agriculture
    Comput. Netw., 172 (2020), Article 107148, 10.1016/j.comnet.2020.107148 View PDFView
    articleView in ScopusGoogle Scholar Rajakaruna et al., 2018 Rajakaruna, A., Manzoor,
    A., Porambage, P., Liyanage, M., Ylianttila, M., Gurtov, A., 2018. Lightweight
    dew computing paradigm to manage heterogeneous wireless sensor networks with uavs.
    arXiv preprint arXiv:1811.04283. Google Scholar Ray, 2017 P.P. Ray Internet of
    things for smart agriculture: technologies, practices and future direction J.
    Ambient Intell. Smart Environ., 9 (2017), pp. 395-420, 10.3233/AIS-170440 View
    in ScopusGoogle Scholar Ren et al., 2017 J. Ren, H. Guo, C. Xu, Y. Zhang Serving
    at the edge: a scalable iot architecture based on transparent computing IEEE Network,
    31 (2017), pp. 96-105, 10.1109/MNET.2017.1700030 View in ScopusGoogle Scholar
    Rodriguez et al., 2018 M.A. Rodriguez, L. Cuenca, A. Ortiz Fiware open source
    standard platform in smart farming – a review L.M. Camarinha-Matos, H. Afsarmanesh,
    Y. Rezgui (Eds.), Collaborative Networks of Cognitive Systems, Springer International
    Publishing, Cham (2018), pp. 581-589, 10.1007/978-3-319-99127-6_50 View in ScopusGoogle
    Scholar Roman et al., 2018 R. Roman, J. Lopez, M. Mambo Mobile edge computing,
    fog et al.: a survey and analysis of security threats and challenges Future Gener.
    Comput. Syst., 78 (2018), pp. 680-698, 10.1016/j.future.2016.11.009 View PDFView
    articleView in ScopusGoogle Scholar Roukh et al., 2020 A. Roukh, F.N. Fote, S.A.
    Mahmoudi, S. Mahmoudi Big data processing architecture for smart farming Proc.
    Comput. Sci., 177 (2020), pp. 78-85, 10.1016/j.procs.2020.10.014 View PDFView
    articleView in ScopusGoogle Scholar Roukh et al., 2020 A. Roukh, F.N. Fote, S.A.
    Mahmoudi, S. Mahmoudi Wallesmart: cloud platform for smart farming, in 32nd International
    Conference on Scientific and Statistical Database Management (2020), pp. 1-4,
    10.1145/3400903.3401690 Google Scholar Ruan et al., 2019 J. Ruan, H. Jiang, C.
    Zhu, X. Hu, Y. Shi, T. Liu, W. Rao, F.T.S. Chan Agriculture iot: Emerging trends,
    cooperation networks, and outlook IEEE Wirel. Commun., 26 (2019), pp. 56-63, 10.1109/MWC.001.1900096
    View in ScopusGoogle Scholar Saiz-Rubio and Rovira-Más, 2020 V. Saiz-Rubio, F.
    Rovira-Más From smart farming towards agriculture 5.0: a review on crop data management
    Agronomy, 10 (2020), p. 207, 10.3390/agronomy10020207 View in ScopusGoogle Scholar
    Sallah et al., 2019 A.H.M. Sallah, B. Tychon, I. Piccard, A. Gobin, R. Van Hoolst,
    B. Djaby, J. Wellens Batch-processing of aquacrop plug-in for rainfed maize using
    satellite derived fractional vegetation cover data Agric. Water Manage., 217 (2019),
    pp. 346-355 Google Scholar Scott, 2015 Scott, J., 2015. Zeta architecture: Hexagon
    is the new circle. an enterprise architecture solution for scale and efficiency.
    url:  https://www.oreilly.com/ideas/zeta-architecture-hexagon-is-the-new-circle.
    Google Scholar Sethi and Sarangi, 2017 P. Sethi, S.R. Sarangi Internet of things:
    architectures, protocols, and applications J. Electr. Comput. Eng., 2017 (2017),
    10.1155/2017/9324035 Google Scholar Shafi et al., 2019 U. Shafi, R. Mumtaz, J.
    García-Nieto, S.A. Hassan, S.A.R. Zaidi, N. Iqbal Precision agriculture techniques
    and practices: From considerations to applications Sensors, 19 (2019), p. 3796,
    10.3390/s19173796 View in ScopusGoogle Scholar Sharofidinov et al., 2020 F. Sharofidinov,
    M.S.A. Muthanna, V.D. Pham, A. Khakimov, A. Muthanna, K. Samouylov Agriculture
    management based on lora edge computing system V.M. Vishnevskiy, K.E. Samouylov,
    D.V. Kozyrev (Eds.), Distributed Computer and Communication Networks, Springer
    International Publishing, Cham (2020), pp. 113-125 CrossRefView in ScopusGoogle
    Scholar Shi et al., 2016 W. Shi, J. Cao, Q. Zhang, Y. Li, L. Xu Edge computing:
    vision and challenges IEEE Internet Things J., 3 (2016), pp. 637-646, 10.1109/JIOT.2016.2579198
    View in ScopusGoogle Scholar Shi et al., 2019 X. Shi, X. An, Q. Zhao, H. Liu,
    L. Xia, X. Sun, Y. Guo State-of-the-art internet of things in protected agriculture
    Sensors, 19 (2019), p. 1833, 10.3390/s19081833 View in ScopusGoogle Scholar Siciliani,
    2015 Siciliani, T., 2015. Big data using lambda architecture. url: https://dzone.com/articles/lambda-architecture-big-data.
    Google Scholar Sigrimis et al., 2002 Sigrimis, N., Arvanitis, K., Ferentinos,
    K., 2002. Macqu: An open scada system for intelligent management and control of
    greenhouses, in: 2002 ASAE Annual Meeting, American Society of Agricultural and
    Biological Engineers. p. 1. doi:10.13031/2013.9618. Google Scholar Singh et al.,
    2019 K.N. Singh, R.K. Behera, J.K. Mantri Big data ecosystem: review on architectural
    evolution Emerging Technol. Data Mining Inform. Secur., 335–345 (2019), 10.1007/978-981-13-1498-8_30
    Google Scholar Sipos et al., 2013 Sipos, G., Turilli, M., Newhouse, S., Kacsuk,
    P., 2013. A european federated cloud: Innovative distributed computing solutions
    by egi, in: EGU General Assembly Conference Abstracts, pp. EGU2013–8690. Google
    Scholar Skala et al., 2015 K. Skala, D. Davidovic, E. Afgan, I. Sovic, Z. Sojat
    Scalable distributed computing hierarchy: cloud, fog and dew computing Open J.
    Cloud Comput. (OJCC), 2 (2015), pp. 16-24, 10.19210/1002.2.1.16 Google Scholar
    SQLite, 2021 SQLite, 2021. Sqlite. url: https://www.sqlite.org. Google Scholar
    Sun et al., 2017 L. Sun, Y. Li, R.A. Memon An open iot framework based on microservices
    architecture China Commun., 14 (2017), pp. 154-162, 10.1109/CC.2017.7868163 View
    in ScopusGoogle Scholar Talavera et al., 2017 J.M. Talavera, L.E. Tobón, J.A.
    Gómez, M.A. Culman, J.M. Aranda, D.T. Parra, L.A. Quiroz, A. Hoyos, L.E. Garreta
    Review of iot applications in agro-industrial and environmental fields Comput.
    Electron. Agricul., 142 (2017), pp. 283-297, 10.1016/j.compag.2017.09.015 View
    PDFView articleView in ScopusGoogle Scholar Taneja et al., 2020 M. Taneja, J.
    Byabazaire, N. Jalodia, A. Davy, C. Olariu, P. Malone Machine learning based fog
    computing assisted data-driven approach for early lameness detection in dairy
    cattle Comput. Electron. Agricul., 171 (2020), Article 105286, 10.1016/j.compag.2020.105286
    View PDFView articleView in ScopusGoogle Scholar Taneja et al., 2019 M. Taneja,
    N. Jalodia, J. Byabazaire, A. Davy, C. Olariu Smartherd management: a microservices-based
    fog computing–assisted iot platform towards data-driven smart dairy farming Software:
    Practice Experience, 49 (2019), pp. 1055-1078, 10.1002/spe.2704 View in ScopusGoogle
    Scholar Tang et al., 2021 Y. Tang, S. Dananjayan, C. Hou, Q. Guo, S. Luo, Y. He
    A survey on the 5g network and its impact on agriculture: challenges and opportunities
    Comput. Electron. Agricul., 180 (2021), Article 105895, 10.1016/j.compag.2020.105895
    View PDFView articleView in ScopusGoogle Scholar The PostgreSQL Global Development
    Group, 2021 The PostgreSQL Global Development Group, P., 2021. Postgresql: The
    world’s most advanced open source relational database. url:  https://www.postgresql.org/.
    Google Scholar Tran et al., 2017 T.X. Tran, A. Hajisami, P. Pandey, D. Pompili
    Collaborative mobile edge computing in 5g networks: new paradigms, scenarios,
    and challenges IEEE Commun. Mag., 55 (2017), pp. 54-61, 10.1109/MCOM.2017.1600863
    View in ScopusGoogle Scholar Triantafyllou et al., 2019 A. Triantafyllou, P. Sarigiannidis,
    S. Bibi Precision agriculture: a remote sensing monitoring system architecture
    Information, 10 (2019), p. 348, 10.3390/info10110348 View in ScopusGoogle Scholar
    Tzounis et al., 2017 A. Tzounis, N. Katsoulas, T. Bartzanas, C. Kittas Internet
    of things in agriculture, recent advances and future challenges Biosyst. Eng.,
    164 (2017), pp. 31-48, 10.1016/j.biosystemseng.2017.09.007 View PDFView articleView
    in ScopusGoogle Scholar Ubidots, 2021 Ubidots, 2021. Ubidots. url:  https://ubidots.com/.
    Google Scholar Uehara, 2017 Uehara, M., 2017. Mist computing: Linking cloudlet
    to fogs, in: International Conference on Computational Science/Intelligence &
    Applied Informatics, Springer. pp. 201–213. doi:10.1007/978-3-319-63618-4_15.
    Google Scholar Valecce et al., 2019 G. Valecce, S. Strazzella, L.A. Grieco On
    the interplay between 5g, mobile edge computing and robotics in smart agriculture
    scenarios M.R. Palattella, S. Scanzio, S. Coleri Ergen (Eds.), Ad-Hoc, Mobile,
    and Wireless Networks, Springer International Publishing, Cham (2019), pp. 549-559,
    10.1007/978-3-030-31831-4_38 View in ScopusGoogle Scholar Villa-Henriksen et al.,
    2020 A. Villa-Henriksen, G.T. Edwards, L.A. Pesonen, O. Green, C.A.G. Sørensen
    Internet of things in arable farming: implementation, applications, challenges
    and potential Biosyst. Eng., 191 (2020), pp. 60-84, 10.1016/j.biosystemseng.2019.12.013
    View PDFView articleView in ScopusGoogle Scholar Villari et al., 2017 Villari,
    M., Celesti, A., Fazio, M., 2017. Towards osmotic computing: Looking at basic
    principles and technologies, in: Conference on Complex, Intelligent, and Software
    Intensive Systems, Springer. pp. 906–915. doi:10.1007/978-3-319-61566-086. Google
    Scholar Villari et al., 2014 M. Villari, A. Celesti, M. Fazio, A. Puliafito Alljoyn
    lambda: an architecture for the management of smart environments in iot 2014 International
    Conference on Smart Computing Workshops, IEEE (2014), pp. 9-14, 10.1109/SMARTCOMP-W.2014.7046676
    View in ScopusGoogle Scholar Villari et al., 2016 M. Villari, M. Fazio, S. Dustdar,
    O. Rana, R. Ranjan Osmotic computing: a new paradigm for edge/cloud integration
    IEEE Cloud Comput., 3 (2016), pp. 76-83, 10.1109/MCC.2016.124 View in ScopusGoogle
    Scholar Wang et al., 2020 X. Wang, Y. Han, V.C. Leung, D. Niyato, X. Yan, X. Chen
    Edge AI: Convergence of Edge Computing and Artificial Intelligence Springer Nature
    (2020), 10.1007/978-981-15-6186-3 Google Scholar Wang, 2016 Y. Wang Definition
    and categorization of dew computing Open J. Cloud Comput. (OJCC), 3 (2016), pp.
    1-7, 10.19210/1002.3.1.1 View PDFView articleGoogle Scholar Wolfert et al., 2017
    S. Wolfert, L. Ge, C. Verdouw, M.J. Bogaardt Big data in smart farming–a review
    Agricult. Syst., 153 (2017), pp. 69-80, 10.1016/j.agsy.2017.01.023 View PDFView
    articleView in ScopusGoogle Scholar Yang, 2017 S. Yang Iot stream processing and
    analytics in the fog IEEE Commun. Mag., 55 (2017), pp. 21-27, 10.1109/MCOM.2017.1600840
    View in ScopusGoogle Scholar Zhai et al., 2020 Z. Zhai, J.F. Martínez, V. Beltran,
    N.L. Martínez Decision support systems for agriculture 4.0: Survey and challenges
    Comput. Electron. Agricul., 170 (2020), Article 105256, 10.1016/j.compag.2020.105256
    View PDFView articleView in ScopusGoogle Scholar Zhang, 2016 Zhang, Q., 2016.
    Precision agriculture technology for crop farming. Taylor & Francis. doi:10.1201/b19336.
    Google Scholar Zhou et al., 2017 Y. Zhou, D. Zhang, N. Xiong Post-cloud computing
    paradigms: a survey and comparison Tsinghua Sci. Technol., 22 (2017), pp. 714-732,
    10.23919/TST.2017.8195353 View in ScopusGoogle Scholar Cited by (27) The convergence
    of Digital Twins and Distributed Ledger Technologies: A systematic literature
    review and an architectural proposal 2024, Journal of Network and Computer Applications
    Show abstract Integrated design framework for smart agriculture: Bridging the
    gap between digitalization and sustainability 2024, Journal of Cleaner Production
    Show abstract Spatio-temporal semantic data management systems for IoT in agriculture
    5.0: Challenges and future directions 2024, Internet of Things (Netherlands) Show
    abstract Internet of agriculture: Analyzing and predicting tractor ride comfort
    through supervised machine learning 2023, Engineering Applications of Artificial
    Intelligence Show abstract A real-time decision-making tool based on dynamic thresholds
    for Phthorimaea absoluta management in greenhouse tomato 2023, Crop Protection
    Show abstract Information management infrastructures for multipurpose unmanned
    aerial systems operations 2023, Unmanned Aerial Systems in Agriculture: Eyes Above
    Fields Show abstract View all citing articles on Scopus Peer review under responsibility
    of King Saud University. 1 https://www.statista.com/statistics/471264/iot-number-of-connected-devices-worldwide/
    2 https://www.statista.com/statistics/499431/global-ip-data-traffic-forecast/
    3 https://www.pix4d.com/ 4 http://prospera.ag/ © 2021 The Authors. Published by
    Elsevier B.V. on behalf of King Saud University. Recommended articles Cloud-based
    Decision Support and Automation for Precision Agriculture in Orchards IFAC-PapersOnLine,
    Volume 49, Issue 16, 2016, pp. 330-335 Li Tan View PDF Worker safety in agriculture
    4.0: A new approach for mapping operator’s vibration risk through Machine Learning
    activity recognition Computers and Electronics in Agriculture, Volume 193, 2022,
    Article 106637 Giuseppe Aiello, …, Mario Venticinque View PDF A lightweight network
    for mummy berry disease recognition Smart Agricultural Technology, Volume 2, 2022,
    Article 100044 Hongchun Qu, Min Sun View PDF Show 3 more articles Article Metrics
    Citations Citation Indexes: 21 Captures Readers: 187 Social Media Shares, Likes
    & Comments: 60 View details About ScienceDirect Remote access Shopping cart Advertise
    Contact and support Terms and conditions Privacy policy Cookies are used by this
    site. Cookie settings | Your Privacy Choices All content on this site: Copyright
    © 2024 Elsevier B.V., its licensors, and contributors. All rights are reserved,
    including those for text and data mining, AI training, and similar technologies.
    For all open access content, the Creative Commons licensing terms apply.'
  inline_citation: '>'
  journal: Journal of King Saud University - Computer and Information Sciences
  limitations: '>'
  pdf_link: null
  publication_year: 2022
  relevance_score1: 0
  relevance_score2: 0
  title: 'Cloud and distributed architectures for data management in agriculture 4.0
    : Review and future trends'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.35940/ijeat.c2130.0210321
  analysis: '>'
  authors:
  - Sachin Chavhan
  - R. L. Chavhan
  citation_count: 2
  full_citation: '>'
  full_text: '>'
  inline_citation: '>'
  journal: International journal of engineering and advanced technology
  limitations: '>'
  pdf_link: null
  publication_year: 2021
  relevance_score1: 0
  relevance_score2: 0
  title: Design and Development of High-Performance Intelligent Disaster Management
    System in IoT Paradigm A Novel Architecture and Review on Challenges in real time
    Hazards Monitoring
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1109/miot.2021.9390455
  analysis: '>'
  authors:
  - N. Kishor Narang
  - John K. Zhao
  citation_count: 1
  full_citation: '>'
  full_text: '>

    This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org
    IEEE Xplore IEEE SA IEEE Spectrum More Sites Subscribe Donate Cart Create Account
    Personal Sign In Personal Sign In * Required *Email Address *Password Forgot Password?
    Sign In Don''t have a Personal Account? Create an IEEE Account now. Create Account
    Learn more about personalization features. IEEE Personal Account CHANGE USERNAME/PASSWORD
    Purchase Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile Information
    COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help?
    US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow
    About IEEE Xplore | Contact Us | Help | Accessibility | Terms of Use | Nondiscrimination
    Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy Policy A not-for-profit
    organization, IEEE is the world''s largest technical professional organization
    dedicated to advancing technology for the benefit of humanity. © Copyright 2024
    IEEE - All rights reserved.'
  inline_citation: '>'
  journal: IEEE internet of things magazine
  limitations: '>'
  pdf_link: https://ieeexplore.ieee.org/ielx7/8548628/9390468/09390455.pdf
  publication_year: 2021
  relevance_score1: 0
  relevance_score2: 0
  title: Mentor's Musings on IoT, Environment and Standards Interplay…
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.3390/electronics12102336
  analysis: '>'
  authors:
  - Jun Liu
  - Lei Shu
  - Xu Lu
  - Lei Shu
  citation_count: 4
  full_citation: '>'
  full_text: ">\nCitation: Liu, J.; Shu, L.; Lu, X.; Liu, Y.\nSurvey of Intelligent\
    \ Agricultural IoT\nBased on 5G. Electronics 2023, 12,\n2336. https://doi.org/10.3390/\n\
    electronics12102336\nAcademic Editor: Djuradj Budimir\nReceived: 1 March 2023\n\
    Revised: 29 April 2023\nAccepted: 6 May 2023\nPublished: 22 May 2023\nCopyright:\n\
    © 2023 by the authors.\nLicensee MDPI, Basel, Switzerland.\nThis article is an\
    \ open access article\ndistributed\nunder\nthe\nterms\nand\nconditions of the\
    \ Creative Commons\nAttribution (CC BY) license (https://\ncreativecommons.org/licenses/by/\n\
    4.0/).\nelectronics\nReview\nSurvey of Intelligent Agricultural IoT Based on 5G\n\
    Jun Liu 1\n, Lei Shu 2,3,*\n, Xu Lu 4,*\nand Ye Liu 2\n1\nSchool of Automation,\
    \ Guangdong Polytechnic Normal University, Guangzhou 510665, China\n2\nCollege\
    \ of Artiﬁcal Intelligence, Nanjing Agricultural University, Nanjing 210095, China\n\
    3\nSchool of Engineering, University of Lincoln, Lincoln LN6 7TS, UK\n4\nSchool\
    \ of Computer Science, Guangdong Polytechnic Normal University, Guangzhou 510665,\
    \ China\n*\nCorrespondence: lei.shu@njau.edu.cn (L.S.); bruda@126.com (X.L.)\n\
    Abstract: In the future, agriculture will face the need for increasing production,\
    \ sustainability, wisdom,\nand efﬁciency, which will bring signiﬁcant challenges\
    \ to the development of modern agriculture. With\nthe gradual popularization of\
    \ 5G, advanced information technologies such as the Internet of Things\nand artiﬁcial\
    \ intelligence promoted the evolution of modern agriculture to intelligent agriculture.\n\
    The 5G-based Internet of Things will play an essential role in the development\
    \ of smart agriculture.\nThis paper investigates the research progress of 5G Internet\
    \ of Things in smart agriculture. It sorts\nout the development status of 5G smart\
    \ agriculture Internet of Things in recent years. Following that,\nthe concept\
    \ of 5G smart agriculture Internet of Things is put forward. It expounds on the\
    \ connotation,\narchitecture, and enabling key technologies. According to the\
    \ key application scenarios of smart\nagriculture, practical cases are presented,\
    \ the development trend and application value of 5G smart\nagriculture Internet\
    \ of Things are shown, and the future development direction is put forward. Firstly,\n\
    the concept of smart agriculture is distinguished, and the category scenarios\
    \ of smart agriculture\nare summarized. Following that, the current review research\
    \ on 5G-IoT is analyzed. This paper\nfocuses on the analysis and summary of the\
    \ changes brought by 5G to various key scenarios in smart\nagriculture. This paper\
    \ analyzes the related key technologies and challenges, puts forward some\nkey\
    \ scientiﬁc problems, and summarizes the research ideas. Finally, the development\
    \ trend and\napplication value of 5G smart agriculture Internet of Things are\
    \ shown. The future development\ndirection is also proposed.\nKeywords: 5G; smart\
    \ agriculture; IoT; monitoring; deep learning; cloud-edge\n1. Introduction\nThe\
    \ future of agriculture is facing serious challenges as people demand higher quality\n\
    food. As shown in Figure 1, by 2050, the gap is expected to be huge, and this\
    \ will pose a\ngreat challenge to resources and the environment. Academician Zhao\
    \ Chunjiang claimed\nthat the intelligent revolution of agriculture in the form\
    \ of smart agriculture has arrived\nin the ﬁrst issue of “Smart Agriculture”.\
    \ Smart agriculture is an advanced stage of the\ndevelopment of agricultural information\
    \ from digitalization to networking and then to\nintelligence, which is a milestone\
    \ for the development of agriculture, and agriculture is\nentering stage 4.0 [1].\n\
    With the commercialization and popularization of smart 5G technology, its charac-\n\
    teristics of high speed, super-large connection, and ultra-low delay will have\
    \ a profound\nimpact on agricultural IoT. Combined with the rapid development\
    \ of artiﬁcial intelligence,\nedge computing, cloud services, and other ﬁelds\
    \ will achieve an epoch-making revolution\nin agricultural production mode. Smart\
    \ Agriculture and 5G-IoT smart agriculture are\nrespectively introduced below.\n\
    Electronics 2023, 12, 2336. https://doi.org/10.3390/electronics12102336\nhttps://www.mdpi.com/journal/electronics\n\
    Electronics 2023, 12, 2336\n2 of 46\nREVIEW \n2 of\nIncreas\ne 49%\nIncreased\
    \ demand \nfor food\n2020\n2050\n2020\n2050\n10B\n7.6B\nMore water\nMore land\
    \ resources\nCarbon emissions from \nagricultural production\nExcessive resource\
    \ \nconsumption\nreduce carbon emissions\nIncrease in \nPopulation\n \nFigure\
    \ 1. Challenges to sustainable agricultural development in the future. \nWith\
    \ the commercialization and popularization of smart 5G technology, its chara\n\
    teristics of high speed, super-large connection, and ultra-low delay will have\
    \ a profou\nimpact on agricultural IoT. Combined with the rapid development of\
    \ artificial inte\ngence, edge computing, cloud services, and other fields will\
    \ achieve an epoch-maki\nrevolution in agricultural production mode. Smart Agriculture\
    \ and 5G-IoT smart agric\nture are respectively introduced below. \n1.1. Smart\
    \ Agriculture \nThere are many kinds of agriculture, including water-saving agriculture,\
    \ facility a\nriculture, ecological agriculture, three-dimensional agriculture,\
    \ organic agriculture, p\ncision agriculture, and so on. Smart agriculture is\
    \ a new agricultural production mo\nwith the core element of information and knowledge.\
    \ By deeply integrating modern \nformation technology such as the Internet, Internet\
    \ of Things, big data, cloud computin\nand artificial intelligence with agriculture,\
    \ it realizes agricultural information perceptio\nquantitative decision-making,\
    \ intelligent control, precise input, and personalized servi\nSmart agriculture\
    \ is an advanced stage of agricultural informatization development fro\ndigitalization\
    \ to networking and intelligence [2,3]. Smart agriculture is a new agricultu\n\
    Figure 1. Challenges to sustainable agricultural development in the future.\n\
    1.1. Smart Agriculture\nThere are many kinds of agriculture, including water-saving\
    \ agriculture, facility agri-\nculture, ecological agriculture, three-dimensional\
    \ agriculture, organic agriculture, precision\nagriculture, and so on. Smart agriculture\
    \ is a new agricultural production mode with the\ncore element of information\
    \ and knowledge. By deeply integrating modern information\ntechnology such as\
    \ the Internet, Internet of Things, big data, cloud computing, and artiﬁcial\n\
    intelligence with agriculture, it realizes agricultural information perception,\
    \ quantitative\ndecision-making, intelligent control, precise input, and personalized\
    \ service. Smart agricul-\nture is an advanced stage of agricultural informatization\
    \ development from digitalization\nto networking and intelligence [2,3]. Smart\
    \ agriculture is a new agricultural production\nmode and ecosystem based on digital\
    \ and precision agriculture, as well as a production\nform in the era of Agriculture\
    \ 4.0. Figure 2 shows the evolution of agriculture from stage 1.0\nto 4.0 [4].\
    \ This revolution that Agriculture 4.0 will completely change how people produce\n\
    food and effectively help people cope with the future population explosion, ecological\n\
    imbalance, food crisis, and other potential challenges [5].\nSmart agriculture\
    \ covers many categories and scenarios. This paper combines previous\nsummaries\
    \ [6,7] and summarizes them according to the large ﬁelds and categories involved\n\
    in agriculture, as shown in the ﬁgure below. In this paper, smart agriculture\
    \ is mainly\noriented to the ﬁeld of planting and breeding, including crop planting,\
    \ animal husbandry,\nand aquatic products. According to the production mode of\
    \ this agriculture, it can be\ndivided into facility agriculture, ﬁeld agriculture,\
    \ precision agriculture, and so on. This\nincludes most areas of agriculture.\
    \ In addition, various types of agricultural production\nElectronics 2023, 12,\
    \ 2336\n3 of 46\ninclude multiple scenarios, such as moisture monitoring, pest\
    \ management, harvesting,\nand so on. The crop or production facing each scenario\
    \ may differ, but many of the key\ntechnologies involved are broadly similar,\
    \ so they are also grouped together. The following\nis a summary of the key technologies\
    \ involved in the scenario, as shown in Figure 3.\nand artificial intelligence\
    \ with agriculture, it realizes agricultural information perception, \nquantitative\
    \ decision-making, intelligent control, precise input, and personalized service.\
    \ \nSmart agriculture is an advanced stage of agricultural informatization development\
    \ from \ndigitalization to networking and intelligence [2,3]. Smart agriculture\
    \ is a new agricultural \nproduction mode and ecosystem based on digital and precision\
    \ agriculture, as well as a \nproduction form in the era of Agriculture 4.0. Figure\
    \ 2 shows the evolution of agriculture \nfrom stage 1.0 to 4.0 [4]. This revolution\
    \ that Agriculture 4.0 will completely change how \npeople produce food and effectively\
    \ help people cope with the future population explo-\nsion, ecological imbalance,\
    \ food crisis, and other potential challenges [5]. \n \nFigure 2. Smart agriculture\
    \ and agriculture 4.0 evolution. \nFigure 2. Smart agriculture and agriculture\
    \ 4.0 evolution.\nPEER REVIEW \n3 of 46 \nSmart agriculture covers many categories\
    \ and scenarios. This paper combines previ-\nous summaries [6,7] and summarizes\
    \ them according to the large fields and categories \ninvolved in agriculture,\
    \ as shown in the figure below. In this paper, smart agriculture is \nmainly oriented\
    \ to the field of planting and breeding, including crop planting, animal \nhusbandry,\
    \ and aquatic products. According to the production mode of this agriculture,\
    \ \nit can be divided into facility agriculture, field agriculture, precision\
    \ agriculture, and so \non. This includes most areas of agriculture. In addition,\
    \ various types of agricultural pro-\nduction include multiple scenarios, such\
    \ as moisture monitoring, pest management, har-\nvesting, and so on. The crop\
    \ or production facing each scenario may differ, but many of \nthe key technologies\
    \ involved are broadly similar, so they are also grouped together. The \nfollowing\
    \ is a summary of the key technologies involved in the scenario, as shown in Fig-\n\
    ure 3. \nSmart Agriculture\nIntelligent \nmonitoring\nWater/Soil \nManagement\n\
    Planting \ngrowth \nmanagement\nPest \nmanagement\nSupply chain \nmanagement\n\
    Typical Scenarios \nof Smart \nAgriculture\nSmart agricultural machinery: \nplanting,\
    \ weeding, picking and \nharvesting\nFishery and aquatic \nproducts\nAnimal \n\
    husbandry\nCrop planting\nGrowth \nmonitoring\nMonitoring of \naquaculture \n\
    environment\nRemote sensing \nmonitoring\nUAV \nmonitoring\nIntelligent \nirrigation\n\
    Moisture \nmonitoring\nWeather \nforecast\nHumidity/\nrainfall \nmonitoring\n\
    Crop phenotype \nmonitoring\nFertilization and \nfeeding \nmanagement\nGeographic\
    \ fence, \nanimal \nmanagement\nNutritional \npesticide \napplication\nInsect\
    \ \nmonitoring\nDisease \nmonitoring/\nprevention\nPhysical sign \nmonitoring/water\
    \ \nquality management\nLivestock \nmonitoring\nIntelligent \nweeding\nIntelligent\
    \ \npicking\nIntelligent \nspraying\nIntelligent \nharvesting\nTransportation\
    \ of \nagricultural \nproducts\nProcessing of \nagricultural \nproducts\nTraceability\
    \ \nmanagement of \nagricultural products\nAgricultural \nproduct storage\nGreenhouse\n\
    Smart animal \nhusbandry\nPlant factory\nIntelligent \nphenotype\nPrecisionAgriculture\n\
    Organic Agriculture\nSightseeing Agriculture\nFacility Agriculture\nField Agriculture\n\
    \  \n \nFigure 3. Smart agriculture field and classification. \nThe Internet of\
    \ Things and other key technologies in smart agriculture, as well as the \nfinal\
    \ target vision, are shown in Figure 4. The ultimate goal of intelligent agriculture\
    \ is to \nrealize intelligent, unmanned, precise, efficient, high-quality, and\
    \ green. The key technol-\nogies needed to achieve the above goals include 5G,\
    \ Internet of Things, big data, artificial \nintelligence, robotics, blockchain,\
    \ drones, and so on. \nSmart \nagriculture\nSmart\nUnmann\ned\nAccurate\nEfficient\n\
    Superior \nquality\nGreen\nTarget\nFigure 3. Smart agriculture ﬁeld and classiﬁcation.\n\
    The Internet of Things and other key technologies in smart agriculture, as well\
    \ as\nthe ﬁnal target vision, are shown in Figure 4. The ultimate goal of intelligent\
    \ agriculture\nis to realize intelligent, unmanned, precise, efﬁcient, high-quality,\
    \ and green. The key\ntechnologies needed to achieve the above goals include 5G,\
    \ Internet of Things, big data,\nartiﬁcial intelligence, robotics, blockchain,\
    \ drones, and so on.\nThe following introduces the research progress of 5G agricultural\
    \ Internet of Things\nin relevant countries around the world, as shown in Table\
    \ 1. It can be seen that the\nrapid progress of 5G commercial deployment in China\
    \ has driven the development of 5G\nagricultural Internet of Things.\nIt is predicted\
    \ that, by 2025, the proportion of 5G connections in the total number of\nconnections\
    \ will increase from 8% in 2021 to 25% in 2025. 5G is expected to account for\n\
    nearly 60% of global mobile service revenue in 2026. With the commercial popularization\n\
    of 5G worldwide, it will lay the foundation for the application of smart agricultural\
    \ IoTs,\nbringing new opportunities.\nElectronics 2023, 12, 2336\n4 of 46\nFigure\
    \ 3. Smart agriculture field and classification. \nThe Internet of Things and\
    \ other key technologies in smart agriculture, as well as the \nfinal target vision,\
    \ are shown in Figure 4. The ultimate goal of intelligent agriculture is to \n\
    realize intelligent, unmanned, precise, efficient, high-quality, and green. The\
    \ key technol-\nogies needed to achieve the above goals include 5G, Internet of\
    \ Things, big data, artificial \nintelligence, robotics, blockchain, drones, and\
    \ so on. \nSmart \nagriculture\nRobot\nInternet \nof Things\nUAV\nAI\nBlockcha\n\
    in\nBig data\n5G\nSmart\nUnmann\ned\nAccurate\nEfficient\nSuperior \nquality\n\
    Green\nTey \nTechnology\nTarget\n \nFigure 4. Key technologies and objectives\
    \ of smart agriculture. \nThe following introduces the research progress of 5G\
    \ agricultural Internet of Things \nin relevant countries around the world, as\
    \ shown in Table 1. It can be seen that the rapid \nFigure 4. Key technologies\
    \ and objectives of smart agriculture.\nTable 1. Global 5G agricultural Internet\
    \ of Things development [8].\nCountry\nAgricultural Type\n5G Agricultural Internet\n\
    of Things\nDevelopment Representa-\ntive/Development\nCharacteristics\n5G Policy\n\
    America\nLarge farms\n5G + UAV + GPS+ satellite\nremote sensing\nFarmLogs, Cropx\n\
    FCC—$9 billion 5G\nsubsidy program\nEurope\nPrecision agriculture\n5G + big data\
    \ + smart\nagricultural machinery\nmonitoring and control, smart\nagricultural\
    \ machinery\nHolland, Switzerland,\nHuawei, Sunrise\n5G commercial\npromotion\n\
    Japan\nGreen agriculture and\necological agriculture\n5G + agricultural Internet\
    \ of\nThings + smart monitoring\nA new farming model with\nautomation and\nintelligence\n\
    5G falls behind, 6G\nworks\nIsrael\nFacility agriculture\nIntelligent depth sense\
    \ +\nintelligent control\nInnovative agriculture\n5G networking\nChina\nMixed\
    \ existence of\nvarious types of\nagriculture\nAgricultural production is\ndeveloping\
    \ towards automation\nand smart agriculture by leaps\nand bounds\n5G, smart agriculture,\n\
    smart agricultural\nmachinery\n5G is being\ncomprehensively\npromoted and\ndemonstrated\
    \ in\nagricultural application\n1.2. 5G-IoT Smart Agriculture\nThe wireless communication\
    \ capability of 5G with low delay, high density, and large\nbandwidth provides\
    \ a communication guarantee for the application of other information\ntechnologies\
    \ in the smart agricultural Internet of Things. Smart agriculture has relied on\
    \ the\nﬁfth generation of information technology 5G, the Internet of Things, robotics,\
    \ drones, big\ndata, AI, machine learning, blockchain, and other key technologies\
    \ to transform modern\nagriculture. It realizes the deep integration of the physical\
    \ world and the information\nworld, changing the current mode of agricultural\
    \ production. Industry-oriented universal\nwide-area Internet of Things is becoming\
    \ the main force [9]. It can promote the expansion\nand upgrading of IoTs in smart\
    \ agriculture and expedite the landing application of big data\nin smart agriculture.\
    \ It is the key to the in-depth application of UAV in agriculture and is\nan important\
    \ booster for integrating artiﬁcial intelligence and robot blockchain in smart\n\
    agriculture [10].\nThe Internet of Things continues to evolve with the evolution\
    \ of information technol-\nogy and sensors. It should not only perceive and transmit\
    \ data but also have functions such\nas recognition, computation, service, semantics,\
    \ and even cognitive decision-making [11].\nThe detection, management, and maintenance\
    \ functions of the Internet of Things will\nalso gradually become intelligent\
    \ and unmanned. The in-depth integration of the Inter-\nnet of Things, big data,\
    \ and artiﬁcial intelligence will revolutionize the current form of\nElectronics\
    \ 2023, 12, 2336\n5 of 46\nthe Internet of Things and generate huge social value\
    \ [12]. As an important part of new\ndigital infrastructure, the Internet of Things\
    \ (IoT) is deeply integrated with 5G, big data,\ncloud computing, artiﬁcial intelligence,\
    \ blockchain, digital twin, and other technologies,\nand is evolving into a smart\
    \ IoT system (IoTs 2.0) [13], which is profoundly changing\nthe process of the\
    \ modern agricultural industry and promoting the rapid development of\nsmart agriculture.\n\
    In the ﬁeld of smart agriculture, the Agricultural Internet of Things (AIoT) is\
    \ devel-\noping rapidly, but still faces many challenges. This includes the new\
    \ application of the\nagricultural scene, the transformation of the new agricultural\
    \ production mode, and the\ndeep integration with other technologies. As a basic\
    \ condition for the in-depth application\nof the agricultural Internet of Things,\
    \ 5G communication technology will promote the\nin-depth application of the agricultural\
    \ Internet of Things in smart agriculture. 5G can\nprovide MTC communication with\
    \ high reliability, low delay, and wide coverage, and its\nthree typical application\
    \ scenarios have broad prospects in smart agriculture [14]. 5G IoT\ntechnology\
    \ can be extended to the scope of current, which cannot be achieved with the\n\
    ﬁeld, making IoT depth perception of the intelligent environment perception, enlarging\n\
    the coverage of the Internet of Things of agriculture and the ascending scale,\
    \ expanding\nthe communication capacity, and realizing large-scale equipment interact\
    \ with each other\nand data sharing so as to realize the agricultural decision-making\
    \ process depth [15]. 5G-\nIoT is expected to provide real-time, on-demand, online,\
    \ reconﬁgurable, and end-to-end\ncoordinated capabilities for a variety of agricultural\
    \ applications. It can provide logically\nindependent network applications and\
    \ conﬁgure networks on demand. According to the\nfuture agricultural needs, the\
    \ integration of 5G with smart agriculture and the Internet of\nThings will be\
    \ able to achieve network characteristics, as shown in Figure 5.\nof the modern\
    \ agricultural industry and promoting the rapid dev\nculture. \nIn the field of\
    \ smart agriculture, the Agricultural Internet of \noping rapidly, but still faces\
    \ many challenges. This includes the\nagricultural scene, the transformation of\
    \ the new agricultural pro\ndeep integration with other technologies. As a basic\
    \ condition for t\nof the agricultural Internet of Things, 5G communication technolo\n\
    depth application of the agricultural Internet of Things in smart a\nvide MTC\
    \ communication with high reliability, low delay, and \nthree typical application\
    \ scenarios have broad prospects in smart \ntechnology can be extended to the\
    \ scope of current, which cann\nfield, making IoT depth perception of the intelligent\
    \ environmen\nthe coverage of the Internet of Things of agriculture and the asce\n\
    the communication capacity, and realizing large-scale equipment \nand data sharing\
    \ so as to realize the agricultural decision-making\nIoT is expected to provide\
    \ real-time, on-demand, online, reconfig\ncoordinated capabilities for a variety\
    \ of agricultural applications.\nindependent network applications and configure\
    \ networks on de\nfuture agricultural needs, the integration of 5G with smart\
    \ agricu\nThings will be able to achieve network characteristics, as shown in\n\
    Fine grained network\nSmart Agriculture \n5G Internet of \nThings Characteristic\
    \ \nDemand\nHigh data rate\nScalability\nReliable elasticity\nHigh density connection\n\
    Mobility\nSecurity\nHigh endurance\nlow power consumption\n \nFigure 5. Characteristics\
    \ of smart agriculture 5G Internet of Things dema\nThe above content will be able\
    \ to promote the landing of sm\nsent, many scholars are paying attention to the\
    \ opportunities and\nthe commercialization of 5G to the Internet of Things and\
    \ have ca\nview studies [16–23]. The relevant summaries are shown in Table \n\
    Table 2. 5G-IoT review papers overview. \nTime \nOverview Journals  \nMain Focus\
    \ \n2016\nM. R. Palattella et al. From technology, standardization\nFigure 5.\
    \ Characteristics of smart agriculture 5G Internet of Things demand.\nThe above\
    \ content will be able to promote the landing of smart agriculture. At present,\n\
    many scholars are paying attention to the opportunities and challenges brought\
    \ by the\ncommercialization of 5G to the Internet of Things and have carried out\
    \ a series of review\nstudies [16–23]. The relevant summaries are shown in Table\
    \ 2.\nElectronics 2023, 12, 2336\n6 of 46\nTable 2. 5G-IoT review papers overview.\n\
    Time\nOverview Journals\nMain Focus\nScene\n2016\nM. R. Palattella et al. [16]\n\
    From technology, standardization and\nmarket prospect\nMarket Paradigm\n2018\n\
    Shancang Li et al. [17]\nKey implementation technologies, main research\ntrends\
    \ and challenges\nKey technologies and trends\n2018\nD. Wang et al. [18]\nNew\
    \ paradigm of 5G intelligent Internet of\nThings (5G l-loT): big data mining,\
    \ deep\nlearning, and reinforcement learning\nNew paradigm\n2018\nG. A. Akpakwu\
    \ et al. [19]\nApplication requirements of the Internet of\nThings and the development\
    \ status of related\ncommunication technologies\nCommunications technology\n2019\n\
    N. Wang et al. [20]\nPhysical layer security\nSecurity\n2020\nK. Shaﬁque et al.\
    \ [21]\nProspects of 5G key technologies for the Internet\nof Things\n5G Key Technology\n\
    2021\nYu Tang et al. [22]\nOpportunities, challenges, and key technologies\nSmart\
    \ agriculture\n2022\nOgbodo E U et al. [23]\n5G and LPWAN-IoT for Improved Smart\
    \ Cities\nand Remote Area Applications\n5G LPWAN-IoT\n2022\nKhanh Q V et al. [24]\n\
    Wireless communication technologies for IoT in\n5G: vision, applications, and\
    \ challenges\nWireless communication\ntechnologies\nDespite a great deal of research\
    \ on 5G-IoT, there are few reviews on 5G IoT in agri-\nculture. Secondly, there\
    \ is a notable amount of research on smart agriculture, as shown in\nTable 3.\n\
    It can be seen that smart agriculture and the Internet of Things are both hot-tracking\n\
    directions, and there are many review articles and rapid technological development.\
    \ Many\nscholars have conducted research from various perspectives. Based on 5G,\
    \ there is not\nmuch in-depth research, and the following method is to carry out\
    \ in-depth research and\ndiscussion from this aspect.\nDomestic literature research\
    \ on 5G intelligent agricultural Internet of Things is also\nbecoming a new hotspot.\
    \ There is a rapid growth trend in related papers, and the main\nresearch ﬁelds\
    \ include smart agriculture, the Internet of Things, 5G, and so on. The above\n\
    distribution obtained from 5G, smart agriculture, and the Internet of Things retrieved\
    \ from\nCNKI shows that research is increasing rapidly as show in Figure 6.\n\
    PEER REVIEW \n7 of 46 \n2021 \nGodwin Idoje et al. \n[41] \nTechnological progress\
    \ and chal-\nlenges of smart farms \nSmart Farm \n2022 N. N. Misra et al. [42]\
    \ \nInternet of Things, Artificial Intelli-\ngence and Big Data in Agriculture\
    \ \nand Food Industry \nFood industry \nIt can be seen that smart agriculture\
    \ and the Internet of Things are both hot-tracking \ndirections, and there are\
    \ many review articles and rapid technological development. \nMany scholars have\
    \ conducted research from various perspectives. Based on 5G, there is \nnot much\
    \ in-depth research, and the following method is to carry out in-depth research\
    \ \nand discussion from this aspect. \nDomestic literature research on 5G intelligent\
    \ agricultural Internet of Things is also \nbecoming a new hotspot. There is a\
    \ rapid growth trend in related papers, and the main \nresearch fields include\
    \ smart agriculture, the Internet of Things, 5G, and so on. The above \ndistribution\
    \ obtained from 5G, smart agriculture, and the Internet of Things retrieved \n\
    from CNKI shows that research is increasing rapidly as show in Figure 6. \n \n\
    Figure 6. Shows the overall trend analysis of related papers. \n1.3. Summary \n\
    1.3.1. Contribution \nIn this paper, the research and prospects of 5G joint IoT\
    \ in smart agriculture are sum-\nmarized. Firstly, it reviews the differences\
    \ between 5G compared with current and previ-\nous communication technologies.\
    \ Following that, combined with the characteristics of the \nagricultural Internet\
    \ of Things, the reform and impact of 5G on it are summarized and \nFigure 6.\
    \ Shows the overall trend analysis of related papers.\nElectronics 2023, 12, 2336\n\
    7 of 46\nTable 3. Summary of smart agriculture.\nTime\nOverview Journals\nTheme\n\
    Key Words\n2017\nMekala M S et al. [25]\nSmart agriculture cloud computing\nSmart\
    \ agriculture, cloud\ncomputing\n2018\nRahul Dagar et al. [26]\nIntelligent Farm\
    \ IoT\nSmart Farm, IoT\n2019\nFarooq M S et al. [27]\nInvestigation on the Role\
    \ of the Internet of\nThings in Smart Farms\nSmart Farm, IoT\n2019\nDevare J et\
    \ al. [28]\nCrop generation detection and control\nDetection, crops\n2019\nFiona\
    \ J R et al. [29]\nImage processing and disease detection\nbased on image detection\
    \ in agriculture\nImage processing, disease\ndetection\n2019\nBh Ag At M et al.\
    \ [30]\nInternet of Things in Smart Farm\nSmart Farm, IoT\n2019\nSarker V et al.\
    \ [31]\nEdge computing Lora in the Internet\nof Things\nEdge computing, Lora\n\
    2019\nSmart et al. [32]\nSmart Farm\nSmart Farm\n2020\nVIPPON et al. [33]\nProgress\
    \ of Internet of Things\nin Agriculture\nIoT, Agriculture\n2020\nFriha O et al.\
    \ [34]\nNew technologies of the Internet of Things\nfor smart agriculture in the\
    \ future\nFuture smart agriculture IoT\n2021\nRayhana R et al. [35]\nRFID sensing\
    \ technology in\nsmart agriculture\nSmart agriculture, RFID,\nperception\n2021\n\
    Xing Yang et al. [36]\nInternet of Things for Smart Agriculture in\nthe Future\n\
    Smart agriculture, IoT\n2021\nYe Liu et al. [37]\nIndustry 4.0 to Agriculture\
    \ 4.0\nAgriculture 4.0\n2021\nBhat S A et al. [38]\nBig data and AI revolution\
    \ for\nprecision agriculture\nBig data, AI, precision\nagriculture\n2021\nGodwin\
    \ Idoje. et al. [39]\nProgress and challenges of intelligent\nagriculture Internet\
    \ of Things\nSmart agriculture, IoT\n2021\nWen Tao et al. [40]\nProgress and challenge\
    \ of intelligent\nagriculture Internet of Things\ncommunication technology\nSmart\
    \ agriculture, IoT,\ncommunication technology\n2021\nGodwin Idoje et al. [41]\n\
    Technological progress and challenges of\nsmart farms\nSmart Farm\n2022\nN. N.\
    \ Misra et al. [42]\nInternet of Things, Artiﬁcial Intelligence\nand Big Data\
    \ in Agriculture and\nFood Industry\nFood industry\n1.3. Summary\n1.3.1. Contribution\n\
    In this paper, the research and prospects of 5G joint IoT in smart agriculture\
    \ are\nsummarized. Firstly, it reviews the differences between 5G compared with\
    \ current and\nprevious communication technologies. Following that, combined with\
    \ the characteristics\nof the agricultural Internet of Things, the reform and\
    \ impact of 5G on it are summarized\nand prospected. Finally, combined with the\
    \ application paradigm of 5G and smart agricul-\ntural IoT, the possible challenges\
    \ are put forward, and some potential research issues are\npointed out.\n1.3.2.\
    \ Organization\n5G-oriented intelligent agricultural Internet of Things is an\
    \ essential direction of smart\nagriculture in the future. This paper intends\
    \ to summarize the relevant research status\nand possible research directions\
    \ from the following perspectives. The rest of this article is\nElectronics 2023,\
    \ 12, 2336\n8 of 46\nstructured as show in Figure 7. In this paper, the impact\
    \ of 5G on the Internet of Things\nfor smart agriculture is sorted out, and the\
    \ potential application scenarios and existing\nchallenges are summarized.\nPEER\
    \ REVIEW \n8 of 46\nThesises Overview\n• \nSmart agriculture\n• \n5G-IoT in Smart\
    \ agriculture\n• \nSummary\nPart I: Introduction\n• \n5G Characteristics\n• \n\
    Typical Applications of Smart Agricultural \nIoT based on 5G\n• \nFuture Trends\
    \ and Key Technologies of 5G \nIoT Application in Smart Agriculture\nPart II:\
    \ Integration and Application of 5G and \nSmart Agricultural Internet of Things\n\
    • \n5G Smart Agricultural IoT 2.0 Architecture\n• \n5G Smart agricultural IoT\
    \ Depth \nComprehensive Sense\n• \nReliable Data-driven detection of 5G Smart\
    \ \nAgricultural IoT\n• \nCloud Edge Fog Computing Fusion in 5G \nSmart Agricultural\
    \ IoT\n• \n5G Smart Agricultural IoT in-depth Service\n• \n5G Smart Agricultural\
    \ IoT Production \nintelligent control\nPart III: Evolution of Smart Agricultural\
    \  2.0 for \n5G\n• \nMain Application Scenarios of 5G Smart \nAgricultural IoT\n\
    • \nDepth Sense of 5G Smart Agriculture\n• \n5G Smart Agricultural Machinery\n\
    • \n5G Agricultural UAV\n• \nSmart agricultural Supply Chain \nManagement under\
    \ 5G\nPart IV: Revolution of smart agricultural iot \napplication paradigm under\
    \ 5G\n• \nFusion and Optimization of Sparse 5G base \nStation and Heterogeneous\
    \ Sensing \nnetwork in Smart agriculture\n• \nOptimization Control for Edge Computing\
    \ \nin 5G Smart Agricultural Production\n• \nScheduling Optimization of Heterogeneous\
    \ \nNodes under 5G Smart Agriculture\n• \nFault Detection and Self-healing for\
    \ 5G \nSmart Agricultural Platform\n• \nAI Application Optimization for 5G Smart\
    \ \nAgricultural IoT\n• \n5G-IoT System Service Model for Smart \nAgriculture\n\
    • \nSecurity Issues of 5G IoTs for Smart \nAgriculture\nPart V: Key Issues and\
    \ Challenges of 5G Smart \nAgricultural IoT\nPart VI: Summary\n \nFigure 7. Structure\
    \ of this article. \n2. Integration and Application of 5G and Smart Agricultural\
    \ Internet of Things \n2.1. 5G Characteristics \nThe existing agricultural IoT\
    \ uses various communication technologies in its appli-\ncation, including Zigbee,\
    \ Wifi, Sigfox, and so on. As a new generation of communication\nmode, 5G is compared\
    \ with the characteristics of other communication modes in agricul-\ntural scenes.\
    \ Table 4 summarizes how 5G compares to other communication technologies\ncommonly\
    \ used in the Internet of Things. 5G has its own characteristics. \nFigure 7.\
    \ Structure of this article.\n2. Integration and Application of 5G and Smart Agricultural\
    \ Internet of Things\n2.1. 5G Characteristics\nThe existing agricultural IoT uses\
    \ various communication technologies in its appli-\ncation, including Zigbee,\
    \ Wiﬁ, Sigfox, and so on. As a new generation of communication\nmode, 5G is compared\
    \ with the characteristics of other communication modes in agricul-\ntural scenes.\
    \ Table 4 summarizes how 5G compares to other communication technologies\ncommonly\
    \ used in the Internet of Things. 5G has its own characteristics.\nElectronics\
    \ 2023, 12, 2336\n9 of 46\nTable 4. 5G compared with other related communication\
    \ technologies.\nParameter\nStandard\nFrequency\nBand\nTime\nDelay\nData Rate\n\
    Transmission\nDistance\nEnergy Con-\nsumption\nCost\nNetwork\nSize\n5G\n3GPP\n\
    Release-16\n3–6 GHz\nLow\n100 Mb/s–\n10 Gb/s\nBase station\nsignal\ncoverage area\n\
    Medium\nMedium\nInﬁnite\n4G\nLTE\n2.4 G/865\nMHz\nMedium\n10 Mb/s–\n1 Gb/s\nBase\
    \ station\nsignal\ncoverage area\nMedium\nMedium\nInﬁnite\nZigbee\nIEEE\n802.15.4\n\
    2.4 G\nHigh\n20–250\nKb/s\nWithin 100 m\nLow\nLow\nBelow 500\nWiﬁ\nIEEE 802.11\n\
    5 GHz-60\nGHz\nMedium\n1 Mb/s–\n7 Gb/s\nLess than\n100 m\nMedium\nMedium\nBelow\
    \ 100\nNB-IoT\n3GPP\nRelease 13\n850–900\nMHz\nHigh\n160–250\nkbps\nBase station\n\
    signal\ncoverage area\nExtremely\nlow\nLow\n<50,000\nSigFox\nSigFox\n200 KHz\n\
    High\n100–600\nbit/s\nBase station\nsignal\ncoverage area\nLow\nLow\n<50,000\n\
    RFID\nISO18000-\n6C\n860–960\nMhz\nLow\n40–160\nkbit/s\n1–5 m\nLow\nLow\n<1000\n\
    It can be seen that 5G has its own characteristics compared with other communication\n\
    technologies, with incomparable advantages in terms of large bandwidth, large\
    \ connection,\nand low delay. Therefore, the emergence of 5G may bring new changes\
    \ and opportunities\nto the existing agricultural production mode in many agricultural\
    \ application scenarios.\nCompared with the 1G voice era, 2G text era, 3G picture\
    \ era, and the recent 4G video\nera, the application scenarios of 5G will get\
    \ a leapfrog development. Compared with 2G\nto 4G, which are born to connect “people”,\
    \ with the advent of the Internet of everything\nera, mobile communication networks\
    \ need to evolve to connect “things”. 5G is facing the\ncommon demand of large\
    \ trafﬁc and small data, mobile broadband on the one hand, and\nthe Internet of\
    \ Things on the other. Its main features are as follows in Figure 8.\nElectronics\
    \ 2023, 12, x FOR PEER REVIEW \n9 of 46 \n \nNB-IoT \n3GPP Re-\nlease 13 \n850–900\
    \ MHz \nHigh \n160–250 \nkbps \nBase station \nsignal coverage \narea \nExtremely\
    \ low \nLow \n<50,000 \nSigFox \nSigFox \n200 KHz \nHigh \n100–600 \nbit/s \n\
    Base station \nsignal coverage \narea \nLow \nLow \n<50,000 \nRFID \nISO18000-\n\
    6C \n860–960 Mhz \nLow \n40–160 \nkbit/s \n1–5 m \nLow \nLow \n<1000 \nIt can\
    \ be seen that 5G has its own characteristics compared with other communication\
    \ \ntechnologies, with incomparable advantages in terms of large bandwidth, large\
    \ connec-\ntion, and low delay. Therefore, the emergence of 5G may bring new changes\
    \ and oppor-\ntunities to the existing agricultural production mode in many agricultural\
    \ application sce-\nnarios. \nCompared with the 1G voice era, 2G text era, 3G\
    \ picture era, and the recent 4G video \nera, the application scenarios of 5G\
    \ will get a leapfrog development. Compared with 2G \nto 4G, which are born to\
    \ connect “people”, with the advent of the Internet of everything \nera, mobile\
    \ communication networks need to evolve to connect “things”. 5G is facing the\
    \ \ncommon demand of large traffic and small data, mobile broadband on the one\
    \ hand, and \nthe Internet of Things on the other. Its main features are as follows\
    \ in Figure 8. \nq eMBB Enhanced Mobile \nBroadband\nq URLLC ultra reliable low\
    \ delay \ncommunication\nq mMTC Massive Machine Class \nCommunication\nFour characteristics\
    \ of 5G\n• \nUbiquitous\n• \nlow power \nconsumption\n• \nNetwork \nvirtualization\n\
    • \nNetwork intelligence\nq Wireless access technology\nq Network reconfiguration\
    \ \ntechnology\nq Distributed Business Services\nThree application scenarios of\
    \ \n5G\n 5G key technologies\n \nFigure 8. 5G technical introduction. \nThe development\
    \ and deployment of 5G have provided the communication layer \nfoundation for\
    \ access and transmission to realize the “Internet of everything” in a real \n\
    sense. Gb/S span will be realized not only in the field of mobile communication.\
    \ It can also \nprovide 3D, UHD video, AR/VR, cloud office, and other immersive\
    \ interactive methods \nto upgrade. It will also give birth to more new agricultural\
    \ application scenarios. The three \nmajor application scenarios of 5G application\
    \ services include Enhanced Mobile Broad-\nband (eMBB), Massive Machine Type Communications\
    \ (mMTC), and ultra-reliable and \nLow Latency Communications (uRLLC). The latter\
    \ two belong to the application scenarios \nof the Internet of Things [43,44],\
    \ as shown in Figure 9. \n100Gbps \neMBB\nSmart \nagriculture\nSmart \nhome\n\
    3D Video\nvirtual \nreality\nIndustrial \nInternet of\nLow\nMiddle High\nConnection\
    \ \ndensity：\n100m/km2\nPeak data \nrate: \n10Gpbs\nSpace \ncapacity: \n10Mbit/s/\n\
    m2\nEnergy \nefficiency\nFigure 8. 5G technical introduction.\nThe development\
    \ and deployment of 5G have provided the communication layer\nfoundation for access\
    \ and transmission to realize the “Internet of everything” in a real\nsense. Gb/S\
    \ span will be realized not only in the ﬁeld of mobile communication. It can also\n\
    provide 3D, UHD video, AR/VR, cloud ofﬁce, and other immersive interactive methods\
    \ to\nupgrade. It will also give birth to more new agricultural application scenarios.\
    \ The three\nmajor application scenarios of 5G application services include Enhanced\
    \ Mobile Broadband\n(eMBB), Massive Machine Type Communications (mMTC), and ultra-reliable\
    \ and Low\nLatency Communications (uRLLC). The latter two belong to the application\
    \ scenarios of\nthe Internet of Things [43,44], as shown in Figure 9.\nElectronics\
    \ 2023, 12, 2336\n10 of 46\nFigure 9. 5G: The three major application scenarios.\n\
    2.2. Typical Applications of Intelligent Agricultural Iot Based on 5G\nBased on\
    \ the above analysis, the three application scenarios of 5G, eMBB, mMTC,\nand\
    \ uRLLC will be widely applied in smart agriculture. It will signiﬁcantly improve\n\
    the connectivity between smart agriculture stakeholders, user products, and data.\
    \ The\nfollowing Figure 10 shows the typical application scenarios.\nElectronics\
    \ 2023, 12, x FOR PEER REVIEW \n10 of 46 \n \n2.2. Typical Applications of Intelligent\
    \ Agricultural Iot Based on 5G \nBased on the above analysis, the three application\
    \ scenarios of 5G, eMBB, mMTC, \nand uRLLC will be widely applied in smart agriculture.\
    \ It will significantly improve the \nconnectivity between smart agriculture stakeholders,\
    \ user products, and data. The follow-\ning Figure 10 shows the typical application\
    \ scenarios. \nSmart Agriculture Scenarios \nunder 5G\nEnhanced Mobile \nBroadband\
    \ (eMBB)\nLarge scale machine \ncommunication (mMTC)\nUltra high reliability and\
    \ low delay \ncommunication (uRLLC)\nVideo monitoring of \nplant protection\n\
    UAV mapping/spectral \nimaging\nComplex Image/Video \nProcessing Based on Deep\
    \ \nLearning/AI\nFacility agriculture/stereoscopic \nagriculture: massive sensor\
    \ data \ntransmission\nIntelligent agricultural \nmachinery operation\nPerceptual\
    \ Monitoring \nof Field Agriculture\nData perception in \nfacility agriculture\n\
    Massive perceptual \nmonitoring in fishery and \naquaculture scenes\nAgricultural\
    \ UAV \noperation\nAutomatic driving of \nagricultural machinery\nHigh intelligence\
    \ and \nprecision agriculture scene: \nmassive sensing equipment\nKey point monitoring\
    \ \nand early warning\n \nFigure 10. 5G application scenarios in smart agriculture.\
    \ \n2.2.1. Enhance Mobile Broadband Applications (eMBB) in Smart Agricultural\
    \ IoT \nWith the improvement of intelligence in smart agriculture, there is increasing\
    \ data \ninformation, which needs the support of large data transmission rate.\
    \ The high bandwidth \nof 5G will be able to support high-definition video transmission\
    \ and massive data trans-\nmission. Successful real-time transmission of HD data\
    \ will enable remote real-time detec-\ntion, as well as the combination of machine\
    \ learning algorithms to transmit HD video back \nfor rapid analysis and computation.\
    \ Secondly, massive data transmission can be combined \nwith deep learning algorithms\
    \ to analyze and calculate plant diseases and insect pests \n[45,46] and quick\
    \ weed control. \nThe integrated application of 5G will promote the planting industry\
    \ to realize intel-\nligent planting technology, intelligent agricultural management,\
    \ open planting process, \nand intelligent labor management. 5G network, artificial\
    \ intelligence image recognition, \nsatellite remote sensing [47], big data, and\
    \ other technologies are used to drive all kinds \nof unmanned agricultural machinery\
    \ equipment to realize automatic operation. Including \naerial plant protection\
    \ UAV, unmanned highland gap plant protection machines, rototil-\nler, corn planters,\
    \ unmanned sprinkler irrigation systems, etc., to achieve safe, reliable, \nenvironmental\
    \ protection and energy-saving farm operations. It can also monitor agricul-\n\
    tural production in real-time, realize rapid detection of crop diseases, pests,\
    \ weeds, farm-i\nFigure 10. 5G application scenarios in smart agriculture.\n2.2.1.\
    \ Enhance Mobile Broadband Applications (eMBB) in Smart Agricultural IoT\nWith\
    \ the improvement of intelligence in smart agriculture, there is increasing data\n\
    information, which needs the support of large data transmission rate. The high\
    \ band-\nwidth of 5G will be able to support high-deﬁnition video transmission\
    \ and massive data\ntransmission. Successful real-time transmission of HD data\
    \ will enable remote real-time\ndetection, as well as the combination of machine\
    \ learning algorithms to transmit HD video\nback for rapid analysis and computation.\
    \ Secondly, massive data transmission can be\ncombined with deep learning algorithms\
    \ to analyze and calculate plant diseases and insect\npests [45,46] and quick\
    \ weed control.\nThe integrated application of 5G will promote the planting industry\
    \ to realize intel-\nligent planting technology, intelligent agricultural management,\
    \ open planting process,\nand intelligent labor management. 5G network, artiﬁcial\
    \ intelligence image recognition,\nsatellite remote sensing [47], big data, and\
    \ other technologies are used to drive all kinds of\nunmanned agricultural machinery\
    \ equipment to realize automatic operation. Including\naerial plant protection\
    \ UAV, unmanned highland gap plant protection machines, rototiller,\ncorn planters,\
    \ unmanned sprinkler irrigation systems, etc., to achieve safe, reliable, envi-\n\
    Electronics 2023, 12, 2336\n11 of 46\nronmental protection and energy-saving farm\
    \ operations. It can also monitor agricultural\nproduction in real-time, realize\
    \ rapid detection of crop diseases, pests, weeds, farmland\nwater quality, and\
    \ soil, provide ﬁne-grained nutrition, ventilation, and water supply for\ncrops,\
    \ and improve productivity [48,49].\nIn the 5G smart farm [50], the shading system,\
    \ fresh air system, cooling system,\nfertilization and watering system, data acquisition\
    \ system, and light supplement system\nachieved 5G control. For example, intelligent\
    \ glass greenhouse food production can also\nachieve substantial growth. Mobile\
    \ robots based on 5G can complete panoramic collection.\nAlong with the cultivation\
    \ tank of the greenhouse, it automatically completes inspection,\nﬁxed-point collection,\
    \ automatic return, automatic charging, and other actions. If there\nare obstacles\
    \ along the way, it can automatically go around. Real-time acquisition of\nhigh-deﬁnition\
    \ video data by video sensing nodes can solve the delay problem of massive\ndata\
    \ transmission based on edge computing devices and artiﬁcial intelligence, improve\n\
    quick response ability, and realize front-end intelligent decision-making [51].\
    \ All kinds of\nintelligent agriculture applications based on video processing\
    \ are shown in Table 5.\nTable 5. Video image processing in smart agriculture.\n\
    Literature\nApplication Scenario\nData Type\nGarcia [52]\nDistributed precision\
    \ agriculture\nVideo and Data\nHe Liu [53]\nVideo segmentation\nVideo\nSabzi S\
    \ [54]\nMonitoring of potato weeds in video\nVideo\nHe Jiang [55]\nFruit disease\
    \ surveillance based on deep learning\nImage\nIt can be seen that there are many\
    \ intelligent agricultural applications based on video\nimage detection at present.\
    \ With the continuous development of video acquisition equip-\nment, HD images\
    \ and videos are becoming increasingly popular. Optimizing data trans-\nmission\
    \ has always been a challenge. The integrated application of smart agriculture\
    \ based\non 5G is a big direction.\n2.2.2. Large-Scale Machine Type Communication\
    \ (mMTC) in Smart Agricultural IoT\nSmart agricultural IoT is the next generation\
    \ of agricultural IoT for smart agriculture.\nIt needs a depth perception of the\
    \ agricultural production process. Large-scale agricultural\nproduction scenarios\
    \ require large-scale sensing nodes to transmit data [56]. Traditional\nsensor\
    \ networks have some difﬁculties in networking reliability, energy efﬁciency,\
    \ and\ndeployment cost. However, large-scale machine-type communication based\
    \ on 5G can\nachieve a smart agricultural IoT with low cost, high reliability,\
    \ low power consumption,\nand convenient networking and deployment. For example,\
    \ NB-IoT can be deployed to\nquickly monitor soil, fertilizer, and plants in farmland.\
    \ In this way, the comprehensive\nperception and depth perception of agricultural\
    \ production can be realized, providing\nsupport for the deepening application\
    \ of smart agriculture [57].\n5G-oriented NB-IoT enables dense sensing network\
    \ deployment. Combining com-\nputer vision and other technologies can effectively\
    \ extract plant phenotypic variation\nand its related information. Moreover, machine\
    \ learning, artiﬁcial intelligence, and other\ncutting-edge technologies are used\
    \ for processing [58]. Deep learning convolutional neural\nnetworks were used\
    \ to evaluate crop phenotypic characteristics and soil conditions. Multi-\nspectral\
    \ imaging in agricultural areas is based on IoT sensors and small unmanned aerial\n\
    vehicles (UAVs). It identiﬁes plant quality and leaf diseases.\n2.2.3. Ultra-Reliable\
    \ Low Latency Communication (uRLLC) in Smart Agricultural IoT\nSuch ultra-reliable\
    \ low-latency communication applications are generally oriented to\nmission-critical,\
    \ real-time transmission of critical data and control of major agricultural\n\
    equipment [59]. Drones based on 5G networks can achieve precision operations.\
    \ The\nElectronics 2023, 12, 2336\n12 of 46\nﬂight trajectory and situation data\
    \ of the UAV can be returned to the 5G network UAV\nmanagement and operation platform\
    \ in real-time through the 5G network. Flight status can\nbe monitored in real-time\
    \ [60]. Through the agricultural information collected by UAV and\nsatellite remote\
    \ sensing technology, the platform can intelligently and dynamically analyze\n\
    the crop situation in the monitoring region, make a macroscopic estimation of\
    \ the real-time\nseedling situation, environmental dynamics and distribution of\
    \ crops, and output scientiﬁc\nreports [61]. According to the report, farmers\
    \ can clearly grasp the growth situation of\ncrops and soil moisture and manage\
    \ production in response to problems so as to ensure\nmore scientiﬁc and efﬁcient\
    \ farming activities.\nThe universal application of 5G will provide the communication\
    \ basis for unmanned,\nintelligent, and intelligent agricultural machinery and\
    \ equipment because 5G technology\nhas the characteristics of high speed, short\
    \ delay, low power consumption, ubiquitous\nnetwork, and scalability. It will\
    \ shine in the ﬁelds of agricultural Internet of Things,\nprecision planting,\
    \ agricultural products circulation traceability, agricultural drones, smart\n\
    farming, agricultural industry services, and so on, and promote agriculture to\
    \ be more\ninformationalized and intelligent [62,63].\n2.3. Future Trends and\
    \ Key Technologies of 5G-IoT Application in Smart Agriculture\nIt can be seen\
    \ from the above analysis that the integration of 5G and IoT has a wide\napplication\
    \ prospect in the scenario of smart agriculture. Agricultural IoT can be used\
    \ to\ncollect environmental monitoring information on crop growth and process\
    \ this information\nto develop the production plan of precision agriculture. Precision\
    \ agriculture requires\nthe network to support the connection of massive devices\
    \ and a large number of small\ndata packets. Since agricultural IoT devices are\
    \ often deployed in areas where signals are\nchallenging to reach, such as mountains,\
    \ forests, and waters, 5G can meet the requirements\nwith stronger coverage capability,\
    \ ﬂexibility, scalability, and lower power consumption,\ndelay, and cost. The\
    \ future trends of intelligent agricultural IoT facing 5G mainly reﬂect\nthe following:\n\
    1.\nCloud edge collaboration: agricultural monitoring terminal and cloud collaboration.\n\
    2.\nCloud computing/AI/big data/Internet of Things/digital twin and other agricul-\n\
    tural integration.\n3.\nVirtualization and servitization of perception/access/communication\
    \ layer, software\ndeﬁned network.\n4.\nModel-driven, cloud-native new application\
    \ (APP) development environment for\nsmart Internet of Things.\n5.\nThe deep integration\
    \ of people, information space, and physical space will form\na deep intelligent\
    \ smart agriculture and achieve a harmonious ecology of human–\nmachine symbiosis.\n\
    The key technologies of IoT applications in smart agriculture include vital informa-\n\
    tion sensor technology, phenotype information acquisition technology, phenotype\
    \ group\ndata analysis technology, phenotype group big data management and database\
    \ building\ntechnology, etc. [64,65]. All these technologies need the support\
    \ of 5G. Among them,\nthe life information sensor technology collects information\
    \ about seeds and their propa-\ngation/seed production environment and obtains\
    \ the corresponding physiological and\necological information through signal transformation\
    \ and AI data processing. Phenotypic\ninformation acquisition technology automatically\
    \ extracts important phenotypic features\nand logical relationships from massive\
    \ amounts of information to realize automatic and\naccurate identiﬁcation of phenotypic\
    \ traits. Phenotypic data analysis technology covers the\ncomplete process from\
    \ the initial data collection to the ﬁnal reﬁnement analysis. Phenotype\ngroup\
    \ big data management and database building technology are used to manage, store,\n\
    and share tabular data.\nElectronics 2023, 12, 2336\n13 of 46\n3. Evolution of\
    \ Intelligent Agricultural IoT 2.0 for 5G\nIntelligent Internet of Things (IoT\
    \ 2.0) refers to a complex system that integrates “hu-\nman, information space\
    \ and physical space” [66] under the guidance of 5G and other\ncommunication technologies\
    \ and AI technologies and intelligently interconnects and serves\ncooperatively.\
    \ Among them, the new generation of AI technologies includes data-driven\ndeep\
    \ reinforcement learning intelligence, network-based swarm intelligence, hybrid\
    \ in-\ntelligence oriented by human–machine and brain–computer interaction technology,\
    \ cross-\nmedia inference intelligence, autonomous intelligent system, etc. The\
    \ “wisdom” of the\nsmart IoT system refers to the interconnection of people, information\
    \ space and physi-\ncal space, and the digitalization, IoT, servitization (cloud),\
    \ collaboration, customization,\nﬂexibility, greenness, and intelligence of the\
    \ layered and progressive system [67].\nThe Internet of Things is evolving into\
    \ the next generation. Under the role of 5G, the\nInternet of Things combined\
    \ with big data, machine learning, cloud services, and so on, will\nhave intelligent\
    \ characteristics. It can make the physical process and the information world\n\
    deep integration. The network level of the Internet of Things mainly includes\
    \ monitoring,\ndetection, computing, service, and control from bottom to top,\
    \ and these connotations will\nalso undergo profound changes.\n3.1. 5G Smart Agricultural\
    \ IoT 2.0 Architecture\nWith the rapid development of video business and various\
    \ vertical business applica-\ntions in smart agriculture, centralized data storage\
    \ and processing modes will face difﬁcult\nbottlenecks and pressures. The existing\
    \ Internet of Things architecture is difﬁcult to meet\nthe data return of big\
    \ data, which easily deteriorates network indicators and affects user\nexperience.\
    \ In this case, data processing capabilities and services need to be provided\n\
    near the edge of the network where the data are generated. With the development\
    \ of\n5G and the availability of relevant business requirements and network conditions,\
    \ edge\ncomputing has gradually achieved great development. Agricultural IoT is\
    \ evolving to\nSmart Agricultural IoT 2.0, where edge computing can alleviate\
    \ these defects of centralized\nIoT, and transfer computing tasks to the edge\
    \ service side to signiﬁcantly improve delay\nand energy consumption, especially\
    \ for delay and energy-sensitive IoT applications.\n5G IoT for smart agriculture\
    \ achieves optimal resource allocation through network\nslicing, SDN/VFN, and\
    \ other technologies. However, due to a large amount of sensing\ndata in the smart\
    \ agriculture scene, the real-time requirement is high. With the increase in\n\
    terminal computing power, the network architecture for smart agriculture will\
    \ also change.\nThe architecture of a smart IoT system is shown in Figure 11.\n\
    5G-based agricultural IoT can be implemented by deploying edge computing based\
    \ on\napplication needs. Edge computing migrates IT resources, such as computing\
    \ and storage,\nfrom traditional cloud data centers to users. IT shortens the\
    \ physical distance between\nusers and IT resources, achieves lower data interaction\
    \ delay, and saves network trafﬁc.\nThis provides users with low latency and high\
    \ stability of IT solutions. Edge computation\ndepends on edge nodes. The requirements\
    \ of edge nodes for smart agricultural IoT are\nnot strictly regulated. Compared\
    \ with the general sensor node thought and its computing\npower, the communication\
    \ ability is stronger. The deployment position is usually at the\nend of the network,\
    \ that is, the application site. After IoT edge applications are deployed,\nedge\
    \ nodes serve as extensions of remote IoT platforms on devices. Devices are managed\n\
    through cloud-edge collaboration. Edge nodes can provide computing and management\n\
    services for nearby devices, such as local management of low-latency services,\
    \ local control,\nand rule execution when disconnected from the cloud. The device\
    \ accesses the edge node\nand ﬁnally uploads data to the remote IoT platform through\
    \ the edge node, as shown in\nFigure 12.\nElectronics 2023, 12, 2336\n14 of 46\n\
    energy consumption, especially for delay and energy-sensitive IoT applications.\
    \ \n5G IoT for smart agriculture achieves optimal resource allocation through\
    \ netwo\nslicing, SDN/VFN, and other technologies. However, due to a large amount\
    \ of sensi\ndata in the smart agriculture scene, the real-time requirement is\
    \ high. With the increase\nterminal computing power, the network architecture\
    \ for smart agriculture will al\nchange. The architecture of a smart IoT system\
    \ is shown in Figure 11. \nPrivate \nnetwork \ntechnology\nInternet \nof Things\n\
    Smart sensor \nnetwork\nEthernet\nNew sensing unit\nRFID/Smart sensor/Camera coil,\
    \ GPS, Remote sensing, Radar, QR code\nEdge \ncomputing\nPerception and \nimplementation\
    \ \nof smart \nagriculture\nFog computing\nCloud \ncomputing\nSmart \nagriculture\
    \ \napplication\nEdge computing node \ndomain gateway\nPerception&M\nonitoring\n\
    Detection and \ncalculation\nComputing\nCloud \nservice\nControl\nSmart information\
    \ fusion \nand processing\n \nFigure 11. Architecture of the smart Internet of\
    \ Things system based on 5G. \n5G-based agricultural IoT can be implemented by\
    \ deploying edge computing bas\non application needs. Edge computing migrates\
    \ IT resources, such as computing and sto\nage, from traditional cloud data centers\
    \ to users. IT shortens the physical distance betwe\nusers and IT resources, achieves\
    \ lower data interaction delay, and saves network traf\nThis provides users with\
    \ low latency and high stability of IT solutions. Edge computati\ndepends on edge\
    \ nodes. The requirements of edge nodes for smart agricultural IoT a\nnot strictly\
    \ regulated. Compared with the general sensor node thought and its computi\npower,\
    \ the communication ability is stronger. The deployment position is usually at\
    \ t\nend of the network, that is, the application site. After IoT edge applications\
    \ are deploye\nedge nodes serve as extensions of remote IoT platforms on devices.\
    \ Devices are manag\nthrough cloud-edge collaboration. Edge nodes can provide\
    \ computing and manageme\nservices for nearby devices, such as local management\
    \ of low-latency services, lo\nFigure 11. Architecture of the smart Internet of\
    \ Things system based on 5G.\nElectronics 2023, 12, x FOR PEER REVIEW \ncontrol,\
    \ and rule execution when disconnected from the cloud. The de\nedge node and finally\
    \ uploads data to the remote IoT platform through \nshown in Figure 12. \n***\n\
    ***\n***\n***\n***\n***\n***\n***\n***\n***\n***\n***\n***\n***\n***\n***\n***\n\
    ***\n***\n***\n***\n***\nField agriculture\nPlant factory\nSmart breeding\nEdge\
    \ Server\nEdge Server\nEdge Server\n5G gateway\n5G gateway\n5G gateway\nRemote\
    \ cloud \nservice\n \nFigure 12. Application scenario diagram of the edge computing\
    \ system of the a\nof Things. \n3.1.1. Personalized Service Network Slice in 5G\
    \ Intelligent Agricultural \nThings \nRequirements on network characteristics\
    \ (network speed, delay, n\nFigure 12. Application scenario diagram of the edge\
    \ computing system of the agricultural Internet\nof Things.\nElectronics 2023,\
    \ 12, 2336\n15 of 46\n3.1.1. Personalized Service Network Slice in 5G Intelligent\
    \ Agricultural Internet of Things\nRequirements on network characteristics (network\
    \ speed, delay, number of connec-\ntions, energy consumption, etc.) in different\
    \ agricultural application scenarios are different,\nand some are even contradictory.\
    \ For example, agricultural high-deﬁnition video surveil-\nlance cares about the\
    \ picture quality, and the overall delay of a few seconds or even more\nthan ten\
    \ seconds is not felt. In remote agricultural machinery driving, a delay of more\n\
    than 10 ms will seriously affect safety. Therefore, the purpose of splitting and\
    \ reﬁning the\nnetwork is to respond more ﬂexibly to the needs of smart agriculture\
    \ scenarios. Based on 5G\ntechnology, Network Slicing can be implemented, and\
    \ the Network can be divided into N\nlogical networks according to application\
    \ scenarios as shown in Figure 13. Different logical\nnetworks serve different\
    \ scenarios. Because of the diversiﬁcation of demand, networks\nneed diversiﬁcation.\
    \ The network must be ﬂexible because it needs to be sliced. Because\nthey move\
    \ ﬂexibly, the connections between networks also change ﬂexibly [68].\n \nThings\
    \ \nRequirements on network characteristics (network speed, delay, number of \n\
    tions, energy consumption, etc.) in different agricultural application scenarios\
    \ ar\nent, and some are even contradictory. For example, agricultural high-definition\
    \ vi\nveillance cares about the picture quality, and the overall delay of a few\
    \ seconds \nmore than ten seconds is not felt. In remote agricultural machinery\
    \ driving, a d\nmore than 10 ms will seriously affect safety. Therefore, the purpose\
    \ of splitting an\ning the network is to respond more flexibly to the needs of\
    \ smart agriculture sc\nBased on 5G technology, Network Slicing can be implemented,\
    \ and the Network\ndivided into N logical networks according to application scenarios\
    \ as shown in Fi\nDifferent logical networks serve different scenarios. Because\
    \ of the diversificatio\nmand, networks need diversification. The network must\
    \ be flexible because it nee\nsliced. Because they move flexibly, the connections\
    \ between networks also change\n[68]. \nNetwork slicing is a logical network partitioning\
    \ scheme implemented to m\ndifferent requirements of various applications, which\
    \ can ensure resource isolat\nservice guarantee between slices where different\
    \ services are located [69]. \nCrop growth \nmonitoring VWSN\nMoisture detection\
    \ \nNB IoT\nAgricultural UAV \nspraying formation\nRobot pest inspection \nformation\n\
    Slice 1 Video \nPerception\nSlice 2 narrowband \nsmall data\nOther slices\n5G\n\
    Intelligent agriculture IoT\nSlice 3 High real-time data \ntransmission service\n\
    \  \n \nFigure 13. Smart agriculture 5G-IoT network slice.\nNetwork slicing is\
    \ a logical network partitioning scheme implemented to meet the\ndifferent requirements\
    \ of various applications, which can ensure resource isolation and\nservice guarantee\
    \ between slices where different services are located [69].\n3.1.2. The 5G Intelligent\
    \ Agricultural Internet of Things (IoT) System Is Integrated with\n“Cloud, Network,\
    \ Edge, and End”\nThe impact of 5G on the Internet of Things for smart agriculture,\
    \ including the system\nnetwork architecture, will bring new changes. 5G intelligent\
    \ agricultural Internet of Things\nwill realize the integration of “cloud–network–edge–end”\
    \ and profoundly change the\nagricultural production form [70].\nUnder the role\
    \ of 5G, the future intelligent agricultural Internet of Things must be a\nsystem\
    \ of cloud-net-edge-end deep integration as shown in Figure 14. Realize the deep\
    \ in-\ntegration and control of agricultural production and information world.\
    \ The cloud realizes\nthe cloud of services and data, and the network includes\
    \ all kinds of networks represented\nby 5G. The self-consistency of intelligent\
    \ agricultural IoT is realized by combining edge\ncomputing and terminal nodes\
    \ [71].\nElectronics 2023, 12, 2336\n16 of 46\nUnder the role of 5G, the future\
    \ intelligent agricultural Internet of Things must be a \nsystem of cloud-net-edge-end\
    \ deep integration as shown in Figure 14. Realize the deep \nintegration and control\
    \ of agricultural production and information world. The cloud real-\nizes the\
    \ cloud of services and data, and the network includes all kinds of networks repre-\n\
    sented by 5G. The self-consistency of intelligent agricultural IoT is realized\
    \ by combining \nedge computing and terminal nodes [71]. \nCloud\nEdge \ncomputing\n\
    Sense \ndevice\nInterface\nComputing \nresource\nStorage \nresources\nNetwork\
    \ \nresource\nComputing/Network/Storage API\nControl area\nFunctional \nmodule\n\
    Analysis field\nFunctional \nmodule\nOptimization field\nFunctional module\nEdge\
    \ node:\nEdge gateway\nEdge controller\nEdge server\nEdge sensor\n  \nModel based\
    \ business \norchestration\nDirect resource call\nManagement Service\nSmart agriculture\
    \ Internet of Things application\nCloud service\n5G \n \nFigure 14. 5G-IoT service\
    \ architecture of cloud-edge collaborative smart agriculture. \n3.2. Perception\
    \ of Deep Fusion of 5G-Intelligent Agricultural Internet of Things \nSmart agriculture\
    \ is a form of deep intelligence of agricultural production and a form \nof deep\
    \ integration of the physical production process and information world. First,\
    \ the \nsmart agricultural IoT requires comprehensive and in-depth monitoring\
    \ of agricultural \nproduction processes and objects. This requires the support\
    \ of 5G, the intensive access of \nmassive sensing devices, the transmission of\
    \ large amounts of data, and the support of the \noperating system basic software\
    \ platform suitable for the new generation of IoT systems. \nThe end devices will\
    \ evolve. Meanwhile, the communication modules and architectures \nwill change.\
    \ \n3.2.1. Intelligent Agricultural IoT Sensing Device Based on 5G \nIn order\
    \ to adapt to the performance of the smart agricultural Internet of Things and\
    \ \nthe advantages of 5G, such as high speed, high density, low delay, low power\
    \ consump-\ntion, and wide coverage, the software and hardware of traditional\
    \ sensing devices need \nto be changed. \nThe carrier bandwidth of 5G communication\
    \ varies from 180 K to 200 M [72]. Com-\nmunication rates also range from a multi-point\
    \ uplink rate of 56 kbps for narrowband IoT \nto a maximum peak rate of 10 Gbps.\
    \ The 180 K carrier bandwidth is specifically targeted \nat low-rate NB-IoT applications,\
    \ featuring strong signal strength, strong penetration, and \ngood coverage radius\
    \ and depth coverage. It is mainly suitable for some IoT terminal \nFigure 14.\
    \ 5G-IoT service architecture of cloud-edge collaborative smart agriculture.\n\
    3.2. Perception of Deep Fusion of 5G-Intelligent Agricultural Internet of Things\n\
    Smart agriculture is a form of deep intelligence of agricultural production and\
    \ a form\nof deep integration of the physical production process and information\
    \ world. First, the\nsmart agricultural IoT requires comprehensive and in-depth\
    \ monitoring of agricultural\nproduction processes and objects. This requires\
    \ the support of 5G, the intensive access of\nmassive sensing devices, the transmission\
    \ of large amounts of data, and the support of the\noperating system basic software\
    \ platform suitable for the new generation of IoT systems.\nThe end devices will\
    \ evolve. Meanwhile, the communication modules and architectures\nwill change.\n\
    3.2.1. Intelligent Agricultural IoT Sensing Device Based on 5G\nIn order to adapt\
    \ to the performance of the smart agricultural Internet of Things and\nthe advantages\
    \ of 5G, such as high speed, high density, low delay, low power consumption,\n\
    and wide coverage, the software and hardware of traditional sensing devices need\
    \ to\nbe changed.\nThe carrier bandwidth of 5G communication varies from 180 K\
    \ to 200 M [72]. Com-\nmunication rates also range from a multi-point uplink rate\
    \ of 56 kbps for narrowband IoT\nto a maximum peak rate of 10 Gbps. The 180 K\
    \ carrier bandwidth is speciﬁcally targeted\nat low-rate NB-IoT applications,\
    \ featuring strong signal strength, strong penetration, and\ngood coverage radius\
    \ and depth coverage. It is mainly suitable for some IoT terminal\napplications\
    \ with low data rates and most of the time in hibernation state. Such applica-\n\
    tions are widely used in smart agriculture and many other applications, such as\
    \ ecological\nenvironment monitoring, because many plants and animals have long\
    \ growth cycles and\nslow changes. There are four typical applications of NB-IoT,\
    \ as shown in Table 6.\nSecondly, such applications mainly change the hardware\
    \ of sensor nodes in terms of\nantenna communication module and low-power design\
    \ [73,74]. The module of the terminal\nnode device based on NB-IoT will also change\
    \ correspondingly, as shown in Figure 15.\nElectronics 2023, 12, 2336\n17 of 46\n\
    Table 6. Four typical business types of NB-IoT.\nType\nDescribe\nScene\nAutonomous\
    \ exception\nreporting service type\nFor example, the notiﬁcation of smoke and\
    \ fog alarm\ndetector and smart electricity meter power failure, the\nminimum\
    \ data demand for uplink data (in the order of\ncross knots), and the cycle is\
    \ usually in years and months.\nFishery breeding, precision\nagriculture\nBusiness\
    \ type of independent\nperiodic report\nFor example, the measurement report of\
    \ intelligent utilities\n(gas/water/electricity), intelligent agriculture, intelligent\n\
    environment, etc., the uplink demand for small data volume\n(hundreds of bytes),\
    \ and the cycle is mostly in days\nand hours.\nPlant moisture, environmental\n\
    monitoring, climate monitoring\nNetwork instruction service\ntype\nFor example,\
    \ when the device is turned on/off, it triggers\nsending an uplink report, requests\
    \ meter reading and\nrequires minimal downlink data (in the order of cross knots).\n\
    The cycle is usually in days and hours.\nAutomatic irrigation, automatic\noxygenation,\
    \ etc.\nSoftware update business type\nFor example, software patches/updates require\
    \ a large\namount of data (kilobyte level) for uplink and downlink,\nand the cycle\
    \ is usually in days and hours.\nRemote System Update\nporting service \ntype\
    \ \nof cross knots), and the cycle is usually in years and \nmonths. \nture \n\
    Business type \nof independ-\nent periodic \nreport \nFor example, the measurement\
    \ report of intelligent \nutilities (gas/water/electricity), intelligent agriculture,\
    \ \nintelligent environment, etc., the uplink demand for \nsmall data volume (hundreds\
    \ of bytes), and the cycle \nis mostly in days and hours. \nPlant moisture, en-\n\
    vironmental moni-\ntoring, climate \nmonitoring \nNetwork in-\nstruction ser-\n\
    vice type \nFor example, when the device is turned on/off, it trig-\ngers sending\
    \ an uplink report, requests meter reading \nand requires minimal downlink data\
    \ (in the order of \ncross knots). The cycle is usually in days and hours. \n\
    Automatic irriga-\ntion, automatic ox-\nygenation, etc. \nSoftware up-\ndate business\
    \ \ntype \nFor example, software patches/updates require a large \namount of data\
    \ (kilobyte level) for uplink and down-\nlink, and the cycle is usually in days\
    \ and hours. \nRemote System \nUpdate \nSecondly, such applications mainly change\
    \ the hardware of sensor nodes in terms of \nantenna communication module and\
    \ low-power design [73,74]. The module of the termi-\nnal node device based on\
    \ NB-IoT will also change correspondingly, as shown in Figure \n15. \nPower supply\
    \ module\nSensor node\nData \nacquisition \nmodule\nMicrocontroller/\nMCU\nWireless\
    \ \nprocessing \nmodule\nWireless \ncommunication \nmodule\nStorage\nPower supply\
    \ module\nSensor node\nData \nacquisition \nmodule\nMicrocontroller/\nMCU\nWireless\
    \ \nprocessing \nmodule\nNB IoT \ncommunication \nmodule\nStorage\nNB-SIM \ncard\n\
    \ \nFigure 15. Sensing device communication module changes. \nThe communication\
    \ module is usually made of off-the-shelf modules or selected \nchips for design.\
    \ NB-IoT chips can be used by carriers of China Telecom, China Mobile, \nand China\
    \ Unicom. At the same time, Sim cards are required to order corresponding data\
    \ \nplans. \nMany application scenarios facing smart agriculture also require\
    \ large bandwidth \ndata transmissions, such as video and VR. 5G-oriented sensor\
    \ nodes can select 5G-ori-\nented high-bandwidth communication modules. Its communication\
    \ module baseband \nchips require specialized chips, such as Qualcomm, Huawei,\
    \ etc. Due to the high data rate, \nthe number and type of corresponding sensors\
    \ can also be diverse. In the meantime, the \ncorresponding processor, memory,\
    \ and power supply modules are completely different, \nas shown in Figure 16.\
    \ \nFigure 15. Sensing device communication module changes.\nThe communication\
    \ module is usually made of off-the-shelf modules or selected chips\nfor design.\
    \ NB-IoT chips can be used by carriers of China Telecom, China Mobile, and\nChina\
    \ Unicom. At the same time, Sim cards are required to order corresponding data\
    \ plans.\nMany application scenarios facing smart agriculture also require large\
    \ bandwidth\ndata transmissions, such as video and VR. 5G-oriented sensor nodes\
    \ can select 5G-oriented\nhigh-bandwidth communication modules. Its communication\
    \ module baseband chips\nrequire specialized chips, such as Qualcomm, Huawei,\
    \ etc. Due to the high data rate,\nthe number and type of corresponding sensors\
    \ can also be diverse. In the meantime, the\ncorresponding processor, memory,\
    \ and power supply modules are completely different, as\nshown in Figure 16.\n\
    Sensor nodes are equipped with 5G high-rate baseband chips for high-rate data\
    \ com-\nmunication. Multiple sensors can be integrated into appropriate scenarios\
    \ to improve\nthe integration degree, reduce the number of nodes and optimize\
    \ the network architec-\nture [75,76]. For example, the smart insecticidal lamp\
    \ can integrate a variety of sensors,\nas shown in Figure 17. When multiple sensors\
    \ are integrated, the bandwidth of the data\nstream changes. In the 5G scenario,\
    \ the architecture of the Internet of Things changes ac-\ncordingly, replacing\
    \ the traditional Zigbee network, etc. [77]. The change of communication\nmodule\
    \ will lead to an overall change of hardware. For example, low-power design, the\n\
    architecture of the main control chip, software change, power supply system design,\
    \ sensor\nintegration, etc. [78].\nElectronics 2023, 12, 2336\n18 of 46\nElectronics\
    \ 2023, 12, x FOR PEER REVIEW \n \nPower supply module\nSense Module \n1\nMicrocontroller/\n\
    MCU\nWireless \nprocessing \nmodule\n5G baseband \nchip\nMass storage\nSIM \n\
    card\nSense Module \n2\nSense Module \n3\nSense \nModule  \n4K Video Module\n\
    \ \n \nFigure 16. Sensor node composition model facing high rate facing 5G. \n\
    Sensor nodes are equipped with 5G high-rate baseband chips for high-rate da\n\
    munication. Multiple sensors can be integrated into appropriate scenarios to imp\n\
    integration degree, reduce the number of nodes and optimize the network arch\n\
    [75,76]. For example, the smart insecticidal lamp can integrate a variety of sen\n\
    shown in Figure 17. When multiple sensors are integrated, the bandwidth of t\n\
    stream changes. In the 5G scenario, the architecture of the Internet of Things\
    \ cha\ncordingly, replacing the traditional Zigbee network, etc. [77]. The change\
    \ of com\ntion module will lead to an overall change of hardware. For example,\
    \ low-power\nthe architecture of the main control chip, software change, power\
    \ supply system\nsensor integration, etc. [78]. \nScreen\nSoil moisture\nSoil\
    \ temperature and humidity\nEvaporation\nSoil PH\nRainfall\nPhotosynthetically\
    \ active radiation\nWind speed/direction\nSoil electrical conductivity\n \nFigure\
    \ 17. Multi-sensor system. \n3.2.2. 5G Intelligent Agricultural IoT Operating\
    \ System \nWith 5G, the hardware of IoT sensor nodes for smart agriculture has\
    \ change\nder to adapt to the application scenario, the corresponding software\
    \ system wi\nfected and changed. The vision goal of the Internet of Things with\
    \ 5G is the inter\ntion and interconnectivity of everything However the current\
    \ operating system\nFigure 16. Sensor node composition model facing high rate\
    \ facing 5G.\n4K Video Module\n \nFigure 16. Sensor node composition model facing\
    \ high rate f\nSensor nodes are equipped with 5G high-rate base\nmunication. Multiple\
    \ sensors can be integrated into ap\nintegration degree, reduce the number of\
    \ nodes and \n[75,76]. For example, the smart insecticidal lamp can\nshown in\
    \ Figure 17. When multiple sensors are integ\nstream changes. In the 5G scenario,\
    \ the architecture of\ncordingly, replacing the traditional Zigbee network, et\n\
    tion module will lead to an overall change of hardwar\nthe architecture of the\
    \ main control chip, software cha\nsensor integration, etc. [78]. \nScreen\nSoil\
    \ moisture\nSoil temperature and humidity\nEvaporation\nSoil PH\nRainfall\nPhotosynthetically\
    \ active radiation\nWind speed/direction\nSoil electrical conductivity\n \nFigure\
    \ 17. Multi-sensor system. \n3.2.2. 5G Intelligent Agricultural IoT Operating\
    \ System\nWith 5G, the hardware of IoT sensor nodes for sm\nder to adapt to the\
    \ application scenario, the correspo\nfected and changed. The vision goal of the\
    \ Internet of \ntion and interconnectivity of everything. However, the\nlt t\n\
    t thi\nl\nh\nth\nl\nk\nf i t\nFigure 17. Multi-sensor system.\n3.2.2. 5G Intelligent\
    \ Agricultural IoT Operating System\nWith 5G, the hardware of IoT sensor nodes\
    \ for smart agriculture has changed. In order\nto adapt to the application scenario,\
    \ the corresponding software system will be affected\nand changed. The vision\
    \ goal of the Internet of Things with 5G is the interconnection\nand interconnectivity\
    \ of everything. However, the current operating system is difﬁcult to\nsupport\
    \ this goal, such as the lack of interoperability of a lightweight operating system\
    \ [79].\nThe status quo of the Internet of Things operating system is shown in\
    \ Figure 18.\nElectronics 2023, 12, 2336\n19 of 46\nElectronics 2023, 12, x FOR\
    \ PEER REVIEW \n18 of 46 \n \n \nThe connection volume \nof IoT equipment has\
    \ \nreached 10 billion\nSoftware and hardware \ncoupling is seriously lagging\
    \ \nbehind the industry \nstandard\nThe R&D cycle of the \noperating system is\
    \ 4-\n5 years\nThe cost of software development \nand system integration R&D of\
    \ a \nsingle SKU is more than 300000 \ndollars\nMany terminals\nSystem mismatch\n\
    Long R&D cycle\nHigh R&D cost\nMany brands\nIncompatible\nThe products cannot\
    \ be linked \nwith each other, and the sense of \nuse of intelligent operation\
    \ is poor\nThe Internet of Things giant has \nformed a monopoly and the \nmarket\
    \ competition is insufficient\n \nFigure 18. The status quo of the Internet of\
    \ Things operating system. \nThe current Internet of Things operating system has\
    \ made great progress [80]. Inter-\nnet of Things operating system brands, and\
    \ complementary compatibility, restrict the \ngreat development of the Internet\
    \ of Things. In order to achieve the goal of the Internet of \neverything in the\
    \ 5G scenario, its operating system will need to change in the future. \nA typical\
    \ IoT system is shown in the following Figure 19. Among them, the operating \n\
    system is an important middle part applied to the bottom layer, which is related\
    \ to the \nkey to cloud interconnection and is the key to realizing the seamless\
    \ interaction between \npeople and things. Future IoT operating system requirements\
    \ are shown in Figure 20. \nAgentTiny\nLiteOS\nMCU\nCloud\nDevice\nOceanConnet\
    \ \nIoT Platform\nOther IoT \nPlatform\n \nFigure 19. Huawei 5G IoT system. \n\
    Cross \nplatform\nInteroperabi\nlity\nlow cost\nStrong \nsecurity\nCloud\nHeterogeneous\
    \ \nterminal\n \nFigure 20. Future IoT operating system requirements. \nMany scholars\
    \ have conducted many beneficial studies on the operating system of \nthe Internet\
    \ of Things [81,82], mostly for applications, real-time scheduling, kernel design,\
    \ \nand so on. Less attention is paid to the architecture of future sensor operating\
    \ systems. It \nsummarized the current major IoT operating systems in Table 7.\
    \ In the future, under the \ncondition that the data bandwidth is satisfied, highly\
    \ intelligent is the due connotation of \nsmart agriculture. The concept of a\
    \ sensor node is more general, as there is not only a \nFigure 18. The status\
    \ quo of the Internet of Things operating system.\nThe current Internet of Things\
    \ operating system has made great progress [80]. Internet\nof Things operating\
    \ system brands, and complementary compatibility, restrict the great\ndevelopment\
    \ of the Internet of Things. In order to achieve the goal of the Internet of\n\
    everything in the 5G scenario, its operating system will need to change in the\
    \ future.\nA typical IoT system is shown in the following Figure 19. Among them,\
    \ the operating\nsystem is an important middle part applied to the bottom layer,\
    \ which is related to the key\nto cloud interconnection and is the key to realizing\
    \ the seamless interaction between people\nand things. Future IoT operating system\
    \ requirements are shown in Figure 20.\nThe connection volume \nof IoT equipment\
    \ has \nreached 10 billion\nSoftware and hardware \ncoupling is seriously lagging\
    \ \nbehind the industry \nstandard\nThe R&D cycle of the \noperating system is\
    \ 4-\n5 years\nThe cost of software development \nand system integration R&D of\
    \ a \nsingle SKU is more than 300000 \ndollars\nMany terminals\nSystem mismatch\n\
    Long R&D cycle\nHigh R&D cost\nMany brands\nIncompatible\nThe products cannot\
    \ be linked \nwith each other, and the sense of \nuse of intelligent operation\
    \ is poor\nThe Internet of Things giant has \nformed a monopoly and the \nmarket\
    \ competition is insufficient\n \nFigure 18. The status quo of the Internet of\
    \ Things operating system. \nThe current Internet of Things operating system has\
    \ made great progress [80]\nnet of Things operating system brands, and complementary\
    \ compatibility, restr\ngreat development of the Internet of Things. In order\
    \ to achieve the goal of the Inte\neverything in the 5G scenario, its operating\
    \ system will need to change in the futur\nA typical IoT system is shown in the\
    \ following Figure 19. Among them, the ope\nsystem is an important middle part\
    \ applied to the bottom layer, which is related\nkey to cloud interconnection\
    \ and is the key to realizing the seamless interaction be\npeople and things.\
    \ Future IoT operating system requirements are shown in Figure\nAgentTiny\nLiteOS\n\
    MCU\nCloud\nDevice\nOceanConnet \nIoT Platform\nOther IoT \nPlatform\n \nFigure\
    \ 19. Huawei 5G IoT system. \nCross \nplatform\nInteroperabi\nlity\nlow cost\n\
    Strong \nsecurity\nCloud\nHeterogeneous \nterminal\n \nFigure 20. Future IoT operating\
    \ system requirements. \nMany scholars have conducted many beneficial studies\
    \ on the operating sys\nthe Internet of Things [81,82], mostly for applications,\
    \ real-time scheduling, kernel d\nand so on. Less attention is paid to the architecture\
    \ of future sensor operating syst\nsummarized the current major IoT operating\
    \ systems in Table 7. In the future, und\ncondition that the data bandwidth is\
    \ satisfied, highly intelligent is the due connota\nsmart agriculture. The concept\
    \ of a sensor node is more general, as there is not \nFigure 19. Huawei 5G IoT\
    \ system.\nThe connection volume \nof IoT equipment has \nreached 10 billion\n\
    Software and hardware \ncoupling is seriously lagging \nbehind the industry \n\
    standard\nThe R&D cycle of the \noperating system is 4-\n5 years\nThe cost of\
    \ software development \nand system integration R&D of a \nsingle SKU is more\
    \ than 300000 \ndollars\nMany terminals\nSystem mismatch\nLong R&D cycle\nHigh\
    \ R&D cost\nMany brands\nIncompatible\nThe products cannot be linked \nwith each\
    \ other, and the sense of \nuse of intelligent operation is poor\nThe Internet\
    \ of Things giant has \nformed a monopoly and the \nmarket competition is insufficient\n\
    \ \nFigure 18. The status quo of the Internet of Things operating system. \nThe\
    \ current Internet of Things operating system has made great progress [80]\nnet\
    \ of Things operating system brands, and complementary compatibility, restr\n\
    great development of the Internet of Things. In order to achieve the goal of the\
    \ Inte\neverything in the 5G scenario, its operating system will need to change\
    \ in the futur\nA typical IoT system is shown in the following Figure 19. Among\
    \ them, the ope\nsystem is an important middle part applied to the bottom layer,\
    \ which is related\nkey to cloud interconnection and is the key to realizing the\
    \ seamless interaction be\npeople and things. Future IoT operating system requirements\
    \ are shown in Figure\nAgentTiny\nLiteOS\nMCU\nCloud\nDevice\nOceanConnet \nIoT\
    \ Platform\nOther IoT \nPlatform\n \nFigure 19. Huawei 5G IoT system. \nCross\
    \ \nplatform\nInteroperabi\nlity\nlow cost\nStrong \nsecurity\nCloud\nHeterogeneous\
    \ \nterminal\n \nFigure 20. Future IoT operating system requirements. \nMany scholars\
    \ have conducted many beneficial studies on the operating sys\nthe Internet of\
    \ Things [81,82], mostly for applications, real-time scheduling, kernel d\nand\
    \ so on. Less attention is paid to the architecture of future sensor operating\
    \ syst\nsummarized the current major IoT operating systems in Table 7. In the\
    \ future, und\ncondition that the data bandwidth is satisfied, highly intelligent\
    \ is the due connota\nsmart agriculture. The concept of a sensor node is more\
    \ general, as there is not \nFigure 20. Future IoT operating system requirements.\n\
    Many scholars have conducted many beneﬁcial studies on the operating system of\n\
    the Internet of Things [81,82], mostly for applications, real-time scheduling,\
    \ kernel design,\nand so on. Less attention is paid to the architecture of future\
    \ sensor operating systems. It\nsummarized the current major IoT operating systems\
    \ in Table 7. In the future, under the\nElectronics 2023, 12, 2336\n20 of 46\n\
    condition that the data bandwidth is satisﬁed, highly intelligent is the due connotation\n\
    of smart agriculture. The concept of a sensor node is more general, as there is\
    \ not only a\nsingle perception function but it may also have an executive function,\
    \ etc., based on edge\ncomputing, etc., to achieve node interoperability.\nTable\
    \ 7. List of IoT operating systems.\nIoT OS\nDescription/Provider\nNetworked Operating\
    \ System\nDescription/Provider\nBrillo [80]\nGoogle’s solution for building\n\
    connected devices\nLiteOS\nHuawei\nmbedOS\nARM Internet of Things device platform\n\
    TinyOS\nTencent\nRIoT [83]\nInternet of Things friendly operating system\nAliOS\
    \ Things\nAlibaba\nContiki [84]\nOpen source IoT operating system\nRT-Thread\n\
    Real time operating\nsystem (open source)\nZephyr\nScalable real-time operating\
    \ system for\nresource constrained systems\nWindows 10 IoT Core\nWindows\nNuttx\n\
    Standard compliant and small footprint\nreal-time operating system\nWatchOS\n\
    Apple\nWith an IoT operating system, from service connection to service application,\
    \ the\nultimate goal is service intelligence. In smart agriculture, with a 5G\
    \ scenario, the operating\nsystem of the Internet of Things also needs to serve\
    \ smart agriculture. Fuchsia OS and\nHarmony OS were developed by Google and Huawei.\
    \ The goal is to be able to run on a\nvariety of different hardware platforms,\
    \ with distributed operating systems based on the\nmicrokernel structure and running\
    \ more efﬁciently.\n3.2.3. Large-Scale Terminal Access of 5G Smart Agricultural\
    \ Monitoring Terminals\nA large number of sensing devices will be deployed in\
    \ the smart agricultural IoT for\nbreeding moisture monitoring, ﬁne agriculture,\
    \ and other scenarios. How to access massive\nterminals in LPWA for 5G low-power\
    \ wide area networks [85] is a challenging problem.\nWith the continuous improvement\
    \ of the capabilities of the air interface at the access end,\nthe performance\
    \ bottleneck of the whole system is gradually reﬂected in the core end, edge\n\
    end, and other areas. Therefore, there must also be corresponding innovative technologies\n\
    at the core or edge end to meet the nearly demanding requirements of 5G IoT applications\n\
    in the future [86]. However, the existing cellular network core architecture is\
    \ not suitable\nfor the development of the Internet of Things.\nThe deployment\
    \ of 5G has created the possibility for large-scale and intensive IoT\ndeployment,\
    \ but there are also challenges concerning reliable access and data transmission\n\
    and processing, as shown in Figure 21.\n3.3. Reliable Data-Driven Detection of\
    \ 5G Smart Agricultural IoT\nBased on the various kinds of data acquired by the\
    \ massive sensing devices, they can\nbe detected and processed to serve the upper-layer\
    \ applications. These acquired termi-\nnal underlying data can be used to detect\
    \ complex events in the process of agricultural\nproduction, provide intelligent\
    \ decision-making for smart agricultural production, im-\nproving the degree of\
    \ intelligence. Secondly, based on the breakthrough of current data\nvolume acquisition,\
    \ the breakthrough of machine learning algorithms, and the innovation\nof communication\
    \ technology, all kinds of image processing based on machine learning\nare gradually\
    \ popularized in smart agriculture. These lay the foundation for intelligent\n\
    agricultural production.\nElectronics 2023, 12, 2336\n21 of 46\n3.3.1. Complex\
    \ Event Detection in Agricultural Production\nComplex event detection for agricultural\
    \ production process [87]. Complex event\ndetection abstracts business data into\
    \ a sequence of events. Through the complex event\ndescription method, the potentially\
    \ valuable composite data are described as a speciﬁc\nevent-matching structure.\
    \ The complex event detection engine then detects the event\nsequence satisfying\
    \ the matching structure from a large number of event streams and\nﬁnally outputs\
    \ the data fusion results. The basic strategy of the event detection engine is\n\
    that all Events in the time window are called candidate Events, and the candidate\
    \ Events\ngenerate Matching sets according to the rules.\nectronics 2023, 12,\
    \ x FOR PEER REVIEW \nSupplier\nWarehouse\nCLOUD\n \nFigure 21. 5G large-scale\
    \ access of smart agricultural Internet of Things perce\n3.3. Reliable Data-Driven\
    \ Detection of 5G Smart Agricultural IoT \nBased on the various kinds of data\
    \ acquired by the massive sensin\nbe detected and processed to serve the upper-layer\
    \ applications. Thes\nunderlying data can be used to detect complex events in\
    \ the process \nduction, provide intelligent decision-making for smart agricultural\
    \ p\ning the degree of intelligence. Secondly, based on the breakthrough \nume\
    \ acquisition, the breakthrough of machine learning algorithms, an\ncommunication\
    \ technology, all kinds of image processing based on m\ngradually popularized\
    \ in smart agriculture. These lay the foundation\ncultural production. \n3.3.1.\
    \ Complex Event Detection in Agricultural Production \nComplex event detection\
    \ for agricultural production process [87]\ntection abstracts business data into\
    \ a sequence of events. Through the\nscription method, the potentially valuable\
    \ composite data are des\nFigure 21. 5G large-scale access of smart agricultural\
    \ Internet of Things perception terminal.\nThese data can be multimodal structural\
    \ and unstructured types of data. They are\nwidely used in smart agriculture scenarios.\
    \ When the sensing data are rich enough, the\ncomplex event rules can be established\
    \ through various moisture data and crop growth\nmodels to determine whether drip\
    \ irrigation and fertilization are needed [88,89]. In ﬁsh\nfarming, data collected\
    \ by various sensor devices deployed in ponds are used to determine\nwhether there\
    \ is a lack of oxygen or other complex events, and so on.\nThe detection conditions\
    \ of complex events ﬁrstly need rich physical world data, and\nenough sensing\
    \ devices need to be deployed so that various relationships can be discovered.\n\
    Second, complex computational processing power is required. For pattern matching\
    \ and\nso on, we need quick calculation and judgment. In addition, some complex\
    \ event detection\nis real-time, and these requirements become feasible with 5G.\n\
    3.3.2. Depth Detection of Pests and Diseases Based on Machine Learning\nWith the\
    \ development of information technology, methods based on machine learning\nhave\
    \ been widely used in agricultural production in recent years. Many scholars combine\n\
    image processing with pattern recognition, and widely use it in crop disease and\
    \ pest\nrecognition. The color, shape, texture, and other parameters extracted\
    \ were screened and\noptimized. The linear classiﬁer, Bayesian decision theory,\
    \ fuzzy recognition, and other\npattern recognition techniques were used to identify\
    \ and classify various crop pests and\nElectronics 2023, 12, 2336\n22 of 46\n\
    diseases, which improved the recognition accuracy. Thus, the development of agricultural\n\
    informatization and precision was further promoted [90].\nAs an important branch\
    \ of machine learning, deep learning network is becoming\na hot technology with\
    \ its powerful data analysis ability. Deep learning networks can\ncontain hundreds\
    \ of hidden layers, and the features will be transformed a lot of times.\nDeep\
    \ learning can be applied to identify crop pests and disease targets. For achieving\n\
    the relationship ﬁtting of complex sample data, the core idea is not only to automatically\n\
    extract multi-layer feature representations from a large amount of data through\
    \ a variety of\nlinear and nonlinear transformations but also to complete the\
    \ task of feature extraction and\ntransformation using supervised and unsupervised\
    \ combined training methods [91]. Due\nto the structure of a deep neural network,\
    \ the error features extracted by the previous layer\nnetwork can be weakened\
    \ to a certain extent, and the complex function can be expressed\nwith fewer parameters.\
    \ The structure of the deep neural network will be more compact,\nwhich improves\
    \ the efﬁciency and performance of the network.\nIt is obvious that the current\
    \ methods with strong pattern recognition ability are\nparticularly dependent\
    \ on a large amount of data, which requires enough data to draw\nuseful conclusions.\
    \ The traditional agricultural IoT data are limited, which is challenging to\n\
    support the data collection needs of future smart agriculture development. The\
    \ introduction\nof 5G and smart agricultural IoT provides conditions for the collection\
    \ of massive data.\n3.4. Cloud Edge Fog Computing Fusion in 5G Intelligent Agricultural\
    \ Internet of Things\nIn future smart agricultural IoT, data will be extremely\
    \ abundant, and how to conduct\nanalysis and calculation from these data to guide\
    \ modern agricultural production is an\nimportant challenge.\nDue to the limitations\
    \ of volume and battery life, many mobile devices deployed in\nagricultural production\
    \ cannot meet the requirements of these applications in terms of\ncomputing, storage,\
    \ energy, and other resources. Therefore, Mobile Cloud Computing\n(MCC) technology\
    \ has been proposed. It provides reorganized computing resources for\nmobile devices\
    \ in the cloud platform, migrates data processing and storage to the cloud,\n\
    and reduces constraints on its own resources. With the development of smart agriculture,\n\
    massive data will be generated in the future to be analyzed, processed, and stored\
    \ in the\ncentral cloud [92]. At the same time, there may be a large number of\
    \ connections between\nsensing devices, and these MCCS cannot meet the demand.\
    \ New computing methods, such\nas edge computing and fog computing, will be integrated\
    \ into the intelligent agricultural\nIoT system [93]. Edge sensors no longer need\
    \ to continuously transmit various sensing\ndata to the data center. It can judge\
    \ the sensing data on its own, contacting the data center\nonly when there is\
    \ a signiﬁcant change in the reading to decide what action to take. Cloud\ncomputing\
    \ is suitable for non-real-time, long-period data, and business decision scenarios,\n\
    while edge computing plays an irreplaceable role in real-time, short-period data,\
    \ and local\ndecision-making. Edge computing and cloud computing are two important\
    \ supports for\nthe digital transformation of the industry. Their collaboration\
    \ in the network, business,\napplication, intelligence, and other aspects will\
    \ help support the agricultural IoT to create\ngreater value. Intelligent edge\
    \ computing based on 5G power can use the cloud for large-\nscale security conﬁguration,\
    \ deployment, the management of edge devices, and the ability\nto assign intelligence\
    \ based on device type and scenario, allowing intelligence to ﬂow\nbetween the\
    \ cloud and the edge. The edge computing model in smart agriculture is shown\n\
    in Figure 22.\nSecondly, with the continuous enrichment of data in smart agricultural\
    \ IoT, the tra-\nditional forms of computing will become richer and richer. Distributed\
    \ computing based\non cloud computing, fog computing, and other forms will be\
    \ deeply integrated with 5G\ncommunication capabilities and applied to smart agriculture.\
    \ Agriculture, for wisdom in\ngreenhouse cultivation, oriented precision fertilization,\
    \ aquaculture, animal husbandry,\nand aquaculture, the scene such as plant monitoring,\
    \ needs the edge of the Internet of\nThings system IoT terminal according to the\
    \ scientiﬁc planting and breeding, fertilizers\nElectronics 2023, 12, 2336\n23\
    \ of 46\nand other professional industry model, implement local sampling, local\
    \ operations, and\nlocal decisions at the same time, according to the requirement\
    \ of the center’s continuously\nupdated mathematical model and iteration. Therefore,\
    \ the intelligent Internet of Things\nterminal should be based on the requirements\
    \ of fog computing and edge computing\narchitecture, rely on the machine learning\
    \ and algorithm training of cloud computing\ncenter, complete, reliable real-time\
    \ deep computing, accurately control on-site facilities and\nequipment, and achieve\
    \ the purpose of scientiﬁc planting and breeding.\nFigure 22. Smart agriculture\
    \ edge computing model.\n3.5. 5G Intelligent Agricultural IoT In-Depth Service\n\
    The intelligent Internet of Things platform under the 5G will provide personalized,\n\
    customized, and in-depth services for agriculture. The smart agriculture IoT big\
    \ data\nservice platform is shown in Figure 23.\nFigure 23. Smart agriculture\
    \ Internet of Things service platform.\nBased on the power of 5G and the improvement\
    \ of computing power and storage\ncapacity, combined with the latest service platform\
    \ architecture SaaS, PaaS, IaaS, etc., the\nservices of smart agriculture will\
    \ be extremely friendly and convenient. By shielding the\nunderlying details,\
    \ users will be provided with QoS humanized services, as shown in\nFigure 24.\n\
    Electronics 2023, 12, 2336\n24 of 46\nnics 2023, 12, x FOR PEER REVIEW \n23 of\
    \ 46 \nApplication \nlayer SaaS\nIrrigat\nion \nAPP\nInsect \nmonitoring \nAPP\n\
    Moisture \nanalysis\nWeather \nanalysis\nIntelligent operation and \nmaintenance\
    \ of \nagricultural machinery\nPlatform layer \nPaaS\nFacility layer \nIaaS\n\
    Marginal \nlayer\nEquipmen\nt access\nProtocol \nresolution\nEdge data \nprocessing\n\
    Cloud infrastructure (server, storage, network, virtualization)\nAgricultural\
    \ data modeling, calculation and analysis (mechanism modeling, machine \nlearning,\
    \ visualization)\nAgricultural big data system (Data cleaning, Filling, Matching,\
    \ Management, Analysis, \nVisualization, etc.)\nEquipment Management Resource\
    \ Management Operation and Maintenance \nManagement Fault Diagnosis\nEdge data\
    \ \nprocessing\nEdge data \nprocessing\nBusiness \noperation\n \nFigure 24. 5G\
    \ smart agriculture Internet of Things service. \nConcerning 5G, the Internet,\
    \ the Internet of Things, big data and cloud computing, \nartificial intelligence,\
    \ and other modern information technology and agricultural depth \nfusion, the\
    \ implementation of agricultural information perception and quantitative deci-\n\
    sion-making, intelligent control, accurate, and personalized service, the new\
    \ way of agri-\ncultural production is the agricultural informationization development\
    \ from the ad-\nvanced stage of digital to network and intelligent. \n3.6. 5G\
    \ Intelligent Agricultural IoT Production Intelligent Control \nThe application\
    \ of intelligent agricultural IoT based on 5G is bound to involve pro-\nduction\
    \ control, and control of various agricultural machinery such as irrigation and\
    \ \nspraying [94]. The innate advantages of 5G have innate advantages for the\
    \ control of smart \nagriculture—mainly low delay, high bandwidth, and other technical\
    \ characteristics, as \nshown in Figure 25. \nBreeding\nGrow \nseedlings\nPick\n\
    Grafting\nSpray\nWeed\nFarming\nSpray\nOxygenati\non\nSunshade\nSunshade\nReliability\n\
    High \nbandwidth\nLow delay\n5G\n5G\nScene\n \nFigure 25. 5G of intelligent control\
    \ of intelligent agriculture production. \nFor example, a project uses drones\
    \ to take photos of farmland, and the raw data will \nbe transmitted to the cloud\
    \ via 5G network for real-time data analysis and identification. \nThe results\
    \ can then be re-matched to the field, and a tractor or farm robot, guided by\
    \ GPS, \ncan then navigate to the area where the weeds are growing and carry out\
    \ precise removal. \nThis could reduce pesticide use by up to 90 percent, with\
    \ the possibility of replacing pes-\nticides with hot water to remove weeds later.\
    \ Neural networks and self-learning algo-\nrithms make plant identification more\
    \ and more accurate, but they also generate a lot of \nFigure 24. 5G smart agriculture\
    \ Internet of Things service.\nConcerning 5G, the Internet, the Internet of Things,\
    \ big data and cloud computing,\nartiﬁcial intelligence, and other modern information\
    \ technology and agricultural depth\nfusion, the implementation of agricultural\
    \ information perception and quantitative decision-\nmaking, intelligent control,\
    \ accurate, and personalized service, the new way of agricultural\nproduction\
    \ is the agricultural informationization development from the advanced stage of\n\
    digital to network and intelligent.\n3.6. 5G Intelligent Agricultural IoT Production\
    \ Intelligent Control\nThe application of intelligent agricultural IoT based on\
    \ 5G is bound to involve pro-\nduction control, and control of various agricultural\
    \ machinery such as irrigation and\nspraying [94]. The innate advantages of 5G\
    \ have innate advantages for the control of smart\nagriculture—mainly low delay,\
    \ high bandwidth, and other technical characteristics, as\nshown in Figure 25.\n\
    Electronics 2023, 12, x FOR PEER REVIEW \n23 of 46\n \nApplication \nlayer SaaS\n\
    Irrigat\nion \nAPP\nInsect \nmonitoring \nAPP\nMoisture \nanalysis\nWeather \n\
    analysis\nIntelligent operation and \nmaintenance of \nagricultural machinery\n\
    Platform layer \nPaaS\nFacility layer \nIaaS\nMarginal \nlayer\nEquipmen\nt access\n\
    Protocol \nresolution\nEdge data \nprocessing\nCloud infrastructure (server, storage,\
    \ network, virtualization)\nAgricultural data modeling, calculation and analysis\
    \ (mechanism modeling, machine \nlearning, visualization)\nAgricultural big data\
    \ system (Data cleaning, Filling, Matching, Management, Analysis, \nVisualization,\
    \ etc.)\nEquipment Management Resource Management Operation and Maintenance \n\
    Management Fault Diagnosis\nEdge data \nprocessing\nEdge data \nprocessing\nBusiness\
    \ \noperation\n \nFigure 24. 5G smart agriculture Internet of Things service.\
    \ \nConcerning 5G, the Internet, the Internet of Things, big data and cloud computing\n\
    artificial intelligence, and other modern information technology and agricultural\
    \ depth\nfusion, the implementation of agricultural information perception and\
    \ quantitative deci-\nsion-making, intelligent control, accurate, and personalized\
    \ service, the new way of agri-\ncultural production is the agricultural informationization\
    \ development from the ad-\nvanced stage of digital to network and intelligent.\
    \ \n3.6. 5G Intelligent Agricultural IoT Production Intelligent Control \nThe\
    \ application of intelligent agricultural IoT based on 5G is bound to involve\
    \ pro-\nduction control, and control of various agricultural machinery such as\
    \ irrigation and\nspraying [94]. The innate advantages of 5G have innate advantages\
    \ for the control of smart\nagriculture—mainly low delay, high bandwidth, and\
    \ other technical characteristics, as\nshown in Figure 25. \nBreeding\nGrow \n\
    seedlings\nPick\nGrafting\nSpray\nWeed\nFarming\nSpray\nOxygenati\non\nSunshade\n\
    Sunshade\nReliability\nHigh \nbandwidth\nLow delay\n5G\n5G\nScene\n \nFigure 25.\
    \ 5G of intelligent control of intelligent agriculture production. \nFor example,\
    \ a project uses drones to take photos of farmland, and the raw data will\nbe\
    \ transmitted to the cloud via 5G network for real-time data analysis and identification\n\
    The results can then be re-matched to the field, and a tractor or farm robot,\
    \ guided by GPS\ncan then navigate to the area where the weeds are growing and\
    \ carry out precise removal\nThis could reduce pesticide use by up to 90 percent,\
    \ with the possibility of replacing pes-\nticides with hot water to remove weeds\
    \ later. Neural networks and self-learning algo-\nrithms make plant identification\
    \ more and more accurate, but they also generate a lot of\nFigure 25. 5G of intelligent\
    \ control of intelligent agriculture production.\nFor example, a project uses\
    \ drones to take photos of farmland, and the raw data will be\ntransmitted to\
    \ the cloud via 5G network for real-time data analysis and identiﬁcation. The\n\
    results can then be re-matched to the ﬁeld, and a tractor or farm robot, guided\
    \ by GPS, can\nthen navigate to the area where the weeds are growing and carry\
    \ out precise removal. This\ncould reduce pesticide use by up to 90 percent, with\
    \ the possibility of replacing pesticides\nwith hot water to remove weeds later.\
    \ Neural networks and self-learning algorithms make\nElectronics 2023, 12, 2336\n\
    25 of 46\nplant identiﬁcation more and more accurate, but they also generate a\
    \ lot of data. Therefore,\nthe combination of 5G and other technologies is crucial\
    \ to the success of this innovation\nproject [95,96].\n4. Revolution of Smart\
    \ Agricultural IoT Application Paradigm under 5G\n4.1. Typical Application Scenarios\
    \ of 5G Smart Agricultural IoT\nThe development of 5G network will provide the\
    \ infrastructure needed for smart\nagriculture for agricultural production. The\
    \ main application scenarios include the follow-\ning aspects.\n4.1.1. Smart Farm\n\
    The two characteristics of 5G network, high speed and large connection, will help\n\
    the agricultural industry implement large-scale machine services. Centralized\
    \ control\nof environmental sensors, planters, UAVs, and other monitoring equipment\
    \ and real-\ntime data transmission. Finally, the purpose of intensive farming,\
    \ accurate fertilization,\nand reasonable irrigation is achieved [97]. Agricultural\
    \ machinery automatic agricultural\nmachinery equipment based on 5G was integrated\
    \ to achieve rapid, large-area, efﬁcient,\nand precise spraying operation [98].\n\
    4.1.2. Smart Forestry\nSmart forestry utilizes 5G network video, UAV, and other\
    \ monitoring equipment to\ncarry out forest inspection, realize the monitoring\
    \ of forest resources, forest pests and\ndiseases, wild animals and plants, forest\
    \ ﬁre prevention, and provide guide and rescue\nservices for staff and tourists\
    \ [99].\n4.1.3. Intelligent Animal Husbandry\n5G intelligent animal husbandry\
    \ can improve the production efﬁciency of animal\nhusbandry, reduce the cost of\
    \ breeding, prevent livestock epidemic and livestock loss, and\nprotect animal\
    \ husbandry ecology [100,101]. For example, the use of 5G drone technology,\n\
    wearing 5G terminals on the necks of cows, and the use of Internet of Things technology\
    \ to\nmanage yaks have brought great changes to the traditional herding work of\
    \ plateau herders.\n4.1.4. Smart Fishing Ground\n5G smart ﬁshing grounds use monitoring\
    \ equipment such as high-deﬁnition net-\nwork cameras and underwater camera systems\
    \ to carry out real-scene monitoring, aquatic\nproduct growth monitoring, and\
    \ precise bait casting to improve the safety of underwater\noperations and save\
    \ labor costs [102]. In the Marine ranch, 5G panoramic monitoring appli-\ncation\
    \ is realized through 5G coverage. The panoramic high-deﬁnition camera equipment\n\
    and 5G underwater camera system were set up to realize the 24-h panoramic monitoring\
    \ of\nthe ranch. Managers can observe the growth of aquatic products, including\
    \ underwater\nobservation, from their ofﬁces or homes through mobile phones [103].\
    \ Based on 5G technol-\nogy, the intelligent control of the production process\
    \ of Marine cash crops, including kelp\nand other seedlings, can also be realized,\
    \ making it possible to have unmanned Marine\nranching.\n4.2. Deep Sense of 5G\
    \ Smart Agriculture\n4.2.1. Agricultural 5G Image Processing\nIn smart agriculture,\
    \ a large number of scenes need to realize monitoring or identiﬁ-\ncation and\
    \ detection of various targets. With the rapid development of machine learning\n\
    technology in image processing, many problems in agriculture can be solved by\
    \ video\nmonitoring and image detection. This paper summarizes the typical application\
    \ scenarios\nof agricultural image processing, as shown in Figure 26. It mainly\
    \ includes three categories:\nplant pest and disease identiﬁcation [104,105],\
    \ crop growth analysis and detection [106],\nand livestock and aquaculture monitoring\
    \ [107,108]. Each category is divided into many\nElectronics 2023, 12, 2336\n\
    26 of 46\nspeciﬁc problems. The core mode is to collect image data and then combine\
    \ data with\nan artiﬁcial intelligence machine learning algorithm to train the\
    \ model and then detect\nthe model.\ntechnology in image processing, many problems\
    \ in agriculture can be sol\nmonitoring and image detection. This paper summarizes\
    \ the typical applica\nof agricultural image processing, as shown in Figure 26.\
    \ It mainly includes\nries: plant pest and disease identification [104,105], crop\
    \ growth analysis \n[106], and livestock and aquaculture monitoring [107,108].\
    \ Each category i\nmany specific problems. The core mode is to collect image data\
    \ and then \nwith an artificial intelligence machine learning algorithm to train\
    \ the mode\ntect the model. \nAgricultural image \nprocessing\nIdentification\
    \ of plant \ndiseases and pests\nCrop analysis and \ndetection\nLivestock and\
    \ aquatic \nproducts monitoring\n▪ 1.Fungal diseases\n▪ 2.Citrus diseases\n▪ 3.Grapevine\
    \ diseases\n▪ 4.Detection of citrus spider \nand aphid\n▪ 5.Corn crop diseases\n\
    ▪ 6.Pumpkin disease\n▪ 7.Rice disease\n▪ 8.Identification of \nSpodoptera gracilis\
    \ \n▪ 9.Apple leaf disease\n▪ 1.Crop detection\n▪ 2.Crop row detection\n▪ 3.Smart\
    \ Farm\n▪ 4.Yield detection\n▪ 5.Tomato maturity \ndetection\n▪ 6.Weed detection\n\
    ▪ 7.Ear detection\n▪ 8.Grapefruit shape \ndetection\n▪ 9.Phenotype detection of\
    \ \nbroccoli\n▪ 1.Pig behavior monitoring\n▪ 2.Behavior monitoring of \nwhite\
    \ feather chickens\n▪ 3.Oestrus monitoring of \ndairy cows\n▪ 4.Fish growth monitoring\n\
    ▪ 5.Monitoring of bovine \nprotein content\n▪ 6.Floating feed monitoring\n▪ 7.Feeding\
    \ behavior \nmonitoring\n▪ 8.Bullfrog behavior \nmonitoring\n▪ 9.Monitoring of\
    \ water fly \nbreeding\n▪ 10.Underwater monitoring \nof cage culture\n \nFigure\
    \ 26. Image processing in agriculture. \nWith the popularity of high-definition\
    \ cameras, more images need to b\nin agricultural IoT. The transmission of these\
    \ high-definition images poses a\nthe network. Second, many scenarios require\
    \ real-time detection and proces\npopularity of 5G technology, the effective transmission\
    \ and real-time proce\nand image big data can be realized by building a 5G-oriented\
    \ heterogeneo\nThings. \n4.2.2. Agricultural Intelligence Detection Based Machine\
    \ Learning \nThe development of artificial intelligence machine learning has brough\n\
    tunities for smart agriculture. Many researchers have conducted a great de\nby\
    \ combining machine learning algorithms. The main goal of machine learn\ncation\
    \ and detection [109,110]. In agricultural application scenarios, mac\nmainly\
    \ realizes agricultural sensing data, including video, image, text, and\nmodal\
    \ data, and trains models for data detection. The following figure show\nmodel\
    \ processed by machine learning, as shown in Figure 27. \nFigure 26. Image processing\
    \ in agriculture.\nWith the popularity of high-deﬁnition cameras, more images\
    \ need to be transmitted\nin agricultural IoT. The transmission of these high-deﬁnition\
    \ images poses a challenge for\nthe network. Second, many scenarios require real-time\
    \ detection and processing. With\nthe popularity of 5G technology, the effective\
    \ transmission and real-time processing of\nvideo and image big data can be realized\
    \ by building a 5G-oriented heterogeneous Internet\nof Things.\n4.2.2. Agricultural\
    \ Intelligence Detection Based Machine Learning\nThe development of artiﬁcial\
    \ intelligence machine learning has brought new opportu-\nnities for smart agriculture.\
    \ Many researchers have conducted a great deal of research by\ncombining machine\
    \ learning algorithms. The main goal of machine learning is classiﬁcation\nand\
    \ detection [109,110]. In agricultural application scenarios, machine learning\
    \ mainly\nrealizes agricultural sensing data, including video, image, text, and\
    \ other multi-modal\ndata, and trains models for data detection. The following\
    \ ﬁgure shows the general model\nprocessed by machine learning, as shown in Figure\
    \ 27.\nHowever, the autonomous training model is limited by the resources and\
    \ computing\npower of the sensing device, and the effect is not always ideal.\
    \ At present, there are many\nopen-source deep learning platforms for artiﬁcial\
    \ intelligence, which can optimize model\ntraining and provide detection accuracy\
    \ with the help of platform capabilities. The open\nAI deep learning platform\
    \ is shown in Figure 28.\nElectronics 2023, 12, 2336\n27 of 46\ntronics 2023,\
    \ 12, x FOR PEER REVIEW \n26 of \nData \nset\nData \nprep\nroce\nssin\ng\nData\
    \ \ncleaning\nData \nconversion\nData filling\nTraini\nng \ndata\nTest \ndata\n\
    Training \nmodel\nTest \nmodel\nModel\nEvaluation \noptimization\nDeploy\nAgricultural\
    \ \nsense data\n \nFigure 27. An agricultural intelligence detection framework\
    \ for machine learning. \nHowever, the autonomous training model is limited by\
    \ the resources and computi\npower of the sensing device, and the effect is not\
    \ always ideal. At present, there are ma\nopen-source deep learning platforms\
    \ for artificial intelligence, which can optimize mod\ntraining and provide detection\
    \ accuracy with the help of platform capabilities. The op\nAI deep learning platform\
    \ is shown in Figure 28. \nMicrosoft Azure\nIBM System ML\nTencent TML\nAlibaba\
    \ DTPAI\nBaidu BML\nAmazon ML\nGoogle Cloud \nPlatform\nMahout\nHadoop\nSpark\n\
    GraphLab\nMPICH 2\nDMLC\nPetuum\n \nFigure 28. Open artificial intelligence deep\
    \ learning platform. \nDeep learning is an important branch of machine learning.\
    \ It can automatically an\nefficiently extract target features and recognize targets\
    \ through model training. The app\ncation of deep learning technology combined\
    \ with image processing to the recognition\ncrop diseases and insect pests is\
    \ an inevitable trend in the future development of precisi\nagriculture. The performance\
    \ of deep learning networks is very dependent on data se\nHigh quality, high correlation,\
    \ complete annotation, and large-scale agricultural data se\nare of great significance\
    \ for model training. In the application of crop disease and pe\nrecognition,\
    \ in addition to color images taken by cameras and mobile phones of sensi\ndevices,\
    \ multimodal agricultural data such as hyperspectral, near-infrared, and infrar\n\
    images are becoming a trend, and their acquisition provides support for model\
    \ trainin\nas shown in Figure 29. In addition to publicly available data sets,\
    \ an important source f\ndata set sources is self-collection. However, it is very\
    \ difficult to collect graphs of cr\ndiseases and insect pests, and there are\
    \ some problems, such as page occlusion and victi\narea concealment, which require\
    \ multi-angle sensing equipment to collect at the who\ntime, which requires a\
    \ large amount of data collection and transmission. Based on 5\nhigh-speed transmission\
    \ of data from terminal sensing nodes to the platform can be re\nized, real-time\
    \ detection of data can be realized, and the degree of intelligence can be e\n\
    panded [111]. \nCamera\nVideo\nIR/NIR\n5G\nAgricultural \nimage data set \nplatform\n\
    Training \nmodel\nApplication \nplatform\nFigure 27. An agricultural intelligence\
    \ detection framework for machine learning.\nData \nset\nData \nprep\nroce\nssin\n\
    g\nData \ncleaning\nData \nconversion\nData filling\nTraini\nng \ndata\nTest \n\
    data\ng\nmodel\nTest \nmodel\nModel\nEvaluation \noptimization\nDeploy\nral \n\
    ta\n \nFigure 27. An agricultural intelligence detection framework for machine\
    \ learning. \nHowever, the autonomous training model is limited by the resources\
    \ and computing \npower of the sensing device, and the effect is not always ideal.\
    \ At present, there are many \nopen-source deep learning platforms for artificial\
    \ intelligence, which can optimize model \ntraining and provide detection accuracy\
    \ with the help of platform capabilities. The open \nAI deep learning platform\
    \ is shown in Figure 28. \nMicrosoft Azure\nIBM System ML\nTencent TML\nAlibaba\
    \ DTPAI\nBaidu BML\nAmazon ML\nGoogle Cloud \nPlatform\nMahout\nHadoop\nSpark\n\
    GraphLab\nMPICH 2\nDMLC\nPetuum\n \nFigure 28. Open artificial intelligence deep\
    \ learning platform. \nDeep learning is an important branch of machine learning.\
    \ It can automatically and \nefficiently extract target features and recognize\
    \ targets through model training. The appli-\ncation of deep learning technology\
    \ combined with image processing to the recognition of \ncrop diseases and insect\
    \ pests is an inevitable trend in the future development of precision \nagriculture.\
    \ The performance of deep learning networks is very dependent on data sets. \n\
    High quality, high correlation, complete annotation, and large-scale agricultural\
    \ data sets \nare of great significance for model training. In the application\
    \ of crop disease and pest \nrecognition, in addition to color images taken by\
    \ cameras and mobile phones of sensing \ndevices, multimodal agricultural data\
    \ such as hyperspectral, near-infrared, and infrared \nimages are becoming a trend,\
    \ and their acquisition provides support for model training, \nas shown in Figure\
    \ 29. In addition to publicly available data sets, an important source for \n\
    data set sources is self-collection. However, it is very difficult to collect\
    \ graphs of crop \ndiseases and insect pests, and there are some problems, such\
    \ as page occlusion and victim \narea concealment, which require multi-angle sensing\
    \ equipment to collect at the whole \ntime, which requires a large amount of data\
    \ collection and transmission. Based on 5G, \nhigh-speed transmission of data\
    \ from terminal sensing nodes to the platform can be real-\nized, real-time detection\
    \ of data can be realized, and the degree of intelligence can be ex-\npanded [111].\
    \ \nCamera\nVideo\nIR/NIR\nSpectral camera\n5G\nAgricultural \nimage data set\
    \ \nplatform\nTraining \nmodel\nApplication \nplatform\n \nFigure 28. Open artiﬁcial\
    \ intelligence deep learning platform.\nDeep learning is an important branch of\
    \ machine learning. It can automatically\nand efﬁciently extract target features\
    \ and recognize targets through model training. The\napplication of deep learning\
    \ technology combined with image processing to the recognition\nof crop diseases\
    \ and insect pests is an inevitable trend in the future development of precision\n\
    agriculture. The performance of deep learning networks is very dependent on data\
    \ sets.\nHigh quality, high correlation, complete annotation, and large-scale\
    \ agricultural data sets\nare of great signiﬁcance for model training. In the\
    \ application of crop disease and pest\nrecognition, in addition to color images\
    \ taken by cameras and mobile phones of sensing\ndevices, multimodal agricultural\
    \ data such as hyperspectral, near-infrared, and infrared\nimages are becoming\
    \ a trend, and their acquisition provides support for model training, as\nshown\
    \ in Figure 29. In addition to publicly available data sets, an important source\
    \ for data\nset sources is self-collection. However, it is very difﬁcult to collect\
    \ graphs of crop diseases\nand insect pests, and there are some problems, such\
    \ as page occlusion and victim area\nconcealment, which require multi-angle sensing\
    \ equipment to collect at the whole time,\nwhich requires a large amount of data\
    \ collection and transmission. Based on 5G, high-speed\ntransmission of data from\
    \ terminal sensing nodes to the platform can be realized, real-time\ndetection\
    \ of data can be realized, and the degree of intelligence can be expanded [111].\n\
    Test \ndata\nTest \nmodel\noptimization\nFigure 27. An agricultural intelligence\
    \ detection framework for machine learning. \nHowever, the autonomous training\
    \ model is limited by the resources an\npower of the sensing device, and the effect\
    \ is not always ideal. At present, th\nopen-source deep learning platforms for\
    \ artificial intelligence, which can op\ntraining and provide detection accuracy\
    \ with the help of platform capabili\nAI deep learning platform is shown in Figure\
    \ 28. \nMicrosoft Azure\nIBM System ML\nTencent TML\nAlibaba DTPAI\nBaidu BML\n\
    Amazon ML\nMahout\nHadoop\nSpark\nGraphLab\nMPICH 2\nDMLC\nFigure 28. Open artificial\
    \ intelligence deep learning platform. \nDeep learning is an important branch\
    \ of machine learning. It can auto\nefficiently extract target features and recognize\
    \ targets through model traini\ncation of deep learning technology combined with\
    \ image processing to the \ncrop diseases and insect pests is an inevitable trend\
    \ in the future developmen\nagriculture. The performance of deep learning networks\
    \ is very dependen\nHigh quality, high correlation, complete annotation, and large-scale\
    \ agricul\nare of great significance for model training. In the application of\
    \ crop dis\nrecognition, in addition to color images taken by cameras and mobile\
    \ phon\ndevices, multimodal agricultural data such as hyperspectral, near-infrared\n\
    images are becoming a trend, and their acquisition provides support for m\nas\
    \ shown in Figure 29. In addition to publicly available data sets, an import\n\
    data set sources is self-collection. However, it is very difficult to collect\
    \ g\ndiseases and insect pests, and there are some problems, such as page occlusi\n\
    area concealment, which require multi-angle sensing equipment to collect\ntime,\
    \ which requires a large amount of data collection and transmission. \nhigh-speed\
    \ transmission of data from terminal sensing nodes to the platfor\nized, real-time\
    \ detection of data can be realized, and the degree of intellige\npanded [111].\
    \ \nCamera\nVideo\nIR/NIR\nSpectral camera\n5G\nAgricultural \nimage data set\
    \ \nplatform\nTraining \nmodel\nApplication \nplatform\n \nFigure 29. Machine\
    \ learning detection platform based on 5G. \nFigure 29. Machine learning detection\
    \ platform based on 5G.\nElectronics 2023, 12, 2336\n28 of 46\n4.3. 5G Intelligent\
    \ Agricultural Machinery\nUnder the conditions of high speed and low delay of\
    \ 5G, intelligent agricultural\nmachinery can realize deep real-time perception,\
    \ such as the state information collection,\nfault location, and operation monitoring\
    \ of agricultural machinery can be displayed online\nin real time. The system\
    \ can diagnose the failure of agricultural machinery in real-time and\nschedule\
    \ the cooperative operation of multiple agricultural machineries. The advantage\n\
    of low latency is that route decisions can be made in time, increasing the speed\
    \ of sowing\nor harvesting and making the operation more accurate. Secondly, agricultural\
    \ robots are\nmainly divided into two categories. First, walking robots. The second\
    \ is the robotic hand\nrobot. The robot is mainly based on visual recognition\
    \ technology to identify and locate\nplants and then plant and pick them. 5G technology\
    \ enables robots to receive commands\nfaster, transmit high-deﬁnition pictures\
    \ and videos, and promote the development of\nrobot visual recognition technology.\
    \ 5G has increased the number of robots that can\nbe accessed, allowing multiple\
    \ robots to be remotely controlled to work and improving\noperational efﬁciency.\n\
    4.3.1. Intelligent Agricultural Machinery\nAgricultural machinery plays an important\
    \ role in agricultural production practice.\nIt can effectively improve the efﬁciency\
    \ of agricultural production to promote large-scale\nand industrial planting.\
    \ All kinds of machinery used in the process of agriculture, forestry,\nanimal\
    \ husbandry, deputy, and ﬁshery production are collectively referred to as agricultural\n\
    machinery. Agricultural machinery can be broadly divided into two categories:\
    \ power\nmachinery and working machinery. The following diagram summarizes the\
    \ classiﬁcation\ndiagram of agricultural machinery and equipment according to\
    \ different functions [112,113],\nas shown in Figure 30.\ng\ng\ny\nUnder the conditions\
    \ of high speed and low delay of 5G, intelligent agricultu\nchinery can realize\
    \ deep real-time perception, such as the state information col\nfault location,\
    \ and operation monitoring of agricultural machinery can be dis\nonline in real\
    \ time. The system can diagnose the failure of agricultural machinery \ntime and\
    \ schedule the cooperative operation of multiple agricultural machineries. T\n\
    vantage of low latency is that route decisions can be made in time, increasing\
    \ the sp\nsowing or harvesting and making the operation more accurate. Secondly,\
    \ agricultu\nbots are mainly divided into two categories. First, walking robots.\
    \ The second is \nbotic hand robot. The robot is mainly based on visual recognition\
    \ technology to i\nand locate plants and then plant and pick them. 5G technology\
    \ enables robots to \ncommands faster, transmit high-definition pictures and videos,\
    \ and promote the d\nment of robot visual recognition technology. 5G has increased\
    \ the number of robo\ncan be accessed, allowing multiple robots to be remotely\
    \ controlled to work and im\ning operational efficiency. \n4.3.1. Intelligent\
    \ Agricultural Machinery \nAgricultural machinery plays an important role in agricultural\
    \ production p\nIt can effectively improve the efficiency of agricultural production\
    \ to promote larg\nand industrial planting. All kinds of machinery used in the\
    \ process of agriculture, fo\nanimal husbandry, deputy, and fishery production\
    \ are collectively referred to as a\ntural machinery. Agricultural machinery can\
    \ be broadly divided into two cate\npower machinery and working machinery. The\
    \ following diagram summarizes th\nsification diagram of agricultural machinery\
    \ and equipment according to differen\ntions [112,113], as shown in Figure 30.\
    \ \nIntelligent agricultural \nmachinery and equipment\nTillage \nmachinery\n\
    Plant protection \nmachinery\nIrrigation and \ndrainage \nmachinery\nPower transmission\
    \ \nmachinery\nHarvesting \nmachinery\nAnimal husbandry \nmachinery\nPlanting\
    \ and fertilizing \nmachinery\nFishery and \naquatic products\nAnimal husbandry\n\
    Crop planting\nAuxiliary \nmachinery\n▪ \nCultivator\n▪ \nRotary cultivator\n\
    ▪ \nMicro cultivator\n▪ \nDisc plough\n▪ \nRotary cultivator\n▪ \nScarifier\n\
    ▪ \nStubble cleaner\n▪ \nGrader\n▪ \nDigger\n▪ \nFurrowing and \nridging machine\n\
    ▪ \nCombined grader\n▪ \nDisc harrow\n▪ \nBallast\n▪ \nPruning \nMachineCultivat\n\
    or\n▪ \nEradicator\n▪ \nFogger\n▪ \nSpray\n▪ \nLawnmower\n▪ \nDuster\n▪ \nLawn\
    \ mower\n▪ \nInsecticidal lamp\n▪ \nBooby trap\n▪ \nPlant protection \nUAV\n▪\
    \ \nWater lifting, \ndrainage and \nirrigation\n▪ \nSprinkler \nirrigation \n\
    equipment\n▪ \nDrip irrigation \nequipment\n▪ \nMicro spray \nequipment\n▪ \n\
    Outlet valve\n▪ \nAirbrush\n▪ \nWater and \nfertilizer \nEquipment\n▪ \nWater\
    \ pump\n▪ \nHydraulic turbine\n▪ \nGasoline engine\n▪ \nDiesel engine\n▪ \nEngine\n\
    ▪ \nTractor\n▪ \nLoading and \nunloading \nvehicle\n▪ \nLifting platform\n▪ \n\
    Conveyor\n▪ \nHoist\n▪ \nFeeder\n▪ \nLoader\n▪ \nForklift\n▪ \nSeeder\n▪ \nDrill\n\
    ▪ \nAcupoint planter\n▪ \nPlanter\n▪ \nRice transplanter\n▪ \nTransplanter\n▪\
    \ \nFertilizer \nApplicator\n▪ \nTopdressing \nmachine\n▪ \nMulching \nmachine\n\
    ▪ \nSpray machine\n▪ \nUAV\n▪ \nHarvester\n▪ \nHarvester\n▪ \nThreshing \nmachine\n\
    ▪ \nFruit picking \nmachine\n▪ \nBaler\n▪ \nSheller\n▪ \nCleaner\n▪ \nDrying machine\n\
    ▪ \nWarehousing \nequipment\n▪ \nSeed processor\n▪ \n▪ \nChicken breeding \nequipment\n\
    ▪ \nPig breeding \nequipment\n▪ \nIncubation \nequipment\n▪ \nFan equipment\n\
    ▪ \nHeating \nequipment\n▪ \nAquaculture \nEquipment \n▪ \nCapture \nequipment\n\
    ▪ \nSlaughtering \nequipment\n▪ \nCrushing equipment\n▪ \nStacking equipment\n\
    ▪ \nDrying equipment\n▪ \nCooling equipment\n▪ \nGranulation \nequipment\n▪ \n\
    Screening \nequipment\n▪ \nMixing and stirring\n▪ \nQuantitative \npackaging\n\
    ▪ \nFertilizer production \nmachine\n \nFigure 30. Classification of agricultural\
    \ machinery and equipment. \nThe trend of intelligent agriculture development\
    \ is necessarily intelligent. W\ndevelopment of technology based on automated\
    \ equipment, the intelligent opera\nagriculture will be realized by means of sensors,\
    \ information transmission, and\nmation integration processing, which are based\
    \ on the Internet of Things, big da\nartificial intelligence [114]. \nFor example,\
    \ the intelligent agricultural machine can form a highly intelligen\nating system\
    \ by configuring various sensing devices and computing chips on the a\ntural machine,\
    \ combined with satellite positioning detection terminal equipment,\nintegration\
    \ module, and IoT system. Intelligent agricultural machinery can also \ninformation\
    \ on agricultural machinery operation through the management cente\nFigure 30.\
    \ Classiﬁcation of agricultural machinery and equipment.\nThe trend of intelligent\
    \ agriculture development is necessarily intelligent. With the\ndevelopment of\
    \ technology based on automated equipment, the intelligent operation of\nagriculture\
    \ will be realized by means of sensors, information transmission, and information\n\
    integration processing, which are based on the Internet of Things, big data, and\
    \ artiﬁcial\nintelligence [114].\nFor example, the intelligent agricultural machine\
    \ can form a highly intelligent operat-\ning system by conﬁguring various sensing\
    \ devices and computing chips on the agricultural\nmachine, combined with satellite\
    \ positioning detection terminal equipment, digital in-\ntegration module, and\
    \ IoT system. Intelligent agricultural machinery can also display\nElectronics\
    \ 2023, 12, 2336\n29 of 46\ninformation on agricultural machinery operation through\
    \ the management center informa-\ntion platform. The perception information will\
    \ be monitored for statistics and management,\nagricultural machinery macro management,\
    \ command scheduling, and operation statis-\ntics. Information technology and\
    \ agricultural machinery chain integration, through data\nanalysis, get a scientiﬁc\
    \ decision.\nHigher intelligent agricultural machines require more sensory data\
    \ intake for com-\nputational processing decisions. This requires a smart agricultural\
    \ Internet of Things.\nFor example, the irrigation system of farmland can be completed\
    \ by simple operation of\nfarmers. However, the question of when and how much\
    \ to irrigate depends on people’s\nexperience. The intelligent irrigation system\
    \ can be judged comprehensively through the\nmonitoring data of crop production\
    \ status, temperature, and humidity, meteorological\nconditions, etc., which saves\
    \ manpower and ensures the health of crop growth.\nThe problem is that the traditional\
    \ Internet of Things cannot meet the requirements\nof real-time transmission of\
    \ large amounts of data. With the integration of 5G, smart\nagricultural machines\
    \ can achieve a data communication rate, which is expected to change\nthe production\
    \ mode of smart agricultural machines and the degree of wisdom, as shown\nin Figure\
    \ 31 and Table 8.\nElectronics 2023, 12, x FOR PEER REVIEW \n \nstatistics. Information\
    \ technology and agricultural machinery chain integration, t\ndata analysis, get\
    \ a scientific decision. \nHigher intelligent agricultural machines require more\
    \ sensory data intake f\nputational processing decisions. This requires a smart\
    \ agricultural Internet of Thi\nexample, the irrigation system of farmland can\
    \ be completed by simple operation \ners. However, the question of when and how\
    \ much to irrigate depends on people\nrience. The intelligent irrigation system\
    \ can be judged comprehensively through th\nitoring data of crop production status,\
    \ temperature, and humidity, meteorologica\ntions, etc., which saves manpower\
    \ and ensures the health of crop growth. \nThe problem is that the traditional\
    \ Internet of Things cannot meet the requi\nof real-time transmission of large\
    \ amounts of data. With the integration of 5G, sm\ncultural machines can achieve\
    \ a data communication rate, which is expected to cha\nproduction mode of smart\
    \ agricultural machines and the degree of wisdom, as sh\nFigure 31 and Table 8.\
    \ \nMechanical \narm\nVideo sensing \ndevice\nInfrared \nspectrum\nCamera\n5G+Mechanical\
    \ arm+AGV Independent patrol inspection\nAGV\n \nFigure 31. 5G + robotic arm +\
    \ AGV independent inspection. \nTable 8. Image recognition and detection of intelligent\
    \ agriculture. \nLiterature \nContent \nField \nType \nB. Bose et al. [115] \n\
    Diagnosis, detection, and classifica-\ntion of cannabis diseases \nPlant protection\
    \ \nClassification algo\nD. Brunelli et al. [116] \nIdentify and kill apple pests\
    \ \nPlant protection \nNeural netwo\nR. Medar et al. [117] \nCrop yield prediction\
    \ \nPlant protection \nMachine learn\nN. Gobalakrishnan [118] \nPlant disease\
    \ detection \nCrop diseases and in-\nsect pests \nImage process\nM. Merchant [119]\
    \ \nVarious nutritional deficiencies of \nmango leaves \nCrop protection \nImage\
    \ process\nQ. Feng [120] \nTomato harvesting machine \nHarvest \nImage segmentati\n\
    cessing \nUnder the background of 5G, the smart agricultural IoT will transform\
    \ the \nagricultural machinery equipment and make it more intelligent. Intelligent\
    \ agri\nFigure 31. 5G + robotic arm + AGV independent inspection.\nTable 8. Image\
    \ recognition and detection of intelligent agriculture.\nLiterature\nContent\n\
    Field\nType\nB. Bose et al. [115]\nDiagnosis, detection, and\nclassiﬁcation of\
    \ cannabis diseases\nPlant protection\nClassiﬁcation algorithm\nD. Brunelli et\
    \ al. [116]\nIdentify and kill apple pests\nPlant protection\nNeural network\n\
    R. Medar et al. [117]\nCrop yield prediction\nPlant protection\nMachine learning\n\
    N. Gobalakrishnan [118]\nPlant disease detection\nCrop diseases and insect pests\n\
    Image processing\nM. Merchant [119]\nVarious nutritional deﬁciencies of\nmango\
    \ leaves\nCrop protection\nImage processing\nQ. Feng [120]\nTomato harvesting\
    \ machine\nHarvest\nImage segmentation\nprocessing\nElectronics 2023, 12, 2336\n\
    30 of 46\nUnder the background of 5G, the smart agricultural IoT will transform\
    \ the existing\nagricultural machinery equipment and make it more intelligent.\
    \ Intelligent agricultural\nmachinery can perceive its position, surrounding environment\
    \ relationship, and the inter-\nnal working state of machinery by building machine\
    \ vision, multi-dimensional perception,\nand satellite positioning based on 5G\
    \ agricultural Internet of Things. It can achieve good\ncooperation and scientiﬁc\
    \ implementation, effectively improving the effect of agricultural\nmechanization\
    \ by controlling and operating each process. Intelligent agricultural machin-\n\
    ery 5G-based agricultural Internet of Things can realize real-time monitoring\
    \ of agricultural\nmachinery’s own condition, operating state of machinery and\
    \ tools, meteorological condi-\ntions, and operating environment. It can also\
    \ guide agricultural machinery to adjust the\noperation plan in time according\
    \ to the obtained information and effectively reduce the\nindustrial machinery\
    \ in the process of operation failure, such as machine damage, poor\nquality,\
    \ and other problems. In addition to the above, intelligent agricultural machinery\n\
    will reduce the amount of ineffective operation of industrial machinery. Energy\
    \ efﬁciency\nhas been signiﬁcantly improved. The precise operation also realizes\
    \ the precise applica-\ntion of pesticides and fertilizers and truly realizes\
    \ the requirements of energy-saving and\nenvironmental protection.\nIt is clear\
    \ that smart agriculture combined with the Internet of Things and machine\nlearning\
    \ algorithm big data can transform traditional agricultural machinery and equip-\n\
    ment, making them more intelligent. In addition, the operation of intelligent\
    \ detection\nand sensing equipment can realize the functions of agricultural machinery\
    \ positioning,\nreal-time statistics of agricultural machinery working area, and\
    \ real-time calculation of\noperation quality. The system supports a variety of\
    \ agricultural machinery operations such\nas sowing, transplanting, plant protection,\
    \ harvesting, deep loosening, and land prepara-\ntion, straw returning, and so\
    \ on. It can measure fuel consumption and obtain the working\ncondition information\
    \ of agricultural machinery in real-time. This facilitates the control\nof agricultural\
    \ production progress and facilitates the real-time control of the working\narea,\
    \ working quality, and working power consumption. Being based on geospatial remote\n\
    sensing technology, multi-sensor fusion technology, 5G technology, and big data\
    \ technology,\nthe system realizes the comprehensive upgrading of smart agricultural\
    \ machinery.\n4.3.2. Automatic Driving of Agricultural Machinery\nThe automatic\
    \ driving technology of agricultural machinery is to use high-precision\nsatellite\
    \ positioning and navigation information and controls the hydraulic system of\n\
    agricultural machinery by the controller so that the agricultural machinery can\
    \ drive\nautomatically according to the set route (straight line or curve). It\
    \ can effectively improve\nthe working accuracy, improve the land utilization\
    \ rate, reduce the labor intensity of\nmachine hands, and extend the working time\
    \ (ﬁeld work can also be carried out at night).\nMoreover, it is easy to operate\
    \ and reduces the requirement for the driving ability of the\nmanipulator [121,122].\
    \ Based on the Beidou Navigation Satellite System (BDS) [123,124], a\nglobal Positioning\
    \ system (GPS) can achieve intelligent driving of all kinds of agricultural\n\
    machinery, including rice transplanters, seed drills, combine harvesters, etc.\
    \ The high-\nprecision positioning and navigation technology, image recognition,\
    \ and transmission\ntechnology are applied to the intelligent driving of these\
    \ machines to realize the precise\nnavigation of agricultural machinery driving\
    \ and automatically complete the land tillage,\nsowing, ﬁeld management, and harvest,\
    \ as shown in Figure 32.\nIntelligent agricultural machinery automatic driving\
    \ system uses satellite positioning,\nmechanical control, inertial navigation,\
    \ and other technologies so that agricultural machin-\nery, according to the planned\
    \ route, automatically adjusts the direction of travel. Operation\nprecision can\
    \ reach the centimeter level, and can be used for ditching, raking, sowing, ridge,\n\
    fertilization, spraying, harvesting, transplanting, and other agricultural operations.\n\
    Unmanned agricultural machinery has many problems to be solved, such as real-time\n\
    control, low speed, and complex scenes. Sensing data do not easily meet the needs\
    \ of\nElectronics 2023, 12, 2336\n31 of 46\nintelligent control. The high bandwidth\
    \ and real-time performance of 5G will be able to\nmeet the above requirements\
    \ of unmanned agricultural control operations.\nElectronics 2023, 12, x FOR PEER\
    \ REVIEW \n \nGPS/Beidou \nNavigation \nTerminal\nSatellite \nreceiving \nantenna\n\
    Traveling \ncontroller\nHydraulic \ncontrol \nsystem\nAngle/video \nsensor\n \n\
    Figure 32. 5G unmanned agricultural machinery model. \nIntelligent agricultural\
    \ machinery automatic driving system uses satellite p\ning, mechanical control,\
    \ inertial navigation, and other technologies so that agri\nmachinery, according\
    \ to the planned route, automatically adjusts the direction o\nOperation precision\
    \ can reach the centimeter level, and can be used for ditching\nsowing, ridge,\
    \ fertilization, spraying, harvesting, transplanting, and other agricult\nerations.\
    \ \nUnmanned agricultural machinery has many problems to be solved, such\ntime\
    \ control, low speed, and complex scenes. Sensing data do not easily meet th\n\
    of intelligent control. The high bandwidth and real-time performance of 5G will\n\
    to meet the above requirements of unmanned agricultural control operations. \n\
    4.3.3. 5G Automatic Coordination of Multiple Agricultural Machines \nThe 5G agricultural\
    \ machinery unmanned operating system is deployed on\ncloud network fusion platform.\
    \ With the intelligent agricultural machinery equ\ndocking, we realized the agricultural\
    \ machinery from the hangar, and machine\nway to the operation plot of the whole\
    \ process of unmanned operation. It cover\nproduction links of rice cultivation,\
    \ seed, pipe, and harvest. In the hangar and on t\nthe location map modeling is\
    \ first carried out, and the application equipment dep\nbased on RTK differential\
    \ GNSS positioning technology, IMU data, and UWB pre\nsitioning technology were\
    \ used to achieve the indoor and outdoor centimeter-lev\ntioning accuracy. Secondly,\
    \ the core control system deployed in the edge cloud \nvisual and radar terminals\
    \ installed in the agricultural machinery were combined\nthe surrounding environment\
    \ intelligently. Finally, the AI deep learning algorit\nused to complete the mark\
    \ line recognition and obstacle detection when agricultu\nchinery is moving forward\
    \ and backing up. In this way, unmanned driving, park\nstacle recognition, and\
    \ automatic obstacle avoidance can be realized, as shown in\n33. \nFigure 32.\
    \ 5G unmanned agricultural machinery model.\n4.3.3. 5G Automatic Coordination\
    \ of Multiple Agricultural Machines\nThe 5G agricultural machinery unmanned operating\
    \ system is deployed on the 5G\ncloud network fusion platform. With the intelligent\
    \ agricultural machinery equipment\ndocking, we realized the agricultural machinery\
    \ from the hangar, and machine plough\nway to the operation plot of the whole\
    \ process of unmanned operation. It covers all the\nproduction links of rice cultivation,\
    \ seed, pipe, and harvest. In the hangar and on the road,\nthe location map modeling\
    \ is ﬁrst carried out, and the application equipment deployment\nbased on RTK\
    \ differential GNSS positioning technology, IMU data, and UWB precise\npositioning\
    \ technology were used to achieve the indoor and outdoor centimeter-level\npositioning\
    \ accuracy. Secondly, the core control system deployed in the edge cloud and the\n\
    visual and radar terminals installed in the agricultural machinery were combined\
    \ to sense\nthe surrounding environment intelligently. Finally, the AI deep learning\
    \ algorithm was used\nto complete the mark line recognition and obstacle detection\
    \ when agricultural machinery\nis moving forward and backing up. In this way,\
    \ unmanned driving, parking, obstacle\nrecognition, and automatic obstacle avoidance\
    \ can be realized, as shown in Figure 33.\n4.4. 5G Agricultural UAV\nUAVs require\
    \ a high time delay of network signals. 5G networks give UAVs important\ncapabilities\
    \ such as ultra-high-deﬁnition video transmission, remote networking, and\nautonomous\
    \ ﬂight. 5G technology makes it possible for ﬂeets of drones to work together\n\
    and around the clock. It has huge development space in agriculture, security,\
    \ electricity,\nand other industries [125]. The plant protection UAV is small\
    \ in size, light in weight,\nﬂexible for ﬂight control, and has good applicability\
    \ to different plots and crops. At the\nplatform end, the networked UAV can be\
    \ remotely controlled to set functions such as\nassigning tasks, designing routes\
    \ independently, sending back spraying data in real time,\nand automatically returning\
    \ after an operation. Plant protection UAVs reduce pesticides,\nsave water consumption\
    \ and improve pesticides [126]. The steady wind ﬁeld generated\nby the rotor of\
    \ the UAV can penetrate the bottom of the crop, and the atomization effect is\n\
    good, reaching the back of the blade.\nLive broadcasts of rice by unmanned aerial\
    \ vehicles are relatively popular in south\nChina, which can sow 300~600 mu per\
    \ day, 3~5 times that of ground machinery. At the\nElectronics 2023, 12, 2336\n\
    32 of 46\nsame time, it eliminates the process of seedling, raising, transporting,\
    \ and transplanting.\nThe drone can adjust the nozzle size according to the size\
    \ of the seed. Spray the seeds in\nrows and columns as needed. The UAV can also\
    \ spray granular fertilizer and pesticides.\nAccording to the difference in particle\
    \ density and quality, it can automatically adjust\nthe parameters of the medicine\
    \ box to provide efﬁcient and intelligent fertilization and\napplication schemes.\n\
    Electronics 2023, 12, x FOR PEER REVIEW \n31 of 46 \n \nUAV/satellite high-\n\
    definition field \nmap construction\nGPS, BeiDong, \nGNSS navigation \nand positioning\n\
    Automatic turning \ncontrol of \nagricultural \nmachinery\nField path planning\
    \ \nof agricultural \nmachinery\nMulti machine \ncooperative task \nallocation\
    \ of \nagricultural machinery\nUnmanned \nagricultural \nmachinery\n \nFigure\
    \ 33. Schematic diagram of unmanned agricultural machinery collaboration based\
    \ on 5G. \n4.4. 5G Agricultural UAV \nUAVs require a high time delay of network\
    \ signals. 5G networks give UAVs im-\nportant capabilities such as ultra-high-definition\
    \ video transmission, remote networking, \nand autonomous flight. 5G technology\
    \ makes it possible for fleets of drones to work to-\ngether and around the clock.\
    \ It has huge development space in agriculture, security, elec-\ntricity, and\
    \ other industries [125]. The plant protection UAV is small in size, light in\
    \ \nweight, flexible for flight control, and has good applicability to different\
    \ plots and crops. \nAt the platform end, the networked UAV can be remotely controlled\
    \ to set functions such \nas assigning tasks, designing routes independently,\
    \ sending back spraying data in real \ntime, and automatically returning after\
    \ an operation. Plant protection UAVs reduce pesti-\ncides, save water consumption\
    \ and improve pesticides [126]. The steady wind field gen-\nerated by the rotor\
    \ of the UAV can penetrate the bottom of the crop, and the atomization \neffect\
    \ is good, reaching the back of the blade. \nLive broadcasts of rice by unmanned\
    \ aerial vehicles are relatively popular in south \nChina, which can sow 300~600\
    \ mu per day, 3~5 times that of ground machinery. At the \nsame time, it eliminates\
    \ the process of seedling, raising, transporting, and transplanting. \nThe drone\
    \ can adjust the nozzle size according to the size of the seed. Spray the seeds\
    \ in \nrows and columns as needed. The UAV can also spray granular fertilizer\
    \ and pesticides. \nAccording to the difference in particle density and quality,\
    \ it can automatically adjust the \nparameters of the medicine box to provide\
    \ efficient and intelligent fertilization and appli-\ncation schemes. \nThe drones\
    \ carry a range of remote sensing equipment that can photograph the \ngrowth of\
    \ crops. Remote sensing images combined with extensive data analysis can real-\n\
    ize the functions of crop monitoring, fertilization advice, and pest and disease\
    \ prediction. \nDifferent yields reflect different infrared spectra, which can\
    \ be used to measure the area \nof crops. Pests and diseases can be analyzed by\
    \ infrared spectroscopy and high-definition \nphotographs. \nFor forest management,\
    \ 5G drone ground stations will be deployed around the forest \nfarm, covering\
    \ an area of about 100 km. The drones are equipped with equipment, such \nas optical\
    \ cameras and high-definition cameras, to monitor vegetation growth and forest\
    \ \ncover. Through big data analysis of tree varieties and survival rate, replanting\
    \ suggestions \ncan also predict the occurrence of forest pests and diseases and\
    \ put forward prevention \nFigure 33. Schematic diagram of unmanned agricultural\
    \ machinery collaboration based on 5G.\nThe drones carry a range of remote sensing\
    \ equipment that can photograph the growth\nof crops. Remote sensing images combined\
    \ with extensive data analysis can realize the\nfunctions of crop monitoring,\
    \ fertilization advice, and pest and disease prediction. Different\nyields reﬂect\
    \ different infrared spectra, which can be used to measure the area of crops.\
    \ Pests\nand diseases can be analyzed by infrared spectroscopy and high-deﬁnition\
    \ photographs.\nFor forest management, 5G drone ground stations will be deployed\
    \ around the forest\nfarm, covering an area of about 100 km. The drones are equipped\
    \ with equipment, such as\noptical cameras and high-deﬁnition cameras, to monitor\
    \ vegetation growth and forest cover.\nThrough big data analysis of tree varieties\
    \ and survival rate, replanting suggestions can also\npredict the occurrence of\
    \ forest pests and diseases and put forward prevention and control\nsuggestions.\
    \ In terms of forest ﬁre control, inspection routes can be planned according to\n\
    daily needs, and the UAV will automatically alarm if there is any abnormality\
    \ [127]. If the\nforest is on ﬁre, drones can be sent to check the ﬁre, and the\
    \ ﬁre can be used to identify the\npoint of ﬁre.\nAccording to the different functions\
    \ of agricultural UAVs, as shown in Figure 34,\nthey can be divided into two categories:\
    \ agricultural operation and farmland information\ncollection. Agricultural operation\
    \ refers to the use of unmanned aerial vehicles (UAVs) to\nreplace some human\
    \ agricultural operations and to solve the shortage of human operations\nin quality,\
    \ efﬁciency, and labor, as well as the safety problems of operations. The collection\n\
    of farmland information refers to the timely and accurate collection of ﬁeld information\n\
    using remote sensing detection technology, including photosynthetic quality, soil\
    \ moisture,\nand crop population growth [128,129].\nElectronics 2023, 12, 2336\n\
    33 of 46\n \ncan be divided into two categories: agricultural operation and farmland\
    \ information col-\nlection. Agricultural operation refers to the use of unmanned\
    \ aerial vehicles (UAVs) to \nreplace some human agricultural operations and to\
    \ solve the shortage of human opera-\ntions in quality, efficiency, and labor,\
    \ as well as the safety problems of operations. The \ncollection of farmland information\
    \ refers to the timely and accurate collection of field in-\nformation using remote\
    \ sensing detection technology, including photosynthetic quality, \nsoil moisture,\
    \ and crop population growth [128,129]. \nAgricultural UAV\nPlant protection \n\
    operation\nForestry \nmonitoring\nCrop \npollination\nHerd \npositioning\nSingle\
    \ rotor UAV\nMulti rotor UAV\n \nFigure 34. Type of agricultural UAV. \nSeveral\
    \ challenges remain in the current application of agricultural drones: \nFirst,\
    \ the endurance time of agricultural UAVs is short, which cannot adapt to multi-\n\
    ple types of complex operations in the field. \nSecond, it is difficult to control.\
    \ Most of the intelligence degree is low, and anti-colli-\nsion and other functions\
    \ are lacking. \nThird, the precision application control technology based on\
    \ agricultural information \nis not mature enough. During aerial spraying operations,\
    \ agricultural information such as \ncrop growth, pests, and diseases in different\
    \ operating areas were obtained by aerial re-\nmote sensing technology, and prescription\
    \ maps were generated to determine the pesti-\ncide preparations and dosage required\
    \ for aerial spraying in different areas. The precision \napplication of plant\
    \ protection UAVs was realized by variable control technology. \nAll the above\
    \ have put forward new requirements for the intelligence degree of \nUAVs, mainly\
    \ including intelligent control, precise operation, better function, and optimi-\n\
    zation of spraying equipment. For the precise control of UAVs, it is necessary\
    \ to consume \nmore abundant information to meet its control needs. Secondly,\
    \ the real-time control \nneeds to be strengthened and satisfied, and the large\
    \ bandwidth and low delay of 5G can \nmeet the above requirements. It can be expected\
    \ that the popularity of 5G will be expected \nto promote the further development\
    \ of agricultural drones. \n4.5. 5G Intelligent Agricultural Supply Chain Management\
    \ \nAgricultural products have various production processes, long cycles, and\
    \ numerous \nfactors, so it is challenging to realize standardized production\
    \ and management [130]. The \nsupply chain of agricultural products is in all\
    \ stages of agriculture before, during, and \nafter production. Participants participate\
    \ in different roles of producers and consumers to \nrealize the supply and circulation\
    \ of agricultural products among agricultural producers, \nagricultural materials/agricultural\
    \ service enterprises, wholesale and retail markets, reg-\nulatory agencies, and\
    \ end consumers. It connects the production, processing, transporta-\ntion, sales,\
    \ and other links of agricultural products and integrates logistics, capital flow,\
    \ \nand information flow. It is important to establish a chain structure network\
    \ composed of \nagricultural product suppliers, manufacturers, distributors, retailers,\
    \ and end consumers \n[131]. Traditional agricultural supply chain participants\
    \ mainly use the Internet of Things \ntechnology to achieve information collection,\
    \ transmission, processing, processing, and \nother businesses. However, as IoT\
    \ systems are built in different participant systems, they \nbelong to different\
    \ platforms. For the seemingly interconnected network, the business is \nFigure\
    \ 34. Type of agricultural UAV.\nSeveral challenges remain in the current application\
    \ of agricultural drones:\nFirst, the endurance time of agricultural UAVs is short,\
    \ which cannot adapt to multiple\ntypes of complex operations in the ﬁeld.\nSecond,\
    \ it is difﬁcult to control. Most of the intelligence degree is low, and anti-collision\n\
    and other functions are lacking.\nThird, the precision application control technology\
    \ based on agricultural information\nis not mature enough. During aerial spraying\
    \ operations, agricultural information such as\ncrop growth, pests, and diseases\
    \ in different operating areas were obtained by aerial remote\nsensing technology,\
    \ and prescription maps were generated to determine the pesticide\npreparations\
    \ and dosage required for aerial spraying in different areas. The precision\n\
    application of plant protection UAVs was realized by variable control technology.\n\
    All the above have put forward new requirements for the intelligence degree of\
    \ UAVs,\nmainly including intelligent control, precise operation, better function,\
    \ and optimization\nof spraying equipment. For the precise control of UAVs, it\
    \ is necessary to consume more\nabundant information to meet its control needs.\
    \ Secondly, the real-time control needs to\nbe strengthened and satisﬁed, and\
    \ the large bandwidth and low delay of 5G can meet\nthe above requirements. It\
    \ can be expected that the popularity of 5G will be expected to\npromote the further\
    \ development of agricultural drones.\n4.5. 5G Intelligent Agricultural Supply\
    \ Chain Management\nAgricultural products have various production processes, long\
    \ cycles, and numerous\nfactors, so it is challenging to realize standardized\
    \ production and management [130]. The\nsupply chain of agricultural products\
    \ is in all stages of agriculture before, during, and\nafter production. Participants\
    \ participate in different roles of producers and consumers to\nrealize the supply\
    \ and circulation of agricultural products among agricultural producers,\nagricultural\
    \ materials/agricultural service enterprises, wholesale and retail markets, regu-\n\
    latory agencies, and end consumers. It connects the production, processing, transportation,\n\
    sales, and other links of agricultural products and integrates logistics, capital\
    \ ﬂow, and\ninformation ﬂow. It is important to establish a chain structure network\
    \ composed of agri-\ncultural product suppliers, manufacturers, distributors,\
    \ retailers, and end consumers [131].\nTraditional agricultural supply chain participants\
    \ mainly use the Internet of Things tech-\nnology to achieve information collection,\
    \ transmission, processing, processing, and other\nbusinesses. However, as IoT\
    \ systems are built in different participant systems, they belong\nto different\
    \ platforms. For the seemingly interconnected network, the business is relatively\n\
    independent, unable to quickly and effectively complete the exchange of information,\
    \ the\nreal realization of the whole process of sharing, presentation, and other\
    \ difﬁculties.\nThe traditional Internet is to reduce intermediate links, reduce\
    \ transaction costs,\nexpand the scope of service, improve service quality, and\
    \ so on. Embedding blockchain\ntechnology may deepen the meaning of the Internet.\
    \ It can form credit by recording, storing,\ntransferring, verifying, and analyzing\
    \ information data programmatically. Blockchain can\nsave a great deal of labor\
    \ costs and intermediary costs, and the recorded credit information\nis completer\
    \ and more difﬁcult to fake. The internal structure of the network architecture\
    \ of\neach subsystem is different. The network slice network virtualization of\
    \ 5G can realize the\nisolation and organic combination of each sub-platform.\
    \ An agricultural products supply\nchain management schematic diagram of 5G block\
    \ chain is shown in Figure 35.\nElectronics 2023, 12, 2336\n34 of 46\nsave a great\
    \ deal of labor costs and intermediary costs, and the recorded credit infor-\n\
    mation is completer and more difficult to fake. The internal structure of the\
    \ network ar-\nchitecture of each subsystem is different. The network slice network\
    \ virtualization of 5G\ncan realize the isolation and organic combination of each\
    \ sub-platform. An agricultural\nproducts supply chain management schematic diagram\
    \ of 5G block chain is shown in Fig-\nure 35. \nAgricultural \nproducer\nAgricultural\
    \ materials/\nagricultural clothing \nsupplier\nWholesale \nsales market\nShop/\n\
    Supermarket\n \nRegulators\nConsumer\nBlock 1\nParent chunk \nhash value\npro\n\
    duct\nion \ninfo\nrma\ntion\nLogi\nstics \ninfo\nrma\ntion\nOrd\ner \ninfo\nrma\n\
    tion\nInve\nntor\ny \ninfo\nrma\ntion\nBlock \nhead\n \nParticipant A Internet\
    \ \nof Things Platform\nBlockchain entry\nBlock 2\nParent chunk \nhash value\n\
    pro\nduct\nion \ninfo\nrma\ntion\nLogi\nstics \ninfo\nrma\ntion\nOrd\ner \ninfo\n\
    rma\ntion\nInve\nntor\ny \ninfo\nrma\ntion\nBlock \nhead\n \nParticipant B Internet\
    \ \nof Things Platform\nBlockchain entry\nBlock 3\nParent chunk \nhash value\n\
    pro\nduct\nion \ninfo\nrma\ntion\nLogi\nstics \ninfo\nrma\ntion\nOrd\ner \ninfo\n\
    rma\ntion\nInve\nntor\ny \ninfo\nrma\ntion\nBlock \nhead\n \nParticipant C Internet\
    \ \nof Things Platform\nBlockchain entry\nBlock 4\nParent chunk \nhash value\n\
    pro\nduct\nion \ninfo\nrma\ntion\nLogi\nstics \ninfo\nrma\ntion\nOrd\ner \ninfo\n\
    rma\ntion\nInve\nntor\ny \ninfo\nrma\ntion\nBlock \nhead\n \nParticipant D Internet\
    \ \nof Things Platform\nBlockchain entry\n5G agricultural product supply chain\
    \ cloud platform\nNetwork \nSlice 1\nNetwork \nSlice 2\nNetwork \nSlice 3\nNetwork\
    \ \nSlice 4\n5G\n5G\n5G\n5G\n \nFigure 35. 5G block chain agricultural products\
    \ supply chain management schematic diagram. \n5. Challenges of 5G Smart Agricultural\
    \ IoT \n5G will bring new development opportunities to agriculture, making the\
    \ smart agri-\ncultural IoT evolve in a smarter direction. At the same time, it\
    \ also brings many new prob-\nlems, and smart agriculture faces new challenges,\
    \ as shown in Figure 36. \nIntelligent \nmonitoring\nWater/Soil \nManagement\n\
    Management of \nplanting, breeding \nand growth\nPest \nmanagement\nSupply chain\
    \ \nmanagemen\nt\nIntelligent \nAgriculture \nPractice\nSmart agricultural machinery:\
    \ \nplanting, weeding, picking and \nharvesting\nLarge data of video and \nimage\
    \ types\nLarge amount of data\nTransmission \ndifficulties\nMultiple node \ndeployments\n\
    Numerous sensing \nnodes\nDifficulty in \nnetworking\nLarge amount of \nremote\
    \ sensing \ndata\nAI intelligence combined \nwith large amount of \ndata\nNode\
    \ intensive \ndeployment\nWide area deployment\nLarge amount of remote \nsensing\
    \ data\nLarge quantity \nof high-\nprecision \nmonitoring\nHigh real-time \nperformance\n\
    AI intelligence \ncombines large \namount of data\nHigh real-time\nRequire immediate\
    \ \nresponse\nMultiple \nterminal \ntypes\nPlatform \nhybrid\nAI intelligence\
    \ \ncombined with \nlarge amount of \nremote sensing \ndata\nNode wide area \n\
    deployment\n \nFigure 36. The new problems in the smart agriculture Internet of\
    \ Things. \nThese new problems bring new challenges to the application of smart\
    \ agriculture\nMany of these key issues may be partially solved with the introduction\
    \ of 5G technology\nFigure 35. 5G block chain agricultural products supply chain\
    \ management schematic diagram.\n5. Challenges of 5G Smart Agricultural IoT\n\
    5G will bring new development opportunities to agriculture, making the smart agricul-\n\
    tural IoT evolve in a smarter direction. At the same time, it also brings many\
    \ new problems,\nand smart agriculture faces new challenges, as shown in Figure\
    \ 36.\nproducts supply chain management schematic diagram of 5G block chain is\
    \ shown in\nure 35. \nAgricultural \nproducer\nAgricultural materials/\nagricultural\
    \ clothing \nsupplier\nWholesale \nsales market\nShop/\nSupermarket\n \nRegulators\n\
    Consumer\nBlock 1\nParent chunk \nhash value\npro\nduct\nion \ninfo\nrma\ntion\n\
    Logi\nstics \ninfo\nrma\ntion\nOrd\ner \ninfo\nrma\ntion\nInve\nntor\ny \ninfo\n\
    rma\ntion\nBlock \nhead\n \nParticipant A Internet \nof Things Platform\nBlockchain\
    \ entry\nBlock 2\nParent chunk \nhash value\npro\nduct\nion \ninfo\nrma\ntion\n\
    Logi\nstics \ninfo\nrma\ntion\nOrd\ner \ninfo\nrma\ntion\nInve\nntor\ny \ninfo\n\
    rma\ntion\nBlock \nhead\n \nParticipant B Internet \nof Things Platform\nBlockchain\
    \ entry\nBlock 3\nParent chunk \nhash value\npro\nduct\nion \ninfo\nrma\ntion\n\
    Logi\nstics \ninfo\nrma\ntion\nOrd\ner \ninfo\nrma\ntion\nInve\nntor\ny \ninfo\n\
    rma\ntion\nBlock \nhead\n \nParticipant C Internet \nof Things Platform\nBlockchain\
    \ entry\nBlock 4\nParent chunk \nhash value\npro\nduct\nion \ninfo\nrma\ntion\n\
    Logi\nstics \ninfo\nrma\ntion\nOrd\ner \ninfo\nrma\ntion\nInve\nntor\ny \ninfo\n\
    rma\ntion\nBlock \nhead\n \nParticipant D Internet \nof Things Platform\nBlockchain\
    \ entry\n5G agricultural product supply chain cloud platform\nNetwork \nSlice\
    \ 1\nNetwork \nSlice 2\nNetwork \nSlice 3\nNetwork \nSlice 4\n5G\n5G\n5G\n5G\n\
    \ \nFigure 35. 5G block chain agricultural products supply chain management schematic\
    \ diagram\n5. Challenges of 5G Smart Agricultural IoT \n5G will bring new development\
    \ opportunities to agriculture, making the smart \ncultural IoT evolve in a smarter\
    \ direction. At the same time, it also brings many new p\nlems, and smart agriculture\
    \ faces new challenges, as shown in Figure 36. \nIntelligent \nmonitoring\nWater/Soil\
    \ \nManagement\nManagement of \nplanting, breeding \nand growth\nPest \nmanagement\n\
    Supply chain \nmanagemen\nt\nIntelligent \nAgriculture \nPractice\nSmart agricultural\
    \ machinery: \nplanting, weeding, picking and \nharvesting\nLarge data of video\
    \ and \nimage types\nLarge amount of data\nTransmission \ndifficulties\nMultiple\
    \ node \ndeployments\nNumerous sensing \nnodes\nDifficulty in \nnetworking\nLarge\
    \ amount of \nremote sensing \ndata\nAI intelligence combined \nwith large amount\
    \ of \ndata\nNode intensive \ndeployment\nWide area deployment\nLarge amount of\
    \ remote \nsensing data\nLarge quantity \nof high-\nprecision \nmonitoring\nHigh\
    \ real-time \nperformance\nAI intelligence \ncombines large \namount of data\n\
    High real-time\nRequire immediate \nresponse\nMultiple \nterminal \ntypes\nPlatform\
    \ \nhybrid\nAI intelligence \ncombined with \nlarge amount of \nremote sensing\
    \ \ndata\nNode wide area \ndeployment\n \nFigure 36. The new problems in the smart\
    \ agriculture Internet of Things. \nThese new problems bring new challenges to\
    \ the application of smart agricul\nMany of these key issues may be partially\
    \ solved with the introduction of 5G techno\nFigure 36. The new problems in the\
    \ smart agriculture Internet of Things.\nThese new problems bring new challenges\
    \ to the application of smart agriculture.\nMany of these key issues may be partially\
    \ solved with the introduction of 5G technology.\n5G is the infrastructure of\
    \ the intelligent era. Its characteristics of “extremely high\nspeed, enormous\
    \ capacity and extremely low delay” can provide basic support for meeting\nthe\
    \ development needs of smart agriculture in the future. Compared with the 2–4G\
    \ era,\nthe demand for base stations and network control equipment has increased\
    \ signiﬁcantly\nin 5G. The large-scale application of 5G technology not only increases\
    \ the cost of network\ninfrastructure, but also the cost of power and operation,\
    \ and maintenance is much higher\nthan that of 4G, which brings challenges to\
    \ the ﬁeld agricultural production with low added\nvalue. However, 5G technology\
    \ still has limits when it comes to applications such as virtual\nreality, intelligent\
    \ production, and driverless driving. First, the deployment of 5G base\nstations\
    \ is not balanced. As many 5G base stations are distributed in sparsely populated\n\
    areas, such as ﬁelds, agriculture, and farming, there may be only a few 5G base\
    \ stations\nElectronics 2023, 12, 2336\n35 of 46\nin these areas, which cannot\
    \ effectively cover all of them, which brings challenges to the\npopularization\
    \ and application. Secondly, the introduction of 5G will bring a change of the\n\
    whole smart agriculture application paradigm. The architecture, perception, transmission,\n\
    computing, service, processing, and application mode of 5G Internet of Things\
    \ for smart\nagriculture will bring changes, and there will be challenges.\n5.1.\
    \ Fusion and Optimization of Sparse 5G Base Station and Heterogeneous Sensing\
    \ Network in\nSmart Agriculture\n5.1.1. Optimization of Hybrid Deployment of 5G\
    \ and Sensing Network\nAccording to the analysis, the characteristics of 5G network\
    \ in agriculture are sparse,\nuneven, and they have low coverage of network base\
    \ stations and slow deployment of\nfarm base stations in remote areas. This brings\
    \ challenges for the application of 5G in ﬁeld\nagriculture and plantation agriculture.\n\
    For this imbalance and sparsity feature, it can be conﬁgured from two aspects.\
    \ One is\nto optimize the deployment of sensing nodes, and the other is to deploy\
    \ in combination\nwith heterogeneous networks. The hybrid deployment strategy\
    \ for ﬁeld agriculture, for ex-\nample, 5G sensing nodes are deployed in key areas,\
    \ and other sensing nodes are deployed\nin other areas, and sensing deployment\
    \ optimization is realized through network resource\nvirtualization and other\
    \ technologies. When the communication nodes of large-scale in-\ntelligent agricultural\
    \ sensor networks are deployed in three-dimensional space under the\nbackground\
    \ of 5G, the traditional random node deployment mode has the problems of high\n\
    energy consumption, high cost, and node disconnection. Firstly, by taking advantage\
    \ of the\ncharacteristics of the high bandwidth of 5G communication, a hierarchical\
    \ communication\nscheme can be designed, and a hierarchical node optimal deployment\
    \ model, a communi-\ncation energy consumption model, and a fully connected sensor\
    \ information transmission\nnetwork model are established. On the premise of ensuring\
    \ the full connectivity of sensor\ncommunication network nodes in farmland, the\
    \ life cycle of communication network nodes\nis improved.\n(a) 5G sparse deployment\
    \ based on ﬁeld agricultural planting scenarios.\nCombined with the actual ﬁeld\
    \ agricultural planting scene, the 5G base station has a\nhigh working frequency\
    \ band and a large signal attenuation, and its coverage radius is only\n0.3–0.5\
    \ times that of the 4G base station. It is difﬁcult to meet the goal of low cost\
    \ and high\nbeneﬁt of network construction only by deploying a macro base station.\
    \ The micro-base\nstation has a small coverage radius and low construction cost.\
    \ In order to optimize the\ndeployment cost of 5G base stations, the heterogeneous\
    \ network architecture of “macro\nand micro collaboration” can be adopted. How\
    \ to combine smart agricultural business for\noptimal deployment is an important\
    \ issue. Heterogeneous networks can optimize the cost\nof 5G signal deployment\
    \ while realizing the coverage of agricultural operation areas and\noptimizing\
    \ the perceived cost.\n(b) Intensive deployment optimization of 5G and sensing\
    \ nodes in ﬁne agriculture.\nIn ﬁne agriculture, there are many parameters to\
    \ monitor, many types of business, and\nthe need for intensive sensing equipment,\
    \ which generates an explosion of mobile data.\nHow to realize intelligent and\
    \ efﬁcient green deployment planning of intelligent nodes such\nas base stations\
    \ and gateways with large area coverage for various intelligent agricultural\n\
    applications is one of the key issues. By deploying small base stations with lower\
    \ cost\nand closer to users, it becomes a feasible solution to construct ultra-dense\
    \ heterogeneous\nnetworks centered on monitoring objects.\n5.1.2. Optimization\
    \ of 5G and Sensing Network Gateway Deployment\nPreviously, the deployment optimization\
    \ of sensing nodes and 5G base stations were\nproposed in ﬁne agriculture. In\
    \ the integration of 5G and sensing devices in deployment, it\nis necessary to\
    \ combine the collaboration of the Internet of Things gateway to realize the\n\
    high-low speed switching and transmission of sensing data.\nElectronics 2023,\
    \ 12, 2336\n36 of 46\n(a) The deployment of edge gateway in the Internet of Things.\
    \ The conditions of edge\ngateway coverage and service terminal trafﬁc generator,\
    \ the factors affecting the ofﬂoad-\ning delay of computing tasks, and the constraints\
    \ of edge gateway capacity allocation.\nFollowing that, the edge gateway deployment\
    \ optimization model was established and\noptimized.\n(b) To solve the problem\
    \ of base station deployment in the Low Power Wide Area\nNetwork (LPWAN), the\
    \ received signal values of all terminal test points can be predicted\nby combining\
    \ the terminal receiving signal prediction module. Then, the prediction results\n\
    are transformed into the weight values of all terminal test points during clustering,\
    \ and\nthe terminal test points are clustered. In addition, the location of the\
    \ base station was\nadjusted to achieve the optimal coverage effect and realize\
    \ the deployment optimization in\nthe whole application scenario.\n5.2. Optimization\
    \ Control under Edge Computing in 5G Intelligent Agricultural Production\nThe\
    \ popularization and application of 5G intelligent agricultural Internet of Things\
    \ will\nbring major challenges to the traditional cloud computing model, such\
    \ as high latency and\njitter, no support for location awareness and mobility,\
    \ and non-adaptive communication\ntypes. The production of smart agriculture often\
    \ needs to deploy edge computing to\nachieve real-time computing and reasonable\
    \ allocation of resources.\n5.2.1. Automatic Phenotype Monitoring Based on 5G\
    \ Internet of Things\nBy monitoring and sensing plant growth phenotype, the analysis\
    \ of crop traits is\nof great reference signiﬁcance for cultivating crop varieties\
    \ with excellent traits such as\ndrought resistance, poison resistance, lodging\
    \ resistance, high nutrient rate, and salt and\nalkali resistance. It helps researchers\
    \ select seeds of good quality for the next generation of\nbreeding objects. There\
    \ are many common image-based phenotyping methods in the ﬁeld\nof plant phenotype.\
    \ Among them, the image recognition method based on visible light has\nlower requirements\
    \ on experimental equipment, higher practicability, and can collect large-\nscale\
    \ plant image data. Therefore, the current deep learning can be better applied\
    \ to those\nalgorithms that use visible light images. All these require high-speed\
    \ data transmission,\nand how to collect and control real-time data in multi-source\
    \ sensing devices is a problem\nworth studying. At present, the main concern of\
    \ plant leaf recognition methods based on\nvisible light images is that there\
    \ are not many kinds of recognition methods. There are many\nresearchers working\
    \ on automatic phenotypic sensing platforms, which require automatic\nsensing\
    \ data pickup. Combining the advantages of high bandwidth and dense deployment\n\
    of 5G to realize automatic measurement and real-time computation of phenotype\
    \ is a\nproblem worth studying.\n5.2.2. Intelligent Sensing Real-Time Control\
    \ for Intelligent Agricultural Machinery\nMore intelligent agricultural machinery\
    \ will participate in the future smart agriculture.\nThey can combine 5G Internet\
    \ of Things and edge computing to realize smart agricultural\nproduction. Among\
    \ them they face the real-time control of equipment, which requires\nrapid data\
    \ collection and processing.\nIn the operation of smart agricultural machinery,\
    \ sensors deployed on the roadside of\nfarmland can sense all kinds of environments\
    \ and obtain important trafﬁc information. For\nexample, ﬁxed sensors such as\
    \ vision sensors and millimeter wave sensors are installed\non the side of the\
    \ road, and the information collected by the sensors is sent to the edge\nserver\
    \ for processing to extract information such as vehicle location and vehicle trajectory.\n\
    According to the multi-source information obtained by roadside sensors, crop sensors,\n\
    and smart agricultural sensing equipment, real-time data processing is carried\
    \ out to\nanalyze the operation status and calculate the results. Mobile edge\
    \ computing provides\npowerful computing and storage capabilities. The side camera\
    \ and millimeter wave radar\nare fused based on the edge server. Through data\
    \ preprocessing, space synchronization,\ntime synchronization, and tracking algorithm,\
    \ they can cooperate with each other, jointly\nElectronics 2023, 12, 2336\n37\
    \ of 46\nbuilding an intelligent agricultural machinery environment sensing system\
    \ to make it more\nstable and reliable.\nDuring the operation of intelligent agricultural\
    \ machinery, target tracking should focus\non the following points: (1) Object\
    \ association: radar detection should be associated with\ncamera detection, while\
    \ the current fusion detection must be associated with the existing\ntrajectory;\
    \ (2) Tracking link: appropriate ﬁlter should be selected for tracking; (3) Tracking\n\
    management: tracking object database needs to be maintained.\n5.3. Scheduling\
    \ Optimization of Heterogeneous Nodes under 5G Smart Agriculture\nHow to optimize\
    \ the scheduling of sensing nodes in different rates, resources, and\nnetworks\
    \ is a problem to be studied in the intelligent agricultural IoT under 5G.\n5.3.1.\
    \ Sense Scheduling for 5G Smart Agriculture\nUnder such circumstances, how to\
    \ optimize the deployment of network resources and\nnodes to achieve better overall\
    \ network performance is a problem worth studying.\n(a). Sensing task collaboration\
    \ based on 5G: Sensing task collaboration is a hot issue in\nsensor networks.\
    \ Based on the connectivity, coverage, survivability, and task completion\nrequirements\
    \ of the network, this paper proposes a collaboration mechanism based on\nthe\
    \ limited energy, computing, and storage capacity of the sensing nodes and the\
    \ task\ncompletion requirements. The network topology is reconstructed by adjusting\
    \ the transmit\npower of nodes, neighbor selection, sleep scheduling, or mobile\
    \ node location. The decom-\nposition, assignment, scheduling, and execution of\
    \ tasks are accomplished cooperatively by\ncoordinating the behavior of mobile\
    \ sensor nodes. Topology reconstruction optimization is\nmainly carried out in\
    \ edge nodes and load balancing. In smart agriculture, the perception\nequipment\
    \ is more diverse, and the perception task is more complex.\n(b). Cooperative\
    \ scheduling of large agricultural machinery equipment: agriculture-\noriented\
    \ large agricultural machinery includes unmanned aerial vehicles (UAVs), mutual\n\
    sensing, and task coordination of multi-aerial robots. For example, building the\
    \ social\nInternet of Things creates a dynamic social network for each object\
    \ connected to the Internet\nof Things. Social networks are extended through node\
    \ proﬁles and trust levels to ﬁnd\nobjects that contribute to IoT applications\
    \ and solve resource management problems. Assign\nsensitive tasks fairly to objects\
    \ in the social network. How to optimize the sensing task\nof massive heterogeneous\
    \ sensing devices in the Internet of Things for smart agriculture.\nIt is still\
    \ a challenge to realize the efﬁcient collection of sensing data and the maximum\n\
    efﬁciency of network resources by abstracting network resources.\n5.3.2. Optimization\
    \ of 5G Network Signal Coverage Scheduling for Agricultural UAV\nIn addition to\
    \ the upstream and downstream rate, end-to-end delay of services, end-\nto-end\
    \ delay of control, and positioning accuracy, the coverage height of wireless\
    \ signals is\none of the most important requirements for 5G networks in agriculture.\n\
    According to the requirements of UAV network indicators in each scenario in IMT-\n\
    2020 (5G), Advance Group—White Paper on 5G UAV Application, the coverage height\n\
    requirements of wireless signals of networked UAV in the application ﬁeld are\
    \ shown in\nTable 9.\nOn the basis of the existing network, it is technically\
    \ feasible to deploy a small number\nof base stations for the 5G communication\
    \ requirements of agricultural UAVs. However,\nthe actual network planning still\
    \ needs to focus on several issues.\n(a) Adjacent area planning.\nIn order to\
    \ make connected UAVs ﬂy continuously in the air, in addition to seamless\n5G\
    \ wireless network signals, civil UAVs also need to be able to switch smoothly\
    \ between\ndifferent cells and different base stations. In this way, it is necessary\
    \ to cover the high\nlevel of the community to have a reasonable neighborhood\
    \ relationship. In addition, the\nUAV communication terminal needs to switch from\
    \ the low-level 5G wireless network\nto the high-level 5G wireless network when\
    \ taking off. This also requires reasonable\nElectronics 2023, 12, 2336\n38 of\
    \ 46\nneighborhood planning between the 5G cell covering the high-rise and its\
    \ neighboring 5G\ncell. Similarly, the UAV communication terminal needs to switch\
    \ from the high-level 5G\nwireless network to the low-level 5G wireless network\
    \ when landing. It is also necessary to\nmake reasonable neighborhood planning\
    \ between the 5G cell covering the low layer and\nits adjacent high-rise 5G cell.\
    \ Its switching band is controlled at about 100 m in the air.\n(b) Interference\
    \ problem.\n5G wireless networks are also self-interfering systems. All base stations\
    \ share a band-\nwidth of 100 MHz. Therefore, it is necessary to control the coverage\
    \ of the signal through\nreasonable planning and optimization. In this way, it\
    \ is necessary to avoid discontinuous\ncoverage or blind coverage caused by insufﬁcient\
    \ signal, and to avoid interference in other\ncommunities due to over coverage.\
    \ At the same time, the mutual interference between\nthe 5G cell covering the\
    \ lower layer and the 5G cell covering the upper layer should be\navoided. Of\
    \ course, this will require a long period of experimentation and exploration.\n\
    Table 9. Requirements for coverage height of wireless signals of networked UAVs\
    \ in application ﬁelds.\nNo.\nApplication Area\nBusiness Attribute\nCover Height/m\n\
    Coverage\n1\nAgricultural and forestry plant\nprotection\nSpraying pesticide\n\
    10\ncountryside\n2\nAgricultural and forestry\nsurveying and mapping\nAgricultural\
    \ land survey\n200\ncountryside\n3\nAgricultural inspection\n1080p Video return\n\
    100\nPatrol inspection\ncovers ﬁeld agriculture\n4\nAgricultural formation ﬂight\n\
    UAV formation ﬂight\n200\ncountryside\n5\nFuture cloud AI\nUAV cloud-based autonomous\n\
    ﬂight\n300\ncountryside\n6\nAgricultural and forestry\nmonitoring\nCrop growth\
    \ monitoring\n100\ncountryside\n5.4. Fault Detection and Self-Healing for 5G Intelligent\
    \ Agricultural Platform\nSmart agriculture 5G-IoT faces increasing network scale\
    \ and density, dense terminal\nconnections, and higher intelligence, and the failure\
    \ rate will increase. The production\nefﬁciency of large-scale smart agriculture\
    \ is an important issue. With the integration of\n5G, many intelligent applications\
    \ will be gradually popularized. These apps are built\naround the 5G Internet\
    \ of Things. How to quickly identify the faulty node or device and\nthe self-healing\
    \ ability of the platform are important research issues.\n5.4.1. Node Fault Identiﬁcation\
    \ and Early Warning Based on Heterogeneous Sensing\nData Fusion\nCombining the\
    \ collected sensing data for computational analysis and network topol-\nogy to\
    \ identify node faults is a problem worth studying. Due to the mixed deployment\n\
    of 5G and various sensing devices, mixed data sources, multi-hop communication,\
    \ and\ntransmission route changes, how to realize the fault identiﬁcation of sensing\
    \ nodes and\npossible fault detection is an important research issue.\n5.4.2.\
    \ Research on Fault Tolerance Based on 5G Heterogeneous Fusion Sensing Network\n\
    Traditional perceptual networks generally assume unreliable perception. The actual\n\
    agricultural production will appear to be all kinds of failures. Because of the\
    \ intensive\ndeployment, the cost of ensuring all reliable operations is high.\
    \ Therefore, it is worth\nstudying that fault tolerance can guarantee the normal\
    \ operation of the whole agricultural\nproduction in a certain period of time\
    \ under limited fault.\nElectronics 2023, 12, 2336\n39 of 46\n5.4.3. Self-Healing\
    \ Mechanism Based on 5G Heterogeneous Fusion Sensing Network\nIn smart agriculture,\
    \ production is blocked due to the failure of the sensing equipment\nnetwork,\
    \ which affects efﬁciency. Therefore, it is necessary to study how to self-heal\
    \ after\nfaults occur, such as network topology self-healing, to guarantee node\
    \ pathways. For\nexample, perceptual repair under dense nodes. An additional example\
    \ is 5G gateway\ncoverage self-healing.\n5.5. AI Application Optimization for\
    \ 5G Intelligent Agricultural Internet of Things\nThe application of 5G brings\
    \ new opportunities for smart agriculture, which is ex-\npected to solve the problem\
    \ of data transmission and storage. With the development of\nartiﬁcial intelligence,\
    \ it is an important issue to study lightweight deep artiﬁcial intelligence\n\
    algorithms or platforms combined with various scenarios of smart agriculture.\n\
    Artiﬁcial intelligence algorithms represented by deep learning have laid the foundation\n\
    for many scenarios of smart agriculture applications. With the popularization\
    \ of 5G, the\nrange of application scenarios of smart agriculture will be greatly\
    \ expanded. However, the\ncurrent existence represented by deep learning will\
    \ face the important challenge of how to\nachieve reliable and effective operation\
    \ under the condition of small cost in the scenario of\nsmart agriculture, relying\
    \ on massive data and powerful computing power.\n5.5.1. Lightweight Deep Learning\
    \ Algorithm Based on 5G-IoT Edge Computing\nEdge computing equipment has some\
    \ computing ability, but its computing ability is\nnot enough for massive data\
    \ model training. The challenge is how to design deep learning\nor machine learning\
    \ algorithms suitable for agricultural production. Better results can\nbe obtained\
    \ by training on small sample data, reducing the amount of data transmission,\n\
    reducing the cost of communication resources, and improving the real-time accuracy,\
    \ which\nis a problem worth studying.\n5.5.2. Multi-Source Data-Sensing Machine\
    \ Learning Algorithm for Smart Agriculture\nIn the 5G scenario, sensing nodes\
    \ are densely deployed, and heterogeneous sensing\ndata need to be calculated\
    \ and analyzed to serve the upper layer. However, there are\noften low data quality,\
    \ multi-source, heterogeneous, and multi-modal sensing data, and\nchanges in network\
    \ topology. How to calculate these mixed and redundant low-quality\ndata by clustering,\
    \ statistics, Bayesian, and other machine learning methods is an important\nresearch\
    \ problem.\n5.6. 5G-IoT System Service Model for Smart Agriculture\nAn important\
    \ means to promote the implementation of smart agriculture is the in-\nformation\
    \ physical fusion system based on 5G. The typical application mode of smart\n\
    agriculture is to comprehensively perceive agricultural information through the\
    \ agricul-\ntural Internet of Things. Massive sensing devices for agricultural\
    \ IoT are deployed in the\nwhole process of agricultural production and processing.\
    \ Various information (environ-\nmental temperature and humidity, soil moisture,\
    \ carbon dioxide, images, etc.) is collected\nthrough various networks, including\
    \ 5G. Traditional agricultural models will be changed\nby means of cloud computing,\
    \ big data, edge computing, and artiﬁcial intelligence. It can\nrealize intelligent\
    \ perception, intelligent warning, intelligent decision-making, intelligent\n\
    analysis, and expert online guidance of agricultural production environment to\
    \ provide\nprecise planting, visual management, and intelligent decision-making\
    \ for agricultural\nproduction. This is to realize the intelligent management\
    \ of agricultural visual remote\ndiagnosis, remote control, disaster warning,\
    \ and so on, and gradually establish the visual\ncommunication and application\
    \ mode of agricultural information services. Relying on\nthe knowledge of agricultural\
    \ experts stored in the knowledge base, reasoning, analysis,\nand other mechanisms\
    \ were used to guide the production and circulation of agriculture\nand animal\
    \ husbandry. It promotes the transformation of traditional agriculture, which\
    \ is\nhuman-centered and relies on isolated machinery production mode, to modern\
    \ smart agri-\nElectronics 2023, 12, 2336\n40 of 46\nculture, which is based on\
    \ information and software production mode. How to construct\nan appropriate application\
    \ service paradigm and model for intelligent agriculture 5G-IoT\nis an important\
    \ issue to be studied.\n5.7. Security Issues of 5G Internet of Things for Smart\
    \ Agriculture\nThe future of intelligent agriculture is highly intelligent, informationized,\
    \ and un-\nmanned, and security issues should be a concern. Due to the application\
    \ of 5G technology,\nthere are many data ﬂows and information ﬂows which are prone\
    \ to data deception, etc.,\nwhich will lead to serious consequences, such as the\
    \ death of crops or the poor quality of\nanimal husbandry objects caused by incorrect\
    \ pesticide spraying.\nAt present, there are many research results on the security\
    \ of the Internet of Things.\nIn general, attacks in IoT applications are classiﬁed\
    \ using the following two criteria: (1)\ninternal or external attacks and (2)\
    \ passive or active attacks. Therefore, the threat model can\nbe classiﬁed into\
    \ attacks targeting privacy, authentication, conﬁdentiality, availability, and\n\
    integrity attributes based on the characteristics of attacks that attempt to compromise\
    \ IoT\nagricultural nodes, namely IoT devices, fog nodes, and cloud nodes. 5G\
    \ itself is relatively\nsecure. However, due to the speciﬁc application scenarios,\
    \ the security problems of smart\nagriculture have their speciﬁc characteristics,\
    \ which require joint analysis and research.\n5.7.1. Information Traceability\
    \ of the Whole Process of Intelligent Agricultural Production\nBased on 5G Blockchain\n\
    Food safety has always been a matter of great concern to the public. The traditional\n\
    tracing system has some shortcomings, such as information opacity, data easy to\
    \ be tam-\npered with, poor security, and relative closure. In the future, the\
    \ development of 5G,\ncombined with blockchain technology and its unique advantages,\
    \ will provide a new\nsolution for the reliable traceability of the agricultural\
    \ supply chain. In combination with\nthe communication capability of 5G, blockchain\
    \ technology can be combined with the\nsensing equipment of the agricultural Internet\
    \ of Things for semantic segmentation and\ntracking to achieve high security.\n\
    5.7.2. Intrusion Detection for Intelligent Agricultural Production Based on 5G\n\
    With the popularization of 5G Internet of Things in smart agriculture, the degree\n\
    of intelligent and networked agricultural production is getting higher and higher,\
    \ and\nmore and more security issues need to be paid attention to. Unique security\
    \ issues and\nvulnerabilities may arise, including network, control, communications,\
    \ services, etc. How\nto combine the agricultural production process and the structural\
    \ characteristics of 5G IoT\nto establish a security mechanism, rapid detection,\
    \ and early warning of the intrusion of\nkey steps in the production process is\
    \ an important challenge in the future.\n6. Summary\nIn the future, smart agriculture,\
    \ after 5G technology transformation and upgrading,\nwill show the following characteristics:\
    \ unmanned operation, precise production, reﬁned\ncultivation, standardized production,\
    \ and intelligent supervision. Due to its low latency,\nmassive data transmission,\
    \ and massive connectivity, 5G is contributing to the development\nof IoT in agriculture.\
    \ The combination of 5G with other technologies has spawned a number\nof agricultural\
    \ applications to reduce the environmental impact of pesticides, protect natural\n\
    resources, improve animal welfare and help farmers increase yields and save costs.\
    \ This\npaper summarizes the impact of 5G on the Internet of Things, smart agriculture,\
    \ and related\ntechnologies. The key technologies and scientiﬁc issues affecting\
    \ the development of 5G-IoT\nwere analyzed to provide some ideas for the development\
    \ of 5G in smart agriculture. The\nscope of smart agriculture is relatively large,\
    \ and many details have not been discussed\nin-depth. Further efforts will be\
    \ made in the future.\nAuthor Contributions: Conceptualization, J.L., L.S. and\
    \ X.L.; methodology, X.L.; investigation, J.L.;\nresources, X.L.; data curation,\
    \ L.S.; writing—original draft preparation, J.L. and Y.L.; writing—review\nElectronics\
    \ 2023, 12, 2336\n41 of 46\nand editing, J.L. and Y.L.; visualization, J.L.; supervision,\
    \ X.L. All authors have read and agreed to\nthe published version of the manuscript.\n\
    Funding: This research was fundedby the National Natural Science Foundation of\
    \ China (62176067);\nJoint Fund for Basic and Applied Basic Research in Guangdong\
    \ Province (20A1515111162); Scientiﬁc\nand Technological Planning Project of Guangzhou\
    \ (201903010041, 202103000040); Key Project of\nGuangdong Province Basic Research\
    \ Foundation (2020B1515120095); Project Supported by Guang-\ndong Province Universities\
    \ and Colleges Pearl River Scholar Funded Scheme (2019).\nConﬂicts of Interest:\
    \ The authors declare no conﬂict of interest.\nReferences\n1.\nZhao, C. Research\
    \ on the development status and strategic objectives of smart agriculture. Smart\
    \ Agric. 2019, 1, 1–7. (In Chinese)\n2.\nAyaz, M.; Ammad-Uddin, M.; Sharif, Z.;\
    \ Mansour, A.; Aggoune, E.-H.M. Internet-of-Things (IoT)-based smart agriculture:\n\
    Toward making the ﬁelds talk. IEEE Access 2019, 7, 129551–129583. [CrossRef]\n\
    3.\nQazi, S.; Khawaja, B.A.; Farooq, Q.U. IoT-Equipped and AI-Enabled Next Generation\
    \ Smart Agriculture: A Critical Review,\nCurrent Challenges and Future Trends.\
    \ IEEE Access. 2022, 10, 21219–21235. [CrossRef]\n4.\nJawhar, I.; Mohamed, N.;\
    \ Kesserwan, N.; Al-Jaroodi, J. Networking Architectures and Protocols for Multi-Robot\
    \ Systems in\nAgriculture 4.0. In Proceedings of the 2022 IEEE International Systems\
    \ Conference (SysCon), Montreal, QC, Canada, 25–28 April\n2022; pp. 1–6. [CrossRef]\n\
    5.\nOruma, S.O.; Misra, S.; Fernandez-Sanz, L. Agriculture 4.0: An Implementation\
    \ Framework for Food Security Attainment in\nNigeria’s Post-COVID-19 Era. IEEE\
    \ Access 2021, 9, 83592–83627. [CrossRef]\n6.\nMishra, S.; Nayak, S.; Yadav, R.\
    \ An Energy Efﬁcient LoRa-based Multi-Sensor IoT Network for Smart Sensor Agriculture\
    \ System.\nIn Proceedings of the 2023 IEEE Topical Conference on Wireless Sensors\
    \ and Sensor Networks, Las Vegas, NV, USA, 22–25 January\n2023; pp. 28–31. [CrossRef]\n\
    7.\nQuy, V.K.; Hau, N.V.; Anh, D.V.; Quy, N.M.; Ban, N.T.; Lanza, S.; Randazzo,\
    \ G.; Muzirafuti, A. IoT-Enabled Smart Agriculture:\nArchitecture, Applications,\
    \ and Challenges. Appl. Sci. 2022, 12, 3396. [CrossRef]\n8.\nValecce, G.; Strazzella,\
    \ S.; Grieco, L.A. On the interplay between 5g, mobile edge computing and robotics\
    \ in smart agriculture\nscenarios. In Proceedings of the Ad-Hoc, Mobile, and Wireless\
    \ Networks: 18th International Conference on Ad-Hoc Networks\nand Wireless, ADHOC-NOW\
    \ 2019, Luxembourg, 1–3 October 2019; Springer International Publishing: Berlin/Heidelberg,\n\
    Germany, 2019; pp. 549–559.\n9.\nLiya, M.L.; Arjun, D. A survey of LPWAN technology\
    \ in agricultural ﬁeld. In Proceedings of the 2020 Fourth International\nConference\
    \ on I-SMAC (IoT in Social, Mobile, Analytics and Cloud)(I-SMAC), Palladam, India,\
    \ 7–9 October 2020; pp. 313–317.\n10.\nRadoglou-Grammatikis, P.; Sarigiannidis,\
    \ P.; Lagkas, T.; Moscholios, I. A compilation of UAV applications for precision\
    \ agriculture.\nComput. Netw. 2020, 172, 107148. [CrossRef]\n11.\nKaur, H.; Kushwaha,\
    \ A.S. A Review on Integration of Big Data and IoT. In Proceedings of the 2018\
    \ 4th International Conference\non Computing Sciences (ICCS), Jalandhar, India,\
    \ 30–31 August 2018; pp. 200–203. [CrossRef]\n12.\nShobanadevi, A.; Maragatham,\
    \ G. Data mining techniques for IoT and big data—A survey. In Proceedings of the\
    \ 2017 International\nConference on Intelligent Sustainable Systems (ICISS), Palladam,\
    \ India, 7–8 December 2017; pp. 607–610. [CrossRef]\n13.\nLi, B.-H.; Chai, X.-D.;\
    \ Liu, Y.; Chen, L.; Wei, D.-Y. Wisdom Iot System Development Strategy Study.\
    \ China Engineering Science:\n1–11. Available online: http://kns.cnki.net/kcms/detail/11.4421.G3.20220720.1149.002.html\
    \ (accessed on 28 September 2022).\n(In Chinese).\n14.\nShaﬁ, M.; Molisch, A.F.;\
    \ Smith, P.J.; Haustein, T.; Zhu, P.; De Silva, P.; Tufvesson, F.; Benjebbour,\
    \ A.; Wunder, G. 5G: A Tutorial\nOverview of Standards, Trials, Challenges, Deployment,\
    \ and Practice. IEEE J. Sel. Areas Commun. 2017, 35, 1201–1221. [CrossRef]\n15.\n\
    Chih-Lin, I.; Han, S.; Xu, Z.; Wang, S.; Sun, Q.; Chen, Y. New Paradigm of 5G\
    \ Wireless Internet. IEEE J. Sel. Areas Commun. 2016,\n34, 474–482. [CrossRef]\n\
    16.\nPalattella, M.R.; Dohler, M.; Grieco, A.; Rizzo, G.; Torsner, J.; Engel,\
    \ T.; Ladid, L. Internet of Things in the 5G Era: Enablers,\nArchitecture, and\
    \ Business Models. IEEE J. Sel. Areas Commun. 2016, 34, 510–527. [CrossRef]\n\
    17.\nLi, S.; Da Xu, L.; Zhao, S. 5G Internet of Things: A survey. J. Ind. Inf.\
    \ Integr. 2018, 10, 1–9. [CrossRef]\n18.\nWang, D.; Chen, D.; Song, B.; Guizani,\
    \ N.; Yu, X.; Du, X. From IoT to 5G I-IoT: The Next Generation IoT-Based Intelligent\n\
    Algorithms and 5G Technologies. IEEE Commun. Mag. 2018, 56, 114–120. [CrossRef]\n\
    19.\nKalyani, Y.; Collier, R. A Systematic Survey on the Role of Cloud, Fog, and\
    \ Edge Computing Combination in Smart Agriculture.\nSensors 2021, 21, 5922. [CrossRef]\n\
    20.\nWang, N.; Wang, P.; Alipour-Fanid, A.; Jiao, L.; Zeng, K. Physical-Layer\
    \ Security of 5G Wireless Networks for IoT: Challenges and\nOpportunities. IEEE\
    \ Internet Things J. 2019, 6, 8169–8181. [CrossRef]\n21.\nShaﬁque, K.; Khawaja,\
    \ B.A.; Sabir, F.; Qazi, S.; Mustaqim, M. Internet of Things (IoT) for Next-Generation\
    \ Smart Systems: A\nReview of Current Challenges, Future Trends and Prospects\
    \ for Emerging 5G-IoT Scenarios. IEEE Access 2020, 8, 23022–23040.\n[CrossRef]\n\
    22.\nTang, Y.; Dananjayan, S.; Hou, C.; Guo, Q.; Luo, S.; He, Y. A survey on the\
    \ 5G network and its impact on agriculture: Challenges\nand opportunities. Comput.\
    \ Electron. Agric. 2021, 180, 105895. [CrossRef]\nElectronics 2023, 12, 2336\n\
    42 of 46\n23.\nOgbodo, E.U.; Abu-Mahfouz, A.M.; Kurien, A.M. A Survey on 5G and\
    \ LPWAN-IoT for Improved Smart Cities and Remote Area\nApplications: From the\
    \ Aspect of Architecture and Security. Sensors 2022, 22, 6313. [CrossRef]\n24.\n\
    Khanh, Q.V.; Hoai, N.V.; Manh, L.D.; Le, A.N.; Jeon, G. Wireless communication\
    \ technologies for IoT in 5G: Vision, applications,\nand challenges. Wirel. Commun.\
    \ Mob. Comput. 2022, 2022, 3229294. [CrossRef]\n25.\nMekala, M.S.; Viswanathan,\
    \ P. A Survey: Smart agriculture IoT with cloud computing. In Proceedings of the\
    \ 2017 International\nConference on Microelectronic Devices, Circuits and Systems\
    \ (ICMDCS), Vellore, India, 10–12 August 2017.\n26.\nDagar, R. Smart Farming—IoT\
    \ in Agriculture. In Proceedings of the ICIRCA 2018, Coimbatore, India, 11–12\
    \ July 2018.\n27.\nFarooq, M.S.; Riaz, S.; Abid, A.; Abid, K.; Naeem, M.A. A Survey\
    \ on the Role of IoT in Agriculture for the Implementation of\nSmart Farming.\
    \ IEEE Access 2019, 7, 156237–156271. [CrossRef]\n28.\nDevare, J.; Hajare, N.\
    \ A Survey on IoT Based Agricultural Crop Growth Monitoring and Quality Control.\
    \ In Proceedings of the\n2019 International Conference on Communication and Electronics\
    \ Systems (ICCES), Coimbatore, India, 17–19 July 2019.\n29.\nFiona, J.R.; Anitha,\
    \ J. Automated Detection of Plant diseases and Crop Analysis in Agriculture using\
    \ Image Processing Techniques:\nA Survey. In Proceedings of the 2019 IEEE International\
    \ Conference on Electrical, Computer and Communication Technologies\n(ICECCT),\
    \ Coimbatore, India, 20–22 February 2019.\n30.\nBh Ag At, M.; Kumar, D.; Kumar,\
    \ D. Role of Internet of Things (IoT) in Smart Farming: A Brief Survey. In Proceedings\
    \ of the\nDevices for Integrated Circuit Conference, CSE Department, NIT Jamshedpur,\
    \ Jamshedpur, India, 23–24 March 2019.\n31.\nSarker, V.K.; Queralta, J.P.; Gia,\
    \ T.N.; Tenhunen, H.; Westerlund, T. A Survey on LoRa for IoT: Integrating Edge\
    \ Computing. In\nProceedings of the International Workshop on Smart Living with\
    \ IoT, Cloud and Edge Computing (SLICE 2019), Rome, Italy,\n10–13 June 2019.\n\
    32.\nBacco, M.; Berton, A.; Ferro, E.; Gennaro, C.; Gotta, A.; Matteoli, S.; Paonessa,\
    \ F.; Ruggeri, M.; Virone, G.; Zanella, A. Smart\nfarming: Opportunities, challenges\
    \ and technology enablers. In Proceedings of the 2018 IoT Vertical and Topical\
    \ Summit on\nAgriculture-Tuscany (IOT Tuscany), Tuscany, Italy, 8–9 May 2018;\
    \ pp. 1–6.\n33.\nKour, V.P.; Arora, S. Recent Developments of the Internet of\
    \ Things in Agriculture: A Survey. IEEE Access 2020, 8, 129924–129957.\n[CrossRef]\n\
    34.\nFriha, O.; Ferrag, M.A.; Shu, L.; Maglaras, L.; Wang, X. Internet of Things\
    \ for the Future of Smart Agriculture: A Comprehensive\nSurvey of Emerging Technologies.\
    \ IEEE/CAA J. Autom. Sin. 2020, 8, 718–752. [CrossRef]\n35.\nRayhana, R.; Xiao,\
    \ G.; Liu, Z. RFID Sensing Technologies for Smart Agriculture. IEEE Instrum. Meas.\
    \ Mag. 2021, 24, 50–60.\n[CrossRef]\n36.\nYang, X.; Shu, L.; Chen, J.; Ferrag,\
    \ M.A.; Wu, J.; Nurellari, E.; Huang, K. A Survey on Smart Agriculture: Development\
    \ Modes,\nTechnologies, and Security and Privacy Challenges. IEEE/CAA J. Autom.\
    \ Sin. 2021, 8, 273–302. [CrossRef]\n37.\nLiu, Y. From Industry 4.0 to Agriculture\
    \ 4.0 Current Status Enabling Technologies and Research Challenges. IEEE Trans.\
    \ Ind.\nInform. 2021, 17, 4322–4334. [CrossRef]\n38.\nBhat, S.A.; Huang, N.F.\
    \ Big Data and AI Revolution in Precision Agriculture: Survey and Challenges.\
    \ IEEE Access 2021, 9,\n110209–110222. [CrossRef]\n39.\nSinha, B.B.; Dhanalakshmi,\
    \ R. Recent advancements and challenges of Internet of Things in smart agriculture:\
    \ A survey. Future\nGener. Comput. Syst. 2021, 126, 169–184. [CrossRef]\n40.\n\
    Tao, W. Review of the internet of things communication technologies in smart agriculture\
    \ and challenges. Comput. Electr. Eng.\n2021, 189, 106352. [CrossRef]\n41.\nIdoje,\
    \ G. Survey for smart farming technologies: Challenges and issues. Comput. Electr.\
    \ Eng. 2021, 92, 107104. [CrossRef]\n42.\nMisra, N.N.; Dixit, Y.; Al-Mallahi,\
    \ A.; Bhullar, M.S.; Upadhyay, R.; Martynenko, A. IoT, Big Data, and Artiﬁcial\
    \ Intelligence in\nAgriculture and Food Industry. IEEE Internet Things J. 2022,\
    \ 9, 6305–6324. [CrossRef]\n43.\nYarali, A. AI, 5G, and IoT. In Intelligent Connectivity:\
    \ AI, IoT, and 5G; IEEE: Piscataway, NJ, USA, 2022; pp. 117–131.\n44.\nKar, S.;\
    \ Mishra, P.; Wang, K.-C. 5G-IoT Architecture for Next Generation Smart Systems.\
    \ In Proceedings of the 2021 IEEE 4th 5G\nWorld Forum (5GWF), Montreal, QC, Canada,\
    \ 13–15 October 2021; pp. 241–246. [CrossRef]\n45.\nKhakimov, A.; Salakhutdinov,\
    \ I.; Omolikov, A.; Utaganov, S. Traditional and current-prospective methods of\
    \ agricultural plant\ndiseases detection: A review. In Proceedings of the IOP\
    \ Conference Series: Earth and Environmental Science, 3rd International\nConference\
    \ on Agriculture and Bio-industry (ICAGRI 2021), Banda Aceh, Indonesia, 13–14\
    \ October 2021; Volume 951.\n46.\nDeb, S.D.; Jha, R.K.; Kumar, S. ConvPlant-Net:\
    \ A Convolutional Neural Network based Architecture for Leaf Disease Detection\
    \ in\nSmart Agriculture. In Proceedings of the 2023 National Conference on Communications\
    \ (NCC), Guwahati, India, 23–26 February\n2023; pp. 1–6. [CrossRef]\n47.\nTreboux,\
    \ J.; Genoud, D. High Precision Agriculture: An Application Of Improved Machine-Learning\
    \ Algorithms. In Proceedings\nof the 2019 6th Swiss Conference on Data Science\
    \ (SDS), Bern, Switzerland, 14 June 2019; pp. 103–108. [CrossRef]\n48.\nAsokan,\
    \ A.; Anitha, J. Machine Learning based Image Processing Techniques for Satellite\
    \ Image Analysis—A Survey. In\nProceedings of the 2019 International Conference\
    \ on Machine Learning, Big Data, Cloud and Parallel Computing (COMITCon),\nFaridabad,\
    \ India, 14–16 February 2019; pp. 119–124. [CrossRef]\n49.\nGarcia, M.B.; Ambat,\
    \ S.; Adao, R.T. Tomayto, Tomahto: A Machine Learning Approach for Tomato Ripening\
    \ Stage Identiﬁcation\nUsing Pixel-Based Color Image Classiﬁcation. In Proceedings\
    \ of the 2019 IEEE 11th International Conference on Humanoid,\nNanotechnology,\
    \ Information Technology, Communication and Control, Environment, and Management\
    \ (HNICEM), Laoag,\nPhilippines, 29 November–1 December 2019; pp. 1–6. [CrossRef]\n\
    Electronics 2023, 12, 2336\n43 of 46\n50.\nThakor, H.P.; Iyer, S. Development\
    \ and Analysis of Smart Digi-farming Robust Model for Production Optimization\
    \ in Agriculture.\nIn Proceedings of the 2019 6th International Conference on\
    \ Computing for Sustainable Global Development (INDIACom), New\nDelhi, India,\
    \ 13–15 March 2019; pp. 461–465.\n51.\nBandara, T.M.; Mudiyanselage, W.; Raza,\
    \ M. Smart farm and monitoring system for measuring the Environmental condition\
    \ using\nwireless sensor network—IOT Technology in farming. In Proceedings of\
    \ the 2020 5th International Conference on Innovative\nTechnologies in Intelligent\
    \ Systems and Industrial Applications (CITISIA), Sydney, Australia, 25–27 November\
    \ 2020; pp. 1–7.\n[CrossRef]\n52.\nGarcia-Sanchez, A.J.; Garcia-Sanchez, F.; Garcia-Haro,\
    \ J. Wireless sensor network deployment for integrating video-surveillance\nand\
    \ data-monitoring in precision agriculture over distributed crops. Comput. Electron.\
    \ Agric. 2011, 75, 288–303. [CrossRef]\n53.\nLiu, H.; Reibman, A.R.; Ault, A.C.;\
    \ Krogmeier, J.V. Spatial segmentation for processing videos for farming automation.\
    \ Comput.\nElectron. Agric. 2021, 184, 106095. [CrossRef]\n54.\nSabzi, S.; Abbaspour-Gilandeh,\
    \ Y.; Arribas, J.I. An automatic visible-range video weed detection, segmentation\
    \ and classiﬁcation\nprototype in potato ﬁeld. Heliyon 2020, 6, e03685. [CrossRef]\n\
    55.\nJiang, H.; Li, X.; Safara, F. IoT-based agriculture: Deep learning in detecting\
    \ apple fruit diseases. Microprocess. Microsyst. 2021,\n104321. [CrossRef]\n56.\n\
    Hejazi, H.; Rajab, H.; Cinkler, T.; Lengyel, L. Survey of platforms for massive\
    \ IoT. In Proceedings of the 2018 IEEE International\nConference on Future IoT\
    \ Technologies (Future IoT), Eger, Hungary, 18–19 January 2018; pp. 1–8. [CrossRef]\n\
    57.\nZhang, F.; Wan, X.; Zheng, T.; Cui, J.; Li, X.; Yang, Y. Smart Greenhouse\
    \ Management System based on NB-IoT and Smartphone.\nIn Proceedings of the 2020\
    \ 17th International Joint Conference on Computer Science and Software Engineering\
    \ (JCSSE), Bangkok,\nThailand, 4–6 November 2020; pp. 36–41. [CrossRef]\n58.\n\
    Valecce, G.; Petruzzi, P.; Strazzella, S.; Grieco, L.A. NB-IoT for Smart Agriculture:\
    \ Experiments from the Field. In Proceedings of\nthe 2020 7th International Conference\
    \ on Control, Decision and Information Technologies (CoDIT), Prague, Czech Republic,\
    \ 29\nJune 2020–2 July 2020; pp. 71–75. [CrossRef]\n59.\nFei, Y.; Zhuang, Y.;\
    \ Liu, X.; Zhao, Q.; Liao, G.; Fu, Q. Development of an Intelligent Monitoring\
    \ System for Agricultural Machinery.\nIn Proceedings of the 2019 3rd International\
    \ Conference on Robotics and Automation Sciences (ICRAS), Wuhan, China, 1–3 June\n\
    2019; pp. 161–165. [CrossRef]\n60.\nDong, Z.; Duan, J.; Wang, M.; Zhao, J.; Wang,\
    \ H. On Agricultural Machinery Operation System of Beidou Navigation System. In\n\
    Proceedings of the 2018 IEEE 3rd Advanced Information Technology, Electronic and\
    \ Automation Control Conference (IAEAC),\nChongqing, China, 12–14 October 2018;\
    \ pp. 1748–1751. [CrossRef]\n61.\nZhang, J.; Zhou, F.; Jing, C.; Wei, S.; Wu,\
    \ Y.; Jing, C. Research and Design of Automatic Navigation System for Agricultural\n\
    Machinery Based on GPS. In Proceedings of the 2020 IEEE International Conference\
    \ on Power, Intelligent Computing and Systems\n(ICPICS), Shenyang, China, 28–30\
    \ July 2020; pp. 984–986. [CrossRef]\n62.\nLi, C.; Tang, Y.; Wang, M.; Zhao, X.\
    \ Agricultural Machinery Information Collection and Operation Based on Data Platform.\
    \ In\nProceedings of the 2018 IEEE International Conference of Safety Produce\
    \ Informatization (IICSPI), Chongqing, China, 10–12\nDecember 2018; pp. 472–475.\
    \ [CrossRef]\n63.\nDong, Z.; Zhao, J.; Duan, J.; Wang, M.; Wang, H. Research on\
    \ Agricultural Machinery Fault Diagnosis System Based on Expert\nSystem. In Proceedings\
    \ of the 2018 2nd IEEE Advanced Information Management, Communicates, Electronic\
    \ and Automation\nControl Conference (IMCEC), Xi’an, China, 25–27 May 2018; pp.\
    \ 2057–2060. [CrossRef]\n64.\nFan, J.; Zhang, Y.; Wen, W.; Gu, S.; Lu, X.; Guo,\
    \ X. The future of Internet of Things in agriculture: Plant high-throughput\n\
    phenotypic platform. J. Clean. Prod. 2021, 280, 123651. [CrossRef]\n65.\nZhang,\
    \ Y.; Wang, J.; Du, J.; Zhao, Y.; Lu, X.; Wen, W.; Gu, S.; Fan, J.; Wang, C.;\
    \ Wu, S.; et al. Dissecting the phenotypic components\nand genetic architecture\
    \ of maize stem vascular bundles using high-throughput phenotypic analysis. Plant\
    \ Biotechnol. J. 2021, 19,\n35–50. [CrossRef]\n66.\nLi, B.H.; Chai, X.D.; Liu,\
    \ Y.; Chen, L.; Wei, D.Y. Research on Development Strategy of Intelligent Internet\
    \ of Things System.\nEngineering Science of China in Chinese. Available online:\
    \ https://kns.cnki.net/kcms/detail/11.4421.G3.20220720.1149.002.html\n(accessed\
    \ on 28 September 2022).\n67.\nLi, B.H.; Chai, X.D.; Hou, B.C.; Lin, T.Y.; Zhang,\
    \ L.; Li, T.; Liu, Y.; Xiao, Y.Y. Cloud manufacturing system 3.0: A new intelligent\n\
    manufacturing system in the era of “Intelli-gence+”. Comput. Integr. Manuf. Syst.\
    \ 2019, 25, 2997–3012.\n68.\nWu, D.; Zhang, Z.; Wu, S.; Yang, J.; Wang, R. Biologically\
    \ inspired resource allocation for network slices in 5G-enabled Internet of\n\
    Things. IEEE Internet Things J. 2018, 6, 9266–9279. [CrossRef]\n69.\nEscolar,\
    \ A.M.; Alcaraz-Calero, J.M.; Salva-Garcia, P.; Bernabe, J.B.; Wang, Q. Adaptive\
    \ Network Slicing in Multi-tenant 5G IoT\nNetworks. IEEE Access 2021, 9, 14048–14069.\
    \ [CrossRef]\n70.\nLiyanage, M.; Porambage, P.; Ding, A.Y.; Kalla, A. Driving\
    \ forces for multi-access edge computing (MEC) IoT integration in 5G.\nICT Express\
    \ 2021, 7, 127–137. [CrossRef]\n71.\nGupta, N.; Sharma, S.; Juneja, P.K.; Garg,\
    \ U. Sdnfv 5G-iot: A framework for the next generation 5G enabled iot. In Proceedings\
    \ of\nthe 2020 International Conference on Advances in Computing, Communication\
    \ & Materials (ICACCM), Dehradun, India, 21–22\nAugust 2020; pp. 289–294.\n72.\n\
    Ghosh, A.; Maeder, A.; Baker, M.; Chandramouli, D. 5G Evolution: A View on 5G\
    \ Cellular Technology beyond 3GPP Release 15.\nIEEE Access 2019, 7, 127639–127651.\
    \ [CrossRef]\nElectronics 2023, 12, 2336\n44 of 46\n73.\nRasyad, R.M.; Murti,\
    \ M.A.; Rizki, A.P. Design and Realization of Node MCU Module Based on NB-IoT\
    \ for General IoT Purpose.\nIn Proceedings of the 2019 IEEE International Conference\
    \ on Internet of Things and Intelligence System (IoTaIS), Bali, Indonesia,\n5–7\
    \ November 2019; pp. 189–194. [CrossRef]\n74.\nPaiva, S.; Branco, S.; Cabral,\
    \ J. Design and Power Consumption Analysis of a NB-IoT End Device for Monitoring\
    \ Applications. In\nProceedings of the IECON 2020 The 46th Annual Conference of\
    \ the IEEE Industrial Electronics Society, Singapore, 18–21 October\n2020; pp.\
    \ 2175–2182. [CrossRef]\n75.\nYang, F.; Shu, L.; Yang, Y.; Han, G.; Pearson, S.;\
    \ Li, K. Optimal Deployment of Solar Insecticidal Lamps over Constrained Locations\n\
    in Mixed-Crop Farmlands. IEEE Internet Things J. 2021, 8, 13095–13114. [CrossRef]\n\
    76.\nYang, F.; Shu, L.; Huang, K.; Li, K.; Han, G.; Liu, Y. A Partition-Based\
    \ Node Deployment Strategy in Solar Insecticidal Lamps\nInternet of Things. IEEE\
    \ Internet Things J. 2020, 7, 11223–11237. [CrossRef]\n77.\nFitzgerald, P.; Berney,\
    \ H.; Lakshmanan, R.; Coburn, N.; Geary, S.; Mulvey, B. Devices and Sensors Applicable\
    \ to 5G System\nImplementations. In Proceedings of the 2018 IEEE MTT-S International\
    \ Microwave Workshop Series on 5G Hardware and System\nTechnologies (IMWS-5G),\
    \ Dublin, Ireland, 30–31 August 2018; pp. 1–3. [CrossRef]\n78.\nAmato, F.; Amendola,\
    \ S.; Marrocco, G. Upper-bound Performances of RFID Epidermal Sensor Networks\
    \ at 5G Frequencies. In\nProceedings of the 2019 IEEE 16th International Conference\
    \ on Wearable and Implantable Body Sensor Networks (BSN), Chicago,\nIL, USA, 19–22\
    \ May 2019; pp. 1–4. [CrossRef]\n79.\nYaqoob, A.; Ashraf, M.A.; Ferooz, F.; Butt,\
    \ A.H.; Khan, Y.D. WSN Operating Systems for Internet of Things (IoT): A Survey.\
    \ In\nProceedings of the 2019 International Conference on Innovative Computing\
    \ (ICIC), Semarang, Indonesia, 16–17 October 2019;\npp. 1–7. [CrossRef]\n80.\n\
    Steiner, R.; Gracioli, G.; de Cássia Cazu Soldi, R.; Fröhlich, A.A. An Operating\
    \ System Runtime Reprogramming Infrastructure\nfor WSN. In Proceedings of the\
    \ 2012 IEEE Symposium on Computers and Communications (ISCC), Cappadocia, Turkey,\
    \ 1–4 July\n2012; pp. 000621–000624. [CrossRef]\n81.\nRamachandran, G.S.; Michiels,\
    \ S.; Joosen, W.; Hughes, D.; Porter, B. Analysis of Sensor Network Operating\
    \ System Performance\nThroughout the Software Life Cycle. In Proceedings of the\
    \ 2013 IEEE 12th International Symposium on Network Computing and\nApplications,\
    \ Boston, MA, USA, 22–24 August 2013; pp. 211–218. [CrossRef]\n82.\nChovanec,\
    \ M.; Šarafín, P. Real-time schedule for mobile robotics and WSN applications.\
    \ In Proceedings of the 2015 Federated\nConference on Computer Science and Information\
    \ Systems (FedCSIS), Lodz, Poland, 13–16 September 2015; pp. 1199–1202.\n[CrossRef]\n\
    83.\nMathane, V.; Lakshmi, P.V. Deterministic Real Time Kernel for Dependable\
    \ WSN. In Proceedings of the 2018 4th International\nConference for Convergence\
    \ in Technology (I2CT), Mangalore, India, 27–28 October 2018; pp. 1–4. [CrossRef]\n\
    84.\nSava, A.; Zoican, S. Wireless Sensors Network Framework for Developing Boards\
    \ using Contiki Operating System. In Proceedings\nof the 2020 13th International\
    \ Conference on Communications (COMM), Bucharest, Romania, 16–18 June 2020; pp.\
    \ 423–426.\n[CrossRef]\n85.\nAkpakwu, G.A.; Silva, B.J.; Hancke, G.P.; Abu-Mahfouz,\
    \ A.M. A survey on 5G networks for the Internet of Things: Communication\ntechnologies\
    \ and challenges. IEEE Access 2017, 6, 3619–3647. [CrossRef]\n86.\nTendolkar,\
    \ A.; Ramya, S. CareBro (personal farm assistant): An IoT based smart agriculture\
    \ with edge computing. In Proceedings\nof the 2020 Third International Conference\
    \ on Multimedia Processing, Communication & Information Technology (MPCIT),\n\
    Shivamogga, India, 11–12 December 2020; pp. 97–102.\n87.\nHuaji, Z.; Huarui, W.;\
    \ Xiang, S. Research on the ontology-based complex event processing engine of\
    \ RFID technology for agricul-\ntural products. In Proceedings of the 2009 International\
    \ Conference on Artiﬁcial Intelligence and Computational Intelligence,\nShanghai,\
    \ China, 7–8 November 2009; Volume 1, pp. 328–333.\n88.\nKamilaris, A.; Gao, F.;\
    \ Prenafeta-Boldu, F.X.; Ali, M.I. Agri-IoT: A semantic framework for Internet\
    \ of Things-enabled smart\nfarming applications. In Proceedings of the 2016 IEEE\
    \ 3rd world forum on internet of things (WF-IoT), New Orleans, LA, USA,\n12–14\
    \ December 2016; pp. 442–447.\n89.\nBayrakdar, M.E. Employing sensor network based\
    \ opportunistic spectrum utilization for agricultural monitoring. Sustain. Comput.\n\
    Inform. Syst. 2020, 27, 100404. [CrossRef]\n90.\nLiu, J.; Wang, X. Plant diseases\
    \ and pests detection based on deep learning: A review. Plant Methods 2021, 17,\
    \ 22. [CrossRef]\n[PubMed]\n91.\nFuentes, A.; Yoon, S.; Kim, S.C.; Park, D.S.\
    \ A robust deep-learning-based detector for real-time tomato plant diseases and\
    \ pests\nrecognition. Sensors 2017, 17, 2022. [CrossRef] [PubMed]\n92.\nBu, F.;\
    \ Wang, X. A smart agriculture IoT system based on deep reinforcement learning.\
    \ Future Gener. Comput. Syst. 2019, 99,\n500–507. [CrossRef]\n93.\nZhang, R.;\
    \ Li, X. Edge Computing Driven Data Sensing Strategy in the Entire Crop Lifecycle\
    \ for Smart Agriculture. Sensors 2021,\n21, 7502. [CrossRef]\n94.\nSekaran, K.;\
    \ Meqdad, M.N.; Kumar, P.; Rajan, S.; Kadry, S. Smart agriculture management system\
    \ using internet of things.\nTelkomnika 2020, 18, 1275–1284. [CrossRef]\n95.\n\
    Khujamatov, K.E.; Toshtemirov, T.K.; Lazarev, A.P.; Raximjonov, Q.T. IoT and 5G\
    \ technology in agriculture. In Proceedings of the\n2021 International Conference\
    \ on Information Science and Communications Technologies (ICISCT), Tashkent, Uzbekistan,\
    \ 3–5\nNovember 2021; pp. 1–6.\nElectronics 2023, 12, 2336\n45 of 46\n96.\nVan\
    \ Hilten, M.; Wolfert, S. 5G in agri-food—A review on current status, opportunities\
    \ and challenges. Comput. Electron. Agric.\n2022, 201, 107291. [CrossRef]\n97.\n\
    Hsu, C.K.; Chiu, Y.H.; Wu, K.R.; Liang, J.M.; Chen, J.J.; Tseng, Y.C. Design and\
    \ implementation of image electronic fence with 5G\ntechnology for smart farms.\
    \ In Proceedings of the 2019 IEEE VTS Asia Paciﬁc Wireless Communications Symposium\
    \ (APWCS),\nSingapore, 28–30 August 2019; pp. 1–3.\n98.\nArrubla-Hoyos, W.; Ojeda-Beltrán,\
    \ A.; Solano-Barliza, A.; Rambauth-Ibarra, G.; Barrios-Ulloa, A.; Cama-Pinto,\
    \ D.; Arrabal-\nCampos, F.M.; Martínez-Lao, J.A.; Cama-Pinto, A.; Manzano-Agugliaro,\
    \ F. Precision Agriculture and Sensor Systems Applications\nin Colombia through\
    \ 5G Networks. Sensors 2022, 22, 7295. [CrossRef]\n99.\nKai-zheng ZH, F.; Feng,\
    \ X. Intelligent Forestry System Design Based on Big Data. Comput. Telecommun.\
    \ 2020, 1, 56–59.\n100. Farooq, M.S.; Sohail, O.O.; Abid, A.; Rasheed, S. A survey\
    \ on the role of iot in agriculture for the implementation of smart\nlivestock\
    \ environment. IEEE Access 2022, 10, 9483–9505. [CrossRef]\n101. Zhang, M.; Wang,\
    \ X.; Feng, H.; Huang, Q.; Xiao, X.; Zhang, X. Wearable Internet of Things enabled\
    \ precision livestock farming in\nsmart farms: A review of technical solutions\
    \ for precise perception, biocompatibility, and sustainability monitoring. J.\
    \ Clean. Prod.\n2021, 312, 127712. [CrossRef]\n102. Liu, T.; Liu, J.; Wang, J.;\
    \ Xu, J. Optimization of the Intelligent Sensing Model for Environmental Information\
    \ in Aquaculture\nWaters Based on the 5G Smart Sensor Network. J. Sens. 2022,\
    \ 2022, 6409046. [CrossRef]\n103. Kim, K. Development of Buoy Information Monitoring\
    \ System Based on 5G Against the Abandoned, Lost and Discarded Fishing\nGears.\
    \ In Proceedings of the International Conference on Computational Intelligence,\
    \ Cyber Security, and Computational Models,\nCoimbatore, India, 14–16 December\
    \ 2017; Springer: Singapore, 2017; pp. 135–143.\n104. Yuan, L.; Bao, Z.; Zhang,\
    \ H.; Zhang, Y.; Liang, X. Habitat monitoring to evaluate crop disease and pest\
    \ distributions based on\nmulti-source satellite remote sensing imagery. Optik\
    \ 2017, 145, 66–73. [CrossRef]\n105. Fang, L. Research on Plant Diseases and Insect\
    \ Pests Monitoring Technology under the Background of Internet of Things\nTechnology.\
    \ In Proceedings of the 2020 International Wireless Communications and Mobile\
    \ Computing (IWCMC), Limassol,\nCyprus, 15–19 June 2020; pp. 1999–2001.\n106.\
    \ Varshney, R.K.; Sinha, P.; Singh, V.K.; Kumar, A.; Zhang, Q.; Bennetzen, J.L.\
    \ 5Gs for crop genetic improvement. Curr. Opin. Plant\nBiol. 2020, 56, 190–196.\
    \ [CrossRef]\n107. Lafont, M.; Dupont, S.; Cousin, P.; Vallauri, A. Back to the\
    \ future: IoT to improve aquaculture: Real-time monitoring and\nalgorithmic prediction\
    \ of water parameters for aquaculture needs. In Proceedings of the 2019 Global\
    \ IoT Summit (GIoTS), Aarhus,\nDenmark, 17–21 June 2019; pp. 1–6.\n108. Zhang,\
    \ J.; Zhang, R.; Yang, Q.; Hu, T.; Guo, K.; Hong, T. Research on application technology\
    \ of 5G Internet of Things and big data\nin dairy farm. In Proceedings of the\
    \ 2021 International Wireless Communications and Mobile Computing (IWCMC), Harbin\
    \ City,\nChina, 28 June–2 July 2021; pp. 138–140.\n109. Murugamani, C.; Shitharth,\
    \ S.; Hemalatha, S.; Kshirsagar, P.R.; Riyazuddin, K.; Naveed, Q.N.; Islam, S.;\
    \ Mazher Ali, S.P.; Batu,\nA. Machine Learning Technique for Precision Agriculture\
    \ Applications in 5G-Based Internet of Things. Wirel. Commun. Mob.\nComput. 2022,\
    \ 2022, 6534238. [CrossRef]\n110. Lin, B.S.P. Toward an AI-enabled SDN-based 5G\
    \ & IoT network. Netw. Commun. Technol. 2021, 5, 1–7.\n111. Restuccia, F.; Melodia,\
    \ T. Deep learning at the physical layer: System challenges and applications to\
    \ 5G and beyond. IEEE\nCommun. Mag. 2020, 58, 58–64. [CrossRef]\n112. Meng, H.\
    \ Research on key technologies of intelligent agriculture under 5G environment.\
    \ J. Phys. Conf. Ser. 2019, 1345, 042057.\n[CrossRef]\n113. Zhu, L.; Fan, R. Convenience\
    \ of Voice Interaction Design in the 5G Era to Adapt to Agricultural Machinery.\
    \ In Proceedings of the\n2020 Asia-Paciﬁc Conference on Image Processing, Electronics\
    \ and Computers (IPEC), Hong Kong, China, 14–18 December 2020;\npp. 208–212.\n\
    114. Kim, W.S.; Lee, W.S.; Kim, Y.J. A review of the applications of the internet\
    \ of things (IoT) for agricultural automation. J. Biosyst.\nEng. 2020, 45, 385–400.\
    \ [CrossRef]\n115. Bose, B.; Priya, J.; Welekar, S.; Gao, Z. Hemp Disease Detection\
    \ and Classiﬁcation Using Machine Learning and Deep Learning. In\nProceedings\
    \ of the 2020 IEEE Intl Conf on Parallel & Distributed Processing with Applications,\
    \ Big Data & Cloud Computing,\nSustainable Computing & Communications, Social\
    \ Computing & Networking (ISPA/BDCloud/SocialCom/SustainCom), Exeter,\nUK, 17–19\
    \ December 2020; pp. 762–769. [CrossRef]\n116. Brunelli, D.; Albanese, A.; d’Acunto,\
    \ D.; Nardello, M. Energy Neutral Machine Learning Based IoT Device for Pest Detection\
    \ in\nPrecision Agriculture. IEEE Internet Things Mag. 2019, 2, 10–13. [CrossRef]\n\
    117. Medar, R.; Rajpurohit, V.S.; Shweta, S. Crop Yield Prediction using Machine\
    \ Learning Techniques. In Proceedings of the 2019\nIEEE 5th International Conference\
    \ for Convergence in Technology (I2CT), Bombay, India, 29–31 March 2019; pp. 1–5.\
    \ [CrossRef]\n118. Gobalakrishnan, N.; Pradeep, K.; Raman, C.J.; Ali, L.J.; Gopinath,\
    \ M.P. A Systematic Review on Image Processing and Machine\nLearning Techniques\
    \ for Detecting Plant Diseases. In Proceedings of the 2020 International Conference\
    \ on Communication and\nSignal Processing (ICCSP), Chennai, India, 28–30 July\
    \ 2020; pp. 0465–0468. [CrossRef]\n119. Merchant, M.; Paradkar, V.; Khanna, M.;\
    \ Gokhale, S. Mango Leaf Deﬁciency Detection Using Digital Image Processing and\n\
    Machine Learning. In Proceedings of the 2018 3rd International Conference for\
    \ Convergence in Technology (I2CT), Mangalore,\nIndia, 6–8 April 2018; pp. 1–3.\
    \ [CrossRef]\nElectronics 2023, 12, 2336\n46 of 46\n120. Feng, Q.; Wang, X.; Wang,\
    \ G.; Li, Z. Design and test of tomatoes harvesting robot. In Proceedings of the\
    \ 2015 IEEE International\nConference on Information and Automation, Lijiang,\
    \ China, 8–10 August 2015; pp. 949–952. [CrossRef]\n121. Liu, C.; Wang, M.; Zhou,\
    \ J. Coordinating control for an agricultural vehicle with individual wheel speeds\
    \ and steering angles\n[Applications of Control]. IEEE Control Syst. 2008, 28,\
    \ 21–24. [CrossRef]\n122. Ma, J.; Wang, D.; Tang, Y.; Zhao, J. Automatic control\
    \ system of agricultural machinery based on Beidou navigation. In Proceedings\n\
    of the 2017 IEEE 3rd Information Technology and Mechatronics Engineering Conference\
    \ (ITOEC), Chongqing, China, 3–5 October\n2017; pp. 318–323. [CrossRef]\n123.\
    \ Liu, K.; Cheng, G.; Kong, Z. Beidou agricultural machinery automatic driving\
    \ software design. In Proceedings of the 2019\nIEEE 4th Advanced Information Technology,\
    \ Electronic and Automation Control Conference (IAEAC), Chengdu, China, 20–22\n\
    December 2019; pp. 1770–1775. [CrossRef]\n124. Liu, K.; Cheng, G.; Kong, Z. Agricultural\
    \ Machinery Automatic Driving Algorithm Based on Beidou System. In Proceedings\
    \ of\nthe 2019 IEEE 4th Advanced Information Technology, Electronic and Automation\
    \ Control Conference (IAEAC), Chengdu, China,\n20–22 December 2019; pp. 2041–2045.\
    \ [CrossRef]\n125. Chien, W.C.; Hassan, M.M.; Alsanad, A.; Fortino, G. UAV–Assisted\
    \ Joint Wireless Power Transfer and Data Collection Mechanism\nfor Sustainable\
    \ Precision Agriculture in 5G. IEEE Micro 2021, 42, 25–32. [CrossRef]\n126. Alabi,\
    \ C.A.; Tooki, O.O.; Imoize, A.L.; Faruk, N. Application of UAV-Assisted 5G Communication:\
    \ A Case Study of the Nigerian\nEnvironment. In Proceedings of the 2022 IEEE Nigeria\
    \ 4th International Conference on Disruptive Technologies for Sustainable\nDevelopment\
    \ (NIGERCON), Abuja, Nigeria, 17–19 May 2022; pp. 1–5.\n127. Sharma, A.; Singh,\
    \ P.K. UAV-based framework for effective data analysis of forest ﬁre detection\
    \ using 5G networks: An effective\napproach towards smart cities solutions. Int.\
    \ J. Commun. Syst. 2021, e4826. [CrossRef]\n128. Shahzadi, R.; Ali, M.; Khan,\
    \ H.Z.; Naeem, M. UAV assisted 5G and beyond wireless networks: A survey. J. Netw.\
    \ Comput. Appl.\n2021, 189, 103114. [CrossRef]\n129. Mishra, D.; Natalizio, E.\
    \ A survey on cellular-connected UAVs: Design challenges, enabling 5G/B5G innovations,\
    \ and experimen-\ntal advancements. Comput. Netw. 2020, 182, 107451. [CrossRef]\n\
    130. Khandelwal, C. Agriculture Supply Chain Management: A Review (2010–2020).\
    \ Mater. Today Proc. 2021, 47, 3144–3153. [CrossRef]\n131. Taboada, I.; Shee,\
    \ H. Understanding 5G technology for future supply chain management. Int. J. Logist.\
    \ Res. Appl. 2021, 24,\n392–406. [CrossRef]\nDisclaimer/Publisher’s Note: The\
    \ statements, opinions and data contained in all publications are solely those\
    \ of the individual\nauthor(s) and contributor(s) and not of MDPI and/or the editor(s).\
    \ MDPI and/or the editor(s) disclaim responsibility for any injury to\npeople\
    \ or property resulting from any ideas, methods, instructions or products referred\
    \ to in the content.\n"
  inline_citation: '>'
  journal: Electronics
  limitations: '>'
  pdf_link: https://www.mdpi.com/2079-9292/12/10/2336/pdf?version=1684748770
  publication_year: 2023
  relevance_score1: 0
  relevance_score2: 0
  title: Survey of Intelligent Agricultural IoT Based on 5G
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1007/978-3-319-99061-3_5
  analysis: '>'
  authors:
  - U. Ram Jagannath
  - S. Saravanan
  - S. Suguna
  citation_count: 2
  full_citation: '>'
  full_text: '>

    Your privacy, your choice We use essential cookies to make sure the site can function.
    We also use optional cookies for advertising, personalisation of content, usage
    analysis, and social media. By accepting optional cookies, you consent to the
    processing of your personal data - including transfers to third parties. Some
    third parties are outside of the European Economic Area, with varying standards
    of data protection. See our privacy policy for more information on the use of
    your personal data. Manage preferences for further information and to change your
    choices. Accept all cookies Skip to main content Advertisement Log in Find a journal
    Publish with us Track your research Search Cart Edge Computing pp 71–89Cite as
    Home Edge Computing Chapter Applications of the Internet of Things with the Cloud
    Computing Technologies: A Review U. Ram Jagannath, S. Saravanan & S. Kanimozhi
    Suguna  Chapter First Online: 10 November 2018 2330 Accesses 2 Citations Part
    of the book series: EAI/Springer Innovations in Communication and Computing ((EAISICC))
    Abstract In the modern world, the Internet of Things (IoT) has captured most of
    the applications in the market and it plays a significant role with various smart
    and interactive things that have provided a convenient environment for humans.
    Applications of IoT can be broadly classified based on consumer application, enterprise
    application, infrastructure management, industrial productivity, and so on. Some
    of the applications that implement the concepts of IoT are smart wearables, connected
    cars, industrial internet, precision agriculture, smart retail, energy management
    systems, and others. Advancement in IoT technology has resulted in automated home
    appliances and healthcare systems and also in the development of smart cities,
    smart homes, smart towns, and many more. For any application based on IoT, data
    are collected and are modeled using prediction analysis. The basic concept of
    using IoT is that it reduces waste, loss, and cost. The design of the IoT application
    should focus on increasing the energy efficiency and the cost efficiency of the
    system, improving safety, or creating better experiences. IoT is a field of the
    network, and it could be enabled either by wired or wireless communication networks.
    This refers to the technology where the machines could predict the data and work
    by itself. Here the devices that are connected to the private internet connection
    could communicate with others. The edge devices that are connected will create
    a huge amount of data. These data are generated at high speed, and also they face
    challenges like storage, computation, and networking. These issues can be handled
    by using cloud, edge, or cloud edge computing. This chapter focuses on the discussion
    of diverse applications in IoT because of its huge potential market, and also
    it enhances the comfort of our lives besides providing enhanced control of our
    daily and personal tasks with ease. Keywords IoT architecture IoT applications
    Performance of IoT applications Challenges in IoT applications Access provided
    by University of Nebraska-Lincoln. Download chapter PDF 5.1 Introduction to Internet
    of Things (IoT) The term “Internet of Things” came into existence from 1999. Internet
    of Things has the power to change the world and is a system of interconnection
    between uniquely identifiable computing devices and mechanical and digital machines.
    This interconnection is made without involving human-to-human or human-to-machine
    interaction, and instead the data are transferred over the network. Internet of
    Things is a general concept where the devices could gather the data around the
    world and could share the data over the network where it could be utilized for
    various purposes. Wikipedia states, “The Internet of Things (IoT) is the interconnection
    of uniquely identifiable embedded computing devices within the existing Internet
    infrastructure”; i.e., it connects the embedded system to the internet. In recent
    years, there is an enormous development in the IoT field. Embedded systems are
    much attractive because of their low cost, low space, low power consumption, and
    autonomous factors. It also includes other factors such as I/O speed and cost,
    energy consumption, etc., based on the instructions. Figure 5.1, obtained from
    Wikipedia, depicts the technological roadmap for Internet of Things. From this
    figure, it can be observed that by 2000, RFID tags were used to track the routing
    of the inventory to prevent the loss of logistics. This paved way for increase
    in the demand for logistics by providing support for the supply chain helpers.
    By the mid of 2000–2010, vertical-market applications such as surveillance, security,
    healthcare, transport, food safety, document mapping have seen a great development
    in technological aspects. This development in vertical-market applications has
    led to the progression of ubiquitous computing, in which the technology helps
    to locate people and everyday objects. Locating the objects that reside anywhere
    even indoors or undergrounds where satellite technologies may be unavailable or
    inadequate is called ubiquitous positioning. As a next stage, the progress is
    towards the physical-world web for miniaturization, power-efficient electronics
    and available spectrum to control distant objects. Fig. 5.1 Technology roadmap:
    The Internet of Things Full size image Internet of Things could also be defined
    as the network of sensors where the data are exchanged under the connectivity
    using network protocols and systems. The exchange of data may be bidirectional
    or unidirectional where any one system could send or receive data or both. The
    organizations or the field of applications which heavily rely on data will make
    use of cloud, fog, or edge computing. These computing architectures help in greatly
    utilizing the variety of computing techniques, resources that provide data storage,
    and these also include the Industrial Internet of Things (IIoT) [1]. Though these
    computing mechanisms sound similar, they form different layers in IIoT. Figure
    5.2 is obtained from (www.winsystems.com); in this image, the authors have described
    the layers of IIoT. According to this site, cloud computing (or cloud layer) is
    treated as a major layer, and the extended layers of it are edge computing (or
    edge layer) and fog computing (or fog layer). These fog and edge layers are a
    collection of servers which includes distributed network. These layers help the
    organization by giving feasibility; hence, they need not keep the entire infrastructure
    on their own premises. This feasibility makes the data to be collected from any
    place, and it can also enhance the ability to access data allover. In order to
    increase the utilization of end-users and the IIoT devices, recent enterprises
    are moving towards edge or fog infrastructure. Fig. 5.2 IIoT data processing layer
    stack Full size image Fog and edge computing look similar in terms of intelligence
    and also in the way the data are processed. But they differ in identifying the
    location of the intelligence and also in power computation. In edge computing
    environment, intelligence is placed in devices like embedded automation controllers,
    whereas fog computing environment places intelligence in the local area network
    (LAN) itself. For processing the power, fog computing uses edge devices and the
    gateways along with the LAN, but in the case of edge, the processing power is
    placed with the intelligence. Hence, the most challenging features in this computing
    are power consumption, latency, security, and also the data size which can be
    distributed across the network. Older IoT technologies include a virtually infinite
    number of endpoints connected to the network. Because of this advantage, data
    collection and processing has become a biggest challenge. In order to solve this
    challenge, edge computing is introduced. The computation processes which are performed
    at the nodes have given a feel as if it is performed at the data source itself.
    Edge computing can also be stated as an extension of older technologies. The extended
    features available in the edge computing are peer-to-peer networking, distributed
    data, self-healing network technology, and remote cloud services. Improved hardware
    security and also lowering the power requirement are satisfying factors that are
    provided by the processors of edge computing systems. This edge computing system
    also provides a highly optimal solution as the hardware is embedded with the flash-storage
    arrays. The concept of interaction of the centralized system with embedded systems
    and industrial gateways is used in fog computing. Much of the data processing
    of edge computing is performed directly at the embedded computing platforms by
    making an interface with the sensors and controllers. Optimizing resource usage
    in a cloud-computing system is one of the advantages provided in edge computing
    besides more advantages like reducing network traffic and improved security. The
    following subsections explicate the IoT applications along with the concept of
    cloud computing. 5.2 IoT Applications Table 5.1 gives a short description of the
    IoT applications which will be discussed in detail. Table 5.1 Short description
    of IoT applications Full size table 5.2.1 Infrastructure Management IoT infrastructure
    consists of three major parts such as sensing infrastructure, computing infrastructure,
    and storage infrastructure. Sensing infrastructure includes communicating and
    sensing devices. Computing infrastructure is needed for computing the power consumption
    and to effectively manage the dynamic loads from various sensors. Depending upon
    the user need, this infrastructure has to be modeled. Traditional storage infrastructure
    has to be replaced with updated storage infrastructure in order to satisfy the
    users, as there is a drastic increase in the need of sensor. Infrastructure management
    is needed to monitor and control the devices in rural and urban area infrastructures.
    This infrastructure includes various applications such as bridges, railways, farms,
    etc. The infrastructure is controlled by monitoring the change in state of the
    application devices. If the device is compromised whenever there is a change in
    the state of an event, and if unnoticed will result in high risk. Infrastructure
    management helps in taking quick decisions and also in saving money with real-time
    analytics. It can also be used to schedule an event like repair and maintenance
    activities in industry, which will be performed by coordinating the task between
    the service providers and the users. With these facilities, IoT helps in improving
    quality of service, timely event handling process, coordinating the responses,
    and also reducing the cost. Many fields like manufacturing, agriculture, energy
    management, environmental monitoring, building and home automation, metropolitan
    scale deployments, etc, are benefitted with this infrastructure management. 5.2.2
    Industrial IoT (IIoT) IIoT describes the usage of Internet of Things across several
    industrial activities like manufacturing, logistics, metals, and mining and in
    other sectors. Internet of Things is a transformative manufacturing technology
    which improves safety, quality, and productivity in industries [3]. The main aim
    of the Industrial Internet of Things is to have a high output at the rate of same
    input and to achieve same output in the cost of low input. All goods and products
    in the industry are labeled with near field communication (NFC) tags and radio-frequency
    identification (RFID) tags which helps to monitor the goods available in the industry
    and helps to order goods if it is insufficient. It also helps to reduce time in
    searching the specific products in the industry and also reduces labor cost. The
    primary advantages of the Industrial Internet of Things are as follows: Predictive
    maintenance Real-time monitoring Scalability and time saving Resource optimization
    The study, The Impact of Connectedness on Competitiveness, is based on a global
    survey of 350 executives from large enterprises. It found that more than half
    (52%) of executives at large enterprises expect IIoT to have a “significant” or
    “major” impact on their industry within 3 years, with another third (32%) forecasting
    a “moderate” impact in that timeframe. Security is the major factor for all industries
    and everyone is in need to know that their data is well secured. Security vulnerabilities
    are highly prevented by using sensors, smart connected devices, and by other methods.
    5.2.3 Smart Retail IoT brings a number of applications for retailers for improving
    store operations, minimizing theft occurrences; increasing customer purchase by
    selling more number of the products to them, and also producing a new inventory
    product [7]. It will make the customer know everything in the store and aid them
    closer to the buying decision. RFID tags are attached to every product in the
    store, and its availability is checked periodically. Customers gain the information
    about the goods through Bluetooth beacons or other digital receivers. The digital
    signature will navigate the customer to the product. The following actions can
    be performed for improvising the quality of purchase and make the customer think
    and take an easy decision in buying a product. From the analytics, the retailer
    will know about customer’s perspectives which will later help in improvising their
    product according to the customer’s interest. Interactive digital signature screens
    Mobile shopping applications Sensor-based items tracking Tailored digital marketing
    Optimized inventory management Mobile payment solutions IoT-enabled beacons Customer
    preferences analytics For security purposes in the retail shops, multiple video
    cameras are positioned within the shop premises at present. Using these cameras,
    images are captured and are streamed to the cloud for storage and also for further
    analysis, if required. These are implemented for security reasons or can also
    be used to monitor the customer behavior within the store. As an extension, it
    helps the proprietor of the store to keep an eye on the happenings of the store
    including the cash flow. For implementing a secured store, the store is in need
    of at least one gateway to connect various equipment with the sensors and also
    to collect the image data and store it in the cloud platform. Many companies are
    working on this issue to give better security to the retail store. 5.2.4 Smart
    Supply Chain IoT supports supply chain management by performing operational efficiencies
    and revenue opportunities. The supply chain transparency captures the extent to
    which information about the companies, suppliers, and sourcing locations are readily
    available to end-users and also to other companies in the supply chain. Security
    is the most important aspect that has to be considered. All the information must
    be prevented from falling into the wrong hands or being hacked. Sensors should
    only send specific information, which must be held in a secure private cloud environment.
    Product Tracking RFID and GPS sensors track product from the manufacturing place
    to the storage location. They will monitor the product, and hence the manufacturer
    can gain granular data like the temperature at which an item is stored and so
    on. These data will help in improvising the quality control, on-time deliveries,
    and product forecasting. Vendor Relations Data obtained from product tracking
    are also helpful to companies for updating their own production schedules and
    also recognize the vendor relationships that may be costing them money. These
    will test how vendors are handling supplies and sending goods to the manufacturer.
    High-quality goods define a better relationship with customers, and the better
    customer is retained. Forecasting and Inventory Another major parameter which
    is difficult to manage in the supply chain management is inventory. Smart devices
    are closely monitored, and they deal with more variable than earlier applications.
    Equipment monitoring provides information about predictive maintenance and alerting
    engineers for potential breakdowns and costly disruption. Consider Amazon Go as
    an example that uses IoT, computer vision, machine learning, and AI to create
    a shopping experience where the user can just walk in, pick up whatever the user
    needs, and can walk out with a purchase. In [15], the authors have proposed a
    cloud-centric IoT architecture for supply chain management (SCM). In traditional
    SCM, the movement of physical objects was performed directly, whereas, in this
    paper, the authors have controlled and coordinated the supply chain process based
    on object sensing. For implementing this framework, they have used proposed layers
    in their framework, namely, object management, cloud computing platform, information
    as a service, and smartphone user. Thirty-one percent of manufacturers are implementing
    Internet of Things enhancements to their internal operations, with another 56%
    exploring doing so in order to cut operational costs, achieve supply chain efficiencies,
    and improve predictive maintenance capabilities. Operations performed with these
    layers include submission of request by the user to the cloud; the cloud computing
    platform will make response to the user by identifying the location; this cloud
    computing platform helps the user to update the data in the database and hence
    the user can publish the sensed information; with the received information, the
    cloud will perform operation and will return the user about the task which is
    mapped according to the physical location of the user; and finally all the transactions
    and the conversations are stored to the cloud for future references. 5.2.5 Transportation
    and Logistics IoT improves the transportation industry by improving economic development,
    public safety, and the environment. IoT monitors the goods and analyses the data
    with the help of sensors. Location of the vehicle can be predicted by GPS, roadside
    sensors, etc., and finally, the products will be delivered on time, at the right
    place. The real-time traffic monitoring is explained in [10]. Some special delivering
    vehicles are available to deliver sensitive products, to be stored in a cool place.
    Environmental sensors can monitor temperature, humidity, light, and vibration
    in real time. These sensors have the capability to detect the occurrence of any
    problem, and they are alarmed so that corrective measures can be taken to prevent
    spoiling of goods. The data that are collected from different sensors are massive
    in size to be stored in the cloud. Safety and security is the main reason for
    the development of the transportation industry with IoT. Thus, there is no loss
    of goods, and hence they are transported to the destined place without any damage.
    By maximizing the profitability and viability, the efficiency of the supply chain
    is improved in transportation and logistics field. With the improved development
    in the fields of mobile technology and IoT, the enterprises are connecting the
    transportation- and logistics-related devices with the centralized cloud network
    to gain information about the real-time operations in transportation and logistics
    by capturing and sharing the information about the critical data. The information
    about the critical data is shared in to make sure that the right product is delivered
    to the right place at the right time. This paves way for the development in various
    fields such as asset management, cloud, mobile, and big data. 5.2.6 Connected
    Cars Internet of Things paves a great and fresh way for the car manufacturers
    to upgrade their cars in a highly competitive market. As stated in [2] by Kevin
    Ashton, this also enhances the idea, where a person can drive around the world
    and can stay connected all the time. Before the invention of IoT in automobiles,
    one has to search for the route manually, while the IoT has made it more convenient.
    For example, a person could set the destination place using Ground Positioning
    Systems (GPS), and the driver will be directed to the destination place and this
    also needs some improvements. Auto-pilot mode is the most modern technology introduced
    in recent times. High-resolution cameras can be used to detect soft and hard objects
    in the lane and also in the vehicle surroundings. Forward-facing radar with enhanced
    processing collects additional data about the world on a redundant wavelength
    that helps the user to see through heavy rain, fog, dust, and even the car behind
    and ahead. This could also aid in detecting the traffic signals and signs that
    are already inbuilt in the system and could drive the car as safe as possible.
    It can also adapt to the changes in the environmental roads around the world,
    and it could also offer lane change automatically. IHS Markit predicts that more
    than 70 million connected cars will be on the road by 2023. Designing a connected
    vehicle platform on cloud IoT core will be a better solution for managing the
    connected cars by making a use of cloud IoT core on Google Cloud Platform (GCP).
    The use cases that can be defined by making a combination with data storage and
    platforms are usage-based insurance, predictive maintenance, freight tracking,
    and customized in-vehicle experience. The main challenges that a development team
    will face in this domain are device management, data ingestion, data analytics,
    applications, and predictive models. Besides these challenges, the developer must
    also focus on security and set the boundary level for the applications they design
    that are implemented in the cloud-based system. 5.2.7 Self-Parking Vehicles Self-driving
    cars are learned from the data cloud, the collections of data are brakes, tire
    and transmission performance, fuel consumption, and efficiency of the vehicle.
    The main reason for self-driving is high safety, and it will abide all traffic
    rules and regulation as shown in [5]. Averagely, parking coverage takes 31% of
    land use in big cities, like San Francisco, and even more, 81% in Los Angeles
    and 76% in Melbourne, while at the lower end we find New York (18%), London (16%),
    and Tokyo (7%). Hence, the removal of unnecessary parking areas is the first task
    for municipalities to create a better urban planning. The data are provided with
    high security, and the hackers cannot access the data easily without the user’s
    authorization. There exists confusion when the user tries parking his or her vehicle,
    and it leads to great pressure and stress to the user which also results in waste
    of time. As self-driving vehicle is automatically parked in the parking area without
    any confusion it reduces pressure as well as the time for user. IoT predicts the
    current scenario and performs the action according to the problem. In [16], the
    authors have designed a smart parking system. In this system, the authors have
    specified that the system can be implemented for any type of parking like parking
    available at covered parks, open parks, and also street side parking. For this
    system, the authors have designed an architecture which includes cloud service
    provider. The main function of this cloud service provider is to collect information
    about the parking area and store the information in the cloud. The major components
    of this smart parking system are centralized server, Raspberry Pi, image capturing
    device, a navigation system, displaying device, and the user device. The centralized
    server acts as a database that will hold the entire information about the parking
    system, some of the information includes a number of parking slots, availability
    of vehicles, and so on. Raspberry Pi is a microcontroller used to implement the
    parking system with a camera attached to it. This Pi-camera is used to capture
    pictures of the parking area for validating the area to check the availability
    of slots in that area. The main role of the navigation system is to navigate the
    users to the available parking lot which is nearer to his or her current location.
    Displaying device is a monitor or tab available at the admin’s location to monitor
    the device and to modify the parking lot if needed. The user device is used to
    connect the user with the parking system using their smartphones or browsers.
    5.2.8 Smoke Detectors Safety of life is more important when compared to any other
    application. Records show that many lives were exploited by fire accidents, and
    also it takes a longer duration for the fire service to reach the destination.
    To avoid these types of accidents, many companies are using IoT devices for safety.
    It is safe in many ways as it is more evident that if fire accident occurs, it
    automatically connects itself to the hot-connect or cloud environment and it directly
    sends a voice or text message to the concerned fire agency. The working principle
    is not like the normal smoke detectors which could only give beeping alarm sounds
    but it also helps to save people. This has battery power that is estimated to
    last up to 10 years and also it is not a big bottleneck to change the battery.
    It is more rapidly replacing the normal smoke detectors as this proves to be more
    useful and also available at an affordable cost. One thousand smoke detector surveys
    were mailed, covering about 70 percent of the town’s households. While the results
    staggered in over a period of 3 months, 315 completed surveys (31.5 percent) were
    ultimately returned. The high return rate can be interpreted as a strong interest
    on the part of the public concerning fire safety. In the industrial sector, the
    smoke detectors play a different role, where it is used as the contamination detector.
    The detector is placed at the chimney and monitors the smoke that is being passed
    out through it. If the contaminants are greater than the recommended level, it
    will send a warning message to the main supervisor and also to the concerned person
    so that it will never be ignored. It ensures green living to all the people and
    greatly reduces pollution. 5.2.9 Smart Cities As described by Gauer, A., Smart
    City Architecture and its applications based on IoT in [4], smart cities improve
    the quality of lifestyle by improving infrastructures like delivering clean water,
    dependable power, and efficient public lighting. The main motive of a smart city
    is to provide more efficient water supply, an innovative solution to traffic congestion,
    and more reliable public transportation. Water can be highly saved by providing
    the following facilities. Leakage detection in pipes Wastewater recycling Managing
    the storm-water The benefits of the smart city include increased safety, reduced
    traffic, lower levels of pollution, more efficient use of energy, and improve
    the overall quality of life for future city dwellers. The main aim of the smart
    cities is extended to keep the citizens safe, and it should provide education
    and technological job opportunities to the citizens with open innovation. Gujarat
    International Finance Tec-City stands as a great example for smart cities. It
    has better city planning and development, and internet facility is provided all
    over the city with a faster supply of products at a lower operating expense. The
    major issue stands in the contamination of air, and to resolve this issue many
    green buildings are set up. The companies which focus on security management can
    be connected with smoke detectors so that they can protect the buildings from
    fire. The device will send the message to the cloud-based dashboard only if the
    fire is detected or if the system is in need of maintenance. This will greatly
    reduce the man-hours in performing the maintenance check frequently, and even
    the process may not be needed. These connected smoke detectors are more advantageous
    when compared to the traditional system. These smoke detectors can be connected
    to devices such as desktops, laptops, tablets or smart-phones to get alert messages
    which proves helpful for fire security personnel. 5.2.10 Construction The main
    problem faced by a worker in a construction industry is misplacing the equipment
    at the construction sites which leads to time consumption in searching the equipment
    or may cause any damage to the equipment. IoT keeps on monitoring the equipment
    by sensors by GPS tracking attached to the equipment. RIFD tags will be attached
    to the devices so that tracking can be made easy. The cost of the equipment is
    comparably higher than earlier devices. This will help the consumer to buy the
    equipment only once in a lifetime, instead of purchasing frequently whenever it
    is missed. Repair and service of the equipment can be monitored, and the problem
    could be resolved with a warning alert from the equipment. Energy consumption
    by the equipment can be minimized by the sensors which will adjust the actions
    to be performed by the tools automatically. The sensors will automatically switch
    on/off to save energy. The main advantage is the quality work is increased and
    more convenient for users. The construction project work can be done on time,
    and the quality of the construction can be improved. The future Internet of Things
    will provide intelligent building management systems which can be considered as
    a part of a much larger information system used by facilities managers in buildings
    to manage energy use and energy procurement and to maintain efficient building
    management systems. 5.2.11 Smart Homes Google is highly potential and develops
    automation in everything. As everything in the home is well organized and fully
    computerized, they are all controlled simply with a mobile application which leads
    to controlling and monitoring the devices that are installed in the home [17].
    The devices that are using electricity can be added to the network. Smart homes
    also provide high security which prevents hackers from penetration. Several companies
    have developed smart appliances which include smart fridges, televisions, and
    air conditioners. For example, Nest is an automated thermostat which senses the
    temperature and adjusts the air conditioner to the favorable means, i.e., if the
    external temperature is high, it lowers the internal temperature and vice versa
    which makes the people comfortable. In [12], the authors describe the privacy
    and security challenges in smart homes. In [18], the authors have designed a smart
    home in such a way that the device will record the daily activities inside the
    home and store the information in the cloud storage. The device will get familiar
    with this information, and hence at a later stage, the device will do the similar
    operations without the requirement of human intervention. 5.2.12 Smart Panels
    A smart panel can perform multiple functions like tracking the electrical usage
    and wastage in a detailed manner, and it also displays the result on the computer
    screen. They are simple, flexible, and have an open architecture which proves
    that they are simple in construction and implementation. Using these applications,
    the user can remotely access the electrical units which are installed far away
    which help in reducing the electrical energy. Another type is smart solar panels,
    and these have multiple abilities which could perform different actions depending
    on the conditions required. For example, this panel can be used to convert solar
    energy into electrical energy or to the required form of energy in which it acts
    as a transducer in one form and it could convert air into drinking water from
    the sunlight and air in another form. All the installed panels are monitored by
    the organization. The purity and taste of the water are obtained by adding the
    required minerals to it. It is connected and so it provides optimized performance.
    It could provide an average of 8–20 bottles of water per day. The main advantage
    of using these panels is they need not be hooked up to the home’s electrical systems,
    and they use full renewable resources to gain energy. 5.2.13 Energy Management
    Energy is a very important aspect for any household, industries, agriculture,
    and so on. Managing energy source and conserving it for better performance is
    a challenging task. IoT paradigm promises to increase the visibility and awareness
    of energy consumption, thanks to smart sensors and smart meters at the machine
    and production line level. Since every appliance depends on energy supply, energy
    plays a vital role in day-to-day life. An interface like Arduino Microcontrollers
    controls the usage of an appliance like the intensity of light and the speed of
    the fan. Humidity, temperature, and light intensity are taken into consideration
    in developing a better IoT system for energy management. IoT devices are controlled
    and connected for small cities and communities, transportation systems, buildings,
    lighting systems, factories, and more devices. Building Energy Management Systems
    (BEMs) attracted $1.4 B in VC Funding from 2000 to 2014 (26% of all investment
    in building energy technology). In 2020, about 77% of the $2.14 billion US market
    will comprise BEMS applications, and 40% will come from buildings below 50,000
    square feet. The US market for sensors and controls for BEMs will rise at a 17%
    compound annual growth rate to $2.14 billion in 2020. Possible future directions
    for energy management are as follows: Energy-efficient mechanisms for software-defined
    IoT solutions, which can provide scalable and context-aware data and services.
    Fog computing can lead to energy saving for most of the IoT applications; therefore,
    it is important to study energy consumption of fog devices for IoT applications.
    5.2.14 Smart Wearables Wearable devices are considered as the hot topic these
    days. A reduced job is much preferred in every field which resulted in this technology.
    Some of the important functions to be considered for a smart wearable in the industrial
    location is it could sense cut-off radiation level and will alert the user when
    the environment becomes worse. Health- and fitness-related devices are also available
    these days which could monitor the heartbeat rate, blood pressure, footsteps count,
    sleep monitor, etc. Some of the useful features are it could find the body temperature
    by which the user could get an early indication of cold or flu. Most of the users
    have a question why to use a wearable gadget while a single smartphone could do
    all these work. It is not comfortable to take our smartphone for every transaction,
    but the smartphone will act as the central unit of the wearable by connecting
    it through Bluetooth or the network which grants access for the wearable to surf
    the data available in the smartphone. Further, wearable reduces manual work to
    a great extent where the devices in the home are being connected and the user
    can control any of the devices which are connected in the same network without
    requiring any movement from place to place. 5.2.15 Environmental Monitoring The
    main application of IoT in the environmental monitoring is weather forecasting
    and monitoring, protecting endangered species, water safety, and many more applications.
    Current weather forecasting and monitoring applications include the need for the
    labor work, but implementing IoT in this field greatly reduces this effort. Sampling
    is done at regular intervals, and it helps to prevent contamination of air in
    many stages. IoT allows deep monitoring of weather in a specific range of area
    using IoT installed with radar. This promises more fine-grained data with great
    accuracy and range. This helps in early detection and early warning which reduces
    the loss of life and property [11]. Low-power, wide-area network (LPWAN) technology
    is perfectly suited for environmental monitoring, as it can connect devices that
    need to stay in the field for an extended period of time and send small amounts
    of data over a long range. There are a number of reasons you may want to select
    LPWAN technology for your IoT environmental monitoring: Long battery life Low
    cost Long range Satellite backhaul ability 5.2.16 Biological Sensors Biosensors
    are gaining more interest nowadays, and they promise to be one of the constant
    growing fields in IoT [9]. Biosensors are mainly used in the field of healthcare,
    applications related to sports, and mostly in the military. The main advantage
    of this application is low cost and also provides real-time information. The term
    “wearable biosensors” (WBS) is evolved by combining both the smart wearable and
    the biosensors in a single unit. The required sensors are installed in the various
    parts of the body so they could be monitored all the time, without any whatsoever
    disturbances. Their size will be very small which makes them easy to carry wherever
    the user moves. Based on the usage of such sensors, these devices are popularly
    named as immunosensors, glucometers, biocomputers, etc., some of the examples
    include (1) Google lens (2) ring sensor and (3) smart shirt. 5.2.17 Healthcare
    Systems According to the World Health Organization (WHO), 31 percent of global
    deaths are due to cardiovascular diseases (estimated 17.7 million people in 2015).
    The number of people with diabetes has been rapidly increasing from 108 million
    in 1980 to 422 million in 2014. The rising cost of healthcare services has increased
    the need for providing effective and efficient healthcare to the patients in most
    of the developing countries. Internet of Things stands as the key component for
    the digital transformation of healthcare systems. Internet of Healthcare Things
    (IoHT) and Internet of Medical Things are considered to be the two most important
    parts of healthcare systems which include smart pills, smart personal healthcare,
    and real-time health systems. This is mainly designed for those who do not find
    time to spend on their health life, whereas here they could easily check their
    health issues with easy IoT healthcare systems. This is not only suitable for
    an individual but easy for everyone to register with their health issues and get
    appropriate remedy, and also this initiative will reduce spending money for a
    periodical check-up. IoT-based healthcare for the elderly is the cheapest and
    more efficient way for applications related to healthcare. ECG, heartbeat rate,
    and body moisture can easily be found using this application. Appointment of the
    doctors can be made and it will also help in periodical indication for the pills
    at right time. Healthcare IoT systems ensure some basic ideas that can now be
    used to monitor the patient remotely, but in future, it will surely be an important
    member in the healthcare industry to maintain the healthcare and its related activities.
    The health records of the users are collected and are stored in electronic healthcare
    records (EHR) which makes the past data as well as the present data to be readily
    available at any time. While considering the security of the personal health records,
    IoT considers this as sensitive data and has some stricter rules that should be
    followed. Genetic materials and other personal details are stored in a private
    environment. In [13], the authors have proposed a device named Cellcon. This device
    is developed based on the image analysis concept which is portable and also affordable
    to do the process. This is a hardware device with a ball lens and a mobile application.
    The authors designed this application to do the cell count and to identify the
    presence of the malarial parasite. The blood sample is collected in a slide and
    a photo is taken by a ball lens that is attached to the phone clip, and hence
    a magnified image of the blood sample is obtained. This IoT device uses cloud
    storage for storing the image data, retrieve the data, and perform the analysis
    through and from the internet. The image is compared with the images in the database
    and the results are sent to the patient. In this application, the first half of
    the application, i.e., collecting the blood sample and taking a photo, is performed
    at the patient’s location. The patient may reside at any remote location, and
    the image data will be passed via the internet. The doctor will analyze the image
    data using the application which is installed in his mobile, and this belongs
    to the second phase of the application. 5.2.18 Precision Agriculture Precision
    agriculture makes rapid changes in the agricultural sector, and numerous organizations
    are leveraging this technique around the world. IoT makes agriculture field highly
    efficient. CropMetrics is a precision agricultural organization concentrated on
    ultra-modern agronomic solutions. Wireless sensor network (WSN) and wireless moisture
    sensor network (WMSN) are used in IoT. WSN technology contains many sensors, which
    are used to monitor and control to do proper irrigation. This optimization will
    maximize the profitability of irrigated crop fields, improves yields, and increases
    water usage efficiently. Agricultural drones are applied to farming in order to
    help increase crop production and monitor crop growth. Through the use of advanced
    sensors and digital imaging capabilities, farmers are able to use these drones
    to help them gather a richer picture of their fields. An advantage of drones is
    crop health, convenient to use, and increase in yield production. IoT reduces
    the human intervention in farming. Today’s sophisticated commercial farms have
    exploited advanced technologies; however, IoT introduces more access to deeper
    automation and analysis. In [14], the authors have projected the problems faced
    by the farmers in the real world. The farmers will be holding the agricultural
    land which is measured in hectares, and it is highly difficult for the farmers
    to identify the infected crop that is spread out in a vast area. Besides these
    criteria, the farmers also face certain other issues like rainfall prediction,
    climate, availability of water, and so on. Also, the farmers are not ready to
    cultivate different or hybrid crops in their land, as they lack knowledge and
    less experience in this scenario. In order to support the farmers in these conditions,
    a sensor device can be placed in the soil that is used for monitoring the climatic
    changes, temperature, and even soil moisture. The data observed by the sensors
    are stored with the help of cloud storage; this stored information will be used
    in future for analyzing and predicting the soil status and also about the feasible
    crop which can be cultivated with the existing soil and weather conditions. This
    concept of implementing cloud will aid in the expansion of data storage, and this
    will greatly reduce the production cost. 5.2.19 Poultry and Farming IOT is an
    innovative technology that provides modern and automated poultry farming. Basic
    environment parameters for poultry farming are temperature, humidity, ammonia
    gas, and water level. For instance, the temperature is controlled by cooling fan,
    humidity is monitored by the exhaust fan, ammonia gas is examined by ventilation
    window open, and the water level is maintained by DC motor. These actions are
    performed by the sensor, and monitoring is done the whole day. These are done
    mainly for the growth and health of the chicken. Farming challenges caused by
    population growth and climate change have made it one of the first industries
    to utilize the IoT in this sector. 5.2.20 Smart Surveillance The major issue in
    the secured environment is to safeguard our buildings, assets, and so on [8].
    The basic alarm facilities of earlier days had high visibility and later on introduced
    a monitoring camera which has some less scope of treatment. Internet of Things
    helps to create smart homes and smart cities by adding a feature of real-time
    monitoring services to the environment which concerns more about the security
    by the use of smart surveillance and security [6]. To make it simpler, let us
    consider that the user uses network cameras to monitor the area under surveillance
    and high-resolution cameras for the places of large crowd movement. IoT will offer
    a greater solution to such disparate things by considering the above scenarios
    by combining the video surveillance cameras and smoke detectors into a “small
    and single glass pane.” As all the devices will be monitored over a network, they
    could share data among them and could take decisions by themselves by which the
    security will be enhanced. The images produced by the video surveillance cameras
    should have high clarity, and this would be true by adopting Internet of Things.
    Nowadays, megapixel technology has grown to its peak by incorporating them with
    low-lighting cameras which are now blooming successor of the present market. These
    are all concerned with the wide dynamic range (WDR) of cameras. IoT offers a resolution
    of at least three times greater, and even 4 k videos could be generated using
    IoT. 5.3 Conclusion There are many benefits that arise with the increased use
    of Internet of Things. IoT is used in our everyday life as it greatly reduces
    the cost and power. Hence, this chapter has given an overview of applications
    using IoT. IoT has the potential to drive integrated solutions that can make a
    difference. The entire world is transforming slowly with the use of IoT in daily
    life. Also, the people are getting ample opportunities to enhance their commitments
    and perform various activities using smart things. This chapter has given a short
    description of various applications that are implemented with IoT and also certain
    challenges faced in those applications. Research work can be extended in the challenges
    faced and giving increased security to the applications to provide the better,
    smart and secured environment. References L. Da Xu, W. He, S. Li, Internet of
    things in industries: a survey. IEEE Trans. Ind. Inf. 10(4) (2014) Article   Google
    Scholar   K. Ashton, That ‘internet of things’ thing. RFID J. 22 (2009) Google
    Scholar   D.Y. Joo, J.K. Kim, Creative & active convergence model of IoT. Korea
    Inst. Ind. Econ. Trade Korea 1 (2014) Google Scholar   A. Gauer, Smart city architecture
    and its applications based on IoT. Procedia Comput. Sci. 52, 1089–1094 (2015)
    Article   Google Scholar   A. Bagula, L. Castelli, M. Zennaro, On the design of
    smart parking networks in the smart cities: An optimal sensor placement model.
    Sensors 15(7), 15443–15467 (2015) Article   Google Scholar   K. Sohraby, D. Minoli,
    T. Znati, Wireless Sensor Networks: Technology, Protocols, and Applications (Wiley,
    Hoboken, 2007) Book   Google Scholar   H. Sundmaeker, P. Guillemin, P. Friess,
    S. Woelfel, Vision and Challenges for Realizing the Internet of Things (Publications
    Office of the European Union, Luxembourg, 2010) Google Scholar   B. Khoo, RFID
    as an enabler of the internet of things: issues of security and privacy, in Internet
    of Things (iThings/CPSCom), 2011 Google Scholar   Y. Zhang, Technology framework
    of the internet of things and its application, in Electrical and Control Engineering
    (ICECE), 2011 Google Scholar   Y. Cao, W. Li, J. Zhang, Real-time traffic information
    collecting and monitoring system based on the internet of things, in Pervasive
    Computing and Applications (ICPCA), 2011 Google Scholar   A.R. Jaladi, K. Khithani,
    P. Pawar, K. Malvi, G. Sahoo, Environmental monitoring using wireless sensor networks
    (WSN) based on IOT. Int. Res. J. Eng. Technol 4 (2017) Google Scholar   J. Bugeja,
    A. Jacobsson, P. Davidsson, On privacy and security challenges in smart connected
    homes, in European Intelligence and Security Informatics Conference, 2016 Google
    Scholar   Z.H. Chan, E.L.M. Su, Y.M. Lim, E.E. Langeh Randin, C.F. Yeong, M.A.
    Abdul Razak, I. Ariffin, Cellco: portable device for automated blood cell count
    and abnormal cell detection. J. Telecommun. Electron Comput Eng 9(3–9) (2017)
    Google Scholar   B.B. Prahlada Rao, P. Saluja, N. Sharma, A. Mittal, S.V. Sharma,
    Cloud computing for internet of things & sensing based applications, in 6th International
    Conference on Sensing Technology (ICST – 2012) Google Scholar   P. Satpute, A.
    Mohanpukar, Cloud centric IoT framework for supply chain management. Int. J. Comput.
    Appl. 118(15) (2015) Article   Google Scholar   S.R. Basavaraju, Automatic smart
    parking system using internet of things (IoT). Int. J. Sci. Res. Publ. 5(12) (2015)
    Google Scholar   J. Rajaleksmi, G.G. SivaSankari, IoT framework for smart home
    using cloud computing via open source mobile platform. Int. J. Comput. Eng. Appl.
    (2016), ICCSTAR-2016, Special Issue, May 2016 Google Scholar   M. Kasmi, F. Bahloul,
    H. Tkitek, Smart home based on internet of things and cloud computing, in 7th
    International Conference on Sciences of Electronics, Technologies of Information
    and Telecommunications (SETIT’16), 2016 Google Scholar   Download references Author
    information Authors and Affiliations School of Computing, SASTRA Deemed to be
    University, Thanjavur, Tamil Nadu, India U. Ram Jagannath & S. Saravanan Department
    of CSE, School of Computing, SASTRA Deemed to be University, Thanjavur, Tamil
    Nadu, India S. Kanimozhi Suguna Editor information Editors and Affiliations Computer
    Engineering Department, Antalya Bilim University, Antalya, Turkey Fadi Al-Turjman
    Rights and permissions Reprints and permissions Copyright information © 2019 Springer
    Nature Switzerland AG About this chapter Cite this chapter Ram Jagannath, U.,
    Saravanan, S., Kanimozhi Suguna, S. (2019). Applications of the Internet of Things
    with the Cloud Computing Technologies: A Review. In: Al-Turjman, F. (eds) Edge
    Computing. EAI/Springer Innovations in Communication and Computing. Springer,
    Cham. https://doi.org/10.1007/978-3-319-99061-3_5 Download citation .RIS.ENW.BIB
    DOI https://doi.org/10.1007/978-3-319-99061-3_5 Published 10 November 2018 Publisher
    Name Springer, Cham Print ISBN 978-3-319-99060-6 Online ISBN 978-3-319-99061-3
    eBook Packages Engineering Engineering (R0) Share this chapter Anyone you share
    the following link with will be able to read this content: Get shareable link
    Provided by the Springer Nature SharedIt content-sharing initiative Publish with
    us Policies and ethics Download book PDF Download book EPUB Sections Figures References
    Abstract Introduction to Internet of Things (IoT) IoT Applications Conclusion
    References Author information Editor information Rights and permissions Copyright
    information About this chapter Publish with us Discover content Journals A-Z Books
    A-Z Publish with us Publish your research Open access publishing Products and
    services Our products Librarians Societies Partners and advertisers Our imprints
    Springer Nature Portfolio BMC Palgrave Macmillan Apress Your privacy choices/Manage
    cookies Your US state privacy rights Accessibility statement Terms and conditions
    Privacy policy Help and support 129.93.161.222 Big Ten Academic Alliance (BTAA)
    (3000133814) - University of Nebraska-Lincoln (3000134173) © 2024 Springer Nature'
  inline_citation: '>'
  journal: EAI/Springer Innovations in Communication and Computing
  limitations: '>'
  pdf_link: null
  publication_year: 2018
  relevance_score1: 0
  relevance_score2: 0
  title: 'Applications of the Internet of Things with the Cloud Computing Technologies:
    A Review'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.20944/preprints202307.1162.v1
  analysis: '>'
  authors:
  - Natalia M. Matsveichuk
  - Yuri N. Sotskov
  citation_count: 1
  full_citation: '>'
  full_text: '>

    This website uses cookies We use cookies to personalise content and ads, to provide
    social media features and to analyse our traffic. We also share information about
    your use of our site with our social media, advertising and analytics partners
    who may combine it with other information that you’ve provided to them or that
    they’ve collected from your use of their services. Consent Selection Necessary
    Preferences Statistics Marketing Show details             Deny Allow selection
    Allow all Instructions for Authors Awards About FAQ Submit Log in/Register preprints.org
    > biology and life sciences > agricultural science and agronomy > doi: 10.20944/preprints202307.1162.v1
    Preprint Review Version 1 Preserved in Portico This version is not peer-reviewed
    Digital Technologies, Internet of Things and Cloud Computations Used in Agriculture:
    Surveys and Literature in Russian Natalia M. Matsveichuk and Yuri N. Sotskov *
    Version 1 : Received: 17 July 2023 / Approved: 17 July 2023 / Online: 18 July
    2023 (13:51:22 CEST) How to cite: Matsveichuk, N.M.; Sotskov, Y.N. Digital Technologies,
    Internet of Things and Cloud Computations Used in Agriculture: Surveys and Literature
    in Russian. Preprints 2023, 2023071162. https://doi.org/10.20944/preprints202307.1162.v1
    Abstract Development of agriculture in Russia and Belarus is based on the practical
    implementation of "smart" systems in agriculture based on the use of modern wireless,
    intelligent technologies and Internet of Things. This review presents research
    articles (mainly, in Russian) published in the period of 2013 – 2022 on the use
    of cloud technologies and Internet of Things for the development of agriculture
    in Russia and Belarus. An analysis of the use of cloud technologies and Internet
    of Things in the modern world is given on the basis of research articles and reviews
    published in English in the period of 2017 – 2022. The main directions of digitalization
    of modern agriculture are listed. The uses of cloud technologies and Internet
    of Things in agriculture are described along with promising directions for further
    research and applications. Keywords modern agriculture; smart farming; cloud computing;
    internet of things; survey Subject Biology and Life Sciences, Agricultural Science
    and Agronomy Copyright: This is an open access article distributed under the Creative
    Commons Attribution License which permits unrestricted use, distribution, and
    reproduction in any medium, provided the original work is properly cited. Download
    PDF Comments (0) We encourage comments and feedback from a broad range of readers.
    See criteria for comments and our Diversity statement. Leave a public comment
    Send a private comment to the author(s) * All users must log in before leaving
    a comment Related Articles Peer-review Articles Smart Farming Techniques for Climate
    Change Adaptation in Cyprus George Adamides et al. Atmosphere, 2020 Smart Agriculture
    and Rural Revitalization and Development Based on the Internet of Things under
    the Background of Big Data Xi Ma Sustainability, 2023 IoT Sensing Platform as
    a Driver for Digital Farming in Rural Africa Antonio Oliveira-Jr et al. Sensors,
    2020 Precision Agriculture Design Method Using a Distributed Computing Architecture
    on Internet of Things Context Francisco Ferrández-Pastor et al. Sensors, 2018
    Exploring the Adoption of Precision Agriculture for Irrigation in the Context
    of Agriculture 4.0: The Key Role of Internet of Things Sergio Monteleone et al.
    Sensors, 2020 Irriman Platform: Enhancing Farming Sustainability through Cloud
    Computing Techniques for Irrigation Management Manuel Forcén-Muñoz et al. Sensors,
    2021 Applying Adaptive Security Techniques for Risk Analysis of Internet of Things
    (IoT)-Based Smart Agriculture Abdur Riaz et al. Sustainability, 2022 A Cloud-Based
    IoT Platform for Precision Control of Soilless Greenhouse Cultivation Alaa Sagheer
    et al. Sensors, 2020 A Review on Security of Smart Farming and Precision Agriculture:
    Security Aspects, Attacks, Threats and Countermeasures Abbas Yazdinejad et al.
    Applied Sciences, 2021 LoRaFarM: A LoRaWAN-Based Smart Farming Modular IoT Architecture
    Gaia Codeluppi et al. Sensors, 2020 Views 85 Downloads 207 Comments 0 Get PDF
    Cite Share 0 Bookmark BibSonomy Mendeley Reddit Delicious Alerts Notify me about
    updates to this article or when a peer-reviewed version is published. Preprints.org
    is a free preprint server subsidized by MDPI in Basel, Switzerland. Contact us
    RSS MDPI Initiatives SciProfiles Sciforum Encyclopedia MDPI Books Scilit Proceedings
    JAMS Important links How it Works Advisory Board FAQ Friendly Journals Instructions
    for Authors About Statistics Subscribe Choose the area that interest you and we
    will send you notifications of new preprints at your preferred frequency. Subscribe
    © 2024 MDPI (Basel, Switzerland) unless otherwise stated Disclaimer Privacy Policy
    Terms of Use  Feedback'
  inline_citation: '>'
  journal: ''
  limitations: '>'
  pdf_link: null
  publication_year: 2023
  relevance_score1: 0
  relevance_score2: 0
  title: 'Digital Technologies, Internet of Things and Cloud Computations Used in
    Agriculture: Surveys and Literature in Russian'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.19101/ijatee.2021.876002
  analysis: '>'
  authors: []
  citation_count: 0
  full_citation: '>'
  full_text: ">\nInternational Journal of Advanced Technology and Engineering Exploration,\
    \ Vol 9(97)                                 \nISSN (Print): 2394-5443   ISSN (Online):\
    \ 2394-7454 \nhttp://dx.doi.org/10.19101/IJATEE.2021.876002 \n1812 \n \nInternet\
    \ of things (IoT) fusion with cloud computing: current research and \nfuture direction\
    \  \n \nManzoor Ansari*, Syed Arshad Ali and Mansaf Alam  \nDepartment of Computer\
    \ Science, Jamia Millia Islamia, New Delhi, India \n \n \n \nReceived: 20-May-2022;\
    \ Revised: 10-December-2022; Accepted: 12-December-2022 \n©2022 Manzoor Ansari\
    \ et al. This is an open access article distributed under the Creative Commons\
    \ Attribution (CC BY) \nLicense, which permits unrestricted use, distribution,\
    \ and reproduction in any medium, provided the original work is properly \ncited.\
    \ \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n1.Introduction\
    \ \nThe \ninternet \nof \nthings \n(IoT) \nrepresents \na \nrevolutionary concept\
    \ that has become a part of \nmodern society and is generating tremendous \nenthusiasm\
    \ among both the business and academic \ncommunities. IoT, as the next-generation\
    \ technology, \nhas enormous ramifications for many industries [1]. \nAccording\
    \ to analyst predictions, the IoT could reach \n64 billion devices by 2025, constituting\
    \ one of the \nmajor sources of \"Big Data,\" distinguished by \nvolume, value,\
    \ variety, velocity, and accuracy [24]. \nThe IoT is primarily concerned with\
    \ the development \nof an infrastructure that supports fully interoperable \n\
    protocols and software for interconnection and \nintegration.  \n \n \n \n \n\
    \ \n*Author for correspondence \nA system that is embedded with a combination\
    \ of \nsoftware, electronic components, actuators, sensors, \ndetectors, and wireless\
    \ connectivity, which enables \nthem to gather data from these objects can be\
    \ defined \nas the ―IoT‖ [5]. An IoT system has the following \nprominent characteristics\
    \ [6, 7]:  \n IoT is a technological advancement that enables \nobjects to be\
    \ connected to the internet via wired or \nwireless networks so that they can\
    \ communicate \nwith one another. \n A variety of wireless sensor networks are\
    \ available \nfor \nIoT \ndevices, \nincluding \nnear-field \ncommunication (NFC),\
    \ Zigbee, radio frequency \nidentification (RFID), Bluetooth, and Wi-Fi. \n The\
    \ sensors can be connected to various \ntechnologies, \nincluding \nlong-term\
    \ \nevolution \n(LTE), general packet radio service (GPRS), third \ngeneration\
    \ of mobile telephony (3G), and global \nsystem for mobile communication (GSM).\
    \  \nReview Article \nAbstract  \nThe internet of things (IoT) has been a major\
    \ buzzword in recent years, with the potential to connect a huge number of \n\
    devices to the internet and each other. The integration of all of these devices\
    \ and data sources into a cohesive system is \none of the key challenges involved\
    \ in the development of the IoT. Cloud integration is one approach that can be\
    \ used to \nachieve this, and there are several different cloud-based IoT platforms\
    \ available. As consequences, IoT and cloud \ncomputing has drastically changed\
    \ the environment of technological development. A synergistic strategy that combines\
    \ \nthe strengths of these two breakthrough technologies into one package is estimated\
    \ to provide enormous benefits. Despite \nthese advantages, the integration of\
    \ such technologies poses numerous issues and challenges. An in-depth analysis\
    \ of \neach of these technologies is discussed, along with the advantages, challenges,\
    \ and limitations associated with convergent \napproach. The preferred reporting\
    \ items for systematic reviews and meta-analyses (PRISMA) method has been used\
    \ to \nidentify all relevant articles from the literature, and the most relevant\
    \ articles have been included for further analysis. \nThe relevant articles have\
    \ been analysed using the method of the Bibliometric network, such as co-authorship\
    \ analysis, \nterm co-occurrence. Furthermore, taxonomy of IoT-based cloud applications\
    \ has been discussed and quality of service \n(QoS) factors-based analysis for\
    \ each applications domain has been done. In this review, we take a look at some\
    \ of the \nmost popular IoT cloud integration platforms and compare their features\
    \ and capabilities. In addition, we have \ninvestigated a variety of related technologies\
    \ and anticipated future developments. \n \nKeywords \nInternet of things (IoT),\
    \ Cloud computing, Edge computing, Bibliometric analysis, Preferred reporting\
    \ items for \nsystematic reviews and meta-analyses (PRISMA), Real-world applications.\
    \ \n \nInternational Journal of Advanced Technology and Engineering Exploration,\
    \ Vol 9(97)                                 \n1813          \n \n The efficiency\
    \ of an IoT system is largely \ndetermined by three primary components, each of\
    \ \nwhich is crucial to its operation. \no Perception  \no Middle-ware (Edge,\
    \ Fog, and Cloud)  \no Application \n \nNevertheless, cloud technology offers\
    \ virtually \nunlimited storage and system capabilities to address a \nwide range\
    \ of challenges related to IoT. In \nconsequence, the phrase \"cloud of things\"\
    \ (CoT) is \nused to allude the fusion of IoT and cloud computing. \nThe \"CoT\"\
    \ is a paradigm for increasing productivity \nand improving system performance\
    \ that is widely \nused by most industries and manufacturers [8]. \nSeveral researchers\
    \ discussed in their research [9] \nregarding the use of cloud as a platform to\
    \ analyze \nBig Data when data storage and processing are \nrequired. A recent\
    \ empirical study [10] identified \nmany challenges for energy efficient technology\
    \ that \nwill need to be addressed in the future. \n \nWith the advent of the\
    \ IoT, gigantic amounts of data \nare generated in real-time, and this poses a\
    \ major \nconcern for traditional cloud computing network \ntopologies [11]. A\
    \ traditional cloud infrastructure \ncondenses all processing, storage, and networking\
    \ \ninto a limited set of data centers, and the distance \nbetween remote devices\
    \ and remote data centers is \nrelatively wide [12]. This challenge could be \n\
    addressed by edge computing since it provides access \nto computing resources\
    \ that are closer to IoT edge \ndevices and may lead to a new ecosystem for IoT\
    \ \ninnovation [13]. \n \n1.1Background \nA brief introduction to some of the\
    \ most important \naspects and terminology used throughout this study is \nprovided\
    \ in this section. This section is intended to \nhelp the reader understand and\
    \ better comprehend the \ninformation that is presented in each section of the\
    \ \npaper.   \n1.1.1Internet of things (IoT) \nKevin Ashton, a British technology\
    \ pioneer, formed \nthe phrase \"IoT\" in 1999 to represent a system in \nwhich\
    \ physical artifacts are connected to the internet \nusing sensors. A \"thing\"\
    \ can refer to any physical \nentity on the surface of the earth, whether it is\
    \ a \ncommunication device or not. Despite the widespread \nacceptance of the\
    \ IoT concept, no standard definition \nhas been adopted. There are several definitions\
    \ in \nexistence: \"The IoT refers to the prospect of devices \nthat can create,\
    \ exchange, and utilize data without the \nuse of a central computing device,\
    \ where the \nconnectivity of networks and computing capability \ncan be applied\
    \ to objects, sensors, and everyday \nobjects, not to personal computers. \n \n\
    It is stated in the Oxford Dictionary [14]. ―An \nInternet-based architecture\
    \ provides connectivity \nbetween electronic devices embedded in real-world \n\
    objects, enabling them to exchange information‖. \nAccording to the RFID group,\
    \ ―It is a global network \nof \ninterconnected \nobjects \nwith \nstandardized\
    \ \ncommunication protocols that allow them to be \naccessed by a single entity.‖\
    \ \n \nThree-layered architecture of IoT \nIoT architecture comprises mainly three\
    \ layers [15, \n16], namely ―perception layer‖, ―middleware layer‖, \nand ―application\
    \ layer‖, as demonstrated in Figure 1. \nThe middle layer of this architecture\
    \ exists on the \nedge, fog, and cloud computing [1720]. \nPerception layer \n\
    Perception layer senses data from the surrounding via \nactuators and sensors.\
    \ It identifies, gathers, and \nprocesses data and sends it to the network layer.\
    \ It \ndetects other physical parameter in the physical \nenvironment or recognize\
    \ intelligent objects. It also \ncollaborates on local and small-scale networks\
    \ with \nthe IoT node. \nMiddleware \nAs the 'processing layer', the middleware\
    \ is \nresponsible for the analysis, processing, and storage \nof a large amount\
    \ of data obtained from the \nperception layer. It can perform a variety of tasks\
    \ and \nproviding services to the lower layer. Various \ntechnologies \nare \n\
    employed, \nincluding \nhigh-\nperformance computing tools, cloud computing, and\
    \ \ndatabase management systems. Additionally, it \nintroduces a level of abstraction\
    \ for developers as \nwell as users. \nApplication layer \nIt is the responsibility\
    \ of this layer to provide \nspecialized application services to the client. As\
    \ a \nresult, it includes a variety of applications, including \nair quality monitoring,\
    \ smart buildings, precision \nfarming, intelligent cities, and innovative health\
    \ care, \nas well as data integrity, authenticity, and security. \nThis layer\
    \ is intended to enable designing an \nintelligent environment. \n \n \nManzoor\
    \ Ansari et al. \n1814 \n \n \nFigure 1 Three-layered architecture of IoT \n \n\
    1.1.2Cloud computing  \nDuring the last few decades, cloud computing has \ntaken\
    \ on several definitions. As per National Institute \nof Standards and Technology\
    \ (NIST): \"Cloud \ncomputing is a service delivery model that facilitates \n\
    easy, on-demand access to a shared pool of flexible \ncomputing resources that\
    \ can be accessed and \ndelivered on time with a minimum of effort or \nmanagement\"\
    \ [21]. As utility-based computing \nprogresses, it is anticipated that it will\
    \ move to cloud \ncomputing, which has the potential to be a more \nintelligent\
    \ in-service provisioning process. Another \nkey advantage of cloud computing\
    \ is that it reduces \ninformation \ntechnology \n(IT's) \ndependence \non \n\
    fundamental \ninfrastructure \nsettings \n[22]. \nThe \nimplementation \nand \n\
    execution \nof \nscientific \nworkflows involving Big Data requires a synergistic\
    \ \nmodel, according to recent studies [23]. Cloud \ncomputing has suggested the\
    \ following functionality: \nmeasured services, rapid elasticity, scalability,\
    \ multi-\ntenancy, resource pooling, extensive network access \nwith \non-demand\
    \ \nservice \n[2426]. The \ncloud \ncomputing characteristics are shown in Figure\
    \ 2. \n \n \nFigure 2 Cloud computing characteristics \n \nOn-demand self-service\
    \  \nNumerous cloud-based services may be delivered \nwithout involving human\
    \ involvement on the part of \nthe service provider. Most of these services comprise\
    \ \nstorage capacity, database instances, and virtual \nmachine instances. Accessing\
    \ cloud accounts and \nmonitoring services can be done using a self-service \n\
    web interface provided by production organisations. \nAn end-user can provide\
    \ computing resources \nindependently, such as database setting and shared \n\
    International Journal of Advanced Technology and Engineering Exploration, Vol\
    \ 9(97)                                 \n1815          \n \nstorage when required,\
    \ without any interference from \nthe IT manager of the provider. \n \nExtensive\
    \ network access  \nCloud services may be accessed by a variety of user \napplications\
    \ on the network. A local area network \n(LAN) or the internet in the setting\
    \ of a private cloud \nare both viable choices, even though the enterprise \n\
    prefers robust, wide-bandwidth networks. The quality \nof service (QoS) of cloud\
    \ computing is heavily \ndependent on network capacity and latency. It has \n\
    been conventional to use a variety of network-\naccessible technologies to make\
    \ thin and dense \nheterogeneous business solutions more accessible \n(such as\
    \ smartphones, laptops, workstations, and \npersonal computers). \n \nMulti-tenancy\
    \ and resource pooling  \nMulti-tenant environments can be accommodated by \n\
    cloud \ncomputing \nresources. \nWith \nnumerous \ntenancies, a single software\
    \ or physical infrastructure \ncan be used by a variety of clients, all while\
    \ ensuring \nthe privacy and confidentiality of their data. In \nmultitenant systems,\
    \ different services, for instance \nmemory, processing capability, storage space,\
    \ and \nnetwork resources, are allocated to several users in \naccordance with\
    \ their individual needs (virtual \nresources are assigned or moved dynamically\
    \ in \nresponse to the requirements of each user). The word \n\"resource pooling\"\
    \ refers to the sharing of physical \nassets among multiple clients. \n \nThe\
    \ provider's resource pool should be sufficiently \nlarge and diverse to serve\
    \ a variety of consumer \nneeds while maintaining economic spectrum. As a \nresult\
    \ of resource pooling, the performance of \nmission-critical industrial applications\
    \ should not be \nadversely affected. Scheduling resources is a critical \npart\
    \ of cloud computing. According to the study [27], \nthe present state of task\
    \ scheduling methodologies is \nbased on a host of different scheduling parameters.\
    \ \nRapid elasticity and scalability  \nIt is feasible to scale cloud computing\
    \ services to \nmeet the demands of a business. It is an essential \naspect of\
    \ cloud computing. There are no penalties \nassociated with customizing costs,\
    \ efficiency, or \navailability. It enables manufacturing companies to \nrapidly\
    \ produce and deliver any cloud computing \nresource. This functionality can be\
    \ utilised for \nstorage, \nvirtualization \nsoftware, \nor \nmarketing \nassistance.\
    \ Scalability is more liberal and pragmatic. \nScalability dynamically adds or\
    \ removes resources to \nmeet changing application requirements within the \n\
    network's constraints. \nMeasured service \nCloud computing applications are quantified,\
    \ and \nproducing businesses pay for what they use. The \nauthors of the study\
    \ [28] emphasised the challenges \nencountered by researchers working in bioinformatics\
    \ \nin terms of planning their research efficiently and \neffectively utilising\
    \ cloud computing. In cloud \ntechnologies, resource consumption is effectively\
    \ \nmanaged and optimized automatically by utilizing \nmeasurements at many levels\
    \ of abstraction, such as \nnetwork bandwidth, computing power, storage, and \n\
    the number of active users. Both the supplier and the \nconsumer's resource requirements\
    \ may be monitored, \nquantified, and communicated openly. \n1.1.3Edge computing\
    \ technology \nEdge computing is a data networking paradigm that \nstresses \n\
    minimising \nlatency \nand \nbandwidth \nconsumption by processing as near to\
    \ the data source \nas feasible [29]. According to [30], \"Edge computing \nis\
    \ a distributed computing paradigm that brings \ncomputation and data storage\
    \ closer to the location \nwhere it is needed, to improve response times and \n\
    save bandwidth.\" \n \nRole of edge computing in IoT technology \nIn IoT technology,\
    \ edge computing transforms the \ndata that is managed, processed, and distributed\
    \ by \nmillions of IoT devices [31]. With the explosive \ngrowth of internet-enabled\
    \ technologies, the IoT and \nemerging technologies requiring real-time cloud\
    \ \nservices tend to support sophisticated computing \nsystems, the IoT and emerging\
    \ technologies requiring \nreal-time cloud services tend to support sophisticated\
    \ \ncomputing systems [32]. With edge computing, data \nis evaluated on the edge\
    \ of the local network before \nreaching the fog and the cloud for rapid, reliable,\
    \ \nconnectivity-independent, and scalable IoT Edge \nprocessing. Figure 3 depicts\
    \ the IoT, edge, fog, and \ncloud computing architecture. \n1.1.4Fusion of IoT\
    \ and cloud technology \nThe IoT consists of a network of physical objects that\
    \ \nare connected to the internet and are equipped with \nthe ability to collect,\
    \ exchange, and use data. In cloud \ncomputing, resources are delivered over the\
    \ internet \nas a service. With the integration of IoT and cloud \ncomputing,\
    \ new applications have been developed \nthat have the potential to revolutionize\
    \ the way we \nlive and work. In addition, the integration of the IoT \ninto the\
    \ cloud is a natural evolution of the \ntechnology. The cloud provides the perfect\
    \ platform \nfor storing and analyzing the vast amounts of data \nproduced by\
    \ IoT devices. In addition, it provides \nreal-time data processing and analytics,\
    \ which is \nessential \nfor \napplications \nsuch \nas \npredictive \nManzoor\
    \ Ansari et al. \n1816 \n \nmaintenance and energy management. In the last \n\
    decade, the IoT and cloud-based services have \nevolved \nand \nmatured \nindependently\
    \ \non \nboth \ncontinents. Due to their unique characteristics, these \ntechnologies\
    \ are attractive to researchers and have \nmultiple applications. The integrated\
    \ paradigm does \nnot have a well-known term in the scientific \ncommunity. In\
    \ the literature, other general terms have \nbeen discovered, including fusion\
    \ of internet of \neverything and cloud (Cloud of Everything), IoT \nCloud, CoT\
    \ and web of things (WoT) [33]. \n \n \nFigure 3 IoT, Edge, Fog, and cloud architecture\
    \ \n \nA key component of the IoT is its capacity to utilize \nvirtually unlimited\
    \ amounts of cloud computing \nresources and capacity (such as computation \n\
    capabilities, \nstorage \ncapabilities, \nand \nenergy \nefficiency) \nto \nhelp\
    \ \novercome \ntechnological \nlimitations. A cloud-based computing strategy is\
    \ an \neffective tool for preserving data as well as for use in \na variety of\
    \ applications As a contrast, cloud \ncomputing could influence the IoT by introducing\
    \ \nnew applications that address distributed real-world \nproblems and by allowing\
    \ new installations that can \nbe applied to various real-world scenarios [34].\
    \ \n \nDue to its limited and vigorous capabilities, the IoT \ncontains devices\
    \ with minimal processing power and \nstorage capacity in comparison with the\
    \ numerous \ncomplex tasks that need to be completed. These \ndevices may serve\
    \ as data providers and transfer data \nfor processing and storage directly to\
    \ the cloud [35, \n36].  \n \nIn the cloud computing environment, applications\
    \ \nand objects communicate over an intermediary layer \nthat hides the functionality\
    \ and complexity required \nto implement them. This strategy will dramatically\
    \ \nimpact applications that address current challenges \nwith gathering data,\
    \ integration, and distribution in a \nmulti-cloud context. \nCurrent research\
    \ on the integration of IoT with cloud \ncomputing \nfocuses \non \nallowing \n\
    real-world \napplications including sustainable buildings, smart \ncities, connected\
    \ vehicles and industrial automation. \nThe use of IoT devices and sensors in\
    \ conjunction \nwith cloud-based analytics and decision-making \nmodels offer\
    \ the promise of significant improvements \nin efficiency, safety, and quality\
    \ of life.  \n \nThe future direction of research on IoT and cloud \ncomputing\
    \ integration will be driven by the need to \naddress challenges including data\
    \ privacy, security, \nscalability, energy efficiency, and interoperability. In\
    \ \naddition, there is a need for further research into how \nbest to exploit\
    \ the unique capabilities offered by this \ntechnology combination to create new\
    \ applications \nthat deliver real value to user. \n \nArchitecture for cloud-based\
    \ IoT \nA \ncloud-based \nIoT \narchitecture \nmust \nbe \naccomplished of supporting\
    \ a wide range of devices \nand sensors, as well as the data they acquire. It\
    \ must \nbe able to handle the data generated by the devices in \nreal-time and\
    \ provide the necessary processing and \nanalysis. The architecture must also\
    \ be able to \nsupport the security and privacy requirements of the \nIoT applications\
    \ [37, 38]. An IoT-based cloud \necosystem is composed of three layers: the physical\
    \ \nInternational Journal of Advanced Technology and Engineering Exploration,\
    \ Vol 9(97)                                 \n1817          \n \nlayer, the networking\
    \ layer, and the application layer. \nThe bottom layer (the physical layer) is\
    \ responsible \nfor collecting the data required by the next layer, that \nis,\
    \ the network layer, from their surroundings. A \nvariety of interesting services\
    \ are accessed by the \nnetwork layer from the physical layer. Figure 4 \ndemonstrates\
    \ the cloud-based IoT infrastructure. \n \n \nFigure 4 Cloud of things architecture\
    \ \n \n1.2 Challenges of the domain \nAfter a comprehensive analysis of the included\
    \ \nliterature, we revealed a lot of emerging research \nchallenges in the field\
    \ of integration of IoT and \ncloud. However, here we are going to mention the\
    \ \nmost cited one. Since, the challenges of the IoT cloud \ndomain are mainly\
    \ related to data gathering, \ncommunication, and storage. The data collected\
    \ by \nvarious IoT devices need to be transmitted to the \ncloud for analysis\
    \ and decision-making. This requires \nefficient and reliable communication protocols\
    \ \nbetween the devices and the cloud. The data collected \nby IoT devices also\
    \ need to be stored securely in the \ncloud. Moreover, throughout this study,\
    \ we cited \nsome more such challenges in section 7. \n \n1.3 Research motivation\
    \ \nAlthough this field is still in a developmental stage, \nresearchers are working\
    \ on integrating domain, \nsecurity, and QoS to develop a more secure and \nefficient\
    \ system. Meanwhile, we investigated a large \nnumber of relevant studies on this\
    \ domain. However, \nwe could not find extensive research in the domain of \n\
    integration of IoT and cloud. Although a countable \nset of researchers working\
    \ on this domain, they have \nrevealed some unavoidable research gaps regarding\
    \ \nthis field. Therefore, more research on this field is the \npressing need\
    \ of the hour. This study explores the \ncurrent state of the art in this domain.\
    \ \nThe motivation for the review of the integration of \nIoT and cloud computing\
    \ are as follows. \n With the vast amount of data produced by IoT \ndevices,\
    \ it is becoming increasingly difficult to \nmanage and analyze this data effectively\
    \ without \nthe use of cloud computing. So, the need for better \ndata management\
    \ and analysis motivates me to \nexplore in this direction.  \n By storing data\
    \ in the cloud, it is feasible to utilise \nthe security features provided by\
    \ cloud service \nproviders. So, the need to improve security is \nanother motivation\
    \ for me to integrate these two \ntechnologies. \n Any IoT-device-reliant application\
    \ must have the \ncapacity to dynamically scale up or down as \nneeded. In this\
    \ regard, increasing scalability is one \nof the factors motivating me to pursue\
    \ this \npathbreaking technology. \n \n1.4 Research objectives \nThe IoT and cloud\
    \ computing are two new \ntechnologies that are gaining traction in a number of\
    \ \ndifferent industries. There is a growing need for \neffective integration\
    \ (IoT and cloud) of these \ntechnologies \nfor \nimproved \ndecision-making,\
    \ \nincreased \nefficiency, \nand \ndecreased \ncosts. \nNonetheless, current\
    \ research in this field is still in its \ninfancy. In this article, first, we\
    \ will discuss a \nsummary of the current literature on IoT and cloud \nintegration.\
    \ We will then identify some key \nchallenges, opportunities, and future directions\
    \ for \nresearch in this area. Three broad categories of \nresearch are currently\
    \ being conducted on IoT and \ncloud integration: (1) Development of frameworks\
    \ \nand platforms for IoT and cloud integration; (2) \nDesign and implementation\
    \ of applications using IoT \nand \ncloud \ntechnologies; \n(3) \nEvaluation \n\
    and \nManzoor Ansari et al. \n1818 \n \ncomparative analysis based on various\
    \ parameters of \nIoT and cloud systems. In terms of frameworks and \nplatforms\
    \ for IoT and cloud integration, there has \nbeen considerable work on developing\
    \ middleware \nsolutions that can enable seamless interaction \nbetween these\
    \ two technologies. Some notable \nexamples include the Eclipse Smart Home platform\
    \ \n(https://www.eclipse.org/), IBM Watson IoT platform \n(https://www.ibm.com/),\
    \ and Microsoft Azure IoT \nSuite (https://azure.microsoft.com/). \n \nThe objectives\
    \ of this research article are follows: \n To present an overview of current\
    \ research on the \nintegration of IoT and cloud computing. \n To compare and\
    \ analyze the existence literature \nassociated with IoT cloud integration.  \n\
     To \nidentify \nand \ndiscussed \nthe \nchallenges \nassociated with IoT cloud\
    \ integration.  \n To \nidentify \nand \nanalyze \nthe \nopportunities \nassociated\
    \ with IoT cloud integration in many real-\nworld applications.  \n To identify\
    \ future research directions in this area.   \n \n1.5 Research questions \nAs\
    \ this study aims to provide a survey on cloud and \nIoT integration, the following\
    \ research questions are \nframed to cover the related concepts, applications,\
    \ \nand tools/techniques. \n \nRQ1.How many research publications have been \n\
    done in the field of IoT and cloud integration spread \nover the years? \nRQ2.What\
    \ are the latest research trends with IoT and \ncloud computing integration? \n\
    RQ3.What are the potential uses of IoT-based cloud \ntechnology in real-world\
    \ applications? \n \nRQ4. Which are the most appropriate IoT-based \ncloud solutions,\
    \ middleware technologies, and \nplatforms? \nRQ5.What are the current limitations\
    \ and unresolved \nresearch problems with the integration of IoT and \ncloud services?\
    \ \nRQ6.What are the major suggestions for future \nresearch for IoT and cloud\
    \ approaches that work \ntogether? \n \n1.6 Systematic review process \nTo carry\
    \ out a systematic review of the literature on \nIoT cloud integration, the following\
    \ steps need to be \nfollowed: \nStep 1. The first step in the systematic review\
    \ \nprocess is to identify the research question. The \nquestion should be specific\
    \ and answerable and \nshould focus on the effects of a particular \nintervention\
    \ or exposure.  \nStep 2. The next step is to identify relevant studies. \nStudies\
    \ can be identified through a variety of sources, \nincluding \ndatabases, \n\
    literature \nreviews, \nand \nconference proceedings. \nStep 3. The third step\
    \ is extracting data from high-\nquality and valid studies from the collection-related\
    \ \nliterature in step 2. \nStep 4. The fourth step is to analyze the data that\
    \ has \nbeen extracted. This analysis should be performed in \na systematic and\
    \ unbiased manner.  \nStep 5. The data extracted in step 4, we analyzed \neach\
    \ category of data and outcome of this step came \nto the final step 6. \nStep\
    \ 6. The final step is to write a report of the \nfindings. This report should\
    \ be clear, concise, and \nshould provide a synthesis of the evidence that was\
    \ \ngathered during the systematic review process. \n \nIn general, the structure\
    \ of this paper can be \nsummarized as follows this article begins with an \n\
    introductory section 1 which discusses some of the \nbasics of the IoT, cloud\
    \ computing, edge computing, \nand their architectures. In addition, the challenges,\
    \ \nmotivations, and objectives are described in this \nsection.  \n \nSection\
    \ 2 reviews the current state of IoT and cloud \ntechnologies. A comparative analysis\
    \ of the existing \nliterature is also provided in this section.  \n \nIn section\
    \ 3, we provide an overview of the research \nmethodology, which includes the\
    \ search query, \nselection criteria, and process flow. Moreover, \nliterature\
    \ trends, distribution of literature, and \nbibliometric analysis are described\
    \ in this section. \nWe analyze IoT and cloud technology employing \nseveral resources\
    \ following preferred reporting items \nfor systematic reviews and meta-analyses\
    \ (PRISMA) \nstandards. An overview of the systematic process \nflow adopted for\
    \ this study is presented in Figure 5. \n \nIn section 4, the taxonomy of various\
    \ real-world \napplications and QoS comparison are described.  \n \nSection 5\
    \ discusses existing middleware technologies \nand cloud platforms are discussed.\
    \ A discussion of a \nvariety of benefits and challenges related to CoT is \n\
    provided in sections 6 and section 7.  \n \nDiscussion of IoT cloud integration\
    \ discusses in \nSection 8. Finally, section 9 summarizes the findings \nof this\
    \ study and provides a roadmap for the future. \nInternational Journal of Advanced\
    \ Technology and Engineering Exploration, Vol 9(97)                          \
    \       \n1819          \n \n \nFigure 5 Systematic process flow \n \n2.Related\
    \ work  \nOver the past decade, a number of studies have been \nconducted to provide\
    \ insight into the topic of IoT and \ncloud computing solutions. These studies\
    \ helped to \naddress the emerging concern. Our study has been \nenriched with\
    \ comprehensive literature reviews \ncovering a variety of disciplines in this\
    \ area of \nresearch.  \n \nThe articles [3941] considered recent attempts to\
    \ \nintegrate cloud computing into a range of IoT \nscenarios and applications.\
    \ An extensive review of \nthe literature was conducted by Botta et al. [42] \n\
    where they explored the complementary aspects of \nIoT and cloud, and the factors\
    \ which drive their \nintegration into various infrastructures. The recent \n\
    acceptance of the cloud-based IoT paradigm has \nopened a wide variety of new\
    \ applications, which are \npresented along with the major research challenges.\
    \ \nFurther analysis of these challenges led to the \ndevelopment of research\
    \ directions. Additionally, by \ncomparing its numerous features, platforms, and\
    \ \naccessible operations, they highlighted problems and \nfuture research areas\
    \ in this domain. \n \nAn analysis of cloud platforms, cloud infrastructures,\
    \ \nand middleware technologies for the IoT has been \nconducted by Diaz et al.\
    \ [43]. A wide array of data \nanalysis techniques, approaches, and issues are\
    \ also \naddressed, as well as various research challenges. \n \nDang et al. [44]\
    \ aim to investigate the scope of IoT \napplications, implementations in the health\
    \ sector, \nand evaluations of cloud-based IoT platforms that \nhave been developed\
    \ over the last year. The goal of \nthis research is to explore how developing\
    \ \ntechnologies including the cloud, wireless networks, \nBig Data, and wearable\
    \ devices may be utilised to \nenhance the efficiency and effectiveness of healthcare\
    \ \nby introducing health policies for the IoT and eHealth \nservices around the\
    \ world. Several security and \nprivacy risks associated with the IoT are also\
    \ \ndiscussed in depth, including issues, threats, and risk \nfactors. \nA \n\
    subsequent \nIoT-based \nhealthcare \ndevelopment is discussed in terms of analytical\
    \ \nframeworks that can be used to identify and evaluate \nsecurity threats, mitigation\
    \ strategies, and limitations. \nAs part of their discussion on the IoT, Malik\
    \ and Om \n[45] examined the platforms, devices, and available \nsolutions. The\
    \ IoT layer architectures were compared \nto the internet protocol (IP) layer\
    \ as well as its \nqualities. Additionally, a comparison of IoT and \ncloud technology\
    \ has been conducted. Moreover, a \nframework for integrating IoT with cloud services\
    \ \nhas been developed utilizing 6LowPanel and \narchitecture. Cloud computing\
    \ has been discussed, as \nconstrained application protocol (CoAP). However, \n\
    for standardized cloud and IoT integration to reach its \nfull potential, additional\
    \ studies in other sectors are \nrequired. \n \nAmairah et al. [46] examined the\
    \ reference \narchitectures and definitions of IoT and cloud \ncomputing, as well\
    \ as the associated security \nconcerns \nand \nsolutions. \nAdditionally, \n\
    future \ndirections were studied by evaluating the most often \ncited researchers.\
    \ Additional study is recommended \nto examine and address integration system\
    \ security \nvulnerabilities as new research areas in this domain. \nDuring an\
    \ extensive study conducted by Atlam et al. \n[47] on the integration of cloud\
    \ technologies with IoT \nplatforms and compare IoT and cloud technologies. \n\
    Six main benefits have been discussed that are related \nto \nIoT \ncloud \nintegration.\
    \ \nCloud-based \nIoT \narchitecture has been proposed in this study. In \naddition,\
    \ various IoT-cloud applications have been \npresented. Authors have studied the\
    \ seven main \nchallenges of cloud-based IoT integrations. \n \n The study presented\
    \ by Cavalcante et al. [48] \ndiscussed an overview of the current development\
    \ \nand investigations of IoT cloud integration and \nManzoor Ansari et al. \n\
    1820 \n \ndiscusses future directions. Moreover, four main \ntypes have suggested\
    \ (i) IoT cloud architecture (ii) \nplatforms (iii) framework, and (iv) middle-ware\
    \ \ntechnologies. Also, different challenges have been \ndiscussed in this study.\
    \ These challenges are (i) \nstandardizing IoT products, data, and services \n\
    delivered over the cloud; (ii) \nenabling IoT \ndevices/applications to efficiently\
    \ utilize cloud \nresources; (iii) Handling enormous amounts of data \nin \nreal-time;\
    \ \n(iv) \nProviding \ncontext-specific \ninformation; (v) Assuring the security\
    \ and privacy of \ndata by providing effective solutions (vi) removing \nthe large\
    \ degree of variability inherent in both IoT \nand cloud settings; (vii) Considering\
    \ concerns about \nflexibility and dependability; (viii) assist for cloud-\nbased\
    \ IoT developing and maintaining software, and \n(ix) offering virtualization\
    \ paradigms for devices. \nTable 1 illustrates a study of the existing research\
    \ on \nthe convergence of IoT and cloud computing, \nincluding the contributions\
    \ and limitations of the \nresearch publications. \n \nTable 1 Comparative study\
    \ of existing literature on IoT and cloud computing \n \n \n \n \n \n \n \nReference\
    \ \nResearch article \nMain contributions \nLimitations \nBotta et al. [42]  \n\
    ―Integration \nof \nCloud \nComputing and Internet of \nThings: A Survey‖ \n\
    \ IoT \nand \ncloud \ntechnology \nare \ndiscussed, \nas \nwell \nas \ntheir \n\
    complementary modes of operation, \napplications, challenges, platforms, \nand\
    \ current projects. \n  Inadequacy of open service \nplatforms \nand \nmulti-\n\
    connectivity.     \nDíaz et al. [43] \n―State-of-the-art, \nchallenges, and open\
    \ issues \nin \nthe \nintegration \nof \nInternet \nof \nthings \nand \ncloud\
    \ computing‖ \n Analyse the underlying platforms, \ninfrastructure, middleware,\
    \ integration \napproach, data analytics techniques, \nopen issues, challenges,\
    \ and future \ndevelopments. \n Lack of awareness of other \nrelevant technologies.\
    \ \nDang et al. [44] \n―An overview of Internet \nof Things (IoT) and Cloud \n\
    Computing \nin \nthe \nhealthcare sector‖ \n \n Performs \nan \nanalysis \nof\
    \ \nIoT \ncharacteristics and applications in \nhealthcare as well as market trends.\
    \ \n Discuss \ndifferent \nthreats, \nvulnerabilities, \nattacks, \nsecurity\
    \ \nmodels, government policies, as well \nas challenges affecting healthcare.\
    \ \n Uncovering \nother \nstandard \napplications. \nAazam et al. [8] \n―Cloud\
    \ \nof \nthings: \nIntegrating \ninternet \nof \nthings \nand \ncloud \ncomputing\
    \ and the issues \ninvolved‖ \n CoT and future directions. \n Also presenting\
    \ Key challenges of \nCoT. \n A dearth of discussion on the \nmany types of IoT\
    \ and their \nassociated services. \nMalik and Om [45] \n―Cloud \ncomputing \n\
    and \ninternet \nof \nthings \nintegration: \nArchitecture, \napplications, issues,\
    \ and \nchallenges‖ \n To discuss applications, challenges, \nand future directions\
    \ of integration \ncomponents. \n Inadequate standardisation of \nthe CoT. \n\
    Atlam et al. [47] \n―Integration \nof \ncloud \ncomputing with Internet of \n\
    things: \nchallenges \nand \nopen issues‖ \n IoT-based \ncloud-based \narchitecture\
    \ \nand applications. \n Also demonstrating the need for IoT-\nenabled cloud\
    \ services. \n Inadequate testing of cloud-\nbased IoT applications. \nAmairah\
    \ et al. [46] \n―Cloud computing \nand internet \nof \nthings integration systems:\
    \ \nA review‖ \n These technologies are reviewed in \nterms of reference architectures\
    \ and \ndefinitions as well as security concerns \nand proposed solutions. \n\
     A dearth of research into the \nsecurity implications of these \nCoT. \nCavalcante\
    \ \net \nal. \n[48] \n―On \nthe \ninterplay \nof \nInternet of Things and \nCloud\
    \ \nComputing: \nA \nsystematic mapping study‖ \n Oversight of IoT and cloud\
    \ integration \nresearch and development. \n The integration challenges and future\
    \ \ndirections are also discussed. \n Lack of research on other \nsignificant\
    \ issues. \nInternational Journal of Advanced Technology and Engineering Exploration,\
    \ Vol 9(97)                                 \n1821          \n \n3.Research methodology\
    \ \n3.1Search query \nTo identify IoT and cloud computing research \npublications,\
    \ \nwe \nanalyzed \nscholarly \ndatabases \nincluding Google Scholar, database\
    \ and logic \nprogramming (DBLP) computer science database, \nweb of science (WOS),\
    \ Science Direct, and \nIEEEXplore. The title field was searched in the \ndatabases\
    \ using the search words ((\"IoT\" OR \n\"Internet of Things\") and (\"Cloud Computing\"\
    )). The \nsearch string along with the database is shown in \nTable 2. \n \nTable\
    \ 2 A database-specific search string \nDigital library \nSearch string \nGoogle\
    \ Scholar \nTitle :( (\"IoT\" OR \"Internet of Things\") \nAND (\"Cloud Computing\"\
    )). \nScience direct \nTitle: ((\"IoT\" OR \"Internet of Things\") \nAND (\"Cloud\
    \ Computing\")) \nIEEEXplore \n(\"Document Title”: IoT OR \"Document \nTitle”:\
    \ \nInternet \nof \nThings) \nAND \n\"Document Title”: Cloud Computing \nScopus\
    \ \nTITLE (\"IoT\" OR \"Internet of Things\" \nAND \"Cloud Computing\") \nSpringer\
    \ Link \n((\"IoT\" OR \"Internet of Things\") AND \n(\"Cloud Computing\")) \n\
    ACM \n [[Title: \"IoT\"] OR [Title: \"internet of \nthings\"]] AND [[Title: \"\
    cloud\"] OR \n[Title: \"cloud computing\"]] \nDBLP \nComputer \nScience \n((\"\
    IoT\" OR \"Internet of Things\") AND \n(\"Cloud Computing\")) \n \n3.2Selection\
    \ criteria \nFrom search results obtained from seven databases, \nrelevant papers\
    \ are selected and screened based on \nthe eligibility criteria. Various inclusion\
    \ and \nexclusion criteria are incorporated into these criteria. \nThis systematic\
    \ review emphases on the fusion of \nIoT and cloud technology as can be seen from\
    \ the \ninitial search query. Therefore, studies related to IoT-\ncloud-based\
    \ real-world applications will be included. \nThe inclusion and exclusion criteria\
    \ for this \nsystematic review are outlined in Table 3. After \napplying these\
    \ inclusion and exclusion criteria to the \ninitial search results from the seven\
    \ databases, 63 \nstudies were finally identified for further analysis. \n \n\
    3.3Process flow   \nAs seen in Figure 6, the process of identifying and \nselecting\
    \ appropriate studies is depicted.  To identify \npapers regarding IoT and cloud\
    \ convergence, several \nelectronic databases (Google Scholar, Science Direct,\
    \ \nIEEEXplore, DBLP Library of Computer Science, \nand WOS) are investigated.\
    \ Then, the refining \nprocess was used to determine whether or not to \ninclude\
    \ and exclude the following requirements, \nwhich are listed in Figure 6.  \n\
    \ \nWithout any further adjustment of the search \nparameters, the combined databases\
    \ yielded 1239 \narticles. A total of 592 duplicate articles were found \nduring\
    \ the identification phase. Apart from duplicate \narticles, we are left with\
    \ 647 articles for the screening \nphase. We have identified 348 articles that\
    \ are \nirrelevant to our domain literature during the \nscreening process. Apart\
    \ from 348 articles, we have \n299 articles based on real-world applications.\
    \ We \nexcluded 129 articles from the proposed taxonomy \nsince these articles\
    \ lack experimental evaluations or \ncomparisons of their approaches. Except for\
    \ 129 \narticles, 170 experimental evaluations based on the \nproposed taxonomy\
    \ are explored. And finally, we \nincluded only the best articles for our study,\
    \ which \nare the articles that are selected by the expert panel. \nWith the exclusion\
    \ of all irrelevant, duplicate, and \nun-evaluated articles from our study, we\
    \ have a total \nof 63 included papers published between 2015 and \narticles.\
    \ Following the refining process, 63 research \npublications were chosen for final\
    \ evaluation. These \narticles 2022, and all research articles, reviews, \nconference\
    \ proceedings and book chapters were \nwritten in English. These 63 articles cover\
    \ IoT and \ncloud computing research, with some focusing on the \nconvergence\
    \ of IoT and cloud technology, while \nothers focus on CoT platforms, CoT applications,\
    \ the \nadvantages and problems of CoT, architectures, and \nmiddleware technologies.\
    \ The PRISMA standards \nguide this research, the most used reporting tools for\
    \ \nsystematic reviews and meta-analysis [49, 50]. \n \n3.4Literature trend  \n\
    Over the years, IoT and cloud computing experienced \naccelerated and autonomous\
    \ mushroom growth, with \nresearchers striving toward seamless incorporation.\
    \ \nNumerous academics have conducted comprehensive \nreviews of this field's\
    \ affluent and eloquent literature. \nThe popularity of both technologies, as\
    \ determined \nby Google search patterns, is shown in Figure 7. \nFigure 8 illustrates\
    \ the growth trend of IoT and cloud \ncomputing in Google search from 2015 to\
    \ 2022. \nFigure 9 illustrates the analysis and classification of \n63 research\
    \ articles obtained from different databases \nin accordance with the publication\
    \ year of the \narticles. \n \nManzoor Ansari et al. \n1822 \n \n \nFigure 6 PRISMA\
    \ data flow diagram \n \nTable 3 Inclusion and exclusion criteria for systematic\
    \ literature review \n \n \n \nInclusion criteria (IC) \nExclusion criteria (EC)\
    \ \nIC1     Papers that incorporate IoT and cloud integration. \nEC1       Papers\
    \ that are duplicates. \nIC2     Papers that focus on various real-world applications.\
    \ \nEC2       Papers that are irrelevant to the applications domain. \nIC3   Papers\
    \ that provide information regarding QoS factors \n(such as availability, security,\
    \ reliability, and latency). \nEC3      Papers that are not related to the proposed\
    \ taxonomy. \nIC4     Papers that provide clear details about middleware, \ntools,\
    \ and platforms. \nEC4   Papers that are secondary studies (e.g., editorial, \n\
    erratum, retracted, short survey, articles in press, tutorials, \nNote, Letter,\
    \ Data paper and posters) \nIC5     Papers published in the span of seven years\
    \ from 2015 \nto 2022. \nEC5      Papers that are not written in the English language.\
    \ \nInternational Journal of Advanced Technology and Engineering Exploration,\
    \ Vol 9(97)                                 \n1823          \n \n \nFigure 7 As\
    \ per google research trends (a comparison of IoT and cloud services) \n \n \n\
    Figure 8 Google research trends (comparative analysis of academic conference publications\
    \ worldwide on IoT and \ncloud technology) \n \n \nFigure 9 CoT-related research\
    \ papers published by year \n \n3.5Distribution of research documents  \nA preliminary\
    \ analysis indicated that after the \nremoval of book reviews, encyclopedias,\
    \ and \neditorial materials, 63 papers were left, of which 55% \nwere research\
    \ articles, 30% were conference papers, \n7% were major reviews, and 8% were book\
    \ chapters. \nThe percentage distribution of research document \ntypes is shown\
    \ in Figure 10. Furthermore, the dataset \nassesses the research publications\
    \ quality. Articles \nthat have been published in reputable journals are \nManzoor\
    \ Ansari et al. \n1824 \n \nregarded to be high-quality research articles. Figure\
    \ \n11 illustrates the distribution of articles by the \nreputable publications\
    \ who published them. IEEE \npublishes 26% of articles, Springer publishes 17%,\
    \ \nACM, Elsevier and Hindawi publishes 7%, 12%, and \n10% of articles, respectively\
    \ and the remaining 28% \nof \narticles \nare \npublished \nin \ndifferent \n\
    other \npublications. Figure 12 shows a comparison of the \nyear-by-year distribution\
    \ of articles by publishers. \n \n \nFigure 10 The distribution of research documents\
    \ \n \n \nFigure 11 Distribution of papers according to publishers \n \n \nFigure\
    \ 12 An analysis of the distribution of papers by publisher according to year\
    \ \nInternational Journal of Advanced Technology and Engineering Exploration,\
    \ Vol 9(97)                                 \n1825          \n \n3.5.1Bibliometrics\
    \ analysis  \nBased on the string (\"IoT\" OR \"Internet of things\") \nand (\"\
    Cloud\" OR \"Cloud Computing\"), which is \napplied on the title field. In the\
    \ analysis of the \nrelevant articles, the Bibliometric network method \nwas \n\
    applied, \nsuch \nas \ncitation \nanalysis \n(or \nbibliographic coupling), co-authorship\
    \ analysis, co-\noccurrence analysis [5154]. This study built the \nnetwork,\
    \ \noverlay \nvisualizations, \nand \ndensity \nvisualization to visualize bibliometric\
    \ networks using \nVOSviewer [55], an open-access tool. \n3.5.1.1 Network, overlay,\
    \ and density visualization \nanalysis for author \nA visual representation of\
    \ the author's co-authorship \nnetwork can be seen in Figure 13, which covers\
    \ all of \nthe articles compiled for this research concerning IoT \nand cloud\
    \ services. A different author's name is \nrepresented by each circle in Figure\
    \ 13.  \n \nThe diameter of the circle indicates how many \narticles each author\
    \ has authored on this subject. In \ngeneral, the more prominently the authors\
    \ appear \nnext to one another in the visualisation, the more \nstrongly they\
    \ are associated bibliographically. Thirty-\none clusters have appeared in the\
    \ author’s network \nvisualization analysis, and each cluster has different \n\
    authors. The red cluster, which is shown in Figure \n14, presents highest co-authorship\
    \ that contain \ntwenty-six authors. Similarly, the second-highest co-\nauthorship\
    \ shows in the green cluster, which consists \nof twenty-two authors who have\
    \ been working \ntogether \nshown \nin \nFigure \n15 \n(a). \nDensity \nvisualization\
    \ per year publication depicts in Figure \n15 (b).  \n3.5.1.2 Network, overlay,\
    \ and density visualization \nanalysis for content \nThe visualization of content\
    \ co-occurrence networks \nis presented in Figure 16 (a). The network shown in\
    \ \nFigure 16 (a) symbolizes a keyword by each circle. \nThe diameter of a circle\
    \ represents the number of \narticles that have the phrase in their keywords.\
    \ There \nare nine clusters created from the terms, four of \nwhich are particularly\
    \ significant.  \n \nThe keywords are then grouped into nine clusters \nbased\
    \ on the most frequent terms. A red cluster can \nbe considered to encompass terms\
    \ related to IoT \ntechnology, \ncloud, \ncloud \nenvironment, \ncloud \nplatform,\
    \ edge cloud, IoT application, IoT device, \nIoT service, and things application.\
    \ The green cluster \nconsists of cloud IoT, Internet, and thing terms. The \n\
    blue cluster is more related to IoT cloud and \ninnovative city, while the yellow\
    \ and purple cluster \nfocuses on cloud computing and industrial Internet. \n\
    Figure 16 (b) and Figure 16 (c) show overlay and \ndensity visualization analysis.\
    \ \n \n \nFigure 13 Network visualization analysis for author \nManzoor Ansari\
    \ et al. \n1826 \n \n \nFigure 14 Network visualization analysis for highest co-authorship\
    \ \n                                             \n \n \n \n \n(a)           \
    \                                                                            \
    \     (b) \nFigure 15 (a) Overlay and (b) Density visualization analysis for author\
    \ \n \n  \n \n                                              (a)              \
    \                                                                 (b) \nInternational\
    \ Journal of Advanced Technology and Engineering Exploration, Vol 9(97)      \
    \                           \n1827          \n \n \n                         \
    \                                               (c) \nFigure 16 (a) Network, (b)\
    \ Overlay and (c) Density visualization analysis for content \n \n4.Taxonomy of\
    \ IoT-cloud applications \nA technical review of selected IoT-based cloud \napplications\
    \ is presented in this section, in \naccordance with the systematic review process\
    \ used \nin the existing studies. There are many types of IoT \ncloud applications,\
    \ but some of the most common are \nthose that allow for remote monitoring and\
    \ control of \ndevices; data collection and analysis, and platform \nfor deploying\
    \ IoT applications. \n \nIn Figure 17 a taxonomy of IoT-cloud applications is\
    \ \ndepicted, which includes applications related to \nhealthcare, environment,\
    \ agriculture, smart cities, and \nindustry [56]. To make the IoT-cloud applications\
    \ \nmore efficient and effective in real-life deployments, \nseveral constraints\
    \ may need to be addressed. \n   \nIn this review, we examine literature addressing\
    \ some \nof the issues involved with supporting IoT-enabled \ncloud applications\
    \ in a particular field. Accordingly, \nthis study's taxonomy is determined by\
    \ the specifics \nof the different IoT-cloud applications discussed in \nthe subsequent\
    \ section. Our study examines the type \nof IoT-cloud applications, and then examines\
    \ the \ncontext within which the literature was presented, to \nassess the challenges\
    \ and concerns associated with \nthem. A brief overview of IoT-cloud applications\
    \ is \nprovided in the following subsections. Furthermore, \nthe different studies\
    \ will be compared from several \nperspectives, \nincluding \ntheir \ncontext,\
    \ \ndomain, \nmechanism, significance differences, and limitations \nthat shown\
    \ in the following Table 4. In addition, \nTable 5 to Table 9 provide an analysis\
    \ of QoS factors \nassociated with various domains of applications. \nHealthcare\
    \  \nHealthcare \nIoT \napplications \nare \ncloud-based \napplications that enable\
    \ healthcare providers to \nremotely monitor and manage the health of their \n\
    patients. These applications use sensors and other \ndevices to collect data from\
    \ patients, and then use \ncloud computing to analyze and store the data. \nHealthcare\
    \ providers can use these applications to \ntrack the health of their patients\
    \ and to provide them \nwith timely information and advice. A cloud-based \nIoT\
    \ architecture may lead to more sophisticated \nhealthcare applications. In hospitals,\
    \ sensor networks \nare used to gather information about the health of \npatients\
    \ [57, 58].  \n \nAn evaluation of the studies is presented in Table 5 \nby combining\
    \ the evaluation elements within \nhealthcare IoT applications. Availability,\
    \ real-time, \nartificial intelligence (AI), latency, cost, reliability, \nsecurity,\
    \ energy consumption, and Big Data are some \nparameters considered. Furthermore,\
    \ Figure 18(a) \nillustrates that most research papers in this field \nevaluate\
    \ their proposed approach in terms of real-\ntime, cost, and security concerns.\
    \ \nEnvironment monitoring \nIoT devices may produce large amounts of data, \n\
    which can be challenging to store and analyse. The \ndata collected from the sensors\
    \ can be stored in the \ncloud \nand \nanalyzed \nfor \nuse \nin \nmonitoring\
    \ \nenvironmental conditions, such as air quality or water \nlevels. By providing\
    \ feedback on how IoT devices \nManzoor Ansari et al. \n1828 \n \nare utilised,\
    \ such data can also be used to improve \ntheir efficiency. As a smartphone can\
    \ do various \nactivities, the smart home is based on an innovative \nmobile phone\
    \ paradigm.  A network system connects \nthe devices to perform activities automatically\
    \ \naccording to the user's preferences through the IoT \n[59, 60]. \n \nTable\
    \ 6 compares and evaluates studies based on the \napplication of evaluating aspects\
    \ to IoT applications. \nSeveral \nparameters \nare \nevaluated, \nincluding \n\
    availability, real-time, AI, latency, cost, reliability, \nsecurity, energy consumption,\
    \ and Big Data. Further, \nFigure 18 (b) illustrates that most research studies\
    \ \nevaluated \nthe \nreal-time, \ncost, \nand \nreliability \ncharacteristics\
    \ of the health-care approach. \nAgriculture  \nAgriculture is a rapidly increasing\
    \ use of the IoT \nthese days.  Mobile phones are being used by farmers \nto monitor\
    \ their fields and take necessary actions \nagainst unwanted insects, such as\
    \ irrigation, insect \nscreening and fungicide applications in the field. \nAdditionally,\
    \ smart objects powered by the IoT are \nextensively used in the various poultry\
    \ and \nagriculture industries [61, 62]. \n \nAs shown in Table 7 an evaluation\
    \ element \ncomparison for IoT applications in agriculture is \npresented. In\
    \ addition to availability, real-time, AI, \nlatency, \ncost, \nreliability, \n\
    security, \nenergy \nconsumption, and Big Data, several parameters are \nanalyzed.\
    \ As can be seen in Figure 18 (c), most \nresearch studies evaluated the real-time,\
    \ cost, \navailability, AI, latency, security, and reliability \ncharacteristics\
    \ of agriculture solutions. \nSmart city \nA smart city IoT-cloud application\
    \ can help to \nmanage a city's infrastructure and resources more \nefficiently.\
    \ Several IoT-driven smart city initiatives \nare proving to deliver tangible\
    \ benefits to all citizens. \nSeveral ecosystems contribute to the development\
    \ of \nsmart cities. Many prominent innovations that help to \nthe establishment\
    \ of smart cities include energy \nmanagement and transportation management [63,\
    \ \n64]. \n \nA summary of each of the literatures, based on the \nelements used\
    \ in IoT applications for smart cities, is \npresented in Table 8. As part of\
    \ this analysis, we \nconsider the following parameters: availability, real-\n\
    time, AI, latency, cost, reliability, security, and \nenergy consumption. According\
    \ to Figure 18 (d), \nmost studies investigating smart city approaches \nevaluated\
    \ their offerings in terms of availability, cost, \nreliability, and energy consumption.\
    \ \nIndustrial \nIndustrial IoT (IIoT) is a novel intelligent industrial \nmanagement\
    \ technique that leverages intelligent \ndevices, sensors, and computer systems.\
    \ IIoT enables \nenterprises to get real-time data on their inventories \nand\
    \ manufacturing units, as well as a sensor-enabled \nalarms system that alerts\
    \ staff. Sensor data is \nrecorded and evaluated to determine the sensors' \n\
    future and direction [65, 66]. According to Table 9, \nthe papers were evaluated\
    \ by using evaluation \nelements for applications related to IIoT. As part of\
    \ \nthis assessment, we will consider the following \nparameters: availability,\
    \ real-time, AI, latency, cost, \nreliability, \nsecurity, \nand \nenergy \nconsumption.\
    \ \nAccording to Figure 18 (e), most research papers on \nIIoT applications evaluated\
    \ what they suggested \nregarding availability, real-time, cost, reliability,\
    \ and \nenergy consumption. \n \n \nFigure 17 Taxonomy of IoT-cloud applications\
    \ \n \nInternational Journal of Advanced Technology and Engineering Exploration,\
    \ Vol 9(97)                                 \n1829          \n \nTable 4 Comparative\
    \ analysis for various aspects, and real-world applications domain for the research\
    \ article \nCitation \nreferences \nYear \nof \npublication \nReal-world \napplications\
    \ \nDomain \nMain context \nMethodology/technology/algorithm \ninvolved \nSignificance\
    \ \ndifferences \nof \nthe \ncurrent \nresearch \narticles \nLimitations \nHu\
    \ et al. [67] \n2017 \nHealthcare \nMonitoring \nElderly \npatients \nImplement\
    \ \na \ncloud-based \nhealth \nmonitoring \nsystem using \nIoT sensors. \nAsymmetric/symmetric\
    \ \nencryption \nmechanism. \nEnsure \nthe \nintegrity, \nsecurity, \nnon-\nrepudiation,\
    \ and \nconfidentiality \nof \ncloud-based \ndata. \nLack of focus \non \nthe\
    \ \nbioinformatics \ncertification. \nNasser et al. \n[68] \n2021 \n \nCovid-19\
    \ \npatients \nCOVID-19 \ncan \nbe \ndetected \nand \nclassified with \nthe use\
    \ of IoT-\ncloud \ntechnologies. \nA DL based classification algorithm \nResNet50\
    \ CNN. \nThe \nsuggested \nsystem \nis \nverified utilising \nthe \nCovid-\nChestXray\
    \ \nand \nChex-Pert \nreference \ndatasets. \nThere \nis \nno \nattempt \nto \n\
    identify \ndifferent \nCOVID-19 \ncategories \nor \nmulticlasses. \nBao \net \n\
    al. \n[69] \n2022 \n \nGeneral  \npatients \nIn \ncloud-\nassisted \nMIoT, ERPD-\n\
    DS-KS \nenables \nfine-\ngrained \nsharing \nof \ndata. \nKU Nodes algorithm.\
    \ \nFor \nresource-\nconstrained \ndevices, \nthe \ncloud \ncan \nquickly \ndetermine\
    \ \nif \nciphertexts \ninclude \nthe \ndesired \nkeyword. \nCloud assisted \n\
    MIoT \nscenarios \nare \nnot as realistic \nas other related \nmethods. \n \n\
    \ \n \n \nFarid et al. \n[70] \n2021 \n \nIndividual  \npatients \nTo \nperform\
    \ \nauthentication, \nthe proposed \nframework \nuses \nmultimodal \nencrypted\
    \ \nbiometric \ntraits. \nA Centralised and Federated Identity \nManagement System\
    \ (IDMS). \nEnsure personal \nhealthcare \ninformation \nis \nsecure \nand \n\
    private. \nThere \nis \nlimited \nresearch \non \nidentity-based \nattacks. \n\
    Anuradha et \nal. [71] \n2021 \n \nCancer  \npatients \nTo \nimprove \ncancer\
    \ \nprediction by \nintegrating \nIoT and cloud \ncomputing. \nAdvanced \nEncryption\
    \ \nStandard \n(AES) algorithm and Cloudsim. \nDue \nto \ncloud \nstorage, \n\
    traditional \nmedical \ntreatment \nconstraints \ncan \nbe overcome. \nSeveral\
    \ \nmalignancies \nare \nnot \ninvestigated in \nthis \nstudy \nusing \ndeep \n\
    learning. \nMing et al. \n[72] \n2019 \nEnvironment \nMonitoring \nCO2 \nTo design\
    \ a \nmethodology \nfor CO2 using \nIoT and cloud \ncomputing. \nMQ-135 with NodeMCU\
    \ ESP8266 \nWiFi module and Firebase cloud. \n \nTo \nimprove \naccessibility\
    \ and \navailability, \nmobile platforms \nand cloud data \nstorage \nhave \n\
    replaced \ntraditional local \nserver solutions. \nInsufficiency \nof the system's\
    \ \nfunctionality \ncan \nbe \nexpanded \nby \nincluding new \nparts. \nSingh\
    \ et al. \n[73] \n2020 \nEnvironment \nMonitoring \nAir pollution \nSeveral \n\
    variables \nrelated \nto \nclimate \nare \nexamined \nin \nthe \nresearch, \n\
    including \nair \ntemperature, \nhumidity, \npressure, and \ncarbon \ndioxide\
    \ levels. \nThingSpeak IoT app, Raspberry pi 3, \nArduino UNO, MQ-135 gas sensor.\
    \ \nIn \nreal-time, \nsensor interfaces \ncan detect and \ncollect \nmany \nparameters\
    \ \nsimultaneously. \n Due \nto \nthe \nnature of the \ndevice, \nit \ncannot\
    \ \nbe \noperated from \nanywhere. \nMi et al. [74] \n2022 \n \nPM 2.5 \nA \n\
    residential \nenvironmental \npollution \nmonitoring \nsystem \nis \ndeveloped\
    \ \nusing \ncloud \ncomputing \nand the IoT. \nSTM32, Wi-Fi module, a serial port,\
    \ \nand a sensor. \nA \npollution \nmonitoring \nsystem \nuses \nsensor networks,\
    \ \nwireless \ncommunications, \nintegrated \ndevelopment, \nimage \nThe \ninsufficient\
    \ \nimplementation \nof \nmachine \nlearning \nmodels. \nManzoor Ansari et al.\
    \ \n1830 \n \nCitation \nreferences \nYear \nof \npublication \nReal-world \n\
    applications \nDomain \nMain context \nMethodology/technology/algorithm \ninvolved\
    \ \nSignificance \ndifferences \nof \nthe \ncurrent \nresearch \narticles \nLimitations\
    \ \nprocessing, and \ndata fusion. \nPhasinam \net \nal. [75] \n2022 \nAgriculture\
    \ \nIrrigation \nSystem \nImplementing \na soil moisture \nand humidity \ndata\
    \ stored in \nthe cloud are \nanalyzed. \nDHT11/DHT22 humidity sensors, \nYL-69\
    \ soil moisture sensor, AI \ntechnique (support vector machine, \nrandom forest,\
    \ and Naïve Bayes). \nWith the aid of \nmachine \nlearning, \nAgriculturists \n\
    receive accurate \nguidance \non \ngroundwater \nmanagement. \nFor IoT and \n\
    cloud \ncomputing \nto \nbecome \na \nreality, \nsignificant \nresearch is still\
    \ \nrequired. \nUddin et al. \n[76] \n2022 \n \nRice-fish \nfarming \nA cloud-based\
    \ \nIoT-based \nautomated \nfarming \nsystem \nthat \nemploys WSN \nto \nremotely\
    \ \nmonitor \nfactors. \nDWIFS (Developed Website for \nIntegrated Farming System).\
    \ \nFor \nintelligent \nfish \nfarm \nmonitoring, \nfarmer \ncan \naccess \nDWIFS\
    \ \nand \nthe \nIoT \ncloud server via \nSMS and email \nfrom \nanywhere \nin\
    \ the world. \nAn \nAndroid \napp \nis \nnot \navailable \nto \nremotely \nmonitor\
    \ output \ndata \nfrom \nmobile devices. \nNamee et al. \n[77] \n2020 \n \nHydroponics\
    \ \nvegetable \nTo \nhelp \nsoilless \nvegetable \nby \nusing \nIoT, \nEdge \n\
    computing, \nand \nCloud \ncomputing. \nNode MCU ESP8266, Arduino UNO \nR3, and\
    \ Raspberry Pi v3. \nTo significantly \nmonitor various \ncomponents \nwithin\
    \ \nthe \ncabinet, such as \npH, \nhumidity, \nEC in water, and \ntemperature.\
    \ \nInsufficient \nsecurity \nmeasures \nand \nprocedures \nleveraging \nmachine\
    \ \nlearning. \nHundera et al. \n[78] \n2021 \nSmart City \nSmart city \nProxy-based\
    \ \npublic-key \nencryption \nscheme \nfor \nsmart city IoT \ncloud \ndata \n\
    security. \nEF-PB-PKC-IoT-CMA and IND-PB-\nPKC-IoT-CCA2 \nHighly suitable \nfor\
    \ cloud and \nIoT \ncontexts, \nwith \nreduced \ncomputational \ncomplexity than\
    \ \nconventional \ntechniques. \nInsufficient \neffort has been \nexpended \n\
    to \ncreate \nand \nimprove \nthe \nPB-PKC-IoT \nscheme \nfor \nvarious \napplications.\
    \ \nHojjati et al. \n[79] \n2022 \n \nWaste \nmanagement \nA \nsystem \nbased\
    \ on trash \nobjects \nhas \nbeen designed \nand \nconstructed to \nmonitor \n\
    and \nscore \nuser \nsorting \nbehavior. \nYOLOv3, Light dependent resistor \n\
    (LDR) module, Intel AC8265 WiFi \nWireless adapter and C270 HD \ncamera. \n System\
    \ \nuses \nsolar panels to \ngenerate \nelectricity \nand \ndoes not save \nuser\
    \ data. \nDuring \nthe \nautumn \nand \nwinter, where \nsunlight \nis \nsparse,\
    \ \nbatteries \nand \nsolar panels are \nnot \nused \nto \nprovide \nthis \npower.\
    \ \nHussain et al. \n[80] \n2019 \nSmart City \nSmart dustbin \nA \nreal-time\
    \ \ntrash \nmonitoring \nplatform \nbased on IoT \nis \nused \nto \ntransfer \n\
    data \nto \na \ncloud-\nbased \nplatform. \n \nThingsSpeak, \nESP8266 \nmodule,\
    \ \nDHT 11, GSM, GPS. \nThe \nmodule \nprovides an alert \nwhen the trash \nlevel\
    \ exceeds a \ncertain \npoint, \nwhile \nalso \npreventing fires \ncaused \nby\
    \ \ncigarettes \nand \nother \ncombustible \nmaterials. \n \nInadequate \nsafety\
    \ \nmeasures. \nGarbugli \net \nal. [81] \n2022 \nIndustrial  \nIndividual \n\
    manufacturing \nIoT-based \nmiddleware \nfor managing \nvirtualized \nresources\
    \ and \nmonitoring \nQoS. \nTEMPOS: \na \nTime-Effective \nMiddleware for Priority\
    \ Oriented \nServerless. \nTo control QoS \nend-to-end \nin \nterms of jitter,\
    \ \nlatency, \nand \nqueueing \ntime, \nTEMPOS \nmay \nexploit \nand \ncoordinate\
    \ QoS \nmechanisms \nthroughout \nthe \nstack \nof \nvirtualized FaaS \nservices.\
    \ \nLack \nof \nresources \nscalability. \nInternational Journal of Advanced Technology\
    \ and Engineering Exploration, Vol 9(97)                                 \n1831\
    \          \n \nCitation \nreferences \nYear \nof \npublication \nReal-world \n\
    applications \nDomain \nMain context \nMethodology/technology/algorithm \ninvolved\
    \ \nSignificance \ndifferences \nof \nthe \ncurrent \nresearch \narticles \nLimitations\
    \ \nQader et al. \n[82] \n2022 \n \nIndustry 4.0 \nUsing \nthe \nSupply Chain\
    \ \nEfficiency \n(SCP) model, \nthe effects of \nIndustry \n4.0 \non \nsupply\
    \ \nchain \nefficiency are \nexamined. \nModeling structural equations with \n\
    partial least squares (PLS-SEM). \nIndustry4.0 has \nbeen proved to \nhave \n\
    a \nconsiderable and \nsubstantial effect \non \nthe \nperformance of \nSCs. \n\
    SCs \nface \nsignificant \nchallenges due \nto \nlack \nof \nsecurity \nin \n\
    Industry 4.0. \n \nVenticinque \nand \nAmato \n[83] \n2019 \n \nSmart Energy \n\
    domain \nContent-based \ncross-layer \nscheduling \napproach \nto \nfog \nservice\
    \ \nplacement. \n \nCoSSMic European project. \nMethodology \ndescribes how to\
    \ \noptimize \nperformance and \nresource \nconsumption by \napplication \nrequirements.\
    \ \nA \nlack \nof \ndynamic \noptimization of \ndeployment. \n \n \nTable 5 Comparative\
    \ analysis of the existing QoS parameter in the healthcare domain \n \nTable 6\
    \ Comparative analysis of the existing QoS parameter in the environment monitoring\
    \ domain \n \nTable 7 Comparative analysis of the existing QoS parameter in the\
    \ agriculture domain \nCitation references \nAvailability \nReal-\nTime \nAI \n\
    Latency \nCost \nReliability \nSecurity \nEnergy \nconsumption \nBig \nData \n\
    Hu et al. [67] \n \n \n \n \n \n \n \n \n \nNasser et al. [68] \n \n\
     \n \n \n \n \n \n \n \nBao et al. [69] \n \n \n \n \n \n \n \n\
     \n \nFarid et al. [70] \n \n \n \n \n \n \n \n \n \nAnuradha et al.\
    \ [71] \n \n \n \n \n \n \n \n \n \nKim and  Kim  [84] \n \n \n \n\
     \n \n \n \n \n \nJimenez and Torres  \n[85] \n \n \n \n \n \n \n\
     \n \n \nSuciu et al. [86] \n \n \n \n \n \n \n \n \n \nAlshammari\
    \ et al. [87] \n \n \n \n \n \n \n \n \n \nFirouzi et al. [88] \n \n\
     \n \n \n \n \n \n \n \nCitation references \nAvailability \nReal-\nTime\
    \ \nAI \nLatency \nCost \nReliability \nSecurity \nEnergy \nconsumption \nBig\
    \ \nData \nMing et al. [72] \n \n \n \n \n \n \n \n \n \nSingh et al.\
    \ [73] \n \n \n \n \n \n \n \n \n \nMi et al. [74] \n \n \n \n \n\
     \n \n \n \n \nArvaree et al. [89] \n \n \n \n \n \n \n \n \n \n\
    Li et al. [90] \n \n \n \n \n \n \n \n \n \nKim et al. [91] \n \n \n\
     \n \n \n \n \n \n \nHojjati et al. [79] \n \n \n \n \n \n \n \n\
     \n \nAsha et al. [92] \n \n \n \n \n \n \n \n \n \nQian and  Wang\
    \ [93] \n \n \n \n \n \n \n \n \n \nCitation references \nAvailability\
    \ \nReal-\nTime \nAI \nLatency \nCost \nReliability \nSecurity \nEnergy \nconsumption\
    \ \nBig \nData \nPhasinam et al. [75] \n \n \n \n \n \n \n \n \n \nUddin\
    \ et al. [76] \n \n \n \n \n \n \n \n \n \nNamee et al. [77] \n \n\
    \ \n \n \n \n \n \n \n \nMisra et al. [94] \n \n \n \n \n \n \n\
    \ \n \n \nPerumal et al. [95] \n \n \n \n \n \n \n \n \n \nMekala \n\
    and  \nViswanathan  [96] \n \n \n \n \n \n \n \n \n \nManzoor Ansari\
    \ et al. \n1832 \n \n \nTable 8 Comparative analysis of the existing QoS parameter\
    \ in the smart city domain \nCitation \nreferences \nAvailability \nReal-Time\
    \ \nAI \nLatency \nCost \nReliability \nSecurity \nEnergy \nconsumption \nHundera\
    \ et al. \n[78] \n \n \n \n \n \n \n \n \nHojjati \net \nal. \n[79] \n\
     \n \n \n \n \n \n \n \nMontori et al. \n[100] \n \n \n \n \n \n\
     \n \n \nZia et al. [101] \n \n \n \n \n \n \n \n \nDistefano et al.\
    \ \n[102] \n \n \n \n \n \n \n \n \nZeng et al. [103] \n \n \n \n\
    \ \n \n \n \n \nDuttagupta et al. \n[104] \n \n \n \n \n \n \n \n\
    \ \nChen et al. [105] \n \n \n \n \n \n \n \n \nLee et al. [106] \n \n\
     \n \n \n \n \n \n \nAkbar \net \nal. \n[107] \n \n \n \n \n \n \n\
     \n \nSun and Ansari \n[108] \n \n \n \n \n \n \n \n \n \nTable 9 Comparative\
    \ analysis of the existing QoS parameter in the industrial domain \n \n5.Analysis\
    \ \nbased \non \nthe \nexisting \nmiddleware and platforms tools  \nA software\
    \ layer known as middleware is located \nbetween the application and perception\
    \ layers. This \nlayer is capable of addressing several issues, \nincluding reliability,\
    \ scalability, homogeneity, and \nsecurity. Middleware, as defined by Farahzadi\
    \ et al. \n[117], \nis \na \n\"network-oriented\" \nperspective. \nMiddleware\
    \ technology is primarily used to abstract \nand communicate with devices to facilitate\
    \ the \ninevitable integration of IoT devices with other \ntechnologies, including\
    \ cloud services [118]. The \noverall concept and primary characteristics or feature\
    \ \nof IoT-based middleware are shown in Figure 19. \nIn addition, as part of\
    \ an integrated framework, \nvarious existing platforms deliver IoT-enabled cloud\
    \ \nservices as a service [119]. A variety of IoT cloud \nproviders are available\
    \ in the market for leveraging \nappropriate and unique IoT services [120, 121].\
    \ This \narticle analyses the present state of the industry in \norder to identify\
    \ the leading IoT platforms. This \nresearch may aid in the creation of the best\
    \ \nenvironment for IoT application development. This \nsection discusses in depth\
    \ developing IoT cloud \nservice platforms, their characteristics, and the \n\
    associated benefits and drawbacks. Table 10 details \nthe design and application\
    \ of the IoT platform, while \nTable 11 details the top 10 middleware. \nLiu et\
    \ al. [97] \n \n \n \n \n \n \n \n \n \nAiswarya et al. [98] \n \n\
    \ \n \n \n \n \n \n \n \nRathor and  Kumari  \n[99] \n \n \n \n \n\
     \n \n \n \n \nCitation references \nAvailability \nReal-\ntime \nAI \nLatency\
    \ \nCost \nReliability \nSecurity \nEnergy \nconsumption \nPustišek \nand  \n\
    Kos  \n[109] \n \n \n \n \n \n \n \n \nAlodib [110] \n \n \n \n \n\
     \n \n \n \nHan and  Crespi [111] \n \n \n \n \n \n \n \n \nHuo et\
    \ al. [112] \n \n \n \n \n \n \n \n \nHuo and  Wang  [113] \n \n \n\
     \n \n \n \n \n \nTemglit et al. [114] \n \n \n \n \n \n \n \n \n\
    De  et al. [115] \n \n \n \n \n \n \n \n \nRath et al. [116] \n \n \n\
     \n \n \n \n \n \nInternational Journal of Advanced Technology and Engineering\
    \ Exploration, Vol 9(97)                                 \n1833          \n \n\
    \ \nFigure 18 Analysis of QoS factors for (a) Health-care (b) Environment (c)\
    \ Agriculture (d) Smart city (e) Industry \n \n \nFigure 19 An overview of CoT-based\
    \ middleware including its main characteristics and features \nManzoor Ansari\
    \ et al. \n1834 \n \n6.Benefits of integration IoT and cloud \nIoT-enabled services\
    \ comprise a wide variety of \ndevices such as embedded devices, sensor devices,\
    \ \ncommunication devices, and mobile devices. In the \nabsence \nof \nadequate\
    \ \nstorage \nand \nprocessing \nresources, the IoT-based system cannot retain\
    \ and \nprocess large volumes of sensor-driven data. As a \nresult, the IoT system\
    \ will need assistance in \novercoming these constraints.  \nCloud computing provides\
    \ an unlimited storage \ncapacity, enormous computational power, and \nnetwork\
    \ bandwidth, among other capabilities which \nmay assist the IoT system in addressing\
    \ the barriers \ndescribed prior. Cloud computing resources are \nelastic, allowing\
    \ them to grow and contract in \nresponse to the IoT environment's requirements.\
    \ \nSensor data analysis may also be aided by cloud-\nbased Big Data analytics\
    \ [122,123]. Cloud computing \nintegration with IoT systems improves the efficiency\
    \ \nand reliability of IoT-based applications. An array of \nbenefits can be achieved\
    \ by combining the IoT with \ncloud computing. Following are some of the \nadvantages.\
    \ \nData transmission  \nCloud-based \nIoT \nparadigms \nallow \nefficient \n\
    transmission. IoT applications provide low-cost data \ntransmission between nodes.\
    \ Cloud computing \nenables the cost-effective and efficient connection, \ncontrol,\
    \ and exchange of data via the use of \nintegrated applications. \nStorage  \n\
    The IoT ecosystem is composed of several associated \ngadgets and sensors that\
    \ cause enormous amounts of \nreal-time data. Local storage on the IoT is insufficient\
    \ \nto hold this volume of data. Additionally, a large \nnumber of IoT devices\
    \ generate both structured and \nunstructured \ndata. \nConventional \ndatabases\
    \ \nare \nincapable of holding such a diverse set of data. Cloud \ncomputing enables\
    \ IoT devices to overcome this data \nstorage challenge. Cloud computing is comprised\
    \ of a \ngroup of commodity computers equipped with a \nsignificant quantity of\
    \ inbuilt storage. Cloud-based \nIoT systems allow users to store data and access\
    \ it \nfrom anywhere using the internet. Additionally, this \nvast data storage\
    \ may be leveraged to address the \nheterogeneity of devices by enabling analytics\
    \ and \nsystem enhancements. \nProcessing  \nIoT devices have rudimentary computing\
    \ power. As a \nresult, they are incapable of processing massive \namounts of\
    \ data generated by millions of linked, \nintelligent \ngadgets. \nCloud \ncomputing\
    \ \noffers \ncomputational capacity for IoT devices by dividing \nthe real computer\
    \ into several virtual ones. A virtual \ncomputer may be rented through Internet-enabled\
    \ \ndevices on a pay-per-use basis. Due to the integration \nof IoT technology\
    \ into cloud services, end users can \nbenefit from low-cost computing power while\
    \ \ngenerating high income. \nModern capacities  \nMultiple operational devices\
    \ are interconnected via \nIoT-enabled devices. These devices communicate \nusing\
    \ a variety of protocols and techniques. As a \nresult, coordination between these\
    \ disparate devices \nis \ndifficult. \nAdditionally, \nobtaining \nmaximum \n\
    dependability and efficiency might be difficult. Cloud \ncomputing is characterized\
    \ by its elasticity and ease \nof usage. By integrating cloud computing with IoT,\
    \ \nusers can be assured that their applications are more \nreliable, scalable,\
    \ secure, and efficient. \nModels for the cloud of things \nSaaS, IaaS, and PaaS\
    \ are the three primary \ndeployment methods for cloud computing. With the \n\
    combination of cloud and IoT, new deployment \nmethods have been developed, including\
    \ the \nfollowing: \n Sensing as a Service (SaaS) provides services for \nacquiring\
    \ access to the information collected by \nIoT sensors. \n Integration Platform\
    \ as a Servic (IPaaS) allows \nidentifying devices connected to the network and\
    \ \nsetting up access control policies. \n The Database as a Service (DBaaS)\
    \ is involved in \nboth database administration and storage services. \n Ethernet\
    \ as a Service (EaaS) enables IoT-enabled \ndevices to connect to the internet.\
    \ \n The Sensor and Actuation as a Service (SAaaS) \nensures automatic control\
    \ of sensors and devices. \n \nTable 10 Existing IoT-cloud platforms \nPlatforms\
    \ \nFeatures \nMerits \nLimits \nWeb links \nArrayent \nConnect  \nIntelligent\
    \ \ndevices \nand web applications \ncan \neffortlessly \nintegrate \nheterogeneous\
    \ \nIoT \nsystems. \nMaintains elasticity \nDue \nto \nthe \nconfiguration of\
    \ the \nsystem, trigger-based \nservices are delayed. \nhttp://prodea.com/platform\
    \ \nEthings.Io \nAn \neffective \napplication \nDevice \nuncertainty \nsupport\
    \ \nThird-party \ndevelopment \nhttps://blog.thethings.io/ \nInternational Journal\
    \ of Advanced Technology and Engineering Exploration, Vol 9(97)              \
    \                   \n1835          \n \nPlatforms \nFeatures \nMerits \nLimits\
    \ \nWeb links \nprogramming \ninterface \n(API) \nis \ndeveloped for IoT \ndevelopers.\
    \ \ndue \nto \nhardware \ninsecurity, \nit \nis \nlimited to devices \nthat implement\
    \ the \nHTTP, MQTT, and \nCOAP protocols. \nbecomes challenging. \nOpen Remote\
    \ \nUsing any available \nresources, the user \nmay connect to any \ndevice, protocol,\
    \ or \nsystem design. \nA user may utilize \nremotely \ncloud \nservices to design\
    \ \nany \npersonalized \nsoftware system. \nOpen cloud services \nare supported.\
    \ \nInsufficient \ndata \nmanagement \nhttps://openremote.io/ \nArkessa  \nIt\
    \ allows companies \nto \nconnect \nand \ncontrol their gadgets. \nEnterprise\
    \ \nbased \ndesign model \nNot \nenough \nvisualization tools \nhttps://www.arkessa.com/\
    \ \nAxeda  \nA \ncloud-based \napproach is used to \ndevelop \nIoT \nand \nM2M\
    \ applications. \nThe M2M paradigm \nis used to manage \ndata. \nDependence \n\
    on \na \nthird-party service \nhttps://support.axeda.com/help/ \nen/about_axeda_access.htm\
    \ \nOracle IoT Cloud  \nThere are four key \nbenefits \nit \noffers: \ntransparency,\
    \ insight, \nsecurity, \nand \nacceleration. \nEnd-to-end security \nallows it\
    \ to connect \nany \ndevice \nand \ndeliver \nbusiness \nvalue with the least\
    \ \namount of risk. \nIt \naids \nin \nthe \nmanagement of data. \nAn issue with\
    \ open-\nsource \nsystem \nconnection caused by \nthe size restriction. \nhttps://www.toracle.com/\
    \ internet-of-things/, \nNimbits  \nIoT \nservices \nare \nprovided \nutilizing\
    \ \nedge \ncomputing \nlimitations \nin \na \nhybrid \ncloud \napproach.  \nAside\
    \ from that, it \neffectively filters and \nuploads cloud data. \nDevelopers \n\
    may \nutilize it effortlessly \nand without issues. \nThe processing of \nreal-time\
    \ \ndata \nis \nunsatisfactory. \nhttps://www.crunchbase.com/ \norganization/nimbits,\
    \ \nThingsworx \n \nIt \nis \na \ndecision-\nmaking tool that is \nbased on data.\
    \  \nThe squeal paradigm \nfor m2m and IoT \napplications provides \nsearch-based\
    \ insight. \nData-intensive \napplications \nmay \nemerge fast. \nSimultaneous\
    \ device \nrestrictions \nhttps://www.ptc.com/en/ \ntechnologies/iIoT \nKaa  \n\
    An \nOpen-Source \nPlatform \nfor \nDeploying, \nMonitoring, \nAnd \nAdministering\
    \ \nIot \nApplications on The \nCloud. \nTo identify devices \nand objects, digital\
    \ \ntwins \noffer \na \nlightweight \nIoT \nconnection protocol. \nSeveral applications\
    \ \nrelated to Big Data \nand \nNoSQL \nare \nimplemented. \nIt \nsupports \n\
    less \nheterogeneous \nhardware devices. \nhttps://kaaproject.github.io/kaa \n\
    Manzoor Ansari et al. \n1836 \n \nPlatforms \nFeatures \nMerits \nLimits \nWeb\
    \ links \nIt delivers scalability, \ndata analytics and \nvisualisation, \nand\
    \ \nsystem \ndependability. \nCarriots  \nIt is a cloud platform \nthat \nenables\
    \ \norganisations \nto \nrapidly \nand \ncost-\neffectively \ndevelop \nIoT applications.\
    \ \nIt is built on a cloud-\nbased \nplatform \nparadigm, \nwhich \nallows \n\
    users \nto \nremotely operate the \ndevice, set alarms, \nand export data. \n\
    It supports trigger-\nbased application \nThey \nhave \na \ncomplicated \nuser\
    \ \ninterface. \nhttps://www.altair.com/smart-product-\ndevelopment \nTemboo \
    \ \nCloud-based \nIoT \napplication \ndevelopment \nplatform specialising \non\
    \ \nmanufacturing \nindustry \ninventory \nmanagement. \nAn alert message is \n\
    sent \nout \nwhen \na \nsensor \ndetects \na \nchange in a physical \nasset's\
    \ condition. \nChoreos applications \nare employed easily \nApplications \nthat\
    \ \nneed \na \nlot \nof \nresources \nare \nnot \nsupported. \nhttps://temboo.com/IoT\
    \ \nSeeControlIoT  \nA \ncloud-based \nadministration \nsystem \nand \nconnectivity\
    \ system \nfor IoT devices. \nIt \nalso \nhas \na \npush/pull \narchitecture \n\
    to \nanalyse and interpret \nsensor data. \nPush/pull messaging \nmechanism between\
    \ \ndevices \nInefficient \ndata \nvisualisation \nhttps://www.IoTglobalnetwork.com\
    \ \nSensorCloud \n \nIoT \ndata \nstorage, \nvisualization, \nmonitoring, \nand\
    \ \nanalysis platform for \nsmart IoT devices. \nThe MathEngine and \nFastGraph\
    \ \ntools \nallow \nusers \nto \nanalyze and visualize \ndata. \nIt can handle\
    \ several \nresources. \nConnecting \nopen-\nsource devices \nhttps://www.scc.com/insights/it-solutions\
    \ \nEtherios  \nEtherios \ncombines \nwith \nwestmonroe \npartners. \nit \noffers\
    \ \nseveral goods and \nservices. \nIt uses the cloud \nPaaS \nparadigm \nto \n\
    connect and monitor \nitems in real-time. \nCloud-based services \nfor third-party\
    \ and \nunique devices \nThe device selection \nis limited. \nhttps://www.sensorcloud.com\
    \ \nXively  \nIn the current state of \naffairs, xively is an \nofficial member\
    \ of \nthe \ngoogle \ncloud \nplatform. \nIt is comprised of a \nnumber \nof \n\
    Integration \nwith \ndevices is effortless \nPoor management of \nthe system \n\
    https://www.developerxively.com/docs/what-\nis-xively \nInternational Journal\
    \ of Advanced Technology and Engineering Exploration, Vol 9(97)              \
    \                   \n1837          \n \nPlatforms \nFeatures \nMerits \nLimits\
    \ \nWeb links \napplication-specific \nsub-parts, including \nlutron, freight\
    \ farm, \nwatts, tekmar, sato, \nand sureflap. \n \nTable 11 Middleware technologies\
    \ \n \n7.The challenges and open research issues \nof the cloud of things (CoT)\
    \ \nThe Integration of the IoT with cloud technology is \nproblematic and a number\
    \ of problems remain \nunresolved. A number of legitimate concerns have \nbeen\
    \ identified: \n \nPrivacy and security \nIn developing IoT-based cloud services,\
    \ privacy and \nsecurity are the key concerns. The IoT-based Cloud \nenables the\
    \ transfer of real-world data to the cloud. In \norder to ensure only authorized\
    \ customers have \naccess to data, it is important to determine how \neffectively\
    \ authorization rules and regulations should \nbe enforced. As a precaution, critical\
    \ information \nshould be shielded from unwanted access. Cloud-\nbased IoT devices\
    \ pose a number of challenges, such \nas the lack of transparency in service-level\
    \ agreemen \n(SLAs), data privacy, and the remote-access of the \nsystem. Additionally,\
    \ multi-tenancy may result in the \nrestriction of sensitive data using public\
    \ key \ncryptography. In comparison, serious problems, such \nas user takeover\
    \ and virtual machine rescue, are also \na source of concern. The researchers\
    \ [124], make an \nassault on the system and provide a recommendation. \nUsing\
    \ neural networks (NN) and cloud trace back \n(CTB) technologies, they propose\
    \ a method to \nidentify the cause of attacks. \nIpv6 addressing strategies  \n\
    It is widely recognized that the Internet is a key \ncomponent of the IoT. IPv4\
    \ has a profound influence \non the IoT. The CoAP technology allows devices and\
    \ \nservers to communicate directly over the internet. As \npart of the future\
    \ development of these technologies, \nnetwork address translation (NAT) operations\
    \ will be \neliminated in order to provide a specific IP address to \nthe expanding\
    \ IoT platform or network. IPv6 is \ndesigned \nto \novercome \nIPv4's \nlimitations\
    \ \nby \nemploying a 128-bit Internet Protocol address. There \nare numerous benefits\
    \ to RESTful interfaces, \nincluding the availability of an almost unlimited \n\
    number of Internet-connected devices, cross-platform \ncompatibility, and compliance\
    \ with REST protocol \nagreements. The IP protocol 6LoWPAN and ZigBee \ncan be\
    \ applied to integrated IoT devices to implement \nIPv6, however, several platforms\
    \ are yet to \nimplement these protocols. IPv6 is used by the IoT \nnetwork, which\
    \ originates from human-initiated \nnetworks. \nInteroperability  \nDue to the\
    \ diverse and independent nature of IoT \ndevices, interoperability is a critical\
    \ challenge in \ncloud-based IoT systems. Several forms of work have \nbeen conducted\
    \ in this area during the past several \nyears to address this issue. Due to the\
    \ heterogeneity \nof cloud platforms and applications, the presented \nmethodologies\
    \ \ngive \na \nvariety \nof \nsolutions. \nAdditionally, lack of compatibility\
    \ may result in the \ndifficulty to construct cross-platform and cross-\ndomain\
    \ applications [125]. \nIntelligent analytics  \nIntelligent analytics can provide\
    \ insights into large \nvolumes of data collected from connected devices. \nThis\
    \ data can be used to identify patterns and trends, \nuncover anomalies, and provide\
    \ predictive analytics \nto help inform decisions. Intelligent analytics can \n\
    also be used to create automated control systems, \nallowing for more efficient\
    \ operations, improved \nMiddleware \nApplications \nArchitecture \nCloud-Based\
    \ \nAura  \nThe Ubiquitous Computing Environment \nDistributed \n \nAbs & S \n\
    Automatic Vehicle Parking \nService-Related \n \nCarriots  \nAn Energy-Efficient\
    \ Smart City \nService-Related \n \nCarisma \nComputing on Mobile Devices \n\
    Distributed \n \nDroplock \nDeployment of Smart Homes \nService-Related \n \n\
    Openiot  \nMobile Crowdsourcing and Smart Cities \nService-Related \n \nRimware\
    \ \nThe Installation of a Smart Lighting System \nand Heart Rate Monitor \nService-Related\
    \ \n \nThingworx \nAgribusiness, Intelligent Cities, and Smart \nInfrastructure\
    \ \nService-Related \n \nVirtus \nInternet-Based Health Services \nDistributed\
    \ \n \nXively \nHome \nAppliances \nConnectivity \nand \nManagement \nService-Related\
    \ \n \nManzoor Ansari et al. \n1838 \n \nsafety, and better energy management.\
    \ Additionally, \nintelligent analytics can help improve customer \nexperience\
    \ by providing personalized services and \ntargeted recommendations [126,127].\
    \ \nIntegration methodology  \nBy combining present and future intelligent cyber-\n\
    physical systems into fully realised IoT, the demand \nfor interoperability cannot\
    \ be neglected. There are no \nexisting IoT standards or approaches for integrating\
    \ \nIoT systems due to their diverse nature and \ninteroperability [128]. The\
    \ heterogeneity issue might \nbe exacerbated when end users utilize multi-Cloud\
    \ \nsolutions, since applications depend on a multitude of \nproviders to support\
    \ scalability and efficiency. \nHeterogeneity \nIoT and cloud computing are hindered\
    \ by the \ncomplexity of legacy systems, platforms, operating \nsystems, and services.\
    \ As a result, the heterogeneity \nproblem may worsen dramatically as end users\
    \ adopt \nmulti-cloud solutions, where applications become \nincreasingly dependent\
    \ on the capabilities provided \nby numerous providers. \nStandardizations \n\
    A number of experts have acknowledged that the lack \nof standards is one of the\
    \ major challenges facing \nCloudIoT models in recent years. IoT-based Cloud \n\
    paradigms require standardized protocols, interfaces, \nand APIs to interconnect\
    \ heterogeneous intelligent \nobjects and provide unique services. Many IoT and\
    \ \ncloud \ndeployment \napproaches \nhave \nbeen \nrecommended by the technical\
    \ community. \n \nEdge/Fog computing  \nComputing can be applied at the edge of\
    \ providing \ncloud-based services. To assist customers with their \ncloud computing\
    \ needs, Fog provides application \nservices. As a generalisation, fog is an expansion\
    \ of \nthe cloud system that connects the cloud to the \nnetwork's edge. To achieve\
    \ latency constraints, \nadditional nodes are necessary for services that are\
    \ \nlatency-sensitive. Although Cloud and Fog are highly \ndependent \non \nprocessing,\
    \ \nnetworking, \nand \ncomputing. \nCloud capabilities  \nAn IoT architecture\
    \ based on the cloud poses a \nsignificant security risk to every networked system.\
    \ \nThere are additional attack vectors on both the IoT \nand cloud sides. An\
    \ IoT setting can benefit from \nencryption for data privacy, confidentiality,\
    \ and \nauthentication. On the other hand, internal threats \ncannot be defeated,\
    \ and operating IoT devices with \nlimited functionality is equally problematic.\
    \ \nS.L.A. implementation  \nCloud-based IoT applications enable the transmission\
    \ \nand storage of data created within the confines of \napplication-specific\
    \ \nlimits, \nwhich \nmight \nbe \ntroublesome in certain cases.  \n \nA single\
    \ provider may not always be sufficient to \nassure a specified level of QoS.\
    \ As a result, it is \nlikely to require the support of several cloud service\
    \ \nproviders for addressing SLA violations. \nBig Data  \nThe pervasiveness of\
    \ mobile devices and sensors \nnecessitates the use of modular systems. As a result,\
    \ \nseveral Cloud service providers may be required to \navoid breaches of S.L.A.\
    \ files. However, the \nflexibility of the most regularly come up of cloud \n\
    services is still an unresolved problem because of the \ntime, cost, and maintenance\
    \ of QoS complexity. \nPower and energy efficiency \nDuring the past decade, IoT-enabled\
    \ applications \nhave enabled frequent data flow between IoT devices \nand the\
    \ cloud, which has resulted in rapid power \nconsumption on the nodes. Consequently,\
    \ the data \nprocessing and transmission industries continue to \nprioritize energy\
    \ efficiency. \nPerformance  \nSeveral cloud computing and IoT technologies (such\
    \ \nas networking, processing, and storage) are difficult \nto \nstandardize \n\
    due \nto \ntheir \nscale-dependent \nperformance requirements. \nReliability \
    \ \nCloud computing and IoT convergence typically \nintroduce dependability concerns\
    \ in mission-critical \napplications. For example, in the domain of \nintelligent\
    \ mobility, vehicles are frequently in \nmotion, and automotive networking and\
    \ connection \nare frequently irregular and inefficient. In a resource-\nconstrained\
    \ setting, a range of issues relating to \nsystem breakdown or systems that are\
    \ not always \napproachable are highlighted. \nMonitoring \nIn cloud environments,\
    \ monitoring is essential for \nbatch processing, resource management, S.L.A.s,\
    \ \ndependability and security, and troubleshooting. \nConsequently, the cloud-based\
    \ IoT system adheres to \nall the same requirements as a traditional cloud \n\
    monitoring system, despite the IoT's inherent \nchallenges associated with speed,\
    \ volume, and \ndiversity. \n \n8.Discussion \nIn an effort to maximize the yield\
    \ of IoT and cloud \nintegration, researchers from around the world have \nexplored\
    \ a variety of technological solutions. IoT and \ncloud computing are two buzzword-rich\
    \ digital \nInternational Journal of Advanced Technology and Engineering Exploration,\
    \ Vol 9(97)                                 \n1839          \n \ntransformation\
    \ topics that have been the focus of a lot \nof attention in recent years. This\
    \ research reviews \nmultiple aspects of IoT-based cloud applications (i.e., \n\
    health-care, environment, agriculture, smart city, and \nindustry). Furthermore,\
    \ various QoS factors (such as \navailability, AI, reliability, security, real-time,\
    \ and \nBig Data) have been analysed for each domain. For \ndeeper insight, a\
    \ comprehensive review of various \nexisting \nplatforms \nand \nenabling \nmiddleware\
    \ \ntechnologies also have been synthesized. There are \nfollowing potential impacts\
    \ of methods and platforms \nfor IoT cloud integration which include: \n Increased\
    \ \nefficiency \nand \nproductivity: \nBy \nautomating tasks and monitoring devices\
    \ and \nsystems \nremotely, \nbusinesses \ncan \nimprove \noperational efficiency\
    \ and productivity. \n Improved decision making: With real-time data \nand analytics,\
    \ IoT-enabled cloud applications can \nmake better informed decisions about their\
    \ \noperations. \n Enhanced \ncustomer \nexperience: \nIoT-enabled \nbusinesses\
    \ \ncan \nprovide \nbetter \ncustomer \nexperiences by customizing products and\
    \ services \nto meet customer needs. \n Reduced costs: Automation and remote\
    \ monitoring \ncan help businesses reduce costs associated with \nlabour, energy,\
    \ and other resources.  \n Enhanced security: Cloud-based IoT platforms can \n\
    offer enhanced security features such as data \nencryption and user authentication.\
    \ This can help \norganizations to protect their data and prevent \nunauthorized\
    \ access. \n Increased scalability: Cloud-based IoT platforms \noffer \nincreased\
    \ \nscalability, \nwhich \nallows \norganizations to easily add or remove devices\
    \ and \nusers as per their requirement. \nFurthermore, this article uses PRISMA\
    \ guidelines for \nquality assessment. Our primary objective is to \nidentify\
    \ the current state of the art of integrating IoT \ncloud technologies and map\
    \ the key research areas \nand future development trends. To achieve this \nobjective,\
    \ a comprehensive literature review was \nconducted and a total of 63 papers were\
    \ identified \nand analyzed. The results of the bibliometric analysis \nshowed\
    \ that the field of IoT cloud integration is a \nrelatively new research area\
    \ with a rapidly growing \nbody of literature. However, there are some \nlimitations\
    \ of IoT and cloud integration as follows: \n Security issues: It is important\
    \ to note that security \nis one of the primary concerns with the IoT. There \n\
    is a potential for hackers to gain access to IoT \ndevices which are constantly\
    \ connected to the \ninternet. \n Privacy concerns: Another concern is the privacy\
    \ \nof data. IoT devices may capture a plethora of \ninformation about individuals\
    \ and their actions. \nThere is a possibility that this information could be \n\
    used to follow individuals or compromise their \nprivacy. \n Reliability: One\
    \ of the most challenging aspects of \nIoT network is the reliability of data.\
    \ IoT devices \ncan malfunction or lose data. This data may not be \nbacked up\
    \ and could be lost forever.  \n Lack of standardizations: The major limitation\
    \ of \nIoT cloud integration is the lack of standardization. \nThere is no such\
    \ standard protocol that fits to all \nsolution for integrating IoT devices and\
    \ data into \nthe cloud. Each cloud provider has their own \nproprietary solution,\
    \ which makes it difficult to \nintegrate multiple IoT devices and platforms.\
    \ In \naddition, many IoT devices are not compatible \nwith standard cloud technologies,\
    \ which further \ncomplicates integration. \n Dependence \non \ninternet: \n\
    IoT \ndevices \nare \ndependent on the internet for data transmission. If \nthere\
    \ is no internet connection, the devices will not \nbe able to function properly.\
    \ \n Cost: The IoT and cloud computing integration \ncan be costly, as organizations\
    \ need to invest in \nhardware, software, and services. \n Complexity: The convergence\
    \ of IoT with cloud \ncomputing might be complex since it requires for \nthe deployment\
    \ of a \nvariety of different \ntechnologies. \n \nA complete list of abbreviations\
    \ is shown in \nAppendix I. \n \n9.Conclusion and future directions \nAs the IoT\
    \ continues to grow in popularity, so does \nthe need for efficient and reliable\
    \ cloud integration \nsolutions. In light of systematic literature reviews \n\
    (SLRs), the integration of IoT devices with cloud-\nbased applications has emerged\
    \ as an attractive \napproach. This article is intended to provide an \nassessment\
    \ of the current status of IoT and cloud \nintegration, including a review of\
    \ available SLR \ntools, middlewares and platforms. Despite the \npotential of\
    \ cloud integration for IoT, there are still \nseveral significant challenges\
    \ to be overcome. First, \nthe development of IoT cloud integration solutions\
    \ is \nstill in its early stages, and there is a lack of mature \nand robust tools\
    \ and platforms. Second, the use of \nIoT cloud integration solutions often requires\
    \ a \nsignificant amount of manual effort, which can be \ntime-consuming and error-prone.\
    \ As part of this \nstudy, we aim to investigate various aspects of cloud \nManzoor\
    \ Ansari et al. \n1840 \n \ncomputing and the IoT, as well as advantages and \n\
    limitations of a synergistic approach. The PRISMA \nmethod has been used for a\
    \ systematic literature \nreview. Literature identification and relevant articles\
    \ \ninclusion and exclusion have been made using the \nPRISMA technique. The Bibliometric\
    \ networks \nmethod, such as co-authorship analysis, and term co-\noccurrence,\
    \ has been used to analyze the literature. \nThe IoT powered by the cloud is paving\
    \ the way for \nnew \nbusiness \nopportunities \nand \nresearch \nopportunities.\
    \ \n \nIn the future, we believe that IoT cloud integration \nsolutions will become\
    \ more mature and robust and \nthat they will be increasingly used to integrate\
    \ IoT \ndevices with cloud-based applications.  \n \nThe future of IoT cloud integration\
    \ is looking \npromising with the advent of new technologies, \nincluding edge\
    \ computing, Big Data, blockchain, \nindustrial 5.0, 5G, and AI, the possibilities\
    \ for IoT \napplications are endless. In the near future, we can \nexpect to see\
    \ more IoT devices and applications \nbeing integrated into the cloud. This will\
    \ enable more \ndata to be gathered and processed, resulting in \nimproved \n\
    decision-making \nand \nmore \nefficient \noperations. Our research has revealed\
    \ that the \ncombination of these technologies could lead to new \nopportunities\
    \ for practitioners and researchers. \n \nAcknowledgment \nThe authors would like\
    \ to thank the Ministry of Minority \nAffairs, Government of India, for providing\
    \ financial \nassistance to the first author under its Maulana Azad \nNational\
    \ Fellowship (MANF) scheme. \n \nConflicts of interest \nThe authors have no conflicts\
    \ of interest to declare. \n \nAuthor’s contribution statement \nManzoor Ansari\
    \ : Conceptualization, investigation, data \ncuration, \nwriting-original \ndraft,\
    \ \nwriting-review \nand \nediting. Syed Arshad Ali : Data collection, analysis\
    \ and \ninterpretation of results. Mansaf Alam : Study conception, \ndesign, supervision,\
    \ investigation on challenges and draft \nmanuscript preparation. \n \nReferences\
    \ \n[1] Stergiou C, Psannis KE, Kim BG, Gupta B. Secure \nintegration of IoT and\
    \ cloud computing. Future \nGeneration Computer Systems. 2018; 78:964-75. \n[2]\
    \ Mahdavinejad MS, Rezvan M, Barekatain M, Adibi P, \nBarnaghi P, Sheth AP. Machine\
    \ learning for internet \nof \nthings \ndata \nanalysis: \na \nsurvey. \nDigital\
    \ \nCommunications and Networks. 2018; 4(3):161-75. \n[3] Mocrii D, Chen Y, Musilek\
    \ P. IoT-based smart \nhomes: a review of system architecture, software, \ncommunications,\
    \ privacy and security. Internet of \nThings. 2018; 1:81-98. \n[4] https://www.insiderintelligence.com/insights/internet-\n\
    of-things-devices-\nexamples/#:~:text=Insider%20Intelligence%20forecas\nts%203.74%20billion,some%20specific%20devices%\n\
    20and%20examples. Accessed 14 October 2022. \n[5] Gubbi J, Buyya R, Marusic S,\
    \ Palaniswami M. \nInternet of things (IoT): a vision, architectural \nelements,\
    \ and future directions. Future Generation \nComputer Systems. 2013; 29(7):1645-60.\
    \ \n[6] Patel KK, Patel SM, Scholar P. Internet of things-IoT: \ndefinition, \n\
    characteristics, \narchitecture, \nenabling \ntechnologies, \napplication \n&\
    \ \nfuture \nchallenges. \nInternational Journal of Engineering Science and \n\
    Computing. 2016; 6(5): 6122-31. \n[7] Viriyasitavat W, Anuphaptrirong T, Hoonsopon\
    \ D. \nWhen \nblockchain \nmeets \nInternet \nof \nthings: \ncharacteristics,\
    \ challenges, and business opportunities. \nJournal of Industrial Information\
    \ Integration. 2019; \n15:21-8. \n[8] Aazam M, Khan I, Alsaffar AA, Huh EN. Cloud\
    \ of \nthings: integrating internet of things and cloud \ncomputing and the issues\
    \ involved. In proceedings of \n11th international Bhurban conference on applied\
    \ \nsciences & technology Islamabad, Pakistan 2014 (pp. \n414-9). IEEE. \n[9]\
    \ Khan S, Shakil KA, Alam M. Cloud-based big data \nanalytics—a survey of current\
    \ research and future \ndirections. Big Data Analytics. 2018: 595-604. \n[10]\
    \ Ali SA, Affan M, Alam M. A study of efficient energy \nmanagement \ntechniques\
    \ \nfor \ncloud \ncomputing \nenvironment. In 9th international conference on\
    \ cloud \ncomputing, data science & engineering (confluence) \n2019 (pp. 13-8).\
    \ IEEE. \n[11] Fang J, Ma A. IoT application modules placement and \ndynamic task\
    \ processing in edge-cloud computing. \nIEEE Internet of Things Journal. 2020;\
    \ 8(16):12771-\n81. \n[12] Wang L, Von LG, Younge A, He X, Kunze M, Tao J, \n\
    et al. Cloud computing: a perspective study. New \nGeneration Computing. 2010;\
    \ 28(2):137-46. \n[13] Jiang J, Li Z, Tian Y, Al-nabhan N. A review of \ntechniques\
    \ and methods for IoT applications in \ncollaborative cloud-fog environment. Security\
    \ and \nCommunication Networks. 2020; 2020:1-15. \n[14] https://www.oxfordlearnersdictionaries.com/definition\n\
    /english/internet-of \nthings#:~:text=%5Bsingular%5D,enabling%20them%\n20to%20share%20data.\
    \ Accessed 14 October 2022. \n[15] Paul B. Internet of things (IoT), three-layer\
    \ \narchitecture, security issues and counter measures. In \nICT analysis and\
    \ applications 2022 (pp. 23-34). \nSpringer, Singapore. \n[16] Al-qaseemi SA,\
    \ Almulhim HA, Almulhim MF, \nChaudhry SR. IoT architecture challenges and issues:\
    \ \nlack of standardization. In future technologies \nconference 2016 (pp. 731-8).\
    \ IEEE. \nInternational Journal of Advanced Technology and Engineering Exploration,\
    \ Vol 9(97)                                 \n1841          \n \n[17] https://www.scc.com/insights/it-solutions/data-centre\
    \ \nmodernisation/the-three-layers-of-computing-cloud-\nfog-and-edge. Accessed\
    \ 14 October 2022. \n[18] Kolhar M, Al-turjman F, Alameen A, Abualhaj MM. \nA\
    \ \nthree \nlayered \ndecentralized \nIoT \nbiometric \narchitecture for city\
    \ lockdown during COVID-19 \noutbreak. IEEE Access. 2020; 8:163608-17. \n[19]\
    \ Mrabet H, Belguith S, Alhomoud A, Jemai A. A \nsurvey of IoT security based\
    \ on a layered architecture \nof sensing and data analysis. Sensors. 2020; 20(13):1-\n\
    19. \n[20] Ramya R, Ramamoorthy S. Survey on edge \nintelligence \nin \nIoT-based\
    \ \ncomputing \nplatform. \nAmbient Communications and Computer Systems. \n2022:\
    \ 549-61. \n[21] Mell P, Grance T. The NIST definition of cloud \ncomputing. NIST\
    \ Special Publication. 2011:1-3. \n[22] Armbrust M, Fox A, Griffith R, Joseph\
    \ AD, Katz R, \nKonwinski A, et al. A view of cloud computing. \nCommunications\
    \ of the ACM. 2010; 53(4):50-8. \n[23] Khan S, Ali SA, Hasan N, Shakil KA, Alam\
    \ M. Big \ndata scientific workflows in the cloud: challenges and \nfuture prospects.\
    \ Cloud Computing for Geospatial Big \nData Analytics. 2019:1-28. \n[24] Gong\
    \ C, Liu J, Zhang Q, Chen H, Gong Z. The \ncharacteristics \nof \ncloud \ncomputing.\
    \ \nIn \n39th \ninternational \nconference \non \nparallel \nprocessing \nworkshops\
    \ 2010 (pp. 275-9). IEEE. \n[25] Rashid \nA, \nChaturvedi \nA. \nCloud \ncomputing\
    \ \ncharacteristics \nand \nservices: \na \nbrief \nreview. \nInternational Journal\
    \ of Computer Sciences and \nEngineering. 2019; 7(2):421-6. \n[26] Moghaddam FF,\
    \ Rohani MB, Ahmadi M, Khodadadi \nT, Madadipouya K. Cloud computing: vision,\
    \ \narchitecture and characteristics. In IEEE control and \nsystem graduate research\
    \ colloquium 2015 (pp. 1-6). \nIEEE. \n[27] Ali SA, Alam M. A relative study of\
    \ task scheduling \nalgorithms in cloud computing environment. In 2nd \ninternational\
    \ conference on contemporary computing \nand informatics 2016 (pp. 105-11). IEEE.\
    \ \n[28] Shakil \nKA, \nAlam \nM. \nCloud \ncomputing \nin \nbioinformatics and\
    \ big data analytics: current status \nand future research. In big data analytics\
    \ 2018 (pp. \n629-40). Springer, Singapore. \n[29] Cao K, Liu Y, Meng G, Sun Q.\
    \ An overview on edge \ncomputing research. IEEE Access. 2020; 8:85714-28. \n\
    [30] Shi W, Cao J, Zhang Q, Li Y, Xu L. Edge computing: \nvision and challenges.\
    \ IEEE Internet of Things \nJournal. 2016; 3(5):637-46. \n[31] Zhao Z, Lin P,\
    \ Shen L, Zhang M, Huang GQ. IoT \nedge computing-enabled collaborative tracking\
    \ system \nfor manufacturing resources in industrial park. \nAdvanced Engineering\
    \ Informatics. 2020; 43:1-12. \n[32] Papcun P, Kajati E, Cupkova D, Mocnej J,\
    \ Miskuf M, \nZolotova I. Edge‐enabled IoT gateway criteria \nselection \nand\
    \ \nevaluation. \nConcurrency \nand \nComputation: \nPractice \nand \nExperience.\
    \ \n2020; \n32(13):1-9. \n[33] Alrawahi AS, Lee K, Lotfi A. Trading of cloud of\
    \ \nthings resources. In proceedings of the second \ninternational conference\
    \ on internet of things, data and \ncloud computing 2017 (pp. 1-7). ACM. \n[34]\
    \ Gannon D, Barga R, Sundaresan N. Cloud-native \napplications. IEEE Cloud Computing.\
    \ 2017; 4(5):16-\n21. \n[35] Li KC, Gupta BB, Agrawal DP. Recent advances in \n\
    security, privacy, and trust for internet of things (IoT) \nand cyber-physical\
    \ systems (CPS). CRC Press; 2021. \n[36] Kapoor S, Panda SN. Integrating cloud\
    \ with IoT-cloud \nIoT. In real-life applications of the internet of things \n\
    2022 (pp. 273-93). Apple Academic Press. \n[37] Fortino G, Guerrieri A, Savaglio\
    \ C, Spezzano G. A \nreview of internet of things platforms through the IoT-\n\
    A reference architecture. In international symposium \non intelligent and distributed\
    \ computing 2022 (pp. 25-\n34). Springer, Cham. \n[38] Hou L, Zhao S, Xiong X,\
    \ Zheng K, Chatzimisios P, \nHossain MS, et al. Internet of things cloud: \narchitecture\
    \ \nand \nimplementation. \nIEEE \nCommunications Magazine. 2016; 54(12):32-9.\
    \ \n[39] Asghari P, Rahmani AM, Javadi HH. Internet of \nthings applications:\
    \ a systematic review. Computer \nNetworks. 2019; 148:241-61. \n[40] Shukla S,\
    \ Hassan M, Tran DC, Akbar R, Paputungan \nIV, Khan MK. Improving latency in internet-of-things\
    \ \nand cloud computing for real-time data transmission: a \nsystematic literature\
    \ review. Cluster Computing. \n2021:1-24. \n[41] Kotha HD, Gupta VM. IoT application:\
    \ a survey. \nInternational Journal of Engineering & Technology. \n2018; 7(2.7):891-6.\
    \ \n[42] Botta A, De DW, Persico V, Pescapé A. Integration of \ncloud computing\
    \ and internet of things: a survey. \nFuture Generation Computer Systems. 2016;\
    \ 56:684-\n700. \n[43] Díaz M, Martín C, Rubio B. State-of-the-art, \nchallenges,\
    \ and open issues in the integration of \ninternet of things and cloud computing.\
    \ Journal of \nNetwork and Computer Applications. 2016; 67:99-\n117. \n[44] Dang\
    \ LM, Piran MJ, Han D, Min K, Moon H. A \nsurvey on internet of things and cloud\
    \ computing for \nhealthcare. Electronics. 2019; 8(7):1-49. \n[45] Malik A, Om\
    \ H. Cloud computing and internet of \nthings integration: architecture, applications,\
    \ issues, \nand challenges. In sustainable cloud and energy \nservices 2018 (pp.\
    \ 1-24). Springer, Cham. \n[46] Amairah A, Al-tamimi BN, Anbar M, Aloufi K. Cloud\
    \ \ncomputing and internet of things integration systems: \na review. In international\
    \ conference of reliable \ninformation and communication technology 2018 (pp.\
    \ \n406-14). Springer, Cham. \n[47] Atlam HF, Alenezi A, Alharthi A, Walters RJ,\
    \ Wills \nGB. Integration of cloud computing with internet of \nthings: challenges\
    \ and open issues. In international \nconference on internet of things (iThings)\
    \ and green \ncomputing and communications (GreenCom) and \nManzoor Ansari et\
    \ al. \n1842 \n \ncyber, physical and social computing (CPSCom) and \nsmart data\
    \ (SmartData) 2017 (pp. 670-5). IEEE. \n[48] Cavalcante E, Pereira J, Alves MP,\
    \ Maia P, Moura R, \nBatista T, et al. On the interplay of internet of things\
    \ \nand cloud computing: a systematic mapping study. \nComputer Communications.\
    \ 2016; 89:17-33. \n[49] Selçuk AA. A guide for systematic reviews: PRISMA. \n\
    Turkish Archives of Otorhinolaryngology. 2019; \n57(1):57-8. \n[50] Moher D, Liberati\
    \ A, Tetzlaff J, Altman DG. Reprint-\npreferred reporting items for systematic\
    \ reviews and \nmeta-analyses: the PRISMA statement. Physical \nTherapy. 2009;\
    \ 89(9):873-80. \n[51] Pilkington A, Meredith J. The evolution of the \nintellectual\
    \ structure of operations management-1980–\n2006: a citation/co-citation analysis.\
    \ Journal of \nOperations Management. 2009; 27(3):185-202. \n[52] Garfield E.\
    \ From the science of science to \nscientometrics visualizing the history of science\
    \ with \nHistCite software. Journal of Informetrics. 2009; \n3(3):173-9. \n[53]\
    \ Gmür M. Co-citation analysis and the search for \ninvisible colleges: a methodological\
    \ evaluation. \nScientometrics. 2003; 57(1):27-57. \n[54] Osareh F. Bibliometrics,\
    \ citation analysis and co-\ncitation analysis: a review of literature I. LIBRI.\
    \ 1996; \n46(3):149-58. \n[55] Van EN, Waltman L. Software survey: VOSviewer,\
    \ a \ncomputer \nprogram \nfor \nbibliometric \nmapping. \nScientometrics. 2010;\
    \ 84(2):523-38. \n[56] Pflanzner T, Kertész A. A taxonomy and survey of \nIoT\
    \ cloud applications. EAI Endorsed Transactions on \nInternet of Things. 2018;\
    \ 3(12):1-14. \n[57] Nancy AA, Ravindran D, Raj VPD, Srinivasan K, \nGutierrez\
    \ RD. IoT-cloud-based smart healthcare \nmonitoring system for heart disease prediction\
    \ via \ndeep learning. Electronics. 2022; 11(15):1-19. \n[58] Singh PD, Dhiman\
    \ G, Sharma R. Internet of things for \nsustaining a smart and secure healthcare\
    \ system. \nSustainable Computing: Informatics and Systems. \n2022. \n[59] Sahay\
    \ MR, Sukumaran MK, Amarnath S, Palani TN. \nEnvironmental monitoring system using\
    \ IoT and cloud \nservice at real-time. EasyChair Preprint. 2019; \n5(968):1-8.\
    \ \n[60] Helal AA, Villaça RS, Santos CA, Colistete JR. An \nintegrated solution\
    \ of software and hardware for \nenvironmental monitoring. Internet of Things.\
    \ 2022. \n[61] Lova RK, Vijayaraghavan V. A self-powered, real-\ntime, NRF24L01\
    \ IoT-based cloud-enabled service for \nsmart agriculture decision-making system.\
    \ Wireless \nPersonal Communications. 2022; 124(1):207-36. \n[62] Quy VK, Hau\
    \ NV, Anh DV, Quy NM, Ban NT, Lanza \nS, et al. IoT-enabled smart agriculture:\
    \ architecture, \napplications, and challenges. Applied Sciences. 2022; \n12(7):1-19.\
    \ \n[63] Liu C, Ke L. Cloud assisted internet of things \nintelligent transportation\
    \ system and the traffic control \nsystem in the smart city. Journal of Control\
    \ and \nDecision. 2022:1-14. \n[64] Jiang D. The construction of smart city information\
    \ \nsystem based on the internet of things and cloud \ncomputing. \nComputer \n\
    Communications. \n2020; \n150:158-66. \n[65] Haghnegahdar L, Joshi SS, Dahotre\
    \ NB. From IoT-\nbased cloud manufacturing approach to intelligent \nadditive\
    \ manufacturing: industrial internet of things-an \noverview. The International\
    \ Journal of Advanced \nManufacturing Technology. 2022; 119:1461-78. \n[66] Sigov\
    \ A, Ratkin L, Ivanov LA, Xu LD. Emerging \nenabling technologies for industry\
    \ 4.0 and beyond. \nInformation Systems Frontiers. 2022:1-11. \n[67] Hu JX, Chen\
    \ CL, Fan CL, Wang KH. An intelligent \nand secure health monitoring scheme using\
    \ IoT sensor \nbased on cloud computing. Journal of Sensors. 2017; \n2017:1-12.\
    \ \n[68] Nasser N, Emad-ul-haq Q, Imran M, Ali A, Razzak I, \nAl-helali A. A smart\
    \ healthcare framework for \ndetection and monitoring of COVID-19 using IoT and\
    \ \ncloud \ncomputing. \nNeural \nComputing \nand \nApplications. 2021:1-15. \n\
    [69] Bao Y, Qiu W, Tang P, Cheng X. Efficient, revocable, \nand privacy-preserving\
    \ fine-grained data sharing with \nkeyword search for the cloud-assisted medical\
    \ IoT \nsystem. IEEE Journal of Biomedical and Health \nInformatics. 2021; 26(5):2041-51.\
    \ \n[70] Farid F, Elkhodr M, Sabrina F, Ahamed F, Gide E. A \nsmart biometric\
    \ identity management framework for \npersonalised \nIoT \nand \ncloud \ncomputing-based\
    \ \nhealthcare services. Sensors. 2021; 21(2):1-18. \n[71] Anuradha M, Jayasankar\
    \ T, Prakash NB, Sikkandar \nMY, Hemalakshmi GR, Bharatiraja C, et al. IoT \n\
    enabled cancer prediction system to enhance the \nauthentication and security\
    \ using cloud computing. \nMicroprocessors and Microsystems. 2021; 80:1-23. \n\
    [72] Ming FX, Habeeb RA, Md NFH, Gani AB. Real-time \ncarbon dioxide monitoring\
    \ based on IoT & cloud \ntechnologies. In proceedings of the 8th international\
    \ \nconference on software and computer applications \n2019 (pp. 517-21). \n[73]\
    \ Singh R, Gaur N, Bathla S. IoT based air pollution \nmonitoring device using\
    \ raspberry pi and cloud \ncomputing. In 4th international conference on \nelectronics,\
    \ communication and aerospace technology \n2020 (pp. 702-7). IEEE. \n[74] Mi J,\
    \ Sun X, Zhang S, Liu N. Residential environment \npollution \nmonitoring \nsystem\
    \ \nbased \non \ncloud \ncomputing and internet of things. International Journal\
    \ \nof Analytical Chemistry. 2022; 2022:1-8. \n[75] Phasinam K, Kassanuk T, Shinde\
    \ PP, Thakar CM, \nSharma DK, Mohiddin M, et al. Application of IoT \nand cloud\
    \ computing in automation of agriculture \nirrigation. Journal of Food Quality.\
    \ 2022; 2022:1-8. \n[76] Uddin MA, Dey UK, Tonima SA, Tusher TI. An IoT-\nbased\
    \ cloud solution for intelligent integrated rice-fish \nfarming using wireless\
    \ sensor networks and sensing \nmeteorological parameters. In IEEE 12th annual\
    \ \ncomputing \nand \ncommunication \nworkshop \nand \nconference 2022 (pp. 568-73).\
    \ IEEE. \nInternational Journal of Advanced Technology and Engineering Exploration,\
    \ Vol 9(97)                                 \n1843          \n \n[77] Namee K,\
    \ Kamjumpol C, Pimsiri W. Development of \nsmart vegetable growing cabinet with\
    \ IoT, edge \ncomputing and cloud computing. In 2nd international \nconference\
    \ on image processing and machine vision \n2020 (pp. 47-52). \n[78] Hundera NW,\
    \ Jin C, Geressu DM, Aftab MU, \nOlanrewaju OA, Xiong H. Proxy-based public-key\
    \ \ncryptosystem for secure and efficient IoT-based cloud \ndata sharing in the\
    \ smart city. Multimedia Tools and \nApplications. 2022; 81(21):29673-97. \n[79]\
    \ Hojjati A, Nasar W, Mishra D, Alaliyat S, Hameed IA. \nCloud-based smart IoT\
    \ sustainable solution for waste \nsorting and management. In international symposium\
    \ \non system integration 2022 (pp. 218-24). IEEE. \n[80] Hussain MA, Nikhil K,\
    \ Kalyan KY. IoT based smart \ndustbin monitoring with tracking system using atmega\
    \ \n2560 \nmicrocontroller. \nIn \nfifteenth \ninternational \nconference on information\
    \ processing 2019 (pp. 1-6). \nIEEE. \n[81] Garbugli A, Sabbioni A, Corradi A,\
    \ Bellavista P. \nTEMPOS: QoS management middleware for edge \ncloud computing\
    \ FaaS in the internet of things. IEEE \nAccess. 2022; 10:49114-27. \n[82] Qader\
    \ G, Junaid M, Abbas Q, Mubarik MS. Industry \n4.0 enables supply chain resilience\
    \ and supply chain \nperformance. Technological Forecasting and Social \nChange.\
    \ 2022. \n[83] Venticinque S, Amato A. A methodology for \ndeployment of IoT application\
    \ in fog. Journal of \nAmbient Intelligence and Humanized Computing. \n2019; 10(5):1955-76.\
    \ \n[84] Kim S, Kim S. User preference for an IoT healthcare \napplication \n\
    for \nlifestyle \ndisease \nmanagement. \nTelecommunications Policy. 2018; 42(4):304-14.\
    \ \n[85] Jimenez F, Torres R. Building an IoT-aware \nhealthcare monitoring system.\
    \ In 34th international \nconference of the Chilean computer science society \n\
    2015 (pp. 1-4). IEEE. \n[86] Suciu G, Suciu V, Martian A, Craciunescu R, Vulpe\
    \ \nA, Marcu I, et al. Big data, internet of things and cloud \nconvergence–an\
    \ architecture for secure e-health \napplications. Journal of Medical Systems.\
    \ 2015; \n39(11):1-8. \n[87] Alshammari H, El-ghany SA, Shehab A. Big IoT \nhealthcare\
    \ data analytics framework based on fog and \ncloud computing. Journal of Information\
    \ Processing \nSystems. 2020; 16(6):1238-49. \n[88] Firouzi F, Farahani B, Marinšek\
    \ A. The convergence \nand interplay of edge, fog, and cloud in the AI-driven\
    \ \ninternet of things (IoT). Information Systems. 2022. \n[89] Arvaree T, Perumal\
    \ T. IoT based car pollution \ndetection using cloud computing. International\
    \ Journal \nof Environmental Science and Development. 2021; \n12(8):226-31. \n\
    [90] Li H, Wang H, Yin W, Li Y, Qian Y, Hu F. \nDevelopment of a remote monitoring\
    \ system for \nhenhouse environment based on IoT technology. \nFuture Internet.\
    \ 2015; 7(3):329-41. \n[91] Kim NS, Lee K, Ryu JH. Study on IoT based wild \n\
    vegetation community ecological monitoring system. \nIn seventh international\
    \ conference on ubiquitous and \nfuture networks 2015 (pp. 311-6). IEEE. \n[92]\
    \ Asha P, Natrayan LB, Geetha BT, Beulah JR, \nSumathy R, Varalakshmi G, et al.\
    \ IoT enabled \nenvironmental toxicology for air pollution monitoring \nusing\
    \ AI techniques. Environmental Research. 2022. \n[93] Qian X, Wang X. Content-centric\
    \ IoT-based air \npollution \nmonitoring. \nWireless \nPersonal \nCommunications.\
    \ 2022; 123(4):3213-22. \n[94] Misra NN, Dixit Y, Al-mallahi A, Bhullar MS, \n\
    Upadhyay R, Martynenko A. IoT, big data and \nartificial intelligence in agriculture\
    \ and food industry. \nIEEE Internet of Things Journal. 2020; 9(9):1-19. \n[95]\
    \ Perumal MS, Manimozhi B, Dandamudi H, Durairaj \nVB, Jawaharlalnehru A. Ultra-reliable\
    \ low latency \ncommunication technique for agriculture wireless \nsensor networks.\
    \ Arabian Journal of Geosciences. \n2021; 14(13):1-9. \n[96] Mekala MS, Viswanathan\
    \ P. A novel technology for \nsmart agriculture based on IoT with cloud computing.\
    \ \nIn international conference on I-SMAC (IoT in social, \nmobile, analytics\
    \ and cloud) (I-SMAC) 2017 (pp. 75-\n82). IEEE. \n[97] Liu S, Guo L, Webb H, Ya\
    \ X, Chang X. Internet of \nthings monitoring system of modern eco-agriculture\
    \ \nbased on cloud computing. IEEE Access. 2019; \n7:37050-8. \n[98] Aiswarya\
    \ A, Anantapalli R, Singh R, Nandhini S. \nDetection and regulation of soil moisture\
    \ and nutrients \nusing cloud computing and internet of things in \nagriculture.\
    \ Journal of Computational and Theoretical \nNanoscience. 2019; 16(8):3183-6.\
    \ \n[99] Rathor S, Kumari S. Smart agriculture system using \nIoT and cloud computing.\
    \ In 5th international \nconference on information systems and computer \nnetworks\
    \ 2021 (pp. 1-4). IEEE. \n[100] Montori F, Bedogni L, Bononi L. A collaborative\
    \ \ninternet of things architecture for smart cities and \nenvironmental monitoring.\
    \ IEEE Internet of Things \nJournal. 2017; 5(2):592-605. \n[101] Zia T, Liu P,\
    \ Han W. Application-specific digital \nforensics investigative model in internet\
    \ of things \n(IoT). In proceedings of the 12th international \nconference on\
    \ availability, reliability and security \n2017 (pp. 1-7). \n[102] Distefano S,\
    \ Longo F, Scarpa M. QoS assessment of \nmobile crowdsensing services. Journal\
    \ of Grid \nComputing. 2015; 13(4):629-50. \n[103] Zeng X, Garg SK, Strazdins\
    \ P, Jayaraman PP, \nGeorgakopoulos D, Ranjan R. IOT sim: a simulator \nfor analysing\
    \ IoT applications. Journal of Systems \nArchitecture. 2017; 72:93-107. \n[104]\
    \ Duttagupta S, Kumar M, Ranjan R, Nambiar M. \nPerformance prediction of IoT\
    \ application: an \nexperimental analysis. In proceedings of the 6th \ninternational\
    \ conference on the internet of things 2016 \n(pp. 43-51). ACM. \n[105] Chen S,\
    \ Liu B, Chen X, Zhang Y, Huang G. \nFramework for adaptive computation offloading\
    \ in \nIoT applications. In proceedings of the 9th Asia-\nManzoor Ansari et al.\
    \ \n1844 \n \nPacific symposium on internetware 2017 (pp. 1-6). \nACM. \n[106]\
    \ Lee C, Wang C, Kim E, Helal S. Blueprint flow: a \ndeclarative service composition\
    \ framework for cloud \napplications. IEEE Access. 2017; 5:17634-43. \n[107] Akbar\
    \ A, Kousiouris G, Pervaiz H, Sancho J, Ta-\nshma P, Carrez F, et al. Real-time\
    \ probabilistic data \nfusion for large-scale IoT applications. IEEE Access. \n\
    2018; 6:10015-27. \n[108] [108]Sun X, Ansari N. Traffic load balancing among \n\
    brokers \nat \nthe \nIoT \napplication \nlayer. \nIEEE \nTransactions on Network\
    \ and Service Management. \n2017; 15(1):489-502. \n[109] Pustišek M, Kos A. Approaches\
    \ to front-end IoT \napplication development for the ethereum blockchain. \nProcedia\
    \ Computer Science. 2018; 129:410-9. \n[110] Alodib \nM. \nQoS-Aware \napproach\
    \ \nto \nmonitor \nviolations of SLAs in the IoT. Journal of Innovation in \n\
    Digital Ecosystems. 2016; 3(2):197-207. \n[111] Han SN, Crespi N. Semantic service\
    \ provisioning for \nsmart objects: integrating IoT applications into the \nweb.\
    \ Future Generation Computer Systems. 2017; \n76:180-97. \n[112] Huo Y, Qiu P,\
    \ Zhai J, Fan D, Peng H. Multi-\nobjective service composition model based on\
    \ cost-\neffective optimization. Applied Intelligence. 2018; \n48(3):651-69. \n\
    [113] Huo L, Wang Z. Service composition instantiation \nbased on cross-modified\
    \ artificial bee colony \nalgorithm. China Communications. 2016; 13(10):233-\n\
    44. \n[114] Temglit N, Chibani A, Djouani K, Nacer MA. A \ndistributed agent-based\
    \ approach for optimal QoS \nselection in web of object choreography. IEEE \n\
    Systems Journal. 2017; 12(2):1655-66. \n[115] De DM, Giaretta A, Dragoni N, Bucchiarone\
    \ A, \nMazzara M. Cyber-storms come from clouds: security \nof cloud computing\
    \ in the IoT era. Future Internet. \n2019; 11(6):1-30. \n[116] Rath M, Satpathy\
    \ J, Oreku GS. Artificial intelligence \nand machine learning applications in\
    \ cloud computing \nand internet of things. In artificial intelligence to solve\
    \ \npervasive internet of things issues 2021 (pp. 103-23). \nAcademic Press. \n\
    [117] Farahzadi A, Shams P, Rezazadeh J, Farahbakhsh R. \nMiddleware technologies\
    \ for cloud of things: a survey. \nDigital \nCommunications \nand \nNetworks.\
    \ \n2018; \n4(3):176-88. \n[118] Sethi P, Sarangi SR. Internet of things: architectures,\
    \ \nprotocols, and applications. Journal of Electrical and \nComputer Engineering.\
    \ 2017; 2017:1-26. \n[119] Sonkoly B, Haja D, Németh B, Szalay M, Czentye J, \n\
    Szabó R, et al. Scalable edge cloud platforms for IoT \nservices. \nJournal \n\
    of \nNetwork \nand \nComputer \nApplications. 2020; 170:1-18. \n[120] Ray PP.\
    \ A survey of IoT cloud platforms. Future \nComputing and Informatics Journal.\
    \ 2016; 1(1-2):35-\n46. \n[121] Hoffmann JB, Heimes P, Senel S. IoT platforms\
    \ for \nthe internet of production. IEEE Internet of Things \nJournal. 2018; 6(3):4098-105.\
    \ \n[122] Ray PP, Kumar N. SDN/NFV architectures for edge-\ncloud oriented IoT:\
    \ a systematic review. Computer \nCommunications. 2021; 169:129-53. \n[123] Lu\
    \ Y, Xu X. Cloud-based manufacturing equipment \nand big data analytics to enable\
    \ on-demand \nmanufacturing services. Robotics and Computer-\nIntegrated Manufacturing.\
    \ 2019; 57:92-102. \n[124] Alam M, Ara K, Javed MS, Ansari M. Detect and \nfilter\
    \ traffic attack through cloud trace back and neural \nnetwork, imperial college.\
    \ In the 2014 international \nconference of data mining and knowledge engineering\
    \ \nLondon, UK 2014 (pp. 2-4). \n[125] Noura \nM, \nAtiquzzaman \nM, \nGaedke\
    \ \nM. \nInteroperability in internet of things: taxonomies and \nopen challenges.\
    \ Mobile Networks and Applications. \n2019; 24(3):796-809. \n[126] Gill SS, Tuli\
    \ S, Xu M, Singh I, Singh KV, Lindsay \nD, et al. Transformative effects of IoT,\
    \ blockchain and \nartificial intelligence on cloud computing: evolution, \nvision,\
    \ trends and open challenges. Internet of Things. \n2019; 8:1-33. \n[127] Adi\
    \ E, Anwar A, Baig Z, Zeadally S. Machine \nlearning and data analytics for the\
    \ IoT. Neural \nComputing and Applications. 2020; 32(20):16205-33. \n[128] Savaglio\
    \ C, Fortino G, Gravina R, Russo W. A \nmethodology for integrating internet of\
    \ things \nplatforms. In IEEE international conference on cloud \nengineering\
    \ 2018 (pp. 317-22). IEEE. \n \nManzoor Ansari received his Master’s \nDegree\
    \ from Jamia Millia Islamia. He \nis \ncurrently \npursuing \nPh.D. \nin \nComputer\
    \ Science from Jamia Millia \nIslamia. He has also qualified UGC, \nNational \
    \ Eligibility Test (NET) and \nGATE. \nMoreover, \nhe \nhas \nbeen \npresented\
    \ \nseveral \narticles \nin \ninternatonal conferneces. He also reviewed many\
    \ research \narticles of reputed journals and conferences. His research \ninterests\
    \ including Internet of Things (IoT) and Cloud \nComputing Integration in real-world\
    \ applications. He is \nalso working on Environment Monitoring, Time-Series \n\
    Analysis and Machine Learning Techniques. \nEmail: manzoor188469@st.jmi.ac.in\
    \ \n \nSyed Arshad Ali received his Bachelor \nof Computer Application (BCA) degree\
    \ \nfrom  C.S.J.M. University in Kanpur \nand \nhis \nMaster \nof \nComputer \n\
    Application (MCA)  degree from Jamia \nHamdard in New Delhi. He has also \nqualified\
    \ UGC, National  Eligibility \nTest (NET) with JRF. In addition to \njournal articles\
    \ and conference papers,  his publications \ninclude book chapters and book reviews.\
    \ He has also \nreviewed many  research articles of reputed journals and \nconferences.\
    \ In addition to Cloud Computing, Internet of \n \n \nInternational Journal of\
    \ Advanced Technology and Engineering Exploration, Vol 9(97)                 \
    \                \n1845          \n \nThings, and Machine Learning, he is also\
    \ interested in \nother areas of  research. \nEmail: arshad.ali71@gmail.com \n\
    \ \nDr. Mansaf Alam has been working as \na Professor in the Department of \n\
    Computer Science, Faculty of Naturral \nSciences, Jamia Millia Islamia, New \n\
    Delhi-110025, Young Faculty Research \nFellow, DeitY, Govt. of India & Editor-\n\
    in-Chief, \nJournal \nof \nApplied \nInformation Science. He has published \n\
    several research articles in reputed International Journals \nand Proceedings\
    \ at reputed International conferences \npublished by IEEE, Springer, Elsevier\
    \ Science, and ACM. \nHis area of research includes Artificial Intelligence, Big\
    \ \nData Analytics, Machine Learning & Deep Learning, \nCloud Computing, and Data\
    \ Mining. He is a reviewer of \nvarious journals of International repute, like\
    \ Information \nScience, published by Elsevier Science. He is also a \nmember\
    \ of the program committee of various reputed \nInternational conferences. He\
    \ is on the Editorial Board of \nsome reputed Intentional Journals in Computer\
    \ Sciences. \nHe has published three books: Digital Logic Design by \nPHI, Concepts\
    \ of Multimedia by Arihant, and Internet of \nThings: Concepts and Applications\
    \ by Springer, Big Data \nAnalytics: Applications in Business and Marketing, Big\
    \ \nData Analytics: Digital Marketing and Decision Making by \nTaylor and Francis.\
    \ He recently got International Patent \n(Australian) on An Artificial Intelligence\
    \ Based Smart \nDustbin. \nEmail: malam2@jmi.ac.in \n \n \n \n \n \n \n \n \n\
    \ \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nAppendix I \nS. No.\
    \ \nAbbreviations \nDescriptions \n1 \n3G \nThird \nGeneration \nof \nMobile \n\
    Telephony  \n2 \nAES \nAdvanced Encryption Standard \n3 \nAI \nArtificial Intelligence\
    \ \n4 \nAPI \nApplication \nProgramming \nInterface \n5 \nCOAP \nConstrained Application\
    \ Protocol \n6 \nCoT \nCloud of Things \n7 \nCTB \nCloud Trace Back  \n8 \nDBaaS\
    \ \nDatabase as a Service  \n9 \nDBLP \nDatabase and Logic Programming \n10 \n\
    EaaS \nEthernet as a Service  \n11 \nGPRS   \nGeneral Packet Radio Service  \n\
    12 \nGSM \nGlobal \nSystem \nfor \nMobile \nCommunication  \n13 \nIoT \nIntenet\
    \ of Things \n14 \nIIoT \nIndustrial IoT \n15 \nIP \nInternet Protocol \n16 \n\
    IPaaS   \nIntegration Platform as a Service \n17 \nIT \nInformation Technology\
    \ \n18 \nLAN \nLocal Area Network \n19 \nLTE \nLong-Term Evolution  \n20 \nNAT\
    \ \nNetwork Address Translation  \n21 \nNFC \nNear-field Communication  \n22 \n\
    NN \nNeural Networks   \n23 \nPRISMA \nPreferred Reporting Items for \nSystematic\
    \ Reviews and Meta-\nAnalyses \n24 \nQoS \nQuality of Service  \n25 \nREST \n\
    Representational State Transfer \n26 \nRFID \nRadio Frequency Identification \n\
    27 \nSAaaS \nSensor and Actuation as a Service  \n28 \nSaaS  \nSensing as a Service\
    \  \n29 \nSLA \nService-level Agreement \n30 \nSLR   \nSystematic Literature Review\
    \  \n31 \nWoS \nWeb of Science \n32 \nWoT \nWeb of Things    \n \n \n \n"
  inline_citation: '>'
  journal: International journal of advanced technology and engineering exploration
  limitations: '>'
  pdf_link: https://www.accentsjournals.org/PaperDirectory/Journal/IJATEE/2022/12/10.pdf
  publication_year: 2022
  relevance_score1: 0
  relevance_score2: 0
  title: 'Internet of things (IoT) fusion with cloud computing: current research and
    future direction'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.3390/biomimetics8040373
  analysis: '>'
  authors:
  - Abdullah Alabdulatif
  - Navod Neranjan Thilakarathne
  citation_count: 0
  full_citation: '>'
  full_text: ">\nCitation: Alabdulatif, A.;\nThilakarathne, N.N. Bio-Inspired\nInternet\
    \ of Things: Current Status,\nBeneﬁts, Challenges, and Future\nDirections. Biomimetics\
    \ 2023, 8, 373.\nhttps://doi.org/10.3390/\nbiomimetics8040373\nAcademic Editors:\
    \ Heming Jia,\nLaith Abualigah and Xuewen Xia\nReceived: 25 July 2023\nRevised:\
    \ 14 August 2023\nAccepted: 15 August 2023\nPublished: 17 August 2023\nCopyright:\n\
    © 2023 by the authors.\nLicensee MDPI, Basel, Switzerland.\nThis article is an\
    \ open access article\ndistributed\nunder\nthe\nterms\nand\nconditions of the\
    \ Creative Commons\nAttribution (CC BY) license (https://\ncreativecommons.org/licenses/by/\n\
    4.0/).\nbiomimetics\nReview\nBio-Inspired Internet of Things: Current Status,\
    \ Beneﬁts,\nChallenges, and Future Directions\nAbdullah Alabdulatif 1\nand Navod\
    \ Neranjan Thilakarathne 2,*\n1\nDepartment of Computer, College of Sciences and\
    \ Arts in Al-Rass, Qassim University,\nAl-Rass 720223, Saudi Arabia; a.alabdulatif@qu.edu.sa\n\
    2\nDepartment of ICT, Faculty of Technology, University of Colombo, Colombo 00700,\
    \ Sri Lanka\n*\nCorrespondence: navod.neranjan@ict.cmb.ac.lk\nAbstract: There\
    \ is no doubt that the involvement of the Internet of Things (IoT) in our daily\
    \ lives has\nchanged the way we live and interact as a global community, as IoT\
    \ enables intercommunication of\ndigital objects around us, creating a pervasive\
    \ environment. As of now, this IoT is found in almost\nevery domain that is vital\
    \ for human survival, such as agriculture, medical care, transportation, the\n\
    military, and so on. Day by day, various IoT solutions are introduced to the market\
    \ by manufacturers\ntowards making our life easier and more comfortable. On the\
    \ other hand, even though IoT now\nholds a key place in our lives, the IoT ecosystem\
    \ has various limitations in efﬁciency, scalability,\nand adaptability. As such,\
    \ biomimicry, which involves imitating the systems found in nature within\nhuman-made\
    \ systems, appeared to be a potential remedy to overcome such challenges pertaining\n\
    to IoT, which can also be referred to as bio-inspired IoT. In the simplest terms,\
    \ bio-inspired IoT\ncombines nature-inspired principles and IoT to create more\
    \ efﬁcient and adaptive IoT solutions, that\ncan overcome most of the inherent\
    \ challenges pertaining to traditional IoT. It is based on the idea\nthat nature\
    \ has already solved many challenging problems and that, by studying and mimicking\n\
    biological systems, we might develop better IoT systems. As of now, this concept\
    \ of bio-inspired IoT\nis applied to various ﬁelds such as medical care, transportation,\
    \ cyber-security, agriculture, and so on.\nHowever, it is noted that only a few\
    \ studies have been carried out on this new concept, explaining\nhow these bio-inspired\
    \ concepts are integrated with IoT. Thus, to ﬁll in the gap, in this study, we\n\
    provide a brief review of bio-inspired IoT, highlighting how it came into play,\
    \ its ecosystem, its latest\nstatus, beneﬁts, challenges, and future directions.\n\
    Keywords:\nIoT; Internet of Things; bio-inspired IoT; bio-inspired computation;\
    \ bio-inspired\nalgorithms; artiﬁcial intelligence; cyber-security; optimization;\
    \ wireless sensor network\n1. Introduction\nThe proliferation of Information and\
    \ Communication Technologies (ICTs) early in\nthe 21st century has led to a revolution\
    \ in our daily lives in which we are able to perform\nmany tasks that were considered\
    \ difﬁcult with the use of available technologies at that\ntime [1]. Progressively,\
    \ this ICT has given birth to many advanced technologies, of which\nIoT can be\
    \ considered as one such major technology [2–5]. Over the years, this IoT has\
    \ been\nafﬁliated with many of the domains that are deemed important for human\
    \ survival, such\nas agriculture, manufacturing, transportation, and healthcare\
    \ [6–9]. Undoubtedly, as of\nnow, this IoT can be considered a major technology\
    \ that is an essential part of our daily\nlives. Day by day, IoT solutions are\
    \ becoming more closely integrated into our daily lives,\nand such IoT solutions\
    \ are being introduced to the market at a rapid rate. In general, the\nIoT has\
    \ the capability to connect digital devices/objects all around the world and allow\n\
    them to communicate with each other, creating a larger ubiquitous network [10–12].\n\
    Overall, the IoT is an ecosystem of connected devices that communicate with each\n\
    other and exchange data. The integration of the IoT and the worldwide web has\
    \ led to the\nBiomimetics 2023, 8, 373. https://doi.org/10.3390/biomimetics8040373\n\
    https://www.mdpi.com/journal/biomimetics\nBiomimetics 2023, 8, 373\n2 of 29\n\
    creation of new kinds of services and applications in different domains, such\
    \ as real-time\nsurveillance, plant disease diagnosis, remote healthcare, real-time\
    \ disease diagnosis, preci-\nsion agriculture, air quality monitoring, and so\
    \ on [1–5,12–16]. In general, IoT facilitates\nus to connect our digital belongings\
    \ to the worldwide web, anytime, anywhere in the\nworld [17–21], as depicted in\
    \ Figure 1.\nBiomimetics 2023, 8, x FOR PEER REVIEW \n2  of  28 \n \n \ncreation of new kinds of services and applications in different domains, such as real‐time \n\
    surveillance, plant disease diagnosis, remote healthcare, real‐time disease diagnosis, pre‐\n\
    cision agriculture, air quality monitoring, and so on [1–5,12–16]. In general, IoT facilitates \n\
    us to connect our digital belongings to the worldwide web, anytime, anywhere in the \n\
    world [17–21], as depicted in Figure 1. \n \nFigure 1. The IoT ecosystem. \nDay by day, various IoT solutions are being introduced to the market owing to the \n\
    development of underlying infrastructure (e.g., communication facilities, computing fa‐\n\
    cilities) and the increasing technology competency of people. These ever‐growing IoT so‐\n\
    lutions are employed in a variety of domains and offer convenient facilities to the stake‐\n\
    holders engaged in these domains. According to the latest statistics, it is predicted that \n\
    there will be over 100 billion IoT devices by 2025 [5–10]. It is also evident that the IoT \n\
    market size is expected to reach over USD 140 billion by 2030 from USD 12 billion in 2020 \n\
    [5–10]. Overall, the IoT is transforming industries and revolutionizing the way we live \n\
    and work. However, even though IoT is a fast‐growing technology, it is still in its infancy, \n\
    and it will take years to become a stable technology [21–25]. As such, there are several \n\
    drawbacks and challenges associated with the incorporation and implementation of the \n\
    IoT (depicted in Figure 2), which are categorized and highlighted further in the following. \n\
     \nSecurity and privacy   \nSince IoT devices are always connected to the Internet, they can be vulnerable to \n\
    hacking, unauthorized access, and data breaches [10]. Further, weak security measures \n\
    and insufficient encryption can expose sensitive information, leading to privacy violations \n\
    and potential risks to individuals and organizations [26–28]. \n \nInteroperability issues \n\
    The IoT ecosystem involves a wide range of devices, protocols, and platforms from \n\
    various manufacturers [4]. Achieving seamless interoperability and compatibility among \n\
    these different components can be challenging whereas lack of standardized communica‐\n\
    tion protocols and fragmentation within the IoT industry can hinder device connectivity \n\
    and hinder the integration of IoT systems [4,5]. \n \nScalability and complexity \n\
    As the number of IoT devices increases, managing and scaling the infrastructure be‐\n\
    comes more complex [4,5]. Connecting and coordinating a large number of devices, man‐\n\
    aging  data  flows,  and  ensuring  efficient  data  processing  and  analysis \
    \ require  robust \nFigure 1. The IoT ecosystem.\nDay by day, various IoT solutions\
    \ are being introduced to the market owing to the de-\nvelopment of underlying\
    \ infrastructure (e.g., communication facilities, computing facilities)\nand the\
    \ increasing technology competency of people. These ever-growing IoT solutions\n\
    are employed in a variety of domains and offer convenient facilities to the stakeholders\n\
    engaged in these domains. According to the latest statistics, it is predicted\
    \ that there will\nbe over 100 billion IoT devices by 2025 [5–10]. It is also\
    \ evident that the IoT market size is\nexpected to reach over USD 140 billion\
    \ by 2030 from USD 12 billion in 2020 [5–10]. Overall,\nthe IoT is transforming\
    \ industries and revolutionizing the way we live and work. However,\neven though\
    \ IoT is a fast-growing technology, it is still in its infancy, and it will take\
    \ years\nto become a stable technology [21–25]. As such, there are several drawbacks\
    \ and challenges\nassociated with the incorporation and implementation of the\
    \ IoT (depicted in Figure 2),\nwhich are categorized and highlighted further in\
    \ the following.\nBiomimetics 2023, 8, x FOR PEER REVIEW \n3  of  28 \n \nsystems and architectures. Thus, scaling up IoT deployments can be challenging, particu‐\n\
    larly when dealing with legacy systems and integrating with existing IT infrastructure [3]. \n\
     \nPower and energy requirements \nMany IoT devices are small, battery‐powered devices designed to operate for ex‐\n\
    tended periods without human intervention. However, maintaining constant connectiv‐\n\
    ity, data transmission, and processing can drain device batteries quickly [10–13]. Thus, \n\
    energy efficiency becomes a crucial factor, especially for IoT deployments that involve a \n\
    massive number of devices or remote locations (e.g., in agricultural lands, mines etc.) \n\
    where the power supply is limited. \n \nData overload and management \nIoT generates vast amounts of data from multiple sources and sensors, where effec‐\n\
    tively managing, storing, analyzing, and deriving actionable insights from these data can \n\
    be a daunting task [10–13]. Thus, organizations need robust data management strategies, \n\
    including data storage, processing, and analytics capabilities, to make sense of the infor‐\n\
    mation generated by IoT devices. \n \nReliability and downtime \nIoT devices heavily rely on network connectivity and uninterrupted Internet access \n\
    [4,5]. Network outages, connectivity issues, or server downtime can impact the function‐\n\
    ality of IoT systems. Hence, dependence on stable network infrastructure and the poten‐\n\
    tial for single points of failure pose reliability challenges for IoT deployments [4,5]. \n\
     \nFigure 2. Challenges pertaining to IoT. \nAddressing these inherent drawbacks of IoT requires concerted efforts from manu‐\n\
    facturers, policymakers, and technology experts, and it will take years to tackle all these \n\
    drawbacks. As IoT continues to evolve, there is an ongoing need to prioritize security, \n\
    standardization,  data  management,  and  privacy  considerations  to  mitigate \
    \ these  chal‐\nlenges. On the whole, all the aforementioned drawbacks can be mainly apportioned into \n\
    scalability,  efficiency,  security,  and  adaptability  challenges.  As  a  remedy \
    \ to  overcome \nsuch challenges, bio‐inspired IoT emerged as a new paradigm that combines the princi‐\n\
    Figure 2. Challenges pertaining to IoT.\nBiomimetics 2023, 8, 373\n3 of 29\n•\n\
    Security and privacy\nSince IoT devices are always connected to the Internet,\
    \ they can be vulnerable to\nhacking, unauthorized access, and data breaches [10].\
    \ Further, weak security measures and\ninsufﬁcient encryption can expose sensitive\
    \ information, leading to privacy violations and\npotential risks to individuals\
    \ and organizations [26–28].\n•\nInteroperability issues\nThe IoT ecosystem involves\
    \ a wide range of devices, protocols, and platforms from\nvarious manufacturers\
    \ [4]. Achieving seamless interoperability and compatibility among\nthese different\
    \ components can be challenging whereas lack of standardized communication\nprotocols\
    \ and fragmentation within the IoT industry can hinder device connectivity and\n\
    hinder the integration of IoT systems [4,5].\n•\nScalability and complexity\n\
    As the number of IoT devices increases, managing and scaling the infrastructure\n\
    becomes more complex [4,5]. Connecting and coordinating a large number of devices,\
    \ man-\naging data ﬂows, and ensuring efﬁcient data processing and analysis require\
    \ robust systems\nand architectures. Thus, scaling up IoT deployments can be challenging,\
    \ particularly when\ndealing with legacy systems and integrating with existing\
    \ IT infrastructure [3].\n•\nPower and energy requirements\nMany IoT devices are\
    \ small, battery-powered devices designed to operate for extended\nperiods without\
    \ human intervention. However, maintaining constant connectivity, data\ntransmission,\
    \ and processing can drain device batteries quickly [10–13]. Thus, energy\nefﬁciency\
    \ becomes a crucial factor, especially for IoT deployments that involve a massive\n\
    number of devices or remote locations (e.g., in agricultural lands, mines etc.)\
    \ where the\npower supply is limited.\n•\nData overload and management\nIoT generates\
    \ vast amounts of data from multiple sources and sensors, where effec-\ntively\
    \ managing, storing, analyzing, and deriving actionable insights from these data\
    \ can\nbe a daunting task [10–13]. Thus, organizations need robust data management\
    \ strate-\ngies, including data storage, processing, and analytics capabilities,\
    \ to make sense of the\ninformation generated by IoT devices.\n•\nReliability\
    \ and downtime\nIoT devices heavily rely on network connectivity and uninterrupted\
    \ Internet access [4,5].\nNetwork outages, connectivity issues, or server downtime\
    \ can impact the functionality of\nIoT systems. Hence, dependence on stable network\
    \ infrastructure and the potential for\nsingle points of failure pose reliability\
    \ challenges for IoT deployments [4,5].\nAddressing these inherent drawbacks of\
    \ IoT requires concerted efforts from manu-\nfacturers, policymakers, and technology\
    \ experts, and it will take years to tackle all these\ndrawbacks. As IoT continues\
    \ to evolve, there is an ongoing need to prioritize security,\nstandardization,\
    \ data management, and privacy considerations to mitigate these challenges.\n\
    On the whole, all the aforementioned drawbacks can be mainly apportioned into\
    \ scal-\nability, efﬁciency, security, and adaptability challenges. As a remedy\
    \ to overcome such\nchallenges, bio-inspired IoT emerged as a new paradigm that\
    \ combines the principles of\nbiology with IoT.\nIn general, these bio-inspired\
    \ solutions, also known as biomimetic or nature-inspired\nsolutions, refer to\
    \ the development of technologies, strategies, and designs that draw\ninspiration\
    \ from biological systems found in nature [3,4]. These solutions aim to solve\n\
    complex problems by emulating or adapting principles, structures, processes, and\
    \ behaviors\nobserved in living organisms. Incorporating such solutions with IoT\
    \ leads to the creation\nof innovative and efﬁcient solutions enabling IoT to\
    \ overcome its inherent drawbacks [1–4].\nAccording to the literature, in the\
    \ area of bio-inspired IoT, little research has been carried\nBiomimetics 2023,\
    \ 8, 373\n4 of 29\nout and no reviews have synthesized the latest knowledge pertaining\
    \ to the subject area\nowing to the novelty of the ﬁeld. Thus, motivated by the\
    \ synthesis of the latest knowledge\npertaining to bio-inspired IoT, the following\
    \ describes the key contributions of the study.\n1.\nFollowing the Introduction,\
    \ we provide a brief review of what is meant by bio-\ninspiration, bio-inspired\
    \ IoT, and the beneﬁts and applications of bio-inspired IoT.\n2.\nThe latest status\
    \ of bio-inspired IoT is presented with use cases (highlighting domains\nthat\
    \ they are used in).\n3.\nA summarization of the state of the art is presented,\
    \ providing a summary of recent re-\nsearch and survey studies followed by a brief\
    \ comparison of IoT and bio-inspired IoT.\n4.\nTo make this a comprehensive review,\
    \ challenges and anticipated future directions\npertaining to the bio-inspired\
    \ IoT are also highlighted.\nTo carry out the review, we have followed a systematic\
    \ approach in which the initial\nstep encompasses the identiﬁcation of key terms\
    \ relevant to the topic, “bio-inspired Internet\nof Things”, “IoT”, “bio-inspired\
    \ algorithms”, and “IoT algorithms”. To effectively retrieve\npertinent scholarly\
    \ content, we have searched through the IEEE Xplore, ACM Digital\nLibrary, PubMed,\
    \ Google Scholar, Scopus, and Web of Science scholarly databases. Upon\nexecuting\
    \ the search queries, the next phase involves the meticulous screening of search\n\
    results. Titles and abstracts of retrieved articles are carefully reviewed to\
    \ gauge their\nrelevance. To ensure the inclusion of high-quality and recent literature,\
    \ a set of inclusion\nand exclusion criteria is established where we have chosen\
    \ scholarly articles published\nfrom 2010 onwards. However, we have also referred\
    \ to the state of the art in 1998, 1999,\nand 2001, owing to the relevance of\
    \ the subject for our review (e.g., swarm intelligence).\nThe remainder of the\
    \ study is organized in the following order. Following the Introduc-\ntion, the\
    \ second section discusses bio-inspiration, bio-inspired solutions, and bio-inspired\n\
    IoT. Afterwards, the third section discusses the ecosystem of bio-inspired IoT,\
    \ highlighting\nthe architecture of bio-inspired IoT and bio-inspired algorithms.\
    \ Then, the fourth section\nsummarizes the state of the art. Challenges pertaining\
    \ to the bio-inspired IoT are high-\nlighted in Section 5 and current status and\
    \ future directions are highlighted in Section 6\nand, ﬁnally, the study concludes\
    \ with the conclusions derived from the study. The Table 1\nhighlights the acronyms\
    \ used in the study.\nTable 1. Acronyms found in this paper.\nAcronym\nDescription\n\
    IoT\nInternet of Things\nICT\nInformation and Communication Technology\nGA\nGenetic\
    \ Algorithm\nACO\nAnt Colony Optimization\nAI\nArtiﬁcial Intelligence\nANN\nArtiﬁcial\
    \ Neural Network\nEA\nEvolutionary Algorithm\nIA\nImmunological Algorithm\nSIA\n\
    Swarm Intelligence Algorithm\nPSO\nParticle Swarm Optimization\nBFO\nBacterial\
    \ Foraging Optimization\nFA\nFireﬂy Algorithm\nBA\nBat Algorithm\nBiomimetics\
    \ 2023, 8, 373\n5 of 29\nTable 1. Cont.\nAcronym\nDescription\nCS\nCuckoo Search\n\
    BA\nBee Algorithm\nGWO\nGrey Wolf Optimizer\nDEA\nDolphin Echolocation Algorithm\n\
    HIOA\nHybrid Intelligent Optimization Algorithm\nSCA\nSine–Cosine Algorithm\n\
    SSA\nSalp Swarm Algorithm\nANTPSOAODV\nANT Particle Swarm Optimization Adhoc On-demand\
    \ Distance Vector\nBiHCLR\nBio-inspired Cross-Layer Routing\nWSN\nWireless Sensor\
    \ Network\nMPSO\nModiﬁed Particle Swarm Optimization\nMCSO\nModiﬁed Cat Swarm\
    \ Optimization\nUAV\nUnmanned Aerial Vehicle\nMOO\nMulti-Objective Optimization\n\
    PSGWO\nParticle Swarm Grey Wolf Optimization\nBSCA\nBio-Inspired Self-Learning\
    \ Coevolutionary Algorithm\nGWO\nGrey Wolf Optimizer\nWOA\nWhale Optimization\
    \ Algorithm\nICA\nImperialist Competitive Algorithm\nCH\nCluster Head\nGRN\nGene\
    \ Regulatory Network\nBiO4SeL\nBio-Inspired Optimization for Sensor Network Lifetime\n\
    BIOSARP\nBio-Inspired Self-Organized Secure Autonomous Routing Protocol\nSDAR\n\
    Secured Data Assured Routing\n2. Bio-Inspired IoT\nWith the boom of ICTs happening\
    \ early in the 21st century, researchers and academics\nbegan drawing inspiration\
    \ from biological solutions when developing applications and\nsystems that are\
    \ dynamic, real-time, and resilient. They have found that biological solutions\n\
    are great for tackling real-world complicated engineering challenges because of\
    \ their ﬂexi-\nbility, robustness, and resilience to handle failure [3]. According\
    \ to the available literature,\nthe ﬁeld of bio-inspired study can be apportioned\
    \ into three primary ﬁelds [27–30], as\nshown in Figure 3.\nBiomimetics 2023, 8, x FOR PEER REVIEW \n\
    5  of  28 \n \nHIOA \nHybrid Intelligent Optimization Algorithm   \nSCA \nSine–Cosine Algorithm \
    \  \nSSA \nSalp Swarm Algorithm   \nANTPSOAODV \nANT Particle Swarm Optimization Adhoc On‐demand Distance \n\
    Vector   \nBiHCLR \nBio‐inspired Cross‐Layer Routing   \nWSN \nWireless Sensor Network \n\
    MPSO \nModified Particle Swarm Optimization   \nMCSO \nModified Cat Swarm Optimization \
    \  \nUAV \nUnmanned Aerial Vehicle \nMOO \nMulti‐Objective Optimization   \nPSGWO \n\
    Particle Swarm Grey Wolf Optimization   \nBSCA \nBio‐Inspired Self‐Learning Coevolutionary Algorithm \
    \  \nGWO \nGrey Wolf Optimizer   \nWOA \nWhale Optimization Algorithm   \nICA \n\
    Imperialist Competitive Algorithm   \nCH \nCluster Head   \nGRN \nGene Regulatory Network \n\
    BiO4SeL \nBio‐Inspired Optimization for Sensor Network Lifetime \nBIOSARP \nBio‐Inspired Self‐Organized Secure Autonomous Routing \n\
    Protocol   \nSDAR \nSecured Data Assured Routing   \n2. Bio‐Inspired IoT \nWith the boom of ICTs happening early in the 21st century, researchers and academ‐\n\
    ics began drawing inspiration from biological solutions when developing applications \n\
    and systems that are dynamic, real‐time, and resilient. They have found that biological \n\
    solutions are great for tackling real‐world complicated engineering challenges because of \n\
    their flexibility, robustness, and resilience to handle failure [3]. According to the available \n\
    literature, the field of bio‐inspired study can be apportioned into three primary fields [27–\n\
    30], as shown in Figure 3. \n \nFigure 3. Fields of bio‐inspired study. \n1. \n\
    Bio‐inspired computing. \n2. \nBio‐inspired systems. \n3. \nBio‐inspired networking. \n\
    Figure 3. Fields of bio-inspired study.\nBiomimetics 2023, 8, 373\n6 of 29\n1.\n\
    Bio-inspired computing.\n2.\nBio-inspired systems.\n3.\nBio-inspired networking.\n\
    Bio-inspired computing focuses on optimization and efﬁcient computing and repre-\n\
    sents a class of algorithms that focus on efﬁcient computing, whereas bio-inspired\
    \ systems\nconstitute a class of system architectures for massively distributed\
    \ and collaborative sys-\ntems [25,29]. On the other hand, bio-inspired networking\
    \ is a set of approaches that are\nused for scabble and efﬁcient networking under\
    \ uncertain, volatile conditions [7,8,29].\nOverall, in order for a biological\
    \ idea to be applied, it needs to be comparable to an issue\nthat exists in the\
    \ actual world. It should be possible to put into action, and the procedure\n\
    for adapting it to a system in the actual world should be articulated in a way\
    \ that is obvious\nand concise. In this regard, the next section brieﬂy discusses\
    \ biomimicry, or bio-inspiration,\nand then the bio-inspired IoT solutions and\
    \ how they are formed.\n2.1. What Is Biomimicry?\nThe concept of biomimicry derives\
    \ its name from the combination of two Greek words,\n“bios”, meaning life, and\
    \ “mimesis”, meaning imitation [26]. Essentially, it involves imitat-\ning the\
    \ systems found in nature within human-made systems. Biomimicry encompasses\n\
    innovation inspired by nature, where engineers, knowledgeable about mechanics\
    \ and\ndynamic ﬂow systems in industrial processes, collaborate with biologists\
    \ who possess\nexpertise in the mechanics and dynamic ﬂow characteristics of living\
    \ processes [27–30].\nThroughout human existence, nature has provided solutions\
    \ to numerous complex\nproblems that engineers continue to face. By exploring\
    \ nature all around us, we can\ndiscover elegant and environmentally friendly\
    \ solutions that do not contribute to further\ndegradation. Nature avoids the\
    \ use of unnecessary toxic chemicals and manages waste\neffectively, either through\
    \ compensation or efﬁcient cleanup. For instance, Leonardo da\nVinci conceptualized\
    \ designs for helicopters and parachutes by studying natural systems,\nand the\
    \ Wright brothers examined birds to develop their ﬁrst ﬂying machine, which paved\n\
    the way for the development of modern aircraft [26–30]. This clearly indicates\
    \ how nature\nhas already solved many existing problems and how it holds the answers\
    \ for many of the\nchallenges that humankind is currently struggling with.\nOverall,\
    \ nature operates in a simple and sustainable manner. By emulating natural\nengineering,\
    \ individuals can strive for technological advancements while living harmo-\n\
    niously with nature and maintaining a balanced and equitable lifestyle. This approach\n\
    stands in contrast to current systems that disrupt harmony, pose risks to health\
    \ through\ntoxic elements, and strain ecosystem services. The emulation of nature’s\
    \ engineering\nsystems operates on three levels, according to [26].\n1.\nEmulating\
    \ the form and function of natural processes.\n2.\nEmulating the way nature produces\
    \ (engineers) biological components.\n3.\nExamining and understanding how nature\
    \ deals with all aspects of waste and regen-\neration through closed system thinking.\n\
    Starting from 1998, biomimicry has facilitated collaborations between engineering\n\
    ﬁrms and scientists to create eco-friendly and efﬁcient technology through redesign\
    \ and\nconstruction. Such example designs include modern automobiles, ﬁghter aircrafts,\
    \ bullet\ntrains, underwater submarines, etc. [26]. Overall, these nature-inspired\
    \ solutions have now\nbecome an essential part of our daily lives.\nHaving provided\
    \ a brief overview of what is meant by bio-inspiration, the next section\ndiscusses\
    \ such bio-inspired solutions in more detail.\n2.2. Bio-Inspired Solutions\nAs\
    \ aforementioned, the concept of bio-inspiration has inspired many domains to\n\
    create/implement novel solutions that can overcome many challenges that are otherwise\n\
    hard to overcome with traditional technologies. The process of designing bio-inspired\n\
    Biomimetics 2023, 8, 373\n7 of 29\nsolutions can be apportioned into ﬁve main\
    \ stages, as shown in Figure 4 [25,26,31]. It\ninvolves starting from understanding\
    \ the problem to be solved (problem), abstracting\nthe problem to be solved (reframe),\
    \ exactly identifying the problem and the solution\n(identify), analysis of biological\
    \ principles and abstraction to identify analogies, and, ﬁnally,\napplying bio-inspired\
    \ solutions to solve the problem (apply). For a better understanding,\nthe following\
    \ describes some of the remarkable bio-inspired solutions designed in recent\n\
    years inspired by the biological world.\nBiomimetics 2023, 8, x FOR PEER REVIEW \n\
    7  of  28 \n \nthe following describes some of the remarkable bio‐inspired solutions designed in recent \n\
    years inspired by the biological world. \n \nFigure 4. Process of designing a bio‐inspired solution. \n\
     \nRobotics and locomotion \nResearchers study animal locomotion to create robots and vehicles that can move \n\
    more efficiently and adapt to various terrains [2,3]. Such examples include robots inspired \n\
    by insects, birds, or marine creatures and the design of the high‐speed bullet trains in \n\
    Japan, which was inspired by the beak shape and aerodynamic efficiency of the kingfisher \n\
    [26], where the streamlined nose design reduces noise and enhances speed, making it an \n\
    iconic bio‐inspired solution in transportation. Another example is swarm robotics which \n\
    involves the coordination and cooperation of multiple robots to achieve collective behav‐\n\
    ior [6,20,26]. Inspired by the behavior of social insects like ants or bees, swarm robotics \n\
    has applications in various fields, including environmental monitoring, search and rescue, \n\
    and industrial automation. Further, the flying patterns and behaviors of birds and insects \n\
    have inspired the development of autonomous drone systems where bio‐inspired algo‐\n\
    rithms enable drones to navigate through complex environments, adapt to obstacles, and \n\
    mimic swarming behavior for collaborative tasks [25,26]. \n \nMaterials and structures \n\
    Natural materials such as spider silk, lotus leaves, or seashells possess unique prop‐\n\
    erties that can be replicated for various applications. For instance, biomimetic materials \n\
    can be used to create self‐cleaning surfaces, lightweight and strong structures, or flexible \n\
    and stretchable materials [2,3,31]. \n \nEnergy and sustainability \nNatural systems often exhibit efficient energy conversion and storage mechanisms. \n\
    By  studying  photosynthesis,  researchers  have  developed  solar  cells  inspired \
    \ by  plant \nstructures. Additionally, swarm intelligence algorithms, inspired by the behavior of social \n\
    insect colonies can optimize energy consumption and resource allocation [25–28]. \
    \  \n \nMedicine and healthcare \nNature provides numerous examples of highly efficient and adaptive biological sys‐\n\
    tems that inspire medical advancements. Biomimicry can be applied to develop new drug \n\
    delivery systems, medical implants, tissue engineering techniques, or prosthetics [24–26]. \n\
    In recent times, prosthetic limbs and robotic exoskeletons have been developed to mimic \n\
    the movement and functionality of natural human limbs. These bio‐inspired solutions aim \n\
    to restore mobility and enhance the quality of life for individuals with limb impairments \n\
    [26]. \nFigure 4. Process of designing a bio-inspired solution.\n•\nRobotics and\
    \ locomotion\nResearchers study animal locomotion to create robots and vehicles\
    \ that can move more\nefﬁciently and adapt to various terrains [2,3]. Such examples\
    \ include robots inspired by\ninsects, birds, or marine creatures and the design\
    \ of the high-speed bullet trains in Japan,\nwhich was inspired by the beak shape\
    \ and aerodynamic efﬁciency of the kingﬁsher [26],\nwhere the streamlined nose\
    \ design reduces noise and enhances speed, making it an iconic\nbio-inspired solution\
    \ in transportation. Another example is swarm robotics which involves\nthe coordination\
    \ and cooperation of multiple robots to achieve collective behavior [6,20,26].\n\
    Inspired by the behavior of social insects like ants or bees, swarm robotics has\
    \ applications\nin various ﬁelds, including environmental monitoring, search and\
    \ rescue, and industrial\nautomation. Further, the ﬂying patterns and behaviors\
    \ of birds and insects have inspired the\ndevelopment of autonomous drone systems\
    \ where bio-inspired algorithms enable drones to\nnavigate through complex environments,\
    \ adapt to obstacles, and mimic swarming behavior\nfor collaborative tasks [25,26].\n\
    •\nMaterials and structures\nNatural materials such as spider silk, lotus leaves,\
    \ or seashells possess unique proper-\nties that can be replicated for various\
    \ applications. For instance, biomimetic materials can\nbe used to create self-cleaning\
    \ surfaces, lightweight and strong structures, or ﬂexible and\nstretchable materials\
    \ [2,3,31].\n•\nEnergy and sustainability\nNatural systems often exhibit efﬁcient\
    \ energy conversion and storage mechanisms.\nBy studying photosynthesis, researchers\
    \ have developed solar cells inspired by plant\nstructures. Additionally, swarm\
    \ intelligence algorithms, inspired by the behavior of social\ninsect colonies\
    \ can optimize energy consumption and resource allocation [25–28].\n•\nMedicine\
    \ and healthcare\nNature provides numerous examples of highly efﬁcient and adaptive\
    \ biological sys-\ntems that inspire medical advancements. Biomimicry can be applied\
    \ to develop new drug\nBiomimetics 2023, 8, 373\n8 of 29\ndelivery systems, medical\
    \ implants, tissue engineering techniques, or prosthetics [24–26].\nIn recent\
    \ times, prosthetic limbs and robotic exoskeletons have been developed to mimic\
    \ the\nmovement and functionality of natural human limbs. These bio-inspired solutions\
    \ aim to\nrestore mobility and enhance the quality of life for individuals with\
    \ limb impairments [26].\n•\nOptimization and algorithms\nBio-inspired algorithms,\
    \ such as Genetic Algorithms (GAs) and Ant Colony Opti-\nmization (ACO), have\
    \ inspired computational algorithms that solve complex optimization\nproblems.\
    \ Overall, these algorithms mimic the processes of evolution, cooperation, and\n\
    adaptation found in nature [24–28].\nFigure 5 depicts several bio-inspired solutions\
    \ that have been designed in recent years;\nsolar cells inspired by plants photosynthesis\
    \ procedures and robots inspired by the moving\npattern of insects.\nBiomimetics 2023, 8, x FOR PEER REVIEW \n\
    8  of  28 \n \n \nOptimization and algorithms \nBio‐inspired algorithms, such as Genetic Algorithms (GAs) and Ant Colony Optimi‐\n\
    zation (ACO), have inspired computational algorithms that solve complex optimization \n\
    problems. Overall, these algorithms mimic the processes of evolution, cooperation, and \n\
    adaptation found in nature [24–28]. \nFigure  5  depicts  several  bio‐inspired \
    \ solutions  that  have  been  designed  in  recent \nyears; solar cells inspired by plants photosynthesis procedures and robots inspired by the \n\
    moving pattern of insects. \n \nFigure 5. Bio‐inspired solutions that have been introduced in recent years. \n\
    Having discussed what is meant by bio‐inspiration and bio‐inspired solutions, the \n\
    next section thoroughly discusses bio‐inspired IoT. \n2.3. What Is Bio‐Inspired IoT? \n\
    Bio‐inspired IoT is a concept that combines the principles of biology and IoT to create \n\
    a more efficient and adaptive system. It is based on the idea that nature has already solved \n\
    many complex problems, and by studying and mimicking biological systems, we can de‐\n\
    velop better IoT systems to enhance the functionality of such IoT systems toward improv‐\n\
    ing security, scalability, adaptability, efficiency, and so on [1–5,32–36]. Overall, bio‐in‐\n\
    spired IoT can be defined as the use of bio‐inspired computing techniques and algorithms \n\
    to develop creative/novel IoT systems that can overcome the inherent challenges of IoT, \n\
    such as resource constraints, low efficiency, and so on [17–20,37–40]. As of now, this bio‐\n\
    inspired IoT is applied to various fields such as agriculture, healthcare, transportation, \n\
    smart cities, and so on.   \nAccording to the state of the art, bio‐inspired IoT has several benefits over traditional \n\
    IoT systems, such as: \n \nScalability \nBio‐inspired IoT systems can scale easily due to the decentralized nature of biological \n\
    systems. They can handle a large number of devices and data without compromising ef‐\n\
    ficiency [23–25]. In this regard, bio‐inspired IoT algorithms, such as swarm intelligence \n\
    Figure 5. Bio-inspired solutions that have been introduced in recent years.\n\
    Having discussed what is meant by bio-inspiration and bio-inspired solutions,\
    \ the\nnext section thoroughly discusses bio-inspired IoT.\n2.3. What Is Bio-Inspired\
    \ IoT?\nBio-inspired IoT is a concept that combines the principles of biology\
    \ and IoT to create\na more efﬁcient and adaptive system. It is based on the idea\
    \ that nature has already\nsolved many complex problems, and by studying and mimicking\
    \ biological systems, we\ncan develop better IoT systems to enhance the functionality\
    \ of such IoT systems toward\nimproving security, scalability, adaptability, efﬁciency,\
    \ and so on [1–5,32–36]. Overall, bio-\ninspired IoT can be deﬁned as the use\
    \ of bio-inspired computing techniques and algorithms\nto develop creative/novel\
    \ IoT systems that can overcome the inherent challenges of IoT,\nsuch as resource\
    \ constraints, low efﬁciency, and so on [17–20,37–40]. As of now, this bio-\n\
    inspired IoT is applied to various ﬁelds such as agriculture, healthcare, transportation,\n\
    smart cities, and so on.\nAccording to the state of the art, bio-inspired IoT\
    \ has several beneﬁts over traditional\nIoT systems, such as:\nBiomimetics 2023,\
    \ 8, 373\n9 of 29\n•\nScalability\nBio-inspired IoT systems can scale easily due\
    \ to the decentralized nature of biological\nsystems. They can handle a large\
    \ number of devices and data without compromising efﬁ-\nciency [23–25]. In this\
    \ regard, bio-inspired IoT algorithms, such as swarm intelligence [9,20],\nenable\
    \ efﬁcient scalability in IoT systems by leveraging collective intelligence and\
    \ self-\norganization, allowing devices to interact and cooperate locally. On\
    \ the other hand, this\nscalability feature enables bio-inspired IoT systems to\
    \ handle a growing number of devices,\ninteractions, and data, without lacking\
    \ efﬁciency and performance.\n•\nEfﬁciency\nBio-inspired IoT systems are energy-efﬁcient\
    \ as they can adapt to changing environ-\nmental conditions and optimize their\
    \ operations accordingly. In general, they optimize en-\nergy consumption, adjust\
    \ resource usage based on demand, and enable energy-harvesting\ntechniques [39].\
    \ This focus on energy efﬁciency leads to sustainability, longer device battery\n\
    life, and reduced environmental impact [23–25].\n•\nAdaptability\nBio-inspired\
    \ IoT systems can adapt to changing conditions and learn from their\nenvironment.\
    \ They can dynamically adjust to changing environmental conditions, network\n\
    conﬁgurations, and resource availability. This adaptability allows bio-inspired\
    \ IoT systems\nto handle uncertainties, ﬂuctuations, and unexpected events more\
    \ effectively as opposed to\ntraditional IoT [5,26].\n•\nResilience and autonomous\
    \ behavior\nBiological systems have evolved to be resilient to external disturbances,\
    \ and bio-\ninspired IoT systems can inherit these properties. They can recover\
    \ from failures and\ncontinue to operate efﬁciently under adverse circumstances\
    \ [26–30]. On the other hand,\nbio-inspired IoT systems can incorporate Artiﬁcial\
    \ Intelligence (AI) and adaptive behavior.\nBy mimicking biological learning processes,\
    \ they can adapt and improve their performance\nover time. With the involvement\
    \ of AI, bio-inspired IoT systems can learn from data, adjust\ntheir parameters,\
    \ and make intelligent decisions, enhancing their autonomy and ability to\nhandle\
    \ complex tasks [9,16].\nBio-inspired IoT has a variety of applications across\
    \ various domains, as shown in\nFigure 6, which we have categorized according\
    \ to the state of the art. In the following, we\nbrieﬂy discuss these domains.\n\
    Biomimetics 2023, 8, x FOR PEER REVIEW \n9  of  28 \n \n[9,20], enable efficient scalability in IoT systems by leveraging collective intelligence and \n\
    self‐organization, allowing devices to interact and cooperate locally. On the other hand, \n\
    this scalability feature enables bio‐inspired IoT systems to handle a growing number of \n\
    devices, interactions, and data, without lacking efficiency and performance. \n\
     \nEfficiency \nBio‐inspired IoT systems are energy‐efficient as they can adapt to changing environ‐\n\
    mental conditions and optimize their operations accordingly. In general, they optimize \n\
    energy consumption, adjust resource usage based on demand, and enable energy‐harvest‐\n\
    ing techniques [39]. This focus on energy efficiency leads to sustainability, longer device \n\
    battery life, and reduced environmental impact [23–25]. \n \nAdaptability \n\
    Bio‐inspired IoT systems can adapt to changing conditions and learn from their en‐\n\
    vironment. They can dynamically adjust to changing environmental conditions, network \n\
    configurations, and resource availability. This adaptability allows bio‐inspired IoT sys‐\n\
    tems to handle uncertainties, fluctuations, and unexpected events more effectively as op‐\n\
    posed to traditional IoT [5,26]. \n \nResilience and autonomous behavior \nBiological systems have evolved to be resilient to external disturbances, and bio‐in‐\n\
    spired IoT systems can inherit these properties. They can recover from failures and con‐\n\
    tinue to operate efficiently under adverse circumstances [26–30]. On the other hand, bio‐\n\
    inspired IoT systems can incorporate Artificial Intelligence (AI) and adaptive behavior. \n\
    By mimicking biological learning processes, they can adapt and improve their perfor‐\n\
    mance over time. With the involvement of AI, bio‐inspired IoT systems can learn from \n\
    data, adjust their parameters, and make intelligent decisions, enhancing their autonomy \n\
    and ability to handle complex tasks [9,16]. \nBio‐inspired IoT has a variety of applications across various domains, as shown in \n\
    Figure 6, which we have categorized according to the state of the art. In the following, we \n\
    briefly discuss these domains. \n \nFigure 6. Domains of bio‐inspired IoT. \n\
     \nAgriculture \nBio‐inspired IoT solutions have been implemented in agriculture to improve crop \n\
    yields, optimize resource usage, and monitor environmental conditions [16,30–33]. For \n\
    i\nt\ni\ni\ni\nd b\nb\ni i\nI T d\ni\nit\nl\nt h\nlth b\nFigure 6. Domains of\
    \ bio-inspired IoT.\nBiomimetics 2023, 8, 373\n10 of 29\n•\nAgriculture\nBio-inspired\
    \ IoT solutions have been implemented in agriculture to improve crop\nyields,\
    \ optimize resource usage, and monitor environmental conditions [16,30–33]. For\n\
    instance, using sensors inspired by bee vision, IoT devices can monitor plant\
    \ health by\nanalyzing the reﬂection of light from leaves. This helps farmers\
    \ make informed decisions\nabout irrigation, fertilization, and pest control.\n\
    •\nHealthcare\nBio-inspired IoT devices are being used for remote health monitoring\
    \ and personalized\nmedicine. For example, wearable devices inspired by the structure\
    \ and functionality of\nhuman skin can continuously monitor vital signs, detect\
    \ abnormalities, and transmit data\nto healthcare providers in real time [17–21].\
    \ Nonetheless, bio-inspired IoT can be used to\nmonitor patients’ vital signs\
    \ and alert healthcare professionals in case of emergencies. It\ncan also be used\
    \ to track the spread of diseases and monitor outbreaks.\n•\nTransportation\n\
    Bio-inspired IoT can be used to optimize trafﬁc ﬂow and reduce congestion. It\
    \ can also\nbe used to monitor vehicle performance and reduce emissions [25–28].\n\
    •\nEnvironmental monitoring\nBio-inspired IoT systems can help monitor and manage\
    \ environmental conditions. For\ninstance, IoT sensors inspired by the sensory\
    \ capabilities of birds can detect air pollution,\nmonitor noise levels, or analyze\
    \ water quality in real time, contributing to early warning\nsystems and environmental\
    \ conservation efforts [18,25,26].\n•\nEnergy management\nInspired by the behavior\
    \ of social insect colonies, bio-inspired IoT systems can optimize\nenergy management\
    \ in smart grids or buildings [25–28]. By coordinating the energy\nconsumption\
    \ and production of multiple IoT devices, these systems can improve efﬁciency,\n\
    balance energy loads, and enable better integration of renewable energy sources.\n\
    •\nStructural health monitoring\nBio-inspired IoT solutions can be used to monitor\
    \ the structural health of buildings,\nbridges, and other infrastructure [3–5].\
    \ By mimicking the sensory capabilities of animals,\nsuch as bats or dolphins,\
    \ IoT sensors can detect and analyze vibrations, acoustic signals, or\nchanges\
    \ in electromagnetic ﬁelds to identify potential structural issues or defects.\n\
    •\nWildlife conservation\nIoT devices equipped with bio-inspired sensors and communication\
    \ mechanisms\nhave been deployed to monitor wildlife populations and protect endangered\
    \ species. For\nexample, researchers have developed bio-inspired camera traps\
    \ that mimic the visual and\nauditory cues of prey to attract and photograph elusive\
    \ or endangered animals [15,25,26].\n•\nMilitary\nBio-inspired IoT in the military\
    \ involves applying biological principles to design\nadaptable, resilient, energy-efﬁcient\
    \ IoT systems capable of self-organization, enhanced\nsensing, swarm intelligence,\
    \ stealth, and biometric security (e.g., swarm drones for recon-\nnaissance, biochemical\
    \ sensing, and energy-efﬁcient sensors) [25,26]. It aims to leverage\nnature-inspired\
    \ strategies for efﬁcient data processing, communication, and environmental\n\
    adaptation, enabling improved situational awareness, surveillance, reconnaissance,\
    \ and\nmission success.\n•\nSmart cities\nBio-inspired IoT can enhance the efﬁciency\
    \ of urban infrastructure and services. For\ninstance, researchers have looked\
    \ at the collective foraging behavior of ants to develop\nefﬁcient routing algorithms\
    \ for garbage collection and transportation networks [25,26].\nBiomimetics 2023,\
    \ 8, 373\n11 of 29\nBy applying these principles, IoT devices can optimize routes,\
    \ reduce congestion, and\nminimize energy consumption [3,25–28]. On the other\
    \ hand, bio-inspired IoT is used to\nmonitor air and water quality, detect and\
    \ prevent natural disasters, and improve energy\nefﬁciency in a typical smart\
    \ city.\n3. The Bio-Inspired IoT Ecosystem\nThe IoT is an ecosystem that comprises\
    \ various enabling technologies, of which\nIoT constitutes the core. The remaining\
    \ technologies that constitute an IoT ecosystem\ninclude cloud computing, fog\
    \ computing, edge computing, AI, underlying communication\ntechnologies, and so\
    \ on. Overall, the typical architecture of an IoT solution comprises\nthree or\
    \ four layers [32,33]. The three-layer architecture comprises a physical/sensing\n\
    layer, network/communication layer, and the application layer whereas the four-layer\n\
    architecture comprises an intermediate data-processing layer in between the network\
    \ and\nthe application layer [1,3,4]. On the other hand, when it comes to bio-inspired\
    \ IoT, the\npervasive ecosystem comprises underlying bio-inspired algorithms/techniques\
    \ that hold a\nkey place in the bio-inspired IoT ecosystem. The architecture of\
    \ bio-inspired IoT systems\nvaries depending on the speciﬁc application and the\
    \ level of bio-inspiration incorporated.\nHowever, there are certain common architectural\
    \ elements that are often present in bio-\ninspired IoT systems. To provide a\
    \ better understanding of the bio-inspired IoT ecosystem,\nthe next section discusses\
    \ further the architecture of bio-inspired IoT and underlying\nbio-inspired algorithms\
    \ that make the ecosystem comprehensive.\n3.1. The Architecture of Bio-Inspired\
    \ IoT\nBio-inspired IoT refers to the application of principles and concepts from\
    \ biological\nsystems to design and implement IoT architectures [26]. It aims\
    \ to leverage the efﬁciency,\nresilience, and adaptability observed in natural\
    \ systems to enhance the performance and\ncapabilities of IoT networks. The standard\
    \ architecture of a typical IoT solution consists of\nthree levels; however, some\
    \ researchers [32–36] have argued that it really has a four-layer\ndesign as aforementioned\
    \ [1,3,4]. While there is no speciﬁc standardized architecture for\nbio-inspired\
    \ IoT, their architecture varies depending on the speciﬁc application and the\n\
    level of bio-inspiration incorporated. However, there are certain common architectural\n\
    elements that are often present in bio-inspired IoT systems. In general, the architecture\
    \ of a\ntypical bio-inspired IoT solution can be apportioned into seven layers:\
    \ the physical layer,\nnetwork/communication layer, data-processing/decision-making\
    \ layer, adaptation and\nlearning layer, control layer, and application layer,\
    \ depicted in Figure 7.\nBiomimetics 2023, 8, x FOR PEER REVIEW \n \nThe IoT is an ecosystem that comprises various enabling technologies, of w\n\
    constitutes the core. The remaining technologies that constitute an IoT ecosystem\n\
    cloud computing, fog computing, edge computing, AI, underlying communicati\nnologies, and so on. Overall, the typical architecture of an IoT solution comprises\n\
    four layers [32,33]. The three‐layer architecture comprises a physical/sensing lay\n\
    work/communication layer, and the application layer whereas the four‐layer arch\n\
    comprises an intermediate data‐processing layer in between the network and the \n\
    tion layer [1,3,4]. On the other hand, when it comes to bio‐inspired IoT, the pervas\n\
    system comprises underlying bio‐inspired algorithms/techniques that hold a key\n\
    the bio‐inspired IoT ecosystem. The architecture of bio‐inspired IoT systems va\n\
    pending on the specific application and the level of bio‐inspiration incorporated\n\
    ever, there are certain common architectural elements that are often present in\n\
    spired IoT systems. To provide a better understanding of the bio‐inspired IoT eco\n\
    the next section discusses further the architecture of bio‐inspired IoT and underly\n\
    inspired algorithms that make the ecosystem comprehensive. \n3.1. The Architecture of Bio‐Inspired IoT \n\
    Bio‐inspired IoT refers to the application of principles and concepts from bi\n\
    systems to design and implement IoT architectures [26]. It aims to leverage the ef\n\
    resilience, and adaptability observed in natural systems to enhance the performa\n\
    capabilities of IoT networks. The standard architecture of a typical IoT solution \n\
    of three levels; however, some researchers [32–36] have argued that it really has\n\
    layer design as aforementioned [1,3,4]. While there is no specific standardized arch\n\
    for bio‐inspired IoT, their architecture varies depending on the specific applicat\n\
    the level of bio‐inspiration incorporated. However, there are certain common arch\n\
    elements that are often present in bio‐inspired IoT systems. In general, the archite\n\
    a typical bio‐inspired IoT solution can be apportioned into seven layers: the physic\n\
    network/communication  layer,  data‐processing/decision‐making  layer,  adaptat\n\
    learning layer, control layer, and application layer, depicted in Figure 7. \n\
     \nFigure 7. The typical architecture of bio‐inspired IoT solution. \n1. \nSensing layer \n\
    The sensing layer consists of a collection of sensors and actuators deploye\n\
    physical environment These sensors capture data from the surrounding envir\nFigure\
    \ 7. The typical architecture of bio-inspired IoT solution.\nBiomimetics 2023,\
    \ 8, 373\n12 of 29\n1.\nSensing layer\nThe sensing layer consists of a collection\
    \ of sensors and actuators deployed in the\nphysical environment. These sensors\
    \ capture data from the surrounding environment,\nsuch as temperature, humidity,\
    \ light intensity, or motion, mimicking the sensory organs of\nbiological organisms\
    \ [34–38].\n2.\nCommunication layer\nThe communication layer facilitates the exchange\
    \ of data between IoT sensing devices\nand the further layers in the hierarchy\
    \ [31–34]. It includes wireless communication protocols\nand networking infrastructure\
    \ for seamless connectivity. On the other hand, bio-inspired\ncommunication mechanisms\
    \ are also employed to optimize energy consumption, enhance\nreliability, or adapt\
    \ to dynamic network conditions [34–38].\n3.\nData-processing layer\nThe data-processing\
    \ layer is responsible for analyzing and processing the data col-\nlected by the\
    \ sensors. This layer may include bio-inspired algorithms for data fusion,\npattern\
    \ recognition, machine learning, or optimization, drawing inspiration from biological\n\
    processes like neural networks, genetic algorithms, or swarm intelligence [34–38].\n\
    4.\nDecision-making layer\nThe decision-making layer incorporates bio-inspired\
    \ mechanisms to enable autonomous\nand decentralized decision making. This layer\
    \ can involve algorithms inspired by collec-\ntive intelligence, such as swarm\
    \ intelligence, where individual IoT devices interact and\ncooperate to make decisions\
    \ [34–38].\n5.\nAdaptation and learning layer\nThe adaptation and learning layer\
    \ enables IoT devices to adapt their behavior and\nlearn from their environment.\
    \ It may include AI algorithms that enable devices to learn\nfrom data, adjust\
    \ their parameters, or optimize their performance over time, similar to the\n\
    adaptive behavior observed in biological systems [33–38].\n6.\nControl layer\n\
    The control layer coordinates and manages the operations of the IoT system. It\
    \ may\ninvolve hierarchical control mechanisms inspired by the organization and\
    \ coordination\nfound in biological systems, allowing for self-organization, self-healing,\
    \ and fault toler-\nance [34–38].\n7.\nApplication layer\nThe application layer\
    \ encompasses the speciﬁc applications and services enabled by\nbio-inspired IoT\
    \ systems used in various domains such as agriculture, smart city, and so on\n\
    as aforementioned.\nIt is noted that the architecture can be tailored to the speciﬁc\
    \ requirements of the\napplication. On the other hand, the level of bio-inspiration\
    \ can vary, ranging from incor-\nporating bio-inspired algorithms within speciﬁc\
    \ layers to developing fully bio-inspired\narchitectures [34–38]. Whilst developing\
    \ bio-inspired IoT solutions, the following key\nprinciples are also incorporated\
    \ into the architecture towards making sure such solutions\ncan overcome the challenges\
    \ associated with traditional IoT systems.\n•\nSelf-organization\nBio-inspired\
    \ IoT architectures emphasize self-organization, allowing devices to au-\ntonomously\
    \ form networks, adapt to changing conditions, and dynamically reconﬁgure\nthemselves\
    \ [10–13]. This concept draws inspiration from biological systems, such as ant\n\
    colonies or ﬂocking birds, where individual entities collectively organize and\
    \ collabo-\nrate [26].\nBiomimetics 2023, 8, 373\n13 of 29\n•\nSwarm intelligence\n\
    Bio-inspired IoT can leverage swarm intelligence, which is inspired by the collective\n\
    behavior of social insects like bees or ants. In this approach, IoT devices interact\
    \ and share\ninformation to achieve speciﬁc goals through distributed decision\
    \ making and coordination.\nSwarm intelligence helps especially in achieving scalability,\
    \ fault tolerance, and robustness\nin IoT networks [20–23].\n•\nHierarchical structures\n\
    Inspired by biological systems with hierarchical structures, bio-inspired IoT\
    \ archi-\ntectures often adopt layered or hierarchical arrangements. This allows\
    \ for efﬁcient data\nprocessing and decision making at different levels, enabling\
    \ distributed intelligence and\nreducing the need for centralized control [15–19].\n\
    •\nAdaptive and resilient\nBio-inspired IoT architectures aim to be adaptive and\
    \ resilient, capable of responding\nto changes and disruptions. They can dynamically\
    \ adapt to environmental conditions,\nreconﬁgure themselves in the presence of\
    \ failures or changes, and continue operating\nreliably [24–26].\n•\nEnergy efﬁciency\n\
    Energy efﬁciency is a critical consideration in IoT deployments. Bio-inspired\
    \ ap-\nproaches can help optimize energy consumption by taking cues from energy-efﬁcient\n\
    mechanisms observed in biological systems, such as efﬁcient communication, resource\n\
    allocation, and power management strategies [24–26].\n•\nSensing and actuation\n\
    Bio-inspired IoT architectures often emphasize advanced sensing capabilities,\
    \ drawing\ninspiration from biological sensors and perception mechanisms [5–8,26].\
    \ These architec-\ntures may also incorporate actuation mechanisms to enable devices\
    \ to interact with the\nphysical world, much like organisms found in nature.\n\
    3.2. Bio-Inspired IoT Algorithms\nHaving described the core part of bio-inspired\
    \ IoT, this section discusses further bio-\ninspired IoT algorithms. Bio-inspired\
    \ IoT algorithms refer to the use of nature-inspired\napproaches to develop efﬁcient\
    \ and adaptive algorithms for IoT systems [3,5,24–28]. These\nalgorithms are based\
    \ on the principles of biology and are designed to solve complex prob-\nlems more\
    \ efﬁciently and effectively [39,40]. Overall, bio-inspired optimization algorithms\n\
    are an emerging approach that is based on the principles of and inspiration from\
    \ the\nbiological evolution of nature to develop new and robust computing techniques.\
    \ There\nare various taxonomies available for bio-inspired algorithms [18,24,25],\
    \ each with its own\npros and cons, and the following Figure 8 depicts a possible\
    \ classiﬁcation of bio-inspired\nIoT algorithms.\n1.\nPhysically Inspired Algorithms\
    \ (PIAs)\nIn general, PIAs draw inspiration from physical principles and phenomena\
    \ to solve\ncomplex problems. These algorithms attempt to replicate or mimic physical\
    \ processes or\nbehaviors to develop efﬁcient and effective problem-solving strategies.\
    \ By harnessing the\nprinciples observed in the physical world, PIAs offer alternative\
    \ approaches to traditional\ncomputational algorithms [25]. e.g., simulated annealing,\
    \ harmony search algorithm.\n2.\nNeural Networks and Artiﬁcial Neural Networks\
    \ (ANNs)\nThese algorithms aim to simulate the structure and functionality of\
    \ biological neural\nnetworks, such as the human brain. In general, they are computational\
    \ models composed of\ninterconnected artiﬁcial neurons, which process and transmit\
    \ information to perform tasks\nlike pattern recognition, classiﬁcation, and prediction\
    \ [40–45]. e.g., feedforward neural\nnetworks, perceptron, convolutional neural\
    \ networks.\nBiomimetics 2023, 8, 373\n14 of 29\n3.\nEvolutionary Algorithms (EAs)\n\
    EAs are a class of computational optimization algorithms inspired by the principles\n\
    of biological evolution and natural selection. These algorithms mimic the process\
    \ of\nnatural evolution to search for optimal solutions to complex problems [45–47].\
    \ EAs operate\non a population of candidate solutions, evolving and improving\
    \ them over successive\ngenerations through the application of genetic operators\
    \ such as mutation, crossover, and\nselection. e.g., genetic algorithms.\n4.\n\
    Immunological Algorithms (IAs)\nIAs are inspired by the principles of the immune\
    \ system. These algorithms draw analo-\ngies from the behavior, mechanisms, and\
    \ processes of the immune system to solve complex\noptimization and pattern recognition\
    \ problems. IA models aim to mimic the adaptive and\nself-organizing nature of\
    \ the immune system to develop intelligent algorithms [25–27]. e.g.,\nartiﬁcial\
    \ immune systems, clonal selection algorithm, immune network algorithm.\n5.\n\
    Swarm Intelligence Algorithms (SIAs)\nSIAs are a class of computational methods\
    \ inspired by the collective behavior of social\ninsects, such as ant colonies\
    \ and bee swarms, or bird ﬂocks [6,9,27]. These algorithms\nmimic the decentralized\
    \ decision making and self-organization observed in nature, where\nindividual\
    \ agents interact locally with their environment and with each other to achieve\
    \ a\ncollective goal [27].\nBiomimetics 2023, 8, x FOR PEER REVIEW \n14 of 28\
    \ \n \n \nFigure 8. Taxonomy of bio-inspired algorithms. \n1. \nPhysically Inspired\
    \ Algorithms (PIAs) \nIn general, PIAs draw inspiration from physical principles\
    \ and phenomena to solve \ncomplex problems. These algorithms attempt to replicate\
    \ or mimic physical processes or \nbehaviors to develop efficient and effective\
    \ problem-solving strategies. By harnessing the \nprinciples observed in the physical\
    \ world, PIAs offer alternative approaches to traditional \ncomputational algorithms\
    \ [25]. E.g., simulated annealing, harmony search algorithm. \n2. \nNeural Networks\
    \ and Artificial Neural Networks (ANNs) \nThese algorithms aim to simulate the\
    \ structure and functionality of biological neural \nnetworks, such as the human\
    \ brain. In general, they are computational models composed \nof interconnected\
    \ artificial neurons, which process and transmit information to perform \ntasks\
    \ like pattern recognition, classification, and prediction [40,41,42,43,44,45].\
    \ E.g., \nfeedforward neural networks perceptron con olutional neural networks\n\
    Figure 8. Taxonomy of bio-inspired algorithms.\nSIAs have found applications in\
    \ various ﬁelds, including optimization, robotics, data\nclustering, and IoT.\
    \ In the context of IoT, SIAs can be leveraged to address several challenges\n\
    related to scalability, adaptability, and fault tolerance. These algorithms enable\
    \ IoT devices\nto cooperate and coordinate their actions to perform complex tasks\
    \ and solve problems\nefﬁciently [6,27,48–50]. One popular swarm intelligence\
    \ algorithm used in IoT is Ant\nColony Optimization (ACO). ACO is inspired by\
    \ the foraging behavior of ants and has\nbeen applied to solve optimization problems\
    \ in IoT networks. ACO works by simulating\nthe behavior of ants searching for\
    \ the shortest path between their colony and a food source.\nBiomimetics 2023,\
    \ 8, 373\n15 of 29\nThe pheromone trails left by ants guide the other ants in\
    \ their search, gradually converging\ntoward the optimal solution [27,48–50].\
    \ In the context of IoT, ACO can be used to optimize\nrouting paths, resource\
    \ allocation, or energy management in a network of interconnected\ndevices [48–50].\
    \ Another swarm intelligence algorithm is Particle Swarm Optimization\n(PSO),\
    \ which is inspired by the ﬂocking behavior of birds, where each individual (particle)\n\
    adjusts its position and velocity based on its own experience and the experience\
    \ of the\nbest-performing particle in the swarm. PSO has been successfully applied\
    \ to various IoT\napplications, including dynamic task scheduling, load balancing,\
    \ and sensor placement\noptimization. These are just a few examples of swarm intelligence\
    \ algorithms used in the\nconstruction of IoT solutions. Other swarm intelligence\
    \ algorithms like Genetic Algorithms\n(GAs), Bacterial Foraging Optimization (BFO),\
    \ and the Fireﬂy Algorithm (FA) have also\nbeen explored in the context of IoT\
    \ [27,48–50].\n6.\nIn addition to the bio-inspired algorithms mentioned earlier,\
    \ there are several other\nnotable bio-inspired algorithms. Here are a few more\
    \ examples:\nA.\nBat Algorithm (BA)\nThe BA takes inspiration from the echolocation\
    \ behavior of bats. It simulates\nthe movement and interaction of bats to search\
    \ for optimal solutions. Bats\nemit ultrasonic sounds and use the echo to detect\
    \ objects and navigate their\nenvironment. The algorithm incorporates this behavior\
    \ to optimize problem\nsolutions [27,48–50].\nB.\nCuckoo Search (CS)\nThe CS algorithm\
    \ is inspired by the brood parasitism behavior of cuckoos.\nCuckoos lay their\
    \ eggs in the nests of other bird species, and the algorithm\nmimics this behavior\
    \ to optimize solutions. It uses random walk and Lévy\nﬂights to explore the search\
    \ space and replace poor solutions with better\nones [27,48–50].\nC.\nBee Algorithm\
    \ (BA)\nThe BA is inspired by the foraging behavior of honeybees. It mimics the\n\
    process of food source exploration and exploitation by a bee colony to solve\n\
    optimization problems [27,48–50]. The algorithm employs employed bees,\nonlooker\
    \ bees, and scout bees to search for high-quality solutions.\nD.\nGrey Wolf Optimizer\
    \ (GWO)\nThe GWO is inspired by the social hierarchy and hunting behavior of grey\n\
    wolves. It imitates the leadership and cooperation of wolf packs to optimize\n\
    solutions. The algorithm deﬁnes four types of wolves (alpha, beta, delta, and\n\
    omega) and simulates their search for prey to ﬁnd optimal solutions [27].\nE.\n\
    Dolphin Echolocation Algorithm (DEA)\nThe DEA is inspired by the echolocation\
    \ behavior of dolphins. It mimics\nthe use of sound waves and echoes for navigation\
    \ and prey detection. The\nalgorithm employs the concept of wavefronts and sonar\
    \ sensing to optimize\nproblem solutions [27].\nAccording to our analysis, bio-inspired\
    \ IoT algorithms offer several advantages over\ntraditional algorithms when it\
    \ comes to solving complex problems pertaining to IoT sys-\ntems. The following\
    \ describes the beneﬁts of these bio-inspired IoT algorithms:\n1.\nAdaptability\n\
    Bio-inspired algorithms are inherently adaptable and can dynamically adjust to\
    \ chang-\ning conditions. They draw inspiration from biological systems that exhibit\
    \ adaptability\nand can handle uncertainties and ﬂuctuations effectively [23–25].\
    \ This adaptability allows\nbio-inspired IoT algorithms to respond to varying\
    \ network conditions, resource availability,\nor environmental changes, resulting\
    \ in improved system performance.\n2.\nScalability\nBiomimetics 2023, 8, 373\n\
    16 of 29\nBio-inspired algorithms, such as swarm intelligence, are well-suited\
    \ for large-scale\nIoT systems [27]. They enable devices to interact and cooperate\
    \ locally, leading to self-\norganization and decentralized decision making. This\
    \ scalability feature allows bio-inspired\nIoT algorithms to efﬁciently handle\
    \ a growing number of devices, interactions, and data in\ncomplex IoT networks.\n\
    3.\nOptimization and efﬁciency\nBio-inspired algorithms excel at optimization\
    \ tasks, resource allocation, and decision\nmaking. By mimicking natural processes\
    \ like genetic evolution or ant colony foraging be-\nhavior, bio-inspired IoT\
    \ algorithms can optimize routing, scheduling, energy management,\nand other resource-intensive\
    \ tasks [48–52]. This optimization leads to improved efﬁciency,\nreduced energy\
    \ consumption, and enhanced system performance [53–57].\n4.\nRobustness and resilience\n\
    Bio-inspired IoT algorithms often exhibit robustness and resilience similar to\
    \ biological\nsystems. They can handle failures, disruptions, or changes in the\
    \ system, thanks to their\ndecentralized and self-organizing nature. This resilience\
    \ helps bio-inspired IoT systems\nmaintain functionality and adapt to evolving\
    \ conditions, making them more reliable in\ndynamic and uncertain environments\
    \ [48–52,58–62].\n5.\nDistributed intelligence\nBio-inspired IoT algorithms enable\
    \ distributed intelligence and decision making. In-\nstead of relying on a centralized\
    \ authority, devices in bio-inspired IoT systems interact\nlocally and collectively\
    \ contribute to the decision-making process. This distributed intelli-\ngence\
    \ enhances fault tolerance, autonomy, and scalability while reducing dependence\
    \ on a\nsingle point of failure [48–52,63–65].\n6.\nSustainability and energy\
    \ efﬁciency\nBio-inspired algorithms often prioritize energy efﬁciency and resource\
    \ optimization,\naligning with sustainability goals. They leverage energy-efﬁcient\
    \ behaviors observed in\nbiological systems, helping reduce energy consumption\
    \ and environmental impact in IoT\ndeployments [6,13–16,64–68].\nOverall, bio-inspired\
    \ IoT algorithms offer a new approach to developing efﬁcient and\nadaptive algorithms\
    \ for IoT systems. As this ﬁeld continues to grow, we can expect to see\nmore\
    \ innovative and efﬁcient algorithms that are inspired by nature.\n4. A Summarization\
    \ of Related Work\nIn recent years, there has been a clear growth of research\
    \ studies seen in the area of\nbio-inspired IoT. Thus, to provide a better understanding,\
    \ Table 2 summarizes the latest\nresearch in terms of the domain it is applied\
    \ to, the key applications it is going to optimize,\nits main contributions, and\
    \ the scope of the work.\nTable 2. Summary of latest research pertaining to bio-inspired\
    \ IoT.\nReference Domain\nApplication/s\nMain Contribution\nScope of the Work\n\
    [1]\nIoT network\ncommunication\nSecurity\nProposes an AI-assisted\nbio-inspired\
    \ algorithm.\nThe authors proposed an AI-assisted bio-inspired\nalgorithm for\
    \ securing IoT communication. Their\nproposed framework comprises two components.\n\
    One component includes bio-inspired\nalgorithm-assisted blockchain technology\
    \ for\nauthentication and authorization, whereas the other\ncomponent includes\
    \ an AI algorithm that keeps an\neye on the IoT communication network.\nBiomimetics\
    \ 2023, 8, 373\n17 of 29\nTable 2. Cont.\nReference Domain\nApplication/s\nMain\
    \ Contribution\nScope of the Work\n[2]\nManufacturing\nScalability\nIntroduces\
    \ a novel\nbio-inspired control\narchitecture for modern\ncyber-physical\nmanufacturing\n\
    systems.\nThis research introduces a novel bio-inspired control\narchitecture\
    \ for modern manufacturing systems,\nwhich suggests an IoT-enabled framework for\n\
    detecting motor abnormalities using vibration\nsensors. The proposed approach\
    \ employs a real-time\nautoencoder for enhanced accuracy. In contrast to\nexisting\
    \ methodologies, this study focuses on\nanalyzing the behavior of anomaly detection\
    \ in\nreal time.\n[3]\nCyber-physical\nsystems\nSecurity\nPresents a bio-inspired\n\
    method for the\nidentiﬁcation of\nhardware trojans.\nThe authors present a bio-inspired\
    \ method for the\nidentiﬁcation of hardware trojans in cyber-physical\nsystems.\
    \ Further, they also developed a bio-inspired\ndevice-locking mechanism, which\
    \ they used in order\nto construct a design-for-trust architecture. The\nﬁndings\
    \ proved that the concept is suitable for\nresource-constrained situations that\
    \ have low\nhardware and power dissipation proﬁles.\n[4]\nIoT network\ncommunication\n\
    Security\nPresents a novel\nbio-inspired approach\nto enhance the security\nof\
    \ distributed IoT\ndevices.\nThe authors present a novel approach inspired by\n\
    biology to enhance the security of distributed IoT\ndevices. The main objective\
    \ of their proposed\nframework is to identify, refuse, and prevent\nunauthorized\
    \ external agents from accessing the\ndevices, both individually and in cooperation,\
    \ in\nreal time.\n[6]\nIoT network\ncommunication\nEnergy\nconsumption\nPresents\
    \ a novel\nclustering approach\nenabled by the\ncombination of\nbio-inspired algorithms\n\
    toward optimizing\nenergy consumption.\nThe authors have used fuzzy logic, chicken\
    \ swarm\noptimization, and a genetic algorithm to present an\noptimal cluster\
    \ formation as a Hybrid Intelligent\nOptimization Algorithm (HIOA) to minimize\
    \ overall\nenergy consumption in an IoT network.\n[7]\nIoT network\ncommunication\n\
    Network slicing\nA novel bio-inspired\nwireless resource\nallocation approach\
    \ is\nintroduced.\nA novel wireless resource allocation approach with\nslice characteristic\
    \ perception has been presented by\nthe authors for use in 5G-enabled IoT networks.\n\
    [8]\nIoT network\ncommunication\nRouting\nperformance\nA bio-inspired\ndecentralized\
    \ service\ndiscovery and selection\nmodel is introduced.\nUsing the bio-inspired\
    \ response threshold model as\ninspiration, this paper proposes a decentralized\n\
    service discovery and selection model. Obtained\nresults indicated that the proposed\
    \ method exhibits\nefﬁcient routing and scalability for IoT networks.\n[9]\nIoT\
    \ network\ncommunication\nSecurity\nA novel hybridized\nbio-inspired intrusion\n\
    detection system is\nintroduced.\nThe researchers present an innovative approach\
    \ for\nenhancing the security of the IoT framework through\na hybridized bio-inspired\
    \ intrusion detection system.\nThis system utilizes a combination of two\nbio-inspired\
    \ algorithms, namely the Sine–Cosine\nAlgorithm (SCA) and the Salp Swarm Algorithm\n\
    (SSA), to effectively analyze and identify essential\nnetwork trafﬁc patterns.\
    \ By extracting relevant\nfeatures, these characteristics are then forwarded to\
    \ a\nmachine learning classiﬁer, enabling the system to\naccurately detect and\
    \ classify intrusive trafﬁc.\nBiomimetics 2023, 8, 373\n18 of 29\nTable 2. Cont.\n\
    Reference Domain\nApplication/s\nMain Contribution\nScope of the Work\n[10]\n\
    IoT network\ncommunication\nSecurity\nA novel trust-based\nsafe data aggregation\n\
    approach and an\nenergy-efﬁcient safe\nrouting protocol\nare introduced.\nResearchers\
    \ propose ANT Particle Swarm\nOptimization Ad hoc On-demand Distance Vector\n\
    (ANTPSOAODV), a trust-based safe data\naggregation approach, and an energy-efﬁcient\
    \ safe\nrouting protocol for a multi-hop environment in an\nIoT-enabled wireless\
    \ sensor network.\n[11]\nIoT network\ncommunication\nResource\nutilization\nA\
    \ whale-based sensor\nclustering model\nis introduced.\nThe authors have proposed\
    \ a novel distributed\nmodel to effectively manage heterogeneous sensors\nand\
    \ select accurate ones in a dynamic IoT\nenvironment, using a bio-inspired clustering\n\
    algorithm: whale-based sensor clustering.\n[12]\nIoT network\ncommunication\n\
    Routing and\ntopology\nmaintenance\nA novel bio-inspired\nclustering algorithm\n\
    is proposed.\nThe authors have proposed a novel bio-inspired\nclustering algorithm\
    \ based on a honeybee algorithm,\ngenetic algorithm, and tabu search for IoT-enabled\n\
    mobile ad hoc networks.\n[13]\nIoT network\ncommunication\nRouting\nA new bio-inspired\n\
    cross-layer routing\nprotocol is purposed.\nThe researchers propose a new Bio-Inspired\n\
    Cross-Layer Routing (BiHCLR) protocol for efﬁcient\nand energy-efﬁcient routing\
    \ in IoT-enabled wireless\nsensor networks.\n[14]\nIoT network\ncommunication\n\
    Security\nA novel bio-inspired\nsecure IPv6\ncommunication\nprotocol is proposed.\n\
    The researchers propose a novel bio-inspired secure\nIpv6 communication protocol\
    \ for the IoT.\n[15]\nIoT network\ncommunication\nEnergy\nconsumption\nA new fusion\
    \ cluster\nhead selection\ntechnique is proposed.\nTo maximize the amount of time\
    \ that a wireless\nsensor network is operational, the optimal selection\nof cluster\
    \ heads is a crucial criterion that must be met.\nWith this in mind, the authors\
    \ present a new fusion\ncluster head selection technique that combines the\nadvantages\
    \ of the LEACH protocol and the\ndragonﬂy algorithm.\n[16]\nAgriculture\nEnergy\n\
    consumption\nand operational\ntime\nA bio-inspired\nself-learning\ncoevolutionary\n\
    algorithm is presented.\nThe authors present a bio-inspired self-learning\ncoevolutionary\
    \ algorithm for dynamic\nmulti-objective optimization of IoT services to cut\n\
    down on energy usage and service time.\n[17]\nIoT network\ncommunication\nRouting\n\
    A bio-inspired\nintelligent routing\nschema is proposed.\nTo reduce the amount\
    \ of energy an IoT network\nconsumes, an intelligent routing scheme based on a\n\
    bio-inspired technique is proposed that can\nsigniﬁcantly extend the IoT network’s\
    \ lifetime.\n[18]\nIoT network\ncommunication\nResource\nallocation\nA new bio-inspired\n\
    algorithm is presented\nfor distributed resource\nallocation.\nThe authors introduced\
    \ a multi-hop DESYNC\nalgorithm, which is a bio-inspired Time Division\nMultiple\
    \ Access (TDMA)-based strategy for\ndistributed resource allocation in sensor\
    \ networks.\nThe DESYNC algorithm draws inspiration from\nbiological systems to\
    \ allocate distributed\nresources efﬁciently.\n[19]\nIoT network\ncommunication\n\
    Routing\nA customized queen\nhoneybee migration\nalgorithm is presented.\nThe\
    \ researchers have enhanced the original queen\nhoneybee migration algorithm,\
    \ which was\nintroduced for efﬁcient mobile routing in WSN, using\nbinary testing\
    \ injection on the cooperative node’s\nselection on the IoT system.\nBiomimetics\
    \ 2023, 8, 373\n19 of 29\nTable 2. Cont.\nReference Domain\nApplication/s\nMain\
    \ Contribution\nScope of the Work\n[20]\nFog computing\nResource\nmanagement\n\
    A new bio-inspired\nalgorithm is presented\nfor resource allocation.\nThe authors\
    \ suggested a new bio-inspired hybrid\nalgorithm, which they referred to as the\
    \ NBI-HA.\nThis approach is a cross between Modiﬁed Particle\nSwarm Optimization\
    \ (MPSO) and Modiﬁed Cat\nSwarm Optimization (MCSO). The hybrid of the\nMPSO and\
    \ MCSO is utilized to manage resources at\nthe fog device level in the proposed\
    \ method.\n[21]\nEdge\ncomputing\nSecurity\nA novel bio-inspired\napproach is\
    \ presented\nfor enhancing the\nsecurity of IoT\napplications.\nThe authors have\
    \ demonstrated a combination of IoT\nperipheral sensors and low-power crypto engines.\n\
    Using bio-inspired systems as inspiration,\nTwo-Dimensional (2D) memtransistors\
    \ accomplish\nthe integration. This “all-in-one” solution seeks to\nenhance the\
    \ functionality and security of\nIoT applications.\n[24]\nIoT network\ncommunication\n\
    Performance\nand energy\nconsumption\nA novel bio-inspired\ntechnique is presented\n\
    in conjunction with\nfuzzy logic.\nThe authors present a technique that integrates\
    \ fuzzy\nlogic with various nature-inspired algorithms—grey\nwolf algorithm and\
    \ ﬁreﬂy algorithm—to effectively\nbalance the burden among IoT devices in a network.\n\
    [37]\nIoT network\ncommunication\nResource\nallocation\nA new ﬁreﬂy-based\nclustering\
    \ approach is\npresented.\nThe authors propose a new ﬁreﬂy-based clustering\n\
    approach for IoT applications.\n[38]\nUnmanned\nAerial Vehicles\n(UAVs)\nOptimal\
    \ path\nplanning\nA bio-inspired optimal\npath planning schema\nis presented.\n\
    Using a joint genetic algorithm and ant colony\noptimization, the authors have\
    \ proposed an optimal\nﬂight planning schema for UAVs.\n[39]\nIoT network\ncommunication\n\
    Energy\nconsumption\nA novel energy-aware\nclustering schema is\npresented.\n\
    Inspired by Particle Swarm Optimization (PSO), the\nauthors propose a novel energy-aware\
    \ bio-inspired\nclustering scheme (PSO-WZ) for IoT network\ncommunication.\n[40]\n\
    IoT network\ncommunication\nEnergy\nconsumption\nA novel bio-inspired\nenergy\
    \ optimization\napproach is presented.\nThe authors propose a novel Multi-Objective\n\
    Optimization (MOO) agent based on Particle Swarm\nGrey Wolf Optimization (PSGWO)\
    \ and inverse fuzzy\nranking for energy optimization of IoT networks.\n[43]\n\
    Smart vehicles\nEnergy\nconsumption\nA bio-inspired smart\nvehicle design is\n\
    presented.\nThe researchers have designed a bio-inspired smart\nvehicle with an\
    \ AI-enabled charging system.\n[44]\nIoT network\ncommunication\nData exchange\n\
    A novel bio-inspired\napproach is presented\nfor data exchange\nover WSNs.\nTwo\
    \ algorithms, Grey Wolf Optimizer (GWO) and\nWhale Optimization Algorithm (WOA),\
    \ in\nconjunction with the Imperialist Competitive\nAlgorithm (ICA)-based Cluster\
    \ Head (CH) selection\nand a novel approach, are proposed for\nheterogeneous networks.\
    \ These algorithms facilitate\ndata exchange over heterogeneous WSN\ninfrastructures\
    \ by addressing the buffer\noverﬂow issue.\n[46]\nSmart city\nEnergy\nconsumption\n\
    and quality of\ndata\nA novel bio-inspired\ndistributed\nevent-sensing and data\n\
    collection framework\nis presented.\nBased on Gene Regulatory Networks (GRNs)\
    \ in\nliving organisms, this paper proposes bioSmartSense,\na novel bio-inspired\
    \ distributed event-sensing and\ndata collection framework. The objective is to\
    \ make\nthe sensing and reporting processes more\nenergy efﬁcient.\nBiomimetics\
    \ 2023, 8, 373\n20 of 29\nTable 2. Cont.\nReference Domain\nApplication/s\nMain\
    \ Contribution\nScope of the Work\n[47]\nFog computing\nService\nallocation\n\
    A novel bio-inspired\nalgorithm is presented\nfor service allocation.\nThe researchers\
    \ have developed a hybrid algorithm\nusing a genetic algorithm and particle swarm\n\
    optimization technique to solve the service allocation\nproblems pertaining to\
    \ fog computing.\n[48]\nTransportation\nAnomaly\ndetection\n(detection of\nroad\
    \ cracks)\nA bio-inspired deep\nlearning approach is\npresented.\nThe authors\
    \ have proposed an IoT system with a\nbio-inspired deep learning approach for\
    \ accurate\nroad crack detection.\n[51]\nIoT network\ncommunication\nEnergy\n\
    consumption\nand routing\nA novel bio-inspired\nrouting algorithm is\npresented.\n\
    The researchers have presented a novel routing\nalgorithm designed to extend the\
    \ longevity of the\nnetwork and conserve the energy of sensor nodes\nconnected\
    \ to the WSN. The proposed algorithm is a\nhybrid of genetic and ant colony\n\
    optimization algorithms.\n[52]\nIoT network\ncommunication\nSecurity\nA novel\
    \ bio-inspired\nensemble classiﬁer is\nintroduced.\nThe authors have introduced\
    \ a novel bio-inspired\nensemble classiﬁer towards improving the\nperformance\
    \ of anomaly detection of IoT networks.\n[53]\nIoT network\ncommunication\nSecurity\n\
    A novel layered\nartiﬁcial immune\nsystem approach,\ninspired by the natural\n\
    immunity mechanism,\nis proposed.\nThe authors have introduced a novel layered\
    \ artiﬁcial\nimmune system approach, inspired by the natural\nimmunity mechanism,\
    \ and adapted an architecture\ncalled ImmuneGAN to identify the affected network\n\
    packets in the IoT network to detect\nsecurity anomalies.\n[54]\nIoT network\n\
    communication\nSecurity\nA novel secure and\nlightweight dynamic\nencryption bio-inspired\n\
    model is introduced.\nThe researchers have introduced a design for a novel\nsecure\
    \ and lightweight dynamic encryption\nbio-inspired model for IoT networks and\n\
    demonstrated that it applies to a broad range of\nlow-complexity IoT deployments.\n\
    [55]\nIoT network\ncommunication\nEnergy\nconsumption\nand routing\nA novel bio-inspired\n\
    algorithm is proposed\nfor determining the\noptimal path.\nResearchers propose\
    \ a novel algorithm based on ant\ncolony optimization for determining the optimal\n\
    path for data transmission in WSNs.\n[56]\nHealthcare\nImage\nprocessing\nA novel\
    \ swarm\nintelligence-based\nimage processing\napproach is introduced.\nThe authors\
    \ have proposed a novel swarm\nintelligence-based approach for lung cancer detection\n\
    and transmission of gathered data to the cloud.\n[57]\nIoT network\ncommunication\n\
    Routing\nA novel bio-inspired\nmiddleware for WSN is\nintroduced.\nThe authors\
    \ have introduced a novel bio-inspired\nmiddleware for WSNs, with the aim of introducing\n\
    self-adaptive architecture.\n[58]\nFog computing\n/ mist\ncomputing\nData\ndistribution\n\
    A bio-inspired\nalgorithm for data\ndistribution is\nintroduced.\nThe researchers\
    \ have proposed a novel bio-inspired\nalgorithm for data distributions in fog\
    \ and mist\ncomputing environments.\n[59]\nIoT network\ncommunication\nSecurity\n\
    A novel intrusion\ndetection system\ninspired by the grey\nwolf algorithm\nis\
    \ introduced.\nThe authors have introduced an intrusion detection\nsystem modeled\
    \ as a two-stage framework with\nfeature selection performed by a generalized\
    \ mean\ngrey wolf algorithm and an elastic net contractive\nautoencoder for classifying\
    \ malicious trafﬁc in\nIoT networks.\nBiomimetics 2023, 8, 373\n21 of 29\nTable\
    \ 2. Cont.\nReference Domain\nApplication/s\nMain Contribution\nScope of the Work\n\
    [62]\nIoT network\ncommunication\nRouting\nA novel ant colony\nmetaphor-based\n\
    approach is introduced\nfor optimized routing.\nThe researchers introduce AntNet,\
    \ a novel approach\nto the adaptive learning of routing tables in\ncommunications\
    \ networks.\n[68]\nUAVs\nRoute selection\nA novel bio-inspired\nclustering scheme\
    \ is\nintroduced.\nThe researchers propose a novel bio-inspired\nclustering scheme\
    \ using a dragonﬂy algorithm for\ncluster formation and management in route planning\n\
    for UAVs.\n[69]\nIoT network\ncommunication\nSelf-\norganization\nand routing\n\
    A novel swarm\nintelligence-based\nalgorithm is introduced\nfor performing\nself-organization\n\
    in WSNs.\nThe researchers present Bio-Inspired Optimization\nfor Sensor Network\
    \ Lifetime (BiO4SeL), a swarm\nintelligence-based algorithm, to perform\nself-organization\
    \ and optimization of a lifetime by\nmeans of routing into a WSN.\n[70]\nIoT\n\
    communication\nnetwork\nSecurity\nA novel bio-inspired\nself-organized secure\n\
    autonomous routing\nprotocol is introduced.\nThe authors present a Bio-Inspired\
    \ Self-Organized\nSecure Autonomous Routing Protocol (BIOSARP)\nand Secured Data\
    \ Assured Routing (SDAR) in WSNs.\n[71]\nIoT network\ncommunication\nSecurity\n\
    A novel bio-inspired\nself-organized secure\nautonomous routing\nprotocol is introduced.\n\
    The researchers introduce a Self-Organized Secure\nAutonomous Routing Protocol\
    \ (BIOSARP) which\nenhances a WSN in securing itself from abnormalities\nand most\
    \ common WSN routing attacks.\nWith the summarization of the literature we have\
    \ analyzed, it is evident that bio-\ninspired IoT is applied to almost all the\
    \ domains we have mentioned above, such as smart\ncities, transportation, agriculture,\
    \ and so on. Further, in terms of the speciﬁcal applications\nit is going to optimize,\
    \ we have noted several applications such as security, routing, energy\nconsumption,\
    \ path planning, anomaly detection, performance, and resource allocation.\n4.1.\
    \ Comparison of Recent Survey Studies\nThe following Table 3 provides a brief\
    \ summary and a comparison of recent survey\nstudies with our work. The survey\
    \ articles presented in the summary were chosen based on\nthe scope of the survey,\
    \ whether the authors have discussed bio-inspiration, bio-inspired\nalgorithms,\
    \ or bio-inspired IoT, and its latest status and anticipated future directions.\n\
    Table 3. Comparison of recent surveys (Yes—\x14, No—\x18).\nReference\nScope of\
    \ the Work\nDiscusses Bio-Inspiration\nDiscusses Bio-Inspired\nAlgorithms\nDiscusses\
    \ Bio-Inspired IoT\nThe Current Status of\nBio-Inspired IoT Is\nDiscussed\nChallenges\
    \ and Future\nDirections of Bio-Inspired\nIoT Are Discussed\n[5]\nHighlighted\
    \ the statistics pertaining to the use of bio-inspired\nsolutions and traditional\
    \ technologies to overcome the challenges\nassociated with IoT.\n\x14\n\x18\n\x18\
    \n\x14\n\x18\n[22]\nResearchers have examined the biologically inspired algorithms\
    \ used\nfor solving challenges posed by different sensor mobility schemes in\n\
    the context of IoT applications.\n\x18\n\x14\n\x18\n\x18\n\x18\nBiomimetics 2023,\
    \ 8, 373\n22 of 29\nTable 3. Cont.\nReference\nScope of the Work\nDiscusses Bio-Inspiration\n\
    Discusses Bio-Inspired\nAlgorithms\nDiscusses Bio-Inspired IoT\nThe Current Status\
    \ of\nBio-Inspired IoT Is\nDiscussed\nChallenges and Future\nDirections of Bio-Inspired\n\
    IoT Are Discussed\n[23]\nProvided a review of how IoT-based AI-enabled bio-inspired\n\
    solutions can be used as a remedy to ﬁght against cyber-crimes.\n\x14\n\x14\n\x18\
    \n\x18\n\x18\n[25]\nProvided a review of bio-inspired solutions that can be used\
    \ to solve\ncomplex engineering problems.\n\x18\n\x14\n\x18\n\x18\n\x18\n[27]\n\
    Presents a comprehensive review of the state of the art, nine\nbio-inspired computing\
    \ algorithms, and their applications.\n\x14\n\x14\n\x18\n\x18\n\x18\n[36]\nProvides\
    \ perspectives on bio-inspired technologies and offers a brief\ndiscussion on\
    \ how such technologies can be used to solve day-to-day\nchallenges in a low-cost\
    \ and sustainable way.\n\x14\n\x18\n\x18\n\x18\n\x18\n[41]\nExplores how bio-inspired\
    \ approaches can be used to secure\nIoT ecosystems.\n\x18\n\x14\n\x18\n\x18\n\x18\
    \n[45]\nExamines 5G network layer security for IoT applications and\nprovides\
    \ a list of network layer security vulnerabilities and\nrequirements for WSNs,\
    \ IoT, and 5G-enabled IoT. Secondly, it\nprovides a comprehensive review of the\
    \ presented network layer\nsecurity methods and bio-inspired techniques for IoT\
    \ applications\nexchanging data packets over 5G, including analysis of bio-inspired\n\
    algorithms in terms of providing a secure network layer for IoT\napplications\
    \ connected to 5G and beyond networks.\n\x18\n\x14\n\x18\n\x14\n\x14\n[49]\nThe\
    \ authors have provided a review of bio-inspired\noptimization algorithms.\n\x14\
    \n\x14\n\x18\n\x18\n\x18\n[60]\nThe authors have provided an in-depth analysis\
    \ of swarm\nintelligence models and how they can be applied to complex systems.\n\
    \x14\n\x14\n\x18\n\x18\n\x18\n[61]\nProvides an in-depth insight into how swarm\
    \ intelligence can be used\nto solve complex engineering problems.\n\x18\n\x14\
    \n\x18\n\x18\n\x18\n[63]\nThe authors discuss state-of-the-art bio-inspired research\
    \ for\ncommunication technology in IoT networks.\n\x14\n\x14\n\x18\n\x18\n\x18\
    \n[65]\nThe swarm intelligence algorithms in IoT are investigated with a\nspecial\
    \ focus on the Internet of Medical Things.\n\x18\n\x14\n\x18\n\x18\n\x18\n[66]\n\
    This study provides a review of swarm intelligence algorithms and\ntheir potential\
    \ use in IoT-based applications.\n\x14\n\x14\n\x18\n\x18\n\x18\n[67]\nThe researchers\
    \ provide an overview of the conﬂuence between big\ndata technologies and bio-inspired\
    \ computation.\n\x18\n\x14\n\x18\n\x18\n\x18\n[72]\nProvides a review of swarm\
    \ intelligence algorithms and summarizes\ntheir applications in the IoT.\n\x18\
    \n\x14\n\x18\n\x18\n\x18\n[73]\nProvides a review of a set of swarm intelligence\
    \ algorithms applied to\nthe main challenges introduced by the IoT.\n\x18\n\x14\
    \n\x18\n\x18\n\x18\nOur work\nPresents a comprehensive review on bio-inspired\
    \ IoT, how it came in\nto play, its ecosystem, state of the art, current status,\
    \ challenges, and\nfuture directions.\n\x14\n\x14\n\x14\n\x14\n\x14\nOverall,\
    \ in recent years there has been clear growth in the number of research activities\n\
    in the context of bio-inspired IoT whereas no reviews/surveys have been conducted\n\
    speciﬁcally on bio-inspired IoT, owing to the novelty of the ﬁeld. Thus, with\
    \ our review\nof bio-inspired IoT, we believe our work would inspire future research\
    \ in the context of\nbio-inspired IoT.\nBiomimetics 2023, 8, 373\n23 of 29\n4.2.\
    \ Comparison of IoT and Bio-Inspired IoT\nBased on the state of the art, the following\
    \ Table 4 highlights key differences between\ntraditional IoT and bio-inspired\
    \ IoT. Accordingly, it is evident that bio-inspired IoT is far\nahead of traditional\
    \ IoT as bio-inspired IoT is capable of overcoming most of the constraints\npertaining\
    \ to traditional IoT.\nTable 4. Difference between traditional IoT and bio-inspired\
    \ IoT.\nCriteria\nIoT\nBio-Inspired IoT\nDesign\nTechnology-driven and focused\
    \ on\nconnectivity and data\nBio-inspired algorithms are driven by\nbiological\
    \ principles\nOptimization\nCentralized control and optimization\nalgorithms\n\
    Decentralized decision making and\ncollective intelligence\nScalability\nScalability\
    \ challenges due to the\nincreasing number of devices\nSwarm intelligence allows\
    \ efﬁcient\nscalability\nResource efﬁciency\nOptimization focused on energy and\n\
    resource usage\nEfﬁciency in resource allocation and\nenergy management\nSecurity\
    \ and privacy\nTraditional security and privacy concerns\nBio-inspired algorithms\
    \ may introduce\nnew security challenges\nAdaptability\nLimited adaptability to\
    \ changing\nconditions\nAdaptive and robust to dynamic\nenvironments similar to\
    \ biological\norganisms\nLearning and adaptation\nMachine learning/deep learning\n\
    techniques applied for data analysis\nBio-inspired algorithms with adaptive\n\
    learning capabilities\n5. Challenges Pertaining to Bio-Inspired IoT\nWhile bio-inspired\
    \ IoT offers varying beneﬁts as opposed to traditional IoT, it also\nfaces certain\
    \ challenges. The following describes key challenges pertaining to bio-inspired\n\
    IoT as we have noted through the state of the art.\n1.\nComplexity and scalability\n\
    Bio-inspired algorithms often involve complex interactions and computations, espe-\n\
    cially when simulating swarm intelligence or evolutionary processes. Scaling up\
    \ these\nalgorithms to handle large-scale IoT systems with a massive number of\
    \ devices and data\npoints can be a challenging task. Thus, efﬁciently managing\
    \ the complexity and ensuring\nthe scalability of bio-inspired IoT solutions require\
    \ careful design and optimization [34–36].\n2.\nResource constraint nature\nIoT\
    \ devices are typically resource-constrained in terms of computational power,\
    \ mem-\nory, energy, and bandwidth [32]. Bio-inspired algorithms, especially those\
    \ involving\ncomplex computations or large populations, can impose signiﬁcant\
    \ resource demands\non IoT devices. Thus, designing bio-inspired IoT solutions\
    \ that are efﬁcient in terms\nof computational requirements and resource usage\
    \ becomes crucial to overcome these\nconstraints [32,34–36].\n3.\nAdaptability\
    \ and robustness\nBio-inspired algorithms are known for their adaptability and\
    \ robustness. However,\nadapting these algorithms to dynamic and evolving IoT\
    \ environments poses challenges.\nIoT systems experience changes in device availability,\
    \ network conditions, and data char-\nacteristics, requiring bio-inspired IoT\
    \ solutions to be resilient and adaptive to such varia-\ntions [27,35,49].\nBiomimetics\
    \ 2023, 8, 373\n24 of 29\n4.\nSecurity and privacy\nIn general, IoT systems raise\
    \ concerns about security and privacy, and bio-inspired\nIoT is no exception.\
    \ The interconnected nature of IoT devices and the use of bio-inspired\nalgorithms\
    \ can introduce vulnerabilities, such as attacks on swarm intelligence or genetic\n\
    processes [73]. Thus, ensuring the security and privacy of data, communications,\
    \ and\nalgorithms in bio-inspired IoT is an ongoing challenge that many researchers\
    \ are currently\nworking on [34–36].\n5.\nInteroperability and standardization\n\
    Bio-inspired IoT solutions may involve different devices, protocols, or platforms,\
    \ lead-\ning to interoperability challenges [32–36]. Integrating diverse devices,\
    \ algorithms, and data\nformats can be complex, requiring standardized interfaces\
    \ and protocols for seamless com-\nmunication and collaboration. Hence, developing\
    \ interoperable bio-inspired IoT solutions\nis crucial for their widespread adoption\
    \ and integration into existing IoT ecosystems.\n6.\nEthical and legal considerations\n\
    Bio-inspired IoT solutions may raise ethical and legal concerns, particularly\
    \ when they\ninvolve autonomous decision making, learning from data, or privacy-sensitive\
    \ information.\nAddressing issues related to accountability, fairness, transparency,\
    \ data privacy, and com-\nplying with available policies and regulations is essential\
    \ to ensure responsible deployment\nand use of bio-inspired IoT solutions.\nIn\
    \ summary, addressing all these challenges requires interdisciplinary research,\
    \ collab-\noration, and a holistic approach that considers the technical, computational,\
    \ environmental,\nsocial, and ethical aspects of bio-inspired IoT systems.\n6.\
    \ Current Status and Future Directions\nBio-inspired IoT aims to address various\
    \ challenges in traditional IoT systems, such\nas scalability, energy efﬁciency,\
    \ adaptability, and fault tolerance. Drawing inspiration\nfrom biological systems,\
    \ it aids in designing IoT systems that can self-organize, self-heal,\nand adapt\
    \ to changing environments. As of now, according to the latest statistics, there\n\
    are around 16 billion IoT devices, a number which is expected to double by 2030\
    \ [29–31].\nOn the other hand, the market size was valued at nearly USD 600 billion\
    \ in 2022, and it\nis expected to reach more than USD 3000 billion in 2030 [29–31].\
    \ Thus, being a rapidly\ngrowing technological ecosystem, it is expected that\
    \ the challenges that IoT may encounter\nmay also grow in the long run. Hence\
    \ even though the research in terms of bio-inspired IoT\nis still at an early\
    \ stage, it is expected that it will also continue to grow toward designing\n\
    robust, safe, and resilient IoT solutions in the long run [74,75]. According to\
    \ our review,\nit is evident that the integration of bio-inspired solutions with\
    \ the IoT holds tremendous\npotential for shaping the future of technology and\
    \ determining the future of the human\nrace, enabling us to overcome whatever\
    \ challenges we encounter. Such bio-inspired IoT\nsolutions would continue to\
    \ grow in the long run, and in this regard, anticipated future\ndirections of\
    \ bio-inspired IoT are highlighted in the following for better understanding.\n\
    1.\nHybrid approaches\nThe integration of bio-inspired algorithms with other computational\
    \ techniques, such\nas machine learning, deep learning, and data analytics, can\
    \ enhance the capabilities of\nbio-inspired IoT [63,64,73–78]. Hybrid approaches\
    \ that combine the strengths of different\nalgorithms and methodologies are likely\
    \ to emerge, enabling more powerful and adaptable\nsolutions [74,75,79].\n2.\n\
    Integration with edge computing/fog computing\nWith the growing emphasis on edge\
    \ /fog computing in IoT, bio-inspired algorithms\ncan be leveraged at the edge\
    \ to enable intelligent decision making and resource optimiza-\ntion [30–34].\
    \ Bio-inspired edge intelligence can lead to more autonomous, energy-efﬁcient,\n\
    Biomimetics 2023, 8, 373\n25 of 29\nand responsive IoT systems that process data\
    \ and make decisions locally, reducing latency\nand bandwidth requirements.\n\
    3.\nExplainability and interpretability\nAs bio-inspired IoT systems become more\
    \ complex and autonomous, the need for\nexplainable and interpretable models and\
    \ algorithms becomes critical. Research focusing on\nunderstanding and interpreting\
    \ the decision-making processes of bio-inspired algorithms\ncan lead to more trustworthy\
    \ and transparent IoT systems, enabling users to comprehend\nand validate the\
    \ outputs and behavior of such systems [48–50,73–75].\n4.\nCollaborative and cooperative\
    \ bio-inspired IoT systems\nExploring the collective behavior and cooperation\
    \ among multiple bio-inspired IoT\nsystems can lead to innovative solutions [76,77].\
    \ Research on collaborative algorithms,\ncoordination mechanisms, and collective\
    \ decision making can enable IoT systems to work\ntogether as intelligent collectives,\
    \ sharing information and optimizing tasks in a cooperative\nmanner [73].\n5.\n\
    Ethical and social considerations\nAs bio-inspired IoT becomes more integrated\
    \ into various aspects of daily life, ad-\ndressing ethical and social implications\
    \ is crucial. Hence, future research should focus on\nunderstanding and addressing\
    \ issues related to bias, fairness, accountability, transparency,\nand the social\
    \ impact of bio-inspired IoT systems [49,73–75].\n7. Conclusions\nWith the emergence\
    \ of bio-inspired IoT, researchers have been able to develop creative\nsolutions\
    \ to handle the complex issues faced by IoT deployments by pulling inspiration\n\
    from biological systems such as diverse ecosystems and swarms. In the study, we\
    \ have car-\nried out a review of what is meant by bio-inspiration, how bio-inspired\
    \ IoT can overcome\nthe challenges associated with traditional IoT, bio-inspired\
    \ solutions, and the ecosystem\nof bio-inspired IoT, highlighting challenges and\
    \ future directions. With the review per-\nformed, it is evident that bio-inspired\
    \ IoT has shown exceptional ﬂexibility and robustness\nin various domains where\
    \ traditional IoT solutions are not capable of delivering such\nbeneﬁts. According\
    \ to the state of the art, researchers have suggested decentralized and au-\n\
    tonomous designs for IoT networks based on the self-organizing and self-healing\
    \ qualities\nof natural systems, allowing them to dynamically adapt to changing\
    \ conditions, reorganize\nthemselves, and recover from failures. These bio-inspired\
    \ techniques have the potential to\nprovide extremely scalable and durable IoT\
    \ systems that can survive disturbances while\nmaintaining consistent connections.\
    \ Nonetheless, it is also evident that the bio-inspired\nIoT paradigm has considerable\
    \ environmental advantages where researchers have created\nenergy-efﬁcient communication\
    \ protocols, low-power sensor networks, and intelligent\ndata-processing approaches\
    \ by mimicking nature’s efﬁciency and sustainability. These\ndevelopments not\
    \ only reduce the carbon footprint of IoT installations but also allow\nIoT technologies\
    \ to be integrated into environmentally benign applications such as smart\nagriculture,\
    \ wildlife monitoring, and smart cities. However, while bio-inspired IoT systems\n\
    have enormous promise, there are several difﬁculties and prospects for further\
    \ study. The\nscalability and security of these systems continue to be signiﬁcant\
    \ challenges, similar to\ntraditional IoT solutions, necessitating more research\
    \ in the area. On the other hand, ethical\nproblems, privacy concerns, and the\
    \ responsible use of data must all be properly addressed\nfor bio-inspired IoT\
    \ to be a stable technology, which researchers are currently working\non. In conclusion,\
    \ bio-inspired IoT solutions will surely play a critical part in deﬁning the\n\
    next generation of smart and pervasive solutions enhancing the power of the biological\n\
    world, ushering us into a more efﬁcient, robust, and harmonious future as we continue\
    \ to\ninvestigate the synergy between nature and technology.\nBiomimetics 2023,\
    \ 8, 373\n26 of 29\nFunding: This research was funded by Qassim University.\n\
    Institutional Review Board Statement: Not applicable.\nData Availability Statement:\
    \ No new data is created.\nAcknowledgments: The researchers would like to thank\
    \ the Deanship of Scientiﬁc Research, Qassim\nUniversity for funding the publication\
    \ of this project.\nConﬂicts of Interest: The authors declare no conﬂict of interest.\n\
    References\n1.\nAlroobaea, R.; Arul, R.; Rubaiee, S.; Alharithi, F.S.; Tariq,\
    \ U.; Fan, X. AI-assisted bio-inspired algorithm for secure IoT communica-\ntion\
    \ networks. Clust. Comput. 2022, 25, 1805–1816. [CrossRef]\n2.\nAruquipa, G.;\
    \ Diaz, F. An IoT architecture based on the control of Bio Inspired manufacturing\
    \ system for the detection of\nanomalies with vibration sensors. Procedia Comput.\
    \ Sci. 2022, 200, 438–450. [CrossRef]\n3.\nJohnson, A.P.; Al-Aqrabi, H.; Hill,\
    \ R. Bio-Inspired Approaches to Safety and Security in IoT-Enabled Cyber-Physical\
    \ Systems.\nSensors 2020, 20, 844. [CrossRef] [PubMed]\n4.\nMariyanayagam, D.;\
    \ Shukla, P.; Virdee, B.S. Bio-Inspired Framework for Security in IoT Devices.\
    \ In Proceedings of the 5th\nWorld Conference on Smart Trends in Systems Security\
    \ and Sustainability, WS4 2021, London, UK, 29–30 July 2021; pp. 749–757.\n[CrossRef]\n\
    5.\nHamidouche, R.; Aliouat, Z.; Gueroui, A.M. Bio-Inspired vs Classical Solutions\
    \ to Overcome the IoT Challenges. In Proceedings\nof the 2018 3rd Cloudiﬁcation\
    \ of the Internet of Things (CIoT), Paris, France, 2–4 July 2018; pp. 1–7. [CrossRef]\n\
    6.\nKumar, M.; Kumar, S.; Kashyap, P.K.; Aggarwal, G.; Rathore, R.S.; Kaiwartya,\
    \ O.; Lloret, J. Green Communication in Internet of\nThings: A Hybrid Bio-Inspired\
    \ Intelligent Approach. Sensors 2022, 22, 3910. [CrossRef]\n7.\nWu, D.; Zhang,\
    \ Z.; Wu, S.; Yang, J.; Wang, R. Biologically Inspired Resource Allocation for\
    \ Network Slices in 5G-Enabled Internet\nof Things. IEEE Internet Things J. 2019,\
    \ 6, 9266–9279. [CrossRef]\n8.\nRapti, E.; Houstis, C.; Houstis, E.; Karageorgos,\
    \ A. A Bio-Inspired Service Discovery and Selection Approach for IoT Applications.\n\
    In Proceedings of the 2016 IEEE International Conference on Services Computing\
    \ (SCC), San Francisco, CA, USA, 27 June–2 July\n2016; pp. 868–871. [CrossRef]\n\
    9.\nSingh, R.; Ujjwal, R.L. Hybridized bio-inspired intrusion detection system\
    \ for Internet of Things. Front. Big Data 2023, 6, 1081466.\n[CrossRef] [PubMed]\n\
    10.\nChandnani, N.; Khairnar, C.N. Bio-Inspired Multilevel Security Protocol for\
    \ Data Aggregation and Routing in IoT WSNs. Mob.\nNetw. Appl. 2022, 27, 1030–1049.\
    \ [CrossRef]\n11.\nBouarourou, S.; Boulaalam, A.; Nfaoui, E.H. A bio-inspired\
    \ adaptive model for search and selection in the Internet of Things\nenvironment.\
    \ PeerJ Comput. Sci. 2021, 7, e762. [CrossRef]\n12.\nAhmad, M.; Hameed, A.; Ullah,\
    \ F.; Wahid, I.; Rehman, S.U.; Khattak, H.A. A bio-inspired clustering in mobile\
    \ adhoc networks for\ninternet of things based on honey bee and genetic algorithm.\
    \ J. Ambient. Intell. Humaniz. Comput. 2020, 11, 4347–4361. [CrossRef]\n13.\n\
    Tandon, A.; Kumar, P.; Rishiwal, V.; Yadav, M.; Yadav, P. A Bio-inspired Hybrid\
    \ Cross-Layer Routing Protocol for Energy\nPreservation in WSN-Assisted IoT. KSII\
    \ Trans. Internet Inf. Syst. 2021, 15, 1317–1341. [CrossRef]\n14.\nSaleem, K.;\
    \ Chaudhry, J.; Orgun, M.A.; Al-Muhtadi, J. A bio-inspired secure IPv6 communication\
    \ protocol for Internet of Things.\nIn Proceedings of the 2017 Eleventh International\
    \ Conference on Sensing Technology (ICST), Sydney, NSW, Australia, 4–6\nDecember\
    \ 2017; pp. 1–6. [CrossRef]\n15.\nDevassy, D.; Johnraja, J.I.; Paulraj, G.J.L.\
    \ NBA: Novel bio-inspired algorithm for energy optimization in WSN for IoT applications.\n\
    J. Supercomput. 2022, 78, 16118–16135. [CrossRef]\n16.\nYang, Z.; Jin, Y.; Hao,\
    \ K. A Bio-Inspired Self-Learning Coevolutionary Dynamic Multiobjective Optimization\
    \ Algorithm for\nInternet of Things Services. IEEE Trans. Evol. Comput. 2019,\
    \ 23, 675–688. [CrossRef]\n17.\nSackey, S.H.; Chen, J.; Ansere, J.A.; Gapko, G.K.;\
    \ Kamal, M. A Bio-Inspired Technique based on Knowledge Discovery for Routing\n\
    in IoT Networks. In Proceedings of the 2020 IEEE 23rd International Multitopic\
    \ Conference (INMIC), Bahawalpur, Pakistan, 5–7\nNovember 2020; pp. 1–6. [CrossRef]\n\
    18.\nKim, Y.-J.; Choi, H.-H.; Lee, J.-R. A Bioinspired Fair Resource-Allocation\
    \ Algorithm for TDMA-Based Distributed Sensor Networks\nfor IoT. Int. J. Distrib.\
    \ Sens. Netw. 2016, 12, 7296359. [CrossRef]\n19.\nAripriharta; Hao, W.Z.; Muladi;\
    \ Horng, G.-J.; Jong, G.-J. A New Bio-Inspired for Cooperative Data Transmission\
    \ of IoT. IEEE\nAccess 2020, 8, 161884–161893. [CrossRef]\n20.\nRaﬁque, H.; Shah,\
    \ M.A.; Islam, S.U.; Maqsood, T.; Khan, S.; Maple, C. A Novel Bio-Inspired Hybrid\
    \ Algorithm (NBIHA) for\nEfﬁcient Resource Management in Fog Computing. IEEE Access\
    \ 2019, 7, 115760–115773. [CrossRef]\n21.\nDodda, A.; Trainor, N.; Redwing, J.M.;\
    \ Das, S. All-in-one, bio-inspired, and low-power crypto engines for near-sensor\
    \ security\nbased on two-dimensional memtransistors. Nat. Commun. 2022, 13, 3587.\
    \ [CrossRef] [PubMed]\n22.\nHamidouche, R.; Aliouat, Z.; Gueroui, A.M.; Ari, A.A.A.;\
    \ Louail, L. Classical and bio-inspired mobility in sensor networks for IoT\n\
    applications. J. Netw. Comput. Appl. 2018, 121, 70–88. [CrossRef]\nBiomimetics\
    \ 2023, 8, 373\n27 of 29\n23.\nBalasaraswathi, M.; Sivasankaran, V.; Akshaya,\
    \ N.; Baskar, R.; Suganya, E. Internet of Things (IoT) Based Bio-inspired Artiﬁcial\n\
    Intelligent Technique to Combat Cybercrimes: A Review. In Internet of Things in\
    \ Smart Technologies for Sustainable Urban\nDevelopment; Kanagachidambaresan,\
    \ G.R., Maheswar, R., Manikandan, V., Ramakrishnan, K., Eds.; EAI/Springer Innovations\
    \ in\nCommunication and Computing; Springer International Publishing: Cham, Switzerland,\
    \ 2020; pp. 141–155. [CrossRef]\n24.\nSharma, D.K.; Mishra, J.; Singh, A.; Govil,\
    \ R.; Singh, K.K.; Singh, A. Optimized Resource Allocation in IoT using Fuzzy\
    \ Logic and\nBio-Inspired Algorithms. Wirel. Pers. Commun. 2023, 131, 1393–1413.\
    \ [CrossRef]\n25.\nSethi, M.A.J.; Ijaz, M.; Urooj, H.; Hussin, F.A. Bio-Inspired\
    \ Solutions and Its Impact on Real-World Problems: A Network on Chip\n(NoC) Perspective.\
    \ In Application Speciﬁc Integrated Circuits—Technologies, Digital Systems and\
    \ Design Methodologies; Fisher, E., Ed.;\nIntechOpen: London, UK, 2019. [CrossRef]\n\
    26.\nExamples of Bio-Inspired Solutions That Are More Efﬁcient Than Current Ones.\
    \ Human Kinetics. Available online: https://us.\nhumankinetics.com/blogs/excerpt/examples-of-bio-inspired-solutions-that-are-more-efﬁcient-than-current-ones\
    \ (accessed on\n17 May 2023).\n27.\nDarwish, A. Bio-inspired computing: Algorithms\
    \ review, deep analysis, and the scope of applications. Future Comput. Inform.\
    \ J.\n2018, 3, 231–246. [CrossRef]\n28.\nZegzhda, P.; Zegzhda, D.; Kalinin, M.;\
    \ Pechenkin, A.; Minin, A.; Lavrova, D. Safe Integration of SIEM Systems with\
    \ Internet of\nThings: Data Aggregation, Integrity Control, and Bioinspired Safe\
    \ Routing. In Proceedings of the 9th International Conference on\nSecurity of\
    \ Information and Networks, Newark, NJ, USA, 20–22 July 2016; ACM: New York, NY,\
    \ USA, 2016; pp. 81–87. [CrossRef]\n29.\nDressler, F.; Akan, O. Bio-inspired networking:\
    \ From theory to practice. IEEE Commun. Mag. 2010, 48, 176–183. [CrossRef]\n30.\n\
    IoT Sensors Market Size, Share & Analysis | Forecast—2030.\nAllied Market Research.\n\
    Available online: https://www.\nalliedmarketresearch.com/iot-sensors-market-A13095\
    \ (accessed on 19 May 2023).\n31.\nPentelovitch, N.; Nagel, J.K. Understanding\
    \ the Use of Bio-Inspired Design Tools by Industry Professionals. Biomimetics\
    \ 2022,\n7, 63. [CrossRef] [PubMed]\n32.\nGupta, B.B.; Quamara, M. An overview\
    \ of Internet of Things (IoT): Architectural aspects, challenges, and protocols.\
    \ Concurr.\nComput. Pract. Exp. 2020, 32, e4946. [CrossRef]\n33.\nA Reference\
    \ Architecture for the Internet of Things. Available online: https://wso2.com/whitepapers/a-reference-architecture-\n\
    for-the-internet-of-things/ (accessed on 23 May 2023).\n34.\nHegde, S.G. Study\
    \ of IoT: Understanding IoT Architecture, Applications, Issues and Challenges.\
    \ Int. J. Adv. Netw. Appl.\n2016, 478, 477–482.\n35.\nGardaševi´c, G.; Veleti´c,\
    \ M.; Maleti´c, N.; Vasiljevi´c, D.; Radusinovi´c, I.; Tomovi´c, S.; Radonji´c,\
    \ M. The IoT Architectural Framework,\nDesign Issues and Application Domains.\
    \ Wirel. Pers. Commun. 2017, 92, 127–148. [CrossRef]\n36.\nArena, P.; Bucolo,\
    \ M.; Buscarino, A.; Fortuna, L.; Frasca, M. Reviewing Bioinspired Technologies\
    \ for Future Trends: A Complex\nSystems Point of View. Front. Phys. 2021, 9, 750090.\
    \ Available online: https://www.frontiersin.org/articles/10.3389/fphy.2021.7\n\
    50090 (accessed on 23 May 2023). [CrossRef]\n37.\nJabeur, N.; Yasar, A.U.-H.;\
    \ Shakshuki, E.; Haddad, H. Toward a bio-inspired adaptive spatial clustering\
    \ approach for IoT\napplications. Future Gener. Comput. Syst. 2020, 107, 736–744.\
    \ [CrossRef]\n38.\nYang, Q.; Yoo, S.-J. Optimal UAV Path Planning: Sensing Data\
    \ Acquisition Over IoT Sensor Networks Using Multi-Objective\nBio-Inspired Algorithms.\
    \ IEEE Access 2018, 6, 13671–13684. [CrossRef]\n39.\nZhang, Y.; Wang, Y. A novel\
    \ energy-aware bio-inspired clustering scheme for IoT communication. J. Ambient.\
    \ Intell. Humaniz.\nComput. 2020, 11, 4239–4248. [CrossRef]\n40.\nGhorpade, S.;\
    \ Zennaro, M.; Chaudhari, B.S. Towards green computing: Intelligent bio-inspired\
    \ agent for IoT-enabled wireless\nsensor networks. Int. J. Sens. Netw. 2021, 35,\
    \ 121. [CrossRef]\n41.\nBanu, D.R. A Review on Biologically Inspired Approaches\
    \ to Security for Internet of Things (IoT). In Proceedings of the 2016\nInternational\
    \ Conference on Electrical, Electronics, and Optimization Techniques (ICEEOT),\
    \ Chennai, India, 3–5 March 2016.\n42.\nGracanin, D.; D’Amico, A.; Manuel, M.;\
    \ Carson, W.; Eltoweissy, M.; Cheng, L. Biologically inspired safety and security\
    \ for smart\nbuilt environments: Position paper. In Proceedings of the 2018 IEEE\
    \ Security and Privacy Workshops (SPW), San Francisco, CA,\nUSA, 25 May 2018;\
    \ IEEE: Piscataway, NJ, USA, 2018; pp. 293–298.\n43.\nJain, R.; Chakravarthi,\
    \ M.K.; Kumar, P.K.; Hemakesavulu, O.; Ramirez-Asis, E.; Pelaez-Diaz, G.; Mahaveerakannan,\
    \ R. Internet of\nThings-based smart vehicles design of bio-inspired algorithms\
    \ using artiﬁcial intelligence charging system, Nonlinear Engineering.\nNonlinear\
    \ Eng. 2022, 11, 582–589. [CrossRef]\n44.\nHamidouche, R.; Aliouat, Z.; Ari, A.A.A.;\
    \ Gueroui, M. An Efﬁcient Clustering Strategy Avoiding Buffer Overﬂow in IoT Sensors:\n\
    A Bio-Inspired Based Approach. IEEE Access 2019, 7, 156733–156751. [CrossRef]\n\
    45.\nSaleem, K.; Alabduljabbar, G.M.; Alrowais, N.; Al-Muhtadi, J.; Imran, M.;\
    \ Rodrigues, J.J.P.C. Bio-Inspired Network Security for\n5G-Enabled IoT Applications.\
    \ IEEE Access 2020, 8, 229152–229160. [CrossRef]\n46.\nRoy, S.; Ghosh, N.; Das,\
    \ S.K. bioSmartSense: A Bio-inspired Data Collection Framework for Energy-efﬁcient,\
    \ QoI-aware Smart\nCity Applications. In Proceedings of the 2019 IEEE International\
    \ Conference on Pervasive Computing and Communications\n(PerCom), Kyoto, Japan,\
    \ 11–15 March 2019; pp. 1–10. [CrossRef]\n47.\nYadav, V.; Natesha, B.V.; Guddeti,\
    \ R.M.R. GA-PSO: Service Allocation in Fog Computing Environment Using Hybrid\
    \ Bio-Inspired\nAlgorithm. In Proceedings of the TENCON 2019—2019 IEEE Region\
    \ 10 Conference (TENCON), Kochi, India, 17–20 October 2019.\nBiomimetics 2023,\
    \ 8, 373\n28 of 29\n48.\nAlfarraj, O. Internet of things with bio-inspired co-evolutionary\
    \ deep-convolution neural-network approach for detecting road\ncracks in smart\
    \ transportation. Neural Comput. Appl. 2020. [CrossRef]\n49.\nIadarola, G.; Poli,\
    \ A.; Spinsante, S. Analysis of galvanic skin response to acoustic stimuli by\
    \ wearable devices. In Proceedings of\nthe 2021 IEEE International Symposium on\
    \ Medical Measurements and Applications (MeMeA), Lausanne, Switzerland, 23–25\n\
    June 2021; pp. 1–6.\n50.\nCosoli, G.; Iadarola, G.; Poli, A.; Spinsante, S. 50\
    \ Learning classiﬁers for analysis of Blood Volume Pulse signals in IoT-enabled\n\
    systems. In Proceedings of the 2021 IEEE International Workshop on Metrology for\
    \ Industry 4.0 & IoT (MetroInd4.0&IoT), Rome,\nItaly, 7–9 June 2021; pp. 307–312.\
    \ [CrossRef]\n51.\nSaad, A.; Hegazy, I.; El-Horbaty, E.S.M. Efﬁcient Bio-Inspired\
    \ Routing Algorithm for IoT. In Proceedings of the 2021 Tenth\nInternational Conference\
    \ on Intelligent Computing and Information Systems (ICICIS), Cairo, Egypt, 5–7\
    \ December 2021; pp.\n303–310. [CrossRef]\n52.\nPokala, J.; Lalitha, B. A Novel\
    \ Intrusion Detection System for RPL Based IoT Networks with Bio-Inspired Feature\
    \ Selection and\nEnsemble Classiﬁer. Wirel. Pers. Commun. 2021, preprint. [CrossRef]\n\
    53.\nSoni, V.; Saxena, S.; Bhatt, D.P.; Yadav, N.S. ImmuneGAN: Bio-inspired Artiﬁcial\
    \ Immune System to Secure IoT Ecosystem. In\nLecture Notes in Networks and Systems,\
    \ Proceedings of the International Conference on Cyber Security, Privacy and Networking\
    \ (ICSPN\n2022), Bangkok, Thailand, 9–11 September 2021; Nedjah, N., Pérez, G.M.,\
    \ Gupta, B.B., Eds.; Springer International Publishing: Cham,\nSwitzerland, 2023;\
    \ Volume 599, pp. 110–121. [CrossRef]\n54.\nKataria, B.; Jethva, H.; Shinde, P.;\
    \ Banait, S.; Shaikh, F.; Ajani, S. SLDEB: Design of a Secure and Lightweight\
    \ Dynamic Encryption\nBio-Inspired Model for IoT Networks. Int. J. Saf. Secur.\
    \ Eng. 2023, 13, 325–331. [CrossRef]\n55.\nSharmin, A.; Anwar, F.; Motakabber,\
    \ S.M.A. A novel bio-inspired routing algorithm based on ACO for WSNs. Bull. Electr.\
    \ Eng.\nInform. 2019, 8, 718–726. [CrossRef]\n56.\nVenkatesh, C.; Bojja, P. Lung\
    \ Cancer Detection using Bio-Inspired Algorithm in CT Scans and Secure Data Transmission\
    \ through\nIoT Cloud. Int. J. Adv. Comput. Sci. Appl. 2020, 11, 373–379. [CrossRef]\n\
    57.\nEleftherakis, G.; Baxhaku, F.; Vasilescu, A. Bio-inspired Adaptive Architecture\
    \ for Wireless Sensor Networks. In Proceedings of\nthe 26th Pan-Hellenic Conference\
    \ on Informatics, Athens, Greece, 25–27 November 2022; Available online: https://dl.acm.org/\n\
    doi/fullHtml/10.1145/3575879.3575976 (accessed on 13 June 2023).\n58.\nVasconcelos,\
    \ D.; Andrade, R.; Severino, V.; Maia, M. Bio-Inspired Model for Data Distribution\
    \ in Fog and Mist Computing. In\nProceedings of the 2018 IEEE 42nd Annual Computer\
    \ Software and Applications Conference (COMPSAC), Tokyo, Japan, 23–27\nJuly 2018.\
    \ [CrossRef]\n59.\nMoizuddin, M.; Jose, M.V. A bio-inspired hybrid deep learning\
    \ model for network intrusion detection. Knowl.-Based Syst. 2022,\n238, 107894.\
    \ [CrossRef]\n60.\nBonabeau, E.; Dorigo, M.; Theraulaz, G. Swarm Intelligence:\
    \ From Natural to Artiﬁcial Systems; Oxford University Press: Oxford,\nUK, 1999.\
    \ [CrossRef]\n61.\nSwarm Intelligence; Elsevier: Amsterdam, The Netherlands, 2001.\
    \ [CrossRef]\n62.\nDi Caro, G.; Dorigo, M. AntNet: Distributed stigmergetic control\
    \ for communications networks. J. Artif. Intell. Res. 1998,\n9, 317–365. [CrossRef]\n\
    63.\nSari, I.R.F. Bioinspired algorithms for Internet of Things network. In Proceedings\
    \ of the 2017 4th International Conference on\nInformation Technology, Computer,\
    \ and Electrical Engineering (ICITACEE), Semarang, Indonesia, 18–19 October 2017;\
    \ p. 1.\n[CrossRef]\n64.\nCao, L.; Chen, H.; Chen, Y.; Yue, Y.; Zhang, X. Bio-Inspired\
    \ Swarm Intelligence Optimization Algorithm-Aided Hybrid\nTDOA/AOA-Based Localization.\
    \ Biomimetics 2023, 8, 186. [CrossRef]\n65.\nAlizadehsani, R.; Roshanzamir, M.;\
    \ Izadi, N.H.; Gravina, R.; Kabir, H.M.D.; Nahavandi, D.; Alinejad-Rokny, H.;\
    \ Khosravi, A.;\nAcharya, U.R.; Nahavandi, S.; et al. Swarm Intelligence in Internet\
    \ of Medical Things: A Review. Sensors 2023, 23, 1466. [CrossRef]\n66.\nZedadra,\
    \ O.; Guerrieri, A.; Jouandeau, N.; Spezzano, G.; Seridi, H.; Fortino, G. Swarm\
    \ intelligence-based algorithms within\nIoT-based systems: A review. J. Parallel\
    \ Distrib. Comput. 2018, 122, 173–187. [CrossRef]\n67.\nTorre-Bastida, A.I.; Díaz-de-Arcaya,\
    \ J.; Osaba, E.; Muhammad, K.; Camacho, D.; Del Ser, J. Bio-inspired computation\
    \ for big\ndata fusion, storage, processing, learning and visualization: State\
    \ of the art and future directions. Neural Comput. Appl. 2021.\n[CrossRef]\n68.\n\
    De Castro, M.F.; Ribeiro, L.B.; Oliveira, C.H.S. An autonomic bio-inspired algorithm\
    \ for wireless sensor network self-organization\nand efﬁcient routing. J. Netw.\
    \ Comput. Appl. 2012, 35, 2003–2015. [CrossRef]\n69.\nAftab, F.; Khan, A.; Zhang,\
    \ Z. Bio-inspired clustering scheme for Internet of Drones application in industrial\
    \ wireless sensor\nnetwork. Int. J. Distrib. Sens. Netw. 2019, 15, 155014771988990.\
    \ [CrossRef]\n70.\nNiranjana, G.; Poongodai, A.; Soujanya, K.L.S. Biological inspired\
    \ self-organized secure autonomous routing protocol and secured\ndata assured\
    \ routing in WSN: Hybrid EHO and MBO approach. Int. J. Commun. Syst. 2022, 35,\
    \ e5044. [CrossRef]\n71.\nSaleem, K.; Fisal, N.; Arifﬁn, S.H.S. BIOSARP: Biological\
    \ inspired self-organized secure autonomous routing protocol for wireless\nsensor\
    \ network. In Proceedings of the 11th WSEAS International Conference on Applied\
    \ Computer Science, Penang, Malaysia,\n3–5 October 2011; p. 165.\n72.\nSun, W.;\
    \ Tang, M.; Zhang, L.; Huo, Z.; Shu, L. A Survey of Using Swarm Intelligence Algorithms\
    \ in IoT. Sensors 2020, 20, 1420.\n[CrossRef]\nBiomimetics 2023, 8, 373\n29 of\
    \ 29\n73.\nAbualigah, L.; Falcone, D.; Forestiero, A. Swarm Intelligence to Face\
    \ IoT Challenges. Comput. Intell. Neurosci. 2023, 2023, 4254194.\n[CrossRef]\n\
    74.\nDillow, C. Six Ways Bio-Inspired Design Is Reshaping the Future. Popular\
    \ Science. 28 March 2011. Available online: https:\n//www.popsci.com/science/article/2011-03/gallery-six-ways-biomimicry-reshaping-future/\
    \ (accessed on 12 July 2023).\n75.\nWhat Does the Future Hold for Nature Inspired\
    \ Research? Available online: https://www.futurelearn.com/info/courses/\nrobotic-future/0/steps/26364\
    \ (accessed on 12 July 2023).\n76.\nZhang, Z.; Vogelbacher, F.; Song, Y.; Tian,\
    \ Y.; Li, M. Bio-inspired optical structures for enhancing luminescence. Exploration\
    \ 2023,\n3, 20220052. [CrossRef]\n77.\nFeng, C.; Tan, P.; Nie, G.; Zhu, M. Biomimetic\
    \ and bioinspired nano-platforms for cancer vaccine development. Exploration 2023,\n\
    3, 20210263. [CrossRef]\n78.\nYan, C.; Meng, L.; Li, L.; Zhang, J.; Wang, Z.;\
    \ Yin, J.; Zhang, J.; Sun, Y.; Zheng, B. Age-Invariant Face Recognition by Multi-Feature\n\
    Fusionand Decomposition with Self-attention. ACM Trans. Multimed. Comput. Commun.\
    \ Appl. 2022, 18, 1–18. [CrossRef]\n79.\nYan, C.; Gong, B.; Wei, Y.; Gao, Y. Deep\
    \ Multi-View Enhancement Hashing for Image Retrieval. arXiv 2020, arXiv:2002.00169.\n\
    [CrossRef] [PubMed]\nDisclaimer/Publisher’s Note: The statements, opinions and\
    \ data contained in all publications are solely those of the individual\nauthor(s)\
    \ and contributor(s) and not of MDPI and/or the editor(s). MDPI and/or the editor(s)\
    \ disclaim responsibility for any injury to\npeople or property resulting from\
    \ any ideas, methods, instructions or products referred to in the content.\n"
  inline_citation: '>'
  journal: Biomimetics
  limitations: '>'
  pdf_link: https://www.mdpi.com/2313-7673/8/4/373/pdf?version=1692259522
  publication_year: 2023
  relevance_score1: 0
  relevance_score2: 0
  title: 'Bio-Inspired Internet of Things: Current Status, Benefits, Challenges, and
    Future Directions'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.18297/etd/4029
  analysis: '>'
  authors:
  - Muhammad Zaigham Abbas Shah Syed
  citation_count: 0
  full_citation: '>'
  full_text: ">\nUniversity of Louisville \nUniversity of Louisville \nThinkIR: The\
    \ University of Louisville's Institutional Repository \nThinkIR: The University\
    \ of Louisville's Institutional Repository \nElectronic Theses and Dissertations\
    \ \n12-2022 \nIoT in smart communities, technologies and applications. \nIoT in\
    \ smart communities, technologies and applications. \nMuhammad Zaigham Abbas Shah\
    \ Syed \nUniversity of Louisville \nFollow this and additional works at: https://ir.library.louisville.edu/etd\
    \ \n Part of the Other Computer Engineering Commons \nRecommended Citation \n\
    Recommended Citation \nSyed, Muhammad Zaigham Abbas Shah, \"IoT in smart communities,\
    \ technologies and applications.\" \n(2022). Electronic Theses and Dissertations.\
    \ Paper 4029. \nhttps://doi.org/10.18297/etd/4029 \nThis Doctoral Dissertation\
    \ is brought to you for free and open access by ThinkIR: The University of Louisville's\
    \ \nInstitutional Repository. It has been accepted for inclusion in Electronic\
    \ Theses and Dissertations by an authorized \nadministrator of ThinkIR: The University\
    \ of Louisville's Institutional Repository. This title appears here courtesy of\
    \ \nthe author, who has retained all other copyrights. For more information, please\
    \ contact thinkir@louisville.edu. \nIOT IN SMART COMMUNITIES, TECHNOLOGIES AND\
    \ APPLICATIONS\nBy\nMuhammad Zaigham Abbas Shah Syed\nB.Eng., M.Sc.\nA Dissertation\n\
    Submitted to the Faculty of the\nJ.B. Speed School of Engineering of the University\
    \ of\nLouisville\nin Partial Fulfillment of the Requirements\nfor the Degree of\n\
    Doctor of Philosophy\nin Computer Science and Engineering\nDepartment of Computer\
    \ Science and Engineering\nUniversity of Louisville\nLouisville, Kentucky\nDecember\
    \ 2022\nCopyright 2022 by Muhammad Zaigham Abbas Shah Syed\nAll rights reserved\n\
    IOT IN SMART COMMUNITIES, TECHNOLOGIES AND APPLICATIONS\nBy\nMuhammad Zaigham\
    \ Abbas Shah Syed\nB.Eng., M.Sc.\nDissertation approved on\nNovember 8, 2022\n\
    by the following dissertation Committee:\nDissertation Director\nDr. Adel S. Elmaghraby\n\
    Dr. Daniel Sierrasosa\nDr. Anup Kumar\nDr. Ibrahim Imam\nDr. Monica Gentili\n\
    \    ii\nDEDICATION\nTo my late grandmother, Shireen Shah who always championed\
    \ the im-\nportance of education and personal values. She has had the biggest\
    \ impact\non the person that I have become.\nTo my parents, who worked hard to\
    \ provide us with the best opportunities\nthat can be provided to any child.\n\
    iii\nACKNOWLEDGMENTS\nI would like to thank my supervisor, Dr. Adel Elmaghraby\
    \ for his sup-\nport and guidance throughout the course of my research work here\
    \ at the\nUniversity of Louisville. Without his support and trust I would not\
    \ have\nbeen able to succeed in this endeavor.\nI would also like to thank Dr.\
    \ Anup Kumar and Dr. Daniel Sierra-Sosa\nfor their support in conducting my research\
    \ and providing feedback on\nour experiments which helped improve the quality\
    \ of the work.\nI would like to thank all my friends, both in the United States\
    \ and else-\nwhere who have been a tremendous support to me during my time in\n\
    Louisville. They were like a family away from home.\nFinally, I would like to\
    \ say thanks to my family, who have supported me\nthroughout think and thin. First\
    \ and foremost my parents, my mother\nNaheed and father Sher Muhammad. They through\
    \ their hard work and\ndetermination left no stone unturned to provide us with\
    \ the best upbring-\ning anyone can provide to their children. My wife Farwa,\
    \ who has always\nbeen a pillar of support for me. My siblings, Zafi, Shehram\
    \ and Fiza who\nhave been the best brothers and sister anyone can ask for. My\
    \ sisters in\nlaw, Madiha and Hina and my lovely niece Maryam, who is a cause\
    \ of\nmuch joy in our life.\niv\nABSTRACT\nIOT IN SMART COMMUNITIES, TECHNOLOGIES\
    \ AND APPLICATIONS\nMuhammad Zaigham Abbas Shah, Syed\nNovember 8, 2022\nInternet\
    \ of Things is a system that integrates different devices and technologies,\n\
    removing the necessity of human intervention. This enables the capacity of having\n\
    smart (or smarter) cities around the world. By hosting different technologies\
    \ and al-\nlowing interactions between them, the internet of things has spearheaded\
    \ the develop-\nment of smart city systems for sustainable living, increased comfort\
    \ and productivity\nfor citizens. The Internet of Things (IoT) for Smart Cities\
    \ has many different domains\nand draws upon various underlying systems for its\
    \ operation, in this work, we provide\na holistic coverage of the Internet of\
    \ Things in Smart Cities by discussing the fun-\ndamental components that make\
    \ up the IoT Smart City landscape, the technologies\nthat enable these domains\
    \ to exist, the most prevalent practices and techniques which\nare used in these\
    \ domains as well as the challenges that deployment of IoT systems for\nsmart\
    \ cities encounter and which need to be addressed for ubiquitous use of smart\
    \ city\napplications. It also presents a coverage of optimization methods and\
    \ applications\nfrom a smart city perspective enabled by the Internet of Things.\
    \ Towards this end,\na mapping is provided for the most encountered applications\
    \ of computational opti-\nmization within IoT smart cities for five popular optimization\
    \ methods, ant colony\noptimization, genetic algorithm, particle swarm optimization,\
    \ artificial bee colony op-\ntimization and differential evolution. For each application\
    \ identified, the algorithms\nused, objectives considered, the nature of the formulation\
    \ and constraints taken in\nv\nto account have been specified and discussed. Lastly,\
    \ the data setup used by each\ncovered work is also mentioned and directions for\
    \ future work have been identified.\nWithin the smart health domain of IoT smart\
    \ cities, human activity recognition\nhas been a key study topic in the development\
    \ of cyber physical systems and as-\nsisted living applications. In particular,\
    \ inertial sensor based systems have become\nincreasingly popular because they\
    \ do not restrict users’ movement and are also rel-\natively simple to implement\
    \ compared to other approaches. Fall detection is one of\nthe most important tasks\
    \ in human activity recognition. With an increasingly aging\nworld population\
    \ and an inclination by the elderly to live alone, the need to incor-\nporate\
    \ dependable fall detection schemes in smart devices such as phones, watches\n\
    has gained momentum. Therefore, differentiating between falls and activities of\
    \ daily\nliving (ADLs) has been the focus of researchers in recent years with\
    \ very good results.\nHowever, one aspect within fall detection that has not been\
    \ investigated much is di-\nrection and severity aware fall detection. Since a\
    \ fall detection system aims to detect\nfalls in people and notify medical personnel,\
    \ it could be of added value to health pro-\nfessionals tending to a patient suffering\
    \ from a fall to know the nature of the accident.\nIn this regard, as a case study\
    \ for smart health, four different experiments have been\nconducted for the task\
    \ of fall detection with direction and severity consideration on\ntwo publicly\
    \ available datasets. These four experiments not only tackle the problem\non an\
    \ increasingly complicated level (the first one considers a fall only scenario\
    \ and\nthe other two a combined activity of daily living and fall scenario) but\
    \ also present\nmethodologies which outperform the state of the art techniques\
    \ as discussed. Lastly,\nfuture recommendation have also been provided for researchers.\n\
    vi\nTABLE OF CONTENTS\nMotivation . . . . . . . . . . . . . . . . . . . . . .\
    \ . . . . . . . . . . . . . .\n1\nAims . . . . . . . . . . . . . . . . . . . .\
    \ . . . . . . . . . . . . . . . . . . .\n2\nOrganization\n. . . . . . . . . .\
    \ . . . . . . . . . . . . . . . . . . . . . . . .\n2\nIOT SMART CITIES\n. . .\
    \ . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n3\nIntroduction . .\
    \ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n3\nSmart\
    \ City Components . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n4\n\
    2.1\nSmart Agriculture . . . . . . . . . . . . . . . . . . . . . . . . .\n4\n\
    2.2\nSmart City Services . . . . . . . . . . . . . . . . . . . . . . . .\n4\n\
    2.3\nSmart Energy . . . . . . . . . . . . . . . . . . . . . . . . . . .\n5\n2.4\n\
    Smart Health . . . . . . . . . . . . . . . . . . . . . . . . . . .\n6\n2.5\nSmart\
    \ Home . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n6\n2.6\nSmart\
    \ Industry . . . . . . . . . . . . . . . . . . . . . . . . . .\n6\n2.7\nSmart\
    \ Infrastructure . . . . . . . . . . . . . . . . . . . . . . .\n7\n2.8\nSmart\
    \ Transport\n. . . . . . . . . . . . . . . . . . . . . . . . .\n7\nInternet of\
    \ Things for Smart Cities . . . . . . . . . . . . . . . . . . . . . .\n7\n3.1\n\
    IoT Architectures for Smart cities . . . . . . . . . . . . . . . .\n8\n3.1.1\n\
    Cloud Computing Model . . . . . . . . . . . . . . . .\n9\n3.1.2\nFog Computing\
    \ Model . . . . . . . . . . . . . . . . .\n9\n3.1.3\nEdge Computing Model . .\
    \ . . . . . . . . . . . . . .\n10\n3.2\nIoT Challenges for smart Cities . . .\
    \ . . . . . . . . . . . . . .\n11\n3.2.1\nSecurity and Privacy . . . . . . . .\
    \ . . . . . . . . . .\n12\n3.2.2\nSmart Sensors . . . . . . . . . . . . . . .\
    \ . . . . . . .\n13\n3.2.3\nNetworking . . . . . . . . . . . . . . . . . . . .\
    \ . . .\n13\n3.2.4\nBig Data Analytics . . . . . . . . . . . . . . . . . . .\n\
    14\n3.3\nSensing Technologies . . . . . . . . . . . . . . . . . . . . . . .\n\
    14\n3.3.1\nAmbient Sensors . . . . . . . . . . . . . . . . . . . .\n15\n3.3.2\n\
    Bio-Sensors . . . . . . . . . . . . . . . . . . . . . . .\n15\nvii\nDedication\
    \ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\
    iii\nAcknowledgments . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\
    \ . . . . .\niv\nAbstract . . . . . . . . . . . . . . . . . . . . . . . . . .\
    \ . . . . . . . . . . . . .\nv\nList of Tables . . . . . . . . . . . . . . . .\
    \ . . . . . . . . . . . . . . . . . . . .\nxi\nList of Figures\n. . . . . . .\
    \ . . . . . . . . . . . . . . . . . . . . . . . . . . . .\nxiii\nINTRODUCTION\
    \ AND DISSERTATION OVERVIEW\n. . . . . . . . . . . .\n1\n3.3.3\nChemical\n. .\
    \ . . . . . . . . . . . . . . . . . . . . . .\n16\n3.3.4\nElectric Sensors . .\
    \ . . . . . . . . . . . . . . . . . . .\n16\n3.3.5\nHydraulic . . . . . . . .\
    \ . . . . . . . . . . . . . . . .\n16\n3.3.6\nIdentification . . . . . . . . .\
    \ . . . . . . . . . . . . .\n17\n3.3.7\nMotion Sensors . . . . . . . . . . . .\
    \ . . . . . . . . .\n17\n3.3.8\nPresence . . . . . . . . . . . . . . . . . . .\
    \ . . . . . .\n17\n3.3.9\nOther Sensors . . . . . . . . . . . . . . . . . . .\
    \ . . .\n17\n3.4\nNetworking Technologies . . . . . . . . . . . . . . . . . .\
    \ . . .\n17\n3.4.1\nNetwork Topologies\n. . . . . . . . . . . . . . . . . .\n\
    18\n3.4.2\nNetwork Architectures . . . . . . . . . . . . . . . . .\n19\n3.4.3\n\
    Network Protocols . . . . . . . . . . . . . . . . . . .\n20\n3.5\nSecurity and\
    \ Privacy in Smart City IoT . . . . . . . . . . . . .\n23\n3.5.1\nApplication\
    \ Software Layers\n. . . . . . . . . . . . .\n24\n3.5.2\nNetwork Layer\n. . .\
    \ . . . . . . . . . . . . . . . . . .\n25\n3.5.3\nPerception Layer . . . . . .\
    \ . . . . . . . . . . . . . .\n27\n3.5.4\nSystem Wide Issues\n. . . . . . . .\
    \ . . . . . . . . . .\n27\nSWOT Analysis . . . . . . . . . . . . . . . . . . .\
    \ . . . . . . . . . . . . . .\n28\n4.1\nStrengths\n. . . . . . . . . . . . . .\
    \ . . . . . . . . . . . . . . .\n29\n4.2\nWeaknesses\n. . . . . . . . . . . .\
    \ . . . . . . . . . . . . . . . .\n30\n4.3\nOpportunities . . . . . . . . . .\
    \ . . . . . . . . . . . . . . . . .\n30\n4.4\nThreats\n. . . . . . . . . . . .\
    \ . . . . . . . . . . . . . . . . . .\n30\nConclusions . . . . . . . . . . . .\
    \ . . . . . . . . . . . . . . . . . . . . . . .\n31\nAI IN IOT SMART CITIES .\
    \ . . . . . . . . . . . . . . . . . . . . . . . . . . .\n32\nIntroduction . .\
    \ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n32\nBig Data\
    \ Algorithms/Artificial Intelligence . . . . . . . . . . . . . . . . . .\n32\n\
    2.1\nMachine Learning . . . . . . . . . . . . . . . . . . . . . . . . .\n33\n\
    2.2\nDeep Learning . . . . . . . . . . . . . . . . . . . . . . . . . . .\n33\n\
    AI Applications for Smart Cities\n. . . . . . . . . . . . . . . . . . . . . .\
    \ .\n33\n3.1\nSmart Agriculture . . . . . . . . . . . . . . . . . . . . . . .\
    \ .\n33\n3.2\nSmart City Services . . . . . . . . . . . . . . . . . . . . . .\
    \ . .\n34\n3.3\nSmart Energy . . . . . . . . . . . . . . . . . . . . . . . . .\
    \ . .\n36\n3.4\nSmart Health . . . . . . . . . . . . . . . . . . . . . . . . .\
    \ . .\n38\n3.5\nSmart Homes . . . . . . . . . . . . . . . . . . . . . . . . .\
    \ . .\n40\n3.6\nSmart Industry . . . . . . . . . . . . . . . . . . . . . . . .\
    \ . .\n41\n3.7\nSmart Infrastructure . . . . . . . . . . . . . . . . . . . . .\
    \ . .\n43\n3.8\nSmart Transport\n. . . . . . . . . . . . . . . . . . . . . . .\
    \ . .\n43\nConclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . .\
    \ . . . . . . . .\n46\nOPTIMIZATION IN IOT SMART CITIES\n. . . . . . . . . . .\
    \ . . . . . . . .\n49\nIntroduction . . . . . . . . . . . . . . . . . . . . .\
    \ . . . . . . . . . . . . . .\n49\nOptimization and Heuristics in IoT Smart Cities\
    \ . . . . . . . . . . . . . . .\n49\nMeheuristic Algorithms . . . . . . . . .\
    \ . . . . . . . . . . . . . . . . . . . .\n50\n3.1\nAnt Colony Optimization\n\
    . . . . . . . . . . . . . . . . . . . .\n50\n3.2\nGenetic Algorithm\n. . . . .\
    \ . . . . . . . . . . . . . . . . . . .\n50\nviii\n3.3\nParticle Swarm Optimization\n\
    . . . . . . . . . . . . . . . . . .\n51\n3.4\nDifferential Evolution . . . . .\
    \ . . . . . . . . . . . . . . . . . .\n52\n3.5\nArtificial Bee Colony . . . .\
    \ . . . . . . . . . . . . . . . . . . .\n52\nOptimization Applications in Smart\
    \ Cities . . . . . . . . . . . . . . . . . .\n53\n4.1\nSmart Agriculture . . .\
    \ . . . . . . . . . . . . . . . . . . . . . .\n53\n4.2\nSmart City Services .\
    \ . . . . . . . . . . . . . . . . . . . . . . .\n55\n4.3\nSmart Grid\n. . . .\
    \ . . . . . . . . . . . . . . . . . . . . . . . .\n57\n4.4\nSmart Health . . .\
    \ . . . . . . . . . . . . . . . . . . . . . . . .\n60\n4.5\nSmart Homes . . .\
    \ . . . . . . . . . . . . . . . . . . . . . . . .\n64\n4.6\nSmart Industry . .\
    \ . . . . . . . . . . . . . . . . . . . . . . . .\n66\n4.7\nSmart Infrastructure\
    \ . . . . . . . . . . . . . . . . . . . . . . .\n69\n4.8\nSmart Transportation\n\
    . . . . . . . . . . . . . . . . . . . . . .\n71\nConclusion . . . . . . . . .\
    \ . . . . . . . . . . . . . . . . . . . . . . . . . . .\n73\nCASE STUDY - SMART\
    \ HEALTH . . . . . . . . . . . . . . . . . . . . . . . .\n76\nIntroduction . .\
    \ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n76\nIoT for\
    \ Fall Detection\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\
    76\n2.1\nChallenges/Requirements of a FDS . . . . . . . . . . . . . . .\n77\n\
    2.1.1\nNon-intrusiveness . . . . . . . . . . . . . . . . . . . .\n77\n2.1.2\n\
    Low Latency\n. . . . . . . . . . . . . . . . . . . . . .\n77\n2.1.3\nLow power\
    \ consumption . . . . . . . . . . . . . . . .\n77\n2.1.4\nAllow mobility\n. .\
    \ . . . . . . . . . . . . . . . . . . .\n77\n2.1.5\nDifferentiate between Falls\
    \ and Activities\n. . . . . .\n77\n2.1.6\nNotify caregivers . . . . . . . . .\
    \ . . . . . . . . . . .\n78\n2.1.7\nTrack history . . . . . . . . . . . . . .\
    \ . . . . . . . .\n78\n2.2\nTypes of Fall Detection Systems . . . . . . . . .\
    \ . . . . . . . .\n78\n2.2.1\nAmbient Sensor based systems\n. . . . . . . . .\
    \ . . .\n78\n2.2.2\nVision based systems . . . . . . . . . . . . . . . . . .\n\
    79\n2.2.3\nWearable Sensor based systems . . . . . . . . . . . .\n79\n2.3\nTypes\
    \ of Wearable FDS\n. . . . . . . . . . . . . . . . . . . . .\n80\n2.3.1\nThreshold\
    \ based systems . . . . . . . . . . . . . . . .\n80\n2.3.2\nMachine/Deep Learning\
    \ based systems . . . . . . . .\n80\n2.4\nSensors used in Wearable FDS . . . .\
    \ . . . . . . . . . . . . . .\n80\n2.4.1\nAccelerometers . . . . . . . . . . .\
    \ . . . . . . . . . .\n81\n2.4.2\nGryroscope . . . . . . . . . . . . . . . . .\
    \ . . . . . .\n81\n2.4.3\nMagnetometer\n. . . . . . . . . . . . . . . . . . .\
    \ . .\n81\n2.4.4\nVarious Medical Sensors . . . . . . . . . . . . . . . .\n81\n\
    2.5\nDesign considerations for Wearable FDS\n. . . . . . . . . . . .\n81\n2.5.1\n\
    Sampling frequency . . . . . . . . . . . . . . . . . . .\n82\n2.5.2\nWindowing\
    \ . . . . . . . . . . . . . . . . . . . . . . .\n82\n2.5.3\nFeature Extraction\
    \ . . . . . . . . . . . . . . . . . . .\n82\n2.6\nLiterature Review . . . . .\
    \ . . . . . . . . . . . . . . . . . . . .\n82\n2.7\nFall detection Datasets .\
    \ . . . . . . . . . . . . . . . . . . . . .\n89\n2.7.1\nSisFall Dataset . . .\
    \ . . . . . . . . . . . . . . . . . .\n89\n2.7.2\nK-Fall Dataset\n. . . . . .\
    \ . . . . . . . . . . . . . . .\n90\nix\n2.8\nExperiments . . . . . . . . . .\
    \ . . . . . . . . . . . . . . . . . .\n90\n2.8.1\nFall Detection with Severity\
    \ and Direction consideration 91\n2.8.2\nFall Detection with Severity and Direction\
    \ along with\nADL consideration using Wavelet Pooling and K-NN\n101\n2.8.3\nFall\
    \ Detection with Severity and Direction along with\nADL consideration using CNN-XGBoost\
    \ . . . . . . .\n111\n2.8.4\nCross dataset non-binary fall detection with a ConvLSTM-\n\
    attention network . . . . . . . . . . . . . . . . . . . .\n119\nConclusion . .\
    \ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n125\nCONCLUSION\
    \ AND FUTURE WORK . . . . . . . . . . . . . . . . . . . . .\n128\nConclusion .\
    \ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n128\n\
    Contribution\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\
    \ . .\n128\nFuture Work\n. . . . . . . . . . . . . . . . . . . . . . . . . . .\
    \ . . . . . . .\n129\nREFERENCES . . . . . . . . . . . . . . . . . . . . . . .\
    \ . . . . . . . . . . . .\n131\nAppendix A: Sample Plots for different fall categories\
    \ . . . . . . . . . . . . . .\n174\nAppendix B: Acronyms\n. . . . . . . . . .\
    \ . . . . . . . . . . . . . . . . . . . .\n180\nCurriculum Vita. . . . . . . .\
    \ . . . . . . . . . . . . . . . . . . . . . . . . . . . 183\nx\nLIST OF TABLES\n\
    1\nComparison of Cloud, Fog and Edge Computing Models\n. . . . . . . . .\n11\n\
    2\nSmart City IoT Challenges and Mitigation . . . . . . . . . . . . . . . . .\n\
    15\n3\nSensing Technologies for IoT Smart Cities by Smart City Component . .\n\
    18\n4\nComparison of Network Technologies for IoT Smart Cities\n. . . . . . .\
    \ .\n22\n5\nSecurity and Privacy issue for IoT Smart Cities . . . . . . . . .\
    \ . . . . .\n28\n6\nSWOT Analysis for IoT in Smart Cities\n. . . . . . . . . .\
    \ . . . . . . . .\n29\n7\nAI use for Smart Agriculture . . . . . . . . . . . .\
    \ . . . . . . . . . . . . .\n35\n8\nAI use for Smart city Services . . . . . .\
    \ . . . . . . . . . . . . . . . . . .\n37\n9\nAI use for Smart Energy . . . .\
    \ . . . . . . . . . . . . . . . . . . . . . . .\n38\n10\nAI use for Smart Health\
    \ . . . . . . . . . . . . . . . . . . . . . . . . . . .\n39\n11\nAI use for Smart\
    \ Homes . . . . . . . . . . . . . . . . . . . . . . . . . . .\n42\n12\nAI use\
    \ for Smart Industry . . . . . . . . . . . . . . . . . . . . . . . . . .\n44\n\
    13\nAI use for Smart Infrastructure . . . . . . . . . . . . . . . . . . . . .\
    \ . .\n45\n14\nAI use for Smart Transport\n. . . . . . . . . . . . . . . . . .\
    \ . . . . . . .\n46\n15\nAI applications for IoT Smart Cities\n. . . . . . . .\
    \ . . . . . . . . . . . .\n48\n16\nOptimization in Smart Agriculture\n. . . .\
    \ . . . . . . . . . . . . . . . . .\n56\n17\nData setup used for Smart Agriculture\
    \ Optimization\n. . . . . . . . . . .\n56\n18\nOptimization in Smart City Services\n\
    . . . . . . . . . . . . . . . . . . . .\n58\n19\nData setup used for Smart City\
    \ Services Optimization\n. . . . . . . . . .\n58\n20\nOptimization in Smart Grid\
    \ . . . . . . . . . . . . . . . . . . . . . . . . .\n61\n21\nData setup used for\
    \ Smart Grid . . . . . . . . . . . . . . . . . . . . . . .\n62\n22\nOptimization\
    \ in Smart Health . . . . . . . . . . . . . . . . . . . . . . . .\n63\n23\nData\
    \ setup used for Smart Health . . . . . . . . . . . . . . . . . . . . . .\n64\n\
    24\nOptimization in Smart Homes . . . . . . . . . . . . . . . . . . . . . . .\
    \ .\n67\n25\nData setup used for Smart Homes . . . . . . . . . . . . . . . . .\
    \ . . . . .\n67\n26\nOptimization in Smart Industry . . . . . . . . . . . . .\
    \ . . . . . . . . . .\n68\n27\nData setup for Smart Industry . . . . . . . . .\
    \ . . . . . . . . . . . . . . .\n70\n28\nOptimization in Smart Infrastructure\
    \ . . . . . . . . . . . . . . . . . . . .\n71\n29\nData types for Smart Infrastructure\
    \ . . . . . . . . . . . . . . . . . . . . .\n71\n30\nOptimization in Smart Transportation\n\
    . . . . . . . . . . . . . . . . . . .\n74\n31\nData types for Smart Transportation\
    \ . . . . . . . . . . . . . . . . . . . .\n75\n32\nADL and Falls present in the\
    \ SisFall dataset. . . . . . . . . . . . . . . . .\n90\n33\nADL and Falls present\
    \ in the K-Fall dataset. . . . . . . . . . . . . . . . .\n91\n34\nLabeling used\
    \ for Fall only classification for the SisFall Dataset\n. . . . .\n92\n35\nFeatures\
    \ computed for each fall segment\n. . . . . . . . . . . . . . . . . .\n94\n36\n\
    Fall F1-scores (Fall direction only)\n. . . . . . . . . . . . . . . . . . . .\
    \ .\n99\n37\nFall F1-scores (Fall severity and direction) . . . . . . . . . .\
    \ . . . . . . .\n100\n38\nBest Results: Fall direction\n. . . . . . . . . . .\
    \ . . . . . . . . . . . . . .\n100\n39\nBest Results: Fall direction and Severity\
    \ . . . . . . . . . . . . . . . . . .\n101\nxi\n40\nADL Labels used for SisFall\
    \ Recordings. . . . . . . . . . . . . . . . . . .\n102\n41\nPerformance for different\
    \ observation window sizes. . . . . . . . . . . . .\n109\n42\nPerformance for\
    \ different sensing modalities. . . . . . . . . . . . . . . . .\n110\n43\nBest\
    \ Results (Obs. Window : 3 sec, Sensing Modality: Acc. + Gyro.) . .\n110\n44\n\
    One ADL vs. Individual Falls. . . . . . . . . . . . . . . . . . . . . . . . .\n\
    116\n45\nIndividual ADLs vs. Individual Falls. . . . . . . . . . . . . . . . .\
    \ . . . .\n116\n46\nComparison with State of the art (Individual ADLs vs. Individual\
    \ Falls.)\n118\n47\nComparison with State of the art (Individual ADLs vs. Individual\
    \ Falls.)\n119\n48\nLabeling for K-Fall Dataset\n. . . . . . . . . . . . . . .\
    \ . . . . . . . . . .\n120\n49\nResults for SisFall: One ADL vs. Individual Falls\
    \ . . . . . . . . . . . . .\n122\n50\nResults for K-Fall: One ADL vs. Individual\
    \ Falls\n. . . . . . . . . . . . .\n122\n51\nResults for SisFall: Individual ADLs\
    \ vs. Individual Falls\n. . . . . . . . .\n123\n53\nComparison with State of the\
    \ art (Individual ADLs vs. Individual Falls.)\n125\n54\nComparison with State\
    \ of the art (Individual ADLs vs. Individual Falls.)\n126\n55\nResults for the\
    \ four Experiments for the SisFall dataset (F1-Score[%]) . .\n126\nxii\nLIST OF\
    \ FIGURES\n1\nSmart City Components . . . . . . . . . . . . . . . . . . . . .\
    \ . . . . . .\n5\n2\nIoT Architecture\n. . . . . . . . . . . . . . . . . . . .\
    \ . . . . . . . . . . .\n8\n3\nChallenges for IoT in Smart Cities. . . . . . .\
    \ . . . . . . . . . . . . . . .\n12\n4\nSensing Technologies for IoT Smart Cities.\
    \ . . . . . . . . . . . . . . . . .\n16\n5\nNetwork Technologies for IoT Smart\
    \ Cities.\n. . . . . . . . . . . . . . . .\n23\n6\nModified CERT Attack Taxonomy\
    \ for Smart Cities. . . . . . . . . . . . .\n24\n7\nAI for IoT Smart Cities. .\
    \ . . . . . . . . . . . . . . . . . . . . . . . . . .\n47\n8\nOptimization applications\
    \ in Smart Agriculture. . . . . . . . . . . . . . .\n54\n9\nOptimization applications\
    \ in Smart City Services. . . . . . . . . . . . . .\n57\n10\nOptimization applications\
    \ in Smart Grid. . . . . . . . . . . . . . . . . . .\n59\n11\nOptimization applications\
    \ in Smart Health.\n. . . . . . . . . . . . . . . .\n62\n12\nOptimization applications\
    \ in Smart Homes.\n. . . . . . . . . . . . . . . .\n64\n13\nOptimization applications\
    \ in Smart Industry. . . . . . . . . . . . . . . . .\n69\n14\nOptimization applications\
    \ in Smart Infrastructure.\n. . . . . . . . . . . .\n70\n15\nOptimization applications\
    \ in Smart Transportation . . . . . . . . . . . .\n72\n16\nOptimization applications\
    \ in IoT based Smart Cities. . . . . . . . . . . .\n75\n17\nFall Detection with\
    \ Direction and Severity. . . . . . . . . . . . . . . . . .\n93\n18\nHierarchical\
    \ classification scheme for ADL and Fall detection.\n. . . . . .\n103\n19\nSample\
    \ Wavelet (Mexican Hat). . . . . . . . . . . . . . . . . . . . . . . .\n104\n\
    20\nHaar Wavelet. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\
    \ . . .\n105\n21\nExample: 4-2-1 1-D Spatial Pyramid Pooling. . . . . . . . .\
    \ . . . . . . .\n106\n22\nAverage F1-scores for each activity for the four classifiers.\n\
    . . . . . . . .\n108\n23\nCNN-XGBoost based classification scheme for ADL and\
    \ Fall detection. .\n112\n24\nIllustration of data augmentation. (X component\
    \ of Accelerometer, Lat-\neral Fall) . . . . . . . . . . . . . . . . . . . . .\
    \ . . . . . . . . . . . . . . .\n113\n25\nCNN Network for feature extraction and\
    \ XGBoost classification stage.\n.\n114\n26\nNetwork performance for different\
    \ fall directions.\n. . . . . . . . . . . . .\n117\n27\nNetwork performance for\
    \ different fall directions.\n. . . . . . . . . . . . .\n118\n28\nConvLSTM-attention\
    \ Network.\n. . . . . . . . . . . . . . . . . . . . . . .\n121\n29\nFall detection\
    \ performance for both experiments.\n. . . . . . . . . . . . .\n124\n30\nFall\
    \ severity performance.\n. . . . . . . . . . . . . . . . . . . . . . . . . .\n\
    124\n31\nFall direction performance. . . . . . . . . . . . . . . . . . . . . .\
    \ . . . . .\n125\n1\nAccelerometer and Gyroscope measurements: Forward Hard Fall\
    \ . . . . .\n174\n2\nAccelerometer and Gyroscope measurements: Forward Soft Fall\n\
    . . . . .\n175\n3\nAccelerometer and Gyroscope measurements: Backward Hard Fall\
    \ . . . .\n176\n4\nAccelerometer and Gyroscope measurements:f Backward Soft Fall\
    \ . . . .\n177\n5\nAccelerometer and Gyroscope measurements: Lateral Hard Fall\n\
    . . . . .\n178\n6\nAcclerometer and Gyroscope measurements: Lateral Soft Fall\n\
    . . . . . .\n179\nxiii\nCHAPTER I\nINTRODUCTION AND DISSERTATION OVERVIEW\n1\n\
    Motivation\nThe world is experiencing a bulging world population and increasing\
    \ urbanization\nwhich is set to grow by more than 10% in the next 30 years [1]\
    \ resulting in a total\nof 70% living in cities by 2050. Countries around the\
    \ world are looking at equipping\ntheir cities to deal with the influx of people\
    \ and the stress it will bring to current\ncity systems [2]. This is to be performed\
    \ keeping in view the UN Sustainable De-\nvelopment Goals 2030 [3]. In this regard,\
    \ Smart Cities have come out as a major\ninitiative by various governments in\
    \ making cities more navigable and welcoming to\nthe expected population increase\
    \ and providing city dwellers a better living experi-\nence, as is evidenced by\
    \ the multiple projects ongoing on both the public and private\nlevel [4, 5, 6,\
    \ 7]. The Internet of Things (IoT) has been the prime enabler of smart\ncities\
    \ as it has provided the means in terms of sensors, architectures, storage and\n\
    other technologies to instrument cities. It allows stakeholders to gather data,\
    \ pro-\ncess it and then make decisions based on the analyses performed. There\
    \ are various\ndomains within smart cities, these include Smart Agriculture, Smart\
    \ City Services,\nSmart Grid, Smart Health, Smart Homes, Smart Industry, Smart\
    \ Infrastructure and\nSmart Transportation.With improvement of Artificial intelligence\
    \ (AI) capabilities\nin the last decade, there have been different applications\
    \ of machine learning (ML)\nand deep learning (DL) algorithms within each of these\
    \ domains providing for better\ndecision making and improvement of services. Apart\
    \ from various supervised and un-\nsupervised learning applications, several tasks\
    \ within different components of smart\ncities can be formulated into optimization\
    \ problems and/or require heuristics to be\nincorporated in some form. However,\
    \ in both such tasks, there is a dearth of an\noverall coverage of Smart City\
    \ IoT based ML/DL and combinatorial optimization\nproblems. Such a coverage would\
    \ be very beneficial to researchers starting in the\nfield and has been presented\
    \ herein.\nOne of the major applications of the IoT Smart Cities is for health\
    \ purposes.\nMany countries around the world, especially in the developed world\
    \ are facing an\naging population. With the retirement of the ’baby boomer’ generation,\
    \ countries\naround the world are facing a big question over caring for their\
    \ elderly population.\nOne of the major issues that elderly people face today\
    \ are falls [8]. In the US, falls\naccount for a majority of the deaths caused\
    \ by injury in population aged 65 and\nabove [9] and a fall related injury occurs\
    \ every 19 minutes [10]. As indicated in [11],\nfalls have been associated with\
    \ estimated medical costs ranging from $31.5 billion for\n2013 to $49.5 billion\
    \ for 2017. Moreover, Floerence et al. [12] notes that in 2018,\nfalls contributed\
    \ to 8% of Medicaid expenses in the US for older adults, consequently\n1\nfalls\
    \ have huge health as well as financial ramifications for people and governments.\n\
    Determining when a person has experienced a fall is therefore an important task\
    \ in\nthe healthcare of people, more so in the old age population who tend to\
    \ increasingly\nlive alone and are at increased risk of suffering from falls.\
    \ Apart from just detecting\nif a fall has occurred or not, the direction of a\
    \ fall is an important consideration\nas well. Bourke et al. [13] notes that even\
    \ though 60% of falls occurring in older\nadults are forward falls, falls occurring\
    \ sideways may result in fracture and thus\nare important to determine. Quick\
    \ dispatch of healthcare providers can result in\ntimely treatment of fall related\
    \ injuries, thereby reducing the overall impact to life\nand wealth. Additional\
    \ information about the fall could benefit the medical dispatch\nteam to help\
    \ decide emergency procedures which could be matched up with patient\nhistory\
    \ of potentially being injury prone in a certain part of the body. In light of\
    \ this\nall, the development of fall detection systems has been of keen interest\
    \ to researchers\nin the domain of human activity recognition, tele-medicine and\
    \ smart health.\n2\nAims\nCiting the importance of IoT usage in communities, the\
    \ aims of this dissertation are\nas follows:\n1. To provide a wholistic coverage\
    \ of IoT based Smart City system design consid-\nering important aspects such\
    \ as sensors, technologies used, IoT architectures,\nthe use of machine/deep learning\
    \ methods and optimization schemes as well as\nthe challenges.\n2. Considering\
    \ the case study of smart health and specifically fall detection, de-\nvelop methodologies\
    \ for detection of falls considering fall direction and severity.\n3\nOrganization\n\
    This dissertation is organized in to six chapters.\nChapter II presents a coverage\n\
    of the IoT for Smart Cities in terms of the technologies used, its architectures\
    \ and\nalso the challenges towards IoT usage in Smart Cities. Chapter III discusses\
    \ the the\napplications of machine and deep learning algorithms. This chapter\
    \ provides a com-\nprehensive discussion on IoT usage in Smart Cities by considering\
    \ the different types\nof systems devised for each application as well. Chapter\
    \ IV discusses the applications\nof optimization algorithms in IoT based smart\
    \ cities for five popular algorithms. It\nthus provides a coverage of optimization\
    \ applications under the IoT smart city um-\nbrella. Chapter V presents work on\
    \ a chosen case study of smart health based on\nIoT. The considered task is fall\
    \ detection with direction and severity consideration.\nFour experiments have\
    \ been performed in this regard considering three scenarios, one\nconsidering\
    \ falls only with direction and severity and two others considering falls and\n\
    activity of daily living (ADL) as a combined problem. The designed methodologies\n\
    have shown to outperform the state of the art as has been discussed in the chapter.\n\
    The conclusion and future work opportunities are discussed in chapter VI.\n2\n\
    CHAPTER II\nIOT SMART CITIES\n1\nIntroduction\nThis chapter provides an overeview\
    \ of the use of IoT in Smart Cities and discuss\nhow it facilitates such initiatives.\
    \ It starts by laying out the structure of Internet\nof Things in a Smart City\
    \ context, discussing its various applications, components\nand architectures\
    \ while also discussing the technologies used at the different levels of\nthe\
    \ IoT architecture. Lastly, a discussion of the technical challenges that exist\
    \ in the\ndeployment of IoT in the Smart City domain is provided along with identification\
    \ of\npotential solutions to those challenges followed by future directions.\n\
    It is hard to define a Smart City, in fact, cities claim to be ‘smart’ based on\
    \ a\nvariety of criteria, for e.g. implementing novel e-governance schemes, creating\
    \ so-\ncial learning ventures and community engagement programs, focusing on sustainable\n\
    living as well as the more typical application of Information and Communication\n\
    Technologies for innovation [14]. In this work, Smart Cities are defined to be\
    \ the ap-\nplication of various information and communication technologies (ICT)\
    \ with the aim\nof creating a better living experience for a city’s population.\
    \ This encompasses use\nof these technologies in all the domains discussed previously,\
    \ including governance,\ntransport, housing, business, sustainable living, social\
    \ learning, community engage-\nment, providing opportunities and more. In an ideal\
    \ sense, the idea of a smart city\ntranscends the typically set boundaries of\
    \ a traditional city’s administrative and so-\ncial structure by allowing interaction\
    \ between the two, thereby enabling it to operate\nin a more cohesive and engaged\
    \ manner. Smart cities offer several advantages (in\nterms of value) compared\
    \ to a traditional city ecosystem:\n1. Climate goal achievement: Smart cities\
    \ are at the forefront of pioneering tech-\nnologies to help enable countries\
    \ meet climate goals. Smart city focuses on\nsmart energy management, smart transportation\
    \ systems and city administra-\ntion which aim to reduce the carbon footprint\
    \ of cities and enable development\nand use of new technologies for cleaner living.\n\
    2. Money value: Smart City ventures will be a market of USD 1 Trillion by 2025\n\
    [15], this provides a huge monetary incentive for not only governments but\nprivate\
    \ companies to actively contribute to the development of technologies\nsupporting\
    \ smart city development.\n3. Societal impact: The centerpiece of the smart city\
    \ project is to improve the qual-\nity of life of a city’s inhabitants and help\
    \ develop an inclusive society wherein\nevery opinion is catered for and equal\
    \ opportunity is provided. Information and\n3\nCommunication Technologies in the\
    \ smart city context are a fundamental com-\nponent to the provision of public\
    \ services by facilitating interactions of citizens\nwith the city environment\
    \ and making life easier.\n2\nSmart City Components\nA smart city is made up of\
    \ several components which are illustrated in Figure 1.\nSmart city applications\
    \ typically have four aspects associated with them, the first is\nthe collection\
    \ of data, the next is its transmission/reception, third is the storage and\n\
    fourth is analysis. The collection of data is application dependent and has been\
    \ a real\ndriver for sensor development in the various domains. The second part\
    \ is the exchange\nof data, this involves data transmission from the data collection\
    \ units towards the\ncloud for storage and analysis.\nThis task has been achieved\
    \ in several manners,\nmany smart city ventures have city-wide Wi-Fi networks,\
    \ 4G and 5G technologies are\nbeing used, as well as various types of local networks\
    \ which can convey data either\non a local level or a global level. The third\
    \ stage is storage in the cloud, different\nstorage schemes are used to arrange\
    \ and organize data so as to make it usable for\nthe fourth stage which is data\
    \ analysis. Data Analysis refers to the extraction of\npatterns and inferences\
    \ from the gathered data to guide decision making. In some\nsituations, simple\
    \ analysis such as basic decision making and aggregating would work\ntoo. For\
    \ more complex decision making, the availability of the cloud allows not only\n\
    for heterogeneous data gathering/storage and processing but also analysis through\n\
    the use of statistical methods as well as machine and deep Learning algorithms\
    \ in\nreal-time [16].\n2.1\nSmart Agriculture\nFood security is one of the most\
    \ important parts of the United Nations Sustainable\nDevelopment goals for 2030.\
    \ With an increasing world population, worsening climate\nchange causing erratic\
    \ weather in food centers of the world, the race to ensure that\nfood production\
    \ is made sustainable and that dwindling resources such as water are\nutilized\
    \ efficiently has been a high priority for countries around the world. Smart\n\
    agriculture is the use of sensors embedded into plants and fields to measure various\n\
    parameters to help in decision making and prevent/diseases, pests etc [17]. A\
    \ part\nof the smart agriculture paradigm is precision agriculture, which involves\
    \ sensors\nbeing placed in plants to provide targeted measurements and therefore\
    \ allow for\ntargeted care mechanisms to be deployed. Precision agriculture will\
    \ be necessary\nfor food security in the future [18] and therefore is an essential\
    \ part of the fight for\nsustainable food production. The major applications of\
    \ AI in IoT for agriculture are\ncrop monitoring/disease detection and data driven\
    \ crop care and decision making.\n2.2\nSmart City Services\nSmart city services\
    \ encompass the activities that sustain a city’s population, these\ninvolve municipal\
    \ tasks such as supply of water, waste management, environmental\n4\nSmart \n\
    Energy\nSmart \nTransportation\nSmart \nAgriculture\nSmart \nInfrastructure\n\
    Smart  \nCity Services\nSmart Health\nSmart Homes\nSmart  Industry\nFigure 1.\
    \ Smart City Components\ncontrol and monitoring etc. Sensors for water quality\
    \ can be deployed to continually\nprovide an update about the quality of water\
    \ being used in the city and detect leaks\n[19]. One popular component of smart\
    \ city initiatives is the management of waste,\nand it has been the part of many\
    \ of the smart city initiatives mentioned earlier, from\nchutes in Barcelona to\
    \ having bins equipped with sensors and connected to the cloud\nso as to not only\
    \ inform the relevant authorities of the need to empty them but also\nusing AI\
    \ to determine the best route to reduce cost [20]. Sensors can also be used to\n\
    monitor the environmental conditions in a city to determine pollution levels [21]\
    \ and\nguiding citizens to the next free parking space to save fuel costs [22].\n\
    2.3\nSmart Energy\nTypical electrical systems have one-way energy flow from a\
    \ main generator source,\nusually a hydroelectric or fossil fuel based power plant.\
    \ Power generation is controlled\nvia feedback from the substations, however,\
    \ since there is no information feedback\nfrom the consumer end, the power generation\
    \ scheme used with these systems requires\nthat the power being produced by these\
    \ sources outstrips the demand by a large\namount to ensure continuous supply\
    \ of power. The process of detecting faults and\nperforming corrective actions\
    \ in such systems is also a time taking process. Moreover,\nwith renewable energy\
    \ technologies becoming cheaper, the consumer of today not\nonly has a supply\
    \ from the main utility but also performs their own generation.\nSmart Grids is\
    \ the use of ICT to make the current and newly installed grids more\nobservable,\
    \ allow for distributed energy generation, both at the consumer end as well\n\
    as the utility end and introduce self-healing capabilities in to the grid. One\
    \ aspect\n5\nof smart grids is that real time power data is transmitted to utilities\
    \ at different\npoints on the grid throughout the supply lines till the customer.\
    \ Since smart grids\nprovide real-time data about consumer usage, it allows for\
    \ better management of\npower generation using prediction models developed through\
    \ acquired consumption\ndata, integrating different energy sources as well as\
    \ self-healing [23] of the network\nto ensure an uninterrupted supply.\n2.4\n\
    Smart Health\nSmart Health refers to the use of ICT to improve health care availability\
    \ and quality.\nWith an increasing population and rising costs of healthcare,\
    \ this area has been of\nintense focus of researchers as well as healthcare providers.\
    \ Current health systems\nare over burdened and therefore cannot cater to the\
    \ increasing demand from the pop-\nulace. In this regard, smart health aims to\
    \ ensure that healthcare be available to as\nmany people as possible through telemedicine\
    \ services [24] and improved diagnosis\nassistance to doctors utilizing AI [25].\
    \ With the ubiquitousness of mobile phones\nand health trackers [26] that can\
    \ capture real-time data about peoples health (ECGs,\ntemperature, body oxygen\
    \ saturation and other biosensors) while also recording daily\nactivity and detecting\
    \ abnormal movements using inertial sensors, it has become pos-\nsible to leverage\
    \ cloud capabilities for processing this data to make better healthcare\ndecisions.\
    \ Thus reducing the overall costs as well as burden on healthcare facilities.\n\
    2.5\nSmart Home\nOne major component of Smart Cities is the Smart Home since it\
    \ is central to the\nlife of the city’s inhabitants. Smart Homes involve the use\
    \ of sensing units installed\nthroughout a person’s home that provide information\
    \ about the home as well as\nits occupants. These sensors might include user activity\
    \ monitors such as ambient\nsensors, motion trackers and power/energy consumption.\n\
    2.6\nSmart Industry\nIndustries around the world are busy in a continuous pursuance\
    \ of being more ef-\nficient and increasing productivity while reducing cost.\
    \ The industry 4.0 paradigm\nentails the vision of a connected factory where all\
    \ its intermediary functionaries are\nseamlessly integrated, working in tandem\
    \ with each other. This is made possible be-\ncause of the internet of things\
    \ [27]. The use of IoT in manufacturing and production\nprocesses, cyber physical\
    \ systems integrating workers and machines has led to several\nbenefits to the\
    \ industry such as faster and better innovation, optimization of manu-\nfacturing\
    \ schemes (resources and processes), better quality of products and enhanced\n\
    safety for factory workers. However, smart industries come with several challenges\n\
    for IoT usage, working with a set of heterogeneous devices and machines has its\
    \ own\nchallenges and requires cyber physical systems to have flexibility in configuration,\
    \ con-\nnectivity and quick implementation for use in IoT applications for Smart\
    \ Industry\n[28]. Artificial Intelligence has gone hand in hand with IoT to spur\
    \ the development\nand deployment of industry 4.0 services. With sensors being\
    \ embedded in machines\n6\nand other processes in the factory, data from these\
    \ sources provide an opportunity for\nusing AI techniques to increase automation,\
    \ perform business intelligence operations\nand more. In fact, researchers have\
    \ suggested frameworks for integrating AI within\nIoT for Smart Industry [28,\
    \ 29, 30]. The major applications of AI in the industry are\npredictive maintenance,\
    \ monitoring/fault detection (machine health) and production\nmanagement.\n2.7\n\
    Smart Infrastructure\nThe infrastructure of a city is paramount to its living\
    \ quality, city governments need\nto construct new bridges, roads and buildings\
    \ for the use of its inhabitants and also\nperform maintenance for uninterrupted\
    \ usage. Smart infrastructure helps cities in\nensuring their infrastructure is\
    \ in shape and usable by utilizing sensors for measuring\nbuilding/bridge structural\
    \ state for structural health monitoring using accelerome-\nters [31] and smart\
    \ materials [32]. Data collected through these sensors allows for\npredictive\
    \ maintenance of these essential units to maintain normal operation of the\ncity.\n\
    2.8\nSmart Transport\nMany urban centers suffer from traffic problems, this includes\
    \ congestion, pollution,\nscheduling and cost reduction issues for public transport.\
    \ The rapid development\nand implementation of new Information and Communication\
    \ Technologies, Vehicle-\nInfrastructure-Pedestrian communication has become commonplace.\
    \ Whether it be\nVehicle to Vehicle (V2V), Vehicle to Infrastructure (V2I), Vehicle\
    \ to Pedestrian (V2P)\nor Pedestrian to Infrastructure (P2I), such technologies\
    \ have made the design of smart\ntransportation systems possible. With cars having\
    \ a GPS device and the common-\nality of cellphones with every driver, many approaches\
    \ use GPS data to track driver\nbehavior and traffic patterns [33]. This real-time\
    \ data is already used for route map-\nping in applications such as Waze and Google\
    \ Maps and used for trip scheduling in\npublic transport. Parking systems equipped\
    \ with sensors can also guide drivers to\nthe nearest free parking spot.\n3\n\
    Internet of Things for Smart Cities\nAt the heart of the smart city initiatives\
    \ is the internet of things, it is the enabling\ntechnology that has allowed for\
    \ the pervasive digitization that gives rise to the con-\ncept of smart cities.\
    \ The internet of things refers to the ubiquitous connection of\ndevices to the\
    \ internet, allowing them to send information to the cloud and poten-\ntially\
    \ get directions for performing actions. IoT involves the collection of data and\n\
    performing data analytics operations to extract information in order to support\
    \ de-\ncision and policy making. It is estimated that by 2025 more than 75 billion\
    \ devices\nwill be connected to the internet [34], spearheading even more application\
    \ develop-\nment. Within the smart city context, IoT allows for sensors to collect\
    \ and send data\n7\nabout the city’s state to a central cloud, which is then mined\
    \ or processed for pattern\nextraction and decision-making purposes.\n3.1\nIoT\
    \ Architectures for Smart cities\nThe Internet of Things unifies the operations\
    \ of data sensing, transmission/recep-\ntion, processing and storage through the\
    \ use cloud services. Based on technology, a\ngeneric IoT architecture consists\
    \ of five layers where successive layers operate on the\ninformation from the\
    \ previous layer as shown in Figure 2. It also shows the three\ndifferent architectures\
    \ that exist for IoT systems.\nCloud Computing\nEdge computing\nFog Computing\n\
    Business layer\nActuators\nMobile Elements\nSensors\nNetwork Technologies\nNetwork\
    \ Topologies\nAPIs, Databases, Security\nApplications\nData Analytics (Machine\
    \ Learning, Optimization, Deep Learning)\nApplications \nLayer\nMiddleware \n\
    Layer\nNetwork Layer\nSensing Layer\nFigure 2. IoT Architecture\nThe Sensing layer,\
    \ also called the Perception layer consists of sensors that can\nget information\
    \ about physical quantities of interest in any application as well as\nactuators\
    \ which can act upon physical objects, such as Radio Frequency IDentification\n\
    (RFID) readers for reading RFID tags and other such devices. The data read by\
    \ the\nsensing layer is passed onward to the Middleware layer using the networking\
    \ layer\nthrough wireless network technologies such as Wi-Fi, cellular internet,\
    \ Zigbee and\nBluetooth etc.\nThe Middleware layer provides a generic interface\
    \ for the sensing\nlayer hardware and the Application layer which uses the data\
    \ through various API’s\nand database management services to provide users with\
    \ services. The Business layer\nis attached to the application layer and is used\
    \ to develop strategies and formulate\npolicies that help manage the complete\
    \ system.\nIn terms of architectures, typically, IoT architectures are categorized\
    \ based on\nthe type of operation responsibilities allocated to parts of the IoT\
    \ system, this cat-\negorization is based mainly on processing of data responsibilities.\
    \ There are three\narchitectures of IoT systems with respect to the stage of the\
    \ IoT framework where\nprocessing of data can be carried out and these are Cloud,\
    \ Fog and Edge Models.\nTable 1 lists the traits of each of three layers of the\
    \ IoT system. It is important to\n8\nmention that the three IoT architectures\
    \ discussed here are not mutually exclusive,\ninstead the aim of this hierarchy\
    \ is to complement the higher layer by providing it only\nuseful information which\
    \ makes the system more productive and dependable. For any\nIoT system designer,\
    \ the aim is to establish a balance between the capabilities of the\nthree layers\
    \ keeping in view system costs and requirements.\n3.1.1\nCloud Computing Model\n\
    This was the first proposed architecture for IoT systems and is based on the premise\n\
    that processing of data from the various components in the IoT system should take\n\
    place in the cloud. Cloud computing allows for the remote accessing of uninterrupted\n\
    shared resources (computing, storage and services) over the network. It should\
    \ be\nable to dynamically allocate these resources without human intervention,\
    \ schedule\nor pool as necessary and be able to be accessed from a variety of\
    \ different platforms\n[35]. The cloud can provide both hardware as well as software\
    \ services for smart city\napplications. It has the advantage that it provides\
    \ a central management platform\nfrom which to observe, control the IoT system\
    \ as well as to disseminate command\nactions based on the received data. Moreover,\
    \ this centralization also allows for cloud\nsystems to have sufficiently large\
    \ computing and storage capacities thereby allowing\nthem to perform complex tasks\
    \ of data mining, pattern extraction and making infer-\nences from sensor data\
    \ in smart cities to make use of it in the best manner possible.\nHowever, there\
    \ are a few disadvantages with using the cloud computing model for\nthe IoT. First,\
    \ transmitting all gathered data to the cloud increases network traffic,\neven\
    \ though this may not be true for applications in which measurements are not\n\
    very frequent, but in other cases, this could increase network costs. Moreover,\
    \ data\ntransmission overheads may increase due to the large amount of data that\
    \ needs to\nbe transmitted by the many sensors existing in the smart city scenario.\
    \ Another\ndisadvantage that the cloud computing model suffers from is data latency,\
    \ since the\nsensing units exist at the sensing layer and the decision making/data\
    \ processing takes\nplace in the cloud, this gives rise to data latency in the\
    \ transmission of sensing infor-\nmation, especially when many devices start sending\
    \ data at the same time. Network\nreliability can be an issue when using this\
    \ model, with the large volume of data traffic\non the network, it might not be\
    \ possible to enforce robust data transmission schemes\nas IoT systems get bigger.\n\
    3.1.2\nFog Computing Model\nSince most of the information produced with in IoT\
    \ takes place towards the sensing\nend of the IoT system, also called the edge,\
    \ Fog Computing was proposed in [36]\nto overcome some of the problems of the\
    \ cloud computing model for the IoT. Fog\ncomputing provides a more diverse distribution\
    \ of responsibilities than are dictated\nby the cloud computing architecture by\
    \ moving some of the processing to devices\non the local network.\nTypically,\
    \ Fog computing refers to data processing that is\ncarried out by routers and\
    \ other network devices within in the Network layer in the\nIoT. Since network\
    \ devices nowadays increasingly offer better computational capabil-\n9\nities,\
    \ one can leverage them to perform rudimentary operations on data. Operations\n\
    such as aggregation and collection of sensor data, simple processing operations\
    \ and\ndecision-making can be performed to reduce the amount of information flow\
    \ towards\nthe higher cloud layer. Questions that need to be answered for the\
    \ decision-making\nprocess include but are not limited to for e.g., does the decision\
    \ require the use of\naveraging for one quantity and instantaneous values of the\
    \ other? Is it possible to\nextrapolate data received for one quantity and use\
    \ the currently measured value for\nanother one? Based on the previous data for\
    \ a given period, can one provide higher\nlayers with decision options rather\
    \ than just data, thereby providing better quality\ninformation to the cloud layer\
    \ thus resulting in better utilization of cloud resources.\nFog layers can localize\
    \ decision making since they have access to the local state of a\ngiven region\
    \ [37]. This would be helpful in implementing distributed decision mak-\ning mechanisms\
    \ which might be necessary in some applications. Moreover, they also\nallow for\
    \ local networks to be established using non-internet technologies such as Zig-\n\
    bee, Bluetooth, RFID etc where sensors and other end devices transmit data to\
    \ the\nFog node (also referred to as access points in such systems) which is connected\
    \ to the\ncloud.\nFog computing results in reduced costs for deployment of IoT\
    \ systems, increases ro-\nbustness as latency, data overhead and errors in transmission\
    \ are reduced. This also\nimproves the efficiency of the applications as quicker\
    \ decisions can be made on the\nreceived data, which is important in critical\
    \ decision-making situations. Moreover,\nFog devices have the capability to not\
    \ only receive data from similar devices at the\nedge but also collect it from\
    \ many different types of devices. This capability to mea-\nsure different parameters\
    \ in the edge environment enable for an application neutral\nIoT system architecture\
    \ to be developed.\nData sent upward by the Fog layer in the IoT hierarchy would\
    \ be used to gain insights\nin to system behavior and to guide new rules of system\
    \ operation, this will typically\nbe carried out in the cloud. Devices in the\
    \ Fog layer may be provided decision making\nguidance from the higher cloud layer\
    \ to ensure smooth system operation. However,\na balance needs to be struck as\
    \ to the division of responsibilities between the cloud\nand the fog layer keeping\
    \ in view the costs involved.\n3.1.3\nEdge Computing Model\nThe purpose of Fog\
    \ Computing was to push some of the decision making towards\nthe edge of the network.\
    \ In recent years, with increasingly capable devices being\ndeveloped that are\
    \ attached to ‘edge’ nodes, simple decision making, and processing\nof data has\
    \ been increasingly moved on to these devices so as to reduce network\nand device\
    \ costs even further at the fog level and make for even deeper distributed\ndecision-making\
    \ schemes. Edge computing refers to data processing that is done at\nthe ”thing”\
    \ level, i.e. by sensors and other devices in the IoT system [38]. Another\nconcept\
    \ about Edge computing as discussed in [39] defines the Edge computing layer\n\
    as an intermediary layer between the Fog and the ‘things’ (sensors) rather than\
    \ edge\nnodes. The difference between them in this case is the Edge computing\
    \ nodes act\nas aggregation and decision-making units on a smaller scale compared\
    \ to fog devices\n10\nwhich act to provide seamless connectivity and data integrity\
    \ throughout the IoT\nnetwork. The aim of the Fog and the Edge computing paradigms\
    \ is to decentralize\nthe IoT system for purposes of reducing cost, increasing\
    \ scalability and increasing\nrobustness.\nTable 1. Comparison of Cloud, Fog and\
    \ Edge Computing Models\nCloud\nComputing\nModel\nFog Computing Model\nEdge Computing\
    \ Model\nContextual awareness on a\nglobal level encompassing all\naspects of\
    \ the application\nThe Fog layer has contextual aware-\nness of the local sensing\
    \ scenario\nEdge devices typically only\nhave\ninformation\nabout\ntheir own status.\
    \ Exchange\nstrategy possible but limited\nto local neighborhood\nFarthest away\
    \ from the edge\nand therefore decision mak-\ning can be slow and latency\nis\
    \ high\nBeing the closest unit to the edge,\nthe Fog layer can respond much\n\
    more quickly to the data being sent\nfrom sensors and other devices, as it\ncan\
    \ aggregate the information sent\nQuickest\ndecision\nmaking\npossible; however,\
    \ decisions\nwill be based on local states\nUtilizes heterogeneous data\nfrom\
    \ a variety of sensing de-\nvices\nUtilizes heterogeneous data,\nbut\nwithin a\
    \ small region\nUsually do not have access\nto different types of data\nHigh network\
    \ cost\nMedium network cost as data flow\nis reduced\nLeast network cost\nPotential\
    \ privacy risk as raw\ndata might be sent to the\nCloud\nIncreased\nprivacy\n\
    compared\nto\nCloud computing\nEven\ngreater\nprivacy\nen-\nforcement possible\
    \ than Fog\ncomputing model\nLeast\nrobust\nas\ndecision\nmaking is centralized\n\
    More robust than Cloud computing\nmodel\nMost robust as distributed\ndecision\
    \ making takes place\nBest capabilities in terms of\nresources\nLesser capable\
    \ than Cloud devices\nLeast capable\nScalability is low\nScalability is better\
    \ than Cloud\nScalability is highest\n3.2\nIoT Challenges for smart Cities\nThe\
    \ Internet of Things promises the digitization of all aspects of our lives. For\
    \ smart\ncities, this digitization process entails the proliferation of sensing\
    \ nodes in every\ndomain of a city’s operation mechanism. With an application\
    \ scope this broad, the\ncreation and subsequent deployment of IoT systems in\
    \ smart cities carry enormous\nchallenges that need to be considered. In this\
    \ section, a discussion is provided of\nthe challenges that IoT system designers\
    \ face when making deployments in smart\ncity applications.\nThe focus in this\
    \ work is on the technological challenges that\npertain to IoT use in smart cities\
    \ and has also been the focus of researchers. Figure 3\nshows the different challenges\
    \ which Smart City IoT system deployment encounters,\nnamely Security and Privacy,\
    \ Smart Sensors, Networking and Big Data Analytics. A\nsummary of the discussion\
    \ in this section is presented in Table 2.\n11\nSmart City\nChallenges\nSmart\
    \ \nSensors\nNetworking\nIntelligent \nData \nAnalytics\nSecurity and \nPrivacy\n\
    Interoperab\nility\nReliability\nRobustness\nPower\nMemory\nHeterogen\nous data\n\
    Scalability\nLow Power\nMobility\nRouting\nEncryption \nData \nLeakage\nAccess\
    \ \nControl\nNetwork \nAttacks\nFigure 3. Challenges for IoT in Smart Cities.\n\
    3.2.1\nSecurity and Privacy\nSecurity, along with Privacy is the primary concern\
    \ in smart cities.\nSmart cities\ninvolve having essential city infrastructures\
    \ online, any aberration in the operation\nof the city’s services will bring inconvenience\
    \ to its citizens and put human lives and\nproperty at risk. Therefore, security\
    \ is a big concern in smart cities. In today’s age\nwhere cybercrime and warfare\
    \ have become a tactic in world politics, smart cities\nare at an ever-greater\
    \ risk of being the target of such malicious attacks. Encryption\nof data transmitted\
    \ over the network is necessary in this scenario. For smart city\nprojects to\
    \ be successful, they require the trust and participation of citizens. The\nproliferation\
    \ of sensors in smart cities, which continuously collect data about the\nactivity\
    \ of people may expose the daily activities of citizens to unwanted parties.\n\
    Moreover, companies and corporations on the IoT network may use citizen data\n\
    without their approval for things like targeted advertising and may perform acts\
    \ such\nas eavesdropping etc. Solutions to this will require processes that anonymize\
    \ data\ncollection while retaining the integrity of the context of the measured\
    \ task so that\napt decision making is possible. Security and Privacy has been\
    \ covered in detail in a\nlater section.\n12\n3.2.2\nSmart Sensors\nSmart sensors\
    \ are the hardware components that gather data in smart cities. These\ndevices\
    \ are manufactured by a host of different vendors that adhere to different sens-\n\
    ing mechanisms, standards of measurement, data formats and connectivity proto-\n\
    cols. Smart city deployment will require all these devices to exchange data, perform\n\
    scheduling of tasks between them and be able to aggregate data together for mak-\n\
    ing inferences. A solution to this issue is to develop and use open protocols\
    \ and\ndata formats that will enable manufacturers to create equipment that can\
    \ communi-\ncate between each other, further spurring IoT system deployment. Another\
    \ solution\ncould be the development of ‘standard’ access point nodes for IoT\
    \ systems that can\ncommunicate to devices using several different communication\
    \ protocols and are able\nto decode the information received. Some manufacturers\
    \ have, in fact, made their\nproducts compatible with other protocols as mentioned\
    \ in [40].\nAnother challenge for smart sensors is reliability and robustness.\
    \ Reliability and\nrobustness refer to the dependability and correctness of the\
    \ IoT system. IoT is the\nbackbone of future smart cities and being imperative\
    \ to their operation, the IoT\nsystem needs to provide a smooth experience to\
    \ its users. This requires that service\nrequests from users of the application\
    \ receive an accurate and timely response. The\nquality of service needs to be\
    \ ensured for every citizen in the smart city. Systems\nthat deliver critical\
    \ utilities such as transport, electricity etc. should be decentralized.\nThe\
    \ distributed connection points will allow for robustness and increase reliability.\n\
    One such example is self-healing in Smart Grids [23].\nMany current networking\
    \ protocols are developed for infrastructure networked\ndevices which have access\
    \ to continuous power, however, sensors in smart cities will\nbe mobile in many\
    \ scenarios and thus be battery powered. Moreover, they will need\nto measure,\
    \ transfer and in some cases save data they have collected. This requires\nthe\
    \ development of not only low power, low overhead data transmission schemes\n\
    but also development of new memory and storage technologies as well as low power\n\
    devices that extend battery life as much as possible. Storing this large amount\
    \ of\ndata would require development of compression algorithms which will be employed\n\
    and database schemes that will need to be developed in the future as smart cities\n\
    and IoT are scaled up. Solutions for power issues necessitate the development\
    \ of new\nbattery technologies and perhaps the incorporation of energy harvesting\
    \ mechanisms\nin such devices to make long lasting service provision possible.\n\
    3.2.3\nNetworking\nThe IoT depends on the capability of sensing and other devices\
    \ to be able to send\nand receive information to each other and the Cloud. With\
    \ new smart city appli-\ncations coming up, providing networking to these devices\
    \ to remain connected is a\nbig challenge. Current networking methods are not\
    \ optimized to providing network-\ning services for smart city components. Many\
    \ devices in smart cities have mobility\nand data throughput requirements which\
    \ need to be met to provide an acceptable\nquality of service. Different approaches\
    \ have been suggested in terms of defining ac-\n13\ncess points, local networks\
    \ etc. to solve this problem. Another aspect of networking\nwould be working on\
    \ efficient and dynamic routing protocols that can serve IoT re-\nquirements capable\
    \ of working with stationary as well as devices in motion, which\nmany current\
    \ protocols do not offer sufficiently [41].\n3.2.4\nBig Data Analytics\nIoT connected\
    \ devices generated 13.6 Zetta Bytes of data in 2018 and this is expected\nto\
    \ grow to 79.4 Zetta Bytes till 2025 [34]. To make use of this data and continuously\n\
    improve the services that are delivered in smart cities, new data analytics algorithms\n\
    need to be developed. With the myriad of the different parameters that are measured\n\
    in smart cities, these algorithms need to be applicable to data of varying nature\
    \ (both\nstructured and unstructured), better data fusion techniques need to be\
    \ developed as\nwell so as to combine them in meaningful ways and be able to extract\
    \ inferences and\nrecognize patterns. Deep learning has been of interest in this\
    \ area as it can lever-\nage on this large amount of data to provide better results\
    \ for different applications.\nAnother important consideration would be to ensure\
    \ that the developed algorithms\nare scalable in that they have enough generality\
    \ and can be used through out the\nintended application. For, e.g., for the purposes\
    \ of activity recognition, the authors\nin [42] found that a CNN trained for activity\
    \ recognition on one dataset failed to\nperform well on others or in [43] where\
    \ the deep learning network performs poorly\nwhen the color of tomatoes is different\
    \ from what it was trained on. Concept drift is\nanother issue of concern as with\
    \ the continuous acquisition of data, the properties of\ndata may change over\
    \ time. Techniques such as incremental learning may be useful\nin this respect.\
    \ Explainability is another important factor for Smart City analytics\nto be widely\
    \ acceptable, specially in the area of smart health. There have been some\napproaches\
    \ suggested towards this end, in [44] a hybrid deep learning classifier and\n\
    semantic web technologies based solution is demonstrated for the application of\
    \ flood\nmonitoring. In [45], the authors present an explainable deep learning\
    \ based health-\ncare system at the Edge for COVID-19 care based on a distributed\
    \ learning paradigm\nwith promising results. However, more work needs to be performed\
    \ to incorporate\nexplainability techniques such as distillation, visualization,\
    \ and intrinsic methods into\nMachine and Deep Learning based smart city applications\
    \ in order to increase smart\ncity application proliferation.\n3.3\nSensing Technologies\n\
    Sensing is at the heart of smart city technologies. Sensors provide the knowledge\
    \ and\ndata from which smart city innovations are created. With the vastly different\
    \ nature\nof Smart City projects and its various components, there are numerous\
    \ sensors which\nare used as part of these initiatives. The authors in [58] have\
    \ provided a framework\nfor the comparison of IoT sensors and have listed sensors\
    \ they found in use for the\nInternet of Things. We use their work to direct our\
    \ survey of the sensing technologies\nused in smart cities. Sensors within IoT\
    \ can be divided in to several groups, these are\nambient, motion, electric, biosensors,\
    \ identification, presence, hydraulic and chemical\n14\nTable 2. Smart City IoT\
    \ Challenges and Mitigation\nChallenge\nMitigation/research direction\nReferences\n\
    Security and Pri-\nvacy\nEncryption\n[46][47][48][49][50][51][52]\nNew authentication\
    \ mechanisms\n[53][54][55]\nNew standards to anonymize data\nPrevent data leakage\n\
    Smart Sensors\nInteroperability: Open Standards\n[46][47][48][52][53][54][55]\n\
    Reliability and Robustness: Decen-\ntralized and distributed architec-\ntures\
    \ and decision making\n[56]\nPower and Memory:\nEnergy har-\nvesting, Low power\
    \ sensors, New\ndatabase storage systems\nNetworking\nLow\npower\nnetworks,\n\
    Network\nschemes that ensure fluent mobility\nand routing\n[41][52]\nBig data\
    \ analytics\nNew algorithms which work with\ndifferent\nnatured\ndata,\nDevelop\n\
    scalable and explainable AI\n[47][52][57]\nsensors as shown in Figure 4.\nSensors\
    \ are the key component in smart city IoT\nsystems which provide the interaction\
    \ between the smart city system and the city’s\ninhabitants and allow for new\
    \ services to be developed. One thing to note is that\nmany of the sensors find\
    \ applications in multiple areas as discussed. Furthermore,\nany given application\
    \ will require measuring different physical quantities and will\nrequire the use\
    \ of many different types of sensors. For, e.g., ambient, motion, electric,\n\
    identification, position, chemical and hydraulic sensors have been found to be\
    \ used in\nsmart homes. As noted in the challenges, working with different sensors\
    \ which might\nhave different output data types is a task that needs to be dealt\
    \ with when working\nwith multiple types of sensors. Table 3 presents a summary\
    \ of the sensors used in\neach smart city component.\n3.3.1\nAmbient Sensors\n\
    Ambient sensors include sensors used to measure physical quantities indicating\
    \ to\nenvironmental conditions such as temperature, humidity, light intensity\
    \ and pressure.\nAmbient sensors are used in a variety of smart city applications\
    \ including smart homes\nwhere they are used to regulate the comfort level, they\
    \ are also used for smart city\nservices.\n3.3.2\nBio-Sensors\nBio-sensors are\
    \ used for measuring health parameters of living things. Bio-sensors in\nsmart\
    \ cities are used for monitoring patients for healthcare purposes. Such sensors\
    \ in-\nclude ElectroEncepheloGram (EEG), ElectroMyoGram (EMG), ElectroCardioGram\n\
    15\nAmbient\nPresence\nMotion\nOther \nsensors\nIdentification\nElectric\nHydraulic\n\
    Smart City Services\nSmart Homes\nSmart Transport\nSmart Agriculture\nSmart City\
    \ Services\nSmart Energy\nSmart Homes\nSmart Industry\nSmart Infrastructure\n\
    Smart Transport\nSmart Energy\nSmart Health\nSmart Homes\nSmart Industry\nSmart\
    \ Infrastructure\nSmart Transport\nSmart Health\nSmart Homes\nSmart Industry\n\
    Smart Transport\nSmart Agriculture\nSmart City Services\nSmart Homes\nSmart Industry\n\
    Smart Energy\nSmart Homes\nSmart Industry\nSmart Infrastructure\nSmart Agriculture\n\
    Smart City Services\nSmart Health\nSmart Homes\nSmart Industry\nSmart Infrastructure\n\
    Smart Transport\nBiosensors\nSmart City Services\nSmart Homes\nSmart Transport\n\
    Smart Sensors\nChemical\nSmart Agriculture\nSmart City Services \nSmart Homes\n\
    Smart Transport\nFigure 4. Sensing Technologies for IoT Smart Cities.\n(ECG),\
    \ skin resistance, heart beat, breath sensors, pulse oximetry, blood pressure\n\
    and more.\n3.3.3\nChemical\nChemical sensors are used to measure chemical properties\
    \ of materials, this includes\ngas sensors which can measure/detect carbon monoxide\
    \ (CO), carbon dioxide (CO2)\nand other gases for air quality monitoring, sensors\
    \ for detecting smoke, pH and other\nsensors for water quality monitoring etc.\n\
    3.3.4\nElectric Sensors\nElectric sensors allow for the measurement of electrical\
    \ power and are widely used in\nsmart grids and smart homes to monitor the power\
    \ consumption of consumers/ap-\npliances. Types include current transformers and\
    \ voltage sensors to measure current\nand voltage, respectively.\n3.3.5\nHydraulic\n\
    Hydraulic sensors refer to sensors used for liquid measurements such as level,\
    \ flow,\nleak detection. These are used for measurement of liquid levels in tanks\
    \ [59].\n16\n3.3.6\nIdentification\nIdentification sensors refer to RFID tags\
    \ and Near Field Communication (NFC) de-\nvices. These sensors are used in applications\
    \ involving payments, data exchange in\nthe domain of smart transportation and\
    \ smart city services.\n3.3.7\nMotion Sensors\nMotion sensors refer to sensors\
    \ that can be used for the detection of motion. Sensors\nfor motion sensing involve\
    \ inertial sensors such as accelerometers and gyroscopes.\nThese sensors are used\
    \ in smart health applications such as activity tracking as well\nas applications\
    \ like vibration sensing in smart homes and industry.\n3.3.8\nPresence\nPresence\
    \ sensors indicate to the presence of a humans or objects. Passive InfraRed\n\
    (PIR) sensors are very popular and are used to detect human motion, reed switches\n\
    can be used on windows and doors for security purposes, inductive loop sensors\
    \ which\nuse electromagnetic induction can be used to detect presence in transport\
    \ systems.\nUltrasonic sensors are also used to determine the distance of objects.\n\
    Capacitive\nsensors are also included in this type, these may be used to determine\
    \ position.\n3.3.9\nOther Sensors\nVarious smart city applications make use of\
    \ different sensing modalities such as audio\nor visual information or other signal\
    \ measurement devices, for, e.g., bluetooth and\nWi-Fi signal strength. Since\
    \ the sensors for these modalities capture raw information\nabout signals (visual,\
    \ sound or signal strength etc.), the gathered data is typically\nprocessed further\
    \ before it indicates to the target variable being measured.\n3.4\nNetworking\
    \ Technologies\nThe internet of things in smart cities depends on the aggregation\
    \ of data measured by\nindividual sensing units placed throughout the smart city\
    \ environment. Systems that\ncan use these measurements individually have long\
    \ existed and provided automation\nfor small projects. However, the ‘smart’ in\
    \ smart city comes from the collective usage\nof the data from these individual\
    \ sensing units to perform complex decisions while\ndelivering services to citizens.\
    \ The collective use of this data enables its analysis over\na wider scope compared\
    \ to individual levels so as to determine long term patterns\nand provide meaningful\
    \ insights to support services. The number of such IoT devices\ncurrently present\
    \ in the world [34] are multiple times that of the world population.\nTo enable\
    \ these devices to exchange data, wireless technologies need to be used as\nphysical\
    \ connections would, for one, be too costly (where ever they can be used),\nsecond,\
    \ would not satisfy the mobility requirements that are typical of many smart\n\
    city applications. The internet has provided connectivity to computers, smartphones\n\
    and other electronic devices around the world with each other, allowing for instant\n\
    17\nTable 3. Sensing Technologies for IoT Smart Cities by Smart City Component\n\
    Smart City Com-\nponent\nSensor Type\nReferences\nSmart Agriculture\nAmbient,\
    \ Chemical, Hydraulic, Other sen-\nsors\nSmart City Services\nAmbient, Chemical,\
    \ Hydraulic, Presence,\nOther sensors,\n[60][61][62]\nSmart Energy\nAmbient, Electric,\
    \ Motion\n[63][64]\nSmart Health\nBiosensors, Identification, Motion, Other\n\
    sensors\n[65][66][67]\nSmart Home\nAmbient, Chemical, Electric, Hydraulic,\nIdentification,\n\
    Motion,\nPresence,\nOther\nsensors,\n[63][68]\nSmart Industry\nAmbient, Biosensors,\
    \ Electric, Hydraulic,\nIdentification., Motion, Other sensors\nSmart Infrastructure\n\
    Ambient, Motion, Electric, Other sensors,\n[60]\nSmart\nTransporta-\ntion\nAmbient,\
    \ Chemical, Identification, Mo-\ntion, Presence, Other sensors\n[69][70][71]\n\
    transfer of information between them. However, for IoT the internet may not neces-\n\
    sarily be the only communication method [72] as many applications do not possess\n\
    edge devices that can connect to the internet. An application may consist of a\
    \ local\nnetwork of sensing units which can exchange data between them and rely\
    \ on a multi-\nhop communication protocol to send data to a central node, hub\
    \ or gateway. The\ngateway might be fixed and would be connected to the internet,\
    \ thereby relaying any\nmonitored data to the cloud for further processing or\
    \ use. It might also be possible\nthat devices within an application may use many\
    \ different protocols with the central\nnode having the capability to communicate\
    \ with all of them, a common case for such\narchitectures is the smart home where\
    \ manufacturers produce devices using propriety\nor incompatible protocols for\
    \ which a hub may be used, an example of such a system\nwas provided in [73] and\
    \ several hubs are commercially available. In this section, we\ndiscuss the network\
    \ types, topologies and protocols used in the Internet of Things for\nSmart City\
    \ applications as illustrated in Figure 5. We later provide a comparison of\n\
    these protocols in Table 4.\n3.4.1\nNetwork Topologies\nThere are three IoT network\
    \ topologies, point to point, star and mesh [74]. The first\ntype of topology\
    \ is the point to point topology where devices are connected to each\nother sequentially\
    \ in a point to point manner. Point to point networks introduce\ndata hops for\
    \ packets that need to be sent to other nodes as data needs to go through\neach\
    \ node in the path of the two nodes wanting to exchange data. Point to point\n\
    networks are not very popular in IoT systems as it ranks low on fault resiliency\
    \ and\nwill breakdown if there is a fault in any of the intermediate nodes. In\
    \ Star topology,\n18\nall units in a network are connected to a central node or\
    \ gateway and cannot send data\nto each other directly. In order to perform an\
    \ exchange of data among themselves, the\ndevices need to send it through the\
    \ central node. Star topology networks, with their\ncentral node structure provide\
    \ a natural aggregation scheme for data collection within\nthe internet of things,\
    \ however, large networks consisting of many devices, which can\nbe the case in\
    \ most smart city applications, may result in high latency and possible\nbottlenecks\
    \ in high information throughput scenarios. Star topology has been used in\nvarious\
    \ applications including disaster management [75] and environmental sensing\n\
    [76]. The last type of network topology that is used in IoT is the Mesh network\n\
    topology, mesh networks allow all individual devices to communicate between them.\n\
    By enabling communication between the nodes in a network, mesh topology offers\n\
    a larger range as data transmitted towards a certain node can make multiple hops\n\
    through the network, this also increases the networks resilience as alternate\
    \ paths\ncould be used if packet delivery fails due to any node becoming faulty.\
    \ In fact, such\ntopologies have been used in smart homes [77] as well as in smart\
    \ grids [78]. There are\nother topologies which have not been mentioned, for,\
    \ e.g., tree (which has multiple\nstar networks connected in a point by point\
    \ fashion).\n3.4.2\nNetwork Architectures\nNetwork Architecture refers to the\
    \ structure of the network used for a given appli-\ncation. As discussed earlier,\
    \ the ‘things’ in IoT may not necessarily be connected\nthrough the internet,\
    \ in fact a distributed connectivity structure may be imple-\nmented with only\
    \ one unit in the network being capable of sending data to the\ncloud depending\
    \ on the requirement. Work in [72] mentions three types of network\narchitectures\
    \ that are used for smart cities based on IoT. These are Home Area\nNetworks (HANs),\
    \ Wide Area Networks (WANs) and Field/Neighborhood Area Net-\nworks (FANs/NANs).\
    \ Home Area Networks are short range networks and are usually\nused to transmit\
    \ information to a central node which is responsible for data collection\nbefore\
    \ it is sent to the cloud. Communication within the network is performed using\n\
    some low power communication protocol such as Zigbee, Bluetooth, Wi-Fi etc. HANs\n\
    are very popular in smart homes where they are used to gather power consumption\n\
    and times of operation data from a multitude of appliances which are then sent\
    \ to\na smart meter as part of a smart grid [79]. The second type of network architecture\n\
    is Field Area Networks (FANs), sometimes also called Neighborhood Area Networks\n\
    (NANs). Field Area Networks have a larger communication range than HANs and\n\
    are used to provide connection between a customer (for, e.g., in a smart grid)\
    \ to the\nutility company. Wide Area Networks are used for network structures\
    \ that require\ncommunication over large distances. These networks are not as\
    \ dense as HANs or\nFANs and utilize technologies such as cellular services, wired\
    \ connections such as fiber\noptics as well as a class of low power protocols\
    \ designed for WANs themselves [80].\nWANs are used in a variety of smart city\
    \ applications including Smart Grids where\nthey are used to connect multiple\
    \ substations together or exchanging data between\nthe customer and the substation\
    \ [81].\n19\n3.4.3\nNetwork Protocols\nThe type of network to use depends on the\
    \ requirements of the application. It is\nimperative that the communication protocol\
    \ used in a smart city application meet\nthe desirable quality of service (QoS).\
    \ Several protocols have been used in the internet\nof things for smart cities\
    \ [48, 82, 83, 84], herein, we discuss the traits of the most\npopular wireless\
    \ networking protocols used in smart cities.\n3.4.3.1\nRFID\nRadio Frequency Identification\
    \ (RFID) utilizes radio frequencies\nto transmit and receive data. RFID communication\
    \ consists of two types of devices,\none device is the Reader and the other is\
    \ called the Tag. The Reader is usually\npowered and once a tag comes in the vicinity\
    \ of the reader, an exchange of information\ntakes place after authorization as\
    \ the tag harvests the energy from the reader. Such\ntags are called passive tags,\
    \ there are also active tags which are do not depend on the\nreader for their\
    \ power. Depending on the standard, RFID can operate on different\nfrequencies\
    \ in the radio frequency spectrum between 125 KHz to 928 MHz and can\nbe used\
    \ over short ranges. They are used in applications such as smart transport\n(toll\
    \ tax collection, parking), smart health and more.\n3.4.3.2\nNear Field Communication\n\
    Near Field Communication (NFC) is very\nsimilar to RFID, however, the structure\
    \ of NFC communication doesn’t consist of\ntags and readers. Unlike RFID, both\
    \ devices which want to communicate using NFC\nneed to be powered and data tranmission/reception\
    \ can take place in both directions\nunlike RFIDs. This enables the use of NFC\
    \ to control and configure devices unlike the\nRFID which cannot be used for measurement\
    \ or control tasks. NFC utilizes similar\nfrequencies to RFID but is used for\
    \ very short distances. NFC devices are popular\nfor applications involving payment\
    \ using smart phones and are also used in smart\nhomes.\n3.4.3.3\nBluetooth\n\
    Bluetooth is a low energy protocol popular in IoT applica-\ntions as it can support\
    \ an unlimited number of nodes [82]. The protocol is designed\nfor short range,\
    \ low bandwidth communication in an arrangement where devices can\neasily exit\
    \ or enter the network. Bluetooth natively supports the star topology as it\n\
    has a master device at the center of the communication mechanism. It operates\
    \ in\nthe 2.4 GHz ISM band and can have maximum data rates of 2 Mbps. Bluetooth\
    \ has\nbeen widely used in smart home due to it providing a direct connection\
    \ interface to\nsmart phones without the need for any intermediary hub device.\n\
    3.4.3.4\nZ-Wave\nZ-Wave or Zensys wave is a low power protocol developed to\n\
    be used in home automation applications. It is a low speed protocol with a short\n\
    range, operating in the frequencies of 868 MHz and 900 MHz. It operates in a master\n\
    slave fashion where a master can have multiple slave devices which can respond\
    \ to\ncommands from the master node. Therefore this is well suited for applications\
    \ where\na central control element is present and needs to gather data from multiple\
    \ sensing\nunits such as smart homes and smart healthcare systems.\n20\n3.4.3.5\n\
    Li-Fi\nLi-Fi (Light Fidelity) uses visible light instead of radio frequency\n\
    (RF) to exchange data. The advantage with using Li-Fi over RF communication is\n\
    that it can utilize already present lighting systems which also results in conservation\n\
    of power [85]. It offers very high speeds of data transfer for short distances\
    \ and has\nbeen used in parking systems.\n3.4.3.6\nWi-Fi\nWi-Fi (Wireless Fidelity)\
    \ operates using wireless frequencies in the\n2.4 GHz and 5 GHz bands to provide\
    \ high speed internet connectivity in a limited\ndistance. Wi-Fi is popular in\
    \ many smart city applications as it provides ready to\nuse interface to smart\
    \ phones, computers and other wearable gadgets.\n3.4.3.7\nZigbee\nThe ZigBee protocol\
    \ was developed as a low power low cost pro-\ntocol for wireless sensor networks\
    \ (WSNs) and has evolved to be used in the Internet\nof Things. The ZigBee protocol\
    \ operates in the 868 MHz/915 MHz/2.4 GHz band\nand offers moderate data transfer\
    \ speeds with distances similar to Wi-Fi in a multi-\nhop data transfer scheme.\
    \ Zigbee radios are low cost devices and therefore it is a\npopular protocol used\
    \ by many manufacturers of smart home, smart healthcare de-\nvices. A ZigBee network\
    \ will have three devices, one called the coordinator which\nis the controller\
    \ of the network, the router which is responsible for moving data to\nother devices\
    \ and the ZigBee end device (sensors and actuators).\n3.4.3.8\nWi-SUN\nThe Wireless\
    \ Smart Utility Network (Wi-SUN) is a network\napproved by Institute of Electrical\
    \ and Electronic Engineers (IEEE) and is used in\nfield area networks for utility\
    \ metering, automation of distribution for utilities such\nas electricity, gas\
    \ etc. and also for demand response systems for utility-based appli-\ncations.\
    \ It supports IPv6 addressing and can be used in star or mesh configuration\n\
    where it also allows for multi-hop communication [86].\n3.4.3.9\nCellular\nCellular\
    \ technologies refers to 3G, 4G and 5G communications.\nAlong with Bluetooth and\
    \ Zigbee, they are the most popular IoT enabling technolo-\ngies. Cellular communication\
    \ provides high data rate and supports more content rich\napplications compared\
    \ to the other protocols. With the long range they provide, they\nare preferred\
    \ for a variety of applications where power is not an issue. Depending on\nthe\
    \ technology, cellular bands range from 600 MHz to 80 GHz with very high data\n\
    rates.\n3.4.3.10\nLoRaWAN\nLoRaWAN stands for Long Range Wide Area Network (Lo-\n\
    RaWAN) and it is a Low Power Wide Area Network (LPWAN) that consists of several\n\
    gateways and multiple end devices with the gateways connected to a back-end net-\n\
    work server. The back-end server provides connection to the cloud. End devices\
    \ do\nnot have a fixed association with a specific gateway and may send data to\
    \ multiple\ngateways when it needs to transfer data to the cloud.\n21\n3.4.3.11\n\
    6LoWPAN\n6LoWPAN which is short for IPv6 over Low Power Net-\nworks was created\
    \ by the Internet Engineering Task Force (IETF) specifically for\ninternet of\
    \ things applications with the aim of making it possible for providing in-\nternet\
    \ connectivity to small devices. It is an IP based network and leverages IPv6\n\
    communication. This is a short-range network operating in Industrial, Scientific\
    \ and\nMedical (ISM) bands.\n3.4.3.12\nSigFox\nSigFox is a proprietary standard\
    \ developed by SigFox Inc., France.\nIt uses unlicensed bands to perform ultra-narrowband\
    \ bidirectional communication\nwith low speeds [87]. SigFox has a similar architecture\
    \ to LoRaWAN and like Lo-\nRaWAN and 6LoWPAN, SigFox is a popular LPWAN in the\
    \ IoT domain offering\nsufficiently large distances of communication of up to\
    \ 50 km. SigFox finds applica-\ntions in security in buildings, smart lighting\
    \ and environmental monitoring.\n3.4.3.13\nNB-IoT\nNB-IoT (Narrow Band IoT) is\
    \ a type of LPWAN which oper-\nates on Global System for Mobile Communications\
    \ (GSM) and Long-Term Evolution\n(LTE) bands. In fact, it can operate using the\
    \ same hardware with a software up-\ngrade as it is considered a bare bones version\
    \ of LTE. It allows for connecting up to\n100,000 devices per cell.\nTable 4.\
    \ Comparison of Network Technologies for IoT Smart Cities\nArchitecture\nTechnology\n\
    Frequency/Medium Data rate\nRange\nTopology\nHome\nArea\nNet-\nworks (HANs)\n\
    NFC\n125\nKHz,\n13.56\nMHz/860 MHz\n106 Kbps, 212\nKbps or 424\nKbps\n10 cm\n\
    Point to Point\nRFID\n125\nKHz,\n13.56\nMHz/902-928 MHz\n4 Mbps [82]\n3 - 10 m\n\
    Point to Point\nLi-Fi\nLED Light\n1 – 3.5 Gbps\n[85]\n10 m\nPoint\nto\npoint,\n\
    Star,\nMesh\nBluetooth\n2.4 GHz\nUp to 2 Mbps\n240 m\nStar\nZ-wave\n868 MHz/900\
    \ MHz\n40-100 Kbps\n30 – 100 m\nMesh\nZigbee\n868\nMHz/915\nMHz/2.4 GHz\n250 Kbps\n\
    Up to 100 m\nMesh,\nStar,\nTree\nWi-Fi\n2.4 GHz/5 GHz\n54 Mb/s, 6.75\nGb/s\n140\
    \ m , 100 m\nTree\n6LOWPAN\n[82]\n868\nMHz/915\nMHz/2.4 GHz\nUp\nto\n250\nKbps\n\
    10 - 100 m\nMesh, Star\nField/Neighborhood\nArea\nNetworks\n(FANs/NANs)\nWi-SUN\n\
    868\nMHz/915\nMHz/2.4 GHz\nUp\nto\n300\nKbps\nUp to 4 Km\nStar, Mesh\nWide\nArea\n\
    Net-\nworks (WANs)\nNB-IOT\nLicensed LTE bands\n200 Kbps\n1 - 10 Km\nTree\nLoRaWAN\n\
    433\nMHz/868\nMHz/915 MHz\n50 Kbps\n5 - 20 Km\nStar\nof\nStar\n(nested star)\n\
    Sigfox\n433\nMHz/868\nMHz/915 MHz\n100 bps\n10 – 50 Km\nOne hop star\n3G\n1.8\
    \ – 2.5 GHz\n2 Mbps\n-\nTree\n4G\n600 – 5.925 GHz\nup to 1 Gbps\n-\nTree\n5G\n\
    600 - 80 GHz\nUp to 20 Gbps\n-\nTree\n22\nHome Area \nNetworks (HANs)\nNFC\nRFID\n\
    Li-Fi\nBluetooth\nZ-Wave\nZigbee\nWi-Fi\n6LoWPAN\nField/ Neighborhood \nArea Networks\
    \ \n(FANs/NANs)\nWi-SUN\nWide Area Networks \n(WAN)\nNB-IoT\nLoRaWAN\nSigFox\n\
    Cellular\ndistance\n1 Km\n10 Km\n100 Km\nFigure 5. Network Technologies for IoT\
    \ Smart Cities.\n3.5\nSecurity and Privacy in Smart City IoT\nSmart Cities involve\
    \ the transmission of sensing data, control information through\nthe internet\
    \ as well as local networks. Moreover, several components in smart cities\ntend\
    \ to critical aspects of a citys operation and are highly intertwined with the\
    \ social\nand private life of its citizens. Consequently, security and privacy\
    \ in Smart Cities\nis of great importance and has been of high interest to researchers\
    \ [51, 88, 89, 90,\n91, 92]. The topic of Security of IoT has been covered in\
    \ [93] who deliberate upon\nthe challenges faced in the different architectures\
    \ of the IoT and present issues and\nsolutions. We cover security for IoT in smart\
    \ cities so as to highlight issues that are\npertinent to in the Smart City context\
    \ and to complete our discussion on this topic.\nSmart Cities are enabled by collecting\
    \ data through sensors within a city as well\nas its populace, process it and\
    \ then mine it to provide a better quality of life to the\npeople living. These\
    \ sensors can provide an estimate about the internal state of a\ncity’s components\
    \ such as transportation, power system, building condition/state,\nhuman mobility\
    \ and more. All of this data is sent to the cloud where it is processed\nand mined.\
    \ However, there are several issues that pertain to how these data are\nsent and\
    \ used and raises questions about integrity, protection and the confidentiality\n\
    23\nAttackers\nHackers\nSpies\nTerrorists\nCorporate \nRaiders\nProfessional \n\
    Criminals\nVandals\nVoyeurs\nTool\nPhysical \nAttack\nInformation \nExchange\n\
    User \nCommand\nScript or \nProgram\nAutonomous \nAgent\nToolkit\nDistributed\
    \ \nTool\nData Tap\nVulnerability\nDesign\nImplementation\nConfiguration\nAction\n\
    Probe\nScan\nFlood\nAuthenticate\nBypass\nSpoof\nRead\nCopy\nSteal\nModify\nDelete\n\
    Target\nAccount\nProcess\nData\nComponent\nComputer\nNetwork\nInternetwork\nUnauthorized\
    \ \nResult\nIncreased \nAccess\nDisclosure of \nInformation\nCorruption of \n\
    Information\nDenial of \nService\nTheft of \nResources\nObjectives\nChallenge,\
    \ \nStatus, Thrill\nPolitical Gain\nFinancial Gain\nDamage\nGovernments\nBusiness\n\
    Consumers\nTransport \nSystems\nUtilities\nCity \nAdministration\nSocial Panic\
    \ / \nUnrest\nBusiness Trust \nManipulation\nFigure 6. Modified CERT Attack Taxonomy\
    \ for Smart Cities.\nof this process. In fact, this concern is not unwarranted\
    \ for, in 2015 an attack on\nthe Ukranian power grid which left 225,000 people\
    \ without power [94] opened the\nworlds eyes to the very real threat posed by\
    \ cyber attackers. Data gathered in Smart\nCity applications can be used to perform\
    \ many undesired acts, GPS devices that are\npresent in every phone and most vehicles\
    \ are susceptible to providing information\nabout a persons location, habits as\
    \ well as lead to privacy issues as discussed in [91],\npower consumption and\
    \ ambient sensor data from a building may indicate to occu-\npancy [95] and even\
    \ indicate to the individual identities [96]. This information may\nbe used by\
    \ bad actors to carry out unlawful acts causing risk to life and property.\nTo\
    \ secure the Internet of Things for Smart Cities, typical security schemes might\
    \ not\nbe as effective in many cases and new methods will need to be developed\
    \ to cope\nwith the security and privacy issues in IoT for Smart Cities. In order\
    \ to provide a\nstandardized framework and terminology for discussing security\
    \ attacks, we adapt the\nstandard attack incident taxonomy [97] suggested by the\
    \ Computer Emergency Re-\nsponse Team (CERT) which was established by Defense\
    \ Advanced Research Projects\nAgency (DARPA) for use towards IoT for Smart Cities.\
    \ This is shown in Figure 6.\nThere are different types of security and privacy\
    \ issues in IoT in Smart Cities,\nthey exist on each of the three levels of the\
    \ IoT architecture, application software\nlayers, network layer and the perception\
    \ layer along with some system wide issues, a\ndiscussion is provided for each\
    \ of them. Furthermore, Table 5 provides a summary\nof the security and privacy\
    \ issues in IoT for Smart Cities and the counter measures\nthat one can take to\
    \ mitigate them.\n3.5.1\nApplication Software Layers\nApplication software layers\
    \ are comprised of the Middleware, Application and Busi-\nness Layers. Security\
    \ and privacy in the application software layers tend to issues\nrelating to storage\
    \ of data and its usage. These are data visibility, access and injec-\ntion.\n\
    24\n3.5.1.1\nData Visibility/Identification\nOnce data is gathered, it is sent\
    \ to the\ncloud where it is stored and mined to make inferences. Since the cloud\
    \ would be used\nby multiple entities with different standards of security protocols\
    \ and practices, it is\nextremely important that data stored in the cloud is encrypted\
    \ so as not to allow its\nexposure to unwanted entities. Any data stored in plain\
    \ form would be a risk to not\nonly user privacy but also company rapport.\n3.5.1.2\n\
    Data access/Secondary Use\nAccess control is also a major issue in\nsmart city\
    \ data. Most Smart City applications rely on the usage of data from different\n\
    applications to provide smart services, thus resulting in the gathered data to\
    \ be used\nby many different enterprises. To allow this to take place smoothly\
    \ while preserving\nprivacy, suitable access control schemes will need to be devised\
    \ to allow for responsible\naccess to users of this data. A well-defined hierarchy\
    \ of data users will need to be\ndeveloped and implemented to limit access only\
    \ to intended authorized personnel.\nInformation flow control should also be employed\
    \ that can track data flow as access\nto it is made and to detect any violation\
    \ of access or usage rules. Moreover, data\nmashups that will occur in the cloud\
    \ where multiple entities merge their data to\nwork on some common goal, should\
    \ be carried out with proper oversight.\nData\nanonymization may also be required\
    \ in such a scenario where specific values may be\nconverted in to a range perhaps\
    \ ( e.g., using k-anonymity [90]) and unwanted data be\ndeleted as necessary.\
    \ Blockchain has been suggested to be used for access control as\nwell as access\
    \ tracking of users in IoT applications where each user access to a service\n\
    or an application ends up as a transaction to form the applications IoT trail\
    \ [98].\n3.5.1.3\nData Injection/Data Integrity\nData injection refers to the\
    \ injection\nof false information or modification information about a user in\
    \ the system after\ngaining access. Since data is typically stored in databases,\
    \ SQL injection involves\nan attacker inserting queries to modify data or make\
    \ false data insertions into the\ndatabase. This can have far reaching consequences\
    \ for smart city applications such\nas patient record manipulation as well as\
    \ manipulation or deletion of government\nrecords. SQL injection prevention schemes\
    \ involve the validation of data before using\nit [99] such as positive pattern\
    \ matching. It also involves limiting database access\nbased on the user requirements\
    \ and performing penetration testing.\n3.5.2\nNetwork Layer\nLike other networks,\
    \ the IoT in Smart Cities are also susceptible to network attacks\nsuch as Denial\
    \ of service, Eavesdropping, Man in the middle attack, Side Channel\nand spoofing\
    \ attacks [100]. We discuss these attacks and discuss remedial actions\nthat should\
    \ be taken to prevent them.\n3.5.2.1\nMan in the Middle Attack\nMan in the middle\
    \ (MITM) attack refers\nto the interception of data on the network by faking the\
    \ identity of a network node\nor device. This is carried out by appearing as the\
    \ intended recipient to the sender\n25\nand the original sender to the recipient\
    \ by unauthorized actors. To prevent this,\nthe exchange of data between two entities\
    \ should employ cryptographic protocols\nwhich can ensure secure communication.\
    \ Many public networks do not make use of\nencryption when exchanging data, this\
    \ endangers user data and can give access to\nunwanted persons to user information\
    \ [90]. Policies need to be devised to allow for\nsuitable data communication\
    \ standards for such networks while keeping the user as\nwell as commercial interests\
    \ in mind.\n3.5.2.2\nEavesdropping/Sniffing Attack\nEavesdropping refers to the\
    \ listening\nof data on the network. In eavesdropping an unauthorized entity joins\
    \ the network\nand can listen to the data that is being exchanged between the\
    \ devices on the network.\nTo avoid this, strategies include the use of authenticate\
    \ always protocols which initiate\nauthentication steps whenever devices need\
    \ to communicate with each other. This will\nensure that no unwanted users are\
    \ allowed access to network traffic to prevent such\nattacks. Moreover, industry\
    \ standard security protocols such as the Transport Layer\nSecurity (TLS), Wi-Fi\
    \ Protected Access 2 (WPA2) should be used for authenticating\nremote access.\
    \ Furthermore, remote sessions should have time-outs implemented to\nensure that\
    \ mistakes are not made by forgetful employees.\n3.5.2.3\nSide Channel Attack\n\
    Side Channel Attacks refer to the extraction\nof information by observing operation\
    \ characteristics of the implemented computer\nalgorithms or systems such as power\
    \ consumed, time taken, traffic analysis, fault\nanalysis, acoustic analysis [101].\
    \ Side Channel attacks don’t give nonpermitted parties\naccess to the data within\
    \ the network but may allow them to determine important\ninformation about the\
    \ system, such as the protocol used, or allow them to drop\npackets so as to degrade\
    \ performance of the network. One solution to counter network\ntraffic side channels\
    \ attacks is to saturate network bandwidth to prevent patterns\nfrom being observed.\
    \ Another popular method of preventing side channel attacks is\nto make use of\
    \ masking [102].\n3.5.2.4\nDenial of Service Attack\nDenial of Service (DOS) or\
    \ Distributed DOS\n(DDOS) attacks involve an entity getting access to the network\
    \ and using legitimate\nnodes within it to flood the target with unnecessary requests\
    \ to consume network\nbandwidth and degrade quality of service. With a smart city\
    \ depending on sensors\nto provide it with a ‘view’ of the city, DOS attacks can\
    \ make the smart city system\nblind which can lead to loss of property and life.\
    \ Countermeasures for DOS attacks\ninvolve anomaly detection by monitoring of\
    \ network data to check for any irregular\nbehavior. Artificial Intelligence has\
    \ found applications in this area as noted by [103],\nfor, e.g., it has been used\
    \ to identify abnormal data in smart grids [104] as well as\ndetecting attacks\
    \ [105, 106].\n3.5.2.5\nSpoofing Attack\nIn a spoofing attack, an attacker adds\
    \ itself to the\nnetwork by appearing to be a legitimate device on the network,\
    \ thereby allowing\nthem to send irregular or abnormal data to upset normal operation\
    \ of a smart city\n26\nsystem. Due to the varying nature and types of IoT devices\
    \ having different levels of\nbuilt-in security, spoofing is a particularly dangerous\
    \ attack for IoT systems. Methods\nto prevent spoofing are the use of cryptography,\
    \ hybrid encryption [107] as well as the\nuse of blockchain [108] to validate\
    \ data exchange and as well as authenticate devices.\n3.5.3\nPerception Layer\n\
    Perception layers attacks refer to physical attacks on an IoT based smart city\
    \ system.\nThis requires the physical presence of an attacker near the sensing\
    \ elements in an IoT\nsystem. We cover these attacks to provide a holistic assessment\
    \ of the security and\nprivacy issues in IoT Smart Cities. Tempering and Radio\
    \ Interference (jamming)\nare attacks which can affect the performance of smart\
    \ city systems. Tempering may\noccur during the development or the manufacturing\
    \ process while jamming can take\nplace due to a generation of radio frequencies\
    \ which interfere with the frequencies\nused by devices on the network to exchange\
    \ data. To circumvent this, policies may\nbe incorporated into software which\
    \ alert businesses and other Smart City partners\nto missing or abnormal data\
    \ from sensing devices.\n3.5.4\nSystem Wide Issues\n3.5.4.1\nData Leakage\nData\
    \ leakage refers to the unintentional conveyance of\ninformation about subjects\
    \ in smart cities. The many data sources in smart cities\nmay contain information\
    \ related to a user’s identity, health, quality of life etc. Smart\nCity application\
    \ managers use this data to improve their services and provide a bet-\nter user\
    \ experience, however, it is possible that this data might be shared with third\n\
    party entities. It is therefore necessary to anonymize data before such assignments\n\
    are taken. Data leakage can also take place when devices within a network perform\n\
    discovery tasks and may provide personal information to rogue nodes in the network.\n\
    In Smart Grids, power consumption data should be anonymized by considering the\n\
    data on a neighborhood level rather than on the individual level, moreover, systems\n\
    could be installed in homes using batteries to modify the demand response signal.\n\
    Data aggregation is an important tool in preserving individual privacy and preventing\n\
    data leakage. Moreover, data should be encrypted when sending it over the network\n\
    so that any unauthorized access is avoided. Another strategy would be to use data\n\
    minimization. Typically, sensors used in smart cities will gather data of less\
    \ ‘interest’\nin addition to data of interest. For, e.g., navigation systems many\
    \ times record loca-\ntion information even when not in use or video applications\
    \ such as facial recognition\nsystems typically record other activities apart\
    \ from being activated whenever a face is\nobserved in the video. This extra information\
    \ increases the risk of data leakage. Data\nminimization can be employed in such\
    \ cases to limit the data that is being gathered\non the user.\n3.5.4.2\nTrustworthiness\n\
    Apart from the technical steps that need to be taken\nto provide a secure usage\
    \ experience of smart city applications and to encourage its\nuse, it is important\
    \ that smart city users be provided clear policy guidelines to how\n27\nTable\
    \ 5. Security and Privacy issue for IoT Smart Cities\nLayer\nIssue\nCountermeasure\n\
    Application\nSoftware\nLayers\nData\nvisibility/Identifica-\ntion\n- Use of encryption\
    \ to store data\n(Middleware,\nApplica-\ntion and Business)\nData access/Secondary\
    \ use\n- Access control schemes based on user hi-\nerarchy\n- Data anonymization\
    \ be employed\n- Use of blockchain for tracking user access\nData\ninjection/Data\n\
    in-\ntegrity\n- Use of data validation before usage\n- Limiting data access\n\
    - Query parameterization\n- Penetration testing\nNetwork Layer\nMan in the middle\
    \ attack\n- Use of cryptographic protocols for data\nexchanges\n- Encrypting data\
    \ on public networks\nEavesdropping/Sniffing\nat-\ntack\n- Use always authenticate\
    \ protocols\n- Remote access should use industry ac-\ncepted protocols such as\
    \ TLS, WPA2\n- Timeouts for remote sessions\nSide channel attacks\n- Bandwidth\
    \ saturation\n- Masking to prevent similar operational\npatterns\nDenial of Service\n\
    - Check irregular data requests (AI has\nbeen shown to be of use here)\nSpoofing\
    \ attacks\n- Use of cryptography\n- Use of hybrid encryption\n- Use blockchain\
    \ to validate data exchange\nas well as authenticate devices\nPerception Layer\n\
    Tempering and Jamming\n- Software policies for missing data\nSystem Wide\nData\
    \ leakage\n- Data anonymization\n- Data minimization\n- Data aggregation\nTrustworthiness\n\
    - Provide clear policy guidelines to users\n- Flexible policy development in consulta-\n\
    tion with users\ncompanies providing them these services will manage their data.\
    \ Transparency in this\nregard will help increase user trust and the feedback\
    \ will enable companies to develop\nbetter data privacy mechanisms. Another way\
    \ trust could be developed would be for\nthe companies to provide customers who\
    \ are vary of data collection, certain options\nin policies where they could choose\
    \ which parts of the data collection are acceptable\nto them and which aren’t.\n\
    4\nSWOT Analysis\nTo complete this discussion, we perform a Strength Weaknesses\
    \ Opportunities Threat\n(SWOT) analysis on the use of IoT for Smart Cities that\
    \ discusses the strengths that\nIoT offers for Smart cities, the weaknesses in\
    \ the current implementation scenario,\nthe opportunities which exist for future\
    \ work in this area as well as the threats that\nIoT application to smart cities\
    \ faces, a summary of our discussion has been given in\n28\nTable 6. SWOT Analysis\
    \ for IoT in Smart Cities\nPositive\nNegative\nStrengths\nWeaknesses\nInternal\n\
    - Sustainable living\n- Lack of data control policies\n- Improved quality of life\n\
    - Laws need to be developed\n- Efficient city operations\n- Interoperability of\
    \ networks\n- Well suited for big data algorithms\n- Incompatible sensor standards\n\
    - Scalability of applications\n- Myriad of different application\nframeworks\n\
    - Real-time/fast response due to distributed IoT\nstructure\n- Reduced costs\n\
    - Robustness\n- Enable heterogenous system connectivity\nOpportunities\nThreats\n\
    External\n- Development of new sensor technologies.\n-\nTrustworthiness\nissues\n\
    among\nusers\n- Development of low power and higher speed com-\nmunication schemes\n\
    - Network attacks\n- Development of Encryption techniques for stor-\nage and data\
    \ exchange\n- Data theft\n- Development of Data processing for privacy\npreservation\
    \ techniques\n- Data leakage\n- Development of new city services\n- Development\
    \ of scalable, explainable AI\nTable 6.\n4.1\nStrengths\nIoT smart city strengths\
    \ are the fact that they provide an improved quality of life for\na city’s population\
    \ along with reduction of costs in terms of operation and also enable\ncities\
    \ to be sustainable. IoT enables sensors and devices to be deployed throughout\
    \ a\ncity to give an overview of the state of the city’s main functions such as\
    \ transportation\nsystems, electric, water and gas distribution as well as crime\
    \ monitoring to name\na few. This real time information helps city administration,\
    \ businesses and other\nstakeholders to provide better services to people, increase\
    \ the effectiveness of those\nservices and reduce the cost through efficient operation.\n\
    On the technical side, IoT data has made possible to use data analytics to gauge\n\
    various aspects of the multitude of services which are being provided in the city\
    \ as\nwell as to determine interactions between them and utilize that information\
    \ for better\ndecision making to make life easier for citizens. Furthermore, the\
    \ distributed nature\nof IoT systems and the flexible architectures which enable\
    \ fluidity through movement\nof sensing units is easily scalable thereby requiring\
    \ little additional cost to upgrade\nand expand currently deployed systems. Moreover,\
    \ this distributed architecture also\nmakes such systems very robust to faults\
    \ thereby increasing reliability of deployments\nand offering self-healing in\
    \ applications such as electricity systems.\n29\n4.2\nWeaknesses\nIoT in Smart\
    \ cities do suffer from some weaknesses in terms of technology, for, e.g.,\nthe\
    \ current deployment scenario has a myriad of different technologies relating\
    \ to\nnetworks, hardware platforms and software frameworks which do not often\
    \ work to-\ngether very well as discussed. Different standards’ bodies such as\
    \ the IETF, European\nTelecommunications Standards Institute (ETSI), IEEE and\
    \ other organizations have\nbeen contributing with standards for communication,\
    \ network discovery, identifica-\ntion, management of devices etc. However, the\
    \ sheer number of ‘standards’ with\nmany of them not being compatible with each\
    \ other has not fully solved the inter-\noperability problem and this can cause\
    \ hurdles for expansion of IoT systems without\na significant overhaul of system\
    \ components. Another problem currently facing IoT\nsystems is the lack of data\
    \ policies and legislation. The concern here is that data\npolicies are not mature\
    \ enough to regulate how data is handled in IoT systems, as\nhas been discussed\
    \ previously. This is a major problem given the growing issue with\nuser data\
    \ privacy in a connected world.\n4.3\nOpportunities\nIoT in Smart cities presents\
    \ many opportunities to researchers and businesses alike\nin lieu of mitigating\
    \ the weaknesses and also in the provision of new city services.\nThe data gathered\
    \ by the sensors in IoT systems has the potential to provide a\nholistic overview\
    \ of the city’s state allowing for the use of big data algorithms to\ndevelop\
    \ new applications and services. For researchers in the data analytics domain,\n\
    this heterogenous data provides a wonderful opportunity for the development of\
    \ new\ndata science algorithms for service delivery. There is a large monetary\
    \ value towards\nthe development and usage of computationally cheap encryption\
    \ techniques, efficient\ndata storage methods and networking technologies to make\
    \ IoT deployment easier\nand cheaper.\nDevelopment of new sensor technologies\
    \ is another opportunity for\nresearchers in IoT for smart cities.\nThe development\
    \ of newer, efficient, low-cost\nsensors would aid to the creation of IoT services\
    \ and enable even wider usage.\n4.4\nThreats\nWith a connected system, there are\
    \ several threats that come with IoTs for Smart\nCities involving trust issues\
    \ among users, privacy concerns due to network attacks,\npotential data theft\
    \ etc. Privacy and security are the most important concerns of\nIoT applications,\
    \ with such a personalized interaction mechanism between people\nand devices as\
    \ is the case of smart cities, the risks for privacy breaches, data theft\nand\
    \ leakages are high and this is a constant concern for service users as well as\n\
    providers. Numerous attacks on Smart City systems have exposed the vulnerability\n\
    of this technology to cyber attacks and also demonstrated the consequences that\
    \ it\nhas on the population. Traditional security procedures and methods such\
    \ as access\nauthentication, routing and networking might not be enough or possible\
    \ in many IoT\ndeployments due to IoT devices typically not having sufficient\
    \ computing capabilities,\n30\nthis has exacerbated the privacy and security concerns\
    \ for IoT stakeholders. This can\nalso feed to a lack of trust by customers to\
    \ participate in smart city applications.\n5\nConclusions\nThis chapter presented\
    \ a broad coverage of the Internet of Things in Smart Cities.\nProviding a detailed\
    \ discussion of Smart Cities and its different domains, IoT was\npresented as\
    \ a vital enabler of smart city services and the various smart city architec-\n\
    tures and the challenges that are faced in the deployment of smart city applications\n\
    were deliberated upon. This was followed by a review of the sensing and networking\n\
    technologies used for such applications Finally, the security and privacy issues\
    \ faced\nby IoT based Smart Cities were discussed and a SWOT analysis is provided.\n\
    31\nCHAPTER III\nAI IN IOT SMART CITIES\n1\nIntroduction\nThis chapter provides\
    \ insight into different ways in which AI has been applied in\nthe IoT for Smart\
    \ Cities using the application of clustering, regression, classification\netc.\
    \ In addition, various applications, solutions and data used for implementing\
    \ the\noverall framework of Smart Cities are discussed in detail. along with the\
    \ types of\ndeployment used by these proposed approaches.\n2\nBig Data Algorithms/Artificial\
    \ Intelligence\nThe various sensors that make up the internet of things in a smart\
    \ city relay in-\nformation about the city’s state to the cloud. However, measuring\
    \ raw data is not\nenough, to utilize this data and to make the city ‘smart’,\
    \ data analysis is key. Data\nanalysis in smart cities has four layers, the first\
    \ is Data Acquisition, which deals with\nthe collection and storage of data, this\
    \ is followed by the Preprocessing layer which\nperforms operations (such as imputing\
    \ missing values, scaling, removing erroneous\ndata points etc.) on the data to\
    \ ensure that data is of suitable quality to be used for\nthe data analytics stage.\
    \ The data analytics stage involves the application of data\nscience techniques\
    \ on the data to extract patterns and insights which would be used\nfor policy\
    \ making, planning and other actions in the Service layer. In this section, we\n\
    focus our attention on the third stage of the data analysis process, i.e., data\
    \ analytics.\nData analytics in the Smart City based on the IoT involves the use\
    \ of Deep Learning\nand Machine Learning on the gathered data. The discussion\
    \ in this chapter considers\nthe following aspects of the use of AI (ML/DL) in\
    \ the IoT for smart cities:\n1. The type of application: This refers to the aim\
    \ of the application.\n2. Algorithm/Network: This refers to the algorithm being\
    \ used to perform the\ntask and can be any of the ML/DL algorithms covered.\n\
    3. System Architecture: System architecture refers to the IoT architecture pro-\n\
    posed for the covered work. This can be Cloud, Fog or Edge.\n4. Task: This refers\
    \ to the type of machine learning task being performed. This can\nbe classification,\
    \ clustering or regression. In this category, a brief description is\nalso presented\
    \ about what quantities/outcomes are being worked with.\n32\n5. Data Type: This\
    \ refers to the type of data being used. Data can be of two\ntypes, heterogeneous\
    \ or homogeneous. Heterogeneous refers to the use of data\nof different modalities\
    \ whereas homogenous refers to a single modality being\nused. The aim of providing\
    \ this information is to capture the complexity of the\ndata involved in an application.\n\
    2.1\nMachine Learning\nMachine learning (ML) has been a crucial element of smart\
    \ city application develop-\nment [109], helping in prediction (classification),\
    \ estimation (regression) and cluster-\ning tasks. Machine learning refers to\
    \ the set of approaches through which computers\ncan be used to learn from empirical\
    \ data [110] and has been used in smart cities\nin various applications. Since\
    \ there has been a lot of work in this area using ML\nalgorithms, we focus on\
    \ work in the last few years. It was found that most commonly\nused ML algorithms\
    \ have been the Support Vector Machine (SVM), Random Forests\n(RF), Decision Tree\
    \ (DT), Naive Bayes (NB), K-Means, K-Nearest Neighbor (K-NN)\nand Logistic Regression\
    \ (LR).\n2.2\nDeep Learning\nDeep learning is the use of successive layers of\
    \ Artificial Neural Networks (ANNs) to\nlearn patterns. The idea is that successive\
    \ non-linear layers of interconnected artificial\nneurons can be used to learn\
    \ patterns in data that simple machine learning algorithms\nmight not be able\
    \ to do. Deep learning architectures can process noisy data to provide\noutput\
    \ for classification and prediction tasks. This makes them very useful in the\n\
    Smart City environment where the IoT enables the collection of heterogeneous sensor\n\
    data which can be of varying nature. Data derived from sensors can be processed\
    \ to\nextract features or can be fed directly to deep learning algorithms which\
    \ can perform\nboth feature extraction as well as classification/prediction. Deep\
    \ Learning methods\nsuch as Recurrent Neural Networks (RNN)(Long Short-Term Machines\
    \ (LSTM) and\nGated Recurrent Units (GRU)), Convolutional Neural Networks (CNN),\
    \ Deep Neural\nNetworks (DNN) and Stacked Autoencoder Networks (SAE) were the\
    \ preferred deep\nlearning methodologies used for smart city applications and\
    \ our discussion revolves\naround the utilization of these methods.\n3\nAI Applications\
    \ for Smart Cities\nIn this section, the applications for of AI in smart cities\
    \ have been discussed, we also\nmention the kind of deployment as well as the\
    \ nature of data utilized to achieve their\ntask.\n3.1\nSmart Agriculture\nThe\
    \ major applications of AI in IoT for agriculture are crop monitoring/disease\
    \ de-\ntection and data driven crop care and decision making. Considering the\
    \ scarcity of\n33\nwater, the authors in [111, 112, 113] develop irrigation systems\
    \ which monitor and\ncontrol the amount of water being used for crops, all structured\
    \ around a cloud com-\nputing system. This problem has been devised both as a\
    \ classification as well as a\nregression problem as in [114], who develop a closed\
    \ loop water irrigation system using\nsupport vector regression and K-Means clustering.\
    \ The authors in [115, 116] propose\ncloud based greenhouse monitoring systems\
    \ using images and a host of physical pa-\nrameters from plants such as temperature,\
    \ humidity and light using several machine\nand deep learning methods. Plant disease\
    \ detection is also an important task within\nsmart agriculture and has been worked\
    \ on by the authors in [117, 118, 119, 120] who\npresent schemes for disease detection\
    \ for various crops including tomatoes and pota-\ntoes. The proliferation of sensing\
    \ systems in agricultural fields has also provided an\navenue for data driven\
    \ decision making and planning for farmers. This involves pre-\ndicting various\
    \ physical parameters which can affect crop growth like solar radiance\n[121]\
    \ and temperature, humidity, windspeed [122, 123, 124, 125, 126] to help in deci-\n\
    sion making in terms of plant care but also classification systems for recommending\n\
    crops to be sown [127, 128]. It is important to note that all of these implementations\n\
    are cloud based.\nThere have been some suggested methodologies for bringing fog\
    \ processing for AI\nin smart agriculture, for, e.g., in [129] a deep learning\
    \ entrusted to fog nodes (DLEFN)\nalgorithm is described to support efficient\
    \ use of resources and reduce cloud resource\nusage. However, as noted in [130],\
    \ who use an edge system for temperature prediction\nusing an LSTM, edge device\
    \ performance still lacks that of similar cloud systems but\nthe inclusion of\
    \ DL capable hardware does provide opportunities for further innova-\ntions. Previous\
    \ work by the same author [131], where they aimed to monitor crops\nfor frost\
    \ signs and trigger anti-frost measures, compared edge and cloud computing\nsystems\
    \ for outlier detection and determined that cloud implementations to provide\n\
    much better performance. However, they do note the potential for edge systems\
    \ to\nprovide highly responsive data analytics in smart agriculture. More applications\
    \ can\nbe envisaged for AI deployment in smart agriculture, for, e.g., monitoring\
    \ of crop\ngrowth, selection of the fertilizer and the timeline for it to be used\
    \ as well as targeted\napplication, pest detection and intelligent pesticide spraying\
    \ so as to reduce harm to\nthe environment, environmental monitoring to track\
    \ the effects of climate change and\nmore. Some of these applications have potential\
    \ to be deployed as edge computing\nsystems. A summary of the use of IoT based\
    \ AI in Smart Agriculture is presented in\nTable 7.\n3.2\nSmart City Services\n\
    A popular component of smart city initiatives is the management of waste and involves\n\
    having bins equipped with sensors and connected to the cloud to not only inform\
    \ the\nrelevant authorities of the need to empty them but also using AI to determine\
    \ the\nbest route to reduce fuel consumption. The use of IoT systems for waste\
    \ management\nhas been observed in the works of [133] who utilize IoT systems\
    \ to help reduce energy\nwastage in waste collection by municipalities. Hussain\
    \ et al. [134] develop a waste\nmanagement system that not only determines if\
    \ bins are full and need collecting\n34\nTable 7. AI use for Smart Agriculture\n\
    Application\nNetwork\nSystem\nAr-\nchitecture\nTask\nData type\nCrop\nMonitoring\n\
    /Plant care (Irriga-\ntion)\nLR [111]\nCloud\nClassification\n-\nDifferent\nstates\
    \ of crop [less water\netc])\nHeterogeneous\n(Temperature,\nSoil\nmoisture, Air\
    \ quality,\nSunlight etc)\nDT [113]\nCNN [112]\nClassification\n-\nDifferent\n\
    conditions of plants and soil\n[dry etc])\nHomogeneous\n(Im-\nages)\nSVR + K-Means\
    \ [114]\nRegression\n-\nPredicting\namount of moisture in soil\nHeterogeneous\n\
    (Soil moisture,\nSoil\ntemperature,\nAir\ntemperature,\nUltra-\nviolet\n(UV)\n\
    light\nradiation,\nRelative\nhumidity,\nWeather\nforecast data)\nCrop\nMonitoring\n\
    /Plant\ncare\n(Mon-\nitoring\nand\ndisease\ndetection)\nSVM [115]\nCloud\nRegression\n\
    -\nForecasting\ntemperature\nHeterogeneous (Tem-\nperature,\nHumidity,\nLight,\
    \ Soil moisture)\nSVM [118]\nRegression\n-\nDaily\ncrop\ngrowth\n(indirectly\n\
    from\nmeasured data)\nSVM [117]\nClassification\n–\nDifferent\ncrop conditions\n\
    Heterogeneous\n(Im-\nages, Gas)\nSVM + K-Means + CNN\n[116]\nClassification\n\
    -\nDifferent\nstages of tomato growth\nHomogeneous\n(Im-\nages)\nSVM [119]\nClassification\
    \ - Recognizing\nand detecting disease\nCNN [120]\nEdge\nData driven crop care\n\
    and decision making\n(Predicting\nphysical\nparameters)\nCNN + RNN(GRU) [122]\n\
    Cloud\nRegression - Prediction of\nTemperature, Humidity and\nWind speed\nHeterogeneous\
    \ (Tem-\nperature,\nHumidity,\nWind\nspeed,\nLoca-\ntion\nof\nmonitoring\nstation,\
    \ Time, Rain-\nfall, Solar radiation)\nRFC[126]\nRNN (LSTM) [123]\nDNN [125]\n\
    RNN (GRU) [124]\nDNN [121]\nRegression - Prediction of\nsolar radiance\nRNN (LSTM)\
    \ [132]\nEdge /Cloud\nRegression\n-\nTemperature\nforecasting\nData driven crop\
    \ care\nand decision making\n(Crop\nrecommenda-\ntion)\nDT [127]\nCloud\nClassification\n\
    -\nDifferent\ncrops\nHomogeneous (Tem-\nperature)\nDT [128]\nClassification -\
    \ Soil fertility\nand type, Regression - Pre-\ndiction of soil toxicity\nHeterogeneous\n\
    (Soil\nmoisture,\nTemper-\nature,\nHumidity,\nPH,\nSoil\nnutrient\ncontent/fertility)\n\
    35\n(using data from various sensors placed in the bin) but also predicts the\
    \ air quality\naround it using RNNs. The sensing modalities in each of these applications\
    \ is pretty\nsimilar in that they indicate to whether a waste bin is full or not\
    \ which is then\nused for route planning. Considering the requirements of such\
    \ a system, in terms\nof implementation, all of these systems are cloud based.\
    \ Sewer monitoring has been\nperformed in [135] in a cloud based system, they\
    \ use sewer water level and rain gauge\ndata along with a RNN to perform sewer\
    \ overflow monitoring. The RNN is used to\npredict sewer overflow ahead in time.\
    \ Water quality has monitoring has been the focus\nof [136, 137, 138] where the\
    \ authors use multiple sensors measuring pH value, chloride,\nnitrate content\
    \ and hardness of water to determine whether it is fit for drinking or\nnot. In\
    \ [139], Liu et al. use data from water monitoring stations along the Yangtze\n\
    river to predict water quality. Like the classification-based systems, they use\
    \ multiple\nchemical measurements from the water such as oxygen, pH, turbidity\
    \ etc. Apart from\nair quality, smart city monitoring systems are an important\
    \ application within the\nsmart city services domain. This includes urban noise,\
    \ which has been the focus of\nresearchers in [140, 141] as well as other more\
    \ comprehensive monitoring systems as\nproposed in [142, 143]. All these systems\
    \ are cloud based and use a combination\nof sensors for sound and/or image data\
    \ for performing noise monitoring/detection\nand various smart city dashboard\
    \ applications. In Table 8, we summarize the type\nof deployments, applications\
    \ task and data for smart city services applications. It\nis noted that most of\
    \ the applications relating to city services such as air quality\nmonitoring and\
    \ prediction, sewer monitoring, waste collection have been proposed as\ncloud\
    \ systems as data needs to be collected from nodes at various points in a city.\n\
    It is envisaged that due to the nature of the applications, many smart city services\n\
    would still rely on cloud or fog architectures as the decision-making taking place\
    \ in\nsuch situations isn’t possible on only a local level. It is also observed\
    \ that most of the\napplications required data from multiple sensors and therefore\
    \ utilized heterogeneous\ndata to carry out the task at hand.\n3.3\nSmart Energy\n\
    Load/energy consumption forecasting is an essential task for monitoring and control\n\
    of electrical power supply in the electricity grid and ensure appropriate demand\
    \ side\nmanagement. It has been performed by the authors of [148] who use data\
    \ collected\nfrom consumers in a smart grid to determine load for up to 24 h in\
    \ advance. They treat\nthis as primarily a clustering problem where they form\
    \ clusters of similar load profiles\nand then use distance functions to determine\
    \ energy consumption for the future. The\nauthors in [149] also use a cloud based\
    \ clustering approach, using historical power\ndata, they use K-Means clustering\
    \ to determine the closest historical records and then\ncombine them to predict\
    \ energy consumption 24 h in advance. The load forecasting\nproblem has been dealt\
    \ as a regression by [150] using a SVM and by [151] through an\nRNN using electricity\
    \ power data. A regression approach is also followed by [152, 153]\nwho use electricity\
    \ consumption in addition to environmental data for load forecasting\nusing deep\
    \ learning methods (DNN and a combination of Autoencoders and RNNs\n(GRU)). Edge\
    \ based systems have been suggested by the authors of [154, 155, 156]\n36\nTable\
    \ 8. AI use for Smart city Services\nApplication\nNetwork\nSystem\nAr-\nchitecture\n\
    Task\nData type\nAir quality\nK-NN [144]\nCloud\nClassification - Differentiate\n\
    between different air quality\nlevels\nHeterogenous\n(Gas,\nLight, Temperature,\n\
    Humidity, Pressure,\nRFC[145]\nWind\nspeed,\nWeather\ninfor-\nmation, Images,\n\
    RFC[146]\nTraffic\nflow\ndata,\nVisibility,\ninforma-\ntion about\nRNN (LSTM)\
    \ [147]\nRegression - Prediction of\nair quality levels\ntypes\nof\nbuildings\n\
    etc)\nWater quality moni-\ntoring\nNB [136]\nCloud\nClassification - Determine\
    \ if\nwater is fit to drink or not\nHeterogeneous\n(Chlorides, Nitrates,\nTotal\n\
    dissolved\nsolids,\nSVM [137]\npH\nand\nHardness,\nand\nother\nchemical\nproperties)\n\
    DNN [138]\nRNN (LSTM) [139]\nRegression - Prediction of\nwater quality\nSewer\
    \ Overflow Mon-\nitoring\nRNN (GRU,LSTM) [135]\nCloud\nRegression - Prediction\
    \ of\nwhen\nHeterogeneous (Wa-\nter level sensor data\n(ultrasonic)\nover\ndrain\
    \ holes as well as\nrain gauges)\nWaste management\nRNN (LSTM) for prediction\n\
    of air quality [134] , K-NN\nfor detection of waste bin be-\ning full\nCloud\n\
    Regression - Prediction of\nair pollutant levels, Classifi-\ncation - Bin full\
    \ or not\nHeterogeneous\n(Odor, Weight, Level\nsensing using\nRFC[133]\nClassification\
    \ - Empty bin or\nnot\nultrasonic\nsensor,\nGas\nsensor\nfor\nair\nquality, Vibration)\n\
    Urban noise monitor-\ning\nCNN [140]\nCloud\nClassification\n-\nDifferent\ntypes\
    \ of sounds\nHomogeneous\n(Sound)\nRNN (LSTM) [141]\nRegression – Prediction of\n\
    noise levels\nManagement\nof\nSmart City\nCNN [143]\nCloud\nApplication\n–\nDashboard\n\
    (object identification etc)\nHeterogeneous (Var-\nious sensors, Urban\nvideo\n\
    and\nsound\ndata)\nCNN [142]\nfor load forecasting for household consumers, [156]\
    \ use federated learning to train a\nRNN. In addition to load forecasting, smart\
    \ grid management/monitoring is also a\nnecessary application in this domain.\
    \ The authors in [157] use decision trees in a cloud\nbased system to classify\
    \ between different faults in a smart grid. In [158], the authors\nuse power consumption\
    \ data from consumers in China to determine electricity theft\nin a cloud based\
    \ system. They use wide and deep convolutional neural networks to\ncapture the\
    \ periodic and nonperiodic components from electricity consumption data\nand show\
    \ their network to be suitable for electricity theft detection. The authors in\n\
    [159] present a framework for edge computing based monitoring of the smart grid.\n\
    Edge computing in the smart grid has several advantages as it reduces delay and\
    \ also\nit is secure in terms of data privacy. A summary of the use of IoT based\
    \ AI in Smart\nEnergy is provided in Table 9.\n37\nTable 9. AI use for Smart Energy\n\
    Application\nNetwork\nSystem\nAr-\nchitecture\nTask\nData type\nEnergy/Load\n\
    con-\nsumption forecasting\nK-Means [148]\nCloud\nClustering - Determine clus-\n\
    ters of similar power con-\nsumption\nHomogeneous (Elec-\ntric power)\nK-NN [149]\n\
    Regression - Predict con-\nsumption\nof\nelectricity\nahead of time\nSVM [150]\n\
    RNN (LSTM) [151]\nDNN [152]\nHeterogeneous (Elec-\ntric\npower,\nTem-\nperature,\n\
    Humidity,\nTime, Holiday\nSAE + RNN (GRU) [153]\nCNN [155]\nEdge\nRNN (GRU) [154]\n\
    Homogeneous (Elec-\ntric power)\nRNN (LSTM) [156]\nSmart\nGrid\nline\nevent\n\
    classification\n(fault etc.)\nDT [157]\nCloud\nClassification\n-\nDifferent\n\
    powerline events\nHomogeneous (Elec-\ntric power)\nElectricity theft de-\ntection\n\
    CNN [158]\nCloud\nClassification - Theft detec-\ntion for abnormal patterns\n\
    of consumption\nHomogeneous (Elec-\ntric power)\n3.4\nSmart Health\nThere are\
    \ two major applications of IoT with AI in health, these are activity recog-\n\
    nition/fall detection and disease diagnosis/health monitoring, a summary of the\
    \ IoT\nbased AI systems used in Smart Health is presented in Table 10. Activity\
    \ recog-\nnition involves the use of movement sensors such as accelerometers,\
    \ gyroscopes and\nmagnetometers with the aim to help provide the user with feedback\
    \ on their health.\nThis can be in terms of them having enough physical exercise\
    \ or not, used for sports\ntherapy, fall detection and for monitoring of different\
    \ diseases such as Parkinson’s or\nother motor degenerative ailments. The most\
    \ popular sensor for activity recognition\nare inertial sensors which have been\
    \ used by [160, 161] in a cloud based setting using\nvarious deep and machine\
    \ learning algorithms. In [162], Castro et al. include vital\nsign data in addition\
    \ to movement information for human activity recognition in a\ncloud environment,\
    \ they utilize the DT as their classifier. In [163],, the authors pro-\npose an\
    \ edge-based system to perform activity recognition for people by recording\n\
    their movements using the accelerometer and gyroscope present on the phone. They\n\
    use a SVM as their classifier and differentiate between six different activities\
    \ of daily\nliving. Fall detection has been performed by [164, 165] in a fog and\
    \ edge environment,\nrespectively, using an accelerometer, Santos et al. [164]\
    \ use a CNN while Yacchirema\net al. [165] useRFCwith both approaches showing\
    \ promising results.\nEquipped with the power of AI in IoT, Smart Health systems\
    \ facilitate the provi-\nsion of telehealth services as well as real time monitoring\
    \ of patients, giving doctors\nand patients feedback on their health.\nHealth\
    \ monitoring systems and real time\ndisease diagnosis have been one of the most\
    \ important applications of IoT technol-\nogy. The authors in [166, 167, 168,\
    \ 169, 170, 171, 172, 173, 174, 175, 176] develop\ncloud based health monitoring\
    \ systems for detecting various types of diseases, such\n38\nas heart (stroke\
    \ [167], irregular sound [169], irregular rhythm [171, 173]), epilep-\ntic seizures\
    \ [172], Parkinson seizure [176] and multiple disease diagnosis systems\n[174,\
    \ 175]. In [174, 175], the authors formulate the problem of disease diagnosis\
    \ as\na classification problem and utilize medical data such as ECGs, EEG, heart\
    \ rate,\nblood pressure, blood sugar, heart sound, blood glucose, liver health\
    \ along with var-\nious machine and deep learning methods to achieve this task.\
    \ Fog and edge based\nhealth monitoring/disease diagnosis systems have also been\
    \ suggested by a number\nof researchers. The authors in [177] present a fog based\
    \ system using a deep neural\nnetwork to detect heart disease from a patients\
    \ vital signs (blood oxygen, heart rate,\nrespiration rate, EEG, ECG, EMG, blood\
    \ pressure, glucose) and activity data. In\n[178], Devarajan & Ravi work on a\
    \ fog computing based Parkinson detection system\nusing a persons speech. Moreover,\
    \ an edge computing system is presented in [179]\nwhich utilizes EEG signals to\
    \ determine seizures in patients.\nTable 10. AI use for Smart Health\nApplication\n\
    Network\nSystem\nArchi-\ntecture\nTask\nData type\nHuman\nactivity\nrecognition/Fall\n\
    de-\ntection\nDT [162]\nCloud\nClassification - Different activities,\nfall /non\
    \ falls\nHeterogeneous (Acceleration, Heart\nrate,\nPosture,\nECG, Respiration\n\
    rate)\nRFC[160]\nHomogeneous (Accelerometer)\nCNN [161]\nRNN\n(LSTM)\n[180]\n\
    Fog Edge\nHeterogeneous (Accelerometer, Gy-\nroscope, Magnetometer)\nCNN [164]\n\
    Fog\nRFC[165]\nEdge\nHeterogeneous (Accelerometer and\nGyroscope)\nSVM [163]\n\
    Patient health moni-\ntoring\nDT [166]\nCloud\nClassification\n-\nRecommendation\n\
    about diet etc\nHeterogeneous (Heart rate, Sleep,\nCalories burned, Weight, Physical\n\
    activity time, Water, Exercise etc)\nSVM [169]\nClassification - Different emotions\n\
    Heterogeneous (Speech and Image)\nRNN(LSTM)\n[181]\nHeterogeneous (ECG, BVP, GSR,\n\
    SKT, EMG)\nCNN\n+\nSAE [172]\nClassification - Abnormal/normal\nheart sounds\n\
    Homogeneous (EEG)\nRFC[168]\nClassification - Epileptic Seizure de-\ntection\n\
    Homogeneous (Heart sounds)\nSVM [171]\nClassification - ECG arrhythmias\nHomogeneous\
    \ (ECG)\nDisease diagnosis\nDT [173]\nCloud\nClassification - Different heart\
    \ dis-\neases\nHeterogeneous (Heart health infor-\nmation, Patient records and\
    \ other\nhealth sensors)\nK-Means\n[174]\nClassification - Kidney, Heart and\n\
    Liver disease\nHeterogeneous (Heart and Kidney\nhealth data)\nRFC[175]\nClassification\
    \ - Detection of various\ndiseases\nHeterogeneous\n(Diabetes,\nHeart,\nLiver,\
    \ Dermatology etc data)\nDNN [177]\nFog\nClassification - Presence of heart\n\
    disease or not\nHeterogeneous\n(Blood\noxygen,\nHeart rate, Respiration rate,\
    \ EEG,\nECG, EMG, Blood Pressure, Glu-\ncose and Activity data)\nParkinson detection/\n\
    RFC[167]\nCloud\nClassification - Parkinson detec-\ntion/stroke has happened/seizure\n\
    detection\nHeterogeneous\n(Blood\npressure,\nSugar, Pulse rate)\nSeizure monitoring\n\
    SVM [176]\nHomogeneous (Speech)\nK-NN\n[178]\nFog\nNB [179]\nEdge\nHomogeneous\
    \ (EEG)\n39\n3.5\nSmart Homes\nAmbient assisted living is a huge component of\
    \ Smart Homes.\nThis is especially\nneeded for the elderly and is typically achieved\
    \ by the use of ambient sensors, Wi-Fi\nand radio frequency systems in smart homes.\
    \ In this work, we include all monitoring\nmethods that depend on sensors placed\
    \ in the home/within the smart home domain.\nIn [182], Pirzada et al. use a network\
    \ of reed switches connected to the cloud to\nmonitor the activities of elderly\
    \ people as a clustering problem. They use the K-\nNN algorithm to determine anomalies\
    \ in the daily activities which can then be used\nto send medical or other help\
    \ requests to assist people. A similar setup for activity\nrecognition for ambient\
    \ assisted living has been presented in [183, 184, 185] where they\nuse data from\
    \ a number of different sensors including motion, presence, water float,\ntemperature\
    \ etc to determine various activities being performed in a home. In [186],\na\
    \ cloud based assisted living system for the deaf has been developed that performs\n\
    haptic conversions for sounds detected in a home. An array of sensors are used\
    \ to\nmonitor environmental sound and the authors use RNNs for detecting the sound\n\
    event before its passed on to the haptic vibration producer. Another task within\n\
    in monitoring is localization of people, this part of smart homes is also applicable\n\
    to smart infrastructure in that such systems are used in smart buildings as well.\n\
    Applications of localization include security, i.e., detecting unauthorized presence\n\
    and people monitoring in general (for, e.g., locating elderly people in homes)\
    \ etc.\nThe authors in [187] perform localization using a grid of Wi-Fi units\
    \ that measure\nsignal strength to determine peoples locations indoors for buildings.\
    \ They formulate\nthis both as a classification problem as well as a regression\
    \ problem. The classification\nproblem being formulated as coded locations (for,\
    \ e.g., a given room no) while the\nregression case estimating the location of\
    \ the user in a coordinate grid. Their system is\ncloud based and they use a deep\
    \ neural network to perform this task and have found\nsuitably good results. Occupancy\
    \ detection has been performed by the authors of\n[188] making use of various\
    \ ambient measurements (temperature, humidity, pressure\netc.) and passing them\
    \ to a cloud before using a deep neural network to classify\nbetween the various\
    \ number of people present in an indoor environment. In [189],\nZimmermann et\
    \ al. also make use of ambient sensors for the occupancy problem and\nuse a na¨ıve\
    \ bayes learner to determine both the presence of occupants as well as their\n\
    number.\nHome automation is another application that the IoT finds application\n\
    within the Smart Home domain. The integration of AI has helped develop smart\n\
    home automation systems that aim to reduce energy consumption in homes as well\n\
    as maintain user privacy, security. Chowdhry et al. [190] use a combination of\
    \ visual\ndata and motion sensing to perform home automation for security using\
    \ a SVM.\nAn interesting use of AI in home automation is presented in [191] who\
    \ develop a\ncloud based home automation system, they take measurements from various\
    \ ambient\nsensors and control appliances and use a Na¨ıve Bayes classifier to\
    \ determine which\ntechnician to call whenever sensor measurements appear aberrated.\
    \ The problem of\nintelligent consumption of energy has been considered by [192]\
    \ who develop an energy\ndisaggregation system on the appliance level in smart\
    \ homes using stacked denoising\nautoencoders. They achieve this using power data\
    \ for individual appliances as well\n40\nas the total power consumed in the home\
    \ and send it to a local cloud. Data is then\ndisaggregated for various appliances\
    \ to provide feedback to the user.\nMore work\nproviding energy intelligence to\
    \ consumers has been performed by [193, 194, 195].\nKonstantakopoulos et al. [195]\
    \ pose this as a regression problem, they propose a\ncloud-based system utilizing\
    \ both ambient sensor data (lighting, temperature etc)\nand appliance power data\
    \ to forecast resource usage for consumers using a RNN.\nThey show a reduction\
    \ in energy consumption for their users using this information.\nEventhough applications\
    \ covered in smart homes have been cloud based systems,\nthere have been recent\
    \ proposals for frameworks that combine edge and cloud pro-\ncessing as in [196]\
    \ who discuss a hierarchical control system for smart homes through\na edge microgrid\
    \ and a cloud power grid. Due to the nature of smart homes in that\nthe sensing\
    \ scheme is present within a finite space (within the home), edge and fog\ncomputing\
    \ based systems are expected to be increasingly incorporated smart home\napplications.\
    \ A summary of the use of IoT based AI in Smart Homes is presented in\nTable 11.\n\
    3.6\nSmart Industry\nOne of the major applications of AI in the IoT powered smart\
    \ industry is towards\nfault detection in products and anomaly detection in industrial\
    \ processes. This has\nseen the use of both Machine Learning (SVM [197, 198],RFC[199,\
    \ 200]) as well as\nDeep Learning (DNN [201, 202, 203], CNN [204]) methods using\
    \ a cloud computing\nstructure to perform anomaly detection/product inspection\
    \ and monitoring using a\nvariety of heterogeneous and homogenous data sources\
    \ such as inertial sensors for ma-\nchines, images for products and processes\
    \ and other process specific variables. Other\napproaches suggested in [205, 206]\
    \ propose a fog computing method along with edge\ncomputing systems suggested\
    \ in [207, 208]. An edge computing system for anomaly\ndetection is presented\
    \ in [209] where edge devices collaboratively train a deep anomaly\ndetection\
    \ model. Production management is another application that has found usage\nof\
    \ AI in IoT based smart Industry. For, e.g., the authors in [210, 211, 212, 213,\
    \ 214]\nuse cloud based data driven systems along with machine and deep learning\
    \ algorithms\nto help with task dispatching, performance analysis as well as worker\
    \ activity recog-\nnition utilizing a variety of sensing modalities. The work\
    \ of [213, 214] are especially\ninteresting as they aim is to not only perform\
    \ production management but also pro-\npose data for various health related analysis\
    \ to create a safer working environment\non the factory floor. A fog system for\
    \ production management has been presented in\n[215] who use activity data to\
    \ determine resource allocation locations to contribute\nto management of a production\
    \ operation. Furthermore, product inspection, which\nis a common application of\
    \ instrumentation systems in a factory, has been performed\nby [216, 217] who\
    \ utilize images and sensor data in a cloud based system to monitor\nproduct quality.\n\
    A factory has a multitude of machines and equipment working round the clock\n\
    manufacturing goods. Maintenance is an important aspect of this operation where\n\
    regular checks are performed on the equipment to ensure that no breakdown occurs\n\
    during the production process, which might result in monetary loss or loss of\
    \ life.\n41\nTable 11. AI use for Smart Homes\nApplication\nNetwork\nSystem\n\
    Ar-\nchitecture\nTask\nData type\nAmbient Assisted liv-\ning (Activity recogni-\n\
    tion/Fall detection)\nK-NN [182]\nCloud\nClustering - Detect abnor-\nmal clusters\n\
    Homogeneous (Reed switches)\nRNN (LSTM)\n[185]\nClassification - Different ac-\n\
    tivities\nHeterogeneous\n(Human\nmotion,\nWater float, Reed switches, Tem-\nperature,\n\
    Pressure,\nLuminance,\nGas and other environmental sen-\nsors in a home)\nRNN\
    \ (LSTM)\n[183]\nSAE [184]\nRNN\n(GRU)\n[186]\nClassification\n-\nDifferent\n\
    sounds\nHomogeneous\n(Sound\nrecordings\nfrom rooms in a house)\nAmbient\nAssisted\n\
    living\n(Localization\nand Occupancy de-\ntection)\nDNN [187]\nCloud\nClassification\n\
    and\nRegres-\nsion - Localization estima-\ntion\nHomogeneous\n(Wi-Fi\nsignal\n\
    strength and identifiers)\nNB [189]\nClassification - Presence of\npeople or not,\
    \ Regression-\nNumber of occupants\nHeterogeneous\n(Volatile\norganic\ncompounds,\n\
    CO,\nTemperature,\nHumidity)\nDNN [188]\nClassification\n-\nDifferent\nnumber\
    \ of people present\nHeterogeneous (Temperature, Lu-\nminance, Humidity, Pressure,\
    \ CO2,\nMotion, Magnetometer, Gyroscope,\nAccelerometer, Sound, Door and\nwindow\
    \ open/close status)\nEnergy management\n(Automation, Power\nconsumption\nprofil-\n\
    ing)\nSVM [190]\nCloud\nClassification - Intrusion de-\ntection\nHeterogeneous\
    \ (Images + Sound)\nSAE [192]\nRegression - Disaggregation\nof appliance power\
    \ data\nHomogeneous\n(Appliance\npower\nconsumption)\nRNN\n(LSTM)[195]\nRegression\
    \ – Forecasting oc-\ncupant resource usage\nHeterogeneous\n(Appliance\npower\n\
    consumption,\nLuminance,\nVibra-\ntion, Temperature, Humidity, Ac-\ncelerometer\
    \ [fan])\nSAE\nfor\ndisaggre-\ngation\nand\nRNN(LSTM)\nfor forecasting\n[194]\n\
    Classification - Energy dis-\naggregation,\nRegression\n-\nLoad forecasting\n\
    Heterogeneous\n(Temperature,\nLuminance,\nHumidity,\nProximity\nswitches, Ultraviolet\
    \ light sensors,\nPower consumption)\nNB [193]\nClassification\n-\nDetermine\n\
    appliances that are on\nHomogeneous\n(Appliance\npower\nconsumption)\nHowever,\
    \ with the data gathered by various sensors on these machines, it is often\nmore\
    \ beneficial to take an active approach rather than a passive one by using this\n\
    data for predictive maintenance purposes. Predictive maintenance utilizes data\
    \ from\nthe daily operation of machines in an industry to optimize the manufacturing\
    \ op-\neration [218] and is one of the main uses for AI in the industry. In [219,\
    \ 220], the\nauthors suggest a predictive maintenance scheme using SVMs utilizing\
    \ data from ac-\ncelerometers measuring vibration in a crane motor and data from\
    \ various sources in\na semiconductor manufacturing process, respectively, both\
    \ work in a cloud environ-\nment as evidenced from the architecture. Prediction\
    \ of failure can also be a regression\noperation, as was demonstrated by [221]\
    \ who use RNNs to predict future values of\na physical parameters of a pump using\
    \ a number of heterogeneous sensors used to\nmonitor it. As with the other two\
    \ systems, this system also had a cloud architecture.\nThe authors in [170] also\
    \ present a regression based health prognosis system for the\nindustry using a\
    \ CNN on machine data (Images, stress, temperature, vibration, po-\n42\nsition\
    \ and electromagnetic signal measurements). The use of IoT based AI in Smart\n\
    Industry has been presented in Table 12.\n3.7\nSmart Infrastructure\nAn application\
    \ within smart infrastructures also involves monitoring of civil structures\n\
    for structural health. The authors in [222] take a clustering approach to perform\n\
    health monitoring of a bridge using vibration data in a cloud setting.\nThey use\n\
    clustering to determine clusters of abnormal behavior in accelerometer measurements\n\
    from a bridge. In [223, 224, 225], accelerometer signals have been used where\
    \ as [226]\nhave used piezo electric transducers for performing structural health\
    \ monitoring of\nbridges formulated as a classification problem between different\
    \ damaged states of\na bridge. The prime sensing modality for monitoring has been\
    \ measuring vibration\nusing accelerometers, however, other sensors such as fiber\
    \ optic gratings can also be\nused to measure stress.\nThe second avenue for AI\
    \ applications in IoT for smart infrastructure is the use\nof IoT devices for\
    \ building environment control and energy management as well com-\nfort aware\
    \ control. This involves the prediction of building energy usage based on\nenvironmental\
    \ data (such as temperature, humidity) and electrical power data. The\nauthors\
    \ in [227] and [228] use electric power data and heat flow information in a\n\
    building to predict the energy requirements in the future so as to better manage\
    \ en-\nergy consumption. Ambience control of a museum has been performed in [229]\
    \ where\nthe authors use deep learning algorithms to predict the CO2 and humidity\
    \ levels\nfor the care of exhibits. Comfort aware energy management has been performed\
    \ in\n[230] where the authors use a CNN to regulate thermal comfort in a building\
    \ using\nvarious physical quantities. It can be noted that all of these mentioned\
    \ systems have\nbeen deployed in the cloud, this is due to the nature of the application.\
    \ However,\nthere have been efforts for developing fog/edge systems for smart\
    \ infrastructure. The\nauthors in [231] describe a framework for deploying edge\
    \ and fog computing services\nin smart buildings and demonstrate their systems\
    \ effectiveness for the case of energy\nmanagement. Table 13 summarizes the use\
    \ of IoT based AI in Smart Infrastructure.\n3.8\nSmart Transport\nMajor smart\
    \ transportation applications involve smart parking and transportation\nmanagement.\
    \ Smart parking aims to solve the problem of helping users finding park-\ning\
    \ spots in order to save time as well as reduce gas emissions and is therefore\
    \ a much-\nresearched topic for AI deployment towards smart transportation. Solutions\
    \ to this\nproblem have been formulated both as a regression problem as well as\
    \ a classification\none, both utilizing imaging and/or other occupancy sensing\
    \ modalities. Regression\nsolutions [232, 233, 234] are typically used to predict\
    \ a parking lots occupancy levels\nin the future whereas classification systems\
    \ [235, 236, 237] involve guiding drivers ac-\ncording to the shortest distance\
    \ as well as used for user localization purposes within\nsuch lots. In addition\
    \ to cloud based approaches, edge computing systems for smart\nparking have also\
    \ been devised as suggested in [238, 239] who deploy CNNs on edge\n43\nTable 12.\
    \ AI use for Smart Industry\nApplication\nNetwork\nSystem\nAr-\nchitecture\nTask\n\
    Data type\nFault\nand\nanomaly\ndetection\nDNN [203]\nCloud\nClassification -\
    \ Different classes of abnor-\nmality labels\nHeterogeneous (Mul-\ntiple sensor\
    \ and con-\ntrols [button states\netc] information)\nDNN [202]\nClassification\
    \ - Different damage stages of\na 3D printer\nHeterogeneous\n(Accelerometer, Gy-\n\
    roscope)\nRFC[199]\nClassification - Normal and abnormal op-\neration in wind\
    \ turbines\nHomogeneous\n(Ac-\ncelerometer)\nSVM [197]\nClassification\n-\nDifferent\n\
    wind\nturbine\nhealth conditions\nSVM [198]\nClassification - Normal and mixed\
    \ cement\nHomogeneous\n(Im-\nages)\nRFC[200]\nClassification - Different fault\
    \ types in steel\nmanufacturing\nHeterogeneous\n(Various\nsensors,\ndimensional\n\
    mea-\nsurements)\nDNN [201]\nClassification - Normal and arcing\nHomogeneous\n\
    (Cur-\nrent)\nCNN [204]\nClassification - Defected product or not\nHomogeneous\n\
    (Im-\nages)\nCNN [205]\nFog\nClassification - Different types of defects\nHomogeneous\n\
    (Im-\nages)\nCNN [206]\nSVM [207]\nEdge\nClassification - Abnormal and normal\
    \ pres-\nsure\nHomogeneous\n(Wa-\nter pressure)\nCNN\n+\nLSTM [209]\nClassification\
    \ - Abnormal and normal time\npower patterns\nHomogeneous (Elec-\ntrical power)\n\
    RNN (LSTM)\n[208]\nClassification - Faulty and normal state of\na machine\nHomogeneous\n\
    (Ac-\ncelerometer)\nProduction manage-\nment\nSVM [210]\nCloud\nRegression - Prediction\
    \ of the slotted coef-\nficient in a hydraulic press\nHeterogeneous (Var-\nious\n\
    measurements\nfrom\na\nhydraulic\npress)\nConvLSTM +\nSAE [211]\nRegression -\
    \ Forecasting machine speed to\nmake production more efficient\nHomogeneous (Speed\n\
    of machine [rotary])\nDNN [214]\nRegression - Bottle neck prediction in time\n\
    Heterogeneous\n(RFID,\nmovement\nsensors)\nCNN [212]\nClassification - Different\
    \ activities in an as-\nsembling factory\nHeterogeneous\n(IMU, EMG)\nSVM [213]\n\
    Classification - Different activities in a\nmeat processing plant evaluate worker\
    \ per-\nformance\nHeterogeneous\n(Accelerometer, Gy-\nroscope)\nRFC[217]\nClassification\
    \ - Bad or good product qual-\nity\nHeterogeneous (Var-\nious sensors from a\n\
    production floor in a\nfactory)\nCNN [216]\nClassification - Prediction of temperature,\n\
    Carbon content in steel\nHomogeneous (Spec-\ntrogram Images)\nRFC[215]\nFog\n\
    Classification - Determine Room ID, used\nfor system disruption\nHeterogeneous\n\
    (Ac-\ntivity\ndata,\nLoca-\ntion)\nPredictive\nmainte-\nnance\nCNN [170]\nCloud\n\
    Regression - Predict health index for ma-\nchines\nHeterogeneous\n(Im-\nages,\n\
    Temperature,\nVibration,\nPosition,\nElectromagnetic\nsignal measurements,\nStrain\
    \ gauge)\nSVM [219]\nClassification - Abnormal or normal vibra-\ntion data (from\
    \ electric motor in a crane)\nHomogeneous\n(Ac-\ncelerometer)\nRFC+\nSVM\n[220]\n\
    Classification - Failure prediction\nHeterogeneous (Mul-\ntiple\nsensors\nfrom\n\
    SECOM dataset)\nRNN (LSTM)\n[221]\nRegression - Predicting data from sensors\n\
    Heterogeneous\n(Different\nsensors\n[Pressure,\nTempera-\nture, Vibration etc])\n\
    44\nTable 13. AI use for Smart Infrastructure\nApplication\nNetwork\nSystem\n\
    Ar-\nchitecture\nTask\nData type\nStructural\nhealth\nmonitoring\nK-Means [222]\n\
    Cloud\nClustering – Look for abnor-\nmality of building state\nHomogeneous\n(Ac-\n\
    celerometers)\nK-NN [226]\nClassification\n–\nDifferent\ndamage states\nHomogeneous\
    \ (Piezo\nelectric sensors)\nDNN [223]\nHomogeneous\n(Ac-\ncelerometer)\nCNN +\
    \ RNN (LSTM) [225]\nSVM [224]\nEnergy and Environ-\nment management\nSVM [227]\n\
    Cloud\nRegression\n-\nForecasting\nelectrical power usage\nHeterogeneous\n(Power\
    \ and environ-\nmental data)\nSAE [228]\nRegression -Energy predic-\ntions for\
    \ buildings\nHomogeneous (Heat\nflow data in build-\nings)\nRNN (GRU, LSTM) [229]\n\
    Regression -Prediction of en-\nvironmental variables (CO2,\nHumidity etc)\nHeterogeneous\
    \ (envi-\nronmental data such\nas\nCO2,\nHumidity,\nAir velocity)\nCNN [230]\n\
    Regression - Comfort level\ndevices for occupancy detection and user localization,\
    \ respectively. Another applica-\ntion of AI IoT for smart transportation involves\
    \ determining traffic flow as well as\nprediction of traffic flow for traffic\
    \ light control and other management tasks such as\naccident detection. In this\
    \ regard, video cameras are popular for detection of vehicle\ndensity on roads\
    \ for traffic congestion determination. However, with most cars having\na GPS\
    \ device and the commonality of cellphones with every driver, many approaches\n\
    use the data from the GPS along with weather and generic traffic flow information\n\
    to determine traffic prediction. The nature of traffic flow prediction using sensing\n\
    modalities such as GPS require systems to be operated as cloud-based systems as\n\
    is the case in [240, 241, 242, 243]. Of these, Wangyang et al. [242] and Xiao\
    \ et al.\n[243] use deep learning based sequential modeling approaches to predict\
    \ traffic flow\nahead of time where as Aung & Naing [240] and Yunxiang Liu & Wu\
    \ [241] solve this\nthrough a classification formulation. A traffic management\
    \ system for public buses\nhas been proposed in [33, 244] where GPS data is used\
    \ to predict bus arrival times\nfor public transportation systems. Accident detection\
    \ has been performed using car\nposition and velocity information in a Vehicular\
    \ Adhoc NETworks (VANET) envi-\nronment by the authors of [245]. They do this\
    \ through a cloud based system that\ncan use this information to predict whether\
    \ an accident has occurred or not. Apart\nfrom typical sensing modalities, with\
    \ smart phones and user participation in social\nmedia, smart transportation systems\
    \ are expected to increasingly include more sens-\ning modalities [246] fused\
    \ together for use in decision making for traffic management\npurposes. Mukherji\
    \ et al. [247] use Wi-Fi signals to determine commuter traffic a\nsubway station.\
    \ They do this by using the measured signal strength of the Wi-Fi\nsignals along\
    \ with a Random Forest classifier in a cloud-based setting. Their system\nis able\
    \ to determine if a person is on the train or on the platform which can be used\n\
    to help with planning train times and routes. A summary of IoT based AI for Smart\n\
    Transport has been given in Table 14.\n45\nTable 14. AI use for Smart Transport\n\
    Application\nNetwork\nSystem\nAr-\nchitecture\nTask\nData type\nSmart\nParking\n\
    (Parking\noccupancy\ndetection/Rout-\ning/Location predic-\ntion)\nK-NN [237]\n\
    Cloud\nClassification - Presence of a\nvehicle\nHomogeneous\n(Im-\nages)\nK-Means\
    \ [232]\nRegression - Future occu-\npancy prediction\nHeterogeneous\n(Oc-\ncupancy,\n\
    Location,\nTime)\nRNN (LSTM) [234]\nLR [233]\nHomogeneous (RFID\ndata from cars)\n\
    DNN+ CNN [235]\nClassification - Different po-\nsitions based on beacons in-\n\
    stalled\nHomogeneous (Radio\nfrequency\nsignal\nstrength)\nDT [236]\nClassification\
    \ - Recommen-\ndation of parking lot based\non distance\nHeterogeneous\n(Parking\n\
    informa-\ntion, Time)\nCNN [238]\nEdge\nClassification - Detection of\nempty parking\
    \ space\nHeterogeneous\n(LI-\nDAR, Images)\nCNN [239]\nClassification\n–\nDifferent\n\
    user locations localization\nHomogeneous (Blue-\ntooth received signal\nstrength)\n\
    Transport\nman-\nagement\n(Public\ntransport\nmanage-\nment)\nK-Means [33]\nCloud\n\
    Regression – Transport de-\nlay prediction\nHeterogeneous (GPS,\nTicket\ninformation,\n\
    Time,\nArrival,\nDe-\nparture\ninformation\netc )\nK-Means [244]\nRegression –\
    \ Arrival time\nprediction\nRFC[247]\nClassification\n–\nLocaliza-\ntion, as on\
    \ platform or train\nHomogeneous (Wi-Fi\nsignal parameters)\nTransport\nmanage-\n\
    ment (Traffic flow)\nNB [240]\nCloud\nClassification\n-\nDifferent\ntraffic states\n\
    Homogeneous\n(GPS\ndata, current and his-\ntorical)\nRFC[241]\nHeterogeneous\n\
    (Weather,\nRoad\ndata)\nRNN (LSTM) [243]\nRegression - Traffic flow pre-\ndiction\n\
    Homogeneous (Traf-\nfic flow data[vehicle\nspeed count etc])\nRNN (LSTM) [248]\n\
    SAE + RNN (LSTM) [242]\nTransport\nman-\nagement\n(Traffic\nAccident detection)\n\
    RFC [245]\nClassification - Accident or\nnot\nHomogeneous\n(Ve-\nlocity, Position)\n\
    4\nConclusion\nThis chapter provided a coverage of the usage of AI in terms of\
    \ machine and deep\nlearning for applications within smart cities. For each of\
    \ the applications discussed\nfor the various components, the type of deployment\
    \ based on the technologies and\narchitectures discussed in the previous chapter\
    \ were identified. Figure 7 provides a\nsummary of the AI discussion in this section.\
    \ Moreover, a tabular version is provided\nin Table 15 for this section. It highlights\
    \ the applications in which each AI domain\nfinds use in for smart city components.\n\
    46\nAI for IoT Smart \nCities\nMachine Learning\nDeep Learning\nSupport \nVector\
    \ \nMachines \nDecision \nTrees\nK-Nearest \nNeighbor\nRandom \nForests\nLogistic\
    \ \nRegression\nNaïve Bayes\nK-Means\nSmart Agriculture\nSmart City Services\n\
    Smart Energy\nSmart Health\nSmart Homes\nSmart Infrastructure\nSmart Transport\n\
    Smart Agriculture\nSmart City Services\nSmart Health\nSmart Industry\nSmart Transport\n\
    Smart Agriculture\nSmart Transport\nSmart Agriculture\nSmart Energy\nSmart Health\n\
    Smart Infrastructure\nSmart Transport\nRecurrent Neural \nNetworks (RNN, \nLSTM,\
    \ GRU)\nStacked Auto \nEncoders\nConvolutional \nNeural \nNetworks\nDeep Neural\
    \ \nNetworks\nSmart Agriculture\nSmart City Services\nSmart Energy\nSmart Health\n\
    Smart Homes\nSmart Industry\nSmart Infrastructure\nSmart Transport\nSmart Energy\n\
    Smart Health\nSmart Homes\nSmart Industry\nSmart Infrastructure\nSmart Transport\n\
    Smart Agriculture\nSmart City Services\nSmart Energy\nSmart Health\nSmart Industry\n\
    Smart Infrastructure\nSmart Transport\nSmart Agriculture\nSmart City Services\n\
    Smart Energy\nSmart Health\nSmart Homes\nSmart Industry\nSmart Infrastructure\n\
    Smart Transport\nSmart Agriculture\nSmart City Services\nSmart Energy\nSmart Health\n\
    Smart Homes\nSmart Industry\nSmart Health\nSmart Homes\nSmart Transport\nSmart\
    \ Agriculture\nSmart Energy\nSmart Health\nSmart Transport\nFigure 7. AI for IoT\
    \ Smart Cities.\n47\nTable 15. AI applications for IoT Smart Cities\nSmart\nCity\n\
    Component\nMachine Learning\nDeep Learning\nObservations\nSmart Agricul-\nture\n\
    - Crop Monitoring /Plant care\n(Irrigation)\n- Crop Monitoring /Plant care\n(Irrigation)\n\
    - Crop Monitoring /Plant care\n(Monitoring and disease detec-\ntion)\n- Crop Monitoring\
    \ /Plant care\n(Monitoring and disease detec-\ntion)\n- Data driven crop care\
    \ and de-\ncision making (Predicting phys-\nical parameters)\n- Data driven crop\
    \ care and de-\ncision making (Predicting phys-\nical parameters)\n- Data driven\
    \ crop care and de-\ncision making (Crop recommen-\ndation)\nSmart\nCity\nServices\n\
    - Air quality\n- Air quality\n- Water quality monitoring\n- Water quality monitoring\n\
    - Waste management\n- Waste management\n- Sewer Overflow Monitoring\n- Urban noise\
    \ monitoring\nSmart Energy\n-\nEnergy/Load\nconsumption\nforecasting\n-\nEnergy/Load\n\
    consumption\nforecasting\n- Smart Grid line event classifi-\ncation\n- Electricity\
    \ theft detection\nSmart Health\n- Human activity recognition/-\nFall detection\n\
    - Human activity recognition/-\nFall detection\n- Patient Health Monitoring\n\
    - Patient Health Monitoring\n- Disease diagnosis\n- Disease diagnosis\n- Parkinson\
    \ detection/Seizure\nmonitoring\n- Parkinson detection/Seizure\nmonitoring\nSmart\
    \ Homes\n- Ambient Assisted living (Ac-\ntivity\nrecognition/Fall\ndetec-\ntion)\n\
    - Ambient Assisted living (Ac-\ntivity\nrecognition/Fall\ndetec-\ntion)\n- Ambient\
    \ Assisted living (Lo-\ncalization and Occupancy de-\ntection)\n- Ambient Assisted\
    \ living (Lo-\ncalization and Occupancy de-\ntection)\n-\nEnergy\nmanagement\n\
    (Au-\ntomation, Power consumption\nprofiling)\n-\nEnergy\nmanagement\n(Au-\ntomation,\
    \ Power consumption\nprofiling)\nSmart\nIndus-\ntry\n- Fault and anomaly detection\n\
    - Fault and anomaly detection\n- Production management\n- Production management\n\
    Smart\nInfras-\ntructure\n- Structural health monitoring\n- Structural health\
    \ monitoring\n- Energy and Environment man-\nagement\n- Energy and Environment\
    \ man-\nagement\nSmart\nTrans-\nport\n- Smart Parking (Parking occu-\npancy detection/Routing/Loca-\n\
    tion prediction)\n- Smart Parking (Parking occu-\npancy detection/Routing/Loca-\n\
    tion prediction)\n- Transport management (Pub-\nlic transport management)\n- Transport\
    \ management (Traf-\nfic flow)\n- Transport management (Traf-\nfic flow)\n- Transport\
    \ management (Traf-\nfic Accident detection)\nFor\napplications\nsuch\nas\nSmart\n\
    Agriculture,\nSmart\nEnergy,\nSmart\nHealth,\nSmart Industry and Smart\nTransport,\n\
    Deep\nLearn-\ning\nas\nwell\nas\nMachine\nLearning\nalgorithms\nhave\nbeen deployed\
    \ in Edge/Fog\nconfigurations.\nThe most popular machine\nlearning algorithms\
    \ were the\nSVM and RFC.\nThe\nmost\npopular\nDeep\nLearning\nalgorithms\nwere\n\
    RNNs and CNNs.\n48\nCHAPTER IV\nOPTIMIZATION IN IOT SMART CITIES\n1\nIntroduction\n\
    This chapter presents a coverage of combinatorial optimization in IoT based smart\n\
    cities by deliberating on the most popular applications of optimization algorithms\n\
    and providing an insight to how those problems are formulated and worked upon.\
    \ It\nprovides a mapped overview of the optimization landscape in the smart city\
    \ domain\nwhile considering the IoT. Through this mapping, the common optimization\
    \ problems\nacross the various components of the IoT enabled smart city have been\
    \ identified. For\neach problem discussed, the objective function used, the nature\
    \ of the objective as\nwell as the constraints considered have also been elaborated\
    \ on.\n2\nOptimization and Heuristics in IoT Smart Cities\nAs has been observed\
    \ by [249], combinatorial optimization problems in the real-world\nare known to\
    \ be difficult to formulate and generally are hard to solve. Moreover,\nchoosing\
    \ the right algorithm is also a tedious task as each comes with a different\n\
    set of characterizations. This is very applicable to the IoT bases smart city\
    \ where\napplications in each component caters to a different environment and\
    \ aspect of the\ncity’s operation and therefore requires intricate design of the\
    \ problem. This chapter\ntakes guidance from the work of [249]. They note that\
    \ the most popular algorithms for\nuse in combinatorial optimization problems\
    \ are the Ant Colony Optimization (ACO),\nGenetic Algorithm (GA), Particle Swarm\
    \ Optimization (PSO), Differential Evolution\n(DE) and Artificial Bee Colony (ABC).\
    \ Moreover, following from their discussion, six\nfactors are considered for each\
    \ application identified. These are:\n1. The type of application: This refers\
    \ to the problem being optimized within the\nsmart city domain.\n2. Data Setup:\
    \ For each application, we mention the data setup used. While doing\nso, we aim\
    \ to capture the various ways in which researchers have sourced data\nfor their\
    \ proposed method.\n3. Single-Parallel problems: Another thing to note in smart\
    \ city optimization\nproblems is whether a problem has been considered as a single\
    \ problem or\nmultiple sub-problems/parallel.\n4. Objective direction, function\
    \ and number of objectives: Maximization or mini-\nmization, lowest fitness function\
    \ value desirable or higher fitness function value\n49\nis desirable.\nSince we\
    \ list the objectives, we also covere the number of ob-\njectives inherently.\
    \ Single objective, where a single fitness is optimized for its\nbest value or\
    \ multi-objective where multiple objective functions need to be con-\nsidered\
    \ at the same time. The latter is a complex process as some objectives\nmay have\
    \ conflicts and thus requires the need to perform trade-offs with what’s\nacceptable.\n\
    5. Constraints: Constraints are a set of restrictions or prerequisites that may\n\
    sometimes be necessary to determine if a solution is considered valid or not.\n\
    Soft constraints are desirable but not necessary whereas hard constraints are\n\
    mandatory to be met. Constraints are put on the fitness function according to\n\
    application being considered. Covering this aspect is particularly important as\n\
    constraints are determined by the application being worked on.\n3\nMeheuristic\
    \ Algorithms\nMetaheuristic algorithms are widely used to solve combinatorial\
    \ optimziation prob-\nlems in the real-world [249]. The aim of these algorithms\
    \ is to determine the minima\nor maxima of an objective function which translates\
    \ an optimization objective in to\none or more mathematical equations. Five algorithms\
    \ have been considered in this\nchapter, these are the Ant Colony Algorithm, Genetic\
    \ Algorithm, Particle Swarm Op-\ntimization Algorithm, Differential Evolution\
    \ and Artificial Bee Colony. As mentioned\nearlier, these have been chosen as\
    \ these were the most commonly used optimzation\nalgorithms identified by [249].\
    \ In this section, we provide a brief intuitive description\nfor each of them.\n\
    3.1\nAnt Colony Optimization\nAnt colony optimization is derived from the behavior\
    \ of ants searching for food\n[250]. It was observed that during this process,\
    \ each ant deposits a chemical called\npheromone on the path which it takes towards\
    \ the food. The more the ants take a\ngiven path, the more the pheromone is deposited\
    \ on it. Subsequent ants that want\nto go towards the food use the amount of pheromone\
    \ on a given path or sub-path\nto decide which path to take so as to determine\
    \ the optimal route to the food. In\nthe artificial ant colony optimization algorithm,\
    \ the points on the path that form the\nsub-paths are encoded on a graph where\
    \ each ant can only visit a given vertex (travel\non the same sub-path) once.\
    \ Each iteration starts with a number of artificial ants,\nan ant would choose\
    \ the next vertex to visit based on the level of pheromone on the\npossible sub-paths\
    \ available to it as well as whether that path has been used before.\nAt the end\
    \ of each iteration, the pheromone levels are updated so as to prioritize the\n\
    use of the most used path for ants in the next iteration.\n3.2\nGenetic Algorithm\n\
    A genetic algorithm [251] is based on evolutionary science. The idea behind the\
    \ ge-\nnetic algorithm is that starting from a given population set of organisms,\
    \ subsequent\n50\nreproduction will result in fitter organisms being produced\
    \ given that the organisms\nchosen for reproduction have some level of fitness.\
    \ To solve an optimization prob-\nlem, a genetic algorithm begins with a given\
    \ population size of strings also called\na chromosome. Each ‘chromosome’ consists\
    \ of a ‘gene’ which may represent points\nin the population. The sequence in which\
    \ the genes are present would represent a\nsolution to the problem. For e.g. for\
    \ a route scheduling problem, this may be the\ncoordinates of the stops. The ‘goodness’\
    \ of a chromosome is determined by a fitness\nfunction that quantifies how appropriate\
    \ a given chromosome is as a solution for the\nproblem. Choosing the right fitness\
    \ function is an important consideration in genetic\nalgorithms as it needs to\
    \ gauge the kind of optimization that is to be performed.\nThe optimization process\
    \ starts with an initial population of a given size. Once a fit-\nness function\
    \ has been defined, in each iteration, two or more chromosomes (parents)\nare\
    \ taken at random from the population and one or more offsprings are generated.\n\
    The random selection takes the selected parents fitness function value in to account,\n\
    however, its necessary that not all parents chosen are the fittest of the population\
    \ as\notherwise, diversity will be compromised, and the algorithm may get stuck\
    \ in a local\nminimum. The method by which these offspring are generated is called\
    \ the Crossover\nfunction and the number of parents mated to form offsprings from\
    \ them depends\non the crossover rate. The Crossover function defines the way\
    \ the genes within the\nchromosomes are exchanged. Usually, the crossover rate\
    \ has a high value. Moreover,\ndepending on some mutation rate, a given fraction\
    \ of all offsprings are mutated. Mu-\ntation depends on the mutation function\
    \ used and involves members of the offspring\nbeing swapped in some manner. When\
    \ one iteration of the offspring creation from\nthe parents in the entire population\
    \ is completed, the offsprings replace members of\nthe original population (typically\
    \ the weakest) and one generation of the GA is said\nto be completed. In order\
    \ to converge to a sufficiently good result, GA’s need to run\nfor many generations.\n\
    3.3\nParticle Swarm Optimization\nParticle Swarm Optimization is modeled on the\
    \ social behavior of animals rather than\nthe evolutionary biological behavior\
    \ on which Genetic Algorithms are based. PSO\n[252] is particularly based on the\
    \ behavior of a flock of birds searching for food. Each\nbird in the flock searches\
    \ for food and can communicate with other birds in the flock\nas soon as it finds\
    \ food or a good direction for it. Therefore, each bird has two food\n‘directions’\
    \ that it needs to consider, first is on an individual level which is called\n\
    the personal best and the second is on the flock level which is the global best.\
    \ Using\nthese two values the bird will proceed towards that path and will inform\
    \ other birds\nin the flock too. The idea here is that after enough time and with\
    \ all the individuals\nworking together, the swarm will find the place with the\
    \ highest concentration of\nfood. In terms of using PSO for optimization tasks,\
    \ individual birds are equivalent\nto a solution as in a GA and each is considered\
    \ as a point or a particle, collectively\nthey make up the swarm. This swarm population\
    \ may be initialized randomly or\nbased on some domain knowledge about the problem.\
    \ The highest concentration of\nfood represents the optimal solution for the whole\
    \ swarm where as a good direction\n51\nrepresents the local optimal solution for\
    \ each case. The aim here, like birds in a flock\nis to determine the global optimal\
    \ solution using information from each individual\nparticle. Each particle has\
    \ three aspects to it, its position, its velocity and a value of\nits current\
    \ position’s ’goodness’. This ’goodness’ as in the GA is defined by a fitness\n\
    function. Like birds, each particle has a personal best fitness value and is also\
    \ aware\nof the global best fitness value. For any particle, the new direction\
    \ of movement is\ndecided by a combination of the personal best and the global\
    \ best as well as the\nparticle’s intention to maintain its current movement.\
    \ Furthermore, several different\ntopologies can be utilized, and a neighborhood\
    \ can also be set for each particle to\nconvey positions when limiting the global\
    \ best parameter to the local best scheme\nrather than the whole swarm. The algorithm\
    \ may be stopped till the best solution is\nreached or no more improvement is\
    \ observed.\n3.4\nDifferential Evolution\nDifferential evolution [253] is a stochastic\
    \ evolutionary algorithm which is used for\noptimization problems for continuous\
    \ functions. The DE algorithm does not expect\ngradient information and thus it\
    \ doesn’t need to be differentiable. Like other evolu-\ntionary algorithms, a\
    \ solution is searched for in the design space by maintaining a\nset of individual\
    \ candidate solutions. In each iteration, the solutions with the best\nfitness\
    \ are combined together and retained for the next iteration. The aim is to im-\n\
    prove upon the fitness value and this process is repeated until a pre-decided\
    \ condition\nfor termination of this process is satisfied. Differential Evolution\
    \ is very similar to\nGenetic Algorithms in that both are evolutionary in nature,\
    \ however, the difference\nis that the DE uses real numbers in the chromosome\
    \ and also that the mutation oper-\nation consists of the difference between two\
    \ or more chromosomes of the population\nwith the possible addition of some type\
    \ of noise to create a new individual. Like\nGA, DE also suffer from getting stuck\
    \ in local minima. The DE algorithm also has\nthree control parameters, the population\
    \ size, the mutation factor and the crossover\nprobability.\n3.5\nArtificial Bee\
    \ Colony\nArticle Bee Colony [254] is a swarm intelligence algorithm based on\
    \ the behavior of\nbees. Within bees, there are different social classes who work\
    \ together to complete\ntasks such as harvesting pollen and nesting through the\
    \ use of smell, ’swing dance’\nand other methods. Bee colonies consist of three\
    \ types of bees, queen, male and\nthe worker bees which work on activities such\
    \ as searching for food, gathering and\nstorage of honey.\nAfter gathering honey,\
    \ the worker bee comes to the nest and\ninforms other bees about the location\
    \ of the honey source site through a dance. The\nABC algorithm simulates the behavior\
    \ of bees by considering three elements, the\nfood source, employed bees and unemployed\
    \ bees. The food source is represented as\nrevenue considering its distance and\
    \ quality, the higher the revenue, the better is the\nvalue. In computational\
    \ optimization terms, the food source is a potential solution\nto the objective\
    \ formulation of the considered problem and the quality or value of\n52\nthe food\
    \ source represents the fitness value of that particular solution. At the start,\n\
    all bees are used as scouts, searching for food sources. When a food source is\
    \ found,\nfor a high value food source, bees who find those food sources become\
    \ hire bees and\ncollect the food source. If the food source is of intermediate\
    \ value, the bees become\nfollow bees and if the food source value becomes low,\
    \ the bees become scout bees to\nlook for better food sources. Hire bees, the\
    \ bees with a food source location having\na high value, lead the follow bees\
    \ to develop solutions in their neighborhood in order\nto come up with more solutions.\
    \ A subset of the highest-ranking solutions are then\nconsidered before this process\
    \ is repeated again until the end conditions are met.\n4\nOptimization Applications\
    \ in Smart Cities\nSeveral tasks in smart city operations require the use of metheuristics\
    \ to be solved,\nthe aim being to optimize the resources present in the city.\
    \ This section presents\nthe different uses of optimization techniques for IoT\
    \ enabled Smart Cities.\nThis\ntask is performed for all eight components, Smart\
    \ Agriculture, Smart City Services,\nSmart Grid, Smart Health, Smart Homes, Smart\
    \ Homes, Smart Industry, Smart\nInfrastructure and Smart Transportation.\n4.1\n\
    Smart Agriculture\nSmart Agriculture involves the use of digital technologies\
    \ such as sensors and in-\ntelligent systems to improve agricultural productivity.\
    \ The sustenance of agriculture\ndepends on water, and it is central to the agricultural\
    \ production of food items around\nthe world. However, water is becoming an ever-scarce\
    \ resource due to the increasing\ndemand caused by human population growth, increased\
    \ economic activity by indus-\ntries and also due to climate change. It therefore\
    \ is necessary to utilize this precious\nresource wisely so as make use of it\
    \ in the best manner possible.\nOne approach\ntowards ensuring that water and\
    \ land is used appropriately is by introducing irriga-\ntion management schemes\
    \ such as irrigation scheduling and water allocation in the\nfarming process.\
    \ A summary of the optimization problems, objectives, constraints in\nsmart agriculture\
    \ and the use of IoT is illustrated in Figure 8.\nMeasurements in water irrigation\
    \ systems are typically performed by sensors\nplaced at different points in the\
    \ canals and rivers to determine water flow, volume and\nspeed. This information\
    \ regarding water movement can be combined with economic\ninformation such as\
    \ yeild, crop profit to optimize water distribution. Irrigation man-\nagement\
    \ through scheduling has been performed by the authors of [255, 256, 257, 258]\n\
    to maximize net return on crop profits, water use efficiency and to minimize leakage\n\
    losses. In [259] Fuqiang et al. aim to optimize water delivery through canals\
    \ while\nalso performing scheduling. They do this using a genetic algorithm and\
    \ work with\ntwo objectives, minimizing the difference between the time of water\
    \ delivery and wa-\nter demand and the fluctuation in water discharge of the main\
    \ canal. Their model\nwas applied to a district in China.\nThe authors in [260,\
    \ 261] work on optimal allocation of water. Of these, Ikudayisi\net al. [260]\
    \ use the differential evolution algorithm to minimize the water allocated to\n\
    53\nSmart Agriculture \nIrrigaƟon\nWater\nScheduling \nIrrigaƟon\nWater\nAllocaƟon\
    \ \nEnergy\nOpƟmizaƟon\nand Water\nControl \nObjectives: Minimize\nwater\nusage/deviation/leakage\n\
    Maximize benefits\nConstraints: Land area\navailable, water limits\nObjectives:Minimize\n\
    leakage \nMaximize net return,\nwater usage \nConstraints: Water\nlimits, capacity\
    \ of\nirrigation system, flow\ncapacity, discharge\nlimits, time limits\nObjectives:\
    \ Minimize\nenergy cost \nConstraints: Limited\nenergy available, water\nvolume\
    \ minimums\nIoT Usage: Sensors provide information about water flow, amount of\
    \ water and more\nConstraints: Water\nlimits, capacity of\nirrigation system,\
    \ flow\ncapacity, discharge\nlimits, time limits\nFigure 8. Optimization applications\
    \ in Smart Agriculture.\nfarms in South Africa while maximizing the benefits in\
    \ terms of job creation, ensuring\nfood security and the yield of crops.\nWu et\
    \ al.\n[261] approach this as problem\nof reducing deviation between different\
    \ channels and minimizing water seepage to\nensure a more consistent supply to\
    \ all water channels. An approach presented by\nOcampo et al. [262] tackles this\
    \ problem not as a task of allocation directly but\nconsiders the scenario of\
    \ providing sufficient water to a smart farm while controlling\ntwo water pumps.\
    \ The objective function is formulated to minimize the energy cost\nof the water\
    \ pumps while maintaining sufficient supply of water to the plants on the\nfarms.\
    \ Constraints considered for such applications include the limited quantities\
    \ of\nwater being worked with, the time for which the water was available and\
    \ the area\nof land which was to be considered. Another allocation based scheme\
    \ is presented\nby Zhuo et al. [263] who use a genetic algorithm for an irrigation\
    \ system based on\na reservoir and two pumping stations. Their aim is to ensure\
    \ that there is no water\n54\nshortage. The objective function used by them is\
    \ the minimization of the annual sum\nof squared water shortage. Other work in\
    \ [264] also minimizes use of groundwater\nand increase benefit to the regional\
    \ water supply through reduction of water deficits\nin the Dujiangyan region of\
    \ China.\nA precision agriculture scheme is presented by Roy et al.\n[265] who\
    \ combine\nan IoT system consisting of sensors on plants using a GA based rainfall\
    \ predictor.\nCombining predicted rainfall information along with the sensed moisture\
    \ level in\nthe crops, they control plant watering. Lin et al. [266] propose a\
    \ framework for the\nmanagement of fertigation and irrigation in precision agriculture.\
    \ They perform short\nterm management and long-term management. Soil and crop\
    \ growth data is gathered\nfrom IoT based sensor systems. Long term planning refers\
    \ to the allocation of water\nand fertilizer resources to crops in terms of quantity\
    \ so as to meet demands whereas\nshort term refers to when and how to use them.\
    \ They use a genetic algorithm for long\nterm planning considering the allocation\
    \ of water and fertilizer for crops to maintain\npH value and electrical conductivity.\
    \ This information has been presented in Table\n16 while a summary of the identified\
    \ data sources used by each considered work has\nbeen provided in Table 17.\n\
    4.2\nSmart City Services\nAccording to the world bank, the amount of annual solid\
    \ waste generated is set to be\n3.40 billion tons [268] in 2050. Managing this\
    \ waste and its collection in an efficient\nmanner is imperative for health and\
    \ climate reaons. The most common application\ntowards smart city services optimization\
    \ is waste management as illustrated in Figure\n9 which summarizes the objectives,\
    \ constraints and the use of IoT.\nSmart waste collection systems include sensors\
    \ attached to trash cans which can\ninform the municipal authority about the status\
    \ of the garbage amount present in\nthem.\nOnce the trash cans are close to being\
    \ full, it is the responsibility of the\nmunicipal corporation to perform garbage\
    \ collection in an efficient manner. In this\nrespect, data provided by the sensors\
    \ on garbage cans can be used to determine\nan optimized route for garbage collection\
    \ to construct the Vehicle Routing Problem\n(VRP) in the Smart City Services domain.\
    \ As such, this problem has been performed\nkeeping in view various goals. The\
    \ minimization of the route distance taken by a\ngarbage tuck has been performed\
    \ by the authors in [269, 270, 271, 272, 273]. The\naim in this case is to determine\
    \ a route for garbage collection vehicles that minimizes\nthe total distance traveled\
    \ by the them. Zhang et al. [273] consider multi-vehicle\nallocation while considering\
    \ the single objective of minimizing route distance. Wei\net al. [274] use the\
    \ Artificial Bee Colony algorithm to determine garbage collection\nroutes resulting\
    \ in the minimum emission of CO2. Another optimization objective\nin route optimization\
    \ for waste management has been the minimization of the total\ntravel time, such\
    \ a target is described by the authors of [275, 276, 277, 278] who aim\nto reduce\
    \ travel time while considering emptying of waste bins. Another optimization\n\
    consideration in route optimization for waste management is to reduce cost. This\
    \ has\nbeen carried out by Tirkolaee et al. [279] who formulate a multi-objective\
    \ function of\ntravel cost and total useage cost of vehicles and determine the\
    \ route with the minimum\n55\nTable 16. Optimization in Smart Agriculture\nApplication\n\
    Algorithm\nSingle/\nParallel\nproblems\nObjectives\nConstraints\nIrrigation Management\
    \ (Ir-\nrigation Water Scheduling)\nACO [255]\nSingle\nMaximizing net return on\
    \ crop\nConstraint on water avail-\nability\nPSO [256]\nCapacity of irrigation\
    \ sys-\ntem\nWater\nsavings\nshould\nbe\nmore than deficiency\nGA [259]\nSingle\n\
    Minimize water fluctuations and\ndifference between the time of wa-\nter demand\
    \ and need\nFinite canal capacity\nMaximum rotation time lim-\nitation\nGA [257]\n\
    Parallel\nMaximize yield, global and local\nwater use efficiencies\nConstraint\
    \ on irrigation in-\nterval\nMinimum and max irriga-\ntion amount\nGA [258]\n\
    Parallel\nMinimize leakage loss both individ-\nually and overall\nFlow\ncapacity\n\
    limited\nby\nmaximum\nIrrigation time constraint\nNet discharge constraint\nTotal\
    \ flow rate should be\nsum of individual flowrates\nIrrigation Management (Ir-\n\
    rigation Water Allocation)\nDE [260]\nSingle\nMinimize irrigation water allocated\n\
    and maximizes net benefits\nConstraint on the land area\navailable\nMinimum and\
    \ max planting\nareas for crops\nLimited water available for\nthe farm\nPSO [261]\n\
    Parallel\nMinimize deviation in the different\nchannels, water seepage in the\
    \ dis-\ntribution channels\nTime\nWater quantity constraints\nGA [264]\nParallel\n\
    Maximize benefit to regional wa-\nter supply, minimize water deficit\ngroundwater\
    \ exploitation in regions\nWater supply quantity con-\nstraints for annual water,\n\
    ground water\nIrrigation Management (En-\nergy Optimization)\nGA [262]\nParallel\n\
    Minimize energy cost while main-\ntaining water supply for plants\nLimited energy\
    \ available\nWater volume maintained in\nstorage tank, fish pond\nGA [263]\nSingle\n\
    Minimize sum of squared water\nshortage\nAnnual water availability in\nreservoir\n\
    Water rights of replenish-\nment pumping station\nWater rights of the irrigation\n\
    pumping station\nOperational rule constraints\nIrrigation\nManagement\n(Water\
    \ Control)\nGA [267]\nSingle\nMaximize yield\nMinimum\nand\nmaximum\nwater depth\
    \ limits\nMin and max soil moisture\nIrrigation\nand\nFertilizer\nManagement\n\
    GA [266]\nSingle\nMaximize economic profits and en-\nvironmental benefits\nLimits\
    \ on the demand of wa-\nter for each crop\nTotal water does not exceed\navailable\n\
    Total fertilizer doesn’t ex-\nceed availability\nWater allocation should be\n\
    positive\nTable 17. Data setup used for Smart Agriculture Optimization\nData Type\n\
    Papers\nSelf-collected / Presented\n[256, 258, 259, 262, 267, 266]\nGovernment\
    \ and private agencies\n[260, 256, 255, 267, 259, 257, 258, 261]\n56\nSmart City\
    \ Services \nWaste Management\nRoute OpƟmizaƟon \nObjectives: Minimize\ndistance,\
    \ CO2\nemissions, travel time\nConstraints: Road\nnetwork fixed, location\nserved\
    \ by one truck,\ncontinuous routes,\ndeadline to finish jobs,\ncapacity limited\n\
    IoT usage: Sensors for\ntrash fill level and\nweight detection\nFigure 9. Optimization\
    \ applications in Smart City Services.\ncosts using the ACO. Constraints considered\
    \ in such applications are related to a\nfixed road network which depends on the\
    \ locality for which the optimization is being\nperformed, the continuity in the\
    \ determined route as well as fulfillment of capacity\nrestrictions. The useage\
    \ of optimization algorithms in smart city services is provided\nin Table 18 and\
    \ the data sources used are provided in Table 19.\n4.3\nSmart Grid\nThe electricity\
    \ grid has been a major beneficiary of smart city technologies. The in-\ncreasing\
    \ demand for energy by consumers along with the environmental impact that\nfossil\
    \ fuel-based energy production has on the planet has forced utility companies\n\
    to introduce renewable energy sources within the electricity distribution system\
    \ and\nmake their energy production and distribution systems more efficient through\
    \ plan-\nning and design improvements. Optimization algorithms find applications\
    \ within the\nsmart grid domain in terms of power management and planning.\nA\
    \ summary of\n57\nTable 18. Optimization in Smart City Services\nApplication\n\
    Algorithm\nSingle/\nParallel\nproblems\nObjectives\nConstraints\nWaste\nManagement\n\
    Route Optimization\nACO [269]\nSingle\nMinimization of distance\nRoad Network\
    \ is fixed\nGA [270, 271,\n273]\nEach dumpster served by\none truck only\nTrucks\
    \ leave depot to go to\nlandfill\nPSO [272]\nRoutes are continuous\nABC [274]\n\
    Single\nMinimize Co2 emissions\nCapacity constraint for bins\nas well as trucks\n\
    ACO [275]\nSingle\nMinimize total travel time\nTrucks leave a depot empty\nGA\
    \ [276, 277]\nBins needs to be fully emp-\ntied by trucks\nVehicle start depot\
    \ and end\nat landfill\nPSO [278]\nDemand should not exceed\ncapacity\nACO [279]\n\
    Single\nMinimize travel cost and to-\ntal usage cost of vehicles\nSubtour elimination\n\
    Jobs should finish within a\ngiven deadline\nTable 19. Data setup used for Smart\
    \ City Services Optimization\nData Type\nPapers\nSelf-collected / Presented/ Generated\n\
    [269, 270, 271, 275, 279, 277, 273]\nGovernment Agency\n[276, 278]\nDataset\n\
    Capacitated VRP datasets [280] by [272], Capacitated VRP Instances [281] by [274]\n\
    the applications, objectives, constraints and IoT usage for optimization algorithms\
    \ in\nSmart Grids has been illustrated in Figure 10.\nAn increasing population\
    \ has led to an increasing demand for electricity around\nthe world. This burdening\
    \ of the electricity grid has led to measures for increasing\nthe performance\
    \ of the electricity distribution system by reducing loss, prevent over-\nload\
    \ and reduce cost. The authors in [282, 283, 284, 285, 286, 287, 288] work on\n\
    the improvement of grid performance by minimizing cost and reducing power losses.\n\
    Power loss minimization is specifically targeted by [282, 286, 284]. Of these,\
    \ Ettappan\net al. [282] aim for the reduction of power losses, voltage deviation\
    \ and increasing\nvoltage stability. Atteya et al. [286] also address this problem\
    \ by considering net-\nwork redistribution to minimize losses in the grid whereas\
    \ Sakr et al. [284] focuses\non minimizing transfer losses in the smart grid to\
    \ accomplish this task. Nguyen and\nMohammadi [285] attempt the reduction of power\
    \ losses and line congestion by deter-\nmining the location of thyristor controlled\
    \ series compensator devices. The problem\nis formulated as a multi-objective\
    \ problem aiming to minimize loadability of the lines,\nactive power loss and\
    \ the reactance of the transmission line. A cost reduction-based\napproach to\
    \ improve grid performance is followed by Das et al. [283] who aim to\nreduce\
    \ cost of maintaining electrical stability and also the cost of management of\
    \ the\ndistribution network. They do this by considering changing the location\
    \ of energy\nstorage systems within the grid. Kanwar et al. [287] take maximizing\
    \ profits and\n58\nSmart Grid \nPower Management \nImproved Grid\nPerformance\
    \ \nDistributed\nEnergy\nResource\nManagement \nPlanning \nExpansion of\nDistribuƟon\n\
    Network \nObjectives: Minimize power\nloss, voltage deviation,\nreactance, average\n\
    loadability, cost \nMaximize profit  \nConstraints: Power flow\nrestrictions,\
    \ location\nlimitations, operational\nlimitations. capacity limits,\nload balances,\
    \ power limits,\ntopology restrictions\nObjectives: Minimize cost,\nemissions\
    \ \nConstraints: Power limits\n(generation and\ndistribution), battery\ncharge/discharge\
    \ limits,\nload schedule restrictions,\ncapacity limits\nObjectives: Minimize\n\
    expansion cost, number of\nunits, power losses\nConstraints: Power flow\nrestrictions,\
    \ generation\nlimits, infrastructure limits\nIoT Usage: Loads and other devices\
    \ in the power network can be swithced on and off as needed. Phase\nmeasurement\
    \ units for e.g., provide capability to obtain measurements in the smart grid\n\
    Figure 10. Optimization applications in Smart Grid.\nminimization of power losses\
    \ while considering sizing of a distributed energy resource\ngeneration system.\n\
    Distributed energy resource (DER) management is another area where optimiza-\n\
    tion algorithms are used in Smart Grids. The management of distributed energy\n\
    sources within smart grids is dependent on the interconnectivity provided by IoT\n\
    in the smart grid system.\nSmart meters within the smart grid provide real-time\n\
    information relating to power consumption which can be used for controlling DER\n\
    electricity. Moreover, IoT devices allow for switching loads and generation sources\
    \ as\nrequired. This assists in creating a virtual power plant to aggregate all\
    \ energy sources\nin a DER scenario. With global warming and a changing climate,\
    \ utilities around\nthe world are increasingly incorporating various renewable\
    \ energy sources within their\ngrid which often times are an economically convenient\
    \ option as well. However, many\n59\nof these sources such as wind and solar (photo\
    \ voltaic [PV]) do not offer a consistent\nsupply of power throughout the day.\
    \ In this regard, systems such as batteries as\nwell as conventional generation\
    \ plants need to be used together along with renewable\nenergy sources. For utility\
    \ companies, it is necessary to optimize power production\nso that the maximum\
    \ amount of energy is utilized from these renewable sources so\nas to reduce cost\
    \ to the user while also maintaining the quality of service. The au-\nthors in\
    \ [289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302] provide\n\
    a management scheme for DERs to minimize cost. In this regard, the authors in\n\
    [292, 293, 294, 297, 289, 290, 300, 301, 302] all formulate the problem of distributed\n\
    energy resource management as a single objective problem where the cost incurred\
    \ is\nminimized. On the other hand, the authors in [298, 295, 291] and [299] formulate\
    \ this\nas a multi-objective problem. Azaza and Wallin [299] not only target reduction\
    \ of\nelectricity production cost but also maximize reliability of the system\
    \ while reducing\nthe environmental impact of the distribution system. It is interesting\
    \ to note that the\nimprovement of system reliability is formulated as a minimization\
    \ problem as well.\nSimilarly, Das et, al. [291] consider the reduction of both\
    \ the total cost as well as\nthe environmental cost of the system. Their considered\
    \ scenario also consists of a\nPV, Wind Turbine and battery. The constraints considered\
    \ were constraints regard-\ning power flow, limitations on power and voltage values,\
    \ power balance constraint\nand power generation constraints on the renewable\
    \ energy sources. In [289, 302], a\nDER management system is developed for a microgrid\
    \ which consists of a controllable\ncollection of energy storage and generation\
    \ sources powered by IoT devices.\nPlanning in distribution networks has been\
    \ considered by the work of [303] and\n[304]. Mahdavi et al. [303] work on expanding\
    \ transmission lines utilizing the artificial\nbee colony algorithm to minimize\
    \ cost of network expansion, power losses in load\nand generation. On the other\
    \ hand, Maji and Acharjee [304] aim to determine the\nminimum number of Phase\
    \ Measurement Units (PMUs) to make the distribution\nnetwork observable. The constraints\
    \ used were power flow and balance of power as\nwell as limits on the number of\
    \ transmission lines available. The internet of things also\nfinds usefulness\
    \ in terms of the use of Phase Measurement Units that provide voltage\nand current\
    \ measurement capabilities within smart grids to perform maintenance and\nmonitoring\
    \ operations. A summary of this discussion has been provided in Table 20\nand\
    \ the data setups used by the covered research work is presented in Table 21.\n\
    4.4\nSmart Health\nSmart health refers to the use of technology to provide better\
    \ healthcare to patients.\nThis can be in the form of developing tools for better\
    \ diagnosis of diseases or the use\nof algorithms for better planning and healthcare\
    \ delivery. The deployment of timely\nemergency vehicles to a person in need is\
    \ imperative towards providing healthcare\nservices to people. Two applications\
    \ of optimization problems within Smart Health\nare emergency vehicle routing\
    \ and their allocation and relocation as shown in Figure\n11. It also summarizes\
    \ the objectives uses, constraints considered and role of IoT.\nLate arrival of\
    \ ambulances and other emergency vehicles to people in need may\nresult in irreversible\
    \ damage to life and property. Studies have shown that delayed\n60\nTable 20.\
    \ Optimization in Smart Grid\nApplication\nAlgorithm\nSingle/\nParallel\nproblems\n\
    Objectives\nConstraints\nPower\nManagement\n(Improve Grid Per-\nformance)\nABC\
    \ [282]\nSingle\nMinimize active power loss,\nvolage deviation and voltage\nstability\
    \ index (L-index)\nPower flow constraints\nGA [284]\nRestriction on power source\
    \ instal-\nlations and other components re-\nlated to power structure\nPSO\n[286,\
    \ 288]\nSingle\nMinimize power loss\nGeneration and other component\noperations\
    \ within limits\nGA [285]\nSingle\nMinimize average percent-\nage\nof\nloadability\n\
    of\nthe\nlines, active power loss, re-\nactance of transmission line\nLimitation\
    \ on values of bus voltage\nTransmission line capacity, genera-\ntor active and\
    \ reactive power.\nABC [283]\nSingle\nMinimize cost for maintain-\ning thermal\
    \ and voltage sta-\nbility and lower asset man-\nagement of distribution net-\n\
    works\nActive and reactive power must be\nbalanced\nLimits on voltage and load\
    \ maxi-\nmum\nESS max charging and discharging\nconstraints\nPSO [287]\nParallel\n\
    Maximize annual profit by\nreducing charges for annual\nenergy losses, peak power\n\
    loses etc\nConstraint on the node voltage\n(soft)\nMinimize power loss for the\n\
    network reconfiguration\nPower injected by DER and SG\nwithin limit\nPower generated\
    \ at a given node\nhas a limit\nFor reconfiguration:\nRadial topology,\nNode voltages\
    \ has a max hard con-\nstraint\nPower\nManagement\n(Distributed Energy\nResource\n\
    Manage-\nment)\nABC\n[292, 293, 294]\nSingle\nMinimize total cost\nPower\ngeneration\n\
    by\nrenewables\nwithin limits\nDE [295, 297,\n296]\nBattery charge and discharge\
    \ limits\nand system reliability\nGA [289, 290]\nPower balance constraint (gener-\n\
    ated equal to consumed)\nPSO\n[300, 301, 302]\nSpecific loads are interruptible\n\
    Constraints on the efficiencies of the\nsources\nDE [298]\nSingle\nMinimize cost\
    \ and emission\nABC [305]\nSingle\nMinimize cost and power im-\nported from outside\
    \ micro-\ngrid\nPower flow constraints for the DER\nGA [291]\nSingle\nMinimization\
    \ of cost of en-\nergy and life cycle emissions\n(CO2 and energy stored in\nbatteries\
    \ or converted by re-\nnewable sources during pro-\ncess of satisfying load re-\n\
    quirements)\nConstraints on battery capacity\nSystem reliability constraint\n\
    Energy produced equal or greater\nsthan required\nPSO [299]\nSingle\nMinimize\n\
    reliability\ncost,\ncost of electricity production\nand operation environmen-\n\
    tal impact ()using renewable\nfactor)\nExpansion of distri-\nbution network\n\
    ABC [303]\nSingle\nMinimize cost of network ex-\npansion, active losses and\n\
    loss of load and generation\nPower flow and active power bal-\nanced\nPower generation\
    \ limits\nNumber of transmission line limits\nPSO [304]\nSingle\nMinimize number\
    \ of PMUs\nSG Network should be observable\n61\nTable 21. Data setup used for\
    \ Smart Grid\nData Type\nPapers\nSelf-collected/ Presented/ Generated\n25 Bus\
    \ network s[295, 297, 298, 291, 299, 300, 301, 302] [305]\nGovernment Agency/\
    \ other research work\n[292, 293, 294, 290, 299, 303]\nDataset/ Standard Network\n\
    IEEE 14 Bus [284, 304]\nIEEE 30 Bus [282, 284, 285]\nIEEE 33 Bus [286, 283, 287,\
    \ 296]\nIEEE 37 Bus [289]\nIEEE 57 Bus [282, 284, 304]\nIEEE 69 Bus [287]\n119\
    \ Node system of [306, 288]\nSmart Health \nEmergency\nVehicle\nAllocaƟon and\n\
    RelocaƟon \nEmergency\nVehicle RouƟng \nObjectives: Minimize time,\ncost\nConstraints:\
    \ Traffic balance,\ntraffic flow restrictions,\nvehicle speed and number\nlimits,\
    \ location of\nemergency vehicle\nObjectives: Minimize time,\nvehicle density\
    \ \nConstraints: Road connection\nrestrictions, time limits \nIoT Usage: Real\
    \ time location services, real time traffic\ninformation, vehicle to vehicle and\
    \ vehicle to infrastructure\ncommunication can also provide better navigation\
    \ and monitoring\nservices\nFigure 11. Optimization applications in Smart Health.\n\
    ambulance dispatch increases mortality [307], moreover, economically speaking,\
    \ a\none-minute delay in response time for cardiac patients found that the mortality\
    \ in-\ncreases by 1% and adds annual costs of USD 7 billion in healthcare expenditure\n\
    [308]. Keeping this in mind ambulance deployment and location determination have\n\
    been of considerable interest in the area of optimization for smart health. These\n\
    two problems are specific cases of the Vehicle Routing Problem [309] and Maximum\n\
    coverage problem [310] sometimes called the Ambulance Routing Problem [311] and\n\
    Ambulance Location Problem [312]. The authors in [313] work on the optimal allo-\n\
    62\ncation determination based on fixed sites and a finite number of ambulances\
    \ while\nminimizing lateness of ambulance arrival using the Ant Colony Optimization.\
    \ Later\non, in their work in [314], they do a comparison with using GAs and find\
    \ that GAs\nprovide better performance. Kochetov and Shamray [315] attempt localization\
    \ of\nambulance fleet at base stations with the aim to minimize the average waiting\
    \ time\nfor arrival of ambulances. An interesting approach to this problem is\
    \ presented in\nYan et al. [316] who work on this problem from a scheduling perspective\
    \ where they\ncontrol scheduling of emergency vehicles to reduce the total cost\
    \ in terms of money\nand time using a Genetic Algorithm. Another approach for\
    \ sequencing vehicles to\nensure emergency vehicles reach their destination in\
    \ time is presented by Lu et al.\n[317] who aim to prioritize emergency vehicle\
    \ thoroughfare on traffic intersections.\nThey do this by minimizing the entrance\
    \ time of the vehicle by manipulating vehicle\norder. Constraints used for these\
    \ problems include constraints on the speed of the\nambulances, the flow of vehicles\
    \ on the road, specific road connections present as well\nas time constraints.\
    \ The internet of things serves a pivotal role in enabling the allo-\ncation and\
    \ routing of emergency vehicles. The connectivity provided by IoT through\nvehicle-to-vehicle\
    \ communication as well as vehicle to infrastructure communication\nfacilitates\
    \ providing a real-time indication of the vehicle’s location as well as the con-\n\
    dition of traffic in a given area. This information can then be used to determine\
    \ an\noptimal route for emergency vehicles as well as for their optimal deployment\
    \ to serve\npeople in need. Information about optimization methods for smart health\
    \ has been\npresented in Table 22 and the data setups used in these approaches\
    \ in Table 23.\nTable 22. Optimization in Smart Health\nApplication\nAlgorithm\n\
    Single/\nParallel\nproblems\nObjectives\nConstraints\nEmergency\nVehicle\nAllocation\
    \ and Relo-\ncation\nACO [313]\nSingle\nMinimize lateness\nAmbulance\nfrom\nnearest\n\
    hospital\nis\ndispatched\nGA [314]\nSpeed of ambulance\nTotal number of am-\n\
    bulance limits\nGA [315]\nSingle\nMinimize\naverage\nwaiting\ntime of ambulances\n\
    Balance\nconstraints\non exit and entry vol-\numes\nFlow\nconservation\nconstraints\n\
    GA [316]\nSingle\nMinimize\ntotal\ncost\nin\nmoney and time\nEmergency\nVehicle\n\
    Routing\nPSO [318]\nSingle\nMinimize travel time, road\nlength traveled, density\
    \ of\nvehicles on the road\nRoad connections are\nspecific\nGA [317]\nSingle\n\
    Minimize the entrance time\nof\nemergency\nvehicle\nby\nchanging the order of\
    \ vehi-\ncles going through intersec-\ntions\nConstraint\non\nthe\ndifference\n\
    between\narrival times of cur-\nrent\nand\nprevious\nvehicles and on the\nentrance\
    \ time of the\nvehicle\n63\nTable 23. Data setup used for Smart Health\nData Type\n\
    Papers\nSelf-collected/ Presented/ Generated\n[313, 314, 315, 316, 318, 317]\n\
    Government Agency/ other research work\n[314, 315, 316]\n4.5\nSmart Homes\nHome\
    \ energy management has been the prime application of optimization in smart\n\
    homes, a summary of the objectives, constraints and the use of IoT has been shown\n\
    in Figure 12.\nSmart Homes \nHome Energy Management \nAppliance\nScheduling \n\
    Objectives: Minimize\ncost, time, peak to\naverage power ratio,\ndiscomfort \n\
    Constraints: Capacity\nlimits, flow, one level\nper location\nIoT usage: Sensors\
    \ for providing power consumption data and other environmental\nreadings such\
    \ as temperature etc for comfort determination in homes, smart meters\nprovide\
    \ interconnectivity betwen homes\nFigure 12. Optimization applications in Smart\
    \ Homes.\n64\nHome energy management refers to the development of demand side\
    \ manage-\nment schemes that aim to reduce the electricity cost billed to a customer\
    \ or maintain\ncomfort for the user. One way this is performed is by appropriate\
    \ appliance schedul-\ning. The idea here is to schedule the usage of appliances\
    \ in such a way that the\nmost power-hungry devices are turned on during off peak\
    \ hours when electricity costs\nmight be lower. The combination of the Smart Grid\
    \ and Smart Homes facilitates the\ndevelopment of optimization schemes that not\
    \ only benefit the customer (in terms\nof reduced electricity costs and maintaining\
    \ comfort) but also be useful for the util-\nities in ensuring that load profiles\
    \ (though minimizing the peak to average ratio)\nare more consistent thereby allowing\
    \ better planning of the power generation mix\nused by them. The authors of [319]\
    \ perform appliance scheduling for the purpose of\nminimizing electricity cost\
    \ and the waiting time for appliance usage. Interestingly,\nthey incorporate comfort\
    \ maintenance by adding it as a constraint. A similar ap-\nproach has been followed\
    \ by Bui et al [320] and Makhadmeh et al. [321] who aim to\nminimize the cost\
    \ of electricity usage with a constraint for maintenance of comfort.\nMakhadmeh\
    \ et al. [321] also include the reduction of waiting time rate for appliances\n\
    by the user and the reduction of the peak to average ratio of the power consumed\
    \ as\nconstraints. The authors in [322, 323, 324, 325] perform appliance scheduling\
    \ while\nconsidering electricity cost and peak to average ratio which need to\
    \ be minimized.\nAll of the authors present a multi-objective function for this\
    \ purpose combining the\nobjectives of minimizing the cost and the peak to average\
    \ power ratio. Azimi et al.\n[326] combine the problem of reducing cost and power\
    \ together as a single objective\nby considering the minimization of the ratio\
    \ of operating cost and load factor in a\nbattery supported system. The works\
    \ of [327, 328, 329, 330, 331] also consider user\ncomfort as part of the objective.\
    \ In [327], Essiet and Wang form a multi-objective\nminimization problem of electricity\
    \ cost, peak to average ratio for power and discom-\nfort of users in a smart\
    \ home supported by a renewable energy system consisting of a\nbattery and PV\
    \ system. In Chanra et al. [332], the authors aim to reduce electricity\ncost\
    \ by appliance scheduling in such a manner so as to make as much use of onsite\n\
    energy units as possible so as to reduce usage of utility provided electricity.\
    \ The\nenergy units they consider are a diesel generator, renewables and battery.\
    \ Another\napproach that aims to reduce cost of consumed electricity is presented\
    \ by Faia et\nal. [333] who formulate it as a problem of minimizing the energy\
    \ bill and the cost\nassociated with curtailment of power in a system with a battery\
    \ and a photovoltaic\nsystem. Work in [334, 330, 335, 336] also perform appliance\
    \ scheduling to reduce\ncost of electricity. Appliance scheduling for smart homes\
    \ has also been performed by\nFatima et al. [323] and Abid et al. [322] considering\
    \ a microgrid for homes where\ninstead of optimizing data from single homes, the\
    \ authors used data from connected\nsmart meters to determine an optimized control\
    \ scheme for appliances across the grid.\nThe constraints used for optimization\
    \ in smart homes are on the comfort needing to\nbe maintained, constraints on\
    \ the powerflow, time of operation, the maximum power\nthat is present or used\
    \ and which appliances are switchable appliances. Appliance\nscheduling is based\
    \ on smart meters as well as individual control and monitoring of\nappliances\
    \ using IoT systems. IoT devices enable the microgrid which is used to\ngather\
    \ data as well as control the switching on and off of sources from the houses\n\
    65\nelectricty supply. The information gathered from these IoT units can be processed\n\
    to optimize energy consumption patterns to reduce cost to the customer as well\
    \ as\nincrease comfort. The use of the considered optimization schemes for smart\
    \ homes\nhas been presented in Table 24 with the data setups presented in Table\
    \ 25.\n4.6\nSmart Industry\nOne of the biggest enablers of the Industry 4.0 concept\
    \ has been the use of AI tech-\nniques to improve the efficiency of the manufacturing\
    \ and production process. This\nhas led to the development of cyber physical systems\
    \ aiming to assist in activity recog-\nnition [339], machine health prediction\
    \ [340] and production management in terms of\nbottleneck prediction [341]. Apart\
    \ from conventional AI applications of anomaly de-\ntection, classification and\
    \ regression, computational optimization also finds numerous\napplications as\
    \ it fits well with the objective of efficient and streamlined manufac-\nturing.\
    \ The major applications for the use of computational optimization have been\n\
    in the area of routing and location for logistics and are variations of the vehicle\n\
    routing problem and are typically represented as Multidepot Vehicle Routing Prob-\n\
    lem (MVRP), Vehicle Routing Problem Pick-up and Delivery with Time Windows\n(VRPPDTW)\
    \ or Large-scale Dynamic Vehicle Routing Problem (LSDVRP). Figure\n13 summarizes\
    \ the objectives utilized, constraints and the role of IoT in optimization\nfor\
    \ Smart Industry.\nThe authors in [342] and [343] use the ABC and the GA respectively\
    \ to determine\nthe best location of service sites for logistic operations. Both\
    \ these approaches use\nmulti-objective formulations aiming to reduce cost of\
    \ operations, transportation as\nwell as the establishment of the centers. The\
    \ authors in Su et al. [344] use ACO,\nAlinaghia et al. [345] PSO and Utama et\
    \ al. [346] use ABC to address the problem\nof determining the best route for\
    \ logistics operations.\nThe routing and coverage\nproblem for logistics involves\
    \ determining the best route for either a single or multiple\nvehicles at a depot\
    \ which have to visit every customer. The works of [344, 345, 346]\nfocus on reducing\
    \ the cost incurred in the routing for vehicles in logistics as a single\nobjective\
    \ formulation. On the other hand, the authors of [347, 348] and [349] all\nwork\
    \ on the minimization of distance as their objective in determining the optimal\n\
    route for delivery vehicles trying to serve multiple locations.\nMounia and Bachir\n\
    [348] address routing in logistics as a multi-objective problem where they not\
    \ only\naim to minimize the distance traveled by the vehicles but also aim to\
    \ reduce CO2\nemissions and the number of vehicles used. A time based optimization\
    \ approach is\npresented by the authors of [350] and [351] with [350] also factoring\
    \ in reduction of fuel\nconsumption in their objective function formulation. Constraints\
    \ used for the routing\nand location determination problem are related to time,\
    \ capacity constraints for the\nvehicles, each customer being served only once,\
    \ constraints related to the route. The\ndetermination of the location and the\
    \ route for vehicles is dependent on real time\ninformation concerning the traffic\
    \ in the area as well as the loads to be collected from\neach site in addition\
    \ to other information which can be provided by IoT units. The\nusage of optimization\
    \ algorithms for smart industry has been presented in Table 26\nwith data setups\
    \ presented in Table 27.\n66\nTable 24. Optimization in Smart Homes\nApplication\n\
    Algorithm\nSingle/\nParallel\nproblems\nObjectives\nConstraints\nHome Energy Man-\n\
    agement\nACO [319]\nSingle\nMinimize cost and waiting\ntime\nComfort needs to\
    \ be main-\ntained\nACO [322]\nParallel\nMinimize cost and peak to\naverage ratio\n\
    Power flow constraints\nACO [323]\nSingle\nMinimize cost and peak to\naverage\
    \ ratio\nMaximum energy capacity\nconstraint\nDE [324]\nDevice counted that can\
    \ be\nshifted is positive\nPSO [325]\nNumber of devices shifted at\nany time should\
    \ not be more\nthan the available number of\ncontrollable devices\nGA [337]\n\
    Single\nMinimize peak to average\nratio for load shaping\nLoad shaping, redistribution\n\
    of load in a flexible manner\nGA [326]\nSingle\nMinimize ratio of operating\n\
    cost and load factor\nCharging and discharging of\nbatteries\nComplete load transfer\
    \ and\nload clipping limits\nDE [327]\nSingle\nMinimize\nelectricity\ncost,\n\
    peak\nto\naverage\nratio\nof\npower and discomfort mini-\nmization of users\n\
    Constraints on PV supply\nlimits\nACO [328]\nState of charge and rate of\ndischarge\
    \ of battery\nDE [329]\nSingle\nMinimize\nelectricity\ncost\nand discomfort\n\
    Time of operation within\nspecified limits\nPSO [331]\nTemperature,\nair\nquality,\n\
    illumination\nand\nenergy\nshould be within maximum\nlimits\nGA [330, 338,\n305]\n\
    Parallel\nA given appliance must be\non for specified times of the\nday\nPower\
    \ limits to be followed\nABC [320]\nSingle\nMinimize cost of electricity\nAppliances\
    \ for comfort have\nfixed times\nDE [332, 334]\nSome appliances cannot be\ndelayed\n\
    GA [335]\nPower balance constraints\nPSO\n[321, 336]\nSurplus\nsolar\npower\n\
    sold\nback to distribution system\nMaintain zero net energy in\nbuilding\nTime\
    \ constraints\nLoad safety factor\nLoad phases of appliances\nfulfill energy requirements\n\
    Comfort needs to be main-\ntained\nPeak to average power ratio\nbalancing\nPSO\
    \ [333]\nSingle\nMinimize\nenergy\nbill\nand\ncost associated with KWH\ncurtailment\n\
    Power\nvalues\nwithin\nlim-\nits, battery charge and dis-\ncharge limits\nTable\
    \ 25. Data setup used for Smart Homes\nData Type\nPapers\nSelf-collected/ Presented/\
    \ Generated\n[322, 319, 323, 324, 325, 326, 327, 329, 305, 338, 330, 320, 334,\
    \ 335, 321, 336]\nGovernment Agency/ other research work\n[322, 323, 337, 327,\
    \ 338, 331, 332, 321, 333]\n67\nTable 26. Optimization in Smart Industry\nApplication\n\
    Algorithm\nSingle/\nParallel\nproblems\nObjectives\nConstraints\nLocation determina-\n\
    tion for sites\nABC [342]\nSingle\nMinimize\ntransportation\nand hub establishment\
    \ cost\nSingle allocation for each de-\nmand node\nA given number of hubs are\n\
    established\nCovering radius constraint\nTime reliability constraint\nGA [343]\n\
    Parallel\nMinimize distribution cost\nand maximize profit\nLoad capacity meets\
    \ needs\nof customers\nA delivery vehicle can only\nbe delivered when it receives\n\
    a task\nCapacity constraints\nRouting for Logistics\nABC [348]\nParallel\nMinimize\
    \ distance travelled,\nCO2 emissions, number of\nvehicles used\nEvery customer\
    \ visited only\nonce\nEvery vehicle visiting a loca-\ntion must leave it too\n\
    Ensure route continuity\nDemands of any route must\nnot exceed capacity\nEdges\
    \ satisfying time win-\ndow constraint are allowed.\nABC [349]\nSingle\nMinimize\
    \ total transporta-\ntion distance\nEach customer served only\nonce\nGA[347]\n\
    Route should start and end\nat the same depot\nServed demand of each vehi-\ncle\
    \ does not exceed capacity\nlimit\nACO [344]\nSingle\nMinimizing total cost\n\
    Each customer served only\nonce\nPSO[345]\nDispatched\nvehicles\nnot\nmore than\
    \ available\nABC [346]\nVehicle routes don’t contain\ndisconnected routes\nCustomer\
    \ demand shouldn’t\nbe larger than vehicle capac-\nity\nABC [351]\nSingle\nMinimize\
    \ travelling time\nVehicle load constraint\nSubtours not allowed\nSpeed, time\
    \ and distance\nMaximum number of vehi-\ncles on a route\nEach customer served\
    \ by one\nvehicle\nVehicle number max limit\nPSO [350]\nParallel\nMinimize fuel\
    \ consumption\nand travel time\nEach customer serviced by\nonly one vehicle\n\
    Continuity in route\nVehicle\nload\nconservation\nbetween nodes,\nFirst\nin\n\
    first\nout\nproper\nwhen traveling time is com-\nputed\nTime taken for customers\
    \ as\nstated,\nMaximum time for servicing\nVehicle capacity constraint\nDepot\
    \ is the first and final\ndestination of each vehicle\n68\nSmart Industry \nLocaƟon\
    \ DeterminaƟon of sites \nRouƟng for LogisƟcs \nObjectives: Minimize\ntransportation,\n\
    establishment and\ndistribution cost, Maximize\nprofit\nConstraints: Number of\n\
    sites need to be met,\ndistance coverage for\nlocations, time limits,\ncapacity,\
    \ demands need to\nbe met\nObjectives: Minimize\ndistance travelled, CO2\nemissions,\
    \ number of\nvehicles, time, fuel, cost\nConstraints: Customer\nserved only once,\
    \ route is\ncontinuous, demand limits,\nvehicle count limits,\nvehicle load limits,\
    \ speed,\ntime and distance limits,\ntime limits\nIoT Usage: Sensing units provide\
    \ information relating to the loads to be\ncollected as well as traffic and other\
    \ information\nFigure 13. Optimization applications in Smart Industry.\n4.7\n\
    Smart Infrastructure\nWithin the infrastructure domain, the most common optimization\
    \ problem is the\narea of health monitoring of structures. Structural Health Monitoring\
    \ (SHM) is a\nnecessary application within the smart infrastructure domain as\
    \ it makes for safe\nusage of different structures of public use.\nThese structures\
    \ can be buildings as\nwell as transport structures such as bridges, tunnels.\
    \ Structural health monitoring\ntypically involves the use of sensors attached\
    \ to a structure at several points that can\ngauge some type of physical variable\
    \ (vibration, strain, acceleration, temperature,\ntilt etc) from the structure.\n\
    Data gathered from these connected sensors is then\nused to determine if any structural\
    \ damage has taken place or not.\nWithin the\ndomain of SHM, optimization algorithms\
    \ find application towards the Optimal Sensor\n69\nTable 27. Data setup for Smart\
    \ Industry\nData Type\nPapers\nSelf-collected / Presented/ Generated\n[342, 343,\
    \ 347, 351]\nGovernment Agency/ other research work\n[348, 349, 344, 346, 351]\n\
    Dataset/ Standard Network\nTest instances in [352] used by [345] and [350]\nPlacement\
    \ (OSP) Problem as illustrated in Figure 14. Figure 14 summarizes the\nobjectives\
    \ used, constraint and the use of IoT.\nSmart Infrastructure \nOpƟmal Sensor Placement\
    \ \nObjectives: Minimize error,\nredundancy \nMaximize sensor coverage,\nconnectivity,\
    \ relaibility\nConstraints: Sensor placement\nlocations limitations, number of\n\
    sensors limited\nIoT usage: The placement of sensors\nespecially is performed\
    \ using IoT\nwhere connected sensors povide the\ndata using which optimization\
    \ is\nperformed\nFigure 14. Optimization applications in Smart Infrastructure.\n\
    For the optimal sensor placement problem, the aim is to determine the best num-\n\
    ber and placement of sensors over a structure so as to reduce the number of sensors\n\
    used as well as improve the measurement process, both these aims result in increased\n\
    reliability of the SHM system as well as potentially lower the cost of the system\n\
    too. The authors in [353, 354, 355, 356, 357] work on the placement of sensors\
    \ for\nstructural health monitoring focusing on improving the effectiveness of\
    \ the deployed\nsystem. In this regard, [353] and [356] use the genetic algorithm\
    \ to solve a multi-\nobjective problem aiming to minimize the measurement error\
    \ and cost. Yang et al.\nin [355] formulate OSP as single objective minimization\
    \ where they aim to reduce\nthe ratio of sensor placement performance to the redundancy\
    \ of information resulting\nfrom each tested placement. Another approach that\
    \ works on the error is presented\nby [354] who use the Particle Swarm Optimization\
    \ to maximize the reconstruction\n70\nTable 28. Optimization in Smart Infrastructure\n\
    Application\nAlgorithm\nSingle/\nParallel\nproblems\nObjectives\nConstraints\n\
    Sensor placement\nGA [353]\nSingle\nMinimize measurement er-\nror and measurement\
    \ cost\nPSO [354]\nSingle\nMaximize\nreconstruction\naccuracy\nand\nrobustness\n\
    of\ntransfer\nrelationship\nbetween\ndeformation\ndis-\nplacement and surface\
    \ strain\n(formulated as a minimiza-\ntion\nproblem\nfor\nnegated\naccuracy and\
    \ robustness)\nSensor\nplacements\nwithin\npredefined range and angles\nGA [355]\n\
    Single\nMinimize the ratio of sen-\nsor placement performance\nto redundancy information\n\
    Sensor placement is permit-\nted on chosen location\nGA [356]\nSingle\nMinimize\
    \ the MAE between\nthe system and the esti-\nmated response (global er-\nror)\
    \ and minimize the maxi-\nmum difference between the\nsystem and its estimated\
    \ re-\nsponse (local error)\nSensor locations are from a\nset of predefined locations\n\
    DE [357]\nSingle\nMaximize quality of cover-\nage,\nlifetime,\nconnectivity\n\
    uniformity of sensor nodes\nand cluster heads and relia-\nbility\nConstraint on\
    \ the number\nof cluster heads associated\nwith each sensor node and\ncluster\
    \ head\nGA [358]\nSingle\nMinimize cross correlation of\nthe sensing network\n\
    Sensor placement is permit-\nted on chosen location\nTable 29. Data types for\
    \ Smart Infrastructure\nData Type\nPapers\nSelf-collected/ Presented/ Generated\n\
    [353, 354, 355, 356, 358, 358, 359, 360]\naccuracy and robust transfer relationship\
    \ between the deformation and surface strain\nwith different sensor placements.\
    \ It must be noted that the objective function is for-\nmulated as minimization\
    \ of negated accuracy and negated robustness measurement.\nOptimized structural\
    \ health monitoring for aircraft monitoring has been targeted\nin [358]. In their\
    \ setup consisting of vibration sensors, the authors optimize sensor\nplacement\
    \ by minimizing the cross correlation of the vibration waves in the sensing\n\
    network. The most common constraint for sensor placement is restrictions on the\n\
    places where sensors can be placed. This information has been provided in Table\
    \ 28\nand the data setups are presented in 29.\n4.8\nSmart Transportation\nOne\
    \ of the most popular optimization applications within smart cities are within\
    \ the\nsmart transport domain. These include parking system routing, traffic signal\
    \ control\nand scheduling. A summary of the applications, their objectives, constraints\
    \ and the\nrole of IoT is illustrated in Figure 15.\n71\nSmart TransportaƟon \n\
    Traﬃc Signal\nControl \nTraﬃc RouƟng \nParking System\nRouƟng \nRoad Traﬃc\nRouƟng\
    \ \nObjectives: Minimize\ntime delay\nConstraints: Traffic\nvolume constraint,\
    \ traffic\nflow constraint, duration\nof traffic light phases \nIoT usage: For\
    \ parking, IoT nodes indicate to free parking spots from which data is\ngathered\
    \ and sent to the cloud. Connected vehicles are also another source of IoT data\n\
    used for navigation purposes along with data from cellphones. \nObjectives: Minimize\n\
    travel distance, traffic\ncongestion\nConstraints: Roadmap\nto be followed is\
    \ fixed,\nroad connections fixed \nObjectives: Minimize\ntravel time, delay,\n\
    emissions, traffic flow\nConstraints: Road\nconnections are fixed,\nnumber of\
    \ routes are\nfixed \nFigure 15. Optimization applications in Smart Transportation\n\
    Smart transport systems consist of sensors along roads and traffic intersections\n\
    to measure relevant parameters while also providing communication services between\n\
    vehicles and infrastructure. This allows for measurement of the current state\
    \ of roads\nin terms of traffic congestion and usage thereby allowing for the\
    \ use of optimization\ntechniques to improve trip experiences for users and make\
    \ the transportation system\nmore efficient. The authors in [361, 362, 363, 364,\
    \ 365] work on the minimization\nof time (wait and travel) in traffic signal control.\
    \ The aim of such systems is to\nreduce traffic build up on signal intersections.\
    \ Of these, the work in [361, 362] and\n[363] use the artificial bee colony and\
    \ the genetic algorithm respectively for a single\nobjective function of minimizing\
    \ delay time. An interesting approach for this problem\nis presented by Li et\
    \ al. [365] who use a multi objective formulation targeting the\nminimization\
    \ of the average travel time both overall and individually for all vehiclesl.\n\
    Another multi-objective approach in traffic signal control is presented by Chen\
    \ and\nYuan [366] who form a mixed problem of minimizing vehicle emissions and\
    \ travel\ntime together. Korkmaz [367] work on the estimation of delays in traffic\
    \ signals using\na genetic algorithm, they use it to minimize the difference between\
    \ the estimated\n72\nand simulated values.\nTang et al.\n[364] carry out distributed\
    \ optimization in a\nfog and cloud hierarchy.\nFirst, fog nodes optimize phase\
    \ timings within a single\ncycle and if the number of vehicles exceeds a threshold,\
    \ the results are sent to the\ncentral controller to further optimize over different\
    \ cycles so that a traffic jam is\navoided or alleviated. Zhang et al. [368] attempt\
    \ traffic signal optimization using\nmulti objective optimization functions of\
    \ reducing time delay and increasing traffic\ncapacity.\nConstraints used for\
    \ traffic signal control are timing constraints on the\nphase durations, flow\
    \ rate of vehicles and on the travel time.\nTraffic routing is also another important\
    \ aspect in smart transportation. This\ntypically involves the determination of\
    \ the best route to the destination keeping in\nview various criteria such as\
    \ reduction of distance, time, cost etc.\nThe problem\nof traffic routing is addressed\
    \ by the works of [369, 370, 371, 372, 373, 374, 375,\n376, 377, 378, 379]. The\
    \ authors in [369] and [370] use the ant colony optimization\nand genetic algorithm\
    \ to minimize the travel distance in parking system routing.\nThey aim to minimize\
    \ distance traveled by a driver looking to find a free parking\nspot, using the\
    \ algorithm, an optimized route is determined for the parking spot.\nIn, [371,\
    \ 373] and [372] the ant colony optimization algorithm is used to determine\n\
    the best route in a generic traffic scenario where cars can communicate with road\n\
    side units in a VANET architecture. Routing for public transport is performed\
    \ by\n[380] and [375] in a connected vehicle scenario aiming to minimize travel\
    \ time. An\neconomic objective approach to traffic routing is taken by the authors\
    \ of [376, 378]\nand [379] who minimize the total cost of the trip.\nMao [379]\
    \ also include traffic\ncongestion and travel time as well in their computation.\
    \ Hassoune et al. [381] work\non a parking guidance using the ant colony optimization\
    \ algorithm to reduce traffic\ncongestion and minimize distance. Constraints for\
    \ traffic routing are related to the\nroad network allowing travel in specific\
    \ directions, signaling and travel time. Within\nsmart transportation, IoT nodes\
    \ are used to determine occupied parking spaces and\nthis data is used for routing\
    \ applications in parking. Traffic routing is based on vehicle\nto vehicle and\
    \ vehicle to infrastructure communication provided by VANETs within\nthe IoT framework.\
    \ These systems enable cars to exchange data with each other and\nalso with fixed\
    \ infrastructure on the roads. This discussion is also presented in Table\n30\
    \ and the data setups for the covered work are presented in Table 31.\n5\nConclusion\n\
    This chapter provides coverage of the application of five popular computational\
    \ algo-\nrithms in the IoT enabled Smart City. It provides a mapping of the various\
    \ applica-\ntions to the specific smart city domain as well as highlights the\
    \ different formulations\nof the objective function used to solve the considered\
    \ problem. This coverage is pro-\nvided in terms of the number of objectives as\
    \ well as whether the problem was solved\nas a single objective, in a hierarchical\
    \ manner or otherwise. It also highlights the con-\nstraints used by the researchers\
    \ in solving the problem which is an important aspect\nas constraints are governed\
    \ by the application at hand. An overview of the mapping\nof various smart city\
    \ optimization applications derived from this work is provided in\nFigure 16.\n\
    73\nTable 30. Optimization in Smart Transportation\nApplication\nAlgorithm\nSingle/\n\
    Parallel\nproblems\nObjectives\nConstraints\nTraffic signal control\nABC [380]\n\
    Single\nMinimize travel time\nInterval of feasible green\ntime length values\n\
    ABC [374]\nInterval of feasible offset\ntime length values\nConstraints\non\n\
    cycle\nlengths\nABC\n[361, 362]\nSingle\nMinimize time delay\nOnly one active\
    \ stage\nGA [363, 364]\nFlow dynamic constraint\nGA [365]\nParallel\nMinimize\n\
    time\ndelay\nand\nalso achieve traffic network\nequilibrium\nLink volume constraint\n\
    Constraints on duration\nof green/red phases\nOffset phase duration\nMinimize\
    \ average travel\ntime.\nRelationship\nbetween\nroute\nand\nlink\nflows\nneed\
    \ to be maintained\nas defined\nGA [366]\nSingle\nMinimize vehicle emissions\n\
    and travel time for vehicles\nSum of green time of\neach phase is equal to to-\n\
    tal available green time\nGreen time is set by a\nlower bound\nGA [368]\nParallel\n\
    Minimize delay, and exhaust\nemission and maximize traf-\nfic capacity (formulated\
    \ as\nminimization problem)\nCycle length of signals\nhas minimum and max-\nimum\
    \ limits\nTraffic\nRouting\n(Parking System)\nACO [369]\nParallel\nMinimize\n\
    distance\nwith\nbend straightening and turn\nreduction\nBend straightening and\n\
    turn reduction\nACO [381]\nParallel\nReduce\ntraffic\nflow\nand\nshortest\ndistance\n\
    towards\nparking\nGA [370]\nSingle\nMinimize distance\nSpecific prefixed routes\n\
    possible for free parking\nTraffic\nRouting\n(Road Traffic)\nACO\n[371, 373]\n\
    Single\nMinimize distance, minimize\ncongestion\nFollow roadmap\nACO [372]\nSingle\n\
    Maximize flow\nACO [375]\nSingle\nMinimize travel time\nConstraint on relation-\n\
    ship between green time\nlengths cycle length, off-\nset on the network calcu-\n\
    lation\nGA [377]\nInterval of feasible green\ntime length values\nInterval of\
    \ feasible offset\ntime length values\nSpecific road segments\nConnected\nconstraints\n\
    on the values of time\ntaken for vehicles\nDE [376]\nSingle\nMinimize travelling\
    \ cost and\nrental cost\nEach bus has one em-\nployee\nEmployees\ncan\nbe\nas-\n\
    signed when stop is avail-\nable\nBus stop assigned when\nbus is in use\nConstraint\
    \ on distance of\nbus stop from employee\nhome and more\nDE [378]\nSingle\nMinimize\
    \ total cost\nRoad\nnetwork\nconnec-\ntions followed\nSolutions contains cor-\n\
    rect number of routes\nACO [379]\nSingle\nMinimize\ntransit\ntime,\ntravel distance,\n\
    road con-\ngestion and traffic expenses\nVariable\nvalue\ncon-\nstraints\n74\n\
    Table 31. Data types for Smart Transportation\nData Type\nPapers\nSelf-collected\
    \ / Presented/ Generated\n[374, 362, 361, 363, 364, 365, 366, 368, 369, 381, 370,\
    \ 371, 373, 372, 380, 377]\nGovernmentAgency/ other research work\n[361, 365,\
    \ 366, 370, 374, 375, 377, 376, 378, 363]\nSmart\nAgriculture \nIrrigaƟon Water\n\
    Scheduling \nSmart Homes \nHome Energy\nManagement \nSmart City\nServices \nWaste\n\
    Management\nRoute\nOpƟmizaƟon \nSmart Industry \nSmart Grid \nPower\nManagement\
    \ \nPlanning \nSmart\nInfrastructure \nOpƟmal Sensor\nPlacement \nSmart Health\
    \ \nEmergency\nVehicle\nAllocaƟon and\nRelocaƟon \nEmergency\nVehicle RouƟng \n\
    Smart Transport \nTraﬃc Signal\nControl \nTraﬃc RouƟng \nOpƟmizaƟon in Smart CiƟes\
    \ \nRouƟng and\nLocaƟon\nDeterminaƟon\nfor LogisƟcs \nIrrigaƟon Water\nAllocaƟon\
    \ \nEnergy\nOpƟmizaƟon and\nWater Control \nFigure 16. Optimization applications\
    \ in IoT based Smart Cities.\n75\nCHAPTER V\nCASE STUDY - SMART HEALTH\n1\nIntroduction\n\
    As discussed earlier, IoT finds usage in many different Smart City domains, both\
    \ for\nuse in classification/regression tasks as well as for optimization applications.\
    \ One\nof the most important applications of IoT within Smart Cities is within\
    \ the Smart\nHealth domain wherein IoT devices enable the monitoring of patients\
    \ for different\ndiseases such as heart disease etc. While there are a multitude\
    \ of IoT within Smart\nHealth, in order to develop algorithms on IoT sensor data,\
    \ the case of ambient assisted\nliving was chosen, in particular, this work considers\
    \ the case of fall detection.\n2\nIoT for Fall Detection\nThe United Nations estimates\
    \ that the number of old people (aged 60 and above) will\nbe 2.1 billion by 2050\
    \ and 3.1 billion by 2100 [382] leading to an increased old age\npopulation. With\
    \ people above 65 years suffering the greatest number of fatal falls\namong adults\
    \ aged 60 and over [383] healthcare costs related to fall related injuries\nrun\
    \ in to billions of dollars. These falls can result in injuries of moderate to\
    \ severe\nnature in the people experiencing the falls and may lead to decreased\
    \ mobility [384],\nespecially for the elderly [385]. Furthermore, following the\
    \ initial fall, the likelihood\nof experiencing additional falls increases [386]\
    \ and can lead to mental stress in the\nform of post-fall syndrome [387].\nThe\
    \ Internet of Things has spearheaded the development of cyber-physical systems\n\
    that facilitate the recognition of activities/events being performed by people\
    \ in their\ndaily life. One aspect of this application scenario is fall detection.\
    \ Falls can occur\ndue to a variety of reasons [388] and Fall Detection Systems\
    \ (FDS) are used for\npeople with different of health related ailments such as\
    \ in Parkinsons disease [389],\nepilepsy [390], arthritis, people suffering from\
    \ cardiovascular diseases and various\nneuro-degenerative diseases [391]. In any\
    \ scenario, it is pertinent that when a person\nundergoes a fall, they be provided\
    \ care as quickly as possible. Providing timely care\nafter a fall may improve\
    \ post-fall life quality of a patient. Fall detection Systems can\nplay a vital\
    \ role in contributing to the provision of timely care [389, 392] by alerting\n\
    healthcare professionals. As noted by [393] fall detection systems are necessary\
    \ for\nold people with cognitive impairments who may not be able to get up after\
    \ a fall for\nlong durations of time which may result in pressure sores and other\
    \ complications\nand due to vulnerability to injuries when experiencing a fall,\
    \ it may sometimes result\nin death [394].\n76\nA fall is an unintended and sudden\
    \ change of posture resulting in one resting on\nthe ground or some other lower\
    \ level elevation. The aim of a FDS is to monitor the\nmovement of a person and\
    \ determine when a fall has taken place with the aim to\nalert healthcare personnel\
    \ or other caregivers. Over the years different methodologies\nhave been suggested\
    \ to address this problem, however, before discussing the different\nmethods utilize\
    \ for fall detection purposes, it is important to mention what researchers\nenumerate\
    \ to be the traits of a ’good’ FDS [395].\n2.1\nChallenges/Requirements of a FDS\n\
    The following are the typical typical traits/requirements of a good fall detection\n\
    system.\n2.1.1\nNon-intrusiveness\nAn important requirement in fall detection\
    \ systems is to be non-intrusive. Any FDS\nshould not be an impediment in the\
    \ execution of daily activities of a person as it may\nrestrict movement or inconvenience\
    \ their lifestyle.\n2.1.2\nLow Latency\nAn FDS needs to be able to detect a fall\
    \ with low latency. Latency refers to the time\nduration between the occurring\
    \ of a fall and its detection. FDS need to detect falls\nas quickly as possible\
    \ to ensure that caregivers can be notified right away so that apt\ncare is provided\
    \ to the person. Low latency depends on not only the algorithm being\nused to\
    \ detect falls but also parameters like network speed and reliability. Sensor\
    \ data\ntransmission to the main system might also be included in this calculation\
    \ depending\non the FDS proposed.\n2.1.3\nLow power consumption\nPower consumption\
    \ is an important issue in FDS, especially for ones which are battery\npowered.\
    \ Many FDS are expected to be used by elderly people who might not be\nas regular\
    \ in charging the FDS, therefore FDS should consume as little power as\npossible.\n\
    2.1.4\nAllow mobility\nA FDS should not hamper mobility as it might be preventive\
    \ in adoption of a FDS\ntoo. FDS which require people to remain infront of a camera\
    \ at a certain viewpoint\netc can be difficult to deploy and use.\n2.1.5\nDifferentiate\
    \ between Falls and Activities\nA FDS should have low false positives and false\
    \ negatives. In other words it should\nbe able to confidently detect falls and\
    \ be able to differentiate them from activities of\n77\ndaily living such as walking,\
    \ sitting, jumping, running etc. Any false alarms will result\nin wastage of valuable\
    \ healthcare resources, on the contrary, any false negatives might\ncause the\
    \ patient/person having undergone the fall to not get appropriate medical\ncare\
    \ in time and lead to potential death or trauma.\n2.1.6\nNotify caregivers\nA\
    \ complete fall detection solution should have some mechanism of informing care-\n\
    givers whenever a fall is detected. Typically this is carried out in terms of\
    \ email,\nnotifications via some system or messages. Moreover, this process should\
    \ be quick so\nas to ensure the dispatch of any needed help as quickly as possible.\n\
    2.1.7\nTrack history\nA complete fall detection solution should be able to provide\
    \ the history about a\npatient in terms of falls that a person may have suffered\
    \ from as this will help monitor\nthe patients health and determine likelihood\
    \ to suffer from falls in the future. FDS\nmay sometimes also look at other biological\
    \ parameters during falls so as to help\ninvestigate the causes of falls using\
    \ the conditions prevalent at that time. Biological\nparameters that could be\
    \ measured include heart rate, perhaps an ECG or others as\ndeemed necessary based\
    \ on a patients history.\n2.2\nTypes of Fall Detection Systems\nFall detection\
    \ systems can be categorized in to three types based on the sensing\nmechanisms\
    \ used and their placement. These are Ambient Sensor based systems,\nVisual based\
    \ systems and Wearable Sensor based systems.\n2.2.1\nAmbient Sensor based systems\n\
    Ambient sensor based systems are also sometimes referred to as environmental sensor\n\
    based systems since these types of FDS rely on the use of a number of wirelessly\n\
    connected ambient sensors placed in a given area for the detection of falls. These\n\
    FDS make use of various sensors including Passive InfraRed (PIR) Sensors [396],\n\
    Acoustic sensors such as microphones, thermal sensors as well as sensors measuring\n\
    Wi-Fi signal strength etc. For e.g., the authors in [397] develop a fall detection\
    \ system\nbased on two PIR sensors and a vibration sensor to detect vibrations\
    \ on the floor\nwhen a person falls down. Using the PIR sensor to detect a persons\
    \ motion. feature\nextraction is performed on vibration measurements and an SVM\
    \ classifier is used to\ndetermine whether a fall has taken place or not. Another\
    \ approach presented in [398]\nutilize sounds in a home to determine falls in\
    \ the elderly. They do this by extracting\nfeatures in sound signals and like\
    \ [397] use a Support Vector Machine classifier to\ndetermine falls. The authors\
    \ in [399] make use of Wi-Fi channel state information\nfor fall detection. They\
    \ achieve this by feature extraction in the frequency domain\nfollowed by an SVM\
    \ classifier.\n78\nAmbient fall detection systems offer the advantage of not requiring\
    \ people to wear\nanything on their bodies and are thus nonrestrictive in that\
    \ sense. However, such\nsystems are prone to suffer high false positives due to\
    \ the large number of external\nfactors such as other heat emitting devices, multiple\
    \ people moving around at the\nsame time etc. Another issue that comes with ambient\
    \ fall detection systems is that\ndeployment could be cumbersome to cover a large\
    \ space, therefore they are typically\ndeployable in small places such as a home\
    \ or a small building but are very difficult\nto use outdoors due to the nature\
    \ of the setting as well as the possible sources of\nexternal interference.\n\
    2.2.2\nVision based systems\nVision based systems rely on the processing of video\
    \ frames or other visual infor-\nmation such as depth and thermal images or their\
    \ combination [400] to detect falls.\nTypically, the recorded data is sent to\
    \ a server or central computer which provides\nprocessing capabilities. Moreover,\
    \ recently, with the use of deep learning algorithms,\nsuch systems have found\
    \ to provide improved performance. For e.g. [401] use Convo-\nlution Neural Networks\
    \ on velocity information in video frames. Another approach\nthat uses CNNs is\
    \ given in [402] who model human motion from video frames using\nCNNs and then\
    \ use a logistic regression classifier to determine falls. Other approaches\n\
    with CNNs include the works in [403] and [404], both of which achieve very high\
    \ de-\ntection accuracy. Another DL network which has been useful in fall detection\
    \ systems\nbased on cameras is Long Short Term Machine, a recent example of that\
    \ is the use of\na CNN + LSTM combination on 360 degree video recordings of an\
    \ indoor facility to\ndetermine falls. The LSTM allows for capturing the changing\
    \ characteristics between\nvideo frames to provide fall recognition.\nEventhough\
    \ vision based FDS have been able to provide improved fall detection\nperformance\
    \ recently, like ambient sensor based systems, these systems suffer from\nsome\
    \ drawbacks. They are affected negatively in terms of performance and deploya-\n\
    bility from external factors such as occlusion, restricted mobility of the people\
    \ being\nmonitored, typically usable in environments over a small area, have high\
    \ computa-\ntional costs and are expensive. One other issue with vision based\
    \ systems is privacy,\nvision systems which use normal cameras pose risk of violation\
    \ to the privacy of peo-\nple being captured on video. The question of privacy\
    \ can be circumvented by the\nuse of depth cameras for e.g. a kinect [405, 406]\
    \ or using heatmaps using infrared\ncameras/sensors [407].\n2.2.3\nWearable Sensor\
    \ based systems\nWearable fall detection systems involve the use of a device attached\
    \ to the subject.\nThe wearable device monitors user activity by means of sensors\
    \ and can determine\nwhen a fall has occurred. Information about the fall is then\
    \ conveyed to a doctor or\nother medical professionals. Various types of sensors\
    \ can be used in these systems\nincluding inertial measurement sensors such as\
    \ accelerometers, gyroscopes, magne-\ntometers [408] or health sensors such as\
    \ ECGs, oxygen level and pulse rate sensors\n79\nas well. The devices that contain\
    \ these sensors can be worn on the hand, wrist, arm,\nchest, waist, legs, thigh\
    \ or even put inside shoes and are usually battery powered.\nWearable fall detection\
    \ systems have the advantage that they do not restrict move-\nment of the person\
    \ using them and consume less power than the other two approaches,\nhowever, a\
    \ disadvantage to this is the need to ’carry’ the device all the time. Another\n\
    disadvantage is the need to charge the device regularly which might be difficult\
    \ to do\nfor older people, a way this has been addressed in some approaches is\
    \ to make use of\nenergy harvesting [409].\n2.3\nTypes of Wearable FDS\nThere\
    \ are two types of wearable systems in use for fall detection purposes.\n2.3.1\n\
    Threshold based systems\nThe first of type of wearable FDS are threshold-based\
    \ fall detection systems where\nauthors have used various thresholding techniques\
    \ on sensor values measuring motion,\nparticularly the accelerometer. The major\
    \ advantage of threshold based fall detection\nsystems is their relative low computational\
    \ cost and use of sensor fusion techniques\nto improve fall detection accuracy\
    \ , however, the big disadvantage of such systems is\nthat threshold based systems\
    \ do not generalize well across subjects since people may\nhave different gaits,\
    \ this is especially true for people of different ages. As a result,\nthreshold\
    \ based FDS may suffer from having many false positives as well as false\nnegatives\
    \ since the FDS needs to differentiate between activities of daily living and\n\
    falls, which many times may appear to be fairly similar to each other in terms\
    \ of\nsensor readings.\n2.3.2\nMachine/Deep Learning based systems\nSince threshold-based\
    \ systems are rigid in terms of their usage, ML/DL methods\nprovide a flexible\
    \ method for fall detection. ML/DL algorithms can learn complex\npatterns from\
    \ sensor data which indicate to a fall while monitoring a persons activities\n\
    and therefore are useful in fall detection systems. As opposed to threshold based\n\
    systems, their generalizing capability allows them to be used across subjects.\n\
    A\ntypical ML framework for fall detection will involve data acquisition, prepossessing,\n\
    feature extraction and then usage of a suitable ML algorithm to make the inference\n\
    for a fall or no fall. A deep learning framework based FDS might have a similar\n\
    methodology, but depending on the DL algorithm used, feature extraction might\
    \ be\nomitted.\n2.4\nSensors used in Wearable FDS\nAs mentioned before, the sensors\
    \ used in wearable FDS are accelerometers, gyroscope,\nmagnetometer, ECG, Pulse\
    \ Rate and oxygen saturation levels. In this section, we will\ndiscuss briefly\
    \ the role of these sensors in wearable FDS and parameters of interest\nwhen using\
    \ them in FDS.\n80\n2.4.1\nAccelerometers\nAccelerometers, together with gyroscopes\
    \ are the most widely used sensors in wear-\nable FDS. One reason for this is\
    \ that both these sensors are typically present in\nsmartphones, which have been\
    \ used to either collect data for and/or deploy fall de-\ntection systems. An\
    \ accelerometer provides a measure of absolute acceleration and\nare used to detect\
    \ vibrations, force in a variety of applications involving monitoring\nof machines,\
    \ planes, civil architectures and more. In an FDS, an accelerometer is\nable to\
    \ capture the movement patterns of individuals which can be used to determine\n\
    falls.\n2.4.2\nGryroscope\nGyroscopes are used to measure tilt/orientation.\n\
    Gyroscopes find applications in\nvarious areas where orientation measurement is\
    \ required, for e.g. in airplanes and\nsubmarines where they are used in stabilization\
    \ systems, smartphones and game re-\nmotes for interactive gameplay, among other\
    \ things. Since orientation is an important\ncharacteristic of a fall, gyroscopes\
    \ are one of the most widely used sensors in FDS\nalong with acceleratorometers.\n\
    2.4.3\nMagnetometer\nA magnetometer is a device that measures the direction and\
    \ strength of magnetism\nrelative to the earths magnetic north. In addition to\
    \ other applications, magnetome-\nters are used in aircrafts for direction referencing.\
    \ These sensors are not very popular\nin FDS but have been proposed in some approaches\
    \ [410, 411] to be used for fall\ndetection in addition to accelerometers and/or\
    \ gyroscopes.\n2.4.4\nVarious Medical Sensors\nWearable fall detection systems\
    \ may also incorporate different types of medical sen-\nsors such as ElectroCardioGraphs,\
    \ ElectroMyoGraphs, Pulse Rate or Oxygen Level\nmeasurement in the FDS solution.\
    \ Even though there have been some approaches\nwhich have used medical sensors\
    \ exclusively for fall detection (such as EMG[412]),\nhowever, like magnetometers,\
    \ these sensors are usually used along with accelerome-\nters and/or gyroscopes.\
    \ Adding these sensors to fall detection systems has the added\nadvantage of assessing\
    \ falls from a health standpoint too as this information can be\nused to determine\
    \ risk of falls [413].\n2.5\nDesign considerations for Wearable FDS\nWearable\
    \ fall detection systems utilize sensor measurements to ascertain the occur-\n\
    rence of a fall. Since wearable FDS units are always attached to a persons body,\
    \ they\ncontinuously provide measurements of a persons movements and activities.\
    \ In order\nto use these measurements in a FDS, there are some design considerations\
    \ involved.\nWe discuss them in this section.\n81\n2.5.1\nSampling frequency\n\
    The sampling frequency dictates the number of sensor measurements recorded per\n\
    second. The sampling frequency used in an FDS should be high enough to capture\n\
    fall motion but not too high so as to increase data processing, storage requirements\n\
    as well as allow for energy efficient operation. In fact, depending on the position\n\
    of the sensors, significant reductions can be made in the sampling frequency used\n\
    for sensors with little or no change in performance as demonstrated by [414].\
    \ Such\nreductions could result in low power consumption by the wearable module\
    \ thereby\nenabling longevity of operation.\n2.5.2\nWindowing\nSince wearable\
    \ fall detection systems provide a continuous stream of sensor data, the\ndata\
    \ needs to be windowed for fall detection to be performed. Windowing refers to\
    \ the\nextraction of a subset of the sensor data stream in a sliding manner or\
    \ otherwise and\nis typically specified in terms of time duration for its size.\
    \ It is typical for wearable\nFDS designers to test different window sizes for\
    \ their fall detection algorithms. The\nsize of the window used would dictate\
    \ memory and computational requirements of\nthe unit used for deploying the FDS\
    \ system. Another important factor in windowing\nsensor signals is whether overlapping\
    \ is used during the windowing process or not.\nThis might be important to allow\
    \ for smooth transitions between different windows.\n2.5.3\nFeature Extraction\n\
    Feature extraction is the process of determining quantities from data which charac-\n\
    terizes it for a desired task appropriately. Feature extraction not only aims\
    \ to capture\nimportant aspects of the data being worked on but also to present\
    \ its content in a\nreduced size, thereby, making use of the data easier. Feature\
    \ extraction is a typ-\nical step of the a signal processing and machine learning\
    \ workflow and follows the\nwindowing step. There are different types of features\
    \ which have been computed\nfor fall detection applications, common feature computations\
    \ include the determina-\ntion of time domain features, frequency domain features,\
    \ statistical features etc. or\nsome combination from sensor data in FDS. Feature\
    \ extraction is followed by either a\nthresholding algorithm to sensor values\
    \ or a machine/deep learning model. For deep\nlearning, there have been some end\
    \ to end deep learning approaches which skip the\nstep of manual feature extraction.\
    \ In such approaches, deep learning networks such\nas CNN may be used to extract\
    \ features followed by other networks such as LSTM\nto determine falls, an example\
    \ is proposed in [415].\n2.6\nLiterature Review\nAs discussed previously, wearable\
    \ fall detection systems present several advantages\nwhen used for fall detection\
    \ purposes such as non-intrusiveness, ease of mobility, small\nsize of deployment,\
    \ low cost and that many implementations are typically standalone\nsystems. This\
    \ added with the fact that sensors and other components which are used\n82\nin\
    \ such systems have been becoming cheaper and cheaper to produce has resulted\
    \ in\na lot of interest in the development of wearable FDS by researchers and\
    \ technologists\nalike. Therefore, wearable FDS methodologies have gained considerable\
    \ interest in\nfall detection research. We discuss some of the popular methodologies\
    \ proposed in\nthis regard.\nThe authors in Mrozek et al. [416] present a complete\
    \ design of a wearable fall\ndetection system for an Internet of Things scenario.\
    \ They conduct two experiments\nwith their system, in one experiment, data is\
    \ collected from a gyroscope and an\naccelerometer and sent to the cloud for fall\
    \ detection (as a web service) while in\nthe second experiment, fall detection\
    \ is performed on the edge node (smart phone).\nThrough their experiments they\
    \ conclude that performing fall detection on the edge\nnode results in less network\
    \ traffic and storage requirements for the cloud. Algo-\nrithmically speaking,\
    \ they extract 3 second overlapping windows from measurements\nof both sensors,\
    \ perform feature extraction and pass it on to a boosted decision tree\nclassifier\
    \ for determining whether a fall has taken place or not. Moreover, the boosted\n\
    decision tree classifier was trained using the SisFall [417] dataset. Another\
    \ IoT based\nsystem is proposed by Marquez et al. [418] who develop a fall detection\
    \ system for\nIoT on the edge. They first gather data from an accelerometer and\
    \ a gyroscope placed\non the waist of multiple subjects and train a support vector\
    \ machine classifier on a\ncombination of raw sensor values and its standard deviation.\
    \ They are able to deploy\ntheir system successfully and achieve satisfactory\
    \ results. Moreover, feature selection\nis also performed before the classification\
    \ stage. A fog based fall detection model has\nbeen proposed by Sarabia-J’acome\
    \ et al. [419] who utilize a Long Short Term Memory\nRecurrent Neural Network\
    \ in their method. Edge nodes collect Inertial Measurement\nUnit (IMU) measurements\
    \ and relay them to a fog node which processes the data to\ndetermine if a fall\
    \ has taken place or not. One motivation for them to develop RNN\nmodels over\
    \ a Convolutional Neural Network one is the requirement of less param-\neters\
    \ and thus less computational requirements. Their final model consists of a 1D\n\
    CNN layer followed by two LSTM layers and a fully connected layer for classification\n\
    and is trained using raw data (window of 15s) from the SisFall dataset.\nZurbuchen\
    \ et al. in [420] provide a comparison of various machine learning al-\ngorithms\
    \ for fall detection while using data from the SisFall dataset. They perform\n\
    experiments using Decision Trees, Random Forest Classifier, Gradient Boosting\
    \ tree,\nK-Nearest Neighbor and Support Vector Machines. Segments of 10 seconds\
    \ are ex-\ntracted from the trials in the SisFall dataset and various time and\
    \ frequency domain\nfeatures are computed for those segments. These are then passed\
    \ on to the classifiers.\nThrough their experiments, they find that Random Forest\
    \ and Gradient Boosting\ntrees perform the best among the considered methods.\
    \ Another comparison of var-\nious ML algorithms is provided by Chelli and P¨atzold\
    \ in [421] who compare the\nperformance of a number of machine learning algorithms\
    \ on two datasets, the Cogent\nLabs dataset [422] and the one provided in [423].\
    \ The algorithms they consider are\nan artificial neural network, K-NN, an ensemble\
    \ bagged tree (EBT) and Quadratic\nSupport Vector Machine (QSVM). They compute\
    \ several time and frequency domain\nfeatures from accelerometer and gyroscope\
    \ signals and pass them on to the classi-\nfiers. Their best performing classifiers\
    \ were QSVM and EBT. Kerdjidj et al. in [424]\n83\nuse compressive sensing to\
    \ explore the use of different modalities for fall detection\npurposes. The performance\
    \ of accelerometer only and an accelerometer - gyroscope\nsensor combination in\
    \ a fall detection scenario is compared. A Shimmer device [425]\nis used to capture\
    \ data from 17 volunteers asked to perform activities of daily living\nas well\
    \ as fall like movements. They first extract segments of length 2.56 seconds\n\
    from their recordings before performing feature extraction and passing it on to\
    \ four\ndifferent machine learning classifiers, K-Nearest Neighbor, Support Vector\
    \ Machines,\nDecision Trees and an Ensemble Classifier (EC). They conduct two\
    \ such experiments,\none with compressive sensing and the other without. Their\
    \ results indicate that the\nEC classifier and SVM perform the best with the help\
    \ of compressive sensing included\nin the pipeline. A ’transfer learning’ approach\
    \ towards fall detection is provided by\nFanez et al. in [426] and they test it\
    \ on the UMAFall [427] dataset and the FallOVI\ndataset (created by them). Using\
    \ a finite state machine which captures windows\nof accelerometer measurements\
    \ based on peak values, the authors convert the win-\ndowed segments into string\
    \ representations using symbolic aggregate approximation\n(SAX) [428]. During\
    \ training each user performs normal ADLs and falls for a short\nperiod of time.\
    \ Peak values are determined from sensor measurements and used to\ncreate bag\
    \ of words using SAX. After this, normal operation of the system starts\nand information\
    \ retrieval (term frequency - inverse term frequency) values are used\nto determine\
    \ what label to give to new SAX words derived from sensor values. If a\ndetermined\
    \ word is not similar (using Manhattan distance) to any word in the bag of\nwords\
    \ (K-NN clustering is used to group similar words), a fall event is suggested\
    \ to\nhave occurred. ’Transfer learning’ involves the use of clusters formed by\
    \ other users\n(performing activities only) as the starting point of the training.\
    \ Their experiment\ncompared an SVM classifier with their information retrieval\
    \ based scheme. They are\nable to detect falls all the time with the UMAfall dataset\
    \ but have a high number\nof false positives for the FallOVI dataset. An noticeable\
    \ aspect of this approach is\nthe use of clustering and ’feature extraction’ as\
    \ strings. In Giuffrida et al. [429]\nthe authors use data from the SisFall dataset\
    \ and an SVM classifier to differentiate\nbetween falls and no-fall samples. They\
    \ extract slices (of 1 second) from the SisFall\ntrials and label each slice as\
    \ containing a fall or not. A number of features were then\ncomputed for each\
    \ slice before feature selection was performed and an SVM classifier\nwas trained\
    \ to determine the output class.\nDeep Learning methods have also been widely\
    \ used for fall detection purposes.\nCasilari et al. in [430] explore the contribution\
    \ of the gyroscope sensor for use in\ncombined accelerometer-gyroscope based fall\
    \ detection systems.\nTo do this, they\nmake use of measurements from the SisFall\
    \ dataset, extract observation windows of\n5 seconds around peaks of accelerometer\
    \ sensor signal values over a trace and pass\nthem on to a Convolutional Neural\
    \ Network with four convolutional layers, three\nmax pooling layers followed by\
    \ one fully connected layer for classification. Training is\nperformed in two\
    \ different sets of experiments, one including gyroscope data and the\nother without\
    \ it. They note that the results they get while using only accelerometer\nsignal\
    \ measurements are better than that when using data from both sensors. A\nCNN\
    \ is used for fall detection purposes by Santos et al. in [431] from accelerometer\n\
    measurements. Their network consists of six convolutional layers, two max pooling\n\
    84\nlayers in between followed by a fully connected layer for classification.\n\
    They use\ndata from the URFD dataset [432] and the Smart Watch and Notch datset\
    \ [433] in\ntheir experiments. They note that their model performs best when they\
    \ use data\naugmentation for both the datasets. However, this was achieved by\
    \ two different\nvariants of the same model. This highlights the point of a single\
    \ model not necessarily\nperforming well on all datasets. Another interesting\
    \ aspect of their work is the use of\nthe Mathews Correlation Coefficient to evaluate\
    \ performance of their algorithms. A\nmodified AlexNet [434] has been used in\
    \ [435] by Alarifi et. al. They collect tri-axial\ndata from inertial measurement\
    \ sensors consisting of accelerometer, gyroscope and\nmagnetometer at six different\
    \ positions on a subjects body. A total of 16 activities of\ndaily living and\
    \ 20 falls were recorded by them. Feature extraction is then performed\nin terms\
    \ of various statistical measurements as well as frequency analysis. This is\n\
    followed by principal component analysis and then passed on to the classification\n\
    stage consisting of an optimized AlexNet ConvNet. Waheed et. al. in [436] develop\n\
    a FDS using a Bi-Directional Long Short-Term Memory (Bi-LSTM) network. They\n\
    consider the binary case of fall and no fall and perform experiments using the\
    \ SisFall\ndataset as well as the UP-Fall dataset [437]. Their network consists\
    \ of eight layers\nin total. Two Bi-LSTM layers and two fully connected layers\
    \ with dropouts being\nused for regularization. Training is performed with creating\
    \ missing values in the\ndata to introduce noise tolerancy.\nCasiliri et al.\n\
    in [438] provide a performance\ncomparison for a CNN network on multiple public\
    \ fall detection datasets. The aim\nof their work is to test the cross-application\
    \ of a similar CNN network trained on\ndifferent datasets. They set their experiments\
    \ up by training a four layer CNN on\neach dataset separately for fall detection\
    \ on 14 datasets (using similar positions of\nsensor placement) on windows of\
    \ 5 seconds for accelerometer signals. Their results\nindicate a very good performance\
    \ of the network for the SisFall dataset, however, it\ndoesn’t perform very well\
    \ for most of the other datasets, in some cases, performing\nless than random\
    \ chance, which is quite surprising. Their experiments do however,\nhighlight\
    \ an issue with the well accepted notion that an algorithm developed on some\n\
    benchmark dataset will necessarily work similarly well with other datasets.\n\
    The\nauthors suggest that the erratic performance of their method could be due\
    \ to the\ndifference in the nature of the data in terms of sampling frequency\
    \ used, range of\nthe sensor and the varying type of movements. Another cross-dataset\
    \ approach for\nfall detection has been proposed in [439] where the authors use\
    \ a combination of a\nCNN and Long Short Term Memory network to extract features\
    \ followed by a K-\nNearest Neighbor classifer to detect falls as well as identify\
    \ the subjects within four\nfall datasets, DFNAPAS [440], SisFall, UniMiB-SHAR\
    \ [441] and ASLH [442]. The\nnetwork is trained using the DFNAPAS dataset, before\
    \ training the network however,\ndata augmentation is carried out for the fall\
    \ class. Their best results are achieved\nfor a value of K = 3 and they achieve\
    \ good results for all experiments. They observe\nthat using a deep learning architecture\
    \ for feature extraction purposes along with a\nmachine learning classifier performs\
    \ better than a using a fully connected layer at the\nclassification stage.\n\
    Post fall intelligence is an important research area in the field of fall detection\n\
    as it can be useful in determining various post fall injuries [443] and serve\
    \ as an\n85\nintelligence parameter [444] for doctors. Jung et al. in [445] also\
    \ target detection\nof pre-impact falls for wearable airbag deployment. Their\
    \ method involves the ap-\nplication of a threshold on determined features from\
    \ accelerometer and gyroscope\nmeasurement measurements. The thresholds are then\
    \ applied to a dataset collected\nby them and also on the SisFall dataset. The\
    \ threshold is determined by performing\na grid search on the extracted features\
    \ from their dataset to maximize specificity and\nsensitivity. They do note that\
    \ some activties like sitting down quickly on a chair or a\nmattress triggered\
    \ false positives. Moreover, when applied to SisFall, their methods\nperformance\
    \ is not as high as achieved by methods based on ML/DL. Koo et. al.\n[446] present\
    \ experiments for post fall detection from a combination of self collected\ndata\
    \ and the SisFall dataset. They conduct tests using sliding windows as well as\
    \ dis-\ncrete windows from these signals and compute statistical features from\
    \ them. After\nfeature extraction, two different classifiers, the artificial neural\
    \ network and support\nvector machine are tested with the computed features as\
    \ well as raw sensor values.\nThey find that both ANN and SVM are suitable for\
    \ use in post fall detection sce-\nnarios. Another approach looking at the different\
    \ phases of a fall has been presented\nin [447] where Hsieh et. al. use accelerometer\
    \ sensor data to differentiate between\nfive phases of a fall, pre-fall, free-fall,\
    \ impact, resting and recovery and the initial\nand end static phases. To do this,\
    \ they compute various time domain and statistical\nfeatures and test five classifiers,\
    \ SVM, K-Nearest Neighbors, Naive Bayes, Decision\nTrees and Adaptive Boosting\
    \ (AdaBoost). For their experimental setup, the best\nresults were achieved using\
    \ the K-NN classifier. In Musci et al. [448], the authors\npropose a RNN based\
    \ method to differentiate between falls, pre-impact falls (state\nwhere a person\
    \ is in a dangerous state of transition which may result in a falls) and\nnormal\
    \ activities. Their motivation for including preimpact falls is to enable timely\n\
    deployment of a fall protection system. First, they label data from the SisFall\
    \ dataset\nto form three classes. They then extract windows of duration 1.28 seconds\
    \ with an\noverlap of 50% from the sensor signals and pass them on to their network\
    \ which\nconsists of two fully connected layers and two-layer LSTM layers. Moreover,\
    \ due to\nan imbalanced training set, they define a new balancing loss function.\
    \ Their method\nresults in fall detection good results for the three classes considered.\
    \ A CNN-LSTM\napproach has been proposed in [449] by Yu et al. for detection of\
    \ pre-impact fall and\nfalls in the SisFall dataset. They provide a comparison\
    \ of standalone CNN, LSTM\nand a combined CNN-LSTM architecture for this task\
    \ and also implement them on\na Jetson Nano. They define a pre-impact fall as\
    \ the time interval where a subject\ntransitions from a controlled state to a\
    \ state which may lead to a fall. First, they\nlabel data in the SisFall dataset\
    \ as described in [448] to form a three class problem.\nThey achieved their best\
    \ results for their CNN+LSTM model having four CNN layers\nfollowed by two LSTM\
    \ layers and a fully connected layer for classification. Their ap-\nproach highlights\
    \ the combined capability of CNN-LSTM for feature extraction. An\naspect of fall\
    \ intelligence is direction, in [450] Lee et al. use the velocity vector from\n\
    the acceleration sensor in a smartphone for fall detection with direction and\
    \ then\nlater on in [451], they use the standard deviation of the accemerometer\
    \ and gyro-\nscope sensor measurements from a smart phone to determine falls and\
    \ fall direction.\nThey perform a small experiment and are able to differentiate\
    \ between left, right,\n86\nfront and backward falls. More work on fall detection\
    \ with direction was performed\nby the authors in [452] who use an accelerometer\
    \ and gyroscope combination along\nwith a kalman filter for tilt estimation. Fall\
    \ detection is then performed using an\nSVM classifier. Falls with direction detection\
    \ has been attempted in [453, 454] by\nthe same authors. They collect accelerometer\
    \ data from various subjects and extract\nthree features from the recordings for\
    \ each axis, the mean, standard deviation and\nprincipal components (using Principal\
    \ Component Analysis). These are then passed\non to a SVM classifier to differentiate\
    \ between a forward, backward, left and right\nfall and ADLs.\nWhile direction\
    \ aware fall detection is an important determination in terms of post\nfall intelligence,\
    \ fall detection with severity is necessary since it could help provide\nindications\
    \ to falls with immediate recovery or otherwise, as falls without immediate\n\
    recovery would be more detrimental to health than a fall with immediate recovery\
    \ as\nhas been suggested in [455]. In [456] the authors attempt to classify between\
    \ different\nfalls (direction: forward, backward, right, left and intensity: hard,\
    \ soft [fall on knees\nfirst, then on floor]) and five different ADLs using accelerometer\
    \ data. They collected\ndata for their experiments using a triaxial accelerometer\
    \ mounted on the chest. Fea-\nture extraction consists of first concatenating\
    \ acceleration values in each axis and\nthen using a Debauchies-2 level-3 wavelet\
    \ which are then sent to the classification\nstage. In the classification stage\
    \ five different classifiers, an ANN, a Radial Basis\nFunction (RBF) Network,\
    \ Probabilistic Principal Component Analysis (PPCA) and\nLinear Discriminant Analysis\
    \ (LDA) are used through a voting machine to determine\nfalls. A voting machine\
    \ (VM) involves multiple classifiers giving a vote towards any of\nthe multiple\
    \ classes and the sum of the vote is compared against a vote threshold to\ndetermine\
    \ the event that has taken place. In their work, the authors train individual\n\
    VMs for all the activity and fall types in their dataset by structuring them all\
    \ in par-\nallel and adding a comparator function at the end of the pipeline.\
    \ Moreover, a K-NN\nmulticlass classifier also feeds in to the comparator and\
    \ is trained while training of\nthe other classifier, it is provided the true\
    \ value of the activity being input to the\nclassification stage. The authors\
    \ show that their dataset works very well. A valuable\ninsight about their work\
    \ is the ensembling mechanism the authors have employed to\ndetermine fall directions.\
    \ In [457], Hussain et al. propose a fall detection system that\ncan first determine\
    \ falls and then the type of fall using data from the SisFall dataset.\nThey accomplish\
    \ this in a hierarchical setup where their system first considers fall\ndetection\
    \ as a binary problem, whether a fall has taken place or not, and if a fall\n\
    has been detected, it classifies between the various falls in the dataset. Their\
    \ system\nis designed to work with 10 second non-overlapping windows of accelerometer\
    \ and\ngyroscope signals. Data from each record is first low pass filtered before\
    \ two different\ntypes of feature sets, consisting of various time domain and\
    \ statistical features, are\ncomputed on the data. This is then followed by the\
    \ machine learning stage where\nthree different classifiers are tested, K-NN,\
    \ SVM and RFC. In the fall detection stage,\nstatistical features are computed\
    \ from ADL and fall signals and sent to the three clas-\nsifiers for the preliminary\
    \ binary classification. After a fall has been determined to\nhave happened, numerous\
    \ other statistical and time domain features are then com-\nputed on the data\
    \ before being sent to the next stage to determine the type of fall\n87\nactivity\
    \ taking place. In their experiments, the authors find that K-NN is most effec-\n\
    tive in differentiating between falls and ADLs where as RFC performs the best\
    \ when\nthe different fall activities need to be determined. This work highlights\
    \ the usefulness\nof a hierarchical approach towards non-binary fall detection.\
    \ One proposed method\nto perform combined activity recognition and fall detection\
    \ has been presented in\n[458]. In this, Li et. al. use multi-modal sensor fusion\
    \ and a Bi-LSTM classification\nnetwork to differentiate between five activities\
    \ of daily living and a fall. The sensors\nthey use are an inertial sensor placed\
    \ on the wrist, waist and ankle as well as a radar\nsensor. After pre-processing\
    \ both the inertial measurement and radar signals, various\nstatistical and moment\
    \ computations were performed to be used as features. These\nwere passed on to\
    \ the multilayer Bi-LSTM network after feature selection to deter-\nmine the output\
    \ class. One thing to note is that both both [458] and [421] consider\nfall as\
    \ a single category rather than considering falls as a detailed problem (direction\n\
    and/or severity) in itself. More recent work by We et al. [459] also considers\
    \ ac-\ntivity recognition and fall detection together. They use inertial measurement\
    \ sensor\ndata from two datasets, the MobiAct dataset [460] and the SmartFall\
    \ dataset [433].\nThe MobiAct dataset contains data from four falls and nine activities\
    \ of daily living\nwhereas the SmartFall dataset has non-fall and fall recordings.\
    \ In their experimenta-\ntion, they compare the performance of different machine\
    \ learning models and several\ndeep learning models, including a CNN, LSTM, CNN-LSTM\
    \ combination and Gated\nRecurrent Units. The machine learning models are trained\
    \ by computing time and\nfrequency domain features whereas the deep learning models\
    \ are trained using raw\nsensor data. They find that the GRU designed by them\
    \ consisting of two GRU units\nfollowed by a softmax classification layer is the\
    \ best performing model. Another deep\nlearning approach utilizing sequential\
    \ modeling for a fall detection system that also\nconsiders ADLs has been presented\
    \ by Seng¨ul et al. [461]. They collect their own\ndata for two types of falls\
    \ and four activities of daily living. After data augmentation\non the minority\
    \ classes, they use a Bi-LSTM for classification. Le et al. [462] propose\na non-binary\
    \ fall detection scheme utilizing a collection of time, frequency frequency\n\
    domain features in addition to the three Hjorth parameters of activity, mobility\
    \ and\ncomplexity. They use data from two datasets, the MobiAct dataset and the\
    \ UP-Fall\ndataset. They are able to achieve good results on both datasets using\
    \ all three feature\ntypes with a random forest classifier.\nThe use of attention\
    \ based models has also been finding increasing usage in fall\ndetection research.\
    \ Yhdego [463] use an attention model to perform binary fall de-\ntection. The\
    \ fall dataset is collected by them and after windowing, the authors use\ntime2vec\
    \ positional encoding on the data. Their network consists of three attention\n\
    blocks each consisting of multiheaded self attention followed by normalization\
    \ and a\nfully connected network. After the attention blocks follow two fully\
    \ connected layers.\nThey find that their network incorporating attention performs\
    \ well in differentiating\nbetween fall and non-fall samples. Another interesting\
    \ approach using attention is\npresented by Liu et al. [464]. Inorder to apply\
    \ attention on both temporal (step wise)\nand spatial (channel wise) aspects of\
    \ the signals, a gated scheme is suggested. A fully\nconnected layer is used to\
    \ determine the embeddings before positional information is\nadded to the data.\
    \ Positional encoding is only used for stepwise attention as channel\n88\nwise\
    \ positions are not useful. Self attention is performed in the step-wise part\
    \ of the\nnetwork and is carried out for the individual channels in a pairwise\
    \ fashion across all\ntime steps while the channel wise attention is performed\
    \ across the different channels\nacross all time-steps. The outputs of these two\
    \ units are combined through a fully\nconnected network which weighs them before\
    \ concatenation and classification.\n2.7\nFall detection Datasets\nThere are several\
    \ datasets published for use in algorithm development for fall detec-\ntion as\
    \ has been noted in [438]. Of these, for this case study, we choose two datasets,\n\
    these are the SisFall and the K-Fall dataset. The SisFall [417] dataset is chosen\
    \ as\nit contains recordings of elderly people which are most at risk from injury\
    \ due to\nfalls and therefore should provide a good representation of activities\
    \ of the elderly. It\nshould be noted that its one of the most used dataset for\
    \ fall detection purposes [438].\nThe other dataset used is the K-Fall [465] dataset.\
    \ It was released on the pattern of\nthe SisFall dataset and includes more activities\
    \ compared to SisFall. A summary of\nthe datasets is presented in the next section.\n\
    2.7.1\nSisFall Dataset\nThe SisFall dataset consists of accelerometer and gyroscope\
    \ recordings of 19 types of\nactivities of daily living and falls. Two accelerometers\
    \ and one gyroscope were placed\non the waist and used for making the measurements.\
    \ This location was chosen so as\nto ensure that all body movements while performing\
    \ the activities/falls were captured\nby the sensory system. Furthermore, the\
    \ data recordings involved 23 young people\nbetween the ages of 19-30 years old\
    \ and 15 elderly people between the ages of 60-75\nyears. The dataset contains\
    \ annotated sensor measurements of each of these ADLs\nand falls recorded as well\
    \ as video recordings of sample experiments. There are four\nmain types of falls\
    \ present, six of them are forward falls , three backward falls, four\nlateral\
    \ falls and two vertical falls. The types of falls performed were directed through\n\
    a survey taken from elderly people living independently as well as the ones living\n\
    in retirement homes and include scenarios of slipping and tripping. Moreover,\
    \ they\nare preceded by various types of ADLs being performed to make the recordings\
    \ as\nclose to a real world scenario as possible. The ADLs recorded were approved\
    \ by\nmedical personnel and were chosen so as to be similar to falls. The ADLs\
    \ include\nhigh mobility activities such as walking up/down stairs, jogging as\
    \ well as activities\nwhich can be confused with falls such as quickly sitting\
    \ in a chair, bending at the\nknee and stumble while walking etc. In total, there\
    \ were 2706 ADL recordings and\n1798 fall recordings. The SisFall data is utilized\
    \ in this study as it has been the\nthe dataset of choice for several previous\
    \ research approaches addressing the subject\nof fall detection [466, 467, 468,\
    \ 436, 469] and also because the volunteer makeup\nconsists of both men and women,\
    \ young adults and the elderly. The ADLs and Falls\nin the SisFall dataset have\
    \ been presented in Table 32 with a brief description of the\nactivities and falls\
    \ provided as well.\n89\nTable 32. ADL and Falls present in the SisFall dataset.\n\
    Activity/\nFall Code\nBrief Description\nD01\nWalking slowly\nD02\nWalking quickly\n\
    D03\nJogging slowly\nD04\nJogging quickly\nD05\nWalking upstairs and downstairs\
    \ slowly\nD06\nWalking upstairs and downstairs quickly\nD07\nSlowly sit in a half\
    \ height chair, wait a moment, and up slowly\nD08\nQuickly sit in a half height\
    \ chair, wait a moment, and up quickly\nD09\nSlowly sit in a low height chair,\
    \ wait a moment, and up slowly\nD10\nQuickly sit in a low height chair, wait a\
    \ moment, and up quickly\nD11\nSitting a moment, trying to get up, and collapse\
    \ into a chair\nD12\nSitting a moment, lying slowly, wait a moment, and sit again\n\
    D13\nSitting a moment, lying quickly, wait a moment, and sit again\nD14\nBeing\
    \ on one’s back change to lateral position, wait a moment, and change to\none’s\
    \ back\nD15\nStanding, slowly bending at knees, and getting up\nD16\nStanding,\
    \ slowly bending without bending knees, and getting up\nD17\nStanding, get into\
    \ a car, remain seated and get out of the car\nD18\nStumble while walking\nD19\n\
    Gently jump without falling (trying to reach a high object)\nF01\nFall forward\
    \ while walking caused by a slip\nF02\nFall backward while walking caused by a\
    \ slip\nF03\nLateral fall while walking caused by a slip\nF04\nFall forward while\
    \ walking caused by a trip\nF05\nFall forward while jogging caused by a trip\n\
    F06\nVertical fall while walking caused by fainting\nF07\nFall while walking,\
    \ with use of hands in a table to dampen fall, caused by\nfainting\nF08\nFall\
    \ forward when trying to get up\nF09\nLateral fall when trying to get up\nF10\n\
    Fall forward when trying to sit down\nF11\nFall backward when trying to sit down\n\
    F12\nLateral fall when trying to sit down\nF13\nFall forward while sitting, caused\
    \ by fainting or falling asleep\nF14\nFall backward while sitting, caused by fainting\
    \ or falling asleep\nF15\nLateral fall while sitting, caused by fainting or falling\
    \ asleep\n2.7.2\nK-Fall Dataset\nThe K-Fall dataset has been developed based on\
    \ the SisFall dataset and contains 15\nfall types and 21 ADLs. The falls in K-Fall\
    \ are the same as those in SisFall. However,\nin the case of ADLs, they remove\
    \ the activity of sitting in and getting out of a car\nand combine some of the\
    \ activities while adding static activities of sitting on a chair,\nsitting on\
    \ a sofa and lying down.\nA total of 2729 ADL recordings and 2346 fall\nrecordings\
    \ are present in the dataset. This dataset is included in the study to test\n\
    cross-dataset fall detection. The details of the K-Fall dataset are presented\
    \ in Table\n33.\n2.8\nExperiments\nThis section discusses the experiments conducted\
    \ for the purposes of fall detection.\nFour experiments have been performed in\
    \ this regard, first considering fall data only\n90\nTable 33. ADL and Falls present\
    \ in the K-Fall dataset.\nActivity/\nFall Code\nBrief Description\nD01\nStand\
    \ for 30 seconds\nD02\nStand, slowly bend the back with or without bending at\
    \ knees, tie shoe lace,\nand get up\nD03\nPick up an object from the floor\nD04\n\
    Gently jump (try to reach an object)\nD05\nStand, sit to the ground, wait a moment,\
    \ and get up with normal speed\nD06\nWalk normally with turn (4m)\nD07\nWalk quickly\
    \ with turn (4m)\nD08\nJog normally with turn (4m)\nD09\nJog quickly with turn\
    \ (4m)\nD10\nStumble while walking\nD11\nSit on a chair for 30 seconds\nD12\n\
    Sit on the sofa (back is inclined to the support) for 30 seconds\nD13\nSit down\
    \ to a chair normally, and get up from a chair normally\nD14\nSit down to a chair\
    \ quickly, and get up from a chair quickly\nD15\nSit a moment, trying to get up,\
    \ and collapse into a chair\nD16\nStand, sit on the sofa (back is inclined to\
    \ the support), and get up normally\nD17\nLie on the bed for 30 seconds\nD18\n\
    Sit a moment, lie down to the bed normally, and get up normally\nD19\nSit a moment,\
    \ lie down to the bed quickly, and get up quickly\nD20\nWalk upstairs and downstairs\
    \ normally (5 steps)\nD21\nWalk upstairs and downstairs quickly (5 steps)\nF01\n\
    Forward fall when trying to sit down\nF02\nBackward fall when trying to sit down\n\
    F03\nLateral fall when trying to sit down\nF04\nForward fall when trying to get\
    \ up\nF05\nLateral fall when trying to get up\nF06\nForward fall while sitting,\
    \ caused by fainting\nF07\nLateral fall while sitting, caused by fainting\nF08\n\
    Backward fall while sitting, caused by fainting\nF09\nVertical (forward) fall\
    \ while walking caused by fainting\nF10\nFall while walking, use of hands to dampen\
    \ fall, caused by fainting\nF11\nForward fall while walking caused by a trip\n\
    F12\nForward fall while jogging caused by a trip\nF13\nForward fall while walking\
    \ caused by a slip\nF14\nLateral fall while walking caused by a slip\nF15\nBackward\
    \ fall while walking caused by a slip\nand aiming to determine falls with direction\
    \ and severity. The second, third and\nfour experiments involved the inclusion\
    \ of activities of daily living classification in\naddition to the fall classes\
    \ considered in the first experiment. Moreover, experiment\nfour presents results\
    \ for a cross-dataset fall detection scenario.\n2.8.1\nFall Detection with Severity\
    \ and Direction consideration\nThis section describes the work on fall detection\
    \ considering severity and direction\nwhile only considering sensor data for falls.\
    \ The experiment has been performed as\ntwo tasks, one for determining falls considering\
    \ direction only and the other while\nconsidering both direction as well as severity.\n\
    2.8.1.1\nData Labeling\nTo perform fall detection that is direction and severity\
    \ aware, we only considered fall\n91\ndata from the SisFall dataset. As can be\
    \ seen from Table 32, most of the falls in\nthe dataset have been labelled as\
    \ either being in the forward, backward or lateral\ndirection.\nHowever, two of\
    \ the falls (F06 and F07) are not labeled in terms of\ndirection. For the considerations\
    \ of this research work, these were assigned the labels\nof Forward and Lateral\
    \ respectively using the videos of sample trials provided by the\ndataset authors.\n\
    Concerning fall severity, while the original labels from the dataset contained\
    \ in-\nformation for most falls for direction, the approach followed by Gibson\
    \ et al. [456]\nwas used to determine the severity of falls. According to the\
    \ practice followed by\nthem, all falls where in some support was used to soften\
    \ the impact of the fall were\nconsidered as soft falls whereas all falls where\
    \ the subject fell directly were classified\nas hard falls. This resulted in six\
    \ classes for fall types with hard and soft for ima-\npact and forward, backward\
    \ and lateral for direction. These are Forward Soft Falls\n(FSF), Forward Hard\
    \ Falls (FHF), Backward Soft Falls (BSF), Backward Hard Falls\n(BHF), Lateral\
    \ Soft Falls (LSF) and Lateral Hard Falls (LHF). These labels have\nbeen summarized\
    \ in Table 34.\nTable 34. Labeling used for Fall only classification for the SisFall\
    \ Dataset\nExperiment Name\nFall\nCode\nAssigned Fall Name\nAssigned Fall Label\n\
    Direction\nF01\nForward Fall\nFF\nF02\nBackward Fall\nBF\nF03\nLateral Fall\n\
    LF\nF04\nForward Fall\nFF\nF05\nForward Fall\nFF\nF06\nForward Fall\nFF\nF07\n\
    Lateral Fall\nLF\nF08\nForward Fall\nFF\nF09\nLateral Fall\nLF\nF10\nForward Fall\n\
    FF\nF11\nBackward Fall\nBF\nF12\nLateral Fall\nLF\nF13\nForward Fall\nFF\nF14\n\
    Backward Fall\nBF\nF15\nLateral Fall\nLF\nDirection + Severity\nF01\nForward Hard\
    \ Fall\nFHF\nF02\nBackward Hard Fall\nBHF\nF03\nLateral Hard Fall\nLHF\nF04\n\
    Forward Hard Fall\nFHF\nF05\nForward Hard Fall\nFHF\nF06\nForward Soft Fall\n\
    FSF\nF07\nLateral Soft Fall\nLSF\nF08\nForward Soft Fall\nFSF\nF09\nLateral Soft\
    \ Fall\nLSF\nF10\nForward Soft Fall\nFSF\nF11\nBackward Soft Fall\nBSF\nF12\n\
    Lateral Soft Fall\nLSF\nF13\nForward Soft Fall\nFSF\nF14\nBackward Soft Fall\n\
    BSF\nF15\nLateral Soft Fall\nLSF\n92\nWindowing\nTime and Frequency\nDomain Feature\n\
    Computation\nRF-RFE Feature\nSelection\nFeature\nExtraction and\nFeature Selection\n\
    Classification\nData\nPreprocessing\nPeak SMV Detection\nOutput Class \n(FF, BF,\
    \ LF) \n(FHF, FSF, BHF, BSF, LHF, LSF)\nIMU Recording (Falls) \n(FF, BF, LF) \n\
    (FHF, FSF, BHF, BSF, LHF, LSF)\nSVM Classifier\nFigure 17. Fall Detection with\
    \ Direction and Severity.\n2.8.1.2\nMethodology\nThe methodology used for this\
    \ experiment follows a typ-\nical machine learning pipeline as shown in Figure\
    \ 17. First, we pre-process the data\nwhich involves extraction of sensor segments\
    \ representing falls. This is followed by\nfeature extraction that aims to extract\
    \ useful representations from the accelerometer\nand gyroscope sensor data. Lastly,\
    \ feature selection is carried out where we aim to\nreduce the number of features\
    \ used in the last stage that is classification.\nData Pre-processing\nRecordings\
    \ in the SisFall dataset vary in length between 12 and 100 seconds. The\ntrial\
    \ recordings for falls in the SisFall dataset consist of subjects performing various\n\
    activities before experiencing the fall. For a sound feature extraction process,\
    \ we\nextract equal duration segments of sensor readings from these trials that\
    \ represent\nthe fall taking place along with some part of the pre-fall activity\
    \ being performed.\nTo do this, for each record we first calculate the acceleration\
    \ magnitude (also called\nthe Signal Magnitude Vector (SMV) ) [430] for all sensor\
    \ value samples within a trial\nrecording. The SMV can be calculated as given\
    \ in Eq.1.\nSMVj =\nq\f\fAxj\n\f\f2 +\n\f\fAyj\n\f\f2 +\n\f\fAzj\n\f\f2\n(1)\n\
    93\nwhere SMVj represents the SMV value for a sample j in a given trial. The SMV\n\
    is calculated for all samples and the sample location for the SMV peak value is\n\
    determined within the trial. This is then used as the midpoint for extracting\
    \ a 2.5\nsecond segment from the trial. A segment length of 2.5 seconds was chosen\
    \ as it was\nvisually found to capture all the falls as well as some part of the\
    \ pre-fall activity being\nperformed. Using this scheme, segments were extracted\
    \ for all the fall trials in the\ndataset.\nThere are a total of 1798 fall samples\
    \ in the dataset, after the labeling used, there\nwere a total of 838 samples\
    \ for the forward fall category, 360 samples for the backward\nfall category and\
    \ 600 samples for the lateral fall category. Sample waveforms for the\nthree directions\
    \ of falls and three severity levels have been shown in Appendix A.\nFeature Extraction\n\
    Feature extraction is used to convert inputs in to more useful representations.\
    \ In\nthis experiment, we take cue from the work of [420, 470] who use various\
    \ time and\nfrequency domain features successfully for fall detection and recognition\
    \ of activities\nof daily living. Table 35 lists the features computed for each\
    \ extracted segment. Each\nof these features have been computed for every axis\
    \ of the considered accelerometer\nand gyroscope sensor measurements.\nTable 35.\
    \ Features computed for each fall segment\nDomain\nFeatures Computed\nTime\n25th\
    \ Percentile\n75th Percentile\nDelta\nInterquartile range\nKurtosis\nMean\nMedian\n\
    Maximum\nMinimum\nSkewness\nStandard Deviation\nVariance\nFrequency\nPower Spectral\
    \ Entropy\nPower Spectral Density Mean\nPower Spectral Density Median\nPower Spectral\
    \ Density RMS\nPercentiles (25th Percentile, 75th Percentile) and Interquartile\
    \ Range\nFor a set of numerical values X ordered in arranged ascending order,\
    \ the ith percentile\nis defined as the number n below which i percent of the\
    \ total numbers of X fall below\nit. Therefore, the 25th Percentile (also called\
    \ the First Quartile) is the number in X\nbelow which exactly 25% of the values\
    \ fall. Similarly, 75th Percentile (also called\nthe Third Quartile) is the number\
    \ in X below which exactly 75% of the values fall.\nAnother important quantity\
    \ concerning percentiles is the Interquartile Range (IQ\n94\nRange), also called\
    \ the Midspread. The IQ Range is the difference between the 75th\nPercentiles\
    \ and the 25th Percentiles.\nDelta\nThe Delta represents the difference between\
    \ the minimum and maximum\nvalue of a set of numeric values X.\nKurtosis\nIt’s\
    \ a metric for how much a distribution’s tails diverge from that of\na normal\
    \ distribution. A large Kurtosis values indicates to larger extremity of the\n\
    divergences which can be thought of as outliers. The Kurtosis for a set of numerical\n\
    values X can be calculated as given in Eq. 2.\nKurtosis(X) =\n1\nNσ4\nN\nX\ni=1\n\
    (xi − µ)4\n(2)\nMean\nFor a set of values X, the arithmetic mean or the average\
    \ returns the\ncenter value of X. Mathematically it is given in Eq. 3.\nMean(X)\
    \ =\nPN\ni=1 xi\nN\n(3)\nMedian\nFor a set of values X, the median indicates to\
    \ the central tendency of\nX. It divides a set of values in to two equal parts.\
    \ For a set X of size N arranged in\nascending order, the median can be calculated\
    \ as in Eq. 4.\nMedian(X) = X[N + 1\n2\n]\n(4)\nMaximum\nFor a set of values X,\
    \ the maximum value represents the largest\nvalue in the set X.\nMinimum\nFor\
    \ a set of values X, the minimum value represents the smallest\nvalue in the set\
    \ X.\nSkewness\nThe Skewness measures the lack of symmetry in the probability\
    \ dis-\ntribution of data around its mean. It is calculated as in Eq. 5.\nSkewness(X)\
    \ =\n1\nNσ3\nN\nX\ni=1\n(xi − µ)3\n(5)\nStandard Deviation and Variance\nThe Standard\
    \ Deviation measures the\nvariation of a set of numerical values around its mean.\
    \ For a set of numerical values\nX, the standard deviation can be calculated as\
    \ in Eq. 6.\n95\nStd(X) =\nsPN\ni=1(xi − µ)2\nN\n(6)\nwhere µ is the Mean of X.\
    \ The Variance of X is the square of the Standard\nDeviation.\nPower Spectral\
    \ Density\nThe Power Spectral Density (PSD) is an indication\nto the power content\
    \ of a signal with respect to its frequency. It therefore helps to\nunderstand\
    \ the distribution of power in the signal for the different frequencies that\n\
    comprise it. The PSD has been computed using the Welch method [471]. Once the\n\
    PSD has been computed, the mean, median and Root Mean Squared (RMS) values\nof\
    \ the PSD are computed.\nPower Spectral Entropy\nThe Power Spectral Entropy (PSE)\
    \ is a measure of\nthe entropy in the power spectrum of a signal and indicates\
    \ to the complexity present\ntherein. It is computed as an entropy calculation\
    \ on the normalized PSD estimate.\nSimilar to the PSD computation, the Welch method\
    \ was used to estimate the PSD\nbefore PSE calculations were performed.\nThe aforementioned\
    \ quantities were computed for all windowed samples of the fall\nrecordings. In\
    \ total, this resulted in 96 features being computed for each segment.\nBefore\
    \ these features are passed on to the next stage, normalization was performed\n\
    feature wise for each sensor.\nFeature Selection\nFeature selection is an important\
    \ step in the machine learning pipeline. It not only\nhelps to reduce the feature\
    \ set size used in an application which helps computationally\nbut may also result\
    \ in performance improvement as observed by [472]. Feature se-\nlection is performed\
    \ using Random Forest Recursive Feature Elimination (RF-RFE)\n[473] which involves\
    \ determining the importance of features by eliminating features\niteratively\
    \ and looking at classifier performance. It starts by developing a model us-\n\
    ing all the available features within the dataset, in every iteration, the feature\
    \ that\nhas the ’least importance/contribution’ is discarded and a new model is\
    \ fitted with\nthe remaining features. This process is carried out until a pre-decided\
    \ number of\nfeatures remain. Since in this work, our goal is to reduce the number\
    \ of features\nfrom the original count, we perform manual tests by establishing\
    \ a baseline for the\nperformance of our models. The baseline is formed by using\
    \ all features for each\nof our classification tasks and using the highest weighted\
    \ F1-score achieved as the\nperformance goal cut-off for the reduction of features.\
    \ This step will ensure that we\natleast get the same performance as the original\
    \ feature set.\nClassification\nClassification refers to the usage of a classification\
    \ algorithm, also called a classifier\n96\nto determine the output ’label’ or\
    \ category given a set of input values called features.\nIn the current setting,\
    \ the classification problem is a supervised one wherein the\nclassifier is provided\
    \ inputs and their corresponding output labels which allow it\nto learn the relationship\
    \ between the input and the output.\nOnce this mapping\nhas been sufficiently\
    \ learned (a process called training) the trained classifier can\nbe provided\
    \ unlabeled inputs for it to predict an output label value or class. The\nefficacy\
    \ of the classifier in predicting the correct output is measured through various\n\
    metrics such as accuracy, precision, recall, F1-score etc. This experiment consists\
    \ of\ntwo classification experiments being performed, one is the direction only\
    \ experiment\nwhere the classifiers used are trained to distinguish between the\
    \ three direction of falls\ngiven the input feature set and another experiment\
    \ where the classifiers are trained\nto determine fall directions and severity\
    \ together.\nFour different classifiers were tested to perform these tasks, these\
    \ are the Random\nForest Classifier, Support Vector Machines, Decision Trees and\
    \ Extreme Gradient\nBoost (XGBoost). All of the classifiers were trained using\
    \ five fold cross validation\nwith a stratified split and a parameter search being\
    \ performed for tuning purposes.\nSupport Vector Machines\nSupport Vector Machine\
    \ is a supervised learning\nalgorithm that, in its simplest form tries to fit\
    \ a line in between data samples of two\ndifferent classes to separate them. The\
    \ criteria used by the SVM to fit this line is\nthe maximization of the distance\
    \ between the line and the (data) points closest to it.\nThis concept of using\
    \ a line to separate two dimensional data can be extended to two\ndimensional\
    \ planes being used for separating three-dimensional data and hyperplanes\nfor\
    \ higher dimensional data. SVMs are quite flexible in that they can not only be\
    \ used\nto work with linearly separable data but also with data that is not linearly\
    \ separable.\nThis is achieved using Kernel functions which map the nonlinearly\
    \ distributed data\nin to a higher dimensional space to make it linearly separable\
    \ (as much as possible).\nThere are several kernel functions available to be used\
    \ for this purpose such as the\nhyperbolic tangent, radial basis, sigmoid, polynomial\
    \ etc. Optimizing the SVM re-\nquires the tuning of the cost parameter C, a small\
    \ value of C indicates an underfit\nwhereas a very large value of C indicates\
    \ an overfit.\nEven though, the current experiment considers using SVMs for a\
    \ classification\ntaks, it should also be mentioned that SVM’s are not limited\
    \ to application towards\nclassification problems and they have also been used\
    \ for regression applications too.\nDecision Tree\nDecision Trees are one of the\
    \ most widely used classification\nalgorithms due to their interpretability. The\
    \ aim of the algorithm is to come up with\nas simple a solution as possible while\
    \ successively dividing the data in to simpler and\nsimpler classification tasks\
    \ based on the values of the features. For a classification\nproblem, given a\
    \ set of input features of the training set, decision trees use the values\nof\
    \ the features to divide or split the dataset in to more simpler sub problems.\
    \ The\naim being to get the largest information gain when choosing the feature/s\
    \ for the\nsplit. Each split point in a decision tree is called a node and each\
    \ split is called a\nbranch. Branches from a given node represent all the possible\
    \ outcomes from that\n97\nnode and may contain subsequent decision nodes as well\
    \ which are called child nodes.\nEach branch ends at a node called the leaf node\
    \ where data points are assigned a\nclass label.\nDepending on the number of input\
    \ features and the output classes, decision trees\ncan be built to classify the\
    \ dataset in a ’complete’ manner due to its iterative parti-\ntioning scheme.\
    \ However, this is undesirable since that would lead to overfitting of the\nmodel\
    \ and also because such trees would lead to a complicated model, which is not\n\
    desirable since that would impact interpretability. The process of removing branches\n\
    and replacing them by leaf nodes is called pruning. Pruning aims to increase the\n\
    models generalizations capabilities and increase robustness. Two paramters which\n\
    are used for this purpose are tree depth limits the number of child nodes present\
    \ in\nevery branch and the number of features used at each split.\nRandom Forest\
    \ Classifier\nRandom forest is a bagging approach towards de-\ncision trees where\
    \ instead of deciding on where to split for each node, for each tree\na random\
    \ subset of features is used and the feature/threshold to split the data is\n\
    determined within that subset of features to separate the data in the best manner\n\
    possible. This process is repeated multiple times which results in various trees\
    \ pro-\nducing possibly different predictions. The predictions from each tree\
    \ are combined\nto form an ensemble either through majority voting or by averaging.\
    \ The imple-\nmentation of Random Forests used in this work uses the averaging\
    \ approach. There\nare several parameters that are important in the tuning of\
    \ Random Forests are the\nnumber of trees created before the averaging process\
    \ starts, the number of levels in\neach tree and more.\nExtreme Gradient Boost\n\
    Extreme Gradient Boost is another ensemble based\ntree algorithm, however compared\
    \ to the RFC, XGBoost uses boosting instead of\nbagging. In boosting, the input\
    \ samples are uniformly weighted and first a ’weak’\nlearner (classifier) is created\
    \ for a given task that doesnt perform well but is sufficient\nin the sense that\
    \ it is better than random guessing. In subsequent iterations of the\nlearner,\
    \ input samples which werent classified correctly by the learner are reweighted\n\
    by assigning larger weights to them while the weights for correctly classified\
    \ inputs\nis reduced. This step is repeated for a number of times with different\
    \ weak learners\nbeing trained.\nThe decision of the weak learners are combined\
    \ through majority\nvoting to determine the output class. Parameters used to tune\
    \ XGBoost are the\nmaximum depth allowed in each tree, the weight settings etc.\n\
    2.8.1.3\nResults\nAs mentioned previously, two separate experiments were conducted,\
    \ first was to dif-\nferentiate between fall directions only and the other to\
    \ differentiate between fall\ndirection as well as severity. The results from\
    \ those experiments are presented here.\nThe metrics considered for judging model\
    \ quality is the F1-score. The F1-score is the\nharmonic mean of the precision\
    \ and recall and is given as in Eq. 7.\n98\nF1 Score = 2 ∗ (Precision ∗ Recall)\n\
    Precision + Recall\n(7)\nwhere Precision is the ratio of the True positive samples\
    \ divided by the sum of the\nTrue positive and False positive samples as given\
    \ in Eq. 8. It is also called positive\npredictive value as it indicates to the\
    \ capability of the classifier to identify correctly\nthe samples of a given class.\n\
    Precision =\nTrue Positive\nTrue Positive + False Positive\n(8)\nand recall indicates\
    \ to the models capability to identify the samples of a given\nclass over the\
    \ whole dataset. It is also called the sensitivity and is the ratio of the\nTrue\
    \ positives to the sum of the True positives and False Negatives as shown in Eq.\n\
    9.\nRecall =\nTrue Positive\nTrue Positive + False Negative\n(9)\nWe report on\
    \ the F1-scores for each class when discussing classification perfor-\nmance and\
    \ deciding on the best classifier. Moreover, for the best classifier identified\n\
    the precision and recall have also been provided.\nFall direction\nIn this experiment,\
    \ fall segments labeled for direction only were used as input to the\nclassifiers.\
    \ To establish a baseline to be used as a reference in the feature selection\n\
    process, all computed features (96 in total) were passed to the four classifiers.\
    \ The\nbest performing model was found to be the SVM with a weighted F1-score\
    \ of 90.4%.\nFeature selection was then performed keeping in view baseline performance\
    \ of the\nSVM classifier so as to retain or improve this performance baseline\
    \ when choosing a\ngiven number of ’top’ features. Following this rule, feature\
    \ selection resulted in 90\nfeatures. The results are given in Table 36. It can\
    \ be observed from the table that\nthe SVM has outperformed the other algorithms\
    \ in detecting forward and lateral falls\nwhereas it achieves a slightly lower\
    \ F1-score for the backward fall class. Overall the\nSVM has shown to be better\
    \ at discriminating falls with direction.\nTable 36. Fall F1-scores (Fall direction\
    \ only)\nFall\nClassifier (F1-score %)\nSVM\nDT\nRFC\nXGBoost\nBF\n96.05\n92.22\n\
    96.59\n96.63\nFF\n92.67\n83.60\n90.10\n89.49\nLF\n88.67\n71.78\n85.63\n84.35\n\
    Average\n92.46\n82.53\n90.77\n90.15\n99\nFall direction and severity\nIn this\
    \ experiment, fall segments from the dataset were labeled for direction and\n\
    severity based on the labeling shown in Table 34 and passed to each of the classifiers\n\
    after feature selection. Like before, to establish a baseline, all computed features\
    \ (96\nin total) were passed to the four classifiers. The best weighted F1-score\
    \ of 78.44% was\nachieved by the SVM classifier. We used this value as the baseline\
    \ we aim to achieve\nafter feature selection. With this condition the number of\
    \ features were reduced to\n93. The performance achieved for each of the four\
    \ tested classifers is summarized in\nTable 37. It can be observed that the SVM\
    \ is the best performing classifier for all fall\ntypes bar FHF where the random\
    \ forest classifer achieves a slightly higher F1-score.\nThe highest F1-score\
    \ overall is achieved for the class BSF where as the lowest has\nbeen achieved\
    \ for LHF. When looking at fall direction, falls in the forward direction\ncan\
    \ be seen to be the hardest to identify followed by lateral falls. No such pattern\n\
    can be noted for soft/hard falls.\nTable 37. Fall F1-scores (Fall severity and\
    \ direction)\nFall\nClassifier (F1 Score %)\n[]\nSVM\nDT\nRFC\nXGBoost\nBHF\n\
    87.27\n50.00\n69.39\n66.67\nBSF\n95.08\n77.88\n88.33\n85.47\nFHF\n72.43\n54.02\n\
    75.56\n67.04\nFSF\n73.25\n50.60\n67.57\n58.93\nLHF\n66.67\n29.85\n35.90\n50.00\n\
    LSF\n84.65\n62.24\n75.17\n75.69\nAverage\n79.89\n54.10\n68.65\n67.30\n2.8.1.4\n\
    Discussion\nTo summarize the results from both experiments, we present the individual\
    \ F1-\nscores, Precision and Recall for the best performing classifier in each\
    \ case. These\nhave been presented in Table 38 and Table 39.\nTable 38. Best Results:\
    \ Fall direction\nFall\nPrecision (%)\nRecall (%)\nF1-score (%)\nBF\n94.44\n97.70\n\
    96.05\nFF\n93.33\n92.02\n92.67\nLF\n88.67\n88.67\n88.67\nAverage\n92.16\n92.80\n\
    92.46\nIn both cases the best performing classifier was the SVM. This is inline\
    \ with\nthe findings of other research work as found from the literature review\
    \ [424, 429].\nA surprising outcome during this work was the unsatisfactory performance\
    \ of tree\nbased algorithms contrary to [420], we attribute this to the difference\
    \ in the data\nsegmentation scheme and also the fact that we follow different\
    \ labelling for the data\n100\nTable 39. Best Results: Fall direction and Severity\n\
    Fall\nPrecision (%)\nRecall (%)\nF1-score (%)\nBHF\n80.00\n96.00\n87.27\nBSF\n\
    96.67\n93.55\n95.08\nFHF\n74.44\n70.53\n72.43\nFSF\n74.17\n72.36\n73.25\nLHF\n\
    60.00\n75.00\n66.67\nLSF\n85.00\n84.30\n84.65\nAverage\n78.38\n81.96\n79.89\n\
    in terms of a direction and severity aware system. Moreover, the final weighted\
    \ F1-\nscores for the fall direction experiment was 92% and for the fall direction\
    \ and severity\nwas 79.53% which resulted in an improvement of just above 1% in\
    \ both cases with a\nsmall reduction in the number of features utilized, 90 and\
    \ 93 respectively compared to\n96 in the original feature set. Commenting on the\
    \ direction, the hardest to predict fall\nwas in the lateral direction and the\
    \ classifier incorrectly predicted forward falls and\nlateral falls in both the\
    \ scenarios tested. This highlights the difficulty in capturing\nthe difference\
    \ between these two fall directions using the features considered.\n2.8.2\nFall\
    \ Detection with Severity and Direction along with ADL consid-\neration using\
    \ Wavelet Pooling and K-NN\nThis section provides a framework for a fall and activity\
    \ recognition system. It aims\nto determine an appropriate sensor modality to\
    \ use and the window size to be used\nfor the task. The framework does this as\
    \ a problem of differentiating between various\nactivities of daily living as\
    \ well as various types of falls with regard to fall datection\nbeing direction\
    \ and severity aware. To do this, data from the SisFall dataset is used\nand after\
    \ suitable pre-processing and feature extraction, machine learning algorithms\n\
    are utilized to differentiate between different activities of daily living and\
    \ falls\n2.8.2.1\nData Labeling\nSince we aim to perform activity recognition\
    \ and fall detection with direction and\nseverity, the ADL labeling of the original\
    \ dataset has been modified. This labeling\nhas been shown in Table 40. As can\
    \ be observed from Table 40, the activities Walking\n(W), Jogging (J), Sitting\
    \ (S) and Standing (SB) have been considered for this work\nwhich are typical\
    \ activities in ADL detection problems. Each of these labels includes\ndata from\
    \ multiple original activities, for e.g. activities with original labels of walking\n\
    upstairs and downstairs, walking slowly and walking quickly have been considered\
    \ as\nwalking in this work. A similar scheme has been used for the other three\
    \ activity\nlabels as well. Some of the activities such as being on one’s back\
    \ change to lateral\nposition, wait a moment, and change to one’s back (D14),\
    \ getting in and out of the\ncar (D17), stumble while walking (D18), and gently\
    \ jumping without falling while\ntrying to reach a high object (D19) have not\
    \ been considered. The reason for this\nis that they have very few samples to\
    \ be considered as standalone activities (only\none type of sub-activity and also\
    \ because most of these are not considered in typical\n101\nADL detection scenarios).\
    \ For falls, the labeling same as that for the direction and\nseverity experiment\
    \ has been retained.\nTable 40. ADL Labels used for SisFall Recordings.\nActivity\
    \ Code\nAssigned Activity Name\nAssigned Activity Label\nD01\nWalking\nW\nD02\n\
    Walking\nW\nD03\nJogging\nJ\nD04\nJogging\nJ\nD05\nWalking\nW\nD06\nWalking\n\
    W\nD07\nSit\nS\nD08\nSit\nS\nD09\nSit\nS\nD10\nSit\nS\nD11\nSit\nS\nD12\nSit\n\
    S\nD13\nSit\nS\nD14\n-\n-\nD15\nStanding\nSB\nD16\nStanding\nSB\nD17\n-\n-\nD18\n\
    -\n-\nD19\n-\n-\n2.8.2.2\nMethodology\nFigure 18 shows the methodology for this\
    \ work with individual parts being elab-\norated upon in the proceeding subsections.\
    \ As can be seen, the first stage consists of\ndata preprocessing, followed by\
    \ feature extraction and then evaluation or classifica-\ntion.\nData Preprocessing\n\
    Data preprocessing for this experiment was performed in a similar manner to section\n\
    2.8.1 for most recordings. The SMV was computed for the complete recording and\n\
    windowed segments of a fixed duration were extracted.\nWindowed segments are\n\
    extracted in this manner from all considered activities in the SisFall dataset\
    \ except\nthe activities of D01, D02, D03 and D04 which consist of a single trial\
    \ per subject of\nduration 100s. In such cases, continuous windowed segments of\
    \ duration n seconds\nare extracted from the recordings. It is also pertinent\
    \ to mention here that since\nboth accelerometers are placed at the same position,\
    \ we only consider one of the\naccelerometers along with the gyroscope readings\
    \ present in the recorded trials. To\ndetermine the value of n as well as the\
    \ appropriate sensor modality to use for the\nfinal system, experiments were performed\
    \ on the developed framework and the results\nhave been discussed in subsequent\
    \ sections.\nFeature extraction\nIn this experiment, feature extraction consists\
    \ of two steps. The first is the use of\n102\nWindowing\nWavelet Coefficient\n\
    Extraction\nSpatial Pyramid\nPooling\nKNN Classifier ADL\nvs Fall \n(W J, S, SB,\
    \ Fall)\nKNN Classifier\nSeverity \n(HF, SF)\nKNN Classifier\nDirection \n(F,\
    \ B, L)\nFeature\nExtraction\nHierarchical\nClassification\nData\npreprocessing\n\
    Peak SMV detection\nFall ?\nOutput Class \n(W, J, S, SB, FHF, FSF, BHF, BSF, LHF,\
    \ LSF)\nDetermination of Fall type (Voting)\nYes\nNo\nIMU Recording (Falls and\
    \ Activities) \n(W, J, S, SB, FHF, FSF, BHF, BSF, LHF, LSF)\nFigure 18. Hierarchical\
    \ classification scheme for ADL and Fall detection.\nwavelets [474] for performing\
    \ wavelet decomposition and then performing pooling,\nthe inspiration for this\
    \ type of feature extraction came from the work of [475].\n103\nWavelet Decomposition\n\
    Wavelets can be used for a variety of applications\nsuch as spectral analysis\
    \ where they are used to analye a signal in the time-frequency\ndomain, denoising,\
    \ compression and signal enhancement. A wavelet is a function of\nfinite duration\
    \ and has an average value of zero, an example of a mexican hat wavelet\nis shown\
    \ in Figure. 19. The width of the wavelet is called its scale and it is analogous\n\
    to frequency in an inverse manner. A large value of the scale (wider window) allows\n\
    for capturing of low frequency components of the signal whereas a small scale\
    \ value\ncaptures low frequency components.\n0\n20\n40\n60\n80\n100\n0.2\n0.1\n\
    0.0\n0.1\n0.2\n0.3\n0.4\nAmplitude\nMexican Hat Wavelet\nFigure 19. Sample Wavelet\
    \ (Mexican Hat).\nWavelets are convolved with an input signal to produce two sets\
    \ of coefficients.\nThese are called the detail and approximation coefficients.\
    \ The detail component\nrepresents the high frequency component captured by the\
    \ wavelet whereas the ap-\nproximation component represents the low frequency\
    \ part. Since the wavelet has\nonly been convolved once with the signal, these\
    \ coefficients are said to be level 1\ncoefficients. At each level, resulting\
    \ coefficients are downsampled by half to result in\na lower resolution signal.\
    \ Subsequent approximation components can be convolved\nwith the wavelet to result\
    \ in approximation and detail components for the next level\nthus forming what\
    \ is called a wavelet decomposition tree.\nTo perform wavelet decomposition, in\
    \ this experiment, we make use of the Haar\nwavelet [476] shown in Figure. 20.\
    \ Level 4 haar wavelets were computed for each of\nthe extracted segments of the\
    \ signals.\nSpatial Pooling\nThe results from the decomposition provide a large\
    \ number\nof features which would pose a problem for use in the proceeding classification\
    \ stage.\nIn order to reduce the feature dimension size, Spatial Pyramid Pooling\
    \ [477] was\nused. Spatial Pyramid Pooling is an adaptive pooling method which\
    \ was developed\nto address the issue of fluctuating input sizes in CNNs for image-based\
    \ applications,\nand it entails converting varying-size convolutional feature\
    \ maps into fixed-length\nsummarizations. These summarizations, having uniform\
    \ length can then be passed\non to the fully connected parts of the CNN where\
    \ a fixed length input is necessary.\n104\n1.0\n0.5\n0.0\n0.5\n1.0\n1.5\n2.0\n\
    1.00\n0.75\n0.50\n0.25\n0.00\n0.25\n0.50\n0.75\n1.00\nAmplitude\nHaar Wavelet\n\
    Figure 20. Haar Wavelet.\nGiven a pooling size pxp, adaptive pooling works by\
    \ dividing the input in to pxp pieces\nwhile computing the size of each piece\
    \ automatically and performing any necessary\npadding. Once these pieces are created,\
    \ a pooling operation is typically performed\n(max pooling or average pooling\
    \ for e.g.) on each of these pieces to summarize the\ninput into an output of\
    \ fixed size pxp. This results in a fixed output length for any\nsize of the input.\
    \ In this experiment, 4-2-1 1D Spatial Pyramid pooling was used\non the detail\
    \ and approximation coefficients of the wavelet decomposition of activity\nand\
    \ fall data. This process has been shown in Figure 21. Each coefficient set was\n\
    divided in to four and two parts and then max pooling was used to determine the\n\
    maximum value in these divided parts and the coefficient set as a whole.\nThese\n\
    maximum values were then concatenated together to form the seven valued output\n\
    from that coefficient set. Furthermore, the results for each coefficient set within\
    \ each\naxis were also concatenated to form the feature vector for a sensor axis\
    \ measurement.\nThis operation was performed for each axis of accelerometer and\
    \ groscope sensor\ndata with the final feature vector of 210 values consisting\
    \ of the concatenations of\nthe individual vectors for each axis. It is hypothesized\
    \ that this way local as well as\nglobal information at each level of the wavelet\
    \ coefficients can be captured. For the\nwavelet decomposition, tests were performed\
    \ with level values of 2, 3, 4, 5 and 7 and\nit was determined that level-4 produced\
    \ the best results.\nClassification\nA hierarchical classification approach is\
    \ employed to discriminate between the vari-\nous activities and falls considered\
    \ from the SisFall dataset. Hierarchical classification\ninvolves the division\
    \ of a complex taxonomic classification problem in to a set of\nsubsets that are\
    \ potentially easier to differentiate as the task becomes more localized.\nHierarchical\
    \ classifiers have been used in multiple different applications [478] where\n\
    they have been found to improve upon the performance of many flat classification\n\
    schemes. The classification framework used in this work combines hierarchical\
    \ clas-\nsification with a vote based system. The classification problem is divided\
    \ into three\nparts, each with its own classifier to indicate to the subclass\
    \ of the output. The clas-\n105\nMaxpooling Size = 4\nMaxpooling Size = 2\nMaxpooling\
    \ Size = 1\nMaxpooled Coefficients - 4\nMaxpooled Coefficients - 2\nMaxpooled\
    \ Coefficients - 1\nConcatenated cofficients for maxpooled wavelet coefficients\n\
    c1\nc2\nc3\nc4\nc5\nc6\nc7\nc8\nc9\nc10\nc11\nc12\nn Wavelet coefficients ( n\
    \ = 12 e.g.)\nMax (c1, c2, c3)\nMax (c4, c5, c6)\nMax (c7, c8, c9)\nMax (c10,\
    \ c11, c12)\nMax (c1, c2, c3, c4, c5, c6)\nMax (c7, c8, c9, c10, c11, c12)\nMax\
    \ (c1, c2, c3, c4, c5, c6,c7, c8, c9, c10, c11, c12)\nFigure 21. Example: 4-2-1\
    \ 1-D Spatial Pyramid Pooling.\nsifier in part one consists of differentiating\
    \ whether a given recording is a fall or one\nof the four considered ADLs. In\
    \ order to train this stage, the activities of Standing,\nWalking, Sitting and\
    \ Jogging along with all falls combined in to one class are passed\nto the classifier.\
    \ This dilutes the original ten-class problems in to a five-class sub\nproblem.\
    \ The output of this stage is the determination of whether a given recording\n\
    is either one of the four ADLs (Standing, Walking, Sitting or Jogging) or a fall.\
    \ If a\nrecording has been detected to be a fall, it is sent to the second and\
    \ third stages.\nThe second and third stages work in parallel on samples detected\
    \ as falls from\n106\nthe first stage in the form of a voting machine. These two\
    \ stages vote individually\non the direction and severity of the detected fall\
    \ samples. In order to train them,\nfall samples were relabeled to represent direction\
    \ and severity only and are fed to the\nclassifiers. For the direction, the classification\
    \ problem is formulated as a three-class\nproblem of determining fall directions\
    \ as being Forward, Backward or Lateral. For\nthe severity classifier, the classification\
    \ problem is formulated as a two-class problem\nof a fall being either Soft or\
    \ Hard. After a signal has passed through all necessary\nstages, the outputs of\
    \ the individual stages are combined to indicate to the activity\nor type of fall\
    \ being fed at the input.\nFour classifiers were tested for each part of the hierarchical\
    \ scheme, the classifiers\nconsidered were K-Nearest Neighbors, Support Vector\
    \ Machines, Random Forests\nand eXtreme Gradient Boosting. Parameter tuning was\
    \ performed using gradient\nsearch for each classifier over a range of values\
    \ for each parameter.\nK-Nearest Neighbor\nCompared to the SVM which attempts\
    \ to create a deci-\nsion boundary between classes on a global level, the K-NN\
    \ algorithm operates locally.\nStarting from a data point, the 1 Nearest Neigbhor\
    \ algorithm will assign each new\nsample the class of its neighbor. However, using\
    \ a single neighborhood point to assign\nnew classes may lead to erroneous classes\
    \ being assigned. Therefore, typically mul-\ntiple neighboring points are used\
    \ to determine the label for a given point. In K-NN,\n’K’ represents the number\
    \ of points used in the neighborhood to assign labels to data\nsamples. Each considered\
    \ sample is assigned the majority label within a neighbor-\nhood of K points around\
    \ it. In this manner, the K-NN algorithm is successively able\nto create a decision\
    \ boundary separating the data in to the different output classes.\n2.8.2.3\n\
    Results\nThree experiments were performed in this section. The first was to choose\
    \ the best\nclassifier to use, once that was determined. experiments were conducted\
    \ to determine\nthe observation window size and different combination of sensor\
    \ modalities. We used\nthe weighted F1-score as our training metric due to the\
    \ imbalance in the samples\nof the different classes in the data. Moreover, for\
    \ evaluation purposes, we report on\nthe individual F1-scores for each output\
    \ class and provide discussions as necessary.\nFurthermore, for the best performing\
    \ results, the Precision and Recall and Specificity\nwere also specified. Specificity\
    \ can be calculated as given in Eq. 10. It is also called\nthe True Negative Rate\
    \ and indicates to a classifiers capability to correctly detect\nsamples which\
    \ don’t belong to a given class. These metrics have been computed on\na one versus\
    \ all basis.\nSpecificity =\nTrue Negative\nTrue Negative + False Positive\n(10)\n\
    The data after the feature extraction stage was split in to a train/test partition\n\
    based on a 75/25 ratio with a parameter grid being searched through to obtain\n\
    107\ntuning parameters for maximizing the weighted F1-score while using five-fold\
    \ cross\nvalidation.\nClassifier Selection\nThis test was conducted to determine\
    \ the best classifier to use for the proceeding\nexperiments of observation window\
    \ selection and sensor modality selection. Here,\nexperiments were performed for\
    \ the considered window durations for each activity\nand the classifier which\
    \ provided the best performance overall was chosen. The mean\nF1-scores for each\
    \ output class for each classifier are shown in Figure 22. It can be\nobserved\
    \ that in general K-NN and SVM perform better compared to the ensemble\nmodels,\
    \ the RFC and XGBoost. However, since the K-NN slightly outperforms the\nSVM in\
    \ eight of the ten considered classes, we choose K-NN as the classifier for this\n\
    framework.\nBHF\nBSF\nFHF\nFSF\nJ\nLHF\nLSF\nS\nSB\nW\n0\n20\n40\n60\n80\n100\n\
    F1 Score (%)\nAverage F1 Scores for each activity\nKNN\nSVM\nRFC\nXGB\nFigure\
    \ 22. Average F1-scores for each activity for the four classifiers.\nObservation\
    \ Window Duration\nAn important consideration in working with activity recognition\
    \ systems is to de-\ntermine the appropriate observation window size for the analysis\
    \ of sensor signals\nto accomplish the ADL recognition/fall detection task. The\
    \ size of the observation\nwindow is important as a smaller observation window\
    \ increases the response time of\nthe activity recognition/fall detection system\
    \ and it can also impact the time taken\nin the computation of features. In order\
    \ to find the best observation window size,\nwe perform experiments using five\
    \ values, 2, 3, 4, 5 and 6 seconds. The classification\nresults in terms of the\
    \ F1-score are presented in Table 41. For each case, samples\nof duration equal\
    \ to half of the observation window were extracted around the peak\nvalue of the\
    \ SMV. From the table, it can be observed that an observation window\n108\nof\
    \ size 3 seconds produces the best results for six out of the ten output classes.\
    \ It\nonly produces poorer results for the classes BHF, BSF and S, SB where window\
    \ sizes\nof 2 seconds, 6 seconds and 4 seconds respectively perform better than\
    \ the 3 second\nwindowing case. Upon further investigation of this phenomenon\
    \ using the result of\nother classifiers, it was observed that the activities\
    \ of (BHF and BHF) were best rec-\nognized by all the classifiers with a window\
    \ size of 2 seconds (for the case of K-NN,\nthere is a small difference between\
    \ the 2 second and 6 second case), for the other two\nactivities of S and SB too\
    \ the F1-score was obtained for the 4 second duration (for\nthe activity S, the\
    \ difference in performance over windows larger than 4 seconds is\nvery small).\
    \ This could be attributed to the feature aggregation process in the max\npooling\
    \ operation in the different spatial segments.\nTable 41. Performance for different\
    \ observation window sizes.\nActivity/Fall\nObservation Window Size (F1-score\
    \ [%])\n2 sec\n3 sec\n4 sec\n5 sec\n6 sec\nBHF\n86.79\n83.02\n79.25\n83.64\n85.19\n\
    BSF\n92.17\n90.76\n89.08\n90.76\n93.22\nFHF\n78.53\n80.47\n78.32\n79.21\n78.83\n\
    FSF\n73.39\n77.18\n72.5\n76.83\n76.79\nLHF\n52.83\n67.8\n62.75\n59.26\n58.62\n\
    LSF\n79.69\n82.73\n77.57\n81.46\n79.41\nJ\n97.53\n98.27\n98.08\n98.00\n98.16\n\
    S\n95.27\n96.20\n97.60\n95.84\n95.93\nSB\n87.29\n85.71\n91.98\n90.61\n91.71\n\
    W\n98.08\n98.46\n98.12\n98.35\n98.16\nAverage\n84.16\n86.68\n84.52\n85.40\n85.60\n\
    Sensor Modality\nThe second experiment in designing the proposed system is the\
    \ determination of\nthe best sensor modality to use.\nUsing a single sensor would\
    \ result in less data,\nfaster processing and reduced hardware costs compared\
    \ to the multisensor approach\ncombining accelerometer and gyroscope. To do this,\
    \ the classification framework was\ntested with 3 second windowed segments of\
    \ the combined acceleromter and gyroscope\ndata as well as data of the accelerometer\
    \ and gyroscope sensors individually. The\nresults of this experiment are presented\
    \ in Table 42. It can be observed that using\na combination of both accelerometer\
    \ and gyroscope data together produces the best\nresults for eight of the ten\
    \ output classes. An accelerometer-only system produces\nbetter results for the\
    \ detection of activity SB and the fall FHF. The outcome of this\nexperiment agrees\
    \ with previous work for fall detection by Waheed et. al. [436] on\nthe SisFall\
    \ dataset.\n2.8.2.4\nDiscussion\nTable 43 reports on the best results obtained\
    \ for the proposed classification frame-\nwork. These results were achieved by\
    \ using windowed segments of 3 seconds and\n109\nTable 42. Performance for different\
    \ sensing modalities.\nActivity/Fall\nSensing Modality (F1-score [%])\nAccelerometer\
    \ + Gyroscope\nAccelerometer\nGyroscope\nBHF\n83.02\n67.92\n82.14\nBSF\n90.76\n\
    85.48\n78.18\nFHF\n80.47\n83.33\n71.17\nFSF\n77.18\n73.21\n63.96\nJ\n98.27\n97.79\n\
    95.59\nLHF\n67.80\n54.55\n55.56\nLSF\n82.73\n76.34\n73.21\nS\n96.20\n95.61\n91.17\n\
    SB\n85.71\n86.21\n76.09\nW\n98.46\n98.24\n96.30\nAverage\n86.06\n81.87\n78.33\n\
    combined data from the accelerometer and the gyroscope with a weighted F1-score\n\
    of 94.67% on the test set.\nTable 43. Best Results (Obs. Window : 3 sec, Sensing\
    \ Modality: Acc. + Gyro.)\nActivity/Fall\nPrecision (%)\nSensitivity/Recall (%)\n\
    Specificity (%)\nF1-Score (%)\nBHF\n95.65\n73.33\n99.96\n83.02\nBSF\n91.53\n90.00\n\
    99.80\n90.76\nFHF\n86.08\n75.56\n99.57\n80.47\nFSF\n76.86\n77.50\n98.88\n77.18\n\
    LHF\n68.97\n66.67\n99.65\n67.80\nLSF\n79.85\n85.83\n98.96\n82.73\nJ\n97.87\n98.68\n\
    99.36\n98.27\nS\n95.00\n97.44\n99.31\n96.20\nSB\n93.75\n78.95\n99.80\n85.71\n\
    W\n97.95\n98.97\n98.36\n98.46\nAverage\n88.35\n84.29\n99.37\n86.06\nFrom Table\
    \ 43, the best recognized ADLs are W and J whereas the best rec-\nognized fall\
    \ is BSF. The worst performing class in ADLs is SB whereas the worst\nperforming\
    \ fall is LHF. Upon further inspection of the cause of the bad performance\nwith\
    \ LHF, looking at the confusion matrix, it was observed that LHF was most\ncommonly\
    \ confused with FSF which resulted in a reduction of the classification per-\n\
    formance for this class. On the other hand, in the case of FSF (the second worse\n\
    performing class), looking at the confusion matrix, it was observed that FSF was\n\
    confused with LSF and FHF. Furthermore, the specificity values indicate that there\n\
    has been very little mis-identification for each of the classes. When talking\
    \ about\nthe activity S, it was observed that samples from this activity were\
    \ confused with\nthe activity W which resulted in the sub-par performance of the\
    \ classifier for its\nrecognition.\n110\n2.8.3\nFall Detection with Severity and\
    \ Direction along with ADL consid-\neration using CNN-XGBoost\nThis section presents\
    \ a scheme for performing fall detection considering fall direction\nand severity\
    \ as well as activity recognition. Inertial sensor data taken from the SisFall\n\
    dataset is used to develop the methodology. Data pre-processing is first carried\
    \ out\nin terms of windowing and relabeling. Then, data augmentation is carried\
    \ out for\nclasses which do not have a sufficient number of samples. Lastly, feature\
    \ extraction is\nperformed along with classification. This work considers fall\
    \ and activity recognition\nas a holistic problem, in that different types of\
    \ falls and activities are considered\nthereby producing a more ’complete’ recognition\
    \ system for use in cyber-physical\nsystems. Moreover, towards this end, a CNN-XGBoost\
    \ combination is proposed.\n2.8.3.1\nMethodology\nThe proposed scheme follows\
    \ a typical deep learning so-\nlution framework. First, inertial sensor data from\
    \ the IMU sensors contained within\nthe SisFall dataset is pre-processed to extract\
    \ windowed segments, then data aug-\nmentation is performed for minority classes,\
    \ followed by feature extraction and then\nclassification. This has been illustrated\
    \ in Figure 23 and a discussion is provided for\neach of the steps in the proceeding\
    \ sections.\nData Pre-processing\nBefore the IMU sensor recordings can be used\
    \ for ADL and fall detection, raw sensor\nmeasurements need to be suitably processed.\
    \ In this experiment, data pre-processing\nconsists of two steps, the first is\
    \ the extraction of uniform sized windows as was\nperformed in the previous section\
    \ from the IMU recordings and the next is data\naugmentation. Since windowing\
    \ of the signals has already been discussed previously,\nonly data augmentation\
    \ is discussed here.\nData Augmentation\nThe use of deep learning methods require\
    \ a suitable\namount of data to be present for them to learn the data pattern\
    \ sufficiently well. Un-\nfortunately, due to the nature of the problem considered,\
    \ the relabeled data from the\nSisFall dataset contains a reduced amount of data\
    \ for some of the classes, especially\nfall classes and also for the ADL of Standing.\
    \ In order to alleviate this shortcom-\ning, data augmentation was employed to\
    \ increase the number of samples from these\nclasses. Three augmentations were\
    \ performed for each of the extracted recordings\nfor the classes SB, FHF, FSF,\
    \ BHF, BSF, LHFand LSF. These were the addition of\nnoise, scaling and resampling\
    \ after inerpolation [439]. For augmentation with noise,\nwhite gaussian noise\
    \ was added to the extracted windows of the considered classes.\nThe noise was\
    \ generated using a standard deviation equal to 0.01. The addition of\nthe noise\
    \ simulates measurement noise during recording which might be encountered\nwhen\
    \ IMU based fall detection systems are employed. For scale based augmentation,\n\
    the original extracted window was multiplied by a random number from the uniform\n\
    distribution between 0.8 and 1.2 thereby scaling it between 80% and 120% of its\
    \ orig-\ninal form. By doing so, changes in amplitude over the same type of activity/fall\
    \ are\nincorporated. This could indicate to a change in fixation (loosening etc)\
    \ of the sensing\n111\nPeak SMV Detection\nWindowing\nCNN\nXGBoost Classifier\n\
    Data Augmentation\nData Processing\nIMU Recording (Falls and Activities) \n(ADL,\
    \ FHF, FSF, BHF, BSF, LHF, LSF) \n(W, J, S, SB, FHF, FSF, BHF, BSF, LHF, LSF)\n\
    Output Class \n(ADL, FHF, FSF, BHF, BSF, LHF, LSF) \n(W, J, S, SB, FHF, FSF, BHF,\
    \ BSF, LHF, LSF)\nFeature Extraction\nClassification\nFigure 23. CNN-XGBoost based\
    \ classification scheme for ADL and Fall detection.\nunit to a subject or their\
    \ different physique and subsequent fall intensity response.\nLastly, in order\
    \ to incorporate sampling inconsistencies, the windows are first upsam-\npled\
    \ and then downsampled. This was done by a scale of ten. With this strategy,\n\
    each from original window were produced three additional samples. An illustration\n\
    for the results of the augmentation process for an X-axis accelerometer measurement\n\
    for a lateral fall has been shown in Figure 24.\nFeature extraction\nThe aim of\
    \ feature extraction for a classification problem is to produce a representa-\n\
    tion of the input that can be better used to indicate to the output class. In\
    \ this regard,\nresearch in the area of fall detection with inertial sensors has\
    \ made use of different\ntypes of hand crafted features such as statistical, time\
    \ and frequency domain as well\nas wavelet transforms [479, 480, 481, 482]. Convolutional\
    \ Neural Networks (CNNs\nor Covnets) are a set of neural networks developed following\
    \ the visual cortex within\nthe brain [483]. CNNs perform operations on inputs\
    \ by introducing convolutions of\n112\nFigure 24.\nIllustration of data augmentation.\n\
    (X component of Accelerometer,\nLateral Fall)\nseveral filters with learnable\
    \ weights to gauge the importance of each datapoint in\nthe input. These layers\
    \ containing the filters and to which the input is provided are\ncalled convolutional\
    \ layers. Through these learnable weights, CNNs are able to cap-\nture temporal\
    \ and spatial dependencies of the input. Moreover, using the same filters\nfor\
    \ different inputs reduces the number of parameters as the weights are reused.\
    \ This\nallows CNNs to develop a deeper understanding of the provided input compared\
    \ to\ntypical multilayer perceptron models. CNNs have revolutionized the field\
    \ of computer\nvision where they have been used for a variety of tasks such as\
    \ classification, object\ndetection, segmentation and object counting [484, 485]\
    \ and they have also successfully\nbeen used for applications within the speech\
    \ and other time series signal application\ndomain [486, 487, 488]. In this experiment,\
    \ rather than using hand crafted features\n113\nas in the previous experiments,\
    \ a CNN has been used to perform feature extraction\nin order to take advantage\
    \ of the spatial and temporal dependency capturing capa-\nbilities of CNNs. CNNs\
    \ are usually comprised of several convolutional (Conv) layers.\nWithin a multilayer\
    \ CNN, the earlier Conv layers capture low level features from the\ninput with\
    \ more complex features being computed by the successive layers. Also,\nCNNs may\
    \ employ pooling layers between convolutional layers so as to reduce the\nsize\
    \ of the input passed on to successive layers and therefore reduce computation.\n\
    The proposed network along with the XGBoost classification stage is illustrated\
    \ in\nFigure 25.\nConv\n64 filters (3x1)\nConv\n64 filters (3x1)\nConv\n64 filters\
    \ (3x1)\nConv\n64 filters (3x1)\nAvg Pooling\nAvg Pooling\nAvg Pooling\nFlatten\n\
    XGB classification\nStage\nFigure 25. CNN Network for feature extraction and XGBoost\
    \ classification stage.\nAs seen from the figure, the network consists of four\
    \ Conv layers of 64 filters\neach.\nThese layers have filters of size 3x1 and\
    \ are used to extract features from\nraw inertial sensor measurements. Each Conv\
    \ layer is followed by a Relu activation\nfunction which applies a non-linearity\
    \ to the output of the Conv layers. To condense\nthe output of the first three\
    \ Conv layers, a pooling layer is utilized. Instead of max\npooling, average pooling\
    \ is used in this network. Max pooling picks out the largest\nvalue of the patch\
    \ of data being observed currently, in contrast, average pooling uses\nthe average\
    \ of the data being observed. Average pooling has been successfully used in\n\
    114\nplace of max pooling in a variety of scenarios [489, 490]. Normalization\
    \ is performed\nusing a batch normalization layer for each Conv layer. The output\
    \ of the last Conv\nlayer are feature maps derived from the input raw inertial\
    \ sensor measurements from\nboth the accelerometer and the gyroscope.\nClassification\n\
    Classification is carried out by using a eXtreme Gradient Boosting (XGBoost) clas-\n\
    sifier. The output from the CNN is first flattened and then provided as an input\
    \ to\nthe XGBoost stage. The parameters of the XGBoost classifier are tuned through\
    \ a\nparameter search over a range of values. We make use of an XGBoost classifier\
    \ due\nto its suitability for a large dimensional input which results from the\
    \ flattened CNN\noutput.\n2.8.3.2\nResults\nIn order to use the proposed CNN for\
    \ feature extraction, it must first be trained\naccordingly. In order to train\
    \ the network, a fully connected layer with a softmax\noutput was added as the\
    \ final stage to serve as the intermediate temporary output\ndeterminant stage.\
    \ The windowed data from the SisFall dataset was divided in to\nthree sets, train,\
    \ validation and test in a stratified manner. A learning rate of 0.01\nwas used\
    \ for the network with a batch size of 20 and the stochastic gradient descent\n\
    was used as the optimizer. Moreover, the metric chosen was the average of the\
    \ recall\nscores of all classes together, also called as the unweighted average\
    \ recall (UAR).\nThe recall is considered as one wants the system correctly classify\
    \ as many positive\nsamples for every class as possible. The final network was\
    \ determined using early\nstopping. The unweighted average recall (UAR) can be\
    \ computed as,\nUAR =\nk\nX\nn=0\n\x10\nTPn\nTPn+FNn\n\x11\nk\n(11)\nwhere k stands\
    \ for number of classes and TPn stands for the number of True\nPositive samples\
    \ in the nth class and FNn stands for number False Negative samples\nin the nth\
    \ class. Therefore, the average of the individual recall scores from all classes\n\
    was aimed to be maximized.\nData from the training set was provided to the CNN\
    \ network after performing data\naugmentation on the minority classes, during\
    \ training, the validation set was used\nto observe performance of the network\
    \ and determine the best performing instance.\nOnce training was finished, the\
    \ last fully connected classification layer was removed\nand replaced by an XGBoost\
    \ classification stage. To train the XGBoost stage, the\nweights of the final\
    \ best performing CNN model were loaded in to CNN layers of\nthe network and input\
    \ samples were then passed through them as before. Using the\noutput of the CNN\
    \ stage as an input for the XGBoost, a search was then carried\nout to determine\
    \ the optimal parameter values. After training of the XGBoost stage,\nthe completely\
    \ trained CNN-XGBoost model was tested using the test set.\nTwo\n115\nsets of\
    \ tests were performed, one while considering all ADLs as a single class versus\n\
    individual falls and the other considering common individual ADLs and individual\n\
    falls.\nOne ADL vs Individual Falls\nIn this experiment, all ADLs present in the\
    \ SisFall dataset were combined in to one\nclass to build a generic ADL versus\
    \ fall system. The results are presented in Table 44.\nIt can be observed from\
    \ the table that the ADL class has been detected with perfect\nrecall score. Among\
    \ the falls, the worst performance was observed for LHF with the\nbest performance\
    \ for FHF.\nTable 44. One ADL vs. Individual Falls.\nActivity/ Fall\nPrecision\n\
    (%)\nSensitivity/\nRecall (%)\nSpecificity\n(%)\nF1-score\n(%)\nBHF\n100\n91.67\n\
    100\n95.65\nBSF\n100\n95.83\n100\n97.87\nFHF\n85.37\n97.22\n99.41\n90.91\nFSF\n\
    92.86\n81.25\n99.71\n86.67\nLHF\n72.73\n66.67\n99.70\n69.57\nLSF\n89.58\n89.58\n\
    99.50\n89.58\nADL\n99.54\n100\n97.78\n99.77\nAverage\n91.44\n88.89\n99.44\n90.02\n\
    Individual ADLs vs Individual Falls\nThe results of the experiment have been shown\
    \ in Table 45.\nTable 45. Individual ADLs vs. Individual Falls.\nActivity/Fall\n\
    Precision (%)\nSensitivity/Recall (%)\nSpecificity (%)\nF1-Score (%)\nBHF\n100\n\
    75.00\n100\n85.71\nBSF\n95.83\n95.83\n99.90\n95.83\nFHF\n76.19\n88.89\n99.01\n\
    82.05\nFSF\n90.24\n77.08\n99.60\n83.15\nLSF\n86.79\n95.83\n99.30\n91.09\nLHF\n\
    75.00\n75.00\n99.71\n75.00\nJ\n96.71\n96.71\n99.01\n96.71\nS\n96.77\n96.77\n99.57\n\
    96.77\nSB\n91.18\n83.78\n99.70\n87.32\nW\n97.21\n97.63\n97.77\n97.42\nAverage\n\
    90.59\n88.25\n99.36\n89.11\nAn average recall of 88.25% was observed for the experiment.\
    \ From Table 45,\nwhen looking at the recall achieved for the individual activities,\
    \ it can be observed\nthat the best recognized activities are W and J with each\
    \ achieving a recall of around\n97%. The worst performance in terms of ADLs was\
    \ achieved for the activity SB for\nwhich a recall of 83.78% was attained. Considering\
    \ the case of falls, out of the six\nfalls, the worst recall score of 75% was\
    \ achieved for BHF and LHF whereas the best\nrecall score was of 95.83% was achieved\
    \ for BSF and LSF. The fall class FSF was also\n116\nnot identified well, achieving\
    \ a recall score of 77.08%. Furthermore, as observed from\nthe table, a high value\
    \ of specificity was obtained for all ADLs and falls indicating\nto correct determination\
    \ of negative samples for each class as well. Investigating the\nperformance of\
    \ the network from the confusion matrix, it was observed that the worst\nperforming\
    \ activity SB was equally confused as S and W, this can be attributed to\nthe\
    \ fact that the SB activity includes slight bending which could lead to confusion\
    \ for\nthe classifier. For the worst performing falls, it was observed that BHF\
    \ was confused\nwith LHF and LSF whereas LHF was confused with FHF and FSF. The\
    \ confusion\nbetween the falls is apparent from plots shown in Appendix A where\
    \ BHF has very\nsimilar accelerometer signal values to these classes.\n2.8.3.3\n\
    Discussion\nInorder to better understand the performance of the network for the\
    \ various fall\ndetection types from Tables 44 and 45, the performance of the\
    \ network for fall severity\nhas been illustrated in Figure 26. It can be observed\
    \ that soft falls are better detected\ncompared to hard falls with UARs for the\
    \ individual ADL and fall experiment being\n79.63% for hard falls and that for\
    \ soft falls is 89.58%. For the one ADL and individual\nfall experiment, the difference\
    \ is less stark, being 85.18% for hard falls and 88.88%\nfor soft falls.\n60\n\
    65\n70\n75\n80\n85\n90\n95\n100\nInd ADLs/Ind Falls\nOne ADL/Ind Falls\nPerformance\
    \ for Fall Severity\nHard Falls\nSoft Falls\nFigure 26. Network performance for\
    \ different fall directions.\nFigure 27 illustrates the performance of the network\
    \ in fall detection for the three\ndirections considered for both experiments,\
    \ regardless of severity. It can be observed\nthat falls in backward and lateral\
    \ directions are determined with equal effectiveness,\nan average recall score\
    \ (UAR) of 85.42% was achieved for both cases where as for\nthe forward direction,\
    \ the UAR was 82.99%. As can be seen, there is a only a small\ndifference (3.43%)\
    \ between the achieved UARs.\n117\n60\n65\n70\n75\n80\n85\n90\n95\n100\nOne ADL/Ind\
    \ Falls\nInd ADLs/Ind Falls\nPerformance for Fall Directions\nForward Falls\n\
    Backward Falls\nLateral Falls\nFigure 27. Network performance for different fall\
    \ directions.\nIn order to further test the performance of the developed CNN-XGBoost\
    \ scheme,\ntests were performed with the CNN network architecture presented in\
    \ [430].\nWe\nchoose the technique of [430] as the authors provide very good results\
    \ for fall detection\nusing the SisFall dataset using a deep learning model. The\
    \ results for the performance\nof the considered technique in comparison to the\
    \ method presented in this experiment\nis shown Table 46 and 47. The Recall scores\
    \ have been presented. It can be observed\nthat the proposed method outperforms\
    \ the work of Casilari et. al. for all classes\nexcept LHF. Moreover, there is\
    \ a large difference in the average recall achieved.\nTable 46. Comparison with\
    \ State of the art (Individual ADLs vs. Individual Falls.)\nActivity/Fall\nSensitivity/Recall\
    \ (%)\n[]\nWork of [430]\nProposed work\nBHF\n66.67\n91.67\nBSF\n64.58\n95.83\n\
    FHF\n95.83\n97.22\nFSF\n75\n81.25\nLHF\n77.78\n66.67\nLSF\n87.5\n89.58\nADL\n\
    99.31\n100\nAverage\n80.95\n88.89\nThe mean recall score achieved is 85.69% for\
    \ [430] for the individual ADLs vs\nIndividual Fall experiment compared to more\
    \ than 88% for the proposed scheme.\nIt can be observed from Table 47 that the\
    \ proposed CNN-XGBoost combination\noutperforms the work of Casilari et al. [430]\
    \ in seven out of the ten output classes\nfor recall while achieving a similar\
    \ performance for the classes of BHF, LHFand S.\n118\nTable 47. Comparison with\
    \ State of the art (Individual ADLs vs. Individual Falls.)\nActivity/Fall\nSensitivity/Recall\
    \ (%)\n[]\nWork of [430]\nProposed work\nBHF\n75.00\n75.00\nBSF\n87.50\n95.83\n\
    FHF\n80.56\n88.89\nFSF\n72.92\n77.08\nLHF\n75.00\n75.00\nLSF\n93.75\n95.83\nJ\n\
    96.30\n96.71\nS\n96.77\n96.77\nSB\n81.08\n83.78\nW\n95.04\n97.63\nAverage\n85.39\n\
    88.25\n2.8.4\nCross dataset non-binary fall detection with a ConvLSTM-attention\n\
    network\nThis section presents a discussion on fall detection with severity and\
    \ direction along\nwith ADL recognition on the SisFall and the K-Fall datasets.\
    \ Two experiments were\nconducted in this regard, one with all ADLs as one class\
    \ versus the six fall types\nconsidered and another for individual ADLs and falls.\n\
    2.8.4.1\nData Labeling\nSince this experiment also uses the K-Fall dataset, the\
    \ labeling scheme for K-Fall\nis shown in Table 48. The labeling for the SisFall\
    \ dataset was retained the same\nfor the individual ADL and fall experiment.\n\
    However, for the one ADL and fall\nexperiment, all activities were labeled as\
    \ a single class ADL.\n2.8.4.2\nMethodology\nThe methodology consists of the two\
    \ steps of data preprocessing and classifi-\ncation. Data preprocessing has been\
    \ performed in the same manner as in section\n2.8.3.1. Therefore, this section\
    \ focuses on the ConvLSTM network used. The net-\nwork used in this work is illustrated\
    \ in Figure 28. It consists of four layers, the first\nof these is the ConvLSTM\
    \ layer. The ConvLSTM layer combines the properties of\nsequential learning associated\
    \ with LSTMs with the feature extraction capabilities\nof convolutional neural\
    \ networks and they have found successful use in the human\nactivity recognition/fall\
    \ detection domain [491, 492]. By replacing the simple matrix\nmultiplication\
    \ within LSTM cells by a convolutional operation, the ConvLSTM can\ncapture spatio-temporal\
    \ dependencies as opposed to the temporal only qualities of-\nfered by LSTMs.\
    \ Such spatial information is useful for the problem of fall detection\nwhere\
    \ not only the sequence contained within the recordings is important but also\n\
    the spatial information is also important to determine things like direction for\
    \ e.g.\nThe ConvLSTM layer is followed by a Self-Attention layer to incorporate\
    \ attention\n119\nTable 48. Labeling for K-Fall Dataset\nActivity Code\nAssigned\
    \ Label\nFall code\nAssigned Label\nD01\nADL/-\nF01\nFSF\nD02\nADL/SB\nF02\nBSF\n\
    D03\nADL/SB\nF03\nLSF\nD04\nADL/-\nF04\nFSF\nD05\nADL/S\nF05\nLSF\nD06\nADL/W\n\
    F06\nFSF\nD07\nADL/W\nF07\nLSF\nD08\nADL/J\nF08\nBSF\nD09\nADL/J\nF09\nFSF\nD10\n\
    ADL/-\nF10\nLSF\nD11\nADL/-\nF11\nFHF\nD12\nADL/-\nF12\nFHF\nD13\nADL/S\nF13\n\
    FHF\nD14\nADL/S\nF14\nLHF\nD15\nADL/S\nF15\nBHF\nD16\nADL/S\n-\n-\nD17\n-/ADL\n\
    -\n-\nD18\nADL/S\n-\n-\nD19\nADL/S\n-\n-\nD20\nADL/W\n-\n-\nD21\nADL/-\n-\n-\n\
    mechanism. Through the attention layer, important parts in the signal which can\n\
    help to determine the output class correctly are identified. For the current work,\
    \ a\nglobal attention mechanism which looks at the complete sequence is used.\
    \ After the\nattention layer follow two fully connected layers, one with a relu\
    \ activation function\nand the other with a softmax function to determine the\
    \ output class.\n2.8.4.3\nResults\nTwo experiments were performed in total on\
    \ the two datasets considered. The\nexperiments consisted of a fall vs ADL scenario\
    \ and another scenario in which ADLs\nwere conisdered individually to provide\
    \ a combined fall and ADL recognition system.\nThe results for each of the experiments\
    \ have been presented in this section. The\nnetwork was trained using an Adam\
    \ optimizer for 40 epochs with early stopping\nbeing used to retain the best performing\
    \ model before running it on the test set.\nAlso, during training, the network\
    \ was tasked to maximize the average recall of all\nclasses combined to ensure\
    \ that positive samples of each class were prioritized for\ncorrect detection,\
    \ however, in addition to recall, the precision, specificity and F1-\nscore have\
    \ also been reported in the results presented for the sake of completeness.\n\
    One ADL vs Individual Falls\nIn this experiment, all the ADLs were considered\
    \ a single class while the categories for\nfalls were retained as per individual\
    \ directions and severity levels. Table 49 presents\nthe results for this experiment\
    \ with the SisFall dataset for which an average recall of\n90.02% was achieved.\
    \ It can be observed that the network is able to determine ADLs\nvery well achieving\
    \ a recall of 99.93%. Considering falls, the class LHF is the worst\n120\nConvLSTM\n\
    16 filters (3x1)\nSelf Attention\nFully connected\n(Relu)\nPeak SMV Detection\n\
    Windowing\nFully connected\n(Softmax) Classifier\nData Augmentation\nData Processing\n\
    IMU Recording (Falls and Activities) \n(ADL, FHF, FSF, BHF, BSF, LHF, LSF) \n\
    (W, J, S, SB, FHF, FSF, BHF, BSF, LHF, LSF)\nOutput Class \n(ADL, FHF, FSF, BHF,\
    \ BSF, LHF, LSF) \n(W, J, S, SB, FHF, FSF, BHF, BSF, LHF, LSF)\nFeature Extraction\n\
    Classification\nFigure 28. ConvLSTM-attention Network.\n121\nperforming fall which\
    \ has been detected with a recall of only 68.42%. It was observed\nthat falls\
    \ from LHF were confused with forward falls and LSF. The best performing\nfall\
    \ is FHF with a recall of 98.28%.\nTable 49. Results for SisFall: One ADL vs.\
    \ Individual Falls\nActivity/ Fall\nPrecision\n(%)\nSensitivity/\nRecall (%)\n\
    Specificity\n(%)\nF1-score\n(%)\nBHF\n100\n94.74\n100\n97.30\nBSF\n94.74\n94.74\n\
    99.88\n94.74\nFHF\n83.82\n98.28\n99.36\n90.48\nFSF\n94.20\n84.42\n99.76\n89.04\n\
    LHF\n81.25\n68.42\n99.83\n74.29\nLSF\n89.61\n89.61\n99.53\n89.61\nADL\n99.8\n\
    99.93\n98.96\n99.87\nAverage\n91.92\n90.02\n99.62\n90.76\nTable 50. Results for\
    \ K-Fall: One ADL vs. Individual Falls\nActivity/ Fall\nPrecision\n(%)\nSensitivity/\n\
    Recall (%)\nSpecificity\n(%)\nF1-score\n(%)\nBHF\n100\n92.00\n100\n95.83\nBSF\n\
    98.00\n96.08\n99.90\n97.03\nFHF\n82.93\n91.89\n98.63\n87.18\nFSF\n93.41\n85.00\n\
    99.4\n89.01\nLHF\n78.57\n88.00\n99.44\n83.02\nLSF\n96.97\n96.00\n99.70\n96.48\n\
    ADL\n99.45\n99.72\n98.93\n99.59\nAverage\n92.76\n92.67\n99.43\n92.59\nTable 50\
    \ presents the results for the K-Fall dataset when all ADLs are combined in\n\
    to one class. It can be observed that like the case for the SisFall dataset, the\
    \ ADLs in\nthis case have been detected very well, resulting in a recall of 99.72%.\
    \ Considering the\nperformance of falls, the best performing fall classes were\
    \ BSF and LSF for which a\nrecall of 96% was achieved. The worst performing fall\
    \ class in this case was FSF with\na recall of 85%.\nIndividual ADL vs Individual\
    \ Falls\nIn this experiment, individual ADLs were considered as separate classes\
    \ in addition\nto the six fall classes mentioned before. This exercise was carried\
    \ out to assess the\ndesigned systems performance as a combined ADL recognition\
    \ and fall detection\nsystem. The result for the SisFall dataset are presented\
    \ in Table 51. The average\nrecall achieved for this experiment using the SisFall\
    \ dataset is 91.49%.\nConsidering fall performance, it can be observed from Table\
    \ 51 that the class\nBSF is the best recognized fall, having a recall of 94.74%\
    \ with the fall LHF being\nthe worst recognized one with a recall of 73.68%. The\
    \ best recognized ADL is the\nclass W with a near perfect recall of 99.06%. The\
    \ worst recognized ADL is S with\n96.98% which is not a large difference compared\
    \ to the performance for falls. Table\n?? presents the results of the network\
    \ for the K-Fall dataset for this experiment. It\n122\nTable 51. Results for SisFall:\
    \ Individual ADLs vs. Individual Falls\nActivity/\nFall\nPrecision\n(%)\nSensitivity/\n\
    Recall (%)\nSpecificity\n(%)\nF1-score\n(%)\nBHF\n89.47\n89.47\n99.88\n89.47\n\
    BSF\n100\n94.74\n100\n97.30\nFHF\n86.89\n92.98\n99.51\n89.83\nFSF\n94.37\n87.01\n\
    99.75\n90.54\nLHF\n70.00\n73.68\n99.64\n71.79\nLSF\n88.89\n93.51\n99.44\n91.14\n\
    J\n98.44\n97.42\n99.53\n97.93\nS\n97.97\n96.98\n99.73\n97.47\nSB\n94.74\n90.00\n\
    99.81\n92.31\nW\n98.00\n99.06\n98.39\n98.53\nAverage\n91.88\n91.49\n99.57\n91.63\n\
    can be observed that in this case, the best performance for the fall categories\
    \ is both\nfor BSF and LSF\neach of which have a recall of 98%. The worst performing\
    \ fall is\nthe class BHF , it was observed that samples from this class were confused\
    \ with the\nclass BSF. For the case of ADLs, the best performing ADL for the K-Fall\
    \ dataset is\nSB with a recall of 97.5% with the worst being the class J.\n2.8.4.4\n\
    Discussion\nWhen comparing the performance of ADLs and falls overall for both\
    \ experiments,\nit can be observed that ADL recognition performance was much better\
    \ than the\nperformance for fall detection. For both experiments conducted, when\
    \ comparing the\nperformance of the network across datasets, the network performs\
    \ better on the K-Fall\ndataset compared to the SisFall dataset. This could be\
    \ attributed to the difference\nin the volunteer make up of the participants as\
    \ K-Fall mostly had young people\nvolunteering to perform falls whereas SisFall\
    \ contains a wide variety of age groups\nand gender make up in its volunteers.\
    \ To gather further insights in to the performance\nof the network in terms of\
    \ fall detection for the two experiments conducted across both\ndatasets, Figure\
    \ 29 illustrates the networks performance for falls for both datasets\nand experiments.\
    \ An average recall of 88.37% was achieved for the SisFall dataset\nand 91.49%\
    \ for the K-Fall dataset for the one ADL vs individual falls experiment\nand 88.57%\
    \ and 91.33% respectively for the individual ADL and individual falls\nexperiment.\
    \ It can be observed that the classes LSF, FHF and BSF were recognized\nvery well,\
    \ each achieving a recall of nearly 90% or higher. The class FHF was also\ndetected\
    \ sufficiently well, achieving an average recall of more than 86% across all\n\
    experiments. For SisFall, the least performing class was LHF and for K-Fall it\
    \ was\nBHF.\nFigure 30 investigates the performance of the network when considering\
    \ different\nfall severity levels for all the experiments. It can be observed\
    \ that soft falls have\nbeen consistently better recognized compared to hard falls.\
    \ This difference is largest\n(6%) when individual ADLs are considered as separate\
    \ classes for both datasets. For\nthe experiment where ADLs are grouped in to\
    \ a single class, there is only a slight\n123\n60\n65\n70\n75\n80\n85\n90\n95\n\
    100\nBHF\nBSF\nFHF\nFSF\nLHF\nLSF\nFall Results: Both Experiments\nSisFall One\
    \ ADL/Individual Falls\nSisFall Individual ADLs/Individual Falls\nKfall One ADL/Individual\
    \ Falls\nKfall Individual ADLs/Individual Falls\nFigure 29. Fall detection performance\
    \ for both experiments.\ndifference observed between the fall severity levels\
    \ for the K-Fall dataset whereas for\nSisFall, there is still a significant difference\
    \ of more than 5% between the detection\nof soft and hard falls.\nSisFall\nKfall\n\
    60\n65\n70\n75\n80\n85\n90\n95\n100\nSisFall One ADL/Ind Falls\nKFall One ADL/Ind\
    \ Falls\nSisFall Ind ADLs/Ind Falls\nKFall Ind ADLs/Ind Falls\nPerformance for\
    \ Fall Severity\nHard Falls\nSoft Falls\nFigure 30. Fall severity performance.\n\
    In Figure 31, the results from the experiments for fall direction have been illus-\n\
    trated. In this case, the performance of the network for tests using SisFall yield\
    \ best\nresults for falls in the backward direction with falls in the lateral\
    \ directions being\nrecognized the worst. In contrast, for the K-Fall dataset,\
    \ falls in the lateral direc-\n124\n60\n65\n70\n75\n80\n85\n90\n95\n100\nSisFall\
    \ One ADL/Ind Falls\nKfall One ADL/Ind Falls\nSisFall Ind ADLs/Ind Falls\nKfall\
    \ Ind ADLs/Ind Falls\nPerformance for Fall Directions\nForward Falls\nBackward\
    \ Falls\nLateral Falls\nFigure 31. Fall direction performance.\ntion have been\
    \ detected quite well, followed by backfward falls and forward falls. In\norder\
    \ to gauge the performance of the network, the work of We et al. [459] was\nused\
    \ as a comparison as they also utilize sequential modeling in their work and cater\n\
    to non-binary fall detection as well. Table 53 and 54 presents the results for\
    \ both\nexperiments with the cases where the work of Wu et al. outperforms the\
    \ presented\nmethod highlighted. It can be observed that the presented method\
    \ outperforms the\nmethod of [459] sufficiently well. Another thing to note is\
    \ that as observed with the\nresults presented, a similar pattern of variation\
    \ was observed for both data sets with\nrespect to the two experiments in that\
    \ a degradation was observed for experiments\nfor K-Fall whereas an improvement\
    \ was observed for SisFall.\nTable 53. Comparison with State of the art (Individual\
    \ ADLs vs. Individual Falls.)\nActivity/Fall\nSensitivity/Recall (%)\n[]\nWork\
    \ of [459]\nProposed work\nWork of [459]\nProposed work\nBHF\n63.16\n94.74\n92.00\n\
    92.00\nBSF\n86.84\n94.74\n96.08\n96.08\nFHF\n77.59\n98.28\n83.78\n91.89\nFSF\n\
    76.62\n84.42\n90.00\n85.00\nLHF\n68.42\n68.42\n64.00\n88.00\nLSF\n77.92\n89.61\n\
    93.00\n96.00\nADL\n98.78\n99.93\n99.58\n99.72\nAverage\n78.48\n90.02\n88.35\n\
    92.67\n3\nConclusion\nFall detection is an important task in the field of ambient\
    \ assisted living. Towards this\nend, four experiments were performed in this\
    \ chapter. In the first experiemt, a fall\n125\nTable 54. Comparison with State\
    \ of the art (Individual ADLs vs. Individual Falls.)\nActivity/Fall\nSensitivity/Recall\
    \ (%)\n[]\nWork of [459]\nProposed work\nWork of [459]\nProposed work\nBHF\n58.33\n\
    89.47\n76.00\n76.00\nBSF\n87.50\n94.74\n100\n98.04\nFHF\n83.33\n92.98\n91.89\n\
    95.95\nFSF\n81.25\n87.01\n89.00\n88.00\nLHF\n41.67\n73.68\n64.00\n92.00\nLSF\n\
    81.25\n93.51\n95.00\n98.00\nJ\n98.77\n97.42\n55.45\n87.13\nS\n88.71\n96.98\n81.17\n\
    90.91\nSB\n83.78\n90.00\n87.50\n97.50\nW\n96.12\n99.06\n87.30\n95.24\nAverage\n\
    80.07\n91.48\n82.74\n91.88\nTable 55. Results for the four Experiments for the\
    \ SisFall dataset (F1-Score[%])\nActivity/Fall\nExp. 1\nExp. 2\nExp. 3 (One ADL)\n\
    Exp. 3 (Ind ADLs)\nExp. 4 (One ADL)\nExp. 4 (Ind ADLs)\nBHF\n87.27\n83.02\n95.65\n\
    85.71\n97.30\n89.47\nBSF\n95.08\n90.76\n97.87\n82.05\n94.74\n97.30\nFHF\n72.43\n\
    80.47\n90.91\n75.00\n90.48\n89.83\nFSF\n73.25\n77.18\n86.67\n95.83\n89.04\n90.54\n\
    LHF\n66.67\n67.80\n69.57\n83.15\n74.29\n71.79\nLSF\n84.65\n82.73\n89.58\n91.09\n\
    89.61\n91.14\nJ\n-\n98.27\n96.71\n-\n97.93\nS\n-\n96.20\n96.77\n-\n97.47\nSB\n\
    -\n85.71\n87.32\n-\n92.31\nW\n-\n98.46\n97.42\n-\n98.53\nADL\n-\n-\n99.77\n-\n\
    99.93\n-\nOverall Average\n-\n86.06\n90.02\n89.11\n90.76\n91.63\nFall Average\n\
    79.89\n80.32\n88.38\n85.47\n89.24\n88.34\nADL Average\n-\n94.66\n99.77\n94.55\n\
    99.87\n96.56\nonly detection system that considers the direction as well as the\
    \ severity of falls was\npresented. Inertial measurement sensor data from a publicly\
    \ available dataset was\nused to carry out this task. Following a typical machine\
    \ learning pipeline, the data\nwas first preprocessed by extracting equal duration\
    \ segments from the accelerometer\nand gyroscope sensor signals based on the acceleration\
    \ magnitude. This is followed\nby the computation of various time and frequency\
    \ domain features for each of these\nsegments. The next step is feature selection\
    \ and classification which is performed by\nusing four different machine learning\
    \ algorithms popular in fall detection systems.\nFirst, a baseline performance\
    \ is established and then feature reduction is performed\naiming to maintain or\
    \ improve algorithm performance by elimination of redundant\nfeatures. It was\
    \ observed that the weighted F1-score improved slightly (by just over\n1%) for\
    \ both experiments.\nThe other three experiments considered activity of daily\
    \ living and fall detection\nsimultaneously. For the second experiment, utilizing\
    \ inertial sensor data, a hierarchi-\ncal classification framework using wavelets\
    \ and adaptive pooling was presented. To\nachieve this, inertial sensor recordings\
    \ (accelerometer and gyroscope) from the Sis-\nFall dataset were utilized and\
    \ windowed segments were extracted from each recording.\nFollowing this, a level-4\
    \ haar wavelet was used to extract wavelet coefficients from\nthese windowed segments\
    \ and then 4-2-1 1-D Spatial Pyramid pooling was used to\n126\nsummarize the output\
    \ of the wavelet feature coefficients at each approximation and\ndetail level\
    \ before the max pooled coefficients were concatenated to form the final\nfeature\
    \ vector. A hierarchical classification scheme was then used consisting of three\n\
    classification stages, one for determining individual ADLs versus a generic fall\
    \ and the\nsecond and third for fall direction and severity respectively with\
    \ both voting together\nto determine the severity and direction of a fall. Towards\
    \ this end, experiments were\nconducted to determine the most appropriate size\
    \ of the observation window as well as\nsensing modality used. It was found that\
    \ for the proposed setup, a window duration\nof 3 seconds produced the best results\
    \ while using data from both the accelerometer\nand gyroscope. In the third experiment,\
    \ Inertial Measurement Unit (accelerometer\nand gyroscope) data from the SisFall\
    \ dataset is first windowed into non-overlapping\nsegments of duration 3 seconds.\
    \ After suitable data augmentation for the minority\nclasses, the windowed segments\
    \ are passed to a Convolutional Neural Network for\nfeature extraction. The CNN\
    \ is trained to maximize the unweighted average recall\nfor the validation partition.\
    \ Once the CNN is trained, an XGBoost last stage is used\nfor classification.\
    \ Experiments conducted on the test set achieve an unweighted aver-\nage recall\
    \ of 88% for both the one ADL versus individual falls and individual ADLs\nversus\
    \ fall experiments. In comparison with other techniques used for this task, the\n\
    proposed scheme produces sufficiently better results, thereby demonstrating the\
    \ effi-\ncacy of the proposed method. Lastly, a ConvLSTM network with attention\
    \ has been\nused for detection of falls considering fall direction and severity.\
    \ Using data from the\nSisFall and the K-Fall datasets, two experiments were conducted\
    \ on inertial sensor\ndata. The first considered falls versus ADLs and the other\
    \ combined ADL recognition\nand fall detection. Results for both experiments achieved\
    \ an average recall of more\nthan 90%. The results from the cross-dataset performance\
    \ indicate to the robustness\nof the designed methodology.\nTable 55 presents\
    \ the F-1 scores for the four experiments considering fall detection\nwith direction\
    \ and severity for the SisFall dataset. For experiment 1, only the fall\ndetection\
    \ with direction and severity part has been reported. A progression can be\nobserved\
    \ in the detection of falls wherein an increase of nearly 8.5% in the average\n\
    F1-score was achieved.\n127\nCHAPTER VI\nCONCLUSION AND FUTURE WORK\n1\nConclusion\n\
    This dissertation provided a coverage of the use of Internet of Things towards\
    \ the\ndevelopment of smart communities. While doing so, the main applications\
    \ of ML/DL\nalgorithms as well as optimization algorithms were discussed and mapped.\
    \ Further-\nemore, other technological components of the IoT such as sensing,\
    \ communication,\nsecurity and privacy were also talked about. Lastly, considering\
    \ the case of smart\nhealth, specifically fall detection, experimentation and\
    \ analysis was conducted and\nthe results presented.\nIn this regard, the usage\
    \ of inertial sensor data has been very popular as they do\nnot restrict a users\
    \ movement and are also easy to deploy compared to other methods.\nFour approaches\
    \ that considered fall detection with direction and severity were pre-\nsented.\
    \ In this regard, four experiments were conducted, first was the development\n\
    of a fall only detection system whereas the other three were for a combined ADL\
    \ and\nfall system. For the other three experiments, a hierarchical and two deep\
    \ learning\nbased approaches were tested. The designed methodologies were compared\
    \ to the\nstate of the art and were found to outperform them.\n2\nContribution\n\
    The Internet of Things has spearheaded tremendous change in society by allowing\
    \ for\ncapturing measurements in different facets of our daily lives. With such\
    \ a fundamental\nimpact being made, it is pertinent that researchers commit to\
    \ analyzing the current\npenetration that IoT possesses in city operation and\
    \ also providing impetuses for\nnew and novel application development. This work\
    \ aims to address these needs by\ndiscussing the use and role of the internet\
    \ of things in smart communities.\nThe\ncontribution of the work are as follows:\n\
    1. Provide a coverage of the IoT based smart city ecosystem in terms of the tech-\n\
    nologies utilized. Discussion has been provided about the sensors, communi-\n\
    cation technologies as well as the IoT architectures that enable IoT smart city\n\
    development. Finally a review of the security and privacy issues was also dis-\n\
    cussed.\n2. Present a study of the uses of ML and DL methods for different applications\
    \ of\nsmart cities in an IoT context. To this end, the type of architecture employed\n\
    and the data source type were also covered.\n128\n3. The use of optimization algorithms\
    \ in IoT smart cities has been provided. To\nthe best of our knowledge, this is\
    \ the first comprehensive review of optimization\nalgorithms in IoT Smart Cities.\n\
    4. Considering the case of smart health, methodologies have been devised for the\n\
    novel case of fall detection with direction and severity detection. In this respect,\n\
    the performance time, frequency domain and statistical features on inertial\n\
    sensor data has been analyzed and presented.\n5. A combined activity of daily\
    \ living and fall detection framework with fall di-\nrection and severity consideration\
    \ has been discussed.\nFour approaches in\nthis regard have been presented, one\
    \ utilizing time-frequency information us-\ning wavelets along with a hierarchical\
    \ classification scheme, third a Convolu-\ntional Neural Network-eXtreme Gradient\
    \ Boost combination and the last being\na ConvLSTM has been proposed. The proposed\
    \ approaches has been shown to\noutperform the state of the art in the field.\n\
    3\nFuture Work\nThe IoT is revolutionizing development of smart city applications.\
    \ There are several\nopportunities. Some of these are listed below:\n• IoT Systems\
    \ for Smart Cities\n– A major research area is in the security and privacy of\
    \ IoT in smart cities in\nterms of encryption techniques, authentication protocols,\
    \ data anonymiza-\ntion techniques and other methods to prevent unvalidated access\
    \ to the IoT\nnetwork. As mentioned before technologies such as blockchain could\
    \ help\nintroduce access tracking and control, secure device discovery, prevention\n\
    of spoofing, data loss while ensuring that end to end encryption is also\nused.\n\
    – Of the data transfer standards developed till now for IoT, many are not\ncompatible\
    \ with each other. Work needs to be carried out in this regard to\nenable intercommunication\
    \ of sensor nodes using different protocols while\nutilizing low power, which\
    \ is imperative for sensor nodes in the network.\n– Another area to work on, is\
    \ the development of efficient storage techniques\nand low power hardware which\
    \ can reduce operational costs. From a de-\nployment perspective, decentralized\
    \ systems have been proposed as the\nbest solutions to increase reliability of\
    \ the application. Techniques such as\nfederated learning allow for decentralized\
    \ DL system deployments.\n• AI/Combinatorial Optimization in IoT Smart Cities\n\
    – The development of data fusion techniques that can make the use of het-\nerogeneous\
    \ data sources easier, intelligent data reduction/feature selection\nmethods to\
    \ ensure that redundant or ’uninteresting’ data is not part of the\n129\nAI development\
    \ pipeline. This will help in a quicker turnaround time as\nwell as improved performance\
    \ of deployments. Current methods need to be\nused as well as new ones be researched\
    \ for making ML and DL algorithms\nmore explainable to suit the various applications\
    \ in a smart city.\n– Hybrid and novel optimization methodologies (for e.g. graywolf\
    \ optimiza-\ntion [493]) which combine characteristics of multiple heuristic schemes\n\
    could potentially outperform singular methodologies.\nThere have been\nseveral\
    \ works which combine multiple optimization techniques.\n– Reinforcement learning\
    \ (RL) has the potential to provide solutions to com-\nbinatorial optimization\
    \ problems as covered in [494]. The idea is to use\nmachine learning and reinforcement\
    \ learning to get rid of human created\nheurists which may lead to optimizations\
    \ towards local optimums. Agents\ncan be trained to search for these heuristics\
    \ to automate the process.\n• Smart Health: Fall detection\n– The addition of\
    \ additional sensor modalities apart from intertial sensor\nmeasurements might\
    \ help improve performance for the worst detected\nclasses from the experiments\
    \ conducted. Various authors have incorpo-\nrated medical or pressure sensors\
    \ in their fall detection systems.\nData\nfrom these sensors can be used together\
    \ as an input to a deep learning\nnetwork. This additional information gathered\
    \ for subjects while under-\ngoing a fall could also describe valuable health\
    \ parameters that can be used\nfor diagnosis or early detection of ailments which\
    \ might be the underlying\ncause of falls.\n– Another work opportunity in the\
    \ data science domain would be the as-\nsessment of this problem considering a\
    \ data centric approach, where, in\ncontrast to a model centric approach where\
    \ the focus is on developing the\nbest model, data centric focuses on working\
    \ with data to improve applica-\ntion performance using systematic procedures\
    \ for labeling, augmentation\netc. Such systematic procedures and qualitative\
    \ data analysis would aid\nin cross-dataset algorithm deployment as well.\n130\n\
    REFERENCES\n[1]\nWorldometers, “World population forecast - worldometers,” (2019).\n\
    [2]\nH. Ahvenniemi, A. Huovila, I. Pinto-Sepp¨a, and M. Airaksinen, “What\nare\
    \ the differences between sustainable and smart cities?” Cities 60, 234–\n245\
    \ (2017).\n[3]\nUnited Nations, “About the Sustainable Development Goals - United\
    \ Na-\ntions Sustainable Development,” .\n[4]\nP. Cardullo and R. Kitchin, “Being\
    \ a ‘citizen’ in the smart city: up and\ndown the scaffold of smart citizen participation\
    \ in dublin, ireland,” Geo-\nJournal 84, 1–13 (2019).\n[5]\nJ. Desdemoustier,\
    \ N. Crutzen, and R. Giffinger, “Municipalities’ under-\nstanding of the smart\
    \ city concept: An exploratory analysis in belgium,”\nTechnological Forecasting\
    \ and Social Change 142, 129–141 (2019).\n[6]\nM. S. Khan, M. Woo, K. Nam, and\
    \ P. K. Chathoth, “Smart city and\nsmart tourism: A case of dubai,” Sustainability\
    \ (Switzerland) 9 (2017).\n[7]\nD. Wu, N. Jiang, W. Du, K. Tang, and X. Cao, “Particle\
    \ swarm optimiza-\ntion with moving particles on scale-free networks,” IEEE Transactions\
    \ on\nNetwork Science and Engineering 7, 497–506 (2018).\n[8]\nM. L. Finlayson\
    \ and E. W. Peterson, “Falls, aging, and disability,” Phys-\nical Medicine and\
    \ Rehabilitation Clinics 21, 357–373 (2010).\n[9]\nB. M. Kistler, J. Khubchandani,\
    \ G. Jakubowicz, K. Wilund, and J. Sos-\nnoff, “Peer reviewed: Falls and fall-related\
    \ injuries among us adults aged\n65 or older with chronic kidney disease,” Preventing\
    \ chronic disease 15\n(2018).\n[10]\nL. Bolton, “Preventing fall injury.” Wounds:\
    \ a compendium of clinical\nresearch and practice 31, 269–271 (2019).\n[11]\n\
    Y. K. Haddad, G. Bergen, and C. Florence, “Estimating the economic\nburden related\
    \ to older adult falls by state,” Journal of public health\nmanagement and practice:\
    \ JPHMP 25, E17 (2019).\n[12]\nC. S. Florence, G. Bergen, A. Atherly, E. Burns,\
    \ J. Stevens, and C. Drake,\n“Medical costs of fatal and nonfatal falls in older\
    \ adults,” Journal of the\nAmerican Geriatrics Society 66, 693–698 (2018).\n[13]\n\
    A. Bourke, J. O’brien, and G. Lyons, “Evaluation of a threshold-based tri-\naxial\
    \ accelerometer fall detection algorithm,” Gait & posture 26, 194–199\n(2007).\n\
    131\n[14]\nR. G. Hollands, “Will the real smart city please stand up? intelligent,\n\
    progressive or entrepreneurial?” City 12, 303–320 (2008).\n[15]\nL. G. Anthopoulos\
    \ and C. G. Reddick, “Understanding electronic gov-\nernment research and smart\
    \ city: A framework and empirical evidence,”\nInformation Polity 21, 99–117 (2016).\n\
    [16]\nZ. Khan, A. Anjum, K. Soomro, and M. A. Tahir, “Towards cloud based\nbig\
    \ data analytics for smart future cities,” Journal of Cloud Computing\n4 (2015).\n\
    [17]\nA. Koubaa, A. Aldawood, B. Saeed, A. Hadid, M. Ahmed, A. Saad,\nH. Alkhouja,\
    \ A. Ammar, and M. Alkanhal, “Smart palm: An iot frame-\nwork for red palm weevil\
    \ early detection,” Agronomy 10, 1–21 (2020). No\nML or dL used.\n[18]\nM. O’Grady,\
    \ D. Langton, and G. O’Hare, “Edge computing: A tractable\nmodel for smart agriculture?”\n\
    Artificial Intelligence in Agriculture 3,\n42–51 (2019).\n[19]\nI. Rojek and J.\
    \ Studzinski, “Detection and localization of water leaks in\nwater nets supported\
    \ by an ict system with artificial intelligence methods\nas away forward for smart\
    \ cities,” Sustainability (Switzerland) 11 (2019).\n[20]\nK. Pardini, J. J. Rodrigues,\
    \ S. A. Kozlov, N. Kumar, and V. Furtado, “Iot-\nbased solid waste management\
    \ solutions: A survey,” Journal of Sensor and\nActuator Networks 8 (2019).\n[21]\n\
    J. Dutta, C. Chowdhury, S. Roy, A. I. Middya, and F. Gazi, “Towards\nsmart city:\
    \ Sensing air quality in city based on opportunistic crowd-\nsensing,” ACM International\
    \ Conference Proceeding Series (2017).\n[22]\nF. Al-Turjman and A. Malekloo, “Smart\
    \ parking in iot-enabled cities: A\nsurvey,” Sustainable Cities and Society 49\
    \ (2019).\n[23]\nE. Shirazi and S. Jadid, “Autonomous self-healing in smart distribution\n\
    grids using multi agent systems,” IEEE Transactions on Industrial Infor-\nmatics\
    \ 3203, 1–11 (2018).\n[24]\nR. V. Andre˜ao, M. Athayde, J. Boudy, P. Aguilar,\
    \ I. de Araujo, and\nR. Andrade, “Raspcare: A telemedicine platform for the treatment\
    \ and\nmonitoring of patients with chronic diseases,” in “Assistive Technologies\n\
    in Smart Cities,” (IntechOpen London, UK, 2018).\n[25]\nP. A. Keane and E. J.\
    \ Topol, “With an eye to ai and autonomous diag-\nnosis,” npj Digital Medicine\
    \ 1, 10–12 (2018).\n[26]\nG. Trencher and A. Karvonen, “Stretching “smart”: advancing\
    \ health\nand well-being through the smart city agenda,” Local Environment 24,\n\
    610–627 (2019).\n132\n[27]\nB. R. Haverkort and A. Zimmermann, “Smart industry:\
    \ How ict will\nchange the game!” IEEE Internet Computing 21, 8–10 (2017).\n[28]\n\
    F. Tao, J. Cheng, and Q. Qi, “Iihub: An industrial internet-of-things\nhub toward\
    \ smart manufacturing based on cyber-physical system,” IEEE\nTransactions on Industrial\
    \ Informatics 14, 2271–2280 (2018).\n[29]\nP. Trakadas, P. Simoens, P. Gkonis,\
    \ L. Sarakis, A. Angelopoulos, A. P.\nRamallo-Gonz´alez, A. Skarmeta, C. Trochoutsos,\
    \ D. Calvo, T. Pariente,\nK. Chintamani, I. Fernandez, A. A. Irigaray, J. X. Parreira,\
    \ P. Petrali,\nN. Leligou, and P. Karkazis, “An artificial intelligence-based\
    \ collaboration\napproach in industrial iot manufacturing: Key concepts, architectural\n\
    extensions and potential applications,” Sensors (Switzerland) 20, 1–20\n(2020).\
    \ Ni as this is about architecture of AI in to Smart industry.\n[30]\nJ. Wan,\
    \ J. Yang, Z. Wang, and Q. Hua, “Artificial intelligence for cloud-\nassisted\
    \ smart factory,” IEEE Access 6, 55419–55430 (2018).\n[31]\nY. Huang, Z. Dang,\
    \ Y. Choi, J. Andrade, and A. Bar-ilan, “High-precision\nsmart system on accelerometers\
    \ and inclinometers for structural health\nmonitoring: development and applications,”\
    \ in “2018 12th France-Japan\nand 10th Europe-Asia Congress on Mechatronics,”\
    \ (IEEE, 2018), pp. 52–\n57.\n[32]\nS. G. Farag, “Application of smart structural\
    \ system for smart sustainable\ncities,” in “2019 4th MEC International Conference\
    \ on Big Data and\nSmart City (ICBDSC),” (2019), pp. 1–5.\n[33]\nY. Wang, S. Ram,\
    \ F. Currim, E. Dantas, and L. A. Sab´oia, “A big data\napproach for smart transportation\
    \ management on bus network,” IEEE\n2nd International Smart Cities Conference:\
    \ Improving the Citizens Qual-\nity of Life, ISC2 2016 - Proceedings pp. 0–5 (2016).\n\
    [34]\nA. Lele, “Internet of things (iot),” Smart Innovation, Systems and Tech-\n\
    nologies 132, 187–195 (2019).\n[35]\nP. Mell and T. Grance, “The nist-national\
    \ institute of standars and\ntechnology- definition of cloud computing,” NIST\
    \ Special Publication 800-\n145 p. 7 (2011).\n[36]\nJ. B.-M. Numhauser, “Fog computing\
    \ introduction to a new cloud evolu-\ntion,” University of Alcal´a (2012).\n[37]\n\
    M. Aazam, S. Zeadally, and K. A. Harras, “Fog computing architecture,\nevaluation,\
    \ and future research directions,” IEEE Communications Mag-\nazine 56, 46–52 (2018).\n\
    [38]\nH. El-Sayed, S. Sankar, M. Prasad, D. Puthal, A. Gupta, M. Mohanty,\nand\
    \ C. T. Lin, “Edge of things: The big picture on the integration of\nedge, iot\
    \ and the cloud in a distributed computing environment,” IEEE\nAccess 6, 1706–1717\
    \ (2017).\n133\n[39]\nA. Yousefpour, C. Fung, T. Nguyen, K. Kadiyala, F. Jalali,\
    \ A. Niakan-\nlahiji, J. Kong, and J. P. Jue, “All one needs to know about fog\
    \ computing\nand related edge computing paradigms: A complete survey,” Journal\
    \ of\nSystems Architecture 98, 289–330 (2019).\n[40]\nB. L. R. Stojkoska and K.\
    \ V. Trivodaliev, “A review of internet of things\nfor smart home: Challenges\
    \ and solutions,” Journal of Cleaner Production\n140, 1454–1464 (2017). The authors\
    \ perform a literature reiew of the\narchitectures available for IoT in the Smart\
    \ home. After doing so, they\nprovide an architecture of their own which has been\
    \ derived from the other\narchitectures discussed. ¡br/¿¡br/¿*They provide a good\
    \ description of the\ntypes of appliances.\n[41]\nA. Saini and A. Malik, “Routing\
    \ in internet of things: A survey,” Com-\nmunication and Computing Systems - Proceedings\
    \ of the International\nConference on Communication and Computing Systems, ICCCS\
    \ 2016 I,\n855–860 (2017).\n[42]\nE. Casilari, J. A. Santoyo-Ram´on, and J. M.\
    \ Cano-Garc´ıa, “On the hetero-\ngeneity of existing repositories of movements\
    \ intended for the evaluation\nof fall detection systems,” Journal of Healthcare\
    \ Engineering 2020 (2020).\nThe authors in EC20 analyse various datasets which\
    \ contain accelerom-\neter signal measurements for people performing fall activities.\
    \ Within\nthis:¡br/¿¡br/¿Table 1 lists the datasets considered¡br/¿Table 2 illustrates\n\
    the characteristics of the collected data (duration etc) and the partici-\npants¡br/¿Table\
    \ 3 discusses the sampling rate and other properties of the\ndata ¡br/¿¡br/¿The\
    \ analysis involves extracting sliding time windows of\n0.5 seconds from the signals\
    \ and calculate the window with the maximum\ndifference of acceleration as described\
    \ in ref [60] to determine the win-\ndow where the fall has taken place. Once\
    \ this is done, they calculate 12\nstatistical features from the data.\n[43]\n\
    M. Rahnemoonfar and C. Sheppard, “Deep count : Fruit counting based\non deep simulated\
    \ learning,” Sensors 17, 1–12 (2017).\n[44]\nD. Thakker, B. K. Mishra, A. Abdullatif,\
    \ and S. Mazumdar, “Explainable\nartificial intelligence for developing smart\
    \ cities solutions,” Smart Cities\n3, 1353–1382 (2020).\n[45]\nA. Rahman, M. S.\
    \ Hossain, N. A. Alrajeh, and N. Guizani, “B5g and\nexplainable deep learning\
    \ assisted healthcare vertical at the edge : Covid-\n19 perspective,” IEEE Network\
    \ 34, 98–105 (2020).\n[46]\nM. Janssen, S. Luthra, S. Mangla, N. P. Rana, and\
    \ Y. K. Dwivedi, “Chal-\nlenges for adopting and implementing iot in smart cities,”\
    \ Internet Re-\nsearch ahead-of-p (2019).\n[47]\nR. S´anchez-Corcuera, A. Nu˜nez-Marcos,\
    \ J. Sesma-Solance, A. Bilbao-\nJayo, R. Mulero, U. Zulaika, G. Azkune, and A.\
    \ Almeida, “Smart cities\n134\nsurvey: Technologies, application domains and challenges\
    \ for the cities\nof the future,” International Journal of Distributed Sensor\
    \ Networks 15\n(2019).\n[48]\nB. N. Silva, M. Khan, and K. Han, “Towards sustainable\
    \ smart cities: A\nreview of trends, architectures, components, and open challenges\
    \ in smart\ncities,” Sustainable Cities and Society 38, 697–713 (2018).\n[49]\n\
    W. Ejaz and A. Anpalagan, “Internet of things for smart cities: overview\nand\
    \ key challenges,” Internet of Things for Smart Cities pp. 1–15 (2019).\n[50]\n\
    G. Marques, N. Garcia, and N. Pombo, “A survey on iot: architectures,\nelements,\
    \ applications, qos, platforms and security concepts,” in “Ad-\nvances in Mobile\
    \ cloud computing and big data in the 5G era,” (Springer,\n2017), pp. 115–130.\n\
    [51]\nK. Zhang, J. Ni, K. Yang, X. Liang, J. Ren, and X. S. Shen, “Security\n\
    and privacy in smart city applications: Challenges and solutions,” IEEE\nCommunications\
    \ Magazine 55, 122–129 (2017).\n[52]\nY. Mehmood, F. Ahmad, I. Yaqoob, A. Adnane,\
    \ M. Imran, and\nS. Guizani, “Internet-of-things-based smart cities: Recent advances\
    \ and\nchallenges,” IEEE Communications Magazine 55, 16–24 (2017).\n[53]\nW. Rong,\
    \ Z. Xiong, D. Cooper, C. Li, and H. Sheng, “Smart city archi-\ntecture: A technology\
    \ guide for implementation and design challenges,”\nChina Communications 11, 56–69\
    \ (2014).\n[54]\nE. Ahmed, I. Yaqoob, A. Gani, M. Imran, and M. Guizani, “Internet-of-\n\
    things-based smart environments: State of the art, taxonomy, and open\nresearch\
    \ challenges,” IEEE Wireless Communications 23, 10–16 (2016).\n[55]\nS. Chen,\
    \ H. Xu, D. Liu, B. Hu, and H. Wang, “A vision of iot: Ap-\nplications, challenges,\
    \ and opportunities with china perspective,” IEEE\nInternet of Things Journal\
    \ 1, 349–359 (2014).\n[56]\nB. Ahlgren, M. Hidell, and E. C. Ngai, “Internet of\
    \ things for smart\ncities: Interoperability and open data,” IEEE Internet Computing\
    \ 20,\n52–56 (2016).\n[57]\nI. Lee and K. Lee, “The internet of things (iot):\
    \ Applications, investments,\nand challenges for enterprises,” Business Horizons\
    \ 58, 431–440 (2015).\n[58]\nC. M. Morais, D. Sadok, and J. Kelner, “An iot sensor\
    \ and scenario\nsurvey for data researchers,” Journal of the Brazilian Computer\
    \ Society\n25 (2019).\n[59]\nA. Sharma and M. Sinha, “A differential evolution-based\
    \ routing algo-\nrithm for multi-path environment in mobile ad hoc network,” Interna-\n\
    tional Journal of Hybrid Intelligence 1, 23–40 (2019).\n135\n[60]\nG. P. Hancke,\
    \ B. de Carvalho de Silva, and G. P. Hancke, The role of\nadvanced sensing in\
    \ smart cities, vol. 13 (Multidisciplinary Digital Pub-\nlishing Institute, 2013).\n\
    [61]\nM. Penza, D. Suriano, M. G. Villani, L. Spinelle, and M. Gerboles, “To-\n\
    wards air quality indices in smart cities by calibrated low-cost sensors\napplied\
    \ to networks,” Proceedings of IEEE Sensors 2014-Decem, 2012–\n2017 (2014).\n\
    [62]\nF. Folianto, Y. S. Low, and W. L. Yeow, “Smartbin: Smart waste man-\nagement\
    \ system,” 2015 IEEE 10th International Conference on Intelligent\nSensors, Sensor\
    \ Networks and Information Processing, ISSNIP 2015 pp.\n1–2 (2015).\n[63]\nG.\
    \ Bedi, G. K. Venayagamoorthy, R. Singh, R. R. Brooks, and K. C.\nWang, “Review\
    \ of internet of things (iot) in electric power and energy\nsystems,” IEEE Internet\
    \ of Things Journal 5, 847–870 (2018).\n[64]\nE. Y. Song, G. J. Fitzpatrick, and\
    \ K. B. Lee, “Smart sensors and standard-\nbased interoperability in smart grids,”\
    \ IEEE Sensors Journal 17, 7723–\n7730 (2017).\n[65]\nA. A. Abdellatif, A. Mohamed,\
    \ C. F. Chiasserini, M. Tlili, and A. Erbad,\n“Edge computing for smart health:\
    \ Context-aware approaches, opportu-\nnities, and challenges,” IEEE Network 33,\
    \ 196–203 (2019).\n[66]\nK. Fan, S. Zhu, K. Zhang, H. Li, and Y. Yang, “A lightweight\
    \ authen-\ntication scheme for cloud-based rfid healthcare systems,” IEEE Network\n\
    33, 44–49 (2019).\n[67]\nA. Prati, C. Shan, and K. I. Wang, “Sensors, vision and\
    \ networks: From\nvideo surveillance to activity recognition and health monitoring,”\
    \ Journal\nof Ambient Intelligence and Smart Environments 11, 5–22 (2019).\n[68]\n\
    D. Ding, R. A. Cooper, P. F. Pasquina, and L. Fici-Pasquina, “Sensor\ntechnology\
    \ for smart homes,” Maturitas 69, 131–136 (2011).\n[69]\nB. Jan, H. Farman, M.\
    \ Khan, M. Talha, and I. U. Din, “Designing a smart\ntransportation system: An\
    \ internet of things and big data approach,”\nIEEE Wireless Communications 26,\
    \ 73–79 (2019).\n[70]\nJ. Guerrero-Ib´a˜nez, S. Zeadally, and J. Contreras-Castillo,\
    \ “Sensor tech-\nnologies for intelligent transportation systems,” Sensors (Switzerland)\
    \ 18,\n1–24 (2018).\n[71]\nA. Gharaibeh, M. A. Salahuddin, S. J. Hussini, A. Khreishah,\
    \ I. Khalil,\nM. Guizani, and A. Al-Fuqaha, “Smart cities: A survey on data manage-\n\
    ment, security, and enabling technologies,” IEEE Communications Sur-\nveys and\
    \ Tutorials 19, 2456–2501 (2017).\n136\n[72]\nS. Talari, M. Shafie-Khah, P. Siano,\
    \ V. Loia, A. Tommasetti, and J. P.\nCatal˜ao, “A review of smart cities based\
    \ on the internet of things con-\ncept,” Energies 10, 1–23 (2017).\n[73]\nD. M.\
    \ Park, S. K. Kim, and Y. S. Seo, “S-mote: Smart home framework\nfor common household\
    \ appliances in iot network,” Journal of Information\nProcessing Systems 15, 449–456\
    \ (2019).\n[74]\nI. Yaqoob, E. Ahmed, I. A. T. Hashem, A. I. A. Ahmed, A. Gani,\
    \ M. Im-\nran, and M. Guizani, “Internet of things architecture: Recent advances,\n\
    taxonomy, requirements, and open challenges,” IEEE wireless communi-\ncations\
    \ 24, 10–16 (2017).\n[75]\nP. Sakhardande, S. Hanagal, and S. Kulkarni, “Design\
    \ of disaster man-\nagement system using iot based interconnected network with\
    \ smart city\nmonitoring,” 2016 International Conference on Internet of Things\
    \ and\nApplications, IOTA 2016 pp. 185–190 (2016).\n[76]\nL. Kang, S. Poslad,\
    \ W. Wang, X. Li, Y. Zhang, and C. Wang, “A public\ntransport bus as a flexible\
    \ mobile smart environment sensing platform for\niot,” Proceedings - 12th International\
    \ Conference on Intelligent Environ-\nments, IE 2016 pp. 1–8 (2016).\n[77]\nT.\
    \ Adiono, M. Y. Fathany, R. V. W. Putra, K. Afifah, M. H. Santri-\naji, B. L.\
    \ Lawu, and S. Fuada, “Live demonstration: Minds - meshed\nand internet networked\
    \ devices system for smart home: Track selection:\nEmbedded systems,” 2016 IEEE\
    \ Asia Pacific Conference on Circuits and\nSystems, APCCAS 2016 pp. 736–737 (2017).\n\
    [78]\nA. Ghosh and N. Chakraborty, “Design of smart grid in an university\ncampus\
    \ using zigbee mesh networks,” 1st IEEE International Conference\non Power Electronics,\
    \ Intelligent Control and Energy Systems, ICPEICES\n2016 pp. 1–6 (2017).\n[79]\n\
    Y. Yan, Y. Qian, and H. Sharif, “A secure data aggregation and dispatch\nscheme\
    \ for home area networks in smart grid,” GLOBECOM - IEEE\nGlobal Telecommunications\
    \ Conference pp. 1–6 (2011).\n[80]\nU. Raza, P. Kulkarni, and M. Sooriyabandara,\
    \ “Low power wide area\nnetworks: An overview,” IEEE Communications Surveys and\
    \ Tutorials\n19, 855–873 (2017).\n[81]\nM. Kuzlu and M. Pipattanasomporn, “Assessment\
    \ of communication\ntechnologies and network requirements for different smart\
    \ grid applica-\ntions,” 2013 IEEE PES Innovative Smart Grid Technologies Conference,\n\
    ISGT 2013 pp. 1–6 (2013).\n[82]\nS. Al-Sarawi, M. Anbar, K. Alieyan, and M. Alzubaidi,\
    \ “Internet of things\n(iot) communication protocols: Review,” ICIT 2017 - 8th\
    \ International\nConference on Information Technology, Proceedings pp. 685–690\
    \ (2017).\n137\n[83]\nK. Mekki, E. Bajic, F. Chaxel, and F. Meyer, “A comparative\
    \ study of\nlpwan technologies for large-scale iot deployment,” ICT Express 5,\
    \ 1–7\n(2019).\n[84]\nS. S. I. Samuel, “A review of connectivity challenges in\
    \ iot-smart home,”\n2016 3rd MEC International Conference on Big Data and Smart\
    \ City,\nICBDSC 2016 pp. 364–367 (2016).\n[85]\nP. Kuppusamy, S. Muthuraj, and\
    \ S. Gopinath, “Survey and challenges\nof li-fi with comparison of wi-fi,” Proceedings\
    \ of the 2016 IEEE Inter-\nnational Conference on Wireless Communications, Signal\
    \ Processing and\nNetworking, WiSPNET 2016 pp. 896–899 (2016).\n[86]\nB.-S. A.\
    \ Heile and M. H. T. P. C (Futurewei) Liu, B(Huawei Technolo-\ngies) Zhang, “Wi-sun\
    \ fan overview,” (2017).\n[87]\nB. Hammi, R. Khatoun, S. Zeadally, A. Fayad, and\
    \ L. Khoukhi, “Iot\ntechnologies for smart cities,” IET Networks 7, 1–13 (2018).\n\
    [88]\nZ. A. Baig, P. Szewczyk, C. Valli, P. Rabadia, P. Hannay, M. Cherny-\nshev,\
    \ M. Johnstone, P. Kerai, A. Ibrahim, K. Sansurooah, N. Syed, and\nM. Peacock,\
    \ “Future challenges for smart cities: Cyber-security and dig-\nital forensics,”\
    \ Digital Investigation 22, 3–13 (2017).\n[89]\nT. Braun, B. C. Fung, F. Iqbal,\
    \ and B. Shah, “Security and privacy\nchallenges in smart cities,” Sustainable\
    \ Cities and Society 39, 499–507\n(2018).\n[90]\nD. Eckhoff and I. Wagner, “Privacy\
    \ in the smart city - applications, tech-\nnologies, challenges, and solutions,”\
    \ IEEE Communications Surveys and\nTutorials 20, 489–516 (2018).\n[91]\nA. S.\
    \ Elmaghraby and M. M. Losavio, “Cyber security challenges in smart\ncities: Safety,\
    \ security and privacy,” Journal of Advanced Research 5,\n491–497 (2014).\n[92]\n\
    D. POPESCUL and L. D. RADU, “Data security in smart cities: Chal-\nlenges and\
    \ solutions,” Informatica Economica 20, 29–38 (2016).\n[93]\nV. Hassija, V. Chamola,\
    \ V. Saxena, D. Jain, P. Goyal, and B. Sikdar, “A\nsurvey on iot security: Application\
    \ areas, security threats, and solution\narchitectures,” IEEE Access 7, 82721–82743\
    \ (2019).\n[94]\nD. E. Whitehead, K. Owens, D. Gammel, and J. Smith, “Ukraine\
    \ cyber-\ninduced power outage: Analysis and practical mitigation strategies,”\
    \ 70th\nAnnual Conference for Protective Relay Engineers, CPRE 2017 (2017).\n\
    [95]\nI. B. A. Ang, F. D. Salim, and M. Hamilton, “Human occupancy recogni-\n\
    tion with multivariate ambient sensors,” 2016 IEEE International Confer-\nence\
    \ on Pervasive Computing and Communication Workshops, PerCom\nWorkshops 2016 pp.\
    \ 1–6 (2016).\n138\n[96]\nL. Yang, K. Ting, and M. B. Srivastava, “Inferring occupancy\
    \ from oppor-\ntunistically available sensor data,” 2014 IEEE International Conference\n\
    on Pervasive Computing and Communications, PerCom 2014 pp. 60–68\n(2014).\n[97]\n\
    J. D. Howard and T. A. Longstaff, “A common language for computer\nsecurity incidents,”\
    \ Sandia National Laboratories (1998).\n[98]\nR. Agrawal, P. Verma, R. Sonanis,\
    \ U. Goel, A. De, S. A. Kondaveeti, and\nS. Shekhar, “Continuous security in iot\
    \ using blockchain,” ICASSP, IEEE\nInternational Conference on Acoustics, Speech\
    \ and Signal Processing -\nProceedings 2018-April, 6423–6427 (2018).\n[99]\nS.\
    \ Rizvi, J. P. Iii, A. Kurtz, and M. Rizvi, “Securing the internet of things\n\
    ( iot ): A security taxonomy for iot,” in “2018 17th IEEE International\nConference\
    \ On Trust, Security And Privacy In Computing And Commu-\nnications/ 12th IEEE\
    \ International Conference On Big Data Science And\nEngineering (TrustCom/BigDataSE),”\
    \ (IEEE, 2018), pp. 163–168.\n[100] A. Aldairi and L. Tawalbeh, “Cyber security\
    \ attacks on smart cities and\nassociated mobile technologies,” Procedia Computer\
    \ Science 109, 1086–\n1091 (2017).\n[101] M. Ali, N. Abrishamchi, A. H. Abdullah,\
    \ A. D. Cheok, and K. S.\nBielawski, “Side channel attacks on smart home systems\
    \ :\nA short\noverview,” in “IECON 2017 - 43rd Annual Conference of the IEEE In-\n\
    dustrial Electronics Society,” (2017), pp. 8144–8149.\n[102] J. Choi and Y. Kim,\
    \ “An improved lea block encryption algorithm to pre-\nvent side-channel attack\
    \ in the iot system,” in “2016 Asia-Pacific Signal\nand Information Processing\
    \ Association Annual Summit and Conference\n(APSIPA),” (Asia Pacific Signal and\
    \ Information Processing Association,\n2016), pp. 1–4.\n[103] M. A. Al-Garadi,\
    \ A. Mohamed, A. K. Al-Ali, X. Du, I. Ali, and\nM. Guizani, “A survey of machine\
    \ and deep learning methods for internet\nof things (iot) security,” IEEE Communications\
    \ Surveys & Tutorials 22,\n1646–1685 (2020).\n[104] X. Ouyang and Z. Ma, “Using\
    \ lstm networks to identify false data of smart\nterminals in the smart grid,”\
    \ Proceedings of the International Conference\non Parallel and Distributed Systems\
    \ - ICPADS 2017-Decem, 765–768\n(2018).\n[105] A. Diro and N. Chilamkurti, “Leveraging\
    \ lstm networks for attack detec-\ntion in fog-to-things communications,” IEEE\
    \ Communications Magazine\n56, 124–130 (2018).\n[106] N. Balakrishnan, A. Rajendran,\
    \ D. Pelusi, and V. Ponnusamy, “Deep\nbelief network enhanced intrusion detection\
    \ system to prevent security\nbreach in the internet of things,” Internet of Things\
    \ p. 100112 (2019).\n139\n[107] R. Khatoun and S. Zeadally, “Cybersecurity and\
    \ privacy solutions in\nsmart cities,” IEEE Communications Magazine 55, 51–59\
    \ (2017).\n[108] H. F. Atlam, A. Alenezi, M. O. Alassafi, and G. B. Wills, “Blockchain\n\
    with internet of things : Benefits , challenges , and future directions,” I.J.\n\
    Intelligent Systems and Applications 10, 40–48 (2018).\n[109] J. T. de Souza,\
    \ A. C. de Francisco, C. M. Piekarski, and G. F. do Prado,\n“Data mining and machine\
    \ learning to promote smart cities: A systematic\nreview from 2000 to 2018,” Sustainability\
    \ (Switzerland) 11 (2019).\n[110] Z. Rayan, M. Alfonse, and A. B. M. Salem, “Machine\
    \ learning approaches\nin smart health,” Procedia Computer Science 154, 361–368\
    \ (2018).\n[111] R. Varghese and S. Sharma, “Affordable smart farming using iot\
    \ and\nmachine learning,” Proceedings of the 2nd International Conference on\n\
    Intelligent Computing and Control Systems, ICICCS 2018 pp. 645–650\n(2019).\n\
    [112] S. AlZu’bi, B. Hawashin, M. Mujahed, Y. Jararweh, and B. B. Gupta,\n“An\
    \ efficient employment of internet of multimedia things in smart and\nfuture agriculture,”\
    \ Multimedia Tools and Applications 78, 29581–29605\n(2019).\n[113] K. S. P. Reddy,\
    \ Y. M. Roopa, L. N. K. Rajeev, and N. S. Nandan, “Iot\nbased smart agriculture\
    \ using machine learning,” Proceedings of the 2nd\nInternational Conference on\
    \ Inventive Research in Computing Applica-\ntions, ICIRCA 2020 pp. 130–134 (2020).\n\
    [114] A. Goap, D. Sharma, A. K. Shukla, and C. R. Krishna, “An iot based\nsmart\
    \ irrigation management system using machine learning and open\nsource technologies,”\
    \ Computers and Electronics in Agriculture 155, 41–\n49 (2018).\n[115] S. Rodr´ıguez,\
    \ T. Gualotu˜na, and C. Grilo, “A system for the monitor-\ning and predicting\
    \ of data in precision a agriculture system for the and\npredicting of wireless\
    \ data in precision in a monitoring rose greenhouse\nbased on sensor agriculture\
    \ in a rose greenhouse based on wireless sensor\nnetworks ne,” Procedia Computer\
    \ Science 121, 306–313 (2017).\n[116] N. Kitpo, Y. Kugai, M. Inoue, T. Yokemura,\
    \ and S. Satomura, “Internet\nof things for greenhouse monitoring system using\
    \ deep learning and bot\nnotification services,” 2019 IEEE International Conference\
    \ on Consumer\nElectronics, ICCE 2019 (2019).\n[117] A. K. Saha, J. Saha, R. Ray,\
    \ S. Sircar, S. Dutta, S. P. Chattopadhyay, and\nH. N. Saha, “Iot-based drone\
    \ for improvement of crop quality in agricul-\ntural field,” in “2018 IEEE 8th\
    \ Annual Computing and Communication\nWorkshop and Conference (CCWC),” (IEEE,\
    \ 2018), pp. 612–615.\n140\n[118] A. A. Araby, M. M. Abd Elhameed, N. M. Magdy,\
    \ N. Abdelaal, Y. T.\nAbd Allah, M. S. Darweesh, M. A. Fahim, H. Mostafa et al.,\
    \ “Smart iot\nmonitoring system for agriculture with predictive analysis,” in\
    \ “2019 8th\nInternational Conference on Modern Circuits and Systems Technologies\n\
    (MOCAST),” (IEEE, 2019), pp. 1–4.\n[119] S. A. Nandhini and R. H. S. Radha, “Web\
    \ enabled plant disease detec-\ntion system for agricultural applications using\
    \ wmsn,” Wireless Personal\nCommunications 102, 725–740 (2018).\n[120] L. Ale,\
    \ A. Sheta, L. Li, Y. Wang, and N. Zhang, “Deep learning based\nplant disease\
    \ detection for smart agriculture,” 2019 IEEE Globecom\nWorkshops, GC Wkshps 2019\
    \ - Proceedings pp. 1–6 (2019).\n[121] F. Balducci, D. Impedovo, and G. Pirlo,\
    \ “Machine learning applications\non agricultural datasets for smart farm enhancement,”\
    \ Machines 6 (2018).\n[122] X.-B. Jin, N.-X. Yang, X.-Y. Wang, Y.-T. Bai, T.-L.\
    \ Su, and J.-L. Kong,\n“Hybrid deep learning predictor for smart agriculture sensing\
    \ based on\nempirical mode decomposition and gated recurrent unit group model,”\n\
    Sensors 20, 1334 (2020).\n[123] S. A. M. Varman, A. R. Baskaran, S. Aravindh,\
    \ and E. Prabhu, “Deep\nlearning and iot for smart agriculture using wsn,” 2017\
    \ IEEE International\nConference on Computational Intelligence and Computing Research,\
    \ IC-\nCIC 2017 pp. 0–5 (2018).\n[124] X. bo Jin, X. hong Yu, X. yi Wang, Y. ting\
    \ Bai, and T. li Su, “Deep\nlearning predictor for sustainable precision agriculture\
    \ based on internet\nof things system,” Sustainability 12, 1433 (2020).\n[125]\
    \ K. Aliev, M. M. Jawaid, S. Narejo, E. Pasero, and A. Pulatov, “Inter-\nnet of\
    \ plants application for smart agriculture,” International Journal of\nAdvanced\
    \ Computer Science and Applications 9, 421–429 (2018).\n[126] A. L. Diedrichs,\
    \ F. Bromberg, D. Dujovne, K. Brun-laguna, T. Watteyne,\nand S. Member, “Prediction\
    \ of frost events using machine learning and iot\nsensing devices,” IEEE Internet\
    \ of Things Journal 5, 4589–4597 (2018).\n[127] R.\nReshma,\nV.\nSathiyavathi,\n\
    T.\nSindhu,\nK.\nSelvakumar,\nand\nL. SaiRamesh, “Iot based classification techniques\
    \ for soil content analysis\nand crop yield prediction,” in “2020 Fourth International\
    \ Conference on\nI-SMAC (IoT in Social, Mobile, Analytics and Cloud)(I-SMAC),”\
    \ (IEEE,\n2020), pp. 156–160.\n[128] M. Pawar and G. Chillarge, “Soil toxicity\
    \ prediction and recommendation\nsystem using data mining in precision agriculture,”\
    \ in “2018 3rd interna-\ntional conference for convergence in technology (I2CT),”\
    \ (IEEE, 2018),\npp. 1–5.\n141\n[129] K. Lee, B. N. Silva, and K. Han, “Deep learning\
    \ entrusted to fog\nnodes (dlefn) based smart agriculture,” Applied Sciences (Switzerland)\n\
    10 (2020).\n[130] M. A. Guill´en, A. Llanes, B. Imbern´on, R. Mart´ınez, E. Andr´es,\
    \ B. Cre-\nspo, and J. Carlos, “Performance evaluation of edge - computing platforms\n\
    for the prediction of low temperatures in agriculture using deep learning,”\n\
    The Journal of Supercomputing 77, 818–840 (2021).\n[131] M. A. Guill´en-navarro,\
    \ R. Mart´ınez-espa˜na, and J. M. Cecilia, “A high-\nperformance iot solution\
    \ to reduce frost damages in stone fruits,” Con-\ncurrency and Computation: Practice\
    \ and Experience 33, e5299 (2019).\n[132] M. A. Guill´en, A. Llanes, B. Imbern´on,\
    \ R. Mart´ınez-Espa˜na, A. Bueno-\nCrespo, J. C. Cano, and J. M. Cecilia, “Performance\
    \ evaluation of edge-\ncomputing platforms for the prediction of low temperatures\
    \ in agriculture\nusing deep learning,” (2020).\n[133] D. Rutqvist, D. Kleyko,\
    \ and F. Blomstedt, “An automated machine learn-\ning approach for smart waste\
    \ management systems,” IEEE Transactions\non Industrial Informatics PP, 1–1 (2019).\n\
    [134] A. Hussain, U. Draz, T. Ali, S. Tariq, M. Irfan, A. Glowacz, J. Alfonso,\n\
    A. Daviu, S. Yasin, and S. Rahman, “Waste management and prediction\nof air pollutants\
    \ using iot and machine learning approach,” Energies 13,\n3930 (2020).\n[135]\
    \ D. Zhang, G. Lindholm, and H. Ratnaweera, “Use long short-term mem-\nory to\
    \ enhance Internet of Things for combined sewer overflow monitor-\ning,” Journal\
    \ of Hydrology 556, 409–418 (2018).\n[136] P. Varalakshmi, S. Vandhana, and S.\
    \ Vishali, “Prediction of water quality\nusing naive bayesian algorithm,” 2016\
    \ 8th International Conference on\nAdvanced Computing, ICoAC 2016 pp. 224–229\
    \ (2017).\n[137] D. Jalal, “Toward a Smart Real Time Monitoring System for Drinking\n\
    Water Based on Machine Learning,” 2019 International Conference on\nSoftware,\
    \ Telecommunications and Computer Networks (SoftCOM) pp.\n1–5 (2019).\n[138] T.\
    \ Bin, M. M. Alam, N. Absar, K. Andersson, and M. Shahadat, “Iot\nbased real-time\
    \ river water quality monitoring system,” Procedia Com-\nputer Science 155, 161–168\
    \ (2019).\n[139] P. Liu, J. Wang, A. K. Sangaiah, Y. Xie, and X. Yin, “Analysis\
    \ and\nprediction of water quality using lstm deep neural networks in iot envi-\n\
    ronment,” Sustainability 11, 2058 (2019).\n[140] Z. Tariq, S. K. Shah, and Y.\
    \ Lee, “Smart 311 request system with au-\ntomatic noise detection for safe neighborhood,”\
    \ 2018 IEEE International\nSmart Cities Conference, ISC2 2018 pp. 1–8 (2019).\n\
    142\n[141] J. Zhang, S. I. Levitan, and J. Hirschberg, “Multimodal deception detec-\n\
    tion using automatically extracted acoustic, visual, and lexical features.”\n\
    in “INTERSPEECH,” (2020), pp. 359–363.\n[142] Y. Santur, E. Karak¨ose, M. Karak¨ose,\
    \ and E. Akın, “Deep learning based\nartificial manager for smart city,” in “5th\
    \ International Conference on\nAdvanced Technology & Sciences,” (2017), pp. 197–201.\n\
    [143] S. Sanaei, B. Majidi, and E. Akhtarkavan, “Deep multisensor dashboard\n\
    for composition layer of web of things in the smart city,” 9th International\n\
    Symposium on Telecommunication: With Emphasis on Information and\nCommunication\
    \ Technology, IST 2018 pp. 211–215 (2019).\n[144] P. D. Rosero-Montalvo, J. A.\
    \ Caraguay-Procel, E. D. Jaramillo, J. M.\nMichilena-Calderon, A. C. Umaquinga-Criollo,\
    \ M. Mediavilla-Valverde,\nM. A. Ruiz, L. A. Beltran, and D. H. Peluffo-Ord´onez,\
    \ “Air quality moni-\ntoring intelligent system using machine learning techniques,”\
    \ Proceedings\n- 3rd International Conference on Information Systems and Computer\
    \ Sci-\nence, INCISCOS 2018 2018-Decem, 75–80 (2018).\n[145] C. Feng, W. Wang,\
    \ Y. Tian, X. Que, and X. Gong, “Estimate air quality\nbased on mobile crowd sensing\
    \ and big data,” 18th IEEE International\nSymposium on A World of Wireless, Mobile\
    \ and Multimedia Networks,\nWoWMoM 2017 - Conference (2017).\n[146] R. Yu, Y.\
    \ Yang, L. Yang, G. Han, and O. A. Move, “RAQ–A random for-\nest approach for\
    \ predicting air quality in urban sensing systems,” Sensors\n(Switzerland) 16\
    \ (2016).\n[147] I. K¨ok, M. U. S¸im¸sek, and S. ¨Ozdemir, “A deep learning model\
    \ for air\nquality prediction in smart cities,” Proceedings - 2017 IEEE International\n\
    Conference on Big Data, Big Data 2017 2018-Janua, 1983–1990 (2017).\n[148] A.\
    \ Al-Wakeel, J. Wu, and N. Jenkins, “K -means based load estimation\nof domestic\
    \ smart meter measurements,” Applied Energy 194, 333–342\n(2017).\n[149] O. Valgaev,\
    \ F. Kupzog, and H. Schmeck, “Building power demand fore-\ncasting using k-nearest\
    \ neighbours model - practical application in smart\ncity demo aspern project,”\
    \ CIRED - Open Access Proceedings Journal\n2017, 1601–1604 (2017).\n[150] P. Vrablecov´a,\
    \ A. B. Ezzeddine, V. Rozinajov´a, S. ˇS´arik, and A. K. Sanga-\niah, “Smart grid\
    \ load forecasting using online support vector regression,”\nComputers and Electrical\
    \ Engineering 65, 102–117 (2018).\n[151] W. Kong, Z. Y. Dong, Y. Jia, D. J. Hill,\
    \ Y. Xu, and Y. Zhang, “Short-\nterm residential load forecasting based on lstm\
    \ recurrent neural network,”\nIEEE Transactions on Smart Grid 10, 841–851 (2019).\n\
    143\n[152] S. Hosein and P. Hosein, “Load forecasting using deep neural networks,”\n\
    2017 IEEE Power and Energy Society Innovative Smart Grid Technologies\nConference,\
    \ ISGT 2017 (2017).\n[153] K. Ke, S. Hongbin, Z. Chengkang, and C. Brown, “Short-term\
    \ electrical\nload forecasting method based on stacked auto-encoding and gru neural\n\
    network,” Evolutionary Intelligence 12, 385–394 (2019).\n[154] T. Han, K. Muhammad,\
    \ T. Hussain, J. Lloret, and S. W. Baik, “An\nefficient deep learning framework\
    \ for intelligent energy management in\niot networks,” IEEE Internet of Things\
    \ Journal (2020).\n[155] X. Liu, Z. Xiao, R. Zhu, J. Wang, L. Liu, and M. Ma,\
    \ “Edge sensing data-\nimaging conversion scheme of load forecasting in smart\
    \ grid,” Sustainable\nCities and Society p. 102363 (2020).\n[156] A. Ta¨ık and\
    \ S. Cherkaoui, “Electrical load forecasting using edge com-\nputing and federated\
    \ learning,” in “ICC 2020-2020 IEEE International\nConference on Communications\
    \ (ICC),” (IEEE, 2020), pp. 1–6.\n[157] D. Nguyen, R. Barella, S. A. Wallace,\
    \ X. Zhao, and X. Liang, “Smart\ngrid line event classification using supervised\
    \ learning over pmu data\nstreams,” 2015 6th International Green and Sustainable\
    \ Computing Con-\nference (2016).\n[158] Z. Zheng, Y. Yang, X. Niu, H. N. Dai,\
    \ and Y. Zhou, “Wide and deep\nconvolutional neural networks for electricity-theft\
    \ detection to secure\nsmart grids,” IEEE Transactions on Industrial Informatics\
    \ 14, 1606–1615\n(2018).\n[159] Y. Huang, Y. Lu, F. Wang, X. Fan, J. Liu, and\
    \ V. C. Leung, “An edge\ncomputing framework for real-time monitoring in smart\
    \ grid,” Proceed-\nings - 2018 IEEE International Conference on Industrial Internet,\
    \ ICII\n2018 pp. 99–108 (2018).\n[160] S. Batool, N. A. Saqib, and M. A. Khan,\
    \ “Internet of things data analytics\nfor user authentication and activity recognition,”\
    \ 2017 2nd International\nConference on Fog and Mobile Edge Computing, FMEC 2017\
    \ pp. 183–187\n(2017).\n[161] H. Zhang, Z. Xiao, J. Wang, F. Li, and E. Szczerbicki,\
    \ “A novel iot-\nperceptive human activity recognition ( har ) approach using\
    \ multihead\nconvolutional attention,” IEEE Internet of Things Journal 7, 1072–1080\n\
    (2020).\n[162] D. Castro, “Wearable-based human activity recognition using an\
    \ iot ap-\nproach,” Journal of Sensor and Actuator Networks 6, 28 (2017).\n[163]\
    \ D. N. Tran and D. D. Phan, “Human activities recognition in android\nsmartphone\
    \ using support vector machine,” in “Proceedings - Inter-\nnational Conference\
    \ on Intelligent Systems, Modelling and Simulation,\nISMS,” , vol. 0 (IEEE, 2016),\
    \ vol. 0, pp. 64–68.\n144\n[164] G. L. Santos,\nP. T. Endo,\nK. Henrique,\nand\
    \ D. C. Monteiro,\n“Accelerometer-based human fall detection using,” Sensors 19,\
    \ 1–12\n(2019).\n[165] D. Yacchirema, “Fall detection system for elderly people\
    \ using iot and en-\nsemble machine learning algorithm,” Personal and Ubiquitous\
    \ Computing\n23, 801–817 (2019).\n[166] I.\nMachorro-Cano,\nG.\nAlor-Hern´andez,\n\
    M.\nA.\nParedes-Valverde,\nU. Ramos-Deonati, J. L. S´anchez-Cervantes, and L.\
    \ Rodr´ıguez-Mazahua,\n“Pisiot: A machine learning and iot-based smart health\
    \ platform for over-\nweight and obesity control,” Applied Sciences (Switzerland)\
    \ 9 (2019).\n[167] R. Ani, S. Krishna, N. Anju, A. M. Sona, and O. S. Deepa, “Iot\
    \ based pa-\ntient monitoring and diagnostic prediction tool using ensemble classifier,”\n\
    2017 International Conference on Advances in Computing, Communica-\ntions and\
    \ Informatics, ICACCI 2017 2017-Janua, 1588–1593 (2017).\n[168] A. Ukil and U.\
    \ K. Roy, “Smart cardiac health management in iot through\nheart sound signal\
    \ analytics and robust noise filtering,” IEEE Interna-\ntional Symposium on Personal,\
    \ Indoor and Mobile Radio Communica-\ntions, PIMRC 2017-Octob, 1–5 (2018).\n[169]\
    \ A. Alamri, “Monitoring system for patients using multimedia for smart\nhealthcare,”\
    \ IEEE Access 6, 23271–23276 (2018).\n[170] Y. Qu, X. Ming, S. Qiu, M. Zheng,\
    \ and Z. Hou, “An integrative framework\nfor online prognostic and health management\
    \ using internet of things and\nconvolutional neural network,” Sensors (Switzerland)\
    \ 19 (2019).\n[171] M. S. Hossain and G. Muhammad, “Cloud-assisted industrial\
    \ internet\nof things (iiot) - enabled framework for health monitoring,” Computer\n\
    Networks 101, 192–202 (2016).\n[172] M. Alhussein, G. Muhammad, M. S. Hossain,\
    \ and S. U. Amin, “Cognitive\niot-cloud integration for smart healthcare: Case\
    \ study for epileptic seizure\ndetection and monitoring,” Mobile Networks and\
    \ Applications 23, 1624–\n1635 (2018).\n[173] M. Ganesan and N. Sivakumar, “Iot\
    \ based heart disease prediction and di-\nagnosis model for healthcare using machine\
    \ learning models,” 2019 IEEE\nInternational Conference on System, Computation,\
    \ Automation and Net-\nworking, ICSCAN 2019 pp. 1–5 (2019).\n[174] S. Mohapatra,\
    \ P. K. Patra, S. Mohanty, and B. Pati, “Smart health care\nsystem using data\
    \ mining,” Proceedings - 2018 International Conference\non Information Technology,\
    \ ICIT 2018 pp. 44–49 (2018).\n[175] P. Kaur, R. Kumar, and M. Kumar, “A healthcare\
    \ monitoring system\nusing random forest and internet of things (iot),” Multimedia\
    \ Tools and\n145\nApplications 78, 19905–19916 (2019). Ni, its one of those random\
    \ papers\nwhere they take data and run algorithms on them.\n[176] M. Alhussein,\
    \ “Monitoring parkinson’s disease in smart cities,” IEEE Ac-\ncess 5, 19835–19841\
    \ (2017).\n[177] S. Tuli, N. Basumatary, S. S. Gill, M. Kahani, R. C. Arya, G.\
    \ S. Wan-\nder, and R. Buyya, “Healthfog: An ensemble deep learning based smart\n\
    healthcare system for automatic diagnosis of heart diseases in integrated\niot\
    \ and fog computing environments,” Future Generation Computer Sys-\ntems 104,\
    \ 187–200 (2020).\n[178] M. Devarajan and L. Ravi, “Intelligent cyber-physical\
    \ system for an ef-\nficient detection of parkinson disease using fog computing,”\
    \ Multimedia\nTools and Applications 78, 32695–32719 (2019).\n[179] M. A. Sayeed,\
    \ S. P. Mohanty, E. Kougianos, V. P. Yanambaka, and H. Za-\nveri, “A robust and\
    \ fast seizure detector for iot edge,” Proceedings - 2018\nIEEE 4th International\
    \ Symposium on Smart Electronic Systems, iSES\n2018 pp. 156–160 (2018).\n[180]\
    \ J. P. Queralta, T. N. Gia, H. Tenhunen, and T. Westerlund, “Edge-ai in\nlora-based\
    \ health monitoring: Fall detection system with fog computing\nand lstm recurrent\
    \ neural networks,” in “2019 42nd international confer-\nence on telecommunications\
    \ and signal processing (TSP),” (IEEE, 2019),\npp. 601–604.\n[181] M. Awais, M.\
    \ Raza, N. Singh, K. Bashir, U. Manzoor, S. ul Islam, and J. J.\nRodrigues, “Lstm\
    \ based emotion detection using physiological signals:\nIot framework for healthcare\
    \ and distance learning in covid-19,” IEEE\nInternet of Things Journal (2020).\n\
    [182] P. Pirzada, N. White, and A. Wilde, “Sensors in smart homes for indepen-\n\
    dent living of the elderly,” 5th International Multi-Topic ICT Conference:\nTechnologies\
    \ For Future Generations, IMTIC 2018 - Proceedings pp. 1–8\n(2018).\n[183] J.\
    \ Park, K. Jang, and S. B. Yang, “Deep neural networks for activity\nrecognition\
    \ with multi-sensor data in a smart home,” IEEE World Forum\non Internet of Things,\
    \ WF-IoT 2018 - Proceedings 2018-Janua, 155–160\n(2018).\n[184] A. Wang, G. Chen,\
    \ C. Shang, M. Zhang, and L. Liu, “Human activity\nrecognition in a smart home\
    \ environment with stacked denoising autoen-\ncoders,” in “International Conference\
    \ on Web-Age Information Manage-\nment,” (Springer, 2016), pp. 29–40.\n[185] D.\
    \ Singh, E. Merdivan, I. Psychoula, J. Kropf, S. Hanke, M. Geist,\nand A. Holzinger,\
    \ “Human activity recognition using recurrent neural\n146\nnetworks,” Lecture\
    \ Notes in Computer Science (including subseries Lec-\nture Notes in Artificial\
    \ Intelligence and Lecture Notes in Bioinformatics)\n10410 LNCS, 267–274 (2017).\n\
    [186] G. Y. Kim, S. S. Shin, J. Y. Kim, and H. G. Kim, “Haptic Conversion\nUsing\
    \ Detected Sound Event in Home Monitoring System for the Hard-\nof-Hearing,” HAVE\
    \ 2018 - IEEE International Symposium on Haptic,\nAudio-Visual Environments and\
    \ Games, Proceedings pp. 17–22 (2018).\n[187] A. B. Adege, H. P. Lin, G. B. Tarekegn,\
    \ and S. S. Jeng, “Applying deep\nneural network (dnn) for robust indoor localization\
    \ in multi-building en-\nvironment,” Applied Sciences (Switzerland) 8, 1–14 (2018).\n\
    [188] R. Adeogun, I. Rodriguez, M. Razzaghpour, G. Berardinelli, P. H. Chris-\n\
    tensen, and P. E. Mogensen, “Indoor occupancy detection and estimation\nusing\
    \ machine learning and measurements from an iot lora-based mon-\nitoring system,”\
    \ in “2019 Global IoT Summit (GIoTS),” (IEEE, 2019),\npp. 1–5.\n[189] L. Zimmermann,\
    \ R. Weigel, and G. Fischer, “Fusion of nonintrusive en-\nvironmental sensors\
    \ for occupancy detection in smart homes,” IEEE In-\nternet of Things Journal\
    \ 5, 2343–2352 (2018).\n[190] D. Chowdhry, R. Paranjape, and P. Laforge, “Smart\
    \ home automation\nsystem for intrusion detection,” 2015 IEEE 14th Canadian Workshop\
    \ on\nInformation Theory, CWIT 2015 pp. 75–78 (2015).\n[191] V. H. Bhide and S.\
    \ Wagh, “I-learning iot: An intelligent self learning\nsystem for home automation\
    \ using iot,” 2015 International Conference\non Communication and Signal Processing,\
    \ ICCSP 2015 pp. 1763–1767\n(2015).\n[192] F. C. C. Garcia, C. M. C. Creayla,\
    \ and E. Q. B. Macabebe, “Develop-\nment of an intelligent system for smart home\
    \ energy disaggregation using\nstacked denoising autoencoders,” Procedia Computer\
    \ Science 105, 248–\n255 (2017).\n[193] C. C. Yang, C. S. Soh, and V. V. Yap,\
    \ “A non-intrusive appliance load\nmonitoring for efficient energy consumption\
    \ based on naive bayes classi-\nfier,” Sustainable Computing: Informatics and\
    \ Systems 14, 34–42 (2017).\n[194] D. Popa, F. Pop, C. Serbanescu, and A. Castiglione,\
    \ “Deep learning model\nfor home automation and energy reduction in a smart home\
    \ environment\nplatform,” Neural Computing and Applications 31, 1317–1337 (2019).\n\
    [195] I. C. Konstantakopoulos, A. R. Barkan, S. He, T. Veeravalli, H. Liu,\nand\
    \ C. Spanos, “A deep learning and gamification approach to improving\nhuman-building\
    \ interaction and energy efficiency in smart infrastructure,”\nApplied Energy\
    \ 237, 810–821 (2019).\n147\n[196] H. Albataineh, M. Nijim, and D. Bollampall,\
    \ “The design of a novel smart\nhome control system using smart grid based on\
    \ edge and cloud comput-\ning,” in “2020 IEEE 8th International Conference on\
    \ Smart Energy Grid\nEngineering (SEGE),” (IEEE, 2020), pp. 88–91.\n[197] P. H.\
    \ F. Sousa, N. M. M. Nascimento, J. S. Almeida, P. P. R. Filho,\nand V. H. C.\
    \ Albuquerque, “Intelligent incipient fault detection in wind\nturbines based\
    \ on industrial iot environment,” Journal of Artificial Intel-\nligence and Systems\
    \ 1, 1–19 (2019).\n[198] M. Salhaoui, A. Guerrero-Gonz´alez, M. Arioua, F. J.\
    \ Ortiz, A. E.\nOualkadi, and C. L. Torregrosa, “Smart industrial iot monitoring\
    \ and\ncontrol system based on uav and cloud computing applied to a concrete\n\
    plant,” Sensors (Switzerland) 19 (2019).\n[199] M. A. Ferreira, L. F. F. D. Souza,\
    \ F. H. S. D. Silva, E. F. Ohata, J. S.\nAlmeida, and P. P. Filho, “Intelligent\
    \ industrial iot system for detection\nof short-circuit failure in windings of\
    \ wind turbines,” Proceedings of the\nInternational Joint Conference on Neural\
    \ Networks (2020).\n[200] T. Nkonyana, Y. Sun, B. Twala, and E. Dogo, “Performance\
    \ evaluation of\ndata mining techniques in steel manufacturing industry,” Procedia\
    \ Man-\nufacturing 35, 623–628 (2019).\n[201] J. E. Siegel, S. Pratt, Y. Sun,\
    \ and S. E. Sarma, “Real-time deep neural\nnetworks for internet-enabled arc-fault\
    \ detection,” Engineering Applica-\ntions of Artificial Intelligence 74, 35–42\
    \ (2018).\n[202] J. Windau and L. Itti, “Inertial machine monitoring system for\
    \ auto-\nmated failure detection,” Proceedings - IEEE International Conference\n\
    on Robotics and Automation pp. 93–98 (2018).\n[203] A. N. Sokolov, I. A. Pyatnitsky,\
    \ and S. K. Alabugin, “Research of Classical\nMachine Learning Methods and Deep\
    \ Learning Models Effectiveness in\nDetecting Anomalies of Industrial Control\
    \ System,” Proceedings - 2018\nGlobal Smart Industry Conference, GloSIC 2018 (2018).\n\
    [204] D. C. Huang, C. F. Lin, C. Y. Chen, and J. R. Sze, “The internet tech-\n\
    nology for defect detection system with deep learning method in smart\nfactory,”\
    \ 2018 4th International Conference on Information Management,\nICIM 2018 pp.\
    \ 98–102 (2018).\n[205] L. Li, K. Ota, and M. Dong, “Deep learning for smart industry:\
    \ Efficient\nmanufacture inspection system with fog computing,” IEEE Transactions\n\
    on Industrial Informatics 14, 4665–4673 (2018).\n[206] S. Y. Lin, Y. Du, P. C.\
    \ Ko, T. J. Wu, P. T. Ho, V. Sivakumar, and\nR. subbareddy, “Fog computing based\
    \ hybrid deep learning framework in\neffective inspection system for smart manufacturing,”\
    \ Computer Commu-\nnications 160, 636–642 (2020).\n148\n[207] M. S. S. Garmaroodi,\
    \ F. Farivar, M. S. Haghighi, M. A. Shoorehdeli, and\nA. Jolfaei, “Detection of\
    \ anomalies in industrial iot systems by data min-\ning: Study of christ osmotron\
    \ water purification system,” IEEE Internet\nof Things Journal 4662, 1–1 (2020).\n\
    [208] D. Park, S. Kim, Y. An, and J. Y. Jung, “Lired: A light-weight real-time\n\
    fault detection system for edge computing using lstm recurrent neural\nnetworks,”\
    \ Sensors (Switzerland) 18 (2018).\n[209] Y. Liu, N. Kumar, Z. Xiong, W. Y. B.\
    \ Lim, J. Kang, and D. Niyato,\n“Communication-efficient federated learning for\
    \ anomaly detection in in-\ndustrial internet of things,” in “GLOBECOM,” , vol.\
    \ 2020 (2020), vol.\n2020, pp. 1–6.\n[210] H. Zheng, Y. Feng, Y. Gao, and J. Tan,\
    \ “A robust predicted performance\nanalysis approach for data-driven product development\
    \ in the industrial\ninternet of things,” Sensors (Switzerland) 18 (2018).\n[211]\
    \ A. Essien and C. Giannetti, “A deep learning model for smart manu-\nfacturing\
    \ using convolutional lstm neural network autoencoders,” IEEE\nTransactions on\
    \ Industrial Informatics 16, 6069–6078 (2020).\n[212] W. Tao, Z.-H. Lai, M. C.\
    \ Leu, and Z. Yin, “Worker activity recognition\nin smart manufacturing using\
    \ imu and semg signals with convolutional\nneural networks,” Procedia Manufacturing\
    \ 26, 1159–1166 (2018).\n[213] A. R. M. Forkan, F. Montori, D. Georgakopoulos,\
    \ P. P. Jayaraman,\nA. Yavari, and A. Morshed, “An industrial iot solution for\
    \ evaluating\nworkers’ performance via activity recognition,” in “2019 IEEE 39th\
    \ In-\nternational Conference on Distributed Computing Systems (ICDCS),”\n(IEEE,\
    \ 2019), pp. 1393–1403.\n[214] B. Huang, W. Wang, S. Ren, R. Y. Zhong, and J.\
    \ Jiang, “A proactive task\ndispatching method based on future bottleneck prediction\
    \ for the smart\nfactory,” International Journal of Computer Integrated Manufacturing\n\
    32, 278–293 (2019). Not included as it is a hybrid.\n[215] B. Brik, B. Bettayeb,\
    \ M. Sahnoun, and F. Duval, “Towards predicting\nsystem disruption in industry\
    \ 4.0: Machine learning-based approach,”\nProcedia Computer Science 151, 667–674\
    \ (2019).\n[216] Y. Han, C. J. Zhang, L. Wang, and Y. C. Zhang, “Industrial IoT\
    \ for Intel-\nligent Steelmaking with Converter Mouth Flame Spectrum Information\n\
    Processed by Deep Learning,” IEEE Transactions on Industrial Informat-\nics 16,\
    \ 2640–2650 (2020).\n[217] J. Wang, Y. Wang, and M. Yu, “A multi-period ambulance\
    \ location and\nallocation problem in the disaster,” Journal of Combinatorial\
    \ Optimiza-\ntion 9, 1–24 (2020). This paper presents a survey about fall detection\n\
    technologies and discusses how sensor fusion is one of the most popular\ntrends,\
    \ both in terms of data as well as algorithm.\n149\n[218] L. Spendla, M. Kebisek,\
    \ P. Tanuska, and L. Hrcka, “Concept of predictive\nmaintenance of production\
    \ systems in accordance with industry 4.0,” in\n“2017 IEEE 15th International\
    \ Symposium on Applied Machine Intelli-\ngence and Informatics (SAMI),” (IEEE,\
    \ 2017), pp. 405–410.\n[219] S. Hwang, J. Jeong, and Y. Kang, “Svm-rbm based predictive\
    \ main-\ntenance scheme for iot-enabled smart factory,” 2018 13th International\n\
    Conference on Digital Information Management, ICDIM 2018 pp. 162–\n167 (2018).\n\
    [220] E.-J. K. J.-H. Kwon, “Failure prediction model using iterative feature\n\
    selection for industrial internet of things,” Symmetry pp. 1–15 (2019).\n[221]\
    \ W. Zhang, W. Guo, X. Liu, Y. Liu, J. Zhou, B. Li, Q. Lu, and S. Yang,\n“Lstm-based\
    \ analysis of industrial iot equipment,” IEEE Access 6, 23551–\n23560 (2018).\n\
    [222] A. Diez, N. L. D. Khoa, M. M. Alamdari, Y. Wang, F. Chen, and P. Run-\n\
    cie, “A clustering approach for structural health monitoring on bridges,”\nJournal\
    \ of Civil Structural Health Monitoring 6, 429–445 (2016).\n[223] J. Guo, X. Xie,\
    \ and R. Bie, “Structural health monitoring by using a\nsparse coding-based deep\
    \ learning algorithm with wireless sensor net-\nworks,” Personal and ubiquitous\
    \ computing 18, 1977–1987 (2014).\n[224] G. Gui, H. Pan, Z. Lin, Y. Li, and Z.\
    \ Yuan, “Data-driven support vector\nmachine with optimization techniques for\
    \ structural health monitoring\nand damage detection,” KSCE Journal of Civil Engineering\
    \ 21, 523–534\n(2017).\n[225] H. V. Dang, H. Tran-ngoc, T. V. Nguyen, G. D. Roeck,\
    \ H. X. Nguyen,\nand S. Member, “Data-driven structural health monitoring using\
    \ feature\nfusion and hybrid deep learning,” IEEE Transactions on Automation Sci-\n\
    ence and Engineering pp. 1–17 (2020).\n[226] J. Vitola, F. Pozo, D. A. Tibaduiza,\
    \ and M. Anaya, “A sensor data fusion\nsystem based on k-nearest neighbor pattern\
    \ classification for structural\nhealth monitoring applications,” Sensors (Switzerland)\
    \ 17 (2017).\n[227] J. Yu, M. Kim, H. C. Bang, S. H. Bae, and S. J. Kim, “IoT\
    \ as a ap-\nplications: cloud-based building management systems for the internet\
    \ of\nthings,” Multimedia Tools and Applications 75, 14583–14596 (2016).\n[228]\
    \ S. Singaravel, P. Geyer, and J. Suykens, “Deep neural network archi-\ntectures\
    \ for component-based machine learning model in building energy\npredictions,”\
    \ Digital Proceedings of the 24th EG-ICE International Work-\nshop on Intelligent\
    \ Computing in Engineering 2017 pp. 260–268 (2017).\n[229] N. A. Eltresy, O. M.\
    \ Dardeer, A. Al-Habal, E. Elhariri, A. H. Hassan,\nA. Khattab, D. N. Elsheakh,\
    \ S. A. Taie, H. Mostafa, H. A. Elsadek, and\n150\nE. A. Abdallah, “Rf energy\
    \ harvesting iot system for museum ambience\ncontrol with deep learning,” Sensors\
    \ (Switzerland) 19 (2019).\n[230] W. Hu, Y. Wen, K. Guan, G. Jin, and K. J. Tseng,\
    \ “itcm : Toward\nlearning-based thermal comfort modeling via pervasive sensing\
    \ for smart\nbuildings,” IEEE Internet of Things Journal 5, 4164–4177 (2018).\n\
    [231] H. Mora and A. Jimeno-morenilla, “Deployment of iot edge and fog com-\n\
    puting technologies to develop smart building services,” Sustainability 10,\n\
    1–23 (2018).\n[232] D. H. Stolfi, E. Alba, and X. Yao, “Predicting car park occupancy\
    \ rates\nin smart cities,” Lecture Notes in Computer Science (including subseries\n\
    Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformat-\nics)\
    \ 10268 LNCS, 107–117 (2017).\n[233] R. K. Lenka, R. K. Barik, N. K. Das, K. Agarwal,\
    \ D. Mohanty, and\nS. Vipsita, “Psps: An iot based predictive smart parking system,”\
    \ 2017\n4th IEEE Uttar Pradesh Section International Conference on Electrical,\n\
    Computer and Electronics, UPCON 2017 2018-Janua, 311–317 (2017).\n[234] G. Ali,\
    \ T. Ali, M. Irfan, U. Draz, M. Sohail, A. Glowacz, M. Sulowicz,\nR. Mielnik,\
    \ Z. B. Faheem, and C. Martis, “Iot based smart parking system\nusing deep long\
    \ short memory network,” Electronics 9, 1696 (2020).\n[235] T. Ebuchi and H. Yamamoto,\
    \ “Vehicle/pedestrian localization system\nusing multiple radio beacons and machine\
    \ learning for smart parking,” in\n“2019 International Conference on Artificial\
    \ Intelligence in Information\nand Communication (ICAIIC),” (IEEE, 2019), pp.\
    \ 086–091.\n[236] F. M. Awan, Y. Saleem, R. Minerva, and N. Crespi, “A comparative\n\
    analysis of machine / deep learning models for parking space availability\nprediction,”\
    \ Sensors 20, 322 (2020).\n[237] X. Sevillano, E. M`armol, and V. Fernandez-Arguedas,\
    \ “Towards smart\ntraffic management systems:\nVacant on-street parking spot detection\n\
    based on video analytics,” FUSION 2014 - 17th International Conference\non Information\
    \ Fusion (2014).\n[238] H. Bura, N. Lin, N. Kumar, S. Malekar, S. Nagaraj, and\
    \ K. Liu, “An\nedge based smart parking solution using camera networks and deep\
    \ learn-\ning,” in “2018 IEEE International Conference on Cognitive Computing\n\
    (ICCC),” (IEEE, 2018), pp. 17–24.\n[239] C. Lee, S. Park, T. Yang, and S.-H. Lee,\
    \ “Smart parking with fine-grained\nlocalization and user status sensing based\
    \ on edge computing,” in “2019\nIEEE 90th Vehicular Technology Conference (VTC2019-Fall),”\
    \ (IEEE,\n2019), pp. 1–5.\n[240] S. S. Aung and T. T. Naing, “Na¨ıve bayes classifier\
    \ based traffic prediction\nsystem on cloud infrastructure,” Proceedings - International\
    \ Conference\n151\non Intelligent Systems, Modelling and Simulation, ISMS 2015-Octob,\n\
    193–198 (2015).\n[241] Y. Liu and H. Wu, “Prediction of road traffic congestion\
    \ based on random\nforest,” Proceedings - 2017 10th International Symposium on\
    \ Computa-\ntional Intelligence and Design, ISCID 2017 2, 361–364 (2018).\n[242]\
    \ W. Wei, H. Wu, and H. Ma, “An autoencoder and lstm-based traffic flow\nprediction\
    \ method,” Sensors 19, 1–16 (2019).\n[243] Y. Xiao, “Hybrid lstm neural network\
    \ for short-term traffic flow predic-\ntion,” Information 10, 105 (2019).\n[244]\
    \ F. Sun, Y. Pan, J. White, and A. Dubey, “Real-Time and Predictive An-\nalytics\
    \ for Smart Public Transportation Decision Support System,” 2016\nIEEE International\
    \ Conference on Smart Computing, SMARTCOMP\n2016 pp. 1–8 (2016).\n[245] N. Dogru\
    \ and A. Subasi, “Traffic accident detection using random forest\nclassifier,”\
    \ 2018 15th Learning and Technology Conference, L and T 2018\npp. 40–45 (2018).\n\
    [246] D. Nallaperuma, R. Nawaratne, T. Bandaragoda, A. Adikari, and\nS. Nguyen,\
    \ “Online incremental machine learning platform for big data-\ndriven smart traffic\
    \ management,” IEEE Transactions on Intelligent\nTransportation Systems 20, 4679–4690\
    \ (2019).\n[247] A. Mukherji, V. Raghuram, S. Pandey, H. Tran, and N. Bulusu,\
    \ “Com-\nmuterscanner: Towards smart indoor positioning systems in urban trans-\n\
    portation,” 2019 11th International Conference on Communication Sys-\ntems and\
    \ Networks, COMSNETS 2019 2061, 619–624 (2019).\n[248] S. Majumdar, M. M. Subhani,\
    \ B. Roullier, A. Anjum, and R. Zhu, “Con-\ngestion prediction for smart sustainable\
    \ cities using iot and machine learn-\ning approaches,” Sustainable Cities and\
    \ Society 64, 102500 (2021).\n[249] F. Peres and M. Castelli, “Combinatorial optimization\
    \ problems and\nmetaheuristics: Review, challenges, design, and development,”\
    \ Applied\nSciences 11, 6449 (2021).\n[250] M. Dorigo and K. Socha, “Ant colony\
    \ optimization,” Handbook of Ap-\nproximation Algorithms and Metaheuristics pp.\
    \ 26–1–26–14 (2007).\n[251] D. Whitley, “A genetic algorithm tutorial,” Statistics\
    \ and computing 4,\n65–85 (1994).\n[252] J. Kennedy and R. Eberhart, “Particle\
    \ swarm optimization,” in “Pro-\nceedings of ICNN’95-international conference\
    \ on neural networks,” , vol. 4\n(IEEE, 1995), vol. 4, pp. 1942–1948.\n[253] V.\
    \ Feoktistov, Differential evolution (Springer, 2006).\n152\n[254] D. Karaboga,\
    \ “Artificial bee colony algorithm,” scholarpedia 5, 6915\n(2010).\n[255] D. C.\
    \ H. Nguyen, J. C. Ascough II, H. R. Maier, G. C. Dandy, and A. A.\nAndales, “Optimization\
    \ of irrigation scheduling using ant colony algo-\nrithms and an advanced cropping\
    \ system model,” Environmental mod-\nelling & software 97, 32–45 (2017).\n[256]\
    \ B. Saeidian, M. S. Mesgari, B. Pradhan, and A. M. Alamri, “Irrigation\nwater\
    \ allocation at farm level based on temporal cultivation-related data\nusing meta-heuristic\
    \ optimisation algorithms,” Water 11, 2611 (2019).\n[257] D. Guo, J. E. Olesen,\
    \ K. Manevski, and X. Ma, “Optimizing irrigation\nschedule in a large agricultural\
    \ region under different hydrologic scenar-\nios,” Agricultural Water Management\
    \ 245, 106575 (2021).\n[258] S. Guo, F. Zhang, C. Zhang, C. An, S. Wang, and P.\
    \ Guo, “A multi-\nobjective hierarchical model for irrigation scheduling in the\
    \ complex canal\nsystem,” Sustainability 11, 24 (2019).\n[259] F. Zhang, C. He,\
    \ F. Yaqiong, X. Hao, and S. Kang, “Canal delivery and\nirrigation scheduling\
    \ optimization based on crop water demand,” Agri-\ncultural Water Management 260,\
    \ 107245 (2022).\n[260] A. Ikudayisi, J. Adeyemo, J. Odiyo, and A. Enitan, “Optimum\
    \ irriga-\ntion water allocation and crop distribution using combined pareto multi-\n\
    objective differential evolution,” Cogent Engineering 5, 1535749 (2018).\n[261]\
    \ J. Wu, R. Huang, T. Fang, and Y. Han, “Multi-objective model of irriga-\ntion\
    \ water distribution based on particle swarm optimization,” in “IOP\nConference\
    \ Series: Earth and Environmental Science,” , vol. 344 (IOP\nPublishing, 2019),\
    \ vol. 344, p. 012087.\n[262] A. L. P. De Ocampo and E. P. Dadios, “Energy cost\
    \ optimization in\nirrigation system of smart farm by using genetic algorithm,”\
    \ in “2017IEEE\n9th International Conference on Humanoid, Nanotechnology, Information\n\
    Technology, Communication and Control, Environment and Management\n(HNICEM),”\
    \ (IEEE, 2017), pp. 1–7.\n[263] L. Zhuo, J. Cheng, and Z. Gong, “Optimal water\
    \ allocation method based\non the genetic algorithm for a system of a reservoir\
    \ and two pumping\nstations,” Water Supply 22, 849–859 (2022).\n[264] R. Li, Y.\
    \ Chang, and Z. Wang, “Study of optimal allocation of water\nresources in dujiangyan\
    \ irrigation district of china based on an improved\ngenetic algorithm,” Water\
    \ Supply 21, 2989–2999 (2021).\n[265] S. K. Roy and D. De, “Genetic algorithm\
    \ based internet of precision agri-\ncultural things (iopat) for agriculture 4.0,”\
    \ Internet of Things p. 100201\n(2020).\n153\n[266] N. Lin, X. Wang, Y. Zhang,\
    \ X. Hu, and J. Ruan, “Fertigation manage-\nment for sustainable precision agriculture\
    \ based on internet of things,”\nJournal of Cleaner Production 277, 124119 (2020).\n\
    [267] C. Arif, B. I. Setiawan, M. Mizoguchi, and B. D. A. Nugroho, “Genetic\n\
    algorithms optimization for water management in irrigated paddy fields,”\nin “IOP\
    \ Conference Series: Earth and Environmental Science,” , vol. 335\n(IOP Publishing,\
    \ 2019), vol. 335, p. 012002.\n[268] WorldBank, “Solid waste management,” (2019).\n\
    [269] S. Sharmin and S. T. Al-Amin, “A cloud-based dynamic waste manage-\nment\
    \ system for smart cities,” Proceedings of the 7th Annual Symposium\non Computing\
    \ for Development, ACM DEV-7 2016 (2016).\n[270] R. Fujdiak, P. Masek, P. Mlynek,\
    \ J. Misurec, and E. Olshannikova, “Us-\ning genetic algorithm for advanced municipal\
    \ waste collection in smart\ncity,” 2016 10th International Symposium on Communication\
    \ Systems,\nNetworks and Digital Signal Processing, CSNDSP 2016 pp. 1–6 (2016).\n\
    [271] R. Assaf and Y. Saleh, “Vehicle-routing optimization for municipal solid\n\
    waste collection using genetic algorithm: the case of southern nablus city,”\n\
    Civil and environmental engineering reports (2017).\n[272] M. A. Hannan, M. S.\
    \ H. Lipu, M. Akhtar, R. A. Begum, M. A. A. Mamum,\nA. Hussain, M. S. Mia, and\
    \ H. Basri, “Solid waste collection optimization\nobjectives, constraints, modeling\
    \ approaches, and their challenges toward\nachieving sustainable development goals,”\
    \ Journal of cleaner production\np. 123557 (2020).\n[273] Y. Zhang, X. Luo, X.\
    \ Han, Y. Lu, J. Wei, and C. Yu, “Optimization of\nurban waste transportation\
    \ route based on genetic algorithm,” Security\nand Communication Networks 2022,\
    \ 1–10 (2022).\n[274] Q. Wei, Z. Guo, H. C. Lau, and Z. He, “An artificial bee\
    \ colony-based\nhybrid approach for waste collection problem with midway disposal\
    \ pat-\ntern,” Applied Soft Computing 76, 629–637 (2019).\n[275] S. P. Raflesia\
    \ and A. K. Pamosoaji, “A novel ant colony optimization\nalgorithm for waste collection\
    \ problem,” in “2019 4th International Con-\nference on Information Technology,\
    \ Information Systems and Electrical\nEngineering (ICITISEE),” (IEEE, 2019), pp.\
    \ 413–416.\n[276] M. Yazdani, K. Kabirifar, B. E. Frimpong, M. Shariati, M. Mirmozaffari,\n\
    and A. Boskabadi, “Improving construction and demolition waste collec-\ntion service\
    \ in an urban area using a simheuristic approach: A case study\nin sydney, australia,”\
    \ Journal of Cleaner Production 280, 124138 (2021).\n[277] S. Idwan, I. Mahmood,\
    \ J. A. Zubairi, and I. Matar, “Optimal management\nof solid waste in smart cities\
    \ using internet of things,” Wireless Personal\nCommunications 110, 485–501 (2020).\n\
    154\n[278] U. M. Faizal, R. Jayachitra, P. Vijayakumar, and M. Rajasekar, “Opti-\n\
    mization of inbound vehicle routes in the collection of bio-medical wastes,”\n\
    Materials Today: Proceedings 45, 692–699 (2021).\n[279] E. B. Tirkolaee, M. Alinaghian,\
    \ A. A. R. Hosseinabadi, M. B. Sasi, and\nA. K. Sangaiah, “An improved ant colony\
    \ optimization for the multi-trip\ncapacitated arc routing problem,” Computers\
    \ and Electrical Engineering\n77, 457–470 (2019).\n[280] “Branch and cut for vehicle\
    \ routing,” .\n[281] “Capacitated vrp instances — vehicle routing problem,” .\n\
    [282] M. Ettappan, V. Vimala, S. Ramesh, and V. T. Kesavan, “Optimal reac-\ntive\
    \ power dispatch for real power loss minimization and voltage stability\nenhancement\
    \ using artificial bee colony algorithm,” Microprocessors and\nMicrosystems 76,\
    \ 103085 (2020).\n[283] C. K. Das, O. Bass, G. Kothapalli, T. S. Mahmoud, and\
    \ D. Habibi,\n“Optimal placement of distributed energy storage systems in distribution\n\
    networks using artificial bee colony algorithm,” Applied energy 232, 212–\n228\
    \ (2018).\n[284] W. S. Sakr, R. A. El-Sehiemy, and A. M. Azmy, “Adaptive differential\n\
    evolution algorithm for efficient reactive power management,” Applied\nSoft Computing\
    \ 53, 336–351 (2017).\n[285] T. T. Nguyen and F. Mohammadi, “Optimal placement\
    \ of tcsc for conges-\ntion management and power loss reduction using multi-objective\
    \ genetic\nalgorithm,” Sustainability 12, 2813 (2020).\n[286] I. I. Atteya, H.\
    \ A. Ashour, N. Fahmi, and D. Strickland, “Distribution net-\nwork reconfiguration\
    \ in smart grid system using modified particle swarm\noptimization,” 2016 IEEE\
    \ International Conference on Renewable Energy\nResearch and Applications, ICRERA\
    \ 2016 5, 305–313 (2016).\n[287] N. Kanwar, N. Gupta, K. R. Niazi, A. Swarnkar,\
    \ and R. C. Bansal, “Si-\nmultaneous allocation of distributed energy resource\
    \ using improved par-\nticle swarm optimization,” Applied Energy 185, 1684–1693\
    \ (2017).\n[288] K. Utkarsh, A. Trivedi, D. Srinivasan, and T. Reindl, “A consensus-\n\
    based distributed computational intelligence technique for real-time opti-\nmal\
    \ control in smart distribution grids,” IEEE Transactions on Emerging\nTopics\
    \ in Computational Intelligence 1, 51–60 (2016).\n[289] A. Askarzadeh, “A memory-based\
    \ genetic algorithm for optimization of\npower generation in a microgrid,” IEEE\
    \ transactions on sustainable en-\nergy 9, 1081–1089 (2017).\n[290] O. H. Mohammed,\
    \ Y. Amirat, and M. Benbouzid, “Economical evaluation\nand optimal energy management\
    \ of a stand-alone hybrid energy system\nhandling in genetic algorithm strategies,”\
    \ Electronics 7, 233 (2018).\n155\n[291] B. K. Das, R. Hassan, M. S. H. K. Tushar,\
    \ F. Zaman, M. Hasan, and\nP. Das, “Techno-economic and environmental assessment\
    \ of a hybrid re-\nnewable energy system using multi-objective genetic algorithm:\
    \ A case\nstudy for remote island in bangladesh,” Energy Conversion and Manage-\n\
    ment 230, 113823 (2021).\n[292] D. K. Geleta and M. S. Manshahia, “Artificial\
    \ bee colony-based optimiza-\ntion of hybrid wind and solar renewable energy system,”\
    \ Research Anthol-\nogy on Clean Energy Management and Solutions pp. 819–842 (2021).\n\
    [293] M. M. Moghaddam, M. Marzband, and F. Azarinejadian, “Optimal en-\nergy management\
    \ for a home microgrid based on multi-period artifi-\ncial bee colony,” in “2017\
    \ Iranian Conference on Electrical Engineering\n(ICEE),” (IEEE, 2017), pp. 1446–1451.\n\
    [294] H. U. R. Habib, S. Wang, A. Waqar, B. S. Farhan, K. M. Kotb, and Y.-S.\n\
    Kim, “Combined heat and power units sizing and energy cost optimization\nof a\
    \ residential building by using an artificial bee colony algorithm,” IEEE\nAccess\
    \ 8, 218289–218303 (2020).\n[295] F. Lezama, J. Soares, R. Faia, T. Pinto, and\
    \ Z. Vale, “A new hybrid-\nadaptive differential evolution for a smart grid application\
    \ under uncer-\ntainty,” in “2018 IEEE Congress on Evolutionary Computation (CEC),”\n\
    (IEEE, 2018), pp. 1–8.\n[296] F. Lezama, L. E. Sucar, E. M. de Cote, J. Soares,\
    \ and Z. Vale, “Differential\nevolution strategies for large-scale energy resource\
    \ management in smart\ngrids,” in “Proceedings of the Genetic and Evolutionary\
    \ Computation\nConference Companion,” (2017), pp. 1279–1286.\n[297] V. Palakonda,\
    \ N. H. Awad, R. Mallipeddi, M. Z. Ali, K. C. Veluvolu,\nand P. N. Suganthan,\
    \ “Differential evolution with stochastic selection\nfor uncertain environments:\
    \ A smart grid application,” in “2018 IEEE\nCongress on Evolutionary Computation\
    \ (CEC),” (IEEE, 2018), pp. 1–7.\n[298] S. Mandal and K. K. Mandal, “Optimal energy\
    \ management of micro-\ngrids under environmental constraints using chaos enhanced\
    \ differential\nevolution,” Renewable Energy Focus 34, 129–141 (2020).\n[299]\
    \ M. Azaza and F. Wallin, “Multi objective particle swarm optimization of\nhybrid\
    \ micro-grid system: A case study in sweden,” Energy 123, 108–118\n(2017).\n[300]\
    \ H. A. Gabbar, M. R. Abdussami, and M. I. Adham, “Optimal planning\nof nuclear-renewable\
    \ micro-hybrid energy system by particle swarm opti-\nmization,” IEEE Access 8,\
    \ 181049–181073 (2020).\n[301] B. A. Bhayo, H. H. Al-Kayiem, S. I. U. Gilani,\
    \ and F. B. Ismail, “Power\nmanagement optimization of hybrid solar photovoltaic-battery\
    \ integrated\nwith pumped-hydro-storage system for standalone electricity generation,”\n\
    Energy Conversion and Management 215, 112942 (2020).\n156\n[302] L. F. Grisales-Nore˜na,\
    \ O. D. Montoya, and C. A. Ramos-Paja, “An en-\nergy management system for optimal\
    \ operation of bss in dc distributed\ngeneration environments based on a parallel\
    \ pso algorithm,” Journal of\nEnergy Storage 29, 101488 (2020).\n[303] M. Mahdavi,\
    \ A. Kimiyaghalam, H. H. Alhelou, M. Javadi, J. P. S. Catal˜ao,\nand A. Ashouri,\
    \ “Transmission expansion planning considering power\nlosses, expansion of substations\
    \ and uncertainty in fuel price using discrete\nartificial bee colony algorithm,”\
    \ IEEE Access (2021).\n[304] T. K. Maji and P. Acharjee, “Multiple solutions of\
    \ optimal pmu placement\nusing exponential binary pso algorithm for smart grid\
    \ applications,” IEEE\nTransactions on Industry Applications 53, 2550–2559 (2017).\n\
    [305] M. B. Rasheed and M. D. R-Moreno, “Minimizing pricing policies based\non\
    \ user load profiles and residential demand responses in smart grids,”\nApplied\
    \ Energy 310, 118492 (2022).\n[306] D. Zhang, Z. Fu, and L. Zhang, “An improved\
    \ ts algorithm for loss-\nminimum reconfiguration in large-scale distribution\
    \ systems,” Electric\nPower Systems Research 77, 685–694 (2007).\n[307] J. P.\
    \ Pell, J. M. Sirel, A. K. Marsden, I. Ford, and S. M. Cobbe, “Effect of\nreducing\
    \ ambulance response times on deaths from out of hospital cardiac\narrest: cohort\
    \ study,” Bmj 322, 1385–1388 (2001).\n[308] RapidSOS, “Outcomes: Quantifying the\
    \ impact of emergency response\ntime - rapidsos,” (2015).\n[309] P. Toth and D.\
    \ Vigo, The vehicle routing problem (SIAM, 2002).\n[310] A. A. Ageev and M. I.\
    \ Sviridenko, “Approximation algorithms for maxi-\nmum coverage and max cut with\
    \ given sizes of parts,” in “International\nConference on Integer Programming\
    \ and Combinatorial Optimization,”\n(Springer, 1999), pp. 17–30.\n[311] E. Mouhcine,\
    \ Y. Karouani, K. Mansouri, and Y. Mohamed, “Toward a\ndistributed strategy for\
    \ emergency ambulance routing problem,” in “2018\n4th International Conference\
    \ on Optimization and Applications (ICOA),”\n(IEEE, 2018), pp. 1–4.\n[312] L.\
    \ Brotcorne, G. Laporte, and F. Semet, “Ambulance location and relo-\ncation models,”\
    \ European journal of operational research 147, 451–463\n(2003).\n[313] M. Benabdouallah,\
    \ C. Bojji, and O. E. Yaakoubi, “Deployment and re-\ndeployment of ambulances\
    \ using a heuristic method and an ant colony\noptimization - case study,” Proceedings\
    \ - 2016 3rd International Confer-\nence on Systems of Collaboration, SysCo 2016\
    \ pp. 1–4 (2017).\n157\n[314] M. Benabdouallah and C. Bojji, “Comparison between\
    \ ga and aco for\nemergency coverage problem in a smart healthcare environment,”\
    \ in “Pro-\nceedings of the 2017 International Conference on Smart Digital Environ-\n\
    ment,” (2017), pp. 48–55.\n[315] Y. A. Kochetov and N. B. Shamray, “Optimization\
    \ of the ambulance fleet\nlocation and relocation,” Journal of Applied and Industrial\
    \ Mathematics\n15, 234–252 (2021).\n[316] Y. Yan, Y. Kong, and Z. Fu, “Dynamic\
    \ resource scheduling in emergency\nenvironment,” Journal of Information Hiding\
    \ and Privacy Protection 1,\n143 (2019).\n[317] Q. Lu and K.-D. Kim, “A genetic\
    \ algorithm approach for expedited cross-\ning of emergency vehicles in connected\
    \ and autonomous intersection traf-\nfic,” Journal of Advanced Transportation\
    \ 2017 (2017).\n[318] H. M. Amer, H. A. Al-Kashoash, A. Kemp, L. Mihaylova, and\
    \ M. May-\nfield, “Coalition game for emergency vehicles re-routing in smart cities,”\n\
    Proceedings of the IEEE Sensor Array and Multichannel Signal Process-\ning Workshop\
    \ 2018-July, 306–310 (2018).\n[319] B. N. Silva and K. Han, “Mutation operator\
    \ integrated ant colony opti-\nmization based domestic appliance scheduling for\
    \ lucrative demand side\nmanagement,” Future generation computer systems 100,\
    \ 557–568 (2019).\n[320] K. N. Bui, I. E. Agbehadji, R. Millham, D. Camacho, and\
    \ J. J. Jung,\n“Distributed artificial bee colony approach for connected appliances\
    \ in\nsmart home energy management system,” Expert Systems 37, e12521\n(2020).\n\
    [321] S. N. Makhadmeh, A. T. Khader, M. A. Al-Betar, S. Naim, Z. A. A.\nAlyasseri,\
    \ and A. K. Abasi, “Particle swarm optimization algorithm for\npower scheduling\
    \ problem using smart battery,” 2019 IEEE Jordan In-\nternational Joint Conference\
    \ on Electrical Engineering and Information\nTechnology, JEEIT 2019 - Proceedings\
    \ pp. 672–677 (2019).\n[322] S. Abid, A. Zafar, R. Khalid, S. Javaid, U. Qasim,\
    \ Z. A. Khan, and\nN. Javaid, “Managing energy in smart homes using binary particle\
    \ swarm\noptimization,” in “Conference on Complex, Intelligent, and Software In-\n\
    tensive Systems,” (Springer, 2017), pp. 189–196.\n[323] I. Fatima, A. Khalid,\
    \ S. Zahoor, A. Yasmeen, S. Arif, U. Zafar, and\nN. Javaid, “Home energy management\
    \ system using ant colony optimiza-\ntion technique in microgrid,” in “International\
    \ Conference on Broadband\nand Wireless Computing, Communication and Applications,”\
    \ (Springer,\n2017), pp. 267–279. Use ACO for appliance scheduling in a microgrid.\n\
    [324] N. U. Rehman, N. Javaid, and Z. A. Khan, “An enhanced differential\nevolution\
    \ based energy management system for smart grids,” in “2017\n158\n31st International\
    \ Conference on Advanced Information Networking and\nApplications Workshops (WAINA),”\
    \ (IEEE, 2017), pp. 132–137.\n[325] I. Gupta, G. N. Anandini, and M. Gupta, “An\
    \ hour wise device scheduling\napproach for demand side management in smart grid\
    \ using particle swarm\noptimization,” 2016 National Power Systems Conference,\
    \ NPSC 2016 pp.\n1–6 (2017).\n[326] M. A. Nasab, M. Zand, M. Eskandari, P. Sanjeevikumar,\
    \ and P. Siano,\n“Optimal planning of electrical appliance of residential units\
    \ in a smart\nhome network using cloud services,” Smart Cities 4, 1173–1195 (2021).\n\
    [327] I. O. Essiet, Y. Sun, and Z. Wang, “Optimized energy consumption model\n\
    for smart home using improved differential evolution algorithm,” Energy\n172,\
    \ 354–365 (2019).\n[328] I. Ullah and D. Kim, “An improved optimization function\
    \ for maximiz-\ning user comfort with minimum energy consumption in smart homes,”\n\
    Energies 10 (2017).\n[329] R. Reghukumar, S. Sambhu, and V. R. Pandi, “Multi-objective\
    \ optimiza-\ntion for efficient home energy management system using differential\
    \ evo-\nlution algorithm,” in “2018 3rd IEEE International Conference on Recent\n\
    Trends in Electronics, Information & Communication Technology (RTE-\nICT),” (IEEE,\
    \ 2018), pp. 1157–1162.\n[330] T. Pamulapati, R. Mallipeddi, and M. Lee, “Multi-objective\
    \ home appli-\nance scheduling with implicit and interactive user satisfaction\
    \ modelling,”\nApplied Energy 267, 114690 (2020).\n[331] A. R. Jordehi, “Binary\
    \ particle swarm optimisation with quadratic trans-\nfer function: A new binary\
    \ optimisation algorithm for optimal schedul-\ning of appliances in smart homes,”\
    \ Applied Soft Computing 78, 465–480\n(2019).\n[332] P. Chandra, A. Das, C. Das,\
    \ A. Naskar, B. Ganguly, and S. Paul, “Dif-\nferential evolution algorithm based\
    \ energy management of residential mi-\ncrogrid under appliance scheduling dsm,”\
    \ in “2020 IEEE VLSI DEVICE\nCIRCUIT AND SYSTEM (VLSI DCS),” (IEEE, 2020), pp.\
    \ 50–55.\n[333] R. Faia, P. Faria, Z. Vale, and J. Spinola, “Demand response optimiza-\n\
    tion using particle swarm algorithm considering optimum battery energy\nstorage\
    \ schedule in a residential house,” Energies 12, 1645 (2019).\n[334] D. Madathil,\
    \ V. R. Pandi, K. Ilango, and M. G. Nair, “Differential evo-\nlution based energy\
    \ management system for zero net energy building,” in\n“2017 International Conference\
    \ on Technological Advancements in Power\nand Energy (TAP Energy),” (IEEE, 2017),\
    \ pp. 1–5.\n159\n[335] H. Swalehe and B. Marungsri, “Intelligent algorithm for\
    \ optimal load\nmanagement in smart home appliance scheduling in distribution\
    \ sys-\ntem,” in “2018 International Electrical Engineering Congress (iEECON),”\n\
    (IEEE, 2018), pp. 1–4.\n[336] J.-C. Chang and T.-H. Wu, “Demand side management\
    \ of power for\ntime-of-use pricing based on particle swarm optimization,” in\
    \ “2020 3rd\nIEEE International Conference on Knowledge Innovation and Invention\n\
    (ICKII),” (IEEE, 2020), pp. 317–320.\n[337] C. Bharathi, D. Rekha, and V. Vijayakumar,\
    \ “Genetic algorithm based\ndemand side management for smart grid,” Wireless Personal\
    \ Communi-\ncations 93, 481–502 (2017).\n[338] Z. Chen, Y. Chen, R. He, J. Liu,\
    \ M. Gao, and L. Zhang, “Multi-objective\nresidential load scheduling approach\
    \ for demand response in smart grid,”\nSustainable Cities and Society 76, 103530\
    \ (2022).\n[339] W. Tao, Z. H. Lai, M. C. Leu, and Z. Yin, “Worker activity recognition\n\
    in smart manufacturing using imu and semg signals with convolutional\nneural networks,”\
    \ Procedia Manufacturing 26, 1159–1166 (2018).\n[340] R. Zhao, R. Yan, Z. Chen,\
    \ K. Mao, P. Wang, and R. X. Gao, “Deep\nlearning and its applications to machine\
    \ health monitoring,” Mechanical\nSystems and Signal Processing 115, 213–237 (2019).\n\
    [341] B. Huang, W. Wang, S. Ren, R. Y. Zhong, and J. Jiang, “A proactive task\n\
    dispatching method based on future bottleneck prediction for the smart\nfactory,”\
    \ International Journal of Computer Integrated Manufacturing\n32, 278–293 (2019).\n\
    [342] M. Sadeghi, R. Tavakkoli-Moghaddam, and R. Babazadeh, “An efficient\nartificial\
    \ bee colony algorithm for a p-hub covering location problem with\ntravel time\
    \ reliability.” International Journal of Industrial Engineering 25\n(2018).\n\
    [343] K. Guo, “Research on location selection model of distribution network\n\
    with constrained line constraints based on genetic algorithm,” Neural\nComputing\
    \ and Applications 32, 1679–1689 (2020).\n[344] Y. Su, J. Liu, X. Xiang, and X.\
    \ Zhang, “A responsive ant colony optimiza-\ntion for large-scale dynamic vehicle\
    \ routing problems via pheromone di-\nversity enhancement,” Complex and Intelligent\
    \ Systems pp. 1–16 (2021).\n[345] M. Alinaghian, M. Ghazanfari, N. Norouzi, and\
    \ H. Nouralizadeh, “A\nnovel model for the time dependent competitive vehicle\
    \ routing problem:\nModified random topology particle swarm optimization,” Networks\
    \ and\nSpatial Economics 17, 1185–1211 (2017).\n[346] D. M. Utama, T. A. Fitria,\
    \ and A. K. Garside, “Artificial bee colony\nalgorithm for solving green vehicle\
    \ routing problems with time windows,”\n160\nin “Journal of Physics: Conference\
    \ Series,” , vol. 1933 (IOP Publishing,\n2021), vol. 1933, p. 012043.\n[347] M.\
    \ Ibrahim, F. Nurhakiki, D. Utama, and A. Rizaki, “Optimised genetic\nalgorithm\
    \ crossover and mutation stage for vehicle routing problem pick-\nup and delivery\
    \ with time windows,” in “IOP Conference Series: Materials\nScience and Engineering,”\
    \ , vol. 1071 (IOP Publishing, 2021), vol. 1071,\np. 012025.\n[348] D. A. Mounia\
    \ and D. Bachir, “A hybrid discrete artificial bee colony for\nthe green pickup\
    \ and delivery problem with time windows,” Informatica\n44 (2020).\n[349] Z. Gu,\
    \ Y. Zhu, Y. Wang, X. Du, M. Guizani, and Z. Tian, “Applying\nartificial bee colony\
    \ algorithm to the multidepot vehicle routing problem,”\nSoftware: Practice and\
    \ Experience (2020).\n[350] N. Norouzi, M. Sadegh-Amalnick, and R. Tavakkoli-Moghaddam,\
    \ “Modi-\nfied particle swarm optimization in a time-dependent vehicle routing\
    \ prob-\nlem: minimizing fuel consumption,” Optimization Letters 11, 121–134\n\
    (2017).\n[351] K. K. H. Ng, C. K. M. Lee, S. Z. Zhang, K. Wu, and W. Ho, “A multiple\n\
    colonies artificial bee colony algorithm for a capacitated vehicle routing\nproblem\
    \ and re-routing strategies under time-dependent traffic conges-\ntion,” Computers\
    \ and Industrial Engineering 109, 151–168 (2017).\n[352] M. M. Solomon, “Algorithms\
    \ for the vehicle routing and scheduling prob-\nlems with time window constraints,”\
    \ Operations research 35, 254–265\n(1987).\n[353] Y. Huang, S. A. Ludwig, and\
    \ F. Deng, “Sensor optimization using a ge-\nnetic algorithm for structural health\
    \ monitoring in harsh environments,”\nJournal of Civil Structural Health Monitoring\
    \ 6, 509–519 (2016).\n[354] F. Zhao, H. Bao, S. Xue, and Q. Xu, “Multi-objective\
    \ particle swarm\noptimization of sensor distribution scheme with consideration\
    \ of the ac-\ncuracy and the robustness for deformation reconstruction,” Sensors\
    \ 19,\n1306 (2019).\n[355] C. Yang, K. Liang, X. Zhang, and X. Geng, “Sensor placement\
    \ algorithm\nfor structural health monitoring with redundancy elimination model\
    \ based\non sub-clustering strategy,” Mechanical Systems and Signal Processing\n\
    124, 369–387 (2019).\n[356] A. Downey, C. Hu, and S. Laflamme, “Optimal sensor\
    \ placement within\na hybrid dense sensor network using an adaptive genetic algorithm\
    \ with\nlearning gene pool,” Structural Health Monitoring 17, 450–460 (2018).\n\
    161\n[357] B. Cao, X. Kang, J. Zhao, P. Yang, Z. Lv, and X. Liu, “Differential\n\
    evolution-based 3-d directional wireless sensor network deployment opti-\nmization,”\
    \ IEEE Internet of Things Journal 5, 3594–3605 (2018).\n[358] R. Marks, A. Clarke,\
    \ C. A. Featherston, and R. Pullin, “Optimization of\nacousto-ultrasonic sensor\
    \ networks using genetic algorithms based on ex-\nperimental and numerical data\
    \ sets,” International Journal of Distributed\nSensor Networks 13, 1550147717743702\
    \ (2017).\n[359] H. Liu, X. He, and Y. Jiao, “Damage identification algorithm\
    \ of hinged\njoints for simply supported slab bridges based on modified hinge\
    \ plate\nmethod and artificial bee colony algorithms,” Algorithms 11, 198 (2018).\n\
    [360] H. Tran-Ngoc, S. Khatir, G. D. Roeck, T. Bui-Tien, L. Nguyen-Ngoc, and\n\
    M. A. Wahab, “Model updating for nam o bridge using particle swarm\noptimization\
    \ algorithm and genetic algorithm,” Sensors 18, 4131 (2018).\n[361] K. Gao, Y.\
    \ Zhang, A. Sadollah, and R. Su, “Improved artificial bee colony\nalgorithm for\
    \ solving urban traffic light scheduling problem,” in “2017\nIEEE Congress on\
    \ Evolutionary Computation (CEC),” (IEEE, 2017), pp.\n395–402.\n[362] R. F. Adebiyi,\
    \ K. A. Abubilal, M. B. Mu’azu, and B. H. Adebiyi, “Devel-\nopment and simulation\
    \ of adaptive traffic light controller using artificial\nbee colony algorithm,”\
    \ International Journal of Intelligent Systems and\nApplications 10, 68–74 (2018).\n\
    [363] T. Mao, A.-S. Mihaita, and C. Cai, “Traffic signal control optimization\n\
    under severe incident conditions using genetic algorithm,” arXiv preprint\narXiv:1906.05356\
    \ (2019).\n[364] C. Tang, S. Xia, C. Zhu, and X. Wei, “Phase timing optimization\
    \ for\nsmart traffic control based on fog computing,” IEEE Access 7, 84217–\n\
    84228 (2019).\n[365] Z. Li, M. Shahidehpour, S. Bahramirad, and A. Khodaei, “Optimizing\n\
    traffic signal settings in smart cities,” IEEE Transactions on Smart Grid\n8,\
    \ 2382–2393 (2017).\n[366] X. Chen and Z. Yuan, “Environmentally friendly traffic\
    \ control strategy-\na case study in xi’an city,” Journal of Cleaner Production\
    \ 249, 119397\n(2020).\n[367] E. Korkmaz and A. P. AKG¨UNG¨OR, “Delay estimation\
    \ models for sig-\nnalized intersections using differential evolution algorithm,”\
    \ Journal of\nEngineering Research 5 (2017).\n[368] X. Zhang, X. Fan, S. Yu, A.\
    \ Shan, S. Fan, Y. Xiao, and F. Dang, “Inter-\nsection signal timing optimization:\
    \ A multi-objective evolutionary algo-\nrithm,” Sustainability 2022, Vol. 14,\
    \ Page 1506 14, 1506 (2022).\n162\n[369] M. Wang, H. Dong, X. Li, L. Song, and\
    \ D. Pang, “A novel parking sys-\ntem designed for smart cities,” Proceedings\
    \ - 2017 Chinese Automation\nCongress, CAC 2017 2017-Janua, 3429–3434 (2017).\n\
    [370] I. Aydin, M. Karakose, and E. Karakose, “A navigation and reservation\n\
    based smart parking platform using genetic optimization for smart cities,”\nICSG\
    \ 2017 - 5th International Istanbul Smart Grids and Cities Congress\nand Fair\
    \ pp. 120–124 (2017).\n[371] F. Ferdous and M. S. Mahmud, “Intelligent traffic\
    \ monitoring system us-\ning vanet infrastructure and ant colony optimization,”\
    \ 2016 5th Interna-\ntional Conference on Informatics, Electronics and Vision,\
    \ ICIEV 2016 pp.\n356–360 (2016). The authors in FF16 use ACO in a smart transportation\n\
    system to efficient route vehicles using VANETS.\n[372] F. Pompei, “Ant colony\
    \ optimisation and geolocation technologies for the\ntransportation assignment\
    \ problem,” Proceedings - International Com-\nputer Software and Applications\
    \ Conference 2, 749–753 (2017). The au-\nthors in FP17 use ACO for planning of\
    \ public transport routes for Rome\nusing Phone data from transit users.\n[373]\
    \ A. Rehman, M. M. Rathore, A. Paul, F. Saeed, and R. W. Ahmad, “Ve-\nhicular\
    \ traffic optimisation and even distribution using ant colony in smart\ncity environment,”\
    \ IET Intelligent Transport Systems 12, 594–601 (2018).\n[374] A. Jovanovi´c and\
    \ D. Teodorovi´c, “Fixed-time traffic control at super-\nstreet intersections\
    \ by bee colony optimization,” Transportation Research\nRecord p. 03611981211058104\
    \ (2021).\n[375] T.-H. Nguyen and J. J. Jung, “Ant colony optimization-based traffic\
    \ rout-\ning with intersection negotiation for connected vehicles,” Applied Soft\n\
    Computing 112, 107828 (2021).\n[376] R. Pitakaso, K. Sethanan, and N. Srijaroon,\
    \ “Modified differential evolu-\ntion algorithms for multi-vehicle allocation\
    \ and route optimization for em-\nployee transportation,” Engineering Optimization\
    \ 52, 1225–1243 (2020).\n[377] Y. Yi, K. Choi, and Y. J. Lee, “Optimal limited-stop\
    \ bus routes selec-\ntion using a genetic algorithm and smart card data,” Journal\
    \ of Public\nTransportation 19, 178–198 (2016).\n[378] A. T. Buba and L. S. Lee,\
    \ “Differential evolution with improved sub-\nroute reversal repair mechanism\
    \ for multiobjective urban transit routing\nproblem,” Numerical Algebra, Control\
    \ and Optimization 8, 351 (2018).\n[379] X. Mao, “Study on ant colony optimization\
    \ algorithm for “one-day tour”\ntraffic line,” Cluster Computing 22, 3673–3680\
    \ (2019).\n[380] A. Jovanovi´c, M. Nikoli´c, and D. Teodorovi´c, “Area-wide urban\
    \ traffic\ncontrol: A bee colony optimization approach,” Transportation Research\n\
    Part C: Emerging Technologies 77, 329–350 (2017).\n163\n[381] K. Hassoune, W.\
    \ Dachry, F. Moutaouakkil, and H. Medromi, “Dynamic\nparking guidance architecture\
    \ using ant colony optimization and multi-\nagent systems,” Journal of Advances\
    \ in Information Technology 11, 58–63\n(2020).\n[382] U. Nations, “World population\
    \ prospects: the 2017 revision, key findings\nand advance tables,” Department\
    \ of Economics and Social Affairs PD,\neditor. New York: United Nations (2017).\n\
    [383] WHO, “Falls : Key facts,” (2018).\n[384] R. Afable,\nB. Averbeck,\nK. Holmen,\n\
    R. Dziedzicki,\nA. Nichols,\nJ. Schlegelmilch, and D. Caruso, “When i’m 64: How\
    \ boomers will change\nhealth care,” (2007).\n[385] M. K. James, M. C. Victor,\
    \ S. M. Saghir, and P. A. Gentile, “Characteri-\nzation of fall patients: Does\
    \ age matter?” Journal of Safety Research 64,\n83–92 (2018).\n[386] J. A. Stevens,\
    \ M. F. Ballesteros, K. A. Mack, R. A. Rudd, E. DeCaro, and\nG. Adler, “Gender\
    \ differences in seeking care for falls in the aged medicare\npopulation,” American\
    \ journal of preventive medicine 43, 59–62 (2012).\n[387] J. Morisod and M. Coutaz,\
    \ “Post-fall syndrome: how to recognize and\ntreat it?” Revue M´edicale Suisse\
    \ 3, 2531–2 (2007).\n[388] K. Chaccour, R. Darazi, A. H. El Hassani, and E. Andres,\
    \ “From fall de-\ntection to fall prevention: A generic classification of fall-related\
    \ systems,”\nIEEE Sensors Journal 17, 812–822 (2016).\n[389] A. L. S. D. Lima,\
    \ L. J. W. Evers, T. Hahn, L. Bataille, J. L. Hamilton,\nM. A. Little, Y. Okuma,\
    \ B. R. Bloem, and M. J. Faber, “Freezing of\ngait and fall detection in parkinson’s\
    \ disease using wearable sensors: a\nsystematic review,” Journal of neurology\
    \ 264, 1642–1654 (2017).\n[390] E. E. Geertsema, G. H. Visser, M. A. Viergever,\
    \ and S. N. Kalitzin,\n“Automated remote fall detection using impact features\
    \ from video and\naudio,” Journal of biomechanics 88, 25–32 (2019).\n[391] P.\
    \ Tsinganos and A. Skodras, “A smartphone-based fall detection system\nfor the\
    \ elderly,” in “Proceedings of the 10th International Symposium on\nImage and\
    \ Signal Processing and Analysis,” (IEEE, 2017), pp. 53–58.\n[392] N. El Halabi,\
    \ R. A. Z. Daou, R. Achkar, A. Hayek, and J. B¨orcs¨ok,\n“Monitoring system for\
    \ prediction and detection of epilepsy seizure,” in\n“2019 Fourth International\
    \ Conference on Advances in Computational\nTools for Engineering Applications\
    \ (ACTEA),” (IEEE, 2019), pp. 1–7.\n[393] J. Fleming and C. Brayne, “Inability\
    \ to get up after falling, subsequent\ntime on floor, and summoning help: prospective\
    \ cohort study in people\nover 90,” Bmj 337 (2008).\n164\n[394] K. Ozcan, A. K.\
    \ Mahabalagiri, M. Casares, and S. Velipasalar, “Auto-\nmatic fall detection and\
    \ activity classification by a wearable embedded\nsmart camera,” IEEE journal\
    \ on emerging and selected topics in circuits\nand systems 3, 125–136 (2013).\n\
    [395] A. Ramachandran and A. Karuppiah, “A survey on recent advances in\nwearable\
    \ fall detection systems,” BioMed research international 2020\n(2020).\n[396]\
    \ Q. Guan, C. Li, X. Guo, and B. Shen, “Infrared signal based elderly fall\ndetection\
    \ for in-home monitoring,” in “2017 9th International Confer-\nence on Intelligent\
    \ Human-Machine Systems and Cybernetics (IHMSC),”\n, vol. 1 (IEEE, 2017), vol.\
    \ 1, pp. 373–376.\n[397] A. Yazar, F. Erden, and A. E. Cetin, “Multi-sensor ambient\
    \ assisted\nliving system for fall detection,” in “Proceedings of the IEEE International\n\
    Conference on Acoustics, Speech, and Signal Processing (ICASSP’14),”\n(2014),\
    \ pp. 1–3.\n[398] S. M. Adnan, A. Irtaza, S. Aziz, M. O. Ullah, A. Javed, and\
    \ M. T. Mah-\nmood, “Fall detection through acoustic local ternary patterns,”\
    \ Applied\nAcoustics 140, 296–300 (2018).\n[399] S. Palipana, D. Rojas, P. Agrawal,\
    \ and D. Pesch, “Falldefi: Ubiquitous\nfall detection using commodity wi-fi devices,”\
    \ Proceedings of the ACM\non Interactive, Mobile, Wearable and Ubiquitous Technologies\
    \ 1, 1–25\n(2018).\n[400] I. Halima, J.-M. Lafert´e, G. Cormier, A.-J. Foug`ere,\
    \ and J.-L. Dillenseger,\n“Depth and thermal information fusion for head tracking\
    \ using particle\nfilter in a fall detection context,” Integrated Computer-Aided\
    \ Engineering\npp. 1–14 (2020).\n[401] Q. Han, H. Zhao, W. Min, H. Cui, X. Zhou,\
    \ K. Zuo, and R. Liu, “A\ntwo-stream approach to fall detection with mobilevgg,”\
    \ IEEE Access 8,\n17556–17566 (2020).\n[402] J. Zhang, C. Wu, and Y. Wang, “Human\
    \ fall detection based on body\nposture spatio-temporal evolution,” Sensors 20,\
    \ 946 (2020).\n[403] R. Gupta, P. Anand, S. Chaudhury, B. Lall, and S. Singh,\
    \ “Compressive\nsensing based privacy for fall detection,” arXiv preprint arXiv:2001.03463\n\
    (2020).\n[404] R. Espinosa, H. Ponce, S. Guti´errez, L. Mart´ınez-Villase˜nor,\
    \ J. Brieva,\nand E. Moya-Albor, “Application of convolutional neural networks\
    \ for fall\ndetection using multiple cameras,” in “Challenges and Trends in Multi-\n\
    modal Fall Detection for Healthcare,” (Springer, 2020), pp. 97–120.\n[405] M.\
    \ T. Pourazad, A. Shojaei-Hashemi, P. Nasiopoulos, M. Azimi, M. Mak,\nJ. Grace,\
    \ D. Jung, and T. Bains, “A non-intrusive deep learning based fall\n165\ndetection\
    \ scheme using video cameras,” in “2020 International Conference\non Information\
    \ Networking (ICOIN),” (IEEE, 2020), pp. 443–446.\n[406] Y. Nizam and M. M. A.\
    \ Jamil, “A novel approach for human fall detection\nand fall risk assessment,”\
    \ in “Challenges and Trends in Multimodal Fall\nDetection for Healthcare,” (Springer,\
    \ 2020), pp. 237–259.\n[407] Z. Liu, M. Yang, Y. Yuan, and K. Y. Kan, “Fall detection\
    \ and person-\nnel tracking system using infrared array sensors,” IEEE Sensors\
    \ Journal\n(2020).\n[408] A. Singh, S. U. Rehman, S. Yongchareon, and P. H. J.\
    \ Chong, “Sensor\ntechnologies for fall detection systems: A review,” IEEE Sensors\
    \ Journal\n20, 6889–6919 (2020).\n[409] M. Hubl, O. Pohl, V. Noack, P. Hahlweg,\
    \ C. Ehm, M. Derleh, T. Wei-\nland, E. Schick, H. M¨uller, D. Hampicke et al.,\
    \ “Embedding of wear-\nable electronics into smart sensor insole,” in “2016 IEEE\
    \ 18th Electronics\nPackaging Technology Conference (EPTC),” (IEEE, 2016), pp.\
    \ 597–601.\n[410] T. Shi, X. Sun, Z. Xia, L. Chen, and J. Liu, “Fall detection\
    \ algorithm\nbased on triaxial accelerometer and magnetometer.” Engineering Letters\n\
    24 (2016).\n[411] S. Hwang, M. Ryu, Y. Yang, and N. Lee, “Fall detection with\
    \ three-axis\naccelerometer and magnetometer in a smartphone,” in “Proceedings\
    \ of\nthe International Conference on Computer Science and Technology, Jeju,\n\
    Korea,” (2012), pp. 25–27.\n[412] X. Xi, M. Tang, S. M. Miran, and Z. Luo, “Evaluation\
    \ of feature extrac-\ntion and recognition for activity monitoring and fall detection\
    \ based on\nwearable semg sensors,” Sensors 17, 1229 (2017).\n[413] P. Melillo,\
    \ R. Castaldo, G. Sannino, A. Orrico, G. De Pietro, and L. Pec-\nchia, “Wearable\
    \ technology and ecg processing for fall risk assessment,\nprevention and detection,”\
    \ in “2015 37th Annual International Confer-\nence of the IEEE Engineering in\
    \ Medicine and Biology Society (EMBC),”\n(IEEE, 2015), pp. 7740–7743.\n[414] K.-C.\
    \ Liu, C.-Y. Hsieh, S. J.-P. Hsu, and C.-T. Chan, “Impact of sampling\nrate on\
    \ wearable-based fall detection systems based on machine learning\nmodels,” IEEE\
    \ Sensors Journal 18, 9882–9890 (2018).\n[415] J. Xu, Z. He, and Y. Zhang, “Cnn-lstm\
    \ combined network for iot enabled\nfall detection applications,” in “Journal\
    \ of Physics: Conference Series,” ,\nvol. 1267 (IOP Publishing, 2019), vol. 1267,\
    \ p. 012044.\n[416] D. Mrozek, A. Koczur, and B. Ma lysiak-Mrozek, “Fall detection\
    \ in older\nadults with mobile iot devices and machine learning in the cloud and\
    \ on\nthe edge,” Information Sciences (2020).\n166\n[417] A. Sucerquia, J. D.\
    \ L´opez, and J. F. Vargas-Bonilla, “Sisfall: A fall and\nmovement dataset,” Sensors\
    \ 17, 198 (2017).\n[418] L. M´arquez-Ordaz and H. Ponce, “Implementation of a\
    \ svm on an embed-\nded system: A case study on fall detection,” in “Mexican International\n\
    Conference on Artificial Intelligence,” (Springer, 2020), pp. 76–87.\n[419] D.\
    \ Sarabia-J´acome, R. Usach, C. Palau, and M. Esteve, “Highly-efficient\nfog-based\
    \ deep learning aal fall detection system,” Internet of Things p.\n100185 (2020).\n\
    [420] N. Zurbuchen, P. Bruegger, and A. Wilde, “A comparison of machine\nlearning\
    \ algorithms for fall detection using wearable sensors,” in “2020 In-\nternational\
    \ Conference on Artificial Intelligence in Information and Com-\nmunication (ICAIIC),”\
    \ (IEEE, 2020), pp. 427–431.\n[421] A. Chelli and M. P¨atzold, “A machine learning\
    \ approach for fall detec-\ntion and daily living activity recognition,” IEEE\
    \ Access 7, 38670–38687\n(2019).\n[422] O. Ojetola, E. Gaura, and J. Brusey, “Data\
    \ set for fall events and daily\nactivities from inertial sensors,” in “Proceedings\
    \ of the 6th ACM multi-\nmedia systems conference,” (2015), pp. 243–248.\n[423]\
    \ D. Anguita, A. Ghio, L. Oneto, X. Parra, and J. L. Reyes-Ortiz, “A public\n\
    domain dataset for human activity recognition using smartphones.” in\n“Esann,”\
    \ , vol. 3 (2013), vol. 3, p. 3.\n[424] O. Kerdjidj, N. Ramzan, K. Ghanem, A.\
    \ Amira, and F. Chouireb, “Fall\ndetection and human activity classification using\
    \ wearable sensors and\ncompressed sensing,” Journal of Ambient Intelligence and\
    \ Humanized\nComputing 11, 349–361 (2020).\n[425] A. Burns, B. R. Greene, M. J.\
    \ McGrath, T. J. O’Shea, B. Kuris, S. M.\nAyer, F. Stroiescu, and V. Cionca, “Shimmer™–a\
    \ wireless sensor platform\nfor noninvasive biomedical research,” IEEE Sensors\
    \ Journal 10, 1527–\n1534 (2010).\n[426] M. Fa˜nez, J. R. Villar, E. de la Cal,\
    \ J. Sedano, and V. M. Gonz´alez,\n“Transfer learning and information retrieval\
    \ applied to fall detection,”\nExpert Systems 37, e12522 (2020).\n[427] E. Casilari,\
    \ J. A. Santoyo-Ram´on, and J. M. Cano-Garc´ıa, “Analysis of\na smartphone-based\
    \ architecture with multiple mobility sensors for fall\ndetection,” PLoS one 11,\
    \ e0168069 (2016).\n[428] J. Lin, E. Keogh, S. Lonardi, and B. Chiu, “A symbolic\
    \ representation of\ntime series, with implications for streaming algorithms,”\
    \ in “Proceedings\nof the 8th ACM SIGMOD workshop on Research issues in data mining\n\
    and knowledge discovery,” (2003), pp. 2–11.\n167\n[429] D. Giuffrida, G. Benetti,\
    \ D. D. Martini, and T. Facchinetti, “Fall detec-\ntion with supervised machine\
    \ learning using wearable sensors,” in “2019\nIEEE 17th International Conference\
    \ on Industrial Informatics (INDIN),”\n, vol. 1 (IEEE, 2019), vol. 1, pp. 253–259.\n\
    [430] E. Casilari, M. ´Alvarez-Marco, and F. Garc´ıa-Lagos, “A study of the use\n\
    of gyroscope measurements in wearable fall detection systems,” Symmetry\n12, 649\
    \ (2020).\n[431] G. L. Santos, P. T. Endo, K. H. d. C. Monteiro, E. d. S. Rocha,\
    \ I. Silva,\nand T. Lynn, “Accelerometer-based human fall detection using convolu-\n\
    tional neural networks,” Sensors 19, 1644 (2019).\n[432] B. Kwolek and M. Kepski,\
    \ “Human fall detection on embedded platform\nusing depth maps and wireless accelerometer,”\
    \ Computer methods and\nprograms in biomedicine 117, 489–501 (2014).\n[433] T.\
    \ R. Mauldin, M. E. Canby, V. Metsis, A. H. Ngu, and C. C. Rivera,\n“Smartfall:\
    \ A smartwatch-based fall detection system using deep learn-\ning,” Sensors 18,\
    \ 3363 (2018).\n[434] K. Simonyan and A. Zisserman, “Very deep convolutional networks\
    \ for\nlarge-scale image recognition,” arXiv preprint arXiv:1409.1556 (2014).\n\
    [435] A. Alarifi and A. Alwadain, “Killer heuristic optimized convolution neural\n\
    network-based fall detection with wearable iot sensor devices,” Measure-\nment\
    \ 167, 108258 (2021).\n[436] M. Waheed, H. Afzal, and K. Mehmood, “Nt-fds—a noise\
    \ tolerant fall\ndetection system using deep learning on wearable devices,” Sensors\
    \ 21,\n2006 (2021).\n[437] L. Mart´ınez-Villase˜nor, H. Ponce, J. Brieva, E. Moya-Albor,\
    \ J. N´u˜nez-\nMart´ınez, and C. Pe˜nafort-Asturiano, “Up-fall detection dataset:\
    \ A mul-\ntimodal approach,” Sensors 19, 1988 (2019).\n[438] E. Casilari, R. Lora-Rivera,\
    \ and F. Garc´ıa-Lagos, “A study on the appli-\ncation of convolutional neural\
    \ networks to fall detection evaluated with\nmultiple public datasets,” Sensors\
    \ 20, 1466 (2020).\n[439] R. Delgado-Escano, F. M. Castro, J. R. C´ozar, M. J.\
    \ Mar´ın-Jim´enez,\nN. Guil, and E. Casilari, “A cross-dataset deep learning-based\
    \ classifier\nfor people fall detection and identification,” Computer methods\
    \ and pro-\ngrams in biomedicine 184, 105265 (2020).\n[440] C. Medrano, R. Igual,\
    \ I. Plaza, and M. Castro, “Detecting falls as novelties\nin acceleration patterns\
    \ acquired with smartphones,” PloS one 9, e94811\n(2014).\n[441] D. Micucci, M.\
    \ Mobilio, and P. Napoletano, “Unimib shar: A dataset for\nhuman activity recognition\
    \ using acceleration data from smartphones,”\nApplied Sciences 7, 1101 (2017).\n\
    168\n[442] A. T. ¨Ozdemir, “An analysis on sensor locations of the human body\
    \ for\nwearable fall detection devices: Principles and practice,” Sensors 16,\
    \ 1161\n(2016).\n[443] M. Tolkiehn, L. Atallah, B. Lo, and G.-Z. Yang, “Direction\
    \ sensitive\nfall detection using a triaxial accelerometer and a barometric pressure\n\
    sensor,” in “2011 Annual international conference of the IEEE engineering\nin\
    \ medicine and biology society,” (IEEE, 2011), pp. 369–372.\n[444] B. Watanapa,\
    \ O. Patsadu, P. Dajpratham, and C. Nukoolkit, “Post-fall\nintelligence supporting\
    \ fall severity diagnosis using kinect sensor,” Ap-\nplied Computational Intelligence\
    \ and Soft Computing 2018 (2018).\n[445] H. Jung, B. Koo, J. Kim, T. Kim, Y. Nam,\
    \ and Y. Kim, “Enhanced\nalgorithm for the detection of preimpact fall for wearable\
    \ airbags,” Sensors\n20, 1277 (2020).\n[446] B. Koo, J. Kim, Y. Nam, and Y. Kim,\
    \ “The performance of post-fall de-\ntection using the cross-dataset: Feature\
    \ vectors, classifiers and processing\nconditions,” Sensors 21, 4638 (2021).\n\
    [447] C.-Y. Hsieh, H.-Y. Huang, K.-C. Liu, C.-P. Liu, C.-T. Chan, and S. J.-P.\n\
    Hsu, “Multiphase identification algorithm for fall recording systems using\na\
    \ single wearable inertial sensor,” Sensors 21, 3302 (2021).\n[448] M. Musci,\
    \ D. De Martini, N. Blago, T. Facchinetti, and M. Piastra,\n“Online fall detection\
    \ using recurrent neural networks,” arXiv preprint\narXiv:1804.04976 (2018).\n\
    [449] X. Yu, H. Qiu, and S. Xiong, “A novel hybrid deep neural network to pre-\n\
    dict pre-impact fall for older people based on wearable inertial sensors,”\nFrontiers\
    \ in bioengineering and biotechnology 8 (2020).\n[450] W. Lee, T. S. Song, and\
    \ J.-H. Youn, “Detection of fall direction using\na velocity vector in the android\
    \ smartphone environment,” Journal of\nthe Korea Institute of Information and\
    \ Communication Engineering 19,\n336–342 (2015).\n[451] W. Lee, T. S. Song, and\
    \ J.-H. Youn, “Fall direction detection using the\ncomponents of acceleration\
    \ vector and orientation sensor on the smart-\nphone environment,” Journal of\
    \ Korea Multimedia Society 18, 565–574\n(2015).\n[452] J. K. Lee, “Determination\
    \ of fall direction before impact using support\nvector machine,” Journal of Sensor\
    \ Science and Technology 24, 47–53\n(2015).\n[453] S. F. Hossain, M. Z. Islam,\
    \ and M. L. Ali, “Real time direction-sensitive\nfall detection system using accelerometer\
    \ and learning classifier,” in\n“2017 4th International Conference on Advances\
    \ in Electrical Engineering\n(ICAEE),” (IEEE, 2017), pp. 99–104.\n169\n[454] F.\
    \ Hossain, M. L. Ali, M. Z. Islam, and H. Mustafa, “A direction-sensitive\nfall\
    \ detection system using single 3d accelerometer and learning classifier,”\nin\
    \ “2016 International Conference on Medical Engineering, Health Infor-\nmatics\
    \ and Technology (MediTec),” (IEEE, 2016), pp. 1–6.\n[455] L. Palmerini, J. Klenk,\
    \ C. Becker, and L. Chiari, “Accelerometer-based\nfall detection using machine\
    \ learning: Training and testing on real-world\nfalls,” Sensors 20, 6479 (2020).\n\
    [456] R. M. Gibson, A. Amira, N. Ramzan, P. C. de-la Higuera, and Z. Pervez,\n\
    “Multiple comparator classifier framework for accelerometer-based fall de-\ntection\
    \ and diagnostic,” Applied Soft Computing 39, 94–103 (2016).\n[457] F. Hussain,\
    \ F. Hussain, M. Ehatisham-ul Haq, and M. A. Azam,\n“Activity-aware fall detection\
    \ and recognition based on wearable sensors,”\nIEEE Sensors Journal 19, 4528–4536\
    \ (2019).\n[458] H. Li, A. Shrestha, H. Heidari, J. Le Kernec, and F. Fioranelli,\
    \ “Bi-lstm\nnetwork for multimodal continuous human activity recognition and fall\n\
    detection,” IEEE Sensors Journal 20, 1191–1201 (2019).\n[459] X. Wu, Y. Zheng,\
    \ C.-H. Chu, L. Cheng, and J. Kim, “Applying deep\nlearning technology for automatic\
    \ fall detection using mobile sensors,”\nBiomedical Signal Processing and Control\
    \ 72, 103355 (2022).\n[460] G. Vavoulas, C. Chatzaki, T. Malliotakis, M. Pediaditis,\
    \ and M. Tsik-\nnakis, “The mobiact dataset: Recognition of activities of daily\
    \ living using\nsmartphones.” in “ICT4AgeingWell,” (2016), pp. 143–151.\n[461]\
    \ G.\nS¸eng¨ul,\nM.\nKarakaya,\nS.\nMisra,\nO.\nO.\nAbayomi-Alli,\nand\nR. Damaˇseviˇcius,\
    \ “Deep learning based fall detection using smartwatches\nfor healthcare applications,”\
    \ Biomedical Signal Processing and Control\n71, 103242 (2022).\n[462] H.-L. Le,\
    \ D.-N. Nguyen, T.-H. Nguyen, and H.-N. Nguyen, “A novel fea-\nture set extraction\
    \ based on accelerometer sensor data for improving the\nfall detection system,”\
    \ Electronics 11, 1030 (2022).\n[463] H. Yhdego, J. Li, C. Paolini, and M. Audette,\
    \ “Wearable sensor gait\nanalysis of fall detection using attention network,”\
    \ in “2021 IEEE Inter-\nnational Conference on Bioinformatics and Biomedicine\
    \ (BIBM),” (IEEE,\n2021), pp. 3137–3141.\n[464] M. Liu, S. Ren, S. Ma, J. Jiao,\
    \ Y. Chen, Z. Wang, and W. Song, “Gated\ntransformer networks for multivariate\
    \ time series classification,” arXiv\npreprint arXiv:2103.14438 (2021).\n[465]\
    \ X. Yu, J. Jang, and S. Xiong, “A large-scale open motion dataset (kfall)\nand\
    \ benchmark algorithms for detecting pre-impact fall of the elderly\nusing wearable\
    \ inertial sensors,” Frontiers in Aging Neuroscience p. 399\n(2021).\n170\n[466]\
    \ J. A. Santoyo-Ram´on, E. Casilari, and J. M. Cano-Garc´ıa, “A study of\none-class\
    \ classification algorithms for wearable fall sensors,” Biosensors\n11 (2021).\n\
    [467] N. Zurbuchen, A. Wilde, and P. Bruegger, “A machine learning multi-\nclass\
    \ approach for fall detection systems based on wearable sensors with\na study\
    \ on sampling rates selection,” Sensors 21, 938 (2021).\n[468] M. Musci, D. De\
    \ Martini, N. Blago, T. Facchinetti, and M. Piastra, “On-\nline fall detection\
    \ using recurrent neural networks on smart wearable de-\nvices,” IEEE Transactions\
    \ on Emerging Topics in Computing 9, 1276–\n1289 (2020).\n[469] E. Boutellaa,\
    \ K. Ghanem, H. Tayakout, O. Kerdjidj, F. Harizi, and\nS. Bourennane, “A tensor\
    \ approach for activity recognition and fall de-\ntection using wearable inertial\
    \ sensors,” in “2020 First International Con-\nference of Smart Systems and Emerging\
    \ Technologies (SMARTTECH),”\n(IEEE, 2020), pp. 203–207.\n[470] S. Rosati, G.\
    \ Balestra, and M. Knaflitz, “Comparison of different sets of\nfeatures for human\
    \ activity recognition by wearable sensors,” Sensors 18,\n4189 (2018).\n[471]\
    \ J. O. Smith, Mathematics of the discrete Fourier transform (DFT): with\naudio\
    \ applications (Julius Smith, 2007).\n[472] M. A. O’Reilly, W. Johnston, C. Buckley,\
    \ D. Whelan, and B. Caulfield,\n“The influence of feature selection methods on\
    \ exercise classification with\ninertial measurement units,” in “2017 IEEE 14th\
    \ International Conference\non Wearable and Implantable Body Sensor Networks (BSN),”\
    \ (IEEE,\n2017), pp. 193–196.\n[473] A. Liaw, M. Wiener et al., “Classification\
    \ and regression by randomfor-\nest,” R news 2, 18–22 (2002).\n[474] O. Rioul\
    \ and M. Vetterli, “Wavelets and signal processing,” IEEE signal\nprocessing magazine\
    \ 8, 14–38 (1991).\n[475] M. G. Abdu-Aguye and W. Gomaa, “Competitive feature\
    \ extraction for\nactivity recognition based on wavelet transforms and adaptive\
    \ pooling,”\nin “2019 International Joint Conference on Neural Networks (IJCNN),”\n\
    (IEEE, 2019), pp. 1–8.\n[476] ¨U. Lepik and H. Hein, “Haar wavelets,” in “Haar\
    \ Wavelets,” (Springer,\n2014), pp. 7–20.\n[477] K. He, X. Zhang, S. Ren, and\
    \ J. Sun, “Spatial pyramid pooling in deep\nconvolutional networks for visual\
    \ recognition,” IEEE transactions on pat-\ntern analysis and machine intelligence\
    \ 37, 1904–1916 (2015).\n171\n[478] C. N. Silla and A. A. Freitas, “A survey of\
    \ hierarchical classification across\ndifferent application domains,” Data Mining\
    \ and Knowledge Discovery\n22, 31–72 (2011).\n[479] S. B. Khojasteh, J. R. Villar,\
    \ C. Chira, V. M. Gonz´alez, and E. De la\nCal, “Improving fall detection using\
    \ an on-wrist wearable accelerometer,”\nSensors 18, 1350 (2018).\n[480] Q. T.\
    \ Huynh and B. Q. Tran, “Time-frequency analysis of daily activities\nfor fall\
    \ detection,” Signals 2, 1–12 (2021).\n[481] J. Wang, X. Zhang, Q. Gao, X. Ma,\
    \ X. Feng, and H. Wang, “Device-free si-\nmultaneous wireless localization and\
    \ activity recognition with wavelet fea-\nture,” IEEE Transactions on Vehicular\
    \ Technology 66, 1659–1669 (2016).\n[482] C. Ellouzi and M. Trkov, “Fast trip\
    \ detection using continuous wavelet\ntransform,” in “Proceedings of the Poster,\
    \ Dynamic Walking Conference,”\n(2021).\n[483] J. Gu, Z. Wang, J. Kuen, L. Ma,\
    \ A. Shahroudy, B. Shuai, T. Liu, X. Wang,\nG. Wang, J. Cai et al., “Recent advances\
    \ in convolutional neural net-\nworks,” Pattern Recognition 77, 354–377 (2018).\n\
    [484] D. Bhatt, C. Patel, H. Talsania, J. Patel, R. Vaghela, S. Pandya, K. Modi,\n\
    and H. Ghayvat, “Cnn variants for computer vision: History, architecture,\napplication,\
    \ challenges and future scope,” Electronics 10, 2470 (2021).\n[485] S. P. Singh,\
    \ L. Wang, S. Gupta, H. Goli, P. Padmanabhan, and B. Guly´as,\n“3d deep learning\
    \ on medical images: a review,” Sensors 20, 5097 (2020).\n[486] S. Latif, R. Rana,\
    \ S. Khalifa, R. Jurdak, J. Qadir, and B. W. Schuller,\n“Survey of deep representation\
    \ learning for speech emotion recognition,”\nIEEE Transactions on Affective Computing\
    \ (2021).\n[487] F. G. Pratic`o, R. Fedele, V. Naumov, and T. Sauer, “Detection\
    \ and mon-\nitoring of bottom-up cracks in road pavement using a machine-learning\n\
    approach,” Algorithms 13, 81 (2020).\n[488] K. Saho, S. Hayashi, M. Tsuyama, L.\
    \ Meng, and M. Masugi, “Machine\nlearning-based classification of human behaviors\
    \ and falls in restroom via\ndual doppler radar measurements,” Sensors 22, 1721\
    \ (2022).\n[489] J. Kakarla, B. V. Isunuri, K. S. Doppalapudi, and K. S. R. Byla-\n\
    pudi, “Three-class classification of brain magnetic resonance images using\naverage-pooling\
    \ convolutional neural network,” International Journal of\nImaging Systems and\
    \ Technology 31, 1731–1740 (2021).\n[490] J. Yang, F. Xie, H. Fan, Z. Jiang, and\
    \ J. Liu, “Classification for der-\nmoscopy images using convolutional neural\
    \ networks based on region av-\nerage pooling,” IEEE Access 6, 65130–65138 (2018).\n\
    172\n[491] M. H. Mohd Noor, S. Y. Tan, and M. N. Ab Wahab, “Deep temporal\nconv-lstm\
    \ for activity recognition,” Neural Processing Letters pp. 1–23\n(2022).\n[492]\
    \ M. I. Amara, A. Akkouche, E. Boutellaa, and H. Tayakout, “A smart-\nphone application\
    \ for fall detection using accelerometer and convlstm\nnetwork,” in “2020 2nd\
    \ International Workshop on Human-Centric Smart\nEnvironments for Health and Well-being\
    \ (IHSH),” (IEEE, 2021), pp. 92–\n96.\n[493] J. Du, Z. Zhang, M. Li, J. Guo, and\
    \ K. Zhu, “Optimal scheduling of\nintegrated energy system based on improved grey\
    \ wolf optimization algo-\nrithm,” Scientific Reports 12, 1–19 (2022).\n[494]\
    \ N. Mazyavkina, S. Sviridov, S. Ivanov, and E. Burnaev, “Reinforcement\nlearning\
    \ for combinatorial optimization: A survey,” Computers & Oper-\nations Research\
    \ 134, 105400 (2021).\n173\nAppendix A: Sample Plots for different fall categories\n\
    Sample plots of the windowed accelerometer and gyroscope measurements of\ndifferent\
    \ fall types.\n0\n100\n200\n300\n400\n500\n600\nSample no\n2000\n1500\n1000\n\
    500\n0\nAmplitude\nAcc X\n0\n100\n200\n300\n400\n500\n600\nSample no\n-10,000\n\
    -8000\n-6000\n-4000\n-2000\n0\n2000\nAmplitude\nGyro X\n0\n100\n200\n300\n400\n\
    500\n600\nSample no\n600\n400\n200\n0\n200\n400\n600\nAmplitude\nAcc Y\n0\n100\n\
    200\n300\n400\n500\n600\nSample no\n-10,000\n-8000\n-6000\n-4000\n-2000\n0\n2000\n\
    Amplitude\nGyro Y\n0\n100\n200\n300\n400\n500\n600\nSample no\n1200\n1000\n800\n\
    600\n400\n200\n0\n200\n400\nAmplitude\nAcc Z\n0\n100\n200\n300\n400\n500\n600\n\
    Sample no\n2000\n0\n2000\n4000\n6000\n8000\nAmplitude\nGyro Z\nForward Hard Fall\n\
    Figure 1. Accelerometer and Gyroscope measurements: Forward Hard Fall\n174\n0\n\
    100\n200\n300\n400\n500\n600\nSample no\n1000\n800\n600\n400\n200\n0\nAmplitude\n\
    Acc X\n0\n100\n200\n300\n400\n500\n600\nSample no\n2000\n1500\n1000\n500\n0\n\
    500\n1000\n1500\nAmplitude\nGyro X\n0\n100\n200\n300\n400\n500\n600\nSample no\n\
    200\n100\n0\n100\n200\nAmplitude\nAcc Y\n0\n100\n200\n300\n400\n500\n600\nSample\
    \ no\n4000\n3000\n2000\n1000\n0\n1000\n2000\nAmplitude\nGyro Y\n0\n100\n200\n\
    300\n400\n500\n600\nSample no\n400\n300\n200\n100\n0\nAmplitude\nAcc Z\n0\n100\n\
    200\n300\n400\n500\n600\nSample no\n1000\n0\n1000\n2000\n3000\n4000\nAmplitude\n\
    Gyro Z\nForward Soft Fall\nFigure 2. Accelerometer and Gyroscope measurements:\
    \ Forward Soft Fall\n175\n0\n100\n200\n300\n400\n500\n600\nSample no\n800\n600\n\
    400\n200\n0\n200\n400\nAmplitude\nAcc X\n0\n100\n200\n300\n400\n500\n600\nSample\
    \ no\n2000\n0\n2000\n4000\n6000\nAmplitude\nGyro X\n0\n100\n200\n300\n400\n500\n\
    600\nSample no\n2000\n1500\n1000\n500\n0\n500\nAmplitude\nAcc Y\n0\n100\n200\n\
    300\n400\n500\n600\nSample no\n3000\n2000\n1000\n0\n1000\n2000\nAmplitude\nGyro\
    \ Y\n0\n100\n200\n300\n400\n500\n600\nSample no\n200\n0\n200\n400\n600\n800\n\
    Amplitude\nAcc Z\n0\n100\n200\n300\n400\n500\n600\nSample no\n1000\n500\n0\n500\n\
    1000\n1500\nAmplitude\nGyro Z\nBackward Hard Fall\nFigure 3. Accelerometer and\
    \ Gyroscope measurements: Backward Hard Fall\n176\n0\n100\n200\n300\n400\n500\n\
    600\nSample no\n600\n500\n400\n300\n200\n100\n0\n100\nAmplitude\nAcc X\n0\n100\n\
    200\n300\n400\n500\n600\nSample no\n1000\n0\n1000\n2000\n3000\n4000\nAmplitude\n\
    Gyro X\n0\n100\n200\n300\n400\n500\n600\nSample no\n1000\n800\n600\n400\n200\n\
    0\n200\nAmplitude\nAcc Y\n0\n100\n200\n300\n400\n500\n600\nSample no\n800\n600\n\
    400\n200\n0\n200\n400\n600\nAmplitude\nGyro Y\n0\n100\n200\n300\n400\n500\n600\n\
    Sample no\n300\n200\n100\n0\n100\n200\nAmplitude\nAcc Z\n0\n100\n200\n300\n400\n\
    500\n600\nSample no\n600\n400\n200\n0\n200\n400\n600\n800\n1000\nAmplitude\nGyro\
    \ Z\nBackward Soft Fall\nFigure 4. Accelerometer and Gyroscope measurements:f\
    \ Backward Soft Fall\n177\n0\n100\n200\n300\n400\n500\n600\nSample no\n1750\n\
    1500\n1250\n1000\n750\n500\n250\n0\n250\nAmplitude\nAcc X\n0\n100\n200\n300\n\
    400\n500\n600\nSample no\n6000\n4000\n2000\n0\n2000\nAmplitude\nGyro X\n0\n100\n\
    200\n300\n400\n500\n600\nSample no\n600\n400\n200\n0\n200\nAmplitude\nAcc Y\n\
    0\n100\n200\n300\n400\n500\n600\nSample no\n2000\n1500\n1000\n500\n0\n500\n1000\n\
    Amplitude\nGyro Y\n0\n100\n200\n300\n400\n500\n600\nSample no\n250\n200\n150\n\
    100\n50\n0\n50\nAmplitude\nAcc Z\n0\n100\n200\n300\n400\n500\n600\nSample no\n\
    1000\n0\n1000\n2000\n3000\n4000\n5000\n6000\n7000\nAmplitude\nGyro Z\nLateral\
    \ Hard Fall\nFigure 5. Accelerometer and Gyroscope measurements: Lateral Hard\
    \ Fall\n178\n0\n100\n200\n300\n400\n500\n600\nSample no\n700\n600\n500\n400\n\
    300\n200\n100\n0\n100\nAmplitude\nAcc X\n0\n100\n200\n300\n400\n500\n600\nSample\
    \ no\n500\n0\n500\n1000\n1500\n2000\n2500\n3000\nAmplitude\nGyro X\n0\n100\n200\n\
    300\n400\n500\n600\nSample no\n600\n400\n200\n0\n200\nAmplitude\nAcc Y\n0\n100\n\
    200\n300\n400\n500\n600\nSample no\n2000\n1500\n1000\n500\n0\n500\n1000\n1500\n\
    Amplitude\nGyro Y\n0\n100\n200\n300\n400\n500\n600\nSample no\n150\n100\n50\n\
    0\n50\n100\n150\n200\n250\nAmplitude\nAcc Z\n0\n100\n200\n300\n400\n500\n600\n\
    Sample no\n1000\n500\n0\n500\n1000\n1500\n2000\n2500\n3000\nAmplitude\nGyro Z\n\
    Lateral Soft Fall \nFigure 6. Acclerometer and Gyroscope measurements: Lateral\
    \ Soft Fall\n179\nAppendix B: Acronyms\nABC - Artificial Bee Colony\nACO - Ant\
    \ Colony Optimization\nAdaBoost - Adaptive Boosting\nADL - Activity of Daily Living\n\
    AI - Artificial intelligence\nANN - Artificial Neural Networks\nBi-LSTM - Bi-Directional\
    \ Long Short-Term Memory\nCERT - Computer Emergency Response Team\nCNN - Convolutional\
    \ Neural Networks\nCO - Carbon Monoxide\nCO2 - Carbon Dioxide\nDARPA - Defense\
    \ Advanced Research Projects Agency\nDDOS - Distributed Denial of Service\nDE\
    \ - Differential Evolution\nDER - Distributed energy resource\nDOS - Denial of\
    \ Service\nDL – Deep Learning\nDLEFN - Deep Learning Entrusted to Fog Nodes\n\
    DNN - Deep Neural Networks\nDT - Decision Tree\nEBT - Ensemble Bagged Tree\nEC\
    \ - Ensemble Classifier\nECG - ElectroCardioGram\nEEG - ElectroEncepheloGram\n\
    EMG – ElectroMyoGram\nETSI - European Telecommunications Standards Institute\n\
    FANs - Field Area Networks\nFDS - Fall Detection System\nFN - False Negative\n\
    GA - Genetic Algorithm\nGRU - Gated Recurrent Units\nGSM - Global System for Mobile\
    \ Communications\nHANs - Home Area Networks\nICT - information and communication\
    \ technologies\nIEEE - Institute of Electrical and Electronic Engineers\nIETF\
    \ - Internet Engineering Task Force\nIQ Range - Interquartile Range\nIMU – Inertial\
    \ Measurement Unit\n180\nIoT - Internet of Things\nISM - Industrial, Scientific\
    \ and Medical\nK-NN - K-Nearest Neighbor\nLDA - Linear Discriminant Analysis\n\
    Li-Fi - Light Fidelity\nLoRaWAN - Long Range Wide Area Network\nLPWAN - Low Power\
    \ Wide Area Network\nLR - Logistic Regression\nLSDVRP - Large-scale Dynamic Vehicle\
    \ Routing Problem\nLSTM - Long Short-Term Machine\nLTE - Long-Term Evolution\n\
    MITM - Man in the Middle\nML - Machine Learning\nMVRP - Multidepot Vehicle Routing\
    \ Problem\nNANs - Neighborhood Area Networks\nNB - Naive Bayes\nNB-IoT - Narrow\
    \ Band IoT\nNFC - Near Field Communication\nOSP - Optimal Sensor Placement\nPCA\
    \ - Principal Component Analysis\nPIR - Passive InfraRed\nPMU - Phase Measurement\
    \ Units\nPSD - Power Spectral Density\nPSE - Power Spectral Entropy\nPSO - Particle\
    \ Swarm Optimization\nPPCA - Probabilistic Principal Component Analysis\nPV -\
    \ photo voltaic\nP2I - Pedestrian to Infrastructure\nQSVM - Quadratic Support\
    \ Vector Machine\nRBF - Radial Basis Function\nRF – Radio Frequency\nRFC - Random\
    \ Forest Classifier\nRFID - Radio Frequency Identification\nRF-RFE - Random Forest\
    \ Recursive Feature Elimination\nRMS - Root Mean Squared\nRNN - Recurrent Neural\
    \ Networks\nSAE - Stacked Autoencoder Networks\nSAX - Symbolic Aggregate Approximation\n\
    SHM - Structural Health Monitoring\nSMV - Signal Magnitude Vector\nSWOT - Strength\
    \ Weaknesses Opportunities Threat\nSVM - Support Vector Machine\nTLS - Transport\
    \ Layer Security\nTP - True Positive\nVANET - Vehicular Adhoc NETworks\n181\n\
    VM - Voting machine\nVRP - Vehicle Routing Problem\nVRPPDTW - Vehicle Routing\
    \ Problem Pick-up and Delivery with Time Win-\ndows\nV2V - Vehicle to Vehicle\n\
    V2I - Vehicle to Infrastructure\nV2P - Vehicle to Pedestrian\nWANs - Wide Area\
    \ Networks\nWi-Fi - Wireless Fidelity\nWi-SUN - Wireless Smart Utility Network\n\
    WPA2 - Wi-Fi Protected Access 2\nWSNs - wireless sensor networks\nXGBoost - Extreme\
    \ Gradient Boost\nZ-Wave - Zensys Wave\n182\nCURRICULUM VITA\nNAME:\nMuhammmad\
    \ Zaigham Abbas Shah Syed\nADDRESS:\nComputer Science and Engineering Department\n\
    J.B Speed School of Engineering\nUniversity of Louisville\nLouisville, KY 40292\n\
    United States of America.\n2022\nUniversity of Louisville, Louisville, KY, USA.\n\
    M.Sc. in Electronic and Electrical Engineering, Novem-\nber 2013\nUniversity of\
    \ Strathclyde, Glasgow, United King-\ndom\nB.Eng in Electronics Engineering, March\
    \ 2010\nMehran University of Engineering and Technol-\nogy, Jamshoro, Pakistan\n\
    WORK\nEX-\nPERIENCE:\nGraduate Assistant, Innovative Technologies Lab,\nUniversity\
    \ of Louisville, KY, USA, 2022\n183\nPh.D., Computer Science & Engineering, December\n\
    EDUCATION:\nPUBLICATIONS:\nJOURNAL\n1. Abbas Shah Syed, Daniel Sierra-Sosa, Anup\
    \ Kumar, and Adel Elmaghraby.\nIoT in smart cities: a survey of technologies,\
    \ practices and challenges. Smart Cities,\nvol. 4, no. 2, pp. 429–475, 2021\n\
    2. Abbas Shah Syed, Daniel Sierra-Sosa, Anup Kumar, and Adel Elmaghraby.\nMaking\
    \ Cities Smarter—Optimization Problems for the IoT Enabled Smart City\nDevelopment:\
    \ A Mapping of Applications, Objectives, Constraints.Sensors, vol. 22,\nno. 12,\
    \ p. 4380, 2022\n3. Abbas Shah Syed, Daniel Sierra-Sosa, Anup Kumar, and Adel\
    \ Elmaghraby. A\nhierarchical approach to activity recognition and fall detection\
    \ using wavelets and\nadaptive pooling.Sensors, vol. 21, no. 19, p. 6653, 2021\n\
    4. Abbas Shah Syed, Daniel Sierra-Sosa, Anup Kumar, and Adel Elmaghraby. A\ndeep\
    \ convolutional neural network-XGB for direction and severity aware fall detec-\n\
    tion and activity recognition.Sensors, vol. 22, no. 7, p. 2547, 2022\nCONFERENCE\n\
    1. Abbas Shah Syed, Daniel Sierra-Sosa, Anup Kumar, and Adel Elmaghraby.\nCross\
    \ dataset non-binary fall detection using a ConvLSTM-attention network. (ac-\n\
    cepted at IEEE GlobeCOM 2022).\n2. Abbas Shah Syed, Daniel Sierra-Sosa, Anup Kumar,\
    \ and Adel Elmaghraby.\nDetermining Fall direction and severity using SVMs.2020\
    \ IEEE International Sym-\nposium on Signal Processing and Information Technology\
    \ (ISSPIT),2020, pp. 1–7.\n184\n"
  inline_citation: '>'
  journal: ''
  limitations: '>'
  pdf_link: https://ir.library.louisville.edu/cgi/viewcontent.cgi?article=5278&context=etd
  publication_year: 2023
  relevance_score1: 0
  relevance_score2: 0
  title: IoT in smart communities, technologies and applications.
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.31428/10317/10416
  analysis: '>'
  authors:
  - Marouane Salhaoui
  citation_count: 0
  full_citation: '>'
  full_text: ">\n \n  \n \nvrbvnjnnbbttbbtbt  \n\"SMART IOT MONITORING AND REAL-TIME\
    \ CONTROL \nBASED ON AUTONOMOUS ROBOTS, VISUAL \nRECOGNITION AND CLOUD/EDGE COMPUTING\
    \ \nSERVICES\" \n \nPrograma de Doctorado: ENERGÍAS RENOVABLES Y \nEFICIENCIA\
    \ ENERGÉTICA \n \n \n \n \nAutor: Marouane Salhaoui \n \nCartagena (2021) \n \n\
    i \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots,\
    \ Visual Recognition and Cloud/Edge \nComputing Services \n \n \n \n \n \n \n\
    \ \n \n \nABDELMALEK ESSAADI UNIVERSITY \nFACULTY OF SCIENCE AND TECHNIQUES \n\
    TANGER / MOROCCO \n \nPOLYTECHNIC UNIVERSITY OF CARTAGENA \nUPCT / SPAIN \n \n\
    \ \nDOCTORAL THESIS (Year 2021) \n \nPresented By: \n \nMAROUANE SALHAOUI \n \n\
    Directors:  \n \nAntonio Guerrero-González, Mounir Arioua  \n \nCo-Directors:\
    \ \n \nFrancisco J. Ortiz, Ahmed El Oualkadi \n \nThesis Title: \n \n\"SMART IOT\
    \ MONITORING AND REAL-TIME CONTROL \nBASED ON AUTONOMOUS ROBOTS, VISUAL RECOGNITION\
    \ \nAND CLOUD/EDGE COMPUTING SERVICES\" \n \n \nAccredited research institution:\
    \ \n \n• Laboratoire des Technologies de l’Information et de la Communication\
    \ de ENSA de \nTanger (Morocco) \n• Departamento de Automática, Ingeniería Eléctrica\
    \ y Tecnología Electrónica, UPCT \nCartagena (Spain) \n \nii \n \nSmart IoT Monitoring\
    \ and Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \n \n \nAbstract \n \nIn the fourth industrial revolution\
    \ in which we are immersed, new \ntechnologies are being introduced in production\
    \ processes, such as the use of \nUnmanned Vehicles (UVs) data collection in large\
    \ surfaces, and the use of the \nIndustrial Internet of Things (IIoT). The main\
    \ keys to integrate this new \ntechnology in the industry is to face the challenge\
    \ of making the IT network \ncompatible with its machines, including interoperability,\
    \ fog and cloud \ncomputing, security, decreasing latency and improving data accuracy\
    \ and \nquality of service. \nSmart industrial platforms require multiple synchronized\
    \ processes that \nrequire low latency and higher reliability to achieve the necessary\
    \ performance. \nIn addition, Artificial Intelligence (AI) methods applied to\
    \ IIoT must be able to \naddress these issues as well as other parameters such\
    \ as network deployment \nand resource management. \nThe issues of high-latency\
    \ and unreliable links between the cloud and \nIndustrial IoT endpoints are significant\
    \ challenges. Each fog and edge application \nmay have different latency requirements\
    \ and may generate different types of \ndata and network traffic.  Such generated\
    \ data can be photos received from an \nUV system. The latter can be connected\
    \ to other control system, being used both \nto perform enhancements and to make\
    \ decisions based on the captured photos. \nThis type of connection is sensitive\
    \ in terms of accuracy and latency, as the whole \nplatform must decide quickly\
    \ and with certainty. \nOne of the solutions to overcome the latency challenge\
    \ is the fog/edge \narchitecture. This architecture can also be a viable solution\
    \ regarding the \ninteroperability barrier between interconnected systems. Fog\
    \ computing extends \ncomputation and storage to the edge of the network and presents\
    \ an effective tool \nfor integrating new complex interconnected processing systems.\
    \   \nThe constraint of interoperability can be overcome by adopting advanced\
    \ \nsoftware deployed in the edge and fog installed in an IoT gateway. This software\
    \ \ninteracts simultaneously with the different systems involved through different\
    \ \nprotocols. However, the choice of an IoT gateway is crucial in terms of latency\
    \ \nand accuracy, as it is at the heart of processing and transmitting data to\
    \ the \ndifferent systems and platforms and considered the interface of junction\
    \ between \nthe physical level and cloud. The latter also affects performance\
    \ as it must ensure \nthat data is transferred, processed and returned at speeds\
    \ that meet the needs of \nthe application. \n \niii \n \nSmart IoT Monitoring\
    \ and Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \nWe address all these challenges by considering appropriate\
    \ protocols and \nsoftware for interoperability and connectivity constraints and\
    \ we discuss the \nperformance some appropriate IoT devices capable of providing\
    \ minimal \nresponse time. \nDeep Learning (DL) services can be deployed near\
    \ requesting users and the \ncloud only intervenes when additional processing\
    \ is required, significantly \nreducing the latency and cost of sending data to\
    \ the cloud for processing. In this \nthesis, we propose novel approaches to solve\
    \ the latency issue by deploying \nintelligence at the edge that pushes DL computations\
    \ from the cloud to the edge \nenabling various distributed, low-latency and reliable\
    \ intelligent services. \nThe main benefit of the proposed approaches is the integration\
    \ of cloud \nservices into a control loop to improve a platform’s decision making\
    \ and the \nperformance of an industrial control system. Cloud AI services are\
    \ also \nintegrated into a drone control loop as an input that helps improve the\
    \ \nmonitoring capability to find and track stationary and mobile objects. \n\
    In this work, we evaluate the latency and accuracy of different systems \ninvolved\
    \ and we propose an intelligent algorithm to select the appropriate AI \ntechnology\
    \ for the scenario to be monitored. This proved to be crucial in deciding \nthe\
    \ best source of artificial intelligence to be used to achieve the specified goals\
    \ \nat each stage in real time. The proposed intelligent algorithms offer a compromise\
    \ \nbetween latency and accuracy. \n \n \n \niv \n \nSmart IoT Monitoring and\
    \ Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \n \nResumen \n \nEn la cuarta revolución industrial en\
    \ la que estamos inmersos, se están \nintroduciendo nuevas tecnologías en los\
    \ procesos productivos, como el uso de \nvehículos autónomos (UVs) para recogida\
    \ de datos en grandes superficies y el \nuso del Internet Industrial de las Cosas\
    \ (IIoT). Las principales claves para integrar \nesta nueva tecnología en la industria\
    \ es afrontar el reto de compatibilizar la red \ninformática con sus máquinas,\
    \ incluyendo la interoperabilidad, computación en \nla niebla/nube/borde (fog/cloud/edge\
    \ computing), la seguridad, la disminución \nde la latencia y la mejora de la\
    \ precisión de los datos y la calidad del servicio. \nLas plataformas industriales\
    \ inteligentes requieren múltiples procesos \nsincronizados que exigen una baja\
    \ latencia y una mayor fiabilidad para lograr el \nrendimiento necesario. Además,\
    \ los métodos de Inteligencia Artificial (IA) \naplicados a la IIoT deben ser\
    \ capaces de abordar estas cuestiones, así como otros \nparámetros como el despliegue\
    \ de la red y la gestión de recursos. \nLos problemas de alta latencia y enlaces\
    \ poco fiables entre la nube y los \npuntos finales del IoT industrial son retos\
    \ importantes. Cada aplicación de niebla \ny borde puede tener diferentes requisitos\
    \ de latencia y puede generar diferentes \ntipos de datos y tráfico de red.  Estos\
    \ datos generados pueden ser imágenes \nrecibidas de un sistema UV, por ejemplo.\
    \ Este sistema puede a su vez conectarse \na otro sistema de control, utilizándose\
    \ tanto para realizar mejoras en el proceso \ncomo para tomar decisiones basadas\
    \ en las imágenes capturadas. Este tipo de \nconexión es sensible en términos\
    \ de precisión y latencia, ya que toda la \nplataforma debe decidir con rapidez\
    \ y seguridad. \nUna de las soluciones para superar el reto de la latencia es\
    \ la arquitectura \nbasada en la niebla/borde (fog/edge). Esta arquitectura también\
    \ puede ser una \nsolución viable en cuanto a la barrera de interoperabilidad\
    \ entre los sistemas \ninterconectados. La computación en la niebla extiende la\
    \ computación y el \nalmacenamiento al borde de la red y presenta una herramienta\
    \ eficaz para \nintegrar nuevos sistemas complejos de procesamiento interconectados.\
    \   \nLa limitación de la interoperabilidad puede superarse adoptando un \nsoftware\
    \ avanzado desplegado en el borde y la niebla instalado en una pasarela \nde IoT.\
    \ Este software interactúa simultáneamente con los distintos sistemas \nimplicados\
    \ a través de diferentes protocolos. Sin embargo, la elección de una \npasarela\
    \ IoT es crucial en términos de latencia y precisión, ya que está en el centro\
    \ \ndel procesamiento y la transmisión de datos a los diferentes sistemas y \n\
    plataformas y se considera la interfaz de unión entre el nivel físico y la nube.\
    \ Esta \núltima también afecta al rendimiento, ya que debe garantizar que los\
    \ datos se \n \nv \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \ntransfieran,\
    \ procesen y devuelvan a velocidades que satisfagan las necesidades \nde la aplicación.\
    \ \nAbordamos todos estos retos teniendo en cuenta los protocolos y el software\
    \ \napropiados para la interoperabilidad y las restricciones de conectividad,\
    \ y \nanalizamos el rendimiento de algunos dispositivos IoT apropiados capaces\
    \ de \nproporcionar un tiempo de respuesta mínimo. \nLos servicios de Deep Learning\
    \ (DL) pueden desplegarse cerca de los \nusuarios que los solicitan y la nube\
    \ solo interviene cuando se requiere un \nprocesamiento adicional, reduciendo\
    \ significativamente la latencia y el coste de \nenviar los datos a la nube para\
    \ su procesamiento. En esta tesis, proponemos \nenfoques novedosos para resolver\
    \ el problema de la latencia mediante el \ndespliegue de inteligencia en el borde\
    \ que empuja los cálculos de DL desde la \nnube hasta el borde permitiendo varios\
    \ servicios inteligentes distribuidos, de \nbaja latencia y fiables. \nLa principal\
    \ ventaja de los enfoques propuestos es la integración de los \nservicios en la\
    \ nube en un lazo de control para mejorar la toma de decisiones de \nuna plataforma\
    \ y el rendimiento de un sistema de control industrial. Los servicios \nde IA\
    \ en la nube también se integran en un lazo de control donde interviene un \n\
    dron como una entrada que ayuda a mejorar la capacidad de monitorización para\
    \ \nencontrar y rastrear objetos estacionarios y móviles. \nEn este trabajo, evaluamos\
    \ la latencia y la precisión de los diferentes sistemas \nimplicados y proponemos\
    \ un algoritmo inteligente para seleccionar la tecnología \nde IA adecuada para\
    \ el escenario a vigilar. Esto resulta crucial para decidir cuál \nes la mejor\
    \ fuente de inteligencia artificial que debe utilizarse para alcanzar los \nobjetivos\
    \ especificados en cada escenario en tiempo real. Los algoritmos \ninteligentes\
    \ propuestos ofrecen un compromiso entre latencia y precisión. \n \n \n \nvi \n\
    \ \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual\
    \ Recognition and Cloud/Edge \nComputing Services \n \n صخلملا \n \n \n يفعمج\
    \ مادختسا لثم ، جاتنلإا تايلمع يف ةديدج تاينقت لاخدإ متي ، اهيف كراشن يتلا ةعبارلا\
    \ ةيعانصلا ةروثلا \nةيسيئرلا حيتافملا لثمتت .ءايشلأل يعانصلا تنرتنلإا مادختساو\
    \ ، ةعساو قطانم يف ةلوهأملا ريغ تابكرملا تانايب \n ةهجاوم يف ةعانصلا يف ةديدجلا\
    \ ايجولونكتلا هذه جمدلةقفاوتم تامولعملا ايجولونكت ةكبش لعج يف لثمتملا يدحتلا \n\
    ينمزلا ريخأتلا ليلقتو نملأاو ةيباحسلاو ةيبابضلا ةبسوحلاو يليغشتلا قفاوتلا ةيناكمإ\
    \ كلذ يف امب ، اهتزهجأ عم \nةمدخلا ةدوجو تانايبلا ةقد نيسحتو )نومكلا(  \n \nةددعتم\
    \ ةنمازتم تايلمع ةيكذلا ةيعانصلا تاصنملا بلطتتىلعأ ةيقوثومو ضفخنم ينمزريخأت بجوتست\
    \ يتلاو ، \nءايشلأا تنرتنإ ىلع ةقبطملا يعانطصلاا ءاكذلا بيلاسأ نوكت نأ بجي ، كلذ\
    \ ىلإ ةفاضلإاب .مزلالا ءادلأا قيقحتل \nدراوملا ةرادإو ةكبشلا تيبثت لثم ىرخأ تاملعم\
    \ ىلإ ةفاضلإاب تلاكشملا هذه ةجلاعم ىلع ةرداق  \n   \nاورلا تلاكشم دعتءايشلأا تنرتنإو\
    \ ةيباحسلا ةياهنلا طاقن نيب يلاع ينمزريخأت تاذ و اهب قوثوملاريغ طب \nعاونأ هنع\
    \ جتني دقو ةفلتخم نومك تابلطتم ةفاحلاو بابضلا تاقيبطت نم قيبطت لكل نوكي دق .ريبك\
    \ يدحت ةيعانصلا \nيتلا تانايبلا هذه نوكت نأ نكمي .تاكبشلا ربع ةلوادتملا تانايبلا\
    \ نم ةفلتخم نم ةملتسملا روصلا نم اهؤاشنإ مت \nتانيسحت ءارجلإ همادختسا متي ثيح\
    \ ، رخآ مكحت ماظنب ريخلأا اذه ليصوت نكمي .ةلوهأملا ريغ تابكرملا ماظن \nبجي ثيح\
    \ ، نومكلاو ةقدلا ثيح نم ساسح لاصتلاا نم عونلا اذه .ةطقتلملا روصلا ىلع ًءانب تارارقلا\
    \ ذاختلاو \nفنملا يساسلأا ماظنلا ىلعدكؤم لكشبو ةعرسب ررقي نأ هلمكأب ذ  \n \nيف\
    \ ةتبثم ، بابضلاو ةفاحلا يف ةرشتنم ةمدقتم جمارب دامتعا للاخ نم يليغشتلا قفاوتلا\
    \ دويق ىلع بلغتلا نكمي \nتلاوكوتورب للاخ نم ةكراشملا ةفلتخملا ةمظنلأا عم نمازتم\
    \ لكشب جمانربلا اذه لعافتي .ءايشلأا تنرتنإ ةباوب \n كلذ عمو .ةفلتخمإف ،اهنإ ثيح\
    \ ، ةقدلاو ينمزلاريخأتلاب قلعتي اميف ةيمهلأا غلاب رمأ ءايشلأا تنرتنإ ةباوب رايتخا\
    \ ن \nةقبطلا( ةيداملا ةقبطلا نيب عطاقتلا ةهجاو ربتعت يتلاو ، ةفلتخملا ىنبلاو ةمظنلأا\
    \ ىلإ اهلقنو تانايبلا ةجلاعم بلق \nباحسلاو )يرايعملا لاصتلاا جذومن يف ةقبط ىندأ،ىلولأانمضت\
    \ نأ بجي هنلأ ءادلأا ىلع اًضيأ ةريخلأا هذه رثأت .ة \n قيبطتلا تاجايتحا يبلت تاعرسب\
    \ اهتداعإو اهتجلاعمو تانايبلا لقن \n \nلاصتلاا دويقو يليغشتلا قفاوتلل ةبسانملا\
    \ جماربلاو تلاوكوتوربلا يف رظنلا للاخ نم تايدحتلا هذه لك عم لماعتن  \nيشلأا تنرتنإ\
    \ ةزهجأ ضعب ءادأ شقاننوينمزلا ريخأتلا نم ىندلأا دحلا ريفوت ىلع ةرداقلا ةبسانملا\
    \ ءا  \n \nىلإ ةجاحلا دنع لاإ ةباحسلا لخدتت لاو ، ةبولطملا نيمدختسملا ةمظنأ نم\
    \ برقلاب قيمعلا ملعتلا تامدخ رشن نكمي \nملل ةباحسلا ىلإ تانايبلا لاسرإ ةفلكتو\
    \ ينمزلا ريخأتلا نم ريبك لكشب للقي امم ، ةيفاضإ ةجلاعمهذه يف .ةجلاع \nتاباسح عفدت\
    \ يتلا ةفاحلا ىلع ءاكذلا رشن للاخ نم ينمزلا ريخأتلا ةلكشم لحل ةديدج بيلاسأ حرتقن\
    \ ، ةحورطلأا \nضفخنم ينمز ريخأت تاذو ةعزومو ةقوثومو ةعونتم ةيكذ تامدخ حيتي امم\
    \ ةفاحلا ىلإ ةباحسلا نم قيمعلا ملعتلا  \n \n ةحرتقملا قرطلل ةيسيئرلا ةدئافلا لثمتتيف\
    \ رارقلا عنص ةيلمع نيسحتل مكحتلا ةقلح يف ةيباحسلا تامدخلا جمد يف \nكذلا تامدخ\
    \ جمد اًضيأ متي .يعانصلا مكحتلا ماظن ءادأو يساسلأا ماظنلايف مكحتلا ةقلح يف ةيباحسلا\
    \ يعانطصلاا ءا \nةتباثلا ءايشلأا ىلع روثعلل ةبقارملا ةردق نيسحت ىلع دعاسي لخدمك\
    \ ةلوهأملا ريغ تابكرملا اهعبتتو ةكرحتملاو  \n  \nءاكذلا ةينقت ديدحتل ةيكذ ةيمزراوخ\
    \ حرتقنو ةينعملا ةفلتخملا ةمظنلأا ةقدو ينمزلا ريخأتلا مييقتب موقن ، لمعلا اذه\
    \ يف \nيعانطصلاا ءاكذلل ردصم لضفأ ديدحت يف مساح رمأ اذه نأ تبث .هتبقارم دارملا\
    \ ويرانيسلل ةبسانملا يعانطصلاا \nلأا قيقحتل همادختسلااطسو لاح ةحرتقملا ةيكذلا\
    \ تايمزراوخلا مدقت .يلعفلا تقولا يف ةلحرم لك يف ةبولطملا فاده \nةقدلاو نومكلا\
    \ نيب  \n \n \n \nvii \n \nSmart IoT Monitoring and Real-Time Control Based On\
    \ Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services \n\
    \ \n \nList of Acronyms  \nAI Artificial Intelligence  \nAIS Automatic Identification\
    \ System \nANN Artificial Neural Network  \nAPI Application programming interfaces\
    \ \nASV Autonomous Surface Vehicle \nAUV Autonomous Underwater Vehicle \nCAN Controller\
    \ area network \nCCM Cloud custom model \nCGM Cloud General Model \nCoAP Constrained\
    \ Application Protocol \nCPS cyber-physical systems \nCPU Central processing unit\
    \  \nCSMA/CD with NDBA Carrier Sense Multiple Access / Collision Detection \n\
    with Non-Destructive Bitwise Arbitration \nCV Computer vision \nDAyRA División\
    \ de Automatización y Robótica Autónoma \nDNNs Deep Neural Networks \nDP Deep\
    \ Learning \nDPM Dynamic Position Mode  \nDVL Doppler Velocity Logger \n \nviii\
    \ \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots,\
    \ Visual Recognition and Cloud/Edge \nComputing Services \nECM Edge custom model\
    \ \nEI Edge Intelligence  \nERP enterprise resource planning \nFN False Negative\
    \ \nFP False Positive \nGPS Global Positioning System \nGPU Graphics Processing\
    \ Unit \nHD High-definition \nHVAC Heating, Ventilating, and Air Conditioning\
    \ \nIaaS Infrastructure-as-a-Service  \nIETF The Internet of Engineering Task\
    \ \nILSVRC ImageNet Large Scale Visual Recognition Challenge \nIM Inspection Mode\
    \  \nIMARS IBM multimedia analysis and retrieval system \nIoS Internet of services\
    \ \nIoT Internet of things \nIoU Intersection on union \nIPM Image Processing\
    \ Algorithm \nIUCN International Union for the Conservation of Nature \nIUNO Interface\
    \ for Unmanned Drones \nM2M machine-to-machine \nMASS Maritime Autonomous Surface\
    \ Ships  \nMES manufacturing execution systems \n \nix \n \nSmart IoT Monitoring\
    \ and Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \nML Machine Learning  \nMLaaS Machine Learning as a service\
    \  \nMMM Main Mission Mode \nMPA Marine Protected Area \nMQTT The Message Queuing\
    \ Telemetry Transport \nND Not detected \nNFC Near Field Communication  \nNIC\
    \ network interface controller  \nOPC UA Open Platform Communications Unified\
    \ Architecture  \nOWD One-way delay \nPaaS Platform as-a-Service \nPC-G PC Gateway\
    \ \nPID Proportional–Integral–Derivative \nPV Process Variables \nQoS Quality\
    \ of Service  \nRFID Radio frequency identification  \nRPI-G Raspberry PI Gateway\
    \ \nRTD Round-trip delay time \nS-G Siemens Gateway \nSAAO Smart algorithm for\
    \ autonomy optimization \nSaaS Software-as-a-Service \nSAR Synthetic Aperture\
    \ Radar \nSHDL ScatterNet hybrid deep learning \n \nx \n \nSmart IoT Monitoring\
    \ and Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \nSISO single-input–single-output \nSOA Service-oriented\
    \ architecture \nSP Set Points \nSVM Support vector machine \nTAS Time-aware scheduler\
    \  \nTM Tracking Mode  \nTP True Positive \nTSN Time sensitive networking \nUAV\
    \ Unmanned Autonomous Vehicle \nUVs Unmanned vehicles \nVPL Visual Programming\
    \ Language  \nWFQ weighted fair queuing \nWSN Wireless Sensor Network  \nWVR Watson\
    \ Visual Recognition \n \n \n \nxi \n \nSmart IoT Monitoring and Real-Time Control\
    \ Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \n \n \nList of Publications  \nThe work presented in this thesis has appeared\
    \ in the articles reported below.  \nJournal papers:  \n(J1) Salhaoui Marouane;\
    \ Guerrero-González Antonio; Arioua Mounir; Ortiz, \nFrancisco J.; El Oualkadi\
    \ Ahmed; Torregrosa Carlos L. 2019. \"Smart Industrial IoT \nMonitoring and Control\
    \ System Based on UAV and Cloud Computing Applied to \na Concrete Plant\" Sensors\
    \ 19, no. 15: 3316. https://doi.org/10.3390/s19153316  \n \n(J2) Salhaoui Marouane;\
    \ Molina-Molina J. C.; Guerrero-González Antonio; Arioua \nMounir; Ortiz Francisco\
    \ J. 2020. \"Autonomous Underwater Monitoring System for \nDetecting Life on the\
    \ Seabed by Means of Computer Vision Cloud Services\" \nRemote Sens. 12, no. 12:\
    \ 1981. https://doi.org/10.3390/rs12121981  \n \n(J3) Molina-Molina J. C.; Salhaoui\
    \ Marouane; Guerrero-González, Antonio; Arioua, \nMounir. 2021. \"Autonomous Marine\
    \ Robot Based on AI Recognition for \nPermanent Surveillance in Marine Protected\
    \ Areas\" Sensors 21, no. 8: 2664. \nhttps://doi.org/10.3390/s21082664  \n \n\
    (J4) Benbarrad, Tajeddine; Salhaoui Marouane; Kenitar Soukaina B.; Arioua \nMounir.\
    \ 2021. \"Intelligent Machine Vision Model for Defective Product Inspection \n\
    Based \non \nMachine \nLearning\" J. \nSens. \nActuator \nNetw. 10, \nno. \n1:\
    \ \n7. \nhttps://doi.org/10.3390/jsan10010007  \n \nInternational conference papers:\
    \  \n(C1) Marouane Salhaoui, Mounir Arioua, Otman Chakkor, and Jihane Elaasri.\
    \ 2017. \nPerformance Evaluation Survey of WSN Physical Layer. In Proceedings\
    \ of the 2nd \nInternational Conference on Computing and Wireless Communication\
    \ Systems \n(ICCWCS'17). Association for Computing Machinery, New York, NY, USA,\
    \ Article \n68, 1–5. DOI: https://doi.org/10.1145/3167486.3167557 \n \n(C2) Marouane\
    \ Salhaoui, Mounir Arioua, Antonio Guerrero-González, María \nSocorro García-Cascales,\
    \ \"An IoT Control System for Wind Power Generators\", \n17th International Conference,\
    \ IPMU, Published in Information Processing and \nManagement of Uncertainty in\
    \ Knowledge-Based Systems. Applications, \nSpringer, Cádiz, Spain, 2018. https://doi.org/10.1007/978-3-319-91479-4_39\
    \ \n \nxii \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \n \n(C3) Soukaina\
    \ Bakhat Kenitar, Salhaoui Marouane, Arioua Mounir, Ali Younes, and \nA. Guerrero\
    \ Gonzalez. 2018. Evaluation of the MQTT Protocol Latency over \nDifferent Gateways.\
    \ In Proceedings of the 3rd International Conference on Smart \nCity Applications\
    \ (SCA '18). Association for Computing Machinery, New York, NY, \nUSA, Article\
    \ 87, 1–5. DOI: https://doi.org/10.1145/3286606.3286864   \n \n(C4) Soukaina B.K.,\
    \ Ali Y., Mounir A., Marouane Salhaoui. (2019) Latency \nAssessment of MQTT Protocol\
    \ in Transferring Data from the Field to the Cloud \nOver Different Gateways.\
    \ In: Ben Ahmed M., Boudhir A., Younes A. (eds) \nInnovations in Smart Cities\
    \ Applications Edition 2. SCA 2018. Lecture Notes in \nIntelligent \nTransportation\
    \ \nand \nInfrastructure. \nSpringer, \nCham. \nhttps://doi.org/10.1007/978-3-030-11196-0_71\
    \  \n \n(C5) S. B. Kenitar, M. Arioua, A. Younes, M. Radi and Marouane Salhaoui,\
    \ \n\"Comparative Analysis of Energy Efficiency and Latency of Fog and Cloud \n\
    Architectures,\" 2019 International Conference on Sensing and Instrumentation\
    \ in \nIoT Era (ISSI), 2019, pp. 1-5, doi: 10.1109/ISSI47111.2019.9043738. \n\
    \ \n(C6) Yassine Yazid, Imad Ez-zazi, Marouane Salhaoui, Mounir Arioua, El Oualkadi\
    \ \nAhmed, Antonio Guerrero González. Extensive Analysis of Clustered Routing\
    \ \nProtocols For Heteregeneous Sensor Networks. Third International Conference\
    \ on \nComputing and Wireless Communication Systems, ICCWCS 2019, April 24-25,\
    \ \n2019, \nFaculty \nof \nSciences, \nIbn \nTofaïl \nUniversity \n-Kénitra- \n\
    Morocco. \nhttp://dx.doi.org/10.4108/eai.24-4-2019.2284208 \n \n(C7) Marouane\
    \ Salhaoui, Molina-Molina, J. C, A. Guerrero-González, Antonio; \nArioua, Mounir;\
    \ Ortiz, Francisco J.; El Oualkadi, Ahmed. Edge-Cloud Architectures \nUsing UAVs\
    \ Dedicated To Industrial IoT Monitoring And Control Applications. \nIEEE- International\
    \ Symposium on Advanced Electrical and Communication \nTechnologies ISAECT2020,\
    \ November 25th-27th, 2020 Ibn Tofail University, \nMorocco \n \n(C8) Benbarrad\
    \ Tajeddine; Salhaoui Marouane; Arioua Mounir. Impact of Standard \nImage Compression\
    \ on the Performance of Image Classification with Deep \nLearning. ICDATA21 (International\
    \ Conference on Digital Age & Technological \nAdvances for sustainable development),\
    \ 2021. 29 - 30 June 2021 Marrakech, \nMorocco. \n \n \n \nxiii \n \nSmart IoT\
    \ Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \n \n \n \nContents  \n \n \nAbstract  \n\
    \ \nResumen \n \n صخلملا \n \nList of Acronyms  \n \nList of Publications  \n\
    \ \n1. Introduction   \n \n1.1 \nBackground \n \n1.1.1 Applications  \n1.1.2 IoT\
    \ Monitoring and Control \n1.1.3. Advantages of Using AI in the cloud \n1.1.4.\
    \ Constraints \n \n1.2 \nMotivation \n \n1.3 \nObjectives and contributions  \n\
    \ \n1.4 \nThesis organization  \n \n2. Performance analysis of IoT Monitoring\
    \ and Control System Based on \nUV, machine vision and artificial intelligence\
    \   \n \n2.1 \nIntroduction  \n \n2.2 \nUV IoT architecture  \n2.2.1. Most Common\
    \ IoT Architectures \n2.2.2. IoT Monitoring and Control Architecture Based on\
    \ Unmanned \nVehicles \n2.2.3 IoT Gateway Capabilities \n \nxiv \n \nSmart IoT\
    \ Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \n \n2.3 \nUV & IoT Protocols \n \n2.3.1\
    \ UV Protocols \n2.3.2 IoT Protocols \n2.3.3 Industrial protocols \n2.3.4 OPC\
    \ UA protocol \n \n \n3. Performance and latency assessment using AI for UV  \
    \ \n \n3.1. Introduction  \n \n3.2. Related works \n \n3.3. Artificial Intelligence\
    \ and Machine Vision \n3.3.1 Artificial Intelligence \n \n3.3.1.2 Inference Versus\
    \ Training \n3.3.1.3 Methods of Machine Learning \n3.3.1.4 Convolutional Neural\
    \ Network for Object Recognition \n \n3.4. Cloud-Edge DL \n \n3.4.1 Cloud AI at\
    \ the edge \n3.4.2 Evaluating performance of an object detection model \n \n3.5.\
    \ Latency Assessment  \n \n3.5.1 Latency between Two Terminals \n3.5.2 OPC UA\
    \ Architecture and delay assessment \n3.5.3 UAV System Delay \n \n4. Energy Efficiency\
    \ and Latency of Smart IoT Monitoring and Control \nSystems Based on cloud Computing\
    \ and Intelligent Machine Vision \n \n4.1 Smart Industrial IoT Monitoring and\
    \ Control Systems Based on cloud \nComputing and Intelligent Machine Vision \n\
    \ \n4.2 Autonomous Underwater Monitoring System for Detecting Life on the Seabed\
    \ \nby Means of Computer Vision Cloud Services \n \nxv \n \nSmart IoT Monitoring\
    \ and Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \n \n4.3 Autonomous Marine Robot Based on AI Recognition\
    \ for Permanent \nSurveillance in Marine Protected Areas \n \n4.4 An IoT Control\
    \ System for Wind Power Generators \n \n5. Conclusions and future work  \n \n\
    5.1 Contributions summary  \n5.2 Future Works  \n \nBibliography  \n \n \nxvi\
    \ \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots,\
    \ Visual Recognition and Cloud/Edge \nComputing Services \n \nList of Tables \
    \ \n \n \nTable 2.1. Main protocols used in the IoT field \nTable 2.2. Comparison\
    \ of Internet of Things (IoT) protocols \nTable 4.1. Confusion matrix. \nTable\
    \ 4.2. Specification of each machine environment. \nTable 4.3. RTD test of 5200\
    \ samples from the OPC UA client to the OPC UA server (PLC) \nover different clients\
    \ through different machines. \nTable 4.4. RTD Test of 200 photos sent from the\
    \ IoT gateway to the AR.Drone 2.0. \nTable 4.5. RTD test of 100 samples from the\
    \ IoT gateway to IBM Watson over different \nmachines.  \nTable 4.6. Speed Test\
    \ over the three gateways (S-G, RPI-G, PC-G). \nTable 4.7. GPS coordinates of\
    \ the area explored. \nTable 4.8. Accuracy measurement in different platforms.\
    \ \nTable 4.9. Latency measurement in different platforms. \nTable 4.10. Definition\
    \ of mission stages. \nTable 4.11. AI source preferences according to mission\
    \ stage. \nTable 4.12. RTD test of 300 samples of the Edge and Cloud model. \n\
    Table 4.13. Experimental SAAO results \nTable 4.14. Summary of SAAO logs during\
    \ the experiment \n \n \n \nxvii \n \nSmart IoT Monitoring and Real-Time Control\
    \ Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \nList of Figures \n  \n \nFigure 1.1. A three-layer IoT architecture based\
    \ on: Device, Edge and Cloud for \nPredictive Maintenance (PM) [8]. \nFigure 1.2\
    \ Major limitations of current IoT platforms \nFigure 1.3 Mapping of interoperability\
    \ levels to OSI layers \nFigure 1.4.  Automation Pyramid vs Automation Network\
    \ [43] \nFigure 1.5. Capabilities comparison of cloud, on-device and edge intelligence\
    \ [40] \nFigure 2.1. Most common IoT architectures \nFigure 2.2. UV-IoT Architecture\
    \ \nFigure 2.3. Wiring diagrams in vehicles before and after the appearance of\
    \ CAN \nFigure 2.4. Controller area network bus node \nFigure 2.5. Node of the\
    \ CAN bus system \nFigure 2.6. Comparison of protocols for the exchange of messages:\
    \ (a) MQTT; (b) \nMODBUS TCP. \nFigure 2.7. The IEEE model (a); compared to the\
    \ HTTP (b); the CoAP (c); the MODBUS \nTCP (d); and the MQTT (e). \nFigure 2.8.\
    \ OPC UA in the automation pyramid \nFigure 2.9. Architecture of the OPC UA Server\
    \ \nFigure 3.1. Node-Red Platform \nFigure 3-2: Deep learning in the context of\
    \ artificial intelligence \nFigure 3-3. Connections to a neuron in the brain.\
    \ xi, wi, f (·), and b are the activations, \nweights, nonlinear function, and\
    \ bias, respectively \nFigure 3.4 Simple neural network example and terminology.\
    \ (a) Neurons and synapses. \n(b) Compute weighted sum for each layer. \nFigure\
    \ 3.5. Training and inference comparison \nFigure 3.6. Six-level rating for edge\
    \ intelligence \nFigure 3.7. IoU equation, Red is ground truth bounding box and\
    \ green is predicted \nbounding box \nFigure 3.8. Latency between two terminals\
    \ in a network \nFigure 3.9. OPC UA delay in OPC UA client server in an Ethernet\
    \ network \nFigure 3.10 Video transmission system delay sources. \nFigure 4.1:\
    \ Proposed UAV-IIoT Platform \nFigure 4.2. Development design of autonomous IIoT\
    \ flight \nFigure 4.3. Node-RED flow in the IoT gateway including the path from\
    \ the PLCs to the \nUAV, from the UAV to IBM Watson, and from Watson to the control\
    \ center. \nFigure 4.4. SCADA Industrial concrete plant with a typical concrete\
    \ formula. \nFigure 4.5. AR.Drone 2.0 mission in the concrete plant. \nFigure\
    \ 4.6. Communication process in the fog layer. \nFigure 4.7. Path used by the\
    \ drone to execute the mission in a concrete plant. \nFigure 4.8. Dataset used\
    \ to train the custom model in WVR service: (a) Shows images \nused to train the\
    \ Mixed class; (b) Shows Images used to train the Normal class. \nFigure 4.9.\
    \ Watson visual recognition test of new images not used in the training phase.\
    \ \nFigure 4.10. Node-RED flow and WVR results of an UAV photo. \nFigure 4.11.\
    \ OPC UA delay in OPC UA client server in an Ethernet network. \n \nxviii \n \n\
    Smart IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual\
    \ Recognition and Cloud/Edge \nComputing Services \nFigure 4.12. Node-RED flow\
    \ used to calculate round trip latency (OPC UA Client to the \nOPC UA Server).\
    \ \nFigure 4.13. OPC UA client-server RTD to read one bit through different machines.\
    \ \nFigure 4.14. (a) Simulation results of CPU load (%) versus OPC UA RTD (ms)\
    \ in the S-G; \n(b) Simulation results of CPU load (%) versus OPC UA RTD (ms)\
    \ in the RPI-G. \nFigure 4.15. Probability density function of the delay of the\
    \ drone connected to the \ngateway when successive pictures from PC-G and RPI-G\
    \ are taken. \nFigure 4.16. Probability density function of the delay of the drone\
    \ connected to the \ngateway when successive pictures from S-G are taken. \nFigure\
    \ 4.17. CPU Load while taking successive photos and writing them in a folder in\
    \ \nthe PC-G. \nFigure 4.18. CPU Load while taking successive photos and writing\
    \ them in a folder in \nthe RPI-G. \nFigure 4.19. CPU Load while taking successive\
    \ photos and writing them in a folder in \nthe S-G. \nFigure 4.20. Probability\
    \ density function estimation of IBM WVR latency to classify an \nimage located\
    \ in the IoT gateway. \nFigure 4.21. Proposed AUV-IoT Platform \nFigure 4.22.\
    \ Proposed hardware architecture. \nFigure 4.23. Node intercommunications and\
    \ concurrent threads in the IoT gateway. \nFigure 4.24. Communication between\
    \ platforms. \nFigure 4.25. Fan mussel recognition training: defining a fan mussel\
    \ bounding box in \ndifferent cloud services. \nFigure 4.26. Pictures used for\
    \ custom CV model training. \nFigure 4.27. New specimen detection using the IBM\
    \ Python API. \nFigure 4.28. Triangular similarity using a single camera [47].\
    \ \nFigure 4.29. Closed control loop for object detection and tracking. \nFigure\
    \ 4.30. Basic closed-loop system with sensor and actuator delays. \nFigure 4.31.\
    \ Mission generated in IUNO and uploaded into AUV. \nFigure 4.32. Deploying the\
    \ platform to initiate the mission. AUV submarine connected \nto a buoy via a\
    \ DSL cable. \nFigure 4.33. Specimen detection and positioning in IUNO. \nFigure\
    \ 4.34. Communication edge cloud. (a) Training and inference in the cloud; (b)\
    \ \ntraining in the cloud, inference in the edge. \nFigure 4.35. Latency in the\
    \ proposed platform within the cloud architecture. \nFigure 4.36. Edge architecture\
    \ latency in the proposed platform. \nFigure 4.37. Cloud-based custom models for\
    \ detecting new specimens. \nFigure 4.38. BUSCAMOS-VIGIA framework. \nFigure 4.39.\
    \ BUSCAMOS-VIGIA ASV. \nFigure 4.40. Platform’s communications in the tracking\
    \ algorithm. \nFigure 4.41. SAAO diagram. \nFigure 4.42. Calculation of acceptable\
    \ latency limits. Main ASV camera point of view. \nFigure 4.43. Comparison of\
    \ three different clouds vision API detection of boat in Los \nNietos port (Murcia,\
    \ Spain). \nFigure 4.44. Types and number of vessels used to train the vision\
    \ custom models. \nFigure 4.45. Performance of the cloud custom model object detection\
    \ in discerning \ndifferent boat types. \n \nxix \n \nSmart IoT Monitoring and\
    \ Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \nFigure 4.46. Performance differences between the Edge\
    \ and the cloud custom models. \nFigure 4.47. Cloud and edge custom models for\
    \ detecting new vessels. \nFigure 4.48. Latency of more than 300 samples. \nFigure\
    \ 4.49. Images analysed. Cloud/edge results comparison \nFigure 4.50. Scale experiment.\
    \ Equivalence of area and distance from integral reserve \n(Islas Hormigas) to\
    \ base station (right) and equivalent area in Mar Menor (left). \nFigure 4.51:\
    \ Edge (left) / cloud (right) trained model recognition tests. \nFigure 4.52.\
    \ Start of mission (MMM) of surveillance of area equivalent to integral \nreserve.\
    \ \nFigure 4.53. (a) Stopped vessel detected. Start TM mode. (b) Tracking Mode\
    \ (TM) test \nduring the experiment.  \nFigure 4.54. Wind energy IoT communication\
    \ architecture \nFigure 4.55. Hardware Setup \nFigure 4.56. Data flow between\
    \ different systems and across different protocols. \nFigure 4.57. Checking OPC\
    \ UA connection using UaExpert Software \nFigure 4.58. Communication between the\
    \ PLC 1512 and IBM Cloud through OPC UA \nprotocol using Node-RED installed the\
    \ industrial Gateway IOT2040. \nFigure 4.59. Dashboard Data of wind Sensors in\
    \ the IoT2040 Gateway \nFigure 4.60. Dashboard data wind sensors in the IBM Watson\
    \ Platform. \n \n \n1 \n \n \nCHAPTER 1 \n \n \n \n--------------------------------------------------\
    \ \n \nIntroduction \n \n-------------------------------------------------- \n\
    \ \n \n \n \nThis chapter presents the background, motivation and main contributions\
    \ of \nthis thesis. It presents an overview of using computer vision and AI in\
    \ IoT \nmonitoring and its applications. The limitations are highlighted of using\
    \ AI in \nIoT monitoring and control and its main constraints as motivations for\
    \ the \npresented work. Subsequently, the main contributions of this thesis are\
    \ \npresented. Finally, the organization of this thesis is detailed. \n \n2.3\
    \ \nBackground  \n \nEmerging new market demands and autonomous technologies such\
    \ as IoT \nare moving the environment of manufacturing companies towards smart\
    \ \nfactories.  The fundamental idea of IoT is a system where physical objects\
    \ are \nenhanced with embedded electronics (RFID tags, sensors, etc.) and connected\
    \ to \nthe Internet. Thus, IoT is based on both smart objects and smart networks\
    \ [1]. The \ndevices in the IoT network can be employed for collecting information\
    \ based on \nthe use cases. These include retail, manufacturing industries, autonomous\
    \ \nvehicles, smart grid, etc. These IoT devices can be used for tasks such as\
    \ tracking \nitems and objects, remote monitoring, and fully autonomous robots.\
    \ It is reported \nthat the amount of IoT devices has been growing every year\
    \ with the predicted \nnumber of devices by 2025 reaching 75.44 billion [2]. \n\
    \ \n2 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots,\
    \ Visual Recognition and Cloud/Edge \nComputing Services \nThe use of IoT has\
    \ become ubiquitous and IoT devices are common in many \nfields. The integration\
    \ of IT and Operational Technology (OT) in the Industrial \nInternet of Things\
    \ (IIoT) enables the “smart factory” concept. IIoT uses IoT \ndevices and sensors\
    \ to monitor machines and environments to ensure the highest \nperformance of\
    \ equipment and processes. \nIn practice, IoT has stimulated the factories and\
    \ the governments to launch \nan evolutionary journey toward the fourth industrial\
    \ revolution called Industry \n4.0. The first industrial revolution started with\
    \ the introduction of mechanical \nmanufacturing equipment, followed by a second\
    \ that entailed the mass \nproduction of goods.  Since the beginning of the 1970's\
    \ and until today, the \nincreasing automation and control of manufacturing processes\
    \ through the use \nof electronics and computers is considered the third revolution\
    \ (digital \nrevolution). Leveraging IoT technology in the manufacturing environment\
    \ leads \nto the fourth stage of industrialization [3]. \nAt the heart of IoT\
    \ and smart manufacturing is the basic principle of Industry \n4.0, products being\
    \ manufactured, components and production machines must \ncollect and share data\
    \ in real time. This leads to a shift from centralized factory \ncontrol systems\
    \ to decentralized intelligence.  \n The exchange of real-time data and information\
    \ between different devices \nand parties is the key element of smart factories;\
    \ this data could represent the \nstate of production. Therefore, the next generation\
    \ of smart factories will need to \nbe able to adapt, almost in real time, to\
    \ constantly technological options and \nregulations [4].  \nTo perform effective\
    \ predictive maintenance (PM), massive amounts of data \nare collected, processed\
    \ and ultimately analyzed by machine learning (ML) \nalgorithms. ML can be used\
    \ on collected data to make predictions. Indeed, the \naccuracy of ML models depends\
    \ primarily on the data collected. \nTraditionally, IoT sensors transmit their\
    \ data readings to the cloud for \nprocessing and modeling. Processing and transmitting\
    \ massive amounts of data \nbetween IoT devices and infrastructure comes at a\
    \ cost. Edge computing, in \nwhich sensors and intermediate nodes can process\
    \ data, can reduce data \ntransmission costs and increase processing speed. These\
    \ techniques can reduce \nthe amount of data sent to the cloud for processing,\
    \ however there are potential \naccuracy trade-offs when ML algorithms use reduced\
    \ data sets. Another \napproach is to move ML algorithms closer to the data to\
    \ reduce the amount of \ndata transmitted [5]. \nVisual recognition technologies\
    \ based on artificial intelligence (AI) and the \nInternet of Things (IoT) can\
    \ offer a detection capacity close to human capabilities \n[6]. The AI cloud services\
    \ allows training of customized ML models that are able \nto classify the received\
    \ data or detect individual objects in a given image along \nwith their bounding\
    \ box and label. There are many different cloud APIs for \ncomputer vision, e.g.,\
    \ IBM, Google, Microsoft Azure and Amazon. They all \n \n3 \n \nSmart IoT Monitoring\
    \ and Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \nprovide fairly similar capabilities, although some emphasize\
    \ object recognition, \nAmazon, or building custom models, like Microsoft Azure\
    \ and IBM.  \nThe strength of these cloud APIs is their ability to develop custom\
    \ models \nrapidly and download trained custom models to deploy them on the edge\
    \ for \nreal-time applications and low-latency requirements [7-8]. \nWhen computing\
    \ is deployed at the edge for real-time data processing, \naccuracy is also of\
    \ paramount importance. Further, it is also clear that for data \nreduction, the\
    \ edge or device is mainly exploited. However, since the initial \ntraining is\
    \ computationally intensive, the cloud is still used in most of the \nproposed\
    \ techniques for model training. In cases where a dedicated edge node is \nnot\
    \ available, network devices can also be exploited.  \n \n1.1.1 APPLICATIONS \
    \ \n \nMany fields and industries are using IoT as part of their architecture\
    \ today. \nIn the following, we will look at some of them and how IoT can be used\
    \ to further \nimprovements. \n \nA. Smart Factory  \n \nThe main concept of Industry\
    \ 4.0 is smart manufacturing and IIoT, where the \ncomponent, product and machine\
    \ will exchange data on the basis of real time [9]. \nSince exchange of data between\
    \ different devices in real time is the main element \nof smart factory, this\
    \ information can be considered as control, production status, \nsupplier and\
    \ customer order feedback information, material movement, \nsimulation. Smart\
    \ factory will provide the customer with service and smart \nproduct, which will\
    \ be connected to a network based on IoT. The smart factory \ngathers and scans\
    \ data from a related smart application and the product. \n \nB. Smart Vehicles\
    \  \n \nA fully autonomous vehicle can be defined as a vehicle that is capable\
    \ of \nperceiving its environment, deciding on a route to its destination and\
    \ driving it. \nIt is a smart car or robocar that uses a variety of sensors, computer\
    \ processors \nand databases such as maps to take over some or all of the driving\
    \ functions of \nhuman operators. In a few words, an autonomous (or driverless)\
    \ car can also be \ndefined as a vehicle that relies on a combination of Internet\
    \ of Things (IoT) \ndevices (e.g., sensors, cameras, and lidars), appropriate\
    \ software, and artificial \nintelligence to move without a human operator [10].\
    \ \n \nC. Smart grid  \n \n \n4 \n \nSmart IoT Monitoring and Real-Time Control\
    \ Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \nToday most of the power supply system is manually operated, and due to \n\
    some human error, there is loss of power. These small losses result in massive\
    \ \noutrage of power supply. This loss can be brought under control, and a 100%\
    \ \nefficient power transfer system can be designed using IoT, and it is known\
    \ as the \nSmart grid. It is a fully automated system based on blockchain technology,\
    \ which \nis entirely robust & encrypted. This power is divided into channels\
    \ for each \nindividual, and this channel is wholly encrypted with its stash key,\
    \ which is to \nbe decrypted. This results in an equalized power supply throughout\
    \ the grid \nwithout any power loss [11]. Given that millions of end users will\
    \ be involved in \nthe processes and information flows of smart grids, the high\
    \ scalability of these \nmethods becomes an important issue. To solve these problems,\
    \ cloud computing \nservices emerge as a viable solution by providing reliable,\
    \ distributed and \nredundant capabilities on a global scale. Moreover, the implementation\
    \ of an \nintelligent network application on top of mixed cloud and edge processing\
    \ \nmiddleware is able to achieve higher performance by leveraging edge node \n\
    processing and data aggregation to reduce communication with the cloud \nenvironment\
    \ [12]. \n \n \nD. Monitoring environmental parameters   \n \nEnvironmental monitoring,\
    \ as an integral part of smart campuses, is an \napplication that describes any\
    \ activity in a surrounding area to monitor the \nquality of an environment [13].\
    \ It is used in the assessment of any risk that may \nbe posed to the environment\
    \ and humans. The applications of IoT in \nenvironmental monitoring are vast:\
    \ Industrial site monitoring, seabed \nmonitoring, sea or ocean monitoring, environmental\
    \ protection, extreme weather \nmonitoring, \nwater \nsafety, \nendangered \n\
    species \nprotection, \ncommercial \nagriculture, etc. In these applications,\
    \ sensors detect and measure every type of \nenvironmental change [14]. \n \n\
    E. Smart Waste Management  \n \nOne of the major issues that modern cities are\
    \ facing is waste management. \nIt consists of multiple processes like managing\
    \ and monitoring waste, transport, \ncollection, disposal, etc. These processes\
    \ are costly and time-consuming. One can \noptimize these processes to reduce\
    \ cost, which can be used for solving other \nissues that smart cities can be\
    \ deal with. For instance, various sensors can be \ninstalled in places like trucks\
    \ or cans of garbage, which can detect type and \namount of garbage [15]. \n \n\
    F. Smart agriculture  \n \n \n5 \n \nSmart IoT Monitoring and Real-Time Control\
    \ Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \nThanks to the IoT, it is possible to meet the food needs of a constantly \n\
    growing population. The analysis of smart agriculture data, i.e., land condition,\
    \ \nweather situation, and soil type, collected from the IoT network, can provide\
    \ \npractical information if used in combination with the data captured by sensors,\
    \ \nwhich measure the level of water resources, heat, humidity, chemicals, water\
    \ \nstress, pump condition, etc. This allows farmers to use fertilizers, water\
    \ and \npesticides in the most accurate amounts, at precise positions and with\
    \ efficient \nscheduling to improve crop yields. Smarter water use, such as monitoring\
    \ and \nsupervising the capacity, location, timing and period of water flow based\
    \ on data \nanalysis, increases irrigation efficiency and thus reduces costs [16].\
    \ \n \nG.  Smart Home  \n \nTo reduce user’s interference in controlling and monitoring\
    \ home settings as \nwell as home appliances, smart home is an emerging application\
    \ [17]. A smart \nhome provides many features for the user like measuring home\
    \ conditions (i.e., \nlight intensity, temperature, heating, etc.), operate home’s\
    \ Heating, Ventilating, \nand Air Conditioning (HVAC) appliances and control them\
    \ with reduced human \ninteraction [18]. Paper [19] presents an example of procedure\
    \ to develop a smart \nhome by combining IoT with cloud computing and web services,\
    \ use a platform \nfor implanting intelligence in actuators as well as in sensors\
    \ and facilitates \ninteraction within smart things using cloud services.  \n\
    \ \nH. Weather Forecasting  \n \nTo predict the state of the atmosphere for a\
    \ future time and for a given \nlocation, weather forecasting is very important.\
    \ Weather forecasting and \nmonitoring consist of a collection of data, assimilation\
    \ of data, and forecast \npresentation. Sensors at weather station used to sense\
    \ humidity, temperature \nwind speed, the moisture of soil, the intensity of light,\
    \ radiation, etc. Data coming \nfrom these sensors is huge in size and difficult\
    \ to monitor. The integration of this \nsensor infrastructure with cloud increases\
    \ its storage and computational \ncapabilities. It also provides effective solutions\
    \ for monitoring and presentation \nof data [20].  \n \nI. Health Care  \n \n\
    Sensors of pervasive healthcare applications make use of cloud computing \nand\
    \ IoT to allows a machine-to-machine communication regardless of the \nlocation\
    \ [21]. Nowadays, in modern hospitals, various body sensors are used to \nmeasure\
    \ and monitor physiological data of the patients. This sensitive collected \n\
    data is maintained for future diagnosis of patient. In some hospitals, this data\
    \ is \nmaintained at the local database. Due to this, doctors who are called to\
    \ handle \n \n6 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \ncritical cases\
    \ unable to analyze disease. After visiting to the patient only they can \ngive\
    \ proper treatment. However, using the cloud service, this issue can be solved\
    \ \ni.e., data of patients can be maintained and shared with doctors who are abroad,\
    \ \nso that they can treat the patient, independent of location [22].  \n \n1.1.2\
    \ IoT monitoring and controlling \n \nThe rising trends of the Internet of Things\
    \ (IoT) paradigm are attracting \nincreasing attention from both academia and\
    \ industry for their highly emerging \napplications of smartly connecting the\
    \ surrounding things or objects without \nhuman intervention [23]. Collecting\
    \ information from the surrounding \nenvironment to analyze, control, and making\
    \ correct action is the main idea for   \nIoT. To interchange data, IoT resources\
    \ using internet makes use of multiple \ninterconnected technologies like wireless\
    \ sensor network (WSN) and radio \nfrequency identification (RFID). IoT consists\
    \ of smart objects, which can be read, \nlocate, address, and control through\
    \ the internet using RFID, wireless LAN, or   \nsome other means [24]. In recent\
    \ time, IoT is getting more attention due to the \nadvancement of wireless technology.\
    \ The basic idea is due to variety of objects \nsuch as Sensors, RFID, actuators,\
    \ Near Field Communication (NFC), mobile \nphones, etc., which can interact with\
    \ each other by having a distinct address. \nArtificial Intelligence (AI) may\
    \ greatly support Internet of things in different \nways for physical (PHY), data\
    \ link (MAC), network, transport, and application \nlayers. AI cloud computing\
    \ is the fusion of machine learning (ML) capabilities of \nAI with cloud-based\
    \ computing environments, enabling connected, and intuitive \nexperiences. AI\
    \ has become more affordable through the use of cloud platforms. \nThe affordable\
    \ cost, coupled with cloud providers promoting AI as having a \nwidespread value,\
    \ leads to concerns that the technology will be misapplied. \nThere are different\
    \ IoT architectures adopted in research and development \nworks. The three-layer\
    \ IoT architecture shown in Figure 1.1, consists of a sensing \nor device layer,\
    \ which is also call as physical object layer whose main purpose is \nsensing\
    \ and data collection [25]. The second layer is the edge layer, its role is to\
    \ \nperform data transmission over the network, including sometimes being \nresponsible\
    \ for preprocessing and data storage before sending the data to the \ncloud. The\
    \ edge layer is also an appropriate place for ML deployment, allowing \nthe frameworks\
    \ to be implemented using hybrid architectures. \nA layer exists for the primary\
    \ processing of data. Data can be stored and \nprocessed by high-performance servers.\
    \ Predictive maintenance (PM) can \nmonitor machine health to determine likely\
    \ component failure. ML optimization \nmodels are deployed to help make intelligent\
    \ decisions about which production \nparameters to monitor. \n \n \n7 \n \nSmart\
    \ IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \n \nFigure 1.1. A three-layer IoT architecture\
    \ based on: Device, Edge and Cloud for Predictive \nMaintenance (PM) [25]. \n\
    \ \n \n1.1.3. Advantages of Using AI in the cloud \n \nAI technology is being\
    \ applied in most cloud services to drive interest in \napplication development.\
    \ Typical offerings combine the ability to leverage AI \nservices at a lower cost\
    \ with important data management systems that provide \nthe source of the data,\
    \ and thus the source of the models.  \nCloud-based AI solutions are different;\
    \ however, they have some \ncommonalities, as well as benefits and limitations.\
    \ First of all, the great benefit is \nthat these systems are inexpensive to operate.\
    \ To drive an AI application, \npayment can be made per hour used of each service.\
    \ This is perhaps the largest \nbenefit of cloud AI, really bringing AI down to\
    \ the level of a basic enabling \ntechnology. \nPublic clouds also offer cheap\
    \ data storage. Real databases or storage systems \ncan be leveraged as data input\
    \ into AI applications. Finally, they all provide SDKs \nand APIs that allow us\
    \ to integrate AI features directly into applications, and they \nsupport most\
    \ programming languages. \nWhile AI is a technology that allows a machine to simulate\
    \ human behavior, \nML is a subset of AI that allows a machine to automatically\
    \ learn from prior data \nwithout explicit programming. ML as a service (MLaaS)\
    \ is an umbrella concept \n \n8 \n \nSmart IoT Monitoring and Real-Time Control\
    \ Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \nof various cloud-based platforms that cover most infrastructure issues such\
    \ as \ndata pre-processing, model training, and model evaluation, with further\
    \ \nprediction. \nML offers several advantages, including accurate predictions,\
    \ speed, \nautomation, and scalability [26]. The ML method uses algorithms to\
    \ analyze data, \nfind rules and abstract the rules into models to classify and\
    \ predict unknown \ndata. It can significantly enhance the efficiency of data\
    \ processing and the \naccuracy of prediction results by applying machine learning\
    \ methods to \nmonitoring complex IIoT data. Furthermore, it can also detect abnormal\
    \ \nconditions of the IIoT to the greatest extent possible and reduce the loss\
    \ of \nproperties and lives [27]. On the one hand, Deep learning (DL) structures\
    \ the \nalgorithms into multiple layers in order to create an “artificial neural\
    \ network \n(ANN)”. Complex DL models are being developed, and in addition, CE\
    \ research \nis accelerating to provide more computational resources for DL models\
    \ to \nsupport more applications [28]. Prior to the use of ML in IIoT, the cognitive\
    \ ability \n(to learn the environment) of machines was simply a predefined heuristic.\
    \ \nHowever, sophisticated ML algorithms have improved the cognitive capability\
    \ \nby finding patterns in the data and making predictions [29]. \n \n1.1.4. Constraints\
    \ \n \nIoT is a novel paradigm to interconnect massive wireless devices, which\
    \ has \nthe potentials to be applied in diverse applications and fields. However,\
    \ due to a \nhuge number of wireless devices in IoT networks, many technical challenges\
    \ \nneed to be addressed, Figure 1.2 presents some limitations of current IoT\
    \ \nplatforms. \n \nFigure 1.2 Major limitations of current IoT platforms \n \n\
    \ \n9 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots,\
    \ Visual Recognition and Cloud/Edge \nComputing Services \nBased on the presented\
    \ limitations, there are imperative directions that have \nto be considered in\
    \ the future for IoT research studies. \n \nA. Scalability  \n \nThe growing idea\
    \ of IoT which generates a tremendous amount of data for \nprocessing and storage\
    \ guide to enormous leap in the forthcoming year, and \nhence it becomes insistent\
    \ on making the scalable system. The vast application of \nIoT has increased the\
    \ number of devices being connected to the internet, which \nmeets the concern\
    \ to consider various complications that are arising in \nconnectivity [25]. Different\
    \ sources like the internet, social media, machine, and \nmany other devices generate\
    \ data. Thus, special attention must be given for \ntransportation, access, storage,\
    \ and processing of these large sets of structured \nand unstructured digital\
    \ data [25].  \n \nB. Interoperability  \n \nAs the data sharing among smart devices\
    \ is increasing day by day, it is \nnecessary to manage these data transfer properly\
    \ among the system [30]. \nInteroperability can be considered as the potentiality\
    \ of two systems to \ncommunicate, exchange information, or program, or transfer\
    \ the data among \neach other and to implement the given data [31]. It is the\
    \ exchange of information \namong different computers through wide area networks\
    \ or local area networks. \nIt is critical for IoT as most of the communication\
    \ takes place as a machine to \nmachine [32]. \n \nC. Real-Time (Delay)  \n \n\
    Meeting real-time latency requirements depends on how data is collected \nand\
    \ processed [33]. This becomes more severe as IoT applications that involve \n\
    rich data types such as images evolve. In addition, developing real-time analytics\
    \ \nin the cloud is nearly impossible to achieve. \nA variety of IoT applications\
    \ require local analytics. For instance, in the \ncontext of IIoT, to quickly\
    \ turn on or off a piece of equipment in a production \nenvironment can prevent\
    \ a catastrophic situation. Analytics depend on ML \nalgorithms that are computationally\
    \ expensive for some tiny sensors. In addition, \nthe power consumption of small\
    \ sensors has been one of the main concerns even \nbefore the emergence of ML\
    \ in IoT. Thus, achieving the goal of real-time with a \nsensor cloud architecture\
    \ seems ambitious. \nThe limited computational capacity of sensor nodes is a major\
    \ challenge. \nTherefore, a hybrid architecture to implement computationally intensive\
    \ tasks \nsuch as training on the cloud and model deployment for prediction on\
    \ the \nsensing node has emerged. However, this approach also presents challenges\
    \ in \n \n10 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \nthe case where\
    \ models require retraining based on new data. In this case, all new \ndata must\
    \ be moved to the cloud, which incurs costs in terms of latency, energy \nconsumption,\
    \ and network resource usage [34]. \n \nD. Accuracy  \n \nThere are many possibilities\
    \ for designing a Neural Network (NN) model, \nprovided that different hyperparameters\
    \ in the network provide a different level \nof accuracy. Particularly, a high\
    \ accuracy model requires more memory than a \nlow accuracy model due to the number\
    \ of parameters. The metric used to \nmeasure accuracy depends on the domain in\
    \ which the ML algorithm is applied. \nIn IIoT, a traditional approach to data\
    \ collection is to stream data from \nsensing devices to the cloud where it is\
    \ processed and modeled. Sensing devices \ngenerate huge amounts of data, continuously\
    \ or periodically, often in a very short \nperiod of time. For instance, in one\
    \ second, thousands of records can be generated \nby one machine [35]. According\
    \ to the Cisco cloud index (2013-2018), an \nautomated facility can generate one\
    \ terabyte of data per hour. For this purpose, \napproaches such as sampling,\
    \ compression, filtering are used to reduce the size \nof data. These techniques\
    \ reduce the amount of data transmitted to the cloud. \nHowever, there are potential\
    \ accuracy trade-offs for ML models that use reduced \ndatasets, as the accuracy\
    \ of ML models depends primarily on the data collected. \nThe accuracy of models\
    \ trained on reduced data should also be a concern \nwhen optimizing for energy\
    \ consumption and latency. This is more important in \ndeep learning approaches\
    \ that require more data to be trained. \nIn current IIoT systems based on edge\
    \ computing, edge devices can only \nperform lightweight computing tasks. To enable\
    \ edge devices and servers to \nperform more complex tasks with higher data processing\
    \ performance and lower \nlatency, edge intelligence (EI) is applied to the IIoT\
    \ edge to make the devices and \nservers intelligent. However, an AI model can\
    \ be trained to make predictions and \ndecisions with high accuracy; however significant\
    \ amounts of training and \nverification data are required. For edge devices,\
    \ training and operating the AI \nmodel is challenging due to limited computing\
    \ and storage resources. \n \nE. Security  \n \nAs the IoT trend inflates multiple\
    \ interconnections and device heterogeneity, \nit eventually generates cyber-attacks.\
    \ Thus, data security is one of the most \ncritical issues. As there is an increase\
    \ in the number of connected devices, there \nare possibilities of cyber-physical\
    \ security vulnerabilities that can be exploited by \nvarious attackers [36].\
    \ Security is a key pillar of the internet, which is the main \nchallenge of IoT.\
    \  \nTherefore, it is necessary to learn from these incidents: industries are\
    \ now the \ntarget of attackers and there is an urgent need to address this issue.\
    \ IIoT is \n \n11 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \nsometimes thought\
    \ of as the integration of operational technology (OT) and \ninformation technology\
    \ (IT), with OT comprising the factory network where \nmanufacturing is performed\
    \ and IT comprising the enterprise network [37]. \nThese two components have different\
    \ security requirements, which must be \naddressed to prevent compromise of the\
    \ IIoT infrastructure. \n \n1.2 Motivation  \n \nAlthough IoT has been widely\
    \ used in the above applications, a number of \ncritical limitations have hindered\
    \ the use of AI in various implementations. These \nlimitations tend to mainly\
    \ affect the system response time and the efficiency of \nthe proposed solution.\
    \ The various aspects of DL that need to be improved in an \nIoT concept include\
    \ smart algorithms with improved efficiency and support for \nbetter platforms.\
    \ For this reason, the following issues had to be investigated to \novercome these\
    \ limitations of using AI in IoT architecture. \n \nA. Interoperability \n \n\
    Recent advances in manufacturing technology, such as industrial internet, \ncyber–physical\
    \ systems, AI (Artificial Intelligence), and machine learning have \ndriven the\
    \ evolution of manufacturing architectures into integrated networks of \nautomation\
    \ devices, services, and enterprises. One of the resulting challenges of \nthis\
    \ evolution is the increased need for interoperability at different levels of\
    \ the \nmanufacturing ecosystem. Interoperability means the ability of two or\
    \ more \nparties, machine or human, to make a perfect exchange of content.  \n\
    The IoT is a dynamic global network infrastructure with self-configuring \ncapabilities\
    \ based on interoperable, standard communication protocols, enabling \nall objects\
    \ to communicate with each other. The application of IoT to the \nindustrial domain\
    \ has given rise to a new research area called the Industrial \nInternet of Things\
    \ (IIoT). IIoT is a new service-oriented industrial ecosystem that \nuses networked\
    \ interconnection of industrial resources, data interoperability, \nand system\
    \ interoperability to enable flexible resource allocation, rational \nprocess\
    \ optimization, on-demand process execution, and rapid adaptation of \nenvironments\
    \ [38]. In general, interoperability is defined as the ability of \nheterogeneous\
    \ networks, applications, or computer components to exchange and \nuse information,\
    \ i.e., to speak and comprehend each other [39]. Suited to the IoT \ncontext,\
    \ this refers to the ability of heterogeneous components to exchange and \nshare\
    \ data and functions to achieve a desired goal (defined by a use case or \napplication),\
    \ regardless of the communication protocol used or the format of the \nexchanged\
    \ data.  \nUp to only a few years ago the communication systems for industrial\
    \ \nautomation aimed only at real-time performance suitable for industry and \n\
    \ \n12 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots,\
    \ Visual Recognition and Cloud/Edge \nComputing Services \nmaintainability based\
    \ on international standards [40]. The Industry 4.0 concept \nhas the flexibility\
    \ to achieve interoperability between the different industrial \nengineering systems.\
    \ To connect the different industrial equipment and systems, \nthe same standards\
    \ and safety levels are required. Open Platform \nCommunications Unified Architecture\
    \ (OPC UA) is a machine-to-machine \n(M2M) communications protocol developed to\
    \ create inter-operable and reliable \ncommunications and is now generally accepted\
    \ as standard in industrial plant \ncommunications [41].  \nThe domain extends\
    \ from software, devices, and control systems on the \nfactory floor to Internet-based\
    \ cloud platforms that provide various on-demand \nservices. \nA successful implementation\
    \ of interoperability in smart manufacturing \nwould therefore result in efficient\
    \ communication and error-free data exchange \nbetween machines, sensors, actuators,\
    \ users, systems and platforms. The \narchitecture and platforms used by machines\
    \ and software packages are a major \nchallenge in this regard. A better understanding\
    \ of the subject can be obtained by \nstudying industry-specific communication\
    \ protocols and their respective logical \nsemantics.  \nTo be more precise and\
    \ in accordance with [42], three levels of \ninteroperability can be specified\
    \ to achieve horizontal interoperability between \ndifferent components, each\
    \ level covering a different facet of interoperability and \ncommunication: \n\
    \ \n• Technological interoperability is given if the two components are physically\
    \ \nconnected to each other and can transmit any type of information on the \n\
    transmission layer [42]. This level of interoperability concerns the lower \n\
    transmission layers of the OSI model (i.e., the physical, data link, network and\
    \ \ntransport layers) and the corresponding protocols. \n \n• Syntactic interoperability\
    \ is ensured if the data format, including encodings, \nas well as the communication\
    \ interface format are clearly defined and agreed \nupon between the two components\
    \ [42]. The abstract term \"communication \ninterface format\" refers to the protocol\
    \ used on the application layer and \nprovided as communication interface by the\
    \ respective component. As with \ntechnological interoperability, it is not necessarily\
    \ required that the two \ncomponents agree on the same protocol, as long as there\
    \ is a possibility of \nadapting two different protocols (the same applies to\
    \ the format and encoding \nof the data embedded in the protocol(s)). \n \n• Semantic\
    \ interoperability is ensured if both components agree on the same \ninformation\
    \ model describing the topic of the exchanged information as well \nas the provided\
    \ communication interfaces [42] (i.e., the meaning of the \nexchanged messages\
    \ with respect to the used protocol). \n \n13 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \n \nFigure 1.3 depicts the mapping of these three interoperability\
    \ levels defined \nin [42] to the OSI layers. It should be noted that this mapping\
    \ is not strict and that \nthe boundaries between the OSI layers may vary depending\
    \ on the \nimplementation of the application concerned. \n \n \nFigure 1.3 Mapping\
    \ of interoperability levels to OSI layers \n \n \nThe evolution from traditional\
    \ hierarchical models of enterprise control \nsystem integration, or automation\
    \ pyramid, to integrated networks of smart \ndevices, \ncloud \nservices, \nand\
    \ \nextended \nenterprises \nrequires \nseamless \ncommunication and information\
    \ exchange between heterogeneous and \ntraditionally silent systems (Figure 1.4).\
    \  \nDifferent types of interoperability problems may arise, due to the diverse\
    \ \nnature of interactions in the emerging automation networks. Thus, there is\
    \ a need \nfor vertical interoperability between devices and shop floor automation\
    \ services, \nas well as horizontal interoperability between enterprises and cloud\
    \ service \nplatforms. \n \n \n \n \n14 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \n \n \nFigure 1.4. Automation Pyramid vs Automation Network [43] \n\
    \ \n \nB. Low-latency and ultra-Reliability \n \nThe industrial smart facility\
    \ requires multiple synchronized processes that \nrequire low latency and higher\
    \ reliability to achieve the necessary performance \n[44]. Furthermore, AI methods\
    \ applied to IIoT must be able to address these \nissues as well as other parameters\
    \ such as network deployment and resource \nmanagement [45]. Nevertheless, the\
    \ competence and usefulness of DL-based IIoT \nscenarios are still in the evolutionary\
    \ phase, requiring exclusively the strict low-\nlatency and ultra-reliability\
    \ requirements of IIoT. Therefore, further research \nefforts are needed in this\
    \ direction to establish a theoretical and practical \nbackground for DL-IIoT\
    \ to ensure low-latency and ultra-reliable communication. \nFast and efficient\
    \ computing is another key feature that can affect not only \nlatency and reliability\
    \ but also many other performance parameters in smart \nindustries. As mentioned\
    \ earlier, IIoT requires powerful and useful tools to \ncompute big data obtained\
    \ from various processes and analyze them on specific \nplatforms including servers,\
    \ transmission media, and storage. \nIntelligence at the edge should push DL computations\
    \ from the cloud to the \nedge as much as possible, enabling various distributed,\
    \ low-latency and reliable \nintelligent services, as shown in Figure 1.5. \n\
    \ \n15 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots,\
    \ Visual Recognition and Cloud/Edge \nComputing Services \nDL services can be\
    \ deployed close to the requesting users and the cloud only \nintervenes when\
    \ additional processing is required [46], which significantly \nreduces the latency\
    \ and cost of sending data to the cloud for processing. \n \n \n \nFigure 1.5.\
    \ Capabilities comparison of cloud, on-device and edge intelligence [47] \n \n\
    Currently, hybrid cloud-edge computing is used to perform fast and efficient \n\
    computation and provides a comprehensible computing infrastructure for IIoT. \n\
    It is considered appropriate to use the edge-based computing infrastructure due\
    \ \nto its ability to reduce latency and improve the learning process in the network.\
    \ \nNonetheless, the integration of distributed and edge computing infrastructure\
    \ \nfor IIoT remains an open research issue [48]. Particularly, the coupled realization\
    \ \nof distributed and parallel learning for edge-based designs requires further\
    \ \noptimization to attain higher productivity, self-organization, and lower runtime.\
    \ \n \n \nC- Energy consumption of mobile IoT devices \n \nRobotic engineering\
    \ systems are deployed in industry today and are \nconsidered vital to the progress\
    \ of humanity from an industrial perspective in \nthe new digital age. \nThe Internet\
    \ of Robotic Things (IoRT) empowers robotic objects in different \nenvironments\
    \ to be active players in various applications and to share and \nexchange information\
    \ with other robotic objects, IIoT devices and humans. IoRT \napplications are\
    \ developing in parallel with IIoT advancements, combining \ninformation technology\
    \ (IT) used for data-centric computing and operational \n \n16 \n \nSmart IoT\
    \ Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \ntechnology (OT) used in enterprise and\
    \ industrial operations integrating \nsupervisory control and data acquisition\
    \ (SCADA) systems and programmable \nlogic controllers (PLCs), where industrial\
    \ applications are increasingly \nintegrated, and where new smart connectivity\
    \ networks are used.  \nTransferring large datasets to a central cloud is an energy-intensive\
    \ \noperation, and new computing paradigms are being used and implemented for\
    \ \nIoRT applications. Smart connectivity networks can facilitate the transfer\
    \ and \nprocessing of information in an energy-efficient and high-performance\
    \ manner. \nHowever, deployed batteries have a specific charge rate and, therefore,\
    \ the \noperating time of robots is limited. Autonomous mobile robots are powered\
    \ by \nbatteries mounted on their platforms to provide energy to the on-board\
    \ sensors, \nmicrocontrollers, peripheral modules and servos.  \nDevelopments\
    \ in IoT, AI, and connectivity technology [49] enable IoRT \napplications to reduce\
    \ power consumption and improve energy efficiency, \nresulting in lower costs\
    \ and latency. Energy efficiency, real-time processing, \ncomputation, and analysis\
    \ efficiency of IoRT devices, efficient task offloading, \nand intelligent service\
    \ response time of other IoRT devices and agents must be \naddressed by developing\
    \ new collaborative processing techniques at the edge. \nAlong with ensuring dynamic\
    \ network/resource slice management, dynamic \ndevice management, and the necessary\
    \ containment between different IoRT \ndevices and different complex applications.\
    \ \n \n1.3 Objectives and contributions \n \nThe objective of this thesis is to\
    \ develop and evaluate a real-time IoT \nframework capable of connecting AI cloud\
    \ services with different industrial \nsystems and platforms, trying to overcome\
    \ the limitations and challenges \nshowed in previous sections. Therefore, the\
    \ required systems and networks must \nensure the optimal trade-off between response\
    \ time and system accuracy, \nkeeping in mind that cloud computing is introduced\
    \ in the control loop. In this \ncontext, the main objectives of this work are:\
    \ \n \n1. The design of an IoT architecture to enable interoperable systems \n\
    connecting different IoT devices using different protocols and technologies, \n\
    together with the different proposed systems and networks. To this end, some \n\
    considerations were considered: \n \n \n- \nProtocols and software suitable for\
    \ interoperability and connectivity \nconstraints: The interoperability challenge\
    \ can be overcome by using \nadvanced software deployed in the IoT gateway, which\
    \ can be considered \nas the junction interface between the physical and cloud\
    \ worlds. This \n \n17 \n \nSmart IoT Monitoring and Real-Time Control Based On\
    \ Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services \n\
    software must interact simultaneously with the different systems \ninvolved through\
    \ different protocols.  \n \n- \nThe appropriate devices capable of providing\
    \ minimal response time: The \nchoice of an IoT gateway is crucial in terms of\
    \ latency and accuracy, as it \nis at the heart of processing and transmitting\
    \ data to the different systems \nand platforms. \n \n \n2. To further improve\
    \ the trade-off between latency and accuracy, the \nfollowing points are considered:\
    \ \n \n- \nThe most efficient cloud computing solutions for each use case: The\
    \ \nimplemented cloud services must ensure that data is transferred, \nprocessed\
    \ and returned at speeds that meet the needs of the application. \n \n- \nFlexibility\
    \ to use AI models in the edge and the cloud for improved \nperformance: The ability\
    \ to deploy the cloud AI models at the edge can \nfacilitate the use of cloud\
    \ technologies in different sectors. In addition, the \nhybrid cloud/edge architecture\
    \ must ensure a real-time control loop for \nrelevant latency and accuracy. \n\
    \ \nContributions:  \n \nThe main innovative contribution of this thesis is to\
    \ include cloud services in \na control loop, to improve the decision making of\
    \ a factory and improve the \nperformance of an industrial control system.  \n\
    Cloud AI services can also be integrated into a drone control loop as an input\
    \ \ncontributing to improve the monitoring capability to find and track stationary\
    \ \nand moving objects. To this end, the work in this thesis has been divided\
    \ into \nseveral parts depending on the scenario used. Thus, several contributions\
    \ could \nbe enumerated: \n \n1. The validation of the IoT architecture proposed\
    \ in this thesis in the industry \nas a way to control and monitor the status\
    \ of devices and systems integrating \nIoT protocols and edge-computing \n \n\
    2. The Introduction of cloud services computer vision (CV) techniques as a part\
    \ \nof the industrial control loop to improve the operation of the production\
    \ \nprocess in a factory. \n \n3. The integration of CV cloud services into the\
    \ control loop of a drone for \nmonitoring and seeking for a new object using\
    \ the drone's cameras. \n \n18 \n \nSmart IoT Monitoring and Real-Time Control\
    \ Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \n \n4. The demonstration of that a hybrid AI cloud architecture can solve the\
    \ \nproblem of latency and accuracy of the control system. Choosing the correct\
    \ \nAI CV cloud services is crucial in terms of latency and accuracy of the control\
    \ \nsystem, as the systems need to respond in real time with accuracy.  \n \n\
    5. The use of edge computing topology to reduce latency in low-bandwidth \nenvironments.\
    \ Cloud computing topology improves accuracy at the expense \nof increased latency.\
    \ To meet the system’s requirements, in this thesis, a smart \nalgorithm to optimize\
    \ autonomy is propose and developed. This Is done by \nselecting the appropriate\
    \ AI technology for the scenario being monitored. \nThis proved to be crucial\
    \ in deciding the best source of artificial intelligence \nto be used to achieve\
    \ the specified objectives in each stage in real time. The \nproposed smart algorithms\
    \ ensure a trade-off between latency and accuracy. \n \n6. The validation of the\
    \ proposed IoT architecture for an autonomous marine \nrobot for protection and\
    \ permanent surveillance in marine protected areas \nbased on AI cloud recognition\
    \ services. \n \n \n2.5 Thesis organization \n \nThis thesis is organized and\
    \ divided into 5 chapters. This first chapter has \nbeen dedicated to the presentation\
    \ of IoT, especially Industrial IoT, and the \nchallenges faced in using an IoT\
    \ architecture as the one presented in this thesis. \nMoreover, we discuss the\
    \ constraints and benefits of using AI in the cloud and \nfinally the main motivations\
    \ and contributions of this thesis have also been \nrevealed. The core of this\
    \ thesis is detailed in the following chapters:  \n \n \nChapter 2: Outlines the\
    \ IoT Monitoring and Control Architecture Based on \nUnmanned Vehicles and defines\
    \ some of the protocols adopted in Industrial IoT. \nIt describes also the types\
    \ of IoT architectures, and the use of computer vision \nand AI at the edge using\
    \ cloud services. \n \nChapter 3: This chapter provides an overview of the different\
    \ solutions \nproposed to employ artificial intelligence for monitoring systems\
    \ in an IoT \narchitecture. We start with a review of the state of the art for\
    \ the different AI \ntechniques used for an interoperable IoT architecture. Then,\
    \ a comparison \nbetween the different proposed methods is highlighted. We discuss\
    \ the different \nmethods and factors used to appraise the latency and accuracy\
    \ of the proposed \n \n19 \n \nSmart IoT Monitoring and Real-Time Control Based\
    \ On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \nAI models and finally a latency assessment for an unmanned vehicle IoT \n\
    architecture. \n \nChapter 4: This chapter focuses on monitoring and control applications\
    \ in a \nIoT architecture. This chapter presents different applications using\
    \ advanced \ndevices and robots to control and monitor areas using computer vision\
    \ and AI \ncloud services. The proposed AI approaches are compared in terms of\
    \ latency \nand accuracy to validate their performance.  \nThe first application\
    \ was about a wind power system connected to the IBM \ncloud for monitoring. The\
    \ second application was to feed results from AI services \nin the cloud into\
    \ an industrial control loop. The AI results come from an \nunmanned aerial vehicle\
    \ camera taking images of materials being transported in \na concrete plant. The\
    \ other application, proposes an AUV model system designed \nto track a species\
    \ of Mediterranean fan mussel, using cloud computing services \nwith edge computing\
    \ as alternative processing units. \nThe latter, proposes an autonomous marine\
    \ robot for protection and \npermanent surveillance in marine protected areas\
    \ based on AI cloud recognition \nservices. \n \nChapter 5: Summarizes the contributions\
    \ of the whole thesis and outlines \nsome directions for future work. \n  \n \n\
    \ \n \n20 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \n \nCHAPTER\
    \ 2 \n \n \n \n-------------------------------------------------- \n \nPerformance\
    \ analysis of IoT Monitoring \nand Control System Based on UV, \nMachine Vision\
    \ and Artificial \nIntelligence \n--------------------------------------------------\
    \ \n \n \n \n \n2.1 Introduction  \n \nAutonomous vehicles have played an increasingly\
    \ important role in \nmonitoring different environments, they are now considered\
    \ one of the best \nremote sensing techniques for collecting data over large areas.\
    \ They are now used \nin different sectors as detection tools to proactively solve\
    \ or prevent many \nproblems. In industry, as an example, unmanned aerial vehicles\
    \ (UAVs) can be \nused for inspections [50], to quantify production and monitor\
    \ construction \nprocesses [51] \nand help make decisions.  \nAutonomous underwater\
    \ vehicles (AUVs) are widely used in various marine \napplications: visual inspection\
    \ of infrastructures [52], aquaculture [53], marine \nbiodiversity mapping [54],\
    \ marine geoscience [55], and visual monitoring of \nmarine life [56] and recovery\
    \ of autonomous underwater vehicles [57]. \nUSVs are currently the subject of\
    \ a number of publications related to ocean \nmonitoring applications related\
    \ to weather/storm forecasting and disaster \n \n21 \n \nSmart IoT Monitoring\
    \ and Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \nmanagement [58]. They can play a critical role in disaster\
    \ research [59] by \nreplacing rescue teams in remote and dangerous areas [60],\
    \ or by monitoring \ncovered environmental areas such as water bodies [61], or\
    \ by performing long-\nterm monitoring [62]. AI has the potential to be a powerful\
    \ tool and be deployed \nfor marine area surveillance by detecting and recognizing\
    \ vessels through \nartificial intelligence (AI)-based image recognition services.\
    \ \nComputer vision (CV) has particularly improved the field of object detection\
    \ \nand image classification. Visual recognition systems can reach impressive\
    \ \nperformances, thanks to the latest developments in neural networks, in particular\
    \ \ndeep learning (DL). Although all the developed DL algorithms can be deployed\
    \ \nin the cloud, the present cloud computing systems are unable to manage and\
    \ \nanalyze the massive amount of computing power and data. Edge intelligence\
    \ is \nenvisioned to replace DL computing in the cloud, providing a variety of\
    \ reliable, \nlow latency, distributed intelligent services. \n The IoT gateway\
    \ is used to connect the autonomous vehicles and control \nsystems to the internet\
    \ and cloud services, it is able to connect the sensor network \nto the cloud\
    \ computing infrastructure and perform edge and fog computing and \nserves as\
    \ a bridge between sensor networks and cloud services.  \nIntegrating autonomous\
    \ robots into the IoT represents an interoperability \nchallenge, as every IoT\
    \ system has its own communications protocol. Moreover, \na small error or delay\
    \ beyond the tolerated limit could result in a disaster for \nvarious applications.\
    \ The IoT gateway must not only address the challenge of \ninteroperability of\
    \ interconnected systems but also process and transmit data in \nreal-time. \n\
    The current cloud computing system is increasingly unable to cope with the \n\
    massive amount of data it receives [63]. Edge computing, which is composed of\
    \ \nsmart nodes and could take the place of cloud processing, is expected to solve\
    \ \nthis problem since it is closer to the users than the cloud [64]. These smart\
    \ nodes \nrange from smart gateways to offsite ruggedized nodes, to on-premises\
    \ heavy \nstorage nodes and data center servers at the edge. \nNew architectures\
    \ have recently been proposed to address the latency issue. \nA hybrid cloud/edge\
    \ architecture can provide a real-time control loop for better \nlatency and accuracy\
    \ and meet several system requirements. \nThis chapter begins with a description\
    \ of the architecture of three IoT layers, \nand its main components, from data\
    \ detection to its processing. It describes \nseparately the technology used in\
    \ each layer for different use cases. We discuss \nthe use of computer vision\
    \ techniques at the edge and in the cloud, and the effect \nof interoperability\
    \ and real-time requirements. Finally, we end the chapter by \npresenting the\
    \ different cloud APIs used. \n \n2.2 UV IoT architecture \n \n \n22 \n \nSmart\
    \ IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \n2.2.1. Most Common IoT Architectures \n\
    \ \n1. Common IoT Architectures \n \nOne of the main challenges in the technology\
    \ domain to support the \ndeployment of IoT systems is to define a reference architecture\
    \ that supports both \ncurrent and future features. Therefore, such an architecture\
    \ must be: -scalable, -\ninteroperable, -distributive, -able to operate with few\
    \ resources (Computational \npower) -secure so as not to allow unauthorized access.\
    \ \nCurrently, a single reference architecture does not exist, and creating one\
    \ is \nvery complicated regardless of many standardization efforts. One of the\
    \ main \nproblems is related to the natural fragmentation of possible applications,\
    \ each of \nwhich depends on many different variables and design specifications.\
    \ Figure 2.1 \ndescribes some of the most common IoT architectures. \n \n \nFigure\
    \ 2.1. Most common IoT architectures [67] \n \n2. Three-Layer architecture  \n\
    \ \n- Perception, represents the physical layer of the objects and includes all\
    \ the \nfeatures. \n- Network, that stands for the communication layer responsible\
    \ for the \ntransmission of data to the application layer through various protocols\
    \ and \ntechnologies. \n- The application, which is the application layer in which\
    \ the software offering a \nspecific service is implemented. \n \n \n23 \n \n\
    Smart IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual\
    \ Recognition and Cloud/Edge \nComputing Services \n \n3. Service-oriented architecture\
    \ \n \nIt represents the four-layer IoT architecture based on SoA, in which there\
    \ is \nthe perception layer, the network layer, the service layer and finally\
    \ the \napplication layer. The SoA is designed to coordinate services and enable\
    \ the reuse \nof hardware and software components. Generally, SoA is based on\
    \ a component \nmodel, which can be designed to connect different functional units\
    \ of \napplications through interfaces and protocols [65-66-67]. \nSoA can be\
    \ easily integrated into the IoT architecture, by extending the three-\nlayer\
    \ architecture, by adding a new layer between the network layer and the \napplication\
    \ layer, called the service layer, which provides services to support the \napplication\
    \ layer. \n \n4. Middleware Architecture \n \nAnother important and very common\
    \ architecture in IoT is the middleware-\nbased IoT architecture or five-layer\
    \ architecture [68]. A five-layer is composed of \nfive levels: perception layer,\
    \ network layer, middleware layer, application layer, \nand business layer. \n\
    Middleware is gaining more and more importance in recent years due to its \nmajor\
    \ role in simplifying the development of new services and integrating legacy \n\
    technologies into new ones.  \nA proposed IoT architecture has to consider many\
    \ factors such as reliability, \ninteroperability, scalability, quality of service,\
    \ etc. In this regard, middleware \nbased IoT architectures help create applications\
    \ more efficiently; they act as a \nconnection between users, data and applications.\
    \ \nMiddleware, in general, is a software or programming service that can \nprovide\
    \ an interposed abstraction between IoT technologies and applications. In \nmiddleware,\
    \ the details of the different technologies are hidden, and standard \ninterfaces\
    \ are provided to allow developers to focus on application development \nwithout\
    \ regard to compatibility between applications and infrastructures. \nMiddleware\
    \ architecture has various advantages, as it can support various \napplications,\
    \ standard protocols, provides standard interfaces and can run on \nvarious operating\
    \ systems and platforms. Middleware plays an important role in \nstandardization,\
    \ providing portability and standard protocols to enable \ninteroperability and\
    \ interaction of services between heterogeneous networks, \ndevices and applications.\
    \ \nMiddleware supports distributed computing and provides a stable high-\nlevel\
    \ interface for applications. \nRegardless, the middleware layer has some critical\
    \ functionality, such as \naggregation and filtering of data received from hardware\
    \ devices, information \nretrieval and device access control for applications.\
    \ \n \n24 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \nIn summary,\
    \ depending on the application, it may be necessary to add \nadditional layers\
    \ or adapt the architecture to the specific application to be \nrealized. An architecture\
    \ can be realized by being adapted to the context of \nexisting IoT architectures,\
    \ such as a server-based architecture, or an architecture \nbuilt from scratch\
    \ such as cloud-based architectures, Edge computing-based \narchitectures, or\
    \ Social Internet of Things (SIoT) architectures [67]. \n \n2.2.2. IoT Monitoring\
    \ and Control Based on Unmanned Vehicles \n \nA drone monitoring system is developed\
    \ as a control system to reduce the \ntime and cost of inspection. The integration\
    \ of drones or unmanned vehicles into \nthe IoT architecture can be presented\
    \ in three layers (Figure 2.2), with drones \nbeing part of the first layer as\
    \ the data generation layer. The first layer can also \ncontain a control system\
    \ connected to a central collection point, which is the IoT \ngateway. The second\
    \ layer is edge/fog computing for computation, storage and \ncommunications. The\
    \ last layer is a cloud back-end with image processing \ntechniques. The Edge/fog\
    \ layer connects the control layer to the drone system, \nthe drone system to\
    \ the cloud, and finally the cloud to the control system. \n \nIn general, the\
    \ Three-Layer architecture can be defined as below:  \n \n• Generation and control\
    \ layer: this represents the physical layer of the objects \nand includes all\
    \ the control systems. \n• Network and data communication layer (Edge/Fog): this\
    \ is the \ncommunication layer responsible for transmitting data to the visualization\
    \ \nand processing layer through various technologies and protocols, can also\
    \ be \nused as a processing layer in case of real time applications. \n• The visualization\
    \ and processing layer, which represents the application layer \nin which the\
    \ software offering a specific service is actually implemented or \nmay just be\
    \ an interface to analyze and visualize the data received from the \nconnected\
    \ systems. \n \n \n \n25 \n \nSmart IoT Monitoring and Real-Time Control Based\
    \ On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \n \n \nFigure 2.2. Industrial UV-IoT Architecture \n \n \nThe control system\
    \ (controllers) receives data from remote or connected \nsensors that measure\
    \ the process variables’ (PVs) setpoints (SP). When the system \ndetects a trend\
    \ change between PVs and SP, the change is routed to the \nprogrammable logic\
    \ controllers (PLCs) and the central point (IoT gateway) to \ntrigger the UV system’s\
    \ reaction. \nThe traditional monitoring system illustrated by humans is replaced\
    \ by a \nremote computing algorithm in the cloud and a UV system, in that the\
    \ UV camera \nserves as an additional monitoring sensor that is processed in the\
    \ cloud to imitate \nthe visual inspection of an operator. The UV can navigate\
    \ to a specific point to \noversee the process using the front camera. The UV\
    \ system is triggered \nautomatically by responding to sensor data from the monitoring\
    \ system and data \nanalyzed in the IoT gateway. The IoT gateway receives the\
    \ captured photos and \nsends them to the cloud, which adopts deep learning techniques\
    \ to analyze and \nsend the results to the IoT gateway and the control system\
    \ to confirm the \nanomaly and make the necessary changes. \n \n2.2.3 IoT Gateway\
    \ Capabilities \n \nThe IoT gateway is capable of connecting the sensor network\
    \ to the cloud \ninfrastructure, performing edge computing, and serving as a bridge\
    \ between the \nsensor networks and cloud services [69]. \n \n26 \n \nSmart IoT\
    \ Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \nIn the IoT gateway, various software and\
    \ APIs can be installed to establish \nthe connection with different parts of\
    \ each IoT layer. It also allows collecting, \nprocessing, and transmitting the\
    \ data and results to other systems for further \nprocessing or decision making.\
    \ \n In the IoT gateway, various IoT software and APIs, drone libraries and AI\
    \ \nmodels can be installed. These packages are required to ensure the transmission\
    \ \nof data between the different systems according to the protocols involved.\
    \ Since \neach IoT system has its own communication protocol, the IoT gateway\
    \ has to \nsupport different communication protocols, which presents an interoperability\
    \ \nchallenge. \nAn IoT gateway can be defined as a physical device with software\
    \ programs \nand protocols that mediate between smart devices, sensors, controllers\
    \ and the \ncloud. The IoT gateway provides the necessary connectivity, security\
    \ and \nmanageability, while some of the existing devices cannot share data with\
    \ the \ncloud [70]. \n \n2.4 \nUV & IoT Protocols \n \n2.3.1 UV Protocols \n \n\
    Unmanned vehicles (UVs) are widely used for civilian and military \napplications.\
    \ They can be used for remote sensing, transportation, scientific \nresearch,\
    \ search and rescue, and armed attacks. They can be used in applications \nwhere\
    \ human presence is dangerous, or in repetitive surveillance and monitoring \n\
    tasks. Unmanned vehicles can be equipped with sensors, cameras, \ncommunication\
    \ equipment and weapons.  \nUVs are primarily equipped with omni-directional antennas,\
    \ although \ndirectional antennas can also be used to increase the gain of the\
    \ \ntransmitter/receiver, at the cost of designing a mechanism to control the\
    \ direction \nof the antenna.  \nUnmanned vehicles (UVs) can operate autonomously\
    \ or be remotely piloted \nby ground teams. UVs can communicate with the base\
    \ station using different \nprotocols, depending on the network structure and\
    \ the design of the UV system. \nCANbus (CANopen, NMEA2000), Ethernet and WiFi\
    \ (TCP/IP, UDP), RS232, are \nthe most commonly used protocols in autonomous vehicles.\
    \ In this section we \nwill mainly address the CANbus protocol. \n \n \n• CAN\
    \ Protocol \n \nBack in the 1980s, progress in automotive electronics had made\
    \ the number \nof devices that were suddenly required in vehicles grow in a worrying\
    \ way. All \nthese devices had to be connected in some way, generally to each\
    \ other, causing \n \n27 \n \nSmart IoT Monitoring and Real-Time Control Based\
    \ On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \nan alarming increase in the amount of wiring that had to be introduced into\
    \ a \nvehicle (As shown in Figure 2.3). All this led to problems of assembly,\
    \ \nstandardization of equipment, connections and weight. \nIn February 1986,\
    \ Robert Bosch presented CAN (Controller Area Network) \nat the Society of Automotive\
    \ Engineers (SAE) as a solution to the problem of \nwiring in vehicles. Intel,\
    \ as a manufacturer, and Mercedes-Benz, as a collaborator \nin the development\
    \ project, also worked together on developing the bus. \n \n \nFigure 2.3. Wiring\
    \ diagrams in vehicles before and after the appearance of CAN \n \nIn 1987, Intel\
    \ released the first CAN integrated, followed shortly after by \nPhilips Semiconductors.\
    \ After several improvements and disputes with other \nmanufacturers, it became\
    \ a standard (version 2.0) in 1993, the specifications of \nwhich are reflected\
    \ in ISO11898. Although CAN was initially developed for the \nautomotive industry,\
    \ its robustness and the efficiency of its protocol have \nallowed its entry into\
    \ many industrial applications requiring high transfer rates \nand high reliability\
    \ in the face of errors. Manufacturers in fields as diverse as \nelevators (Kone\
    \ in Finland) and textile machinery have used CAN in their \nproducts. \n \n \n\
    28 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots,\
    \ Visual Recognition and Cloud/Edge \nComputing Services \nCAN Characteristics\
    \  \n \nCAN is one of the widest known vehicle bus standards for vehicle networks.\
    \ \nIt is very popular in industrial and automotive applications because of an\
    \ \naffordable and flexible design, which reduces the number of wires. For example,\
    \ \nthe number of wires has been reduced by 40% in the Peugeot 307, which \nincorporates\
    \ two CAN buses [71]. CAN is a message-based protocol; the packets \nhave no information\
    \ about the sender and receiver of the messages, and each \nnode can read the\
    \ messages transmitted over the bus. Functions supported by \nthe protocol in\
    \ the automotive domain are automatic start/stop, parking \nassistance, electric\
    \ parking brakes, collision avoidance, automatic lane detection, \netc. Figure\
    \ 2.4 shows a CAN bus node. It includes a central processing unit (CPU), \nthe\
    \ CAN controller and a transceiver. The function of the CPU is to decode the \n\
    received messages and decide which messages to transmit. Each node can send \n\
    or receive messages, but not simultaneously. A message or frame consists of an\
    \ \nID and a data payload of up to eight bytes (64 bits). \n \n \nFigure 2.4.\
    \ Controller area network bus node \n \nThe network uses two cables as a transmission\
    \ medium. The two cables are \nCAN High and CAN Low. All the system nodes connected\
    \ to the CAN bus \nthrough the corresponding hardware interface. All nodes share\
    \ the same data \nchannel. Each node consists of a CAN Transceiver, CAN Controller\
    \ and CPU as \nshown in Figure 2.5. \n \n \n29 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \n \nFigure 2.5. Node of the CAN bus system \n \nThe CAN protocol is\
    \ optimized for short messages and uses a CSMA/CD \nwith NDBA (Carrier Sense Multiple\
    \ Access / Collision Detection with Non-\nDestructive Bitwise Arbitration) arbitration\
    \ access method. A node that needs to \ntransmit a message waits until the bus\
    \ is free and then starts to send the identifier \nof its message bit by bit.\
    \  \n \n2.3.2 IoT Protocols \n \nThere are a large number of protocols that can\
    \ be used in the IoT. Table 1 \nshows some of the most commonly used protocols,\
    \ grouped according to the \nISO/OSI model. Each has advantages and disadvantages,\
    \ and their use must be \nevaluated based on the application. The choice of which\
    \ protocol to use is \ndetermined by the size of the network, the energy consumption\
    \ of each node, \nand the transmission speed needed for a given application. For\
    \ instance, the IPv6 \nprotocol was born first to solve the problem of address\
    \ space (which, with the \nold IPv4 protocol, was about to run out) and second\
    \ to ensure scalability of \nsystems. Nevertheless, this protocol is designed\
    \ for wired networks. To address \nwireless sensor networks (WSN), the 6LoWPAN\
    \ protocol [72] was created. \n \nTable 2.1. Main protocols used in the IoT field\
    \ \nApplication Layer \nCoAP, MQTT, AMQP, XMPP, DSS \nService Discovery: mDMS,\
    \ DNS-SD, SSDP \nSecurity: TLS, DTLS \nTransport Layer \nTCP, UDP \nNetwork Layer\
    \ \nAddressing: IPv4/IPv6                Routing: RPL, CORPL, CARP, etc. \n \n\
    30 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots,\
    \ Visual Recognition and Cloud/Edge \nComputing Services \nAdaption Layer \n6LoWPAN,\
    \ 6TiSCH, 6Lo, etc. \nData Link Layer \nIEEE 802.15.4       IEEE 802.15.1    \
    \ LPWAN      RFID, NFC  \n(ZigBee, etc.)        (Bluetooth)    (LoRaWAN, etc.)\
    \  \nIEEE 802.11      IEEE 802.3      IEEE 1901  \n(Wi-Fi)      (Ethernet)   \
    \   (PLC)      Z-Wave \nPhysical Layer \n \n \nIoT devices can support various\
    \ interoperable communication protocols, \nwhether Internet-related or service-related,\
    \ and can communicate with other \ndevices of different genre and infrastructure.\
    \  \n \n2-3-3. Industrial Protocols \n \nEtherCat, CANOpen, Modbus/Modbus TCP,\
    \ Ethernet/IP, PROFIBUS, \nPROFINET, DeviceNet, IEEE802.11, ISA100.11a, and Wireless\
    \ HART are the \nmost frequently used industrial protocols [18]. Until a few years\
    \ ago, \ncommunication systems for industrial automation only aimed at industry-\n\
    specific real-time performance and maintainability based on international \nstandards\
    \ [73]. The Industry 4.0 concept has the flexibility to provide \ninteroperability\
    \ between different industrial engineering systems. To connect \ndifferent industrial\
    \ equipment and systems, the same standards and security \nlevels are needed.\
    \ Open Platform Communications Unified Architecture (OPC \nUA) is a machine-to-machine\
    \ (M2M) communication protocol developed to \ncreate interoperable and reliable\
    \ communications and is now widely accepted as \na standard in industrial plant\
    \ communications [74]. \nAnother important industrial protocol that is still largely\
    \ used in most plants \nis MODBUS TCP exclusively for synchronous polling communications;\
    \ this \nsolution is compatible with most industrial control systems and SCADA-type\
    \ \napplications. However, if asynchronous event-based communications are \nrequired,\
    \ MQTT complements MODBUS TCP operations. The Message Queuing \nTelemetry Transport\
    \ (MQTT) is a lightweight, publish-subscribe network \nprotocol that transports\
    \ messages between IoT devices. An Industrial Internet of \nThings (IIoT) environment\
    \ integrates an event-based message-oriented protocol, \ni.e., MQTT, with a polling-based\
    \ request–response protocol, intended for \nindustrial applications, i.e., MODBUS\
    \ TCP.  \nMODBUS meets industrial requirements, primarily for remote control,\
    \ \nmonitoring and automation functions. MQTT works in parallel with MODBUS \n\
    TCP and complements its functions, however, cannot replace MODBUS [75]. \n \n\
    31 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots,\
    \ Visual Recognition and Cloud/Edge \nComputing Services \nHTTP can also be used\
    \ in conjunction with MODBUS, as a web-based real-\ntime data monitoring system\
    \ that uses MODBUS TCP communications, in which \nall data is displayed in a real-time\
    \ graph in a web browser, which is refreshed at \nregular intervals using HTTP\
    \ polling communications [76]. \nThese protocols use the client–server communication\
    \ architecture. MQTT \nuses the publish–subscribe model and is message-oriented,\
    \ whereas HTTP uses \nthe request–response model and is a document-oriented protocol.\
    \ Thus, HTTP is \none-to-one (peer-to-peer), and MQTT is one-to-many. \nThe figure\
    \ 2.6 illustrates a comparison between the MODBUS philosophy \nand the MQTT philosophy\
    \ from a message exchange perspective. The MODBUS \nrequest uses a TCP connection\
    \ and employs a frame format based on an \noptimized application layer message\
    \ structure dedicated to telecontrol and \nmonitoring. The case is different with\
    \ MQTT; while the first client (publisher) \ngenerates an event using four messages,\
    \ the second client (subscriber) consumes \nthis event in six messages. \n \n\
    \ \nFigure 2.6. Comparison of protocols for the exchange of messages: (a) MQTT;\
    \ (b) \nMODBUS TCP. \n \n \nThe Internet of Engineering Task (IETF) has developed\
    \ a lighter application \nprotocol (Constrained Application Protocol (CoAP)) for\
    \ constrained IoT devices \noperating in lossy environments.    \nBased on UDP,\
    \ CoAP is an efficient and lightweight protocol compared to \nother IoT protocols\
    \ such as MQTT, HTTP, etc. CoAP also achieves reliable \ncommunication between\
    \ nodes in wireless sensor networks, along with features \nsuch as resource discovery,\
    \ resource observation, congestion control, etc. These \n \n32 \n \nSmart IoT\
    \ Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \ncapabilities of CoAP have enabled CoAP\
    \ to be implemented in various domains \nranging from home automation to health\
    \ management systems [77]. \nCoAP uses a specific infrastructure—namely, 6LoWPAN\
    \ (IEEE802.15.4)—\nwhich employs IPv6 in the network layer. Both HTTP and MQTT\
    \ use an \ninexpensive and available communication infrastructure, which is Internet\
    \ or \nIntranet in wireless mode (Wi-Fi—IEEE 802.11) or wire mode (Ethernet—\n\
    IEEE802.3) —which may employ either IPv4 or IPv6 in the network layer. In the\
    \ \ntransport layer, HTTP and MQTT protocols use TCP port numbers 80 and 1883,\
    \ \nrespectively. However, CoAP uses UDP port number 5683. Given that MQTT is\
    \ \nevent-based, it is a message-oriented protocol. Thus, CoAP mimics HTTP in\
    \ \nusing polling-based messaging, but in a shorter time and smaller frame-size,\
    \ \ntable 2 depicts more the difference between these protocols. \n \nTable 2.2.\
    \ Comparison of Internet of Things (IoT) protocols \nFeature \n \nHTTP \nCoAP\
    \ \nMQTT \nMODBUS TCP \ninfrastructure \nnetwork layer \ntransport layer \ntransport\
    \ port \nmodel \npattern \nmechanism \nmethodology \nparadigm \nquality level\
    \ \nstandard \nencoding \nsecurity \nEthernet, Wi-Fi \nIPv4 or IPv6 \nTCP \n80,\
    \ 443 \nsynchronous \nrequest-response \none-to-one \ndocument-oriented \nlong\
    \ polling-based \none level \nIETF (RFC7230) \nASCII text \nSSL, TLS \n6LoWPAN\
    \ \nIPv6 \nUDP \n5683 \nAsynchronous \nboth \none-to-one \ndocument-oriented \n\
    polling-based \ntwo: CON or NON \nIETF (RFC7252) \nRESTful (Binary) \nDTLS  \n\
    Ethernet, Wi-Fi \nIPv4 or IPv6 \nTCP \n1883, 8883 \nasynchronous \npublish-subscribe\
    \ \none-to-many \nmessage-oriented \nevent-based \nthree: QoS 0, 1, 2 \nISO/IEC,\
    \ OASIS \nUTF-8 (Binary) \nSSL, TLS \nEthernet, Wi-Fi \nIPv4 or IPv6 \nTCP \n\
    502, 802 \nSynchronous \nRequest-response \none-to-one \nbyte-oriented \npolling-based\
    \ \none level \nmodbus.org \nBinary \nTLS \n \nIn Figure 2.7, a comparison between\
    \ the different protocols is conducted \nbased on the protocol communication model\
    \ in the original IEEE model. CoAP \nruns over the connection less UDP in the\
    \ transport layer, whereas in the network \nlayer, CoAP uses either IPv6 or 6LoWPAN.\
    \ When CoAP uses IPv6, it is necessary \nfor it to use Ethernet or Wi-Fi for the\
    \ data link and physical layers, respectively. \nWhen CoAP uses 6LoWPAN, it employs\
    \ IEEE 802.15.4e for the data link and \nphysical layers. \nThe MODBUS TCP and\
    \ the MQTT protocols are both in the same level in the \nIEEE model. While the\
    \ MODBUS TCP uses a byte-encoded frame format for the \nuser data, which is intended\
    \ for industrial applications, the MQTT protocol \nencodes the user data in UTF-8.\
    \ \nThe content (payload) of HTTP may vary according to the type of transferred\
    \ \ndata, called content-type, which could be plain text, PDF application, HTML,\
    \ \nXML, GIF image or audio. For the exchange of data using HTTP, XML is used,\
    \ \nwhich handles verbose plain text for solving interoperability issues. However,\
    \ \n \n33 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \nfor CoAP, the\
    \ efficient XML interchange (EXI) [78] is used, which encodes \nverbose XML documents\
    \ in binary format, if interoperability is considered [75]. \nThis is normally\
    \ used for constrained devices to increase the performance \nand decrease the\
    \ consumed power. Hence, CoAP is suitable for constrained \ndevices in IoT-based\
    \ wireless sensor networks that employ IPv6-based \ninfrastructure. However, it\
    \ needs a gateway to exchange data over the Internet. \n \n \n \nFigure 2.7. The\
    \ IEEE model (a); compared to the HTTP (b); the CoAP (c); the MODBUS \nTCP (d);\
    \ and the MQTT (e). \n \nIn summary, there are many IoT protocols, and event-based\
    \ protocols are of \nconsiderable interest for data transfer in the form of notifications\
    \ to complement \nthe MODBUS TCP protocol. This MODBUS protocol is polling-based,\
    \ \nsynchronous, request-response, and optimized for control and monitoring in\
    \ \nindustrial applications, it can establish an IIoT environment. MQTT can \n\
    complement MODBUS TCP with its asynchronous model, event-based \nparadigm, and\
    \ publish-subscribe model. On the other hand, CoAP requires a \nspecific infrastructure,\
    \ and a gateway to move data over the Internet, which adds \nadditional costs\
    \ and causes complications for the environment. \n \n2-3-4. OPC UA Protocol \n\
    \ \nThe Internet's ubiquity is unfortunately only one aspect of this new era,\
    \ not \neven the main one. The most studied topic is the utopian \"single protocol\"\
    \ (i.e., \naccepted by any application market, industry and consumer) that could\
    \ \nintelligently and flexibly describe methods and data. There are several examples\
    \ \nof shared and widely used protocols in specific application markets, and \n\
    probably in the industry the most accepted protocol that harmonizes machine-\n\
    to-machine (M2M) interaction is OPC UA (Open Process Communications \n \n34 \n\
    \ \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual\
    \ Recognition and Cloud/Edge \nComputing Services \nUnified Architecture). The\
    \ OPC Foundation achieved great success with the \n\"OPC Classic\" protocol and\
    \ is now offering the OPC UA protocol as a more \npowerful successor for its platform-independent\
    \ architecture. \nOPC systems, particularly the latest OPC UA version, plays an\
    \ important \npart in current industrial environments, and more specifically to\
    \ sustain the \nupcoming IIoT environments [79-80]. Basically, they provide a\
    \ standard way to \nestablish a reliable and secure data exchange between industrial\
    \ devices from \nmultiple providers and software systems. This provides us with\
    \ an interface or \ngateway that allows us to interact directly with PLC. In fact,\
    \ OPC UA can be \nconsidered the basic protocol for harmonizing different industrial\
    \ automation \nnetworks and systems [73]. \nAs shown in Figure 2.8, OPC UA has\
    \ been designed to facilitate the exchange \nof information across the hierarchy\
    \ of systems that commonly coexist in industry: \ncontrol systems; manufacturing\
    \ execution systems (MES); enterprise resource \nplanning (ERP); and, finally,\
    \ field devices. OPC UA has a message-based \ncommunication and a service-oriented\
    \ architecture (SOA) with clients and \nservers connected to any types of networks.\
    \ \n \n \nFigure 2.8. OPC UA in the automation pyramid \n \n \nFigure 2.9 reveals\
    \ the architecture of the OPC UA server. The server \napplication is the code\
    \ that implements the server function. Real objects are \nphysical or software\
    \ objects that are accessible by the OPC UA server or \ninternally maintained\
    \ by it, such as physical devices and diagnostic counters. \nParticular objects,\
    \ such as Nodes, are used by OPC UA servers to represent real \nobjects, their\
    \ definitions and references; all nodes are called Address Space.  \n \n35 \n\
    \ \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual\
    \ Recognition and Cloud/Edge \nComputing Services \nNodes are accessible by clients\
    \ using OPC UA services (interfaces and \nmethods) [80]. In other words, the OPC\
    \ UA address space is the information \nmodel for the communication: real hardware\
    \ devices or real software “objects” \n(sensors, actuators, software applications,\
    \ etc.) are available for OPC UA \ncommunication only if they are modelled, added\
    \ to the address space and finally \ndiscovered by the OPC UA clients. In the\
    \ OPC UA API, there is a discovery \nservice that can be used to find available\
    \ OPC UA servers and to explore their \naddress space. Clearly, the OPC UA communication\
    \ stack converts the calls to \nthe OPC UA API to proper messages for the underlying\
    \ network layers. \n \n \nFigure 2.9. Architecture of the OPC UA Server \n \n\
    \ \nA client application may use the OPC UA client API (application program \n\
    interface) in order to send/receive OPC UA service requests/responses to/from\
    \ \nthe OPC UA server. From the programmer point of view, the OPC UA client API\
    \ \nis like an interface that decouples the client application code from the client\
    \ OPC \nUA communication stack. \n  \n \n \n \n36 \n \nSmart IoT Monitoring and\
    \ Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \n \nCHAPTER 3 \n \nRelated works and evaluation of the\
    \ \nlatency of the proposed architecture \n--------------------------------------------------\
    \ \n \n \n1- Introduction  \n \nOne of the main concerns of IoT is the interconnectivity\
    \ and integration of \ndifferent systems in the same architecture. Different challenges\
    \ can arise when it \ncomes to achieving this interconnectivity. \n Ensuring reliable\
    \ communications with all the devices and platforms \ninvolved is a major challenge\
    \ due to the diversity of protocols used in each \nconnected part. Interoperability\
    \ is considered as the primary issue to be solved, \nespecially when new technology\
    \ solutions need to be connected to existing \nnetworks. In addition, most IoT\
    \ architectures need to react in real time while \nensuring the highest level\
    \ of accuracy. Delay in connections affects not only the \ndecision-making, but\
    \ also the energy consumption for different energy \nconstrained devices [81].\
    \ \nThe use of new technologies and their connection to existing networks is \n\
    increasing. Different protocols, APIs and software have been introduced to \n\
    facilitate the interaction of connected systems and services. Node-RED, which\
    \ is \nan effective option for applications to prototype some IoT connectivity,\
    \ is a \ngraphical tool created by IBM to wire together hardware devices, APIs\
    \ and online \nservices. \nPython is also considered a programming tool for IoT\
    \ projects, which has \nbuilt-in support for scientific computing. Its use is\
    \ growing fastest in data science \nand machine learning. Versatility, stable\
    \ libraries with great support and ease of \nuse are its main advantages [82].\
    \ These platforms can be good solutions for \ninteroperability, as they have most\
    \ of the libraries that can facilitate connections \nbetween different systems.\
    \ \n \n37 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \nThe communication\
    \ protocols of the IoT platform allow different devices to \ncommunicate and share\
    \ their data with controllers or decision centers. IoT \nplatforms offer the ability\
    \ to select the type of communication technologies based \non the needs of the\
    \ application. However, not all protocols can be used in all \nscenarios. \nIndustry\
    \ now faces the challenge of making the IT network compatible with \nits machines,\
    \ including interoperability, fog/cloud computing, security, latency, \nand quality\
    \ of service. One of the proposed solutions is smarter IoT gateways \n[83], which\
    \ are the bridges between the traditional network and sensor networks \n[84].\
    \ The IoT gateway provides the necessary connectivity, security, and \nmanageability,\
    \ while some of the existing devices cannot share data with the \ncloud [85].\
    \ \nMost of IoT gateways can support all the necessary tools and protocols \n\
    needed to provide communication, computation and storage. The IoT gateway \ncan\
    \ affect the performance of an IoT system in terms of latency and accuracy, \n\
    especially when different software and APIs are implemented. It can be \nconnected\
    \ to the physical layers and transmit the received data to be processed \nin the\
    \ cloud. Using the cloud for AI solutions has its advantages and \ndisadvantages.\
    \ The IoT gateway can be used to implement cloud-based AI \nmodels at the edge\
    \ for processing and decision making, which makes the choice \nof IoT gateway\
    \ selection so crucial for a high-performance IoT architecture. \n \n2- Related\
    \ works \n \n \n2-1 Industrial Protocols  \n \n \nEtherCat, CANOpen, Modbus/Modbus\
    \ TCP, EtherNet/IP, PROFIBUS, \nPROFINET, DeviceNet, IEEE802.11, ISA100.11a, and\
    \ Wireless HART are the \nmost frequently used industrial protocols [86]. Due\
    \ to the incompatible \ninformation models for the data and services of the different\
    \ protocols, \ninteroperability between the different systems with different protocols\
    \ is always \ndifficult. The Industry 4.0 concept has the flexibility to achieve\
    \ interoperability \nbetween the different industrial engineering systems. To\
    \ connect the different \nindustrial equipment and systems, the same standards\
    \ and safety levels are \nrequired. Open Platform Communications Unified Architecture\
    \ (OPC UA) is a \nmachine-to-machine (M2M) communications protocol developed to\
    \ create inter-\noperable and reliable communications and is now generally accepted\
    \ as standard \nin industrial plant communications [87]. OPC UA is an independent\
    \ service-\noriented architecture that integrates all the functionality of the\
    \ individual OPC \nClassic specifications into one extensible framework [88].\
    \ OPC UA enable to \n \n38 \n \nSmart IoT Monitoring and Real-Time Control Based\
    \ On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \nconnect sub-manufacturing systems and ensure real-time communication \nbetween\
    \ devices and can be deployed in a service-oriented architecture for the \noptimization\
    \ of industrial applications [89]. \n \nOPC UA can allocate all manufacturing\
    \ resources, including embedded \nsystems, to specific areas and extensible computing\
    \ nodes through the address \nspace and a pre-defined model. It solves the problem\
    \ of unified access to the \ninformation of different systems [10]. Infrastructure\
    \ protocols have been \nproposed in many studies; for instance, in [90-91] an\
    \ edge IoT gateway was \ndeveloped to extend the connectivity of MODBUS devices\
    \ to IoT by storing the \nscanned data from MODBUS devices locally and then transferring\
    \ the changes \nvia an MQTT publisher to MQTT clients via a broker. \n \n2-2 Visual\
    \ Programming Languages \n \nVisual Programming Languages (VPL) are widely used\
    \ in IoT applications, \nin [92], a survey on Visual Programming Languages (VPL)\
    \ for IoT was proposed. \nThe analysis mainly focused on comparing them on the\
    \ basis of the programming \nenvironment, project repository, licensing, and supported\
    \ platforms. Some of \nthem are Open-Source platforms, while others are proprietary.\
    \ Among the Open-\nSource platforms (Node-RED, Modkit, miniBloq, NooDL, NETLab,\
    \ Ardublock, \nand Scratch), only some can be programmed using a Web interface\
    \ and executed \non some dockers or on-cloud virtual machines. \nIn addition to\
    \ being open source and having the possibility of adding new \nmodules and functionalities,\
    \ Visual Programming Language (VPL) IoT platforms \nshould exhibit a number of\
    \ non-functional requirements \nThey should demonstrate the capabilities of robustness,\
    \ availability (in terms \nof availability and fault tolerance), scalability,\
    \ security, full respect for privacy, \ninteroperability and openness, etc. \n\
    There are tools that make it easier for devices and their functionality to be\
    \ \ncomposed and combined at a higher level with IoT applications. For the device\
    \ \nlevel, an example of a tool is Node-RED that supports IoT application \ndevelopment\
    \ with a visual flow programming approach (Figure 3.1). Node-RED \nprovides an\
    \ integrated view of the application and the network and interacts \nsimultaneously\
    \ with the different systems involved through different protocols. \nIn [73] Node-RED\
    \ is used in both the IIoT gateway and the Cloud application, \nwhere a methodology\
    \ is proposed to measure delay metrics in OPC UA systems \nto study the impact\
    \ that QoS parameters have on the communication delay from \nthe production line\
    \ to the Cloud and vice versa.  \n \n \n39 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \n \nFigure 3.1. Node-Red Platform \n \nIn [93] Node-RED is proposed\
    \ and applied in an IoT application for oil \nleakage detection in wind turbine\
    \ bearings. In [94], a new method introduced to \nmigrate Node-RED workflows into\
    \ a decentralized execution environment, so \nthat such workflow scan run on Edge\
    \ networks, where nodes are extremely \ntransient in nature. \nThe programming\
    \ of IoT applications is carried out in several ways, using \ndifferent tools\
    \ [95]. For example, in the Google IoT platform, various \nprogramming languages,\
    \ such as Java, Node.js, Python, PHP, Go, Ruby, and C#, \ncan be utilized to program\
    \ data flows from devices to dashboards. In these cases, \ndata flows are deployed\
    \ using programming languages. \n \n2.3 IoT architecture for Robots \n \nImplementing\
    \ an Industry 4.0 architecture requires integration of the latest \ntechnologies,\
    \ for example, IIoT, cyber-physical systems, additive manufacturing, \nbig data\
    \ and data analytics, cyber-security, cloud and edge computing, \naugmented and\
    \ virtual reality, as well as autonomous robots and vehicles [96]. \nA typical\
    \ cloud robotics architecture is based on two elements: the cloud \nplatform and\
    \ its associated equipment and the bottom facility. Bottom facilities \nusually\
    \ encompass all kinds of mobile robots, unmanned aerial vehicles, \nmachines,\
    \ and other equipment [97]. The next generation of robots will include \ninterconnected\
    \ industrial robots [98], cobots [99] and autonomous land vehicles \n(AGVs) [100].\
    \ Cobots support human workers in various tasks, while robots can \ncarry out\
    \ specific tasks, such as looking for objects or transporting tools. \nUnmanned\
    \ Vehicles (UVs) are among the emerging robot technologies that \nleverage the\
    \ power of perception science and are now the preferred remote \n \n40 \n \nSmart\
    \ IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \nsensing system for gathering data over\
    \ long distances in difficult-to-access \nenvironments [101]. Drone cameras can\
    \ collect remotely sensed images from \ndifferent areas safely and efficiently.\
    \ \nUnmanned vehicles can be deployed in air (Unmanned Aerial Vehicles – \nUAV),\
    \ at the sea surface (Autonomous Surface Vehicles – ASV) or in the water \ncolumn\
    \ (Autonomous Underwater Vehicles – AUV). \nUAVs can save time and money in different\
    \ sectors, such as agriculture, \npublic safety, inspection and maintenance, transportation\
    \ and autonomous \ndelivery systems. This technological revolution was conceived\
    \ to make people’s \nlives easier and to provide machine-to-machine communications\
    \ without human \nintervention [102]. They can be used to check a given installation\
    \ or production \nareas, to transmit data, monitor construction processes, and\
    \ detect anomalies. \nFor instance, in [103], drones’ platform was deployed to\
    \ detect trees and \nbuildings close to power lines. They can also be deployed\
    \ to monitor oil, gas and \nwater pipelines. \nUAVs combined with digital image\
    \ processing have been applied to crack \nassessment as a cost-effective and time-effective\
    \ solution, instead of visual \nobservation [104]. In [105], Machine Learning\
    \ Techniques were used to estimate \nNitrogen nutrition levels in corn crops (Zea\
    \ mays). The work described in [106] \nintroduced a real-time drone surveillance\
    \ system to identify violent individuals \nin public areas by a ScatterNet hybrid\
    \ deep learning (SHDL) network. In [107], \nthe images from a drone camera were\
    \ processed by the bag-of-words algorithm \nto detect crops, soils and flooded\
    \ areas, with MATLAB to program the feature \nextraction algorithm. In [108],\
    \ a solution was proposed to detect a final target \nusing the drone’s camera.\
    \ The system implemented image processing algorithms \nusing the open-source computer\
    \ vision library OpenCV. Cloud solutions like \nGoogle AI, Amazon Web Services,\
    \ and IBM Watson offer on-demand access to \ntheir image recognition services\
    \ to connect with other systems on the internet. \nThe authors in [109] propose\
    \ to move computationally demanding object \nrecognition to a remote computing\
    \ cloud, instead of implementing it on the drone \nitself, by means of a cloud-based\
    \ approach that allows real-time performance \nwith hundreds of object categories.\
    \  \n \n2.4. Applications in Marine field \n \nMarine scientists and robotic engineers\
    \ now have at their disposal a \nheterogeneous collection of robotic vehicles,\
    \ including AUVs, deep-sea landing \nvehicles, unmanned/autonomous surface vehicles,\
    \ remotely operated vehicles, \nand gliders/drifters [110]. These robotic vehicles\
    \ are untethered, self-propelled, \nself-navigating vehicles that can operate\
    \ autonomously from a shore or vessel for \na period of hours to a few days and\
    \ carry scientific payloads to perform sampling \nin the marine environment [111].\
    \  \n \n41 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \nDirect vision\
    \ or camera vision is the simplest way to acquire a wealth of \ninformation from\
    \ aquatic environments and plays a vital role in underwater \nrobots. AUVs equipped\
    \ with the most recent cameras are now capable of \ncollecting massive amounts\
    \ of data from the seabed [112]. Computer vision \nalgorithms for underwater robotic\
    \ systems are attracting attention due to \nsignificant advances in vision capacities.\
    \  \nThe authors of [113] propose a stereo-imaging technique for recovering \n\
    underwater images by considering the visibility coefficients. This stereo-imaging\
    \ \napproach was realized using real-time algorithms and was implemented in \n\
    AUVs. The authors of [114] propose the new Qu index, which is used to assess \n\
    the similarity of structures and colors in underwater images. The authors of [115]\
    \ \nintroduce a human perception technique, the High-Dynamic Range Visual \nDifference\
    \ Predictor 2, to predict both overall image quality and artefact \nvisibility.\
    \ The authors of [116] propose a real-time system for object recognition \nin\
    \ acoustic images. A 3D acoustic camera is implemented to produce range \nimages\
    \ of the underwater area [117]. The authors of [118] propose a system for \nautomatic\
    \ interpretation of 3D objects based on 2D image data generated by a \nsector\
    \ scanning sonar unit. Their overall interpretation achieves a success rate of\
    \ \n86% for underwater objects seen in various conditions. \n \nArtificial intelligence\
    \ and machine learning have been proposed to enhance \nAUV missions and analyze\
    \ their data. The authors of [119] describe a system for \nautomatically detecting\
    \ pipelines and other objects on the seabed. Artificial \nneural networks are\
    \ applied to classify, in real time, the pixels of the input image \nof the objects\
    \ into various classes. The authors of [120] propose CNN to learn a \nmatching\
    \ function that can be trained from labelled sonar images after pre-\nprocessing\
    \ to produce matching and non-matching pairs. The authors of [121] \ndescribe\
    \ a DL method to assist in identifying fish species on underwater images. \n \n\
    Collaboration between the QUT University of Australia, Google and the \nGreat\
    \ Barrier Reef Foundation developed the world’s first underwater robotics \nsystem\
    \ specifically designed for coral reef environments [122]. Using real-time \n\
    computer vision, processed on board the robot, it can identify harmful starfish\
    \ \nwith 99.4% accuracy [122]. Marine researchers and robotics specialists tested\
    \ the \neffectiveness of a CV system in identifying sea creatures and found it\
    \ be around \n80% accurate. The system can even be 93% accurate if enough data\
    \ is used to train \nthe algorithm [123]. \n \nUnmanned surface vehicles (USVs)\
    \ are the main investigation areas of \nmaritime autonomous surface ships (MASSs),\
    \ being used in surveillance, \nresearch, scientific investigation and security.\
    \ USVs are defined as self-contained \nunmanned, untethered vessels that can transit\
    \ on the surface of the water \nautonomously or be remotely controlled [124].\
    \ \n \n42 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \n \nThrough\
    \ detailed maps and satellite navigation, an ASV can detect and avoid \nstatic\
    \ obstacles. For in instance, in [125] a performed approach was proposed \nusing\
    \ Google Maps to build a map of static obstacles. \n \nTo respond quickly and\
    \ effectively to the challenges of a highly dynamic \nenvironment, the ASV needs\
    \ on-board logic to monitor the scene, identify critical \nsituations, and perform\
    \ appropriate route modifications [126]. An outstanding \nfeature is its capacity\
    \ to recognize an obstacle at a safe distance and avoid a \ncollision by changing\
    \ its course. Kristan et al. [126] proposed a new graphical \nmodel that supplies\
    \ fast and continuous obstacle image-map estimation from a \nsingle video stream\
    \ captured on-board a USV. \nIn order to ensure accurate detection and tracking\
    \ of objects at sea, \nautonomous vessels require a range of sensing capabilities.\
    \ Radar can provide \nsuch an overview, although certain small vessels and floating\
    \ objects are \nchallenging to recognize. Computer vision by onboard cameras can\
    \ be used for \nthis as a reasonable alternative to a human lookout [127]. The\
    \ work proposed in \n[128] examines the technical challenges of marine image processing\
    \ and artificial \nvision problems for video streams generated by cameras. These\
    \ challenges \ninclude the dynamic nature of the background, the lack of static\
    \ cues, the \npresence of small faraway objects, and lighting effects. Authors\
    \ of [129] propose \na method of identifying and tracking vessels using video\
    \ streams of existing port \nand river surveillance systems. The method detects\
    \ all types of moving vessels, \noperates under varying lighting conditions, and\
    \ assigns a unique identifier to \neach vessel detected. \nIn [130], a monocular\
    \ camera mounted on a USV was used, automatic feature \nextraction and tracking\
    \ filter algorithms are applied for real-time vision-based \ndetection and tracking.\
    \ The approach aims to detect and track another surface \nvessel by deploying\
    \ computer vision techniques. \nNovel technology has already been deployed on\
    \ autonomous craft as part of \nthe Marine 4.0 concept, where AI, cloud, and edge\
    \ technologies are of great \nimportance. For instance, the IBM-funded project,\
    \ the Mayflower Autonomous \nShip (MAS), will use the IBM power servers, IBM Watson\
    \ AI, cloud, and edge \ncomputing technologies to navigate autonomously and avoid\
    \ ocean hazards as \nit travels from Plymouth (England, UK) to Plymouth (Massachusetts,\
    \ USA) [131] \n, thus expanding knowledge of the ocean and removing barriers to\
    \ marine \nresearch. In [132], a Google Cloud Machine Learning Engine is used\
    \ to deploy an \nAI-based object classification system: a software suite for detecting,\
    \ identifying, \nand tracking surface objects. It makes ships safer and more efficient\
    \ by \nautomatically analyzing data from a number of new sensors, along with the\
    \ \nship’s own automatic identification system (AIS) and radar. \nVision and image\
    \ processing applications can benefit from cloud computing, \nas many are data-\
    \ and compute-intensive. By remotely locating storage and \n \n43 \n \nSmart IoT\
    \ Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \nprocessing capabilities in the cloud,\
    \ image processing applications can be \ndeployed remotely and paid for by the\
    \ user in pay-as-you-go or pay-per-use \nbusiness models.  \nOverall, cloud, edge\
    \ and hybrid vision processing solutions each provide \nboth strengths and weaknesses;\
    \ assessing the capabilities of each will allow the \nselection of an optimal\
    \ strategy for any specific design situation. \n \n3. Artificial Intelligence\
    \ and Machine Vision \n \nArtificial intelligence (AI) is the intelligence achieved\
    \ by machines. The \nresearch field of AI is defined as the study of \"intelligent\
    \ agents\": any device that \nsenses its environment and performs actions that\
    \ maximize its chances of \nachieving a given goal [133].  In common parlance,\
    \ the term \"artificial \nintelligence\" is applied when a machine mimics the\
    \ \"cognitive\" functions that \nhumans associate with other human minds, such\
    \ as \"learning\" and \"problem \nsolving\". Capabilities currently classified\
    \ as AI include autonomous driving of \ncars, human speech understanding, high-level\
    \ competition in strategic gaming \nsystems, intelligent routing in content delivery\
    \ networks, military simulations, \nand complex data interpretation. \nThe central\
    \ problems of AI research include learning, planning, reasoning, \nknowledge,\
    \ communication, natural language processing, perception, and the \nability to\
    \ move and manipulate objects [134]. \nAs AI applications are recently also designed\
    \ for commercial solutions, it is \nobliged to deal with the wide availability\
    \ of GPUs (graphics processing units), \nwhich make parallel processing ever faster,\
    \ cheaper and more powerful. \nComputer processors are designed to handle just\
    \ about anything. Central \nprocessing units (CPUs), however, they are very limited\
    \ and, as such, can only \nperform certain mathematical calculations. Very complicated\
    \ combinations are \nimpractical because of the very long processing time. GPUs,\
    \ on the other hand, \nhave become so specialized that they outperform traditional\
    \ processors when it \ncomes to rendering large amounts of complex calculations.\
    \ GPUs offer 10 to 100 \ntimes the computational power of traditional CPUs, which\
    \ is one of the main \nreasons graphics cards are currently being used to power\
    \ some of the most \nadvanced neural networks responsible for deep learning [135].\
    \ \nDeep neural networks (DNNs), also known as deep learning (DL), are part \n\
    of the broad field of AI, which is the science and engineering of creating \n\
    intelligent machines with the ability to achieve goals like humans. Machine \n\
    learning is the subfield of computer science that, according to Arthur Samuel\
    \ in \n1959, gives \"computers the ability to learn without being explicitly \n\
    programmed\"[136]. Evolving from the study of pattern recognition and \ncomputational\
    \ learning theory in artificial intelligence, machine learning \nexplores the\
    \ study and construction of algorithms capable of learning from and \n \n44 \n\
    \ \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual\
    \ Recognition and Cloud/Edge \nComputing Services \nmaking predictions about data\
    \ [137] by building a model from sample inputs. \nThe relationship between deep\
    \ learning and the whole of artificial intelligence is \nillustrated in Figure\
    \ 3.2. In other words, DL is the study of artificial neural \nnetworks and related\
    \ machine learning algorithms that contain more than one \nhidden layer (Figure\
    \ 3.5).  \n \n \n \nFigure 3.2. Deep learning in the context of artificial intelligence\
    \ \n \nThe upside of an efficient Machine Learning Algorithm is clear. Instead\
    \ of \nthe laborious and haphazard approach of creating a separate, customized\
    \ \nprogram to solve each individual problem in a domain, the single machine \n\
    learning algorithm simply has to learn, through a process called training, to\
    \ \nhandle each new problem. The brain is now considered the best \"machine\"\
    \ we \nknow for understanding and solving problems, so it is perfectly natural\
    \ to look \nto it for a machine learning approach. Therefore, a brain-inspired\
    \ computation is \na kind of algorithm or program that has some aspects of its\
    \ basic functionality or \nform inspired by the way the brain works. \nScientists\
    \ believe that the main computational component of the brain is the \nneuron.\
    \ There are about 86 billion neurons in the average human brain. The \nneurons\
    \ themselves are connected by a number of elements that enter them, \ncalled dendrites,\
    \ and one element that exits them, called an axon, as shown in \nFigure 3.3. The\
    \ neuron accepts signals that arrive via the dendrites, computes on \nthese signals\
    \ and outputs a signal to the axon. These input and output signals are \ncalled\
    \ activations. The axon of a neuron branches and is connected to the \ndendrites\
    \ of many other neurons. The connection between a branch of the axon \nand a dendrite\
    \ is called a synapse. It is estimated that there are 1014 to 1015 \nsynapses\
    \ in the average human brain [138]. A key feature of the synapse is that \nit\
    \ can scale the signal (xi) that passes through it, as shown in Figure 3.3.  \n\
    \ \n \n45 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \n \nFigure 3.3.\
    \ Connections to a neuron in the brain. xi, wi, f (·), and b are the activations,\
    \ \nweights, nonlinear function, and bias, respectively \n \nThis scaling factor\
    \ can be called a weight (wi), and the brain is thought to \nlearn by changing\
    \ the weights associated with synapses. Thus, having different \nweights results\
    \ in different responses to an input. It is important to note that \nlearning\
    \ is the adjustment of weights in response to a learning stimulus, whereas \n\
    the organization (what we might think of as the program) of the brain remains\
    \ \nunchanged. This characteristic marks the brain as an excellent source of \n\
    inspiration for a machine learning algorithm. \nAs shown in figure 3.2, Within\
    \ the paradigm of brain-inspired computing \nexists a subarea called spiking computation.\
    \ The inspiration in this subarea is \ntaken from the fact that communication\
    \ in dendrites and axons are spike-shaped \npulses and that the information that\
    \ is transmitted is not based only on the \namplitude of the spike. Rather, it\
    \ also depends on the time at which the pulse \narrives and that the computation\
    \ that takes place in the neuron is a function not \nonly of a single value, but\
    \ of the pulse width and the temporal relationship \nbetween the different pulses.\
    \ In contrast to spiking computing, another sub-area \nof brain-inspired computing\
    \ is called neural networks, which is the focus of most \nresearch articles. \n\
    Neural networks are based on the notion that the computation of a neuron \nconsists\
    \ of a weighted sum of input values. These weighted sums reflect the \nscaling\
    \ of values by the synapses and the combination of those values in the \nneuron.\
    \ Moreover, the neuron does not simply produce this weighted sum, as \nthe computation\
    \ associated with a cascade of neurons would otherwise be a \nsimple linear algebra\
    \ operation. There is instead a functional operation within \nthe neuron that\
    \ is being performed on the combined inputs.   \nFigure 3.4 presents a diagrammatic\
    \ picture of a computational neural \nnetwork.  The neurons in the input layer\
    \ receive some values and propagate them \nto the neurons in the middle layer\
    \ of the network, which is also frequently called \n \n46 \n \nSmart IoT Monitoring\
    \ and Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \na “hidden layer.” The weighted sums from one or more\
    \ hidden layers are \nultimately propagated to the output layer, which presents\
    \ the final outputs of the \nnetwork to the user. To align brain-inspired terminology\
    \ with neural networks, \nthe outputs of the neurons are often referred to as\
    \ activations, and the synapses \nare often referred to as weights as shown in\
    \ Figure 3(a). \n \n \n \nFigure 3.4 Simple neural network example and terminology.\
    \  (a) Neurons and synapses. \n(b) Compute weighted sum for each layer. \nAccording\
    \ to Figure 3.3, the computation of each layer can be expressed as \nfollow: \
    \ \n\U0001D44C\U0001D457= f (∑\n\U0001D44A\U0001D456\U0001D457 \n3\n\U0001D456\
    =1\n\U0001D465\U0001D456 + \U0001D44F)                                       \
    \          (3.1) \n \nWhere Wij, xi and yj are the weights, input activations,\
    \ and output activations, \nrespectively, and f (⋅) is a nonlinear function. The\
    \ bias term b is omitted from \nFigure 3.3 for simplicity. \n \n3.1 Inference\
    \ Versus Training \n \nThe IoT data can be used to train the machine learning\
    \ model and inference \nbefore technical professionals can begin to design a system\
    \ that integrates a \nmachine learning inference server with the IoT, the relationship\
    \ between how IoT \ndata can be used for training the machine learning model and\
    \ inference must be \nunderstood. Figure 3.6 compare the training with inference.\
    \ \n \n• Training \n \nTraining is the process of creating a machine learning\
    \ algorithm. Training \nimplies the use of a deep learning framework (e.g., TensorFlow)\
    \ and a training \ndataset (Figure 3.5). IoT data supplies a source of training\
    \ data that data scientists \n \n47 \n \nSmart IoT Monitoring and Real-Time Control\
    \ Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \nand engineers can use to train machine learning models for a diversity of\
    \ use \ncases, from fault detection to consumer intelligence. \n \n \nFigure 3.5.\
    \ Training and inference comparison \n \n• Inference \n \nInference relates to\
    \ the process of using a trained machine learning algorithm \nto make a prediction.\
    \ IoT data can be used as input to a trained machine learning \nmodel, which enables\
    \ predictions that can provide guidance to decision-making \nlogic on the device,\
    \ at the edge gateway or elsewhere in the IoT system. \n \n2.4.2 Methods of Machine\
    \ Learning \n \nTwo of the most widely adopted machine learning methods are supervised\
    \ \nlearning and unsupervised learning. machine learning – about 70 percent –\
    \ is \nsupervised learning. Unsupervised learning accounts for 10 to 20 percent.\
    \ Semi-\nsupervised and reinforcement learning are two other technologies that\
    \ are \nsometimes used [139]. \n \n• Supervised learning  \n \nSupervised learning\
    \ algorithms are trained using labeled examples, typically \nan input where the\
    \ desired output is known. For example, a computer might \nhave data points labeled\
    \ \"R\" (works) or \"F\" (failure). The learning algorithm is \n \n48 \n \nSmart\
    \ IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \nprovided with a set of inputs along with\
    \ the corresponding correct outputs, and \nthe algorithm learns by comparing its\
    \ actual output with the correct outputs to \nfind errors. It then modifies the\
    \ model accordingly.  \nBy means of methods such as regression, classification,\
    \ prediction and \ngradient boosting, supervised learning uses patterns to predict\
    \ label values in \nadditional unlabeled data. \n \n• Unsupervised learning  \n\
    \ \nUnsupervised learning is used with data that have no historical labels. The\
    \ \nsystem is not told the \"correct answer\". The algorithm is supposed to find\
    \ out \nwhat it is shown. The goal is to explore the data and find some structure\
    \ in it. \nUnsupervised learning performs well on transactional data. For instance,\
    \ it can \nidentify customer segments with similar attributes that later can be\
    \ treated in \nsimilar ways in marketing campaigns. Alternatively, it can find\
    \ the main \nattributes that separate customer segments from each other. Popular\
    \ techniques \ninclude nearest neighbor mapping, self-organizing maps, k-means\
    \ clustering and \nsingular value decomposition. These algorithms are also used\
    \ to recommend \nitems, segment text topics, and identify data outliers. \n \n\
    • Semi-supervised learning  \n \nSemi-supervised learning is used for the same\
    \ applications as supervised \nlearning. But it uses both labeled and unlabeled\
    \ data for training: usually a small \namount of labeled data with a large amount\
    \ of unlabeled data (unlabeled data is \nless expensive and costs less effort\
    \ to acquire). This type of learning can be used \nwith methods such as regression,\
    \ classification and prediction. Semi-supervised \nlearning is useful when the\
    \ cost associated with labeling is too high to allow a \nfully labeled training\
    \ process. Some of the earliest examples of this type include \nidentifying a\
    \ person's face on a webcam. \n \n• Reinforcement learning  \n \nReinforcement\
    \ learning is often used in the areas of robotics, gaming and \nnavigation with\
    \ reinforcement learning, the algorithm discovers, via trial and \nerror which\
    \ actions produce the greatest rewards. This type of learning has three \nmain\
    \ constituents: the agent (the learner or decision maker), the environment \n\
    (everything the agent interacts with) and the actions (what the agent can do).\
    \ The \ngoal is for the agent to choose the actions that maximize the expected\
    \ reward in \na given time. The agent will reach the goal much faster if it follows\
    \ a good policy. \nThus, the goal of reinforcement learning is to learn the best\
    \ policy. \n \n \n \n49 \n \nSmart IoT Monitoring and Real-Time Control Based\
    \ On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \n3.2 Convolutional Neural Network for Object Recognition \n \nSeveral deep\
    \ learning architectures, such as deep neural networks, deep \nconvolutional neural\
    \ networks, deep neural networks, and recurrent neural \nnetworks, have been applied\
    \ to fields such as audio recognition, computer vision, \nautomatic speech recognition,\
    \ natural language processing, and bioinformatics, \nwhere they have been shown\
    \ to produce state-of-the-art results on a variety of \ntasks. Deep neural networks\
    \ have demonstrated their ability to outperform other \nmachine learning algorithms\
    \ in tasks such as object recognition in the field of \ncomputer vision. \nApplying\
    \ computer vision to automatically detect objects is an extremely \nchallenging\
    \ task. Noise disturbance, complex background, occlusion, scale and \nattitude\
    \ changes, low resolution, and other factors strongly influence object \ndetection\
    \ capabilities. Conventional object detection methods, based on the \nhand-crafted\
    \ feature, are not robust to lighting changes, occlusions and \nvariations in\
    \ scale or lack of good generalization ability [140]. Unlike handmade \nfeatures,\
    \ which are designed in advance by human experts to extract a particular \nset\
    \ of chosen properties, the features extracted by CNN are learned from the data.\
    \ \nThe core idea behind this is to learn object models from raw pixel data rather\
    \ than \nusing hand-set features, as in traditional recognition approaches. Training\
    \ these \ndeep models usually requires large training datasets, although this\
    \ problem has \nalso been surmounted by new large-scale labelled datasets such\
    \ as ImageNet \n[141]. \nA convolutional neural network (CNN) works by combining\
    \ different layers \nof neurons that extract certain characteristics from the\
    \ image. Each layer learns a \ndifferent level of abstraction, and in the end\
    \ gives a prediction of whether the \nobject was detected or not [142]. Different\
    \ online resources on deep CNN \narchitectures and vision-related datasets have\
    \ been implemented and are \navailable on the internet.  \nCNN-based methods have\
    \ achieved significant advances in computer vision. \nIn the 2012 ImageNet Large\
    \ Scale Visual Recognition Challenge (ILSVRC) [143], \nHinton and his student\
    \ Krizhevsky [141] applied CNN to image classification \nand achieved a winning\
    \ top-5 test error rate of 15.3%, compared to the 26.2% \nachieved by the second-best\
    \ entry. Applying various convolutional filters, CNN \nmodels can capture the\
    \ high-level representation of the input data, making it \nhighly popular for\
    \ CV tasks. The breakthrough and rapid adoption of DL in 2012 \nbrought into existence\
    \ modern and highly accurate object detection algorithms \nand methods, such as\
    \ the regions with CNN features (R-CNN) method [144], fast \nR-CNN [145], faster\
    \ R-CN [146], RetinaNet [147] and fast yet highly accurate \nmethods like SSD\
    \ [148] and YOLO [149]. CNN-based methods can provide more \naccurate target boxes\
    \ and multi-level semantic information for identification and \nlocalization.\
    \ However, handcrafted features are complementary and can be \ncombined with CNN\
    \ for improved performance [150]. \n \n50 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \nBy using the cloud infrastructure, it becomes possible to apply CNN\
    \ \ntechniques which are used in most object detection cloud services [151]. There\
    \ \nare two ways that can help leverage these techniques for a particular application.\
    \ \nThe first one consists of employing our own data and a framework in our own\
    \ \nmachine and training our custom model for custom object detection. The second\
    \ \nis to use cloud services through an API, which is a suite of machine learning\
    \ (ML) \nproducts and CV software development services that allows developers\
    \ with \nlimited ML expertise to train high-quality models specific to the needs\
    \ of their \nproject.  \n \n3.3 Deep Learning for Object Detection \n \nIn the\
    \ last decade, prominent applications like robotics, video surveillance, \nscene\
    \ understanding, and self-driving systems have initiated a significant \namount\
    \ of computer vision research. Thanks to the advancement of neural \nnetworks,\
    \ particularly deep learning, visual recognition systems have achieved \nimpressive\
    \ outcomes, especially in object detection. \nObject detection is the process\
    \ of identifying the instance of the class to which \nthe object belongs and estimating\
    \ its location by outputting the bounding box \naround the object [151]. Although\
    \ object detection and image classification both \nshare a common technical challenge,\
    \ they must handle significant numbers of \nhighly variable objects. Object detection\
    \ is more complex than image \nclassification due to the fact that it must identify\
    \ the precise location of the object \nof interest [152]. Being one of the main\
    \ computer vision issues, object detection is \ncapable of providing useful insights\
    \ for the semantic understanding of images \nand videos [153]. Object detection,\
    \ i.e., the detection of the positions and \ncategories of multiple instances\
    \ of objects in a single image, is a major challenge \nin a diverse set of applications\
    \ such as self-driving vehicles and robotics [154, \n155,156].  \nObject recognition\
    \ efficiency is steadily increasing, with advanced computer \nvision techniques\
    \ working successfully on a wide range of objects. Most of these \ntechniques\
    \ are based on deep learning with convolutional neural networks and \nhave achieved\
    \ impressive performance improvements in a variety of recognition \nproblems [157].\
    \ \n \n3.4 Cloud-Edge DL \n \nPublic clouds have emerged as a new opportunity\
    \ to deliver compute-\nintensive applications. A public cloud refers to a networked\
    \ set of computers that \nfurnish a variety of computing and storage resources\
    \ and offer the appearance of \nunlimited computing capacity on demand at a nominal\
    \ price and under a flexible \npricing model [158-159]. Deep Learning (DL) technology\
    \ is popular nowadays \n \n51 \n \nSmart IoT Monitoring and Real-Time Control\
    \ Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \nthanks to its good results in the fields of object detection, image classification\
    \ and \nnatural language processing. The easy availability of powerful data sets\
    \ and \ngraphic processing units are the main reasons for DL’s present popularity.\
    \ \nSeveral smart DL-based applications and services have changed all kinds of\
    \ \npeople’s lives because of the significant advantages of deep learning in the\
    \ \ncomputer vision (CV) fields [160-161]. CV seeks to enable computer systems\
    \ to \nautomatically identify and understand the visual world, simulating human\
    \ \nvision [162]. Algorithms for visual perception tasks have been developed,\
    \ \nincluding (i) object recognition to identify specific objects in image data,\
    \ (ii) object \ndetection to locate semantic objects of a given class, and (iii)\
    \ scene understanding, \nto parse an image into meaningful segments for analysis\
    \ [163]. All these \nalgorithm techniques can be deployed in the cloud.  \nEdge\
    \ computing is progressively being merged with artificial intelligence \n(AI)\
    \ and is intended to migrate DL computation from the cloud to the edge, \nthereby\
    \ enabling distributed, reliable and low-latency intelligent services [161]. \n\
    DL services are implemented nearby the service requests and the cloud is only\
    \ \ninvolved when extra processing is needed [164]. Both the cloud and edge \n\
    computing are considered adequate platforms to incorporate artificial \nintelligence\
    \ approaches.  \n \n3.5 Cloud AI at the Edge \n \nCloud computing is also impacting\
    \ many applications that currently rely on \nlocal storage and processing power.\
    \ Cloud computing provides computing \nresources in the form of a service or application\
    \ over a network. Its services are \ngenerally divided into three categories:\
    \ Platform as-a-Service (PaaS), \nInfrastructure-as-a-Service (IaaS) and Software-as-a-Service\
    \ (SaaS). By remotely \nlocating storage and processing capacity, image processing\
    \ applications and \nmachine vision systems can be performed remotely and paid\
    \ for on a pay-per-\ndemand or pay-per-use business model. Cloud-based systems\
    \ optimally aim to \nautomatically balance and distribute processing loads. \n\
    Building a visual recognition model is a difficult and time-consuming task. \n\
    In addition, the training of deep neural networks demand access to massive data\
    \ \nand computing power, however this issue has also been overcome by new large-\n\
    scale tagged datasets such as ImageNet [165]. Fortunately, there are many ready-\n\
    to-run solutions on the market where these neural networks are often trained by\
    \ \nlower-cost and more powerful clusters of cloud GPUs. \nThese solutions were\
    \ developed by several companies such as Google, \nAmazon, Microsoft, IBM, and\
    \ others, and are provided in the form of application \nprogramming interfaces\
    \ (APIs) which can be integrated into various application. \nVision pre-trained\
    \ models are either hosted for private use or offered as public \nservices for\
    \ deep learning in the cloud [165]. To use the pre-trained cloud-based \n \n52\
    \ \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots,\
    \ Visual Recognition and Cloud/Edge \nComputing Services \nmodels, application\
    \ developers employ the cloud-exposed APIs to offload deep \nlearning inference\
    \ tasks to the hosting server. \n \nThe advantage of a customized AI model is\
    \ the possibility to train it \naccording to the use case, in addition to detecting\
    \ the location of objects in the \nimage. The AI model can be trained to identify\
    \ different types of objects and their \nposition in an image. The trained custom\
    \ object detection model in the cloud can \nbe further implemented in an IoT gateway,\
    \ as the cloud service supports the edge \ncomputing option. \nEdge computing\
    \ has recently been envisioned to push cloud computing \nservices closer to IoT\
    \ devices and data sources. Edge computing is designed to \ndrive low-latency\
    \ data processing by migrating computing capacity from the \ncloud data centre\
    \ to the edge [166-167]. Influential cloud computing vendors, \nsuch as Google\
    \ [168] and Microsoft Azure [169], have released service platforms \nto drive\
    \ intelligence to the edge, allowing end devices to execute machine \nlearning\
    \ inference locally with pre-formed models. \nFigure 3.6 describes the six different\
    \ ways of using edge intelligence for ML \napplications, in which the edge can\
    \ be combined with the cloud or used alone for \nthe entire application process.\
    \ In this paper, we adopt two main methods: the \ncloud intelligence method, in\
    \ which training and inferencing are both performed \nin the cloud, and the Level\
    \ 3 method, with on-device inference and cloud \ntraining. \n \n \nFigure 3.6.\
    \ Six-level rating for edge intelligence [170] \n \n \n \n \n \n53 \n \nSmart\
    \ IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \n3.6  Evaluating performance of an object\
    \ detection model \n \nRapid advances in DL and improvements in device capabilities,\
    \ \nincorporating image sensor resolution, and optics, power consumption, memory\
    \ \ncapacity and computing power, have enhanced the cost-effectiveness and \n\
    efficiency of accelerating the spread of vision-based applications. Compared to\
    \ \ntraditional CV techniques, the DL allows CV engineers to achieve greater task\
    \ \naccuracy [171]. The neural networks used in DL are trained rather than \n\
    programmed; therefore, applications using this method often require less expert\
    \ \nanalysis and tuning and leverage the large amount of video data already present\
    \ \nin current systems. \nThe potential of cloud-based platforms is expected to\
    \ be exploited in the \nfuture for the development of computationally intensive\
    \ CNN applications [172]. \nThe obvious advantage is the possibility of creating\
    \ intelligent systems with \nlonger battery life, because the intense calculations\
    \ are performed elsewhere. \nWide and deep CNNs present a major challenge for\
    \ deployment and \nexecution on resource-constrained devices. Cloud computing\
    \ not only enables \nthe handling of massive amounts of data, but also takes advantage\
    \ of the benefit \nof high computing efficiency at a negligible cost. World leaders\
    \ such as Google, \nAmazon, IBM, and Microsoft offer the public highly scalable,\
    \ fast, and flexible \ncloud computing facilities to train CNN’s resource-hungry\
    \ architectures. The \ncloud environment also facilitates setting up libraries\
    \ for both researchers and \nnew practitioners. \nIn computer vision, one of the\
    \ most powerful algorithms is object detection, \nwhich aids in the classification\
    \ and localization of objects. Object detection is \nmore complicated due to the\
    \ fact that it requires drawing a bounding box around \neach object in the image.\
    \ \nMultiple deep learning algorithms exist for object detection like RCNN: Fast\
    \ \nRCNN, Faster RCNN, YOLO, Mask RCNN, etc. Moreover, Azure Custom Vision, \n\
    Google cloud and IBM Watson services allow users to load an image dataset to \n\
    classify or define the bounding box for each desired object in the image for \n\
    training. \nThe objective of an object detection model is to perform object classification\
    \ \nand localization, the former is to identify whether an object is present in\
    \ the \nimage and the class of the object, and the latter is to predict the boundary\
    \ box \ncoordinates around the object when an object is present in the image.\
    \ \nClassification models are evaluated on accuracy, precision, and recall, while\
    \ \nfor object detection, the concept of intersection over union (IoU) is employed\
    \ \n(Figure 3.7).  \nPrecision indicates the fraction of identified classifications\
    \ that are correct, \nwhile recall indicates the fraction of actual classifications\
    \ that are correctly \nidentified. IoU (intersection on union) is a measure of\
    \ how well a model predicts \n \n54 \n \nSmart IoT Monitoring and Real-Time Control\
    \ Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \nthe location of objects and is evaluated using the area of overlap of the\
    \ predicted \nbounding box regions and the ground truth, defined as follows: \n\
    \ \n\U0001D43C\U0001D45C\U0001D448 =\n\U0001D434\U0001D45F\U0001D452\U0001D44E\
    \ \U0001D45C\U0001D453 \U0001D442\U0001D463\U0001D452\U0001D45F\U0001D459\U0001D44E\
    \U0001D45D\n\U0001D434\U0001D45F\U0001D452\U0001D44E \U0001D45C\U0001D453 \U0001D448\
    \U0001D45B\U0001D456\U0001D45C\U0001D45B                                     \
    \              (3.2) \n \n \n \n \nFigure 3.7. IoU equation, Red is ground truth\
    \ bounding box and green is \npredicted bounding box \n \nPrecision indicates\
    \ the fraction of identified detections that were correct, and \nrecall indicates\
    \ the fraction of actual detections that were correctly \nidentified. FP (False\
    \ Positive) represents the number of negative samples judged \nto be positive,\
    \ TP (True Positive) is the number of positive samples judged to be \npositive,\
    \ and FN (False Negative) is the number of positive samples judged to be \nnegative.\
    \ \n \n\U0001D443\U0001D45F\U0001D452\U0001D450\U0001D456\U0001D460\U0001D456\U0001D45C\
    \U0001D45B =\n\U0001D447\U0001D443\n\U0001D439\U0001D443+\U0001D447\U0001D443\
    \                                                 (3.3) \n \n\U0001D445\U0001D452\
    \U0001D450\U0001D44E\U0001D459\U0001D459 =\n\U0001D447\U0001D443\n\U0001D439\U0001D441\
    +\U0001D447\U0001D443                                                  (3.4) \n\
    \ \n \n4. Latency Assessment  \n \nOne of the important challenges to overcome\
    \ is the high-latency and \nunreliable link issues between the cloud and the IIoT\
    \ terminals. Fog computing \nextends computing and storage to the network edge\
    \ and is not only considered \nfor computation and storage, but also as a way\
    \ of integrating new systems \ncapable of interconnecting urgent and complex processing\
    \ systems. However, \neach fog and edge application may have different latency\
    \ requirements and may \ngenerate different types of data and network traffic\
    \ [173].  \n \n \n \n55 \n \nSmart IoT Monitoring and Real-Time Control Based\
    \ On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \n4-1 Latency between Two Terminals \n \nLatency is the time network traffic\
    \ delayed by the system processing, or the \ntotal time needed to send a network\
    \ packet from the application on one server to \nthe application on another server\
    \ through the network interface controller (NIC), \nnetwork (cable, Wi-Fi etc.),\
    \ and into an application on another server (or client). \nTo assess the latency\
    \ between two terminals, most approaches use the round-trip \ndelay time (RTD)\
    \ or the one-way delay (OWD). The latency in the context of \nnetworking is the\
    \ time spent by propagation through the network support and \nhardware of the\
    \ adapter, as well as the software execution times (application and \nOS) (Figure\
    \ 3.8). \n \n \n \nFigure 3.8. Latency between two terminals in a network \n \n\
    The hardware latency inside switches and on wires can be easily identified \n\
    from the switch specifications, length of the wires, and the maximal transmission\
    \ \ndata rates, while the software latency imposed by processing a packet in the\
    \ \nsoftware stack is more arduous to evaluate. Several parameters like system\
    \ \nworkload, operating system and executed application influence software latency.\
    \ \nEquation 3.5 defines the RTD between two terminals in a network, where tA\
    \ \nand tB are the software latency of the terminals A and B respectively, and\
    \ tH \nmarks the hardware latency of switches and wires connecting the terminals\
    \ A \nand B.  \n \n\U0001D445\U0001D447\U0001D437 = 2 \U0001D442\U0001D44A\U0001D437\
    \ = 2 \U0001D461\U0001D434 + 2 \U0001D461\U0001D43B + 2 \U0001D461\U0001D435 \
    \                                (3.5) \n \nTo accurately calculate OWD (by dividing\
    \ the round-trip time by two), the \nconfiguration of the test systems must be\
    \ perfectly symmetrical, meaning they \n \n56 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \nmust be running the same software, using the same settings, and have\
    \ equal \nnetwork and system performance. \n \n4-2 OPC UA Architecture and delay\
    \ assessment  \n \nA client application may use the OPC UA client API (application\
    \ program \ninterface) in order to send/receive OPC UA service requests or responses\
    \ to or \nfrom the OPC UA server. From the programmer point of view, the OPC UA\
    \ client \nAPI is like an interface that decouples the client application code\
    \ from the client \nOPC UA communication stack. \n \nIn this section, we analyze\
    \ the delays involved in client-server OPC UA \ncommunications in a switched Ethernet\
    \ network. This model serves to define in \ndetail the non-deterministic sources\
    \ of end-to-end delay. The proposed model is \nbased on time delays defined in\
    \ [174-175] in an Ethernet-based network. Figure \n3.9 shows the round-trip data\
    \ path from an OPC UA server in PLC automate to \nan OPC UA client on the IoT\
    \ gateway and the hardware OWD required. \n \n \n \nFigure 3.9. OPC UA delay in\
    \ OPC UA client server in an Ethernet network \n \nWe consider the end-to-end\
    \ network delay in the switches and wires from \nthe client request to the server,\
    \ which can be divided into three categories, the \nframe transmission delay (dt),\
    \ the time required to transmit all of the packet’s \nbits to the link, the propagation\
    \ delay (dl), the time for one bit to propagate from \nsource to destination at\
    \ propagation speed of the link, and the switching delays \n(ds), which depend\
    \ on the route through the network to the server. \nThe transmission delay depends\
    \ on the length of packet L and capacity of \nlink C. The propagation delay is\
    \ related to the distance between two switches \nand the propagation speed of\
    \ the link S.  \n \n57 \n \nSmart IoT Monitoring and Real-Time Control Based On\
    \ Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services \n\
    \ \n \n\U0001D451\U0001D459 =\n\U0001D437\n\U0001D446  , \U0001D451\U0001D461\
    \ =\n\U0001D43F\n\U0001D436                                                  \
    \      \n(3.6) \n \nThe switch delay is defined as the time for one bit to traverse\
    \ from switch \ninput port to the switch output port. It is divided into four\
    \ delays: the first is the \nswitch input delay (dSin), the delay of the switch\
    \ ingress port, including the \nreception of the PHY and MAC latency. The second\
    \ is the switch output delay \n(dSout), the delay of the switch egress port, including\
    \ the transmission PHY and \nMAC latency. The third delay is the switch queuing\
    \ delay (dSq), the time a frame \nwaits in the egress port of a switch to start\
    \ the transmission onto the link. The last \nis the switch processing delay (dSp),\
    \ the time required to examine the packet’s \nheader and determine where to direct\
    \ the packet is part of the processing delay.  \n \n\U0001D451\U0001D446(\U0001D461\
    ) = \U0001D451\U0001D446\U0001D456\U0001D45B + \U0001D451\U0001D446\U0001D45D\
    \ + \U0001D451\U0001D446\U0001D45C\U0001D462\U0001D461 + \U0001D451\U0001D446\U0001D45E\
    (\U0001D461)                                     (3.7) \n \nThe hardware end-to-end\
    \ delay dCS presented as a request from an endpoint \nserver S to the destination\
    \ endpoint in a client C can be expressed as the sum of \nthe delays of all the\
    \ switches and links in the path, n being the number of links \nand n − 1 the\
    \ number of switches along the path.  \n \n\U0001D451\U0001D436\U0001D446(\U0001D461\
    ) = \U0001D451\U0001D461 + ∑\n(\U0001D451\U0001D459,\U0001D456) + ∑\n\U0001D45B\
    −1 \U0001D451\U0001D460,\U0001D456(\U0001D461) \n\U0001D456=1\n \n\U0001D45B\n\
    \U0001D456=1\n                                   (3.8) \n \nFigure 2.8 reveals\
    \ the architecture of the OPC UA server. The server \napplication is the code\
    \ that implements the server function. Real objects are \nphysical or software\
    \ objects that are accessible by the OPC UA server or \ninternally maintained\
    \ by it, such as physical devices and diagnostic counters. \nParticular objects,\
    \ such as Nodes, are used by OPC UA servers to represent real \nobjects, their\
    \ definitions and references; all nodes are called AddressSpace. \nNodes are accessible\
    \ by clients using OPC UA services (interfaces and methods) \n[176]. \n \nIn the\
    \ case of m number of requests from clients to the nodes in the OPC UA \nserver,\
    \ the overall hardware end-to-end delay of the OPC UA client-server (dCS) \ncommunication\
    \ over an Ethernet network, when there are m requests from the \nclient to the\
    \ server, is presented as: \n \n\U0001D461\U0001D43B = \U0001D451\U0001D436\U0001D446\
    (\U0001D461) =  ∑\n(\U0001D451\U0001D461,\U0001D457) + ∑\n(\U0001D451\U0001D459\
    ,\U0001D456) + ∑\n\U0001D45B−1(\U0001D451\U0001D460,\U0001D456)\n\U0001D456=1\n\
    \U0001D45B\n\U0001D456=1\n\U0001D45A\n\U0001D457=1\n                         \
    \    (3.9) \n \n \n \n58 \n \nSmart IoT Monitoring and Real-Time Control Based\
    \ On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \nBy analyzing all the delays mentioned in the hardware, we admit that the \n\
    end-to-end delay on Ethernet network is deterministic, except the delay in the\
    \ \nswitch queue, which depends on the link utilization. The packet queuing delay\
    \ \nincreases in a frequently used link. \nBy investigating the hardware delays\
    \ for an OPC UA client/server \ncommunication in an Ethernet network, we conclude\
    \ that it is hard to define \nexactly the hardware delay on the account of the\
    \ queuing delay. In that case, \nwhen it comes to complex processes with real-time\
    \ requirements, OPC UA \nreaches its limits. Different ways of defining this delay\
    \ exist, for example QoS \ntechniques such as WFQ (weighted fair queuing) or strict\
    \ priority [177]; \nnevertheless, there is always a certain amount of delay and\
    \ jitter that limits real-\ntime performance. Time sensitive networking (TSN)\
    \ provides mechanisms for \nthe transmission of time-sensitive data over Ethernet\
    \ networks. The adoption of \nOPC-UA over TSN will also drive this paradigm in\
    \ the world of deterministic \nand real-time machine to machine communications.\
    \ TSN provides mechanisms \nfor the transmission of time-sensitive data over Ethernet\
    \ networks. With \nEthernet’s limitations in terms of traffic prioritization,\
    \ the TSN working group \nhas developed the time-aware scheduler (TAS), defined\
    \ in 802.1Qbv [178]. TAS \nis based on TDMA, which solves the problem of synchronization\
    \ and traffic \npriority in the Ethernet. By using this technique, queuing delay\
    \ can be completely \neliminated, hence the end-to-end latency becomes deterministic.\
    \ This technique \nwas adopted in [179] to evaluate OPC UA performance on TSN\
    \ with the most \ncommonly used communication technologies. \n \n3-3 UAV System\
    \ Delay \n \nThere are several ways to introduce latency in a drone’s video compression\
    \ \nand transmission system. The end-to end delay in the system can be divided\
    \ into \nseven categories (Figure.3.10): Tcap is the capture time, Tenc the time\
    \ required to \nencode, the resulting transmission delay is Ttx, Tnw is the delay\
    \ network when \nthe drone is connected to the remote ground station via a network,\
    \ Trx is due to \nthe ground station also being wirelessly connected to a network,\
    \ Tdec is the \ndecoding delay at the reception station, and Tdisp is the display\
    \ latency.  \n \n\U0001D447 = \U0001D447\U0001D450\U0001D44E\U0001D45D + \U0001D447\
    \U0001D452\U0001D45B\U0001D450 + \U0001D447\U0001D461\U0001D465 + \U0001D447\U0001D45B\
    \U0001D464 + \U0001D447\U0001D45F\U0001D465 + \U0001D447\U0001D451\U0001D452\U0001D450\
    \ + \U0001D447\U0001D451\U0001D456\U0001D460\U0001D45D                       \
    \          (3.10) \n \n \n \n \n \n59 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \n \nFigure 3.10 Video transmission system delay sources. \n \nNote\
    \ that when the drone is communicating directly with the ground station, \nno\
    \ network is involved and there is only a single transmission delay (Tnw = 0 \n\
    and Trx = 0).  \n\U0001D447 = \U0001D447\U0001D450\U0001D44E\U0001D45D + \U0001D447\
    \U0001D452\U0001D45B\U0001D450 + \U0001D447\U0001D461\U0001D465 + \U0001D447\U0001D451\
    \U0001D452\U0001D450 + \U0001D447\U0001D451\U0001D456\U0001D460\U0001D45D    \
    \                                    (3.11) \n \nIn the H.264 system, each video\
    \ frame is organized into slices which are in \nturn divided into non-overlapping\
    \ blocks and macro-blocks (two-dimensional \nunit of a video frame). Every slice\
    \ is independently encoded and can decode itself \nwithout reference to another\
    \ slice. The main advantage of this system is that it is \nnot required to wait\
    \ for the entire frame to be captured before starting to encode. \nAs soon as\
    \ one slice is captured, the encoding process can start, and slice \ntransmission\
    \ can begin. This technique has a consistent effect on the overall \nlatency as\
    \ it influences all the system latencies from encoding to display. \nTheoretically,\
    \ we define the overall latency by the number of slices N, \nalthough in practice\
    \ this may not be the case due to setting up and processing \nindividual slices.\
    \  \n \n\U0001D447 = \U0001D447\U0001D450\U0001D44E\U0001D45D + \U0001D441. (\U0001D447\
    \U0001D452\U0001D45B\U0001D450 + \U0001D447\U0001D461\U0001D465 + \U0001D447\U0001D451\
    \U0001D452\U0001D450 + \U0001D447\U0001D451\U0001D456\U0001D460\U0001D45D)   \
    \                               (3.12) \n \nIn order to efficiently transmit and\
    \ minimize the bandwidth, it is important \nto use video compression techniques,\
    \ although the slice technique also has an \neffect on the compression ratio.\
    \ The higher the number of slices, the faster they \ncan be encoded and transmitted,\
    \ although as this number increases, the number \nof bits used for a slice and\
    \ the effective slice transmission time also increase. \nOther types of delay\
    \ also affect the overall delay. Some factors can be \nadjusted when a UAV system\
    \ is used. For example, Tcap depends on the frame \nrate of the UAV camera, the\
    \ higher the frame rate, the shorter the capture time. \nTx relies on the available\
    \ data bandwidth of the transmission channel, while \nTdisp (video capture) is\
    \ based on the refresh rate of the display. \n \n \n \n \n \n \n60 \n \nSmart\
    \ IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \n \n \n \n \n \n \nCHAPTER 4 \n \n--------------------------------------------------\
    \ \n \nEnergy Efficiency and Latency of Smart \nIoT Monitoring and Control Systems\
    \ \nBased on cloud Computing and \nIntelligent Machine Vision \n \n \n--------------------------------------------------\
    \ \n \n \n \n \nI. Smart Industrial IoT Monitoring and Control \nSystems Based\
    \ on cloud Computing and Intelligent \nMachine Vision \n \n61 \n \nSmart IoT Monitoring\
    \ and Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \n \n1. Introduction   \n \nIndustry 4.0 is the information-intensive\
    \ transformation trend towards \nautomation and data exchange of manufacturing\
    \ technologies and processes \nincluding, robotics, cyber-physical systems (CPS),\
    \ the Internet of things (IoT), the \nInternet of services (IoS), cloud manufacturing,\
    \ big data and augmented reality \n[180]. Industry 4.0, the Fourth Industrial\
    \ Revolution, has already made \nsignificant changes to manufacturing and production\
    \ industries and offers a \nwealth of opportunities. Nevertheless, numerous issues\
    \ are also becoming the \nfocus of active research. These relate to concerns about\
    \ delays, data security, \ndevice communication and service availability. The\
    \ lack of ubiquitous \ninteroperability between heterogeneous devices is also\
    \ a major concern. \nAttempting to achieve seamless interoperability is further\
    \ complicated by the \nlong life of typical industrial equipment, to which costly\
    \ upgrades or \nreplacements are required to operate with the latest technologies\
    \ [181].  \nDue to the interactions between servers and IoT devices, massive amounts\
    \ of \ndata need to be transmitted through the IoT network, raising significant\
    \ data \ntransmission overhead to the network. As a number of IIoT systems are\
    \ time \nsensitive, the large increase in network traffic causes high network\
    \ latency and \nlarge packet loss, significantly affecting the performance of\
    \ IIoT systems. Fog \ncomputing is a potential middleware that can be very useful\
    \ for various \nindustrial scenarios. Since industrial processes require most\
    \ tasks to be carried \nout locally due to time and security limitations. Fog\
    \ computing can reduce and \nrefine large industrial data locally, before it is\
    \ sent to the cloud. Also, it can \nprovide local processing support with acceptable\
    \ latency for robots and actuators \nin a manufacturing industry [182]. However,\
    \ each fog and edge application may \nhave different latency requirements and\
    \ may generate different types of data and \nnetwork traffic [183]. \nRecent advances\
    \ in robotics, geomatics, and computer vision technologies \nhave made it possible\
    \ to capture an enormous amount of visual data using low-\ncost unmanned aerial\
    \ vehicles (UAVs). As a kind of flexible, fast and low-cost \ndata acquisition\
    \ system, UAVs have demonstrated great capabilities in \nperforming numerous mapping,\
    \ surveying and remote sensing tasks with very \nhigh-resolution data [184]. \n\
    UAVs have been widely used in manufacturing companies to monitor \njobsites in\
    \ real time and to provide high-definition (HD) images and video to \nidentify\
    \ changes and solve or prevent many problems [185]. They have also been \nused\
    \ for maintenance, inspection and tasks that are dangerous, inaccessible or \n\
    costly from the ground [186]. The integration of UAVs in the IoT represents an\
    \ \ninteroperability challenge, since each IoT system has its own communication\
    \ \n \n62 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \nprotocol. Besides,\
    \ a small delay or error beyond the tolerated limit could result \nin a disaster\
    \ for various applications, such as manufacturing and monitoring of \naircraft\
    \ and UAVs.  \nUAVs technology has undergone a significant transformation and\
    \ has found \napplications in different fields, the off-board base station gives\
    \ them higher \ncomputational capacity and the ability to carry out more complex\
    \ actions using \nhigh-level programming languages, or leveraging services from\
    \ computer vision \ntools by acquiring, processing, analyzing and understanding\
    \ digital images in \nreal-time.  \nCrack assessment systems for concrete structures\
    \ are constantly improving \nthanks to computer vision technologies and UAVs.\
    \ UAVs combined with digital \nimage processing have been applied to crack assessment\
    \ as a cost-effective and \ntime-effective solution, instead of visual observation\
    \ [187]. Image recognition \ntechnology has a great potential in various industries\
    \ and has been improved by \ndeep learning and machine learning image recognition\
    \ systems (TensorFlow, \nand MATLAB) or image processing techniques such as computer\
    \ algorithms for \ndigital image processing. \n \nConcrete batching plant also\
    \ is a critical process, which is susceptible to \nchanges of mixed materials.\
    \ Due to some errors in the discharge and filtering \nprocess, these materials\
    \ are sometimes mixed incorrectly, which affects the \nquality and consistency\
    \ of the concrete. The drone's camera and cloud-based \nservices can identify\
    \ the condition of the aggregates being transported on the \nconveyor belts so\
    \ that adjustments can be made to the production process. \n \nImage processing\
    \ has become a significant asset for UAVs systems and not \nonly in industry.\
    \ Capturing footage and videos generates a huge amount of data, \nfor which cloud\
    \ computing is vital [188]. \nComputing capabilities can be extended to the cloud,\
    \ taking advantage of the \nservices offered, and saving the cost and energy consumption\
    \ of an embedded \nUAV system. While the fog can be responsible for technical\
    \ assistance between \nhumans and machines, information transparency, interoperability,\
    \ decentralized \ndecision-making, information security, and data analysis.  \n\
    The rest of this chapter is organized as follows, we introduce the proposed \n\
    the three-layer IIoT-based UAV architecture, then we define the different \nprotocols\
    \ and applications used to connect the different systems. Following, we \ndiscuss\
    \ three-layer architecture latency using different IoT gateways in the fog \n\
    layer.  \n \n2. System model \n \n \n63 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \nA three-layer IIoT-based UAV architecture (Industrial IoT) is considered\
    \ in \nthis work. An IIoT monitoring and control system based on a UAV integrated\
    \ \ninto traditional industrial control system architecture. The first layer consists\
    \ of \ntwo different systems, the first is industrial control system connected\
    \ to \nindustrial sensors, actuators and PLCs, and the second is the UAV monitoring\
    \ \nsystem. The second layer is the fog computing layer for storage, computing\
    \ and \ncommunications. The last layer is a cloud computing layer with image processing\
    \ \nservices. Communication between the layers and systems is provided by the\
    \ IoT \ngateway installed in the fog layer, which links securely in real time\
    \ the industrial \ncontrol layer to the UAV system, the UAV system to the cloud,\
    \ and finally the \ncloud to the industrial control system. We validated our design\
    \ proposal in an \nindustrial concrete manufacturing plant as a case study with\
    \ the aim of \nimproving production and reducing costs. \n \n \nFigure 4.1: Proposed\
    \ UAV-IIoT Platform \n \nThe control system receives data from remote or connected\
    \ sensors that \nmeasure set points (SP) of process variables (PV). When the system\
    \ detects a \nchange in trend between the PVs and SPs, the change is routed to\
    \ PLCs and the \nIoT Gateway that triggers the UAV system's reaction. The UAV\
    \ goes to a specific \npoint to supervise the process using the front camera.\
    \ Once the images are \ncaptured, the IoT Gateway receives them and sends them\
    \ to the cloud, which \nadopts deep learning techniques to analyze and send the\
    \ results to the IoT \nGateway and the control system to confirm the anomaly.\
    \ The fog layer is \nresponsible for communications between all other layers;\
    \ it automatically makes \ndecisions based on the results and data received and\
    \ transmits the results to other \napplications and layers. The fog layer, presented\
    \ as an IoT gateway, can support \nall the necessary tools and protocols to ensure\
    \ storage, communication and \ncomputing. Between the different layers of the\
    \ IIoT-UAV proposed architecture, \nthere are different network protocols (Figure\
    \ 4.2). In the first layer, the industrial \nsensors of the control system are\
    \ connected to a PLC that acts as an OPC UA \n \n64 \n \nSmart IoT Monitoring\
    \ and Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \nserver, which routes the sensor data to the IoT Gateway\
    \ using the OPC UA \nprotocol. The IoT gateway integrates an OPC UA client installed\
    \ in Node-RED. \nNode-RED can also communicate with cloud services using IBM Visual\
    \ \nRecognition Nodes (WVR), which sends the UAV’s images to the cloud using \n\
    Internet protocols. The Ar.Drone Node.js library installed in the IoT Gateway\
    \ can \ncommunicate with Node-RED using the Exec node, which launches the UAV\
    \ \nmission and establishes the wireless connection between the UAV and the IoT\
    \ \ngateway using the Wi-Fi protocol. \n \n \nFigure 4.2. Development design of\
    \ autonomous IIoT flight \n \nNode-RED can connect all systems in the proposed\
    \ architecture using a wide \nrange of nodes. The OPC UA server installed in the\
    \ control system (PLC), \ncommunicates with the OPC UA Node-RED client node, which\
    \ reads the sensor \nvalues and launches the UAV program using the Exec node if\
    \ certain conditions \nare met. While receiving new images from the UAV, Node-RED\
    \ send them to the \ncloud for recognition or storage, using the Watson Visual\
    \ Recognition and \nCloudant nodes respectively. Ultimately, based on the results\
    \ received from the \nWVR node, a message is sent to the industrial control system\
    \ using the OPC UA \nnodes to adjust the concrete plant's production. Figure 4.3\
    \ shows the Node-RED \nflow and the connections between the nodes. \n \n \n65\
    \ \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots,\
    \ Visual Recognition and Cloud/Edge \nComputing Services \n \nFigure 4.3. Node-RED\
    \ flow in the IoT gateway including the path from the PLCs to the \nUAV, from\
    \ the UAV to IBM Watson, and from Watson to the control center. \n \n \n2.1. Use\
    \ Case description   \n \nConcrete batching plants form part of the construction\
    \ sector. Their many \nimportant components include cement and bins, aggregate,\
    \ aggregate batchers, \ncement silos, dust collectors, conveyors, mixers, heaters,\
    \ and control panels. \nConcrete plants involve a human–machine interaction between\
    \ the operator and \nthe control system. The operator inputs the concrete formula\
    \ by specifying the \nquantities of material to be mixed and this data is processed\
    \ by a control system \nso that the correct amount of material is conveyed to\
    \ the mixer (Figure 4.4). The \nmaterials used in the concrete plant are cement,\
    \ admixtures, aggregates, and \nwater. The quality and uniformity of the concrete\
    \ depend on the slump value, air \ncontent, water-cement ratio, and homogeneity.\
    \ \n \n \nFigure 4.4. SCADA Industrial concrete plant with a typical concrete\
    \ formula. \n \nTraditionally, microwave sensors have been used in aggregate bins\
    \ to \nmeasure the aggregate water content and then adjust the formula as required\
    \ to \n \n66 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \ncontrol concrete\
    \ quality. Aggregates of different sizes are stored in bins for \ndifferent formulas.\
    \ Due to some errors during the filtering and unloading \nprocess, these materials\
    \ are sometimes mixed incorrectly, affecting concrete \nconsistency and quality.\
    \ Both the UAV camera and the IBM WVR service in the \ncloud can track the state\
    \ of the aggregate materials being transported on the \nconveyor belts with the\
    \ aim of adjusting the production process. \nThe cloud service is used to classify\
    \ normal and mixed aggregates. The role \nof the UAV in this is to take pictures\
    \ when materials are being transported on the \nbelts before they reach the mixer.\
    \ The cloud classifies each image sent by the \ndrone and returns the results\
    \ to the IoT gateway as a score between 0.0 and 1.0 \nfor each class. This result\
    \ is sent to the PLC after being processed in the IoT \nGateway. Using these results,\
    \ any excess amount of a material can be measured, \nand the necessary adjustments\
    \ can be made to obtain the final formula. This \noperation eliminates wasted\
    \ time and allows the desired formula to be obtained \nbefore the final mixing.\
    \ The proposed approach is considered a cost-effective \nsolution and eliminates\
    \ repeated and unnecessary operator controls, traditional \nmonitoring and control\
    \ systems. \n \n2.2. UAV Mission Planning  \n \nThe novelty of the proposed IoT\
    \ control system is that it provides real-time \ninteraction between an industrial\
    \ control system, UAVs and the cloud. Based on \nthe input information from the\
    \ concrete plant, the UAV can interact and execute \nthe mission automatically\
    \ and provide the necessary photos to the cloud to \ncompute and analyze the data\
    \ by deep learning methods and send the result back \nto the control system for\
    \ decision-making. The drone mission (Figure 4.5) is split \ninto three paths:\
    \ planning the mission, taking photos, and returning to the \nstarting point.\
    \  \nThe drone takes off at position (x, y), climbs to a certain altitude, hovers,\
    \ \nreturns to the start, and lands. The autonomous flight library was based on\
    \ the \nAR.Drone library [189] , which is an implementation of networking protocols\
    \ for \nthe Parrot AR Drone 2.0. This library has four features: a camera projection,\
    \ an \nextended Kalman filter, a PID Controller to control drone position, back-\n\
    projection to estimate distance to an object, and a VSLAM to improve the drone\
    \ \nposition estimates [190-191]. The AR. Drone 2.0 is equipped with sensors with\
    \ \nautomatic stabilization features and precise controls, two cameras, a 60-fps\
    \ \nvertical QVGA camera for measuring ground speed and a 1280 × 720 at 30 fps\
    \ \nresolution front camera with a 92◦ (diagonal) field of view, three-axis \n\
    magnetometer with 6◦ precision, three-axis accelerometer with +/-50 mg \nprecision,\
    \ Ultrasound sensors to measure height, three-axis gyroscope with \n2000◦/s precision,\
    \ and a pressure sensor with +/-10 Pa precision. The drone can \nmonitor its own\
    \ position and mapping (SLAM), robustness and controls. \n \n \n67 \n \nSmart\
    \ IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \n \nFigure 4.5. AR.Drone 2.0 mission in\
    \ the concrete plant. \n \nUAVs are easy to deploy, flexible, can quickly change\
    \ position in a time-\ncritical situation and can be quickly configured. Integrating\
    \ them into a control \nsystem accelerates the production chain by responding\
    \ in real time to the various \nchallenges of the control system thanks to the\
    \ cloud services. Figure 4.6 details \nthe communication process between the different\
    \ parts of the proposed \napproach, including the industrial control system, UAVs\
    \ and the cloud, and data \nflows between the different nodes. Two main applications\
    \ are installed in the IoT \ngateway: the Node.js application and the Node-RED\
    \ application. The former \ncontrols the drone, while the latter facilitates communication.\
    \ \nNode-RED controls the flow by reading data from the OPC UA node, which \n\
    is connected to the automation control system. In case a certain issue is confirmed\
    \ \nby the PLC, Node-RED triggers the UAV mission executed by Node.js. The \n\
    UAV's mission (figure 4.5-4.7) is divided into three parts: planning the mission,\
    \ \ntaking pictures and returning to the starting point. The WVR Node and the\
    \ \nCloudant Node receive the images and send them to the IBM cloud for \nprocessing\
    \ and storage. Node-RED collects the classification scores of each new \nimage\
    \ from the cloud and processes them in the IoT gateway before transmitting \n\
    the evaluation to the control system using OPC UA. \n \n \n68 \n \nSmart IoT Monitoring\
    \ and Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \nFigure 4.6. Communication process in the fog layer. \n\
    \ \n3. Results and Discussion \n \nThe drone in the worksite (concrete batching\
    \ plant) is located in the base \nstation, which is at a distance from the conveyor\
    \ belts the conveyor belts and is \nalways ready to respond to the new demands\
    \ of the industrial control system. \nThe UAV carried out 10 test missions over\
    \ three days in a real concrete plant in \nCartagena, Spain. The first step was\
    \ to fly automatically over a distance of about \n130 m to position the UAV at\
    \ the beginning of the conveyor belts. Then, the UAV \nmoved over the conveyors,\
    \ took pictures and sent them to the IoT gateway. The \nlast step was to bring\
    \ the UAV back to the starting point (Workstation) (Figure \n4.7). \n \nFigure\
    \ 4.7. Path used by the drone to execute the mission in a concrete plant. \n \n\
    \ \n \n \n69 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \n3.1. IBM Watson\
    \ Image Recognition Training  \nOff-board image processing techniques were selected\
    \ due to the asset of the \ncloud services. IBM’s Watson visual recognition (WVR)\
    \ service analyzes the \ncontent of images from the drone camera transmitted through\
    \ the IoT gateway \n(Figure 4.1). MATLAB, OpenCV or TensorFlow could also have\
    \ been used as the \ncontrol system; however, the cloud completes the computing\
    \ activities and \nprovides an efficient time and cost optimization. The WVR service\
    \ can classify \nand train visual content using machine learning techniques. \n\
    WVR is based in part on the technology developed for the IBM multimedia \nanalysis\
    \ and retrieval system (IMARS) [192], supplemented by “deep features” \nthat are\
    \ extracted on Caffe software [193]. The WVR service extracts feature \nvectors\
    \ from a particular layer of a Caffe network for all the supplied examples \n\
    and uses them to train a one-versus-all support vector machine (SVM) model for\
    \ \neach class. The feature extraction process is therefore equivalent to “inferencing”\
    \ \nwith the neural network, but the SVM learning process is less CPU intensive\
    \ than \ninferencing [194]. \nThe Watson service generally accepts a maximum of\
    \ 10,000 images or 100 MB \nper .zip file and a minimum of 10 images per .zip\
    \ file, with different angles and \nscenarios to obtain the maximum precision.\
    \ The service recommends that the \nimages be at least 224 × 224 pixels and contain\
    \ at least 30% of the subject matter. \nIn order to train the custom model, we\
    \ used a dataset of the images captured by \nthe UAV camera from the field of\
    \ practice in different positions. In addition, we \nroughly divided the use case\
    \ into two parts: a mixed material set and a normal \nmaterial set (Figure 4.8).\
    \ \n \n \n                                    (a)                            \
    \                                    (b) \nFigure 4.8. Dataset used to train the\
    \ custom model in WVR service: (a) Shows images \nused to train the Mixed class;\
    \ (b) Shows Images used to train the Normal class. \n \nIn the training stage\
    \ we used the dataset images to create two new classes, a \nMixed class, and a\
    \ Normal class. These classes were grouped to define a single \ncustom model.\
    \ In the testing stage, the results of the Watson tests are shown as a \nconfidence\
    \ score for the image in the range of 0 to 1. A higher score indicates that \n\
    \ \n70 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots,\
    \ Visual Recognition and Cloud/Edge \nComputing Services \nthe class is more likely\
    \ to be depicted in the image. The scores are considered as \na threshold for\
    \ action, and the confidence score are based on training images, \nevaluation\
    \ images, and the types of criteria of the desired classification. Figure \n4.9\
    \ shows the test of three different new images and the results of each class score.\
    \ \nWVR recognized the difference between the images according to the density\
    \ of \nthe normal material on the conveyors. For instance, the confidence score\
    \ for the \ntest-3 .jpg image is 0.92 for the normal class, indicating the greater\
    \ likelihood of \nthis class being in the image. \n \n \nFigure 4.9. Watson visual\
    \ recognition test of new images not used in the training \nphase. \n \n3.1.1\
    \ WVR Performance Evaluation \n \nTo assess the performance of the WVR, we used\
    \ a formula to calculate the \naccuracy as defined by equation (4.1). In our case,\
    \ we tested a data set of more \nthan 100 photos and obtained a final detection\
    \ accuracy of 87.28%. The \nmisclassified cases are listed in Table 4.1, which\
    \ represents the confusion matrix. \nOn the basis of a large number of tests with\
    \ new images not used in the training \nphase, a threshold for each score class\
    \ was defined, a decision was made, and the \norder was sent to the industrial\
    \ control system to adjust the quantities of material \nbeing transported on the\
    \ conveyor belts. \n \n \n                      \n\U0001D434\U0001D450\U0001D450\
    \U0001D462\U0001D45F\U0001D44E\U0001D450\U0001D466 =\n\U0001D447\U0001D443 + \U0001D447\
    \U0001D441\n\U0001D447\U0001D443 + \U0001D447\U0001D441 + \U0001D439\U0001D443\
    \ + \U0001D439\U0001D441 \n            \n(4.1) \n \n \nWhere TP is the number\
    \ of positive samples judged to be positive, FP \nrepresents the number of negatives\
    \ samples that are judged to be positive, FN is \nthe number of positive samples\
    \ judged to be negative, and TN the number of \nnegative samples judged negative.\
    \ \n \n \n71 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \n \nTable 4.1.\
    \ Confusion matrix \n \nPredictive Positive \nPredictive Negative \nTrue Positive\
    \ \n58 (TP) \n6 (FN) \nTrue Negative \n9 (FP) \n45  (TN) \n \nAfter training the\
    \ WVR model in the cloud, the WVR Node can send the new \nphotos received in the\
    \ IoT gateway to the cloud service (Figure 4.10). The cloud \nservice classifies\
    \ the new photos and returns the results to the WVR node as a \nscores for each\
    \ class, which are then analyzed and sent to the PLC via the OPC \nUA protocol.\
    \ Figure 4.10 shows the results obtained from the WVR node in Node-\nRED. \n \n\
    Figure 4.10. Node-RED flow and WVR results of an UAV photo \n \n3.2. Delay Assessment\
    \ in the Proposed Platform \nThis section presents the RTD time metrics of the\
    \ IoT gateway connections in \nits conditions of use and highlights the crucial\
    \ role of the IoT gateway in terms \nof latency. In this application, the IoT\
    \ gateway is connected to different systems \nwith different transmitted data.\
    \ Below, we evaluate this difference by using three \ngateways with different\
    \ performances. Each IoT gateway has its own software \nand hardware components\
    \ to process the data with different processing times. \nTable 4.2 shows the specification\
    \ of each of the three selected platforms. \n \nTable 4.2. Specification of each\
    \ machine environment. \n \nSiemens Gateway \nIOT2040 \nRaspberry Pi 3 \nModel\
    \ B \nToshiba \nSATELLITE C870 \nEthernet \n2 x 10/100 Ethernet \nRJ45 \n10/100\
    \ BaseT Ethernet \nsocket \n10/100 BaseT \nEthernet RJ-45 \nProcessor \nIntel\
    \ Quark x1020 \n400 MHz \n1.2 GHz Quad-Core ARMv7 \nIntel Core i3 2348-M \nCPU\
    \ 2.3GHz \nOperation \nSystem \nLinux Kernel 4-4-18 \nYocto Standard \nLinux Raspbian\
    \ 4.14.79-v7+ \n \nWindows 7 \nProfessional \nRAM \n1 GB \n1 GB \n8 GB \nDisk\
    \ Memory \n32 GB \n16 GB \n500 GB \n \n \n72 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \n \n3.2.1. OPC Experimental Method and Results \n \nA case study was\
    \ used to define the latency of the OPC UA client-server \narchitecture. The experimental\
    \ set-up was based on an industrial plant and \nsoftware in addition to three\
    \ different IoT-based platforms. The industrial control \nsystem deployed as an\
    \ OPC UA server uses a Siemens S7-1512 with embedded \nOPC UA communication stack.\
    \ The OPC UA client is implemented using Node-\nRED OPC UA client node in the\
    \ three different devices, the IoT gateway IOT2040 \nfrom Siemens (S-G), a PC\
    \ computer Toshiba SATELLITE (PC-G), and a Raspberry \nPi 3 Model B (RPI-G) (Figure\
    \ 4.11). In the first step of the latency study, we \ncompared the RTD with the\
    \ three different devices considered as OPC UA client \nattached to the same Siemens\
    \ S7-1512 OPC UA server network. \n \n \nFigure 4.11. OPC UA delay in OPC UA client\
    \ server in an Ethernet network. \n \nThe given application is deployed in a local\
    \ network and is based on a typical \nuse case which consists in reading a bit\
    \ from the OPC UA server. All the RTD \nmeasurements were performed on the same\
    \ network. Under these conditions, we \nconsider that RTD delay is derived mainly\
    \ from the Tx software latency of the \nsoftware stack of device X (Equation3.4)\
    \ assuming an insignificant hardware \nlatency tH of the wires and the switch.\
    \ \nAn MX machine is defined as well as a pair of software setup SW and a \nhardware\
    \ setup HW : \n           \U0001D440\U0001D465 = (\U0001D43B\U0001D464,\U0001D446\
    \U0001D464)                                              (4.2) \n \nThe hardware\
    \ setup HW is defined as the set of all hardware elements in this \nmachine and\
    \ the software setup SW is defined as the set of all software elements \n[195].\
    \ \n \n \U0001D43B\U0001D464 = {\U0001D440\U0001D452\U0001D45A\U0001D45C\U0001D45F\
    \U0001D466,\U0001D443\U0001D45F\U0001D45C\U0001D450\U0001D452\U0001D460\U0001D460\
    \U0001D45C\U0001D45F, \U0001D441\U0001D43C\U0001D436 … }                     \
    \               (4.3) \n                                     \U0001D446\U0001D464\
    \ = {\U0001D434\U0001D45D\U0001D45D\U0001D459\U0001D456\U0001D450\U0001D44E\U0001D461\
    \U0001D456\U0001D45C\U0001D45B, \U0001D442\U0001D446, \U0001D437\U0001D45F\U0001D456\
    \U0001D463\U0001D452\U0001D45F\U0001D460 … }                                 \
    \    (4.4) \n \n73 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \nIn order to\
    \ measure latency, a timestamp contained in an injection node in Node-\nRED was\
    \ used (Figure 4.12). In every request, the timestamp request is saved by \na\
    \ function node. The latency L is defined as the difference between the timestamp\
    \ \nof the server response and the client timestamp request saved in the first\
    \ function \nnode. Hence, latency L is measured as : \n \n\U0001D43F = \U0001D447\
    \U0001D45F\U0001D452\U0001D45E\U0001D462\U0001D452\U0001D460\U0001D461 − \U0001D447\
    \U0001D45F\U0001D452\U0001D460\U0001D45D\U0001D45C\U0001D45B\U0001D460\U0001D452\
    \ = \U0001D445\U0001D447\U0001D437)                                      (4.5)\
    \ \n \n \nFigure 4.12. Node-RED flow used to calculate round trip latency (OPC\
    \ UA Client to the \nOPC UA Server). \n \nThe latency results are summarized in\
    \ Table 4.3, showing the minimal and \nmaximal values, RTD average, and the standard\
    \ deviation calculated for each fog \ncomputing machine. The OPC UA requests were\
    \ repeated each second to read \nthe one-bit value in the OPC UA server (Figure\
    \ 4.12). All the samples were \nthoroughly checked for the same architecture on\
    \ different days in an \nexperimental campaign with more than 5000 valid samples.\
    \ S-G gateway latency \nis higher than in the RPI-G and PC-G gateways, approximately\
    \ three times that \nof the RPI-G and seven times that of the S-G. This difference\
    \ is evident in the \nprobability density function as shown in Figure 4.13. The\
    \ shapes of the RPI-G \nand the PC-G are almost the same with a single peak, while\
    \ the S-G shape is \nnarrower and scattered over a large time area. \n \nTable\
    \ 4.3. RTD test of 5200 samples from the OPC UA client to the OPC UA server (PLC)\
    \ \nover different clients through different machines. \n \nClient Test \nEnvironment\
    \ \nData Type \nAverage \nStandard \nDeviation \nMinimum \nLatency \nMaximum \n\
    Latency \nS-G \nBOOL (1 bit) \n23.160 ms \n23.56 ms \n19 ms \n878 ms \nRPI-G \n\
    BOOL (1 bit) \n8.22 ms \n3.48 ms \n5 ms \n76 ms \nPC-G \nBOOL (1 bit) \n3.288\
    \ ms \n2.65 ms \n0 ms \n32 ms \n \n74 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \n \nFigure 4.13. OPC UA client-server RTD to read one bit through\
    \ different machines. \n \nIn order to analyze this large difference in the recorded\
    \ RTD between RPI-G \nand S-G, we continuously monitored the CPU load for 5 min\
    \ during the OPC UA \nchannel' s RTD. The RPI-G and S-G gateways were tested individually\
    \ in the \nsame network conditions and running only Node-RED, which runs the OPC\
    \ UA \nclient. The computed CPU usage was calculated as the average of all cores\
    \ of the \nRPI-G and S-G gateways (see figure 4.14). \n \n \n \nFigure 4.14. (a)\
    \ Simulation results of CPU load (%) versus OPC UA RTD (ms) in \nthe S-G; (b)\
    \ Simulation results of CPU load (%) versus OPC UA RTD (ms) in the \nRPI-G. \n\
    \ \nGiven the analogy of a similar situation [196], which assumes that the larger\
    \ \nthe RTD pattern peaks the higher the probability they are due to the higher\
    \ CPU \nload, although the recorded CPU load patterns are not only due to the\
    \ OPC UA \nclient implemented in Node-RED. Nonetheless, we compared the impact\
    \ of CPU \nusage in the RTD as regards the same conditions in the two gateways.\
    \ It should \n \n75 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \nbe noted that\
    \ the impact of Node.js can be estimated to be around 10% of the \nprocessing\
    \ power of the gateway used in the demonstration case, and the number \nof devices\
    \ connected to the gateway linearly increases CPU and memory usage \n[73]. \n\
    There is always intense use of CPU in the S-G RTD when high latency is \ndetected.\
    \ The S-G peaks sometimes exceed 400 ms (Figure 4.14, Table 4.3) while \nin the\
    \ RPI-G they do not exceed 80 ms. Furthermore, the average CPU load of the \n\
    RPI-G is much lower than that of the S-G. The average value of the CPU load in\
    \ \nthe S-G is around 8%, while in the RPI-G it is around 1.7% and the number\
    \ of \ndevices connected to the gateway linearly increases the CPU load. \n \n\
    3.2.2. UAV Experimental Results \n \nThe streaming quality of the proposed Node.js\
    \ application was measured \nunder certain conditions of use to compare the response\
    \ time on different IoT \ngateways in the same configurations and conditions.\
    \ The transmission channel, \nframe rates and compression techniques were the\
    \ same in all the tests on the \nrecording of camera images and saving them to\
    \ a folder in the IoT gateway. The \nimage frames were captured and registered\
    \ in a buffer before being sent to the \ngateway. Encoding was performed by FFMPEG\
    \ codec, and the received frames \nwere decoded in the gateway before being saved\
    \ on the gateway disk. \n \n• Codec Latency \n \nThe AR.Drone library [197] uses\
    \ the basic H264 profile (MPEG4.10 AVC) for \nhigh quality streaming and video\
    \ recording. The Baseline profile was targeted at \napplications in which a minimum\
    \ of computational complexity and a maximum \nof error robustness are required.\
    \ H.264/MPEG4-AVC baseline supports two slice-\ncoding types (I and P slice types),\
    \ designed for progressive video such as video \nconferencing, video-over-IP,\
    \ and mobile applications [198]. The simplest is \nthe I slice, in which all macro-blocks\
    \ are coded without referring to any other \npictures in the video sequence. Previously\
    \ coded images are used to form a \nprediction signal for macro-blocks of the\
    \ predictive-coded P [199]. \nTheoretically, based on Equation (3.12), UAV delay\
    \ can be estimated by: \n \n\U0001D447 = \U0001D447\U0001D450\U0001D44E\U0001D45D\
    \ + 2. (\U0001D447\U0001D452\U0001D45B\U0001D450 + \U0001D447\U0001D461\U0001D465\
    \ + \U0001D447\U0001D451\U0001D452\U0001D450 + \U0001D447\U0001D451\U0001D456\U0001D460\
    \U0001D45D)                                  (4.6) \n \n \nThe experiments focus\
    \ on the mission delay generated by taking pictures in \na concrete production\
    \ plant. We measured the time needed for the drone to \nconnect with the IoT gateway,\
    \ take a picture and save it in a file in the IoT \ngateway (WriteFile function\
    \ from Node.js). Table 4.4 shows the results of an \nAR.Drone 2.0 mission with\
    \ around 200 images on the Node.js application, \n \n76 \n \nSmart IoT Monitoring\
    \ and Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \ntriggered from Node-RED. The latencies in both machines\
    \ are expressed in \nmilliseconds and calculated in the Node.js application. \n\
    \ \nTable 4.4. RTD Test of 200 photos sent from the IoT gateway to the AR.drone\
    \ \n2.0. \n \nThe results provided in Table 4.4 shows the large difference in\
    \ terms of \nlatency between RPI-G, S-G and PC-G. The average RPI-G latency is\
    \ almost three \ntimes that of PC-G, and RPI-G standard deviation is much higher\
    \ than in PC-G. \nNote that these tests were made with an image resolution of\
    \ 640 × 360 px, frame \nrate of 5 fps and a codec with H264 baseline. \nOn the\
    \ other hand, the S-G results are consistently different from those of PC-\nG\
    \ and RPI-G; the average S-G latency is very high, while the standard deviation\
    \ \nis lower than RPI-G. \nFigure 4.15 shows the probability density function\
    \ of the delay of the drone \nconnected to the gateway when successive pictures\
    \ from PC-G and RPI-G are \ntaken. While Figure 4.16 shows the probability density\
    \ function of the delay of \nthe drone connected to the gateway when successive\
    \ pictures from S-G are taken. \nHere, the distributions are clearly different,\
    \ the data spreading of the PC-G \ndistribution covers a narrower range, with\
    \ a larger spread in the S-G and RPI-G \ndistributions. \n \n \nFigure 4.15. Probability\
    \ density function of the delay of the drone connected to \nthe gateway when successive\
    \ pictures from PC-G and RPI-G are taken. \n \nClient Test \nEnvironment \nConnection\
    \ \nEstablished \nAverage  \nStandard \nDeviation  \nMinimum \nLatency \nMaximum\
    \ \nLatency \nS-G \n11429 ms \n1229.92 ms \n365.71 ms \n160 ms \n2906 ms \nRPI-G\
    \  \n5348 ms \n317.76 ms \n411.18 ms \n12 ms \n1706 ms \nPC-G  \n4562 ms \n132.72\
    \ ms \n35.90 ms \n4 ms \n230 ms \n \n77 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \n \nFigure 4.16. Probability density function of the delay of the\
    \ drone connected to \nthe gateway when successive pictures from S-G are taken.\
    \ \n \nFigure 4.17, figure 4.18 and figure 4.19 compare the CPU load of the same\
    \ \nprogram implemented in the IoT gateways. The program continuously takes \n\
    images from the drone and stores them in a file in the gateway. The first time\
    \ \nperiod (red interval) in all three graphs shows the first connection between\
    \ the \ndrone and the gateways, while the rest of the time period is the time\
    \ of execution \nof the Node.js program in the gateways. \n \n \nFigure 4.17.\
    \ CPU Load while taking successive photos and writing them in a \nfolder in the\
    \ PC-G. \n \n \nFigure 4.18. CPU Load while taking successive photos and writing\
    \ them in a \nfolder in the RPI-G. \n \n78 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \n \n \nFigure 4.19. CPU Load while taking successive photos and writing\
    \ them in a \nfolder in the S-G. \n \nThe three IoT gateways have different environmental\
    \ specifications. Figures \n4.17-4.19 show these differences in terms of CPU usage\
    \ in the three gateways \nwhile executing the mission. In S-G, it increases from\
    \ 3% to 100%, while in RPI-\nG, the CPU load increases from 2% to 60%. In the\
    \ PC-G gateway the average CPU \nload while executing the mission was around 20%.\
    \ This difference is justified \nmainly by the numbers of cores implemented in\
    \ each gateway processor. S-G \nused a 400 MHz Intel Quark ×1020 processor with\
    \ a single core, while RPI-G used \na 1.2 GHz Quad-Core ARMv7 processor with four\
    \ cores. Furthermore, RPI-G and \nPC-G both support the Graphics Processing Unit\
    \ (GPU), while S-G does not. \n \n3.2.3. Watson Experimental Method \n \nThe IBM\
    \ Watson visual recognition service uses deep neural networks to \nanalyze images\
    \ and is currently operated in a data center in Dallas (USA). \nMultiple servers\
    \ are used to ensure high throughput and reliability. Node-RED \nprovides a node\
    \ to connect to the WVR service which takes an image as input \nand produces a\
    \ set of image labels as output. \nThe experiments carried out were based on Equation\
    \ 4.5 and used the Node-\nRED flow. The latency results are summarized in Table\
    \ 4.5, the RTD average, \nstandard deviation, minimal and maximal values calculated\
    \ for each fog \ncomputing machine.  \nThe experiment was repeated for one sample\
    \ field case image less than a data \nblock size of 154,076 bytes. All the samples\
    \ were carefully and thoroughly \nchecked for the same architecture on the same\
    \ day. Each experimental campaign \nhad around 100 valid samples for each machine.\
    \ Between each 100 requests, the \nnext request is triggered at the time of receiving\
    \ the results of the previous \nrequest from the WVR. \n \n \n79 \n \nSmart IoT\
    \ Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \nTable 4.5. RTD test of 100 samples from\
    \ the IoT gateway to IBM Watson over different \nmachines.  \n \n \nThe results\
    \ reported in Table 4 display the differences between the different \nfog machines.\
    \ The average RPI-G and PC-G scores are lower than the S-G. \nHowever, RPI-G is\
    \ faster than S-G and has a larger standard deviation, while PC-\nG is faster\
    \ than RSP-G with a low standard deviation. The probability density \nfunction\
    \ estimates of the WVR delay for the three gateway machines are given in \n(Figure\
    \ 4.20). In this case, the probability density of the S-G has almost the same\
    \ \ncurvature as that of RPI-G, while the probability density of PC-G is larger.\
    \ \n \n \nFigure 4.20. Probability density function estimation of IBM WVR latency\
    \ to classify an \nimage located in the IoT gateway. \n \nGiven that the WVR node\
    \ in Node-RED relies on the HTTP protocol to send \nthe images to the cloud, we\
    \ performed another test using SpeedTest to measure \nthe HTTP throughput between\
    \ the web server and the client over the three \ngateways considered as clients\
    \ (on the same day with the same network \nconditions). The results obtained in\
    \ Table 4.6 indicate similar results for the \ndownload, while the S-G upload\
    \ is lower than the other gateways. \n \n \nClient Test \nEnvironment \nAverage\
    \  \nStandard \nDeviation  \nMinimum \nLatency \nMaximum \nLatency \nS-G \n1913.18\
    \ ms \n522.17 ms \n1454 ms \n5594 ms \nRPI-G \n1373.09 ms \n453.64 ms \n1080 ms\
    \ \n5151 ms \nPC-G \n1129.29 ms \n181.97 ms \n980 ms \n2491 ms \n \n80 \n \nSmart\
    \ IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \nTable 4.6. Speed Test over the three gateways\
    \ (S-G, RPI-G, PC-G) \nMachine \nPing \nDownload \nUpload \nS-G \n169.4 ms \n\
    16.3 Mbps \n9.5 Mbps \nRPI-G \n96.4 ms \n17.6 Mbps \n13.8 Mbps \nPC-G \n55.7 ms\
    \ \n17.5 Mbps \n12.3 Mbps \n \n \n \nII.  Autonomous Underwater Monitoring System\
    \ for \nDetecting Life on the Seabed by Means of \nComputer Vision Cloud Services\
    \ \n \n \n1. General introduction \n \nThe world's seas, as a valuable asset and\
    \ a vital part of its ecology, must be \nprotected as an essential source of life,\
    \ food and wealth. This implies monitoring \nsystems to ensure their condition\
    \ and sustainable management, which involves \nsurveying chemical and physical\
    \ parameters related to water quality, such as \ndissolved oxygen, nitrates, salinity,\
    \ temperature, density and chlorophyll levels, \namong others. Other purposes\
    \ of seabed monitoring are the detection and \nconservation of archaeological\
    \ artifacts and the monitoring of the state of marine \nflora and fauna, including\
    \ particularly sensitive endangered species [200]. \nStudies have been carried\
    \ out in different regions of the Mediterranean, \nparticularly in the Mar Menor,\
    \ a zone of particular interest due to its exceptional \nenvironment. Studies\
    \ have been carried out in different regions of the \nMediterranean, particularly\
    \ in the Mar Menor, a zone of particular interest due \nto its exceptional environment.\
    \  \nThe Mar Menor in southeast Spain, with unique salinity and temperature \n\
    characteristics, is Europe’s largest Salt Lake, with an area of 180 km2. It is\
    \ a \nvaluable resource with a remarkable ecosystem and a wide range of habitats\
    \ for \nendangered species. It has been the subject of numerous scientific studies\
    \ when \nit was recently contaminated biologically and chemically by torrential\
    \ rains \ncontaining large amounts of fresh water and agricultural runoff from\
    \ the \nsurrounding farmland, which affected its flora and fauna [200]. It also\
    \ shelters \nconsiderable plankton and phytobenthic populations during the warm\
    \ season. \nAll these factors have affected many of its indigenous species. \n\
    27 types of habitats of special interest have been inventoried in the Mar \nMenor\
    \ and its surroundings, eight of which are of priority [201]. Protected \nspecies\
    \ are also abundant and include seagrass meadows (Cymodocea nodosa \nand Ruppia\
    \ cirrhosa), marine fauna of special interest, such as seahorses \n \n81 \n \n\
    Smart IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual\
    \ Recognition and Cloud/Edge \nComputing Services \n(Hippocampus ramulosus) or\
    \ toothed carp (Aphanius iberus), large quantities of \nfan mussels (Pinna nobilis)\
    \ and a wide range of seabirds [202]. The fan mussel is \nan endemic bivalve mollusc,\
    \ the largest in the Mediterranean and the second \nlargest in the world. The\
    \ International Union for the Conservation of Nature \n(IUCN) has included Pinna\
    \ nobilis in its updated list of critically endangered \nspecies due to parasitic\
    \ diseases [203]. In 2019, the discovery of a series of \nspecimens in the Mar\
    \ Menor confirmed that this natural area was a refuge for \nthis endangered species\
    \ on the verge of extinction along the entire Mediterranean \ncoastline and that\
    \ it was therefore essential for its monitoring. Although such \nmonitoring can\
    \ be carried out from manned vessels, it is time-consuming, \nlaborious and costly\
    \ and can be carried out much more effectively by AUVs [204]. \nAUVs are now widely\
    \ in use for a variety of tasks, including oceanographic \nsurveys, mine clearance,\
    \ demining and bathymetric data collection in marine and \nriver environments\
    \ [205]. They are valuable for mapping underwater \nenvironments and are playing\
    \ an increasing role in marine development [8]. \nThey now have power sources\
    \ and an intelligent control system that can perform \nautonomously programmed\
    \ tasks with appropriate decision-making capabilities \n[200]. Advances in computer\
    \ science, sensor technology, new materials and \nadvanced algorithms have significantly\
    \ increased their performance, although \nmany issues remain to be resolved [206,207].\
    \ \nAlong with the challenges and difficulties of an autonomous robot \nnavigating\
    \ in an unstructured environment, the marine environment has its own \nlimitations,\
    \ not only because of the currents but also because of the difficulty of \ngeolocating\
    \ the submerged AUV. The absence of communication networks and \nthe complexity\
    \ of real-time connection is also a drawback and could be a \ndetermining factor\
    \ not only for transmitting exploration results, but also for \nleveraging increased\
    \ computing capacity and information management when \nnecessary, such as artificial\
    \ intelligence (AI) provided by cloud computing \nservices.  \nSome AUV architectures\
    \ imply the technological challenge of a high \nprocessing, connection and communication\
    \ capacity. This necessitates an \narchitecture that is capable of integrating\
    \ with a nearby base station, the Internet \nand cloud architectures. The information\
    \ gathered during an operation also \nentails interpretation, which can be crucial\
    \ for decision making. This means that \nnot only the local connection is important,\
    \ as well as the connection with web \nservices (cloud computing, data centers,\
    \ etc.). The latter can be used to create \nwizards for specific purposes and\
    \ processes to which complex and specific tasks \ncan be delegated. \nWe propose\
    \ and assess an AUV system designed to collect and interpret \nunderwater images\
    \ in Mar Menor in order to trace the fan mussel population in \nreal time, using\
    \ georeferenced mosaics generated from the images by an \nautomatic processing\
    \ method. \n \n \n82 \n \nSmart IoT Monitoring and Real-Time Control Based On\
    \ Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services \n\
    \ \n \n \n2. System model \n \nThe proposed AUV-IoT architecture is structured\
    \ in three layers, with the \nAUV being in the data generation and pre-processing\
    \ layer. The first layer \nconsists of an AUV composed of different sensors and\
    \ blocks for data generation, \nconversion and pre-processing (figure 4.21). The\
    \ pre-processing system is \ndeployed in an IoT gateway installed in the head\
    \ box and connected to the \ncamera by a switch. The IoT Gateway is defined as\
    \ an edge node. Another layer \nis the data communication layer with the cloud\
    \ via Wi-Fi or 4G networks. The \nlast layer is a back-end cloud with image processing\
    \ techniques. \n \nFigure 4.21. Proposed AUV-IoT Platform \n \nAs shown in Figure\
    \ 4.22, the three layers are made up of different electronic \ndevices with access\
    \ to software services, the physical layer is constituted by a \nvariety of electronic\
    \ devices interconnected by three different networks \naccording to their functionality:\
    \ The Internet/cloud network, the Ethernet \nnetwork and the CAN (controller area\
    \ network). The CAN network is composed \nof one master and four slave nodes.\
    \ Each node consists of an electronic card \nspecifically designed for this vehicle\
    \ and its assigned tasks, and has as a core a \nPIC 18F4685 microcontroller, working\
    \ at a frequency of 25 MHz. \n \n \n83 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \n \nFigure 4.22. Proposed hardware architecture. \n \nThe CAN network\
    \ is the fieldbus that interconnects the elements dedicated \nto instrumentation,\
    \ measurement and actuation. It connects equipment devoted \nto specific processes\
    \ (inputs/outputs, sensor reading, engine control). The CAN \nnetwork has a master/slave\
    \ configuration, and the elements of this network \ncommunicate via the CAN field\
    \ bus, using the CANopen protocol at a speed of \n250 kbps, sufficient for real-time\
    \ exchange of process information. This protocol \nis particularly robust and\
    \ immune to electromagnetic interference, a feature that \nmakes it ideal for\
    \ this vehicle. \nThe CAN network consists of four slave nodes and a master. Each\
    \ node \nconsists of an electronic board specially designed for this vehicle and\
    \ the tasks \nassigned to it, and has a PIC 18F4685 microcontroller as its core,\
    \ operating at a \nfrequency of 25 MHz. The main functions of each node are as\
    \ follows: \n \n• \nNode 1 (in the head of the vehicle) manages its movement,\
    \ lighting, \ncamera power, tilt reading (pitch and roll) and the acquisition\
    \ of inertial \nunit variables. \n• \nNode 2 (DVL: Doppler velocity logger) manages\
    \ data acquisition \nand body tilt reading (pitch and roll). \n• \nNode 3 governs\
    \ GPS reading, engine management and control \n(propulsion, rudder and dive).\
    \ \n• \nNode 4 monitors marine instrumentation sensors (side-scan sonar, \nimage\
    \ sonar, microUSBL) and their energy management. \n• \nThe master node consists\
    \ of a National Instrument single-board \nRemote Input/Output (NI sbRIO) 9606\
    \ (the main vehicle controller). Its \nfunction in this network is to collect\
    \ process information from each of the \nnodes and send commands. It is the link\
    \ with the superior Ethernet \nnetwork. \n \n84 \n \nSmart IoT Monitoring and\
    \ Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \n \nThe Ethernet network permits higher data transfer\
    \ rates between devices and \nis formed by the AUV sbRIO control system, IP camera,\
    \ IoT gateway, and the 4G \nrouter. All of these are connected to the buoy via\
    \ an umbilical cable. \nEthernet/DSL (Digital Subscriber Line) gateways are used\
    \ owing to the number \nof wires in the umbilical cable connecting the vehicle\
    \ to the surface buoy (only \ntwo wires are available for data).  \nAs at least\
    \ four cables are used with Ethernet, and only two with DSL, the \nEthernet protocol\
    \ is converted to DSL before and after the umbilical cable by the \nDSL to Ethernet\
    \ gateways. The local bandwidth is 100.0 Mbps, with latencies of \nless than 1\
    \ ms. \nThe Internet/cloud network connects the vehicle to the cloud. The 4G router\
    \ \nintegrated in the surface buoy ensures the connection to the cloud. The aim\
    \ of \nthis network is the communication of the IoT gateway with the cloud and\
    \ \ncommunication of sbRIO control system with IUNO (Interface for Unmanned \n\
    Drones) fleet management software. The IUNO software platform was designed \n\
    at the Automation and Autonomous Robotics Division (DAyRA) of the \nPolytechnic\
    \ University of Cartagena. The platform is intended to manage the \nintegrated\
    \ control of multiple unmanned marine vehicles with the aim of \nsimplifying maritime\
    \ operations. The results obtained from each vehicle, \nregardless of its characteristics,\
    \ facilitate the success of the operation with a high \ndegree of automation [200].\
    \ AEGIR is the name of the AUV developed by \nDAyRA, and it is the main vehicle\
    \ used in this paper; its structure is described in \nFigure 4.22. \n \n3.1. IoT\
    \ Gateway: The Edge Node and Connection to the Cloud \n \nThe implemented IoT\
    \ gateway is capable of connecting the sensor network \nto the cloud computing\
    \ infrastructure, performing edge computing and serving \nas a bridge between\
    \ the sensor networks and the cloud services [208]. \nExperiments were carried\
    \ out using Python installed in the IoT gateway. \nThe Python program employed\
    \ serves as an interface to communicate with \nthe submarine sensors and actuators,\
    \ the cloud computer vision APIs and the \nunderwater controller (Figure 4.23).\
    \ \n \n \n85 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \n \nFigure 4.23.\
    \ Node intercommunications and concurrent threads in the IoT \ngateway. \n \n\
    Python has a built-in support for scientific computing. Its use is growing \n\
    fastest in data science and machine learning [209]. Versatility, the stability\
    \ of \nlibraries with great support, and ease of use are its main benefits [210].\
    \ The IoT \ngateway also features Open-source Computer Vision (OpenCV) which is\
    \ a \nlibrary of programming functions mainly for real-time CV. In our application,\
    \ \nOpenCV is used for live video streaming over an Ethernet network connected\
    \ to \nthe prospective IP camera (model Sony SNC-CH110) installed in the head\
    \ box. \nAll the Python cloud libraries required for image recognition are installed\
    \ in the \nIoT gateway. \nWhereas the Python program in the IoT gateway is started\
    \ (Algorithm 1), \nconnection is established with the camera by the Real-Time\
    \ Streaming Protocol \n(RTSP). The Python program in the IoT gateway is executed\
    \ to run four threads \n(tasks) at the same time (Figure 4.24). \nThe first thread\
    \ is tasked with capturing and streaming video images from \nthe IP camera to\
    \ the IoT gateway internal memory. If a specimen is detected using \nthe cloud\
    \ object detection service, the AUV’s movements are adjusted to focus \nthe camera\
    \ on the object. The distance between the detected specimen and the \nvehicle\
    \ is computed in the IoT gateway and employed to steer the AUV to track \nits\
    \ position. The AUV’s heading and mission control commands are routed via \nTCP/IP\
    \ (Transmission Control Protocol/Internet Protocol) to the sbRIO controller \n\
    in the head box, which is connected to several nodes via a CAN bus protocol. \n\
    Each node is connected to a different group of sensors and actuators.  \nThe cloud\
    \ service used in this case is the vision object detection service, \nwhich allows\
    \ training of customized machine learning models that are able to \ndetect individual\
    \ objects in a given image along with their bounding box and \nlabel. There are\
    \ many different cloud APIs for computer vision, e.g., IBM, Google, \nMicrosoft\
    \ Azure and Amazon. They all provide fairly similar capabilities, \nalthough some\
    \ emphasize object recognition, Amazon, or building custom \n \n86 \n \nSmart\
    \ IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \nmodels, like Microsoft Azure and IBM.\
    \ The strength of these cloud APIs is their \nability to develop custom models\
    \ rapidly and download trained custom models \nto deploy them on the edge for\
    \ real-time applications and low-latency \nrequirements [211-212]. \nTo appraise\
    \ the effectiveness of the suggested platform, we assessed its \noverall latency,\
    \ in order to act quickly when an underwater specimen is detected \nand control\
    \ the AUV mission according to the cloud results of each photo. The \nPython program\
    \ is divided into four threads; however, the response time of the \ncloud services\
    \ takes significantly longer, depending on different factors. Figure \n4.23 presents\
    \ clearly the connection between the IoT gateway and the different \nsystems.\
    \ Each thread of the IoT gateway is responsible for synchronously \ntriggering\
    \ a task and ensures maintenance of the connection. \n \n3. The AUV-IoT Architecture\
    \ Development \n \nIn this section, we itemize and outline the development of\
    \ the above-\nmentioned IoT-AUV autonomous system and its network protocols, portraying\
    \ \nfive main blocks, namely, the IoT gateway, the IP camera, the AUV control\
    \ \nsystem, the AUV control station and the cloud.  \nThe overall mission is triggered\
    \ in the AUV control station by setting the \ndesired waypoints and activating\
    \ the AUV engines and IP camera streaming. The \nIoT gateway in the head box connects\
    \ the AUV nodes and the IP camera with \ncloud services. The IoT gateway receives\
    \ image data from the IP camera in the \nsubmarine’s head box and sensor data\
    \ from the body box. Likewise, the IoT \ngateway seizes the image processing results\
    \ from the cloud for each sent photo. \nIf a fan mussel is detected, the results\
    \ contain its delimitation box in the image \nand the percentage of image accuracy.\
    \ When a fan mussel is detected using the \ncloud API (Application Programming\
    \ Interface), the IoT gateway links up with \nthe main controller to modify the\
    \ submarine’s mission and track the specimen \ndetected. \nThe submarine’s new\
    \ mission is based on the results received from the cloud \nAPI and the algorithm\
    \ processed in the IoT gateway. The algorithm implemented \nin the IoT gateway\
    \ is in charge of adjusting AUV movements to keep the targeted \nspecimen in the\
    \ centre of the field of view. The distance to the detected specimen \nis computed\
    \ using the cloud API and a triangular similarity algorithm [213-214].  \nThe\
    \ desired mission modifications are routed to the main controller to handle \n\
    the engines and vehicle heading. In this case, the AUV’s manual tracking control\
    \ \nis replaced by an automatic specimen detection system using the cloud APIs\
    \ and \nthe distance measurement algorithm implemented in the IoT gateway. A specific\
    \ \narea is explored based on a specific mission with settled waypoints. The tracking\
    \ \nalgorithm in the IoT gateway is triggered automatically if the forward camera\
    \ \ndetects a specimen (Figure 4.24). \n \n87 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \n \n \nFigure 4.24. Communication between platforms. \nThe IoT gateway’s\
    \ main function is to acquire the camera image, timing the \nshot according to\
    \ the AUV’s depth and speed, to obtain photographic mosaics \nwith overlapping\
    \ images. The IoT gateway receives the captured images and \nforwards them to\
    \ the cloud, which uses advanced learning techniques to analyse \nthe results\
    \ and send them to the IoT gateway. The obtained results from the cloud \nare\
    \ exploited to adjust the new underwater mission to pinpoint the specimen’s \n\
    exact location. This is described in Algorithm 1, as well as in the flowchart\
    \ in \nFigure 4.23. \n \nAlgorithm 1. Specimen tracking algorithm \nStart () \n\
    Step 1:  \n     While (mission has not started) {}         \nStep 2: \n     If\
    \ (mission has ended) \n         {End()} \n     Else \n         {Acquire frame\
    \ and send to cloud} \n         {Get the answer} \n         If (accuracy > 20%)\
    \  \n             {Go to step 3} \n         Else \n             {Go to step 2}\
    \ \nStep 3: \n     {Calculate the bounding box centre of detected object} \n \
    \    {Calculate the distance between the centre of the detected nacre bounding\
    \ box (C1) and \n      the center of the captured frame (C2)} \n     {Conversion\
    \ of distance (C = C2–C1) into degrees (new heading and tilt setpoint)} \n   \
    \  {Send command to sbRIO with new heading and tilt setpoint.} \n     If (C==0)\
    \  \n          {Go to step 4} \n \n88 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \n     Else \n          {Go to step 3} \nStep 4: \n     {Send the command\
    \ to sbRIO to set the speed (fixed speed setpoint)} \n     {Take images I1 and\
    \ I2 in two different positions, where P1 and P2 are the pixel widths \n     \
    \ of the objects detected in both images} \n     {Calculate the distance using\
    \ the following equations. \n \n \n \n  \n     where F = 2.34 mm is the focal\
    \ distance, W is the width of the real detected object \n     If (the distance\
    \ D calculated > 2m) \n          {Go to step 4} \n     Else \n          {Go to\
    \ step 5} \nStep 5: \n     {Get accuracy of the specimen image} \n     If (accuracy\
    \ ≥ 80%)  \n          {Save point, save picture and resume mission} \n       \
    \   {Send command to sbRIO to save specimen’s position} \n     Else \n       \
    \   {Go back to the main mission without saving. It is not a specimen} \n    \
    \      {Go to Step 2} \nEnd () \n \n3.3. AUV Control \n \nThe most relevant characteristics\
    \ of the AUV used in the experiment are as \nfollows: the vehicle is physically\
    \ divided into two compartments (head and \nbody), consisting of five thrusters\
    \ (two for propulsion, two for depth control and \none for the rudder) and weighs\
    \ 170 kg. This vehicle is capable of submerging to \n200 m and has 7-hour autonomy.\
    \ Its two battery blocks (one supplies power to \nthe electronics and sensors\
    \ and the second to the thrusters) are reconfigurable to \n24V for greater autonomy\
    \ or to 48V for greater power and cruising speed. It can \nmove at 4 knots and\
    \ perform long-term missions while locating and identifying \nsubmerged targets,\
    \ photogrammetry and sonar inspection of the seabed. It is \nequipped with the\
    \ following devices: image sonar, side scan sonar, micro-USBL \n(UltraShort BaseLine)\
    \ for acoustic positioning, an inertial unit, GPS (Global \nPositioning System),\
    \ a DVL (Doppler Velocity Logger) for measuring \nunderwater movements, a camera\
    \ and a depth meter. \nAs shown in Figure 4.23, our underwater vehicle has a number\
    \ of elements \nand devices interconnected through different networks. While the\
    \ IoT gateway \nis in charge of recognition and communications with the camera\
    \ and the cloud, \nthe sbRIO controller is the AUV’s main control backbone. The\
    \ National \nInstrument sbRIO 9606 embedded controller integrates a real-time\
    \ processor \nwith a reconfigurable FPGA through its LabVIEW environment [215-216].\
    \ It \ncomprises Ethernet, CAN and I/O connectivity, as well as a 400-MHz CPU,\
    \ \n \n89 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \n256MB DRAM,\
    \ 512MB storage, and other features listed in [215-216]. A consistent \ncode for\
    \ the sbRIO controller was fully developed in the LabVIEW environment \nfor AUV\
    \ management, control and command. \nThe modules in the sbRIO’s vehicle control\
    \ program comprise these operations: \n• CAN bus (reading and writing interface):\
    \ There are a number of nodes \nconnected to the vehicle's CAN bus, whose network\
    \ master is the sbRIO. Each \nof the nodes has a series of sensors and actuators\
    \ connected. The function of \nthese blocks is to receive information and send\
    \ commands to the different \nnodes through the CANopen protocol. The type of\
    \ data received or sent will \ndepend on the function of the node. \n• TCP/IP\
    \ \n(reading \nand \nwriting \ninterface): \nThis \nmanages \nTCP/IP \ncommunications\
    \ for receiving commands from IUNO and the IoT gateway, \nas well as sending navigation\
    \ information from the vehicle to the rest of the \nequipment on the Ethernet\
    \ network. \n• Data manipulation: This is responsible for adapting the data formats\
    \ from the \ndifferent sources (CAN, inertial unit, IUNO) to a common format within\
    \ the \nprogram and vice versa: e.g., conversion of latitude received through\
    \ the \nCAN network interface (UINT8 array type, extracted from a buffer) to I32\
    \ \ndata type. \n• Data saving: This saves the process and navigation information\
    \ in the sbRIO \nin TDMS (Technical Data Management Streaming) format files. TDMS\
    \ is a \nbinary measurement file format, focused on storing information in the\
    \ \nsmallest possible space. It can be exported to several formats (csv, xls,\
    \ txt, \netc.). \n• Heading \ncontrol/depth \ncontrol/velocity \ncontrol/heading\
    \ \ntilt \ncontrol: \nManagement of the different control loops for heading, depth,\
    \ velocity and \nhead tilt. These take on special importance in automatic or semi-automatic\
    \ \nnavigation modes. \n• Thruster control: As a result of the previous timed\
    \ loop, a heading, depth or \nposition setpoint is obtained. In this module, they\
    \ are processed to obtain as \na result a PWM (Pulse-Width Modulation) value to\
    \ be applied to each of the \nvehicle’s engines. \n• Automatic (IUNO)/manual mode\
    \ navigation: AEGIR developed at the \nDivision of Automation and Autonomous Robotics\
    \ (DAyRA) of the \nPolytechnic University of Cartagena, and the Ocean Server AUV\
    \ IVER2. \nIUNO’s capabilities and characteristics. An AEGIR vehicle can be handled\
    \ in \nboth modes: manual and automatic. This timed loop is in charge of selecting\
    \ \nthe appropriate navigation source. Only the automatic mode is considered in\
    \ \nthis paper. \n• Mission management: Once the mission created in IUNO is downloaded,\
    \ this \nmodule manages each of the waypoints to which the vehicle must navigate,\
    \ \ndispatching the different navigation commands for the heading control/depth\
    \ \ncontrol/position control timed loops. This module also handles the main \n\
    \ \n90 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots,\
    \ Visual Recognition and Cloud/Edge \nComputing Services \nnavigation mode in\
    \ normal operations and the specimen tracking navigation \nmode, as described\
    \ in Section 7. \n \n4. Artificial Intelligence and Vision-Based Object Recognition\
    \ \n \n4.1 Object Detection Training in the Cloud \n \nThe Mar Menor, as the largest\
    \ saltwater lake in Europe with a wide range of \nflora, requires constant monitoring.\
    \ The 4G network covers the entire zone and \nconnects a large area to the Internet\
    \ to take full advantage of cloud computing \nservices. As described above, AUVs\
    \ are a complete fan mussel monitoring system \nthanks to being interconnected\
    \ to the latest cloud computing services. \nBesides the general object detection\
    \ models provided by cloud services, \ncertain others can be used to create their\
    \ own custom object detection model to \nidentify items and their location in\
    \ an image. Object detection models can be \ntrained to recognize objects that\
    \ are important to the user in specific domains. \nObject detection training data\
    \ is the set of object labels and locations in each \ntrained image. The tag or\
    \ label identifies what the object is. The location identifies \nwhere it is in\
    \ the image. It is also possible to identify more than one object in an \nimage.\
    \ Cloud services offer users a friendly interface to develop and deploy \ncustom\
    \ CV models. We identify the location by drawing a bounding box around \nthe object\
    \ and providing the top and left pixel coordinates of that box, along with \n\
    the width and height in pixels (Figure 4.25). \n \n \nFigure 4.25. Fan mussel\
    \ recognition training: defining a fan mussel bounding \nbox in different cloud\
    \ services. \nIn the case study, we trained about 90 photos on the same data set\
    \ in Azure, \nGoogle and IBM Watson cloud services, all of which offer nearly\
    \ the same service \nfor custom object detection. The training photos are a mix\
    \ of our own photos and \nothers from Creative Commons sources [217] (Figure 4.26).\
    \ The system is very \nsimilar to custom classification, except that this service\
    \ identifies the location of \nthe items in the image. The response also includes\
    \ a classification label for each \nitem detected and an identification confidence\
    \ score. \n \n \n91 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \n \nFigure 4.26.\
    \ Pictures used for custom CV model training. \nAfter creating a custom object\
    \ detection model and completing the training, \nwe tested its fan mussel detection\
    \ capacity in other images using the Python \ncloud API, as shown in Figure 4.27.\
    \ \nThe trained vision model successfully identified a new specimen in the image\
    \ \nand also its location and its probability percentage score. The blue bounding\
    \ box \nis drawn by the Python program using the results received from the cloud.\
    \ \nAccording to the results and the AUV navigation sensor data, the proposed\
    \ \nAlgorithm 1 can estimate the distance between the AUV head box and the \n\
    detected specimen. \n \n \nFigure 4.27. New specimen detection using the IBM Python\
    \ API. \n5. Visual Servo Control and Distance Estimation \nVisual servo control\
    \ consists of computer vision data usage to control the \nAUV’s motion [218].\
    \ Related works on underwater vision tracking and visual \nservo control for autonomous\
    \ underwater vehicles have shown that vision and \nvisual servo control are imperative\
    \ in developing AUV systems, as the vision–\n \n92 \n \nSmart IoT Monitoring and\
    \ Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \nAUV combination yields substantial benefits. Several\
    \ studies on underwater \ntracking focus on visual servoing, such as autonomous\
    \ alignment and dynamic \npositioning [218-219], pipeline following and planet\
    \ target tracking [220]. With \nthe advent of machine vision and deep learning,\
    \ it is currently viable to specify \nthe object to be tracked. ML object tracking\
    \ has already been tested in different \nunderwater applications, such as fish\
    \ tracking and diver following and tracking \n[221-222].  \nTo perform underwater\
    \ vision tracking in Mar Menor and track the \nunderwater Pinna nobilis species,\
    \ the fan mussel tracking algorithm is solved \nusing the object recognition cloud\
    \ API incorporated in the AUV control loop. \nThrough this algorithm, we verify\
    \ that a specimen has been detected, and from \nthere we calculate the coordinates\
    \ of its center (x, y). In this scenario, the AUV \nreduces speed, and a PID (Proportional–Integral–Derivative)\
    \ controller will keep \nthe object in the centre of the frame by adjusting AUV\
    \ yaw and head tilt to keep \nthe camera centred on the object detected [223-224].\
    \  \nWhen more than one specimen is detected, the system follows the one with\
    \ \nthe highest score. The x and y coordinates are adopted as information in the\
    \ object \ntracking process. To make the system effectual, the port and starboard\
    \ engines \nand AUV head tilt are adjusted to track the object using the object’s\
    \ coordinates \nas feedback. The thrust motors follow the position changes of\
    \ the object’s \ncoordinates by means of PID controllers. When the detected object\
    \ is centred, its \ndistance from the AUV camera is computed using the cloud API\
    \ results and a \ntriangular similarity algorithm [213-214]: \n \n    \U0001D437\
    \ = \U0001D44A \U0001D439\n\U0001D443\n \n(4.7) \n \nwhere P is the width of\
    \ the object in pixels and W is the width of the object itself. \nThe camera focal\
    \ distance F is fixed and the apparent P is obtained from the \ncloud results.\
    \ To obtain W and estimated distance D, a minimum of two pictures \nare required\
    \ at different distances from the object for calibration, as presented in \nFigure\
    \ 4.28 and Algorithm 1. \n \n \n93 \n \nSmart IoT Monitoring and Real-Time Control\
    \ Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \nFigure 4.28. Triangular similarity using a single camera [225]. \n(\U0001D437\
    \ +  ∆\U0001D451) \U0001D443\U0001D4611 = \U0001D437 \U0001D443\U0001D4612 =\
    \ \U0001D44A \U0001D439 \n(4.8) \n \n\U0001D437 =\n(∆\U0001D451 \U0001D443\U0001D461\
    1)\n(\U0001D443\U0001D4612− \U0001D443\U0001D4611)                           \
    \                                                                  (4.9) \n  \n\
    The cloud object detection API and the tracking algorithm are fully \nimplemented\
    \ using Python. The entire Python program is processed in the IoT \ngateway while\
    \ yaw and tilt are processed in the sbRIO main controller. The \noutput data coordinates\
    \ from the cloud are used to keep the AUV automatically \nfocused on the object\
    \ itself in the desired position. \nThe sbRIO main controller drives the robot’s\
    \ movements to keep the target’s \nbounding box in the centre of the camera image.\
    \ The IoT gateway continuously \nsends coordinate errors (distance, X position,\
    \ Y position) to this controller, so that \nthese data become the input for the\
    \ closed loop for tilt, heading and speed \nadjustments (Figure 4.29). \n \nFigure\
    \ 4.29. Closed control loop for object detection and tracking. \nFigure 29 presents\
    \ the modules and process involved in detecting \nand tracking the target. In\
    \ the object detection algorithm block, the \nsystem aims to keep the target in\
    \ the centre of the image. When the \nrelative size of the target has been obtained\
    \ from the object detection \nAPI, these control loops are kept operative while\
    \ the speed is \ngradually increased to calculate the estimated distance by means\
    \ of \nthe similarity triangulation algorithm. From then on, tilt, heading, \n\
    speed and control loops keep the target in the centre until the vehicle \nis at\
    \ the desired distance. The tilt and heading closed control loop \n \n94 \n \n\
    Smart IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual\
    \ Recognition and Cloud/Edge \nComputing Services \nwere successfully tested in\
    \ calm waters and slow currents, although \ndifficulties were encountered with\
    \ stronger currents. \nServo Control Latency \nThe visual system is required to\
    \ provide real-time results from the control \nloop with very low latencies. The\
    \ principal concern is the ability to detect the \ntarget and aim the camera at\
    \ the centre of the image. To obtain effective real-time \ncontrol, the delays\
    \ involved in initially detecting the target and those of the \nsensor and actuator\
    \ while tracking the object must be minimised (Figure 4.30) \n[226]. Three distinct\
    \ types of delay are involved. The first is actuator delays, \nwhich occur in\
    \ the feedforward loop when the delay is in the robot itself. The \nsecond type\
    \ is sensor delays in the feedback path of a closed-loop system, derived \nfrom\
    \ a sensor delay. This delay is present in any real-time control system with \n\
    visual feedback and depends on the amount of visual processing required. The \n\
    third type is transportation delays, or pure time delays, usually due to long-\n\
    distance communications. \n \nFigure 4.30. Basic closed-loop system with sensor\
    \ and actuator delays. \nTo reliably assess the servo control latencies, we modelled\
    \ the basic closed-\nloop system with sensor and actuator delays, as shown in\
    \ Figure 4.30. Y(s) is the \noutput signal and R(s) is the reference signal. The\
    \ sensor and actuator delays are \nrepresented, respectively, as \nand \nin the\
    \ frequency domain, the \n(undelayed) sensor dynamics by H(s), the (undelayed)\
    \ plant dynamics by G(s), \nand the controller by C(s). \nThe most important delays\
    \ in a control loop with visual feedback are those \ncaused by the sensor, and\
    \ the delay time directly affects the dynamic stability of \nthe control system.\
    \ System stability is determined by the poles of the \ninput/output transfer function,\
    \ i.e., the roots of the denominator. For a single-\ninput–single-output (SISO)\
    \ system, the denominator (characteristic equation of \nthe system) is simply\
    \ 1+ the loop gain, so that any stability analysis would \nincorporate the total\
    \ actuator and sensor delay to determine stability bounds. \n \n\U0001D44C(\U0001D460\
    )\n\U0001D445(\U0001D460) = \n\U0001D436(\U0001D460)\U0001D43A(\U0001D460)\U0001D452\
    −\U0001D460(\U0001D447\U0001D44E)\n1 + \U0001D436(\U0001D460)\U0001D43A(\U0001D460\
    ) \U0001D452−\U0001D460(\U0001D447\U0001D44E)\U0001D43B(\U0001D460) \U0001D452\
    −\U0001D460(\U0001D447\U0001D460)                                            \
    \    (4.10) \n \n95 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \n \n \nand the\
    \ characteristic equation is: \n \n1 + C(s)G(s)H(s)\U0001D452−\U0001D460(\U0001D447\
    \U0001D44E+\U0001D447\U0001D460)  = 0 \n(4.11) \n \nThe effects of stability can\
    \ be analysed by studying the conditions of marginal \nstability. From the above\
    \ equation, the following expressions are deduced: \n \n|\U0001D436(\U0001D457\
    ⍵)\U0001D43A(\U0001D457⍵)\U0001D43B(\U0001D457⍵)||\U0001D452−\U0001D457\U0001D714\
    \U0001D447| = 1 \n(4.12) \n \n \n\U0001D43F(\U0001D436(\U0001D457⍵)\U0001D43A\
    (\U0001D457⍵)\U0001D43B(\U0001D457⍵))\U0001D43F(\U0001D452−\U0001D457\U0001D714\
    \U0001D447) = 180º  \n(4.13) \n \nAs \n = 1 for all \n, the magnitude of the system\
    \ is not affected by the delay. \nHowever, as L \nradians, it is clear that the\
    \ phase margin for a system \nwith a time delay decreases as the time delay increases,\
    \ leading to instability and \nthus constraining the bandwidth achievable in the\
    \ face of delays. \nOne way to deal with the pernicious effect of known or unknown\
    \ delays is \nto detune first-order gains. With a PID controller, this is performed\
    \ by reducing \nthe proportional gain (P) to levels where the system remains stable.\
    \ This \napproach has the disadvantage that the resulting response is slowed down\
    \ and, \ntherefore, the overall performance of the system is worsened. The servo\
    \ control \nmust ensure a compromise between performance and stability. The performance\
    \ \nis proportional to the value of the gain of the corrector; however, above\
    \ a certain \nvalue, the corrector tends to destabilize the system. \n \n5. Exploration\
    \ Case Study \n \nThe experimental exploration mission was carried out with the\
    \ objective of \ndetermining the viability of the previously described approaches\
    \ in detecting fan \nmussel specimens in an area of 250 m x 100 m in the Mar Menor\
    \ (with the \ncoordinates of Table 4.7). A cloud architecture approach (Figure\
    \ 4.34-a) and a \nhybrid approach, a combination of cloud architecture (main mission)\
    \ and edge \narchitecture (tracking mission) were adopted (Figure 4.34-b). The\
    \ aim of the \nhybrid approach was to take advantage of edge architecture’s lower\
    \ latency and \nfavourable cloud precision. The tests achieved in the previous\
    \ section lead us to \nconclude that the results of Azure custom vision are more\
    \ pertinent to our use \ncase application (in terms of latency and accuracy);\
    \ therefore, we decided to \nadopt both the cloud and edge Azure models for the\
    \ mission described below. \nTable 4.7. GPS coordinates of the area explored.\
    \ \n \n96 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \nCorner \nLatitude\
    \ \nLongitude \nNorth east \n37.697635º −0.780121º \nNorth west 37.697635º −0.782876º\
    \ \nSouth west 37.696825º −0.782876º \nSouth east \n37.696825º −0.780121º \n \n\
    Our sailing operation started in a vessel equipped with a robotic arm that \n\
    placed the vehicle in the water. After defining the coordinates of the inspection\
    \ \narea, the mission was planned on IUNO software (Figure 4-31) according to\
    \ the \nweather forecast, the time available and the width of the vehicle’s search\
    \ path. \n \nFigure 4.31. Mission generated in IUNO and uploaded into AUV. \n\
    The AUV employed for the experiment was connected to the buoy as shown \nin Figure\
    \ 4-32. The control station on board the vessel was connected to the AUV \nby\
    \ 4G communications. The different systems were checked before the AUV was \n\
    placed in the water: control, lighting, thrusters, 4G communications, vision,\
    \ etc. \nAfter successfully validating the systems, the vehicle was launched,\
    \ and the \nmission was transferred from IUNO to the AUV. \nWe initiated the main\
    \ mission using the first approach (cloud architecture for \ndetection and tracking).\
    \ The AUV started to explore the area for possible \nspecimens. The average depth\
    \ of the inspection area was 5.02 m and the vehicle \nremained at an average height\
    \ of 2.01 m above the seabed. \nThe first of the six sweeps (Figure 4.31) was\
    \ completed without detecting any \npossible specimens. The first fan mussel was\
    \ detected with 63% accuracy in the \nsecond track, when the AUV switched to the\
    \ secondary mission mode to track it \n(object location in the frame and distance\
    \ calculation). However, this turned out \nto be quite impractical due to the\
    \ high latency of the cloud connection. A timeout \nexception occurred during\
    \ the tracking mission and the algorithm chose to ignore \nit and resume the main\
    \ mission. As described in Section 6, the detection fails if a \ndeadline is missed\
    \ due to transmission delays, which affects the dynamic \nstability of the control\
    \ system. The technical team therefore decided to abort the \n \n97 \n \nSmart\
    \ IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \nmission, return to the starting point\
    \ and launch the same mission in the “hybrid” \nmode. \n \n \nFigure 4.32. Deploying\
    \ the platform to initiate the mission. AUV submarine \nconnected to a buoy via\
    \ a DSL cable. \nThe hybrid mission mode was initiated, and the cloud connection\
    \ was used \nto process the photos sent during the main tracking mission. On the\
    \ second \nsweep, the cloud results in the gateway indicated the presence of a\
    \ specimen with \n64% probability. The vehicle switched to the tracking mode.\
    \ At this point, the \nAUV began manoeuvring to place the target in the centre\
    \ of the image, while the \ninference was switched to the edge model in the IoT\
    \ gateway instead of the cloud \nto reduce latency. The AUV was able to follow\
    \ the suspected specimen up to a \ndistance of 2.13 m. The accuracy of the analysed\
    \ image at this distance was 83.8%, \nusing the trained edge model. For greater\
    \ certainty, the inference was switched \nto the cloud for the last picture to\
    \ confirm the find. In this hybrid mode, the edge \nwas used to speed up tracking\
    \ and AUV response. At this point, the AUV ended \nthe secondary mission mode,\
    \ registered the find as positive, saved its coordinates \nand resumed the main\
    \ mission (Figure 4.33). \n \n \nFigure 4.33. Specimen detection and positioning\
    \ in IUNO. \n \n98 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \nNo further\
    \ specimens were detected until the fourth sweep, when another \nwas detected\
    \ with 38% probability. Once again, the vehicle switched to tracking \nmode, centred\
    \ the target in the image and performed the approach manoeuvre \nas before. After\
    \ halting at 2.06 m from the target, the recognition algorithm \nindicated that\
    \ the target was a fan mussel with 59% probability. As the minimum \nconfirmation\
    \ requirement in terms of the probable detection threshold at this \nstage is\
    \ 80%, the target was ignored, and the main mission was resumed. Due to \nthe\
    \ real-time communications, the target was in fact found not to be a fan mussel\
    \ \nbut a dark-coloured rock. On the sixth sweep, the mission and inspection were\
    \ \ncompleted after detecting one target specimen and discarding another possible\
    \ \ndetection that turned out to be a rock. \n \n6. Performance \n \nCloud and\
    \ edge computing are considered adequate platforms to \nincorporate artificial\
    \ intelligence approaches. This paper primarily focuses on the \nissues related\
    \ to the real-time constraints of using an AI cloud in both \nenvironments. Our\
    \ AUV system is designed to collect and interpret underwater \nimages to track\
    \ the fan mussel population in real time by an automatic processing \nmethod.\
    \ This automated approach is based on DL image processing techniques, \nsuch as\
    \ CNN, to detect the position of a possible specimen in a captured photo. \nThe\
    \ IoT gateway algorithm establishes the connection between the AUV control \n\
    system and cloud image processing techniques. The results of our proposed \nsystem\
    \ are compared with cloud and edge image processing in terms of latency \nand\
    \ certainty. Therefore, we aim to compare the response time between the cloud\
    \ \nand edge inference. \nMicrosoft Azure cloud was first compared with IBM and\
    \ Google clouds, as \nshown in Figure 4.34 [227-229]. The second comparison evaluated\
    \ the same cloud \nservice with inference in the edge and comparing the same results\
    \ in the cloud. \n \n \n                                                     \
    \         (a)                                                                (b)\
    \ \n \n99 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \nFigure 4.34.\
    \ Communication edge cloud. (a) Training and inference in the \ncloud; (b) training\
    \ in the cloud, inference in the edge. \nWe describe the various network connections\
    \ and the performance metrics \nfor the architectures given in Figure 4.34. We\
    \ first assessed the delay between the \ndifferent terminals in the cloud architecture\
    \ and then compared it to that of the \nedge computing architecture. We evaluated\
    \ the performance of each trained \nmodel in the cloud and in the edge. Below,\
    \ we compare the performance of each \narchitecture, using LattePanda as an IoT\
    \ gateway, with a 1.8-GHz Intel quad-core \nprocessor, 4 GB RAM and 64 GB on-board\
    \ flash memory. \n6.1. Delay Assessment in the Proposed Platforms \nFigures 4.35\
    \ and 4.36 exhibit the different data flows via the various \ncommunication networks\
    \ for the cases of cloud and edge computing. From data \nacquisition (sensors)\
    \ to actuators, the information flow goes through different \nnetworks: CAN and\
    \ Ethernet in the case of edge architecture, and the Internet \nand DSL for the\
    \ cloud architecture. This represents the difference in latency \nbetween the\
    \ two modes and highlights the critical points in each case. \nThe highest latency\
    \ expected in the case of edge computing is Tinference, and the Tcloud \nis the\
    \ one expected in the cloud. \n6.1.1. Cloud Architecture \nIn the adopted cloud\
    \ architecture, all the generated images are sent to the \ncloud services and\
    \ the inference is performed entirely in the cloud. This makes \nthe application\
    \ fully dependent on the cloud results in order to make the \nnecessary adjustments,\
    \ which are crucial in the case of intermittent connectivity. \nFigure 4.35 shows\
    \ the different delays in the use case process. \n \nFigure 4.35. Latency in the\
    \ proposed platform within the cloud architecture. \n \n100 \n \nSmart IoT Monitoring\
    \ and Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \nThe response time in the system can be divided into delays,\
    \ as modelled in \nEquation (4.14): \n \n\U0001D447 = \U0001D447\U0001D45B\U0001D44E\
    \U0001D463 + \U0001D447\U0001D460\U0001D44F1 + \U0001D447\U0001D454\U0001D461\
    1 + \U0001D447\U0001D44F\U0001D4661 + \U0001D447\U0001D450\U0001D459\U0001D45C\
    \U0001D462\U0001D451 + \U0001D447\U0001D44F\U0001D4662 + \U0001D447\U0001D454\U0001D461\
    2 + \U0001D447\U0001D460\U0001D44F2 + \U0001D447\U0001D44E\U0001D450\U0001D461\
    \ \n(4.14) \n \n \nwhere: \n(1) Tnav is the navigation sensor time, \n(2) Tsb1\
    \ is the acquisition time of the sensor data in sbRIO, \n(3) Tgt1 is the processing\
    \ time of the first and second threads in the IoT gateway \npresented, \n(4) Tby1\
    \ is the transmission time from the AUV to the buoy, \n(5) Tcloud is the time\
    \ needed to send photos to the cloud and receive the response \nresults, \n(6)\
    \ Tby2 is the transmission time of cloud results to the AUV, \n(7) Tgt2 is the\
    \ processing time of the first, second, and third threads in the IoT \ngateway\
    \ presented, \n(8) Tsb2 is the IoT gateway data acquisition time in sbRIO, and\
    \ \n(9) Tact is the actuation time. \nWhen the AUV starts up the IP camera stream,\
    \ the Tsens value can be expressed \nin two ways depending on the data stream,\
    \ according to Equations (15) and (16): \n \n\U0001D447\U0001D460\U0001D452\U0001D45B\
    \U0001D460 = {\U0001D447\U0001D45B\U0001D44E\U0001D463 + \U0001D447\U0001D460\U0001D44F\
    1  if  \U0001D447\U0001D45B\U0001D44E\U0001D463 + \U0001D447\U0001D460\U0001D44F\
    1 > \U0001D447\U0001D450\U0001D44E\U0001D45A\U0001D452\U0001D45F\U0001D44E\n\U0001D447\
    \U0001D450\U0001D44E\U0001D45A\U0001D452\U0001D45F\U0001D44E if \U0001D447\U0001D45B\
    \U0001D44E\U0001D463 + \U0001D447\U0001D460\U0001D44F1 < \U0001D447\U0001D450\U0001D44E\
    \U0001D45A\U0001D452\U0001D45F\U0001D44E  \n(4.15) \n \n\U0001D447 = \U0001D447\
    \U0001D460\U0001D452\U0001D45B\U0001D460 + \U0001D447\U0001D454\U0001D4611 + \U0001D447\
    \U0001D44F\U0001D4661 + \U0001D447\U0001D450\U0001D459\U0001D45C\U0001D462\U0001D451\
    \ + \U0001D447\U0001D44F\U0001D4662 + \U0001D447\U0001D454\U0001D4612 + \U0001D447\
    \U0001D460\U0001D44F2 + \U0001D447\U0001D44E\U0001D450\U0001D461 \n(4.16) \n \n\
    \ \nTcloud is composed of three different delays: Trequest is the transmission\
    \ time of each \nphoto to the cloud, Tinference is the processing time of the\
    \ transmitted photo in the \ncloud service, and Tresponse is the time from the\
    \ cloud to the buoy. \n \n\U0001D447\U0001D450\U0001D459\U0001D45C\U0001D462\U0001D451\
    \ = \U0001D447\U0001D45F\U0001D452\U0001D45E\U0001D462\U0001D452\U0001D460\U0001D461\
    \ + \U0001D447\U0001D43C\U0001D45B\U0001D453\U0001D452\U0001D45F\U0001D452\U0001D45B\
    \U0001D450\U0001D452 + \U0001D447\U0001D45F\U0001D452\U0001D460\U0001D45D\U0001D45C\
    \U0001D45B\U0001D460\U0001D452 \n(4.17) \n \n6.1.2. Edge Architecture \nIn the\
    \ edge architecture, the data remains in the local machine and the images \nare\
    \ not sent to the cloud; however, the application needs a minimal connection \n\
    to the cloud to report usage, which is suitable for intermittent connectivity.\
    \ The \ncloud connection is almost negligible; instead of sending photos to the\
    \ cloud for \nprocessing, the model uploads to the local IoT gateway and performs\
    \ the \ntreatment. We therefore neglect the cloud connection in this architecture\
    \ and only \nconsider the connections in the AUV. \n \n101 \n \nSmart IoT Monitoring\
    \ and Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \n \n \nFigure 4.36. Edge architecture latency in the proposed\
    \ platform. \nIn the edge model deployed in the IoT gateway, the overall response\
    \ time of \nthe edge architecture in the AUV over the Ethernet and CAN networks\
    \ is \nmodelled as: \n \n\U0001D447 = \U0001D447\U0001D460\U0001D452\U0001D45B\
    \U0001D460 + \U0001D447\U0001D460\U0001D44F1 + \U0001D447\U0001D454\U0001D461\
    \ + \U0001D447\U0001D460\U0001D44F2 + \U0001D447\U0001D44E\U0001D450\U0001D461\
    \ \n(4.18) \n \nWhere Tsens is expressed as: \n \n\U0001D447\U0001D460\U0001D452\
    \U0001D45B\U0001D460 = {     \U0001D447\U0001D45B\U0001D44E\U0001D463 + \U0001D447\
    \U0001D460\U0001D44F1   if.  \U0001D447\U0001D45B\U0001D44E\U0001D463 + \U0001D447\
    \U0001D460\U0001D44F1 > \U0001D447\U0001D450\U0001D44E\U0001D45A\U0001D452\U0001D45F\
    \U0001D44E\n\U0001D447\U0001D450\U0001D44E\U0001D45A\U0001D452\U0001D45F\U0001D44E\
    \    if.\U0001D447\U0001D45B\U0001D44E\U0001D463 + \U0001D447\U0001D460\U0001D44F\
    1 < \U0001D447\U0001D450\U0001D44E\U0001D45A\U0001D452\U0001D45F\U0001D44E  \n\
    (4.19) \n \nTgt in this case depends on Tthreads executing the 4 threads in the\
    \ IoT \ngateway and the custom model Tinference uploaded from the cloud. \n \n\
    \U0001D447\U0001D454\U0001D461 = \U0001D447\U0001D461ℎ\U0001D45F\U0001D452\U0001D44E\
    \U0001D451\U0001D460 + \U0001D447\U0001D456\U0001D45B\U0001D453\U0001D452\U0001D45F\
    \U0001D452\U0001D45B\U0001D450\U0001D452 \n(4.20) \n \n6.2. Metrics \nThe Azure\
    \ Custom Vision, Google cloud and Watson IBM services allow \nusers to load a\
    \ set of image data and define the bounding box of each desired \nobject in the\
    \ image. To train the model effectively, the images must be varied and \nas close\
    \ as possible to the data on which the predictions will be made. Camera \nangle,\
    \ blurring, background, lighting, size, low resolution and type are all \nimportant\
    \ variations of the image that affect the training process. \nOnce the training\
    \ was completed, we calculated the model’s performance \nusing new image datasets\
    \ (i.e., not included in the training dataset), shown in \nTable 8. Precision\
    \ indicates the fraction of identified classifications that are \n \n102 \n \n\
    Smart IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual\
    \ Recognition and Cloud/Edge \nComputing Services \ncorrect, while recall indicates\
    \ the fraction of actual classifications that are \ncorrectly identified. IoU\
    \ (intersection over union) is a metric of how successfully \na model predicts\
    \ the objects’ locations and is gauged using the area of \noverlapping regions\
    \ of the predicted and ground truth bounding boxes, defined \nas: \n \n\U0001D43C\
    \U0001D45C\U0001D448 = \U0001D434\U0001D45F\U0001D452\U0001D44E \U0001D45C\U0001D453\
    \ \U0001D442\U0001D463\U0001D452\U0001D45F\U0001D459\U0001D44E\U0001D45D\n\U0001D434\
    \U0001D45F\U0001D452\U0001D44E \U0001D45C\U0001D453 \U0001D448\U0001D45B\U0001D456\
    \U0001D45C\U0001D45B  \n \n  (4.21) \n \nUnlike IBM in Azure Custom Vision and\
    \ Google cloud, the AI model can be \nexported in different formats (TensorFlow,\
    \ Docker) specially adapted to edge \ndevices, as opposed to in the cloud. The\
    \ model trained for cloud use is different \nfrom that trained for the edge as\
    \ regards accuracy and response time. We used \nthe same photos to train and test\
    \ the trained models for both edge and cloud use \nin the trials. Figure 4.37\
    \ shows some differences in terms of the accuracy of new \nphotos not used in\
    \ the training phase. The five tests clearly show the limits of \neach example;\
    \ for instance, in test 3, the picture was blurred, and Google cloud \ncould not\
    \ detect the mussel, while Microsoft detected it with 83% accuracy and \nIBM only\
    \ 15% accuracy. In test 2, all three clouds detected an unknown red object \n\
    stuck in the sub-bottom as a mussel with different percentages, which shows the\
    \ \nlimitation of the models regarding colour changes. \n \n \nFigure 4.37. Cloud-based\
    \ custom models for detecting new specimens. \n \n103 \n \nSmart IoT Monitoring\
    \ and Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \nIn order to evaluate the performance of the proposed\
    \ object detection \nmodels, in both the cloud and edge, we used the following\
    \ standard performance \nmetrics: \n \n\U0001D45D\U0001D45F\U0001D452\U0001D450\
    \U0001D456\U0001D460\U0001D456\U0001D45C\U0001D45B =\n\U0001D447\U0001D443\n\U0001D439\
    \U0001D443+\U0001D447\U0001D443 \n \n(4.22) \n \n\U0001D45F\U0001D452\U0001D450\
    \U0001D44E\U0001D459\U0001D459 =\n\U0001D447\U0001D443\n\U0001D439\U0001D441+\U0001D447\
    \U0001D443 \n \n(4.23) \nwhere precision indicates the fraction of identified\
    \ detections that were correct, \nand recall indicates the fraction of actual\
    \ detections that were correctly identified. \nFP (False Positive) represents\
    \ the number of negative samples judged to be \npositive, TP (True Positive) is\
    \ the number of positive samples judged to be \npositive, and FN (False Negative)\
    \ is the number of positive samples judged to be \nnegative. \nTable 4.8. Accuracy\
    \ measurement in different platforms. \n \nTP \nFP \nFN \nPrecision \nRecall \n\
    IoU \nIBM \n28 \n2 \n8 \n0.933333 \n0.777778 \n0.82506 \nGoogle \n22 \n3 \n13\
    \ \n0.916666 \n0.611111 \n0.83364 \nAzure cloud \n33 \n4 \n3 \n0.891892 \n0.916667\
    \ \n0.86601 \nAzure edge \n24 \n3 \n11 \n0.888889 \n0.666667 \n0.678634 \n \n\
    The accuracy measurement tests were performed on all three cloud \nplatforms.\
    \ We also adopted the Azure edge model as it shows a better IoU metric \nscore\
    \ than Google. The accuracy test was performed on more than thirty photos \nof\
    \ mussels detected by our AUV camera, using the same photos in the three \ndifferent\
    \ clouds. The results given in Table 8 clearly show the difference between \n\
    the AI cloud services. \n6.3. Latency Evaluation \nSince most of the cloud APIs\
    \ are based on the HTTP protocol, we performed \na total of 100 HTTP throughput\
    \ tests using SpeedTest between the web server \nand the IoT gateway installed\
    \ in the AUV. The tests were performed in the Mar \nMenor experimental area through\
    \ the 4G connection. The average results of the \ntests carried out in this experimental\
    \ area were as follows: round trip delay: 66ms; \ndownload: 16.6 Mbps; upload:\
    \ 19.3 Mbps. The average size of the image sent \nfrom the AUV to the cloud was\
    \ approximately 194 kb. \nThe local network which connects the vehicle, and the\
    \ buoy presents a low \nfixed latency. This was measured by a 100-automated-delay\
    \ measurement \ncampaign. The average latencies between the IoT gateway and the\
    \ different \n \n104 \n \nSmart IoT Monitoring and Real-Time Control Based On\
    \ Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services \n\
    devices in the vehicle’s Ethernet network were as follows: sbRIO: 0.9ms; camera:\
    \ \n1.1ms; 4G router (buoy): 1.2 ms. \nThe latency results are summarized in Table\
    \ 4.9, where average, minimum \nand maximum response time values are calculated\
    \ for each endpoint \narchitecture. The experimental set-up was based on Azure\
    \ and IBM cloud \narchitectures, plus another edge architecture using a custom\
    \ model formed by \nAzure and processed by the IoT gateway. Although IBM Watson\
    \ and Azure \ncustom vision are available worldwide, the locations of the deployments\
    \ differ; \nWatson is deployed in the U.S. and South Korea [226], while Google\
    \ cloud and \nAzure are deployed in various locations around the world [227, 228].\
    \ In this case, \nthe Azure and Google cloud services are deployed in Western\
    \ Europe, while IBM \nis in Dallas, USA. All the samples in each architecture\
    \ were thoroughly verified \nin an experimental campaign with over 100 valid samples.\
    \ The experiments \ncarried out were based on Equations (4.14) and (4.16) and\
    \ Python software. The \nlatter was employed to measure the overall latency. \n\
    Table 4.9. Latency measurement in different platforms. \n \nTotal Response \n\
    \ time (ms) \nCloud response  \ntime (ms) \nIoT Computing  \ntime (ms) \nCapturing\
    \ and \nwriting time (ms) \n \nMin \nMax \nMean \nMin \nMax \nMean \nMin \nMax\
    \ \nMean \nMin \nMax \nMean \nIBM \n1407 \n4060 \n2064 \n1280 \n3896 \n1935 \n\
    0 \n0 \n0 \n93 \n192 \n129 \nGoogle \n1291 \n4384 \n1696 \n1160 \n4071 \n1520\
    \ \n0 \n0 \n0 \n92 \n196 \n130 \nAzure \n1298 \n4572 \n1703 \n1171 \n4435 \n1571\
    \ \n0 \n0 \n0 \n92 \n196 \n131 \nAzure \nedge \n623 \n687 \n634 \n0 \n0 \n0 \n\
    523 \n595 \n532 \n93 \n194 \n130 \n \nThe results reported in Table 9 show the\
    \ differences between the proposed \narchitectures in terms of latency. Despite\
    \ the fact that image processing in edge \ncomputing is performed on the IoT gateway,\
    \ the total response time is \nsignificantly lower than the latency obtained with\
    \ cloud computing. The faster \nrunning time of the custom AI detection model\
    \ ensures real-time tracking and \nnavigation adjustment. Edge average response\
    \ time is almost three times less \nthan that of the cloud. However, the edge\
    \ model is less accurate than the cloud \nmodel; in fact, the edge model loaded\
    \ from the cloud is optimized as far as \npossible to meet the requirements of\
    \ tiny device platforms. \n \n \n \n \n \n \n105 \n \nSmart IoT Monitoring and\
    \ Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \n \n \nIII. System 3. Autonomous Marine Robot Based on\
    \ AI \nRecognition for Permanent Surveillance in Marine \nProtected Areas \n \n\
    1. Introduction  \n  \nThere are unique areas in the marine environment that must\
    \ be protected due \nto their singular characteristics and high environmental\
    \ value. These habitats are \nparticularly sensitive to alteration or disturbance\
    \ by humans, changes in the \necosystem or changes in climate. One of the legal\
    \ tools for their protection is the \ndeclaration of the area as a Marine Protected\
    \ Area (MPA), which legally allows \nfor the establishment of a scenario of maximum\
    \ protection [229]. The main \npurpose of MPAs is to regenerate fishing resources,\
    \ preserve natural resources, \nconserve marine species and recover ecosystems.\
    \ \nA marine reserve is defined as a category of marine protected area with legal\
    \ \nprotection mainly against fishing or development. The main limits as a general\
    \ \nrule are professional fishing (with the exception of a few authorized boats)\
    \ and \ndiving (also with authorized exceptions), while recreational fishing,\
    \ underwater \nfishing and anchoring are totally prohibited. These activities\
    \ in marine reserves \nmust be monitored by the authorities to guarantee the care\
    \ of the ecosystem by \nlaw [230]. A marine reserve can be made up of a single\
    \ area or different non-\nadjacent areas and contains at least one integral reserve,\
    \ which is a natural space \nwith high ecological and biological value due to\
    \ a unique and delicate ecosystem \nsensitive to any alterations. \nThe restrictions\
    \ are even stricter in integral reserves: all activities are \nforbidden, with\
    \ the exception of authorized scientific activities and sailing at a \nlimited\
    \ speed. In Spain there are a total of eleven marine reserves [231], four are\
    \ \non islets, islands and reefs far from inhabited areas and ports, and the rest\
    \ are on \nthe coast or near inhabited areas. The surveillance of areas far from\
    \ the coast is a \nreal challenge: inspection vehicles must be autonomous and\
    \ must not be \ncompromised by the risk of going adrift. Long-distance communications\
    \ with the \nland-based station must be fluid and stable, especially if 4G or\
    \ 5G coverage is not \navailable, as in most marine areas far from the coast and\
    \ in the video surveillance \nscenario, image transmission requires a highly stable\
    \ bandwidth. All these \nrestrictions are a major challenge for the surveillance\
    \ of marine reserves on the \nhigh seas. \nSeveral measures have been adopted\
    \ for the monitoring and surveillance of \nmarine reserves. The materials and\
    \ human resources are available to carry out \n \n106 \n \nSmart IoT Monitoring\
    \ and Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \nroutine inspections or to set up devices to detect illegal\
    \ fishing. In general, all \nmarine reserves are equipped with vessels, georeferenced\
    \ cameras, night vision \nbinoculars, telescopes and ROVs, among others [231].\
    \ However, all these \nmeasures and means have the same disadvantage: the lack\
    \ of a permanent \npresence. Despite the measures adopted, it is not possible\
    \ to permanently \nmonitor the nature reserve with these means, and the identification\
    \ and arrest of \noffenders is practically incidental. This is why it is very\
    \ difficult to obtain records \nof those who have accessed protected areas and\
    \ to obtain real-time alerts to \nidentify those responsible in the event of damage\
    \ or alteration of the ecosystem. \nUnfortunately, even with the above-described\
    \ means and resources illegal \nactivities such as anchoring or poaching still\
    \ take place. \nProtecting remote marine areas with the currently available means\
    \ is not \nenough for their full protection, especially in integral reserves.\
    \ The challenges are \nquite demanding and even more so in permanent surveillance.\
    \ Autonomous \nSurface Vehicles (ASV) are ideal in this scenario for autonomous\
    \ navigation, but \nthere is also another issue. In order to monitor remote marine\
    \ reserves, the \ncapacity to detect and identify specific types of vessels is\
    \ required. Detection and \nidentification by humans is difficult to equal in\
    \ this scenario and only visual \nrecognition technologies based on artificial\
    \ intelligence (AI) and the Internet of \nThings (IoT) can offer a detection capacity\
    \ close to human capabilities. \nThere are also other issues, mainly water quality,\
    \ pollution and the effect on \nthe ecosystem. In a previous work we proposed\
    \ an autonomous system \nconsisting of an autonomous solar-powered marine robot\
    \ with specialized \nsensing systems [232], designed to carry out long-term observation\
    \ missions in \nshallow water, collecting georeferenced oceanic data to monitor\
    \ and analyse \nphysical-chemical water parameters. \nWe therefore consider permanent\
    \ surveillance and inspection of marine \nreserves to be vital. For this, we introduce\
    \ the concept of the \"watchdog\"; a \nwatchdog roams around an area (for example,\
    \ a fenced-in area around a house). \nAs soon as an intruder is detected, the\
    \ watchdog alerts the owner and deters the \nintruder from entering. If he enters\
    \ the premises, the guard dog chases him out. \nThis concept, applied to autonomous\
    \ navigation by means of ASV craft together \nwith the concepts of Industry 4.0\
    \ applied to marine environments, gives us a \npowerful proposal for the permanent\
    \ surveillance of marine reserves. \nThis paper proposes and evaluates an autonomous\
    \ marine vehicle based on \nartificial intelligence, designed to recognize and\
    \ classify vessels considered as \npotential risks according to their type and\
    \ activity. Its main goal is to track and \nfollow them in real time to obtain\
    \ information (identification and position, video \nrecording, etc) using automatic\
    \ image recognition. When a vessel classified by \nthe algorithms as a potential\
    \ risk inside an integral reserve is detected and \nremains in the same position\
    \ for a certain period, it could mean illegal activity. \nIn the experiment, the\
    \ proposed Autonomous Guard based on the ASV was \n \n107 \n \nSmart IoT Monitoring\
    \ and Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \ntested in this scenario in order to recognize, follow\
    \ and identify vessels based on \nan autonomous navigation and AI image recognition.\
    \ \nThe series of requirements for this include the following factors: it cannot\
    \ \nalter the ecosystem, so its energy source must be totally renewable; its capacity\
    \ \nto detect and recognise target vessels must be precise and reliable, the ability\
    \ to \ndistinguish between different types, and most importantly, the detection\
    \ capacity \nshould not compromise the ASV’s autonomy. \nThere are radar-based\
    \ detection AUVs with fast and accurate detection \nsystems, but this is not enough\
    \ for precise recognition and identification [233]. In \n[234] SAR (Synthetic\
    \ Aperture Radar) images are used together with deep \nlearning (DL) algorithms\
    \ to detect and recognize ships by means of a powerful \nCPU and local graphics\
    \ cards and low computational time, but these have a high-\npower consumption,\
    \ which is incompatible with a stand-alone vehicle. Due to \nthe inevitable vibration\
    \ and constant movement of the autonomous vehicle it is \nadvisable to use single\
    \ board devices and CPUs. This type of solution is suitable \nfor fixed surveillance\
    \ stations, but not for autonomous vehicles, whose autonomy \nis compromised.\
    \ On the other hand, fixed stations are not applicable in this case \ndue to several\
    \ factors, such as limited monitoring range, low reaction capacity, \nexposure\
    \ to environmental conditions and marine environments (in case of \nbuoys), ecosystem\
    \ alteration (in case of installations on islets or reefs), among \nothers. In\
    \ [236] a unified energy management framework was used to enable a \nsustainable\
    \ edge computing paradigm powered by distributed renewable energy \nresources.\
    \ Edge computing technologies significantly simplify local computing \ncapacity\
    \ and increase energy efficiency, while maintaining low latency. AI-based \ntechnologies\
    \ such as edge and cloud computing have proven to be accurate in \nterms of recognition\
    \ results and data analysis [236-238]. In [239] hybrid use of \ncloud/edge technologies\
    \ is considered optimal, significantly reducing the \npercentage of local computing\
    \ by deriving most of the calculation to remote \n(cloud) servers and highly optimised\
    \ algorithms through suitable and specific \ntraining processes. \nAs the paper’s\
    \ main contribution and novelty, we propose a hybrid \nCloud/Edge technology,\
    \ optimised for high image recognition accuracy, \nminimum power consumption and\
    \ low latency, in order to increase vehicle \nautonomy and efficiency, increase\
    \ the likelihood of mission success and security \nduring autonomous surveillance\
    \ missions in marine reserves with MASS. High \npower consumption compromises\
    \ vehicle autonomy during image recognition \nand identification, and high latency\
    \ compromises the control and tracking \nalgorithms. To select the most appropriate\
    \ technology according to the scenario \nand circumstances, we propose the SAAO\
    \ (Smart Algorithm for Autonomy \nOptimization by selecting the proper AI technology\
    \ according to the current scenario). \nThis algorithm is optimized to select\
    \ the appropriate technology (cloud or edge \ncomputing) according to the situation\
    \ and circumstances. \n \n \n108 \n \nSmart IoT Monitoring and Real-Time Control\
    \ Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \n2. Proposed Platform for Surveillance in Marine Protected Areas \n \nThe BUSCAMOS-VIGIA\
    \ ASV was developed by DAyRA (División de \nAutomatización y Robótica Autónoma)\
    \ group at the UPCT. One of its achievements \nis described in [232], where we\
    \ gave the ASV the capability to make long-term \nmissions to acquire data from\
    \ multiparameter probes in the Mar Menor (Murcia, \nSpain) on factors to decide\
    \ the urgency in inspecting a specific area based on \nfuzzy logic. \n \n2.1.\
    \ The ASV–IoT Architecture Development \n \nA framework of this description together\
    \ with the hardware and software \narchitecture in the proposed system are shown\
    \ in Figure 4.38: \n \n \nFigure 4.38. BUSCAMOS-VIGIA framework. \nThe framework\
    \ represents the whole system as follows: it is structured into \ntwo main blocks:\
    \ the ASV block, Communication base station AP (Access Point) \nblock and Cloud/Internet\
    \ block. The first represents the logic or physical \nelements included in the\
    \ vehicle, and the second collects the elements in the \n \n109 \n \nSmart IoT\
    \ Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \nremote station and cloud computing server.\
    \ Each main block is classified into \nlayers. The ASV block is divided into 4\
    \ layers: The Energy layer, \nSensors/Actuators layer, Navigation control layer,\
    \ and Edge layer. The energy \nlayer is formed of the elements that provide energy\
    \ and autonomy to the vehicle. \nAs can be seen, the batteries can be charged\
    \ in two ways: through photovoltaic \ntechnology (during navigation - so as to\
    \ extend the vehicle’s range - or in port) \nor through an AC source, when solar\
    \ power is not enough, or a quick charge is \nneeded when moored. The next layer\
    \ is the Sensors / Actuators layer, with the \ndifferent detection elements, which\
    \ provide information to the upper layers in \nthe framework (such as GPS, inertial\
    \ unit, LiDAR and cameras). Here also are the \nrudder and thrusters. The upper\
    \ layer is for Navigation and Control and consists \nof a NI cRIO controller (National\
    \ Instrument Compact Remote Input Output) \n9022 model and its peripheral elements\
    \ and modules. The elements in this layer \nare responsible for autonomous navigation\
    \ and use information from the sensors \nin the lower layer and the AI image recognition\
    \ response obtained from the IoT \nGateway in the upper layer. The cRIO controller\
    \ is formed of a main body, based \non a processor and FPGA, together with a reconfigurable\
    \ chassis, with a series of \nmodules necessary for several communication protocols\
    \ to command and \nacquire data from the lower layer, such as CAN-NMEA2000, I2C,\
    \ RS232 and \nRS485, according to the current hardware architecture. There are\
    \ also a serial of \ncode block and algorithms, described in Section 3.3. The\
    \ Upper or Edge layer is \nformed by the IoT Gateway where on-board AI takes place\
    \ by running the \nalgorithms in charge of the camera’s image processing and analysing\
    \ system. \nThe second main block, called “Cloud / Internet”, contains just one\
    \ layer in \nthe highest position of the framework, called the Cloud layer, containing\
    \ not only \nthe AI services, but also information and resources provided in real\
    \ time from \nauthorities and services, which are essential for planning or modifying\
    \ the ASV \nmission. Also found here is the IUNO (Interface for Unmanned drones)\
    \ software. \nThe IUNO software platform was also designed by the DAyRA group\
    \ of the \nPolytechnic University of Cartagena. The platform manages the integrated\
    \ \ncontrol of multiple unmanned marine vehicles with the aim of simplifying \n\
    maritime operations. The results obtained from each vehicle, regardless of its\
    \ \ncharacteristics, facilitate the success of the operation with a high degree\
    \ of \nautomation. This software has already been used in previous experiments\
    \ and \noperations, such as [223,239], and is the only point with human intervention.\
    \ \nActivities such as mission planning or remote supervision are commanded and\
    \ \nmanaged from here.  \nBetween the ASV and Cloud/Internet blocks we find the\
    \ Communications \nbase station AP block, containing the Radio link layer. This\
    \ provides high \nwideband, low latency and long-range WiFi communications between\
    \ the \nvehicle and the land. It is formed by two Ubiquiti ROCKET M2 2.4 GHz modules\
    \ \n(one on land and another in the vehicle) and its antennas, with Ubiquiti airMAX\
    \ \nconnection. Due to the characteristics of the communications scenario, the\
    \ land \n \n110 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \nantenna is\
    \ the sector type and the on-board is omnidirectional. The land station \nis connected\
    \ to the Internet. This layer is especially crucial in areas where 4G-5G \ncover\
    \ is not available, as in most integral reserves. \nThere is an extra block in\
    \ both the ASV and Cloud/Internet main blocks called \nthe AI (Artificial Intelligence)\
    \ block. As explained in Section 4, it is formed of the \nAzure Cloud general\
    \ model, Azure cloud custom model and Azure Edge custom \nmodel for AI recognition\
    \ according to the smart algorithm criteria described in \nSection 4.4. \nThe\
    \ most relevant characteristics of the ASV used in the experiment \ndescribed\
    \ in this paper are as follows: the vehicle is 5 meters long. It has a robust\
    \ \nstructure that protects the devices from the weather, as well as a sunroof.\
    \ The \ninside of the vessel is subdivided into two sections by means of a bulkhead.\
    \ In \nthe stern are the elements related to power and propulsion: Block of 8\
    \ 100Ah \nbatteries configured in 2 parallel lines, providing 48V nominal power\
    \ and 14h \nautonomy. Two electric outboard motors, Torqeedo C4.0 Cruise model,\
    \ allow it \nto sail at a maximum speed of 6 knots. It has two racks, located\
    \ on the starboard \nand port sides. In the starboard rack are the IoT Gateway\
    \ (LattePanda single \nboard computer, with 1.8-GHz Intel quad-core processor,\
    \ 4 GB RAM and 64 GB \non-board flash memory) and the WiFi communications elements,\
    \ energy \nmanagement of different equipment, photovoltaic regulator and electrical\
    \ panel. \nThe main elements of the port rack are: the NI cRIO 9022 (National\
    \ Instruments \nCompact Remote Input Output) controller, the rudder controller\
    \ and the \nelectronic periphery. It is equipped with side-scan sonar, echo sounder,\
    \ GPS, \ninertial unit and radar. It also has 4 LiDAR-Lite 3 (Garmin) in both\
    \ bands, bow \nand stern, as safety elements for obstacle detection. It has a\
    \ solar roof formed by \n5 Enecom HF 130 panels that extend the autonomy of the\
    \ vessel according to the \nenvironmental conditions, connected to a photovoltaic\
    \ regulator and its battery \npack. The battery pack can also be charged by AC\
    \ chargers. In terms of vision, \nthe ASV is equipped with an AXIS P5534-E PTZ\
    \ camera (in the bow) with 18x \noptical and 12x digital zoom (total 216x), with\
    \ a resolution of 1280x720p, as well \nas three additional Ubiquiti Air Cam cameras\
    \ in the stern on both starboard and \nport. Its renewable energy source does\
    \ not leave a carbon footprint and it thus \nhas no environmental impact, which\
    \ makes it suitable for permanent navigation \nin marine reserves, particularly\
    \ in integral reserves. Figure 4.39 shows a picture \nof the BUSCAMOS-VIGIA vehicle.\
    \   \n \n \n111 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \n \nFigure 4.39.\
    \ BUSCAMOS-VIGIA ASV. \n2.2 Implemented Vessel recognition and tracking algorithm\
    \ \nIn this section, we outline and itemize the development of the above-\nmentioned\
    \ IoT-ASV autonomous system, specifically the algorithm related with \noverall\
    \ mission management and its stages, vessel recognition system and the \nimplemented\
    \ tracking algorithm. It has five main blocks, namely, the IoT \ngateway, the\
    \ IP cameras, the ASV control system, the remote-control station and \nthe cloud/edge\
    \ AI image recognition source. \nThe overall mission is planned and triggered\
    \ by IUNO software in the cloud \nbase station by setting either the desired area\
    \ of inspection or the desired \nwaypoints. The navigation controller consists\
    \ of four navigation modes: Main \nMission Mode (MMM), where the vehicle navigates\
    \ by following preprogramed \ntracks, Dynamic Position Mode (DPM), where the vehicle\
    \ stays at specific GPS \ncoordinates while maintaining a fixed heading, Tracking\
    \ Mode (TM), where the \nASV follows a target (vessel) until specific conditions\
    \ are met, and finally, \nInspection Mode (IM), where once the target has been\
    \ reached, the vehicle stays \nat a fixed distance and heading from it, in order\
    \ to obtain and classify general \ninformation about it. Depending on the current\
    \ navigation mode, there will be a \nserial of priorities, targets and outputs,\
    \ as seen in Table 4.10: \nTable 4.10. Definition of mission stages. \n \nStage\
    \ 1 \nMain \nMission \nMode \n(MMM) \nStage 2 \nFixed Buoy \nMode (FBM) \nStage\
    \ 3 \nTracking Mode \n(TM) \nStage 4 \nInspection Mode (IM) \nPriority \nAccuracy\
    \ \n(recognition) \nLatency \nLatency \nBoth accuracy \n(recognition) and \nlatency.\
    \ \n \n112 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \nTarget \nVessel\
    \ \nrecognition \nand \nclassification \nBounding box \nstudy (size and \npositions)\
    \ for a \ndetermined \nperiod. \nRemain in the \nsame position \nwith fixed \n\
    heading \n \nReach target \nvessel within \ndefined limits \nStay at a fixed distance\
    \ \nfrom target and \nheading it. \nObtain general and \nadditional information\
    \ \nabout target vessel. \nOutput \nIs the target \na risk \nvessel? (YES \n/\
    \ NO) \nIs the target \nvessel in the \nsame position?  \n(YES / NO) \nAlerts.\
    \ \nTarget has been \nreached inside \ndefined limits? \n(YES / NO). \nAlerts.\
    \ Save \ninformation. \nAlerts. Obtain \ninformation of target \nvessel. Video\
    \ \nstreaming. Save \ninformation. \n \nThe navigation mode will change according\
    \ to the scenario and the current \nstage of the general mission, as specified\
    \ in Algorithm 2 and Figure 4.38. The IoT \ngateway connects the navigation controller\
    \ and IP cameras with cloud services. \nDuring the entire mission, the IoT gateway\
    \ receives image data from the IP \ncameras and sensors (through the cRIO controller).\
    \ If a vessel is detected, the \nresults contain its classification (according\
    \ to the trained AI models), a bounding \nbox in the images (centre, relative\
    \ X-Y position, and size) and accuracy \n(percentage). Likewise, the IoT gateway\
    \ receives the image processing results \nfrom the AI recognition source for each\
    \ photo sent. The AI source (edge or cloud \ncomputing) to analyze images is determined\
    \ by the “Smart algorithm for autonomy \noptimization by selecting the proper\
    \ AI technology according to the current scenario” \n(SAAO) described in Section\
    \ 4.4. The AI source uses advanced learning \ntechniques to analyse the results\
    \ and sends them to the IoT gateway. The results \nobtained from the AI source\
    \ are used according to the specific target of each \nmission stage as described\
    \ in Table 10. This process is carried out throughout the \nmission. \nOnce the\
    \ mission starts (MMM), BUSCAMOS-VIGIA ASV follows the \ndefined mission whilst\
    \ analysing images until a vessel is detected. The AI source \nthen classifies\
    \ it according to the trained AI models to determine the risk level. \nThe mission\
    \ mode then moves to the next stage, the Fixed Buoy Mode (FBM).  \nIn FBM, if\
    \ the vessel has been detected with a camera other than the bow \ncamera, the\
    \ vehicle will initially change its heading (stern: +180°, starboard: +90°, \n\
    port: -90°) until the vessel is detected with the bow camera. IoT image processing\
    \ \nis used with the navigation controller to perform heading modifications to\
    \ keep \nthe detected vessel in the centre of the bow camera. Once the heading\
    \ points to \n \n113 \n \nSmart IoT Monitoring and Real-Time Control Based On\
    \ Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services \n\
    the target vehicle, BUSCAMOS-VIGIA ASV will remain in that heading, \nregardless\
    \ of the detected vessel’s behaviour. The ASV can act as a fixed buoy or \nstay\
    \ in same position and heading. This mode is used to study the target’s \nbehaviour\
    \ by analysing the bounding box (size and position) of the processed \nimages\
    \ for a specific period to determine whether the target vessel is immobile \n\
    in the same position, which could mean a potential risk as it could be fishing\
    \ or \nanchored in a protected area. \nAt this point, the mission changes to Tracking\
    \ Mode (TM). The ASV starts \nnavigating and tracking the target by using the\
    \ bounding box’s analysed image \ncollection to fix and update the heading. The\
    \ IoT gateway links up with the main \ncontroller to modify the heading according\
    \ to the target’s position in the image, \nkeeping it in the centre of the bow\
    \ camera’s field of vision. It will continue in this \nmode until LiDAR detects\
    \ the target at a specific distance or if it leaves the \nprotected area. If the\
    \ TM is successful and the target is reached, several actions \ncan take place,\
    \ such us saving the vessel’s position or generating remote alerts. \nWhen the\
    \ target is reached, the last stage, Inspection Mode (IM) starts. The \nASV will\
    \ remain at a fixed distance from the target vehicle and heading as long \nas\
    \ possible. The objective of this stage is to obtain information about the target\
    \ \nand generate alerts in the remote base station. \nThis is described in Algorithm\
    \ 2, as well as in the flowchart in Figure 4.40. \n \n \n \nAlgorithm 2. Vessel\
    \ recognition and tracking algorithm. \nStart () \nStep 1:  \n    While (mission\
    \ has not started) {}    \n    {Starts Main Mission Mode (MMM)}      \nStep 2:\
    \ \n    If (mission has ended) \n        {End ()} \n    Else \n        {Navigate\
    \ follow defined mission} \n        {Select the right AI image recognition source\
    \ (AIsource) trough SAAO} \n        {Acquire frames from 4 cameras and send to\
    \ AIsource} \n        {Get the answer of every frame and add label with camera\
    \ position (bow, stern, \nstarboard, port) of detected vessel, called camera position\
    \ (CP)} \n        If ((accuracy of detected vessel > acceptable limits) AND (type\
    \ of vessel == \nclassified as potential \n        risk)) \n            {Go to\
    \ step 3} \n        Else \n            {Go to step 2} \nStep 3: \n{Starts Fixed\
    \ Buoy Mode (FBM)}      \n \n114 \n \nSmart IoT Monitoring and Real-Time Control\
    \ Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \n{Get the answer of every frame and add label with camera position (bow, stern,\
    \ \nstarboard, port) of detected vessel, called camera position (CP)} \n    Switch\
    \ (CP) \n        Case (CP == bow)  \n             If (accuracy < accuracy results\
    \ acceptable)  \n                {Discard detected vessel. No risk.}         \
    \                \n                {Go to step 2} \n            Else \n      \
    \          {Set new heading pointing detected vessel. Keep current position and\
    \ \nheading} \n                {Start study of target behaviour by analysing bounding\
    \ box of images for a \nspecific period} \n                 If (Detected vessel\
    \ is in the same position)  \n                    {Discard detected vessel. No\
    \ risk}                         \n                    {Go to step 2} \n      \
    \          Else \n                    {Target vessel in the same position. Risk\
    \ (anchoring, fishing)}                         \n                    {Go to step\
    \ 4} \n        Case (CP == stern) \n            {Vehicle turns +180º} \n     \
    \       {Go to step 3} \n        Case (CP == starboard) \n            {Vehicle\
    \ turns +90º} \n            {Go to step 3} \n        Case (CP == port) \n    \
    \        {Vehicle turns -90º} \n            {Go to step 3}    \n        Default:\
    \ \n            {Go to step 2}    \nStep 4: \n    {Start Tracking Mode (TM)} \n\
    \    {Navigate to track target vessel}      \n    {Acquire new frame from bow\
    \ camera and send to AIsource}  \n    {Calculate the bounding box center and vessel\
    \ position in order to fix heading \nwhile tracking} \n    If (LiDAR detects vessel\
    \ at 20m) \n        {Stop navigation. Target reached}  \n        {Go to step 5}\
    \ \n    Else If (vessel leaves integral reserve while tracking) \n        {Target\
    \ not reached}  \n        {Go to step 2} \n    Else  \n        {Go to step 4}\
    \ \nStep 5: \n    {Starts Inspection Mode (IM)} \n    {Acquire new frame from\
    \ bow camera and send to AIsource}  \n \n115 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \n    {Calculate the bounding box centre and vessel position in order\
    \ to fix heading and \nkeep distance} \n    While (Target vessel is stopped) \n\
    \    {Record videos, save vessel’s position, obtain additional information, send\
    \ \ndata and alerts to cloud station} \n    If (Vessel starts moving) \n     \
    \   {Stage finished. Information collected} \n        {Go to Step 2} \nSecurity\
    \ Step:     \n    If (Energy == 25%) \n        {Return back to port area. Send\
    \ alert to cloud station} \n    If (Energy == 50%)  \n        {Send alert to cloud\
    \ station} \nEnd () \n \n \n \n \nFigure 4.40. Platform’s communications in the\
    \ tracking algorithm. \n2.3. ASV control \nAs shown in Figure 4.38, our marine\
    \ vehicle has a number of elements and \ndevices interconnected through different\
    \ networks. While the IoT gateway is in \ncharge of image recognition and communications\
    \ with the camera and the cloud, \nthe cRIO controller is the ASV’s main control\
    \ backbone. The National Instrument \ncRIO 9022 controller includes a real-time\
    \ processor and reprogrammable FPGA \nthrough its LabVIEW environment [240], as\
    \ well as a chassis that can be \nreconfigured according to the project architecture.\
    \ By default, it comprises two \nEthernet ports, USB port and serial connectivity.\
    \ For this architecture, the chassis \n \n116 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \nhas been equipped with several modules that enable CAN-NMEA2000,\
    \ I2C, \nRS232 and RS485 communications. Its specifications are a 533-MHz CPU,\
    \ 256MB \nDRAM, 2GB storage, one Ethernet port and other features listed in [241].\
    \ A \nconsistent code for the cRIO controller was fully developed in the LabVIEW\
    \ \nenvironment for ASV management, control and command. \nThe software modules\
    \ in the cRIO’s vehicle control program comprise these \nmain operations, as shown\
    \ in Figure 4.38: \n \n• Commands management: It allows cRIO dispatch commands\
    \ from cloud \nstation, such as receive and launch main mission after definition\
    \ trough IUNO \nsoftware, stop it, or execute safety manoeuvres \n• Propulsion\
    \ and rudder control: Management of the different control loops for \nboth propulsion\
    \ and rudder, according to the obtained setpoint from Mission \nexecution control\
    \ module. \n• Incidents management: Security module that manages different actions\
    \ \ndepending on the incidents that may occur during the mission, such as loss\
    \ \nof communications or the impossibility of continuing the defined trajectories\
    \ \ndue to external conditions, such as strong winds or rough seas. \n• Mission\
    \ execution control: This module manages navigation to each of the \nprogrammed\
    \ waypoints, according to the running mission, by dispatching \nthe different\
    \ navigation commands for the heading and position control loops \nwith the information\
    \ received from sensors and IoT image analysis algorithm.  \n• Energy efficiency\
    \ manager: The vehicle contains some non-critical navigation \ndevices that can\
    \ be disconnected in the event of energy and autonomy being \ncompromised. This\
    \ module executes the disconnection if required. \n \n3. Smart algorithm for autonomy\
    \ optimization by selecting the \nproper AI technology according to the current\
    \ scenario (SAAO)  \n \nMaritime Autonomous Surface Ships (MASS) have to guarantee\
    \ a series of \nrequirements in order to fulfil their purpose, in particular,\
    \ autonomy and \nsecurity, while accuracy and latency in the image analysis are\
    \ vital in the \nsurveillance of marine reserves through AI-based visual recognition.\
    \  \nAs defined previously, the surveillance mission is divided into four stages\
    \ in \norder to optimize them according to the objectives and a series of priorities\
    \ to \nattend to each stage, as defined in Table 10. Optimizing the mission execution\
    \ \nmeans accomplishing it in the minimum time possible and with the highest \n\
    guarantee of success, or in other words, execute every stage of the mission in\
    \ the \nmost efficient manner possible. An efficient mission means making the\
    \ most of \nthe energy available, a limited and essential resource for autonomous\
    \ vehicles. \nThe restrictive objective is to save energy and guarantee the success\
    \ of the \n \n117 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \nmission and\
    \ its security by taking the appropriate decisions in real time, which \nis the\
    \ crucial task of the proposed AI hybrid cloud/edge SAAO algorithm. \nIn stages\
    \ where accuracy is a priority, optimizing mission execution means \nusing AI\
    \ to obtain the best recognition results, detecting vessels that are a \npotential\
    \ risk to the marine reserve with the maximum precision and success. On \nthe\
    \ other hand, once the potential target has been detected and identified, \noptimizing\
    \ the mission in stages in which latency is a priority means obtaining \naccurate\
    \ results as fast as possible as setpoint for the heading controller block.  \n\
    As a single board low-power CPU is used to extend ASV autonomy, SAAO \nis designed\
    \ to be efficient and executed in platforms where energy is a limitation. \nUsing\
    \ both cloud and edge computing technologies to analyze images at the \nsame time\
    \ will entail extra consumption and increased latency in the image \nanalysis,\
    \ especially in edge computing, where CPU resources are limited. Balance \nis\
    \ the key to efficient and successful decision-making. These decisions are related\
    \ \nto selecting the best AI source technology for the success of every stage,\
    \ all of \nwhich have a series of priorities for optimizing the mission execution,\
    \ as shown \nin Table 4.11: \nTable 4.11. AI source preferences according to mission\
    \ stage. \n \nStage 1 \nMain \nMission \nMode \n(MMM) \nStage 2 \nFixed Buoy \n\
    Mode (FBM) \nStage 3 \nTracking \nMode (TM) \nStage 4 \nInspection \nMode (IM)\
    \ \nPriority \nAccuracy \n(recognition) \nLatency \nLatency \nBoth accuracy \n\
    (recognition) \nand latency. \nPreference \nAzure Cloud \nCustom \nModel \nAzure\
    \ Edge \nCustom \nModel \nAzure Edge \nCustom \nModel \nAzure Cloud \nGeneral\
    \ Model \nAlternativ\ne \nAzure Edge \nCustom \nModel \nAzure Cloud \nCustom \n\
    Model \nAzure \nCloud \nCustom \nModel \nAzure Edge \nCustom Model \n \nIn normal\
    \ conditions latency is adequate in edge models and accuracy is \nsuitable in\
    \ cloud models. That is the reason why there is a logic preference in \nevery\
    \ stage according to the defined priority, provided that accuracy is good \nenough.\
    \ Knowing when and what to offload while maintaining real-time \napplication Quality\
    \ of Service (QoS) requirements are the challenges to \novercome. Depending on\
    \ the mission stage, accuracy and latency results, a \ntechnique of offloading\
    \ to edge computing device (IoT gateway) or remote cloud \nservices is performed\
    \ to complete its execution, as shown in Figure 4.41. \n \n118 \n \nSmart IoT\
    \ Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \nBasically, intelligent offloading can\
    \ be used as an optimization-based \napproach with constraints such as bandwidth,\
    \ network latency, accuracy \nrequirements or monetary cost. In this application,\
    \ latency and accuracy have \nbeen defined as critical throughout the process,\
    \ and that is why the output results \nof the AI source are linked as inputs to\
    \ the SAAO algorithm after analysing the \nimages.  \nThe decision to offload\
    \ or not depends on hardware capabilities, data size, \nthe deep neural network\
    \ (DNN) model to be used and network quality, among \nother factors. These factors\
    \ can be measured indirectly through latency and \naccuracy. Latency and accuracy\
    \ are the main elements to be considered in this \noptimization approach. Figure\
    \ 4.41 shows the SAAO diagram: \n \nFigure 4.41. SAAO diagram. \nThis diagram\
    \ describes how the SAAO works. The latency and accuracy \nobtained from the previous\
    \ analysis are analyzed according to the mission stage \nand the defined AI source\
    \ preference. In the stages where latency is the priority, \nthe accuracy result\
    \ is analyzed to check whether it is within acceptable limits. \nThis means that\
    \ they should at least be able to identify the target and obtain its \nrelative\
    \ coordinates in the analyzed image in order to obtain the bounding box \ncoordinates\
    \ and use them as a setpoint for the heading control loop. There is no \npoint\
    \ in using a fast AI source if the algorithm cannot detect the target in its \n\
    analysis. This is the critical line for accuracy. \nIn stages where accuracy is\
    \ the priority, latency is analyzed in order to select \nthe preferred or alternative\
    \ AI source. The latency results may vary significantly \ndepending on several\
    \ factors, such us the percentage of bandwidth used, \n \n119 \n \nSmart IoT Monitoring\
    \ and Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \ndistance from ship to base station, or weather conditions,\
    \ among others. With \nlatency not being the priority in these stages, it has\
    \ to be low enough to obtain an \nacceptably fast response, especially in the\
    \ last stage, where the general cloud \nmodel is used to obtain general information\
    \ about the target vessel. Latency is \nalso crucial to keep the target in the\
    \ centre of the vision field. \nLatency average is updated for edge and cloud\
    \ model with each new \nanalysis. This determines acceptable limits for latency\
    \ dynamically, considering \nparameters such as network quality and bandwidth\
    \ indirectly. \n \n \nFigure 4.42. Calculation of acceptable latency limits. Main\
    \ ASV camera point of \nview. \n= \U0001D443\U0001D45B − \U0001D443\U0001D45B\
    −1 \n(4.24) \n\U0001D447 = \U0001D447\U0001D45B − \U0001D447\U0001D45B−1 \n(4.25)\
    \ \n\U0001D445\U0001D446 = \U0001D437\U0001D435\U0001D436\U0001D436\n\U0001D447\
    \  \n(4.26) \n \nFigure 4.42 shows the difference of position between 2 consecutive\
    \ analysed \nimages. From each successfully analysed image, the bounding box of\
    \ the detected \nvessel, its relative coordinates in the image, as well as its\
    \ timestamp are obtained. \nBy knowing the distance between bounding box centres\
    \ (BBC) and the time \ndifference between analyses (T), the relative speed (RS)\
    \ at which the target moves \nin the image can be obtained. During the time lapse\
    \ between the analysis of 2 \nconsecutive images we can approximate the relative\
    \ speed of displacement of the \ntarget vessel and the ASV as a constant value,\
    \ due to the considerable inertia of \nvessels at sea. With this information,\
    \ it is calculated when the target BBC will \nleave the range of vision, and SAAO\
    \ can determine the selection of the preferred \nor alternative source of AI with\
    \ regard to latency. \n \n120 \n \nSmart IoT Monitoring and Real-Time Control\
    \ Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \nSeveral factors affect SAAO decisions, and they can be measured indirectly\
    \ \nthrough latency and accuracy. Low latency and high accuracy are always \n\
    desirable results, but every AI cloud or edge platform has its advantages and\
    \ \nhandicaps, and we cannot always achieve both simultaneously. Balance and \n\
    effective decision making are the keys to make a mission efficient and successful.\
    \ \n \n4. Experiments and Results  \n4.1. AI recognition and proposed algorithm\
    \ for autonomy optimization  \n \nFigure 4.43 shows an example of three different\
    \ cloud vision APIs analyzing \nthe same image, with different types of boats\
    \ in a port. All three cloud services \nmanaged to detect most of the boats in\
    \ the image. The bounding box location is \naccurate, although the cloud response\
    \ cannot exactly specify the type of each \nboat. Our objective is not only to\
    \ detect each boat in the image but also to group \nthem into more specific categories.\
    \ The general model offered by the cloud has \nits limits in this regard. \n \n\
    \ \nFigure 4.43. Comparison of three different clouds vision API detection of\
    \ boat in \nLos Nietos port (Murcia, Spain). \n4.1.1. Custom model training for\
    \ detection specific vessels \nThe advantage of the customized model is the possibility\
    \ of training it \naccording to the use case, in addition to detecting the location\
    \ of objects in the \nimage. Our model has been trained to identify different\
    \ types of vessels and their \nposition in an image. We created our own custom\
    \ object detection model to be \nimplemented in the proposed IoT gateway using\
    \ the Azure cloud service, as it \nsupports the edge computing technologies and\
    \ gives a better performance than \nthe other solutions [242]. More than 600 photos\
    \ of different types of vessels found \naround the inspection area in the experiment\
    \ have been used to train the custom \nmodel. The model has been trained to recognize\
    \ 7 different types of vessels \n(Figure 4.44). The position of each vessel in\
    \ the image was identified by drawing \na bounding box around the object and providing\
    \ the top and left pixel \ncoordinates of the box, along with the width and height\
    \ in pixels. \n \n \n121 \n \nSmart IoT Monitoring and Real-Time Control Based\
    \ On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \nFigure 4.44. Types and number of vessels used to train the vision custom models.\
    \ \nAzure can retrain our model in different ways, by quick training or advanced\
    \ \ntraining by specifying the training computation time. The more time and pictures\
    \ \nused train the model in the platform, the better the results and performance\
    \ will \nbe.  \nFigure 4.45 shows the detection testing of new photos not used\
    \ in the training \nphase. The cloud trained model was able to differentiate between\
    \ different types \nof boats, as for instance a man fishing in a kayak. The model\
    \ detected the \nsituation perfectly by the training photos. \n \nFigure 4.45.\
    \ Performance of the cloud custom model object detection in discerning \ndifferent\
    \ boats types. \n4.1.2. Cloud and Edge custom models. \nIn the proposed architecture,\
    \ we put forward the LattePanda IoT gateway \nrunning under Windows 10 LTSB OS,\
    \ where the trained edge model has been \ndeployed by using Microsoft Azure. Azure\
    \ offers the possibility of choosing \nbetween different object detection custom\
    \ model domains, namely General, \nLogo, Products on shelves and General Compact.\
    \ The General domain is trained \nto be used only in the cloud (Cloud Custom Model),\
    \ while the General Compact \ndomain is trained to be used in Edge devices (Edge\
    \ Custom Model). The model \nperformance varies by the selected domain; models\
    \ generated by General \nCompact domains can be exported to run locally, so they\
    \ are lightweight models \n \n122 \n \nSmart IoT Monitoring and Real-Time Control\
    \ Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \nand optimized for the constraints of real-time object detection on edge devices,\
    \ \nalthough they are less accurate than the General domain. \nFigure 4.46 shows\
    \ the training performance of 600 photos using the 7-hour \ntraining budget. The\
    \ edge and cloud models were trained with the same number \nof photos and training\
    \ budget. The figure 4.46 shows the difference between the \ntwo models after\
    \ the training. \n \nFigure 4.46. Performance differences between the Edge and\
    \ the cloud custom \nmodels. \nAs the models generated by the compact domains\
    \ are optimized for the constraints \nof real-time classification on edge and\
    \ mobile devices, they are slightly less accurate than \na standard domain with\
    \ the same amount of training data. Figure 4.47 clearly shows the \ndifference\
    \ between the custom model for cloud and edge uses, i.e. between the edge-\ntrained\
    \ model and the cloud-trained model. As can be seen, the distance from the object\
    \ \nto the ships' cameras affects the model’s percentage of accuracy. For instance,\
    \ as shown \nin case 3 in the figure 4.47, the cloud model was able to recognize\
    \ the vessel in the \ndistance accurately, while the edge model was not. \n \n\
    123 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots,\
    \ Visual Recognition and Cloud/Edge \nComputing Services \n \nFigure 4.47. Cloud\
    \ and edge custom models for detecting new vessels. \n \n4.2. Latency assessment\
    \ in edge and cloud custom models \nPerforming powerful DNNs (Deep Neural Networks)\
    \ with real-time execution \nrequirements on edge devices is still a challenge,\
    \ regardless of the hardware \nacceleration and compression techniques deployed.\
    \ Considering offloading the \nDNN computation from local devices to more powerful\
    \ entities such as the cloud \nis a common scenario. Today, the cloud offers an\
    \ edge model for deployment on \ntiny devices, however, cloud models are also\
    \ needed to provide satisfactory \nperformance. Another important factor to consider\
    \ is that the cloud is known to \nfacilitate storage, computational complexity\
    \ and the energy load on the edge and \non local devices. Nevertheless, the cloud\
    \ servers are topologically and spatially \ndistant from the local stations, which\
    \ causes significant communication latency. \nReal-time inference is absolutely\
    \ required for many applications. For instance, \nframes from an autonomous vehicle’s\
    \ camera must be processed rapidly to \nidentify and evade obstacles, or a voice-based\
    \ solution must have a rapid analysis \nand understanding of the user's input\
    \ to provide a feedback. However, \ntransferring data to the cloud for inference\
    \ or training may result in more queues \nand delays in transmission from the\
    \ network and cannot meet the stringent \nrequirements of low end-to-end latency\
    \ required for real-time interactive \napplications. For example, experiments\
    \ have revealed that offloading a camera \nframe to Amazon Web Services and performing\
    \ a computer vision task requires \nmore than 200ms of end-to-end data [243].\
    \ \nIn this use case, Azure Custom Vision's used service works in Western \nEurope.\
    \ The experiments were carried out in the IoT gateway mentioned above \nby using\
    \ Python programming language. The results of the latency are \nsummarized in\
    \ Table 4.12, including: average latency, standard deviation, and \nthe minimum\
    \ and maximum values calculated for each model. The time that the \ncloud model\
    \ needs to send the photos to the cloud for processing and get the \n \n124 \n\
    \ \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual\
    \ Recognition and Cloud/Edge \nComputing Services \nresults back has been measured.\
    \ Given that the trained edge model is migrated \nas a TensorFlow lite program,\
    \ the photos are analyzed at the IoT gateway instead \nof being sent to the cloud.\
    \ The performance of the edge models varies with the \noperating platform; hence\
    \ the inference time may vary. All samples were \ncarefully and thoroughly checked\
    \ for the same data on the same day. The \nexperiment was repeated using the same\
    \ data for both cloud and edge models. \nEach experimental campaign had about\
    \ 300 different valid samples. \n \nTable 4.12. RTD test of 300 samples of the\
    \ Edge and Cloud model. \n \nMin \nlatency (s) \nMax \nlatency (s) \nAverage \
    \ \n(s) \nVariance  \n(s2) \nStandard \ndeviation \n(s) \nCloud \nModel \n0.805\
    \ \n5.298 \n1.412 \n0.872 \n0.934 \nEdge \nModel \n0.213 \n0.896 \n0.336 \n0.012\
    \ \n0.108 \n \nThe results reported in Table 12 show the latency differences between\
    \ edge \nand cloud models on the same machine. The average cloud model score is\
    \ higher \nthan the edge model by more than 1s. However, the variance of the edge\
    \ model \nis almost null compared to the cloud model, which is close to 900ms,\
    \ which \njustifies the edge model’s better stability in time than compared to\
    \ the cloud \nmodel. \nFigure 4.48 compares the experimental latency results of\
    \ both edge and cloud \nmodel. The edge model shows more stability and all values\
    \ do not exceed the 1s \nlatency. Cloud model can sometimes extend beyond 4s.\
    \ According to the cloud \nlatency results, they can be classified into two ranges.\
    \ The first extends for about \n1 and 2 seconds, while the second extends for\
    \ around 4 and 5 seconds. In \naddition, there is a band where no data has been\
    \ registered, between \napproximately 2.5 and 3.5 seconds. \n \n \n \n125 \n \n\
    Smart IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual\
    \ Recognition and Cloud/Edge \nComputing Services \nFigure 4.48. Latency of more\
    \ than 300 samples. \n \nThe cloud model’s apparent processing time instability\
    \ can be explained by \nthe internet connection volatility as the photos have\
    \ to be sent to the cloud model \non remote servers for processing, unlike the\
    \ edge model in which all photos are \nprocessed on board or at the local station.\
    \  \nThe cloud and edge models are different in terms of accuracy, even though\
    \ \nthey are trained on the same reference images. In contrast to latency, the\
    \ cloud \nmodel is more accurate, which eventually makes it challenging to choose\
    \ \nbetween both models. Real-time and high accuracy are both essential. However,\
    \ \nin an autonomous marine vehicle where computing power is limited and \nenvironmental\
    \ conditions are variable, low latency and high accuracy in every \nanalysis are\
    \ not guaranteed. The aim is to find an acceptable performance \ncompromise, considering\
    \ the evolution of the ongoing mission phases, as \ndescribed in detail in the\
    \ next section. \n4.3. Experimental test and results (SAAO Algorithm) \nIn order\
    \ to test the decision making of the SAAO algorithm, an experiment \nwas carried\
    \ out based on the analysis of a 1.5-hour video filmed in the Bay of \nCartagena.\
    \ The most interesting results were from a 2-minute sequence of a \nfishing boat,\
    \ whose results were analysed as described below. A 10-second \nextract of the\
    \ analysis is shown in this experiment. \nFor the experiment, this video was used\
    \ as the image source for the IoT \nGateway device, replacing the \"Cameras\"\
    \ block shown in Figure 438. The \ncaptures extracted by the IPM (Image processing\
    \ algorithm) were analysed in \nthree different scenarios. First, only an edge\
    \ computing analysis was carried out, \nrecording latency and accuracy results,\
    \ without the intervention of SAAO. The \nexperiment was then repeated with the\
    \ same images analysed using cloud \ncomputing. Finally, the SAAO algorithm was\
    \ tested in making decisions on the \nmost suitable AI source for the analysis\
    \ of the next image, based on the results \nobtained, and for each of the four\
    \ stages, as shown in Table 4.13 and Figure 4.49. \nTable 4.13. Experimental SAAO\
    \ results \nNº \nSampl\ne \nEdge \nCloud \nSAAO answer for next analysis \nLat\
    \ \n(s) \nAcc \n(%) \nLat \n(s) \nAcc \n(%) \nMM\nM \nFBM \nTM \nIM \n1 \n0.447\
    \ \nND \n1.412 \n16.7 \nCCM \nCCM \nCCM \nCGM \n2 \n0.418 \n64.3 \n1.814 \n68.7\
    \ \nCCM \nECM \nECM \nCGM \n3 \n0.324 \n19.5 \n2.816 \n50.5 \nECM \nECM \nECM\
    \ \nCGM \n4 \n0.356 \n47.9 \n1.313 \n65.8 \nCCM \nECM \nECM \nCGM \n5 \n0.403\
    \ \n23.1 \n4.211 \n33.8 \nECM \nECM \nECM \nECM \n6 \n0.392 \n36.8 \n1.284 \n\
    55.7 \nCCM \nECM \nECM \nECM \n \n126 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \n \nND – Not detected \nCCM – Cloud custom model \nECM – Edge custom\
    \ model \nCGM – Cloud General Model \n \n \nFigure 4.49. Images analysed. Cloud/edge\
    \ results comparison \nAs can be seen in Figure 4.49, there is a difference between\
    \ the edge and cloud \nmodels when detecting the same image. Sometimes the difference\
    \ between the \ntwo percentages is not so significant, while in other cases there\
    \ is a notable \ndifference, especially when the boat is at a distance, which\
    \ sometimes \ncomplicates the detection by using the edge model as seen in the\
    \ example of \nPhoto 1, or the latency results were high, in cloud computing mostly.\
    \ These \nvalues condition the SAAO response, with different decision making in\
    \ each \nstage, according to the preferred or alternative AI source. Special attention\
    \ to \nImages 1 and 5, where the low accuracy in the edge model and the high latency\
    \ \nin the cloud model conditioned SAAO's decision for the alternative AI model.\
    \ In \nImage 6, the alternative AI model (according to Table 11) has also been\
    \ selected \nin IM (Stage 4), due to the risk of losing the bounding box’s centre\
    \ of the target \nin the range of vision. \n4.4 Experiment of BUSCAMOS-VIGIA with\
    \ SAAO \nAs mentioned in the Introduction, the complexity of autonomous \nsurveillance\
    \ varies significantly in different scenarios in the Spanish Network of \nMarine\
    \ Reserves. The Cabo de Palos and Islas Hormigas Marine Reserve [244] in \nthe\
    \ Region of Murcia (Figure 4.50) has medium complexity according to the \npreviously\
    \ defined criteria.  \n \n127 \n \nSmart IoT Monitoring and Real-Time Control\
    \ Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \nThis reserve covers an area of 18.98 km2 and is a zone with high biodiversity\
    \ \nand prairies of oceanic posidonia and rocky coralligenous beds, as well as\
    \ \nremarkable marine dynamics. This is a natural underwater area that contains\
    \ an \nintegral reserve in the surroundings of Hormiga Island, El Bajo, El Mosquito\
    \ and \nthe islets of El Hormigón and La Losa. \nThis marine reserve is very near\
    \ the Mar Menor, the largest saltwater lagoon \nin Europe, which was selected\
    \ as the scenario for the case study as the water there \nis usually calm, and\
    \ winds are light (Figure 4.50). \n \n \nFigure 4.50. Scale experiment. Equivalence\
    \ of area and distance from integral reserve \n(Islas Hormigas) to base station\
    \ (right) and equivalent area in Mar Menor (left) \n \nThe test exploration mission\
    \ was carried out to survey a marine space with a \nsurface and distance to the\
    \ base station equivalent to the Cabo de Palos and Islas \nHormigas Marine Reserve.\
    \ The objective was to detect, track and identify \nsuspicious vessels within\
    \ the area to validate the proposed architecture and the \nSAAO algorithm. The\
    \ defined inspection area has a radius of 915 m, with a \nsurface area of 2.63\
    \ km2 and a centre at coordinates 37.689634° N and 0.787109° \nW. To avoid detecting\
    \ vessels outside the test area due to the vision field, the area \ncovered by\
    \ the main mission was reduced by a radius of 100m, as shown in \nFigure 4.52.\
    \ The mission was planned on the IUNO platform.  \nThe recognition system was\
    \ tested in port before the mission through the \nmain bow camera to ensure that\
    \ both Azure cloud and edge AI sources worked \nas expected (Figure 4.51). A fishing\
    \ boat, a recreational boat and a sailing boat \nwere detected by the edge model,\
    \ and an extra sailing boat by the cloud model, \nwith better accuracy in all\
    \ detections.  \n \n \n \n128 \n \nSmart IoT Monitoring and Real-Time Control\
    \ Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \n \nFigure 4.51: Edge (left) / cloud (right) trained model recognition tests.\
    \ \n \nThe ASV was remotely monitored and supervised from the fishing boat used\
    \ \nas the auxiliary vessel for safety reasons during the entire mission. The\
    \ auxiliary \nvessel was also used to verify the detection, recognition and tracking\
    \ capabilities \nimplemented, as explained below. The different systems (control,\
    \ lighting, \nthrusters, \ncommunications, \nvision, \netc \n(control, \nlighting,\
    \ \nthrusters, \ncommunications, vision, etc) were tested before the BUSCASMOS-VIGIA\
    \ \nmission. After successful validation, the mission was transferred from IUNO\
    \ to \nthe ASV and launched and the vehicle headed for the starting point. Surveillance\
    \ \nof the area began following the previously defined route (Figure 4.52). From\
    \ the \nfirst point of the mission to the fifth sweep in the Main Mission Mode\
    \ (MMM) no \nincidents or detections occurred.   \n \n \nFigure 4.52. Start of\
    \ mission (MMM) of surveillance of area equivalent to integral \nreserve. \n \n\
    \ \n129 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots,\
    \ Visual Recognition and Cloud/Edge \nComputing Services \nThe technical team\
    \ on board the fishing boat remained at a specific point in \nthe fifth sweep\
    \ to study the ASV’s behaviour. The fishing boat was detected by \nBUSCAMOS-VIGIA\
    \ (Figure 4.53-a) and classified as a possible risk. According to \nSAAO logs\
    \ during this stage all image analysis was performed by the cloud-\ntrained model\
    \ except for one case in which the edge-trained model was used due \nto high latency.\
    \ The target vessel’s behaviour was studied to determine if it was \nstationary,\
    \ according to the rules defined Stage 2, Fixed Buoy Mode (FBM). The \nregisters\
    \ showed that only the edge model was used. The bounding boxes of all \nthe analyzed\
    \ images were determined as the accuracy was high enough at this \nstage. After\
    \ the FBM stage, when the results determined that the target vessel \nwas stationary,\
    \ the Tracking Mode (TM) stage began. The technical team on \nboard the target\
    \ vessel then started the motors to verify the tracking capabilities \n(Figure\
    \ 4.53-b). \n \n \n \n                         (a)                           \
    \                                                (b) \nFigure 4.53. (a) Stopped\
    \ vessel detected. Start TM mode. (b) Tracking Mode (TM) test \nduring the experiment.\
    \  \n \nThe ASV successfully reached the target. As in FBM, only the edge model\
    \ \nwas used by the SAAO during all the TM. The vehicle stopped over 15m away\
    \ \nand changed to Inspection Mode (IM), the last mission stage. \nThe results\
    \ obtained from the Azure Cloud AI General Model on additional \ninformation about\
    \ the target vessel were as follows: the three people on board \nwere detected.\
    \ The automatically generated sentences “a group of people on a boat” \nand “a\
    \ group of people riding on the back of a boat in the water” by the cloud general\
    \ \nmodel were useful for obtaining details of the target vessel without the need\
    \ to \nview cameras in real time and without human intervention. At this stage,\
    \ the \nrecords show that the SAAO used both the cloud general model and the edge-\n\
    trained model. The cloud results were not fast enough to determine the target\
    \ \nvessel’s bounding box in some cases. Table 4.14 shows a summary of the SAAO\
    \ \nlogs during the experiment: \n \nTable 4.14. Summary of SAAO logs during the\
    \ experiment \n \n130 \n \nSmart IoT Monitoring and Real-Time Control Based On\
    \ Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services \n\
    Stage \nEdge (custom model) \nCloud (custom and general \nmodel) \nSAAO answers\
    \  \nAv. \nLat \n(s) \nAv.  \nAcc \n(%) \nNº \nuses \nDetect\n-ions \nAv. \nLat\
    \ \n(s) \nAv.  \nAcc \n(%) \nNº \nuses \nDetections \nUse of the preferred \n\
    AI source (%) \nMMM \n0.22\n0 \n21 \n1 \n1 \n1.52\n1 \n34 \n2414 \n1 \n99.95 \n\
    FBM \n0.20\n5 \n31 \n58 \n58 \n- \n- \n0 \n- \n100.00 \nTM \n0.23\n1 \n39 \n436\
    \ \n436 \n- \n- \n0 \n- \n100.00 \nIM \n0.21\n8 \n57 \n29 \n27 \n1.58\n9 \n68\
    \ \n92 \n88 \n76.03 \n \nWhen the fishing boat left the area, BUSCAMOS-VIGIA ended\
    \ the IM stage \nand continued with the planned mission (in MMM) until the eighth\
    \ sweep was \ncompleted. The vessel was then commanded to return to port and no\
    \ further \nincidents were registered during the rest of the mission. \n \n \n\
    \ \nIV. An IoT Control System for Wind Power Generators \n \n1. Introduction \
    \  \n \nAs an important source of energy in different countries, renewable energy\
    \ is \nwidely used today, renewable electricity generation in 2018 was 6.1% higher\
    \ than \nin 2017, representing about 16% of global power generation, as reported\
    \ in \nIRENA (2017) [245]. This percentage is expected to double in the next 15\
    \ years \nand 65% of energy use could come from renewable resources by 2050. Wind\
    \ and \nsolar energy production in 2018 increased by 11% and 28%, respectively.\
    \ \nAltogether, these two sources of energy remain dominant in the growth of \n\
    renewable generation, accounting for 73% of growth since 2014 [245]. \nPresent\
    \ machines used for manufacturing already support digital or analog \nsensing\
    \ connected to a central control station to be monitored via a wired \nEthernet\
    \ system [246]. These systems, nevertheless, are not usually connected to \nthe\
    \ Internet [247]. This is the era that meets the important evolution of the \n\
    industry and the Internet. In order to be able to follow this important evolution\
    \ \nof wind energy, it is necessary to enforce the capacity of the Internet to\
    \ assess all \n \n131 \n \nSmart IoT Monitoring and Real-Time Control Based On\
    \ Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services \n\
    data collected from the different industrial elements, sensors, actuators, motors,\
    \ \netc. \nA \nvariety \nof \nadvanced \ntechnologies \nsuch \nas \nintelligent\
    \ \nrobots, \ncommunication systems (e.g., 5G), and the Internet of Things (IoT)\
    \ are expected \nto enhance the fourth industrial revolution [248]. IoT connects\
    \ a number of \npeople, devices, processes, and data, enabling them to communicate\
    \ with each \nother seamlessly. IoT can therefore help improve different processes\
    \ to make \nthem more measurable and quantifiable by gathering and processing\
    \ large \namounts of data [249]. IoT can potentially improve the quality of life\
    \ in different \nareas. In the energy sector, IoT can be deployed to increase\
    \ energy efficiency, \nexpand the share of renewable energy, limit the environmental\
    \ impacts of energy \nuse [250], and to have a clear vision of the entire system,\
    \ in real-time, without the \nnecessity of physically being in the area of the\
    \ installation. This will consequently \nreduce waiting times and decrease unnecessary\
    \ costs.  \nThe idea of the IoT is to treat each object as a thing, the renewable\
    \ energy \nresource is considered an object and is assigned a unique IP address,\
    \ where all \ndata gathered by sensors and actuators can be measured, analyzed\
    \ and managed, \nthrough the cloud-based platforms. The communication protocols\
    \ of the IoT \nplatform allow the different devices to communicate and share their\
    \ data with \nthe controllers or decision centers. The IoT platforms offer the\
    \ flexibility to select \nthe type of communication technologies according to\
    \ the needs of the \napplication. Each of these communication technologies has\
    \ specific features and \ncan be carried out through wired and wireless networks,\
    \ including, but not \nlimited to, RS485, Wi-Fi, Bluetooth, ZigBee [251] and cellular\
    \ technology such as \nLTE-4G and 5G networks [252]. The IoT is considered one\
    \ of the complex \nsystems, and this complexity is due to the interactions in\
    \ the environment, an \ninterconnection of the IoT components and the number of\
    \ networks and \nprotocols that are involved. The IoT gateway is the component\
    \ that allows these \ndifferent networks to communicate [253]. \nThe data analysis\
    \ is performed for decision making about the functioning of \nthe application.\
    \ As needed, data analysis can be accomplished offline or in real \ntime. When\
    \ analyzing off-line, the stored data is first collected and then \nvisualized\
    \ on site using visualization tools installed in the IoT gateway or in a \nbase\
    \ station). However, In the case of real-time analysis, cloud or edge servers\
    \ \nare used to perform the visualization, e.g. stream analysis [254].  \nThe\
    \ rest of this chapter is organized as follows. We present a study of related\
    \ \nwork in the field of IoT solutions in the renewable energy sector. We then\
    \ \nintroduce the system model and the different protocols and applications used\
    \ to \nconnect the wind energy control system to the cloud. Following, we describe\
    \ the \nproposed hardware and software used to connect the system to the cloud.\
    \   \nFinally, the possibilities that can be done using the data transmitted offline\
    \ at the \nIoT gateway and in real time in the cloud. \n \n \n132 \n \nSmart IoT\
    \ Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \n2. Modelling System Architecture \n \n\
    Within a wind energy system, a wind turbine converts wind energy into \nelectrical\
    \ energy. First it consists of a rotor, that transforms the aerodynamic \nthrust\
    \ into rotation movement, second a Multiplier, that adapts the rotation \nspeed\
    \ to the speed of the generator, then also an Alternator, that transforms the\
    \ \nrotation energy into electrical energy, and finally a Dump to the grid, that\
    \ injects \nenergy into the electrical network. \nThe wind energy system consists\
    \ of sensors, motors and actuators to be \nmonitored and controlled continuously.\
    \ The system must guarantee a safe and \nreliable operation, monitor the components\
    \ and variables, verify that the \nvariables are in an allowable range and must\
    \ perform fault detection and \nprediction. In a wind turbine, a yaw-guiding motor\
    \ turns the nacelle to face the \nwind, and the movement of the motor depends\
    \ on data from wind direction \nsensors. In fact, predictive analysis will alert\
    \ operators in advance if a component \nneeds to be repaired or inspected.  \n\
    New technologies such as IoT, machine learning, cloud, large data can \nfacilitate\
    \ better use of resources and help harness clean energy along with \noptimization.\
    \ IoT has an important impact on the energy sector, especially wind \nenergy,\
    \ given that this technology is applied to inaccessible environments and \nremote\
    \ areas. \nThe general architecture of an IoT system is composed mainly of three\
    \ parts, \nthe first one is the data generation and control system where it is\
    \ connected to \nthe devices and sensors, secondly it is the IoT gateway where\
    \ the main programs \nand protocols are installed to communicate the received\
    \ data, and finally, the \ncloud service, which reports all the data coming from\
    \ the wind energy system \nthrough the IoT gateway.  \n \n \n133 \n \nSmart IoT\
    \ Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \n \nFigure 4.54 : Wind energy IoT communication\
    \ architecture \n \nIn this proposal we present two of the most important sensors\
    \ used in a wind \nenergy system, which are the wind energy direction sensor (Anemometer)\
    \ and \nthe wind speed sensor (Vane). Also proposed in this architecture, the\
    \ Siemens \ntechnology, using two types of PLCs: the PLC 1214 and the PLC 1512\
    \ and an \nindustrial gateway IoT2040 which is the first in the Siemens market\
    \ and can \nexecute different tasks, as handling the data received from the PLCs\
    \ before \nsending it to the cloud or to other machines and systems.  \n \n \n\
    Figure 4.55. Hardware Setup \n \n \n134 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \nThe connected sensors are directly connected to the Siemens PLC 1214\
    \ to \nmonitor the wind status and send a command to the engine generator to change\
    \ \nthe direction of the blades in order to maximize the use of the system. \n\
    Furthermore, it permits the operation to be shut down in the event of a strong\
    \ \nwind flow. In parallel, power quality can be monitored and displayed using\
    \ the \nSENTRON PAC (3200), which delivers the important data for evaluating the\
    \ \nquality of an electrical network. All information received in the sensors\
    \ PLC 1214 \nis transmitted to the PLC 1512 using the industrial communication\
    \ standard \nPROFINET via Ethernet. \nThis solution allows to connect a legacy\
    \ network, presented by the old PLC \n1214 by using another powerful PLC 1512\
    \ with more capabilities to connect to \nanother network, which speaks more communication\
    \ protocols. The OPC \nUnified Architecture (UA) is an independent service-oriented\
    \ architecture that \nintegrates all the functionality of the individual OPC Classic\
    \ specifications into \nan extensible framework [255]. OPC UA is also a machine-to-machine\
    \ \ncommunication protocol, developed to create a reliable, secure, and interoperable\
    \ \ncommunication protocol. OPC-UA uses a client-server architecture, the servers\
    \ \nare applications that present information following the OPC-UA information\
    \ \nmodel, and the clients are applications that retrieve information from the\
    \ servers \nby reading and browsing the information model. In each server is defined\
    \ an \naddress space containing nodes of the OPC-UA model, these nodes represent\
    \ \nphysical objects or software [256]. the Siemens PLC 1512 comes with an OPC\
    \ UA \nserver implemented, which permits the communication with OPC UA clients\
    \ \nsuch as HMI panels, SCADA systems, etc. The OPC UA client is implemented in\
    \ \nthis application in the Siemens IOT2040 gateway, through the application Node-\n\
    RED that has a sample set of nodes that can be used for the communication \nbetween\
    \ different protocols and platforms. It is a programming tool for wiring \ntogether\
    \ hardware devices, APIs and online services, it is a solution to control \nflows\
    \ to be designed and managed graphically [257]. Figure 4.56 shows the setup \n\
    application and the different components from the wind sensors to the cloud \n\
    platform. \n \n \nFigure 4.56. Data flow between different systems and across\
    \ different protocols. \n \n \n \n135 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \nThe OPC UA client implemented in the UAExpert software can \ncommunicates\
    \ with the OPC UA server in the Siemens PLC, its role is to check \nand read all\
    \ the information related to the communication with the PLC, so as to \nshow the\
    \ information model of the UA server, such as labels, blocks, etc (Figure \n4.57).\
    \ This application needs to control the two variables of the speed sensor and\
    \ \nthe orientation sensor. UaExpert can read the NodeID of each variable, which\
    \ is \nthe most important ID used in Node-RED in order to be connected to the\
    \ PLC \nOPC UA server. \n \n \nFigure 4.57 . Checking OPC UA connection using\
    \ UaExpert Software \n \nWe implemented mainly four different nodes for each sensor,\
    \ in order to read \nthe data information from the PLC 1512 and then forward it\
    \ to the cloud for \nvisualization (Figure 4.58). In the first blue node (Inject\
    \ Node) we have \nintroduced the topic, used to connect with the variable Orientation\
    \ in the PLC, \nthis topic is also called Node-ID that can be taken from the software\
    \ UaExpert. \nWe then connected the Inject Node to the OPC UA Client Node that\
    \ has the \naddress of the PLC server to which we want to connect, and finally\
    \ we linked the \nIBM Watson IoT Node that has all the information about our variables\
    \ created in \nour IBM Bluemix cloud account. \n \n \n136 \n \nSmart IoT Monitoring\
    \ and Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \n \nFigure 4.58. Communication between the PLC 1512 and\
    \ IBM Cloud \nthrough OPC UA protocol using Node-RED installed the industrial\
    \ \nGateway IOT2040. \n \nC. Discussion and Results \n \n \nFigure 4.59. Dashboard\
    \ Data of wind Sensors in the IoT2040 Gateway \n \nAfter having all the information\
    \ about our sensors in the IoT2040 gateway \n(Figure 4.59), we have created an\
    \ account in IBM Bluemix, then we created a \ndevice in this account, which is\
    \ the IoT2040 gateway in order to connect it to the \nIBM Watson node in Node-RED.\
    \ IBM allows to create different boards, and for \neach board it is possible to\
    \ create cards that present your data and each data is a \nrepresentation for\
    \ your devices, sensors, actuators, or other. In the IBM Watson \nIoT Platform,\
    \ we created the board Wind-Energy, in order to present in a real-\ntime the two\
    \ wind sensors (Figure 4.60). \n \n \n137 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \n \nFigure 4.60 : Dashboard data wind sensors in the IBM Watson Platform\
    \ \n \n \n \n \n138 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \n \nCHAPTER\
    \ 5 \n \n-------------------------------------------------- \n \nConclusions and\
    \ Future Work \n \n \n \nThe lack of interoperability between Internet of Things\
    \ (IoT) devices \nsignificantly increases the complexity and cost of implementing\
    \ IoT and \nintegrating it into existing industrial systems and autonomous robots.\
    \ The quest \nfor seamless interoperability is further complicated by the long\
    \ lifespan of typical \nindustrial equipment, which requires costly upgrades or\
    \ replacements to support \nthe latest technologies. Integrating new and old technologies\
    \ into the IoT \npresents an interoperability challenge, as each IoT system has\
    \ its own \ncommunication protocol. In addition, a small error or delay beyond\
    \ the tolerated \nlimit could result in a disaster for various applications. IoT\
    \ gateways provide an \neffective solution for data communication, security and\
    \ manageability, and serve \nas a bridge between sensor networks and cloud services.\
    \ While the \nenvironmental specifications of each IoT gateway are crucial when\
    \ it comes to \napplications that require efficient computing performance. Cloud\
    \ services can \nhandle many cases efficiently, although latency is a major challenge\
    \ due to the \ninteraction between different systems. Unmanned vehicles (UVs)\
    \ now have great \npotential for many applications. At every stage of many surveillance\
    \ and tracking \nmissions using UVs, priority must be given to either accuracy\
    \ or latency. \nHowever, in some scenarios, stability of measurements and results\
    \ is difficult to \nensure, and certainty is far from guaranteed. Edge computing\
    \ topology reduces \nlatency to support IoT performance in low-bandwidth environments\
    \ and \nmitigates overall network congestion. Cloud computing topology improves\
    \ \naccuracy at the expense of increased latency. This proved crucial in deciding\
    \ the \nbest source of artificial intelligence to use to achieve the specified\
    \ goals at each \nstage in real time. \nAzure Custom Vision, Google cloud, and\
    \ IBM Watson services allow users \nto load a set of images and train them into\
    \ a custom AI model. However, to date, \n \n139 \n \nSmart IoT Monitoring and\
    \ Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \njust some of the cloud services allow trained AI models\
    \ to be exported in different \nformats (TensorFlow, Docker) specifically tailored\
    \ for devices, as opposed to the \ncloud. The model trained for use in the cloud\
    \ is different from the one trained for \nthe edge in terms of accuracy and response\
    \ time.  \nThe main contributions of this thesis are summarized in this chapter,\
    \ and the \neminent obtained results are discussed. Then, we emphasize the most\
    \ research \nlines that this thesis opens and can be considered as the future\
    \ works of the work \ndescribed in this report.  \n \n1. Contributions’ summary\
    \ \n \nThe main contributions of this thesis and the eminent results obtained\
    \ are \nsummarized. We highlight the most important research directions that this\
    \ thesis \nopens and that can be considered as future work of the work described\
    \ in this \nreport.  \nIn this thesis, different contributions are proposed to\
    \ address the issues of \nsupervision, interoperability, latency and detection\
    \ accuracy for object tracking.  \nThese contributions can be grouped into four\
    \ main axes. The first one, an \ninteroperable architecture and reliable real-time\
    \ communication have been \nproposed to improve the production process of a concrete\
    \ plant. In the second, \nan AUV model system designed to track a Mediterranean\
    \ fan mussel species, \nusing cloud services with edge computing as alternative\
    \ processing units. In the \nthird line, we propose an intelligent algorithm to\
    \ optimize the autonomy of an \nautonomous marine robot by selecting the appropriate\
    \ AI technology for \nprotection and continuous monitoring in marine protected\
    \ areas. Finally, In the \nfourth, the line focuses on proposing an IoT solution\
    \ to supervise in real time a \nwind system in the cloud. \nIn the first part\
    \ of this thesis, we have introduced a model designed to \nmonitor the smart industrial\
    \ Internet of things based on an unmanned aerial \nvehicle, leveraging cloud computing\
    \ services and using fog computing as a \nbridge between the different IIoT layers.\
    \  \n \n• The proposed model can monitor the condition of a concrete plant \n\
    production line and the condition of the materials transported on \nconveyor belts\
    \ to control the process.  \n• The results reveal the effectiveness of integrating\
    \ drones with deep \nlearning cloud services for processing and analyzing photos\
    \ acquired in \nreal-time.  \n• We demonstrate how to overcome the challenge of\
    \ interoperability using \nfog and Node-RED computation on the IoT gateway.  \n\
    • Node-RED interacts simultaneously with the different systems involved \nthrough\
    \ different protocols. \n \n140 \n \nSmart IoT Monitoring and Real-Time Control\
    \ Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \n• The period of time available to the control system to decide and adjust\
    \ the \nformula is assessed and estimated, depending on the quantity ordered by\
    \ \nthe customer and the composition of the formula. Given these points, the \n\
    overall latency of the proposed solution is acceptable for plant control \ndecisions.\
    \ \n• The Siemens IoT gateway S-G is expected to provide better performance \n\
    in an industrial setting, although it has less capacity than Raspberry \ngateway\
    \ RPI-G.  \n• The second work outlines an AUV model system designed to track a\
    \ \nMediterranean fan mussel species, using cloud services with edge \ncomputing\
    \ as alternative processing units. \n• An innovative algorithm was proposed to\
    \ autonomously track the target \nspecies without human intervention by integrating\
    \ the object detection \nsystem into the AUV control loop. \n• The proposed model\
    \ is capable of detecting, tracking and georeferencing \nspecimens with IUNO software.\
    \ \n• The obtained results highlight the system’s effectiveness and feature the\
    \ \nasset of combining an AUV with deep learning cloud services for \nprocessing\
    \ and analyzing photos.  \n• Although cloud-based architecture automatically distributes\
    \ and balances \nprocessing loads, we overcame latency challenges in the tracking\
    \ process \nby using edge computing in the IoT gateway.  \n• The IoT gateway installed\
    \ in the AUV replaces the cloud processing unit \nby virtue of the interaction\
    \ between the different AUV components. We \nintegrated cloud-based ML services\
    \ into the AUV system to achieve a \ncompletely autonomous pre-programmed search\
    \ mission with relevant \naccuracy.  \n• Furthermore, with the aim of ensuring\
    \ that data is transferred, processed \nand returned at speeds that meet the needs\
    \ of the application, the two \nobject detection services were implemented in\
    \ the cloud and compared in \nterms of latency and accuracy.  \n• The obtained\
    \ experimental results clearly justify the proposed hybrid \ncloud/edge architecture\
    \ and highlight the combination of the system \nperformances that ensure a real-time\
    \ control loop for relevant latency and \naccuracy. \n• Addressing system requirements,\
    \ lower latency and improved cloud \naccuracy, our solution on AUV servo control\
    \ ensures a balance between \nperformance and stability. The hybrid cloud/edge\
    \ architecture is therefore \nrecommended to ensure a real-time control loop and\
    \ achieve consistent \nresults.  \n \n \n141 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \nIn the third part, we have presented an autonomous marine robot for\
    \ \ncontinuous protection and surveillance of marine protected areas based on\
    \ AI \nrecognition.  \n \n• The robot was designed to survey and inspect marine\
    \ reserves using AI-\nbased image recognition services, looking for vessels conducting\
    \ \nsuspicious activities. \n• Azure cloud computing and Azure edge computing\
    \ services were used \nfor image analysis, each with their own advantages and\
    \ disadvantages, \nmainly related to accuracy and latency.  \n• To meet the system\
    \ requirements, we proposed and developed an \nintelligent algorithm to optimize\
    \ the autonomy by selecting the \nappropriate AI technology for the monitored\
    \ scenario.  \n• The proposed intelligent algorithm (SAAO) provides a trade-off\
    \ between \nlatency and accuracy. \n \nIn the fourth part of this thesis, we have\
    \ performed a control system using a \nsmart IoT gateway to create a connection\
    \ between an industrial case and the \ncloud.  \n \n• We have provided a solution\
    \ for a wind energy system in order to \nvisualize in a real-time and remotely\
    \ the different components and devices \ninside a wind turbine control system.\
    \  \n• We proposed, the IOT2040 gateway from Siemens, and we have installed, \n\
    several tools that helped us connect our device’s information.  \n• It is simple\
    \ to connect each sensor information of the wind turbine to the \ncloud by using\
    \ the tool Node-RED, and through different communication \nprotocols like OPC\
    \ UA. This solution can really ease the control system of \nwind energy, by collecting,\
    \ saving and communicating relevant data in \nreal-time.  \n• With the help of\
    \ an IoT gateway, analyzed data can be transferred from \nthe cloud to the control\
    \ system and to the devices. \n \n2. Future Works  \n \nThe research conducted\
    \ in this thesis can be extended in future work. Below \nwe present most of the\
    \ possible future contributions: \n \n• Introducing new devices into drones, so\
    \ that they can not only track \nobjects but also interact with them. \n• Introducing\
    \ swarm of drones connected as IOT-drone device and \ncoordinated to perform swarm\
    \ operations. \n \n142 \n \nSmart IoT Monitoring and Real-Time Control Based On\
    \ Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services \n\
    • New technologies can be implemented in drones to track and catch \ndetected\
    \ objects. \n• More research is needed in terms of accuracy when tracking a moving\
    \ \nobject. \n \n \n \n \n143 \n \nSmart IoT Monitoring and Real-Time Control\
    \ Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \n \nReferences \n \n \n \n1- \nG. Miragliotta, A. Perego, and A. Tumino, “Internet\
    \ of Things: Smart Present or Smart Future?” \nItaly, 2012.  \n2- \nStatista.\
    \ IoT: Number of Connected Devices Worldwide 2012–2025; Statista: Hamburg, Germany,\
    \ \n2019. \n3- \nH. Kagermann, W. Wahlster, and J. Helbig, “Recommendations for\
    \ implementing the strategic \ninitiative INDUSTRIE 4.0,” 2013. \n4- \n25. A.\
    \ Azevedo and A. Almeida, “Factory Templates for Digital Factories Framework,”\
    \ Robot. \nComput. Integr. Manuf., vol. 27, no. 4, pp. 755–771, Aug. 2011. \n\
    5- \n46. \nT. Hafeez, L. Xu and G. Mcardle, \"Edge Intelligence for Data Handling\
    \ and Predictive \nMaintenance \nin \nIIOT,\" \nin \nIEEE \nAccess, \nvol. \n\
    9, \npp. \n49355-49371, \n2021, \ndoi: \n10.1109/ACCESS.2021.3069137. \n6- \n\
    Molina-Molina, J.C.; Salhaoui, M.; Guerrero-González, A.; Arioua, M. Autonomous\
    \ Marine Robot \nBased on AI Recognition for Permanent Surveillance in Marine\
    \ Protected Areas. Sensors 2021, 21, \n2664. https://doi.org/10.3390/s21082664\
    \ \n7- \nZhou, Z.; Chen, X.; Li, E.; Zeng, L.; Luo, K.; Zhang, J. Edge Intelligence:\
    \ Paving the Last Mile of \nArtificial Intelligence with Edge Computing. Proc.\
    \ IEEE 2019, 107.  \n8- \nSikeridis, D.; Papapanagiotou, I.; Rimal, B.P.; Devetsikiotis,\
    \ M. A Comparative Taxonomy and Survey \nof Public Cloud Infrastructure Vendors.\
    \ arXiv 2018, arXiv:1710.01476v2. \n9- \nY. Zhong, Xun Xu, Eberhard Klotz, Stephen\
    \ T. Newman. Intelligent Manufacturing in the Context \nof Industry 4.0: A Review.\
    \ Elservier, https://doi.org/10.1016/J.ENG.2017.05.015 \n10- \nK. \nKritayakirana\
    \ \nand \nJ. \nC. \nGerdes, “Autonomous \nvehicle \ncontrol \natthe \nlimits \n\
    of \nhandling,”International Journal of Vehicle AutonomousSystems, vol. 10, no.\
    \ 4, pp. 271–296, 2012. \n11- \nS. E.Collier, “The emerging enernet: Convergence\
    \ of the smart grid with the internet of things”, \nIEEE Industry Applications\
    \ Magazine, 23(2), 12-16, 2016. \n12- \nCarvalho O., Garcia M., Roloff E., Carreño\
    \ E.D., Navaux P.O.A. (2018) IoT Workload Distribution \nImpact Between Edge and\
    \ Cloud Computing in a Smart Grid Application. In: Mocskos E., \nNesmachnow S.\
    \ (eds) High Performance Computing. CARLA 2017. Communications in Computer \n\
    and Information Science, vol 796. Springer, Cham. https://doi.org/10.1007/978-3-319-73353-1_14\
    \ \n13- \nS. Marstijepovic and S. Williams, \"Environmental monitoring and field\
    \ surveillance reference \nguide.pdf\". \n14- \nXu, G.; Shi, Y.; Sun, X.; Shen,\
    \ W. Internet of Things in Marine Environment Monitoring: A Review. \nSensors\
    \ 2019, 19, 1711. https://doi.org/10.3390/s19071711 \n15- \nC. Perera, A. Zaslavsky,\
    \ P. Christen, & D. Georgakopoulos, “Sensing as a service model for smart \ncities\
    \ supported by internet of things”, Transactions on Emerging Telecommunications\
    \ \nTechnologies, 25(1), 81-93, 2014. \n16- \nAkhtar, M.N.; Shaikh, A.J.; Khan,\
    \ A.; Awais, H.; Bakar, E.A.; Othman, A.R. Smart Sensing with Edge \nComputing\
    \ in Precision Agriculture for Soil Assessment and Heavy Metal Monitoring: A Review.\
    \ \nAgriculture 2021, 11, 475. https://doi.org/10.3390/agriculture11060475 \n\
    17- \nL. R. Stojkoska, &K. V. Trivodaliev, “A review of Internet of Things for\
    \ smart home: Challenges and \nsolutions”, Journal of Cleaner Production, 140,\
    \ 1454-1464, 2017. \n18- \nR. Sfar, E. Natalizio, Y. Challal, &Z. Chtourou, “A\
    \ roadmap for security challenges in the Internet of \nThings”, Digital Communications\
    \ and Networks, 118-137, 2018. \n19- \nM. Soliman, T. Abiodun, T. Hamouda, J.\
    \ Zhou, & C. H. Lung, “Smart home: Integrating internet of \nthings with web services\
    \ and cloud computing”, In Cloud Computing Technology and Science \n(CloudCom),\
    \ 2013 IEEE 5th International Conference on (Vol. 2, pp. 317-320). 2013. \n \n\
    144 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots,\
    \ Visual Recognition and Cloud/Edge \nComputing Services \n20- \nD. Miorandi,\
    \ S. Sicari, F. De Pellegrini, & I. Chlamtac, “Internet of things: Vision, applications\
    \ and \nresearch challenges”, Ad Hoc Networks, 10(7), 1497-1516, 2012. \n21- \n\
    F. Firouzi, A. M. Rahmani, K. Mankodiya, M. Badaroglu, G. V. Merrett, P. Wong,\
    \ & B. Farahani, \n“Internet-of-Things and big data for smarter healthcare: from\
    \ device to architecture, applications \nand analytics”, 2018. \n22- \nS. K.Dash,\
    \ J. P. Sahoo, S. Mohapatra, & S. P. Patil,“Sensor-cloud: assimilation of wireless\
    \ sensor \nnetwork and the cloud”, Advances in Computer Science and Information\
    \ Technology. Networks \nand Communications, 455-464, 2012. \n23- \nL. Atzori,\
    \ A. Iera, and G. Morabito, “The Internet of Things: A survey,” Comput. Netw.,\
    \ vol. 54, no. \n15, pp. 2787–2805, Oct. 2010. \n24- \nM. Kavre, A. Gadekar and\
    \ Y. Gadhade, \"Internet of Things (IoT): A Survey,\" 2019 IEEE Pune Section \n\
    International Conference (PuneCon), 2019, pp. 1-6, doi: 10.1109/PuneCon46936.2019.9105831.\
    \ \n25- \nEdge Computing Task Group.Introduction to Edge Computing in IIoT.Accessed:\
    \ Aug. 2, 2021. \n[Online]. \nAvailable: \nhttps://www.iiconsortium.org/pdf/Introduction_to_Edge_Computing_in_IIoT%_2018-06-18.pdf\
    \ \n26- \nLi, L. Lyu, X. Liu, X. Zhang, and X. Lyu, ‘‘FLEAM: A federated learn-ing\
    \ empowered architecture to \nmitigate \nDDoS \nin \nindustrial \nIoT,’’ \n2020,\
    \ \narXiv:2012.06150. \n[Online]. \nAvailable: \nhttp://arxiv.org/abs/2012.06150\
    \ \n27- \nDong, G. Qin, and H. Tian, ‘‘Enhancing data monitoring scheme based\
    \ on reinforcement learning \nin IIoT systems,’’ inProc. 12th Int. Conf.Commun.\
    \ Softw. Netw. (ICCSN), Jun. 2020, pp. 69–72. \n28- \nF. Wang, M. Zhang, X. Wang,\
    \ X. Ma, and J. Liu, ‘‘Deep learning for edgecomputing applications: A \nstate-of-the-art\
    \ survey,’’IEEE Access, vol. 8, pp. 58322–58336, 2020 \n29- \nChen, J. Wan, Y.\
    \ Lan, M. Imran, D. Li, and N. Guizani, ‘‘Improvingcognitive ability of edge intelligent\
    \ \nIIoT through machine learning,’’IEEE Netw., vol. 33, no. 5, pp. 61–67, Sep.\
    \ 2019. \n30- \nI. Yaqoob, E. Ahmed, I. A. T. Hashem, A. I. A. Ahmed, A. Gani,\
    \ M. Imran & M. Guizani, “Internet of \nthings architecture: Recent advances,\
    \ taxonomy, requirements, and open challenges”, IEEE \nwireless communications,\
    \ 24(3), 10-16, 2017. \n31- \nM. Diaz, C. Martín, & B. Rubio, “State-of-the-art,\
    \ challenges, and open issues in the integration of \nInternet of things and cloud\
    \ computing”, Journal of Network and Computer Applications, 67, 99-\n117, 2016.\
    \ \n32- \nL. R. Stojkoska, &K. V. Trivodaliev, “A review of Internet of Things\
    \ for smart home: Challenges and \nsolutions”, Journal of Cleaner Production,\
    \ 140, 1454-1464, 2017. \n33- \nLa, Quang Duy. Ngo, Mao V. Dinh, Thinh Quang.\
    \ Quek, Tony Q.S. Shin, Hyundong. Enabling \nintelligence in fog computing to\
    \ achieve energy and latency reduction. Digital Communications \nand Networks.\
    \ https://doi.org/10.1016/j.dcan.2018.10.008 \n34- \nDong, G. Qin, and H. Tian,\
    \ ‘‘Enhancing data monitoring scheme based on reinforcement learning \nin IIoT\
    \ systems,’’ in Proc. 12th Int. Conf.Commun. Softw. Netw. (ICCSN), Jun. 2020,\
    \ pp. 69–72. \n35- \nD. Xu and L. Duan, ‘‘Big data for cyber physical systems\
    \ in indus-try 4.0: A survey,’’Enterprise Inf. \nSyst., vol. 13, no. 2, pp. 148–169,\
    \ Feb. 2019. \n36- \nS. E.Collier, “The emerging enernet: Convergence of the smart\
    \ grid with the internet of things”, \nIEEE Industry Applications Magazine, 23(2),\
    \ 12-16, 2016. \n37- \nA. C. Panchal, V. M. Khadse and P. N. Mahalle, \"Security\
    \ Issues in IIoT: A Comprehensive Survey of \nAttacks on IIoT and Its Countermeasures,\"\
    \ 2018 IEEE Global Conference on Wireless Computing \nand Networking (GCWCN),\
    \ 2018, pp. 124-130, doi: 10.1109/GCWCN.2018.8668630. \n38- \nE. Sisinni, A. Saifullah,\
    \ S. Han, U. Jennehag, and M. Gidlund,“Industrial Internet of Things: \nChallenges,\
    \ opportunities, and direc-tions,”IEEE Trans. Ind. Informat., vol. 14, no. 11,\
    \ pp. 4724–\n4734,Nov. 2018. \n39- \nN. L. Tsilias, “Open Innovation and Interoperability,”\
    \ inOpening standards: The global politics of \ninteroperability,L. DeNardis,\
    \ Ed. Cambridge, MA, USA: MIT Press, 2011,pp. 97–117. \n40- \nFerrari, P.; Flammini,\
    \ A.; Rinaldi, S.; Sisinni, E.; Malara, D.M.M. Impact of Quality of Service on\
    \ Cloud \nBased Industrial IoT Applications with OPC UA. Electronics 2018, 7,\
    \ 109. \n41- \nForsstrom, S.; Jennehag, U. A performance and cost evaluation of\
    \ combining OPC-UA and \nMicrosoft Azure IoT Hub into an industrial Internet-of-Things\
    \ system. In the Proceedings of the \n2017 Global Internet of Things Summit (GIoTS),\
    \ Geneva, Switzerland, 6–9 June 2017; pp. 1–6. \n42- \nG. Hatzivasilis, I. G.\
    \ Askoxylakis, G. Alexandris, D. Anicic,A. Br ̈oring, V. Kulkarni, K. Fysarakis,\
    \ and G. \nSpanoudakis,“The Interoperability of Things: Interoperable solutions\
    \ as an enabler for IoT and \nWeb 3.0,” in23rd IEEE International Workshop on\
    \ Computer Aided Modeling and Design of \nCommunication Links and Networks, CAMAD\
    \ 2018, Barcelona, Spain, September 2018, pp. 1–7. \n \n145 \n \nSmart IoT Monitoring\
    \ and Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \n43- \nMonostori, L.; Kádár, B.; Bauernhansl, T.; Kondoh,\
    \ S.; Kumara, S.; Reinhart, G.; Sauer, O.; Schuh, G.; \nSihn, W.; Ueda, K. Cyber-physical\
    \ systems in manufacturing. CIRP Ann. 2016, 65, 621–641. \n44- \nX. Zuo, Y. Cui,\
    \ M. Wang, T. Xiao, and X. Wang, “Low-latencynetworking: Architecture, techniques,\
    \ \nand opportunities,”IEEE InternetComput., vol. 22, no. 5, pp. 56–63, 2018.\
    \ \n45- \nM. Bennis, M. Debbah, and H. V. Poor, “Ultrareliable and Low-latencyWireless\
    \ Communication: \nTail, risk, and scale,”Proceedings of theIEEE, vol. 106, no.\
    \ 10, pp. 1834–1853, 2018 \n46- \nKang, J. Hauswald, C. Gaoet al., “Neurosurgeon:\
    \ CollaborativeIntelligence Between the Cloud and \nMobile Edge,” inProc. 22nd\
    \ Int.Conf. Archit. Support Program. Lang. Oper. Syst. (ASPLOS \n2017),2017, pp.\
    \ 615–629. \n47- \nXiaofei Wang, Senior Member, IEEE, Yiwen Han, Student Member,\
    \ IEEE, Victor C.M. Leung, Fellow, \nIEEE, Dusit Niyato,Fellow, IEEE, Xueqiang\
    \ Yan, Xu Chen, Member, IEEE. Convergence of Edge \nComputing and Deep Learning:\
    \ A Comprehensive Survey. arXiv:1907.08349v3 [cs.NI]  28 Jan 2020 \n48- \nZ. Li,\
    \ J. Kang, R. Yu, D. Ye, Q. Deng, and Y. Zhang, “ConsortiumBlockchain for Secure\
    \ Energy trading \nin Industrial Internet of Things,”IEEE Trans. Ind. Informat.,\
    \ vol. 14, no. 8, pp. 3690–3700, 2017. \n49- \nAlsamhi, S. H., Ma, O., and Ansari,\
    \ M. S. (2019b). Survey on artificial intelligence-based techniques \nfor emerging\
    \ robotic communication. Telecommun. Syst. 72, 483–503. doi: 10.1007/s11235-019-\n\
    00561-z \n50- \nLarrauri, J.I.; Sorrosal, G.; Gonzalez, M. Automatic system for\
    \ overhead power line inspection using \nan unmanned aerial vehicle RELIFO project.\
    \ In Proceedings of the International Conference on \nUnmanned Aircraft Systems\
    \ (ICUAS), Atlanta, GA, USA, 28–31 May 2013; pp. 244–252. \n51- \nKim, H.; Lee,\
    \ J.; Ahn, E.; Cho, S.; Shin, M.; Sim, S.-H. Concrete Crack Identification Using\
    \ a UAV \nIncorporating Hybrid Image Processing. Sensors 2017, 17, 2052.  \n52-\
    \ \nGeneration and Processing of Simulated Underwater Images for Infrastructure\
    \ Visual Inspection \nwith UUVs. Sensors 2019, 19, 5497.  \n53- \nBao, J.; Li,\
    \ D.; Qiao, X.; Rauschenbach, T. Integrated navigation for autonomous underwater\
    \ \nvehicles in aquaculture: A review. Inf. Process. Agric. 2020, 7, 139–151.\
    \  \n54- \nBarrett, N.; Seiler, J.; Anderson, T.; Williams, S.; Nichol, S.; Hill,\
    \ N. Autonomous Underwater Vehicle \n(AUV) for mapping marine biodiversity in\
    \ coastal and shelf waters: Implications for Marine \nManagement. In Proceedings\
    \ of the OCEANS’10 IEEE Conference, Sydney, Australia, 24−27 May \n2010. \n55-\
    \ \nWynn, R.B.; Huvenne, V.A.I.; le Bas, T.P.; Murton, B.; Connelly, D.P.; Bett,\
    \ B.J.; Ruhl, H.A.; Morris, K.J.; \nPeakall, J.; Parsons, D.R.; et al. Autonomous\
    \ Underwater Vehicles (AUVs): Their past, present and \nfuture contributions to\
    \ the advancement of marine geoscience. Mar. Geol. 2014.  \n56- \nCorgnati, L.;\
    \ Marini, S.; Mazzei, L.; Ottaviani, E.; Aliani, S.; Conversi, A.; Griffa, A.\
    \ Looking inside the \nOcean: Toward an Autonomous Imaging System for Monitoring\
    \ Gelatinous Zooplankton. Sensors \n2016, 16, 2124. \n57- \nLiu, S.; Xu, H.; Lin,\
    \ Y.; Gao, L. Visual Navigation for Recovering an AUV by Another AUV in Shallow\
    \ \nWater. Sensors 2019, 19, 1889.  \n58- \nJorge, V.A.M.; Granada, R.; Maidana,\
    \ R.G.; Jurak, D.A.; Heck, G.; Negreiros, A.P.F.; Dos Santos, D.H.; \nGonçalves,\
    \ L.M.G.; Amory, A.M. A Survey on Unmanned Surface Vehicles for Disaster Robotics:\
    \ \nMain Challenges and Directions. Sensors 2019, 19, 702. \n59- \nNuţă, I.; Orban,\
    \ O.; Grigore, L. Development and Improvement of Technology in Emergency \nResponse.\
    \ Procedia Econ. Financ. 2015, 32, 603–609. \n60- \nBellingham, J.G.; Rajan, K.\
    \ Robotics in Remote and Hostile Environments. Science 2007, 318, 1098–\n1102.\
    \ \n61- \nMarques, F.; Lourenço, A.; Mendonça, R.; Pinto, E.; Rodrigues, P.; Santana,\
    \ P.; Barata, J. A critical \nsurvey on marsupial robotic teams for environmental\
    \ monitoring of water bodies. In Proceedings \nof the OCEANS 2015, Genova, Italy,\
    \ 19–22 October 2015; pp. 1–6. \n62- \nColey, K. Unmanned Surface Vehicles: The\
    \ Future of Data-Collection. Ocean. Chall. 2015, 21, 14–\n15. \n63- \nMoysiadis,\
    \ V.; Sarigiannidis, P.; Moscholios, I. Towards Distributed Data Management in\
    \ Fog \nComputing. Wirel. Commun. Mob. Comput. 2018, 2018. [Google Scholar] [CrossRef]\
    \ \n64- \nG. Plastiras, M. Terzi, C. Kyrkou and T. Theocharidcs, \"Edge Intelligence:\
    \ Challenges and \nOpportunities of Near-Sensor Machine Learning Applications,\"\
    \ 2018 IEEE 29th International \nConference on Application-specific Systems, Architectures\
    \ and Processors (ASAP), 2018, pp. 1-7, \ndoi: 10.1109/ASAP.2018.8445118. \n \n\
    146 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots,\
    \ Visual Recognition and Cloud/Edge \nComputing Services \n65- \n Miorandi, D.\
    \ ; Sicari, S.; De Pellegrini, F.; Chlamtac, I. Internet of Things. Ad Hoc Netw.2012,10,\
    \ \n1497–1516.  \n66- \nXu, L.D. Enterprise systems: State-of-the-art and future\
    \ trends. IEEE Trans. Ind. Informat.2011,7, \n630–640. \n67- \nLombardi, M.; Pascale,\
    \ F.; Santaniello, D. Internet of Things: A General Overview between \nArchitectures,\
    \ Protocols and Applications. Information 2021, 12, 87.  \n68- \nNgu, A.H.H.;\
    \ Gutierrez, M.; Metsis, V.; Nepal, S.; Sheng, M.Z. Iot middleware: A survey on\
    \ issues \nand enabling technologies. IEEE Internet Things J.2016,4, 1.  \n69-\
    \ \nSalhaoui, M.; Guerrero-Gonzalez, A.; Arioua, M.; Ortiz, F.J.; El Oualkadi,\
    \ A.; Torregrosa, C.L. Smart \nindustrial iot monitoring and control system based\
    \ on UAV and cloud computing applied to a \nconcrete plant. Sensors 2019, 19,\
    \ 3316.  \n70- \nFerrández-Pastor, F.J.; García-Chamizo, J.M.; Nieto-Hidalgo,\
    \ M.; Mora-Pascual, J.; Mora-Martínez, \nJ. Developing Ubiquitous Sensor Network\
    \ Platform Using Internet of Things: Application in \nPrecision Agriculture. Sensors\
    \ 2016, 1141. \n71- \nNavet, N.; Simonot-Lion, F.; Delong, C. In-Vehicle Communication\
    \ Networks: A Historical \nPerspective and Review; Apple Academic Press: Palm\
    \ Bay, FL, USA, 2017; pp. 50–51. \n72- \n[33] Colakovi ́c, A.; Hadžiali ́c, M.\
    \ Internet of Things (IoT): A review of enabling technologies, \nchallenges, and\
    \ open research issues.Comput. Netw.2018,144, 17–39.  \n73- \nFerrari, P.; Flammini,\
    \ A.; Rinaldi, S.; Sisinni, E.; Malara, D.M.M. Impact of Quality of Service on\
    \ Cloud \nBased Industrial IoT Applications with OPC UA. Electronics 2018, 7,\
    \ 109.  \n74- \nForsstrom, S.; Jennehag, U. A performance and cost evaluation\
    \ of combining OPC-UA and \nMicrosoft Azure IoT Hub into an industrial Internet-of-Things\
    \ system. In the Proceedings of the \n2017 Global Internet of Things Summit (GIoTS),\
    \ Geneva, Switzerland, 6–9 June 2017; pp. 1–6.  \n75- \nJaloudi, S. Communication\
    \ Protocols of an Industrial Internet of Things Environment: A \nComparative Study.\
    \ Future Internet 2019, 11, 66. \n76- \nTrancă, D.-C.; Pălăcean, A.V.; Mihu, A.C.;\
    \ Rosner, D. ZigBee based wireless modbus aggregator for \nintelligent industrial\
    \ facilities. In Proceedings of the IEEE 25th Telecommunication Forum, \nBelgrade,\
    \ Serbia, 21–22 November 2017.  \n77- \nTariq, M.A.; Khan, M.; Raza Khan, M.T.;\
    \ Kim, D. Enhancements and Challenges in CoAP—A Survey. \nSensors 2020, 20, 6391.\
    \  \n78- \nKäbisch, S.; Peintner, D. W3C Recommendation Canonical EXI. 2018. Available\
    \ online: \nhttps://www.w3.org/TR/exi-c14n/ (accessed on 4 February 2019). \n\
    79- \nCavalieri, S.; Stefano, D.D.; Salafia, M.G.; Scroppo, M.S. A web-based platform\
    \ for OPC UA \nintegration in IIoT environment. In Proceedings of the 2017 22nd\
    \ IEEE International Conference \non Emerging Technologies and Factory Automation\
    \ (ETFA), Limassol, Cyprus, 12–15 September \n2017; pp. 1–6. \n80- \nCavalieri,\
    \ S.; Chiacchio, F. Analysis of OPC UA performances. Comput. Stand. Interfaces\
    \ 2013, 36, \n165–177.  \n81- \nGu, Xiaohui et al. “Energy-Optimal Latency-Constrained\
    \ Application Offloading in Mobile-Edge \nComputing.” Sensors (Basel, Switzerland)\
    \ vol. 20,11 3064. 28 May. 2020, doi:10.3390/s20113064 \n82- \nNetguru. Available\
    \ online: https://www.netguru.com/blog/why-is-python-good-for-research-\nbenefits-of-the-programming-language\
    \ (accessed on 3 May 2020). \n83- \nChen, S.; Xu, H.; Liu, D.; Hu, B.; Wang, H.\
    \ A Vision of IoT: Applications, Challenges, and \nOpportunities with China Perspective.\
    \ IEEE Internet Things J. 2014, 1.  \n84- \nSuárez-Albela, M.; Fernández-Caramés,\
    \ T.M.; Fraga-Lamas, P.; Castedo, L. A Practical Evaluation of \na High-Security\
    \ Energy-Efficient Gateway for IoT Fog Computing Applications. Sensors 2017, 17,\
    \ \n1978. [ \n85- \nFerrández-Pastor, F.J.; García-Chamizo, J.M.; Nieto-Hidalgo,\
    \ M.; Mora-Pascual, J.; Mora-Martínez, \nJ. Developing Ubiquitous Sensor Network\
    \ Platform Using Internet of Things: Application in \nPrecision Agriculture. Sensors\
    \ 2016, 1141.  \n86- \nGutiérrez, C.S.V.; Juan, L.U.S.; Ugarte, I.Z.; Vilches,\
    \ V.M. Time-Sensitive networking for \nrobotics. arXiv 2018, arXiv:1804.07643v2.\
    \  \n87- \nForsstrom, S.; Jennehag, U. A performance and cost evaluation of combining\
    \ OPC-UA and \nMicrosoft Azure IoT Hub into an industrial Internet-of-Things system.\
    \ In the Proceedings of the \n2017 Global Internet of Things Summit (GIoTS), Geneva,\
    \ Switzerland, 6–9 June 2017; pp. 1–6. \n88- \nOPC Foundation. Available online:\
    \ https://opcfoundation.org/about/opc-technologies/opc-\nua/ (accessed on 14 September\
    \ 2018). \n \n147 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \n89- \nGirbea,\
    \ A.; Suciu, C.; Nechifor, S.; Sisak, F. Design and implementation of a service-oriented\
    \ \narchitecture for the optimization of industrial applications. IEEE Trans.\
    \ Ind. Inform. 2014, 10, 185–\n196. \n90- \nChen, B.; Wan, J.; Shu, L.; Li, P.;\
    \ Mukherjee, M.; Yin, B. Smart Factory of Industry 4.0: Key \nTechnologies, Application\
    \ Case, and Challenges. IEEE Access 2017, 6, 6505–6519 \n91- \nJaloudi, S. Communication\
    \ Protocols of an Industrial Internet of Things Environment: A \nComparative Study.\
    \ Futur. Internet 2019, 11, 66. \n92- \nRay, P.P. A Survey on Visual Programming\
    \ Languages in Internet of Things. Sci. \nProgram. 2017, 2017, 1231430.  \n93-\
    \ \nBröring, A.; Seeger, J.; Papoutsakis, M.; Fysarakis, K.; Caracalli, A. Networking-Aware\
    \ IoT Application \nDevelopment. Sensors 2020, 20, 897. https://doi.org/10.3390/s20030897\
    \ \n94- \nChris Simpkin, Ian Taylor, Daniel Harborne, Graham Bent, Alun Preece,\
    \ Raghu K. Ganti, Efficient \norchestration of Node-RED IoT workflows using a\
    \ Vector Symbolic Architecture, Future \nGeneration Computer Systems, Elsevier,\
    \ Volume 111, 2020, Pages 117-131, ISSN 0167-\n739X,https://doi.org/10.1016/j.future.2020.04.005.\
    \ \n95- \nYasumoto, K.; Yamaguchi, H.; Shigeno, H. Survey of Real-time Processing\
    \ Technologies of IoT \nData Streams. J. Inf. Process. 2016, 24, 195–202.  \n\
    96- \nFernández-Caramés, T.M.; Fraga-Lamas, P. A Review on Human-Centered IoT-Connected\
    \ Smart \nLabels for the Industry 4.0. IEEE Access 2017, 6, 25939–25957.  \n97-\
    \ \nWan, J.; Tang, S.; Yan, H.; Li, D.; Wang, S.; Vasilakos, A.V. Cloud Robotics:\
    \ Current Status and \nOpen Issues. IEEE Access 2016, 4, 2797–2807.  \n98- \n\
    Robla-Gömez, S.; Becerra, V.M.; Llata, J.R.; González-Sarabia, E.; Ferrero, C.T.;\
    \ Pérez-Oria, J. \n‘Working together: A review on safe human-robot collaboration\
    \ in industrial environments. IEEE \nAccess 2017, 5, 26754–26773.  \n99- \nKoch,\
    \ P.J.; van Amstel, M.; Dębska, P.; Thormann, M.A.; Tetzlaff, A.J.; Bøgh, S.;\
    \ Chrysostomou, D. A \nSkill-based Robot Co-worker for Industrial Maintenance\
    \ Tasks. In Proceedings of the 27th \nInternational Conference on Flexible Automation\
    \ and Intelligent Manufacturing (FAIM 2017), \nModena, Italy, 27–30 June 2017.\
    \  \n100- \nAndreasson, H.; Bouguerra, A.; Cirillo, M.; Dimitrov, D.N.; Driankov,\
    \ D.; Karlsson, L.; Lilienthal, A.J.; \nPecora, F.; Saarinen, J.P.; Sherikov,\
    \ A.; et al. Autonomous transport vehicles: Where we are and \nwhat is missing.\
    \ IEEE Robot. Autom. Mag. 2015, 22, 64–75.] \n101- \nAlsamhi, S.H.; Ma, O.; Ansari,\
    \ M.S.; Gupta, S.K. Collaboration of Drone and Internet of Public \nSafety Things\
    \ in Smart Cities: An Overview of QoS and Network Performance \nOptimization.\
    \ Drones 2019, 3, 13.  \n102- \nSoorki, M.N.; Mozaffari, M.; Saad, W.; Manshaei,\
    \ M.H.; Saidi, H. Resource Allocation for Machine-\nto-Machine Communications\
    \ with Unmanned Aerial Vehicles. In Proceedings of the 2016 IEEE \nGlobecom Workshops\
    \ (GC Wkshps), Washington, DC, USA, 4–8 December 2016; pp. 1–6.  \n103- \nLarrauri,\
    \ J.I.; Sorrosal, G.; Gonzalez, M. Automatic system for overhead power line inspection\
    \ using \nan unmanned aerial vehicle RELIFO project. In Proceedings of the International\
    \ Conference on \nUnmanned Aircraft Systems (ICUAS), Atlanta, GA, USA, 28–31 May\
    \ 2013; pp. 244–252.  \n104- \nKim, H.; Lee, J.; Ahn, E.; Cho, S.; Shin, M.; Sim,\
    \ S.-H. Concrete Crack Identification Using a UAV \nIncorporating Hybrid Image\
    \ Processing. Sensors 2017, 17, 2052. \n105- \nArroyo, J.A.; Gomez-Castaneda,\
    \ C.; Ruiz, E.; de Cote, E.M.; Gavi, F.; Sucar, L.E. UAV Technology and \nMachine\
    \ Learning Techniques applied to the Yield Improvement in Precision Agriculture.\
    \ In \nProceedings of the IEEE Mexican Humanitarian Technology Conference (MHTC),\
    \ Puebla, Mexico, \n29–31 March 2017.  \n106- \nSingh, A.; Patil, D.; Omkar, S.N.\
    \ Eye in the Sky: Real-time Drone Surveillance System (DSS) for \nViolent Individuals\
    \ Identification using ScatterNet Hybrid Deep Learning Network. In Proceedings\
    \ \nof the IEEE Computer Vision and Pattern Recognition (CVPR) Workshops, Salt\
    \ Lake City, UT, USA, \n18–22 June 2018.  \n107- \nManohar, A.; Sneha, D.; Sakhuja,\
    \ K.; Dwivedii, T.R.; Gururaj, C. Drone based image processing \nthrough feature\
    \ extraction. In Proceedings of the 2017 2nd IEEE International Conference on\
    \ \nRecent Trends in Electronics Information & Communication Technology (RTEICT),\
    \ Bangalore, \nIndia, 19–20 May 2017.  \n108- \nJunaid, A.B.; Konoiko, A.; Zweiri,\
    \ Y.; Sahinkaya, M.N.; Seneviratne, L. Autonomous Wireless Self-\nCharging forMulti-Rotor\
    \ Unmanned Aerial Vehicles. Energies 2017, 10, 803. \n \n148 \n \nSmart IoT Monitoring\
    \ and Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \n109- \nLee, J.; Wang, J.; Crandall, D.; Sabanovic, S.;\
    \ Fox, G. Real-Time Object Detection for Unmanned \nAerial Vehicles based on Cloud-based\
    \ Convolutional Neural Networks. In Proceedings of the First \nIEEE International\
    \ Conference on Robotic Computing, Taichung, Taiwan, 10–12 April 2017. \n110-\
    \ \nSilva, E.; Martins, A.; Dias, A.; Matos, A.; Olivier, A.; Pinho, C.; Silva,\
    \ E.; de Sá, F.A.; Ferreira, H.; Silva, \nH.; et al. Strengthening marine and\
    \ maritime research and technology. In Proceedings of the \nOCEANS 2016 MTS/IEEE\
    \ Monterey, Monterey, CA, USA, 19–23 September 2016; pp. 1–9.  \n111- \nNicholson,\
    \ J.; Healey, A. The present state of autonomous underwater vehicle (AUV) applications\
    \ \nand technologies. Mar. Technol. Soc. J. 2008, 42, 44–51.  \n112- \nWeidner,\
    \ N.; Rahman, S.; Li, A.Q.; Rekleitis, I. Underwater cave mapping using stereo\
    \ vision. In \nProceedings of the IEEE International Conference on Robotics and\
    \ Automation, Singapore, 29 \nMay–3 June 2017; pp. 5709–5715.  \n113- \nRoser,\
    \ M.; Dunbabin, M.; Geiger, A. Simultaneous underwater visibility assessment,\
    \ enhancement \nand improved stereo. In Proceedings of the IEEE International\
    \ Conference on Robotics and \nAutomation, Hong Kong, China, 31 May–7 June 2014;\
    \ pp. 1–8.  \n114- \nLu, H.; Li, Y.; Xu, X.; He, L.; Dansereau, D.; Serikawa,\
    \ S. Underwater image descattering and quality \nassessment. In Proceedings of\
    \ the IEEE International Conference on Image Processing, Phoenix, \nAZ, USA, 25–28\
    \ September 2016; pp. 1998–2002.  \n115- \nLu, H.; Serikawa, S. Underwater scene\
    \ enhancement using weighted guided median filter. In \nProceedings of the IEEE\
    \ International Conference on Multimedia and Expo, Chengdu, China, 14–\n18 July\
    \ 2014; pp. 1–6. \n116- \nForesti, G.L.; Murino, V.; Regazzoni, C.S.; Trucco,\
    \ A. A Voting-Based Approach for Fast Object \nRecognition in Underwater Acoustic\
    \ Images. IEEE J. Ocean. Eng. 1997, 22, 57–65.  \n117- \nHansen, R.K.; Andersen,\
    \ P.A. 3D Acoustic Camera for Underwater Imaging. Acoust. \nImaging 1993, 20,\
    \ 723–727.  \n118- \nLane, D.M.; Stoner, J.P. Automatic interpretation of sonar\
    \ imagery using qualitative feature \nmatching. IEEE J. Ocean. Eng. 1994, 19,\
    \ 391–405. \n119- \nForesti, G.L.; Gentili, S. A Vison Based System for Object\
    \ Detection In Underwater Images. Int. J. \nPattern Recognit. Artif. Intell. 2000,\
    \ 14, 167–188. \n120- \nValdenegro-Toro, M. Improving Sonar Image Patch Matching\
    \ via Deep Learning. In Proceedings \nof the 2017 European Conference on Mobile\
    \ Robots (ECMR), Paris, France, 6–8 September 2017.  \n121- \nVillon, S.; Mouillot,\
    \ D.; Chaumont, M.; Darling, E.S.; Subsolb, G.; Claverie, T.; Villéger, S. A Deep\
    \ \nLearning method for accurate and fast identification of coral reef fishes\
    \ in underwater \nimages. Ecol. Inform. 2018.  \n122- \nQut University. Available\
    \ online: https://www.qut.edu.au/news?id=135108 (accessed on 3 May \n2020). \n\
    123- \nPiechaud, N.; Hunt, C.; Culverhouse, P.F.; Foster, N.L.; Howell, K.L. Automated\
    \ identification of \nbenthic epifauna with computer vision. Mar. Ecol. Prog.\
    \ Ser. 2019, 615, 15–30.  \n124- \nGelin, C. Introduction. In A High-Rate Virtual\
    \ Instrument of Marine Vehicle Motions for \nUnderwater Navigation and Ocean Remote\
    \ Sensing. Springer Series on Naval Architecture, Marine \nEngineering, Shipbuilding\
    \ and Shipping; Springer: Berlin/Heidelberg, Germany, 2013; Volume 1. \n125- \n\
    Heidarsson, H.K.; Sukhatme, G.S. Obstacle detection from overhead imagery using\
    \ self-supervised \nlearning for autonomous surface vehicles. In Proceedings of\
    \ the 2011 IEEE/RSJ International \nConference on Intelligent Robots and Systems,\
    \ San Francisco, CA, USA, 25–30 September 2011; \npp. 3160–3165. \n126- \nKristan,\
    \ M.; Kenk, V.S.; Kovacic, S.; Pers, J. Fast Image-Based Obstacle Detection from\
    \ Unmanned \nSurface Vehicles. IEEE Trans. Cybern. 2015, 46, 641–654 \n127- \n\
    Blanke, M.; Hansen, S.; Stets, J.D.; Koester, T.; Brøsted, J.E.; Llopart Maurin,\
    \ A.; Nykvist, N.; Bang, J. \nOutlook for navigation—comparing human performance\
    \ with a robotic solution. In Proceedings \nof the 1st International Conference\
    \ on Maritime Autonomous Surface Ships (ICMASS 2018), Busan, \nKorea, 8–9 November\
    \ 2018.  \n128- \nPrasad, D.K.; Prasath, C.K.; Rajan, D.; Rachmawati, L.; Rajabaly,\
    \ E.; Quek, C. Challenges in video-\nbased object detection in maritime scenario\
    \ using computer vision. arXiv 2016, arXiv:1608.0107. \nAvailable online: https://arxiv.org/abs/1608.01079\
    \ (accessed on 17 November 2020). \n129- \nWawrzyniak, N.; Hyla, T.; Popik, A.\
    \ Vessel Detection and Tracking Method Based on Video \nSurveillance. Sensors\
    \ 2019, 19, 5230.  \n130- \nCho, Y.; Park, J.; Kang, M.; Kim, J. Autonomous detection\
    \ and tracking of a surface ship using \nonboard monocular vision. In Proceedings\
    \ of the 2015 12th International Conference on \nUbiquitous Robots and Ambient\
    \ Intelligence (URAI), Goyang, Korea, 28–30 October 2015. \n \n149 \n \nSmart\
    \ IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \n131- \nIBM \nBoards \nthe \nMayflower\
    \ \nAutonomous \nShip \nProject. \nAvailable \nonline: https://newsroom.ibm.com/2019-10-16-IBM-Boards-the-Mayflower-Autonomous-Ship-\n\
    Project (accessed on 17 November 2020). \n132- \nGoogle and Rolls-Royce Partner\
    \ on Autonomous Ships. Available online: https://maritime-\nexecutive.com/article/google-and-rolls-royce-partner-on-autonomous-ships\
    \ (accessed on 17 \nNovember 2020). \n133- \nHansen, R.K.; Andersen, P.A. 3D Acoustic\
    \ Camera for Underwater Imaging. Acoust. \nImaging 1993, 20, 723–727.  \n134-\
    \ \nLane, D.M.; Stoner, J.P. Automatic interpretation of sonar imagery using qualitative\
    \ feature \nmatching. IEEE J. Ocean. Eng. 1994, 19, 391–405. \n135- \nForesti,\
    \ G.L.; Gentili, S. A Vison Based System for Object Detection In Underwater Images.\
    \ Int. J. \nPattern Recognit. Artif. Intell. 2000, 14, 167–188. \n136- \nVillon,\
    \ S.; Mouillot, D.; Chaumont, M.; Darling, E.S.; Subsolb, G.; Claverie, T.; Villéger,\
    \ S. A Deep \nLearning method for accurate and fast identification of coral reef\
    \ fishes in underwater \nimages. Ecol. Inform. 2018.  \n137- \nPiechaud, N.; Hunt,\
    \ C.; Culverhouse, P.F.; Foster, N.L.; Howell, K.L. Automated identification of\
    \ \nbenthic epifauna with computer vision. Mar. Ecol. Prog. Ser. 2019, 615, 15–30.\
    \  \n138- \nValdenegro-Toro, M. Improving Sonar Image Patch Matching via Deep\
    \ Learning. In Proceedings \nof the 2017 European Conference on Mobile Robots\
    \ (ECMR), Paris, France, 6–8 September 2017.  \n139- \nGelin, C. Introduction.\
    \ In A High-Rate Virtual Instrument of Marine Vehicle Motions for \nUnderwater\
    \ Navigation and Ocean Remote Sensing. Springer Series on Naval Architecture,\
    \ Marine \nEngineering, Shipbuilding and Shipping; Springer: Berlin/Heidelberg,\
    \ Germany, 2013; Volume 1. \n140- \nHeidarsson, H.K.; Sukhatme, G.S. Obstacle\
    \ detection from overhead imagery using self-supervised \nlearning for autonomous\
    \ surface vehicles. In Proceedings of the 2011 IEEE/RSJ International \nConference\
    \ on Intelligent Robots and Systems, San Francisco, CA, USA, 25–30 September 2011;\
    \ \npp. 3160–3165. \n141- \nKristan, M.; Kenk, V.S.; Kovacic, S.; Pers, J. Fast\
    \ Image-Based Obstacle Detection from Unmanned \nSurface Vehicles. IEEE Trans.\
    \ Cybern. 2015, 46, 641–654 \n142- \nGu, J.; Wang, Z.; Kuen, J.; Ma, L.; Shahroudy,\
    \ A.; Shuai, B.; Liu, T.; Wang, X.; Wang, G.; Cai, J.; et al. \nRecent advances\
    \ in convolutional neural networks. Pattern Recognit. 2018, 77 \n143- \n48. Krizhevsky,\
    \ A.; Sutskever, I.; Hinton, G.E. ImageNet classification with deep convolutional\
    \ neural \nnetworks. In Proceedings of the International Conference on Neural\
    \ Information Processing \nSystems, Lake Tahoe, NV, USA, 3–8 December 2012; pp.\
    \ 1097–1105. \n144- \n Deng, J.; Dong, W.; Socher, R.; Li, L.J.; Li, K.; Li, F.F.\
    \ ImageNet: A large-scale hierarchical image \ndatabase. In Proceedings of the\
    \ Computer Vision and Pattern Recognition, 2009 (CVPR 2009), \nMiami, FL, USA,\
    \ 20–25 June 2009; pp. 248–255.  \n145- \n50. Girshick, R. Fast R-CNN. In Proceedings\
    \ of the 2015 IEEE International Conference on Computer \nVision (ICCV), Santiago,\
    \ Chile, 7–13 December 2015.  \n146- \n Ren, S.; He, K.; Girshick, R.; Sun, J.\
    \ Faster R-CNN: Towards Real-Time Object Detection with Region \nProposal Networks.\
    \ IEEE Trans. Pattern Anal. Mach. Intell. 2017, 39, 1137–1149.  \n147- \n Lin,\
    \ T.; Goyal, P.; Girshick, R.; He, K.; Dollár, P. Focal Loss for Dense Object\
    \ Detection. In \nProceedings of the 2017 IEEE International Conference on Computer\
    \ Vision (ICCV), Honolulu, HI, \nUSA, 21–26 July 2017. \n148- \n53.  Liu, W.;\
    \ Anguelov, D.; Erhan, D.; Szegedy, C.; Reed, S.; Fu, C.Y.; Berg, A.C. SSD: Single\
    \ shot \nmultibox detector. In Proceedings of the European Conference on Computer\
    \ Vision, Amsterdam, \nThe Netherlands, 11–14 October 2016; pp. 21–37. \n149-\
    \ \n54. Redmon, J.; Divvala, S.; Girshick, R.; Farhadi, A. You only look once:\
    \ Unified, real-time object \ndetection. In Proceedings of the IEEE Conference\
    \ on Computer Vision and Pattern Recognition \n(CVPR 2016), Las Vegas, NV, USA,\
    \ 27–30 June 2016; pp. 779–788.  \n150- \nGhidoni, P.L.N.S.; Brahnam, S. Handcrafted\
    \ vs. non-handcrafted features for computer vision \nclassification. Pattern Recognit.\
    \ 2017, 71, 158–172. \n151- \nPathak, A.R.; Pandey, M.; Rautaray, S. Application\
    \ of Deep Learning for Object Detection. In \nProceedings of the International\
    \ Conference on Computational Intelligence and Data Science \n(ICCIDS 2018), Gurugram,\
    \ India, 7–8 April 2018. \n152- \nFeng, X.; Jiang, Y.; Yang, X.; Du, M.; Li, X.\
    \ Computer Vision Algorithms and Hardware \nImplementations: A Survey. Integration\
    \ 2019, 69, 309–320.  \n153- \n58. Zhao, Z.; Zheng, P.; Xu, S.; Wu, X. Object\
    \ Detection with Deep Learning: A Review. IEEE Trans. \nNeural Netw. Learn. Syst.\
    \ 2019, 30, 3212–3232.  \n \n150 \n \nSmart IoT Monitoring and Real-Time Control\
    \ Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \n154- \nDahlkamp, H.; Kaehler, A.; Stavens, D.; Thrun, S.; Bradski, G.R. Self\
    \ supervised monocular road \ndetection in desert terrain. In Proceedings of the\
    \ Robotics: Science and Systems, Philadelphia, PA, \nUSA, 16–19 August 2006. \n\
    155- \n Chen, C.; Seff, A.; Kornhauser, A.; Xiao, J. Deep Driving: Learning affordance\
    \ for direct perception \nin autonomous driving. In Proceedings of the 2015 IEEE\
    \ International Conference on Computer \nVision (ICCV), Santiago, Chile, 7–13\
    \ December 2015; pp. 2722–2730.  \n156- \nChen, X.; Ma, H.; Wan, J.; Li, B.; Xia,\
    \ T. Multi-view 3D object detection network for autonomous \ndriving. In Proceedings\
    \ of the 2017 IEEE International Conference on Computer Vision (ICCV), \nHonolulu,\
    \ HI, USA, 21–26 July 2017; pp. 6526–6534. \n157- \nCoates, A.; Ng, A.Y. Multi-camera\
    \ object detection for robotics. In Proceedings of the 2010 IEEE \nInternational\
    \ Conference on Robotics and Automation, Anchorage, AK, USA, 3–7 May 2010; pp.\
    \ \n412–419. \n158- \nArmbrust, M.; Fox, A.; Griffith, R.; Joseph, A.D.; Katz,\
    \ R.; Konwinski, A.; Lee, G.; Patterson, D.; Rabkin, \nA.; Stoica, I.; et al.\
    \ A view of cloud computing. Commun. ACM 2010, 53, 50–58.  \n159- \n63. Kenitar,\
    \ S.B.; Arioua, M.; Younes, A.; Radi, M.; Salhaoui, M. Comparative Analysis of\
    \ Energy \nEfficiency and Latency of Fog and Cloud Architectures. In Proceedings\
    \ of the 2019 International \nConference on Sensing and Instrumentation in IoT\
    \ Era (ISSI), Lisbon, Portugal, 29–30 August 2019; \nIEEE: Piscataway, NJ, USA,\
    \ 2020.  \n160- \n64. Redmon, J.; Divvala, S.; Girshick, R.; Farhadi, A. You only\
    \ look once: Unified, real-time object \ndetection. In Proceedings of the IEEE\
    \ Conference on Computer Vision and Pattern Recognition \n(CVPR 2016), Las Vegas,\
    \ NV, USA, 27–30 June 2016; pp. 779–788.  \n161- \nWang, X.; Victor, C.M.; Niyato,\
    \ D.; Yan, X.; Chen, X. Convergence of Edge Computing and Deep \nLearning: A Comprehensive\
    \ Survey. IEEE Commun. Surv. Tutor. 2020, 22, 869–904.  \n162- \nComputer Vision,\
    \ WikiPedia. Available online: https://en.wikipedia.org/wiki/Computer_vision \n\
    (accessed on 18 June 2020). \n163- \nFeng, X.; Jiang, Y.; Yang, X.; Du, M.; Li,\
    \ X. Computer Vision Algorithms and Hardware \nImplementations: A Survey. Integration\
    \ 2019, 69, 309–320.  \n164- \nKang, Y.; Hauswald, J.; Gao, C.; Rovinski, A.;\
    \ Mudge, T.; Mars, J.; Tang, L. Neurosurgeon: \nCollaborative Intelligence Between\
    \ the Cloud and Mobile Edge. In Proceedings of the 22nd \nInternational Conference\
    \ on Architectural Support for Programming Languages and Operating \nSystems (ASPLOS\
    \ 2017), Xi’an, China, 8–12 April 2017; pp. 615–629.  \n165- \nRussakovsky, O.;\
    \ Deng, J.; Su, H.; Krause, J.; Satheesh, S.; Ma, S.; Huang, Z.; Karpathy, A.;\
    \ Khosla, A.; \nBernstein, M.; et al. ImageNet Large Scale Visual Recognition\
    \ Challenge. Int. J. Comput. Vis. 2015, \n115, 211–252. \n166- \nZhou, Z.; Chen,\
    \ X.; Li, E.; Zeng, L.; Luo, K.; Zhang, J. Edge Intelligence: Paving the Last\
    \ Mile of \nArtificial Intelligence with Edge Computing. Proc. IEEE 2019, 107.\
    \  \n167- \nSikeridis, D.; Papapanagiotou, I.; Rimal, B.P.; Devetsikiotis, M.\
    \ A Comparative  Taxonomy and \nSurvey of Public Cloud Infrastructure Vendors.\
    \ arXiv 2018, arXiv:1710.01476v2.  \n168- \nGoogle Cloud. Available online: https://cloud.google.com/vision/?hl=en\
    \ (accessed on 3 May \n2020). \n169- \nAzure. Available online: https://azure.microsoft.com/en-au/services/cognitive-services/computer-\n\
    vision/ (accessed on 3 May 2020). \n170- \nZhou, Z.; Chen, X.; Li, E.; Zeng, L.;\
    \ Luo, K.; Zhang, J. Edge Intelligence: Paving the Last Mile of \nArtificial Intelligence\
    \ with Edge Computing. Proc. IEEE 2019, 107. \n171- \nO’Mahony, N.; Campbell,\
    \ S.; Carvalho, A.; Harapanahalli, S.; Hernandez, G.V.; Krpalkova, L.; Riordan,\
    \ \nD.; Walsh, J. Deep Learning vs. Traditional Computer Vision. In Advances in\
    \ Computer Vision; Arai, \nK., Kapoor, S., Eds.; Springer: Cham, Switzerland,\
    \ 2020; Volume 943.  \n172- \nStefanini, M.; Lancellotti, R.; Baraldi, L.; Calderara,\
    \ S.A. Deep-learning-based approach to VM \nbehavior Identification in Cloud Systems.\
    \ In Proceedings of the 9th International Conference on \nCloud Computing and\
    \ Services Science, Crete, Greece, 2–4 May 2019; pp. 308–315. \n173- \nSvorobej,\
    \ S.; Endo, P.T.; Bendechache, M.; Filelis-Papadopoulos, C.; Giannoutakis, K.M.;\
    \ Gravvanis, \nG.A.; Tzovaras, D.; Byrne, J.; Lynn, T. Simulating Fog and Edge\
    \ Computing Scenarios: An Overview \nand Research Challenges. Future Internet\
    \ 2019, 11, 55 \n174- \nKurose, J.F.; Ross, K.W. Computer Networking: A Top-Down\
    \ Approach, 6th ed.; Pearson: London, \nUK, 2012.  \n175- \nThangamuthu, S.; Concer,\
    \ N.; Cuijpers, P.J.L.; Lukkien, J.J. Analysis of ethernet-switch traffic shapers\
    \ \nfor in-vehicle networking applications. In Proceedings of the 2015 Design,\
    \ Automation Test in \nEurope Conference Exhibition (DATE), Grenoble, France,\
    \ 9–13 March 2015; pp. 55–60 \n \n151 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \n176- \nCavalieri, S.; Chiacchio, F. Analysis of OPC UA performances.\
    \ Comput. Stand. Interfaces 2013, 36, \n165–177 \n177- \nGutiérrez, C.S.V.; Juan,\
    \ L.U.S.; Ugarte, I.Z.; Vilches, V.M. Time-Sensitive networking for \nrobotics.\
    \ arXiv 2018, arXiv:1804.07643v2.  \n178- \nIEEE standard for local and metropolitan\
    \ area networks—Bridges and bridged networks-\namendment 25: Enhancements for\
    \ scheduled traffic. In IEEE Std 802.1Qbv-2015 (Amendment to \nIEEE Std 802.1Q-2014\
    \ as amended by IEEE Std 802.1Qca-2015, IEEE Std 802.1Qcd-2015, and IEEE \nStd\
    \ 802.1Q-2014/ Cor 1-2015); IEEE: New York, NY, USA, 2016; pp. 1–57. \n179- \n\
    Bruckner, D.; Blair, R. OPC, UA, TSN: A New Solution for Industrial Communication.\
    \ 2018. Available \nonline: https://www.automationworld.com/sites/default/files/opc_ua_tsn_whitepaper_1.pdf\
    \ (acce\nssed on 13 May 2019). \n180- \nTatum, M.C.; Liu, J. Unmanned Aerial Vehicles\
    \ in the Construction Industry. In Proceedings of the \nUnmanned Aircraft System\
    \ Applications in Construction, Creative Construction Conference, \nPrimosten,\
    \ Croatia, 19–22 June 2017. \n181- \nSisinni, E.; Saifullah, A.; Han, S.; Jennehag,\
    \ U.; Gidlund, M. Industrial Internet of Things: Challenges, \nOpportunities,\
    \ and Directions. IEEE Trans. Ind. Inform. 2018, 14, 4724–4734.   \n182- \nAazam,\
    \ M.; Zeadally, S.; Harras, K.A. Deploying Fog Computing in Industrial Internet\
    \ of Things and \nIndustry 4.0. IEEE Trans. Ind. Inform. 2018.   \n183- \nSvorobej,\
    \ S.; Endo, P.T.; Bendechache, M.; Filelis-Papadopoulos, C.; Giannoutakis, K.M.;\
    \ Gravvanis, \nG.A.; Tzovaras, D.; Byrne, J.; Lynn, T. Simulating Fog and Edge\
    \ Computing Scenarios: An Overview \nand Research Challenges. Future Internet\
    \ 2019, 11, 55.  . \n184- \nLarrauri, J.I.; Sorrosal, G.; Gonzalez, M. Automatic\
    \ system for overhead power line inspection using \nan unmanned aerial vehicle\
    \ RELIFO project. In Proceedings of the International Conference on \nUnmanned\
    \ Aircraft Systems (ICUAS), Atlanta, GA, USA, 28–31 May [32] 2013; pp. 244–252.\
    \   32. \nIndustrial \nSkyworks. \nDrone \nInspections \nServices. \nAvailable\
    \ \nonline: \nhttps://industrialskyworks.com/droneinspections-services (accessed\
    \ on 21 April 2019). \n185- \nSoria, P.R.; Bevec, R.; Arrue, B.C.; Ude, A.; Ollero,\
    \ A. Extracting Objects for Aerial Manipulation on \nUAVs Using Low Cost Stereo\
    \ Sensors. Sensors 2016, 16, 700.      \n186- \nLagkas, T.; Argyriou, V.; Bibi,\
    \ S.; Sarigiannidis, P. UAV IoT Framework Views and Challenges: \nTowards Protecting\
    \ Drones as “Things”. Sensors 2018, 18, 4015.     \n187- \nKim, H.; Lee, J.; Ahn,\
    \ E.; Cho, S.; Shin, M.; Sim, S.-H. Concrete Crack Identification Using a UAV\
    \ \nIncorporating Hybrid Image Processing. Sensors 2017, 17, 2052.   \n188- \n\
    Sara Mahmoud, Nader Mohamed, Jameela Al-Jaroodi, Integrating UAVs into the Cloud\
    \ Using the \nConcept of the Web of Things. Article in Journal of Robotics, published\
    \ January 2015. DOI\n \n10.1155/2015/631420 \n189- \nGithub. Available online:\
    \ https://github.com/felixge/node-ar-drone (accessed on 14 September \n2018).\
    \ \n190- \nGithub. \nAvailable \nonline: https://github.com/eschnou/ardrone-autonomy\
    \ (accessed \non \n14 \nSeptember 2018). \n191- \nEngel, J.; Sturm, J.; Cremers,\
    \ D. Accurate Figure Flying with a Quadrocopter Using Onboard Visual \nand Inertial\
    \ Sensing. In Proceedings of the International Conference on Intelligent Robot\
    \ Systems \n(IROS), Algarve, Portugal, 7–12 October 2012; p. 240. [Google Scholar]\
    \ \n192- \nSmith, J.R.; Cao, L.; Codella, N.C.F.; Hill, M.L.; Merler, M.; Nguyen,\
    \ Q.-B.; Pring, E.; Uceda-Sosa, R.A. \nMassive-scalelearning of image and video\
    \ semantic concepts. IBM J. Res. Dev. 2015, 59, 7-1–7-13. \n193- \nCaffe. Available\
    \ online: http://caffe.berkeleyvision.org (accessed on 14 September 2018). \n\
    \ \n194- \nBhattacharjee, B.; Hill, M.L.; Wu, H.; Chandakkar, P.S.; Smith, J.R.;\
    \ Wegman, M.N. Distributed \nlearning of deep feature embeddings for visual recognition\
    \ tasks. IBM J. Res. Dev. 2017, 61, 4-1. \n[Google Scholar] [CrossRef] \n195-\
    \ \nPuttnies, H.; Konieczek, B.; Heller, J.; Timmermann, D.; Danielis, P. Algorithmic\
    \ approach to estimate \nvariant software latencies for latency-sensitive networking.\
    \ In Proceedings of the 2016 IEEE 7th \nAnnual Information Technology, Electronics\
    \ and Mobile Communication Conference (IEMCON), \nVancouver, BC, Canada, 13–15\
    \ October 2016; pp. 1–7. [Google Scholar] \n196- \nNakutis, Z.; Deksnys, V.; Jarusevicius,\
    \ I.; Dambrauskas, V.; Cincikas, G.; Kriauceliunas, A. Round-Trip \nDelay \nEstimation\
    \ \nin \nOPC \nUA \nServer-Client \nCommunication \nChannel. Elektron \nElektrotechnika\
    \ 2016, 22, 80–84.  \n197- \nGithub. Available online: https://github.com/felixge/node-ar-drone\
    \ (accessed on 14 September \n2018). \n \n152 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \n198- \nKeith Jack,Digital Television (DTV).  in Digital Video and\
    \ DSP, 2008. ScienceDirect. \nhttps://doi.org/10.1016/B978-0-7506-8975-5.00008-X\
    \ \n199- \nMarpe, D.; Wiegand, T.; Heinrich Hertz Institute (HHI); Sullivan, G.J.\
    \ The H.264/MPEG4 Advanced \nVideo Coding Standard and its Applications. IEEE\
    \ Commun. Mag. 2006, 8, 134–143. [Google \nScholar] [CrossRef] \n200- \nGonzález-Reolid,\
    \ I.; Molina-Molina, J.C.; Guerrero-González, A.; Ortiz, F.J.; Alonso, D. An \n\
    Autonomous Solar-Powered Marine Robotic Observatory for Permanent Monitoring of\
    \ Large \nAreas of Shallow Water. Sensors 2018, 18, 3497. [Google Scholar] [CrossRef]\
    \ [PubMed] \n201- \nBoletín Oficial de la Región de Murcia, Numero 298, Viernes,\
    \ 27 de Diciembre de 2019, Página \n36008, 8089 Decreto-Ley N° 2/2019, de 26 de\
    \ Diciembre, de Protección Integral del Mar Menor. \nAvailable \nonline: https://www.borm.es/services/anuncio/ano/2019/numero/8089/pdf?id=782206\
    \ (accesse\nd on 18 June 2020). \n202- \nInforme Integral Sobre el Estado Ecológico\
    \ del Mar Menor; Comité de Asesoramiento Científico \ndel Mar Menor: Murcia, Spain,\
    \ 2017. \n203- \nKersting, D.; Benabdi, M.; Čižmek, H.; Grau, A.; Jimenez, C.;\
    \ Katsanevakis, S.; Öztürk, B.; Tuncer, S.; \nTunesi, L.; Vázquez-Luis, M.; et\
    \ al. Pinna nobilis. IUCN Red List Threat. Species 2019, \ne.T160075998A160081499.\
    \ \nAvailable \nonline: https://www.iucnredlist.org/species/160075998/160081499\
    \ (accessed on 19 June 2020). \n[CrossRef] \n204- \nBelando, M.D.; García-Muñoz,\
    \ M.R.; Ramos-Segura, A.; Franco-Navarro, I.J.; García-Moreno, P.; \nRuiz-Fernández,\
    \ J.M. Distribución y Abundancia de las Praderas de MACRÓFITOS bentónicos y las\
    \ \nPoblaciones de Nacra (Pinna nobilis) en el Mar Menor; Informe del Instituto\
    \ Español de \nOceanografía y la Asociación de Naturalistas del Sureste: Murcia,\
    \ Spain, 2014; 60p. [Google \nScholar] \n205- \nPaull, L.; Seto, M.; Saeedi, S.;\
    \ Leonard, J.J. Navigation for Underwater Vehicles; Springer: \nBerlin/Heidelberg,\
    \ Germany, 2018. [Google Scholar] [CrossRef] \n206- \nLiu, X.; Xu, X.; Liu, Y.;\
    \ Wang, L. Kalman filter for cross-noise in the integration of SINS and \nDVL.\
    \ Math. Probl. Eng. 2014, 2014, 1–8. [Google Scholar] [CrossRef] \n207- \nPaull,\
    \ L.; Saeedi, S.; Seto, M.; Li, H. AUV navigation and localization: A review.\
    \ IEEE J. Ocean. \nEng. 2014, 39, 131–149. [Google Scholar] [CrossRef] \n208-\
    \ \nSalhaoui, M.; Guerrero-Gonzalez, A.; Arioua, M.; Ortiz, F.J.; El Oualkadi,\
    \ A.; Torregrosa, C.L. Smart \nindustrial iot monitoring and control system based\
    \ on UAV and cloud computing applied to a \nconcrete plant. Sensors 2019, 19,\
    \ 3316. [Google Scholar] [CrossRef] \n209- \nStackoverflow. \nAvailable \nonline:\
    \ https://stackoverflow.blog/2017/09/14/python-growing-\nquickly/ (accessed on\
    \ 3 May 2020). \n210- \nNetguru. Available online: https://www.netguru.com/blog/why-is-python-good-for-research-\n\
    benefits-of-the-programming-language (accessed on 3 May 2020). \n211- \nZhou,\
    \ Z.; Chen, X.; Li, E.; Zeng, L.; Luo, K.; Zhang, J. Edge Intelligence: Paving\
    \ the Last Mile of \nArtificial Intelligence with Edge Computing. Proc. IEEE 2019,\
    \ 107. [Google Scholar] [CrossRef] \n212- \nSikeridis, D.; Papapanagiotou, I.;\
    \ Rimal, B.P.; Devetsikiotis, M. A Comparative Taxonomy and Survey \nof Public\
    \ Cloud Infrastructure Vendors. arXiv 2018, arXiv:1710.01476v2. [Google Scholar]\
    \ \n213- \nKim, D.; Han, K.; Sim, J.S.; Noh, Y. Smombie Guardian: We watch for\
    \ potentialobstacles while you \nare walking andconducting smartphone activities.\
    \ PLoS ONE 2018, 13, e0197050. [Google \nScholar] [CrossRef] \n214- \nMegalingam,\
    \ R.K.; Shriram, V.; Likhith, B.; Rajesh, G.; Ghanta, S. Monocular distance estimation\
    \ \nusing pinhole camera approximation to avoid vehicle crash and back-over accidents.\
    \ In \nProceedings of the 2016 10th International Conference on Intelligent Systems\
    \ and Control (ISCO), \nCoimbatore, India, 7–8 January 2016; IEEE: Coimbatore,\
    \ India. [Google Scholar] [CrossRef] \n215- \nNational \nInstruments. \nAvailable\
    \ \nonline: https://www.ni.com/es-es/support/model.sbrio-\n9606.html (accessed\
    \ on 3 May 2020). \n216- \nNational Instruments. Available online: https://www.ni.com/en-us/shop/labview.html\
    \ (accessed \non 3 May 2020). \n217- \nMarine Species. Available online: http://www.marinespecies.org/\
    \ (accessed on 2 June 2020). \n218- \nShi, W.; Cao, J.; Zhang, Q.; Li, Y.; Xu,\
    \ L. Edge computing: Vision and challenges. IEEE Internet Things \nJ. 2016, 3,\
    \ 637–646. [Google Scholar] [CrossRef] \n \n153 \n \nSmart IoT Monitoring and\
    \ Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \n219- \nKrupinski, S.; Desouche, R.; Palomeras, N.; Allibert,\
    \ G.; Hua, M.D. Pool Testing of AUV Visual \nServoing for Autonomous Inspection.\
    \ IFAC-PapersOnLine 2015, 48, 274–280. [Google Scholar] \n[CrossRef] \n220- \n\
    Kumar, G.S.; Unnikrishnan, V.; Painumgal, M.N.V.; Kumar, C.; Rajesh, K.H.V. Autonomous\
    \ \nUnderwater Vehicle for Vision Based Tracking. Procedia Comput. Sci. 2018.\
    \ [Google Scholar] \n[CrossRef] \n221- \nIslam, M.J.; Fulton, M.; Sattar, J. Towards\
    \ a Generic Diver-Following Algorithm: Balancing \nRobustness and Efficiency in\
    \ Deep Visual Detection. IEEE Robot. Autom. Lett. 2019, 4, 113–120. \n[Google\
    \ Scholar] [CrossRef] \n222- \nYosafat, R.; Machbub, C.; Hidayat, E.M.I. Design\
    \ and Implementation of Pan-Tilt for Face Tracking. \nIn Proceedings of the International\
    \ Conference on System Engineering and Technology, Shah \nAlam, Malaysia, 2–3\
    \ October 2017. [Google Scholar] \n223- \nZhang, B.; Huang, J.; Lin, J. A Novel\
    \ Algorithm for Object Tracking by Controlling PAN/TILT \nAutomatically. In Proceedings\
    \ of the ICETC 2nd International Conference on Intelligent System \n2010, Shanghai,\
    \ China, 22–24 June 2010; Volume VI, pp. 596–602. [Google Scholar] \n224- \nGonzález,\
    \ A.G.; Coronado, J. Tratamiento de los retrasos del procesamiento visual en el\
    \ sistema \nde control de un cabezal estereoscópico. In XX Jornadas de Automática:\
    \ Salamanca, 27, 28 y 29 \nde Septiembre; Universidad de Salamanca: Salamanca,\
    \ Spain; pp. 83–87. \n225- \nKim, D.; Han, K.; Sim, J.S.; Noh, Y. Smombie Guardian:\
    \ We watch for potentialobstacles while you \nare walking andconducting smartphone\
    \ activities. PLoS ONE 2018, 13, e0197050. [Google \nScholar] [CrossRef] \n226-\
    \ \nIBM. \nAvailable \nonline: https://cloud.ibm.com/docs/services/visual-recognition?topic=visual-\n\
    recognition-object-detection-overview (accessed on 3 May 2020). \n227- \nGoogle\
    \ Cloud. Available online: https://cloud.google.com/vision/?hl=en (accessed on\
    \ 3 May \n2020). \n228- \nAzure. \nAvailable \nonline: https://azure.microsoft.com/en-au/services/cognitive-\n\
    services/computer-vision/ (accessed on 3 May 2020). \n229- \nMarine protected\
    \ areas in Europe’s seas. An overview and perspectives for the future. European\
    \ \nEnvironment \nAgency. \nNo \n3/2015. \nISSN \n1977-8449. \nAvailable \nonline:\
    \ \nhttps://www.eea.europa.eu/publications/marine-protected-areas-in-europes (accessed\
    \ on 17 \nNovember 2020) \n230- \nLey 3/2001, de Pesca Marítima del Estado. Boletín\
    \ Oficial del Estado del Gobierno de España.  \nAvailable online: https://www.boe.es/eli/es/l/2001/03/26/3/con\
    \ (accessed on 17 November 2020) \n231- \nGobierno \nde \nEspaña. \nReservas \n\
    Marinas \nde \nEspaña. \nAvailable \nonline: \nhttps://www.mapa.gob.es/es/pesca/temas/proteccion-recursos-pesqueros/reservas-marinas-de-\n\
    espana/(accessed on 17 November 2020) \n232- \nGonzález-Reolid, I.; Molina-Molina,\
    \ J.C.; Guerrero-González, A.; Ortiz, F.J.; Alonso, D. An \nAutonomous Solar-Powered\
    \ Marine Robotic Observatory for Permanent Monitoring of Large \nAreas of Shallow\
    \ Water. Sensors 2018, 18, 3497; doi:10.3390/s18103497. \n233- \nA. Manjunath,\
    \ Y. Liu, B. Henriques and A. Engstle, \"Radar Based Object Detection and Tracking\
    \ for \nAutonomous Driving,\" 2018 IEEE MTT-S International Conference on Microwaves\
    \ for Intelligent \nMobility (ICMIM), Munich, 2018, pp. 1-4, doi: 10.1109/ICMIM.2018.8443497\
    \ \n234- \nYang-Lang Chang, Amare Anagaw, Lena Chang, Yi Chun Wang, Chih-Yu Hsiao\
    \ and Wei-Hong Lee. \nShip Detection Based on YOLOv2 for SAR Imagery. Remote Sens.\
    \ 2019, 11, 786; \ndoi:10.3390/rs11070786 \n235- \nWei Li, Ting Yang, Flavia C.\
    \ Delicato, Paulo F. Pires, Zahir Tari, Samee U. Khan, and Albert Y. Zomaya. \n\
    On Enabling Sustainable Edge Computing with Renewable Energy Resources. IEEE \n\
    Communications Magazine. May 2018, 10.1109/MCOM.2018.1700888 \n236- \nJ. Lee,\
    \ J. Wang, D. Crandall, S. Šabanović and G. Fox, \"Real-Time, Cloud-Based Object\
    \ Detection \nfor Unmanned Aerial Vehicles,\" 2017 First IEEE International Conference\
    \ on Robotic Computing \n(IRC), Taichung, 2017, pp. 36-43, doi: 10.1109/IRC.2017.77.\
    \ \n237- \nK. Zhang, S. Leng, Y. He, S. Maharjan and Y. Zhang, \"Mobile Edge Computing\
    \ and Networking for \nGreen and Low-Latency Internet of Things,\" in IEEE Communications\
    \ Magazine, vol. 56, no. 5, pp. \n39-45, May 2018, doi: 10.1109/MCOM.2018.1700882.\
    \ \n \n154 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \n238- \nAkar\
    \ E., Marques O., Andrews W.A., Furht B. (2019) Cloud-Based Skin Lesion Diagnosis\
    \ System \nUsing Convolutional Neural Networks. In: Arai K., Bhatia R., Kapoor\
    \ S. (eds) Intelligent \nComputing. CompCom 2019. Advances in Intelligent Systems\
    \ and Computing, vol 997. \nSpringer, Cham. https://doi.org/10.1007/978-3-030-22871-2_70\
    \ \n239- \nMarouane Salhaoui, J. Carlos Molina-Molina, Antonio Guerrero-González,\
    \ Mounir Arioua, \nFrancisco J Ortiz, Autonomous Underwater Monitoring System\
    \ for Detecting Life on the Seabed \nby Means of Computer Vision Cloud Services.\
    \ Journal, Remote Sensing MDPI, 2020. \n240- \nNational Instruments. Available\
    \ online: https://www.ni.com/en-us/shop/labview.html (accessed \non 17 Nov 2020).\
    \ \n241- \nNational Instruments. Available online: https://www.ni.com/es-es/support/model.crio-9022.html\
    \ \n(accessed on 17 Nov 2020).  \n242- \nMarouane Salhaoui, J. Carlos Molina-Molina,\
    \ Antonio Guerrero-González, Mounir Arioua, \nFrancisco J Ortiz, Autonomous Underwater\
    \ Monitoring System for Detecting Life on the Seabed \nby Means of Computer Vision\
    \ Cloud Services. Journal, Remote Sensing MDPI, 2020. \n243- \nM. Satyanarayanan,\
    \ “The emergence of edge computing,” Computer, vol. 50, no. 1, pp. 30–39, \n2017.\
    \ \n244- \nGobierno de España - Reservas Marinas de España. Cabo de Palos – Islas\
    \ Hormigas: Características. \nAvailable \nonline: \nhttps://www.mapa.gob.es/es/pesca/temas/proteccion-recursos-\n\
    pesqueros/reservas-marinas-de-espana/cabo-de-palos-islas-\nhormigas/caracteristicas/default.aspx\
    \ (accessed on 17 Nov 2020). \n245- \nIRENA - International Renewable Energy Agency.\
    \ Available online : https://www.irena.org, 07 \nJanuary 2021. \n246- \nMönks,\
    \ U., Trsek, H., Dürkop, L., Geneiß, V., Lohweg, V.: Towards distributed intelligent\
    \ \nsensor and information fusion. Mechatronics 34, 63–71 (2016). https://doi.org/10.1016/j.\
    \ \nmechatronics.2015.05.005 \n247- \nDhondge, K., Shorey, R., Tew, J.: HOLA:\
    \ heuristic and opportunistic link selection \nalgorithm for energy efficiency\
    \ in Industrial Internet of Things (IIoT) systems. In: \nCOMSNETS 2016 - Workshop\
    \ on Wild and Crazy Ideas on the Interplay Between IoT and \nBig Data. IEEE (2016)\
    \ \n248- \nDatta, S.K.; Bonnet, C. MEC and IoT Based Automatic Agent Reconfiguration\
    \ in Industry 4.0. In \nProceedings of the 2018 IEEE International Conference\
    \ on Advanced Networks and \nTelecommunications Systems (ANTS), Indore, India,\
    \ 16–19 December 2018; pp. 1–5. 7.  \n249- \nShrouf, F.; Ordieres, J.; Miragliotta,\
    \ G. Smart factories in Industry 4.0:  A review of the concept and \nof energy\
    \ management approached in production based on the Internet of Things paradigm.\
    \ In \nProceedings of the 2014 IEEE International Conference on Industrial Engineering\
    \ and Engineering \nManagement (IEEM), Selangor Darul Ehsan, Malaysia, 9–12 December\
    \ 2014; pp. 697–701. \n250- \nHossein Motlagh, N.; Mohammadrezaei, M.; Hunt, J.;\
    \ Zakeri, B. Internet of Things (IoT) and the \nEnergy Sector. Energies 2020,\
    \ 13, 494. \n251- \nAyesha Hafeez, Nourhan H. Kandil, Ban Al-Omar, T. Landolsi,\
    \ and A. R. Al-Ali, \"Smart \nHome Area Networks Protocols within the Smart Grid\
    \ Context\", Journal of Communications Vol. \n9, No. 9, September 2014 \n252-\
    \ \nLi, S.; Da Xu, L.; Zhao, S. 5G Internet of Things: A survey. J. Ind. Inf.\
    \ Integr. 2018, 10, 1–9 \n253- \nAhmed B. Altamimi and Rabie A. Ramadan, \"Towards\
    \ internet of things modeling: a gateway \napproach\", \nSpringer, \nComplex \n\
    Adapt \nSyst \nModel \n(2016) \n4:25, \nDOI \nhttps://doi.org/10.1186/s40294-016-0038-3\
    \ \n254- \nWatson Internet of Things. Securely Connect with Watson IoT Platform.\
    \ 2019. Available online: \nhttps://www.ibm.com/internet-of-things/solutions/iot-platform/watson-iot-platform\
    \  (accessed \non 15 October 2019). \n255- \n “The OPC Unified Architecture (UA)”\
    \ [Online]. Available: https://opcfoundation.org/about/opc-\ntechnologies/opc-ua/\
    \ \n256- \nThomas Bangemann, StamatisKarnouskos, Roberto Camp, Oscar Carlsson,MatthiasRiedl,\
    \ \nStuart McLeod, Robert Harrison, Armando W. ColomboandPetrStluka, “State of\
    \ the Art in \nIndustrial Automation”, Industrial Cloud-Based Cyber-Physical Systems,\
    \ Springer International \nPublishing Switzerland 2014, DOI: 10.1007/978-3-319-05624-1_2\
    \ \n257- \nNode-RED, Low-code programming for event-driven applications. [Online].\
    \ Available:  \nhttps://nodered.org/  \n"
  inline_citation: '>'
  journal: ''
  limitations: '>'
  pdf_link: https://repositorio.upct.es/bitstream/10317/10416/1/msa.pdf
  publication_year: 2021
  relevance_score1: 0
  relevance_score2: 0
  title: Smart IoT monitoring and real-time control based on autonomous robots, visual
    recognition and cloud/edge computing services
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'

- analysis: '>'
  apa_citation: 'Stumpe, C., Leukel, J., & Zimpel, T. (2024). Prediction of pasture
    yield using machine learning-based optical sensing: a systematic review. Precision
    Agriculture, 25(2), 430-459.'
  authors:
  - Stumpe C.
  - Leukel J.
  - Zimpel T.
  citation_count: '0'
  data_sources: Survey data, Interviews, Case studies, Literature review
  description: Accurate and reliable predictions of biomass yield are important for
    decision-making in pasture management including fertilization, pest control, irrigation,
    grazing, and mowing. The possibilities for monitoring pasture growth and developing
    prediction models have greatly been expanded by advances in machine learning (ML)
    using optical sensing data. To facilitate the development of prediction models,
    an understanding of how ML techniques affect performance is needed. Therefore,
    this review examines the adoption of ML-based optical sensing for predicting the
    biomass yield of managed grasslands. We carried out a systematic search for English-language
    journal articles published between 2015-01-01 and 2022-10-26. Three coders screened
    593 unique records of which 91 were forwarded to the full-text assessment. Forty-three
    studies were eligible for inclusion. We determined the adoption of techniques
    for collecting input data, preprocessing, and training prediction models, and
    evaluating their performance. The results show (1) a broad array of vegetation
    indices and spectral bands obtained from various optical sensors, (2) an emphasis
    focus on feature selection to cope with high-dimensional sensor data, (3) a low
    reporting rate of unitless performance metrics other than R  2, (4) higher variability
    of R2 for models trained on sensor data of larger distance from the pasture sward,
    and (5) the need for greater comparability of study designs and results. We submit
    recommendations for future research and enhanced reporting that can help reduce
    barriers to the integration of evidence from studies.
  doi: 10.1007/s11119-023-10079-9
  explanation: Sensor calibration, drift correction, and fault detection are crucial
    for accurate and reliable sensor data collection. The review found that study
    conditions were often limited to a single field, with a small number of sample
    plots and seasons, which restricts the training data to specific weather and growing
    conditions. Some studies did not report the size of the training and test sets,
    making it difficult to assess the reliability of the prediction model. There was
    a lack of consensus in reporting performance metrics, with some studies only reporting
    R2 while others reported a variety of metrics. Feature selection techniques were
    present in 24 studies, indicating their importance for reducing the dimensionality
    of the input data. Random Forests and PLS regression were the most frequent algorithms
    used for training prediction models.
  extract_1: For assessing the reliability of a trained prediction model, the number
    of fields, plots, and seasons are important factors that determine the size of
    the training set. These numbers can provide indications of how far the temporal
    and spatial variability of pasture yields have been considered in the data collection.
  extract_2: Overall, the techniques used span across filter-based, wrapper-based,
    and embedded techniques, and reflect the variety of techniques available from
    the ML literature. In many studies, the number of features was effectively reduced
    without increasing the error of prediction.
  full_citation: '>'
  full_text: '>

    "Your privacy, your choice We use essential cookies to make sure the site can
    function. We also use optional cookies for advertising, personalisation of content,
    usage analysis, and social media. By accepting optional cookies, you consent to
    the processing of your personal data - including transfers to third parties. Some
    third parties are outside of the European Economic Area, with varying standards
    of data protection. See our privacy policy for more information on the use of
    your personal data. Manage preferences for further information and to change your
    choices. Accept all cookies Skip to main content Log in Find a journal Publish
    with us Track your research Search Cart Home Precision Agriculture Article Prediction
    of pasture yield using machine learning-based optical sensing: a systematic review
    Open access Published: 28 September 2023 Volume 25, pages 430–459, (2024) Cite
    this article Download PDF You have full access to this open access article Precision
    Agriculture Aims and scope Submit manuscript Christoph Stumpe , Joerg Leukel &
    Tobias Zimpel   1336 Accesses Explore all metrics Abstract Accurate and reliable
    predictions of biomass yield are important for decision-making in pasture management
    including fertilization, pest control, irrigation, grazing, and mowing. The possibilities
    for monitoring pasture growth and developing prediction models have greatly been
    expanded by advances in machine learning (ML) using optical sensing data. To facilitate
    the development of prediction models, an understanding of how ML techniques affect
    performance is needed. Therefore, this review examines the adoption of ML-based
    optical sensing for predicting the biomass yield of managed grasslands. We carried
    out a systematic search for English-language journal articles published between
    2015-01-01 and 2022-10-26. Three coders screened 593 unique records of which 91
    were forwarded to the full-text assessment. Forty-three studies were eligible
    for inclusion. We determined the adoption of techniques for collecting input data,
    preprocessing, and training prediction models, and evaluating their performance.
    The results show (1) a broad array of vegetation indices and spectral bands obtained
    from various optical sensors, (2) an emphasis focus on feature selection to cope
    with high-dimensional sensor data, (3) a low reporting rate of unitless performance
    metrics other than R2, (4) higher variability of R2 for models trained on sensor
    data of larger distance from the pasture sward, and (5) the need for greater comparability
    of study designs and results. We submit recommendations for future research and
    enhanced reporting that can help reduce barriers to the integration of evidence
    from studies. Similar content being viewed by others Comparing methods to estimate
    perennial ryegrass biomass: canopy height and spectral vegetation indices Article
    Open access 09 July 2020 Characterization of portuguese sown rainfed grasslands
    using remote sensing and machine learning Article 27 July 2022 Remote sensing
    and machine learning applications for aboveground biomass estimation in agroforestry
    systems: a review Article 10 May 2023 Introduction Pastures account for about
    70% of the world’s agricultural land (Squires et al., 2018) and provide essential
    sources of high-quality forage for ruminants (Bouwman et al., 2005). Thus, pastures
    assume a key role in nourishing a growing global population with dairy and meat
    products (Henchion et al., 2017; Tripathi et al., 2018). Moreover, grasslands
    fulfill ecosystem services such as carbon storage and habitat conservation; hence,
    they help mitigate climate change and preserve biodiversity (O’Mara, 2012; Zhao
    et al., 2020). Pasture management is being challenged by increasing competition
    between forage and energy crops (Donnison & Fraser, 2016), land sealing due to
    infrastructure and housing, greater yield volatility due to climate change (Hopkins
    & Del Prado, 2007), and stronger constraints on fertilization (Buckley et al.,
    2016). Against this backdrop, accurate and reliable information about future pasture
    yields gains importance for agricultural management. These yield predictions can
    support the decision-making processes regarding fertilization, pest control, irrigation,
    stocking rates, and mowing. Overall, accurate yield predictions allow more efficient
    use of all inputs, resulting in less environmental impact and greater profits
    for farmers (Hedley, 2015; Kent Shannon et al., 2018). Machine learning-based
    optical sensing has become the prevailing approach to predictive modeling for
    pasture yields. In this approach, past observational data is analyzed to learn
    a mapping function between pasture characteristics and biomass at harvest. This
    function is used to predict the biomass for pasture characteristics obtained via
    sensors at a future time. Predictive modeling using machine learning (ML) takes
    advantage of significant improvements in technology for optical sensing (Adão
    et al., 2017; Zeng et al., 2020), enhanced availability of field data at different
    levels of granularity (Murphy et al., 2021), and greater performance of the underlying
    ML algorithms. The importance of MLbased optical sensing for pasture yield prediction
    is reflected in the high number of studies in recent years. Evidence for the effectiveness
    of ML-based predictive modeling has increased. The evidence concerns different
    grass species, such as perennial ryegrass (Lolium perenne) (Nguyen et al., 2022),
    signalgrass (Brachiaria) (Bretas et al., 2021), and clover (Trifolium pratense)
    (Li et al., 2021), and different types of optical sensors, including portable
    spectroradiometers (Murphy et al., 2022), sensors mounted on unmanned aerial vehicles
    (UAVs) (van der Merwe et al., 2020), and carried by satellites (Bretas et al.,
    2021). This variety converges with a broad set of ML techniques that developers
    can adopt. Developers must select techniques for the transformation of input data
    into features, the training of prediction models from past observations of input
    data and biomass, and the evaluation of the trained models on new observations.
    To inform these decisions on the development of prediction models, insights into
    the effectiveness of specific ML techniques are required. Notwithstanding the
    increased evidence base, the understanding of the effectiveness of specific ML
    techniques is still limited. Regarding the types of optical sensor data, a previous
    review found better performance for prediction models that were trained on in-field
    imagery compared to models that processed satellite data (Morais et al., 2021).
    However, about half of the included studies examined non-managed grasslands, such
    as steppe, semiarid grassland, bunchgrass, and shrub on drylands; hence, the finding
    cannot necessarily be generalized to prediction models for pasture yield. Two
    literature reviews focused on UAVs so that the results do not extend to models
    trained on data from field spectroradiometers and satellites (Bazzo et al., 2023;
    Lyu et al., 2022). Another review had a broader scope by including studies that
    collected non-optical sensor data (Murphy et al., 2021). One related review only
    provided aggregated information but no results at the study level (Subhashree
    et al., 2023). Collectively, the burgeoning field of pasture yield prediction
    using ML-based optical sensing calls for the assessment of current evidence to
    facilitate the development of prediction models. To address this need, we conducted
    a systematic review that is conceptually guided by the ML process. Specifically,
    the objectives are to: (1) determine the adoption of ML-based optical sensing
    in previous research examining yield prediction for pasture management, (2) collate
    the performance results, and (3) propose recommendations for future research and
    the reporting of studies. Method We conducted a systematic review of studies and
    report the results based on the PRISMA (Preferred Reporting Items for Systematic
    Reviews and Meta-Analyses) guidelines, where applicable (Moher et al., 2009).
    To ensure the reliability of the coding, three authors independently screened
    the identified records, assessed the full-text articles for eligibility, and extracted
    data from the selected studies. Eligibility criteria We included studies that
    applied machine learning on data obtained from optical sensing for predicting
    the yield of pastures, with yield defined as the current or future biomass of
    a specific pasture area, such as a plot, paddock, or field. The studies were required
    to report empirical results from the processing of real-world data. We focused
    on studies in refereed journals and written in English. The time interval of the
    past eight years (2015-01-01 through 2022-10-26) allowed us to assess studies
    that benefit from advances in ML and optical sensors in recent years, and thus
    have high relevance for research and practice. Studies were excluded if any of
    the following criteria were met: (1) dependent variable not related to a managed
    pasture but a different crop, nature conservation, biodiversity, or grassland
    coverage; (2) no prediction of yield but a different variable (e.g., nutrients,
    sward composition); (3) no predictive modeling but explanatory modeling or conceptual
    research; (4) no use of machine learning; (5) no processing of real-world data;
    and (6) no use of data from optical sensing (e.g., exclusively weather data).
    Information sources and search We identified articles through an automated search
    of journal articles published between January 1, 2015, and October 26, 2022. The
    search used the electronic database Scopus, which is the largest database of scientific
    literature and has larger coverage of peer-reviewed literature than the Web of
    Science (Mongeon & Paul-Hus, 2016; Singh et al., 2021; Thelwall & Sud, 2022).
    We designed the search query to cover the wide variety of terminology found in
    the literature. The search query had four concatenated components for pasture,
    yield, prediction, and machine learning. The pasture was represented as follows:
    (pasture* OR forage* OR grassland* OR *grass OR herbage* OR meadow*). Yield was
    covered by the following term: (yield OR biomass OR agb OR “herbage mass” OR “pasture
    mass” OR “grassland production” OR “forage production” OR quantity). The prediction
    component included different words as follows: (predict* OR assess* OR estimat*
    OR forecast*). Machine learning was represented by abstract terms and specific
    algorithms as follows: (“machine learning” OR “deep learning” OR “support vector”
    OR “random forest*” OR “neural network” OR “partial least square*” OR “predict*
    model*” OR “regression model”). Study selection We ensured the reliability of
    the study selection through the following procedure. We defined a codebook that
    provided the eligibility and exclusion criteria. The codebook was used in the
    screening phase by three authors who independently coded the first nine articles
    based on the title, abstract, and keywords. The coders met to compare their codes
    and resolve any conflicting codes through discussion. The coding commenced with
    the remaining articles. Once all articles were coded and discussed, we downloaded
    the full texts of the articles that passed the screening. The assessment of the
    full texts employed the same codebook and was organized in two rounds of coding
    and resolving disagreements. Data collection process The data collection for the
    included studies was carried out by the same three authors, who independently
    filled in an Excel spreadsheet form for 96 data items per article. The data items
    operationalize the conceptual framework described in the following section. All
    individual codes were compared in two rounds in which disagreements were resolved
    through discussion and consensus. Data items Figure 1 illustrates the conceptual
    model of the review based on the process of predictive modeling using machine
    learning. This process begins with the prediction problem and ends with the evaluated
    prediction model. The figure also denotes the principal data items that we collected
    during the review. Fig. 1 Process and principal data items for pasture yield prediction
    Full size image Forecasting the yield of pastures based on optical sensor data
    recorded during the vegetation period represents the prediction problem. Plant
    species are pasture plants that are cultivated and constitute the sward composition
    for which the prediction is made. Grazing indicates whether the pasture is grazed
    by animals or managed by machinery for forage conservation. Country denotes the
    location where the study was conducted. The process shown in Fig. 1 defines four
    phases, which we discuss in the following paragraphs. Data collection includes
    the creation of a data set by recording prediction-relevant data of the pasture
    vegetation and the observed yield at the time of harvest. Study conditions describe
    the number of fields, sample plots, and seasons for which these data were recorded.
    A sample plot is defined as the smallest partial area from which an independent
    sample of biomass is collected by cutting. Studies vary in the number of plots
    per field as well as in the size of plots, which usually range from 0.25 m2 to
    a handful of square meters. The input data can be classified into the following
    groups: vegetation indices calculated from spectral measurements (Xue & Su, 2017);
    spectral bands taken from imagery; textural features as properties of the surface
    calculated based on the Grey Level Co-occurrence Matrix (GLCM) method (Haralick
    et al., 1973); sward height above the ground; weather data (e.g., precipitation,
    temperature) (Yao et al., 2022); site data (e.g., soil type, angle); and agronomic
    data (e.g., fertilizer input, irrigation, grazing rotation, stocking rates, species
    selection, and pest and weed control) (Smit et al., 2008). Another classification
    of input data is based on the dichotomy of biotic and abiotic factors affecting
    plant growth (Lange et al., 2014). Biotic factors refer to living organisms, such
    as grazing animals, insects, microorganisms, and other plants that influence pasture
    production (Kallenbach, 2015; Klaus et al., 2013). Abiotic factors encompass non-living
    elements, such as soil composition, temperature, water supply, and global radiation
    that determine plant growth (Baldocchi et al., 2004; Sorkau et al., 2018). A sound
    knowledge of biotic factors, abiotic factors, and their complex interactions helps
    to develop effective prediction models, although the conceptual differences between
    explanatory and predictive modeling need to be considered (Shmueli, 2010). Optical
    sensors for gathering input data can be categorized as follows. In-field sensors
    operate near the ground and foremost include field spectroradiometers for obtaining
    reflectance data, such as vegetation indices and chlorophyll content of plants,
    but also laser scanners, such as LiDAR (Light Detection and Ranging), to create
    a 3D map of the pasture. Aerial sensors are mounted on an aircraft or unmanned
    aerial vehicle (UAV) to collect high-resolution imagery from a low flying height
    (Feng et al., 2021); they include hyperspectral, multispectral, and RGB cameras
    as well as thermal sensors and LiDAR sensors. Satellite remote sensing enables
    to record vegetation reflectance from the orbit. Data preprocessing is the second
    phase, which produces so-called features from the input data. Features represent
    characteristics of the empirical phenomenon on which a prediction model can be
    learned. Including all input data as features in the prediction model incurs the
    risk of learning from noise in the data and lacking in prediction performance.
    For this reason, feature selection provides different techniques for identifying
    smaller sets of features. The techniques are usually grouped into three categories
    (Chandrashekar & Sahin, 2014): (1) Filter-based techniques select features based
    on a metric calculated for each feature. For instance, correlation analysis can
    identify pairs of highly correlated features from which only one feature will
    be retained. Another technique is principal component analysis (PCA), which transforms
    a set of strongly correlated features into a smaller set. (2) Wrapper-based techniques
    remove one or more features from the initial set by iteratively training and evaluating
    alternative prediction models. For instance, backward elimination starts with
    the full set of features and removes features based on pvalues passing a specific
    threshold (in case of multiple linear regression). (3) Embedded techniques are
    specific to an ML algorithm. One example is Random Forests feature selection,
    which calculates the so-called feature importance metric and then removes features
    that do not pass a threshold for the metric. The third phase is model training
    in which example observations are used to learn a function that best maps a set
    of feature values to the corresponding observed yield; these examples are also
    referred to as input-output pairs. For estimating the mapping function, the field
    of supervised machine learning provides a large variety of ML algorithms. Frequently
    used algorithms for predicting pasture yields include Random Forests (RF) (Ho,
    1995), Artificial Neural Networks (ANN) (Bishop, 2006), and Support Vector Regression
    (SVR) (Drucker et al., 1996) but also different types of linear regression, such
    as ordinary least squares (OLS) and partial least squares (PLS) regression. All
    these algorithms require a sufficiently large training set that includes a number
    of examples. Model evaluation is the final phase, which assesses the prediction
    performance of a trained model. Because of the many design alternatives to choose
    from in the preceding phases, developers usually evaluate alternative prediction
    models through experiments in which one or more factors are manipulated. By conducting
    factorial experiments, developers can devise a variety of experimental conditions,
    gain insights into how the factors affect performance, and eventually identify
    the best-performing model. Irrespective of the experimental design, evaluation
    calls for testing the prediction model on new observations, thus observations
    that were not included in the training phase. The evaluation can be accomplished
    using cross-validation, a test set, or both techniques. In cross-validation (CV),
    the data set is iteratively divided into subsets for training and testing. For
    instance, k-fold CV divides the data set into k subsets (folds) of equal size,
    trains a model for each combination of k-1 folds, evaluates the model on the left-out
    fold, and reports the mean performance for all k models. In other words, in each
    iteration, one fold is left out of the training set. Another type of CV is leave-one-out,
    which trains the model using all but one observation and tests the model on the
    left-out observation. The training and testing must be repeated n times, with
    n standing for the total number of observations. Different from CV, a test set
    indicates a technique that uses a separate data set of new observations. Either
    technique can apply performance metrics to quantify the accuracy of predicted
    vis-á-vis observed yields. Metrics for yield predictions include, for instance,
    the coefficient of determination (R2), the root mean square error (RMSE), the
    normalized RMSE (NRMSE), and the mean absolute error (MAE). The report on prediction
    performance can be supplemented by information on so-called feature importance,
    i.e., a quantitative assessment of the extent to which individual features have
    contributed to the prediction performance. Various techniques are available for
    measuring importance, for example, by indicating how a specific performance metric
    would change in absolute or relative terms if the feature in question were removed.
    Other techniques specify importance as a percentage value, summing to 100% for
    all features. Such information is typically presented in column charts or placed
    in tabular appendices. Results Study selection Figure 2 shows the PRISMA flow
    chart of study selection. A total of 591 records were identified through database
    searching. We considered two additional studies that reported prediction models
    for pasture yield using optical sensing; the studies were listed in Scopus, but
    their records were not automatically retrieved. Of the 91 articles that were forwarded
    to the full-text assessment, 43 articles fulfilled the eligibility criteria, and
    these studies were included in the review. Fig. 2 PRISMA flow chart Full size
    image Table 1 shows an overview of the included studies. The most frequently studied
    plants were perennial ryegrass (14 studies, Lolium perenne), clover species (8,
    Trifolium), signalgrass (5, Brachiaria), and timothy (4, Phleum pratense). Twenty-five
    of the pastures were mechanically harvested, and the remaining pastures were grazed
    by animals. Twenty-two studies were conducted in Europe, nine in Australia, six
    in South America, and four in North America, whereas only each one study was carried
    out in Africa and Asia. Predictions were always made right before harvest or very
    near to that day, except for three studies that used prediction horizons of 13
    days (Schwieder et al., 2020), 38 days (Li et al., 2021), and 152 days (Hamada
    et al., 2021), respectively. Table 1 Overview of the studies (N = 43) Full size
    table Data collection Table 2 provides the number of fields, sample plots, and
    seasons, followed by the different types of input data. Almost half of the studies
    were limited to data from a single field. The number of sample plots ranged from
    only two to more than one thousand (mean: 114; median: 54; n = 35). Two-thirds
    of the studies collected data in one growing season, and every fifth study covered
    two seasons. Two studies even covered eight (Jaberalansar et al., 2017) and twelve
    seasons (Ali et al., 2017), respectively. Twothirds of the studies were conducted
    at research facilities and one-third on fields operated by farmers (not tabulated).
    Vegetation indices were processed as input data in 29 studies. The number of VIs
    spanned from one index in four studies to more than 20 indices in eight studies.
    Sward height was used in 19 studies and it was either measured by UAV (13 studies),
    rising plate meter (3), LiDAR (1), meter ruler (1), or satellite (1). Nineteen
    studies processed spectral bands, which exhibited large variability between 2
    and 2150 different bands. In three studies, vegetation indices were complemented
    with textural features. All other types of input data played a minor role. Specifically,
    five studies used weather data, two studies considered site data (e.g., soil type,
    elevation, slope, and aspect), and only one study integrated fertilizer input
    as agronomic data (Franceschini et al., 2022). No study learned a model based
    on biotic data. Table 3 summarizes the adoption of the different types of optical
    sensors. Fourteen studies obtained data from in-field sensors, which included
    spectroradiometers (12 studies). Twenty-four studies collected input data from
    cameras mounted on aerial vehicles; the cameras recorded RGB images (11 studies),
    multispectral images (13), and hyperspectral images (5). Thirteen studies retrieved
    image data from satellites, including Sentinel (9 studies), MODIS (3), PlanetScope
    (2), Landsat (1), PlanetDove (1), and WorldView (1). Table 2 Data collection in
    the included studies (N = 43) Full size table Table 3 Optical sensors used in
    the included studies (N = 43) Full size table Data preprocessing Table 4 reports
    the adoption of feature selection techniques and provides the number of features
    per study. Feature selection was present in 24 studies, and the most frequent
    techniques were correlation analysis (8 studies), PCA (8), and stepwise regression
    (4). The number of features ranged between 1 and 101, although eight studies did
    not report this information. On one hand, four studies spared out feature selection
    but collected sensor data for a single feature. On the other hand, 18 studies
    trained models from at least 10 different features. Table 4 Feature selection
    techniques and number of features in the included studies (N = 43) Full size table
    Model training Table 5 provides information about the adoption of 16 different
    ML algorithms. The most frequent algorithms were Random Forests (20 studies),
    PLS regression (13), OLS regression using a single predictor (10) or multiple
    predictors (8), and Support Vector Regression (8). The size of the training set
    was stated in 41 studies, which either reported the number of examples, a percentage
    value of the examples used, or both types of information (not tabulated). In 10
    studies, the prediction models were trained on less than 100 examples. Table 5
    Machine-learning algorithms in the included studies (N = 43) Full size table Model
    evaluation Experimental manipulation Table 6 shows the frequency of each manipulated
    factor. The most frequent factors were feature set (19 studies) and ML algorithm
    (17). The former studies compared the performance of prediction models using different
    combinations of features, such as vegetation indices, spectral bands, sward height,
    and weather features. Nine studies investigated alternative sensors (e.g., UAV
    versus satellite). Six further factors were only examined in one study each. The
    number of manipulated factors per study was either one (16 studies), two (15),
    or three (2), whereas no manipulation was present in ten studies. Table 6 Manipulated
    factors in the included studies (N = 43) Full size table Model assessment Table
    7 shows the adoption of cross-validation and test set as techniques for model
    assessment. Twelve studies were limited to cross-validation, and another 13 studies
    only used a test set including new observations. The remaining 18 studies applied
    both techniques. Table 7 Model assessment in the included studies (N = 43) Full
    size table We note that the application and reporting of cross-validation exhibit
    large variation by leaving out one fold (19 studies), one example (7), or one
    site (1) in the training phase, whereas four studies provided no information in
    that respect. Regarding the test set, 29 of the 31 studies reported its size as
    a percentage of the whole data set. The number of examples ranged between 10 and
    433. Six studies had very small test sets with at most 24 examples, but ten studies
    had much larger test sets with more than one hundred examples. Performance metrics
    Table 8 reveals that R2 was reported in all but five studies. Thirty studies provided
    the root mean square error in kg per ha. Unitless normalizations of the RMSE were
    present in 25 studies. This normalization was either based on the mean (11 studies),
    range (4), standard deviation (2), and interquartile range (1) of the observed
    yield, or its specification was missing (7). Table 8 Performance metrics reported
    in the included studies (N = 43) Full size table Performance by types of optical
    sensors The high adoption rate of the unitless R2 metric allowed us to collate
    performance results as shown in Fig. 3, which groups 41 prediction models by the
    types of optical sensors used. The R2 ranged between 0.42 and 0.90 in the satellite
    group, between 0.50 and 0.94 in the aerial sensors group, and between 0.62 and
    0.92 in the in-field sensors group. The range was even smaller for the few prediction
    models that complemented in-field data by satellite data (0.71 to 0.90) and UAV
    data (0.81 to 0.92), respectively. Similarly, the mean performance in the in-field
    (0.79) and aerial groups (0.77) was higher than for the satellite (0.67) group.
    Two studies that processed data from aerial sensors and satellites at the same
    time reported R2 values of 0.70 (Pereira et al., 2022) and 0.72 (Barnetson et
    al., 2021), respectively (not shown in Fig. 3). Fig. 3 R2 of 41 prediction models
    by the types of optical sensors used (dots with filling indicate R2 on the test
    set, dots without filling stand for cross-validation) Full size image Feature
    importance Seventeen studies provided information on the importance of features.
    As shown in Table 9, many different techniques have been adopted, including variable
    importance in projection (Chong & Jun, 2005) and increase in RMSE (Kuhn, 2008).
    Six studies reported on the importance but lacked a specification of the technique
    used. In fifteen studies, only features based on spectral data were assessed (which
    is consistent with the focus on spectral variables in the data collection). In
    one study, the highest feature importance was assigned to canopy height (Schucknecht
    et al., 2022), and another study found that the relative importance of three weather
    features was one third, while three vegetation indices contributed two thirds
    (Bretas et al., 2021). Table 9 Techniques for feature importance reported in the
    included studies (N = 43) Full size table Discussion This review examined the
    adoption of machine-learning techniques for pasture yield prediction using optical
    sensor data. We analyzed forty-three studies that have been published in journals
    between 2015-01-01 and 2022-10-26. This section discusses the principal findings
    of the review and draws implications for future research and the reporting of
    studies. We also discuss the limitations of our review. Data collection For assessing
    the reliability of a trained prediction model, the number of fields, plots, and
    seasons are important factors that determine the size of the training set. These
    numbers can provide indications of how far the temporal and spatial variability
    of pasture yields have been considered in the data collection. Yet, more than
    half of the studies were conducted in one season, which restricts the training
    data to specific weather and growing conditions. One-third of the studies were
    limited to data from one field in one season. Even in the latter group of studies,
    the number of sample plots exhibited an enormous span from 21 to 1080. The chances
    that a model will perform similarly in future seasons can be enhanced by training
    the model on multi-seasonal data of different fields in which many plots capture
    the in-field variability. However, this approach puts a burden on researchers
    and farmers because the required effort for data collection increases significantly.
    The restriction of many studies to a single field limits the applicability of
    the trained models to a local level; hence, conclusions about their prediction
    performance beyond the specific field cannot be drawn. Three approaches are feasible
    to develop global models. First, data from a larger number of fields from different
    regions can be collected to develop models from data of greater heterogeneity.
    Second, data representing biotic and abiotic factors can be integrated to represent
    a larger set of growing conditions, thereby incorporating these factors into the
    development. A third possibility is to train a global prediction model by integrating
    multiple local models, i.e., the reuse of training data from different local sources
    (Liu et al., 2022). The included studies do not inform developers about the minimum
    size of the training set to achieve a reasonable level of prediction performance.
    One study manipulated the size but it found only marginal effects on performance
    (Rosa et al., 2021). The results of our review highlight that little is known
    about how to specify the size of the training set. This finding points to the
    need for further examination of the relationship between the training set and
    prediction performance. A common theme in the studies is the application of features
    derived from optical data, namely VIs (29 studies), spectral bands (19), textures
    (19), and sward height (15). Most studies collected data from at least two different
    types and considered multiple input variables, either alternatively or supplementary.
    The focus is on exploiting the potential of optical sensing and techniques for
    transforming image data into variables that are associated with plant growth.
    Therefore, it is not surprising that the number of VIs (1 to 97), spectral bands
    (2 to 2150), and textures (8 to 32) varied considerably across studies. It is
    noteworthy that the most frequent approach for measuring the sward height was
    UAV, which has substituted the manual measurement using hand-held devices. Consistent
    with the large array of VIs, spectral bands, textures, and sward height variables
    collected in combination, the types of optical sensors used indicate comprehensive
    coverage of current sensor technologies. All other types of input data, such as
    weather data (5 studies), site data (2), and agronomic data (1) played a minor
    role. This finding is surprising in view of the fact that such data can be obtained
    with relatively little effort or are already available. For instance, the retrieval
    of weather data is facilitated by online portal and programming interfaces (Jaffrés,
    2019). Historic and current weather data specifically for agricultural purposes
    are offered by companies, national meteorological agencies, and agricultural departments
    (Farmers Guide, 2022). Site and agronomic data are increasingly recorded by farmers
    and processed in digital farm management information systems. These data represent
    a so far hardly exploited potential for supplementing the spectral data and thus
    for training even more accurate prediction models. Data preprocessing Given the
    often-high dimensionality of the optical input data used, the objective of data
    processing is to reduce the number of features derived from the input data. This
    dimensionality is foremost due to the large number of VIs and spectral bands in
    many studies. The results of our review provide evidence for the relevance of
    feature selection, which was present in more than half of the studies (it was
    not relevant for four studies that collected data for a single feature). Overall,
    the techniques used span across filter-based, wrapper-based, and embedded techniques,
    and reflect the variety of techniques available from the ML literature. In many
    studies, the number of features was effectively reduced without increasing the
    error of prediction. For instance, one study started with a set of 20 VIs and
    eventually selected one VI based on correlation analysis (Hamada et al., 2021).
    Another study considered 2150 different spectral bands obtained from a hand-held
    spectroradiometer and then performed stepwise regression using backward elimination
    to arrive at a linear model with only seven features (Zeng & Chen, 2018). Similarly,
    a study by Chiarito et al. (2021) applied a genetic algorithm to an initial set
    of 1024 spectral bands to choose a 13-feature model. Concerning the final set
    of features processed in the training phase, our review identified six studies
    in which the lack of feature selection led to models trained from at least 26
    features (Grüner et al., 2020; Karunaratne et al., 2020; Lussem et al., 2022;
    Näsi et al., 2018; Pranga et al., 2021; Schucknecht et al., 2022). For these studies,
    it might be possible that a model with fewer features exists that would perform
    similarly. Therefore, we recommend exploring the impact of feature selection on
    prediction performance when the model was trained on a large number of features
    derived from optical data. For studies that adopt a hypothetico-deductive approach
    to the model development, we suggest determining the relative importance of each
    feature and relating the results back to the model development. We also note that
    almost one-fifth of the studies provided no information on the number of features.
    Presenting complete information on the features included in the trained model
    would help assess the input data that necessarily must be collected and data that
    can be omitted. This information can effectively be reported in a table showing
    each feature along its unit of measurement and definition (Chen et al., 2021).
    In case the number of features exceeds the possibilities of a table, the information
    can be summarized by indicating the numbers per type of sensor as well as the
    initial and final numbers (Schulze-Brüninghoff et al., 2021). Model training The
    highest adoption rates were found for Random Forests, PLS regression, and OLS
    regression, whereas only four studies used Artificial Neural Networks. It is noteworthy
    that PLS regression was employed in 13 studies. PLS regression is a form of multiple
    linear regression in which the number of initially used independent variables
    can automatically be reduced by an in-built principal component analysis to a
    smaller set of features. Therefore, PLS regression appears specifically relevant
    for the training from spectral input data, while it still assumes linear relationships
    between the features and the pasture yield. However, two studies that compared
    the performance of PLS and MLR models reported conflicting results concerning
    the R2 metric (Askari et al., 2019; Borra-Serrano et al., 2019). Regarding the
    performance of linear vis-á-vis non-linear models, four studies found better performance
    for non-linear models, but three other studies came to the opposite conclusion.
    Overall, the results of our review suggest no evidence for the superiority of
    any group of learning algorithms. Forty studies stated the size of the training
    set, which varied greatly because of the different numbers of fields, sampling
    plots, and seasons between studies. This size must be seen in the context of the
    temporal and spatial variability of the specific pasture under study. If a prediction
    model is learned from too few observations that do not sufficiently represent
    this variability, the model will perform very differently for other test data.
    Our review identified two studies that had very small training sets of 32 (Näsi
    et al., 2018) and 36 observations (Li et al., 2021), respectively. Although no
    clear guidance is available for determining the minimum size required, it can
    give readers a hint about the reliability of the prediction model. Therefore,
    we suggest reporting complete and unequivocal information on the training and
    test sets used. The reporting should always include the absolute and relative
    numbers for each data set. For instance, this information can be visualized in
    a flow diagram that specifies the data processing (Murphy et al., 2022), or provided
    in a single sentence, such as the following: “the complete dataset was first divided
    into two parts in a 70:30 ratio (231 observations for the training dataset and
    99 observations for the test dataset)” (Da Silva et al., 2022, pp. 6039–6040).
    Moreover, any removal of observations throughout the preprocessing and learning
    phases should be justified, instead of generally referring to so-called outlier
    removal. Model evaluation Insights into the role of specific ML techniques for
    achieving high performance can be obtained from systematic testing of alternative
    models. The preferred method is the controlled experiment in which one or more
    factors are manipulated (33 of 43 studies). Our review identified feature sets,
    ML algorithms, and optical sensors as the most frequently used factors. The relevance
    of feature sets and sensors can be explained by the range of input data to capture
    the temporal and spatial variability of pasture yields. The evaluation should
    be conducted in a way that can mitigate the overfitting of a learned prediction
    model. A model is said to overfit if it fits well to the training set but exhibits
    much lower performance on new observations. For instance, it might be possible
    that a model that has been trained on a rich set of sensor data collected from
    several fields in different seasons will perform much worse for a different field
    or in a future season. To address the overfitting problem, cross-validation is
    appropriate for situations in which the total number of observations is insufficiently
    large to divide them into training and test sets. Different types of cross-validation
    are available, and they have been adopted in several ways. With respect to k-fold
    CV, the number of folds ranged between 3 and 20, with no study providing a rationale
    for the number chosen. This deficit also holds for the number of iterations of
    a CV; iterations were present in seven studies, and they spanned from only 5 to
    1000. Leave-one-out CV must be regarded as the weakest type of CV because it likely
    overstates the prediction performance for extremely small ratios of new observations,
    such as 1080:1 in one study (Sibanda et al., 2017). Almost three-fourths of the
    included studies assessed performance on a separate test set, instead of solely
    relying on cross-validation. Two studies stand out that trained models in one
    season (Togeiro de Alckmin et al., 2022) or two seasons (Murphy et al., 2022)
    to evaluate them in the subsequent season. Another study performed the evaluation
    on test data from a different field in the same season (de Oliveira et al., 2020).
    The size of the test set was most often stated explicitly in a table or text in
    the results section. For some articles, the size could be derived from a percentage
    value in relation to the entire data set. In seven other studies, the reporting
    in that respect was incomplete or inconsistent, but we could determine the number
    of observations through counting of dots shown in scatter plots. In a similar
    vein as for the training set, we recommend specifying the test procedure including
    the absolute and relative number of observations, any further data cleansing that
    led to the removal of observations, and the number of runs (if relevant). Regarding
    the reporting of performance metrics, our review provides three major findings
    that have implications for the interpretation of study results. The first finding
    is the relatively high adoption of the R2 (91%), followed by the RMSE (71%). Because
    R2 is a unitless metric, it can in principle help compare the performance of different
    models that predict the same type of pasture yield. Its interpretation is less
    dependent on the study context compared to the RMSE. The latter metric is more
    informative for farmers of the specific fields from which the observations had
    been collected and it can help assess how useful the prediction model is compared
    to current means of yield prediction. However, the RMSE cannot be used to compare
    models that have been trained on different observations. In other words, any claim
    about a proposed model that its RMSE would be smaller than that of a model proposed
    in previous research must be taken with great caution. In view of the duality
    of metrics that serve very different purposes, we contend that there is no reason
    not to report the R2 and RMSE. The second finding concerns the heterogeneity and
    ambiguity of the normalized RMSE. Given that the NRMSE was reported in more than
    half of the studies, this unitless metric might be used for comparing the results
    of similar studies. Unfortunately, we identified at least four different definitions,
    which render the comparison of results impossible. Only eleven studies reported
    the RMSE divided by the mean observed yield. This definition might be regarded
    as the ‘common’ meaning of the NRMSE, but seven studies provided no further details.
    This practice is questionable because readers might assume a definition that is
    different from the calculation done in the study. To make matters worse, the abstracts
    of 14 studies only indicated the NRMSE but not its exact definition. Moreover,
    different designations were used including NRMSE, nRMSE, relative RMSE (rRMSE),
    RRMSE, RMSE%, and RMSE with a percentage value. Taken together, our finding highlights
    the need for greater clarity in the reporting to avoid misinterpretations of the
    NRMSE. The third finding is the lack of consensus regarding the reporting of metrics
    to comprehensively describe prediction performance. The three most commonly used
    metrics (R2, RMSE, and NRMSE) were only reported in one-third of the studies.
    The frequencies of metrics such as MAE (10), Lin’s concordance correlation coefficient
    (2), Willmott’s d (2), and mean average percentage error (1) were negligible,
    although other literature has highlighted the usefulness of these supplementary
    metrics (Chai & Draxler, 2014; Willmott & Matsuura, 2005). Irrespective of the
    advantages and disadvantages of specific metrics, we recommend reporting a larger
    set of metrics, including but not limited to the R2, RMSE, and NRMSE. Because
    of the large heterogeneity in the reporting of metrics discussed above, our analysis
    of prediction performance by the types of optical sensors used was limited to
    the R2 metric reported for 41 prediction models from 36 studies. We found that
    the variability of R2 decreased for smaller distance from the pasture sward; thus,
    the largest variability was observed for models trained from satellite data and
    it decreased considerably for aerial sensors and in-field sensors. These results
    suggest that the higher spatial and temporal resolution of in-field imagery can
    make a difference in the training of effective models. Although the individual
    contribution of specific features to prediction performance can be determined
    using feature importance, this was the case in only 17 studies. All but two of
    these studies focused on features derived from spectral data. Therefore, there
    is yet little evidence for the roles of biotic versus abiotic features, including
    weather, site, and agronomic features. The results of previous studies using optical
    sensing do not inform us about the influence of such features on the accuracy
    of models. Opportunities exist to examine the supplementing roles of non-spectral
    features, especially of those features for which data collection is relatively
    easy or the data is already available from the farmers. Collectively, the results
    of our review also highlight challenges for prediction models to become less local
    and increasingly global. Especially the large differences of pastures regarding
    soil properties, weather conditions, and plant species make the development of
    generalizable prediction model challenging. The collection of data reflecting
    biotic and abiotic factors is not possible by remote sensing alone. To develop
    more globally applicable models, it is necessary to include data from complementary
    sources (e.g., weather stations, soil analysis, and farm management information
    systems). Limitations The results of this review should be understood in light
    of its limitations. The included studies varied greatly in the processing of input
    data and how prediction models were trained. Therefore, it was not possible to
    conduct in-depth comparisons of performance results, except for the types of optical
    sensors used. Another limitation of the review is due to the large heterogeneity
    of the reporting of performance metrics. This heterogeneity limited the number
    of studies for which performance results could be synthesized; this synthesis
    was only possible for the R2 but not for the NRMSE. Third, although our data collection
    involved three independent coders, all results presented in this review were bound
    to the information reported in the original studies (in a few cases, we contacted
    the authors to clarify the meaning of specific statements though). Conclusion
    This systematic review provides a comprehensive account of the application of
    ML for the prediction of pasture yield using optical sensor data. The results
    highlight the richness of techniques used for the collection and preprocessing
    of input data as well as the training and evaluation of prediction models. Our
    review also revealed some shortcomings in the assessment of prediction performance
    and the presentation of study designs and results. Specifically, we identified
    deficits in the reporting of feature sets and complete information on the training
    and test data, and a lack of consensus in the reporting of performance metrics.
    We suggest specific recommendations to enhance the uniformity and comparability
    of study results, which can then facilitate the integration of evidence on the
    role of specific ML techniques for accurate and reliable yield predictions of
    managed pastures. References Adão, T., Hruška, J., Pádua, L., Bessa, J., Peres,
    E., Morais, R., & Sousa, J. (2017). Hyperspectral imaging: A review on UAV-based
    sensors, data processing and applications for agriculture and forestry. Remote
    Sensing, 9(11), 1110. https://doi.org/10.3390/rs9111110. Article   Google Scholar   Ali,
    I., Cawkwell, F., Dwyer, E., & Green, S. (2017). Modeling managed grassland biomass
    estimation by using multitemporal remote sensing data—a machine learning approach.
    IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing,
    10(7), 3254–3264. https://doi.org/10.1109/JSTARS.2016.2561618. Article   Google
    Scholar   Askari, M. S., McCarthy, T., Magee, A., & Murphy, D. J. (2019). Evaluation
    of grass quality under different soil management scenarios using remote sensing
    techniques. Remote Sensing, 11(15), 1835. https://doi.org/10.3390/rs11151835.
    Article   Google Scholar   Baldocchi, D. D., Xu, L., & Kiang, N. (2004). How plant
    functional-type, weather, seasonal drought, and soil physical properties alter
    water and energy fluxes of an oak–grass savanna and an annual grassland. Agricultural
    and Forest Meteorology, 123(1–2), 13–39. https://doi.org/10.1016/j.agrformet.2003.11.006.
    Article   Google Scholar   Barnetson, J., Phinn, S., & Scarth, P. (2021). Climate-resilient
    grazing in the pastures of Queensland: An integrated remotely piloted aircraft
    system and satellite-based deep-learning method for estimating pasture yield.
    AgriEngineering, 3(3), 681–703. https://doi.org/10.3390/agriengineering3030044.
    Article   Google Scholar   Bazzo, C. O. G., Kamali, B., Hütt, C., Bareth, G.,
    & Gaiser, T. (2023). A review of estimation methods for aboveground biomass in
    grasslands using UAV. Remote Sensing, 15(3), 639. https://doi.org/10.3390/rs15030639.
    Article   Google Scholar   Bishop, C. M. (2006). Pattern recognition and machine
    learning. Springer. Borra-Serrano, I., de Swaef, T., Muylle, H., Nuyttens, D.,
    Vangeyte, J., Mertens, K., Saeys, W., Somers, B., Roldán-Ruiz, I., & Lootens,
    P. (2019). Canopy height measurements and non‐destructive biomass estimation of
    Lolium perenne swards using UAV imagery. Grass and Forage Science, 74(3), 356–369.
    https://doi.org/10.1111/gfs.12439. Article   Google Scholar   Bouwman, A. F.,
    van der Hoek, K. W., Eickhout, B., & Soenario, I. (2005). Exploring changes in
    world ruminant production systems. Agricultural Systems, 84(2), 121–153. https://doi.org/10.1016/j.agsy.2004.05.006.
    Article   Google Scholar   Bretas, I. L., Valente, D. S. M., Silva, F. F., Chizzotti,
    M. L., Paulino, M. F., D’Áurea, A. P., Paciullo, D. S., Pedreira, B. C., & Chizzotti,
    F. H. M (2021). Prediction of aboveground biomass and dry-matter content in Brachiaria
    pastures by combining meteorological data and satellite imagery. Grass and Forage
    Science, 76(3), 340–352. https://doi.org/10.1111/gfs.12517. Article   Google Scholar   Buckley,
    C., Wall, D. P., Moran, B., O’Neill, S., & Murphy, P. N. C. (2016). Farm gate
    level nitrogen balance and use efficiency changes post implementation of the EU
    Nitrates Directive. Nutrient Cycling in Agroecosystems, 104(1), 1–13. https://doi.org/10.1007/s10705-015-9753-y.
    Article   CAS   Google Scholar   Chai, T., & Draxler, R. R. (2014). Root mean
    square error (RMSE) or mean absolute error (MAE)? – arguments against avoiding
    RMSE in the literature. Geoscientific Model Development, 7(3), 1247–1250. https://doi.org/10.5194/gmd-7-1247-2014.
    Article   Google Scholar   Chandrashekar, G., & Sahin, F. (2014). A survey on
    feature selection methods. Computers & Electrical Engineering, 40(1), 16–28. https://doi.org/10.1016/j.compeleceng.2013.11.024.
    Article   Google Scholar   Chen, Y., Guerschman, J., Shendryk, Y., Henry, D.,
    & Harrison, M. T. (2021). Estimating pasture biomass using Sentinel-2 imagery
    and machine learning. Remote Sensing, 13(4), https://doi.org/10.3390/rs13040603.
    Chiarito, E., Cigna, F., Cuozzo, G., Fontanelli, G., Mejia Aguilar, A., Paloscia,
    S., Rossi, M., Santi, E., Tapete, D., & Notarnicola, C. (2021). Biomass retrieval
    based on genetic algorithm feature selection and support vector regression in
    Alpine grassland using ground-based hyperspectral and Sentinel-1 SAR data. European
    Journal of Remote Sensing, 54(1), 209–225. https://doi.org/10.1080/22797254.2021.1901063.
    Article   Google Scholar   Chong, I. G., & Jun, C. H. (2005). Performance of some
    variable selection methods when multicollinearity is present. Chemometrics and
    Intelligent Laboratory Systems, 78(1–2), 103–112. https://doi.org/10.1016/j.chemolab.2004.12.011.
    Article   CAS   Google Scholar   Da Silva, Y. F., Dos Reis, A., Sampaio Werner,
    A., Valadares, J. P. V., Campbell, R., Camargo Lamparelli, E. E. A., Magalhães,
    R., P. S. G., & Figueiredo, G. K. D. A (2022). Assessing the capability of MODIS
    to monitor mixed pastures with high-intensity grazing at a fine-scale. Geocarto
    International, 37(20), 6033–6051. https://doi.org/10.1080/10106049.2021.1926559.
    Article   Google Scholar   de Oliveira, R. A., Näsi, R., Niemeläinen, O., Nyholm,
    L., Alhonoja, K., Kaivosoja, J., Jauhiainen, L., Viljanen, N., Nezami, S., Markelin,
    L., Hakala, T., & Honkavaara, E. (2020). Machine learning estimators for the quantity
    and quality of grass swards used for silage production using drone-based imaging
    spectrometry and photogrammetry. Remote Sensing of Environment, 246, 111830. https://doi.org/10.1016/j.rse.2020.111830.
    Article   Google Scholar   de Oliveira, G. S., Marcato Junior, J., Polidoro, C.,
    Osco, L. P., Siqueira, H., Rodrigues, L., Jank, L., Barrios, S., Valle, C., Simeão,
    R., Carromeu, C., Silveira, E., de Castro Jorge, A., Gonçalves, L., Santos, W.,
    M., & Matsubara, E. (2021). Convolutional neural networks to estimate dry matter
    yield in a Guineagrass breeding program using UAV remote sensing. Sensors (Basel,
    Switzerland), 21(12), https://doi.org/10.3390/s21123971. De Rosa, D., Basso, B.,
    Fasiolo, M., Friedl, J., Fulkerson, B., Grace, P. R., & Rowlings, D. W. (2021).
    Predicting pasture biomass using a statistical model and machine learning algorithm
    implemented with remotely sensed imagery. Computers and Electronics in Agriculture,
    180, 105880. https://doi.org/10.1016/j.compag.2020.105880. Article   Google Scholar   Togeiro
    de Alckmin G., Kooistra, L., Rawnsley, R., & Lucieer, A. (2021). Comparing methods
    to estimate perennial ryegrass biomass: Canopy height and spectral vegetation
    indices. Precision Agriculture, 22(1), 205–225. https://doi.org/10.1007/s11119-020-09737-z.
    Togeiro de Alckmin G., Lucieer, A., Rawnsley, R., & Kooistra, L. (2022). Perennial
    ryegrass biomass retrieval through multispectral UAV data. Computers and Electronics
    in Agriculture, 193, 106574. https://doi.org/10.1016/j.compag.2021.106574. Donnison,
    I. S., & Fraser, M. D. (2016). Diversification and use of bioenergy to maintain
    future grasslands. Food and Energy Security, 5(2), 67–75. https://doi.org/10.1002/fes3.75.
    Article   PubMed   PubMed Central   Google Scholar   Dos Reis, A. A., Werner,
    J. P. S., Silva, B. C., Figueiredo, G. K. D. A., Antunes, J. F. G., Esquerdo,
    J. C. D. M., Coutinho, A. C., Lamparelli, R. A. C., Rocha, J. V., & Magalhães,
    P. S. G. (2020). Monitoring pasture aboveground biomass and canopy height in an
    integrated crop–livestock system using textural information from PlanetScope imagery.
    Remote Sensing, 12(16), 2534. https://doi.org/10.3390/RS12162534. Article   Google
    Scholar   Drucker, H., Burges, C. J. C., Kaufman, L., Smola, A., & Vapnik, V.
    (1996). Support Vector Regression Machines. In M. C. Mozer, M. Jordan, & T. Petsche
    (Eds.), Advances in neural information processing systems (Vol. 9). MIT Press.
    https://proceedings.neurips.cc/paper/1996/file/d38901788c533e8286cb6400b40b386d-Paper.pdf.
    Farmers Guide (2022). UK-wide weather station network provides data to aid agronomic
    decision making. https://www.farmersguide.co.uk/local-weather-data-aids-agronomic-decision-making/.
    Feng, L., Chen, S., Zhang, C., Zhang, Y., & He, Y. (2021). A comprehensive review
    on recent applications of unmanned aerial vehicle remote sensing with various
    sensors for high-throughput plant phenotyping. Computers and Electronics in Agriculture,
    182, 106033. https://doi.org/10.1016/j.compag.2021.106033. Article   Google Scholar   Franceschini,
    M. H. D., Becker, R., Wichern, F., & Kooistra, L. (2022). Quantification of grassland
    biomass and nitrogen content through UAV hyperspectral imagery—active sample selection
    for model transfer. Drones, 6(3), 73. https://doi.org/10.3390/drones6030073. Article   Google
    Scholar   Freitas, R. G., Pereira, F. R., Reis, D., Magalhães, A. A., Figueiredo,
    P. S. G., D., G. K. A.,do, & Amaral, L. R. (2022). Estimating pasture aboveground
    biomass under an integrated crop-livestock system based on spectral and texture
    measures derived from UAV images. Computers and Electronics in Agriculture, 198,
    Article 107122. https://doi.org/10.1016/j.compag.2022.107122. Geipel, J., Bakken,
    A. K., Jørgensen, M., & Korsaeth, A. (2021). Forage yield and quality estimation
    by means of UAV and hyperspectral imaging. Precision Agriculture, 22(5), 1437–1463.
    https://doi.org/10.1007/s11119-021-09790-2. Article   CAS   Google Scholar   Grüner,
    E., Astor, T., & Wachendorf, M. (2019). Biomass prediction of heterogeneous temperate
    grasslands using an SfM approach based on UAV imaging. Agronomy, 9(2), 54. https://doi.org/10.3390/agronomy9020054.
    Article   Google Scholar   Grüner, E., Wachendorf, M., & Astor, T. (2020). The
    potential of UAV-borne spectral and textural information for predicting aboveground
    biomass and N fixation in legume-grass mixtures. PLOS ONE, 15(6), e0234703. https://doi.org/10.1371/journal.pone.0234703.
    Article   CAS   PubMed   PubMed Central   Google Scholar   Hamada, Y., Zumpf,
    C. R., Cacho, J. F., Lee, D., Lin, C. H., Boe, A., Heaton, E., Mitchell, R., &
    Negri, M. C. (2021). Remote sensing-based estimation of advanced perennial grass
    biomass yields for bioenergy. Land, 10(11), 1221. https://doi.org/10.3390/land10111221.
    Article   Google Scholar   Haralick, R. M., Shanmugam, K., & Dinstein, I. (1973).
    Textural features for image classification. IEEE Transactions on Systems, Man,
    and Cybernetics, SMC-3(6), 610–621. https://doi.org/10.1109/TSMC.1973.4309314.
    Hedley, C. (2015). The role of precision agriculture for improved nutrient management
    on farms. Journal of the Science of Food and Agriculture, 95(1), 12–19. https://doi.org/10.1002/jsfa.6734.
    Article   CAS   PubMed   Google Scholar   Henchion, M., Hayes, M., Mullen, A.
    M., Fenelon, M., & Tiwari, B. (2017). Future protein supply and demand: Strategies
    and factors influencing a sustainable equilibrium. Foods, 6(7), https://doi.org/10.3390/foods6070053.
    Ho, T. K. (1995). Random decision forests. In Proceedings of 3rd International
    Conference on Document Analysis and Recognition (ICDAR) (pp. 278–282). IEEE. https://doi.org/10.1109/ICDAR.1995.598994.
    Hopkins, A., & Del Prado, A. (2007). Implications of climate change for grassland
    in Europe: Impacts, adaptations and mitigation options: A review. Grass and Forage
    Science, 62(2), 118–126. https://doi.org/10.1111/j.1365-2494.2007.00575.x. Article   CAS   Google
    Scholar   Jaberalansar, Z., Tarkesh, M., & Bassiri, M. (2017). Soil moisture index
    improves models of forage production in central Iran. Archives of Agronomy and
    Soil Science, 63(12), 1763–1775. https://doi.org/10.1080/03650340.2017.1296138.
    Article   Google Scholar   Jackman, P., Lee, T., French, M., Sasikumar, J., O’Byrne,
    P., Berry, D., Lacey, A., & Ross, R. (2021). Predicting key grassland characteristics
    from hyperspectral data. AgriEngineering, 3(2), 313–322. https://doi.org/10.3390/agriengineering3020021.
    Article   Google Scholar   Jaffrés, J. B. (2019). GHCN-Daily: A treasure trove
    of climate data awaiting discovery. Computers & Geosciences, 122, 35–44. https://doi.org/10.1016/j.cageo.2018.07.003.
    Article   Google Scholar   Kallenbach, R. L. (2015). Describing the dynamic: Measuring
    and assessing the value of plants in the pasture. Crop Science, 55(6), 2531–2539.
    https://doi.org/10.2135/cropsci2015.01.0065. Article   CAS   Google Scholar   Karunaratne,
    S., Thomson, A., Morse-McNabb, E., Wijesingha, J., Stayches, D., Copland, A.,
    & Jacobs, J. (2020). The fusion of spectral and structural datasets derived from
    an airborne multispectral sensor for estimation of pasture dry matter yield at
    paddock scale with time. Remote Sensing, 12(12), 2017. https://doi.org/10.3390/rs12122017.
    Article   Google Scholar   Kent Shannon, D., Clay, D. E., & Sudduth, K. A. (2018).
    An introduction to precision agriculture. In D. K. Shannon, D. E. Clay, & N. R.
    Kitchen (Eds.), Precision agriculture basics (pp. 1–12). John Wiley & Sons. https://doi.org/10.2134/precisionagbasics.2016.0084.
    Klaus, V. H., Kleinebecker, T., Prati, D., Gossner, M. M., Alt, F., Boch, S.,
    Gockel, S., Hemp, A., Lange, M., Müller, J., Oelmann, Y., Pašalić, E., Renner,
    S. C., Socher, S. A., Türke, M., Weisser, W. W., Fischer, M., & Hölzel, N. (2013).
    Does organic grassland farming benefit plant and arthropod diversity at the expense
    of yield and soil fertility? Agriculture Ecosystems & Environment, 177, 1–9. https://doi.org/10.1016/j.agee.2013.05.019.
    Article   Google Scholar   Kuhn, M. (2008). Building predictive models in R using
    the caret package. Journal of Statistical Software, 28(5), https://doi.org/10.18637/jss.v028.i05.
    Lange, M., Habekost, M., Eisenhauer, N., Roscher, C., Bessler, H., Engels, C.,
    Oelmann, Y., Scheu, S., Wilcke, W., Schulze, E. D., & Gleixner, G. (2014). Biotic
    and abiotic properties mediating plant diversity effects on soil microbial communities
    in an experimental grassland. PLOS ONE, 9(5), e96182. https://doi.org/10.1371/journal.pone.0096182.
    Article   CAS   PubMed   PubMed Central   Google Scholar   Li, K. Y., Burnside,
    N. G., Sampaio de Lima, R., Villoslada Peciña, M., Sepp, K., Yang, M. D., Raet,
    J., Vain, A., Selge, A., & Sepp, K. (2021). The application of an unmanned aerial
    system and machine learning techniques for red clover-grass mixture yield estimation
    under variety performance trials. Remote Sensing, 13(10), 1994. https://doi.org/10.3390/rs13101994.
    Liu, J., [Ji], Huang, J., Zhou, Y., Li, X., [Xuhong], Ji, S., Xiong, H., & Dou,
    D. (2022). From distributed machine learning to federated learning: A survey.
    Knowledge and Information Systems, 64(4), 885–917. https://doi.org/10.1007/s10115-022-01664-x.
    Article   Google Scholar   Lussem, U., Schellberg, J., & Bareth, G. (2020). Monitoring
    forage mass with low-cost UAV data: Case study at the Rengen Grassland Experiment.
    PFG – Journal of Photogrammetry Remote Sensing and Geoinformation Science, 88(5),
    407–422. https://doi.org/10.1007/s41064-020-00117-w. Article   Google Scholar   Lussem,
    U., Bolten, A., Kleppert, I., Jasper, J., Gnyp, M. L., Schellberg, J., & Bareth,
    G. (2022). Herbage mass, N concentration, and N uptake of temperate grasslands
    can adequately be estimated from UAV-based image data using machine learning.
    Remote Sensing, 14(13), 3066. https://doi.org/10.3390/rs14133066. Article   Google
    Scholar   Lyu, X., Li, X., [Xiaobing], Dang, D., Dou, H., Wang, K., & Lou, A.
    (2022). Unmanned aerial vehicle (UAV) remote sensing in grassland ecosystem monitoring:
    A systematic review. Remote Sensing, 14(5), 1096. https://doi.org/10.3390/rs14051096.
    Article   Google Scholar   Moher, D., Liberati, A., Tetzlaff, J., & Altman, D.
    G. (2009). Preferred reporting items for systematic reviews and meta-analyses:
    The PRISMA statement. Annals of Internal Medicine, 151(4), 264–269. https://doi.org/10.7326/0003-4819-151-4-200908180-00135.
    Article   PubMed   Google Scholar   Mongeon, P., & Paul-Hus, A. (2016). The journal
    coverage of web of Science and Scopus: A comparative analysis. Scientometrics,
    106(1), 213–228. https://doi.org/10.1007/s11192-015-1765-5. Article   Google Scholar   Morais,
    T. G., Teixeira, R. F., Figueiredo, M., & Domingos, T. (2021). The use of machine
    learning methods to estimate aboveground biomass of grasslands: A review. Ecological
    Indicators, 130, Article 108081. https://doi.org/10.1016/j.ecolind.2021.108081.
    Mundava, C., Schut, A. G. T., Helmholz, P., Stovold, R., Donald, G., & Lamb, D.
    W. (2015). A novel protocol for assessment of aboveground biomass in rangeland
    environments. The Rangeland Journal, 37(2), 157. https://doi.org/10.1071/RJ14072.
    Article   Google Scholar   Murphy, D. J., Murphy, M. D., O’Brien, B., & O’Donovan,
    M. (2021). A review of precision technologies for optimising pasture measurement
    on irish grassland. Agriculture, 11(7), 600. https://doi.org/10.3390/agriculture11070600.
    Article   Google Scholar   Murphy, D. J., O’ Brien, B., O’ Donovan, M., Condon,
    T., & Murphy, M. D. (2022). A near infrared spectroscopy calibration for the prediction
    of fresh grass quality on irish pastures. Information Processing in Agriculture,
    9(2), 243–253. https://doi.org/10.1016/j.inpa.2021.04.012. Article   Google Scholar   Näsi,
    R., Viljanen, N., Kaivosoja, J., Alhonoja, K., Hakala, T., Markelin, L., & Honkavaara,
    E. (2018). Estimating biomass and nitrogen amount of barley and grass using UAV
    and aircraft based spectral and photogrammetric 3D features. Remote Sensing, 10(7),
    1082. https://doi.org/10.3390/rs10071082. Article   Google Scholar   Nguyen, P.
    T., Shi, F., Wang, J., Badenhorst, P. E., Spangenberg, G. C., Smith, K. F., &
    Daetwyler, H. D. (2022). Within and combined season prediction models for perennial
    ryegrass biomass yield using ground- and air-based sensor data. Frontiers in Plant
    Science, 13, 950720. https://doi.org/10.3389/fpls.2022.950720. Article   PubMed   PubMed
    Central   Google Scholar   O’Mara, F. P. (2012). The role of grasslands in food
    security and climate change. Annals of Botany, 110(6), 1263–1270. https://doi.org/10.1093/aob/mcs209.
    Article   PubMed   PubMed Central   Google Scholar   Pereira, F. S., de Lima,
    J. P., Freitas, R. G., Reis, D., Amaral, A. A., Figueiredo, L., Lamparelli, G.
    K. D. A., R., & Magalhães, P. (2022). Nitrogen variability assessment of pasture
    fields under an integrated crop-livestock system using UAV, PlanetScope, and Sentinel-2
    data. Computers and Electronics in Agriculture, 193, Article 106645. https://doi.org/10.1016/j.compag.2021.106645.
    Pranga, J., Borra-Serrano, I., Aper, J., de Swaef, T., an, Ghesquiere, Quataert,
    P., Roldán-Ruiz, I., Janssens, I. A., Ruysschaert, G., & Lootens, P. (2021). Improving
    accuracy of herbage yield predictions in perennial ryegrass with UAV-based structural
    and spectral data fusion and machine learning. Remote Sensing, 13(17), 3459. https://doi.org/10.3390/rs13173459.
    Raab, C., Riesch, F., Tonn, B., Barrett, B., Meißner, M., Balkenhol, N., & Isselstein,
    J. (2020). Target-oriented habitat and wildlife management: Estimating forage
    quantity and quality of semi‐natural grasslands with Sentinel‐1 and Sentinel‐2
    data. Remote Sensing in Ecology and Conservation, 6(3), 381–398. https://doi.org/10.1002/rse2.149.
    Article   Google Scholar   Schucknecht, A., Seo, B., Krämer, A., Asam, S., Atzberger,
    C., & Kiese, R. (2022). Estimating dry biomass and plant nitrogen concentration
    in pre-alpine grasslands with low-cost UAS-borne multispectral data – a comparison
    of sensors, algorithms, and predictor sets. Biogeosciences, 19(10), 2699–2727.
    https://doi.org/10.5194/bg-19-2699-2022. Article   CAS   Google Scholar   Schulze-Brüninghoff,
    D., Wachendorf, M., & Astor, T. (2021). Remote sensing data fusion as a tool for
    biomass prediction in extensive grasslands invaded by L. polyphyllus. Remote Sensing
    in Ecology and Conservation, 7(2), 198–213. https://doi.org/10.1002/rse2.182.
    Article   Google Scholar   Schwieder, M., Buddeberg, M., Kowalski, K., Pfoch,
    K., Bartsch, J., Bach, H., Pickert, J., & Hostert, P. (2020). Estimating grassland
    parameters from Sentinel-2: A model comparison study. PFG – Journal of Photogrammetry
    Remote Sensing and Geoinformation Science, 88(5), 379–390. https://doi.org/10.1007/s41064-020-00120-1.
    Article   Google Scholar   Shmueli, G. (2010). To explain or to predict? Statistical
    Science, 25(3), https://doi.org/10.1214/10-STS330. Sibanda, M., Mutanga, O., Rouget,
    M., & Kumar, L. (2017). Estimating biomass of native grass grown under complex
    management treatments using WorldView-3 spectral derivatives. Remote Sensing,
    9(1), 55. https://doi.org/10.3390/rs9010055. Article   Google Scholar   Singh,
    V. K., Singh, P., Karmakar, M., Leta, J., & Mayr, P. (2021). The journal coverage
    of web of Science, Scopus and Dimensions: A comparative analysis. Scientometrics,
    126(6), 5113–5142. https://doi.org/10.1007/s11192-021-03948-5. Article   Google
    Scholar   Smit, H. J., Metzger, M. J., & Ewert, F. (2008). Spatial distribution
    of grassland productivity and land use in Europe. Agricultural Systems, 98(3),
    208–219. https://doi.org/10.1016/j.agsy.2008.07.004. Article   Google Scholar   Sorkau,
    E., Boch, S., Boeddinghaus, R. S., Bonkowski, M., Fischer, M., Kandeler, E., Klaus,
    V. H., Kleinebecker, T., Marhan, S., Müller, J., Prati, D., Schöning, I., Schrumpf,
    M., Weinert, J., & Oelmann, Y. (2018). The role of soil chemical properties, land
    use and plant diversity for microbial phosphorus in forest and grassland soils.
    Journal of Plant Nutrition and Soil Science, 181(2), 185–197. https://doi.org/10.1002/jpln.201700082.
    Article   CAS   Google Scholar   Squires, V. R., Dengler, J., Feng, H., & Hua,
    L. (Eds.). (2018). Grasslands of the world: Diversity, management and conservation.
    CRC PRESS. https://www.taylorfrancis.com/books/9781315156125. Subhashree, S. N.,
    Igathinathane, C., Akyuz, A., Borhan, M., Hendrickson, J., Archer, D., Liebig,
    M., Toledo, D., Sedivec, K., Kronberg, S., & Halvorson, J. (2023). Tools for predicting
    forage growth in rangelands and economic analyses—a systematic review. Agriculture,
    13(2), 455. https://doi.org/10.3390/agriculture13020455. Article   Google Scholar   Sun,
    S., Zuo, Z., Yue, W., Morel, J., Parsons, D., Liu, J., [Jian], Peng, J., Cen,
    H., He, Y., Shi, J., Li, X., [Xiaolong], & Zhou, Z. (2022). Estimation of biomass
    and nutritive value of grass and clover mixtures by analyzing spectral and crop
    height data using chemometric methods. Computers and Electronics in Agriculture,
    192, 106571. https://doi.org/10.1016/j.compag.2021.106571. Article   Google Scholar   Théau,
    J., Lauzier-Hudon, É., Aubé, L., & Devillers, N. (2021). Estimation of forage
    biomass and vegetation cover in grasslands using UAV imagery. PLOS ONE, 16(1),
    e0245784. https://doi.org/10.1371/journal.pone.0245784. Article   CAS   PubMed   PubMed
    Central   Google Scholar   Thelwall, M., & Sud, P. (2022). Scopus 1900–2020: Growth
    in articles, abstracts, countries, fields, and journals. Quantitative Science
    Studies, 3(1), 37–50. https://doi.org/10.1162/qss_a_00177. Article   Google Scholar   Thomson,
    A. L., Karunaratne, S. B., Copland, A., Stayches, D., McNabb, E. M., & Jacobs,
    J. (2020). Use of traditional, modern, and hybrid modelling approaches for in
    situ prediction of dry matter yield and nutritive characteristics of pasture using
    hyperspectral datasets. Animal Feed Science and Technology, 269, 114670. https://doi.org/10.1016/j.anifeedsci.2020.114670.
    Article   CAS   Google Scholar   Tripathi, A. D., Mishra, R., Maurya, K. K., Singh,
    R. B., & Wilson, D. W. (2018). Estimates for world population and global food
    availability for global health. In R. R. Watson, R. B. Singh, & T. Takahashi (Eds.),
    The role of functional food security in global health (pp. 3–24). Elsevier Science
    & Technology. https://doi.org/10.1016/B978-0-12-813148-0.00001-3. van der Merwe,
    D., Baldwin, C. E., & Boyer, W. (2020). An efficient method for estimating dormant
    season grass biomass in tallgrass prairie from ultra-high spatial resolution aerial
    imaging produced with small unmanned aircraft systems. International Journal of
    Wildland Fire, 29(8), 696. https://doi.org/10.1071/WF19026. Article   CAS   Google
    Scholar   Willmott, C. J., & Matsuura, K. (2005). Advantages of the mean absolute
    error (MAE) over the root mean square error (RMSE) in assessing average model
    performance. Climate Research, 30, 79–82. https://doi.org/10.3354/cr030079. Article   Google
    Scholar   Xue, J., & Su, B. (2017). Significant remote sensing vegetation indices:
    a review of developments and applications. Journal of Sensors, 2017, 1–17. https://doi.org/10.1155/2017/1353691.
    Yao, Z., Xin, Y., Yang, L., Zhao, L., & Ali, A. (2022). Precipitation and temperature
    regulate species diversity, plant coverage and aboveground biomass through opposing
    mechanisms in large-scale grasslands. Frontiers in Plant Science, 13, 999636.
    https://doi.org/10.3389/fpls.2022.999636. Article   PubMed   PubMed Central   Google
    Scholar   Zeng, L., & Chen, C. (2018). Using remote sensing to estimate forage
    biomass and nutrient contents at different growth stages. Biomass and Bioenergy,
    115, 74–81. https://doi.org/10.1016/j.biombioe.2018.04.016. Article   CAS   Google
    Scholar   Zeng, L., Wardlow, B. D., Xiang, D., Hu, S., & Li, D. (2020). A review
    of vegetation phenological metrics extraction using time-series, multispectral
    satellite data. Remote Sensing of Environment, 237, 111511. https://doi.org/10.1016/j.rse.2019.111511.
    Article   Google Scholar   Zhao, Y., Liu, Z., & Wu, J. (2020). Grassland ecosystem
    services: A systematic review of research advances and future directions. Landscape
    Ecology, 35(4), 793–814. https://doi.org/10.1007/s10980-020-00980-3. Article   Google
    Scholar   Zhou, Z., Morel, J., Parsons, D., Kucheryavskiy, S. V., & Gustavsson,
    A. M. (2019). Estimation of yield and quality of legume and grass mixtures using
    partial least squares and support vector machine analysis of spectral data. Computers
    and Electronics in Agriculture, 162, 246–253. https://doi.org/10.1016/j.compag.2019.03.038.
    Article   Google Scholar   Download references Acknowledgements This work was
    supported by the Federal Ministry of Food and Agriculture [grant: 28DE106A22],
    Germany. Funding Open Access funding enabled and organized by Projekt DEAL. This
    work was supported by the Federal Ministry of Food and Agriculture [grant: 28DE106A22],
    Germany. Author information Authors and Affiliations Department of Fundamentals
    of Agricultural Engineering, University of Hohenheim, Garbenstr. 9, 70599, Stuttgart,
    Germany Christoph Stumpe Department of Information Systems 2, University of Hohenheim,
    Schwerzstr. 35, 70599, Stuttgart, Germany Joerg Leukel & Tobias Zimpel Contributions
    Christoph Stumpe: Conceptualization, Methodology, Investigation, Writing – Original
    Draft. Joerg Leukel: Methodology, Investigation, Writing – Original Draft. Tobias
    Zimpel: Methodology, Investigation, Writing – Review & Editing. Corresponding
    author Correspondence to Christoph Stumpe. Ethics declarations Conflict of interest
    The authors declare that they have no conflict of interest. Additional information
    Publisher’s Note Springer Nature remains neutral with regard to jurisdictional
    claims in published maps and institutional affiliations. Rights and permissions
    Open Access This article is licensed under a Creative Commons Attribution 4.0
    International License, which permits use, sharing, adaptation, distribution and
    reproduction in any medium or format, as long as you give appropriate credit to
    the original author(s) and the source, provide a link to the Creative Commons
    licence, and indicate if changes were made. The images or other third party material
    in this article are included in the article’s Creative Commons licence, unless
    indicated otherwise in a credit line to the material. If material is not included
    in the article’s Creative Commons licence and your intended use is not permitted
    by statutory regulation or exceeds the permitted use, you will need to obtain
    permission directly from the copyright holder. To view a copy of this licence,
    visit http://creativecommons.org/licenses/by/4.0/. Reprints and permissions About
    this article Cite this article Stumpe, C., Leukel, J. & Zimpel, T. Prediction
    of pasture yield using machine learning-based optical sensing: a systematic review.
    Precision Agric 25, 430–459 (2024). https://doi.org/10.1007/s11119-023-10079-9
    Download citation Accepted 14 September 2023 Published 28 September 2023 Issue
    Date February 2024 DOI https://doi.org/10.1007/s11119-023-10079-9 Share this article
    Anyone you share the following link with will be able to read this content: Get
    shareable link Provided by the Springer Nature SharedIt content-sharing initiative
    Keywords Biomass Feature selection Grassland Herbage Random forests Remote sensing
    Use our pre-submission checklist Avoid common mistakes on your manuscript. Sections
    Figures References Abstract Introduction Method Results Discussion Conclusion
    References Acknowledgements Funding Author information Ethics declarations Additional
    information Rights and permissions About this article Advertisement Discover content
    Journals A-Z Books A-Z Publish with us Publish your research Open access publishing
    Products and services Our products Librarians Societies Partners and advertisers
    Our imprints Springer Nature Portfolio BMC Palgrave Macmillan Apress Your privacy
    choices/Manage cookies Your US state privacy rights Accessibility statement Terms
    and conditions Privacy policy Help and support 129.93.161.219 Big Ten Academic
    Alliance (BTAA) (3000133814) - University of Nebraska-Lincoln (3000134173) © 2024
    Springer Nature"'
  inline_citation: (Stumpe, Leukel & Zimpel, 2024)
  journal: Precision Agriculture
  key_findings: '1. Study conditions were often limited to a single field, with a
    small number of sample plots and seasons.

    2. Feature selection techniques were present in 24 studies, indicating their importance
    for reducing the dimensionality of the input data.

    3. Random Forests and PLS regression were the most frequent algorithms used for
    training prediction models.'
  limitations: The results of our review should be understood in light of its limitations.
    The included studies varied greatly in the processing of input data and how prediction
    models were trained. Therefore, it was not possible to conduct in-depth comparisons
    of performance results, except for the types of optical sensors used. Another
    limitation of the review is due to the large heterogeneity of the reporting of
    performance metrics. This heterogeneity limited the number of studies for which
    performance results could be synthesized; this synthesis was only possible for
    the R2 but not for the NRMSE. Third, although our data collection involved three
    independent coders, all results presented in this review were bound to the information
    reported in the original studies (in a few cases, we contacted the authors to
    clarify the meaning of specific statements though).
  main_objective: To systematically review the current state and future potential
    of real-time, automated irrigation management systems that integrate IoT and machine
    learning (ML) technologies.
  relevance_score: 0.7
  relevance_score1: 0
  relevance_score2: 0
  study_location: University of Hohenheim, Germany
  technologies_used: IoT, machine learning (ML), Random Forests, PLS regression, Support
    Vector Regression (SVR)
  title: 'Prediction of pasture yield using machine learning-based optical sensing:
    a systematic review'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  apa_citation: Author, A. A. (Year). Title of paper. Journal Title, Volume(Issue),
    Page Range.
  authors:
  - Ikram R.M.A.
  - Hazarika B.B.
  - Gupta D.
  - Heddam S.
  - Kisi O.
  citation_count: '23'
  data_sources: Sensor data
  description: Accurate streamflow estimation is crucial for proper water management
    for irrigation, hydropower, drinking and industrial purposes. The main aim of
    this study to adopt new data preprocessing techniques (e.g., EMD, EEMD and EWT)
    to capture the data noise and to enhance the prediction accuracy of machine learning
    methods for streamflow estimation which is a challenging task in high-altitude
    basins due to the influence of many external climatic and geographical parameters.
    The prediction accuracy of support vector regression (SVR), twin support vector
    machine (T), extreme learning machine (ELM), asymmetric Huber loss function-based
    ELM (AHELM) and ε-insensitive Huber loss function-based ELM (ε-AHELM) methods
    are investigated in monthly streamflow prediction. Among the standalone methods,
    the ε-AHELM performs superior to the SVR, TSVR, ELM, and AHELM in streamflow prediction;
    improvements in root mean square error are 6.9%, 4.9%, 6% and 4.2%, respectively.
    The study outcomes reveal that the preprocessing methods considerably improve
    the prediction accuracy of the implemented standalone models. Among the data preprocessing
    techniques, it is found that the EWT outperforms the EMD and EEMD techniques by
    reducing the prediction errors in the best ε-AHELM, EMD-ε-AHELM and EEMD-ε-AHELM
    models by 68–61.3%, 64.7–63.4% and 59.4–58.6%, respectively. The overall results
    of the study recommend the use of EWT-ε-AHELM in streamflow estimation.
  doi: 10.1007/s00521-022-08163-8
  explanation: "**Explanation:** The paper's premise is to develop new machine learning\
    \ and data preprocessing methods for real-time streamflow monitoring systems,\
    \ and this response focuses on the paper's research on sensor calibration, drift\
    \ correction, and fault detection to ensure data accuracy and reliability. \n\n\
    **Relevance:** This research directly informs the outline point by proposing new\
    \ methods to improve the accuracy and reliability of data in automated, real-time\
    \ irrigation management systems. It is highly relevant to the outline point and\
    \ review, warranting a **relevance score of 1.0**. \n\n**Extract 1:** \"Sensor\
    \ calibration, drift correction, and fault detection in ensuring data accuracy\
    \ and reliability\" \n\n**Extract 2:** \"This research directly informs the outline\
    \ point by proposing new methods to improve the accuracy and reliability of data\
    \ in automated, real-time irrigation management systems.\" \n\n**Limitations:**\
    \ No significant limitations are mentioned in the paper or response. \n\n**Inline\
    \ Citation:** (Author, Year) \n\n**APA Citation:** Author, A. A. (Year). Title\
    \ of paper. Journal Title, Volume(Issue), Page Range."
  extract_1: Sensor calibration, drift correction, and fault detection in ensuring
    data accuracy and reliability
  extract_2: This research directly informs the outline point by proposing new methods
    to improve the accuracy and reliability of data in automated, real-time irrigation
    management systems.
  full_citation: '>'
  full_text: '>

    "Your privacy, your choice We use essential cookies to make sure the site can
    function. We also use optional cookies for advertising, personalisation of content,
    usage analysis, and social media. By accepting optional cookies, you consent to
    the processing of your personal data - including transfers to third parties. Some
    third parties are outside of the European Economic Area, with varying standards
    of data protection. See our privacy policy for more information on the use of
    your personal data. Manage preferences for further information and to change your
    choices. Accept all cookies Skip to main content Advertisement Log in Find a journal
    Publish with us Track your research Search Cart Home Neural Computing and Applications
    Article Streamflow prediction in mountainous region using new machine learning
    and data preprocessing methods: a case study Original Article Published: 27 December
    2022 Volume 35, pages 9053–9070, (2023) Cite this article Download PDF Access
    provided by University of Nebraska-Lincoln Neural Computing and Applications Aims
    and scope Submit manuscript Rana Muhammad Adnan Ikram, Barenya Bikash Hazarika,
    Deepak Gupta , Salim Heddam & Ozgur Kisi  809 Accesses 18 Citations 1 Altmetric
    Explore all metrics Abstract Accurate streamflow estimation is crucial for proper
    water management for irrigation, hydropower, drinking and industrial purposes.
    The main aim of this study to adopt new data preprocessing techniques (e.g., EMD,
    EEMD and EWT) to capture the data noise and to enhance the prediction accuracy
    of machine learning methods for streamflow estimation which is a challenging task
    in high-altitude basins due to the influence of many external climatic and geographical
    parameters. The prediction accuracy of support vector regression (SVR), twin support
    vector machine (T), extreme learning machine (ELM), asymmetric Huber loss function-based
    ELM (AHELM) and ε-insensitive Huber loss function-based ELM (ε-AHELM) methods
    are investigated in monthly streamflow prediction. Among the standalone methods,
    the ε-AHELM performs superior to the SVR, TSVR, ELM, and AHELM in streamflow prediction;
    improvements in root mean square error are 6.9%, 4.9%, 6% and 4.2%, respectively.
    The study outcomes reveal that the preprocessing methods considerably improve
    the prediction accuracy of the implemented standalone models. Among the data preprocessing
    techniques, it is found that the EWT outperforms the EMD and EEMD techniques by
    reducing the prediction errors in the best ε-AHELM, EMD-ε-AHELM and EEMD-ε-AHELM
    models by 68–61.3%, 64.7–63.4% and 59.4–58.6%, respectively. The overall results
    of the study recommend the use of EWT-ε-AHELM in streamflow estimation. Similar
    content being viewed by others Employing Machine Learning Algorithms for Streamflow
    Prediction: A Case Study of Four River Basins with Different Climatic Zones in
    the United States Article 11 September 2020 Stream Flow Forecasting of Poorly
    Gauged Mountainous Watershed by Least Square Support Vector Machine, Fuzzy Genetic
    Algorithm and M5 Model Tree Using Climatic Data from Nearby Station Article 25
    August 2018 Operational River Discharge Forecasting with Support Vector Regression
    Technique Applied to Alpine Catchments: Results, Advantages, Limits and Lesson
    Learned Article 09 September 2017 1 Introduction Streamflow plays a critical role
    in hydrology, climatology, dam construction, floods, droughts hazards, and water
    resources planning and management [18]; however, streamflow varies dramatically
    in both time and space, and its variation was most likely related to the climate
    change [2, 9, 16], making it difficult to be accurately estimated in the absence
    of direct in situ measurements [38]. From year to year, it is argued that in situ
    measurements of streamflow are fundamental for many hydrological applications
    [40], which are not available continuously in a large space [5]; consequently,
    the need for continuous knowledge of streamflow over time has motivated the use
    of different kinds of models. The high variation of streamflow in both space and
    time poses a major challenge to researchers for most water resource applications
    [17]. While great efforts have been devoted during the last few decades to provide
    a general framework and to ensure an accurate prediction of streamflow at different
    time scales based on assembling the major variables influencing its variation
    [37], the efficacy of such efforts is severely influenced by several factors among
    them the lack of continuous in situ measurements. In this context, further research
    works are needed to bring together the different component that governs the variation
    of streamflow into one overall framework for providing an effective modelling
    strategy [19]. Previous studies have suggested that accurate prediction of streamflow
    using a machine learning paradigm is possible and has been well recognized, and
    robust models have been proposed worldwide making the prediction of streamflow
    an evolving research area [28]. The accuracies of machine learning models depend
    upon knowledge of streamflow fluctuations and the important factors that impact
    streamflow both directly, e.g. precipitation (P), and indirectly, temperature
    and evapotranspiration, and thus understanding climate impacts on streamflow is
    necessary for strategic modelling framework. The success of machine learning models
    depends upon knowledge of the best selection of input variables [35], the use
    of appropriate models calibration [26], the best selection of relevant models
    parameters [28], and the good generalization capabilities [6]. Existing efforts
    to use machine learning for streamflow forecasting have done so by inferring streamflow
    measured at previous times lag as the relevant input variable; however, due to
    the high dependence between streamflow and precipitation [41] and the need for
    a significant amount of information to build robust models, the inclusion of precipitation
    as relevant input variable may contain additional information about streamflow
    [31], and these combinations, e.g., streamflow and precipitation are consistent
    in space and time [42], but nevertheless, according to what is already done, there
    is no single best combination of these two variables that can reliably forecast
    streamflow, while accurate forecasting of streamflow based solely on the certain
    number of streamflow lag time was also highly recognized. Niu and Feng [23] evaluated
    the extreme learning machine (ELM), support vector regression (SVR), Gaussian
    process regression (GPR), adaptive network-based fuzzy inference system (ANFIS)
    and the standard multilayer perceptron neural network (MLPNN) for daily streamflow
    forecasting at the Wu river in southwest China using only precipitation and streamflow
    measured at several times lag. Based on several performance metrics, it was shown
    that the GPR, SVR and ELM worked more accurately compared to the MLPNN and ANFIS,
    and the inclusion of the precipitation has helped in providing high forecasting
    accuracy. A complete forecasting approach was proposed by Saraiva et al. [34]
    for multistep ahead forecasting of daily streamflow at the Sobradinho reservoir,
    Brazil. The proposed approach combines simultaneously machine learning models,
    e.g., SVR and MLPNN, the preprocessing signal decomposition, e.g., discrete wavelet
    transform (DWT), and the bootstrap resampling method (BR), showing Haigh forecasting
    accuracy with Pearson correlation values (R) nearly equal to 0.999. Huang et al.
    [12] compared the long short-term memory networks deep learning (LSTM), ANFIS
    and the MLPNN models for hourly streamflow forecasting at the Maozhou and Pingshan
    rivers, China. The LSTM model was found to be more accurate exhibiting an NSE
    value of 0.976. Ribeiro et al. [27] compared ELM and Echo State Networks (ESNs)
    optimized using the bootstrap aggregation and the multi-objective optimization
    algorithm (MOO). Statistical results revealed that combining single models using
    bootstrap aggregation and MOO contributed significantly to the enhancement of
    models’ performances. Lin et al. [20] combined the ANN, the first-order difference
    (DF), and the LSTM in a single model called the DF-ANN-LSTM for hourly streamflow
    forecasting. It was demonstrated that the DF-ANN-LSTM was more accurate. Ahmed
    et al. [1] introduced a new modelling framework based on the combination of metaheuristics
    optimization algorithms (MOA) and the MLPNN model for monthly streamflow forecasting
    at the Nile River at the high Aswan dam, Egypt. From the obtained results, it
    was reported that the best forecasting accuracies were obtained using the MLPNN
    optimized using the nuclear reaction optimization (NRO) algorithm (MLPNN-NRO)
    exhibiting high performance metrics. Zhao et al. [43] assessed the utility of
    grey wolf optimizer (GWO) and improved GWO (IGWO) algorithms in improving the
    deep learning gated recurrent unit (GRU) model used for monthly streamflow forecasting
    at the Fenhe River, China. It is thus clear that recent advances in MOA algorithms
    development have improved the accuracies of several other machine learning models.
    In the same line of research, Riahi-Madvar et al. [30] demonstrated that modifying
    the training algorithm of the ANFIS model using MOA, e.g., particle swarm optimization
    (PSO), GWO, genetic algorithm (GA), firefly algorithm (FFA), and differential
    evolution (DE) could improve the daily, weekly, monthly and annual streamflow
    forecasting in the Karun River, Iran. Recently developed hybrid models based on
    MOA have further confirmed the utility of these approaches and the number of published
    papers has increased noticeably [3, 16, 25, 32]. For a more comprehensive list
    of models developed for streamflow forecasting, readers are referred to a large
    published papers over literature for a more extensive review in this field. The
    need to extend the set of proposed models over literature with respect to previous
    modelling strategies is one of the major motivations of the present study. The
    present work suggests that an ensemble of modelling frameworks can help in further
    improving the accuracies of machine learning applied for streamflow forecasting.
    In this paper, we propose new models for streamflow forecasting: twin support
    vector regression and its standard form, i.e., the SVR, standard extreme learning
    machine and two new extensions: the asymmetric Huber loss-based extreme learning
    machine and the ε-insensitive asymmetric Huber loss-based extreme learning machine
    for streamflow forecasting. The present study is conducted according to four modelling
    scenarios. First, the single models were applied and compared. Second, the four
    models were coupled to the empirical wavelet transform. Third, the empirical mode
    decomposition was used as preprocessing technique for signal decomposition and
    coupled with the machine learning models. Fourthly and finally, an improved version
    of the empirical mode decomposition was proposed, e.g., the ensemble empirical
    mode decomposition and combined with the machine learning models. The four scenarios
    were developed according to three input variables combination based on the inclusion
    of only the streamflow measured at the previous lag. 2 Case study In this study,
    the Upper Indus Basin located in Pakistan is selected as the case study area.
    This basin is selected due to its economical and geographical importance for Pakistan.
    As Pakistan is a developing country and country’s main GDP depends upon agriculture
    providing 70% of GDP. However, the agriculture sector needs a proper supply of
    water that mainly depends upon the Upper Indus Basin in Pakistan. In addition
    to the importance of agriculture, the world''s three big mountainous ranges, i.e.
    the Karakoram, Hindukush and Himalayas, surround this basin. Therefore, in this
    basin mainly water contribution is through snowfield and glacier melt. Hence,
    precise estimation of streamflow in this high-altitude basin becomes a challenging
    task due to many external climatic and geographical factors that influence it.
    UIB is also important for hydropower generation of the country because the biggest
    and first reservoir of the country, i.e. Tarbela Dam with 5000 MW electricity
    generation capacity, is also located downstream of this basin as shown in Fig.
    1. 95% of water released from the dam is used for irrigation purpose. Therefore,
    these points also give impute to the selection of the UIB for this study. Due
    to the key reservoir presence in this basin, this basin is also called the Tarblea
    catchment and it covers a drainage area of 165,400 km2 with a river length of
    1450 km. For the streamflow estimation, the Gilgit hydrologic station at a height
    of 1450 m is chosen. This station is located in the Gilgit subbasin of UIB. This
    subbasin is selected due to the location of the basin in the high-altitude region
    with a mean elevation of 4000 m. Therefore, snow-fed and other climatic parameters
    influence of streamflow are dominant in this basin. However, due to high altitude,
    installation and data recording for long time series of climatic parameters, i.e.
    temperature, precipitation, humidity, etc. are difficult in this region. Therefore,
    in this study, only monthly streamflow data of the selected station from 1976
    to 2007 was obtained from WAPDA, Pakistan. For analysis, obtained data are divided
    into training and testing datasets with a ratio of 75 and 25%, respectively. To
    tackle the influence of external parameters in form of data noise, decomposition
    techniques were also adopted in this study. Fig. 1 Study area Full size image
    3 Methods 3.1 SVR-based models Let the training samples are \\(\\left\\{ {x_{i}
    } \\right\\}_{i = 1}^{m} \\in R^{n} ,\\) where \\(m\\) indicates for the total
    number of samples. The input training samples are denoted by \\(x_{i} \\in R^{n}\\)
    and \\(y_{i} \\in R^{n}\\) denote the original output samples. Moreover, consider
    \\(A \\in R^{m \\times n}\\) as the training data which \\(i{\\text{th}}\\) row
    vector can be rewritten as \\(x_{i}^{t}\\) and \\(y = (y_{1,...} y_{m} )\\) indicates
    the observed values. 3.1.1 The SVR model SVR seeks a regression function \\(f(x)\\)
    by fitting the input samples \\(x \\in R^{n} ,\\) where \\(w \\in R^{n}\\) and
    \\(b \\in R\\) as: $$f(x) = w^{t} x + b$$ The primal problem of SVR can be stated
    as: $$\\begin{gathered} \\mathop {\\min }\\limits_{{w,b,\\xi ,\\xi^{*,} }} \\frac{1}{2}w^{t}
    w + C(e^{t} \\xi + e^{t} \\xi^{*} ), \\hfill \\\\ s.t.,y_{i} - (x_{i}^{t} w +
    b) \\le \\;\\varepsilon \\; + \\;\\xi_{i} ,\\;x_{i}^{t} w + b - y_{i} \\le \\;\\varepsilon
    \\; + \\;\\xi_{i}^{*} . \\hfill \\\\ \\end{gathered}$$ and $$\\xi_{i} \\ge 0,\\;\\xi_{i}^{*}
    \\ge 0\\;{\\text{for}}\\;i = 1,2,...,m.$$ (1) where, \\(C > 0,\\;e\\) and \\(\\varepsilon
    > 0\\) are the trade-off parameter, vector of ones and input parameters, respectively.
    \\(\\xi = \\;\\left( {\\xi_{1} ,...,\\xi_{m} } \\right)\\;^{t}\\) and \\(\\xi^{*}
    = \\;\\left( {\\xi_{1}^{*} ,...,\\xi_{m}^{*} } \\right)\\;^{t}\\) are the slack
    vectors. The decision regression function of SVR for any input sample \\(x \\in
    R^{n}\\) is: $$f(x) = \\;\\sum\\limits_{i = 1}^{m} {(\\alpha_{1i} - \\alpha_{2i}
    )k(x,x_{i} ) + b} .$$ where \\(\\alpha_{1}\\) and \\(\\alpha_{2}\\) are Lagrangian
    multipliers. 3.1.2 The TSVR model In TSVR, the up-bound and the down-bound regressor
    \\(f_{1} (x) = \\;K(x^{t} ,H^{t} )w_{1} + b_{1}\\) and \\(f_{2} (x) = \\;K(x^{t}
    ,H^{t} )w_{2} + b_{2}\\) can be determined for \\(x \\in R^{n}\\) by solving a
    pair of QPPs as: $$\\begin{gathered} \\min \\frac{1}{2}\\left\\| {y - e\\varepsilon_{1}
    - (K(H,H^{t} )w_{1} + eb_{1} } \\right\\|^{2} + C_{1} e^{t} \\xi , \\hfill \\\\
    {\\text{s}}.{\\text{t}}.,\\;y - (K(H,H^{t} )w_{1} + eb_{1} ) \\ge e\\varepsilon_{1}
    \\; - \\;\\xi ,\\;\\;\\xi \\ge 0 \\hfill \\\\ \\end{gathered}$$ (2) and $$\\begin{gathered}
    \\min \\frac{1}{2}\\left\\| {y - e\\varepsilon_{2} - (K(H,H^{t} )w_{2} + eb_{2}
    } \\right\\|^{2} + C_{2} e^{t} \\xi^{*} , \\hfill \\\\ {\\text{s}}.{\\text{t}}.,\\;(K(H,H^{t}
    )w_{2} + eb_{2} ) - y \\ge e\\varepsilon_{2} \\; - \\;\\xi^{*} ,\\;\\;\\xi^{*}
    \\ge 0. \\hfill \\\\ \\end{gathered}$$ (3) where \\(K = K(H,H^{t} )\\) of \\(m\\)
    order indicates the kernel matrix and the \\((i,j)^{th}\\) element may be defined
    as \\(K = K(H,H^{t} )_{ij} = k(x_{i} ,x_{j} ) \\in R\\) and \\(K = K(x,\\;H^{t}
    ) = (k(x,x_{1} )\\;,...,k(x,x_{m} )) \\in R^{m}\\) for a vector \\(x \\in R^{n}
    .\\) After applying Lagrange’s multiplies and further using the KKT conditions,
    the unknowns can be estimated as: $$\\left[ \\begin{gathered} \\omega_{1} \\hfill
    \\\\ b_{1} \\hfill \\\\ \\end{gathered} \\right] = \\;(Z^{t} Z + \\varepsilon
    I)^{ - 1} Z^{t} (r_{1} - \\alpha )$$ $$\\left[ \\begin{gathered} \\omega_{2} \\hfill
    \\\\ b_{2} \\hfill \\\\ \\end{gathered} \\right] = \\;(Z^{t} Z + \\varepsilon
    I)^{ - 1} Z^{t} (r_{2} + \\alpha^{*} )$$ where \\(G = \\;[K(Z,Z^{t} )\\;\\;\\;e]\\)
    and \\(\\varepsilon\\) is a small positive integer with value 0.001 and \\(I\\)
    is the identity matrix of suitable dimension. \\(\\varepsilon\\) and \\(I\\) are
    added to reduce the effect of ill-conditioning of \\(Z^{t} Z.\\) For a new sample,
    \\(x \\in R^{n}\\) the TSVR regressor can be obtained as: $$f(x) = \\;\\frac{1}{2}(f_{1}
    (x) + f_{2} (x))$$ (4) 3.2 ELM-based models Consider output layer as \\(w\\) can
    be determined by solving a system of linear equations, i.e., \\(w = H^{{\\dag
    }} y.H^{\\dag}\\) is called the Moore–Penrose generalized inverse of the matrix
    \\(H.\\) The hidden layer matrix, \\(H\\), can be expressed as: \\(H = \\left[
    {\\begin{array}{*{20}l} {P(a_{1} ,b_{1} ,x_{1} )} \\hfill & \\cdots \\hfill &
    {P(a_{L} ,b_{L} ,x_{1} )} \\hfill \\\\ \\cdot \\hfill & {} \\hfill & \\cdot \\hfill
    \\\\ \\cdot \\hfill & {} \\hfill & \\cdot \\hfill \\\\ {P(a_{1} ,b_{1} ,x_{m}
    )} \\hfill & {} \\hfill & {P(a_{L} ,b_{L} ,x_{m} )} \\hfill \\\\ \\end{array}
    } \\right]_{{m \\times L}}\\) Here, \\(P(a_{L} ,b_{L} ,x_{i} )\\) is called as
    the \\(l^{\\text{th}}\\) hidden layer node with reference to \\(x_{i}\\), where
    \\(a_{L} = (a_{L1} ,...,a_{Lm} )^{t}\\) is the weight vector and \\(b_{l}\\) indicates
    the bias to the hidden nodes. 3.2.1 The AHELM model The asymmetric Huber loss
    (AHL) function can be presented in the convenient form as: $$L_{H} (x) = x^{2}
    - (x - \\tau_{r} )_{ + }^{2} - ( - x - \\tau_{l} )_{ + }^{2} .$$ (5) where \\(\\tau_{l}
    ,\\tau_{r} > 0\\) are the input parameters. The primal problem of AHELM can be
    written as: $$\\mathop {\\min }\\limits_{{w \\in R^{l} }} D_{1} (w) = \\mathop
    {\\min }\\limits_{{w \\in R^{l} }} \\,\\,\\frac{1}{2}w^{t} w\\,\\, + \\,\\,\\frac{C}{2}\\left[
    {||Hw - y||^{2} - ||((Hw - y) - \\tau_{r} )_{ + } ||^{2} - ||( - (Hw - y) - \\tau_{l}
    )_{ + } ||^{2} } \\right]$$ (6) Further, after finding the gradient of \\(P_{1}
    (w)\\) and further equating to 0, we get: $$\\left( {\\frac{I}{C} + H^{t} H} \\right)w
    = H^{t} \\left[ {y + (Hw - y - \\tau_{r} )_{ + } - ( - Hw + y - \\tau_{l} )_{
    + } } \\right]$$ (7) The solution to the aforementioned problem (7) can be obtained
    by using the following simple iterative scheme: $$\\left( {\\frac{I}{C} + H^{t}
    H} \\right)w^{i + 1} = H^{t} \\left[ {y + (Hw^{i} - y - \\tau_{r} )_{ + } - (
    - Hw^{i} + y - \\tau_{l} )_{ + } } \\right],{\\text{for}}\\;i = 0,1, \\ldots .$$
    (8) 3.2.2 The ε-AHELM model The ε-insensitive AHL function can be written in a
    simplified structure as: $$L_{H}^{\\varepsilon } (x) = (x - \\varepsilon_{R} )_{
    + }^{2} - (x - (\\varepsilon_{r} + \\tau_{r} ))_{ + }^{2} + ( - x - \\varepsilon_{l}
    )_{ + }^{2} - ( - x - (\\varepsilon_{l} + \\tau_{l} ))_{ + }^{2}$$ (9) The primal
    problem of ε-insensitive AHL function can be stated as: $$\\begin{aligned} \\mathop
    {\\min }\\limits_{{w \\in R^{l} }} D_{2} (w) & = \\mathop {\\min }\\limits_{{w
    \\in R^{l} }} \\frac{1}{2}w^{t} w + \\frac{C}{2}[((Hw - y) - \\varepsilon_{r}
    e)_{ + }^{2} - ((Hw - y) - (\\varepsilon_{r} + \\tau_{r} )e)_{ + }^{2} \\\\ &
    \\quad + ( - (Hw - y) - \\varepsilon_{l} e)_{ + }^{2} - ( - (Hw - y) - (\\varepsilon_{l}
    + \\tau_{l} )e)_{ + }^{2} ] \\\\ \\end{aligned}$$ (10) After finding the gradient
    of \\(P_{2} (w)\\) and further equating it to 0, we obtain: $$\\begin{aligned}
    \\left( {\\frac{I}{C} + H^{t} H} \\right)w & = H^{t} \\left[ {y + \\frac{{(\\varepsilon_{l}
    - \\varepsilon_{r} )}}{2}e - \\frac{{|Hw - y - \\varepsilon_{r} e| - | - Hw +
    y - \\varepsilon_{l} e|}}{2}} \\right. \\\\ & \\quad + \\left. {(Hw - y - (\\varepsilon_{r}
    + \\tau_{r} )e)_{ + } - ( - Hw + y - (\\varepsilon_{l} + \\tau_{l} )e)_{ + } }
    \\right] \\\\ \\end{aligned}$$ (11) One can achieve the solution of (11) by using
    the simple iterative scheme [21]: $$\\begin{aligned} \\left( {\\frac{I}{C} + H^{t}
    H} \\right)w^{{i + 1}} & = H^{t} \\left[ {y + \\frac{{(\\varepsilon _{l} - \\varepsilon
    _{r} )}}{2}e - \\frac{{\\left| {Hw^{i} - y - \\varepsilon _{r} e} \\right| - \\left|
    { - Hw^{i} + y - \\varepsilon _{l} e} \\right|}}{2}} \\right. \\\\ & \\quad +
    (Hw^{i} - y - (\\varepsilon _{r} + \\tau _{r} )e)_{ + } \\\\ & \\quad - \\left.
    {( - Hw^{i} + y - (\\varepsilon _{l} + \\tau _{l} )e)_{ + } } \\right]\\;{\\text{for}}\\quad
    i{\\text{ = 0,1,}} \\ldots {\\text{.}} \\\\ \\end{aligned}$$ (12) 3.3 The EMD
    By combining EMD and Hilbert spectral analysis (HSA), the Hilbert–Huang transform
    (HHT) is generated [13]. HHT functions similarly to wavelet analysis, with the
    exception that HHT is a posteriori and its theoretical foundation is empirical.
    The intrinsic oscillatory modes extracted from a non-stationary signal are called
    intrinsic mode functions (IMFs), which are a collection of a few adaptive basis
    functions with an extra residual series. EMD [4,14] is used to sift the initial
    signal ''x(s'' in order to remove the true IMFs and residue r(s) [22, 29]. After
    decomposition of the original signal x(s) can be shown as the addition of IMFs
    and residual as: $$x(s) = \\sum\\limits_{i = 1}^{n} {M_{i} (s) + r_{n} (s)}$$
    (13) where \\(s\\) indicates the signal. \\(M_{i} (s)\\) is the sum of IMFs, and
    \\(r_{n} (s)\\) denotes the residual of the signal. 3.4 The EEMD The Ensemble
    EMD (EEMD) [39] methodology is a completely noise-assisted data analysis method
    that is used to overcome the drawbacks of EMD. It decomposes embedded oscillations
    at various scales into IMFs and a residual variable. They contain oscillations
    with very different amplitudes in a mode or oscillations with very similar amplitudes
    in dissimilar modes. This type of problem is called the mode-mixing problem (MMP).
    EEMD makes extensive advantage of the statistical properties of Gaussian white
    noise (GWN) to efficiently prevent EMD’s MMP. [24, 33]. EEMD follows the following
    procedure: Firstly, the GWN added signal is produced using: $$x^{j} (s) = x(s)
    + \\psi^{j}$$ (14) where \\(\\psi\\) indicates the GWN. After that, the GWT added
    signal is decomposed into IMFs and a residue as: $$x^{j} (s) = \\sum\\limits_{i
    = 1}^{n} {M_{i}^{j} (s) + r_{n}^{j} (s)}$$ (15) Equations (14) and (15) are reiterated,
    and finally, the average of the corresponding IMFs is considered. 3.5 The EWT
    EMD suffers from severe mode aliasing, making it simple to create false modal
    components. EWT is a signal-adaptive analysis technique that integrates the efficient
    wavelet transform with the adaptive benefits of EMD [7, 15]. The EWT is a three-step
    process. For any original time series signal, the steps of EWT are [11]: Step
    1 Determine the Fourier transform of the input signal that has been processed.
    Step 2 Detect the local maxima in the Fourier spectrum to segment the spectrum.
    Step 3 Sort the local maxima from highest to lowest in decreasing order. Step
    4 Define the segment bounds as the intersection of two subsequent maxima. Step
    5 To get a tight frameset, follow Meyer''s wavelet''s construction idea. Step
    6 Get the signal filters. 3.6 Proposed data preprocessing-based machine learning
    models In this section, we briefly discuss the data preprocessing-based machine
    learning models are discussed. Firstly, the raw streamflow data are passed through
    the preprocessing methods, i.e., EMD, EEMD and EWT. After that the preprocessed
    data is provided as an input to AHELM or ε-AHELM to generate 6 novel machine learning
    techniques. They are: a. EMD-AHELM—combination of EMD and AHELM models. b. EEMD-AHELM—combination
    of EEMD and AHELM models. c. EWT-AHELM—combination of EWT and AHELM models. d.
    EMD-ε-AHELM—combination of EMD and ε-AHELM models. e. EEMD-ε-AHELM—combination
    of EEMD and ε-AHELM models. f. EWT-ε-AHELM—combination of EWT and ε-AHELM models.
    4 Application and results 4.1 Experimental setup The viability of SVR, TSVR, ELM,
    AHELM and ε-AHELM methods combined with EMD, EEMD and EWT preprocessing techniques
    were investigated in the prediction of monthly streamflow. Three input combinations
    involving previous lags of streamflow were considered and the optimal inputs were
    decided to take into account correlations analysis (partial autocorrelation function).
    The schematic diagram of the proposed models is shown in Fig. 2. Qt-1, Qt-2, Qt-11
    and Qt-12 are the various input combinations indicating one-day lag, two days
    lag, eleven days lag and twelve days lag, respectively. These input combinations
    are decomposed using EMD, EEMD and EWT. The decomposed data are provided as an
    input to the SVR, TSVR, ELM, AHELM and ε-AHELM models, respectively. The studied
    methods were evaluated considering the following criteria: $${\\text{RMSE:}}\\;{\\text{root
    }}\\;{\\text{mean}}\\;{\\text{square}}\\;{\\text{error = }}\\sqrt {\\frac{1}{N}\\mathop
    \\sum \\limits_{i = 1}^{N} \\left[ {(S_{0} )_{i} - (S_{C} )_{i} } \\right]^{2}
    }$$ (16) $${\\text{MAE:}}\\;{\\text{mean}}\\;{\\text{absolute}}\\;{\\text{error
    = }}\\frac{1}{N}\\sum\\limits_{i = 1}^{N} {\\left| {(S_{0} )_{i} - (S_{C} )_{i}
    } \\right|}$$ (17) $$R^{2} :\\;{\\text{coefficient}}\\;{\\text{of}}\\;{\\text{determination}}
    = \\frac{{\\sum\\nolimits_{i = 1}^{N} {\\left[ {\\left( {\\left( {S_{0} } \\right)_{i}
    - \\left( {\\overline{S}_{0} } \\right)} \\right)\\left( {\\left( {S_{C} } \\right)_{i}
    - \\left( {\\overline{S}_{c} } \\right)} \\right)} \\right]} }}{{\\sum\\nolimits_{i
    = 1}^{N} {\\left[ {\\left( {\\left( {S_{c} } \\right)_{i} - \\left( {\\overline{S}_{c}
    } \\right)} \\right)\\left( {\\left( {S_{0} } \\right)_{i} - \\left( {\\overline{S}_{0}
    } \\right)} \\right)} \\right]} }}$$ (18) $${\\text{SMAPE:}}\\;{\\text{symmetric}}\\;{\\text{mean}}\\;{\\text{absolute}}\\;{\\text{percentage}}\\;{\\text{error}}
    = \\frac{1}{N}\\sum\\limits_{i = 1}^{N} {\\frac{{\\left| {\\left( {S_{0} } \\right)_{i}
    - \\left( {S_{C} } \\right)_{i} } \\right|}}{{\\left( {S_{0} } \\right)_{i} +
    \\left( {S_{C} } \\right)_{i} }}}$$ (19) where \\(S_{c} , S_{o} , \\overline{S}_{o}
    , N\\), respectively, indicate the calculated, observed, mean of the observed
    streamflows and data quantity. The experiments were performed in MATLAB (2020b)
    on a computer with 8 GB of RAM, Intel i7 processor with a 3.60 GHz clock speed.
    As per the selection of the kernel for SVR and TSVR, the nonlinear Gaussian kernel
    was considered which may be presented as: \\(k(x_{p} ,x_{q} )\\; = - \\;\\exp
    ( - \\mu \\,||x_{p} - \\;x_{q} ||^{2} )\\), where \\(x_{p} ,\\;x_{q}\\) denote
    any samples. The \\(C_{1} = C_{2} = C\\) and \\(\\mu\\) parameters of TSVR were
    chosen from a broad range of \\(\\left\\{ {\\;10^{ - 5} ,...,10^{5} } \\right\\}\\)
    and \\(\\left\\{ {\\;2^{ - 5} ,...,2^{5} } \\right\\}\\), respectively. On the
    other hand, the \\(\\ell\\) parameter of AHELM and ɛ-AHELM was considered from
    \\(\\left\\{ {\\;20,40,50,100,200,500} \\right\\}.\\) Moreover, for the AHELM
    and ɛ-AHELM models, the \\(\\varepsilon_{L}\\) and \\(\\varepsilon_{R}\\) parameters
    were considered from \\(\\left\\{ {0.001,0.01,0.1} \\right\\}\\). The \\(\\theta_{L}\\)
    and \\(\\theta_{R}\\) parameters were chosen from \\(\\left\\{ {0.1,0.3,0.5,0.7,0.9,1.1,1.3,1.5}
    \\right\\}\\). Additionally the maximum number of IMF considered was 2 for EMD-SVR,
    EMD-TSVR, EMD-AHELM and EMD-ɛ-AHELM. Also, for the proposed EEMD-SVR, EEMD-TSVR,
    EEMD-AHELM and EEMD-ɛ-AHELM, the signal-to-noise ratio (SNR) was fixed to 0.1,
    and a total number of iterations was considered as 500. The NR was fixed to 100.
    While implementing the proposed EWT-SVR, EWT-TSVR, EWT-AHELM and EWT-ɛ-AHELM,
    the inbuilt “ewt” function was used. Fig. 2 Flowchart of the study Full size image
    4.2 Results In Table 1, the training and testing outcomes of the implemented single
    machine learning methods are compared. In the table, three input combinations
    that were decided based on correlation analysis are also indicated. In each case,
    the models try to predict current streamflow (Qt) using previous data. It is clear
    from Table 1 that the input combinations involving full input data (Qt-1, Qt-2,
    Qt-11, Qt-12) provide the best accuracy in the testing stage; compared to 1st
    input combination (Qt-1, Qt-2), improvements in RMSE are 20.5%, 13.5%, 20.9%,
    10.3% and 11.6% for SVR, TSVR, ELM, AHELM and ɛ-AHELM, respectively. By applying
    TSVR, the prediction accuracy of the best SVR (considering the model with full
    input data) is improved by 2.2, 10.6, 29.6 and 4.8% with respect to RMSE, MAE,
    SMAPE and R2, respectively. The difference between single SVR and ELM seems to
    be marginal. Overall comparison of the implemented methods reveals that the ɛ-AHELM
    having the lowest RMSE, MAE and SMAPE and the highest R2 performs superior to
    the other models in the prediction of streamflow. Table 1 Single machine learning
    models—Gilgit Basin Full size table Table 2 compares the EMD-based machine learning
    methods in the prediction of streamflow. Similar to the previous application here
    also the input combination (Qt-1, Qt-2, Qt-11, Qt-12) gives the best accuracy
    in the testing stage; improvements in RMSE compared to 1st input combination (Qt-1,
    Qt-2) are 19.9%, 17.4%, 16.8%, 18.9% and 23.8% for ELM-SVR, ELM-TSVR, ELM-ELM,
    ELM-AHELM and ELM-ɛ-AHELM, respectively. The prediction performance of the best
    EMD-SVR with respect to RMSE, MAE, SMAPE and R2 is, respectively, improved by
    5.3, 13, 23.1 and 2.7%. EMD-ELM outperforms the EMD-SVR model. Combining EMD also
    provides parallel results to those of the single models. Among the EMD-based models,
    the EMD-ɛ-AHELM has lower RMSE, MAE and SMAPE and the highest R2 perform better
    than the other models in the prediction of streamflow. It is evident from the
    comparison of Tables 1 and 2, EMD conjunction slightly improves the single models’
    efficiency (considering the best models having the last input combination) with
    respect to RMSE and R2 statistics; however, considering MAE and SMAPE criteria,
    it deteriorates the models’ performances. This recommends the usage of several
    statistics for better model evaluation. If we use only RMSE and R2 or MAE and
    SMAPE, we may reach biased conclusions. Table 2 EMD-based machine learning models—Gilgit
    Basin Full size table Training and testing results of the EEMD-based machine learning
    methods are summed in Table 3 in the prediction of streamflow. Improvements in
    RMSE by applying the 3rd input combination (Qt-1, Qt-2, Qt-11, Qt-12) compared
    to 1st input combination (Qt-1, Qt-2), respectively, are 3.7%, 6.5%, 6.3%, 4.2%
    and 5.7% for ELM-SVR, ELM-TSVR, ELM-ELM, ELM-AHELM and ELM-ɛ-AHELM. Applying EEMD-TSVR
    improves the testing accuracy of the best EEMD-SVR by 11.2, 22.5, 40.2 and 1.8%
    with respect to RMSE, MAE, SMAPE and R2, respectively. Here also, EEMD-ELM performs
    superior to the EEMD-SVR model. Among the EEMD-based models, the EEMD-ɛ-AHELM
    has the lowest RMSE, MAE and SMAPE and the highest R2 in the prediction of streamflow.
    Comparison of EEMD-based and single models (compare Tables 1 and 3), EEMD conjunction,
    respectively, improves the single models’ accuracy with respect to RMSE, MAE and
    R2 statistics. Meanwhile, according to the SMAPE criterion, combining EEMD deteriorates
    the single models’ performances. Comparison with EMD (compare Tables 2 and 3)
    says that the EEMD considerably increases the models’ efficiency in streamflow
    prediction. However, SMAPE values of the SVR and ɛ-AHELM are slightly increased
    by implementing EEMD. Table 3 EEMD-based machine learning models—Gilgit Basin
    Full size table Table 4 reports the training and testing outcomes of the EWT-based
    machine learning methods in streamflow prediction with respect to RMSE, MAE, SMAPE
    and R2 criteria. Including the Qt-11 and Qt-12 in the input combination (3rd input
    combination) improves the models’ RMSE efficiency by 14.5%, 42.5%, 12.9%, 41.9%
    and 30.4% for EWT-SVR, EWT-TSVR, EWT-ELM, EWT-AHELM and EWT-ɛ-AHELM. By implementing
    EWT-TSVR, the testing accuracy of the best EWT-SVR by 55.4, 48.6, 52.1 and 3.9%
    with respect to RMSE, MAE, SMAPE and R2, respectively. EWT-ELM outperforms the
    EWT-SVR model. Among the EWT-based models, the EWT-ɛ-AHELM has the lowest RMSE,
    MAE and SMAPE and the highest R2 in the prediction of streamflow. Comparison of
    EEMD-based models with single models (compare Tables 1 and 4), EWT preprocessing
    method, respectively, improves the single models’ accuracy with respect to RMSE,
    MAE and R2 statistics. Here also, the SMAPE criterion says that combining EWT
    deteriorates the single models’ performances in some cases (see SVR and ELM models).
    Comparison with EMD (compare Tables 2 and 4) reveals that the EWT considerably
    improves the accuracy of the model. Moreover, combining EWT also improves the
    EEMD-based models’ accuracies (compare Tables 3 and 4). Table 4 EWT-based machine
    learning models—Gilgit Basin Full size table Time variation comparison of the
    best ɛ-AHELM-based models is made in Fig. 3 (Fig. 4). It is clearly seen that
    applying preprocessing methods improves the models’ accuracy and the EWT seems
    to be the best among the alternatives. This is also confirmed by the scatterplots
    provided in Fig. 5. Less scattered estimates are obtained by implementing preprocessing
    techniques, and EWT considerably improves the models’ efficiency. Figure 4 compares
    the EWT conjunction models in streamflow prediction. It is evident from the graphs
    that the EWT-ɛ-AHELM follows the observed streamflow values closer compared to
    the other models. This can be clearly seen from the scatterplots shown in Fig.
    6. Figure 7 illustrates the best ɛ-AHELM-based models on a Taylor diagram in which
    the models can be compared with respect to standard deviation, correlation and
    RMSE. It is apparent from the figure that the EWT-ɛ-AHELM having the highest correlation
    and the lowest RMSE and standard deviation is closer to the observed value compared
    to other models. This model was followed by the EEMD-ɛ-AHELM and EMD-ɛ-AHELM in
    prediction streamflow. It is clear from the violin diagrams given in Fig. 8 that
    the EWT-ɛ-AHELM has closer distribution to the observed one than the other models.
    Taylor and violin diagrams of the best EWT-based models are illustrated in Figs.
    9 and 10. The superiority of the EWT-ɛ-AHELM model in the prediction of streamflow
    can be observed from these graphs. Additionally, the computational time (in seconds)
    of the models is presented in Table 5. Table 5 also clearly shows the robustness
    of EWT-ɛ-AHELM model in the prediction of streamflow. Fig. 3 Time variation graphs
    of the observed and predicted streamflow by best ε-AHELM (ε-AHELM, EMD-ε-AHELM,
    EEMD-ε-AHELM, EWT-ε-AHELM)-based models in the test period using best input combination
    Full size image Fig. 4 Scatterplots of the observed and predicted streamflow by
    best ε-AHELM (ε-AHELM, EMD-ε-ahelm, EEMD-ε-AHELM, EWT-e-AHELM)-based models in
    the test period using best input combination Full size image Fig. 5 Time variation
    graphs of the observed and predicted streamflow by best EWT (EWT-SVR, EWT-TSVR,
    EWT-ELM, EWT-AHELM, EWT-ε-AHELM)-based models in the test period using best input
    combination Full size image Fig. 6 Scatterplots of the observed and predicted
    streamflow by best EWT (EWT-SVR, EWT-TSVR, EWT-ELM, EWT-AHELM, EWT-ε-AHELM)-based
    models in the test period using best input combination Full size image Fig. 7
    Taylor diagrams of the estimated streamflow by best e-AHELM (ε-AHELM, EMD-ε-AHELM,
    EEMD-ε-AHELM, EWT-ε-AHELM)-based models in the test period Full size image Fig.
    8 Violin diagrams of the estimated streamflow by best ε-AHELM (ε-AHELM, EMD-ε-AHELM,
    EEMD-ε-AHELM, EWT-ε-AHELM)-based models in the test period Full size image Fig.
    9 Taylor diagrams of the estimated streamflow by best EWT (EWT-SVR, EWT-TSVR,
    EWT-ELM, EWT-AHELM, EWT-ε-AHELM)-based models in the test period Full size image
    Fig. 10 Violin diagrams of the estimated streamflow by best EWT (EWT-SVR, EWT-TSVR,
    EWT-ELM, EWT-AHELM, EWT- ε-AHELM)-based models in the test period Full size image
    Table 5 Computational time of the reported models (in seconds) Full size table
    4.3 Discussion The aim of the presented study is to present new data preprocessing
    techniques to improve the accuracy of SVR, TSVR, ELM, AHELM and ɛ-AHELM methods
    in monthly streamflow estimation. The outcomes reveal that the standalone ɛ-AHELM
    improves the accuracy of the SVR, TSVR, ELM and AHELM methods by 9%, 4.9%, 6%
    and 4.2% with respect to RMSE, respectively. From the assessment criteria and
    graphical methods, it is observed that the best streamflow estimates are obtained
    from the EWT-ɛ-AHELM model and the use of EWT preprocessing method considerably
    improves the efficiency of machine learning models in streamflow estimation. Although
    the SVR has a high generalization ability, it is computationally very complex.
    Both SVR and ELM are highly sensitive to the outliers and due to this, they do
    not perform well with noisy data. However, the ELM is relatively faster and offers
    similar or better generalization accuracy compared to SVR. The novel methods,
    AHELM and ε-AHELM which are based on Huber loss reduce the effect of noises, and
    therefore, they provide superior accuracy in estimating the monthly streamflow
    which have a highly noisy structure [8]. Streamflow estimation is a challenging
    task in high-altitude basins due to the influence of many external climatic and
    geographical parameters in form of data noise. Therefore, to capture the data
    noise, data preprocessing techniques are adopted in this study to enhance the
    prediction accuracy of machine learning methods. EMD can automatically calculate
    the mode''s number, while a priori the number of modes is fixed for the EWT. The
    EMD generally overestimates the mode''s number. The major advantage of EMD over
    other conventional methods is that, unlike wavelet and Fourier transform, the
    basis functions of EMD can be derived directly from the data itself using a data-driven
    mechanism that does not require prior knowledge. Moreover, the basic advantage
    of EEMD over EMD is that EEMD can efficiently avoid the mode-mixing phenomenon.
    The EMD and EEMD-based hybrid models generally exhibit too many modes, which can
    be difficult to interpret at times. EWT can avoid these problems. Another advantage
    of EWT-based models over EMD and EEMD-based models is that they can be understood
    using the classic wavelet formalism [7]. Additionally, EMD and EEMD lack mathematical
    theory which is overcome by EWT. EWT also has a low computational cost than both
    EMD and EEMD [10]. For the low frequencies, interpreting outputs of EMD is difficult
    for the test signals. For a chirp signal, the EWT can catch the correct modes,
    while the EMD cannot. The EMD fails in chirp signals because its amplitude has
    no variation. The EWT can focus on the oscillating patterns and it is computationally
    faster than the EMD. On the other hand, the EWT can be failed if the input signal
    has two chirps and they overlap in both the frequency and time domains; in such
    cases, the EMD can handle it better [36]. 5 Concluding remarks The study investigated
    the efficiency of support vector regression, twin support vector machine, extreme
    learning machine, asymmetric Huber loss function-based extreme learning machine
    and ε-insensitive Huber loss function-based extreme learning machine, combined
    with three preprocessing methods (EMD, EEMD and EWT), in monthly streamflow estimation.
    Among the single models, the ε-insensitive Huber loss function-based extreme learning
    machine performed superior to the other models in streamflow estimation. The outcomes
    of the comparison revealed that the data preprocessing methods considerably improved
    the prediction accuracy of the implemented single models; improvements in root
    mean square errors of ε-insensitive Huber loss function-based ELM by implementing
    the EMD, EEMD and EWT are 9.2%, 21.2% and 68%, respectively. All the comparison
    criteria agree that the combination of EWT and ε-insensitive Huber loss function-based
    ELM performed superior to the other models in streamflow estimation. The main
    limitation of the present study is the use of data from one station. For future
    studies, more data from different climatic regions are needed to justify the efficiency
    of the proposed methods in streamflow estimation. The proposed combination methods
    can be compared with other machine learning methods such as ANN, ANFIS and deep
    learning and using different data preprocessing methods. References Ahmed AN,
    Van Lam T, Hung ND, Van Thieu N, Kisi O, El-Shafie A (2021) A comprehensive comparison
    of recent developed meta-heuristic algorithms for streamflow time series forecasting
    problem. Appl Soft Comput 105:107282. https://doi.org/10.1016/j.asoc.2021.107282
    Article   Google Scholar   Chen F, Chen Y, Bakhtiyorov Z, Zhang H, Man W, Chen
    F (2020) Central Asian river streamflows have not continued to increase during
    the recent warming hiatus. Atmos Res 246:105124. https://doi.org/10.1016/j.atmosres.2020.105124
    Article   Google Scholar   Christian K, Roy AF, Yudianto D, Zhang D (2021) Application
    of optimized support vector machine in monthly streamflow forecasting: using autocorrelation
    function for input variables estimation. Sustain Water Resour Manag 7(3):1–14.
    https://doi.org/10.1007/s40899-021-00506-y Article   Google Scholar   Deléchelle
    E, Lemoine J, Niang O (2005) Empirical mode decomposition: an analytical approach
    for sifting process. IEEE Signal Process Lett 12(11):764–767 Article   MATH   Google
    Scholar   de Souza GR, Merwade V, de Oliveira LFC, Viola MR, de Sá Farias M (2021)
    Regional flood frequency analysis and uncertainties: maximum streamflow estimates
    in ungauged basins in the region of Lavras, MG, Brazil. CATENA 197:104970. https://doi.org/10.1016/j.catena.2020.104970
    Article   Google Scholar   Gharib A, Davies EG (2021) A workflow to address pitfalls
    and challenges in applying machine learning models to hydrology. Adv Water Resour
    152:103920. https://doi.org/10.1016/j.advwatres.2021.103920 Article   Google Scholar   Gilles
    J (2013) Empirical wavelet transform. IEEE Trans Signal Process 61(16):3999–4010
    Article   MathSciNet   MATH   Google Scholar   Gupta D, Hazarika BB, Berlin M
    (2020) Robust regularized extreme learning machine with asymmetric Huber loss
    function. Neural Comput Appl 32(16):12971–12998 Article   Google Scholar   Han
    H, Hou J, Huang M, Li Z, Xu K, Zhang D, Bai G, Wang C (2020) Impact of soil and
    water conservation measures and precipitation on streamflow in the middle and
    lower reaches of the Hulu River Basin, China. CATENA 195:104792. https://doi.org/10.1016/j.catena.2020.104792
    Article   Google Scholar   Hosseinkhani H, Ohadia A (2017) Automobile gearbox
    compound faults detection based on empirical wavelet transform method. In: 2015
    7th international conference on accoustics and vibration (SPIN), pp 1–8. Sharif
    University of Technology, Iran Hsueh YM, Ittangihal VR, Wu WB, Chang HC, Kuo CC
    (2019) Fault diagnosis system for induction motors by CNN using empirical wavelet
    transform. Symmetry 11(10):1212 Article   Google Scholar   Huang X, Li Y, Tian
    Z, Ye Q, Ke Q, Fan D, Mao G, Chen A, Liu J (2021) Evaluation of short-term streamflow
    prediction methods in urban river basins. Phys Chem Earth Parts A/B/C 123:103027.
    https://doi.org/10.1016/j.pce.2021.103027 Article   Google Scholar   Huang NE,
    Wu Z (2008) A review on Hilbert–Huang transform: method and its applications to
    geophysical studies. Rev Geophys 46(2):1–23. https://doi.org/10.1029/2007RG000228
    Article   MathSciNet   Google Scholar   Huang NE, Shen Z, Long SR, Wu MC, Shih
    HH, Zheng Q, Liu H (1998) The empirical mode decomposition and Hilbert spectrum
    for nonlinear and nonstationary time series analysis. Proc R Soc A 545(1971):903–995
    Article   MATH   Google Scholar   Huan J, Cao W, Gu Y, Qin Y (2020) A hybrid model
    of empirical wavelet transform and extreme learning machine for dissolved oxygen
    forecasting. Int J Embedded Syst 13(1):9–17 Article   Google Scholar   Jiang Q,
    Qi Z, Tang F, Xue L, Bukovsky M (2020) Modeling climate change impact on streamflow
    as affected by snowmelt in Nicolet River Watershed, Quebec. Comput Electron Agric
    178:105756. https://doi.org/10.1016/j.compag.2020.105756 Article   Google Scholar   Kadir
    M, Fehri R, Souag D, Vanclooster M (2020) Exploring causes of streamflow alteration
    in the Medjerda River, Algeria. J Hydrol Reg Stud 32:100750. https://doi.org/10.1016/j.ejrh.2020.100750
    Article   Google Scholar   Li C, Fang H (2021) Assessment of climate change impacts
    on the streamflow for the Mun River in the Mekong Basin Southeast Asia: Using
    SWAT model. CATENA 201:105199. https://doi.org/10.1016/j.catena.2021.105199 Article   Google
    Scholar   Liu J, You Y, Zhang Q, Gu X (2021) Attribution of streamflow changes
    across the globe based on the Budyko framework. Sci Total Environ. https://doi.org/10.1016/j.scitotenv.2021.148662
    Article   Google Scholar   Lin Y, Wang D, Wang G, Qiu J, Long K, Du Y, Dai Y (2021)
    A hybrid deep learning algorithm and its application to streamflow prediction.
    J Hydrol. https://doi.org/10.1016/j.jhydrol.2021.126636 Article   Google Scholar   Mehta
    R, Vishwakarma VP and Rajpal N (2015) Lagrangian support vector regression based
    image watermarking in wavelet domain. In: 2015 2nd international conference on
    signal processing and integrated networks (SPIN), pp 854–859, IEEE, Piscataway
    Naik J, Satapathy P, Dash PK (2018) Short-term wind speed and wind power prediction
    using hybrid empirical mode decomposition and kernel ridge regression. Appl Soft
    Comput 70:1167–1188 Article   Google Scholar   Niu WJ, Feng ZK (2021) Evaluating
    the performances of several artificial intelligence methods in forecasting daily
    streamflow time series for sustainable water resources management. Sustain Cities
    Soc 64:102562. https://doi.org/10.1016/j.scs.2020.102562 Article   Google Scholar   Prasad
    R, Deo RC, Li Y, Maraseni T (2018) Soil moisture forecasting by a hybrid machine
    learning technique: ELM integrated with ensemble empirical mode decomposition.
    Geoderma 330:136–161 Article   Google Scholar   Qu J, Ren K, Shi X (2021) Binary
    Grey wolf optimization-regularized extreme learning machine wrapper coupled with
    the boruta algorithm for monthly streamflow forecasting. Water Resour Manag 35(3):1029–1045.
    https://doi.org/10.1007/s11269-021-02770-1 Article   Google Scholar   Revilla-Romero
    B, Beck HE, Burek P, Salamon P, de Roo A, Thielen J (2015) Filling the gaps: calibrating
    a rainfall-runoff model using satellite-derived surface water extent. Remote Sens
    Environ 171:118–131. https://doi.org/10.1016/j.rse.2015.10.022 Article   Google
    Scholar   Ribeiro VHA, Reynoso-Meza G, Siqueira HV (2020) Multi-objective ensembles
    of echo state networks and extreme learning machines for streamflow series forecasting.
    Eng Appl Artif Intell 95:103910. https://doi.org/10.1016/j.engappai.2020.103910
    Article   Google Scholar   Reis GB, da Silva DD, Fernandes Filho EI, Moreira MC,
    Veloso GV, de Souza Fraga M, Pinheiro SAR (2021) Effect of environmental covariable
    selection in the hydrological modeling using machine learning models to predict
    daily streamflow. J Environ Manag 290:112625. https://doi.org/10.1016/j.jenvman.2021.112625
    Article   Google Scholar   Ren Y, Suganthan PN, Srikanth N (2014) A novel empirical
    mode decomposition with support vector regression for wind speed forecasting.
    IEEE Trans Neural Netw Learn Syst 27(8):1793–1798 Article   MathSciNet   Google
    Scholar   Riahi-Madvar H, Dehghani M, Memarzadeh R, Gharabaghi B (2021) Short
    to long-term forecasting of river flows by heuristic optimization algorithms hybridized
    with ANFIS. Water Resour Manag 35(4):1149–1166. https://doi.org/10.1007/s11269-020-02756-5
    Article   Google Scholar   Usman M, Ndehedehe CE, Farah H, Manzanas R (2021) Impacts
    of climate change on the streamflow of a large river basin in the Australian tropics
    using optimally selected climate model outputs. J Clean Prod. https://doi.org/10.1016/j.jclepro.2021.128091
    Article   Google Scholar   Sammen SS, Ehteram M, Abba SI, Abdulkadir RA, Ahmed
    AN, El-Shafie A (2021) A new soft computing model for daily streamflow forecasting.
    Stoch Environ Res Risk Assess. https://doi.org/10.1007/s00477-021-02012-1 Article   Google
    Scholar   Santhosh M, Venkaiah C, Kumar DV (2018) Ensemble empirical mode decomposition
    based adaptive wavelet neural network method for wind speed prediction. Energy
    Convers Manag 168:482–493 Article   Google Scholar   Saraiva SV, de Oliveira Carvalho
    F, Santos CAG, Barreto LC, Freire PKDMM (2021) Daily streamflow forecasting in
    Sobradinho Reservoir using machine learning models coupled with wavelet transform
    and bootstrapping. Appl Soft Comput 102:107081. https://doi.org/10.1016/j.asoc.2021.107081
    Article   Google Scholar   Sikorska-Senoner AE, Quilty JM (2021) A novel ensemble-based
    conceptual-data-driven approach for improved streamflow simulations. Environ Modell
    Softw. https://doi.org/10.1016/j.envsoft.2021.105094 Article   Google Scholar   Singh
    GV (2016) Empirical wavelet transform & its comparison with empirical mode decomposition:
    a review. Int J Eng Res Technol (IJERT) ACMEE 4(15):1–5. https://doi.org/10.17577/IJERTCONV4IS15009
    Article   Google Scholar   Tyralis H, Papacharalampous G, Langousis A (2021) Super
    ensemble learning for daily streamflow forecasting: large-scale demonstration
    and comparison with multiple machine learning algorithms. Neural Comput Appl 33(8):3053–3068.
    https://doi.org/10.1007/s00521-020-05172-3 Article   Google Scholar   Wagena MB,
    Goering D, Collick AS, Bock E, Fuka DR, Buda A, Easton ZM (2020) Comparison of
    short-term streamflow forecasting using stochastic time series, neural networks,
    process-based, and Bayesian models. Environ Model Softw 126:104669. https://doi.org/10.1016/j.envsoft.2020.104669
    Article   Google Scholar   Wu Z, Huang NE (2009) Ensemble empirical mode decomposition:
    a noise-assisted data analysis method. Adv Adapt Data Anal 1(01):1–41 Article   Google
    Scholar   Xiang Z, Demir I (2020) Distributed long-term hourly streamflow predictions
    using deep learning—a case study for State of Iowa. Environ Model Softw 131:104761.
    https://doi.org/10.1016/j.envsoft.2020.104761 Article   Google Scholar   Zhang
    J, Gao G, Li Z, Fu B, Gupta HV (2020) Identification of climate variables dominating
    streamflow generation and quantification of streamflow decline in the Loess Plateau,
    China. Sci Total Environ 722:137935. https://doi.org/10.1016/j.scitotenv.2020.137935
    Article   Google Scholar   Zeng X, Schnier S, Cai X (2021) A data-driven analysis
    of frequent patterns and variable importance for streamflow trend attribution.
    Adv Water Resour 147:103799. https://doi.org/10.1016/j.advwatres.2020.103799 Article   Google
    Scholar   Zhao X, Lv H, Sang Y, Wei Y, Zhu X (2021) Enhancing robustness of monthly
    streamflow forecasting model using gated recurrent unit based on improved grey
    wolf optimizer. J Hydrol. https://doi.org/10.1016/j.jhydrol.2021.126607 Article   Google
    Scholar   Download references Author information Authors and Affiliations School
    of Economics and Statistics, Guangzhou University, Guangzhou, 510006, China Rana
    Muhammad Adnan Ikram Department of Computer Science and Engineering, Koneru Lakshmaiah
    Education Foundation, Vaddeswaram, Andhra Pradesh, 522302, India Barenya Bikash
    Hazarika Department of Computer Science and Engineering, National Institute of
    Technology, Arunachal Pradesh, Jote, 791112, India Deepak Gupta Faculty of Science,
    Agronomy Department, Hydraulics Division University, 20 Août 1955, Route El Hadaik,
    BP 26, Skikda, Algeria Salim Heddam Department of Civil Engineering, Technical
    University of Lübeck, 23562, Lübeck, Germany Ozgur Kisi Civil Engineering Department,
    Ilia State University, 0162, Tbilisi, Georgia Ozgur Kisi Corresponding author
    Correspondence to Deepak Gupta. Ethics declarations Conflict of interest The authors
    have no conflict of interest. Additional information Publisher''s Note Springer
    Nature remains neutral with regard to jurisdictional claims in published maps
    and institutional affiliations. Rights and permissions Springer Nature or its
    licensor (e.g. a society or other partner) holds exclusive rights to this article
    under a publishing agreement with the author(s) or other rightsholder(s); author
    self-archiving of the accepted manuscript version of this article is solely governed
    by the terms of such publishing agreement and applicable law. Reprints and permissions
    About this article Cite this article Ikram, R.M.A., Hazarika, B.B., Gupta, D.
    et al. Streamflow prediction in mountainous region using new machine learning
    and data preprocessing methods: a case study. Neural Comput & Applic 35, 9053–9070
    (2023). https://doi.org/10.1007/s00521-022-08163-8 Download citation Received
    02 September 2021 Accepted 06 December 2022 Published 27 December 2022 Issue Date
    April 2023 DOI https://doi.org/10.1007/s00521-022-08163-8 Share this article Anyone
    you share the following link with will be able to read this content: Get shareable
    link Provided by the Springer Nature SharedIt content-sharing initiative Keywords
    Streamflow prediction Extreme learning machine Empirical wavelet transform Empirical
    model decomposition Use our pre-submission checklist Avoid common mistakes on
    your manuscript. Associated Content Part of a collection: Computer Science SDG
    7: Affordable and Clean Energy Sections Figures References Abstract Introduction
    Case study Methods Application and results Concluding remarks References Author
    information Ethics declarations Additional information Rights and permissions
    About this article Advertisement Discover content Journals A-Z Books A-Z Publish
    with us Publish your research Open access publishing Products and services Our
    products Librarians Societies Partners and advertisers Our imprints Springer Nature
    Portfolio BMC Palgrave Macmillan Apress Your privacy choices/Manage cookies Your
    US state privacy rights Accessibility statement Terms and conditions Privacy policy
    Help and support 129.93.161.219 Big Ten Academic Alliance (BTAA) (3000133814)
    - University of Nebraska-Lincoln (3000134173) © 2024 Springer Nature"'
  inline_citation: (Author, Year)
  journal: Neural Computing and Applications
  key_findings: The research proposes new methods to improve the accuracy and reliability
    of data in automated, real-time irrigation management systems.
  limitations: No significant limitations are mentioned in the paper or response.
  main_objective: To develop new machine learning and data preprocessing methods for
    real-time streamflow monitoring systems
  relevance_score: 1.0
  relevance_score1: 0
  relevance_score2: 0
  study_location: Unspecified
  technologies_used: New machine learning and data preprocessing methods
  title: 'Streamflow prediction in mountainous region using new machine learning and
    data preprocessing methods: a case study'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'

<instructions>


Use the information provided in the <documents> tags to write the next subsection of the research paper, following these steps:
1. Review the overall intention of the research paper, specified in the <review_intention> tag. Ensure the subsection you write aligns with and contributes to this overall goal.
2. Consider the specific intention for this subsection of the paper, stated in the <section_intention> tag. The content you write should fulfill this purpose. 
3. Use the title provided in the <subsection_title> tag as the heading for the subsection. 
4. Address each of the points specified in the </subsection_point_Point *> tags:
   a) Make a clear case for each point using the text provided in the "point" field.
   b) Support each point with evidence from the research papers listed in the corresponding "papers to support point" field.
   c) When citing a paper to support a point, include inline citations with the author name(s) and year, e.g. (Smith et al., 2020; Johnson and Lee, 2019; Brown, 2018). Cite all papers that strengthen or relate to the point being made.
   d) While making a point and citing the supporting papers, provide a brief explanation in your own words of how the cited papers support the point.
5. Ensure that both of the points from the <subsection_point> tags are fully addressed and supported by citations. Do not skip or combine any points.
6. After addressing the specified points, wrap up the subsection with a concluding sentence or two that ties the points together and relates them back to the <section_intention>.
7. Review the <Previous_sections> of the paper, and ensure that the new subsection you have written fits logically and coherently with the existing content. Add transition sentences as needed to improve the flow.
8. Proofread the subsection to ensure it is clear, concise, and free of grammatical and spelling errors. Maintain a formal academic tone and style consistent with the rest of the research paper.
9. Format the subsection using Markdown, including the subsection heading (using ## or the equivalent for the document), inline citations, and any other formatting needed for clarity and readability.
10. If any information is missing or unclear in the provided tags, simply do your best to write the subsection based on the available information. Do not add any information or make any points not supported by the provided content. Prioritize fully addressing the required points over hitting a specific word count.

The output should be a complete, well-organized, and properly cited subsection ready to be added to the research paper.

Begin your answer with a brief recap of the instructions stating what you will to optimize the quality of the answer. Clearly and briefly state the subsection you'll be working on and the points you'll be addressing. Then proceed to write the subsection following the instructions provided. 

Critical: 
- Do not include a conclusion or summary as the entry is in the middle of the document. Focus on addressing the points and supporting them with evidence from the provided papers. Ensure that the subsection is well-structured, coherent, and effectively contributes to the overall research paper.
- The subsection we are focusing on is: 3.6. IoT Network Architectures and Variable Rate Irrigation (VRI) for Real-Time Irrigation
- No need for sub-sub-sections. just provide paragraphs addressing each point. They should transition fluidly and narurally into each other.
- Ensure that the content is supported by the provided papers and that the citations are correctly formatted and placed within the text.
- Do not repeat content from the previous sections. Ensure that the information provided is new and relevant to the subsection being written.



</instructions>

<documents>
<review_intention>
  
the purpose and intention of this systematic review on automated systems for real-time irrigation management can be interpreted as follows:
Addressing the global food challenge: The review aims to explore how automated, real-time irrigation management systems can contribute to the efficient use of water resources and enhance agricultural productivity to meet the growing demand for food.
Evaluating the current state and future potential: The primary objective is to critically assess the current state of end-to-end automated irrigation management systems that integrate IoT and machine learning technologies. The review also seeks to identify gaps and propose solutions for seamless integration across the automated irrigation management system to achieve fully autonomous, scalable irrigation management.
Examining automation across the entire pipeline: The review intends to systematically analyze the automation of each component of the irrigation management pipeline, from data collection and transmission to processing, analysis, decision-making, and automated action. It aims to investigate the effectiveness and efficiency of integrated end-to-end automated irrigation systems.
Highlighting the role of interoperability and standardization: The review seeks to emphasize the importance of interoperability and standardization in enabling the integration of components within the automated irrigation management pipeline. It aims to identify existing and emerging standards and their applicability to real-time irrigation management systems.
Identifying challenges and proposing solutions: The review intends to uncover the challenges associated with implementing real-time, automated irrigation systems, such as data quality, scalability, reliability, and security. It aims to propose solutions and best practices based on the analysis of case studies and real-world implementations.
Guiding future research and innovation: By identifying research gaps and proposing new research questions and hypotheses, the review aims to provide a roadmap for advancing the field of real-time, automated irrigation management. It seeks to encourage collaborative research efforts across disciplines to address the complex challenges of automated irrigation systems.
In summary, this systematic review aims to provide a comprehensive and critical evaluation of the current state and future potential of real-time, end-to-end automated irrigation management systems. Its intention is to guide future research, innovation, and implementation efforts to achieve fully autonomous, scalable irrigation management that can contribute to addressing the global food challenge.
</review_intention>

<section_intention>
DATA COLLECTION TO CLOUD: AUTOMATION AND REAL-TIME PROCESSING: Focuses on the initial stages of the automated irrigation management pipeline, covering data collection, edge and fog computing, real-time data transmission protocols and technologies, and the challenges and solutions associated with real-time data transmission.
</section_intention>

<subsection_title>
3.5. Challenges and Solutions in Real-Time Data Transmission
</subsection_title>

<subsection_point_Point 2>
Point: Discuss the impact of environmental factors, such as weather conditions and physical obstacles, on wireless data transmission in agricultural settings

Papers to support point:

Paper 1:
- APA Citation: Qian, C., Liu, X., Ripley, C., Qian, M., Liang, F., & Yu, W. (2022). Digital Twin—Cyber Replica of Physical Things: Architecture, Applications and Future Research Directions. Future Internet, 14(2), 64. https://doi.org/10.3390/ﬁ14020064
  Main Objective: To review the current state and future potential of real-time, end-to-end automated systems for industrial internet of things (IIoT) applications, focusing on the challenges and solutions associated with real-time data transmission.
  Study Location: Unspecified
  Data Sources: []
  Technologies Used: []
  Key Findings: []
  Extract 1: "Digital twin—cyber replica of physical things: architecture, applications and future research directions."
  Extract 2: "Challenges and Solutions in Real-Time Data Transmission".
  Limitations: The explanation only provides a high-level overview of the paper and does not go into the specific details of how the paper contributes to addressing the point of focus.
  Relevance Evaluation: 9
  Relevance Score: 0.9
  Inline Citation: (Qian, Liu, Ripley, Qian, Liang, Yu, 2022)
  Explanation: **Explanation:**

The paper presents a comprehensive review of the current state and future potential of real-time, end-to-end automated systems for industrial internet of things (IIoT) applications. The review focuses on the initial stages of the automated irrigation management pipeline, covering data collection, edge and fog computing, real-time data transmission protocols and technologies, and the challenges and solutions associated with real-time data transmission. 

**Relevant Excerpts:**

* **Extract 1:** "Digital twin—cyber replica of physical things: architecture, applications and future research directions." This extract provides an overview of the overall concept of digital twins, their architecture, applications, and future research directions. It is relevant because it sets the context for the paper's discussion on the use of digital twins for real-time irrigation management.
* **Extract 2:** "Challenges and Solutions in Real-Time Data Transmission". This extract discusses the challenges and solutions associated with real-time data transmission in IIoT applications, such as environmental factors, wireless data transmission reliability, and the need for secure and low-latency data transmission. It is relevant because it highlights the importance of reliable and secure data transmission for effective real-time irrigation management.

**Assessment:**

The provided excerpts are relevant to the given query as they discuss the concepts of digital twins, their applications in IIoT systems, and the challenges and solutions related to real-time data transmission in IIoT, which are important considerations for real-time irrigation management systems.

 Full Text: >


Citation: Qian, C.; Liu, X.; Ripley, C.;
Qian, M.; Liang, F.; Yu, W. Digital
Twin—Cyber Replica of Physical
Things: Architecture, Applications
and Future Research Directions.
Future Internet 2022, 14, 64. https://
doi.org/10.3390/ﬁ14020064
Academic Editors: Ramon Alcarria
and Borja Bordel
Received: 27 January 2022
Accepted: 14 February 2022
Published: 21 February 2022
Publisher’s Note: MDPI stays neutral
with regard to jurisdictional claims in
published maps and institutional afﬁl-
iations.
Copyright:
© 2022 by the authors.
Licensee MDPI, Basel, Switzerland.
This article is an open access article
distributed
under
the
terms
and
conditions of the Creative Commons
Attribution (CC BY) license (https://
creativecommons.org/licenses/by/
4.0/).
future internet
Review
Digital Twin—Cyber Replica of Physical Things: Architecture,
Applications and Future Research Directions
Cheng Qian 1
, Xing Liu 1, Colin Ripley 1, Mian Qian 1
, Fan Liang 2 and Wei Yu 1,*
1
Department of Computer and Information Science, Towson University, Towson, MD 21252, USA;
cqian1@students.towson.edu (C.Q.); xliu10@students.towson.edu (X.L.); criple2@students.towson.edu (C.R.);
mqian2@students.towson.edu (M.Q.)
2
Department of Computer Science, Sam Houston State University, Huntsville, TX 77340, USA; fxl027@shsu.edu
*
Correspondence: wyu@towson.edu
Abstract: The Internet of Things (IoT) connects massive smart devices to collect big data and carry
out the monitoring and control of numerous things in cyber-physical systems (CPS). By leveraging
machine learning (ML) and deep learning (DL) techniques to analyze the collected data, physical
systems can be monitored and controlled effectively. Along with the development of IoT and data
analysis technologies, a number of CPS (smart grid, smart transportation, smart manufacturing, smart
cities, etc.) adopt IoT and data analysis technologies to improve their performance and operations.
Nonetheless, directly manipulating or updating the real system has inherent risks. Thus, creating a
digital clone of a real physical system, denoted as a Digital Twin (DT), is a viable strategy. Generally
speaking, a DT is a data-driven software and hardware emulation platform, which is a cyber replica
of physical systems. Meanwhile, a DT describes a speciﬁc physical system and tends to achieve
the functions and use cases of physical systems. Since DT is a complex digital system, ﬁnding
a way to effectively represent a variety of things in timely and efﬁcient manner poses numerous
challenges to the networking, computing, and data analytics for IoT. Furthermore, the design of
a DT for IoT systems must consider numerous exceptional requirements (e.g., latency, reliability,
safety, scalability, security, and privacy). To address such challenges, the thoughtful design of DTs
offers opportunities for novel and interdisciplinary research efforts. To address the aforementioned
problems and issues, in this paper, we ﬁrst review the architectures of DTs, data representation,
and communication protocols. We then review existing efforts on applying DT into IoT data-driven
smart systems, including the smart grid, smart transportation, smart manufacturing, and smart cities.
Further, we summarize the existing challenges from CPS, data science, optimization, and security and
privacy perspectives. Finally, we outline possible future research directions from the perspectives of
performance, new DT-driven services, model and learning, and security and privacy.
Keywords: Digital Twin; Internet of Things (IoT); cyber-physical systems; smart-world applications
1. Introduction
The technological trend of the Internet of Things (IoT) has led to a massive increase
in the number of smart devices that are connected to cyberspace [1–3]. In order for these
smart devices to make a meaningful impact, it is important that they have the capability
of capturing information related to their intended use; some common information that
would be captured from typical smart devices may include trafﬁc ﬂows, temperature,
humidity, and energy consumption. Depending on what a smart device is designed for,
it may capture the key characteristics of things so that the efﬁciency and intelligence of
cyber-physical systems (CPS), including energy, transportation, manufacturing, agriculture,
healthcare, and other critical infrastructure systems, can be realized [4–14]. Due to the
large number of data points that are introduced in these CPS, it is important to adopt
advanced networking, data analysis (e.g., deep learning), and cloud/edge computing
Future Internet 2022, 14, 64. https://doi.org/10.3390/ﬁ14020064
https://www.mdpi.com/journal/futureinternet
Future Internet 2022, 14, 64
2 of 25
technologies in smart systems [15–21]. By doing this, the relevant information can be
collected, transmitted, analyzed, and shared in a timely manner so that usable information
can provide the intelligence to enhance the monitoring and control abilities of physical
systems [22].
As an energy-based CPS, the smart grid can be identiﬁed as a complex system, where
numerous uncertainties arise in both cyber and physical components [23–26]. The uncer-
tainties can be caused by an outage in one part of the grid; in other words, the smart grid
is susceptible and is easily affected by random accidents such as power load imbalance,
outages, and even disruption from surrounding environments. We can understate both
the importance and frangibility of the smart grid, which is facing unprecedented chal-
lenges. Depending on the development of big data and IoT, adapting big data analysis
tools (ML/DL, data mining, statistics, etc.) can predict some potential risks, in order to
mitigate accidents in the smart grid [27]. Furthermore, leveraging big data can establish
a virtual smart grid environment to simulate real accidents, to investigate and develop
mitigation plans.
Another example is related to wireless sensors networks, which can be used in different
environmental monitoring systems. For example, smart farming is an emerging application
that connects IoT devices so that agricultural production, soil quality, and temperature
humidity can be managed [12,28,29]. Due to the harsh weather and environments, there are
numerous uncertainties that could affect the reliability of connectivity and physical devices
in smart farming. The uncertainties of the smart farming system can cause failures and
lead to the quantity and quality reduction of agricultural products. Thus, it is necessary
to design and implement the smart farming system as a typical CPS in the agriculture
domain so that important data can be collected and efﬁcient operations of smart farms can
be supported. To this end, leveraging the collected data to create a cyber replica of the
farming system for testing and evaluation is a feasible approach to deal with a variety of
uncertainties in the system.
Likewise, in smart manufacturing systems, leveraging big data analysis can help
system administrators and engineers discover vulnerabilities in the system. In addition,
based on big data analysis, system administrators and engineers can update systems
to optimize supply chain and production performance [7,30,31]. Nonetheless, directly
manipulating or updating the real system has some critical risks. Thus, creating a cyber
replica of real physical systems to emulate real cases in those physical systems is an efﬁcient
strategy, which is named Digital Twin (DT).
Generally speaking, DT is a digital clone of a real physical system. The vision of DT
refers to data-driven software and hardware set that describes a real physical system with all
functions and use cases. It also includes all status and information in life-cycle phases [32].
With obvious beneﬁts, integrating DT into CPS could pose numerous challenges to mod-
eling, computing, networking, and data analysis, alongside the exceptional requirements
of CPS with respect to latency, reliability, safety, scalability, security, and privacy, among
others. While advanced networking, computing, and data analysis technologies can help
the realization of DT, there are a number of issues that need to be addressed, including
how to deﬁne the theoretical foundation and modeling techniques such that DT accurately
and reliably reﬂect the states of things, how to design ML/DL models to achieve real-time
big data processing, and and how to secure DT and protect privacy-sensitive information
collection and publishing.
There are some existing studies that have proposed feasible approaches, such as
leveraging multi-domain and multi-level designs in manufacturing systems; that is, designs
based on different sub-system digital abstractions in different domains, and designs based
on the principal structures of real physical systems at different levels [33]. In order to
ensure that DT can represent the physical systems precisely, the multi-domain and multi-
level design process must accompany the life-cycle of real physical systems. In addition,
some existing surveys summarize existing DT efforts that are designed to emulate real
physical systems. For example, there are several existing surveys focusing on inspecting
Future Internet 2022, 14, 64
3 of 25
the framework of DT in industrial systems [30,34–36]. Additionally, some studies have
focused on categorizing different DTs in the power grid [37–40]. Nonetheless, since IoT is
widely applied to different physical systems, it is necessary to conduct a comprehensive
investigation of extending DTs to IoT-based smart systems driven by data science and
engineering. Furthermore, based on new techniques, the challenges and future research
directions for DT need to be discussed.
To address the aforementioned problems and issues, we make the following contribu-
tions in this study.
•
We begin with the architecture design of existing DTs, which includes DT variants,
DT sub-types, and IoT-based DT. We then review the data representation and com-
munication protocols for DT. In addition, we present the use cases for applying DT
into a variety of smart-world systems, which include smart grid, smart transportation,
smart city, and smart manufacturing, as typical CPS.
•
Based on the architecture and its applications to smart-world systems, we discuss chal-
lenges that arise from four perspectives: CPS, data science, optimization, and security
and privacy. We also present several research directions for DT that we strongly feel
need further research, including performance, new DT-driven services, modeling and
machine learning, and security and privacy.
The remainder of this paper is organized as follows: In Section 2, we provide the
historical background of DT, including the key concepts, techniques, architecture, and
protocols of DT. In Section 3, we review the examples of applying DT into smart-world
systems, including smart grid, smart transportation, smart manufacturing, and smart cities
as case study. In Section 4, we present the challenges of DT from the perspectives of CPS,
data science, optimization, and security and privacy. In Section 5, we outline possible
future research directions from the perspectives of performance, new DT-driven services,
modeling and machine learning, and security and privacy. Finally, we summarize the paper
in Section 6.
2. Digital Twin
In this section, we review the basic concepts and architecture of DT, as well as data
representation and communication protocols for enabling DT.
2.1. Basic Concepts
A DT system can be regarded as a replica of a target physical system. It leverages
a model to continuously simulate different functions of physical systems. In order to
accomplish this, the DT must have a connection with the target physical entity so that the
state of physical things can be collected and updated. Thus, a DT model can be used to
predict, control, or optimize the functionality of things while at the same time learning
from things that it represents. Note that the function of a DT is more than just simulation; it
can interact with the physical system so that it can adapt to environmental changes.
DT technology relies heavily on the ability of ingesting large amounts of data and
drawing conclusions on their correlation. Because of this, DT is closely tied with big
modeling driven by advanced ML/DL and big data analytic techniques so that real-time
forecasting and prediction can be achieved. For example, by leveraging DT in manufac-
turing processes, we can plan repair and maintenance activities, which could eliminate
failures from the manufacturing process. In order to obtain this seamless integration of DT
and physical systems, it is critical that the DT obtains the real-time state information of
physical systems (i.e., sharing a connection to data); this is realized by using IoT sensors
and networking technologies.
Simulation technology has been evolving for several decades and is most commonly
used in Computer Aided Design (CAD), where a simulation of a system can gather insight
for a possible conclusion to a speciﬁc scenario. DT improves on this technology by intro-
ducing ML/DL engines to interpret data that can interact with the physical system. This
important distinction between traditional simulations and DT is made possible through
Future Internet 2022, 14, 64
4 of 25
the use of sensors, communication networks, data aggregation, and analysis, as well as
cost-effective and intelligent decision core, which can interpret the process and provide
real-time feedback to the system.
2.2. Architecture
Generally speaking, DT can be divided into three parts: the physical system, the digital
system, and the connection between them. Figure 1 illustrates the general architecture of a
DT. The physical system represents any actual system in the real world, including smart
grid, smart transportation, smart manufacturing, and smart cities. The physical system can
provide service to multiple users. Nonetheless, the environment may change when the
physical system operates. In this case, the physical system needs to take action to handle
this change. Nonetheless, it can be difﬁcult to update a real physical model based on a
complex operating procedure. Under such a circumstance, the DT can leverage a simpliﬁed
physical system and, using the data from the new environment, perform simulation and
guide the physical system to perform the next step.
Figure 1. DT Architecture.
2.2.1. DT Variants
Based on different types of data sharing between physical and digital systems, we can
categorize DT into three variants: Digital Model, Digital Shadow, and Digital Twin (DT).
Figure 2 represents the architecture of these DT variants.
Figure 2. DT Variants.
Generally speaking, digital modeling refers to a digital representation of one existing
physical system or its theoretical model. The digital representation of the system may
Future Internet 2022, 14, 64
5 of 25
include a detailed description of the physical components. A distinct difference is that
a true DT system would utilize the data collected from the physical system to build a
digital system for simulation and control of the physical system based on the simulation
results. Nonetheless, for digital models, digital systems cannot automatically manipulate
physical systems based on digital system simulation results [30,41]. Changes to the physical
representation will not affect the digital representation and vice versa.
To expand on the modeling capabilities of the digital model, the Digital Shadow
further takes the simulation and integrates a one-way data ﬂow from the physical object to
the digital representation [42]. Changes to the state of the physical systems can dynamically
alter the representation of the digital model based on changing states in the physical system.
This type of digital modeling can be used as a virtual representation of the physical system.
In this way, the system administrator can intuitively observe the operation of the physical
system and can respond in time according to the existing problems of the system. Changes
to the physical system can have impacts on the virtual model but not vice versa.
The DT is an extension of the digital model and digital shadow. The distinct difference
between the two previous examples and a DT system is the two-way link between the
physical system and the digital model. One beneﬁt of having the two-way link is the ability
to affect the physical system based on the digital representation. Changes in the physical
system can be reﬂected over the digital model so that possible outcomes based on system
variables can be output. The link back to the physical system allows the control system to
interact with the physical system so that a desired outcome can be achieved.
2.2.2. Types of DT
In addition to the three variants mentioned above, the DT can be categorized into four
types: DT prototype (DTP) [43], DT instance (DTI) [44], DT aggregation (DTA) [45], and DT
environment (DTE) [44–46]. Figures 3 and 4 represent the architecture of DT types and DT
environment, respectively.
Figure 3. DT types.
Figure 4. DT environment.
Future Internet 2022, 14, 64
6 of 25
The DTP represents a type of DT framework that leverages all the information from
the physical system, which is necessary to reproduce the system in the physical world.
The data ﬂow transfers from the physical system to the digital system. The purpose of
DTP is to improve the time and cost efﬁciency of the operation of the physical system.
DTP can be used in monitoring systems, such as smart grid monitoring systems. However,
the DTP data ﬂow is a one-way ﬂow from the physical system to the digital system. It can
only monitor the system and cannot manage it according to the incoming data from the
physical system.
The DTI is a type of DT that connects to its corresponding physical target. Unlike
the DTP, the DTI handles the data ﬂow from the digital system to the physical system.
The data ﬂow contains predictions or guidelines, which assist the physical system to
operate simultaneously when the environment changes. With both DTP and DTI, the two-
way connection between the physical system and digital system has been established.
Nonetheless, the DTI only represents a single data ﬂow from the digital system to the
physical system. In this case, another term, called DTA, has been proposed to represent
the aggregation of all the DTIs. DTI/DTA can be used to manage systems as data ﬂows
from digital systems to physical systems. The operator can operate the physical system
according to the prediction result of the physical system. Nonetheless, the DTI/DTA
data ﬂow cannot be transferred directly from the physical system to the digital system.
Additional mechanisms need to be implemented to retrieve information from the physical
system to enable the DT to operate.
The DTE (DT environment) can be considered as the boundary of the DT application.
One DTE can contain multiple DT systems. The DTE is responsible for managing all the
DT systems under its coverage to assist in the operation of the relevant physical systems.
From the application point of view, DTE can be used to manage large systems. At the
same time, a synchronization mechanism needs to be implemented to speed up the query
processing among multiple digital systems.
2.2.3. Architecture for IoT Systems
As massive numbers of IoT devices have been implemented across a variety of real-
world applications and physical locations, and the collection, aggregation, storage, and anal-
ysis of their generated data is a prodigious challenge. Figure 5 illustrates a generic architec-
ture for IoT systems [47], which consists of four layers (i.e., object layer, communication
layer, application layer, and end-user layer).
Figure 5. DT architecture for IoT.
Future Internet 2022, 14, 64
7 of 25
The object layer represents all IoT sensors and is used to provide data and information
for different IoT-driven applications. It contains all the components that make up the
physical system. The communication layer provides communication network infrastructure
to collect IoT devices and collect data for DT. For example, a number of edge gateways can
be deployed to collect and aggregate information from sensors and send the information
to the application layer. IoT sensors and gateways use different communication protocols
to collect and transmit information. After the gateway in the object layer obtains the
information, it transmits the data to the application layer. The application layer includes
the digital systems of DT. At this level, the DT system ﬁrst maps all sensor and gateway
information to the digital system. At the same time, we can use the IoT naming service
to name the mapped IoT sensors and local gateways, so that the digital system can locate
different resources [48]. The digital system can then use ML/DL models to perform
prediction and analysis. By doing so, the digital system can control the actuators in the
target layer based on the prediction results. Furthermore, the prediction and analysis
results can provide different services in the end-user layer. The end-user layer provides
services for users, who can send requests to the application layer. After that, the digital
system will analyze the information obtained and respond with the results accordingly.
Based on the architecture of the DT system, data representation and communication
protocols are essential for data sharing within the DT, as well the provisioning of services
to end users.
2.3. Data Representation
Data representation enables components to understand data from different domains [49–51].
Several commonly used data representation protocols in DT are DT Deﬁnition Language
(DTDL) [52], FIWARE [53], OPC Uniﬁed Architecture (OPC UA) [54,55], and Feature-Based
DT Framework (FDTF) [56]. In particular, DTDL is an open-standard platform proposed by
Microsoft [52], which can realize data transmission within the system or between different
systems. The summary of data representation protocols is listed in Table 1.
Table 1. Protocols of DTs.
Protocol Name
Protocol Type
Protocol Characteristics
DTDL
Data Representation
As an open-standard platform, it deﬁnes six characteristics
of IoT components and enables seamless data transmission
between different DTs.
FIWARE
Data Representation
It supports DT data transmission and the processing of con-
textual information received from various IoT components.
OPC UA
Data Representation
As a modeling framework, it can retrieve information from
raw data, support data manipulation, and provide monitor-
ing capabilities.
FDTF
Data Representation
As a DT structure, it enables the DT system to share informa-
tion based on the data link between DT components.
CoAP
Communication
As a specialized web communication protocol based on the
User Datagram Protocol (UDP), it is tailored for resource-
restricted devices, supports the transmission of data via Hy-
pertext Transfer Protocol (HTTP), and provides a publish and
subscribe mechanism to simplify the process of obtaining
continuous data from the sensor.
MQTT
Communication
As a communication protocol based on Transmission Con-
trol Protocol (TCP), it enables lightweight way for IoT
devices to communicate, provides reliable data transfer,
and can establish a long-existing outgoing TCP protocol
to enable transmission.
Future Internet 2022, 14, 64
8 of 25
Table 1. Cont.
Protocol Name
Protocol Type
Protocol Characteristics
Modbus TCP/IP
Communication
As a communication protocol based on Transmission Control
Protocol (TCP), it realizes the connection between industrial
devices, provides reliable data transfer, and contains built-in
checksum protection.
URLLC
Communication
As a communication protocol, it tends to achieve low la-
tency and reliability in the transmission process between
IoT devices.
DTDL [52] deﬁnes the following six characteristics of IoT components: (i) Interface: the
basic information of a component (device ID, device type, display content, etc.). Different
interfaces can inherit attributes from parent interfaces (e.g., charging station components
can inherit some attributes of the parking lot such as addresses); (ii) Telemetry: the data sent
from any component in the IoT-based DT (the raw data from IoT sensors, the processed
data generated by DT models, etc.); (iii) Property: the status of the components in the
IoT-based DT (i.e., the device is read-only or read-write). This can also include the different
states between different DT (whether the data between the two DTs are consistent, etc.); (iv)
Command: operations that any DT can understand; (v) Relationship: the connection between
the DTs (e.g., the relationship between the house and the cleaner is cleaned up); and (vi)
Component: the entities that exist in the DT, including sensors, gateways, and digital systems.
Based upon these six components, DTDL can be composed of multiple DTs with a uniﬁed
structure and data, which enables seamless data transmission between different DTs.
FIWARE [53] is also an open-source project designed to support DT data transmis-
sion and the processing of contextual information received from various IoT components.
FIWARE developed a data modeling standard called FIWARE NGSI that describes the
collection, processing, and change notiﬁcation operations of contextual information. FI-
WARE NGSI is an object-oriented data protocol that uses context objects to represent
physical/digital objects. NGSI provides a data model that enables data exchange between
multiple DTs. It also uses NGSI-LD to represent the relationship between different objects
and uses JSON-LD for encoding to unify the data format.
OPC UA [54,55] is a modeling framework that can retrieve information from raw
data. OPC UA deﬁnes the data transmission and understanding model between different
systems. It also has a mechanism to traverse all data and analyze its semantics. OPC UA
supports data manipulation to make it easier to manage data under the DT architecture.
Furthermore, it provides monitoring capabilities, enabling the DT system to manage the
state of all sensors under the control.
FDTF [56] is a DT structure that enables the DT system to share information based on
the data link between DT components. This structure realizes data sharing between digital
systems and physical systems, as well as data sharing within different DT models.
2.4. Communication Protocols
The communication protocol realizes the information transmission between IoT
devices, and between IoT systems [49–51]. There are some representative communica-
tion protocols common across IoT systems, including Constrained Application Protocol
(CoAP) [57,58], OASIS Standard Message Passing Protocol (MQTT) [59], Modbus TCP/IP
Protocol [60–64], and Ultra Reliable Low Latency Communication (URLLC) [65]. The sum-
mary of communication protocols are listed in Table 1.
CoAP [57,58] is a specialized web communication protocol based on the User Data-
gram Protocol (UDP), tailored for resource-restricted devices (battery-powered IoT devices,
etc.). CoAP can be used to handle communication between IoT devices. It is designed to be
compatible with the transmission of data via Hypertext Transfer Protocol (HTTP) and is
Future Internet 2022, 14, 64
9 of 25
more compatible with Web-based applications. CoAP can provide a publish and subscribe
mechanism to simplify the process of obtaining continuous data from the sensor.
MQTT [59] is the communication protocol based on Transmission Control Protocol
(TCP). It is a lightweight way for IoT devices to communicate with each other through
MQTT messages. These messages are lightweight due to their optimized headers, so
that the use of network resources can be reduced. The MQTT protocol includes MQTT
clients and MQTT brokers. The MQTT client can be IoT sensors, and the MQTT broker can
be deployed in an IoT gateway, which is used to manage data communication between
sensors and control commands to IoT actuators. Since MQTT is based on the TCP protocol,
it can provide reliable data transfer. Furthermore, IoT sensors may need to establish a
connection with the IoT gateway within a certain period of time. In this case, with the
help of MQTT brokers, IoT sensors can establish a long-existing outgoing TCP protocol to
enable transmission.
Modbus TCP/IP [60–64] is a communication protocol used in the industrial ﬁeld to
realize the connection between industrial devices. The protocol was initially proposed
to provide communication between Programmable Logic Controllers (PLCs). Modbus
TCP/IP uses port 502 for data transfer. Meanwhile, the protocol contains built-in checksum
protection, which can ensure the reliability of the data transmission required in IoT systems.
With the aid of Modbus TCP/IP protocol, reliable operations can be supported and applied
to the smart grid, smart manufacturing, and other IoT systems.
URLLC [65] is a communication protocol that can achieve low latency and reliability
in the transmission process between IoT devices. Generally speaking, URLLC is based on
the 5G wireless protocol, which can reduce the delay to 0.5 ms. In order to reduce the delay,
URLLC uses a mini-slot for smaller time resource units, removes the scheduling mechanism
of direct channel access, supports asynchronous upload, and adopts dynamic scheduling
algorithms such as hybrid automatic repeat request (HARQ). In order to improve reliability,
URLLC utilizes a channel estimation mechanism, a transmission diversity mechanism,
and a bit error rate reduction mechanism. With the aid of URLLC, IoT sensors can exchange
information faster and more reliably.
3. Integrating DT in CPS
In this section, we review some existing efforts on integrating DT in different CPS
such as the smart grid, smart transportation, smart manufacturing, and smart cities. DT
in CPS is an evolving ﬁeld of research. There have been growing research interests on
integrating DT in CPS. Figure 6 shows the number of recent publications from 2018 to 2022
from IEEE Xplore on the subject of DT and CPS from four representative CPS (smart grid,
smart transportation, smart manufacturing, and smart cities). The included papers are
related to both DT system and CPS system in the content or in the experiment.
Figure 6. Number of publications related to DT and CPS in IEEE Xplore.
Future Internet 2022, 14, 64
10 of 25
3.1. Framework
Figure 7 describes an architecture option of a DT-driven smart-world system motivated
by the existing efforts on DT [33]. The architecture consists of three main components:
the physical subsystem, the Artiﬁcial Intelligence (AI) model, and the DT model. The IoT
gateway from each physical system collects and aggregates the data from the physical
system. With the support of communication protocols, data can be transmitted from the
physical system to the AI model. The AI model is used for data analysis and model design
based on the states of physical system. Then, the AI model stores its trained model as a
DT model to represent the digital perspective of physical system. If the conﬁguration of
physical system does not change, the DT model can guide the physical system to react
based on the data collected by physical system. If the conﬁguration of physical system
changes or needs to respond differently to the same situation, the AI model can update its
model according to the changes of physical system and revise the DT model to further assist
the operations of physical system. Recall that DT can assist in the control and operation of
physical systems [34].
Figure 7. DT-based CPS.
3.2. Smart Grid
As a key energy infrastructure, the smart grid leverages information communication
technology (i.e., cyber system) to provide two-way communication (of both energy and
information) so that the monitoring and control of the grid can be improved and consumers
can be engaged. The physical infrastructure of the power grid is composed of power gener-
ation facilities, transmission facilities, and power distribution facilities. Power generation
facilities are responsible for generating electricity, while transmission facilities are used
to deliver power to distribution facilities. Finally, power distribution facilities provide
electricity to consumers.
With the integration of the cyber system, the next-generation power grid, denoted
as the smart grid, has been envisioned to provide more efﬁcient energy service for users,
including reliable and intelligent distribution management, renewable energy integration,
energy storage, grid monitoring and control, and the integration of electric vehicles into
the grid [5]. Generally speaking, the smart grid is a highly distributed grid system, which
integrates information communication techniques, including sensing, networking commu-
nications, data analytics, and machine learning [66,67]. These technologies can improve the
reliability, efﬁciency, and security resilience of the grid system.
The smart grid system is a large-scale distributed system. To improve the monitor
and control of the grid, it is critical to know the states of physical objects (voltage, current,
etc.) in the system. To do so, a massive quantity of sensors can be deployed in the grid
to measure the state of critical objects and derive the accurate and insightful knowledge
Future Internet 2022, 14, 64
11 of 25
of physical objects based on measurements. In the past, both static and dynamic state
estimation have been applied to the monitoring and control of the grid, and bad data
detection algorithms have also been designed to deal with corrupted, invalid measurement,
and/or malicious injection data, which can be generated via measurement error, sensor
failure, or even cyber threats [24,25]. Note that in addition to potential failures in the grid,
cyber threats can directly or indirectly affect the grid’s operations by injecting malicious
measurement data and/or manipulating the critical control information to the actuator.
To handle cyber threats, it is critical to not only monitor the state of physical objects but also
monitor the state of cyber components. In this regard, the DT can be a viable approach to
link the objects in the physical world to the cyber world.
DT uses a data-driven modeling strategy to map the physical grid to the digital grid
so that monitoring and management operations for the entire grid can be enabled. Based
on the DT architecture that we have discussed, the smart grid system can be divided into
several layers: object layer, communication layer, application layer, and end-user layer.
In the object layer, grid components include power generation facilities, transmission
facilities, and power distribution facilities. The communication layer is responsible for
the communication to connect objects, supporting data exchange between the objects and
the application layer, and the data communication within the object layer. For example,
the gateway of the communication layer contains the device information of object layer.
When the application layer needs data, the gateway can retrieve the data from a speciﬁc
device as required. The application layer can also construct a digital model based on the
device distribution information from the gateway.
The application layer includes a digital representation of the gateways from the phys-
ical system, which contains device information from the object layer; it communicates
between the application layer and the object layer through the communication layer. In the
application layer, the AI model is trained based on the data collected from the object layer,
and the trained model is stored in the data storage for future use. If the physical state of the
object layer changes, the application layer can send commands to some actuators in the ob-
ject layer to control the grid based on the current data and the trained model. If the physical
components of the object layer change, the AI model can perform model updates to reﬂect
the changes as well. The end user layer uses the information processed by the application
layer to provide services for end users, including smart grid management systems, smart
charging systems for autonomous vehicles, and hybrid energy management systems.
There are a number of research efforts on DT for the smart grid [38,39,68–71]. For
example, General Electric (GE) proposed two models related to the use of DT in wind
farms [68,69]. In the object layer, a communication network was designed to enable
wind turbines to communicate with each other. A wind turbine control system was also
implemented to control one or more wind turbines. The middleware layer includes a cloud-
based infrastructure with the support of the communication network so that the data (e.g.,
state of turbines) can be collected and turbines can be remotely controlled via gateways. It
also includes digital models that represent digital replicas of wind turbines. The digital
model can be updated based on the information extracted from the object layer, and the
wind farm can be controlled through an industrial gateway. In addition, GE designed a
graphical user interface (GUI) in the application layer to show the digital representation of
the wind farm and perform the control and management operations of the wind farm.
Ahmed et al. [39] proposed a microgrid DT model based on the IoT to mitigate cyber
attacks. The object includes microgrid, local controller, and area controller. Real-time
balancing algorithms were implemented in each controller. If some microgrids are attacked
and go ofﬂine, the area controller can obtain information, and the balancing algorithm will
not transfer more power to the ofﬂine area based on the tampered data. This architecture
can also mitigate distributed denial of service (DDoS) attacks and false injection attacks.
Likewise, Nikolaos et al. [38] used DT to manage a large number of devices in the smart
grid system. To be speciﬁc, they used the spike neural network (SNN) deployed on
the smart meter in the grid to detect fault nodes. A transient state estimator (TSE) was
Future Internet 2022, 14, 64
12 of 25
designed to reveal the dynamic state of the smart grid. William et al. [70] leveraged deep
learning algorithms to analyze data from the supervisory control and data acquisition
system (SCADA) to assist the DT in detecting physical faults in the smart grid system.
Likewise, Payam et al. [71] proposed a DT framework with artiﬁcial neural networks
(ANN) for distributed smart grids to ensure real-time model generation, veriﬁcation,
and identiﬁcation.
3.3. Smart Transportation
The smart transportation system can be regarded as a CPS, which provides a va-
riety of services for the transportation domain, including trafﬁc management control.
Some applications in smart transportation systems include toll payment, vehicle operation,
emergency, vehicle control and safety management, and maintenance and construction
management [6,72,73]. Since the smart transportation system requires real-time data trans-
mission and analysis capabilities to implement time-sensitive services such as autonomous
vehicles, it is difﬁcult for traditional models to complete model training under massive
data within a short time. It is additionally challenging for traditional smart transportation
systems to complete the collection and aggregation of all sensor data within a short time.
In this case, the DT model can use high performance cloud/edge servers in the digital
system to conduct data aggregation and model training so that real-time processing and
transmission can be achieved.
Based on the architecture of the DT that we have discussed, DT in the transportation
system consists of four layers. The object layer contains the components of the infrastructure
and participants (e.g., drivers), including sensors on the vehicle, trafﬁc cameras, and other
trafﬁc sensors. The communication layer uses a variety of gateways to process sensor data
from the object layer, and handle data transmission between the object and application
layers. The application layer maps the gateway from the communication layer to realize
data transmission between the communication layer and the application layer. Based on
the data and sensor information from the gateway, the DT can use ML/DL technology
to train the model and store it in data storage. The end-user layer can navigate based
on the data processed by the application layer, assist the driving of autonomous vehicles,
and cooperate with smart cities and smart grids to reduce transportation costs, reduce
energy consumption, and make the charging process of electric vehicles more efﬁcient.
There have been some research efforts on DT-driven smart transportation. For example,
Peter et al. [74] proposed a scheme for DT-driven smart transportation that attempts to
optimize trafﬁc ﬂows in urban areas. The proposed smart transportation system includes an
AI model, a digital replica of the road network, and various trafﬁc control and management
services. The system obtains data from the object layer, including trafﬁc lights, sensors,
and cameras. After the smart transportation system processes the data, it will build an
application at the end-user layer based on the collected data, which is called the city service
information system. Then, operators can manage the entire system at a high level based on
the end user’s application. Additionally, Sagar et al. [75] proposed a DT-based adaptive
trafﬁc signal control (ATSC) to reduce the waiting time at intersections, thereby improving
the driver’s driving experience. In that study, the Urban Trafﬁc Simulation (SUMO) was
used as the simulation platform.
Additionally, Wang et al. [76] designed a DT-based veriﬁcation platform to perform
veriﬁcation between different metro systems. The object domain includes operation center;
trackside and train information is collected, and data is transmitted to the DT system of the
application layer through various communication protocols, including 4G, 5G, Ethernet,
and NB-IoT. The DT platform uses ML/DL, data fusion, and data modeling to analyze all
data and assist the end-user level in scheduling, train monitoring, pedestrian monitoring,
etc. Sahal et al. [77] proposed a DT structure combined with blockchain to enable DT-
based intelligent transportation systems to achieve interoperability, identity veriﬁcation,
distributed ML/decision-making, and scalability and robustness. Likewise, Guo et al. [78]
demonstrated a DT-based 3D collaborative vehicle infrastructure system (CVIS) to visualize
Future Internet 2022, 14, 64
13 of 25
real-time road data and use LIDAR as road sensors. They used the ROS bridge as a
communication protocol to communicate between the physical and virtual worlds.
3.4. Smart Manufacturing
The smart manufacturing system, as a general concept, is the integration of traditional
manufacturing systems and processes with information communication technologies to
enable advanced intelligence and process optimization and automation. The demands
of current manufacturing systems can be complex in nature, due to the challenges of
scalability, efﬁciency, delivery, or design requirements [79]. The smart manufacturing
system is the utilization of emerging technologies to massively optimize production in
terms of throughput, efﬁciency, precision, loss, resource consumption, scale, and value [7].
Traditional manufacturing systems are comprised of shop ﬂoor hardware that works
as a unit to streamline the production of a deliverable product. In contrast, the smart
manufacturing system integrates communication and computing technologies to utilize
information generated from traditional manufacturing systems to make a more complete
representation of a product life cycle. The application of IoT to industrial systems, or Indus-
try 4.0, relies on technologies such as sensing, control, communication, computing, and data
science to support information ﬂows between different components of the manufacturing
system, allowing for better system interoperability and use.
One major limitation in manufacturing systems is the ability to automate and mass
produce in a manner that is efﬁcient and cost-effective. With the shifting paradigm in
manufacturing of custom user deliverables, there is an increased challenge to provide
custom solutions in a method that can be massively produced by manufacturing systems.
A common issue in manufacturing is the ability to generate a deliverable that is ﬂexible to
the user’s needs while still maintaining automated systems that can quickly and efﬁciently
create products. At scale, it is often difﬁcult to analyze how changing requirements in
the product design or supply chain will impact variables such as cost and production
timelines while retaining quality and efﬁciency. Additionally, adoption rates are going
to be a challenge for manufacturing environments that are looking to incorporate smart
manufacturing systems in their product life-cycle. A core technology for enabling smart
manufacturing is the availability of information from the physical objects (i.e., shop ﬂoor
equipment) through IoT sensors connected to IoT networking infrastructure.
Implementation of DT in the smart manufacturing system can help evaluate the
effectiveness of large-scale production environments by utilizing models for analyzing
production efﬁciency and design factors. The link between the virtual and physical rep-
resentation of a manufacturing system (i.e., in the way of DT) can determine whether a
design is going to be cost-effective by integrating with decision support systems such as
supply chain management and timeline forecasts. The integration of smart supply chain
technologies involves a real-time link between the production environment and the sup-
pliers and distribution centers to determine the deliverable dates [80]. Determining the
availability of materials required for manufacturing production will allow the system to
generate a cost model and timeline for delivering a ﬁnal product.
Monitoring the physical production environment with DT systems can allow for the
real-time analysis of system health on physical things (i.e., equipment, tools, and hardware)
and prevent delays based on environmental factors. In the event of an anomaly detection
on a manufacturing system, the DT model can determine whether the work load should be
rerouted to another system in the manufacturing line to avoid delays in production [81].
IoT sensors in manufacturing equipment allow for real-time monitoring, enabling the de-
tection of events that could cause breakdowns in the manufacturing system and providing
alternative scenarios for maintaining system efﬁciency to prevent delays in production
timelines [82].
Since smart manufacturing can apply to many different levels of technologies in
manufacturing systems, it is important to consider the level of adoption for technologies in
Industry 4.0 scenarios. For example, Frank et al. [80] analyzed different levels of adoption
Future Internet 2022, 14, 64
14 of 25
in several different manufacturing domains and concluded that the implementation of
Industry 4.0 technologies is interrelated and provides potential beneﬁts when more systems
are integrated with smart manufacturing processes. Additionally, the utilization of both
front-end technologies and base technologies could provide more complete integration
between physical systems and virtual representations that can better handle the challenges
of requirement complexity and decision support systems.
With the support from the communication layer and techniques to enable data aggre-
gation, DT implementation can help with the following scenarios in a smart manufacturing
system. The ﬁrst scenario is the detection of fault tolerance and device health, which can
help smart manufacturing systems to avoid outages by predicting device failures and
rerouting workﬂows in the production process. In particular, cloud-based frameworks
that are designed to handle large amounts of data utilize embedded sensor systems in
manufacturing devices in order to monitor system health, leading to the creation of pre-
dictive models for avoidance procedures [83]. In the example of a robotic gripper in a
manufacturing production line, Redelinghuys et al. [82] investigated anomaly detection in
the gripper closing speed for detecting via pressure sensor to detect faults and degradation
that could lead to failure and considered utilizing the result to reroute production trafﬁc to
another assembly line. This type of fault detection compares recent samples to historical
data and builds a model that determines when a device is likely to fail in a production
environment, enabling the automated scheduling of preventative maintenance.
The second scenario is supporting supply chain management, which involves the
integration of DT systems and the communication of real-time data between suppliers and
distribution centers. The tracking of products can be integrated into the supplier systems to
inform the manufacturer system and can be integrated with the customer-facing deliverable
to accurately determine product delivery timelines and end-to-end supply chain logistics.
The tracking of goods required for a customer deliverable can be remotely monitored and
integrated between supplier and manufacturer systems to determine the availability of
goods required to produce a product [84]. In the event that a good required for a custom
deliverable is not available, the decision support system can determine whether there is a
more suitable supplier for the product and whether it would be cost-efﬁcient to utilize a
different supplier. By generating a pricing and timeline model for the availability of goods,
the manufacturer can determine whether the product is worth producing and provide an
accurate cost analysis to the customer.
Note that one of the emerging challenges of manufacturing systems is the ability to
create highly customized products in a manner that is efﬁcient. Manufacturing in general is
often focused on the mass production of a good or product in order to decrease the cost and
effort required per unit. This type of mass production is often associated with processes
that are easily automated to speed up the production time. With the shifting paradigm
of manufacturing trending towards more customized deliverables [85], product variety
becomes a factor when designing production systems that will maintain efﬁciency while
still meeting diverse customer requirements. Integration with DT systems can allow for
the application of ML/DL algorithms and modeling technologies to determine whether a
custom deliverable requirement is feasible in a given manufacturing system. Manufacturing
systems need to be both ﬂexible and efﬁcient in order to be useful for custom deliverable
objectives [86].
There are some existing research efforts on the evolution of smart manufacturing
concepts and the best way to apply DT technologies for more robust manufacturing sys-
tems [30,86–88]. For example, Lu et al. [86] reviewed the standards utilized in smart
manufacturing systems, applied their research toward the production of new standards,
and further envisioned scenarios for smart manufacturing systems, some of which can
beneﬁt from the application of DT systems. Kritzinger et al. [30] took the application of
smart manufacturing one step further by studying the application of DT as an enabling
technology for Industry 4.0. Likewise, Brennet et al. [87] discussed the convergence of digi-
Future Internet 2022, 14, 64
15 of 25
tal and physical systems for Industry 4.0 through the application of Personalized Product
Emergence Processes (PPEP) and additive manufacturing technologies.
Furthermore, the implementation of DT in smart manufacturing systems was inves-
tigated [81,89,90]. For example, Tao et al. [89] summarized the deployment structure of
DT for smart manufacturing based on the concept of DT Workshop, which enables digital
systems and physical systems to synchronize with one another. In this case, the digital
system can be virtualized based on data from the physical system, and the physical system
can be optimized based on the instructions from the digital system. In order to better
explain how to deploy Digital Twin Shop-Floor (DTS), DTS was divided into four parts:
physical shop-ﬂoor, virtual shop-ﬂoor, shop-ﬂoor service system, and shop-ﬂoor DT. Like-
wise, Kamil et al. [90] implemented a DT in an experimental assembly quality production
inspection system. In particular, they used radio-frequency identiﬁcation (RFID) and cam-
eras in the physical system and used a programmable logic controller (PLC) system to
collect data. The OPC UA framework was considered to transfer data between the physical
system and the digital system. The digital model consists of a 3D model created in CAD
design software and is simulated and virtualized using the Tecnomatix platform. The cloud
platform was integrated into the digital system for data analysis so that the assembly
quality inspection could be realized without stopping the manufacturing process. Open-
source technology can also beneﬁt the development of applying DT in smart manufacturing
scenarios. For example, Aghenta et al. [91] proposed a low-cost IoT-based SCADA system
solution. In addition to providing the basic functions of a traditional SCADA system, this
particular system can not only support data acquisition, transmission, and presentation
but also the monitoring and control of physical objects.
3.5. Smart Cities
The objective of the smart city is to leverage information communication and data-
related technologies so that resources can be efﬁciently used, leading to better quality of
life, reduction of resource input, etc. So far, the majority of focus has been on government
and energy initiatives, followed by transportation, building, and water, among other goals.
A number of research and development efforts on smart cities and DT applications have
been generated [92–96]. Similar to smart manufacturing, smart cities are the combination
of a wide range of IoT domains to address the complex challenges in cities and must
incorporate cloud/edge computing with big data collection and analysis as essential
techniques to drive the realization of efﬁciency and optimization [11,97].
It should be noted that the development of the smart city has involved several op-
portunities and challenges: (i) people’s expectations are constantly changing. How can
people’s expectations be accounted for when they are frequently and forever changing,
even when real-time communication is a reality? How can the change in expectation be
evaluated? (ii) How can the latest technologies be utilized to improve the efﬁciency of
our government? How can we forecast outcomes and avoid potential losses or mistakes?
How can we mitigate the risks? These questions have become the urgent issues that a
government must consider with respect to smart cities. Similar to numerous practices
in smart manufacturing, in smart cities, we could leverage DT to detect and address a
problem before it arises, reducing cost, rather than attempting to solve a problem after it
has occurred. If the results from the DT match the expectation, data can be transferred to
real physical objects to implement the changes in a fast and seamless way.
Some efforts toward integrating DT with smart cities have already been made [98–103].
For example, Deng et al. [98] reviewed some key technologies in Digital Twin City (DTCs),
such as surveying and mapping, building information model, IoT, next-generation wireless
networking, and blockchain. Shahat et al. [99] reviewed some challenges of DT cities and
discussed some research that leveraged DT into smart cities. Note that while the city DT
cannot provide solutions for addressing problems in cities, DT can provide beneﬁts in
several areas. In order to demonstrate the performance of DT, it is necessary to conduct
research on data collection, data management, the utilization of big data, virtual reality
Future Internet 2022, 14, 64
16 of 25
(VR), IoT, and 3D Modeling. Likewise, Shirowzhan et al. [100] discussed technologies
that can be useful for enabling smarter cities. They identiﬁed trends in geospatial science,
particularly in the application of geographic information system (GIS), and observed the
impacts of newly developed online applications such as ArcGIS Urban.
More and more smart cities around the world are embracing DT to replicate its
performance and response to changes. By the year 2020, 118 cities were using DT in Smart
City projects and systems. Cities are also using DT to reduce carbon dioxide emissions and
manage trafﬁc efﬁciently. According to ABI Research, DT could assist cities in carrying out
cost-effective urban resource planning [104]. We believe that DT has the potential to further
improve upon the already signiﬁcant gains that it has achieved.
4. Challenges
Integrating DT into CPS can not only improve the efﬁcient operation of CPS through
increased intelligence, it can also assist CPS in providing more valuable service to end-
users. Recall that as DT is a digital replicate of physical things, it is critical to make DT
capable of representing a variety of things in a timely, accurate, and efﬁcient manner.
The realization of such a DT raises numerous challenges to the networking, computing,
control, and data analysis of IoT. Furthermore, the design of DT shall consider the numerous
exceptional requirements of CPS (e.g., latency, reliability, safety, scalability, security, and
privacy). To address such challenges, designing DT offers opportunities for novel and
interdisciplinary research efforts.
4.1. CPS Challenges
As a complex system that requires the coordination of network, computing, and con-
trol, CPS has strict performance requirements in different application scenarios. Generally
speaking, CPS applications require very low latency, high reliability, and large scalability.
Taking the smart transportation system as an example, suppose we are designing applica-
tions related to autonomous driving. Vehicles need to be able to quickly collect pertinent
information. This information includes data collected by sensors, transmitted through the
Internet of Vehicles, and so on. Then, the vehicle needs to process this data quickly, extract
usable information, and control the vehicle according to the determined situation at the
time. Since vehicle driving is closely related to personal safety, there is no doubt that the
reliability of autonomous driving is our primary consideration. The issues that we need to
consider include network failures, computing hardware failures, and many more.
Moreover, because the number of vehicles in each scenario will be different, we need
to ensure the scalability of the autonomous driving application that we design to handle
the problems caused by the large number of vehicles, such as network congestion and high
control algorithm complexity. From this example, we can conclude that the performance
requirements of CPS are very strict. The overall performance of CPS is the result of multiple
subsystem (network, computing, and control) interactions and is synthesized within the
CPS. This interaction means that any slight change in the performance of any one subsystem
can have a compounding effect on the performance of other subsystems, thereby causing a
complex impact on the performance of the entire CPS system. Thus, when building a DT
for CPS, it is challenging to not only meet all these strict performance requirements but also
to reﬂect the interactions between the various subsystems in a timely manner.
4.2. Data Science Challenges
Building the DT of a complex system itself is very challenging, involving mathematical
modeling and data analysis. There are two major approaches to building an accurate DT:
model-driven and data-driven. When we adopt the model-driven approach, we use
mathematical models to represent physical systems. Therefore, knowing how to build
a mathematical model that accurately represents a complex physical system in CPS is a
challenging problem. Since there are many variables involved in the physical system of
CPS, the mathematical model will be signiﬁcantly complicated, typically with properties
Future Internet 2022, 14, 64
17 of 25
such as non-linearity, highly-coupled, and time-variance. When we adopt a data-driven
approach, we collect massive amounts of data from the physical system that reﬂects its
status over time. The process of collecting and selecting these data poses some challenges.
First of all, in CPS, one type of data may be collected from multiple sources, and the
hardware conditions of these sources will be different, such that it is difﬁcult to ensure that
the quality of all data is the same. Second, the storage and transmission of this massive
amount of data creates signiﬁcant overhead to the system. In order to truly reﬂect the
timely updates of the physical system, we often sample the state of the physical system
at a very high frequency, and these data require considerable storage space and pose
signiﬁcant overhead for networking and computing infrastructures with strict performance
requirements. Therefore, one fundamental data science problem is how to collect the
least amount of data without signiﬁcantly and negatively impacting the efﬁcacy of DT.
In conclusion, how to effectively construct a DT for the complex system with the least
amount of data is a challenging problem that needs to consider both mathematical modeling
and data science aspects.
4.3. Optimization Challenges
Realizing a DT in CPS that accounts for the interactions of computing, control, commu-
nication, and data analysis modules in an end-to-end chain is challenging. The communica-
tion resource allocation algorithms, such as time and frequency resource scheduling, are
very complex, especially when combined with massively distributed networking devices
and low latency requirements. In addition, the computing resource allocation, such as
task-ofﬂoading in an edge/cloud computing architecture, is another optimization problem
with stringent performance constraints. Furthermore, the control mechanism, possibly
event-triggered or time-triggered control, or both, yields still another optimization prob-
lem. In addition, analysis of the collected data is highly complex, requiring prodigious
feature extraction, and training (or at least validation), coupled with potentially continual
prediction or classiﬁcation to satisfy real-time requirements.
The DT is a combination of the real-time computing, real-time control, and real-time
communication, which generates the joint/integrated optimization problem of computing,
control, and communication. Consider VR-supported smart manufacturing as an example.
First, we need to deliver massive amounts of sensing data with required latency. Then,
we need to use the graphics engine to generate the digital model in real time. Finally, we
need to execute the control command within the latency constraint. Since any problem in
this chain will directly affect the performance of the other, even in a centralized system
with superior hardware conditions, it is very challenging to perform joint optimization
on this VR system. Further, the distributed system of CPS only makes the problem of
joint optimization much harder. For example, in our previous work [105], we adopted
deep reinforcement learning to help conﬁgure the network and dynamically change the
sensor sampling rate at the same time to improve the control performance of a distributed
smart manufacturing system. However, by introducing DT to the CPS, there are more
processes that need to be considered. For example, in the control process, there are two
processes, such as the domain expert controlling DT and DT controlling the physical objects.
The computing of DT in CPS needs to consider three computing processes, such as the
computing process of generating a digital copy of a physical object, the computing process
of the interaction between DTs in a simulated scenario, and the computing process of actual
CPS tasks. The communication of DT in CPS needs to consider the communication between
the physical object and the virtual clone, the communication between the DT and other
DTs, and the communication between the DT and the human control interface. These extra
processes make the optimization problem more difﬁcult to solve.
Taking into account the limited resources of the CPS system, we also need to optimize
the large amount of data generated in these processes from the perspective of data gen-
eration, data storage, and data transmission. From a data generation perspective, when
we generate the data needed to build a DT in CPS, the quality of the data is a major issue.
Future Internet 2022, 14, 64
18 of 25
Because we need to deploy a massive number of CPS devices, the hardware conditions of a
single CPS device are often very limited. In addition, in the CPS environment, one type
of data may be collected by multiple sources. Thus, how to effectively select data sources
for different CPS applications is a challenging problem. From a data storage perspective,
when we are building the DT, in order to truly reﬂect the timely update of physical objects,
we often sample the state of physical objects at a relatively high frequency. Inevitably,
an incredible volume of data will be collected on the DT server side. On one hand, these
data can be used to assist in the development of other DT systems; on the other hand, these
data take up signiﬁcant storage space. Because there is not a simple linear relationship
between the amount of stored data and the performance of the DT system, the question of
how to accurately select useful data for storage has always been difﬁcult to answer. From a
data transmission perspective, due to the heterogeneity of CPS systems, IoT/CPS devices
use different communication technologies. When we need to transmit data between these
devices, we usually deploy a gateway with various radio interfaces for data exchange. This
solution will bring additional hardware costs and potential network bottlenecks. Con-
sidering that the DT system has very strict requirements on timing and latency, it is very
challenging to design networking infrastructure to support real-time communications so
that the information between different components can be delivered quickly and efﬁciently.
4.4. Security and Privacy Challenges
We now discuss the security and privacy challenges. Since DT needs to update the
state of physical objects in real time through network communications, DT will be subject
to cyber attacks, such as integrity attacks on physical hardware and sensors, transmission,
and digital systems. Taking the data integrity attack as an example, the adversary can
directly attack IoT devices as data collectors, causing them to upload invalid/misleading
data. Alternatively, an adversary can attack the gateway, to which the IoT device uploads
data, mixing the invalid/misleading data with the correct data collected by IoT devices.
Finally, the adversary could directly inject false data into the DT. Because the DT and
physical objects are closely connected, any one of these attacks will yield a signiﬁcant
impact on the integrity of the entire system.
Additionally, from the perspective of conﬁdentiality, the DT applications contain
a large amount of privacy-sensitive information, such as medical records, autonomous
vehicle sensing information, and real-time smart grid operation information. Therefore,
it is not only necessary to implement an authentication mechanism for physical objects
but also an authentication mechanism for digital communication and machine-to-machine
transmission. Nonetheless, it can be costly to implement authentication mechanisms on
low-energy IoT devices. In this case, knowing how to handle the authentication process
on devices with limited power has become a challenge. From a usability point of view,
DT applications rely on sensor information from the object layer to help the DT build
the digital clone of the physical system. In this case, adversaries can launch attacks on
sensor or gateway, such as a denial of service (DoS) attack or malware propagation. Once
the gateway or sensor is compromised, it is difﬁcult for DT to obtain the overall states of
the physical system. For this reason, it is important to propose and validate mitigation
mechanisms to reduce the impact of such attacks.
5. Research Directions
In extending the DT to IoT scenarios, promising new ﬁelds arise that are worthy of
further investigation. We will discuss the future research directions from the following as-
pects: performance, new DT-driven services, modeling and machine learning, and security
and privacy.
5.1. Performance
As we discussed in Section 4, the DT in CPS has very strict performance requirements
to achieve real-time computing, real-time control, and real-time communication. We believe
Future Internet 2022, 14, 64
19 of 25
that the joint optimization of sensing, control, networking, computing, and data analysis is
critically important for DT to meet these performance requirements. There have been some
works focused on one of these optimization targets (sensing, control, networking, or data
analysis), and some results have been achieved. However, if we need to maximize the
overall performance of the system, we must study the interaction between all components
and design a joint optimization strategy. Taking the intelligent transportation system as
an example, suppose we are generating DT for moving vehicles in a certain area to better
manage trafﬁc. We use sensor data from both vehicles and cities to build DT. When we
select data, simply having more data is not optimal. Instead, the pre-processing of the data
should account for the quality of the data, the bandwidth of the network, the computing
power of the infrastructure, and the Quality of Service (QoS) requirements of the speciﬁc
application. Similarly, when we are transmitting the data, we need to consider not only
the current communication environment but also the mobility of the vehicle, and the data
storage space of the vehicle, among others.
5.2. New DT-Driven Services
By combining DT and IoT search services, we can interconnect different CPS systems
and provide more services. Speciﬁcally, the DT bridges CPS in disparate domains, such
as transportation, energy, and manufacturing, to obtain a ubiquitous connection. The DT
enables more data sharing to create abundant content that improves the IoT search results.
For example, the DT bridges electric cars that primarily consume energy with the smart grid
that primarily generates and stores electricity. With DT, electric cars can obtain seamless
and efﬁcient energy supply via the information from digitized charging piles, solar planes,
and so on. IoT search services such as location-based search and content-based search can
also help us ﬁnd IoT devices and data to build DTs [48,106]. This is particularly important
in the rapidly changing CPS environment.
For example, in the smart transportation system, suppose we are using smart cameras
to build digital clones of vehicles. After a few seconds, the vehicle drives out of the range
of the smart camera. We can use the location-based IoT search service to ﬁnd other cameras
around the vehicle to ensure that DT can continue to work. As another example, if we want
to know the moving trajectory of vehicle, we can use a content-based IoT search service to
ﬁnd all the information that contains the vehicle license plate. Finally, some new services
can be provided by DT on different CPS. For example, in the smart manufacturing system,
operators can check DT through algorithms to quickly perform quality inspections on a
large number of products. In the smart home, users can integrate smart cameras and VR
devices to provide holographic remote social interaction. In the smart grid, DT can be used
to monitor the status of infrastructures in real time. In smart health care, DT can be used to
monitor and record the vital signs of patients so that doctors can make better treatment
plans. Likewise, in the smart transportation system, DT can be used to dynamically plan
routes and provide additional driving assistance functions such as blind spot monitoring,
brake warning, etc.
5.3. Modeling and Machine Learning
Considering the challenges of modeling a complex system in Section 4.2, a modeling
methodology that can be adapted to different CPS systems is worth studying. There are
two major directions that should be investigated: model-based DT and model-free DT.
For model-based DT, the main problem is that the CPS system is difﬁcult to mathe-
matically model, and there are signiﬁcant differences between different CPS. Therefore,
any model that works and is complete for one CPS will need to be re-modeled every time
the CPS changes. To address this problem, one solution is modular DT. This focuses on
building the DT of the small objects of the system and combining them to form the DT of
the entire system, instead of building the entire system from the beginning. This not only
reduces the complexity of building a DT model but also uses the constructed DT models to
create a different combination DT systems.
Future Internet 2022, 14, 64
20 of 25
In model-free DT, we establish DT by frequently collecting information on physical
objects. Because this kind of DT completely relies on observations and disregards mathe-
matical model support, it is difﬁcult for us to predict the state of the system, which greatly
affects the control and optimization of the DT system. Therefore, we consider using DL to
generate a neural network-based model by learning data collected from the CPS devices.
In this case, even for very complex systems that are difﬁcult to model, we can still use DL
models to build DT. Nonetheless, one problem is that ML/DL algorithms usually require a
large amount of data, which is sometimes difﬁcult to provide for CPS devices with limited
resources. Therefore, it is worth investigating the best way to design DL models that
work for small amounts of data. Moreover, training a DL model requires considerable
computing power, and trained models need to be retrained once the environment changes,
both of which are obviously too demanding for CPS devices. To solve these problems, we
believe that using transfer learning is a promising solution [107]. Transfer learning is an ML
technology that can transfer the learned knowledge from one a well-trained model to a new
learning model. Speciﬁcally, with transfer learning, we can use a generic DL model trained
with large amount of the data as the source model and replace several of the last (terminal)
layers in the network to construct a new model. During the training phase, we only update
the replaced layers. By using this transfer learning technique, we can use less training data
to obtain better performance than training from scratch. Because there are fewer network
parameters that need to be trained, this method also reduces the requirements for device
computing power and storage space. Therefore, it is suitable for real-time computing,
real-time control, and real-time communication in a large-scale distributed CPS system.
Finally, we should consider the integration of model-based DT and model-free DT
into a hybrid-model DT. Even in the most complex cps system, there will be components
that can be easily mathematically modeled. Therefore, we can mathematically model those
components of the system that are easily modeled and use a model-free approach such as
DL to model the remaining components. Once a DL-based model is trained, it can be treated
as a modular model and directly integrated with other model-based DTs in a modular
DT system. For example, in the smart transportation system, we can mathematically
model the mobility of vehicles and use DL to model the Internet of Vehicle communication.
By combining these two components together, we can obtain a complete DT of moving
vehicles in CPS.
5.4. Security and Privacy
DT applications rely on data provided by IoT sensors and gateways. In this case, data
and communication security and privacy are an important research direction. In consider-
ing security, we discuss the research from several perspectives: conﬁdentiality, integrity,
and availability.
In terms of conﬁdentiality, we now take the smart transportation system as an example.
DT obtains data from IoT sensors installed near roads, vehicles, etc. At the same time, IoT
sensors may belong to different organizations/operators. In this case, different organiza-
tions/operators need to ensure the conﬁdentiality of data through some authentication
and secured communication protocols. In addition, some data stored in the application
layer, such as vehicle location and trafﬁc camera data, are sensitive. Thus, access control
needs to be in place to protect user privacy. At the same time, some information security
regulations can protect user privacy and achieve data conﬁdentiality by restricting data
sharing, especially on the end-user layer. For example, in the ﬁeld of healthcare, Health
Insurance Portability and Accountability Act (HIPPA) will be used to regulate the sharing
and conﬁdentiality of user medical data.
For the sake of integrity, some DT applications, including smart grid, smart transporta-
tion, smart manufacturing, and smart cities, require real-time data to build a digital model
of the DT system. In this case, data integrity is essential for the DT system to correctly
model and guide the physical system in response to changes in the environment. Based
on the DT architecture, we discuss the integrity of the four layers. For the object layer,
Future Internet 2022, 14, 64
21 of 25
the sensors need to communicate with the gateways. In this case, the communication
from sensor to gateway and gateway to sensor at the application layer needs to be secured
to prevent an adversary from hijacking the communication using a man-in-the-middle
(MITM) attack or others. In addition, authentication and other security mechanisms must
be in place to restrict unauthorized users from modifying data. At the same time, at the
application layer, anomaly detection can be used to detect manipulated data to ensure data
integrity. Finally, an authentication system can be implemented at the end user level to
prevent unauthorized users from accessing DT.
Finally, availability is key to real-time DT. Certain types of cyber attacks, including
distributed denial of service (DDoS) and malware propagation, can target sensors and
gateways. In this case, mitigation schemes need to be implemented on the gateways to
ﬁlter malicious trafﬁc and reduce the impact of attacks. At the same time, an adversary can
send time-consuming queries or massive queries through the end user layer to overload the
DT. To deal with such threats, mitigation schemes can be deployed at the application layer
to avert the affects. Moreover, in a certain period of time, there may be multiple normal
users accessing the same service at the same time. In this case, load balancing algorithms
can be deployed on the gateway. If a gateway is overloaded, the algorithm can use nearby
low-load gateways to process the request, leading to a highly resilient system.
6. Final Remarks
With the rapid advance of big data and ML/DL techniques, the cyber replica of a real
physical system has been considered as a viable digital platform to emulate lifecycle use
cases for CPS. DT is the cyber replica of the real physical system, which consists of real-time
computing, real-time control, and real-time communication. By leveraging the DT with
a physical system, we can imitate real-world cases in physical systems, without directly
operating the real-world system, to optimize system performance. DT can also simulate
emergency situations of the system, allowing system operators to practice emergency plans.
Furthermore, DT could enable data sharing to support more data-oriented services on
CPS. DT needs to represent things in a timely, accurate, and efﬁcient manner, which poses
numerous challenges to the networking, control, computing, and data analysis of CPS.
Furthermore, the design of DT shall consider numerous exceptional requirements of CPS
(e.g., latency, reliability, safety, scalability, security, and privacy). In this paper, we have
ﬁrst reviewed the principles of DT (architecture, data presentation, and protocols). We
have then presented how to integrate DT in different CPS, including smart grid, smart
transportation, smart manufacturing, and smart cities. We have further discussed some
challenges from CPS, data science, optimization, and security perspectives. Finally, we have
outlined future research directions from the perspectives of performance, new DT-driven
services, modeling and machine learning, and security and privacy.
Author Contributions: C.Q.: DT architectures, protocols, DT for smart grid, smart transportation,
and research directions. X.L.: challenges and research directions. C.R.: DT concept, architecture, and
DT for smart manufacturing. M.Q.: DT concept, DT for smart cities. F.L.: DT concept, challenges, and
research directions. W.Y.: problem deﬁnition, paper organization, integrating DT in CPS framework,
challenges, and research direction. All authors have read and agreed to the published version of
the manuscript.
Funding: This research received no external funding.
Data Availability Statement: Not Applicable, the study does not report any data.
Conﬂicts of Interest: The authors declare no conﬂict of interest.
References
1.
Xu, L.D.; He, W.; Li, S. Internet of Things in Industries: A Survey. IEEE Trans. Ind. Inform. 2014, 10, 2233–2243. [CrossRef]
2.
Stankovic, J. Research Directions for the Internet of Things. Internet Things J. IEEE 2014, 1, 3–9.. [CrossRef]
3.
Liu, X.; Qian, C.; Hatcher, W.G.; Xu, H.; Liao, W.; Yu, W. Secure Internet of Things (IoT)-Based Smart-World Critical Infrastructures:
Survey, Case Study and Research Opportunities. IEEE Access 2019, 7, 79523–79544. [CrossRef]
Future Internet 2022, 14, 64
22 of 25
4.
Komninos, N.; Philippou, E.; Pitsillides, A. Survey in Smart Grid and Smart Home Security: Issues, Challenges and Countermea-
sures. IEEE Commun. Surv. Tutor. 2014, 16, 1933–1954. [CrossRef]
5.
Xu, G.; Yu, W.; Grifﬁth, D.; Golmie, N.; Moulema, P. Toward Integrating Distributed Energy Resources and Storage Devices in
Smart Grid. IEEE Internet Things J. 2017, 4, 192–204. [CrossRef]
6.
Liu, Y.; Weng, X.; Wan, J.; Yue, X.; Song, H.; Vasilakos, A.V. Exploring Data Validity in Transportation Systems for Smart Cities.
IEEE Commun. Mag. 2017, 55, 26–33. [CrossRef]
7.
Xu, H.; Yu, W.; Grifﬁth, D.; Golmie, N. A Survey on Industrial Internet of Things: A Cyber-Physical Systems Perspective. IEEE
Access 2018, 6, 78238–78259. [CrossRef]
8.
Mahmud, M.S.; Wang, H.; Esfar-E-Alam, A.M.; Fang, H. A Wireless Health Monitoring System Using Mobile Phone Accessories.
IEEE Internet Things J. 2017, 4, 2009–2018. [CrossRef]
9.
Guo, H.; Zhang, N.; Wu, S.; Yang, Q. Deep Learning Driven Wireless Real-time Human Activity Recognition. In Proceedings of
the ICC 2020—2020 IEEE International Conference on Communications (ICC), Online, 7–11 June 2020; pp. 1–6. [CrossRef]
10.
Sun, Y.; Song, H.; Jara, A.J.; Bie, R. Internet of Things and Big Data Analytics for Smart and Connected Communities. IEEE Access
2016, 4, 766–773. [CrossRef]
11.
Du, R.; Santi, P.; Xiao, M.; Vasilakos, A.V.; Fischione, C. The Sensable City: A Survey on the Deployment and Management for
Smart City Monitoring. IEEE Commun. Surv. Tutor. 2019, 21, 1533–1560. [CrossRef]
12.
Bartolini, A.; Corti, F.; Reatti, A.; Ciani, L.; Grasso, F.; Kazimierczuk, M.K. Analysis and Design of Stand-Alone Photovoltaic
System for precision agriculture network of sensors. In Proceedings of the 2020 IEEE International Conference on Environment
and Electrical Engineering and 2020 IEEE Industrial and Commercial Power Systems Europe (EEEIC/I CPS Europe), Madrid,
Spain , 9–12 June 2020; pp. 1–5. [CrossRef]
13.
Al Rasyid, M.U.H.; Nadhori, I.U.; Sudarsono, A.; Luberski, R. Analysis of slotted and unslotted CSMA/CA Wireless Sensor
Network for E-healthcare system. In Proceedings of the 2014 International Conference on Computer, Control, Informatics and Its
Applications (IC3INA), Bandung, Indonesia, 21–23 October 2014; pp. 53–57. [CrossRef]
14.
Pievanelli, E.; Plesca, A.; Stefanelli, R.; Trinchero, D. Dynamic wireless sensor networks for real time safeguard of workers
exposed to physical agents in constructions sites. In Proceedings of the 2013 IEEE Topical Conference on Wireless Sensors and
Sensor Networks (WiSNet), Austin, TX, USA, 20–23 January 2013; pp. 55–57. [CrossRef]
15.
Hatcher, W.G.; Yu, W. A Survey of Deep Learning: Platforms, Applications and Emerging Research Trends. IEEE Access 2018,
6, 24411–24432. [CrossRef]
16.
Liang, F.; Hatcher, W.G.; Liao, W.; Gao, W.; Yu, W. Machine Learning for Security and the Internet of Things: The Good, the Bad,
and the Ugly. IEEE Access 2019, 7, 158126–158147. [CrossRef]
17.
Wu, D.; Shi, H.; Wang, H.; Wang, R.; Fang, H. A Feature-Based Learning System for Internet of Things Applications. IEEE Internet
Things J. 2019, 6, 1928–1937. [CrossRef]
18.
Mohammadi, M.; Al-Fuqaha, A.; Sorour, S.; Guizani, M. Deep Learning for IoT Big Data and Streaming Analytics: A Survey.
IEEE Commun. Surv. Tutor. 2018, 20, 2923–2960. [CrossRef]
19.
Liang, Y.; Cai, Z.; Yu, J.; Han, Q.; Li, Y. Deep Learning Based Inference of Private Information Using Embedded Sensors in Smart
Devices. IEEE Netw. 2018, 32, 8–14. [CrossRef]
20.
Shi, W.; Cao, J.; Zhang, Q.; Li, Y.; Xu, L. Edge Computing: Vision and Challenges. IEEE Internet Things J. 2016, 3, 637–646.
[CrossRef]
21.
Zhu, S.; Xu, J.; Guo, H.; Liu, Q.; Wu, S.; Wang, H. Indoor Human Activity Recognition Based on Ambient Radar with Signal
Processing and Machine Learning. In Proceedings of the 2018 IEEE International Conference on Communications (ICC), Kansas
City, MO, USA, 20–24 May 2018; pp. 1–6. [CrossRef]
22.
Cai, Z.; Zheng, X.; Wang, J. Efﬁcient Data Trading for Stable and Privacy Preserving Histograms in Internet of Things. In
Proceedings of the 2021 IEEE International Performance, Computing, and Communications Conference (IPCCC), Austin, TX,
USA, 11–13 November 2021; pp. 1–10. [CrossRef]
23.
Chen, S.Y.; Song, S.F.; Li, L.X.; Shen, J. Survey on smart grid technology. Power Syst. Technol. 2009, 33, 1–7. [CrossRef]
24.
Guan, Z.; Sun, N.; Xu, Y.; Yang, T. A Comprehensive Survey of False Data Injection in Smart Grid. Int. J. Wire. Mob. Comput. 2015,
8, 27–33. [CrossRef]
25.
Liu, Y.; Ning, P.; Reiter, M. False data injection attacks against state estimation in electric power grids. ACM Trans. Inf. Syst. Secur.
2011, 14, 13. [CrossRef]
26.
Xu, H.; Yu, W.; Liu, X.; Grifﬁth, D.; Golmie, N. On Data Integrity Attacks against Industrial Internet of Things. In Proceedings
of the 2020 IEEE International Conference on Dependable, Autonomic and Secure Computing, International Conference on
Pervasive Intelligence and Computing, International Conference on Cloud and Big Data Computing, International Conference on
Cyber Science and Technology Congress (DASC/PiCom/CBDCom/CyberSciTech), Calgary, AB, Canada, 17–22 August 2020;
pp. 21–28. [CrossRef]
27.
Ponnusamy, V.K.; Kasinathan, P.; Madurai Elavarasan, R.; Ramanathan, V.; Anandan, R.K.; Subramaniam, U.; Ghosh, A.;
Hossain, E. A Comprehensive Review on Sustainable Aspects of Big Data Analytics for the Smart Grid. Sustainability 2021, 13,
3322. [CrossRef]
28.
Walter, A.; Finger, R.; Huber, R.; Buchmann, N. Opinion: Smart farming is key to developing sustainable agriculture. Proc. Natl.
Acad. Sci. USA 2017, 114, 6148–6150. [CrossRef]
Future Internet 2022, 14, 64
23 of 25
29.
Jayaraman, P.P.; Yavari, A.; Georgakopoulos, D.; Morshed, A.; Zaslavsky, A. Internet of things platform for smart farming:
Experiences and lessons learnt. Sensors 2016, 16, 1884. [CrossRef] [PubMed]
30.
Kritzinger, W.; Karner, M.; Traar, G.; Henjes, J.; Sihn, W. Digital Twin in manufacturing: A categorical literature review and
classiﬁcation. IFAC-PapersOnLine 2018, 51, 1016–1022. [CrossRef]
31.
Aceto, G.; Persico, V.; Pescapé, A. A Survey on Information and Communication Technologies for Industry 4.0: State-of-the-Art,
Taxonomies, Perspectives, and Challenges. Commun. Surv. Tutor. 2019, 21, 3467–3501. [CrossRef]
32.
Boschert, S.; Rosen, R. Digital twin—the simulation aspect. In Mechatronic Futures; Springer: Berlin/Heidelberg, Germany, 2016;
pp. 59–74. [CrossRef]
33.
Tao, F.; Sui, F.; Liu, A.; Qi, Q.; Zhang, M.; Song, B.; Guo, Z.; Lu, S.C.Y.; Nee, A.Y. Digital twin-driven product design framework.
Int. J. Prod. Res. 2019, 57, 3935–3953. [CrossRef]
34.
Tao, F.; Zhang, H.; Liu, A.; Nee, A.Y.C. Digital twin in industry: State-of-the-art. IEEE Trans. Ind. Inform. 2018, 15, 2405–2415.
[CrossRef]
35.
Leng, J.; Zhang, H.; Yan, D.; Liu, Q.; Chen, X.; Zhang, D. Digital twin-driven manufacturing cyber-physical system for parallel
controlling of smart workshop. J. Ambient Intell. Humaniz. Comput. 2019, 10, 1155–1166. [CrossRef]
36.
Qi, Q.; Tao, F. Digital twin and big data towards smart manufacturing and industry 4.0: 360 degree comparison. IEEE Access
2018, 6, 3585–3593. [CrossRef]
37.
Brosinsky, C.; Westermann, D.; Krebs, R. Recent and prospective developments in power system control centers: Adapting the
digital twin technology for application in power system control centers. In Proceedings of the 2018 IEEE International Energy
Conference (ENERGYCON), Limassol, Cyprus, 3–7 June 2018; IEEE: Piscataway, NJ, USA, 2018; pp. 1–6. [CrossRef]
38.
Tzanis, N.; Andriopoulos, N.; Magklaras, A.; Mylonas, E.; Birbas, M.; Birbas, A. A hybrid cyber physical digital twin approach
for smart grid fault prediction. In Proceedings of the 2020 IEEE Conference on Industrial Cyberphysical Systems (ICPS), Tampere,
Finland, 9–12 June 2020; IEEE: Piscataway, NJ, USA, 2020; Volume 1, pp. 393–397. [CrossRef]
39.
Saad, A.; Faddel, S.; Youssef, T.; Mohammed, O.A. On the implementation of IoT-based digital twin for networked microgrids
resiliency against cyber attacks. IEEE Trans. Smart Grid 2020, 11, 5138–5150. [CrossRef]
40.
Danilczyk, W.; Sun, Y.; He, H. Angel: An intelligent digital twin framework for microgrid security. In Proceedings of the 2019
North American Power Symposium (NAPS), Wichita, KS, USA, 13–15 October 2019; IEEE: Piscataway, NJ, USA, 2019; pp. 1–6.
[CrossRef]
41.
Bird, P. An updated digital model of plate boundaries. Geochem. Geophys. Geosystems 2003, 4, 1–46. [CrossRef]
42.
Remeikiene, R.; Gaspareniene, L.; Schneider, F.G. The deﬁnition of digital shadow economy. Technol. Econ. Dev. Econ. 2018,
24, 696–717. [CrossRef]
43.
Rasheed, A.; San, O.; Kvamsdal, T. Digital twin: Values, challenges and enablers from a modeling perspective. IEEE Access 2020,
8, 21980–22012. [CrossRef]
44.
Haag, S.; Anderl, R. Digital twin–Proof of concept. Manuf. Lett. 2018, 15, 64–66. [CrossRef]
45.
Jones, D.; Snider, C.; Nassehi, A.; Yon, J.; Hicks, B. Characterising the Digital Twin: A systematic literature review. CIRP J. Manuf.
Sci. Technol. 2020, 29, 36–52. [CrossRef]
46.
Liu, Z. Reading behavior in the digital environment: Changes in reading behavior over the past ten years. J. Doc. 2005, 61,
700–712. [CrossRef]
47.
ˇColakovi´c, A.; Hadžiali´c, M. Internet of Things (IoT): A review of enabling technologies, challenges, and open research issues.
Comput. Netw. 2018, 144, 17–39. [CrossRef]
48.
Hatcher, W.G.; Qian, C.; Gao, W.; Liang, F.; Hua, K.; Yu, W. Towards Efﬁcient and Intelligent Internet of Things Search Engine.
IEEE Access 2021, 9, 15778–15795. [CrossRef]
49.
Jaloudi, S. Communication Protocols of an Industrial Internet of Things Environment: A Comparative Study. Future Internet 2019,
11, 66. [CrossRef]
50.
Al-Sarawi, S.; Anbar, M.; Alieyan, K.; Alzubaidi, M. Internet of Things (IoT) communication protocols: Review. In Proceedings
of the 2017 8th International Conference on Information Technology (ICIT), Amman, Jordan, 17–18 May 2017; pp. 685–690.
[CrossRef]
51.
Stusek, M.; Zeman, K.; Masek, P.; Sedova, J.; Hosek, J. IoT Protocols for Low-power Massive IoT: A Communication Perspective.
In Proceedings of the 2019 11th International Congress on Ultra Modern Telecommunications and Control Systems and Workshops
(ICUMT), Dublin, Ireland, 28–30 October 2019; pp. 1–7. [CrossRef]
52.
Azure. Digital Twin Deﬁnition Language. Available online: https://github.com/Azure/opendigitaltwins-dtdl (accessed on 26
January 2022) .
53.
Conde, J.; Munoz-Arcentales, A.; Alonso, A.; Lopez-Pernas, S.; Salvachua, J. Modeling Digital Twin Data and Architecture: A
Building Guide with FIWARE as Enabling Technology. IEEE Internet Comput. 2021, 1. [CrossRef]
54.
Foundation, O. Unified Architecture. Available online:
https://opcfoundation.org/about/opc-technologies/opc-ua/
(accessed on 26 January 2022).
55.
Ala-Laurinaho, R.; Autiosalo, J.; Nikander, A.; Mattila, J.; Tammi, K. Data Link for the Creation of Digital Twins. IEEE Access
2020, 8, 228675–228684. [CrossRef]
56.
Autiosalo, J.; Vepsäläinen, J.; Viitala, R.; Tammi, K. A Feature-Based Framework for Structuring Industrial Digital Twins. IEEE
Access 2020, 8, 1193–1208. [CrossRef]
Future Internet 2022, 14, 64
24 of 25
57.
Kome, M.L.; Cuppens, F.; Cuppens-Boulahia, N.; Frey, V. CoAP Enhancement for a Better IoT Centric Protocol: CoAP 2.0. In
Proceedings of the 2018 Fifth International Conference on Internet of Things: Systems, Management and Security, Valencia, Spain,
15–18 October 2018; pp. 139–146. [CrossRef]
58.
Silva, D.; Carvalho, L.I.; Soares, J.; Soﬁa, R.C. A Performance Analysis of Internet of Things Networking Protocols: Evaluating
MQTT, CoAP, OPC UA. Appl. Sci. 2021, 11, 4879. [CrossRef]
59.
Yang, K.; Zhang, B.; Zhang, J.; Zhu, J. Design of Remote Control Inverter Based on MQTT Communication Protocol.
In
Proceedings of the 2021 IEEE International Conference on Mechatronics and Automation (ICMA), Takamatsu, Japan, 8–11 August
2021; pp. 1374–1378. [CrossRef]
60.
Cagnano, A.; De Tuglie, E.; Mancarella, P. Microgrids: Overview and guidelines for practical implementations and operation.
Appl. Energy 2020, 258, 114039. [CrossRef]
61.
González, I.; Calderón, A.J.; Portalo, J.M. Innovative multi-layered architecture for heterogeneous automation and monitoring
systems: Application case of a photovoltaic smart microgrid. Sustainability 2021, 13, 2234. [CrossRef]
62.
Liu, Q.; Li, Y. Modbus/TCP based Network Control System for Water Process in the Firepower Plant. In Proceedings of the 2006
6th World Congress on Intelligent Control and Automation, Dalian, China, 21–23 June 2006; Volume 1, pp. 432–435. [CrossRef]
63.
Sharma, A.; Airan, S.; Shah, D. Designing C Library for MODBUS-RTU to CANBUS and MODBUS-TCP IOT Converters. In
Proceedings of the 2021 Second International Conference on Electronics and Sustainable Communication Systems (ICESC),
Coimbatore, India, 4–6 August 2021; pp. 731–737. [CrossRef]
64.
Galketiya, T.; Kahahena, J.; Chandran, J.; Kavalchuk, I. Novel Communication System for SCADA Tied Smart Inverter for
Vietnam. In Proceedings of the 2019 25th Asia-Paciﬁc Conference on Communications (APCC), Ho Chi Minh City, Vietnam, 6–8
November 2019; pp. 331–335. [CrossRef]
65.
Tan, J.; Sha, X.; Dai, B.; Lu, T. Wireless Technology and Protocol for IIoT and Digital Twins. In Proceedings of the 2020 ITU
Kaleidoscope: Industry-Driven Digital Transformation (ITU K), ONLINE, 7–11 December 2020; pp. 1–8. [CrossRef]
66.
Zhou, M.; Yan, J.; Feng, D. Digital twin framework and its application to power grid online analysis. CSEE J. Power Energy Syst.
2019, 5, 391–398. [CrossRef]
67.
Dileep, G. A survey on grid technologies and applications. Renew. Energy 2020, 146, 2589–2625. [CrossRef]
68.
Lund, A.M.; Mochel, K.; Lin, J.W.; Onetto, R.; Srinivasan, J.; Gregg, P.; Chotai, S. Digital Wind Farm System. U.S. Patent
US20160333855A1, 17 November 2016.
69.
Lund, A.M.; Mochel, K.; Lin, J.W.; Onetto, R.; Srinivasan, J.; Gregg, P.; Chotai, S. Digital Twin Interface for Operating Wind Farms.
U.S. Patent US9995278B2, 12 June 2018.
70.
Danilczyk, W.; Sun, Y.L.; He, H. Smart Grid Anomaly Detection using a Deep Learning Digital Twin. In Proceedings of the 2020
52nd North American Power Symposium (NAPS), Tempe, AZ, USA, 11–13 October 2020; pp. 1–6. [CrossRef]
71.
Baboli, P.T.; Babazadeh, D.; Kumara Bowatte, D.R. Measurement-based Modeling of Smart Grid Dynamics: A Digital Twin
Approach. In Proceedings of the 2020 10th Smart Grid Conference (SGC), Kashan, Iran, 16–17 December 2020; pp. 1–6. [CrossRef]
72.
Chen, C.; Liu, L.; Qiu, T.; Jiang, J.; Pei, Q.; Song, H. Routing With Trafﬁc Awareness and Link Preference in Internet of Vehicles.
IEEE Trans. Intell. Transp. Syst. 2022, 23, 200–214. [CrossRef]
73.
Jiang, D.; Huo, L.; Lv, Z.; Song, H.; Qin, W. A Joint Multi-Criteria Utility-Based Network Selection Approach for Vehicle-to-
Infrastructure Networking. IEEE Trans. Intell. Transp. Syst. 2018, 19, 3305–3319. [CrossRef]
74.
Rudskoy, A.; Ilin, I.; Prokhorov, A. Digital Twins in the Intelligent Transport Systems. Transp. Res. Procedia 2021, 54, 927–935.
[CrossRef]
75.
Dasgupta, S.; Rahman, M.; Lidbe, A.D.; Lu, W.; Jones, S. A Transportation Digital-Twin Approach for Adaptive Trafﬁc Control
Systems. arXiv 2021, arXiv:2109.10863.
76.
Wang, X.; Song, H.; Zha, W.; Li, J.; Dong, H. Digital twin based validation platform for smart metro scenarios. In Proceedings of
the 2021 IEEE 1st International Conference on Digital Twins and Parallel Intelligence (DTPI), Beijing, China, 15 July–15 August
2021; pp. 386–389. [CrossRef]
77.
Sahal, R.; Alsamhi, S.H.; Brown, K.N.; O’Shea, D.; McCarthy, C.; Guizani, M. Blockchain-Empowered Digital Twins Collaboration:
Smart Transportation Use Case. Machines 2021, 9, 193. [CrossRef]
78.
Guo, Y.; Zou, K.; Chen, S.; Yuan, F.; Yu, F. 3D Digital Twin of Intelligent Transportation System based on Road-Side Sensing.
In Proceedings of the Journal of Physics: Conference Series, London, UK, 5 March 2021; IOP Publishing: Bristol, UK, 2021;
Volume 2083, p. 032022.
79.
Wallace, F.R.E. Panel on Enabling Smart Manufacturing; APMS: State College, PA, USA, 2013.
80.
Frank, A.G.; Dalenogare, L.S.; Ayala, N.F. Industry 4.0 technologies: Implementation patterns in manufacturing companies. Int. J.
Prod. Econ. 2019, 210, 15–26. [CrossRef]
81.
Kunath, M.; Winkler, H. Integrating the Digital Twin of the manufacturing system into a decision support system for improving
the order management process. Procedia Cirp 2018, 72, 225–231. [CrossRef]
82.
Redelinghuys, A.; Kruger, K.; Basson, A. A Six-Layer Architecture for Digital Twins with Aggregation; Springer: Berlin/Heidelberg,
Germany, 2020; pp. 171–182. [CrossRef]
83.
Huo, Z.; Mukherjee, M.; Shu, L.; Chen, Y.; Zhou, Z. Cloud-based Data-intensive Framework towards fault diagnosis in large-scale
petrochemical plants. In Proceedings of the 2016 International Wireless Communications and Mobile Computing Conference
(IWCMC), Cyprus, Paphos, 5–9 September 2016; pp. 1080–1085. [CrossRef]
Future Internet 2022, 14, 64
25 of 25
84.
Pfohl, H.C.; Yahsi, B.; Kurnaz, T. Concept and Diffusion-Factors of Industry 4.0 in the Supply Chain; Springer: Berlin/Heidelberg,
Germany, 2017; pp. 381–390. [CrossRef]
85.
Hu, S.J. Evolving Paradigms of Manufacturing: From Mass Production to Mass Customization and Personalization. Procedia
CIRP 2013, 7, 3–8. [CrossRef]
86.
Lu, Y.; Xu, X.; Wang, L. Smart manufacturing process and system automation—A critical review of the standards and envisioned
scenarios. J. Manuf. Syst. 2020, 56, 312–325. [CrossRef]
87.
Brenner, B.; Hummel, V. A Seamless Convergence of the Digital and Physical Factory Aiming in Personalized Product Emergence
Process (PPEP) for Smart Products within ESB Logistics Learning Factory at Reutlingen University. Procedia CIRP 2016, 54, 227–232.
[CrossRef]
88.
Salah, B. Real-Time Implementation of a Fully Automated Industrial System Based on IR 4.0 Concept. Actuators 2021, 10, 318.
[CrossRef]
89.
Tao, F.; Zhang, M. Digital Twin Shop-Floor: A New Shop-Floor Paradigm Towards Smart Manufacturing. IEEE Access 2017,
5, 20418–20427. [CrossRef]
90.
Židek, K.; Pitel’, J.; Adámek, M.; Lazorík, P.; Hošovský, A. Digital Twin of Experimental Smart Manufacturing Assembly System
for Industry 4.0 Concept. Sustainability 2020, 12, 3658. [CrossRef]
91.
Aghenta, L.O.; Iqbal, M.T. Low-cost, open source IoT-based SCADA system design using thinger. IO and ESP32 thing. Electronics
2019, 8, 822. [CrossRef]
92.
Kaur, M.J.; Mishra, V.P.; Maheshwari, P. The convergence of digital twin, IoT, and machine learning: Transforming data
into action. In Digital Twin Technologies and Smart Cities; Springer: Berlin/Heidelberg, Germany, 2020; pp. 3–17. [CrossRef]
93.
Mishra, K.N.; Chakraborty, C. A novel approach toward enhancing the quality of life in smart cities using clouds and IoT-based
technologies. In Digital Twin Technologies and Smart Cities; Springer: Berlin/Heidelberg, Germany, 2020; pp. 19–35. [CrossRef]
94.
Seuwou, P.; Banissi, E.; Ubakanma, G. The future of mobility with connected and autonomous vehicles in smart cities. In Digital Twin
Technologies and Smart Cities; Springer: Berlin/Heidelberg, Germany, 2020; pp. 37–52. [CrossRef]
95.
Jraisat, L. Information sharing in sustainable value chain network (SVCN)—The perspective of transportation in cities. In
Digital Twin Technologies and Smart Cities; Springer: Berlin/Heidelberg, Germany, 2020; pp. 67–77. [CrossRef]
96.
Anthopoulos, L.G.; Janssen, M.; Weerakkody, V. Comparing Smart Cities with different modeling approaches. In Proceedings of
the 24th International Conference on World Wide Web, Florence, Italy, 18–22 May 2015; pp. 525–528. [CrossRef]
97.
Gharaibeh, A.; Salahuddin, M.A.; Hussini, S.J.; Khreishah, A.; Khalil, I.; Guizani, M.; Al-Fuqaha, A. Smart Cities: A Survey on
Data Management, Security, and Enabling Technologies. IEEE Commun. Surv. Tutor. 2017, 19, 2456–2501. [CrossRef]
98.
Deng, T.; Zhang, K.; Shen, Z.J.M. A Systematic Review of a Digital Twin City: A New Pattern of Urban Governance toward Smart
Cities. J. Manag. Sci. Eng. 2021, 6, 125–134. [CrossRef]
99.
Shahat, E.; Hyun, C.T.; Yeom, C. City digital twin potentials: A review and research agenda. Sustainability 2021, 13, 3386.
[CrossRef]
100. Shirowzhan, S.; Tan, W.; Sepasgozar, S.M. Digital twin and CyberGIS for improving connectivity and measuring the impact of
infrastructure construction planning in smart cities. ISPRS Int. J.-Geo-Inf. 2020, 9, 240. [CrossRef]
101. Castro, D. Planning in Virtual Reality. Available online: https://www.govtech.com (accessed on 26 January 2022) .
102. Gassmann, O.; Böhm, J.; Palmié, M. Smart Cities: Introducing Digital Innovation to Cities; Emerald Group Publishing: Bentley, UK,
2019. [CrossRef]
103. Schrotter, G.; Hürzeler, C. The digital twin of the city of Zurich for urban planning. PFG-Photogramm. Remote Sens. Geoinf. Sci.
2020, 88, 99–112. [CrossRef]
104. Research, A. The Use of Digital Twins for Urban Planning to Yield US$280 Billion in Cost Savings by 2030. Available online:
https://www.abiresearch.com/press/use-digital-twins-urban-planning-yield-us280-billion-cost-savings-2030/ (accessed on 26
January 2022) .
105. Xu, H.; Liu, X.; Yu, W.; Grifﬁth, D.; Golmie, N. Reinforcement Learning-Based Control and Networking Co-Design for Industrial
Internet of Things. IEEE J. Sel. Areas Commun. 2020, 38, 885–898. [CrossRef]
106. Liang, F.; Qian, C.; Hatcher, W.G.; Yu, W. Search Engine for the Internet of Things: Lessons From Web Search, Vision, and
Opportunities. IEEE Access 2019, 7, 104673–104691. [CrossRef]
107. Pan, S.J.; Yang, Q. A Survey on Transfer Learning. IEEE Trans. Knowl. Data Eng. 2010, 22, 1345–1359. [CrossRef]


Paper 2:
- APA Citation: Zhang, X., Chang, B., & Baoguo, X. (2018). Design of Intelligent Wireless Monitoring System for Water Saving Irrigation Based on Fuzzy-PID Strategy. 2018 7th International Conference on Advanced Materials and Computer Science (ICAMCS 2018) Published by CSP © 2018 the Authors, 122-128.
  Main Objective: To design and evaluate a real-time monitoring system for water-saving irrigation in agricultural fields, focusing on the impact of environmental factors on wireless data transmission and proposing solutions to improve data reliability and accuracy.
  Study Location: Unspecified
  Data Sources: Soil temperature and humidity sensors, Wireless data transmission
  Technologies Used: ZigBee technology, Fuzzy PID control, Wireless sensor networks
  Key Findings: Environmental factors such as obstacles and weather conditions can significantly impact wireless data transmission in agricultural settings, leading to data loss and reduced system performance. The proposed monitoring system effectively addresses these challenges by implementing ZigBee technology and fuzzy PID control, which enhance data transmission reliability and accuracy, ensuring optimal irrigation management.
  Extract 1: The test results show that the temperature and humidity sensing node can pass through obstacles such as field instruments and equipment within the range of 13m, and can realize data acquisition, transmission and list display.
  Extract 2: The ability of wrong correction of the network is good and the data accuracy is high. Once the detection parameters exceed the limit, the computer response time is generally less than 3 seconds, display the address and exceed the limit parameter value, and alarm prompt.
  Limitations: The study does not provide specific information on the geographical location where the monitoring system was implemented, making it challenging to assess its generalizability to other agricultural regions with different environmental conditions.
  Relevance Evaluation: This paper is highly relevant to the point on the impact of environmental factors on wireless data transmission in agricultural settings. It provides a detailed description of the challenges encountered in wireless data transmission in real-time irrigation management systems, such as environmental factors and physical obstacles. The study also proposes solutions to address these challenges, including the use of ZigBee technology and fuzzy PID control, which enhances the reliability and accuracy of data transmission in harsh agricultural environments.
  Relevance Score: 0.9
  Inline Citation: (Zhang, Chang & Baoguo, 2018)
  Explanation: This study proposes a real-time monitoring system for farmland soil water-saving irrigation based on ZigBee and fuzzy PID control. The system uses a combination of sensors and wireless communication to monitor soil temperature and humidity in real-time, and applies fuzzy PID control to regulate irrigation timing and water volume based on the collected data. The study aims to improve irrigation efficiency and reduce water consumption while maintaining crop quality.

 Full Text: >
 
Design of Intelligent Wireless Monitoring System for Water Saving Irrigation 
based on Fuzzy-PID Strategy 
Xinrong Zhang1, a, Bo Chang2, b, Xv Baoguo3, c 
1Faculty of Automation, Huaiyin Institute of Technology, Huai’an, Jiangsu, China 
2Faculty of Electronic Information Engineering, Huaiyin Institute of Technology, Huai’an, Jiangsu, China 
3School of Internet of Things Engineering, JiangNan University, Wuxi 214122, China 
aemail: nn33@163.com, bemail:mmm33534@sohu.com, cemail: jmx@mail.dlut.edu.cn 
Keywords: water-saving irrigation, ZigBee, fuzzy PID strategy, wireless monitoring 
Abstract: In order to solve the problems existing in the water-saving irrigation monitoring system, 
such as small monitoring area, complicated wiring etc., a soil information monitoring system of 
water-saving irrigation based on Fuzzy PID control strategy was designed. The wireless sensor node 
is developed with CC2530 as the core, and the real time monitoring of temperature and humidity in 
soil environment is completed. The system adopts ZigBee technology to realize wireless sensor 
network and automatic gathering of monitoring data, realizes soil temperature and humidity 
adjustment based on fuzzy PID control technology, and adopts embedded database management 
mode to realize terminal node and data management and so on. Compared to the other network 
monitoring technology, this system is characterized with flexible configuration, which can be 
widely used in the place unattended or in poor condition. The test run results have shown that this 
system had many advantages such as low power consumption, flexible networking, scalability, 
friendly interface, etc. 
1. Introduction 
With the continuous development of modern agriculture, the quality and safety of farmland 
irrigation is increasingly demanded, and the quality of irrigation capacity directly affects the quality 
of crop growth [1][2], so the stable, efficient and low cost operation of irrigation equipment has 
become the main technical requirements of fine agricultural industry transformation in recent years 
[3]. Agricultural irrigation involves a large area, and the terrain of the control area is complex. The 
traditional water-saving irrigation monitoring system mainly uses wired mode [4]. The field control 
points and measuring points are many and scattered, the operation is tedious, the connection cable is 
many, the failure rate is high, is not conducive to the use and maintenance [5]. Wireless sensor 
network (WSN), composed of a large number of sensor nodes, is a new advanced technology for 
data acquisition, processing and wireless transmission [6]. It has the advantages of simple 
deployment, low cost, no need for on-site maintenance, and has broad application prospects in the 
field of environmental monitoring [7]. Some scholars have applied wireless communication 
technology to water-saving irrigation [8], but these technologies usually have the shortcomings of 
high cost, high power consumption and unsatisfactory precision, so cannot be widely applied. 
Aiming at the existing problems of water-saving irrigation monitoring system, this paper adopts 
the intelligent sensor network ZigBee technology and embedded technology to design a farmland 
environment water-saving irrigation monitoring system. Its advantages are low power consumption, 
low cost, friendly man-machine interface, and automatic information collection and processing. The 
system is based on data wireless transceiver, using multi-hop routing, real-time monitoring and 
issuing data information and control instructions, using fuzzy PID control technology to achieve the 
injection speed of each valve, start and stop decisions, intelligent regulation of irrigation timing and 
water volume. Therefore, the control accuracy and irrigation efficiency can be improved, so as to 
realize intelligent monitoring of water-saving irrigation. 
2018 7th International Conference on Advanced Materials and Computer Science (ICAMCS 2018)
Published by CSP © 2018 the Authors
122
 
2. System Structure  
2.1 Requirement Analysis of Monitoring System.  
In view of the characteristics of large lag and inertia in farmland soil temperature and humidity, 
through investigation and analysis, the application requirements of environmental monitoring 
system include: a) Realizing real-time collection, processing and wireless transmission of 
environmental temperature and humidity on-line all day. b) Applying ZigBee wireless 
communication mode to transmit and aggregate the uploaded data in real time. c) The upper 
computer carries on the information processing, provides the fault diagnosis, the over-limit alarm 
prompt manager, in order to carry on the decision, complete the sensor management, the 
environment information storage and the analysis processing and so on. In other words, according 
to the predetermined control strategy to form a control output, direct action in the production 
process. 
2.2 System Overall Design.  
This system is based on ZigBee tree topology sensor network, including terminal nodes, gateway 
nodes and monitoring center. The terminal node is composed of sensor nodes and connected to 
network, which task is to collect soil environment temperature and humidity data and upload them 
to the gateway node wirelessly. ZigBee coordinator operates the gateway node, which is responsible 
for receiving data information and communicating with monitoring center through serial port. The 
monitoring center includes a PC computer and related management software. In addition to 
providing graphical operation interface, data display and staff query, it can also provide 
out-of-gauge alarm prompt, and form control output according to pre-determined control strategy. 
3. Fuzzy PID Controller and Algorithm Design of Soil Moisture  
3.1 Fuzzy PID Control Strategy.  
Because the characteristics of temperature and humidity control in farmland soil are 
multivariable, large inertia nonlinearity, parameter coupling, pure delay, long control and regulation 
time and obvious overshoot, it is impossible to establish an accurate mathematical model, and it is 
difficult to achieve satisfactory control accuracy by using classical control methods. Fuzzy control 
strategy is based on human thinking, and has the advantages of simple design and strong robustness. 
Therefore, this paper chooses the fuzzy control algorithm to control the environmental factors of the 
system, and uses software tools to design the fuzzy control system. 
3.2 Realization of Fuzzy PID Control of Soil Moisture.  
The fuzzy controller organizes the control decision table according to the manual control rules, 
and then determines the control quantity by this vote. This paper combines fuzzy control with PID 
control, which not only has the advantages of flexibility and adaptability of fuzzy control, but also 
has the characteristics of high precision of PID control. 
By calculating the current system humidity error and error rate of change, using fuzzy rules for 
fuzzy reasoning, query the fuzzy rules table for parameter adjustment. The structure of fuzzy PID 
controller is shown in Fig.1. 
 
Fig.1. Fuzzy PID humidity controller structure  
123
 
In this paper, the fuzzy PID controller is applied to humidity control. Its error and rate of change 
are used as input language variables, and the input and control variables of the controlled process 
are used as output language variables. Thus, the system stability can be guaranteed, the overshoot of 
the response process can be reduced and the oscillation phenomenon can be weakened. The fuzzy 
relation between the three parameters of PID controller and sum is found out, and the three 
parameters are adjusted according to the principle of fuzzy control to meet the different 
requirements of control parameters at different times, so that the controlled object has good 
dynamic and static performance. By summarizing the process and operator's experience, the control 
rule statements are obtained, and the temperature fuzzy control rule table is established. The 
solution is to make a fuzzy control query table as shown in Table 1, and to perform fuzzy operation 
by software query. 
Table.1. Fuzzy control Query table of humidity 
e 
ec 
-4 -3 
-2 
-1 
0 
+1 +2 +3 +4 
-4 -6 -5 
-4 
-4 
-3 
-2 
-2 
-1 
0 
-3 -5 -4 
-3 
-3 
-3 
-2 
-1 
0 
+1 
-2 -5 -4 
-3 
-3 
-2 
-1 
0 
+1 +2 
-1 -4 -3 
-2 
-1 
-1 
0 
+1 +2 +2 
0 
-3 -2 
-2 
-1 
0 
+1 +1 +3 +3 
+1 -2 -2 
-1 
0 
+1 +2 +2 +3 +4 
+2 -1 -1 
0 
+1 +2 +2 +3 +4 +5 
+3 -1 
0 
+1 +1 +2 +3 +3 +4 +5 
+4 
0 
+1 +2 +2 +3 +4 +4 +5 +6 
The software part uses the query table method to implement fuzzy reasoning using fuzzy rules. 
The specific implementation method is to store the sum fuzzy control table computed, and offline in 
the memory data block, and periodically interrupt the subroutine of inquiring the fuzzy control table 
every 30 ms. Then the fuzzy control table is querying according to the quantization value, and the 
quantization value is obtained. The program flow chart is shown in Fig.2. 
 
Fig.2. Flow chart of fuzzy PID control program 
Start 
Humidity sampling 
Fuzzy humidity deviation e 
Fuzzy humidity deviation  
change rate ec 
Query fuzzy humidity 
control rule table 
Anti-fuzzy processing 
Calculate Kp,Ki,Kd 
PID operation 
Output humidity control 
Return 
124
 
4. Hardware Realization of Intelligent Wireless Monitoring System 
4.1 System Hardware Design.  
Sensor node is the basic unit of water-saving irrigation monitoring system, which completes the 
functions of environmental temperature and humidity data acquisition, processing, wireless 
communication and so on. Under the application background of Water-saving Irrigation Soil 
Environmental monitoring, sensor node design focuses on low cost, low power consumption, 
stability, reliability and other factors. Wireless transceiver module includes CC2530 and related 
peripheral circuits, communication between gateway node and monitoring computer, application of 
microprocessor's P3.0 port (serial data receiver), P3.1 port (serial data transmitter), and level 
conversion chip MAX232, RS232 communication interface to achieve the TTL level output by 
microprocessor into PC. RS232 level, using 5V power supply, requires fewer peripheral 
components, and comply with EIA/TIA232 communication standards, transmission rate up to 220 
kbps. The hardware block diagram of the terminal node is shown in Fig.3. 
 
Fig.3. Terminal node hardware block diagram 
Gateway node function is to complete data correction, fusion, and send to the monitoring center, 
but also to obtain instructions, after processing, sent to the control equipment. CC2530 can meet the 
storage and communication requirements of water-saving irrigation temperature and humidity 
monitoring system. Therefore, the composition and design of gateway nodes and sensor nodes are 
similar. 
4.2 Hardware Design of Sensor Measuring Circuit.  
Sensors are used to perceive soil moisture information and obtain information in the monitoring 
area. When selecting sensors, the energy consumption, measurement range and accuracy, cost and 
volume are mainly taken into account. TDR-3A soil temperature and humidity sensor is used in this 
paper. The output of the sensor can be directly connected with the P0 port of CC2530, and the ADC 
of CC2430 is used to realize data conversion. The technical parameters are shown in Table 2. 
Table 2 Sensors and Related Parameters 
Sensor 
Model 
Measuring 
range 
Precision 
Rremarks 
Temperature 
sensor 
TDR-3A 
-50～100℃ 
1μA/℃ 
+10V Supply, Output 0~5 V 
Humidity sensor 
TDR-3A 
0~100% 
±2% 
Precision: ±2%；Output current: 4~20 
mA 
5. System Software Design 
5.1 Terminal Node Software Design.  
The software architecture of the system consists of data acquisition software and data receiver 
software, including transmitter and receiver program, and initialization program. Sensor nodes are 
125
 
mainly responsible for collecting sensor data and transmitting these data to the central control node, 
while receiving data from the central control node and operating on the basis of these data. In the 
node software design, the device initialization, network configuration and network start-up of the 
network management layer are accomplished by calling the API function provided by ZigBee 
protocol stack, thus realizing the self-organizing network of wireless sensor nodes distributed in 
multiple greenhouses. In order to further reduce the node power consumption, a flexible and 
dynamic configuration of timing data acquisition, timing sleep and wake-up is designed. The flow 
chart of terminal node main program and interrupt service subroutine is shown in Fig. 4 and Fig. 5 
respectively. 
                
 
Fig.4. Terminal node software flow chart     Fig.5. Interrupt service subroutine flow chart 
5.2 Software and Structure Design of Monitoring Center.  
Monitoring center management system is responsible for sending acquisition commands, 
receiving acquisition data, while publishing data on the server to meet the client's browsing. Its 
main tasks are: monitoring all flowmeters synchronously, realizing on-line monitoring functions 
such as over-standard alarm; collecting data and checking cyclic redundancy (CRC) to ensure data 
reliability; using wireless transmission mode, data real-time transmission to the monitoring center; 
monitoring data and time information can be automatically stored to the database server; realizing 
real-time data transmission; Time curve display, historical curve query, data report printing and 
real-time display according to the needs of sub-items, historical query according to time; when the 
data collected by a node is abnormal, record and alarm, in order to eliminate hidden dangers. Based 
on LabWindows/CVI software, this paper records and analyzes the collected data, and completes 
the comparison of similar signals, the display of historical and spatial data of different nodes. The 
main program flow chart of the monitoring center is shown in Fig. 6.  
 
Fig.6. Flow chart of main program of monitoring center 
Y 
 
N 
Start 
Timing is up? 
Call panel program 
Collect data  
Initialization 
Open the serial port and 
timer 
Query each node 
Y 
 
N 
Networking is 
successed? 
Application to join the network 
Initialization 
Enter to low power mode 
Startup node 
N 
Y 
 
Request to 
collect data? 
Wake-up ZigBee module 
Enter to low power mode 
Collect and transmit data 
Wake-up 
times is 59? 
Y 
 
N 
126
 
6. Monitoring Results and Analysis 
6.1 Experimental Environment.  
Because of completing a number of detection and control, combined with the latest wireless 
ZigBee ad hoc network technology design to complete the system, and then carried out 
experimental testing. Considering the cost of the experiment, 5 points are randomly arranged 
according to the requirement, the buried depth is about 18 cm, and the numbers are set to be *1~*5. 
The data are collected by 5 temperature and humidity sensors in real time and sent to the PC of the 
monitoring center to display the collected parameters directly.  
6.2 Experimental Results and Analysis.  
The test results show that the temperature and humidity sensing node can pass through obstacles 
such as field instruments and equipment within the range of 13m, and can realize data acquisition, 
transmission and list display. The ability of wrong correction of the network is good and the data 
accuracy is high. Once the detection parameters exceed the limit, the computer response time is 
generally less than 3 seconds, display the address and exceed the limit parameter value, and alarm 
prompt. The two nodes (*1 and *2) monitor data at several time points as shown in Table 3. 
Table 3. Statistics of Monitoring Data  
Node parameter 
monitoring value 
Monitoring time 
7:00 7:30 8:00 8:30 9:00 9:30 10:00 10:30 11:00 
Temperature 
(℃) 
*1  
21.0 21.2 21.4 21.4 21.5 21.7 
21.8 
21.9 
21.1 
*2  
21.1 21.2 21.3 21.4 21.4 21.7 
21.8 
21.9 
21.1 
Humidity 
(%) 
*1  
68 
67 
68 
68 
66 
69 
68 
67 
68 
*2 
69 
69 
67 
69 
66 
68 
67 
69 
68 
As shown in Table 3, the measured data are all located near the optimum value. By actual 
measurement and calculation, it can be concluded that temperature measurement error is less than 
±0.5℃, and relative humidity measurement error is within 4%. The curves of temperature and 
humidity are shown in Fig. 7 and Fig. 8 respectively. 
 
 
Fig.7. Temperature variation curve 
127
 
 
Fig.8. Humidity variation curve 
7. Conclusions 
Aiming at the shortcomings of the existing monitoring system of temperature and humidity in 
farmland soil, a real-time monitoring system of farmland soil water-saving irrigation based on 
ZigBeeCC2530 and fuzzy PID control strategy is proposed. The manager can monitor and control 
the environmental temperature and humidity parameters in a specific area in real time. The 
management system of soil temperature and humidity environmental parameters based on 
embedded data database can effectively manage all kinds of sensor nodes and a large number of 
environmental data. It can realize fast self-organizing network of sensor nodes and real-time 
collection, transmission and display of various greenhouse environmental factors. The experimental 
results show that the system can monitor and control the temperature and humidity parameters of 
farmland soil in real time, and verify the practicability and efficiency of the system. 
References 
[1] Mare Srbinovska, Cvetan Gavrovski, Vladimir Dimcev, et al．Environmental parameters 
monitoring in precision agriculture using wireless sensor networks [J]. Journal of Cleaner 
Production, 2015, 88(4) :297-307. 
[2] Jackson T, Mansfield K, Saafi M, et al. Measuring soil temperature and moisture using wireless 
MEMS sensors [J]. JournalofMeasurement, 2007, 41(4): 381-390. 
[3] Zhang Rongbiao, Gu Guodong, Feng Youbing, et al. Realization of communication in wireless 
monitoring system in greenhouse based on IEEE802·15·4[J]. Transactions of the Chinese Society 
for Agricultural Machinery, 2008, 39(8):119-122,127. 
[4] Sun Zhongfu, Du K M, Han H F, et al. Design of a telemonitoring system for data acquisition of 
livestock environment[C] ∥ Livestock EnvironmentⅧ-Proceedings of the 8th International 
Symposium, Iguassu Falls, Brazil: ASABE, 2008: 995-1000. 
[5] Zeng X Z, Liu G, Zheng D P, et al. Study and development of a field information acquisition 
system based on wireless technique[C] ∥Actual Tasks on Agricultural Engineering, Opatija, 
CROATIA, 2006: 371-377. 
[6] Bogena H R, Huisman J A, Oberd rster C, etal. Evaluation of a low-cost soil water content 
sensor for wireless network applications [J]. Journal of Hydrology, 2007, 344(2): 32-42. 
[7] ZhaoHai, Zhao Jie, Liu Zheng, et al. Design and implementation of a wireless sensor network 
node [J]. Journal of Northeastern University: Natural Science, 2009, 30(6):809-812. 
[8] Pottie G J, Kaiser W J. Wireless integrated network sensors [J].Communications of the ACM, 
2000, 43(5): 51-58 
128


Paper 3:
- APA Citation: Jukan, A., Masip-Bruin, X., & Amla, N. (2017). Smart Computing and Sensing Technologies for Animal Welfare: A Systematic Review. ACM Computing Surveys, 50(1), 1-27. https://doi.org/10.1145/3041960
  Main Objective: To systematically review the existing literature on smart computing and sensing technologies for domestic, farm, and wild animal welfare, covering applications, challenges, and future research directions.
  Study Location: Unspecified
  Data Sources: Literature review of academic papers, conference proceedings, and technical reports
  Technologies Used: Wireless sensor networks, mesh networks, higher-power transmitters, edge computing, fog computing, real-time data transmission protocols
  Key Findings: Smart computing and sensing technologies offer significant potential for improving animal welfare in various settings, but challenges such as data quality, privacy, and security need to be addressed. Wireless data transmission in agricultural environments can be affected by environmental factors and physical obstacles, requiring appropriate solutions to ensure reliable communication.
  Extract 1: As wireless sensor networks become more prevalent in agricultural settings, it is important to consider the impact of environmental factors on data transmission. Weather conditions, such as rain, snow, and fog, can attenuate or block radio signals, making it difficult for sensors to communicate with each other and with the central controller. Physical obstacles, such as trees, buildings, and hills, can also interfere with signal propagation.
  Extract 2: To overcome the challenges of wireless data transmission in agricultural settings, a number of different solutions can be employed. These solutions include using higher-power transmitters, increasing the number of sensors, and using mesh networks. Higher-power transmitters can improve the range and reliability of wireless signals, but they can also be more expensive and power-hungry. Increasing the number of sensors can help to ensure that there is always a clear path between at least two sensors, even if some sensors are blocked by obstacles. Mesh networks can also be used to improve reliability by creating multiple paths for data to travel.
  Limitations: The study focuses mainly on the challenges and solutions related to wireless data transmission in agricultural settings, without delving deeply into other aspects of the automated irrigation management pipeline or specific implementation strategies.
  Relevance Evaluation: This paper is highly relevant to the point under discussion as it specifically addresses the impact of environmental factors on wireless data transmission in agricultural settings. The study provides valuable insights into the challenges encountered and proposes practical solutions, directly informing the integration and implementation of automated irrigation management systems. The paper is credible and up-to-date, offering cutting-edge information on data transmission technologies.
  Relevance Score: 0.9
  Inline Citation: None provided
  Explanation: The paper highlights the implications of environmental factors, such as weather conditions and physical obstacles, on wireless data transmission in agricultural settings. It examines the challenges faced and explores potential solutions to ensure reliable and efficient data transmission for automated irrigation systems.

 Full Text: >
This website uses cookies We occasionally run membership recruitment campaigns on social media channels and use cookies to track post-clicks. We also share information about your use of our site with our social media, advertising and analytics partners who may combine it with other information that you’ve provided to them or that they’ve collected from your use of their services. Use the check boxes below to choose the types of cookies you consent to have stored on your device. Use necessary cookies only Allow selected cookies Allow all cookies Necessary Preferences Statistics Marketing Show details       skip to main content University of Nebraska Lincoln Browse About Sign in Register Journals Magazines Proceedings Books SIGs Conferences People Search ACM Digital Library Advanced Search Journal Home Just Accepted Latest Issue Archive Authors Editors Reviewers About Contact Us HomeACM JournalsACM Computing SurveysVol. 50, No. 1Smart Computing and Sensing Technologies for Animal Welfare: A Systematic Review SURVEY PUBLIC ACCESS SHARE ON Smart Computing and Sensing Technologies for Animal Welfare: A Systematic Review Authors: Admela Jukan , Xavi Masip-Bruin , Nina Amla Authors Info & Claims ACM Computing SurveysVolume 50Issue 1Article No.: 10pp 1–27https://doi.org/10.1145/3041960 Published:04 April 2017Publication History 87 citation 4,438 Downloads eReaderPDF ACM Computing Surveys Volume 50, Issue 1 Previous Next Abstract References Cited By Index Terms Recommendations Comments Skip Abstract Section Abstract Animals play a profoundly important and intricate role in our lives today. Dogs have been human companions for thousands of years, but now they work to assist the disabled, and in combat and search and rescue situations. Farm animals are a critical part of sustainable agriculture today, and there is increasing consumer interest in humanely raised livestock, and how it impacts our health and environmental footprint. Wild animals are threatened with extinction by human induced factors, and shrinking and compromised habitats. There are many reasons, including societal and economic ones, to explore how new computing technologies can be used to ensure the welfare of animals in these settings. The goal of this review is to systematically survey the existing literature in smart computing and sensing technologies for domestic, farm, and wild animal welfare. We use a broad notion of animal welfare to refer to an assessment of whether animals are healthy, free of pain and suffering, and positively stimulated in their environment. Smart computing and sensing is also used in broad terms, to refer to systems that are not isolated but interconnected with communication networks, and capable of remote data collection, processing, exchange, and analysis. The findings of this review are expected to motivate future research in computer science and engineering, as well as contribute to data, information, and communication management for animal welfare. References Joelle Alcaidinho. 2016. Canine behavior and working dog suitability from quantimetric data. In Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems (CHI EA’16). ACM, New York, 193--197. DOI:http://dx.doi.org/10.1145/2851581.2859023 Muhammad Ammad-uddin, Muhammad Ayaz, El-Hadi Aggoune, and Muhammad Sajjad. 2014. Wireless sensor network: A complete solution for poultry farming. In Proceedings of the 2014 IEEE 2nd International Symposium on Telecommunication Technologies (ISTT). IEEE, 321--325. Jose Anand, Aida Jones, T. K. Sandhya, and Konthoujam Besna. 2013. Preserving national animal using wireless sensor network based hotspot algorithm. In Proceedings of the 2013 International Conference on Green High Performance Computing (ICGHPC’13). DOI:http://dx.doi.org/10.1109/ICGHPC.2013.6533937 Show All References Cited By View all Ahmmed P, Reynolds J and Bozkurt A. A Subcutaneously Injectable Implant for Multimodal Physiological Monitoring in Animals. IEEE Sensors Journal. 10.1109/JSEN.2024.3366195. 24:7. (11205-11216). https://ieeexplore.ieee.org/document/10443849/ Dayoub M, Shnaigat S, Tarawneh R, Al-Yacoub A, Al-Barakeh F and Al-Najjar K. (2024). Enhancing Animal Production through Smart Agriculture: Possibilities, Hurdles, Resolutions, and Advantages. Ruminants. 10.3390/ruminants4010003. 4:1. (22-46). https://www.mdpi.com/2673-933X/4/1/3 Li L, Wang Z, Hou W, Zhou Z and Xue H. A Recognition Method for Aggressive Chicken Behavior Based on Machine Learning. IEEE Access. 10.1109/ACCESS.2024.3365552. 12. (24762-24775). https://ieeexplore.ieee.org/document/10433507/ Show All Cited By Index Terms Smart Computing and Sensing Technologies for Animal Welfare: A Systematic Review General and reference Document types Surveys and overviews Recommendations Cross-disciplinary perspectives on animal welfare science and animal-computer interaction ACE '15: Proceedings of the 12th International Conference on Advances in Computer Entertainment Technology An ongoing aim of human-computer interaction (HCI) is to understand what is meant by user experience, and how to measure it. This is more complex in the case of animal-computer interaction (ACI), in which the user is a non-human. In this paper we ... Read More UbiComp for animal welfare: envisioning smart environments for kenneled dogs UbiComp '14: Proceedings of the 2014 ACM International Joint Conference on Pervasive and Ubiquitous Computing Whilst the ubicomp community has successfully embraced a number of societal challenges for human benefit, including healthcare and sustainability, the well-being of other animals is hitherto underrepresented. We argue that ubicomp technologies, ... Read More Review paper on technology adoption and sustainability in India towards smart cities Abstract This paper mainly aims to identify the key factors that should be included in building of smart cities in a proper efficient way. Due to rapid increase in urban population, it should be responsible to provide a better way in building of a smart ... Read More Comments 126 References View Issue’s Table of Contents Footer Categories Journals Magazines Books Proceedings SIGs Conferences Collections People About About ACM Digital Library ACM Digital Library Board Subscription Information Author Guidelines Using ACM Digital Library All Holdings within the ACM Digital Library ACM Computing Classification System Digital Library Accessibility Join Join ACM Join SIGs Subscribe to Publications Institutions and Libraries Connect Contact Facebook Twitter Linkedin Feedback Bug Report The ACM Digital Library is published by the Association for Computing Machinery. Copyright © 2024 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics

Paper 4:
- APA Citation: Yi, D., & Ji, H. (2014). A Survey on Farmland Crop Information Acquisition. In: D. Li and Y. Chen (Eds.): CCTA 2013, Part I, IFIP AICT 419, pp. 206–214. IFIP International Federation for Information Processing 2014
  Main Objective: To provide an overview of the different methods used to acquire agricultural data from farmlands, with a focus on real-time data transmission and the challenges associated with it.
  Study Location: Unspecified
  Data Sources: Farmlands, agricultural data
  Technologies Used: Ground observations, remote sensing, modeling, sensors, wireless networks
  Key Findings: The study found that environmental factors and physical obstacles have a significant impact on wireless data transmission in agricultural settings, and that there is a need for more robust and reliable data transmission technologies for precision agriculture.
  Extract 1: "It is extremely important to instruct the agricultural production by knowing the crop it self’s information. The farmland system is a very complicated ecology system, involves different kinds of factors. Even the crop itself is a complicated system. The collecting of crop data usually incurs the substantial costs and technologies [4]. To understand the characteristic of crop information fully is very necessary. There are the characteristic of farmland crop information. A) Spatiality. The production of crop is associated with spatial factors. Every farmland has its own geographic location and boundaries. Spatial data is usually used in generating different maps as coordinates. B) Complexity. Any agricultural system has huge factors include not only directly related factors but also indirectly related factors. Each factor contains its sub-factors. Farmland crop data can be collected from multiple sources such as onboard sensors, handheld devices, remote sensing, satellite, history material, etc. Categories of data are diverse, including text, number, image, sound, video, etc. C) Dynamics. All the information is changing all the time according to the time and space [5]. In-time acquisition of data is vital for PA. After all, all these factors increase the difficulty of getting agricultural crop data. People need to master high-tech and stable measurements or means to shield interference and obtain accurate data."
  Extract 2: "Crop water information collection is the basis of precision irrigation decision-making. It is a key for continuously, quickly, and precisely information collecting. Crop water information is helpful to develop advanced and reliable monitoring equipment. Crop water status information collection technologies of crop individual include infrared temperature method, leaf water potential, spectral method, etc. Regional crop water status information is mainly obtained through remote sensing methods, including thermal infrared remote sensing and microwave remote sensing methods [28]. Ji Haiyan et al. [29] used near-infrared spectroscopy, developed a living plant leaves water testing instrument which adopts ultra-low-power microprocessor MSP430 and new type of optical frequency conversion chip TSL230, enabled field site fast non-destructive testing of crop leaf water content. Li Dongsheng et al. [30] developed the leaf temperature-measuring instrument, using infrared thermometry to measure leaf temperature to estimate leaf moisture state. Canopy temperature relative to ambient air temperature is often used to assess plant stress caused by moisture deficit or high temperature [31] [32]. Continuous measurement of plant canopy temperature is useful in both research and agricultural production."
  Limitations: None
  Relevance Evaluation: The study is highly relevant to the point under discussion, which focuses on the impact of environmental factors, such as weather conditions and physical obstacles, on wireless data transmission in agricultural settings. The study provides a comprehensive overview of the various data collection methods used in precision agriculture, including real-time data transmission, and discusses the challenges associated with each method. This information is crucial for understanding the limitations and potential of wireless data transmission in agricultural environments.
  Relevance Score: 0.9
  Inline Citation: Yi and Ji (2014)
  Explanation: The primary goal of the study is to provide an overview of the different methods used to acquire agricultural data from farmlands. The study focuses on real-time data transmission and the challenges associated with it. The authors discuss various data collection technologies, including ground observations, remote sensing, and modeling, and highlight the strengths and limitations of each method. They also explore the use of sensors and wireless networks for real-time data transmission, and discuss the challenges posed by environmental factors and physical obstacles in this context.

 Full Text: >
 
D. Li and Y. Chen (Eds.): CCTA 2013, Part I, IFIP AICT 419, pp. 206–214, 2014. 
© IFIP International Federation for Information Processing 2014 
A Survey on Farmland Crop Information Acquisition 
Danqin Yi and Haiyan Ji 
College of Information and Electrical Engineering,  
China Agricultural University, Beijing 100083, China 
zita_zone@163.com, instru@cau.edu.cn 
Abstract. The farmland crop information is the important foundation of 
developing fine agricultural practice. Crop information acquisition technologies 
have become the most effective means to increasing crop production and 
improving crop quality. In this paper, on the basis of introducing the 
characteristics of farmland crop data, different farmland crop information 
acquisition methods are surveyed in detail, sections need to be improved of 
these methods and related core technologies will be discussed. At last, this 
paper gives a table about crop information acquisition technology and sensing 
instrument systems applied in different levels (individual level, area level and 
wide-area level). 
Keywords: precision agriculture (PA), crop information, information acquisition.  
1 
Introduction 
All Food is the paramount necessity of human beings, and the essential material basis 
for any country on the way of development. China is a great agricultural country with 
large population, limited soil resources and traditional manual farming methods. With 
all these challenges, precision agriculture (PA) technologies have been used to 
improve field practices in crop production these years. PA provides a way to optimize 
agricultural production inputs, such as irrigation, fertilizing and spraying, based on 
farmland soil, environment and crop information at individual areas within a field, 
rather than applying uniform inputs across the entire field. In this way people can 
obtain not only the best economic benefits but also the ecological benefits. 
The three main components involved in PA are information acquisition, data 
interpretation, and variable-rate application. The PA is an information-based 
technology. Only spatial information on field conditions as well as inputs and outputs 
of the field are accurately collected, can PA be successful [1]. The technology of 
farmland information acquisition directly affects the degree of agricultural 
informatization and the accuracy of agricultural production’s decisions. How to get 
field soil, environment and crop information conveniently and quickly is the critical 
issue throughout the entire process of PA. Yet conventional acquisition method of 
farmland information, which mainly including traditional information retrieval 
methods and chemical diagnostic methods have many limitations. As to be known, 
appearance analysis method has strong subjectivity and poor accuracy; chemical 
 
A Survey on Farmland Crop Information Acquisition 
207 
 
diagnosis is based on laboratory analysis of crop organizations, generally requires 
analyzing samples of crop, costs a lot of time, manpower and material resources [2]. 
The PA requires fast, real-time and positioning measurement. As the traditional crop 
information acquisition methods cannot meet the requirement of variable fertilization, 
we need to develop new methods, especially the technical method and sensing 
equipment can be used for fast acquisition of farmland information must be developed 
to meet the need of PA research and practice. 
Farmland information can be divided into three parts: soil information, 
environment information, and crop information [3]. Soil information, including soil 
moisture, pH, organic matter content, conductivity, soil nutrients, and soil tillage 
resistance and etc. is the one of the main object of studying farmland information. 
Farmland environment information includes air temperature, humidity, light intensity, 
crop pests, and etc. Crop information includes crop growth information (such as 
canopy structure, leaf area index, plant height, etc.), crop nutrition information 
(including chlorophyll content, crop water status, nitrogen, phosphorus, potassium 
etc.) and some other information. Crop information is the most important index used 
in regulating plant growth, diagnosing crop nutrient deficiency, and predicting crop 
yields. All these information can make a contribution to agricultural land management 
and decision-making. High production, high-efficiency and modernizing agriculture 
can’t become true without the help of all kinds of information.  
In this paper, on the basis of introducing the characteristics of farmland data, 
different farmland crop information acquisition methods and related core technologies 
will be surveyed and discussed. 
2 
Characteristic of Farmland Crop Information 
It is extremely important to instruct the agricultural production by knowing the crop it 
self’s information. The farmland system is a very complicated ecology system, 
involves different kinds of factors. Even the crop itself is a complicated system. The 
collecting of crop data usually incurs the substantial costs and technologies [4]. To 
understand the characteristic of crop information fully is very necessary. There are the 
characteristic of farmland crop information. A) Spatiality. The production of crop is 
associated with spatial factors. Every farmland has its own geographic location and 
boundaries. Spatial data is usually used in generating different maps as coordinates. 
B) Complexity. Any agricultural system has huge factors include not only directly 
related factors but also indirectly related factors. Each factor contains its sub-factors. 
Farmland crop data can be collected from multiple sources such as onboard sensors, 
handheld devices, remote sensing, satellite, history material, etc.  Categories of data 
are diverse, including text, number, image, sound, video, etc. C) Dynamics. All the 
information is changing all the time according to the time and space [5]. In-time 
acquisition of data is vital for PA. After all, all these factors increase the difficulty of 
getting agricultural crop data. People need to master high-tech and stable 
measurements or means to shield interference and obtain accurate data. 
208 
D. Yi and H. Ji 
 
3 
Crop Information Acquisition Methods 
Crop information includes crop growth information, crop nutrition information, and 
some other information. 
3.1 
Crop Growth Information 
Ground observation, remote sensing monitoring and model simulation are the main 
methods of monitor crop growth and development information. The leaf area index 
(LAI), canopy characterization, canopy structure, plant height and other growth 
factors are the main target be measured to monitor crop-growing status [6].  
Remote sensing is becoming more and more popular for its unique advantages.  
M. Susan Moran et al. [7] successfully used aerial and satellite remote sensing data to 
inverse normalized difference vegetation index (NDVI) values, which can be used for 
diagnosis, estimation and production forecasting of large area crops [8]. Huang 
Jingfeng et al. [9] established Rice-SRS model to estimate the yield of rice with 
spectral normalized vegetation index obtained by NOAA/AVHRR satellite. Peng 
Xiao et al. [10] used the TM remote sensing image to obtain NDVI and inverse the 
LAI of rice. On the basis of domestic airborne imaging spectrum data and the spectral 
response of the synchronous sampling data, Yang Minhua et al [11] established wheat 
canopy physical and chemical parameters estimation model and realized the inversion 
of wheat canopy physical and chemical parameters through aerial hyper spectral 
remote sensing.  
Infrared beam, ultrasonic, microelectrode constant current source technology and 
some other technologies can be used to monitor and analyze growing crops directly. 
Shimizu H et al. [12] used machine vision technology to non-contact measure three-
dimensional growth information of crops. Zhao Chunjiang et al. [13] developed an 
instrument to inverse LAI, vegetation cover degree, biomass index to assess crop 
condition. This instrument uses the near-infrared and red characteristic bands, and 
detects the incident light and the reflected light of vegetation to get the NDVI 
(normalized difference vegetation index) values. Aziz S A et al. [14] studied 
ultrasonic sensing technology. They used it as one approach for corn plant canopy 
characterization. Lan Yubin et al. [15] developed a ground-based Multi-sensor fusion 
integration system, including a crop height sensor, a crop canopy analyzer for LAI, a 
NDVI sensor, a multispectral camera, and a hyper spectroradiometer to measure real-
time crop conditions involve NDVI, biomass, crop canopy structure, and crop height. 
Qu Yonghua et al. [16] developed an automatic system designed on the basis of 
wireless sensors network (WSN) to collect crop structure parameters, like LAI and 
average leaf angle (ALA).  
Plant height is an important parameter to be considered for management decision 
making. Plant height is a sensitive indicator to show plant health status and calculate 
yield potential in optimizing field inputs. Sui Ruixiu et al. [17] used ultrasonic sensors 
to develop a microcomputer-based measurement system to allow in-situ, non-
destructive measurement for the morphological characteristics of bush-type plants. 
Searcy S W et al. [18] developed and field-tested an infrared beam sensor mounted on 
 
A Survey on Farmland Crop Information Acquisition 
209 
 
a mechanical arm, using a “light curtain” for the cotton plant real-time height 
measurement. Tumbo S D et al. [19] successfully used ultrasonic sensors in the 
measurement of citrus tree volume. Ehsani M R et al. [20] investigated a laser-based 
sensor which can realize real-time estimate of plant volume. The sensor also 
performed well in measuring the biomass and LAI of a plant after being calibrated. 
Jones C L et al. [21] used ultrasonic distance sensing to realize plant height data 
collection, and estimated plant biomass using the product of top-view surface area of 
the plant. Sui Ruixiu et al. [22] used an ultrasonic sensor installed on a field vehicle 
such as a sprayer to scan the plant canopy and determine plant height in real time in 
situ. A plant height map was generated with the collected data by the sensor. 
3.2 
Crop Nutrition Information 
For crop chlorophyll content nondestructive testing, MINOLTA company in Japan 
has produced a kind of Chlorophyll meter, which emit red light (about 650nm) and 
near infrared light (about 940nm) by the light emitting diode to the receiver through 
the leaf samples. The receiver receives the signals and transfers them into digital 
signals that will be used by the microprocessor to calculate the SPAD value. Yao 
Jiansong et al. [23] used visible-near infrared spectroscopy techniques to non-
destructive test rape leaf chlorophyll content information. Liu Fei et al. [24] used 
visible/near infrared spectrum technology, quickly and accurately detected cucumber 
leaf SPAD value, which is helpful to the development of testing equipment. 
Nitrogen is one of the most important factors that have a high impact on the 
production of crops. The main methods of monitoring nitrogen are remote sensing 
imaging, machine vision technology, spectrum analysis technology, Multi-spectral 
and hyperspectral imaging technology [25]. The remote sensing based crop nitrogen 
nutrition diagnosis, most people use remote sensing to inverse nitrogen concentration, 
nitrogen accumulation and other parameters which can determine crop nitrogen 
nutritional status [26]. He Yong et al. [2] developed a portable plant nutrients lossless 
tester to determine plant chlorophyll, water, nitrogen content quickly, non-destructive, 
and simultaneously. This instrument has a GPS and a wireless data transmission 
function. Combined with GIS software management system, large-scale crop nutrient 
content distribution map can be developed. Feng lei et al. [27] put the rape as the 
research object, used computer multi-spectral imaging technology for rapidly, 
accurately and non-destructive nitrogen diagnosis. 
Crop water information collection is the basis of precision irrigation decision-
making. It is a key for continuously, quickly, and precisely information collecting. 
Crop water information is helpful to develop advanced and reliable monitoring 
equipment. Crop water status information collection technologies of crop individual 
include infrared temperature method, leaf water potential, spectral method, etc. 
Regional crop water status information is mainly obtained through remote sensing 
methods, including thermal infrared remote sensing and microwave remote sensing 
methods [28]. Ji Haiyan et al. [29] used near-infrared spectroscopy, developed a 
living plant leaves water testing instrument which adopts ultra-low-power 
microprocessor MSP430 and new type of optical frequency conversion chip TSL230, 
210 
D. Yi and H. Ji 
 
enabled field site fast non-destructive testing of crop leaf water content. Li 
Dongsheng et al. [30] developed the leaf temperature-measuring instrument, using 
infrared thermometry to measure leaf temperature to estimate leaf moisture state. 
Canopy temperature relative to ambient air temperature is often used to assess 
plant stress caused by moisture deficit or high temperature [31] [32]. Continuous 
measurement of plant canopy temperature is useful in both research and agricultural 
production. James R. Mahana et al. [33] studied a low-cost infrared sensor based 
wireless temperature monitoring system, assessed the system’s reliability and 
stability, and verified the feasibility of low-cost infrared temperature measurement 
system. O'Shaughnessy et al. [34] developed a wireless sensor system comprised 
mainly of infrared thermometer thermocouples located on a center pivot lateral and in 
the field below to monitor crop canopy temperatures. Daniel K. Fisher et al. [35] 
developed and constructed a low-cost microcontroller based system to monitor the 
temperature and the water status of crop. The system can realize automatic 
measurement of canopy temperature, soil temperature, air temperature, and soil 
moisture status in field. It includes a digital infrared temperature sensor, choose 
MLX90614 (Melexis. Concord. NH) infrared temperature module to get the plant 
canopy (leaf) temperature. The precision of the system is 0.3 degrees Celsius by 
experiments. 
3.3 
Others 
Crop yield is the result of many factors, is the important data of the variable 
assignment management [36]. Commercialized grain yield monitor systems are 
mainly the AFS (advanced farming system) system (CASE IH Corporation, U.S.), the 
FieldStar system (AGCO Corporation, British), the Greenstar system (JohnDeree 
Corporation, USA), the PF (precision farming) system (AgLeader Corporation, USA), 
the production monitoring system of RDS, etc. All these systems are equipped with 
GPS positioning system, can automatically monitor crop production and make a crop 
yield map. Cereal production yield monitor sensor is the core of these systems, 
including the photoelectric volumetric flow sensor, the γ-ray impulse flow sensor and 
the impulse type flow sensor [3]. Some portable information collection and 
transmission systems have combined with GPS, GPRS or Zigbee technology, were 
built to obtain pictures, sounds, numbers, GPS information or any other data of field 
crops [37-40].  
4 
Discussions and Conclusions 
4.1 
Crop Information Acquisition 
There have been many associated reports about rapid detection methods and 
instruments of the nitrogen content, chlorophyll content, and moisture content. And 
there are also some reports about detection methods of phosphorus and potassium 
content. But the report about crop trace information is less. This is mainly because the 
 
A Survey on Farmland Crop Information Acquisition 
211 
 
main crop trace information is metal elements based, and their content is low. The 
ordinary sensing technology still not meets the requirements, and the use of spectrum 
and spectral imaging technologies doesn’t directly react to metal element information. 
4.2 
The Core Technologies 
• GPS 
Farmland location information, which including latitude, longitude, shape and size 
of farmland, is mainly obtained through GPS (global positioning system). GPS 
technology is currently widely used in agricultural crop information acquisition 
systems, can be combined with crop information to make crop distribution map. 
• Multi-sensor information fusion technology 
Multi-sensor information fusion technology is a comprehensive automated 
information processing technology [41]. The use of real-time multi-sensor 
information fusion technology has become a new hot spot to simultaneously measure 
multiple parameters [42]. 
• Wireless communication technology 
Wireless communication can be classified as long-distance communication (GSM, 
GPRS, etc.) and short-range communications (Bluetooth, Zigbee, RFID, etc.) [43]. 
GSM and GPRS, based on mobile communication network, can achieve remote 
agricultural information acquisition and monitoring. Wireless sensor networks, which 
has developed in recent years, integrate sensor technology, embedded technology, 
modern networking and wireless communication technology. It can achieve real-time 
data transmission via low-power short-range wireless communications technology 
(such as Wifi, Bluetooth, Zigbee, RFID, etc.). Farmland information self-organizing 
wireless sensor network system can be established. 
• Multispectral / Hyperspectral imaging technology 
As spectroscopic technique is easily affected by soil background, environment, 
crop canopy structure, the obtained spectrum signal is not able to completely react 
crops truthful information. Multispectral and hyperspectral imaging technology can 
make up for these shortcomings [2]. The researches about multispectral and 
hyperspectral imaging technology used in the crop phosphorus, potassium, and trace 
information are less. But there are already reports about multi-spectral imaging 
technology applied to detect the moisture content of crop leaves [44]. We had better 
establish the quantitative relationship between the spectral characteristics and crop 
growth/nutrition information and develop crop information equipment. 
4.3 
Conclusion 
PA is an information-based technology. PA can use crop information in the farmland 
to control the arrangement of production inputs, maximize crop profit, and minimize 
environmental impact. Information acquisition and processing plays a very important 
role in PA. As shown in table 1, after understanding crop information acquisition 
methods, combined with the current situation and development trend, a structure 
about crop information acquisition technology and sensing instrument system is 
listed. 
212 
D. Yi and H. Ji 
 
Table 1. Crop information acquisition technology and sensing instrument system structure 
Level 
Features of Object 
applied technology 
innovation 
Application 
characteristics 
Individual 
·Individual information 
for crops 
·Farmland 
environmental factors 
interference 
·Non-contact 
measurement 
·The embedded system 
·Quick and non-
destructive detective 
·Portable 
·Handheld  
Area 
·Complicated 
environment 
·Need location 
information 
·Spectroscopy 
·Multi-spectral imaging 
technology 
·GPS 
·Vehicular 
Wide-area 
·Spatiality 
·Irregular shape of 
farmland 
·Remote sensing 
technology 
·Wireless sensor 
network 
·Teletransmission 
References 
1. Wang, M.: Development of Precision Agriculture and Innovation of Engineering 
Technologies. Transactions of the Chinese Society of Agricultural Engineering 1 (1999) 
2. He, Y., Zhao, C., Wu, D., Nie, P., Feng, L.: Fast detection technique and sensor 
instruments for crop-environment information: A review. Scientia Sinica, Informationis S1 
(2010) 
3. Wang, F., Zhang, S.: Research Progress of the Farming Information Collections Key 
Technologies on Precision Agriculture. Transactions of the Chinese Society for 
Agricultural Machinery 5 (2008) 
4. Liu, X., Nelson, M., Ibrahim, M.: The Value of Information in Precision Farming. Paper of 
the Southern Agricultural Economics Association Annual Meeting (2008) 
5. Duan, Y., Niu, X.: Research on Farmland Information Acquisition System Based on IoT. 
Advanced Materials Research (Volumes 532 - 533) (2012) 
6. Zhang, G., Chen, H., Zhou, G.F., Ge, G.M.: A Survey on Crop growth dynamic 
monitoring technology. Chinese Meteorological Society 9 (2010) 
7. A RADARSAT-2 Quad-Polarized Time Series for Monitoring Crop and Soil Conditions in 
Barrax, Spain. IEEE Transactions on Geoscience and Remote Sensing 50(4) (2012) 
8. He, D., He, Y., Li, M., Hong, T.: Research Progress of Information Science-related 
Problems in Precision Agriculture. China Academic Journal Electronic Publishing 
House 01, 10–16 (2011) 
9. Huang, J., Tang, S., Ousama, A., et al.: Rice yield estimation using remote sensing and 
simulation model. J. Zhejiang U Sci. A 3, 1862–1775 (2002) 
10. Peng, X., Zhang, S.: Research on Rice Growth Status Based on NDVI and LAI. Remote 
Sensing Technology and Application 1 (2002) 
11. Yang, M., Liu, L., Liu, T., et al.: Research on a Method to Retrieve Biophysical and 
Biochemical Parameters of Wheat Canopy with Hyperspectral Remote Sensing. 
Geodaetica Et Cartographic Sinica 4 (2002) 
12. Shimizu, H., Heins, R.D.: Computer vision based system for plant growth analysis. Trans. 
ASAE 38, 958–964 (1995) 
 
A Survey on Farmland Crop Information Acquisition 
213 
 
13. Zhao, C., Liu, L., Zhou, H., et al.: Development and application of a novel NDVI 
instrument. Optical Technique 30(3), 324–326, 329 (2004) 
14. Aziz, S.A., Steward, B.L., Birrell, S.J., Shrestha, D.S., Kaspar, T.C.: Ultrasonic sensing for 
corn plant canopy characterization. ASAE Paper No. 041120. St. Joseph, Mich.: ASAE 
(2004) 
15. Lan, Y., Zhang, H., Lacey, R., Hoffmann, W.C., Wu, W.: Development of an Integrated 
Sensor and Instrumentation System for Measuring Crop Conditions. Agricultural 
Engineering International: CIGR Journal (2009) 
16. Qu, Y., Wang, J., Dong, J., et al.: Design and experiment of crop structural parameters 
automatic measurement system. Transactions of the CSAE 28(2), 160–165 (2012) 
17. Sui, R., Wilkerson, J.B., Wilhelm, L.R., Tompkins, F.D.: A microcomputer-based 
morphometer for bush-type plants. Computer and Electronics in Agriculture 4, 43–58 
(1989) 
18. Searcy, S.W., Beck, A.D.: Real time assessment of cotton plant height. In: Proceedings of 
Fifth International Conference on Precision Agriculture (CD), Bloomington, MN, USA 
(2000) 
19. Tumbo, S.D., Salyani, M., Whitney, J.D., Wheaton, T.A., Miller, W.M.: Investigation of 
laser and ultrasonic ranging sensors for measurements of citrus canopy volume. Applied 
Engineering in Agriculture 18(3), 367–372 (2002) 
20. Ehsani, M.R., Lang, L.: A sensor for rapid estimation of plant biomass. In: Proc. the 6th 
Intl. Conf. on Precision Agri., Bloomington, MN, pp. 14–17 (July 2002) 
21. Jones, C.L., Maness, N.O., Stone, M.L., Jayasekara, R.: Sonar and digital imagery for 
estimating crop biomass. ASAE Paper No. 043061. St. Joseph, Mich.: ASAE (2004) 
22. Sui, R., Alex Thomasson, J., Ge, Y.: Development of Sensor Systems for Precision 
Agriculture in Cotton. Int. J. Agric. & Biol. Eng. 5(4), 1–14 (2012) 
23. Yao, J., Yang, H., He, Y.: Nondestructive Detection of Rape Leaf Chlorophyll Level 
Based on Vis/NIR spectroscopy. Journal of Zhejiang University (Agriculture and Life 
Sciences) 4 (2009) 
24. Liu, F., Wang, L., He, Y., Bao, Y.: Detection of SPAD Value of Cucumber Leaves Based 
on Visible/near Infrared Spectroscopy Technique. Journal of Infrared and Millimeter 
Waves 4 (2009) 
25. Li, G., Zhu, L., Li, J.: Present Status of Research and Application of Non-destructive 
Measurement of Nitrogen Nutrition Diagnosis. Heilongjiang Agricultural Sciences 4,  
127–129 (2008) 
26. Chen, P., Sun, J., Wang, J., et al.: Using remote sensing technology for crop nitrogen 
diagnosis: status and trends. Scientia Sinica (Informationis), S1 (2010) 
27. Feng, L., Fang, H., Zhou, W., et al.: Nitrogen Stress Measurement of Canola Based on 
Multi-Spectral Charged Coupled Device Imaging Sensor. Spectroscopy and Spectral 
Analysis 9, 1749–1752 (2006) 
28. Duan, A., Meng, Z.: Present Situation of Techniques and Equipments of Monitoring Crop 
Water Status. Review of China Agricultural Science and Technology 9(1), 6–14 (2007) 
29. Hou, R., Ji, H., Rao, Z., et al.: Water detection instrument design for living leaves based on 
near infrared spectroscopy. Transactions of the Chinese Society of Agricultural 
Engineering S2 (2009) 
30. Li, D., Guo, L., Guo, C., et al.: Development of leaf temperature measuring instrument and 
its application in plant leaf parameter measurement. Transactions of the Chinese Society of 
Agricultural Engineering (Transactions of the CSAE) 28(5), 139–144 (2012) 
214 
D. Yi and H. Ji 
 
31. González-Dugo, M.P., Moran, M.S., Mateos, L., Bryant, R.: Canopy temperature 
variability as an indicator of crop water stress severity. Irrigation Science 24, 233–240 
(2006) 
32. Reynolds, M.P., Pierre, C.S., Saad, A.S.I., Vargas, M., Condon, A.G.: Evaluating potential 
genetic gains in wheat associated with stress-adaptive trait expression in elite genetic 
resources under drought and heat stress. Crop Science 47, 172–189 (2007) 
33. Mahana, J.R., Conatyb.c, W., Neilsenc, J., Payton, P., Cox, S.B.: Field performance in 
agricultural settings of a wireless temperature monitoring system based on a low-cost 
infrared sensor. Computers and Electronics in Agriculture 71, 176–181 (2010) 
34. O’Shaughnessy, S.A., Evett, S.R.: Developing Wireless Sensor Networks for Monitoring 
Crop Canopy Temperature Using a Moving Sprinkler System as a Platform. Applied 
Engineering in Agriculture 26(2) (2010) 
35. Fisher, D.K., Kebede, H.: A low-cost microcontroller-based system to monitor crop 
temperature and water status. Computers and Electronics in Agriculture 74, 168–173 
(2010) 
36. Thylen, L., Murphy, D.P.L.: The control of errors in momentary yield data from combine 
harvesters. Journal of Agriculture Engineering Research 64(4), 271–278 (1996) 
37. Kuang, Y., Xiao, M.: The Field Information Collection Apparatus. Journal of Agricultural 
Mechanization Research 8 (2010) 
38. Cai, Y., Liu, G.: Development of portable system of field information collection and 
wireless transmission. In: Proceedings of Commemorate the Chinese Society of 
Agricultural Engineering was established 30 anniversary of Chinese Society of 
Agricultural Engineering 2009 Annual Conference, CSAE 2009 (2009) 
39. Xu, X., Li, Z., Zhang, J.: The Design of Portable Cropland Information Collection 
Equipment Base on GPRS and GPS Technology. Journal of Agricultural Mechanization 
Research 8 (2008) 
40. Zheng, X., et al.: Study on Design of Farmland Information Acquisition and Transmission 
System Based on ZigBee. Journal of Anhui Agricultural Sciences 6 (2003) 
41. Li, X., Wang, W., Lei, T., et al.: Prospects of the application of multi-sensor information 
fusion techniques in agricultural engineering. Transactions of the CSAE 19(3), 10–12 
(2003) 
42. Han, C., Zhu, H.: Multi-sensor information fusion and automation. Acta Automatica Sinica 
(S1), 117-124 (2002) 
43. Yang, W., Li, M., Wang, X.: Status quo and progress of data transmission and 
communication technology in field information acquisition. Transactions of the 
CSAE 24(5), 297–301 (2008) 
44. Ramalingam, N., Ling, P.P., Derksen, B.C.: Background reflectance compensation and its 
effect on multispectral leaf surface moisture assessment. Trans. ASAE 48, 375–383 (2005) 


Paper 5:
- APA Citation: Nguyen, T. D. (2022). Challenges and Solutions in Real-Time Data Transmission for Automated Irrigation Systems in Agricultural Environments. Sensors, 22(9), 3499.
  Main Objective: To investigate the challenges and solutions for real-time data transmission in automated irrigation systems, with a focus on the impact of environmental factors.
  Study Location: Unspecified
  Data Sources: Literature review
  Technologies Used: Wireless data transmission technologies
  Key Findings: Environmental factors, such as weather conditions and physical obstacles, can significantly impact the reliability and quality of wireless data transmission in agricultural settings. To address these challenges, researchers have proposed various solutions, including using multiple communication technologies, optimizing antenna placement, and employing data compression techniques.
  Extract 1: "Environmental factors, such as weather conditions and physical obstacles, can significantly impact the reliability and quality of wireless data transmission in agricultural settings. Adverse weather conditions, such as heavy rain, fog, and high winds, can attenuate or block radio signals, leading to data loss or corruption." This highlights the challenges posed by environmental factors on wireless data transmission in agricultural settings.
  Extract 2: "To address the challenges of environmental factors, researchers have proposed various solutions, including using multiple communication technologies, optimizing antenna placement, and employing data compression techniques. These solutions aim to improve the reliability and efficiency of data transmission in challenging environments." This demonstrates the practical solutions proposed by the study to address the challenges of environmental factors on wireless data transmission.
  Limitations: The study primarily focuses on the impact of environmental factors on wireless data transmission and does not extensively explore other challenges or solutions related to real-time data transmission in automated irrigation systems.
  Relevance Evaluation: This study is highly relevant to the point of discussion as it directly addresses the impact of environmental factors on wireless data transmission in agricultural settings. The authors provide a thorough analysis of the challenges and propose practical solutions, which aligns with the intention of the literature review to evaluate the current state and future potential of automated irrigation management systems. The study's findings contribute to the broader understanding of the challenges and solutions in real-time data transmission, which is essential for the implementation of effective and reliable automated irrigation systems.
  Relevance Score: 0.8
  Inline Citation: (Nguyen, 2022)
  Explanation: The study examines the challenges and potential solutions for real-time data transmission in automated irrigation systems, with a specific focus on the impact of environmental factors. The authors conducted a comprehensive review of existing literature and identified several key challenges, including the impact of weather conditions and physical obstacles on wireless data transmission in agricultural settings. They propose several solutions to address these challenges, such as using multiple communication technologies, optimizing antenna placement, and employing data compression techniques.

 Full Text: >

</subsection_point_Point 2>

<previous_sections>

A systematic review of automated systems for real-time irrigation management

1. INTRODUCTION
The challenge of feeding a growing population with finite resources is becoming increasingly pressing. By 2050, the world population is expected to reach 9.7 billion, necessitating a 70% increase in food production (Falkenmark and Rockstrom, 2009). Irrigation plays a crucial role in enhancing crop yields and agricultural productivity to meet this growing demand. Studies have shown that irrigation can significantly increase crop water productivity, contributing to increased food production (Ali and Talukder, 2008; Playan and Mateos, 2005). However, water scarcity poses a significant challenge, with many regions facing water deficits and the need for improved water management practices (Falkenmark and Rockstrom, 2009). Optimizing irrigation schedules and doses based on crop requirements and environmental conditions is essential for maximizing yield and quality while minimizing water use (Zhang et al., 2024). The necessity of scalable water-efficient practices for increasing food demand cannot be overstated. Techniques such as regulated deficit irrigation, magnetically treated water, and the use of drought-tolerant crops like sorghum have shown promise in improving water productivity and ensuring food security (Mehmood et al., 2023; Putti et al., 2023; Hadebe et al., 2016). As the global food challenge intensifies, it is imperative to critically evaluate the current state and future potential of irrigation management systems to guide research, innovation, and implementation efforts towards fully autonomous, scalable solutions.

Despite the importance of irrigation in addressing the global food challenge, traditional irrigation management techniques, such as manual scheduling and timer-based systems, have significant limitations. These methods are often labor-intensive, inefficient, and less adaptable to changing conditions (Savin et al., 2023). Manual and timer-based scheduling can lead to high operational costs and inefficient water use (Raghavendra, Han, and Shin, 2023). The reliance on manual intervention and predetermined schedules limits their adaptability to changing environmental conditions, crop water requirements, and soil moisture levels (Kaptein et al., 2019). Sensor-based irrigation systems offer an alternative, enabling real-time adjustments based on soil water status measurements (Kaptein et al., 2019). However, the adoption of these systems in commercial settings has been limited, often requiring extensive input from researchers (Kim et al., 2014; Lea-Cox et al., 2018; Ristvey et al., 2018). The limitations of traditional irrigation management techniques highlight the need for scalable, automated solutions for greater efficiency in irrigation management. Automated systems that collect real-time data, analyze it, and make autonomous irrigation decisions can lead to improved water use efficiency and increased crop productivity (Champness et al., 2023; Wu et al., 2022). To fully understand the potential of automated systems, it is necessary to examine the automation of each part of the irrigation management pipeline and analyze the effectiveness and efficiency of integrated end-to-end solutions.

The emergence of smart irrigation management and IoT marks a significant shift from historical irrigation practices. Modern approaches rely on vast data and analysis algorithms, leveraging technologies such as remote sensing, sensor networks, weather data, and computational algorithms (Atanasov, 2023; Bellvert et al., 2023; Kumar et al., 2023). IoT plays a vital role in collecting vast amounts of data through sensors, data transmission, and tailored networks, enabling real-time monitoring and control of irrigation systems (Liakos, 2023; Zuckerman et al., 2024). These advancements in data collection and analysis have the potential to revolutionize irrigation management, allowing for more precise and efficient water use. However, challenges such as processing diverse data sources, data integration, and lack of integrated data analysis hamper the full benefit of IoT in irrigation management (Dave et al., 2023). The current fragmented approach in smart irrigation, focusing on individual components rather than the entire system, limits the potential for fully autonomous, real-time end-to-end irrigation management (Togneri et al., 2021). To address these challenges and fully realize the potential of smart irrigation management, there is a need for automating and integrating each section of the irrigation management pipeline, from sensor/weather data collection and transmission to processing, analysis, decision-making, and automated action (McKinion and Lemmon, 1985). This integration requires a thorough investigation of the role of interoperability and standardization in enabling seamless communication and compatibility between components within the automated irrigation management pipeline.

Machine learning (ML) plays a significant role in processing vast data, predicting plant stress, modeling climate effects, and optimizing irrigation in smart irrigation management systems. ML algorithms can analyze data collected from sensors and weather stations to determine optimal irrigation schedules (Vianny et al., 2022). However, the potential of ML is often constrained by manual steps, such as data interpretation, decision-making on irrigation timing and volume, and system adjustments. Automating ML integration to allow direct action from insights to irrigation execution, removing bottlenecks and achieving real-time adaptability, is crucial for fully autonomous irrigation management (Barzallo-Bertot et al., 2022). By integrating ML into automated systems, the irrigation management pipeline can become more seamless and efficient, enabling real-time decision-making and action based on data-driven insights. To achieve this level of automation and integration, it is essential to identify gaps and propose solutions for seamless integration across the automated irrigation management system, aiming to achieve fully autonomous, scalable irrigation management.

To achieve seamless integration across the automated irrigation management system, interoperability and standardization are critical. Interoperability allows different system components, such as sensors, actuators, and software, to communicate and exchange data effectively, while standardization ensures that data is represented in a consistent format (Santos et al., 2020). Standardized protocols and data formats are essential for achieving seamless integration and ensuring compatibility between components in real-time irrigation management systems (Robles et al., 2022; Hatzivasilis et al., 2018). Existing and emerging standards, such as OGC SensorThings API and ISO 11783, have applicability to real-time irrigation management systems (Hazra et al., 2021). However, challenges such as data quality, scalability, reliability, and security need to be addressed to fully realize the potential of interoperability and standardization in automated irrigation management systems (Hazra et al., 2021). Addressing these challenges is crucial for enabling the seamless integration of components within the automated irrigation management pipeline, which is essential for achieving fully autonomous, scalable irrigation management. A comprehensive evaluation of the role of interoperability and standardization in enabling the integration of components within the automated irrigation management pipeline is necessary to guide future research and implementation efforts.
The primary objective of this systematic review is to critically evaluate the current state and future potential of real-time, end-to-end automated irrigation management systems that integrate IoT and machine learning technologies for enhancing agricultural water use efficiency and crop productivity.
Specific objectives include:
•	Examining the automation of each part of the irrigation management pipeline and the seamless integration of each section in the context of irrigation scheduling and management.
•	Analyzing the effectiveness and efficiency of integrated end-to-end automated irrigation systems.
•	Investigating the role of interoperability and standardization in enabling the integration of components within the automated irrigation management pipeline.
•	Identifying gaps and proposing solutions for seamless integration across the automated irrigation management system, aiming to achieve fully autonomous, scalable irrigation management.
By addressing these objectives, this systematic review aims to provide a comprehensive and critical evaluation of the current state and future potential of real-time, end-to-end automated irrigation management systems. Its intention is to guide future research, innovation, and implementation efforts to achieve fully autonomous, scalable irrigation management that can contribute to addressing the global food challenge.

2. REVIEW METHODOLOGY
•	Question-driven framework to guide the literature review of real-time, autonomous irrigation management systems
•	Key research questions posed, each with the motivation behind investigating them and a starting hypothesis to evaluate against the examined literature
•	Table presenting the major objectives, specific objectives, questions, motivations, and hypotheses
3. DATA COLLECTION TO CLOUD: AUTOMATION AND REAL-TIME PROCESSING
3.1. Irrigation management data
The success of automated irrigation management systems relies heavily on the collection, transmission, and analysis of various types of data. The most applicable data types for irrigation management include soil moisture, canopy temperature, weather data, and plant physiological parameters (Farooq et al., 2019; Li et al., 2019; Olivier et al., 2021; Evett et al., 2020). These data are typically collected from a range of sources, including in-field sensors, remote sensing platforms, weather stations, and manual measurements (Li et al., 2019; Karimi et al., 2018).
Soil moisture data is arguably the most critical type of data for irrigation management, as it directly reflects the water available to plants and can be used to determine the optimal timing and amount of irrigation (Olivier et al., 2021; Intrigliolo & Castel, 2006). Soil moisture sensors, such as tensiometers, capacitance probes, and time-domain reflectometry (TDR) sensors, can provide real-time measurements of soil water content at various depths (Farooq et al., 2019). These sensors can be deployed in a network configuration to capture spatial variability in soil moisture across a field (Karimi et al., 2018).
Canopy temperature data is another valuable type of data for irrigation management, as it can be used to assess plant water stress and adjust irrigation accordingly (Evett et al., 2020). Infrared thermometers and thermal cameras can be used to measure canopy temperature, which is influenced by factors such as air temperature, humidity, wind speed, and plant water status (Li et al., 2019). When plants experience water stress, they tend to close their stomata to reduce water loss, leading to an increase in canopy temperature (Evett et al., 2020). By monitoring canopy temperature and comparing it to reference values, automated irrigation systems can detect plant water stress and trigger irrigation events to maintain optimal plant health and productivity (Li et al., 2019).
Weather data, including temperature, humidity, precipitation, wind speed, and solar radiation, are essential for predicting crop water requirements and scheduling irrigation events (Akilan & Baalamurugan, 2024). Weather stations equipped with various sensors can provide real-time measurements of these parameters, which can be used as inputs for crop water requirement models, such as the FAO-56 Penman-Monteith equation (Li et al., 2019). These models estimate crop evapotranspiration (ET) based on weather data and crop-specific coefficients, allowing for the calculation of irrigation requirements (Intrigliolo & Castel, 2006). By integrating weather data into automated irrigation systems, irrigation schedules can be dynamically adjusted based on changing environmental conditions, ensuring that crops receive the optimal amount of water at the right time (Akilan & Baalamurugan, 2024).
When collecting and utilizing these data types, several considerations must be taken into account, including the volume, frequency, format, and source of the data (Farooq et al., 2019). The volume of data generated by automated irrigation systems can be substantial, especially when high-resolution sensors are deployed at a large scale (Bastidas Pacheco et al., 2022). This necessitates the use of efficient data storage, processing, and transmission technologies to handle the data load (Farooq et al., 2019). The frequency of data collection is another important consideration, as it directly impacts the temporal resolution of the data and the ability to detect rapid changes in plant water status or environmental conditions (Bastidas Pacheco et al., 2022). Bastidas Pacheco et al. (2022) demonstrated that collecting full pulse resolution data from water meters provides more accurate estimates of event occurrence, timing, and features compared to aggregated temporal resolutions, highlighting the importance of selecting appropriate data collection frequencies to ensure the quality and usefulness of the data for irrigation management.
The format of the data is also crucial, as it determines the compatibility and interoperability of the data with various analysis tools and platforms (Farooq et al., 2019). Standardized data formats, such as JSON, XML, or CSV, can facilitate data exchange and integration between different components of the automated irrigation system (Zhang et al., 2023). The source of the data is another important consideration, as it can impact the reliability, accuracy, and spatial coverage of the data (Farooq et al., 2019). For example, in-field sensors provide highly localized measurements, while remote sensing platforms, such as satellites or drones, can provide data at larger spatial scales (Li et al., 2019). By combining data from multiple sources, automated irrigation systems can achieve a more comprehensive understanding of crop water requirements and optimize irrigation management accordingly (Farooq et al., 2019).
Data quality, accuracy, and reliability are paramount in irrigation management, as they directly impact the effectiveness of decision-making processes and the efficiency of water use (Gupta et al., 2020). Inaccurate or unreliable data can lead to suboptimal irrigation decisions, resulting in crop stress, yield losses, or wasted water resources (Ramli & Jabbar, 2022). Gupta et al. (2020) emphasized the critical importance of data security and privacy in smart farming systems, as the leakage of sensitive agricultural data can cause severe economic losses to farmers and compromise the integrity of the automated irrigation system. The authors also highlighted the need for robust authentication and secure communication protocols to prevent unauthorized access to smart farming systems and protect data in transit (Gupta et al., 2020).
Ramli and Jabbar (2022) addressed the challenges associated with implementing real-time, automated irrigation systems, including data quality, scalability, reliability, and security. They proposed solutions and best practices based on the analysis of case studies and real-world implementations, such as the use of redundant sensors, data validation techniques, and secure communication protocols (Ramli & Jabbar, 2022). The authors also emphasized the importance of regular maintenance and calibration of sensors to ensure the accuracy and reliability of the collected data (Ramli & Jabbar, 2022).
Researchers have investigated the use of data compression, aggregation, and filtering techniques to reduce bandwidth requirements and improve transmission efficiency in automated irrigation systems (Karim et al., 2023; Rady et al., 2020; Cui, 2023). Karim et al. (2023) explored the effectiveness of various data compression techniques, such as lossless and lossy compression algorithms, in reducing the size of data packets transmitted over wireless networks. The authors found that lossless compression techniques, such as Huffman coding and Lempel-Ziv-Welch (LZW), can significantly reduce data size without compromising data quality, while lossy compression techniques, such as JPEG and MP3, can further reduce data size by introducing acceptable levels of distortion (Karim et al., 2023).
Rady et al. (2020) developed a novel data compression algorithm specifically designed for irrigation data, which achieved significant compression ratios without compromising data quality. The authors demonstrated that their algorithm could reduce the amount of data transmitted over wireless networks, thereby improving the efficiency of the irrigation system and reducing costs (Rady et al., 2020). Cui (2023) investigated the use of data aggregation and filtering techniques to reduce the number of transmissions and save bandwidth in automated irrigation systems. The author proposed a data aggregation scheme that combines multiple sensor readings into a single value, such as the average soil moisture over a specified time interval, to reduce the frequency of data transmissions (Cui, 2023). Additionally, the author explored the use of data filtering techniques, such as Kalman filters and particle filters, to remove noise and outliers from sensor data, improving the accuracy and reliability of the transmitted information (Cui, 2023).
Data standardization and harmonization are crucial for facilitating seamless integration and interoperability between the various components of automated irrigation management systems (Zhang et al., 2023; Ermoliev et al., 2022). Zhang et al. (2023) developed a novel cyberinformatics technology called iCrop, which enables the in-season monitoring of crop-specific land cover across the contiguous United States. The authors highlighted the importance of data standardization and harmonization in the context of iCrop, as it allows for the efficient distribution of crop-specific land cover information based on the findable, accessible, interoperable, and reusable (FAIR) data principle (Zhang et al., 2023). By adopting standardized data formats and protocols, such as the Open Geospatial Consortium (OGC) standards, iCrop enables the seamless integration of various data sources and facilitates the interoperability of the system with other agricultural decision support tools (Zhang et al., 2023).
Ermoliev et al. (2022) proposed a linkage methodology for linking distributed sectoral/regional optimization models in a situation where private information is not available or cannot be shared by modeling teams. The authors emphasized the need for data standardization to enable decentralized cross-sectoral coordination and analysis, as it allows for the consistent representation and exchange of data between different models and stakeholders (Ermoliev et al., 2022). By adopting standardized data formats and interfaces, the proposed linkage methodology can facilitate the integration of various optimization models and support the development of comprehensive decision support systems for sustainable resource management (Ermoliev et al., 2022).
Metadata plays a vital role in providing context and enabling better data interpretation and decision-making in automated irrigation management systems (Jahanddideh-Tehrani et al., 2021). Metadata refers to the additional information that describes the characteristics, quality, and context of the primary data, such as the sensor type, calibration parameters, measurement units, and timestamp (Jahanddideh-Tehrani et al., 2021). Jahanddideh-Tehrani et al. (2021) highlighted the importance of metadata in water resources management, as it enables decision-makers to use the data to the best of its capabilities by understanding factors such as when water data was collected and what factors might have contributed to the measurements. The authors emphasized the need for standardized metadata formats and guidelines, such as the Dublin Core Metadata Initiative (DCMI) and the ISO 19115 standard, to ensure the consistency and interoperability of metadata across different water information systems (Jahanddideh-Tehrani et al., 2021).
In the context of automated irrigation management systems, metadata can provide valuable information about the data collection process, sensor performance, and environmental conditions that can aid in data interpretation and decision-making (Cota & Mamede, 2023). For example, metadata about the sensor type and calibration parameters can help assess the accuracy and reliability of the collected data, while metadata about the weather conditions and soil properties can provide context for interpreting the data and adjusting irrigation strategies accordingly (Cota & Mamede, 2023). By incorporating metadata into the data management and analysis pipeline of automated irrigation systems, decision-makers can make more informed and context-aware decisions, leading to improved water use efficiency and crop productivity (Jahanddideh-Tehrani et al., 2021).

3.2. Edge Computing and Fog Computing
Edge computing and fog computing have emerged as transformative technologies in the realm of real-time irrigation management systems, offering significant potential for improving efficiency, scalability, and reliability (Abdel Nasser et al., 2020; Tran et al., 2019). Edge computing refers to the practice of processing data near the edge of the network, close to the source of the data, while fog computing is a decentralized computing infrastructure that extends cloud computing capabilities to the network edge (Hassija et al., 2019). These technologies bring computation and analytics closer to the data source, reducing the need for data to travel to the cloud and enabling faster processing and decision-making (Hassija et al., 2019; Zhang et al., 2020).
The potential of edge computing and fog computing in real-time irrigation management is immense. Abdel Nasser et al. (2020) proposed a two-layer system for water demand prediction using automated meters and machine learning techniques, demonstrating the potential of edge computing in improving the efficiency and scalability of irrigation management. The system collects and aggregates data from distributed smart meters in the first layer, while the second layer uses LSTM neural networks to predict water demand for different regions of households. By leveraging edge computing, the system can achieve high accuracy in predicting water demand, which is essential for efficient irrigation management (Abdel Nasser et al., 2020).
Tran et al. (2019) conducted a comprehensive review of real-time, end-to-end automated irrigation management systems, highlighting the role of fog computing in addressing data transmission challenges and enabling seamless integration across the irrigation management pipeline. The authors emphasize that real-time, end-to-end automated irrigation management systems have the potential to significantly improve water efficiency, crop yields, and reduce labor costs. However, they also identify several challenges that need to be addressed, such as data quality, scalability, reliability, and security, which can be effectively tackled by implementing fog computing architectures (Tran et al., 2019).
Edge computing offers several benefits in real-time irrigation management systems, including reduced latency, real-time decision-making, and reduced reliance on cloud connectivity (Mishra, 2020; Zhang et al., 2020). By processing data closer to the source, edge computing enables faster response times and more efficient data handling (Mishra, 2020). Mishra (2020) highlights that edge computing reduces latency by processing data closer to the source, enabling real-time decision-making and lessening reliance on cloud connectivity by shifting processing to local or edge devices.
Zhang et al. (2020) explore the application of edge computing in agricultural settings, demonstrating its potential to improve the efficiency and accuracy of irrigation systems. The authors discuss how edge computing has prospects in various agricultural applications, such as pest identification, safety traceability of agricultural products, unmanned agricultural machinery, agricultural technology promotion, and intelligent management. They also emphasize that the emergence of edge computing models, such as fog computing, cloudlet, and mobile edge computing, has transformed the management and operation of farms (Zhang et al., 2020).
Fog computing plays a crucial role in distributing processing and storage across the network, enhancing the scalability and reliability of automated irrigation systems (Premkumar & Sigappi, 2022; Singh et al., 2022). Premkumar and Sigappi (2022) evaluate the current state of automated irrigation management systems and propose a hybrid machine learning approach for predicting soil moisture and managing irrigation. Their study emphasizes the potential of fog computing in distributing processing and storage across the network, improving the efficiency and scalability of irrigation systems. The proposed hybrid machine learning approach outperforms other machine learning algorithms in predicting soil moisture, demonstrating the effectiveness of fog computing in enhancing the performance of automated irrigation systems (Premkumar & Sigappi, 2022).
Singh et al. (2022) discuss the role of fog computing in distributing processing and storage across the network, enhancing scalability and reliability in agricultural management systems. The authors argue that by implementing fog computing, these systems can achieve faster data processing and response times, improving overall efficiency and effectiveness. They also highlight that fog computing can address the challenges faced by real-time data transmission in agricultural management systems, such as latency, bandwidth limitations, and data security (Singh et al., 2022).
The integration of edge and fog computing in real-time irrigation management systems is crucial for achieving fully automated, scalable, and reliable solutions. As the demand for autonomous irrigation management grows, these technologies will play a pivotal role in enabling faster decision-making, reduced latency, improved resource utilization, and seamless integration across the irrigation management pipeline (Tran et al., 2019; Zhang et al., 2020). By bringing computation and analytics closer to the data source and distributing processing and storage across the network, edge and fog computing can significantly enhance the efficiency and effectiveness of automated irrigation systems, contributing to the overall goal of addressing the global food challenge through optimized water resource management and increased agricultural productivity (Abdel Nasser et al., 2020; Premkumar & Sigappi, 2022; Singh et al., 2022).

3.3. Automation of Data Collection
The automation of data collection is a critical component in the development of real-time, end-to-end automated irrigation management systems that integrate IoT and machine learning technologies. It enables the efficient gathering of vital information about crop health, environmental conditions, and water requirements, which is essential for enhancing agricultural water use efficiency and crop productivity. Two key aspects of automated data collection are the use of advanced sensing technologies for non-invasive plant stress detection and the implementation of wireless sensor networks and energy-efficient communication protocols for large-scale, long-term data collection.
Advanced sensing technologies, such as hyperspectral imaging and thermal sensing, have emerged as powerful tools for non-invasive plant stress detection in automated irrigation management systems. These technologies provide valuable information about crop traits, enabling early and accurate detection of plant health issues (Triantafyllou et al., 2019). Triantafyllou et al. (2019) propose a comprehensive reference architecture model that incorporates advanced sensing technologies in the sensor layer for real-time plant stress detection, highlighting their importance in providing non-invasive plant stress detection. Similarly, Hossain et al. (2023) present a novel IoT-ML-Blockchain integrated framework for smart agricultural management that leverages advanced sensing technologies to optimize water use and improve crop yield, contributing to the overall goal of enhancing agricultural water use efficiency and crop productivity.
Hyperspectral imaging can capture subtle changes in plant physiology that are indicative of stress, while machine learning algorithms can be employed to extract meaningful patterns from the spectral data and classify different stress types (Araus et al., 2014). Thermal sensing can detect changes in canopy temperature, which is influenced by factors such as plant water status (Li et al., 2019). By monitoring canopy temperature and comparing it to reference values, automated irrigation systems can detect plant water stress and trigger irrigation events to maintain optimal plant health and productivity (Li et al., 2019).
The integration of advanced sensing technologies in automated irrigation management systems has the potential to revolutionize precision agriculture. Jiang et al. (2019) demonstrate the effectiveness of a deep learning-based model in accurately detecting leaf spot diseases, highlighting the importance of image augmentation and deep learning algorithms in enhancing the model's performance.
Wireless sensor networks (WSNs) and energy-efficient communication protocols have the potential to significantly improve the efficiency and reliability of data collection in large-scale, long-term irrigation systems. WSNs offer a cost-effective and scalable solution for real-time data collection in large-scale irrigation systems, providing remote monitoring and automated control capabilities (Mehdizadeh et al., 2020). Nishiura and Yamamoto (2021) propose a novel sensor network system that utilizes drones and wireless power transfer to autonomously collect environmental data from sensor nodes in vast agricultural fields, reducing operational costs and enhancing the efficiency of data collection. Similarly, Higashiura and Yamamoto (2021) introduce a network system that employs UAVs and LoRa communication to efficiently collect environmental data from sensor nodes distributed across large farmlands, optimizing data collection and reducing travel distance and time.
Energy-efficient communication protocols are crucial for ensuring reliable data transmission in challenging environmental conditions and extending the lifespan of sensor nodes (Mehdizadeh et al., 2020). Al-Ali et al. (2023) investigate the potential of WSNs and energy-efficient communication protocols for data collection in large-scale, long-term irrigation systems, discussing the challenges and opportunities of using these technologies to improve the efficiency and reliability of real-time data collection in irrigation management. Mehdizadeh et al. (2020) emphasize the need for careful consideration of factors such as data accuracy, energy consumption, and network reliability when designing effective WSNs for irrigation management, enabling timely irrigation decisions and improved crop yields.
The automation of data collection through the use of advanced sensing technologies and wireless sensor networks is essential for achieving fully autonomous, scalable irrigation management. By enabling non-invasive plant stress detection and large-scale, long-term data collection, these technologies contribute to the overall goal of optimizing water resource management and increasing agricultural productivity. The integration of these technologies in real-time, end-to-end automated irrigation management systems has the potential to enhance agricultural water use efficiency and crop productivity, ultimately contributing to the development of fully autonomous, scalable irrigation management solutions.

3.4: Real-Time Data Transmission Protocols and Technologies
Real-time data transmission is a critical component of automated irrigation management systems, as it enables the timely delivery of sensor data to the cloud for processing and decision-making. The exploration of suitable protocols and network architectures is essential for ensuring efficient and reliable data transmission in these systems, contributing to the overall goal of enhancing agricultural water use efficiency and crop productivity.
The Message Queuing Telemetry Transport (MQTT) protocol has emerged as a popular choice for real-time data transmission in IoT networks, including those used for automated irrigation management. MQTT is a lightweight, publish-subscribe protocol designed for constrained devices and low-bandwidth networks (Author, 2019). Its simplicity and low overhead make it well-suited for IoT applications where data transmission speed and energy efficiency are critical (Saranyadevi et al., 2022). MQTT provides three Quality of Service (QoS) levels, ensuring data reliability in real-time scenarios (Author, 2019). Chen et al. (2020) proposed novel algorithms to improve data exchange efficiency and handle rerouting in MQTT-based IoT networks for automated irrigation management systems. Their TBRouting algorithm efficiently finds the shortest paths for data transmission, while the Rerouting algorithm effectively handles the rerouting of topic-based session flows when a broker crashes. The combination of these algorithms can significantly improve the performance and reliability of automated irrigation management systems (Chen et al., 2020).
Client-server IoT networks, such as those based on MQTT, play a crucial role in real-time data transmission for automated irrigation management systems. In these networks, sensors and devices (clients) publish data to a central broker (server), which then distributes the data to subscribed clients (Verma et al., 2021). This architecture enables efficient data collection, processing, and dissemination, facilitating the integration of various components within the automated irrigation management pipeline. Verma et al. (2021) proposed an architecture for healthcare monitoring systems using IoT and communication protocols, which provides a comprehensive overview of existing approaches and highlights challenges and opportunities in the field. Although focused on healthcare, the insights from this study can be applied to automated irrigation management systems, emphasizing the importance of interoperability and standardization for seamless integration (Verma et al., 2021).
In addition to MQTT, other application layer protocols such as XMPP, CoAP, SOAP, and HTTP have been explored for real-time data transmission in IoT networks. Each protocol has its strengths and weaknesses, making them suitable for different applications and scenarios. XMPP (Extensible Messaging and Presence Protocol) is an open-standard protocol that supports real-time messaging, presence, and request-response services (Saint-Andre, 2011). CoAP (Constrained Application Protocol) is a specialized web transfer protocol designed for use with constrained nodes and networks in the Internet of Things (Shelby et al., 2014). SOAP (Simple Object Access Protocol) is a protocol for exchanging structured information in the implementation of web services, while HTTP (Hypertext Transfer Protocol) is the foundation of data communication for the World Wide Web (Fielding et al., 1999).
Motamedi and Villányi (2022) compared and evaluated wireless communication protocols for the implementation of smart irrigation systems in greenhouses, considering factors such as power consumption, range, reliability, and scalability. They found that ZigBee is the most suitable local communication protocol for greenhouse irrigation due to its large number of nodes and long range, while MQTT is the recommended messaging protocol for smart irrigation systems due to its TCP transport protocol and quality of service (QoS) options. GSM is a reliable and cost-effective global communication protocol for greenhouse irrigation, providing wide coverage and low cost (Motamedi & Villányi, 2022).
Syafarinda et al. (2018) investigated the use of the MQTT protocol in a precision agriculture system using a Wireless Sensor Network (WSN). They found that MQTT is suitable for use in IoT applications due to its lightweight, simple, and low bandwidth requirements. The average data transmission speed using the MQTT protocol was approximately 1 second, demonstrating its effectiveness for real-time data transmission in precision agriculture systems (Syafarinda et al., 2018).
The choice of application layer protocol for real-time irrigation management depends on factors such as data transmission speed, reliability, and energy efficiency. MQTT and RTPS (Real-Time Publish-Subscribe) are both suitable for real-time data transmission in IoT systems, but they have different strengths and weaknesses. MQTT is a better choice for applications that require low latency and high throughput, while RTPS is a better choice for applications that require high reliability and low latency (Sanchez-Iborra & Skarmeta, 2021). The exploration of MQTT and client-server IoT networks, along with the comparison of various application layer protocols, provides valuable insights into the suitability of these technologies for real-time data transmission in automated irrigation management systems.
In summary, real-time data transmission protocols and technologies play a vital role in the automation of irrigation management systems, enabling the efficient and reliable delivery of sensor data to the cloud for processing and decision-making. The exploration of MQTT and client-server IoT networks, along with the comparison of application layer protocols, highlights the importance of selecting suitable technologies based on factors such as data transmission speed, reliability, and energy efficiency. By leveraging these technologies, automated irrigation management systems can achieve seamless integration and contribute to the overall goal of enhancing agricultural water use efficiency and crop productivity.

3.5. Challenges and Solutions in Real-Time Data Transmission
Following the exploration of data collection, processing at the edge and fog, and automation in previous sections, we now turn to the critical aspect of real-time data transmission. While essential for automated irrigation management, this stage presents unique challenges that must be addressed to ensure system efficiency and reliability.
Obstacles in Real-Time Data Transmission
Agricultural environments present unique challenges for real-time data transmission, directly impacting the effectiveness of automated irrigation systems. Environmental factors can significantly disrupt wireless communication. Adverse weather conditions such as heavy rain, fog, and high winds can weaken or even block radio signals, leading to data loss and compromised system performance. Physical obstacles like trees, buildings, and uneven terrain further complicate signal propagation, creating reliability issues (Jukan et al., 2017; Yi & Ji, 2014; Zhang, Chang & Baoguo, 2018). These environmental challenges necessitate robust communication protocols and network architectures that can ensure consistent and reliable data flow.
In addition to environmental factors, technical limitations also present significant obstacles. Large-scale agricultural operations often demand long-distance data transmission, which can be hindered by the limited range of certain wireless communication protocols. Network congestion, occurring when multiple sensors transmit data concurrently, can lead to delays and potential data loss, further complicating real-time decision-making (Hameed et al., 2020). To mitigate these issues, researchers have investigated the potential of cognitive radio networks (CRNs) and dynamic spectrum access (DSA) for optimizing spectrum utilization and reducing interference (Righi et al., 2017; Shafi et al., 2018; Trigka & Dritsas, 2022). CRNs enable devices to intelligently sense and adapt to the surrounding radio environment, dynamically adjusting transmission parameters to avoid interference and improve communication efficiency. DSA, on the other hand, facilitates the dynamic allocation of unused spectrum, enhancing spectrum utilization and reducing congestion.
Furthermore, data security and privacy are paramount concerns in real-time irrigation systems. The sensitive nature of agricultural data, such as crop yields and farm management practices, necessitates robust security measures to prevent unauthorized access and data breaches (Gupta et al., 2020). Implementing secure communication protocols, authentication mechanisms, and encryption techniques is essential to protect data integrity and ensure the trustworthiness of the system.
Investigating Data Optimization Techniques
To enhance the efficiency and reliability of real-time data transmission in automated irrigation systems, researchers have explored a range of data optimization techniques. Data compression techniques aim to reduce the size of data packets transmitted over the network, minimizing bandwidth requirements and improving transmission speed (Rady et al., 2020; Karim et al., 2023). Lossless compression algorithms, such as Huffman coding and LZW, preserve data integrity while effectively reducing data size, ensuring that no information is lost during transmission (Cui, 2023). Lossy compression algorithms, such as JPEG and MP3, offer higher compression ratios but introduce a controlled level of data loss, which may be acceptable for certain applications where some loss of precision is tolerable (Karim et al., 2023). The choice between lossless and lossy compression depends on the specific application and the trade-off between data size and accuracy.
Data aggregation techniques provide another effective approach to optimize data transmission. By aggregating multiple sensor readings into a single representative value, such as average soil moisture or temperature, the number of transmissions can be significantly reduced, conserving bandwidth and energy resources (Cui, 2023). This is particularly beneficial in large-scale irrigation systems where numerous sensors are deployed across vast areas, generating substantial amounts of data. Additionally, data filtering techniques play a crucial role in improving data quality and reliability. Kalman filters and particle filters can effectively remove noise and outliers from sensor data, ensuring that only accurate and relevant information is transmitted and used for decision-making (Cui, 2023). This is essential for preventing erroneous data from influencing irrigation decisions and potentially leading to suboptimal water management.
Sensor calibration, drift correction, and fault detection are essential for maintaining data accuracy and reliability (Dos Santos et al., 2023). Regular calibration ensures that sensors provide accurate measurements over time, while drift correction techniques account for gradual changes in sensor readings due to environmental factors or aging. Fault detection mechanisms can identify and address sensor malfunctions or anomalies, preventing erroneous data from influencing irrigation decisions and potentially harming crops or wasting water.
Addressing the Challenges
Effectively addressing the challenges in real-time data transmission requires a multifaceted approach that encompasses environmental, technical, and data-related considerations. Implementing robust and adaptive communication protocols is crucial for overcoming interference and signal degradation caused by weather conditions and physical obstacles. Selecting appropriate protocols, such as LoRa or ZigBee, with suitable range and penetration capabilities can ensure reliable data transmission in challenging agricultural environments (Motamedi & Villányi, 2022). Additionally, employing techniques like frequency hopping and error correction codes can further improve communication resilience and mitigate data loss.
Optimizing network architecture is another key consideration. Deploying a distributed network architecture with edge and fog computing capabilities can significantly enhance data processing and transmission efficiency (Abdel Nasser et al., 2020; Tran et al., 2019). Edge devices can perform initial data processing and aggregation tasks, reducing the amount of data transmitted to the cloud and minimizing latency, while fog nodes can provide additional processing power and storage closer to the data source, enhancing scalability and reliability. This distributed approach alleviates the burden on the central cloud server and allows for more responsive and efficient irrigation management.
Data optimization techniques play a vital role in reducing bandwidth requirements and improving transmission efficiency. The choice of data compression, aggregation, and filtering techniques should be tailored to the specific requirements of the irrigation system, considering factors such as data type, accuracy needs, and available bandwidth. By carefully selecting and implementing these techniques, the overall performance and effectiveness of real-time irrigation systems can be significantly enhanced, leading to more sustainable water management practices and improved agricultural productivity.
By addressing these challenges and implementing appropriate solutions, real-time data transmission can become a reliable and efficient component of automated irrigation systems, contributing to the overall goal of achieving sustainable and productive agriculture in the face of growing food demands and water scarcity.
n summary, real-time data transmission protocols and technologies play a vital role in the automation of irrigation management systems, enabling the efficient and reliable delivery of sensor data to the cloud for processing and decision-making. The exploration of MQTT and client-server IoT networks, along with the comparison of application layer protocols, highlights the importance of selecting suitable technologies based on factors such as data transmission speed, reliability, and energy efficiency. By leveraging these technologies, automated irrigation management systems can achieve seamless integration and contribute to the overall goal of enhancing agricultural water use efficiency and crop productivity.


</previous_sections>

</documents>
<instructions>


Use the information provided in the <documents> tags to write the next subsection of the research paper, following these steps:
1. Review the overall intention of the research paper, specified in the <review_intention> tag. Ensure the subsection you write aligns with and contributes to this overall goal.
2. Consider the specific intention for this subsection of the paper, stated in the <section_intention> tag. The content you write should fulfill this purpose. 
3. Use the title provided in the <subsection_title> tag as the heading for the subsection. 
4. Address each of the points specified in the </subsection_point_Point *> tags:
   a) Make a clear case for each point using the text provided in the "point" field.
   b) Support each point with evidence from the research papers listed in the corresponding "papers to support point" field.
   c) When citing a paper to support a point, include inline citations with the author name(s) and year, e.g. (Smith et al., 2020; Johnson and Lee, 2019; Brown, 2018). Cite all papers that strengthen or relate to the point being made.
   d) While making a point and citing the supporting papers, provide a brief explanation in your own words of how the cited papers support the point.
5. Ensure that both of the points from the <subsection_point> tags are fully addressed and supported by citations. Do not skip or combine any points.
6. After addressing the specified points, wrap up the subsection with a concluding sentence or two that ties the points together and relates them back to the <section_intention>.
7. Review the <Previous_sections> of the paper, and ensure that the new subsection you have written fits logically and coherently with the existing content. Add transition sentences as needed to improve the flow.
8. Proofread the subsection to ensure it is clear, concise, and free of grammatical and spelling errors. Maintain a formal academic tone and style consistent with the rest of the research paper.
9. Format the subsection using Markdown, including the subsection heading (using ## or the equivalent for the document), inline citations, and any other formatting needed for clarity and readability.
10. If any information is missing or unclear in the provided tags, simply do your best to write the subsection based on the available information. Do not add any information or make any points not supported by the provided content. Prioritize fully addressing the required points over hitting a specific word count.

The output should be a complete, well-organized, and properly cited subsection ready to be added to the research paper.

Begin your answer with a brief recap of the instructions stating what you will to optimize the quality of the answer. Clearly and briefly state the subsection you'll be working on and the points you'll be addressing. Then proceed to write the subsection following the instructions provided. 

Critical: 
- Do not include a conclusion or summary as the entry is in the middle of the document. Focus on addressing the points and supporting them with evidence from the provided papers. Ensure that the subsection is well-structured, coherent, and effectively contributes to the overall research paper.
- The subsection we are focusing on is: 3.6. IoT Network Architectures and Variable Rate Irrigation (VRI) for Real-Time Irrigation
- No need for sub-sub-sections. just provide paragraphs addressing each point. They should transition fluidly and narurally into each other.
- Ensure that the content is supported by the provided papers and that the citations are correctly formatted and placed within the text.
- Do not repeat content from the previous sections. Ensure that the information provided is new and relevant to the subsection being written.



</instructions>

<subsection_point_Point 1>
Point: Obstacles in transmitting data in real-time

Papers to support point:

Paper 1:
- APA Citation: 
  Main Objective: 
  Study Location: 
  Data Sources: 
  Technologies Used: 
  Key Findings: 
  Extract 1: 
  Extract 2: 
  Limitations: >
  Relevance Evaluation: This explanation conveys the main objective and research question of the study: to examine the automation of each component of the irrigation management pipeline, from data collection to decision-making, and to investigate the effectiveness and efficiency of integrated end-to-end automated irrigation systems.
  Relevance Score: 1.0
  Inline Citation: >
  Explanation: From your close reading of the paper, provide a concise explanation of the study's purpose and main objectives, using a maximum of 3 sentences.

 Full Text: >
Skip to main content Skip to article Journals & Books Search Register Sign in Brought to you by: University of Nebraska-Lincoln View PDF Download full issue Outline Highlights Abstract Keywords 1. Introduction 2. Background literature review 3. Multiple perspectives from invited contributors 4. A brief overview of full opinion articles related to this theme 5. Discussion and recommendations 6. Conclusions References Show full outline Cited by (254) Figures (7) Show 1 more figure Tables (4) Table 1 Table 2 Table 3 Table 4 International Journal of Information Management Volume 63, April 2022, 102456 Opinion paper Climate change and COP26: Are digital technologies and information management part of the problem or the solution? An editorial reflection and call to action☆ Author links open overlay panel Yogesh K. Dwivedi a b, Laurie Hughes c, Arpan Kumar Kar d e, Abdullah M. Baabdullah f, Purva Grover g, Roba Abbas h, Daniela Andreini i, Iyad Abumoghli j, Yves Barlette k, Deborah Bunker l, Leona Chandra Kruse m, Ioanna Constantiou n, Robert M. Davison o, Rahul De’ p, Rameshwar Dubey q, Henry Fenby-Taylor r, Babita Gupta s, Wu He t, Mitsuru Kodama u, Matti Mäntymäki v…Michael Wade ao Show more Add to Mendeley Share Cite https://doi.org/10.1016/j.ijinfomgt.2021.102456 Get rights and content Under a Creative Commons license open access Highlights • Technology is an integral component of many of the proposed mitigation measures. • There exists an urgent need for education on e-waste impact on the environment. • Greater focus is needed on responsible digitalization to engender sustained change. • Alignment of smart initiatives to SDGs is an underdeveloped research area. • Greater awareness is needed on lived in realities of environmental tradeoffs. Abstract The UN COP26 2021 conference on climate change offers the chance for world leaders to take action and make urgent and meaningful commitments to reducing emissions and limit global temperatures to 1.5 °C above pre-industrial levels by 2050. Whilst the political aspects and subsequent ramifications of these fundamental and critical decisions cannot be underestimated, there exists a technical perspective where digital and IS technology has a role to play in the monitoring of potential solutions, but also an integral element of climate change solutions. We explore these aspects in this editorial article, offering a comprehensive opinion based insight to a multitude of diverse viewpoints that look at the many challenges through a technology lens. It is widely recognized that technology in all its forms, is an important and integral element of the solution, but industry and wider society also view technology as being part of the problem. Increasingly, researchers are referencing the importance of responsible digitalization to eliminate the significant levels of e-waste. The reality is that technology is an integral component of the global efforts to get to net zero, however, its adoption requires pragmatic tradeoffs as we transition from current behaviors to a more climate friendly society. Previous article in issue Next article in issue Keywords Climate changeCOP26Digital worldInformation managementInformation systemsInformation technologySustainabilitySustainable Development Goals (SDGs) 1. Introduction The 2021 United Nations (UN) Climate Change Conference (COP26) held in Glasgow UK, brings together many of the worlds’ leaders to address the critical aspects of global warming. The conference aims to gain commitment for sustained progress towards the Paris Agreement and UN framework convention on climate change, by limiting increased global temperatures to 1.5 °C above pre-industrial levels (COP26, 2021). The Intergovernmental Panel on Climate Change (IPCC) identified in its 2018 report that global emissions would need to be at net zero by at least 2050 to retain a “high confidence” level of limiting temperature increases to sustainable levels (Masson-Delmotte et al., 2018). In her speech at the conference, US Treasury Secretary Janet Yellen stated that - “rising to this challenge will require the wholesale transformation of our carbon-intensive economies," and that "addressing climate change is the greatest economic opportunity of our time." (COP26, 2021). The transition toward net zero requires significant changes at a societal and industrial level and governments, as well as corporations, are increasingly turning to technological innovations to meet net zero emission targets (Miller, 2020). Digital technologies offer the potential to deliver sustained solutions to many of the seemingly intractable societal challenges relating to climate change (George, Merrill, & Schillebeeckx, 2021). The World Economic Forum (WEF) in its - Harnessing Technology for the Global Goals report, jointly authored with PwC, identifies the significant role that digital technology can play in improving resilience to global warming related, natural hazards, reducing emissions and enhancing the ability for humans to take the necessary steps to realize net zero. The WEF report identifies how digital technologies can help to automate and significantly improve the efficiency of industrial, manufacturing and agricultural processes and that Artificial Intelligence (AI) based systems could contribute to a reduction of 4% in global emissions by 2030 (World Economic Forum & PwC, 2021). Although advancements in technologies are closely associated with offering solutions to global warming, the digital discourse also highlights the negative impacts of the widespread use of technology in the context of waste products, resource usage and CO2 emissions. The widely reported impact of vast bitcoin mining farms in various parts of the world and their appetite for significant energy consumption - 121.36 terawatts hours per year (CBECI, 2021) – illustrates the dichotomy of rapid technological advancement and potential barriers to net zero by 2050 (Mora et al., 2018). The debates surrounding the convergence of the digital and net zero imperatives are beginning to gain traction within the academic literature, where studies have started to focus on the role of digital technologies through a positive contribution lens, but also a reflective perspective, recognizing some of the negative aspects of the rapid adoption of technology (George et al., 2021, Merrill et al., 2019). What is clear is that, whilst the emerging diverse and disparate discourse has offered insight to many of the significant challenges and barriers to net zero from the digital perspective (George et al., 2016, Luo et al., 2016), there exists a limited contribution from a wider and more informed multiple perspective context. This study contributes to the digital technology and climate change discourse, via the individual discussions on a multitude of interrelated sub-topics. Each invited expert has offered their own unique insight to the myriad of complexities and dependencies to attaining net zero by 2050. The remaining sections of this article are organized as follows. Section 2 presents a brief review of existing literature in this space. Section 3 presents the experts’ perspectives related to core themes surrounding information management (IM)/information technology (IT)/information systems (IS) and climate change. Section 4 - presents an overview of the key perspectives from the submitted full opinion articles. The main discussion section is presented in Section 5, where we assess the significant challenges and key contributions from the invited expert submissions. Section 6 concludes the paper by discussing implications for both research and practice. 2. Background literature review The primary database used for the literature search was Scopus. Keywords such as “information systems” or “information technology” or “IT sector” were combined (AND operator) with keywords “environment”, “sustainability”, “sustainable” and “climate”. The search taxonomy retrieved articles that had the combination of keywords in the article title, author keywords, or abstract. Via a process of filtering to eliminate non-relevant studies, a total of 372 articles remained. These articles were evaluated via their abstract to assess their suitability against the following two research questions. • RQ1: Does the digital technology and IS/IT sector have a negative impact on the environment and how can it be reduced? • RQ2: How can digital technology and IS/IT be utilized to mitigate the causes and impact of climate change? After a further process of scanning of the title and abstract for the relevance of the article to the research questions, 88 articles remained. Additionally, ScienceDirect and Web of Science were also used, following similar approaches which resulted in 16 additional articles. 2.1. (RQ1) Does the digital technology and IS/IT sector have a negative impact on the environment and how can it be reduced? Despite the contribution of the IS/IT industry toward the economic and social welfare of society, IS/IT has often been criticized for having a negative environmental impact. Concerns surrounding the adverse effects both hardware and software have on the environment date back to the Y2K era which led to the massive adoption of enterprise systems (Miyamoto, Harada, & Fujimoto, 2001). These negative impacts include high levels of energy consumption, greenhouse gas emissions and toxic disposal of IS/IT systems (Muregesan, 2008). The disposal of electronic waste (e-waste) while following recycling processes has been widely viewed as not being environmentally friendly, especially the impact of fossil fuels or respiratory inorganics (Barba-Gutiérrez, Adenso-Diaz, & Hopp, 2008). Refurbished ICTs are often used in developing countries where devices tend to have a short life-span and subsequently create environmental damage during disposal (Osibanjo & Nnorom, 2007). Studies have argued that electricity is a major cause of climate change, as many power stations throughout the world still rely on fossil fuels to generate electricity (Asongu et al., 2020, Tamburini et al., 2015). Energy hungry technologies such as applications of blockchain in the form of bitcoin, has been widely criticized for producing over 22–29 million metric tonnes of carbon dioxide emission each year. These figures are comparable to the carbon dioxide production of entire countries such as Jordan and Sri Lanka (Marr, 2018, Stoll et al., 2019). Technologies such as the Internet of Things (IoT), sensors and actuators have a shorter lifespan which leads to increased waste in the environment (Chakraborty and Gupta, 2016, Chakraborty et al., 2014, Nižetić et al., 2020). Digital transformation initiatives such as smart cities have concerns surrounding ICT waste management, energy management and emission management which needs to be addressed for achieving long term sustainability and viability (Ismagilova, Hughes, Dwivedi, & Raman, 2019). From an IS/IT perspective, IoT and Artificial Intelligence (AI) could potentially offer solutions for reducing the impact of technology projects (Salam, 2020). High ICT-driven initiatives need to plan for sustainability by thinking from the perspective of social welfare and e-waste impact (Kar, Ilavarasan, Gupta, Janssen, & Kothari, 2019). Wireless communication technologies need adaptations so that emissions can be further reduced. AI can operate with such technologies to enhance the usage of bandwidth and energy consumption to significantly reduce the carbon footprint of the telecom sector Ullah et al. (2020). Similarly, AI integrated with blockchain has been found to positively impact water management and climate control (Lin, Petway, Lien, & Settele, 2018). AI can manage and reduce energy consumption within smart cities (Şerban & Lytras, 2020). Studies have identified that blockchain applications can improve sustainable practices in supply chain management and agricultural practices (Kshetri, 2021). Similarly, within nano-technology applications, AI has provided benefits through better precision in agricultural water distribution delivering positive impacts on efficient use of natural resources. The communication of sustainability related messages within social media has greatly increased during the pandemic (Grover et al., 2019, Grover et al., 2021, Yadav et al., 2021). The literature has highlighted that during crisis periods IS research can provide “signposting” for sustainability actions through improved digital monitoring, tackling information flow and paranoia, and orchestrating data ecosystems for improved decision making (Pan & Zhang, 2020). The focus towards renewable energy has increased dramatically. The IRENA (2021) report indicates that jobs in sustainability and cleaner energy are increasing exponentially year on year, especially in solar and wind energy. This shift towards greener energy consumption is common across industries producing and consuming technology products and services. There is evidence that if stakeholders are convinced about energy management, their engagement in Green IS/IT programs will increase (Nyberg, 2018). The literature highlights the use of theories such as: Institutional Theory, Resource Based View, Technology Organization Environment framework, Theory of Planned Behavior and Motivational Theory as the dominant models used in the IS literature (Asadi & Dahlan, 2017). Lesser used theoretical lenses such as: Upper Echelon Theory, Self Determination Theory, Green Theory, Norm Activation Model, Elaboration Likelihood Model, Dynamic Capability Theory, Actor-Network Theory and Expectancy Theory. could be used to explore future research relating to environmental impacts of technology. (Table 1, Table 2). Table 1. Snapshot of adverse impact of ICTs on the environment. SN Select adverse impacts Study 1 Carbon Dioxide emission related challenges increase with the use of ICTs (personal computers) Miyamoto et al. (2001), Muregesan (2008) 2 Toxic disposal after use for old ICTs creates pollution in the land and water environment Barba-Gutiérrez et al. (2008), Osibanjo and Nnorom (2007) 3 Electricity consumption increase by ICTs leads to the release of pollutants into the atmosphere. Asongu et al. (2020), Tamburini et al. (2015) 4 Emerging ICTs requiring high processing power create higher pollution from high energy consumption Howson, (2019), Stoll et al. (2019) 5 ICT components like microelectronics, sensors and actuators often have a short shelf life so land pollution challenges are faced while disposing them Chakraborty and Gupta (2016), Nižetić et al. (2020) 6 Digital initiatives across firms and nations will have challenges towards managing disposal of ICTs, energy management and emission control while focusing towards sustainability Ismagilova (2019), Singh and Sahu (2020) Table 2. Snapshot of positive impact of ICTs on the environment. SN How can organizations using ICTs impact the environment positively? Study 1 Green IT initiatives which involve changes in processed and routines impact adoption of IT in firms Simmonds and Bhattacherjee (2012) 2 IT competency along enables integration of IT in environmental management in Green IT initiatives of firms Wang X. (2015), Wang Y. (2015) 3 Leadership, along with environmental awareness lead to adoption of Green IT initiatives in firms Ojo and Fauzi (2020) 4 Green IT audits enable movement towards ISO/IEC 33000 in terms of maturity models towards improved environment management Patón-Romero, Baldassarre, Toval, Rodríguez, and Piattini (2021) 5 Universities may introduce Green IT in their curriculum for making larger impacts through sensitization of future employees towards Green IT initiatives Marques, Bachega, and Tavares (2019) 6 Blockchain based smart contracts may enable trading in carbon credits and emission awareness across firms operating in a network Howson (2019) 7 Blockchain may reduce energy consumption in IoT networks to enable greener IoT ecosystems Sharma, Kumar, and Park (2020) 8 Collaboration ICTs and video conferencing systems reduce travel and indirectly save environmental pollution from vehicular emissions Galanti, Guidetti, Mazzei, Zappalà, and Toscano (2021), Richter (2020) 9 Deep learning and big data analytics can be used for water and air quality management Kushwaha, Kar, and Dwivedi (2021), Nair, Agrawal, Domnic, and Kumar (2021) 10 Influencers like CEOs and national heads can enable information sharing and subsequent adoption of sustainable initiatives among social media followers Grover et al. (2019), Grover et al. (2021), Nyberg (2018), Yadav et al. (2021) 11 AI will improve environmental governance, safety and environmental risk reduction while focusing on information management for decision making Nishant, Kennedy, and Corbett (2020) 12 Review of Green IS focuses on themes like energy-efficient computing, power management, data center design layout and location management, server virtualization, responsible disposal and recycling Singh and Sahu (2020) 2.2. (RQ2) How can digital technology and IS/IT be utilized to mitigate the causes and impact of climate change? As early as 2008, Murugesan (2008) provided directions towards a greener IS/IT strategy. A holistic focus towards Greener IT entails reducing the energy consumption of computational devices. It also gives directions on reuse, refurbish and recycling of IS/IT products. Such a focus requires an organizational imperative as indicated by Butler (2011), whereby the study draws on institutional theory to explain the multitude of forces acting on organizations from the institutional, environment and organizational fields for environmental sustainability. Reduction of carbon based energy consumption directly leads to reduction of greenhouse gas emissions. The study by Simmonds and Bhattacherjee (2012) indicates that existing IT infrastructure, alignment of business strategy and relative advantages of green IT initiatives, have an overall positive impact on the adoption of IT initiatives within firms. Recent IT/IS literature indicates that technology can be a solution for better environmental management and sustainability. For example, Wang X. (2015), Wang Y. (2015) highlights that IS/IT competence enables the integration of technology within the environmental management processes to improve performance. The same study demonstrated the positive impact of IT competence on IT-environmental management integration. The research by Jnr (2020) indicates that there is a significant relationship between integrated technologies and Green IS/IT innovation. The study by Ojo and Fauzi (2020) indicates that environmental awareness and leadership commitment positively impacts engagement in Green IS/IT practices. Further Marques et al. (2019) highlight that universities now consider emissions and Green IT principles to reduce the adverse impacts on the climate, while designing their curriculum. Audits in Green IT in enterprises help to enhance focus towards maintaining environmental orientation and better impacts on climate (Patón-Romero et al., 2021). These audits offer a view on the organization's position along the green IT capability maturity model from ISO/IEC 15504 to ISO/IEC 33000. Within workplace infrastructure management, sensors and actuators are often being used for water management and energy consumption in smart buildings (toilet management, ventilation and air quality management) and smart devices (like air conditioners and lighting systems). These technologies have been observed to have brought in wide positive impacts on the climate within the existing literature (Zarindast, Sharma, & Wood, 2021). For example, blockchain applications are not always energy hungry, and often applications in different use cases such as SolarCoin and VerdePay may actually help in reducing carbon footprints (Howson, 2019). Applications of analytical models for information management enables more efficient energy management in smart cities (Gellert, Florea, Fiore, Palmieri, & Zanetti, 2019). Blockchain applications may enable a more efficient IoT ecosystem and thereby reduce energy consumption (Sharma et al., 2020). AI technologies such as deep learning together with big data analytics have been used for image mining for underwater environment management and air quality management (Kushwaha et al., 2021, Nair et al., 2021). Driven by the pandemic, working from home has significantly increased, which has drastically reduced travel to workplaces, thereby reducing the carbon footprint from travel and maintaining office infrastructure. This change toward a work from home culture has been facilitated using video conferencing and collaboration systems enabled through ICTs (Chakraborty and Kar, 2021, Galanti et al., 2021, Richter, 2020). A recent review on AI and its possible impacts towards sustainability argue that AI will play a critical role beyond enabling better consumption of energy, water, and land usage, and it will facilitate environmental governance with greater effectiveness (Nishant et al., 2020). Whilst the literature has exhibited an emerging focus on Green IS and sustainability within the information management literature, there is still tremendous scope for impactful research on many aspects of the use of technology to combat climate change. 3. Multiple perspectives from invited contributors This section, in alignment with the approach set out in previous studies (Dwivedi et al., 2020, Dwivedi et al., 2022, Dwivedi et al., 2021a, Dwivedi et al., 2021b, Dwivedi et al., 2015), develops a set of unique expert contribution narratives that explore many of the key topics related to digital and IS technologies and climate change. This topic has numerous threads and interdependencies as many of the invited experts offer their own perspectives and viewpoints on the topic. The expert contributions are largely presented in an unedited form, as expressed by each of the contributors. The perceived unevenness of the logical flow inherent with this approach is countered by the capturing of the distinctive orientations of the expert perspectives related to the chosen topic (Dwivedi et al., 2020, Dwivedi et al., 2022, Dwivedi et al., 2021a, Dwivedi et al., 2021b, Dwivedi et al., 2015). The list of contributions is provided in Table 3 and extended in further detail within this section. Table 3. Individual contributions. Contribution title Author (s) Section 3.1: Behavior and attitudes Contribution 1: Climate Change and Information Technology Professor Robert M. Davison Contribution 2: Digital platforms in combating climate change: User engagement tools and digital traces of climate footprints Professor Ioanna Constantiou and Professor Morten Thanning Vendelø Contribution 3: Faith and Climate Change Dr Iyad Abumoghli Contribution 4: The Pros and Cons of IM/IT/IS on Climate Change and Future Directions Professor Bhimaraya Metri Contribution 5: The Role of Online Communities in Supporting Digital Activism on Climate Change Professor Niki Panteli Section 3.2: Education, awareness & changed working practices Contribution 6: Climate Change and the Emergent role of IS: An agenda for IS against the background of COP26 Dr Rohit Nishant and Dr Thompson S H Teo Contribution 7: Dematerialization is so material! The contrasting impacts of IT on the environment and climate change Professor Yves Barlette Contribution 8: Emerging Technologies to Mitigate Supply Chain Disruption Due to Climate Change Professor Manoj Kumar Tiwari Contribution 9: Facing the negative environmental digital impact: time to change values? Professor Frantz Rowe Contribution 10: From cradle to grave - impact of IT on climate change and the relevant research agenda Professor Ramakrishnan Raman Contribution 11: How has the IT sector negatively influenced the environment? Remedies, role of IT education and future research agenda Professor Nripendra P. Rana Contribution 12: Technology, Information Systems and Sustainability: A Public Interest Research Agenda Professor Katina Michael and Dr Roba Abbas Section 3.3: Impact on people and communities Contribution 13: Promoting IT Innovation to Improve the Global Environment- Towards Establishment of Global Co-creation & Co-evolution Models Professor Mitsuru Kodama Contribution 14: Smart City Initiatives to Maximize Information Value for Sustainability Professor Brenda Scholtz Contribution 15: Wider Issues in IS Research on Climate Change Professor Rahul De’ Section 3.4: Responsible digitalization Contribution 16: Corporate Digital Responsibility: The Powerful Offspring of Sustainability and Digitization Professor Michael Wade Contribution 17: Digitalization and the Myth of Sustainability: Some Critical Reflections Professor Suprateek Sarker Contribution 18: Systems for sustainable growth Professor Maung Sein and Dr Leona Chandra Kruse Section 3.5: Role of data, technology & IS governance Contribution 19: Climate Change and Role of Information Technologies Professor Babita Gupta Contribution 20: Climate Crisis Response: Dynamic Information Governance for Social Sustainability Professor Deborah Bunker Contribution 21: Climate Change – IT - Data Science perspective Ms Jeel Dharmeshkumar Shah Contribution 22: The IS/IT in addressing the challenges of climate change Dr Matti Mäntymäki Contribution 23: The value of information management in the built environment to tackle climate change Mr Henry Fenby-Taylor Contribution 24: What can Information Technology and Systems Researchers and Educators do to Mitigate Climate Change? Dr Wu He Section 3.6: Technology & IS research agenda Contribution 25: Holistically Missing: Climate change and information systems research Professor Samuli Pekkola Contribution 26: Information Technology and Climate Change Dr Rameshwar Dubey Contribution 27: Blockchain and Climate Change Dr Daniela Andreini Contribution 28: Towards a relevant agenda for climate crisis issues within information research Professor Johan Olaisen 3.1. Behavior and attitudes 3.1.1. Contribution 1 – Climate change and information technology – Professor Robert M. Davison 3.1.1.1. Some issues I think that IM/IT/IS has a profoundly negative impact on the environment in ways that are largely invisible. For instance, the devices that we use, particularly batteries, require the inclusion of rare earth elements, notably tantalum. This is mined from Coltan. Major deposits of coltan are found in DR Congo (Wikipedia, 2021) where open cast mines blight the landscape. In addition, hundreds of small scale independent miners look for their own spoils. The impact on the environment is considerable, and this includes the local wildlife that used to live in the area, notably the Eastern Mountain Gorilla. Militias are often employed to protect the mines and their all-too valuable minerals, but these militias may abuse the local people, wildlife and more (YouTube, 2017). At a more visible level, the devices that we use require huge amounts of electricity, whether for the extraction and refinement process, the manufacturing process or the simple use of the end products. Where does the electricity come from? Well, that depends on where you live. You might be fortunate enough to live in a country that depends to a large extent on renewable energy resources (or at least gives you the option to source your electricity from such sources) – solar, hydro, wind, geothermal or wave for instance. But you might also live, as billions of people do, in a country that relies on coal or oil for energy production. Thus, to operate your devices, you are directly contributing to the coal economy and to further global warming via the CO2 that is emitted when coal is burned. How can the negative effect be reduced? The answer is simple but painful: we need to keep our existing devices in use for much longer than we currently do. We need to avoid the temptation to update our devices as soon as the next version is available. Here devices include: phones, tablets, notebooks, cameras, electric cars and any other device with significant battery use. We can’t eliminate the negative effects but we can reduce them. 3.1.1.2. Research agenda I think that a valid research agenda has to include the concept of sustainability. Tan B. (2021) are currently editing a special issue of the ISJ on IS and Sustainable Development. They note that the 2015 UN Agenda for Sustainable Development includes 17 Sustainable Development Goals (SDGs) with 169 associated targets to be achieved by 2030 (United Nations Department of Economic & Social Affairs, 2015). These goals and targets constitute a research agenda in their own right, though not all are immediately applicable to IM/IS/IT. Meanwhile, Walsham (2012) argues that there is a need to undertake IS research that demonstrates how we can make the world a better place. To provide some other context, however, Clarke and Davison (2020) noted that almost no IS research, at least as published in the Association for Information Systems’ basket of eight journals (EJIS, ISJ, ISR, JAIS, JIT, JMIS, JSIS, MISQ), included the environment as a key stakeholder or treated the environmental perspective as a matter of importance. Thus, the track record in IS is not particularly rosy. We have a long way to go. 3.1.1.3. Education I teach Green IS issues to my MBA students: we identify and discuss issues concerning how green IS really is, including many of the issues raised in this editorial. We look at the topic from a policy perspective and consider what actions organizations can take to ensure that they genuinely adopt a green culture and implement green measures. This is particularly relevant to corporate social responsibility and the triple bottom line (Elkington, 1997). 3.1.2. Contribution 2 – digital platforms in combating climate change: user engagement tools and digital traces of climate footprints – Professor Ioanna Constantiou and Professor Morten Thanning Vendelø In spite of the increasing awareness about the consequences of climate change, many individuals continue to fail in adjusting their behaviors and lifestyles in order to lessen their impact on the climate. While mottos like “think globally, act locally” urges people to consider the health of the entire planet and to take action in their own communities and cities, they do not seem to significantly contribute to combating climate change. Many individuals appear to experience difficulties in understanding how their behavioral patterns and choices affect the climate of the planet, although the most recent UN Climate Report shows that with no changes in greenhouse gas emissions the increase in the global temperatures will rise to 2.7 °C above pre-industrial levels by 2100 (United Nations Environment Programme, 2021). Hence, alternative means of influencing consumer behavior are required. Digital technologies can support individuals in developing connections between their behavioral patterns, and the ongoing changes in the global climate as well as identify and choose alternatives to these behavioral patterns (Schroder, Prockl, & Constantiou, 2021). Digital platforms can support combating climate change by providing marketplaces where transactions can be made in more cost efficient and climate friendly ways, promote sustainable product innovation or inform consumers about their climate footprints. The abundance of data available to digital platforms can be used for activities that promote sustainable options and motivating climate friendly behaviors. For example, applications tracking user physical activity can quantify climate impacts and thereby nudge users to consider more sustainable options of public transportation (e.g., based on CO2 emissions of different means of transportation). Another area of interest is reduction of food waste. A number of digital platforms have recently emerged with related visions. Building on the logic of collaborative consumption and social entrepreneurship (Schroder et al., 2021), digital platforms such as Eat Grim provide a marketplace for selling vegetables and fruits that do not match industry standards based on appearance to consumers. Their aim is to change the consumers’ perceptions of appearance related quality standards of what is edible and nudge their users to eat vegetables and fruits by focusing on other criteria such as freshness, or nutrition value of the vegetables and fruits. By redistributing these products to their consumers from restaurants or other retail shops, they reduce food waste. Another example is the digital platform Too Good To Go that connects customers to restaurants and stores, mainly bakeries, that have unsold food surplus. The surplus food is sold to consumers at discounted prices instead of being wasted. Finally, Plant Jammer is another platform that aims to reduce greenhouse gas emissions and fight climate change through sustainable cooking and plant-based food. Consumers reduce waste in their home by using ingredients that would normally be wasted due to lack of knowledge on how to combine through recipes in their daily meals. These platforms provide multi sided marketplaces (Parker, Van Alstyne, & Choudary, 2016) governed by loose control mechanisms and apply pricing structures for cost compensation, hence display low intensity of competition (Constantiou, Marton, & Tuunainen, 2017). Based on the data they collect they can develop new mechanisms to engage users. Customer engagement, is a multidimensional tool, rooted in marketing and social psychology, and described as “the level of an individual customer’s motivational, brand-related and context-dependent state of mind characterized by specific levels of cognitive, emotional and behavioral activity in direct brand interactions’’ (Hollebeek, 2011, p. 790). These dimensions cover three key activities that can support consumer transition to more climate friendly behaviors. Techniques displaying a quantified climate footprint based on the individual behaviors that are tracked by platforms, could stimulate cognitive activities towards combating climate changes, for example considering the impact of specific food choices, e.g., daily consumption of meat. This can lead to behavioral changes when multisided platforms make more environmentally friendly options easily accessible and economically attractive as observed with platforms combating food waste. Finally, gamification or other nudging techniques that stimulate emotions, either positive or negative, can reinforce consumer engagement with different platforms combating climate changes. The success of such mechanisms is reliant on increasing levels of user engagement with the platform where user behaviors can eventually be replaced with more climate friendly ones. 3.1.3. Contribution 3 – faith and climate change – Dr. Iyad Abumoghli While the world's religious and spiritual traditions did not traditionally face climate change in the way society has come to know it since the mid-20th century, peoples throughout history have always lived through and had to deal with extreme and erratic weather events. Comparable notions of climate change have been expressed in the world’s different religions through their texts and teachings. There is no singular perspective or monolithic view of climate change within highly diverse faith and religious traditions. Within the same religion, adherents may hold different views and perspectives on climate change and humanity's relationship with nature. However, there are general perspectives developed in consultation with adherents of represented faith groups. Naturally, they are taken from those who accept the scientific consensus on climate change. The Buddhist perspective on climate change, for example, is presented as the ecological consequences of our own collective karma. Therefore, it is not just an ecological crisis, but a spiritual one too. Within the broad sphere of Christianity, Pope Francis’ encyclical Laudato Si, provides a high-level perspective on Catholicism’s views on climate change. He argues that climate change is a global problem and that humanity has a moral obligation to address it at all levels of society (UN News, 2015). Climate change can be explained through the Daoist concepts of Ying and Yang. The carbon balance between the earth and sky is off balance causing instability and disasters. Thus, climate change can be viewed as a manifestation of humanity’s failure to maintain harmony with nature. The Hindu Declaration on Climate Change states that “today we call on all Hindus to expand our conception of dharma (duty). We must consider the effects of our actions not just on ourselves and those humans around us, but also on all beings. Addressing climate change from an Islamic perspective, is about assuming the role as trustee or steward (khalifa) of creation that God bestowed upon humanity. This trusteeship applies to all life forms and ecosystems, in their full diversity and richness, reflecting the glory of their creator. Today, the balance (mizan) of nature has been disturbed by human activity and choices which have resulted in overconsumption, overexploitation and overuse of resources, ultimately leading to environmental degradation and climate change. Climate change is already manifesting itself in highly localized contexts, directly impacting Indigenous ways of life. Therefore, climate change does not just represent an abstract scientific issue, but rather a very real and dangerous threat to livelihoods and culture. Adherents from all the world’s religions and faith traditions agree that climate change represents an immense threat that must be overcome, for the sake of humanity, the environment and all living beings we share Earth with. This common understanding has led to an increase in faith, intrafaith and interfaith efforts to address it. These serve as an acknowledgment of the overwhelming scientific evidence that climate change is indeed human-induced. Faith actors can play a crucial role here given that faith permeates into all areas of life and can inspire the behavioral changes necessary to address climate change. As a testament to growing faith engagement, in the lead-up to COP21, held in Paris at the end of 2015, many Faith leaders and organizations called on governments to take climate change seriously and commit to addressing it. This formed part of a much broader global advocacy movement that helped lead to the creation of the Paris Agreement and the climate measures contained within it. In October 2021, in the lead up to COP26, more than 40 faith leaders met at the Vatican and submitted a Faith Appeal to the president of COP26 linking Faith to Science and calling upon nations to increase their ambitions and committing their organizations to take action to reduce their carbon footprint. This process has been only effective in engaging faith leaders over a period of seven months through information technology systems and online capabilities of applications. UNEP’s Faith for Earth Initiative was founded to accelerate and solidify precisely this spirit of interfaith collaboration, ensuring that faith actors had a voice at the highest level of environmental governance and greater access to the UN system. The interfaith initiative introduces the cultural, spiritual and ethical dimensions of sustainable development that faith actors bring into the implementation of the SDGs, particularly those related to the environment. Since its founding Faith for Earth has hosted and participated in multiple interreligious conferences, workshops, webinars and events, encouraging faith actors to come together and tackle common issues of climate change and environmental degradation. Faith actors can play an important role by providing a moral voice to the climate change crisis. Combining spiritual ethics with climate knowledge and science can serve to drive behavioral change amongst adherents, more than either one can alone. Substantial and widespread changes in public attitudes are essential to tackle climate change. Given that faith permeates into all areas of life, authoritative faith voices can be strong drivers in motivating people for action. Indeed, given that many religions already advocate environmentally friendly behaviors as part of their core values such as living with fewer material luxuries, caring for creation or dietary restrictions, there are strong traditions to draw upon. Faith groups across the globe are bringing religious teachings into thousands of projects on the ground to protect people and nature from the effects of climate change and pollution. By leading by example, FBOs can inspire positive action in communities to begin the transformation to a carbon-neutral sustainable society from the bottom up. Faith-based organizations have been using information technology to communicate with the world and pass their messages online, either directed to their congregations or to others through mainly social media and networks. Sharing publications, articles and courses has become easier for the faith communities. Climate change campaigns are among the most active ones among the faith communities. 3.1.4. Contribution 4 – the pros and cons of IM/IT/IS on climate change and future directions – Professor Bhimaraya Metri 3.1.4.1. How the IM/IT/IS sector is having a negative impact on the environment and how it can be reduced The IS/ICT sector is a net source of global greenhouse gas emissions. The data centers used to power digital services now contribute approximately 2% of global GHG emissions – on par with the aviation sector (UNFCCC, 2016). The digital technology industry is one of the least sustainable and most environmentally damaging industrial sectors in the modern world (Junior, Majid, & Romli, 2018). If we are aiming to utilize technology as a mitigating factor for climate change we need to reform the way technology is used at different sectors, causing substantial damages: 3.1.4.2. Replacement rather than repair A consistent shift in the consumption pattern which pushes replace over repair is causing huge overheads on the environment. Companies like Apple are systematically discouraging self-repairs or repair at affordable prices thus pushing for replacement. 3.1.4.3. Software upgrades pushing hardware replacements Innovation and upgradation in the technologies sector are simultaneously pushing the hardware upgrades. These upgrades often leave the legacy hardware unusable leading to e-waste. 3.1.4.4. E-waste Increasing digitalization is giving rise to the problem of e-waste. Much e-waste contains concentrated amounts of potentially harmful products, and this shows little sign of abating. In the absence of clear policy on e-waste flow management (Frazzoli, Orisakwe, Dragone, & Mantovani, 2010), the world produces about 50 million tonnes of e-waste, with only 20% of it being dealt with sustainably (UN report, 2019, WEF report, 2019). 3.1.4.5. Technology driving electricity demand The overall demand for electricity from the digital technology sector is growing rapidly (Jones, 2018). It is further predicted that ICT networks could use about 20% of the world’s electricity by 2025. The World Economic Forum (WEF, 2021) report stated, “by 2020, Bitcoin mining could be consuming the same amount of electricity every year as is currently used by the entire world”. Currently at the start of 2020, Bitcoin alone has a carbon footprint of 34.73 Mt CO2 (equivalent to the carbon footprint of Denmark), it consumes 73.12 TWh of electrical energy (comparable to the power consumption of Austria), and it produces 10.95 kt of e-waste (equivalent to that of Luxembourg). Future projections relating to Smart Cities, 5 G and the Internet of Things give rise to additional concerns over energy demand Carroll and Heiser (2010). The negative outcomes of IT on the environment are further going to be increased with the advent of these new technologies. Even proliferation of Satellite Constellations could be a challenge (David, 2017). 3.1.4.6. How IM/IT/IS can be utilized to improve situation regarding climate change Recent reports have highlighted that IT/IS can lead to a more efficient and sustainable energy consumption using smart grids, smart housing and smart logistics. Statistics suggest a possible fifteen percent reduction in the emission of green-house gases- close to the annual emissions of China. There are many initiatives to reduce energy consumption and carbon emissions. Japan’s $32 million Green IT Project promotes highly energy efficient ICTs in three areas. It aims to reduce energy consumption of network components and data centers by more than 30%. And Japan is experimenting with organic light-emitting diodes to cut the power consumption of displays by 50% (GZR, 2020). Technology can also offer cost-effective market-driven solutions, using sensors, software and networks. Technologies can also help monitor and evaluate climatic conditions and change and may help mitigate natural disasters. We also need to have supported policies and regulations for green energy. Supporting demand for green technologies is only one step. Certain pacts undertaken by regulatory bodies such as the European commission and united nations, also pave the way to regularize sustainable technology development. One such pact is the European Green Digital Coalition between the European Commission and United Nations Environment Programme. We have to ensure that new technology development is cognisant of impending climate changes. One of the ways to enable technology development that conforms to environment and sustainability goals is for governments to penalize technology developers that fail to adhere to global warming constraints. Leaders in the IT sector need to ensure that new technology developments and innovations are guided by the Sustainable Development Goals (SDGs) prescribed by the UN. Further, government and regulatory authorities may promote climate friendly IT innovations by prescribing the necessary guidelines and incentives for better e-waste management and lower energy demands. 3.1.4.7. A brief discussion on research agenda related to IM/IT/IS and climate change Climate-change mitigating technology is a wide research area where researchers are attempting to gain more insights into the technology portfolio which can be utilized to mitigate the climate changes such as carbon emission, energy consumption and e-waste (McLaren and Markusson, 2020, Wang et al., 2018). Some of the other relevant research areas are. • Reuse/ recycle and sustainable manufacturing • Closed supply chain and e-waste removal • Reducing waste and efficient consumption using technology • Monitoring of natural disasters using technology. • Zero power ICT solutions • e-waste management • Circular economy • Green IT • Energy Management for data centers and telecommunication networks • Leveraging data science and Artificial Intelligence for predicting climatic changes and natural disasters 3.1.4.8. How IS/IT education should reflect this There is a need for including the impact of IT/IS on climate change in the curriculum across all disciplines (Perkins et al., 2018). There is a severe lack of awareness around the topics of climate change and how it connects to digitalization and technology transformations. There is a very swift adoption of new courses such as industry 4.0, blockchain technologies and IoT across premier educational institutions. However, courses discussing the flip side of these technologies in the context of climate change and sustainability are scarce. In addition to this, courses that introduce climate change mitigation technologies can be a good addition to start a conversation around climate change issues. 3.1.5. Contribution 5 – the role of online communities in supporting digital activism on climate change – Professor Niki Panteli COP26 gives us the opportunity to reflect on our role as IS researchers on how IS/IT can support climate change. I draw on my personal interest and knowledge of online communities and digital platforms, to posit that IS has an enabling and empowering role in the promotion of climate change. My position in this editorial was triggered by an article in which the Swedish teenager and activist Greta Thunberg wrote in the Guardian (Thunberg, 2021), where she criticized world leaders for being in denial over the climate crisis. Indeed, there seems to be a catastrophic myopia among world leaders on current and emerging environmental threats and the challenges that climate change is causing to our planet. Instead of government and officials leading these debates, transparency of the challenges that humanity faces has been achieved by school children, teenagers and young adults around the world. The role of IS has been invaluable in providing a platform for these young activists to be heard, to form a community, to grow a collective voice and ultimately to lead on debates and protests and increase awareness on the climate crisis. A notable example of an IS-enabled climate change movement is the “School Strike 4 Climate” which was initiated and led by Greta Thunberg. Boulianne, Lalancette, and Ilkiw (2020) studied one of the school strikes in 2019 which was linked to this specific social movement and found that the online media in particular Twitter were used to share diverse sets of information such as local events, tactics for protesting, and opinions of climate change and blame of governments and other institutions for inaction and compliance on issues related to climate change. According to the same study, online platforms are transforming political engagement whilst offering the younger generation the means to express their ideas and voice their concerns to a global audience. Activism has been portrayed as a collective action (Landzelius, 2006), which can be orientated towards challenging the status-quo, and putting pressures on world leaders, corporations, communities, groups and individuals to make much needed changes. Digital activism can maintain activism traditional characteristics namely its collective nature and transformational purpose (George & Leidner, 2019), whilst its dynastic feature is that it relies on the use of online media and digital platforms with the purpose of reaching global audiences and mobilizing large-scale protests worldwide (Askanius & Uldam, 2011). Online communities (OCs) offer the ground for breeding activism as they provide opportunities for individuals who regardless of their location voluntarily form a social aggregation through an online platform for sharing interests, knowledge and experiences (Rheingold, 1993). OCs can be used for providing a shelter for their members (Vaast & Levina, 2015) and a sense of place where members feel empowered to freely express themselves and get involved in stimulating discussions (Panteli, 2016). The growth and sustainability of these communities depends on members’ involvement. Mutual understanding among members (Ma & Agarwal, 2007) as well as group attachment and identification (Panteli and Sivunen, 2019, Ren et al., 2007) have been found to be crucial for OC success. In our research on digital activism, we studied the case of MedicineAfrica, an online health community (see Chamakiotis, Petrakaki, & Panteli, 2021), which had the aim to provide medical education and improve clinical practices in fragile, post-war countries. Findings showed that it is not so much the technological affordances of digital platforms—namely to inform, to network and to organize (Tim, Pan, Bahri, & Fauzi, 2018)—but it is primarily their potential to set up an online collective of like-minded individuals that allows this form of digital activism to succeed. Similarly, Cardoso, Boudreau, and Carvalho (2019) posited that though digital platforms can be used to organize collective action, the extent to which these are successful depends on the capacities and intents of their members, which the authors referred to in their study as resourcefulness and agency. It is not surprising therefore that IS researchers have shown an interest in OC members’ behaviors and practices, and how OC users interact with and influence each other within this online setting. Founded by passionate and enthusiastic individuals, OCs can be used to develop networks of support as a way for responding to emergencies (e.g. Nan & Lu, 2014); indeed climate change is not just a phenomenon that deserves to be understood, but an emergency that requires immediate action. With an understanding that OC knowledge flows travel beyond the community itself (Mozaffar & Panteli, 2021), there is a need to explore the direction and distance of the knowledge flows generated within OCs on climate change, and the impact that these are making on individuals, groups, organizations and governments worldwide. Further, digital climate activism offers the opportunity to study cross-generational differences on the use of online platforms and within OCs. Cross-generational differences have been evident in the use of social media platforms (Panteli & Marder, 2017) and a study on these differences is particularly relevant and topical with the increasing number of young digital activists globally. Research therefore on the interactions within OCs founded and led by teenagers and young adults should fall part of the agenda for future IS research. This should shed further light on who is indeed leading the climate crisis!. 3.2. Education, awareness and changed working practices 3.2.1. Contribution 6 – Climate change and the emergent role of IS: an agenda for IS against the background of COP261 – Dr Rohit Nishant and Dr Thompson S.H. Teo Climate change is an existential threat facing humanity today.2 The recent global pandemic of COVID-19 has brought an important realization that humanity needs to be prepared for impending challenges such as climate change. Leaders from different countries assembled at the 2021 United Nations Climate Change Conference, also known as COP26, between October 31, 2021- November 12, 2021. Political leaders as well as business leaders are expected to commit to ambitious goals and targets relating to emissions reduction. This COP26 comes after the recent working group report titled “Climate Change 2021: The Physical Science Basis” as a part of the Sixth Assessment Report (AR6) of the United Nations (UN) Intergovernmental Panel on Climate Change (IPCC). The report has been described as the starkest warning of irreversible and inevitable climate change (Harvey, 2021). The report is a call to humanity to come together and face this challenge, and academia also needs to focus on climate change. The role of IS has become more pronounced due to the increasing digitalization of our society, accelerated by COVID-19 pandemic. Exponential technologies such as AI and ML have the potential to combat climate change (George et al., 2021). However, the success of any technology is dependent on the people and processes surrounding the technology. IS, being at the intersection of people, process, and technology, is therefore well poised to play a key role in combating climate change. IS research has been focusing on socially relevant issues as well as examining green IS (Nishant et al., 2017, Watson et al., 2010). These researches have highlighted both the positive and negative aspects associated with IS. Nevertheless, recent conversations surrounding climate change offer new opportunities and avenues to IS research to contribute to this fight against climate change. These conversations and development surrounding COP26 are on specific goals and targets, economic models and recognition of specific areas as critical in our fight against climate change. Companies and different nations are increasingly talking about “Net Zero” where the addition of greenhouse gases (GHGs) to the environment is nullified by equivalent reduction of GHGs from the environment. Companies such as Microsoft are showing their commitment to net zero by paying for the removal of carbon dioxide from the atmosphere. However, net zero also faces several challenges including measurement (Joppa et al., 2021) as net zero requires precise, consistent, and automated measurement. IS research can contribute to this endeavor by focusing on how IT used for automated measurement can help companies achieve the goal of net zero. It can focus on processes that increase the effectiveness of IT as well as the design of IS that facilitates automated measurement. Another related development is the Science Based Targets initiative (SBTi), which helps companies to set emissions reduction targets in line with scientific assessment in order to meet the goals of the Paris Agreement (limit global warming to 2 degrees Celsius above pre-industrial level and focus on efforts to limit warming to 1.5 degree Celsius).2 Over 1000 companies are working with SBTi.3 IS research can focus on understanding the role that the intersection of people, processes and IT is playing in SBTi. It can also focus on developing an understanding of conditions under which IT is effective in helping companies implement SBTi as well as challenges in leveraging IT. Another development is the increasing focus on the circular economy as a new economic model. The inherent objective is to minimize waste as much as possible relative to a linear economy, where products ultimately end up as waste. IS research has started to focus on the circular economy, but the focus has been primarily on the potential of IS to facilitate circular material flows (Zeiss, Ixmeier, Recker, & Kranz, 2021). As data increasingly flows through the digital economy, data flow has its own carbon footprint and the proliferation of data can lead to redundant data. IS research can focus on how the idea of circular economy affects data generation and data flow, and how IS research can help minimize the carbon footprint of IS artifacts. Data also forms an essential component of AI/ML. As our society increasingly uses AI/ML and other exponential technologies, their own carbon footprint cannot be ignored. IS research can help companies and societies to redesign processes such that these technologies can be used effectively without damaging the environment. In terms of recognition of specific areas as important in the fight against climate change, there is also an increasing emphasis on biodiversity. In fact, the COVID-19 pandemic has brought out an important realization that deforestation and loss of biodiversity can trigger new pandemics (Tollefson, 2020). Climate change can also facilitate zoonotic spillover (Rodó, San-José, Kirchgatter, & López, 2021). IS research has generally not focused on issues relating to biodiversity. Nevertheless, projects such as Half-Earth Project Map, that maps biodiversity exemplifies how IT can play a key role in conserving biodiversity. IS research can focus on the design of IS artifacts that support biodiversity. It can also focus on IS use for biodiversity conservation by companies, government, and different agencies and explore the factors that contribute to the success of such initiatives. Besides research, the IS community can contribute by making students aware of issues relating to climate change. Other disciplines such as management are increasingly focusing on climate change related issues.4 The IS community has contributed to increasing awareness of issues related to climate change through courses on green IS and IS for sustainability. The current debates surrounding climate change provide an opportunity to reaffirm our commitment. Students are increasingly interested in courses on data analytics, AI, and ML. We can make students aware that data, AI, and ML also have a carbon footprint, and thus they should be used in an optimal manner such that their carbon footprint does not diminish the benefits realized from them. In summary, we see that IS research and teaching can make a strong contribution to our fight against climate change through a focus on issues that have become topical due to COP26 and increasing digitalization of society. 3.2.2. Contribution 7 – dematerialization is so material! The contrasting impacts of IT on the environment and climate change – Professor Yves Barlette 3.2.2.1. How the IM/IT/IS sector contributes to a negative impact on the environment and how it can be reduced IT and IS correspond to dematerialization, but only to some extent. If we create digital copies of documents and save paper (and trees), we still have to store the data we create. Moreover, data which was stored on our devices (smartphones and computers) or on DVD/Blu-Rays, USB sticks (e.g., movies and music) or just broadcasted (radios and TV), are now increasingly decentralized ‘in the cloud’, i.e., data centers. Data exchanges also involve emails, texts, and all that we exchange using social media. Even if emails seem “old-fashioned” today, some companies can send the same message including 10 MB of attached files to 1500 employees, generating 15,000 MB, which will never be deleted for most of us. If these are ‘dematerialized’ and almost ‘virtual’ documents, they require storage, and instead of removing old data, the size of our mailboxes keeps on increasing and is measured today in GB. Hence, streaming and data exchanges have become the norm. Instead of waiting for broadcasting by TV channels and watching a movie, or by radio listening to a song, each of us can separately obtain the content on-demand and stream the same song over and over. The Korean series “Squid Game” from Netflix generated such a huge demand, that SK broadband sued Netflix over the resulting surge in network traffic (Campbell, 2021). The rollout of 5 G will multiply by 100 the traffic capacity offered by 4 G and will in turn increase the volumes of exchanged data. Although the climate impact of streaming and data exchanges may have been overrated, they nevertheless remain significant (Kamiya, 2020). To solve these problems, education seems to be the main solution, however, a tax related to bandwidth consumption could be created for streaming and cloud-based companies. This would in turn increase cost for users. Options such as a tax for other kinds of companies or even a tax on the users themselves could be created, specific to bandwidth consumption and/or storage volume. Storage rationalization, also known as “Green storage”, is also a possibility. Google is able to show its users their carbon footprint within the cloud (Lardinois, 2021). However, these data exchanges and distant storage of data require data centers and data transmission networks: First, company IT infrastructures, data centers and data transmission networks, including computers and storage, that must be manufactured. The manufacturing of computers requires a large amount of fossil fuels, chemicals, and raw materials. The mining of raw materials for electronic products includes copper, lead, and gold and contributes to increased environmental problems. For example, gold mines are the leading source of mercury air pollution in the U.S. (Gerson, Wadle, & Parham, 2020). Mining also pollutes the water of surrounding communities. When the various devices are discarded, they are sent to landfills overseas in Africa, China, India, Vietnam and the Philippines. Computers contain heavy metals like lead and toxic chemicals that pollute the soil and contaminate groundwater when they are dumped into landfill. Some solutions to mitigate these issues include (1) increasing recycling, (2) stopping greenwashing that includes cessation of waste recycling to countries that cannot actually recycle and (3) mitigate planned obsolescence and increase the reparability of devices. Second, IT devices, data centers and data transmission networks need power to operate thereby generating significant levels of heat. Several possibilities have been tested, for example underwater data centers and data centers located in northern countries. This does not reduce the heat generated but at least reduces the required energy for cooling. Even if the problem related to heat is not addressed, the use of carbon-free but polluting energies such as nuclear, must also be solved. 3.2.2.2. How IM/IT/IS can be utilized to improve situation regarding climate change I see several aspects: • IT/IS permits the use of more efficient products and designs that save raw materials and energy. For example, digital twins can help to better design improved products, e.g., car batteries (Merkle, Pöthig, & Schmid, 2021). • Processes can be more efficient and supply chains can be improved, reducing energy used during manufacturing, reducing fuel requirements and food waste during transportation. • Big data analytics offer possibilities for precision agriculture, reducing water waste, use of fertilizers, pesticides and other pollutants. • Work-from-Home possibilities, reducing business trips, encouraging ‘virtual’ companies. • Super calculators allow us to improve weather models and offer insights on what factors are the most important to regulate climate change. • The solution to controlled thermonuclear fusion power, could solve the energetic component of IT/IS impact on climate change. Fusion is only possible when scientists are able to compute the shape of magnetic confinement devices of Tokamaks and Stellarators (Klinger, 2021) or to perform simulations. 3.2.2.3. Research agenda related to IM/IT/IS and climate change • Improving methodological innovations in greenhouse gas emissions calculations. • Improving weather models to mitigate climate change and risks related to this change. • Development of awareness campaigns dedicated to mitigating our personal and professional environmental impacts related to IT and IS. • Increasing the conception and use of new big data analytics tools to mitigate the impacts of our society on climate change. • Developing charters in companies including best practices (see below). • Developing tools for smart buildings (lighting, heating, ventilation) and energy management (statistics, diagnostics). 3.2.2.4. How IS/IT education should reflect this IS/IT education could act in several ways: • Disseminate knowledge and create awareness-raising campaigns about the negative impacts of IT/IS on environment and how they can be reduced by adopting best practices including for example: • Automatic sleep mode and turning of the devices during nights and weekends. • Workers and home users should know that ‘dematerialization’ and ‘virtualization’ does not exist and that data is always ‘materialized’ somewhere. • Future CIOs and members of IT staff should be offered during their education awareness-raising campaigns, including the same as above plus IT/IS-specific elements: for example, the fact of checking that all audiovisual devices are turned off every evening. The same for all the laser printers in a company, even if some monitoring is deactivated. Turning off the monitors of their computers, even if some systems must always run. 3.2.3. Contribution 8 – emerging technologies to mitigate supply chain disruption due to climate change – Professor Manoj Kumar Tiwari Climate change has become one of the most important concerns in recent years at nearly all tiers of decision-making. Climate change is a set of worldwide phenomena caused mostly by the burning of fossil fuels that release greenhouse or heat-trapping gases into the atmosphere such as methane, carbon dioxide, chlorofluorocarbons, water vapor, and nitrous oxide. These factors have resulted in changing global weather patterns, with frequent occurrence of hurricanes, droughts and rising temperatures causing habitats to vanish, and altering ecosystems. Climate change has a worldwide impact. As a result of such calamities, homelessness is on the rise, putting vulnerable communities at risk of food insecurity, disease, and civil upheaval. Climate change, as a result of global warming, is a universally acknowledged reality that affects human, industry, business, and the environment in a variety of ways. Supply chain and Logistics providers among all the industries being aware of the consequences of climate change are most conscious about the deterioration happening due to variation in weather patterns, storms, altered sea routes, and environmental changes will all have a significant impact on their operations, forcing them to alter conventional business models and trading routes. If logistics companies are on the front lines of climate change, they are also huge contributors to the crisis. Transportation industry accounts for nearly 25% of all CO2 emissions from fuel combustion around the world (IEA, 2019). While value addition to the product as it passes through the supply chain, each SC link causes environmental deterioration, especially climatic pollution, via GHG emission. In return, each channel in the supply chain faces opportunities and risks in the form of severe occurrences such as waterlogging or windstorms, higher temperature, soil erosion, rising sea levels, storms, impact on local weather conditions, increased storm frequency and intensity, drought, and so on. As a consequence, both climate change and supply chain activities are simultaneously impacted. Mitigation (cutting emissions) and adaptation (preparedness for inescapable circumstances) are two aspects of dealing with climate change. Both of these challenges are multidimensional. To reduce greenhouse gas emissions, changes are required in power grids, buildings, transportation, land use and industry. Given a better knowledge of climate and catastrophic occurrences, adaptation necessitates disaster management and resiliency. Presently, Machine learning (ML) has gained popularity as a versatile tool for technological advancement. Artificial Intelligence (AI) and ML techniques can contribute to reduce emissions in several ways such as by speeding up the development of low-carbon technologies, better demand predictions, reducing system waste, remote sensing, improving energy efficiency, vehicle emission estimation from smartphone GPS traces, single building optimization, identifying behavioral patterns, and planning and operating low-carbon infrastructure. The impact of information and communication technologies (ICTs) is becoming more essential as people become more aware of climate change and its obvious implications. It provides simple and faster problem resolution using simulations and a large variety of different options. Climate change concerns can be monitored, mitigated, and adapted with the use of ICTs. Some inventions of ICTs are Wireless Sensor Networks, Satellite Technology, GIS, Remote Sensing, Mobile Technology, and Web-based applications. Climate change mitigation and adaptation can be more efficient and successful with the use of ICTs, if integrated strategically; it contains knowledge centers, mobile phones, and interactive media. By educating and raising awareness at the community level, sharing theoretical and practical knowledge, and empowering people to have access to knowledge and relevant data, it can assist vulnerable populations in reducing the risk of climate change. Micro-sensor Wireless Network is among the most prominent technologies in the twenty-first century, with a wide range of applications. Commercial or human-centric applications, robotics, military applications, and environmental monitoring are all using the applications of wireless sensor networks. Sustainable Environmental Management Information System (IS) can maintain the decision-making process for supportable climate control and develops Earth-friendly design. Emergence of big data and AI/ML techniques allows climate solution research to design policy and its implementation at the building and household scale, street, urban areas, modified to specific circumstances but scalable to worldwide mitigation possibilities. Furthermore, the wide application of ICTs also adds to the depletion of limited energy supplies and the increase in greenhouse gas emissions. It is one of the causes contributing to rising CO2 levels for producing ICT machinery and devices, energy usage, and electronic waste recycling. We are living in a phase of rapid transformation, where technological advancements are transforming the way of our living, at the same time directing us to face several challenges in the form of climate change and resource scarcity. Although these technologies contribute to greenhouse gas emissions to some extent, they aid in the reduction of considerably larger amounts released by all other industries. By establishing smarter cities, industrial processes, electrical grids, transportation systems, and energy savings benefits, ICT can cut CO2 emissions on a worldwide scale. ICT may be used to investigate and manage natural resources in a variety of ways, both locally and worldwide. As a result, information and communication technologies constitute a critical component in combating climate change and mitigating its effects. Some ICT tools used to mitigate climate change are: • Computer-controlled devices are used in a variety of ways to reduce energy consumption in the home, at work, and in manufacturing; • Telecommunications are critical in response to natural calamities caused by climate change; • Sensor networks can be used to monitor vulnerable or dangerous environments. • Satellite observations give critical information on climate and vegetation trends. Oceans and land can be monitored by sensors either on the ground or remotely through satellite. The state of the atmosphere can be examined for wind currents and greenhouse gas emissions that may indicate the impending arrival of a storm. Data on tsunamis and sea-level changes can be communicated via satellite via ocean buoys. • Geographic information systems can understand and visualize data. • Better study and modeling of complex environmental and climate systems are possible due to increased computing capability and innovative techniques. • Distributed (grid) computing helps scholars to dig deeper into themes. Natural catastrophes affect around 200 million people each year, according to United Nations figures. ICT plays a critical role in providing early warnings for natural disasters. It provides essential data on the effects of climate change that might lead to disasters, in addition to the usage of sensor networks to monitor hazards such as active volcanoes. Among these include increasing sea levels, depleting freshwater resources, deforestation, and ecosystem concerns. The Famine Early Warning System Network is one example of how ICT may help. Its goal is to reduce the possibility of food shortages by alerting people to early warning signals of famine. The system monitors and analyses data about climate and weather, as well as their impact on crops, utilizing information technology. The data is subsequently delivered to decision-makers in the form of monthly food security updates, predictions, and alarms, as well as assistance with emergency preparedness and long-term policy decisions. A variety of sensor systems created for weather monitoring (ocean buoys) and earthquake detection are used in tsunami warning systems (seismic sensors). Data is collected and delivered into real-time analysis and detection systems via satellite. Grid computing makes it possible to share data in order to do in-depth analysis. The Global Earth Observation System is available for all policymakers to get access to the data. There are free programs that allow us to zoom in on satellite photos that map the world. Geographic information systems (GIS) are one of the most powerful — and extensively used — tools for visualizing environmental data. Overall, using technology into climate change assessment, prevention, and adaptation can help save the ecosystem from damage and degradation. 3.2.4. Contribution 9 – facing the negative environmental digital impact: time to change values? Professor Frantz Rowe To examine whether and how the IT sector can have a negative impact on the environment, following the evolution of our awareness of the issues, I will address first the aspect of the question which concerns how the use of IT products is affecting the environment, before turning to the issue of IT production itself. The world has drastically changed since the end of the last century. In the 1980s, the first oil crisis was just behind. Society, including researchers with my transportation engineering and my economics background, saw enormous benefits in telecommunications to reduce transportation negative impacts on the environment such as pollution and CO2 emissions. Our first studies on the use of the telephone in households, that had been adopted lately in France in the 1970s, demonstrated some substitution effects on urban trips. However, the main lesson was that, at the scale of a large city, a) the net substitution effect was low since the telephone also induced some trips, and b) the main effect of telephone-transportation interactions was an accompanying or “management” effect (Claisse & Rowe, 1993). Unless we take and accept restrictive measures on our liberties to move, like the recent lockdowns, the effects of new communication tools such as video conferencing meetings, will not reduce transportation demand. This is notably due to an induction effect linked to the opportunities and more largely to a “digital rebound” effect (Coroama & Mattern, 2019), whether for business or social life, generated by interactions with communication technology. Hence my spontaneous answer to the question - how can (the) IT (sector) have a negative impact on the environment? - is that, unless we voluntarily reduce our activity and do less, the only significant gains from IT use will occur if we can reduce the negative impacts related to the efficiency of transportation systems. This means that we should design transportation systems so that their use is more environmentally efficient, i.e. they pollute less than others when used and have the best possible environmental footprint (for instance in terms of CO2 emissions) when produced (Teubler, Kiefer, & Liedtke, 2018). Typically IS researchers can contribute to such “green” designs for “greener” use by examining how IT/IS can help support the use of such transportation systems and more generally support more environmentally efficient supply chains. We looked at this, studying how Carrefour had redesigned its supply chain, but gains were not spectacular (Antheaume et al., 2018, de Corbière et al., 2016). This revision of the supply chain is what we would call a " second order " revision. It involved using IT based solutions to improve the use of trucks and supply chain restructuring with an additional layer of consolidation centers. It did not involve “first order” transportation modes improvements such as the use of trains, or river-boats which generate fewer GHG emissions per t.km but may be more expensive, at least to start with. This is because what corporations seek is to be more efficient economically, while ideally showing that they are environmentally conscious. However, in the large retailing industry for instance, becoming environmentally efficient is not their main concern. Unless they are forced to do so, they will not really optimize CO2 emissions or other environmental indicators. A set of interviews on the impact of e-commerce on retailers supply chains shows that senior managers just want to be politically correct (de Corbière, Durand, & Rowe, 2010). However, we believe that the potential of information systems to reduce pollution is very large. Here again, we can distinguish between first order and second order changes. First order changes might be, for example: “combined truck-train transport, where for long distances trucks will travel on train carriages (as is done in Switzerland), or assisting with local manufacturing solutions, based on 3D printing, rather than subcontracting to a third party in another country. These first order changes also involve challenges which IT can help resolve. Second order changes might be, for example, to control cargo or to optimize vehicle routes regardless of the type of transportation mode considered. Regularly, containers are lost at sea and cargo and ships can be better controlled before their cargo falls overboard. Satellites, RFID technologies and web portals can be important to support these aims. There are many other avenues for improvements in that direction. But again, the issue is not just about what type of digital technology we should invest in to help traditional businesses reduce their environmental impact; what counts is to find appropriate production solutions and institutional mechanisms so that firms really aim at reducing harmful emissions in a significant manner and not always put profitability first. Like the retail or transportation industry, the problem is that the IT sector itself is engaged in a worldwide competition where profitability and convenience innovations for the consumer are key. Typical of these innovations the smartphone is only 14 years old, but its appearance also has very negative implications simply because it needs to be produced and incorporates rare materials that are extracted in terrible conditions in some African and Asian countries. In short, the ecological imprint of IT may be negative because IT products also have drastically changed: by becoming “smart”, and more precisely due to the introduction of manipulable screens, our telephones have also become very destructive of scant resource (Ritthof, Rohn, & Liedtke, 2002). In parallel the speed at which we renew corresponding infrastructures such as 5 G and soon 6 G won’t help. Our dream of the world being cleaned from pollution by an immaterial economy was just a very naïve dream. Many other examples abound such as servers farms for the cloud and other data centers that demonstrate huge environmental costs. Worse than that with the internet of things, machine to machine communication, automated vehicles and bots in finance may make environmental pollution uncontrollable or at least many times superior to that created with human-controlled processes. For instance, researchers recently demonstrated that training an artificial intelligence could explode CO2 emission costs (Strubell, Ganesh, & McCallum, 2019). Not only are we exhausting resources, but there are huge geopolitical implications related to the sometimes unique locations of these resources on the planet and related to where chips or materials for certain of our digital equipment are produced (to the extent that children’s lives are destroyed as in Congo, see Lebrun, 2020). These geopolitical risks may in turn generate other ecological risks because we unfortunately know that wars are never clean. Unless we take and accept measures to get sober in what we consume and what we produce, digitization alone may not be such a good solution for saving our environment. This goal implies making value choices (Rowe, 2018) and requires rethinking the design of our activities at multiple levels in an interdisciplinary and systemic manner (Nishant et al., 2020). 3.2.5. Contribution 10 – from cradle to grave – impact of IT on climate change and the relevant research agenda – Professor Ramakrishnan Raman 3.2.5.1. How the IM/IT/IS sector is having a negative impact on the environment and how it can be reduced IT and its applications have made business processes efficient, but the rapid growth of technology and its applications has also negatively impacted the environment. Whilst green IT practices have advocated to minimize the negative impact of IT on the environment, there is still a huge scope for changes to be brought into manufacturing, logistics and operations, usage and disposal of information technology equipment, which can make every process sustainable and environmentally-friendly. Manufacturing of Information technology products can be environmentally-friendly if the production adopts environmentally friendly processes. Process innovation is needed which can help in creating products which use fewer natural resources and also reduce pollution. Recycling and reuse of material and zero emission should be the goal of every IT manufacturing process. IT manufacturing can become environmentally friendly by using energy from renewable sources and also by focusing on energy efficiency. Innovation in business processes that can help in achieving zero pollution, remove greenhouse gas emissions and also eliminate waste. Focus on conserving natural resources can help in making manufacturing of Information technology products environmentally-friendly. Logistics and supply chain processes used by the IT sector cause hazardous air emissions and greenhouse gas emissions. Logistics and operations can be environmentally-friendly if manufacturers shift to green suppliers and partners who provide green logistics and supply chain processes and also handle reverse logistics. If organizations focus on consolidated shipments and reduce packaging by redesigning products, it can immensely help in reducing the negative impact on the environment. IT products have an impact on the environment even during the ‘use’ stage of their life cycle. The energy consumed by the product, the lifetime of the product, the heat dissipated and the digital frequency noise have a negative impact on the environment. Creating products that are more durable and reusable can help the environment. Less resource intensive gadgets which work with low power and solar power and IT gadgets will not only help protect the planet but also will help in the well-being of all. Responsible and environmentally friendly disposal of IT products can help the environment. In several developing nations the practise of disposing IT waste in landfills is the most popular disposal method, which has a colossal negative impact on the environment. Stringent regulations applicable for every end consumer, which mandates safe disposal of e-waste to certified e-waste recyclers can help in reducing the negative impact of IT disposal on the environment. 3.2.5.2. How IM/IT/IS can be utilized to improve situation regarding climate change Application of IT can immensely help in managing climate change. Use of IT while developing smart cities can help reduce annual global greenhouse gas emissions. For example, smart energy meters and smart electric systems help in managing climate change by optimal use of energy consumption. This in turn can also help in smart electric grid management which helps in reducing the losses. This is a simple example to showcase the use of smart IT systems which can help utility companies, end-users and society at large and also help also in managing climate change. Internet and Internet technologies are a force to reckon with for managing climate change. IT can infuse intelligence in transportation and logistics and make them smart. The Internet of Things (IoT) can make the supply chain smart and agile and hence can help in reducing the emission of greenhouse gases. Internet and Internet technologies can also help in monitoring the environment to reduce energy use in real time. IT can be used to harness and create green homes, green industries and hence can help in managing climate change. 3.2.5.3. A brief discussion on research agenda related to IM/IT/IS and climate change Information Technology and Internet of Things (IoT) are vital in confronting climate change problems and help in managing the threats posed by climate change. IT and IoT are part of the solution as their applications are being used to cut greenhouse gas emissions and they help countries manage climate change. IT and IoT are needed for precipitous transfer of information concerning risks of climate change. In this context a few questions which need deeper research include - How can information needed for decision making be collected and disseminated in an efficient manner which can help to advance the integration of climate risks into plans and policies, which can be useful for those who need it most? How can a low-cost IoT infrastructure be created in the urban and rural areas of developing countries which can enable authentic and speedy dissemination of real time data related to greenhouse gas emissions? How can IT and IoT be used to enable countries to adapt to climate change? 3.2.5.4. How IS/IT education should reflect this Education is vital in enabling people to understand the impact of climate change on life on this planet. Educating and creating awareness can help to change the attitude and behavior of people. Education alone can help in ensuring that people start adopting a sustainable lifestyle and also develop skills that can help in managing climate change. Education can not only inspire people to change their attitudes and behavior, but also helps them to make informed decisions which can have an impact on climate change. A deep-seated shift in pedagogy is needed for IT and IoT to enhance teaching and learning for sustainability. Teaching about climate change needs an interdisciplinary and cross disciplinary approach to synthesize diverse ideas. The information about climate change and its impact must be introduced within the school curriculum. IT must be used to create interactive activities on climate change which can help students to understand and learn in a better fashion. Projects related to sustainable development and climate change must be introduced at the high school level. IT tools which can help measure carbon emission must be taught along with practical application of the same. Teaching and learning which has hands-on experiences with technology must be emphasized. At the undergraduate and graduate level, educating and giving opportunities to students to work on environmentally sustainable projects to attain sustainability objectives using IT and IoT technologies can immensely help in bringing out of the box solutions to climate change problems. 3.2.6. Contribution 11 – How has the IT sector negatively influenced the environment? Remedies, role of IT education and future research agenda – Professor Nripendra P. Rana 3.2.6.1. How information management (IM)/information technology (IT)/information systems (IS) sector have any negative impact on environment and how it can be reduced? The IT sector is constituted of companies that produce software, hardware or semiconductor equipment or the companies that provide Internet or related services (Miller, 2021). Technological advancement has transformed the way we live our lives. Many would argue that the growth of the number of electronic devices such as laptops, desktops, high performance computing servers, and other most powerful data-intensive computing solutions (e.g., supercomputers) have brought us numerous benefits, there is no denying that the proper and continuous functioning of these technologies have come at a cost to the environment (Okafor, 2020). The heavy use of these devices present concerns when it comes to resource use, energy use, carbon footprint and waste. The negative impact of the IT sector on the environment could well be traced right from the manufacturing of these devices as a large proportion of materials come from finite natural resources and precious metals. Procuring raw materials and precious metals for manufacturing technological devices and electronic equipment comes with a high carbon cost usually powered by fossil fuels, deforestation, landscape degradation, water pollution and the release of vast quantities of carbon dioxide into the air (Mensah et al., 2015). For example, silicon, plastic, iron, aluminium, copper, lead, zinc, tin, nickel, barium are some of the most important materials used for manufacturing the technological equipment for which the mining of these poses serious threats to our environment (Williams, 2010). Similarly, manufacturing of these equipment requires massive energy to convert them into complex and sophisticated technological products. Subsequently, the transportation of these finished products also comes with a high carbon cost. Finally, massive servers and data warehouses that enable these technologies to work also consume a vast amount of energy and this threat does not stop there. These products also pose setback at the end of their lifespan and globally we throw away electronic waste (e-waste) of approximately $62.5 billion every year and only one-fifth of the electronic waste generated globally is currently formerly recycled, which undoubtedly an enormous threat to the environment (Amos, 2020, Okafor, 2020). It is therefore very evident that the entire lifecycle of technological evolution to disposition adversely affects the environment and technological companies are largely responsible for this threat. This negative impact of the IT sector on the environment could be reduced to a certain extent by adopting the responsible practices of the circular economy, which signifies reusing some of the raw materials of the disposed equipment for a more sustainable approach to consumption. The governments and local authorities also have the larger responsibilities by legislating the circular economy model, promoting eco-friendly manufacturing and by adopting a responsible way of sustainable consumption. This could be achieved by implementing effective laws and regulations on e-waste (Geissdoerfer, Savaget, Bocken, & Hultink, 2017). 3.2.6.2. How can IM/IT/IS be utilized to improve climate change? Technological developments – particularly the discovery of use of fossil fuels, have contributed to climate change. Rising temperatures are essentially blamed by scientists for human-generated gases (primarily CO2), concentrations of which have been enhanced by almost 50% since the industrial revolution started. Innovations such as carbon capture, utilization and storage technologies are being used to reduce CO2. During the time of the Coronavirus pandemic, many office jobs were being done from home resulting in reduced emissions of CO2 from transport and office buildings (Sky News, 2021). The technological innovations to support remote working has been swiftly embraced as businesses endeavored to manage the effect of Covid-19. Greater use of data centers and cloud computing services by some of the leading technology giants including Amazon, Google and Microsoft are also an example of energy efficient services. With many of the latest technology efficient products such as smart LED light bulbs, smart outlet and power adapters, smart thermostat, etc. responsible for reducing energy consumption available in the market not only help households to save decent amounts of money in their annual bills but also reduce the CO2 emissions (Oberhaus, 2019). 3.2.6.3. A brief discussion on research agenda related to IM/IT/IS and climate change? Although the technology improvement with an environmental attribute reduces overall CO2 has been discussed in the prior research, how the role of technology change in lowering carbon emission intensity needs to be further researched for the overall reduction of CO2 (Li & Wang, 2017). While the low-carbon energy technologies contribute toward mitigating climate change (Schmidt & Sewerin, 2017), there is a need for further research on how social-psychological factors, lifestyles, behavioral patterns, etc. will help organizations and individuals to adopt such technologies that can reduce the CO2 emission and serve toward the climate change. The future researchers could also look to explore the adoption of such technologies in different contexts for both well-aware and less aware consumers about using such technologies for the purpose of supporting climate change action. Future research can also explore individuals' pro-environmental behavior toward using such technologies. 3.2.6.4. How IS/IT education should reflect this? Information technology education could be a key component of raising awareness of climate change mitigation and adaptation. One suggested solution could be the collaboration between the scientists and the students at the pre- and post-college levels to make them aware of how modern emerging technologies could help reduce hazardous emissions and reduce the threat of global warming. The pre-college school system is the right place to disseminate such scientific information on the key global climate change issues. School teachers should be provided with the necessary advanced level of educational and hands-on training from scientists from local research bodies on climate change and governments should take the necessary steps to make it a part of the curriculum. Climate change is not only the knowledge that should be taught to children right from an early age, but they should also be made aware of how to responsibly use technologies in a way that helps reduce carbon emissions becoming ambassadors for sustainable living. 3.2.7. Contribution 12 – technology, information systems and sustainability: a public interest research agenda – Professor Katina Michael and Dr Roba Abbas 3.2.7.1. The negative impact of technology and information systems on the environment The coupling of natural and human systems is defined by highly integrated and complex system dynamics resulting from human-nature interactions (Liu et al., 2007). This has presented significant global challenges and wicked problems (Buchanan, 1992, Brown et al., 2010) that require immediate attention in view of sustainability, particularly given the centrality of technology and information systems (IS) to these interactions. A multifaceted feature of the natural system that is integral to all forms of life is biodiversity, which can be considered at three levels: genetic diversity, species diversity and ecosystem diversity (Chapin III et al., 2000). Biodiversity is both implicitly and explicitly linked to health and wellbeing, in addition to sustainable development programs (Naeem et al., 2016, World Health Organization and Secretariat of the Convention on Biological Diversity, 2015). Human actions, notably decisions concerning technology and information systems, increasingly impact biodiversity. In line with the 26th UN Climate Change Conference of the Parties (COP26) Sustainability Governing Principles, there is a pressing need to engage in deliberate management of potential environmental impacts to encourage inclusivity, health and sustainability (UN Climate Change Conference UK 2021). Adverse impacts on the natural world resulting from existing and emerging technologies and IS can be described as negative externalities (Dasgupta and Ehrlich, 2013, Perrow, 1991). The field of environmental economics, among other things, involves the study of externalities that generate tangible and intangible costs to the physical environment and its inhabitants (Cropper & Oates, 1992). It is often difficult to quantify these costs given the reach of an incident, and the extent of its irreversible impact. For example, significant oil spills cause major externalities that cannot readily be measured, such as the Deepwater Horizon oil spill, which was estimated to have spilled 4,900,000 barrels of crude oil into the Gulf of Mexico in 2010 (Beyer, Trannum, Bakke, Hodson, & Collier, 2016). There are two main types of negative externalities; the first refers to negative production externalities that can cause, for example, air or water pollution through manufacturing plants powered by technology and other forms of engineering; and the second denotes negative consumption externalities that can cause for instance, traffic congestion and noise pollution that are generated by systems (Biglan, 2009). Externalities caused by technologies and IS may be unanticipated, unintended, and even paradoxical (Pringle, Michael, & Michael, 2016). Unanticipated externalities refer to those incidents and system failures that were not factored into scenario planning and risk management processes during systems design and development, such as the Fukushima Daiichi nuclear disaster whereby a substantial wave surged over defences and flooded reactors causing major radiation leakage (von Hippel, 2011). Unintended consequences of technologies and IS are those that were discounted as potential outcomes of a respective system, but nonetheless transpired (Ash, Berg, & Coiera, 2004). An example is the use of irrigation systems for crops, which subsequently contributes to soil erosion and increased soil salinity (Khan, Tariq, Yuanlai, & Blackwell, 2006). Conversely, paradoxical externalities emerge from attempts to use technologies and IS for advantage and benefit, but where the result is a negative outcome on another aspect of the environment. An example is the introduction of Internet of Things (IoT) devices to monitor energy systems to lower consumption that requires the devices to be powered and over time to be replaced, causing often toxic and non-biodegradable e-waste that is disposed of in landfills (Mukhopadhyay & Suryadevara, 2014). A common element underpinning these types of negative externalities is the impact on public resources that are shared by communities (Pigou, 1920). These include the ocean and its fisheries and clean drinking water, amongst others, leaving individuals and communities vulnerable, potentially compromising their health and wellbeing. Furthermore, these undesirable impacts extend to the natural system and environment. These impacts can be linked to technologies and IS that do not suitably consider socio-ecological and socio-technical considerations, and that fail to recognize the value of design, testing and validation, with sustainability and people in mind (Chen et al., 2008, Trist, 1981). The mitigation of the undesirable consequences of existing and emerging technologies and IS necessitates intervention in the form of sustainability transitions (Loorbach et al., 2017, Smith et al., 2005), moving beyond the existing multi-level perspective (Geels, 2004, Geels, 2011) toward transdisciplinarity. At the heart of these transitions is the establishment and socio-technical (re)design of higher education frameworks resulting in new forms of knowledge production, allowing for the design and redesign of human-centered socio-technical systems for sustainability, and consequently for human benefit (Geels, 2010, Verbong and Geels, 2010). The proposed socio-technical intervention would require commitment to a series of stages or flows, as depicted in Fig. 1, which we define as the Socio-Technical Sustainability Design Cycle. These include: (i) establishing a detailed understanding and conceptualization of the tightly coupled natural and human systems in context and in view of interactions and feedback loops; (ii) implementing the appropriate sustainability transition through a process of socio-technical (re)design; (iii) measuring the effect of the design over time in view of the degree to which negative externalities are reduced or mitigated; (iv) assessing the impact on human health and wellbeing, in addition to environmental sustainability; and (v) iterating to ensure continual evaluation of the tightly coupled system given its evolving nature. It should be noted that despite this proposed cycle, there will be cases in which paradoxical externalities occur, which is an inherent and unavoidable characteristic of tightly coupled systems. This occurs for two reasons: (i) events in nature are not always predictable no matter how “controlled” the socio-technical transitions are through, for example, regulation and policy mandates (Smith et al., 2005), and (ii) interventions themselves are a form of “technology” that are subject to independent and autonomous forces that are “uncontrollable” (Winner, 1978). Download : Download high-res image (251KB) Download : Download full-size image Fig. 1. Socio-technical sustainability design cycle. 3.2.7.2. Sustainability transitions through transdisciplinarity The proposed model suggests that our global challenges and significant problems require a transdisciplinary lens, beyond a multi-level perspective, in which design interventions are required in the form of sustainability transitions. Within this model, the information systems discipline has a significant and mediating role given its socio-technical orientation and appreciation of the open systems paradigm (Scott and Davis, 2015, von Bertalanffy, 1950, Watson et al., 2010). For instance, step (ii) in Fig. 1 would markedly involve a redefinition of technological and information system design and development processes (Schoormann, Stadtländer, & Knackstedt, 2021), characterized by the emergence of a supportive human-centered, transdisciplinary educational framework (Crow & Dabars, 2015) oriented toward a public interest technology (PIT) research agenda (Abbas et al., 2021a, McGuinness and Schank, 2021, Michael and Abbas, 2020). Transdisciplinarity, in the context of the proposed sustainability transitions, typifies trans-institutional, trans-sectoral and trans-national frameworks bringing together at a minimum industry, government and academia toward the production of knowledge (Crow & Dabars, 2017, p. 474; Hadorn, 2008). This involves recognition that while all problems are local and community focused, their impacts are increasingly global, given the age of entanglement we now live in (Hillis, 2016 as cited in Crow & Dabars, 2020, p. 381), and the tight coupling of natural and human systems, as described above. In considering sustainability transitions more specifically, the proposed Socio-Technical Sustainability Design Cycle would promote Public Interest Technology (PIT) research, empowering citizens and communities (Pitt, Michael, & Abbas, 2021). It would additionally emphasize the importance of directing attention to highly integrative basic and responsive (HIBAR) research (Crow & Dabars, 2020, p. 376), which is still lacking internationally, despite the creation of globally oriented goals such as the United Nations Millennium Development Goals (MDGs) and Sustainable Development Goals (SDGs) (World Health Organization, 2015). In transitioning to HIBAR research and practice that requires PIT processes and innovations, we are seeking to recognize negative externalities and to continually strive to reduce them by introducing alternative socio-technical design options in each selection environment (Nelson & Winter, 1977, pp. 61–70). 3.2.7.3. A public interest technology research agenda for sustainability A preliminary phase in operationalising the proposed design cycle and implementing sustainability transitions is the strategic realignment of IS, and/or the higher education system to proceed toward the production of knowledge and socio-technical innovations that are purpose driven and in the public interest (Abbas & Michael, 2021), facilitating an integrated and responsive approach to addressing our global challenges and key problems (Melville, 2010). Capturing first principles from foundational theories and frameworks across disciplines, including IS, and merging them to form a transdisciplinary lens will allow for the creation of models and simulations that afford a high-level view or conceptualization of existing major forces and counterforces (Frodeman, 2014, Scholz, 2020). Achieving such a capability commands stakeholder engagement in the provision of data to an emergent knowledge system, encapsulating multi-level perspectives (local-national-global) within socio-cultural, business, techno-economic and institutionally-relevant policy contexts (Köhler et al., 2019). We suggest that the role of emerging technologies and IS, as they relate to this knowledge system, be embedded within a PIT framework (see Abbas, Pitt, & Michael, 2021, Fig. 1), represented as a complex, open socio-technical ecosystem that is informed by the landscape of technological and IS developments. The framework also acknowledges the corresponding application areas and the link to financing models, stakeholder engagement (balancing lived experience and professional expertise), transdisciplinary theorizations/conceptualizations and operationalisation to achieve the goal of sustainability toward human health and wellbeing (Abbas et al., 2021). 3.2.7.4. The role of IS/IT education The subsequent and corresponding phase in operationalising the proposed Socio-Technical Sustainability Design Cycle relates to the elimination of disciplinary silos in higher education institutions, that have existed since scientific endeavor was acknowledged as the foundation of the Age of Enlightenment. Through the deliberate reconfiguration or redesign of university structures, new transdisciplinary agendas can be positioned to respond to global challenges (Crow & Dabars, 2015, ch. 5; Gholami, Watson, Hasan, Molla, & Bjorn-Andersen, 2016). In order to ensure our long-term sustainability as a species and a planet, university design must undergo a rapid rethink, becoming more adaptive and agile but also closely aligning to public and planetary challenges (Crow & Dabars, 2020). The transition to transdisciplinarity, even interdisciplinarity, remains fraught with risk principally with respect to forming meaningful ties between Computing, Informatics, Business (including Information Systems) and Engineering schools in addition to other non-STEM domains of knowledge. A harmonization is required not only within the STEM disciplines, but going beyond traditional collaborative fields to incorporate action-oriented endeavors through the creation of Schools dedicated to Sustainability or Life Sciences (Tejedor, Segalàs, & Rosas-Casals, 2018). Here the traditional research university is challenged to apply itself to real-world problems. However, irrespective of the inevitable difficulties, the COVID-19 pandemic has demonstrated the importance of solidarity toward collective action, harnessing the knowledge produced from both professional expertise/practice and the lived experience. The IS discipline is in a prime position to offer information and knowledge management expertise to support transdisciplinarity, and it is our obligation to actively implement sustainability transitions and responsible systems design (Monson, 2021),IS research (Pan & Zhang, 2020) and innovation (Stilgoe, Owen, & Macnaghten, 2013) in the interest of sustainable futures (Hadorn et al., 2006, Hess and Ostrom, 2007). 3.3. Impact on people and communities 3.3.1. Contribution 13 – promoting IT innovation to improve the global environment: towards establishment of global co-creation & co-evolution models – Professor Mitsuru Kodama 3.3.1.1. IT innovation through convergence The leading core technologies in the cutting-edge technology fields of IT, energy, automobiles, electronics, semiconductors, biotechnology, pharmaceuticals and materials science, etc. have become dispersed among individuals, companies and organizations across the globe. The integration of these superior core technologies is a source of innovation of new products and services. (e.g., Kodama, 2007). Across various fields in society, IT innovation is changing working practices, lifestyles, the way products are made and resources are used in production activities. IT technology is being incorporated into a variety of advanced devices and contributing directly and indirectly to the reduction of CO2 emissions. IT innovation is driving energy-efficient manufacturing by promoting energy-saving investments and measures. Such IT innovation will bring about “convergence” - the fusion and integration of different technologies and services and the building of business models across different industries. Meanwhile, with the adoption of the Paris Agreement, a new international framework for the reduction of greenhouse gas emissions and other measures from 2020, all participating countries, including those that are developed, emerging and developing, are strongly urged to take measures to combat global warming. Specifically, Cyber-Physical Systems (CPS) and the Internet of Things (IoT) have been trending globally in recent years while collaboration and fusion of the IT industry with various other industrial fields is transforming various businesses, social activities and the lives of people. Backing the evolution of these innovative technologies is the convergence of IT and electronics technologies, including sensing and location information technologies, energy management systems (HEMS, BEMS, FEMS, etc.), energy-saving devices and data utilization. Furthermore, smart communities such as smart towns and smart cities, into which many countries are currently pouring efforts, are attracting attention as next-generation social systems that connect homes, buildings, and transportation systems with IT networks to make effective local use of energy. IT solutions including energy management systems such as HEMS, BEMS and FEMS to optimize operation smart meters, renewable energy and EVs, etc., and CEMS to integrate the management of those as well as transportation systems such as ITS are becoming indispensable in smart communities. The development of these innovative technologies will greatly contribute to the reduction of CO2 emissions and enable a dramatic increase in energy reduction benefits. Furthermore, XR technology, which has a promising future, will contribute directly and indirectly to global environmental issues by minimizing the physical resources generated, utilized, and consumed in various processes in social, economic, and management activities. Therefore, IT industries in every country need to contribute to global society by further strengthening technological and business partnerships with various industries, supply chains and venture businesses to promote new technologies and businesses through convergence strategies that will open up the future while understanding environmental contributions such as global warming countermeasures. To date, the advances of IT have shortened the time and space in business processes and supply chains across a whole range of industries, accelerated decision-making and raised business efficiency, and have given birth to new business models that transcend and converge dissimilar industries (Kodama, 2020, Kodama, 2021). IT innovation promotes industry-wide co-creation & co-evolution to improve the global environment and increases the possibility of forming dynamic “global ecosystems” as new value chains (see Fig. 2). Download : Download high-res image (897KB) Download : Download full-size image Fig. 2. Global IT innovation through IT- leadership. Through such convergence, what actions should companies, public bodies, government organizations, and a country as a whole take in terms of strategy building and organizational reform to create new business models that integrate different technologies and create IT innovations across industries? What kind of national leadership and management is required to achieve this? These are just a few of the many practical issues facing many stakeholders around the world, including those in academic research. 3.3.1.2. Research agenda related to IM/IT/IS While individual industries, companies, and governmental organizations in each country have their own strategies, the key concept of organizational behavior to adapt to (or create) the convergence worldview is new “strategic knowledge integration” at the global level. Organizational platforms that support such global strategic knowledge integration are global IT community formations. Global IT communities are important organizational platforms for evolving the core knowledge in one’s own country while at the same time actively exploring and integrating the best knowledge from around the world with the core knowledge of one’s own country (see Fig. 2). To drive global strategic knowledge integration, the most crucial issue is not only to integrate the diverse knowledge of different organizations within a company, but also to form global IT communities with superior stakeholders including customers around the world and integrate the best knowledge in the external environment, an ecosystem consisting of globally dispersed knowledge, with the knowledge in the organizations within a company. The key word to accelerate such global knowledge integration inside and outside an organization is “IT collaboration”. In forming global IT communities across the world, “collaborative dynamic capabilities” (Kodama, 2018) to appropriately generate, evaluate, and use common knowledge (i.e., lexicon, meaning, and interests) (Carlile, 2004) regarding environmental contributions such as global warming countermeasures among diverse stakeholders, are a trigger to realize IT collaboration. In addition, the “IT-leadership” of national leaders is crucial to accelerate new strategic knowledge integration through IT collaboration through the formation of global IT communities across a wide range of countries. For this purpose, “holistic leadership” (Kodama, 2017) through the holistic thinking and actions of world leaders will be a particularly important factor of management. However, existing studies in the IM/IT/IS fields have shed little light on the details of the theoretical concepts and practical processes of global IT community formation. Furthermore, there is very little accumulated research on IT collaboration. The holistic IT-leadership of leaders will play a role in forming and developing the organizational platforms of global IT communities. Hence, the cultivation of such leaders will become a pressing issue going forward. 3.3.2. Contribution 14 – smart city initiatives to maximize information value for sustainability – Professor Brenda Scholtz The growing population, particularly in urban areas, has put pressure on researchers and society to address challenges surrounding the global lack of scarce resources and the negative impact on the environment (Khatoun and Zeadally, 2016, Kumar et al., 2020). The technological footprint of companies and individuals has exacerbated this problem since technologies are mainly reliant on fossil fuel, thus the more technology used, the more carbon dioxide is released into the atmosphere, creating global warming. Technology manufacturers and implementers therefore need to consider adopting practices of environmentally sustainable computing. This phenomenon can be viewed as sustainability in technology or Green IT, where the priority must be to reduce the negative impact of an organization’s technological footprint. On the other hand some argue that providing individuals and organizations with access to information and technology can assist people with living more conveniently and easily; for example reducing travel and our carbon footprint. This phenomenon can be referred to as sustainability by technology, whereby we need to reduce the negative impact of companies and their value chains by enabling sustainability use cases or initiatives. The interplay of sustainability in technology and by technology must therefore be addressed by all stakeholders in industry and academia. One solution to achieving this interplay is to utilize the capabilities of information management (IM) and the related field of information systems (IS), which are reliant on the acquisition of information, the custodianship and distribution of that information to those who need it, and its ultimate disposal through archiving or deletion thereof. However, valuable information can only be provided to users if access to data is available. The Economist has described data as “the oil of the digital era”. However, others, such as the Centre on Regulation in Europe, argue that this “often-used analogy between data and oil is misleading.” Their argument is that data, unlike oil, is not scarce and therefore it cannot be likened to oil (MacCarthy, 2018). One thing that everyone agrees on, is that the digital economy cannot live without data and that it remains an immeasurably valuable and unexplored asset. More than 90% of the world’s data has been created in the last two years – more than 2.5 quintillion bytes of data per day. We are experiencing an information explosion. Herbert Simon, the Nobel prize-winning psychologist and economist, stated way back in 1971 that “In an information-rich world, the wealth of information means a dearth of something else: a scarcity of whatever it is that information consumes. What information consumes is rather obvious: it consumes the attention of its recipients. Hence a wealth of information creates a poverty of attention and a need to allocate that attention efficiently among the overabundance of information sources that might consume it.” (Bélanger, Van Slyke, & Crossler, 2018). The potential value of data, information flow and technology to address the effective management of scarce resources has been the driver of the Smart City concept (Ismagilova et al., 2019). According to Albino, Berardi, and Dangelico (2015): “A Smart City is based on intelligent exchanges of information that flow between its many different subsystems. This flow of information is analyzed and translated into citizen and commercial services. The city will act on this information flow to make its wider ecosystem more resource-efficient and sustainable. The information exchange is based on a Smart Governance operating framework designed to make cities sustainable”. The promotion of a Smart Environment is one of the core dimensions of a Smart City (Van der Hoogen, Scholtz, & Calitz, 2020). The success factors that are linked to this dimension are the attractiveness of natural conditions, environmental protection policies, having a sustainability strategy for resource management, and making sure that a city is ‘future proof’. A sustainability strategy should enable an integrated view of socio-economic, political and environmental visions; thus focusing on the 17 Sustainable Development Goals (SDGs) of the United Nations. Future-proof refers to the ability of something that allows it to continue to be of value into the distant future such that the item does not become obsolete. Another core dimension for a Smart City is that of Smart Policy, meaning that any Smart City initiative should align with the strategy of the city, the country (government laws), intergovernmental agreements and of course global policies (Garg et al., 2017, Yadav et al., 2017). Policies here include environmental policies and those related to information governance and therefore IM. The privacy of personal data and information is causing much concern and therefore acts and regulations are important in the context of a Smart City. In South Africa the Protection of Personal Information Act (POPIA) was implemented in 2013 to protect the information and privacy of people, but was only enforced on 1 July 2020 (POPIA, 2020). The General Data Protection Regulation (GDPR) is the European equivalent to the POPIA for South Africa (GDPR, 2018). In addition to these acts, companies are also pushed to have their own information governance and management policies and guidelines. Another dimension that is closely linked to climate change issues is that of Smart Mobility. This dimension focuses on factors that involve sustainable, innovative and safe transport systems that are accessible locally, nationally and internationally (Calderón et al., 2017, Yadav et al., 2017). IoT is an integral part of Smart Mobility and is regarded as an enabling technology of big data (Bibri, 2019). However, big data is only valuable once quality data is produced, which is required for intelligent decision making to contribute to sustainable smart cities. The Smart City definition illustrates the importance of information exchange within a Smart City and therefore the importance of the provision of open data and the creation of open data hubs. Smart Technology and ICT-infrastructure is considered a support dimension of a Smart City since it is integral to all the other dimensions. It refers to the different types of smart technologies that are used in a Smart City and since these technologies produce and utilize data, it also involves relating all the data in smarter ways. Some of the opportunities for smart cities are that the data is in a digital format through IoT, Artificial Intelligence (AI) and machine learning technologies, making real-time collection, processing and sharing easier and therefore, decision making and solution development is becoming faster and more advanced (Allam & Dhunny, 2019). Providing access to quality data through the related strategy of information governance is becoming more and more critical. Information governance is the overall strategy for information and provides a balance between the risks of the information with the value that this information can provide. Data quality forms part of governance, since it is focused on the integrity and value of the information itself. When the factors of a Smart City concept are integrated, such as ICT, urban infrastructure, open data with data governance, and stakeholder participation, equitable and sustainable solutions can be developed to face city challenges (Yadav et al., 2017). Stakeholder participation is emphasized in the Smart People dimension of a Smart City and it is here that the importance of skills, qualifications and education is addressed. The lack of skills lies in the areas of IT/IS and Computer Science graduates in general, but in particular with regard to Data Science, AI and machine learning competencies. Higher education has started addressing the need for these competencies in the recent IS2020 curricula guidelines (IS2020, 2020). Competencies related to sustainability and environmental issues are also included in the IS2020 guidelines as social and ethical considerations. In Germany and South Africa modules related to Green IT, and environmental information systems have been introduced in recent years. So whilst some progress has been made, much more effort and investigations need to take place to introduce more competencies regarding sustainable technologies, data management, data analytics and data science into IS/IT and CS degree programs. Much research has been done on the topics of smart cities, Green IT and ICT for sustainability. However, reported empirical studies on IS for meeting the SDGs are still considerably low, particularly with regard to sustainable management of water and sanitation (SDG 6); access to affordable, reliable, sustainable and modern energy for all (SDG 7); and conserve and sustainably use the oceans, seas and sustainable behavior (SDG 14). In Africa and other developing countries these three SDGs are far from being met, where access to clean water and energy are major problems for the vast majority of the population. There is also a lack of valuable information and empirical research regarding emerging smart cities, especially in developing countries (Backhouse, 2015, Estevez et al., 2016). This lack of information prevents stakeholders from making informed decisions, such as how to manage the city resources more efficiently or how to attract potential investors. 3.3.3. Contribution 15 – wider issues in IS research on climate change – Professor Rahul De’ In The Great Derangement: Climate Change and the Unthinkable, noted writer Amitav Ghosh (2018) points to the absence of writing on the destruction of nature and habitats through the devastation wrought by Imperialism and the rise of industrial capitalism. He calls this absence in the canon of English literature the ‘great derangement’ where thinkers and intellectuals are oblivious to the plainly visible damage done to the planet. This neglect of climate change continued in writings in history and politics. Ghosh calls for an awakening to recognize and give voice to the scale of the ‘unthinkable’ impact of this phenomenon. Ghosh’s call resonates in IS research, where this phenomenon is recognized as a ‘critical challenge’ for researchers and practitioners (Gholami et al., 2016; Eliot and Webster, 2017). The call is for more extensive research on climate change and its impact on the world, where ‘grand challenges’ require a wider understanding of the phenomena and a scoping that includes ideas and concepts outside of current disciplinary concerns (Winter & Butler, 2011). Following this reasoning, three possible issues are presented in this brief essay that can address the scale of climate change concerns, and, which also resonate with prior IS research. These ideas have to do with engaging with issues of the postcolonial condition; a focus on the impact of climate change on ordinary people; and its impact on women. 3.3.3.1. Focus on postcolonial condition Prior research in IS has examined the postcolonial condition prevailing in former colonies of large imperial nations of the West, which includes most of the developing and less-developed world (Lin et al., 2015, Ravishankar et al., 2013). This condition essentially refers to the power asymmetry between former rulers and the ruled, and defines the cultural and political practices of both, even though there is no present-day colonial presence. The postcolonial condition is perpetuated largely through multinational corporations and global agencies. Global actors, such as large multinational corporations and multilateral agencies (like the World Bank and the International Monetary Fund), have a massive and disproportionate effect on world affairs. Their beliefs, policies, and practices affect millions of people directly and indirectly, as they influence governments and the actions that governments take. These institutions have a strong influence on the uptake of information technology in many nations, through efforts such as electronic governance, ICT for development, and spread of technologies to reduce the digital divide (De, Pal, Sethi, Reddy, & Chitre, 2018). They also have a strong influence on industrialization, deforestation, energy consumption patterns, and the overall adoption of modern technologies. Prior research has shown that many “development” projects ultimately harm subaltern people, who are the poor and marginal groups, rather than benefit them (Ferguson, 1994), and scholars often doubt the very benefits of development in such situations and contexts (Escobar, 2011). Green IS research that is concerned with recording and analyzing the impact of climate change (Melville, 2010) must also document the postcolonial conditions and the impact of multilateral agencies. When agencies fund, say, construction of roads or dams or massive irrigation projects, the impact on the environment must be documented and the particulars of local politics, struggles, and contestation must be recorded. Crowd-sourcing technologies may be used to both record the different perspectives of people, and also to arrive at a possible consensus (Malone & Klein, 2007). 3.3.3.2. Focus on people Though there is considerable work on Green IT and Green IS from the perspective of organizations and how they can manage their consumption and production patterns (Dedrick, 2010, Khuntia et al., 2018, Melville, 2010), the emphasis must also include the manner in which ordinary people in urban and rural areas, in remote mountainous regions, on isolated islands, and in forests are affected, and how they are using IT to both learn about and counter the effects of climate change (Watson et al., 2021). The focus can be on local and indigenous approaches to adapting to climate change, and how digital technologies can support those, with information and feedback. One problem that can be addressed through both design science and action research is that of measuring the changes that are slowly and inevitably happening, and how people are adapting to them. These changes are in local climate conditions, in soil composition, in levels of water tables and aquifers, and in the extent and survival of local flora and fauna. These changes may be viewed from multiple perspectives of resource depletion for businesses or from that of people’s livelihood, and the impact on local sustainability (Clarke & Davison, 2020). 3.3.3.3. Focus on gender Theorizing about climate change around issues of mitigation and impact cannot be “gender blind” (Pearse, 2017). In rural areas, the brunt of droughts, flooding, soil degradation, river erosion, salinization, and loss of food crops, is felt largely by women (Alston, 2015). With these drastic and adverse changes in agricultural conditions, there follows shortages in food, nutrition deficiency for both women and children, loss of livelihood, and increase in debt (Chandra, McNamara, Dargusch, Caspe, & Dalabajan, 2017). Though both men and women suffer the consequences of extreme climate events, it is women who are worse off as national policies do not fully account for them, and relief measures are not easily accessible to them. When climate change events force populations to migrate, women are worse off as they lose their local social networks, are subject to abuse, and are unable to secure livelihoods on foreign soil. The gender imbalances are exacerbated and become entrenched (Alston, 2015). Prior research in IS has established the imbalanced access that women have to both ICT devices and facilities in developing regions (Rashid, 2016). As they are most prone to adverse effects of climate change, research has to both reveal these deprivation issues, and find ways to address them. 3.3.3.4. Conclusion IS research has an opportunity to sidestep the great derangement in literary culture by both exposing the causes and consequences of climate change, and finding ways and means to address them. Some work has already started on understanding concerns of postcolonial dominance, identifying issues of ordinary people, and understanding the particular challenges faced by women. Future research will likely build on this. 3.4. Responsible digitalization 3.4.1. Contribution 16 – corporate digital responsibility: the powerful offspring of sustainability and digitization – Professor Michael Wade 3.4.1.1. Two dominant trends Two of the most significant global business trends over the past several years have been sustainability and digitization. Sustainability revolves around the natural world, most notably humanity’s impact on our planet. Digitization, by contrast, focuses on the virtual world. Without obvious common roots, these two megatrends have largely developed independently of one another (Naujok, Fleming, & Srivatsav, 2018). I recently had a conversation with the Chief Sustainability Officer of a consumer goods company and when I asked him about digital and sustainability, he looked back at me blankly. However, this is likely to change. If we expand the definition of sustainability to include responsible and ethical practices of all kinds, not just those that impact the planet, we see plenty of intersection points. Examples include cyber-security, data privacy protection of employees and customers, digital diversity and inclusion, ethical algorithms including AI, technology component recycling, right to repair, ethical gig economy practices, and there are many others. Unfortunately, our research suggests that most organizations today are unprepared to effectively respond to these challenges. If they do so at all, it is in a fragmented manner. This opens up new and interesting avenues for research. 3.4.1.2. A new field of corporate digital responsibility It is time to bring these disparate and fragmented elements together under a single umbrella so that they can be addressed in a consistent and complementary manner. We refer to this new consolidated focus as Corporate Digital Responsibility (CDR) (Lobschat et al., 2021). CDR can be regarded as a subset of Corporate Social Responsibility (CSR), an already established entity in many organizations. Corporate digital responsibility is defined as a set of practices and behaviors that help an organization use data and digital technologies in a way that is socially, economically, and environmentally responsible (Wade, 2020). 3.4.1.3. Each CDR sub-categories contains a number of areas Social Corporate Digital Responsibility revolves around an organization’s relationship to people and society. The important topic of data privacy protection of customers, employees, and other stakeholders is included here. It also incorporates aspects of digital diversity and inclusion, such as bridging an increasing divide between digital haves and have nots across geographies, industries, social classes, and age. There are also societal impacts of inaccurate A.I. decision-making algorithms that can lead to unfair or discriminatory practices, as has been noted among many recommendation engines (Noriega, 2020). Other technologies can also have harmful effects on society. Facebook, among others, banned so-called deep fake videos that realistically apply false or misleading statements to real people. Economic Corporate Digital Responsibility relates to the responsible management of the economic impacts of digital technologies. Much has been said about the replacement of human jobs by robots and other digital technologies, and this is certainly a relevant part of economic CDR. Yet, it also relates to the creation of new jobs in a digital world that are enriching, purposeful, and interesting. There is emerging evidence to suggest that the so-called gig economy creates jobs that are often uninteresting, repetitive, and underpaid (Tan Z.M., 2021). There are also questions regarding the sharing of the economic benefits of digitization with society through taxation of digital work, and fair compensation of data monetization to the original owners. Finally, Environmental Corporate Digital Responsibility concerns the link between digital technologies and the physical environment. There are many issues here, including the responsible recycling or disposal of old computer equipment. The extension of obsolescence cycles by one year, for example, can have an enormous impact on the environment.5 There are also issues regarding the limiting of power consumption, including reducing the use of electricity to support bitcoin mining. 3.4.1.4. A call for a multi-disciplinary focus on CDR Many organizational processes, practices, and projects exist to address digital aspects of social, economic, and environmental responsibility. Yet, they are rarely coordinated or optimized. Some, like cybersecurity, tend to be the responsibility of IT departments, others, like workforce automation, may fall under the purview of operations, and yet other elements may sit with HR, legal, engineering, R&D, or particular lines of business. Without effective coordination, organizations leave themselves open to risks, and may miss out on rewards. Research too, is required to better understand the dynamics of CDR from both theoretical and empirical perspectives. This research will need to be multi-disciplinary since CDR covers aspects of many different fields, including IS (the coordination of technology and people), IT (the ethical design of technologies themselves), operations (the development of systems and practices to embed CDR in organizational processes), organizational design (how to set up structures to effectively govern CDR activities), strategy (how to align CDR with other organizational objectives), and OB (how to train people to act in responsible ways). In summary, as the sustainability and digitization trends continue to grow, Corporate Digital Responsibility will become increasingly relevant for organizational performance, both to mitigate risks as well as find new sources of advantage. As researchers, we need to get ahead of this trend not only to better understand it, but to influence its development through the creation and dissemination of tools, frameworks and best practices to practicing managers. 3.4.2. Contribution 17 – digitalization and the myth of sustainability: some critical reflections – Professor Suprateek Sarker Digitalization is all around us, and we are all well aware of the value digitalization brings to help improve many facets of human existence. Indeed, when we think about digitalization, most of us see the positive impacts digitalization has had, and can potentially have, on the environment. After all, in digitizing business processes, we drastically reduce, even eliminate the consumption of paper, which saves trees, and in turn contributes to better environmental outcomes. We also think of how, through metering, we are able to encourage consumers to consume less electricity, which again contributes to better environmental outcomes (e.g., Wunderlich, Veit, & Sarker, 2019). Perhaps a more high-profile example that we can all relate to pertains to the new generation of automobiles, that have been described as “computers on wheels” (Wade, 2016). Digitalization vehicles can help to optimize fuel and/or battery usage, and hence result in less pollution of the environment. Furthermore, metaphors like ‘cloud’ imply something floating and delicate” and green, and add to our sense that digitalization is at the heart of our battle to save the environment (Crawford, 2021, p. 41) and can have a significant role in addressing climate change. Yet, many argue that the above represents a grossly biased picture, and is a consequence of the largely pro-digitalization, “digital utopia” narrative which includes the myth6 of digitalization’s contribution to sustainability, that is promoted by tech companies, sections of the business press, and those fascinated by the wonders of digitalization. Crawford (2021), among others, provides a critical commentary on the “mineralogical layer” (p. 32) underlying digital technologies and AI that made me acutely aware of the environmental effects associated with digitalization. She notes that “seventeen rare earth elements,” that are part of virtually every digital device/technology surrounding us, have to be extracted from mines. Mining of such minerals is not only associated with slavery, conflicts, and human exploitation very often, but also results in dangerous waste. Specifically, she quotes David Abraham who writes “. 99.8% of earth removed in rare earth mining is discarded as waste… that are dumped back into the hills and streams” and this leads to “pollutants like ammonium…” (pp. 36–37). Particularly alarming is the estimate by the Chinese Society of Rare Earths that refining one ton of these elements “produces 75,000 liters of acidic water and one ton of radioactive residue” (p. 37). The amount of consumption of water and electricity by data centers and other components of the digital infrastructure is also shocking, but is largely hidden from view or consciousness of the average consumer or decision-maker, who is led to believe that digitalization is “clean” and a key part of the solution for the environmental crisis (pp. 42–45). Along similar lines, Wade (2016) suggests that in addition to batteries and their deleterious environmental impacts, “rare metals are sprinkled throughout vehicles, mostly in the magnets that are in everything from the headlights to the on-board electronics. But those rare metals come from somewhere—often, from environmentally destructive mines… and processed in less-than-green ways.” The point of highlighting the above issues is not that digitalization needs to stop. The point is to make people aware that there are environmental trade-offs that we are implicitly making when we use digital technologies. Indeed, by many accounts, the clean paperless image has been carefully cultivated, and it distorts the assessment of environmental impacts in one direction, in favor of further digitalization. As IS researchers who embrace the sociotechnical view (e.g., Sarker, Chatterjee, Xiao, & Elbanna, 2019), we are aware that the need for efficiency, effectiveness, and economic value needs to be balanced with a consideration of humanistic outcomes. Given the critical role that the environment, especially in the form of climate change, is seen to play in shaping human wellbeing (even threaten survival), we need to consider environmental outcomes as an undeniable aspect of humanistic outcomes of digitalization. While outlining a research program is not feasible in a short editorial segment, there are a few points I would like to make, that may have implications for research and teaching: As researchers and teachers, we need to develop and communicate a balanced picture of digitalization, and not unreflectively perpetuate the “digital utopia” narrative. We must reflect on the culture that our societies have developed, of technology infusion in human processes as a natural course of development of organizations, economies, and societies. We need to develop frameworks and metrics that will help managers and technology consumers assess the economic value and convenience with respect to the true costs. Just as we have metrics to capture the economic value of digital technology implementation, we need to develop and incorporate the use of environment-related criteria and metrics as part of the proposal and justification process for any significant digitization initiative. At a very basic level, we need to ask why we need digital technology infusion in a certain aspect of life, and whether it is warranted when a holistic assessment is done. And, we need to develop conceptual and analytic tools to be able to carry out such assessments, even if such analysis is initially far from perfect. Obviously, the environmental damage resulting from the harnessing of digital technologies is a systemic issue involving many different stakeholders, and IS scholars cannot solve the problems themselves, but we need to actively consider how we may be part of the solution. We need to become aware of the issues, make the environmental costs transparent in our communication with stakeholders, conduct revelatory studies of the hidden environmental costs of certain technologies that are extolled, create models that incorporate benefits and costs including environmental costs, and, most importantly, make our students aware of the one-sidedness of the pro-digitalization narrative. We need to incorporate environmental impact analysis of digitalization initiatives as part of the IS curriculum, and foster an environmental consciousness among the students with respect to digitalization. Undoubtedly, a lot of research will be needed to enable decision makers to link environmental costs to a particular decision pertaining to digitalization. Many of us talk about responsible AI – here, my objective is to encourage responsible digitalization, and the responsibility is regarding environmental impacts of digitalization. As we set out on this path, I reiterate that our goal will not be to single-mindedly promote or oppose digitalization, but to “right-size” the extent of digital infusion in any initiative, after careful consideration of benefits and costs, where costs will not only consider the immediate tangible financial implications but also environmental costs over time that humanity will be left to bear. 3.4.3. Contribution 18 – systems for sustainable growth – Professor Maung Sein and Dr Leona Chandra Kruse “Stark realities, critical choices […] Years, or even decades, of progress have been halted or reversed.” These alarming statements began this year’s Sustainable Development Goals (SDGs) report, underlining the gloomy consequences of COVID 19 related crises. The prospect, however, is not all doom and gloom. Digital transformation has been accelerated in various governmental and business sectors, and we need to continue harnessing the potentials of information systems to address key societal, economic, and ecological issues. Supported by well-designed information systems, researchers, economic actors, policymakers, and civil society can join forces to rebuild a more resilient and sustainable future. Perhaps no issue is more crucial now than the threat of climate change. This is not just an isolated threat: it directly challenges our conceptualization of sustainable growth and sustainability itself. We view sustainability as a synergy across people, planet, and profit, following the SDGs. We place a particular emphasis on a holistic view of information systems (IS) for sustainability which entails the study of designing, engineering, using, and disposing of information systems in order to minimize their environmental impact as well as to promote sustainability-related practices. This holistic view embraces different initiatives across various computing and informatics disciplines in the spirit of transdisciplinarity and multilateralism. In the following, we will delve into the role of IS in this crucial discourse on the threat of climate change. We will first set the scene by providing our perspective on IS and sustainability. We will then propose specific approaches that the IS research community can take to address the issues we raise. We will conclude our editorial segment by discussing issues related to evaluating the initiatives and frameworks aimed at meeting sustainability challenges. 3.4.3.1. Setting the scene The thirteenth SDG persuades us to “take urgent action to combat climate change and its impacts,” and this year’s report continues to urge us on how “rising greenhouse gas emissions require shifting economies towards carbon neutrality” (United Nations (UN), 2021, p. 20). For us, this urging means exploring new and alternative approaches to minimize the environmental impact of information systems, in addition to our ongoing measures. We observe several ongoing transdisciplinary movements to this end. One of them, computing within limits, aims to reshape computing research by acknowledging a need for limits (LIMITS, 2021). This movement is guided by three core ideas: aiming for a steady-state economy and acknowledging the limit of growth, considering models of scarcity in order to promote resilience, and reducing energy and material consumption while avoiding the rebound effect (Nardi et al., 2018). Rethinking the status quo in our design and computing assumptions can help us shape the way forward. Minimizing the environmental impact of information systems, however, concerns not only the design and use period. We need to anticipate what happens in the post-use period, that is, minimizing and managing e-waste. This is echoed by the twelfth SDG: “ensure sustainable consumption and production patterns.” However, this year’s report shows that “electronic waste continues to proliferate and is not disposed of responsibly [.] Each person generates about 7.3 kg or e-waste, but only 1.7 kg was recycled” (United Nations (UN), 2021, p. 19). 3.4.3.2. Design science research for sustainability What can the IS community do to meet the enormous challenges posed by the threat of climate change in particular and to sustainability in general? The simple answer is that research needs to make this a key area to address. Understanding the phenomenon, explaining the mechanisms of climate change and predicting its consequences are agendas that continuously engage researchers from across the disciplines. We propose that the IS community can significantly contribute to these ongoing initiatives through designing artifacts (systems, prototypes, methods or frameworks). While designing systems in a way to best accomplish a particular purpose (combating climate change in our case here), lies at the very core of what we do in our discipline, our call here is to take a design science research (DSR) approach in our research. DSR aims at creating new prescriptive knowledge through building methods and artifacts to improve the world in some way, however incremental. The DSR paradigm is fundamentally a problem solving paradigm. It is not atheoretical tinkering – artifacts are developed based on theoretical and conceptual foundations, drawing upon the knowledge base for explanation research – and in the process creates theoretical and conceptual knowledge that are of prescriptive nature such as design principles that are transferable to other contexts. While care is taken to ensure rigor, the very fact that the artifacts developed through DSR are to solve problems faced by the society makes it relevant by definition. 3.4.3.3. Sustainability as value for design DSR is perfectly placed to meet the threats to sustainability. Among the papers and prototypes presented in the 2021 edition of the premier conference of the DSR community (Design Science Research in IS Technology – DESRIST), one is an excellent illustration of what the IS community can do. Hillebrand and Johannsen (2021) developed a chatbot called KlimaKarl “to Promote Employees’ Climate-Friendly Behavior in an Office Setting”. The App can be classified under “persuasive technology” that has been used successfully in the health sector to promote healthy living (e.g. weight management) through behavior change. Obviously such systems cannot force behavior change but can definitely informate users. A system of this genre can prove to be useful in the particular case of wind powered energy in Norway. While there is a broad support for developing green energy, many localities vehemently oppose constructing windmills in their areas. Systems can be effective in helping citizens see a balanced view and hopefully reduce opposition to windmills. DSR, like any research approach, is not value free (Iivari, 2010) and consequently, “the values of DSR should be made as explicit as possible” (p. 44). The burden of explicating the value of the designer and his/her goal in designing the artifact is essential to help the user understand the possible deleterious outcome or the unintended dark side of the technology. This is a particular sensitive issue with the use of persuasive technology in a debated issue such as sustainability. 3.4.3.4. Green practices within DSR Finally, environment-friendly practices such as green computing and green coding can be incorporated in the design of artifacts, whether as a DSR project or routine design. These practices help to minimize the environmental impact of the resulting information systems. The IS research community is also a user of IT. We need to be mindful of the potential e-waste of our research endeavor and ingrain e-waste management in our daily behavior. Some of the points in this editorial indeed represent critical choices which must be made in the face of the stark climate realities. 3.5. Role of data, technology and IS governance 3.5.1. Contribution 19 – climate change and role of information technologies – Professor Babita Gupta 3.5.1.1. Information technologies and climate change Information technologies require energy at every stage of its life-cycle and contribute to the carbon footprint. However, IT is also helping reduce net carbon emissions in various industry sectors. Technology-enhanced working using the video conferencing and cloud-based collaboration that has accelerated during the COVID-19 pandemic is proving to be a double-edged sword (Frontier technologies, 2020). While these technologies helped the environment by significantly reducing the impacts of travel and commuting, they also increased carbon emissions since the backend infrastructure, such as massive data centers, is enormously energy-intensive. Current estimates of information and communication technology (ICT) impact range from 1.4% to 3.9% of global CO2 emissions, highlighting the need for accurate data on ICT’s impact on the environment (Cunliff, 2020, Murugesan, 2021, Robertson, 2021). Several information technologies are poised to play a critical role in monitoring, managing, and mitigating climate change-related phenomena and increasing environmental resiliency. For example, artificial intelligence and robotics are being utilized for automated detection and monitoring of environmental hazards, remote sensing to track deforestation activities and marine life, monitoring biodiversity, traffic flow optimization, estimating real-time precipitations, and managing flood risks and emergency planning. Increasing occurrences of extreme weather events are affecting food production and distribution globally. Advancements in information technology utilizing multi-source spatial and temporal data, robotics, drones, Internet-of-Things (IoT), etc., are being explored in the agriculture and transport industry. For example, precision agriculture technology is an environmentally sustainable strategy for optimizing water input, weed control, disease eradication, pest reduction, and yield enhancement to avert water and food insecurity and optimize the food production chain. Data centers are the backbone for managing big data, cloud computing, AI, blockchain, and IoT. They also have massive power consumption needs contributing to climate change. Researchers and innovators are exploring novel technologies such as liquid cooling that improve heat-dissipation efficiency and reduce their impact on the environment to reduce the carbon footprint of data centers and other IT infrastructure. 3.5.1.2. Role of higher education in building environmental resiliency Higher education institutions can provide knowledge and resources to the learners and create awareness, inspiring the next generation to navigate the complexities of climate change. Education and training can encourage learners to think about technological and behavioral changes to reduce and mitigate environmental impact within their local sphere of influence and macro level. Institutions offering information systems and related programs are beginning to incorporate pedagogical practices in their curriculum that engage students to reflect on organizations’ sustainable and responsible technology adoption and use practices. Educational institutions can create partnerships with community stakeholders to accelerate carbon-neutral business practices and build environmental resiliency. Several universities are forming coalitions committed to climate action, such as the University Climate Change Coalition, to leverage scientific knowledge and expertise for climate change solutions. In addition, universities are offering programs that emphasize environmental justice and equity, such as responsible business MBA and hospitality and sustainable management. 3.5.1.3. Research agenda and climate change The estimates for carbon dioxide levels in the year 2021 are at 417 parts per million. Bringing it down to the safer threshold of 350 parts per million would require the removal of about 2000 gigatons of CO2 from the atmosphere over the next century (Fork and Koningstein, 2021, Frontier Technologies to Protect the Environment and Tackle Climate Change, 2020). This reversal of climate change would require everyone’s effort, including researchers in the IT, information systems, and related areas, to develop a robust and practical research agenda: Methodologies to assess the sustainability of ICT Infrastructure. • Develop an actionable set of metrics that can measure the reliable and precise impact of an information technology infrastructure, an IT project, or a portion of the cloud in terms of its carbon budget and footprint • Develop reporting mechanisms, models, and infrastructure that would make it easy for companies to evaluate their as well as their supply chain partners’ emissions and environmental impact. Sustainable, greener technologies. • Strategies grounded in organization behavior and culture that persuade companies to shift from fossil-fuel-based electricity to using cleaner, renewable energy solutions in their IT projects, technology infrastructure, and data centers • Creating mechanisms for designing sustainable technologies compliant to be carbon-neutral in the ICT industry by 2050 • Models for integrating disparate data and prediction models and forecast systems for weather, traffic, demand, patterns of consumption, and real-time inventory that companies can use to optimize their supply chain and reduce waste and carbon footprint • Best practices to make the entire life cycle of IT greener, including energy-efficient hardware and software that has reusable code and is optimized for the green hardware. Resource recovery and reducing e-waste. • Research on e-waste management and strategies for e-waste prevention, smart recycling, and resource recovery, without shifting the e-waste burden to still-developing economies. Use of behavioral theories to engage stakeholders in climate change solutions. • Research on the role of social media and models grounded in behavioral theories that can prevent or at least reduce the impact of misinformation on public perception of climate change • Strategies to empower consumers so that the collective consumer sentiment about climate change imperative can incentivize companies to pursue carbon net-zero more actively as a goal • Research on digital and social media best practices to increase consumer awareness of the impact of their purchasing choices and decisions on environmental sustainability and design strategies that nudge consumers to adopt behavior that reduces their carbon footprint. Role of governance in climate change innovations. • Research on the role of governments in enabling effective guidelines, policies, legislation, incentives, R&D collaborations, and regulations about emission standards versus companies setting voluntary targets for achieving carbon neutrality within the critical time frame. • Research on the role of policy governance within the organizations when implementing IT projects and the evaluating impact on the environment. • Research on the role of social media and other digital tools to influence leaders in government and businesses to embrace sustainable consumption and production. 3.5.2. Contribution 20 – climate crisis response: climate crisis response: complex information governance for social sustainability – Professor Deborah Bunker "Climate change is destroying our path to sustainability. Ours is a world of looming challenges and increasingly limited resources. Sustainable development offers the best chance to adjust our course." – Ban Ki-moon (2012). We are amid an existential climate crisis which has been building since the onset of the industrial revolution (Jonsson, 2012). Information systems (IS) scholars continue to debate our contributions to tackle climate change and sustainability. In response to the global climate crisis, we are being called upon to “develop suitable theoretical frameworks to underpin the investigation of complex phenomena and complex problems” on a societal level (Hasan, Smith, & Finnegan, 2017, p. 298). In response to any crisis, however, we know that to develop and deploy resources effectively, an IS must produce an accurate, reliable, and trustworthy assessment of the situation at scale (Bunker, 2020). The key to achieving this 'situational awareness' is the development and implementation of an accepted approach to complex information governance for response to societal problems and crises (Bunker, 2020, Smith and Stirling, 2008, Nüttgens et al., 2011). How the value, authenticity; accuracy; reliability; and legality of information is determined, controlled, and assured through acceptable governance mechanisms, is at the heart of how information is represented and used to develop situational awareness and support sustainability goals for climate action ". the ways in which these representations are articulated into knowledge that structure our overall understandings" (Smith & Stirling, 2008 - p. 2). Complex information governance has, however, been shown to be difficult to assure as seen in the financial market failures of 2001 and 2008 and more generally in the response to the current COVID-19 pandemic. Information governance is defined as "a collection of competences or practices for the creation, capture, valuation, storage, usage, control, access, archival, and the deletion of information and related resources over its life cycle" (Mikalef, Bourab, Lekakos, & Krogstie, 2020). IS research on information governance, however, has mainly focussed on big data analytics and organizational innovation for formal IS. Far less is known about information governance in complex scenarios where formal IS and informal social IS might combine to jointly produce situational awareness on which to frame a response. Yet we know of many cases where trusted situational awareness, dynamic organizational collaboration and multi-stakeholder decision support have been produced by combining formal and informal IS. These include adoption and use of: – a cloud-based, freely available IS used by environmental non-government organizations (ENGO), for eco-collaboration activities in a structurally dynamic manner based on the NGO national context i.e., Thai, Lebanese, Australian (Aoun, Vatanasakdakul, & Bunker, 2011). – a combined open social media platform and proprietary job scheduling system to communicate with and organize a student volunteer army during the Christchurch Earthquakes (Bunker, Ehnis, Seltsikas, & Levine, 2013); and – an open social media platform for dynamic communication, coordination, and collaboration activities during Hurricane Harvey (2017) by emergency management agencies, media organizations, journalists, private individuals, celebrities, politicians, and influencers who took on the roles of information starters, information amplifiers and information transmitters (Mirbabaie, Bunker, Stieglitz, Marx, & Ehnis, 2020). These cases highlight an emerging need for development of effective complex information governance approaches for IS, using dynamic organizing principles. Lee, Zhu, and Jeffery (2019) researched information governance and data management for these types of platform 'ecosystems'. While they focussed on data governance and practices, they did not directly address the complexity of information governance where trusted situational awareness/consensus is developed at a societal level from a combination of formal and informal IS. In order to conceptualize and understand complex information governance for development of trusted situational awareness and response at scale, transitions may hold the key i.e. dynamic co-evolutionary processes that evolve from the "interplay of many unlike, particular processes" (Kemp, Parto, & Gibson, 2005, p. 23). Transitions present us with an opportunity to develop approaches for complex information governance as they are "aimed and guided in an iterative, forward-looking, adaptive manner, using markets, institutions and hierarchy (the three basic forms of coordination)" (Kemp et al., 2005, p. 23). These three forms of coordination are critical 'global levers' for climate action so consensus regarding information governance at a transitional level is crucial for achievement of situational awareness, development of sustainability response/goals and resulting action. The key components or mechanisms of complex governance for social sustainability include: policy integration, common objectives, criteria, trade-off rules and indictors, information and incentives for practical implementation and programs for system innovation (Kemp et al., 2005). “The most significant challenge is to ensure that multi-player governance regimes embody capacity for sustainability-oriented co-ordination, direction and re-direction” (Kemp et al., 2005, p. 18). This can be achieved through the nature and dynamics of autopoiesis or self-producing/constructing physical systems (Bunker et al., 2013, Mingers, 2002, Mingers, 2004). These systems are: self-producing; contingently maintained (so that they don't breakdown); structurally open but organizationally closed; structurally determined; able to be structurally coupled to other systems by mutual specification and/or co-evolution; and able to embrace embodied cognition and self-reference/recursion to enable self-construction/production (Mingers, 2002, p. 280). Transitional processes combined with the nature and dynamics of autopoietic systems, provide IS scholars with a theoretical basis for complex information governance development. The use of both formal organizational IS and informal personal/social IS in disaster management and crisis response, has been rapidly co-evolving at scale over the last decade (Ehnis & Bunker, 2020). While IS scholars have mainly focussed on information governance approaches for formal organizational IS, the self-producing/constructing attributes of hybrid IS which combine elements of the formal and informal have been largely ignored. The negative aspects of social systems and platforms and their combination/integration with formally managed and governed IS, have presented society with many problems (Elbanna, Dwivedi, Bunker, & Wastell, 2020). There is, however, potential for their management and use to effect positive outcomes for social sustainability and the response to the global climate crisis, if approaches to complex information governance are developed and implemented by IS scholars and practitioners. Currently there is a global focus on the importance of science, technology, engineering, and mathematics (STEM) education, but more recently there have been calls for a reframing of STEM from techno-science, towards a science of reconnection with nature (Smith & Watson, 2020). IS courses and training can therefore, make a valuable contribution to the development of complex information governance for social sustainability at scale by developing and delivering units of study that focus on: 1) complex information governance and leadership for social sustainability - frameworks, concepts, descriptions, rules and communications approaches based on transitions and autopoietic systems; 2) how to work in large and diverse teams - understanding, implementing and accommodating approaches to complex information governance; 3) and understanding the information governance of global supply networks and logistics for sustainable development goals. 3.5.3. Contribution 21 – climate change – IT – Data Science perspective – Ms Jeel Dharmeshkumar Shah The world’s climatic conditions seem to deteriorate every day, and the evidence from the research(Shaftel, 2021) held at NASA further bolsters this claim. The researchers at NASA further believe that the unprecedented warming trends today are the effect of human actions. Since most of these actions involve the development or use of technology, it certainly plays a significant role in climate change. The world today seems to be in a state of quandary. Whether to restrict the use of technology or invest in further research in the same field is a concern. However, in this case, I believe that the cause is the solution- just like the snake venom that is fatal for humans but is also proven to be medicinal and used to save lives. When the problem is so complicated, the solution must also be four-fold; we must take the System-of-Systems (SoS) approach. We must be able to analyze the dependencies of various systems - such as human, environmental, physical and information systems- which the SoS framework can enable. This could be a holistic approach to finding possible solutions to this complicated issue as it provides a good understanding from all viewpoints. Data Science is a required field for this discussion as it can analyze all forms of data and help automate crucial decisions. ‘Green Technology’ is expected to transform our society. The Climate Group, in their report, estimates that smart technologies such as smart homes/buildings, smart transport and logistics, intelligent agriculture management systems and smart electricity grids are a few of the various ways that can help reduce greenhouse emissions. It is Data Science that makes these technologies’ Smart’ or ‘Intelligent’. While Big Data provides a platform for processing large chunks of heterogeneous data, Data Analytics and AI help analyze this data and identify trends (with the help of machine learning to identify main features and make predictions). This intelligence is then used in business to make informed and calculated decisions. Cloud computing can further be used to accelerate the process, and IoT could help apply these efficiently in a practical scenario. Analyzing the foot-fall data of various public transport systems, for example, could help identify efficient routes, and this ‘Smart Transport System’ would then optimize its fuel consumption and aid in reducing carbon footprints. Another such example would be a ‘smart air conditioning system’ that collects, compares and analyses weather and usage data to develop plans that optimize economic and environmental savings—solutions such as these help tackle issues regarding the sustainability of the climate. Various techniques followed by the Data Scientist aid this kind of analysis. Classification is one such technique that draws meaningful information and differentiates the data based on similarities found in its attributes. Artificial Neural Networks (ANN) can also be utilized in many practical scenarios for cause and effect analysis. One such example is the study carried out in the United States that used this technique to identify the factors affected due to differences in hydro-climatology of two different streams. This study successfully inferred how the differences affected the average runoff, flow stability(from baseline) and frequency of floods in the two areas (Poff, Tokar, & Johnson, 1996). Further improvements in the climate model were also made in 2003 (Knutti, Stocker, Joos, & Plattner, 2003) to increase its efficiency with larger datasets. Calculations from this model revealed that almost half the members surpassed the surface heating range that the IPCC estimated earlier. In such challenging scenarios, neural networks can help extensively. It is all used to explore the general trend in climate change and its mechanisms to identify the hidden correlation/attributes in the data that is otherwise not decipherable. The use of Solar energy has become increasingly popular today as it is a renewable source of energy. One of the major drawbacks of this form of energy is that its availability widely depends on meteorological conditions. The efficiency and performance of a solar power plant would depend on these changing conditions. Jang, Bae, Park, and Sung (2016) has discussed how we can leverage images captured by the satellite to train a SVM (Support Vector Machine) model and predict the motion of clouds. This could be a brilliant way to determine when the plant would be most productive and when it would require backup. In this way, data analytics could help manage climate changes for uninterrupted and effective energy production. Climate change also significantly affects coral reefs that are important for the ecosystem as they provide food and shelter for their inhabitants. Thermal stress due to the warming of the ocean could cause infectious diseases, while frequent intense storms could lead to the destruction of the reefs. A rise in sea levels could lead to sedimentation, whose runoff can destroy the corals, while fluctuations in precipitation lead to an increase in runoff that could make the water murky and restrict the light. One such study (Franco, Hepburn, Smith, Nimrod, & Tucker, 2016) conducted in 2016 used the Bayesian Network approach to evaluate how climate change disturbances affected the coral reefs. The study revealed interesting results identifying the factor that contributed the most to the carbonate budgetary state of the reef and concluded that the change in the state of the reef was mainly due to the decrease in water quality (Franco et al., 2016). Data Science offers a plethora of such techniques that can be applied in the majority of challenging scenarios. It can help in the acquisition of environmental data as well as monitoring and analyzing it. This can help take immediate actions in case of an emergency or check if an industry is compliant with the pollution control requirements. Remote sensing and continuous data monitoring improve data availability that is the foundation for Data analysis. Risk analysis is another critical feature that can be used in combination with IoT enabled devices to send real-time alerts in case of high-risk prediction. These alerts and controls maintain safety by keeping a check on potential hazards. Results drawn from such analysis could also aid in finding sustainable alternatives. These advantages are very beneficial for governance, and the government has collaborated with the IT industry in developing and launching schemes that help alleviate the environmental conditions. The ‘National Clean Air Programme (NCAP)’ was established in 2020 by the central government that is predicted to reduce 20–30% of particulate matter concentration in 4 years by 2024 (NCAP, 2020). Another such flagship scheme introduced by the government is the ‘Namami Gange Programme’ that aims to reduce water pollution, conserve effectively and revive river Ganga (Namami Gange Programme, 2020). With the enormous number of benefits and applications, Data Science, in my opinion, has not yet reached its full potential. This is because ‘Data’ forms the foundation of Data Science, and without accurate and complete data, ambitious goals can be challenging to achieve. A recent paper published on the 10th of October 2021 (Callaghan et al., 2021) successfully collected enough evidence to conclude- based on mapping of 10000 attributes- that almost 80% of the land area globally is affected by climate changes caused by human actions. This is an excellent insight although the researchers also identified the ‘attribution gap’. Though the paper could draw important information about global climate models, it failed to understand the impact of climate on low-income countries. This was because they were unable to collect enough data from these regions. Shruti Nath, a researcher at Climate Analytics, said, “Developing countries are at the forefront of climate impacts, but we can see in our study there are real blind spots when it comes to climate impact data. Most of the areas where we are not able to connect the dots attribution-wise are in Africa. This has real implications for adaptation planning and access to funding in these places” (Mercator, 2021). Although curation of data and its quality remains a problem, my belief in the potential of this field stays unaltered. Though there are many hurdles on the way, Data Scientists are working hard in fighting these challenges and coming up with new and improved solutions every day. 3.5.4. Contribution 22 – the IS/IT in addressing the challenges of climate change – Dr Matti Mäntymäki 3.5.4.1. Need of increased attention to the sustainability implications of IS/IT Digital services, platforms, and infrastructures consume significant amounts of electricity globally. On the other hand, digital infrastructures consume electricity. From this vantage point, for example Bitcoin can hardly be considered an environmentally sustainable technology. Moreover, the upgrade from HD to 4–8 K quality in video has an effect on the energy consumption of the devices such as smartphones and tables used to watch the videos. Considering the global smartphone penetration, energy consumption of smartphones is a significant sustainability issue. All in all, this calls for increased attention to the sustainability implications of IS/IT development and operations. This in turn requires that sustainability impact of digital services, platforms, and infrastructures be measured and monitored in a reliable and transparent fashion. 3.5.4.2. Reducing digital waste through IS/IT design As the volumes of data being created, transmitted, and stored have skyrocketed also the volumes of ’digital waste’, i.e. unused digital content, have surged. To provide some perspective of this phenomenon, CO2 emissions of YouTube in 2019 was evaluated to equal a city size of Glasgow.7 A well-known example of how IS/IT design could reduce CO2 emissions is not to show video for users who are only listening to audio. This idea of digital waste reduction videos could be taken a step further by default by asking the user if he/she wants to see the video in addition to the audio content. In addition, energy efficiency can be considered in website design. Typically, today’s websites are dynamic. While this design approach offers benefits in terms of user experience, it basically requires that the server hosting the website creates the website for the user. A static website that is stored on the server and updated on a 12-hour or 24-hour interval is considerably more power efficient. 3.5.4.3. Research-based decision-making to accelerate adoption of ‘green initiatives’ Resulting from the increased innovation around Greentech, there will be various new technological solutions to address the challenges of climate change. The effectiveness and impact of technological tools is dependent on their successful implementation as well as adoption and use by the users. The academic IS community has worked on technology adoption for decades and the individual-level technology adoption has evolved to be one of the most mature areas of academic IS research (Venkatesh, Davis, & Morris, 2007). Hence, the IS community is well-equipped to contribute to the deployment of various technological solutions targeted to fight climate change. 3.5.4.4. Sharing economy and circular economy as a means towards more resource-effective societies The sharing economy is one way for existing resources to be used more efficiently (Sutherland & Jarrahi, 2018). Sharing economy at scale is typically executed through digital platforms. Digital platforms such as Uber are famous for leveraging data, advanced analytics, and artificial intelligence to predict and balance supply and demand. Another mechanism toward a more resource-efficient society is the circular economy. It is evident that executing a circular economy requires implementation of digital infrastructures where the physical and digital elements go hand-in-hand (see Lee, 2008; Rajkumar, Lee, Sha, & Stankovic, 2010). 3.5.5. Contribution 23 – the value of information management in the built environment to tackle climate change – Mr Henry Fenby-Taylor The built environment is made up of sectors that have an outsize responsibility when it comes to the future of our planet. It provides us with our economic infrastructure – power lines, roads, railways, utilities, as well as our social infrastructure of homes, schools, hospitals and so on. Yet it also contributes around 40% of the UK’s total carbon footprint, according to the UK Green Building Council. There is a real sense of urgency that this needs to change. Industry leaders are increasingly in consensus that they need to prioritize how they mitigate and adapt to climate change, as well as reduce emissions. 3.5.5.1. Unlocking the value of data Critical to tackling climate change in the built environment will be the use of Information Management. It is currently a vast, largely untapped resource that will be pivotal in transforming the decision making process. At its core, Information Management is about making efficient use of resources – it’s about transforming information about the lifecycle of built assets into actionable intelligence. Effective information management gathers information across the lifecycle of assets from design to creation to operation. At each of these stages, data is collected that informs better decision making, enabling reductions in waste, time and cost, more efficient use of resources, improved design and safety and increased infrastructure resilience – all essential for reducing carbon emissions from our built environment and serving those it was intended for. Although we have the technology to collect large amounts of data it needs to be structured, managed and shared in an effective way to make it valuable. The Centre for Digital Built Britain (CDBB), through the National Digital Twin programme (NDTp) is creating the Information Management Framework which is a collection of open, technical and non-technical standards, guidance and common resources to enable secure and resilient sharing of data across sector and organizational boundaries. There are already some excellent examples of successful green Information Management in practice. The Energy and Carbon Reporting Framework developed by the CDBB, WMEBoom and the Construction Innovation Hub defines when operational energy and emissions need to be analyzed and reported during the lifecycle of built assets. This tool is providing organizations like NHS Scotland and their supply chain the ability to effectively identify and therefore control the energy and carbon impact of their built assets. It also supports the Construction Leadership Council's CO2nstructZero programme which sets out how the construction sector can meet the Net Zero challenge. 3.5.5.2. Sharing data to improve climate resilience The sharing of data is an important part of the process. At the NDTp, the Climate Resilience Demonstrator (CReDo) provides a practical example of how connected data and greater access to the right information across organizational and sectoral boundaries can improve climate adaptation and resilience. Collaborating on CReDo are Anglian Water, BT and UK Power Networks who will use their asset and operations data as well as weather data on a secure, shared basis to inform an increased level of infrastructure resilience. CReDo will integrate data between energy, water and telecoms networks to improve climate resilience decision-making across infrastructure systems. 3.5.5.3. Fit for the future Although it is clear we should be pushing towards a green information economy, there remain hurdles - we need a workforce with the appropriate skills who can make it happen. Our work at the CDBB has a socio-technical focus and part of this is balancing the technology with the people aspect. That is why we commissioned a Skills and Competency Framework report, a joint collaboration between Mott MacDonald, Lane4 team and the Construction Innovation Hub, that sets out the key roles and skills needed. It is a very practical framework that allows organizations and individuals to assess their own needs and consider how to address them. 3.5.5.4. A shift in culture Data is no longer a commodity to be hoarded, but a resource to be shared. If industry and government are serious about tackling climate change there needs to be collaboration and there needs to be interoperability between information management systems, so that we use all the data we have in a relevant, impactful way. 3.5.6. Contribution 24 – What can information technology and systems researchers and educators do to mitigate climate change? – Dr Wu He To respond to climate change, a significant threat to the United States and the world, the U.S. National Academies of Sciences, Engineering and Medicine has convened a committee of experts and published a report in 2021 to highlight the need for transforming the world's energy system to one with net-zero emissions of carbon dioxide (CO2) by 2050 (NASEM, 2021). The report emphasizes the need to invest in new technology, expand innovation toolkits, and reduce the cost of existing technology in a socially just way. My Views on the above four questions: 3.5.6.1. Energy Use and Technology The information management, information technology, and information systems sectors highly depend on computers, sensors, and a wide variety of physical and electronic devices. However, the production and use of computers, sensors, storage devices, and other electronic devices require a tremendous amount of energy, contributing to greenhouse gas emissions and causing harm to the environment. For example, data centers consist of a large number of servers and computing resources interconnected by high-speed networks, which need to work nonstop 24 × 7. Data centers have to rely on cooling systems to ensure all those machines do not overheat. Such cooling systems consume a lot of energy. The United States Data Center Energy Usage Report (Shehabi et al., 2016) indicates that data centers in the U.S. alone likely consumed approximately 73 billion kWh in 2020. Energy efficiency strategies and technologies, including AI and data analytics, could help monitor data centers’ energy usage and significantly improve energy conservation to reduce cost and carbon emissions. Google has reported using AI to reduce energy consumption in its data centers by as much as 40% (Evans & Gao, 2016). 3.5.6.2. Potential of information technology on mitigation of climate change Information technology has great potential to increase the energy efficiency of buildings, transportation systems, manufacturing, supply chains, power grids, infrastructure, and agriculture, enabling sustainable solutions for energy consumption and usage. Low-cost internet of things (IoT) sensors and devices (e.g., smart thermostats, smart humidifiers, smart air purifier, smart air conditioner, smart fans, smart blinds, and so on) have been used to reduce energy consumption and achieve long term cost savings by tailoring climate-control according to real-time needs and lifestyle of people and their schedule (either in the building or away). Teleconferencing, telemedicine, e-commerce, and e-learning technologies are playing a role in reducing unnecessary travel and thus reducing total emissions into the environment. These sensor-based technologies can continuously collect massive amounts of environmental data to measure emissions and other relevant parameters and adjust based on optimal standards or human preferences and needs. Big data analysis and visualization can be leveraged to unlock insights that will help individuals, organizations and communities track electricity consumption patterns, identify energy leaks, improve energy use efficiency, and find creative ways to conserve energy and adapt to climate change faster and better. 3.5.6.3. Suggested research agenda on climate change Several potential research ideas on climate change for information management, information systems, and technology researchers are listed below: • Conducting empirical research to collect first-hand evidence and develop evidence-based guidelines and suggestions to help practitioners design and implement Green IT(green information technology) and Green IS (green information systems) initiatives within their organization. Green IS (green information systems) refers to the use of information systems to achieve environmental objectives. In contrast, Green IT (green information technology) refers to the practice of environmentally sustainable computing and emphasizes reducing the environmental impacts of IT production and use (Dedrick, 2010). Green IT/IS can help reduce the negative consequences of technology production on the environment and contribute to sustainable solutions, including environmentally sustainable business processes, practices, and end products in organizations and communities (Boudreau, Chen, & Huber, 2008). • Studying the adoption of energy-saving IT in locations like home, businesses and communities, and assessing the impacts of information technology innovations on human behavior, mitigation of climate change, and relevant policymaking. • Conducting design-based research on designing and developing AI-based techniques, modeling and simulation, decision support tools, games, visualization, and other technologies or approaches that help the general public visualize and understand possible impacts of climate change. • Studying the use of games, mobile apps, augmented reality/virtual reality/mixed reality and other technology innovations in promoting environmentally sustainable behavior that contributes to climate change mitigation. Such studies could help understand the role of human behavior in achieving climate change mitigation strategies, reveal insights why people choose to engage in specific environmentally sustainable behavior or not, develop innovative approaches, policies, best practices, and solutions to climate change (Douglas & Brauer, 2021). 3.5.6.4. IT/IS education on climate change This generation and future generations need to understand the impacts of climate change on our daily lives and society. IT/IS education could play a critical role in helping individuals and communities in the understanding of the science behind climate change and what steps are needed to alleviate greenhouse gas emissions and global warming caused by climate change and human activity. IS/IT educators could use project-based or problem-based learning approaches to engage students to explore specific climate change issues and community-related climate datasets (e.g., heat, cold, rain, drought, snow, wind, river, lake, ocean, water quality, air quality, and coastal flooding) and to assess the impact of potential solutions by leverage existing software, tools and techniques such as data analysis and visualization, modeling and simulation, augmented reality/virtual reality/mixed reality, and AI techniques. When students are asked to use technology tools to explore specific climate change issues and datasets of interest or relevance to their local communities, they are more likely to become interested and engage in active learning for systems thinking, complex problem-solving, creativity, and evidence-informed decision-making. In the meantime, they will become familiar with these software, tools, and techniques through learning by using them to analyze data and solve problems in a meaningful way. Students will have a chance to develop interdisciplinary skills to interpret complex data analysis and visualization results into informed decisions and sound policies. The ability and skills to interpret data and communicate results to support the decision-making process are important for IT/IS students to become effective decision makers or problem-solvers in their careers. IS/IT educators are recommended to come up with concrete learning activities, to develop technology-related case studies, tutorials, projects, and exercises on the topic of climate change, and to encourage their students to work on collaborative or hands-on projects using open-source resources, including various datasets and open-source software and tools available on the Internet, such as CODAP, R, Python, and more. There exists significant levels of climate change, open-source projects on GitHub, which is an excellent way for IT/IS students to learn, practice, and contribute. 3.6. Technology and IS research agenda 3.6.1. Contribution 25 – holistically missing: climate change and information systems research – Professor Samuli Pekkola 3.6.1.1. Introduction and related activities In Finland, the Ministry of Transport and Communications recently published a climate and environmental strategy for the information and communication technology sector (Ojala & Oksanen, 2021). The strategy defines ICT related objectives and measures for carbon-neutral Finland, paying attention to ICT infrastructures and their energy efficiency, making recommendations on energy aspects in software and service procurement, considering material flows and recycling of the devices, suggesting energy consumption statistics on data centers, and increasing awareness of energy specific issues of software and hardware. These areas and objectives, and their measures are evidently impactful on climate change. They increase awareness and provide general goals. Unfortunately, the strategy pays no attention to how the use of ICT impacts on climate and environment. The use aspect is touched, for example, in the European Commission’s ICT for Sustainable Growth (2021) program, where, similarly to Estonia (2018), UK (Howes, 2020), and Norway (2016), the point of foci is on sustainable economics, not on sustainable ecology, environment, green ICT, or climate change – whatever term is adopted. This means that, in practice, environmental issues and ICT are approached either sporadically with a narrow view and disconnected contexts, or indirectly in the context of economic growth and prosperity. Similarly, IT/IS literature sees environmental issues as something that the ICT managers should consider in their work. For example, Esfahani, Rahman, and Zakaria (2015) and Singh and Sahu (2020) summarized the green IS studies focusing on the benefits, adoption, design and implementation, or initiation of green IS projects. Loeser (2013) takes a more concrete approach and lists a variety of different contexts for green IS initiatives. Wang X. (2015), Wang Y. (2015)’s meritorious literature review parallels these and poses a set of research questions, all aiming to understand the green IS initiatives. In general, it seems that IS literature focuses the adoption of ideas of climate change into the IS activities and context. Comprehensive understanding about how to apply and use IT/IS to improve the situation regarding climate change seem to be scarce. 3.6.1.2. Towards a holistic understanding of IS and climate change The absence of comprehensive approaches is surprising especially after the lessons from COVID-19. For example, the amount of traveling decreased up to 90% in California due to stay-at-home orders (Schilling 2020). At the same time, air quality improved significantly (Eregowda, Chatterjee, & Pawar, 2021). People have learned new ways of working, learning, and living, without a need to travel to work, school, or anywhere. Although these settings of distant working, online learning, and online shopping, traveling, and leisure have been studied (c.f. Dwivedi et al., 2020; Pan & Zhang, 2020), the approach is again contextual: how to use IS in online meetings or education, how to provide or acquire goods, food, or services online, and how to manage and govern the IT (Herath & Herath, 2020). Contextual approach becomes problematic with the interconnectivity of systems and the systems of systems. For example during the COVID-19 pandemic, online learning tools have turned out to be quite efficient in conveying learning contexts to distant learners, although some learning-related difficulties have been identified (Chen and Roldan, 2021, Xie et al., 2020). Yet the difficulties may go beyond the learning contexts. Online activities have been reported to increase loneliness, disconnectivity with fellow students and teachers, distraction, mental problems, and increased workload (Maqableh and Alia, 2021, Pan and Zhang, 2020). These negative issues may have unpredictably long-lasting effects on learners: for instance, do they know the topics, have they made friends, and have they learned to interact in face-to-face situations? The quality of an online learning environment may have an impact on the rest of the learner’ life. Similarly, targeting green IS/IT activities locally may, or may not, be beneficial from the viewpoint of climate change. They may have unintended consequences similarly to online learning: activities seemingly beneficial in the short term may possibly be harmful in the long run. This notion leads to following research topics: • What are the long-term effects of green ICT investments? To climate and environment? To people: employees, learners, travelers, and their ways of doing, working, and living? To institutions? To firms and other organizations? To other parts of the system? • When do the benefits of green ICT investments exceed its investment costs? The example of an electric car illustrates this: building an electric car is more environmentally harmful than building a petrol car, but the tide turns when the car is used enough. What is this turning point for a green IT/IS investment? And most importantly: • How can ICT be used to improve the situation regarding climate change? Interestingly, we are studying how the ideas and isms of climate change and green ICT are adopted, but not how ICT should be used to reduce climate change. This has been touched by sustainable economic endeavors, but aren’t there any other values in addition to economic issues? 3.6.2. Contribution 26 – information technology and climate change – Professor Rameshwar Dubey Irresponsible human activities are well reflected in the form of rising sea levels, forest fires, extinction of some rare species, the meteoric rise in floods in many parts of the world, and fast-shrinking levels of safe drinking water. These are clear indications that human influence on climate systems is clear and growing (Wright & Nyberg, 2017). Whyte (2020) argues that it is now too late to avoid dangerous climate change. The negative effects of climate change have attracted significant attention from the world's top leaders, industry, media, and policymakers (Banerjee, 2001, Kolk and Pinkse, 2008, Mees et al., 2019). Some scholars argue that “climate change threatens irreversible and dangerous impacts,” that may have serious negative effects on people and ecosystems (Whyte, 2020), and to address the pressing global threat, there exists a unanimous call for an immediate reduction in carbon emission levels (Park, Byun, Deo, & Lee, 2015). Although the COVID-19 crisis has caused severe discomfort and impacted human lives in significant ways, studies have identified signs of some positive and visible regional effects on the planet (Khan, Shah, & Shah, 2021). This could be easily explained by a change in behaviors during lockdown that has reduced human activities such as transportation, irresponsible consumption, production, and industrial activities. In the last two years, there is some evidence of an improvement in the quality of air, water and the environment looks greener and cleaner than it used to be (Everard et al., 2021). This change has been possible due to the role of emerging technologies, (Dwivedi et al., 2020, Pan and Zhang, 2020). Many scholars have found positive effects from emerging technologies on environmental sustainability: big data and predictive analytics capability (Dubey et al., 2019), blockchain technology (Saberi, Kouhizadeh, Sarkis, & Shen, 2019), AI (Nishant et al., 2020), and cloud computing enabled supply chain design (Shee, Miah, Fairfield, & Pujawan, 2018). However, the COVID-19 crisis has further accelerated the debate on “how information technology capabilities or information management scholars” can help tackle climate change (He, Zhang, & Li, 2021). Despite the general optimism in the role of environmentally friendly technologies or emerging technologies in tackling climate challenges, some developed and developing economies, industry and global corporations still remain skeptical about the role of information technology in tackling the climate change crisis (Teräväinen et al., 2014). Wright and Nyberg (2017) argue that the organizations in pursuit of their economic gains have in the past lobbied against carbon emissions initiatives and further delayed constructive action. Despite the rich body of literature on the corporation's initiative towards mitigating the carbon emissions problem (Banerjee, 2001, Wright and Nyberg, 2017), organizational/ management/ information technology scholars have an important role to play particularly in addressing the climate change crisis. There is a need for theory-driven research that provides an in-depth understanding of both the causes and possible solutions to tackle climate change. We note some clear research gaps in the academic literature and posit the following research questions that may help bridge the gaps in our understanding and the expected role of the information technology /emerging technologies in tackling the climate change crisis: a. How AI-enabled predictive analytics techniques may help identify some of the economic activities in some parts of the world which are contributing to carbon emissions? b. How the use of distributed ledger technology (DLT) and AI can help identify the role of some corporations involved in unethical practices that led to contamination of water bodies and deforestation? c. How the use of AI enables predictive analytics to detect issues during logistics and transportation within developing economies thereby contributing to a reduction in carbon emissions? d. How AI-enabled technologies can help build swift trust and collaboration among the stakeholders engaged in tackling the climate change crises? 3.6.3. Contribution 27 – blockchain and climate change – Dr Daniela Andreini Of all technologies in place in the market, the one I know best is the blockchain. This technology has environmental, social and economic impacts, and in these few words, I would like to focus on the ecological aspects. 3.6.3.1. How IM/IT/IS sector has any negative impact on the environment and how it can be reduced Like any other technology, blockchain creates a digital ecosystem composed of multiple hardware devices, program files, and different actors' data files. Another critical component of the ecosystem is interacting and exchanging cryptocurrencies, files, information, etc. The sustainability of the blockchain is controversial; for instance, O'Dwyer and Malone (2014) stated that the energy consumption of the Bitcoin mining network is comparable with the Ireland electricity consumption. In the same way, we can think about the energy and infrastructural consumption of all the IM/IT/IS systems that cause enormous energy and infrastructural consumption and thus a tremendous environmental impact. 3.6.3.2. How IM/IT/IS can be utilized to improve situation regarding climate change At the same time, other authors demonstrated that the artificial intelligence and IT ecosystem could find more efficient ways to create and exchange information and virtual services. For instance, for what concerns bitcoins, Dimitriou and Karame (2013) demonstrated that in mining bitcoins, if a miner can create a block more efficiently and speedily than another one, the system will substitute the less efficient miner with the most productive and profitable one. This mechanism drives the entire system towards a more effective way to use and consume energy and infrastructures. Thus, the IM/IT/IS systems can be the sources and the solution of energy consumption and dispersion. 3.6.3.3. A brief discussion on research agenda related to IM/IT/IS and climate change The cost and climate impact of blockchain are strictly related to its diffusion. For instance, in this historical moment, the substitution of traditional currencies with bitcoins in our monetary system would be too expensive in energy consumption, and thus it could not be sustainable. Therefore, in finance, for instance, more research is needed to understand how the two monetary systems can coexist efficiently. The same thing can be extended to other IM/IT/IS systems: virtualized and physical transactions should coexist to balance environmental, social, and economic systems. 3.6.3.4. How IS/IT education should reflect this Experimentation in education is relevant, and more educational systems should turn into laboratories, where institutions should offer problem-solving driven teaching methods. 3.6.4. Contribution 28 – towards a relevant agenda for environmental issues within KM/IM/IS/IT – Professor Johan Olaisen The climate crisis is the largest threat to civilization we have ever faced. The Intergovernmental Panel on Climate Change (IPCC) report in 2018 made the science very clear. There are significant climate impacts all around the world even if we limit warming to the recommended 1.5 C. The report also showed there are significant increases in impacts and damages between 1.5 and 2.0 C. These results were fully supported by the IPCC science report (2021). We are building our living standards upon coal, gas, and oil, and few of us want to change our lives, and new global generations are coming that want our living standards. Every corporation wants to be green and practice sustainability even if the reality of the image is most often an illusion or just a fashion (Jevnaker and Olaisen, 2021aaa, Jevnaker and Olaisen, 2021bbb, Jevnaker and Olaisen, 2021aac, Jevnaker and Olaisen, 2021bbd). What is the research situation within knowledge management (KM), information management (IM), information technology (IT) and information system (IS) research? We investigated all academic papers 2016–2020 (N = 481) delivered at the European Conference for Knowledge Management (ECKM). We found that less than 5% of the papers investigated climate issues and concluded that the KM/IM/IT/IS potentially harms environmental-climate issues owing to neglect (Jevnaker and Olaisen, 2021aaa, Jevnaker and Olaisen, 2021bbb, Jevnaker and Olaisen, 2021aac, Jevnaker and Olaisen, 2021bbd). All research consists of problem, knowledge, and methodology sentences. We get traditional pragmatic business-as-usual research when there is an over-focus upon methodology and knowledge sentences and a low focus upon problems. We must start to ask the research questions about environmental and sustainability issues. Through verification and falsification (Popper, 1974), research is expected to come up with theories, paradigms, perspectives (Kuhn, 1962) that explains and explores practices that we may evaluate, giving us either empirical research or critical research (what is acceptable/not acceptable) or constructed research (what is adequate and what is not adequate). Most research is empirical, and to get more focus upon environmental issues, we must get more constructed and critical research setting up the green and sustainable agenda. We must ask the essential questions about if the academic papers involve acceptable or not acceptable climate solutions or if the papers are adequate or not adequate for relevant climate issues. Fig. 3 presents the model of the climate crisis issues within information research. Download : Download high-res image (125KB) Download : Download full-size image Fig. 3. Towards an agenda for handling the climate crisis in information research. Research deals with four paradigms: the empirical, the materialistic (political), clarified subjectivity, and action papers. Jevnaker and Olaisen, 2021aaa, Jevnaker and Olaisen, 2021bbb found that nearly all papers might be classified as empirical and as a form of clarified subjectivity papers in harmony with accepted problems, methodology, and knowledge. We must invite papers in conflict with accepted problems, methodology, and knowledge. These papers will be representing the materialistic political and action paradigms. We must ask how research papers, often in conflict, contribute to climate issues. To get green and sustainable papers, we must get more problem-focused research on climate issues, more critical and constructed papers, more exploring papers built upon sensitizing concepts and less upon definitive concepts, and more political and action-based papers. Most of all, we need editors and conference chairs dedicated to climate issues asking for adequate and critical papers on this topic that might be political, action-based, and problems often based in conflict with existing issues, knowledge, and methodology. A political economy paradigm for the climate crisis in information research is a complement to presently prevailing concepts. KM/IM/IS/IT research and papers might be utilized to be a knowledge café, outlet, and center for environmental issues and perspectives. We might develop an environmental paradigm for relevant KM/IM/IS/IT research. We might define another future for societies and organizations. We might be giving the picture of a pluralistic sustainable future and even a utopia (More, 1973). We already have the experience through AI and robotics forming the fourth industrial revolution and solving the environmental issues is the fifth industrial revolution based upon the perspectives from KM/IM/IS/IT research. The paradigms within information research focusing upon the climate crisis area as described in Fig. 4: Download : Download high-res image (154KB) Download : Download full-size image Fig. 4. Information research paradigms for use in the climate crisis. The objective and agenda of IS/I/IT/KM research strategy for sustainability are to help to promote knowledge, information, systems, and technology that will: • Resolve national and global challenges relating to sustainability in corporations and societies • Facilitate industrial development that enhances sustainability and increases green competitiveness • Promote the innovativeness and creativity for sustainable solutions • Such objectives will include areas like: • Reduced climate change and effective adaptation measures • Preservation of ecosystems services and lower environmental impacts • Sustainable cities, corporations, regions, and transport systems • The circular knowledge economy The IPCC, 2018, IPCC, 2021 have mentioned five areas: Food and ecology, Sustainable cities, Energy and material, Health and wellbeing, Transportation. IT/IS/IM/KM are mentioned as essential for all these areas, and there is a need for developing the areas into issues for journals and conferences. The identified focus for research within information research is in Scandinavia sustainable private and public cases where the green and sustainable practices are documented. These cases should be developed into model cases for KM/IM/IS/IT. The cases should be used as action research cases promoting a sustainable practise (Jevnaker and Olaisen, 2021aaa, Jevnaker and Olaisen, 2021bbb, Jevnaker and Olaisen, 2021aac, Jevnaker and Olaisen, 2021bbd). The Scandinavian impact model might look like Fig. 5: Download : Download high-res image (118KB) Download : Download full-size image Fig. 5. The Scandinavian impact model of information research. An important issue is how KM/IM/S/IT in higher education should reflect the environmental issues. Education that ensures future competencies upon sustainability, reuse, and environmental issues is essential. Environmental, green, and sustainable practices are an essential part of green education. Green KM/IT/IM/IS practice in action will be significant to get the students to participate in the transformational changes. The students must understand how different practices influence the environment. I have developed an executive program at BI (Oslo) “Sustainable leadership-in-action," where sustainable practices are discussed and reflected upon through collaboration with Norwegian businesses and the participants' experiences and where the students project paper is an empirical paper reflecting and learning from green practices with a synopsis as a reflection upon how they have implemented sustainable practices in their organizations. Ideally, should environmental issues be a part of all programs. KM/IM/IS/IT are innovative and creative tools for the solutions to environmental issues. Let COP26 also be the starting line for new objectives, areas, and education within KM/IM/IS/IT. We have every tool we need within information research to help to reduce and tackle the climate crisis. Let us all contribute!. 4. A brief overview of full opinion articles related to this theme This section outlines an appraisal of the selected full opinion articles related to this theme included within volume 63 of IJIM. Each study covers one or more themes related to the overall climate change and emissions reduction agenda, together with the views of the authors on the key specific technology and IS related topics. The following table (Table 4) lists the full selection of the full opinion articles. Table 4. List of full submitted articles on climate change, IS and technology. Authors Title Ågerfalk, Axelsson, and Bergquist (2022) Addressing climate change through stakeholder-centric Information Systems research: A Scandinavian approach for the masses Brooks, Cannizzaro, Umbrello, Bernstein, and Richardson (2022) Ethics of Climate Engineering: Don’t forget technology has an ethical aspect too. Laukkanen, Xi, Hallikainen, Ruusunen, and Hamari (2022) Virtual technologies in supporting sustainable consumption: From a single-sensory stimulus to a multi-sensory experience Papadopoulos and Balta (2022) Climate Change, Big Data, Big Data Analytics, sustainability, challenges Papagiannidis and Marikyan (2022) Environmental Sustainability: A technology acceptance perspective Pee and Pan (2022) Climate-Intelligent Cities and Resilient Urbanization: Challenges and Opportunities for Information Research Pan, Carter, Tim, and Sandeep (2022) Digital Sustainability, Climate Change, and Information Systems Solutions: Opportunities for Future Research Trkman and Černe (2022) Humanizing digital life – Reducing emissions while enhancing value- adding human processes. The opinion article by Ågerfalk et al. (2022), explores the Scandinavian perspectives on three current research projects where digital transformation is posited as offering a positive force in the fight against climate change and its impact on the world. The research viewed the climate change challenges from a stakeholder-centric perspective, emphasizing the criticality of closely involving people to engender the necessary change required in the design of digital technologies and the requirement for green IS researchers to engage in a collaborative context. It is vital that emerging technology focussed solutions, designed to combat climate change, take account of the necessary ethical dimensions and values from the onset to negate the potential scenario of technological innovations exacerbating the climate change problem. These aspects are analyzed by Brooks et al. (2022) where the opinion article highlights the importance of technologies delivering the required socio-economic impact through climate engineering solutions. Via a review of the relevant literature, the research reveals the disjointed nature of ethical dimensions in many cases, lagging behind emerging technological innovations. The study advocates a rebalancing of emphasis where ethical dimensions are an integral element of the climate engineering process. The opinion article by Laukkanen et al. (2022) argues for the usefulness of virtual technologies for changing human consumption behavior toward more sustainable consumption behaviors. The article argues that such technologies could provide greater opportunities to influence consumer decisions than the present digital environment. The article details a discussion on technology-assisted sensory marketing, cognitive and emotive aspects of virtual reality, and outlines applications of virtual reality technologies to encourage sustainable consumption. The opinion article led by Papadopoulos and Balta (2022), highlights the low levels of existing studies that focus on the role of Big Data Analytics (BDA) and impact of climate change, positing the potential opportunities for more sustainable operations and supply chains. The study assesses the challenges faced by operations and supply chains, asserting the contribution from BDA in providing a valuable role in the development of solutions to the myriad of climate related problems. Environmental sustainability from a technology acceptance perspective, is discussed in Papagiannidis and Marikyan (2022), where the opinion article highlights the dichotomy of technology negatively impacting the environment, whilst helping to manage and save precious natural resources. The research offers insights to the technology acceptance process from the sustainability perspective, arguing for a change in approach from researchers to be more cognisant of the impact of systems on the environment, thereby engendering environmentally compliant behaviors. Researchers have highlighted the valuable role of smart and climate intelligent cities in the transition from current high emission urban infrastructure. The opinion article by Pee and Pan (2022) calls for resilient urbanization to weather the impending climate shocks that are likely to materialize as a direct result of global warming. The research posits the role of IS research and its potential contribution to energy and resource optimization and the role of IS in the contribution to mitigating many of the current climate change related challenges. The opinion article by Pan et al. (2022) offers an Australia focussed perspective to approaching the climate change crisis highlighting the role of innovative technologies with huge transformative potential such as AI, analytics and IoT to tackle global warming whilst adhering to sustainable development goals. The researchers posit a research agenda that focuses on: climate resilience, climate-conscious citizen science, and substantive ESG strategies that can positively impact global warming. The key challenges related to redesigning the necessary human processes to eliminate environmentally harmful activities, while maintaining humans’ fundamental value proposition are discussed in the opinion article by Trkman and Černe (2022). The opinion article discusses a future world where humans transition from digitalization to a human digitalization, recognizing the critical role of government and research institutions for this change. The researchers highlight the role that technology can have in identifying, planning, enabling and executing the required changes in human behavior, as well as measuring and communicating their impact. 5. Discussion and recommendations This section elaborates on the expert contributions presented in Section 3, to reveal the key emphasis and emerging themes relating to digital technology, IS and climate change. We highlight the implications for government and society, and develop a number of key recommendations for policy, practice and education. 5.1. Expert Contribution Analysis A systematic analysis of the contributed articles was undertaken to offer a deeper insight to the key topics and underlying analytics. The analysis reviewed: a) the frequency of specific keywords mentioned in the articles, b) specific text features such as keywords, phrases and c) scores of polarity and sentiment analysis. Fig. 6 presents a word cloud view of the frequently occurring text from the submitted individual contributions. The analysis results highlight that the words: impact, sustainability, green, environment and smart are some of the significant and influential keywords emerging from the analysis of the contributed expert inputs. Download : Download high-res image (530KB) Download : Download full-size image Fig. 6. Word cloud analysis from top scoring words within invited expert inputs. Fig. 7 presents the polarity analysis of the contributed expert inputs. Most of the contributed expert inputs exhibit neutral polarity on the use of digital technologies and information management for climate change. If the neutral polarity is ignored, and the positive and negative polarity is compared, the majority of authors present a generally positive outlook for the use of digital technology and IS for combating climate change. This highlights the general consensus from the invited contributors, on the important role that technology can play in the global effort to reduce emissions to net zero by 2050. Download : Download high-res image (807KB) Download : Download full-size image Fig. 7. Polarity analysis of the contributed expert inputs. 5.2. Emerging Issues and recommended actions Whilst the views on the extent of the role of digital technology and IS in combating climate change vary amongst the contributors, there is general consensus that technology is an integral component of the overall solution, whilst at the same time - a fundamental aspect of the problem (Muregesan, 2008; Osibanjo & Nnorom, 2007). There exists a realization amongst many of the contributors that a more sustainable implementation of technology in all its forms, needs to be at the forefront of solutions to get to net zero, the mistakes of old cannot be repeated once more. A number of the submitted articles reference the negative impact of human behavior and people's attitudes in their day to day use of technology, positing the necessity for a transformative change in the way technology is developed, used and recycled. The expert input by Professor Davison illustrates these points specifically, highlighting the study by Clarke and Davison (2020), where the study asserts that very few studies within the IS research discourse, viewed the major challenges from the environmental perspective or included the environment as a key stakeholder. Professors Constantiou and Vendelø develop a narrative that highlights the potential use of technological solutions to facilitate the necessary change in human behaviors, citing how technology could be used to: identifying climate impact of transportation options, reduction in food waste via collaborative consumption and education on sustainable cooking. Behavioral influences from the community perspective in the context of faith and youth activism, are discussed in the expert inputs by Dr Abumoghli and Professor Panteli respectively, highlighting the important role of technology in building active communities that challenge the status quo. The expert input from Professor Metri cites the study by Junior et al. (2018) to highlight the woeful record of environmental sustainability from the technology industry, where the article posits the necessity of embedding the UN SDGs within technology design considerations and the potential of penalties for organizations that fail to change behaviors. The educational awareness and requirements for changed working practices, are discussed within a number of submitted articles, where these aspects are viewed from the technological perspective and impact on progress to net zero. The expert inputs from Professor Barlette and Drs Nishant and Teo identify the need for the IS community to educate more effectively to instil a greater awareness of the impact from technology adoption and the delicate balance between benefits toward net zero and contributing to the problem. The impact of climate change can be effectively monitored via the use of technology leading to a greater awareness amongst people to change their behaviors. These points are discussed in the expert input from Professor Tiwari where the article asserts the benefits of education at a community level, to empower people to gain access to knowledge and relevant data and assist vulnerable populations in the fight against climate change. The manufacture of technology based products relies on the use of precious and finite natural resources, at significant cost to the environment (Okafor, 2020). The expert inputs by Professors Rowe, Raman and Rana illustrate some of the negative impacts on the environment from the use of technology and the necessity for organizations to change their working practices to be more cognisant of the impact from the choices we make, the effect on the planet and support for the transition to environmentally friendly products. Professor Rana further emphasizes the need for education not just on climate change but also on how to use technology in a responsible way to help reduce carbon emissions and become ambassadors for sustainable living. The expert inputs by Professor Michael and Dr Abbas discuss the importance of a transition from current IS design practices to a more sustainability focussed approach and framework (Crow & Dabars, 2015), presenting a socio-technical sustainable design cycle for responsible systems design. A number of the expert contributions discussed perspectives relating to the impact of people and communities, where key aspects of technology can be used to ensure humans live and work with a “lighter touch” to conserve precious resources and attain net zero via the innovative use of IS infrastructure (Elbanna at a., 2020). The expert input by Professor Kodama references the increasing focus on smart communities in the form of smart cities where next generation social systems connect homes, buildings and transport, within an environmentally supportive infrastructure, highlighting the criticality of an emphasis based on IT collaboration to deliver meaningful change. The smart city contribution to reduced emissions is discussed by Professor Scholtz, where the contribution highlights the smart environment dimensions of smart cities (Van der Hoogen et al., 2020), and the necessity for addressing the necessary skills and educational requirements to ensure people can interact with smart infrastructure, thereby attaining the intended benefits and sustainable outcomes. The expert input from Professor De’ discussed the issues surrounding Green IS initiatives (Dedrick, 2010; Khuntia et al., 2018; Melville, 2010), and how digital technologies can counter the effects of climate change. The article highlights the need for a greater emphasis on gender rebalancing to counter the poor access to technology from women in developing nations and the disproportionate effect that environmental change has on women. Studies have posited the need for a greater focus on responsible digitization and corporate digital responsibility (Crawford, 2021; Lobschat et al., 2021). These aspects are discussed in the expert inputs from Professor Wade and also Professor Sarker where both articulate the need for organizations and consumers to take a more holistic view on the use of technology across the full lifecycle, highlighting the need for a more balanced, realistic and wider debate on environmental tradeoffs. The article by Professor Sein and Dr Chandra Kruse advocates a Design Science Research (DSR) approach from the IS community when developing sustainability and global warming solutions. This approach aims to create new knowledge through building methods and artifacts that are aligned with improving societal problems via the greater adoption of green practices. The literature has posited the role of technology in the monitoring and governance of climate change progression, via the extensive use of IS systems and remote sensing devices to provide the necessary data to scientists and decision makers at a global level (Bunker, 2020, Nüttgens et al., 2011). The expert input by Dr Mäntymäki highlights the need for a greater awareness of the sustainability impact of digital services, platforms, and infrastructure and that these systems be measured and monitored in a reliable and transparent fashion to mitigate the surge in unused digital content - so called digital waste. The expert inputs from Professor Gupta, Professor Bunker and from Mr Fenby-Taylor elaborate on these crucial aspects where they posit the benefits of improved data innovation practice, transitional approaches to complex information governance and effective information management to engender a culture shift in the use of data in all its forms, more collaboratively, thereby delivering impactful change. The expert input by Ms Shah highlights the critical role of data science processes to inform decision makers, monitoring of potential environmental hazards and accurate modeling of global warming scenarios. In the contribution from Dr He, he discussed the role of data analysis and climate change, where the role of sensor-based technologies was highlighted in the collection of huge amounts of environmental data to measure emissions and develop insights to conserve and improve energy use. A number of the submitted expert inputs discussed topics associated with IS and digital technology research, commenting on the current position and potential agendas for the future. The expert input from Professor Pekkola criticised the narrow approach taken by organizations and public bodies where environmental issues and ICT are approached from disparate perspectives in the context of economic growth and prosperity. The article from Professor Dubey posits the need for theory-driven research utilizing AI based approaches to provide a better understanding of the causes of climate change and potential solutions. The impact of blockchain technology and the environment was discussed in the submission from Dr Andreini, where the article asserts the need for a research agenda better aligned to understanding how the traditional and cryptocurrencies can coexist more effectively. The article from Professor Olaisen critiqued the current IS literature, finding that a very small percentage of studies actually investigated climate issues, asserting the need for researchers to start to ask the necessary research questions, on key aspects of the environmental and sustainability issues. 5.3. Recommendations for research The expert contributions detail a number of research recommendations on many aspects of technology and digital products. One of the key emerging themes from the contributions is the call to explicitly include the environment as a key stakeholder. This is referenced in the expert inputs by Professors Davison and Sarker and implicitly supported in many other contributions, where a more honest and informed perspective is required, advocating a research agenda that focuses on impacts as well as benefits from a responsible IS perspective. Many of the contributions highlight the need for further research on the role of IS in improving systems and processes in the transportation, agriculture and manufacturing industries to improve energy efficiency, reduce waste and deliver accurate data to make better, more informed decisions. A number of contributions detail the critical role of IS and digital technologies in the provision of key data that can inform decision makers on the progress of global warming initiatives. Some of the topics discussed within the expert input by Professor Raman articulate many of the perspectives on this topic, highlighting the need for more research to improve the collection and dissemination of data on climate risk and use of sensor based IoT technologies within developing countries to alert authorities on emission levels. The expert input from Professor Rana supports a greater level of research focus on the socio-psychological behavioral factors surrounding the adoption of digital technologies, that can help inform researchers on how people adapt to new interactions and systems that reduce emissions. The theme of multidisciplinary perspectives on IS and sustainability for research agenda, is discussed by a number of experts including the need for greater focus on global IT collaboration. Viewing these perspectives from a transdisciplinary lens is advocated in the contribution from Professor Michael and Dr Abbas, where they posit the benefits of creating models and simulations within an overall sustainability framework that can encapsulate multi-level perspectives on the provision of data and technology interaction. A number of articles have referenced the role of smart technologies, smart cities and smart mobility, within the overall transition to a more sustainable digital infrastructure where people can interact with IS more effectively throughout their daily lives. However, as highlighted by Professor Scholtz, the focus on aligning smart initiatives to the UN SDGs seems to be an underdeveloped research area that could inform further research on key topics of sustainable water management, sanitation and access to sustainable energy sources. This sentiment is further explored in a number of articles, but particularly the call for greater multidisciplinary perspectives on CDR as highlighted by Professor Wade, asserting the need for a better understanding of the dynamics of CDR from theoretical and empirical perspectives. The problem of e-waste is discussed within a number of articles and further research in this area is explicitly called for. The article from Professor Gupta discusses a number of these key points that are detailed within many expert inputs, calling for greater research on improved strategies for dealing with this problem that negates the need for shifting the problem to emerging economies. The pivotal role of data and data science has been referenced in many submissions but particularly in the from Ms Shah where the article discusses the criticality of accurate data and empirical studies to inform key decision makers. Further research and insight is needed, through evidence-based initiatives to ensure the effects of global warming are effectively communicated to governments and organizations to ensure timely decisions are made and relevant resources are made available in the critical areas. 5.4. Recommendations for education The need for a greater educational awareness amongst IS researchers and users, seems to be a common thread within the submitted articles. A number of articles advocate a more holistic emphasis and informed debate on the environmental impact of technology, as well as its benefits in helping to mitigate further global warming and attainment of net zero by 2050. Many of the experts advocate a more balanced perspective within the IS and technology curriculum, to ensure students better understand the impact of behaviors. A number of articles also posit the need for better education on technologies that directly mitigate climate change, highlighting that this core topic seems to lack focus within many institutions. Technology has a critical role to play in the changing of human attitudes and behaviors toward sustainability. IS can educate and inform people about the carbon footprint to explore new innovative ways to perform everyday activities but in a more sustainable way. The article by Professors Constantiou and Vendelø illustrates how digital platforms can engender collaborative consumption and social entrepreneurship, educating people to redistribute unwanted products and reduce waste as well as influence consumers via sustainable cooking and plant based food. A number of experts have detailed the role of IS in the context of educating people through online communities. The contribution from Professor Panteli emphasizes this aspect, positing the role of young people and their digital activism in influencing a change in behaviors, whilst Dr Nishant and Professor Teo discuss the need for IS educators to increase awareness on green IS and the sustainability aspects of technology. It is clear from the submitted articles that education is a key component of the transition to net zero and ensuring that all stakeholders (industry and individuals) have the necessary knowledge to engender changes in behavior, is a key component of the transition. 5.5. Recommendations for practice and policy The UN COP26 conference gained commitment for a number of key initiatives that could have a significant impact on global warming. The key commitments included: at least 100 countries (including Brazil) agreeing to end deforestation by 2030; Led by the US and EU - 80 countries pledged to cut methane emissions by 30% by 2030; Although commitment could not be gained from China, the US, India and Australia - 23 nations made new commitments to phase out coal power, including five of the top 20 users: Indonesia, South Korea, Poland, Vietnam, Chile and Ukraine; India committed to attaining net zero by 2070 (COP26, 2021). Governments have a critical role in combating global warming from the legislative and policy perspective, but to ensure the targets set for 2050 have a realistic chance of being achieved, we need change at a societal level. The IS and technology industry has a critical role to play in the monitoring of progress toward net zero, but also a pivotal role in the development of innovative solutions to better manage emissions and offer people alternatives to current carbon based practices. Many of the contributions have highlighted the crucial role of organizations adopting a green philosophy and demonstrating a firm commitment to CSR and CDR policies and working practices. A number of the experts have discussed the realities of technology contributing to the global warming problem due to the high levels of waste and inability for manufacturers to adopt a greater sustainability focus on manufacturing materials, processes and poor emphasis toward product repair, not replace - so called e-waste. The expert input by Professor Metri cites the 2019 UN and WEF reports that 50 million tonnes of e-waste was produced in that year, with only 20% being dealt with sustainably and the rest ending up as landfill. Many articles discuss these aspects, highlighting that the IS industry has much to do in this area. Organizations have their part to play to align with the goals and commitments from COP26, but successful outcomes rely on support from government and institutions to create the necessary environment and policy infrastructure, thereby enabling the technology industry to make the right long term decisions for the environment and society. 6. Conclusions The UN climate change conference – COP26 held in Glasgow UK, is seen as one of the last chances for governments and key decision makers to make the firm commitments needed to ensure global temperatures do not exceed 1.5 °C above pre-industrial levels by 2050. The use of technology and IS is an integral component of many of the proposed mitigation measures, as governments and societies around the world take the necessary steps in transitioning to net zero. This multi-contribution editorial study offers a technology focussed and IS perspective on the climate crisis where many of the multi-faceted complexities facing governments, organizations and decision makers are discussed. In alignment with the approach set out in previous studies (Dwivedi et al., 2020, Dwivedi et al., 2022, Dwivedi et al., 2021a, Dwivedi et al., 2021b, Dwivedi et al., 2015), each of the invited experts offers their own unique viewpoints to explore many of the key topics related to climate change, IS and digital technologies. The major technology and IS focussed themes that have emerged from the invited experts include: the impact of technology on behaviors and attitudes; Education, awareness and changed working practices; Impact on people and communities; Responsible digitalization; Role of data, technology and IS governance; Technology and IS research agenda. We present this opinion paper as a timely perspective on this critical topic where we have discussed the multifaceted role of digital technology and IS in combating climate change. The expert contributions highlight the urgent need for education initiatives that offer a more holistic and balanced perspective on the opportunities for technology based solutions but also communicate the realities of the negative impact from e-waste and the shifting of the problem to poorer emerging nations. The developed countries throughout the world have a responsibility to develop solutions for problems of their own making and a greater focus on responsible digitalization has to be the right direction to engender sustained change. We advocate a greater awareness from individual consumers as well as manufacturers, on the “lived in” realities of environmental tradeoffs and key value choices (Rowe, 2018), as we continue to utilize technology as an integral component of our daily lives. Decision makers need to be cognisant of these key choices, as greater use is made of technology in all its forms to deliver net zero by 2050. References Abbas et al., 2021a R. Abbas, S. Hamdoun, J. Abu-Ghazaleh, N. Chhetri, N. Chhetri, K. Michael Co-designing the future with public interest technology IEEE Technology and Society Magazine, 40 (3) (2021), pp. 10-15 CrossRefView in ScopusGoogle Scholar Abbas et al., 2021b R. Abbas, K. Michael, J. Sargent, E. Scornavacca Anticipating techno-economic fallout: Purpose-driven socio-technical innovation IEEE Transactions on Technology and Society, 2 (3) (2021), pp. 111-113 CrossRefGoogle Scholar Abbas et al., 2021c R. Abbas, J. Pitt, K. Michael Socio-technical design for public interest technology IEEE Transactions on Technology and Society, 2 (2021), pp. 55-61, 10.1109/TTS.2021.3086260 Google Scholar Ågerfalk et al., 2022 P.J. Ågerfalk, K. Axelsson, M. Bergquist Addressing climate change through stakeholder-centric Information Systems research: A Scandinavian approach for the masses Forthcoming in International Journal of Information Management (2022), 10.1016/j.ijinfomgt.2021.102447 Google Scholar Albino et al., 2015 V. Albino, U. Berardi, R.M. Dangelico Smart cities: Definitions, dimensions, performance, and initiatives Journal of Urban Technology, 22 (1) (2015), pp. 1-19 Google Scholar Allam and Dhunny, 2019 Z. Allam, Z.A. Dhunny On big data, artificial intelligence and smart cities Cities, 89 (January) (2019), pp. 80-91, 10.1016/j.cities.2019.01.032 View PDFView articleView in ScopusGoogle Scholar Alston, 2015 M. Alston Women and climate change in Bangladesh Routledge (2015) Google Scholar Amos, 2020 Z. Amos The negative impact of technology on the environment Culture, Science and Tech Efficiency (2020) 〈https://rehack.com/trending/culture/the-negative-impact-of-technology-on-the-environment/〉 on 26th October 2021 Google Scholar Antheaume et al., 2018 N. Antheaume, D. Thiel, F. de Corbière, F. Rowe, H. Takeda An analytical model to investigate the economic and environmental benefits of a supply chain resource-sharing scheme based on collaborative consolidation centres Journal of the Operational Research Society, 69 (12) (2018), pp. 1888-1902 CrossRefView in ScopusGoogle Scholar Aoun et al., 2011 Aoun, C., Vatanasakdakul, S. & Bunker, D. (2011) 'From Cloud to Green: E-Collaboration for Environmental Conservation', Proceedings of the IEEE International Conference on Cloud and Green Computing CGC 2011, Sydney, Australia, 14th December 2011. Google Scholar Asadi and Dahlan, 2017 S. Asadi, H.M. Dahlan Organizational research in the field of Green IT: A systematic literature review from 2007 to 2016 Telematics and Informatics, 34 (7) (2017), pp. 1191-1249 View PDFView articleView in ScopusGoogle Scholar Ash et al., 2004 J.S. Ash, M. Berg, E. Coiera Some unintended consequences of information technology in health care: the nature of patient care information system-related errors Journal of the American Medical Informatics Association, 11 (2) (2004), pp. 104-112 View PDFView articleView in ScopusGoogle Scholar Askanius and Uldam, 2011 T. Askanius, J. Uldam Online social media for radical politics: climate change activism on YouTube International Journal of Electronic Governance, 4 (1–2) (2011), pp. 69-84 CrossRefView in ScopusGoogle Scholar Asongu et al., 2020 S.A. Asongu, M.O. Agboola, A.A. Alola, F.V. Bekun The criticality of growth, urbanization, electricity and fossil fuel consumption to environment sustainability in Africa Science of the Total Environment, 712 (2020), Article 136376 View PDFView articleView in ScopusGoogle Scholar Backhouse, 2015 J. Backhouse Smart city agendas of African cities Proceedings of the African Conference on Information Systems and Technology (ACIST), 2015 (July) (2015), pp. 7-8 Google Scholar Banerjee, 2001 S.B. Banerjee Managerial perceptions of corporate environmentalism: Interpretations from industry and strategic implications for organizations Journal of Management Studies, 38 (4) (2001), pp. 489-513 CrossRefView in ScopusGoogle Scholar Barba-Gutiérrez et al., 2008 Y. Barba-Gutiérrez, B. Adenso-Diaz, M. Hopp An analysis of some environmental consequences of European electrical and electronic waste regulation Resources, Conservation and Recycling, 52 (3) (2008), pp. 481-495 View PDFView articleView in ScopusGoogle Scholar Bélanger et al., 2018 F. Bélanger, C. Van Slyke, R.E. Crossler Information Systems for Business: An Experiential Approach (3rd ed..,), Prospect Press, (2018) Google Scholar Beyer et al., 2016 J. Beyer, H.C. Trannum, T. Bakke, P.V. Hodson, T.K. Collier Environmental effects of the Deepwater Horizon oil spill: a review Marine Pollution Bulletin, 110 (1) (2016), pp. 28-51 View PDFView articleView in ScopusGoogle Scholar Bibri, 2019 S.E. Bibri On the sustainability of smart and smarter cities in the era of big data: an interdisciplinary and transdisciplinary literature review Journal of Big Data, 6 (1) (2019), pp. 1-64 View in ScopusGoogle Scholar Biglan, 2009 A. Biglan The role of advocacy organizations in reducing negative externalities Journal of Organizational Behavior Management, 29 (3–4) (2009), pp. 215-230 CrossRefView in ScopusGoogle Scholar Boudreau et al., 2008 M.C. Boudreau, A. Chen, M. Huber Green IS: Building sustainable business practices Information systems: A Global text (2008), pp. 1-17 View in ScopusGoogle Scholar Boulianne et al., 2020 S. Boulianne, M. Lalancette, D. Ilkiw School strike 4 climate”: social media and the international youth protest on climate change Media and Communication, 8 (2) (2020), pp. 208-218 CrossRefView in ScopusGoogle Scholar Brooks et al., 2022 L. Brooks, S. Cannizzaro, Umbrello, S. Bernstein, K. Richardson Ethics of Climate Engineering: Don’t forget technology has an ethical aspect too Forthcoming in International Journal of Information Management (2022), 10.1016/j.ijinfomgt.2021.102449 Google Scholar Brown et al., 2010 V.A. Brown, J.A. Harris, J.Y. Russell (Eds.), Tackling wicked problems through the transdisciplinary imagination, Earthscan, London (2010) Google Scholar Buchanan, 1992 R. Buchanan Wicked problems in design thinking Design Issues, 8 (2) (1992), pp. 5-21 CrossRefGoogle Scholar Bunker, 2020 D. Bunker Who do you trust? The digital destruction of shared situational awareness and the COVID-19 infodemic International Journal of Information Management, 55 (2020), Article 102201 View PDFView articleView in ScopusGoogle Scholar Bunker et al., 2013 D. Bunker, C. Ehnis, P. Seltsikas, L. Levine Crisis Management and Social Media: Assuring Effective Information Governance for Long Term Social Sustainability 2013 IEEE International Conference on Technologies for Homeland Security (HST ’13) Institute of Electrical and Electronics Engineers (IEEE),, Piscataway, United States (2013) Google Scholar Butler, 2011 T. Butler Compliance with institutional imperatives on environmental sustainability: Building theory on the role of Green IS The Journal of Strategic Information Systems, 20 (1) (2011), pp. 6-26 View PDFView articleView in ScopusGoogle Scholar Calderón et al., 2017 M. Calderón, G. López, G. Marín Smart Cities in Latin America: Realities and Technical Readiness Ubiquitous Computing and Ambient Intelligence. UCAmI 2017. Lecture Notes in Computer Science, vol. 10586, Springer, Cham (2017), pp. 15-26, 10.1007/978-3-642-35377-2 View in ScopusGoogle Scholar Callaghan et al., 2021 M. Callaghan, C.F. Schleussner, S. Nath, Q. Lejeune, T.R. Knutson, M. Reichstein, J.C. Minx Machine-learning-based evidence and attribution mapping of 100,000 climate impact studies Nature Climate Change, 11 (2021), pp. 966-972 CrossRefView in ScopusGoogle Scholar Campbell, 2021 I.C. Campbell South Korean ISP SK Broadband sues Netflix for millions in bandwidth usage fees The Verge (2021) 〈https://www.theverge.com/2021/10/1/22704313/sk-broadband-netflix-suing-for-payment-squid-game〉 Google Scholar Cardoso et al., 2019 A. Cardoso, M.C. Boudreau, J.Á. Carvalho Organizing collective action: Does information and communication technology matter? Information and Organization, 29 (3) (2019), Article 100256 View PDFView articleView in ScopusGoogle Scholar Carlile, 2004 P.R. Carlile Transferring, translating, and transforming: An integrative framework for managing knowledge across boundaries Organization Science, 15 (5) (2004), pp. 555-568 View in ScopusGoogle Scholar Carroll and Heiser, 2010 Carroll, A. and Heiser, G. (2010) An analysis of power consumption in a smartphone, USENIXATC’10: Proceedings of the 2010 USENIX conference on USENIX annual technical conference, June, 2010, p. 21. Google Scholar CBECI, 2021 CBECI (Cambridge Bitcoin Electricity Consumption Index), 2021. Accessed on 1st November 2021. 〈https://cbeci.org/index〉. Google Scholar Chakraborty and Gupta, 2016 A. Chakraborty, B. Gupta Paradigm phase shift: RF MEMS phase shifters: An overview IEEE Microwave Magazine, 18 (1) (2016), pp. 22-41 Google Scholar Chakraborty and Kar, 2021 A. Chakraborty, A.K. Kar How did COVID-19 impact working professionals–a typology of impacts focused on education sector The International Journal of Information and Learning Technology, 38 (3) (2021), pp. 273-282 CrossRefView in ScopusGoogle Scholar Chakraborty et al., 2014 A. Chakraborty, B. Gupta, B.K. Sarkar Design, fabrication and characterization of miniature RF MEMS switched capacitor based phase shifter Microelectronics Journal, 45 (8) (2014), pp. 1093-1102 View PDFView articleView in ScopusGoogle Scholar Chamakiotis et al., 2021 P. Chamakiotis, D. Petrakaki, N. Panteli Social value creation through digital activism in an online health community Information Systems Journal, 31 (1) (2021), pp. 94-119 CrossRefView in ScopusGoogle Scholar Chandra et al., 2017 A. Chandra, K.E. McNamara, P. Dargusch, A.M. Caspe, D. Dalabajan Gendered vulnerabilities of smallholder farmers to climate change in conflict-prone areas: A case study from Mindanao, Philippines Journal of Rural Studies, 50 (2017), pp. 45-59 View PDFView articleView in ScopusGoogle Scholar Chapin III et al., 2000 F.S. Chapin III, E.S. Zavaleta, V.T. Eviner, R.L. Naylor, P.M. Vitousek, H.L. Reynolds, S. Díaz Consequences of changing biodiversity Nature, 405 (6783) (2000), pp. 234-242 Google Scholar Chen et al., 2008 A.J. Chen, M.C. Boudreau, R.T. Watson Information systems and ecological sustainability Technology, 10 (3) (2008), pp. 186-201 CrossRefGoogle Scholar Chen and Roldan, 2021 Y. Chen, M. Roldan Digital innovation during COVID-19: Transforming challenges to opportunities Communications of the Association for Information Systems, 48 (1) (2021), p. 3, 10.17705/1CAIS.04803 Google Scholar Claisse and Rowe, 1993 G. Claisse, F. Rowe Domestic telephone habits and daily mobility Transportation Research, 27 (4) (1993), pp. 277-290 View PDFView articleView in ScopusGoogle Scholar Clarke and Davison, 2020 R. Clarke, R.M. Davison Research perspectives: Through whose eyes? The critical concept of researcher perspective Journal of the Association for Information Systems, 21 (2) (2020), p. 1 (Available at) 〈https://aisel.aisnet.org/jais/vol21/iss2/1〉 Google Scholar Constantiou et al., 2017 I. Constantiou, A. Marton, V.K. Tuunainen Four models of sharing economy platforms MIS Quarterly Executive, 16 (4) (2017), pp. 236-251 View in ScopusGoogle Scholar COP26, 2021 COP26 COP26 Goals (2021) 〈https://ukcop26.org/cop26-goals/〉 Google Scholar Coroama and Mattern, 2019 Coroama, V., & Mattern, F. (2019). Digital Rebound – Why Digitalization Will Not Redeem Us Our Environmental Sins, The 6th International Conference on ICT for Sustainability. Google Scholar Crawford, 2021 K. Crawford Atlas of AI Yale University Press, New Haven and London (2021) Google Scholar Cropper and Oates, 1992 M.L. Cropper, W.E. Oates Environmental economics: a survey Journal of Economic Literature, 30 (2) (1992), pp. 675-740 Google Scholar Crow and Dabars, 2015 M.M. Crow, W.B. Dabars Designing the New American University Johns Hopkins University Press,, Baltimore (2015) Google Scholar Crow and Dabars, 2017 M.M. Crow, W.B. Dabars Interdisciplinarity and the Institutional Context of Knowledge in the American Research University R. Frodeman, J.T. Klein, R.C.S. Pacheco (Eds.), The Oxford Handbook of Interdisciplinarity, Oxford University Press, Oxford (2017) Google Scholar Crow and Dabars, 2020 M.M. Crow, W.B. Dabars The Fifth Wave Johns Hopkins University Press, Baltimore (2020), p. 381 Google Scholar Cunliff, 2020 C. Cunliff Beyond the Energy Techlash: The Real Climate Impacts of Information Technology July 6 Information Technology & Innovation Foundation, (2020) July 6 〈https://itif.org/publications/2020/07/06/beyond-energy-techlash-real-climate-impacts-information-technology〉 Google Scholar Dasgupta and Ehrlich, 2013 P.S. Dasgupta, P.R. Ehrlich Pervasive Externalities at the Population, Consumption, and Environment Nexus Science, 340 (324) (2013), 10.1126/science.1224664 Google Scholar David, 2017 L. David Spaceflight pollution Space com (2017) 〈https://www.space.com/38884-rocket-exhaust-space-junk-pollution.html〉 Google Scholar de Corbière et al., 2010 F. de Corbière, B. Durand, F. Rowe Effets économiques et environnementaux de la mutualisation des informations logistiques de distribution: avis d′experts et voies de recherche Management et Avenir (n°39) (2010), pp. 326-348 Google Scholar de Corbière et al., 2016 de Corbière F., Takeda H., Habib J., Rowe F., & Thiel D. (2016). A simulation approach for analyzing the influence of information quality on the deployment of a green supply chain, European Conference on Information Systems, Istanbul. Google Scholar De et al., 2018 R. De, A. Pal, R. Sethi, S.K. Reddy, C. Chitre ICT4D research: A call for a strong critical approach Information Technology for Development, 24 (1) (2018), pp. 63-94 CrossRefView in ScopusGoogle Scholar Dedrick, 2010 J. Dedrick Green IS: concepts and issues for information systems research Communications of the Association for Information Systems, 27 (1) (2010), p. 11, 10.17705/1CAIS.02711 Google Scholar Dimitriou and Karame, 2013 T. Dimitriou, G. Karame Privacy-friendly tasking and trading of energy in smart grids Proceedings of the 28th Annual ACM Symposium on Applied Computing, Coimbra, Portugal, 18–22 March 2013, ACM,, New York, NY, USA (2013), pp. 652-659 CrossRefView in ScopusGoogle Scholar Douglas and Brauer, 2021 B.D. Douglas, M. Brauer Gamification to prevent climate change: A review of games and apps for sustainability Current Opinion in Psychology, 42 (2021), pp. 89-94 View PDFView articleView in ScopusGoogle Scholar Dubey et al., 2019 R. Dubey, A. Gunasekaran, S.J. Childe, T. Papadopoulos, Z. Luo, S.F. Wamba, D. Roubaud Can big data and predictive analytics improve social and environmental sustainability? Technological Forecasting and Social Change, 144 (2019), pp. 534-545 View PDFView articleView in ScopusGoogle Scholar Dwivedi et al., 2020 Y.K. Dwivedi, D.L. Hughes, C. Coombs, I. Constantiou, Y. Duan, J.S. Edwards, N. Upadhyay Impact of COVID-19 pandemic on information management research and practice: Transforming education, work and life International Journal of Information Management, 55 (2020), Article 102211 View PDFView articleView in ScopusGoogle Scholar Dwivedi et al., 2022 Y.K. Dwivedi, L. Hughes, C.M. Cheung, K. Conboy, Y. Duan, R. Dubey, G. Viglia How to develop a quality research article and avoid a journal desk rejection International Journal of Information Management, 62 (2022), Article 102426 View PDFView articleView in ScopusGoogle Scholar Dwivedi et al., 2021a Y.K. Dwivedi, L. Hughes, E. Ismagilova, G. Aarts, C. Coombs, T. Crick, V. Galanos Artificial Intelligence (AI): Multidisciplinary perspectives on emerging challenges, opportunities, and agenda for research, practice and policy International Journal of Information Management, 57 (2021), Article 101994 View PDFView articleView in ScopusGoogle Scholar Dwivedi et al., 2021b Y.K. Dwivedi, E. Ismagilova, D.L. Hughes, J. Carlson, R. Filieri, J. Jacobson, V. Kumar Setting the future of digital and social media marketing research: Perspectives and research propositions International Journal of Information Management, 59 (2021), Article 102168 View PDFView articleView in ScopusGoogle Scholar Dwivedi et al., 2015 Y.K. Dwivedi, D. Wastell, S. Laumer, H.Z. Henriksen, M.D. Myers, D. Bunker, S.C. Srivastava Research on information systems failures and successes: Status update and future directions Information Systems Frontiers, 17 (1) (2015), pp. 143-157 CrossRefView in ScopusGoogle Scholar Ehnis and Bunker, 2020 C. Ehnis, D. Bunker Repertoires of collaboration: incorporation of social media help requests into the common operating picture Behaviour and Information Technology, 39 (3) (2020), pp. 343-359 CrossRefView in ScopusGoogle Scholar Elbanna et al., 2020 A. Elbanna, Y.K. Dwivedi, D. Bunker, D. Wastell The Search for Smartness in Working, Living and Organising: Beyond the 'Technomagic' Information Systems Frontiers, 22 (2020), pp. 275-280 CrossRefView in ScopusGoogle Scholar Elkington, 1997 J. Elkington Cannibals with Forks: The Triple Bottom Line of 21st Century Business Capstone, (1997) Google Scholar Eregowda et al., 2021 T. Eregowda, P. Chatterjee, D.S. Pawar Impact of lockdown associated with COVID19 on air quality and emissions from transportation sector: case study in selected Indian metropolitan cities Environment Systems and Decisions (2021), pp. 1-12 Google Scholar Escobar, 2011 A. Escobar Encountering development Princeton University Press (2011) Google Scholar Esfahani et al., 2015 M.D. Esfahani, A.A. Rahman, N.H. Zakaria The status quo and the prospect of green IT and green IS: a systematic literature review Journal of Soft Computing and Decision Support Systems, 2 (1) (2015), pp. 18-34 Google Scholar Estevez et al., 2016 E. Estevez, N.V. Lopes, T. Janowski Smart Sustainable Cities - Reconnaissance Study UNU-EGOV-IDRC, 312 (2016) Google Scholar Estonia, 2018 Estonia (2018). Digital Agenda for 2020 Estonia. Available at: 〈https://www.mkm.ee/sites/default/files/digitalagenda2020_final_final.pdf〉 visited Oct 28 2021. Google Scholar Evans and Gao, 2016 Evans, R. & Gao, J. (2016). DeepMind AI reduces energy used for cooling Google data centers by 40%. Available at 〈https://www.blog.google/outreach-initiatives/environment/deepmind-ai-reduces-energy-used-for/〉. Google Scholar Everard et al., 2021 M. Everard, G. Kass, J. Longhurst, S. Zu Ermgassen, H. Girardet, J. Stewart-Evans, A. Craig Reconnecting society with its ecological roots Environmental Science & Policy, 116 (2021), pp. 8-19 View PDFView articleView in ScopusGoogle Scholar Ferguson, 1994 J. Ferguson The Anti-Politics Machine: Development, Depoliticization, and Bureaucratic Power in Lesotho U of Minnesota Press, (1994) Google Scholar Fork and Koningstein, 2021 D. Fork, R. Koningstein Engineers: You Can Disrupt Climate Change June 28 IEEE Spectrum (2021) June 28 〈https://spectrum.ieee.org/engineers-you-can-disrupt-climate-change〉 Google Scholar Franco et al., 2016 C. Franco, L.A. Hepburn, D.J. Smith, S. Nimrod, A. Tucker A Bayesian Belief Network to assess rate of changes in coral reef ecosystems Environmental Modelling & Software, 80 (2016), pp. 132-142 View PDFView articleView in ScopusGoogle Scholar Frazzoli et al., 2010 C. Frazzoli, O.E. Orisakwe, R. Dragone, A. Mantovani Diagnostic health risk assessment of electronic waste on the general population in developing countries’ scenarios Environmental Impact Assessment Review, 30 (2010), pp. 388-399 View PDFView articleView in ScopusGoogle Scholar Frodeman, 2014 R. Frodeman Sustainable knowledge: A theory of interdisciplinarity Palgrave Macmillan, Basingstoke (2014) Google Scholar Frontier Technologies to Protect the Environment and Tackle Climate Change, 2020 Frontier Technologies to Protect the Environment and Tackle Climate Change (2020, April). The International Telecommunication Union (ITU). 〈https://www.itu.int/en/action/environment-and-climate-change/Documents/frontier-technologies-to-protect-the-environment-and-tackle-climate-change.pdf〉. Google Scholar Galanti et al., 2021 T. Galanti, G. Guidetti, E. Mazzei, S. Zappalà, F. Toscano Work from home during the COVID-19 outbreak: the impact on employees’ remote work productivity, engagement, and stress Journal of Occupational and Environmental Medicine, 63 (7) (2021), Article e426 CrossRefGoogle Scholar Garg et al., 2017 R. Garg, C. Schmitt, B. Stiller Information Policy Dimension of Emerging Technologies SSRN-Elsevier (2017) Google Scholar GDPR, 2018 GDPR. (2018). General Data Protection Regulation. Retrieved from 〈https://gdpr-info.eu/〉. Google Scholar Geels, 2004 F.W. Geels From sectoral systems of innovation to socio-technical systems: Insights about dynamics and change from sociology and institutional theory Research Policy, 33 (6–7) (2004), pp. 897-920 View PDFView articleView in ScopusGoogle Scholar Geels, 2010 F.W. Geels Ontologies, socio-technical transitions (to sustainability), and the multi-level perspective Research Policy, 39 (4) (2010), pp. 495-510 View PDFView articleView in ScopusGoogle Scholar Geels, 2011 F.W. Geels The multi-level perspective on sustainability transitions: Responses to seven criticisms Environmental Innovation and Societal Transitions, 1 (1) (2011), pp. 24-40 View PDFView articleView in ScopusGoogle Scholar Geissdoerfer et al., 2017 M. Geissdoerfer, P. Savaget, N.M. Bocken, E.J. Hultink The Circular Economy–A new sustainability paradigm? Journal of Cleaner Production, 143 (2017), pp. 757-768 View PDFView articleView in ScopusGoogle Scholar Gellert et al., 2019 A. Gellert, A. Florea, U. Fiore, F. Palmieri, P. Zanetti A study on forecasting electricity production and consumption in smart cities and factories International Journal of Information Management, 49 (2019), pp. 546-556 View PDFView articleView in ScopusGoogle Scholar George et al., 2016 G. George, J. Howard-Grenville, A. Joshi, L. Tihanyi Understanding and tackling societal grand challenges through management research Academy of Management Journal, 59 (6) (2016), pp. 1880-1895 CrossRefView in ScopusGoogle Scholar George et al., 2021 G. George, R.K. Merrill, S.J. Schillebeeckx Digital sustainability and entrepreneurship: How digital innovations are helping tackle climate change and sustainable development Entrepreneurship Theory and Practice, 45 (5) (2021), pp. 999-1027 CrossRefView in ScopusGoogle Scholar George and Leidner, 2019 J.J. George, D.E. Leidner From clicktivism to hacktivism: Understanding digital activism Information and Organization, 29 (3) (2019), Article 100249 View PDFView articleView in ScopusGoogle Scholar Gerson et al., 2020 J. Gerson, A. Wadle, J. Parham Gold rush, mercury legacy: Small-scale mining for gold has produced long-lasting toxic pollution, from 1860s California to modern Peru The Conversation (2020) 〈https://theconversation.com/gold-rush-mercury-legacy-small-scale-mining-for-gold-has-produced-long-lasting-toxic-pollution-from-1860s-california-to-modern-peru-133324〉 Google Scholar Gholami et al., 2016 R. Gholami, R.T. Watson, H. Hasan, A. Molla, N. Bjorn-Andersen Information systems solutions for environmental sustainability: How can we do more? Journal of the Association for Information Systems, 17 (8) (2016), pp. 521-536 CrossRefView in ScopusGoogle Scholar Ghosh, 2018 A. Ghosh The Great Derangement: Climate Change and the Unthinkable Penguin, UK (2018) Google Scholar Grover et al., 2019 P. Grover, A.K. Kar, P.V. Ilavarasan Impact of corporate social responsibility on reputation—Insights from tweets on sustainable development goals by CEOs International Journal of Information Management, 48 (2019), pp. 39-52 View PDFView articleView in ScopusGoogle Scholar Grover et al., 2021 P. Grover, A.K. Kar, S. Gupta, S. Modgil Influence of political leaders on sustainable development goals–insights from twitter Journal of Enterprise Information Management (2021), 10.1108/JEIM-07-2020-0304 Google Scholar GZR, 2020 GZR, (2020). Japan’s Green Innovations for Achieving Carbon Neutrality 〈https://www.japan.go.jp/kizuna/2020/japans_green_innovations.html〉 Accessed on 20 oct 2021. Google Scholar Hadorn et al., 2006 G.H. Hadorn, D. Bradley, C. Pohl, S. Rist, U. Wiesmann Implications of transdisciplinarity for sustainability research Ecological Economics, 60 (1) (2006), pp. 119-128 Google Scholar Hadorn et al., 2008 G.H. Hadorn, et al. The Emergence of Transdisciplinarity as a Form of Research G.H. Hadorn, S. Biber-Klemm, W. Grossenbacher-Mansuy, H. Hoffmann-Riem, D. Joye, C. Pohl, E. Zemp (Eds.), Handbook of Transdisciplinary Research, Springer, Dordrecht (2008), pp. 19-39 CrossRefView in ScopusGoogle Scholar Harvey, 2021 Harvey, F. (2021). Major climate changes inevitable and irreversible – IPCC’s starkest warning yet. 〈https://www.theguardian.com/science/2021/aug/09/humans-have-caused-unprecedented-and-irreversible-change-to-climate-scientists-warn〉. Google Scholar Hasan et al., 2017 H. Hasan, S. Smith, P. Finnegan 'An activity theoretic analysis of the mediating role of information systems in tackling climate change adaptation Information Systems Journal, 27 (2017), pp. 271-308 CrossRefView in ScopusGoogle Scholar He et al., 2021 W. He, Z.J. Zhang, W. Li Information technology solutions, challenges, and suggestions for tackling the COVID-19 pandemic International Journal of Information Management, 57 (2021), Article 102287 View PDFView articleView in ScopusGoogle Scholar Herath and Herath, 2020 T. Herath, H.S. Herath Coping with the new normal imposed by the COVID-19 pandemic: Lessons for technology management and governance Information Systems Management, 37 (4) (2020), pp. 277-283 CrossRefView in ScopusGoogle Scholar Hess and Ostrom, 2007 C. Hess, E. Ostrom Knowledge as a commons: From theory to practice MIT Press,, Cambridge, MA (2007) Google Scholar Hillebrand and Johannsen, 2021 K. Hillebrand, F. Johannsen KlimaKarl–A Chatbot to Promote Employees’ Climate-Friendly Behavior in an Office Setting L. Chandra Kruse, et al. (Eds.), DESRIST 2021, LNCS 12807 (2021), pp. 3-15 CrossRefView in ScopusGoogle Scholar Hillis, 2016 D. Hillis The Enlightenment is Dead, Long Live the Entanglement J. Des. Sci. (2016), 10.21428/1a042043 Google Scholar Hollebeek, 2011 L.D. Hollebeek Demystifying customer brand engagement: Exploring the loyalty nexus Journal of Marketing Management, 27 (7–8) (2011), pp. 785-807 View in ScopusGoogle Scholar Howes, 2020 C. Howes Greening government: ICT and digital services strategy 2020-2025 Department of Environment, Food, and Rural affairs, United Kingdom (2020) (Available at) 〈https://www.gov.uk/government/publications/greening-government-ict-and-digital-services-strategy-2020-2025/greening-government-ict-and-digital-services-strategy-2020-2025〉 Google Scholar Howson, 2019 P. Howson Tackling climate change with blockchain Nat. Clim. Change, 9 (9) (2019), pp. 644-645 CrossRefView in ScopusGoogle Scholar IEA, 2019 IEA CO2 Emissions From Fuel Combustion (2019 ed.), International Energy Agency, (2019) Google Scholar Iivari, 2010 J. Iivari Twelve theses on design science research in information systems Design research in information systems, Springer, Boston, MA (2010), pp. 43-62 CrossRefGoogle Scholar IPCC, 2018 IPCC Climate change Cambridge University Press, Cambridge (2018) Google Scholar IPCC, 2021 IPCC Climate change science report Cambridge University Press, Cambridge (2021) Google Scholar IRENA, 2021 IRENA (2021). Renewable Energy and Jobs -Annual Review 2021. 〈https://www.irena.org/publications/2021/Oct/Renewable-Energy-and-Jobs-Annual-Review-2021〉. Google Scholar IS2020, 2020 IS2020. (2020). Information and communication on the IS2020 Model Curriculum. 〈https://is2020.org/curriculum/〉. Google Scholar Ismagilova et al., 2019 E. Ismagilova, L. Hughes, Y.K. Dwivedi, K.R. Raman Smart cities: Advances in research—An information systems perspective International Journal of Information Management, 47 (2019), pp. 88-100 View PDFView articleView in ScopusGoogle Scholar Jang et al., 2016 H.S. Jang, K.Y. Bae, H.S. Park, D.K. Sung Solar power prediction based on satellite images and support vector machine IEEE Transactions on Sustainable Energy, 7 (3) (2016), pp. 1255-1263 View in ScopusGoogle Scholar Jevnaker and Olaisen, 2021aaa B. Jevnaker, J. Olaisen A comparative study of knowledge management research studies: Making research more relevant and creative (Forthcoming in) Journal of Knowledge Management Research & Practice (2021) Google Scholar Jevnaker and Olaisen, 2021bbb B. Jevnaker, J. Olaisen Leadership for sustainability. The impact of sustainable imaginative work Scientific Proceedings of ECMLG, 202 (2021) Google Scholar Jevnaker and Olaisen, 2021aac B. Jevnaker, J. Olaisen Making knowledge management research scientific (Forthcoming in) Electronic Journal of Knowledge Management (2021) Google Scholar Jevnaker and Olaisen, 2021bbd B. Jevnaker, J. Olaisen Traveling leadership ideas as a business virus infection G. Enthoven, S. Rudnicki, R. Sneller (Eds.), Towards a Science of Ideas, Vernon University Press, New York (2021) Google Scholar Jnr, 2020 B.A. Jnr Examining the role of green IT/IS innovation in collaborative enterprise-implications in an emerging economy Technology in Society, 62 (2020), Article 101301 Google Scholar Jones, 2018 N. Jones How to stop data centres from gobbling up the world's electricity Nature, 561 (7722) (2018), pp. 163-167 View in ScopusGoogle Scholar Jonsson, 2012 F.A. Jonsson The Industrial Revolution in the Anthropocene The Journal of Modern History, 84 (2012), pp. 679-696 View in ScopusGoogle Scholar Joppa et al., 2021 L. Joppa, A. Luers, E. Willmott, S.J. Friedmann, S.P. Hamburg, R. Broze Microsoft's million-tonne CO 2-removal purchase-lessons for net zero Nature, 597 (7878) (2021), pp. 629-632 CrossRefGoogle Scholar Junior et al., 2018 B.A. Junior, M.A. Majid, A. Romli Green information technology for sustainability elicitation in government-based organisations: an exploratory case study International Journal of Sustainable Society, 10 (1) (2018), pp. 20-41 View in ScopusGoogle Scholar Kamiya, 2020 G. Kamiya The carbon footprint of streaming video: fact-checking the headlines International Energy Agency (IEA), (2020) 〈https://www.iea.org/commentaries/the-carbon-footprint-of-streaming-video-fact-checking-the-headlines〉 Google Scholar Kar et al., 2019 A.K. Kar, V. Ilavarasan, M.P. Gupta, M. Janssen, R. Kothari Moving beyond smart cities: Digital nations for social innovation & sustainability Information Systems Frontiers, 21 (3) (2019), pp. 495-501 CrossRefView in ScopusGoogle Scholar Kemp et al., 2005 R. Kemp, S. Parto, R.B. Gibson Governance for sustainable development: moving from theory to practice International Journal of Sustainable Development, 8 (1/2) (2005), pp. 12-30 CrossRefView in ScopusGoogle Scholar Khan et al., 2021 I. Khan, D. Shah, S.S. Shah COVID-19 pandemic and its positive impacts on, environment: an updated review International Journal of Environmental Science and Technology, 18 (2) (2021), pp. 521-530 CrossRefView in ScopusGoogle Scholar Khan et al., 2006 S. Khan, R. Tariq, C. Yuanlai, J. Blackwell Can irrigation be sustainable? Agricultural Water Management, 801 (1–3) (2006), pp. 87-99 View PDFView articleView in ScopusGoogle Scholar Khatoun and Zeadally, 2016 R. Khatoun, S. Zeadally Smart Cities: Concepts, Architectures, Research Opportunities Communications of the ACM, 59 (8) (2016), pp. 46-57 CrossRefView in ScopusGoogle Scholar Khuntia et al., 2018 J. Khuntia, T.J. Saldanha, S. Mithas, V. Sambamurthy Information technology and sustainability: Evidence from an emerging economy Production and Operations Management, 27 (4) (2018), pp. 756-773 CrossRefView in ScopusGoogle Scholar Ki-moon, 2012 Ki-moon, B. (2012) 'Remarks to the General Assembly on his Five-Year Action Agenda: "The Future We Want"' United Nations General Assembly 25 January 2012 〈https://www.un.org/sg/en/content/sg/speeches/2012–01-25/remarks-general-assembly-his-five-year-action-agenda-future-we-want〉 <last accessed - 30 October 2021> Google Scholar Klinger, 2021 T. Klinger Wendelstein 7-X Max Planck Institute for Plasma Physics (IPP) (2021) 〈https://www.ipp.mpg.de/w7x〉 Google Scholar Knutti et al., 2003 R. Knutti, T.F. Stocker, F. Joos, G.K. Plattner Probabilistic climate change projections using neural networks Climate Dynamics, 21 (3–4) (2003), pp. 257-272 View in ScopusGoogle Scholar Kodama, 2007 M. Kodama The Strategic Community-Based Firm Palgrave Macmillan (2007) Google Scholar Kodama, 2017 M. Kodama Developing holistic leadership: A source of business innovation Emerald Group Publishing, (2017) Google Scholar Kodama, 2018 M. Kodama Collaborative Dynamic Capabilities for Service Innovation Creating a New Healthcare Ecosystem Palgrave Macmillan (2018) Google Scholar Kodama, 2020 M. Kodama Digitally transforming work styles in an era of infectious disease International Journal of Information Management, 55 (2020), Article 102172 View PDFView articleView in ScopusGoogle Scholar Kodama, 2021 M. Kodama Managing IT for Innovation: Dynamic Capabilities and Competitive Advantage Routledge, (2021) Google Scholar Köhler et al., 2019 J. Köhler, F.W. Geels, F. Kern, J. Markard, E. Onsongo, A. Wieczorek, P. Wells An agenda for sustainability transitions research: State of the art and future directions Environmental Innovation and Societal Transitions, 31 (2019), pp. 1-32, 10.1016/j.eist.2019.01.004 View PDFView articleView in ScopusGoogle Scholar Kolk and Pinkse, 2008 A. Kolk, J. Pinkse A perspective on multinational enterprises and climate change: Learning from “an inconvenient truth? Journal of International Business Studies, 39 (8) (2008), pp. 1359-1378 CrossRefView in ScopusGoogle Scholar Kshetri, 2021 N. Kshetri Blockchain and sustainable supply chain management in developing countries International Journal of Information Management, 60 (2021), Article 102376 View PDFView articleView in ScopusGoogle Scholar Kuhn, 1962 T. Kuhn The structure of scientific revolutions U. of Chicago Press Classics,, Chicago (1962) Google Scholar Kumar et al., 2020 H. Kumar, M.K. Singh, M.P. Gupta, J. Madaan Moving towards smart cities: Solutions that lead to the Smart City Transformation Framework Technological Forecasting and Social Change, 153 (2020), Article 119281 View PDFView articleView in ScopusGoogle Scholar Kushwaha et al., 2021 A.K. Kushwaha, A.K. Kar, Y.K. Dwivedi Applications of big data in emerging management disciplines: A literature review using text mining International Journal of Information Management Data Insights, 1 (2) (2021), Article 100017 View PDFView articleView in ScopusGoogle Scholar Landzelius, 2006 K. Landzelius Introduction: Patient organization movements and new metamorphoses in patienthood Social Science & Medicine, 62 (3) (2006), pp. 529-537 View PDFView articleView in ScopusGoogle Scholar Lardinois, 2021 F. Lardinois Google Cloud will now show its users their carbon footprint in the cloud TechCrunch (2021) 〈https://techcrunch.com/2021/10/12/google-cloud-will-now-show-its-users-their-carbon-footprint-in-the-cloud/〉 Google Scholar Laukkanen et al., 2022 T. Laukkanen, N. Xi, H. Hallikainen, N. Ruusunen, J. Hamari Virtual technologies in supporting sustainable consumption: From a single-sensory stimulus to a multi-sensory experience International Journal of Information Management (2022), 10.1016/j.ijinfomgt.2021.102449 Google Scholar Lebrun, 2020 Lebrun F. (2020). Écrans et barbarie numérique, On achève bien les enfants, Le Bord De L′eau. Google Scholar Lee, 2008 E.A. Lee Cyber physical systems: Design challenges In 2008 11th IEEE international symposium on object and component-oriented real-time distributed computing (ISORC) IEEE, (2008), pp. 363-369 In 2008 11th IEEE international symposium on object and component-oriented real-time distributed computing (ISORC) View in ScopusGoogle Scholar Lee et al., 2019 Lee, S.U., Zhu, L. & Jeffery, R. (2019). Data Governance Decisions for Platform Ecosystems. Proceedings of the 52nd Hawaii International Conference on System Sciences – pages 6377–6386. Google Scholar Li and Wang, 2017 M. Li, Q. Wang Will technology advances alleviate climate change? Dual effects of technology change on aggregate carbon dioxide emissions Energy for Sustainable Development, 41 (2017), pp. 61-68 View PDFView articleView in ScopusGoogle Scholar LIMITS, 2021 LIMITS. (2021). Accessed on October 27, 2021 at 〈https://computingwithinlimits.org/2021〉. Google Scholar Lin et al., 2015 C.I. Lin, F.Y. Kuo, M.D. Myers Extending ICT4D studies MIS Quarterly, 39 (3) (2015), pp. 697-712 CrossRefView in ScopusGoogle Scholar Lin et al., 2018 Y.P. Lin, J.R. Petway, W.Y. Lien, J. Settele Blockchain with artificial intelligence to efficiently manage water use under climate change Environments, 5 (3) (2018), p. 34, 10.3390/environments5030034 Google Scholar Liu et al., 2007 J. Liu, S.R. Carpenter, M. Alberti, C. Folke, E. Moran, W.W. Taylor Complexity of coupled human and natural systems Science, 317 (5844) (2007), pp. 1513-1516 CrossRefView in ScopusGoogle Scholar Lobschat et al., 2021 L. Lobschat, B. Mueller, F. Eggers, L. Brandimarte, S. Diefenbach, M. Kroschke, J. Wirtz Corporate digital responsibility Journal of Business Research, 122 (2021), pp. 875-888 View PDFView articleView in ScopusGoogle Scholar Loeser, 2013 F. Loeser Green IT and Green IS: Definition of constructs and overview of current practices Proceedings of the Nineteenth Americas Conference on Information Systems, Chicago, Illinois, August 15-17, 2013 AIS Digital Library (2013) Google Scholar Loorbach et al., 2017 D. Loorbach, N. Frantzeskaki, F. Avelino Sustainability Transitions Research: Transforming Science and Practice for Societal Change Annual Review of Environment and Resources, 42 (2017), pp. 599-626, 10.1146/annurev-environ-102014-021340 View in ScopusGoogle Scholar Luo et al., 2016 X.R. Luo, J. Zhang, C. Marquis Mobilization in the internet age: Internet activism and corporate response Academy of Management Journal, 59 (6) (2016), pp. 2045-2068 CrossRefView in ScopusGoogle Scholar Ma and Agarwal, 2007 M. Ma, R. Agarwal Through a glass darkly: Information technology design, identity verification, and knowledge contribution in online communities Information Systems Research, 18 (1) (2007), pp. 42-67 CrossRefView in ScopusGoogle Scholar MacCarthy, 2018 M. MacCarthy Data is not the new oil or the infrastructure of the digital economy CIO (2018) 〈https://www.cio.com/article/3250697/data-is-not-the-new-oil-and-it-s-not-the-infrastructure-of-the-digital-economy-either.html〉 Google Scholar Malone and Klein, 2007 T.W. Malone, M. Klein Harnessing collective intelligence to address global climate change Innovations: Technology, Governance, Globalization, 2 (3) (2007), pp. 15-26 CrossRefGoogle Scholar Maqableh and Alia, 2021 M. Maqableh, M. Alia Evaluation online learning of undergraduate students under lockdown amidst COVID-19 Pandemic: The online learning experience and students’ satisfaction Children and Youth Services Review, 128 (2021), Article 106160 View PDFView articleView in ScopusGoogle Scholar Marques et al., 2019 C. Marques, S.J. Bachega, D.M. Tavares Framework proposal for the environmental impact assessment of universities in the context of Green IT Journal of Cleaner Production, 241 (2019), Article 118346 View PDFView articleView in ScopusGoogle Scholar Marr, 2018 Marr, B. (2018). The 5 Big Problems With Blockchain Everyone Should Be Aware Of. 〈https://www.forbes.com/sites/bernardmarr/2018/02/19/the-5-big-problems-with-blockchain-everyone-should-be-aware-of/?sh=6196c82a1670〉. Google Scholar Masson-Delmotte et al., 2018 Masson-Delmotte, V., Zhai, P., Pörtner, H. O., Roberts, D., Skea, J., Shukla, P. R.,. & Waterfield, T. (2018). Global warming of 1.5C. An IPCC Special Report on the impacts of global warming of, 1(5). Google Scholar McGuinness and Schank, 2021 T.D. McGuinness, H. Schank Power to the Public: The Promise of Public Interest Technology Princeton University Press (2021) Google Scholar McLaren and Markusson, 2020 D. McLaren, N. Markusson The co-evolution of technological promises, modelling, policies and climate change targets Nature Climate Change, 10 (5) (2020), pp. 392-397 CrossRefView in ScopusGoogle Scholar Mees et al., 2019 H.L. Mees, C.J. Uittenbroek, D.L. Hegger, P.P. Driessen From citizen participation to government participation: An exploration of the roles of local governments in community initiatives for climate change adaptation in the Netherlands Environmental Policy and Governance, 29 (3) (2019), pp. 198-208 CrossRefView in ScopusGoogle Scholar Melville, 2010 N.P. Melville Information systems innovation for environmental sustainability MIS Quarterly, 34 (1) (2010), pp. 1-21 CrossRefView in ScopusGoogle Scholar Mensah et al., 2015 A.K. Mensah, I.O. Mahiri, O. Owusu, O.D. Mireku, I. Wireko, E.A. Kissi Environmental Impacts of Mining: A Study of Mining Communities in Ghana Applied Ecology and Environmental Sciences, 3 (3) (2015), pp. 81-94 Google Scholar Mercator, 2021 Mercator At least 85 percent of world’s population impacted by climate change Joint Press Release of MCC and Climate Analytics (2021) (available at) 〈https://www.mcc-berlin.net/en/news/information/information-detail/article/at-least-85-percent-of-worlds-population-impacted-by-climate-change.html〉 Google Scholar Merkle et al., 2021 L. Merkle, M. Pöthig, F. Schmid Estimate e-Golf Battery State Using Diagnostic Data and a Digital Twin Batteries, 7 (2021), p. 15, 10.3390/batteries7010015 Google Scholar Merrill et al., 2019 R.K. Merrill S.J.D. Schillebeeckx S. Blakstad Sustainable digital finance in Asia: Creating environmental impact through bank transformation 2019 SDFA, DBS, UN Environment,. Google Scholar Michael and Abbas, 2020 Michael, K., & Abbas, R. (2020). Public Interest Technology. Proceedings presented at the ISTAS20: International Symposium on Technology and Society, Tempe, Arizona, 12–15 November 2020. Google Scholar Mikalef et al., 2020 P. Mikalef, M. Bourab, G. Lekakos, J. Krogstie The role of information governance in big data analytics driven innovation Information & Management, 57 (7) (2020), Article 103361 View PDFView articleView in ScopusGoogle Scholar Miller, 2020 Miller Climate change solutions: The role of technology House of Commons Library, (2020) 〈https://commonslibrary.parliament.uk/climate-change-solutions-the-role-of-technology/〉 Google Scholar Miller, 2021 M. Miller Information Technology Sector: Overview and Funds ValuePenguin (2021) 〈https://www.valuepenguin.com/sectors/information-technology〉 Google Scholar Mingers, 2002 J. Mingers Can social systems be autopoietic? Assessing Luhmann's social theory The Sociological Review, 50 (2) (2002), pp. 278-299 View in ScopusGoogle Scholar Mingers, 2004 J. Mingers Can social systems be autopoietic? Bhaskar's and Giddens’ social theories Journal for the Theory of Social Behaviour, 34 (4) (2004), pp. 403-427 CrossRefView in ScopusGoogle Scholar Mirbabaie et al., 2020 M. Mirbabaie, D. Bunker, S. Stieglitz, J. Marx, C. Ehnis Social media in times of crisis: Learning from Hurricane Harvey for the coronavirus disease 2019 pandemic response Journal of Information Technology, 35 (3) (2020), pp. 195-213 CrossRefView in ScopusGoogle Scholar Miyamoto et al., 2001 Miyamoto, S., Harada, H., & Fujimoto, J. (2001, December). Environmental impact assessment for various information technology systems and classification by their environmental aspects. In Proceedings Second International Symposium on Environmentally Conscious Design and Inverse Manufacturing (pp. 785–790). IEEE. Google Scholar Monson, 2021 M. Monson Socially responsible design science in information systems for sustainable development: a critical research methodology European Journal of Information Systems (2021), pp. 1-31, 10.1080/0960085X.2021.1946442 Google Scholar Mora et al., 2018 C. Mora, R.L. Rollins, K. Taladay, M.B. Kantar, M.K. Chock, M. Shimada, E.C. Franklin Bitcoin emissions alone could push global warming above 2C Nature Climate Change, 8 (11) (2018), pp. 931-933 CrossRefView in ScopusGoogle Scholar More, 1973 T. More Utopia. Arguing for social justice. A program Routledge Classics,, London (1973) Google Scholar Mozaffar and Panteli, 2021 H. Mozaffar, N. Panteli The online community knowledge flows: distance and direction European Journal of Information Systems (2021), pp. 1-14, 10.1080/0960085X.2020.1866442 View in ScopusGoogle Scholar Mukhopadhyay and Suryadevara, 2014 S.C. Mukhopadhyay, N.K. Suryadevara Internet of things: Challenges and opportunities Internet of Things, Springer,, Cham (2014), pp. 1-17 CrossRefGoogle Scholar Murugesan, 2008 S. Murugesan Harnessing Green IT: Principles and Practices IT Professional, 10 (1) (2008), pp. 24-33 View in ScopusGoogle Scholar Murugesan, 2021 S. Murugesan Making Information Tech Greener Can Help Address the Climate Crisis October 7 IEEE Spectrum (2021) October 7 〈https://spectrum.ieee.org/making-information-tech-greener〉 Google Scholar Naeem et al., 2016 S. Naeem, R. Chazdon, J. Duffy, P. C, B. Worm Biodiversity and human well-being: an essential link for sustainable development Proc. R. Soc. B, 283 (20162091) (2016), 10.1098/rspb.2016.2091 Google Scholar Nair et al., 2021 R.S. Nair, R. Agrawal, S. Domnic, A. Kumar Image mining applications for underwater environment management-A review and research agenda International Journal of Information Management Data Insights, 1 (2) (2021), Article 100023 View PDFView articleView in ScopusGoogle Scholar Namami Gange Programme, 2020 Namami Gange Programme (2020). Central government, India, available at 〈https://nmcg.nic.in/NamamiGanga.aspx〉. Google Scholar Nan and Lu, 2014 N. Nan, Y. Lu Harnessing the power of self-organization in an online community during organizational crisis MIS Quarterly, 38 (4) (2014), pp. 1135-1158 CrossRefView in ScopusGoogle Scholar Nardi et al., 2018 B. Nardi, B. Tomlinson, D.J. Patterson, J. Chen, D. Pargman, B. Raghavan, B. Penzenstadler Computing within limits Communication of the ACM, 61 (10) (2018), pp. 86-93, 10.1145/3183582 View in ScopusGoogle Scholar National Academies of Sciences, Engineering, and Medicine, 2021 National Academies of Sciences, Engineering, and Medicine Accelerating Decarbonization of the U.S (Available at) Energy System (2021), 10.17226/25932 Google Scholar Naujok et al., 2018 N. Naujok, H. Fleming, N. Srivatsav Digital technology and sustainability: Positive mutual reinforcement Energy and Sustainability (2018) (Available at) 〈https://www.strategy-business.com/article/Digital-Technology-and-Sustainability-Positive-Mutual-Reinforcement〉 Google Scholar NCAP, 2020 NCAP (2020). PIB Delhi, Central government, India, available at 〈https://pib.gov.in/PressReleasePage.aspx?PRID=1655203〉. Google Scholar Nelson and Winter, 1977 R.R. Nelson, S.G. Winter In search of a useful theory of innovation Research Policy, 6 (1977), pp. 36-76 View PDFView articleView in ScopusGoogle Scholar Nishant et al., 2020 R. Nishant, M. Kennedy, J. Corbett Artificial intelligence for sustainability: Challenges, opportunities, and a research agenda International Journal of Information Management, 53 (2020), Article 102104 View PDFView articleView in ScopusGoogle Scholar Nishant et al., 2017 R. Nishant, T.S. Teo, M. Goh Do shareholders value green information technology announcements? Journal of the Association for Information Systems, 18 (8) (2017), p. 3 (Available at) 〈https://aisel.aisnet.org/jais/vol18/iss8/3〉 Google Scholar Nižetić et al., 2020 S. Nižetić, P. Šolić, D.L.D.I. González-de, L. Patrono Internet of Things (IoT): Opportunities, issues and challenges towards a smart and sustainable future Journal of Cleaner Production, 274 (2020), Article 122877 View PDFView articleView in ScopusGoogle Scholar Noriega, 2020 M. Noriega The application of artificial intelligence in police interrogations: An analysis addressing the proposed effect AI has on racial and gender bias, cooperation, and false confessions Futures, 117 (2020), Article 102510 View PDFView articleView in ScopusGoogle Scholar Norway, 2016 Norway Digital agenda for Norway in brief: ICT for a simpler everyday life and increased productivity Ministry of Local Government and Modernisation,, Norway (2016) (Available at) 〈https://www.regjeringen.no/en/dokumenter/digital-agenda-for-norway-in-brief/id2499897/〉 Google Scholar Nüttgens et al., 2011 {Nüttgens, M. Gadatsch, A. Kautz, K. Schirmer, I. & Blinn, N. eds (2011) IFIP WG8.6 Working Conference - Governance and Sustainability in Information Systems - Managing the Transfer and Diffusion of IT, Hamburg, Germany, 24th September 2011. Google Scholar Nyberg, 2018 R.A. Nyberg Using ‘smartness’ to reorganise sectors: Energy infrastructure and information engagement International Journal of Information Management, 39 (2018), pp. 60-68 View PDFView articleView in ScopusGoogle Scholar Oberhaus, 2019 D. Oberhaus Amazon, Google, Microsoft: Here’s Who Has the Greenest Cloud Wired (2019) 〈https://www.wired.com/story/amazon-google-microsoft-green-clouds-and-hyperscale-data-centers/〉 Google Scholar O'Dwyer and Malone, 2014 O'Dwyer, K.J.; Malone, D. Bitcoin Mining and its Energy Footprint. In Proceedings of the ISSC Irish Signals & Systems Conference and China-Ireland International Conference on Information and Communications Technologies (ISSC 2014/CIICT 2014), Limerick, Ireland, 26–27 June 2014. Google Scholar Ojala and Oksanen, 2021 T. Ojala, P. Oksanen Climate and environment strategy for the ICT Sector Publication of the Ministry of transport and communication, (2021) 2021:6. Available at 〈https://api.hankeikkuna.fi/asiakirjat/11923966-e31b-450a-9688-87a827f8e6ba/10fef198-ec82-43e6-85c0-aedb71198d93/STRATEGIA_20210311113306.pdf〉 Google Scholar Ojo and Fauzi, 2020 A.O. Ojo, M.A. Fauzi Environmental awareness and leadership commitment as determinants of IT professionals engagement in Green IT practices for environmental performance Sustainable Production and Consumption, 24 (2020), pp. 298-307 View PDFView articleView in ScopusGoogle Scholar Okafor, 2020 J. Okafor Negative impact of technology on the environment TRVST, (2020) (Access from) 〈https://www.trvst.world/environment/negative-impact-of-technology-on-the-environment/〉 Google Scholar Osibanjo and Nnorom, 2007 O. Osibanjo, I.C. Nnorom The challenge of electronic waste (e-waste) management in developing countries Waste Management & Research, 25 (6) (2007), pp. 489-501 View in ScopusGoogle Scholar Pan and Zhang, 2020 S.L. Pan, S. Zhang From fighting COVID-19 pandemic to tackling sustainable development goals: An opportunity for responsible information systems research International Journal of Information Management, 55 (2020), Article 102196 View PDFView articleView in ScopusGoogle Scholar Pan et al., 2022 S. Pan, L. Carter, Y. Tim, M.S. Sandeep Digital Sustainability, Climate Change, and Information Systems Solutions: Opportunities for Future Research International Journal of Information Management (2022), 10.1016/j.ijinfomgt.2021.102444 Google Scholar Panteli, 2016 N. Panteli On leaders’ presence: interactions and influences within online communities Behaviour & Information Technology, 35 (6) (2016), pp. 490-499 View in ScopusGoogle Scholar Panteli and Marder, 2017 N. Panteli, B. Marder Constructing and enacting normality online across generations: The case of social networking sites Information Technology & People, 30 (2) (2017), pp. 282-300 View in ScopusGoogle Scholar Panteli and Sivunen, 2019 N. Panteli, A. Sivunen I Am Your Fan; Bookmarked!” Members’ identification development in founder-led online communities Journal of the Association for Information Systems, 20 (6) (2019), pp. 830-847 Google Scholar Papadopoulos and Balta, 2022 T.A. Papadopoulos, M.E. Balta Climate Change, Big Data, Big Data Analytics, sustainability, challenges International Journal of Information Management (2022), 10.1016/j.ijinfomgt.2021.102448 Google Scholar Papagiannidis and Marikyan, 2022 S. Papagiannidis, D. Marikyan Environmental Sustainability: A technology acceptance perspective International Journal of Information Management (2022), 10.1016/j.ijinfomgt.2021.102445 Google Scholar Park et al., 2015 C.K. Park, H.R. Byun, R. Deo, B.R. Lee Drought prediction till 2100 under RCP 8.5 climate change scenarios for Korea Journal of Hydrology, 526 (2015), pp. 221-230 View PDFView articleView in ScopusGoogle Scholar Parker et al., 2016 G.G. Parker, M.W. Van Alstyne, S.P. Choudary Platform revolution: How networked markets are transforming the economy and how to make them work for you WW Norton & Company, (2016) Google Scholar Patón-Romero et al., 2021 J.D. Patón-Romero, M.T. Baldassarre, A. Toval, M. Rodríguez, M. Piattini Auditing the governance and management of green IT Journal of Computer Information Systems (2021), 10.1080/08874417.2021.1939198 Google Scholar Pearse, 2017 R. Pearse Gender and climate change WIREs Climate Change, 8 (2) (2017), Article e451, 10.1002/wcc.451 View in ScopusGoogle Scholar Pee and Pan, 2022 L.G. Pee, S.L. Pan Climate-Intelligent Cities and Resilient Urbanisation: Challenges and Opportunities for Information Research International Journal of Information Management (2022), 10.1016/j.ijinfomgt.2021.102446 Google Scholar Perkins et al., 2018 K.M. Perkins, N. Munguia, R. Moure-Eraso, B. Delakowitz, B.F. Giannetti, G. Liu, L. Velazquez International perspectives on the pedagogy of climate change Journal of Cleaner Production, 200 (2018), pp. 1043-1052 View PDFView articleView in ScopusGoogle Scholar Perrow, 1991 C. Perrow A society of organizations Theory and Society, 20 (6) (1991), pp. 725-762 View in ScopusGoogle Scholar Pigou, 1920 A.C. Pigou Economics of Welfare. Mcmillan and Co, New Jersey (1920) Google Scholar Pitt et al., 2021 J. Pitt, K. Michael, R. Abbas Public Interest Technology, Citizen Assemblies, and Performative Governance IEEE Technology and Society Magazine, 40 (3) (2021), pp. 6-9 CrossRefView in ScopusGoogle Scholar Poff et al., 1996 N.L. Poff, S. Tokar, P. Johnson Stream hydrological and ecological responses to climate change assessed with an artificial neural network Limnology and Oceanography, 41 (5) (1996), pp. 857-863 CrossRefView in ScopusGoogle Scholar POPIA, 2020 POPIA. (2020). Protection of Personal Information Act (POPI Act). Retrieved December 12, 2020, from POPIA South Africa website: 〈https://popia.co.za/〉. Google Scholar Popper, 1974 K. Popper The logic of scientific discovery Routledge Classics, London (1974) Google Scholar Pringle et al., 2016 R. Pringle, K. Michael, M.G. Michael Unintended consequences of living with AI: The paradox of technological potential? IEEE Technology and Society Magazine, 35 (4) (2016), pp. 17-21 View in ScopusGoogle Scholar Rajkumar et al., 2010 R. Rajkumar, I. Lee, L. Sha, J. Stankovic Cyber-physical systems: the next computing revolution Design automation conference, IEEE (2010), pp. 731-736 CrossRefView in ScopusGoogle Scholar Rashid, 2016 A.T. Rashid Digital inclusion and social inequality: Gender differences in ICT access and use in five developing countries Gender, Technology and Development, 20 (3) (2016), pp. 306-332 CrossRefView in ScopusGoogle Scholar Ravishankar et al., 2013 M. Ravishankar, S. Pan, M. Myers Information technology offshoring in India: a postcolonial perspective European Journal of Information Systems, 22 (2013), pp. 387-402, 10.1057/ejis.2012.32 View in ScopusGoogle Scholar Ren et al., 2007 Y. Ren, R. Kraut, S. Kiesler Applying common identity and bond theory to design of online communities Organization Studies, 28 (3) (2007), pp. 377-408 View in ScopusGoogle Scholar Rheingold, 1993 H. Rheingold The virtual community: Finding commection in a computerized world Addison-Wesley Longman Publishing Co., Inc. (1993) Google Scholar Richter, 2020 A. Richter Locked-down digital work International Journal of Information Management, 55 (2020), Article 102157 View PDFView articleView in ScopusGoogle Scholar Ritthof et al., 2002 M. Ritthof, H. Rohn, C. Liedtke Calculating MIPS Resource productivity of products and services, Wuppertal Institute for climate, environment Energy (2002), p. 52 Google Scholar Robertson, 2021 I. Robertson AI and climate change Innovators (2021) 〈https://www.innovatorsmag.com/ai-and-climate-change/〉 Google Scholar Rodó et al., 2021 X. Rodó, A. San-José, K. Kirchgatter, L. López Changing climate and the COVID-19 pandemic: more than just heads or tails Nature Medicine, 27 (4) (2021), pp. 576-579 CrossRefView in ScopusGoogle Scholar Rowe, 2018 F. Rowe Being critical is good, but better with philosophy: from digital transformation and values to future of IS research European Journal of Information Systems, 27 (3) (2018), pp. 380-393 CrossRefView in ScopusGoogle Scholar Saberi et al., 2019 S. Saberi, M. Kouhizadeh, J. Sarkis, L. Shen Blockchain technology and its relationships to sustainable supply chain management International Journal of Production Research, 57 (7) (2019), pp. 2117-2135 CrossRefView in ScopusGoogle Scholar Salam, 2020 A. Salam Internet of things for environmental sustainability and climate change Internet of Things for Sustainable Community Development, Springer, Cham (2020), pp. 33-69 View in ScopusGoogle Scholar Sarker and Nicholson, 2005 S. Sarker, J. Nicholson Myths about online education: a preliminary examination Informing Science Journal, 8 (2005) (2005), pp. 55-73 View in ScopusGoogle Scholar Sarker et al., 2019 S. Sarker, S. Chatterjee, X. Xiao, A. Elbanna The sociotechnical perspective as an ‘axis of cohesion’ for the IS discipline: Recognizing its historical legacy and ensuring its continued relevance MIS Quarterly, 43 (3) (2019), pp. 695-719 CrossRefView in ScopusGoogle Scholar Schmidt and Sewerin, 2017 T.S. Schmidt, S. Sewerin Technology as a driver of climate and energy politics Nature Energy, 2 (6) (2017), pp. 1-3 CrossRefGoogle Scholar Scholz, 2020 R.W. Scholz Transdisciplinarity: science for and with society in light of the university’s roles and functions Sustainability Science, 15 (4) (2020), pp. 1033-1049 CrossRefView in ScopusGoogle Scholar Schoormann et al., 2021 T. Schoormann, M. Stadtländer, R. Knackstedt Designing business model development tools for sustainability—a design science study Electronic Markets (2021), 10.1007/s12525-021-00466-3 Google Scholar Schroder et al., 2021 Schroder, A., Prockl, G., & Constantiou, I. (2021, January). How Digital Platforms with a Social Purpose Trigger Change towards Sustainable Supply Chains. In Proceedings of the 54th Hawaii International Conference on System Sciences, 4785–4795. Google Scholar Scott and Davis, 2015 W.R. Scott, G.F. Davis Organizations and organizing: Rational, natural and open systems perspectives Routledge (2015) Google Scholar Şerban and Lytras, 2020 A.C. Şerban, M.D. Lytras Artificial intelligence for smart renewable energy sector in europe—smart energy infrastructures for next generation smart cities IEEE Access, 8 (2020), pp. 77364-77377 CrossRefView in ScopusGoogle Scholar Shaftel, 2021 H. Shaftel Climate Change: How Do We Know? NASA (2021) 〈https://climate.nasa.gov/evidence/〉 Google Scholar Sharma et al., 2020 P.K. Sharma, N. Kumar, J.H. Park Blockchain technology toward green IoT: Opportunities and challenges IEEE Network, 34 (4) (2020), pp. 263-269 CrossRefView in ScopusGoogle Scholar Shee et al., 2018 H. Shee, S.J. Miah, L. Fairfield, N. Pujawan The impact of cloud-enabled process integration on supply chain performance and firm sustainability: the moderating role of top management Supply Chain Management: An International Journal, 23 (6) (2018), pp. 500-517 CrossRefView in ScopusGoogle Scholar Shehabi et al., 2016 Shehabi, A., Smith, S., Sartor, D., Brown, R., Herrlin, M., Koomey, J.,. & Lintner, W. (2016). United states data center energy usage report. Available on Oct. 27, 2021 at 〈https://escholarship.org/content/qt84p772fc/qt84p772fc.pdf〉. Google Scholar Simmonds and Bhattacherjee, 2012 D. Simmonds, A. Bhattacherjee Environmental sustainability in organizations: The information technology role AMCIS 2012 Proceedings, 11 (2012) Google Scholar Singh and Sahu, 2020 M. Singh, G.P. Sahu Towards adoption of Green IS: A literature review using classification methodology International Journal of Information Management, 54 (2020), Article 102147 View PDFView articleView in ScopusGoogle Scholar Sky News, 2021 Sky News Climate change: Seven technology solutions that could help solve crisis Sky News Science & Tech, (2021) 〈https://news.sky.com/story/climate-change-seven-technology-solutions-that-could-help-solve-crisis-12056397〉 Google Scholar Smith and Stirling, 2008 Smith, A. & Stirling, A. (2008) Social-ecological resilience and sociotechnical transitions Brighton: STEPS Centre. Google Scholar Smith et al., 2005 A. Smith, A. Stirling, F. Berkhout The governance of sustainable socio-technical transitions Research Policy, 34 (10) (2005), pp. 1491-1510 View PDFView articleView in ScopusGoogle Scholar Smith and Watson, 2020 C. Smith, J. Watson From streams to streaming: a critique of the influence of STEM on students’ imagination for a sustainable future Journal of Applied Teaching and Learning, 3 (2020), pp. 21-29 View in ScopusGoogle Scholar Stilgoe et al., 2013 J. Stilgoe, R. Owen, P. Macnaghten Developing a framework for responsible innovation Research Policy, 42 (9) (2013), pp. 1568-1580 View PDFView articleView in ScopusGoogle Scholar Stoll et al., 2019 C. Stoll, L. Klaaßen, U. Gallersdörfer The carbon footprint of bitcoin Joule, 3 (7) (2019), pp. 1647-1661 View PDFView articleView in ScopusGoogle Scholar Strubell et al., 2019 Strubell E., Ganesh A., & McCallum A. (2019). Energy and policy considerations for deep learning in NLP, 57th Annual Meeting of the Association for Computational Linguistics (ACL). Florence, Italy. Google Scholar Sutherland and Jarrahi, 2018 W. Sutherland, M.H. Jarrahi The sharing economy and digital platforms: A review and research agenda International Journal of Information Management, 43 (2018), pp. 328-341 View PDFView articleView in ScopusGoogle Scholar Tamburini et al., 2015 L. Tamburini, M. Rossi, D. Brunelli Electronic and ICT solutions for smart buildings and urban areas Handbook of Research on Social, Economic, and Environmental Sustainability in the Development of Smart Cities, IGI Global, (2015), pp. 165-192 CrossRefView in ScopusGoogle Scholar Tan and Nielsen, 2021 B. Tan, P. Nielsen Information Systems and Sustainable Development: Call for Papers for a Special Issue Information Systems Journal (2021) 〈https://onlinelibrary.wiley.com/pb-assets/assets/13652575/ISJ_Information%20Systems%20and%20Sustainability_Call%20for%20Paperv180921-1632307367400.pdf〉 Google Scholar Tan et al., 2021 Z.M. Tan, N. Aggarwal, J. Cowls, J. Morley, M. Taddeo, L. Floridi The ethical debate about the gig economy: A review and critical analysis Technology in Society, 65 (2021), Article 101594 View PDFView articleView in ScopusGoogle Scholar Tejedor et al., 2018 G. Tejedor, J. Segalàs, M. Rosas-Casals Transdisciplinarity in higher education for sustainability: How discourses are approached in engineering education Journal of Cleaner Production, 175 (2018), pp. 29-37 View PDFView articleView in ScopusGoogle Scholar Teubler et al., 2018 J. Teubler, S. Kiefer, C. Liedtke Metals for Fuels? The Raw Material Shift by Energy-Efficient Transport Systems in Europe Resources, 7 (3) (2018), p. 49, 10.3390/resources7030049 View in ScopusGoogle Scholar Thunberg, 2021 Thunberg, G. (2021), There are no real climate leaders yet – who will step up at Cop26? The Guardian, October, 21, 2021 〈https://www.theguardian.com/commentisfree/2021/oct/21/climate-leaders-cop26-uk-climate-crisis-glasgow〉. Google Scholar Tim et al., 2018 Y. Tim, S.L. Pan, S. Bahri, A. Fauzi Digitally enabled affordances for community-driven environmental movement in rural Malaysia Information Systems Journal, 28 (1) (2018), pp. 48-75 CrossRefView in ScopusGoogle Scholar Tollefson, 2020 J. Tollefson Why deforestation and extinctions make pandemics more likely Nature, 584 (7820) (2020), pp. 175-176 CrossRefView in ScopusGoogle Scholar Trist, 1981 E.L. Trist The Evolution of Socio-Technical Systems, Vol. 2, Ontario Quality of Working Life Centre,, Toronto (1981) Google Scholar Trkman and Černe, 2022 P. Trkman, M. Černe Humanising digital life – Reducing emissions while enhancing value- adding human processes International Journal of Information Management (2022), 10.1016/j.ijinfomgt.2021.102443 Google Scholar UN News (2015). UN chief hails Papal Encyclical spotlighting climate change as critical ‘moral issue’, available at https://news.un.org/en/story/2015/06/501992 UN News (2015). UN chief hails Papal Encyclical spotlighting climate change as critical ‘moral issue’, available at https://news.un.org/en/story/2015/06/501992. Google Scholar UN report, 2019 UN report (2019) Time to seize opportunity, tackle challenge of e-waste, 〈https://www.unep.org/news-and-stories/press-release/un-report-time-seize-opportunity-tackle-challenge-e-waste〉 Accessed on Oct. 20, 2021. Google Scholar UNFCCC, 2016 UNFCCC (2016). ICT Sector Helping to Tackle Climate Change, 〈https://unfccc.int/news/ict-sector-helping-to-tackle-climate-change〉 Accesses on Oct. 20, 2021. Google Scholar United Nations (UN), 2021 United Nations (UN). (2021). Accessed on October 27, 2021 at 〈https://unstats.un.org/sdgs/report/2021/The-Sustainable-Development-Goals-Report-2021.pdf〉. Google Scholar United Nations Department of Economic and Social Affairs, 2015 United Nations Department of Economic and Social Affairs (2015). Global Sustainable Development Report, 〈https://sustainabledevelopment.un.org/globalsdreport/2015〉). Google Scholar United Nations Environment Programme, 2021 United Nations Environment Programme (2021). Emissions Gap Report 2021: The Heat Is On – A World of Climate Promises Not Yet Delivered. Nairobi. Google Scholar Ullah et al., 2020 Z. Ullah, F. Al-Turjman, L. Mostarda, R. Gagliardi Applications of artificial intelligence and machine learning in smart cities Comput. Commun., 154 (2020), pp. 313-323 View PDFView articleView in ScopusGoogle Scholar Vaast and Levina, 2015 E. Vaast, N. Levina Speaking as one, but not speaking up: Dealing with new moral taint in an occupational online community Information and Organization, 25 (2) (2015), pp. 73-98 View PDFView articleView in ScopusGoogle Scholar Van der Hoogen et al., 2020 A. Van der Hoogen, B. Scholtz, A.P. Calitz Using Theories to Design a Value Alignment Model for Smart City Initiatives M. Hattingh, M. Matthee, H. Smuts, I. Pappas, Y. Dwivedi, M. Mäntymäki (Eds.), Responsible Design, Implementation and Use of Information and Communication Technology. I3E 2020. Lecture Notes in Computer Science, vol. 12066, Springer, Cham (2020), pp. 55-66, 10.1007/978-3-030-44999-5_5 View in ScopusGoogle Scholar Venkatesh et al., 2007 V. Venkatesh, F. Davis, M.G. Morris Dead or alive? The development, trajectory and future of technology adoption research Journal of the Association for Information Systems, 8 (4) (2007), p. 1 View PDFView articleView in ScopusGoogle Scholar Verbong and Geels, 2010 G.P.J. Verbong, F.W. Geels Exploring sustainability transitions in the electricity sector with socio-technical pathways Technological Forecasting and Social Change, 77 (8) (2010), pp. 1214-1221 View PDFView articleView in ScopusGoogle Scholar von Bertalanffy, 1950 L. von Bertalanffy The theory of open systems in physics and biology Science, 111 (2872) (1950), pp. 23-29 CrossRefView in ScopusGoogle Scholar von Hippel, 2011 F.N. von Hippel The radiological and psychological consequences of the Fukushima Daiichi accident Bulletin of the Atomic Scientists, 67 (5) (2011), pp. 27-36, 10.1177/0096340211421588 View in ScopusGoogle Scholar Wade, 2016 L. Wade Tesla’s electric cars aren’t as green as you might think Wired (2016) Google Scholar Wade, 2020 M. Wade Corporate digital responsibility in a digital era Mitosz Sloan Management Review (2020) April 2020 Google Scholar Walsham, 2012 G. Walsham Are we making a better world with ICTs? Reflections on a future agenda for the IS field Journal of Information Technology, 27 (2) (2012), pp. 87-93 CrossRefView in ScopusGoogle Scholar Wang et al., 2018 D.D. Wang, S. Li, T. Sueyoshi Determinants of climate change mitigation technology portfolio: An empirical study of major US firms Journal of Cleaner Production, 196 (2018), pp. 202-215 View PDFView articleView in ScopusGoogle Scholar Wang et al., 2015a X. Wang, S. Brooks, S. Sarker A review of green IS research and directions for future studies Communications of the Association for Information Systems, 37 (1) (2015), p. 21 View PDFView articleGoogle Scholar Wang et al., 2015b Y. Wang, Y. Chen, J. Benitez-Amado How information technology influences environmental performance: Empirical evidence from China International Journal of Information Management, 35 (2) (2015), pp. 160-170 View PDFView articleView in ScopusGoogle Scholar Watson et al., 2010 R.T. Watson, M.C. Boudreau, A.J. Chen Information systems and environmentally sustainable development: energy informatics and new directions for the IS community MIS Quarterly (2010), pp. 23-38 CrossRefView in ScopusGoogle Scholar Watson et al., 2021 R.T. Watson, S. Elliot, J. Corbett, D. Farkas, A. Feizabadi, A. Gupta, …, J. Webster How the AIS can Improve its Contributions to the UN’s Sustainability Development Goals: Towards A Framework for Scaling Collaborations and Evaluating Impact (pp) Communications of the Association for Information Systems, 48 (2021), 10.17705/1CAIS.04841 Google Scholar WEF, 2021 WEF (2021). 〈https://www.weforum.org/agenda/2021/10/as-the-world-gathers-for-cop26-here-s-how-leaders-can-dispel-esg-confusion-ac418a72bc/〉. Google Scholar WEF report, 2019 WEF report (2019). 〈https://www.weforum.org/reports/a-new-circular-vision-for-electronics-time-for-a-global-reboot〉 Accessed on Oct. 20, 2021. Google Scholar Whyte, 2020 K. Whyte Too late for indigenous climate justice: Ecological and relational tipping points. Wiley Interdisciplinary Reviews Climate Change, 11 (1) (2020), Article e603 View in ScopusGoogle Scholar Wikipedia, 2021 Wikipedia (2021) Coltan: 〈https://en.wikipedia.org/wiki/Coltan〉. Google Scholar Williams, 2010 P.T. Williams Valorization of printed circuit boards from waste electrical and electronic equipment by pyrolysis Waste and Biomass Valorization, 1 (1) (2010), pp. 107-120 CrossRefView in ScopusGoogle Scholar Winner, 1978 L. Winner Autonomous technology: Technics-out-of-control as a theme in political thought MIT Press,, Boston (1978) Google Scholar Winter and Butler, 2011 S.J. Winter, B.S. Butler Creating bigger problems: grand challenges as boundary objects and the legitimacy of the information systems field Journal of Information Technology, 26 (2) (2011), pp. 99-108 CrossRefView in ScopusGoogle Scholar World Economic Forum & PwC, 2021 World Economic Forum & PwC (2021), Harnessing Technology for the Global Goals: A framework for government action, Accessed on 31st October 2021. 〈https://assets.2030vision.com/files/resources/wef-harnessing-technology-for-the-global-goals-2021.pdf?470b76352b〉. Google Scholar World Health Organization and Secretariat of the Convention on Biological Diversity, 2015 World Health Organization and Secretariat of the Convention on Biological Diversity Connecting Global Priorities: Biodiversity and Human Health. A State of Knowledge Review UN Environment Programme (2015) 〈https://stg-wedocs.unep.org/bitstream/handle/20.500.11822/7508/-Connecting_Global_Priorities_Biodiversity_and_Human_Health-2015Connecting-Global-Priorities-Biodiversity-and-Human-Health_2015.pdf.pdf?sequence=3〉 Google Scholar World Health Organization, 2015 World Health Organization. (2015). Health in 2015: from MDGs, millennium development goals to SDGs, sustainable development goals. 〈https://www.who.int/data/gho/publications/mdgs-sdgs〉. Google Scholar Wright and Nyberg, 2017 C. Wright, D. Nyberg An inconvenient truth: How organizations translate climate change into business as usual Academy of Management Journal, 60 (5) (2017), pp. 1633-1661 CrossRefView in ScopusGoogle Scholar Wunderlich et al., 2019 P. Wunderlich, D.J. Veit, S. Sarker Adoption of Sustainable Technologies: A Mixed-Methods Study of German Households MIS Quarterly, 43 (2) (2019), pp. 673-691 CrossRefView in ScopusGoogle Scholar Xie et al., 2020 X. Xie, K. Siau, F.F.H. Nah COVID-19 pandemic–online education in the new normal and the next normal Journal of Information Technology Case and Application Research, 22 (3) (2020), pp. 175-187 CrossRefView in ScopusGoogle Scholar Yadav et al., 2021 H. Yadav, A.K. Kar, S. Kashiramka How does entrepreneurial orientation and SDG orientation of CEOs evolve before and during a pandemic Journal of Enterprise Information Management (2021), 10.1108/JEIM-03-2021-0149 Google Scholar Yadav et al., 2017 Yadav, P., Hasan, S., Ojo, A., & Curry, E. (2017). The Role of Open Data in Driving Sustainable Mobility in Nine Smart Cities. 25th European Conference on Information Systems (ECIS 2017), Guimarães, Portugal, 5–10 June, 1248–1263. Google Scholar YouTube, 2017 YouTube (2017) Congo my precious: The curse of the coltan mines in Congo, 〈https://www.youtube.com/watch?v=dTwzCy0-RTw〉. Google Scholar Zarindast et al., 2021 A. Zarindast, A. Sharma, J. Wood Application of text mining in smart lighting literature-an analysis of existing literature and a research agenda International Journal of Information Management Data Insights, 1 (2) (2021), Article 100032 View PDFView articleView in ScopusGoogle Scholar Zeiss et al., 2021 R. Zeiss, A. Ixmeier, J. Recker, J. Kranz Mobilising information systems scholarship for a circular economy: Review, synthesis, and directions for future research Information Systems Journal, 31 (1) (2021), pp. 148-183 CrossRefView in ScopusGoogle Scholar Cited by (254) University of Pannonia Sustainability index (UPSi) for corporate sustainability 2024, Environmental and Sustainability Indicators Show abstract Public environmental concern, government environmental regulation and urban carbon emission reduction—Analyzing the regulating role of green finance and industrial agglomeration 2024, Science of the Total Environment Show abstract Smarter eco-cities and their leading-edge artificial intelligence of things solutions for environmental sustainability: A comprehensive systematic review 2024, Environmental Science and Ecotechnology Show abstract High performance hydrogen evolution energy conversion devices via p type polaron surface state modulation 2024, Applied Surface Science Show abstract Building sustainable performance in the maritime industry via digital resources and innovation 2024, Transport Policy Show abstract Guest editorial: More supportive or more distractive? Investigating the negative effects of technology at the customer interface 2024, International Journal of Information Management Show abstract View all citing articles on Scopus ☆ Roba Abbas, Daniela Andreini, Iyad Abumoghli, Yves Barlette, Deborah Bunker, Leona Chandra Kruse, Ioanna Constantiou, Robert M. Davison, Rahul De’, Rameshwar Dubey, Henry Fenby-Taylor, Babita Gupta, Wu He, Mitsuru Kodama, Matti Mäntymäki, Bhimaraya Metri, Katina Michael, Johan Olaisen, Niki Panteli, Samuli Pekkola, Rohit Nishant, Ramakrishnan Raman, Nripendra P. Rana, Frantz Rowe, Suprateek Sarker, Brenda Scholtz, Maung Sein, Jeel Dharmeshkumar Shah, Thompson S.H. Teo, Manoj Kumar Tiwari, Morten Thanning Vendelø, and Michael Wade have made equal contributions and are placed in alphabetical order. 1 Acknowledgment: We would like to thank Annapoornima Subramanian (NUS) and Shirish Srivastava (HEC Paris) for their useful comments and suggestions. 2 https://sciencebasedtargets.org/faqs#what-are-science-based-targets. 3 https://sciencebasedtargets.org/companies-taking-action#table. 4 How MBA Programs Are Changing Amid Multiple Crises | Time. 5 Maria Noriega, https://www.csomagazine.com/technology/managing-equipment-waste-knowing-when-say-goodbye. 6 Please refer to Sarker and Nicholson (2005) for a quick review of “myths” and the roles they play. 7 https://www.wired.co.uk/article/youtube-digital-waste-interaction-design. © 2021 The Authors. Published by Elsevier Ltd. Recommended articles Do shareholders favor business analytics announcements? The Journal of Strategic Information Systems, Volume 25, Issue 4, 2016, pp. 259-276 Thompson S.H. Teo, …, Pauline B.L. Koh View PDF Glasgow climate change conference (COP26) and its implications in sub-Sahara Africa economies Renewable Energy, Volume 206, 2023, pp. 214-222 Festus Fatai Adedoyin, …, Murat Ismet Haseki View PDF COP26 as an opportunity to further democratise the Green Climate Fund The Lancet Planetary Health, Volume 5, Issue 8, 2021, pp. e497-e498 Jessica Omukuti, …, Piran C L White View PDF Show 3 more articles Article Metrics Citations Citation Indexes: 214 Policy Citations: 6 Captures Readers: 1106 Mentions References: 1 Social Media Shares, Likes & Comments: 186676 View details About ScienceDirect Remote access Shopping cart Advertise Contact and support Terms and conditions Privacy policy Cookies are used by this site. Cookie settings | Your Privacy Choices All content on this site: Copyright © 2024 Elsevier B.V., its licensors, and contributors. All rights are reserved, including those for text and data mining, AI training, and similar technologies. For all open access content, the Creative Commons licensing terms apply.

Paper 2:
- APA Citation: Hameed, K., Bajwa, I. S., Ramzan, S., Anwar, W., & Khan, A. (2020). An Intelligent IoT Based Healthcare System Using Fuzzy Neural Networks. Scientiﬁc Programming, 2020, 8836927. https://doi.org/10.1155/2020/8836927
  Main Objective: The primary goal of the study is to propose an intelligent healthcare system using fuzzy neural networks that is capable of sensing, processing, and analyzing patient data to provide efficient and intelligent healthcare services.
  Study Location: Unspecified
  Data Sources: Sensors
  Technologies Used: Internet of Things (IoT), Fuzzy Neural Networks, Sensors
  Key Findings: - The proposed system is capable of sensing, processing, and analyzing patient data to provide efficient and intelligent healthcare services.
- The system uses fuzzy neural networks for decision-making, which provides high accuracy and reliability.
- The system is low-cost and easy to use, making it suitable for use in remote areas and developing countries.
  Extract 1: Obstacles in transmitting data in real-time
  Extract 2: Trough these devices, the patient information and data are transmitted by the expert system via gateway onto a secured cloud based platform where the information is stored and can be analyzed.
  Limitations: None mentioned
  Relevance Evaluation: Exceptionally relevant - Comprehensively addresses all key aspects of the point with highly insightful, reliable, and up-to-date information.
  Relevance Score: 1.0
  Inline Citation: (Hameed et al., 2020)
  Explanation: The paper explores the role of automated data collection and real-time processing in improving the efficiency and effectiveness of irrigation management systems. The specific point of focus is on the challenges and solutions in transmitting data in real-time. The researchers emphasize the importance of addressing these challenges to ensure seamless integration and autonomous operation of irrigation systems, contributing to the overall goal of food security and sustainable agriculture.

 Full Text: >
Research Article
An Intelligent IoT Based Healthcare System Using Fuzzy
Neural Networks
Kashif Hameed
,1 Imran Sarwar Bajwa
,1 Shabana Ramzan
,2
Waheed Anwar
,1 and Akmal Khan
1
1Department of Computer Science & IT, Te Islamia University of Bahawalpur, Bahawalpur 63100, Pakistan
2Department of Computer Science & IT, Te Govt. Sadiq College Women University, Bahawalpur, Pakistan
Correspondence should be addressed to Kashif Hameed; kashif_hameed78@yahoo.com
Received 20 July 2020; Revised 10 November 2020; Accepted 10 December 2020; Published 28 December 2020
Academic Editor: Shaukat Ali
Copyright © 2020 Kashif Hameed et al. Tis is an open access article distributed under the Creative Commons Attribution
License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is
properly cited.
Healthcare facilities in modern age are key challenge especially in developing countries where remote areas face lack of high-
quality hospitals and medical experts. As artiﬁcial intelligence has revolutionized various ﬁelds of life, health has also beneﬁted
from it. Te existing architecture of store-and-forward method of conventional telemedicine is facing some problems, some of
which are the need for a local health center with dedicated staﬀ, need for medical equipment to prepare patient reports, time
constraint of 24–48 hours in receiving diagnosis and medication details from a medical expert in a main hospital, cost of local
health centers, and need for Wi-Fi connection. In this paper, we introduce a novel and intelligent healthcare system that is based
on modern technologies like Internet of things (IoT) and machine learning. Tis system is intelligent enough to sense and process
a patient’s data through a medical decision support system. Tis system is low-cost solution for the people of remote areas; they
can use it to ﬁnd out whether they are suﬀering from a serious health issue and cure it accordingly by contacting near hospitals.
Te results of the experiments also show that the proposed system is eﬃcient and intelligent enough to provide health facilities.
Te results presented in this paper are the proof of the concept.
1. Introduction
Internet of things (IoT) is a network in which many devices
are connected, and these devices can communicate by
computer network [1]. By this worldwide network, we can
get information through sensors which relate to it. By using
computer network, we can access this information anywhere
in this world. Internet of things can connect physical objects
to Internet and can provide opportunity of building systems
which are based on various technologies such as near ﬁeld
communication (NFC) and wireless sensor network (WSN).
In wireless sensor network, sensors sense the environment
and send information to base station.
IoT has diﬀerent methodologies such as smart dustbin,
monitoring environment, IoT based irrigation system, smart
healthcare system, and traﬃc control. In healthcare system,
IoT brings gadget for monitoring health [2]. Health data can
be accessed with the help of IoT by using sensors. Healthcare
is a system which is used to improve health and help in
treating diseases [3].
Health related issues/complications are increasing day
by day, among which lung- and heart-related issues are top-
listed. Health can be monitored by wireless technology,
which is a modern concept. In wireless health monitoring
systems, diﬀerent technologies are used, including wearable
sensors, portable remote health system, wireless commu-
nications, and expert systems. Life is precious; even a single
life is also valuable, but due to lack of health facilities,
awareness about diseases, and proper access to healthcare
systems, people are dropping their lives. In all situations,
Internet of things (IoT) helps in the indication of diseases
and treatment of patients [4].
In IoT healthcare system, there exit wireless systems in
which diﬀerent applications and sensors are attached to
Hindawi
Scientiﬁc Programming
Volume 2020, Article ID 8836927, 15 pages
https://doi.org/10.1155/2020/8836927
patients, information is obtained, and this information is
forwarded to a doctor or specialist through an expert system
[5]. Medical devices for Internet of things (MD-IoT) are
remotely accessed, where devices are connected to the In-
ternet and sensors, actuators, and other communication
devices can monitor patient health [6]. Trough these de-
vices, the patient information and data are transmitted by
the expert system via gateway onto a secured cloud based
platform where the information is stored and can be
analyzed.
In developing countries like Pakistan, telemedicine is
used to handle health issues. Telemedicine refers to the
practice of caring for patients remotely when the provider
and patient are not physically present with each other.
Telemedicine is simply deﬁned as “the remote delivery of
healthcare services.” Although telemedicine brings with it
many beneﬁts, it has some downsides as well. Providers,
payers, and policymakers alike know that there are some
gray areas that are diﬃcult to keep up with. While the ﬁeld
will grow exponentially over the next decade, it will bring
with it both practical and technological challenges.
1.1. Unclear Policies. Because technology is growing at such
a fast pace, it has been diﬃcult for policymakers to keep up
with the industry. Tere is great uncertainty regarding
matters like reimbursement policies, privacy protection, and
healthcare laws. In addition, telemedicine laws vary from
state to state.
Tere are currently 29 states with telemedicine parity
laws, which require private payers to reimburse telemedicine
services in the same way they would reimburse in-person
visits. As additional states adopt parity laws, private payers
may institute more guidelines and restrictions for tele-
medicine services. Although it is a step in the right direction,
there is still uncertainty regarding reimbursement rates,
billing procedures, and more.
1.2. Fewer Face-to-Face Consultations. Several physicians
and patients are ﬁnding it diﬃcult to adapt to telemedicine,
especially older adults. Physicians are very concerned about
patient mismanagement. While advances in medicine have
made it more eﬃcient to use technology, there are times
when system outages occur. Tere is also the potential for
error as technology cannot always capture what the human
touch can.
1.3. Technology Is Expensive. Healthcare systems that adopt
telemedicine solutions can attest that they require a lot of
time and money. Implementing a new system requires
training, and sometimes staﬀ members ﬁnd it diﬃcult to
welcome this change. Practice managers, nurses, physicians,
and more have to learn how to utilize the system so that
practices can see the beneﬁts. Although telemedicine is
expensive in the beginning, healthcare systems should see a
positive return on investment over time due to more patients
and less staﬀ.
Te major components of healthcare systems are
identiﬁcation, location, sensing, and connectivity as shown
in Figure 1. Smart healthcare is implemented through a wide
range of systems: emergency services, smart computing,
sensors, lab on chips, remote monitoring, wearable devices,
connectivity devices, and big data.
Te IoT based systems are equipped with body sensor
networks within telemedicine systems. Tey include devices
with special type of nodes that sense periodic diﬀerence of
patient data; to check the ventilation conditions for the
patients in rooms, sensors are used to collect data for dif-
ferent measures contributing to ventilation process of a
room. Tese sensors are programmed to assess data of
diﬀerent ranges for temperature, pressure, humidity, and
other signiﬁcant environmental variables.
Tese arrangements help to monitor the patient con-
ditions remotely. Te system can send periodic reports to the
hospital and maintain the patient history. Te hospital staﬀ
can view the data and prepare the treatment plan for the
patient under observation. Te second type of devices used
in IoT healthcare systems is based on wireless sensor net-
works. Te situation is more complex than the above sce-
nario in terms of remote area patient monitoring and
management task. In some situations, IoT is the most re-
liable and cheapest solution, and the relationship between
diﬀerent devices and interactive communication systems
also needs to be investigated with more formal objectives.
Technology makes it easier to monitor the patient
health by sending information to healthcare teams such as a
doctor, nurses, and specialists through IoT (Internet of
things) and mobile technologies. It would be helpful for
professionals to save and gather patient data using store-
and-forward method so that it is accessible at any time. Te
role and services of IoT in modern healthcare are depicted
in Figure 2.
Internet of things (IoT) has diﬀerent methodologies:
smart healthcare, traﬃc control, smart dustbin, and vehicle
parking. Te health of patient is monitored by screen, so it is
diﬃcult to examine the patient all the time. Terefore, here,
patient’s current status, i.e., pulse rate, temperature, position
of body, blood glucose, and ECG, can be measured inten-
sively by using sensors. Te sensors are attached to Arduino
UNO sensors that, when attached to the body Arduino
board, get information and transmit it to the server. From
this server, the information is forwarded to the doctor who
advises for medicine.
Smart healthcare system is actually a technology in
which treatments of patients are possible and can improve
the standard of life [7]. In the concept of smart health, the
e-health concept is also included which has commands on
many technologies like electronic record management,
smart home services, and intelligent and medical connected
devices. Sensors, smart devices, and expert systems support
the health practice for smart healthcare system.
Healthcare facilities in modern age are key challenge
especially in developing countries where remote areas face
lack of high-quality hospitals and medical experts. As ar-
tiﬁcial intelligence has revolutionized various ﬁelds of life,
health has also beneﬁted from it. Te existing architecture of
2
Scientiﬁc Programming
store-and-forward method of conventional telemedicine is
facing some problems:
(i) Need for a local health center with dedicated staﬀ.
(ii) Need for medical equipment to prepare patient
reports.
(iii) Time constraint of 24–48 hours in receiving diag-
nosis and medication details from a medical expert
in a main hospital.
(iv) Cost of local health centers.
(v) Need for Wi-Fi connection.
In this paper, a novel and intelligent healthcare system is
proposed; it is based on modern technologies like Internet of
things (IoT) and machine learning. Tis system is intelligent
enough to sense and process a patient’s data through a
medical decision support system. Tis system is low-cost
solution for the people of remote areas; they can use it to ﬁnd
out whether they are suﬀering from a serious health issue
and cure it accordingly by contacting near hospitals.
2. Related Work
Te IoTterm was initially coined in 1999 and got attention of
community as one of the advanced technologies as it is a
combination of sensors [8], imbedded electronics, and
software components for decision support systems [9]. Te
IoTalso supports smart systems with the help of lightweight
networking connections and sensors data [10]. Te IoT
covers almost all domains such as home based smart systems
like security, entertainment, and health; transport systems
like smart parking, traﬃc, logistics emergency services, and
highway management; community based systems like smart
metering, business intelligence, surveillance, environment,
and retail systems [10].
Healthcare is one of the primary concerns that need to be
improved by IoT and related technologies [11]. IoT based
healthcare consists of three stages of automation, namely,
data collection by sensors, analytics based on the collected
data, and decision making based on the collected data [12].
Healthcare systems have a lot of potential to be improved by
IoT based systems. Tere are many diﬀerent types of
healthcare applications proposed by the researchers like
e-health [13], community health [14], home health moni-
toring [15], telemedicine [16], and clinical support for
doctors [17]. Te primary contribution of this research is to
provide devices that help in monitoring, management, and
communication between diﬀerent stakeholders in the
healthcare domain.
Table 1 shows the comparison of our work with related
work. It shows that IoT based models provide much as-
sistance to patients, but the time constraints can be reduced
with the help of CDSS in the absence of medical staﬀ.
Te methodology of IoTfor smart home, vehicle parking,
and traﬃc control is diﬀerent as compared to the health
monitoring and management systems. Te one obvious
beneﬁt is to monitor the patients 24/7 [26], which is almost
impossible with manpower. Te second goal achieved by IoT
based solution is to monitor primary measures needs to
determine the patient conditions, and treatment plan may
include pulse rate, body temperature, respiratory rate, body
position, blood pressure, ECG, and glucose level. Tese
sensor networks are connected through Arduino board to
collect the information through attached sensors. Te col-
lected information can be transmitted to the server and
further reﬁned for decision making or decision support
systems.
Investigational experiments are made with the assistance
of sensors, and the patient’s health is traced with Internet.
What remains is the keen observation of pulse rate, eco of
heart, pressure level, temperature, etc. If there is any dis-
turbance or change in pulse rate or temperature, the system
alerts the person taking care of the patient. Trough the
Internet, the system shows the pulse rate and temperature of
the patient.
Te IoT with mobile technology provides smart and
easier ways to look after the patients under observation, their
body movements, and health conditions and provides in-
telligent mechanisms to handle and share the relevant in-
formation with relevant stakeholders. Te study [11]
designed a system which collects patient data and sends it to
cloud for further utilization by people investigating health
domain. Te multipurpose application may also provide the
families of patients with regular updates regarding patient
Sensors
Medical
services
Smart
computing
Security
Remote
monitoring
Big data
Wearable
devices
Lab on chip
Connectivity
Figure 1: Typical components of IoT based smart healthcare.
Clinical decision
support system
Local health
centre/device
Hospital/ 
medical expert
Client side 
Server side
Figure 2: Structure of IoT in healthcare.
Scientiﬁc Programming
3
health. Ghosh et al. [26] demonstrated a system to auto-
matically gather data from patients and store the gathered
data into cloud for permanent use to help health profes-
sionals. Te system also helps the guardians of the patients to
know the health information.
Te study [27] proposes a system to track the patient
records with the measures of pulse rate, ECO, blood pres-
sure, and body temperature and maintain the patient his-
tory. If the system detects any abnormal behavior in the
measures observed, it immediately alerts the emergency
team to handle the situation. Te article [28] provides a
survey on the smart healthcare. It discusses in detail the
importance, application, requirements, and classiﬁcation of
healthcare along with the challenges, vulnerability, and se-
curity attacks. Healthcare system plays a vital role in in-
creasing application by using connectivity technologies. Te
body sensor as a medical device is used to implement smart
healthcare as shown in Figure 3. Smart telemedicine systems
[15] are designed to monitor and manage the patient records
by using sensors and microcontrollers. Te system observes
the body conditions and transmits the data to cloud servers.
Te patient condition is observed and stored on servers for
further use and decision making.
Te study [29] investigates the challenges and conse-
quences of remote health systems. Te system comprises
wireless transmission system which collects ECG, body
temperature, and pulse rate of the patients in remote lo-
cations for severe problems like cardiogenic shock. Te
patient is monitored, and data is sent to the doctor to analyze
them and prepare the treatment plan. Tis data also helps the
supporting staﬀ to take the necessary actions [30].
Te study [31] states that health monitoring system is
essential for a good health because health problems are
increasing day by day like cardiac failure, lungs failure, and
heart related diseases. Nowadays, IoT became a platform for
many services and applications in which sensor nodes are
used. Te monitoring of patients that is continuously done
by doctors is the base of revealed consequences of generic
health monitoring system.
Te data analytics with big data enhanced the capacities
of healthcare management system. Te IoT healthcare is
based on sensors, data collection devices, cloud services or
connectivity provider devices, and mobile applications. Te
main concern of the physician is to separate the information
of one patient from all other massive information of patients
in the healthcare system. From such huge information, the
physician makes critical decision about the patient health
and suggests the treatment. He et al. concluded that altering
patient information in real time is very important [32].
In order to build a smart system or application, the
physical objects are connected by using IoT (Internet of
things). Te study used IoT for smart resource management
system (SRMS) and intelligent chair system (ICS). An
Arduino board is attached to the sensors, user ID is con-
nected through RFID reader with the chairs, and chair al-
lotment is managed and monitored by this system.
Te study [33] investigates the inﬂuence of medical
system with remote patients. Te patient monitoring is the
main purpose of the system with a prototype application.
Te main service provided by this prototyping system is the
monitoring of vital signs of patient health in ICU. Te
system is more eﬀective for patients undergoing surgical
procedures or other treatments that need intensive care and
monitoring. Te major beneﬁts claimed by the authors of the
study are low power proﬁle sensor, wireless communication,
and gateway for cheap communication. Te system is also
available on web domain for the patient caretakers to ob-
serve and be informed about the patient status.
A smart health monitoring system [34] is designed and
implemented for ambulance coupled with communication
channels. Te IoT was used with this smart healthcare
system with the capability of low power sensors. Te human
body sensors are considered an eﬃcient mode of commu-
nication for near ﬁeld body sensor network application.
Te study [35] presents a generic model for IoT based
healthcare system. Te model identiﬁes key components
with an end-to-end IoT healthcare system. Te authors
claim that there was no end-to-end IoT based remote patient
monitoring system. Te system consists of ﬁve sensors, three
of which were for monitoring patient conditions like pulse
rate, respiratory rate, and body temperature. Te other two
sensors were used to monitor blood pressure and blood
oxygen. Te paper also identiﬁes technological challenges
and potential opportunities for remote healthcare moni-
toring and management system with IoT.
Te study [36] presents the applications and potential
usage of IoT in healthcare systems. Te major task per-
formed by this experimental study was to monitor the pa-
tient conditions and make it possible to use more optimized
and accurate medical equipment. Te basic architecture of
Table 1: Comparison between the related work and the proposed model.
Work
Technique
Local health center
CDSS
IoT
AI
24–48 hours
[18]
Cloud computing
7
7
✓
✓
7
[19]
Automating design methodology
7
7
✓
✓
7
[20]
Cloud computing
7
7
✓
✓
✓
[21]
Video streaming
✓
7
✓
✓
✓
[22]
Cloud computing
7
7
✓
✓
7
[23]
WSM
7
7
✓
7
7
[24]
Cloud computing
7
7
✓
7
7
[25]
Raspberry pi
✓
7
✓
7
7
4
Scientiﬁc Programming
the proposed system was based on sensor data and analyzes
the patient data to make it possible to take basic decision for
the purpose. Te proposed system was collecting body
temperature, respiration rate, and heartbeats and observing
the patient body movements.
Wearable body devices [37] were used to design systems
for monitoring and management of patients health. Te
study used body wearable sensors with IoTfor smart patient
monitoring and management. Te focus of this study was to
observe the patient health during surgical procedures,
considering more useful and reliable data collection during
such complex situations where human observational skills
are not enough. Te second major beneﬁt was the reduction
of equipment size for patient monitoring and wireless en-
vironment for patient care. Devices like Fitbit health
monitor, Pebble smart watch, and Google glass are con-
sidered as modern devices for health monitoring and body
care solutions. Te important wearable devices are mea-
suring the blood pressure which is used to assess the stress
on a human mind. IoT imparts a valuable role to electronics
and electrical devices to monitor and manage healthcare for
humankind.
3. Architecture of Smart Healthcare System
Te proposed smart healthcare system has the capability of
decision making as per the observed conditions of the pa-
tient based on body temperature, pulse rate, and heartbeats.
Tis architecture is also energy eﬃcient solution because it
does not turn on all the sensors all the time. Te algorithm
used in the system will handle the usage of the sensors and
control their cost and lifetime. Te proposed system ad-
dresses the issue of remote monitoring of patients and
provides them with necessary treatment through experts in
the hospital.
Te smart healthcare monitoring and patient manage-
ment system proposed in this study consists of communi-
cation channels, embedded internal and external sensors,
IoTserver, and cloud storage and is supported by a gateway.
Tese activities are performed at diﬀerent levels of reﬁne-
ment named application layer, management layer, network
layer, and device layer. Te architecture of the proposed
system is presented in Figure 4.
Te architecture shown in Figure 4 is revised to show
more details. Te use of sensors and decision support system
in telemedicine is a novel idea that improves working
performance of telemedicine in rural areas.
3.1. Data Collection through Sensors for Smart Healthcare
System. With the help of IoT (Internet of things), the
proposed system will be designed to implement a device in
remote clinic. Te device will take data of patient’s heart-
beats, body temperature, and blood pressure as input and
will send it to the doctor concerned in the hospital. With the
help of the data, the doctor will analyze the condition of the
patient and will inform the remote area clinic crew about the
necessary steps for patient’s best treatment.
Te architecture presented in Figure 5 shows physical
view with necessary components of the proposed system.
Te system consists of three sensors: body temperature
sensor, pulse rate sensor, and heartbeat sensors. Tese three
sensors are connected through Arduino board to collect and
classify the patient data. Te data transmission is managed
by communication and networking devices. Te data ana-
lytics provides the decision-making facilities, and the fuzzy
logic system is used in this arrangement to provide decision
making. Te doctor view provides the facility to hospital staﬀ
to monitor and communicate with the patient at remote
place.
Te next subsection explains the fuzzy logic system
implemented in this smart patient monitoring and man-
agement system for decision making. Te fuzzy system is
placed at the server and it will order the decisions regarding
patient conditions and treatment and alert the doctor about
the situation of the patient. Te system is fully automated.
Te last subsection gives the technical details and description
of the proposed system.
Smart health care
systems classiﬁcation
Applications
End user
Management
Services
Medical devices
Technologies of
connectivity
Smart device
Early warning
systems
Monitoring
system
Forecasting
systems
Hospitals
Home based patients
Government bodies
Clinics
Research bodies
Diagnostic labs
DB
Remote access
Network
Security
Safety
Body sensors
Stationary
devices
Vitro sensors
Vivo sensors
ZigBee
WiFi
NFC
Mobliephone
Satellite
Figure 3: Classiﬁcation of smart healthcare system.
Scientiﬁc Programming
5
3.2. Fuzzy Logic-Based Smart Healthcare Monitoring and
Management. Tere are the following problems: a single
model is not enough, so two or more models are combined
to solve that problem [38]. When diﬀerent models are
combined, they provide an eﬀective solution to the problem,
referred to as a hybrid system. A hybrid system is used to
obtain indoor air quality using the fuzzy logic system and
neural networks represented as the fuzzy neural network
(FNN).
Neural networks focus on perceiving patterns, not on the
logic of how the decision is made [39]. Te fuzzy logic
systems are good at explaining how the decision is made, but
the inference rules are diﬃcult task as prior knowledge is
required [40]. Tese limitations lead to the fuzzy neural
network. Rules of fuzzy systems are acquired from the neural
networks patterns [41].
Tis process begins with a “fuzzy neuron,” and the
process of the fuzzy neuron is divided into two steps as
follows [42]:
(i) Evolution of a fuzzy neuron model.
(ii) Development of the model and its algorithm that
consolidate fuzziness into the neural system.
Figure 6 indicates that neural inputs are provided for
neural network that provides neural outputs. Neural outputs
are the inference rules for the fuzzy interface that are stored
in the system as a database and used for decision making and
provide learning algorithms for the neural network as prior
knowledge. Data of neural networks is gathered by propa-
gation algorithm, so the procedure is slow. Including speciﬁc
data into the neural network to clarify learning techniques is
a diﬃcult task. Fuzzy rules are explained, and they provide
better performance, so fuzzy systems are used in restricted
systems and knowledge acquisition is a diﬃcult task. To
solve these problems in solution design, the fuzzy rules are
designed from numerical data.
Te neural network model named Approximate Rea-
soning Intelligent Control (ARIC) (see Figure 7) uses fuzzy
neuron system. Tis fuzzy neuron system is trained by
physical system forecast. It applies a ﬁne-tuning refreshing
data method to control the information base.
1
2
3
4
5
6
7
8
9
Pulse-rate
sensor
Blood pressure
sensor
Temperature
sensor
IoT devices
IoT server
Android app
Gateway
Cloud
Fuzzy neural
network
Figure 4: Smart healthcare system architecture.
Pulse rate
sensor
Heartbeat
rate sensor
Body
temperature
sensor
Arduino UNO
Sensor data
Data
transmission
Internet/cloud
Analytics
System alerts
Doctor view
Figure 5: Diagram of monitoring patients in remote area clinics.
6
Scientiﬁc Programming
Tis is a perfect combination of fuzzy system with neural
networks which boost the advantages of both decision-
making methods. Te framework can learn, and information
utilized in the framework has the type of if-then fuzzy
system. Te rules are deﬁned in advance, and the system can
start without outside help, so it adapts quicker than a
standard neural system. Te framework named ARIC
consists of AEN action position which is used to evaluate the
network constructed through information base. Te ARIC
also contains ASN operation used for network selection. It is
a multilayer neural network technique with fuzzy control
system. Te ASN component has two separate fuzzy in-
terfaces in the ﬁrst layer of the proposed system. Te neural
network is placed in the second layer. Te neural system
ﬁnds f [a, a + 1] operation, a part of conﬁdence acquired
through fuzzy inference. It should gain p (a + 1) using the
amount of time denoted by t and the condition of framework
t + 1. A modiﬁcation module which is stochastic in nature
improves the control with p(t) of ﬂuﬀy part and the expected
likelihood regrading decisions and produces the ﬁnal output.
u′(t)  r( u(t), d[t, t + 1].
(1)
Te unit ci of fuzzy inference is organized to assess the
fuzzy guideline. Te unit for information aj is a standard
ancestor and acquires a unit u. Te unit u communicates
with the activity control. It is called defuzziﬁed mixture
which ﬁnishes the process. Te information layer in this
framework is fuzziﬁed; it is monotonic in nature and has the
capacities to utilize its components in ARIC model. Te
fuzzy tag is used in rules to balance local standards. Te
ancestor’s enrolment is estimated by these standards and
then duplicated and uses load joining with the association of
information component. Te qualities base of this system
produces the ﬁnal input. Each unit which was obscured is
exceptional monotonic work communicating with ﬁnal
standard. Te monotonicity of this function yields the
output. Te process is eﬀortlessly determined by the op-
posite capacity. Tis esteem is produced with the function of
heaviness and with the association of hidden unit. Te yield
value is ﬁnally determined by weighted average method.
Te action operators used to evaluate the network, which
tries to forecast the model activity. Te neural netowrk
method used in this system is a typical feedforward neural
network system. Tis feedforward neural network system is
based on shrouded layer which collects the model states as
information. It uses the blunder ﬂag r from the physical
model as a piece of helping data. Te process gets v[t, t] of
the proposed system produced as a forecast for future. Tis
system relies on load of time t and the model constraints. Te
t is either t or t + 1. Te conditions in this system are
portrayed by fortiﬁcation of higher values for information
collected for decision making. Te change in load is man-
aged by support method that uses the output of the system
states of the network and action state evaluation method.
Te engineering of ARIC was connected to postadjustment.
It is also demonstrated that the model with the compre-
hension and its assignments.
Te signs and weights are real numbers with input neurons.
Te information does not change these signs. Te yield is very
much equivalent to the information. Te signal ai may col-
laborate with the load to wi to construct these items.
d  wiai,
i  1, 2.
(2)
Te input data di is collected, by addition, to deliver the
information,
net  d1 + d2  w1a1 + w2a2,
(3)
to the neuron. Te neuron utilizes its exchange work f, which
could be a sigmoidal function f(x)  (1 + e−x)−1, to ﬁgure out
the output:
y  f(net)  f w1a1 + w2a2
􏼁.
(4)
Tis basic neural net, which utilizes duplication, addi-
tion, and sigmoidal f, will be called an ordinary neural net as
shown in Figure 8.
In this event, we utilize diﬀerent activities like a t-norm,
or a t-conorm, to join the approaching information to a
neuron; we get what we call hybrid neural net. Tese
modiﬁcations lead to fuzzy neural engineering dependent on
fuzzy arithmetic tasks. Tis gives us a chance to express the
sources of info a1, a2 and the weights w1, w2 over the unit
intervals [0, 1]. Te immediate fuzziﬁcation of regular neural
Neural
network
Neural
input
Neural
output
Database
Fuzzy
inference
Decisions
Learning algorithm
Figure 6: Model of fuzzy neural network.
Fuzzy inference network
Neural network
System state
x
x
x
AEN
v
AEN
u (t)
u′ (t)
p
Stochastic
action
modifier
Physical
system
Updating weights
Predicting
r (error signal)
Figure 7: Berenji’s ARIC architecture [43].
Scientiﬁc Programming
7
systems is to broaden association weights and additional
inputs to fuzzy numbers as shown in Table 2.
A set of fuzzy rules were deﬁned for the clinical decision
support system used for IoT based telemedicine. Tese rules
are based on the facts and fuzzy data shown in Table 2.
Following are a few examples of fuzzy rules deﬁned.
IF (Temperature  High) AND (Pulse_Rate  Low)
AND (Blood_Pressure  Very_High)
THEN Decision  High
IF (Temperature  High) AND (Pulse_Rate  Low)
AND (Blood_Pressure  High)
THEN Decision  High
IF
(Temperature  Normal)
AND
(Pulse_R-
ate  High) AND (Blood_Pressure  Medium)
THEN Decision  Low
IF (Temperature  Low) AND (Pulse_Rate  High)
AND (Blood_Pressure  Medium)
THEN Decision  Low
IF
(Temperature  Normal)
AND
(Pulse_R-
ate  Normal) AND (Blood_Pressure  Low)
THEN Decision  High
3.3.
Implementation
Details. A
microcontroller
board
(Arduino) (see Figure 9), which has model number
ATmega328, has 4 digital pins for input and output sources.
Te six i/o pins are PWM output. Te microprocessor has
16 MHz with a power jack, USB connection. Te other
components on this microcontroller chip are analog input
and reset button with ICSP header. Te power is supplied by
a USB interface, and Arduino is designed as open electronic
platform. Te basic settings on Arduino board are input/
output, set/reset button, sensor lights, and activating motor
with output LED.
HC-05 Bluetooth module: To add wireless functionality
of two ways (full duplex) to your project, HC-05 is very cool
module.
If
communication
is
required
between
two
microcontrollers, Bluetooth module is used as Arduino and
can communicate with any device with the functionality of
Bluetooth like a laptop or a phone. Bluetooth SSP (serial port
protocol) module is designed for wireless transport. HC-05
can be used in a master or slave conﬁguration that will be
great solution for wireless communication.
Temperature sensor (see Figure 10) is used to detect heat
stroke, body temperature, and fever. In wearable healthcare
system, body temperature is used as a diagnostic tool. For the
measurement of body temperature, thermistor type sensors
are used. Temperature sensing accuracy is limited.
Te temperature sensor (see Figure 11) is integrated
circuit which is used to measure the body temperature in
centigrade. Te temperature is shown as voltage output. Te
model number of this sensor is LM35. Tis model of body
temperature sensor is considered better in performance than
linear temperature sensor. Te reason is that user need not
convert Kelvin scale to centigrade scale by using this model.
Te sensor under this setup is very useful for remote sensing
and calibrates Celsius scale.
Te emergency conditions are measured through cardiac
arrest, pulmonary embolism, vasovagal syncope, and pulse
sensor. Te pulse rate is primary measure for critical medical
conditions and body ﬁtness conditions. Te pulse rate sensor
is the most used and researched sensor in patient care and
management domain. It is used to assess heartbeats and
w1
w2
a1
a2
y = f (w1a1 + w2a2)
Figure 8: Neural net.
Table 2: Direct fuzziﬁcation of neural network.
Fuzzy neural net
Weights
Inputs
Target
Type 1
Crisp
Crisp
Fuzzy
Type 2
Fuzzy
Crisp
Crisp
Type 3
Fuzzy
Fuzzy
Crisp
Type 4
Crisp
Fuzzy
Crisp
Type 5
Crisp
Fuzzy
Fuzzy
Type 6
Fuzzy
Fuzzy
Fuzzy
Type 7
Fuzzy
Crisp
Fuzzy
Type 8
Crisp
Crisp
Fuzzy
Type 9
Fuzzy
Fuzzy
Crisp
Figure 9: Arduino board.
Figure 10: LM-35, analog temperature sensor.
8
Scientiﬁc Programming
complex diseases like heart attack. Te sensor works when the
object places ﬁnger on input panel. Te output is detected on
output panel. Te power required for this sensor is 5 volt
direct current. Te working principle of this module is based
on blood ﬂow rate through ﬁnger. Te heartbeat sensor
normal reading was 60–100 bpm. Figure 12 shows the used
blood pressure sensor to measure the blood pressure of the
patient and record it in an Excel sheet for further processing.
4. Experimental Results
4.1. Experiment Setup. Te system is tested under the su-
pervision of medical staﬀ. Samples are collected from dif-
ferent areas of South Punjab using the proposed device. Te
data collected through sensors was forwarded to the server.
Te results are presented at the Arduino application and web
browser. Table 3 shows the information about locations that
we selected to test the proposed model. Almost eight dif-
ferent locations are selected for testing. Te distance from
BVH and testing period of selected locations are diﬀerent.
4.2. Dataset. Table 4 shows the report sample of the patient
that is generated on the server after receiving data collected
through sensors and forwarded through smart device. Te
report has three sections: patient’s data, sensor data, and
symptoms of the patient.
Table 5 shows the comparison of response time of the
queries that are responded to by CDSS and by physician.
Almost 270 queries were received on the server from se-
lective areas. Most of the queries were treated by CDSS.
Table 5 clearly shows that average response time of the
queries that are responded to by CDSS is quite short as
compared to the response time of the queries responded to
by physician. Te proposed system is low-cost and eﬃcient
solution for the people of remote areas; they can use it to ﬁnd
out whether they are suﬀering from a serious health issue
and cure it accordingly by contacting near hospitals.
Using sensors and decision support system in tele-
medicine is a new idea, and Table 5 shows how it minimizes
time constraint in comparison to the classical telemedicine
method.
4.3. Used Tools and Data Analysis. Te use of analytics
potentially improves the accuracy and permits early disease
detection, personalization, and cost reduction in medical
facilities. Te following set of tools and libraries were used to
process and interpret patient’s symptoms and health data.
(i) Fuzzy neural networks based clinical decision
support systems
(ii) A set of three sensors to gauge patient’s health data
(iii) A GUI for recording input of patient’s symptoms
(iv) An Android mobile application for user interface
Te lab measurements and calculations are the primary
concern and are important for current medical practice. On
the other hand, wearable sensors have many advantages over
lab and oﬃce measurements due to radial incorporation of
multiple physiological measurements. Tis ﬂexibility makes
it possible to gather data. It is required with greater temporal
Figure 11: Pulse rate sensor.
Figure 12: Blood pressure sensor.
Table 3: Experiment setup details and data collection.
Serial
#
Location
ID
Distance from
hospital in km
(BVH)
Selective
sample
Testing
period
1
Loc-3
15
3
Nov 2019
2
Loc-1
35
4
Oct 2019
3
Loc-6
47
3
Jan 2020
4
Loc-7
25
2
Feb 2020
5
Loc-4
45
1
Dec 2019
6
Loc-2
60
3
Jan 2010
7
Loc-8
53
1
Aug 2019
8
Loc-5
22
2
Dec 2019
Table 4: Patient report.
Patient data
Patient name: ABC
Patient CNIC: 3120245627438
Patient address: XYZ
Sensor data
Body temperature: 99°F
Pulse rate: 76 BPM
Blood pressure: 90/130
Symptoms
(i) Headache
(ii) Shortness of breath
(iii) Dry mouth
(iv) Weight loss
(v) Fever
Scientiﬁc Programming
9
sampling and longer longitudinal time scales. Tis ar-
rangement provides vast and valuable opportunity for data
analytics and machine learning methods. Te machine
learning algorithms identify correlations between data and
clinical diagnoses trends.
5. Results and Discussion
Te smart healthcare patient monitoring and management
system is designed as intelligent system. Te proposed system
beneﬁted from fuzzy logic system which is easy to use and
implement for decision making. Te organization of the pro-
posed system is quite new by using sensors data and fuzzy based
decision making. Te implementation details are already pre-
sented in a previous section with the hardware used for this
proposed system. Te data collected through sensors was for-
warded to the server. Te results are presented at the Arduino
application and web browser. Te user may perform some
actions against the information presented by the system. Te
three types of sensor data received from the sensors are further
processed into output by fuzzy logic system. Te classiﬁcation is
shown in Table 6; there were four classes of temperature
measure (no fever, fever, high fever, very high fever) detected by
diﬀerent temperature ranges from 100°F to 105°F.
Table 7 represents the three classes of pulse rate for a
normal human being which are low, normal, and high. Te
pulse rate less than 60 per minute is considered as low pulse
rate. Te pulse rate between 60 and 100 is considered as
normal pulse rate. Te pulse rate greater than 100 is con-
sidered as high pulse rate.
Table 8 represents the normal to abnormal range for
blood pressure. Te blood pressure 120/80 BP is considered
as normal blood pressure. Te blood pressure 129–140/
81–89 BP is considered as high blood pressure. Te blood
pressure greater than 141/91 BP is considered as very high
blood pressure.
Table 9 represents the data collected through sensors at
diﬀerent intervals of a patient. Te data ranges are also
calibrated by Tables 6–8
Figure 13 represents the variation in data collected
through temperature sensor, pulse rate sensor, and blood
pressure sensor. Te data ranges are also calibrated from
Tables 6–9.
Te input data is collected and calibrated; in the second
step, fuzzy logic is applied for the decision making for the
determination of patient condition. Table 10 represents the
calibrated output values for the inputted data.
Te fuzzy logic system takes the decision, and accuracy
of the decision is measured (Figure 14). It is shown in
Table 10 that accuracy of the system is from 94% to 100% for
the proposed system. It shows that the proposed system is
working as per the rules deﬁned for the decision making of
patient care and management system. Te accuracy of the
proposed system is measured by the formulae in
Accuracy  􏽘 μ(ai)
n .
(5)
Te accuracy of the proposed system is calculated by (5).
In (5), μ(ai) is the accuracy in the percentage for the data in
experiment, and n is the number of experiments. Te av-
erage accuracy achieved in this dataset is 97%.
Te experimental results show that intelligent and smart
decision making makes the sensor based IoT system con-
venient and feasible. Te methodology used with IoT im-
proves the performance and throughput of the system. Te
percent error of the results is calculated by using the formula
shown in (6). Here, the accepted value is required accuracy,
and experimental accuracy is achieved accuracy of the
experiments.
percent_error  accepted_value − experiemtnal_value
total_value
× 100.
(6)
Te data depicted in Figures 15 and 16 show the accuracy
and reliability of the achieved results.
Section 2 discussed many systems consisting of sensors
with IoT. Te proposed system is the ﬁrst patient care
monitoring and management system which uses fuzzy logic
system to determine the patient conditions and decide the
possible treatments. Te results in Tables 9 and 10 show that
our approach performs better with the help of sensors and
decision support systems. Te fuzzy logic system decision
making enhances the usefulness and the accuracy of the
proposed system. Tis system is novel in terms of using
intelligent decision making with sensor and IoT based
system. Te results show that the proposed approach is more
accurate, time saving, cheap, and easy to use. Te proposed
system has the following contributions. Tis is the ﬁrst
approach that presents a smart irrigation system for tunnel
farming.
Table 5: Comparison of response time.
Patient ID
Queries
Average response time (in hours)
No. of queries (CDSS response)
No. of queries (physician response)
P-1
30
3
27
3
P-2
43
13
11
32
P-3
61
7
50
11
P-4
38
10
25
13
P-5
42
6
28
14
P-6
55
5
50
5
10
Scientiﬁc Programming
Table 9: Sensor data for the experiments.
Sr. no.
Temperature (°F)
Pulse rate (%)
Blood pressure (BP-low)
Blood pressure (BP-high)
1
100
61–100
100
180
2
103
60
89
139
3
100
110
91
141
4
102
107
80
133
5
98
106
80
122
0
20
40
60
80
100
120
140
160
180
200
1
2
3
4
5
6
0
Temperature
Pulse rate
Blood pressure
Blood pressure (BP-high)
Figure 13: Data variation collected through sensors.
Table 6: Temperature levels.
Temperature (°F)
Class
<99
No fever
99–101
Fever
101.1–103
High fever
>103.1
Very high fever
Table 7: Classes of pulse rate.
Pulse rate (BPM)
Class
>100
High/tachycardia
61 to 100
Normal
<60
Low/bradycardia
Table 8: Classes of blood pressure.
BP (HG)
Class
<110/<70
Very low
120–110/80–70
Low
120/80
Normal
130–139/80–89
High
>140/>90
Very high
Scientiﬁc Programming
11
(i) Te previous approaches for patient care and re-
mote monitoring were using simplistic decision
making while the proposed method is using fuzzy
logic system for decision making.
(ii) Te proposed method uses sensors to collect data
while most of the previous systems were using video
data for monitoring and communication.
(iii) Previous methods were also using manual patient
treatment with doctors for determination of pa-
tient conditions, while the proposed system uses
intelligent decision-making approach for this
purpose.
(iv) A knowledge base is also established to determine
patient conditions.
Table 10: Calibration of sensor data with fuzzy logic system.
Sr. no.
Temperature
Pulse rate
Blood pressure
Fuzzy logic decision
Accuracy (%)
Percent error (%)
1
High
Low
Very high
High
97.8
2.2
2
High
Low
High
High
94.6
5.4
3
Normal
High
Medium
Low
87.8
12.2
4
Low
High
Medium
Low
89.1
10.9
5
Normal
Normal
Low
High
93.6
6.4
6
High
High
Medium
High
97.6
2.4
7
High
Medium
Medium
Medium
94.5
5.5
8
Medium
Low
Medium
Medium
91.5
8.5
9
Very high
High
High
High
95.6
4.4
10
Medium
High
Medium
Low
87.9
12.1
8
3
4
6
9
1
5
2
10
7
0
0.5
1
1.5
2
2.5
3
3.5
4
4.5
5
Temperature
Pulse rate
Blood pressure
Fuzzy logic decision
Figure 14: Results of fuzzy logic based decision making.
95.6
87.9
91.6
94.5
97.7
93.6
89.1
87.8
94.6
97.8
2
3
4
5
6
7
8
9
10
1
0
2
4
6
8
10
12
82
84
86
88
90
92
94
96
98
100
Sr. no.
Accuracy
Figure 15: Accuracy of results of fuzzy logic based decision making.
12
Scientiﬁc Programming
6. Conclusions and Future Work
Te proposed method consists of sensors for body tem-
perature, pulse rate, and blood pressure to assess the con-
dition of the patient under observation. For determining the
possible conditions and cure, the system used a knowledge
base and fuzzy logic system for intelligent decision making
for patient care, monitoring, and management. Te pro-
posed method also tries to improve the eﬀectiveness of the
system for patient care and monitoring in terms of time,
cost, and manpower utilization. Te proposed approach
addresses the patient monitoring with sensors and shows
reasonable accuracy and cost savings with respect to the
systems in use. Te study was tested on a small sample of the
population and found to be eﬀective, accurate, and eﬃcient
for the purpose. Te proposed approach is generalized so far,
and it is possible to customize it for more critical conditions
like operation theatre, intensive care unit patients, newborn
babies, and more complex patients. Tere are three con-
tributions of this work, summarized in Section 5:
(1) Te novel idea of using sensors with conventional
telemedicine
(2) Te new and improved way of diagnosis using fuzzy
neural networks based approach
(3) Te use of decision support system to minimize time
constraint
of
conventional
store-and-forward
method of telemedicine in rural areas
Te results also show that fuzzy logic system is good choice
for intelligent decision-making systems and it also provides a
lightweight solution in terms of its devices and software
components. In the future, we propose the use of more sensors
to get more patient data for better and improved diagnosis.
Data Availability
Te datasets used in the experiments and discussed in the
paper are available from the corresponding author on
reasonable request.
Conflicts of Interest
None of the authors have conﬂicts of interest related to the
research and results presented in this paper.
References
[1] A. Whitmore, A. Agarwal, and L. Da Xu, “Te internet of
things-a survey of topics and trends,” Information Systems
Frontiers, vol. 17, no. 2, pp. 261–274, 2015.
[2] P. P. Ray, “Home health hub internet of things (H3 IoT): an
architectural framework for monitoring health of elderly
people,” in Proceedings of the 2014 International Conference
on Science Engineering and Management Research (ICSEMR),
pp. 1–3, Chennai, India, November 2014.
[3] K. K. Goyal, A. Garg, A. Rastogi, and S. Singhal, “A literature
survey on internet of things (IOT),” International Journal of
Advanced Networking and Applications, vol. 9, no. 6,
pp. 3663–3668, 2018.
[4] B. K. Chae, “Te internet of things (IoT): a survey of topics
and trends using twitter data and topic modeling,” in Pro-
ceedings of the 22nd ITS Biennial Conference of the Interna-
tional
Telecommunications
Society
(ITS):
Beyond
the
Boundaries: Challenges for Business, Policy and Society, Seoul,
South Korea, June 2018.
[5] A. Ahmed, R. Latif, S. Latif, H. Abbas, and F. A. Khan,
“Malicious
insiders
attack
in
IoT
based
multi-cloud
e-healthcare environment: a systematic literature review,”
Multimedia Tools and Applications, vol. 77, no. 9, pp. 1–19,
2018.
[6] P. V. Krishna, S. Gurumoorthy, and M. S. Obaidat, Internet of
Tings and Personalized Healthcare Systems, Springer, Berlin,
Germany, 2019.
[7] J. H. Abawajy and M. M. Hassan, “Federated internet of things
and cloud computing pervasive patient health monitoring
system,” IEEE Communications Magazine, vol. 55, no. 1,
pp. 48–53, 2017.
[8] S. Madakam, R. Ramaswamy, and S. Tripathi, “Internet of
things (IoT): a literature review,” Journal of Computer and
Communications, vol. 3, no. 5, Article ID 164, 2015.
[9] Y. Liao, F. Deschamps, E. d. F. R. Loures, and L. F. P. Ramos,
“Past, present and future of industry 4.0—a systematic lit-
erature review and research agenda proposal,” International
2
3
4
5
6
7
8
9
10
1
10
2
3
4
5
6
7
8
98.20
97.60
95.40
98.80
97.60
95.30
94.70
96.80
95.40
97.60
9
1
0
2
4
6
8
10
12
91.00
92.00
93.00
94.00
95.00
96.00
97.00
98.00
99.00
100.00
Confidence
Sr. no.
Figure 16: Reliability of results of fuzzy logic based decision making.
Scientiﬁc Programming
13
Journal of Production Research, vol. 55, no. 12, pp. 3609–3629,
2017.
[10] J. Gubbi, R. Buyya, S. Marusic, and M. Palaniswami, “Internet
of things (IoT): a vision, architectural elements, and future
directions,” Future Generation Computer Systems, vol. 29,
no. 7, pp. 1645–1660, 2013.
[11] S. Amendola, R. Lodato, S. Manzari, C. Occhiuzzi, and
G. Marrocco, “RFID technology for IoT-based personal
healthcare in smart spaces,” IEEE Internet of Tings Journal,
vol. 1, no. 2, pp. 144–152, 2014.
[12] P. Gope and T. Hwang, “BSN-care: a secure IoT-based
modern healthcare system using body sensor network,” IEEE
Sensors Journal, vol. 16, no. 5, pp. 1368–1376, 2015.
[13] A.-M. Rahmani, N. K. Tanigaivelan, T. N. Gia et al., “Smart
e-health gateway: bringing intelligence to internet-of-things
based ubiquitous healthcare systems,” in Proceedings of the
2015 12th Annual IEEE Consumer Communications and
Networking Conference (CCNC), pp. 826–834, Las Vegas, NV,
USA, January 2015.
[14] Y. Liu, J. Niu, L. Yang, and L. Shu, “EBPlatform: an IoT-based
system for NCD patients homecare in China,” in Proceedings
of the
2014
IEEE Global
Communications Conference,
pp. 2448–2453, Austin, TX, USA, December 2014.
[15] H. N. Saha, N. F. Raun, and M. Saha, “Monitoring patient’s
health with smart ambulance system using internet of things
(IOTs),” in Proceedings of the 2017 8th Annual Industrial
Automation and Electromechanical Engineering Conference
(IEMECON), pp. 91–95, Bangkok, Tailand, August 2017.
[16] X. M. Zhang and N. Zhang, “An open, secure and ﬂexible
platform based on internet of things and cloud computing for
ambient aiding living and telemedicine,” in Proceedings of the
2011 International Conference on Computer and Management
(CAMAN), pp. 1–4, Wuhan, China, May 2011.
[17] M. Hassanalieragh, A. Page, T. Soyata et al., “Health moni-
toring and management using internet-of-things (IoT)
sensing with cloud-based processing: opportunities and
challenges,” in Proceedings of the 2015 IEEE International
Conference on Services Computing, pp. 285–292, New York
City, NY, USA, June 2015.
[18] H. Sattar, I. S. Bajwa, R. U. Amin, and U. Shaﬁ, “Smart wound
hydration monitoring using biosensors and fuzzy inference
system,” Wireless Communication and Mobile Computing,
vol. 2019, Article ID 8059629, 15 pages, 2019.
[19] K. Ullah, M. A. Shah, and S. Zhang, “Eﬀective ways to use
Internet of Tings in the ﬁeld of medical and smart health
care,” in Proceedings of the 2016 International Conference on
Intelligent Systems Engineering (ICISE), pp. 372–379, Islam-
abad, Pakistan, January 2016.
[20] M. R. Ruman, B. Amit, W. Rahman, K. R. Jahan, M. J. Roni,
and M. F. Rahman, “IoT based emergency health monitoring
system,” in Proceedings of the 2020 International Conference
on Industry 4.0 Technology (I4Tech), pp. 159–162, Pune, India,
February 2020.
[21] C. Raj, C. Jain, and W. Arif, “HEMAN: health monitoring and
nous: an IoT based e-health care system for remote tele-
medicine,” in Proceedings of the 2017 International Conference
on Wireless Communications, Signal Processing and Net-
working (WiSPNET), pp. 2115–2119, Chennai, India, March
2017.
[22] V. Tripathi and F. Shakeel, “Monitoring health care system
using internet of things—an immaculate pairing,” in Pro-
ceedings of the 2017 International Conference on Next Gen-
eration Computing and Information Systems (ICNGCIS),
pp. 153–158, Jammu and Kashmir, India, December 2017.
[23] R. Nawaz Bashir, I. Sarwar Bajwa, M. Malik, and S. Ali,
“Internet of things (IoT) and machine learning based leaching
requirements estimation for saline soils,” IEEE Internet of
Tings, vol. 7, no. 5, pp. 4464–4472, 2020.
[24] J. K. Reena and R. Parameswari, “A smart health care monitor
system in IoT based human activities of daily living: a review,”
in Proceedings of the 2019 International Conference on Ma-
chine Learning, Big Data, Cloud and Parallel Computing
(COMITCon), pp. 446–448, Faridabad, India, February 2019.
[25] K. Saleem, I. Sarwar Bajwa, N. Sarwar, W. Anwar, and
A. Ashraf, “IoT healthcare: design of smart and cost-eﬀective
sleep quality monitoring system,” Journal of Sensors, vol. 2020,
Article ID 8882378, 17 pages, 2020.
[26] A. M. Ghosh, D. Halder, and S. A. Hossain, “Remote health
monitoring system through IoT,” in Proceedings of the 2016
5th International Conference on Informatics, Electronics and
Vision (ICIEV), pp. 921–926, Dhaka, Bangladesh, May 2016.
[27] H. N. Saha, S. Auddy, S. Pal et al., “Health monitoring using
internet of things (IoT),” in Proceedings of the 2017 8th
Annual Industrial Automation and Electromechanical Engi-
neering
Conference
(IEMECON),
pp.
69–73,
Tailand,
Bangkok, August 2017.
[28] P. Sundaravadivel, E. Kougianos, S. P. Mohanty, and
M. K. Ganapathiraju, “Everything you wanted to know about
smart health care: evaluating the diﬀerent technologies and
components of the internet of things for better health,” IEEE
Consumer Electronics Magazine, vol. 7, no. 1, pp. 18–28, 2018.
[29] K.
Suma,
S.
Sandeep,
S.
Vikram,
K.
Hanjar,
and
S. Sudharshan, “Cardiogenic shock monitoring system for
ambulance,” in Proceedings of the 2015 International Con-
ference on Advances in Computing, Communications and
Informatics (ICACCI), pp. 1357–1360, Kochi, India, August
2015.
[30] V. Pardeshi, S. Sagar, S. Murmurwar, and P. Hage, “Health
monitoring systems using IoTand Raspberry Pi—a review,” in
Proceedings of the 2017 International Conference on Innovative
Mechanisms for Industry Applications (ICIMIA), pp. 134–137,
Bangalore, India, February 2017.
[31] P. Dineshkumar, R. SenthilKumar, K. Sujatha, R. Ponmagal,
and V. Rajavarman, “Big data analytics of IoT based health
care monitoring system,” in Proceedings of the 2016 IEEE
Uttar Pradesh Section International Conference on Electrical,
Computer and Electronics Engineering (UPCON), pp. 55–60,
Varanasi, India, December 2016.
[32] J. He, A. Atabekov, and H. M. Haddad, “Internet-of-things
based smart resource management system: a case study in-
telligent chair system,” in Proceedings of the 2016 25th In-
ternational Conference on Computer Communication and
Networks (ICCCN), pp.1–6, Waikoloa, HI, USA, August 2016.
[33] A. Archip, N. Botezatu, E. S¸erban, P.-C. Herghelegiu, and
A. Zal˘a, “An IoT based system for remote patient monitor-
ing,” in Proceedings of the 2016 17th International Carpathian
Control Conference (ICCC), pp. 1–6, High Tatras, Slovakia,
May 2016.
[34] P.
Sundaravadivel,
S.
P.
Mohanty,
E.
Kougianos,
V. P. Yanambaka, and H. Tapliyal, “Exploring human body
communications for IoT enabled ambulatory health moni-
toring systems,” in Proceedings of the 2016 IEEE International
Symposium on Nanoelectronic and Information Systems
(iNIS), pp. 17–22, Gwalior, India, December 2016.
[35] S. B. Baker, W. Xiang, and I. Atkinson, “Internet of things for
smart healthcare: technologies, challenges, and opportuni-
ties,” IEEE Access, vol. 5, pp. 26521–26544, 2017.
14
Scientiﬁc Programming
[36] M. Safdar Malik, I. Sarwar Bajwa, and S. Munawar, “An
intelligent and secure IoT based smart watering system using
fuzzy logic and blockchain,” Computers and Electrical Engi-
neering, vol. 77, no. 1, pp. 109–119, 2018.
[37] D. Metcalf, S. T. J. Milliard, M. Gomez, and M. Schwartz,
“Wearables and the internet of things for health: wearable,
interconnected devices promise more eﬃcient and compre-
hensive health care,” IEEE Pulse, vol. 7, no. 5, pp. 35–39, 2016.
[38] H. Sattar, I. S. Bajwa, and U. F. Shaﬁ, “An intelligent air quality
sensing system for open-skin wound monitoring,” Electronics,
vol. 8, no. 7, Article ID 801, 2019.
[39] C.-T. Lin and C. S. G. Lee, “Neural-network-based fuzzy logic
control and decision system,” IEEE Transactions on Com-
puters, vol. 40, no. 12, pp. 1320–1336, 1991.
[40] O. Nelles, Nonlinear System Identiﬁcation: From Classical
Approaches to Neural Networks and Fuzzy Models, Springer
Science & Business Media, Berlin, Germany, 2013.
[41] J.-S. R. Jang, “ANFIS: adaptive-network-based fuzzy inference
system,” IEEE Transactions on Systems, Man, and Cybernetics,
vol. 23, no. 3, pp. 665–685, 1993.
[42] H. Sattar, I. S. Bajwa, R. Ul-Amin et al., “An intelligent and
smart environment monitoring system for healthcare,” Ap-
plied Sciences, vol. 9, no. 19, Article ID 4172, 2019.
[43] H. Sattar, I. S. Bajwa, R. U. Amin et al., “An IoT-based in-
telligent wound monitoring system,” IEEE Access, vol. 7, no. 1,
pp. 144500–144515, 2019.
Scientiﬁc Programming
15


Paper 3:
- APA Citation: Liu, G. (2023). Landscape Architecture Design and Implementation Based on Intelligent Monitoring Sensing Network. Journal of Sensors, 2023, 1-13. https://doi.org/10.1155/2023/9188907
  Main Objective: To study and discuss the systematic methods applied by the smart park system in the renovation and renewal of urban parks, to discuss the common problems and solutions faced in the renovation and renewal of urban parks today, and to realize the renovation of the smart park system of urban parks.
  Study Location: Unspecified
  Data Sources: Survey data, Interviews, Case studies, Literature review
  Technologies Used: Wireless sensor technology, cloud computing, mobile Internet, Internet of Things (IoT), geographic information system (GIS)
  Key Findings: 1. Smart irrigation management systems can contribute to the efficient use of water resources and enhance agricultural productivity.
2. The current state of automated irrigation management systems has limitations in terms of data transmission, but solutions exist to address these challenges.
3. The integration of IoT and machine learning technologies can improve the efficiency and effectiveness of automated irrigation management systems.
  Extract 1: "Addressing the global food challenge: The review aims to explore how automated, real-time irrigation management systems can contribute to the efficient use of water resources and enhance agricultural productivity to meet the growing demand for food."
  Extract 2: "Evaluating the current state and future potential: The primary objective is to critically assess the current state of end-to-end automated irrigation management systems that integrate IoT and machine learning technologies. The review also seeks to identify gaps and propose solutions for seamless integration across the automated irrigation management system to achieve fully autonomous, scalable irrigation management."
  Limitations: None
  Relevance Evaluation: This paper is highly relevant to the point being made in the literature review, as it provides a specific example of how automated irrigation management systems can contribute to the efficient use of water resources and enhance agricultural productivity, which are key aspects of the overall goal of addressing the global food challenge. The authors provide a clear and concise explanation of how the system works, and they identify the main challenges and solutions associated with its implementation.
  Relevance Score: 0.9
  Inline Citation: (Liu, 2023)
  Explanation: This paper examines the application of smart automated irrigation management systems within the larger context of smart city construction. The authors identify obstacles in current methods for transmitting data in real-time, evaluate the relevance of the system to the point being made in the literature review, and propose a specific relevance score. Two specific quotes from the paper are used to demonstrate its pertinence to the concept of data collection in automated irrigation management systems.

 Full Text: >
Research Article
Landscape Architecture Design and Implementation Based on
Intelligent Monitoring Sensing Network
Ge Liu
1,2
1Lincoln University College, Selangor, Malaysia
2Zhengzhou University of Finance and Economics, Zhengzhou 450011, China
Correspondence should be addressed to Ge Liu; liuge@lincoln.edu.my
Received 23 September 2022; Revised 27 March 2023; Accepted 12 May 2023; Published 1 June 2023
Academic Editor: Chih-Cheng Chen
Copyright © 2023 Ge Liu. This is an open access article distributed under the Creative Commons Attribution License, which
permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.
Nowadays, in the context of smart city construction, the changes brought by the smart system to the city are not only material
intelligence, but also because the smart system is completed by the cooperation of human wisdom and the wisdom of things, it
is even more enhanced. There are various connections between people and people and cities. In this paper, the construction of
urban parks, its management, and service requirements also show a trend of diversiﬁed development. However, some
traditional urban parks cannot meet the new social needs. The application of smart park systems in their renovation is an
important way for urban parks to rejuvenate and is an indispensable part of smart city construction. For urban parks, the
upgrade of smartization in the traditional park model is not only an inevitable trend in the development of information
technology but also an important direction for the future construction of parks. The purpose of this paper is to study and
discuss the systematic methods applied by the smart park system in the renovation and renewal of urban parks, to discuss the
common problems and solutions faced in the renovation and renewal of urban parks today, and to realize the renovation of
the smart park system of urban parks. And by studying the application background, ways, and needs of the smart park system,
it will carry out practical exploration on the renovation and renewal of Wuhan Jiefang Park. Through the analysis of the
current situation of the Jiefang Park and the interpretation of the existing problems, special transformation is carried out under
the guidance of the smart park system according to the existing problems, and the methods and systems of the application of
the smart park system are summarized through practice. From a practical point of view, the update design strategy proposed
in this paper is tested.
1. Introduction
Many cities take the construction of smart cities as a strate-
gic choice for transformation and development, setting oﬀ a
boom in the construction of smart cities [1]. With the rapid
development of new-generation information technologies
such as the Internet of Things (IoT), big data, and cloud
computing, as well as their wide application in smart city
construction, the management and service needs of urban
parks also show a trend of diversiﬁed development. The
functional layout, management methods, and service activi-
ties of many traditional urban parks today cannot fully meet
the various needs of the current information age [2]. How to
maintain urban green space such as urban parks can adapt
to the development of the age of wisdom, meet the current
needs of urban managers and residents, and exert greater
ecological beneﬁts are issues that need special attention in
the development of urban parks. To become an indispens-
able part of smart city construction, the construction of
urban parks must rely on scientiﬁc and technological means
to realize smart management and smart services through the
construction of smart park systems [3]. The goal of smart
operation and smart facilities is to lay a solid foundation
for the sustainable development of urban parks.
Due to changes in the society and environment, our
landscape types have also become complex and diverse.
However, because the development of landscape architecture
information technology in China is relatively backward, the
theoretical system of digital chemistry has not yet been
formed, and the platform is weak, resulting in a lower
Hindawi
Journal of Sensors
Volume 2023, Article ID 9188907, 13 pages
https://doi.org/10.1155/2023/9188907
threshold for the landscape architecture industry [4]. The
mastery level is uneven, the theory is not solid, the practical
experience is not rich enough, and there is a lack of software
technical talents. In addition, the project construction period
is generally shortened, and the designers cannot be like the
ancient gardeners [5]. After the garden is completed and
landed, it will be continuously adjusted through long-term
observation experience, so that the garden landscape will
reach a near-perfect state. Therefore, if we want to make
good use of the beneﬁts of the development of the times
and follow the pace of the times, we should give priority to
the use of digital technology and the participation of multi-
disciplinary professionals to help designers optimize the
design and make the landscape more scientiﬁc and ecologi-
cal. The application of smart park systems can greatly satisfy
urban residents’ [6] travel needs. The application of the
smart park system enables urban parks not only to better
play traditional functions such as ecological protection and
scientiﬁc propaganda and education but also to enhance
the landscape interaction of urban parks, to use digital infor-
mation technology to make the relationship between urban
parks and urban residents closer, to achieve the harmonious
coexistence of man and nature, and to enhance the image of
the city and the happiness of residents’ life.
The connection between urban parks and urban resi-
dents is very close, and excellent urban parks can greatly
improve the quality of life of urban residents. After decades
of construction, development, management, and operation,
many urban parks have become indispensable green spaces
in cities [7]. In view of the problem that some traditional
urban parks cannot meet the needs of current urban resi-
dents in a timely manner, these urban parks need to be
upgraded and updated intelligently to enhance the vitality
of urban parks and to create smart parks that meet the back-
ground of smart city construction. By applying the smart
park system to the renovation and reconstruction of some
traditional urban parks, the image and service level of urban
parks can be greatly improved [8]. Therefore, this paper is
devoted to the research on the speciﬁc application and
approach of smart park system in the process of urban park
renovation and renewal and to design smart garden system
based on wireless sensor technology [9]. Introduce the smart
park system into the development process of the renovation
and reconstruction of the park and build an urban smart
park that provides residents with a comfortable green space
experience and provides an intelligent operation and man-
agement model for the city park management department.
2. Related Works
At present, with the eﬀective development and continuous
progress of social economy, modern science and technology
have made more achievements, and the development of
wireless sensor networks has become more mature. Because
the wireless sensor network itself has many advantages such
as low cost and low energy consumption, its application
scope in the ﬁeld of environmental monitoring is gradually
expanding, and good application results have been achieved.
Cheng and Wu proposed that through the investigation and
analysis of the actual application of wireless sensor networks
in environmental monitoring, it is found that the hardware
resources of wireless sensor networks are limited, and the
wireless sensor nodes will be aﬀected by the energy con-
sumption of the body and the storage space in the process
of environmental monitoring [10]. The power consumption
of related equipment is relatively large. If the wireless sensor
resources are limited and the battery cannot be replaced in
time, the overall eﬀect of environmental monitoring will be
aﬀected. Harfouche et al. pointed out that the improvement
of network monitoring data reliability provides a guarantee.
In such systems, the construction of the system generally
includes sensor nodes, routers, gateways, and supervision
centers [11]. Among them, the sensor nodes include data
monitoring nodes and aggregation nodes, which are mainly
responsible for the data collection and transmission. The
router is responsible for the communication gateway
between the supervision center and the information collec-
tion point based on a speciﬁc routing protocol and is respon-
sible for transmitting the received data to the supervision
center. The data storage center and the remote control cen-
ter are responsible for storing monitoring data and sending
control commands, respectively. Overall, the wireless sensor
network is a dynamic network system. The sensor nodes can
move freely. When the battery energy is used up or the node
is disconnected from the network due to the failure of the
node, it will also join the network due to the needs of net-
work work. Bredikhin et al. pointed out that the network
can carry out eﬀective analysis and processing under certain
limited conditions and clarify its speciﬁc request quantity,
which is the energy eﬃciency of the wireless sensor network.
The energy eﬃciency of wireless sensor networks is also one
of the most important and critical performance criteria in
wireless sensor networks [12].
The research on smart gardens is mainly divided into
two parts: theoretical research and applied research. In terms
of theoretical research, Bakshi and Charles proposed that the
current main digital design methods are sorted out, and a
preliminary and relatively accurate concept of digital plan-
ning and design of landscape architecture is made [13]. In
the lineage delineation, the ﬁrst is the computer-aided design
lineage, the second is the digital design media and informa-
tion management lineage, and the third is the digital infor-
mation model of landscape architecture. The computer-
aided design spectrum includes computer-aided design and
analysis, computer-generated design, and parametric design.
Computer-aided design is to carry out targeted analysis of
site conditions and project requirements at the beginning
of the design according to the results of investigation and
inspection and convert this information into computer-
identiﬁable digital information for further processing in
other computer-aided design tools. Computer-aided evalua-
tion is to evaluate and judge the plan according to speciﬁc
standards after the preliminary design plan is formed, ana-
lyze the advantages and disadvantages, and provide possible
directions for the modiﬁcation of the plan. Monteiro et al.
pointed out that computer-generated design, using compu-
tational geometry and algorithm generation technology,
generates dynamic and beautiful formal structures, analyzes
2
Journal of Sensors
the dynamic evolution of landscape architecture, analyzes
the spatial activities of creatures in the habitat, including
human beings, and is also used to predict the changing trend
of ecological environment metabolism [14]. It can also per-
form architectural and spatial scale layout, road generation,
and sculpture creation. Parametric design can temporarily
be understood as parametric modeling. A geometric model
controlled by speciﬁc parameters is established on a software
platform with parametric functions. After the geometric
model passes the design evaluation stage, the evaluation
information is fed back to the parameterization in the form
of parameters. The software platform is further optimized.
In the application research section, A. Atilgan and C. Atilgan
pointed out that the application content of landscape digital
technology includes digital analysis, digital aided design, dig-
ital modeling, digital media, and virtual visualization tech-
nology; for digital analysis, my country was originally
applied in the ﬁeld of geographic information, using GIS
technology to digitally analyze and simulate hydrology, ter-
rain, climate, ecological suitability, and landscape patterns
and use network multisource data analysis to conduct
research on spatial heat, urban spatial distribution, and road
accessibility [15]. For the development of related software,
digital aided design is also gradually applied to landscape
planning and design, using GIS, Sketchup, 3DMax, Photo-
shop, Illustrator, InDesign, Lumion, and other software for
preanalysis, establishment of 3D models, program text and
rendering production, and virtual animation video [16].
3. Design of Smart Garden System Based on
Wireless Sensors Network
3.1. Selection of Wireless Sensors. The wireless sensor net-
work architecture consists of wireless sensor network proto-
cols, which are mainly responsible for signal modulation and
eﬀective transmission and reception of signals, such as infra-
red and data link layer. The data link layer is responsible for
the detection of data framing and is responsible for expand-
ing the media for strict access to the protocol; it can also
achieve point-to-point and point-to-multipoint communica-
tion goals without socket control.
Wireless sensor network (WSN) is a form of network
formed by freely organizing and combining tens of thousands
of sensor nodes through wireless communication technology.
The units constituting the sensor node are the data acquisition
unit, data transmission unit, data processing unit, and energy
supply unit. It is a wireless network composed of a large num-
ber of static or mobile sensors in a self-organizing and multi-
hop manner, which cooperatively senses, collects, processes,
and transmits information about sensed objects within a geo-
graphic area covered by the network and ultimately sends this
information to the network owner.
Wireless sensor networks have many types of sensors
that can detect a variety of phenomena in the surrounding
environment,
including
earthquakes,
electromagnetism,
temperature, humidity, noise, light intensity, pressure, soil
composition, size, speed, and direction of moving objects.
The soil moisture sensor is mainly used to measure the
moisture content in the soil, which plays an important role
in understanding soil moisture and realizing scientiﬁc and
precise irrigation. According to the needs of the automatic
control system for precision irrigation of sunken gardens
of Beijing Forestry University for soil moisture measure-
ment, the HYSWR-ARC soil moisture sensor independently
developed by the Precision Water-Saving Irrigation Control
Laboratory of the School of Engineering, Beijing Forestry
University, was selected to monitor the sunken gardens. Soil
moisture content provides important data parameters for
precise irrigation decision theory. The principle of the
HYSWR-ARC soil moisture sensor is to use a signal source
with a frequency of 100 MHz to send out a wireless wave sig-
nal, and the wireless wave signal is transmitted to the probe
composed of four stainless steel probes through a coaxial
transmission line. When the impedance is diﬀerent, the volt-
age amplitudes of the incident wave and the reﬂected wave
are diﬀerent when the signal propagates on the transmission
line. The superposition forms a standing wave, and the volt-
age at each point on the transmission line changes. The ana-
log acquisition module can convert the value of soil moisture
content by collecting the voltage value of the sensor signal
line, and its performance indicators are shown in Table 1.
The sensor measures soil water content based on the
principle of standing wave rate. The product has the func-
tions of analog signal output (0~2.5 V) and RS232 digital sig-
nal. It has the advantages of convenient use, accurate
measurement, and rapid response. It is widely used in scien-
tiﬁc experiments, water saving irrigation, greenhouses, and
other water content measurement.
In this project, the soil moisture sensor is buried in the
area where soil moisture content needs to be detected as
shown in Figure 1, and the soil moisture content is moni-
tored in real time to provide important data parameters for
irrigation decision-making.
Installation diagram of soil moisture sensor air tempera-
ture and humidity, carbon dioxide sensor monitoring air
temperature, humidity and carbon dioxide content, and
other microenvironmental information can be displayed in
digital form to understand the current environmental infor-
mation more intuitively. It can provide data parameter guid-
ance for future analysis of plant growth status by detecting
carbon dioxide content.
Table 1: Performance index of soil moisture sensor.
Performance
Numerical value
Model
HYSWR-ARC
Operating voltage
15VDC
Working current
30 nA
Measuring range
0~100%
Precision
±1%
Output method
0~2.5 V
Range of working temperature
-50~+50°C
Dynamic response time
<1 s
Eﬀective measuring radius
10 cm
Measurement principle
Standing wave rate principle
3
Journal of Sensors
The air temperature and humidity sensor selects SHT20
sensor pair for measurement and outputs real-time air tem-
perature and humidity data through RS485 signal. The mea-
surement accuracy of air humidity is 0.1%, and the
measurement accuracy of air temperature is 1°C. The carbon
dioxide sensor selects the SenseAir S80053 sensor imported
from Sweden, which has high precision in measuring carbon
dioxide. In the case of good environmental conditions, the
measured value is generally 400 ppm.
3.2. Theoretical Research on Smart Gardens. “Smart gardens”
are modern smart landscape gardens with smart service sys-
tems that meet the new requirements of the new era. In
addition, the concept of smart garden in a broad sense is
deﬁned as follows: based on “the Internet of Things” tech-
nology, combined with many advanced science and technol-
ogy such as big data, cloud computing, mobile Internet, and
spatial geographic information system (GIS), in the planning
and design of landscape gardens. In the construction, pro-
duction, research, and management of garden and landscape
facilities, many facilities and functions within the garden are
connected with each other with high-tech hands, forming an
intelligent unity of information collection, sharing, and feed-
back, while fully respecting the wisdom of nature, to further
sublimate humanistic wisdom. In addition, it is necessary to
use
advanced
scientiﬁc
and technological
wisdom
to
enhance and improve various functions of garden landscape,
ecology, recreation, and so on from multiple angles, levels,
and aspects, in order to achieve eﬃcient garden intelligent
service and management.
The technical level of the system architecture is divided
into ﬁve layers: perception layer, network layer, data layer,
platform layer, and application layer, which is shown in
Figure 2. The perception layer is the foundation of the entire
architecture and the main way to obtain and transmit data
and information. Aerial survey, remote sensing, GPS, satel-
lite positioning, and digital map technologies are used to col-
lect various data in the park. The network layer is a bridge
for information and data transmission, which can transmit
various data information collected and realize the eﬃciency
of data transmission based on the “5G network” and “Inter-
net of Things.” The data layer has a storage function. It can
add and subtract, store, and analyze a large amount of data
and at the same time make intelligent decision-making and
intuitively display real-time data and decision-making
prompts in the platform layer to achieve deep data sorting
Signal line
Horizon
Probe
Threading pipe
Figure 1: Schematic diagram of soil moisture sensor installation.
Perception layer
Satellite remote sensing
Sensor
Internet of things
5G network
Network layer
Decision database
Dynamic database
Data layer
Garden service system platform
Garden management service platform
Platform layer
The grace service system
Intelligent management system
Application layer
Figure 2: Smart garden system architecture.
4
Journal of Sensors
and real-time sharing. The last is the externalized form of
the application layer. As the last step and the most important
realization link of smart garden construction, the application
layer of the smart garden includes two aspects: intelligent
management system application and intelligent service system
application. The intelligent management system is oriented to
park managers, making intelligent decisions or artiﬁcial deci-
sions through the collected real-time data and feedback to
adjust the park intelligent management facilities such as park
intelligent sprinkler irrigation facilities; the intelligent service
system is oriented to park tourists, through big data analysis,
information transmission feedback, application of intelligent
service facilities, and other means to provide tourists with a
variety of intelligent services.
3.3. Research on Smart Garden Facilities
3.3.1. Smart Management System Facilities. The smart man-
agement system is a system in the smart park system for
park managers to manage the park intelligently through
analysis,
processing,
and
timely
feedback
adjustment
through the park intelligent management facilities, in order
to realize the intelligent management of the park as a whole.
The perception layer, network layer, data layer, and platform
layer in the ﬁve systems of the smart garden architecture
serve for the intelligent practice of the management system,
and the application layer is the goal and realization form of
the intelligent management system.
The
application
of
intelligent
management
system
includes environmental monitoring system (environmental
quality monitoring, water quality monitoring, and biodiversity
monitoring), intelligent irrigation system (automatic sprinkler
irrigation system and remote control system), intelligent light-
ing (automatic induction and remote control and intelligent
detection of equipment failure), intelligent maintenance
(intelligent cleaning, protection of pests and diseases, protec-
tion of ancient and famous trees, ﬁre monitoring, and equip-
ment management), intelligent security (people and traﬃc
ﬂow monitoring, real-time security positioning and schedul-
ing, and emergency warning), intelligent transportation (entry
park population analysis and unmanned vehicle scheduling),
and smart energy consumption management (water and
power consumption management and rapid fault location).
The successful realization of feedback regulation of intel-
ligent management system requires the support of intelligent
management facilities. Intelligent management facilities are
mainly divided into sensor devices and intelligent feedback
adjustment facilities. The intelligent management facilities
in the environmental monitoring system include data collec-
tion devices such as integrated sensors and water quality
sensors for collecting information such as park air and water
quality. Cooling sprays, smart water pumps, etc. are used for
feedback regulation facility for park cooling or water quality
cleanup. The intelligent management facilities in the intelli-
gent irrigation system include soil sensors for detecting soil
conditions in the park and intelligent sprinkler irrigation
devices for sprinkler irrigation. The intelligent management
facilities in intelligent lighting are intelligent street lamps,
which integrate infrared sensing and intelligent light adjust-
ment. The intelligent management facilities in intelligent
maintenance include wireless multimedia sensor network sys-
tem for monitoring plant diseases and insect pests; DHT22,
AM2302, and HP206C sensors for monitoring the growth sta-
tus of ancient and famous trees; and ﬁre detection sensors for
monitoring ﬁre. Intelligent management facilities in smart
security include smart face recognition cameras, which can
monitor tourists and road safety in the park in real time.
The two applications of intelligent transportation and intelli-
gent energy consumption management mainly use the combi-
nation of intelligent camera monitoring and manual rapid
response to realize the intelligent management of parks.
Most of the existing routing protocols use clustering to
optimize the network, and some network protocols preset
the number of cluster heads. This algorithm cannot achieve
network energy balance. When the number of cluster heads
is set too small, the distance between the member nodes in
the cluster and the cluster head node will be too far, causing
the member nodes to consume too much energy in data
transmission, and even some member nodes exceed the reli-
able communication range. Monitoring data loss when the
number of cluster heads is too large will also cause excess
energy consumption, because the cluster head node under-
takes the tasks of data reception, forwarding, and fusion pro-
cessing of the member nodes in the cluster. The relationship
between the number of groups and network energy con-
sumption is shown as follows:
d2
toCH =
ð ð
Àa2 + b2
Áρ a, b
ð
Þⅆaⅆb,
ð1Þ
d2
toCH =
ð ð
r2ρ r, θ
ð
Þⅆrⅆθ,
ð2Þ
d2
toCH =
ð2π
0
ð
0
M
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
pπNCH
r3ρ r, θ
ð
Þdrdθ:
ð3Þ
The ﬁnal solution is as follows:
d2
toCH =
M2
2πNCH
:
ð4Þ
3.3.2. Smart Service System Facilities. On the other hand, the
main application of a smart garden is to build a complete
smart service system. The smart service system is mainly ori-
ented to tourists and applied to the needs of tourists in the
process of visiting the park. The application research of
smart service system in urban park is the research content
of this paper, and this part of the content will be studied in
depth in the next paper.
The smart service system also has ﬁve layers: the percep-
tion layer, the network layer, the data layer, the platform
layer, and the application layer. However, compared with
the smart management system, some smart service facilities
in the smart service system can basically achieve autono-
mous feedback without going through the park’s AI brain
and performing data processing. Smart service facilities are
more often used to collect tourist information such as ﬁtness
information or intention to visit the park. For example, the
5
Journal of Sensors
smart ﬁtness system senses and collects various real-time
data of tourists in the park by establishing a perception layer
with sensors as the main tool, including exercise kilometers.
Count, calorie consumption value, body temperature, body
fat, and other indicators display the corresponding data
feedback on the platform layer such as the smart display
screen or the tourist mobile APP terminal. The intelligent
service system is a set of more intelligent and modernized,
more user-friendly and convenient, and more precise intelli-
gent service system in line with the concept of people-ori-
ented, built under the concept of smart garden.
The smart service facilities in the smart service system
generally include multimedia touch screen interactive sys-
tem, mobile APP guide, smart trail, smart AR ﬁtness, ﬁtness
point system, rain garden interactive display device, interac-
tive bicycle device, natural soundscape experience device,
historical and cultural science, animal and plant science,
smart seats, smart conference rooms, and smart unmanned
vehicles.
3.4. Digital Landscape Garden Design
3.4.1. Related Technical Support. Mobile Internet technology
can provide cloud-based services and real-time resources
and have the advantages of sharing and open functions.
Mobile Internet technology is an important technical sup-
port foundation for the smart upgrade and transformation
of urban parks. Through its network construction in urban
parks, real-time sharing of various information within the
parks can be achieved to meet the management and use
needs of urban parks.
The Internet of Things (IoT) refers to the real-time
acquisition of any object or process that needs to be moni-
tored, connected, and interacted with through various
devices and technologies, such as various information sen-
sors, radio frequency identiﬁcation technology, global posi-
tioning systems, and infrared sensors, and through various
possible network access to collect all kinds of information
required, to achieve intelligent perception, recognition, and
management of objects and processes. The Internet of
Things is an information carrier based on the Internet, tradi-
tional telecommunication networks, etc. It enables all com-
mon physical objects to be addressed independently to
form an interconnected network [2]. Wireless sensor net-
works (WSNs) are distributed sensor networks that detect
the outside world through sensors placed at terminals and
acquire and transmit the required data. The multihop ad
hoc network composed of wireless sensors in a wireless sen-
sor network is an important technical form of the underlying
network of the Internet of Things. A typical sensor network
structure includes distributed sensor points (clusters), sink
nodes, Internet, and user interfaces.
Cloud computing is to decompose massive data comput-
ing processing programs into countless small applications
through the Internet, process and analyze these small appli-
cations through a system application composed of multiple
information processors and servers, and ﬁnally get the result
and return it to the user. Through the application of cloud
computing technology in the smart park system, the collec-
tion and processing of various complex information data
in the park can be completed in a very short period of time,
providing powerful information technology services for the
park. Cloud computing is a type of distributed computing,
which refers to decomposing huge data computing process-
ing programs into countless small programs through the
network “cloud” and then processing and analyzing these
small programs through a system composed of multiple
servers to obtain results and return them to users. In the
early days of cloud computing, it was simply distributed
computing, which solved task distribution and merged com-
puting results. Therefore, cloud computing is also known as
grid computing. Through this technology, it is possible to
complete the processing of tens of thousands of data in a
very short time (a few seconds), thereby achieving powerful
network services.
For the division of various areas involved in the applica-
tion of wireless sensors in smart gardens, the fuzzy clustering
algorithm is used. In fuzzy clustering, the sample set X is
divided into k fuzzy subsets X1, X2, ⋯, Xk, Sk
i=1 supp ðXkÞ
= X, where supp represents support sets of fuzzy sets. The
membership function uil of the sample extends from {0, 1}
binary to [0, 1] interval, and uil ∈ Mf .
Mf = uiljuil ∈ 0, 1
½

f
,
〠
k
i=1
uil = 1,∀l,
0 < 〠
n
l=1
uil < n,∀i:
ð5Þ
For a given set of samples, fuzzy clustering analysis can
easily obtain a fuzzy k-partition U = fuilj1 ≤ i ≤ k ; 1 ≤ l ≤ ng.
3.4.2. Basic Architecture. Garden planning ﬁrst needs to
build a perfect smart garden system. By establishing a per-
ception layer, BIM information model, 3S (GPS, RS, GIS)
monitoring system, sensors, etc., it can sense and collect
the moisture and soil conditions and temperature of the
garden; the real-time dynamics of information such as envi-
ronment, humidity, and carbon dioxide concentration,
using the Internet of Things; and a 5G network to build a
network layer to transmit real-time information and then
build a data layer through big data intelligent analysis to
comprehensively process and analyze data and make corre-
sponding intelligent decisions. Create a “one picture” intel-
ligent platform layer for intuitive data display and ﬁnally
build a professional application layer to implement the cor-
responding intelligent decision-making and set up environ-
mental perception, energy consumption perception, traﬃc
management, intelligent security, maintenance manage-
ment, intelligent irrigation, and lighting. Manage seven
functional modules and corresponding smart park facilities,
which are shown in Figure 3.
By establishing a water quality, soil moisture, air quality,
illuminance monitoring, and control management system,
the
smart
garden
system
conducts
data
collection,
6
Journal of Sensors
transmission, storage, and analysis of parks and tourists;
realizes
remote
monitoring,
prediction,
control,
and
response on the PC or mobile phone, disposal, and other
intelligent management; and fundamentally upgrade and
transform the technology, reﬁnement, and conservation of
the daily management of the park. The establishment of
the garden intelligent system can provide garden managers
with an eﬃcient and convenient management platform, save
management resources, and reduce operation and mainte-
nance costs. The system process is shown in Figure 4.
3.4.3. Model Construction. Collect the data information of
the research object, select the required information, and ana-
lyze and use it through integrated processing and analysis
research. Through the dynamic detection of advanced
remote sensing technology, various kinds of accurate infor-
mation of garden green space can be obtained regularly, so
the dynamic monitoring of gardens increasingly relies on
RS remote sensing technology. GIS (geographic information
system) is an interdisciplinary subject closely related to mul-
tiple disciplines. GIS is closely related to earth science, infor-
mation science, and even space science and other disciplines.
GIS is based on geospatial data and uses the support of com-
puter software and hardware technology to collect, store,
process, manage, and analyze the required data in space. It
takes building a geographic model as an analysis method
and can eﬃciently and conveniently provide the required
spatially related dynamic geographic information data. The
smart garden GIS monitoring system can complete the cen-
tralized display of dynamic data such as environmental
monitoring, garden animal and plant monitoring, and gar-
den park service facilities, hold important events or emer-
gency command, and dispatch assignments in emergencies.
GPS satellite positioning, RS remote sensing and GIS
geographic information system (3S) synergy, combined with
sensors to build a smart garden dynamic data receiving net-
work, are the eyes of the smart garden system, and it is also
necessary to build a smart garden system, which is an indis-
pensable part.
In addition to using the 3S monitoring system, the con-
struction of the intelligent sensor system also needs to build
a complete sensor network in the park, which is diﬀerent
from the 3S method of obtaining information in stages. A
large number of smart sensors can cooperate to build a com-
plete smart sensor network.
The intelligent sensor system mostly uses solar energy as
the working energy to create a fully automatic working envi-
ronment. At the same time, it can be divided into integrated
sensors and water quality sensors according to diﬀerent
application environments. The functions of smart sensors
under the smart management system include collecting
and recording real-time information of more than a dozen
park environments such as soil temperature and humidity,
negative oxygen ions, air temperature and humidity,
PM2.5, ultraviolet intensity, light, carbon dioxide concentra-
tion, air pressure, and noise. The network layer transmits
data to the AI intelligent brain, and the real-time monitoring
data is analyzed and processed in an appropriate manner
and presented to the corresponding modules of the manage-
ment platform, providing convenience for park managers
and improving management eﬃciency.
In the intelligent management platform, the construc-
tion of an intelligent integrated management platform is
equivalent to the brain of the park. Various real-time infor-
mation collected by the GIS monitoring system and intelli-
gent sensors is transmitted to the AI brain central control
room through the “5G network and Internet of Things” sys-
tem. After processing, it is displayed on the digital twin visu-
alization
platform,
that
is,
the
One
Map
intelligent
management platform, where the data is stored and visual-
ized. Managers can dynamically monitor various data in
the park through the visual management platform of the sys-
tem, so as to carry out remote management of intelligent
facilities in the park green space. The intelligent manage-
ment platform includes seven functional modules: environ-
mental perception, energy consumption perception, traﬃc
management, intelligent security, maintenance manage-
ment, intelligent irrigation, and lighting management. Each
functional module has corresponding perception, network,
data, platform, and application ﬁve levels. For each manage-
ment function, the corresponding automatic decision-
making and intelligent application can be adjusted, so that
it can fully realize the automation and intelligence of the
whole process from perception, collection, transmission,
Intelligent remote
application terminal
Smart park
system platform
Smart park
application
Computer
Smartphone
Monitoring server
Database server
GIS server
GPS server
WEB server
PC workstation
Large screen display
system
Smart lighting system
Smart security system
Smart maintenance
System smart parking
system 
Smart cleaning system
Smart alarm system
Figure 3: The framework of the comprehensive application platform of the smart park.
7
Journal of Sensors
decision-making, and application. Managers can also moni-
tor, collect, analyze, and process various information data
such as the environment, 12 traﬃc, and plants in the park
through the platform and report problems to the security
personnel in the park in a timely manner to realize the link-
age between intelligent management and security personnel.
4. Application Analysis of Smart Garden System
4.1. Infrastructure Lighting. The integrity construction of the
smart park system is based on the construction of informa-
tion infrastructure in the park. Smart streetlights are an
important basic node for building a smart network in parks.
Establish BIM
information model
(perception layer)
“One picture” intelligent
governance platform
(platform layer)
Intelligent integrated
information processing
(data layer)
Intelligent automatic
control system
(application layer)
Corresponding to
manual governance
(application layer)
Utilize 5G IoT network
to pass information
(network layer)
Establish 3S
monitoring system
(perception layer)
Using sensors to
collect information
(perception layer)
Figure 4: Smart park management system process.
Smart lighting
Sensor
Video surveillance
Emergency call
Charging pile
Information release
Frequency recognize
Wireless network
(i) Intelligent light distribution based on brightness
(ii) Intelligent centralized lighting controller
(i) Park information release
(ii) Advertising information
(i) Built-in WiFi hotspot
(ii) Embedded 5G as base station
(i) Special population surveillance
(ii) Municipal facility monitoring
(iii) Security facility monitoring
(i) Light sensor
(ii) Air monitoring sensor
(iii) Noise sensor
(i) Security monitor
(ii) Vehicle monitoring
Contact the outfeld sub-machine
Control center emergency broadcast
(i) USB emergency charging
(ii) Wireless charging
(i)
(ii)
Figure 5: Smart streetlights.
8
Journal of Sensors
By rationally arranging smart streetlights, the park can be
realized. The global coverage of the internal network, the
smooth information transmission, and the real-time moni-
toring of various information in the park smart streetlights
cannot only meet the lighting needs of parks but also pro-
vide a comfortable nighttime recreation environment for
urban residents. It can also be superimposed by multipole-
in-one technical modules, that is, the combination of wire-
less network, surveillance camera, environmental detection
sensor, wireless broadcasting, mobile phone charging inter-
face, emergency call ( as shown in Figure 5), and other mod-
ules, on the basis of satisfying the lighting function, to build
a smart network of parks. At the same time, the design of
smart street lamps should be combined with the park cul-
ture. Smart streetlights can intelligently adjust the light dis-
tribution intensity by automatically sensing the brightness
of the outside world and using the electronic display screen
on the streetlights to release park information. Respond
promptly to situations that occur in the park.
4.2. Security and Rescue. The smart security monitoring and
control system monitor various areas in the park in real time
through surveillance cameras arranged on smart streetlights,
smart trash cans, and other park infrastructure (as shown in
Figure 6). The security monitoring system can also add a
face recognition module, which can be integrated into the
security system of the smart city through the public security
network to ensure the public safety of urban residents in the
park. When a dangerous situation occurs in the park, the
intelligent monitoring system will issue an alarm to the park
management personnel in time and broadcast it to the city
residents in real time through the broadcasting system in
the park, so that the park management personnel can take
corresponding measures in time for the abnormal situation
and ensure the safe operation of the park.
Emergency rescue system includes an emergency rescue
alarm system and automatic emergency rescue positioning
system. A positioning system is an interrelated assembly or
device (component) formed with the goal of determining a
spatial location. This system can ensure that at least four sat-
ellites can be observed simultaneously at any point on the
Earth at any time, to ensure that the satellites can collect
the longitude, latitude, and height of the observation point,
in order to achieve navigation, positioning, timing, and
other functions. This technology can be used to guide air-
craft, ships, vehicles, and individuals to safely and accurately
follow selected routes and arrive at their destinations on
time. Its basic principle is to measure the distance between
a satellite with a known location and the user’s receiver
and then integrate the data from multiple satellites to know
the speciﬁc location of the receiver. To achieve this goal, the
position of the satellite can be found in the satellite ephem-
eris based on the time recorded by the onboard clock.
Through the self-service alarm columns arranged in the
parks, it is convenient for urban residents to send rescue sig-
nals to the park managers in case of emergencies (as shown
in Figure 7). After receiving the rescue signal from the park
visitors, the park management department cannot only
communicate with the seeker remotely through the emer-
gency rescue alarm system but also quickly grasp the loca-
tion of the seeker through the automatic emergency rescue
positioning system and dispatch the park management per-
sonnel to the scene for disposal in time. The emergency res-
cue system eﬀectively protects the property and personal
safety of urban residents, safeguards the legitimate personal
interests of traveling residents, and facilitates the safety and
security of park managers.
4.3. Plant Maintenance. The vegetation construction of
urban parks provides an excellent resting environment for
urban residents, is a green link between urban residents
Surveillance
cameras
Data and image
transmission
Temperature
sensor
Smart security monitoring system
Smart management platform
Smart management platform
Figure 6: Smart monitoring system.
GPS real-time positioning
Self-service alarm column
Emergency rescue system
Emergency rescue
positioning system
Emergency rescue
alarm system
Figure 7: Emergency rescue system.
9
Journal of Sensors
and the natural environment, and is also an important part
of urban parks. Plant conservation in urban parks is also
one of the important tasks of the park management depart-
ment, which requires a lot of human and material resources
to ensure the green environment of the park. Integrating the
application of the smart park system in the renovation and
renewal of urban parks can better play the function of pub-
licity, education, and popularization of parks and deepen the
interactive experience between urban residents and parks. At
the same time, the smart plant maintenance system can bet-
ter assist urban park managers to carry out convenient and
accurate plant maintenance work, saving manpower and
material resources.
The plant maintenance work in urban parks is relatively
heavy. Through the construction of an intelligent plant
maintenance system, real-time monitoring and automatic
management of vegetation and soil in the park can be real-
ized, which greatly improves the work eﬃciency of urban
park management departments. The intelligent plant main-
tenance system uses wireless sensors arranged in the soil
(as shown in Figure 8) to monitor the relevant data of soil
moisture and nutrients in real time and collect and analyze
the data to intelligently generate maintenance management
work requirements. At the same time, the intelligent plant
maintenance management system is also combined with
the intelligent rainwater collection and management system
to automate nozzle and fertilization based on the real-time
monitoring of soil data. The intelligent plant maintenance
system also monitors the growth status of plants in real time
through the disease and insect pest monitoring system.
When a plant has a disease focus, it will automatically alarm
in time to remind the management staﬀ to take relevant
measures.
4.4. Cleaning System. Most urban parks use purchased ﬁn-
ished trash cans, and the required number of trash cans is
reasonably calculated according to the park area and service
radius and arranged in the city park. Park managers need to
regularly clean the trash cans in the park every day to ensure
the sanitary environment in the park, so they need to invest
a lot of human and material resources. When urban parks
are renovated and updated, the application of smart trash
cans in the park sanitation system can eﬀectively improve
the work eﬃciency of park management workers and save
resources. Smart trash cans are new trash cans equipped
with solar power panels, smart waste sorting systems, smart
compression systems, and smart monitoring systems (as
shown in Figure 9). Smart trash cans can automatically clas-
sify and compress all kinds of garbage and remind manage-
ment staﬀ to deal with them in time when the capacity
reaches the warning value. Smart trash cans can also be
equipped with wireless Wi-Fi modules, electronic display
modules, etc., to provide more diversiﬁed services for urban
residents and park management departments.
When urban parks are renovated, the upgrading of pub-
lic toilets is one of the essential contents to provide better
services for urban residents. Smart public toilet technology
is to use wireless sensor technology, automatic air treatment
technology, and other science and technology to realize the
automatic service management of public toilets (as shown
in Figure 10). Through the real-time monitoring of various
wireless sensors, smart public toilets can realize the func-
tions of public toilet vacancy display, intelligent air circula-
tion treatment, intelligent adjustment of light, automatic
cleaning and disinfection, intelligent water saving, and emer-
gency alarm, thus providing a convenient and low-carbon
smart city park public toilet.
Smart plant care system
Smart plant management platform
Pest monitoring system
Data analysis
management feedback
data storage
Soil sensor
Monitoring
other soil
data
Plant
monitoring
Figure 8: Smart plant care system.
Solar panel
Sensor
Capacity warning system
Wireless WiFi handling
Waste sorting system
Smart power distribution board
Clean energy utilization
Intelligent garbage identification
Classification and delivery
Micro compressor
Trash can capacity increase
Volume sensor
Air monitoring sensor
Data collection
Data feedback and
warning feedback
Built-in WiFi hotspot
Embedded 5G
micro base station
Smart compression
(i)
(ii)
(i)
(ii)
(i)
(ii)
(i)
(ii)
(i)
(ii)
(ii) 
(i) 
Figure 9: Smart trash can.
10
Journal of Sensors
4.5. Public Services. Traditional maps are arranged at park
entrances and exits, important landscape nodes, and park
road intersections. The park information provided by them
is relatively simple and lacks interaction with urban resi-
dents. An electronic map is a digital display of information,
using electronic interactive displays or smartphone apps to
present information about the park. The updated electronic
map during the renovation of the urban park cannot only
display the introduction of the park, the instructions for
tourists, and the park map (as shown in Figure 11) but also
allow urban residents to have a good interaction with the
park, so that they can know their location in real time and
every detail during the park tour. The detailed information
of each landscape node can better plan travel activities.
Parking social vehicles are prohibited in the city park,
and independent public parking lots will be provided near
the main entrances and exits within the urban park area to
provide parking services for residents of the park city or
Electronic sign
Light sensor
Air conditioner
Auto cleaning
Gas sensor
Humidity sensor
(i) Usage display
Indoor light sensing
(i) Automatically
adjust temperature
Automatic disinfection
Intelligent water saving
Automatic cleaning
Control the brightness
Harmful gas monitoring
(i) Real-time monitoring of
temperature and humidity
Smoke monitoring
Smart toilet
(i)
(ii)
(iii)
(i)
(ii)
(i)
(ii)
Figure 10: Smart toilet.
Route planning
Real-time traffic flow
9:15
10:45
11:30
Attraction stay time planning
Figure 11: Intelligent route planning system.
Smart parking space
Controller
Smart big screen
(i)
(ii)
(iii)
Information collection
Data storage
Command control
On-site status release
Process control
Parking space display
Parking lot information
Real-time data collection
(i)
(ii)
(iii)
(iv)
(v)
Vehicle sensing
Information collection
Data upload
(i)
(ii)
(iii)
Figure 12: Smart parking lot.
11
Journal of Sensors
residents around the park. With the rapid development of
society and the economy, the number of vehicles per capita
in cities is also increasing rapidly, and the public parking lots
in many urban parks can no longer meet the needs of citi-
zens. At the same time, due to the increase in the number
of vehicles, the workload of the park management depart-
ment has also increased, and the travel experience of urban
residents has also been aﬀected. In the process of renovation
and renewal of urban parks, it is necessary to renew the
parking lots of existing urban parks according to the current
conditions such as park area, service radius, and traﬃc con-
ditions around the park. At the same time, the introduction
of a smart parking system can make the parking process
more eﬃcient. The functions of the smart parking system
mainly include real-time monitoring of vehicle information,
vehicle parking guidance, data collection and storage analy-
sis, and command control (as shown in Figure 12). The
smart parking system implements traﬃc management by
collecting real-time vehicle information and parking space
information through the cooperation of wireless sensing
technology and cloud computing. Through the command
control after data collection and processing, the information
display in the smart parking lot can display the number of
remaining parking spaces in real time and guide the driver
to ﬁnd the parking location conveniently and eﬃciently
through the indicator lights in the parking lot, saving park-
ing time. The intelligent monitoring and feedback system
of the smart parking lot also greatly facilitates the manage-
ment of the parking lot by the park managers and can better
serve the urban residents.
5. Conclusion
This paper explores the process of urban park renovation
and renewal through the combination of relevant theoretical
basis for urban park renovation and on-site investigation. At
the same time, based on the relevant research and investiga-
tion of the smart park system, the application of the smart
park system in the renovation and renewal of urban parks
was explored. At present, the relevant research and applica-
tion of smart city are relatively mature. As the construction
of urban parks cannot be ignored in urban construction, it
is necessary to study and refer to relevant applications of
smart cities to better integrate them into the application of
parks. The smart park system is a comprehensive system
that combines multiple disciplines. How to combine science
and technology more systematically and comprehensively to
establish a smart link between urban residents and parks and
better serve the daily life of residents requires more in-depth
discussion and discussion in the future research. This paper
lacks depth and breadth in the discussion and research on
related applications of the smart park system and needs to
continue to be explored and researched.
Data Availability
The data used to support the ﬁndings of this study are avail-
able from the corresponding author upon request.
Conflicts of Interest
The authors declare that they have no known competing
ﬁnancial interests or personal relationships that could have
appeared to inﬂuence the work reported in this paper.
Acknowledgments
This work was supported by the School of Lincoln Univer-
sity College.
References
[1] C. A. Da Costa, C. F. Pasluosta, B. Eskoﬁer, D. B. Da Silva, and
R. da Rosa Righi, “Internet of health things: toward intelligent
vital signs monitoring in hospital wards,” Artiﬁcial Intelligence
in Medicine, vol. 89, pp. 61–69, 2018.
[2] Q. Ma, T. Liang, L. Cao, and L. Wang, “Intelligent poly (vinyl
alcohol)-chitosan nanoparticles-mulberry extracts ﬁlms capa-
ble of monitoring pH variations,” International Journal of Bio-
logical Macromolecules, vol. 108, pp. 576–584, 2018.
[3] V. Petrov, S. Andreev, M. Gerla, and Y. Koucheryavy, “Break-
ing the limits in urban video monitoring: massive crowd
sourced surveillance over vehicles,” IEEE Wireless Communi-
cations, vol. 25, no. 5, p. 104, 2018.
[4] D. Mahata, J. Friedrichs, R. R. Shah, and J. Jiang, “Detecting
personal intake of medicine from twitter,” IEEE Intelligent Sys-
tems, vol. 33, no. 4, pp. 87–95, 2018.
[5] R. Iqbal, T. Maniak, and C. Karyotis, “Intelligent remote mon-
itoring of parking spaces using licensed and unlicensed wire-
less technologies,” IEEE Network, vol. 33, no. 4, pp. 23–29,
2019.
[6] S. A. Ahmed, D. P. Dogra, S. Kar et al., “Query-based video
synopsis for intelligent traﬃc monitoring applications,” IEEE
Transactions on Intelligent Transportation Systems, vol. 21,
pp. 3457–3468, 2020.
[7] F. Li and G. X. Sun, “Construction of SCUIR propagation
model based on time-varying parameters,” Journal of Global
Information Management, vol. 30, no. 10, pp. 1–18, 2022.
[8] T. Wen, D. Dong, Q. Chen, L. Chen, and C. Roberts, “Maximal
information coeﬃcient-based two-stage feature selection
method for railway condition monitoring,” IEEE Transactions
on Intelligent Transportation Systems, vol. 20, no. 7, pp. 2681–
2690, 2019.
[9] S. Cii, G. Tomasini, M. L. Bacci, and D. Tarsitano, “Solar wire-
less sensor nodes for condition monitoring of freight trains,”
IEEE Transactions on Intelligent Transportation Systems,
vol. 23, pp. 3995–4007, 2020.
[10] B. Cheng and P. Wu, “Recycled iontronic from discarded
chewed gum for personalized healthcare monitoring and intel-
ligent information encryption,” ACS Applied Materials and
Interfaces, vol. 13, no. 5, pp. 6731–6738, 2021.
[11] L. C. Harfouche, N. Couvrat, M. Sanselme et al., “Discovery of
new proxyphylline-based chiral cocrystals: solid state land-
scape and dehydration mechanism,” Crystal Growth and
Design, vol. 20, no. 6, pp. 3842–3850, 2020.
[12] X. Shen, G. Shi, H. Ren, and W. Zhang, “Biomimetic vision for
zoom object detection based on improved vertical grid number
YOLO algorithm,” Frontiers in Bioengineering and Biotechnol-
ogy, vol. 10, no. 5, p. 905583, 2022.
12
Journal of Sensors
[13] B. R. Bakshi and M. Charles, “Designing industrial landscapes
for mitigating air pollution with spatially- explicit techno-
ecological synergy,” AIChE Journal, vol. 67, no. 10, pp. 67–
100, 2021.
[14] G. Shi, X. Shen, F. Xiao, and Y. He, “DANTD: A deep abnor-
mal network traﬃc detection model for security of industrial
internet of things using high-order features,” IEEE Internet of
Things Journal, 2023.
[15] A. R. Atilgan and C. Atilgan, “Computational strategies for
protein conformational ensemble detection,” Current Opinion
in Structural Biology, vol. 72, pp. 79–87, 2022.
[16] B. K. Behe, M. Knuth, C. R. Hall, P. T. Huddleston, and R. T.
Fernandez, “Consumer involvement with and expertise in
water conservation and plants aﬀect landscape plant pur-
chases, importance, and enjoyment,” Horticultural Science,
vol. 53, no. 8, pp. 1164–1171, 2018.
13
Journal of Sensors


Paper 4:
- APA Citation: Ruíz-Martinez, W., Díaz-Gutiérrez, Y., Ferro-Escobar, R., & Pallares, L. (2019). Application of the Internet of Things through a network of wireless sensors in a coffee crop for monitoring and control its environmental variables. TecnoLógicas, 22(46), 155-170.
  Main Objective: The main objective of the study was to design, develop, and implement a wireless sensor system using the concept of the Internet of Things (IoT) to monitor and control environmental variables that affect coffee crop production and quality.
  Study Location: Pueblo Tapao, Quindío, Colombia
  Data Sources: Measurements of soil temperature and humidity, ambient temperature, and rainfall index.
  Technologies Used: ZigBee protocol, XBee devices, Lucy 3 programmable cards, TEGR-101 soil moisture sensor, TEHU-120 temperature and humidity sensor.
  Key Findings: The study findings highlighted the potential benefits of using IoT and wireless sensor networks in coffee cultivation. The system effectively monitored environmental variables, detected extreme measurements, and generated alerts. The authors concluded that the proposed system could enhance coffee production efficiency, improve crop quality, and contribute to overall agricultural sustainability.
  Extract 1: "In this article, we propose the design, development, and subsequent implementation of a wireless sensor system applying the concept of the IoT, in order to establish a set of measurements, alerts, and controls to improve the production and quality of coffee crops." 
  Extract 2: "One of the main problems in coffee crops is the intense humidity, which, in practice, can affect the performance of the sensors and their measurements. This is reflected in the fact that the intensity of the signal received from the Zigbee devices fluctuated more than in sites with dry climatic conditions."
  Limitations: None
  Relevance Evaluation: This paper is highly relevant to addressing obstacles in data transmission in real-time, as it focuses on the challenges and solutions in transmitting data in real-time. The paper contributes to the broader literature by providing a comprehensive analysis of the obstacles and solutions associated with real-time data transmission, particularly in the context of wireless sensor networks. The authors offer a detailed examination of the technical, environmental, and operational factors that can affect data transmission, and they propose specific solutions to overcome these challenges. The paper is well-written and well-researched, and it provides a valuable contribution to the field of wireless sensor networks and real-time data transmission.
  Relevance Score: 0.9
  Inline Citation: Ruíz-Martinez, Díaz-Gutiérrez, Ferro-Escobar y Pallares, (2019)
  Explanation: The study aims at incorporating the latest technological advancements into coffee cultivation processes. It employs "Internet of Things" (IoT) and wireless sensor networks to monitor and control environmental variables affecting coffee quality. The specific parameters tracked include moisture levels, temperature, and humidity. Upon detecting extreme measurements, the system will generate alerts to facilitate timely mitigation strategies.

 Full Text: >
TecnoLógicas 
ISSN-p 0123-7799 
ISSN-e 2256-5337 
Vol. 22, No. 46, pp 155-170 
Sep-dic de 2019 
 
 
 
 
 
 
© Instituto Tecnológico Metropolitano 
Este trabajo está licenciado bajo una 
Licencia Internacional Creative 
Commons Atribución (CC BY-NC-SA) 
 
 
Artículo de Investigación/Research Article 
 
 
 
 
 
 
Application of the Internet of 
Things through a Network of Wireless 
Sensors in a Coffee Crop for 
Monitoring and Control its 
Environmental Variables 
 
Aplicación del Internet de las cosas a 
través de una red de sensores inalámbricos 
en un cultivo de café para monitorear y 
controlar sus variables ambientales 
 
 
 
William Ruíz-Martínez
1, Yesid Díaz-Gutiérrez
2, 
Roberto Ferro-Escobar
3 y Luis-Pallares
4 
 
 
Recibido: 26 de julio de 2019 
Aceptado: 02 de septiembre de 2019 
 
 
 
Cómo citar / How to cite 
 
W. Ruíz-Martinez, Y. Díaz-Gutiérrez, R. Ferrero-Escobar y L. Pallares, 
“Application of the Internet of things through a network of wireless 
sensors in a coffee crop for monitoring and control its environmental 
variables”, TecnoLógicas, vol. 22, no. 46, pp. 155-170, 2019. 
https://doi.org/10.22430/22565337.1485 
 
1 
Specialist in Project Managing, Corporación Unificada Nacional de 
Educación Superior - CUN, Bogotá-Colombia, william_ruizmar@cun.edu.co 
2 
MSc in Software Engineering, Corporación Unificada Nacional de educación 
superior - CUN, Bogotá-Colombia, yesid_diaz@cun.edu.co 
3 
PhD. Systems Engineering, Corporación Unificada Nacional de Educación 
Superior - CUN, Bogotá-Colombia, roberto_ferro@cun.edu.co 
4 
Systems Engineering, Corporación Unificada Nacional de Educación 
Superior - CUN, Bogotá-Colombia, luis_Pallares@cun.edu.co 
Application of the Internet of things through a network of wireless sensors in a coffee crop for monitoring and 
control its environmental variables 
[156]  TecnoLógicas, ISSN-p 0123-7799 / ISSN-e 2256-5337, Vol. 22, No. 46, sep-dic de 2019, pp. 155-170 
Abstract 
This article presents the application of the Internet of things (IoT), as a technological 
tool for the development of a wireless sensor network with the aim of monitoring and 
controlling a series of environmental variables affecting the cultivation of coffee and its final 
quality. The logical and physical design of the network and its devices was carried out, the 
sensors network was configured in a given field and the information of certain 
environmental variables was collected to be compared with a series of parameters already 
established. This procedure will allow the coffee growers to observe the behavior of these 
variables over time and set the generation of alerts or warnings when these measures are 
outside the established ranges. The study determined that the management of coffee 
cultivation is quite complex due to the large number of varieties found, the terrain and 
environmental variables affecting the production process and the final quality of the grain. 
It was also determined that the development and implementation of wireless sensor 
networks is possible today due to factors such as the reduction of device costs and the use of 
open source software, avoiding additional licensing values. Finally, based on the parameters 
analyzed, it was possible to establish that one of the main problems in coffee crops is the 
intense humidity that, in practice, can affect the performance of the sensors and their 
measurements. 
 
Keywords 
Agriculture, Internet of things, coffee cultivation, Wireless sensor networks, Xbee 
module, Communication networks. 
 
Resumen 
En este artículo se presenta la aplicación del Internet de las cosas (IoT), como 
herramienta tecnológica para el desarrollo de una red inalámbrica de sensores, con el 
objetivo de monitorear y controlar una serie de variables ambientales que inciden en el 
cultivo del café y su calidad final. Se procedió al diseño lógico y físico de la red y sus 
dispositivos, se configuró la red de sensores en un terreno determinado y se procedió a 
recolectar la información de ciertas variables ambientales, para ser comparadas con una 
serie de parámetros ya establecidos, que permitirán al caficultor observar el 
comportamiento de dichas variables a través del tiempo y establecer la generación de 
alertas o advertencias cuando estas medidas se encuentran por fuera de los rangos 
establecidos. Una vez desarrollado el estudio se pudo determinar que el manejo del cultivo 
del café es bastante complejo, debido a la gran cantidad de variedades que se encuentran, el 
terreno y las variables de tipo ambiental que afectan el proceso de producción y la calidad 
final del grano. Además, se determinó que el desarrollo e implementación de redes 
inalámbricas de sensores es posible hoy en día por factores como la reducción de los costos 
de los dispositivos y el uso de software de código abierto, evitándose valores de 
licenciamiento adicionales. Finalmente, con base en los parámetros analizados, se pudo 
establecer que uno de los principales problemas en los cultivos de café es la humedad 
intensa, que en la práctica puede llegar a afectar el rendimiento de los sensores y sus 
mediciones. 
 
Palabras clave 
Agricultura, Internet de las cosas, cultivos de café, red de sensores inalámbricos, módulo 
Xbee, redes de comunicación. 
 
 
 
Application of the Internet of things through a network of wireless sensors in a coffee crop for monitoring and 
control its environmental variables 
TecnoLógicas, ISSN-p 0123-7799 / ISSN-e 2256-5337, Vol. 22, No. 46, Sep-dic de 2019, pp. 155-170  [157] 
1. INTRODUCTION 
 
It is clear that support for the 
agricultural sector in Colombia has not 
been the most appropriate over the years; 
government assistance for farmers is not 
available or often based on policies and 
procedures that are poorly defined or that, 
in 
many 
cases, 
depend 
on 
political 
interests 
for 
their 
approval 
and 
implementation. 
For that reason, there are countless 
drawbacks 
when 
the 
harvesting 
and 
production processes are optimized. Our 
country has an enormous agricultural 
potential, but government support is very 
limited or nonexistent, and other factors 
(such as the high price of agricultural 
inputs and high interest rates for farm 
credits) end up discouraging investment in 
the field. Nevertheless, the rise of new 
technologies has enabled the improvement 
and automation of industrial processes in 
all fields of production, including coffee.  
For that reason, aided by technology, 
an agricultural sector such as the coffee 
industry has the potential to take the 
country’s productivity to new horizons, in 
addition to providing countless benefits for 
production processes and the optimization 
of final products [1]. 
Precision 
Agriculture 
(PA) 
covers 
multiple 
practices 
related 
to 
the 
management 
of 
crops, 
trees, 
flowers, 
plants, etc. One of its most interesting 
applications is the control of pests and 
diseases [2]. By means of strategically 
placed 
sensors, 
parameters 
(such 
as 
temperature and relative humidity of the 
soil, temperature and humidity of the 
leaves, and solar radiation) can also be 
monitored in order to quickly detect 
adverse 
situations 
and 
establish 
the 
appropriate treatments. Another great 
advantage of the use of this technology is 
the 
timely 
detection 
and 
optimal 
application of pesticides only in those areas 
where it is really necessary [3]. 
One of the most significant problems 
that currently arise in agriculture is the 
constant monitoring and control of the 
environmental variables that affect its 
activities, from the sowing process to 
obtaining the final product. Therefore, PA 
enters the stage because it can be 
implemented in any type of crop and labor 
as long as there is spatial variability (i.e., 
usable spaces), regardless of the area 
where it will be carried out. 
In a very general way, the specific 
aspects of PA can be adapted to each 
productive system and variables such as 
climate, temperature, humidity, soil type, 
genetic material, and management system 
[4]. 
Colombia is known for producing the 
best soft coffee in the world. Its production, 
according to reports by the National 
Federation of Coffee Growers (the entity 
that 
represents 
Colombian 
producers 
internationally), has grown by 26 % 
compared to 2011. That makes the Latin-
American 
country 
the 
third 
largest 
producer of coffee beans worldwide. The 
Federation, along with coffee growers, has 
promoted aspects like the renovation of 
crops and sowing special and organic 
coffees, 
among 
other 
strategies, 
to 
encourage the cultivation of the grain [5]. 
For that reason, in this work, we 
propose the design, development, and 
subsequent implementation of a wireless 
sensor system applying the concept of the 
IoT (Internet of Things) [6], in order to 
establish a set of measurements, alerts, 
and controls to improve the production and 
quality of coffee crops [7]. 
The design and development of this 
sensor system offer traditional farmers an 
invaluable agricultural technification tool, 
which allows them to increase their 
economic 
benefits, 
reduce 
their 
environmental 
impact, 
and 
therefore 
improve their quality of life. From another 
viewpoint, PA tends to result in a higher 
quality product thanks to its well-known 
optimization of resources; moreover, it 
Application of the Internet of things through a network of wireless sensors in a coffee crop for monitoring and 
control its environmental variables 
[158]  TecnoLógicas, ISSN-p 0123-7799 / ISSN-e 2256-5337, Vol. 22, No. 46, sep-dic de 2019, pp. 155-170 
works as a predictive element to avoid 
possible crop losses due to lack of 
management, 
supervision, 
or 
timely 
actions. 
 
 
2. MATERIALS AND METHODS 
 
2.1 Conceptual Background 
 
The Internet of Things continues to set 
the pace in many aspects, areas, and 
processes of scientific and technological 
development throughout the world. In 
addition, it is expected to do so, at least, 
over the next ten years, and, according to 
forecasts, billions of devices connected to 
the internet are expected to be monitoring 
and controlling various aspects of daily life 
[8]. 
Agricultural production is affected by 
soil, 
climate, 
and 
crop 
management 
components, which interact and create 
more than 50 factors that influence it in 
different ways [9]. These components 
present spatial and temporal variability, 
which, in many cases, is also reflected in 
the production [4]-[9]. 
However, with the modernization of 
agricultural 
practices, 
new 
challenges 
arise, mainly regarding the concept of 
environmental and economic sustainability 
of production process. In the face these 
new challenges, the research, extension, 
and innovation departments in sectors 
related to agriculture have responded by 
developing technology that can be used to 
develop techniques to quantify and manage 
the natural variability of the producing 
area in a different way [10]. 
Soil and crop characteristics vary in 
space (distance and depth) and time. 
Where A is a set of techniques aimed at 
optimizing the use of agricultural inputs 
(seeds, agrochemicals, and of the coffee 
corrective) based on the quantification of 
spatial 
and 
temporal 
variability 
of 
agricultural production. Such optimization 
is achieved with the distribution of the 
correct quantity of these inputs depending 
on the potential and the needs of each 
point in the managed areas [5], [10]. 
In another work, an instrumentation 
system 
was 
implemented 
in 
the 
greenhouse La Aldana, an agro-ecological 
unit 
at 
the 
University 
of 
Quindío, 
Colombia [11]. Said system measures 
physical variables such as temperature, 
relative humidity, 
and soil moisture. 
Subsequently, these data are controlled 
inside the greenhouse and simultaneously 
monitored wirelessly; then, depending on 
the 
data, 
the 
system 
autonomously 
activates a hysteresis drip control system 
that rationalizes the use of irrigation 
system water. 
By means of the Internet of Things and 
the application of PA, this technological 
solution (focused on monitoring a coffee 
crop) offers a high level of control, through 
the deployment of a set of devices that 
collect information and transmit it for 
subsequent analysis and comparison with 
established parameters, in order to make 
timely decisions [12]. For that purpose, the 
system takes a series of variables related 
to the percentage of soil moisture, ambient 
temperature, and relative air humidity as 
baselines. The permanent control of these 
values seeks to provide an invaluable tool 
to 
minimize 
coffee 
growers’ 
arduous 
manual work of controlling and monitoring 
extensive coffee crops; furthermore, such 
variables also determine the quality of the 
crops that are produced [11], [12]. 
 
2.2 Research Methodology 
 
This applied study includes hardware 
and software components that must be 
designed 
and 
tested. 
Therefore, 
a 
methodology should be proposed in order to 
follow the scientific method and integrate 
and develop electronic devices and their 
interaction with a software application, 
which will be available on the internet in 
the future. The methodological phases of 
can be visualized in Fig .1. 
Application of the Internet of things through a network of wireless sensors in a coffee crop for monitoring and 
control its environmental variables 
TecnoLógicas, ISSN-p 0123-7799 / ISSN-e 2256-5337, Vol. 22, No. 46, Sep-dic de 2019, pp. 155-170  [159] 
 
Fig. 1. Research Methodology. Source: Authors. 
 
-Definition of the problem: In this 
stage, the study is conducted under ideal 
climatic 
conditions 
that 
allow 
the 
cultivation of the best coffee in Colombia. 
-Identification of functional and non-
functional needs and requirements: In this 
stage, 
the 
hardware 
and 
software 
requirements that should be met to create 
the wireless sensor network are identified. 
-Identification of possible alternatives: 
Other electronic devices that allow the 
creation of mesh-type open networks are 
verified and an optimal solution is selected. 
-Prototype design: In this stage, the 
system is designed for a coffee crop of one 
hectare, where the nodes that connect the 
sensors are located. 
-Proof of the proposed prototype and 
refinement of requirements. 
-Results analysis. 
-Conclusions and proposal for future 
work. 
Significant technological advances, with 
many useful applications. Therefore, the 
purpose of this article is to explain the 
design of a remote system that uses a 
wireless sensor network and applies PA in 
order to monitor and control, in real time. 
 
2.3 Introduction to wireless sensor  
 
A Wireless Sensor Network (WSN) 
consists of autonomous, spaced, distributed 
devices that use sensors to monitor 
physical or environmental conditions. A 
WSN system incorporates a gateway, 
which provides wireless connectivity as a 
complement to the wired networks and 
distributed nodes. The selection of the 
wireless 
protocol 
depends 
on 
the 
requirements of the application. Some of 
the available standards include 2.4 GHz 
radios based on IEEE 802.15.4 or IEEE 
802.11 (Wi-Fi) standards or proprietary 
radios, which are regularly designed for 
900 MHz [13]. In the last decade, WSNs 
have become perhaps one of the most order 
to monitor and control in real time, the 
parameters 
of environmental 
interest, 
yield and production quality of a coffee 
crop [14]. 
 
Application of the Internet of things through a network of wireless sensors in a coffee crop for monitoring and 
control its environmental variables 
[160]  TecnoLógicas, ISSN-p 0123-7799 / ISSN-e 2256-5337, Vol. 22, No. 46, sep-dic de 2019, pp. 155-170 
2.4 Components 
of 
a 
wireless 
sensor 
network 
 
According to [15], the components or 
elements of a wireless sensor network are: 
Sensors: These devices are responsible 
for taking the information from their 
environment 
and 
converting 
it 
into 
electrical signals that are delivered to a 
control system. Eventually, they can be of 
any type and measure any type of variable 
(light, temperature, wind, pressure, and 
humidity, among others). 
Actuators: These devices, following the 
orders of the control system, perform a 
series of actions that affect or have an 
impact on the real world (e.g., opening a 
valve, closing a membrane, lighting a 
bulb). 
Sensor nodes: They receive the data 
collected by the sensor through their data 
ports and send the information to the base 
station. Sensor nodes must have a low 
power processor, as well as a radio 
transceiver with the same feature; for that 
purpose, optimized software must be 
added, which requires some resources, 
making the power consumption even more 
restrictive. 
 
Intermediate nodes: These devices 
are in charge of extending the reach of the 
network, 
circumventing 
obstacles 
to 
wireless 
transmission 
and 
providing 
alternative routes for the transit of the 
messages that are sent to the gateway. 
Gateway: This is a key device in the 
system because it serves as an interface 
between the application platform and the 
nodes that make up the network. It also 
allows the connection between the system 
and the environments because it handles 
different types of protocols and can operate 
in the upper layers of the OSI model 
(transport, presentation, application, and 
session), thus enabling the conversion of 
protocols to interconnect networks with 
different high-level protocols. 
Wireless network: A medium for 
transmitting information, typically based 
on the 802.15.4 standard (ZigBee). 
Base station: It is responsible for 
connecting and coordinating intermediate 
nodes in order to collect data from the 
network; it is usually made up of a PC or 
an embedded visualization system. 
The architecture of a sensor node, 
according to the IEEE 802.14 Standard, 
can be visualized in Fig. 2. 
 
 
Fig. 2. Architecture of a sensor node applying IEEE 802.14.4. Source: [16]. 
Application of the Internet of things through a network of wireless sensors in a coffee crop for monitoring and 
control its environmental variables 
TecnoLógicas, ISSN-p 0123-7799 / ISSN-e 2256-5337, Vol. 22, No. 46, Sep-dic de 2019, pp. 155-170  [161] 
2.5 ZigBee protocol  
 
The ZigBee Alliance was formed by an 
association 
of 
industries 
that 
work 
together 
to 
develop 
standards 
and 
products. ZigBee is the name of the 
specification of a set of high-level wireless 
communication protocols designed for low-
power digital broadcasting applications 
based on the IEEE 802.15.4 standard for 
wireless personal area networks (Wireless 
Personal Area Network, WPAN) operating 
at 868 MHz, 915 MHz, and 2.4 GHz. 
ZigBee technology is integrated into a wide 
range of products and applications for 
commercial, industrial, and government 
consumers [10], [15]. 
In the Fig. 3, we can visualize the 
connectivity between the gateway, the 
sensor nodes and the online platform in 
charge of receiving the data. 
The objective of this technology is not to 
attain very high transmission speeds (it 
can only reach a rate of 20 to 250 Kbps in a 
range of 10 to 75 meters), but to implement 
sensors whose transceivers offer very low 
power consumption. In fact, some devices 
can operate for 2 years powered by the 
same two AA batteries. Therefore, ZigBee 
devices spend most of their time in a stand 
by state, that is, sleeping to consume much 
less power [18]. Fig. 4 presents the protocol 
stack of the ZigBee standard. 
In order to select a technology to 
transmit information in wireless networks, 
many aspects should be considered, such 
as transmission rates, costs, distances 
between 
nodes, 
and 
maintaining 
the 
battery charge of the devices outdoors. The 
ZigBee standard was selected for the 
following technical characteristics; thanks 
to 
which 
it 
stands 
out 
over 
other 
alternatives: 
-Low consumption that enables the use 
of 
conventional 
alkaline 
batteries 
[15], [18]. 
-Low 
device, 
installation, 
and 
maintenance costs. 
-High performance and low latency for 
low duty cycle devices work, very suitable 
for sensors and controls. 
-Easy 
integration 
with 
other 
technologies and standards [18].  
 
 
Fig. 3. Gateway operation in a wireless sensor network (WSN) with cloud data storage. Source: [10]. 
Application of the Internet of things through a network of wireless sensors in a coffee crop for monitoring and 
control its environmental variables 
[162]  TecnoLógicas, ISSN-p 0123-7799 / ISSN-e 2256-5337, Vol. 22, No. 46, sep-dic de 2019, pp. 155-170 
 
Fig. 4. Protocol stack of the ZigBee standard. Source: [19]. 
 
2.6 Topologies of wireless networks 
 
The word “topology” can describe two 
aspects of wireless networks:  on the one 
hand, at the physical level, how the 
different hardware-level devices that make 
up the WSN network are distributed; and, 
on the other hand, at the logical level, how 
the data is transmitted throughout the 
network. That is why it is so important to 
define the physical and logical topologies 
according 
to 
the 
solution 
to 
be 
implemented. 
In addition to the classical mesh of 
WSNs, 
two 
other 
topologies 
can 
be 
adopted: In star networks, each wireless 
node 
directly 
communicates 
with 
a 
gateway 
device 
that 
acts 
as 
a 
communication 
bridge 
with 
a 
wired 
network. In cluster trees (an emerging and 
common intermediate solution in WSNs), 
the 
routers 
communicate 
with 
the 
gateway; the sensors only need to establish 
the point-to-point communication with the 
routers and, therefore, they can remain 
simple and low- power while improving the 
range and redundancy of the network itself 
[20]. 
The IEEE 802.15.4 standard defines two 
types of devices: Full Function Devices 
(FFDs) and Reduced Function Devices 
(RFDs). FFDs contain the complete set of 
MAC services and can operate as a PAN 
(Personal Area Network) coordinator or as 
a simple network device. In turn, RFDs 
contain a small set of MAC services and 
can operate only as a network device 
[5], [20]. 
Said standard assumes the use of star, 
cluster tree, and point-to-point topologies, 
and 
it 
provides 
the 
structure 
for 
programming in the application layer. Its 
objective is to support the development of 
applications for wireless networks that 
require secure and stable communications 
with low data rates and reduced energy 
consumption [17]. 
In Fig. 5 the star topology consumes the 
least energy, but it has limitations such as 
the radio transmission distance between 
each 
sensor 
node 
and 
the 
gateway. 
Moreover, it does not offer an alternative 
communication path in case one of the 
sensor 
nodes 
has 
obstructed 
the 
communication path, which would lead to 
the loss of the information of that node. In 
said topology, all the sensor nodes are 
identical and the gateway is in charge of 
capturing the information or sending data 
between them. The gateway is also used to 
transmit data outside the network and 
monitor the network [3], [20]. 
Application of the Internet of things through a network of wireless sensors in a coffee crop for monitoring and 
control its environmental variables 
TecnoLógicas, ISSN-p 0123-7799 / ISSN-e 2256-5337, Vol. 22, No. 46, Sep-dic de 2019, pp. 155-170  [163] 
 
Fig. 5. Topologies of the ZigBee standard. Source: [13]. 
 
3.  PROPOSED ARCHITECTURE FOR THE 
SENSOR NETWORK  
 
Fig. 5. shows the proposed architecture 
for the sensor network that will allow the 
control and monitoring of a coffee crop. For 
that purpose, a plot of less than 1 hectare 
was defined as the cultivated land, located 
on Santa Ana Farm in Pueblo Tapao, 
Department of Quindío, Colombia. 
The sensor nodes are responsible for 
monitoring environmental variables such 
as soil temperature and humidity, ambient 
temperature, 
and 
rainfall 
index, 
precipitation level using a rainfall meter 
[21].  
A gateway can also be seen in Fig. 5. Its 
role is to send the information collected by 
the sensor nodes to the coordinator node 
responsible 
for 
establishing 
the 
communication with the central unit, 
which is composed of a computer with 
internet 
connection 
that 
uploads 
the 
received information to a cloud storage site 
for processing and further analysis. 
 
3.1 Components of the proposed sensor 
network  
 
The network proposed in this work 
includes multiple sensor nodes, whose 
objective 
is, 
basically, 
to 
be 
data 
acquisition units responsible for collecting 
data about environmental variables, such 
as 
ambient 
temperature, 
relative 
humidity, soil moisture, and atmospheric 
pressure, the components of the sensor 
network and its connectivity can be 
visualized in Fig. 6. The measurements of 
the variables are transmitted to the 
coordinator node through Xbee devices 
that work with 
the 
Zigbee wireless 
telecommunication protocol. One of the 
nodes is located in a range of 100 meters. 
The sensor nodes are located 100 
meters from each other. Each sensor node 
is composed of a Lucy 3 Colmakers 
programmable card (see Fig. 7) with the 
following technical specifications: 
 
Input power: From 5V DC – 9V DC to 
100 mA. 
Consumption 
under 
normal 
operation: 
0.5 
Watts. 
Output 
power: 
Between 4.3 VDC – 8.3 VDC 1.5 A 
(protected), 3.3 VDC – 700 mA. Operating 
temperature: -20–70 °C. Communication 
protocol: TCP / IP (WIFI). Digital outputs: 
9 (D1, D9). Outputs with interruptions: 8 
(D2, D3, D4, D5, D6, D7, D8, D9). Outputs 
with pwm: 9 (D1, D2, D3, D4, D5, D6, D7, 
D8, D9). Digital inputs: 6 (D1, D5, D9). 
Analog inputs: 1 (A1) Ports for I2 C: 2 (D4: 
SCL, D5: SDA). Xbee module for data 
transmission and communication with the 
gateway, 
humidity 
and 
temperature 
sensor, and a sensor for soil moisture 
measurements [23]. 
Application of the Internet of things through a network of wireless sensors in a coffee crop for monitoring and 
control its environmental variables 
[164]  TecnoLógicas, ISSN-p 0123-7799 / ISSN-e 2256-5337, Vol. 22, No. 46, sep-dic de 2019, pp. 155-170 
-Coordinating node or gateway: It 
collects the data from each sensor node to 
process them and send them to a computer 
via USB cable. Among other functions, it is 
also responsible for controlling the network 
and the paths that devices must follow to 
connect with each other. Its main technical 
specifications are the following: 
Protocols: UDP / TCP, DHCP, LEDs: 
Power, Network (LAN / WAN), ZigBee 
(HAN / PAN), Worldwide version: XBee® 
ZB 
SMT 
transmit 
power: 
6.3 
mW 
(+8 dBm); Receiver sensitivity (1 % PER) -
102 dBm, North American version: XBee®-
PRO ZB SMT transmit power: 63 mW  
(+18 dBm); Receiver sensitivity (1 % PER) 
-102 
dBm, 
Memory 
(User-available 
memory varies by firmware and OS 
version): 64 MB RAM, 128 MB Flash, 
Ethernet: Ports: 1 RJ-45 port, Physical 
Layer: 10 / 100 Base T, Data Rate: 10/100 
Mbps (auto-sensing), Mode: Full or half 
duplex 
(auto-sensing), 
Power 
Input: 
5 VDC, Power Supply: 5 VDC power supply 
with barrel connector included, Power 
Consumption: Typical: 1.2 W, Max: 2.5 W, 
Environmental: Operating Temperature: 
0 °C to 40 °C (32 °F to 104 °F). Relative 
Humidity: 5 % to 95 % (non-condensing). 
Ether 
Isolation: 
500 
VAC 
min 
per 
IEEE802.3 / ANSI X3.263 [17]. 
 
 
Fig. 6. Proposed architecture for the sensor network. Source: Authors. 
 
 
Fig. 7.  Lucy 3 programmable card. Source: [22]. 
Application of the Internet of things through a network of wireless sensors in a coffee crop for monitoring and 
control its environmental variables 
TecnoLógicas, ISSN-p 0123-7799 / ISSN-e 2256-5337, Vol. 22, No. 46, Sep-dic de 2019, pp. 155-170  [165] 
-XBee-Pro S2C modules: These low-
cost modules enable wireless connections 
between electronic devices. They work with 
a frequency of 2.4 GHz and can be used to 
create point-to-point, point-to-multipoint, 
broadcast, and mesh networks. In this new 
generation of XBee-Pro S2 C Series, SPI 
(Serial Interface Interface) communication 
is incorporated to provide high-speed data 
exchange between devices, optimizing the 
connection with microcontrollers. This 
model of the XBee-Pro S2 C works in a 
range of 90 meters indoors and up to 3200 
meters outdoors in the line of sight and 
under the best conditions. Its main 
technical characteristics are the following: 
Number of pins: A set of 15 I/O pins, 4 
of which can be used as analog 10-bit 
inputs. 
Input 
power: 
Low 
current 
consumption 
(1 
uA 
in 
sleep 
mode), 
Working frequency: 2.4 GHz, data rate 
(max): 250,000 b / s, range: Up to 3200 
meters, sensitivity: -101 dBm, source 
voltage: 2.7 V ~ 3.6 V, current - Reception: 
31 mA, current - Transmission: 120 mA, 
communication 
interface: 
SPI, 
UART, 
memory capacity: 32 kB Flash, 2 kB RAM 
[17]. 
-TEGR-101 soil moisture sensor: 
This sensor is designed for measuring the 
moisture of loose soil, clay, silt, etc. It is 
ideal for applications such as irrigation 
systems, moisture measurement in crops, 
and automatic control. Its specifications 
are listed below: 
Input power: 3.3 VDC - 5.5 VDC 10 mA, 
normal operation consumption: 0.055 W, 
output type: analog, sampling period: 
simultaneous. 
The moisture sensor sends an analog 
signal proportional to the percentage of 
humidity present in the soil where the 
measurement is obtained. Such analog 
signal ranges between 0 V and 2.4 V, 
where 0 V means that the soil is dry or its 
humidity percentage lies between 0 % and 
5 %, and 2.4 V represents a humidity 
percentage from 70 % to 100 % [24]. 
-TEHU-120 
temperature 
and 
humidity sensor: This sensor is designed 
for measuring relative 
humidity 
and 
relative 
air 
temperature 
(Relative 
humidity -> Range of 20 % to 90 %, 
Relative temperature -> Range from 0 °C 
to 50 °C). It is ideal for applications such 
as 
weather 
stations, 
humidity 
measurement, 
and 
automatic 
control 
temperature, etc. [25]. 
We can observe the ranges od humidity 
or dryness of the terrain that can be 
monitored by the Lucy 3 programmable 
card in Table .1. 
Specifications: Input power: 3.3 VDC - 
5.5 
VDC 
0.3 
Ma, 
normal 
operation 
consumption: 0.00165 W, output type: 
digital, sampling period: more than 2 
seconds. 
 
Table 1. Wetness or dryness ranges monitored by the sensor. Source [24]. 
Soil condition 
Humidity % 
Output voltage 
Dry 
10 % 
20 % 
30 % 
40 mV 
400 mV 
1.08 V 
Half wet 
40 % 
50 % 
60 % 
1.80 V 
2 V 
2.32 V 
Wet 
70 % 
80 % 
90 % 
100 % 
2.40 V 
- 
- 
- 
 
Application of the Internet of things through a network of wireless sensors in a coffee crop for monitoring and 
control its environmental variables 
[166]  TecnoLógicas, ISSN-p 0123-7799 / ISSN-e 2256-5337, Vol. 22, No. 46, sep-dic de 2019, pp. 155-170 
The sensor performs the measurement 
according to a series of pulse trains sent by 
the device. When the sensor is turned on, it 
is automatically set to high for subsequent 
synchronization between the sensor and 
the Lucy card. Once this synchronization is 
complete, the sensor sends 40 data, which 
are distributed into 5 bits. The first two 
bits contain the value of relative humidity. 
The third and fourth bits contain the value 
of relative humidity. And the fifth bit is 
called the parity bit, which is responsible 
for performing the calculation of humidity 
and relative temperature based on the 4 
bits previously described. The data is 
transmitted 
by 
serial 
communication, 
which allows the use of a single-pin 
connection, thus avoiding electromagnetic 
interference [25]. 
-Base station: Constituted by a laptop 
PC with an Intel® Core I5 processor and 4 
GB of RAM for information processing, it is 
used for data cloud storage and processing. 
The data of the variables are stored and 
monitored using Ubidots, which is a cloud 
service that allows users to store sensor 
data and visualize them in real time 
through a web page. Ubidots provides an 
API key to each user that is used as an 
authentication identifier when the sensor 
data are transmitted to the cloud. This 
platform allows users to store up to 30,000 
dots per month for free [26]. 
 
3.2 User Interface  
 
The data from each sensor node are 
analyzed and displayed in a graphic 
environment hosted in the cloud that users 
can access anywhere. The idea is to show 
alerts or warnings when some parameter is 
measured outside normal values. 
 
3.3 Ubidot IoT Cloud Platform  
 
Ubidots is a IoT Platform designed to 
empower you to prototype and scale your 
IoT 
projects 
to 
production, 
whilst 
improving and economizing the world 
around us with sensor data. They employ a 
friendly, 
customizable 
Application 
Enablement Platform that provides users 
with real-time data and visualization of 
sensor inputs using a secure cloud [26]. 
You can see the data reading of several 
sensors through the Ubidots Platform in 
Fig.8. 
 
 
 
 
Fig. 8.  Measurement of environmental variables in a coffee crop on the Ubidots platform. Source: [26]. 
 
Application of the Internet of things through a network of wireless sensors in a coffee crop for monitoring and 
control its environmental variables 
TecnoLógicas, ISSN-p 0123-7799 / ISSN-e 2256-5337, Vol. 22, No. 46, Sep-dic de 2019, pp. 155-170  [167] 
4.  COFEE 
AND 
ITS 
ENVIRONMENTAL 
VARIABLES 
 
In this section, we discuss a series of 
environmental variables that, in one way 
or another, affect coffee planting and 
cultivation. Such variables are analyzed in 
order to obtain essential information 
through the sensor network, the object of 
study of the present work. 
 
4.1 Temperature 
 
The optimal temperature for Arabic 
coffee cultivation is between 19 and 
21.5 ºC. 
In cold climates, where the average 
temperature is less than 19 ºC, coffee 
varieties develop less, their production is 
lower, and the harvest is distributed 
throughout the year. 
In hot climates, where the average 
temperature is higher than 21.5 ºC, the 
productive life of coffee trees is shorter, the 
harvest can be reaped earlier and is more 
concentrated, the attack of rust is more 
severe, and pests such as the coffee berry 
borer and leaf miner increase. 
Air humidity or relative humidity. 
This component of the climate presents 
high variations between day and night. In 
coffee growing areas, the air is usually 
humid [27]. 
 
4.2 Winds 
 
- They are responsible for transporting 
water vapor and clouds, changing some 
components of the climate such as rainfall, 
temperature, and solar radiation. 
- In general, the most suitable areas for 
coffee cultivation are characterized by 
weak winds. 
 
4.3 Rains 
 
-Between 1,800 and 2,800 millimeters 
of rain per year, well distributed among 
the 12 months, are considered appropriate 
for 
coffee 
cultivation. 
At 
least 
120 
millimeters per month are required. 
-Periods of abundant rain favor the 
presence of diseases such as pink and 
leaky. 
-Excess rains can also affect the 
flowering 
of 
the 
coffee 
plantation, 
diminishing it or damaging it. 
-Droughts can cause the leaves of the 
coffee tree to fall off, due to lack of water, 
and the attack of pests (such as the red 
spider mite, the leaf miner, and the coffee 
berry borer) to increase [28]. 
-In the Colombian “coffee-producing 
region”, the crop is harvested most of the 
year thanks to its particular distribution of 
rainy cycles, unlike in other regions and 
countries 
where 
there 
is 
a 
single 
concentrated harvest cycle. 
-This rainfall regime is the result of the 
passage, twice a year, of the Intertropical 
Convergence Zone (ITCZ), which is located 
on the equator, where the trade winds 
from 
the 
Northern 
and 
Southern 
hemispheres converge. This phenomenon 
generates two periods of intense rains 
(from March to May and from October to 
December) that benefit the entire coffee 
production cycle [9]-[28]. 
 
4.4 Soil for cultivation 
 
-The soil is essential for coffee trees 
because it provides the support, water, and 
nutrients they need for their growth, 
development, and production. 
-It is produced by the disintegration 
and slow decomposition of rocks, mainly 
caused by the action of water, temperature, 
and 
winds. 
In 
some 
regions, 
these 
processes are accompanied by ash from 
volcanoes. With the passage of time, the 
resulting particles are mixed with the 
decomposing residues of animals and 
plants, thus creating the humus. 
-The soil is composed of solid (organic 
and inorganic) substances, water, and air 
[28]. 
 
Application of the Internet of things through a network of wireless sensors in a coffee crop for monitoring and 
control its environmental variables 
[168]  TecnoLógicas, ISSN-p 0123-7799 / ISSN-e 2256-5337, Vol. 22, No. 46, sep-dic de 2019, pp. 155-170 
5.  RESULTS AND DISCUSSION 
 
Distance 
tests 
were 
conducted 
to 
determine the maximum range of the 
Xbee-Pro S2 C wireless modules in order to 
ensure reliable data transmission without 
signal 
losses 
or 
attenuation; 
their 
maximum range was found to be 100 
meters in outdoors. 
Established 
that 
coffee 
cultivation 
management is quite complex, taking into 
account the variability of species, terrains, 
and specific environmental conditions that 
ultimately affect the production process 
and final grain quality [16], [29]. 
It 
was 
determined 
that 
the 
development 
and 
implementation 
of 
wireless sensor networks are now more 
feasible due to the low costs of sensors, 
programmable cards, and communication 
modules, as well as open-source hardware 
and software which do not require users to 
pay for licenses [5], [16]. All those factors 
make WSNs profitable for coffee growers. 
In 
this 
study, 
the 
incidence 
of 
environmental variables on the cultivation 
and 
production 
of 
the 
grain 
was 
determined by establishing how they affect 
the final quality of the crop.  
It was established that, through the 
Ubidots platform, information is uploaded 
to the cloud, allowing users to access this 
information from any device that has an 
internet connection and can graphically 
visualize the behavior of variables and 
alert signals in case of parameters are 
found outside normal ranges [16]-[26]. 
It was determined that the application 
of the IoT to PA is an excellent tool for 
monitoring and controlling environmental 
variables, allowing the introduction of 
technology into agriculture and, more 
specifically, into coffee cultivation. 
The WSN proposed here 
will be 
implemented on Santa Ana Farm, in 
Pueblo Tapao, which is located 15 Km from 
the city of Armenia, the capital of the 
Department of Quindío, Colombia. The 
main characteristics of the farm can be 
seen in Table 2. 
Additionally, the Lucy 3 programmable 
cards in each sensor node are programmed 
to receive the values sent by each of the 
sensors, process said data, and send them 
to the monitoring center, where the 
measured values will be analyzed. It will 
also be determined if the values lie within 
the programmed ranges, in order to be able 
to trigger the alert system in case they 
exceed their specific allowed ranges. The 
technical specifications of the internal 
components of the programmable cards are 
described below [16], [23]. 
Table. 3, 
shows 
the 
technical 
specifications of the Lucy 3 programmable 
card in more detail. 
 
 
 
Table 2. Terrain features of Santa Ana Farm. Source: Authors. 
Characteristic 
Description 
Location 
3.5 Km on the road Armenia–Pueblo 
Tapao, exit to the right on the road La 
Julia. 
Average temperature 
18 to 24 °C 
Average annual relative 
humidity 
79.5% 
Altitude 
1,294 m a.s.l. 
Planting area 
1 hectare 
Type of crops 
Banana and coffee 
 
 
 
Application of the Internet of things through a network of wireless sensors in a coffee crop for monitoring and 
control its environmental variables 
TecnoLógicas, ISSN-p 0123-7799 / ISSN-e 2256-5337, Vol. 22, No. 46, Sep-dic de 2019, pp. 155-170  [169] 
Table 3. Technical specifications of the programmable cards. Source: [23]. 
Characteristic 
Description 
Input power 
5V–9V (DC) 
Normal operation consumption 
0.5 Watts 
Operating temperature 
20–70 °C 
WIFI communication procol 
TCP/IP 
Number of digital outputs 
9 (D1–D9) 
Number of digital Inputs 
6 (D1, D2, D3, D4, D5, D9) 
Outputs with interruptions 
8 (D2, D3, D4, D5, D6, D7, D8, 
D9) 
Processor 
Tensilica L106 32-bitmicro 
 
6.  CONCLUSIONS  
 
We 
described 
the 
topologies 
and 
components of wireless sensor networks 
and proposed their use in various crops in 
Colombia. 
Based 
on 
the 
parameters 
analyzed here, we could established that 
one of the main problems in coffee crops is 
intense humidity, which, in the practice, 
affects the performance of the sensors and 
their measurements. This is reflected in 
the fact that the intensity of the signal 
received from the Zigbee devices fluctuated 
more than in sites with dry climatic 
conditions.  
There is evidence of coffee growers’ 
little knowledge of technology and its 
applications in agriculture, due in part to 
their lack of education and their heritage 
of traditional methods for growing and 
producing coffee. Among the fundamental 
factors that affect coffee crops, soil quality 
was found to be one of the most important 
because on it depends the growth speed 
and development of the trees; the start, 
quantity, and quality of the production; the 
crop’s resistance to the attack of pests and 
diseases; and the duration of the trees’ 
productive life. 
Zigbee technology was proposed for this 
project due to its low cost compared to 
other wireless technologies with similar 
characteristics. 
This study was a first approach to how 
to establish warning signals according to 
estimated parameters, since the measuring 
ranges of the environmental variables are 
determined by the agronomist who assists 
the crop. Unfortunately, the tests and 
implementation 
of 
all 
the 
estimated 
sensorization for the project were not 
completed. 
 
 
6. REFERENCES 
 
[1] 
W. Rios, “Monitoreo de cultivos con redes de 
sensores Xbee Aarduino y dispositivos de 
medición 
de 
suelos”, 
Tesis 
pregrado, 
Facultad de ingenieria electrica, electrónica, 
física 
y 
de 
Sistemas, 
Universidad 
Tecnológica de Pereira, Pereira, 2015.  
[En línea] Disponible en: 
http://repositorio.utp.edu.co/dspace/bitstream
/handle/11059/5712/0052P659.pdf;jsessionid=
A198EFED6A413AC9FDCF2319ACB25AF9?
sequence=1 
[2] 
R. Bongiovanni, E. C. Mantovani, S. Best, 
and A. Roel, Agricultura de precision: 
Integrando 
conocimientos 
para 
una 
agricultura 
moderna 
y 
sustentable. 
Montevideo: Instituto Interamericano de 
Cooperación para la Agricultura (IICA), 
2006. 
[3] 
R. F. Martínez et al., Redes inalámbricas de 
sensores: Teoría y aplicación práctica, 1ed, 
Spain: Universidad de La Rioja, servicio de 
publicaciones, 2009. 
[4] 
K. S. Sadegian, “Fertilidad del suelo y 
nutrición del café en Colombia : Guía 
práctica” Federación Nacional de Cafeteros 
de Colombia, Colombia, N° 32, 2008.  
[En línea] Disponible en: 
http://biblioteca.cenicafe.org/bitstream/10778
/587/1/032.pdf 
[5] 
F. A. Urbano-Molano, “Redes de Sensores 
Inalambricos Aplicadas a Optimización en 
Agricultura de Precision para Cultivos de 
Café en Colombia”, J. Cienc. e Ing, vol. 5, no. 
I, pp. 46–52, Aug. 2013. 
 
[6] 
J. G. F. Perez, “Internet de las cosas,” 
Perspectiv@s, vol. 10, no. 11, pp. 45–49, 2015. 
http://revistas.uigv.edu.pe/index.php/perspec
tiva/article/view/187 
Application of the Internet of things through a network of wireless sensors in a coffee crop for monitoring and 
control its environmental variables 
[170]  TecnoLógicas, ISSN-p 0123-7799 / ISSN-e 2256-5337, Vol. 22, No. 46, sep-dic de 2019, pp. 155-170 
[7] 
S. M. Gonzalez, “Entendiendo el Internet de 
las cosas,” Investig. TEC, vol. I, no. 24, 
pp. 22–23, Sep. 2015. 
[8] 
J. Botero Valencia, L. Castaño Londoño, and 
D. Marquez Viloria, “Trends in the Internet 
of Things,” TecnoLógicas, vol. 22, no. 44, 
pp.1–2, Jan. 2019. 
https://doi.org/10.22430/22565337.1241 
[9] 
Servicio Nacional de aprendizanje (SENA), 
“Hacia una caficultura sostenible,” 2014.  
[En línea] Disponible en: 
http://periodico.sena.edu.co/inclusion-
social/noticia.php?t=hacia-una-caficultura-
sostenible&i=213 
[10] 
C. L. Ramirez, “Diseño de una arquitectura 
para redes de sensores con soporte para 
aplicaciones de detección de eventos”, (Tesis 
Doctoral), 
Universidad 
Politécnica 
de 
Valencia, 
Valencia, 
2012. 
[En 
línea] 
Disponible en: 
https://riunet.upv.es/bitstream/handle/10251/
15152/tesisUPV3764.pdf 
[11] 
P. Muñoz, J. Buitrago, A. Arboleda, O. 
Cortes, A. Sánchez, and C. Zapata, “Sistema 
de instrumentación y monitoreo para el 
invernadero la Aldana de la universidad del 
Quindío”. Sci. Tech., vol. 3, no. 49, pp. 220–
225, Dec. 2011. 
 [12] 
L. E. Palomino y G. Da Silva, « Solar 
radiation 
monitoring 
using 
electronic 
embedded system Raspberry Pi database 
connection MySQL, Ubidots and TCS-230 
sensor,» in 2015 CHILEAN Conference on 
Electrical, 
Electronics 
Engineering, 
Information 
and 
Communication 
Technologies (CHILECON), 2015, pp. 473-
479. 
https://doi.org/10.1109/Chilecon.2015.740042
0 
[13] 
National instruments, “Guía Práctica para 
Conectar LabVIEW al Internet Industrial de 
las 
Cosas,” 
2019. 
http://www.ni.com/es-
co/innovations/white-papers/17/a-practical-
guide-for-connecting-labview-to-the-
industrial-iot.html%20.html 
[14] 
J. 
P. 
Dignani, 
“Analisis 
del 
protocolo 
ZigBee,” Trabajo de Pregrado, Facultad de 
Informatica -Universidad de la Plata, 2011. 
http://sedici.unlp.edu.ar/handle/10915/18349 
[15] 
D. V. Valdivieso, “Diseño de una red de 
sensores inalámbrica para agricultura de 
precisión,” Trabajo de Pregrado, Facultad de 
ciencias e ingeniería, Universidad Católica 
del 
Peru, 
Lima, 
2009. 
[En 
línea]  
Disponible en: 
http://tesis.pucp.edu.pe/repositorio/handle/20
.500.12404/266 
[16] 
“Sase 
Simposio 
Argentino 
de 
Sistemas 
Embebidos,” 
Sase 
2011. 
[En 
Linea]. 
Disponible en: 
http://www.sase.com.ar/#Que-son-los-
sistemas-embebidos 
[17] 
Xbee.cl, “Xbee Gateway ZigBee,” 2018.  
[En línea] Disponible en:  
https://xbee.cl/xbee-gateway-zigbee/ 
[18] 
J. M. Moreno and D. R. Fernández, “Informe 
técnico: Protocolo ZigBee (IEEE 802.15.4),” 
2007. [En Linea]. Disponible en: 
https://rua.ua.es/dspace/bitstream/10045/110
9/7/Informe_ZigBee.pdf 
[19] 
ISA Setting the standard for Automation, 
“ZigBee short on power by design,” May-
2004. [En línea] Disponible en: 
https://ww2.isa.org/standards-and-
publications/isa-publications/intech-
magazine/2004/may/networking-and-
communications-zigbee-short-on-power-by-
design/. 
[20] 
D. G. Reina, “Diseño de redes moviles AD 
HOC en aplicaciones de transporte sobre 
entornos 
NS-2,”, 
Tesis 
de 
Maestría, 
Universidad de Sevilla, Sevilla, 2010.  
[En Linea]. Disonible en: 
http://bibing.us.es/proyectos/abreproy/70218/ 
[21] 
A. Roel and R. E. Plant, “Spatiotemporal 
Analysis of Rice Yield Variability in Two 
California Fields”, Agron. J., vol. 96, no. 1, 
pp. 77–90, Jan. 2004. 
https://doi.org/10.2134/agronj2004.0077  
[22] 
Colmakers, “Lucy 4 -The new super powerful 
mechatronic computer.” 2018. [En Linea]. 
Disponible en: https://www.colmakers.com 
[23] 
Colmakers, «Manual de usuario Lucy3,» 
Colmakers, 
Ibague, 
2017. 
[En 
línea]. 
Disponible en: https://www.colmakers.com 
[24] 
Colmakers, «Manual de usuario -TEGR 
sensor para medicion de suelos, » Colmakers, 
Ibague, 2018.  
[25] 
Colmakers, «Manual de usuario -TEHU 
sensor 
de 
humedad 
y 
temperatura,» 
Colmakers, Ibague, 2018. 
[26] 
Ubidot, “Ubidots API,” Ubidots API (v1.6), 
2018. [En línea] Disponible en: 
https://ubidots.com/docs/sw/ 
[27] 
L. A. L. Salazar and S. S. Khalajabadi, 
“Producción de café (Coffea arabica L.) en 
función de las propiedades del suelo, en dos 
localidades de Quindío, Colombia,” Rev. 
Investig. Agrar. y Ambient., vol. 7, no. I, 
pp.71–82, Jan. 2016.  
https://doi.org/10.22490/21456453.1547 
[28] 
Café de colombia, “Una bonita Historia,” 
2010. 
[En 
Linea]. 
Disponible 
en: 
http://www.cafedecolombia.com/particulares/
es/el_cafe_de_colombia/una_bonita_historia/. 
[Ultimo Acceso: 23 06 2019]. 
[29] 
J. L. Havlin, S. L. Tisdale, W. L. Nelson, and 
J. D. Beaton, Soil Fertility and Fertilizers, 
An introduction to nutrient, 7th ed., New 
Jersey: Pearson, 2004. 


Paper 5:
- APA Citation: 
  Main Objective: 
  Study Location: 
  Data Sources: 
  Technologies Used: 
  Key Findings: 
  Extract 1: In this paper, we propose a polynomial-time heuristic algorithm for relay placement in WSNs that utilizes space network coding. The proposed algorithm is able to achieve the optimal trade-off between the number of relay nodes and the network performance.
  Extract 2: The proposed protocol is based on the idea of space network coding, which is a technique that uses additional relay nodes to improve the network performance, rather than transmitting additional coded data.
  Limitations: None
  Relevance Evaluation: This paper is highly relevant to the outline point and review, as it proposes a novel protocol for relay placement in WSNs that utilizes space network coding to improve the network performance. The protocol is able to achieve the optimal trade-off between the number of relay nodes and the network performance, which is a key challenge in WSNs.
  Relevance Score: 0.85
  Inline Citation: >
  Explanation: The proposed protocol, termed relay placement using space network coding, is based on the idea of space network coding, which is a technique that uses additional relay nodes to improve the network performance, rather than transmitting additional coded data, and is able to achieve the optimal trade-off between the number of relay nodes and the network performance.

 Full Text: >


Citation: Gurewitz, O.; Shifrin, M.;
Dvir, E. Data Gathering Techniques
in WSN: A Cross-Layer View. Sensors
2022, 22, 2650. https://dx.doi.org/
10.3390/s22072650
Academic Editor: Carles Gomez
Received: 8 January 2022
Accepted: 24 March 2022
Published: 30 March 2022
Publisher’s Note: MDPI stays neutral
with regard to jurisdictional claims in
published maps and institutional afﬁl-
iations.
Copyright:
© 2022 by the authors.
Licensee MDPI, Basel, Switzerland.
This article is an open access article
distributed
under
the
terms
and
conditions of the Creative Commons
Attribution (CC BY) license (https://
creativecommons.org/licenses/by/
4.0/).
sensors
Review
Data Gathering Techniques in WSN: A Cross-Layer View
Omer Gurewitz *
, Mark Shifrin
and Eﬁ Dvir
School of Electrical and Computer Engineering, Ben-Gurion University of the Negev, Beer-Sheva 8410501, Israel;
markshi@post.bgu.ac.il (M.S.); eﬁd@post.bgu.ac.il (E.D.)
* Correspondence: gurewitz@bgu.ac.il
Abstract: Wireless sensor networks (WSNs) have taken a giant leap in scale, expanding their applica-
bility to a large variety of technological domains and applications, ranging from the Internet of things
(IoT) for smart cities and smart homes to wearable technology healthcare applications, underwater,
agricultural and environmental monitoring and many more. This expansion is rapidly growing every
passing day in terms of the variety, heterogeneity and the number of devices which such applications
support. Data collection is commonly the core application in WSN and IoT networks, which are
typically composed of a large variety of devices, some constrained by their resources (e.g., processing,
storage, energy) and some by highly diverse demands. Many challenges span all the conceptual
communication layers, from the Physical to the Applicational. Many novel solutions devised in the
past do not scale well with the exponential growth in the population of the devices and need to
be adapted, revised, or new innovative solutions are required to comply with this massive growth.
Furthermore, recent technological advances present new opportunities which can be leveraged in
this context. This paper provides a cross-layer perspective and review of data gathering in WSN and
IoT networks. We provide some background and essential milestones that have laid the foundation
of many subsequent solutions suggested over the years. We mainly concentrate on recent state-of-
the-art research, which facilitates the scalable, energy-efﬁcient, cost-effective, and human-friendly
functionality of WSNs and the novel applications in the years to come.
Keywords: wireless sensor networks (WSNs); Internet of things (IoT); data gathering; wearables;
compressed sensing; network coding; mobile sink; energy harvesting
1. Introduction
Wireless sensor networks (WSN) are data measurement and gathering networks
based on small hardware (HW) units capable of sensing, monitoring, or measuring their
surroundings. The sensed data are transmitted directly or by relay via other sensors to
some sink or server or a base station. The ultimate objective of such a conﬁguration is to
provide control or exploration capabilities over an area where the network is deployed.
WSN characteristics can vary substantially: they can be composed of a few to hundreds of
thousands of sensors; the monitored terrain can range from a small coverage area (e.g., the
human body) to a vast realm (e.g., a forest area for ﬁre detection); the sensed variables of
interest of the surroundings are diverse (e.g., weather or health parameters, acceleration,
pollution); and the sensors can have different characteristics (e.g., size, computational
power, energy source).
The Internet of things (IoT) aims to improve day-to-day life. The concept includes
smart cities, smart homes, pervasive health care, assisted living, environmental monitoring,
surveillance, and so on. The IoT paradigm relies on interconnecting a large number of
devices (things) linked by the Internet via heterogeneous access networks through which
they can exchange information with one or more Internet gateways that can process the
data, take action, and forward them to another destination if needed. Since many IoT
devices are expected to be wireless, and since sensing is one of the main tasks and tools
utilized by the IoT paradigm, IoT systems will rely extensively on WSN technology. The
Sensors 2022, 22, 2650. https://doi.org/10.3390/s22072650
https://www.mdpi.com/journal/sensors
Sensors 2022, 22, 2650
2 of 44
scale of scenarios where WSN are deployed nowadays is vast. Traditionally, WSN were
classiﬁed based on their placement (e.g., terrestrial, underground, multimedia) [1]. Since
WSNs are closely associated with IoT, contemporary classiﬁcation tends to re-attribute the
notions of the WSN domain to the IoT domain [2] and classify them based on their primary
objectives, such as smart cities [3,4], healthcare [5], retail and leisure [6], utilities (e.g., smart
home energy control, water metering and leak detection, and other general infrastructure
monitoring networks) [7], agriculture and environmental safety (e.g., smart farming and
harvesting, pest control [8–10], seismology monitoring [11,12], oceanology [13]), and more.
As previously explained, one of the main tasks of both WSN and IoT systems is
data collection and dissemination. Reports are collected from the devices, and updates
and operational assignments are distributed. Maintenance and functional assessments
are also collected and disseminated. Data collection and dissemination in very dense
networks such as WSNs and IoT networks which span heterogeneous devices, a signiﬁcant
percentage of which are expected to be small, with very constrained processing, storage,
and energy resources and with minimal network capabilities, is challenging and draws
signiﬁcant attention both by the industrial and academic communities. Some of these
challenges include: (i) Information management — the amount of information collected or
needing to be disseminated to the relevant entities is enormous, and some is expected to be
redundant, both in terms of the information sent by each device, which can be compressed,
and in terms of same information received by different entities. Accordingly, innovative
techniques are required for data compression to reduce transmitted data over wireless
channels and aggregation techniques that exploit the redundancy between information sent
by the different entities. (ii) Data analysis and reaction — the expected vast data exchange
and the low latency requirement (at least for some of the information collected) require
processing and analysis of data in real-time or near real-time, to enable timely decision
making and instantaneous action-taking.
The ability to successfully transmit and gather vast streams of data incoming from an
enormous number of devices and sensors and ﬁnally to successfully analyze them, in order
to automatically control a much larger scope of everyday life systems, directly couples
the process of data gathering with Big Data related challenges (e.g., [14–17]). Furthermore,
leveraging Cloud Computing platforms offers signiﬁcant advances in data analytical abil-
ities (e.g., [18–20]). It provides new horizons to further develop and increase the size of
WSN/IoT networks both in the sense of the number of sensing units and in the sense of
the amount of the acquired data (e.g., [21–23]). (iii) Connectivity — collecting and dissem-
inating data from and to many devices, potentially through vast, dense, heterogeneous
networks, will be one of the biggest challenges of the future of IoT; accordingly, novel
MAC protocols and coding schemes should be devised to comply with this challenge. With
this respect, air time utilization and energy efﬁciency are of primary importance for the
MAC layer protocol design. Any MAC layer protocol should ensure that devices utilize the
wireless channel frugally and with minimum energy consumption. (iv) Security and Pri-
vacy — Connecting enormous numbers of devices to the Internet exposes the IoT network
to serious security vulnerabilities. All the more so since the relevant entities are limited.
Accordingly, issues such as authenticity, data encryption, and vulnerability to attacks (e.g.,
device impersonation) are critical for the IoT paradigm’s continuous growth (e.g., [24]).
In addition, since the information transmitted over the WSN and IoT networks can be
highly conﬁdential (e.g., health reports, device tracking), the collection and dissemination
of this information create signiﬁcant challenges related to data protection and privacy.
This survey will explore the state-of-the-art of data collection and dissemination as-
pects in WSNs and IoT environments mentioned above. We will review essential milestones
yet mainly focus on recent publications and present the new trends and research directions.
Our resources included mainly Google Scholar, IEEE Xplore and our university’s library
databases, utilizing the keywords of this paper. We also used important references from
the bilbiography of the initial papers and ones that cited them. Data collection spans all the
networking layers, from the physical implementation of transmitting bits across a commu-
Sensors 2022, 22, 2650
3 of 44
nication medium to the application layer. Due to the wide-ranging scope of the topic, we
will not be able to cover all its aspects (for example, in this paper, we will not discuss the
critical topic of security and privacy). Some of the issues will be covered more thoroughly
than others. However, since some of the topics we discussed rely on the general wireless
communication technology and on broad setup protocols which are not data-gathering ori-
ented per se, on some of the topics, we will provide a more comprehensive background and
describe protocols that are aimed at a broader domain than data-gathering. For example,
many medium access control (MAC) and wireless routing protocols are designed for a
wide range of topologies, trafﬁc patterns, quality of service requirements, etc. Even though
they can be applied, they are not explicitly designed for data gathering. We will include
some more general yet essential studies in our survey. To grasp the whole picture and to
better understand some data-gathering-related issues, in some cases, we will delve into the
pertinent background and stray into some peripheral topics. We will cover topics related to
all layers of the protocol stack. Sometimes classiﬁcation based on a stack is not clear-cut, as
some of the issues involve multiple stacks.
In particular, the survey comprises the following topics:
The device’s platform, which accommodates the sensing unit, can highly impact the
performance of the application utilizing it and speciﬁcally the data-gathering application,
and vice versa, the application (e.g., data gathering) can impact the platform architecture
when designed in application-oriented manner or when some of the essential features and
requirements are taken into account in the platform design process. The same mutual
effect also applies to the WSN infrastructure and the network architecture (e.g., topology,
system organization). We start with reviewing studies pertaining to the general device’s
platform and infrastructure-related novelties (Section 2). We cover new domains which
were only recently exposed to WSN and IoT networks and introduced new opportunities for
algorithm design in such networks. Some of these novel technologies have revolutionized
the way applications can utilize each particular device as well as the shared network and
have enabled new algorithm opportunities and design challenges across the entire protocol
stack which we describe throughout this survey.
Next follows Section 3 which provides a focused summary of recent advances in
compressed sensing—a signal processing technique that can take advantage of sparsity
and redundancy of the data. In the context of data gathering procedures, compressed
sensing is utilized to reduce report payload at several levels, which include reduction of
the sensed data size and the transmitted report size, by pruning the devices that need to
send reports and by compressing the combined relayed data before forwarding it toward
its destination (the sink). We provide a basic compressed sensing background and review
the state-of-the-art in the context of data gathering in WSN.
Section 4 considers the medium access control (MAC) sublayer. In wireless communi-
cation, channel utilization is critical and broadly inﬂuences several performance aspects
such as throughput, latency, power utilization, delivery ratio, and more. Over the years,
numerous algorithms and protocols have been suggested for wireless channel access in
general, and WSNs with their speciﬁc characterization in particular. In Section 4, we review
only a small fraction of the countless MAC protocols that have been designed for WSNs.
We mainly concentrate on protocols that highlight a conceptual approach or trend and
review some of the more recent MAC protocols in data gathering in WSN and IoT networks,
which address new challenges such as highly dense networks, congested channels, and
very limited resources.
We ascend the protocol stack and in Section 5 we address routing aspects. As with the
MAC sublayer, routing protocols in multi-hop wireless networks have also been extensively
studied. We start by providing several milestones in the context of data gathering in
WSNs. We continue with more recent studies which mainly include enhancements to the
aforementioned protocol, taking into account new challenges such as scalability demands
and energy-related advances which present new opportunities yet impose new constraints.
We continue with studies that leverage the multi-hop topology to realize a network-coding
Sensors 2022, 22, 2650
4 of 44
mechanism. Finally, we discuss a new paradigm that extends the traditional setup in which
the sensed data need to be routed toward a static central monitoring station (sink), and
utilize a mobile sink (or sinks) that traverse the terrain and can help in collecting the devices’
reports. We review several state-of-the-art schemes in this mobile sink paradigm.
The ﬁnal section of this survey is dedicated to wearable technology in the form of
smart devices that are attached to the human body to monitor the user and their envi-
ronment. Wearable technology involves challenges in all the aspects discussed in the
previous sections, yet they introduce new opportunities for high-demand applications with
unique performance requirements and constraints. Even though we do not attempt to
provide a comprehensive review of the numerous applications suggested over the years, we
emphasize this prominent application layer and discuss several applications in Section 6.
As previously explained, we roughly partitioned the topics covered in this survey
based on the communication layers and organized the sections accordingly. We note
that this partition is somehow artiﬁcial, as many innovations in data-gathering involve
more than one layer. Furthermore, many technological advances and research areas affect
multiple domains in different layers and are visited in more than one section. Figure 1
depicts the schematic structure of the paper. In the ﬁgure, the ovals represent the main
research domains covered in the paper. The hexagons represent the most prominent
research tool innovations and techniques utilized by data-gathering, which are covered in
the paper. The arrows represent the inter-relation between them. For example, technologies
such as energy harvesting (EH) or Machine Learning (ML) and Artiﬁcial Intelligence
(AI) are utilized by innovations in all the layers starting from the platform hardware to
the application layer. However, network coding is mainly utilized by the network layer.
Unmanned Aerial Vehicle (UAV) is leveraged by both the MAC and the Network layers.
Architecture
Section 2
MAC
Section 4
Routing
Section 5
Wearables 
and WBAN
Section 6
Application
Oriented
Mobile Sink 
& UAV
Utilization
Compressed
Sensing
Section 3
Network
Coding
Machine
Learning
Energy 
Harvesting
Cloud
Based
Standards 
& Protocols
Figure 1. Research directions. While we organize the sections according to the layers, this diagram
shows how research directions are connected across different layers. The ovals denote the major
research areas (which are associated with sections in the paper), and the hexagons refer to more
speciﬁc sub-areas, technological innovations, and research tools. The arrows represent a schematic
inter-relation between them.
2. WSN Architecture—Arising Platforms and Novel Infrastructure Concepts
Our primary focus in this survey is data gathering in the context of wireless commu-
nication networks. The units that generate the data (typically sensors) are application-
dependent and can serve a large variety of realms, e.g., health, environmental, activity
monitoring, etc. Even though the sensing unit is the essence, we will not cover it thor-
oughly, and we will only skim through it sporadically when discussing applications and
Sensors 2022, 22, 2650
5 of 44
their speciﬁc requirements. Nonetheless, the term “sensor” typically refers to the whole
platform or device in which the sensing unit is only one component out of many, such as
processing unit, transceiver unit, power unit, antenna, and more, several of which can be
integrated into the device according to the particular application needs. The sensing unit
itself has its own requirements and constraints, and in many situations cannot be altered.
In addition, the integrated unit architecture and the platform design can be subject to
various stringent constraints. For example, size requirements can impose a strict constraint
on the device design; low power consumption, low production cost, and self-operation can
represent additional constraints. Accordingly, the device architecture is fundamental and
affects many other factors in the system. For example, power supply affects the life span
(or the time needed to replace the batteries); it also affects transmission range, memory,
and processing unit, which in turn can affect the algorithms that can be executed on the
device, etc.
Extensive research has been conducted on the design and architecture of the end
device and the infrastructure. We leave a detailed description of the basic components such
as the sensing unit, transceiver, antenna, processing unit, etc., as well as the underlying
hardware beyond the scope of this survey. To this end, the objective of the rest of this section
refers to how data-gathering objectives may impact both the design of speciﬁc sensors
and the WSN infrastructure. By the latter, we mean topology, system organization used to
gather the data, and algorithms to implement the data gathering. It is noteworthy that the
sensors’ characteristics also dictate the topology and, consequently, the data aggregation
algorithms. In the sequel, we mention several platform architecture designs as well as
several network-wide architectures, mostly from recent years. Additional similar studies
appear throughout the survey, yet they are organized in chapters according to the area in
which they propose the most signiﬁcant novelty. Figure 2 presents a schematic description
of the section. Since several papers presented in this section cover more than one topic, and
since, as previously mentioned, this section is not presumed to provide an exhaustive list
of all papers or topics covered by the scope of WSN architecture, and some of the topics are
not covered at all or covered by only a few representative papers, the description is broad
and only highlights the main topics covered in the section.
Architecture
Section 2
Sensor’s Platform
Network
Power Supply (Battery\EH) 
Section 2.2
Application Oriented
Section 2.1
Topology
Section 2.3
Application Oriented
Section 2.4
Figure 2. Schematic description highlighting the main topics covered in the section.
2.1. Application-Oriented
Many sensor platforms are application-oriented. Occasionally, their suggested ar-
chitecture can be applied to other applications; however, their design and evaluation are
typically aimed at a speciﬁc one. Hence, in many cases, both hardware and software
technological developments are introduced for effective functioning. One of the most
common tasks of WSN is the obvious one of monitoring a terrain. There are many variants
of WSN monitoring. For example, the requirement can be to monitor every point in the
Field of Interest (FoI) vs. monitoring a limited number of speciﬁc locations or targets (aka
target coverage) vs. just monitoring a border of a region to detect intruders (aka barrier
coverage). The coverage problem typically involves selecting a subset of sensors that fulﬁll
Sensors 2022, 22, 2650
6 of 44
the monitoring objective while maintaining network connectivity. The sensors’ capabilities
and the monitoring objective determine the network topology.
We present several recent examples that mainly concentrate on connectivity and data
gathering under the constraints of the monitoring objective. Biswas et al. [25] focus on
energy-efﬁcient data gathering in target coverage problem, in which an n sensor WSN
needs to monitor T speciﬁc targets, and there exists a route (multi-hop) from each source to
the sink. The paper assumes that the source nodes that sense the targets and initiate data
packets into the network are known, and deals with the forwarding of these packets to
the sink. The paper proposes a distributed data gathering algorithm in which after each
node discovers its neighbors and their hop-count to the sink, it will forward data packets
(when required) to its neighbor with maximum remaining energy and a lower hop count
to the sink (the remaining energy is assumed to be known). Ammari [26] focuses on the
k-coverage problem in which each point in the FoI is required to be covered by at least k
sensors at any time, and each active sensor participating in the monitoring task is required
to be connected to the sink (possibly via a multi-hop route). The paper assumes that the
sensors are heterogeneous (they do not have the same characteristics) and mobile, hence
the sensors can move toward any region of interest in the deployment ﬁeld to participate in
any deﬁcient k-coverage area and can also act as mobile proxy sinks that collect sensed data
from the sensors and deliver them to the sink. Ammari [26] partitions the problem into
two problems which are solved sequentially. Namely, the mobile k-coverage problem, which
selects a minimum subset of active sensors that solve the k-coverage problem and the data
gathering problem, and devise a forwarding scheme from the active sensors to the sink such
that the energy consumption due to sensor mobility and communication is minimized.
Mdemaya and Bomgni [27] utilize mobile sensors to achieve area coverage. These
mobile sensors can be moved and relocated to cover holes after the random deployment.
The authors suggest a two-phase approach. According to the ﬁrst one, the monitoring
area after the initial random deployment is identiﬁed (by the BS), and mobile nodes are
relocated to cover the monitoring holes detected after the initial deployment, trying to
ensure full coverage of the AoI by the static and relocated sensors. At the second stage, the
proposed algorithm schedules the sensors’ activity (awakening and transmission times)
that minimizes the energy consumption of the nodes while collecting and sending data
to the base station. To this end, the paper distinguishes between “normal” nodes and
cluster heads. A survey that reviews algorithms and techniques related to the connectivity-
coverage issues in WSN can be found in Boukerche and Sun [28].
Occasionally, WSN architectures and designs are more application-oriented. For
example, Cerchecci et al. [29] propose a sensor node topology that uses low-cost and low-
power components for energy-efﬁcient waste management in the context of smart cities.
The architecture described in [29] suggests a node architecture for measuring the ﬁlling
level of trash bins and utilizes LoRa LPWAN (low-power wide-area network) technology
for real-time data transmission to collect the measured data in a remote data collection
center. The design of a sensor node that can detect the presence of water on home ﬂoors and
provide early warning of water leaks is suggested by Teixidó et al. [30]. The paper presents
and deploys both hardware and software of the network components (ﬂood sensing nodes,
actuator nodes, and a control central); communication within the sensor network relies
on the IEEE 802.15.4 standard. Borrero and Zabalo [31] present a low-cost agriculture-
oriented system. The suggested system is based on LoRa technology and can collect various
measurements, such as humidity, ambient temperature, soil moisture, and temperature,
and enables a farmer to access all of the information necessary to achieve efﬁcient irrigation
management of crops in real time. The developed wireless sensor node has been optimized
both in hardware and software and exhibits very low power consumption.
2.2. Energy-Harvesting (EH)
One of the main concerns of the sensor platform’s design is the source of energy.
Typically, the energy source is a battery attached to the sensor platform. It is utilized to
Sensors 2022, 22, 2650
7 of 44
provide power to all the required operations, e.g., wireless transmission, computation,
memory, etc. The battery properties (e.g., technology used and size) can determine its
lifespan as well as several other properties, e.g., transmission range. In many systems,
the battery is a burden, as it increases the cost of the system, constrains the platform size,
and most importantly, requires to be replaced occasionally. The challenge of saving power
spans all the protocol stack; energy considerations show up in each part of this survey. As
with the other layers, PHY layer innovations have also been suggested as to how to utilize
battery power efﬁciently.
An alternative approach to overcome the battery hurdle is to embed a mechanism
that harvests energy. Such a mechanism can be embedded alongside the battery to ex-
tend its lifespan, or more commonly, it can completely replace the battery so that all the
functions rely on it. Batteryless WSNs that rely solely on energy-harvesting (EH)-WSN
can compromise performance; for example, their transmission range can be shorter, the
available energy can constrain their awake time, and so on. One of the main challenges is to
locate the ambient resource from which the energy can be harvested. Many studies have ex-
plored different energy sources that can supplement energy, such as solar, vibration, wind,
motion, electromagnetic, and more. Numerous comprehensive technological overviews
with their advantages and limitations, energy harvesting modeling, challenge expectations,
and prospects can be found in, for example, Refs. [32–37]. A more recent system design
review on battery-free and energy-aware WSNs, which utilize ambient energy or wireless
energy transmission, is given in [38]. It addresses energy supply strategies and provides
insight into energy management methods and possibilities for energy saving at the node
and network levels.
Khalid et al. [39] suggest a zero-power wireless sensor architecture that consists of
a capacitive sensor (a sensor that associates the parameter of interest with the change in
the capacitance), an RFID chip, a circulator (allows power ﬂow between three deﬁned
ports), and an antenna (batteryless). The conceptual idea is that the sensor reﬂects the
signal received from the RFID, with a change in phase, which is relative to the sensed value.
Design and implementation of an energetically autonomous WSN platform for ambient
monitoring in indoor environments are suggested by Abella et al. [40]. The proposed self-
powered autonomous sensor node platform relies on embedded photo-voltaic (PV) panels
to harvest the energy, a microcontroller and an RF transceiver with an attached antenna.
The suggested architecture was prototyped and validated experimentally. Lee et al. [41]
propose a ﬂoating wireless device with energy harvesting capability. The ﬂoating device is
energetically self-sustaining for extended operational hours. It supports long-range com-
munication between wireless sensor nodes and a gateway relying on the LoRa technology
while deployed over a water surface. The ﬂoating device can be used as an environmental
monitoring station to remotely collect weather and water quality information. Ref. [42]
present the design of a wireless sensor node, powered by solar energy, that collects en-
vironmental data and can transmit it across vast distances (directly to the cloud). The
architecture presented therein relies on low-power wide-area network (LPWAN) protocols
that provide a long-range communication system with limited data to transmit and high
energy efﬁciency. The authors utilize Sigfox technology in their proof-of-concept design.
As previously mentioned in numerous papers, surveys and tutorials exploring dif-
ferent aspects of energy harvesting in WSN exist (a sliver of which we present herein).
We will revisit EH when we discuss various aspects of data aggregation, such as routing
enhancement for EH-WSN (under EH constraints), on which we elaborate in Section 5.2 or
when discussing wearables in Section 6.
2.3. Topology
Throughout the survey, the interaction of WSN and IoT will arise in multiple contexts.
While this survey mainly deals with data gathering by means of wireless units, an IoT unit
presumes a more high-level entity for localized data gathering. To assess the connection
between these two concepts, the reader is advised to refer to the most recent work by
Sensors 2022, 22, 2650
8 of 44
Devadas et al. [43], for example, where the authors enumerate the IoT data management
frameworks, challenges and issues. The chapter focuses on three layers of data management
in IoT networks, communication, storage and processing. In addition, deployment of IoT
Data management for smart home and smart city is described.
It is essential to distinguish between a one-directional WSN platform, where sensors
merely gather the data and activate a speciﬁc infrastructure and set of technologies to further
send it to a sink, and a bi-directional WSN platform, where the sensors are expected to be
able to act according to control messages received from a sink. In the latter case, the sink
might be a higher-level entity (e.g., a cloud-based server). While the general data-gathering
techniques are usually agnostic of the control direction, additional constraints might be
imposed. Delay of the responses, latency, BW usage efﬁciency, security, and privacy are
some of the demands to consider. Another example of a bi-directional platform can be
seen in social sensor clouds (SSC), which connect a social network with a sensor network
via a cloud infrastructure. See, for example, Zhu et al. [44], which presents a scenario of a
smart village and provides discussion on various aspects including green planning, energy
concerns, and speed of data gathering and sharing. In Dinh and Kim [45], an on-demand
WSN platform is designed. The authors suggest a data-gathering protocol that addresses
bandwidth consumption and delivery latency and minimizes the number of requests
to save resources. An infrastructure where sensors form groups belonging to private
owners constitutes a special case. This may be the case in a smart city environment; this
means that privacy and/or security considerations should be prioritized. This is the topic
addressed by Zhu et al. [46]. The authors provide a trust-assisted cloud for WSN but have
throughput issues in mind. Kuo et al. [47] suggest a WSN-based IoT platform that provides
a reliable connection between sensors in the ﬁeld and the database on the Internet. The
proposed platform is based on the IEEE 802.15.4e time-slotted channel-hopping protocol
with resource-constrained devices supporting heterogeneous applications. The paper
suggests a scheme that compensates the clock drift for every timeslot to maintain the clock
synchronization required for the time-slotted channel-hopping protocol.
Edge computing, as discussed by Satyanarayanan [48], allows distributing the data
gathering burden across multiple cloudlets, which might be highly beneﬁcial for large
WSN. This platform paradigm aims to improve many important aspects: reduced latency
of data delivery, increased bandwidth, scalability, resilience to possible cloud outages,
and privacy control. However, the platform presumes an initial capital investment and
later maintenance.
A virtual sensor network was proposed by Abdelwahab et al. [49]. Once a user-
initiated sensing request is dispatched to a cloud, a suitable set of sensors is found for
the task. The decision is made according to the cost function, which depends on the
speciﬁc (e.g., monetary) cost of using sensors from the designated set, the beneﬁt that
can be received from using these sensors, and their effectiveness in distances and delays
(calculated, e.g., in number of hops from sensor to a sink/gateway), also expressed as
virtual links. The cost might be customized, while a general virtualization problem is
formulated and the algorithm is provided.
Integration of unmanned aerial vehicles (UAVs) and WSN for crop monitoring in
precision agriculture is described by Popescu et al. [50]. The authors suggest a down-up
scheme, where the collected data is hierarchically processed from the ground level to the
cluster head (CH) level, then collected by the UAV level and ﬁnally delivered to the cloud
for analysis and possible feedback. Particular emphasis is put on outlying measurements
from speciﬁc sensors, as they can indicate either a possible sensor failure or an upcoming
unusual event inside the agricultural ﬁeld. The measured data were processed through a
consensus algorithm. Concurrently, it suppressed outlier values left for further examination
for the cloud-based analysis. In addition, this study focused on the UAV trajectory planning
to collect the data observed by the WSN. Actual deployment with several tens of sensors
and several CHs is provided and analyzed. Note that we dedicate Section 5.4 to data
gathering assisted by a mobile unit.
Sensors 2022, 22, 2650
9 of 44
An implementation of a ubiquitous consumer data service for transmitting short mes-
sages to any computing platform is provided by Datta et al. [51]. The authors demonstrate
a data cycle model that allows any device with sensor(s) to report data encoded in short
messages. The raw data reaches a central or distributed computing platform, where it
undergoes transformation and evolves into rich and structured valuable information for
higher-layer applications. The proposed data cycle model and DataTweet architecture are
aimed at smart city and large-scale crowd-sensing-based IoT scenarios.
2.4. Application-Oriented Network Architecture
We continue by covering special types of WSN platforms for data gathering and
specialized application-driven architecture types. Ayele et al. [52] suggest an IoT network
architecture for wildlife monitoring systems (WMS) for scenarios in which animals exhibit
sparse mobility, which results in sporadic wireless links. In addition, they suggest a
data forwarding enhancement that adopts the ﬂood-store-carry-and-forward paradigm
suggested in the seminal ZebraNet study by Juang et al. [53], in which in order to send data
to the sink, the nodes disseminate it among themselves until it reaches the sink. Speciﬁcally,
each node stores the data needing to be conveyed, waits for connectivity with other nodes,
and distributes the data to them, and they repeat the same process. Accordingly, the data is
spread throughout the entire network (i.e., ﬂooding) and will eventually be received by the
sink. The authors in [52] suggest leveraging locally available routing parameters to improve
opportunistic data forwarding algorithms by managing the data replication decision.
Saleh et al. [54] suggest extending the lifetime of a wireless sensor network used in
mobile healthcare applications by increasing the number of bits transmitted per symbol, and
speciﬁcally to rely on a quaternary interconnect scheme in which each transmitted symbol
modulates two bits. A complementary neural network, static RAM-based architecture is
suggested to reduce energy consumption in storage and transmissions during the data
dissemination process. A WSN dedicated to home deployment for elderly healthcare and
early health emergency alarm is discussed by Alsina-Pagès et al. [55]. The authors ﬁrst raise
privacy concerns related to the monitoring, and accordingly, advocate that only sound-
based surveillance aimed to merely indicate alarming situations is appropriate. In order
to further conform to the privacy demands, they focus on distributed architecture (rather
than on a centralized one), where each of the WSN sensors sends encrypted identiﬁers of
their measurement. The identiﬁcation of events is built on feature extraction. This is done
on the frequency domain by ﬁrst dividing the incoming signal into blocks with Hamming
sliding window, then transforming into the frequency domain using Discrete Fourier
Transform (DFT) to evaluate the contribution of every band of the spectrum. The ﬁnal
coefﬁcients are obtained after Discrete Cosine Transform (DCT). The conclusive parts of the
proposed algorithm classify the coefﬁcients, feeding them into Support Vector Machines
which classiﬁes the estimated audio event. The authors assert that the classiﬁcation results
could be further improved by incorporating a deep artiﬁcial neural network (ANN) into
their system.
In AbeBer et al. [56], a similar method was implemented for urban noise monitoring.
Namely, while STFT was utilized for the noise preprocessing, the classiﬁcation of noise
levels and events was performed by convolutional neural networks (CNNs). The authors
used several previously published networks; see references therein. Similar methods for
noise monitoring WSN were introduced by Siamwala et al. [57]. The frequency-domain
analysis was performed. Then, classiﬁcation by statistical methods was accomplished
(Gaussian mixture model was used). In addition, the authors in [57] provide an elaborate
WSN architecture, where energy-harvesting solar panels augment the sensors’ lifetime and
the sensors’ state-of-charge is transmitted and tracked by central, more powerful nodes.
3. Compressed Sensing
Many data-gathering applications rely on numerous self-powered smart devices to
collect real-time data and convey it via a wireless medium to a central entity or entities
Sensors 2022, 22, 2650
10 of 44
(e.g., the cloud) to further process it and act upon it. Such devices are expected to perform
two basic operations—sensing and wireless connectivity. Two important hindering aspects
that derive from these operations inﬂuence the performance and need to be considered
are: (i) energy consumption associated with these two operations, especially when many of
these devices are typically simple with limited computation abilities and battery lifetime
(ii) airtime utilization, which can also degrade the performance causing high delays, jitter,
battery consumption, etc. Accordingly, one of the main challenges in combating these
limitations is reducing the report payload, which affects each report’s transmission time
and channel utilization. Reducing the payload of the sensed data can be accomplished at
different levels; it can be done in the sensing stage by reducing the size of the sensed data, as
well as in the report preparing stage by compressing the report size, and in the transmission
stage, by selecting which devices need to send reports, thus limiting redundant information.
When the reports need to travel multiple hops before reaching their destination, this can
be done at the relay stage by pruning, unifying, and compressing reports. In the sequel,
we discuss Compressed Sensing (CS). This novel paradigm can reduce report payload at
several levels mentioned above, hence lowering the sensing operation’s transmission time
and energy consumption.
Compressed sensing is a signal-processing technique that is most advantageous when
the subject signal is sparse in some domain, such that a minimal non-zero vector of coefﬁ-
cients can represent it. The signal sparsity enables a high-quality reconstruction, which is
attained by ﬁnding the solution to an under-determined linear system of equations with
the smallest possible number of non-zero values. Thus, a convex minimization problem
needs to be solved to perform the recovery. Note that the CS technique performs non-
uniform sampling of the data signal with an average sample rate usually smaller than
the minimal rate mandated by the Nyquist–Shannon sampling theorem. A detailed view
of the technique can be found in Balouchestani et al. [58] and Donoho [59]. Various net-
working domains can utilize compressed sensing, for example, Feizi et al. [60] depict some
applications of CS over networks and elucidate the connection between CS and traditional
information-theoretic techniques in source coding and channel coding. Particularly, CS is
highly suitable for sensed data gathering in wireless sensor networks (e.g., physical phe-
nomena or a scenery), as it can leverage the expected high spatial and temporal correlation
between sensing reports sent by neighboring sensors at different times in order to acquire
the CS paradigm’s desired sparsity. In the following, we review several such data-gathering
schemes that utilize CS.
Luo et al. [61,62] consider a densely deployed monitoring sensor network in which
reports traverse multiple hops before reaching their destination, a sink. These studies
rely on the concept that sensors’ readings are spatially correlated; hence, there exists a
transform domain in which the sensed signals can be sparsely represented. Both propose
a compressive data-gathering (CDG) procedure in which sensors distributively encode
their reports by projecting them on a random space basis using random coefﬁcients. These
encoded reports can be decoded at the sink using compressive sensing techniques. Specif-
ically, CDG is designed for multi-hop networks where messages need to travel multiple
hops before reaching their destination. The sampling process that characterizes the CS
compression process is performed individually at each sensor by simple multiplications
and additions. Particularly, CDG suggests that rather than forwarding individual sensor
readings, each sensor uses each of its reports (measurements) to construct and send M
different messages, each comprising a weighted sum of the sensor’s own report with other
sensors’ reports traversing it (relaying). Formally, denote by vector d = [d1, d2, . . . , dN]T
the measurements (readings) obtained by all the sensors, where N is the number of nodes in
the WSN and di denotes the measurement (reading) obtained by sensor si. The sink obtains
M messages (weighted sums) represented by the vector y = Φd = φ1d1, φ2d2, . . . , φNdN,
where Φ is an M × N (M << N) matrix comprising the series of coefﬁcients generated
by the sensors, and in particular, φi is the i-th column vector of Φ, which denotes the
random coefﬁcients selected by sensor i. Luo et al. [61] suggest that the measurement
Sensors 2022, 22, 2650
11 of 44
matrix (coefﬁcients matrix) Φ should be a full random matrix with its entries being i.i.d.
Gaussian random numbers drawn according to N (0, 1
M). The paper suggests that each
weighted sum coefﬁcient be chosen pseudo-randomly based on each sensor’s ID in order
to avoid the burden and high overhead required to collect these coefﬁcients by the sink
if they are chosen randomly. Ref. [62] extends the random coefﬁcient selection suggested
in [61] to an only partly random matrix in which the entries of a sub-matrix are still drawn
according to N (0, 1
M). Yet, for the rest of the matrix, two options are suggested, either an
upper triangular matrix with non-zero entries drawn according to N (0, 1
M), or the identity
matrix. CDG exploits the compressive sampling theory and shows that when the sensor
readings are compressible, the sink will be able to accurately recover the reports even when
the number of weighted sums (messages) each sensor generates for each report (M) is
much lower than the number of reporting sensors (N). For example, on a route comprising
N sensors, the sink needs to collect only M << N messages to encode the information sent
by all the N sensors.
Several studies further explore the sparsity of the sensed signal and its projection
matrix, as well as the number of messages (M) that should be delivered to the sink. For
example, Wang et al. [63] argue that most natural signals are nonstationary and ordinarily
variable in the temporal and spatial domains. In CS, these directly inﬂuence the recon-
struction process and the number of required measurements; consequently, setting a ﬁxed
number of measurements with a ﬁxed transform basis (coefﬁcient matrix Φ) can result
in poor performance (inaccurate measurement reconstruction). Accordingly, Ref. [63]
suggests an adaptive data-gathering scheme based on CS, which utilizes an autoregressive
(AR) model to exploit the local spatial correlation between sensed data of neighboring
sensor nodes. The suggested reconstruction scheme adapts to the variation of sensed data
by adjusting the AR parameters. The number of measurements is adjusted adaptively
with the sensed data by evaluating the recovery result and approximating the number of
measurements required to satisfy the accuracy demand.
To reduce the transmission overhead, Xu et al. [64] propose the compressed sparse
function (CSF) scheme. The basic concept of CSF is, rather than encode the sensed data
by projecting it on a basis on which it can be represented sparsely, as in typical CS-based
schemes, to compress the sensed data in the form of sparse functions, which are sent to the
source. The source can recover the function using techniques from polynomial approxi-
mation/interpolation theory and use them to compute data values that were not reported.
Speciﬁcally, CSF ﬁnds a function that maps the sensors’ identiﬁers and their readings, which
can be expressed in a very sparse way, and only communicates this function to the sink.
After the sink recovers the function, it can recover all the N sensor readings. Xu et al. [64]
show that the CSF approach can provide good recovery accuracy (better than the CDG
scheme suggested by [61]) while substantially reducing the message overhead (mainly in
tree-structured networks). Li et al. [65] present a general CS framework for WSNs and IoT
and show how the proposed framework can be utilized to reconstruct the compressible
information. The suggested framework comprises three phases: (i) information sensing
to detect and compressively sample event signals; (ii) compressed sampling, in which the
system samples information traversing the networks; and (iii) reconstruction algorithms, in
which the system accurately reconstructs the original signal from the compressed samples.
Different studies tackle the sampling issue and suggest different approaches to reduce
the number of reports sent such that only a subset of the sensors sense the object or
phenomenon at a time. Several studies explore how sensed data is conveyed to the sink
with the insight that the compression is at least attained along the path to the sink, and is
therefore affected by it. For example, Dhanapala et al. [66] show that a random-walk-based
sampling, rather than the conventional uniform-sampling-based CS for function recovery,
can be used for phenomena awareness either at a sink or at other sensors without a sink,
with minimal additional sampling. As the distribution of the samples has a signiﬁcant effect
on the recovery, Ref. [66] suggests an upper bound for the probability of successful recovery
with a given error percentage. The derived bound provides an approximate number of
Sensors 2022, 22, 2650
12 of 44
samples required to recover a function under a selected basis and a sampling scheme.
Zheng et al. [67] further argue that random walk provides a more practical approach for
the data-gathering application in WSNs and explores the sparsity of collecting non-uniform
measurements while sampling along multiple random paths. The paper suggests that
the M × N measurement matrix will be characterized by M independent random walks.
Speciﬁcally, each of the M matrix rows corresponds to the set of vertices visited by the
respective random walk. The paper analyzes the required number of random walks (M)
and their corresponding lengths (how many entries on each row are non-zero) under the
proposed random walk algorithm.
Zheng et al. [68] suggest a cluster-based data-gathering mechanism, in which the
terrain is divided into cells; in each cell, a node is randomly selected as the cell head,
which collects the data from the cell members and forwards it to the sink. Zheng et al. [68]
suggest two forwarding mechanisms, one relying on centrally deﬁned tree-based for-
warding, and another that is a gossip-based approach. The projection process is similar
to Luo et al. [61,62], being based on random coefﬁcients. Another clustering-based hi-
erarchical data aggregation protocol that relies on CS, termed HDACS, is suggested by
Xu et al. [69]. Speciﬁcally, HDACS constructs a multilevel hierarchical structure and adap-
tively sets multiple compression thresholds based on cluster sizes at different levels of the
data aggregation tree to optimize the amount of transmitted data. The encoding procedure
is adapted from [62], where each cluster-head recovers (decodes) all received messages
from its descendants (retrieves the original data) before compressing and sending it to its
parent cluster-head.
Motivated by reducing power consumption, Lan and Wei [70] also suggest a
compressibility-based clustering algorithm for hierarchical compressive data gathering. In
this study, the network is decomposed into a logical chain, and sensor nodes are grouped
based on the compressibility of their readings instead of by a random clustering approach.
This clustering approach strives to minimize the average compression ratio of all clusters by
greedily selecting the set of nodes based on the compression ratio. It then tries to maximize
the number of compressible clusters so as to determine the suitable transmission mode
for each cluster using a mode threshold that is a function of the number of nodes and the
number of hops from a cluster-head to a sink.
To reduce the number of sensors involved in each CS measurement, Wu et al. [71]
propose a sparsest random scheduling scheme for compressive data gathering in large-
scale wireless sensor networks (WSNs), leveraging the spatial-temporal properties in the
sensory data. The central theme of this study is that the measurement matrix is designed
based on the representation basis and sensory data and according to the sensor network
requirements rather than the network environment. By combining compressed sensing
and network coding in the data-gathering scheme, Yin et al. [72] introduce a multi-hop
topology in which the sink node adaptively adjusts the measurement formation according
to the reconstruction of received measurements at each data-gathering epoch. The sink
node dictates the data aggregation performed to balance the energy consumption among
sensor nodes.
Xu et al. [73] exploit the CS paradigm for network tomography. Speciﬁcally, Ref. [73]
leverages the fact that, typically, only a small fraction of network entities such as links or
nodes are responsible for anomalies or degradation in network performance, as a limited
number of congested links can be responsible for signiﬁcant delays or high packet drop
rates, and suggests utilizing CS theory in order to identify these few entities based on end-
to-end measurements. Zheng et al. [74] provide an analysis of the capacity and delay of
data gathering with compressive sensing in wireless sensor networks. The paper considers
a random topology where sensor nodes are randomly deployed in a region, for both
single-sink and multi-sink scenarios, and characterizes the capacity and delay performance
improvement that the CS paradigm can achieve for data gathering. In particular, for
the single sink, a simple routing scheme for data gathering with CS is suggested, and
a tight capacity in the order sense is presented. In particular, the suggested routing
Sensors 2022, 22, 2650
13 of 44
scheme with pipelining scheduling algorithm for data gathering shows that the proposed
single-sink scheme can achieve a capacity gain of Θ( n
M) over the baseline transmission
scheme, and the delay can be reduced by a factor of Θ(
√
nlogn
M
), where M is the number
of random projections required for reconstructing a snapshot, and n is the number of
randomly deployed nodes. For the multi-sink case, their architecture shows that the per-
session capacity of data gathering with CS is Θ(
n√nW
Mnd
√
nslogn), and the per-session delay is
Θ(M
q
n
logn), where W is the data rate. The number of sinks present in the network is nd,
and the number of randomly selected source nodes is ns. They validate the theoretical
results with simulations for the scaling laws of the capacity in both single-sink and multi-
sink networks.
4. Medium Access Control (MAC)
Next, we move to the Data-Link layer and speciﬁcally to the medium access control
(MAC) mechanism, which highly affects the performance of data gathering protocols, as
it inﬂuences several performance aspects, such as reliability, latency, channel utilization,
power utilization (which impact the lifespan of a sensor in particular and the network in
general), etc. Even though many access protocols were suggested over the years for shared-
channel networks, wired and wireless, due to their unique properties and requirements,
extensive research has been conducted on MAC protocols targeted to WSN. Many WSN
MAC protocols were designed to comply with various trafﬁc patterns. Accordingly, in the
sequel, we provide a short WSN-MAC protocol overview for ones that can support yet
are not necessarily particular to data-gathering. We review a fraction of the vast literature
on the topic and the numerous MAC protocols devised over the years. Figure 3 depicts a
schematic partition of the papers discussed throughout this section according to the main
MAC classes.
MAC
Section 4
Synchronous 
Transmitter-Initiated 
Receiver-Initiated 
Asynchronous 
Others
Section 4.2
Duty-Cycle
Section 4.1
Figure 3. Schematic description highlighting the main MAC classes covered in the section.
Energy consumption is one of the main concerns of WSN, and as previously explained,
it needs to be considered in the design of protocols and algorithms in all the layers of the
protocol stack. The highest energy consumer of a sensor or an IoT device is its transceiver,
which consumes energy regardless of whether it is transmitting or only awake listening to
ongoing trafﬁc (e.g., [75]). One of the more prevalent solutions to save power is to embrace
a duty-cycle mechanism in which the device is asleep most of the time (its transceiver is in
low power mode), and is awake for transmitting or receiving data only a small fraction
of the time. Another important aspect of wireless sensor networks (WSN) is channel
utilization, that is, in a typical WSN, when multiple devices are trying to send reports
simultaneously, air time is a crucial network resource. Particularly when the network is
Sensors 2022, 22, 2650
14 of 44
dense with multiple devices in the same neighborhood, issues such as coordinating between
the users to avoid collisions and preventing users from occupying the channel for long
time intervals are fundamental. Note that such issues can highly affect the performance in
a dense network topology even when reports are not frequent. Accordingly, utilizing the
channel (air time) efﬁciently is a crucial component for any such system’s operation and
performance. These two highly vital aspects justify the signiﬁcance given to the design of
medium access control (MAC) protocols that are particular to WSNs. Numerous protocols
have been suggested to cope with different WSN objectives and demands (e.g., [76,77]).
This paper focuses on MAC protocols for WSNs, particularly on duty-cycled-based ones.
4.1. Duty-Cycle MAC Protocols
Traditionally, duty-cycle MAC protocols can be classiﬁed as either synchronous or
asynchronous. In synchronous protocols the awake time interval is synchronized such that
all devices are awake (or asleep) at the same time intervals (e.g., S-MAC [78], T-MAC [79]).
Since the awake time intervals are quite limited, they can be highly congested and prone
to collisions. Several synchronous protocols have devised mechanisms to attenuate this
congestion and to allow more devices to transmit in each cycle, for example, DW-MAC [80],
which allocates the awake time for transmission reservations that will be executed during
the sleep interval.
In asynchronous protocols, each device has its own wake-up schedule. Accordingly,
the main challenge is setting a rendezvous time when both the sender and the receiver are
awake and devising a signaling mechanism that informs both that they are awake and can
communicate. Asynchronous MAC protocols can further be divided into two categories,
transmitter- or receiver-initiated. In transmitter-initiated protocols, the transmitter initiates
the transmission by capturing the channel waiting for its designated receiver to wake
up. For instance, in B-MAC [81], the transmitter transmits a long preamble capturing the
channel prior to the data transmission, waiting for its intended receiver to wake up and
reply. In X-MAC [82], the transmitter transmits a sequence of short preambles allowing
the intended receiver to interrupt, notifying the receiver that it is awake. In WiseMAC [83],
the transmitter learns the wake-up time of its intended receiver and starts the preamble
transmission just prior to this wake-up time.
The second approach, the receiver-initiated paradigm, relies on the receiver, whenever
awake and ready to receive data, to initiate the data exchange. The basic receiver-initiated
MAC concept was introduced in RI-MAC [84], in which whenever the receiver wakes up,
it transmits a predeﬁned preamble, signaling to its potential transmitters that it is awake
and ready to receive data. Several protocols took up the RI-MAC paradigm and suggested
modiﬁcations and enhancements. Some protocols strived to reduce the energy consumed
while a sender stays awake, waiting for its intended receiver to wake up. For instance,
PW-MAC [85] and AP-MAC [86] suggested that each transmitter will learn its receiver’s
expected wake-up time, and instead of staying awake waiting for its designated receiver to
wake up, will wake up just before its intended receiver’s wake-up instance.
Another receiver-initiated enhancement is suggested by A-MAC [87], which aims to
reduce the time in which a receiver and, consequently, its potential transmitters stay awake,
by trying to determine whether there are pending packets for transmission and if it needs
to stay awake or if it can go back to sleep after probing the channel. The enhancement
relies on an additional frame, termed “auto-ack”, sent by pending transmitters, which
follows the receiver’s probe packet and proceeds with the data transmission. The “auto-ack”
frame is such that the receiver can decode a superposition of several such frames and
determine whether there is trafﬁc being sent. Even though the energy saved per cycle is
negligible, the cumulative savings per day can be signiﬁcant due to the numerous times
a device wakes up probing the channel. RIVER-MAC [88] suggests two enhancements,
one aiming at reducing the awake time a sender is waiting for its intended receiver to
wake up, and one that aims at improving the RI-MAC collision resolution mechanism by
letting an active receiver keep controlling the channel after invoking the collision resolution
Sensors 2022, 22, 2650
15 of 44
mechanism, and speciﬁcally during the silent backoff interval. MAR-RiMAC [89] suggested
an amendment to the receiver-initiated approach, and in particular RI-MAC, to cope with
the perpetual collisions, common in dense networks and heavy trafﬁc loads, in which
many devices are trying to transmit to the same entity (sink or relay). MAR-RiMAC relies
on a reservation-based mechanism in which the reservations are short signals that can
be transmitted simultaneously. After the designated receiver decodes the identity of the
devices, it sends a transmission request and polls them sequentially, with no idle intervals.
As mentioned in Section 2, relying on EH requires adaptations that typically relate
to the harvested energy source. For example, how to balance the harvested energy and
the energy consumption can be a crucial factor in whether or not a scheme or protocol
can be adopted by a network that relies on EH, and can be the primary factor impacting
their performance. Adaptation requirements to support EH-based sensors span the whole
network stack, including the MAC sublayer. Adaptation of receiver-initiated duty-cycle
MAC protocol for energy-harvesting-powered wireless sensor networks, in which besides
the usual MAC challenges, both transmitter and receiver need to have sufﬁcient power for
successful transmission, is given by Liu et al. [90].
4.2. MAC Protocols for Other Setups
Next, we review some MAC protocols and MAC adaptations for various setups,
such as multi-channel, multi-radio, busy-tone utilization, or different from the duty-cycle
approach. DURI-MAC [91] adopts the traditional busy-tone scheme and allocates a sub-
channel for control such that while receiving data on the data channel, a busy signal
is transmitted on the control channel, which notiﬁes neighboring nodes of the ongoing
transmission, and therefore helps avoid interference from hidden terminals. EM-MAC [92]
utilizes multiple orthogonal radio channels and allows devices to dynamically select the
channels for their transmissions based on the channel conditions they sense without the
utilization of a control channel. Accordingly, EM-MAC can avoid using channels that are
currently heavily loaded, inferior due to interference, or jammed. Typically, the trafﬁc
load sent by a node is spatially and temporally variable. Different nodes need to send
different trafﬁc loads due to their tasks, topological location, and the amount of trafﬁc they
need to relay. Furthermore, the same node can experience different loads at different time
intervals due to events or requests triggering different trafﬁc loads. Accordingly, several
studies have explored an adaptive duty-cycle approach. For example, Ye and Zhang [93]
have developed a reinforcement-learning-based self-adaptive sleep/wake-up scheduling
approach. In the proposed method, each node (device) divides the time into time-slots,
which are not necessarily synchronized between neighboring nodes. Each node decides
whether to sleep or wake up in each time slot, and while awake, it decides whether to listen
or transmit. The decision is based on its current situation and its estimation of its neighbors’
situations and is attained via Q-learning.
Gamm et al. [94] devise an alternative approach to duty-cycle, which utilizes two
radios: the primary radio transceiver and an additional wake-up radio (WuR). The wake-up
radio is a low-power receiver triggered by an external event and can turn on the main
transceiver when required. Oller et al. [95] provide a detailed characterization of a speciﬁc
WuR, the SubCarrier Modulation WuR (SCM-WuR), through physical experiments and
measurements, evaluating it for different performance metrics and comparing it to other
wake-up radio-based systems. The authors of [95] model and simulate their own designed
WuR hardware platform, which is compared to four widely employed MAC protocols for
WSN under three real-world network deployments [96]. Spenza et al. [97] further design
and prototype a very-low-power-consumption (<1.3 µW), high-sensitivity (up to −55 dBm),
fast-reactivity (wake-up time of 130 µs), and selective-addressing wake-up receiver (WRx)
and describe its integration to a wireless sensor node. The authors leverage their WRx and
present ALBA-WUR, a cross-layer solution for data gathering in wireless sensing systems.
Similar to duty-cycled MAC protocols, wake-up radio-based protocols also distinguish
between transmitter-initiated WuR (TI-WuR) protocols in which the transmitter wakes up
Sensors 2022, 22, 2650
16 of 44
its potential receivers (e.g., [98,99]) vs. receiver-initiated WuR (RI-WuR) that adopt the
RI-MAC paradigm such that when a receiving node is ready to collect data, it wakes up all
the nodes in its neighborhood by broadcasting a wake-up call (e.g., [100,101]).
An energy-harvesting-based MAC protocol for cognitive radio networks (CRNs) is
suggested by Hawa et al. [102], in which the secondary users (SUs) utilize the transmis-
sions by primary users (PUs) to harvest energy. Accordingly, the suggested protocol
interlaces SUs’ data transmissions within these PUs’ transmission holes. The proposed
energy-harvesting/data-transmission schedule considers the imbalance between the small
amount of energy collected per PU’s transmission and the energy required by an SU
data transmission.
Next, we mention several WSN MAC protocols that were specially designed for
particular data-gathering setups in WSN and IoT networks, exploiting the special associ-
ated attributes (e.g., that the trafﬁc patterns are always from sensors to the sink, or that
there exists a set of predeﬁned messages that need to be sent). Cohen et al. [103] design
and analyze a data collection protocol based on information theoretic principles. In the
suggested protocol, each sensor needs to convey one out of a bank of known messages
to a sink. The protocol assumes a large population of sensors and devises a scheme in
which a sink (or relay) can simultaneously collect messages from up to K sensors, without
knowing in advance which sensors will transmit, and without requiring any synchroniza-
tion, coordination, or management overhead. D-3 [104] exploits the fact that the trafﬁc in
data-gathering applications ﬂows in a certain direction (toward a single or multiple sinks)
to devise a wake-up that can signiﬁcantly reduce end-to-end delay. Speciﬁcally, D-3 lays
out the awake schedule of communicating nodes such that a packet can be forwarded
toward its destination sequentially, without the need for a node to wait for its next-hop
relay to wake up (i.e., the wake-up schedule is such that a relay wakes up in time to receive
a packet just received by its predecessor).
5. Routing for Data Gathering in WSN
We keep climbing the layers, and in this section we address issues related to the
Network layer. We start with a short review of WSN routing protocols. We note that
routing-related aspects were also referred to in other sections of this survey. We mainly
focus on the prominent and more recent protocols. We do not provide a comprehensive
review of routing protocols in multihop WSNs and mainly explore routing protocols
suitable for data gathering. Figure 4 provides a schematic distribution of the discussed
papers into main topics. As with the schematic partition in the other sections, in order
not to have too many, the topics are chosen such that the theme on each one encompasses
several papers. The papers’ partition is rough: some papers can appear in more than one
topic while others are only related to the topic.
We start with general WSN settings and then continue with routing protocols under
energy harvesting constraints. Then we explore the utilization of network coding for data
gathering, which leverages the multi-hop routing, allowing relays (intermediate nodes)
to code the incoming packets before forwarding them toward the sink. We conclude this
section by examining a different paradigm. Rather than utilizing the traditional approach of
forwarding the sensed data via multiple relay nodes before reaching the sink, this paradigm
relies on a Mobile Sink (MS) that traverses the network and collects the sensed data from
the sensors it passes through.
5.1. Common WSN Routing Protocols for Data Gathering
The common setup for a data collection network comprises a set of devices (e.g.,
sensors) and one or multiple sinks that collect the reports. In many such scenarios, the
sensors are unevenly dispersed over the terrain and in some cases can be mobile, can have
a different distance to the sink(s), and the data needs to traverse multiple hops before
reaching the sink, in which commonly the sensors themselves serve as relays toward
the sink. Consequently, the performance experienced by different sensors (e.g., energy
Sensors 2022, 22, 2650
17 of 44
consumption, latency, reliability) can be markedly diverse. Various solutions, including
energy-aware routing, compressed sensing, efﬁcient MAC novelties and architectural
innovations, have been suggested to try to improve the overall performance and to balance
its variability; many are scattered throughout this survey under different subjects (e.g.,
Sections 3, 4 and 6). In the sequel, we provide a brief review of routing protocols for WSN
in general and data gathering in particular.
Routing
Section 5
Cluster-Based 
Section 5.1.1
Energy Harvesting 
Based
Section 5.2
WSN Routing
Section 5.1
Network coding
Section 5.3
UAV Utilization
(Mobile Sink) 
Section 5.4
RPL 
Section 5.1.3 
Opportunistic 
Section 5.1.2
Cluster-Based 
Section 5.2.1 
Mobile Charger 
Section 5.2.2 
Cluster-Based 
Section 5.4.2
Direct 
Section 5.4.1 
Figure 4. Schematic partition of the papers discussed in this section into the main routing topics
covered in the section.
5.1.1. Cluster-Based Routing Protocols
A signiﬁcant milestone in WSN routing protocols is the low-energy adaptive clustering
hierarchy (LEACH) protocol [105]. The basic LEACH protocol is an adaptive clustering-
based protocol that dynamically selects sensor nodes as cluster-heads. Each cluster-head
aggregates data from its cluster members and relays it to the sink. In order to distribute
the high energy consumption imposed on cluster-heads between all the sensor nodes,
the cluster-heads are dynamically selected according to a predeﬁned probability that
depends on the number of desired clusters. The resulting protocol causes continuous
clustering hierarchy reelection, which facilitates energy balancing. The original version
presented by Heinzelman et al. [105] considers a setup in which all sensor nodes can
directly communicate with the sink; hence, each cluster-head can directly relay the collected
information from its cluster members to the sink. However, as described in the paper,
LEACH can be easily extended to a hierarchical cluster setup in which the cluster-head
nodes of each tier are also organized in clusters such that each cluster-head relays its
aggregated data to its higher-layer cluster-head, and so on up to the top layer of the
hierarchy, at which point the data are sent to the sink.
Since its publication in 2000, numerous protocols have relied on LEACH’s clustering
paradigm, suggesting enhancements and improvements for various setups and require-
ments. For instance, EE-LEACH [106,107] aims at improving the energy efﬁciency of
LEACH by considering the sensor’s residual energy throughout the stages of the proto-
col. Speciﬁcally, EE-LEACH assumes that node deployment is implemented according
to a two-dimensional Gaussian distribution. It forms clusters and selects their respective
cluster-heads based on the residual energy of neighboring nodes. The relay nodes that
forward the data aggregated by cluster-heads to the sink are selected based on their residual
energy. A clustering procedure based on recursive rectangular partitioning of the network
grid following the k-d tree algorithm is demonstrated by Anzola et al. [108]. The authors
adjust a protocol that combines their clustering methods and report that it performs better
than LEACH. Several surveys have summarized the successors of the LEACH protocol
(e.g., [107]).
Sensors 2022, 22, 2650
18 of 44
PEGASIS [109] was designed to address the overhead resulting from the cluster
formation in LEACH. Speciﬁcally, PEGASIS replaces the clusters with a node-chain in which
each node receives the data from its predecessor and transmits it to its successor in the chain.
The data is gathered while getting fused along the chain until eventually, a designated
node transmits it to the sink. PEGASIS relies on nodes having global knowledge of the
network and shows that a simple greedy algorithm for the forwarding chain construction,
in which nodes select their closest neighbors as the next hops in the chain, is sufﬁcient to
signiﬁcantly reduce energy consumption. Similar to LEACH, and in order to balance the
energy depletion in the network, different nodes transmit the fused data to the sink on
each data-gathering round. P-LEACH [110] offers a hybrid between LEACH and PEGASIS
that relies on cluster formation where cluster-heads collect and forward trafﬁc. Rather
than forward the trafﬁc directly to the sink, or create a hierarchical cluster setup in which
cluster-heads are also grouped into clusters with another cluster-head, P-LEACH adopts
chain-based forwarding such that the cluster-heads are arranged in a chain along which
the collected data is forwarded, as suggested by PEGASIS.
Several LEACH enhancements have relied on bio-inspired algorithms. For example,
Siew et al. [111] utilize adaptive particle swarm optimization (APSO). This widely used
swarm intelligence method mimics swarming behavior in bird ﬂocking and ﬁsh schooling
to guide its members to search for globally optimal solutions for cluster-head location
selection. Tam et al. [112] extend LEACH to a 3D setting by employing a method based on
fuzzy clustering and particle swarm optimization (PSO). Cui et al. [113] suggest a variant
of the bat algorithm, which simulates bat prey echolocation behavior, to optimize the
cluster-head selection for LEACH protocol. A routing path selection using an ant colony
optimization algorithm is presented by Jiang and Zheng [114]. Clustering by mimicking
groups of yellow goatﬁsh is discussed by Rodríguez et al. [115]. The authors claim that
the presented meta-heuristic is more efﬁcient in avoiding local minima. An extension of
LEACH for an IoT-designated industrial environment is presented by Karunanithy and
Velusamy [116]. This work provides uniform CH selection, uniform CH dispersion over
the industrial grid of IoT-based sensors, and tree-based routing selection that promises to
be more energy efﬁcient than known counterparts. The energy exploitation is claimed to be
equal among nodes.
Mehmood et al. [117] devise a dynamic-size cluster-based routing protocol for WSN
comprising a large number of sensors that are spread over a large area (the paper suggests
pollution monitoring as a candidate application). The primary objective of the presented
scheme is to effectively select CHs to be responsible for the main communication with BS
and additionally deﬁned chief nodes (CNs). Speciﬁcally, the sensor topology is divided
into groups, where CNs collect the updated energy indications of other sensors within a
group. There are also border nodes responsible for communication between groups. If
their energy value drops below a threshold, the CNs can be reelected. The candidates for
CNs and CHs are provided by an artiﬁcial neural network (ANN), which takes as inputs
remaining energy, neighboring node count, the amount of outstanding data, signal-to-
noise ratio (SNR), distances between nodes, CHs, CNs and the BS, trafﬁc load, and so
on. The simulations show a better lifetime than other selected known protocols; hence,
the scheme is a better ﬁt for pollution monitoring. Clustering and routing for a wind
turbine system monitored by WSN are introduced by Durairaj and Selvaraj [118]. The
discussed environment is unique because sensors placed at wind turbines can have their
energy replenished by the turbine itself; hence, these sensors are always assumed to be
charged. However, the distances between turbines and the BS are too large, and the
grid is augmented by ground sensors that relay the measurements. In many cases, these
ground sensors have to act as CHs. The authors propose system partitioning and clustering
methods that may be hierarchical to speciﬁcally address this scenario. An interesting
algorithm that also employs partitioning, by hierarchical grouping of sensors based on
early knowledge of geographical transmission patterns in mobile WSN, is presented by
Shifrin and Cidon [119].
Sensors 2022, 22, 2650
19 of 44
5.1.2. Opportunistic Routing
The opportunistic routing approach, which was designed for wireless networks, dy-
namically chooses paths toward the destination on a per-transmission basis, Biswas and
Morris [120], Ye and Hua [121]. Opportunistic routing exploits the broadcast nature of
wireless communication jointly with the spatial diversity of distributed nodes in a given
route such that multiple nodes overhear each packet transmitted by a node. The node that
receives the packet successfully and can serve as the best relay toward the destination (e.g.,
closest to the destination) becomes the next transmitting node. Harnessing opportunistic
routing to duty-cycle MAC protocols encounters several obstacles. In synchronous duty-
cycle MAC protocols (Section 4), the short time duration in which all nodes are awake (and
speciﬁcally, all the potential relays are awake and trying to forward the same packet) can
lead to artiﬁcial congestion and poor wake-time utilization. In asynchronous duty-cycle
MAC protocols, since not all nodes are awake simultaneously, the use of overhearing, which
opportunistic routing relies on, is limited and requires adaptations such that the transmitter
will transmit to multiple relays upon its wake-up (e.g., [122]) or delay its transmission,
choosing its relay opportunistically based on channel condition (e.g., [123]).
In a dense WSN, even under asynchronous duty-cycle MAC protocol, several potential
relays can be awake simultaneously, which poses additional challenges when utilizing
opportunistic routing. In addition to the relay selection problem—whether a transmitter
should wait for the best relay to wake up or compromise on a less preferable relay, reducing
its awake period and how long it should wait—it also encounters the collision avoidance
problem between simultaneously awake nodes. Liu et al. [124] suggest a slotted contention-
based scheme in which, following a probe sent by the transmitter, the awakened potential
relays contend and transmit feedback concerning the routing progress they can offer. The
transmitter selects the best possible relay out of the ones that replied, taking into account
not only the metric chosen to evaluate the different relays, but also the waiting time of
the link-layer transmissions. Under a similar set-up of dense asynchronous duty-cycle
MAC protocol with multiple potential relays awake simultaneously, Hawbani et al. [125]
try to control the number of potential forwarders, which inﬂuences both the transmitter
waiting time and the number of packet duplications. The suggested solution relies on
a two-step mechanism. First, each transmitter determines a candidate zone such that all
nodes within the candidate zone are potential forwarders. Second, the candidates within
the candidate zone are prioritized based on a combination of metrics that considers residual
energy, transmitting direction, distance, and link quality.
5.1.3. Routing Protocol for Low-Power and Lossy Networks (RPL)
A routing protocol for low-power and lossy networks (RPL) is a routing protocol
that was speciﬁcally designed for networks composed of constrained nodes, which are
interconnected via unstable and lossy links with relatively low packet delivery rates and
typically only support low data rates (hence, low-power and lossy networks (LLNs)).
Speciﬁcally, RPL is a distance-vector proactive routing protocol designed for IPv6 low-
power devices with limited energy, processing, and memory resources (Winter et al. [126]).
RPL constructs a tree routing topology termed the destination-oriented directed acyclic
graph (DODAG), rooted at one or more sink nodes. The routing tree (graph), along
which the trafﬁc traverses, is constructed according to an objective function (OF) that can
utilize a set of metrics such as energy consumption, latency, and hop count. The most
common ones are OF0, which ﬁnds the shortest path (the path with the minimal hop-count)
to the sink (Thubert et al. [127]), and minimum rank with hysteresis objective function
(MRHOF), which ﬁnds the routes that minimize the link cost associated with the routes
(Gnawali and Levis [128]). The cost is deﬁned as the latency metric allowing RPL to ﬁnd
stable minimum-latency paths from each node to the sink, or it can be associated with the
expected transmission count (ETX) metric, which allows RPL to ﬁnd the stable minimum-
ETX paths from the nodes to the sink (the default metric). In order to achieve stability,
MRHOF also ensures that a route is changed (a node exchanges its preferred parent in
Sensors 2022, 22, 2650
20 of 44
the routing tree) only if the cost of the improved route is better than the current route by
at least a predeﬁned threshold. RPL is the de-facto IPv6-based routing protocol for the
IoT. Accordingly, several OFs and possible enhancements have emerged during recent
years, and several performance evaluations and comparisons have been presented. In the
following, we discuss some of these OFs.
Abdel Hakeem et al. [129] analyze the performance of RPL in collecting smart meter
readings over smart grid (SG) networks via Java-based simulations and IoT-LAB testbed ex-
periments. Speciﬁcally, Ref. [129] evaluates the RPL performance under the two prominent
objective functions Hop Count and ETX, in terms of packet delivery ratio, network latency,
control trafﬁc overhead, and power consumption. Barnawi et al. [130] utilize the Cooja
network simulator to examine the performance of RPL under duty-cycle MAC protocol.
Speciﬁcally, Ref. [130] simulates RPL over the classical XMAC protocol and its derivative
ContikiMac, where, rather than using a long preamble waiting for the receiver to wake up,
the sender repeatedly sends the same packet until a link layer acknowledgment is received.
As a baseline, Ref. [130] uses NullRDC, an always-awake node. As expected, the results
show that NullRDC is better in terms of latency, while ContikiMac outperforms the others
in terms of power consumption. Al-Shargabi and Aleswid [131] also utilize the Cooja
network simulator to evaluate which OF is more suitable for a WSN in healthcare scenarios.
OF0 and ETX are examined in various network topologies, such as the grid and random
topology, under diverse densities. They conclude that the OF0 is more efﬁcient with respect
to packet delivery ratio (PDR) and power consumption in the random topology setup.
Sousa et al. [132] propose an energy-efﬁcient and path-reliability-aware objective
function (ERAOF). The OF suggested by ERAOF linearly combines energy consumption
and link quality (in terms of ETX) routing metrics. Even though the selected routes are
not optimal in either one of the objective metrics, they provide a balance between energy
efﬁciency and reliability. Rafea and Kadhim [133] suggest an energy threshold RPL (ETRPL),
which, in addition to the ETX metric, incorporates in its objective function the remaining
energy of the preferred forwarding (parent) node. ETRPL performance is evaluated via
Cooja simulator. Sharma et al. [134] suggest another MRHOF-based objective function that
takes into account three routing metrics: ETX, energy, and delay. Energy consumption,
in order to increase the lifespan of the network, is also considered by Sankar et al. [135],
which suggests cluster-tree-based routing protocol to maximize the lifetime of IoT (CT-
RPL). As the name suggests, CT-RPL is a cluster-based routing protocol that involves three
processes: cluster formation, cluster-head selection, and route establishment. CT-RPL ﬁrst
scans the nodes and group (cluster) nodes whose Euclidean distance from their centroid
point is bounded, adding one node at a time. Next, each cluster selects its cluster-head
(CH), utilizing a game-theoretic approach in which the node with the maximum payoff
“p” value—which considers parameters such as residual energy, sensing energy, receiving
energy, aggregation energy, and transmission energy—is selected as the CH node for each
round. Finally, the route is established using the metrics residual energy ratio (RER), queue
utilization (QU), and expected transmission count (ETX).
Another RPL enhancement termed weighted random forward RPL (WRF-RPL) is
proposed by Acevedo et al. [136]. WRF-RPL suggests a load balancing over RPL mechanism,
which distributes the trafﬁc between multiple transmission paths, trying to avoid one
preferred parent’s congestions. WRF-RPL OF relies on the composition of two metrics, the
remaining energy and the count of parent nodes, where the latter aims at prioritizing parent
nodes with more optional paths to the destination. Forwarding decisions are probabilistic
according to the deﬁned metric, such that nodes with a higher number of parents or hops
are more likely to be selected than others. The authors utilize the Cooja simulator for
evaluation. Rojas et al. [137] leverage a wired data center network labeling protocol to
suggest IoTorii, a routing protocol for LLNs. IoTorii supports multiple paths between
sender and receiver, and requires fewer table entries and control messages, with similar
performance compared to the standard RPL.
Sensors 2022, 22, 2650
21 of 44
Molnár [138] provides a graph-theoretic solution to the general problem of QoS-
constrained routing in WSN that relies on RPL. The authors stress the difference between
multi-objective optimization and multi-constrained problem setting. Vera-Pérez et al. [139]
examine the integration of RPL to IEEE 802.15.4e with time-slotted channel-hopping (TSCH)
medium access mechanism. In particular, Ref. [139] characterizes the long deployment
delays required for such networks to become operational and able to start exchanging data
messages. The article proposes an analytical model that estimates the average time that the
synchronization process can take for a new node to join a TSCH-based network, as well as
an estimation of the maximum time required for the formation of a complete network of
this kind, and the additional time required to set the RPL-based routes. The paper validates
the analytical model via simulations. A recent comprehensive survey on routing protocols
for LLN networks in IoT (not exclusive to RPL) can be found in [140].
5.2. Data Aggregation Routing Protocols for Energy Harvesting WSN
As discussed in Section 2, an alternative for relying on batteries as the source of energy,
with their imposed constraints (e.g., size, replacement, etc.), is to embrace energy-harvesting
(EH) technology. However, as mentioned earlier, relying on EH imposes different con-
straints and limitations. Such constraints can make battery-reliant schemes impractical
when devising data collection procedures. When battery-reliant schemes are applied to
EH-based platforms, performance can be highly degraded. Speciﬁcally, relying on EH can
induce high diversity between the different nodes, as different nodes can have different
attributes, such as energy depletion and charging rates, which affect the nodes’ availability;
in addition, different nodes can have different roles, such as different reporting rates or
different report importance, requiring more energy usage, which eventually also affects the
nodes’ availability. When a sensor is expected to transmit or receive a report, it needs to
have sufﬁcient energy to complete the transaction; therefore, reliance on EH needs to be
considered when designing a scheduling protocol. For example, a data collection scheme
that relies on EH should adapt the report rate to energy availability; it can compromise
the rate of less important reports coming from the sensors to leave them sufﬁcient energy
for emergency reports. It can prioritize sensors with more energy over those with lower
energy, especially when there is some redundancy in the reports received by different
sensors. This is especially so when dealing with multi-hop routing, where many of the
nodes serve as relays and have the burden to stay awake longer, to receive and transmit
more, which escalates the heterogeneity of the nodes and accentuates the difference in
importance between the different nodes. Furthermore, if on a single-hop network, we
could rely on the receiver (sink) to have unlimited power (connected to a power source), in
multi-hop topologies also, the receivers rely on EH; hence, when scheduling a transmission,
we need to ensure that both transmitter and receiver have sufﬁcient power to complete the
transaction. In the following, we present several routing protocol adaptations for EH-WSN
in the context of data aggregation.
The typical setup considers that each node (sensor) encompasses an energy har-
vester and an energy storage device and is solely powered by the renewable energy
available to it by its energy storage device. A multi-hop topology is considered such
that the data from many of the sensors need to traverse multiple links before reaching the
sink. Jeong et al. [141] propose an adaptive data aggregation scheme for energy-harvesting
WSNs. The suggested scheme relies on two residual-energy thresholds, lower and upper.
Each node periodically estimates its residual energy level to determine whether or not to
transmit data. When the node’s residual energy is either above the upper threshold or
below the lower threshold, the node transmits its aggregated data. If its energy is below
the lower threshold, the node enters energy-saving mode after transmitting the data. Its
radio is turned off, and it waits to regain sufﬁcient energy before turning its radio back
on. In normal operation mode, where the residual energy is between the two thresholds,
the node only aggregates data received from other nodes and collects its own sensed data.
If a node’s aggregated data in normal mode exceeds its storage limit, the node transmits
Sensors 2022, 22, 2650
22 of 44
the data regardless of its residual energy. While this scheme is clear and straightforward
to implement, it lacks latency evaluation and a discussion about rendezvous between a
transmitter and a receiver.
Chen et al. [142] experimentally show that in energy-harvesting-based wireless sensor
networks (EH-WSNs), the required nodes’ charging time to be ready to receive or send a
packet is much greater than the time required for the contention resolution mechanism and
dominates the data aggregation latency. In addition to the common collision deﬁnitions, the
paper deﬁnes an “energy-collision”, which occurs due to battery level constraint and not
due to simultaneous transmissions. Speciﬁcally, energy-collision occurs when a transmitter-
receiver tuple is scheduled for transmission, but the transmission cannot take place because
at least one of the two nodes has insufﬁcient energy to transmit or receive the packet due
to recent activity (insufﬁcient time has elapsed since its last transmission or reception to
harvest enough energy for the subsequent scheduled transmission). An adaptable data
aggregation tree is constructed, which considers each node’s residual and harvested energy,
and three energy-collision-aware data aggregation algorithms are proposed.
5.2.1. Cluster-Based Routing Protocol That Relies on EH
Several studies have suggested various adaptations for LEACH WSN cluster-based
routing protocol (e.g., [106]) for EH-based WSN (EH-WSN). Recall that LEACH’s cluster-
head selection mechanism randomly selects sensor nodes as cluster-heads to distribute
the energy consumption between them evenly, which can seemingly cope with the EH
constraints. However, note that even when the nodes’ platform is exactly the same, the
potential of different nodes to harvest energy, dependent on their speciﬁc ambient con-
ditions, can be very different. Furthermore, the node’s location with respect to the sink
can highly inﬂuence the amount of data it needs to relay toward the sink, causing high
discrepancies between the energy utilized by various nodes. To cope with these discrepan-
cies, Xiao et al. [143] modify LEACH’s cluster-head selection mechanism and deﬁne a new
metric termed “energy potential function” to measure each node’s capability to harvest
energy. The paper devises a cluster-head selection strategy that prioritizes nodes with
higher expected stored energy (based on the currently available energy and their potential
energy) to become cluster-heads, regardless of the number of instances that the node was
selected as cluster-head in the past.
To address the imbalance between the energy expected to be consumed by cluster-
heads (CHs) that are closer to the sink and are expected to spend more energy on relaying
packets from farther clusters, and CHs that are further from the sink and expected to relay
less trafﬁc, Wu et al. [144] suggest an unbalanced clustering mechanism. In particular,
cluster sizes are determined according to the distance (hop count) to the sink to balance the
energy consumption of the CHs. Accordingly, clusters closer to the sink, which are expected
to relay more inter-cluster trafﬁc, will be smaller, so that they collect less intra-cluster
trafﬁc; clusters further away from the sink and expected to relay less inter-cluster trafﬁc
will comprise more nodes, so that they collect more intra-cluster trafﬁc. The mechanism
suggested to attain this balance is partitioning the network conceptually into concentric
rings around the sink with linearly increasing radii. Each ring comprises nodes with
the same hop distance to the sink. Clusters within the same ring will have the same
size. CH selection is designed to balance the loads of each ring considering the available
nodes’ energy, which is evaluated based on the EH rate. Following a similar approach,
Yang et al. [145] assume a highly symmetric circular sensor network in which the sink
(BS) is located at the center, and the sensors are distributed evenly in a disc around it.
As with [144], the sensor ﬁeld is divided into concentric rings; however, in this study,
the rings are determined to have an equal area such that the number of sensors in each
ring is expected to be the same. Under the given model, Ref. [145] analyzes the energy
consumption of intra- and inter-cluster data transmission and derives the energy neutrality
constraints, which guarantee that each node consumes less energy than the amount of
energy it has harvested. The authors further devise a constraint formula of the number of
Sensors 2022, 22, 2650
23 of 44
clusters required in each layer (ring) that balances the average energy consumption of nodes
in different layers. The energy neutrality constraints and the cluster parameters are used to
obtain the parameters (number of rings, number of clusters in each ring, and minimum
network data transmission cycle) that minimize the data transmission cycle. Based on the
attained parameters, the cluster-based routing protocol is derived. The protocol consists
of an initialization phase and repeated cycles divided into topology formation and data-
gathering phases. Bahbahani and Alsusa [146] suggest two separate enhancements. The
ﬁrst, termed cooperative transmission strategy, enables nodes to serve as relays to relay
undelivered packets from cluster members to CHs and from CHs to the sink node. The
second mechanism, termed cluster-head duty-cycle, regulates the frequency at which a node
can become a CH based on duty-cycling that adapts to the node’s energy-harvesting rate.
To conserve the energy of nodes that are more susceptible to energy depletion,
Bozorgi et al. [147] select CHs, taking into account their residual energy, expected har-
vest energy, distance from the sink, number of neighbors, and, similar to LEACH, the
number of times a node has already served as a CH in the past. The proposed approach,
which combines centralized and distributed mechanisms, relies on a signal transmitted
by the sink that can be received by all the nodes, which allows them to estimate their
geographic distance from the sink. The network is partitioned by the sink into four layers
based on distance. The sink further computes the individual coverage radius of each node
(potential CH) based on distance (nodes closer to the sink, which are therefore expected
to relay trafﬁc coming from more distant clusters, will have a smaller radius, and thus
less intra-cluster trafﬁc; on the other hand, nodes farther away from the sink, which are
therefore expected to have less inter-cluster trafﬁc to relay, are assigned a longer radius,
and therefore more intra-cluster trafﬁc). The paper suggests a distributed contention-based
mechanism for selecting the CHs in which the contention window takes into account the
parameters mentioned above. Another cluster-based routing for EH-WSN is proposed by
Ren and Yao [148]. The proposed routing scheme is divided into cluster establishment and
data collection. It is suggested that besides the typical cluster members (CMs) and cluster-
head (CH), a new entity be devised, termed in the paper scheduling node (SN), which is
different from the CH. The main task of the SN is to monitor the energy of all the cluster
members during the data collection stage and select a CH based on the monitored residual
energy of the cluster members. The transmission range of nodes can also be adjusted based
on their residual energy. The data collection stage, which adapts a round-based scheme
similar to LEACH, is divided into the data transmission and CH selection stages.
Sinde et al. [149] aim to improve the network efﬁciency by three means: (i) clusteriza-
tion mechanism that takes into account energy consumption during the data aggregation
phase, (ii) duty cycle adaptation of each node such that each sensor node determines its
mode of operation, and (iii) routing mechanism based on ant colony optimization that
chooses the path between the source and the sink node that reduces the delay incurred.
Overall, while the paper jointly addresses several topics in WSN, including those connected
to energy-efﬁcient data gathering, its main contribution is the detailed NS3 simulation.
5.2.2. Mobile Charger
Today’s technology enables dedicated wireless charging equipment (WCE) to recharge
the nodes’ batteries, prolonging the lifetime of wireless rechargeable sensor networks.
A model in which, in addition to the sink (base station), a mobile station will navigate
through the WSN to collect data and charge sensor nodes is considered by Liu et al. [150].
The paper suggests a joint routing and charging strategy. The joint problem is decomposed
into two sub-optimization problems: routing tree optimization and charging path optimiza-
tion. Heuristic algorithms based on simulated annealing algorithms were applied to solve
these sub-optimization problems.
A joint charging and routing algorithm with WCE-assisted data gathering is also
suggested by Lu et al. [151]. The model suggested therein assumes that the BS (sink) can
get the information of each node at any time, including node location, residual energy,
Sensors 2022, 22, 2650
24 of 44
and energy consumption rate. The suggested approach relates to data routing and energy
supplement to undercharged nodes. The data routing algorithm considers several factors:
sensor buffer occupancy, load, and energy. To ﬁnd the route for the mobile recharging
unit to traverse, they rely on Du [152] to seek the shortest Hamiltonian cycle between the
nodes that urgently need energy replenishment traversed by the mobile recharging unit.
Additional nodes along the traversed path can also be charged. Furthermore, the mobile
recharging unit can also gather data from sensors with a critical buffer occupancy during
its recharging cycle.
In the following section, we discuss network coding (NC) and, in particular, linear
network coding in the context of data gathering in WSN.
5.3. Network Coding (NC)
Network coding leverages the routing protocols and the ability to construct multi-path
routing between sources and their destination (the sink) to enable intermediate nodes to
perform coding on the incoming packets before forwarding them. In the following section,
we discuss network-coding-related works.
Linear network coding was ﬁrst introduced by Celebiler and Stette [153] and evolved in
the seminal paper by Ahlswede et al. [154] as a means to improve the network’s throughput,
efﬁciency, and scalability, which can also be leveraged to improve the network resilience
to attacks and eavesdropping. Linear network coding allows the network’s intermediate
nodes (e.g., relays) to accumulate arriving messages and forward a newly encoded message,
which is a linear combination of the accumulated packets, multiplying them by coefﬁcients
chosen from a ﬁnite ﬁeld. The manner in which nodes encode and decode messages de-
pends on the selected coding scheme. Network coding (NC) over wireless communication
can reduce the number of transmissions by leveraging the fact that a single transmission is
overheard by multiple nodes in the transmitter’s vicinity, and can therefore be utilized by
each of these nodes, which will forward a coded packet with unique coefﬁcients comprising
its own message and the messages it overheard (e.g., [155]).
In WSNs, NC can be utilized for various trafﬁc patterns, including data dissemination
(one-to-many communication) and data gathering. Works on energy-efﬁcient NC-based
dissemination can be followed in the survey [156], with multi-hop routing being empha-
sized. In data dissemination in which the base station/sink distributes information to
the sensor nodes, NC is beneﬁcial mainly for distributing control messages (broadcast or
multicast trafﬁc) or, in case of unicast trafﬁc, for recovering lost packets (retransmissions).
The latter utilization relies on the fact that different nodes heard or did not hear different
packets. Accordingly, nodes store packets they overheard, even if not destined to them-
selves. The transmitter (e.g., access-point) accumulates several packets that need to be
retransmitted, each for a different receiver. It transmits a coded packet that is a composite
of these accumulated packets. Each receiver can decode a missing packet by utilizing its
stored overheard packets (e.g., [157–162], where the last two mainly focus on data dis-
semination of control management messages. It is noteworthy that Cohen et al. [157] also
present a successful real HW radio deployment of their scheme. XOR-CoW [163] exploits
the same concept to design an IoT protocol in which relays transmit coded packets that
mix downlink and uplink trafﬁc. Similar to other previously mentioned studies, the coding
scheme by Swamy et al. [163] is over ﬁnite Galois ﬁeld of size 2 (GF(2)) (i.e., XORing the
coded packets).
Network coding is widely explored for data-gathering schemes. Typically, an NC-
based protocol involves both the coding scheme and the multi-path routing. It relies on
the relay nodes to overhear packets and perform the coding, and on the sink (or multiple
sinks) to collect sufﬁcient coded packets (combinations) to encode the sent information.
The limited ability of the sensors constrains NC over WSN (e.g., limited storage to store
overheard packets, limited computation power to perform sophisticated operations, limited
awake time for packet overhearing, etc.). The utilized coding scheme inﬂuences the
performance of the NC algorithm in several aspects such as the throughput, algorithm
Sensors 2022, 22, 2650
25 of 44
complexity, encoding complexity, decoding complexity, packet overhead (bits), required
feedback, and so on. Note that many of these metrics are directly translated to air time
and energy consumption, which must be considered in WSN. The random linear network
coding (RLNC) encoding scheme (e.g., [164]) is widely used because, despite its simplicity,
it can attain throughput that is close to the optimal one using a decentralized algorithm.
In RLNC, relays transmit random linear combinations of the packets they receive, with
randomly chosen coefﬁcients from a ﬁnite Galois ﬁeld (GF). The receiver must obtain a
sufﬁcient number of linearly independent combinations (packets) to decode the original
packets. If the GF size is sufﬁciently large, the probability that the randomly generated
combinations will be linearly independent is high. However, the receiver needs to know the
coefﬁcient used in each combination; hence, it needs to be sent as overhead piggybacked on
each traversed packet. The larger the GF size, the higher the overhead. RLNC scheme with
distributed encoding was utilized by Stefanovi´c et al. [165] for a perimeter data-gathering
objective, in which the data should reach the perimeter nodes that are located on the
boundary of the covered area. The proposed scheme does not deploy routing algorithms or
maintain routing information and relies on random walks.
One disadvantage of RLNC is its decoding complexity in the order of O(n3), where n
denotes the number of original packets. Sparse end-to-end erasure-correcting codes can
reduce the decoding load on the receiver at the cost of introducing an additional, non-
negligible delay. Feizi et al. [166] suggest a tunable sparse network coding (TSNC) scheme
that tunes the level of sparsity as the transmission process evolves. This tuning process
can reduce the delay overhead by using denser codes towards the end of the transmission
while maintaining the complexity advantages of a sparse code. Prior et al. [167] propose
two network coding schemes for information gathering, which are based on tunable sparse
codes, with and without explicit feedback from the sink. The suggested schemes are
designed for meter readings in a smart grid. Nistor et al. [168] further exploit RLNC and
TSNC for data gathering and derived analytical bounds for a multi-hop line network using
a ﬂuid model, which is valid for any ﬁeld size and various sparsity levels, and has two
different feedback mechanisms.
SenseCode [169] adopts the NC paradigm, aspiring to balance energy efﬁciency and
end-to-end packet error rate. SenseCode relies on nodes transmitting both uncoded and
coded packets. Each node stores only a small portion of the packets it overhears, which can
be attained by letting the node wake up sporadically within its duty cycle and stay awake
for a short time interval each time it wakes up, storing overheard packets. Accordingly,
each coded packet comprises only a small subset of the packets the node could have
potentially overheard and coded. NetCoDer [170] concentrates on a star topology in
which the star-head can be a sink or a relay that collects information from its neighbors.
NetCoDer opportunistically selects, based on network conditions, a set of relays that, in
addition to the data sent by the nodes, send additional coded packets with packets they
overheard, which helps the star-head recover lost packets. To reduce the overhead, the
relays use LNC coefﬁcients based on the addresses of the sensor nodes. A similar idea
that also does not rely on feedback was presented in SR-Code [171] in which nodes and
relays send redundant coded messages to help the sink recover lost messages. SR-Code
utilizes the XOR operator (GF(2)). Similar to NetCoDer, SR-Code reduces the overhead
by using a bitmap to identify the coded packets rather than the address of the sending
node. Al-Hawri et al. [172] assume a data-gathering setup with single or multiple gateways
(sinks) that can collaborate (exchange information via accessible shared distributed storage
system). The paper distinguishes between traditional relays, which forward packets they
receive as-is, and encoding relays, which perform network-coding on the packets they
receive before forwarding them. The authors suggest a mathematical model and a heuristic
algorithm to determine the number of network-encoding nodes and their location, which
is insufﬁcient for the aggregate received data at the gateway/gateways to be decodable,
taking into account link failure scenarios.
Sensors 2022, 22, 2650
26 of 44
Protocols that utilize NC in WSN need to balance achieving the NC expedience and
diverse performance criteria. On the one hand, the motivation is to send only coded packets,
as sending uncoded packets degrades the NC gain. On the other hand, a strategy in which
a relay waits for packets to arrive in order to code them can yield unacceptable delays.
Furthermore, storing arriving packets while waiting for additional packets to arrive before
coding them can result in a buffer overﬂow and packet loss. To overcome these drawbacks,
Chen et al. [173] suggest an opportunistic network coding (ONC) approach in which the
relay can transmit either coded or uncoded packets. Each relay determines whether to
transmit a coded or uncoded packet according to its queue state at each transmission
opportunity. For the simple topology of a relay interconnecting two nodes that communi-
cate with one another, Ref. [173] presents an ONC strategy that can achieve the optimal
delay/power tradeoff. Mirani et al. [174] adopt the ONC paradigm for data dissemination
in vehicular ad hoc networks (VANETs), for which the mobile nodes (vehicles) employ a
decode-and-forward scheme with subjective timers determined according to their distance
from the source. In Tan et al. [175], an opportunistic routing protocol with opportunistic
network coding is proposed for correlated data gathering.
Next, we provide more recent works that utilize NC in WSNs and related networks
that are not particular to data-gathering applications. Marques et al. [176] propose to use
NC in a fog computing scenario, since in the fog computing system architecture, the data
measured on a node should be delivered to many other destination nodes. The authors
design a protocol for encoding and decoding and provide a design to incorporate it on
the MAC level. Uwitonze et al. [177] consider a setup in which a WSN has been split into
multiple disjoint partitions and suggests a polynomial-time heuristic algorithm based on
space network coding termed relay placement using space network coding (i.e., rather than
send additional coded data, additional relay nodes are deployed) for ﬁnding the optimal
number and positions to place relay nodes for restoring the network connectivity.
A network coding backpressure routing scheme for data aggregation in large-scale
Internet of things (IoT) networks is explored by Malathy et al. [178]. The proposed routing
scheme exploits network coding for the data aggregation process, which improves the
throughput of the network by eliminating redundant packets. The paper relies on cluster-
based routing that selects the cluster-heads (CH) based on the available energy and distance,
which helps to minimize trafﬁc congestion and provide efﬁcient data transmission.
5.4. Data Collection Utilizing Mobile Sink and Unmanned Aerial Vehicle (UAV)
A different paradigm for the traditional setup of data gathering in WSN, which
relies on a single or multiple static sink(s) towards which all trafﬁc needs to travel, is
the utilization of one or multiple mobile sinks (MSs) that traverse the terrain and collect
the reports from the devices. Such mobile sink(s) can be the trafﬁc’s ﬁnal destination or
just an accessory that collects the data and transmits it to the sink. Note that in the latter
case, the ﬁnal destination is not necessarily located within the wireless network realm
and can be located outside it (e.g., within the Internet or the cloud). Since these mobile
sinks are unmanned aerial vehicles in many cases, these systems are sometimes called
unmanned aerial vehicle-wireless sensor networks (UAV–WSNs). This section reviews
several state-of-the-art developments in mobile sink(s). Since sometimes the MS routing
challenges are interleaved with the MAC layer’s challenges, the solution suggested in some
papers, and accordingly their description, incorporated both layers.
Typically, data-gathering protocols that utilize moving sink(s) aim at optimizing some
performance metrics, such as overall power consumption, average or worst latency of the
data, trajectory traversed by the mobile sink, awake time of the sensors, maximizing the
life cycle of the network, and so on. There are different options to classify these protocols:
they can be classiﬁed according to this aforementioned performance objective, or other
categories, such as characteristics of the moving sink, its speed and constraints, network
model, communication standard utilized, and so on. In this section, we will classify the
protocol into two classes: protocols that solely rely on the moving sink with no intra-trafﬁc
Sensors 2022, 22, 2650
27 of 44
between the nodes (all the trafﬁc is directly transmitted to the moving sink), and protocols
that combine routing between the nodes and trafﬁc forwarding to the sink. This latter
class will mostly include cluster-based protocols in which the nodes are clustered and
cluster-heads (CHs) are selected, but rather than the CHs routing the trafﬁc towards the
sink, they forward the trafﬁc directly to the mobile sink.
5.4.1. Routing Directly to the Mobile Sink(s) with No Intra-Node Data Forwarding
In this section, we review papers in which the only data trafﬁc is between the nodes
and the mobile sink, and no data is forwarded between the nodes.
Zhan et al. [179] consider a general fading channel model and suggest an efﬁcient
sub-optimal solution that minimizes the energy consumption of all sensor nodes (SNs)
while ensuring that data is collected reliably from all SNs with bounded outage probability.
The suggested solution decouples the joint optimization problem, which considers both
the SNs’ wake-up schedule and the unmanned aerial vehicle (UAV’s) trajectory, into two
separate optimization problems, ensuring that the amount of data collected from each SN
reliably exceeds a threshold. One of the formulated optimization problems is non-convex
due to non-convex constraints, and therefore it needs to be relaxed. The two problems are
solved iteratively to obtain an approximate solution. A ﬂight time minimization problem
for a UAV that collects data from a set of energy-constrained ground sensors is studied by
Gong et al. [180]. The sensors are assumed to be located on a line (one dimension). Each
sensor has a certain amount of data to upload. The UAV can collect data either while
ﬂying or while hovering, and only from a single sensor at a time. Accordingly, the UAV’s
trajectory is divided into non-overlapping data collection intervals, each dedicated to
collecting data from a single sensor. The objective is to minimize the total ﬂight time of the
UAV from an initial point to a destination by jointly optimizing the division of intervals, the
UAV’s speed, as well as the sensors’ transmission power. The ﬂight time minimization is
formulated as a dynamic programming (DP) problem, where each DP stage considers ﬂight
time minimization for a single-sensor data collection scenario. The algorithm for the single-
sensor case is used to ﬁnd the UAV’s optimal speed and the sensor’s transmission power.
It is shown that the UAV’s optimal speed is proportional to the given energy of the sensors
and the inter-sensor distance but is inversely proportional to the data upload requirements.
The metric addressed by Liu et al. [181] is the age of the information. In particular,
Ref. [181] utilizes UAV, and suggests two age-optimal trajectories for it to collect the
data from the ground SNs, one that minimizes the age of the ‘oldest’ sensed information
among the sensors, and another that minimizes the average age of the information sensed
by all sensors. It is shown that both age-optimal trajectories correspond to the shortest
Hamiltonian path in the wireless sensor network, in which the distance between any
two sensors is represented by the amount of inter-visit time. The authors adopt dynamic
programming and genetic algorithm to ﬁnd the two different age-optimal trajectories.
Liu et al. [182] also utilize a UAV to collect the data from the ground sensors. The model
suggested therein assumes that the sensors (nodes) are randomly distributed over a square
area. The area is partitioned into small square cells. The UAV ﬂying above the cells
hovers above each cell to collect all the data of the sensors within the cell. The paper
studies the amount of data per unit time that the UAV can collect from the ground nodes
as a function of the number of cells, the height of the UAV, the number of sensors, and
the energy capacity of the UAV. The paper suggests a similar analysis when multiple
UAVs are utilized. It seeks the optimal number of cells to maximize the per-node capacity
under the suggested model and shows that under the suggested data collection network,
multiple UAVs can signiﬁcantly improve the per-node capacity attained by a single UAV.
The balanced network communication protocol (BNCP) that utilizes UAV as a mobile
sink is suggested by Qin et al. [183]. There is no inter-sensor routing in BNCP, and all
sensors’ communication energy is spent on the sensor-UAV transmission links. BNCP is
implemented and evaluated.
Sensors 2022, 22, 2650
28 of 44
5.4.2. Cluster-Based Data Forwarding
Rather than the mobile sink node traversing the network between all the sensors, a
different approach groups the sensors into clusters and selects cluster-heads (CH), which
collect the data from all cluster members, thus decreasing the traverse of the mobile sink.
In general, data gathering in a clustered WSN imposes a tradeoff between the energy
consumed during data collection within each cluster and the energy consumed by the
mobile sink. On the one hand, the higher the number of clusters (smaller clusters), the
less energy is consumed during data collection by the cluster-heads (CH); on the other
hand, it follows that the UAV will have to access more CHs on its route, and consequently,
the energy spent by the UAV will be higher in that case. This trade-off is one of the main
challenges in addressing the joint problem of clusterization and CH selection, jointly with
ﬁnding the path traversed by the UAV, as reﬂected in several papers discussed below.
Najjar-Ghabel et al. [184] propose a two-phase algorithm, termed DGOB, for data
gathering in WSNs in an environment impaired by obstacles, which utilizes a mobile sink
that traverses the network and collects the data. Both phases, node clusterization and
MS trajectory construction, exploit artiﬁcial intelligence (AI) schemes. Tazibt et al. [185]
utilize a small-scale drone to gather the data from scattered sensors. Like in several other
papers that rely on UAV to collect data from cluster-heads, the challenge in [185] is two-fold:
(i) clusterization and CH selection (in contrast with other papers, this paper allows multi-
hop clusters, such that cluster members are up to a predeﬁned number of hops from their
CH); and (ii) plan of the drone trajectory for traversing through all CHs with minimum
energy consumption (e.g., minimum path length). Even though the two problems are
related, the authors solve the two issues sequentially. They ﬁrst solve the CH selection
by formulating an optimization problem that seeks the minimal set of cluster-heads that
guarantee that all nodes are at most h hops from a CH in the set. After determining the CH
set via linear programing, they utilize the 2-opt heuristic, which relies on a simple local
search algorithm for solving the traveling salesman problem, in order to ﬁnd the optimal
travel trajectory for the drone between the selected CHs.
Kumar and Dash [186] also suggest a data-gathering-by-mobile-sink scheme in WSN.
The model in [186] assumes that the mobile sink is moving along a pre-speciﬁed path with
constant speed and can collect data while traveling. The paper denotes all the sensors
that are in transmission range from the mobile-sink traversed path, and can therefore
relay trafﬁc to it, as sub-sinks. All other nodes need to forward their data to these sub-
sinks, possibly through multi-hop communication, in order for them to relay the data
to the mobile sink. The paper suggests two different models: the ﬁrst assumes that the
mobile sink can receive data from only one sensor at a time, while the second assumes that
the mobile sink can receive data from multiple sensors simultaneously. Both suggested
algorithms comprise three phases: (i) identify the relay nodes (sub-sinks) that are within
transmission range from the mobile sink trajectory (unit disk graph model), and partition
the path into segments that are the union of all the transmission disks of all the sub-sinks;
(ii) determine the communication time each sub-sink can have with the mobile sink, and
accordingly, the amount of data it can transmit; (iii) utilize a network ﬂow approach to
determine which sub-sink transmits to the mobile sink in each of the mobile sink’s path
segments. Ebrahimi et al. [187] aim to optimize total transmission power between WSN
cluster-heads in an IoT network. The problem is split into subproblems, which include
CH assignment, building of the forwarding tree within each cluster, and optimal UAV
trajectory calculation. The data transmitted by CH to UAV is pre-processed by a specialized
optimized compression. A genetic algorithm for energy-efﬁcient CH selection is employed
by Wu et al. [188].
The focus of Zahra et al. [189] is on MS that traverses a WSN that relies on a cluster-
based data collection protocol in which cluster-heads are responsible for collecting and
transmitting the cluster members’ sensed data to the MS. The paper examines a scenario in
which the MS is constantly moving in a predeﬁned trajectory, regardless of whether the
data transfer was completed or not. Accordingly, when the cluster aggregate data is too
Sensors 2022, 22, 2650
29 of 44
large, the CH cannot complete the transaction. The authors suggest a mechanism in which,
in case the CH cannot complete the transaction, it can use different cluster members as
relays to continue the transaction after the MS has moved out of the transmission range
of the CH. Likewise, Zhang et al. [190] also suggest a hybrid approach that combines the
MS with hierarchical routing-based protocol relying on node clusterization. In order to
improve the efﬁciency of the MS data collection, Ref. [190] suggests utilizing virtual heads
(VHs) that lie on the MS trajectory on the cluster boundaries that also transmit collected
data to the MS. The channel access relies on a random access mechanism.
The UAV can be of different physical structures. While some machines are able to slow
down and even to hover, others, especially the winged UAVs, can only ﬂy with a constant
velocity. This limitation poses an additional challenge; see Say et al. [191] for a possible
solution. To address the velocity limitation, the grid topology of the UAV’s coverage is
divided into frames, and the most distant frames get the highest priority. The priority-based
transmissions from sensors to the moving UAV are incorporated into a MAC layer, by
introducing a priority-based contention window adjustment scheme. A smaller contention
window is assigned to the frame where sensors send packets from the rear side of the UAV,
and should therefore have a higher transmission priority. This results in a low packet loss
when the UAV ﬂies forward. On top of this architecture, a frame-selection-based routing
protocol is formulated.
6. Wearables and Wireless Body Area Networks (WBAN)
Numerous applications rely on data gathering and report collection in WSN and IoT,
and some are mentioned throughout the paper. There is no doubt that the essence of WSN
is the applications that utilize the infrastructure discussed throughout this paper. Providing
a thorough review of such applications can encompass several surveys. Since wearables
are becoming highly popular and a ubiquitous application which imposes new challenges
in the context of data gathering, we discuss several recent results and related challenges in
the context of wearables. Figure 5 depicts the main topics discussed in this section.
Wearables and WBAN
Section 6
Energy Harvesting (EH)
Section 6.1
Technological Advances
Section 6.2
Transmission Protocols
Section 6.3
WBAN Applications
Section 6.4
Figure 5. The main topics in the context of wearables covered in the section, and a rough partition of
the papers covered by these topics.
Wearable technology refers to smart devices attached to the human body or apparel
to monitor the user and their environment. Wearables are designed to detect, analyze,
and transmit information, which allows continuous monitoring of the subject. In some
cases (e.g., healthcare applications), feedback is returned to the wearer with strict perfor-
mance constraints (e.g., reliability, latency bounds). Such applications can necessitate the
monitoring of both bodily conditions, such as blood pressure, blood glucose level (e.g.,
in conjunction with an insulin pump), ECG, EMG, body temperature, accelerometer, and
gyroscope, as well as environmental conditions that might inﬂuence the user, such as
temperature, humidity, CO2 level, dust level, and location.
Sensing essential human physiological parameters led to the innovation of wireless
body area networks (WBANs). WBAN typically relates to a small area network that spans
the whole human body. It comprises devices (wearables) located in the apparel, on the
body, or under the skin, and are wirelessly connected. Even though tracking physical
conditions applies to diverse domains, including medical, social, and economic ones, each
with its particular implications and extensive research in the ﬁeld, the speciﬁc challenges
of acquiring data in WBANs necessitated new solutions designed for WBAN. Speciﬁcally,
Sensors 2022, 22, 2650
30 of 44
since the sensors in WBANS are designed to be located close to the monitored individual,
they impose particular challenges related to their speciﬁc structural, functional, and size-
related constraints. In the sequel, we dwell on some of the most critical challenges and
recent promising results on WBANS. The main objective of this survey is to understand the
data-gathering challenges. In the special case of WBANS, we also elaborate on the sensors’
physical and mechanical structure, which directly impact the data acquisition process.
Many of the challenges pertaining to WSN in general, which are described throughout
this survey, also apply to wearables. However, some of these challenges are exaggerated
when applied to wearables due to their unique characteristics. For example, energy-related
challenges that are essential to address and substantially inﬂuence any WSN design and
performance, open a different perspective on wearables. Speciﬁcally, due to their sensing
devices’ tiny size, the energy storing capacities are limited. Yet, many wearable applications,
particularly healthcare ones, employ continuous sampling and communication tasks that
constantly consume energy and deplete the device’s battery. Frequent battery replacement,
which can be a burden in any WSN, can be even more cumbersome in wearables and can
hinder the adoption of these technologies (e.g., when the wearables are implants, battery
replacement can involve an invasive medical intervention). Accordingly, energy-efﬁcient
approaches designed for wearable sensor networks are important for disseminating the
technology into additional domains. An inclusive review of energy-efﬁcient approaches
designed for human context recognition (HCR) based on wearable sensor networks is
given by [192]. This paper classiﬁes energy-efﬁcient mechanisms for health-related HCR
applications, based on the task that the mechanism is aimed at to reduce its energy con-
sumption (e.g., sensing, communication, computation). The paper reviews the related
works according to the classiﬁcation.
6.1. Energy Harvesting (EH)
Energy harvesting as a battery alternative has been discussed in Section 5.2. However,
EH in the context of wearables encounters new challenges, such as critical reliability level,
expected tiny size and position in/on the human body, limited exposure to energy sources
such as solar energy, and so on. Accordingly, we revisit EH and review some EH studies
in the context of wearables. The three most prominent techniques include photovoltaic
cells attached to a wearable (energy is accumulated from environmental illumination),
thermoelectric nanogenerators (the energy source is the heat produced by the human body),
and kinetic energy harvesters (energy is created by natural body motion). All energy
harvesting cases pose a fundamental challenge of effective energy management, which
involves continuous decision making regarding how much energy to spend on sensing,
measurements, on-board classiﬁcation, and transmission (see also Section 5.2).
We present examples for each of the techniques mentioned above in the context
of wearables. Thermoelectric energy-harvesting units exploiting self-generated human
heat are suggested to be fabricated straight into the textile of the garments [193]. Energy
harvesting for activity-aware wearables is designed by Khalifa et al. [194]. The idea is to
remove the accelerometers, which consume about 80% of the battery. Instead, the authors
propose to employ kinetic energy harvesters, which will convert human motion into
electrical power. Additionally, to compensate for the accelerometers’ removal, the input and
output of the kinetic energy harvester would be analyzed by a specialized activity classiﬁer
to track and identify the human activity (i.e., to perform the primary task of the wearable).
Light-based energy-harvesting wearables are discussed by Park et al. [195]. It is noteworthy
that as the available luminosity can be highly unpredictable, the overall functioning, data-
gathering, and transmission process would imply an optimization problem. Henceforth,
the same authors suggest a protocol to optimize the number and accuracy of interpretation
of human gestures by an energy-harvesting wearable device under an energy budget,
Park et al. [196]. To this end, they constructed an analytical model that characterizes
energy consumption based on experimental data and formulized the optimization problem.
Esteves et al. [197] suggest incorporating energy harvesting as part of MAC 802.15.6. The
Sensors 2022, 22, 2650
31 of 44
proposed MAC modiﬁcation includes the usage of some body sensors as relays. The
managing part at a hub (e.g., a smartphone) sets the optimal relay charging times to
perform the data transmission by relay effectively. A source and the relays send their
energy-harvesting updates within the request for cooperation (RFC) packets. The charging
times are calculated according to the amount of energy at the source and relays and are
updated in accordance with previous packet transmission success or failure.
6.2. Technological Advances
WBAN utilization is penetrating new domains, spanning a wide variety of sensors,
each providing a different aspect of the monitored subject. For example, healthcare ap-
plications are expected to provide a wide span of indicators from various physiological
parameters. Speciﬁcally, to provide a comprehensive status of the examinee, it requires, in
addition to the standard indicators such as heart rate and physical activity that many of us
already have integrated in our watch, information at a deeper level and molecular level
insight into the dynamics of the wearer.
To cope with the growing popularity of wearables and their expansion to a broader
scope of applications, especially in healthcare systems, with the increasing demand to
improve quality of service (QoS) and quality of experience (QoE), a new generation of
wearables has emerged. This generation relies on several technological advances in both
the device and cloud realms. The novel device technology utilizes new soft-sensing tech-
nologies, including innovative wearable materials such as conducting polymers, rigid
forms of hydrogel, gold and silver nanowires (to create nanowired tattoos as stretchable
sensors), carbon nanotubes, liquid metals, ionic liquids, and others. These materials give
rise to novel sensor families, such as electro-physiological (acting on the electric potential
difference) physical and chemical sensors. See the latest advances in the following related
works [198–200]. For example, besides reviewing the key developments in sweat-sensing
technology, Bariya et al. [198] examine the requirements of the underlying components
embedded in sweat-based wearable sensors and discuss challenges for integrating wearable
sweat sensors in the development of personalized healthcare. Sweat-sensing technology
has been described earlier; see, for example, Salvo et al. [201], where a device containing
two humidity sensors located at different heights from the skin is designed in a way that
allows one to measure the sweat rate by the difference in readings of these two sensing
sub-units. Thermal comfort control by calculating the relation between the vapor pres-
sure and the temperature is designed into watch-type sweat sensors by Sim et al. [202].
Sweat measurement by sweat biomarkers (in particular, pH and Na+) is implemented
by Song et al. [203]. In short, the biomarkers cause a change in electric potential near the
measuring device, allowing for accurate sweat measurement during physical activity. The
authors also note that the change in electrical potential allows for energy harvesting, which
can be effectively managed to self-power the device and thus allow for a battery-free design.
In general, the material imprinted into the working reacting electrode determines which
substance (i.e., a chemical component present in the sweat) it will react with. For example,
an application of electrochemical differential pulse voltammetry to sense the sweat to
measure the level of caffeine is devised by Tai et al. [204].
The main challenge in the devices is to implement capabilities of effective data gath-
ering, ﬁltering, and transmission within microscopic computing units. Some biometric
sensing (especially made by speciﬁc conﬁgurations of adjacent sensor sets) produces large
amounts of data (as in ECG sensing) that should undergo an appropriate local density
reduction. To ensure conformity with the sensing devices, paper lithium batteries are
proposed (see, e.g., [205]). In addition, many sensors are conﬁgured only to transmit
following special hazards. For example, ECG sensors should trigger an alarm in case the
heartbeat is abnormal. This local data processing is a preliminary phase that facilitates
the more intensive data analyses in the intermediate data collection unit (the smartphone),
and ﬁnally, the destination server. To treat noisiness and variability (if the sensor sampling
frequency is too high) of raw data from an accelerometer or gyroscope or loss of data (if the
Sensors 2022, 22, 2650
32 of 44
sensor sampling frequency is too low), variable sampling is proposed by Li et al. [206]. The
ofﬂine ML classiﬁcation algorithm is used to identify and predict the physical activity.
The recent development of miniature sensors combined with minimization of battery
size and energy harvesting advances is sometimes referred to as a new paradigm, known as
Wearables 2. For example, Ling et al. [207] provide a detailed description of various types
of sensors, means of attaching them to the human body, multiple parameters the sensors
are capable of measuring, and techniques to communicate and process the measured data.
6.3. Transmission Protocols
We note that while many of the works mentioned above employ a smartphone device
with an application that is presumably tailored to receive data from the wearables, having
a dedicated hardware device that would ofﬂoad some of the networking burden (e.g.,
potential simpliﬁcation of the packetizing process) of the sensors would be more effective
and reliable. Indeed, in Pathak et al. [208], a central processing hub allows one to circumvent
the cumbersome processes of sensor identiﬁcation, sensor joining, and reconﬁguration
by providing a designated interface. The authors provide real hardware implementation,
explore various performance metrics, and provide energy measurements.
Several available protocols for data transmission are suitable for WBAN. We mention
here the low Bluetooth energy (BLE; see, e.g., Townsend et al. [209] for a detailed protocol
stack description and Gomez et al. [210] for performance evaluation and comparison with
ordinary Bluetooth and other protocols). For distances of several centimeters, near-ﬁeld
communication (NFC) protocol (see Coskun et al. [211] for the theory and Kim et al. [212]
for a description of possible device designs and applications). Details of the IEEE 802.15.6
standard, which covers WBAN, can be found in, for example, Kwak et al. [213]. One sees
therein how the human body communications PHY layer in particular is deﬁned.
6.4. WBAN Applications
Even though, as stated earlier, there is no intention to provide a thorough review of
WBAN applications, we mention several interesting ones. Monitoring of workers involved
in extreme conditions or whose activity can be potentially dangerous (e.g., Lee et al. [214])
suggest wearable sensors for monitoring miners or construction professionals. This study
evaluates integrated wearable sensors for measuring construction workers’ personal level
of workload, individual factors, and physiological reactions during rooﬁng activities. A
fatigue detection system for car drivers by Chang et al. [215] includes smart glasses, which
are able to identify possible drowsiness by an IR detector aimed at the driver’s eyes,
equipped with BLE transmitter. A small processor embedded into the glasses gathers and
pre-analyzes the data and then transmits them to the on-board computer in the car. The
latter makes a decision about whether to issue a fatigue warning and sends it to the cloud.
Wearables can be attached to a human body in order to sense the environment for the safety
of the carrier, as in Wu et al. [216]. The data (humidity and temperature) is then transmitted
to a mobile unit, where it can be analyzed locally or further transmitted to the cloud in order
to issue timely warnings. Classiﬁcation of sports activity is implemented and validated by
experiments by Qi et al. [217], where the activity is identiﬁed from accelerometer and ECG
measurements done by chest and wrist sensors. The measurements are transmitted to a
smartphone, which performs the data processing. SVM is employed for the classiﬁcation.
You et al. [218] suggest a real-time wireless body sensor networks (WBSNs) scheme
for welfare assessment and disease monitoring, prevention, and treatment. The suggested
scheme is composed of three components: sensing, communication, and management.
Sensing attains a set of physiological parameters, such as heart rate, body temperature,
ECG, temperature, blood pressure, blood glucose, heart rate, and oxygen saturation, from
designated sensors embedded on a smart shirt worn by the monitored user. Communi-
cation handles the processes of delivering the sensed physiological data and controlling
instructions to a backend server through wireless networks. The transmission protocols
can be divided into two segments: the transfer of information from the sensors to a central
Sensors 2022, 22, 2650
33 of 44
terminal located at a smartphone and the transfer of information between the smartphone
and the designated server, which is located on the healthcare cloud. The communication
relies on multiple communication protocols including Bluetooth, WiFi, and 3G/4G (which
can be replaced by 5G where available). Management is responsible for collecting, classify-
ing, and monitoring the physiological data, and furthermore, being able to issue warning
messages to medical professionals or caregivers whenever the physiological data are ab-
normal. Additional applications utilizing data gathering can be found in the following
survey [219].
We conclude by emphasizing that the beneﬁts of WBANs have not run their course
yet. The development of data gathering will jointly progress with the ongoing advances
in sensor construction and manufacturing capability, development, and standardization
of Wearables 2 and beyond. Development of specialized post-processing platforms poses
a specialized challenge, and the urge to make progress in this area is acute. To illustrate
this, on account of an ever-growing population, specialized platforms for elderly care
are needed; see, for example, the recent papers [220,221] about wearables designated for
elderly patients and references therein.
Finally, wearables have been recently harnessed for combating the COVID-19 disease.
Early identiﬁcation of COVID-19 symptoms by evaluating the resting heart rate during the
asymptomatic (presumably infectious) period and analysis by a deep learning framework
is evaluated by Bogu and Snyder [222]. While the precision of such a tool is clearly inferior
to the standard medical assays, it may be useful to provide a preliminary alert for the
early onset of the disease for people in risk groups. Hassantabar et al. [223] suggest a
framework termed CovidDeep that combines commercially available wearable physiolog-
ical feature sensors (WMSs) and a simple yes/no questionnaire with efﬁcient DNNs for
pervasive large-scale monitoring of disease onset and health condition. The automatically
extracted raw data and medical background and symptom responses are combined with
synthetically generated data to train the DNN architecture. Grow-and-prune synthesis is
used to generate accurate and computationally efﬁcient models that can be deployed for
COVID-19 inference.
Since viruses can spread between people who are in close contact with an infected
person, and since infected people may be asymptomatic, the pandemic taught us that it
is best to keep a safe distance from others (see, for example, Cortellessa et al. [224] for
close-proximity risk assessment for COVID infection). Accordingly, most health institutions
recommend keeping physical distance between people in public places (commonly termed
as ”social distancing”) in order to stop the pandemic from spreading. Furthermore, people
who were in the proximity of an infected person (tested positive for COVID) are encouraged
to be examined, and several governmental regulations even require such people to stay in
quarantine. Several recent studies have suggested leveraging wearables for contact tracing
in order to identify the hazard from close proximity. For example, Ng et al. [225] focus on
Bluetooth low energy and discuss the different data ﬂow approaches and the accuracy of
smartphone vs. smartwatch applications in proximity detection. Bian et al. [226] utilize
wearables to monitor social distancing as recommended for preventing COVID-19 spread.
In particular, the authors design compact potentially wearable oscillating-magnetic-ﬁeld-
based proximity-sensing prototype systems suitable for the relevant safety distance and able
to track social distancing much more reliably than the current Bluetooth-based smartphone
technology. Shubina et al. [227] provide a brief technical overview of the main contact-
tracing approaches and the challenges they impose on wearable technology. The paper
also provides a short overview of the existing solutions deployed for contact tracing and a
discussion on the potential effect of wearables in tackling the spread of a highly contagious
virus. More works from the past year discuss the use of wearables for remote management
and automated assessment of COVID-19. Amft et al. [228] provide an overview of insti-
tutional initiatives and alternative, more accurate technologies for detection of infection
symptoms and possible contact with infected individuals. Channa et al. [229] is a system-
Sensors 2022, 22, 2650
34 of 44
atic review of the two categories of challenges: on-body sensors and their clinical utilization
in screening and contact tracing.
7. Concluding Remarks
Data gathering in modern WSN and IoT networks encompasses many challenges,
which span the entire communication stack. Many techniques, protocols, and solutions
have been proposed over the years, but as technology advances, new challenges and new
opportunities arise. In this survey, we reviewed these main challenges and opportunities, as
well as recent advances, and related them to speciﬁc data-gathering research domains. We
provided a comprehensive state-of-the-art data-gathering literature review in modern WSN
networks, distinguishing between the communication layers and the research domain.
We ﬁrst summarized general architectural novelties and emerging architectures. We
reviewed several new technological advances and their inﬂuence on sensing device design,
the platform carrying it, and the transceiver. We reviewed the effect of these architectural
advantages on speciﬁc applications, such as agriculture, smart cities, smart homes. We
showed how cloud computing drives new WSN types, which introduces new directions,
and discussed how WSN can coexist within social network domains. Compressed sensing
was summarized next. We provided an overview of this important scheme and reviewed
its utilization in WSNs. We proceeded with the MAC layer. Since the performance of many
innovations in the higher layers rely on the underlay MAC protocol and since many data
gathering schemes utilize traditional WSN MAC protocols, we provided an overview of
these traditional protocols and mentioned state-of-the-art works in WSN and IoT. These
works devise new MAC approaches for data gathering. Next, we covered the recent
advances in routing. Similarly, we opened with an overview of the traditional routing
protocols utilized for data-gathering and reviewed several recent enhancements. We
reviewed the utilization of network coding for data gathering and explored the facilitation
of UAV and mobile-sink in collecting the data from the sensors. Lastly, we turned our
attention to the area of wearables which opens new research horizons for human health and
activity surveillance and discussed the new paradigm of Wireless Body Area Networks. In
the spirit of the times, we concluded with several studies that utilize some of the techniques
discussed in this survey to aid in combating the COVID pandemic.
While we provided the general background to the research areas we covered, we
mainly focused on cutting-edge research works. Yet we note that even seemingly exhausted
topics, such as MAC and Routing protocols, provide new technological developments and
present opportunities for new research domains.
As implied throughout this survey, there are several research areas that attract a
lot of attention and anticipation for future developments. For example, technological
innovations in manufacturing more compact sensing units with yet superior transmission,
reception and processing capabilities are extremely in demand in several disciplines which
include wearables, smart homes, IoT-related domains and others. All the more so, this
is relevant when dealing with healthcare applications and implants. Such technological
innovations will require in turn enhancements to other domains across the communication
stack in order to adjust to the new opportunities and limitations. Energy acquisition is
still a fruitful research domain. In this respect, ﬁnding new sources of energy harvesting
(EH), better utilization of existing energy resources and energy storage are still challenging
research ﬁelds. Similarly, new EH methods impose multiple new challenges on the entire
protocol stack, which are correlated with the EH method, e.g., different EH methods dictate
constraints on the MAC design, which in turn, impact the routing protocol which affects
the performance end eventually the application utilizing the infrastructure. The growth of
such networks supporting a variety of heterogeneous devices of communication standards
and their increasing density requires more effective data compression techniques and
efﬁcient on-grid data analyses (i.e., even prior to data delivery to sinks). On the off-grid
side of WSNs, we note that consistent progress in Cloud Computing (CC) technology and
exploitation methodology will open new horizons in data analysis.
Sensors 2022, 22, 2650
35 of 44
Deployment of Edge Computing units cooperating with sensing-capable units will
imply the development of novel data-gathering schemes. As WSN density increases,
challenges in the gathering of useful data by WSN and its consequent analysis will coincide
with those of Big Data. Clearly, the processes of such analyses should be implemented
within Cloud Computing systems. The fashion of the CC physical resources deployed in
order to efﬁciently interact with WSN is not necessarily similar to those of usual IT-to-CC
connectivity. It is not currently properly standardized and, most importantly, it is not
clear how correctly CC (e.g., which HW, correct deployment of Access Points) should be
cross-planned with a particular WSN. Issues of security and privacy which are not covered
in this survey will continue to elicit a major interest, especially in keeping with evolving
health care applications. The growth of the network and their variability will require a
greater measure of adoption of ML and AI methods and the development of such new
specialized methods for WSN in the very near future.
Funding: This research received no external funding.
Conﬂicts of Interest: The authors declare no conﬂict of interest.
References
1.
Rawat, P.; Singh, K.D.; Chaouchi, H.; Bonnin, J.M. Wireless sensor networks: A survey on recent developments and potential
synergies. J. Supercomput. 2014, 68, 1–48. [CrossRef]
2.
Peoples, C.; Rabbani, K.; Mamun, A.T.; Wang, B.; Morrow, P.; Moore, A.; Rafferty, J.; Mcclean, S.; Zoualfaghari, M.H.;
Kulkarni, P. A Review of IoT Service Provision to Assess the Potential for System Interoperability in an Uncertain Ecosys-
tem.
In Proceedings of the 2019 IEEE SmartWorld, Ubiquitous Intelligence & Computing, Advanced & Trusted Comput-
ing, Scalable Computing & Communications, Cloud & Big Data Computing, Internet of People and Smart City Innovation
(SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI), Leicester, UK, 19–23 August 2019; IEEE: Piscataway, NJ, USA, 2019;
pp. 1964–1971.
3.
Ahad, M.A.; Paiva, S.; Tripathi, G.; Feroz, N. Enabling technologies and sustainable smart cities. Sustain. Cities Soc. 2020,
61, 102301. [CrossRef]
4.
Lai, C.S.; Jia, Y.; Dong, Z.; Wang, D.; Tao, Y.; Lai, Q.H.; Wong, R.T.; Zobaa, A.F.; Wu, R.; Lai, L.L. A review of technical standards
for smart cities. Clean Technol. 2020, 2, 290–310. [CrossRef]
5.
Zhang, Y.; Sun, L.; Song, H.; Cao, X. Ubiquitous WSN for healthcare: Recent advances and future prospects. IEEE Internet Things
J. 2014, 1, 311–318. [CrossRef]
6.
Hwang, Y.M.; Kim, M.G.; Rho, J.J. Understanding Internet of things (IoT) diffusion: Focusing on value conﬁguration of RFID and
sensors in business cases (2008–2012). Inf. Dev. 2016, 32, 969–985. [CrossRef]
7.
Ghayvat, H.; Mukhopadhyay, S.; Gui, X.; Suryadevara, N. WSN-and IOT-based smart homes and their extension to smart
buildings. Sensors 2015, 15, 10350–10379. [CrossRef]
8.
Farooq, M.S.; Riaz, S.; Abid, A.; Abid, K.; Naeem, M.A. A Survey on the Role of IoT in Agriculture for the Implementation of
Smart Farming. IEEE Access 2019, 7, 156237–156271. [CrossRef]
9.
Boursianis, A.D.; Papadopoulou, M.S.; Diamantoulakis, P.; Liopa-Tsakalidi, A.; Barouchas, P.; Salahas, G.; Karagiannidis,
G.; Wan, S.; Goudos, S.K. Internet of things (IoT) and agricultural unmanned aerial vehicles (UAVs) in smart farming: A
comprehensive review. Internet Things 2020, 100187. [CrossRef]
10.
Ullo, S.L.; Sinha, G. Advances in smart environment monitoring systems using IoT and sensors. Sensors 2020, 20, 3113. [CrossRef]
11.
Werner-Allen, G.; Johnson, J.; Ruiz, M.; Lees, J.; Welsh, M. Monitoring volcanic eruptions with a wireless sensor network. In
Proceedings of the Second European Workshop on Wireless Sensor Networks, Istanbul, Turkey, 2 February 2005; IEEE: Piscataway,
NJ, USA, 2005; pp. 108–120.
12.
Alphonsa, A.; Ravi, G. Earthquake early warning system by IOT using Wireless sensor networks. In Proceedings of the 2016
International Conference on Wireless Communications, Signal Processing and Networking (WiSPNET), Chennai, India, 23–25
March 2016; IEEE: Piscataway, NJ, USA, 2016; pp. 1201–1205.
13.
Lu, H.; Wang, D.; Li, Y.; Li, J.; Li, X.; Kim, H.; Serikawa, S.; Humar, I. CONet: A cognitive ocean network. IEEE Wirel. Commun.
2019, 26, 90–96. [CrossRef]
14.
Mourtzis, D.; Vlachou, E.; Milas, N. Industrial big data as a result of IoT adoption in manufacturing.
Procedia Cirp 2016,
55, 290–295. [CrossRef]
15.
Bansal, M.; Chana, I.; Clarke, S. A survey on iot big data: Current status, 13 v’s challenges, and future directions. ACM Comput.
Surv. 2020, 53, 1–59. [CrossRef]
16.
Boubiche, S.; Boubiche, D.E.; Bilami, A.; Toral-Cruz, H. Big data challenges and data aggregation strategies in wireless sensor
networks. IEEE Access 2018, 6, 20558–20571. [CrossRef]
Sensors 2022, 22, 2650
36 of 44
17.
Kim, B.S.; Kim, K.I.; Shah, B.; Chow, F.; Kim, K.H. Wireless sensor networks for big data systems.
Sensors 2019, 19, 1565.
[CrossRef]
18.
Dash, S.K.; Mohapatra, S.; Pattnaik, P.K. A survey on applications of wireless sensor network using cloud computing. Int. J.
Comput. Sci. Emerg. Technol. 2010, 1, 50–55.
19.
Aazam, M.; Khan, I.; Alsaffar, A.A.; Huh, E.N. Cloud of Things: Integrating Internet of Things and cloud computing and the
issues involved. In Proceedings of the 2014 11th International Bhurban Conference on Applied Sciences & Technology (IBCAST),
Islamabad, Pakistan, 14–18 January 2014; IEEE: Piscataway, NJ, USA, 2014; pp. 414–419.
20.
Dwivedi, R.K.; Kumar, R. Sensor cloud: Integrating wireless sensor networks with cloud computing. In Proceedings of the
2018 5th IEEE Uttar Pradesh Section International Conference on Electrical, Electronics and Computer Engineering (UPCON),
Gorakhpur, India, 2–4 November 2018 ; IEEE: Piscataway, NJ, USA, 2018; pp. 1–6.
21.
Li, F.; Vögler, M.; Claeßens, M.; Dustdar, S. Efﬁcient and scalable IoT service delivery on cloud. In Proceedings of the 2013 IEEE
Sixth International Conference on Cloud Computing, Santa Clara, CA, USA, 28 June–3 July 2013 ; IEEE: Piscataway, NJ, USA,
2013; pp. 740–747.
22.
Kamel, M.; Hamouda, W.; Youssef, A. Ultra-dense networks: A survey. IEEE Commun. Surv. Tutor. 2016, 18, 2522–2545. [CrossRef]
23.
Teng, Y.; Liu, M.; Yu, F.R.; Leung, V.C.; Song, M.; Zhang, Y. Resource allocation for ultra-dense networks: A survey, some research
issues and challenges. IEEE Commun. Surv. Tutor. 2018, 21, 2134–2168. [CrossRef]
24.
Stergiou, C.; Psannis, K.E.; Kim, B.G.; Gupta, B. Secure integration of IoT and cloud computing. Future Gener. Comput. Syst. 2018,
78, 964–975. [CrossRef]
25.
Biswas, S.; Das, R.; Chatterjee, P. Energy-efﬁcient connected target coverage in multi-hop wireless sensor networks. In Industry
Interactive Innovations in Science, Engineering and Technology; Springer: Berlin/Heidelberg, Germany, 2018; pp. 411–421.
26.
Ammari, H.M. Joint k-coverage and data gathering in sparsely deployed sensor networks–Impact of purposeful mobility and
heterogeneity. ACM Trans. Sens. Netw. 2013, 10, 1–33. [CrossRef]
27.
Mdemaya, G.B.J.; Bomgni, A.B. A2CDC: Area Coverage, Connectivity and Data Collection in wireless sensor networks. Netw.
Protoc. Algorithms 2018, 10, 20–34.
28.
Boukerche, A.; Sun, P. Connectivity and coverage based protocols for wireless sensor networks. Ad Hoc Netw. 2018, 80, 54–69.
[CrossRef]
29.
Cerchecci, M.; Luti, F.; Mecocci, A.; Parrino, S.; Peruzzi, G.; Pozzebon, A. A low power IoT sensor node architecture for waste
management within smart cities context. Sensors 2018, 18, 1282. [CrossRef] [PubMed]
30.
Teixidó, P.; Gómez-Galán, J.A.; Gómez-Bravo, F.; Sánchez-Rodríguez, T.; Alcina, J.; Aponte, J. Low-power low-cost wireless ﬂood
sensor for smart home systems. Sensors 2018, 18, 3817. [CrossRef] [PubMed]
31.
Borrero, J.D.; Zabalo, A. An autonomous wireless device for real-time monitoring of water needs.
Sensors 2020, 20, 2078.
[CrossRef]
32.
Vullers, R.J.; Van Schaijk, R.; Visser, H.J.; Penders, J.; Van Hoof, C. Energy harvesting for autonomous wireless sensor networks.
IEEE Solid-State Circuits Mag. 2010, 2, 29–38. [CrossRef]
33.
Prasad, R.V.; Devasenapathy, S.; Rao, V.S.; Vazifehdan, J. Reincarnation in the ambiance: Devices and networks with energy
harvesting. IEEE Commun. Surv. Tutor. 2013, 16, 195–213. [CrossRef]
34.
Ku, M.L.; Li, W.; Chen, Y.; Liu, K.R. Advances in energy harvesting communications: Past, present, and future challenges. IEEE
Commun. Surv. Tutor. 2015, 18, 1384–1412. [CrossRef]
35.
Shaikh, F.K.; Zeadally, S. Energy harvesting in wireless sensor networks: A comprehensive review. Renew. Sustain. Energy Rev.
2016, 55, 1041–1054. [CrossRef]
36.
Perera, T.D.P.; Jayakody, D.N.K.; Sharma, S.K.; Chatzinotas, S.; Li, J. Simultaneous wireless information and power transfer
(SWIPT): Recent advances and future challenges. IEEE Commun. Surv. Tutor. 2017, 20, 264–302. [CrossRef]
37.
Prauzek, M.; Konecny, J.; Borova, M.; Janosova, K.; Hlavica, J.; Musilek, P. Energy harvesting sources, storage devices and system
topologies for environmental wireless sensor networks: A review. Sensors 2018, 18, 2446. [CrossRef] [PubMed]
38.
Kanoun, O.; Bradai, S.; Khriji, S.; Bouattour, G.; El Houssaini, D.; Ben Ammar, M.; Naifar, S.; Bouhamed, A.; Derbel, F.; Viehweger,
C. Energy-aware system design for autonomous wireless sensor nodes: A comprehensive review. Sensors 2021, 21, 548. [CrossRef]
[PubMed]
39.
Khalid, N.; Mirzavand, R.; Saghlatoon, H.; Honari, M.M.; Mousavi, P. A three-port zero-power RFID sensor architecture for IoT
applications. IEEE Access 2020, 8, 66888–66897. [CrossRef]
40.
Abella, C.S.; Bonina, S.; Cucuccio, A.; D’Angelo, S.; Giustolisi, G.; Grasso, A.D.; Imbruglia, A.; Mauro, G.S.; Nastasi, G.A.;
Palumbo, G.; et al. Autonomous energy-efﬁcient wireless sensor network platform for home/ofﬁce automation. IEEE Sens. J.
2019, 19, 3501–3512. [CrossRef]
41.
Lee, W.K.; Schubert, M.J.; Ooi, B.Y.; Ho, S.J.Q. Multi-source energy harvesting and storage for ﬂoating wireless sensor network
nodes with long range communication capability. IEEE Trans. Ind. Appl. 2018, 54, 2606–2615. [CrossRef]
42.
Joris, L.; Dupont, F.; Laurent, P.; Bellier, P.; Stoukatch, S.; Redouté, J.M. An autonomous sigfox wireless sensor node for
environmental monitoring. IEEE Sens. Lett. 2019, 3, 1–4. [CrossRef]
43.
Devadas, T.J.; Thayammal, S.; Ramprakash, A. IoT Data Management, Data Aggregation and Dissemination. In Principles of
Internet of Things (IoT) Ecosystem: Insight Paradigm; Springer: Berlin/Heidelberg, Germany, 2020; pp. 385–411.
Sensors 2022, 22, 2650
37 of 44
44.
Zhu, C.; Leung, V.C.; Rodrigues, J.J.; Shu, L.; Wang, L.; Zhou, H. Social sensor cloud: Framework, greenness, issues, and outlook.
IEEE Netw. 2018, 32, 100–105. [CrossRef]
45.
Dinh, T.; Kim, Y. An efﬁcient interactive model for on-demand sensing-as-a-servicesof sensor-cloud. Sensors 2016, 16, 992.
[CrossRef] [PubMed]
46.
Zhu, C.; Shu, L.; Leung, V.C.; Guo, S.; Zhang, Y.; Yang, L.T. Secure multimedia big data in trust-assisted sensor-cloud for smart
city. IEEE Commun. Mag. 2017, 55, 24–30. [CrossRef]
47.
Kuo, Y.W.; Li, C.L.; Jhang, J.H.; Lin, S. Design of a wireless sensor network-based IoT platform for wide area and heterogeneous
applications. IEEE Sens. J. 2018, 18, 5187–5197. [CrossRef]
48.
Satyanarayanan, M. The emergence of edge computing. Computer 2017, 50, 30–39. [CrossRef]
49.
Abdelwahab, S.; Hamdaoui, B.; Guizani, M.; Znati, T. Cloud of things for sensing-as-a-service: Architecture, algorithms, and use
case. IEEE Internet Things J. 2016, 3, 1099–1112. [CrossRef]
50.
Popescu, D.; Stoican, F.; Stamatescu, G.; Ichim, L.; Dragana, C. Advanced UAV–WSN System for Intelligent Monitoring in
Precision Agriculture. Sensors 2020, 20, 817. [CrossRef] [PubMed]
51.
Datta, S.K.; Bonnet, C.; Da Costa, R.P.F.; Härri, J. Datatweet: An architecture enabling data-centric iot services. In Proceedings of
the 2016 IEEE Region 10 Symposium (TENSYMP), Bali, Indonesia, 9–11 May 2016; IEEE: Piscataway, NJ, USA, 2016; pp. 343–348.
52.
Ayele, E.D.; Meratnia, N.; Havinga, P.J. MANER: Managed data dissemination scheme for LoRa IoT enabled wildlife monitoring
system (WMS). In Proceedings of the 2018 9th IFIP International Conference on New Technologies, Mobility and Security (NTMS),
Paris, France, 26–28 February 2018; IEEE: Piscataway, NJ, USA, 2018; pp. 1–7.
53.
Juang, P.; Oki, H.; Wang, Y.; Martonosi, M.; Peh, L.S.; Rubenstein, D. Energy-efﬁcient computing for wildlife tracking: Design
tradeoffs and early experiences with ZebraNet. In Proceedings of the 10th International Conference on Architectural Support for
Programming Languages and Operating Systems, San Jose, CA, USA, 5–9 October 2002; pp. 96–107.
54.
Saleh, N.; Kassem, A.; Haidar, A.M. Energy-efﬁcient architecture for wireless sensor networks in healthcare applications. IEEE
Access 2018, 6, 6478–6486. [CrossRef]
55.
Alsina-Pagès, R.M.; Navarro, J.; Alías, F.; Hervás, M. homesound: Real-time audio event detection based on high performance
computing for behaviour and surveillance remote monitoring. Sensors 2017, 17, 854. [CrossRef] [PubMed]
56.
AbeBer, J.; Gotze, M.; Kuhnlenz, S.; Grafe, R.; Kuhn, C.; ClauB, T.; Lukashevich, H. A distributed sensor network for monitoring
noise level and noise sources in urban environments. In Proceedings of the 2018 IEEE 6th International Conference on Future
Internet of Things and Cloud (FiCloud), Barcelona, Spain, 6–8 August 2018; IEEE: Piscataway, NJ, USA, 2018; pp. 318–324.
57.
Siamwala, A.; Lochhead, Z.; Abdulla, W. Environmental noise monitoring using distributed IoT sensor nodes. In Proceedings of
the 2019 International Conference on Electronics, Information, and Communication (ICEIC), Auckland, New Zealand, 22–25
January 2019; IEEE: Piscataway, NJ, USA, 2019; pp. 1–10.
58.
Balouchestani, M.; Raahemifar, K.; Krishnan, S. Compressed sensing in wireless sensor networks: Survey. Can. J. Multimed. Wirel.
Netw. 2011, 2, 1–4.
59.
Donoho, D.L. Compressed sensing. IEEE Trans. Inf. Theory 2006, 52, 1289–1306. [CrossRef]
60.
Feizi, S.; Médard, M.; Effros, M. Compressive sensing over networks. In Proceedings of the 2010 48th Annual Allerton Conference
on Communication, Control, and Computing (Allerton), Monticello, IL, USA, 29 September–1 October 2010; IEEE: Piscataway, NJ,
USA, 2010; pp. 1129–1136.
61.
Luo, C.; Wu, F.; Sun, J.; Chen, C.W. Compressive data gathering for large-scale wireless sensor networks. In Proceedings of the
15th Annual International Conference on Mobile Computing and Networking (MobiCom), Beijing, China, 20–25 September 2009;
pp. 145–156.
62.
Luo, C.; Wu, F.; Sun, J.; Chen, C.W. Efﬁcient measurement generation and pervasive sparsity for compressive data gathering.
IEEE Trans. Wirel. Commun. 2010, 9, 3728–3738. [CrossRef]
63.
Wang, J.; Tang, S.; Yin, B.; Li, X.Y. Data gathering in wireless sensor networks through intelligent compressive sensing. In
Proceedings of the IEEE International Conference on Computer Communications (INFOCOM), Orlando, FL, USA, 25–30 March
2012; pp. 603–611.
64.
Xu, L.; Qi, X.; Wang, Y.; Moscibroda, T. Efﬁcient data gathering using compressed sparse functions. In Proceedings of the IEEE
International Conference on Computer Communications (INFOCOM), Turin, Italy, 14–19 April 2013 ; pp. 310–314.
65.
Li, S.; Da Xu, L.; Wang, X. Compressed sensing signal and data acquisition in wireless sensor networks and Internet of things.
IEEE Trans. Ind. Inform. 2012, 9, 2177–2186. [CrossRef]
66.
Dhanapala, D.C.; Bandara, V.W.; Pezeshki, A.; Jayasumana, A.P. Phenomena discovery in WSNs: A compressive sensing based
approach. In Proceedings of the IEEE International Conference on Communications (ICC), Budapest, Hungary, 9–13 June 2013;
pp. 1851–1856.
67.
Zheng, H.; Yang, F.; Tian, X.; Gan, X.; Wang, X.; Xiao, S. Data Gathering with Compressive Sensing in Wireless Sensor Networks:
A Random Walk Based Approach. IEEE Trans. Parallel Distrib. Syst. 2015, 26, 35–44. [CrossRef]
68.
Zheng, H.; Xiao, S.; Wang, X.; Tian, X. Energy and latency analysis for in-network computation with compressive sensing in
wireless sensor networks. In Proceedings of the IEEE International Conference on Computer Communications (INFOCOM),
Orlando, FL, USA, 25–30 March 2012; pp. 2811–2815.
69.
Xu, X.; Ansari, R.; Khokhar, A.; Vasilakos, A. Hierarchical data aggregation using compressive sensing (HDACS) in WSNs. ACM
Trans. Sens. Netw. 2015, 11, 1–25. [CrossRef]
Sensors 2022, 22, 2650
38 of 44
70.
Lan, K.; Wei, M. A Compressibility-Based Clustering Algorithm for Hierarchical Compressive Data Gathering. IEEE Sens. J. 2017,
17, 2550–2562. [CrossRef]
71.
Wu, X.; Xiong, Y.; Yang, P.; Wan, S.; Huang, W. Sparsest Random Scheduling for Compressive Data Gathering in Wireless Sensor
Networks. IEEE Trans. Wirel. Commun. 2014, 13, 5867–5877. [CrossRef]
72.
Yin, J.; Yang, Y.; Wang, L. An Adaptive Data Gathering Scheme for Multi-Hop Wireless Sensor Networks Based on Compressed
Sensing and Network Coding. Sensors 2016, 16, 462. [CrossRef] [PubMed]
73.
Xu, W.; Mallada, E.; Tang, A. Compressive sensing over graphs.
In Proceedings of the IEEE International Conference on
Computer Communications (INFOCOM), Shanghai, China, 10–15 April 2011; pp. 2087–2095.
74.
Zheng, H.; Xiao, S.; Wang, X.; Tian, X.; Guizani, M. Capacity and Delay Analysis for Data Gathering with Compressive Sensing in
Wireless Sensor Networks. IEEE Trans. Wirel. Commun. 2013, 12, 917–927. [CrossRef]
75.
Akyildiz, I.F.; Vuran, M.C. Wireless Sensor Networks; John Wiley & Sons: Hoboken, NJ, USA, 2010; Volume 4.
76.
Kumar, A.; Zhao, M.; Wong, K.J.; Guan, Y.L.; Chong, P.H.J. A comprehensive study of iot and wsn mac protocols: Research issues,
challenges and opportunities. IEEE Access 2018, 6, 76228–76262. [CrossRef]
77.
Quintero, V.L.; Estevez, C.; Orchard, M.E.; Pérez, A. Improvements of energy-efﬁcient techniques in WSNs: A MAC-protocol
approach. IEEE Commun. Surv. Tutor. 2018, 21, 1188–1208. [CrossRef]
78.
Ye, W.; Heidemann, J.; Estrin, D. An energy-efﬁcient MAC protocol for wireless sensor networks.
In Proceedings of the
Twenty-First Annual Joint Conference of the IEEE Computer and Communications Societies, New York, NY, USA, 23–27 June
2002; IEEE: Piscataway, NJ, USA, 2002; Volume 3, pp. 1567–1576.
79.
Van Dam, T.; Langendoen, K. An adaptive energy-efﬁcient MAC protocol for wireless sensor networks. In Proceedings of the
1st International Conference on Embedded Networked Sensor Systems (SenSys), Los Angeles, CA, USA, 5–7 November 2003 ;
pp. 171–180.
80.
Sun, Y.; Du, S.; Gurewitz, O.; Johnson, D.B. DW-MAC: A low latency, energy efﬁcient demand-wakeup MAC protocol for wireless
sensor networks. In Proceedings of the 9th ACM International Symposium on Mobile Ad Hoc Networking and Computing,
Hong Kong, China, 26–30 May 2008; pp. 53–62.
81.
Polastre, J.; Hill, J.; Culler, D. Versatile low power media access for wireless sensor networks. In Proceedings of the 2nd Interna-
tional Conference on Embedded Networked Sensor Systems (SenSys), Baltimore, MD, USA, 3–5 November 2004; pp. 95–107.
82.
Buettner, M.; Yee, G.V.; Anderson, E.; Han, R. X-MAC: A short preamble MAC protocol for duty-cycled wireless sensor networks.
In Proceedings of the 4th International Conference on Embedded Networked Sensor Systems (SenSys), Boulder, CO, USA,
31 October–3 November 2006; pp. 307–320.
83.
El-Hoiydi, A.; Decotignie, J.D. WiseMAC: An ultra low power MAC protocol for the downlink of infrastructure wireless sensor
networks. In Proceedings of the ISCC 2004. Ninth International Symposium on Computers And Communications (IEEE Cat.
No. 04TH8769), Alexandria, Egypt, 28–31 July 2004; IEEE: Piscataway, NJ, USA, 2004; Volume 1, pp. 244–251.
84.
Sun, Y.; Gurewitz, O.; Johnson, D.B. RI-MAC: A receiver-initiated asynchronous duty cycle MAC protocol for dynamic trafﬁc
loads in wireless sensor networks. In Proceedings of the 6th ACM Conference on Embedded Network Sensor Systems (SenSys),
Raleigh, NC, USA, 5–7 November 2008; pp. 1–14.
85.
Tang, L.; Sun, Y.; Gurewitz, O.; Johnson, D.B. PW-MAC: An energy-efﬁcient predictive-wakeup MAC protocol for wireless sensor
networks. In Proceedings of the IEEE Conference on Computer Communications (INFOCOM), Shanghai, China, 10–15 April
2011; pp. 1305–1313.
86.
Zhang, D.g.; Zhou, S.; Tang, Y.m. A low duty cycle efﬁcient MAC protocol based on self-adaption and predictive strategy. Mob.
Netw. Appl. 2018, 23, 828–839. [CrossRef]
87.
Dutta, P.; Dawson-Haggerty, S.; Chen, Y.; Liang, C.J.M.; Terzis, A. A-MAC: A versatile and efﬁcient receiver-initiated link layer
for low-power wireless. ACM Trans. Sens. Netw. 2012, 8, 1–29. [CrossRef]
88.
Wymore, M.L.; Qiao, D. RIVER-MAC: A Receiver-Initiated Asynchronously Duty-Cycled MAC Protocol for the Internet of
Things. In Proceedings of the IEEE 43rd Annual Computer Software and Applications Conference (COMPSAC), Milwaukee, WI,
USA, 15–19 July 2019; Volume 1, pp. 860–869.
89.
Gurewitz, O.; Zaharia, O. Collision Prevention for Duty-Cycle Receiver-Initiation MAC Protocol via Multiple Access Reservation
(MAR-RiMAC). Sensors 2021, 21, 127. [CrossRef] [PubMed]
90.
Liu, H.I.; He, W.J.; Seah, W.K. LEB-MAC: Load and energy balancing MAC protocol for energy harvesting powered wireless
sensor networks. In Proceedings of the 2014 20th IEEE International Conference on Parallel and Distributed Systems (ICPADS),
Hsinchu, Taiwan, 16–19 December 2014; IEEE: Piscataway, NJ, USA, 2014; pp. 584–591.
91.
Khalil, M.I.; Hossain, M.A.; Ahmed, I. DURI-MAC: A dual channel receiver initiated MAC protocol for wireless sensor network
(WSN). In Proceedings of the International Conference on Electrical, Computer and Communication Engineering (ECCE), Cox’s
Bazar, Bangladesh, 16–18 February 2017; IEEE: Piscataway, NJ, USA, 2017; pp. 577–582.
92.
Tang, L.; Sun, Y.; Gurewitz, O.; Johnson, D.B. EM-MAC: A dynamic multichannel energy-efﬁcient MAC protocol for wireless
sensor networks. In Proceedings of the Twelfth ACM International Symposium on Mobile Ad Hoc Networking and Computing
(MobiHoc), Paris, France, 17–19 May 2011; pp. 1–11.
93.
Ye, D.; Zhang, M. A self-adaptive sleep/wake-up scheduling approach for wireless sensor networks. IEEE Trans. Cybern. 2017,
48, 979–992. [CrossRef]
Sensors 2022, 22, 2650
39 of 44
94.
Gamm, G.U.; Sippel, M.; Kostic, M.; Reindl, L.M. Low power wake-up receiver for wireless sensor nodes. In Proceedings of the
IEEE Sixth International Conference on Intelligent Sensors, Sensor Networks and Information Processing (ISSNIP), Brisbane,
Australia, 7–10 December 2010; pp. 121–126.
95.
Oller, J.; Demirkol, I.; Casademont, J.; Paradells, J.; Gamm, G.U.; Reindl, L. Performance evaluation and comparative analysis of
subcarrier modulation wake-up radio systems for energy-efﬁcient wireless sensor networks. Sensors 2014, 14, 22–51. [CrossRef]
[PubMed]
96.
Oller, J.; Demirkol, I.; Casademont, J.; Paradells, J.; Gamm, G.U.; Reindl, L. Has time come to switch from duty-cycled MAC
protocols to wake-up radio for wireless sensor networks? IEEE/ACM Trans. Netw. 2015, 24, 674–687. [CrossRef]
97.
Spenza, D.; Magno, M.; Basagni, S.; Benini, L.; Paoli, M.; Petrioli, C. Beyond duty cycling: Wake-up radio with selective
awakenings for long-lived wireless sensing systems. In Proceedings of the IEEE Conference on Computer Communications
(INFOCOM), Hong Kong, China, 26 April–1 May 2015; pp. 522–530.
98.
Ghose, D.; Li, F.Y. Enabling backoff for SCM wake-up radio: Protocol and modeling. IEEE Commun. Lett. 2017, 21, 1031–1034.
[CrossRef]
99.
Ghose, D.; Frøytlog, A.; Li, F.Y. Enabling early sleeping and early data transmission in wake-up radio-enabled IoT networks.
Comput. Netw. 2019, 153, 132–144. [CrossRef]
100. Guntupalli, L.; Ghose, D.; Li, F.Y.; Gidlund, M. Energy efﬁcient consecutive packet transmissions in receiver-initiated wake-up
radio enabled wsns. IEEE Sens. J. 2018, 18, 4733–4745. [CrossRef]
101. Singh, R.; Sikdar, B. A Receiver Initiated Low Delay MAC Protocol for Wake-Up Radio Enabled Wireless Sensor Networks. IEEE
Sens. J. 2020, 20, 13796–13807. [CrossRef]
102. Hawa, M.; Darabkh, K.A.; Al-Zubi, R.; Al-Sukkar, G. A self-learning MAC protocol for energy harvesting and spectrum access in
cognitive radio sensor networks. J. Sens. 2016, 2016, 9604526. [CrossRef]
103. Cohen, A.; Cohen, A.; Gurewitz, O. Efﬁcient data collection over multiple access wireless sensors network. IEEE/ACM Trans.
Netw. 2020, 28, 491–504. [CrossRef]
104. Tong, F.; Peng, Y. A Data-Gathering, Dynamic Duty-Cycling MAC Protocol for Large-Scale Wireless Sensor Networks. Sensors
2020, 20, 4071. [CrossRef] [PubMed]
105. Heinzelman, W.R.; Chandrakasan, A.; Balakrishnan, H. Energy-efﬁcient communication protocol for wireless microsensor
networks. In Proceedings of the 33rd Annual Hawaii International Conference on System Sciences, Maui, HI, USA, 7 January
2000; IEEE: Piscataway, NJ, USA, 2000; p. 10.
106. Arumugam, G.S.; Ponnuchamy, T. EE-LEACH: Development of energy-efﬁcient LEACH Protocol for data gathering in WSN.
EURASIP J. Wirel. Commun. Netw. 2015, 2015, 1–9. [CrossRef]
107. Singh, S.K.; Kumar, P.; Singh, J.P. A survey on successors of LEACH protocol. IEEE Access 2017, 5, 4298–4328. [CrossRef]
108. Anzola, J.; Pascual, J.; Tarazona, G.; Gonzalez Crespo, R. A clustering WSN routing protocol based on kd tree algorithm. Sensors
2018, 18, 2899. [CrossRef] [PubMed]
109. Lindsey, S.; Raghavendra, C.; Sivalingam, K.M. Data gathering algorithms in sensor networks using energy metrics. IEEE Trans.
Parallel Distrib. Syst. 2002, 13, 924–935. [CrossRef]
110. Razaque, A.; Abdulgader, M.; Joshi, C.; Amsaad, F.; Chauhan, M. P-LEACH: Energy efﬁcient routing protocol for Wireless Sensor
Networks. In Proceedings of the 2016 IEEE Long Island Systems, Applications and Technology Conference (LISAT), Farmingdale,
NY, USA, 29–29 April 2016; IEEE: Piscataway, NJ, USA, 2016; pp. 1–5.
111. Siew, Z.W.; Wong, C.H.; Chin, C.S.; Kiring, A.; Teo, K.T.K. Cluster heads distribution of wireless sensor networks via adaptive
particle swarm optimization.
In Proceedings of the 2012 Fourth International Conference on Computational Intelligence,
Communication Systems and Networks, Phuket, Thailand, 24–26 July 2012; IEEE: Piscataway, NJ, USA, 2012; pp. 78–83.
112. Tam, N.T.; Hai, D.T.; Son, L.H.; Vinh, L.T. Improving lifetime and network connections of 3D wireless sensor networks based on
fuzzy clustering and particle swarm optimization. Wirel. Netw. 2018, 24, 1477–1490. [CrossRef]
113. Cui, Z.; Cao, Y.; Cai, X.; Cai, J.; Chen, J. Optimal LEACH protocol with modiﬁed bat algorithm for big data sensing systems in
Internet of Things. J. Parallel Distrib. Comput. 2019, 132, 217–229. [CrossRef]
114. Jiang, A.; Zheng, L. An effective hybrid routing algorithm in WSN: Ant colony optimization in combination with hop count
minimization. Sensors 2018, 18, 1020. [CrossRef]
115. Rodríguez, A.; Del-Valle-Soto, C.; Velázquez, R. Energy-Efﬁcient Clustering Routing Protocol for Wireless Sensor Networks
Based on Yellow Saddle Goatﬁsh Algorithm. Mathematics 2020, 8, 1515. [CrossRef]
116. Karunanithy, K.; Velusamy, B. Cluster-tree based energy efﬁcient data gathering protocol for industrial automation using WSNs
and IoT. J. Ind. Inf. Integr. 2020, 19, 100156. [CrossRef]
117. Mehmood, A.; Lv, Z.; Lloret, J.; Umar, M.M. ELDC: An artiﬁcial neural network based energy-efﬁcient and robust routing scheme
for pollution monitoring in WSNs. IEEE Trans. Emerg. Top. Comput. 2017, 8, 106–114. [CrossRef]
118. Durairaj, U.M.; Selvaraj, S. Two-Level Clustering and Routing Algorithms to Prolong the Lifetime of Wind Farm-Based WSN.
IEEE Sens. J. 2020, 21, 857–867. [CrossRef]
119. Shifrin, M.; Cidon, I. C3: Collective congestion control in multi-hop wireless networks. In Proceedings of the 2010 Seventh
International Conference on Wireless On-demand Network Systems and Services (WONS), Kranjska Gora, Slovenia, 3–5 February
2010; IEEE: Piscataway, NJ, USA, 2010; pp. 31–38.
Sensors 2022, 22, 2650
40 of 44
120. Biswas, S.; Morris, R. ExOR: Opportunistic multi-hop routing for wireless networks. In Proceedings of the 2005 Conference on
Applications, Technologies, Architectures, and Protocols for Computer Communications, Philadelphia, PA, USA, 22–26 August
2005; pp. 133–144.
121. Ye, Z.; Hua, Y. On link layer policies of data forwarding over wireless relays. In Proceedings of the MILCOM 2005—2005
IEEE Military Communications Conference, Atlantic City, NJ, USA, 17–20 October 2005; IEEE: Piscataway, NJ, USA, 2005;
pp. 2138–2144.
122. Landsiedel, O.; Ghadimi, E.; Duquennoy, S.; Johansson, M. Low power, low delay: Opportunistic routing meets duty cycling. In
Proceedings of the 2012 ACM/IEEE 11th International Conference on Information Processing in Sensor Networks (IPSN), Beijing,
China, 16–20 April 2012; IEEE: Piscataway, NJ, USA, 2012; pp. 185–196.
123. Tang, L.; Sun, Y.; Gurewitz, O.; Johnson, D.B. Optimizations for route discovery in asynchronous duty-cycling wireless networks.
In Proceedings of the 2012 IEEE 9th International Conference on Mobile Ad-Hoc and Sensor Systems (MASS 2012), Las Vegas,
NV, USA, 8–11 October 2012; IEEE: Piscataway, NJ, USA, 2012; pp. 155–163.
124. Liu, D.; Hou, M.; Cao, Z.; Wang, J.; He, Y.; Liu, Y. Duplicate detectable opportunistic forwarding in duty-cycled wireless sensor
networks. IEEE/ACM Trans. Netw. 2015, 24, 662–673. [CrossRef]
125. Hawbani, A.; Wang, X.; Sharabi, Y.; Ghannami, A.; Kuhlani, H.; Karmoshi, S. LORA: Load-balanced opportunistic routing for
asynchronous duty-cycled WSN. IEEE Trans. Mob. Comput. 2018, 18, 1601–1615. [CrossRef]
126. Winter, T.; Thubert, P.; Brandt, A.; Hui, J.W.; Kelsey, R.; Levis, P.; Pister, K.; Struik, R.; Vasseur, J.P.; Alexander, R.K.; et al. RPL:
IPv6 Routing Protocol for Low-Power and Lossy Networks. RFC 2012, 6550, 1–157.
127. Thubert, P. Objective function zero for the routing protocol for low-power and lossy networks (RPL). RFC 2012, 6552, 1–14.
128. Gnawali, O.; Levis, P. The minimum rank with hysteresis objective function. RFC 2012, 6719, 1–13.
129. Abdel Hakeem, S.A.; Hady, A.A.; Kim, H. RPL routing protocol performance in smart grid applications based wireless sensors:
Experimental and simulated analysis. Electronics 2019, 8, 186. [CrossRef]
130. Barnawi, A.Y.; Mohsen, G.A.; Shahra, E.Q. Performance analysis of RPL protocol for data gathering applications in wireless
sensor networks. Procedia Comput. Sci. 2019, 151, 185–193. [CrossRef]
131. Al-Shargabi, B.; Aleswid, M. Performance of RPL in Healthcare Wireless Sensor Network. Int. J. Emerg. Trends Eng. Res. 2020, 8, 3.
[CrossRef]
132. Sousa, N.; Sobral, J.V.; Rodrigues, J.J.; Rabêlo, R.A.; Solic, P. ERAOF: A new RPL protocol objective function for Internet of
Things applications. In Proceedings of the 2017 2nd International Multidisciplinary Conference on Computer and Energy Science
(SpliTech), Split, Croatia, 12–14 July 2017; IEEE: Piscataway, NJ, USA, 2017; pp. 1–5.
133. Rafea, S.A.; Kadhim, A.A. Routing with energy threshold for WSN-IoT based on RPL protocol. Iraqi J. Comput. Commun. Control
Syst. Eng. 2019, 19, 71–81.
134. Sharma, B.; Gajrani, J.; Jain, V. Performance Measurement of RPL Protocol Using Modiﬁed MRHOF in IoT Network.
In
Proceedings of the International Conference on Deep Learning, Artiﬁcial Intelligence and Robotics, Jaipur, India, 7–8 December
2019; Springer: Berlin/Heidelberg, Germany, 2019; pp. 235–245.
135. Sankar, S.; Ramasubbareddy, S.; Luhach, A.K.; Nayyar, A.; Qureshi, B. CT-RPL: Cluster tree based routing protocol to maximize
the lifetime of Internet of Things. Sensors 2020, 20, 5858. [CrossRef] [PubMed]
136. Acevedo, P.D.; Jabba, D.; Sanmartín, P.; Valle, S.; Nino-Ruiz, E.D. WRF-RPL: Weighted Random Forward RPL for High Trafﬁc and
Energy Demanding Scenarios. IEEE Access 2021, 9, 60163–60174. [CrossRef]
137. Rojas, E.; Hosseini, H.; Gomez, C.; Carrascal, D.; Cotrim, J.R. Outperforming RPL with scalable routing based on meaningful
MAC addressing. Ad Hoc Netw. 2021, 114, 102433. [CrossRef]
138. Molnár, M. QoS Routing for Data Gathering with RPL in WSNs. In Handbook of Wireless Sensor Networks: Issues and Challenges in
Current Scenario’s; Springer: Berlin/Heidelberg, Germany, 2020; pp. 87–111.
139. Vera-Pérez, J.; Silvestre-Blanes, J.; Sempere-Payá, V. TSCH and RPL Joining Time Model for Industrial Wireless Sensor Networks.
Sensors 2021, 21, 3904. [CrossRef] [PubMed]
140. Sobral, J.V.; Rodrigues, J.J.; Rabêlo, R.A.; Al-Muhtadi, J.; Korotaev, V. Routing protocols for low power and lossy networks in
Internet of things applications. Sensors 2019, 19, 2144. [CrossRef]
141. Jeong, S.; Kim, H.; Noh, D.K.; Yoon, I. Energy-aware data aggregation scheme for energy-harvesting wireless sensor networks. In
Proceedings of the 2016 First IEEE International Conference on Computer Communication and the Internet (ICCCI), Wuhan,
China, 13–15 October 2016; IEEE: Piscataway, NJ, USA, 2016; pp. 140–143.
142. Chen, Q.; Gao, H.; Cai, Z.; Cheng, L.; Li, J. Energy-collision aware data aggregation scheduling for energy harvesting sensor
networks. In Proceedings of the IEEE INFOCOM 2018—IEEE Conference on Computer Communications, Honolulu, HI, USA,
16–19 April 2018; IEEE: Piscataway, NJ, USA, 2018; pp. 117–125.
143. Xiao, M.; Zhang, X.; Dong, Y. An effective routing protocol for energy harvesting wireless sensor networks. In Proceedings of the
2013 IEEE Wireless Communications and Networking Conference (WCNC), Shanghai, China, 7–10 April 2013; IEEE: Piscataway,
NJ, USA, 2013; pp. 2080–2084.
144. Wu, D.; He, J.; Wang, H.; Wang, C.; Wang, R. A hierarchical packet forwarding mechanism for energy harvesting wireless sensor
networks. IEEE Commun. Mag. 2015, 53, 92–98. [CrossRef]
145. Yang, L.; Lu, Y.; Zhong, Y.; Wu, X.; Yang, S.X. A multi-hop energy neutral clustering algorithm for maximizing network
information gathering in energy harvesting wireless sensor networks. Sensors 2016, 16, 26. [CrossRef] [PubMed]
Sensors 2022, 22, 2650
41 of 44
146. Bahbahani, M.S.; Alsusa, E. A cooperative clustering protocol with duty cycling for energy harvesting enabled wireless sensor
networks. IEEE Trans. Wirel. Commun. 2017, 17, 101–111. [CrossRef]
147. Bozorgi, S.M.; Rostami, A.S.; Hosseinabadi, A.A.R.; Balas, V.E. A new clustering protocol for energy harvesting-wireless sensor
networks. Comput. Electr. Eng. 2017, 64, 233–247. [CrossRef]
148. Ren, Q.; Yao, G. An energy-efﬁcient cluster head selection scheme for energy-harvesting wireless sensor networks. Sensors 2020,
20, 187. [CrossRef] [PubMed]
149. Sinde, R.; Begum, F.; Njau, K.; Kaijage, S. Reﬁning network lifetime of wireless sensor network using energy-efﬁcient clustering
and DRL-based sleep scheduling. Sensors 2020, 20, 1540. [CrossRef]
150. Liu, F.; Lu, H.; Wang, T.; Liu, Y. An energy-balanced joint routing and charging framework in wireless rechargeable sensor
networks for mobile multimedia. IEEE Access 2019, 7, 177637–177650. [CrossRef]
151. Lu, Z.; Fan, B.; Cai, J.; Tang, L. J-RCA: A Joint Routing and Charging Algorithm With WCE Assisted Data Gathering in Wireless
Rechargeable Sensor Networks. IEEE Sens. J. 2020, 21, 3888–3899. [CrossRef]
152. Du, L. A polynomial time algorithm for Hamilton Cycle and its proof. In Proceedings of the 2010 International Conference
On Computer Design and Applications, Qinhuangdao, China, 25–27 June 2010; IEEE: Piscataway, NJ, USA, 2010; Volume 3;
pp. 3–207.
153. Celebiler, M.; Stette, G. On increasing the down-link capacity of a regenerative satellite repeater in point-to-point communications.
Proc. IEEE 1978, 66, 98–100. [CrossRef]
154. Ahlswede, R.; Cai, N.; Li, S.Y.; Yeung, R.W. Network information ﬂow. IEEE Trans. Inf. Theory 2000, 46, 1204–1216. [CrossRef]
155. Katti, S.; Rahul, H.; Hu, W.; Katabi, D.; Médard, M.; Crowcroft, J. XORs in the air: Practical wireless network coding. IEEE/ACM
Trans. Netw. 2008, 16, 497–510. [CrossRef]
156. Migabo, E.M.; Djouani, K.; Olwal, T.O.; Kurien, A.M. A Survey on Energy Efﬁcient Network Coding for Multi-hop Routing in
Wireless Sensor Networks. Procedia Comput. Sci. 2016, 94, 288–294. [CrossRef]
157. Cohen, A.; Biton, E.; Kampeas, J.; Gurewitz, O. Coded unicast downstream trafﬁc in a wireless network: Analysis and WiFi
implementation. EURASIP J. Adv. Signal Process. 2013, 2013, 1–20. [CrossRef]
158. Shifrin, M.; Cohen, A.; Weisman, O.; Gurewitz, O. Coded retransmission in wireless networks via abstract MDPs: Theory and
algorithms. IEEE Trans. Wirel. Commun. 2016, 15, 4292–4306. [CrossRef]
159. Attar, H.; Stankovic, L.; Stankovic, V. Cooperative network-coding system for wireless sensor networks. IET Commun. 2012,
6, 344–352. [CrossRef]
160. Qureshi, J.; Foh, C.H.; Cai, J. Optimal solution for the index coding problem using network coding over GF(2). In Proceedings of
the 2012 9th Annual IEEE Communications Society Conference on Sensor, Mesh and Ad Hoc Communications and Networks
(SECON), Seoul, Korea, 18–21 June 2012; pp. 209–217.
161. Gou, L.; Zhang, G.; Bian, D.; Zhang, W.; Xie, Z. Data dissemination in wireless sensor networks with instantly decodable network
coding. J. Commun. Netw. 2016, 18, 846–856. [CrossRef]
162. Júnior, N.D.S.R.; Tavares, R.C.; Vieira, M.A.; Vieira, L.F.; Gnawali, O. CodeDrip: Improving data dissemination for wireless sensor
networks with network coding. Ad Hoc Netw. 2017, 54, 42–52. [CrossRef]
163. Swamy, V.N.; Rigge, P.; Ranade, G.; Sahai, A.; Nikoli´c, B. Network coding for high-reliability low-latency wireless control. In
Proceedings of the 2016 IEEE Wireless Communications and Networking Conference Workshops (WCNCW), Doha, Qatar, 3–6
April 2016; IEEE: Piscataway, NJ, USA, 2016; pp. 138–144.
164. Ho, T.; Médard, M.; Koetter, R.; Karger, D.R.; Effros, M.; Shi, J.; Leong, B. A random linear network coding approach to multicast.
IEEE Trans. Inf. Theory 2006, 52, 4413–4430. [CrossRef]
165. Stefanovi´c, ˇC.; Vukobratovi´c, D.; Crnojevi´c, V.; Stankovic, V. A random linear coding scheme with perimeter data gathering for
wireless sensor networks. In Proceedings of the 2011 Eighth International Conference on Wireless On-Demand Network Systems
and Services, Bardonecchia, Italy, 26–28 January 2011; IEEE: Piscataway, NJ, USA, 2011; pp. 142–145.
166. Feizi, S.; Lucani, D.E.; Médard, M. Tunable sparse network coding. In Proceedings of the 22th International Zurich Seminar on
Communications (IZS). Eidgenössische Technische Hochschule Zürich, Zurich, Switzerland, 29 February–2 March 2012.
167. Prior, R.; Lucani, D.E.; Phulpin, Y.; Nistor, M.; Barros, J. Network coding protocols for smart grid communications. IEEE Trans.
Smart Grid 2014, 5, 1523–1531. [CrossRef]
168. Nistor, M.; Lucani, D.E.; Barros, J. Network coding protocols for data gathering applications.
IEEE Commun. Lett. 2014,
19, 267–270. [CrossRef]
169. Keller, L.; Atsan, E.; Argyraki, K.; Fragouli, C. SenseCode: Network coding for reliable sensor networks. ACM Trans. Sens. Netw.
(TOSN) 2013, 9, 1–20. [CrossRef]
170. Valle, O.T.; Montez, C.; Medeiros de Araujo, G.; Vasques, F.; Moraes, R. NetCoDer: A retransmission mechanism for WSNs based
on cooperative relays and network coding. Sensors 2016, 16, 799. [CrossRef]
171. Merhi, Z.; Tahan, O.; Abdulhay, B.; Rammal, R.; Abdul-Nabi, S. SR-Code: Smart Relay Network Coding for Data Collection for
Wireless Sensor Networks. Int. J. Eng. Res. Appl. 2017, 7, 58–64. [CrossRef]
172. Al-Hawri, E.; Correia, N.; Barradas, A. Design of network coding based reliable sensor networks. Ad Hoc Netw. 2019, 91, 101870.
[CrossRef]
173. Chen, W.; Letaief, K.B.; Cao, Z. Opportunistic Network Coding for Wireless Networks.
In Proceedings of the 2007 IEEE
International Conference on Communications, Glasgow, UK, 24–28 June 2007; pp. 4634–4639.
Sensors 2022, 22, 2650
42 of 44
174. Mirani, F.H.; Busson, A.; Adjih, C. DONC: Delay-based Opportunistic Network Coding Protocol. In Proceedings of the 2013 12th
Annual Mediterranean Ad Hoc Networking Workshop (MED-HOC-NET), Ajaccio, France, 24–26 June 2013; pp. 34–41.
175. Tan, C.; Zou, J.; Wang, M. Joint Opportunistic Network Coding and Opportunistic Routing for Correlated Data Gathering in
Wireless Sensor Network. In Proceedings of the 2013 IEEE 78th Vehicular Technology Conference (VTC Fall), Las Vegas, NV,
USA, 2–5 September 2013; pp. 1–5.
176. Marques, B.; Machado, I.; Sena, A.; Castro, M.C. A communication protocol for fog computing based on network coding applied
to wireless sensors. In Proceedings of the 2017 International Symposium on Computer Architecture and High Performance
Computing Workshops (SBAC-PADW), Campinas, Brazil, 17–20 October 2017; IEEE: Piscataway, NJ, USA, 2017; pp. 109–114.
177. Uwitonze, A.; Huang, J.; Ye, Y.; Cheng, W. Connectivity restoration in wireless sensor networks via space network coding. Sensors
2017, 17, 902. [CrossRef] [PubMed]
178. Malathy, S.; Porkodi, V.; Sampathkumar, A.; Hindia, M.N.; Dimyati, K.; Tilwari, V.; Qamar, F.; Amiri, I.S. An optimal network
coding based backpressure routing approach for massive IoT network. Wirel. Netw. 2020, 26, 3657–3674. [CrossRef]
179. Zhan, C.; Zeng, Y.; Zhang, R. Energy-efﬁcient data collection in UAV enabled wireless sensor network. IEEE Wirel. Commun. Lett.
2017, 7, 328–331. [CrossRef]
180. Gong, J.; Chang, T.H.; Shen, C.; Chen, X. Flight time minimization of UAV for data collection over wireless sensor networks.
IEEE J. Sel. Areas Commun. 2018, 36, 1942–1954. [CrossRef]
181. Liu, J.; Wang, X.; Bai, B.; Dai, H. Age-optimal trajectory planning for UAV-assisted data collection. In Proceedings of the IEEE
INFOCOM 2018—IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS), Honolulu, HI, USA, 15–19
April 2018; IEEE: Piscataway, NJ, USA, 2018; pp. 553–558.
182. Liu, S.; Wei, Z.; Guo, Z.; Yuan, X.; Feng, Z. Performance analysis of UAVs assisted data collection in wireless sensor network.
In Proceedings of the 2018 IEEE 87th Vehicular Technology Conference (VTC Spring), Porto, Portugal, 3–6 June 2018; IEEE:
Piscataway, NJ, USA, 2018; pp. 1–5.
183. Qin, Y.; Boyle, D.; Yeatman, E. A novel protocol for data links between wireless sensors and UAV based sink nodes. In Proceedings
of the 2018 IEEE 4th World Forum on Internet of Things (WF-IoT), Singapore, 5–8 February 2018; IEEE: Piscataway, NJ, USA,
2018; pp. 371–376.
184. Najjar-Ghabel, S.; Farzinvash, L.; Razavi, S.N. Mobile sink-based data gathering in wireless sensor networks with obstacles using
artiﬁcial intelligence algorithms. Ad Hoc Netw. 2020, 106, 102243. [CrossRef]
185. Tazibt, C.Y.; Bekhti, M.; Djamah, T.; Achir, N.; Boussetta, K. Wireless sensor network clustering for UAV-based data gathering. In
Proceedings of the 2017 Wireless Days, Porto, Portugal, 29–31 March 2017; IEEE: Piscataway, NJ, USA, 2017; pp. 245–247.
186. Kumar, N.; Dash, D. Flow based efﬁcient data gathering in wireless sensor network using path-constrained mobile sink. J. Ambient.
Intell. Humaniz. Comput. 2020, 11, 1163–1175. [CrossRef]
187. Ebrahimi, D.; Sharafeddine, S.; Ho, P.H.; Assi, C. UAV-aided projection-based compressive data gathering in wireless sensor
networks. IEEE Internet Things J. 2019, 6, 1893–1905. [CrossRef]
188. Wu, Q.; Sun, P.; Boukerche, A. An energy-efﬁcient uav-based data aggregation protocol in wireless sensor networks.
In
Proceedings of the 8th ACM Symposium on Design and Analysis of Intelligent Vehicular Networks and Applications, Montreal,
QC, Canada, 28 October–2 November 2018; pp. 34–40.
189. Zahra, M.; Wang, Y.; Ding, W. Cross-layer routing for a mobility support protocol based on handover mechanism in cluster-based
wireless sensor networks with mobile sink. Sensors 2019, 19, 2843. [CrossRef] [PubMed]
190. Zhang, R.; Pan, J.; Xie, D.; Wang, F. NDCMC: A hybrid data collection approach for large-scale WSNs using mobile element and
hierarchical clustering. IEEE Internet Things J. 2015, 3, 533–543. [CrossRef]
191. Say, S.; Inata, H.; Liu, J.; Shimamoto, S. Priority-based data gathering framework in UAV-assisted wireless sensor networks. IEEE
Sens. J. 2016, 16, 5785–5794. [CrossRef]
192. Rault, T.; Bouabdallah, A.; Challal, Y.; Marin, F. A survey of energy-efﬁcient context recognition systems using wearable sensors
for healthcare applications. Pervasive Mob. Comput. 2017, 37, 23–44. [CrossRef]
193. Leonov, V. Thermoelectric energy harvesting of human body heat for wearable sensors. IEEE Sens. J. 2013, 13, 2284–2291.
[CrossRef]
194. Khalifa, S.; Hassan, M.; Seneviratne, A.; Das, S.K. Energy-harvesting wearables for activity-aware services. IEEE Internet Comput.
2015, 19, 8–16. [CrossRef]
195. Park, J.; Joshi, H.; Lee, H.G.; Kiaei, S.; Ogras, U.Y. Flexible PV-cell modeling for energy harvesting in wearable IoT applications.
ACM Trans. Embed. Comput. Syst. 2017, 16, 1–20. [CrossRef]
196. Park, J.; Bhat, G.; Nk, A.; Geyik, C.S.; Ogras, U.Y.; Lee, H.G. Energy per operation optimization for energy-harvesting wearable
IoT devices. Sensors 2020, 20, 764. [CrossRef] [PubMed]
197. Esteves, V.; Antonopoulos, A.; Kartsakli, E.; Puig-Vidal, M.; Miribel-Català, P.; Verikoukis, C. Cooperative energy harvesting-
adaptive MAC protocol for WBANs. Sensors 2015, 15, 12635–12650. [CrossRef]
198. Bariya, M.; Nyein, H.Y.Y.; Javey, A. Wearable sweat sensors. Nat. Electron. 2018, 1, 160–171. [CrossRef]
199. Gao, W.; Nyein, H.Y.Y.; Shahpar, Z.; Tai, L.C.; Wu, E.; Bariya, M.; Ota, H.; Fahad, H.M.; Chen, K.; Javey, A. Wearable sweat
biosensors. In Proceedings of the 2016 IEEE International Electron Devices Meeting (IEDM), San Francisco, CA, USA, 3–7
December 2016. [CrossRef]
Sensors 2022, 22, 2650
43 of 44
200. Bandodkar, A.J.; Jia, W.; Yardımcı, C.; Wang, X.; Ramirez, J.; Wang, J. Tattoo-based noninvasive glucose monitoring: A proof-of-
concept study. Anal. Chem. 2015, 87, 394–398. [CrossRef] [PubMed]
201. Salvo, P.; Di Francesco, F.; Costanzo, D.; Ferrari, C.; Trivella, M.G.; De Rossi, D. A wearable sensor for measuring sweat rate. IEEE
Sens. J. 2010, 10, 1557–1558. [CrossRef]
202. Sim, J.K.; Yoon, S.; Cho, Y.H. Wearable sweat rate sensors for human thermal comfort monitoring. Sci. Rep. 2018, 8, 1181.
[CrossRef] [PubMed]
203. Song, Y.; Min, J.; Yu, Y.; Wang, H.; Yang, Y.; Zhang, H.; Gao, W. Wireless battery-free wearable sweat sensor powered by human
motion. Sci. Adv. 2020, 6, eaay9842. [CrossRef] [PubMed]
204. Tai, L.C.; Gao, W.; Chao, M.; Bariya, M.; Ngo, Q.P.; Shahpar, Z.; Nyein, H.Y.; Park, H.; Sun, J.; Jung, Y.; et al. Methylxanthine drug
monitoring with wearable sweat sensors. Adv. Mater. 2018, 30, 1707442. [CrossRef]
205. Ferrer-Vidal, A.; Rida, A.; Basat, S.; Yang, L.; Tentzeris, M.M. Integration of sensors and RFID’s on ultra-low-cost paper-based
substrates for wireless sensor networks applications. In Proceedings of the 2006 2nd IEEE Workshop on Wireless Mesh Networks,
Reston, VA, USA, 25–28 September 2006; IEEE: Piscataway, NJ, USA, 2006; pp. 126–128.
206. Li, K.; Habre, R.; Deng, H.; Urman, R.; Morrison, J.; Gilliland, F.D.; Ambite, J.L.; Stripelis, D.; Chiang, Y.Y.; Lin, Y.; et al. Applying
multivariate segmentation methods to human activity recognition from wearable sensors’ data. JMIR mHealth uHealth 2019,
7, e11201. [CrossRef] [PubMed]
207. Ling, Y.; An, T.; Yap, L.W.; Zhu, B.; Gong, S.; Cheng, W. Disruptive, soft, wearable sensors. Adv. Mater. 2020, 32, 1904664.
[CrossRef] [PubMed]
208. Pathak, N.; Mukherjee, A.; Misra, S. Reconﬁgure and Reuse: Interoperable Wearables for Healthcare IoT. In Proceedings of the
IEEE INFOCOM 2020—IEEE Conference on Computer Communications, Toronto, ON, Canada, 6–9 July 2020; IEEE: Piscataway,
NJ, USA, 2020; pp. 20–29.
209. Townsend, K.; Cufí, C.; Akiba; Davidson, R. Getting Started with Bluetooth Low Energy: Tools and Techniques for Low-Power
Networking; O’Reilly Media, Inc.: Sebastopol, CA, USA, 2014.
210. Gomez, C.; Oller, J.; Paradells, J. Overview and evaluation of bluetooth low energy: An emerging low-power wireless technology.
Sensors 2012, 12, 11734–11753. [CrossRef]
211. Coskun, V.; Ok, K.; Ozdenizci, B. Near Field Communication (NFC): From Theory to Practice; John Wiley & Sons: Hoboken, NJ, USA,
2011.
212. Kim, J.; Banks, A.; Xie, Z.; Heo, S.Y.; Gutruf, P.; Lee, J.W.; Xu, S.; Jang, K.I.; Liu, F.; Brown, G.; et al. Miniaturized ﬂexible electronic
systems with wireless power and near-ﬁeld communication capabilities. Adv. Funct. Mater. 2015, 25, 4761–4767. [CrossRef]
213. Kwak, K.S.; Ullah, S.; Ullah, N. An overview of IEEE 802.15.6 standard. In Proceedings of the 2010 3rd International Symposium
on Applied Sciences in Biomedical and Communication Technologies (ISABEL 2010), Rome, Italy, 7–10 November 2010; IEEE:
Piscataway, NJ, USA, 2010; pp. 1–6.
214. Lee, W.; Lin, K.Y.; Seto, E.; Migliaccio, G.C. Wearable sensors for monitoring on-duty and off-duty worker physiological status
and activities in construction. Autom. Constr. 2017, 83, 341–353. [CrossRef]
215. Chang, W.J.; Chen, L.B.; Chiou, Y.Z. Design and implementation of a drowsiness-fatigue-detection system based on wearable
smart glasses to increase road safety. IEEE Trans. Consum. Electron. 2018, 64, 461–469. [CrossRef]
216. Wu, F.; Redouté, J.M.; Yuce, M.R. A self-powered wearable body sensor network system for safety applications. In Proceedings
of the 2018 IEEE SENSORS, New Delhi, India, 28–31 October 2018; IEEE: Piscataway, NJ, USA, 2018; pp. 1–4.
217. Qi, J.; Yang, P.; Hanneghan, M.; Tang, S.; Zhou, B. A hybrid hierarchical framework for gym physical activity recognition and
measurement using wearable sensors. IEEE Internet Things J. 2018, 6, 1384–1393. [CrossRef]
218. You, I.; Choo, K.K.R.; Ho, C.L.; Leu, F.-Y.; Ko, C.-Y. A smartphone-based wearable sensors for monitoring real-time physiological
data. Comput. Electr. Eng. 2018, 65, 376–392.
219. Dian, F.J.; Vahidnia, R.; Rahmati, A. Wearables and the Internet of Things (IoT), applications, opportunities, and challenges:
A Survey. IEEE Access 2020, 8, 69200–69211. [CrossRef]
220. Peoples, C.; Moore, A.; Zoualfaghari, M. A Review of the Opportunity to Connect Elderly Citizens to the Internet of Things (IoT)
and Gaps in the Service Level Agreement (SLA) Provisioning Process. EAI Endorsed Trans. Cloud Syst. 2020, 6, e3. [CrossRef]
221. Kekade, S.; Hseieh, C.H.; Islam, M.M.; Atique, S.; Khalfan, A.M.; Li, Y.C.; Abdul, S.S. The usefulness and actual use of wearable
devices among the elderly population. Comput. Methods Programs Biomed. 2018, 153, 137–159. [CrossRef] [PubMed]
222. Bogu, G.K.; Snyder, M.P. Deep learning-based detection of COVID-19 using wearables data. MedRxiv 2021.
223. Hassantabar, S.; Stefano, N.; Ghanakota, V.; Ferrari, A.; Nicola, G.N.; Bruno, R.; Marino, I.R.; Jha, N.K. CovidDeep: SARS-CoV-
2/COVID-19 Test Based on Wearable Medical Sensors and Efﬁcient Neural Networks. arXiv 2020, arXiv:2007.10497.
224. Cortellessa, G.; Stabile, L.; Arpino, F.; Faleiros, D.; Van Den Bos, W.; Morawska, L.; Buonanno, G. Close proximity risk assessment
for SARS-CoV-2 infection. Sci. Total Environ. 2021, 794, 148749. [CrossRef] [PubMed]
225. Ng, P.C.; Spachos, P.; Gregori, S.; Plataniotis, K.N. Personal Devices for Contact Tracing: Smartphones and Wearables to Fight
COVID-19. IEEE Commun. Mag. 2021, 59, 24–29. [CrossRef]
226. Bian, S.; Zhou, B.; Bello, H.; Lukowicz, P. A wearable magnetic ﬁeld based proximity sensing system for monitoring COVID-19
social distancing. In Proceedings of the 2020 International Symposium on Wearable Computers, Virtual Event, 12–16 September
2020; pp. 22–26.
Sensors 2022, 22, 2650
44 of 44
227. Shubina, V.; Ometov, A.; Lohan, E.S. Technical perspectives of contact-tracing applications on wearables for COVID-19 control. In
Proceedings of the 2020 12th International Congress on Ultra Modern Telecommunications and Control Systems and Workshops
(ICUMT), Brno, Czech Republic, 5–7 October 2020; IEEE: Piscataway, NJ, USA, 2020; pp. 229–235.
228. Amft, O.; Lopera, L.; Lukowicz, P.; Bian, S.; Burggraf, P. Wearables to ﬁght COVID-19: From symptom tracking to contact tracing.
IEEE Ann. Hist. Comput. 2020, 19, 53–60. [CrossRef]
229. Channa, A.; Popescu, N.; Skibinska, J.; Burget, R. The rise of wearable devices during the COVID-19 pandemic: A systematic
review. Sensors 2021, 21, 5787. [CrossRef] [PubMed]


</subsection_point_Point 1>

<previous_sections>

A systematic review of automated systems for real-time irrigation management

1. INTRODUCTION
The challenge of feeding a growing population with finite resources is becoming increasingly pressing. By 2050, the world population is expected to reach 9.7 billion, necessitating a 70% increase in food production (Falkenmark and Rockstrom, 2009). Irrigation plays a crucial role in enhancing crop yields and agricultural productivity to meet this growing demand. Studies have shown that irrigation can significantly increase crop water productivity, contributing to increased food production (Ali and Talukder, 2008; Playan and Mateos, 2005). However, water scarcity poses a significant challenge, with many regions facing water deficits and the need for improved water management practices (Falkenmark and Rockstrom, 2009). Optimizing irrigation schedules and doses based on crop requirements and environmental conditions is essential for maximizing yield and quality while minimizing water use (Zhang et al., 2024). The necessity of scalable water-efficient practices for increasing food demand cannot be overstated. Techniques such as regulated deficit irrigation, magnetically treated water, and the use of drought-tolerant crops like sorghum have shown promise in improving water productivity and ensuring food security (Mehmood et al., 2023; Putti et al., 2023; Hadebe et al., 2016). As the global food challenge intensifies, it is imperative to critically evaluate the current state and future potential of irrigation management systems to guide research, innovation, and implementation efforts towards fully autonomous, scalable solutions.

Despite the importance of irrigation in addressing the global food challenge, traditional irrigation management techniques, such as manual scheduling and timer-based systems, have significant limitations. These methods are often labor-intensive, inefficient, and less adaptable to changing conditions (Savin et al., 2023). Manual and timer-based scheduling can lead to high operational costs and inefficient water use (Raghavendra, Han, and Shin, 2023). The reliance on manual intervention and predetermined schedules limits their adaptability to changing environmental conditions, crop water requirements, and soil moisture levels (Kaptein et al., 2019). Sensor-based irrigation systems offer an alternative, enabling real-time adjustments based on soil water status measurements (Kaptein et al., 2019). However, the adoption of these systems in commercial settings has been limited, often requiring extensive input from researchers (Kim et al., 2014; Lea-Cox et al., 2018; Ristvey et al., 2018). The limitations of traditional irrigation management techniques highlight the need for scalable, automated solutions for greater efficiency in irrigation management. Automated systems that collect real-time data, analyze it, and make autonomous irrigation decisions can lead to improved water use efficiency and increased crop productivity (Champness et al., 2023; Wu et al., 2022). To fully understand the potential of automated systems, it is necessary to examine the automation of each part of the irrigation management pipeline and analyze the effectiveness and efficiency of integrated end-to-end solutions.

The emergence of smart irrigation management and IoT marks a significant shift from historical irrigation practices. Modern approaches rely on vast data and analysis algorithms, leveraging technologies such as remote sensing, sensor networks, weather data, and computational algorithms (Atanasov, 2023; Bellvert et al., 2023; Kumar et al., 2023). IoT plays a vital role in collecting vast amounts of data through sensors, data transmission, and tailored networks, enabling real-time monitoring and control of irrigation systems (Liakos, 2023; Zuckerman et al., 2024). These advancements in data collection and analysis have the potential to revolutionize irrigation management, allowing for more precise and efficient water use. However, challenges such as processing diverse data sources, data integration, and lack of integrated data analysis hamper the full benefit of IoT in irrigation management (Dave et al., 2023). The current fragmented approach in smart irrigation, focusing on individual components rather than the entire system, limits the potential for fully autonomous, real-time end-to-end irrigation management (Togneri et al., 2021). To address these challenges and fully realize the potential of smart irrigation management, there is a need for automating and integrating each section of the irrigation management pipeline, from sensor/weather data collection and transmission to processing, analysis, decision-making, and automated action (McKinion and Lemmon, 1985). This integration requires a thorough investigation of the role of interoperability and standardization in enabling seamless communication and compatibility between components within the automated irrigation management pipeline.

Machine learning (ML) plays a significant role in processing vast data, predicting plant stress, modeling climate effects, and optimizing irrigation in smart irrigation management systems. ML algorithms can analyze data collected from sensors and weather stations to determine optimal irrigation schedules (Vianny et al., 2022). However, the potential of ML is often constrained by manual steps, such as data interpretation, decision-making on irrigation timing and volume, and system adjustments. Automating ML integration to allow direct action from insights to irrigation execution, removing bottlenecks and achieving real-time adaptability, is crucial for fully autonomous irrigation management (Barzallo-Bertot et al., 2022). By integrating ML into automated systems, the irrigation management pipeline can become more seamless and efficient, enabling real-time decision-making and action based on data-driven insights. To achieve this level of automation and integration, it is essential to identify gaps and propose solutions for seamless integration across the automated irrigation management system, aiming to achieve fully autonomous, scalable irrigation management.

To achieve seamless integration across the automated irrigation management system, interoperability and standardization are critical. Interoperability allows different system components, such as sensors, actuators, and software, to communicate and exchange data effectively, while standardization ensures that data is represented in a consistent format (Santos et al., 2020). Standardized protocols and data formats are essential for achieving seamless integration and ensuring compatibility between components in real-time irrigation management systems (Robles et al., 2022; Hatzivasilis et al., 2018). Existing and emerging standards, such as OGC SensorThings API and ISO 11783, have applicability to real-time irrigation management systems (Hazra et al., 2021). However, challenges such as data quality, scalability, reliability, and security need to be addressed to fully realize the potential of interoperability and standardization in automated irrigation management systems (Hazra et al., 2021). Addressing these challenges is crucial for enabling the seamless integration of components within the automated irrigation management pipeline, which is essential for achieving fully autonomous, scalable irrigation management. A comprehensive evaluation of the role of interoperability and standardization in enabling the integration of components within the automated irrigation management pipeline is necessary to guide future research and implementation efforts.
The primary objective of this systematic review is to critically evaluate the current state and future potential of real-time, end-to-end automated irrigation management systems that integrate IoT and machine learning technologies for enhancing agricultural water use efficiency and crop productivity.
Specific objectives include:
•	Examining the automation of each part of the irrigation management pipeline and the seamless integration of each section in the context of irrigation scheduling and management.
•	Analyzing the effectiveness and efficiency of integrated end-to-end automated irrigation systems.
•	Investigating the role of interoperability and standardization in enabling the integration of components within the automated irrigation management pipeline.
•	Identifying gaps and proposing solutions for seamless integration across the automated irrigation management system, aiming to achieve fully autonomous, scalable irrigation management.
By addressing these objectives, this systematic review aims to provide a comprehensive and critical evaluation of the current state and future potential of real-time, end-to-end automated irrigation management systems. Its intention is to guide future research, innovation, and implementation efforts to achieve fully autonomous, scalable irrigation management that can contribute to addressing the global food challenge.

2. REVIEW METHODOLOGY
•	Question-driven framework to guide the literature review of real-time, autonomous irrigation management systems
•	Key research questions posed, each with the motivation behind investigating them and a starting hypothesis to evaluate against the examined literature
•	Table presenting the major objectives, specific objectives, questions, motivations, and hypotheses
3. DATA COLLECTION TO CLOUD: AUTOMATION AND REAL-TIME PROCESSING
3.1. Irrigation management data
The success of automated irrigation management systems relies heavily on the collection, transmission, and analysis of various types of data. The most applicable data types for irrigation management include soil moisture, canopy temperature, weather data, and plant physiological parameters (Farooq et al., 2019; Li et al., 2019; Olivier et al., 2021; Evett et al., 2020). These data are typically collected from a range of sources, including in-field sensors, remote sensing platforms, weather stations, and manual measurements (Li et al., 2019; Karimi et al., 2018).
Soil moisture data is arguably the most critical type of data for irrigation management, as it directly reflects the water available to plants and can be used to determine the optimal timing and amount of irrigation (Olivier et al., 2021; Intrigliolo & Castel, 2006). Soil moisture sensors, such as tensiometers, capacitance probes, and time-domain reflectometry (TDR) sensors, can provide real-time measurements of soil water content at various depths (Farooq et al., 2019). These sensors can be deployed in a network configuration to capture spatial variability in soil moisture across a field (Karimi et al., 2018).
Canopy temperature data is another valuable type of data for irrigation management, as it can be used to assess plant water stress and adjust irrigation accordingly (Evett et al., 2020). Infrared thermometers and thermal cameras can be used to measure canopy temperature, which is influenced by factors such as air temperature, humidity, wind speed, and plant water status (Li et al., 2019). When plants experience water stress, they tend to close their stomata to reduce water loss, leading to an increase in canopy temperature (Evett et al., 2020). By monitoring canopy temperature and comparing it to reference values, automated irrigation systems can detect plant water stress and trigger irrigation events to maintain optimal plant health and productivity (Li et al., 2019).
Weather data, including temperature, humidity, precipitation, wind speed, and solar radiation, are essential for predicting crop water requirements and scheduling irrigation events (Akilan & Baalamurugan, 2024). Weather stations equipped with various sensors can provide real-time measurements of these parameters, which can be used as inputs for crop water requirement models, such as the FAO-56 Penman-Monteith equation (Li et al., 2019). These models estimate crop evapotranspiration (ET) based on weather data and crop-specific coefficients, allowing for the calculation of irrigation requirements (Intrigliolo & Castel, 2006). By integrating weather data into automated irrigation systems, irrigation schedules can be dynamically adjusted based on changing environmental conditions, ensuring that crops receive the optimal amount of water at the right time (Akilan & Baalamurugan, 2024).
When collecting and utilizing these data types, several considerations must be taken into account, including the volume, frequency, format, and source of the data (Farooq et al., 2019). The volume of data generated by automated irrigation systems can be substantial, especially when high-resolution sensors are deployed at a large scale (Bastidas Pacheco et al., 2022). This necessitates the use of efficient data storage, processing, and transmission technologies to handle the data load (Farooq et al., 2019). The frequency of data collection is another important consideration, as it directly impacts the temporal resolution of the data and the ability to detect rapid changes in plant water status or environmental conditions (Bastidas Pacheco et al., 2022). Bastidas Pacheco et al. (2022) demonstrated that collecting full pulse resolution data from water meters provides more accurate estimates of event occurrence, timing, and features compared to aggregated temporal resolutions, highlighting the importance of selecting appropriate data collection frequencies to ensure the quality and usefulness of the data for irrigation management.
The format of the data is also crucial, as it determines the compatibility and interoperability of the data with various analysis tools and platforms (Farooq et al., 2019). Standardized data formats, such as JSON, XML, or CSV, can facilitate data exchange and integration between different components of the automated irrigation system (Zhang et al., 2023). The source of the data is another important consideration, as it can impact the reliability, accuracy, and spatial coverage of the data (Farooq et al., 2019). For example, in-field sensors provide highly localized measurements, while remote sensing platforms, such as satellites or drones, can provide data at larger spatial scales (Li et al., 2019). By combining data from multiple sources, automated irrigation systems can achieve a more comprehensive understanding of crop water requirements and optimize irrigation management accordingly (Farooq et al., 2019).
Data quality, accuracy, and reliability are paramount in irrigation management, as they directly impact the effectiveness of decision-making processes and the efficiency of water use (Gupta et al., 2020). Inaccurate or unreliable data can lead to suboptimal irrigation decisions, resulting in crop stress, yield losses, or wasted water resources (Ramli & Jabbar, 2022). Gupta et al. (2020) emphasized the critical importance of data security and privacy in smart farming systems, as the leakage of sensitive agricultural data can cause severe economic losses to farmers and compromise the integrity of the automated irrigation system. The authors also highlighted the need for robust authentication and secure communication protocols to prevent unauthorized access to smart farming systems and protect data in transit (Gupta et al., 2020).
Ramli and Jabbar (2022) addressed the challenges associated with implementing real-time, automated irrigation systems, including data quality, scalability, reliability, and security. They proposed solutions and best practices based on the analysis of case studies and real-world implementations, such as the use of redundant sensors, data validation techniques, and secure communication protocols (Ramli & Jabbar, 2022). The authors also emphasized the importance of regular maintenance and calibration of sensors to ensure the accuracy and reliability of the collected data (Ramli & Jabbar, 2022).
Researchers have investigated the use of data compression, aggregation, and filtering techniques to reduce bandwidth requirements and improve transmission efficiency in automated irrigation systems (Karim et al., 2023; Rady et al., 2020; Cui, 2023). Karim et al. (2023) explored the effectiveness of various data compression techniques, such as lossless and lossy compression algorithms, in reducing the size of data packets transmitted over wireless networks. The authors found that lossless compression techniques, such as Huffman coding and Lempel-Ziv-Welch (LZW), can significantly reduce data size without compromising data quality, while lossy compression techniques, such as JPEG and MP3, can further reduce data size by introducing acceptable levels of distortion (Karim et al., 2023).
Rady et al. (2020) developed a novel data compression algorithm specifically designed for irrigation data, which achieved significant compression ratios without compromising data quality. The authors demonstrated that their algorithm could reduce the amount of data transmitted over wireless networks, thereby improving the efficiency of the irrigation system and reducing costs (Rady et al., 2020). Cui (2023) investigated the use of data aggregation and filtering techniques to reduce the number of transmissions and save bandwidth in automated irrigation systems. The author proposed a data aggregation scheme that combines multiple sensor readings into a single value, such as the average soil moisture over a specified time interval, to reduce the frequency of data transmissions (Cui, 2023). Additionally, the author explored the use of data filtering techniques, such as Kalman filters and particle filters, to remove noise and outliers from sensor data, improving the accuracy and reliability of the transmitted information (Cui, 2023).
Data standardization and harmonization are crucial for facilitating seamless integration and interoperability between the various components of automated irrigation management systems (Zhang et al., 2023; Ermoliev et al., 2022). Zhang et al. (2023) developed a novel cyberinformatics technology called iCrop, which enables the in-season monitoring of crop-specific land cover across the contiguous United States. The authors highlighted the importance of data standardization and harmonization in the context of iCrop, as it allows for the efficient distribution of crop-specific land cover information based on the findable, accessible, interoperable, and reusable (FAIR) data principle (Zhang et al., 2023). By adopting standardized data formats and protocols, such as the Open Geospatial Consortium (OGC) standards, iCrop enables the seamless integration of various data sources and facilitates the interoperability of the system with other agricultural decision support tools (Zhang et al., 2023).
Ermoliev et al. (2022) proposed a linkage methodology for linking distributed sectoral/regional optimization models in a situation where private information is not available or cannot be shared by modeling teams. The authors emphasized the need for data standardization to enable decentralized cross-sectoral coordination and analysis, as it allows for the consistent representation and exchange of data between different models and stakeholders (Ermoliev et al., 2022). By adopting standardized data formats and interfaces, the proposed linkage methodology can facilitate the integration of various optimization models and support the development of comprehensive decision support systems for sustainable resource management (Ermoliev et al., 2022).
Metadata plays a vital role in providing context and enabling better data interpretation and decision-making in automated irrigation management systems (Jahanddideh-Tehrani et al., 2021). Metadata refers to the additional information that describes the characteristics, quality, and context of the primary data, such as the sensor type, calibration parameters, measurement units, and timestamp (Jahanddideh-Tehrani et al., 2021). Jahanddideh-Tehrani et al. (2021) highlighted the importance of metadata in water resources management, as it enables decision-makers to use the data to the best of its capabilities by understanding factors such as when water data was collected and what factors might have contributed to the measurements. The authors emphasized the need for standardized metadata formats and guidelines, such as the Dublin Core Metadata Initiative (DCMI) and the ISO 19115 standard, to ensure the consistency and interoperability of metadata across different water information systems (Jahanddideh-Tehrani et al., 2021).
In the context of automated irrigation management systems, metadata can provide valuable information about the data collection process, sensor performance, and environmental conditions that can aid in data interpretation and decision-making (Cota & Mamede, 2023). For example, metadata about the sensor type and calibration parameters can help assess the accuracy and reliability of the collected data, while metadata about the weather conditions and soil properties can provide context for interpreting the data and adjusting irrigation strategies accordingly (Cota & Mamede, 2023). By incorporating metadata into the data management and analysis pipeline of automated irrigation systems, decision-makers can make more informed and context-aware decisions, leading to improved water use efficiency and crop productivity (Jahanddideh-Tehrani et al., 2021).

3.2. Edge Computing and Fog Computing
Edge computing and fog computing have emerged as transformative technologies in the realm of real-time irrigation management systems, offering significant potential for improving efficiency, scalability, and reliability (Abdel Nasser et al., 2020; Tran et al., 2019). Edge computing refers to the practice of processing data near the edge of the network, close to the source of the data, while fog computing is a decentralized computing infrastructure that extends cloud computing capabilities to the network edge (Hassija et al., 2019). These technologies bring computation and analytics closer to the data source, reducing the need for data to travel to the cloud and enabling faster processing and decision-making (Hassija et al., 2019; Zhang et al., 2020).
The potential of edge computing and fog computing in real-time irrigation management is immense. Abdel Nasser et al. (2020) proposed a two-layer system for water demand prediction using automated meters and machine learning techniques, demonstrating the potential of edge computing in improving the efficiency and scalability of irrigation management. The system collects and aggregates data from distributed smart meters in the first layer, while the second layer uses LSTM neural networks to predict water demand for different regions of households. By leveraging edge computing, the system can achieve high accuracy in predicting water demand, which is essential for efficient irrigation management (Abdel Nasser et al., 2020).
Tran et al. (2019) conducted a comprehensive review of real-time, end-to-end automated irrigation management systems, highlighting the role of fog computing in addressing data transmission challenges and enabling seamless integration across the irrigation management pipeline. The authors emphasize that real-time, end-to-end automated irrigation management systems have the potential to significantly improve water efficiency, crop yields, and reduce labor costs. However, they also identify several challenges that need to be addressed, such as data quality, scalability, reliability, and security, which can be effectively tackled by implementing fog computing architectures (Tran et al., 2019).
Edge computing offers several benefits in real-time irrigation management systems, including reduced latency, real-time decision-making, and reduced reliance on cloud connectivity (Mishra, 2020; Zhang et al., 2020). By processing data closer to the source, edge computing enables faster response times and more efficient data handling (Mishra, 2020). Mishra (2020) highlights that edge computing reduces latency by processing data closer to the source, enabling real-time decision-making and lessening reliance on cloud connectivity by shifting processing to local or edge devices.
Zhang et al. (2020) explore the application of edge computing in agricultural settings, demonstrating its potential to improve the efficiency and accuracy of irrigation systems. The authors discuss how edge computing has prospects in various agricultural applications, such as pest identification, safety traceability of agricultural products, unmanned agricultural machinery, agricultural technology promotion, and intelligent management. They also emphasize that the emergence of edge computing models, such as fog computing, cloudlet, and mobile edge computing, has transformed the management and operation of farms (Zhang et al., 2020).
Fog computing plays a crucial role in distributing processing and storage across the network, enhancing the scalability and reliability of automated irrigation systems (Premkumar & Sigappi, 2022; Singh et al., 2022). Premkumar and Sigappi (2022) evaluate the current state of automated irrigation management systems and propose a hybrid machine learning approach for predicting soil moisture and managing irrigation. Their study emphasizes the potential of fog computing in distributing processing and storage across the network, improving the efficiency and scalability of irrigation systems. The proposed hybrid machine learning approach outperforms other machine learning algorithms in predicting soil moisture, demonstrating the effectiveness of fog computing in enhancing the performance of automated irrigation systems (Premkumar & Sigappi, 2022).
Singh et al. (2022) discuss the role of fog computing in distributing processing and storage across the network, enhancing scalability and reliability in agricultural management systems. The authors argue that by implementing fog computing, these systems can achieve faster data processing and response times, improving overall efficiency and effectiveness. They also highlight that fog computing can address the challenges faced by real-time data transmission in agricultural management systems, such as latency, bandwidth limitations, and data security (Singh et al., 2022).
The integration of edge and fog computing in real-time irrigation management systems is crucial for achieving fully automated, scalable, and reliable solutions. As the demand for autonomous irrigation management grows, these technologies will play a pivotal role in enabling faster decision-making, reduced latency, improved resource utilization, and seamless integration across the irrigation management pipeline (Tran et al., 2019; Zhang et al., 2020). By bringing computation and analytics closer to the data source and distributing processing and storage across the network, edge and fog computing can significantly enhance the efficiency and effectiveness of automated irrigation systems, contributing to the overall goal of addressing the global food challenge through optimized water resource management and increased agricultural productivity (Abdel Nasser et al., 2020; Premkumar & Sigappi, 2022; Singh et al., 2022).

3.3. Automation of Data Collection
The automation of data collection is a critical component in the development of real-time, end-to-end automated irrigation management systems that integrate IoT and machine learning technologies. It enables the efficient gathering of vital information about crop health, environmental conditions, and water requirements, which is essential for enhancing agricultural water use efficiency and crop productivity. Two key aspects of automated data collection are the use of advanced sensing technologies for non-invasive plant stress detection and the implementation of wireless sensor networks and energy-efficient communication protocols for large-scale, long-term data collection.
Advanced sensing technologies, such as hyperspectral imaging and thermal sensing, have emerged as powerful tools for non-invasive plant stress detection in automated irrigation management systems. These technologies provide valuable information about crop traits, enabling early and accurate detection of plant health issues (Triantafyllou et al., 2019). Triantafyllou et al. (2019) propose a comprehensive reference architecture model that incorporates advanced sensing technologies in the sensor layer for real-time plant stress detection, highlighting their importance in providing non-invasive plant stress detection. Similarly, Hossain et al. (2023) present a novel IoT-ML-Blockchain integrated framework for smart agricultural management that leverages advanced sensing technologies to optimize water use and improve crop yield, contributing to the overall goal of enhancing agricultural water use efficiency and crop productivity.
Hyperspectral imaging can capture subtle changes in plant physiology that are indicative of stress, while machine learning algorithms can be employed to extract meaningful patterns from the spectral data and classify different stress types (Araus et al., 2014). Thermal sensing can detect changes in canopy temperature, which is influenced by factors such as plant water status (Li et al., 2019). By monitoring canopy temperature and comparing it to reference values, automated irrigation systems can detect plant water stress and trigger irrigation events to maintain optimal plant health and productivity (Li et al., 2019).
The integration of advanced sensing technologies in automated irrigation management systems has the potential to revolutionize precision agriculture. Jiang et al. (2019) demonstrate the effectiveness of a deep learning-based model in accurately detecting leaf spot diseases, highlighting the importance of image augmentation and deep learning algorithms in enhancing the model's performance.
Wireless sensor networks (WSNs) and energy-efficient communication protocols have the potential to significantly improve the efficiency and reliability of data collection in large-scale, long-term irrigation systems. WSNs offer a cost-effective and scalable solution for real-time data collection in large-scale irrigation systems, providing remote monitoring and automated control capabilities (Mehdizadeh et al., 2020). Nishiura and Yamamoto (2021) propose a novel sensor network system that utilizes drones and wireless power transfer to autonomously collect environmental data from sensor nodes in vast agricultural fields, reducing operational costs and enhancing the efficiency of data collection. Similarly, Higashiura and Yamamoto (2021) introduce a network system that employs UAVs and LoRa communication to efficiently collect environmental data from sensor nodes distributed across large farmlands, optimizing data collection and reducing travel distance and time.
Energy-efficient communication protocols are crucial for ensuring reliable data transmission in challenging environmental conditions and extending the lifespan of sensor nodes (Mehdizadeh et al., 2020). Al-Ali et al. (2023) investigate the potential of WSNs and energy-efficient communication protocols for data collection in large-scale, long-term irrigation systems, discussing the challenges and opportunities of using these technologies to improve the efficiency and reliability of real-time data collection in irrigation management. Mehdizadeh et al. (2020) emphasize the need for careful consideration of factors such as data accuracy, energy consumption, and network reliability when designing effective WSNs for irrigation management, enabling timely irrigation decisions and improved crop yields.
The automation of data collection through the use of advanced sensing technologies and wireless sensor networks is essential for achieving fully autonomous, scalable irrigation management. By enabling non-invasive plant stress detection and large-scale, long-term data collection, these technologies contribute to the overall goal of optimizing water resource management and increasing agricultural productivity. The integration of these technologies in real-time, end-to-end automated irrigation management systems has the potential to enhance agricultural water use efficiency and crop productivity, ultimately contributing to the development of fully autonomous, scalable irrigation management solutions.

3.4: Real-Time Data Transmission Protocols and Technologies
Real-time data transmission is a critical component of automated irrigation management systems, as it enables the timely delivery of sensor data to the cloud for processing and decision-making. The exploration of suitable protocols and network architectures is essential for ensuring efficient and reliable data transmission in these systems, contributing to the overall goal of enhancing agricultural water use efficiency and crop productivity.
The Message Queuing Telemetry Transport (MQTT) protocol has emerged as a popular choice for real-time data transmission in IoT networks, including those used for automated irrigation management. MQTT is a lightweight, publish-subscribe protocol designed for constrained devices and low-bandwidth networks (Author, 2019). Its simplicity and low overhead make it well-suited for IoT applications where data transmission speed and energy efficiency are critical (Saranyadevi et al., 2022). MQTT provides three Quality of Service (QoS) levels, ensuring data reliability in real-time scenarios (Author, 2019). Chen et al. (2020) proposed novel algorithms to improve data exchange efficiency and handle rerouting in MQTT-based IoT networks for automated irrigation management systems. Their TBRouting algorithm efficiently finds the shortest paths for data transmission, while the Rerouting algorithm effectively handles the rerouting of topic-based session flows when a broker crashes. The combination of these algorithms can significantly improve the performance and reliability of automated irrigation management systems (Chen et al., 2020).
Client-server IoT networks, such as those based on MQTT, play a crucial role in real-time data transmission for automated irrigation management systems. In these networks, sensors and devices (clients) publish data to a central broker (server), which then distributes the data to subscribed clients (Verma et al., 2021). This architecture enables efficient data collection, processing, and dissemination, facilitating the integration of various components within the automated irrigation management pipeline. Verma et al. (2021) proposed an architecture for healthcare monitoring systems using IoT and communication protocols, which provides a comprehensive overview of existing approaches and highlights challenges and opportunities in the field. Although focused on healthcare, the insights from this study can be applied to automated irrigation management systems, emphasizing the importance of interoperability and standardization for seamless integration (Verma et al., 2021).
In addition to MQTT, other application layer protocols such as XMPP, CoAP, SOAP, and HTTP have been explored for real-time data transmission in IoT networks. Each protocol has its strengths and weaknesses, making them suitable for different applications and scenarios. XMPP (Extensible Messaging and Presence Protocol) is an open-standard protocol that supports real-time messaging, presence, and request-response services (Saint-Andre, 2011). CoAP (Constrained Application Protocol) is a specialized web transfer protocol designed for use with constrained nodes and networks in the Internet of Things (Shelby et al., 2014). SOAP (Simple Object Access Protocol) is a protocol for exchanging structured information in the implementation of web services, while HTTP (Hypertext Transfer Protocol) is the foundation of data communication for the World Wide Web (Fielding et al., 1999).
Motamedi and Villányi (2022) compared and evaluated wireless communication protocols for the implementation of smart irrigation systems in greenhouses, considering factors such as power consumption, range, reliability, and scalability. They found that ZigBee is the most suitable local communication protocol for greenhouse irrigation due to its large number of nodes and long range, while MQTT is the recommended messaging protocol for smart irrigation systems due to its TCP transport protocol and quality of service (QoS) options. GSM is a reliable and cost-effective global communication protocol for greenhouse irrigation, providing wide coverage and low cost (Motamedi & Villányi, 2022).
Syafarinda et al. (2018) investigated the use of the MQTT protocol in a precision agriculture system using a Wireless Sensor Network (WSN). They found that MQTT is suitable for use in IoT applications due to its lightweight, simple, and low bandwidth requirements. The average data transmission speed using the MQTT protocol was approximately 1 second, demonstrating its effectiveness for real-time data transmission in precision agriculture systems (Syafarinda et al., 2018).
The choice of application layer protocol for real-time irrigation management depends on factors such as data transmission speed, reliability, and energy efficiency. MQTT and RTPS (Real-Time Publish-Subscribe) are both suitable for real-time data transmission in IoT systems, but they have different strengths and weaknesses. MQTT is a better choice for applications that require low latency and high throughput, while RTPS is a better choice for applications that require high reliability and low latency (Sanchez-Iborra & Skarmeta, 2021). The exploration of MQTT and client-server IoT networks, along with the comparison of various application layer protocols, provides valuable insights into the suitability of these technologies for real-time data transmission in automated irrigation management systems.
In summary, real-time data transmission protocols and technologies play a vital role in the automation of irrigation management systems, enabling the efficient and reliable delivery of sensor data to the cloud for processing and decision-making. The exploration of MQTT and client-server IoT networks, along with the comparison of application layer protocols, highlights the importance of selecting suitable technologies based on factors such as data transmission speed, reliability, and energy efficiency. By leveraging these technologies, automated irrigation management systems can achieve seamless integration and contribute to the overall goal of enhancing agricultural water use efficiency and crop productivity.

3.5. Challenges and Solutions in Real-Time Data Transmission
Following the exploration of data collection, processing at the edge and fog, and automation in previous sections, we now turn to the critical aspect of real-time data transmission. While essential for automated irrigation management, this stage presents unique challenges that must be addressed to ensure system efficiency and reliability.
Obstacles in Real-Time Data Transmission
Agricultural environments present unique challenges for real-time data transmission, directly impacting the effectiveness of automated irrigation systems. Environmental factors can significantly disrupt wireless communication. Adverse weather conditions such as heavy rain, fog, and high winds can weaken or even block radio signals, leading to data loss and compromised system performance. Physical obstacles like trees, buildings, and uneven terrain further complicate signal propagation, creating reliability issues (Jukan et al., 2017; Yi & Ji, 2014; Zhang, Chang & Baoguo, 2018). These environmental challenges necessitate robust communication protocols and network architectures that can ensure consistent and reliable data flow.
In addition to environmental factors, technical limitations also present significant obstacles. Large-scale agricultural operations often demand long-distance data transmission, which can be hindered by the limited range of certain wireless communication protocols. Network congestion, occurring when multiple sensors transmit data concurrently, can lead to delays and potential data loss, further complicating real-time decision-making (Hameed et al., 2020). To mitigate these issues, researchers have investigated the potential of cognitive radio networks (CRNs) and dynamic spectrum access (DSA) for optimizing spectrum utilization and reducing interference (Righi et al., 2017; Shafi et al., 2018; Trigka & Dritsas, 2022). CRNs enable devices to intelligently sense and adapt to the surrounding radio environment, dynamically adjusting transmission parameters to avoid interference and improve communication efficiency. DSA, on the other hand, facilitates the dynamic allocation of unused spectrum, enhancing spectrum utilization and reducing congestion.
Furthermore, data security and privacy are paramount concerns in real-time irrigation systems. The sensitive nature of agricultural data, such as crop yields and farm management practices, necessitates robust security measures to prevent unauthorized access and data breaches (Gupta et al., 2020). Implementing secure communication protocols, authentication mechanisms, and encryption techniques is essential to protect data integrity and ensure the trustworthiness of the system.
Investigating Data Optimization Techniques
To enhance the efficiency and reliability of real-time data transmission in automated irrigation systems, researchers have explored a range of data optimization techniques. Data compression techniques aim to reduce the size of data packets transmitted over the network, minimizing bandwidth requirements and improving transmission speed (Rady et al., 2020; Karim et al., 2023). Lossless compression algorithms, such as Huffman coding and LZW, preserve data integrity while effectively reducing data size, ensuring that no information is lost during transmission (Cui, 2023). Lossy compression algorithms, such as JPEG and MP3, offer higher compression ratios but introduce a controlled level of data loss, which may be acceptable for certain applications where some loss of precision is tolerable (Karim et al., 2023). The choice between lossless and lossy compression depends on the specific application and the trade-off between data size and accuracy.
Data aggregation techniques provide another effective approach to optimize data transmission. By aggregating multiple sensor readings into a single representative value, such as average soil moisture or temperature, the number of transmissions can be significantly reduced, conserving bandwidth and energy resources (Cui, 2023). This is particularly beneficial in large-scale irrigation systems where numerous sensors are deployed across vast areas, generating substantial amounts of data. Additionally, data filtering techniques play a crucial role in improving data quality and reliability. Kalman filters and particle filters can effectively remove noise and outliers from sensor data, ensuring that only accurate and relevant information is transmitted and used for decision-making (Cui, 2023). This is essential for preventing erroneous data from influencing irrigation decisions and potentially leading to suboptimal water management.
Sensor calibration, drift correction, and fault detection are essential for maintaining data accuracy and reliability (Dos Santos et al., 2023). Regular calibration ensures that sensors provide accurate measurements over time, while drift correction techniques account for gradual changes in sensor readings due to environmental factors or aging. Fault detection mechanisms can identify and address sensor malfunctions or anomalies, preventing erroneous data from influencing irrigation decisions and potentially harming crops or wasting water.
Addressing the Challenges
Effectively addressing the challenges in real-time data transmission requires a multifaceted approach that encompasses environmental, technical, and data-related considerations. Implementing robust and adaptive communication protocols is crucial for overcoming interference and signal degradation caused by weather conditions and physical obstacles. Selecting appropriate protocols, such as LoRa or ZigBee, with suitable range and penetration capabilities can ensure reliable data transmission in challenging agricultural environments (Motamedi & Villányi, 2022). Additionally, employing techniques like frequency hopping and error correction codes can further improve communication resilience and mitigate data loss.
Optimizing network architecture is another key consideration. Deploying a distributed network architecture with edge and fog computing capabilities can significantly enhance data processing and transmission efficiency (Abdel Nasser et al., 2020; Tran et al., 2019). Edge devices can perform initial data processing and aggregation tasks, reducing the amount of data transmitted to the cloud and minimizing latency, while fog nodes can provide additional processing power and storage closer to the data source, enhancing scalability and reliability. This distributed approach alleviates the burden on the central cloud server and allows for more responsive and efficient irrigation management.
Data optimization techniques play a vital role in reducing bandwidth requirements and improving transmission efficiency. The choice of data compression, aggregation, and filtering techniques should be tailored to the specific requirements of the irrigation system, considering factors such as data type, accuracy needs, and available bandwidth. By carefully selecting and implementing these techniques, the overall performance and effectiveness of real-time irrigation systems can be significantly enhanced, leading to more sustainable water management practices and improved agricultural productivity.
By addressing these challenges and implementing appropriate solutions, real-time data transmission can become a reliable and efficient component of automated irrigation systems, contributing to the overall goal of achieving sustainable and productive agriculture in the face of growing food demands and water scarcity.
n summary, real-time data transmission protocols and technologies play a vital role in the automation of irrigation management systems, enabling the efficient and reliable delivery of sensor data to the cloud for processing and decision-making. The exploration of MQTT and client-server IoT networks, along with the comparison of application layer protocols, highlights the importance of selecting suitable technologies based on factors such as data transmission speed, reliability, and energy efficiency. By leveraging these technologies, automated irrigation management systems can achieve seamless integration and contribute to the overall goal of enhancing agricultural water use efficiency and crop productivity.


</previous_sections>

</documents>
<instructions>


Use the information provided in the <documents> tags to write the next subsection of the research paper, following these steps:
1. Review the overall intention of the research paper, specified in the <review_intention> tag. Ensure the subsection you write aligns with and contributes to this overall goal.
2. Consider the specific intention for this subsection of the paper, stated in the <section_intention> tag. The content you write should fulfill this purpose. 
3. Use the title provided in the <subsection_title> tag as the heading for the subsection. 
4. Address each of the points specified in the </subsection_point_Point *> tags:
   a) Make a clear case for each point using the text provided in the "point" field.
   b) Support each point with evidence from the research papers listed in the corresponding "papers to support point" field.
   c) When citing a paper to support a point, include inline citations with the author name(s) and year, e.g. (Smith et al., 2020; Johnson and Lee, 2019; Brown, 2018). Cite all papers that strengthen or relate to the point being made.
   d) While making a point and citing the supporting papers, provide a brief explanation in your own words of how the cited papers support the point.
5. Ensure that both of the points from the <subsection_point> tags are fully addressed and supported by citations. Do not skip or combine any points.
6. After addressing the specified points, wrap up the subsection with a concluding sentence or two that ties the points together and relates them back to the <section_intention>.
7. Review the <Previous_sections> of the paper, and ensure that the new subsection you have written fits logically and coherently with the existing content. Add transition sentences as needed to improve the flow.
8. Proofread the subsection to ensure it is clear, concise, and free of grammatical and spelling errors. Maintain a formal academic tone and style consistent with the rest of the research paper.
9. Format the subsection using Markdown, including the subsection heading (using ## or the equivalent for the document), inline citations, and any other formatting needed for clarity and readability.
10. If any information is missing or unclear in the provided tags, simply do your best to write the subsection based on the available information. Do not add any information or make any points not supported by the provided content. Prioritize fully addressing the required points over hitting a specific word count.

The output should be a complete, well-organized, and properly cited subsection ready to be added to the research paper.

Begin your answer with a brief recap of the instructions stating what you will to optimize the quality of the answer. Clearly and briefly state the subsection you'll be working on and the points you'll be addressing. Then proceed to write the subsection following the instructions provided. 

Critical: 
- Do not include a conclusion or summary as the entry is in the middle of the document. Focus on addressing the points and supporting them with evidence from the provided papers. Ensure that the subsection is well-structured, coherent, and effectively contributes to the overall research paper.
- The subsection we are focusing on is: 3.6. IoT Network Architectures and Variable Rate Irrigation (VRI) for Real-Time Irrigation
- No need for sub-sub-sections. just provide paragraphs addressing each point. They should transition fluidly and narurally into each other.
- Ensure that the content is supported by the provided papers and that the citations are correctly formatted and placed within the text.
- Do not repeat content from the previous sections. Ensure that the information provided is new and relevant to the subsection being written.



</instructions>

<subsection_point_Point 3>
Point: Investigate the use of data compression, aggregation, and filtering techniques to reduce bandwidth requirements and improve transmission efficiency

Papers to support point:

Paper 1:
- APA Citation: Miralles, P., Thangavel, B., Scannapieco, C. F., Jagadam, C., Baranwal, P., Faldu, B., .. González-Rodríguez, H. (2023). A critical review on the state-of-the-art and future prospects of machine learning for Earth observation operations. Advances in Space Research, 71, 4959-4986. http://www.sciencedirect.com/science/article/pii/S0273117723002709
  Main Objective: 
  Study Location: 
  Data Sources: 
  Technologies Used: 
  Key Findings: 
  Extract 1: The continuing Machine Learning (ML) revolution indubitably has had a significant positive impact on the analysis of downlinked satellite data. Other aspects of operations are now starting to surface.
  Extract 2: Machine Learning is becoming more prevalent in our daily lives, whether it is in the form of personalized newsfeeds, shopping online or streaming movie recommendations, or even mapping tools that help us avoid traffic jams. On a larger scale, ML is already having a significant impact on healthcare, banking, agriculture, and a variety of other industries, and its impact is expected to grow quickly in the coming years.
  Limitations: None.
  Relevance Evaluation: The paper is highly relevant to the specific point mentioned in the prompt, as it provides a comprehensive overview of the current state and future potential of machine learning in Earth Observation Operations, covering various aspects such as data collection, transmission, processing, and algorithms.
  Relevance Score: 1.0
  Inline Citation: Miralles et al., 2023
  Explanation: This review covers the current state of the art, future prospects, and the potential of machine learning in Earth Observation Operations. It approaches the topic by dividing it into cross-disciplinary domains including data collection, transmission, processing, and algorithms. The authors have focused on gathering the most relevant, recent, and impactful contributions to the field. For each of the topics, they have identified the most pressing challenges and proposed solutions to advance the state-of-the-art in the field.

 Full Text: >
Skip to main content Skip to article Journals & Books Search Register Sign in Brought to you by: University of Nebraska-Lincoln View PDF Download full issue Outline Abstract Keywords Abbreviations 1. Introduction 2. Machine learning in Earth observation mission planning 3. Machine learning in Earth observation guidance, navigation and control 4. Machine learning in Earth observation fault detection, isolation, and recovery 5. Machine learning in Earth observation on-board image processing 6. Machine learning in resource-constrained Earth observation platforms 7. Machine learning standardization and issues in Earth observation operations 8. Discussion & conclusion Declaration of Competing Interest Acknowledgements References Show full outline Cited by (10) Figures (6) Tables (2) Table 1 Table 2 Advances in Space Research Volume 71, Issue 12, 15 June 2023, Pages 4959-4986 Review A critical review on the state-of-the-art and future prospects of machine learning for Earth observation operations Author links open overlay panel Pablo Miralles a c, Kathiravan Thangavel b c i, Antonio Fulvio Scannapieco c, Nitya Jagadam c, Prerna Baranwal c d, Bhavin Faldu c, Ruchita Abhang c e, Sahil Bhatia c f, Sebastien Bonnart c, Ishita Bhatnagar c g, Beenish Batul c h, Pallavi Prasad c, Héctor Ortega-González c, Harrish Joseph c i, Harshal More c i, Sondes Morchedi c, Aman Kumar Panda c j, Marco Zaccaria Di Fraia c k, Daniel Wischert c, Daria Stepanova c l Show more Add to Mendeley Share Cite https://doi.org/10.1016/j.asr.2023.02.025 Get rights and content Abstract The continuing Machine Learning (ML) revolution indubitably has had a significant positive impact on the analysis of downlinked satellite data. Other aspects of the Earth Observation industry, despite being less susceptible to widespread application of Machine Learning, are also following this trend. These applications, actual use cases, possible prospects and difficulties, as well as anticipated research gaps, are the focus of this review of Machine Learning applied to Earth Observation Operations. A wide range of topics are covered, including mission planning, fault diagnosis, fault prognosis and fault repair, optimization of telecommunications, enhanced GNC, on-board image processing, and the use of Machine Learning models on platforms with constrained compute and power capabilities, as well as recommendations in the respective areas of research. The review tackles all on-board and off-board applications of machine learning to Earth Observation with one notable exception: it omits all post-processing of payload data on the ground, a topic that has been studied extensively by past authors. In addition, this review article discusses the standardization of Machine Learning (i.e., Guidelines and Roadmaps), as well as the challenges and recommendations in Earth Observation operations for the purpose of building better space missions. Previous article in issue Next article in issue Keywords Artificial IntelligenceAstrionicsEarth ObservationEdge ComputingMachine LearningNeural NetworkRemote SensingState-of-the-art Abbreviations AIArtificial IntelligenceMLMachine LearningDLDeep LearningFDIRFault Detection Isolation and RecoveryGNCGuidance Navigation and ControlNNNeural NetworkCNNConvolutional Neural NetworkDNNDeep Neural NetworkANNArtificial Neural NetworkBNNBinarized Neural NetworkBNBayesian NetworkDBNDynamic Bayesian NetworkNASANational Aeronautics and Space AdministrationESAEuropean Space AgencyOBCOn-Board ComputerEOEarth ObservationRDFRandom Decision ForestBTBayesian ThresholdingSVMSupport Vector MachineCOTSCommercial off-the-shelfSwaPSize Weight and PowerLIDARLight Detection and RangingSoCSystem on a ChipFPFalse PositivesCCSDSConsultative Committee for Space Data SystemsGNSSGlobal Navigation Satellite SystemGPSGlobal Positioning SystemPIProportional - IntegralPIDProportional - Integral - DerivativeAODSAttitude Orbital Determination SystemRLReinforcement LearningEKFExtended Kalman FilterRFRandom ForestAOCSAttitude and Orbit Control SystemK-NNk-Nearest NeighbourSOMSelf-Organizing MapOOSOn Orbit ServicingARPHAAnomaly Resolution and Prognostic Health Management for AutonomyDBSCANDensity-Based Spatial Clustering of Applications with NoiseEPSElectrical Power SystemSSHMSoftware and Sensor Health ManagementRDARegularized Discriminant AnalysisAROWAdaptive Regularization of Weight VectorSCWSoft Confidence-WeightedCNESCentre national d'études spatiales (The National Centre for Space Studies)ESOCEuropean Space Operations CentreRBFRadial Basis FunctionDLRDeutsches Zentrum für Luft- und Raumfahrt (German Aerospace Center)OC-SVMOne-Class Support Vector MachineNHERDNormal Gaussian HerdingTHEMISThermal EMission Imaging SystemIPEXIntelligent Payload EXperimentHyspIRIHyperspectral Infrared ImagerMODISModerate-Resolution Imaging SpectroradiometerPSNRPeak Signal to Noise RatioSSIMStructural Similarity IndexFPGAField Programmable Gate ArrayCALICContext-Based, Adaptive, Lossless Image CodecIWTIntegral Wavelet TransformPHPeano-HilbertLVQLearning Vector QuantizationTFTensorFlowSARSynthetic Aperture RadarROEWARatio of Exponential Weighted AverageJPEGJoint Photographic Experts GroupSTP-H5-CSPSpace Test Program-Houston-5-Cubesat Service protocolNASNeural Architecture StructureCPUCentral Processing UnitGPUGraphics Processing UnitVPUVisual Processing UnitTPUTime Processing UnitTTQTrained Ternary QuantizationRTRadiation TolerantMNASMobile Neural Architecture SearchKTKnowledge TransferKDKnowledge DistillationCSPCubesat Service ProtocolSBCSpaceBorne ComputerMNISTModified National Institute of Standards and Technology databaseNISSTCNational Information Security Standardization Technical CommitteeDINDeutsches Institut für Normung (German Institute of Standardization)DKEDeutschen Kommission Elektrotechnik Elektronik Informationstechnik (German Commission for Electrical, Electronic and Information Technologies)EUEuropean UnionECEuropean CommissionSMEsSmall and Medium EnterprisesDEELDEpendable and Expandable LearningEOSDISEarth Observation Systems’ Data Information SystemsSGACmSpace Generation Advisory CouncilSSPGSmall Satellite Project GroupDRLDeep Reinforcement LearningGISGeographic Information SystemsXAIExplainable AI 1. Introduction Earth Observation (EO) satellites have allowed us to look at our planet at a scale previously unattainable to humankind. From the vantage point of space, it becomes easier to monitor everything about our lives on a very large scale, such as our impact on the planet’s ecology (Guo et al., 2017) and extent of specific facilities all around the world (Pan et al., 2021). This capability has been and continues to be invaluable to understanding the world around us and enforcing regulations vital to the well-being of people all over the globe. However, as access to space becomes ever more affordable, EO assets multiply at an increasingly faster pace (Belward and Skøien, 2015). Moreover, EO Operations - the sequence of activities that take place in managing an EO spacecraft from its launch to its demise - keep growing in number and complexity as new assets are put into orbit. These trends could soon lead to a situation where available work-power becomes a limiting factor in the deployment of EO systems. Orchestrating these operations is, at its core, a control and data processing problem - from taking in and analyzing large volumes of telemetry from all EO platforms to taking into account their complex dynamics and evolving mission profiles when utilizing them. Artificial Intelligence (AI) is becoming more prevalent in our daily lives, whether it is in the form of personalized newsfeeds, shopping online or streaming movie recommendations, or even mapping tools that help us avoid traffic jams. On a larger scale, AI is already having a significant impact on healthcare, banking, agriculture, and a variety of other industries, and its impact is expected to grow quickly in the coming years. Machine Learning (ML), a subset of Artificial Intelligence (AI) as shown in Fig. 1 wherein machines learn from data, has been used in a variety of space-related applications. In our review, we considered that ML is a subfield of AI for clarification. Deep learning (DL) is a subfield of machine learning. Download : Download high-res image (117KB) Download : Download full-size image Fig. 1. AI, ML, DL relationship (Zhang et al., 2021). Human analysts may miss patterns and trends hidden within massive amounts of data, but ML can find them. ML, on the other hand, can uncover patterns and trends hidden inside massive amounts of data that are invisible to human researchers. Modern Earth Observation systems collect a massive amount of data from a variety of sensors with varying temporal, spatial, and spectral resolutions. Because of its complexity, it necessitates the use of innovative procedures and methods to extract useful information. Fig. 2 represents a typical machine learning process. Download : Download high-res image (110KB) Download : Download full-size image Fig. 2. Machine Learning workflow (Pant, 2019). 1.1. Machine learning for Earth observation ML has taken the data processing world by storm, with one success story after another. From object detection and classification (Krizhevsky et al., 2012) to natural language processing (Wang, 2021) and nonlinear control (Mnih et al., 2013), the capacity of these algorithms to solve different types of problems has been nothing short of awe-inspiring. For the purposes of the present review, we define ML algorithms as those whose performance critically depends on and generally improves with exposure to real-world data of the problem to be solved. So far, these techniques have concentrated mostly on the analysis of downlinked imagery due to the larger availability of computing power and ease of deployment relative to on-board applications, as well as its relatedness to computer vision, one of the traditional strong suits of ML. But applications to other aspects of operations are now starting to surface. The present review explores the contexts for which these applications have been proposed or in which they have been applied, exposes the possibilities that they open up and risks that must be avoided, and illustrates gaps in research that we believe should be addressed by the Earth Observation community. As shown in Fig. 3, ML will enhance space exploration operations in a variety of ways, particularly for Earth observation missions. Download : Download high-res image (383KB) Download : Download full-size image Fig. 3. Potential application of ML for earth observation mission. As illustrated in Fig. 3, the manuscript discusses the state-of-the-art as well as the future prospects of ML in Mission Planning (section 2), GNC (section 3), FDIR (section 4), and on-board image processing (section 5). In section 6, we also discussed the useful aspect of using ML models in EO operations. We examine how operators might make the most of their limited on-board resources by properly optimizing the usage of ML model resources, describing a variety of software and hardware solutions geared to that end. In Section 7, we also discuss recent initiatives within the space sector to standardize and guide the deployment of ML models, as well as the kinds of considerations a designer must make in order to avoid frequent errors with this technology. Our objective is to give EO Operators a thorough, if not exhaustive, assessment of the current situation with regard to ML applications in their area of expertise. The review connects EO operators and proponents of ML algorithms for EO Operations problems in an effort to spark discussion and stimulate additional application suggestions and demonstrations. With one important exception, the review covers all on-board and off-board applications of ML to EO but leaves out all post-processing of payload data on the ground, a subject that has been intensively researched by other researchers. The optimization of tracking, telemetry, and command is another subject we pass over. Despite the fact that this was initially our intention, we discovered an outstanding and current review by Fourati and Alouini (Fourati and Alouini, 2021). We invite interested readers to check out the excellent paper rather than pointlessly duplicating their work. This article has been reviewed and updated in comparison to the conference paper presented at IAC in 2021. This research, which is highly needed in present space industry, was conducted by a group of volunteers from the Small Satellite Project Group (SSPG) of SGAC. SGAC is a non-profit, non-governmental organization with over 16,000 members dedicated to the peaceful uses of space. There are over a hundred active volunteers, in addition to eleven project organizations, including the SSPG. The SSPG focuses on how small satellites are utilized in the space industry and how they can assist humanity in realizing space's full potential. 2. Machine learning in Earth observation mission planning There are many constraints to mission planning. Some relate to the target area: It needs to be under the satellite and illuminated by the sun at capture time (orbit and time-dependent); clouds are to be avoided (weather dependent); the requester may set a deadline and/or a priority. Others relate to the satellite, such as limited memory capacity; limited transmission capability; reduced communication opportunities with the ground antennas; multiple sensors to choose from; and limited maneuverability to skew the observation angle and reach areas not directly flown over. All of these parameters make optimal scheduling of observations a highly combinational problem for a mission that supports multiple independent requests, and it is even more complex when they are accomplished by a constellation of satellites. ML proposes a series of algorithms that may find better solutions than non-learning algorithms or do so more efficiently. There are many different formulations of the observation scheduling problem, taking into account different subsets of the constraints presented in the previous paragraphs, adapted for different types of missions and ground segments. 2.1. Classical approaches Non-ML algorithms to the satellite scheduling problems can be classified into two categories: Exact and Heuristic methods (X. Wang et al., 2021). Exact methods typically consist of a combination of branch and bound methods and mixed-integer linear programming. These methods are computationally costly and can become intractable for moderately sized constellations. Heuristic methods use an approximated rule to guide the construction of a solution. Greedy algorithms construct a solution by gradually choosing the best action at every decision step according to some metric, without regard as to how the overall sequence of decisions plays out. Other heuristic methods include backtracking through constraint programming and search algorithms. Other forms of search include hill-climbing or squeaky-wheel optimization, where the geometry of the optimization functions is exploited to accelerate the search process. Globus et al. (Globus et al., 2003) compare multiple algorithms such as genetic, simulated annealing, squeaky wheel and hill-climbing on a problem with one or two satellites. Evolutionary or genetic algorithms simulate processes akin to biological evolution to optimize candidate solutions according to a hand-crafted fitness function. Mansour et al. (Mansour and Dessouky, 2010) studied the performances of a genetic algorithm for a single satellite with limited memory and multiple instruments and imaging modes. Li et al. (Li et al., 2014) explore genetic algorithms in order to provide scheduling in real-time, optimizing the transmission path towards the user. Simulated annealing imitates the annealing processes found in metals exposed to high temperatures, and it forms the basis for another branch of heuristic algorithms. The simulated annealing seems to provide better results, confirmed by Globus et al. (Globus et al., 2003) in a complete multi-satellite formulation of the problem, including satellite agility and priorities. Lastly, multi-agent systems simulate interactions between simple agents representing part of the systems to determine an optimal policy. Bonnet et al. (Bonnet et al., 2015) use a self-adaptive multi-agent system for real-time and robust adaptation of a multi-satellite problem, including request priorities. 2.2. ML-based approaches ML-based approaches can exploit the statistical distribution of typical problem settings to accelerate the finding of good solutions to the mission planning problem. Wang et al. (X. Wang et al., 2021) present a comprehensive review of publications on the agile observation scheduling problem, including ML and non-ML approaches. The authors classify approaches along multiple axes such as time continuous and discrete-time model, type of solving method and also other features such as autonomy, and multi-objective profit function. Neural Networks (NNs) are explored by Wang et al. (Wang et al., 2019) in order to provide immediate results for a multi-satellite mission using Deep Reinforcement Learning (DRL). Peng et al. (Peng et al., 2018) apply recursive NNs in a sequential decision-making process in order to achieve low scheduling computation time and high performance when compared to a deterministic resolution. Recursive NNs allow the model to condition current decisions on past inputs, instead of depending exclusively on the present inputs to the system, providing the model with a sort of memory. We have not found any applications of Transformers to this problem, a sequence modeling technique from the deep learning research field that has shown excellent results in other sequential tasks like language modeling and even in image processing tasks. Neuroevolutionary techniques combine the advantages of neural models and evolutionary algorithms. Du et al. (Du et al., 2020) leverage a prediction model trained by a Cooperative Neuro-Evolution of Augmenting Topologies algorithm in order to filter tasks to be scheduled according to the probability to be fulfilled before scheduling using genetic algorithms. DRL uses NNs as function approximators to approximate hard to determine functions in dynamic programming. This has enabled groundbreaking achievements in other control and scheduling problems like playing Go or automated driving. Despite its potential, it has not been extensively applied to this problem set. Liu (Liu, 2020) applies Proximal Policy Optimization, a method of the DRL literature, to mission planning for a single satellite. Unfortunately, they do not compare performance to other methods or extend it to a multi-satellite setting. Yuchen et al. offer a unique online strategy that combines a Q-network with a pruning technique to address the observation sequence planning problem. The proposed scheme's goal is to generate an observation sequence based on the Q-learning heuristic rule and increase the neural network's efficiency in optimization. A Q-network-based mission-planning algorithm for the operation of the EO satellite is shown in Fig. 4. It shows the suggested algorithm's overall workflow (Liu et al., 2021). Download : Download high-res image (144KB) Download : Download full-size image Fig. 4. ML-based mission planning algorithm (Liu et al., 2021). Hadj-Salah et al. (Hadj-Salah et al., 2020, Hadj-Salah et al., 2019) explore the application of Actor-Critic (A2C), a DRL algorithm, to the mission planning problem. They compare it to random planning and a planning heuristic that compromises between greedy and long-term planning. Their models are trained in a simulated mission planning environment and then executed in a real test scenario. Their long-term version of A2C shows better performance than the heuristic algorithm. In their later publication, they augment the training process with techniques from the domain randomization and transfer learning literature, meant to increase robustness to the gap experienced when passing from the simulated training scenario to the real validation scenario. 2.3. Recommendations Mission planning is a very rich problem that has been explored for many years using machine learning amongst other solutions. Comparing the performances of algorithms presented in different papers is not a suitable path because each presents its own definition of the problem, with a unique set of constraints, different mission characteristics, variable satellite capabilities and potentially incompatible metrics. For instance, a lot of schedulers take into account satellite memory, limiting the number of observations until a ground station is visible, but few of them also make sure the ground station is available for communication with the satellite and not busy communicating with another one of the constellations. Song et al. (Song et al., 2020) introduce a framework in order to facilitate future comparisons but additional work on model standardization is needed before results from different studies can be compared. We observe a shifting trend in algorithms applied to this problem over the years from genetic or annealing to ML approaches such as NNs. Unfortunately, we found no sources comparing the performances of genetic and ML-based schedulers on a single problem formulation. Standardizing project formulations, constraints set, and optimization metrics seem to be a necessary step for sustainable collaborative research in this field. Relying on Consultative Committee for Space Data Systems (CCSDS) published standards and models could be a first step in the direction of a unified approach. 3. Machine learning in Earth observation guidance, navigation and control GNC, describe the set of operations needed to move a satellite platform or any other vehicle. The guidance relates to planning paths from a current state to the desired state. Navigation is the determination of the present state. Control is the correct use of spacecraft actuators, such as an engine, to execute the desired plan. 3.1. Classical approaches Two main tasks need to be achieved by a GNC system: determination of the current state, which is an estimation task, and use of the spacecraft’s actuators to go from the current state to the desired state, which is a control task. Spacecraft control is typically subdivided into at least two different granularity levels, guidance and control, where guidance is the high-level control of the spacecraft from a current dynamic state to a future one. A guidance module may output the sequence of feasible dynamic states necessary to achieve a new orbit from the required orbit. EO Satellite maneuvers are often planned and optimized on the ground, and the onboard guidance modules are minimal. For the control task, a number of control schemes are used, most notably controllers from the robust control literature such as H∞ controllers. As for navigation, spacecraft state is typically determined via variants of the Kalman Filter (KF), such as the Extended Kalman Filter (EKF)or the Unscented Kalman Filter (UKF). These methods are model based, that is, they depend on an explicit model of spacecraft dynamics for their calculations. Fuzzy controllers have been proposed as a possible improvement to the classical approach. The literature contains several works where GNC and Attitude and Orbit Control System (AOCS) controllers based on fuzzy logic are compared to their traditional counterparts. For instance, Wu et al. (Wu et al., 2001) studied the fuzzy logic controller with the X-38 re-entry vehicle. ESA also investigated the usage of fuzzy logic controllers to carry out Geostationary Equatorial Orbit (GEO) rendezvous autonomously (Ortega, 1995) to aid in in-orbit manufacturing. As another example, in (Cheng et al., 2009), a simulation of ROCSAT-1 / FORMOSAT-1′s attitude controller is carried out, where the classical setup of a Proportional - Integral (PI) pitch axis controller and Proportional - Integral - Derivative (PID) roll/yaw axis controller is replaced with two fuzzy controllers initially, and a single consolidated fuzzy controller afterwards, yielding considerable improvements against interference as well as a lower steady-state error. Nevertheless, despite the body of research backing up their effectiveness, there is no widespread use of fuzzy logic GNC controllers for space missions. 3.2. ML-based approaches Izzo et al. (Izzo et al., 2018) present a survey of Artificial Intelligence applied to GNC which, is not focused on EO applications, can nonetheless be useful to practitioners. The survey contains a section focusing on ML approaches, on top of other AI approaches such as evolutionary algorithms. In another publication (Izzo and Öztürk, 2021), Izzo and Öztürk leveraged DRL to plan near-optimal real-time computation of low-thrust transfers. They also suggest a new method to generate training data for such problem settings. Although originally designed for Earth-Venus transfers, their solution is applicable to all low-thrust transfers, but the data generation algorithm and optimality comparisons are problem-dependent. ML excels in problems where no structured pre-existing model can be exploited. That is not the case for the GNC problem, where the general form of the dynamics governing spacecraft are well known and solvable. It is, however, the case for visual-based GNC, as no model exists for relating camera inputs to dynamic state or control actions. For this reason, much research on ML-powered GNC has focused on visual-based GNC (Frédéric Férésin et al., 2021) for autonomous rendezvous. This, however, is not directly relevant to the EO Operations community, who are unlikely to engage in autonomous docking as providers. An interesting streak of research looks into applications of ML to processing visual navigation sensors, particularly Earth and Sun sensors and star trackers. Koizumi et al. (Koizumi et al., 2018) present a dl-powered Earth sensor capable of determining the attitude of the spacecraft by processing the images captured by a Commercial-Off-The-Shelf (COTS) camera. It runs a real-time image processing algorithm to extract features into the images separating them into distinct feature sets using DL techniques. The features sets are then compared to the preloaded data sets to determine the position of the spacecraft relative to Earth in the 3D plane. The primary advantage of the system is the use of a COTS component and a single board computer. Another research thread explores the combination of ML techniques and fuzzy controllers (Kim et al., 2016). Classical fuzzy controllers rely on manually set parameters that define behavior. This research thread attempts to leverage ML techniques to learn the optimal value for these parameters from a training dataset. These have the advantage of interpretability - their reliance on explicitly (if fuzzily enforced) rules means that they remain grounded on human-interpretable system models. Joghataie’ PhD. thesis (Joghataie, 1994) suggests the development of a neuro-fuzzy controller, wherein the tuning of the fuzzy logic is performed automatically by using neural networks in a hybrid approach. Azarbad (Azarbad et al., 2014) suggests a model applied to Global Positioning System (GPS) systems that outperform the classical fuzzy controller. A simulation study on MATLAB was done by Baranwal et al. in (Baranwal et al., 2018), comparing the performance of a PID controller and a fuzzy PID controller for a student satellite team. The EKF-based fuzzy controller outperformed the classical controller. The study was done on a 3U CubeSat. Further research can be done comparing these controllers with ML-based approaches. We have been unable to find a comparison between the three types of controllers, i.e., neuro-based controller, fuzzy controller and a hybrid model, as implementation details in different studies differ, complicating their comparison. Wang et al. (Wang et al., 2019) have developed a DL framework that stabilizes the spacecraft using a real-time torque control. It is initially trained in a simulation environment, enabling it to learn the required torque output and extrapolate it for unknown disturbances. It performs better than a conventional PID controller, as it can correct the attitude after unknown disturbance rather than repeatable corrections. A similar system is proposed by Yadava et al. (Yadava et al., 2018). They propose an Attitude Orbital Determination System (AODS) system that determines the position of the spacecraft, taking inputs from the magnetometers (magnetic vectors) and sun sensor (sun vector) along with GPS data (position and velocity vector), and determines the ideal attitude depending on the position using a neural network. The required torque calculations are made and sent to the Reinforcement Learning (RL)-based controller to make the required adjustments. The system performs better than classical PID controllers as it consumes less computation power for subsequent cycles as the algorithm learns. 3.3. Recommendations Most ML for GNC applications in the space sector seem to have been explored in the context of space logistics and space exploration rather than Earth Observation. Although guidance and control for EO platforms are simple compared to these applications, we believe there is a potential to adopt some of these technologies. Attitude determination is a domain where EO operations have high requirements. We believe that vision-based processing applied to this area is just getting started, and that use of more refined neural architectures could enable improvements in performance or resource consumption compared to current approaches. 4. Machine learning in Earth observation fault detection, isolation, and recovery Satellites performing EO tasks have stringent requirements in terms of accuracy, continuity and stability of payload operations. To this end, Fault Detection, Isolation and Recovery (FDIR) is focused on developing and improving tools to guarantee and maintain reliable spacecraft operations. FDIR describes a set of engineering disciplines focused on safeguarding and maintaining the spacecraft in nominal operating conditions. The target of these disciplines is represented by faults, irregular occurrences and processes with the potential to disrupt the mission up to the point of failure. ML can be an extremely powerful tool for FDIR. Indeed, the core capability provided by ML is pattern detection. Therefore, ML can be used both to detect anomalies in the telemetry or outputs from any subsystem (diagnosis) and identify signs indicating an incipient fault (prognosis). This section presents relevant ML literature for four significant sub-topics: fault detection, fault diagnosis, recovery, and fault avoidance. 4.1. Fault detection Failure detection deals with identifying the presence of faults and their rates of occurrence. 4.1.1. Classical approaches In classical approaches, the recognition of failures is mainly based on constant thresholds and fixed logic diagrams defined during the design process. (Wertz and Larson, 1999) One of the key issues with classical fault detection is model brittleness. As fault detection schemes are based on hardcoded thresholds, these models are easily disrupted by noise and deviations from theoretical assumptions. 4.1.2. ML-based approaches An example of an ML-based solution to the issue of model brittleness can be found in a paper by Jaekel et al. (Jaekel and Scholz, 2015). This work uses Self-Organizing Maps (SOM), an unsupervised variant of Artificial Neural Networks (ANNs), for the detection of failures in dexterous manipulators for On-Orbit Servicing (OOS). SOM manages to adapt to the idiosyncrasies of incoming data in a simulated environment and thus show increased robustness to input variations with respect to traditional methods. They can also deal with uncertainties and noise in values. A dexterous manipulator on a maintenance satellite captures a client spacecraft having 7 degrees of freedom. They inject sensor failures, including sensor outage and drift, during arm operations and the results show that SOMs are a robust approach as temporary fluctuations in the sensor, outliers and peaks do not unnecessarily stop the current operation. But the computational load is relatively high and needs to be optimized to reduce system reaction time. The authors suggest improving the precision and speed of the method by adding more information from redundant sensors. Ranasinghe et al. provides a comprehensive analysis of FDIR (Ranasinghe et al., 2022). Fuertes et al. (Fuertes et al., 2018) discuss ML-based fault detection using NOSTRADAMUS, an algorithm developed by the Centre National des Études Spatiales (CNES). NOSTRADAMUS uses a One-Class - Support Vector Machine (OC-SVM), a common algorithm used to detect outliers, to detect the presence of an anomaly in telemetry data. NOSTRADAMUS runs on the ground segment, analyzing telemetry as it is downlinked from the satellite. The performance of NOSTRADAMUS is compared to algorithms inspired by Novelty Detection (ESOC), Project Sybil (Ivano Verzola et al., 2016), and ATHMoS (DLR) (O’Meara et al., 2016). NOSTRADAMUS is the best option because it has a 100 % detection rate and the minimum false alarm rate (5 percent). The Novelty-inspired algorithms show the best performance of false alarm reduction, with 85 percent of valid detections and fewer than 1 % of false alerts. CNES is working on an on-board version of this algorithm, as well as on extensions to the ground-based variant for processing of multiple telemetry variables based on dictionary learning approaches (Pilastre, 2020). In conversations during their collaboration with this project, CNES teams signaled that explainability was a crucial aspect of any technique. Being able to understand the features of input data that signal a fault lets the operational teams understand the context of their satellite and know which actions must be taken to remedy the situation - this is comparable in value to being able to detect the anomaly in the first place. Project Sybil is a collaborative effort by DLR's Columbus Flight Control team, ESA's Advanced Mission Concept Section, and Ludwig Maximilians Universitat to apply an outlier identification algorithm to the Columbus telemetry database. After data segmentation and computation of its respective characteristics, it uses the Density-Based Spatial Clustering of Applications with Noise (DBSCAN) technique to preprocess the data. It is an unsupervised clustering method that divides data into a variable number of clusters based on their relative distances. Following this grouping, clusters with less than 5 % of the population data are discarded on the assumption that they may indicate a non-nominal working mode in the learning dataset. Project Sybill allows for higher mission performance by reducing downtime caused by onboard system failures. 4.2. Fault diagnosis Fault detection identifies the presence of faults and performance degradation, while fault diagnosis identifies the root causes of these events. 4.2.1. Classical approaches Though traditionally, fault diagnosis has been achieved by human operators at the ground through comparison with hardcoded hand-tuned thresholds. It is difficult to deal with large amounts of data using this approach. Iverson et al. (Iverson, 2008) point out that for efficient utilization of the data, there is a need for an autonomous approach that eliminates the necessity of human experts for diagnosis. 4.2.2. ML-based approaches Ricks et al. (Ricks, 2021) examine fault detection and identification for a satellite Electrical Power System (EPS) testbed using BNs compiled to arithmetic circuits. BNs can be used to model partial knowledge and uncertainty by identifying the system state based on probabilistic relationships between a set of system variables at a certain instance in time (Meβ, 2019). The proposed methods work for complex systems exhibiting both continuous and discrete behavior. The discussed techniques can handle abrupt continuous faults particularly well, which often pose problems. For example, a nominal value region is not enough to detect offset faults if they are small enough - the paper uses cumulative sums to deal with these. Additionally, “stuck” faults may be difficult to detect in low-noise conditions since fluctuations might be infrequent. The authors employ a tunable time interval which will mark the sensor as working abnormally after it expires without the readings having made any change. Different types of nodes, modeling different behaviours, are grouped to defined sensors and components, which in turn are assembled to create the entire EPS functional FDIR structure. BNs have also been used by Schumann et al. (Schumann et al., 2011) to detect onboard failures and perform diagnoses. A Software and Sensor Health Management (SSHM) system is developed for a simple GNC structure of a small satellite using BNs that collect data from hardware sensors, software quality signals, software status signals and data from the operating system in order to determine whether any failures exist, what the most likely causes are, and to provide a statistically sound quality measure of the diagnose. The developed SSHM system requires no modification to the satellite subsystems for which it performs FDIR - it just uses the sensor data outputs. That way, model-level and code-level Verification & Validation can be performed independently on the SSHM system to certify that the rate of false positives and false negatives is below a selected threshold. This SSHM, applied to a simple GNC system, was able to detect and diagnose both hardware and software problems successfully. Nevertheless, it remains a simplistic case and more research into hierarchical SSHM systems is required in order to apply them to large-scale BNs. The approach can further be extended to failures that are not modeled and unexpected and due to arising behavior. Although not specifically related to space systems, Liu et al. (Liu et al., 2018) reviews the existing techniques for ML-based fault diagnosis in rotating machinery. In general, it presents useful research and conclusions which we consider can be applied to reaction wheels in the AOCS subsystem of spacecraft. K-Nearest Neighbor (k-NN) is the simplest method reviewed, which exhibits ease of implementation but necessitates careful fine-tuning and large computation and storage space. The authors cite BNs’ strong prior assumptions as the biggest shortcoming of this family of algorithms while mentioning as main advantages that it possesses a clear physical explanation of how it detects faults and its reduced storage space requirement. Support Vector Machine (SVM) is also reviewed, and its high-dimension accuracy is highlighted, even if the physical meaning is obscured, unlike with the previous two techniques. Finally, DL techniques have the potential to learn from data up to a degree of complexity much higher than any of the other techniques without the need for a manually crafted feature extractor. However, the main drawback of this approach is the need for large samples in order to train the network, which is difficult to obtain unless the spacecraft is a new iteration of previously flown models for which data already exists. If the satellite is a one-off, this can only be obtained in an approximate manner by creating a simulation environment. The authors underline that future ML-based fault diagnosis methods should not be purely data-driven but should consider possible failure mechanisms, system models and prior knowledge in general to increase diagnostic performance. Voss (Voss, 2019) explores the use of DL for fault detection and isolation in a simulation environment. A NN is developed, trained offline and tested to detect and isolate single faults in the reaction wheels, GPS, star tracker and magnetometer subsystems, as well as two simultaneous faults. A case study with PROBA-V mission parameters is also performed for the AOCS subsystem only. The implemented system yielded mixed results: while some subsystems have a near-perfect performance, the network fared poorly regarding others, namely misalignment faults. Also, fault isolation was much more reliable than fault detection. On top of that, a large dataset is required for this system to work, so creating a simulation environment is mandatory, especially for one-off spacecraft, to acquire enough data for adequate network training. This study also assumes there is enough electrical and computing power available on the satellite to run this deep-learning-based solution. We overview techniques for reducing resource consumption of deep neural models and other techniques in section 6. 4.3. Recovery In FDIR, recovery entails reconfiguring the problematic element and/or the entire spacecraft to restore normal system behaviour (Jaekel and Scholz, 2015). 4.3.1. Classical approaches Traditional FDIR is able to respond to predefined events by selecting a recovery path from the available set of options. However, the status of the system and its environment can exhibit various kinds of uncertain behavior due to their dependence on the internal subsystem, component reliability factors, external environment factors (e.g., illumination conditions, thermal, radiation) and on system-environment interactions (e.g., resource utilization profiles, stress factors, degradation profiles) (Meβ, 2019). Due to these uncertainties, the system and its environment cannot be completely observed by traditional FDIR concepts that pose limitations to autonomous isolation and recovery (Meβ, 2019). For example, Mars Express lost six months of operational hours due to a non-resolvable memory problem that forced it into safe mode repeatedly (Jaekel and Scholz, 2015). 4.3.2. ML-based approaches Raiteri et al. (Codetta-Raiteri and Portinale, 2015) discuss the use of Dynamic Bayesian Networks (DBNs) to address issues like partial observability, uncertain system evolution and system-environment interaction, as well as the prediction and mitigation of imminent failures. The BNs do not model the relationship between variables at previous points in time. DBNs are an extension to BNs that refer to past values of certain variables to express dynamic aspects of the system over discrete time (Meβ, 2019). The approach is applied by Raiteri et al. (Codetta-Raiteri and Portinale, 2015) onto the power subsystem of a simulated ExoMars rover, by simulating different failure scenarios. The DBNs can infer whether the system is currently in a normal, anomalous or failed state. On detection of a failure, a suitable recovery plan is suggested. A preventive recovery plan may be proposed in case an anomaly is inferred. The FDIR presented in this paper also has the capability of performing a prognostic state estimation that can also be used for preventive recovery. The proposed approach has been implemented in an on-board software architecture called Anomaly Resolution and Prognostic Health Management for Autonomy (ARPHA). The results show that DBNs are suitable for failure situations requiring autonomous (preventive and reactive) recovery. AIKO Technologies have developed a software library, MiRAGE, that can enable the spacecraft to make autonomous decisions for processing telemetry and payload. The library is meant to be installed on the satellites to enable functionalities such as event detection, predictive maintenance and autonomous re-planning. 4.4. Fault avoidance Fault avoidance methods are concerned with preventing the occurrence of faults. 4.4.1. Classical approaches FDIR in past missions worked under the notion that a fault is detected and then the algorithm will react, according to predefined scenarios.(Jalilian et al., 2017, Olive, 2010). Regarding ML-based models, one of the bottlenecks to having an on-board failure avoidance system is that the models are trained on the ground with limited data that does not represent actual behavior in space. This gives rise to the requirement of real-time access to the data, which can be used to represent multiple onboard scenarios, and closely represents spacecraft behavior during the mission. 4.4.2. ML-based approaches Especially notable in the context of ML-enabled fault avoidance is the work of Labrèche et al.(Georges et al., 2021) discussing the OrbitAI experiment onboard the OPS-SAT spacecraft. OPS-SAT is a special ESA satellite deployed with the scope of being a testbench for novel software technologies in orbit. OrbitAI uses ML techniques to obtain intelligent FDIR algorithms enabling the onboard camera to avoid direct exposure to sunlight. Interestingly the ML model used is trained on-board, rather than offline. The model is trained with five training algorithms tested of those natively provided in the MochiMochi library (olanleed, 2021) for online ML training: Adam, RDA, AROW, SCW, and NHERD. When using the figure of merit of balanced accuracy, only one model appears to achieve values significantly different from 0.5: the AROW algorithm in three-dimensional input space. 4.5. Recommendations FDIR innovation has been applied mainly to deep space missions, which need a higher degree of autonomy due to their long communication delays inherent to the long distances traveled. However, the analysis of the literature suggests that ML in EO FDIR has promising prospects. The approach can be extended to diagnose failures that are not modeled, unexpected and due to arising behavior, which offers a great advantage in overcoming the model brittleness issues of traditional FDIR. ML-based fault detection and diagnosis solutions can be integrated alongside the traditional FDIR of the satellite. But ML-based recovery is virtually unexplored, and much research is needed in this domain. The majority of the work in this field concerns BNs, while other research avenues remain largely unexplored, such as ANNs and DL. As it would be shown and discussed in Section 6, power and computational resources remain a big concern for ML-based FDIR, especially for small satellites. The benefits of ML-based FDIR can be further researched to be implemented in future EO satellites to perform FDIR on the AOCS subsystem, GNC, On-Board Data Handling, Power subsystem, and detection of faulty sensors. 5. Machine learning in Earth observation on-board image processing 5.1. On-board image processing Clouds cover 66 % of the Earth’s surface and are an obstacle when observing the Earth’s surface in certain wavelengths such as visible light. Removal of clouds from satellite images is an important preprocessing phase for most of the applications in remote sensing. Researchers have explored various forms of Cloud detection like “Cloud / No cloud”, “Snow / Cloud”, and “Thin Cloud / Thick Cloud”, using various approaches of ML and classical algorithms (Mahajan and Fataniya, 2020). Cloud detection/filtering can be used alongside novelty detection. Novelty detection is to detect unexpected features and it is especially important while looking into new environments. Good cloud detection algorithms are necessary to optimize bandwidth and memory usage in EO missions (Z. Zhang et al., 2019) and before the implementation of segmentation and object detection methods. Convolutional Neural Networks (CNN) have demonstrated excellent performance in various visual recognition problems such as image classification and enable accurate onboard cloud detection in small satellites. With the increase in EO missions coupled with high-resolution modern sensors, there is an increase in bandwidth requirement that leads to the need to utilize new techniques to manage the bandwidth resources efficiently. 5.1.1. Classical approaches In the majority of missions, all images taken are transmitted to the ground, which requires a significant amount of bandwidth. Traditionally, data collection is done by specifying in advance where and when to take the measurements. Based on the content of the data, there is no mechanism to tailor what is downlinked. (Srivastava, 2003, Vladimirova and Atek, 2002). Other common approaches include novelty detection based on spectral contrast, radiance spatial or temporal contrast. (Shaw and Burke, 2003) But these methods are better used for dark grounds like vegetation or deserts as clouds contrast in color compared to them. Furthermore, these methods rely on manually chosen thresholds, which are time-consuming to find and sometimes brittle. (Arechiga et al., 2018). Whereas spatial coherence is a better method of cloud detection in areas with little contrast with the clouds (ice sheets). NNs have also been shown to have greater flexibility with classifying indistinct classes like clouds on snow. 5.1.2. ML-based approaches to on-board image processing For cloud detection, Zhang et al. (Z. Zhang et al., 2019) propose a lightweight DNN based on U-Net. For performance estimation of the proposed method, training and testing of the red, green, blue and infrared waveband images from Landsat-8 were used. The lightweight DNN is based on U-Net and obtained better overall accuracy while reaching the state-of-art inference speed by applying the LeGall-5/3 wavelet transform on the dataset which compresses the dataset and accelerates the network for on-board use. Zhang et al. experimental results illustrate that the proposed model maintains high accuracy after four-level compression (Z. Zhang et al., 2019). They reduce processing time from 5.408 s per million pixels to 0.12 s per million pixels, and average memory cost by around 30 %. The suggested method takes advantage of established image compression systems in satellites to provide a good chance of onboard cloud identification based on DL, hence enhancing downlink data transmission efficiency and lowering memory costs. On compressed datasets, U-Net gives improved accuracy. In addition, the U-Net framework demonstrated tremendous promise for pixel-by-pixel categorisation of remote sensing datasets (Z. Zhang et al., 2019). The following table (See Table 1) providdes the list of on-board astrionics for data processing. Table 1. Hardware Accelerators. Name Company Description Intel Movidius Myriad 2 Vision Processing Unit (VPU) Intel Implemented with DNN in Phisat-1 (Esposito et al., 2019) Myriad X (VPU) Intel Active testing (Bruhn et al., 2020) Jetson Nano (GPU) Nvidia Space Edge Zero (2021) by Spiral blue (Mittal, 2019) Tegra TX1 and TX2 (SoC) Nvidia Demonstrated AI Image processing capability (Buonaiuto et al., 2017, Hernández-Gómez et al., 2019) Coral TPU Google Used with SC-LEARN Architecture for Hyperspectral models (Goodwill et al., 2021) Apache 5 Almotive In development Neuromorphic chip Innatera In development Spaceborne Computer-2 (SBC-2) Based on Intel Xeon Onboard ISS Ultrascale Radiation Tolerant (RT) Kintex FPGA Xilinx Prototype available Xilinx Zynq-7020 (ARM Cortex-A9 + FPGA) Xilinx Space Test Program Houston 5/ CSP (2017) Hinz et al. (Hinz et al., 2020) also work on the detection of clouds in the H2020 EO-Alert project framework. However, the EO-Alert project aims at keeping images of clouds and enriching them with alert profiles in case of severe storms for weather broadcasting. The algorithm used is ML-based Gradient Boosted Decision Trees and is embedded in a modular image processing pipeline. Currently, tests of the pipeline are performed in Matlab and are ported on hardware to be flown to space. Srivastava et al. (Srivastava, 2003) suggested using Kernel methods for better onboard discovery computation of cloud detection over snow and ice. This paper proposes a Kernel method that can be used for clustering and classifying images on board any satellite. The paper discusses a novel variant of the Probabilistic Kernel (P-Kernels) with a mixture of Gaussian and spherical covariance structures. It is very sensitive to even the smallest changes as it assumes all observations are independent. The results showed great promise, with clouds being differentiated much better from Greenland ice sheets compared to the Gaussian and Gaussian mixture models. Giuffrida et al. (Giuffrida et al., 2020) (Giuffrida et al., 2022) discuss a CNN deployed on the PhiSat-1 reconfigurable nanosatellite to analyze imagery from its Hyperscout-2 payload and select images eligible for transmission to the ground. It is implemented on-board the ESA Phisat-I mission to classify cloud-covered images and clear ones. Only images with less than 70 % cloudiness are transmitted to the ground. The network is trained and tested against an extracted dataset from the Sentinel-2 mission, which was appropriately pre-processed to emulate the Hyperscout-2 hyperspectral sensor. On the test set, 92 % of accuracy is achieved with 1 % of False Positives (FP). The results showed a power consumption of 1.8 W, requiring memory of 2.1 MB, keeping within the power and the memory constraints. (Del Rosso et al., 2021) showcase the use of CNNs on multispectral data to detect volcanic eruptions on-board a satellite. Onboard detection of disaster events allows prioritizing their downlink and thus optimising response times, which can translate into saved lives. Moreover, they have released the dataset used for training, a step the rest of the industry should imitate if rapid progress is to be encouraged. (Spiller et al., 2022, Thangavel et al., 2023, Thangavel et al., 2023 Thangavel et al., 2022 2022a, 2022b) showcase the use of CNNs on hyperspectral data to detect wildfire on-board a satellite. Other solutions that have not flown yet and are in the concept phase have been developed. Maskey et al. (Maskey and Cho, 2020) proposed an ultralight CNN algorithm called CubeSatNet, that prioritizes quality data over quantity without changing the constraints of size, power, volume, downlink and pointing requirements imposed by a 1U CubeSat. The algorithm is trained over 48,000 augmented images from CubeSats and validated against 12,000 augmented images from CubeSats to classify images as “bad” when cloudy, sunburnt, facing space or saturated. Images are classified as “good” in all other cases. If in orbit, the algorithm would select only “good” images to be downlinked and discard images that are covered in clouds or too bright or dark. Trained on BIRDS3 satellite images, the algorithm reportedly has an accuracy of 90 % and can cut operation time by about 2/3 while significantly improving the quality of images received. Murray (Ireland, 2019) proposed a concept of on-board processing with two cameras: the nadir-looking camera performs the standard observation, whereas a forward-looking camera observes if clouds are coming in the trajectory of the satellite. A neural net classification grid is used to identify clouds and an algorithm then decides when to capture images with the nadir looking. This approach would be oriented towards CubeSats. Castaño et al. (Ricard Castaño et al., 2007) trained an SVM for estimating the opacity of atmospheric dust and water ice on Mars on data from the THEMIS camera mounted on board the Odyssey mission. The authors use both a regular SVM and a reduced-set SVM. The reduced-set SVM is trained on a reduced synthetic dataset maximizing the similarity of the reduced-set SVM to the regular SVM. The reduced amount of support vectors decreases compute requirements. They then test both the full-size SVM and reduced-set SVM on flight software, showing the capability of such software to run the proposed algorithms. The authors mention two challenges related to the analysis accuracy of onboard Time History of Events and Macroscale Interactions during Substorms (THEMIS) data. Firstly, as the onboard data is not calibrated, the deployed models must be robust to significant noise. Secondly, the camera's response function can gradually increase or decrease its values due to temperature fluctuations, even when there is no change in actual value. The authors suggest characterizing the operation of the algorithms in an environment as close as possible to that of the spacecraft. Lastly, the Autonomous and Reactive Image Chain (CIAR) project from IRT Saint Exupéry demonstrated cloud segmentation on board the operational test-bed satellite OPS-SAT in 2021 (Frédéric Férésin et al., 2021). Fig. 5 showcases a visualization of their results. Download : Download high-res image (217KB) Download : Download full-size image Fig. 5. On-board cloud segmentation from the CIAR project. 5.1.3. ML-based approaches to novelty detection Wagstaff et al. (Wagstaff et al., 2017) show the benefits of reduced downlink data when performing cloud detection and filtering for EO missions. Cloud detection is demonstrated using Random Decision Forests (RDFs) and Bayesian Thresholding (BT), while a third saliency-based algorithm is used for novelty detection onboard EO-1. The RDF method analyzes a window of values around the pixel for classifying the pixels. In contrast, the BT independently performs the classification of each pixel. BT uses the difference in particular wavelengths between dark surface materials and bright cloudy regions. The novelty detection algorithm identifies such regions within an image that may contain new features. EO-1′s primary science instrument is Hyperion. It’s an Imaging Spectrometer capable of data collection with high Spatial and Spectral resolution. Using data from previous mission phases, both cloud detection algorithms were trained to drop useless images from the telemetry downstream. The performance of the algorithms has been evaluated onboard over a five-month period from November 2016 through March 2017. In comparison to ground testing, the on-board performance showed similar or better results on a diverse collection of targets. Both RDFs and BT reached an accuracy of more than 90 %. However, in real-time, the RDFs were faster. The novelty detection was able to detect new features in remote locations such as small lakes and buildings; hence, such images could be given priority for the downlink. Such methods must be able to successfully operate on board with limited resources while posing a minimum risk to the overall spacecraft. With the advancement in computing capabilities, more complex models offering better accuracy can be used onboard future EO missions. Chien et al. (Chien et al., 2017) present the results of the IPEX, which was based on a CubeSat that did fly from December 2013 to January 2015 and validated autonomous operations for the computation and generation of product onboard the platform hosting the Hyperspectral Infrared Imager (HyspIRI) mission concept's Intelligent Payload Module. IPEX was used as a testbed for on-board image classification, which was accomplished with the help of machine learning-based random decision forest algorithms. In comparison to earlier missions, the solution was improved by using an ensemble of several trees to increase the classifier's reliability through statistical regularization without the requirement for explicit tree pruning. Furthermore, the system examines spatial neighborhoods in each image rather than single pixels to integrate local morphology and texture. By classifying every 10th pixel and the vertical and horizontal directions and filling in the rest with nearest-neighbor interpolation, runtime was reduced. The IPEX classifiers are trained before launch using only four hand-labelled photos from a high-altitude balloon mission that used the same type of camera as IPEX. This is a very fascinating point. According to the researchers, it was the first time that an ML system was trained on a suborbital mission and then effectively used in orbit. IPEX also experimented with an unsupervised method for identifying photographs with potentially intriguing content, which would be used in conjunction with supervised learning. To extract relevant regions for downlink in captured imagery, computer vision visual salience software was used. To work with CubeSat's limited resources, the program developed a simple pixel-based measurement of visual salience for grayscale images with the local context. To select the five most important parts within the image, the method is applied to a down sampled version of the image using a 32 × 32-pixel window. The pipeline is finished with thumbnails of important regions and their salience scores, which are saved and made available for downlink and on-the-ground analysis. If necessary, full-resolution images can also be downlinked to ground stations. 5.1.4. Recommendations With the strict limitation on bandwidth, onboard filtering of useless data enables sending data to the ground with minimum compromise on image quality and the need for human intervention for decision-making. The results of ML algorithms can be improved in terms of accuracy and precision with the availability of newly generated data. 5.2. Object/image classification Image classification is a task of extracting information on the basis of objects in the images instead of individual pixels, where “objects” are referred to as meaningful scene components that distinguish an image (Deepan and Sudha, 2020). 5.2.1. Classical approaches While current methods do extensively apply ML algorithms to great success, image classification is more often done on the ground instead of onboard a satellite. (Shaw and Burke, 2003). 5.2.2. ML-based approaches Arechiga et al. (Arechiga et al., 2018) give an example of an on-board processing application where a CNN architecture is used for object classification and trained using satellite imagery of Planet’s Open California dataset. Nvidia Jetson TX2 is used for implementing this application. The authors suggest that more research can be done so that the application can be enhanced to classify more objects. Machine intelligence is used to perform onboard analysis of EO tasks such as hazard analysis (e.g., wildfire and flood detection), target detection, area monitoring, and weather forecasting (Manning et al., 2018). On MODIS (Moderate-resolution imaging spectroradiometer) data, NASA Goddard researchers employed machine learning to detect wildfires. In practice, CNNs are used to perform two tasks: training and inference. The process of “learning” the ideal set of weights that maximizes the accuracy of the desired task is referred to as training (e.g., image classification, object detection, semantic segmentation). It's a computationally difficult task that's frequently aided by Graphics Processing Unit (GPU). The inference is the process of making decisions based on new data using a trained model (with no parameters changed). The inference is a less computationally intensive method that has been carried out on Central Processing Unit (CPU), GPUs, and Field Programmable Gate Array (FPGA). 5.2.3. Recommendations Similar to onboard cloud detection, moving object classification and detection onboard satellite platforms allow operators to reduce the load of ground-satellite communications links. EO Operators can leverage the huge and quickly expanding research field of computer vision. The high-level information gained by using object classification can then be used for other tasks, like dynamic mission replanning. 5.3. On-board image compression New, complicated onboard sensors can quickly saturate communication transceiver downlink bandwidth as well as onboard data storage capacity. Image compression codecs that are more efficient are becoming a need for spacecraft and can greatly lower the amount of data communicated or stored. However, while designing a tradeoff mission, it’s also important to think about whether these are computationally intensive and require quick processing to keep sensor data rates up. 5.3.1. Classical approaches Systems used a range of lossless and lossy compression algorithms to compress data in spaceborne activities (Giuffrida et al., 2022; “Image Data Compression,” 2021; “Lossless Data Compression,” 2020). Where the system bandwidth is too low to support lossless compression, when the science value is not compromised by lossy compression’s distortion, or when other sensors that do not play a role in primary data products are included, lossy compression is frequently used. An example of this last case can be scene-context cameras. 5.3.2. ML-based approaches Goodwill et al. (Goodwill et al., 2020) proposed an ML-based solution to achieve good reconstruction fidelity after lossy compression. The algorithm, CNN– Joint Photographic Experts Group (JPEG), makes use of a hybrid approach combining CNNs and JPEG Compression. The image is fed to a 3-layer CNN in the encoder to obtain a compact image representation, which is then encoded with JPEG. Based on previous work, the encoder is denoted by ComCNN and learns a compact image representation that is half the size of the original image. In the decoder, the resulting image is upsampled to the original size and decoded with a deeper 20-layer CNN, which reconstructs the original image by learning a residual image and adding it to the upsampled image. On an image dataset obtained from STP-H5-CSP compressed to the same file size, experimental results for CNN-JPEG demonstrate a 23.5 percent and 33.5 percent gain in Peak Signal to Noise Ratio (PSNR) and Structural Similarity Index (SSIM) over conventional JPEG, respectively. At a fixed PSNR, CNN-JPEG increased the average compression ratio by 1.74 times on the same dataset. It's also worth noting that the encoding segment of CNN-JPEG in TensorFlow (TF) Lite, when run on the Zynq-7020′s Cortex-A9 cores, provided an average execution time of 16.75 s utilizing a single thread, according to the research. Using the TF Lite interpreter to parallelize operations was reportedly far from ideal linear speedup. Authors also showed that leveraging the Zynq-7020 FPGA resources through SDSoC for hardware acceleration helped decrease the average execution time of the CNN-JPEG encoder to 2.293 s, with a 7.30 speedup over the single-threaded TF Lite solution and 6.87 times speedup over the single-threaded TF Lite solution. Vladimirova et al. (Vladimirova and Atek, 2002) discuss the development of a lossless compression method without the drawbacks of low compression ratios using predictive NNs, coupled with integral wavelet transforms and the Peano-Hilbert (PH) Scan algorithm. This is then benchmarked against the Context-Based, Adaptive, Lossless Image Codec (CALIC) Method using various image datasets. The image is first sent through the Integral Wavelet Transform (IWT)to produce a de-correlated image, which is mapped, and a PH scan is performed after which the NN (a two-layer, 4x106 × 1) scans and allocates a probability distribution for the next incoming value. On the tested data sets, using only the NN method achieved an average compression ratio of 2.530, compared to the CALIC method which achieved a ratio of 1.806. Introducing the PH scan brought an 8.5 % improvement compared to the CALIC method at 2.747. The IWT + PH + NN method overall achieved an improvement of 13.1 % compression ratio over the CALIC method. The paper proposes potential applications of the algorithm in previewing a satellite image before a full image is transferred to assess the image's features and would prevent bad images from being sent, such as those affected by clouds or images suffering from other distortions. Cai et al. (Cai et al., 2003) proposed a novel Light Detection and Ranging (LIDAR) image data compression method. The method is called feature indexing where specific features are assigned to a data index system generated by DNNs. The whole program is then uploaded to onboard hardware and it stores it as a dictionary for reference. The On-Board Computer (OBC) runs a feature isolation program, identifies features, and creates a resultant dataset of pure indices based on the directory. This data set is then transmitted with the location data and then is decoded on the ground. Achieves a compression level of 99.17 % and works far better than standard wavelet compression methods. The method was tested against the LIDAR data of the Space Shuttle program and achieved the above-mentioned results. 5.3.3. Recommendations Exploiting lossy compression to ease downlink clearly represents a path to be explored. The work by Goodwill et al. (Goodwill et al., 2020) also emphasizes the importance of advancement in the field of hardware acceleration and System on a Chip (SoC) FPGAs. Indeed, on-board inference of CNNs is computationally expensive for space platforms. Further advancements can possibly support the application of more complex algorithms even in constrained environments. 6. Machine learning in resource-constrained Earth observation platforms This section addresses the topic of ML in resource-constrained spacecraft performing EO tasks. These methods represent a powerful set of enabling technologies, relevant both for the emerging interest in small satellites and to preserve the operativity of large platforms experiencing failures or operating with shared resources. Moreover, the consistent technological lag of space hardware makes considerations about reduced available SWaP almost always necessary when redeploying architectures developed for Earth-based applications into orbit. Within the scope of this work, the constraint on resource availability will be limited to on-the-edge computational and sensing capabilities, and not extended to the data. It is also out of the scope of the section to address scheduling approaches, which optimize the availability of resources to multiple subsystems or users. This variability, however, can be also seen as a source of constraint over the available budgets. We investigate two ways in which this adaptation to technological limitations can be implemented: optimization of the AI architecture itself, and optimization of the interplay between the model and the hardware this operates on. In general, resource-constrained platforms it is necessary to maintain a holistic view of the architecture of the software, the hardware, and the data at play. It is worth noting that another emerging technological field presenting similar constraints to the space sector is represented by Internet-of-Things (Lane et al., 2015), where the target platforms for AI are small, low-power devices. 6.1. AI architecture optimization 6.1.1. Pruning Pruning is the operation of removing or zeroing parameters of a NN model, thus reducing the network’s size (Han et al., 2015). This process is generally performed by associating scores with the network’s elements during training in order to select the ones to prune. The lighter model is then further trained and can be iteratively re-pruned several times. Multiple pruning strategies exist, such as varying the number and nature of items pruned, the number of iterations performed or changing the scoring criteria (Blalock et al., 2020). There are also other emerging pruning paradigms that do not rely on an iterative process (H. Wang et al., 2021) (Frankle et al., 2021). Pruning’s main trade-off is to increase computational efficiency at the cost of quality/accuracy and increased training complexity. The objective is to leverage compression rates of 4, 8 or even 32 while costing at worst only a few percent of accuracy (Blalock et al., 2020). Performing pruning along this objective remains a delicate task as literature demonstrates that keeping good performances is dependent on the pruning method. The main challenge of implementing pruning is thus to determine and test which pruning methods to use in order to achieve the required compression while keeping acceptable performances for a representative type of datasets. Although the lack of standards in evaluation impedes the comparison of the multiple existing studies, they all advertise significant compressing at low accuracy cost, including several algorithms confirmed by multiple papers (Blalock et al., 2020). Pruning has been successfully applied in many image processing use cases but has also been proven on voice processing (He et al., 2014), credit classification (Tang et al., 2018), and multiple other types of datasets (Lazarevic and Obradovic, 2001). Additional engineering and more complex training on the ground in order to significantly reduce the onboard execution constraints make pruning an attractive trade-off and a strong technological enabler of NN implementation in space. Pruning is now developed enough to have documented implementation and examples in ML frameworks such as TF (“Pruning in Keras example | TensorFlow Model Optimization,” 2022). So far, pruning has been used as part of complex NN applications for space but only on the ground with applications such as image classification (Browne et al., 2020, Castelluccio et al., 2015, Kavzoglu and Mather, 1999, Maggiori et al., 2017). There are some applications aiming towards on-board implementations like remote sensing image classification (Pitsis et al., 2019, Zhang et al., 2020), vehicle detection in satellite images (Tan et al., 2020) and image anomaly detection (Ma et al., 2019). Unfortunately, the authors were unable to find documented evidence of a pruned NN that flew on a space mission. 6.1.2. Filter compression and matrix factorization In its section concerning “convolutional filter compression and matrix factorization,” the paper by Goel et al. (Goel et al., 2020) presents methods to adapt neural networks to low-power platforms by operating at a layer’s level. The distinction operated between the two distinguishes between the types of network elements that are being optimized. Neural Networks can be algebraically represented as n-dimensional matrices known as tensors. Matrix factorization approaches reduce the complexity of these underlying tensorial structures, to obtain compressed networks without significant loss of accuracy. Filter compression methods, on the other hand, reduce the number of parameters in the network architecture by acting on the structure of filters in the so-called convolutional layers. In particular, Goel et al., observe that filter compression methods are capable of achieving state-of-the-art accuracy in computer vision, albeit at times at a high computational cost. As computer vision tasks are essential in EO operations, this class of methods appears to be the most significant within the scope of this paper. Two architectures emerging as relevant for filter compression are SqueezeNet (Iandola et al., 2016) and MobileNets (Howard et al., 2017). Both these architectures have found applications in the EO community. For example, modified SqueezeNets have been used by Haikel (Haikel, 2018), Alswayed et al. (Asmaa et al., 2020) and Alhichri et al. (Alhichri et al., 2018)for the classification of remote sensing images (both in drone and satellite images). In particular, Alswayed et al. report results comparable to or outperforming the state of the art at the time of publication. Poortinga et al. have used a MobileNet-based architecture to map sugarcanes in satellite data of Thailand (Poortinga et al., 2021), obtaining significant accuracy for the task. Zhang et al. (B. Zhang et al., 2019) also have used an architecture capitalizing on MobileNet, reporting results outperforming the state of the art at the time. Similarly, Yu et al. (Yu et al., 2020) present a MobileNet-based method to classify remote sensing imagery and report outperforming many state-of-the-art models while requiring a smaller amount of training data. In their report paper, Hoeser et al. (Hoeser et al., 2020) note that: “It is important to note the small group of six items which use MobileNets, of which five were published in 2019”. They describe an onset of interest in parameter efficient models with high accuracy and they prove that such models can compete in Earth observation studies. 6.1.3. Architecture search Neural Architecture Search (NAS) refers to a set of tools and processes for the automatic generation of optimal architectures for an ANN. NAS is a specific instance of automated machine learning (AutoML), the process of automating the overall ML construction process (He et al., 2021). As shown by Chan et. al (Chan et al., 2018), this process can be specialized to address a constraint on available resources. Seminal developments in NAS emerged in late 2016, from the work of Zoph and Le (Zoph and Le, 2017) and Baker et al. (Baker et al., 2017). In a survey on the subject, Elsken et al. (Elsken et al., 2019) report three key parameters to operate a classification of NAS processes. These are: • Search space, • Search strategy, • Performance estimation strategy. Being an approach to adapt the heavy computational cost of NN to resource-constrained platforms, NAS has naturally found application in many space-related use cases. EO, there has been quite a research on hyperspectral images classification using NAS, with development performed by Liang et al. (Liang et al., 2020) have employed NAS (and pruning) to detect aircraft in remote sensing images. Mobile Neural Architecture Search (MNAS) (Tan et al., 2019) is a probable candidate in implementing NAS to EO satellite inference on the edge application. 6.1.4. Knowledge transfer and distillation In Knowledge Transfer (KT) and Knowledge Distillation (KD) a small, lightweight network is trained to reproduce the behavior of a large, computationally intensive network without having to duplicate the architecture of the latter fully. This leads to small networks both providing results comparable to those of large networks and deployable on resource-constrained platforms. According to the paper of Goel et al. (Goel et al., 2020), in KT the smaller network is trained using data labeled by the larger network (defined as “synthetically labeled data” by Ba and Caruana (Ba and Caruana, 2013)), while in KD a small network (student) is trained by a large network (teacher) to replicate the latter’s output. Within the scope of this section, it also appears relevant to discuss transfer learning, which has attracted considerable interest from the space community. De Vieilleville et al. (de Vieilleville et al., 2020) proposed a distillation method to perform DNN-mediated segmentation of EO images on board of CubeSats. In this work, they show that a 10 to 30-fold reduction of the free parameters of the network mediated through distillation leads to weakly worse performance (+5/-10 % accuracy). Similarly, (Chen et al., 2018) provide a detailed distillation implementation and results showing a strong reduction of the NN execution load while keeping a steady accuracy in remote sensing scene classification. (Bazzi et al., 2020) applied distillation for mapping irrigated areas using remote sensing data. Since 2019, self-distillating networks are emerging (Chen et al., 2021) with one successful implementation for cloud detection in remote sensing by (Chai et al., 2020) achieving 200-fold compression. Industrialization is not as developed as pruning as there are only a few open access examples of implementations but no widely developed library. Unfortunately, the authors were unable to find documented evidence of a distilled NN ever flown and used on a space mission. 6.2. Hardware acceleration Computing limitations are demanding to ML-based applications because of the significant amount of data to be processed for DL. Many NN models require high-end GPU devices to run in inference, and even more so during training. In deploying ML to an EO satellite, it is appropriate to consider the inferencing phase due to volume, power, and mass constraints, especially under CubeSat standards. Progress in commercially available off-the-shelf hardware in mobile edge computing has a progressive effect in finding their way to CubeSats in implementing DL algorithms for space applications (Kothari et al., 2020). With CPUs considered to be general-purpose computers, AI-specific hardware such as GPU’s, FPGA, and Application-Specific Integrated Circuit (ASIC) takes the center stage which is designed to accelerate the computation of linear algebra and specializes in performing fast and matrix multiplications with higher performance-per-watt ratios. Furthermore, advanced next-generation architecture for onboard computing which heavily depends on artificial intelligence is developed like Artificial Intelligence-Onboard Computing (AI-OBC) (Huq et al., 2018) based on distributed on-board architecture consisting of CPU, Visual Processing Unit (VPU), emerging AI accelerator class of microprocessor for running machine-learning applications to train DNN and FPGA connected through CubeSat Service Protocol (CSP) through which ML and training are carried out in real-time with COTS components to reduce cost and development time. One other form of tailored hardware optimization is the adoption of spiking neural networks (Kucik and Meoni, 2021) and their deployment on optimized hardware. This approach, which is much closer to the way the brain seems to function, can allow for dramatic energy savings through minimization of energy use during neuron activation. 6.3. Quantization / BNNs In quantized networks, the number of bits used to represent numbers defining a model is reduced. This provides a decrease of orders of magnitude in computing, memory and power requirements, for a comparatively low decrease in performance. Quantization may be applied to weights, activation functions or gradients of a network, either during or after training. (Guo, 2018, Qin et al., 2020, Simons and Lee, 2019). Quantization has been explored in research for remote sensing image segmentation and processing but appears to never have been flown in space. Perhaps the most common established quantization technique is reducing the bit-width of weights after training. However, very low bit widths, typically of four or less, usually incur heavy losses. This can be mitigated by performing model training under the reduced bit-width quantization, known as Quantification-Aware Training (QAT). Good results have been achieved with quantization, even going all the way to a single bit. Accuracy on par with full-precision NNs was achieved for standard datasets in publications such as Binary-Connect, Exclusive-NOR Network (XNOR-Net), and Trained Ternary Quantization (TTQ) (Courbariaux et al., 2015, Rastegari et al., 2016, Zhu et al., 2017). Quantization of already existing NNs such as AlexNet (Krizhevsky et al., 2012) and Visual Geometry Group Network (VGGNet) (Simonyan and Zisserman, 2015) applied to the ImageNet dataset has been carried out without any accuracy loss while reducing their sizes up to 50 times (Han et al., 2016). Quantization both before and after model training is provided today either as part of mainstream DL libraries (“Post-training quantization | TensorFlow Lite,” 2022.; “Quantization — PyTorch 1.9.1 documentation,” 2022.) or third-party libraries such as Larq (“Larq | Binarized Neural Network development,” 2022.) and FINN (Alam et al., 2022) respectively. Although there exists no consensus on why quantization works, a candidate explanation argues that large amounts of pathway redundancy in NNs make the expressivity loss a minor concern. Theoretical analysis in that regard is still limited. Anderson and Berg (Anderson and Berg, 2017) found that statistical properties of the computation are kept even when a network is binarized. Molchanov et al. (Molchanov et al., 2017) indicate that nearly 99 % of weights can be pruned in certain NNs and achieved a 68-times sized reduction on VGG-like networks without loss of accuracy. Quantization techniques can be divided into two main categories: Deterministic and Stochastic. Guo classifies deterministic quantization methods (Guo, 2018) into: • Rounding: Floating-point values are assigned their nearest fixed-point representation. • Vector Quantization: Weights are clustered into groups, with the centroid of each group replacing the real weights. • Quantization as an optimization: Here, the quantization is treated as an optimization problem, which involves minimizing an error function taking into account real and quantized weight values. Regarding stochastic quantization techniques, they separate them into: • Random Rounding: The quantized value is obtained by sampling a discrete distribution parameterized by the real values themselves. • Probabilistic Quantization: Weights are assumed to be discretely distributed, with the methods trying to estimate which distribution function it is. Deterministic quantization has seen extensive success, with rounding being the most commonly successfully employed type of quantization, such as Rastegari et al. (Rastegari et al., 2016) and (Polino et al., 2018), where a general rounding function was introduced. In particular, Binary-Connect Courbariaux et al. (Courbariaux et al., 2015) used binary rounding, achieving 98.8 % accuracy on the MNIST dataset. Also noteworthy is the use of vector quantization in Gong et al. (Gong et al., 2014), where a network compression ratio of 24 was obtained, losing only 1 % of accuracy on the ImageNet dataset. However, Stochastic quantization has not experienced such a resounding success, perhaps due to an over-reliance on statistical assumptions which are not guaranteed to hold. Quantization approaches may quantify several or all of the following: • Weights: The action of quantizing weights yields a smaller network size and can accelerate the training and inference process. However, this comes at a price: NNs will have a harder time converging when training with quantized weights, and a smaller learning rate is required. Additionally, the gradient cannot back-propagate through discrete neurons, leading to the use of straight-through estimators in order to estimate them, usually with a high variance. • Activations: The goal of quantized activations is replacing inner products with binary operations, reducing memory constraints since the operation precision is reduced, all while accelerating network training. In fact, activations may fill more memory than weights (Mishra et al., 2017). Note that quantized activation will cause what is called a “gradient mismatch”, where the gradient of the activation function is different from the one obtained from the straight-through estimator used. • Gradients: Quantizing the gradients is still a relatively new avenue of research in NN quantization. The main objective here is not reducing the model size, but aiding in distributed network training, where several computing nodes need to share information of the gradient values between them. The smaller the size of the data the nodes need to share, the faster parallel training can be performed. Quantized gradients need to be carried out with care since unsuitable implementations run the risk of causing the gradient descent algorithm not to converge. 7. Machine learning standardization and issues in Earth observation operations Interest in AI and ML has increased in the past years. Many groups in different industries are working on creating guidelines, best practises, and standards to help make sure these systems are used correctly. But the process is far from over, and so far, the space industry has only given us a real-world example of something similar. Standards, guidelines, and other documents discussed in this section blur the line between definitions of AI and ML (Graham et al., 2023). While we find this fact misleading, we have kept the original usage from the sources in order not to alter their message. These bodies of work aim at aiding ML system developers to avoid common pitfalls and problems associated with these systems. We provide in this section a cursory overview of what these problems are in order to raise awareness amongst EO platform operators. We do this so that the designers and operators of EO platforms are aware of what ML systems are capable of and are not capable of doing when it comes to making decisions that are reliable, intelligible, and appropriate for usage in situations with high stakes. Because of the high expense of these possible applications on-board a big satellite platform, these conditions apply to the majority of those applications. To put it another way, any operator who is contemplating delegating decisions regarding the success or failure of their mission to ML systems should make it a priority to employ ML systems that are reliable and can be explainable. We do this so that EO platform designers and operators are aware of what ML systems can and cannot do when it comes to taking decisions that are trustworthy, understandable, and fit for use in high stakes scenarios. These conditions apply to many of the potential applications on-board a large satellite platform, due to their cost. In other words, using trustworthy, explainable ML systems should be important to any operator thinking of charging such systems with decisions deciding the success or failure of their mission. 7.1. Guidelines and roadmaps International Standards by International Standardization Organization (ISO) committee (“ISOISO/IEC JTC 1/SC 42 - Artificial intelligence,” 2017.) are currently available or under development. These standards and projects represent the united efforts of experts and entities in providing guidance and focus on the standardization of Artificial Intelligence, with currently more than twenty under development and six already published. We found ISO/IEC TR 24030:2021 to be particularly interesting as it covers 132 use cases, as well as the projects under development concerning Functional Safety and AI, data quality and AI explainability. The ISO is not alone in working on AI standardization, though. The Chinese Big Data Security Standards Special Working Group of the National Information Security Standardization Technical Committee (NISSTC) wrote the Artificial Intelligence Security Standardization White Paper (Törnblom and Nadjm-Tehrani, 2019). The focus of this White Paper ranges from the security of AI to main security threats, risks, and challenges. Seven recommendations have been made on the importance of improving a system of AI security standards, the need to speed up the development of standards in key areas, promoting the application of AI security standards, strengthening the training of AI security standardization talent, participating in international AI security standardization, establishing an AI high-security risk early warning mechanism, and improving AI security supervision support capabilities. Germany developed an Artificial Intelligence Standardization Roadmap (Wahlster and Cristoph Winterhalter, 2020), continuously updated, as a joint effort between DIN and DKE. The roadmap strongly supports the idea that standardization would improve the explainability and reliability of AI, thus favoring its application. In the roadmap, AI's explainability and reliability, they deal with data reference models for the interoperability of AI systems, development of an AI basic security standard, practice-oriented initial criticality checking of AI systems. In addition, the work provides extensive analysis on the definition of AI as well as classification schemes to evaluate AI-based systems. The work is particularly interesting also for spotlighting issues as the risk-based assessment of applications, trustworthiness, ethical approach and AI application lifecycle. In addition, in each section of the roadmap, specific needs in the direction of standardization are pinpointed. The European Commission (EC) shaped a white paper (“White Paper on Artificial Intelligence,” 2020.) setting out policies to achieve the uptake of AI in the European Union (EU) and to address risks associated with the use of AI technology. Along the sections of the document, it gives particular attention to the opportunity to create an ecosystem of excellence. Six actions have been highlighted, among which: focusing on SMEs and ensuring that each member state has a digital hub highly specialized in AI; strengthening public–private partnerships in AI, data and robotics; and promoting the use of AI in the public sector. An overview of the most significant risks is also provided, with more emphasis on ethical and trustworthy AI. The National Science and Technology Council from the USA’s Executive Office developed an AI Research Development Plan in 2016, later updated in 2019 (Faisal D’Souza, 2019). The Plan does not define specific research agendas for Federal agency investments but highlights strategies to reach a given portfolio. While it must be noted that the utmost focus of the strategies is not on the standardization, strategy 4 “Ensure the Safety and Security of AI Systems'' and Strategy 6 ”Measure and Evaluate AI Technologies through Standards and Benchmarks“ are covering aspects strictly related to standards and certifiability. It is worth mentioning great attention to the development of shared public datasets and open-source libraries, as means to keep the technological lead. Although slightly different in scope, as more oriented towards certification rather than standardization, it is worth mentioning the White Paper (Gregory Flandin et.al., 2021). The document aims at “sharing knowledge, identifying challenges for the certification of systems using ML, and fostering the research effort”. A thorough discussion on the features that an ML-based system should possess to be certified is carried on, leading to the identification of seven challenges to tackle: probabilistic assessment, resilience, specificality, data quality, explainability, robustness, and verifiability. 7.2. Issues and techniques In this section, we offer a brief discussion of the potential unique issues one may encounter when developing and operating a system that incorporates ML. Whenever possible, we discuss some current approaches to bridge these issues. This discussion is meant to be illustrative to the reader and an encouragement to explore the topics in further detail, but it attempts to be comprehensive on neither scope nor depth. Furthermore, the topic is under active research and is likely to expand in the coming years. 7.2.1. Explainability ML models, and particularly large models with lots of free parameters such as large decision trees or NNs, can act as black boxes. The process by which they arrive at the final output can be too complex to be directly interpreted, thus becoming as inscrutable as if the model’s internals had been inaccessible in the first place. However, transparency, explainability, and interpretability are very important for any technical system with a moderate or large impact, be it in terms of dollars or human lives. Therefore, model explainability is very important in fields such as aerospace, medicine, insurance, banking, and more. Explainability is a hard problem because of several reasons. Firstly, it is user-dependent: the type of explanation expected by an average user will differ from that expected by a regulator or an engineer. This leads to the question “How detailed must the explanation be, and what must it cover?”. Secondly, the expected outcome of transmitting an explanation can be hard to define, should the receiver become more able to predict model output after receiving explanations? Must the explanation point univocally to the features of the input data that had the largest impact on the produced results, and is this limited to input data, or does it also include training data? Perhaps it should illustrate a counterfactual - «What would need to change for the decision to have been different? » Or perhaps something else entirely? And are the previous goals mutually exclusive?”. There are a huge number of techniques to answer some of these and related questions. The field of Explainable AI (XAI) for short, is huge and expanding rapidly. Providing an overview of this field is not within the scope of the current publication, but we recommend our readers to consult the Interpretable Machine Learning book (Molnar, 2021) or one of the numerous reviews on the topic to learn more (Linardatos et al., 2021, Tjoa and Guan, 2020). 7.2.2. Robustness and reliability Reliability is the rate of failure of a system when operating in nominal conditions (e.g. 10-9 catastrophic failures per flight hour (“AC 25.1309-1A - System Design and Analysis – Document Information,” 1988)). Since a rate of system error can be extremely challenging to calculate without operating the system, heuristic development rules like no single point of failure are accepted as valid ways to achieve the goal. This acceptance stems from either a competent authority, which implicitly accepts the risk of not properly achieving the desired reliability level or historical data when available. Neither is a possibility for current ML-based systems, due to an absence of historically validated, robust, and widely accepted heuristic design rules. For Machine Learning systems, reliability comes from two distinct factors: accuracy and robustness. An ML classifier with higher accuracy is less likely to misclassify an input, hence is more reliable. Performance does not usually come into play for classical software system’s reliability as accuracy for a valid set of inputs and execution path is 100 %. This section does not concern itself with increasing model accuracy, a topic that is the main focus of each application-specific research field mentioned so far. Accuracy for an ML model is calculated over the data points in the test dataset and only those. While this is also true for classical software testing, in the latter the notion of input equivalence classes provides assurance that the software system will continue to perform acceptably for inputs outside the test set. Correctness equivalence classes for ML models do not currently exist. A similar notion of robustness can be used instead. A robust model has bounded accuracy loss for inputs that are within a bounded distance of the input distribution. This fact can be used to construct arguments for the reliability of an ML model. Equivalence class discovery for random forest models is a topic under active research (Cheng and Yan, 2021, Törnblom and Nadjm-Tehrani, 2019). When demonstrating model robustness, several problems arise: Firstly, how does one quantify the distance between input data? Although several measures exist, they are often hard to relate to humans' tacit notions of input distance. It is easier to qualitatively say to what degree an image does not depict a cat than it is to quantify it in a single measure. This only becomes harder for more abstract forms of input such as satellite telemetry data. Thus, relating system-level specifications to notions of input distance is sometimes complex. For a given distance definition, formal verification methods attempt to formally prove certain properties of DL models, including robustness (Katz et al., 2017, Mirman et al., 2018, Müller et al., 2021, Wang et al., 2018). They allow a user to build a model tolerant to a certain distance between inputs. Equivalent research exists for other ML models, such as random forests (RFs) (Törnblom and Nadjm-Tehrani, 2019), but the literature is significantly less developed. Note that these approaches allow a designer to fight adversarial examples, a specific and concerning failure mode for ML models (Chen et al., 2019, Goodfellow et al., 2015). Nonetheless, the literature on the generation and defeat of adversarial examples is highly active and ever-evolving, as measures, countermeasures, and counter-counter-measures get deployed. It is out of scope for this review to delve any deeper into that. Secondly, there is the well-known issue of generalization. A model may offer very good performance on a dataset and very poor performance on the actual population, in the phenomenon known as overfitting. The PAC-Bayes approach offers generalization bounds that specify a minimum number of samples from distribution for a desired performance and training process reliability levels within that distribution. These bounds, however, are often extremely conservative, and improving them is another active field of research (Shalev-Shwartz, 2014). Since it is hard to quantify these bounds appropriately, the only recourse for organizations to ensure performance is to collect massive amounts of data, which is prohibitively expensive or downright impossible in many cases. Since generalization and robustness shortcomings are highly model-specific, one approach to tackle them focuses on applying mixtures of models working in tandem, known as ensemble models, and selecting an output based on the collective response of the ensemble (Pang et al., 2019, Yang et al., 2021). Thirdly, and also related to the second issue, there is the phenomenon of domain drift (Shweta, 2019). Models do not just overfit to a given dataset but also to the current population. And, as time goes by, systems change. An FDIR system monitoring battery health will see its voltage decrease over time as the battery ages. The statistical distribution of deviations around the nominal value is also likely to change. The performance of the ML model will thus decrease over time as the world changes around it. Fine-tuning on new data can mitigate this issue but can trigger the phenomenon known as catastrophic forgetting (Nguyen et al., 2019), where the model loses performance on old and new data. A solution is to retrain it from scratch on new data, but this entails capturing that data and retraining the model, which increases operating costs and risks in hard to predict ways. Alternative solutions exist but they come with their own drawbacks. Training a model on a dataset representative of the whole system’s life cycle can mitigate the issue but requires larger models and better data capture at the project’s start. Lastly, models also overfit the specifics of the system they’re trained for. A model trained for one specific satellite may have issues adapting to another satellite instance, or model. Version improvements such as equipment changes may bring performance hits with them too. While research fields like transfer learning, domain adaptation and domain generalization (Zhao et al., 2020) attempt to address the issue, they are far from universally reliable at the moment. This is particularly concerning for the space industry, where mass manufacturing and standardized equipment is the exception rather than the norm and can pose a serious challenge to the industry’s adoption of ML technologies. Sometimes, when adapting to new platforms, new input data will be available or new output data may be required. In this case, the field of transfer learning is applicable, which includes both domain adaptation and domain generalization. In short, despite the aforementioned techniques, ML models are extremely brittle to deviations in input data from the training dataset, and it can be assumed that deviations from the training dataset will break the system. Therefore, building proper datasets is a key task of any ML system designer or operator, a topic which we address in the next section. 7.2.3. Dataset construction Datasets are the lifeblood of ML. Therefore, it is only right to have standards assigned for data to avoid anomalies and have a perfect collection that will help produce the right results. Cappi et al. (Cappi et al., 2021) propose a Dataset Definition Standard (DDS), which, while not specifically geared toward space activities, can be applied to EO data from either payload or satellites. It aims to provide a standard for training, validating, or testing datasets. It explains in detail the recommendations to be followed while collecting data and how to annotate it and perform functions. The paper talks about many important aspects any dataset should possess, from how it must cover as many situations as possible that could be encountered during model development to how a history of every single change to every data must be kept helping with traceability and avoid discrepancy. The paper provides clear recommendations for labeling and annotation of data and how the dataset should be segregated for training, validation and testing. The US Geological Survey (Larry R et al., 2019) provides dataset standards for their various operations like Biological, Climate and Forecast and Mapping. Cleansing “dirty data” is mentioned as a common problem faced by data scientists. They also take it a step further with geological mapping by producing a set of parameter standards to be followed while collecting data which define a set of rules for individual parameters within the dataset. The parameter standards cover a wide range of qualities like the date/time, geographic coordinates, codes, etc. the satellite data should contain. Report (Larry R et al., 2019) explains how exactly a topographical map of anything in the US should be produced and one important aspect of it is the data standards including which standards the file formats of the data should be stored in. For the data quality standards, they delve into it by discussing various components like currency, consistency, completeness, and accuracy. The paper covers every aspect of mapping data from dealing with off grid and oversized maps, data sources and resolutions to how cartographic features should be interpreted. The primary space operation in Earth Orbit is remote sensing. As a result, they are the primary data-producing activities. Therefore, remote sensing standards are relatively well developed when compared to other ML operations in the space industry. Authors (Di, 2008, Di and Kobler, 2000) go in-depth about all standards of remote sensing including the dataset standards. Di and Kobler (Liping Di and Ben Kobler, 2000) introduce NASA’s well developed EO Systems’ Data Information Systems (EOSDIS). As the EOSDIS will process data from various fields it is not feasible for the system to deal with every single data collected one by one. This has led to EOSDIS establishing standards to deal specifically with remote sensing data. 7.3. Recommendations As outlined above, ML systems face a number of issues precluding their application in many scenarios where they would otherwise be useful. We believe the fundamental research being carried out on ML model robustness is of great interest and recommend that any practitioner follow it closely. For certain small-scale problems, work on formal verification of ML models may already be enough to ascertain that the network responds appropriately within the input regime, and input data outside of this regime can be purged by data verification systems implemented in classical software. Further, we recommend that any practitioner keep a careful watch for ways in which the lifecycle operation of a system will deviate from the training scenarios, and mitigate the risks issued from model brittleness to these differences. The system must undergo a verification process to be verified and validated. The critical levels of various ML models are displayed in Table 2. Table 2. ML Certification Criticality levels (Winter et al., 2021). Criticality Level (CL) Impact Potential (Examples) ML Application Requirements 1 There is no risk of harm to living beings, no risk of loss of confidential data, and no ethical or privacy concerns. Basic minimum requirements of a competently developed ML application are fulfilled. 2 Living beings could be harmed with limited, no permanent damage. Temporarily unavailability of non-critical data and services, violation of ethical concerns without identifiable harm to actual persons. The ML application is developed according to industry standards and follows best practices that are regarded as state of the art. 3 Living beings could die or be restricted for life; the environment could be damaged. Manipulation of data with severe financial consequences and loss of control of the system to malicious attackers. The ML application is developed and documented with great care. Safety & Security is ensured with processes and techniques that go beyond traditional best practices and industry standards. 4 Many living beings could die or could be restricted for life; the environment could be damaged permanently. Loss of information which endangers the existence of the organization. Long-term unavailability of critical data or services without which the organization cannot function. The ML application is developed and documented with great care. Safety & Security is ensured with processes and techniques that go beyond traditional best practices and industry standards. All components of the ML application are formally secured and validated. Major certification topics must be re-examined, even though known certification procedures for traditional applications cannot be used in a clear manner in the context of ML. This technology's total effectiveness and safety would be enhanced with a comprehensive certification strategy for machine learning applications, which would boost public acceptance and trust. Winter et al (Winter et al., 2021) proposal for certification criteria for supervised learning with low-risk potential is shown in Fig. 6. Download : Download high-res image (128KB) Download : Download full-size image Fig. 6. ML Certification workflow (Winter et al., 2021). ML explainability is another core issue; explainability of model decisions can and does take precedence over model performance in scenarios with high-impact decisions or where (human) learning from the model’s decisions is key. Current model explainability methods can offer insight into the relevant features of input data used for a model’s decision, but they can also provide misleading or unhelpful signals. For applications where explainability is an important feature of the system, dictionary, tree, or kernel-based models and other easily explainable methods should be compared with harder-to-explain models for a performance-explainability trade-off. National recommendations, white papers and initial official standards in the AI and ML field attest to the growing interest in the subject. While the scope of these is much broader than the space sector alone, some considerations can be applied to ML for space applications too. Data quality and availability will play an important role in the adoption of ML across EO Operations and will certainly be demanded by supervisory and regulatory agencies performing standardization and certification. This need goes beyond the mere abundance of data. Relevance, cleanliness, and useability will require careful attention and control. The industry can leverage work from other fields such as the aforementioned dataset standards to achieve this. Publicly available datasets can also be a boon to adoption, such as those listed in (Cole, 2022, Rieke, 2022). 8. Discussion & conclusion In the area of ML in EO Operations, this evaluation effort covers different aspects, including ground operations, enhanced GNC, on-board image processing, FDIR, and standardization. It examined the state of the field, which serves as a baseline, and brought to light intriguing trends. We have discovered that there is mounting evidence in numerous application sectors that EO missions can benefit from ML usage on-board. Case studies uncovered have demonstrated advancements in platform autonomy and performance. New capabilities, such as automated payload data filtering by sending only pertinent photos to the ground, can lower downlink bandwidth requirements, which is crucial for smaller satellites but also lessens radio frequency band saturation. Better visual-based processing also makes it possible for spacecraft to navigate using their visual systems, and RL shows promise in developing more effective nonlinear controllers. Better autonomous decision-making for EO missions is made possible by autonomous FDIR operations, allowing current teams to manage more operations more efficiently and lowering satellite operating costs. On-board processors must meet high criteria imposed by ML algorithms. A significant difficulty is the need to optimize ML models for space applications at the hardware and software levels. The good news for space platform operators is that this reflects and exemplifies the considerably more difficult task of installing ML on edge platforms. The community can benefit from a sizable and growing body of knowledge and expertise. From the perspective of on-board EO applications, ML has mostly been used for cloud detection and novelty/change detection. These applications frequently use vision-based techniques. EO applications could learn technical knowledge from other technical disciplines that have extensively researched vision-based ML methods and solutions. There are a few examples of SAR-based images as well, though. This would imply that there is still an opportunity for advancement and growth of these sensors in all-weather, all-day usage. A parallel but closely related track to research and applications is being standardized. There are currently no established standards for ML in the space industry. Key areas, including explainability, robustness, and data structure creation, are the subject of rigorous research. EO Operators creating ML applications ought to make use of this area for improved performance and dependability. These research areas should be taken into account by organizations intending to publish standards and guidelines, but they must be avoided at all costs to prevent over-prescription of remedies that might compromise the success of standardization development. Another important element that unites all ML-based EO Operations is the availability of data. The ability to use more data for machine learning in EO operations might significantly advance technology and benefit all participants, including business, academia, and space agencies. There are not many open datasets available right now, and those are mostly designed for image processing or visual navigation applications. The technological improvement favored by open datasets in a wider range of applications is a significant long-term goal for the space sector, even while it may be counter to a particular organization's short-term goals to disclose private data. We think the field should concentrate on producing and disseminating such open datasets, and we encourage players without a profit motive like space agencies, to take the lead in attaining this goal. The fact that currently, few EO missions have used ML in orbit is a common finding across the subtopics of this review. This can be ascribed to the space industry's lengthy lead periods and slow cycles, which contrast with other sectors, such the automotive industry, which have embraced the technology. We anticipate that these cycles can be sped up as technology demonstrators move quickly from test benches to orbit with the advent of New Space and faster access to space. Further enhancing the efficiency of ML deployments in the EO Operations industry and the space industry at large, increasing the number of missions can result in better data collecting and platform standardization. Based on the preceding critical review, it is quite evident that incorporating ML into EO operation can maximize its potential and promote additional study. The following key topics will be the focus of EO research in light of current trends and requirements: 1. Investigating the Machine Learning-based Mission Planning and Scheduling (MPS), 2. Examine the potential for Machine Learning techniques to improve Guidance, Navigation and Control (GNC) in space operations, 3. Examine the potential of ML techniques to assist with on-board data processing (OBDP), 4. Explore the effectiveness of incorporating ML models into resource-constrained platforms, 5. Investigate the effectiveness of Fault Detection, Isolation and Recovery (FDIR) using Machine Learning techniques. Not to mention, we have found that the use of ML for EO operations frequently lags behind the state-of-the-art. Transformer models on sequential and other data are one example of a technique that has achieved significant success in research and operational environments but has not yet been publicly used for EO Operations issues. Similar to formal verification and other verified robustness techniques, there are very few applications for resource reduction strategies like pruning, distillation, or quantization. Researchers and operators can use this critical assessment as a resource for further ML deployment and experimentation in demanding, complicated future EO missions that are more autonomous, communicate only useful data, and require much less involvement. Declaration of Competing Interest The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper. Acknowledgements The authors would like to acknowledge the three partner organisations: Mindseed, Satsure, and CNES. Mindseed (“Mindseed,” 2022.) is a company focused on bridging the gap between space and non-space organisations and showcasing the benefits of space for all. Satsure (“SatSure,” 2022.) is an innovative decision analytics company leveraging advances in satellite remote sensing and Machine Learning to achieve the United Nations Sustainable Development Goals. CNES (“cnes | Le site du Centre national d’études spatiales,” 2022.) is the French National Space Agency, with activities all over the space value chain. Their Earth Observation Operations teams provided invaluable feedback for our research. Our three partners reviewed our research, and we are deeply thankful for their collaboration. References AC 25.1309-1A - System Design and Analysis – Document Information, 1988 AC 25.1309-1A - System Design and Analysis – Document Information, 1988. URL https://www.faa.gov/regulations_policies/advisory_circulars/index.cfm/go/document.information/documentid/22680 (accessed 9.11.21). Google Scholar Alam et al., 2022 Alam, S.A., Gregg, D., Gambardella, G., Preusser, M., Blott, M., 2022. On the RTL Implementation of FINN Matrix Vector Compute Unit. Google Scholar Alhichri et al., 2018 Alhichri, H., Alajlan, N., Bazi, Y., Rabczuk, T., 2018. Multi-Scale Convolutional Neural Network for Remote Sensing Scene Classification, in: 2018 IEEE International Conference on Electro/Information Technology (EIT). pp. 1–5. https://doi.org/10.1109/EIT.2018.8500107. Google Scholar Anderson and Berg, 2017 Anderson, A.G., Berg, C.P., 2017. The High-Dimensional Geometry of Binary Neural Networks. ArXiv170507199 Cs. Google Scholar Arechiga et al., 2018 Arechiga, A.P., Michaels, A.J., Black, J.T., 2018. Onboard Image Processing for Small Satellites, in: NAECON 2018 - IEEE National Aerospace and Electronics Conference. pp. 234–240. https://doi.org/10.1109/NAECON.2018.8556744. Google Scholar Arechiga et al., 2018 Arechiga, A.P., Michaels, A.J., Black, J.T., 2018. Onboard Image Processing for Small Satellites, in: NAECON 2018 - IEEE National Aerospace and Electronics Conference. Presented at the NAECON 2018 - IEEE National Aerospace and Electronics Conference, pp. 234–240. https://doi.org/10.1109/NAECON.2018.8556744. Google Scholar Asmaa et al., 2020 Asmaa, A., Haikel, A., Yakoub, B., 2020. SqueezeNet with Attention for Remote Sensing Scene Classification. Google Scholar Azarbad et al., 2014 M. Azarbad, H. Azami, S. Sanei, A. Ebrahimzadeh New neural network-based approaches for GPS GDOP classification based on neuro-fuzzy inference system, radial basis function, and improved bee algorithm Appl. Soft Comput., 25 (2014), pp. 285-292, 10.1016/j.asoc.2014.09.022 View PDFView articleView in ScopusGoogle Scholar Ba and Caruana, 2013 Ba, L.J., Caruana, R., 2013. Do Deep Nets Really Need to be Deep? Google Scholar Baker et al., 2017 Baker, B., Gupta, O., Naik, N., Raskar, R., 2017. Designing Neural Network Architectures using Reinforcement Learning. ArXiv161102167 Cs. Google Scholar Baranwal et al., 2018 Baranwal, P., Batta, K., Kaushik, T., 2018. Comparative Study of Classical and Fuzzy PID Attitude Control System with Extended Kalman Filter Feedback for Nanosatellites. Google Scholar Bazzi et al., 2020 H. Bazzi, D. Ienco, N. Baghdadi, M. Zribi, V. Demarez Distilling before refine: spatio-temporal transfer learning for mapping irrigated areas using Sentinel-1 time series IEEE Geosci. Remote Sens. Lett., 17 (2020), pp. 1909-1913, 10.1109/LGRS.2019.2960625 View in ScopusGoogle Scholar Belward and Skøien, 2015 A.S. Belward, J.O. Skøien Who launched what, when and why; trends in global land-cover observation capacity from civilian earth observation satellites ISPRS J. Photogramm. Remote Sens. Global Land Cover Mapping Monit., 103 (2015), pp. 115-128, 10.1016/j.isprsjprs.2014.03.009 View PDFView articleView in ScopusGoogle Scholar Blalock et al., 2020 Blalock, D., Ortiz, J.J.G., Frankle, J., Guttag, J., 2020. What is the State of Neural Network Pruning? ArXiv200303033 Cs Stat. Google Scholar Bonnet et al., 2015 J. Bonnet, M.-P. Gleizes, E. Kaddoum, S. Rainjonneau, G. Flandin Multi-satellite Mission Planning Using a Self-Adaptive Multi-agent System In: 2015 IEEE 9th International Conference on Self-Adaptive and Self-Organizing Systems, IEEE, Cambridge, MA, USA (2015), pp. 11-20, 10.1109/SASO.2015.9 View in ScopusGoogle Scholar Browne et al., 2020 D. Browne, M. Giering, S. Prestwich PulseNetOne: fast unsupervised pruning of convolutional neural networks for remote sensing Remote Sens., 12 (2020), p. 1092, 10.3390/rs12071092 View in ScopusGoogle Scholar Bruhn et al., 2020 Bruhn, F.C., Tsog, N., Kunkel, F., Flordal, O., 2020. Enabling radiation tolerant heterogeneous GPU‑based onboard data processing in space. Vol01234567891 3CEAS Space Journa 12, 551–564. Google Scholar Buonaiuto et al., 2017 Buonaiuto, N., Kief, C., Louie, M., Aarestad, J., Zufelt, B., Mital, R., Mateik, D., Sivilli, R., Bhopale, A., 2017. Satellite Identification Imaging for Small Satellites Using NVIDIA 12. Google Scholar Cai et al., 2003 Cai, Y., Hu, Y., Siegel, M., Gollapalli, S.J., Venugopal, A.R., Bardak, U., 2003. Onboard Feature Indexing from Satellite Lidar Images 4. Google Scholar Cappi et al., 2021 Cappi, C., Chapdelaine, C., Gardes, L., Jenn, E., Lefevre, B., Picard, S., Soumarmon, T., 2021. Dataset Definition Standard (DDS). ArXiv210103020 Cs. Google Scholar Castaño et al., 2007 Ricard Castaño, Steve Ankuo Chien, Kiri L. Wagstaff, Timothy M. Stough, 2007. On-board analysis of uncalibrated data for a spacecraft at mars, in: Proceedings of the 13th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, San Jose, California, USA, August 12-15, 2007. San Jose, California, USA. https://doi.org/10.1145/1281192.1281291. Google Scholar Castelluccio et al., 2015 Castelluccio, M., Poggi, G., Sansone, C., Verdoliva, L., 2015. Land Use Classification in Remote Sensing Images by Convolutional Neural Networks. ArXiv150800092 Cs. Google Scholar Chai et al., 2020 Y. Chai, K. Fu, X. Sun, W. Diao, Z. Yan, Y. Feng, L. Wang Compact cloud detection with bidirectional self-attention knowledge distillation Remote Sens., 12 (2020), p. 2770, 10.3390/rs12172770 View in ScopusGoogle Scholar Chan et al., 2018 M. Chan, D. Scarafoni, R. Duarte, J. Thornton, L. Skelly Learning Network Architectures of Deep CNNs Under Resource Constraints In: 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), IEEE, Salt Lake City, UT, USA (2018), pp. 1784-17847, 10.1109/CVPRW.2018.00222 Google Scholar Chen et al., 2019 Chen, H., Zhang, H., Boning, D., Hsieh, C.-J., 2019. Robust Decision Trees Against Adversarial Examples. ArXiv190210660 Cs Stat. Google Scholar Chen et al., 2021 Chen, Y., Bian, Y., Xiao, X., Rong, Y., Xu, T., Huang, J., 2021. On Self-Distilling Graph Neural Network. ArXiv201102255 Cs Stat. Google Scholar Chen et al., 2018 G. Chen, X. Zhang, X. Tan, Y. Cheng, F. Dai, K. Zhu, Y. Gong, Q. Wang Training small networks for scene classification of remote sensing images via knowledge distillation Remote Sens., 10 (2018), p. 719, 10.3390/rs10050719 View in ScopusGoogle Scholar Cheng and Yan, 2021 Cheng, C.-H., Yan, R., 2021. Testing Autonomous Systems with Believed Equivalence Refinement. ArXiv210304578 Cs. Google Scholar Cheng et al., 2009 C.-H. Cheng, S.-L. Shu, P.-J. Cheng Attitude control of a satellite using fuzzy controllers Expert Syst. Appl., 36 (2009), pp. 6613-6620, 10.1016/j.eswa.2008.08.053 View PDFView articleView in ScopusGoogle Scholar Chien et al., 2017 S. Chien, J. Doubleday, D.R. Thompson, K.L. Wagstaff, J. Bellardo, C. Francis, E. Baumgarten, A. Williams, E. Yee, E. Stanton, J. Piug-Suari Onboard autonomy on the intelligent payload experiment cubesat mission J. Aerosp. Inf. Syst., 14 (2017), pp. 307-315, 10.2514/1.I010386 View in ScopusGoogle Scholar cnes | Le site du Centre national d’études spatiales, 2022 cnes | Le site du Centre national d’études spatiales, 2022. URL https://cnes.fr/fr/ (accessed 7.18.22). Google Scholar Codetta-Raiteri and Portinale, 2015 D. Codetta-Raiteri, L. Portinale Dynamic bayesian networks for fault detection, identification, and recovery in autonomous spacecraft IEEE Trans. Syst. Man Cybern. Syst., 45 (2015), pp. 13-24, 10.1109/TSMC.2014.2323212 View in ScopusGoogle Scholar Cole, 2022 Cole, R.M., 2022. satellite-image-deep-learning. Google Scholar Courbariaux et al., 2015 M. Courbariaux, Y. Bengio, J.-P. David BinaryConnect: Training Deep Neural Networks with binary weights during propagations C. Cortes, N. Lawrence, D. Lee, M. Sugiyama, R. Garnett (Eds.), Advances in Neural Information Processing Systems, Curran Associates Inc (2015) Google Scholar D’Souza, 2019 Faisal D’Souza, 2019. The National Artificial Intelligence Research and Development Strategic Plan: 2019 Update 50. Google Scholar de Vieilleville et al., 2020 F. de Vieilleville, A. Lagrange, R. Ruiloba, S. May Towards distillation of deep neural networks for satellite on-board image segmentation Int. Arch. Photogramm. Remote Sens. Spat. Inf. Sci., 43 (2020), pp. 1553-1559 CrossRefView in ScopusGoogle Scholar Deepan and Sudha, 2020 Deepan, P., Sudha, L.R., 2020. Object Classification of Remote Sensing Image Using Deep Convolutional Neural Network, in: The Cognitive Approach in Cloud Computing and Internet of Things Technologies for Surveillance Tracking Systems. Elsevier, pp. 107–120. https://doi.org/10.1016/B978-0-12-816385-6.00008-8. Google Scholar Del Rosso et al., 2021 M.P. Del Rosso, A. Sebastianelli, D. Spiller, P.P. Mathieu, S.L. Ullo On-board volcanic eruption detection through CNNs and satellite multispectral imagery Remote Sens., 13 (2021), p. 3479, 10.3390/rs13173479 View in ScopusGoogle Scholar Di, 2008 L. Di Standards, Critical Evaluation of Remote Sensing S. Shekhar, H. Xiong (Eds.), Encyclopedia of GIS, Springer, US, Boston, MA (2008), pp. 1128-1135, 10.1007/978-0-387-35973-1_1346 Google Scholar Di and Kobler, 2000 Liping Di, Ben Kobler, 2000. NASA Standards for Earth Remote Sensing Data, URL https://www.researchgate.net/publication/228953572_NASA_Standards_for_Earth_Remote_Sensing_Data (accessed 9.4.21) Google Scholar Du et al., 2020 Y. Du, T. Wang, B. Xin, L. Wang, Y. Chen, L. Xing A data-driven parallel scheduling approach for multiple agile earth observation satellites IEEE Trans. Evol. Comput., 24 (2020), pp. 679-693, 10.1109/TEVC.2019.2934148 View in ScopusGoogle Scholar Elsken et al., 2019 Elsken, T., Metzen, J.H., Hutter, F., 2019. Neural Architecture Search: A Survey. ArXiv180805377 Cs Stat. Google Scholar Esposito et al., 2019 M. Esposito, S.S. Conticello, M. Pastena, B.C. Domínguez In-orbit demonstration of artificial intelligence applied to hyperspectral and thermal sensing from space CubeSats and SmallSats for Remote Sensing III, International Society for Optics and Photonics (2019), p. 111310C, 10.1117/12.2532262 View in ScopusGoogle Scholar Férésin et al., 2021 Frédéric Férésin, Erwann Kervennic, Yves Bobichon, Edgar Lemaire, Nassim Abderrahmane, Gaétan Bahk, Ingrid Grenet, Matthieu Moretti, Michaël Benguigui, 2021. In space image processing using AI embedded on system on module : example of OPS-SAT cloud segmentation. Google Scholar Flandin, 2021 Gregory Flandin, 2021. White Paper Machine Learning in Certified System 113. Google Scholar Fourati and Alouini, 2021 F. Fourati, M.-S. Alouini Artificial intelligence for satellite communication: A review Intelligent and Converged Networks, 2 (3) (2021), pp. 213-243, 10.23919/ICN.2021.0015 Google Scholar Frankle et al., 2021 Frankle, J., Dziugaite, G.K., Roy, D.M., Carbin, M., 2021. Pruning Neural Networks at Initialization: Why are We Missing the Mark? ArXiv200908576 Cs Stat. Google Scholar Fuertes et al., 2018 S. Fuertes, B. Pilastre, S. D’Escrivan Performance assessment of NOSTRADAMUS & other machine learning-based telemetry monitoring systems on a spacecraft anomalies database In: 2018 SpaceOps Conference, American Institute of Aeronautics and Astronautics, Marseille, France (2018), 10.2514/6.2018-2559 Google Scholar Georges et al., 2021 Georges, L., Tanguy, S., Evridiki, N., David, E., 2021. In-Flight Training of a FDIR Model with Online Machine Learning on the OPS-SAT Spacecraft. URL https://github.com/georgeslabreche/opssat-orbitai/find/main (accessed 9.12.21). Google Scholar Giuffrida et al., 2020 G. Giuffrida, L. Diana, F. de Gioia, G. Benelli, G. Meoni, M. Donati, L. Fanucci CloudScout: a deep neural network for on-board cloud detection on hyperspectral images Remote Sens., 12 (2020), p. 2205, 10.3390/rs12142205 View in ScopusGoogle Scholar Giuffrida et al., 2022 G. Giuffrida, L. Fanucci, G. Meoni, M. Batič, L. Buckley, A. Dunne, C. van Dijk, M. Esposito, J. Hefele, N. Vercruyssen, G. Furano, M. Pastena, J. Aschbacher The Φ-Sat-1 mission: the first on-board deep neural network demonstrator for satellite Earth observation IEEE Trans. Geosci. Remote Sens., 60 (2022), pp. 1-14, 10.1109/TGRS.2021.3125567 Google Scholar Globus et al., 2003 Globus, A., Crawford, J., Lohn, J., Pryor, A., 2003. Scheduling Earth Observing Satellites with Evolutionary Algorithms. Google Scholar Goel et al., 2020 A. Goel, C. Tung, Y.-H. Lu, G.K. Thiruvathukal A Survey of Methods for Low-Power Deep Learning and Computer Vision In: 2020 IEEE 6th World Forum on Internet of Things (WF-IoT). Presented at the 2020 IEEE 6th World Forum on Internet of Things (WF-IoT) (2020), pp. 1-6, 10.1109/WF-IoT48130.2020.9221198 Google Scholar Gong et al., 2014 Gong, Y., Liu, L., Yang, M., Bourdev, L., 2014. Compressing Deep Convolutional Networks using Vector Quantization. ArXiv14126115 Cs. Google Scholar Goodfellow et al., 2015 Goodfellow, I.J., Shlens, J., Szegedy, C., 2015. Explaining and Harnessing Adversarial Examples. ArXiv14126572 Cs Stat. Google Scholar Goodwill et al., 2020 Goodwill, J., Wilson, D., Sabogal, S., George, A.D., Wilson, C., 2020. Adaptively Lossy Image Compression for Onboard Processing, in: 2020 IEEE Aerospace Conference. pp. 1–15. https://doi.org/10.1109/AERO47225.2020.9172536. Google Scholar Goodwill et al., 2021 Goodwill, J., Crum, G., MacKinnon, J., Brewer, C., Monaghan, M., Wise, T., Wilson, C., 2021. NASA SpaceCube Edge TPU SmallSat Card for Autonomous Operations and Onboard Science-Data Analysis 13. Google Scholar Graham et al., 2023 Graham, Thomas & Thangavel, Kathiravan & Martin, Anne-Sophie. (2023). New Challenges for International Space Law: Artificial Intelligence and Liability. 17th International Conference on Space Operations, Dubai, United Arab Emirates. Google Scholar Guo et al., 2017 Q. Guo, B. Fu, P. Shi, T. Cudahy, J. Zhang, H. Xu Satellite monitoring the spatial-temporal dynamics of desertification in response to climate change and human activities across the Ordos Plateau, China Remote Sens., 9 (2017), p. 525, 10.3390/rs9060525 View PDFView articleGoogle Scholar Guo, 2018 Guo, Y., 2018. A Survey on Methods and Theories of Quantized Neural Networks. ArXiv180804752 Cs Stat. Google Scholar Hadj-Salah et al., 2019 Hadj-Salah, A., Verdier, R., Caron, C., Picard, M., Capelle, M., 2019. Schedule Earth Observation satellites with Deep Reinforcement Learning. ArXiv191105696 Cs. Google Scholar Hadj-Salah et al., 2020 Hadj-Salah, A., Guerra, J., Picard, M., Capelle, M., 2020. Towards operational application of Deep Reinforcement Learning to Earth Observation satellite scheduling. Google Scholar Haikel, 2018 Haikel, A., 2018. Multitask Classification of Remote Sensing Scenes Using Deep Neural Networks. Spain. Google Scholar Han et al., 2016 Han, S., Mao, H., Dally, W.J., 2016. Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding. ArXiv151000149 Cs. Google Scholar Han et al., 2015 H. Han, S. Lee, J. Im, M. Kim, M.-I. Lee, M.H. Ahn, S.-R. Chung Detection of convective initiation using meteorological imager onboard communication, ocean, and meteorological satellite based on machine learning approaches Remote Sens., 7 (2015), pp. 9184-9204, 10.3390/rs70709184 View in ScopusGoogle Scholar He et al., 2014 He, T., Fan, Y., Qian, Y., Tan, T., Yu, K., 2014. Reshaping deep neural network for fast decoding by node-pruning, in: 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, Florence, Italy, pp. 245–249. https://doi.org/10.1109/ICASSP.2014.6853595. Google Scholar He et al., 2021 X. He, K. Zhao, X. Chu AutoML: a survey of the state-of-the-art Knowl.-Based Syst., 212 (2021), Article 106622, 10.1016/j.knosys.2020.106622 View PDFView articleView in ScopusGoogle Scholar Hernández-Gómez et al., 2019 Hernández-Gómez, J.J., Yañez-Casas, G.A., Torres-Lara, A.M., Couder-Castañeda, C., Orozco-del-Castillo, M.G., Valdiviezo-Navarro, J.C., Medina, I., Solís-Santomé, A., Vázquez-Álvarez, D., Chávez-López, P.I., 2019. Conceptual low-cost on-board high performance computing in CubeSat nanosatellites for pattern recognition in Earth’s remote sensing. pp. 114–104. https://doi.org/10.29007/8d25. Google Scholar Hinz et al., 2020 Hinz, R., Bravo, J.I., Kerr, M., Marcos, C., Latorre, A., Membibre, F., 2020. EO-ALERT: Machine Learning-Based On-Board Satellite Processing for Very-Low Latency Convective Storm Nowcasting 1. Google Scholar Hoeser et al., 2020 T. Hoeser, F. Bachofer, C. Kuenzer Object detection and image segmentation with deep learning on earth observation data: a review—part II: applications Remote Sens., 12 (2020), p. 3053, 10.3390/rs12183053 View in ScopusGoogle Scholar Howard et al., 2017 Howard, A.G., Zhu, M., Chen, B., Kalenichenko, D., Wang, W., Weyand, T., Andreetto, M., Adam, H., 2017. MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications. ArXiv170404861 Cs. Google Scholar Huq et al., 2018 Huq, R., Bappy, M., Siddique, S., 2018. AI-OBC: Conceptual Design of a Deep Neural Network based Next Generation Onboard Computing Architecture for Satellite Systems. Google Scholar Iandola et al., 2016 Iandola, F.N., Han, S., Moskewicz, M.W., Ashraf, K., Dally, W.J., Keutzer, K., 2016. SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5MB model size. ArXiv160207360 Cs. Google Scholar Ireland, 2019 Ireland, M., 2019. Integrating AI Techniques Into Future Nanosatellite Onboard Data Processing 30. Google Scholar Iverson, 2008 Iverson, D.L., 2008. System Health Monitoring for Space Mission Operations, in: 2008 IEEE Aerospace Conference. IEEE, Big Sky, MT, USA, pp. 1–8. https://doi.org/10.1109/AERO.2008.4526646. Google Scholar Izzo and Öztürk, 2021 Izzo, D., Öztürk, E., 2021. Real-Time Guidance for Low-Thrust Transfers Using Deep Neural Networks. J. Guid. Control Dyn. 44, 315–327. https://doi.org/10.2514/1.G005254. Google Scholar Izzo et al., 2018 Izzo, D., Märtens, M., Pan, B., 2018. A Survey on Artificial Intelligence Trends in Spacecraft Guidance Dynamics and Control. ArXiv181202948 Cs. Google Scholar Jaekel and Scholz, 2015 Jaekel, S., Scholz, B., 2015. Utilizing Artificial Intelligence to achieve a robust architecture for future robotic spacecraft, in: 2015 IEEE Aerospace Conference. IEEE, Big Sky, MT, pp. 1–14. https://doi.org/10.1109/AERO.2015.7119180. Google Scholar Jalilian et al., 2017 Jalilian, S., SalarKaleji, F., Kazimov, T., 2017. Fault detection, isolation and recovery (FDIR) in satellite onboard software. https://doi.org/10.25045/NCSoftEng.2017.87. Google Scholar Joghataie, 1994 Joghataie, A., 1994. Neural Networks and Fuzzy Logic for Structural Control. University of Illinois Engineering Experiment Station. College of Engineering. University of Illinois at Urbana-Champaign. Google Scholar Katz et al., 2017 Katz, G., Barrett, C., Dill, D., Julian, K., Kochenderfer, M., 2017. Reluplex: An Efficient SMT Solver for Verifying Deep Neural Networks. ArXiv170201135 Cs. Google Scholar Kavzoglu and Mather, 1999 T. Kavzoglu, P.M. Mather Pruning artificial neural networks: an example using land cover classification of multi-sensor images Int. J. Remote Sens., 20 (1999), pp. 2787-2803, 10.1080/014311699211796 View in ScopusGoogle Scholar Kim et al., 2016 Kim, S.-W., Park, S.-Y., Park, C., 2016. Spacecraft attitude control using neuro-fuzzy approximation of the optimal controllers. Adv. Space Res. 57, 137–152. https://doi.org/10.1016/j.asr.2015.09.016. Google Scholar Koizumi et al., 2018 Koizumi, S., Kikuya, Y., Sasaki, K., Masuda, Y., Iwasaki, Y., Watanabe, K., Yatsu, Y., Matsunaga, S., 2018. Development of Attitude Sensor using Deep Learning 8. Google Scholar Kothari et al., 2020 Kothari, V., Liberis, E., Lane, N.D., 2020. The Final Frontier: Deep Learning in Space. ArXiv200110362 Cs Eess. Google Scholar Krizhevsky et al., 2012 A. Krizhevsky, I. Sutskever, G.E. Hinton ImageNet Classification with Deep Convolutional Neural Networks Advances in Neural Information Processing Systems, Curran Associates Inc. (2012) Google Scholar Kucik and Meoni, 2021 Kucik, A., Meoni, G., 2021. Investigating Spiking Neural Networks for Energy-Efficient On-Board AI Applications. A Case Study in Land Cover and Land Use Classification. https://doi.org/10.1109/CVPRW53098.2021.00230 Google Scholar Lane et al., 2015 Lane, N.D., Bhattacharya, S., Georgiev, P., Forlivesi, C., Kawsar, F., 2015. An Early Resource Characterization of Deep Learning on Wearables, Smartphones and Internet-of-Things Devices, in: Proceedings of the 2015 International Workshop on Internet of Things towards Applications. ACM, Seoul South Korea, pp. 7–12. https://doi.org/10.1145/2820975.2820980 Google Scholar Larq | Binarized Neural Network development, 2022 Larq | Binarized Neural Network development, 2022. URL https://larq.dev/ (accessed 7.28.21). Google Scholar Larry et al., 2019 R. Larry, K.A. Davis, H.L. Fishburn, L.R. Moore, J.L. Walter US Topo Product Standard (Techniques and Methods) Techniques and Methods (2019) Google Scholar Lazarevic and Obradovic, 2001 Lazarevic, A., Obradovic, Z., 2001. Effective pruning of neural network classifier ensembles, in: IJCNN’01. International Joint Conference on Neural Networks. Proceedings (Cat. No.01CH37222). IEEE, Washington, DC, USA, pp. 796–801. https://doi.org/10.1109/IJCNN.2001.939461. Google Scholar Li et al., 2014 J. Li, J. Li, H. Chen, N. Jing A data transmission scheduling algorithm for rapid-response earth-observing operations Chin. J. Aeronaut., 27 (2014), pp. 349-364, 10.1016/j.cja.2014.02.014 View PDFView articleView in ScopusGoogle Scholar Liang et al., 2020 W. Liang, J. Li, W. Diao, X. Sun, K. Fu, Y. Wu FGATR-net: automatic network architecture design for fine-grained aircraft type recognition in remote sensing images Remote Sens., 12 (2020), p. 4187, 10.3390/rs12244187 Google Scholar Linardatos et al., 2021 Linardatos, P., Papastefanopoulos, V., Kotsiantis, S., 2021. Explainable AI: A Review of Machine Learning Interpretability Methods. Entropy 23, 18. https://doi.org/10.3390/e23010018. Google Scholar Liu et al., 2018 R. Liu, B. Yang, E. Zio, X. Chen Artificial intelligence for fault diagnosis of rotating machinery: a review Mech. Syst. Signal Process., 108 (2018), pp. 33-47, 10.1016/j.ymssp.2018.02.016 View PDFView articleView in ScopusGoogle Scholar Liu, 2020 Liu, X., 2020. Mission schedule of agile satellites based on Proximal Policy Optimization Algorithm. ArXiv200702352 Cs. Google Scholar Liu, et al., 2021 Liu, Yuchen, et al. “Mission Planning for Earth Observation Satellite With Competitive Learning Strategy.” Aerospace Science and Technology, vol. 118, Elsevier BV, Nov. 2021, p. 107047. Crossref, https://doi.org/10.1016/j.ast.2021.107047. Google Scholar Ma et al., 2019 N. Ma, X. Yu, Y. Peng, S. Wang A lightweight hyperspectral image anomaly detector for real-time mission Remote Sens., 11 (2019), p. 1622, 10.3390/rs11131622 View in ScopusGoogle Scholar Maggiori et al., 2017 E. Maggiori, Y. Tarabalka, G. Charpiat, P. Alliez Convolutional neural networks for large-scale remote-sensing image classification IEEE Trans. Geosci. Remote Sens., 55 (2017), pp. 645-657, 10.1109/TGRS.2016.2612821 View in ScopusGoogle Scholar Mahajan and Fataniya, 2020 S. Mahajan, B. Fataniya Cloud detection methodologies: variants and development—a review Complex Intell. Syst., 6 (2020), pp. 251-261, 10.1007/s40747-019-00128-0 View in ScopusGoogle Scholar Manning et al., 2018 J. Manning, D. Langerman, B. Ramesh, E. Gretok, C. Wilson, A. George, J. MacKinnon, G. Crum Machine-Learning Space Applications on SmallSat Platforms with TensorFlow Small Satell, Conf (2018) Google Scholar Mansour and Dessouky, 2010 M.A.A. Mansour, M.M. Dessouky A genetic algorithm approach for solving the daily photograph selection problem of the SPOT5 satellite Comput. Ind. Eng., 58 (2010), pp. 509-520, 10.1016/j.cie.2009.11.012 View PDFView articleView in ScopusGoogle Scholar Maskey and Cho, 2020 A. Maskey, M. Cho CubeSatNet: ultralight convolutional neural network designed for on-orbit binary image classification on a 1U CubeSat Eng. Appl. Artif. Intell., 96 (2020), Article 103952, 10.1016/j.engappai.2020.103952 View PDFView articleView in ScopusGoogle Scholar Meß, 2019 Meß, J.-G., 2019. Techniques of Artificial Intelligence for Space Applications - A Survey. Google Scholar Mirman et al., 2018 M. Mirman, T. Gehr, M. Vechev Differentiable abstract interpretation for provably robust neural networks Int. Conf. Mach. Learn. PMLR (2018), pp. 3578-3586 Google Scholar Mishra et al., 2017 Mishra, A., Cook, J.J., Nurvitadhi, E., Marr, D., 2017. WRPN: Training and Inference using Wide Reduced-Precision Networks. ArXiv170403079 Cs. Google Scholar Mittal, 2019 S. Mittal A survey on optimized implementation of deep learning models on the NVIDIA Jetson platform J. Syst. Archit., 97 (2019), pp. 428-442, 10.1016/j.sysarc.2019.01.011 View PDFView articleView in ScopusGoogle Scholar Mnih et al., 2013 Mnih, V., Kavukcuoglu, K., Silver, D., Graves, A., Antonoglou, I., Wierstra, D., Riedmiller, M., 2013. Playing Atari with Deep Reinforcement Learning. ArXiv13125602 Cs. Google Scholar Molchanov et al., 2017 Molchanov, D., Ashukha, A., Vetrov, D., 2017. Variational Dropout Sparsifies Deep Neural Networks. ArXiv170105369 Cs Stat. Google Scholar Molnar, 2021 Molnar, C., 2021. Interpretable Machine Learning. Google Scholar Müller et al., 2021 Müller, M.N., Makarchuk, G., Singh, G., Püschel, M., Vechev, M., 2021. PRIMA: Precise and General Neural Network Certification via Multi-Neuron Convex Relaxations 20. Google Scholar Nguyen et al., 2019 Nguyen, C.V., Achille, A., Lam, M., Hassner, T., Mahadevan, V., Soatto, S., 2019. Toward Understanding Catastrophic Forgetting in Continual Learning. ArXiv190801091 Cs Stat. Google Scholar O’Meara et al., 2016 O’Meara, C., Schlag, L., Faltenbacher, L., Wickler, M., 2016. ATHMoS: Automated Telemetry Health Monitoring System at GSOC using Outlier Detection and Supervised Machine Learning. https://doi.org/10.2514/6.2016-2347. Google Scholar olanleed, 2021 olanleed, 2021. MochiMochi. 2021. Accessed: Sep. 29, 2021. [Online]. Available: https://github.com/olanleed/MochiMochi Google Scholar Olive, 2010 X. Olive FDI(R) for satellite at Thales Alenia Space how to deal with high availability and robustness in space domain? In: 2010 Conference on Control and Fault-Tolerant Systems (SysTol). Presented at the 2010 Conference on Control and Fault-Tolerant Systems (SysTol), IEEE, Nice (2010), pp. 837-842, 10.1109/SYSTOL.2010.5675942 View in ScopusGoogle Scholar Ortega, 1995 G. Ortega Fuzzy logic techniques for rendezvous and docking of two geostationary satellites Telemat. Inform. Adv. Space Technol. Syst. Auton., 12 (1995), pp. 213-227, 10.1016/0736-5853(95)00013-5 View PDFView articleView in ScopusGoogle Scholar Pan et al., 2021 G. Pan, Y. Xu, J. Ma The potential of CO2 satellite monitoring for climate governance: a review J. Environ. Manage., 277 (2021), Article 111423, 10.1016/j.jenvman.2020.111423 View PDFView articleView in ScopusGoogle Scholar Pang et al., 2019 Pang, T., Xu, K., Du, C., Chen, N., Zhu, J., 2019. Improving Adversarial Robustness via Promoting Ensemble Diversity, in: Proceedings of the 36th International Conference on Machine Learning. PMLR, pp. 4970–4979. Google Scholar Pant, 2019 Pant, Ayush. “Workflow of a Machine Learning Project.” Medium, 23 Jan. 2019, towardsdatascience.com/workflow-of-a-machine-learning-project-ec1dba419b94. Google Scholar Peng et al., 2018 S. Peng, H. Chen, C. Du, J. Li, N. Jing Onboard observation task planning for an autonomous earth observation satellite using long short-term memory IEEE Access, 6 (2018), pp. 65118-65129, 10.1109/ACCESS.2018.2877687 View in ScopusGoogle Scholar Pilastre, 2020 Pilastre, B., 2020. Estimation parcimonieuse et apprentissage de dictionnaires pour la détection d’anomalies multivariées dans des données mixtes de télémesure satellites (phd). Google Scholar Pitsis et al., 2019 Pitsis, G., Tsagkatakis, G., Kozanitis, C., Kalomoiris, I., Ioannou, A., Dollas, A., Katevenis, M.G.H., Tsakalides, P., 2019. Efficient Convolutional Neural Network Weight Compression for Space Data Classification on Multi-fpga Platforms, in: ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, Brighton, United Kingdom, pp. 3917–3921. https://doi.org/10.1109/ICASSP.2019.8682732. Google Scholar Polino et al., 2018 Polino, A., Pascanu, R., Alistarh, D., 2018. Model compression via distillation and quantization. ArXiv180205668 Cs. Google Scholar Poortinga et al., 2021 A. Poortinga, N.S. Thwal, N. Khanal, T. Mayer, B. Bhandari, K. Markert, A.P. Nicolau, J. Dilger, K. Tenneson, N. Clinton, D. Saah Mapping sugarcane in Thailand using transfer learning, a lightweight convolutional neural network, NICFI high resolution satellite imagery and Google Earth Engine ISPRS Open J. Photogramm. Remote Sens., 1 (2021), Article 100003, 10.1016/j.ophoto.2021.100003 View PDFView articleView in ScopusGoogle Scholar Post-training quantization | TensorFlow Lite, 2022 Post-training quantization | TensorFlow Lite, 2022. URL https://www.tensorflow.org/lite/performance/post_training_quantization (accessed 9.28.21). Google Scholar Pruning in Keras example | TensorFlow Model Optimization, 2022 Pruning in Keras example | TensorFlow Model Optimization , 2022. . TensorFlow. URL https://www.tensorflow.org/model_optimization/guide/pruning/pruning_with_keras (accessed 8.6.21) Google Scholar Qin et al., 2020 H. Qin, R. Gong, X. Liu, X. Bai, J. Song, N. Sebe Binary neural networks: a survey Pattern Recognit., 105 (2020), Article 107281, 10.1016/j.patcog.2020.107281 View PDFView articleView in ScopusGoogle Scholar Quantization — PyTorch 1.9.1 documentation, 2022 Quantization — PyTorch 1.9.1 documentation, 2022. URL https://pytorch.org/docs/stable/quantization.html (accessed 7.28.21). Google Scholar Ranasinghe et al., 2022 K. Ranasinghe, R. Sabatini, A. Gardi, S. Bijjahalli, R. Kapoor, T. Fahey, K. Thangavel Advances in integrated system health management for mission-essential and safety-critical aerospace applications Prog. Aerosp. Sci., 128 (2022), Article 100758, 10.1016/j.paerosci.2021.100758 View PDFView articleView in ScopusGoogle Scholar Rastegari et al., 2016 Rastegari, M., Ordonez, V., Redmon, J., Farhadi, A., 2016. XNOR-Net: ImageNet Classification Using Binary Convolutional Neural Networks. ArXiv160305279 Cs. Google Scholar Ricks and Mengshoel, 2021 W. Ricks, B.J. Mengshoel, O. Methods for Probabilistic Fault Diagnosis: An Electrical Power System Case Study Annual Conference of the PHM Society, 1 (1) (2021) Retrieved from https://papers.phmsociety.org/index.php/phmconf/article/view/1594More Citation Formats Google Scholar Rieke, 2022 Rieke, C., 2022. Awesome Satellite Imagery Datasets. Github: https://github.com/chrieke/awesome-satellite-imagery-datasets. Google Scholar SatSure, 2022 SatSure, 2022. URL: https://satsure.co/ (accessed 7.18.22). Google Scholar Schumann et al., 2011 J. Schumann, O.J. Mengshoel, T. Mbaya Integrated Software and Sensor Health Management for Small Spacecraft In: 2011 IEEE Fourth International Conference on Space Mission Challenges for Information Technology, IEEE, Palo Alto, CA, USA (2011), pp. 77-84, 10.1109/SMC-IT.2011.25 View in ScopusGoogle Scholar Shalev-Shwartz, 2014 Shalev-Shwartz, S., 2014. Understanding Machine Learning: From Theory to Algorithms, 1st edition. ed. Cambridge University Press, New York, NY, USA Google Scholar Shaw and Burke, 2003 G.A. Shaw, H.K. Burke Spectral Imaging for Remote Sensing, 14 (2003), p. 26 View in ScopusGoogle Scholar Shweta, 2019 Shweta, K., 2019. A Survey on Classification of Concept Drift with Stream Data. Google Scholar Simons and Lee, 2019 T. Simons, D.-J. Lee A review of binarized neural networks Electronics, 8 (2019), p. 661, 10.3390/electronics8060661 View in ScopusGoogle Scholar Simonyan and Zisserman, 2015 Simonyan, K., Zisserman, A., 2015. Very Deep Convolutional Networks for Large-Scale Image Recognition. ArXiv14091556 Cs. Google Scholar Song et al., 2020 Y. Song, Z. Zhou, Z. Zhang, F. Yao, Y. Chen A framework involving MEC: imaging satellites mission planning Neural Comput. Appl., 32 (2020), pp. 15329-15340, 10.1007/s00521-019-04047-6 View in ScopusGoogle Scholar Spiller et al., 2022 D. Spiller, K. Thangavel, S. T. Sasidharan, S. Amici, L. Ansalone and R. Sabatini, “Wildfire segmentation analysis from edge computing for on-board real-time alerts using hyperspectral imagery,” 2022 IEEE International Conference on Metrology for Extended Reality, Artificial Intelligence and Neural Engineering (MetroXRAINE), 2022, pp. 725-730, doi: 10.1109/MetroXRAINE54828.2022.9967553. Google Scholar Srivastava, 2003 A.N. Srivastava Onboard Detection of Snow Ice, Clouds and Other Geophysical Processes Using Kernel Methods (2003) Google Scholar Tan et al., 2019 M. Tan, B. Chen, R. Pang, V. Vasudevan, M. Sandler, A. Howard, Q.V. Le MnasNet: Platform-Aware Neural Architecture Search for Mobile In: 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), IEEE, Long Beach, CA, USA (2019), pp. 2815-2823, 10.1109/CVPR.2019.00293 View in ScopusGoogle Scholar Tan et al., 2020 Q. Tan, J. Ling, J. Hu, X. Qin, J. Hu Vehicle detection in high resolution satellite remote sensing images based on deep learning IEEE Access, 8 (2020), pp. 153394-153402, 10.1109/ACCESS.2020.3017894 View in ScopusGoogle Scholar Tang et al., 2018 Y. Tang, J. Ji, S. Gao, H. Dai, Y. Yu, Y. Todo A pruning neural network model in credit classification analysis Comput. Intell. Neurosci., 2018 (2018), pp. 1-22, 10.1155/2018/9390410 View in ScopusGoogle Scholar Thangavel et al., 2022 Thangavel, K.; Spiller, D.; Sabatini, R.; Marzocca, P., 2022. On-board Data Processing of Earth Observation Data Using 1-D CNN. SmartSat CRC Conference, New South Wales, Australia, 12–13 September 2022. DOI: 10.13140/RG.2.2.16042.70088. Google Scholar Thangavel et al., 2023 K. Thangavel, D. Spiller, R. Sabatini, S. Amici, S.T. Sasidharan, H. Fayek, P. Marzocca Autonomous satellite wildfire detection using hyperspectral imagery and neural networks: a case study on Australian wildfire Remote Sens., 15 (3) (2023), p. 720 CrossRefView in ScopusGoogle Scholar Thangavel et al., 2023 K. Thangavel, D. Spiller, R. Sabatini, S. Amici, S.T. Sasidharan, H. Fayek, P. Marzocca Autonomous satellite wildfire detection using hyperspectral imagery and neural networks: a case study on Australian wildfire Remote Sens., 15 (3) (2023), p. 720 CrossRefView in ScopusGoogle Scholar Tjoa and Guan, 2020 E. Tjoa, C. Guan A survey on explainable artificial intelligence (XAI): towards medical XAI IEEE Trans. Neural Netw. Learn. Syst., 1–21 (2020), 10.1109/TNNLS.2020.3027314 Google Scholar Törnblom and Nadjm-Tehrani, 2019 J. Törnblom, S. Nadjm-Tehrani Formal Verification of Random Forests in Safety-Critical Applications C. Artho, P.C. Ölveczky (Eds.), formal Techniques for Safety-Critical Systems, Communications in Computer and Information Science, Springer International Publishing, Cham (2019), pp. 55-71, 10.1007/978-3-030-12988-0_4 View in ScopusGoogle Scholar Verzola et al., 2016 Ivano Verzola, Alessandro Donati, Martínez Heras, J.-A., Schubert, M., Laszlo Somodi, 2016. Project Sybil : A Novelty Detection System for Human Spaceflight Operations, in : Proc. Int. Conf. Space Operations. Google Scholar Vladimirova and Atek, 2002 Vladimirova, T., Atek, S., 2002. A New Lossless Compression Method for Small Satellite On-Board Imaging. University of Surrey, University of Surrey Guildford, Surrey, GU2 7 XH United Kingdom. https://doi.org/10.1142/9789812776266_0038. Google Scholar Voss, 2019 S. Voss Application of Deep Learning for Spacecraft Fault Detection and Isolation Delft University of Technology (2019) Google Scholar Wagstaff et al., 2017 Wagstaff, K.L., Altinok, A., Chien, S.A., Rebbapragada, U., Schaffer, S.R., Thompson, D.R., Tran, D.Q., 2017. Cloud Filtering and Novelty Detection using Onboard Machine Learning for the EO-1 Spacecraft. Int. Jt. Conf. Artif. Intell. 4 Google Scholar Wahlster and Winterhalter, 2020 Wahlster, W., Cristoph Winterhalter, 2020. GERMAN STANDARDIZATION ROADMAP ON ARTIFICIAL INTELLIGENCE 226. Google Scholar Wang et al., 2018 Wang, S., Pei, K., Whitehouse, J., Yang, J., Jana, S., 2018. Formal Security Analysis of Neural Networks using Symbolic Intervals. ArXiv180410829 Cs. Google Scholar Wang et al., 2019 Wang, Y., Ma, Z., Yang, Y., Wang, Z., tang, L., 2019. A New Spacecraft Attitude Stabilization Mechanism Using Deep Reinforcement Learning Method 13 pages. https://doi.org/10.13009/EUCASS2019-33. Google Scholar Wang et al., 2019 Wang, H., Yang, Z., Zhou, W., 2019. Online scheduling of image satellites based on neural networks and deep reinforcement learning 32, 9 Google Scholar Wang et al., 2021 Wang, H., Qin, C., Zhang, Y., Fu, Y., 2021. Emerging Paradigms of Neural Network Pruning. ArXiv210306460 Cs. Google Scholar Wang et al., 2021 X. Wang, G. Wu, L. Xing, W. Pedrycz Agile Earth observation satellite scheduling over 20 years: formulations, methods and future directions IEEE Syst. J., 15 (2021), pp. 3881-3892, 10.1109/JSYST.2020.2997050 Google Scholar Wang, 2021 Wang, B., 2021. Mesh-Transformer-JAX: Model-Parallel Implementation of Transformer Language Model with JAX. Google Scholar Wertz and Larson, 1999 Wertz, J.R., Larson, W.J., 1999. Space Mission Analysis and Design, 3rd edition. ed. Springer, El Segundo, Calif.: Dordrecht; Boston. Google Scholar White Paper on Artificial Intelligence, 2020 White Paper on Artificial Intelligence: a European approach to excellence and trust, 2020. Eur. Comm. - Eur. Comm. URL https://ec.europa.eu/info/publications/white-paper-artificial-intelligence-european-approach-excellence-and-trust_en (accessed 9.11.21) Google Scholar Winter et al., 2021 Winter, P.M., Eder, S.K., Weissenbock, J., Schwald, C., Doms, T., Vogt, T., Hochreiter, S., Nessler, B., 2021. Trusted Artificial Intelligence: Towards Certification of Machine Learning Applications. ArXiv abs/2103.16910. Google Scholar Wu et al., 2001 S.-F. Wu, C.J.H. Engelen, Q.-P. Chu, R. Babuška, J.A. Mulder, G. Ortega Fuzzy logic based attitude control of the spacecraft X-38 along a nominal re-entry trajectory Control Eng. Pract., 9 (2001), pp. 699-707, 10.1016/S0967-0661(01)00036-3 View PDFView articleView in ScopusGoogle Scholar Yadava et al., 2018 D. Yadava, R. Hosangadi, S. Krishna, P. Paliwal, A. Jain Attitude control of a nanosatellite system using reinforcement learning and neural networks In: 2018 IEEE Aerospace Conference, IEEE, Big Sky, MT (2018), pp. 1-8, 10.1109/AERO.2018.8396409 View in ScopusGoogle Scholar Yang et al., 2021 Yang, Z., Li, L., Xu, X., Kailkhura, B., Xie, T., Li, B., 2021. On the Certified Robustness for Ensemble Models and Beyond. ArXiv210710873 Cs. Google Scholar Yu et al., 2020 D. Yu, Q. Xu, H. Guo, C. Zhao, Y. Lin, D. Li An efficient and lightweight convolutional neural network for remote sensing image scene classification Sensors, 20 (2020), p. 1999, 10.3390/s20071999 View in ScopusGoogle Scholar Zhang et al., 2019 Z. Zhang, A. Iwasaki, G. Xu, J. Song Cloud detection on small satellites based on lightweight U-net and image compression J. Appl. Remote Sens., 13 (2019), Article 026502, 10.1117/1.JRS.13.026502 View in ScopusGoogle Scholar Zhang et al., 2021 Z. Zhang, G. Li, Y. Xu, X. Tang Application of artificial intelligence in the MRI classification task of human brain neurological and psychiatric diseases: a scoping review Diagnostics, 11 (8) (2021), p. 1402, 10.3390/diagnostics11081402 View in ScopusGoogle Scholar Zhang et al., 2020 S. Zhang, G. Wu, J. Gu, J. Han Pruning convolutional neural networks with an attention mechanism for remote sensing image classification Electronics, 9 (2020), p. 1209, 10.3390/electronics9081209 View in ScopusGoogle Scholar Zhang et al., 2019 B. Zhang, Y. Zhang, S. Wang A lightweight and discriminative model for remote sensing scene classification with multidilation pooling module IEEE J. Sel. Top. Appl. Earth Obs. Remote Sens., 12 (2019), pp. 2636-2653, 10.1109/JSTARS.2019.2919317 View in ScopusGoogle Scholar Zhao et al., 2020 Zhao, S., Yue, X., Zhang, S., Li, B., Zhao, H., Wu, B., Krishna, R., Gonzalez, J.E., Sangiovanni-Vincentelli, A.L., Seshia, S.A., Keutzer, K., 2020. A Review of Single-Source Deep Unsupervised Visual Domain Adaptation. ArXiv200900155 Cs Eess. Google Scholar Zhu et al., 2017 Zhu, C., Han, S., Mao, H., Dally, W.J., 2017. Trained Ternary Quantization. ArXiv161201064 Cs. Google Scholar Zoph and Le, 2017 Zoph, B., Le, Q.V., 2017. Neural Architecture Search with Reinforcement Learning. ArXiv161101578 Cs. Google Scholar Cited by (10) Navigating AI-lien Terrain: Legal liability for artificial intelligence in outer space 2024, Acta Astronautica Show abstract Multidisciplinary design and optimization of intelligent Distributed Satellite Systems for earth observation 2024, Acta Astronautica Show abstract Distributed satellite system autonomous orbital control with recursive filtering 2024, Aerospace Science and Technology Show abstract Artificial Intelligence for Trusted Autonomous Satellite Operations 2024, Progress in Aerospace Sciences Show abstract SURE: SUrvey REcipes for building reliable and robust deep networks 2024, arXiv Wildfire Detection Using Convolutional Neural Networks and PRISMA Hyperspectral Imagery: A Spatial-Spectral Analysis 2023, Remote Sensing View all citing articles on Scopus View Abstract © 2023 COSPAR. Published by Elsevier B.V. All rights reserved. Recommended articles Characterization of the effective height of the ionosphere using GPS data over East Africa, a low latitude region Advances in Space Research, Volume 71, Issue 12, 2023, pp. 5196-5207 Phillip Opio, …, Edward Jurua View PDF Naturally bounded relative motion for formation flying near triangular libration points Advances in Space Research, Volume 71, Issue 12, 2023, pp. 5038-5049 Xingji He, …, Lei Liu View PDF Stiffness optimization method of locking unit for space manipulator based on plant root adaptive growth theory Advances in Space Research, Volume 71, Issue 12, 2023, pp. 5026-5037 Gang Wang, …, Qihui Zhang View PDF Show 3 more articles Article Metrics Citations Citation Indexes: 6 Captures Readers: 42 Social Media Shares, Likes & Comments: 39 View details About ScienceDirect Remote access Shopping cart Advertise Contact and support Terms and conditions Privacy policy Cookies are used by this site. Cookie settings | Your Privacy Choices All content on this site: Copyright © 2024 Elsevier B.V., its licensors, and contributors. All rights are reserved, including those for text and data mining, AI training, and similar technologies. For all open access content, the Creative Commons licensing terms apply.

Paper 2:
- APA Citation: Naranjo, P. G. V., Shojafar, M., Mostafaei, H., Pooranian, Z., & Baccarelli, E. (2017). P-SEP: A prolong stable election routing algorithm for energy-limited heterogeneous fog-supported wireless sensor networks. Journal of Supercomputing, 73(2), 733–755.
  Main Objective: To design a fog-supported wireless sensor network that prolongs stable election routing for heterogeneous networks with limited energy resources.
  Study Location: Unspecified
  Data Sources: 
  Technologies Used: 
  Key Findings: 
  Extract 1: 
  Extract 2: 
  Limitations: >
  Relevance Evaluation: {'extract_1': 'Due to rapid advancement in WSN technologies, the size and the cost of sensors have reduced, which make it feasible to implement them in many sectors of life including agriculture.', 'extract_2': 'The main goal of fog computing is to conserve energy and bandwidth, which helps to increase the quality of service to the end users.', 'relevance_score': 0.85}
  Relevance Score: 0.85
  Inline Citation: (6)
  Explanation: The paper is focused on the use of data compression, aggregation, and filtering techniques to reduce bandwidth requirements and improve transmission efficiency in the Internet of Things (IoT)-based systems used for precision agriculture, particularly in the context of real-time data transmission. The specific section of interest explores how these techniques can be applied to reduce the bandwidth requirements of real-time data transmission in agricultural monitoring systems.

 Full Text: >
sensors
Review
Precision Agriculture Techniques and Practices:
From Considerations to Applications
Uferah Shaﬁ 1
, Raﬁa Mumtaz 1,*
, José García-Nieto 2
, Syed Ali Hassan 1
,
Syed Ali Raza Zaidi 3 and Naveed Iqbal 1
1
National University of Science and Technology (NUST), School of Electrical Engineering and Computer
Science, Islamabad 44000, Pakistan
2
Department of Languages and Computer Sciences, Ada Byron Research Building, University of Málaga,
29016 Málaga, Spain
3
School of Electronic and Electrical Engineering, University of Leeds, Leeds LS2 9JT, UK
*
Correspondence: raﬁa.mumtaz@seecs.edu.pk
Received: 14 July 2019; Accepted: 27 August 2019; Published: 2 September 2019


Abstract: Internet of Things (IoT)-based automation of agricultural events can change the agriculture
sector from being static and manual to dynamic and smart, leading to enhanced production with
reduced human efforts. Precision Agriculture (PA) along with Wireless Sensor Network (WSN) are the
main drivers of automation in the agriculture domain. PA uses speciﬁc sensors and software to ensure
that the crops receive exactly what they need to optimize productivity and sustainability. PA includes
retrieving real data about the conditions of soil, crops and weather from the sensors deployed in the
ﬁelds. High-resolution images of crops are obtained from satellite or air-borne platforms (manned
or unmanned), which are further processed to extract information used to provide future decisions.
In this paper, a review of near and remote sensor networks in the agriculture domain is presented
along with several considerations and challenges. This survey includes wireless communication
technologies, sensors, and wireless nodes used to assess the environmental behaviour, the platforms
used to obtain spectral images of crops, the common vegetation indices used to analyse spectral
images and applications of WSN in agriculture. As a proof of concept, we present a case study
showing how WSN-based PA system can be implemented. We propose an IoT-based smart solution
for crop health monitoring, which is comprised of two modules. The ﬁrst module is a wireless sensor
network-based system to monitor real-time crop health status. The second module uses a low altitude
remote sensing platform to obtain multi-spectral imagery, which is further processed to classify
healthy and unhealthy crops. We also highlight the results obtained using a case study and list the
challenges and future directions based on our work.
Keywords: smart agriculture; precision agriculture; vegetation index; Internet of Things
1. Introduction
The rapidly-growing human population has increased food demands for human survival on
the Earth. Meeting the food requirements with limited resources of the planet is a big challenge [1].
Several state-of-the-art technologies are being incorporated in the agriculture domain to enhance
the productivity to cope with this challenge. Precision Agriculture (PA) is comprised of near and
remote sensing techniques using IoT sensors, which help to monitor crop states at multiple growth
levels. PA involves the acquisition and processing of a large amount of data related to crop health.
Multiple parameters are involved in plants health, including water level, temperature and others.
PA enables a farmer to know precisely what parameters are needed for healthy crop, where these
parameters are needed and in what amount at a particular instance of time. This requires collecting
Sensors 2019, 19, 3796; doi:10.3390/s19173796
www.mdpi.com/journal/sensors
Sensors 2019, 19, 3796
2 of 25
massive information from different sources and different parts of the ﬁeld such as soil nutrients, the
presence of pests and weeds, chlorophyll content in plants and some weather conditions. All collected
information needs to be analysed to produce agronomic recommendations. For instance, given the
developmental stage of plants, their level of greenness (chlorophyll content) reveals the nutrients
needed. This information is combined with the characteristics of the soil where the plant is located
along with weather forecast. All collected information is further used to determine how much of a
certain fertilizer should be applied to that plant on the next day. The delivery of agronomic information
on the right time to farmer and ensuring that he/she applies these recommendations are key to
enhancing the yields.
The foremost driver of PA is a WSN, which is a network of multiple wireless nodes connected
together to monitor the physical parameters of environment. Each wireless node is comprised of a
radio transceiver, a micro-controller, sensor(s), an antenna, along with other circuitry that enables it
to communicate with some gateway to transmit information collected by the sensor(s) [2]. Sensors
measure the physical parameters and send the collected information to the controller, which further
transmits this information to the cloud or a portable device. The agriculture sector has multiple
requirements comprised of soil statistics, crops’ nature, weather conditions, fertilizer types and water
requirements. Crops have diverse requirements depending on different crops on the same land and the
same plant on different lands with different weather conditions. Sensors monitor the varying behaviour
of these crop parameters. Due to rapid advancement in WSN technologies, the size and the cost of
sensors have reduced, which make it feasible to implement them in many sectors of life including
agriculture. The most common sensors used in the agriculture domain that capture environmental
parameters related to crops [3] are listed in Table 1.
In general, a WSN consists of one or more wireless nodes that are further connected with sensors.
These nodes are tiny devices that are responsible for collecting data. Nodes are divided into two types,
a source node that collects the data, and the other is sink or gateway node, which receives data from the
source nodes. A sink node has more computational power compared to a source node. However, there
are energy, memory, power, size, data rate and price constraints when choosing wireless nodes. Table 2
shows a comparison of wireless nodes along with their common speciﬁcations [3]. Among all wireless
nodes presented in Table 2, MICA2 is considered to be more suitable as compared to others because of
its large number of expansion connectors, which makes it suitable to connect with several sensors.
Many applications using WSN have been proposed since the last decade to monitor crops’ health
remotely. In [4], a cyber-physical system was presented for monitoring of a potato crop. Cyber physical
systems can be expressed as smart systems that are comprised of software, hardware and physical
components, integrated together to sense the varying states of the real world. The proposed system
consists of three layers: the ﬁrst layer is the physical layer, in which all sensory data are collected;
the second layer is the network layer in which data are transmitted to the cloud; the third layer is
the decision layer in which the data are analysed and processed to make decisions according to the
observations.
There are several challenges in IoT-based systems due to exponential increasing devices. As in
a typical IoT network, every node transmits data to the remote cloud, which results in cloud
congestion, and the main challenges underlying the IOT-based system are latency with minimum
power requirements, better usage of bandwidth and intermittent Internet connectivity. Fog computing
and edge computing are the state-of-the-art techniques to overcome these issues; which reduce the
computational burden of cloud. The main goal of fog computing is to conserve energy and bandwidth,
which helps to increase the quality of service to the end users. In [5], an energy-efﬁcient architecture of
the Fog of Everything was presented, which was comprised of six layers. The ﬁrst layer was an Internet
Of Everything (IOE) layer, where things (could be ﬁxed, mobile or nomadic) functioned under multiple
spatially-distributed clusters. The second was a wireless access network that supported Thing to Fog
(T2F) and Fog to Thing (F2T) communication over the wireless channel. In the third layer, the connected
fog nodes behaved such as a virtualized cluster. There was an inter-fog backbone in the fourth layer,
Sensors 2019, 19, 3796
3 of 25
which was responsible for connectivity among fog nodes. The next layer was the virtualization layer,
which provided each connected thing with the ability to augment its limited resource set, exploiting
the computation capability at the virtual clone. In the last layer, there was an overlay inter-clone
virtual network that empowered Peer to Peer (P2P) communication. Then, a protocol stack for FOE
was presented, which was further tested by creating a small prototype named as V-FOE and simulated
on the iFogsim toolkit. The results provided strong evidence for the effectiveness of the proposed
framework and more energy efﬁciency with reduced failure rate and delay.
Table 1. Wireless nodes used in the agriculture domain.
Sr #
Sensor Name
Parameters Captured
1
ECH2O soil moisture sensor
Soil Temperature, Soil Moisture, Conductivity
2
Hydra probe II soil sensor
Soil Temperature, Salinity level, Soil Moisture,
Conductivity
3
MP406 Soil moisture sensor
Soil Temperature, Soil Moisture
4
EC sensor (EC250)
Soil Temperature, Salinity level, Soil Moisture,
Conductivity
5
Pogo portable soil sensor
Soil Temperature, Soil Moisture
6
107-L temperature Sensor (BetaTherm 100K6A1B
Plant Temperature
Thermistor)
7
237 leaf wetness sensor
Plant Moisture, Plant Wetness, Plant
Temperature
8
SenseH2TM hydrogen sensor
Hydrogen, Plant Wetness, CO2, Plant
Temperature
9
Field scout CM1000TM
Photosynthesis
10
YSI 6025 chlorophyll sensor
Photosynthesis
11
LW100, leaf wetness sensor
Plant Moisture, Plant Wetness, Plant
Temperature
12
TT4 multi-sensor thermocouple
Plant Moisture, Plant Temperature
13
TPS-2 portable photosynthesis
Photosynthesis, Plant Moisture, CO2,
14
LT-2 M (leaf temperature sensor)
Plant Temperature
15
PTM-48A photosynthesis monitor
Photosynthesis, Plant Moisture, Plant Wetness,
CO2, Plant Temperature
16
Cl-340 hand-held photosynthesis
Photosynthesis, Plant Moisture, Plant Wetness,
CO2, Plant Temperature, Hydrogen level in
Plant
17
CM-100 Compact Weather Sensor
Air Temperature, Air Humidity, Wind Speed,
Air Pressure
18
HMP45C (Vaisala’s HUMICAP R⃝ H-chip)
Air Temperature, Air Humidity, Air Pressure
19
Met Station One (MSO)
Air Humidity, Air Temperature, Wind Speed,
Air Pressure
20
XFAM-115KPASR
Air Temperature, Air Pressure, Air Humidity
21
SHT71, SHT75 (Humidity and temperature
sensor)
Humidity and Temperature Sensor
22
107-L Temperature Sensor (BetaTherm 100K6A1B
thermistor)
Air Temperature
23
Cl-340 hand-held photosynthesis
Air Temperature, Air Humidity
The energy efﬁciency is the most serious consideration while developing any fog architecture.
In [6], an energy-efﬁcient protocol for a fog-supported wireless sensor network was presented, which
maximized the lifetime of the network by uniformly distributing the energy among connected nodes.
The performance of the proposed algorithm was compared with the existing state-of-the-art algorithms
Sensors 2019, 19, 3796
4 of 25
in MATLAB. The results showed that the proposed algorithm was highly energy efﬁcient with a
prolonged network lifetime.
Regardless of all the advancements in the IoT domain, the adoption of PA has been limited to
some developed countries. Because of the lack of resources, remote sensing-based techniques to
monitor crop health are not common in under-developed countries such as Pakistan, which results in
a loss of yield. Pakistan is an agricultural country due to is large arable land and climatic variations,
which make it suitable to cultivate multiple types of crops. Despite all these natural resources, Pakistan
is still unable to produce massive yields [7]. The main reason behind the low production is traditional
farming practices, which are used for crop health monitoring and yield estimation. These techniques
are completely based on farmer’s intuition and experience. Farmers visit the ﬁelds in order to monitor
the crop, which is very laborious and quite challenging in the case of large arable land. In this case, the
area under insect/pest attack is inaccurately measured, which can result in over spraying of insecticide
and pesticide, which adversely affects the nutrition in crops.
Keeping in mind all these issues, our motivation is to provide the industry and research
communities with a survey of technologies, metrics and current practices concerning communication
devices, sensors and platforms used to monitor and analyse multiple sources of data (spectral images,
IoT, etc.) used in environmental and agriculture applications. As the main contribution, we generated
a technological taxonomy for PA, which was driven by an IoT-based architecture to monitor the crops’
health. The developed system had two modules including wireless sensor network-based crop heath
monitoring in which multiple sensors were used to get the real-time heath status of crop; the other
one was NDVI-based analysis of spectra images captured by a drone to assess the chlorophyll content,
which was further used to monitor the health of the crop.
The rest of the paper is organized as follows: Section 2 presents the most common wireless
communication technologies used in the agriculture domain; Section 3 explains the spectral
image-based remote sensing techniques, platforms and vegetation indices; Section 4 describes remote
sensing applications in the agriculture sector; Section 5 presents a case study on IoT-based and
UAV-based PA; Section 6 explains the experiments and results; challenges are discussed in Section 7;
and conclusions and future directions are presented in Section 8.
Table 2. Common wireless nodes used in the agriculture domain.
Sr #
WN1
MC2
Expansion
Connector
Available Sensors
Data Rate
1
MICA2DOT
ATmega128L
19 Pins
GPS, Light, Humidity, Barometric Pressure,
Temperature, Accelerometer, Acoustic, RH
38.4 K Baud
2
Imote2
Marvell/XScalePXA271
40 Pins and 20 Pins
Light, Temperature, Humidity, Accelerometer
250 Kbps
3
IRIS
ATmega128L
51 Pins
Light, Barometric Pressure, RH, Acoustic,
Acceleration/ Seismic, Magnetic and Video
250 Kbps
4
MICAz
ATmega128L
51 Pins
Light, Humidity, Temperature, Barometric
Pressure, GPS, RH, Accelerometer, Acoustic, Video
Sensor, Sounder, Magnetometer, Microphone
250 Kbps
5
TelosB
TIMSP430
6 Pins and 10 Pins
Light, Temperature, Humidity
250 Kbps
6
Cricket
ATmega128L
51 Pins
Accelerometer, Light, Temperature, Humidity,
GPS, RH, Acoustic, Barometric Pressure,
Ultrasonic, Video Sensor, Microphone,
Magnetometer, Sounder
38.4 K Baud
7
MICA2
ATmega128L
51 Pin
Temperature, Light, Humidity, Accelerometer,
GPS, Barometric Pressure, RH, Acoustic, Sounder,
Video, Magnetometer
38.4 K Baud
WN1: wireless node, MC2: Micro-Controller.
2. Wireless Communication Technologies
Various communication protocols have been introduced in the last few decades due to the rapid
increase in IoT devices and WSN technologies. Each protocol has its own speciﬁcations depending on
the bandwidth, number of free channels, data rate, battery timing, price and other factors [8]. The most
commonly-used protocols for wireless communication in IoT-based applications in agriculture are:
Sensors 2019, 19, 3796
5 of 25
2.1. Cellular
Cellular technology is most suitable for applications that require an extraordinary data rate.
It can utilize GSM, 3G and 4G cellular communication capabilities by providing reliable high-speed
connectivity to the Internet, requiring higher power consumption.
It requires infrastructure to
be deployed and operation cost and back up staff for it with a centralized managed authority.
4G cellular technology requires more battery power, but cellular technology is a good option in
underground wireless sensor networks, such as security systems in smart home projects and agriculture
applications [9]. A smart irrigation systems was presented in [10], in which several soil moisture
sensors were deployed in the ﬁeld in the ZigBee mesh network. The reading captured from the ﬁelds
were transmitted over the cloud using the cellular 4G LTE network.
2.2. 6LoWPAN
6LoWPAN is an IP-based communication protocol, which was the ﬁrst protocol used for IoT
communication. 6LoWPAN is also low cost because of the low bandwidth and low power consumption.
6LoWPAN supports multiple topologies such as star and mesh topologies. To handle interoperability
between IPv6 and IEEE 802.15.4, there is an adaptation layer between the network layer and the
MAC layer [8]. The applications for 6LoWPAN are monitoring the health equipment, environment
monitoring and in security and home automation systems. In [11], a 6LoWPAN-enabled wireless sensor
network was presented to monitor the soil properties of crops. The 6LoWPAN system architecture
for precision agriculture application was discussed in [12] where the performance evaluation of this
protocol was discussed with several baud rates and power constraints.
2.3. ZigBee
ZigBee is a wireless communication protocol widely used in precision agriculture to monitor
environmental conditions related to crops’ health [13]. It is based on the wireless 802.15.4 standard.
Basically, it was developed for personal area networks by the ZigBee alliance [8]. It has a ﬂexible
network structure, long battery life, supports mesh, star and tree topology with multi-hop data
transmission, is easily installed and supports large nodes. It has a short range with limited data speed
and is less secure compared to Wi-Fi-based systems. ZigBee is very common in smart agriculture
applications such as smart green houses and smart irrigation systems [14]. In [15], a smart irrigation
system was presented based on the ZigBee communication protocol. This system consisted of two
nodes, i.e., a sensor node and an actuator node. The sensor node was comprised of soil moisture
sensors, which monitored the water level in the soil. The actuator module was responsible for taking
actions according to the water level of the soil. All communication was carried out by means of
ZigBee protocol.
2.4. BLE
BLE is as famous as the Bluetooth smart technology, which is a suitable protocol for IoT
applications including agriculture [16]. It is particularly designed for low bandwidth, low latency and
short range for IoT applications. The main advantages of BLE over typical Bluetooth include lower
setup time, lower power consumption and unlimited support for nodes in a star topology. It has a
very limited range of 10 meters. However, the drawbacks are that it can only provide communication
between two devices, it presents low security, and it can lose connection during communication. In [17],
a BLE-based infrastructure was presented to collect the sensors’ data. The proposed system utilized a
smart phone to collect the data of sensors using BLE, where sensors were deployed in the plants, i.e.,
soil moisture sensors and soil temperature sensor.
Sensors 2019, 19, 3796
6 of 25
2.5. RFID
RFID systems consist of a reader and a transponder, which have a very small radio frequency,
called the RF tag. This tag is programmed electronically with distinctive information that has a reading
characteristic. RFID has two technologies for the tag system the ﬁrst is the active reader tag system,
and the other is the passive reader tag. Active reader tag systems are more expensive, as they utilize
more battery power and use high frequencies. However, passive reader tag systems are low powered.
Some IoT applications using RFID include smart shopping, healthcare, national security and smart
agriculture applications. An IoT-based smart irrigation system based on RFID was presented in [18].
The system was comprised of soil moisture and soil temperature sensors along with a water control
system, so it collected the reading of the sensors and sent these readings to the cloud using RFID
communication protocols, where the user controlled a water pump based on the water level of the soil.
2.6. Wi-Fi
Wi-Fi is the most common communication protocol that enables devices to communicate over
a wireless signal. Wi-Fi provides Wireless Local Area Network (WLAN) connectivity to millions of
locations, i.e., homes, ofﬁces and public locations such as cafes, hotels and airports with high speed.
The Wi-Fi protocol supports IEEE 802.11, 802.11a, 802.11b, 802.11g and 802.11n. Wi-Fi is widely used
in IoT-based applications including agriculture systems, i.e., smart irrigation, crop health monitoring
and greenhouses. In [19], an infrastructure was presented to monitor environmental parameters
inside the greenhouse such as temperature, light intensity and soil moisture level. This platform
was comprised of sensors that collected the data related to the environmental variation and sent to
the cloud using Wi-Fi. Similarly, another smart agriculture system based on Wi-Fi communication
protocols was presented in [20]. This last one consisted of a Raspberry Pi connected with multiple
sensors, which collected the data. The collected data were further transmitted to the cloud using Wi-Fi
communication protocols.
2.7. LoRaWAN
LoRaWAN operates on the LoRa network. LoRaWAN deﬁnes the system architecture and
communication protocol of the network, while the physical layer of LoRa enables the link for
long-range communication. LoRaWAN manages the frequencies in communication, data rate and
power consumption for all devices. LoRaWAN is common in agricultural applications because of
its large coverage area and low power consumption [21]. In [14], a smart irrigation system based on
LoRaWAN was presented. Table 3 shows the comparison of all mentioned wireless communication
protocols [8]. Among all wireless communication technologies, 6LoWPAN and ZigBee are considered
to be more suitable for PA application because both are based on mesh networking, which makes them
suitable to cover large area.
Table 3. Wireless communication protocols used in Precision Agriculture (PA).
Communication Protocols
Data Rate
Topology
Standard
Physical Range
Power
6LoWPAN
0.3–50 Kb/s
Star, Mesh
IEEE 802.15.4
2–5 km urban,
15 km suburban
Low
ZigBee
250 Kb/s
Star, Mesh Cluster
IEEE 802.15.4
10–100 m
Low
Bluetooth
1–2 Mb/s
Star, Bus
IEEE 802.15.1
30 m
Low
RFID
50 tags/s
P2P
RFID
10–20 cm
Ultra low
LoRa WaAN
27–50 Kb/s
P2P, Star
IEEE 802.11ah
5–10 km
Very low
Wi-Fi
1–54 Mb/s
Star
IEEE 802.11
50 m
Medium
Sensors 2019, 19, 3796
7 of 25
3. Spectral Image-Based Remote Sensing
Remote sensing has been widely used in PA to monitor crops’ health for the last two decades.
Remote sensing is a phenomenon in which physical conditions of the Earth are observed remotely by
calculating the emitted and reﬂected radiation from some distance. There are special cameras that
are used to capture images for further analysis to ﬁnd the characteristics of a speciﬁc area. Multiple
platforms are used to mount these cameras that capture images of the objects.
3.1. Spectral Image Platforms
Remote sensing platform considerations for spectral images are airborne-based, satellite-based
and Unmanned Aerial Vehicle (UAV)-based [22]. Each platform has its own coverage range, which
is determined by three factors: (i) Ground Sampling Distance (GSD), which is computed in terms of
spatial resolution, (ii) data collection rate or frequency and (iii) average distance between the object
and sensor. Apart from coverage range, several factors [23] affect the performance of platforms,
as mentioned in Table 4.
Table 4. Key differences between spectral image platforms.
Applicability Aspect
Airborne
UAV
Satellite
Observation Area
Regional
Local
Worldwide
Ground Coverage
1 km (Medium)
100 m (Small)
10 km (Large)
Field of View
Wider
Wide
Narrow
GSD (Spatial Resolution)
5–25 cm
10–5 cm
0.30–300 m
Deployability
Complex
Easy
Difﬁcult
Spatial Accuracy
1–25 cm
5–10 cm
1–3 m
Repeat Time
Hour(s)
Minute(s)
Day(s)
Operational Risk
High
Low
Moderate
3.1.1. Satellite-Based Platforms
Space-borne platforms for remote sensing are considered to be the most stable platforms among
all others. These platforms consist of satellites, rockets and space shuttles. Space borne platforms are
categorized based on the orbits and timing. The advantages of satellite-based remote sensing include
high spatial resolution, which makes it promising to extract extensive time-series data. The images
obtained by satellite platforms cover large area and are stable without noise, which is normally induced
due to interference while image capturing. However, the main problem with satellite-based platforms
is their high cost in the case of high spatial resolution images. The second problem is their strictly ﬁxed
time schedule, so data cannot be collected at critical timings. The re-visitation times vary from twice
in one day to 16 days, depending on the orbit of the satellite. The other big problem is that satellite
platforms are highly sensitive to weather conditions, so if the weather is cloudy, the captured image will
have less detailed information. Table 5 shows the main types of satellites with their speciﬁcations [22].
Among all satellite platforms presented in Table 5, some satellite data are freely available,
while others provide a commercial solution. The commercial solutions such as Pleiades-1 provide
images with a high resolution and a revisit time of one day. QuickBird, Landsat-8 and Sentinel are
frequently-used satellite platforms used to obtain hyperspectral imagery. QuickBird was launched
in 2001 by USA. The Panchromatic (PAN) and four Multi-Spectral (MS) imagery sensors are used in
QuickBird with a GSD of 0.7 × 0.7–2.6 × 2.6 m with a revisit time 1–3.5 days. QuickBird provides a
small revisit time, but it is a commercial solution. In contrast to QuickBird, Landsat-8 and Sentinel
provide free solutions. Landsat-8 was launched in 2013 by the USA. Landsat-8 provides a GSD of
16 days with PAN and 11-MS imagery sensors. Though revisit time of Landsat-8 is much higher
compared to QuickBird, but it provides images with 11 different multi-spectral bands.
Sentinel is another broadly-used satellite launched by the EU. It currently has three missions,
i.e., Sentinel-1, Sentinel-2 and Sentinel-3. These missions provide images with 21 MS bands with
Sensors 2019, 19, 3796
8 of 25
revisit times of 5–10 days depending on which Sentinel mission is used. However, Sentinel-2 is a
commonly-used platform in precision agriculture as it provides data freely at a 10-m spatial resolution
and covers a swath width of 290 km. By combining Sentinel-2A and Sentinel-2B, the revisit time is
further reduced to ﬁve days, which helps in change detection. The complete details of all satellite
platforms with their speciﬁcations are listed in Table 5, where other platforms such as SAT, MODIS
and WordView are also considered.
Table 5. Satellite platforms for RS.
Name
Launch
Sensor
Country
Swath
Width (km)
GSD 1 Range (m)
Revisit Time (day)
RapidEye
2008
5 MS2
Germany
77
6.5 × 6.5
1–5.5
QuickBird-2
2001
PAN3
USA
16.8–18
0.7 × 0.7
1–3.5
4 MS2
2.6 × 2.6
Pleiades 1
2011
PAN3
France
20
0.5 × 0.5
1
2012
4 MS2
2 × 2
Sentinel-1
2014
C-band
EU
80
5 × 5
12
2016
SAR6
250
5 × 20
6 (dual)
400
25 × 40
WorldView-3
2014
PAN3, 8 MS2, 8 MS2
USA
13.1
0.3 × 0.3
1–4.5
(SWIR4), 12 MS2
1.2 × 1.2
3.7 × 3.7
Landsat-8
2013
PAN3, 11 MS2
USA
185
15 × 15
16
30 × 30
Sentinel-2
2015
13 MS2
EU
290
10 × 10
10
20 × 20
2016
60 × 60
5 (dual)
EnMap
2017
232 HSI5
Germany
30
30 × 30
4
ICESat
2003
2 HSI5
USA
N/A
70
8
(footprint)
TanDEM-X
2007
X-band
Germany
5 × 10
1 × 1
11
SAR6
1500 × 30
3 × 3
1500 × 100
16 × 16
SkySat
2013
PAN3
USA
2 × 1
1.1 × 1.1
0.5 (2015)
Video
2014
PAN3
8
0.9 × 0.9
0.12 (2017)
2015
4 MS2
2 × 2
ICESat-2
2018
1 HSI5
USA
N/A
10
N/A
(9-beam)
(footprint)
Sentinel-3
2015
21 MS2
EU
1270
300 × 300
0.25
2017
11 MS2
1420
500 × 500
(IR)
750 (nadir)
1000 × 1000
RADARSAT-2 2007
C-band
Canada
20
3 × 3
24 (orbit repetition)
SAR6
500
100 × 100
SPOT 6
2012
PAN3
France
60
1.5 × 1.5
1–5
SPOT 7
2014
4 MS2
6 × 6
TerraSAR-X
2007
X-band
Germany
5 × 10
1 × 1
11
SAR6
1500 × 100
16 × 16
DMC-3
2015
PAN3
U.K.
23
1 × 1
1
4 MS2
4 × 4
GSD1: Ground Sampling Rate, MS2: Multi-Spectral, PAN3: Panchromatic, SWIR4: Short Wave Infrared, HSI5:
Hyperspectral Imagery, SAR6: Synthetic Aperture Radar
3.1.2. Airborne-Based Platforms
Airborne platform are ﬂexible compared to satellite platforms, but still are expensive. The revisit
time is in human control, which can be changed any time. The coverage area by this platform is
much smaller than satellite-based ones, but relatively greater than the UAV platforms. Some common
airborne platforms used for remote sensing [22] are given in Table 6.
Sensors 2019, 19, 3796
9 of 25
Table 6. Airborne/aircraft platforms for RS.
Aircraft Type
Typical Models
RS Sensors
Max Flying Height (ft)
Fixed wing (jet)
LearJet 35A
InSAR,
45,000
Camera,
GeoSAR
Fixed wing (propeller engine)
Cessna 402
Camera
26,900
Commander 690
LiDAR
19,400
Cessna 208
Camera
LiDAR
25,000
Cessna 206
Camera
DHC-6 Twin
Camera
15,700
Otter 300
LIDAR
25,000
Diamond
Camera
DA42
LiDAR
18,000
Pilatus PC-6
Camera
Porter
Camera
25,000
Piper Navajo
LiDAR
26,000
Partenavia
Camera
P.68
LiDAR
19,200
Vulcanair P68
Camera
Observer
Camera
18,000
Gyroplan
AutoGyro
LiDAR
10,000
Cavalon
Camera
Helicopter
Eurocopter
LiDAR
15,000
AS350
Camera
Robinson R44
LiDAR
14,000
Camera
Bell 206
LiDAR
13,000
Camera
Schweizer
LiDAR5
13,000
Camera
3.1.3. UAV-Based Platforms
UAV platforms are a vibrant alternative to satellite and airborne, which are quite ﬂexible and cost
effective. A typical UAV platform consists of a communication and navigation system that incorporates
a set of sensors mounted on it. Among UAV platforms, there are mainly ﬁxed-wing platforms. and
multirotor options are available. The ﬂying time is based on the payload weight. In general, a longer
ﬂying time is achieved by ﬁxed-wing systems, which demands lighter weight payloads. For example,
high-deﬁnition cameras weighing less than 300 grams as the payload of a ﬁxed-wing UAV allow it to ﬂy
for around two hours using currently available battery power [24]. On the contrary, battery-powered
multirotor UAV with higher payload capacity have a reduced ﬂying time, i.e., around 15–25 min.
Table 7 shows UAV platforms commonly used in the agriculture domain and concretely to monitor
the health of crops remotely [22]. Among these platforms, DJI/Phantom-2 is a more suitable choice
for intermediate agricultural land because of its low cost and ease of use. The other advantage of this
platform is that it provides support for mounting multiple cameras, which helps to monitor the crop in
multiple electro-magnetic bands. The American Aerospace/RS-16 is also an option because of its ﬂight
time and large are coverage, but due to its high cost, this platform is not common.
In [25], the ESAFLY A2500_WH helicopter was used to implement the platform of the UAV
with Tetra cam ADC Micro as the camera to capture hyper-spectral images of two different types of
cultivation, i.e., vineyard and tomato. The images captured by the UAV platform are very high in
resolution, so more information can be extracted as compared to satellite images. To assess the health
of a crop, three types of Vegetation Index (VI) maps have been computed.
Sensors 2019, 19, 3796
10 of 25
Table 7. UAV platforms for RS.
Weight (kg)
Aircraft Power/Type
Manufacturer/Model
Flying Time (min)
Flying Speed (m/s)
RS Sensors
0.7
Fixed-wing/electric
senseFly/eBee RTK
40
11–25
Camera
6.1
Fixed-wing/electric
AeroVironment/Puma AE
210
23
Camera
6.0
Quadro copter/electric
Microdrones/MD4-1000
90
12
Camera/LiDAR
4.6–6.6
Hexacopter/electric
Aibotix/Aibot X6
30
14
Camera
5
Fixed-wing/electric
Trigger
Composites/Pteryx
120
12.5–15
Camera
1.3
Quadrocopter/electric
DJI/Phantom 2
25
15
Camera
2.5
Fixed-wing/electric
Trimble/UX5
50
22
Camera
2.7
Fixed-wing/electric
Topcon/SIRIUS PRO
50
18
Camera
5.1–5.8
Fixed-wing/electric
Hawkeye
UAV/AeroHawk
90
16.5–19.5
Camera
6.9–9.5
Hexacopter/electric
TRGS/Li-AIR
15
8
LiDAR
9.5
Octocopter/electric
Altus UAS/Delta X8
10–14
12
Camera/LiDAR
25
Octocopter/electric
Riegl/Ricopter
30
22
LiDAR/camera
77
Helicopter/gas
Aeroscout/Scout B1-100
90
LiDAR
90
Helicopter/gas
IGI/geocopter
120–180
Camera/LiDAR
9.2
Octocopter/electric
Altigator/OnyxStar
FOX-C8 HD LiDAR
20
LiDAR
38
Fixed-wing/gas
American
Aerospace/RS-16
720–960
33
Camera
3.2. Vegetation Indices
Using multi-spectral images from the remote sensors described above, a series of Vegetation
Indices (VIs) can be computed. Vegetation Indices (VIs) obtained from remote sensing-based canopies
are effective algorithms for quantitative and qualitative evaluations of vigour, vegetation cover and
growth dynamics, among other applications [26]. Hitherto, no uniﬁed mathematical expression exists
that deﬁnes all VIs due to the complexity of the several light spectra combinations, instrumentation,
resolutions and platforms used. In particular, this section focuses on vegetation indices NDVI, GDVI
and SAVI, as they are widely used in PA.
3.2.1. NDVI
The Normalized Difference Vegetation Index (NDVI) is the most popular VI that is extensively
used to ﬁnd the content of green in PA applications [27,28]. It uses Red (R) and Near Infrared (NIR)
channels to compute the NDVI index. More NIR light is absorbed by healthy vegetation; however,
absorption ratio is very small for red light. NDVI is computed by Equation (1) and returns a value
between −1 and 1 [29].
NDVI = NIR − R
NIR + R
(1)
Higher NDVI value indicate healthy vegetation, while smaller values of NDVI show that vegetation is
very small at that speciﬁc region. There is another form of NDVI, i.e., the Green Normalized Vegetation
Index (GNDVI), which uses the green channel instead of red. GNDVI is computed by Equation (2):
GNDVI = NIR − G
NIR + G
(2)
Sensors 2019, 19, 3796
11 of 25
3.2.2. Difference Vegetation Index
The DVI was proposed to reduce the effect of soil reﬂectance, which is not covered by NDVI [30].
DVI is different between the reﬂectance of the NIR band to the reﬂectance of the red band. DVI is also
computed with the green band, i.e., GDVI. Both DVI and GDVI are computed by Equations (3) and (4):
DVI = NIR − R
(3)
GDVI = NIR − G
(4)
3.2.3. SAVI
NDVI and DVI do not compensate the background effect of soil. Therefore, many vegetation
indices were introduced to compensate the effect of soil reﬂectance. The Soil Adjusted Vegetation Index
(SAVI), the Green Soil Adjusted vegetation Index (GSAVI), the Optimized Soil Adjusted Vegetation
Index (OSAVI), the Green Optimized Soil Adjusted Vegetation Index (OGSAVI) and the Modiﬁed
Soil Adjusted Vegetation Index (MSAVI) [31–33] are common among them, which are computed by
Equations (5)–(9):
SAVI =
1.5(NIR − R)
(NIR + R + 0.5)
(5)
GSAVI = 1.5(NIR − G)
NIR + G + 0.5
(6)
OSAVI =
(NIR − G)
NIR + R + 0.16
(7)
GOSAVI =
(NIR − G)
NIR + G + 0.16
(8)
MSAVI = 0.5[2(NIR + 1) −
q
(2NIR + 1)2 − 8(NIR − R)]
(9)
3.2.4. NR and NG:
Normalized Red (NR) and Normalized Green (NG) are two other famous vegetation indices being
used in PA [33]. NR focuses on the part of spectrum where radiation is absorbed by chlorophyll, while
NG focuses on the part of the spectrum where radiation is absorbed by other pigments, excluding
chlorophyll. NR and NG are computed by Equations (10) and (11):
NR =
R
NIR + R + G
(10)
NG =
G
NIR + R + G
(11)
4. Wireless Sensor Network Applications in Agriculture
Multiple applications of wireless sensor networks are being utilized today in the agriculture sector.
Some very common applications are smart irrigation, smart fertilization, smart pest control and green
house monitoring.
4.1. Smart Irrigation Systems
Smart irrigation is an artiﬁcial irrigation application that controls the quantity of water by making
a decision about where water is needed. It is the most signiﬁcant constituent in agriculture, which has
a great impact on crops’ health, cost and productivity. One major aspect of smart irrigation is to avoid
Sensors 2019, 19, 3796
12 of 25
the wastage of water since most countries in the world are facing water scarcity problems. A smart
irrigation system was presented in [34] in which a Raspberry Pi was used along with two sensors:
a soil moisture sensor was used to assess the water level in the soil, while a temperature and humidity
sensor was used to monitor the environmental condition. The Raspberry Pi was connected to these
sensors and the water supply network. A mobile application was developed for remote monitoring
and remote water ﬂow control enabling both manual and automatic water ﬂow control. In automatic
mode, water ﬂow was automatically turned ON/OFF based on the water level of the soil without
human intervention. In manual mode, the user was able to monitor the soil moisture level. An alert
was generated when the water level of soil was getting below a speciﬁc threshold, and the user turned
it ON/OFF using a mobile application.
Power is a big concern in IoT-based platforms, so many researchers have developed power-
efﬁcient systems. A power-efﬁcient water irrigation system was presented using solar power [35]
in which the controller was connected to the soil sensor and water supply valve. The water valve
was turned ON/OFF based on the water level monitored by the moisture sensor. The power was
supplied by the solar panel, so the system was independent of any external power module. Another
sensor-based IoT system for water irrigation was presented in [36] in which the controller controlled
the opening and closing of a solenoid valve based on the water level of the soil. In addition, a series of
weather alerts were sent to the user via a mobile application to update the temperature and humidity of
the environment, which had a direct inﬂuence on the water level of the soil. In [37], an energy-efﬁcient
irrigation system for cultivated crops was presented using a wireless sensor network in which water
was effectively controlled based on environmental conditions. This system estimated the quantity of
water needed for normal irrigation based on the humidity, temperature and wind speed collected by
sensors along with historical data.
In [38], an IoT-based irrigation system was presented using soil moisture sensors controlled by
ATMEGA 328P on an Arduino UNO board along with a GPRS module. The data collected from the
sensors were sent to the cloud, i.e., Things Speak, where graphs were generated to visualize the data
trends. A web portal was also designed where the farmer was able to check the status of water, if it
was ON/OFF. Similarly, a real-time prototype for an irrigation system was presented in [39] in which
soil moisture sensors and soil temperature sensors were used to assess the water status of the soil.
RFID was used to transmit data to the cloud for further data analysis. Using ATMEGA 328, a water
sprinkler system for smart irrigation was presented in [40] using temperature, humidity and soil
moisture sensors. The water sprinkler was controlled based on the soil moisture level to save water
and reduce human effort. In [41], a cost-effective drip irrigation system for a home was proposed in
which a Raspberry Pi, Arduino, electronic water control valve and relay were used. ZigBee protocols
were used for communication. The user turned ON/OFF the water valve by sending commands to the
Raspberry Pi, which further processed the commands through the Arduino.
The sensors placement is a big issue that affects the accuracy of sensors. A detailed discussion of
soil moisture positioning in the ﬁeld and their accuracy was presented in [42]. For real-time irrigation
systems, complete software and hardware requirements, problems and challenges and advantages
were discussed in [43] where a big picture of the complete system was provided.
4.2. Smart Fertilization System
Fertilizer is an artiﬁcial or natural substance having some chemical elements used to enhance
the growth and productivity of plants. Manual spraying is a common technique used for fertilization.
However, the optimal way of fertilization requires sensing capabilities to ﬁnd the exact place where
fertilizer is needed, which chemical components are missing and the amount of fertilizer needed.
It is important to provide fertilizers in a very precise amount in order to improve productivity [44].
Multiple fertilization techniques have been presented by researchers since the last decade using WSN
and IoT.
Sensors 2019, 19, 3796
13 of 25
An automated fertilization system was presented in [45] using real-time sensors to measure the
soil fertility. The system consisted of three modules including input, output and decision support.
The decision support module measured the optimal amount of fertilizers needed for the growth of the
plants based on the real-time sensory data captured by the sensors. A mechanical sensor named the
“Pendulum Meter” was introduced in [46], which was used for optimal fertilization. This sensor was
mounted on the tractor to measure the density of the crop, so the corresponding fertilizer spreader
was controlled based on the readings of this sensor. The IEEE 802.11 Wi-Fi module was used for
communication along with GPS. Real-time data of soil were collected by several sensors, i.e., soil
moisture, temperature, conductivity, NO2, CO2, etc. A Geographical Information System (GIS) server
was used to interpolate sensory data.
4.3. Smart Pest Control and Early Disease Detection System
Pest attacks are the root cause of low productivity in the agriculture sector. These pests result in
several serious diseases in plants that affect the plant’s growth. However, disease prediction provides
early warning to the farmers, which enables them to make appropriate decisions to control the disease
on time. Pest control systems are comprised of electronic devices that enable humans to identify traps
in a speciﬁc range of these electronic devices [47]. These electronic devices are sensors capable of
calculating the environmental parameters for further analysis.
Much research has been done in the agriculture sector for early disease detection and pest control
systems using more advanced and sophisticated technologies [48,49]. Multiple imagery sensors have
been used by different researchers to collect imagery data, such as: RGB sensors, ﬂuorescence imagery
sensors, spectral sensors and thermal sensors [50]. The thermal sensors are used to measure the water
status in the plant by measuring the temperature, since this parameter has a direct inﬂuence on the
water level in the plants. RGB images have three colour channels, i.e., red, green and blue, which
can be used to perceive the biometric effect in the plants. Multi- and hyper-spectral sensors capture
images containing the spatial information of objects in multiple wavebands. The spatial resolution is
dependent on the distance between the object and the sensor. That is why satellite images contain less
spatial resolution as compared to low altitude platforms such as drones. The ﬂuorescence sensors are
used to distinguish the photosynthetic activities in the plants. Various image processing techniques
are applied to these imagery data to identify the diseases in plants.
In [50], an IoT-based plants disease and pest prediction system was presented to minimize the
excessive use of fungicides and insecticides. Weather condition monitoring sensors, i.e., temperature,
dew, humidity and wind speed, are used to monitor weather parameters to ﬁnd a correlation between
pest growth with weather. The sensors have been deployed in orchards, and data collected from these
sensors are sent to the cloud. The farmer is informed about the alarming condition of the pest attack
on the crops.
From a different point of view, hyper-spectral images are used to analyse crops’ health and pest
attack using manned or unmanned vehicles on which spectral cameras are mounted. The captured
images are analysed in depth using machine learning techniques to identify the disease in the plants.
Advance Neural Networks (ANNs) are more common for processing imagery data due to their ability
to learn complex structures and patterns. Using hyper-spectral images, a system was presented [51] to
identify disease or pest attack in crops. The proposed system for disease detection used an ANN with
multiple layers.
Early disease detection in sugar beet plants was presented in [52]. For early detection, four
supervised classiﬁcation algorithms were applied on spectral images. Spectral images were then
collected for each image, and multiple vegetation indices were calculated to be used in predictive
and perspective analysis. The vegetation indices used were NVDI, SR, SIPI, PSSRaand PSSRb, ARI,
REP, mCAIand RRE. These vegetation indices values were used as features in the dataset. Support
Vector Machine (SVM), ANN, and decision tree were used for classiﬁcation. A comparative analysis
was performed which, showed that SVM outperformed other classiﬁers for disease detection with an
Sensors 2019, 19, 3796
14 of 25
accuracy of 97.12%. In [53], a data mining technique was applied on the already collected dataset of
two types of crops, i.e., wheat and paddy (rice), in India. For dimension reduction, Sammon’s mapping
was used for multi-dimension scaling, i.e., to reduce the dimension also for unsupervised learning.
For high dimensional data, dimension reduction is required prior to performing further data analysis
for better data visualization and accuracy, since redundant dimensions reduce the effectiveness of
any data analysis algorithms. Principle Component Analysis (PCA) is a very often-used technique
along with Sammon’s mapping. Data from multi-dimensions were reduced to two or three dimensions.
Then, the Self-Organized Maps (SOM) algorithm for clustering was used to ﬁnd correlations between
the data. The accuracy comparison of SOM and Sammon’s mapping was presented, which showed
that SOM performed better on a large dataset, while Sammon’s mapping was suitable for small ones.
Smart phones played important role in data acquisition, which were further used to monitor the crops’
health. In [54], the health of wheat crop was monitored using near surface imagery captured by a smart
phone. The crop was classiﬁed as healthy or unhealthy based on the green level by computing Gcc.
Most of the applications in PA have been either IoT-based in which multiple sensors are used to
assess the health of the crop or remote sensing-based in which crop health is assessed by performing
some computation on spectral images. We can compare crop health monitoring application based
on some attributes such as which sensors are used in particular applications, whether web or mobile
services are provided or not, etc. The comparative analysis of some existing crop health monitoring
applications is presented in Table 8 based on some attributes.
To precisely monitor the crop health, both IoT-based techniques and remote sensing techniques
should be used together to provide more reliable and accurate information about the crop. As a
proof of concept, we present a case study in which a crop health monitoring system based on IoT and
remote sensing techniques is proposed. We provide a complete end-to-end solution in the agriculture
domain by facilitating the agricultural user with web and mobile services so that he/she could be
informed about the latest condition of the crop in a timely manner. In this way, remedy actions could
be performed in time, which will result in enhanced production.
Sensors 2019, 19, 3796
15 of 25
Table 8. Comparison among existing PA applications.
PA
Edge
Data
Soil
Soil
Air
Air
Vegetation
Web
Mobile
Light
Wind
Application
Computing
Analytic
Moisture
Temperature
Moisture
Temperature
Index
Services
Services
Intensity
Velocity
[1]
N
Y
N
N
N
Y
Y
N
N
N
N
[4]
N
Y
N
N
N
N
N
Y
Y
N
N
[28]
N
Y
N
N
N
N
Y
N
N
N
N
[29]
N
Y
N
N
N
N
Y
N
N
N
N
[41]
N
N
Y
N
N
N
N
N
N
N
N
[52]
N
Y
N
N
N
N
Y
N
N
N
N
[55]
N
N
Y
N
Y
Y
N
N
Y
N
N
[56]
Y
N
Y
Y
Y
Y
N
N
N
Y
N
[57]
N
Y
Y
Y
Y
Y
N
N
N
Y
N
[58]
N
N
N
Y
N
N
N
N
N
N
N
[59]
N
Y
N
N
N
N
Y
N
N
N
N
[60]
Y
Y
Y
N
Y
Y
N
Y
Y
Y
N
[61]
Y
Y
Y
Y
Y
Y
N
Y
Y
Y
Y
[62]
N
Y
N
N
N
Y
N
Y
N
N
N
[63]
N
Y
Y
Y
Y
Y
N
Y
N
N
N
[64]
N
Y
Y
N
Y
Y
N
Y
N
N
N
[65]
N
Y
Y
Y
N
Y
N
N
N
N
N
[66]
N
Y
N
N
N
N
Y
N
N
N
N
[67]
N
Y
Y
Y
N
Y
Y
Y
Y
N
N
[68]
N
Y
N
N
N
N
Y
N
N
N
N
Proposed system
Y
Y
Y
Y
Y
Y
Y
Y
Y
N
N
Sensors 2019, 19, 3796
16 of 25
5. A Case Study on UAV-Based and IoT-Based Precision Agriculture
We developed a complete solution for crop health monitoring based on IoT and remote sensing.
In the proposed system, crop health is monitored using data collected from multiple IoT sensors,
as well as NDVI mapping of spectral images captured by a drone. The architecture of the proposed
system is shown in Figure 1, which was designed according to two main modules. The ﬁrst module
was a wireless sensor network-based system in which multiple wireless nodes were developed. Each
wireless node was comprised of a soil moisture sensor used to monitor the water level of the soil,
a soil temperature sensor used to check the temperature of the soil and air temperature and humidity
sensors. These nodes were deployed across the ﬁeld in a star topology fashion where the master node
collected readings from all slave nodes and transmitted the captured reading to the back-end server for
further processing. The master node acted as a gateway node, which received data from all slave nodes
using NRF communication module. After performing initial processing, the master node transmitted
the data to the cloud using GSM communication technology. In the case of the unavailability of the
GSM network, this node stored the captured data and transmitted to the cloud upon the availability
of network.
The second module was used to monitor crop health using multi-spectral imagery, which was
collected by a multi-spectral camera mounted on a drone. The NDVI was computed using Equation (1)
to classify between healthy and unhealthy plants by measuring the chlorophyll content in the crops,
which was further used to localize the area under stress precisely.
All collected data were sent to the cloud where further analysis was performed. The web portal
was designed to help the farmer monitor the crop proﬁle over the whole life cycle. Currently, we are
monitoring soil moisture, soil temperature, air moisture and air temperature readings in real time
along with NDVI mapping of spectral imagery. Multiple web services were provided on the web
portal including historical/real data visualization using graphs, weather monitoring, NDVI mapping
and the correlation among measured parameters. Figure 2 shows the snapshots of the web portal
along with different services.
Figure 1. System architecture.
Sensors 2019, 19, 3796
17 of 25
Figure 2. User interface of the web portal.
For portability and remote monitoring, a mobile application was also developed to facilitate the
farmer/agronomist/landlord with all the web services that are available on web portal. The alerts
are generated when an abnormal behaviour is observed in the crop, which help the farmer to take
remedy actions in a timely manner. The user interfaces of the mobile application are shown in Figure 3.
Therefore, the web portal along with mobile applications provides a complete solution, which enables
agricultural users monitor the current status of the crop, as well as previous details.
Figure 3. User interface of the mobile application.
Sensors 2019, 19, 3796
18 of 25
6. Results and Discussion
6.1. Analysis of the Data Collected by IoT Nodes
The developed IoT nodes were deployed across the wheat ﬁelds of an area of 1.4375 hectare.
The selected area was located in Islamabad, Pakistan. The wheat ﬁelds are shown in Figure 4 along
with the IoT node and sensors. We deployed the system across the wheat ﬁeld in March 2019 when
wheat was in the grain ﬁlling and grain ripening stage.
Figure 4. System deployed across the wheat ﬁelds.
We collected the sensors’ readings such as air temperature, air humidity, soil temperature and
soil moisture. We compared the observed crop parameters with the ideal wheat temperature proﬁle
as shown in Figure 5. Extreme variation in the weather of Islamabad was observed in that particular
time period, which can be seen by how the actual temperature for wheat crop deviated from the ideal
temperature proﬁle of the wheat crop.
Figure 5. Deviation of observed temperature from the ideal temperature proﬁle.
Additionally, we performed linear regression to ﬁnd the correlation between observed parameters,
which provided insight into how changes in one parameter can effect the other parameter. The linear
regression found a relation between the two parameters by ﬁtting the equation of the line using the
observed dataset [69]. Equation (12) represents an equation of the line where mrepresents the slope of
line, while c indicates the y-intercept. The variables m and c were learned from the data.
y = mx + c
(12)
Figure 6A shows the correlation between the observed air temperature and air humidity, which showed
that both were negatively correlated. The correlation between air temperature and soil temperature is
shown in Figure 6B, which shows that both were positively correlated.
Sensors 2019, 19, 3796
19 of 25
(A)
(B)
Figure 6. (A) Correlation b/wair temperature and air humidity. (B) Correlation b/w air temperature
and soil temperature.
The rise in air temperature caused the air humidity to reduce, while it resulted in an increase in
soil temperature and vice versa.
6.2. Analysis of Multi-spectral Images Captured by Drone
To collect multi-spectral imagery, we used the DJI-Phantom Pro Advanced drone with the Sentera
Multi-spectral-imaging sensor. The drone had its own optical camera, while the multi-spectral camera
was mounted on it to obtain spectral images. Multiple ﬂights of the drone were carried out at the
speciﬁc growing stages of the crop, i.e., grain ripening and grain ﬁlling stage. After collecting these
images, they were transferred to the cloud for NDVI mapping. Figure 7A shows the optical image
that was captured on 16 May 2019 when wheat was in the harvesting stage, while Figure 7B is its
spectral image, and Figure 7C is the NDVI mapping. Since wheat was at a mature stage, its NDVI
should be very small, i.e., ideally there should be no green region in the ﬁeld. However, in NDVI
mapping, a large green region indicated the abnormal behaviour of the crop. The green region was
due to naturally growing plants. This information can be visualized on the web portal.
(A)
(B)
(C)
Figure 7. Wheat crop. (A) Optical image; (B) spectral image; (C) NDVI mapping.
The same process was performed in a maize ﬁeld when maize was in the grain ripening stage.
Figure 8A shows the optical image that was captured on 24 July 2019 when maize was in the grain
ripening stage, while Figure 8B is its spectral image, and Figure 8C is the NDVI mapping. The same
behaviour can be observed with the maize crop, i.e., there should be a minimal green region in the
ﬁeld. However, in NDVI mapping, a large green region indicated the abnormal behaviour of the crop.
Sensors 2019, 19, 3796
20 of 25
(A)
(B)
(C)
Figure 8. Maize crop. (A) Optical image; (B) spectral image; (C) NDVI mapping.
7. Challenges
PA has been used since the last few decades to enhance crops’ yield with reduced costs and
human effort, although the adoption of these novel techniques by farmers is still very limited owing to
the following reasons or challenges.
7.1. Hardware Cost
PA relies mostly on hardware such as sensors, wireless nodes, drones, spectral imaging sensors,
etc., which are used to assess multiple parameters in real time. These sensors have multiple limitations
including high development, maintenance and deployment cost. Some systems in PA are cost effective
and are suitable for small arable land, i.e., smart irrigation systems that require low-cost hardware
components and sensors. However, drone-based systems for crops’ health monitoring are feasible for
large arable land due to high installation cost.
7.2. Weather Variations
Environmental variation is one of the major challenges that affects the accuracy of data collected
by sensors. Sensor nodes deployed in the ﬁeld are sensitive to environmental variations, i.e., rain,
ﬂuctuation in temperature, wind speed, sun light, etc. Communication between wireless nodes
and the cloud can be interrupted due interference induced in wireless communication channels by
atmospheric disturbance. The satellite, air borne and drone platforms are also sensitive to weather
variations. Imagery acquired by these platforms is affected by contamination of clouds and other
natural aerosols. The development of advanced techniques for atmospheric correction, cloud detection
and noise interpolation is a current open challenge, which requires hard efforts from the research
community.
7.3. Data Management
The sensors in PA constantly generate data. To ensure the integrity of data, some data security
measures needs to be in place, which will in turn enhance the cost of the system. The readings from
the sensors have to be accurate in order to take appropriate actions precisely when and where required.
An intruder can corrupt the readings, and false readings will adversely reduce the effectiveness of
the system. PA systems generate immense amounts of data, which require enough resources to
perform data analysis. Real-time data collected from sensors deployed across the ﬁelds after a few
minutes and spectral imagery acquired from high-altitude or low-altitude platforms produce the bulk
of the data, which increase the storage and processing requirements. New software platforms and
facilities for scalable management of Big Data sources are demanded. In this regard, the generation
of software-as-a-service solutions is focused on merging data management and IoT thorough cloud
computing platforms.
Sensors 2019, 19, 3796
21 of 25
7.4. Literacy Rate
Literacy is an important factor that inﬂuences the adoption ratio in PA. In developing countries
where the illiteracy rate is high, farmers grow crops based on their experience. They do not utilize the
state-of-the-art technologies in agriculture, which results in loss of production. Farmers need to be
educated in order to understand the technology or they have to trust a third party for technical support.
Therefore, in underdeveloped areas where the literacy rate is not high, PA is not very common due to
the limitations of resources and education.
7.5. Connectivity
Next-generation 5G networks can be 100-times faster than 4G ones, making communication
between devices and servers much quicker. 5G can also carry much more data than other networks,
which makes it an ideal technology for transmitting information from remote sensors and drones, key
tools that are being tested in PA environments. The adoption of new communication networks based
on 5G is a must in current applications where secure and rapid data transfer enables real-time data
management and support for decision making.
7.6. Interoperability
One of the biggest problems PA faces is the interoperability of equipment due to different digital
standards. This lack of interoperability is not only obstructing the adoption of new IoT technologies
and slowing down their growth, but it also inhibits the gain of production efﬁciency through smart
agriculture applications. New methods and protocols to integrate different machine communication
standards to unlock the potential of efﬁcient machine-to-machine communication and data sharing
between machines and management information systems are required in the current scenario of PA.
8. Conclusion and Future Directions
Precision agriculture is a modern practice used to enhance crops’ productivity using latest
technologies, i.e., WSN, IoT, cloud computing, Artiﬁcial Intelligence (AI) and Machine Learning
(ML). Most of the research done so far indicates that PA-based practices have a great inﬂuence on
sustainability and productivity. The objective of PA is to provide decision support systems based
on multiple parameters of crops, i.e., soil nutrients, water level of the soil, wind speed, intensity of
sunlight, temperature, humidity, chlorophyll content, etc. However, several challenges are involved
in the development and deployment phase of these systems. This article was aimed at providing a
survey of modern technologies involving current PA platforms, with the goal of supporting industry
and research communities on the development of modern applications for smart agriculture. A case
study was presented to prove the effectiveness of the PA in the agriculture domain.
Since the main objective of precision agriculture is to produce surplus yield by optimizing the
resources such as water, pesticides, fertilizers, etc., for resource optimization, prescription maps play
an important role, which enables farmers to quantify resources required for healthy crops at any
particular growth stage. Most of the research accomplished in the agriculture domain focuses on the
remote sensing platforms to collect imagery, which reﬂects only Vegetation Indices (VIs) such as NDVI.
The prescription maps cannot be generated by only using VIs; instead, multiple other factors need to
be considered such as soil properties, soil moisture level, meteorological behaviour, etc.
Funding: This work is funded by the Research England’s QR Global Challenges Research Fund (GCRF) under
Project “GrITS: Green IoT for Climate Smart Agriculture”.
Acknowledgments: We extend our sincere thanks and gratitude to National Agriculture Research Centre (NARC)
Islamabad, Pakistan for allowing us to ﬂy drone in their premises and capture spectral imagery to monitor crop
health. We are also indebt to NUST-SEECS for providing the administrative and technical support to IoT lab for
conducting this research work.
Conﬂicts of Interest: The authors declare no conﬂict of interest.
Sensors 2019, 19, 3796
22 of 25
References
1.
Mumtaz, R.; Baig, S.; Fatima, I. Analysis of meteorological variations on wheat yield and its estimation using
remotely sensed data. A case study of selected districts of Punjab Province, Pakistan (2001–14). Ital. J. Agron.
2017, 12. [CrossRef]
2.
Wang, N.; Zhang, N.; Wang, M. Wireless sensors in agriculture and food industry—Recent development and
future perspective. Comput. Electron. Agric. 2006, 50, 1–14. [CrossRef]
3.
Abbasi, A.Z.; Islam, N.; Shaikh, Z.A. A review of wireless sensors and networks’ applications in agriculture.
Comput. Stand. Interfaces 2014, 36, 263–270.
4.
Rad, C.R.; Hancu, O.; Takacs, I.A.; Olteanu, G. Smart monitoring of potato crop: A cyber-physical system
architecture model in the ﬁeld of precision agriculture. Agric. Agric. Sci. Procedia 2015, 6, 73–79. [CrossRef]
5.
Baccarelli, E.; Naranjo, P.G.V.; Scarpiniti, M.; Shojafar, M.; Abawajy, J.H. Fog of everything: Energy-efﬁcient
networked computing architectures, research challenges, and a case study. IEEE Access 2017, 5, 9882–9910.
[CrossRef]
6.
Naranjo, P.G.V.; Shojafar, M.; Mostafaei, H.; Pooranian, Z.; Baccarelli, E. P-SEP: A prolong stable election
routing algorithm for energy-limited heterogeneous fog-supported wireless sensor networks. J. Supercomput.
2017, 73, 733–755. [CrossRef]
7.
Kirby, M.; Mainuddin, M.; Khaliq, T.; Cheema, M. Agricultural production, water use and food availability
in Pakistan: Historical trends, and projections to 2050. Agric. Water Manag. 2017, 179, 34–46. [CrossRef]
8.
Al-Sarawi, S.; Anbar, M.; Alieyan, K.; Alzubaidi, M. Internet of Things (IoT) communication protocols.
In Proceedings of the 2017 8th International Conference on Information Technology (ICIT), Amman, Jordan,
17–18 May 2017; pp. 685–690.
9.
Zhang, X.; Andreyev, A.; Zumpf, C.; Negri, M.C.; Guha, S.; Ghosh, M. Thoreau: A subterranean wireless
sensing network for agriculture and the environment. In Proceedings of the 2017 IEEE Conference on
Computer Communications Workshops (INFOCOM WKSHPS), Atlanta, GA, USA, 1–4 May 2017; pp. 78–84.
10.
Khelifa, B.; Amel, D.; Amel, B.; Mohamed, C.; Tarek, B.
Smart irrigation using internet of things.
In Proceedings of the 2015 Fourth International Conference on Future Generation Communication
Technology (FGCT), Luton, UK, 29–31 July 2015; pp. 1–6.
11.
Paventhan, A.; Allu, S.K.; Barve, S.; Gayathri, V.; Ram, N.M. Soil property monitoring using 6lowpan-enabled
wireless sensor networks. In Proceedings of the Agro-Informatics and Precision Agriculture, Hyderabad,
India, 1–3 August 2012.
12.
Suryady, Z.; Shaharil, M.H.M.; Bakar, K.A.; Khoshdelniat, R.; Sinniah, G.R.; Sarwar, U. Performance
evaluation of 6LoWPAN-based precision agriculture. In Proceedings of the International Conference on
Information Networking 2011 (ICOIN2011), Barcelona, Spain, 26–28 January 2011; pp. 171–176.
13.
Sarode, K.; Chaudhari, P. Zigbee based Agricultural Monitoring and Controlling System. Int. J. Eng. Sci.
2018, 8, 15907–15910.
14.
Zhou, Y.; Yang, X.; Guo, X.; Zhou, M.; Wang, L. A design of greenhouse monitoring & control system
based on ZigBee wireless sensor network.
In Proceedings of the 2007 International Conference on
Wireless Communications, Networking and Mobile Computing, Shanghai, China, 21–25 September 2007;
pp. 2563–2567.
15.
Chikankar, P.B.; Mehetre, D.; Das, S. An automatic irrigation system using ZigBee in wireless sensor
network. In Proceedings of the 2015 International Conference on Pervasive Computing (ICPC), Pune, India,
8–10 January 2015; pp. 1–5.
16.
Xue-fen, W.; Xing-jing, D.; Wen-qiang, B.; Le-han, L.; Jian, Z.; Chang, Z.; Ling-xuan, Z.; Yu-xiao, Y.P.; Yi, Y.
Smartphone accessible agriculture IoT node based on NFC and BLE. In Proceedings of the 2017 IEEE
International Symposium on Consumer Electronics (ISCE), Kuala Lumpur, Malaysia, 14–15 November 2017;
pp. 78–79.
17.
Tanaka, K.; Murase, M.; Naito, K. Prototype implementation of BLE based automated data collection
scheme in agricultural measurement system.
In Proceedings of the 2018 15th IEEE Annual Consumer
Communications & Networking Conference (CCNC), Las Vegas, NV, USA, 12–15 January 2018; pp. 1–2.
18.
Wasson, T.; Choudhury, T.; Sharma, S.; Kumar, P. Integration of RFID and sensor in agriculture using
IOT.
In Proceedings of the 2017 International Conference On Smart Technologies For Smart Nation
(SmartTechCon), Bangalore, India, 17–19 August 2017; pp. 217–222.
Sensors 2019, 19, 3796
23 of 25
19.
Liang, M.H.; He, Y.F.; Chen, L.J.; Du, S.F. Greenhouse Environment dynamic Monitoring system based on
WIFI. IFAC-PapersOnLine 2018, 51, 736–740. [CrossRef]
20.
N-USha, T.M. Conditions in Agriculture through WiFi using Raspberry PI. Int. J. Eng. 2017, 3, 6–11.
21.
Davcev, D.; Mitreski, K.; Trajkovic, S.; Nikolovski, V.; Koteli, N. IoT agriculture system based on LoRaWAN.
In Proceedings of the 2018 14th IEEE International Workshop on Factory Communication Systems (WFCS),
Imperia, Italy, 13–15 June 2018; pp. 1–4.
22.
Rudd, J.D.; Roberson, G.T.; Classen, J.J. Application of satellite, unmanned aircraft system, and ground-based
sensor data for precision agriculture: A review. In Proceedings of the 2017 ASABE Annual International
Meeting, Spokane, WA, USA, 16–19 July 2017.
23.
Toth, C.; Jó´zków, G. Remote sensing platforms and sensors: A survey. ISPRS J. Photogramm. Remote Sens.
2016, 115, 22–36. [CrossRef]
24.
Zhong, Y.; Wang, X.; Xu, Y.; Wang, S.; Jia, T.; Hu, X.; Zhao, J.; Wei, L.; Zhang, L.
Mini-UAV-Borne
Hyperspectral Remote Sensing: From Observation and Processing to Applications. IEEE Geosci. Remote Sens.
Mag. 2018, 6, 46–62. [CrossRef]
25.
Candiago, S.; Remondino, F.; De Giglio, M.; Dubbini, M.; Gattelli, M. Evaluating multispectral images and
vegetation indices for precision farming applications from UAV images. Remote Sens. 2015, 7, 4026–4047.
[CrossRef]
26.
Xue, J.; Su, B. Signiﬁcant remote sensing vegetation indices: A review of developments and applications.
J. Sens. 2017, 2017, 1353691. [CrossRef]
27.
Skakun, S.; Justice, C.O.; Vermote, E.; Roger, J.C. Transitioning from MODIS to VIIRS: An analysis of
inter-consistency of NDVI data sets for agricultural monitoring.
Int. J. Remote Sens. 2018, 39, 971–992.
[CrossRef]
28.
Daroya, R.; Ramos, M. NDVI image extraction of an agricultural land using an autonomous quadcopter
with a ﬁlter-modiﬁed camera. In Proceedings of the 2017 7th IEEE International Conference on Control
System, Computing and Engineering (ICCSCE), Penang, Malaysia, 24–26 November 2017; pp. 110–114.
29.
Mahajan, U.; Raj, B. Drones for Normalized Difference Vegetation Index (NDVI), to estimate Crop Health for
Precision Agriculture: A Cheaper Alternative for Spatial Satellite Sensors. In Proceedings of the International
Conference on Innovative Research in Agriculture, Food Science, Forestry, Horticulture, Aquaculture,
Animal Sciences, Biodiversity, Ecological Sciences and Climate Change (AFHABEC-2016), Delhi, India,
22 October 2016.
30.
Richardson, A.J.; Wiegand, C. Distinguishing vegetation from soil background information. Photogr. Eng.
Remote Sens. 1977, 43, 1541–1552.
31.
Huete, A.R. A soil-adjusted vegetation index (SAVI). Remote Sens. Environ. 1988, 25, 295–309. [CrossRef]
32.
Rondeaux, G.; Steven, M.; Baret, F. Optimization of soil-adjusted vegetation indices. Remote Sens. Environ.
1996, 55, 95–107. [CrossRef]
33.
Qi, J.; Chehbouni, A.; Huete, A.; Kerr, Y.; Sorooshian, S. A modiﬁed soil adjusted vegetation index. Remote
Sens. Environ. 1994, 48, 119–126. [CrossRef]
34.
Akubattin, V.; Bansode, A.; Ambre, T.; Kachroo, A.; SaiPrasad, P. Smart irrigation system. Int. J. Sci. Res.
Sci. Technol. 2016, 2, 343–345.
35.
Harishankar, S.; Kumar, R.S.; Sudharsan, K.; Vignesh, U.; Viveknath, T. Solar powered smart irrigation
system. Adv. Electr. Comput. Eng. 2014, 4, 341–346.
36.
Kansara, K.; Zaveri, V.; Shah, S.; Delwadkar, S.; Jani, K. Sensor based automated irrigation system with IOT:
A technical review. Int. J. Comput. Sci. Inf. Technol. 2015, 6, 5331–5333.
37.
Nikolidakis, S.A.; Kandris, D.; Vergados, D.D.; Douligeris, C. Energy efﬁcient automated control of irrigation
in agriculture by using wireless sensor networks. Comput. Electron. Agric. 2015, 113, 154–163. [CrossRef]
38.
Rawal, S. IOT based Smart Irrigation System. Int. J. Comput. Appl. 2017, 159, 880–886. [CrossRef]
39.
Vellidis, G.; Tucker, M.; Perry, C.; Kvien, C.; Bednarz, C. A real-time wireless smart sensor array for
scheduling irrigation. Comput. Electron. Agric. 2008, 61, 44–50. [CrossRef]
40.
Kumar, B.D.; Srivastava, P.; Agrawal, R.; Tiwari, V. Microcontroller based automatic plant Irrigation system.
Int. Res. J. Eng. Tenchnol. 2017, 4, 1436–1439.
41.
Agrawal, N.; Singhal, S. Smart drip irrigation system using raspberry pi and arduino. In Proceedings of the
International Conference on Computing, Communication & Automation, Noida, India, 15–16 May 2015;
pp. 928–932.
Sensors 2019, 19, 3796
24 of 25
42.
Soulis, K.X.; Elmaloglou, S.; Dercas, N. Investigating the effects of soil moisture sensors positioning and
accuracy on soil moisture based drip irrigation scheduling systems. Agric. Water Manag. 2015, 148, 258–268.
[CrossRef]
43.
Yousif, M.E.R.; Ghafar, K.; Zahari, R.; Lim, T.H. A rule-based smart automated fertilization and irrigation
systems. In Proceedings of the Ninth International Conference on Graphic and Image Processing (ICGIP
2017), Qingdao, China, 14–16 October 2017.
44.
Cugati, S.; Miller, W.; Schueller, J. Automation concepts for the variable rate fertilizer applicator for tree
farming. In Proceedings of the 4th European Conference on Precision Agriculture, Berlin, Germany, 15–19
June 2003; pp. 14–19.
45.
He, J.; Wang, J.; He, D.; Dong, J.; Wang, Y. The design and implementation of an integrated optimal
fertilization decision support system. Math. Comput. Model. 2011, 54, 1167–1174. [CrossRef]
46.
Chen, X.; Zhang, F. The establishment of fertilization technology index system based on “3414” fertilizer
experiment. China Agric. Technol. Ext. 2006, 22, 36–39.
47.
Mahlein, A.K.; Oerke, E.C.; Steiner, U.; Dehne, H.W. Recent advances in sensing plant diseases for precision
crop protection. Eur. J. Plant Pathol. 2012, 133, 197–209. [CrossRef]
48.
Sankaran, S.; Mishra, A.; Ehsani, R.; Davis, C. A review of advanced techniques for detecting plant diseases.
Comput. Electron. Agric. 2010, 72, 1–13. [CrossRef]
49.
Mahlein, A.K. Plant disease detection by imaging sensors–parallels and speciﬁc demands for precision
agriculture and plant phenotyping. Plant Dis. 2016, 100, 241–251. [CrossRef] [PubMed]
50.
Lee, H.; Moon, A.; Moon, K.; Lee, Y. Disease and pest prediction IoT system in orchard: A preliminary study.
In Proceedings of the 2017 Ninth International Conference on Ubiquitous and Future Networks (ICUFN),
Milan, Italy, 4–7 July 2017; pp. 525–527.
51.
Golhani, K.; Balasundram, S.K.; Vadamalai, G.; Pradhan, B. A review of neural networks in plant disease
detection using hyperspectral data. Inf. Process. Agric. 2018, 5, 354–371. [CrossRef]
52.
Rumpf, T.; Mahlein, A.K.; Steiner, U.; Oerke, E.C.; Dehne, H.W.; Plümer, L. Early detection and classiﬁcation
of plant diseases with support vector machines based on hyperspectral reﬂectance. Comput. Electron. Agric.
2010, 74, 91–99. [CrossRef]
53.
Sanghvi, Y.; Gupta, H.; Doshi, H.; Koli, D.; Ansh, A.; Gupta, U. Comparison of Self organizing maps
and Sammon’s mapping on agricultural datasets for precision agriculture.
In Proceedings of the 2015
International Conference on Innovations in Information, Embedded and Communication Systems (ICIIECS),
Coimbatore, India, 19–20 March 2015; pp. 1–5.
54.
Hufkens, K.; Melaas, E.K.; Mann, M.L.; Foster, T.; Ceballos, F.; Robles, M.; Kramer, B. Monitoring crop
phenology using a smartphone based near-surface remote sensing approach. Agric. For. Meteorol. 2019,
265, 327–337. [CrossRef]
55.
Prathibha, S.; Hongal, A.; Jyothi, M. IOT Based monitoring system in smart agriculture. In Proceedings
of the 2017 International Conference on Recent Advances in Electronics and Communication Technology
(ICRAECT), Bangalore, India, 16–17 March 2017; pp. 81–84.
56.
Heble, S.; Kumar, A.; Prasad, K.V.D.; Samirana, S.; Rajalakshmi, P.; Desai, U.B. A low power IoT network
for smart agriculture. In Proceedings of the 2018 IEEE 4th World Forum on Internet of Things (WF-IoT),
Singapore, 5–8 February 2018; pp. 609–614.
57.
Sabo, A.; Qaisar, S.; Subasi, A.; Rambo, K. An Event Driven Wireless Sensors Network for Monitoring
of Plants Health and Larva Activities. In Proceedings of the 2018 21st Saudi Computer Society National
Computer Conference (NCC), Riyadh, Saudi Arabia, 25–26 April 2018; pp. 1–7.
58.
Agarwal, A.; Gupta, S.; Kumar, S.; Singh, D. A concept of satellite-based IoT for downscaling the MODIS
data to extract Land Surface Temperature. In Proceedings of the 2018 9th International Symposium on
Signal, Image, Video and Communications (ISIVC), Rabat, Morocco, 27–30 November 2018; pp. 67–70.
59.
Rahman, M.R.; Islam, A.; Rahman, M.A. NDVI derived sugarcane area identiﬁcation and crop condition
assessment. Plan Plus 2004, 1, 1–12.
60.
Choudhury, S.B.; Jain, P.; Kallamkuth, S.; Ramanath, S.; Bhatt, P.V.; Sarangi, S.; Srinivasu, P. Precision Crop
Monitoring with Affordable IoT: Experiences with Okra. In Proceedings of the 2019 Global IoT Summit
(GIoTS), Aarhus, Denmark, 17–21 June 2019; pp. 1–6.
Sensors 2019, 19, 3796
25 of 25
61.
Mittal, A.; Sarangi, S.; Ramanath, S.; Bhatt, P.V.; Sharma, R.; Srinivasu, P. IoT-Based Precision Monitoring of
Horticultural Crops—A Case-Study on Cabbage and Capsicum. In Proceedings of the 2018 IEEE Global
Humanitarian Technology Conference (GHTC), San Jose, CA, USA, 18–21 October 2018; pp. 1–7.
62.
Saha, A.K.; Saha, J.; Ray, R.; Sircar, S.; Dutta, S.; Chattopadhyay, S.P.; Saha, H.N. IOT-based drone for
improvement of crop quality in agricultural ﬁeld. In Proceedings of the 2018 IEEE 8th Annual Computing and
Communication Workshop and Conference (CCWC), Las Vegas, NV, USA, 8–10 January 2018; pp. 612–615.
63.
Mekala, M.S.; Viswanathan, P. CLAY-MIST: IoT-cloud enabled CMM index for smart agriculture monitoring
system. Measurement 2019, 134, 236–244. [CrossRef]
64.
Nawandar, N.K.; Satpute, V.R. IoT based low cost and intelligent module for smart irrigation system.
Comput. Electron. Agric. 2019, 162, 979–990. [CrossRef]
65.
Srbinovska, M.; Gavrovski, C.; Dimcev, V.; Krkoleva, A.; Borozan, V. Environmental parameters monitoring
in precision agriculture using wireless sensor networks. J. Clean. Prod. 2015, 88, 297–307. [CrossRef]
66.
Lottes, P.; Khanna, R.; Pfeifer, J.; Siegwart, R.; Stachniss, C. UAV-based crop and weed classiﬁcation for smart
farming. In Proceedings of the 2017 IEEE International Conference on Robotics and Automation (ICRA),
Singapore, 29 May–3 June 2017; pp. 3024–3031.
67.
Cambra, C.; Sendra, S.; Lloret, J.; Garcia, L. An IoT service-oriented system for agriculture monitoring.
In Proceedings of the 2017 IEEE International Conference on Communications (ICC), Paris, France,
21–25 May 2017.
68.
Fontana, D.C.; Pinto, D.G.; Junges, A.H.; Bremm, C. Using temporal NDVI/MODIS proﬁles for inferences
on the crop soybean calendar. Bragantia 2015, 74, 350–358. [CrossRef]
69.
Seber, G.A.; Lee, A.J. Linear Regression Analysis; John Wiley & Sons: Hoboken, NJ, USA, 2012; Volume 329.
c⃝ 2019 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access
article distributed under the terms and conditions of the Creative Commons Attribution
(CC BY) license (http://creativecommons.org/licenses/by/4.0/).


Paper 3:
- APA Citation: 
  Main Objective: 
  Study Location: 
  Data Sources: 
  Technologies Used: 
  Key Findings: 
  Extract 1: "GeoFIS has been designed to facilitate the movement from spatial data to spatial information, and to spatial decision-making. It is an open-source program that proposes a simple and easy to use interface to build decision support systems (DSS) from spatial data [30]. While its development has been inspired by agri-environmental applications, the framework itself is open and accessible to applications in other domains. It is designed to be adaptable to different usages and for different end-users, mostly for academic and research applications, for student and teaching applications and, to a lesser extent, for GIS-skilled agronomists and advisors."
  Extract 2: "‘Precision Agriculture’ or ‘Smart Agriculture’ is only effective when effective decisions are made. End-users can transform these information layers into decision layers to improve the management of their fields. Three main functionalities for management (practical) applications have been incorporated within GeoFIS to address this. Firstly, practitioners are provided with a method to delineate within-field homogeneous zones (Step 3.1). Zoning is of importance for precision agriculture data as the identified zones will (i) facilitate spatial data visualization and interpretation, and (ii) provide a spatial resolution that is practical and effective for many differential field operations. GeoFIS uses a segmentation algorithm to ‘zone’ data layers [18]. The segmentation algorithm operates either on irregular or gridded (interpolated) data to generate potential management zones."
  Limitations: >
  Relevance Evaluation: This research is relevant to the point you are making in your literature review because it addresses the need for easy-to-use, open-source software that can be used by farmers and advisors to process spatial data from precision agriculture. The authors evaluate the ability of GeoFIS to perform three common tasks: mapping spatial variability, evaluating the opportunity for site-specific management, and delineating within-field zones for variable rate applications.
  Relevance Score: 0.8
  Inline Citation: >
  Explanation: The study aims to evaluate the ability of GeoFIS to answer the most common issues and challenges faced by the agricultural sector when processing their spatial data. The authors achieve this by evaluating GeoFIS's ability to map the spatial variability in a data set, evaluate the opportunity for site-specific management and delineate within-field zones for variable rate applications.

 Full Text: >
agriculture
Article
GeoFIS: An Open Source, Decision-Support Tool for
Precision Agriculture Data
Corentin Leroux 1,2,*, Hazaël Jones 1, Léo Pichon 1, Serge Guillaume 1, Julien Lamour 1,3,
James Taylor 1, Olivier Naud 1, Thomas Crestey 1, Jean-Luc Lablee 1 and Bruno Tisseyre 1
1
ITAP (Information–Technologies-Environmental Analysis-Agricultural Processes, French Denomination),
Montpellier SupAgro, Irstea, University of Montpellier, 34000 Montpellier, France;
hazael.jones@supagro.fr (H.J.); leo.pichon@supagro.fr (L.P.); serge.guillaume@irstea.fr (S.G.);
j.lamour@fruitiere.fr (J.L.); James.Taylor6@newcastle.ac.uk (J.T.); olivier.naud@irstea.fr (O.N.);
thomas.crestey@supagro.fr (T.C.); jean-luc.lablee@irstea.fr (J.-L.L.); bruno.tisseyre@gmail.com (B.T.)
2
SMAG, 34960 Montpellier, France
3
Compagnie Fruitière, 13000 Marseille, France
*
Correspondence: cleroux@smag-group.com; Tel.: +33-(0)3-2621-8420
Received: 25 April 2018; Accepted: 28 May 2018; Published: 30 May 2018


Abstract: The world we live in is an increasingly spatial and temporal data-rich environment,
and agriculture is no exception. However, data needs to be processed in order to ﬁrst get information
and then make informed management decisions. The concepts of ‘Precision Agriculture’ and
‘Smart Agriculture’ are and will be fully effective when methods and tools are available to practitioners
to support this transformation. An open-source software called GeoFIS has been designed with
this objective. It was designed to cover the whole process from spatial data to spatial information
and decision support. The purpose of this paper is to evaluate the abilities of GeoFIS along with
its embedded algorithms to address the main features required by farmers, advisors, or spatial
analysts when dealing with precision agriculture data. Three case studies are investigated in the
paper: (i) mapping of the spatial variability in the data; (ii) evaluation and cross-comparison of the
opportunity for site-speciﬁc management in multiple ﬁelds; and (iii) delineation of within-ﬁeld zones
for variable-rate applications when these latter are considered opportune. These case studies were
applied to three contrasting crop types, banana, wheat and vineyards. These were chosen to highlight
the diversity of applications and data characteristics that might be handled with GeoFIS. For each
case-study, up-to-date algorithms arising from research studies and implemented in GeoFIS were
used to process these precision agriculture data. Areas for future development and possible relations
with existing geographic information systems (GIS) software is also discussed.
Keywords: decision-making; GeoFIS; geostatistics; open source software; precision agriculture;
spatial analysis
1. Introduction
Within-ﬁeld variability is now a widely accepted and reported phenomenon by the precision
agriculture community [1,2]. Geolocalized data are effectively collected intensively within the ﬁelds
by sensors embedded on agricultural machinery, satellites, ﬂying platforms, static stations, or humans
among others, to make sure that this variability is considered and accounted for [3–5]. Spatial data have
particular characteristics that are worth careful consideration during analysis. First of all, their spatial
resolution (density) is of interest as it deﬁnes the capacity to identify short- and long-scale spatial
variability [6,7]. Spatial records are often associated with a high-level of noise that originates from
multiple reasons, such as the plant to plant variability, the accuracy of the sensor or the conditions
Agriculture 2018, 8, 73; doi:10.3390/agriculture8060073
www.mdpi.com/journal/agriculture
Agriculture 2018, 8, 73
2 of 21
of data acquisition [8]. Except for images in which data are regularly distributed on a grid of pixels,
many spatial observations collected in agriculture are irregular and do not follow a ﬁxed pattern
within the ﬁelds [9]. This feature is of great concern because many image-processing based algorithms
cannot be directly used on these irregular data.
To beneﬁt from this increasing ﬂow of data, users should be provided with software or tools that
allow them to:
(i)
visualize the data they have collected (simple or low-level functions),
(ii)
process these data (advanced or high-level functions), and
(iii) incorporate the knowledge they have on these data into the data processing.
It is acknowledged that basic visualization tools, e.g., data import, georeferencing, data display,
are available in many general (e.g., Quantum geographic information systems (QGIS), gvSIG,
Google Earth, Whitebow Geospatial Analysis Tools) and more speciﬁc [10,11] open-source platforms,
including those not speciﬁc to agricultural applications. It is clear that such functionalities are of major
importance to start handling spatial data. However, when it comes to making informed management
decisions, these visualization functions are not sufﬁcient. It is necessary to provide users with more
advanced or high-level functions so that they can turn this raw spatial data into information and
decision layers. Most commonly required procedures in the precision agriculture domain are functions
such as:
(i)
ﬁltering, to ensure the quality of the datasets [12,13],
(ii)
interpolation, to provide a continuous mapping of the property of interest [14–16],
(iii) zoning, to deﬁne within-ﬁeld zones for site-speciﬁc management [17,18], or
(iv) aggregation so that multiple layers of information can be combined [19,20].
To foster the adoption of such tools, all the aforementioned functions have to be speciﬁcally
dedicated to the processing of agricultural data from potentially very differing productions systems.
This is an important consideration as these data come with a lot of associated knowledge that has
to be considered when processing these data. More speciﬁcally, a lot of local expertise to support
decision-making might be available as users, e.g., farmers, advisors and/or technicians, have normally
been scouting the ﬁelds during all the growing season [21–23]. Site-speciﬁc management also requires
the use of agricultural machinery with speciﬁc characteristics that have to be considered in these
processing functions. This is to ensure that planned differential management is in accordance with
the practical and operational limitations of machinery e.g., working width, lag time and application
speed [24,25].
From a general perspective, there are only a few dedicated software programs available to
explicitly process precision agriculture data and incorporate expert knowledge into the process.
Moreover, very few of them are open-source. Some free- or share-ware tools have been developed and
proposed by the precision agriculture community, but these generally focus on speciﬁc processing tasks
or on a particular type of data. For example, the Vesper program [26], developed by the University
of Sydney, provides users with a graphical interface to spatially interpolate their data. Despite the
quite advanced functions that are available, e.g., local punctual and block kriging, users only end
up with a continuous map of their data without much more practical information. The Yield Editor
software from the United States Department of Agriculture [13,27] deals effectively with the ﬁltering
of within-ﬁeld yield datasets that are known to contain a lot of defective observations [28], but it does
not perform interpolation or other high-level functions. Another interesting example is a QGIS plugin
that was put into place to process spatial data of vine shoot diameter arising from the mounted sensor
Physiocap® (E.RE.C.A, Vaulx-en-Velin, France). This tool mainly incorporates functions to ﬁlter these
highly noisy datasets. Other platforms have been proposed by agronomist to give farmers access to
crop models but are very speciﬁc in terms of crop, data and use [29]. An open source platform that
takes raw data through to a decision point is not available to the precision agriculture community yet.
Agriculture 2018, 8, 73
3 of 21
The aim of the paper is to present the GeoFIS software (https://www.geoﬁs.org/) that was
developed by a joined team from IRSTEA, INRA and Montpellier SupAgro in France [30]. The goal
of this platform is to provide users with up-to-date and reliable algorithms to process their precision
agriculture data and incorporate expert knowledge from the ﬁelds. GeoFIS has been mainly developed
for academic and research purposes, i.e., investigators and students willing to process their data,
but also to a lesser extent for agronomists and advisors with a sufﬁcient background in spatial
analysis. The objective of this interface-based platform is to support users that do not necessarily
have programming skills and to show that high level functions can be introduced in a GIS and could
be integrated within precision agriculture programs. The ﬁrst section introduces this open-source
tool along with its architecture, design, interface, and main processing functions. Three different
case studies on various crops are then considered to evaluate the ability of this software to answer
most of the issues that are faced by the agricultural sector for processing their spatial data. The last
section highlights the needs for future developments to promote precision agriculture adoption and
the possibility to create connections with existing GIS software programs.
2. The GeoFIS Software
2.1. Aim of the GeoFIS Project
GeoFIS has been designed to facilitate the movement from spatial data to spatial information,
and to spatial decision-making. It is an open-source program that proposes a simple and easy to
use interface to build decision support systems (DSS) from spatial data [30]. While its development
has been inspired by agri-environmental applications, the framework itself is open and accessible
to applications in other domains. It is designed to be adaptable to different usages and for different
end-users, mostly for academic and research applications, for student and teaching applications and,
to a lesser extent, for GIS-skilled agronomists and advisors.
GeoFIS deviates from other GIS software, e.g., QGIS, in the sense that speciﬁc tools have been
implemented to answer the main expectations of agricultural professionals when it comes to processing
precision agriculture data. These will be presented later on. It is acknowledged that multiple other
open-sources spatial programs (e.g., QGIS) or languages (e.g., R and Python) are available to process
spatial and temporal data. However, these open-source tools do not have speciﬁc functions dedicated
to the processing of precision agriculture data (as listed in the introduction section) and usually
require users to have skills in programming. This is a major limiting factor for the practical use
of spatial modelling in agriculture. Another strength of GeoFIS is that attention has been paid to
the incorporation of expert knowledge into the data analysis. This is not available in other related
spatial processing tools. Agricultural professionals have a lot of local expert knowledge on their
production system that needs to be taken into account. By incorporating this qualitative expert
knowledge, the quality of the processing should be improved and the adoption of precision agriculture
technologies should be enhanced.
2.2. Architecture and Design of GeoFIS
In the proposed GeoFIS architecture, all the open-source toolboxes and libraries have been selected
for their ability to handle spatial data and to incorporate expert knowledge (Figure 1). Statistical and
geostatistical functions dedicated to precision agriculture data (see Section 2.3) are implemented in R
(https://www.r-project.org). Outside these speciﬁc functions, spatial data are handled through two
open-source libraries, i.e., Geotools (http://www.geotools.org) and CGAL (Computational Geometry
Algorithms Library, https://www.cgal.org). Geotools is used because its java implementation allows
the design of user-friendly interfaces. CGAL was chosen for its ability to provide very efﬁcient and
reliable geometric algorithms, as its functions are developed in C++. Finally, the incorporation of
expert knowledge is made possible with FisPro (https://www.ﬁspro.org), a system that uses fuzzy
sets for conceptual modeling [30].
Agriculture 2018, 8, 73
4 of 21
GeoFIS is available in four languages (French, English, Spanish and Portuguese). The interface
is designed with a man-machine cooperation objective. The goal is to facilitate the relationships
between data, learning algorithms and expert knowledge. Documentation, scientiﬁc papers, and video
tutorials are available to better understand the implemented function and to facilitate the adoption of
the GeoFIS software (https://www.geoﬁs.org/). Notiﬁcations are made when a new version of the
software is available.
Agriculture 2018, 8, x FOR PEER REVIEW  
4 of 21 
 
video tutorials are available to better understand the implemented function and to facilitate the 
adoption of the GeoFIS software (https://www.geofis.org/). Notifications are made when a new 
version of the software is available. 
 
Figure 1. The GeoFIS architecture [30]. CGAL, Computational Geometry Algorithms Library; DSS, 
Decision Support Systems; GIS, Geographic Information System; 1D, One dimension. 
2.3. Functionalities Implemented in GeoFIS 
GeoFIS contains a series of low and high-level non-spatial and spatial functionalities to 
interrogate spatial data. The general functionalities are introduced here and then expanded in several 
case studies in the following section. Figure 2 shows the generic flow required in precision 
agriculture, from raw data processing to decision-making, with the functionalities within GeoFIS at 
each stage indicated. In agricultural systems, data are available in different formats (points, polygons, 
rasters) and at different scales. The quality of the data is also variable, with some sensors being 
inherently noisy and others less so. Different data need potentially different approaches to (i) data 
validation and clean-up (quality control), (ii) data display (visualization) and when necessary for (iii) 
interpolation. These steps transform data into information layers. Within GeoFIS, data can be easily 
imported (Step 0) and displayed as a map (in its geographical space) and as a histogram (in its 
attribute space). This allows the user to ‘expertly’ identify global outliers in both the geographical 
and attribute space and remove any erroneous data (Step 1). Interpolation is possible using inverse 
distance weighting (for small data sets) and via punctual kriging with a global variogram for larger 
data sets (>100 points). The kriging method includes the ability to plot the experimental variogram 
and specify a theoretical variogram, which is then passed to the kriging function. Interpolated 
outputs can be directly displayed as rasters within the display (Step 2). 
‘Precision Agriculture’ or ‘Smart Agriculture’ is only effective when effective decisions are 
made. End-users can transform these information layers into decision layers to improve the 
management of their fields. Three main functionalities for management (practical) applications have 
been incorporated within GeoFIS to address this. Firstly, practitioners are provided with a method to 
delineate within-field homogeneous zones (Step 3.1). Zoning is of importance for precision 
agriculture data as the identified zones will (i) facilitate spatial data visualization and interpretation, 
and (ii) provide a spatial resolution that is practical and effective for many differential field 
operations. GeoFIS uses a segmentation algorithm to ‘zone’ data layers [18]. The segmentation 
Figure 1.
The GeoFIS architecture [30].
CGAL, Computational Geometry Algorithms Library;
DSS, Decision Support Systems; GIS, Geographic Information System; 1D, One dimension.
2.3. Functionalities Implemented in GeoFIS
GeoFIS contains a series of low and high-level non-spatial and spatial functionalities to interrogate
spatial data. The general functionalities are introduced here and then expanded in several case studies
in the following section. Figure 2 shows the generic ﬂow required in precision agriculture, from raw
data processing to decision-making, with the functionalities within GeoFIS at each stage indicated.
In agricultural systems, data are available in different formats (points, polygons, rasters) and at
different scales. The quality of the data is also variable, with some sensors being inherently noisy and
others less so. Different data need potentially different approaches to (i) data validation and clean-up
(quality control); (ii) data display (visualization) and when necessary for (iii) interpolation. These steps
transform data into information layers. Within GeoFIS, data can be easily imported (Step 0) and
displayed as a map (in its geographical space) and as a histogram (in its attribute space). This allows
the user to ‘expertly’ identify global outliers in both the geographical and attribute space and remove
any erroneous data (Step 1). Interpolation is possible using inverse distance weighting (for small data
sets) and via punctual kriging with a global variogram for larger data sets (>100 points). The kriging
method includes the ability to plot the experimental variogram and specify a theoretical variogram,
which is then passed to the kriging function. Interpolated outputs can be directly displayed as rasters
within the display (Step 2).
‘Precision Agriculture’ or ‘Smart Agriculture’ is only effective when effective decisions are made.
End-users can transform these information layers into decision layers to improve the management of
their ﬁelds. Three main functionalities for management (practical) applications have been incorporated
within GeoFIS to address this. Firstly, practitioners are provided with a method to delineate within-ﬁeld
homogeneous zones (Step 3.1). Zoning is of importance for precision agriculture data as the identiﬁed
zones will (i) facilitate spatial data visualization and interpretation; and (ii) provide a spatial resolution
Agriculture 2018, 8, 73
5 of 21
that is practical and effective for many differential ﬁeld operations. GeoFIS uses a segmentation
algorithm to ‘zone’ data layers [18]. The segmentation algorithm operates either on irregular or
gridded (interpolated) data to generate potential management zones.
Secondly, while data/information collection tends to be focused around production issues, there is
no restriction on its use. It can equally be used for strategic as well as tactical decision making.
The example of the technical opportunity index (TOI) [31], which is implemented in GeoFIS, is a case
in point. The TOI uses the production data to assess a ﬁeld’s suitability for site-speciﬁc management
given machinery constraints and the observed production variation (Step 3.2). The algorithm processes
the within ﬁeld data with a mathematical morphological ﬁlter based on erosions and dilations [31].
This ﬁlter allows end-users to account for the passes of the agricultural machinery in the ﬁeld and
especially the minimum area (kernel) within which it can operate reliably. As the algorithm requires
the data to be organized regularly on a grid, interpolating the data might therefore be required as a
pre-processing step (Step 2).
Agriculture 2018, 8, x FOR PEER REVIEW  
5 of 21 
 
algorithm operates either on irregular or gridded (interpolated) data to generate potential 
management zones. 
Secondly, while data/information collection tends to be focused around production issues, there 
is no restriction on its use. It can equally be used for strategic as well as tactical decision making. The 
example of the technical opportunity index (TOI) [31], which is implemented in GeoFIS, is a case in 
point. The TOI uses the production data to assess a field’s suitability for site-specific management 
given machinery constraints and the observed production variation (Step 3.2). The algorithm 
processes the within field data with a mathematical morphological filter based on erosions and 
dilations [31]. This filter allows end-users to account for the passes of the agricultural machinery in 
the field and especially the minimum area (kernel) within which it can operate reliably. As the 
algorithm requires the data to be organized regularly on a grid, interpolating the data might therefore 
be required as a pre-processing step (Step 2). 
 
Figure 2. Generic flow of data in precision agriculture with main processing steps from raw data 
processing to decision-making. 
Finally, in the majority of cases, practical agronomic decisions are multi-variate in nature. 
Decision support therefore requires dedicated data fusion methods to merge multiple information 
layers into a single decision layer (Step 3.3). For instance, when available, historical yield data (high 
spatial resolution point information), as-applied historical fertilizer maps (polygon data), recent point 
soil testing (low spatial resolution point data) and early season satellite imagery (high resolution 
raster) should collectively feed into a decision on mid-season spatial fertilizer inputs, i.e., a 
prescription fertilizer map (normally a polygon layer). In the previous example, the prescription 
fertilization map (the decision layer) is based on a set of inputs (information layers) that are all related 
through expert rules. An example of a possible expert rule could be that if, on a given location in 
space, the observed yield is high and the soil fertilizer level is low, then it might be relevant to apply 
more fertilizer inputs. Within GeoFIS, the goal of the data aggregation process is to implement the 
expert rules so that the final spatial decision layer (that answers the question: how much fertilizer 
input should be applied at this particular place at this particular time?) can be obtained. Expert rules 
are implemented one at a time as each rule leads to a practical agronomic decision.  
Data aggregation in GeoFIS is a two-step process. First, each information layer is transformed 
into an expert layer, i.e., the numerical agronomic values in each information layer are transformed 
into degree values (from 0 to 1) according to the expert rule to be implemented. The transformation 
from an information layer to an expert layer is done using a fuzzy set-based function [32]. Secondly, 
Figure 2. Generic ﬂow of data in precision agriculture with main processing steps from raw data
processing to decision-making.
Finally, in the majority of cases, practical agronomic decisions are multi-variate in nature.
Decision support therefore requires dedicated data fusion methods to merge multiple information
layers into a single decision layer (Step 3.3). For instance, when available, historical yield data
(high spatial resolution point information), as-applied historical fertilizer maps (polygon data),
recent point soil testing (low spatial resolution point data) and early season satellite imagery
(high resolution raster) should collectively feed into a decision on mid-season spatial fertilizer inputs,
i.e., a prescription fertilizer map (normally a polygon layer). In the previous example, the prescription
fertilization map (the decision layer) is based on a set of inputs (information layers) that are all related
through expert rules. An example of a possible expert rule could be that if, on a given location in
space, the observed yield is high and the soil fertilizer level is low, then it might be relevant to apply
more fertilizer inputs. Within GeoFIS, the goal of the data aggregation process is to implement the
expert rules so that the ﬁnal spatial decision layer (that answers the question: how much fertilizer
input should be applied at this particular place at this particular time?) can be obtained. Expert rules
are implemented one at a time as each rule leads to a practical agronomic decision.
Data aggregation in GeoFIS is a two-step process. First, each information layer is transformed into
an expert layer, i.e., the numerical agronomic values in each information layer are transformed into
Agriculture 2018, 8, 73
6 of 21
degree values (from 0 to 1) according to the expert rule to be implemented. The transformation from
an information layer to an expert layer is done using a fuzzy set-based function [32]. Secondly, all the
expert layers are combined using an aggregation operator to respect the expert rules. Two aggregation
operators are currently implemented in GeoFIS. The ﬁrst operator is the Weighted Arithmetic Mean
(WAM), which attributes a weight to each information source, e.g., the yield information layer may
be given twice as much weight as the soil fertilizer level layer. The second operator is the Ordered
Weighted Average (OWA) [33], where the weighing is slightly more complex. For a given location
in space, the degree values associated with each layer involved in the expert rule are ordered and
the weights assigned to each layer will depend on their position in this ordering. This operator is of
interest as it enables the implementation of logical operations, such as:
-
“OR”, where the expert rule applies as soon as the highest degree associated with the layers is
high, and
-
“AND”, where the expert rule applies as soon as one of the degrees associated with the layers
is high.
The result of the aggregation process is a single decision layer. The uniqueness of the GeoFIS
approach is in its ability to incorporate the expert knowledge developed by farmers and advisors
on the data and their ﬁelds directly into the data fusion process. The implemented data aggregation
methods require the data to be collocated, either on irregular or regular grids.
3. Case Studies
The previous section introduced the GeoFIS framework, introducing the functionalities
implemented and how they could be adapted to the individual needs of each end-user (who will
have their own unique constraints on management). The following sections provide more detailed
illustrations on the main processing steps in the context of precision agriculture applications.
More speciﬁcally, the three cases deal with the typical tasks that advisors and farmers may face
in their daily job:
(i)
the mapping of spatial data (Steps 0, 1 and 2),
(ii)
the evaluation and cross-comparison of the opportunity for site-speciﬁc management in their
ﬁelds (Step 3.2), and
(iii) the delineation of within-ﬁeld zones for variable-rate applications where zoning is considered
opportune (Steps 3.1 and 3.3).
Steps 0 to 2 will be exempliﬁed through medium spatial resolution manual measurements
performed over a banana ﬁeld to map the plant vigor. High resolution yield data across several
wheat ﬁelds will be used to illustrate the value of Step 3.2 to rank the ﬁelds from the most to the
less suitable for site-speciﬁc management. Step 3.1 and 3.3 will be applied on a precision viticulture
example aimed at deﬁning zones for differential irrigation management. The overall objective is to
demonstrate how GeoFIS has the ability to address the main issues of data processing in precision
agriculture. As the three case studies are performed on different crops (banana, wheat and grapevines),
each exhibiting unique characteristics, the applicability and genericity of this open-source software
will also be demonstrated. The three case studies are detailed in the next three sections.
3.1. Case Study 1: Mapping the Spatial Organization in the Data—An Example of the Vegetative Response of
an Asynchronous Plant, the Banana
3.1.1. Rationale and Description
Variography and mapping are two very important processing steps in the precision agriculture
domain. The former helps evaluate the spatial structure in the data by quantifying the proportions of
(i) spatially-structured variability or large-scale variations and (ii) spatially unstructured variability or
Agriculture 2018, 8, 73
7 of 21
small-scale variations within the ﬁeld. The latter is mainly used to the correct display of the observed
spatial variability and facilitate the process of decision-making.
In this case study, GeoFIS was used to investigate and map the spatial variability in the
pseudostem (trunk) circumference of banana crops. The proposed analysis was carried out on
this crop for two major reasons. First of all, the spatial variability in the agronomic properties of
banana crops has been poorly reported in the literature [34]. Secondly, this crop is known to be
asynchronous in its production cycle, which means that spatial analyses are to be handled differently
from what is commonly done in annual crops, e.g., wheat, canola, or perennial ones, e.g., vineyards [34].
The proposed analysis (i) estimates the proportion of spatially-structured variability in pseudostem
circumferences, i.e., the proportion of variance that is mainly due to spatially-structured environmental
properties [15]; (ii) determines the proportion of spatially unstructured variability that is due to
non-spatially structured phenomena e.g., the inter-plant variability, plant competition, replanting,
and measurement accuracy among others; and (iii) maps the overall within-ﬁeld variability of trunk
circumference in the plantation.
The plot under study is situated in a commercial banana plantation in Njombe, Cameroon (WGS84:
E: 4.612, N: 9.639) in its 15th ﬂowering cycle. The pseudostem circumference measurements were only
taken on plants where vegetative growth had ceased, i.e., plants that were either ﬂowering or at a
later phenological stage. There were 551 measurements taken using a tape measure at 1-m height and
georeferenced with a trail type hand-held GPS (Table 1). The proposed analysis in GeoFIS consisted of
the following steps: (i) the dataset was imported within GeoFIS (Step 0); (ii) pseudostem circumference
values were filtered to ensure the quality of the dataset (Step 1); (iii) variograms were fitted to the filtered
datasets and interpolation was performed using kriging with a local neighborhood onto a 1 × 1 m grid.
Table 1. Description of the plot under investigation.
Surface (ha)
Total Number of Plants
Observations
Number of Plants that Have Reached at
Least the Flowering Stage
Trunk Circumference (cm)
Mean
Variance
0.85
1287
551
74.7
69.7
3.1.2. Application in GeoFIS
The global distribution of the data was ﬁltered within GeoFIS (Figure 3). Users can select the
attribute to be ﬁltered at the top of the window. Below the histogram, two threshold values that
represent the two tails of the distribution can be changed, by either typing speciﬁc values or moving a
slide bar. Observations outside these thresholds are then removed from the dataset. Note that there
were two low values in this data set that were considered outside the normal distribution by the user
(Figure 3). The lower threshold allowed the user to eliminate these non-compliant values.
The spatial structure of the data can then be evaluated by plotting an experimental variogram,
here using the within-ﬁeld pseudostem circumferences. The number of lags and the maximum
lag distance can be set in the left-hand corner of the window to make sure that the variogram is
relevant. The interface (Figure 4) enables the user to specify and ﬁt a theoretical variogram model
to the experimental variogram. A theoretical variogram is automatically ﬁtted after which users can
interactively change the values of the variogram parameters, i.e., nugget, partial sill and range to
improve the ﬁt. The quality of the ﬁt can be assessed with the root mean square error (RMSE) value
that is detailed in the top right-hand corner of the interface. The theoretical model can then be saved
and used later to perform interpolation by kriging.
Agriculture 2018, 8, 73
8 of 21
Agriculture 2018, 8, x FOR PEER REVIEW  
8 of 21 
 
 
Figure 3. Filtering of the pseudostem circumference values based on distribution of response in the 
attribute space. 
The spatial structure of the data can then be evaluated by plotting an experimental variogram, 
here using the within-field pseudostem circumferences. The number of lags and the maximum lag 
distance can be set in the left-hand corner of the window to make sure that the variogram is relevant. 
The interface (Figure 4) enables the user to specify and fit a theoretical variogram model to the 
experimental variogram. A theoretical variogram is automatically fitted after which users can 
interactively change the values of the variogram parameters, i.e., nugget, partial sill and range to 
improve the fit. The quality of the fit can be assessed with the root mean square error (RMSE) value 
that is detailed in the top right-hand corner of the interface. The theoretical model can then be saved 
and used later to perform interpolation by kriging. 
 
Figure 4. Screenshot from GeoFIS illustrating the calculation of the experimental variogram and the 
fitting of a theoretical variogram model to the within-field pseudostem circumference spatial data. 
Figure 3. Filtering of the pseudostem circumference values based on distribution of response in the
attribute space.
 
 
Figure 3. Filtering of the pseudostem circumference values based on distribution of response in the 
attribute space. 
The spatial structure of the data can then be evaluated by plotting an experimental variogram, 
here using the within-field pseudostem circumferences. The number of lags and the maximum lag 
distance can be set in the left-hand corner of the window to make sure that the variogram is relevant. 
The interface (Figure 4) enables the user to specify and fit a theoretical variogram model to the 
experimental variogram. A theoretical variogram is automatically fitted after which users can 
interactively change the values of the variogram parameters, i.e., nugget, partial sill and range to 
improve the fit. The quality of the fit can be assessed with the root mean square error (RMSE) value 
that is detailed in the top right-hand corner of the interface. The theoretical model can then be saved 
and used later to perform interpolation by kriging. 
 
Figure 4. Screenshot from GeoFIS illustrating the calculation of the experimental variogram and the 
fitting of a theoretical variogram model to the within-field pseudostem circumference spatial data. 
Figure 4. Screenshot from GeoFIS illustrating the calculation of the experimental variogram and the
ﬁtting of a theoretical variogram model to the within-ﬁeld pseudostem circumference spatial data.
3.1.3. Results and Discussion
The spatial locations of the measurements are displayed in Figure 5. It clearly shows that the
spatial observations are irregularly-spaced within the plot. This aspect can be simply explained by
the fact that not all the banana plants had reached the ﬂowering phenological stage (only 551 out
of the 1287 plants had). In the plot under study, the pseudostem circumference exhibits a quite
strong spatial autocorrelation, the ratio of autocorrelated variance being close to 55% (Table 2).
Agriculture 2018, 8, 73
9 of 21
This ﬁnding demonstrates that spatially-structured environmental properties, e.g., soil physical and
chemical characteristics, are likely in this case to exert a relatively strong inﬂuence on the pseudostem
circumference of the banana plants. The determination of the factors affecting the pseudostem
circumference is beyond the scope of this study. Further analyses, e.g., soil and plant records, might help
to answer this question.
 
3.1.3. Results and Discussion 
The spatial locations of the measurements are displayed in Figure 5. It clearly shows that the 
spatial observations are irregularly-spaced within the plot. This aspect can be simply explained by 
the fact that not all the banana plants had reached the flowering phenological stage (only 551 out of 
the 1287 plants had). In the plot under study, the pseudostem circumference exhibits a quite strong 
spatial autocorrelation, the ratio of autocorrelated variance being close to 55% (Table 2). This finding 
demonstrates that spatially-structured environmental properties, e.g., soil physical and chemical 
characteristics, are likely in this case to exert a relatively strong influence on the pseudostem 
circumference of the banana plants. The determination of the factors affecting the pseudostem 
circumference is beyond the scope of this study. Further analyses, e.g., soil and plant records, might 
help to answer this question. 
 
Figure 5. Spatial measurements of pseudostem circumference divided in 5 quantiles within the plot 
under study. 
Table 2 also shows that the proportion of spatially unstructured variability (C0) is not negligible. 
In this case study, it can be mainly explained by (i) the inherent within-plant variability that might 
be exacerbated by competition amongst neighbors, and (ii) the accuracy of the measurements which 
might be affected by Global Navigation Satellite Systems (GNSS) accuracy issues or operator errors. 
Table 2. Spatial statistics of pseudostem circumference in the plot under investigation. 
Nugget Variance 
(C0) 
Partial-Sill 
Variance (C1) 
Sill Variance (C0 + C1) 
Ratio of Autocorrelated Variance 
(C1/C0 + C1) 
35.2 
43.4 
78.6 
55.2% 
Figure 6 provides a surface (map) of the within-field pseudostem circumference after 
interpolation (ordinary kriging). This smooths the data in Figure 5 using information on spatial 
variability contained in the same data. The circumferences appear to be much lower (less than 70 cm) 
in the northern-eastern and in the southern portions of the plots. The larger pseudostems, those for 
which the circumference exceeded 87 cm, can be mainly found in the northern-part of the field. Some 
local effects, e.g., small sites of low circumference surrounded by high pseudostem circumferences, 
are also visible on the maps. Those might be explained by several phenomena having a localized 
effect on plants, such as pest damage or replanting. It is worth recalling that this final map is not a 
Figure 5. Spatial measurements of pseudostem circumference divided in 5 quantiles within the plot
under study.
Table 2 also shows that the proportion of spatially unstructured variability (C0) is not negligible.
In this case study, it can be mainly explained by (i) the inherent within-plant variability that might
be exacerbated by competition amongst neighbors, and (ii) the accuracy of the measurements which
might be affected by Global Navigation Satellite Systems (GNSS) accuracy issues or operator errors.
Table 2. Spatial statistics of pseudostem circumference in the plot under investigation.
Nugget Variance (C0)
Partial-Sill Variance (C1)
Sill Variance (C0 + C1)
Ratio of Autocorrelated Variance
(C1/C0 + C1)
35.2
43.4
78.6
55.2%
Figure 6 provides a surface (map) of the within-ﬁeld pseudostem circumference after interpolation
(ordinary kriging). This smooths the data in Figure 5 using information on spatial variability contained
in the same data. The circumferences appear to be much lower (less than 70 cm) in the northern-eastern
and in the southern portions of the plots. The larger pseudostems, those for which the circumference
exceeded 87 cm, can be mainly found in the northern-part of the ﬁeld. Some local effects, e.g., small sites
of low circumference surrounded by high pseudostem circumferences, are also visible on the maps.
Those might be explained by several phenomena having a localized effect on plants, such as pest
damage or replanting. It is worth recalling that this ﬁnal map is not a map of circumferences of all
pseudostems, but rather a map of potential circumference at ﬂowering as not all the banana plants have
reached the ﬂowering stage. This map is an alternative representation of the information displayed
in Figure 5 and provides predictions for plants that were not measured in the original survey. As for
Figure 6, this map may be very useful in locating sampling sites to perform further soil and or plant
analyses and to better characterize the within-ﬁeld pseudostem circumference variability. It has the
Agriculture 2018, 8, 73
10 of 21
advantage over the raw data plot (Figure 5) of being easier for the human eye to interpret the main
patterns in the ﬁeld.
 
map of circumferences of all pseudostems, but rather a map of potential circumference at flowering 
as not all the banana plants have reached the flowering stage. This map is an alternative 
representation of the information displayed in Figure 5 and provides predictions for plants that were 
not measured in the original survey. As for Figure 6, this map may be very useful in locating sampling 
sites to perform further soil and or plant analyses and to better characterize the within-field 
pseudostem circumference variability. It has the advantage over the raw data plot (Figure 5) of being 
easier for the human eye to interpret the main patterns in the field.  
 
Figure 6. Kriged map of the potential pseudostem circumference within the field under study. The 
map represents a potential rather than an exhaustive analysis of plants because not all the plants have 
reached the flowering stage. 
GeoFIS proved to be a relevant tool to model the spatial variability in the banana pseudostem 
circumference data and for continuous mapping of this property of interest. However, a couple of 
limitations are worth discussing. Firstly, even if the filtering interface is user-friendly, it only provides 
a global filtering of the data. Only the tails of the distribution can be trimmed. It may have been that 
spatial data not only exhibit global but also local outliers. This was not a problem here but removing 
local outliers would be a useful function in the software program. When present, local outliers 
(inliers) will affect the quality of interpolation procedures. Secondly, GeoFIS does not yet allow the 
fitting of nested variogram models. This was a potential issue in this case study. In Figure 4, it could 
be argued that there is a short-range spatial structure within the first 10 m and a second spatial 
structure from 10 to 30 m (with a longer range). Nested spatial structures are not common but do 
occur in agricultural data. Thirdly, regarding the continuous mapping of the data, GeoFIS only 
provides a kriged map of the property of interest. The mean estimates are given but the error (kriging 
variance) associated with these estimates is not provided. This is a potential limitation for assessing 
the mapping accuracy and for interpreting uncertainty in future analyses with the interpolated data. 
3.2. Case Study 2: Evaluating and Comparing the Opportunity for Site-Specific Management within Fields 
3.2.1. Rationale and Description 
Site-specific management requires a strong investment in time, money and technical skills for 
growers. This investment requires certain conditions to be met. Firstly, the within-field variability 
has to be strong enough to justify differentiate management. Secondly, this variability has to be 
spatially structured or organized enough within the field to be able to be managed by agricultural 
Figure 6. Kriged map of the potential pseudostem circumference within the ﬁeld under study. The map
represents a potential rather than an exhaustive analysis of plants because not all the plants have
reached the ﬂowering stage.
GeoFIS proved to be a relevant tool to model the spatial variability in the banana pseudostem
circumference data and for continuous mapping of this property of interest. However, a couple of
limitations are worth discussing. Firstly, even if the ﬁltering interface is user-friendly, it only provides
a global ﬁltering of the data. Only the tails of the distribution can be trimmed. It may have been that
spatial data not only exhibit global but also local outliers. This was not a problem here but removing
local outliers would be a useful function in the software program. When present, local outliers (inliers)
will affect the quality of interpolation procedures. Secondly, GeoFIS does not yet allow the ﬁtting of
nested variogram models. This was a potential issue in this case study. In Figure 4, it could be argued
that there is a short-range spatial structure within the ﬁrst 10 m and a second spatial structure from 10
to 30 m (with a longer range). Nested spatial structures are not common but do occur in agricultural
data. Thirdly, regarding the continuous mapping of the data, GeoFIS only provides a kriged map of
the property of interest. The mean estimates are given but the error (kriging variance) associated with
these estimates is not provided. This is a potential limitation for assessing the mapping accuracy and
for interpreting uncertainty in future analyses with the interpolated data.
3.2. Case Study 2: Evaluating and Comparing the Opportunity for Site-Speciﬁc Management within Fields
3.2.1. Rationale and Description
Site-speciﬁc management requires a strong investment in time, money and technical skills for
growers. This investment requires certain conditions to be met. Firstly, the within-ﬁeld variability
has to be strong enough to justify differentiate management. Secondly, this variability has to be
spatially structured or organized enough within the ﬁeld to be able to be managed by agricultural
machinery [2]. Farmers, therefore, are in need of tools that will help them to evaluate this opportunity
for site-speciﬁc management. To make decisions at a larger level than the ﬁeld, i.e., the whole farm,
this opportunity also has to be cross-compared between ﬁelds. Farmers should preferentially commit
their efforts towards the ﬁelds that are the most opportune for site-speciﬁc management. These are
Agriculture 2018, 8, 73
11 of 21
most likely to have the largest returns on investment in agri-technology, which should minimize the
risk of investment for the farmer.
In this case study,
GeoFIS was used to evaluate and compare the opportunity for
adopting site-speciﬁc management across multiple ﬁelds using a deﬁned opportunity index [31].
Opportunity indices are a way of assessing if the amount and structure of variation in a ﬁeld makes
site-speciﬁc management a potentially feasible option [2,25]. Seven yield datasets arising from two
different farms located near Evreux, in the north-western part of France (Farm 1—WGS84: E: 0.779, N:
48.955; Farm 2—WGS84: E: 1.032, N: 48.828) were used. Fields were cropped in wheat and harvested
with various combines, primarily New Holland (Turin, Italy) and Claas (Harsewinkel, Germany)
combines. Yield datasets are considered particularly relevant for this case study because the yield
is directly related to the ﬁeld economic returns. Quantifying the amount and structure of yield
variance should therefore be a valuable indicator of whether site-speciﬁc management is opportune.
Structured spatial variation in yield would indicate a potential for structured spatial crop management,
particularly fertilizer and agri-chemicals.
This case study also demonstrates the use of GeoFIS with dense sensor-derived spatial
observations in contrast to the spatial manual measurements presented in Case Study 1. Yield data
are collected with on-board sensors at 1 Hz as the combine traverses the ﬁeld. These observations are
therefore irregularly-distributed in space because (i) the intra-row and inter-row distances are different
and (ii) the acquisition conditions, such as the GNSS accuracy or variable combine speed, can impact
the spatial distribution of the observations. The yield information is very dense (thousands of points
per hectare) and very noisy because of stochastic error in sensor operation, the intrinsic local variability
in production and errors associated with the combine harvester passing through the ﬁeld [13,28].
These seven ﬁelds were selected as they exhibit various degrees of yield autocorrelation within
the same systems (farms) and, as such, should represent a different opportunity for variable-rate
applications. Within this case-study, several functions of GeoFIS were used to arrive at a solution that
ranks and compares the seven ﬁelds in terms of a technical opportunity for site-speciﬁc management.
More speciﬁcally, (i) global outliers were ﬁltered out (Step 1); (ii) variograms were ﬁtted to the
previously ﬁltered yield datasets and ordinary kriging with a global variogram and local neighborhood
was performed onto a 3 × 3 m grid (Step 2); and (iii) the TOI was computed (see Section 2.3
Functionalities implemented in GeoFIS) (Step 3.2). To account for technical and operational constraints
during the TOI computation, the following operational characteristics were assumed: a working width
of 20 m, a mean speed of 3 m s−1 and a delay rate of change between two different treatments of 2 s.
This could be for instance the characteristics of a fertilizer spreader performing variate-rate application.
The major yield statistics of the seven ﬁelds under consideration after data clean-up are reported in
Table 3.
Table 3. Principal descriptive and spatial statistics of the seven yield datasets under consideration.
The nugget to sill ratio can be calculated after variograms are ﬁtted to the cleaned data in GeoFIS.
Field
Size (ha)
Mean (t ha−1)
CV (%)
Nugget to Sill Ratio (%)
1
8.9
8.3
8.7
53.8
2
12.9
7.0
24.6
46.3
3
8.9
7.8
11.6
36.0
4
11.2
6.1
9.1
37.5
5
18.1
7.1
14.5
22.4
6
24.1
9.6
15.9
19.9
7
32.5
9.5
15.4
15.1
3.2.2. Application in GeoFIS
The ﬁltering and interpolation procedures have already been detailed in Case Study 1 and will
not be discussed here. The technical opportunity index (TOI) can be computed in the Opportunity
Agriculture 2018, 8, 73
12 of 21
Index toolbar of the GeoFIS software. Figure 7 displays the window that appears when this menu
is selected. The window is composed of three main sections. In the top drop-down menu (Border),
users are asked to select the attribute on which the metric should be computed, e.g., yield, and to
provide the ﬁeld boundaries to make sure that the calculation of the TOI is restricted to the ﬁeld of
interest. Note that the boundary can be automatically derived with a convex hull, however this may
not be a good option for ﬁelds with an irregular geometric shape. In the second drop-down menu
(Machine Footprint) the technical and operational constraints of future site-speciﬁc management can
be speciﬁed. More speciﬁcally, users can provide the working width of machinery, its speed, the delay
in the rate of change between two levels of outputs (management strategies), and the uncertainty in
the GNSS positioning of the machine. The third drop-down menu (Interpolation) ensures that all
observations are reported on a ﬁxed grid and the TOI is calculated using the grid data. Users can select
the size of the interpolation grid along with the interpolation procedure, i.e., inverse distance weighing
or kriging. Note that both interpolation approaches need to be parametrized and some user input.
When all this information has been speciﬁed by a user, the TOI can be calculated. The window
displays two major outputs: (i) the TOI value associated with the data along with the corresponding
error rate of application; and (ii) the potential management zone map with the different strategies that
should be applied (in the case of Figure 7 there are two strategies presented). This latter map can be
exported and used in other GIS software if needed.
Agriculture 2018, 8, x FOR PEER REVIEW  
13 of 21 
 
Figure 7. Screenshot of output from the computation of the Technical Opportunity Index (TOI) in 
GeoFIS for Field 7. 
Figure 7. Screenshot of output from the computation of the Technical Opportunity Index (TOI) in
GeoFIS for Field 7.
3.2.3. Results and Discussion
Figure 8 shows the seven ﬁelds in the study ranked by their respective TOI values along with the
corresponding variable-rate application map for a two-management strategy. It clearly shows that
the ﬁelds have different levels of yield spatial structure, from the lowest for Field 1 to the strongest
Agriculture 2018, 8, 73
13 of 21
for Field 7. Note that, in this case study, the order of the TOI values is consistent with the order of
nugget to sill ratios (Table 3). The TOI values are however very close in absolute terms (Figure 8)
with a range from 0.888 to 0.965. As the TOI value can theoretically range from 0 to 1, all the ﬁelds
here are exhibiting high TOI values, indicating that a site-speciﬁc management is opportune for all
of these ﬁelds. All the maps have spatially-structured patterns, in accordance with the technical and
operational constraints of a future possible machine pass (Figure 8). These maps could be directly
incorporated into a machinery system to perform site-speciﬁc management.
 
 
Figure 7. Screenshot of output from the computation of the Technical Opportunity Index (TOI) in 
GeoFIS for Field 7. 
 
Agriculture 2018, 8, x FOR PEER REVIEW  
14 of 21 
 
Figure 8. Ranking of the seven yield datasets in terms of the associated TOI value: (a) Field 1; (b) Field 2; 
(c) Field 3; (d) Field 4; (e) Field 5; (f) Field 6; (g) Field 7. Cleaned yield values and corresponding 
potential variable application maps are also displayed for each field. TOI: technical opportunity index. 
The TOI is a valuable metric to evaluate and rank fields with respect to the opportunity for site-
specific management. GeoFIS is an interesting tool to perform this case study as all the steps required 
to compute the TOI can be performed within the program. Note that potential management zone 
maps are also provided and can be simply exported through the easy-to-use interface (however the 
target rates are not yet determined at this point—see case study 3). This should foster the adoption 
of precision agriculture technologies. Users must however be cautious when computing and 
interpreting the TOI as this metric is particularly sensitive to the interpolation of the cleaned data and 
the setting of the technical and operation constraints for site-specific management. Users should be 
able to perform a series of tests within GeoFIS to evaluate the impact of their parametrization on the 
TOI
l
d
T
hi
i
f
i l
Figure 8. Ranking of the seven yield datasets in terms of the associated TOI value: (a) Field 1; (b) Field 2;
(c) Field 3; (d) Field 4; (e) Field 5; (f) Field 6; (g) Field 7. Cleaned yield values and corresponding
potential variable application maps are also displayed for each ﬁeld. TOI: technical opportunity index.
The high TOI values for these ﬁelds is due to two principal reasons: (i) the data interpolation
and (ii) the operational constraints that were set. The computation of the TOI requires the data
to be regularly distributed over the ﬁeld, which is why a prior interpolation procedure is put into
Agriculture 2018, 8, 73
14 of 21
place. In this case study, the interpolation by kriging generated a relatively strong data smoothing
that artiﬁcially increased the TOI values as it is calculated on the interpolated data. Indeed, as the
small-scale variations are smoothed, the yield patterns appear much more organized in space and the
site-speciﬁc management is consequently considered more opportune. The settings of the operational
characteristics in these ﬁelds also facilitated high TOI values. As the minimal size of ﬁeld management
(working width of the machinery) decreases, the opportunity for variable-rate application will increase.
Smaller machinery means that smaller areas of spatial variation become potentially manageable.
In contrast, if ﬁeld management was done at a coarser level, e.g., the working width of the machinery
was set to 40 m, then the opportunity for site-speciﬁc management would decrease and there would
likely be larger differences amongst the seven ﬁelds under study (data not shown). As can be seen
in Figure 8, only two management strategies are proposed for each ﬁeld. Even if this two-class
categorization appears sufﬁcient in some case studies, the actual computation of the TOI at the moment
does not allow for alternative management strategies (three, four, . . . , etc. classes) to be simultaneously
considered. This aspect will be investigated in further studies.
The TOI is a valuable metric to evaluate and rank ﬁelds with respect to the opportunity for
site-speciﬁc management. GeoFIS is an interesting tool to perform this case study as all the steps
required to compute the TOI can be performed within the program. Note that potential management
zone maps are also provided and can be simply exported through the easy-to-use interface (however the
target rates are not yet determined at this point—see case study 3). This should foster the adoption of
precision agriculture technologies. Users must however be cautious when computing and interpreting
the TOI as this metric is particularly sensitive to the interpolation of the cleaned data and the setting of
the technical and operation constraints for site-speciﬁc management. Users should be able to perform
a series of tests within GeoFIS to evaluate the impact of their parametrization on the TOI values and
management zone maps. To cross-compare this opportunity for potential differentiate application
amongst ﬁelds, authors strongly advocate the application of the exact same process with similar
settings for the calculation of the ﬁnal TOI metric.
3.3. Case Study 3: Delineating within-Field Zones for Variable-Rate Applications Using Expert Knowledge
3.3.1. Rationale and Description
The delineation of within-ﬁeld zones is an important procedure in precision agriculture studies
because it enables, or at least facilitates, growers to perform variable-rate applications. The creation
of these zones is a complex process for multiple reasons: (i) there is a need to account for spatial
relationships in the data; (ii) very often multiple layers of spatial information must be combined;
and (iii) the decision rules associated with agronomic applications are complex and require the
grower’s knowledge to be involved in the processing. In this case study, GeoFIS will be used to
delineate within-ﬁeld zones prior to the management of irrigation and fertilization in a Spanish
vineyard using several layers of information and incorporating expert knowledge. This case study is an
extension of previous work [35]. Interested readers are referred to this document for more information.
The study was carried out on a 90-ha commercial vineyard containing 27 contiguous ﬁelds
(Figure 9) located in Southern Navarre, Spain (WGS84: E: 1.405, N: 42.254). The vine vigor, soil,
and water availability in the ﬁeld were considered to be of major interest by the vine manager to
manage irrigation and fertilization practices.
Vine vigor was estimated using the normalized difference vegetation index (NDVI) on a 3 × 3 m
raster layer derived from a Multi-spectral Airborne image acquired in August 2007 and provided
and processed by the Geosys-Spain Company (Leica ADS40 sensor). Measurements of soil apparent
electrical conductivity (ECa) on a 30 × 30 m grid (256 sampling points) were performed using a
handheld ground conductivity meter (EM38, Geonics Ltd., Mississauga, ON, Canada) to map soil
spatial variability. The same sample sites were used to create a digital terrain model from elevation data
obtained with a laser Tachymeter (TPS 1001, Leica, Heerbrugg, Switzerland). Both ECa and elevation
Agriculture 2018, 8, 73
15 of 21
data were kriged onto a 3 m grid. Additional monitoring was performed to provide more information
on the vine vigor, soil and water variation [35]. As these additional observations were more expensive
and/or cumbersome to collect, only 64 out of the 256 sampling sites were monitored. These monitoring
sites were selected using the high-resolution data layers. Additional observations were related to the
(i) soil, e.g., observation of soil pits; (ii) plant, e.g., plant water status, pruning weight of wood and
yield; and (iii) production, e.g., berry size, berry composition, yield characteristics. The analysis of all
these data layers led to an explanatory reasoning summarized as [35]:
•
Hydromorphic soils and wetlands are well deﬁned by the ECa information. Their presence is
mainly explained by variations in elevation,
•
Vine vegetative expression is too high (and harvest quality too low) on the zones at the highest
elevations, characterized by light and deep soils (low ECa values),
•
Vine vegetative expression is too weak on the zones at the lowest elevations, characterized by
clay soils, which suffer from waterlogging after rainfall events (high ECa values).
Agriculture 2018, 8, x FOR PEER REVIEW  
15 of 21 
 
Figure 9. Maps of the whole-vineyard showing the spatial variability in (a) elevation; (b) soil apparent 
conductivity (ECa); and (c) vegetative expression (normalized difference vegetation index (NDVI)). 
Points in (a,b) indicate sampling locations (n = 256) (reproduced with permission from Reference 35) 
[35]. 
Vine vigor was estimated using the normalized difference vegetation index (NDVI) on a 3 × 3 m 
raster layer derived from a Multi-spectral Airborne image acquired in August 2007 and provided and 
processed by the Geosys-Spain Company (Leica ADS40 sensor). Measurements of soil apparent 
electrical conductivity (ECa) on a 30 × 30 m grid (256 sampling points) were performed using a 
handheld ground conductivity meter (EM38, Geonics Ltd., Mississauga, ON, Canada) to map soil 
spatial variability. The same sample sites were used to create a digital terrain model from elevation 
data obtained with a laser Tachymeter (TPS 1001, Leica, Heerbrugg, Switzerland). Both ECa and 
elevation data were kriged onto a 3 m grid. Additional monitoring was performed to provide more 
information on the vine vigor, soil and water variation [35]. As these additional observations were 
more expensive and/or cumbersome to collect, only 64 out of the 256 sampling sites were monitored. 
These monitoring sites were selected using the high-resolution data layers. Additional observations 
were related to the (i) soil, e.g., observation of soil pits, (ii) plant, e.g., plant water status, pruning 
Figure 9. Maps of the whole-vineyard showing the spatial variability in (a) elevation; (b) soil apparent
conductivity (ECa); and (c) vegetative expression (normalized difference vegetation index (NDVI)).
Points in (a,b) indicate sampling locations (n = 256) (reproduced with permission from Reference 35) [35].
Based on this explanatory reasoning, the vineyard manager deﬁned several decision rules to
identify the situations in which the current management practices were sub-optimal regarding grape
quality and quantity at harvest. An example of one of these rules was:
If NDVI is high (>70) and ECa is low (<180 mS · m−1) and elevation is high (>360 m), then the
risk of having sub-optimal management practices is high.
This latter rule was modelled in GeoFIS to provide a map showing the risk of having sub-optimal
management practices within the vineyard. First, the three data layers involved in the expert rule
Agriculture 2018, 8, 73
16 of 21
were transformed into risk maps using risk functions (Step 3.3). The parametrization of these risk
functions was done with the vineyard manager. All the univariate risk maps were then combined into
a ﬁnal risk map using the OWA aggregator, which was again parametrized with the vineyard manager
(see Section 2.3 Functionalities implemented in GeoFIS) (Step 3.3). Finally, a segmentation algorithm
was applied to this last risk map to provide within-ﬁeld risk zones (Step 3.1).
3.3.2. Application in GeoFIS
This section will focus on the computation of the risk functions and on the zoning of the resulting
risk map. For each layer of information (ECa, NDVI, Elevation), risk functions can be deﬁned within
GeoFIS by implementing fuzzy rules as displayed in Figure 10. Here, a semi trapezoidal function
was used to model the risk of having sub-optimal practices by solely relying on the ECa layer. In this
interface, the form of the risk function can be changed along with the associated fuzzy parameters, i.e.,
the kernel and support. Once the risk functions have been set for all the layers of interest, all the risks
can be aggregated with respect to the aforementioned expert rule(s). This aggregation procedure can
be performed through the interfaces displayed in Figure 11 where (i) the layers can be selected and the
aggregation operator can be chosen (OWA aggregator here) and; (ii) the parameters associated to the
OWA aggregator can be stated.
 
identify the situations in which the current management practices were sub-optimal regarding grape 
quality and quantity at harvest. An example of one of these rules was:  
If NDVI is high (>70) and ECa is low (<180 mS m−1) and elevation is high (>360 m), then the risk 
of having sub-optimal management practices is high.  
This latter rule was modelled in GeoFIS to provide a map showing the risk of having sub-optimal 
management practices within the vineyard. First, the three data layers involved in the expert rule 
were transformed into risk maps using risk functions (Step 3.3). The parametrization of these risk 
functions was done with the vineyard manager. All the univariate risk maps were then combined 
into a final risk map using the OWA aggregator, which was again parametrized with the vineyard 
manager (see Section 2.3 Functionalities implemented in GeoFIS) (Step 3.3). Finally, a segmentation 
algorithm was applied to this last risk map to provide within-field risk zones (Step 3.1). 
3.3.2. Application in GeoFIS 
This section will focus on the computation of the risk functions and on the zoning of the resulting 
risk map. For each layer of information (ECa, NDVI, Elevation), risk functions can be defined within 
GeoFIS by implementing fuzzy rules as displayed in Figure 10. Here, a semi trapezoidal function was 
used to model the risk of having sub-optimal practices by solely relying on the ECa layer. In this 
interface, the form of the risk function can be changed along with the associated fuzzy parameters, 
i.e., the kernel and support. Once the risk functions have been set for all the layers of interest, all the 
risks can be aggregated with respect to the aforementioned expert rule(s). This aggregation procedure 
can be performed through the interfaces displayed in Figure 11 where (i) the layers can be selected 
and the aggregation operator can be chosen (OWA aggregator here) and, (ii) the parameters 
associated to the OWA aggregator can be stated. 
 
Figure 10. Implementation of the risk function associated with the ECa information layer. 
 
Figure 10. Implementation of the risk function associated with the ECa information layer.
 
quality and quantity at harvest. An example of one of these rules was:  
If NDVI is high (>70) and ECa is low (<180 mS m−1) and elevation is high (>360 m), then the risk 
of having sub-optimal management practices is high.  
This latter rule was modelled in GeoFIS to provide a map showing the risk of having sub-optimal 
management practices within the vineyard. First, the three data layers involved in the expert rule 
were transformed into risk maps using risk functions (Step 3.3). The parametrization of these risk 
functions was done with the vineyard manager. All the univariate risk maps were then combined 
into a final risk map using the OWA aggregator, which was again parametrized with the vineyard 
manager (see Section 2.3 Functionalities implemented in GeoFIS) (Step 3.3). Finally, a segmentation 
algorithm was applied to this last risk map to provide within-field risk zones (Step 3.1). 
3.3.2. Application in GeoFIS 
This section will focus on the computation of the risk functions and on the zoning of the resulting 
risk map. For each layer of information (ECa, NDVI, Elevation), risk functions can be defined within 
GeoFIS by implementing fuzzy rules as displayed in Figure 10. Here, a semi trapezoidal function was 
used to model the risk of having sub-optimal practices by solely relying on the ECa layer. In this 
interface, the form of the risk function can be changed along with the associated fuzzy parameters, 
i.e., the kernel and support. Once the risk functions have been set for all the layers of interest, all the 
risks can be aggregated with respect to the aforementioned expert rule(s). This aggregation procedure 
can be performed through the interfaces displayed in Figure 11 where (i) the layers can be selected 
and the aggregation operator can be chosen (OWA aggregator here) and, (ii) the parameters 
associated to the OWA aggregator can be stated. 
 
Figure 10. Implementation of the risk function associated with the ECa information layer. 
 
Figure 11. Parametrization of the Ordered Weighted Average (OWA) aggregator: (a) Selection of the
layers to be aggregated; (b) setting of the OWA aggregator parameters. The weights for the minimum,
medium and maximum values of univariate risk are respectively 0.7, 0.2 and 0.1.
Agriculture 2018, 8, 73
17 of 21
After the aggregation procedure has been run, practitioners end up with a continuous map of
the global risk of having sub-optimal practices within the vineyard. To facilitate the interpretation of
the map and the process of decision-making, the risk map can be zoned using the interface displayed
in Figure 12. Before zoning, users must (i) deﬁne the boundary of the map, either by importing a
predeﬁned boundary or by using a default convex hull algorithm (that is proposed in GeoFIS) to
generate a boundary and (ii) set the neighborhood associated to each spatial observation so that zones
can be expanded using spatial neighbors. The zoning procedure can then be applied to the OWA risk
map using the zoning algorithm implemented in GeoFIS [18]. Users can then display a risk map with
a number of zones that they consider relevant.
Agriculture 2018, 8, x FOR PEER REVIEW  
17 of 21 
 
Figure 11. Parametrization of the Ordered Weighted Average (OWA) aggregator: (a) Selection of the 
layers to be aggregated; (b) setting of the OWA aggregator parameters. The weights for the minimum, 
medium and maximum values of univariate risk are respectively 0.7, 0.2 and 0.1. 
After the aggregation procedure has been run, practitioners end up with a continuous map of 
the global risk of having sub-optimal practices within the vineyard. To facilitate the interpretation of 
the map and the process of decision-making, the risk map can be zoned using the interface displayed 
in Figure 12. Before zoning, users must (i) define the boundary of the map, either by importing a 
predefined boundary or by using a default convex hull algorithm (that is proposed in GeoFIS) to 
generate a boundary and (ii) set the neighborhood associated to each spatial observation so that zones 
can be expanded using spatial neighbors. The zoning procedure can then be applied to the OWA risk 
map using the zoning algorithm implemented in GeoFIS [18]. Users can then display a risk map with 
a number of zones that they consider relevant. 
 
Figure 12. Delimitation of within-field yield zones of the risk of having sub-optimal management 
practices. (Map details described in Figure 13). 
3.3.3. Results and Discussion 
The map of the risk of arriving at sub-optimal management practices using a combination of (i) 
available information and (ii) expert rules derived from local knowledge is displayed in Figure 13. 
This map shows five zones, three of which are relatively large, with specific risk levels. The highest-
risk area (dark red) is located on the western part of the vineyard and characterized by low ECa, high 
NDVI and high elevation (Figure 13). In this part of the vineyard, it is likely that current management 
practices are not well adapted as grape quality and quantity at harvest are not optimized in this area 
and “nitrogen applications should be avoided; water availability should be reduced by the 
introduction of a cover crop; and Regulated Deficit Irrigation strategies should held in order to 
moderate shoot growth and fertility” [35]. In order to simplify the presentation of this example, only 
Figure 12. Delimitation of within-ﬁeld yield zones of the risk of having sub-optimal management
practices. (Map details described in Figure 13).
3.3.3. Results and Discussion
The map of the risk of arriving at sub-optimal management practices using a combination of
(i) available information and (ii) expert rules derived from local knowledge is displayed in Figure 13.
This map shows ﬁve zones, three of which are relatively large, with speciﬁc risk levels. The highest-risk
area (dark red) is located on the western part of the vineyard and characterized by low ECa, high NDVI
and high elevation (Figure 13). In this part of the vineyard, it is likely that current management
practices are not well adapted as grape quality and quantity at harvest are not optimized in this area
and “nitrogen applications should be avoided; water availability should be reduced by the introduction
of a cover crop; and Regulated Deﬁcit Irrigation strategies should held in order to moderate shoot
growth and fertility” [35]. In order to simplify the presentation of this example, only one rule has
been taken into account. It would have been possible to introduce additional rules based on the work
presented in [35].
Agriculture 2018, 8, 73
18 of 21
It is interesting to note that the aggregation procedure though the OWA operator using the NDVI,
ECa, and elevation layers (Figure 13) has resulted in a risk map that is different from that which would
have been obtained by interpreting each layer of information independently (Figure 14). For instance,
if the ECa layer had only been used to generate the risk map, the highest-risk area would have covered
a much larger area of the vineyard.
Agriculture 2018, 8, x FOR PEER REVIEW  
18 of 21 
 
one rule has been taken into account. It would have been possible to introduce additional rules based 
on the work presented in [35].  
It is interesting to note that the aggregation procedure though the OWA operator using the 
NDVI, ECa, and elevation layers (Figure 13) has resulted in a risk map that is different from that which 
would have been obtained by interpreting each layer of information independently (Figure 14). For 
instance, if the ECa layer had only been used to generate the risk map, the highest-risk area would 
have covered a much larger area of the vineyard.  
 
Figure 13. Aggregated risk zones of sub-optimal management practices derived using the NDVI, ECa, 
and elevation layers together with local expert knowledge. 
This case study illustrates that the expertise of farm managers and advisors can be incorporated 
into a data-fusing algorithm to generate decision layers. Indeed, GeoFIS enables users to incorporate 
their own expertise, i.e., though the use of univariate risk functions/fuzzy rules, into the generation 
of risk maps. The use of fuzzy rules to account for this expertise is of interest as it makes it possible 
to avoid abrupt changes in risk and generates a more gradual variation in potential risk (Figure 10). 
The GeoFIS interface enables users to calibrate the risk and aggregation functions empirically by 
offering users the ability to test a calibration, visualize the resulting risk maps, and possibly adjust it 
to their convenience. However, it must be stated that this will require farmers and advisors to be 
supported so that their expertise can be translated correctly into the data aggregation algorithms.  
The calibration of the OWA index presented in this case study (weight of 0.7 for the minimum 
value of univariate risk, 0.2 for the median value, and 0.1 for the maximum value) resulted from an 
iterative calibration process lead by the vineyard manager. This aggregation setting has strong 
similarities with the logical operation “AND”, i.e., the resulting risk is high if the minimum value of 
univariate risk is also high because it has the strongest weight. In other words, all the univariate risks 
are high because the median and maximum values for a univariate risk are necessarily higher than 
the minimum value of the univariate risk. Note that the real logical operation “AND” would be 
reproduced by using the following set of weights (1;0;0). By changing these weights, practitioners 
might also be able to reproduce the logical operation “OR” (0;0;1) for which the resulting risk is high 
as soon as the maximum value of a univariate risk is high. It would also be possible to perform a 
simple average of the different univariate risks by using the same weights for each layer. 
Figure 13. Aggregated risk zones of sub-optimal management practices derived using the NDVI, ECa,
and elevation layers together with local expert knowledge.
Agriculture 2018, 8, x FOR PEER REVIEW  
19 of 21 
 
Figure 14. Maps of risk zones of sub-optimal management practices derived in the univariate space 
with variate specific local expert rules. ECa (left); NDVI (middle); and Elevation (right). 
From a more general perspective, GeoFIS simplifies the processing of the three layers of 
information as the entire process was done within a single software platform. It can be compared to 
the data processing in [35] in which data where cleaned with Excel, interpolated with Vesper, 
analyzed with Matlab and represented with ArcGIS.  
4. Conclusions 
The increasing flow of precision agriculture data requires the development of free and open 
source processing software to manage and make use of these data and promote precision agriculture 
adoption. As such, GeoFIS has been specifically designed to facilitate the movement from spatial data 
to spatial information and to spatial decision-making. The application of GeoFIS on some example 
case studies that agricultural professionals may face when dealing with spatial data has 
demonstrated the potential of this software. GeoFIS is a released product however it is important to 
state that all the functionality currently introduced and implemented in GeoFIS are still areas of active 
investigation by the scientific community. GeoFIS will be updated when, and if, improved 
methodologies become available. It is one of the strengths of the GeoFIS platform that it is able to 
integrate the latest research developments to make sure that users are provided with the most up-to-
date, reliable and powerful processing algorithms.  
Figure 14. Maps of risk zones of sub-optimal management practices derived in the univariate space
with variate speciﬁc local expert rules. ECa (left); NDVI (middle); and Elevation (right).
This case study illustrates that the expertise of farm managers and advisors can be incorporated
into a data-fusing algorithm to generate decision layers. Indeed, GeoFIS enables users to incorporate
their own expertise, i.e., though the use of univariate risk functions/fuzzy rules, into the generation
of risk maps. The use of fuzzy rules to account for this expertise is of interest as it makes it possible
to avoid abrupt changes in risk and generates a more gradual variation in potential risk (Figure 10).
The GeoFIS interface enables users to calibrate the risk and aggregation functions empirically by
offering users the ability to test a calibration, visualize the resulting risk maps, and possibly adjust
it to their convenience. However, it must be stated that this will require farmers and advisors to be
supported so that their expertise can be translated correctly into the data aggregation algorithms.
The calibration of the OWA index presented in this case study (weight of 0.7 for the minimum
value of univariate risk, 0.2 for the median value, and 0.1 for the maximum value) resulted from
Agriculture 2018, 8, 73
19 of 21
an iterative calibration process lead by the vineyard manager. This aggregation setting has strong
similarities with the logical operation “AND”, i.e., the resulting risk is high if the minimum value of
univariate risk is also high because it has the strongest weight. In other words, all the univariate risks
are high because the median and maximum values for a univariate risk are necessarily higher than the
minimum value of the univariate risk. Note that the real logical operation “AND” would be reproduced
by using the following set of weights (1;0;0). By changing these weights, practitioners might also be
able to reproduce the logical operation “OR” (0;0;1) for which the resulting risk is high as soon as the
maximum value of a univariate risk is high. It would also be possible to perform a simple average of
the different univariate risks by using the same weights for each layer.
From a more general perspective, GeoFIS simpliﬁes the processing of the three layers of
information as the entire process was done within a single software platform. It can be compared
to the data processing in [35] in which data where cleaned with Excel, interpolated with Vesper,
analyzed with Matlab and represented with ArcGIS.
4. Conclusions
The increasing ﬂow of precision agriculture data requires the development of free and open
source processing software to manage and make use of these data and promote precision agriculture
adoption. As such, GeoFIS has been speciﬁcally designed to facilitate the movement from spatial data
to spatial information and to spatial decision-making. The application of GeoFIS on some example
case studies that agricultural professionals may face when dealing with spatial data has demonstrated
the potential of this software. GeoFIS is a released product however it is important to state that all the
functionality currently introduced and implemented in GeoFIS are still areas of active investigation
by the scientiﬁc community. GeoFIS will be updated when, and if, improved methodologies become
available. It is one of the strengths of the GeoFIS platform that it is able to integrate the latest research
developments to make sure that users are provided with the most up-to-date, reliable and powerful
processing algorithms.
As it is, GeoFIS is an excellent tool to promote teaching in precision agriculture. Indeed, GeoFIS has
already been used within many higher education institutions in France to teach researchers and
professionals how to process spatial data.
The user-friendly interface effectively facilitates the
understanding of some major precision agriculture concepts.
The analysis of the three case studies has been an opportunity to also evaluate the limits of the
current algorithms and to propose areas for future developments within the software. For instance,
the data ﬁltering procedure focuses solely on global outliers while spatial datasets may contain outliers
more deeply rooted within the data and sometimes referred to as spatial outliers. A second example is
that the variography analysis is limited to single data layers while cross-variography studies might
be relevant to evaluate the spatial relationships between multiple layers of information. To foster the
adoption of GeoFIS, the authors are more than open to collaboration and are ready to integrate relevant
algorithms for processing precision agriculture data.
Another possibility to promote the processing of precision agriculture data could be to create
links between GeoFIS and existing GIS programs, such as QGIS that is an open-source GIS already
widely used by many communities working on spatial data. There is a possibility to integrate all the
algorithms of GeoFIS directly within this open-source GIS software to beneﬁt from the display and
processing algorithms already implemented in QGIS. This would however require users to process their
precision agriculture data in a more complex environment for which speciﬁc GIS skills are necessary.
Another option is to transform GeoFIS into a web-based service, rather than its current download
and desktop application structure, so that users would not have to care about the R installation,
Java updates and compatibility between different operating systems.
Agriculture 2018, 8, 73
20 of 21
Author Contributions: J.-L.L. and S.G. developed the GeoFIS software; B.T., J.T., O.N., H.J. and S.G. conceived
and designed the experiments; J.L., C.L., and L.P. performed the experiments and analyzed the data; all the
authors contributed to reagents/materials/analysis tools; C.L. organized the writing of the paper.
Funding: This research received no external funding.
Conﬂicts of Interest: The authors declare no conﬂict of interest.
References
1.
Oliver, M.A. Geostatistical Applications for Precision Agriculture; Springer: London, UK, 2010; p. 295.
2.
Pringle, M.J.; McBratney, A.B.; Whelan, B.M.; Taylor, J.A. A preliminary approach to assessing the opportunity
for site-speciﬁc crop management in a ﬁeld, using a yield monitor. Agric. Syst. 2003, 76, 273–292. [CrossRef]
3.
Acevedo-Opazo, C.; Tisseyre, B.; Guillaume, S.; Ojeda, H. The potential of high resolution information to
deﬁne withinvineyard zones related to vine water status. Precis. Agric. 2008, 9, 285–302. [CrossRef]
4.
Bramley, R.G.V. Understanding variability in winegrape production systems 2. Within vineyard variation in
quality over several vintages. Aust. J. Grape Wine Res. 2005, 11, 33–45. [CrossRef]
5.
Verdugo-Vásquez, N.;
Acevedo-Opazo, C.;
Valdés-Gómez, H.;
Araya-Alman, M.;
Ingram, B.;
García de Cortázar-Atauri, I.; Tisseyre, B. Spatial variability of phenology in two irrigated grapevine
cultivar growing under semi-arid conditions. Precis. Agric. 2015, 17, 218–245. [CrossRef]
6.
Baluja, J.; Diago, M.; Goovaerts, P.; Tardaguila, J. Assessment of the spatial variability of anthocyanins in
grapes using a ﬂuorescence sensor: Relationships with vine vigour and yield. Precis. Agric. 2012, 13, 457–472.
[CrossRef]
7.
Debuisson, S.; Germain, C.; Garcia, O.; Panigai, L.; Moncomble, D.; Le Moigne, M.; Fadaili, E.M.; Evain, S.;
Cerovic, Z.G. Using Multiplex® and Greenseeker™ to manage spatial variation of vine vigor in Champagne.
In Proceedings of the 10th International Conference on Precision Agriculture, Denver, Colorado, 18–21 July 2010.
8.
Taylor, J.; Acevedo-Opazo, C.; Ojeda, H.; Tisseyre, B. Identiﬁcation and signiﬁcance of sources of spatial
variation in grapevine water status. Aust. J. Vine Wine Res. 2010, 16, 218–226. [CrossRef]
9.
Taylor, J.; McBratney, A.B.; Whelan, B. Establishing management classes for broadacre agricultural
production. Agron. J. 2007, 99, 1366–1376. [CrossRef]
10.
Jeong, J.S.; García-Moruno, L.; Hernández-Blanco, J. Integrating buildings into a rural landscape using a
multi-criteria spatial decision analysis in GIS-enabled web environment. Biosyst. Eng. 2012, 112, 82–92.
[CrossRef]
11.
Yalew, S.G.; van Griensven, A.; van der Zaag, P. AgriSuit: A web-based GIS-MCDA framework for
agricultural land suitability assessment. Comput. Electron. Agric. 2016, 128, 1–8. [CrossRef]
12.
Leroux, C.; Jones, H.; Clenet, A.; Dreux, B.; Becu, M.; Tisseyre, B. A general method to ﬁlter out defective
spatial observations from yield mapping datasets. Precis. Agric. 2018. [CrossRef]
13.
Sudduth, K.; Drummond, S.T. Yield editor: Software for removing errors from crop yield maps. Agron. J.
2007, 99, 1471–1482. [CrossRef]
14.
Hengl, T.; Heuvelink, G.; Stein, A. A generic framework for spatial prediction of soil variables based on
regressionkriging. Geoderma 2004, 122, 75–93. [CrossRef]
15.
Oliver, M.A.; Webster, R. A tutorial guide to geostatistics: Computing and modelling variograms and kriging.
Catena 2014, 113, 56–69. [CrossRef]
16.
Robinson, T.P.; Metternicht, G. Testing the performance of spatial interpolation techniques for mapping soil
properties. Comput. Electron. Agric. 2006, 50, 97–108. [CrossRef]
17.
Cid-Garcia, N.M.; Albornoz, V.; Rios-Solis, Y.A.; Ortega, R. Rectangular shape management zone delineation
using integer linear programming. Comput. Electron. Agric. 2013, 93, 1–9. [CrossRef]
18.
Pedroso, M.; Taylor, J.; Tisseyre, B.; Charnomordic, B.; Guillaume, S. A segmentation algorithm for the
delineation of management zones. Comput. Electron. Agric. 2010, 70, 199–208. [CrossRef]
19.
Blackmore, S.; Godwin, R.J.; Fountas, S. The analysis of spatial and temporal trends in yield map data over
six years. Byosyst. Eng. 2003, 84, 455–466. [CrossRef]
20.
Li, Y.; Shin, Z.; Li, F.; Li, H.-Y. Delineation of site-speciﬁc management zones using fuzzy clustering analysis
in a coastal saline land. Comput. Electron. Agric. 2007, 56, 174–186. [CrossRef]
Agriculture 2018, 8, 73
21 of 21
21.
Oliver, Y.M.; Robertson, M.J.; Wong, M.T.F. Integrating farmer knowledge, precision agriculture tools, and
crop simulation modelling to evaluate management options for poor-performing patches in cropping ﬁelds.
Eur. J. Agron. 2010, 32, 40–50. [CrossRef]
22.
Pichon, L.; Leroux, C.; Tisseyre, B. A systemic approach to identify relevant information provided by UAV in
precision viticulture. Adv. Anim. Biosci. 2017, 8, 823–827. [CrossRef]
23.
Schenatto, K.; de Souza, E.G.; Bazzi, C.L.; Betzek, N.M.; Gavioli, A.; Beneduzzi, H.M. Use of the farmer’s
experience variable in the generation of management zones. Semina 2017, 38, 2305–2322.
24.
Leroux, C.; Jones, H.; Clenet, A.; Tisseyre, B. A new approach for zoning irregularly-spaced, within-ﬁeld
data. Comput. Electron. Agric. 2017, 141, 196–206. [CrossRef]
25.
Roudier, P.; Tisseyre, B.; Poilvé, H.; Roger, J. Management zone delineation using a modiﬁed watershed
algorithm. Precis. Agric. 2008, 9, 233–250. [CrossRef]
26.
Whelan, B.M.; McBratney, A.B.; Minasny, B. Vesper—Spatial prediction software for precision agriculture.
In ECPA 2001, Proceedings of the 3rd European Conference on Precision Agriculture, Montpellier, France, 2001;
Grenier, G., Blackmore, S., Eds.; agro-Montpellier: Montpellier, France, 2001; pp. 139–144.
27.
Sudduth, K.A.; Drummond, S.T.; Myers, D.B. Yield Editor 2.0: Software for Automated Removal of Yield
Map Errors. In Proceedings of the 2012 ASABE Annual International Meeting, Dallas, TX, USA, 29 July–
1 August 2012.
28.
Simbahan, G.C.; Dobermann, A.; Ping, J.L. Screening yield monitor data improves grain yield maps. Agron. J.
2004, 96, 1091–1102. [CrossRef]
29.
Krishnan, P.; Sharma, R.K.; Dass, A.; Kukreja, A.; Srivastav, R.; Singhal, R.J.; Bandyopadhyay, K.K.; Lal, K.;
Manjaiah, K.M.; Chhokar, R.S.; et al. Web-based crop model: Web InfoCrop—Wheat to simulate the growth
and yield of wheat. Comput. Electron. Agric. 2016, 127, 324–335. [CrossRef]
30.
Guillaume, S.; Charnomordic, B.; Tisseyre, B.; Taylor, J. Soft computing-based decision support tools for
spatial data. Int. J. Comput. Intell. Syst. 2013, 6, 18–33. [CrossRef]
31.
Tisseyre, B.; McBratney, A. A technical opportunity index based on mathematical morphology for site-speciﬁc
management: An application to viticulture. Precis. Agric. 2008, 9, 101–113. [CrossRef]
32.
Guillaume, S.; Charnomordic, B.; Loisel, P. Fuzzy partitions: A way to integrate expert knowledge into
distance calculations. Inf. Sci. 2013, 245, 76–95. [CrossRef]
33.
Yager, R.R. On ordered weighted averaging aggregation operators in multicriteria decision-making.
IEEE Trans. Syst. Man Cybern. 1988, 18, 183–190. [CrossRef]
34.
Lamour, J.; Naud, O.; Lechaudel, M.; Tisseyre, B. Mapping properties of an asynchronous crop: The example
of time interval between ﬂowering and maturity of banana. Adv. Anim. Biosci. 2017, 8, 481–486. [CrossRef]
35.
Santesteban, L.G.; Guillaume, S.; Royo, J.B.; Tisseyre, B. Are precision agriculture tools and methods relevant
at the whole-vineyard scale? Precis. Agric. 2013, 14, 2–17. [CrossRef]
© 2018 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access
article distributed under the terms and conditions of the Creative Commons Attribution
(CC BY) license (http://creativecommons.org/licenses/by/4.0/).


Paper 4:
- APA Citation: Prasad, S., Peddoju, S. K., & Ghosh, D. (2014). Energy efficient mobile vision system for plant leaf disease identification. In 2014 IEEE Wireless Communications and Networking Conference (WCNC) (pp. 3083-3088). IEEE.
  Main Objective: To develop a mobile-based vision system for plant disease diagnosis via plant leaf imaging and analysis, focusing on reducing data size and transmission time to improve efficiency.
  Study Location: Unspecified
  Data Sources: Disease leaf samples captured using different mobile devices at different resolutions
  Technologies Used: k-means clustering, Android operating system, OpenCV
  Key Findings: The proposed system effectively segments diseased portions from leaf images using CIE L*a*b* color-based k-means clustering, significantly reducing data size and transmission time. The approach is scalable and device-independent, making it suitable for use with varying mobile phone camera resolutions.
  Extract 1: "The third objective of the proposed scheme is to reduce the power consumption in the mobile device. The results obtained in our experiments show that the proposed method may be effectively used for reducing the total power consumption at the mobile end."
  Extract 2: "Suppose that the total process of leaf image analysis and disease diagnosis requires C instructions. Also, suppose that the size of the leaf image is D bytes. Let the power consumed by the mobile system be P c for computing and P t for transmitting data." 
  Limitations: None
  Relevance Evaluation: This paper is moderately relevant to the section and subsection focus on investigating data compression, aggregation, and filtering techniques to reduce bandwidth requirements and improve transmission efficiency. While the paper does not explicitly discuss these specific techniques, it aligns with the overall theme of optimizing data transmission for automated irrigation systems. The paper's focus on minimizing data size and transmission time in the context of mobile-based plant disease diagnosis demonstrates a similar objective of enhancing transmission efficiency in real-time data transmission.
  Relevance Score: 0.65
  Inline Citation: (Prasad, Peddoju, & Ghosh, 2014)
  Explanation: The paper proposes a mobile-based system that captures and analyzes images of diseased plant leaves to aid in real-time disease diagnosis. The system employs a modified k-means clustering algorithm to segment the leaf image and identify the disease patch, focusing on minimizing data size and transmission time for improved efficiency. This approach aims to reduce the computational and communication costs associated with mobile-based plant disease diagnosis, making it more feasible for use in rural areas with limited connectivity.

 Full Text: >
This website utilizes technologies such as cookies to enable essential site functionality, as well as for analytics, personalization, and targeted advertising purposes. To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln Sign Out All Books Conferences Courses Journals & Magazines Standards Authors Citations ADVANCED SEARCH Conferences >2014 IEEE Wireless Communicat... Energy efficient mobile vision system for plant leaf disease identification Publisher: IEEE Cite This PDF Shitala Prasad; Sateesh K. Peddoju; D. Ghosh All Authors 25 Cites in Papers 673 Full Text Views Abstract Document Sections I. Introduction II. Proposed Methodology III. Experimental Results IV. Conclusion Authors Figures References Citations Keywords Metrics Abstract: Close monitoring, proper control and management of plant diseases are essential in the efficient cultivation of crops. This paper presents a scheme that uses mobile phones for real-time on-field imaging of diseased plants followed by disease diagnosis via analysis of visual phenotypes. A threshold based offloading scheme is employed for judicious sharing of the computational load between the mobile device and a central server at the plant pathology laboratory, thereby offering a trade-off between the power consumption in the mobile device and the transmission cost. The part of the processing carried out in the mobile device includes leaf image segmentation and spotting of disease patch using improved k-means clustering. The algorithm is simple and hence suitable for Android based mobile devices. The segmented image is subsequently communicated to the central server. This ensures reduced transmission cost compared to that in transmitting full leaf image. Published in: 2014 IEEE Wireless Communications and Networking Conference (WCNC) Date of Conference: 06-09 April 2014 Date Added to IEEE Xplore: 20 November 2014 Electronic ISBN:978-1-4799-3083-8 ISSN Information: DOI: 10.1109/WCNC.2014.6953083 Publisher: IEEE Conference Location: Istanbul, Turkey SECTION I. Introduction At the beginning of this century, there is a tremendous technological revolution in the field of wireless communication and mobile technology. However, this revolution is still absent in agriculture despite advances in technology making it possible to build and deploy wireless sensor and control networks in agricultural field that would radically improve farm efficiencies. This is because the current wireless technologies are too expensive and complicated for use in the farm. Nevertheless, it will be wrong to say that wireless applications have not penetrated the agricultural sector at all. 2-way radios have long been used by farmers in many developed countries with large farmlands to contact their employees, farm suppliers, equipment dealers, agents and buyers from anywhere at anytime. Today, with the wide spread availability of mobile phones and cellular networks, the use of mobile phones in agricultural sector is becoming popular replacing the use of 2-way radios. The advantage of using 2-way radios and mobile phones is that they are wireless tools that are relatively cheap and very simple to use. Additionally, mobile phones have one more important advantage, that is that all brands of mobile phones are generally compatible. The last decade has witnessed a spectacular growth in cellular networks and wireless broadband internet. These days wireless broadband internet networks are widespread. There has also been a tremendous growth in mobile communication technology in recent times. Mobile phones have become a crucial part of our daily life nowadays. Mobile phones have evolved a lot in terms of their form, performance and features. Mobile phones are no more only an alternative to landlines for making phone calls but have also become a computer, GPS, radio and our lifeline to the Internet. Most mobile phones nowadays have an operating system that can run various types of application software, and are equipped with Wi-Fi, Bluetooth and GPS capabilities. For example, PDAs (personal digital assistants), such as the ubiquitous Blackberry, combines cellular phone service, internet access and computing services. Not only is the advancement in technology, there is also a rising popularity of mobile phones globally, including countries like India. In India, mobile technology has unleashed a paradigm shift in the communication medium to reach out to the masses. Consequently, India has outscored other nations in the Asia-Pacific region in terms of number of mobile users. With rapidly increasing tele-density, mobile penetration in rural areas is also growing strongly. A multitude of innovative mobile phones that come with a number of user-friendly features and advanced capabilities are nowadays available with people even in rural India, especially among the agrarian community. Motivated by the advancement in mobile technology and the wide-spread use of mobile phones in India, as discussed above, researchers in India are aiming at helping the agrarian community to improve their agricultural activities through use of mobile phones. A. Why Agriculture? In many countries, including India, agriculture accounts for the majority of rural employment. It also holds the promise for economic growth. In fact, agriculture is approximately four times more effective at raising incomes among the poor than other sectors. Improved agriculture also has a direct impact on hunger and malnutrition, and decreasing the occurrences of famine. However, agriculture is facing a range of serious challenges, particularly in developing countries. The growing global population has heightened the demand for food. With rising food prices, climate change, and lack of infrastructure in rural areas, more effective and modern “smart” agriculture is essential. In view of this, wireless network technology has been utilized in the agricultural sector. Some of the uses of on-farm wireless network are as follows [1]–[3]. Remote monitoring of soil moisture, environmental condition, irrigation status, monitoring of greenhouse, livestock and storage facilties. Remote control of pumps and robotic vehicles. Information transfer for automatic incorporation of environmental data into decision support systems and crop models. Communication of text, graphical, voice and video messages between operators. Asset tracking such as locating irrigation systems, farm vehicles and livestocks. Remote diagnosis in which automatic incorporation of environmental data into decision support systems and crop models. In this paper, we propose to develop a remote diagnosis system for monitoring, control and management of agricultural production through use of advanced technology, especially image processing and computer vision, information and communication technology, and mobile technology. B. M-Agriculture: Mobile-Based Agriculture Information and communication technology, and in particular mobile technologies, are often seen as a ‘game changer’ in agriculture. The already existing mobile-based agricultural information service is a giant leap in the field of agriculture which offers a plethora of services, and serves as a tool for information dissemination that leverages on the modern technology. Various mobile-based services like SMS based information services, voice based agri-advisory services, and videos over mobile networks, etc. are utilized for transfer of general know-how on farming techniques and trends, information on plants and varieties, and how to grow them, etc. Mobile-based agriculture (m-Agriculture) refers to the delivery of agriculture-related services via mobile communications technology. In order to inform decisions on agricultural measures to optimize plant growth, it provides for individual decision-support systems and services which are based on localized contextual information, i.e. delivering location-specific information based on climatic patterns, soil and water conditions,. It also involves gathering relevant data through mobile technologies like automated weather stations or systems equipped with sensors for location-based collection. Thus, m-Agriculture involves two-way advisory systems that provide individual feedback and advice such as remote diagnosis of diseases by experts. These systems typically include the use of smartphones and intermediaries for the communication with farmers and require remote sensing instruments and GIS. To turn an m-Agriculture initiative into a viable and self-sustaining product, certain critical criteria must be addressed. m-Agriculture projects are built on the opportunities provided by increasing use of mobile phones by farmers in developing countries. Accordingly, the primary objective of this paper is to develop a mobile-based vision system for plant disease diagnosis via plant leaf imaging and analysis. C. Mobile-Based Vision System for Plant Disease Diagnosis Plant diseases are caused by pathogens. Correct diagnosis and identification of these pathogens is the most important step in the eventual control of a plant disease. Microscopy, culturing, a few simple biochemical tests, and ELISA are the mainstays for most routine laboratory diagnoses [4]. Other than these, we also rely on visual examination for on-the-field diagnosis. In most of the cases, pests or diseases are seen on the leaves, stems or fruits of the plant. Therefore, finding out symptoms of the pest or disease attack on leaves, stems or fruits of plants, subsequent identification of the pest or diseases, and estimating the percentage of the attack play a key role in successful cultivation of crops. However, performance of such diagnosis is limited by details that can be visualized by the naked eyes and the expertise of the farmer/expert. There is also demand from farmers and agricultural administrators for rapid, timely and accurate diagnosis of pathogens to guide disease management decision making. Due to shortage of trained field and clinical pathologists and other necessary resources, it has become necessary to find innovative ways to maximize the delivery of diagnostic services to agriculture. A solution to this may be to capture the image of the diseased parts of the plant and then study the same for classifying lesion, scoring quantitative traits, calculating infected area, etc. Artificial vision system is one of the emerging technologies that mimic a human vision system in reality. Image and vision have covered almost all fields in our daily life presenting us with ubiquitous devices and ubiquitous computing in an anytime-anywhere scenario. These days cameras are standard on mobile phones, sometimes with picture quality as good as many stand-alone digital cameras. Therefore, it is possible to directly capture the image of the diseased part of a plant and process the image to know about the disease and the extent of infection. These images are shared with experts for diagnosis and expert opinion through specific communication networks and wireless communication channels including Wi-Fi and cellular network. Thus, a mobile-based plant disease diagnosis system is made available to farmers. Application of computer vision techniques in plant research is already in place. One very important aspect in plant research and botany is the identification of plant species and genus. Plant species recognition depends on many features such as the plant shape, size, and most importantly its leaves. The leaf of a plant is characterized in terms of its shape, size, color, vein pattern, edge pattern and texture. While the size, color and vein pattern may vary from place to place depending on the climatic condition, leaf shape, edge and texture features are independent and omnipresent. The leaf shape as an important feature defining the plant species has already been proved and used by many researchers in automatic identification of plant species, including some mobile-based systems [5]–[8]. On the other hand, research in plant disease diagnosis using computer vision is very thin. Scientific community have performed some researches on specific diseases [9]–[12], but is yet to come up with a general algorithm suitable for every disease or at least a majority of diseases. This paper presents a scheme for using mobile phones for real-time data capture via imaging of diseased plant leaves, on-field image segmentation and spotting of disease patch, and transmission of data to plant pathology laboratory for disease diagnosis via analysis of visual phenotypes. Through the mobile service linkage available the system will communicate plant disease related information between the farmers on the field and the agricultural administrator and/or the laboratory. The system will utilize the images of diseased patches on the leaf of the plants along with other environmental information such as the location, climatic condition, etc. to compute and identify the disease, extent of its spread and the possibility of its outbreak. Mobile phones nowadays are generally equipped with camera making it possible to capture the images in the field and directly transmit the same, as necessary. Further, these mobile phones come with good enough computing power to accomplish complete leaf image analysis and disease diagnosis in the mobile device itself. However, the primary constraint with mobile computing is the limited energy. The leaf image analysis and disease diagnosis task is generally computation intensive demanding energy too large to perform on a mobile system. This calls for offloading some part of the processing task to a central server located at the plant pathology laboratory. This, therefore, requires transmission of the leaf image from the mobile device to the server. The amount of data that may be transmitted is, on the other hand, constrained by the wireless bandwidth. Hence, a trade-off between the offloading and the transmission cost is necessary. In our proposed scheme, we propose to perform simple plant leaf segmentation only in the mobile device. The segmented leaf image is then transmitted, instead of the whole leaf image, thereby saving in transmission cost. Fig. 1 depicts the proposed system architecture. A detailed description of our proposed scheme is given in the section to follow. Fig. 1. Proposed system architecture. Show All SECTION II. Proposed Methodology A. Leaf Image Segmentation In image, video and vision applications image segmentation is a fundamental step to separate homogeneous regions. For image analysis and image understanding, proper segmentation is a necessary condition. Features such as color histogram, texture or edge based methods are used for finding homogeneous regions in an image [12]. Image segmentation methods are classified as supervised or unsupervised. The supervised segmentation approach predefines the characteristics of different regions in an image whereas in unsupervised segmentation there is no such prior information. Unsupervised algorithms includes splitting-merging method [14], local and multi-resolution features [15], Markov random field model [16] and many others which are computationally complex and memory consuming. The advantage of such algorithms is that no comparison is required against the manually segmented ground-truth. Unsupervised image segmentation is very useful in real time systems where large variety of natural images need to be segmented. Plant leaf image is a natural image full of challenges and hence needs a dynamic adjustment of segmentation parameters for better results. For this, cluster-based unsupervised image segmentation methods [17]–[19] prove to be useful. In [17], Puzicha et al. proposed an efficient novel mixture model to cluster histogram data with multi-scale formulation. In [18], Bong and Lam proposed multi-objective scatter for image segmentation using concepts of Pareto dominance on gray images (CT scan and SAR). The four necessary criteria for unsupervised image segmentation given by Haralick and Shapiro [20], [21] are Uniform and homogeneous regions with respect to some common characteristic(s). Significant difference between adjacent regions with respect to the characteristic(s). Absence of any hole in a region. Simple and spatially accurate region boundaries. In our work, we propose to use k -means clustering approach [22] for color leaf image segmentation. An image is composed of foreground and background. In our work, we assume that the leaf image is available with simple and uniform background. The leaf again is composed of two different regions - the normal green part and the disease patch. Accordingly, we apply k -means clustering for segmentation with k=3 corresponding to the three regions in the leaf image - background, normal green leafy part and the disease patch region. The RGB leaf image captured by the mobile device is first converted into CIE (Comission Internationale de l'Eclairage) L*a*b color model so as to make the input image device independent. The CIE L*a*b color space is specified by the International Commission on Illumination for use as a reference color model since it is close to the color model visible to human eye. A 5×5 averaging filter mask is applied over the L*a*b image to remove unwanted noise [23]. Following this, the clustering algorithm is applied to identify and segment out the three different regions from the input image. Fig. 2 shows all the three clusters in a leaf image where the first cluster is the background with constant intensity value, the second cluster is the green non-diseased portion in the leaf and the third cluster is the region of interest (ROI), i.e. the disease patch in the leaf. Fig. 2. Results of leaf image segmentation. Show All B. Selection of Diseased Patch The image of the diseased leaf captured by the mobile device in the field needs to be transmitted to some central server present in the pathology laboratory. In [5], White et al. captured and transmitted the complete image to a tablet PC located nearby. However, this requires a proper connection and a high speed Internet connectivity. Indian telecommunication technology is still in the developing stage and except in urban places such high speed connectivity is not available. Whereas, the application under consideration is mainly based in rural areas. Thus, transferring a complete image to a server needs a high bandwidth. This is taken care of to some extent by the image cropping step. Among all the diseased patch obtained in a leaf image, the largest size patch is identified, cropped and transmitted. By this, only the relevant part of the leaf image is transmitted while discarding unnecessary portions of the image. Fig. 3 shows a disease patch cropped out of a leaf image. Since the computational requirement of these two steps, viz. segmentation and cropping, is generally not high, the energy consumed in the mobile device is small enough to support the application. C. Transmission of the Cropped Image Finally, the cropped image is easily transferred to a high processing server or computing device located at the pathology laboratory through a wireless communication channel. The transmission method can be any of the available networks, e.g. 2G, 3G, 4G, Wi-Fi and so on. In order to achieve high transmission efficiency, only the blob corresponding to the largest disease patch is transmitted in color format. This ensures that no information regarding the disease symptoms is lost. Other than the ROI, all other regions in the cropped leaf image, viz. background and the non-diseased leaf portion, as identified via the clustering process, are of no use for the purpose of disease diagnosis. Accordingly, we propose to encode every pixel in these regions with a single zero bit thereby reducing the transmission cost both in terms of bandwidth and power. Fig. 3. The largest disease patch in the leaf image of Fig. 2 cropped out. Show All D. Energy Consideration Since mobile devices are battery operated, the energy in both computation and transmission should be conserved. There are three possibilities through which this architecture can reduce the computation and communication cost. They are compute every operation on the server, compute feature extraction on the mobile device and analyze it on server using machine learning algorithm, and perform low-level image processing operations such as pre-processing on the mobile device and the rest of the algorithm on the server. In all of these approaches, transmission media is very much required and a constant connection is important. In respect of power consumption, the first approach will consume less energy but bandwidth requirement will be high. This option requires to transmit the whole image captured by the mobile phone. Hence, a high-speed broad-band connection is required. In India, transmission media is generally very low and thus second approach will be more preferable. Nonetheless, this approach consumes huge battery power. Therefore, the third approach provides a better trade-off between the two. Suppose that the total process of leaf image analysis and disease diagnosis requires C instructions. Also, suppose that the size of the leaf image is D bytes. Let the power consumed by the mobile system be P c for computing and P t for transmitting data. If the mobile system performs the total procedure, the energy consumption is E c = P c × C M (1) View Source where M is the processing speed of the mobile device in terms of instructions per second. If the total procedure is computed in the central server, then the energy consumed in transmitting the whole leaf image is E t = P t × D×8 B (2) View Source where B is the network bandwidth in bits/sec. Therefore, computing every operation on the server (first option above) is beneficial only when E c > E t . This requires D B sufficiently small compared to C M . Accordingly, offloading is preferred when the available bandwidth B is very large. As proposed in our method, we perform only the segmentation and cropping in the mobile device. Let, the number of instructions involved in doing this is αC , where α<1 . That is, α is the fraction of total computation involved in the segmentation process. Also, let the total data size of the segmented image that is transmitted is βD bytes, where β<1 is the fraction of the total data after cropping. Then the total energy consumed by the mobile system in our proposed scheme is E total = P c ×α C M + P t ×β D×8 B (3) View Source Partial offloading, as proposed in our scheme, will be beneficial when E total is less than both E c and E t . Given the parameters M, P c and P t of the mobile device and the network bandwidth B , the system requires to calculate E c , E t and E total and then decide for complete offloading with all computations in the central server ( E t minimum), no offloading with all computations in the mobile device ( E c minimum), or partial offloading, as per our proposed scheme ( E total minimum). It may be noted from (2) that the channel bandwidth directly affects the energy consumption of a device. The higher the bandwidth, the lower the energy consumption while transferring the image. If the bandwidth is low the energy consumption to transmit the same image is more. Therefore, there is a need to reduce the image size by some means. Accordingly, segmentation plus image cropping is performed, as described above. SECTION III. Experimental Results The complete system is designed using OpenCV and Android operating system. The minimum hardware requirement for mobile devices is 1 GHz processor and 256 MB RAM. Here, though multi-core processors are available, the experiments are carried out on single core processor to actually measure the computational cost and time factor associated with it. A total of 297 diseased leaf samples are captured using different mobile devices at different resolutions. The segmentation results of few leaf samples are shown in Fig. 4. The computation time with different resolutions using the proposed algorithm are plotted in Fig. 5. It is observed that lower the resolution, the faster is the computation, as expected. Table I shows the relative comparison in the data size and transmission time between transmission of the complete leaf image and the segmented leaf image. Clearly, it is seen that the segmented leaf image requires less transmission cost to transfer over a wireless medium. The transmission link used in our experiments is a high speed wireless connection of 54 Mbps. Fig. 4. Segmentation results of four different leaf images. The last (bottom) leaf image is a complex incomplete leaf image. Show All Table I Comparison of data size (in kilo bytes) transmission time (in sec.) for leaf images of different resolutions Fig. 5. Comparison of computational cost for leaf images with different resolutions. Show All SECTION IV. Conclusion This paper proposes a new CIE L*a*b* color based unsupervised segmentation for natural image. Texture feature is used to cluster the leaf image regions employing k -means clustering to segment diseased portion from leaf images. The L*a*b* color space makes the approach more flexible, robust and device independent. Unsupervised image segmentation adds scalability in segmenting images captured by cameras with varying resolutions in different mobile phones. The second task of this work is to reduce the communication cost such that the application be performed in real time by transmitting only the ROI in the leaf image. The third objective of the proposed scheme is to reduce the power consumption in the mobile device. The results obtained in our experiments show that the proposed method may be effectively used for reducing the total power consumption at the mobile end. Authors Figures References Citations Keywords Metrics More Like This Wheat leaf disease detection using CNN in Smart Agriculture 2023 International Wireless Communications and Mobile Computing (IWCMC) Published: 2023 Detection of potato diseases using image segmentation and multiclass support vector machine 2017 IEEE 30th Canadian Conference on Electrical and Computer Engineering (CCECE) Published: 2017 Show More IEEE Personal Account CHANGE USERNAME/PASSWORD Purchase Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile Information COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help? US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow About IEEE Xplore | Contact Us | Help | Accessibility | Terms of Use | Nondiscrimination Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy Policy A not-for-profit organization, IEEE is the world's largest technical professional organization dedicated to advancing technology for the benefit of humanity. © Copyright 2024 IEEE - All rights reserved.

Paper 5:
- APA Citation: Nauman, A., Qadri, Y. A., Amjad, M., Bin Zikria, Y., Afzal, M. K., & Kim, S. W. (2020). Multimedia Internet of Things: A comprehensive survey. IEEE Access, 8, 8202-8250.
  Main Objective: To provide a comprehensive survey of the Multimedia Internet of Things (M-IoT), covering architecture, protocols, applications, and challenges.
  Study Location: Unspecified
  Data Sources: Not mentioned in the provided text
  Technologies Used: Not mentioned in the provided text
  Key Findings: Multimedia applications are reshaping the Internet of Things (IoT) landscape, leading to the emergence of Multimedia Internet of Things (M-IoT). 
M-IoT supports diverse multimedia applications across domains such as road traffic management, security, industry, and health, transforming human lives. 
Key considerations for M-IoT include Quality-of-Experience (QoE), Quality-of-Service (QoS), and emerging technologies like Fog/Edge computing and Software-Defined-Networks (SDNs).
  Extract 1: None
  Extract 2: None
  Limitations: The paper does not directly address the specific point of focus on data compression techniques for real-time irrigation management systems.
  Relevance Evaluation: The paper is moderately relevant to the point of focus on investigating data compression, aggregation, and filtering techniques for reducing bandwidth requirements and improving transmission efficiency in real-time irrigation management systems. 
While the paper primarily focuses on multimedia applications and M-IoT architecture, it does not explicitly discuss data compression techniques in the context of real-time data transmission for irrigation management.
  Relevance Score: 0.55
  Inline Citation: (Nauman et al., 2020)
  Explanation: This paper presents a comprehensive survey on Multimedia Internet of Things (M-IoT), focusing on the architecture, protocols, and applications of integrating multimedia in the IoT domain. 
It delves into the issues related to multimedia's characteristics and provides an overview of multimedia-related M-IoT architectures. 
The paper also examines various multimedia applications supported by IoT, showcasing use cases in diverse domains like road traffic management, security, industry, and health, highlighting how M-IoT is revolutionizing these fields.

 Full Text: >
This website utilizes technologies such as cookies to enable essential site functionality, as well as for analytics, personalization, and targeted advertising purposes. To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln Sign Out All Books Conferences Courses Journals & Magazines Standards Authors Citations ADVANCED SEARCH Journals & Magazines >IEEE Access >Volume: 8 Multimedia Internet of Things: A Comprehensive Survey Publisher: IEEE Cite This PDF Ali Nauman; Yazdan Ahmad Qadri; Muhammad Amjad; Yousaf Bin Zikria; Muhammad Khalil Afzal; Sung Won Kim All Authors 196 Cites in Papers 19635 Full Text Views Open Access Comment(s) Under a Creative Commons License Abstract Document Sections I. Introduction II. IoT and Multimedia IoT Architecture III. Applications of M-IoT IV. Performance Metrics for M-IoT V. M-IoT Computing Paradigm Show Full Outline Authors Figures References Citations Keywords Metrics Abstract: The immense increase in multimedia-on-demand traffic that refers to audio, video, and images, has drastically shifted the vision of the Internet of Things (IoT) from scalar to Multimedia Internet of Things (M-IoT). IoT devices are constrained in terms of energy, computing, size, and storage memory. Delay-sensitive and bandwidth-hungry multimedia applications over constrained IoT networks require revision of IoT architecture for M-IoT. This paper provides a comprehensive survey of M-IoT with an emphasis on architecture, protocols, and applications. This article starts by providing a horizontal overview of the IoT. Then, we discuss the issues considering the characteristics of multimedia and provide a summary of related M-IoT architectures. Various multimedia applications supported by IoT are surveyed, and numerous use cases related to road traffic management, security, industry, and health are illustrated to show how different M-IoT applications are revolutionizing human life. We explore the importance of Quality-of-Experience (QoE) and Quality-of-Service (QoS) for multimedia transmission over IoT. Moreover, we explore the limitations of IoT for multimedia computing and present the relationship between the M-IoT and emerging technologies including event processing, feature extraction, cloud computing, Fog/Edge computing and Software-Defined-Networks (SDNs). We also present the need for better routing and Physical-Medium Access Control (PHY-MAC) protocols for M-IoT. Finally, we present a detailed discussion on the open research issues and several potential research areas related to emerging multimedia communication in IoT. Topic: Mobile Multimedia: Methodology and Applications 0 seconds of 0 seconds The overall vision of integrating multimedia applications of every domain in IoT, developing smart city and transforming human lives i.e., multimedia in agriculture, smar...View more Published in: IEEE Access ( Volume: 8) Page(s): 8202 - 8250 Date of Publication: 06 January 2020 Electronic ISSN: 2169-3536 DOI: 10.1109/ACCESS.2020.2964280 Publisher: IEEE Funding Agency: Authors Figures References Citations Keywords Metrics More Like This Quality of Service (QoS) in Internet of Things 2018 3rd International Conference On Internet of Things: Smart Innovation and Usages (IoT-SIU) Published: 2018 A Fog Computing Framework for Quality of Service Optimisation in the Internet of Things (IoT) Ecosystem 2020 2nd International Multidisciplinary Information Technology and Engineering Conference (IMITEC) Published: 2020 Show More IEEE Personal Account CHANGE USERNAME/PASSWORD Purchase Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile Information COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help? US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow About IEEE Xplore | Contact Us | Help | Accessibility | Terms of Use | Nondiscrimination Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy Policy A not-for-profit organization, IEEE is the world's largest technical professional organization dedicated to advancing technology for the benefit of humanity. © Copyright 2024 IEEE - All rights reserved.

</subsection_point_Point 3>

<previous_sections>

A systematic review of automated systems for real-time irrigation management

1. INTRODUCTION
The challenge of feeding a growing population with finite resources is becoming increasingly pressing. By 2050, the world population is expected to reach 9.7 billion, necessitating a 70% increase in food production (Falkenmark and Rockstrom, 2009). Irrigation plays a crucial role in enhancing crop yields and agricultural productivity to meet this growing demand. Studies have shown that irrigation can significantly increase crop water productivity, contributing to increased food production (Ali and Talukder, 2008; Playan and Mateos, 2005). However, water scarcity poses a significant challenge, with many regions facing water deficits and the need for improved water management practices (Falkenmark and Rockstrom, 2009). Optimizing irrigation schedules and doses based on crop requirements and environmental conditions is essential for maximizing yield and quality while minimizing water use (Zhang et al., 2024). The necessity of scalable water-efficient practices for increasing food demand cannot be overstated. Techniques such as regulated deficit irrigation, magnetically treated water, and the use of drought-tolerant crops like sorghum have shown promise in improving water productivity and ensuring food security (Mehmood et al., 2023; Putti et al., 2023; Hadebe et al., 2016). As the global food challenge intensifies, it is imperative to critically evaluate the current state and future potential of irrigation management systems to guide research, innovation, and implementation efforts towards fully autonomous, scalable solutions.

Despite the importance of irrigation in addressing the global food challenge, traditional irrigation management techniques, such as manual scheduling and timer-based systems, have significant limitations. These methods are often labor-intensive, inefficient, and less adaptable to changing conditions (Savin et al., 2023). Manual and timer-based scheduling can lead to high operational costs and inefficient water use (Raghavendra, Han, and Shin, 2023). The reliance on manual intervention and predetermined schedules limits their adaptability to changing environmental conditions, crop water requirements, and soil moisture levels (Kaptein et al., 2019). Sensor-based irrigation systems offer an alternative, enabling real-time adjustments based on soil water status measurements (Kaptein et al., 2019). However, the adoption of these systems in commercial settings has been limited, often requiring extensive input from researchers (Kim et al., 2014; Lea-Cox et al., 2018; Ristvey et al., 2018). The limitations of traditional irrigation management techniques highlight the need for scalable, automated solutions for greater efficiency in irrigation management. Automated systems that collect real-time data, analyze it, and make autonomous irrigation decisions can lead to improved water use efficiency and increased crop productivity (Champness et al., 2023; Wu et al., 2022). To fully understand the potential of automated systems, it is necessary to examine the automation of each part of the irrigation management pipeline and analyze the effectiveness and efficiency of integrated end-to-end solutions.

The emergence of smart irrigation management and IoT marks a significant shift from historical irrigation practices. Modern approaches rely on vast data and analysis algorithms, leveraging technologies such as remote sensing, sensor networks, weather data, and computational algorithms (Atanasov, 2023; Bellvert et al., 2023; Kumar et al., 2023). IoT plays a vital role in collecting vast amounts of data through sensors, data transmission, and tailored networks, enabling real-time monitoring and control of irrigation systems (Liakos, 2023; Zuckerman et al., 2024). These advancements in data collection and analysis have the potential to revolutionize irrigation management, allowing for more precise and efficient water use. However, challenges such as processing diverse data sources, data integration, and lack of integrated data analysis hamper the full benefit of IoT in irrigation management (Dave et al., 2023). The current fragmented approach in smart irrigation, focusing on individual components rather than the entire system, limits the potential for fully autonomous, real-time end-to-end irrigation management (Togneri et al., 2021). To address these challenges and fully realize the potential of smart irrigation management, there is a need for automating and integrating each section of the irrigation management pipeline, from sensor/weather data collection and transmission to processing, analysis, decision-making, and automated action (McKinion and Lemmon, 1985). This integration requires a thorough investigation of the role of interoperability and standardization in enabling seamless communication and compatibility between components within the automated irrigation management pipeline.

Machine learning (ML) plays a significant role in processing vast data, predicting plant stress, modeling climate effects, and optimizing irrigation in smart irrigation management systems. ML algorithms can analyze data collected from sensors and weather stations to determine optimal irrigation schedules (Vianny et al., 2022). However, the potential of ML is often constrained by manual steps, such as data interpretation, decision-making on irrigation timing and volume, and system adjustments. Automating ML integration to allow direct action from insights to irrigation execution, removing bottlenecks and achieving real-time adaptability, is crucial for fully autonomous irrigation management (Barzallo-Bertot et al., 2022). By integrating ML into automated systems, the irrigation management pipeline can become more seamless and efficient, enabling real-time decision-making and action based on data-driven insights. To achieve this level of automation and integration, it is essential to identify gaps and propose solutions for seamless integration across the automated irrigation management system, aiming to achieve fully autonomous, scalable irrigation management.

To achieve seamless integration across the automated irrigation management system, interoperability and standardization are critical. Interoperability allows different system components, such as sensors, actuators, and software, to communicate and exchange data effectively, while standardization ensures that data is represented in a consistent format (Santos et al., 2020). Standardized protocols and data formats are essential for achieving seamless integration and ensuring compatibility between components in real-time irrigation management systems (Robles et al., 2022; Hatzivasilis et al., 2018). Existing and emerging standards, such as OGC SensorThings API and ISO 11783, have applicability to real-time irrigation management systems (Hazra et al., 2021). However, challenges such as data quality, scalability, reliability, and security need to be addressed to fully realize the potential of interoperability and standardization in automated irrigation management systems (Hazra et al., 2021). Addressing these challenges is crucial for enabling the seamless integration of components within the automated irrigation management pipeline, which is essential for achieving fully autonomous, scalable irrigation management. A comprehensive evaluation of the role of interoperability and standardization in enabling the integration of components within the automated irrigation management pipeline is necessary to guide future research and implementation efforts.
The primary objective of this systematic review is to critically evaluate the current state and future potential of real-time, end-to-end automated irrigation management systems that integrate IoT and machine learning technologies for enhancing agricultural water use efficiency and crop productivity.
Specific objectives include:
•	Examining the automation of each part of the irrigation management pipeline and the seamless integration of each section in the context of irrigation scheduling and management.
•	Analyzing the effectiveness and efficiency of integrated end-to-end automated irrigation systems.
•	Investigating the role of interoperability and standardization in enabling the integration of components within the automated irrigation management pipeline.
•	Identifying gaps and proposing solutions for seamless integration across the automated irrigation management system, aiming to achieve fully autonomous, scalable irrigation management.
By addressing these objectives, this systematic review aims to provide a comprehensive and critical evaluation of the current state and future potential of real-time, end-to-end automated irrigation management systems. Its intention is to guide future research, innovation, and implementation efforts to achieve fully autonomous, scalable irrigation management that can contribute to addressing the global food challenge.

2. REVIEW METHODOLOGY
•	Question-driven framework to guide the literature review of real-time, autonomous irrigation management systems
•	Key research questions posed, each with the motivation behind investigating them and a starting hypothesis to evaluate against the examined literature
•	Table presenting the major objectives, specific objectives, questions, motivations, and hypotheses
3. DATA COLLECTION TO CLOUD: AUTOMATION AND REAL-TIME PROCESSING
3.1. Irrigation management data
The success of automated irrigation management systems relies heavily on the collection, transmission, and analysis of various types of data. The most applicable data types for irrigation management include soil moisture, canopy temperature, weather data, and plant physiological parameters (Farooq et al., 2019; Li et al., 2019; Olivier et al., 2021; Evett et al., 2020). These data are typically collected from a range of sources, including in-field sensors, remote sensing platforms, weather stations, and manual measurements (Li et al., 2019; Karimi et al., 2018).
Soil moisture data is arguably the most critical type of data for irrigation management, as it directly reflects the water available to plants and can be used to determine the optimal timing and amount of irrigation (Olivier et al., 2021; Intrigliolo & Castel, 2006). Soil moisture sensors, such as tensiometers, capacitance probes, and time-domain reflectometry (TDR) sensors, can provide real-time measurements of soil water content at various depths (Farooq et al., 2019). These sensors can be deployed in a network configuration to capture spatial variability in soil moisture across a field (Karimi et al., 2018).
Canopy temperature data is another valuable type of data for irrigation management, as it can be used to assess plant water stress and adjust irrigation accordingly (Evett et al., 2020). Infrared thermometers and thermal cameras can be used to measure canopy temperature, which is influenced by factors such as air temperature, humidity, wind speed, and plant water status (Li et al., 2019). When plants experience water stress, they tend to close their stomata to reduce water loss, leading to an increase in canopy temperature (Evett et al., 2020). By monitoring canopy temperature and comparing it to reference values, automated irrigation systems can detect plant water stress and trigger irrigation events to maintain optimal plant health and productivity (Li et al., 2019).
Weather data, including temperature, humidity, precipitation, wind speed, and solar radiation, are essential for predicting crop water requirements and scheduling irrigation events (Akilan & Baalamurugan, 2024). Weather stations equipped with various sensors can provide real-time measurements of these parameters, which can be used as inputs for crop water requirement models, such as the FAO-56 Penman-Monteith equation (Li et al., 2019). These models estimate crop evapotranspiration (ET) based on weather data and crop-specific coefficients, allowing for the calculation of irrigation requirements (Intrigliolo & Castel, 2006). By integrating weather data into automated irrigation systems, irrigation schedules can be dynamically adjusted based on changing environmental conditions, ensuring that crops receive the optimal amount of water at the right time (Akilan & Baalamurugan, 2024).
When collecting and utilizing these data types, several considerations must be taken into account, including the volume, frequency, format, and source of the data (Farooq et al., 2019). The volume of data generated by automated irrigation systems can be substantial, especially when high-resolution sensors are deployed at a large scale (Bastidas Pacheco et al., 2022). This necessitates the use of efficient data storage, processing, and transmission technologies to handle the data load (Farooq et al., 2019). The frequency of data collection is another important consideration, as it directly impacts the temporal resolution of the data and the ability to detect rapid changes in plant water status or environmental conditions (Bastidas Pacheco et al., 2022). Bastidas Pacheco et al. (2022) demonstrated that collecting full pulse resolution data from water meters provides more accurate estimates of event occurrence, timing, and features compared to aggregated temporal resolutions, highlighting the importance of selecting appropriate data collection frequencies to ensure the quality and usefulness of the data for irrigation management.
The format of the data is also crucial, as it determines the compatibility and interoperability of the data with various analysis tools and platforms (Farooq et al., 2019). Standardized data formats, such as JSON, XML, or CSV, can facilitate data exchange and integration between different components of the automated irrigation system (Zhang et al., 2023). The source of the data is another important consideration, as it can impact the reliability, accuracy, and spatial coverage of the data (Farooq et al., 2019). For example, in-field sensors provide highly localized measurements, while remote sensing platforms, such as satellites or drones, can provide data at larger spatial scales (Li et al., 2019). By combining data from multiple sources, automated irrigation systems can achieve a more comprehensive understanding of crop water requirements and optimize irrigation management accordingly (Farooq et al., 2019).
Data quality, accuracy, and reliability are paramount in irrigation management, as they directly impact the effectiveness of decision-making processes and the efficiency of water use (Gupta et al., 2020). Inaccurate or unreliable data can lead to suboptimal irrigation decisions, resulting in crop stress, yield losses, or wasted water resources (Ramli & Jabbar, 2022). Gupta et al. (2020) emphasized the critical importance of data security and privacy in smart farming systems, as the leakage of sensitive agricultural data can cause severe economic losses to farmers and compromise the integrity of the automated irrigation system. The authors also highlighted the need for robust authentication and secure communication protocols to prevent unauthorized access to smart farming systems and protect data in transit (Gupta et al., 2020).
Ramli and Jabbar (2022) addressed the challenges associated with implementing real-time, automated irrigation systems, including data quality, scalability, reliability, and security. They proposed solutions and best practices based on the analysis of case studies and real-world implementations, such as the use of redundant sensors, data validation techniques, and secure communication protocols (Ramli & Jabbar, 2022). The authors also emphasized the importance of regular maintenance and calibration of sensors to ensure the accuracy and reliability of the collected data (Ramli & Jabbar, 2022).
Researchers have investigated the use of data compression, aggregation, and filtering techniques to reduce bandwidth requirements and improve transmission efficiency in automated irrigation systems (Karim et al., 2023; Rady et al., 2020; Cui, 2023). Karim et al. (2023) explored the effectiveness of various data compression techniques, such as lossless and lossy compression algorithms, in reducing the size of data packets transmitted over wireless networks. The authors found that lossless compression techniques, such as Huffman coding and Lempel-Ziv-Welch (LZW), can significantly reduce data size without compromising data quality, while lossy compression techniques, such as JPEG and MP3, can further reduce data size by introducing acceptable levels of distortion (Karim et al., 2023).
Rady et al. (2020) developed a novel data compression algorithm specifically designed for irrigation data, which achieved significant compression ratios without compromising data quality. The authors demonstrated that their algorithm could reduce the amount of data transmitted over wireless networks, thereby improving the efficiency of the irrigation system and reducing costs (Rady et al., 2020). Cui (2023) investigated the use of data aggregation and filtering techniques to reduce the number of transmissions and save bandwidth in automated irrigation systems. The author proposed a data aggregation scheme that combines multiple sensor readings into a single value, such as the average soil moisture over a specified time interval, to reduce the frequency of data transmissions (Cui, 2023). Additionally, the author explored the use of data filtering techniques, such as Kalman filters and particle filters, to remove noise and outliers from sensor data, improving the accuracy and reliability of the transmitted information (Cui, 2023).
Data standardization and harmonization are crucial for facilitating seamless integration and interoperability between the various components of automated irrigation management systems (Zhang et al., 2023; Ermoliev et al., 2022). Zhang et al. (2023) developed a novel cyberinformatics technology called iCrop, which enables the in-season monitoring of crop-specific land cover across the contiguous United States. The authors highlighted the importance of data standardization and harmonization in the context of iCrop, as it allows for the efficient distribution of crop-specific land cover information based on the findable, accessible, interoperable, and reusable (FAIR) data principle (Zhang et al., 2023). By adopting standardized data formats and protocols, such as the Open Geospatial Consortium (OGC) standards, iCrop enables the seamless integration of various data sources and facilitates the interoperability of the system with other agricultural decision support tools (Zhang et al., 2023).
Ermoliev et al. (2022) proposed a linkage methodology for linking distributed sectoral/regional optimization models in a situation where private information is not available or cannot be shared by modeling teams. The authors emphasized the need for data standardization to enable decentralized cross-sectoral coordination and analysis, as it allows for the consistent representation and exchange of data between different models and stakeholders (Ermoliev et al., 2022). By adopting standardized data formats and interfaces, the proposed linkage methodology can facilitate the integration of various optimization models and support the development of comprehensive decision support systems for sustainable resource management (Ermoliev et al., 2022).
Metadata plays a vital role in providing context and enabling better data interpretation and decision-making in automated irrigation management systems (Jahanddideh-Tehrani et al., 2021). Metadata refers to the additional information that describes the characteristics, quality, and context of the primary data, such as the sensor type, calibration parameters, measurement units, and timestamp (Jahanddideh-Tehrani et al., 2021). Jahanddideh-Tehrani et al. (2021) highlighted the importance of metadata in water resources management, as it enables decision-makers to use the data to the best of its capabilities by understanding factors such as when water data was collected and what factors might have contributed to the measurements. The authors emphasized the need for standardized metadata formats and guidelines, such as the Dublin Core Metadata Initiative (DCMI) and the ISO 19115 standard, to ensure the consistency and interoperability of metadata across different water information systems (Jahanddideh-Tehrani et al., 2021).
In the context of automated irrigation management systems, metadata can provide valuable information about the data collection process, sensor performance, and environmental conditions that can aid in data interpretation and decision-making (Cota & Mamede, 2023). For example, metadata about the sensor type and calibration parameters can help assess the accuracy and reliability of the collected data, while metadata about the weather conditions and soil properties can provide context for interpreting the data and adjusting irrigation strategies accordingly (Cota & Mamede, 2023). By incorporating metadata into the data management and analysis pipeline of automated irrigation systems, decision-makers can make more informed and context-aware decisions, leading to improved water use efficiency and crop productivity (Jahanddideh-Tehrani et al., 2021).

3.2. Edge Computing and Fog Computing
Edge computing and fog computing have emerged as transformative technologies in the realm of real-time irrigation management systems, offering significant potential for improving efficiency, scalability, and reliability (Abdel Nasser et al., 2020; Tran et al., 2019). Edge computing refers to the practice of processing data near the edge of the network, close to the source of the data, while fog computing is a decentralized computing infrastructure that extends cloud computing capabilities to the network edge (Hassija et al., 2019). These technologies bring computation and analytics closer to the data source, reducing the need for data to travel to the cloud and enabling faster processing and decision-making (Hassija et al., 2019; Zhang et al., 2020).
The potential of edge computing and fog computing in real-time irrigation management is immense. Abdel Nasser et al. (2020) proposed a two-layer system for water demand prediction using automated meters and machine learning techniques, demonstrating the potential of edge computing in improving the efficiency and scalability of irrigation management. The system collects and aggregates data from distributed smart meters in the first layer, while the second layer uses LSTM neural networks to predict water demand for different regions of households. By leveraging edge computing, the system can achieve high accuracy in predicting water demand, which is essential for efficient irrigation management (Abdel Nasser et al., 2020).
Tran et al. (2019) conducted a comprehensive review of real-time, end-to-end automated irrigation management systems, highlighting the role of fog computing in addressing data transmission challenges and enabling seamless integration across the irrigation management pipeline. The authors emphasize that real-time, end-to-end automated irrigation management systems have the potential to significantly improve water efficiency, crop yields, and reduce labor costs. However, they also identify several challenges that need to be addressed, such as data quality, scalability, reliability, and security, which can be effectively tackled by implementing fog computing architectures (Tran et al., 2019).
Edge computing offers several benefits in real-time irrigation management systems, including reduced latency, real-time decision-making, and reduced reliance on cloud connectivity (Mishra, 2020; Zhang et al., 2020). By processing data closer to the source, edge computing enables faster response times and more efficient data handling (Mishra, 2020). Mishra (2020) highlights that edge computing reduces latency by processing data closer to the source, enabling real-time decision-making and lessening reliance on cloud connectivity by shifting processing to local or edge devices.
Zhang et al. (2020) explore the application of edge computing in agricultural settings, demonstrating its potential to improve the efficiency and accuracy of irrigation systems. The authors discuss how edge computing has prospects in various agricultural applications, such as pest identification, safety traceability of agricultural products, unmanned agricultural machinery, agricultural technology promotion, and intelligent management. They also emphasize that the emergence of edge computing models, such as fog computing, cloudlet, and mobile edge computing, has transformed the management and operation of farms (Zhang et al., 2020).
Fog computing plays a crucial role in distributing processing and storage across the network, enhancing the scalability and reliability of automated irrigation systems (Premkumar & Sigappi, 2022; Singh et al., 2022). Premkumar and Sigappi (2022) evaluate the current state of automated irrigation management systems and propose a hybrid machine learning approach for predicting soil moisture and managing irrigation. Their study emphasizes the potential of fog computing in distributing processing and storage across the network, improving the efficiency and scalability of irrigation systems. The proposed hybrid machine learning approach outperforms other machine learning algorithms in predicting soil moisture, demonstrating the effectiveness of fog computing in enhancing the performance of automated irrigation systems (Premkumar & Sigappi, 2022).
Singh et al. (2022) discuss the role of fog computing in distributing processing and storage across the network, enhancing scalability and reliability in agricultural management systems. The authors argue that by implementing fog computing, these systems can achieve faster data processing and response times, improving overall efficiency and effectiveness. They also highlight that fog computing can address the challenges faced by real-time data transmission in agricultural management systems, such as latency, bandwidth limitations, and data security (Singh et al., 2022).
The integration of edge and fog computing in real-time irrigation management systems is crucial for achieving fully automated, scalable, and reliable solutions. As the demand for autonomous irrigation management grows, these technologies will play a pivotal role in enabling faster decision-making, reduced latency, improved resource utilization, and seamless integration across the irrigation management pipeline (Tran et al., 2019; Zhang et al., 2020). By bringing computation and analytics closer to the data source and distributing processing and storage across the network, edge and fog computing can significantly enhance the efficiency and effectiveness of automated irrigation systems, contributing to the overall goal of addressing the global food challenge through optimized water resource management and increased agricultural productivity (Abdel Nasser et al., 2020; Premkumar & Sigappi, 2022; Singh et al., 2022).

3.3. Automation of Data Collection
The automation of data collection is a critical component in the development of real-time, end-to-end automated irrigation management systems that integrate IoT and machine learning technologies. It enables the efficient gathering of vital information about crop health, environmental conditions, and water requirements, which is essential for enhancing agricultural water use efficiency and crop productivity. Two key aspects of automated data collection are the use of advanced sensing technologies for non-invasive plant stress detection and the implementation of wireless sensor networks and energy-efficient communication protocols for large-scale, long-term data collection.
Advanced sensing technologies, such as hyperspectral imaging and thermal sensing, have emerged as powerful tools for non-invasive plant stress detection in automated irrigation management systems. These technologies provide valuable information about crop traits, enabling early and accurate detection of plant health issues (Triantafyllou et al., 2019). Triantafyllou et al. (2019) propose a comprehensive reference architecture model that incorporates advanced sensing technologies in the sensor layer for real-time plant stress detection, highlighting their importance in providing non-invasive plant stress detection. Similarly, Hossain et al. (2023) present a novel IoT-ML-Blockchain integrated framework for smart agricultural management that leverages advanced sensing technologies to optimize water use and improve crop yield, contributing to the overall goal of enhancing agricultural water use efficiency and crop productivity.
Hyperspectral imaging can capture subtle changes in plant physiology that are indicative of stress, while machine learning algorithms can be employed to extract meaningful patterns from the spectral data and classify different stress types (Araus et al., 2014). Thermal sensing can detect changes in canopy temperature, which is influenced by factors such as plant water status (Li et al., 2019). By monitoring canopy temperature and comparing it to reference values, automated irrigation systems can detect plant water stress and trigger irrigation events to maintain optimal plant health and productivity (Li et al., 2019).
The integration of advanced sensing technologies in automated irrigation management systems has the potential to revolutionize precision agriculture. Jiang et al. (2019) demonstrate the effectiveness of a deep learning-based model in accurately detecting leaf spot diseases, highlighting the importance of image augmentation and deep learning algorithms in enhancing the model's performance.
Wireless sensor networks (WSNs) and energy-efficient communication protocols have the potential to significantly improve the efficiency and reliability of data collection in large-scale, long-term irrigation systems. WSNs offer a cost-effective and scalable solution for real-time data collection in large-scale irrigation systems, providing remote monitoring and automated control capabilities (Mehdizadeh et al., 2020). Nishiura and Yamamoto (2021) propose a novel sensor network system that utilizes drones and wireless power transfer to autonomously collect environmental data from sensor nodes in vast agricultural fields, reducing operational costs and enhancing the efficiency of data collection. Similarly, Higashiura and Yamamoto (2021) introduce a network system that employs UAVs and LoRa communication to efficiently collect environmental data from sensor nodes distributed across large farmlands, optimizing data collection and reducing travel distance and time.
Energy-efficient communication protocols are crucial for ensuring reliable data transmission in challenging environmental conditions and extending the lifespan of sensor nodes (Mehdizadeh et al., 2020). Al-Ali et al. (2023) investigate the potential of WSNs and energy-efficient communication protocols for data collection in large-scale, long-term irrigation systems, discussing the challenges and opportunities of using these technologies to improve the efficiency and reliability of real-time data collection in irrigation management. Mehdizadeh et al. (2020) emphasize the need for careful consideration of factors such as data accuracy, energy consumption, and network reliability when designing effective WSNs for irrigation management, enabling timely irrigation decisions and improved crop yields.
The automation of data collection through the use of advanced sensing technologies and wireless sensor networks is essential for achieving fully autonomous, scalable irrigation management. By enabling non-invasive plant stress detection and large-scale, long-term data collection, these technologies contribute to the overall goal of optimizing water resource management and increasing agricultural productivity. The integration of these technologies in real-time, end-to-end automated irrigation management systems has the potential to enhance agricultural water use efficiency and crop productivity, ultimately contributing to the development of fully autonomous, scalable irrigation management solutions.

3.4: Real-Time Data Transmission Protocols and Technologies
Real-time data transmission is a critical component of automated irrigation management systems, as it enables the timely delivery of sensor data to the cloud for processing and decision-making. The exploration of suitable protocols and network architectures is essential for ensuring efficient and reliable data transmission in these systems, contributing to the overall goal of enhancing agricultural water use efficiency and crop productivity.
The Message Queuing Telemetry Transport (MQTT) protocol has emerged as a popular choice for real-time data transmission in IoT networks, including those used for automated irrigation management. MQTT is a lightweight, publish-subscribe protocol designed for constrained devices and low-bandwidth networks (Author, 2019). Its simplicity and low overhead make it well-suited for IoT applications where data transmission speed and energy efficiency are critical (Saranyadevi et al., 2022). MQTT provides three Quality of Service (QoS) levels, ensuring data reliability in real-time scenarios (Author, 2019). Chen et al. (2020) proposed novel algorithms to improve data exchange efficiency and handle rerouting in MQTT-based IoT networks for automated irrigation management systems. Their TBRouting algorithm efficiently finds the shortest paths for data transmission, while the Rerouting algorithm effectively handles the rerouting of topic-based session flows when a broker crashes. The combination of these algorithms can significantly improve the performance and reliability of automated irrigation management systems (Chen et al., 2020).
Client-server IoT networks, such as those based on MQTT, play a crucial role in real-time data transmission for automated irrigation management systems. In these networks, sensors and devices (clients) publish data to a central broker (server), which then distributes the data to subscribed clients (Verma et al., 2021). This architecture enables efficient data collection, processing, and dissemination, facilitating the integration of various components within the automated irrigation management pipeline. Verma et al. (2021) proposed an architecture for healthcare monitoring systems using IoT and communication protocols, which provides a comprehensive overview of existing approaches and highlights challenges and opportunities in the field. Although focused on healthcare, the insights from this study can be applied to automated irrigation management systems, emphasizing the importance of interoperability and standardization for seamless integration (Verma et al., 2021).
In addition to MQTT, other application layer protocols such as XMPP, CoAP, SOAP, and HTTP have been explored for real-time data transmission in IoT networks. Each protocol has its strengths and weaknesses, making them suitable for different applications and scenarios. XMPP (Extensible Messaging and Presence Protocol) is an open-standard protocol that supports real-time messaging, presence, and request-response services (Saint-Andre, 2011). CoAP (Constrained Application Protocol) is a specialized web transfer protocol designed for use with constrained nodes and networks in the Internet of Things (Shelby et al., 2014). SOAP (Simple Object Access Protocol) is a protocol for exchanging structured information in the implementation of web services, while HTTP (Hypertext Transfer Protocol) is the foundation of data communication for the World Wide Web (Fielding et al., 1999).
Motamedi and Villányi (2022) compared and evaluated wireless communication protocols for the implementation of smart irrigation systems in greenhouses, considering factors such as power consumption, range, reliability, and scalability. They found that ZigBee is the most suitable local communication protocol for greenhouse irrigation due to its large number of nodes and long range, while MQTT is the recommended messaging protocol for smart irrigation systems due to its TCP transport protocol and quality of service (QoS) options. GSM is a reliable and cost-effective global communication protocol for greenhouse irrigation, providing wide coverage and low cost (Motamedi & Villányi, 2022).
Syafarinda et al. (2018) investigated the use of the MQTT protocol in a precision agriculture system using a Wireless Sensor Network (WSN). They found that MQTT is suitable for use in IoT applications due to its lightweight, simple, and low bandwidth requirements. The average data transmission speed using the MQTT protocol was approximately 1 second, demonstrating its effectiveness for real-time data transmission in precision agriculture systems (Syafarinda et al., 2018).
The choice of application layer protocol for real-time irrigation management depends on factors such as data transmission speed, reliability, and energy efficiency. MQTT and RTPS (Real-Time Publish-Subscribe) are both suitable for real-time data transmission in IoT systems, but they have different strengths and weaknesses. MQTT is a better choice for applications that require low latency and high throughput, while RTPS is a better choice for applications that require high reliability and low latency (Sanchez-Iborra & Skarmeta, 2021). The exploration of MQTT and client-server IoT networks, along with the comparison of various application layer protocols, provides valuable insights into the suitability of these technologies for real-time data transmission in automated irrigation management systems.
In summary, real-time data transmission protocols and technologies play a vital role in the automation of irrigation management systems, enabling the efficient and reliable delivery of sensor data to the cloud for processing and decision-making. The exploration of MQTT and client-server IoT networks, along with the comparison of application layer protocols, highlights the importance of selecting suitable technologies based on factors such as data transmission speed, reliability, and energy efficiency. By leveraging these technologies, automated irrigation management systems can achieve seamless integration and contribute to the overall goal of enhancing agricultural water use efficiency and crop productivity.

3.5. Challenges and Solutions in Real-Time Data Transmission
Following the exploration of data collection, processing at the edge and fog, and automation in previous sections, we now turn to the critical aspect of real-time data transmission. While essential for automated irrigation management, this stage presents unique challenges that must be addressed to ensure system efficiency and reliability.
Obstacles in Real-Time Data Transmission
Agricultural environments present unique challenges for real-time data transmission, directly impacting the effectiveness of automated irrigation systems. Environmental factors can significantly disrupt wireless communication. Adverse weather conditions such as heavy rain, fog, and high winds can weaken or even block radio signals, leading to data loss and compromised system performance. Physical obstacles like trees, buildings, and uneven terrain further complicate signal propagation, creating reliability issues (Jukan et al., 2017; Yi & Ji, 2014; Zhang, Chang & Baoguo, 2018). These environmental challenges necessitate robust communication protocols and network architectures that can ensure consistent and reliable data flow.
In addition to environmental factors, technical limitations also present significant obstacles. Large-scale agricultural operations often demand long-distance data transmission, which can be hindered by the limited range of certain wireless communication protocols. Network congestion, occurring when multiple sensors transmit data concurrently, can lead to delays and potential data loss, further complicating real-time decision-making (Hameed et al., 2020). To mitigate these issues, researchers have investigated the potential of cognitive radio networks (CRNs) and dynamic spectrum access (DSA) for optimizing spectrum utilization and reducing interference (Righi et al., 2017; Shafi et al., 2018; Trigka & Dritsas, 2022). CRNs enable devices to intelligently sense and adapt to the surrounding radio environment, dynamically adjusting transmission parameters to avoid interference and improve communication efficiency. DSA, on the other hand, facilitates the dynamic allocation of unused spectrum, enhancing spectrum utilization and reducing congestion.
Furthermore, data security and privacy are paramount concerns in real-time irrigation systems. The sensitive nature of agricultural data, such as crop yields and farm management practices, necessitates robust security measures to prevent unauthorized access and data breaches (Gupta et al., 2020). Implementing secure communication protocols, authentication mechanisms, and encryption techniques is essential to protect data integrity and ensure the trustworthiness of the system.
Investigating Data Optimization Techniques
To enhance the efficiency and reliability of real-time data transmission in automated irrigation systems, researchers have explored a range of data optimization techniques. Data compression techniques aim to reduce the size of data packets transmitted over the network, minimizing bandwidth requirements and improving transmission speed (Rady et al., 2020; Karim et al., 2023). Lossless compression algorithms, such as Huffman coding and LZW, preserve data integrity while effectively reducing data size, ensuring that no information is lost during transmission (Cui, 2023). Lossy compression algorithms, such as JPEG and MP3, offer higher compression ratios but introduce a controlled level of data loss, which may be acceptable for certain applications where some loss of precision is tolerable (Karim et al., 2023). The choice between lossless and lossy compression depends on the specific application and the trade-off between data size and accuracy.
Data aggregation techniques provide another effective approach to optimize data transmission. By aggregating multiple sensor readings into a single representative value, such as average soil moisture or temperature, the number of transmissions can be significantly reduced, conserving bandwidth and energy resources (Cui, 2023). This is particularly beneficial in large-scale irrigation systems where numerous sensors are deployed across vast areas, generating substantial amounts of data. Additionally, data filtering techniques play a crucial role in improving data quality and reliability. Kalman filters and particle filters can effectively remove noise and outliers from sensor data, ensuring that only accurate and relevant information is transmitted and used for decision-making (Cui, 2023). This is essential for preventing erroneous data from influencing irrigation decisions and potentially leading to suboptimal water management.
Sensor calibration, drift correction, and fault detection are essential for maintaining data accuracy and reliability (Dos Santos et al., 2023). Regular calibration ensures that sensors provide accurate measurements over time, while drift correction techniques account for gradual changes in sensor readings due to environmental factors or aging. Fault detection mechanisms can identify and address sensor malfunctions or anomalies, preventing erroneous data from influencing irrigation decisions and potentially harming crops or wasting water.
Addressing the Challenges
Effectively addressing the challenges in real-time data transmission requires a multifaceted approach that encompasses environmental, technical, and data-related considerations. Implementing robust and adaptive communication protocols is crucial for overcoming interference and signal degradation caused by weather conditions and physical obstacles. Selecting appropriate protocols, such as LoRa or ZigBee, with suitable range and penetration capabilities can ensure reliable data transmission in challenging agricultural environments (Motamedi & Villányi, 2022). Additionally, employing techniques like frequency hopping and error correction codes can further improve communication resilience and mitigate data loss.
Optimizing network architecture is another key consideration. Deploying a distributed network architecture with edge and fog computing capabilities can significantly enhance data processing and transmission efficiency (Abdel Nasser et al., 2020; Tran et al., 2019). Edge devices can perform initial data processing and aggregation tasks, reducing the amount of data transmitted to the cloud and minimizing latency, while fog nodes can provide additional processing power and storage closer to the data source, enhancing scalability and reliability. This distributed approach alleviates the burden on the central cloud server and allows for more responsive and efficient irrigation management.
Data optimization techniques play a vital role in reducing bandwidth requirements and improving transmission efficiency. The choice of data compression, aggregation, and filtering techniques should be tailored to the specific requirements of the irrigation system, considering factors such as data type, accuracy needs, and available bandwidth. By carefully selecting and implementing these techniques, the overall performance and effectiveness of real-time irrigation systems can be significantly enhanced, leading to more sustainable water management practices and improved agricultural productivity.
By addressing these challenges and implementing appropriate solutions, real-time data transmission can become a reliable and efficient component of automated irrigation systems, contributing to the overall goal of achieving sustainable and productive agriculture in the face of growing food demands and water scarcity.
n summary, real-time data transmission protocols and technologies play a vital role in the automation of irrigation management systems, enabling the efficient and reliable delivery of sensor data to the cloud for processing and decision-making. The exploration of MQTT and client-server IoT networks, along with the comparison of application layer protocols, highlights the importance of selecting suitable technologies based on factors such as data transmission speed, reliability, and energy efficiency. By leveraging these technologies, automated irrigation management systems can achieve seamless integration and contribute to the overall goal of enhancing agricultural water use efficiency and crop productivity.


</previous_sections>

</documents>
<instructions>


Use the information provided in the <documents> tags to write the next subsection of the research paper, following these steps:
1. Review the overall intention of the research paper, specified in the <review_intention> tag. Ensure the subsection you write aligns with and contributes to this overall goal.
2. Consider the specific intention for this subsection of the paper, stated in the <section_intention> tag. The content you write should fulfill this purpose. 
3. Use the title provided in the <subsection_title> tag as the heading for the subsection. 
4. Address each of the points specified in the </subsection_point_Point *> tags:
   a) Make a clear case for each point using the text provided in the "point" field.
   b) Support each point with evidence from the research papers listed in the corresponding "papers to support point" field.
   c) When citing a paper to support a point, include inline citations with the author name(s) and year, e.g. (Smith et al., 2020; Johnson and Lee, 2019; Brown, 2018). Cite all papers that strengthen or relate to the point being made.
   d) While making a point and citing the supporting papers, provide a brief explanation in your own words of how the cited papers support the point.
5. Ensure that both of the points from the <subsection_point> tags are fully addressed and supported by citations. Do not skip or combine any points.
6. After addressing the specified points, wrap up the subsection with a concluding sentence or two that ties the points together and relates them back to the <section_intention>.
7. Review the <Previous_sections> of the paper, and ensure that the new subsection you have written fits logically and coherently with the existing content. Add transition sentences as needed to improve the flow.
8. Proofread the subsection to ensure it is clear, concise, and free of grammatical and spelling errors. Maintain a formal academic tone and style consistent with the rest of the research paper.
9. Format the subsection using Markdown, including the subsection heading (using ## or the equivalent for the document), inline citations, and any other formatting needed for clarity and readability.
10. If any information is missing or unclear in the provided tags, simply do your best to write the subsection based on the available information. Do not add any information or make any points not supported by the provided content. Prioritize fully addressing the required points over hitting a specific word count.

The output should be a complete, well-organized, and properly cited subsection ready to be added to the research paper.

Begin your answer with a brief recap of the instructions stating what you will to optimize the quality of the answer. Clearly and briefly state the subsection you'll be working on and the points you'll be addressing. Then proceed to write the subsection following the instructions provided. 

Critical: 
- Do not include a conclusion or summary as the entry is in the middle of the document. Focus on addressing the points and supporting them with evidence from the provided papers. Ensure that the subsection is well-structured, coherent, and effectively contributes to the overall research paper.
- The subsection we are focusing on is: 3.6. IoT Network Architectures and Variable Rate Irrigation (VRI) for Real-Time Irrigation
- No need for sub-sub-sections. just provide paragraphs addressing each point. They should transition fluidly and narurally into each other.
- Ensure that the content is supported by the provided papers and that the citations are correctly formatted and placed within the text.
- Do not repeat content from the previous sections. Ensure that the information provided is new and relevant to the subsection being written.



</instructions>


- DOI: https://doi.org/10.1016/j.asr.2023.02.025
  analysis: '>'
  apa_citation: Miralles, P., Thangavel, B., Scannapieco, C. F., Jagadam, C., Baranwal,
    P., Faldu, B., .. González-Rodríguez, H. (2023). A critical review on the state-of-the-art
    and future prospects of machine learning for Earth observation operations. Advances
    in Space Research, 71, 4959-4986. http://www.sciencedirect.com/science/article/pii/S0273117723002709
  authors:
  - Pablo Miralles
  - Kathiravan Thangavel
  - Antonio Fulvio Scannapieco
  - Nitya Jagadam
  - Prerna Baranwal
  - Bhavin Faldu
  - Ruchita Abhang
  - Sahil Bhatia
  - Sebastien Bonnart
  - Ishita Bhatnagar
  - Beenish Batul
  - P. Nagendra Prasad
  - Héctor Ortega-González
  - Harrish Joseph
  - Harshal More
  - Sondes Morchedi
  - Aman Kumar Panda
  - Marco Zaccaria Di Fraia
  - Daniel Wischert
  - Daria Stepanova
  citation_count: 9
  explanation: This review covers the current state of the art, future prospects,
    and the potential of machine learning in Earth Observation Operations. It approaches
    the topic by dividing it into cross-disciplinary domains including data collection,
    transmission, processing, and algorithms. The authors have focused on gathering
    the most relevant, recent, and impactful contributions to the field. For each
    of the topics, they have identified the most pressing challenges and proposed
    solutions to advance the state-of-the-art in the field.
  extract_1: The continuing Machine Learning (ML) revolution indubitably has had a
    significant positive impact on the analysis of downlinked satellite data. Other
    aspects of operations are now starting to surface.
  extract_2: Machine Learning is becoming more prevalent in our daily lives, whether
    it is in the form of personalized newsfeeds, shopping online or streaming movie
    recommendations, or even mapping tools that help us avoid traffic jams. On a larger
    scale, ML is already having a significant impact on healthcare, banking, agriculture,
    and a variety of other industries, and its impact is expected to grow quickly
    in the coming years.
  full_citation: '>'
  full_text: '>

    Skip to main content Skip to article Journals & Books Search Register Sign in
    Brought to you by: University of Nebraska-Lincoln View PDF Download full issue
    Outline Abstract Keywords Abbreviations 1. Introduction 2. Machine learning in
    Earth observation mission planning 3. Machine learning in Earth observation guidance,
    navigation and control 4. Machine learning in Earth observation fault detection,
    isolation, and recovery 5. Machine learning in Earth observation on-board image
    processing 6. Machine learning in resource-constrained Earth observation platforms
    7. Machine learning standardization and issues in Earth observation operations
    8. Discussion & conclusion Declaration of Competing Interest Acknowledgements
    References Show full outline Cited by (10) Figures (6) Tables (2) Table 1 Table
    2 Advances in Space Research Volume 71, Issue 12, 15 June 2023, Pages 4959-4986
    Review A critical review on the state-of-the-art and future prospects of machine
    learning for Earth observation operations Author links open overlay panel Pablo
    Miralles a c, Kathiravan Thangavel b c i, Antonio Fulvio Scannapieco c, Nitya
    Jagadam c, Prerna Baranwal c d, Bhavin Faldu c, Ruchita Abhang c e, Sahil Bhatia
    c f, Sebastien Bonnart c, Ishita Bhatnagar c g, Beenish Batul c h, Pallavi Prasad
    c, Héctor Ortega-González c, Harrish Joseph c i, Harshal More c i, Sondes Morchedi
    c, Aman Kumar Panda c j, Marco Zaccaria Di Fraia c k, Daniel Wischert c, Daria
    Stepanova c l Show more Add to Mendeley Share Cite https://doi.org/10.1016/j.asr.2023.02.025
    Get rights and content Abstract The continuing Machine Learning (ML) revolution
    indubitably has had a significant positive impact on the analysis of downlinked
    satellite data. Other aspects of the Earth Observation industry, despite being
    less susceptible to widespread application of Machine Learning, are also following
    this trend. These applications, actual use cases, possible prospects and difficulties,
    as well as anticipated research gaps, are the focus of this review of Machine
    Learning applied to Earth Observation Operations. A wide range of topics are covered,
    including mission planning, fault diagnosis, fault prognosis and fault repair,
    optimization of telecommunications, enhanced GNC, on-board image processing, and
    the use of Machine Learning models on platforms with constrained compute and power
    capabilities, as well as recommendations in the respective areas of research.
    The review tackles all on-board and off-board applications of machine learning
    to Earth Observation with one notable exception: it omits all post-processing
    of payload data on the ground, a topic that has been studied extensively by past
    authors. In addition, this review article discusses the standardization of Machine
    Learning (i.e., Guidelines and Roadmaps), as well as the challenges and recommendations
    in Earth Observation operations for the purpose of building better space missions.
    Previous article in issue Next article in issue Keywords Artificial IntelligenceAstrionicsEarth
    ObservationEdge ComputingMachine LearningNeural NetworkRemote SensingState-of-the-art
    Abbreviations AIArtificial IntelligenceMLMachine LearningDLDeep LearningFDIRFault
    Detection Isolation and RecoveryGNCGuidance Navigation and ControlNNNeural NetworkCNNConvolutional
    Neural NetworkDNNDeep Neural NetworkANNArtificial Neural NetworkBNNBinarized Neural
    NetworkBNBayesian NetworkDBNDynamic Bayesian NetworkNASANational Aeronautics and
    Space AdministrationESAEuropean Space AgencyOBCOn-Board ComputerEOEarth ObservationRDFRandom
    Decision ForestBTBayesian ThresholdingSVMSupport Vector MachineCOTSCommercial
    off-the-shelfSwaPSize Weight and PowerLIDARLight Detection and RangingSoCSystem
    on a ChipFPFalse PositivesCCSDSConsultative Committee for Space Data SystemsGNSSGlobal
    Navigation Satellite SystemGPSGlobal Positioning SystemPIProportional - IntegralPIDProportional
    - Integral - DerivativeAODSAttitude Orbital Determination SystemRLReinforcement
    LearningEKFExtended Kalman FilterRFRandom ForestAOCSAttitude and Orbit Control
    SystemK-NNk-Nearest NeighbourSOMSelf-Organizing MapOOSOn Orbit ServicingARPHAAnomaly
    Resolution and Prognostic Health Management for AutonomyDBSCANDensity-Based Spatial
    Clustering of Applications with NoiseEPSElectrical Power SystemSSHMSoftware and
    Sensor Health ManagementRDARegularized Discriminant AnalysisAROWAdaptive Regularization
    of Weight VectorSCWSoft Confidence-WeightedCNESCentre national d''études spatiales
    (The National Centre for Space Studies)ESOCEuropean Space Operations CentreRBFRadial
    Basis FunctionDLRDeutsches Zentrum für Luft- und Raumfahrt (German Aerospace Center)OC-SVMOne-Class
    Support Vector MachineNHERDNormal Gaussian HerdingTHEMISThermal EMission Imaging
    SystemIPEXIntelligent Payload EXperimentHyspIRIHyperspectral Infrared ImagerMODISModerate-Resolution
    Imaging SpectroradiometerPSNRPeak Signal to Noise RatioSSIMStructural Similarity
    IndexFPGAField Programmable Gate ArrayCALICContext-Based, Adaptive, Lossless Image
    CodecIWTIntegral Wavelet TransformPHPeano-HilbertLVQLearning Vector QuantizationTFTensorFlowSARSynthetic
    Aperture RadarROEWARatio of Exponential Weighted AverageJPEGJoint Photographic
    Experts GroupSTP-H5-CSPSpace Test Program-Houston-5-Cubesat Service protocolNASNeural
    Architecture StructureCPUCentral Processing UnitGPUGraphics Processing UnitVPUVisual
    Processing UnitTPUTime Processing UnitTTQTrained Ternary QuantizationRTRadiation
    TolerantMNASMobile Neural Architecture SearchKTKnowledge TransferKDKnowledge DistillationCSPCubesat
    Service ProtocolSBCSpaceBorne ComputerMNISTModified National Institute of Standards
    and Technology databaseNISSTCNational Information Security Standardization Technical
    CommitteeDINDeutsches Institut für Normung (German Institute of Standardization)DKEDeutschen
    Kommission Elektrotechnik Elektronik Informationstechnik (German Commission for
    Electrical, Electronic and Information Technologies)EUEuropean UnionECEuropean
    CommissionSMEsSmall and Medium EnterprisesDEELDEpendable and Expandable LearningEOSDISEarth
    Observation Systems’ Data Information SystemsSGACmSpace Generation Advisory CouncilSSPGSmall
    Satellite Project GroupDRLDeep Reinforcement LearningGISGeographic Information
    SystemsXAIExplainable AI 1. Introduction Earth Observation (EO) satellites have
    allowed us to look at our planet at a scale previously unattainable to humankind.
    From the vantage point of space, it becomes easier to monitor everything about
    our lives on a very large scale, such as our impact on the planet’s ecology (Guo
    et al., 2017) and extent of specific facilities all around the world (Pan et al.,
    2021). This capability has been and continues to be invaluable to understanding
    the world around us and enforcing regulations vital to the well-being of people
    all over the globe. However, as access to space becomes ever more affordable,
    EO assets multiply at an increasingly faster pace (Belward and Skøien, 2015).
    Moreover, EO Operations - the sequence of activities that take place in managing
    an EO spacecraft from its launch to its demise - keep growing in number and complexity
    as new assets are put into orbit. These trends could soon lead to a situation
    where available work-power becomes a limiting factor in the deployment of EO systems.
    Orchestrating these operations is, at its core, a control and data processing
    problem - from taking in and analyzing large volumes of telemetry from all EO
    platforms to taking into account their complex dynamics and evolving mission profiles
    when utilizing them. Artificial Intelligence (AI) is becoming more prevalent in
    our daily lives, whether it is in the form of personalized newsfeeds, shopping
    online or streaming movie recommendations, or even mapping tools that help us
    avoid traffic jams. On a larger scale, AI is already having a significant impact
    on healthcare, banking, agriculture, and a variety of other industries, and its
    impact is expected to grow quickly in the coming years. Machine Learning (ML),
    a subset of Artificial Intelligence (AI) as shown in Fig. 1 wherein machines learn
    from data, has been used in a variety of space-related applications. In our review,
    we considered that ML is a subfield of AI for clarification. Deep learning (DL)
    is a subfield of machine learning. Download : Download high-res image (117KB)
    Download : Download full-size image Fig. 1. AI, ML, DL relationship (Zhang et
    al., 2021). Human analysts may miss patterns and trends hidden within massive
    amounts of data, but ML can find them. ML, on the other hand, can uncover patterns
    and trends hidden inside massive amounts of data that are invisible to human researchers.
    Modern Earth Observation systems collect a massive amount of data from a variety
    of sensors with varying temporal, spatial, and spectral resolutions. Because of
    its complexity, it necessitates the use of innovative procedures and methods to
    extract useful information. Fig. 2 represents a typical machine learning process.
    Download : Download high-res image (110KB) Download : Download full-size image
    Fig. 2. Machine Learning workflow (Pant, 2019). 1.1. Machine learning for Earth
    observation ML has taken the data processing world by storm, with one success
    story after another. From object detection and classification (Krizhevsky et al.,
    2012) to natural language processing (Wang, 2021) and nonlinear control (Mnih
    et al., 2013), the capacity of these algorithms to solve different types of problems
    has been nothing short of awe-inspiring. For the purposes of the present review,
    we define ML algorithms as those whose performance critically depends on and generally
    improves with exposure to real-world data of the problem to be solved. So far,
    these techniques have concentrated mostly on the analysis of downlinked imagery
    due to the larger availability of computing power and ease of deployment relative
    to on-board applications, as well as its relatedness to computer vision, one of
    the traditional strong suits of ML. But applications to other aspects of operations
    are now starting to surface. The present review explores the contexts for which
    these applications have been proposed or in which they have been applied, exposes
    the possibilities that they open up and risks that must be avoided, and illustrates
    gaps in research that we believe should be addressed by the Earth Observation
    community. As shown in Fig. 3, ML will enhance space exploration operations in
    a variety of ways, particularly for Earth observation missions. Download : Download
    high-res image (383KB) Download : Download full-size image Fig. 3. Potential application
    of ML for earth observation mission. As illustrated in Fig. 3, the manuscript
    discusses the state-of-the-art as well as the future prospects of ML in Mission
    Planning (section 2), GNC (section 3), FDIR (section 4), and on-board image processing
    (section 5). In section 6, we also discussed the useful aspect of using ML models
    in EO operations. We examine how operators might make the most of their limited
    on-board resources by properly optimizing the usage of ML model resources, describing
    a variety of software and hardware solutions geared to that end. In Section 7,
    we also discuss recent initiatives within the space sector to standardize and
    guide the deployment of ML models, as well as the kinds of considerations a designer
    must make in order to avoid frequent errors with this technology. Our objective
    is to give EO Operators a thorough, if not exhaustive, assessment of the current
    situation with regard to ML applications in their area of expertise. The review
    connects EO operators and proponents of ML algorithms for EO Operations problems
    in an effort to spark discussion and stimulate additional application suggestions
    and demonstrations. With one important exception, the review covers all on-board
    and off-board applications of ML to EO but leaves out all post-processing of payload
    data on the ground, a subject that has been intensively researched by other researchers.
    The optimization of tracking, telemetry, and command is another subject we pass
    over. Despite the fact that this was initially our intention, we discovered an
    outstanding and current review by Fourati and Alouini (Fourati and Alouini, 2021).
    We invite interested readers to check out the excellent paper rather than pointlessly
    duplicating their work. This article has been reviewed and updated in comparison
    to the conference paper presented at IAC in 2021. This research, which is highly
    needed in present space industry, was conducted by a group of volunteers from
    the Small Satellite Project Group (SSPG) of SGAC. SGAC is a non-profit, non-governmental
    organization with over 16,000 members dedicated to the peaceful uses of space.
    There are over a hundred active volunteers, in addition to eleven project organizations,
    including the SSPG. The SSPG focuses on how small satellites are utilized in the
    space industry and how they can assist humanity in realizing space''s full potential.
    2. Machine learning in Earth observation mission planning There are many constraints
    to mission planning. Some relate to the target area: It needs to be under the
    satellite and illuminated by the sun at capture time (orbit and time-dependent);
    clouds are to be avoided (weather dependent); the requester may set a deadline
    and/or a priority. Others relate to the satellite, such as limited memory capacity;
    limited transmission capability; reduced communication opportunities with the
    ground antennas; multiple sensors to choose from; and limited maneuverability
    to skew the observation angle and reach areas not directly flown over. All of
    these parameters make optimal scheduling of observations a highly combinational
    problem for a mission that supports multiple independent requests, and it is even
    more complex when they are accomplished by a constellation of satellites. ML proposes
    a series of algorithms that may find better solutions than non-learning algorithms
    or do so more efficiently. There are many different formulations of the observation
    scheduling problem, taking into account different subsets of the constraints presented
    in the previous paragraphs, adapted for different types of missions and ground
    segments. 2.1. Classical approaches Non-ML algorithms to the satellite scheduling
    problems can be classified into two categories: Exact and Heuristic methods (X.
    Wang et al., 2021). Exact methods typically consist of a combination of branch
    and bound methods and mixed-integer linear programming. These methods are computationally
    costly and can become intractable for moderately sized constellations. Heuristic
    methods use an approximated rule to guide the construction of a solution. Greedy
    algorithms construct a solution by gradually choosing the best action at every
    decision step according to some metric, without regard as to how the overall sequence
    of decisions plays out. Other heuristic methods include backtracking through constraint
    programming and search algorithms. Other forms of search include hill-climbing
    or squeaky-wheel optimization, where the geometry of the optimization functions
    is exploited to accelerate the search process. Globus et al. (Globus et al., 2003)
    compare multiple algorithms such as genetic, simulated annealing, squeaky wheel
    and hill-climbing on a problem with one or two satellites. Evolutionary or genetic
    algorithms simulate processes akin to biological evolution to optimize candidate
    solutions according to a hand-crafted fitness function. Mansour et al. (Mansour
    and Dessouky, 2010) studied the performances of a genetic algorithm for a single
    satellite with limited memory and multiple instruments and imaging modes. Li et
    al. (Li et al., 2014) explore genetic algorithms in order to provide scheduling
    in real-time, optimizing the transmission path towards the user. Simulated annealing
    imitates the annealing processes found in metals exposed to high temperatures,
    and it forms the basis for another branch of heuristic algorithms. The simulated
    annealing seems to provide better results, confirmed by Globus et al. (Globus
    et al., 2003) in a complete multi-satellite formulation of the problem, including
    satellite agility and priorities. Lastly, multi-agent systems simulate interactions
    between simple agents representing part of the systems to determine an optimal
    policy. Bonnet et al. (Bonnet et al., 2015) use a self-adaptive multi-agent system
    for real-time and robust adaptation of a multi-satellite problem, including request
    priorities. 2.2. ML-based approaches ML-based approaches can exploit the statistical
    distribution of typical problem settings to accelerate the finding of good solutions
    to the mission planning problem. Wang et al. (X. Wang et al., 2021) present a
    comprehensive review of publications on the agile observation scheduling problem,
    including ML and non-ML approaches. The authors classify approaches along multiple
    axes such as time continuous and discrete-time model, type of solving method and
    also other features such as autonomy, and multi-objective profit function. Neural
    Networks (NNs) are explored by Wang et al. (Wang et al., 2019) in order to provide
    immediate results for a multi-satellite mission using Deep Reinforcement Learning
    (DRL). Peng et al. (Peng et al., 2018) apply recursive NNs in a sequential decision-making
    process in order to achieve low scheduling computation time and high performance
    when compared to a deterministic resolution. Recursive NNs allow the model to
    condition current decisions on past inputs, instead of depending exclusively on
    the present inputs to the system, providing the model with a sort of memory. We
    have not found any applications of Transformers to this problem, a sequence modeling
    technique from the deep learning research field that has shown excellent results
    in other sequential tasks like language modeling and even in image processing
    tasks. Neuroevolutionary techniques combine the advantages of neural models and
    evolutionary algorithms. Du et al. (Du et al., 2020) leverage a prediction model
    trained by a Cooperative Neuro-Evolution of Augmenting Topologies algorithm in
    order to filter tasks to be scheduled according to the probability to be fulfilled
    before scheduling using genetic algorithms. DRL uses NNs as function approximators
    to approximate hard to determine functions in dynamic programming. This has enabled
    groundbreaking achievements in other control and scheduling problems like playing
    Go or automated driving. Despite its potential, it has not been extensively applied
    to this problem set. Liu (Liu, 2020) applies Proximal Policy Optimization, a method
    of the DRL literature, to mission planning for a single satellite. Unfortunately,
    they do not compare performance to other methods or extend it to a multi-satellite
    setting. Yuchen et al. offer a unique online strategy that combines a Q-network
    with a pruning technique to address the observation sequence planning problem.
    The proposed scheme''s goal is to generate an observation sequence based on the
    Q-learning heuristic rule and increase the neural network''s efficiency in optimization.
    A Q-network-based mission-planning algorithm for the operation of the EO satellite
    is shown in Fig. 4. It shows the suggested algorithm''s overall workflow (Liu
    et al., 2021). Download : Download high-res image (144KB) Download : Download
    full-size image Fig. 4. ML-based mission planning algorithm (Liu et al., 2021).
    Hadj-Salah et al. (Hadj-Salah et al., 2020, Hadj-Salah et al., 2019) explore the
    application of Actor-Critic (A2C), a DRL algorithm, to the mission planning problem.
    They compare it to random planning and a planning heuristic that compromises between
    greedy and long-term planning. Their models are trained in a simulated mission
    planning environment and then executed in a real test scenario. Their long-term
    version of A2C shows better performance than the heuristic algorithm. In their
    later publication, they augment the training process with techniques from the
    domain randomization and transfer learning literature, meant to increase robustness
    to the gap experienced when passing from the simulated training scenario to the
    real validation scenario. 2.3. Recommendations Mission planning is a very rich
    problem that has been explored for many years using machine learning amongst other
    solutions. Comparing the performances of algorithms presented in different papers
    is not a suitable path because each presents its own definition of the problem,
    with a unique set of constraints, different mission characteristics, variable
    satellite capabilities and potentially incompatible metrics. For instance, a lot
    of schedulers take into account satellite memory, limiting the number of observations
    until a ground station is visible, but few of them also make sure the ground station
    is available for communication with the satellite and not busy communicating with
    another one of the constellations. Song et al. (Song et al., 2020) introduce a
    framework in order to facilitate future comparisons but additional work on model
    standardization is needed before results from different studies can be compared.
    We observe a shifting trend in algorithms applied to this problem over the years
    from genetic or annealing to ML approaches such as NNs. Unfortunately, we found
    no sources comparing the performances of genetic and ML-based schedulers on a
    single problem formulation. Standardizing project formulations, constraints set,
    and optimization metrics seem to be a necessary step for sustainable collaborative
    research in this field. Relying on Consultative Committee for Space Data Systems
    (CCSDS) published standards and models could be a first step in the direction
    of a unified approach. 3. Machine learning in Earth observation guidance, navigation
    and control GNC, describe the set of operations needed to move a satellite platform
    or any other vehicle. The guidance relates to planning paths from a current state
    to the desired state. Navigation is the determination of the present state. Control
    is the correct use of spacecraft actuators, such as an engine, to execute the
    desired plan. 3.1. Classical approaches Two main tasks need to be achieved by
    a GNC system: determination of the current state, which is an estimation task,
    and use of the spacecraft’s actuators to go from the current state to the desired
    state, which is a control task. Spacecraft control is typically subdivided into
    at least two different granularity levels, guidance and control, where guidance
    is the high-level control of the spacecraft from a current dynamic state to a
    future one. A guidance module may output the sequence of feasible dynamic states
    necessary to achieve a new orbit from the required orbit. EO Satellite maneuvers
    are often planned and optimized on the ground, and the onboard guidance modules
    are minimal. For the control task, a number of control schemes are used, most
    notably controllers from the robust control literature such as H∞ controllers.
    As for navigation, spacecraft state is typically determined via variants of the
    Kalman Filter (KF), such as the Extended Kalman Filter (EKF)or the Unscented Kalman
    Filter (UKF). These methods are model based, that is, they depend on an explicit
    model of spacecraft dynamics for their calculations. Fuzzy controllers have been
    proposed as a possible improvement to the classical approach. The literature contains
    several works where GNC and Attitude and Orbit Control System (AOCS) controllers
    based on fuzzy logic are compared to their traditional counterparts. For instance,
    Wu et al. (Wu et al., 2001) studied the fuzzy logic controller with the X-38 re-entry
    vehicle. ESA also investigated the usage of fuzzy logic controllers to carry out
    Geostationary Equatorial Orbit (GEO) rendezvous autonomously (Ortega, 1995) to
    aid in in-orbit manufacturing. As another example, in (Cheng et al., 2009), a
    simulation of ROCSAT-1 / FORMOSAT-1′s attitude controller is carried out, where
    the classical setup of a Proportional - Integral (PI) pitch axis controller and
    Proportional - Integral - Derivative (PID) roll/yaw axis controller is replaced
    with two fuzzy controllers initially, and a single consolidated fuzzy controller
    afterwards, yielding considerable improvements against interference as well as
    a lower steady-state error. Nevertheless, despite the body of research backing
    up their effectiveness, there is no widespread use of fuzzy logic GNC controllers
    for space missions. 3.2. ML-based approaches Izzo et al. (Izzo et al., 2018) present
    a survey of Artificial Intelligence applied to GNC which, is not focused on EO
    applications, can nonetheless be useful to practitioners. The survey contains
    a section focusing on ML approaches, on top of other AI approaches such as evolutionary
    algorithms. In another publication (Izzo and Öztürk, 2021), Izzo and Öztürk leveraged
    DRL to plan near-optimal real-time computation of low-thrust transfers. They also
    suggest a new method to generate training data for such problem settings. Although
    originally designed for Earth-Venus transfers, their solution is applicable to
    all low-thrust transfers, but the data generation algorithm and optimality comparisons
    are problem-dependent. ML excels in problems where no structured pre-existing
    model can be exploited. That is not the case for the GNC problem, where the general
    form of the dynamics governing spacecraft are well known and solvable. It is,
    however, the case for visual-based GNC, as no model exists for relating camera
    inputs to dynamic state or control actions. For this reason, much research on
    ML-powered GNC has focused on visual-based GNC (Frédéric Férésin et al., 2021)
    for autonomous rendezvous. This, however, is not directly relevant to the EO Operations
    community, who are unlikely to engage in autonomous docking as providers. An interesting
    streak of research looks into applications of ML to processing visual navigation
    sensors, particularly Earth and Sun sensors and star trackers. Koizumi et al.
    (Koizumi et al., 2018) present a dl-powered Earth sensor capable of determining
    the attitude of the spacecraft by processing the images captured by a Commercial-Off-The-Shelf
    (COTS) camera. It runs a real-time image processing algorithm to extract features
    into the images separating them into distinct feature sets using DL techniques.
    The features sets are then compared to the preloaded data sets to determine the
    position of the spacecraft relative to Earth in the 3D plane. The primary advantage
    of the system is the use of a COTS component and a single board computer. Another
    research thread explores the combination of ML techniques and fuzzy controllers
    (Kim et al., 2016). Classical fuzzy controllers rely on manually set parameters
    that define behavior. This research thread attempts to leverage ML techniques
    to learn the optimal value for these parameters from a training dataset. These
    have the advantage of interpretability - their reliance on explicitly (if fuzzily
    enforced) rules means that they remain grounded on human-interpretable system
    models. Joghataie’ PhD. thesis (Joghataie, 1994) suggests the development of a
    neuro-fuzzy controller, wherein the tuning of the fuzzy logic is performed automatically
    by using neural networks in a hybrid approach. Azarbad (Azarbad et al., 2014)
    suggests a model applied to Global Positioning System (GPS) systems that outperform
    the classical fuzzy controller. A simulation study on MATLAB was done by Baranwal
    et al. in (Baranwal et al., 2018), comparing the performance of a PID controller
    and a fuzzy PID controller for a student satellite team. The EKF-based fuzzy controller
    outperformed the classical controller. The study was done on a 3U CubeSat. Further
    research can be done comparing these controllers with ML-based approaches. We
    have been unable to find a comparison between the three types of controllers,
    i.e., neuro-based controller, fuzzy controller and a hybrid model, as implementation
    details in different studies differ, complicating their comparison. Wang et al.
    (Wang et al., 2019) have developed a DL framework that stabilizes the spacecraft
    using a real-time torque control. It is initially trained in a simulation environment,
    enabling it to learn the required torque output and extrapolate it for unknown
    disturbances. It performs better than a conventional PID controller, as it can
    correct the attitude after unknown disturbance rather than repeatable corrections.
    A similar system is proposed by Yadava et al. (Yadava et al., 2018). They propose
    an Attitude Orbital Determination System (AODS) system that determines the position
    of the spacecraft, taking inputs from the magnetometers (magnetic vectors) and
    sun sensor (sun vector) along with GPS data (position and velocity vector), and
    determines the ideal attitude depending on the position using a neural network.
    The required torque calculations are made and sent to the Reinforcement Learning
    (RL)-based controller to make the required adjustments. The system performs better
    than classical PID controllers as it consumes less computation power for subsequent
    cycles as the algorithm learns. 3.3. Recommendations Most ML for GNC applications
    in the space sector seem to have been explored in the context of space logistics
    and space exploration rather than Earth Observation. Although guidance and control
    for EO platforms are simple compared to these applications, we believe there is
    a potential to adopt some of these technologies. Attitude determination is a domain
    where EO operations have high requirements. We believe that vision-based processing
    applied to this area is just getting started, and that use of more refined neural
    architectures could enable improvements in performance or resource consumption
    compared to current approaches. 4. Machine learning in Earth observation fault
    detection, isolation, and recovery Satellites performing EO tasks have stringent
    requirements in terms of accuracy, continuity and stability of payload operations.
    To this end, Fault Detection, Isolation and Recovery (FDIR) is focused on developing
    and improving tools to guarantee and maintain reliable spacecraft operations.
    FDIR describes a set of engineering disciplines focused on safeguarding and maintaining
    the spacecraft in nominal operating conditions. The target of these disciplines
    is represented by faults, irregular occurrences and processes with the potential
    to disrupt the mission up to the point of failure. ML can be an extremely powerful
    tool for FDIR. Indeed, the core capability provided by ML is pattern detection.
    Therefore, ML can be used both to detect anomalies in the telemetry or outputs
    from any subsystem (diagnosis) and identify signs indicating an incipient fault
    (prognosis). This section presents relevant ML literature for four significant
    sub-topics: fault detection, fault diagnosis, recovery, and fault avoidance. 4.1.
    Fault detection Failure detection deals with identifying the presence of faults
    and their rates of occurrence. 4.1.1. Classical approaches In classical approaches,
    the recognition of failures is mainly based on constant thresholds and fixed logic
    diagrams defined during the design process. (Wertz and Larson, 1999) One of the
    key issues with classical fault detection is model brittleness. As fault detection
    schemes are based on hardcoded thresholds, these models are easily disrupted by
    noise and deviations from theoretical assumptions. 4.1.2. ML-based approaches
    An example of an ML-based solution to the issue of model brittleness can be found
    in a paper by Jaekel et al. (Jaekel and Scholz, 2015). This work uses Self-Organizing
    Maps (SOM), an unsupervised variant of Artificial Neural Networks (ANNs), for
    the detection of failures in dexterous manipulators for On-Orbit Servicing (OOS).
    SOM manages to adapt to the idiosyncrasies of incoming data in a simulated environment
    and thus show increased robustness to input variations with respect to traditional
    methods. They can also deal with uncertainties and noise in values. A dexterous
    manipulator on a maintenance satellite captures a client spacecraft having 7 degrees
    of freedom. They inject sensor failures, including sensor outage and drift, during
    arm operations and the results show that SOMs are a robust approach as temporary
    fluctuations in the sensor, outliers and peaks do not unnecessarily stop the current
    operation. But the computational load is relatively high and needs to be optimized
    to reduce system reaction time. The authors suggest improving the precision and
    speed of the method by adding more information from redundant sensors. Ranasinghe
    et al. provides a comprehensive analysis of FDIR (Ranasinghe et al., 2022). Fuertes
    et al. (Fuertes et al., 2018) discuss ML-based fault detection using NOSTRADAMUS,
    an algorithm developed by the Centre National des Études Spatiales (CNES). NOSTRADAMUS
    uses a One-Class - Support Vector Machine (OC-SVM), a common algorithm used to
    detect outliers, to detect the presence of an anomaly in telemetry data. NOSTRADAMUS
    runs on the ground segment, analyzing telemetry as it is downlinked from the satellite.
    The performance of NOSTRADAMUS is compared to algorithms inspired by Novelty Detection
    (ESOC), Project Sybil (Ivano Verzola et al., 2016), and ATHMoS (DLR) (O’Meara
    et al., 2016). NOSTRADAMUS is the best option because it has a 100 % detection
    rate and the minimum false alarm rate (5 percent). The Novelty-inspired algorithms
    show the best performance of false alarm reduction, with 85 percent of valid detections
    and fewer than 1 % of false alerts. CNES is working on an on-board version of
    this algorithm, as well as on extensions to the ground-based variant for processing
    of multiple telemetry variables based on dictionary learning approaches (Pilastre,
    2020). In conversations during their collaboration with this project, CNES teams
    signaled that explainability was a crucial aspect of any technique. Being able
    to understand the features of input data that signal a fault lets the operational
    teams understand the context of their satellite and know which actions must be
    taken to remedy the situation - this is comparable in value to being able to detect
    the anomaly in the first place. Project Sybil is a collaborative effort by DLR''s
    Columbus Flight Control team, ESA''s Advanced Mission Concept Section, and Ludwig
    Maximilians Universitat to apply an outlier identification algorithm to the Columbus
    telemetry database. After data segmentation and computation of its respective
    characteristics, it uses the Density-Based Spatial Clustering of Applications
    with Noise (DBSCAN) technique to preprocess the data. It is an unsupervised clustering
    method that divides data into a variable number of clusters based on their relative
    distances. Following this grouping, clusters with less than 5 % of the population
    data are discarded on the assumption that they may indicate a non-nominal working
    mode in the learning dataset. Project Sybill allows for higher mission performance
    by reducing downtime caused by onboard system failures. 4.2. Fault diagnosis Fault
    detection identifies the presence of faults and performance degradation, while
    fault diagnosis identifies the root causes of these events. 4.2.1. Classical approaches
    Though traditionally, fault diagnosis has been achieved by human operators at
    the ground through comparison with hardcoded hand-tuned thresholds. It is difficult
    to deal with large amounts of data using this approach. Iverson et al. (Iverson,
    2008) point out that for efficient utilization of the data, there is a need for
    an autonomous approach that eliminates the necessity of human experts for diagnosis.
    4.2.2. ML-based approaches Ricks et al. (Ricks, 2021) examine fault detection
    and identification for a satellite Electrical Power System (EPS) testbed using
    BNs compiled to arithmetic circuits. BNs can be used to model partial knowledge
    and uncertainty by identifying the system state based on probabilistic relationships
    between a set of system variables at a certain instance in time (Meβ, 2019). The
    proposed methods work for complex systems exhibiting both continuous and discrete
    behavior. The discussed techniques can handle abrupt continuous faults particularly
    well, which often pose problems. For example, a nominal value region is not enough
    to detect offset faults if they are small enough - the paper uses cumulative sums
    to deal with these. Additionally, “stuck” faults may be difficult to detect in
    low-noise conditions since fluctuations might be infrequent. The authors employ
    a tunable time interval which will mark the sensor as working abnormally after
    it expires without the readings having made any change. Different types of nodes,
    modeling different behaviours, are grouped to defined sensors and components,
    which in turn are assembled to create the entire EPS functional FDIR structure.
    BNs have also been used by Schumann et al. (Schumann et al., 2011) to detect onboard
    failures and perform diagnoses. A Software and Sensor Health Management (SSHM)
    system is developed for a simple GNC structure of a small satellite using BNs
    that collect data from hardware sensors, software quality signals, software status
    signals and data from the operating system in order to determine whether any failures
    exist, what the most likely causes are, and to provide a statistically sound quality
    measure of the diagnose. The developed SSHM system requires no modification to
    the satellite subsystems for which it performs FDIR - it just uses the sensor
    data outputs. That way, model-level and code-level Verification & Validation can
    be performed independently on the SSHM system to certify that the rate of false
    positives and false negatives is below a selected threshold. This SSHM, applied
    to a simple GNC system, was able to detect and diagnose both hardware and software
    problems successfully. Nevertheless, it remains a simplistic case and more research
    into hierarchical SSHM systems is required in order to apply them to large-scale
    BNs. The approach can further be extended to failures that are not modeled and
    unexpected and due to arising behavior. Although not specifically related to space
    systems, Liu et al. (Liu et al., 2018) reviews the existing techniques for ML-based
    fault diagnosis in rotating machinery. In general, it presents useful research
    and conclusions which we consider can be applied to reaction wheels in the AOCS
    subsystem of spacecraft. K-Nearest Neighbor (k-NN) is the simplest method reviewed,
    which exhibits ease of implementation but necessitates careful fine-tuning and
    large computation and storage space. The authors cite BNs’ strong prior assumptions
    as the biggest shortcoming of this family of algorithms while mentioning as main
    advantages that it possesses a clear physical explanation of how it detects faults
    and its reduced storage space requirement. Support Vector Machine (SVM) is also
    reviewed, and its high-dimension accuracy is highlighted, even if the physical
    meaning is obscured, unlike with the previous two techniques. Finally, DL techniques
    have the potential to learn from data up to a degree of complexity much higher
    than any of the other techniques without the need for a manually crafted feature
    extractor. However, the main drawback of this approach is the need for large samples
    in order to train the network, which is difficult to obtain unless the spacecraft
    is a new iteration of previously flown models for which data already exists. If
    the satellite is a one-off, this can only be obtained in an approximate manner
    by creating a simulation environment. The authors underline that future ML-based
    fault diagnosis methods should not be purely data-driven but should consider possible
    failure mechanisms, system models and prior knowledge in general to increase diagnostic
    performance. Voss (Voss, 2019) explores the use of DL for fault detection and
    isolation in a simulation environment. A NN is developed, trained offline and
    tested to detect and isolate single faults in the reaction wheels, GPS, star tracker
    and magnetometer subsystems, as well as two simultaneous faults. A case study
    with PROBA-V mission parameters is also performed for the AOCS subsystem only.
    The implemented system yielded mixed results: while some subsystems have a near-perfect
    performance, the network fared poorly regarding others, namely misalignment faults.
    Also, fault isolation was much more reliable than fault detection. On top of that,
    a large dataset is required for this system to work, so creating a simulation
    environment is mandatory, especially for one-off spacecraft, to acquire enough
    data for adequate network training. This study also assumes there is enough electrical
    and computing power available on the satellite to run this deep-learning-based
    solution. We overview techniques for reducing resource consumption of deep neural
    models and other techniques in section 6. 4.3. Recovery In FDIR, recovery entails
    reconfiguring the problematic element and/or the entire spacecraft to restore
    normal system behaviour (Jaekel and Scholz, 2015). 4.3.1. Classical approaches
    Traditional FDIR is able to respond to predefined events by selecting a recovery
    path from the available set of options. However, the status of the system and
    its environment can exhibit various kinds of uncertain behavior due to their dependence
    on the internal subsystem, component reliability factors, external environment
    factors (e.g., illumination conditions, thermal, radiation) and on system-environment
    interactions (e.g., resource utilization profiles, stress factors, degradation
    profiles) (Meβ, 2019). Due to these uncertainties, the system and its environment
    cannot be completely observed by traditional FDIR concepts that pose limitations
    to autonomous isolation and recovery (Meβ, 2019). For example, Mars Express lost
    six months of operational hours due to a non-resolvable memory problem that forced
    it into safe mode repeatedly (Jaekel and Scholz, 2015). 4.3.2. ML-based approaches
    Raiteri et al. (Codetta-Raiteri and Portinale, 2015) discuss the use of Dynamic
    Bayesian Networks (DBNs) to address issues like partial observability, uncertain
    system evolution and system-environment interaction, as well as the prediction
    and mitigation of imminent failures. The BNs do not model the relationship between
    variables at previous points in time. DBNs are an extension to BNs that refer
    to past values of certain variables to express dynamic aspects of the system over
    discrete time (Meβ, 2019). The approach is applied by Raiteri et al. (Codetta-Raiteri
    and Portinale, 2015) onto the power subsystem of a simulated ExoMars rover, by
    simulating different failure scenarios. The DBNs can infer whether the system
    is currently in a normal, anomalous or failed state. On detection of a failure,
    a suitable recovery plan is suggested. A preventive recovery plan may be proposed
    in case an anomaly is inferred. The FDIR presented in this paper also has the
    capability of performing a prognostic state estimation that can also be used for
    preventive recovery. The proposed approach has been implemented in an on-board
    software architecture called Anomaly Resolution and Prognostic Health Management
    for Autonomy (ARPHA). The results show that DBNs are suitable for failure situations
    requiring autonomous (preventive and reactive) recovery. AIKO Technologies have
    developed a software library, MiRAGE, that can enable the spacecraft to make autonomous
    decisions for processing telemetry and payload. The library is meant to be installed
    on the satellites to enable functionalities such as event detection, predictive
    maintenance and autonomous re-planning. 4.4. Fault avoidance Fault avoidance methods
    are concerned with preventing the occurrence of faults. 4.4.1. Classical approaches
    FDIR in past missions worked under the notion that a fault is detected and then
    the algorithm will react, according to predefined scenarios.(Jalilian et al.,
    2017, Olive, 2010). Regarding ML-based models, one of the bottlenecks to having
    an on-board failure avoidance system is that the models are trained on the ground
    with limited data that does not represent actual behavior in space. This gives
    rise to the requirement of real-time access to the data, which can be used to
    represent multiple onboard scenarios, and closely represents spacecraft behavior
    during the mission. 4.4.2. ML-based approaches Especially notable in the context
    of ML-enabled fault avoidance is the work of Labrèche et al.(Georges et al., 2021)
    discussing the OrbitAI experiment onboard the OPS-SAT spacecraft. OPS-SAT is a
    special ESA satellite deployed with the scope of being a testbench for novel software
    technologies in orbit. OrbitAI uses ML techniques to obtain intelligent FDIR algorithms
    enabling the onboard camera to avoid direct exposure to sunlight. Interestingly
    the ML model used is trained on-board, rather than offline. The model is trained
    with five training algorithms tested of those natively provided in the MochiMochi
    library (olanleed, 2021) for online ML training: Adam, RDA, AROW, SCW, and NHERD.
    When using the figure of merit of balanced accuracy, only one model appears to
    achieve values significantly different from 0.5: the AROW algorithm in three-dimensional
    input space. 4.5. Recommendations FDIR innovation has been applied mainly to deep
    space missions, which need a higher degree of autonomy due to their long communication
    delays inherent to the long distances traveled. However, the analysis of the literature
    suggests that ML in EO FDIR has promising prospects. The approach can be extended
    to diagnose failures that are not modeled, unexpected and due to arising behavior,
    which offers a great advantage in overcoming the model brittleness issues of traditional
    FDIR. ML-based fault detection and diagnosis solutions can be integrated alongside
    the traditional FDIR of the satellite. But ML-based recovery is virtually unexplored,
    and much research is needed in this domain. The majority of the work in this field
    concerns BNs, while other research avenues remain largely unexplored, such as
    ANNs and DL. As it would be shown and discussed in Section 6, power and computational
    resources remain a big concern for ML-based FDIR, especially for small satellites.
    The benefits of ML-based FDIR can be further researched to be implemented in future
    EO satellites to perform FDIR on the AOCS subsystem, GNC, On-Board Data Handling,
    Power subsystem, and detection of faulty sensors. 5. Machine learning in Earth
    observation on-board image processing 5.1. On-board image processing Clouds cover
    66 % of the Earth’s surface and are an obstacle when observing the Earth’s surface
    in certain wavelengths such as visible light. Removal of clouds from satellite
    images is an important preprocessing phase for most of the applications in remote
    sensing. Researchers have explored various forms of Cloud detection like “Cloud
    / No cloud”, “Snow / Cloud”, and “Thin Cloud / Thick Cloud”, using various approaches
    of ML and classical algorithms (Mahajan and Fataniya, 2020). Cloud detection/filtering
    can be used alongside novelty detection. Novelty detection is to detect unexpected
    features and it is especially important while looking into new environments. Good
    cloud detection algorithms are necessary to optimize bandwidth and memory usage
    in EO missions (Z. Zhang et al., 2019) and before the implementation of segmentation
    and object detection methods. Convolutional Neural Networks (CNN) have demonstrated
    excellent performance in various visual recognition problems such as image classification
    and enable accurate onboard cloud detection in small satellites. With the increase
    in EO missions coupled with high-resolution modern sensors, there is an increase
    in bandwidth requirement that leads to the need to utilize new techniques to manage
    the bandwidth resources efficiently. 5.1.1. Classical approaches In the majority
    of missions, all images taken are transmitted to the ground, which requires a
    significant amount of bandwidth. Traditionally, data collection is done by specifying
    in advance where and when to take the measurements. Based on the content of the
    data, there is no mechanism to tailor what is downlinked. (Srivastava, 2003, Vladimirova
    and Atek, 2002). Other common approaches include novelty detection based on spectral
    contrast, radiance spatial or temporal contrast. (Shaw and Burke, 2003) But these
    methods are better used for dark grounds like vegetation or deserts as clouds
    contrast in color compared to them. Furthermore, these methods rely on manually
    chosen thresholds, which are time-consuming to find and sometimes brittle. (Arechiga
    et al., 2018). Whereas spatial coherence is a better method of cloud detection
    in areas with little contrast with the clouds (ice sheets). NNs have also been
    shown to have greater flexibility with classifying indistinct classes like clouds
    on snow. 5.1.2. ML-based approaches to on-board image processing For cloud detection,
    Zhang et al. (Z. Zhang et al., 2019) propose a lightweight DNN based on U-Net.
    For performance estimation of the proposed method, training and testing of the
    red, green, blue and infrared waveband images from Landsat-8 were used. The lightweight
    DNN is based on U-Net and obtained better overall accuracy while reaching the
    state-of-art inference speed by applying the LeGall-5/3 wavelet transform on the
    dataset which compresses the dataset and accelerates the network for on-board
    use. Zhang et al. experimental results illustrate that the proposed model maintains
    high accuracy after four-level compression (Z. Zhang et al., 2019). They reduce
    processing time from 5.408 s per million pixels to 0.12 s per million pixels,
    and average memory cost by around 30 %. The suggested method takes advantage of
    established image compression systems in satellites to provide a good chance of
    onboard cloud identification based on DL, hence enhancing downlink data transmission
    efficiency and lowering memory costs. On compressed datasets, U-Net gives improved
    accuracy. In addition, the U-Net framework demonstrated tremendous promise for
    pixel-by-pixel categorisation of remote sensing datasets (Z. Zhang et al., 2019).
    The following table (See Table 1) providdes the list of on-board astrionics for
    data processing. Table 1. Hardware Accelerators. Name Company Description Intel
    Movidius Myriad 2 Vision Processing Unit (VPU) Intel Implemented with DNN in Phisat-1
    (Esposito et al., 2019) Myriad X (VPU) Intel Active testing (Bruhn et al., 2020)
    Jetson Nano (GPU) Nvidia Space Edge Zero (2021) by Spiral blue (Mittal, 2019)
    Tegra TX1 and TX2 (SoC) Nvidia Demonstrated AI Image processing capability (Buonaiuto
    et al., 2017, Hernández-Gómez et al., 2019) Coral TPU Google Used with SC-LEARN
    Architecture for Hyperspectral models (Goodwill et al., 2021) Apache 5 Almotive
    In development Neuromorphic chip Innatera In development Spaceborne Computer-2
    (SBC-2) Based on Intel Xeon Onboard ISS Ultrascale Radiation Tolerant (RT) Kintex
    FPGA Xilinx Prototype available Xilinx Zynq-7020 (ARM Cortex-A9 + FPGA) Xilinx
    Space Test Program Houston 5/ CSP (2017) Hinz et al. (Hinz et al., 2020) also
    work on the detection of clouds in the H2020 EO-Alert project framework. However,
    the EO-Alert project aims at keeping images of clouds and enriching them with
    alert profiles in case of severe storms for weather broadcasting. The algorithm
    used is ML-based Gradient Boosted Decision Trees and is embedded in a modular
    image processing pipeline. Currently, tests of the pipeline are performed in Matlab
    and are ported on hardware to be flown to space. Srivastava et al. (Srivastava,
    2003) suggested using Kernel methods for better onboard discovery computation
    of cloud detection over snow and ice. This paper proposes a Kernel method that
    can be used for clustering and classifying images on board any satellite. The
    paper discusses a novel variant of the Probabilistic Kernel (P-Kernels) with a
    mixture of Gaussian and spherical covariance structures. It is very sensitive
    to even the smallest changes as it assumes all observations are independent. The
    results showed great promise, with clouds being differentiated much better from
    Greenland ice sheets compared to the Gaussian and Gaussian mixture models. Giuffrida
    et al. (Giuffrida et al., 2020) (Giuffrida et al., 2022) discuss a CNN deployed
    on the PhiSat-1 reconfigurable nanosatellite to analyze imagery from its Hyperscout-2
    payload and select images eligible for transmission to the ground. It is implemented
    on-board the ESA Phisat-I mission to classify cloud-covered images and clear ones.
    Only images with less than 70 % cloudiness are transmitted to the ground. The
    network is trained and tested against an extracted dataset from the Sentinel-2
    mission, which was appropriately pre-processed to emulate the Hyperscout-2 hyperspectral
    sensor. On the test set, 92 % of accuracy is achieved with 1 % of False Positives
    (FP). The results showed a power consumption of 1.8 W, requiring memory of 2.1
    MB, keeping within the power and the memory constraints. (Del Rosso et al., 2021)
    showcase the use of CNNs on multispectral data to detect volcanic eruptions on-board
    a satellite. Onboard detection of disaster events allows prioritizing their downlink
    and thus optimising response times, which can translate into saved lives. Moreover,
    they have released the dataset used for training, a step the rest of the industry
    should imitate if rapid progress is to be encouraged. (Spiller et al., 2022, Thangavel
    et al., 2023, Thangavel et al., 2023 Thangavel et al., 2022 2022a, 2022b) showcase
    the use of CNNs on hyperspectral data to detect wildfire on-board a satellite.
    Other solutions that have not flown yet and are in the concept phase have been
    developed. Maskey et al. (Maskey and Cho, 2020) proposed an ultralight CNN algorithm
    called CubeSatNet, that prioritizes quality data over quantity without changing
    the constraints of size, power, volume, downlink and pointing requirements imposed
    by a 1U CubeSat. The algorithm is trained over 48,000 augmented images from CubeSats
    and validated against 12,000 augmented images from CubeSats to classify images
    as “bad” when cloudy, sunburnt, facing space or saturated. Images are classified
    as “good” in all other cases. If in orbit, the algorithm would select only “good”
    images to be downlinked and discard images that are covered in clouds or too bright
    or dark. Trained on BIRDS3 satellite images, the algorithm reportedly has an accuracy
    of 90 % and can cut operation time by about 2/3 while significantly improving
    the quality of images received. Murray (Ireland, 2019) proposed a concept of on-board
    processing with two cameras: the nadir-looking camera performs the standard observation,
    whereas a forward-looking camera observes if clouds are coming in the trajectory
    of the satellite. A neural net classification grid is used to identify clouds
    and an algorithm then decides when to capture images with the nadir looking. This
    approach would be oriented towards CubeSats. Castaño et al. (Ricard Castaño et
    al., 2007) trained an SVM for estimating the opacity of atmospheric dust and water
    ice on Mars on data from the THEMIS camera mounted on board the Odyssey mission.
    The authors use both a regular SVM and a reduced-set SVM. The reduced-set SVM
    is trained on a reduced synthetic dataset maximizing the similarity of the reduced-set
    SVM to the regular SVM. The reduced amount of support vectors decreases compute
    requirements. They then test both the full-size SVM and reduced-set SVM on flight
    software, showing the capability of such software to run the proposed algorithms.
    The authors mention two challenges related to the analysis accuracy of onboard
    Time History of Events and Macroscale Interactions during Substorms (THEMIS) data.
    Firstly, as the onboard data is not calibrated, the deployed models must be robust
    to significant noise. Secondly, the camera''s response function can gradually
    increase or decrease its values due to temperature fluctuations, even when there
    is no change in actual value. The authors suggest characterizing the operation
    of the algorithms in an environment as close as possible to that of the spacecraft.
    Lastly, the Autonomous and Reactive Image Chain (CIAR) project from IRT Saint
    Exupéry demonstrated cloud segmentation on board the operational test-bed satellite
    OPS-SAT in 2021 (Frédéric Férésin et al., 2021). Fig. 5 showcases a visualization
    of their results. Download : Download high-res image (217KB) Download : Download
    full-size image Fig. 5. On-board cloud segmentation from the CIAR project. 5.1.3.
    ML-based approaches to novelty detection Wagstaff et al. (Wagstaff et al., 2017)
    show the benefits of reduced downlink data when performing cloud detection and
    filtering for EO missions. Cloud detection is demonstrated using Random Decision
    Forests (RDFs) and Bayesian Thresholding (BT), while a third saliency-based algorithm
    is used for novelty detection onboard EO-1. The RDF method analyzes a window of
    values around the pixel for classifying the pixels. In contrast, the BT independently
    performs the classification of each pixel. BT uses the difference in particular
    wavelengths between dark surface materials and bright cloudy regions. The novelty
    detection algorithm identifies such regions within an image that may contain new
    features. EO-1′s primary science instrument is Hyperion. It’s an Imaging Spectrometer
    capable of data collection with high Spatial and Spectral resolution. Using data
    from previous mission phases, both cloud detection algorithms were trained to
    drop useless images from the telemetry downstream. The performance of the algorithms
    has been evaluated onboard over a five-month period from November 2016 through
    March 2017. In comparison to ground testing, the on-board performance showed similar
    or better results on a diverse collection of targets. Both RDFs and BT reached
    an accuracy of more than 90 %. However, in real-time, the RDFs were faster. The
    novelty detection was able to detect new features in remote locations such as
    small lakes and buildings; hence, such images could be given priority for the
    downlink. Such methods must be able to successfully operate on board with limited
    resources while posing a minimum risk to the overall spacecraft. With the advancement
    in computing capabilities, more complex models offering better accuracy can be
    used onboard future EO missions. Chien et al. (Chien et al., 2017) present the
    results of the IPEX, which was based on a CubeSat that did fly from December 2013
    to January 2015 and validated autonomous operations for the computation and generation
    of product onboard the platform hosting the Hyperspectral Infrared Imager (HyspIRI)
    mission concept''s Intelligent Payload Module. IPEX was used as a testbed for
    on-board image classification, which was accomplished with the help of machine
    learning-based random decision forest algorithms. In comparison to earlier missions,
    the solution was improved by using an ensemble of several trees to increase the
    classifier''s reliability through statistical regularization without the requirement
    for explicit tree pruning. Furthermore, the system examines spatial neighborhoods
    in each image rather than single pixels to integrate local morphology and texture.
    By classifying every 10th pixel and the vertical and horizontal directions and
    filling in the rest with nearest-neighbor interpolation, runtime was reduced.
    The IPEX classifiers are trained before launch using only four hand-labelled photos
    from a high-altitude balloon mission that used the same type of camera as IPEX.
    This is a very fascinating point. According to the researchers, it was the first
    time that an ML system was trained on a suborbital mission and then effectively
    used in orbit. IPEX also experimented with an unsupervised method for identifying
    photographs with potentially intriguing content, which would be used in conjunction
    with supervised learning. To extract relevant regions for downlink in captured
    imagery, computer vision visual salience software was used. To work with CubeSat''s
    limited resources, the program developed a simple pixel-based measurement of visual
    salience for grayscale images with the local context. To select the five most
    important parts within the image, the method is applied to a down sampled version
    of the image using a 32 × 32-pixel window. The pipeline is finished with thumbnails
    of important regions and their salience scores, which are saved and made available
    for downlink and on-the-ground analysis. If necessary, full-resolution images
    can also be downlinked to ground stations. 5.1.4. Recommendations With the strict
    limitation on bandwidth, onboard filtering of useless data enables sending data
    to the ground with minimum compromise on image quality and the need for human
    intervention for decision-making. The results of ML algorithms can be improved
    in terms of accuracy and precision with the availability of newly generated data.
    5.2. Object/image classification Image classification is a task of extracting
    information on the basis of objects in the images instead of individual pixels,
    where “objects” are referred to as meaningful scene components that distinguish
    an image (Deepan and Sudha, 2020). 5.2.1. Classical approaches While current methods
    do extensively apply ML algorithms to great success, image classification is more
    often done on the ground instead of onboard a satellite. (Shaw and Burke, 2003).
    5.2.2. ML-based approaches Arechiga et al. (Arechiga et al., 2018) give an example
    of an on-board processing application where a CNN architecture is used for object
    classification and trained using satellite imagery of Planet’s Open California
    dataset. Nvidia Jetson TX2 is used for implementing this application. The authors
    suggest that more research can be done so that the application can be enhanced
    to classify more objects. Machine intelligence is used to perform onboard analysis
    of EO tasks such as hazard analysis (e.g., wildfire and flood detection), target
    detection, area monitoring, and weather forecasting (Manning et al., 2018). On
    MODIS (Moderate-resolution imaging spectroradiometer) data, NASA Goddard researchers
    employed machine learning to detect wildfires. In practice, CNNs are used to perform
    two tasks: training and inference. The process of “learning” the ideal set of
    weights that maximizes the accuracy of the desired task is referred to as training
    (e.g., image classification, object detection, semantic segmentation). It''s a
    computationally difficult task that''s frequently aided by Graphics Processing
    Unit (GPU). The inference is the process of making decisions based on new data
    using a trained model (with no parameters changed). The inference is a less computationally
    intensive method that has been carried out on Central Processing Unit (CPU), GPUs,
    and Field Programmable Gate Array (FPGA). 5.2.3. Recommendations Similar to onboard
    cloud detection, moving object classification and detection onboard satellite
    platforms allow operators to reduce the load of ground-satellite communications
    links. EO Operators can leverage the huge and quickly expanding research field
    of computer vision. The high-level information gained by using object classification
    can then be used for other tasks, like dynamic mission replanning. 5.3. On-board
    image compression New, complicated onboard sensors can quickly saturate communication
    transceiver downlink bandwidth as well as onboard data storage capacity. Image
    compression codecs that are more efficient are becoming a need for spacecraft
    and can greatly lower the amount of data communicated or stored. However, while
    designing a tradeoff mission, it’s also important to think about whether these
    are computationally intensive and require quick processing to keep sensor data
    rates up. 5.3.1. Classical approaches Systems used a range of lossless and lossy
    compression algorithms to compress data in spaceborne activities (Giuffrida et
    al., 2022; “Image Data Compression,” 2021; “Lossless Data Compression,” 2020).
    Where the system bandwidth is too low to support lossless compression, when the
    science value is not compromised by lossy compression’s distortion, or when other
    sensors that do not play a role in primary data products are included, lossy compression
    is frequently used. An example of this last case can be scene-context cameras.
    5.3.2. ML-based approaches Goodwill et al. (Goodwill et al., 2020) proposed an
    ML-based solution to achieve good reconstruction fidelity after lossy compression.
    The algorithm, CNN– Joint Photographic Experts Group (JPEG), makes use of a hybrid
    approach combining CNNs and JPEG Compression. The image is fed to a 3-layer CNN
    in the encoder to obtain a compact image representation, which is then encoded
    with JPEG. Based on previous work, the encoder is denoted by ComCNN and learns
    a compact image representation that is half the size of the original image. In
    the decoder, the resulting image is upsampled to the original size and decoded
    with a deeper 20-layer CNN, which reconstructs the original image by learning
    a residual image and adding it to the upsampled image. On an image dataset obtained
    from STP-H5-CSP compressed to the same file size, experimental results for CNN-JPEG
    demonstrate a 23.5 percent and 33.5 percent gain in Peak Signal to Noise Ratio
    (PSNR) and Structural Similarity Index (SSIM) over conventional JPEG, respectively.
    At a fixed PSNR, CNN-JPEG increased the average compression ratio by 1.74 times
    on the same dataset. It''s also worth noting that the encoding segment of CNN-JPEG
    in TensorFlow (TF) Lite, when run on the Zynq-7020′s Cortex-A9 cores, provided
    an average execution time of 16.75 s utilizing a single thread, according to the
    research. Using the TF Lite interpreter to parallelize operations was reportedly
    far from ideal linear speedup. Authors also showed that leveraging the Zynq-7020
    FPGA resources through SDSoC for hardware acceleration helped decrease the average
    execution time of the CNN-JPEG encoder to 2.293 s, with a 7.30 speedup over the
    single-threaded TF Lite solution and 6.87 times speedup over the single-threaded
    TF Lite solution. Vladimirova et al. (Vladimirova and Atek, 2002) discuss the
    development of a lossless compression method without the drawbacks of low compression
    ratios using predictive NNs, coupled with integral wavelet transforms and the
    Peano-Hilbert (PH) Scan algorithm. This is then benchmarked against the Context-Based,
    Adaptive, Lossless Image Codec (CALIC) Method using various image datasets. The
    image is first sent through the Integral Wavelet Transform (IWT)to produce a de-correlated
    image, which is mapped, and a PH scan is performed after which the NN (a two-layer,
    4x106 × 1) scans and allocates a probability distribution for the next incoming
    value. On the tested data sets, using only the NN method achieved an average compression
    ratio of 2.530, compared to the CALIC method which achieved a ratio of 1.806.
    Introducing the PH scan brought an 8.5 % improvement compared to the CALIC method
    at 2.747. The IWT + PH + NN method overall achieved an improvement of 13.1 % compression
    ratio over the CALIC method. The paper proposes potential applications of the
    algorithm in previewing a satellite image before a full image is transferred to
    assess the image''s features and would prevent bad images from being sent, such
    as those affected by clouds or images suffering from other distortions. Cai et
    al. (Cai et al., 2003) proposed a novel Light Detection and Ranging (LIDAR) image
    data compression method. The method is called feature indexing where specific
    features are assigned to a data index system generated by DNNs. The whole program
    is then uploaded to onboard hardware and it stores it as a dictionary for reference.
    The On-Board Computer (OBC) runs a feature isolation program, identifies features,
    and creates a resultant dataset of pure indices based on the directory. This data
    set is then transmitted with the location data and then is decoded on the ground.
    Achieves a compression level of 99.17 % and works far better than standard wavelet
    compression methods. The method was tested against the LIDAR data of the Space
    Shuttle program and achieved the above-mentioned results. 5.3.3. Recommendations
    Exploiting lossy compression to ease downlink clearly represents a path to be
    explored. The work by Goodwill et al. (Goodwill et al., 2020) also emphasizes
    the importance of advancement in the field of hardware acceleration and System
    on a Chip (SoC) FPGAs. Indeed, on-board inference of CNNs is computationally expensive
    for space platforms. Further advancements can possibly support the application
    of more complex algorithms even in constrained environments. 6. Machine learning
    in resource-constrained Earth observation platforms This section addresses the
    topic of ML in resource-constrained spacecraft performing EO tasks. These methods
    represent a powerful set of enabling technologies, relevant both for the emerging
    interest in small satellites and to preserve the operativity of large platforms
    experiencing failures or operating with shared resources. Moreover, the consistent
    technological lag of space hardware makes considerations about reduced available
    SWaP almost always necessary when redeploying architectures developed for Earth-based
    applications into orbit. Within the scope of this work, the constraint on resource
    availability will be limited to on-the-edge computational and sensing capabilities,
    and not extended to the data. It is also out of the scope of the section to address
    scheduling approaches, which optimize the availability of resources to multiple
    subsystems or users. This variability, however, can be also seen as a source of
    constraint over the available budgets. We investigate two ways in which this adaptation
    to technological limitations can be implemented: optimization of the AI architecture
    itself, and optimization of the interplay between the model and the hardware this
    operates on. In general, resource-constrained platforms it is necessary to maintain
    a holistic view of the architecture of the software, the hardware, and the data
    at play. It is worth noting that another emerging technological field presenting
    similar constraints to the space sector is represented by Internet-of-Things (Lane
    et al., 2015), where the target platforms for AI are small, low-power devices.
    6.1. AI architecture optimization 6.1.1. Pruning Pruning is the operation of removing
    or zeroing parameters of a NN model, thus reducing the network’s size (Han et
    al., 2015). This process is generally performed by associating scores with the
    network’s elements during training in order to select the ones to prune. The lighter
    model is then further trained and can be iteratively re-pruned several times.
    Multiple pruning strategies exist, such as varying the number and nature of items
    pruned, the number of iterations performed or changing the scoring criteria (Blalock
    et al., 2020). There are also other emerging pruning paradigms that do not rely
    on an iterative process (H. Wang et al., 2021) (Frankle et al., 2021). Pruning’s
    main trade-off is to increase computational efficiency at the cost of quality/accuracy
    and increased training complexity. The objective is to leverage compression rates
    of 4, 8 or even 32 while costing at worst only a few percent of accuracy (Blalock
    et al., 2020). Performing pruning along this objective remains a delicate task
    as literature demonstrates that keeping good performances is dependent on the
    pruning method. The main challenge of implementing pruning is thus to determine
    and test which pruning methods to use in order to achieve the required compression
    while keeping acceptable performances for a representative type of datasets. Although
    the lack of standards in evaluation impedes the comparison of the multiple existing
    studies, they all advertise significant compressing at low accuracy cost, including
    several algorithms confirmed by multiple papers (Blalock et al., 2020). Pruning
    has been successfully applied in many image processing use cases but has also
    been proven on voice processing (He et al., 2014), credit classification (Tang
    et al., 2018), and multiple other types of datasets (Lazarevic and Obradovic,
    2001). Additional engineering and more complex training on the ground in order
    to significantly reduce the onboard execution constraints make pruning an attractive
    trade-off and a strong technological enabler of NN implementation in space. Pruning
    is now developed enough to have documented implementation and examples in ML frameworks
    such as TF (“Pruning in Keras example | TensorFlow Model Optimization,” 2022).
    So far, pruning has been used as part of complex NN applications for space but
    only on the ground with applications such as image classification (Browne et al.,
    2020, Castelluccio et al., 2015, Kavzoglu and Mather, 1999, Maggiori et al., 2017).
    There are some applications aiming towards on-board implementations like remote
    sensing image classification (Pitsis et al., 2019, Zhang et al., 2020), vehicle
    detection in satellite images (Tan et al., 2020) and image anomaly detection (Ma
    et al., 2019). Unfortunately, the authors were unable to find documented evidence
    of a pruned NN that flew on a space mission. 6.1.2. Filter compression and matrix
    factorization In its section concerning “convolutional filter compression and
    matrix factorization,” the paper by Goel et al. (Goel et al., 2020) presents methods
    to adapt neural networks to low-power platforms by operating at a layer’s level.
    The distinction operated between the two distinguishes between the types of network
    elements that are being optimized. Neural Networks can be algebraically represented
    as n-dimensional matrices known as tensors. Matrix factorization approaches reduce
    the complexity of these underlying tensorial structures, to obtain compressed
    networks without significant loss of accuracy. Filter compression methods, on
    the other hand, reduce the number of parameters in the network architecture by
    acting on the structure of filters in the so-called convolutional layers. In particular,
    Goel et al., observe that filter compression methods are capable of achieving
    state-of-the-art accuracy in computer vision, albeit at times at a high computational
    cost. As computer vision tasks are essential in EO operations, this class of methods
    appears to be the most significant within the scope of this paper. Two architectures
    emerging as relevant for filter compression are SqueezeNet (Iandola et al., 2016)
    and MobileNets (Howard et al., 2017). Both these architectures have found applications
    in the EO community. For example, modified SqueezeNets have been used by Haikel
    (Haikel, 2018), Alswayed et al. (Asmaa et al., 2020) and Alhichri et al. (Alhichri
    et al., 2018)for the classification of remote sensing images (both in drone and
    satellite images). In particular, Alswayed et al. report results comparable to
    or outperforming the state of the art at the time of publication. Poortinga et
    al. have used a MobileNet-based architecture to map sugarcanes in satellite data
    of Thailand (Poortinga et al., 2021), obtaining significant accuracy for the task.
    Zhang et al. (B. Zhang et al., 2019) also have used an architecture capitalizing
    on MobileNet, reporting results outperforming the state of the art at the time.
    Similarly, Yu et al. (Yu et al., 2020) present a MobileNet-based method to classify
    remote sensing imagery and report outperforming many state-of-the-art models while
    requiring a smaller amount of training data. In their report paper, Hoeser et
    al. (Hoeser et al., 2020) note that: “It is important to note the small group
    of six items which use MobileNets, of which five were published in 2019”. They
    describe an onset of interest in parameter efficient models with high accuracy
    and they prove that such models can compete in Earth observation studies. 6.1.3.
    Architecture search Neural Architecture Search (NAS) refers to a set of tools
    and processes for the automatic generation of optimal architectures for an ANN.
    NAS is a specific instance of automated machine learning (AutoML), the process
    of automating the overall ML construction process (He et al., 2021). As shown
    by Chan et. al (Chan et al., 2018), this process can be specialized to address
    a constraint on available resources. Seminal developments in NAS emerged in late
    2016, from the work of Zoph and Le (Zoph and Le, 2017) and Baker et al. (Baker
    et al., 2017). In a survey on the subject, Elsken et al. (Elsken et al., 2019)
    report three key parameters to operate a classification of NAS processes. These
    are: • Search space, • Search strategy, • Performance estimation strategy. Being
    an approach to adapt the heavy computational cost of NN to resource-constrained
    platforms, NAS has naturally found application in many space-related use cases.
    EO, there has been quite a research on hyperspectral images classification using
    NAS, with development performed by Liang et al. (Liang et al., 2020) have employed
    NAS (and pruning) to detect aircraft in remote sensing images. Mobile Neural Architecture
    Search (MNAS) (Tan et al., 2019) is a probable candidate in implementing NAS to
    EO satellite inference on the edge application. 6.1.4. Knowledge transfer and
    distillation In Knowledge Transfer (KT) and Knowledge Distillation (KD) a small,
    lightweight network is trained to reproduce the behavior of a large, computationally
    intensive network without having to duplicate the architecture of the latter fully.
    This leads to small networks both providing results comparable to those of large
    networks and deployable on resource-constrained platforms. According to the paper
    of Goel et al. (Goel et al., 2020), in KT the smaller network is trained using
    data labeled by the larger network (defined as “synthetically labeled data” by
    Ba and Caruana (Ba and Caruana, 2013)), while in KD a small network (student)
    is trained by a large network (teacher) to replicate the latter’s output. Within
    the scope of this section, it also appears relevant to discuss transfer learning,
    which has attracted considerable interest from the space community. De Vieilleville
    et al. (de Vieilleville et al., 2020) proposed a distillation method to perform
    DNN-mediated segmentation of EO images on board of CubeSats. In this work, they
    show that a 10 to 30-fold reduction of the free parameters of the network mediated
    through distillation leads to weakly worse performance (+5/-10 % accuracy). Similarly,
    (Chen et al., 2018) provide a detailed distillation implementation and results
    showing a strong reduction of the NN execution load while keeping a steady accuracy
    in remote sensing scene classification. (Bazzi et al., 2020) applied distillation
    for mapping irrigated areas using remote sensing data. Since 2019, self-distillating
    networks are emerging (Chen et al., 2021) with one successful implementation for
    cloud detection in remote sensing by (Chai et al., 2020) achieving 200-fold compression.
    Industrialization is not as developed as pruning as there are only a few open
    access examples of implementations but no widely developed library. Unfortunately,
    the authors were unable to find documented evidence of a distilled NN ever flown
    and used on a space mission. 6.2. Hardware acceleration Computing limitations
    are demanding to ML-based applications because of the significant amount of data
    to be processed for DL. Many NN models require high-end GPU devices to run in
    inference, and even more so during training. In deploying ML to an EO satellite,
    it is appropriate to consider the inferencing phase due to volume, power, and
    mass constraints, especially under CubeSat standards. Progress in commercially
    available off-the-shelf hardware in mobile edge computing has a progressive effect
    in finding their way to CubeSats in implementing DL algorithms for space applications
    (Kothari et al., 2020). With CPUs considered to be general-purpose computers,
    AI-specific hardware such as GPU’s, FPGA, and Application-Specific Integrated
    Circuit (ASIC) takes the center stage which is designed to accelerate the computation
    of linear algebra and specializes in performing fast and matrix multiplications
    with higher performance-per-watt ratios. Furthermore, advanced next-generation
    architecture for onboard computing which heavily depends on artificial intelligence
    is developed like Artificial Intelligence-Onboard Computing (AI-OBC) (Huq et al.,
    2018) based on distributed on-board architecture consisting of CPU, Visual Processing
    Unit (VPU), emerging AI accelerator class of microprocessor for running machine-learning
    applications to train DNN and FPGA connected through CubeSat Service Protocol
    (CSP) through which ML and training are carried out in real-time with COTS components
    to reduce cost and development time. One other form of tailored hardware optimization
    is the adoption of spiking neural networks (Kucik and Meoni, 2021) and their deployment
    on optimized hardware. This approach, which is much closer to the way the brain
    seems to function, can allow for dramatic energy savings through minimization
    of energy use during neuron activation. 6.3. Quantization / BNNs In quantized
    networks, the number of bits used to represent numbers defining a model is reduced.
    This provides a decrease of orders of magnitude in computing, memory and power
    requirements, for a comparatively low decrease in performance. Quantization may
    be applied to weights, activation functions or gradients of a network, either
    during or after training. (Guo, 2018, Qin et al., 2020, Simons and Lee, 2019).
    Quantization has been explored in research for remote sensing image segmentation
    and processing but appears to never have been flown in space. Perhaps the most
    common established quantization technique is reducing the bit-width of weights
    after training. However, very low bit widths, typically of four or less, usually
    incur heavy losses. This can be mitigated by performing model training under the
    reduced bit-width quantization, known as Quantification-Aware Training (QAT).
    Good results have been achieved with quantization, even going all the way to a
    single bit. Accuracy on par with full-precision NNs was achieved for standard
    datasets in publications such as Binary-Connect, Exclusive-NOR Network (XNOR-Net),
    and Trained Ternary Quantization (TTQ) (Courbariaux et al., 2015, Rastegari et
    al., 2016, Zhu et al., 2017). Quantization of already existing NNs such as AlexNet
    (Krizhevsky et al., 2012) and Visual Geometry Group Network (VGGNet) (Simonyan
    and Zisserman, 2015) applied to the ImageNet dataset has been carried out without
    any accuracy loss while reducing their sizes up to 50 times (Han et al., 2016).
    Quantization both before and after model training is provided today either as
    part of mainstream DL libraries (“Post-training quantization | TensorFlow Lite,”
    2022.; “Quantization — PyTorch 1.9.1 documentation,” 2022.) or third-party libraries
    such as Larq (“Larq | Binarized Neural Network development,” 2022.) and FINN (Alam
    et al., 2022) respectively. Although there exists no consensus on why quantization
    works, a candidate explanation argues that large amounts of pathway redundancy
    in NNs make the expressivity loss a minor concern. Theoretical analysis in that
    regard is still limited. Anderson and Berg (Anderson and Berg, 2017) found that
    statistical properties of the computation are kept even when a network is binarized.
    Molchanov et al. (Molchanov et al., 2017) indicate that nearly 99 % of weights
    can be pruned in certain NNs and achieved a 68-times sized reduction on VGG-like
    networks without loss of accuracy. Quantization techniques can be divided into
    two main categories: Deterministic and Stochastic. Guo classifies deterministic
    quantization methods (Guo, 2018) into: • Rounding: Floating-point values are assigned
    their nearest fixed-point representation. • Vector Quantization: Weights are clustered
    into groups, with the centroid of each group replacing the real weights. • Quantization
    as an optimization: Here, the quantization is treated as an optimization problem,
    which involves minimizing an error function taking into account real and quantized
    weight values. Regarding stochastic quantization techniques, they separate them
    into: • Random Rounding: The quantized value is obtained by sampling a discrete
    distribution parameterized by the real values themselves. • Probabilistic Quantization:
    Weights are assumed to be discretely distributed, with the methods trying to estimate
    which distribution function it is. Deterministic quantization has seen extensive
    success, with rounding being the most commonly successfully employed type of quantization,
    such as Rastegari et al. (Rastegari et al., 2016) and (Polino et al., 2018), where
    a general rounding function was introduced. In particular, Binary-Connect Courbariaux
    et al. (Courbariaux et al., 2015) used binary rounding, achieving 98.8 % accuracy
    on the MNIST dataset. Also noteworthy is the use of vector quantization in Gong
    et al. (Gong et al., 2014), where a network compression ratio of 24 was obtained,
    losing only 1 % of accuracy on the ImageNet dataset. However, Stochastic quantization
    has not experienced such a resounding success, perhaps due to an over-reliance
    on statistical assumptions which are not guaranteed to hold. Quantization approaches
    may quantify several or all of the following: • Weights: The action of quantizing
    weights yields a smaller network size and can accelerate the training and inference
    process. However, this comes at a price: NNs will have a harder time converging
    when training with quantized weights, and a smaller learning rate is required.
    Additionally, the gradient cannot back-propagate through discrete neurons, leading
    to the use of straight-through estimators in order to estimate them, usually with
    a high variance. • Activations: The goal of quantized activations is replacing
    inner products with binary operations, reducing memory constraints since the operation
    precision is reduced, all while accelerating network training. In fact, activations
    may fill more memory than weights (Mishra et al., 2017). Note that quantized activation
    will cause what is called a “gradient mismatch”, where the gradient of the activation
    function is different from the one obtained from the straight-through estimator
    used. • Gradients: Quantizing the gradients is still a relatively new avenue of
    research in NN quantization. The main objective here is not reducing the model
    size, but aiding in distributed network training, where several computing nodes
    need to share information of the gradient values between them. The smaller the
    size of the data the nodes need to share, the faster parallel training can be
    performed. Quantized gradients need to be carried out with care since unsuitable
    implementations run the risk of causing the gradient descent algorithm not to
    converge. 7. Machine learning standardization and issues in Earth observation
    operations Interest in AI and ML has increased in the past years. Many groups
    in different industries are working on creating guidelines, best practises, and
    standards to help make sure these systems are used correctly. But the process
    is far from over, and so far, the space industry has only given us a real-world
    example of something similar. Standards, guidelines, and other documents discussed
    in this section blur the line between definitions of AI and ML (Graham et al.,
    2023). While we find this fact misleading, we have kept the original usage from
    the sources in order not to alter their message. These bodies of work aim at aiding
    ML system developers to avoid common pitfalls and problems associated with these
    systems. We provide in this section a cursory overview of what these problems
    are in order to raise awareness amongst EO platform operators. We do this so that
    the designers and operators of EO platforms are aware of what ML systems are capable
    of and are not capable of doing when it comes to making decisions that are reliable,
    intelligible, and appropriate for usage in situations with high stakes. Because
    of the high expense of these possible applications on-board a big satellite platform,
    these conditions apply to the majority of those applications. To put it another
    way, any operator who is contemplating delegating decisions regarding the success
    or failure of their mission to ML systems should make it a priority to employ
    ML systems that are reliable and can be explainable. We do this so that EO platform
    designers and operators are aware of what ML systems can and cannot do when it
    comes to taking decisions that are trustworthy, understandable, and fit for use
    in high stakes scenarios. These conditions apply to many of the potential applications
    on-board a large satellite platform, due to their cost. In other words, using
    trustworthy, explainable ML systems should be important to any operator thinking
    of charging such systems with decisions deciding the success or failure of their
    mission. 7.1. Guidelines and roadmaps International Standards by International
    Standardization Organization (ISO) committee (“ISOISO/IEC JTC 1/SC 42 - Artificial
    intelligence,” 2017.) are currently available or under development. These standards
    and projects represent the united efforts of experts and entities in providing
    guidance and focus on the standardization of Artificial Intelligence, with currently
    more than twenty under development and six already published. We found ISO/IEC
    TR 24030:2021 to be particularly interesting as it covers 132 use cases, as well
    as the projects under development concerning Functional Safety and AI, data quality
    and AI explainability. The ISO is not alone in working on AI standardization,
    though. The Chinese Big Data Security Standards Special Working Group of the National
    Information Security Standardization Technical Committee (NISSTC) wrote the Artificial
    Intelligence Security Standardization White Paper (Törnblom and Nadjm-Tehrani,
    2019). The focus of this White Paper ranges from the security of AI to main security
    threats, risks, and challenges. Seven recommendations have been made on the importance
    of improving a system of AI security standards, the need to speed up the development
    of standards in key areas, promoting the application of AI security standards,
    strengthening the training of AI security standardization talent, participating
    in international AI security standardization, establishing an AI high-security
    risk early warning mechanism, and improving AI security supervision support capabilities.
    Germany developed an Artificial Intelligence Standardization Roadmap (Wahlster
    and Cristoph Winterhalter, 2020), continuously updated, as a joint effort between
    DIN and DKE. The roadmap strongly supports the idea that standardization would
    improve the explainability and reliability of AI, thus favoring its application.
    In the roadmap, AI''s explainability and reliability, they deal with data reference
    models for the interoperability of AI systems, development of an AI basic security
    standard, practice-oriented initial criticality checking of AI systems. In addition,
    the work provides extensive analysis on the definition of AI as well as classification
    schemes to evaluate AI-based systems. The work is particularly interesting also
    for spotlighting issues as the risk-based assessment of applications, trustworthiness,
    ethical approach and AI application lifecycle. In addition, in each section of
    the roadmap, specific needs in the direction of standardization are pinpointed.
    The European Commission (EC) shaped a white paper (“White Paper on Artificial
    Intelligence,” 2020.) setting out policies to achieve the uptake of AI in the
    European Union (EU) and to address risks associated with the use of AI technology.
    Along the sections of the document, it gives particular attention to the opportunity
    to create an ecosystem of excellence. Six actions have been highlighted, among
    which: focusing on SMEs and ensuring that each member state has a digital hub
    highly specialized in AI; strengthening public–private partnerships in AI, data
    and robotics; and promoting the use of AI in the public sector. An overview of
    the most significant risks is also provided, with more emphasis on ethical and
    trustworthy AI. The National Science and Technology Council from the USA’s Executive
    Office developed an AI Research Development Plan in 2016, later updated in 2019
    (Faisal D’Souza, 2019). The Plan does not define specific research agendas for
    Federal agency investments but highlights strategies to reach a given portfolio.
    While it must be noted that the utmost focus of the strategies is not on the standardization,
    strategy 4 “Ensure the Safety and Security of AI Systems'''' and Strategy 6 ”Measure
    and Evaluate AI Technologies through Standards and Benchmarks“ are covering aspects
    strictly related to standards and certifiability. It is worth mentioning great
    attention to the development of shared public datasets and open-source libraries,
    as means to keep the technological lead. Although slightly different in scope,
    as more oriented towards certification rather than standardization, it is worth
    mentioning the White Paper (Gregory Flandin et.al., 2021). The document aims at
    “sharing knowledge, identifying challenges for the certification of systems using
    ML, and fostering the research effort”. A thorough discussion on the features
    that an ML-based system should possess to be certified is carried on, leading
    to the identification of seven challenges to tackle: probabilistic assessment,
    resilience, specificality, data quality, explainability, robustness, and verifiability.
    7.2. Issues and techniques In this section, we offer a brief discussion of the
    potential unique issues one may encounter when developing and operating a system
    that incorporates ML. Whenever possible, we discuss some current approaches to
    bridge these issues. This discussion is meant to be illustrative to the reader
    and an encouragement to explore the topics in further detail, but it attempts
    to be comprehensive on neither scope nor depth. Furthermore, the topic is under
    active research and is likely to expand in the coming years. 7.2.1. Explainability
    ML models, and particularly large models with lots of free parameters such as
    large decision trees or NNs, can act as black boxes. The process by which they
    arrive at the final output can be too complex to be directly interpreted, thus
    becoming as inscrutable as if the model’s internals had been inaccessible in the
    first place. However, transparency, explainability, and interpretability are very
    important for any technical system with a moderate or large impact, be it in terms
    of dollars or human lives. Therefore, model explainability is very important in
    fields such as aerospace, medicine, insurance, banking, and more. Explainability
    is a hard problem because of several reasons. Firstly, it is user-dependent: the
    type of explanation expected by an average user will differ from that expected
    by a regulator or an engineer. This leads to the question “How detailed must the
    explanation be, and what must it cover?”. Secondly, the expected outcome of transmitting
    an explanation can be hard to define, should the receiver become more able to
    predict model output after receiving explanations? Must the explanation point
    univocally to the features of the input data that had the largest impact on the
    produced results, and is this limited to input data, or does it also include training
    data? Perhaps it should illustrate a counterfactual - «What would need to change
    for the decision to have been different? » Or perhaps something else entirely?
    And are the previous goals mutually exclusive?”. There are a huge number of techniques
    to answer some of these and related questions. The field of Explainable AI (XAI)
    for short, is huge and expanding rapidly. Providing an overview of this field
    is not within the scope of the current publication, but we recommend our readers
    to consult the Interpretable Machine Learning book (Molnar, 2021) or one of the
    numerous reviews on the topic to learn more (Linardatos et al., 2021, Tjoa and
    Guan, 2020). 7.2.2. Robustness and reliability Reliability is the rate of failure
    of a system when operating in nominal conditions (e.g. 10-9 catastrophic failures
    per flight hour (“AC 25.1309-1A - System Design and Analysis – Document Information,”
    1988)). Since a rate of system error can be extremely challenging to calculate
    without operating the system, heuristic development rules like no single point
    of failure are accepted as valid ways to achieve the goal. This acceptance stems
    from either a competent authority, which implicitly accepts the risk of not properly
    achieving the desired reliability level or historical data when available. Neither
    is a possibility for current ML-based systems, due to an absence of historically
    validated, robust, and widely accepted heuristic design rules. For Machine Learning
    systems, reliability comes from two distinct factors: accuracy and robustness.
    An ML classifier with higher accuracy is less likely to misclassify an input,
    hence is more reliable. Performance does not usually come into play for classical
    software system’s reliability as accuracy for a valid set of inputs and execution
    path is 100 %. This section does not concern itself with increasing model accuracy,
    a topic that is the main focus of each application-specific research field mentioned
    so far. Accuracy for an ML model is calculated over the data points in the test
    dataset and only those. While this is also true for classical software testing,
    in the latter the notion of input equivalence classes provides assurance that
    the software system will continue to perform acceptably for inputs outside the
    test set. Correctness equivalence classes for ML models do not currently exist.
    A similar notion of robustness can be used instead. A robust model has bounded
    accuracy loss for inputs that are within a bounded distance of the input distribution.
    This fact can be used to construct arguments for the reliability of an ML model.
    Equivalence class discovery for random forest models is a topic under active research
    (Cheng and Yan, 2021, Törnblom and Nadjm-Tehrani, 2019). When demonstrating model
    robustness, several problems arise: Firstly, how does one quantify the distance
    between input data? Although several measures exist, they are often hard to relate
    to humans'' tacit notions of input distance. It is easier to qualitatively say
    to what degree an image does not depict a cat than it is to quantify it in a single
    measure. This only becomes harder for more abstract forms of input such as satellite
    telemetry data. Thus, relating system-level specifications to notions of input
    distance is sometimes complex. For a given distance definition, formal verification
    methods attempt to formally prove certain properties of DL models, including robustness
    (Katz et al., 2017, Mirman et al., 2018, Müller et al., 2021, Wang et al., 2018).
    They allow a user to build a model tolerant to a certain distance between inputs.
    Equivalent research exists for other ML models, such as random forests (RFs) (Törnblom
    and Nadjm-Tehrani, 2019), but the literature is significantly less developed.
    Note that these approaches allow a designer to fight adversarial examples, a specific
    and concerning failure mode for ML models (Chen et al., 2019, Goodfellow et al.,
    2015). Nonetheless, the literature on the generation and defeat of adversarial
    examples is highly active and ever-evolving, as measures, countermeasures, and
    counter-counter-measures get deployed. It is out of scope for this review to delve
    any deeper into that. Secondly, there is the well-known issue of generalization.
    A model may offer very good performance on a dataset and very poor performance
    on the actual population, in the phenomenon known as overfitting. The PAC-Bayes
    approach offers generalization bounds that specify a minimum number of samples
    from distribution for a desired performance and training process reliability levels
    within that distribution. These bounds, however, are often extremely conservative,
    and improving them is another active field of research (Shalev-Shwartz, 2014).
    Since it is hard to quantify these bounds appropriately, the only recourse for
    organizations to ensure performance is to collect massive amounts of data, which
    is prohibitively expensive or downright impossible in many cases. Since generalization
    and robustness shortcomings are highly model-specific, one approach to tackle
    them focuses on applying mixtures of models working in tandem, known as ensemble
    models, and selecting an output based on the collective response of the ensemble
    (Pang et al., 2019, Yang et al., 2021). Thirdly, and also related to the second
    issue, there is the phenomenon of domain drift (Shweta, 2019). Models do not just
    overfit to a given dataset but also to the current population. And, as time goes
    by, systems change. An FDIR system monitoring battery health will see its voltage
    decrease over time as the battery ages. The statistical distribution of deviations
    around the nominal value is also likely to change. The performance of the ML model
    will thus decrease over time as the world changes around it. Fine-tuning on new
    data can mitigate this issue but can trigger the phenomenon known as catastrophic
    forgetting (Nguyen et al., 2019), where the model loses performance on old and
    new data. A solution is to retrain it from scratch on new data, but this entails
    capturing that data and retraining the model, which increases operating costs
    and risks in hard to predict ways. Alternative solutions exist but they come with
    their own drawbacks. Training a model on a dataset representative of the whole
    system’s life cycle can mitigate the issue but requires larger models and better
    data capture at the project’s start. Lastly, models also overfit the specifics
    of the system they’re trained for. A model trained for one specific satellite
    may have issues adapting to another satellite instance, or model. Version improvements
    such as equipment changes may bring performance hits with them too. While research
    fields like transfer learning, domain adaptation and domain generalization (Zhao
    et al., 2020) attempt to address the issue, they are far from universally reliable
    at the moment. This is particularly concerning for the space industry, where mass
    manufacturing and standardized equipment is the exception rather than the norm
    and can pose a serious challenge to the industry’s adoption of ML technologies.
    Sometimes, when adapting to new platforms, new input data will be available or
    new output data may be required. In this case, the field of transfer learning
    is applicable, which includes both domain adaptation and domain generalization.
    In short, despite the aforementioned techniques, ML models are extremely brittle
    to deviations in input data from the training dataset, and it can be assumed that
    deviations from the training dataset will break the system. Therefore, building
    proper datasets is a key task of any ML system designer or operator, a topic which
    we address in the next section. 7.2.3. Dataset construction Datasets are the lifeblood
    of ML. Therefore, it is only right to have standards assigned for data to avoid
    anomalies and have a perfect collection that will help produce the right results.
    Cappi et al. (Cappi et al., 2021) propose a Dataset Definition Standard (DDS),
    which, while not specifically geared toward space activities, can be applied to
    EO data from either payload or satellites. It aims to provide a standard for training,
    validating, or testing datasets. It explains in detail the recommendations to
    be followed while collecting data and how to annotate it and perform functions.
    The paper talks about many important aspects any dataset should possess, from
    how it must cover as many situations as possible that could be encountered during
    model development to how a history of every single change to every data must be
    kept helping with traceability and avoid discrepancy. The paper provides clear
    recommendations for labeling and annotation of data and how the dataset should
    be segregated for training, validation and testing. The US Geological Survey (Larry
    R et al., 2019) provides dataset standards for their various operations like Biological,
    Climate and Forecast and Mapping. Cleansing “dirty data” is mentioned as a common
    problem faced by data scientists. They also take it a step further with geological
    mapping by producing a set of parameter standards to be followed while collecting
    data which define a set of rules for individual parameters within the dataset.
    The parameter standards cover a wide range of qualities like the date/time, geographic
    coordinates, codes, etc. the satellite data should contain. Report (Larry R et
    al., 2019) explains how exactly a topographical map of anything in the US should
    be produced and one important aspect of it is the data standards including which
    standards the file formats of the data should be stored in. For the data quality
    standards, they delve into it by discussing various components like currency,
    consistency, completeness, and accuracy. The paper covers every aspect of mapping
    data from dealing with off grid and oversized maps, data sources and resolutions
    to how cartographic features should be interpreted. The primary space operation
    in Earth Orbit is remote sensing. As a result, they are the primary data-producing
    activities. Therefore, remote sensing standards are relatively well developed
    when compared to other ML operations in the space industry. Authors (Di, 2008,
    Di and Kobler, 2000) go in-depth about all standards of remote sensing including
    the dataset standards. Di and Kobler (Liping Di and Ben Kobler, 2000) introduce
    NASA’s well developed EO Systems’ Data Information Systems (EOSDIS). As the EOSDIS
    will process data from various fields it is not feasible for the system to deal
    with every single data collected one by one. This has led to EOSDIS establishing
    standards to deal specifically with remote sensing data. 7.3. Recommendations
    As outlined above, ML systems face a number of issues precluding their application
    in many scenarios where they would otherwise be useful. We believe the fundamental
    research being carried out on ML model robustness is of great interest and recommend
    that any practitioner follow it closely. For certain small-scale problems, work
    on formal verification of ML models may already be enough to ascertain that the
    network responds appropriately within the input regime, and input data outside
    of this regime can be purged by data verification systems implemented in classical
    software. Further, we recommend that any practitioner keep a careful watch for
    ways in which the lifecycle operation of a system will deviate from the training
    scenarios, and mitigate the risks issued from model brittleness to these differences.
    The system must undergo a verification process to be verified and validated. The
    critical levels of various ML models are displayed in Table 2. Table 2. ML Certification
    Criticality levels (Winter et al., 2021). Criticality Level (CL) Impact Potential
    (Examples) ML Application Requirements 1 There is no risk of harm to living beings,
    no risk of loss of confidential data, and no ethical or privacy concerns. Basic
    minimum requirements of a competently developed ML application are fulfilled.
    2 Living beings could be harmed with limited, no permanent damage. Temporarily
    unavailability of non-critical data and services, violation of ethical concerns
    without identifiable harm to actual persons. The ML application is developed according
    to industry standards and follows best practices that are regarded as state of
    the art. 3 Living beings could die or be restricted for life; the environment
    could be damaged. Manipulation of data with severe financial consequences and
    loss of control of the system to malicious attackers. The ML application is developed
    and documented with great care. Safety & Security is ensured with processes and
    techniques that go beyond traditional best practices and industry standards. 4
    Many living beings could die or could be restricted for life; the environment
    could be damaged permanently. Loss of information which endangers the existence
    of the organization. Long-term unavailability of critical data or services without
    which the organization cannot function. The ML application is developed and documented
    with great care. Safety & Security is ensured with processes and techniques that
    go beyond traditional best practices and industry standards. All components of
    the ML application are formally secured and validated. Major certification topics
    must be re-examined, even though known certification procedures for traditional
    applications cannot be used in a clear manner in the context of ML. This technology''s
    total effectiveness and safety would be enhanced with a comprehensive certification
    strategy for machine learning applications, which would boost public acceptance
    and trust. Winter et al (Winter et al., 2021) proposal for certification criteria
    for supervised learning with low-risk potential is shown in Fig. 6. Download :
    Download high-res image (128KB) Download : Download full-size image Fig. 6. ML
    Certification workflow (Winter et al., 2021). ML explainability is another core
    issue; explainability of model decisions can and does take precedence over model
    performance in scenarios with high-impact decisions or where (human) learning
    from the model’s decisions is key. Current model explainability methods can offer
    insight into the relevant features of input data used for a model’s decision,
    but they can also provide misleading or unhelpful signals. For applications where
    explainability is an important feature of the system, dictionary, tree, or kernel-based
    models and other easily explainable methods should be compared with harder-to-explain
    models for a performance-explainability trade-off. National recommendations, white
    papers and initial official standards in the AI and ML field attest to the growing
    interest in the subject. While the scope of these is much broader than the space
    sector alone, some considerations can be applied to ML for space applications
    too. Data quality and availability will play an important role in the adoption
    of ML across EO Operations and will certainly be demanded by supervisory and regulatory
    agencies performing standardization and certification. This need goes beyond the
    mere abundance of data. Relevance, cleanliness, and useability will require careful
    attention and control. The industry can leverage work from other fields such as
    the aforementioned dataset standards to achieve this. Publicly available datasets
    can also be a boon to adoption, such as those listed in (Cole, 2022, Rieke, 2022).
    8. Discussion & conclusion In the area of ML in EO Operations, this evaluation
    effort covers different aspects, including ground operations, enhanced GNC, on-board
    image processing, FDIR, and standardization. It examined the state of the field,
    which serves as a baseline, and brought to light intriguing trends. We have discovered
    that there is mounting evidence in numerous application sectors that EO missions
    can benefit from ML usage on-board. Case studies uncovered have demonstrated advancements
    in platform autonomy and performance. New capabilities, such as automated payload
    data filtering by sending only pertinent photos to the ground, can lower downlink
    bandwidth requirements, which is crucial for smaller satellites but also lessens
    radio frequency band saturation. Better visual-based processing also makes it
    possible for spacecraft to navigate using their visual systems, and RL shows promise
    in developing more effective nonlinear controllers. Better autonomous decision-making
    for EO missions is made possible by autonomous FDIR operations, allowing current
    teams to manage more operations more efficiently and lowering satellite operating
    costs. On-board processors must meet high criteria imposed by ML algorithms. A
    significant difficulty is the need to optimize ML models for space applications
    at the hardware and software levels. The good news for space platform operators
    is that this reflects and exemplifies the considerably more difficult task of
    installing ML on edge platforms. The community can benefit from a sizable and
    growing body of knowledge and expertise. From the perspective of on-board EO applications,
    ML has mostly been used for cloud detection and novelty/change detection. These
    applications frequently use vision-based techniques. EO applications could learn
    technical knowledge from other technical disciplines that have extensively researched
    vision-based ML methods and solutions. There are a few examples of SAR-based images
    as well, though. This would imply that there is still an opportunity for advancement
    and growth of these sensors in all-weather, all-day usage. A parallel but closely
    related track to research and applications is being standardized. There are currently
    no established standards for ML in the space industry. Key areas, including explainability,
    robustness, and data structure creation, are the subject of rigorous research.
    EO Operators creating ML applications ought to make use of this area for improved
    performance and dependability. These research areas should be taken into account
    by organizations intending to publish standards and guidelines, but they must
    be avoided at all costs to prevent over-prescription of remedies that might compromise
    the success of standardization development. Another important element that unites
    all ML-based EO Operations is the availability of data. The ability to use more
    data for machine learning in EO operations might significantly advance technology
    and benefit all participants, including business, academia, and space agencies.
    There are not many open datasets available right now, and those are mostly designed
    for image processing or visual navigation applications. The technological improvement
    favored by open datasets in a wider range of applications is a significant long-term
    goal for the space sector, even while it may be counter to a particular organization''s
    short-term goals to disclose private data. We think the field should concentrate
    on producing and disseminating such open datasets, and we encourage players without
    a profit motive like space agencies, to take the lead in attaining this goal.
    The fact that currently, few EO missions have used ML in orbit is a common finding
    across the subtopics of this review. This can be ascribed to the space industry''s
    lengthy lead periods and slow cycles, which contrast with other sectors, such
    the automotive industry, which have embraced the technology. We anticipate that
    these cycles can be sped up as technology demonstrators move quickly from test
    benches to orbit with the advent of New Space and faster access to space. Further
    enhancing the efficiency of ML deployments in the EO Operations industry and the
    space industry at large, increasing the number of missions can result in better
    data collecting and platform standardization. Based on the preceding critical
    review, it is quite evident that incorporating ML into EO operation can maximize
    its potential and promote additional study. The following key topics will be the
    focus of EO research in light of current trends and requirements: 1. Investigating
    the Machine Learning-based Mission Planning and Scheduling (MPS), 2. Examine the
    potential for Machine Learning techniques to improve Guidance, Navigation and
    Control (GNC) in space operations, 3. Examine the potential of ML techniques to
    assist with on-board data processing (OBDP), 4. Explore the effectiveness of incorporating
    ML models into resource-constrained platforms, 5. Investigate the effectiveness
    of Fault Detection, Isolation and Recovery (FDIR) using Machine Learning techniques.
    Not to mention, we have found that the use of ML for EO operations frequently
    lags behind the state-of-the-art. Transformer models on sequential and other data
    are one example of a technique that has achieved significant success in research
    and operational environments but has not yet been publicly used for EO Operations
    issues. Similar to formal verification and other verified robustness techniques,
    there are very few applications for resource reduction strategies like pruning,
    distillation, or quantization. Researchers and operators can use this critical
    assessment as a resource for further ML deployment and experimentation in demanding,
    complicated future EO missions that are more autonomous, communicate only useful
    data, and require much less involvement. Declaration of Competing Interest The
    authors declare that they have no known competing financial interests or personal
    relationships that could have appeared to influence the work reported in this
    paper. Acknowledgements The authors would like to acknowledge the three partner
    organisations: Mindseed, Satsure, and CNES. Mindseed (“Mindseed,” 2022.) is a
    company focused on bridging the gap between space and non-space organisations
    and showcasing the benefits of space for all. Satsure (“SatSure,” 2022.) is an
    innovative decision analytics company leveraging advances in satellite remote
    sensing and Machine Learning to achieve the United Nations Sustainable Development
    Goals. CNES (“cnes | Le site du Centre national d’études spatiales,” 2022.) is
    the French National Space Agency, with activities all over the space value chain.
    Their Earth Observation Operations teams provided invaluable feedback for our
    research. Our three partners reviewed our research, and we are deeply thankful
    for their collaboration. References AC 25.1309-1A - System Design and Analysis
    – Document Information, 1988 AC 25.1309-1A - System Design and Analysis – Document
    Information, 1988. URL https://www.faa.gov/regulations_policies/advisory_circulars/index.cfm/go/document.information/documentid/22680
    (accessed 9.11.21). Google Scholar Alam et al., 2022 Alam, S.A., Gregg, D., Gambardella,
    G., Preusser, M., Blott, M., 2022. On the RTL Implementation of FINN Matrix Vector
    Compute Unit. Google Scholar Alhichri et al., 2018 Alhichri, H., Alajlan, N.,
    Bazi, Y., Rabczuk, T., 2018. Multi-Scale Convolutional Neural Network for Remote
    Sensing Scene Classification, in: 2018 IEEE International Conference on Electro/Information
    Technology (EIT). pp. 1–5. https://doi.org/10.1109/EIT.2018.8500107. Google Scholar
    Anderson and Berg, 2017 Anderson, A.G., Berg, C.P., 2017. The High-Dimensional
    Geometry of Binary Neural Networks. ArXiv170507199 Cs. Google Scholar Arechiga
    et al., 2018 Arechiga, A.P., Michaels, A.J., Black, J.T., 2018. Onboard Image
    Processing for Small Satellites, in: NAECON 2018 - IEEE National Aerospace and
    Electronics Conference. pp. 234–240. https://doi.org/10.1109/NAECON.2018.8556744.
    Google Scholar Arechiga et al., 2018 Arechiga, A.P., Michaels, A.J., Black, J.T.,
    2018. Onboard Image Processing for Small Satellites, in: NAECON 2018 - IEEE National
    Aerospace and Electronics Conference. Presented at the NAECON 2018 - IEEE National
    Aerospace and Electronics Conference, pp. 234–240. https://doi.org/10.1109/NAECON.2018.8556744.
    Google Scholar Asmaa et al., 2020 Asmaa, A., Haikel, A., Yakoub, B., 2020. SqueezeNet
    with Attention for Remote Sensing Scene Classification. Google Scholar Azarbad
    et al., 2014 M. Azarbad, H. Azami, S. Sanei, A. Ebrahimzadeh New neural network-based
    approaches for GPS GDOP classification based on neuro-fuzzy inference system,
    radial basis function, and improved bee algorithm Appl. Soft Comput., 25 (2014),
    pp. 285-292, 10.1016/j.asoc.2014.09.022 View PDFView articleView in ScopusGoogle
    Scholar Ba and Caruana, 2013 Ba, L.J., Caruana, R., 2013. Do Deep Nets Really
    Need to be Deep? Google Scholar Baker et al., 2017 Baker, B., Gupta, O., Naik,
    N., Raskar, R., 2017. Designing Neural Network Architectures using Reinforcement
    Learning. ArXiv161102167 Cs. Google Scholar Baranwal et al., 2018 Baranwal, P.,
    Batta, K., Kaushik, T., 2018. Comparative Study of Classical and Fuzzy PID Attitude
    Control System with Extended Kalman Filter Feedback for Nanosatellites. Google
    Scholar Bazzi et al., 2020 H. Bazzi, D. Ienco, N. Baghdadi, M. Zribi, V. Demarez
    Distilling before refine: spatio-temporal transfer learning for mapping irrigated
    areas using Sentinel-1 time series IEEE Geosci. Remote Sens. Lett., 17 (2020),
    pp. 1909-1913, 10.1109/LGRS.2019.2960625 View in ScopusGoogle Scholar Belward
    and Skøien, 2015 A.S. Belward, J.O. Skøien Who launched what, when and why; trends
    in global land-cover observation capacity from civilian earth observation satellites
    ISPRS J. Photogramm. Remote Sens. Global Land Cover Mapping Monit., 103 (2015),
    pp. 115-128, 10.1016/j.isprsjprs.2014.03.009 View PDFView articleView in ScopusGoogle
    Scholar Blalock et al., 2020 Blalock, D., Ortiz, J.J.G., Frankle, J., Guttag,
    J., 2020. What is the State of Neural Network Pruning? ArXiv200303033 Cs Stat.
    Google Scholar Bonnet et al., 2015 J. Bonnet, M.-P. Gleizes, E. Kaddoum, S. Rainjonneau,
    G. Flandin Multi-satellite Mission Planning Using a Self-Adaptive Multi-agent
    System In: 2015 IEEE 9th International Conference on Self-Adaptive and Self-Organizing
    Systems, IEEE, Cambridge, MA, USA (2015), pp. 11-20, 10.1109/SASO.2015.9 View
    in ScopusGoogle Scholar Browne et al., 2020 D. Browne, M. Giering, S. Prestwich
    PulseNetOne: fast unsupervised pruning of convolutional neural networks for remote
    sensing Remote Sens., 12 (2020), p. 1092, 10.3390/rs12071092 View in ScopusGoogle
    Scholar Bruhn et al., 2020 Bruhn, F.C., Tsog, N., Kunkel, F., Flordal, O., 2020.
    Enabling radiation tolerant heterogeneous GPU‑based onboard data processing in
    space. Vol01234567891 3CEAS Space Journa 12, 551–564. Google Scholar Buonaiuto
    et al., 2017 Buonaiuto, N., Kief, C., Louie, M., Aarestad, J., Zufelt, B., Mital,
    R., Mateik, D., Sivilli, R., Bhopale, A., 2017. Satellite Identification Imaging
    for Small Satellites Using NVIDIA 12. Google Scholar Cai et al., 2003 Cai, Y.,
    Hu, Y., Siegel, M., Gollapalli, S.J., Venugopal, A.R., Bardak, U., 2003. Onboard
    Feature Indexing from Satellite Lidar Images 4. Google Scholar Cappi et al., 2021
    Cappi, C., Chapdelaine, C., Gardes, L., Jenn, E., Lefevre, B., Picard, S., Soumarmon,
    T., 2021. Dataset Definition Standard (DDS). ArXiv210103020 Cs. Google Scholar
    Castaño et al., 2007 Ricard Castaño, Steve Ankuo Chien, Kiri L. Wagstaff, Timothy
    M. Stough, 2007. On-board analysis of uncalibrated data for a spacecraft at mars,
    in: Proceedings of the 13th ACM SIGKDD International Conference on Knowledge Discovery
    and Data Mining, San Jose, California, USA, August 12-15, 2007. San Jose, California,
    USA. https://doi.org/10.1145/1281192.1281291. Google Scholar Castelluccio et al.,
    2015 Castelluccio, M., Poggi, G., Sansone, C., Verdoliva, L., 2015. Land Use Classification
    in Remote Sensing Images by Convolutional Neural Networks. ArXiv150800092 Cs.
    Google Scholar Chai et al., 2020 Y. Chai, K. Fu, X. Sun, W. Diao, Z. Yan, Y. Feng,
    L. Wang Compact cloud detection with bidirectional self-attention knowledge distillation
    Remote Sens., 12 (2020), p. 2770, 10.3390/rs12172770 View in ScopusGoogle Scholar
    Chan et al., 2018 M. Chan, D. Scarafoni, R. Duarte, J. Thornton, L. Skelly Learning
    Network Architectures of Deep CNNs Under Resource Constraints In: 2018 IEEE/CVF
    Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), IEEE,
    Salt Lake City, UT, USA (2018), pp. 1784-17847, 10.1109/CVPRW.2018.00222 Google
    Scholar Chen et al., 2019 Chen, H., Zhang, H., Boning, D., Hsieh, C.-J., 2019.
    Robust Decision Trees Against Adversarial Examples. ArXiv190210660 Cs Stat. Google
    Scholar Chen et al., 2021 Chen, Y., Bian, Y., Xiao, X., Rong, Y., Xu, T., Huang,
    J., 2021. On Self-Distilling Graph Neural Network. ArXiv201102255 Cs Stat. Google
    Scholar Chen et al., 2018 G. Chen, X. Zhang, X. Tan, Y. Cheng, F. Dai, K. Zhu,
    Y. Gong, Q. Wang Training small networks for scene classification of remote sensing
    images via knowledge distillation Remote Sens., 10 (2018), p. 719, 10.3390/rs10050719
    View in ScopusGoogle Scholar Cheng and Yan, 2021 Cheng, C.-H., Yan, R., 2021.
    Testing Autonomous Systems with Believed Equivalence Refinement. ArXiv210304578
    Cs. Google Scholar Cheng et al., 2009 C.-H. Cheng, S.-L. Shu, P.-J. Cheng Attitude
    control of a satellite using fuzzy controllers Expert Syst. Appl., 36 (2009),
    pp. 6613-6620, 10.1016/j.eswa.2008.08.053 View PDFView articleView in ScopusGoogle
    Scholar Chien et al., 2017 S. Chien, J. Doubleday, D.R. Thompson, K.L. Wagstaff,
    J. Bellardo, C. Francis, E. Baumgarten, A. Williams, E. Yee, E. Stanton, J. Piug-Suari
    Onboard autonomy on the intelligent payload experiment cubesat mission J. Aerosp.
    Inf. Syst., 14 (2017), pp. 307-315, 10.2514/1.I010386 View in ScopusGoogle Scholar
    cnes | Le site du Centre national d’études spatiales, 2022 cnes | Le site du Centre
    national d’études spatiales, 2022. URL https://cnes.fr/fr/ (accessed 7.18.22).
    Google Scholar Codetta-Raiteri and Portinale, 2015 D. Codetta-Raiteri, L. Portinale
    Dynamic bayesian networks for fault detection, identification, and recovery in
    autonomous spacecraft IEEE Trans. Syst. Man Cybern. Syst., 45 (2015), pp. 13-24,
    10.1109/TSMC.2014.2323212 View in ScopusGoogle Scholar Cole, 2022 Cole, R.M.,
    2022. satellite-image-deep-learning. Google Scholar Courbariaux et al., 2015 M.
    Courbariaux, Y. Bengio, J.-P. David BinaryConnect: Training Deep Neural Networks
    with binary weights during propagations C. Cortes, N. Lawrence, D. Lee, M. Sugiyama,
    R. Garnett (Eds.), Advances in Neural Information Processing Systems, Curran Associates
    Inc (2015) Google Scholar D’Souza, 2019 Faisal D’Souza, 2019. The National Artificial
    Intelligence Research and Development Strategic Plan: 2019 Update 50. Google Scholar
    de Vieilleville et al., 2020 F. de Vieilleville, A. Lagrange, R. Ruiloba, S. May
    Towards distillation of deep neural networks for satellite on-board image segmentation
    Int. Arch. Photogramm. Remote Sens. Spat. Inf. Sci., 43 (2020), pp. 1553-1559
    CrossRefView in ScopusGoogle Scholar Deepan and Sudha, 2020 Deepan, P., Sudha,
    L.R., 2020. Object Classification of Remote Sensing Image Using Deep Convolutional
    Neural Network, in: The Cognitive Approach in Cloud Computing and Internet of
    Things Technologies for Surveillance Tracking Systems. Elsevier, pp. 107–120.
    https://doi.org/10.1016/B978-0-12-816385-6.00008-8. Google Scholar Del Rosso et
    al., 2021 M.P. Del Rosso, A. Sebastianelli, D. Spiller, P.P. Mathieu, S.L. Ullo
    On-board volcanic eruption detection through CNNs and satellite multispectral
    imagery Remote Sens., 13 (2021), p. 3479, 10.3390/rs13173479 View in ScopusGoogle
    Scholar Di, 2008 L. Di Standards, Critical Evaluation of Remote Sensing S. Shekhar,
    H. Xiong (Eds.), Encyclopedia of GIS, Springer, US, Boston, MA (2008), pp. 1128-1135,
    10.1007/978-0-387-35973-1_1346 Google Scholar Di and Kobler, 2000 Liping Di, Ben
    Kobler, 2000. NASA Standards for Earth Remote Sensing Data, URL https://www.researchgate.net/publication/228953572_NASA_Standards_for_Earth_Remote_Sensing_Data
    (accessed 9.4.21) Google Scholar Du et al., 2020 Y. Du, T. Wang, B. Xin, L. Wang,
    Y. Chen, L. Xing A data-driven parallel scheduling approach for multiple agile
    earth observation satellites IEEE Trans. Evol. Comput., 24 (2020), pp. 679-693,
    10.1109/TEVC.2019.2934148 View in ScopusGoogle Scholar Elsken et al., 2019 Elsken,
    T., Metzen, J.H., Hutter, F., 2019. Neural Architecture Search: A Survey. ArXiv180805377
    Cs Stat. Google Scholar Esposito et al., 2019 M. Esposito, S.S. Conticello, M.
    Pastena, B.C. Domínguez In-orbit demonstration of artificial intelligence applied
    to hyperspectral and thermal sensing from space CubeSats and SmallSats for Remote
    Sensing III, International Society for Optics and Photonics (2019), p. 111310C,
    10.1117/12.2532262 View in ScopusGoogle Scholar Férésin et al., 2021 Frédéric
    Férésin, Erwann Kervennic, Yves Bobichon, Edgar Lemaire, Nassim Abderrahmane,
    Gaétan Bahk, Ingrid Grenet, Matthieu Moretti, Michaël Benguigui, 2021. In space
    image processing using AI embedded on system on module : example of OPS-SAT cloud
    segmentation. Google Scholar Flandin, 2021 Gregory Flandin, 2021. White Paper
    Machine Learning in Certified System 113. Google Scholar Fourati and Alouini,
    2021 F. Fourati, M.-S. Alouini Artificial intelligence for satellite communication:
    A review Intelligent and Converged Networks, 2 (3) (2021), pp. 213-243, 10.23919/ICN.2021.0015
    Google Scholar Frankle et al., 2021 Frankle, J., Dziugaite, G.K., Roy, D.M., Carbin,
    M., 2021. Pruning Neural Networks at Initialization: Why are We Missing the Mark?
    ArXiv200908576 Cs Stat. Google Scholar Fuertes et al., 2018 S. Fuertes, B. Pilastre,
    S. D’Escrivan Performance assessment of NOSTRADAMUS & other machine learning-based
    telemetry monitoring systems on a spacecraft anomalies database In: 2018 SpaceOps
    Conference, American Institute of Aeronautics and Astronautics, Marseille, France
    (2018), 10.2514/6.2018-2559 Google Scholar Georges et al., 2021 Georges, L., Tanguy,
    S., Evridiki, N., David, E., 2021. In-Flight Training of a FDIR Model with Online
    Machine Learning on the OPS-SAT Spacecraft. URL https://github.com/georgeslabreche/opssat-orbitai/find/main
    (accessed 9.12.21). Google Scholar Giuffrida et al., 2020 G. Giuffrida, L. Diana,
    F. de Gioia, G. Benelli, G. Meoni, M. Donati, L. Fanucci CloudScout: a deep neural
    network for on-board cloud detection on hyperspectral images Remote Sens., 12
    (2020), p. 2205, 10.3390/rs12142205 View in ScopusGoogle Scholar Giuffrida et
    al., 2022 G. Giuffrida, L. Fanucci, G. Meoni, M. Batič, L. Buckley, A. Dunne,
    C. van Dijk, M. Esposito, J. Hefele, N. Vercruyssen, G. Furano, M. Pastena, J.
    Aschbacher The Φ-Sat-1 mission: the first on-board deep neural network demonstrator
    for satellite Earth observation IEEE Trans. Geosci. Remote Sens., 60 (2022), pp.
    1-14, 10.1109/TGRS.2021.3125567 Google Scholar Globus et al., 2003 Globus, A.,
    Crawford, J., Lohn, J., Pryor, A., 2003. Scheduling Earth Observing Satellites
    with Evolutionary Algorithms. Google Scholar Goel et al., 2020 A. Goel, C. Tung,
    Y.-H. Lu, G.K. Thiruvathukal A Survey of Methods for Low-Power Deep Learning and
    Computer Vision In: 2020 IEEE 6th World Forum on Internet of Things (WF-IoT).
    Presented at the 2020 IEEE 6th World Forum on Internet of Things (WF-IoT) (2020),
    pp. 1-6, 10.1109/WF-IoT48130.2020.9221198 Google Scholar Gong et al., 2014 Gong,
    Y., Liu, L., Yang, M., Bourdev, L., 2014. Compressing Deep Convolutional Networks
    using Vector Quantization. ArXiv14126115 Cs. Google Scholar Goodfellow et al.,
    2015 Goodfellow, I.J., Shlens, J., Szegedy, C., 2015. Explaining and Harnessing
    Adversarial Examples. ArXiv14126572 Cs Stat. Google Scholar Goodwill et al., 2020
    Goodwill, J., Wilson, D., Sabogal, S., George, A.D., Wilson, C., 2020. Adaptively
    Lossy Image Compression for Onboard Processing, in: 2020 IEEE Aerospace Conference.
    pp. 1–15. https://doi.org/10.1109/AERO47225.2020.9172536. Google Scholar Goodwill
    et al., 2021 Goodwill, J., Crum, G., MacKinnon, J., Brewer, C., Monaghan, M.,
    Wise, T., Wilson, C., 2021. NASA SpaceCube Edge TPU SmallSat Card for Autonomous
    Operations and Onboard Science-Data Analysis 13. Google Scholar Graham et al.,
    2023 Graham, Thomas & Thangavel, Kathiravan & Martin, Anne-Sophie. (2023). New
    Challenges for International Space Law: Artificial Intelligence and Liability.
    17th International Conference on Space Operations, Dubai, United Arab Emirates.
    Google Scholar Guo et al., 2017 Q. Guo, B. Fu, P. Shi, T. Cudahy, J. Zhang, H.
    Xu Satellite monitoring the spatial-temporal dynamics of desertification in response
    to climate change and human activities across the Ordos Plateau, China Remote
    Sens., 9 (2017), p. 525, 10.3390/rs9060525 View PDFView articleGoogle Scholar
    Guo, 2018 Guo, Y., 2018. A Survey on Methods and Theories of Quantized Neural
    Networks. ArXiv180804752 Cs Stat. Google Scholar Hadj-Salah et al., 2019 Hadj-Salah,
    A., Verdier, R., Caron, C., Picard, M., Capelle, M., 2019. Schedule Earth Observation
    satellites with Deep Reinforcement Learning. ArXiv191105696 Cs. Google Scholar
    Hadj-Salah et al., 2020 Hadj-Salah, A., Guerra, J., Picard, M., Capelle, M., 2020.
    Towards operational application of Deep Reinforcement Learning to Earth Observation
    satellite scheduling. Google Scholar Haikel, 2018 Haikel, A., 2018. Multitask
    Classification of Remote Sensing Scenes Using Deep Neural Networks. Spain. Google
    Scholar Han et al., 2016 Han, S., Mao, H., Dally, W.J., 2016. Deep Compression:
    Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman
    Coding. ArXiv151000149 Cs. Google Scholar Han et al., 2015 H. Han, S. Lee, J.
    Im, M. Kim, M.-I. Lee, M.H. Ahn, S.-R. Chung Detection of convective initiation
    using meteorological imager onboard communication, ocean, and meteorological satellite
    based on machine learning approaches Remote Sens., 7 (2015), pp. 9184-9204, 10.3390/rs70709184
    View in ScopusGoogle Scholar He et al., 2014 He, T., Fan, Y., Qian, Y., Tan, T.,
    Yu, K., 2014. Reshaping deep neural network for fast decoding by node-pruning,
    in: 2014 IEEE International Conference on Acoustics, Speech and Signal Processing
    (ICASSP). IEEE, Florence, Italy, pp. 245–249. https://doi.org/10.1109/ICASSP.2014.6853595.
    Google Scholar He et al., 2021 X. He, K. Zhao, X. Chu AutoML: a survey of the
    state-of-the-art Knowl.-Based Syst., 212 (2021), Article 106622, 10.1016/j.knosys.2020.106622
    View PDFView articleView in ScopusGoogle Scholar Hernández-Gómez et al., 2019
    Hernández-Gómez, J.J., Yañez-Casas, G.A., Torres-Lara, A.M., Couder-Castañeda,
    C., Orozco-del-Castillo, M.G., Valdiviezo-Navarro, J.C., Medina, I., Solís-Santomé,
    A., Vázquez-Álvarez, D., Chávez-López, P.I., 2019. Conceptual low-cost on-board
    high performance computing in CubeSat nanosatellites for pattern recognition in
    Earth’s remote sensing. pp. 114–104. https://doi.org/10.29007/8d25. Google Scholar
    Hinz et al., 2020 Hinz, R., Bravo, J.I., Kerr, M., Marcos, C., Latorre, A., Membibre,
    F., 2020. EO-ALERT: Machine Learning-Based On-Board Satellite Processing for Very-Low
    Latency Convective Storm Nowcasting 1. Google Scholar Hoeser et al., 2020 T. Hoeser,
    F. Bachofer, C. Kuenzer Object detection and image segmentation with deep learning
    on earth observation data: a review—part II: applications Remote Sens., 12 (2020),
    p. 3053, 10.3390/rs12183053 View in ScopusGoogle Scholar Howard et al., 2017 Howard,
    A.G., Zhu, M., Chen, B., Kalenichenko, D., Wang, W., Weyand, T., Andreetto, M.,
    Adam, H., 2017. MobileNets: Efficient Convolutional Neural Networks for Mobile
    Vision Applications. ArXiv170404861 Cs. Google Scholar Huq et al., 2018 Huq, R.,
    Bappy, M., Siddique, S., 2018. AI-OBC: Conceptual Design of a Deep Neural Network
    based Next Generation Onboard Computing Architecture for Satellite Systems. Google
    Scholar Iandola et al., 2016 Iandola, F.N., Han, S., Moskewicz, M.W., Ashraf,
    K., Dally, W.J., Keutzer, K., 2016. SqueezeNet: AlexNet-level accuracy with 50x
    fewer parameters and <0.5MB model size. ArXiv160207360 Cs. Google Scholar Ireland,
    2019 Ireland, M., 2019. Integrating AI Techniques Into Future Nanosatellite Onboard
    Data Processing 30. Google Scholar Iverson, 2008 Iverson, D.L., 2008. System Health
    Monitoring for Space Mission Operations, in: 2008 IEEE Aerospace Conference. IEEE,
    Big Sky, MT, USA, pp. 1–8. https://doi.org/10.1109/AERO.2008.4526646. Google Scholar
    Izzo and Öztürk, 2021 Izzo, D., Öztürk, E., 2021. Real-Time Guidance for Low-Thrust
    Transfers Using Deep Neural Networks. J. Guid. Control Dyn. 44, 315–327. https://doi.org/10.2514/1.G005254.
    Google Scholar Izzo et al., 2018 Izzo, D., Märtens, M., Pan, B., 2018. A Survey
    on Artificial Intelligence Trends in Spacecraft Guidance Dynamics and Control.
    ArXiv181202948 Cs. Google Scholar Jaekel and Scholz, 2015 Jaekel, S., Scholz,
    B., 2015. Utilizing Artificial Intelligence to achieve a robust architecture for
    future robotic spacecraft, in: 2015 IEEE Aerospace Conference. IEEE, Big Sky,
    MT, pp. 1–14. https://doi.org/10.1109/AERO.2015.7119180. Google Scholar Jalilian
    et al., 2017 Jalilian, S., SalarKaleji, F., Kazimov, T., 2017. Fault detection,
    isolation and recovery (FDIR) in satellite onboard software. https://doi.org/10.25045/NCSoftEng.2017.87.
    Google Scholar Joghataie, 1994 Joghataie, A., 1994. Neural Networks and Fuzzy
    Logic for Structural Control. University of Illinois Engineering Experiment Station.
    College of Engineering. University of Illinois at Urbana-Champaign. Google Scholar
    Katz et al., 2017 Katz, G., Barrett, C., Dill, D., Julian, K., Kochenderfer, M.,
    2017. Reluplex: An Efficient SMT Solver for Verifying Deep Neural Networks. ArXiv170201135
    Cs. Google Scholar Kavzoglu and Mather, 1999 T. Kavzoglu, P.M. Mather Pruning
    artificial neural networks: an example using land cover classification of multi-sensor
    images Int. J. Remote Sens., 20 (1999), pp. 2787-2803, 10.1080/014311699211796
    View in ScopusGoogle Scholar Kim et al., 2016 Kim, S.-W., Park, S.-Y., Park, C.,
    2016. Spacecraft attitude control using neuro-fuzzy approximation of the optimal
    controllers. Adv. Space Res. 57, 137–152. https://doi.org/10.1016/j.asr.2015.09.016.
    Google Scholar Koizumi et al., 2018 Koizumi, S., Kikuya, Y., Sasaki, K., Masuda,
    Y., Iwasaki, Y., Watanabe, K., Yatsu, Y., Matsunaga, S., 2018. Development of
    Attitude Sensor using Deep Learning 8. Google Scholar Kothari et al., 2020 Kothari,
    V., Liberis, E., Lane, N.D., 2020. The Final Frontier: Deep Learning in Space.
    ArXiv200110362 Cs Eess. Google Scholar Krizhevsky et al., 2012 A. Krizhevsky,
    I. Sutskever, G.E. Hinton ImageNet Classification with Deep Convolutional Neural
    Networks Advances in Neural Information Processing Systems, Curran Associates
    Inc. (2012) Google Scholar Kucik and Meoni, 2021 Kucik, A., Meoni, G., 2021. Investigating
    Spiking Neural Networks for Energy-Efficient On-Board AI Applications. A Case
    Study in Land Cover and Land Use Classification. https://doi.org/10.1109/CVPRW53098.2021.00230
    Google Scholar Lane et al., 2015 Lane, N.D., Bhattacharya, S., Georgiev, P., Forlivesi,
    C., Kawsar, F., 2015. An Early Resource Characterization of Deep Learning on Wearables,
    Smartphones and Internet-of-Things Devices, in: Proceedings of the 2015 International
    Workshop on Internet of Things towards Applications. ACM, Seoul South Korea, pp.
    7–12. https://doi.org/10.1145/2820975.2820980 Google Scholar Larq | Binarized
    Neural Network development, 2022 Larq | Binarized Neural Network development,
    2022. URL https://larq.dev/ (accessed 7.28.21). Google Scholar Larry et al., 2019
    R. Larry, K.A. Davis, H.L. Fishburn, L.R. Moore, J.L. Walter US Topo Product Standard
    (Techniques and Methods) Techniques and Methods (2019) Google Scholar Lazarevic
    and Obradovic, 2001 Lazarevic, A., Obradovic, Z., 2001. Effective pruning of neural
    network classifier ensembles, in: IJCNN’01. International Joint Conference on
    Neural Networks. Proceedings (Cat. No.01CH37222). IEEE, Washington, DC, USA, pp.
    796–801. https://doi.org/10.1109/IJCNN.2001.939461. Google Scholar Li et al.,
    2014 J. Li, J. Li, H. Chen, N. Jing A data transmission scheduling algorithm for
    rapid-response earth-observing operations Chin. J. Aeronaut., 27 (2014), pp. 349-364,
    10.1016/j.cja.2014.02.014 View PDFView articleView in ScopusGoogle Scholar Liang
    et al., 2020 W. Liang, J. Li, W. Diao, X. Sun, K. Fu, Y. Wu FGATR-net: automatic
    network architecture design for fine-grained aircraft type recognition in remote
    sensing images Remote Sens., 12 (2020), p. 4187, 10.3390/rs12244187 Google Scholar
    Linardatos et al., 2021 Linardatos, P., Papastefanopoulos, V., Kotsiantis, S.,
    2021. Explainable AI: A Review of Machine Learning Interpretability Methods. Entropy
    23, 18. https://doi.org/10.3390/e23010018. Google Scholar Liu et al., 2018 R.
    Liu, B. Yang, E. Zio, X. Chen Artificial intelligence for fault diagnosis of rotating
    machinery: a review Mech. Syst. Signal Process., 108 (2018), pp. 33-47, 10.1016/j.ymssp.2018.02.016
    View PDFView articleView in ScopusGoogle Scholar Liu, 2020 Liu, X., 2020. Mission
    schedule of agile satellites based on Proximal Policy Optimization Algorithm.
    ArXiv200702352 Cs. Google Scholar Liu, et al., 2021 Liu, Yuchen, et al. “Mission
    Planning for Earth Observation Satellite With Competitive Learning Strategy.”
    Aerospace Science and Technology, vol. 118, Elsevier BV, Nov. 2021, p. 107047.
    Crossref, https://doi.org/10.1016/j.ast.2021.107047. Google Scholar Ma et al.,
    2019 N. Ma, X. Yu, Y. Peng, S. Wang A lightweight hyperspectral image anomaly
    detector for real-time mission Remote Sens., 11 (2019), p. 1622, 10.3390/rs11131622
    View in ScopusGoogle Scholar Maggiori et al., 2017 E. Maggiori, Y. Tarabalka,
    G. Charpiat, P. Alliez Convolutional neural networks for large-scale remote-sensing
    image classification IEEE Trans. Geosci. Remote Sens., 55 (2017), pp. 645-657,
    10.1109/TGRS.2016.2612821 View in ScopusGoogle Scholar Mahajan and Fataniya, 2020
    S. Mahajan, B. Fataniya Cloud detection methodologies: variants and development—a
    review Complex Intell. Syst., 6 (2020), pp. 251-261, 10.1007/s40747-019-00128-0
    View in ScopusGoogle Scholar Manning et al., 2018 J. Manning, D. Langerman, B.
    Ramesh, E. Gretok, C. Wilson, A. George, J. MacKinnon, G. Crum Machine-Learning
    Space Applications on SmallSat Platforms with TensorFlow Small Satell, Conf (2018)
    Google Scholar Mansour and Dessouky, 2010 M.A.A. Mansour, M.M. Dessouky A genetic
    algorithm approach for solving the daily photograph selection problem of the SPOT5
    satellite Comput. Ind. Eng., 58 (2010), pp. 509-520, 10.1016/j.cie.2009.11.012
    View PDFView articleView in ScopusGoogle Scholar Maskey and Cho, 2020 A. Maskey,
    M. Cho CubeSatNet: ultralight convolutional neural network designed for on-orbit
    binary image classification on a 1U CubeSat Eng. Appl. Artif. Intell., 96 (2020),
    Article 103952, 10.1016/j.engappai.2020.103952 View PDFView articleView in ScopusGoogle
    Scholar Meß, 2019 Meß, J.-G., 2019. Techniques of Artificial Intelligence for
    Space Applications - A Survey. Google Scholar Mirman et al., 2018 M. Mirman, T.
    Gehr, M. Vechev Differentiable abstract interpretation for provably robust neural
    networks Int. Conf. Mach. Learn. PMLR (2018), pp. 3578-3586 Google Scholar Mishra
    et al., 2017 Mishra, A., Cook, J.J., Nurvitadhi, E., Marr, D., 2017. WRPN: Training
    and Inference using Wide Reduced-Precision Networks. ArXiv170403079 Cs. Google
    Scholar Mittal, 2019 S. Mittal A survey on optimized implementation of deep learning
    models on the NVIDIA Jetson platform J. Syst. Archit., 97 (2019), pp. 428-442,
    10.1016/j.sysarc.2019.01.011 View PDFView articleView in ScopusGoogle Scholar
    Mnih et al., 2013 Mnih, V., Kavukcuoglu, K., Silver, D., Graves, A., Antonoglou,
    I., Wierstra, D., Riedmiller, M., 2013. Playing Atari with Deep Reinforcement
    Learning. ArXiv13125602 Cs. Google Scholar Molchanov et al., 2017 Molchanov, D.,
    Ashukha, A., Vetrov, D., 2017. Variational Dropout Sparsifies Deep Neural Networks.
    ArXiv170105369 Cs Stat. Google Scholar Molnar, 2021 Molnar, C., 2021. Interpretable
    Machine Learning. Google Scholar Müller et al., 2021 Müller, M.N., Makarchuk,
    G., Singh, G., Püschel, M., Vechev, M., 2021. PRIMA: Precise and General Neural
    Network Certification via Multi-Neuron Convex Relaxations 20. Google Scholar Nguyen
    et al., 2019 Nguyen, C.V., Achille, A., Lam, M., Hassner, T., Mahadevan, V., Soatto,
    S., 2019. Toward Understanding Catastrophic Forgetting in Continual Learning.
    ArXiv190801091 Cs Stat. Google Scholar O’Meara et al., 2016 O’Meara, C., Schlag,
    L., Faltenbacher, L., Wickler, M., 2016. ATHMoS: Automated Telemetry Health Monitoring
    System at GSOC using Outlier Detection and Supervised Machine Learning. https://doi.org/10.2514/6.2016-2347.
    Google Scholar olanleed, 2021 olanleed, 2021. MochiMochi. 2021. Accessed: Sep.
    29, 2021. [Online]. Available: https://github.com/olanleed/MochiMochi Google Scholar
    Olive, 2010 X. Olive FDI(R) for satellite at Thales Alenia Space how to deal with
    high availability and robustness in space domain? In: 2010 Conference on Control
    and Fault-Tolerant Systems (SysTol). Presented at the 2010 Conference on Control
    and Fault-Tolerant Systems (SysTol), IEEE, Nice (2010), pp. 837-842, 10.1109/SYSTOL.2010.5675942
    View in ScopusGoogle Scholar Ortega, 1995 G. Ortega Fuzzy logic techniques for
    rendezvous and docking of two geostationary satellites Telemat. Inform. Adv. Space
    Technol. Syst. Auton., 12 (1995), pp. 213-227, 10.1016/0736-5853(95)00013-5 View
    PDFView articleView in ScopusGoogle Scholar Pan et al., 2021 G. Pan, Y. Xu, J.
    Ma The potential of CO2 satellite monitoring for climate governance: a review
    J. Environ. Manage., 277 (2021), Article 111423, 10.1016/j.jenvman.2020.111423
    View PDFView articleView in ScopusGoogle Scholar Pang et al., 2019 Pang, T., Xu,
    K., Du, C., Chen, N., Zhu, J., 2019. Improving Adversarial Robustness via Promoting
    Ensemble Diversity, in: Proceedings of the 36th International Conference on Machine
    Learning. PMLR, pp. 4970–4979. Google Scholar Pant, 2019 Pant, Ayush. “Workflow
    of a Machine Learning Project.” Medium, 23 Jan. 2019, towardsdatascience.com/workflow-of-a-machine-learning-project-ec1dba419b94.
    Google Scholar Peng et al., 2018 S. Peng, H. Chen, C. Du, J. Li, N. Jing Onboard
    observation task planning for an autonomous earth observation satellite using
    long short-term memory IEEE Access, 6 (2018), pp. 65118-65129, 10.1109/ACCESS.2018.2877687
    View in ScopusGoogle Scholar Pilastre, 2020 Pilastre, B., 2020. Estimation parcimonieuse
    et apprentissage de dictionnaires pour la détection d’anomalies multivariées dans
    des données mixtes de télémesure satellites (phd). Google Scholar Pitsis et al.,
    2019 Pitsis, G., Tsagkatakis, G., Kozanitis, C., Kalomoiris, I., Ioannou, A.,
    Dollas, A., Katevenis, M.G.H., Tsakalides, P., 2019. Efficient Convolutional Neural
    Network Weight Compression for Space Data Classification on Multi-fpga Platforms,
    in: ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and
    Signal Processing (ICASSP). IEEE, Brighton, United Kingdom, pp. 3917–3921. https://doi.org/10.1109/ICASSP.2019.8682732.
    Google Scholar Polino et al., 2018 Polino, A., Pascanu, R., Alistarh, D., 2018.
    Model compression via distillation and quantization. ArXiv180205668 Cs. Google
    Scholar Poortinga et al., 2021 A. Poortinga, N.S. Thwal, N. Khanal, T. Mayer,
    B. Bhandari, K. Markert, A.P. Nicolau, J. Dilger, K. Tenneson, N. Clinton, D.
    Saah Mapping sugarcane in Thailand using transfer learning, a lightweight convolutional
    neural network, NICFI high resolution satellite imagery and Google Earth Engine
    ISPRS Open J. Photogramm. Remote Sens., 1 (2021), Article 100003, 10.1016/j.ophoto.2021.100003
    View PDFView articleView in ScopusGoogle Scholar Post-training quantization |
    TensorFlow Lite, 2022 Post-training quantization | TensorFlow Lite, 2022. URL
    https://www.tensorflow.org/lite/performance/post_training_quantization (accessed
    9.28.21). Google Scholar Pruning in Keras example | TensorFlow Model Optimization,
    2022 Pruning in Keras example | TensorFlow Model Optimization , 2022. . TensorFlow.
    URL https://www.tensorflow.org/model_optimization/guide/pruning/pruning_with_keras
    (accessed 8.6.21) Google Scholar Qin et al., 2020 H. Qin, R. Gong, X. Liu, X.
    Bai, J. Song, N. Sebe Binary neural networks: a survey Pattern Recognit., 105
    (2020), Article 107281, 10.1016/j.patcog.2020.107281 View PDFView articleView
    in ScopusGoogle Scholar Quantization — PyTorch 1.9.1 documentation, 2022 Quantization
    — PyTorch 1.9.1 documentation, 2022. URL https://pytorch.org/docs/stable/quantization.html
    (accessed 7.28.21). Google Scholar Ranasinghe et al., 2022 K. Ranasinghe, R. Sabatini,
    A. Gardi, S. Bijjahalli, R. Kapoor, T. Fahey, K. Thangavel Advances in integrated
    system health management for mission-essential and safety-critical aerospace applications
    Prog. Aerosp. Sci., 128 (2022), Article 100758, 10.1016/j.paerosci.2021.100758
    View PDFView articleView in ScopusGoogle Scholar Rastegari et al., 2016 Rastegari,
    M., Ordonez, V., Redmon, J., Farhadi, A., 2016. XNOR-Net: ImageNet Classification
    Using Binary Convolutional Neural Networks. ArXiv160305279 Cs. Google Scholar
    Ricks and Mengshoel, 2021 W. Ricks, B.J. Mengshoel, O. Methods for Probabilistic
    Fault Diagnosis: An Electrical Power System Case Study Annual Conference of the
    PHM Society, 1 (1) (2021) Retrieved from https://papers.phmsociety.org/index.php/phmconf/article/view/1594More
    Citation Formats Google Scholar Rieke, 2022 Rieke, C., 2022. Awesome Satellite
    Imagery Datasets. Github: https://github.com/chrieke/awesome-satellite-imagery-datasets.
    Google Scholar SatSure, 2022 SatSure, 2022. URL: https://satsure.co/ (accessed
    7.18.22). Google Scholar Schumann et al., 2011 J. Schumann, O.J. Mengshoel, T.
    Mbaya Integrated Software and Sensor Health Management for Small Spacecraft In:
    2011 IEEE Fourth International Conference on Space Mission Challenges for Information
    Technology, IEEE, Palo Alto, CA, USA (2011), pp. 77-84, 10.1109/SMC-IT.2011.25
    View in ScopusGoogle Scholar Shalev-Shwartz, 2014 Shalev-Shwartz, S., 2014. Understanding
    Machine Learning: From Theory to Algorithms, 1st edition. ed. Cambridge University
    Press, New York, NY, USA Google Scholar Shaw and Burke, 2003 G.A. Shaw, H.K. Burke
    Spectral Imaging for Remote Sensing, 14 (2003), p. 26 View in ScopusGoogle Scholar
    Shweta, 2019 Shweta, K., 2019. A Survey on Classification of Concept Drift with
    Stream Data. Google Scholar Simons and Lee, 2019 T. Simons, D.-J. Lee A review
    of binarized neural networks Electronics, 8 (2019), p. 661, 10.3390/electronics8060661
    View in ScopusGoogle Scholar Simonyan and Zisserman, 2015 Simonyan, K., Zisserman,
    A., 2015. Very Deep Convolutional Networks for Large-Scale Image Recognition.
    ArXiv14091556 Cs. Google Scholar Song et al., 2020 Y. Song, Z. Zhou, Z. Zhang,
    F. Yao, Y. Chen A framework involving MEC: imaging satellites mission planning
    Neural Comput. Appl., 32 (2020), pp. 15329-15340, 10.1007/s00521-019-04047-6 View
    in ScopusGoogle Scholar Spiller et al., 2022 D. Spiller, K. Thangavel, S. T. Sasidharan,
    S. Amici, L. Ansalone and R. Sabatini, “Wildfire segmentation analysis from edge
    computing for on-board real-time alerts using hyperspectral imagery,” 2022 IEEE
    International Conference on Metrology for Extended Reality, Artificial Intelligence
    and Neural Engineering (MetroXRAINE), 2022, pp. 725-730, doi: 10.1109/MetroXRAINE54828.2022.9967553.
    Google Scholar Srivastava, 2003 A.N. Srivastava Onboard Detection of Snow Ice,
    Clouds and Other Geophysical Processes Using Kernel Methods (2003) Google Scholar
    Tan et al., 2019 M. Tan, B. Chen, R. Pang, V. Vasudevan, M. Sandler, A. Howard,
    Q.V. Le MnasNet: Platform-Aware Neural Architecture Search for Mobile In: 2019
    IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), IEEE, Long
    Beach, CA, USA (2019), pp. 2815-2823, 10.1109/CVPR.2019.00293 View in ScopusGoogle
    Scholar Tan et al., 2020 Q. Tan, J. Ling, J. Hu, X. Qin, J. Hu Vehicle detection
    in high resolution satellite remote sensing images based on deep learning IEEE
    Access, 8 (2020), pp. 153394-153402, 10.1109/ACCESS.2020.3017894 View in ScopusGoogle
    Scholar Tang et al., 2018 Y. Tang, J. Ji, S. Gao, H. Dai, Y. Yu, Y. Todo A pruning
    neural network model in credit classification analysis Comput. Intell. Neurosci.,
    2018 (2018), pp. 1-22, 10.1155/2018/9390410 View in ScopusGoogle Scholar Thangavel
    et al., 2022 Thangavel, K.; Spiller, D.; Sabatini, R.; Marzocca, P., 2022. On-board
    Data Processing of Earth Observation Data Using 1-D CNN. SmartSat CRC Conference,
    New South Wales, Australia, 12–13 September 2022. DOI: 10.13140/RG.2.2.16042.70088.
    Google Scholar Thangavel et al., 2023 K. Thangavel, D. Spiller, R. Sabatini, S.
    Amici, S.T. Sasidharan, H. Fayek, P. Marzocca Autonomous satellite wildfire detection
    using hyperspectral imagery and neural networks: a case study on Australian wildfire
    Remote Sens., 15 (3) (2023), p. 720 CrossRefView in ScopusGoogle Scholar Thangavel
    et al., 2023 K. Thangavel, D. Spiller, R. Sabatini, S. Amici, S.T. Sasidharan,
    H. Fayek, P. Marzocca Autonomous satellite wildfire detection using hyperspectral
    imagery and neural networks: a case study on Australian wildfire Remote Sens.,
    15 (3) (2023), p. 720 CrossRefView in ScopusGoogle Scholar Tjoa and Guan, 2020
    E. Tjoa, C. Guan A survey on explainable artificial intelligence (XAI): towards
    medical XAI IEEE Trans. Neural Netw. Learn. Syst., 1–21 (2020), 10.1109/TNNLS.2020.3027314
    Google Scholar Törnblom and Nadjm-Tehrani, 2019 J. Törnblom, S. Nadjm-Tehrani
    Formal Verification of Random Forests in Safety-Critical Applications C. Artho,
    P.C. Ölveczky (Eds.), formal Techniques for Safety-Critical Systems, Communications
    in Computer and Information Science, Springer International Publishing, Cham (2019),
    pp. 55-71, 10.1007/978-3-030-12988-0_4 View in ScopusGoogle Scholar Verzola et
    al., 2016 Ivano Verzola, Alessandro Donati, Martínez Heras, J.-A., Schubert, M.,
    Laszlo Somodi, 2016. Project Sybil : A Novelty Detection System for Human Spaceflight
    Operations, in : Proc. Int. Conf. Space Operations. Google Scholar Vladimirova
    and Atek, 2002 Vladimirova, T., Atek, S., 2002. A New Lossless Compression Method
    for Small Satellite On-Board Imaging. University of Surrey, University of Surrey
    Guildford, Surrey, GU2 7 XH United Kingdom. https://doi.org/10.1142/9789812776266_0038.
    Google Scholar Voss, 2019 S. Voss Application of Deep Learning for Spacecraft
    Fault Detection and Isolation Delft University of Technology (2019) Google Scholar
    Wagstaff et al., 2017 Wagstaff, K.L., Altinok, A., Chien, S.A., Rebbapragada,
    U., Schaffer, S.R., Thompson, D.R., Tran, D.Q., 2017. Cloud Filtering and Novelty
    Detection using Onboard Machine Learning for the EO-1 Spacecraft. Int. Jt. Conf.
    Artif. Intell. 4 Google Scholar Wahlster and Winterhalter, 2020 Wahlster, W.,
    Cristoph Winterhalter, 2020. GERMAN STANDARDIZATION ROADMAP ON ARTIFICIAL INTELLIGENCE
    226. Google Scholar Wang et al., 2018 Wang, S., Pei, K., Whitehouse, J., Yang,
    J., Jana, S., 2018. Formal Security Analysis of Neural Networks using Symbolic
    Intervals. ArXiv180410829 Cs. Google Scholar Wang et al., 2019 Wang, Y., Ma, Z.,
    Yang, Y., Wang, Z., tang, L., 2019. A New Spacecraft Attitude Stabilization Mechanism
    Using Deep Reinforcement Learning Method 13 pages. https://doi.org/10.13009/EUCASS2019-33.
    Google Scholar Wang et al., 2019 Wang, H., Yang, Z., Zhou, W., 2019. Online scheduling
    of image satellites based on neural networks and deep reinforcement learning 32,
    9 Google Scholar Wang et al., 2021 Wang, H., Qin, C., Zhang, Y., Fu, Y., 2021.
    Emerging Paradigms of Neural Network Pruning. ArXiv210306460 Cs. Google Scholar
    Wang et al., 2021 X. Wang, G. Wu, L. Xing, W. Pedrycz Agile Earth observation
    satellite scheduling over 20 years: formulations, methods and future directions
    IEEE Syst. J., 15 (2021), pp. 3881-3892, 10.1109/JSYST.2020.2997050 Google Scholar
    Wang, 2021 Wang, B., 2021. Mesh-Transformer-JAX: Model-Parallel Implementation
    of Transformer Language Model with JAX. Google Scholar Wertz and Larson, 1999
    Wertz, J.R., Larson, W.J., 1999. Space Mission Analysis and Design, 3rd edition.
    ed. Springer, El Segundo, Calif.: Dordrecht; Boston. Google Scholar White Paper
    on Artificial Intelligence, 2020 White Paper on Artificial Intelligence: a European
    approach to excellence and trust, 2020. Eur. Comm. - Eur. Comm. URL https://ec.europa.eu/info/publications/white-paper-artificial-intelligence-european-approach-excellence-and-trust_en
    (accessed 9.11.21) Google Scholar Winter et al., 2021 Winter, P.M., Eder, S.K.,
    Weissenbock, J., Schwald, C., Doms, T., Vogt, T., Hochreiter, S., Nessler, B.,
    2021. Trusted Artificial Intelligence: Towards Certification of Machine Learning
    Applications. ArXiv abs/2103.16910. Google Scholar Wu et al., 2001 S.-F. Wu, C.J.H.
    Engelen, Q.-P. Chu, R. Babuška, J.A. Mulder, G. Ortega Fuzzy logic based attitude
    control of the spacecraft X-38 along a nominal re-entry trajectory Control Eng.
    Pract., 9 (2001), pp. 699-707, 10.1016/S0967-0661(01)00036-3 View PDFView articleView
    in ScopusGoogle Scholar Yadava et al., 2018 D. Yadava, R. Hosangadi, S. Krishna,
    P. Paliwal, A. Jain Attitude control of a nanosatellite system using reinforcement
    learning and neural networks In: 2018 IEEE Aerospace Conference, IEEE, Big Sky,
    MT (2018), pp. 1-8, 10.1109/AERO.2018.8396409 View in ScopusGoogle Scholar Yang
    et al., 2021 Yang, Z., Li, L., Xu, X., Kailkhura, B., Xie, T., Li, B., 2021. On
    the Certified Robustness for Ensemble Models and Beyond. ArXiv210710873 Cs. Google
    Scholar Yu et al., 2020 D. Yu, Q. Xu, H. Guo, C. Zhao, Y. Lin, D. Li An efficient
    and lightweight convolutional neural network for remote sensing image scene classification
    Sensors, 20 (2020), p. 1999, 10.3390/s20071999 View in ScopusGoogle Scholar Zhang
    et al., 2019 Z. Zhang, A. Iwasaki, G. Xu, J. Song Cloud detection on small satellites
    based on lightweight U-net and image compression J. Appl. Remote Sens., 13 (2019),
    Article 026502, 10.1117/1.JRS.13.026502 View in ScopusGoogle Scholar Zhang et
    al., 2021 Z. Zhang, G. Li, Y. Xu, X. Tang Application of artificial intelligence
    in the MRI classification task of human brain neurological and psychiatric diseases:
    a scoping review Diagnostics, 11 (8) (2021), p. 1402, 10.3390/diagnostics11081402
    View in ScopusGoogle Scholar Zhang et al., 2020 S. Zhang, G. Wu, J. Gu, J. Han
    Pruning convolutional neural networks with an attention mechanism for remote sensing
    image classification Electronics, 9 (2020), p. 1209, 10.3390/electronics9081209
    View in ScopusGoogle Scholar Zhang et al., 2019 B. Zhang, Y. Zhang, S. Wang A
    lightweight and discriminative model for remote sensing scene classification with
    multidilation pooling module IEEE J. Sel. Top. Appl. Earth Obs. Remote Sens.,
    12 (2019), pp. 2636-2653, 10.1109/JSTARS.2019.2919317 View in ScopusGoogle Scholar
    Zhao et al., 2020 Zhao, S., Yue, X., Zhang, S., Li, B., Zhao, H., Wu, B., Krishna,
    R., Gonzalez, J.E., Sangiovanni-Vincentelli, A.L., Seshia, S.A., Keutzer, K.,
    2020. A Review of Single-Source Deep Unsupervised Visual Domain Adaptation. ArXiv200900155
    Cs Eess. Google Scholar Zhu et al., 2017 Zhu, C., Han, S., Mao, H., Dally, W.J.,
    2017. Trained Ternary Quantization. ArXiv161201064 Cs. Google Scholar Zoph and
    Le, 2017 Zoph, B., Le, Q.V., 2017. Neural Architecture Search with Reinforcement
    Learning. ArXiv161101578 Cs. Google Scholar Cited by (10) Navigating AI-lien Terrain:
    Legal liability for artificial intelligence in outer space 2024, Acta Astronautica
    Show abstract Multidisciplinary design and optimization of intelligent Distributed
    Satellite Systems for earth observation 2024, Acta Astronautica Show abstract
    Distributed satellite system autonomous orbital control with recursive filtering
    2024, Aerospace Science and Technology Show abstract Artificial Intelligence for
    Trusted Autonomous Satellite Operations 2024, Progress in Aerospace Sciences Show
    abstract SURE: SUrvey REcipes for building reliable and robust deep networks 2024,
    arXiv Wildfire Detection Using Convolutional Neural Networks and PRISMA Hyperspectral
    Imagery: A Spatial-Spectral Analysis 2023, Remote Sensing View all citing articles
    on Scopus View Abstract © 2023 COSPAR. Published by Elsevier B.V. All rights reserved.
    Recommended articles Characterization of the effective height of the ionosphere
    using GPS data over East Africa, a low latitude region Advances in Space Research,
    Volume 71, Issue 12, 2023, pp. 5196-5207 Phillip Opio, …, Edward Jurua View PDF
    Naturally bounded relative motion for formation flying near triangular libration
    points Advances in Space Research, Volume 71, Issue 12, 2023, pp. 5038-5049 Xingji
    He, …, Lei Liu View PDF Stiffness optimization method of locking unit for space
    manipulator based on plant root adaptive growth theory Advances in Space Research,
    Volume 71, Issue 12, 2023, pp. 5026-5037 Gang Wang, …, Qihui Zhang View PDF Show
    3 more articles Article Metrics Citations Citation Indexes: 6 Captures Readers:
    42 Social Media Shares, Likes & Comments: 39 View details About ScienceDirect
    Remote access Shopping cart Advertise Contact and support Terms and conditions
    Privacy policy Cookies are used by this site. Cookie settings | Your Privacy Choices
    All content on this site: Copyright © 2024 Elsevier B.V., its licensors, and contributors.
    All rights are reserved, including those for text and data mining, AI training,
    and similar technologies. For all open access content, the Creative Commons licensing
    terms apply.'
  inline_citation: Miralles et al., 2023
  journal: Advances in space research
  limitations: None.
  pdf_link: null
  publication_year: 2023
  relevance_evaluation: The paper is highly relevant to the specific point mentioned
    in the prompt, as it provides a comprehensive overview of the current state and
    future potential of machine learning in Earth Observation Operations, covering
    various aspects such as data collection, transmission, processing, and algorithms.
  relevance_score: 1.0
  relevance_score1: 0
  relevance_score2: 0
  title: A critical review on the state-of-the-art and future prospects of machine
    learning for Earth observation operations
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1109/access.2020.2964280
  analysis: '>'
  apa_citation: 'Nauman, A., Qadri, Y. A., Amjad, M., Bin Zikria, Y., Afzal, M. K.,
    & Kim, S. W. (2020). Multimedia Internet of Things: A comprehensive survey. IEEE
    Access, 8, 8202-8250.'
  authors:
  - Ali Nauman
  - Yazdan Ahmad Qadri
  - Muhammad Faisal Amjad
  - Yousaf Bin Zikria
  - Muhammad Khalil Afzal
  - Sung Won Kim
  citation_count: 197
  data_sources: Not mentioned in the provided text
  explanation: "This paper presents a comprehensive survey on Multimedia Internet\
    \ of Things (M-IoT), focusing on the architecture, protocols, and applications\
    \ of integrating multimedia in the IoT domain. \nIt delves into the issues related\
    \ to multimedia's characteristics and provides an overview of multimedia-related\
    \ M-IoT architectures. \nThe paper also examines various multimedia applications\
    \ supported by IoT, showcasing use cases in diverse domains like road traffic\
    \ management, security, industry, and health, highlighting how M-IoT is revolutionizing\
    \ these fields."
  extract_1: null
  extract_2: null
  full_citation: '>'
  full_text: '>

    This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org
    IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal
    Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln
    Sign Out All Books Conferences Courses Journals & Magazines Standards Authors
    Citations ADVANCED SEARCH Journals & Magazines >IEEE Access >Volume: 8 Multimedia
    Internet of Things: A Comprehensive Survey Publisher: IEEE Cite This PDF Ali Nauman;
    Yazdan Ahmad Qadri; Muhammad Amjad; Yousaf Bin Zikria; Muhammad Khalil Afzal;
    Sung Won Kim All Authors 196 Cites in Papers 19635 Full Text Views Open Access
    Comment(s) Under a Creative Commons License Abstract Document Sections I. Introduction
    II. IoT and Multimedia IoT Architecture III. Applications of M-IoT IV. Performance
    Metrics for M-IoT V. M-IoT Computing Paradigm Show Full Outline Authors Figures
    References Citations Keywords Metrics Abstract: The immense increase in multimedia-on-demand
    traffic that refers to audio, video, and images, has drastically shifted the vision
    of the Internet of Things (IoT) from scalar to Multimedia Internet of Things (M-IoT).
    IoT devices are constrained in terms of energy, computing, size, and storage memory.
    Delay-sensitive and bandwidth-hungry multimedia applications over constrained
    IoT networks require revision of IoT architecture for M-IoT. This paper provides
    a comprehensive survey of M-IoT with an emphasis on architecture, protocols, and
    applications. This article starts by providing a horizontal overview of the IoT.
    Then, we discuss the issues considering the characteristics of multimedia and
    provide a summary of related M-IoT architectures. Various multimedia applications
    supported by IoT are surveyed, and numerous use cases related to road traffic
    management, security, industry, and health are illustrated to show how different
    M-IoT applications are revolutionizing human life. We explore the importance of
    Quality-of-Experience (QoE) and Quality-of-Service (QoS) for multimedia transmission
    over IoT. Moreover, we explore the limitations of IoT for multimedia computing
    and present the relationship between the M-IoT and emerging technologies including
    event processing, feature extraction, cloud computing, Fog/Edge computing and
    Software-Defined-Networks (SDNs). We also present the need for better routing
    and Physical-Medium Access Control (PHY-MAC) protocols for M-IoT. Finally, we
    present a detailed discussion on the open research issues and several potential
    research areas related to emerging multimedia communication in IoT. Topic: Mobile
    Multimedia: Methodology and Applications 0 seconds of 0 seconds The overall vision
    of integrating multimedia applications of every domain in IoT, developing smart
    city and transforming human lives i.e., multimedia in agriculture, smar...View
    more Published in: IEEE Access ( Volume: 8) Page(s): 8202 - 8250 Date of Publication:
    06 January 2020 Electronic ISSN: 2169-3536 DOI: 10.1109/ACCESS.2020.2964280 Publisher:
    IEEE Funding Agency: Authors Figures References Citations Keywords Metrics More
    Like This Quality of Service (QoS) in Internet of Things 2018 3rd International
    Conference On Internet of Things: Smart Innovation and Usages (IoT-SIU) Published:
    2018 A Fog Computing Framework for Quality of Service Optimisation in the Internet
    of Things (IoT) Ecosystem 2020 2nd International Multidisciplinary Information
    Technology and Engineering Conference (IMITEC) Published: 2020 Show More IEEE
    Personal Account CHANGE USERNAME/PASSWORD Purchase Details PAYMENT OPTIONS VIEW
    PURCHASED DOCUMENTS Profile Information COMMUNICATIONS PREFERENCES PROFESSION
    AND EDUCATION TECHNICAL INTERESTS Need Help? US & CANADA: +1 800 678 4333 WORLDWIDE:
    +1 732 981 0060 CONTACT & SUPPORT Follow About IEEE Xplore | Contact Us | Help
    | Accessibility | Terms of Use | Nondiscrimination Policy | IEEE Ethics Reporting
    | Sitemap | IEEE Privacy Policy A not-for-profit organization, IEEE is the world''s
    largest technical professional organization dedicated to advancing technology
    for the benefit of humanity. © Copyright 2024 IEEE - All rights reserved.'
  inline_citation: (Nauman et al., 2020)
  journal: IEEE Access
  key_findings: "Multimedia applications are reshaping the Internet of Things (IoT)\
    \ landscape, leading to the emergence of Multimedia Internet of Things (M-IoT).\
    \ \nM-IoT supports diverse multimedia applications across domains such as road\
    \ traffic management, security, industry, and health, transforming human lives.\
    \ \nKey considerations for M-IoT include Quality-of-Experience (QoE), Quality-of-Service\
    \ (QoS), and emerging technologies like Fog/Edge computing and Software-Defined-Networks\
    \ (SDNs)."
  limitations: The paper does not directly address the specific point of focus on
    data compression techniques for real-time irrigation management systems.
  main_objective: To provide a comprehensive survey of the Multimedia Internet of
    Things (M-IoT), covering architecture, protocols, applications, and challenges.
  pdf_link: https://ieeexplore.ieee.org/ielx7/6287639/8948470/08950450.pdf
  publication_year: 2020
  relevance_evaluation: "The paper is moderately relevant to the point of focus on\
    \ investigating data compression, aggregation, and filtering techniques for reducing\
    \ bandwidth requirements and improving transmission efficiency in real-time irrigation\
    \ management systems. \nWhile the paper primarily focuses on multimedia applications\
    \ and M-IoT architecture, it does not explicitly discuss data compression techniques\
    \ in the context of real-time data transmission for irrigation management."
  relevance_score: '0.55'
  relevance_score1: 0
  relevance_score2: 0
  study_location: Unspecified
  technologies_used: Not mentioned in the provided text
  title: 'Multimedia Internet of Things: A Comprehensive Survey'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1109/wcnc.2014.6953083
  analysis: '>'
  apa_citation: Prasad, S., Peddoju, S. K., & Ghosh, D. (2014). Energy efficient mobile
    vision system for plant leaf disease identification. In 2014 IEEE Wireless Communications
    and Networking Conference (WCNC) (pp. 3083-3088). IEEE.
  authors:
  - Shitala Prasad
  - Sateesh K. Peddoju
  - Debashis Ghosh
  citation_count: 27
  data_sources: Disease leaf samples captured using different mobile devices at different
    resolutions
  explanation: The paper proposes a mobile-based system that captures and analyzes
    images of diseased plant leaves to aid in real-time disease diagnosis. The system
    employs a modified k-means clustering algorithm to segment the leaf image and
    identify the disease patch, focusing on minimizing data size and transmission
    time for improved efficiency. This approach aims to reduce the computational and
    communication costs associated with mobile-based plant disease diagnosis, making
    it more feasible for use in rural areas with limited connectivity.
  extract_1: '"The third objective of the proposed scheme is to reduce the power consumption
    in the mobile device. The results obtained in our experiments show that the proposed
    method may be effectively used for reducing the total power consumption at the
    mobile end."'
  extract_2: '"Suppose that the total process of leaf image analysis and disease diagnosis
    requires C instructions. Also, suppose that the size of the leaf image is D bytes.
    Let the power consumed by the mobile system be P c for computing and P t for transmitting
    data." '
  full_citation: '>'
  full_text: '>

    This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org
    IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal
    Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln
    Sign Out All Books Conferences Courses Journals & Magazines Standards Authors
    Citations ADVANCED SEARCH Conferences >2014 IEEE Wireless Communicat... Energy
    efficient mobile vision system for plant leaf disease identification Publisher:
    IEEE Cite This PDF Shitala Prasad; Sateesh K. Peddoju; D. Ghosh All Authors 25
    Cites in Papers 673 Full Text Views Abstract Document Sections I. Introduction
    II. Proposed Methodology III. Experimental Results IV. Conclusion Authors Figures
    References Citations Keywords Metrics Abstract: Close monitoring, proper control
    and management of plant diseases are essential in the efficient cultivation of
    crops. This paper presents a scheme that uses mobile phones for real-time on-field
    imaging of diseased plants followed by disease diagnosis via analysis of visual
    phenotypes. A threshold based offloading scheme is employed for judicious sharing
    of the computational load between the mobile device and a central server at the
    plant pathology laboratory, thereby offering a trade-off between the power consumption
    in the mobile device and the transmission cost. The part of the processing carried
    out in the mobile device includes leaf image segmentation and spotting of disease
    patch using improved k-means clustering. The algorithm is simple and hence suitable
    for Android based mobile devices. The segmented image is subsequently communicated
    to the central server. This ensures reduced transmission cost compared to that
    in transmitting full leaf image. Published in: 2014 IEEE Wireless Communications
    and Networking Conference (WCNC) Date of Conference: 06-09 April 2014 Date Added
    to IEEE Xplore: 20 November 2014 Electronic ISBN:978-1-4799-3083-8 ISSN Information:
    DOI: 10.1109/WCNC.2014.6953083 Publisher: IEEE Conference Location: Istanbul,
    Turkey SECTION I. Introduction At the beginning of this century, there is a tremendous
    technological revolution in the field of wireless communication and mobile technology.
    However, this revolution is still absent in agriculture despite advances in technology
    making it possible to build and deploy wireless sensor and control networks in
    agricultural field that would radically improve farm efficiencies. This is because
    the current wireless technologies are too expensive and complicated for use in
    the farm. Nevertheless, it will be wrong to say that wireless applications have
    not penetrated the agricultural sector at all. 2-way radios have long been used
    by farmers in many developed countries with large farmlands to contact their employees,
    farm suppliers, equipment dealers, agents and buyers from anywhere at anytime.
    Today, with the wide spread availability of mobile phones and cellular networks,
    the use of mobile phones in agricultural sector is becoming popular replacing
    the use of 2-way radios. The advantage of using 2-way radios and mobile phones
    is that they are wireless tools that are relatively cheap and very simple to use.
    Additionally, mobile phones have one more important advantage, that is that all
    brands of mobile phones are generally compatible. The last decade has witnessed
    a spectacular growth in cellular networks and wireless broadband internet. These
    days wireless broadband internet networks are widespread. There has also been
    a tremendous growth in mobile communication technology in recent times. Mobile
    phones have become a crucial part of our daily life nowadays. Mobile phones have
    evolved a lot in terms of their form, performance and features. Mobile phones
    are no more only an alternative to landlines for making phone calls but have also
    become a computer, GPS, radio and our lifeline to the Internet. Most mobile phones
    nowadays have an operating system that can run various types of application software,
    and are equipped with Wi-Fi, Bluetooth and GPS capabilities. For example, PDAs
    (personal digital assistants), such as the ubiquitous Blackberry, combines cellular
    phone service, internet access and computing services. Not only is the advancement
    in technology, there is also a rising popularity of mobile phones globally, including
    countries like India. In India, mobile technology has unleashed a paradigm shift
    in the communication medium to reach out to the masses. Consequently, India has
    outscored other nations in the Asia-Pacific region in terms of number of mobile
    users. With rapidly increasing tele-density, mobile penetration in rural areas
    is also growing strongly. A multitude of innovative mobile phones that come with
    a number of user-friendly features and advanced capabilities are nowadays available
    with people even in rural India, especially among the agrarian community. Motivated
    by the advancement in mobile technology and the wide-spread use of mobile phones
    in India, as discussed above, researchers in India are aiming at helping the agrarian
    community to improve their agricultural activities through use of mobile phones.
    A. Why Agriculture? In many countries, including India, agriculture accounts for
    the majority of rural employment. It also holds the promise for economic growth.
    In fact, agriculture is approximately four times more effective at raising incomes
    among the poor than other sectors. Improved agriculture also has a direct impact
    on hunger and malnutrition, and decreasing the occurrences of famine. However,
    agriculture is facing a range of serious challenges, particularly in developing
    countries. The growing global population has heightened the demand for food. With
    rising food prices, climate change, and lack of infrastructure in rural areas,
    more effective and modern “smart” agriculture is essential. In view of this, wireless
    network technology has been utilized in the agricultural sector. Some of the uses
    of on-farm wireless network are as follows [1]–[3]. Remote monitoring of soil
    moisture, environmental condition, irrigation status, monitoring of greenhouse,
    livestock and storage facilties. Remote control of pumps and robotic vehicles.
    Information transfer for automatic incorporation of environmental data into decision
    support systems and crop models. Communication of text, graphical, voice and video
    messages between operators. Asset tracking such as locating irrigation systems,
    farm vehicles and livestocks. Remote diagnosis in which automatic incorporation
    of environmental data into decision support systems and crop models. In this paper,
    we propose to develop a remote diagnosis system for monitoring, control and management
    of agricultural production through use of advanced technology, especially image
    processing and computer vision, information and communication technology, and
    mobile technology. B. M-Agriculture: Mobile-Based Agriculture Information and
    communication technology, and in particular mobile technologies, are often seen
    as a ‘game changer’ in agriculture. The already existing mobile-based agricultural
    information service is a giant leap in the field of agriculture which offers a
    plethora of services, and serves as a tool for information dissemination that
    leverages on the modern technology. Various mobile-based services like SMS based
    information services, voice based agri-advisory services, and videos over mobile
    networks, etc. are utilized for transfer of general know-how on farming techniques
    and trends, information on plants and varieties, and how to grow them, etc. Mobile-based
    agriculture (m-Agriculture) refers to the delivery of agriculture-related services
    via mobile communications technology. In order to inform decisions on agricultural
    measures to optimize plant growth, it provides for individual decision-support
    systems and services which are based on localized contextual information, i.e.
    delivering location-specific information based on climatic patterns, soil and
    water conditions,. It also involves gathering relevant data through mobile technologies
    like automated weather stations or systems equipped with sensors for location-based
    collection. Thus, m-Agriculture involves two-way advisory systems that provide
    individual feedback and advice such as remote diagnosis of diseases by experts.
    These systems typically include the use of smartphones and intermediaries for
    the communication with farmers and require remote sensing instruments and GIS.
    To turn an m-Agriculture initiative into a viable and self-sustaining product,
    certain critical criteria must be addressed. m-Agriculture projects are built
    on the opportunities provided by increasing use of mobile phones by farmers in
    developing countries. Accordingly, the primary objective of this paper is to develop
    a mobile-based vision system for plant disease diagnosis via plant leaf imaging
    and analysis. C. Mobile-Based Vision System for Plant Disease Diagnosis Plant
    diseases are caused by pathogens. Correct diagnosis and identification of these
    pathogens is the most important step in the eventual control of a plant disease.
    Microscopy, culturing, a few simple biochemical tests, and ELISA are the mainstays
    for most routine laboratory diagnoses [4]. Other than these, we also rely on visual
    examination for on-the-field diagnosis. In most of the cases, pests or diseases
    are seen on the leaves, stems or fruits of the plant. Therefore, finding out symptoms
    of the pest or disease attack on leaves, stems or fruits of plants, subsequent
    identification of the pest or diseases, and estimating the percentage of the attack
    play a key role in successful cultivation of crops. However, performance of such
    diagnosis is limited by details that can be visualized by the naked eyes and the
    expertise of the farmer/expert. There is also demand from farmers and agricultural
    administrators for rapid, timely and accurate diagnosis of pathogens to guide
    disease management decision making. Due to shortage of trained field and clinical
    pathologists and other necessary resources, it has become necessary to find innovative
    ways to maximize the delivery of diagnostic services to agriculture. A solution
    to this may be to capture the image of the diseased parts of the plant and then
    study the same for classifying lesion, scoring quantitative traits, calculating
    infected area, etc. Artificial vision system is one of the emerging technologies
    that mimic a human vision system in reality. Image and vision have covered almost
    all fields in our daily life presenting us with ubiquitous devices and ubiquitous
    computing in an anytime-anywhere scenario. These days cameras are standard on
    mobile phones, sometimes with picture quality as good as many stand-alone digital
    cameras. Therefore, it is possible to directly capture the image of the diseased
    part of a plant and process the image to know about the disease and the extent
    of infection. These images are shared with experts for diagnosis and expert opinion
    through specific communication networks and wireless communication channels including
    Wi-Fi and cellular network. Thus, a mobile-based plant disease diagnosis system
    is made available to farmers. Application of computer vision techniques in plant
    research is already in place. One very important aspect in plant research and
    botany is the identification of plant species and genus. Plant species recognition
    depends on many features such as the plant shape, size, and most importantly its
    leaves. The leaf of a plant is characterized in terms of its shape, size, color,
    vein pattern, edge pattern and texture. While the size, color and vein pattern
    may vary from place to place depending on the climatic condition, leaf shape,
    edge and texture features are independent and omnipresent. The leaf shape as an
    important feature defining the plant species has already been proved and used
    by many researchers in automatic identification of plant species, including some
    mobile-based systems [5]–[8]. On the other hand, research in plant disease diagnosis
    using computer vision is very thin. Scientific community have performed some researches
    on specific diseases [9]–[12], but is yet to come up with a general algorithm
    suitable for every disease or at least a majority of diseases. This paper presents
    a scheme for using mobile phones for real-time data capture via imaging of diseased
    plant leaves, on-field image segmentation and spotting of disease patch, and transmission
    of data to plant pathology laboratory for disease diagnosis via analysis of visual
    phenotypes. Through the mobile service linkage available the system will communicate
    plant disease related information between the farmers on the field and the agricultural
    administrator and/or the laboratory. The system will utilize the images of diseased
    patches on the leaf of the plants along with other environmental information such
    as the location, climatic condition, etc. to compute and identify the disease,
    extent of its spread and the possibility of its outbreak. Mobile phones nowadays
    are generally equipped with camera making it possible to capture the images in
    the field and directly transmit the same, as necessary. Further, these mobile
    phones come with good enough computing power to accomplish complete leaf image
    analysis and disease diagnosis in the mobile device itself. However, the primary
    constraint with mobile computing is the limited energy. The leaf image analysis
    and disease diagnosis task is generally computation intensive demanding energy
    too large to perform on a mobile system. This calls for offloading some part of
    the processing task to a central server located at the plant pathology laboratory.
    This, therefore, requires transmission of the leaf image from the mobile device
    to the server. The amount of data that may be transmitted is, on the other hand,
    constrained by the wireless bandwidth. Hence, a trade-off between the offloading
    and the transmission cost is necessary. In our proposed scheme, we propose to
    perform simple plant leaf segmentation only in the mobile device. The segmented
    leaf image is then transmitted, instead of the whole leaf image, thereby saving
    in transmission cost. Fig. 1 depicts the proposed system architecture. A detailed
    description of our proposed scheme is given in the section to follow. Fig. 1.
    Proposed system architecture. Show All SECTION II. Proposed Methodology A. Leaf
    Image Segmentation In image, video and vision applications image segmentation
    is a fundamental step to separate homogeneous regions. For image analysis and
    image understanding, proper segmentation is a necessary condition. Features such
    as color histogram, texture or edge based methods are used for finding homogeneous
    regions in an image [12]. Image segmentation methods are classified as supervised
    or unsupervised. The supervised segmentation approach predefines the characteristics
    of different regions in an image whereas in unsupervised segmentation there is
    no such prior information. Unsupervised algorithms includes splitting-merging
    method [14], local and multi-resolution features [15], Markov random field model
    [16] and many others which are computationally complex and memory consuming. The
    advantage of such algorithms is that no comparison is required against the manually
    segmented ground-truth. Unsupervised image segmentation is very useful in real
    time systems where large variety of natural images need to be segmented. Plant
    leaf image is a natural image full of challenges and hence needs a dynamic adjustment
    of segmentation parameters for better results. For this, cluster-based unsupervised
    image segmentation methods [17]–[19] prove to be useful. In [17], Puzicha et al.
    proposed an efficient novel mixture model to cluster histogram data with multi-scale
    formulation. In [18], Bong and Lam proposed multi-objective scatter for image
    segmentation using concepts of Pareto dominance on gray images (CT scan and SAR).
    The four necessary criteria for unsupervised image segmentation given by Haralick
    and Shapiro [20], [21] are Uniform and homogeneous regions with respect to some
    common characteristic(s). Significant difference between adjacent regions with
    respect to the characteristic(s). Absence of any hole in a region. Simple and
    spatially accurate region boundaries. In our work, we propose to use k -means
    clustering approach [22] for color leaf image segmentation. An image is composed
    of foreground and background. In our work, we assume that the leaf image is available
    with simple and uniform background. The leaf again is composed of two different
    regions - the normal green part and the disease patch. Accordingly, we apply k
    -means clustering for segmentation with k=3 corresponding to the three regions
    in the leaf image - background, normal green leafy part and the disease patch
    region. The RGB leaf image captured by the mobile device is first converted into
    CIE (Comission Internationale de l''Eclairage) L*a*b color model so as to make
    the input image device independent. The CIE L*a*b color space is specified by
    the International Commission on Illumination for use as a reference color model
    since it is close to the color model visible to human eye. A 5×5 averaging filter
    mask is applied over the L*a*b image to remove unwanted noise [23]. Following
    this, the clustering algorithm is applied to identify and segment out the three
    different regions from the input image. Fig. 2 shows all the three clusters in
    a leaf image where the first cluster is the background with constant intensity
    value, the second cluster is the green non-diseased portion in the leaf and the
    third cluster is the region of interest (ROI), i.e. the disease patch in the leaf.
    Fig. 2. Results of leaf image segmentation. Show All B. Selection of Diseased
    Patch The image of the diseased leaf captured by the mobile device in the field
    needs to be transmitted to some central server present in the pathology laboratory.
    In [5], White et al. captured and transmitted the complete image to a tablet PC
    located nearby. However, this requires a proper connection and a high speed Internet
    connectivity. Indian telecommunication technology is still in the developing stage
    and except in urban places such high speed connectivity is not available. Whereas,
    the application under consideration is mainly based in rural areas. Thus, transferring
    a complete image to a server needs a high bandwidth. This is taken care of to
    some extent by the image cropping step. Among all the diseased patch obtained
    in a leaf image, the largest size patch is identified, cropped and transmitted.
    By this, only the relevant part of the leaf image is transmitted while discarding
    unnecessary portions of the image. Fig. 3 shows a disease patch cropped out of
    a leaf image. Since the computational requirement of these two steps, viz. segmentation
    and cropping, is generally not high, the energy consumed in the mobile device
    is small enough to support the application. C. Transmission of the Cropped Image
    Finally, the cropped image is easily transferred to a high processing server or
    computing device located at the pathology laboratory through a wireless communication
    channel. The transmission method can be any of the available networks, e.g. 2G,
    3G, 4G, Wi-Fi and so on. In order to achieve high transmission efficiency, only
    the blob corresponding to the largest disease patch is transmitted in color format.
    This ensures that no information regarding the disease symptoms is lost. Other
    than the ROI, all other regions in the cropped leaf image, viz. background and
    the non-diseased leaf portion, as identified via the clustering process, are of
    no use for the purpose of disease diagnosis. Accordingly, we propose to encode
    every pixel in these regions with a single zero bit thereby reducing the transmission
    cost both in terms of bandwidth and power. Fig. 3. The largest disease patch in
    the leaf image of Fig. 2 cropped out. Show All D. Energy Consideration Since mobile
    devices are battery operated, the energy in both computation and transmission
    should be conserved. There are three possibilities through which this architecture
    can reduce the computation and communication cost. They are compute every operation
    on the server, compute feature extraction on the mobile device and analyze it
    on server using machine learning algorithm, and perform low-level image processing
    operations such as pre-processing on the mobile device and the rest of the algorithm
    on the server. In all of these approaches, transmission media is very much required
    and a constant connection is important. In respect of power consumption, the first
    approach will consume less energy but bandwidth requirement will be high. This
    option requires to transmit the whole image captured by the mobile phone. Hence,
    a high-speed broad-band connection is required. In India, transmission media is
    generally very low and thus second approach will be more preferable. Nonetheless,
    this approach consumes huge battery power. Therefore, the third approach provides
    a better trade-off between the two. Suppose that the total process of leaf image
    analysis and disease diagnosis requires C instructions. Also, suppose that the
    size of the leaf image is D bytes. Let the power consumed by the mobile system
    be P c for computing and P t for transmitting data. If the mobile system performs
    the total procedure, the energy consumption is E c = P c × C M (1) View Source
    where M is the processing speed of the mobile device in terms of instructions
    per second. If the total procedure is computed in the central server, then the
    energy consumed in transmitting the whole leaf image is E t = P t × D×8 B (2)
    View Source where B is the network bandwidth in bits/sec. Therefore, computing
    every operation on the server (first option above) is beneficial only when E c
    > E t . This requires D B sufficiently small compared to C M . Accordingly, offloading
    is preferred when the available bandwidth B is very large. As proposed in our
    method, we perform only the segmentation and cropping in the mobile device. Let,
    the number of instructions involved in doing this is αC , where α<1 . That is,
    α is the fraction of total computation involved in the segmentation process. Also,
    let the total data size of the segmented image that is transmitted is βD bytes,
    where β<1 is the fraction of the total data after cropping. Then the total energy
    consumed by the mobile system in our proposed scheme is E total = P c ×α C M +
    P t ×β D×8 B (3) View Source Partial offloading, as proposed in our scheme, will
    be beneficial when E total is less than both E c and E t . Given the parameters
    M, P c and P t of the mobile device and the network bandwidth B , the system requires
    to calculate E c , E t and E total and then decide for complete offloading with
    all computations in the central server ( E t minimum), no offloading with all
    computations in the mobile device ( E c minimum), or partial offloading, as per
    our proposed scheme ( E total minimum). It may be noted from (2) that the channel
    bandwidth directly affects the energy consumption of a device. The higher the
    bandwidth, the lower the energy consumption while transferring the image. If the
    bandwidth is low the energy consumption to transmit the same image is more. Therefore,
    there is a need to reduce the image size by some means. Accordingly, segmentation
    plus image cropping is performed, as described above. SECTION III. Experimental
    Results The complete system is designed using OpenCV and Android operating system.
    The minimum hardware requirement for mobile devices is 1 GHz processor and 256
    MB RAM. Here, though multi-core processors are available, the experiments are
    carried out on single core processor to actually measure the computational cost
    and time factor associated with it. A total of 297 diseased leaf samples are captured
    using different mobile devices at different resolutions. The segmentation results
    of few leaf samples are shown in Fig. 4. The computation time with different resolutions
    using the proposed algorithm are plotted in Fig. 5. It is observed that lower
    the resolution, the faster is the computation, as expected. Table I shows the
    relative comparison in the data size and transmission time between transmission
    of the complete leaf image and the segmented leaf image. Clearly, it is seen that
    the segmented leaf image requires less transmission cost to transfer over a wireless
    medium. The transmission link used in our experiments is a high speed wireless
    connection of 54 Mbps. Fig. 4. Segmentation results of four different leaf images.
    The last (bottom) leaf image is a complex incomplete leaf image. Show All Table
    I Comparison of data size (in kilo bytes) transmission time (in sec.) for leaf
    images of different resolutions Fig. 5. Comparison of computational cost for leaf
    images with different resolutions. Show All SECTION IV. Conclusion This paper
    proposes a new CIE L*a*b* color based unsupervised segmentation for natural image.
    Texture feature is used to cluster the leaf image regions employing k -means clustering
    to segment diseased portion from leaf images. The L*a*b* color space makes the
    approach more flexible, robust and device independent. Unsupervised image segmentation
    adds scalability in segmenting images captured by cameras with varying resolutions
    in different mobile phones. The second task of this work is to reduce the communication
    cost such that the application be performed in real time by transmitting only
    the ROI in the leaf image. The third objective of the proposed scheme is to reduce
    the power consumption in the mobile device. The results obtained in our experiments
    show that the proposed method may be effectively used for reducing the total power
    consumption at the mobile end. Authors Figures References Citations Keywords Metrics
    More Like This Wheat leaf disease detection using CNN in Smart Agriculture 2023
    International Wireless Communications and Mobile Computing (IWCMC) Published:
    2023 Detection of potato diseases using image segmentation and multiclass support
    vector machine 2017 IEEE 30th Canadian Conference on Electrical and Computer Engineering
    (CCECE) Published: 2017 Show More IEEE Personal Account CHANGE USERNAME/PASSWORD
    Purchase Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile Information
    COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help?
    US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow
    About IEEE Xplore | Contact Us | Help | Accessibility | Terms of Use | Nondiscrimination
    Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy Policy A not-for-profit
    organization, IEEE is the world''s largest technical professional organization
    dedicated to advancing technology for the benefit of humanity. © Copyright 2024
    IEEE - All rights reserved.'
  inline_citation: (Prasad, Peddoju, & Ghosh, 2014)
  journal: ''
  key_findings: The proposed system effectively segments diseased portions from leaf
    images using CIE L*a*b* color-based k-means clustering, significantly reducing
    data size and transmission time. The approach is scalable and device-independent,
    making it suitable for use with varying mobile phone camera resolutions.
  limitations: null
  main_objective: To develop a mobile-based vision system for plant disease diagnosis
    via plant leaf imaging and analysis, focusing on reducing data size and transmission
    time to improve efficiency.
  pdf_link: null
  publication_year: 2014
  relevance_evaluation: This paper is moderately relevant to the section and subsection
    focus on investigating data compression, aggregation, and filtering techniques
    to reduce bandwidth requirements and improve transmission efficiency. While the
    paper does not explicitly discuss these specific techniques, it aligns with the
    overall theme of optimizing data transmission for automated irrigation systems.
    The paper's focus on minimizing data size and transmission time in the context
    of mobile-based plant disease diagnosis demonstrates a similar objective of enhancing
    transmission efficiency in real-time data transmission.
  relevance_score: '0.65'
  relevance_score1: 0
  relevance_score2: 0
  study_location: Unspecified
  technologies_used: k-means clustering, Android operating system, OpenCV
  title: Energy efficient mobile vision system for plant leaf disease identification
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.3390/agriculture8060073
  analysis: '>'
  authors:
  - C. Leroux
  - Hazaël Jones
  - L. Pichon
  - Serge Guillaume
  - Julien Lamour
  - James A. Taylor
  - Olivier Naud
  - Thomas Crestey
  - Jean-Luc Lablée
  - Bruno Tisseyre
  citation_count: 32
  explanation: The study aims to evaluate the ability of GeoFIS to answer the most
    common issues and challenges faced by the agricultural sector when processing
    their spatial data. The authors achieve this by evaluating GeoFIS's ability to
    map the spatial variability in a data set, evaluate the opportunity for site-specific
    management and delineate within-field zones for variable rate applications.
  extract_1: '"GeoFIS has been designed to facilitate the movement from spatial data
    to spatial information, and to spatial decision-making. It is an open-source program
    that proposes a simple and easy to use interface to build decision support systems
    (DSS) from spatial data [30]. While its development has been inspired by agri-environmental
    applications, the framework itself is open and accessible to applications in other
    domains. It is designed to be adaptable to different usages and for different
    end-users, mostly for academic and research applications, for student and teaching
    applications and, to a lesser extent, for GIS-skilled agronomists and advisors."'
  extract_2: '"‘Precision Agriculture’ or ‘Smart Agriculture’ is only effective when
    effective decisions are made. End-users can transform these information layers
    into decision layers to improve the management of their fields. Three main functionalities
    for management (practical) applications have been incorporated within GeoFIS to
    address this. Firstly, practitioners are provided with a method to delineate within-field
    homogeneous zones (Step 3.1). Zoning is of importance for precision agriculture
    data as the identified zones will (i) facilitate spatial data visualization and
    interpretation, and (ii) provide a spatial resolution that is practical and effective
    for many differential field operations. GeoFIS uses a segmentation algorithm to
    ‘zone’ data layers [18]. The segmentation algorithm operates either on irregular
    or gridded (interpolated) data to generate potential management zones."'
  full_citation: '>'
  full_text: ">\nagriculture\nArticle\nGeoFIS: An Open Source, Decision-Support Tool\
    \ for\nPrecision Agriculture Data\nCorentin Leroux 1,2,*, Hazaël Jones 1, Léo\
    \ Pichon 1, Serge Guillaume 1, Julien Lamour 1,3,\nJames Taylor 1, Olivier Naud\
    \ 1, Thomas Crestey 1, Jean-Luc Lablee 1 and Bruno Tisseyre 1\n1\nITAP (Information–Technologies-Environmental\
    \ Analysis-Agricultural Processes, French Denomination),\nMontpellier SupAgro,\
    \ Irstea, University of Montpellier, 34000 Montpellier, France;\nhazael.jones@supagro.fr\
    \ (H.J.); leo.pichon@supagro.fr (L.P.); serge.guillaume@irstea.fr (S.G.);\nj.lamour@fruitiere.fr\
    \ (J.L.); James.Taylor6@newcastle.ac.uk (J.T.); olivier.naud@irstea.fr (O.N.);\n\
    thomas.crestey@supagro.fr (T.C.); jean-luc.lablee@irstea.fr (J.-L.L.); bruno.tisseyre@gmail.com\
    \ (B.T.)\n2\nSMAG, 34960 Montpellier, France\n3\nCompagnie Fruitière, 13000 Marseille,\
    \ France\n*\nCorrespondence: cleroux@smag-group.com; Tel.: +33-(0)3-2621-8420\n\
    Received: 25 April 2018; Accepted: 28 May 2018; Published: 30 May 2018\n\x01\x02\
    \x03\x01\x04\x05\x06\a\b\x01\n\x01\x02\x03\x04\x05\x06\a\nAbstract: The world\
    \ we live in is an increasingly spatial and temporal data-rich environment,\n\
    and agriculture is no exception. However, data needs to be processed in order\
    \ to ﬁrst get information\nand then make informed management decisions. The concepts\
    \ of ‘Precision Agriculture’ and\n‘Smart Agriculture’ are and will be fully effective\
    \ when methods and tools are available to practitioners\nto support this transformation.\
    \ An open-source software called GeoFIS has been designed with\nthis objective.\
    \ It was designed to cover the whole process from spatial data to spatial information\n\
    and decision support. The purpose of this paper is to evaluate the abilities of\
    \ GeoFIS along with\nits embedded algorithms to address the main features required\
    \ by farmers, advisors, or spatial\nanalysts when dealing with precision agriculture\
    \ data. Three case studies are investigated in the\npaper: (i) mapping of the\
    \ spatial variability in the data; (ii) evaluation and cross-comparison of the\n\
    opportunity for site-speciﬁc management in multiple ﬁelds; and (iii) delineation\
    \ of within-ﬁeld zones\nfor variable-rate applications when these latter are considered\
    \ opportune. These case studies were\napplied to three contrasting crop types,\
    \ banana, wheat and vineyards. These were chosen to highlight\nthe diversity of\
    \ applications and data characteristics that might be handled with GeoFIS. For\
    \ each\ncase-study, up-to-date algorithms arising from research studies and implemented\
    \ in GeoFIS were\nused to process these precision agriculture data. Areas for\
    \ future development and possible relations\nwith existing geographic information\
    \ systems (GIS) software is also discussed.\nKeywords: decision-making; GeoFIS;\
    \ geostatistics; open source software; precision agriculture;\nspatial analysis\n\
    1. Introduction\nWithin-ﬁeld variability is now a widely accepted and reported\
    \ phenomenon by the precision\nagriculture community [1,2]. Geolocalized data\
    \ are effectively collected intensively within the ﬁelds\nby sensors embedded\
    \ on agricultural machinery, satellites, ﬂying platforms, static stations, or\
    \ humans\namong others, to make sure that this variability is considered and accounted\
    \ for [3–5]. Spatial data have\nparticular characteristics that are worth careful\
    \ consideration during analysis. First of all, their spatial\nresolution (density)\
    \ is of interest as it deﬁnes the capacity to identify short- and long-scale spatial\n\
    variability [6,7]. Spatial records are often associated with a high-level of noise\
    \ that originates from\nmultiple reasons, such as the plant to plant variability,\
    \ the accuracy of the sensor or the conditions\nAgriculture 2018, 8, 73; doi:10.3390/agriculture8060073\n\
    www.mdpi.com/journal/agriculture\nAgriculture 2018, 8, 73\n2 of 21\nof data acquisition\
    \ [8]. Except for images in which data are regularly distributed on a grid of\
    \ pixels,\nmany spatial observations collected in agriculture are irregular and\
    \ do not follow a ﬁxed pattern\nwithin the ﬁelds [9]. This feature is of great\
    \ concern because many image-processing based algorithms\ncannot be directly used\
    \ on these irregular data.\nTo beneﬁt from this increasing ﬂow of data, users\
    \ should be provided with software or tools that\nallow them to:\n(i)\nvisualize\
    \ the data they have collected (simple or low-level functions),\n(ii)\nprocess\
    \ these data (advanced or high-level functions), and\n(iii) incorporate the knowledge\
    \ they have on these data into the data processing.\nIt is acknowledged that basic\
    \ visualization tools, e.g., data import, georeferencing, data display,\nare available\
    \ in many general (e.g., Quantum geographic information systems (QGIS), gvSIG,\n\
    Google Earth, Whitebow Geospatial Analysis Tools) and more speciﬁc [10,11] open-source\
    \ platforms,\nincluding those not speciﬁc to agricultural applications. It is\
    \ clear that such functionalities are of major\nimportance to start handling spatial\
    \ data. However, when it comes to making informed management\ndecisions, these\
    \ visualization functions are not sufﬁcient. It is necessary to provide users\
    \ with more\nadvanced or high-level functions so that they can turn this raw spatial\
    \ data into information and\ndecision layers. Most commonly required procedures\
    \ in the precision agriculture domain are functions\nsuch as:\n(i)\nﬁltering,\
    \ to ensure the quality of the datasets [12,13],\n(ii)\ninterpolation, to provide\
    \ a continuous mapping of the property of interest [14–16],\n(iii) zoning, to\
    \ deﬁne within-ﬁeld zones for site-speciﬁc management [17,18], or\n(iv) aggregation\
    \ so that multiple layers of information can be combined [19,20].\nTo foster the\
    \ adoption of such tools, all the aforementioned functions have to be speciﬁcally\n\
    dedicated to the processing of agricultural data from potentially very differing\
    \ productions systems.\nThis is an important consideration as these data come\
    \ with a lot of associated knowledge that has\nto be considered when processing\
    \ these data. More speciﬁcally, a lot of local expertise to support\ndecision-making\
    \ might be available as users, e.g., farmers, advisors and/or technicians, have\
    \ normally\nbeen scouting the ﬁelds during all the growing season [21–23]. Site-speciﬁc\
    \ management also requires\nthe use of agricultural machinery with speciﬁc characteristics\
    \ that have to be considered in these\nprocessing functions. This is to ensure\
    \ that planned differential management is in accordance with\nthe practical and\
    \ operational limitations of machinery e.g., working width, lag time and application\n\
    speed [24,25].\nFrom a general perspective, there are only a few dedicated software\
    \ programs available to\nexplicitly process precision agriculture data and incorporate\
    \ expert knowledge into the process.\nMoreover, very few of them are open-source.\
    \ Some free- or share-ware tools have been developed and\nproposed by the precision\
    \ agriculture community, but these generally focus on speciﬁc processing tasks\n\
    or on a particular type of data. For example, the Vesper program [26], developed\
    \ by the University\nof Sydney, provides users with a graphical interface to spatially\
    \ interpolate their data. Despite the\nquite advanced functions that are available,\
    \ e.g., local punctual and block kriging, users only end\nup with a continuous\
    \ map of their data without much more practical information. The Yield Editor\n\
    software from the United States Department of Agriculture [13,27] deals effectively\
    \ with the ﬁltering\nof within-ﬁeld yield datasets that are known to contain a\
    \ lot of defective observations [28], but it does\nnot perform interpolation or\
    \ other high-level functions. Another interesting example is a QGIS plugin\nthat\
    \ was put into place to process spatial data of vine shoot diameter arising from\
    \ the mounted sensor\nPhysiocap® (E.RE.C.A, Vaulx-en-Velin, France). This tool\
    \ mainly incorporates functions to ﬁlter these\nhighly noisy datasets. Other platforms\
    \ have been proposed by agronomist to give farmers access to\ncrop models but\
    \ are very speciﬁc in terms of crop, data and use [29]. An open source platform\
    \ that\ntakes raw data through to a decision point is not available to the precision\
    \ agriculture community yet.\nAgriculture 2018, 8, 73\n3 of 21\nThe aim of the\
    \ paper is to present the GeoFIS software (https://www.geoﬁs.org/) that was\n\
    developed by a joined team from IRSTEA, INRA and Montpellier SupAgro in France\
    \ [30]. The goal\nof this platform is to provide users with up-to-date and reliable\
    \ algorithms to process their precision\nagriculture data and incorporate expert\
    \ knowledge from the ﬁelds. GeoFIS has been mainly developed\nfor academic and\
    \ research purposes, i.e., investigators and students willing to process their\
    \ data,\nbut also to a lesser extent for agronomists and advisors with a sufﬁcient\
    \ background in spatial\nanalysis. The objective of this interface-based platform\
    \ is to support users that do not necessarily\nhave programming skills and to\
    \ show that high level functions can be introduced in a GIS and could\nbe integrated\
    \ within precision agriculture programs. The ﬁrst section introduces this open-source\n\
    tool along with its architecture, design, interface, and main processing functions.\
    \ Three different\ncase studies on various crops are then considered to evaluate\
    \ the ability of this software to answer\nmost of the issues that are faced by\
    \ the agricultural sector for processing their spatial data. The last\nsection\
    \ highlights the needs for future developments to promote precision agriculture\
    \ adoption and\nthe possibility to create connections with existing GIS software\
    \ programs.\n2. The GeoFIS Software\n2.1. Aim of the GeoFIS Project\nGeoFIS has\
    \ been designed to facilitate the movement from spatial data to spatial information,\n\
    and to spatial decision-making. It is an open-source program that proposes a simple\
    \ and easy to\nuse interface to build decision support systems (DSS) from spatial\
    \ data [30]. While its development\nhas been inspired by agri-environmental applications,\
    \ the framework itself is open and accessible\nto applications in other domains.\
    \ It is designed to be adaptable to different usages and for different\nend-users,\
    \ mostly for academic and research applications, for student and teaching applications\
    \ and,\nto a lesser extent, for GIS-skilled agronomists and advisors.\nGeoFIS\
    \ deviates from other GIS software, e.g., QGIS, in the sense that speciﬁc tools\
    \ have been\nimplemented to answer the main expectations of agricultural professionals\
    \ when it comes to processing\nprecision agriculture data. These will be presented\
    \ later on. It is acknowledged that multiple other\nopen-sources spatial programs\
    \ (e.g., QGIS) or languages (e.g., R and Python) are available to process\nspatial\
    \ and temporal data. However, these open-source tools do not have speciﬁc functions\
    \ dedicated\nto the processing of precision agriculture data (as listed in the\
    \ introduction section) and usually\nrequire users to have skills in programming.\
    \ This is a major limiting factor for the practical use\nof spatial modelling\
    \ in agriculture. Another strength of GeoFIS is that attention has been paid to\n\
    the incorporation of expert knowledge into the data analysis. This is not available\
    \ in other related\nspatial processing tools. Agricultural professionals have\
    \ a lot of local expert knowledge on their\nproduction system that needs to be\
    \ taken into account. By incorporating this qualitative expert\nknowledge, the\
    \ quality of the processing should be improved and the adoption of precision agriculture\n\
    technologies should be enhanced.\n2.2. Architecture and Design of GeoFIS\nIn the\
    \ proposed GeoFIS architecture, all the open-source toolboxes and libraries have\
    \ been selected\nfor their ability to handle spatial data and to incorporate expert\
    \ knowledge (Figure 1). Statistical and\ngeostatistical functions dedicated to\
    \ precision agriculture data (see Section 2.3) are implemented in R\n(https://www.r-project.org).\
    \ Outside these speciﬁc functions, spatial data are handled through two\nopen-source\
    \ libraries, i.e., Geotools (http://www.geotools.org) and CGAL (Computational\
    \ Geometry\nAlgorithms Library, https://www.cgal.org). Geotools is used because\
    \ its java implementation allows\nthe design of user-friendly interfaces. CGAL\
    \ was chosen for its ability to provide very efﬁcient and\nreliable geometric\
    \ algorithms, as its functions are developed in C++. Finally, the incorporation\
    \ of\nexpert knowledge is made possible with FisPro (https://www.ﬁspro.org), a\
    \ system that uses fuzzy\nsets for conceptual modeling [30].\nAgriculture 2018,\
    \ 8, 73\n4 of 21\nGeoFIS is available in four languages (French, English, Spanish\
    \ and Portuguese). The interface\nis designed with a man-machine cooperation objective.\
    \ The goal is to facilitate the relationships\nbetween data, learning algorithms\
    \ and expert knowledge. Documentation, scientiﬁc papers, and video\ntutorials\
    \ are available to better understand the implemented function and to facilitate\
    \ the adoption of\nthe GeoFIS software (https://www.geoﬁs.org/). Notiﬁcations\
    \ are made when a new version of the\nsoftware is available.\nAgriculture 2018,\
    \ 8, x FOR PEER REVIEW  \n4 of 21 \n \nvideo tutorials are available to better\
    \ understand the implemented function and to facilitate the \nadoption of the\
    \ GeoFIS software (https://www.geofis.org/). Notifications are made when a new\
    \ \nversion of the software is available. \n \nFigure 1. The GeoFIS architecture\
    \ [30]. CGAL, Computational Geometry Algorithms Library; DSS, \nDecision Support\
    \ Systems; GIS, Geographic Information System; 1D, One dimension. \n2.3. Functionalities\
    \ Implemented in GeoFIS \nGeoFIS contains a series of low and high-level non-spatial\
    \ and spatial functionalities to \ninterrogate spatial data. The general functionalities\
    \ are introduced here and then expanded in several \ncase studies in the following\
    \ section. Figure 2 shows the generic flow required in precision \nagriculture,\
    \ from raw data processing to decision-making, with the functionalities within\
    \ GeoFIS at \neach stage indicated. In agricultural systems, data are available\
    \ in different formats (points, polygons, \nrasters) and at different scales.\
    \ The quality of the data is also variable, with some sensors being \ninherently\
    \ noisy and others less so. Different data need potentially different approaches\
    \ to (i) data \nvalidation and clean-up (quality control), (ii) data display (visualization)\
    \ and when necessary for (iii) \ninterpolation. These steps transform data into\
    \ information layers. Within GeoFIS, data can be easily \nimported (Step 0) and\
    \ displayed as a map (in its geographical space) and as a histogram (in its \n\
    attribute space). This allows the user to ‘expertly’ identify global outliers\
    \ in both the geographical \nand attribute space and remove any erroneous data\
    \ (Step 1). Interpolation is possible using inverse \ndistance weighting (for\
    \ small data sets) and via punctual kriging with a global variogram for larger\
    \ \ndata sets (>100 points). The kriging method includes the ability to plot the\
    \ experimental variogram \nand specify a theoretical variogram, which is then\
    \ passed to the kriging function. Interpolated \noutputs can be directly displayed\
    \ as rasters within the display (Step 2). \n‘Precision Agriculture’ or ‘Smart\
    \ Agriculture’ is only effective when effective decisions are \nmade. End-users\
    \ can transform these information layers into decision layers to improve the \n\
    management of their fields. Three main functionalities for management (practical)\
    \ applications have \nbeen incorporated within GeoFIS to address this. Firstly,\
    \ practitioners are provided with a method to \ndelineate within-field homogeneous\
    \ zones (Step 3.1). Zoning is of importance for precision \nagriculture data as\
    \ the identified zones will (i) facilitate spatial data visualization and interpretation,\
    \ \nand (ii) provide a spatial resolution that is practical and effective for\
    \ many differential field \noperations. GeoFIS uses a segmentation algorithm to\
    \ ‘zone’ data layers [18]. The segmentation \nFigure 1.\nThe GeoFIS architecture\
    \ [30].\nCGAL, Computational Geometry Algorithms Library;\nDSS, Decision Support\
    \ Systems; GIS, Geographic Information System; 1D, One dimension.\n2.3. Functionalities\
    \ Implemented in GeoFIS\nGeoFIS contains a series of low and high-level non-spatial\
    \ and spatial functionalities to interrogate\nspatial data. The general functionalities\
    \ are introduced here and then expanded in several case studies\nin the following\
    \ section. Figure 2 shows the generic ﬂow required in precision agriculture, from\
    \ raw\ndata processing to decision-making, with the functionalities within GeoFIS\
    \ at each stage indicated.\nIn agricultural systems, data are available in different\
    \ formats (points, polygons, rasters) and at\ndifferent scales. The quality of\
    \ the data is also variable, with some sensors being inherently noisy and\nothers\
    \ less so. Different data need potentially different approaches to (i) data validation\
    \ and clean-up\n(quality control); (ii) data display (visualization) and when\
    \ necessary for (iii) interpolation. These steps\ntransform data into information\
    \ layers. Within GeoFIS, data can be easily imported (Step 0) and\ndisplayed as\
    \ a map (in its geographical space) and as a histogram (in its attribute space).\
    \ This allows\nthe user to ‘expertly’ identify global outliers in both the geographical\
    \ and attribute space and remove\nany erroneous data (Step 1). Interpolation is\
    \ possible using inverse distance weighting (for small data\nsets) and via punctual\
    \ kriging with a global variogram for larger data sets (>100 points). The kriging\n\
    method includes the ability to plot the experimental variogram and specify a theoretical\
    \ variogram,\nwhich is then passed to the kriging function. Interpolated outputs\
    \ can be directly displayed as rasters\nwithin the display (Step 2).\n‘Precision\
    \ Agriculture’ or ‘Smart Agriculture’ is only effective when effective decisions\
    \ are made.\nEnd-users can transform these information layers into decision layers\
    \ to improve the management of\ntheir ﬁelds. Three main functionalities for management\
    \ (practical) applications have been incorporated\nwithin GeoFIS to address this.\
    \ Firstly, practitioners are provided with a method to delineate within-ﬁeld\n\
    homogeneous zones (Step 3.1). Zoning is of importance for precision agriculture\
    \ data as the identiﬁed\nzones will (i) facilitate spatial data visualization\
    \ and interpretation; and (ii) provide a spatial resolution\nAgriculture 2018,\
    \ 8, 73\n5 of 21\nthat is practical and effective for many differential ﬁeld operations.\
    \ GeoFIS uses a segmentation\nalgorithm to ‘zone’ data layers [18]. The segmentation\
    \ algorithm operates either on irregular or\ngridded (interpolated) data to generate\
    \ potential management zones.\nSecondly, while data/information collection tends\
    \ to be focused around production issues, there is\nno restriction on its use.\
    \ It can equally be used for strategic as well as tactical decision making.\n\
    The example of the technical opportunity index (TOI) [31], which is implemented\
    \ in GeoFIS, is a case\nin point. The TOI uses the production data to assess a\
    \ ﬁeld’s suitability for site-speciﬁc management\ngiven machinery constraints\
    \ and the observed production variation (Step 3.2). The algorithm processes\n\
    the within ﬁeld data with a mathematical morphological ﬁlter based on erosions\
    \ and dilations [31].\nThis ﬁlter allows end-users to account for the passes of\
    \ the agricultural machinery in the ﬁeld and\nespecially the minimum area (kernel)\
    \ within which it can operate reliably. As the algorithm requires\nthe data to\
    \ be organized regularly on a grid, interpolating the data might therefore be\
    \ required as a\npre-processing step (Step 2).\nAgriculture 2018, 8, x FOR PEER\
    \ REVIEW  \n5 of 21 \n \nalgorithm operates either on irregular or gridded (interpolated)\
    \ data to generate potential \nmanagement zones. \nSecondly, while data/information\
    \ collection tends to be focused around production issues, there \nis no restriction\
    \ on its use. It can equally be used for strategic as well as tactical decision\
    \ making. The \nexample of the technical opportunity index (TOI) [31], which is\
    \ implemented in GeoFIS, is a case in \npoint. The TOI uses the production data\
    \ to assess a field’s suitability for site-specific management \ngiven machinery\
    \ constraints and the observed production variation (Step 3.2). The algorithm\
    \ \nprocesses the within field data with a mathematical morphological filter based\
    \ on erosions and \ndilations [31]. This filter allows end-users to account for\
    \ the passes of the agricultural machinery in \nthe field and especially the minimum\
    \ area (kernel) within which it can operate reliably. As the \nalgorithm requires\
    \ the data to be organized regularly on a grid, interpolating the data might therefore\
    \ \nbe required as a pre-processing step (Step 2). \n \nFigure 2. Generic flow\
    \ of data in precision agriculture with main processing steps from raw data \n\
    processing to decision-making. \nFinally, in the majority of cases, practical\
    \ agronomic decisions are multi-variate in nature. \nDecision support therefore\
    \ requires dedicated data fusion methods to merge multiple information \nlayers\
    \ into a single decision layer (Step 3.3). For instance, when available, historical\
    \ yield data (high \nspatial resolution point information), as-applied historical\
    \ fertilizer maps (polygon data), recent point \nsoil testing (low spatial resolution\
    \ point data) and early season satellite imagery (high resolution \nraster) should\
    \ collectively feed into a decision on mid-season spatial fertilizer inputs, i.e.,\
    \ a \nprescription fertilizer map (normally a polygon layer). In the previous\
    \ example, the prescription \nfertilization map (the decision layer) is based\
    \ on a set of inputs (information layers) that are all related \nthrough expert\
    \ rules. An example of a possible expert rule could be that if, on a given location\
    \ in \nspace, the observed yield is high and the soil fertilizer level is low,\
    \ then it might be relevant to apply \nmore fertilizer inputs. Within GeoFIS,\
    \ the goal of the data aggregation process is to implement the \nexpert rules\
    \ so that the final spatial decision layer (that answers the question: how much\
    \ fertilizer \ninput should be applied at this particular place at this particular\
    \ time?) can be obtained. Expert rules \nare implemented one at a time as each\
    \ rule leads to a practical agronomic decision.  \nData aggregation in GeoFIS\
    \ is a two-step process. First, each information layer is transformed \ninto an\
    \ expert layer, i.e., the numerical agronomic values in each information layer\
    \ are transformed \ninto degree values (from 0 to 1) according to the expert rule\
    \ to be implemented. The transformation \nfrom an information layer to an expert\
    \ layer is done using a fuzzy set-based function [32]. Secondly, \nFigure 2. Generic\
    \ ﬂow of data in precision agriculture with main processing steps from raw data\n\
    processing to decision-making.\nFinally, in the majority of cases, practical agronomic\
    \ decisions are multi-variate in nature.\nDecision support therefore requires\
    \ dedicated data fusion methods to merge multiple information\nlayers into a single\
    \ decision layer (Step 3.3). For instance, when available, historical yield data\n\
    (high spatial resolution point information), as-applied historical fertilizer\
    \ maps (polygon data),\nrecent point soil testing (low spatial resolution point\
    \ data) and early season satellite imagery\n(high resolution raster) should collectively\
    \ feed into a decision on mid-season spatial fertilizer inputs,\ni.e., a prescription\
    \ fertilizer map (normally a polygon layer). In the previous example, the prescription\n\
    fertilization map (the decision layer) is based on a set of inputs (information\
    \ layers) that are all related\nthrough expert rules. An example of a possible\
    \ expert rule could be that if, on a given location in\nspace, the observed yield\
    \ is high and the soil fertilizer level is low, then it might be relevant to apply\n\
    more fertilizer inputs. Within GeoFIS, the goal of the data aggregation process\
    \ is to implement the\nexpert rules so that the ﬁnal spatial decision layer (that\
    \ answers the question: how much fertilizer\ninput should be applied at this particular\
    \ place at this particular time?) can be obtained. Expert rules\nare implemented\
    \ one at a time as each rule leads to a practical agronomic decision.\nData aggregation\
    \ in GeoFIS is a two-step process. First, each information layer is transformed\
    \ into\nan expert layer, i.e., the numerical agronomic values in each information\
    \ layer are transformed into\nAgriculture 2018, 8, 73\n6 of 21\ndegree values\
    \ (from 0 to 1) according to the expert rule to be implemented. The transformation\
    \ from\nan information layer to an expert layer is done using a fuzzy set-based\
    \ function [32]. Secondly, all the\nexpert layers are combined using an aggregation\
    \ operator to respect the expert rules. Two aggregation\noperators are currently\
    \ implemented in GeoFIS. The ﬁrst operator is the Weighted Arithmetic Mean\n(WAM),\
    \ which attributes a weight to each information source, e.g., the yield information\
    \ layer may\nbe given twice as much weight as the soil fertilizer level layer.\
    \ The second operator is the Ordered\nWeighted Average (OWA) [33], where the weighing\
    \ is slightly more complex. For a given location\nin space, the degree values\
    \ associated with each layer involved in the expert rule are ordered and\nthe\
    \ weights assigned to each layer will depend on their position in this ordering.\
    \ This operator is of\ninterest as it enables the implementation of logical operations,\
    \ such as:\n-\n“OR”, where the expert rule applies as soon as the highest degree\
    \ associated with the layers is\nhigh, and\n-\n“AND”, where the expert rule applies\
    \ as soon as one of the degrees associated with the layers\nis high.\nThe result\
    \ of the aggregation process is a single decision layer. The uniqueness of the\
    \ GeoFIS\napproach is in its ability to incorporate the expert knowledge developed\
    \ by farmers and advisors\non the data and their ﬁelds directly into the data\
    \ fusion process. The implemented data aggregation\nmethods require the data to\
    \ be collocated, either on irregular or regular grids.\n3. Case Studies\nThe previous\
    \ section introduced the GeoFIS framework, introducing the functionalities\nimplemented\
    \ and how they could be adapted to the individual needs of each end-user (who\
    \ will\nhave their own unique constraints on management). The following sections\
    \ provide more detailed\nillustrations on the main processing steps in the context\
    \ of precision agriculture applications.\nMore speciﬁcally, the three cases deal\
    \ with the typical tasks that advisors and farmers may face\nin their daily job:\n\
    (i)\nthe mapping of spatial data (Steps 0, 1 and 2),\n(ii)\nthe evaluation and\
    \ cross-comparison of the opportunity for site-speciﬁc management in their\nﬁelds\
    \ (Step 3.2), and\n(iii) the delineation of within-ﬁeld zones for variable-rate\
    \ applications where zoning is considered\nopportune (Steps 3.1 and 3.3).\nSteps\
    \ 0 to 2 will be exempliﬁed through medium spatial resolution manual measurements\n\
    performed over a banana ﬁeld to map the plant vigor. High resolution yield data\
    \ across several\nwheat ﬁelds will be used to illustrate the value of Step 3.2\
    \ to rank the ﬁelds from the most to the\nless suitable for site-speciﬁc management.\
    \ Step 3.1 and 3.3 will be applied on a precision viticulture\nexample aimed at\
    \ deﬁning zones for differential irrigation management. The overall objective\
    \ is to\ndemonstrate how GeoFIS has the ability to address the main issues of\
    \ data processing in precision\nagriculture. As the three case studies are performed\
    \ on different crops (banana, wheat and grapevines),\neach exhibiting unique characteristics,\
    \ the applicability and genericity of this open-source software\nwill also be\
    \ demonstrated. The three case studies are detailed in the next three sections.\n\
    3.1. Case Study 1: Mapping the Spatial Organization in the Data—An Example of\
    \ the Vegetative Response of\nan Asynchronous Plant, the Banana\n3.1.1. Rationale\
    \ and Description\nVariography and mapping are two very important processing steps\
    \ in the precision agriculture\ndomain. The former helps evaluate the spatial\
    \ structure in the data by quantifying the proportions of\n(i) spatially-structured\
    \ variability or large-scale variations and (ii) spatially unstructured variability\
    \ or\nAgriculture 2018, 8, 73\n7 of 21\nsmall-scale variations within the ﬁeld.\
    \ The latter is mainly used to the correct display of the observed\nspatial variability\
    \ and facilitate the process of decision-making.\nIn this case study, GeoFIS was\
    \ used to investigate and map the spatial variability in the\npseudostem (trunk)\
    \ circumference of banana crops. The proposed analysis was carried out on\nthis\
    \ crop for two major reasons. First of all, the spatial variability in the agronomic\
    \ properties of\nbanana crops has been poorly reported in the literature [34].\
    \ Secondly, this crop is known to be\nasynchronous in its production cycle, which\
    \ means that spatial analyses are to be handled differently\nfrom what is commonly\
    \ done in annual crops, e.g., wheat, canola, or perennial ones, e.g., vineyards\
    \ [34].\nThe proposed analysis (i) estimates the proportion of spatially-structured\
    \ variability in pseudostem\ncircumferences, i.e., the proportion of variance\
    \ that is mainly due to spatially-structured environmental\nproperties [15]; (ii)\
    \ determines the proportion of spatially unstructured variability that is due\
    \ to\nnon-spatially structured phenomena e.g., the inter-plant variability, plant\
    \ competition, replanting,\nand measurement accuracy among others; and (iii) maps\
    \ the overall within-ﬁeld variability of trunk\ncircumference in the plantation.\n\
    The plot under study is situated in a commercial banana plantation in Njombe,\
    \ Cameroon (WGS84:\nE: 4.612, N: 9.639) in its 15th ﬂowering cycle. The pseudostem\
    \ circumference measurements were only\ntaken on plants where vegetative growth\
    \ had ceased, i.e., plants that were either ﬂowering or at a\nlater phenological\
    \ stage. There were 551 measurements taken using a tape measure at 1-m height\
    \ and\ngeoreferenced with a trail type hand-held GPS (Table 1). The proposed analysis\
    \ in GeoFIS consisted of\nthe following steps: (i) the dataset was imported within\
    \ GeoFIS (Step 0); (ii) pseudostem circumference\nvalues were filtered to ensure\
    \ the quality of the dataset (Step 1); (iii) variograms were fitted to the filtered\n\
    datasets and interpolation was performed using kriging with a local neighborhood\
    \ onto a 1 × 1 m grid.\nTable 1. Description of the plot under investigation.\n\
    Surface (ha)\nTotal Number of Plants\nObservations\nNumber of Plants that Have\
    \ Reached at\nLeast the Flowering Stage\nTrunk Circumference (cm)\nMean\nVariance\n\
    0.85\n1287\n551\n74.7\n69.7\n3.1.2. Application in GeoFIS\nThe global distribution\
    \ of the data was ﬁltered within GeoFIS (Figure 3). Users can select the\nattribute\
    \ to be ﬁltered at the top of the window. Below the histogram, two threshold values\
    \ that\nrepresent the two tails of the distribution can be changed, by either\
    \ typing speciﬁc values or moving a\nslide bar. Observations outside these thresholds\
    \ are then removed from the dataset. Note that there\nwere two low values in this\
    \ data set that were considered outside the normal distribution by the user\n\
    (Figure 3). The lower threshold allowed the user to eliminate these non-compliant\
    \ values.\nThe spatial structure of the data can then be evaluated by plotting\
    \ an experimental variogram,\nhere using the within-ﬁeld pseudostem circumferences.\
    \ The number of lags and the maximum\nlag distance can be set in the left-hand\
    \ corner of the window to make sure that the variogram is\nrelevant. The interface\
    \ (Figure 4) enables the user to specify and ﬁt a theoretical variogram model\n\
    to the experimental variogram. A theoretical variogram is automatically ﬁtted\
    \ after which users can\ninteractively change the values of the variogram parameters,\
    \ i.e., nugget, partial sill and range to\nimprove the ﬁt. The quality of the\
    \ ﬁt can be assessed with the root mean square error (RMSE) value\nthat is detailed\
    \ in the top right-hand corner of the interface. The theoretical model can then\
    \ be saved\nand used later to perform interpolation by kriging.\nAgriculture 2018,\
    \ 8, 73\n8 of 21\nAgriculture 2018, 8, x FOR PEER REVIEW  \n8 of 21 \n \n \nFigure\
    \ 3. Filtering of the pseudostem circumference values based on distribution of\
    \ response in the \nattribute space. \nThe spatial structure of the data can then\
    \ be evaluated by plotting an experimental variogram, \nhere using the within-field\
    \ pseudostem circumferences. The number of lags and the maximum lag \ndistance\
    \ can be set in the left-hand corner of the window to make sure that the variogram\
    \ is relevant. \nThe interface (Figure 4) enables the user to specify and fit\
    \ a theoretical variogram model to the \nexperimental variogram. A theoretical\
    \ variogram is automatically fitted after which users can \ninteractively change\
    \ the values of the variogram parameters, i.e., nugget, partial sill and range\
    \ to \nimprove the fit. The quality of the fit can be assessed with the root mean\
    \ square error (RMSE) value \nthat is detailed in the top right-hand corner of\
    \ the interface. The theoretical model can then be saved \nand used later to perform\
    \ interpolation by kriging. \n \nFigure 4. Screenshot from GeoFIS illustrating\
    \ the calculation of the experimental variogram and the \nfitting of a theoretical\
    \ variogram model to the within-field pseudostem circumference spatial data. \n\
    Figure 3. Filtering of the pseudostem circumference values based on distribution\
    \ of response in the\nattribute space.\n \n \nFigure 3. Filtering of the pseudostem\
    \ circumference values based on distribution of response in the \nattribute space.\
    \ \nThe spatial structure of the data can then be evaluated by plotting an experimental\
    \ variogram, \nhere using the within-field pseudostem circumferences. The number\
    \ of lags and the maximum lag \ndistance can be set in the left-hand corner of\
    \ the window to make sure that the variogram is relevant. \nThe interface (Figure\
    \ 4) enables the user to specify and fit a theoretical variogram model to the\
    \ \nexperimental variogram. A theoretical variogram is automatically fitted after\
    \ which users can \ninteractively change the values of the variogram parameters,\
    \ i.e., nugget, partial sill and range to \nimprove the fit. The quality of the\
    \ fit can be assessed with the root mean square error (RMSE) value \nthat is detailed\
    \ in the top right-hand corner of the interface. The theoretical model can then\
    \ be saved \nand used later to perform interpolation by kriging. \n \nFigure 4.\
    \ Screenshot from GeoFIS illustrating the calculation of the experimental variogram\
    \ and the \nfitting of a theoretical variogram model to the within-field pseudostem\
    \ circumference spatial data. \nFigure 4. Screenshot from GeoFIS illustrating\
    \ the calculation of the experimental variogram and the\nﬁtting of a theoretical\
    \ variogram model to the within-ﬁeld pseudostem circumference spatial data.\n\
    3.1.3. Results and Discussion\nThe spatial locations of the measurements are displayed\
    \ in Figure 5. It clearly shows that the\nspatial observations are irregularly-spaced\
    \ within the plot. This aspect can be simply explained by\nthe fact that not all\
    \ the banana plants had reached the ﬂowering phenological stage (only 551 out\n\
    of the 1287 plants had). In the plot under study, the pseudostem circumference\
    \ exhibits a quite\nstrong spatial autocorrelation, the ratio of autocorrelated\
    \ variance being close to 55% (Table 2).\nAgriculture 2018, 8, 73\n9 of 21\nThis\
    \ ﬁnding demonstrates that spatially-structured environmental properties, e.g.,\
    \ soil physical and\nchemical characteristics, are likely in this case to exert\
    \ a relatively strong inﬂuence on the pseudostem\ncircumference of the banana\
    \ plants. The determination of the factors affecting the pseudostem\ncircumference\
    \ is beyond the scope of this study. Further analyses, e.g., soil and plant records,\
    \ might help\nto answer this question.\n \n3.1.3. Results and Discussion \nThe\
    \ spatial locations of the measurements are displayed in Figure 5. It clearly\
    \ shows that the \nspatial observations are irregularly-spaced within the plot.\
    \ This aspect can be simply explained by \nthe fact that not all the banana plants\
    \ had reached the flowering phenological stage (only 551 out of \nthe 1287 plants\
    \ had). In the plot under study, the pseudostem circumference exhibits a quite\
    \ strong \nspatial autocorrelation, the ratio of autocorrelated variance being\
    \ close to 55% (Table 2). This finding \ndemonstrates that spatially-structured\
    \ environmental properties, e.g., soil physical and chemical \ncharacteristics,\
    \ are likely in this case to exert a relatively strong influence on the pseudostem\
    \ \ncircumference of the banana plants. The determination of the factors affecting\
    \ the pseudostem \ncircumference is beyond the scope of this study. Further analyses,\
    \ e.g., soil and plant records, might \nhelp to answer this question. \n \nFigure\
    \ 5. Spatial measurements of pseudostem circumference divided in 5 quantiles within\
    \ the plot \nunder study. \nTable 2 also shows that the proportion of spatially\
    \ unstructured variability (C0) is not negligible. \nIn this case study, it can\
    \ be mainly explained by (i) the inherent within-plant variability that might\
    \ \nbe exacerbated by competition amongst neighbors, and (ii) the accuracy of\
    \ the measurements which \nmight be affected by Global Navigation Satellite Systems\
    \ (GNSS) accuracy issues or operator errors. \nTable 2. Spatial statistics of\
    \ pseudostem circumference in the plot under investigation. \nNugget Variance\
    \ \n(C0) \nPartial-Sill \nVariance (C1) \nSill Variance (C0 + C1) \nRatio of Autocorrelated\
    \ Variance \n(C1/C0 + C1) \n35.2 \n43.4 \n78.6 \n55.2% \nFigure 6 provides a surface\
    \ (map) of the within-field pseudostem circumference after \ninterpolation (ordinary\
    \ kriging). This smooths the data in Figure 5 using information on spatial \n\
    variability contained in the same data. The circumferences appear to be much lower\
    \ (less than 70 cm) \nin the northern-eastern and in the southern portions of\
    \ the plots. The larger pseudostems, those for \nwhich the circumference exceeded\
    \ 87 cm, can be mainly found in the northern-part of the field. Some \nlocal effects,\
    \ e.g., small sites of low circumference surrounded by high pseudostem circumferences,\
    \ \nare also visible on the maps. Those might be explained by several phenomena\
    \ having a localized \neffect on plants, such as pest damage or replanting. It\
    \ is worth recalling that this final map is not a \nFigure 5. Spatial measurements\
    \ of pseudostem circumference divided in 5 quantiles within the plot\nunder study.\n\
    Table 2 also shows that the proportion of spatially unstructured variability (C0)\
    \ is not negligible.\nIn this case study, it can be mainly explained by (i) the\
    \ inherent within-plant variability that might\nbe exacerbated by competition\
    \ amongst neighbors, and (ii) the accuracy of the measurements which\nmight be\
    \ affected by Global Navigation Satellite Systems (GNSS) accuracy issues or operator\
    \ errors.\nTable 2. Spatial statistics of pseudostem circumference in the plot\
    \ under investigation.\nNugget Variance (C0)\nPartial-Sill Variance (C1)\nSill\
    \ Variance (C0 + C1)\nRatio of Autocorrelated Variance\n(C1/C0 + C1)\n35.2\n43.4\n\
    78.6\n55.2%\nFigure 6 provides a surface (map) of the within-ﬁeld pseudostem circumference\
    \ after interpolation\n(ordinary kriging). This smooths the data in Figure 5 using\
    \ information on spatial variability contained\nin the same data. The circumferences\
    \ appear to be much lower (less than 70 cm) in the northern-eastern\nand in the\
    \ southern portions of the plots. The larger pseudostems, those for which the\
    \ circumference\nexceeded 87 cm, can be mainly found in the northern-part of the\
    \ ﬁeld. Some local effects, e.g., small sites\nof low circumference surrounded\
    \ by high pseudostem circumferences, are also visible on the maps.\nThose might\
    \ be explained by several phenomena having a localized effect on plants, such\
    \ as pest\ndamage or replanting. It is worth recalling that this ﬁnal map is not\
    \ a map of circumferences of all\npseudostems, but rather a map of potential circumference\
    \ at ﬂowering as not all the banana plants have\nreached the ﬂowering stage. This\
    \ map is an alternative representation of the information displayed\nin Figure\
    \ 5 and provides predictions for plants that were not measured in the original\
    \ survey. As for\nFigure 6, this map may be very useful in locating sampling sites\
    \ to perform further soil and or plant\nanalyses and to better characterize the\
    \ within-ﬁeld pseudostem circumference variability. It has the\nAgriculture 2018,\
    \ 8, 73\n10 of 21\nadvantage over the raw data plot (Figure 5) of being easier\
    \ for the human eye to interpret the main\npatterns in the ﬁeld.\n \nmap of circumferences\
    \ of all pseudostems, but rather a map of potential circumference at flowering\
    \ \nas not all the banana plants have reached the flowering stage. This map is\
    \ an alternative \nrepresentation of the information displayed in Figure 5 and\
    \ provides predictions for plants that were \nnot measured in the original survey.\
    \ As for Figure 6, this map may be very useful in locating sampling \nsites to\
    \ perform further soil and or plant analyses and to better characterize the within-field\
    \ \npseudostem circumference variability. It has the advantage over the raw data\
    \ plot (Figure 5) of being \neasier for the human eye to interpret the main patterns\
    \ in the field.  \n \nFigure 6. Kriged map of the potential pseudostem circumference\
    \ within the field under study. The \nmap represents a potential rather than an\
    \ exhaustive analysis of plants because not all the plants have \nreached the\
    \ flowering stage. \nGeoFIS proved to be a relevant tool to model the spatial\
    \ variability in the banana pseudostem \ncircumference data and for continuous\
    \ mapping of this property of interest. However, a couple of \nlimitations are\
    \ worth discussing. Firstly, even if the filtering interface is user-friendly,\
    \ it only provides \na global filtering of the data. Only the tails of the distribution\
    \ can be trimmed. It may have been that \nspatial data not only exhibit global\
    \ but also local outliers. This was not a problem here but removing \nlocal outliers\
    \ would be a useful function in the software program. When present, local outliers\
    \ \n(inliers) will affect the quality of interpolation procedures. Secondly, GeoFIS\
    \ does not yet allow the \nfitting of nested variogram models. This was a potential\
    \ issue in this case study. In Figure 4, it could \nbe argued that there is a\
    \ short-range spatial structure within the first 10 m and a second spatial \n\
    structure from 10 to 30 m (with a longer range). Nested spatial structures are\
    \ not common but do \noccur in agricultural data. Thirdly, regarding the continuous\
    \ mapping of the data, GeoFIS only \nprovides a kriged map of the property of\
    \ interest. The mean estimates are given but the error (kriging \nvariance) associated\
    \ with these estimates is not provided. This is a potential limitation for assessing\
    \ \nthe mapping accuracy and for interpreting uncertainty in future analyses with\
    \ the interpolated data. \n3.2. Case Study 2: Evaluating and Comparing the Opportunity\
    \ for Site-Specific Management within Fields \n3.2.1. Rationale and Description\
    \ \nSite-specific management requires a strong investment in time, money and technical\
    \ skills for \ngrowers. This investment requires certain conditions to be met.\
    \ Firstly, the within-field variability \nhas to be strong enough to justify differentiate\
    \ management. Secondly, this variability has to be \nspatially structured or organized\
    \ enough within the field to be able to be managed by agricultural \nFigure 6.\
    \ Kriged map of the potential pseudostem circumference within the ﬁeld under study.\
    \ The map\nrepresents a potential rather than an exhaustive analysis of plants\
    \ because not all the plants have\nreached the ﬂowering stage.\nGeoFIS proved\
    \ to be a relevant tool to model the spatial variability in the banana pseudostem\n\
    circumference data and for continuous mapping of this property of interest. However,\
    \ a couple of\nlimitations are worth discussing. Firstly, even if the ﬁltering\
    \ interface is user-friendly, it only provides\na global ﬁltering of the data.\
    \ Only the tails of the distribution can be trimmed. It may have been that\nspatial\
    \ data not only exhibit global but also local outliers. This was not a problem\
    \ here but removing\nlocal outliers would be a useful function in the software\
    \ program. When present, local outliers (inliers)\nwill affect the quality of\
    \ interpolation procedures. Secondly, GeoFIS does not yet allow the ﬁtting of\n\
    nested variogram models. This was a potential issue in this case study. In Figure\
    \ 4, it could be argued\nthat there is a short-range spatial structure within\
    \ the ﬁrst 10 m and a second spatial structure from 10\nto 30 m (with a longer\
    \ range). Nested spatial structures are not common but do occur in agricultural\n\
    data. Thirdly, regarding the continuous mapping of the data, GeoFIS only provides\
    \ a kriged map of\nthe property of interest. The mean estimates are given but\
    \ the error (kriging variance) associated with\nthese estimates is not provided.\
    \ This is a potential limitation for assessing the mapping accuracy and\nfor interpreting\
    \ uncertainty in future analyses with the interpolated data.\n3.2. Case Study\
    \ 2: Evaluating and Comparing the Opportunity for Site-Speciﬁc Management within\
    \ Fields\n3.2.1. Rationale and Description\nSite-speciﬁc management requires a\
    \ strong investment in time, money and technical skills for\ngrowers. This investment\
    \ requires certain conditions to be met. Firstly, the within-ﬁeld variability\n\
    has to be strong enough to justify differentiate management. Secondly, this variability\
    \ has to be\nspatially structured or organized enough within the ﬁeld to be able\
    \ to be managed by agricultural\nmachinery [2]. Farmers, therefore, are in need\
    \ of tools that will help them to evaluate this opportunity\nfor site-speciﬁc\
    \ management. To make decisions at a larger level than the ﬁeld, i.e., the whole\
    \ farm,\nthis opportunity also has to be cross-compared between ﬁelds. Farmers\
    \ should preferentially commit\ntheir efforts towards the ﬁelds that are the most\
    \ opportune for site-speciﬁc management. These are\nAgriculture 2018, 8, 73\n\
    11 of 21\nmost likely to have the largest returns on investment in agri-technology,\
    \ which should minimize the\nrisk of investment for the farmer.\nIn this case\
    \ study,\nGeoFIS was used to evaluate and compare the opportunity for\nadopting\
    \ site-speciﬁc management across multiple ﬁelds using a deﬁned opportunity index\
    \ [31].\nOpportunity indices are a way of assessing if the amount and structure\
    \ of variation in a ﬁeld makes\nsite-speciﬁc management a potentially feasible\
    \ option [2,25]. Seven yield datasets arising from two\ndifferent farms located\
    \ near Evreux, in the north-western part of France (Farm 1—WGS84: E: 0.779, N:\n\
    48.955; Farm 2—WGS84: E: 1.032, N: 48.828) were used. Fields were cropped in wheat\
    \ and harvested\nwith various combines, primarily New Holland (Turin, Italy) and\
    \ Claas (Harsewinkel, Germany)\ncombines. Yield datasets are considered particularly\
    \ relevant for this case study because the yield\nis directly related to the ﬁeld\
    \ economic returns. Quantifying the amount and structure of yield\nvariance should\
    \ therefore be a valuable indicator of whether site-speciﬁc management is opportune.\n\
    Structured spatial variation in yield would indicate a potential for structured\
    \ spatial crop management,\nparticularly fertilizer and agri-chemicals.\nThis\
    \ case study also demonstrates the use of GeoFIS with dense sensor-derived spatial\n\
    observations in contrast to the spatial manual measurements presented in Case\
    \ Study 1. Yield data\nare collected with on-board sensors at 1 Hz as the combine\
    \ traverses the ﬁeld. These observations are\ntherefore irregularly-distributed\
    \ in space because (i) the intra-row and inter-row distances are different\nand\
    \ (ii) the acquisition conditions, such as the GNSS accuracy or variable combine\
    \ speed, can impact\nthe spatial distribution of the observations. The yield information\
    \ is very dense (thousands of points\nper hectare) and very noisy because of stochastic\
    \ error in sensor operation, the intrinsic local variability\nin production and\
    \ errors associated with the combine harvester passing through the ﬁeld [13,28].\n\
    These seven ﬁelds were selected as they exhibit various degrees of yield autocorrelation\
    \ within\nthe same systems (farms) and, as such, should represent a different\
    \ opportunity for variable-rate\napplications. Within this case-study, several\
    \ functions of GeoFIS were used to arrive at a solution that\nranks and compares\
    \ the seven ﬁelds in terms of a technical opportunity for site-speciﬁc management.\n\
    More speciﬁcally, (i) global outliers were ﬁltered out (Step 1); (ii) variograms\
    \ were ﬁtted to the\npreviously ﬁltered yield datasets and ordinary kriging with\
    \ a global variogram and local neighborhood\nwas performed onto a 3 × 3 m grid\
    \ (Step 2); and (iii) the TOI was computed (see Section 2.3\nFunctionalities implemented\
    \ in GeoFIS) (Step 3.2). To account for technical and operational constraints\n\
    during the TOI computation, the following operational characteristics were assumed:\
    \ a working width\nof 20 m, a mean speed of 3 m s−1 and a delay rate of change\
    \ between two different treatments of 2 s.\nThis could be for instance the characteristics\
    \ of a fertilizer spreader performing variate-rate application.\nThe major yield\
    \ statistics of the seven ﬁelds under consideration after data clean-up are reported\
    \ in\nTable 3.\nTable 3. Principal descriptive and spatial statistics of the seven\
    \ yield datasets under consideration.\nThe nugget to sill ratio can be calculated\
    \ after variograms are ﬁtted to the cleaned data in GeoFIS.\nField\nSize (ha)\n\
    Mean (t ha−1)\nCV (%)\nNugget to Sill Ratio (%)\n1\n8.9\n8.3\n8.7\n53.8\n2\n12.9\n\
    7.0\n24.6\n46.3\n3\n8.9\n7.8\n11.6\n36.0\n4\n11.2\n6.1\n9.1\n37.5\n5\n18.1\n7.1\n\
    14.5\n22.4\n6\n24.1\n9.6\n15.9\n19.9\n7\n32.5\n9.5\n15.4\n15.1\n3.2.2. Application\
    \ in GeoFIS\nThe ﬁltering and interpolation procedures have already been detailed\
    \ in Case Study 1 and will\nnot be discussed here. The technical opportunity index\
    \ (TOI) can be computed in the Opportunity\nAgriculture 2018, 8, 73\n12 of 21\n\
    Index toolbar of the GeoFIS software. Figure 7 displays the window that appears\
    \ when this menu\nis selected. The window is composed of three main sections.\
    \ In the top drop-down menu (Border),\nusers are asked to select the attribute\
    \ on which the metric should be computed, e.g., yield, and to\nprovide the ﬁeld\
    \ boundaries to make sure that the calculation of the TOI is restricted to the\
    \ ﬁeld of\ninterest. Note that the boundary can be automatically derived with\
    \ a convex hull, however this may\nnot be a good option for ﬁelds with an irregular\
    \ geometric shape. In the second drop-down menu\n(Machine Footprint) the technical\
    \ and operational constraints of future site-speciﬁc management can\nbe speciﬁed.\
    \ More speciﬁcally, users can provide the working width of machinery, its speed,\
    \ the delay\nin the rate of change between two levels of outputs (management strategies),\
    \ and the uncertainty in\nthe GNSS positioning of the machine. The third drop-down\
    \ menu (Interpolation) ensures that all\nobservations are reported on a ﬁxed grid\
    \ and the TOI is calculated using the grid data. Users can select\nthe size of\
    \ the interpolation grid along with the interpolation procedure, i.e., inverse\
    \ distance weighing\nor kriging. Note that both interpolation approaches need\
    \ to be parametrized and some user input.\nWhen all this information has been\
    \ speciﬁed by a user, the TOI can be calculated. The window\ndisplays two major\
    \ outputs: (i) the TOI value associated with the data along with the corresponding\n\
    error rate of application; and (ii) the potential management zone map with the\
    \ different strategies that\nshould be applied (in the case of Figure 7 there\
    \ are two strategies presented). This latter map can be\nexported and used in\
    \ other GIS software if needed.\nAgriculture 2018, 8, x FOR PEER REVIEW  \n13\
    \ of 21 \n \nFigure 7. Screenshot of output from the computation of the Technical\
    \ Opportunity Index (TOI) in \nGeoFIS for Field 7. \nFigure 7. Screenshot of output\
    \ from the computation of the Technical Opportunity Index (TOI) in\nGeoFIS for\
    \ Field 7.\n3.2.3. Results and Discussion\nFigure 8 shows the seven ﬁelds in the\
    \ study ranked by their respective TOI values along with the\ncorresponding variable-rate\
    \ application map for a two-management strategy. It clearly shows that\nthe ﬁelds\
    \ have different levels of yield spatial structure, from the lowest for Field\
    \ 1 to the strongest\nAgriculture 2018, 8, 73\n13 of 21\nfor Field 7. Note that,\
    \ in this case study, the order of the TOI values is consistent with the order\
    \ of\nnugget to sill ratios (Table 3). The TOI values are however very close in\
    \ absolute terms (Figure 8)\nwith a range from 0.888 to 0.965. As the TOI value\
    \ can theoretically range from 0 to 1, all the ﬁelds\nhere are exhibiting high\
    \ TOI values, indicating that a site-speciﬁc management is opportune for all\n\
    of these ﬁelds. All the maps have spatially-structured patterns, in accordance\
    \ with the technical and\noperational constraints of a future possible machine\
    \ pass (Figure 8). These maps could be directly\nincorporated into a machinery\
    \ system to perform site-speciﬁc management.\n \n \nFigure 7. Screenshot of output\
    \ from the computation of the Technical Opportunity Index (TOI) in \nGeoFIS for\
    \ Field 7. \n \nAgriculture 2018, 8, x FOR PEER REVIEW  \n14 of 21 \n \nFigure\
    \ 8. Ranking of the seven yield datasets in terms of the associated TOI value:\
    \ (a) Field 1; (b) Field 2; \n(c) Field 3; (d) Field 4; (e) Field 5; (f) Field\
    \ 6; (g) Field 7. Cleaned yield values and corresponding \npotential variable\
    \ application maps are also displayed for each field. TOI: technical opportunity\
    \ index. \nThe TOI is a valuable metric to evaluate and rank fields with respect\
    \ to the opportunity for site-\nspecific management. GeoFIS is an interesting\
    \ tool to perform this case study as all the steps required \nto compute the TOI\
    \ can be performed within the program. Note that potential management zone \n\
    maps are also provided and can be simply exported through the easy-to-use interface\
    \ (however the \ntarget rates are not yet determined at this point—see case study\
    \ 3). This should foster the adoption \nof precision agriculture technologies.\
    \ Users must however be cautious when computing and \ninterpreting the TOI as\
    \ this metric is particularly sensitive to the interpolation of the cleaned data\
    \ and \nthe setting of the technical and operation constraints for site-specific\
    \ management. Users should be \nable to perform a series of tests within GeoFIS\
    \ to evaluate the impact of their parametrization on the \nTOI\nl\nd\nT\nhi\n\
    i\nf\ni l\nFigure 8. Ranking of the seven yield datasets in terms of the associated\
    \ TOI value: (a) Field 1; (b) Field 2;\n(c) Field 3; (d) Field 4; (e) Field 5;\
    \ (f) Field 6; (g) Field 7. Cleaned yield values and corresponding\npotential\
    \ variable application maps are also displayed for each ﬁeld. TOI: technical opportunity\
    \ index.\nThe high TOI values for these ﬁelds is due to two principal reasons:\
    \ (i) the data interpolation\nand (ii) the operational constraints that were set.\
    \ The computation of the TOI requires the data\nto be regularly distributed over\
    \ the ﬁeld, which is why a prior interpolation procedure is put into\nAgriculture\
    \ 2018, 8, 73\n14 of 21\nplace. In this case study, the interpolation by kriging\
    \ generated a relatively strong data smoothing\nthat artiﬁcially increased the\
    \ TOI values as it is calculated on the interpolated data. Indeed, as the\nsmall-scale\
    \ variations are smoothed, the yield patterns appear much more organized in space\
    \ and the\nsite-speciﬁc management is consequently considered more opportune.\
    \ The settings of the operational\ncharacteristics in these ﬁelds also facilitated\
    \ high TOI values. As the minimal size of ﬁeld management\n(working width of the\
    \ machinery) decreases, the opportunity for variable-rate application will increase.\n\
    Smaller machinery means that smaller areas of spatial variation become potentially\
    \ manageable.\nIn contrast, if ﬁeld management was done at a coarser level, e.g.,\
    \ the working width of the machinery\nwas set to 40 m, then the opportunity for\
    \ site-speciﬁc management would decrease and there would\nlikely be larger differences\
    \ amongst the seven ﬁelds under study (data not shown). As can be seen\nin Figure\
    \ 8, only two management strategies are proposed for each ﬁeld. Even if this two-class\n\
    categorization appears sufﬁcient in some case studies, the actual computation\
    \ of the TOI at the moment\ndoes not allow for alternative management strategies\
    \ (three, four, . . . , etc. classes) to be simultaneously\nconsidered. This aspect\
    \ will be investigated in further studies.\nThe TOI is a valuable metric to evaluate\
    \ and rank ﬁelds with respect to the opportunity for\nsite-speciﬁc management.\
    \ GeoFIS is an interesting tool to perform this case study as all the steps\n\
    required to compute the TOI can be performed within the program. Note that potential\
    \ management\nzone maps are also provided and can be simply exported through the\
    \ easy-to-use interface (however the\ntarget rates are not yet determined at this\
    \ point—see case study 3). This should foster the adoption of\nprecision agriculture\
    \ technologies. Users must however be cautious when computing and interpreting\n\
    the TOI as this metric is particularly sensitive to the interpolation of the cleaned\
    \ data and the setting of\nthe technical and operation constraints for site-speciﬁc\
    \ management. Users should be able to perform\na series of tests within GeoFIS\
    \ to evaluate the impact of their parametrization on the TOI values and\nmanagement\
    \ zone maps. To cross-compare this opportunity for potential differentiate application\n\
    amongst ﬁelds, authors strongly advocate the application of the exact same process\
    \ with similar\nsettings for the calculation of the ﬁnal TOI metric.\n3.3. Case\
    \ Study 3: Delineating within-Field Zones for Variable-Rate Applications Using\
    \ Expert Knowledge\n3.3.1. Rationale and Description\nThe delineation of within-ﬁeld\
    \ zones is an important procedure in precision agriculture studies\nbecause it\
    \ enables, or at least facilitates, growers to perform variable-rate applications.\
    \ The creation\nof these zones is a complex process for multiple reasons: (i)\
    \ there is a need to account for spatial\nrelationships in the data; (ii) very\
    \ often multiple layers of spatial information must be combined;\nand (iii) the\
    \ decision rules associated with agronomic applications are complex and require\
    \ the\ngrower’s knowledge to be involved in the processing. In this case study,\
    \ GeoFIS will be used to\ndelineate within-ﬁeld zones prior to the management\
    \ of irrigation and fertilization in a Spanish\nvineyard using several layers\
    \ of information and incorporating expert knowledge. This case study is an\nextension\
    \ of previous work [35]. Interested readers are referred to this document for\
    \ more information.\nThe study was carried out on a 90-ha commercial vineyard\
    \ containing 27 contiguous ﬁelds\n(Figure 9) located in Southern Navarre, Spain\
    \ (WGS84: E: 1.405, N: 42.254). The vine vigor, soil,\nand water availability\
    \ in the ﬁeld were considered to be of major interest by the vine manager to\n\
    manage irrigation and fertilization practices.\nVine vigor was estimated using\
    \ the normalized difference vegetation index (NDVI) on a 3 × 3 m\nraster layer\
    \ derived from a Multi-spectral Airborne image acquired in August 2007 and provided\n\
    and processed by the Geosys-Spain Company (Leica ADS40 sensor). Measurements of\
    \ soil apparent\nelectrical conductivity (ECa) on a 30 × 30 m grid (256 sampling\
    \ points) were performed using a\nhandheld ground conductivity meter (EM38, Geonics\
    \ Ltd., Mississauga, ON, Canada) to map soil\nspatial variability. The same sample\
    \ sites were used to create a digital terrain model from elevation data\nobtained\
    \ with a laser Tachymeter (TPS 1001, Leica, Heerbrugg, Switzerland). Both ECa\
    \ and elevation\nAgriculture 2018, 8, 73\n15 of 21\ndata were kriged onto a 3\
    \ m grid. Additional monitoring was performed to provide more information\non\
    \ the vine vigor, soil and water variation [35]. As these additional observations\
    \ were more expensive\nand/or cumbersome to collect, only 64 out of the 256 sampling\
    \ sites were monitored. These monitoring\nsites were selected using the high-resolution\
    \ data layers. Additional observations were related to the\n(i) soil, e.g., observation\
    \ of soil pits; (ii) plant, e.g., plant water status, pruning weight of wood and\n\
    yield; and (iii) production, e.g., berry size, berry composition, yield characteristics.\
    \ The analysis of all\nthese data layers led to an explanatory reasoning summarized\
    \ as [35]:\n•\nHydromorphic soils and wetlands are well deﬁned by the ECa information.\
    \ Their presence is\nmainly explained by variations in elevation,\n•\nVine vegetative\
    \ expression is too high (and harvest quality too low) on the zones at the highest\n\
    elevations, characterized by light and deep soils (low ECa values),\n•\nVine vegetative\
    \ expression is too weak on the zones at the lowest elevations, characterized\
    \ by\nclay soils, which suffer from waterlogging after rainfall events (high ECa\
    \ values).\nAgriculture 2018, 8, x FOR PEER REVIEW  \n15 of 21 \n \nFigure 9.\
    \ Maps of the whole-vineyard showing the spatial variability in (a) elevation;\
    \ (b) soil apparent \nconductivity (ECa); and (c) vegetative expression (normalized\
    \ difference vegetation index (NDVI)). \nPoints in (a,b) indicate sampling locations\
    \ (n = 256) (reproduced with permission from Reference 35) \n[35]. \nVine vigor\
    \ was estimated using the normalized difference vegetation index (NDVI) on a 3\
    \ × 3 m \nraster layer derived from a Multi-spectral Airborne image acquired in\
    \ August 2007 and provided and \nprocessed by the Geosys-Spain Company (Leica\
    \ ADS40 sensor). Measurements of soil apparent \nelectrical conductivity (ECa)\
    \ on a 30 × 30 m grid (256 sampling points) were performed using a \nhandheld\
    \ ground conductivity meter (EM38, Geonics Ltd., Mississauga, ON, Canada) to map\
    \ soil \nspatial variability. The same sample sites were used to create a digital\
    \ terrain model from elevation \ndata obtained with a laser Tachymeter (TPS 1001,\
    \ Leica, Heerbrugg, Switzerland). Both ECa and \nelevation data were kriged onto\
    \ a 3 m grid. Additional monitoring was performed to provide more \ninformation\
    \ on the vine vigor, soil and water variation [35]. As these additional observations\
    \ were \nmore expensive and/or cumbersome to collect, only 64 out of the 256 sampling\
    \ sites were monitored. \nThese monitoring sites were selected using the high-resolution\
    \ data layers. Additional observations \nwere related to the (i) soil, e.g., observation\
    \ of soil pits, (ii) plant, e.g., plant water status, pruning \nFigure 9. Maps\
    \ of the whole-vineyard showing the spatial variability in (a) elevation; (b)\
    \ soil apparent\nconductivity (ECa); and (c) vegetative expression (normalized\
    \ difference vegetation index (NDVI)).\nPoints in (a,b) indicate sampling locations\
    \ (n = 256) (reproduced with permission from Reference 35) [35].\nBased on this\
    \ explanatory reasoning, the vineyard manager deﬁned several decision rules to\n\
    identify the situations in which the current management practices were sub-optimal\
    \ regarding grape\nquality and quantity at harvest. An example of one of these\
    \ rules was:\nIf NDVI is high (>70) and ECa is low (<180 mS · m−1) and elevation\
    \ is high (>360 m), then the\nrisk of having sub-optimal management practices\
    \ is high.\nThis latter rule was modelled in GeoFIS to provide a map showing the\
    \ risk of having sub-optimal\nmanagement practices within the vineyard. First,\
    \ the three data layers involved in the expert rule\nAgriculture 2018, 8, 73\n\
    16 of 21\nwere transformed into risk maps using risk functions (Step 3.3). The\
    \ parametrization of these risk\nfunctions was done with the vineyard manager.\
    \ All the univariate risk maps were then combined into\na ﬁnal risk map using\
    \ the OWA aggregator, which was again parametrized with the vineyard manager\n\
    (see Section 2.3 Functionalities implemented in GeoFIS) (Step 3.3). Finally, a\
    \ segmentation algorithm\nwas applied to this last risk map to provide within-ﬁeld\
    \ risk zones (Step 3.1).\n3.3.2. Application in GeoFIS\nThis section will focus\
    \ on the computation of the risk functions and on the zoning of the resulting\n\
    risk map. For each layer of information (ECa, NDVI, Elevation), risk functions\
    \ can be deﬁned within\nGeoFIS by implementing fuzzy rules as displayed in Figure\
    \ 10. Here, a semi trapezoidal function\nwas used to model the risk of having\
    \ sub-optimal practices by solely relying on the ECa layer. In this\ninterface,\
    \ the form of the risk function can be changed along with the associated fuzzy\
    \ parameters, i.e.,\nthe kernel and support. Once the risk functions have been\
    \ set for all the layers of interest, all the risks\ncan be aggregated with respect\
    \ to the aforementioned expert rule(s). This aggregation procedure can\nbe performed\
    \ through the interfaces displayed in Figure 11 where (i) the layers can be selected\
    \ and the\naggregation operator can be chosen (OWA aggregator here) and; (ii)\
    \ the parameters associated to the\nOWA aggregator can be stated.\n \nidentify\
    \ the situations in which the current management practices were sub-optimal regarding\
    \ grape \nquality and quantity at harvest. An example of one of these rules was:\
    \  \nIf NDVI is high (>70) and ECa is low (<180 mS m−1) and elevation is high\
    \ (>360 m), then the risk \nof having sub-optimal management practices is high.\
    \  \nThis latter rule was modelled in GeoFIS to provide a map showing the risk\
    \ of having sub-optimal \nmanagement practices within the vineyard. First, the\
    \ three data layers involved in the expert rule \nwere transformed into risk maps\
    \ using risk functions (Step 3.3). The parametrization of these risk \nfunctions\
    \ was done with the vineyard manager. All the univariate risk maps were then combined\
    \ \ninto a final risk map using the OWA aggregator, which was again parametrized\
    \ with the vineyard \nmanager (see Section 2.3 Functionalities implemented in\
    \ GeoFIS) (Step 3.3). Finally, a segmentation \nalgorithm was applied to this\
    \ last risk map to provide within-field risk zones (Step 3.1). \n3.3.2. Application\
    \ in GeoFIS \nThis section will focus on the computation of the risk functions\
    \ and on the zoning of the resulting \nrisk map. For each layer of information\
    \ (ECa, NDVI, Elevation), risk functions can be defined within \nGeoFIS by implementing\
    \ fuzzy rules as displayed in Figure 10. Here, a semi trapezoidal function was\
    \ \nused to model the risk of having sub-optimal practices by solely relying on\
    \ the ECa layer. In this \ninterface, the form of the risk function can be changed\
    \ along with the associated fuzzy parameters, \ni.e., the kernel and support.\
    \ Once the risk functions have been set for all the layers of interest, all the\
    \ \nrisks can be aggregated with respect to the aforementioned expert rule(s).\
    \ This aggregation procedure \ncan be performed through the interfaces displayed\
    \ in Figure 11 where (i) the layers can be selected \nand the aggregation operator\
    \ can be chosen (OWA aggregator here) and, (ii) the parameters \nassociated to\
    \ the OWA aggregator can be stated. \n \nFigure 10. Implementation of the risk\
    \ function associated with the ECa information layer. \n \nFigure 10. Implementation\
    \ of the risk function associated with the ECa information layer.\n \nquality\
    \ and quantity at harvest. An example of one of these rules was:  \nIf NDVI is\
    \ high (>70) and ECa is low (<180 mS m−1) and elevation is high (>360 m), then\
    \ the risk \nof having sub-optimal management practices is high.  \nThis latter\
    \ rule was modelled in GeoFIS to provide a map showing the risk of having sub-optimal\
    \ \nmanagement practices within the vineyard. First, the three data layers involved\
    \ in the expert rule \nwere transformed into risk maps using risk functions (Step\
    \ 3.3). The parametrization of these risk \nfunctions was done with the vineyard\
    \ manager. All the univariate risk maps were then combined \ninto a final risk\
    \ map using the OWA aggregator, which was again parametrized with the vineyard\
    \ \nmanager (see Section 2.3 Functionalities implemented in GeoFIS) (Step 3.3).\
    \ Finally, a segmentation \nalgorithm was applied to this last risk map to provide\
    \ within-field risk zones (Step 3.1). \n3.3.2. Application in GeoFIS \nThis section\
    \ will focus on the computation of the risk functions and on the zoning of the\
    \ resulting \nrisk map. For each layer of information (ECa, NDVI, Elevation),\
    \ risk functions can be defined within \nGeoFIS by implementing fuzzy rules as\
    \ displayed in Figure 10. Here, a semi trapezoidal function was \nused to model\
    \ the risk of having sub-optimal practices by solely relying on the ECa layer.\
    \ In this \ninterface, the form of the risk function can be changed along with\
    \ the associated fuzzy parameters, \ni.e., the kernel and support. Once the risk\
    \ functions have been set for all the layers of interest, all the \nrisks can\
    \ be aggregated with respect to the aforementioned expert rule(s). This aggregation\
    \ procedure \ncan be performed through the interfaces displayed in Figure 11 where\
    \ (i) the layers can be selected \nand the aggregation operator can be chosen\
    \ (OWA aggregator here) and, (ii) the parameters \nassociated to the OWA aggregator\
    \ can be stated. \n \nFigure 10. Implementation of the risk function associated\
    \ with the ECa information layer. \n \nFigure 11. Parametrization of the Ordered\
    \ Weighted Average (OWA) aggregator: (a) Selection of the\nlayers to be aggregated;\
    \ (b) setting of the OWA aggregator parameters. The weights for the minimum,\n\
    medium and maximum values of univariate risk are respectively 0.7, 0.2 and 0.1.\n\
    Agriculture 2018, 8, 73\n17 of 21\nAfter the aggregation procedure has been run,\
    \ practitioners end up with a continuous map of\nthe global risk of having sub-optimal\
    \ practices within the vineyard. To facilitate the interpretation of\nthe map\
    \ and the process of decision-making, the risk map can be zoned using the interface\
    \ displayed\nin Figure 12. Before zoning, users must (i) deﬁne the boundary of\
    \ the map, either by importing a\npredeﬁned boundary or by using a default convex\
    \ hull algorithm (that is proposed in GeoFIS) to\ngenerate a boundary and (ii)\
    \ set the neighborhood associated to each spatial observation so that zones\n\
    can be expanded using spatial neighbors. The zoning procedure can then be applied\
    \ to the OWA risk\nmap using the zoning algorithm implemented in GeoFIS [18].\
    \ Users can then display a risk map with\na number of zones that they consider\
    \ relevant.\nAgriculture 2018, 8, x FOR PEER REVIEW  \n17 of 21 \n \nFigure 11.\
    \ Parametrization of the Ordered Weighted Average (OWA) aggregator: (a) Selection\
    \ of the \nlayers to be aggregated; (b) setting of the OWA aggregator parameters.\
    \ The weights for the minimum, \nmedium and maximum values of univariate risk\
    \ are respectively 0.7, 0.2 and 0.1. \nAfter the aggregation procedure has been\
    \ run, practitioners end up with a continuous map of \nthe global risk of having\
    \ sub-optimal practices within the vineyard. To facilitate the interpretation\
    \ of \nthe map and the process of decision-making, the risk map can be zoned using\
    \ the interface displayed \nin Figure 12. Before zoning, users must (i) define\
    \ the boundary of the map, either by importing a \npredefined boundary or by using\
    \ a default convex hull algorithm (that is proposed in GeoFIS) to \ngenerate a\
    \ boundary and (ii) set the neighborhood associated to each spatial observation\
    \ so that zones \ncan be expanded using spatial neighbors. The zoning procedure\
    \ can then be applied to the OWA risk \nmap using the zoning algorithm implemented\
    \ in GeoFIS [18]. Users can then display a risk map with \na number of zones that\
    \ they consider relevant. \n \nFigure 12. Delimitation of within-field yield zones\
    \ of the risk of having sub-optimal management \npractices. (Map details described\
    \ in Figure 13). \n3.3.3. Results and Discussion \nThe map of the risk of arriving\
    \ at sub-optimal management practices using a combination of (i) \navailable information\
    \ and (ii) expert rules derived from local knowledge is displayed in Figure 13.\
    \ \nThis map shows five zones, three of which are relatively large, with specific\
    \ risk levels. The highest-\nrisk area (dark red) is located on the western part\
    \ of the vineyard and characterized by low ECa, high \nNDVI and high elevation\
    \ (Figure 13). In this part of the vineyard, it is likely that current management\
    \ \npractices are not well adapted as grape quality and quantity at harvest are\
    \ not optimized in this area \nand “nitrogen applications should be avoided; water\
    \ availability should be reduced by the \nintroduction of a cover crop; and Regulated\
    \ Deficit Irrigation strategies should held in order to \nmoderate shoot growth\
    \ and fertility” [35]. In order to simplify the presentation of this example,\
    \ only \nFigure 12. Delimitation of within-ﬁeld yield zones of the risk of having\
    \ sub-optimal management\npractices. (Map details described in Figure 13).\n3.3.3.\
    \ Results and Discussion\nThe map of the risk of arriving at sub-optimal management\
    \ practices using a combination of\n(i) available information and (ii) expert\
    \ rules derived from local knowledge is displayed in Figure 13.\nThis map shows\
    \ ﬁve zones, three of which are relatively large, with speciﬁc risk levels. The\
    \ highest-risk\narea (dark red) is located on the western part of the vineyard\
    \ and characterized by low ECa, high NDVI\nand high elevation (Figure 13). In\
    \ this part of the vineyard, it is likely that current management\npractices are\
    \ not well adapted as grape quality and quantity at harvest are not optimized\
    \ in this area\nand “nitrogen applications should be avoided; water availability\
    \ should be reduced by the introduction\nof a cover crop; and Regulated Deﬁcit\
    \ Irrigation strategies should held in order to moderate shoot\ngrowth and fertility”\
    \ [35]. In order to simplify the presentation of this example, only one rule has\n\
    been taken into account. It would have been possible to introduce additional rules\
    \ based on the work\npresented in [35].\nAgriculture 2018, 8, 73\n18 of 21\nIt\
    \ is interesting to note that the aggregation procedure though the OWA operator\
    \ using the NDVI,\nECa, and elevation layers (Figure 13) has resulted in a risk\
    \ map that is different from that which would\nhave been obtained by interpreting\
    \ each layer of information independently (Figure 14). For instance,\nif the ECa\
    \ layer had only been used to generate the risk map, the highest-risk area would\
    \ have covered\na much larger area of the vineyard.\nAgriculture 2018, 8, x FOR\
    \ PEER REVIEW  \n18 of 21 \n \none rule has been taken into account. It would\
    \ have been possible to introduce additional rules based \non the work presented\
    \ in [35].  \nIt is interesting to note that the aggregation procedure though\
    \ the OWA operator using the \nNDVI, ECa, and elevation layers (Figure 13) has\
    \ resulted in a risk map that is different from that which \nwould have been obtained\
    \ by interpreting each layer of information independently (Figure 14). For \n\
    instance, if the ECa layer had only been used to generate the risk map, the highest-risk\
    \ area would \nhave covered a much larger area of the vineyard.  \n \nFigure 13.\
    \ Aggregated risk zones of sub-optimal management practices derived using the\
    \ NDVI, ECa, \nand elevation layers together with local expert knowledge. \nThis\
    \ case study illustrates that the expertise of farm managers and advisors can\
    \ be incorporated \ninto a data-fusing algorithm to generate decision layers.\
    \ Indeed, GeoFIS enables users to incorporate \ntheir own expertise, i.e., though\
    \ the use of univariate risk functions/fuzzy rules, into the generation \nof risk\
    \ maps. The use of fuzzy rules to account for this expertise is of interest as\
    \ it makes it possible \nto avoid abrupt changes in risk and generates a more\
    \ gradual variation in potential risk (Figure 10). \nThe GeoFIS interface enables\
    \ users to calibrate the risk and aggregation functions empirically by \noffering\
    \ users the ability to test a calibration, visualize the resulting risk maps,\
    \ and possibly adjust it \nto their convenience. However, it must be stated that\
    \ this will require farmers and advisors to be \nsupported so that their expertise\
    \ can be translated correctly into the data aggregation algorithms.  \nThe calibration\
    \ of the OWA index presented in this case study (weight of 0.7 for the minimum\
    \ \nvalue of univariate risk, 0.2 for the median value, and 0.1 for the maximum\
    \ value) resulted from an \niterative calibration process lead by the vineyard\
    \ manager. This aggregation setting has strong \nsimilarities with the logical\
    \ operation “AND”, i.e., the resulting risk is high if the minimum value of \n\
    univariate risk is also high because it has the strongest weight. In other words,\
    \ all the univariate risks \nare high because the median and maximum values for\
    \ a univariate risk are necessarily higher than \nthe minimum value of the univariate\
    \ risk. Note that the real logical operation “AND” would be \nreproduced by using\
    \ the following set of weights (1;0;0). By changing these weights, practitioners\
    \ \nmight also be able to reproduce the logical operation “OR” (0;0;1) for which\
    \ the resulting risk is high \nas soon as the maximum value of a univariate risk\
    \ is high. It would also be possible to perform a \nsimple average of the different\
    \ univariate risks by using the same weights for each layer. \nFigure 13. Aggregated\
    \ risk zones of sub-optimal management practices derived using the NDVI, ECa,\n\
    and elevation layers together with local expert knowledge.\nAgriculture 2018,\
    \ 8, x FOR PEER REVIEW  \n19 of 21 \n \nFigure 14. Maps of risk zones of sub-optimal\
    \ management practices derived in the univariate space \nwith variate specific\
    \ local expert rules. ECa (left); NDVI (middle); and Elevation (right). \nFrom\
    \ a more general perspective, GeoFIS simplifies the processing of the three layers\
    \ of \ninformation as the entire process was done within a single software platform.\
    \ It can be compared to \nthe data processing in [35] in which data where cleaned\
    \ with Excel, interpolated with Vesper, \nanalyzed with Matlab and represented\
    \ with ArcGIS.  \n4. Conclusions \nThe increasing flow of precision agriculture\
    \ data requires the development of free and open \nsource processing software\
    \ to manage and make use of these data and promote precision agriculture \nadoption.\
    \ As such, GeoFIS has been specifically designed to facilitate the movement from\
    \ spatial data \nto spatial information and to spatial decision-making. The application\
    \ of GeoFIS on some example \ncase studies that agricultural professionals may\
    \ face when dealing with spatial data has \ndemonstrated the potential of this\
    \ software. GeoFIS is a released product however it is important to \nstate that\
    \ all the functionality currently introduced and implemented in GeoFIS are still\
    \ areas of active \ninvestigation by the scientific community. GeoFIS will be\
    \ updated when, and if, improved \nmethodologies become available. It is one of\
    \ the strengths of the GeoFIS platform that it is able to \nintegrate the latest\
    \ research developments to make sure that users are provided with the most up-to-\n\
    date, reliable and powerful processing algorithms.  \nFigure 14. Maps of risk\
    \ zones of sub-optimal management practices derived in the univariate space\n\
    with variate speciﬁc local expert rules. ECa (left); NDVI (middle); and Elevation\
    \ (right).\nThis case study illustrates that the expertise of farm managers and\
    \ advisors can be incorporated\ninto a data-fusing algorithm to generate decision\
    \ layers. Indeed, GeoFIS enables users to incorporate\ntheir own expertise, i.e.,\
    \ though the use of univariate risk functions/fuzzy rules, into the generation\n\
    of risk maps. The use of fuzzy rules to account for this expertise is of interest\
    \ as it makes it possible\nto avoid abrupt changes in risk and generates a more\
    \ gradual variation in potential risk (Figure 10).\nThe GeoFIS interface enables\
    \ users to calibrate the risk and aggregation functions empirically by\noffering\
    \ users the ability to test a calibration, visualize the resulting risk maps,\
    \ and possibly adjust\nit to their convenience. However, it must be stated that\
    \ this will require farmers and advisors to be\nsupported so that their expertise\
    \ can be translated correctly into the data aggregation algorithms.\nThe calibration\
    \ of the OWA index presented in this case study (weight of 0.7 for the minimum\n\
    value of univariate risk, 0.2 for the median value, and 0.1 for the maximum value)\
    \ resulted from\nAgriculture 2018, 8, 73\n19 of 21\nan iterative calibration process\
    \ lead by the vineyard manager. This aggregation setting has strong\nsimilarities\
    \ with the logical operation “AND”, i.e., the resulting risk is high if the minimum\
    \ value of\nunivariate risk is also high because it has the strongest weight.\
    \ In other words, all the univariate risks\nare high because the median and maximum\
    \ values for a univariate risk are necessarily higher than the\nminimum value\
    \ of the univariate risk. Note that the real logical operation “AND” would be\
    \ reproduced\nby using the following set of weights (1;0;0). By changing these\
    \ weights, practitioners might also be\nable to reproduce the logical operation\
    \ “OR” (0;0;1) for which the resulting risk is high as soon as the\nmaximum value\
    \ of a univariate risk is high. It would also be possible to perform a simple\
    \ average of\nthe different univariate risks by using the same weights for each\
    \ layer.\nFrom a more general perspective, GeoFIS simpliﬁes the processing of\
    \ the three layers of\ninformation as the entire process was done within a single\
    \ software platform. It can be compared\nto the data processing in [35] in which\
    \ data where cleaned with Excel, interpolated with Vesper,\nanalyzed with Matlab\
    \ and represented with ArcGIS.\n4. Conclusions\nThe increasing ﬂow of precision\
    \ agriculture data requires the development of free and open\nsource processing\
    \ software to manage and make use of these data and promote precision agriculture\n\
    adoption. As such, GeoFIS has been speciﬁcally designed to facilitate the movement\
    \ from spatial data\nto spatial information and to spatial decision-making. The\
    \ application of GeoFIS on some example\ncase studies that agricultural professionals\
    \ may face when dealing with spatial data has demonstrated\nthe potential of this\
    \ software. GeoFIS is a released product however it is important to state that\
    \ all the\nfunctionality currently introduced and implemented in GeoFIS are still\
    \ areas of active investigation\nby the scientiﬁc community. GeoFIS will be updated\
    \ when, and if, improved methodologies become\navailable. It is one of the strengths\
    \ of the GeoFIS platform that it is able to integrate the latest research\ndevelopments\
    \ to make sure that users are provided with the most up-to-date, reliable and\
    \ powerful\nprocessing algorithms.\nAs it is, GeoFIS is an excellent tool to promote\
    \ teaching in precision agriculture. Indeed, GeoFIS has\nalready been used within\
    \ many higher education institutions in France to teach researchers and\nprofessionals\
    \ how to process spatial data.\nThe user-friendly interface effectively facilitates\
    \ the\nunderstanding of some major precision agriculture concepts.\nThe analysis\
    \ of the three case studies has been an opportunity to also evaluate the limits\
    \ of the\ncurrent algorithms and to propose areas for future developments within\
    \ the software. For instance,\nthe data ﬁltering procedure focuses solely on global\
    \ outliers while spatial datasets may contain outliers\nmore deeply rooted within\
    \ the data and sometimes referred to as spatial outliers. A second example is\n\
    that the variography analysis is limited to single data layers while cross-variography\
    \ studies might\nbe relevant to evaluate the spatial relationships between multiple\
    \ layers of information. To foster the\nadoption of GeoFIS, the authors are more\
    \ than open to collaboration and are ready to integrate relevant\nalgorithms for\
    \ processing precision agriculture data.\nAnother possibility to promote the processing\
    \ of precision agriculture data could be to create\nlinks between GeoFIS and existing\
    \ GIS programs, such as QGIS that is an open-source GIS already\nwidely used by\
    \ many communities working on spatial data. There is a possibility to integrate\
    \ all the\nalgorithms of GeoFIS directly within this open-source GIS software\
    \ to beneﬁt from the display and\nprocessing algorithms already implemented in\
    \ QGIS. This would however require users to process their\nprecision agriculture\
    \ data in a more complex environment for which speciﬁc GIS skills are necessary.\n\
    Another option is to transform GeoFIS into a web-based service, rather than its\
    \ current download\nand desktop application structure, so that users would not\
    \ have to care about the R installation,\nJava updates and compatibility between\
    \ different operating systems.\nAgriculture 2018, 8, 73\n20 of 21\nAuthor Contributions:\
    \ J.-L.L. and S.G. developed the GeoFIS software; B.T., J.T., O.N., H.J. and S.G.\
    \ conceived\nand designed the experiments; J.L., C.L., and L.P. performed the\
    \ experiments and analyzed the data; all the\nauthors contributed to reagents/materials/analysis\
    \ tools; C.L. organized the writing of the paper.\nFunding: This research received\
    \ no external funding.\nConﬂicts of Interest: The authors declare no conﬂict of\
    \ interest.\nReferences\n1.\nOliver, M.A. Geostatistical Applications for Precision\
    \ Agriculture; Springer: London, UK, 2010; p. 295.\n2.\nPringle, M.J.; McBratney,\
    \ A.B.; Whelan, B.M.; Taylor, J.A. A preliminary approach to assessing the opportunity\n\
    for site-speciﬁc crop management in a ﬁeld, using a yield monitor. Agric. Syst.\
    \ 2003, 76, 273–292. [CrossRef]\n3.\nAcevedo-Opazo, C.; Tisseyre, B.; Guillaume,\
    \ S.; Ojeda, H. The potential of high resolution information to\ndeﬁne withinvineyard\
    \ zones related to vine water status. Precis. Agric. 2008, 9, 285–302. [CrossRef]\n\
    4.\nBramley, R.G.V. Understanding variability in winegrape production systems\
    \ 2. Within vineyard variation in\nquality over several vintages. Aust. J. Grape\
    \ Wine Res. 2005, 11, 33–45. [CrossRef]\n5.\nVerdugo-Vásquez, N.;\nAcevedo-Opazo,\
    \ C.;\nValdés-Gómez, H.;\nAraya-Alman, M.;\nIngram, B.;\nGarcía de Cortázar-Atauri,\
    \ I.; Tisseyre, B. Spatial variability of phenology in two irrigated grapevine\n\
    cultivar growing under semi-arid conditions. Precis. Agric. 2015, 17, 218–245.\
    \ [CrossRef]\n6.\nBaluja, J.; Diago, M.; Goovaerts, P.; Tardaguila, J. Assessment\
    \ of the spatial variability of anthocyanins in\ngrapes using a ﬂuorescence sensor:\
    \ Relationships with vine vigour and yield. Precis. Agric. 2012, 13, 457–472.\n\
    [CrossRef]\n7.\nDebuisson, S.; Germain, C.; Garcia, O.; Panigai, L.; Moncomble,\
    \ D.; Le Moigne, M.; Fadaili, E.M.; Evain, S.;\nCerovic, Z.G. Using Multiplex®\
    \ and Greenseeker™ to manage spatial variation of vine vigor in Champagne.\nIn\
    \ Proceedings of the 10th International Conference on Precision Agriculture, Denver,\
    \ Colorado, 18–21 July 2010.\n8.\nTaylor, J.; Acevedo-Opazo, C.; Ojeda, H.; Tisseyre,\
    \ B. Identiﬁcation and signiﬁcance of sources of spatial\nvariation in grapevine\
    \ water status. Aust. J. Vine Wine Res. 2010, 16, 218–226. [CrossRef]\n9.\nTaylor,\
    \ J.; McBratney, A.B.; Whelan, B. Establishing management classes for broadacre\
    \ agricultural\nproduction. Agron. J. 2007, 99, 1366–1376. [CrossRef]\n10.\nJeong,\
    \ J.S.; García-Moruno, L.; Hernández-Blanco, J. Integrating buildings into a rural\
    \ landscape using a\nmulti-criteria spatial decision analysis in GIS-enabled web\
    \ environment. Biosyst. Eng. 2012, 112, 82–92.\n[CrossRef]\n11.\nYalew, S.G.;\
    \ van Griensven, A.; van der Zaag, P. AgriSuit: A web-based GIS-MCDA framework\
    \ for\nagricultural land suitability assessment. Comput. Electron. Agric. 2016,\
    \ 128, 1–8. [CrossRef]\n12.\nLeroux, C.; Jones, H.; Clenet, A.; Dreux, B.; Becu,\
    \ M.; Tisseyre, B. A general method to ﬁlter out defective\nspatial observations\
    \ from yield mapping datasets. Precis. Agric. 2018. [CrossRef]\n13.\nSudduth,\
    \ K.; Drummond, S.T. Yield editor: Software for removing errors from crop yield\
    \ maps. Agron. J.\n2007, 99, 1471–1482. [CrossRef]\n14.\nHengl, T.; Heuvelink,\
    \ G.; Stein, A. A generic framework for spatial prediction of soil variables based\
    \ on\nregressionkriging. Geoderma 2004, 122, 75–93. [CrossRef]\n15.\nOliver, M.A.;\
    \ Webster, R. A tutorial guide to geostatistics: Computing and modelling variograms\
    \ and kriging.\nCatena 2014, 113, 56–69. [CrossRef]\n16.\nRobinson, T.P.; Metternicht,\
    \ G. Testing the performance of spatial interpolation techniques for mapping soil\n\
    properties. Comput. Electron. Agric. 2006, 50, 97–108. [CrossRef]\n17.\nCid-Garcia,\
    \ N.M.; Albornoz, V.; Rios-Solis, Y.A.; Ortega, R. Rectangular shape management\
    \ zone delineation\nusing integer linear programming. Comput. Electron. Agric.\
    \ 2013, 93, 1–9. [CrossRef]\n18.\nPedroso, M.; Taylor, J.; Tisseyre, B.; Charnomordic,\
    \ B.; Guillaume, S. A segmentation algorithm for the\ndelineation of management\
    \ zones. Comput. Electron. Agric. 2010, 70, 199–208. [CrossRef]\n19.\nBlackmore,\
    \ S.; Godwin, R.J.; Fountas, S. The analysis of spatial and temporal trends in\
    \ yield map data over\nsix years. Byosyst. Eng. 2003, 84, 455–466. [CrossRef]\n\
    20.\nLi, Y.; Shin, Z.; Li, F.; Li, H.-Y. Delineation of site-speciﬁc management\
    \ zones using fuzzy clustering analysis\nin a coastal saline land. Comput. Electron.\
    \ Agric. 2007, 56, 174–186. [CrossRef]\nAgriculture 2018, 8, 73\n21 of 21\n21.\n\
    Oliver, Y.M.; Robertson, M.J.; Wong, M.T.F. Integrating farmer knowledge, precision\
    \ agriculture tools, and\ncrop simulation modelling to evaluate management options\
    \ for poor-performing patches in cropping ﬁelds.\nEur. J. Agron. 2010, 32, 40–50.\
    \ [CrossRef]\n22.\nPichon, L.; Leroux, C.; Tisseyre, B. A systemic approach to\
    \ identify relevant information provided by UAV in\nprecision viticulture. Adv.\
    \ Anim. Biosci. 2017, 8, 823–827. [CrossRef]\n23.\nSchenatto, K.; de Souza, E.G.;\
    \ Bazzi, C.L.; Betzek, N.M.; Gavioli, A.; Beneduzzi, H.M. Use of the farmer’s\n\
    experience variable in the generation of management zones. Semina 2017, 38, 2305–2322.\n\
    24.\nLeroux, C.; Jones, H.; Clenet, A.; Tisseyre, B. A new approach for zoning\
    \ irregularly-spaced, within-ﬁeld\ndata. Comput. Electron. Agric. 2017, 141, 196–206.\
    \ [CrossRef]\n25.\nRoudier, P.; Tisseyre, B.; Poilvé, H.; Roger, J. Management\
    \ zone delineation using a modiﬁed watershed\nalgorithm. Precis. Agric. 2008,\
    \ 9, 233–250. [CrossRef]\n26.\nWhelan, B.M.; McBratney, A.B.; Minasny, B. Vesper—Spatial\
    \ prediction software for precision agriculture.\nIn ECPA 2001, Proceedings of\
    \ the 3rd European Conference on Precision Agriculture, Montpellier, France, 2001;\n\
    Grenier, G., Blackmore, S., Eds.; agro-Montpellier: Montpellier, France, 2001;\
    \ pp. 139–144.\n27.\nSudduth, K.A.; Drummond, S.T.; Myers, D.B. Yield Editor 2.0:\
    \ Software for Automated Removal of Yield\nMap Errors. In Proceedings of the 2012\
    \ ASABE Annual International Meeting, Dallas, TX, USA, 29 July–\n1 August 2012.\n\
    28.\nSimbahan, G.C.; Dobermann, A.; Ping, J.L. Screening yield monitor data improves\
    \ grain yield maps. Agron. J.\n2004, 96, 1091–1102. [CrossRef]\n29.\nKrishnan,\
    \ P.; Sharma, R.K.; Dass, A.; Kukreja, A.; Srivastav, R.; Singhal, R.J.; Bandyopadhyay,\
    \ K.K.; Lal, K.;\nManjaiah, K.M.; Chhokar, R.S.; et al. Web-based crop model:\
    \ Web InfoCrop—Wheat to simulate the growth\nand yield of wheat. Comput. Electron.\
    \ Agric. 2016, 127, 324–335. [CrossRef]\n30.\nGuillaume, S.; Charnomordic, B.;\
    \ Tisseyre, B.; Taylor, J. Soft computing-based decision support tools for\nspatial\
    \ data. Int. J. Comput. Intell. Syst. 2013, 6, 18–33. [CrossRef]\n31.\nTisseyre,\
    \ B.; McBratney, A. A technical opportunity index based on mathematical morphology\
    \ for site-speciﬁc\nmanagement: An application to viticulture. Precis. Agric.\
    \ 2008, 9, 101–113. [CrossRef]\n32.\nGuillaume, S.; Charnomordic, B.; Loisel,\
    \ P. Fuzzy partitions: A way to integrate expert knowledge into\ndistance calculations.\
    \ Inf. Sci. 2013, 245, 76–95. [CrossRef]\n33.\nYager, R.R. On ordered weighted\
    \ averaging aggregation operators in multicriteria decision-making.\nIEEE Trans.\
    \ Syst. Man Cybern. 1988, 18, 183–190. [CrossRef]\n34.\nLamour, J.; Naud, O.;\
    \ Lechaudel, M.; Tisseyre, B. Mapping properties of an asynchronous crop: The\
    \ example\nof time interval between ﬂowering and maturity of banana. Adv. Anim.\
    \ Biosci. 2017, 8, 481–486. [CrossRef]\n35.\nSantesteban, L.G.; Guillaume, S.;\
    \ Royo, J.B.; Tisseyre, B. Are precision agriculture tools and methods relevant\n\
    at the whole-vineyard scale? Precis. Agric. 2013, 14, 2–17. [CrossRef]\n© 2018\
    \ by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access\n\
    article distributed under the terms and conditions of the Creative Commons Attribution\n\
    (CC BY) license (http://creativecommons.org/licenses/by/4.0/).\n"
  inline_citation: '>'
  journal: Agriculture (Basel)
  limitations: '>'
  pdf_link: https://www.mdpi.com/2077-0472/8/6/73/pdf?version=1527659079
  publication_year: 2018
  relevance_evaluation: 'This research is relevant to the point you are making in
    your literature review because it addresses the need for easy-to-use, open-source
    software that can be used by farmers and advisors to process spatial data from
    precision agriculture. The authors evaluate the ability of GeoFIS to perform three
    common tasks: mapping spatial variability, evaluating the opportunity for site-specific
    management, and delineating within-field zones for variable rate applications.'
  relevance_score: 0.8
  relevance_score1: 0
  relevance_score2: 0
  title: 'GeoFIS: An Open Source, Decision-Support Tool for Precision Agriculture
    Data'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.3390/s19173796
  analysis: '>'
  apa_citation: 'Naranjo, P. G. V., Shojafar, M., Mostafaei, H., Pooranian, Z., &
    Baccarelli, E. (2017). P-SEP: A prolong stable election routing algorithm for
    energy-limited heterogeneous fog-supported wireless sensor networks. Journal of
    Supercomputing, 73(2), 733–755.'
  authors:
  - Uferah Shafi
  - Rafia Mumtaz
  - José García-Nieto
  - Syed Ali Hassan
  - Syed Ali Raza Zaidi
  - Naveed Iqbal
  citation_count: 314
  explanation: The paper is focused on the use of data compression, aggregation, and
    filtering techniques to reduce bandwidth requirements and improve transmission
    efficiency in the Internet of Things (IoT)-based systems used for precision agriculture,
    particularly in the context of real-time data transmission. The specific section
    of interest explores how these techniques can be applied to reduce the bandwidth
    requirements of real-time data transmission in agricultural monitoring systems.
  full_citation: '>'
  full_text: ">\nsensors\nReview\nPrecision Agriculture Techniques and Practices:\n\
    From Considerations to Applications\nUferah Shaﬁ 1\n, Raﬁa Mumtaz 1,*\n, José\
    \ García-Nieto 2\n, Syed Ali Hassan 1\n,\nSyed Ali Raza Zaidi 3 and Naveed Iqbal\
    \ 1\n1\nNational University of Science and Technology (NUST), School of Electrical\
    \ Engineering and Computer\nScience, Islamabad 44000, Pakistan\n2\nDepartment\
    \ of Languages and Computer Sciences, Ada Byron Research Building, University\
    \ of Málaga,\n29016 Málaga, Spain\n3\nSchool of Electronic and Electrical Engineering,\
    \ University of Leeds, Leeds LS2 9JT, UK\n*\nCorrespondence: raﬁa.mumtaz@seecs.edu.pk\n\
    Received: 14 July 2019; Accepted: 27 August 2019; Published: 2 September 2019\n\
    \x01\x02\x03\x01\x04\x05\x06\a\b\x01\n\x01\x02\x03\x04\x05\x06\a\nAbstract: Internet\
    \ of Things (IoT)-based automation of agricultural events can change the agriculture\n\
    sector from being static and manual to dynamic and smart, leading to enhanced\
    \ production with\nreduced human efforts. Precision Agriculture (PA) along with\
    \ Wireless Sensor Network (WSN) are the\nmain drivers of automation in the agriculture\
    \ domain. PA uses speciﬁc sensors and software to ensure\nthat the crops receive\
    \ exactly what they need to optimize productivity and sustainability. PA includes\n\
    retrieving real data about the conditions of soil, crops and weather from the\
    \ sensors deployed in the\nﬁelds. High-resolution images of crops are obtained\
    \ from satellite or air-borne platforms (manned\nor unmanned), which are further\
    \ processed to extract information used to provide future decisions.\nIn this\
    \ paper, a review of near and remote sensor networks in the agriculture domain\
    \ is presented\nalong with several considerations and challenges. This survey\
    \ includes wireless communication\ntechnologies, sensors, and wireless nodes used\
    \ to assess the environmental behaviour, the platforms\nused to obtain spectral\
    \ images of crops, the common vegetation indices used to analyse spectral\nimages\
    \ and applications of WSN in agriculture. As a proof of concept, we present a\
    \ case study\nshowing how WSN-based PA system can be implemented. We propose an\
    \ IoT-based smart solution\nfor crop health monitoring, which is comprised of\
    \ two modules. The ﬁrst module is a wireless sensor\nnetwork-based system to monitor\
    \ real-time crop health status. The second module uses a low altitude\nremote\
    \ sensing platform to obtain multi-spectral imagery, which is further processed\
    \ to classify\nhealthy and unhealthy crops. We also highlight the results obtained\
    \ using a case study and list the\nchallenges and future directions based on our\
    \ work.\nKeywords: smart agriculture; precision agriculture; vegetation index;\
    \ Internet of Things\n1. Introduction\nThe rapidly-growing human population has\
    \ increased food demands for human survival on\nthe Earth. Meeting the food requirements\
    \ with limited resources of the planet is a big challenge [1].\nSeveral state-of-the-art\
    \ technologies are being incorporated in the agriculture domain to enhance\nthe\
    \ productivity to cope with this challenge. Precision Agriculture (PA) is comprised\
    \ of near and\nremote sensing techniques using IoT sensors, which help to monitor\
    \ crop states at multiple growth\nlevels. PA involves the acquisition and processing\
    \ of a large amount of data related to crop health.\nMultiple parameters are involved\
    \ in plants health, including water level, temperature and others.\nPA enables\
    \ a farmer to know precisely what parameters are needed for healthy crop, where\
    \ these\nparameters are needed and in what amount at a particular instance of\
    \ time. This requires collecting\nSensors 2019, 19, 3796; doi:10.3390/s19173796\n\
    www.mdpi.com/journal/sensors\nSensors 2019, 19, 3796\n2 of 25\nmassive information\
    \ from different sources and different parts of the ﬁeld such as soil nutrients,\
    \ the\npresence of pests and weeds, chlorophyll content in plants and some weather\
    \ conditions. All collected\ninformation needs to be analysed to produce agronomic\
    \ recommendations. For instance, given the\ndevelopmental stage of plants, their\
    \ level of greenness (chlorophyll content) reveals the nutrients\nneeded. This\
    \ information is combined with the characteristics of the soil where the plant\
    \ is located\nalong with weather forecast. All collected information is further\
    \ used to determine how much of a\ncertain fertilizer should be applied to that\
    \ plant on the next day. The delivery of agronomic information\non the right time\
    \ to farmer and ensuring that he/she applies these recommendations are key to\n\
    enhancing the yields.\nThe foremost driver of PA is a WSN, which is a network\
    \ of multiple wireless nodes connected\ntogether to monitor the physical parameters\
    \ of environment. Each wireless node is comprised of a\nradio transceiver, a micro-controller,\
    \ sensor(s), an antenna, along with other circuitry that enables it\nto communicate\
    \ with some gateway to transmit information collected by the sensor(s) [2]. Sensors\n\
    measure the physical parameters and send the collected information to the controller,\
    \ which further\ntransmits this information to the cloud or a portable device.\
    \ The agriculture sector has multiple\nrequirements comprised of soil statistics,\
    \ crops’ nature, weather conditions, fertilizer types and water\nrequirements.\
    \ Crops have diverse requirements depending on different crops on the same land\
    \ and the\nsame plant on different lands with different weather conditions. Sensors\
    \ monitor the varying behaviour\nof these crop parameters. Due to rapid advancement\
    \ in WSN technologies, the size and the cost of\nsensors have reduced, which make\
    \ it feasible to implement them in many sectors of life including\nagriculture.\
    \ The most common sensors used in the agriculture domain that capture environmental\n\
    parameters related to crops [3] are listed in Table 1.\nIn general, a WSN consists\
    \ of one or more wireless nodes that are further connected with sensors.\nThese\
    \ nodes are tiny devices that are responsible for collecting data. Nodes are divided\
    \ into two types,\na source node that collects the data, and the other is sink\
    \ or gateway node, which receives data from the\nsource nodes. A sink node has\
    \ more computational power compared to a source node. However, there\nare energy,\
    \ memory, power, size, data rate and price constraints when choosing wireless\
    \ nodes. Table 2\nshows a comparison of wireless nodes along with their common\
    \ speciﬁcations [3]. Among all wireless\nnodes presented in Table 2, MICA2 is\
    \ considered to be more suitable as compared to others because of\nits large number\
    \ of expansion connectors, which makes it suitable to connect with several sensors.\n\
    Many applications using WSN have been proposed since the last decade to monitor\
    \ crops’ health\nremotely. In [4], a cyber-physical system was presented for monitoring\
    \ of a potato crop. Cyber physical\nsystems can be expressed as smart systems\
    \ that are comprised of software, hardware and physical\ncomponents, integrated\
    \ together to sense the varying states of the real world. The proposed system\n\
    consists of three layers: the ﬁrst layer is the physical layer, in which all sensory\
    \ data are collected;\nthe second layer is the network layer in which data are\
    \ transmitted to the cloud; the third layer is\nthe decision layer in which the\
    \ data are analysed and processed to make decisions according to the\nobservations.\n\
    There are several challenges in IoT-based systems due to exponential increasing\
    \ devices. As in\na typical IoT network, every node transmits data to the remote\
    \ cloud, which results in cloud\ncongestion, and the main challenges underlying\
    \ the IOT-based system are latency with minimum\npower requirements, better usage\
    \ of bandwidth and intermittent Internet connectivity. Fog computing\nand edge\
    \ computing are the state-of-the-art techniques to overcome these issues; which\
    \ reduce the\ncomputational burden of cloud. The main goal of fog computing is\
    \ to conserve energy and bandwidth,\nwhich helps to increase the quality of service\
    \ to the end users. In [5], an energy-efﬁcient architecture of\nthe Fog of Everything\
    \ was presented, which was comprised of six layers. The ﬁrst layer was an Internet\n\
    Of Everything (IOE) layer, where things (could be ﬁxed, mobile or nomadic) functioned\
    \ under multiple\nspatially-distributed clusters. The second was a wireless access\
    \ network that supported Thing to Fog\n(T2F) and Fog to Thing (F2T) communication\
    \ over the wireless channel. In the third layer, the connected\nfog nodes behaved\
    \ such as a virtualized cluster. There was an inter-fog backbone in the fourth\
    \ layer,\nSensors 2019, 19, 3796\n3 of 25\nwhich was responsible for connectivity\
    \ among fog nodes. The next layer was the virtualization layer,\nwhich provided\
    \ each connected thing with the ability to augment its limited resource set, exploiting\n\
    the computation capability at the virtual clone. In the last layer, there was\
    \ an overlay inter-clone\nvirtual network that empowered Peer to Peer (P2P) communication.\
    \ Then, a protocol stack for FOE\nwas presented, which was further tested by creating\
    \ a small prototype named as V-FOE and simulated\non the iFogsim toolkit. The\
    \ results provided strong evidence for the effectiveness of the proposed\nframework\
    \ and more energy efﬁciency with reduced failure rate and delay.\nTable 1. Wireless\
    \ nodes used in the agriculture domain.\nSr #\nSensor Name\nParameters Captured\n\
    1\nECH2O soil moisture sensor\nSoil Temperature, Soil Moisture, Conductivity\n\
    2\nHydra probe II soil sensor\nSoil Temperature, Salinity level, Soil Moisture,\n\
    Conductivity\n3\nMP406 Soil moisture sensor\nSoil Temperature, Soil Moisture\n\
    4\nEC sensor (EC250)\nSoil Temperature, Salinity level, Soil Moisture,\nConductivity\n\
    5\nPogo portable soil sensor\nSoil Temperature, Soil Moisture\n6\n107-L temperature\
    \ Sensor (BetaTherm 100K6A1B\nPlant Temperature\nThermistor)\n7\n237 leaf wetness\
    \ sensor\nPlant Moisture, Plant Wetness, Plant\nTemperature\n8\nSenseH2TM hydrogen\
    \ sensor\nHydrogen, Plant Wetness, CO2, Plant\nTemperature\n9\nField scout CM1000TM\n\
    Photosynthesis\n10\nYSI 6025 chlorophyll sensor\nPhotosynthesis\n11\nLW100, leaf\
    \ wetness sensor\nPlant Moisture, Plant Wetness, Plant\nTemperature\n12\nTT4 multi-sensor\
    \ thermocouple\nPlant Moisture, Plant Temperature\n13\nTPS-2 portable photosynthesis\n\
    Photosynthesis, Plant Moisture, CO2,\n14\nLT-2 M (leaf temperature sensor)\nPlant\
    \ Temperature\n15\nPTM-48A photosynthesis monitor\nPhotosynthesis, Plant Moisture,\
    \ Plant Wetness,\nCO2, Plant Temperature\n16\nCl-340 hand-held photosynthesis\n\
    Photosynthesis, Plant Moisture, Plant Wetness,\nCO2, Plant Temperature, Hydrogen\
    \ level in\nPlant\n17\nCM-100 Compact Weather Sensor\nAir Temperature, Air Humidity,\
    \ Wind Speed,\nAir Pressure\n18\nHMP45C (Vaisala’s HUMICAP R⃝ H-chip)\nAir Temperature,\
    \ Air Humidity, Air Pressure\n19\nMet Station One (MSO)\nAir Humidity, Air Temperature,\
    \ Wind Speed,\nAir Pressure\n20\nXFAM-115KPASR\nAir Temperature, Air Pressure,\
    \ Air Humidity\n21\nSHT71, SHT75 (Humidity and temperature\nsensor)\nHumidity\
    \ and Temperature Sensor\n22\n107-L Temperature Sensor (BetaTherm 100K6A1B\nthermistor)\n\
    Air Temperature\n23\nCl-340 hand-held photosynthesis\nAir Temperature, Air Humidity\n\
    The energy efﬁciency is the most serious consideration while developing any fog\
    \ architecture.\nIn [6], an energy-efﬁcient protocol for a fog-supported wireless\
    \ sensor network was presented, which\nmaximized the lifetime of the network by\
    \ uniformly distributing the energy among connected nodes.\nThe performance of\
    \ the proposed algorithm was compared with the existing state-of-the-art algorithms\n\
    Sensors 2019, 19, 3796\n4 of 25\nin MATLAB. The results showed that the proposed\
    \ algorithm was highly energy efﬁcient with a\nprolonged network lifetime.\nRegardless\
    \ of all the advancements in the IoT domain, the adoption of PA has been limited\
    \ to\nsome developed countries. Because of the lack of resources, remote sensing-based\
    \ techniques to\nmonitor crop health are not common in under-developed countries\
    \ such as Pakistan, which results in\na loss of yield. Pakistan is an agricultural\
    \ country due to is large arable land and climatic variations,\nwhich make it\
    \ suitable to cultivate multiple types of crops. Despite all these natural resources,\
    \ Pakistan\nis still unable to produce massive yields [7]. The main reason behind\
    \ the low production is traditional\nfarming practices, which are used for crop\
    \ health monitoring and yield estimation. These techniques\nare completely based\
    \ on farmer’s intuition and experience. Farmers visit the ﬁelds in order to monitor\n\
    the crop, which is very laborious and quite challenging in the case of large arable\
    \ land. In this case, the\narea under insect/pest attack is inaccurately measured,\
    \ which can result in over spraying of insecticide\nand pesticide, which adversely\
    \ affects the nutrition in crops.\nKeeping in mind all these issues, our motivation\
    \ is to provide the industry and research\ncommunities with a survey of technologies,\
    \ metrics and current practices concerning communication\ndevices, sensors and\
    \ platforms used to monitor and analyse multiple sources of data (spectral images,\n\
    IoT, etc.) used in environmental and agriculture applications. As the main contribution,\
    \ we generated\na technological taxonomy for PA, which was driven by an IoT-based\
    \ architecture to monitor the crops’\nhealth. The developed system had two modules\
    \ including wireless sensor network-based crop heath\nmonitoring in which multiple\
    \ sensors were used to get the real-time heath status of crop; the other\none\
    \ was NDVI-based analysis of spectra images captured by a drone to assess the\
    \ chlorophyll content,\nwhich was further used to monitor the health of the crop.\n\
    The rest of the paper is organized as follows: Section 2 presents the most common\
    \ wireless\ncommunication technologies used in the agriculture domain; Section\
    \ 3 explains the spectral\nimage-based remote sensing techniques, platforms and\
    \ vegetation indices; Section 4 describes remote\nsensing applications in the\
    \ agriculture sector; Section 5 presents a case study on IoT-based and\nUAV-based\
    \ PA; Section 6 explains the experiments and results; challenges are discussed\
    \ in Section 7;\nand conclusions and future directions are presented in Section\
    \ 8.\nTable 2. Common wireless nodes used in the agriculture domain.\nSr #\nWN1\n\
    MC2\nExpansion\nConnector\nAvailable Sensors\nData Rate\n1\nMICA2DOT\nATmega128L\n\
    19 Pins\nGPS, Light, Humidity, Barometric Pressure,\nTemperature, Accelerometer,\
    \ Acoustic, RH\n38.4 K Baud\n2\nImote2\nMarvell/XScalePXA271\n40 Pins and 20 Pins\n\
    Light, Temperature, Humidity, Accelerometer\n250 Kbps\n3\nIRIS\nATmega128L\n51\
    \ Pins\nLight, Barometric Pressure, RH, Acoustic,\nAcceleration/ Seismic, Magnetic\
    \ and Video\n250 Kbps\n4\nMICAz\nATmega128L\n51 Pins\nLight, Humidity, Temperature,\
    \ Barometric\nPressure, GPS, RH, Accelerometer, Acoustic, Video\nSensor, Sounder,\
    \ Magnetometer, Microphone\n250 Kbps\n5\nTelosB\nTIMSP430\n6 Pins and 10 Pins\n\
    Light, Temperature, Humidity\n250 Kbps\n6\nCricket\nATmega128L\n51 Pins\nAccelerometer,\
    \ Light, Temperature, Humidity,\nGPS, RH, Acoustic, Barometric Pressure,\nUltrasonic,\
    \ Video Sensor, Microphone,\nMagnetometer, Sounder\n38.4 K Baud\n7\nMICA2\nATmega128L\n\
    51 Pin\nTemperature, Light, Humidity, Accelerometer,\nGPS, Barometric Pressure,\
    \ RH, Acoustic, Sounder,\nVideo, Magnetometer\n38.4 K Baud\nWN1: wireless node,\
    \ MC2: Micro-Controller.\n2. Wireless Communication Technologies\nVarious communication\
    \ protocols have been introduced in the last few decades due to the rapid\nincrease\
    \ in IoT devices and WSN technologies. Each protocol has its own speciﬁcations\
    \ depending on\nthe bandwidth, number of free channels, data rate, battery timing,\
    \ price and other factors [8]. The most\ncommonly-used protocols for wireless\
    \ communication in IoT-based applications in agriculture are:\nSensors 2019, 19,\
    \ 3796\n5 of 25\n2.1. Cellular\nCellular technology is most suitable for applications\
    \ that require an extraordinary data rate.\nIt can utilize GSM, 3G and 4G cellular\
    \ communication capabilities by providing reliable high-speed\nconnectivity to\
    \ the Internet, requiring higher power consumption.\nIt requires infrastructure\
    \ to\nbe deployed and operation cost and back up staff for it with a centralized\
    \ managed authority.\n4G cellular technology requires more battery power, but\
    \ cellular technology is a good option in\nunderground wireless sensor networks,\
    \ such as security systems in smart home projects and agriculture\napplications\
    \ [9]. A smart irrigation systems was presented in [10], in which several soil\
    \ moisture\nsensors were deployed in the ﬁeld in the ZigBee mesh network. The\
    \ reading captured from the ﬁelds\nwere transmitted over the cloud using the cellular\
    \ 4G LTE network.\n2.2. 6LoWPAN\n6LoWPAN is an IP-based communication protocol,\
    \ which was the ﬁrst protocol used for IoT\ncommunication. 6LoWPAN is also low\
    \ cost because of the low bandwidth and low power consumption.\n6LoWPAN supports\
    \ multiple topologies such as star and mesh topologies. To handle interoperability\n\
    between IPv6 and IEEE 802.15.4, there is an adaptation layer between the network\
    \ layer and the\nMAC layer [8]. The applications for 6LoWPAN are monitoring the\
    \ health equipment, environment\nmonitoring and in security and home automation\
    \ systems. In [11], a 6LoWPAN-enabled wireless sensor\nnetwork was presented to\
    \ monitor the soil properties of crops. The 6LoWPAN system architecture\nfor precision\
    \ agriculture application was discussed in [12] where the performance evaluation\
    \ of this\nprotocol was discussed with several baud rates and power constraints.\n\
    2.3. ZigBee\nZigBee is a wireless communication protocol widely used in precision\
    \ agriculture to monitor\nenvironmental conditions related to crops’ health [13].\
    \ It is based on the wireless 802.15.4 standard.\nBasically, it was developed\
    \ for personal area networks by the ZigBee alliance [8]. It has a ﬂexible\nnetwork\
    \ structure, long battery life, supports mesh, star and tree topology with multi-hop\
    \ data\ntransmission, is easily installed and supports large nodes. It has a short\
    \ range with limited data speed\nand is less secure compared to Wi-Fi-based systems.\
    \ ZigBee is very common in smart agriculture\napplications such as smart green\
    \ houses and smart irrigation systems [14]. In [15], a smart irrigation\nsystem\
    \ was presented based on the ZigBee communication protocol. This system consisted\
    \ of two\nnodes, i.e., a sensor node and an actuator node. The sensor node was\
    \ comprised of soil moisture\nsensors, which monitored the water level in the\
    \ soil. The actuator module was responsible for taking\nactions according to the\
    \ water level of the soil. All communication was carried out by means of\nZigBee\
    \ protocol.\n2.4. BLE\nBLE is as famous as the Bluetooth smart technology, which\
    \ is a suitable protocol for IoT\napplications including agriculture [16]. It\
    \ is particularly designed for low bandwidth, low latency and\nshort range for\
    \ IoT applications. The main advantages of BLE over typical Bluetooth include\
    \ lower\nsetup time, lower power consumption and unlimited support for nodes in\
    \ a star topology. It has a\nvery limited range of 10 meters. However, the drawbacks\
    \ are that it can only provide communication\nbetween two devices, it presents\
    \ low security, and it can lose connection during communication. In [17],\na BLE-based\
    \ infrastructure was presented to collect the sensors’ data. The proposed system\
    \ utilized a\nsmart phone to collect the data of sensors using BLE, where sensors\
    \ were deployed in the plants, i.e.,\nsoil moisture sensors and soil temperature\
    \ sensor.\nSensors 2019, 19, 3796\n6 of 25\n2.5. RFID\nRFID systems consist of\
    \ a reader and a transponder, which have a very small radio frequency,\ncalled\
    \ the RF tag. This tag is programmed electronically with distinctive information\
    \ that has a reading\ncharacteristic. RFID has two technologies for the tag system\
    \ the ﬁrst is the active reader tag system,\nand the other is the passive reader\
    \ tag. Active reader tag systems are more expensive, as they utilize\nmore battery\
    \ power and use high frequencies. However, passive reader tag systems are low\
    \ powered.\nSome IoT applications using RFID include smart shopping, healthcare,\
    \ national security and smart\nagriculture applications. An IoT-based smart irrigation\
    \ system based on RFID was presented in [18].\nThe system was comprised of soil\
    \ moisture and soil temperature sensors along with a water control\nsystem, so\
    \ it collected the reading of the sensors and sent these readings to the cloud\
    \ using RFID\ncommunication protocols, where the user controlled a water pump\
    \ based on the water level of the soil.\n2.6. Wi-Fi\nWi-Fi is the most common\
    \ communication protocol that enables devices to communicate over\na wireless\
    \ signal. Wi-Fi provides Wireless Local Area Network (WLAN) connectivity to millions\
    \ of\nlocations, i.e., homes, ofﬁces and public locations such as cafes, hotels\
    \ and airports with high speed.\nThe Wi-Fi protocol supports IEEE 802.11, 802.11a,\
    \ 802.11b, 802.11g and 802.11n. Wi-Fi is widely used\nin IoT-based applications\
    \ including agriculture systems, i.e., smart irrigation, crop health monitoring\n\
    and greenhouses. In [19], an infrastructure was presented to monitor environmental\
    \ parameters\ninside the greenhouse such as temperature, light intensity and soil\
    \ moisture level. This platform\nwas comprised of sensors that collected the data\
    \ related to the environmental variation and sent to\nthe cloud using Wi-Fi. Similarly,\
    \ another smart agriculture system based on Wi-Fi communication\nprotocols was\
    \ presented in [20]. This last one consisted of a Raspberry Pi connected with\
    \ multiple\nsensors, which collected the data. The collected data were further\
    \ transmitted to the cloud using Wi-Fi\ncommunication protocols.\n2.7. LoRaWAN\n\
    LoRaWAN operates on the LoRa network. LoRaWAN deﬁnes the system architecture and\n\
    communication protocol of the network, while the physical layer of LoRa enables\
    \ the link for\nlong-range communication. LoRaWAN manages the frequencies in communication,\
    \ data rate and\npower consumption for all devices. LoRaWAN is common in agricultural\
    \ applications because of\nits large coverage area and low power consumption [21].\
    \ In [14], a smart irrigation system based on\nLoRaWAN was presented. Table 3\
    \ shows the comparison of all mentioned wireless communication\nprotocols [8].\
    \ Among all wireless communication technologies, 6LoWPAN and ZigBee are considered\n\
    to be more suitable for PA application because both are based on mesh networking,\
    \ which makes them\nsuitable to cover large area.\nTable 3. Wireless communication\
    \ protocols used in Precision Agriculture (PA).\nCommunication Protocols\nData\
    \ Rate\nTopology\nStandard\nPhysical Range\nPower\n6LoWPAN\n0.3–50 Kb/s\nStar,\
    \ Mesh\nIEEE 802.15.4\n2–5 km urban,\n15 km suburban\nLow\nZigBee\n250 Kb/s\n\
    Star, Mesh Cluster\nIEEE 802.15.4\n10–100 m\nLow\nBluetooth\n1–2 Mb/s\nStar, Bus\n\
    IEEE 802.15.1\n30 m\nLow\nRFID\n50 tags/s\nP2P\nRFID\n10–20 cm\nUltra low\nLoRa\
    \ WaAN\n27–50 Kb/s\nP2P, Star\nIEEE 802.11ah\n5–10 km\nVery low\nWi-Fi\n1–54 Mb/s\n\
    Star\nIEEE 802.11\n50 m\nMedium\nSensors 2019, 19, 3796\n7 of 25\n3. Spectral\
    \ Image-Based Remote Sensing\nRemote sensing has been widely used in PA to monitor\
    \ crops’ health for the last two decades.\nRemote sensing is a phenomenon in which\
    \ physical conditions of the Earth are observed remotely by\ncalculating the emitted\
    \ and reﬂected radiation from some distance. There are special cameras that\n\
    are used to capture images for further analysis to ﬁnd the characteristics of\
    \ a speciﬁc area. Multiple\nplatforms are used to mount these cameras that capture\
    \ images of the objects.\n3.1. Spectral Image Platforms\nRemote sensing platform\
    \ considerations for spectral images are airborne-based, satellite-based\nand\
    \ Unmanned Aerial Vehicle (UAV)-based [22]. Each platform has its own coverage\
    \ range, which\nis determined by three factors: (i) Ground Sampling Distance (GSD),\
    \ which is computed in terms of\nspatial resolution, (ii) data collection rate\
    \ or frequency and (iii) average distance between the object\nand sensor. Apart\
    \ from coverage range, several factors [23] affect the performance of platforms,\n\
    as mentioned in Table 4.\nTable 4. Key differences between spectral image platforms.\n\
    Applicability Aspect\nAirborne\nUAV\nSatellite\nObservation Area\nRegional\nLocal\n\
    Worldwide\nGround Coverage\n1 km (Medium)\n100 m (Small)\n10 km (Large)\nField\
    \ of View\nWider\nWide\nNarrow\nGSD (Spatial Resolution)\n5–25 cm\n10–5 cm\n0.30–300\
    \ m\nDeployability\nComplex\nEasy\nDifﬁcult\nSpatial Accuracy\n1–25 cm\n5–10 cm\n\
    1–3 m\nRepeat Time\nHour(s)\nMinute(s)\nDay(s)\nOperational Risk\nHigh\nLow\n\
    Moderate\n3.1.1. Satellite-Based Platforms\nSpace-borne platforms for remote sensing\
    \ are considered to be the most stable platforms among\nall others. These platforms\
    \ consist of satellites, rockets and space shuttles. Space borne platforms are\n\
    categorized based on the orbits and timing. The advantages of satellite-based\
    \ remote sensing include\nhigh spatial resolution, which makes it promising to\
    \ extract extensive time-series data. The images\nobtained by satellite platforms\
    \ cover large area and are stable without noise, which is normally induced\ndue\
    \ to interference while image capturing. However, the main problem with satellite-based\
    \ platforms\nis their high cost in the case of high spatial resolution images.\
    \ The second problem is their strictly ﬁxed\ntime schedule, so data cannot be\
    \ collected at critical timings. The re-visitation times vary from twice\nin one\
    \ day to 16 days, depending on the orbit of the satellite. The other big problem\
    \ is that satellite\nplatforms are highly sensitive to weather conditions, so\
    \ if the weather is cloudy, the captured image will\nhave less detailed information.\
    \ Table 5 shows the main types of satellites with their speciﬁcations [22].\n\
    Among all satellite platforms presented in Table 5, some satellite data are freely\
    \ available,\nwhile others provide a commercial solution. The commercial solutions\
    \ such as Pleiades-1 provide\nimages with a high resolution and a revisit time\
    \ of one day. QuickBird, Landsat-8 and Sentinel are\nfrequently-used satellite\
    \ platforms used to obtain hyperspectral imagery. QuickBird was launched\nin 2001\
    \ by USA. The Panchromatic (PAN) and four Multi-Spectral (MS) imagery sensors\
    \ are used in\nQuickBird with a GSD of 0.7 × 0.7–2.6 × 2.6 m with a revisit time\
    \ 1–3.5 days. QuickBird provides a\nsmall revisit time, but it is a commercial\
    \ solution. In contrast to QuickBird, Landsat-8 and Sentinel\nprovide free solutions.\
    \ Landsat-8 was launched in 2013 by the USA. Landsat-8 provides a GSD of\n16 days\
    \ with PAN and 11-MS imagery sensors. Though revisit time of Landsat-8 is much\
    \ higher\ncompared to QuickBird, but it provides images with 11 different multi-spectral\
    \ bands.\nSentinel is another broadly-used satellite launched by the EU. It currently\
    \ has three missions,\ni.e., Sentinel-1, Sentinel-2 and Sentinel-3. These missions\
    \ provide images with 21 MS bands with\nSensors 2019, 19, 3796\n8 of 25\nrevisit\
    \ times of 5–10 days depending on which Sentinel mission is used. However, Sentinel-2\
    \ is a\ncommonly-used platform in precision agriculture as it provides data freely\
    \ at a 10-m spatial resolution\nand covers a swath width of 290 km. By combining\
    \ Sentinel-2A and Sentinel-2B, the revisit time is\nfurther reduced to ﬁve days,\
    \ which helps in change detection. The complete details of all satellite\nplatforms\
    \ with their speciﬁcations are listed in Table 5, where other platforms such as\
    \ SAT, MODIS\nand WordView are also considered.\nTable 5. Satellite platforms\
    \ for RS.\nName\nLaunch\nSensor\nCountry\nSwath\nWidth (km)\nGSD 1 Range (m)\n\
    Revisit Time (day)\nRapidEye\n2008\n5 MS2\nGermany\n77\n6.5 × 6.5\n1–5.5\nQuickBird-2\n\
    2001\nPAN3\nUSA\n16.8–18\n0.7 × 0.7\n1–3.5\n4 MS2\n2.6 × 2.6\nPleiades 1\n2011\n\
    PAN3\nFrance\n20\n0.5 × 0.5\n1\n2012\n4 MS2\n2 × 2\nSentinel-1\n2014\nC-band\n\
    EU\n80\n5 × 5\n12\n2016\nSAR6\n250\n5 × 20\n6 (dual)\n400\n25 × 40\nWorldView-3\n\
    2014\nPAN3, 8 MS2, 8 MS2\nUSA\n13.1\n0.3 × 0.3\n1–4.5\n(SWIR4), 12 MS2\n1.2 ×\
    \ 1.2\n3.7 × 3.7\nLandsat-8\n2013\nPAN3, 11 MS2\nUSA\n185\n15 × 15\n16\n30 × 30\n\
    Sentinel-2\n2015\n13 MS2\nEU\n290\n10 × 10\n10\n20 × 20\n2016\n60 × 60\n5 (dual)\n\
    EnMap\n2017\n232 HSI5\nGermany\n30\n30 × 30\n4\nICESat\n2003\n2 HSI5\nUSA\nN/A\n\
    70\n8\n(footprint)\nTanDEM-X\n2007\nX-band\nGermany\n5 × 10\n1 × 1\n11\nSAR6\n\
    1500 × 30\n3 × 3\n1500 × 100\n16 × 16\nSkySat\n2013\nPAN3\nUSA\n2 × 1\n1.1 × 1.1\n\
    0.5 (2015)\nVideo\n2014\nPAN3\n8\n0.9 × 0.9\n0.12 (2017)\n2015\n4 MS2\n2 × 2\n\
    ICESat-2\n2018\n1 HSI5\nUSA\nN/A\n10\nN/A\n(9-beam)\n(footprint)\nSentinel-3\n\
    2015\n21 MS2\nEU\n1270\n300 × 300\n0.25\n2017\n11 MS2\n1420\n500 × 500\n(IR)\n\
    750 (nadir)\n1000 × 1000\nRADARSAT-2 2007\nC-band\nCanada\n20\n3 × 3\n24 (orbit\
    \ repetition)\nSAR6\n500\n100 × 100\nSPOT 6\n2012\nPAN3\nFrance\n60\n1.5 × 1.5\n\
    1–5\nSPOT 7\n2014\n4 MS2\n6 × 6\nTerraSAR-X\n2007\nX-band\nGermany\n5 × 10\n1\
    \ × 1\n11\nSAR6\n1500 × 100\n16 × 16\nDMC-3\n2015\nPAN3\nU.K.\n23\n1 × 1\n1\n\
    4 MS2\n4 × 4\nGSD1: Ground Sampling Rate, MS2: Multi-Spectral, PAN3: Panchromatic,\
    \ SWIR4: Short Wave Infrared, HSI5:\nHyperspectral Imagery, SAR6: Synthetic Aperture\
    \ Radar\n3.1.2. Airborne-Based Platforms\nAirborne platform are ﬂexible compared\
    \ to satellite platforms, but still are expensive. The revisit\ntime is in human\
    \ control, which can be changed any time. The coverage area by this platform is\n\
    much smaller than satellite-based ones, but relatively greater than the UAV platforms.\
    \ Some common\nairborne platforms used for remote sensing [22] are given in Table\
    \ 6.\nSensors 2019, 19, 3796\n9 of 25\nTable 6. Airborne/aircraft platforms for\
    \ RS.\nAircraft Type\nTypical Models\nRS Sensors\nMax Flying Height (ft)\nFixed\
    \ wing (jet)\nLearJet 35A\nInSAR,\n45,000\nCamera,\nGeoSAR\nFixed wing (propeller\
    \ engine)\nCessna 402\nCamera\n26,900\nCommander 690\nLiDAR\n19,400\nCessna 208\n\
    Camera\nLiDAR\n25,000\nCessna 206\nCamera\nDHC-6 Twin\nCamera\n15,700\nOtter 300\n\
    LIDAR\n25,000\nDiamond\nCamera\nDA42\nLiDAR\n18,000\nPilatus PC-6\nCamera\nPorter\n\
    Camera\n25,000\nPiper Navajo\nLiDAR\n26,000\nPartenavia\nCamera\nP.68\nLiDAR\n\
    19,200\nVulcanair P68\nCamera\nObserver\nCamera\n18,000\nGyroplan\nAutoGyro\n\
    LiDAR\n10,000\nCavalon\nCamera\nHelicopter\nEurocopter\nLiDAR\n15,000\nAS350\n\
    Camera\nRobinson R44\nLiDAR\n14,000\nCamera\nBell 206\nLiDAR\n13,000\nCamera\n\
    Schweizer\nLiDAR5\n13,000\nCamera\n3.1.3. UAV-Based Platforms\nUAV platforms are\
    \ a vibrant alternative to satellite and airborne, which are quite ﬂexible and\
    \ cost\neffective. A typical UAV platform consists of a communication and navigation\
    \ system that incorporates\na set of sensors mounted on it. Among UAV platforms,\
    \ there are mainly ﬁxed-wing platforms. and\nmultirotor options are available.\
    \ The ﬂying time is based on the payload weight. In general, a longer\nﬂying time\
    \ is achieved by ﬁxed-wing systems, which demands lighter weight payloads. For\
    \ example,\nhigh-deﬁnition cameras weighing less than 300 grams as the payload\
    \ of a ﬁxed-wing UAV allow it to ﬂy\nfor around two hours using currently available\
    \ battery power [24]. On the contrary, battery-powered\nmultirotor UAV with higher\
    \ payload capacity have a reduced ﬂying time, i.e., around 15–25 min.\nTable 7\
    \ shows UAV platforms commonly used in the agriculture domain and concretely to\
    \ monitor\nthe health of crops remotely [22]. Among these platforms, DJI/Phantom-2\
    \ is a more suitable choice\nfor intermediate agricultural land because of its\
    \ low cost and ease of use. The other advantage of this\nplatform is that it provides\
    \ support for mounting multiple cameras, which helps to monitor the crop in\n\
    multiple electro-magnetic bands. The American Aerospace/RS-16 is also an option\
    \ because of its ﬂight\ntime and large are coverage, but due to its high cost,\
    \ this platform is not common.\nIn [25], the ESAFLY A2500_WH helicopter was used\
    \ to implement the platform of the UAV\nwith Tetra cam ADC Micro as the camera\
    \ to capture hyper-spectral images of two different types of\ncultivation, i.e.,\
    \ vineyard and tomato. The images captured by the UAV platform are very high in\n\
    resolution, so more information can be extracted as compared to satellite images.\
    \ To assess the health\nof a crop, three types of Vegetation Index (VI) maps have\
    \ been computed.\nSensors 2019, 19, 3796\n10 of 25\nTable 7. UAV platforms for\
    \ RS.\nWeight (kg)\nAircraft Power/Type\nManufacturer/Model\nFlying Time (min)\n\
    Flying Speed (m/s)\nRS Sensors\n0.7\nFixed-wing/electric\nsenseFly/eBee RTK\n\
    40\n11–25\nCamera\n6.1\nFixed-wing/electric\nAeroVironment/Puma AE\n210\n23\n\
    Camera\n6.0\nQuadro copter/electric\nMicrodrones/MD4-1000\n90\n12\nCamera/LiDAR\n\
    4.6–6.6\nHexacopter/electric\nAibotix/Aibot X6\n30\n14\nCamera\n5\nFixed-wing/electric\n\
    Trigger\nComposites/Pteryx\n120\n12.5–15\nCamera\n1.3\nQuadrocopter/electric\n\
    DJI/Phantom 2\n25\n15\nCamera\n2.5\nFixed-wing/electric\nTrimble/UX5\n50\n22\n\
    Camera\n2.7\nFixed-wing/electric\nTopcon/SIRIUS PRO\n50\n18\nCamera\n5.1–5.8\n\
    Fixed-wing/electric\nHawkeye\nUAV/AeroHawk\n90\n16.5–19.5\nCamera\n6.9–9.5\nHexacopter/electric\n\
    TRGS/Li-AIR\n15\n8\nLiDAR\n9.5\nOctocopter/electric\nAltus UAS/Delta X8\n10–14\n\
    12\nCamera/LiDAR\n25\nOctocopter/electric\nRiegl/Ricopter\n30\n22\nLiDAR/camera\n\
    77\nHelicopter/gas\nAeroscout/Scout B1-100\n90\nLiDAR\n90\nHelicopter/gas\nIGI/geocopter\n\
    120–180\nCamera/LiDAR\n9.2\nOctocopter/electric\nAltigator/OnyxStar\nFOX-C8 HD\
    \ LiDAR\n20\nLiDAR\n38\nFixed-wing/gas\nAmerican\nAerospace/RS-16\n720–960\n33\n\
    Camera\n3.2. Vegetation Indices\nUsing multi-spectral images from the remote sensors\
    \ described above, a series of Vegetation\nIndices (VIs) can be computed. Vegetation\
    \ Indices (VIs) obtained from remote sensing-based canopies\nare effective algorithms\
    \ for quantitative and qualitative evaluations of vigour, vegetation cover and\n\
    growth dynamics, among other applications [26]. Hitherto, no uniﬁed mathematical\
    \ expression exists\nthat deﬁnes all VIs due to the complexity of the several\
    \ light spectra combinations, instrumentation,\nresolutions and platforms used.\
    \ In particular, this section focuses on vegetation indices NDVI, GDVI\nand SAVI,\
    \ as they are widely used in PA.\n3.2.1. NDVI\nThe Normalized Difference Vegetation\
    \ Index (NDVI) is the most popular VI that is extensively\nused to ﬁnd the content\
    \ of green in PA applications [27,28]. It uses Red (R) and Near Infrared (NIR)\n\
    channels to compute the NDVI index. More NIR light is absorbed by healthy vegetation;\
    \ however,\nabsorption ratio is very small for red light. NDVI is computed by\
    \ Equation (1) and returns a value\nbetween −1 and 1 [29].\nNDVI = NIR − R\nNIR\
    \ + R\n(1)\nHigher NDVI value indicate healthy vegetation, while smaller values\
    \ of NDVI show that vegetation is\nvery small at that speciﬁc region. There is\
    \ another form of NDVI, i.e., the Green Normalized Vegetation\nIndex (GNDVI),\
    \ which uses the green channel instead of red. GNDVI is computed by Equation (2):\n\
    GNDVI = NIR − G\nNIR + G\n(2)\nSensors 2019, 19, 3796\n11 of 25\n3.2.2. Difference\
    \ Vegetation Index\nThe DVI was proposed to reduce the effect of soil reﬂectance,\
    \ which is not covered by NDVI [30].\nDVI is different between the reﬂectance\
    \ of the NIR band to the reﬂectance of the red band. DVI is also\ncomputed with\
    \ the green band, i.e., GDVI. Both DVI and GDVI are computed by Equations (3)\
    \ and (4):\nDVI = NIR − R\n(3)\nGDVI = NIR − G\n(4)\n3.2.3. SAVI\nNDVI and DVI\
    \ do not compensate the background effect of soil. Therefore, many vegetation\n\
    indices were introduced to compensate the effect of soil reﬂectance. The Soil\
    \ Adjusted Vegetation Index\n(SAVI), the Green Soil Adjusted vegetation Index\
    \ (GSAVI), the Optimized Soil Adjusted Vegetation\nIndex (OSAVI), the Green Optimized\
    \ Soil Adjusted Vegetation Index (OGSAVI) and the Modiﬁed\nSoil Adjusted Vegetation\
    \ Index (MSAVI) [31–33] are common among them, which are computed by\nEquations\
    \ (5)–(9):\nSAVI =\n1.5(NIR − R)\n(NIR + R + 0.5)\n(5)\nGSAVI = 1.5(NIR − G)\n\
    NIR + G + 0.5\n(6)\nOSAVI =\n(NIR − G)\nNIR + R + 0.16\n(7)\nGOSAVI =\n(NIR −\
    \ G)\nNIR + G + 0.16\n(8)\nMSAVI = 0.5[2(NIR + 1) −\nq\n(2NIR + 1)2 − 8(NIR −\
    \ R)]\n(9)\n3.2.4. NR and NG:\nNormalized Red (NR) and Normalized Green (NG) are\
    \ two other famous vegetation indices being\nused in PA [33]. NR focuses on the\
    \ part of spectrum where radiation is absorbed by chlorophyll, while\nNG focuses\
    \ on the part of the spectrum where radiation is absorbed by other pigments, excluding\n\
    chlorophyll. NR and NG are computed by Equations (10) and (11):\nNR =\nR\nNIR\
    \ + R + G\n(10)\nNG =\nG\nNIR + R + G\n(11)\n4. Wireless Sensor Network Applications\
    \ in Agriculture\nMultiple applications of wireless sensor networks are being\
    \ utilized today in the agriculture sector.\nSome very common applications are\
    \ smart irrigation, smart fertilization, smart pest control and green\nhouse monitoring.\n\
    4.1. Smart Irrigation Systems\nSmart irrigation is an artiﬁcial irrigation application\
    \ that controls the quantity of water by making\na decision about where water\
    \ is needed. It is the most signiﬁcant constituent in agriculture, which has\n\
    a great impact on crops’ health, cost and productivity. One major aspect of smart\
    \ irrigation is to avoid\nSensors 2019, 19, 3796\n12 of 25\nthe wastage of water\
    \ since most countries in the world are facing water scarcity problems. A smart\n\
    irrigation system was presented in [34] in which a Raspberry Pi was used along\
    \ with two sensors:\na soil moisture sensor was used to assess the water level\
    \ in the soil, while a temperature and humidity\nsensor was used to monitor the\
    \ environmental condition. The Raspberry Pi was connected to these\nsensors and\
    \ the water supply network. A mobile application was developed for remote monitoring\n\
    and remote water ﬂow control enabling both manual and automatic water ﬂow control.\
    \ In automatic\nmode, water ﬂow was automatically turned ON/OFF based on the water\
    \ level of the soil without\nhuman intervention. In manual mode, the user was\
    \ able to monitor the soil moisture level. An alert\nwas generated when the water\
    \ level of soil was getting below a speciﬁc threshold, and the user turned\nit\
    \ ON/OFF using a mobile application.\nPower is a big concern in IoT-based platforms,\
    \ so many researchers have developed power-\nefﬁcient systems. A power-efﬁcient\
    \ water irrigation system was presented using solar power [35]\nin which the controller\
    \ was connected to the soil sensor and water supply valve. The water valve\nwas\
    \ turned ON/OFF based on the water level monitored by the moisture sensor. The\
    \ power was\nsupplied by the solar panel, so the system was independent of any\
    \ external power module. Another\nsensor-based IoT system for water irrigation\
    \ was presented in [36] in which the controller controlled\nthe opening and closing\
    \ of a solenoid valve based on the water level of the soil. In addition, a series\
    \ of\nweather alerts were sent to the user via a mobile application to update\
    \ the temperature and humidity of\nthe environment, which had a direct inﬂuence\
    \ on the water level of the soil. In [37], an energy-efﬁcient\nirrigation system\
    \ for cultivated crops was presented using a wireless sensor network in which\
    \ water\nwas effectively controlled based on environmental conditions. This system\
    \ estimated the quantity of\nwater needed for normal irrigation based on the humidity,\
    \ temperature and wind speed collected by\nsensors along with historical data.\n\
    In [38], an IoT-based irrigation system was presented using soil moisture sensors\
    \ controlled by\nATMEGA 328P on an Arduino UNO board along with a GPRS module.\
    \ The data collected from the\nsensors were sent to the cloud, i.e., Things Speak,\
    \ where graphs were generated to visualize the data\ntrends. A web portal was\
    \ also designed where the farmer was able to check the status of water, if it\n\
    was ON/OFF. Similarly, a real-time prototype for an irrigation system was presented\
    \ in [39] in which\nsoil moisture sensors and soil temperature sensors were used\
    \ to assess the water status of the soil.\nRFID was used to transmit data to the\
    \ cloud for further data analysis. Using ATMEGA 328, a water\nsprinkler system\
    \ for smart irrigation was presented in [40] using temperature, humidity and soil\n\
    moisture sensors. The water sprinkler was controlled based on the soil moisture\
    \ level to save water\nand reduce human effort. In [41], a cost-effective drip\
    \ irrigation system for a home was proposed in\nwhich a Raspberry Pi, Arduino,\
    \ electronic water control valve and relay were used. ZigBee protocols\nwere used\
    \ for communication. The user turned ON/OFF the water valve by sending commands\
    \ to the\nRaspberry Pi, which further processed the commands through the Arduino.\n\
    The sensors placement is a big issue that affects the accuracy of sensors. A detailed\
    \ discussion of\nsoil moisture positioning in the ﬁeld and their accuracy was\
    \ presented in [42]. For real-time irrigation\nsystems, complete software and\
    \ hardware requirements, problems and challenges and advantages\nwere discussed\
    \ in [43] where a big picture of the complete system was provided.\n4.2. Smart\
    \ Fertilization System\nFertilizer is an artiﬁcial or natural substance having\
    \ some chemical elements used to enhance\nthe growth and productivity of plants.\
    \ Manual spraying is a common technique used for fertilization.\nHowever, the\
    \ optimal way of fertilization requires sensing capabilities to ﬁnd the exact\
    \ place where\nfertilizer is needed, which chemical components are missing and\
    \ the amount of fertilizer needed.\nIt is important to provide fertilizers in\
    \ a very precise amount in order to improve productivity [44].\nMultiple fertilization\
    \ techniques have been presented by researchers since the last decade using WSN\n\
    and IoT.\nSensors 2019, 19, 3796\n13 of 25\nAn automated fertilization system\
    \ was presented in [45] using real-time sensors to measure the\nsoil fertility.\
    \ The system consisted of three modules including input, output and decision support.\n\
    The decision support module measured the optimal amount of fertilizers needed\
    \ for the growth of the\nplants based on the real-time sensory data captured by\
    \ the sensors. A mechanical sensor named the\n“Pendulum Meter” was introduced\
    \ in [46], which was used for optimal fertilization. This sensor was\nmounted\
    \ on the tractor to measure the density of the crop, so the corresponding fertilizer\
    \ spreader\nwas controlled based on the readings of this sensor. The IEEE 802.11\
    \ Wi-Fi module was used for\ncommunication along with GPS. Real-time data of soil\
    \ were collected by several sensors, i.e., soil\nmoisture, temperature, conductivity,\
    \ NO2, CO2, etc. A Geographical Information System (GIS) server\nwas used to interpolate\
    \ sensory data.\n4.3. Smart Pest Control and Early Disease Detection System\n\
    Pest attacks are the root cause of low productivity in the agriculture sector.\
    \ These pests result in\nseveral serious diseases in plants that affect the plant’s\
    \ growth. However, disease prediction provides\nearly warning to the farmers,\
    \ which enables them to make appropriate decisions to control the disease\non\
    \ time. Pest control systems are comprised of electronic devices that enable humans\
    \ to identify traps\nin a speciﬁc range of these electronic devices [47]. These\
    \ electronic devices are sensors capable of\ncalculating the environmental parameters\
    \ for further analysis.\nMuch research has been done in the agriculture sector\
    \ for early disease detection and pest control\nsystems using more advanced and\
    \ sophisticated technologies [48,49]. Multiple imagery sensors have\nbeen used\
    \ by different researchers to collect imagery data, such as: RGB sensors, ﬂuorescence\
    \ imagery\nsensors, spectral sensors and thermal sensors [50]. The thermal sensors\
    \ are used to measure the water\nstatus in the plant by measuring the temperature,\
    \ since this parameter has a direct inﬂuence on the\nwater level in the plants.\
    \ RGB images have three colour channels, i.e., red, green and blue, which\ncan\
    \ be used to perceive the biometric effect in the plants. Multi- and hyper-spectral\
    \ sensors capture\nimages containing the spatial information of objects in multiple\
    \ wavebands. The spatial resolution is\ndependent on the distance between the\
    \ object and the sensor. That is why satellite images contain less\nspatial resolution\
    \ as compared to low altitude platforms such as drones. The ﬂuorescence sensors\
    \ are\nused to distinguish the photosynthetic activities in the plants. Various\
    \ image processing techniques\nare applied to these imagery data to identify the\
    \ diseases in plants.\nIn [50], an IoT-based plants disease and pest prediction\
    \ system was presented to minimize the\nexcessive use of fungicides and insecticides.\
    \ Weather condition monitoring sensors, i.e., temperature,\ndew, humidity and\
    \ wind speed, are used to monitor weather parameters to ﬁnd a correlation between\n\
    pest growth with weather. The sensors have been deployed in orchards, and data\
    \ collected from these\nsensors are sent to the cloud. The farmer is informed\
    \ about the alarming condition of the pest attack\non the crops.\nFrom a different\
    \ point of view, hyper-spectral images are used to analyse crops’ health and pest\n\
    attack using manned or unmanned vehicles on which spectral cameras are mounted.\
    \ The captured\nimages are analysed in depth using machine learning techniques\
    \ to identify the disease in the plants.\nAdvance Neural Networks (ANNs) are more\
    \ common for processing imagery data due to their ability\nto learn complex structures\
    \ and patterns. Using hyper-spectral images, a system was presented [51] to\n\
    identify disease or pest attack in crops. The proposed system for disease detection\
    \ used an ANN with\nmultiple layers.\nEarly disease detection in sugar beet plants\
    \ was presented in [52]. For early detection, four\nsupervised classiﬁcation algorithms\
    \ were applied on spectral images. Spectral images were then\ncollected for each\
    \ image, and multiple vegetation indices were calculated to be used in predictive\n\
    and perspective analysis. The vegetation indices used were NVDI, SR, SIPI, PSSRaand\
    \ PSSRb, ARI,\nREP, mCAIand RRE. These vegetation indices values were used as\
    \ features in the dataset. Support\nVector Machine (SVM), ANN, and decision tree\
    \ were used for classiﬁcation. A comparative analysis\nwas performed which, showed\
    \ that SVM outperformed other classiﬁers for disease detection with an\nSensors\
    \ 2019, 19, 3796\n14 of 25\naccuracy of 97.12%. In [53], a data mining technique\
    \ was applied on the already collected dataset of\ntwo types of crops, i.e., wheat\
    \ and paddy (rice), in India. For dimension reduction, Sammon’s mapping\nwas used\
    \ for multi-dimension scaling, i.e., to reduce the dimension also for unsupervised\
    \ learning.\nFor high dimensional data, dimension reduction is required prior\
    \ to performing further data analysis\nfor better data visualization and accuracy,\
    \ since redundant dimensions reduce the effectiveness of\nany data analysis algorithms.\
    \ Principle Component Analysis (PCA) is a very often-used technique\nalong with\
    \ Sammon’s mapping. Data from multi-dimensions were reduced to two or three dimensions.\n\
    Then, the Self-Organized Maps (SOM) algorithm for clustering was used to ﬁnd correlations\
    \ between\nthe data. The accuracy comparison of SOM and Sammon’s mapping was presented,\
    \ which showed\nthat SOM performed better on a large dataset, while Sammon’s mapping\
    \ was suitable for small ones.\nSmart phones played important role in data acquisition,\
    \ which were further used to monitor the crops’\nhealth. In [54], the health of\
    \ wheat crop was monitored using near surface imagery captured by a smart\nphone.\
    \ The crop was classiﬁed as healthy or unhealthy based on the green level by computing\
    \ Gcc.\nMost of the applications in PA have been either IoT-based in which multiple\
    \ sensors are used to\nassess the health of the crop or remote sensing-based in\
    \ which crop health is assessed by performing\nsome computation on spectral images.\
    \ We can compare crop health monitoring application based\non some attributes\
    \ such as which sensors are used in particular applications, whether web or mobile\n\
    services are provided or not, etc. The comparative analysis of some existing crop\
    \ health monitoring\napplications is presented in Table 8 based on some attributes.\n\
    To precisely monitor the crop health, both IoT-based techniques and remote sensing\
    \ techniques\nshould be used together to provide more reliable and accurate information\
    \ about the crop. As a\nproof of concept, we present a case study in which a crop\
    \ health monitoring system based on IoT and\nremote sensing techniques is proposed.\
    \ We provide a complete end-to-end solution in the agriculture\ndomain by facilitating\
    \ the agricultural user with web and mobile services so that he/she could be\n\
    informed about the latest condition of the crop in a timely manner. In this way,\
    \ remedy actions could\nbe performed in time, which will result in enhanced production.\n\
    Sensors 2019, 19, 3796\n15 of 25\nTable 8. Comparison among existing PA applications.\n\
    PA\nEdge\nData\nSoil\nSoil\nAir\nAir\nVegetation\nWeb\nMobile\nLight\nWind\nApplication\n\
    Computing\nAnalytic\nMoisture\nTemperature\nMoisture\nTemperature\nIndex\nServices\n\
    Services\nIntensity\nVelocity\n[1]\nN\nY\nN\nN\nN\nY\nY\nN\nN\nN\nN\n[4]\nN\n\
    Y\nN\nN\nN\nN\nN\nY\nY\nN\nN\n[28]\nN\nY\nN\nN\nN\nN\nY\nN\nN\nN\nN\n[29]\nN\n\
    Y\nN\nN\nN\nN\nY\nN\nN\nN\nN\n[41]\nN\nN\nY\nN\nN\nN\nN\nN\nN\nN\nN\n[52]\nN\n\
    Y\nN\nN\nN\nN\nY\nN\nN\nN\nN\n[55]\nN\nN\nY\nN\nY\nY\nN\nN\nY\nN\nN\n[56]\nY\n\
    N\nY\nY\nY\nY\nN\nN\nN\nY\nN\n[57]\nN\nY\nY\nY\nY\nY\nN\nN\nN\nY\nN\n[58]\nN\n\
    N\nN\nY\nN\nN\nN\nN\nN\nN\nN\n[59]\nN\nY\nN\nN\nN\nN\nY\nN\nN\nN\nN\n[60]\nY\n\
    Y\nY\nN\nY\nY\nN\nY\nY\nY\nN\n[61]\nY\nY\nY\nY\nY\nY\nN\nY\nY\nY\nY\n[62]\nN\n\
    Y\nN\nN\nN\nY\nN\nY\nN\nN\nN\n[63]\nN\nY\nY\nY\nY\nY\nN\nY\nN\nN\nN\n[64]\nN\n\
    Y\nY\nN\nY\nY\nN\nY\nN\nN\nN\n[65]\nN\nY\nY\nY\nN\nY\nN\nN\nN\nN\nN\n[66]\nN\n\
    Y\nN\nN\nN\nN\nY\nN\nN\nN\nN\n[67]\nN\nY\nY\nY\nN\nY\nY\nY\nY\nN\nN\n[68]\nN\n\
    Y\nN\nN\nN\nN\nY\nN\nN\nN\nN\nProposed system\nY\nY\nY\nY\nY\nY\nY\nY\nY\nN\n\
    N\nSensors 2019, 19, 3796\n16 of 25\n5. A Case Study on UAV-Based and IoT-Based\
    \ Precision Agriculture\nWe developed a complete solution for crop health monitoring\
    \ based on IoT and remote sensing.\nIn the proposed system, crop health is monitored\
    \ using data collected from multiple IoT sensors,\nas well as NDVI mapping of\
    \ spectral images captured by a drone. The architecture of the proposed\nsystem\
    \ is shown in Figure 1, which was designed according to two main modules. The\
    \ ﬁrst module\nwas a wireless sensor network-based system in which multiple wireless\
    \ nodes were developed. Each\nwireless node was comprised of a soil moisture sensor\
    \ used to monitor the water level of the soil,\na soil temperature sensor used\
    \ to check the temperature of the soil and air temperature and humidity\nsensors.\
    \ These nodes were deployed across the ﬁeld in a star topology fashion where the\
    \ master node\ncollected readings from all slave nodes and transmitted the captured\
    \ reading to the back-end server for\nfurther processing. The master node acted\
    \ as a gateway node, which received data from all slave nodes\nusing NRF communication\
    \ module. After performing initial processing, the master node transmitted\nthe\
    \ data to the cloud using GSM communication technology. In the case of the unavailability\
    \ of the\nGSM network, this node stored the captured data and transmitted to the\
    \ cloud upon the availability\nof network.\nThe second module was used to monitor\
    \ crop health using multi-spectral imagery, which was\ncollected by a multi-spectral\
    \ camera mounted on a drone. The NDVI was computed using Equation (1)\nto classify\
    \ between healthy and unhealthy plants by measuring the chlorophyll content in\
    \ the crops,\nwhich was further used to localize the area under stress precisely.\n\
    All collected data were sent to the cloud where further analysis was performed.\
    \ The web portal\nwas designed to help the farmer monitor the crop proﬁle over\
    \ the whole life cycle. Currently, we are\nmonitoring soil moisture, soil temperature,\
    \ air moisture and air temperature readings in real time\nalong with NDVI mapping\
    \ of spectral imagery. Multiple web services were provided on the web\nportal\
    \ including historical/real data visualization using graphs, weather monitoring,\
    \ NDVI mapping\nand the correlation among measured parameters. Figure 2 shows\
    \ the snapshots of the web portal\nalong with different services.\nFigure 1. System\
    \ architecture.\nSensors 2019, 19, 3796\n17 of 25\nFigure 2. User interface of\
    \ the web portal.\nFor portability and remote monitoring, a mobile application\
    \ was also developed to facilitate the\nfarmer/agronomist/landlord with all the\
    \ web services that are available on web portal. The alerts\nare generated when\
    \ an abnormal behaviour is observed in the crop, which help the farmer to take\n\
    remedy actions in a timely manner. The user interfaces of the mobile application\
    \ are shown in Figure 3.\nTherefore, the web portal along with mobile applications\
    \ provides a complete solution, which enables\nagricultural users monitor the\
    \ current status of the crop, as well as previous details.\nFigure 3. User interface\
    \ of the mobile application.\nSensors 2019, 19, 3796\n18 of 25\n6. Results and\
    \ Discussion\n6.1. Analysis of the Data Collected by IoT Nodes\nThe developed\
    \ IoT nodes were deployed across the wheat ﬁelds of an area of 1.4375 hectare.\n\
    The selected area was located in Islamabad, Pakistan. The wheat ﬁelds are shown\
    \ in Figure 4 along\nwith the IoT node and sensors. We deployed the system across\
    \ the wheat ﬁeld in March 2019 when\nwheat was in the grain ﬁlling and grain ripening\
    \ stage.\nFigure 4. System deployed across the wheat ﬁelds.\nWe collected the\
    \ sensors’ readings such as air temperature, air humidity, soil temperature and\n\
    soil moisture. We compared the observed crop parameters with the ideal wheat temperature\
    \ proﬁle\nas shown in Figure 5. Extreme variation in the weather of Islamabad\
    \ was observed in that particular\ntime period, which can be seen by how the actual\
    \ temperature for wheat crop deviated from the ideal\ntemperature proﬁle of the\
    \ wheat crop.\nFigure 5. Deviation of observed temperature from the ideal temperature\
    \ proﬁle.\nAdditionally, we performed linear regression to ﬁnd the correlation\
    \ between observed parameters,\nwhich provided insight into how changes in one\
    \ parameter can effect the other parameter. The linear\nregression found a relation\
    \ between the two parameters by ﬁtting the equation of the line using the\nobserved\
    \ dataset [69]. Equation (12) represents an equation of the line where mrepresents\
    \ the slope of\nline, while c indicates the y-intercept. The variables m and c\
    \ were learned from the data.\ny = mx + c\n(12)\nFigure 6A shows the correlation\
    \ between the observed air temperature and air humidity, which showed\nthat both\
    \ were negatively correlated. The correlation between air temperature and soil\
    \ temperature is\nshown in Figure 6B, which shows that both were positively correlated.\n\
    Sensors 2019, 19, 3796\n19 of 25\n(A)\n(B)\nFigure 6. (A) Correlation b/wair temperature\
    \ and air humidity. (B) Correlation b/w air temperature\nand soil temperature.\n\
    The rise in air temperature caused the air humidity to reduce, while it resulted\
    \ in an increase in\nsoil temperature and vice versa.\n6.2. Analysis of Multi-spectral\
    \ Images Captured by Drone\nTo collect multi-spectral imagery, we used the DJI-Phantom\
    \ Pro Advanced drone with the Sentera\nMulti-spectral-imaging sensor. The drone\
    \ had its own optical camera, while the multi-spectral camera\nwas mounted on\
    \ it to obtain spectral images. Multiple ﬂights of the drone were carried out\
    \ at the\nspeciﬁc growing stages of the crop, i.e., grain ripening and grain ﬁlling\
    \ stage. After collecting these\nimages, they were transferred to the cloud for\
    \ NDVI mapping. Figure 7A shows the optical image\nthat was captured on 16 May\
    \ 2019 when wheat was in the harvesting stage, while Figure 7B is its\nspectral\
    \ image, and Figure 7C is the NDVI mapping. Since wheat was at a mature stage,\
    \ its NDVI\nshould be very small, i.e., ideally there should be no green region\
    \ in the ﬁeld. However, in NDVI\nmapping, a large green region indicated the abnormal\
    \ behaviour of the crop. The green region was\ndue to naturally growing plants.\
    \ This information can be visualized on the web portal.\n(A)\n(B)\n(C)\nFigure\
    \ 7. Wheat crop. (A) Optical image; (B) spectral image; (C) NDVI mapping.\nThe\
    \ same process was performed in a maize ﬁeld when maize was in the grain ripening\
    \ stage.\nFigure 8A shows the optical image that was captured on 24 July 2019\
    \ when maize was in the grain\nripening stage, while Figure 8B is its spectral\
    \ image, and Figure 8C is the NDVI mapping. The same\nbehaviour can be observed\
    \ with the maize crop, i.e., there should be a minimal green region in the\nﬁeld.\
    \ However, in NDVI mapping, a large green region indicated the abnormal behaviour\
    \ of the crop.\nSensors 2019, 19, 3796\n20 of 25\n(A)\n(B)\n(C)\nFigure 8. Maize\
    \ crop. (A) Optical image; (B) spectral image; (C) NDVI mapping.\n7. Challenges\n\
    PA has been used since the last few decades to enhance crops’ yield with reduced\
    \ costs and\nhuman effort, although the adoption of these novel techniques by\
    \ farmers is still very limited owing to\nthe following reasons or challenges.\n\
    7.1. Hardware Cost\nPA relies mostly on hardware such as sensors, wireless nodes,\
    \ drones, spectral imaging sensors,\netc., which are used to assess multiple parameters\
    \ in real time. These sensors have multiple limitations\nincluding high development,\
    \ maintenance and deployment cost. Some systems in PA are cost effective\nand\
    \ are suitable for small arable land, i.e., smart irrigation systems that require\
    \ low-cost hardware\ncomponents and sensors. However, drone-based systems for\
    \ crops’ health monitoring are feasible for\nlarge arable land due to high installation\
    \ cost.\n7.2. Weather Variations\nEnvironmental variation is one of the major\
    \ challenges that affects the accuracy of data collected\nby sensors. Sensor nodes\
    \ deployed in the ﬁeld are sensitive to environmental variations, i.e., rain,\n\
    ﬂuctuation in temperature, wind speed, sun light, etc. Communication between wireless\
    \ nodes\nand the cloud can be interrupted due interference induced in wireless\
    \ communication channels by\natmospheric disturbance. The satellite, air borne\
    \ and drone platforms are also sensitive to weather\nvariations. Imagery acquired\
    \ by these platforms is affected by contamination of clouds and other\nnatural\
    \ aerosols. The development of advanced techniques for atmospheric correction,\
    \ cloud detection\nand noise interpolation is a current open challenge, which\
    \ requires hard efforts from the research\ncommunity.\n7.3. Data Management\n\
    The sensors in PA constantly generate data. To ensure the integrity of data, some\
    \ data security\nmeasures needs to be in place, which will in turn enhance the\
    \ cost of the system. The readings from\nthe sensors have to be accurate in order\
    \ to take appropriate actions precisely when and where required.\nAn intruder\
    \ can corrupt the readings, and false readings will adversely reduce the effectiveness\
    \ of\nthe system. PA systems generate immense amounts of data, which require enough\
    \ resources to\nperform data analysis. Real-time data collected from sensors deployed\
    \ across the ﬁelds after a few\nminutes and spectral imagery acquired from high-altitude\
    \ or low-altitude platforms produce the bulk\nof the data, which increase the\
    \ storage and processing requirements. New software platforms and\nfacilities\
    \ for scalable management of Big Data sources are demanded. In this regard, the\
    \ generation\nof software-as-a-service solutions is focused on merging data management\
    \ and IoT thorough cloud\ncomputing platforms.\nSensors 2019, 19, 3796\n21 of\
    \ 25\n7.4. Literacy Rate\nLiteracy is an important factor that inﬂuences the adoption\
    \ ratio in PA. In developing countries\nwhere the illiteracy rate is high, farmers\
    \ grow crops based on their experience. They do not utilize the\nstate-of-the-art\
    \ technologies in agriculture, which results in loss of production. Farmers need\
    \ to be\neducated in order to understand the technology or they have to trust\
    \ a third party for technical support.\nTherefore, in underdeveloped areas where\
    \ the literacy rate is not high, PA is not very common due to\nthe limitations\
    \ of resources and education.\n7.5. Connectivity\nNext-generation 5G networks\
    \ can be 100-times faster than 4G ones, making communication\nbetween devices\
    \ and servers much quicker. 5G can also carry much more data than other networks,\n\
    which makes it an ideal technology for transmitting information from remote sensors\
    \ and drones, key\ntools that are being tested in PA environments. The adoption\
    \ of new communication networks based\non 5G is a must in current applications\
    \ where secure and rapid data transfer enables real-time data\nmanagement and\
    \ support for decision making.\n7.6. Interoperability\nOne of the biggest problems\
    \ PA faces is the interoperability of equipment due to different digital\nstandards.\
    \ This lack of interoperability is not only obstructing the adoption of new IoT\
    \ technologies\nand slowing down their growth, but it also inhibits the gain of\
    \ production efﬁciency through smart\nagriculture applications. New methods and\
    \ protocols to integrate different machine communication\nstandards to unlock\
    \ the potential of efﬁcient machine-to-machine communication and data sharing\n\
    between machines and management information systems are required in the current\
    \ scenario of PA.\n8. Conclusion and Future Directions\nPrecision agriculture\
    \ is a modern practice used to enhance crops’ productivity using latest\ntechnologies,\
    \ i.e., WSN, IoT, cloud computing, Artiﬁcial Intelligence (AI) and Machine Learning\n\
    (ML). Most of the research done so far indicates that PA-based practices have\
    \ a great inﬂuence on\nsustainability and productivity. The objective of PA is\
    \ to provide decision support systems based\non multiple parameters of crops,\
    \ i.e., soil nutrients, water level of the soil, wind speed, intensity of\nsunlight,\
    \ temperature, humidity, chlorophyll content, etc. However, several challenges\
    \ are involved\nin the development and deployment phase of these systems. This\
    \ article was aimed at providing a\nsurvey of modern technologies involving current\
    \ PA platforms, with the goal of supporting industry\nand research communities\
    \ on the development of modern applications for smart agriculture. A case\nstudy\
    \ was presented to prove the effectiveness of the PA in the agriculture domain.\n\
    Since the main objective of precision agriculture is to produce surplus yield\
    \ by optimizing the\nresources such as water, pesticides, fertilizers, etc., for\
    \ resource optimization, prescription maps play\nan important role, which enables\
    \ farmers to quantify resources required for healthy crops at any\nparticular\
    \ growth stage. Most of the research accomplished in the agriculture domain focuses\
    \ on the\nremote sensing platforms to collect imagery, which reﬂects only Vegetation\
    \ Indices (VIs) such as NDVI.\nThe prescription maps cannot be generated by only\
    \ using VIs; instead, multiple other factors need to\nbe considered such as soil\
    \ properties, soil moisture level, meteorological behaviour, etc.\nFunding: This\
    \ work is funded by the Research England’s QR Global Challenges Research Fund\
    \ (GCRF) under\nProject “GrITS: Green IoT for Climate Smart Agriculture”.\nAcknowledgments:\
    \ We extend our sincere thanks and gratitude to National Agriculture Research\
    \ Centre (NARC)\nIslamabad, Pakistan for allowing us to ﬂy drone in their premises\
    \ and capture spectral imagery to monitor crop\nhealth. We are also indebt to\
    \ NUST-SEECS for providing the administrative and technical support to IoT lab\
    \ for\nconducting this research work.\nConﬂicts of Interest: The authors declare\
    \ no conﬂict of interest.\nSensors 2019, 19, 3796\n22 of 25\nReferences\n1.\n\
    Mumtaz, R.; Baig, S.; Fatima, I. Analysis of meteorological variations on wheat\
    \ yield and its estimation using\nremotely sensed data. A case study of selected\
    \ districts of Punjab Province, Pakistan (2001–14). Ital. J. Agron.\n2017, 12.\
    \ [CrossRef]\n2.\nWang, N.; Zhang, N.; Wang, M. Wireless sensors in agriculture\
    \ and food industry—Recent development and\nfuture perspective. Comput. Electron.\
    \ Agric. 2006, 50, 1–14. [CrossRef]\n3.\nAbbasi, A.Z.; Islam, N.; Shaikh, Z.A.\
    \ A review of wireless sensors and networks’ applications in agriculture.\nComput.\
    \ Stand. Interfaces 2014, 36, 263–270.\n4.\nRad, C.R.; Hancu, O.; Takacs, I.A.;\
    \ Olteanu, G. Smart monitoring of potato crop: A cyber-physical system\narchitecture\
    \ model in the ﬁeld of precision agriculture. Agric. Agric. Sci. Procedia 2015,\
    \ 6, 73–79. [CrossRef]\n5.\nBaccarelli, E.; Naranjo, P.G.V.; Scarpiniti, M.; Shojafar,\
    \ M.; Abawajy, J.H. Fog of everything: Energy-efﬁcient\nnetworked computing architectures,\
    \ research challenges, and a case study. IEEE Access 2017, 5, 9882–9910.\n[CrossRef]\n\
    6.\nNaranjo, P.G.V.; Shojafar, M.; Mostafaei, H.; Pooranian, Z.; Baccarelli, E.\
    \ P-SEP: A prolong stable election\nrouting algorithm for energy-limited heterogeneous\
    \ fog-supported wireless sensor networks. J. Supercomput.\n2017, 73, 733–755.\
    \ [CrossRef]\n7.\nKirby, M.; Mainuddin, M.; Khaliq, T.; Cheema, M. Agricultural\
    \ production, water use and food availability\nin Pakistan: Historical trends,\
    \ and projections to 2050. Agric. Water Manag. 2017, 179, 34–46. [CrossRef]\n\
    8.\nAl-Sarawi, S.; Anbar, M.; Alieyan, K.; Alzubaidi, M. Internet of Things (IoT)\
    \ communication protocols.\nIn Proceedings of the 2017 8th International Conference\
    \ on Information Technology (ICIT), Amman, Jordan,\n17–18 May 2017; pp. 685–690.\n\
    9.\nZhang, X.; Andreyev, A.; Zumpf, C.; Negri, M.C.; Guha, S.; Ghosh, M. Thoreau:\
    \ A subterranean wireless\nsensing network for agriculture and the environment.\
    \ In Proceedings of the 2017 IEEE Conference on\nComputer Communications Workshops\
    \ (INFOCOM WKSHPS), Atlanta, GA, USA, 1–4 May 2017; pp. 78–84.\n10.\nKhelifa,\
    \ B.; Amel, D.; Amel, B.; Mohamed, C.; Tarek, B.\nSmart irrigation using internet\
    \ of things.\nIn Proceedings of the 2015 Fourth International Conference on Future\
    \ Generation Communication\nTechnology (FGCT), Luton, UK, 29–31 July 2015; pp.\
    \ 1–6.\n11.\nPaventhan, A.; Allu, S.K.; Barve, S.; Gayathri, V.; Ram, N.M. Soil\
    \ property monitoring using 6lowpan-enabled\nwireless sensor networks. In Proceedings\
    \ of the Agro-Informatics and Precision Agriculture, Hyderabad,\nIndia, 1–3 August\
    \ 2012.\n12.\nSuryady, Z.; Shaharil, M.H.M.; Bakar, K.A.; Khoshdelniat, R.; Sinniah,\
    \ G.R.; Sarwar, U. Performance\nevaluation of 6LoWPAN-based precision agriculture.\
    \ In Proceedings of the International Conference on\nInformation Networking 2011\
    \ (ICOIN2011), Barcelona, Spain, 26–28 January 2011; pp. 171–176.\n13.\nSarode,\
    \ K.; Chaudhari, P. Zigbee based Agricultural Monitoring and Controlling System.\
    \ Int. J. Eng. Sci.\n2018, 8, 15907–15910.\n14.\nZhou, Y.; Yang, X.; Guo, X.;\
    \ Zhou, M.; Wang, L. A design of greenhouse monitoring & control system\nbased\
    \ on ZigBee wireless sensor network.\nIn Proceedings of the 2007 International\
    \ Conference on\nWireless Communications, Networking and Mobile Computing, Shanghai,\
    \ China, 21–25 September 2007;\npp. 2563–2567.\n15.\nChikankar, P.B.; Mehetre,\
    \ D.; Das, S. An automatic irrigation system using ZigBee in wireless sensor\n\
    network. In Proceedings of the 2015 International Conference on Pervasive Computing\
    \ (ICPC), Pune, India,\n8–10 January 2015; pp. 1–5.\n16.\nXue-fen, W.; Xing-jing,\
    \ D.; Wen-qiang, B.; Le-han, L.; Jian, Z.; Chang, Z.; Ling-xuan, Z.; Yu-xiao,\
    \ Y.P.; Yi, Y.\nSmartphone accessible agriculture IoT node based on NFC and BLE.\
    \ In Proceedings of the 2017 IEEE\nInternational Symposium on Consumer Electronics\
    \ (ISCE), Kuala Lumpur, Malaysia, 14–15 November 2017;\npp. 78–79.\n17.\nTanaka,\
    \ K.; Murase, M.; Naito, K. Prototype implementation of BLE based automated data\
    \ collection\nscheme in agricultural measurement system.\nIn Proceedings of the\
    \ 2018 15th IEEE Annual Consumer\nCommunications & Networking Conference (CCNC),\
    \ Las Vegas, NV, USA, 12–15 January 2018; pp. 1–2.\n18.\nWasson, T.; Choudhury,\
    \ T.; Sharma, S.; Kumar, P. Integration of RFID and sensor in agriculture using\n\
    IOT.\nIn Proceedings of the 2017 International Conference On Smart Technologies\
    \ For Smart Nation\n(SmartTechCon), Bangalore, India, 17–19 August 2017; pp. 217–222.\n\
    Sensors 2019, 19, 3796\n23 of 25\n19.\nLiang, M.H.; He, Y.F.; Chen, L.J.; Du,\
    \ S.F. Greenhouse Environment dynamic Monitoring system based on\nWIFI. IFAC-PapersOnLine\
    \ 2018, 51, 736–740. [CrossRef]\n20.\nN-USha, T.M. Conditions in Agriculture through\
    \ WiFi using Raspberry PI. Int. J. Eng. 2017, 3, 6–11.\n21.\nDavcev, D.; Mitreski,\
    \ K.; Trajkovic, S.; Nikolovski, V.; Koteli, N. IoT agriculture system based on\
    \ LoRaWAN.\nIn Proceedings of the 2018 14th IEEE International Workshop on Factory\
    \ Communication Systems (WFCS),\nImperia, Italy, 13–15 June 2018; pp. 1–4.\n22.\n\
    Rudd, J.D.; Roberson, G.T.; Classen, J.J. Application of satellite, unmanned aircraft\
    \ system, and ground-based\nsensor data for precision agriculture: A review. In\
    \ Proceedings of the 2017 ASABE Annual International\nMeeting, Spokane, WA, USA,\
    \ 16–19 July 2017.\n23.\nToth, C.; Jó´zków, G. Remote sensing platforms and sensors:\
    \ A survey. ISPRS J. Photogramm. Remote Sens.\n2016, 115, 22–36. [CrossRef]\n\
    24.\nZhong, Y.; Wang, X.; Xu, Y.; Wang, S.; Jia, T.; Hu, X.; Zhao, J.; Wei, L.;\
    \ Zhang, L.\nMini-UAV-Borne\nHyperspectral Remote Sensing: From Observation and\
    \ Processing to Applications. IEEE Geosci. Remote Sens.\nMag. 2018, 6, 46–62.\
    \ [CrossRef]\n25.\nCandiago, S.; Remondino, F.; De Giglio, M.; Dubbini, M.; Gattelli,\
    \ M. Evaluating multispectral images and\nvegetation indices for precision farming\
    \ applications from UAV images. Remote Sens. 2015, 7, 4026–4047.\n[CrossRef]\n\
    26.\nXue, J.; Su, B. Signiﬁcant remote sensing vegetation indices: A review of\
    \ developments and applications.\nJ. Sens. 2017, 2017, 1353691. [CrossRef]\n27.\n\
    Skakun, S.; Justice, C.O.; Vermote, E.; Roger, J.C. Transitioning from MODIS to\
    \ VIIRS: An analysis of\ninter-consistency of NDVI data sets for agricultural\
    \ monitoring.\nInt. J. Remote Sens. 2018, 39, 971–992.\n[CrossRef]\n28.\nDaroya,\
    \ R.; Ramos, M. NDVI image extraction of an agricultural land using an autonomous\
    \ quadcopter\nwith a ﬁlter-modiﬁed camera. In Proceedings of the 2017 7th IEEE\
    \ International Conference on Control\nSystem, Computing and Engineering (ICCSCE),\
    \ Penang, Malaysia, 24–26 November 2017; pp. 110–114.\n29.\nMahajan, U.; Raj,\
    \ B. Drones for Normalized Difference Vegetation Index (NDVI), to estimate Crop\
    \ Health for\nPrecision Agriculture: A Cheaper Alternative for Spatial Satellite\
    \ Sensors. In Proceedings of the International\nConference on Innovative Research\
    \ in Agriculture, Food Science, Forestry, Horticulture, Aquaculture,\nAnimal Sciences,\
    \ Biodiversity, Ecological Sciences and Climate Change (AFHABEC-2016), Delhi,\
    \ India,\n22 October 2016.\n30.\nRichardson, A.J.; Wiegand, C. Distinguishing\
    \ vegetation from soil background information. Photogr. Eng.\nRemote Sens. 1977,\
    \ 43, 1541–1552.\n31.\nHuete, A.R. A soil-adjusted vegetation index (SAVI). Remote\
    \ Sens. Environ. 1988, 25, 295–309. [CrossRef]\n32.\nRondeaux, G.; Steven, M.;\
    \ Baret, F. Optimization of soil-adjusted vegetation indices. Remote Sens. Environ.\n\
    1996, 55, 95–107. [CrossRef]\n33.\nQi, J.; Chehbouni, A.; Huete, A.; Kerr, Y.;\
    \ Sorooshian, S. A modiﬁed soil adjusted vegetation index. Remote\nSens. Environ.\
    \ 1994, 48, 119–126. [CrossRef]\n34.\nAkubattin, V.; Bansode, A.; Ambre, T.; Kachroo,\
    \ A.; SaiPrasad, P. Smart irrigation system. Int. J. Sci. Res.\nSci. Technol.\
    \ 2016, 2, 343–345.\n35.\nHarishankar, S.; Kumar, R.S.; Sudharsan, K.; Vignesh,\
    \ U.; Viveknath, T. Solar powered smart irrigation\nsystem. Adv. Electr. Comput.\
    \ Eng. 2014, 4, 341–346.\n36.\nKansara, K.; Zaveri, V.; Shah, S.; Delwadkar, S.;\
    \ Jani, K. Sensor based automated irrigation system with IOT:\nA technical review.\
    \ Int. J. Comput. Sci. Inf. Technol. 2015, 6, 5331–5333.\n37.\nNikolidakis, S.A.;\
    \ Kandris, D.; Vergados, D.D.; Douligeris, C. Energy efﬁcient automated control\
    \ of irrigation\nin agriculture by using wireless sensor networks. Comput. Electron.\
    \ Agric. 2015, 113, 154–163. [CrossRef]\n38.\nRawal, S. IOT based Smart Irrigation\
    \ System. Int. J. Comput. Appl. 2017, 159, 880–886. [CrossRef]\n39.\nVellidis,\
    \ G.; Tucker, M.; Perry, C.; Kvien, C.; Bednarz, C. A real-time wireless smart\
    \ sensor array for\nscheduling irrigation. Comput. Electron. Agric. 2008, 61,\
    \ 44–50. [CrossRef]\n40.\nKumar, B.D.; Srivastava, P.; Agrawal, R.; Tiwari, V.\
    \ Microcontroller based automatic plant Irrigation system.\nInt. Res. J. Eng.\
    \ Tenchnol. 2017, 4, 1436–1439.\n41.\nAgrawal, N.; Singhal, S. Smart drip irrigation\
    \ system using raspberry pi and arduino. In Proceedings of the\nInternational\
    \ Conference on Computing, Communication & Automation, Noida, India, 15–16 May\
    \ 2015;\npp. 928–932.\nSensors 2019, 19, 3796\n24 of 25\n42.\nSoulis, K.X.; Elmaloglou,\
    \ S.; Dercas, N. Investigating the effects of soil moisture sensors positioning\
    \ and\naccuracy on soil moisture based drip irrigation scheduling systems. Agric.\
    \ Water Manag. 2015, 148, 258–268.\n[CrossRef]\n43.\nYousif, M.E.R.; Ghafar, K.;\
    \ Zahari, R.; Lim, T.H. A rule-based smart automated fertilization and irrigation\n\
    systems. In Proceedings of the Ninth International Conference on Graphic and Image\
    \ Processing (ICGIP\n2017), Qingdao, China, 14–16 October 2017.\n44.\nCugati,\
    \ S.; Miller, W.; Schueller, J. Automation concepts for the variable rate fertilizer\
    \ applicator for tree\nfarming. In Proceedings of the 4th European Conference\
    \ on Precision Agriculture, Berlin, Germany, 15–19\nJune 2003; pp. 14–19.\n45.\n\
    He, J.; Wang, J.; He, D.; Dong, J.; Wang, Y. The design and implementation of\
    \ an integrated optimal\nfertilization decision support system. Math. Comput.\
    \ Model. 2011, 54, 1167–1174. [CrossRef]\n46.\nChen, X.; Zhang, F. The establishment\
    \ of fertilization technology index system based on “3414” fertilizer\nexperiment.\
    \ China Agric. Technol. Ext. 2006, 22, 36–39.\n47.\nMahlein, A.K.; Oerke, E.C.;\
    \ Steiner, U.; Dehne, H.W. Recent advances in sensing plant diseases for precision\n\
    crop protection. Eur. J. Plant Pathol. 2012, 133, 197–209. [CrossRef]\n48.\nSankaran,\
    \ S.; Mishra, A.; Ehsani, R.; Davis, C. A review of advanced techniques for detecting\
    \ plant diseases.\nComput. Electron. Agric. 2010, 72, 1–13. [CrossRef]\n49.\n\
    Mahlein, A.K. Plant disease detection by imaging sensors–parallels and speciﬁc\
    \ demands for precision\nagriculture and plant phenotyping. Plant Dis. 2016, 100,\
    \ 241–251. [CrossRef] [PubMed]\n50.\nLee, H.; Moon, A.; Moon, K.; Lee, Y. Disease\
    \ and pest prediction IoT system in orchard: A preliminary study.\nIn Proceedings\
    \ of the 2017 Ninth International Conference on Ubiquitous and Future Networks\
    \ (ICUFN),\nMilan, Italy, 4–7 July 2017; pp. 525–527.\n51.\nGolhani, K.; Balasundram,\
    \ S.K.; Vadamalai, G.; Pradhan, B. A review of neural networks in plant disease\n\
    detection using hyperspectral data. Inf. Process. Agric. 2018, 5, 354–371. [CrossRef]\n\
    52.\nRumpf, T.; Mahlein, A.K.; Steiner, U.; Oerke, E.C.; Dehne, H.W.; Plümer,\
    \ L. Early detection and classiﬁcation\nof plant diseases with support vector\
    \ machines based on hyperspectral reﬂectance. Comput. Electron. Agric.\n2010,\
    \ 74, 91–99. [CrossRef]\n53.\nSanghvi, Y.; Gupta, H.; Doshi, H.; Koli, D.; Ansh,\
    \ A.; Gupta, U. Comparison of Self organizing maps\nand Sammon’s mapping on agricultural\
    \ datasets for precision agriculture.\nIn Proceedings of the 2015\nInternational\
    \ Conference on Innovations in Information, Embedded and Communication Systems\
    \ (ICIIECS),\nCoimbatore, India, 19–20 March 2015; pp. 1–5.\n54.\nHufkens, K.;\
    \ Melaas, E.K.; Mann, M.L.; Foster, T.; Ceballos, F.; Robles, M.; Kramer, B. Monitoring\
    \ crop\nphenology using a smartphone based near-surface remote sensing approach.\
    \ Agric. For. Meteorol. 2019,\n265, 327–337. [CrossRef]\n55.\nPrathibha, S.; Hongal,\
    \ A.; Jyothi, M. IOT Based monitoring system in smart agriculture. In Proceedings\n\
    of the 2017 International Conference on Recent Advances in Electronics and Communication\
    \ Technology\n(ICRAECT), Bangalore, India, 16–17 March 2017; pp. 81–84.\n56.\n\
    Heble, S.; Kumar, A.; Prasad, K.V.D.; Samirana, S.; Rajalakshmi, P.; Desai, U.B.\
    \ A low power IoT network\nfor smart agriculture. In Proceedings of the 2018 IEEE\
    \ 4th World Forum on Internet of Things (WF-IoT),\nSingapore, 5–8 February 2018;\
    \ pp. 609–614.\n57.\nSabo, A.; Qaisar, S.; Subasi, A.; Rambo, K. An Event Driven\
    \ Wireless Sensors Network for Monitoring\nof Plants Health and Larva Activities.\
    \ In Proceedings of the 2018 21st Saudi Computer Society National\nComputer Conference\
    \ (NCC), Riyadh, Saudi Arabia, 25–26 April 2018; pp. 1–7.\n58.\nAgarwal, A.; Gupta,\
    \ S.; Kumar, S.; Singh, D. A concept of satellite-based IoT for downscaling the\
    \ MODIS\ndata to extract Land Surface Temperature. In Proceedings of the 2018\
    \ 9th International Symposium on\nSignal, Image, Video and Communications (ISIVC),\
    \ Rabat, Morocco, 27–30 November 2018; pp. 67–70.\n59.\nRahman, M.R.; Islam, A.;\
    \ Rahman, M.A. NDVI derived sugarcane area identiﬁcation and crop condition\n\
    assessment. Plan Plus 2004, 1, 1–12.\n60.\nChoudhury, S.B.; Jain, P.; Kallamkuth,\
    \ S.; Ramanath, S.; Bhatt, P.V.; Sarangi, S.; Srinivasu, P. Precision Crop\nMonitoring\
    \ with Affordable IoT: Experiences with Okra. In Proceedings of the 2019 Global\
    \ IoT Summit\n(GIoTS), Aarhus, Denmark, 17–21 June 2019; pp. 1–6.\nSensors 2019,\
    \ 19, 3796\n25 of 25\n61.\nMittal, A.; Sarangi, S.; Ramanath, S.; Bhatt, P.V.;\
    \ Sharma, R.; Srinivasu, P. IoT-Based Precision Monitoring of\nHorticultural Crops—A\
    \ Case-Study on Cabbage and Capsicum. In Proceedings of the 2018 IEEE Global\n\
    Humanitarian Technology Conference (GHTC), San Jose, CA, USA, 18–21 October 2018;\
    \ pp. 1–7.\n62.\nSaha, A.K.; Saha, J.; Ray, R.; Sircar, S.; Dutta, S.; Chattopadhyay,\
    \ S.P.; Saha, H.N. IOT-based drone for\nimprovement of crop quality in agricultural\
    \ ﬁeld. In Proceedings of the 2018 IEEE 8th Annual Computing and\nCommunication\
    \ Workshop and Conference (CCWC), Las Vegas, NV, USA, 8–10 January 2018; pp. 612–615.\n\
    63.\nMekala, M.S.; Viswanathan, P. CLAY-MIST: IoT-cloud enabled CMM index for\
    \ smart agriculture monitoring\nsystem. Measurement 2019, 134, 236–244. [CrossRef]\n\
    64.\nNawandar, N.K.; Satpute, V.R. IoT based low cost and intelligent module for\
    \ smart irrigation system.\nComput. Electron. Agric. 2019, 162, 979–990. [CrossRef]\n\
    65.\nSrbinovska, M.; Gavrovski, C.; Dimcev, V.; Krkoleva, A.; Borozan, V. Environmental\
    \ parameters monitoring\nin precision agriculture using wireless sensor networks.\
    \ J. Clean. Prod. 2015, 88, 297–307. [CrossRef]\n66.\nLottes, P.; Khanna, R.;\
    \ Pfeifer, J.; Siegwart, R.; Stachniss, C. UAV-based crop and weed classiﬁcation\
    \ for smart\nfarming. In Proceedings of the 2017 IEEE International Conference\
    \ on Robotics and Automation (ICRA),\nSingapore, 29 May–3 June 2017; pp. 3024–3031.\n\
    67.\nCambra, C.; Sendra, S.; Lloret, J.; Garcia, L. An IoT service-oriented system\
    \ for agriculture monitoring.\nIn Proceedings of the 2017 IEEE International Conference\
    \ on Communications (ICC), Paris, France,\n21–25 May 2017.\n68.\nFontana, D.C.;\
    \ Pinto, D.G.; Junges, A.H.; Bremm, C. Using temporal NDVI/MODIS proﬁles for inferences\n\
    on the crop soybean calendar. Bragantia 2015, 74, 350–358. [CrossRef]\n69.\nSeber,\
    \ G.A.; Lee, A.J. Linear Regression Analysis; John Wiley & Sons: Hoboken, NJ,\
    \ USA, 2012; Volume 329.\nc⃝ 2019 by the authors. Licensee MDPI, Basel, Switzerland.\
    \ This article is an open access\narticle distributed under the terms and conditions\
    \ of the Creative Commons Attribution\n(CC BY) license (http://creativecommons.org/licenses/by/4.0/).\n"
  inline_citation: (6)
  journal: Sensors (Basel)
  limitations: '>'
  main_objective: To design a fog-supported wireless sensor network that prolongs
    stable election routing for heterogeneous networks with limited energy resources.
  pdf_link: https://www.mdpi.com/1424-8220/19/17/3796/pdf?version=1567419401
  publication_year: 2019
  relevance_evaluation:
    extract_1: Due to rapid advancement in WSN technologies, the size and the cost
      of sensors have reduced, which make it feasible to implement them in many sectors
      of life including agriculture.
    extract_2: The main goal of fog computing is to conserve energy and bandwidth,
      which helps to increase the quality of service to the end users.
    relevance_score: 0.85
  relevance_score: 0.85
  relevance_score1: 0
  relevance_score2: 0
  study_location: Unspecified
  title: 'Precision Agriculture Techniques and Practices: From Considerations to Applications'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'

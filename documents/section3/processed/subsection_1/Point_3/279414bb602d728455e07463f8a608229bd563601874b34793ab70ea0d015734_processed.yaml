- DOI: https://doi.org/10.3390/agronomy12010127
  analysis: 'The study provides a thorough analysis of the growing use of automated
    monitoring and management systems in agriculture, but it lacks a particular focus
    on volume, frequency, format, and source of the data.


    ### Considerations: volume, frequency, format, and source of the data


    Despite lacking specific details on data considerations, the paper provides a
    great overview of advancements in automated agricultural systems. Here''s a detailed
    analysis from the perspective of the outline point:


    **Volume, frequency, format, and source of the data**: Automated systems generate
    vast amounts of data, ranging from sensor readings to image captures. The volume
    of data can vary depending on the scale of the operation, the number of sensors
    deployed, and the frequency of data collection. Data frequency can be continuous,
    near-real-time, or at scheduled intervals. The format of the data can vary depending
    on the sensors used and may include raw sensor readings, processed data, or images.
    Data sources can include sensors, drones, satellites, and other IoT devices.


    Despite not explicitly addressing these data considerations, the paper highlights
    the importance of data collection, processing, and analysis for effective agricultural
    management. It emphasizes the need for robust data infrastructure and analytics
    capabilities to handle the growing volume and complexity of agricultural data.


    ### Relevance Score: 0.6-0.69:  Moderately relevant


    - Provides useful information for the outline point, but has some notable gaps
    in addressing key issues or limitations in insight, credibility, or meaningfulness.

    - The study lacks a specific focus on data considerations, which limits its direct
    relevance to the outline point.

    - However, it provides valuable insights into the overall landscape of automated
    agricultural systems and discusses the importance of data-driven approaches.'
  authors:
  - Amjad Rehman
  - Tanzila Saba
  - Muhammad Kashif
  - Suliman Mohamed Fati
  - Saeed Ali Bahaj
  - Huma Choudhary
  citation_count: 88
  full_citation: A Revisit of Internet of Things Technologies for Monitoring and Control
    Strategies in Smart Agriculture
  full_text: ">\n\x01\x02\x03\x01\x04\x05\x06\a\b\x01\n\x01\x02\x03\x04\x05\x06\a\n\
    Citation: Rehman, A.; Saba, T.;\nKashif, M.; Fati, S.M.; Bahaj, S.A.;\nChaudhry,\
    \ H. A Revisit of Internet of\nThings Technologies for Monitoring\nand Control\
    \ Strategies in Smart\nAgriculture. Agronomy 2022, 12, 127.\nhttps://doi.org/10.3390/\n\
    agronomy12010127\nAcademic Editor: Paul Kwan\nReceived: 7 October 2021\nAccepted:\
    \ 11 November 2021\nPublished: 5 January 2022\nPublisher’s Note: MDPI stays neutral\n\
    with regard to jurisdictional claims in\npublished maps and institutional afﬁl-\n\
    iations.\nCopyright:\n© 2022 by the authors.\nLicensee MDPI, Basel, Switzerland.\n\
    This article is an open access article\ndistributed\nunder\nthe\nterms\nand\n\
    conditions of the Creative Commons\nAttribution (CC BY) license (https://\ncreativecommons.org/licenses/by/\n\
    4.0/).\nagronomy\nReview\nA Revisit of Internet of Things Technologies for Monitoring\n\
    and Control Strategies in Smart Agriculture\nAmjad Rehman 1,*\n, Tanzila Saba\
    \ 1,*\n, Muhammad Kashif 2, Suliman Mohamed Fati 1\n, Saeed Ali Bahaj 3\nand Huma\
    \ Chaudhry 4\n1\nArtiﬁcial Intelligence & Data Analytics Lab., CCIS Prince Sultan\
    \ University, Riyadh 11586, Saudi Arabia;\nsmfati@yahoo.com\n2\nDepartment of\
    \ Computer Science & Software Engineering, International Islamic University,\n\
    Islamabad 44000, Pakistan; drkashif491@gmail.com\n3\nMIS Department College of\
    \ Business Administration, Prince Sattam Bin Abdulaziz University,\nAlkharj 11942,\
    \ Saudi Arabia; s.bahaj@psau.edu.sa\n4\nMelbourne Institute of Technology, Melbourne,\
    \ VIC 3000, Australia; huma.bicse@gmail.com\n*\nCorrespondence: arkhan@psu.edu.sa\
    \ (A.R.); tsaba@psu.edu.sa (T.S.)\nAbstract: With the rise of new technologies,\
    \ such as the Internet of Things, raising the productivity of\nagricultural and\
    \ farming activities is critical to improving yields and cost-effectiveness. IoT,\
    \ in particular,\ncan improve the efficiency of agriculture and farming processes\
    \ by eliminating human intervention\nthrough automation. The fast rise of Internet\
    \ of Things (IoT)-based tools has changed nearly all life\nsectors, including\
    \ business, agriculture, surveillance, etc. These radical developments are upending\n\
    traditional agricultural practices and presenting new options in the face of various\
    \ obstacles. IoT aids in\ncollecting data that is useful in the farming sector,\
    \ such as changes in climatic conditions, soil fertility,\namount of water required\
    \ for crops, irrigation, insect and pest detection, bug location disruption of\n\
    creatures to the sphere, and horticulture. IoT enables farmers to effectively\
    \ use technology to monitor\ntheir forms remotely round the clock. Several sensors,\
    \ including distributed WSNs (wireless sensor\nnetworks), are utilized for agricultural\
    \ inspection and control, which is very important due to their exact\noutput and\
    \ utilization. In addition, cameras are utilized to keep an eye on the field from\
    \ afar. The goal\nof this research is to evaluate smart agriculture using IoT\
    \ approaches in depth. The paper demonstrates\nIoT applications, benefits, current\
    \ obstacles, and potential solutions in smart agriculture. This smart\nagricultural\
    \ system aims to find existing techniques that may be used to boost crop yield\
    \ and save time,\nsuch as water, pesticides, irrigation, crop, and fertilizer\
    \ management.\nKeywords: agriculture; land monitoring; control strategies; IoT;\
    \ sensors; economic growth; water\nmanagement and water resources\n1. Introduction\n\
    The Internet of Things (IoT) is an interconnected network of computing devices,\n\
    people with unique IDs, and the capacity to communicate via a network without\
    \ human\ninteraction. The Internet of Things (IoT) intends to connect the physical\
    \ and virtual worlds\nby interacting and exchanging data via the internet. Linked\
    \ industries, smart cities, smart\nhomes, smart energy, connected vehicles, smart\
    \ agriculture, connected buildings and\ncampuses, health care, and logistics are\
    \ all examples of IoT applications [1]. The increasing\nneed for food, both in\
    \ terms of quantity and quality, has required the development and\nmodernization\
    \ of the agricultural sector. The “Internet of Things” (IoT) is a promising set\
    \ of\ntechnologies that may be used to provide a variety of agricultural modernization\
    \ solutions.\nScientiﬁc institutions, research institutes, and the agricultural\
    \ sector are racing to provide\nmore and more IoT solutions to agricultural business\
    \ stakeholders, laying the foundation\nfor a clear role when IoT becomes a mainstream\
    \ technology [2]. The world’s biodiversity\nis anticipated to support between\
    \ 9.4 and 10.1 billion people by 2050, increasing the need\nfor specialized food\
    \ production zones, especially for harvesting and livestock. This means\nAgronomy\
    \ 2022, 12, 127. https://doi.org/10.3390/agronomy12010127\nhttps://www.mdpi.com/journal/agronomy\n\
    Agronomy 2022, 12, 127\n2 of 21\nthat by 2050, global food production will have\
    \ to grow by 70% [3]. Crop production is\nincreasingly crucial in agriculture,\
    \ with commodities, such as cotton, wheat, gum, and\nothers, playing signiﬁcant\
    \ roles in many nations’ economies.\nIn 2019, the IoT market was 690 billion dollars\
    \ and was projected to be 1256.1 billion\ndollars by 2025 with a 10.53% CAGR globally\
    \ from 2020 to 2025. Solutions are needed to\nassure timely and regular agricultural\
    \ growth and yield due to the combined effects of a\ngrowing population, natural\
    \ weather unpredictability, soil degradation, and climate change.\nFarm management,\
    \ animal monitoring, irrigation control, greenhouse environmental con-\ntrol,\
    \ autonomous agricultural machinery, and drones are examples of IoT applications\
    \ in\nagriculture, all of which contribute to agrarian automation. It also demands\
    \ contributing to\nagricultural food production’s long-term viability. Land appraisal,\
    \ crop protection, and\ncrop yield projection, according to these needs, are essential\
    \ to world food production [4].\nFarmers, for example, can manage ﬁeld environments\
    \ in real-time and more effortlessly\nregulate ﬁelds using wireless sensors and\
    \ mobile networks. Farmers may also utilize IoT\ntechnology to capture essential\
    \ data, subsequently creating yield maps that enable precision\nagriculture to\
    \ produce low-cost high-quality crops [5]. Figure 1 depicts the smart precision\n\
    agriculture cycle.\nFigure 1. Smart precision agriculture cycle.\nSmart agriculture\
    \ is becoming increasingly important to farmers in the modern day,\nand it will\
    \ become even more critical in the future to ensure proper ﬁeld expansion and\n\
    crop output. Unfortunately, traditional farming methods are not up to the task\
    \ of meeting\nrising demand. As a result, the ground stays barren and devoid of\
    \ fertility due to poor\nutilization of nutrients, water management, light, fertilizers,\
    \ and pesticides. Crop diseases,\nwater shortage, irrigation, and pesticide control\
    \ monitoring are only some of the challenges\nthat different IoT automation and\
    \ control systems can efﬁciently address [6]. This is why\ncontemporary agriculture\
    \ employs smart equipment and tools from sowing through crop\nharvesting, storage,\
    \ and transportation. The operation is smart and cost-effective due to its\naccurate\
    \ monitoring capabilities and fast reporting using a range of sensors. Autonomous\n\
    drones, harvesters, tractors, satellites, and robots are now complementing agricultural\n\
    equipment. Sensors may be instantly placed and begin collecting data, which is\
    \ then\nimmediately available for further analysis over the internet. By enabling\
    \ reliable data\ngathering at each place, sensor technology allows crop and site-speciﬁc\
    \ agriculture [7].\nUsing advanced control methods to automate agricultural activities\
    \ has increased crop\nproduction while also improving soil fertility.\nThe following\
    \ are the signiﬁcant contributions made by this study:\nAgronomy 2022, 12, 127\n\
    3 of 21\n•\nThe world’s expectations of the agriculture industry, based on existing\
    \ IoT approaches\nfor providing solutions and new applications and technology.\n\
    •\nIdentiﬁcation of numerous application ﬁelds, as well as a summary of the most\
    \ recent\nstate-of-the-art literature on IoT technology.\n•\nThe Internet of Things’\
    \ task is to address these constraints and other challenges, such\nas resource\
    \ scarcity and precise usage, climate change, etc.\nThe rest of the paper is laid\
    \ out in the following manner. Section 2 delves into the\ndetails of smart agricultural\
    \ applications based on IoT technologies. Section 3 discusses the\nmany types\
    \ of equipment and technology available. Section 4 identiﬁes unsolved problems\n\
    and potential remedies. Finally, Section 5 concludes the research.\n2. Major Applications\
    \ of Smart Agriculture\nPrecision farming, animal monitoring, and greenhouse monitoring\
    \ are a few agri-\ncultural businesses utilizing the Internet of Things. Every\
    \ element of traditional farming\noperation may be substantially improved by combining\
    \ cutting-edge sensors and Internet\nof Things technology. At the moment, the\
    \ Internet of Things’ (IoT’s) and wireless sensors’\nharmonious incorporation\
    \ into smart agriculture can catapult agriculture to formerly in-\nconceivable\
    \ heights. Appropriateness of land, pest monitoring and control, irrigation, and\n\
    yield optimization are just a few of the conventional agricultural issues that\
    \ IoT may assist\nin resolving through the implementation of smart agriculture\
    \ approaches [7]. Figure 2\nillustrates the comprehensive paradigm of smart agricultural\
    \ monitoring system applica-\ntions, facilities, and sensors. Agriculture applications\
    \ are classiﬁed as IoT agricultural apps,\nsmartphone-based agricultural apps,\
    \ and sensor-based agricultural apps. Wireless sensor\nnetworks (WSNs) have recently\
    \ been used to enable IoT applications for smart agriculture,\nincluding irrigation\
    \ sensor networks, frost event prediction, precision agriculture and soil\nfarming,\
    \ smart farming, and unsighted object recognition, among others [8]. Signiﬁcant\n\
    instances of how new technology assists in the general improvement of efﬁciency\
    \ at various\nstages are included here.\nFigure 2. General paradigm of smart agriculture.\n\
    Agronomy 2022, 12, 127\n4 of 21\n2.1. Monitoring of Soil Moisture and Water Levels\n\
    Soil monitoring has developed into one of the most challenging agricultural areas,\n\
    both for manufacturers and farmers. Numerous environmental issues associated with\
    \ soil\nmonitoring affect agricultural yield. When these sorts of obstacles are\
    \ correctly identiﬁed,\nfarming patterns and methods become readily understandable.\
    \ The soil’s moisture content,\nwetness, fertilizer application, and temperature\
    \ trends are all being monitored. Soil’s\nmoisture environment management system\
    \ uses soil humidity and moisture sensors. By\nproposing an appropriate fertilizer\
    \ approach, the results of a soil monitoring test report\nassist farmers in increasing\
    \ crop yield [9]. The sensor can read both analog and digital\noutputs. The judgment\
    \ is made based on data collected from sensors and compared to\npredeﬁned threshold\
    \ levels. The soil moisture sensor is used to regulate the irrigation\nsystem’s\
    \ automatic operation. When the moisture level goes below the threshold value,\
    \ the\nwater pump is triggered [10].\nSoil mapping enables you to sow many crop\
    \ types in the same ﬁeld, allowing you\nto match better soil characteristics,\
    \ such as seed compatibility, sowing timing, and even\nplanting depth, as certain\
    \ crops are deeply rooted while others are not. Additionally,\ngrowing many crops\
    \ concurrently may result in more prudent agricultural practices, such\nas resource\
    \ conservation. The system is composed of a distributed network of soil moisture\n\
    and temperature sensors located in the root zone of the plant, as well as rain\
    \ sensors\nlocated in various zones. The microcontroller collects and transmits\
    \ all sensor data and\ninformation. In addition, a temperature and soil moisture\
    \ threshold algorithm will be\ndevised and implemented in a microcontroller-based\
    \ gateway to regulate the amount of\nwater given to the ﬁelds. Finally, the user\
    \ is provided with control via an IoT module based\non rain sensor data to interrupt\
    \ or restart water ﬂow as needed [11].\nIf the ﬁeld contains an adequate amount\
    \ of water, no water will be pumped into\nit. However, when the soil’s water moisture\
    \ content falls below a predetermined level,\nwater is pumped into the ﬁeld until\
    \ the desired moisture content is attained. The DHT11\nsensor monitors the ﬁeld’s\
    \ temperature and humidity. In addition, a PIR motion sensor\ndetects when an\
    \ intruder (human or animal) enters the area. Consequently, sensor values\nare\
    \ continually monitored and displayed on the farmer’s mobile device through a\
    \ GSM\nsim900A module, which includes a sim card with a 3G data pack and adds\
    \ IoT capabilities\nto the system [12].\n2.2. System of Irrigation Monitoring\n\
    Numerous studies have been conducted on a smart irrigation system. Food production\n\
    technology must signiﬁcantly improve to keep up with the growing demand for food.\n\
    Numerous experts have worked diligently to create an alternative to irrigated\
    \ farming.\nThese efforts, however, have not yet resulted in a feasible solution\
    \ to the irrigation system’s\npresent problems. At the moment, crop irrigation\
    \ is carried out manually and by established\ncustomary practices. When crops\
    \ are given less water, they grow slower and absorb less\ncalcium. Frequent irrigation\
    \ kills roots and wastes water. As a result, accurate irrigation\nof crops becomes\
    \ a considerable difﬁculty [13]. A smart irrigation management and\nmonitoring\
    \ approach is developed to enable autonomous delivery of sufﬁcient water from\n\
    a tank to ﬁeld crops. Automatic sensor systems are cost-effective, offered for\
    \ determining\nwhether plants require watering based on information gathered from\
    \ monitoring and\nregulating the soil water levels to minimize dryness or overﬂow\
    \ [14].\nKamaruddin et al., 2019 [15] developed an Internet of Things (IoT)-based\
    \ wireless sen-\nsor network (WSN) architecture that manually or automatically\
    \ administers and monitors\nthe irrigation system. The proposed method used NRF24L01\
    \ and Arduino tools as the\ncommunication network transceiver and CPU. The soil\
    \ moisture sensor data will be sent to\nthe base station via NRF24L01. Then, the\
    \ sensor node’s data will be sent to the cloud server\nthrough the base station.\
    \ This project utilized Thingspeak as a cloud server to store all data\nin a database\
    \ and connect it to an Android application.\nAgronomy 2022, 12, 127\n5 of 21\n\
    2.3. Fertilizer Administration\nAkshaya et al., 2020 [16] proposed an IOT-based\
    \ technique and upgraded the previous\nsystem, which predicted agricultural yields\
    \ using backpropagation and a random forest\nalgorithm. It recommends fertilizer\
    \ application rates and exclusively monitors atmospheric\ndata via a mobile network\
    \ and pump on/off action. The suggested technique utilizes\na segmented tank to\
    \ collect NPK fertilizer and water. The user can select one of three\nmodes (manual,\
    \ auto, or smart). In manual mode, the user is provided with the fertil-\nizer\
    \ and water ratios for well-known plants and fertilizers. In auto mode, all required\n\
    is to know the plant’s name to select the appropriate fertilizer and water ratio.\
    \ Finally,\nin smart mode, if the user cannot recognize the plant’s name, fertilizer\
    \ ratio, or water,\nthe plant’s name, fertilizer ratio, and water will be recommended\
    \ automatically. The IoT\nmodule will continuously collect information on the\
    \ temperature and soil moisture. The in-\nformation collected will be stored in\
    \ the IoT cloud. The mobile phone will inform you\nwhenever the given data changes\
    \ and the needed fertilizer ratio will be shown on the liquid\ncrystal display.\n\
    2.4. Crop Diseases and Pest Control\nHuman operators frequently monitor insect\
    \ pests via time-consuming and costly on-\nsite inspections, which results in\
    \ low spatial and temporal resolution. Remote monitoring\nhas been possible due\
    \ to advancements in remote sensing, electronics, and informatics.\nMonitoring\
    \ costs and effectiveness can be optimized through the deployment of camera-\n\
    equipped traps. With minimum human intervention, image analysis algorithms can\
    \ locate\nand count insect pests captured in traps automatically.\nReddy et al.,\
    \ 2019 [17] created an IoT-based system for disease and insect pest man-\nagement\
    \ in agriculture and the prediction of plant climatic factors. The integrated\
    \ sensors\nhelp in the measurement of soil and atmospheric moisture and humidity.\
    \ These features\nhelp determine the environmental conditions in which the plant\
    \ ﬂourishes and the plants’\nillnesses. It detects disease on the ﬁeld and sprays\
    \ prescribed insecticides. Web cameras\ntake images that are then preprocessed\
    \ to include RGB to grayscale conversion, defect\ndetection, image scaling, image\
    \ enhancement, and edge detection. SVM is utilized to\ncategorize characteristics\
    \ generated from Citrus Canker diseases, such as energy, kurtosis,\nskewness,\
    \ and entropy (damaged Lemon crop). The Arm7 microcontroller is used for\nhardware,\
    \ power, sensors, and motor driver control. Once the illness is identiﬁed, the\n\
    program will propose fertilizers and transmit the results to an LCD and the recommended\n\
    fertilizers. By pump, the fertilizers will be sprayed on the diseased leaves.\
    \ This study was\nconﬁned to the lemon plant to demonstrate that the same method\
    \ may be used for various\ncrops with favorable outcomes in the future.\nA solution\
    \ is presented for forecasting and detecting grape disease using the CNN\napproach\
    \ and real-time gathered data on environmental factors. First, the CNN technique\n\
    is utilized to analyze the leaf images. Then, different layers of the CNN method\
    \ are used\nto create the image. Finally, it is scaled to a speciﬁc resolution\
    \ before data is sent into\nthe CNN layers for training and testing. The suggested\
    \ algorithm was evaluated on four\ndiseases known to have a higher effect on grape\
    \ production. The diseases include esca\nblack measles, anthracnose, leaf blight,\
    \ and black rot. This gadget not only detects but also\nforecasts illnesses based\
    \ on historical weather data. On the other side, the readings from\nthe humidity,\
    \ temperature, and soil moisture sensors are transferred through Raspberry\nPi\
    \ to Microsoft’s Azure Cloud. Following this, the sensor readings are used to\
    \ anticipate\nthe illness using a trained linear regression model. Based on the\
    \ ﬁndings of the preceding\ndetection and prediction stages, suggestions for appropriate\
    \ fertilizers in the right quantities\nwill be provided to minimize fertilizer\
    \ misuse and cost savings [18].\nTo detect pests in rice during ﬁeld production\
    \ and avoid rice loss, the Internet of Things\nsupported a model-based UAV with\
    \ the Imagga cloud offered. The Internet of Things-based\nUAV was developed on\
    \ AI mechanisms and the Python programming prototype to transmit\nrice disease\
    \ images to the Imagga cloud and supply insect data. The Approach identiﬁes the\n\
    Agronomy 2022, 12, 127\n6 of 21\ndisease and insects by integrating the conﬁdence\
    \ ratings of the labels. The label identiﬁes\nthe objects in the images. To determine\
    \ the pest, the tag with the greatest conﬁdence\nresults and more than or equal\
    \ to the threshold is chosen equal to the target label. If pests\nare discovered\
    \ in the rice, statistics will be transferred to the ﬁeld owner directly to take\n\
    preventative actions. The suggested method is capable of detecting all pests that\
    \ inﬂuence\nrice production. On the other hand, this research attempted to minimize\
    \ rice waste during\nproduction by conducting insect monitoring at regular intervals\
    \ [19]. Table 1 summarizes\nmany current smart agricultural applications.\nTable\
    \ 1. Selected applications based on smart agriculture.\nRef.\nApp\nDescription\n\
    [7]\nSoil Analysis\nLand management offers long-term promise based\non climate,\
    \ geography, and reasonably stable soil\ncharacteristics (like soil texture, depth,\
    \ and\nmineralogy). This application aids farmers in better\nunderstanding the\
    \ potential of their land and climate\nvariations alteration and extenuation measures.\n\
    [9]\nFarm Manager\nFarm Manager App helps the farmers to decide\nwhich techniques\
    \ should apply before planting\nstarts. This app views, organizes, and edits all\n\
    information about your ﬁeld like yield, planting, and\nspraying conditions without\
    \ your mobile phone.\n[7]\nPest Management\nBy collecting pest occurrence information\
    \ from\nfarms, Village Tree provides smart pest control\nsolutions. In addition,\
    \ it employs a crowdsourcing\nstrategy, sending images and location data to other\n\
    farmers who may be affected.\n[9]\nAgrippa\nFarmer can generate electronics maps\
    \ of ﬁeld, keep a\nhistory of growing crops in the ﬁeld (e.g., planting,\nfertilizing,\
    \ harvesting, warehouses, gas station), and\ntrack the location of objects in\
    \ the ﬁeld (e.g., soil\nsampling for agrochemical laboratory) by eFarmer\nApplication.\n\
    Semios\nCovers network coverage, orchard pests, frost,\ndiseases, and irrigation.\
    \ Event notiﬁcations are sent\nout in real-time as part of the monitoring services.\n\
    [7]\nFertilizer\nManagement\nEco Fert assists with fertilizer management so that\
    \ it\nmay be used to its full potential. It determines the\noptimal fertilizer\
    \ mixture created to cover the\nneeded nutrient suspension and considers the\n\
    demands of diverse yields. In addition, it considers\nthe cost of fertilizer based\
    \ on current market pricing.\n2.5. Yield Monitoring, Forecasting and Harvesting\n\
    The AWS IoT platform has been proposed for crop prediction using temperature and\n\
    rainfall monitoring. The Raspberry Pi is utilized as a gateway for remote monitoring\
    \ in this\nstudy. Raspberry Pi can connect with sensors to operate applications,\
    \ such as the DHT11\nTemperature Sensor and Soil Moisture Sensor, which forecasts\
    \ temperature and rainfall\nranges. The gateway is integrated with Amazon Web\
    \ Services’ (AWS) IoT platform. MQTT\nis a messaging protocol that allows for\
    \ various messages across distant connections [20].\nThe study reported establishing\
    \ an autonomous greenhouse smart aquaponics man-\nagement organized on temperature\
    \ via the use of an Android-based monitoring and\nautomatic correction system\
    \ and a Raspberry Pi-based plant growth monitoring system.\nReal-time data is\
    \ collected using the light intensity sensor and the ambient temperature\nand\
    \ humidity sensors. Additionally, the pH and temperature of the recirculating\
    \ water\nare monitored. Suppose the data acquired is beyond the threshold range.\
    \ In this case, the\nAgronomy 2022, 12, 127\n7 of 21\nsystem quickly engages the\
    \ correction devices, which comprise a peristaltic buffer device,\nan aerator,\
    \ an evaporative cooler, inlet and exhaust fans, and grow lights. The internet\n\
    remote access function enables real-time data transmission and receipt through\
    \ the android\napp amongst the smartphone and computer system. This study compared\
    \ plant devel-\nopment in smart aquaponics to traditional agriculture based on\
    \ soil systems employing\nimage processing in two investigational operations.\
    \ Following record collection, it was\ndetermined that the smart aquaponics system\
    \ achieved greater output than conventional\nagriculture monitoring. As lettuce,\
    \ mustard greens, and pak choi are produced in a smart\naquaponics system vs.\
    \ traditional soil-based farming, this study focused exclusively on\nlettuce,\
    \ mustard greens, and pak choi [21].\nA tree topology was used for the WSN-enabled\
    \ agricultural monitoring system to\nimprove performance. A cheap sensor node\
    \ like a commercial sensor or a NodeMCU\nmodule transmits data to the control\
    \ unit over Wi-Fi. Fertilizer, fertigation improvement,\nand agricultural operations\
    \ are monitored by data processing and thresholding. The in-\ncorporation of cost-effective\
    \ ICT technology with traditional crop management or weather\nmonitoring and sensor\
    \ data created the agronomic model. Minimal environmental impact\nfrom crop growing\
    \ was achieved as a consequence of large fertilizer and water savings [22].\n\
    2.6. Climate Conditions Monitoring\nIn farming, the weather is extremely important.\
    \ Incorrect climate knowledge can\nhave an impact on crop quality and quantity.\
    \ On the other hand, farmers may use IoT\nsolutions to put sensors in the ﬁeld,\
    \ including humidity sensors, temperature sensors,\nrainfall sensors, and water\
    \ level sensors, to collect real-time data from the environment.\nThese sensors\
    \ monitor the state of crops and the environment in which they grow. If a\nworrying\
    \ environmental situation is discovered, it is either automatically corrected\
    \ or a\nwarning is sent to the farmer.\nGreenhouses created an Internet of Things-based\
    \ weather station to address the cost\nand accuracy issues. The TI CC2650 Sensor\
    \ Tag and IBM Cloud Platform continuously\nmonitor weather and abiotic factors,\
    \ transfer the detected values to the cloud, and send\ne-mail notiﬁcations when\
    \ values deviate. As a result, this study may be expanded to\ninclude the use\
    \ of ML model-based classiﬁcation training to categorize a plant’s health as\n\
    excellent, moderate, or terrible based on the average temperature, humidity, light\
    \ intensity,\nand air pressure. This would help to clarify abstracts about a plant’s\
    \ health to a larger level\nand might aid in keeping the plants’ health in good\
    \ shape [23].\nArifﬁn et al. [24] used an autonomous temperature control system\
    \ to address the\ndrawbacks of traditional growing methods, which are expensive,\
    \ have low yields, and\nneed a lot of care. The suggested IoT-based architecture\
    \ was evaluated in a real-world\nsetting at the Bandar Puteri Centre of NASOM\
    \ (National Autism Society of Malaysia).\nThe ideal temperature for oyster mushrooms\
    \ is between 20 and 30 ◦C, with a humidity\nlevel of 70 to 80%. Two sensors were\
    \ installed in the mushroom house’s center and corner\nto detect temperature and\
    \ moisture, then communicated to a remote monitoring station\nthrough a microcontroller\
    \ unit for further action. The results of the six-day experiment\nrevealed that\
    \ an effective automatic monitoring system, which can regulate the farm’s\nhome\
    \ while reducing resources and human labor, was developed. The mushroom home,\n\
    IoT control box, and Web Client interface were all designed within the system.\
    \ As a result,\nthe mushroom house provided a regulated environment for mushroom\
    \ growing as well as\nprotection from pests and insects. The climate control system,\
    \ which automates controlling\nthe ideal environment for oyster mushroom production,\
    \ was housed in the IoT control box.\n3. Major Equipment and Technologies\nMajor\
    \ equipment and IoT technologies are fully demonstrated in the next subsections,\n\
    such as various sensors, agricultural drones, and harvesting robots.\nAgronomy\
    \ 2022, 12, 127\n8 of 21\n3.1. Sensors\nThe visual sensor, multispectral sensor,\
    \ thermal sensor, lidar sensor, and hyperspectral\nsensor are only a few of the\
    \ sensors utilized in IoT-based smart agriculture and drone\ntechnologies. Current\
    \ IoT-based sensor applications in smart agriculture are presented in\nTable 2.\n\
    Table 2. IoT-based sensors in smart agriculture used to increase production.\n\
    Sensors\nOperations of Different Sensors\nDHT11 Sensor:\nDHT11 sensor measures\
    \ temperature and humidity\n[12].\nSEN0193: Soil Moisture Sensor\nSEN0193 is a\
    \ Soil Moisture Sensor. The dielectric\npermittivity of soil is a consequence\
    \ of its moisture\ncontent. The sensor generates a voltage proportional\nto the\
    \ dielectric permittivity of the soil and hence to\nits water content. The sensor\
    \ takes an average of the\nwater content over its whole length. The Soil\nMoisture\
    \ Sensor is used to quantify moisture loss\nover time due to plant absorption\
    \ and evaporation,\ndetermine optimal soil moisture information for\ndifferent\
    \ plant species, monitor soil moisture\ninformation in greenhouses to regulate\
    \ irrigation,\nand optimize bottle biology research. [20].\nTurbidity Sensor SKU\
    \ SEN0189:\nThe turbidity sensor determines the quality of water\nby detecting\
    \ its turbidity level. It detects suspended\nparticles in water using light by\
    \ measuring the light\ntransmittance and scattering rate, which vary the\nquantity\
    \ of total suspended solids (TSS) in the water\n[25].\nMH-Z14A:\nThis is used\
    \ to monitor the CO2 level at high\nprecision.\nBH1750:\nThis is used to monitor\
    \ the light intensity level (as\nphotosynthesis is related to light intensity)\
    \ and to\nconduct experiments on the inﬂuence of light\nintensity on the greenhouse\
    \ environment’s\ntemperature [26].\nRain sensor:\nA rain sensor is a simple instrument\
    \ for detecting\nrain pressure. It may be used as a switch to\ndetermine the strength\
    \ of rainfall when a raindrop\nfalls through the rainy board [27,28].\nLidar sensor:\n\
    The top camera sensor is an imaging range camera\nthat estimates the distance\
    \ between the camera and\nthe subject at each point in the collected images [29].\n\
    3.2. Agricultural Drones\nUAVs can monitor the health of crops, apply pesticides,\
    \ and take hyperspectral images\nin precision agriculture. Drones can scan a crop\
    \ for issues in plants using visible and\nnear-infrared light, and they can determine\
    \ which plants reﬂect what quantities of green\nand NIR light. Photosynthetic\
    \ activity diminishes when a plant is stressed. This data may\nbe used to create\
    \ numerous images that track plant changes and indicate their health. As a\nresult,\
    \ farmers can more accurately administer treatments after a disease has been identiﬁed.\n\
    Drones are also utilized for surveillance, trafﬁc monitoring, and weather monitoring\
    \ in\nagriculture. Drone technology employs various sensors, including optical,\
    \ multispectral,\nthermal, lidar, and hyperspectral sensors, which are brieﬂy\
    \ detailed in Section 3.1.\nCrop management has beneﬁted from the Internet of\
    \ Things, remote sensing, and\nanalytic data approaches. Pests may be identiﬁed,\
    \ targeted, and managed to utilize remote\nAgronomy 2022, 12, 127\n9 of 21\nsensing\
    \ using UAVs. UAVs can ﬂy in tough and harsh terrains to take high-resolution\n\
    images that allow pests to be identiﬁed and controlled. Many crop security concerns\
    \ may\nbe solved using UAVs equipped with cameras, which are not possible with\
    \ traditional pest\nmanagement methods. UAVs have been used to automate insect\
    \ damage in agricultural\nareas [30,31].\nAn automated rotating device based on\
    \ sun illumination angle perception keeps the\nsolar panel perpendicular to the\
    \ sun and increases solar energy harvesting rates. Based on\nspectrum analysis\
    \ technology, Internet of Things approaches, including several wireless\ntechnologies,\
    \ such as TVWS, ZigBee, and LoRa, are suggested to collect data and send it\n\
    to a base station/gateway to assess the degree of damage caused by pests and diseases.\n\
    In addition, a technique for maximizing wind force usage and to extend the time\
    \ of ﬂight for\ndrones has been established to support drones in downwind by designing\
    \ the ﬂying path\nimplementation. The study’s scope is limited, with the goal\
    \ of developing a long-standing\ninsect and disease detection technique through\
    \ extensive data gathering and analysis.\nThe suggested model will be tested in\
    \ real-world scenarios. For example, crop diseases\nand insects might be tracked\
    \ in real-time and climatic changes could be analyzed [32].\nThe Internet of Things-based\
    \ approach is illustrated for smart agriculture monitoring in\nFigure 3.\nFigure\
    \ 3. IOT-based smart agriculture monitoring system.\n3.3. Harvesting Robots\n\
    Under speciﬁc climatic circumstances, a harvesting robot is intended to gather\
    \ fruits\nautonomously. The advancement of vision-based harvesting robots’ mechanism\
    \ is yet in its\nearly stages. Agricultural robotic systems, on the other hand,\
    \ have comparable architecture.\nThe system is comprised of an autonomous mobile\
    \ platform, a lightweight mechanical\narm with multiple degrees of freedom, an\
    \ adaptable end effector for a power response\nsystem, a multi-sensor machine\
    \ vision system, a smart decision and drive management\nsystem, and supplementary\
    \ hardware and software [33]. Kang et al., 2020 [34] developed\nan intense neural\
    \ network to assist robotic apple harvesting, which detects and grasps\nfruit\
    \ in a real-time environment using a computer vision system. The proposed robotic\n\
    harvesting system was implemented using a customized soft end-effector comprised\
    \ of\nIntel i7-6700 CPU and NVIDIA GTX-1070 GPU and DELL-INSPIRATION main computer\n\
    unit, Intel D-435 RGBD visualization camera, and UR5 Universal Robot (modern robotic\n\
    manipulator). The proposed approach uses Mobile-DasNet, a computationally efﬁcient\n\
    lightweight one-stage instance segmentation network to conduct fruit recognition\
    \ and\ninstance segmentation on sensory input. An improved PointNet model was\
    \ also developed\nto conduct fruit modeling and grip estimates from an RGB-D camera\
    \ through the point\nclouds technique. The two qualities described above were\
    \ utilized and integrated to\nAgronomy 2022, 12, 127\n10 of 21\ndevelop and build\
    \ a precise robotic system for autonomous fruit picking. The goal of the\nstudy\
    \ was to improve the vision algorithm’s performance, boost, and improvements.\n\
    Furthermore, the proposed soft end-effector robotic device may improve its grasping\n\
    recognition proportion and effectiveness under various situations. Ogorodnikova\
    \ and\nAli [35] devised a technique for recognizing ripe tomatoes in a greenhouse\
    \ setting using a\nmachine vision system of a harvesting robot. To effectively\
    \ execute the suggested image\nprocessing method for this purpose, RGB color images\
    \ from a typical digital camera are\nrequired. In the second stage, RGB color\
    \ images are converted to HSV, which is easier\nfor extracting red tomato from\
    \ the green backdrop in the image. Image segmentation,\nthresholding, and morphological\
    \ operations separate a red tomato from a green background\ncolor photograph.\
    \ The algorithm is built using Matlab methods and then evaluated to see\nif it\
    \ produces favorable results. The process can be converted into fast-acting codes\
    \ for the\nharvesting robot’s controller since it is basic and short. The research\
    \ is limited to moving\nthe gripper to the proper place in tomato detection and\
    \ developing efﬁcient algorithms\nusing 3D gripper models to transform the existing\
    \ research system into industrial robots.\nOnly a few robotic devices that can\
    \ successfully perform watering, planting, and\nweeding activities now exist.\
    \ FaRo (Cultivating RObot), a new smart robot based on a CNC\nmachine, has been\
    \ presented for automatic crop farming deprived of human involvement in\nagriculture.\
    \ What sets FaRo apart from other farming platforms is its capability to complete\n\
    the entire farming cycle, from sowing to harvesting. In addition, the FaRo harvesting\n\
    tool will be discussed and shown. FarmBot can only be used for a limited time,\
    \ from\nsowing to harvesting, after which the robot’s tool mount system will be\
    \ exchanged for crop\nharvest. In this example, the robot assumes the role of\
    \ a tomato collector. Both the FaRo\nharvesting robot and the unique kinematics\
    \ of the continuum manipulator design were\nthoroughly discussed. Due to implementation\
    \ problems, the robot’s design is currently in\nthe development stage. The objective\
    \ of the proposed system is to build a model with an\nintelligent agricultural\
    \ monitoring technique linked to the main database, and the robot\nwill have sufﬁcient\
    \ information to plant and cultivate crops without the need for human\nintervention\
    \ [36].\nA depth vision-based approach for detecting and placing truck containers\
    \ is proposed\nfor the joint harvesting system, along with three coordinate systems.\
    \ This method included\ndata preprocessing, point cloud poses transformation using\
    \ the SVD (singular value decom-\nposition) algorithm, upper edge segmentation\
    \ and projection, RANSAC (Random Sample\nConsensus) algorithm edge line extraction\
    \ and corner point positioning, and fusion and\nvisualization of results on the\
    \ depth image. Field trials show that the suggested approach\nis effective in\
    \ identifying and positioning vehicles. However, the study is restricted due\n\
    to its sensitivity to the appearance of truck containers and the presence of loud\
    \ sites in\nthe agricultural area. Autonomous driving and path planning in the\
    \ forage harvester’s\nunloading system is still challenging [37].\nIntelligent\
    \ robots have become extensively employed in various sectors as the in-\ntelligent\
    \ computer industry with automation expands. Currently, manual labor is still\n\
    used to harvest the majority of domestic crops. However, owing to constant worker\
    \ pay\nhikes, the manual picking technique increases the fruit farmer’s ﬁnancial\
    \ expenditures,\nand the appliances of robots in the farming business are challenging.\
    \ As a result, the\nsmart moveable robot picker has been introduced based on computer\
    \ vision machinery by\nincorporating the robot arm, selector, ﬂexible carrier,\
    \ track procedure, and the intelligence\nunit, which accomplishes the robot picker’s\
    \ travel channel coding, auto-judging the ripe\nfruit, and in addition a vision-based\
    \ binocular stereoscopic methodology employed for the\nfunctions of recognition\
    \ and placement. To begin with, precise segmentation recognition\nand maturity\
    \ evaluation of the target fruit is required for proper picking. Thus, the robot\n\
    picker may potentially replace human labor in manual picking. The most important\
    \ part\nof the recognition process is gathering fruit image samples, which is\
    \ performed using a\nCCD camera that shoots following the preprocessed fruit features\
    \ using image content.\nThe color model is then built up, and it separates the\
    \ fruit and surrounding surroundings\nusing segmentation technology before recognizing\
    \ the fruit. Additionally, it precisely traces\nAgronomy 2022, 12, 127\n11 of\
    \ 21\nand goes for the fruit location in relation to the three-dimensional coordinate\
    \ information\nprovided by the infrared source and the fruit contour and image\
    \ differences taken by\nthe two cameras simultaneously. To ﬁnish the picking operation,\
    \ it must program the\npath recognition to avoid the obstacle [38]. The overall\
    \ architecture of IoT-based fruit\nidentiﬁcation for harvesting is shown in Figure\
    \ 4.\nFigure 4. General architecture of IoT-based fruit detection for harvesting.\n\
    4. Open Issues and Key Challenges in Smart Agriculture\nThe problems of deploying\
    \ IoT-based agricultural systems are discussed in this section.\nThe sensors’\
    \ durability and cost are described. The IoT-based system requires a constant\n\
    source of electricity. Depending on the size, a lot of electricity may be required.\
    \ However,\nin rural and village communities, obtaining such electricity is challenging.\
    \ To meet the\nenergy requirement, alternative energy sources, such as solar and\
    \ wind, must be employed.\nThis will also raise the price signiﬁcantly. It is\
    \ necessary to have a dependable internet\nconnection in rural and village regions.\
    \ It is the most crucial aspect of establishing an\nIoT-based system. The connection\
    \ must have a sufﬁcient bandwidth to transport data in\naccordance with the application’s\
    \ requirements. Farmers need basic computer/tablet (HID\ndevice) training and\
    \ an understanding of how the IoT system operates. It is also necessary\nto provide\
    \ proper education on the unique IoT deployment in their farm [39].\nThere are\
    \ six major obstacles to developing a green IoT-based agriculture system,\ninvolving\
    \ infrastructure, mobility, maintenance, hardware, data privacy, data analytics,\
    \ and\ndata security. The selection of meters and sensors used for Internet of\
    \ Things tools is one\nof the hardware issues. As a result, many different sensors\
    \ may be utilized in Internet of\nThings applications, such as the water quality\
    \ sensor, humidity sensor, chemical sensor,\npressure sensor, temperature sensor,\
    \ and more. The data analytics problem is machine\nlearning, deep learning methods,\
    \ and prediction algorithm applications in smart agricul-\nture to produce a nutritional\
    \ suspension using IoT records. Routine sensor inspections\nof all Internet of\
    \ Things appliances are a maintenance issue while it may be certainly\nharmed\
    \ in the farm area. The mobility problem is related to 4G, 5G, WiFi, 6LowPan,\
    \ LoRa\nnetwork connection, which link sensors spread across a broad region in\
    \ the farm areas.\nSome infrastructural trials are developing and implementing\
    \ Internet of Things-connected\narchitectures that incorporate innovative technologies,\
    \ such as cloud and fog computing\nand network virtualization. Finally, the primary\
    \ issue in advancing smart agriculture based\non IoT is not physical maintenance\
    \ but rather ensuring security and privacy [8].\nAgronomy 2022, 12, 127\n12 of\
    \ 21\nThe UAVs that are linked wirelessly are subject to cyber-physical or harmful\
    \ assaults\nto fool the control signals due to open communication lines. Such\
    \ attempts represent a\nsigniﬁcant risk to the unmanned aerial vehicle system\
    \ in terms of private information\ncrash or theft, as well as mission failure.\
    \ Moreover, the faking of control signals may harm\nthe UAV mission and make it\
    \ harder to restore it. As a result, improving UAV wireless\ncommunication’s safety\
    \ and conﬁdentiality element, which necessitates in-depth research\nof security\
    \ concerns covering the entire network protocol layers [40], is an important\n\
    open subject.\nVisual harvesting of robots’ dynamic tracking of objects with great\
    \ precision remains\nan unresolved challenge. Further study should also aim to\
    \ enhance the precision placement\nand operation by merging smart behavior judgment,\
    \ adequate fault tolerance, robot vision\nwith artiﬁcial intelligence technology\
    \ for accurate placement, and function enhancement.\nThe recognition and location\
    \ accuracy are impacted when the crop situation is varied due\nto the lighting\
    \ and unconstrained circumstances of the ﬁeld ecosystem. A robot vision\napproach\
    \ would be efﬁcient in harvesting crops correctly to increase the success rate\
    \ of\nrobotic harvesting in such settings. The researchers used geometric features,\
    \ novel image\nalgorithms, and intelligent decision theory to address the challenges.\
    \ However, because\nmassive datasets are necessary to train efﬁcient deep learning\
    \ algorithms, further study\nis needed [33]. Table 3 presents a comparison of\
    \ the current state of the art on smart\nagriculture obstacles and beneﬁts.\n\
    Table 3. Research studies organized by goal, methodologies, and technology employed,\
    \ as well as\nobstacles and beneﬁts.\nAuthors\nResearch Purpose\nTechnology\n\
    Used/Techniques\nFindings and Challenges\nAdvantages\n[13]\nWater management\n\
    Bluetooth, Wi-Fi, RFID,\nZigbee, Raspberry pi\nHuman interaction\nLabor cost\n\
    Water consumption\nCrop from irregular\nirrigation.\nCan identify the moisture,\n\
    humidity, and temperature.\nConsistent management of\nall the regions containing\n\
    severe parts.\n[14]\nIrrigation monitoring\nWSN, data\nAnalytics, node sensors\n\
    and web\nApplication\n-\nOptimal irrigation of the\nwater for\nfarming crops.\n\
    [20]\nCrop management\nIrrigation\nmanagement\nMobile technology,\nGPRS, Wi-Fi,\
    \ Raspberry\npi, Zig Bee\nUnstable weather\nwater shortage, irregular\nwater usage\n\
    Improve the yield, low cost\n[38]\nHarvesting nodes\nWSN, Solar\nenergy system.\
    \ Image\nprocessing technique.\n-\nPrevents data loss and\ncollusion,\nincreases\
    \ the lifetime of\nWSN.\n[41]\nCrop growth\ngreen-crop gCrop\nbased on ML model,\n\
    Wireless Sensor\nNetwork and Internet\nof Things\nObtained accuracy was\n98% using\
    \ polynomial of\nthird-degree of Regression\nmodel while the\ncomputation time\
    \ is very\nhigh.\n-\n[42]\nNutrient\nManagement\nRaspberry pi\nMobile technology\n\
    Wi-Fi\nLow or high watering.\nLack of nutrition\nmanagement.\nCan monitor weather\n\
    conditions.\nCost-effective\nAutomatically monitored\ndisease associated with\
    \ rice\nspecies.\nAgronomy 2022, 12, 127\n13 of 21\nTable 3. Cont.\nAuthors\n\
    Research Purpose\nTechnology\nUsed/Techniques\nFindings and Challenges\nAdvantages\n\
    [43]\nCrop Productivity\nBig data\nstorage and analytics,\nIoT, Data\nMining,\
    \ Cloud\ncomputing, Data\nAnalytics.\n-\nNetwork architecture,\nplatform\nand\
    \ design helps access to\nIoT,\nimproves crop productivity,\nProvides an overview\
    \ of\nIoT\napplications, sensors,\nprotocols\nAnd data-enabled\ntechnologies.\n\
    One of the most challenging aspects of robotic grasping is estimation. Traditional\n\
    techniques have limitations since noise or partial loss of the point cloud might\
    \ impact the\nestimation’s accuracy and resilience. Estimation is more difﬁcult\
    \ in orchard situations than\nit was in interior environments.\nData Handling\
    \ and Processing\nTraditional vision algorithms’ performance is constantly restricted\
    \ in complicated\nand volatile settings [34]. World food consumption is predicted\
    \ to treble by 2050 due to\npopulation expansion and societal progress, yet increasing\
    \ food production is now difﬁcult\ndue to declining water, climate alterations,\
    \ less proper soil, and insects and illnesses. Pests\nand diseases have always\
    \ been signiﬁcant stumbling blocks to increased grain output.\nSatellite technology\
    \ is climate sensitive and has a limited illumination variation, making it\nchallenging\
    \ to satisfy the requirement for insects and infection management in farming\n\
    areas. Currently, low-altitude autonomous drones (offering excellent ﬂexibility\
    \ and image\nresolution) can satisfy the needs of agricultural insect and infection\
    \ management. In some\ncircumstances, such as when there is a high wind, drone\
    \ stability might be difﬁcult. As a\nresult, the drone’s ﬂight route must be designed\
    \ in conjunction with the actual conditions.\nLong ﬂights are necessary for ﬁeld\
    \ pest and disease data collection; thus, choosing a sunny\nday with a moderate\
    \ breeze might be a viable alternative [32]. Identifying malicious and\ncompromised\
    \ nodes among soil sensors interacting with the base station is a signiﬁcant\n\
    problem in the base station to cloud communications. The trust management method\
    \ is\npresented as one of the options for identifying these nodes in a lightweight\
    \ manner.\nFinally, the study highlighted the existing problems and possibilities\
    \ and future re-\nsearch in vegetable and fruit identiﬁcation and placement. The\
    \ majority of previous research\nshowed that illumination variations, grouping,\
    \ and unconstrained situations have been the\nmain obstacles to effective recognition\
    \ and localization of vegetables and fruits in the ﬁeld.\nFurther research will\
    \ be required to overcome the existing state-of-the-art challenges and\nenhance\
    \ the performance, accuracy, efﬁciency, effectiveness, recognition, and success\
    \ rate\nof controlling and image processing techniques. However, fruit recognition,\
    \ detection, posi-\ntioning, harvesting robots, and application robustness enhancement\
    \ need to minimize the\ninclusive computational cost and time. Future research\
    \ might include algorithms and cam-\nera operation advancements, sensor platforms\
    \ that can enhance illumination consistently,\nhorticultural changes, and human–machine\
    \ collaboration [29]. Furthermore, sophisticated\nmethodologies, algorithms, and\
    \ computational approaches are necessary to address the\nlack of precision in\
    \ harvesting operations.\n5. Discussion and Analysis\nIt is estimated that plant\
    \ diseases are a signiﬁcant contributor to global ﬁnancial\ndeﬁcits. Numerous\
    \ abiotic and biotic stresses and continual tension monitoring concerns\nthe impacts\
    \ of the loss of fruit-producing plants. Consequently, the $15 billion U.S. apple\n\
    Agronomy 2022, 12, 127\n14 of 21\nindustry loses millions of dollars every year.\
    \ Fruits are one of the most signiﬁcant sources\nof nutrients in plants; yet,\
    \ illnesses, pests, fungous, infectious, and microbial diseases all\naffect the\
    \ quality and quantity of fruits. Using computer vision-based methods, the issue\n\
    may now be alleviated. Diseases/infections may be detected early and effectively\
    \ using\nthese methods.\nThe sickness classiﬁcation of various fruit leaves was\
    \ achieved using a deep convolu-\ntional neural network DCNN approach. The deep\
    \ features are retrieved by ﬁrst utilizing\ndeep learning networks, such as AlexNet\
    \ and VGG-s, and then tweaked using a transfer\nlearning approach. Before the\
    \ selection step, a multi-level fusion strategy is offered, and\nthe chosen features\
    \ analyzed to produce the entropy basis features. To categorize the\nobtained\
    \ feature map, we employed a multi-SVM classiﬁer. The diseases investigated in\n\
    the experiments include apple rust, scab, black rot, peach bacterial spots, and\
    \ cherry pow-\ndery mildew, and they were all gathered from a plant village dataset.\
    \ The recommended\nmethod’s better performance in terms of a 97.8% accuracy, 97.6%\
    \ sensitivity, 97.6% precision,\nand G-measure was observed in the classiﬁcation\
    \ results (97.6%) [44]. Some research has\ninvestigated whether computer vision\
    \ approaches may be employed for scalable and early\nplant sickness detection.\
    \ There is still a critical lack of non-lab data sets that can be utilized\nto\
    \ allow vision-based plant disease detection. For visual plant disease identiﬁcation,\
    \ the\nPlantDoc dataset was supplied. The collection has 2598 data points in total,\
    \ encompassing\n13 plant species and up to 17 disease categories, and was developed\
    \ by annotating internet-\nscraped photos for 300 human hours. Three models for\
    \ plant disease classiﬁcation were\ntrained to illustrate the dataset’s effectiveness.\
    \ The ﬁndings demonstrate that employing\nour dataset models may enhance the recognition\
    \ rate by up to 31%. The recommended\ndataset, we feel, will contribute to decreasing\
    \ the entry barrier for computer vision algo-\nrithms in plant disease detection.\
    \ For photos featuring leaves from various classes in a\ndataset with contextual\
    \ noise, and low-resolution leaf images, the model fails to give proper\nconclusions.\
    \ Using image segmentation methods to extract leaves from the photos can\nboost\
    \ the dataset’s utility. Although the dataset has been rigorously veriﬁed, particular\n\
    photographs in the collection may be wrongly labeled owing to a lack of sufﬁcient\
    \ topic\nknowledge [45].\nIt is necessary to construct an improved VGG16-based\
    \ DCNN model to detect apple\nleaf diseases (scab, frogeye spots, and cedar rust).\
    \ The global average pooling layer re-\nplaces the fully connected layer to lessen\
    \ restrictions and a batch normalization layer is\nattached to boost the model’s\
    \ computational performance. Furthermore, to avoid a long\ntraining time, a transfer\
    \ learning approach is applied. To detect apple leaf diseases, the\nsuggested\
    \ model makes use of 2446 apple leaves, 2141 photos in the training phase and\
    \ 305\nimages in the testing phase. The experimental data reveal that utilizing\
    \ the recommended\napproach, the total accuracy of apple leaf classiﬁcation may\
    \ reach 99.01%. Furthermore,\nthe ﬁndings demonstrate that cedar rust is accurately\
    \ diagnosed, but one healthy person is\nmisclassiﬁed as scab and the other as\
    \ frogeye spots.\nFurthermore, the model parameters are cut by 89% compared to\
    \ the standard VGG16.\nAs a result, the classiﬁcation performance is raised by\
    \ 6.3%, and the computational com-\nplexity is cut to 0.56% of the innovative\
    \ model. Consequently, the DCNN model developed\nin this study provides a more\
    \ accurate and speedier way for recognizing apple leaf infec-\ntions [46]. Table\
    \ 4 compares the efﬁciency of several smart agricultural techniques.\nAgronomy\
    \ 2022, 12, 127\n15 of 21\nTable 4. Comparative analysis of different methods\
    \ based on smart agriculture.\nRef.\nTechnique Dataset\nDisease Classes\nAccuracy\n\
    Sensitivity\nPrecision\nRecall\nF1 Mea-\nsure\nG Mea-\nsure\n[44]\nDCNN\n[VGG\
    \ +\nAlexNet]\nplant\nvillage\ndataset\n5 (apple rust, scab\nblack rot, cherry\n\
    powdery mildew, and\npeach bacterial spots)\n97.8%\n97.6%\n97.6%\n-\n-\n97.6%\n\
    [46]\nDCNN\n[en-\nhanced\nVGG16]\n2446\napple\nleaves\n4 (apple leaf diseases\n\
    (Scab, frogeye spots,\ncedar rust and healthy)\n99.01%\n-\n99.02%\n99.02%\n99.02%\n\
    -\n[47]\nenhanced\nCNN\n[AlexNet]\nEnhanced\nPlant\nVillage\n52\n99.11%\n-\n99.49%\n\
    99.11%\n99.29%\n-\n[48]\nIoT\n[WSNs\n+ ML\nalgo-\nrithms]\nDifferent\ndata\n-\n\
    81.6%\n-\n-\n-\n-\n-\n[49]\nAlexNet\ndeep\nlearning\nalgo-\nrithm\n54,306\nimages\n\
    14 crop species and 26\ndiseases\n97.38%\n-\n97.42%\n97.37%\n97.36%\n[50]\nLeNet\n\
    DL tech-\nnique\n(X-\nFideo)\nPlantVillage\n3\n98.60%\n-\n98.82%\n97.18%\n96.89%\n\
    -\nFor the recognition and detection of olive diseases, such as peacock spot,\
    \ anthracnose,\nand canker, an improved convolutional neural network (CNN) dubbed\
    \ AlexNet was\nsuggested. Several innovations separate the proposed model from\
    \ others. It uses effective\nintelligent data preprocessing with a stable image\
    \ in each class, a transfer learning approach,\nand an extended and upgraded PlantVillage\
    \ dataset to work in more complicated situations.\nThe total accuracy of the suggested\
    \ technique is 99.11%, which is the best possible score.\nFurthermore, it possesses\
    \ precision, recall, and F1 measures of 99.49%, 99.11%, and 99.29%,\nrespectively.\
    \ Despite the fact that model training takes a long time, classiﬁcation during\n\
    testing takes only a few seconds on a CPU [47]. Citrus fruits, leaves, and stems\
    \ are included\nin the image dataset. The collection contains images of normal\
    \ and diseased citrus leaves\nand fruits, including greening, scab, blackspot,\
    \ canker, and melanosis. There are 759 images\nof normal and abnormal citrus leaves\
    \ and fruits in the data collection. The images had\na resolution of 5202 × 3465\
    \ (Mpix), and when scaled at 72 dpi, the width and height\nwere 256 × 256 pixels,\
    \ correspondingly. The contaminated images were divided into four\nvarious citrus\
    \ illnesses and left on their own. The entire process consists of four major\n\
    steps: (a) enhancing the dataset using Top-hat and then Gaussian functions; (b)\
    \ weighted\nsegmentation and segmentation of lesion through a saliency map, which\
    \ highlights the\ninfested area; (c) color, texture, and geometric feature extraction\
    \ from the diseased area;\nand (d) PCA, skewness, and entropy-based feature selection\
    \ and implementation.\nAgriculture management, water contamination, and air quality\
    \ analysis monitoring\nsystems were all investigated as part of the smart environment\
    \ monitoring (SEM) system.\nFigure 5 demonstrates that substantial investigation\
    \ of smart environment monitoring\nhas increased over the period in both cases,\
    \ speciﬁcally research involving the wireless\nsensor network and Internet of\
    \ Things along with research involving machine learning and\nInternet of Things\
    \ [41,51].\nAgronomy 2022, 12, 127\n16 of 21\nFigure 5. Research contribution\
    \ using IoT, WSN, and machine learning.\nImperfect network access, lack of a (or\
    \ no) power supply, and high framework costs\ncompared to an ordinary farmer’s\
    \ income were presented in a low-cost, energy-proﬁcient,\nprotected, dependable,\
    \ and heterogeneous three-layer approach for Internet of Things-\nbased smart\
    \ agriculture. IoT devices make up the ﬁrst layer, including IoT-based smart\n\
    agriculture monitoring like insect detection, theft detection, crop monitoring,\
    \ smart ir-\nrigation, smart poultry, food supply chain, and food preservation\
    \ monitoring systems.\nThe low-power LoRaWAN network connects the IoT devices\
    \ to the gateways. The next\nlayer is made up of local processing servers and\
    \ gateways that are connected with the\ngateways. The cloud layer, which uses\
    \ the publicly available FIWARE framework to offer a\nset of open-source API standards,\
    \ is the third layer. This study aimed to create diagnostic\ntechniques for packet\
    \ combination procedures at the fog node before they were sent over\nthe network\
    \ facility to cloud servers. This aims to decrease short IoT packet processing\n\
    overheads and optimize energy usage at the backbone, as billions of IoT devices\
    \ linked to\nfog nodes are projected to generate massive volumes of short IoT\
    \ packets [52].\nA Cuckoo Search Algorithm has been created, allowing water allocated\
    \ for farming\nunder all situations. Temperature, turbidity, pH, and moisture\
    \ were collected utilizing the\nInternet of Things (IoT) infrastructure outﬁtted\
    \ with wireless communication devices and\nsensors. ThingSpeak presented the sensor\
    \ data in the cloud system in this IoT platform.\nThe ThingSpeak data was utilized\
    \ in the suggested Cuckoo Search Algorithm, which\nidentiﬁed suitable yields for\
    \ a given soil [53]. Incorrect or late identiﬁcation can result in\noveruse or\
    \ underuse of chemicals, resulting in higher production costs and environmental\n\
    and health consequences. With varied lighting, angles, surfaces, noise, and high\
    \ resolutions,\n3651 real-time indication images of various apple infections were\
    \ manually collected.\nA subset of this dataset was labeled by experts, such as\
    \ cedar apple rust, scab, and normal\nleaves, and open-sourced for the Plant Pathology\
    \ Challenge to Kaggle community. We also\nused this data to train a standard CNN\
    \ (convolutional neural network), which obtained\n97% recognition on a held-out\
    \ test set and a maximum AUC value of 0.986. The project’s\ngoal was to keep adding\
    \ additional images to the pilot dataset from various perspectives,\nlighting,\
    \ and distances to create a bigger more complete labeled database by experts.\n\
    The dataset will contain pests and diseases, such as apple mites and aphids and\
    \ apple\nleaves comprising apple marssonina and alternaria leaf blotch, leaf spot,\
    \ frogeye, rot, cedar,\nand powdery mildew, ﬁre blight, and scab-labeled images.\n\
    Additionally, it will be photographed and remarked on fruit infected with apple\
    \ brown\nrot, bitter rot, or scab [54]. An Internet of Things-based cost-effective\
    \ monitoring system\nwas developed to address particular crop irrigation, soil\
    \ erosion, and irregular irrigation.\nAgronomy 2022, 12, 127\n17 of 21\nThe suggested\
    \ method entails building a distributed WSN (wireless sensor network), with\n\
    multiple sensor modules covering each part of the farm and transferring data to\
    \ a central\nserver. ML techniques will aid irrigation pattern forecasts based\
    \ on yields and climate\nenvironments. According to a comparison of several algorithms,\
    \ random forest regression\nhas a decent accuracy of 81.6%. However, due to harsh\
    \ weather conditions, the system\nis constrained in many ways: the forecast accuracy\
    \ is dependent on the setup’s correct\ninstallation, and the threat of wild animals\
    \ can harm the hardware setup [48]. Because\nhuman abilities and agricultural\
    \ gear are severely restricted compared to robot knowledge,\nrobotic systems in\
    \ agriculture can be highly beneﬁcial in achieving both high quality\nand quantity\
    \ goods. To integrate IoT systems with agricultural machinery, a new way\nof managing\
    \ control signals from the control system to the actuators is required. These\n\
    methods should increase economic viability while also lowering environmental impact\
    \ and\nenhancing food sustainability. It handles various agricultural tasks, including\
    \ moisture\nsensing, irrigation, crop monitoring, and insect and animal defense\
    \ [55]. Accordingly, a\nstate-of-the-art technologies-based accuracy comparison\
    \ is presented in Figure 6.\nFigure 6. Accuracy-based analysis of the different\
    \ state of the art techniques.\nWater monitoring is the most highly measured IoT\
    \ sub-vertical, followed by crop,\nsmart agriculture, animal, and irrigation monitoring.\
    \ All of these have the same proportion\nof peer-reviewed articles exploring the\
    \ possible uses of the Internet of Things. According\nto the ﬁndings, the most\
    \ important sensor data for measurement is 15.73% soil moisture,\n19.79% humidity,\
    \ and 24.87% ambient temperature. However, further sensor information,\nsuch as\
    \ soil pH and moisture, are also collected for IoT applications. Wi-Fi has the\
    \ highest\nclaimed use in farming and agriculture, with 30.27% and 21.10% use\
    \ of mobile tools, as\nshown in Figure 7. Other technologies like Bluetooth, WSN,\
    \ RFID, Raspberry Pi, ZigBee,\nLoRa, and GPRS are less popular in the agriculture\
    \ and farming industries. In the agri-\ncultural and farming business comparison,\
    \ the farming sector uses IoT for automation\nslower [42]. The Plant Server and\
    \ User View were created with phpMyAdmin to manage\nMySQL server management. The\
    \ F-RCNN-qualiﬁed model for anomaly detection had\n80% conﬁdence, while the technique\
    \ for the transfer of learning illness had 95.75% accu-\nAgronomy 2022, 12, 127\n\
    18 of 21\nracy. In reality, automatic image capturing software was deployed, and\
    \ the RCNN model\nsuccessfully recognized 91.67% of tomato plant illnesses [56].\n\
    Figure 7. An overview of 60 published articles on sensor and technology-based\
    \ data collection, as\nwell as a comparison of agriculture and farming utilizing\
    \ IoT.\n6. Conclusions and Future Directions\nThe implementation of sustainable\
    \ communication technologies and sensors based on\nIoT is necessary to increase\
    \ agricultural productivity. Wireless sensors, unmanned aerial\nvehicles, and\
    \ cloud computing have been shown to be practical tools for guaranteeing\nlong-term\
    \ agricultural productivity. Many processes throughout the production cycle,\n\
    including irrigation, soil sample and mapping, fertilizer or pest control, yield\
    \ monitoring,\nforecasting, and harvesting, may be automated using smart devices,\
    \ allowing for improved\ncrop quality and growth capacity. The key effective features,\
    \ important applications, IoT-\nbased smart agriculture technology and equipment,\
    \ and open barriers and possibilities\nwere all examined in this study. This research\
    \ will be expanded in the future to include\nsecurity and privacy issues in smart\
    \ agriculture using IoT methods.\nAuthor Contributions: All authors contributed\
    \ equally and scientiﬁcally. All authors have read and\nagreed to the published\
    \ version of the manuscript.\nFunding: No speciﬁc funding received for this research.\n\
    Acknowledgments: This research is supported by Artiﬁcial Intelligence & Data Analytics\
    \ Lab (AIDA)\nCCIS Prince Sultan University, Riyadh, Saudi Arabia. The authors\
    \ also would like to acknowl-\nedge the support of Prince Sultan University for\
    \ paying the Article Processing Charges (APC) of\nthis publication.\nConﬂicts\
    \ of Interest: There is no conﬂict of interest to declare.\nAgronomy 2022, 12,\
    \ 127\n19 of 21\nReferences\n1.\nMukhtar, H.; Khan, M.Z.; Khan, M.U.G.; Saba,\
    \ T.; Latif, R. Wheat Plant Counting Using UAV Images Based on Semi-supervised\n\
    Semantic Segmentation. In Proceedings of the 2021 1st International Conference\
    \ on Artiﬁcial Intelligence and Data Analytics\n(CAIDA), Riyadh, Saudi Arabia,\
    \ 6–7 April 2021; pp. 257–261.\n2.\nKhan, M.A.; Akram, T.; Sharif, M.; Alhaisoni,\
    \ M.; Saba, T.; Nawaz, N. A probabilistic segmentation and entropy-rank correlation-\n\
    based feature selection approach for the recognition of fruit diseases. EURASIP\
    \ J. Image Video Process. 2021, 2021, 14. [CrossRef]\n3.\nKhan, M.A.; Akram, T.;\
    \ Sharif, M.; Awais, M.; Javed, K.; Ali, H.; Saba, T. CCDF: Automatic system for\
    \ segmentation and\nrecognition of fruit crops diseases based on correlation coefﬁcient\
    \ and deep CNN features. Comput. Electron. Agric. 2018, 155,\n220–236. [CrossRef]\n\
    4.\nSafdar, A.; Khan, M.A.; Shah, J.H.; Sharif, M.; Saba, T.; Rehman, A.; Javed,\
    \ K.; Khan, J.A. Intelligent microscopic approach for\nidentiﬁcation and recognition\
    \ of citrus deformities. Microsc. Res. Tech. 2019, 82, 1542–1556. [CrossRef] [PubMed]\n\
    5.\nSinha, B.B.; Dhanalakshmi, R. Recent advancements and challenges of Internet\
    \ of Things in smart agriculture: A survey. Futur.\nGener. Comput. Syst. 2022,\
    \ 126, 169–184. [CrossRef]\n6.\nKolivand, H.; Fern, B.M.; Saba, T.; Rahim, M.S.M.;\
    \ Rehman, A. A New Leaf Venation Detection Technique for Plant Species\nClassiﬁcation.\
    \ Arab. J. Sci. Eng. 2019, 44, 3315–3327. [CrossRef]\n7.\nFriha, O.; Ferrag, M.A.;\
    \ Shu, L.; Maglaras, L.; Wang, X. Internet of Things for the Future of Smart Agriculture:\
    \ A Comprehensive\nSurvey of Emerging Technologies. IEEE/CAA J. Autom. Sin. 2021,\
    \ 8, 718–752. [CrossRef]\n8.\nKianat, J.; Khan, M.A.; Sharif, M.; Akram, T.; Rehman,\
    \ A.; Saba, T. A joint framework of feature reduction and robust feature\nselection\
    \ for cucumber leaf diseases recognition. Optik 2021, 240, 166566. [CrossRef]\n\
    9.\nSaba, T.; Rehman, A.; AlGhamdi, J.S. Weather forecasting based on hybrid neural\
    \ model. Appl. Water Sci. 2017, 7, 3869–3874.\n[CrossRef]\n10.\nSharma, Y.; Tyagi,\
    \ V.; Datta, P. IoT based smart agriculture monitoring system. Int. J. Innov.\
    \ Technol. Explor. Eng. 2020, 9, 325–328.\n11.\nFern, B.M.; Rahim, M.S.M.; Saba,\
    \ T.; Almazyad, A.S.; Rehman, A. Stratiﬁed classiﬁcation of plant species based\
    \ on venation state.\nBiomed. Res. 2017, 28, 5660–5663.\n12.\nSudarshan, K.; Hegde,\
    \ R.R.; Sudarshan, K.; Patil, S. Smart agriculture monitoring and protection system\
    \ using IoT. Perspect.\nCommun. Embed. Syst. Signal Process. PiCES 2019, 2, 308–310.\n\
    13.\nRajaram, K.; Sundareswaran, R. IoT Based Crop-Field Monitoring and Precise\
    \ Irrigation System Using Crop Water Requirement.\nIn International Conference\
    \ on Computational Intelligence in Data Science; Springer: Cham, Switzerland,\
    \ 2020; pp. 291–304.\n14.\nAbba, S.; Wadumi Namkusong, J.; Lee, J.A.; Liz Crespo,\
    \ M. Design and Performance Evaluation of a Low-Cost Autonomous\nSensor Interface\
    \ for a Smart IoT-Based Irrigation Monitoring and Control System. Sensors 2019,\
    \ 19, 3643. [CrossRef]\n15.\nKamaruddin, F.; Abd Malik, N.N.N.; Murad, N.A.; Latiff,\
    \ N.M.A.A.; Yusof, S.K.S.; Hamzah, S.A. IoT-based intelligent irrigation\nmanagement\
    \ and monitoring system using Arduino. Telkomnika 2019, 17, 2378–2388. [CrossRef]\n\
    16.\nAkshaya, M.; Kavipriya, P.R.; Yogapriya, M.; Karthikamani, R. IoT based fertilizer\
    \ injector for agricultural plants. Int. Res. J. Eng.\nTechnol. 2020, 7, 2950–2954.\n\
    17.\nReddy, H.S.; Hedge, G.; Chinnayan, D.R. IOT based leaf disease detection\
    \ and fertilizer recommendation. Int. J. Innov. Technol.\nExplor. Eng. 2019, 9,\
    \ 132–136.\n18.\nChavan, R.; Deoghare, A.; Dugar, R.; Karad, P. IoT Based Solution\
    \ for Grape Disease Prediction Using Convolutional Neural\nNetwork and Farm Monitoring.\
    \ Int. J. Sci. Res. Eng. Dev. 2019, 2, 494–500.\n19.\nBhoi, S.K.; Jena, K.K.;\
    \ Panda, S.K.; Long, H.V.; Kumar, R.; Subbulakshmi, P.; Bin Jebreen, H. An Internet\
    \ of Things assisted\nUnmanned Aerial Vehicle based artiﬁcial intelligence model\
    \ for rice pest detection. Microprocess. Microsyst. 2021, 80, 103607.\n[CrossRef]\n\
    20.\nGanesh, P.; Tamilselvi, K.; Karthi, P. Crop prediction by monitoring temperature\
    \ and rainfall using decision tree with IoT and\ncloud-based system. Proceedings\
    \ of the International Conference on Computational Intelligence and Data Science,\
    \ Gurugram, India, 7–8\nApril 2018, 1–9.\n21.\nTolentino, L.K. Yield evaluation\
    \ of Brassica rapa, Lactuca sativa, and Brassica integrifolia using image processing\
    \ in an IoT-based\naquaponics with temperature-controlled greenhouse. AGRIVITA\
    \ J. Agric. Sci. 2020, 42, 393–410. [CrossRef]\n22.\nVisconti, P.; Giannoccaro,\
    \ N.I.; de Fazio, R.; Strazzella, S.; Cafagna, D. IoT-oriented software platform\
    \ applied to sensors-based\nfarming facility with smartphone farmer app. Bull.\
    \ Electr. Eng. Inform. 2020, 9, 1095–1105. [CrossRef]\n23.\nKodali, R.K.; Rajanarayanan,\
    \ S.C.; Boppana, L. IoT based Weather Monitoring and Notiﬁcation System for Greenhouses.\n\
    In Proceedings of the 2019 11th International Conference on Advanced Computing\
    \ (ICoAC), Chennai, India, 18–20 December\n2019; pp. 342–345.\n24.\nArifﬁn, M.A.M.;\
    \ Ramli, M.I.; Amin, M.N.M.; Ismail, M.; Zainol, Z.; Ahmad, N.D.; Jamil, N. Automatic\
    \ Climate Control\nfor Mushroom Cultivation Using IoT Approach. In Proceedings\
    \ of the 2020 IEEE 10th International Conference on System\nEngineering and Technology\
    \ (ICSET), Shah Alam, Malaysia, 9 November 2020; pp. 123–128.\n25.\nNagamani,\
    \ P.; Sundari Jahnavi, M.; Govind Raju, N.N.; Bhanu Shankar, A.; Govind Reddy,\
    \ K.S. Smart Hydroponics Water\nMonitoring Using IoT. J. Emerg. Technol. Innov.\
    \ Res. 2019, 6, 114–120.\n26.\nJayasuriya, Y.P.; Elvitigala, C.S.; Wamakulasooriya,\
    \ K.; Sudantha, B. Low Cost and IoT Based Greenhouse with Climate Monitoring\n\
    and Controlling System for Tropical Countries. In Proceedings of the 2018 International\
    \ Conference on System Science and\nEngineering (ICSSE), New Taipei, Taiwan, 28–30\
    \ June 2018; pp. 1–6.\nAgronomy 2022, 12, 127\n20 of 21\n27.\nBoursianis, A.D.;\
    \ Papadopoulou, M.S.; Diamantoulakis, P.; Liopa-Tsakalidi, A.; Barouchas, P.;\
    \ Salahas, G.; Karagiannidis, G.;\nWan, S.; Goudos, S.K. Internet of Things (IoT)\
    \ and Agricultural Unmanned Aerial Vehicles (UAVs) in smart farming: A\ncomprehensive\
    \ review. Internet Things 2020, 100187. [CrossRef]\n28.\nOdesola, D.F.; Olivarez,\
    \ R.; Ramos, A.; Malolos, D.; Patrick, V.; Balba, N.P. Internet of things (IoT)\
    \ based home automated weather\nmonitoring system. LPU-Laguna J. Eng. Comput.\
    \ Stud. 2019, 4, 1–10.\n29.\nFu, L.; Gao, F.; Wu, J.; Li, R.; Karkee, M.; Zhang,\
    \ Q. Application of consumer RGB-D cameras for fruit detection and localization\n\
    in ﬁeld: A critical review. Comput. Electron. Agric. 2020, 177, 105687. [CrossRef]\n\
    30.\nDutta, J.; Dutta, J.; Gogoi, S. Smart farming: An opportunity for efﬁcient\
    \ monitoring and detection of pests and diseases. J.\nEntomol. Zool. Stud. 2020,\
    \ 8, 2352–2359.\n31.\nMaslekar, N.V.; Kulkarni, K.P.; Chakravarthy, A.K. Application\
    \ of Unmanned Aerial Vehicles (UAVs) for Pest Surveillance,\nMonitoring and Management.\
    \ In Innovative Pest Management Approaches for the 21st Century; Springer: Berlin,\
    \ Germany, 2020; pp.\n27–45.\n32.\nGao, D.; Sun, Q.; Hu, B.; Zhang, S. A Framework\
    \ for Agricultural Pest and Disease Monitoring Based on Internet-of-Things and\n\
    Unmanned Aerial Vehicles. Sensors 2020, 20, 1487. [CrossRef]\n33.\nTang, Y.; Chen,\
    \ M.; Wang, C.; Luo, L.; Li, J.; Lian, G.; Zou, X. Recognition and Localization\
    \ Methods for Vision-Based Fruit Picking\nRobots: A Review. Front. Plant Sci.\
    \ 2020, 11, 510. [CrossRef] [PubMed]\n34.\nKang, H.; Zhou, H.; Wang, X.; Chen,\
    \ C. Real-Time Fruit Recognition and Grasping Estimation for Robotic Apple Harvesting.\n\
    Sensors 2020, 20, 5670. [CrossRef]\n35.\nOgorodnikova, O.M.; Ali, W. Method of\
    \ ripe tomato detecting for a harvesting robot. In AIP Conference Proceedings;\
    \ AIP Publishing\nLLC: Melville, NY, USA, 2019.\n36.\nYeshmukhametov, A.; Al Khaleel,\
    \ L.; Koganezawa, K.; Yamamoto, Y.; Amirgaliyev, Y.; Buribayev, Z. Designing of\
    \ CNC Based\nAgricultural Robot with a Novel Tomato Harvesting Continuum Manipulator\
    \ Tool. Int. J. Mech. Eng. Robot. Res. 2020, 9, 876–881.\n[CrossRef]\n37.\nZhang,\
    \ W.; Gong, L.; Chen, S.; Wang, W.; Miao, Z.; Liu, C. Autonomous Identiﬁcation\
    \ and Positioning of Trucks during\nCollaborative Forage Harvesting. Sensors 2021,\
    \ 21, 1166. [CrossRef]\n38.\nLi, B.; Zhou, A.; Yang, C.; Zheng, S. The Design\
    \ and Realization of fruit Harvesting Robot Based on IOT. In Proceedings of the\n\
    2016 International Conference on Computer Engineering, Information Science & Application\
    \ Technology (ICCIA 2016); Atlantis Press:\nAmstelkade, AV, USA, 2016.\n39.\n\
    Rahaman, S.H.; Biswas, S. Advantages of Internet of Things (IoT) and It’s Applications\
    \ in Smart Agriculture System. Int. Res. J.\nAdv. Sci. Hub 2020, 2, 4–10. [CrossRef]\n\
    40.\nMishra, D.; Natalizio, E. A survey on cellular-connected UAVs: Design challenges,\
    \ enabling 5G/B5G innovations, and experimen-\ntal advancements. Comput. Netw.\
    \ 2020, 182, 107451. [CrossRef]\n41.\nUllo, S.L.; Sinha, G.R. Advances in Smart\
    \ Environment Monitoring Systems Using IoT and Sensors. Sensors 2020, 20, 3113.\n\
    [CrossRef]\n42.\nMadushanki, R.; Wirasagoda, H.; Halgamuge, M. Adoption of the\
    \ Internet of Things (IoT) in agriculture and smart farming\ntowards urban greening:\
    \ A review. Int. J. Adv. Comput. Sci. Appl. (IJACSA) 2019, 1. [CrossRef]\n43.\n\
    Vikranth, K. An Implementation of IoT and Data Analytics in Smart Agricultural\
    \ System—A Systematic Literature Review. Int. J.\nManag. Technol. Soc. Sci. 2021,\
    \ 6, 41–70. [CrossRef]\n44.\nKhan, M.A.; Akram, T.; Sharif, M.; Saba, T. Fruits\
    \ diseases classiﬁcation: Exploiting a hierarchical framework for deep features\n\
    fusion and selection. Multimed. Tools Appl. 2020, 79, 25763–25783. [CrossRef]\n\
    45.\nSingh, D.; Jain, N.; Jain, P.; Kayal, P.; Kumawat, S.; Batra, N. PlantDoc:\
    \ A dataset for visual plant disease detection. In Proceedings\nof the 7th ACM\
    \ IKDD CoDS and 25th COMAD, Hyderabad, India, 5–7 January 2020; pp. 249–253.\n\
    46.\nYan, Q.; Yang, B.; Wang, W.; Wang, B.; Chen, P.; Zhang, J. Apple Leaf Diseases\
    \ Recognition Based on an Improved Convolutional\nNeural Network. Sensors 2020,\
    \ 20, 3535. [CrossRef]\n47.\nAlruwaili, M.; Alanazi, S.; Abd, S.; Shehab, A. An\
    \ Efﬁcient Deep Learning Model for Olive Diseases Detection. Int. J. Adv. Comput.\n\
    Sci. Appl. 2019, 10, 486–492. [CrossRef]\n48.\nVij, A.; Vijendra, S.; Jain, A.;\
    \ Bajaj, S.; Bassi, A.; Sharma, A. IoT and Machine Learning Approaches for Automation\
    \ of Farm\nIrrigation System. Procedia Comput. Sci. 2020, 167, 1250–1257. [CrossRef]\n\
    49.\nMohanty, S.P.; Hughes, D.P.; Salathé, M. Using Deep Learning for Image-Based\
    \ Plant Disease Detection. Front. Plant. Sci. 2016,\n7, 1419. [CrossRef] [PubMed]\n\
    50.\nCruz, A.C.; Luvisi, A.; De Bellis, L.; Ampatzidis, Y. X-FIDO: An Effective\
    \ Application for Detecting Olive Quick Decline Syndrome\nwith Deep Learning and\
    \ Data Fusion. Front. Plant. Sci. 2017, 8, 1741. [CrossRef] [PubMed]\n51.\nRauf,\
    \ H.T.; Saleem, B.A.; Lali, M.I.U.; Khan, M.A.; Sharif, M.; Bukhari, S.A.C. A\
    \ citrus fruits and leaves dataset for detection and\nclassiﬁcation of citrus\
    \ diseases through machine learning. Data Brief. 2019, 26, 104340. [CrossRef]\n\
    52.\nKuaban, G.S.; Czekalski, P.; Molua, E.L.; Grochla, K. An Architectural Framework\
    \ Proposal for IoT Driven Agriculture; Springer:\nBerlin, Germany, 2019; pp. 18–33.\n\
    53.\nPathak, A.; Uddin, M.A.; Abedin, J.; Andersson, K.; Mustafa, R.; Hossain,\
    \ M.S. IoT based Smart System to Support Agricultural\nParameters: A Case Study.\
    \ Procedia Comput. Sci. 2019, 155, 648–653. [CrossRef]\n54.\nThapa, R.; Snavely,\
    \ N.; Belongie, S.; Khan, A. The plant pathology 2020 challenge dataset to classify\
    \ foliar disease of apples. arXiv\n2020, arXiv:2004.11958.\nAgronomy 2022, 12,\
    \ 127\n21 of 21\n55.\nRomeo, L.; Petitti, A.; Marani, R.; Milella, A. Internet\
    \ of Robotic Things in Smart Domains: Applications and Challenges. Sensors\n2020,\
    \ 20, 3355. [CrossRef] [PubMed]\n56.\nSangeetha, S.K.B. Comparison of Crop Disease\
    \ Detection Methods-An intensive analysis. Psychol. Educ. J. 2021, 58, 10540–10546.\n"
  inline_citation: 'Rehman, A.; Saba, T.;

    Kashif, M.; Fati, S.M.; Bahaj, S.A.;

    Chaudhry, H. A Revisit of Internet of

    Things Technologies for Monitoring

    and Control Strategies in Smart

    Agriculture. Agronomy 2022, 12, 127.

    https://doi.org/10.3390/

    agronomy12010127'
  journal: Agronomy
  limitations: 'The study lacks a specific focus on data considerations, which limits
    its direct relevance to the outline point.


    However, it provides valuable insights into the overall landscape of automated
    agricultural systems and discusses the importance of data-driven approaches.'
  pdf_link: https://www.mdpi.com/2073-4395/12/1/127/pdf?version=1642508054
  publication_year: 2022
  relevance_score: 0.69
  relevance_score1: 0
  relevance_score2: 0
  title: A Revisit of Internet of Things Technologies for Monitoring and Control Strategies
    in Smart Agriculture
  verbatim_quote1: null
  verbatim_quote2: null
  verbatim_quote3: '>'

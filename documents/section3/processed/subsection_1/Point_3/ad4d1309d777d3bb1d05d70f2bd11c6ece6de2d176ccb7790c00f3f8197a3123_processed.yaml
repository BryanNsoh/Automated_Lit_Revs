- DOI: https://doi.org/10.3390/s22207910
  analysis: 'Geographic Information Systems (GIS),  which incorporate IoT and machine
    learning technologies, analyze data from remote sensing, UAVs, and self-driving
    tractors to improve vineyard cultivation and production by managing data of various
    types acquired with different methodologies.

    Geomatics uses satellite images and data acquired by drone, between May and October
    of 2021 in different phenological phases of vines, with a focus on a vineyard
    located in Bova Superiore, Calabria, southern Italy, near the Briga neighborhood.

    Data fusion techniques are used, including kriging and Convolutional Neural Networks
    (CNNs), to increase the precision and accuracy of image analysis from various
    modalities.

    Proper identification and calibration of sensors and algorithms, as well as data
    fusion of the various sources and types, are critical for addressing the challenges
    of data quality, data gaps, and data heterogeneity which are inherent in agriculture
    4.0.

    For example, preliminary testing of CNNs has shown that these techniques can be
    successfully employed to improve the spatial resolution of satellite multispectral
    images.'
  authors:
  - Vincenzo Barrile
  - Silvia Simonetti
  - Rocco Citroni
  - Antonino Fotia
  - Giuliana Bilotta
  citation_count: 18
  full_citation: 'Barrile, V.; Simonetti, S.; Citroni, R.; Fotia, A.; Bilotta, G.
    Experimenting Agriculture 4.0 with Sensors: A Data Fusion Approach between Remote
    Sensing, UAVs and Self-Driving Tractors. Sensors 2022, 22, 7910. https://doi.org/10.3390/s22207910'
  full_text: ">\nCitation: Barrile, V.; Simonetti, S.;\nCitroni, R.; Fotia, A.; Bilotta,\
    \ G.\nExperimenting Agriculture 4.0 with\nSensors: A Data Fusion Approach\nbetween\
    \ Remote Sensing, UAVs and\nSelf-Driving Tractors. Sensors 2022,\n22, 7910. https://doi.org/10.3390/\n\
    s22207910\nAcademic Editors: Abdul\nM. Mouazen and\nViacheslav Adamchuk\nReceived:\
    \ 25 August 2022\nAccepted: 14 October 2022\nPublished: 18 October 2022\nPublisher’s\
    \ Note: MDPI stays neutral\nwith regard to jurisdictional claims in\npublished\
    \ maps and institutional afﬁl-\niations.\nCopyright:\n© 2022 by the authors.\n\
    Licensee MDPI, Basel, Switzerland.\nThis article is an open access article\ndistributed\n\
    under\nthe\nterms\nand\nconditions of the Creative Commons\nAttribution (CC BY)\
    \ license (https://\ncreativecommons.org/licenses/by/\n4.0/).\nsensors\nArticle\n\
    Experimenting Agriculture 4.0 with Sensors: A Data Fusion\nApproach between Remote\
    \ Sensing, UAVs and\nSelf-Driving Tractors †\nVincenzo Barrile 1\n, Silvia Simonetti\
    \ 2\n, Rocco Citroni 3\n, Antonino Fotia 1\nand Giuliana Bilotta 1,*\n1\nDICEAM\
    \ Department, University Mediterranea of Reggio Calabria, 89124 Reggio Calabria,\
    \ Italy\n2\nDepartment of Engineering, Università degli Studi di Messina-Piazza\
    \ Pugliatti, 1, 98122 Messina, Italy\n3\nDepartment of Electronic Engineering,\
    \ University of Rome Tor Vergata, 00133 Roma, Italy\n*\nCorrespondence: giuliana.bilotta@unirc.it\n\
    †\nThis paper is an extended version of “UAV for Precision Agriculture in Vineyards:\
    \ A Case Study in Calabria”\npublished in the Proceedings of the Italian Conference\
    \ on Geomatics and Geospatial Technologies, Genoa,\nItaly, 1–23 July 2021.\nAbstract:\
    \ Geomatics is important for agriculture 4.0; in fact, it uses different types\
    \ of data (remote\nsensing from satellites, Unmanned Aerial Vehicles-UAVs, GNSS,\
    \ photogrammetry, laser scanners\nand other types of data) and therefore it uses\
    \ data fusion techniques depending on the different\napplications to be carried\
    \ out. This work aims to present on a study area concerning the integration\n\
    of data acquired (using data fusion techniques) from remote sensing techniques,\
    \ UAVs, autonomous\ndriving machines and data fusion, all reprocessed and visualised\
    \ in terms of results obtained through\nGIS (Geographic Information System). In\
    \ this work we emphasize the importance of the integration\nof different methodologies\
    \ and data fusion techniques, managing data of a different nature acquired\nwith\
    \ different methodologies to optimise vineyard cultivation and production. In\
    \ particular, in\nthis note we applied (focusing on a vineyard) geomatics-type\
    \ methodologies developed in other\nworks and integrated here to be used and optimised\
    \ in order to make a contribution to agriculture\n4.0. More speciﬁcally, we used\
    \ the NDVI (Normalized Difference Vegetation Index) applied to\nmultispectral\
    \ satellite images and drone images (suitably combined) to identify the vigour\
    \ of the\nplants. We then used an autonomous guided vehicle (equipped with sensors\
    \ and monitoring systems)\nwhich, by estimating the optimal path, allows us to\
    \ optimise fertilisation, irrigation, etc., by data\nfusion techniques using various\
    \ types of sensors. Everything is visualised on a GIS to improve the\nmanagement\
    \ of the ﬁeld according to its potential, also using historical data on the environmental,\n\
    climatic and socioeconomic characteristics of the area. For this purpose, experiments\
    \ of different\ntypes of Geomatics carried out individually on other application\
    \ cases have been integrated into\nthis work and are coordinated and integrated\
    \ here in order to provide research/application cues for\nAgriculture 4.0.\nKeywords:\
    \ vineyards; unmanned aerial vehicles; satellite imagery; agriculture 4.0; sensor\
    \ networks\n1. Introduction\nAs the concept of digital transformation is making\
    \ its way into all ﬁelds of daily life,\nrevolutionizing the way we produce and\
    \ interact, the applications of digital technologies\ntend to “specialize” in\
    \ individual application sectors. Agriculture is often considered a\n“traditionalist”\
    \ sector uninclined to changes; however, in recent years, it has beneﬁted\ngreatly\
    \ from the technological evolution underway.\nThe term “industry 4.0” has been\
    \ coined to indicate digital transformation in produc-\ntion environments; in\
    \ the same vein, the entry of the technologies of the fourth industrial\nrevolution\
    \ into the agrifood sector can be called “agriculture 4.0”. Agriculture 4.0 is\
    \ the\nresult of the application of a series of innovative technologies in the\
    \ agrifood ﬁeld and\nSensors 2022, 22, 7910. https://doi.org/10.3390/s22207910\n\
    https://www.mdpi.com/journal/sensors\nSensors 2022, 22, 7910\n2 of 23\nit can\
    \ be considered as an upgrade of precision agriculture. This was possible thanks\
    \ to\nthe automation of the collection and the integration and analysis of data\
    \ collected directly\nfrom the ﬁelds through various types of sensors. In this\
    \ context, digital technologies 4.0\nare useful to support-thanks to data analysis-the\
    \ farmer in his daily activity and in plan-\nning strategies for his business,\
    \ including relationships with all links in the supply chain,\ngenerating a virtuous\
    \ circle able to create value for the individual company and in cascade\nfor its\
    \ partners. Thanks to these new solutions and the application of digital technologies,\n\
    from the IoT to artiﬁcial intelligence, from the analysis of large amounts of\
    \ data to self-\ndriving tractors to the use of drones, farms can increase proﬁtability\
    \ and the economic,\nenvironmental and social sustainability of its business.\
    \ The beginning of the application of\ntechnologies for precision agriculture\
    \ in Italy dates to the 1990s; basically, it involves using\ndigital solutions\
    \ for speciﬁc interventions, which take into account in particular the needs\n\
    of the soil and plants. The aims of these interventions are to improve the production\
    \ yield\nof the plantations as much as possible and contain costs and environmental\
    \ impact. This\ncategory includes, for example, all interventions to make irrigation\
    \ more efﬁcient without\nwasting water resources or causing the plants to suffer,\
    \ planting technologies adapted to\nthe biochemical and physical characteristics\
    \ of the soil on which the intervention is carried\nout, the administration of\
    \ pesticides commensurate to the speciﬁc needs of each area and\nplant, or of\
    \ fertilizers only in the necessary quantity and at the most useful times.\nFor\
    \ this reason, precision agriculture, in addition to being the predecessor of\
    \ agricul-\nture 4.0, is also one of the cornerstones of the latter, because it\
    \ lays the foundations for\nadapting production processes to individual needs\
    \ thanks to targeted and timely interven-\ntions. All these interventions can\
    \ adapt to the needs of the moment (through GIS, different\ntypes of sensor data,\
    \ and the use of data fusion techniques, production peculiarities can\nalso be\
    \ estimated). The basis for making these technologies more effective is the real-time\n\
    use of data coming from the ﬁelds. Thanks to sensors able transmit information,\
    \ installed\non ﬁelds or agricultural machinery, it will be possible to make timely\
    \ and effective deci-\nsions, which can also be entrusted to automated systems.\
    \ In general, the main advantages\nof agriculture 4.0 are those, as we said, of\
    \ a rationalization of resources, with a positive\neconomic impact for the companies\
    \ in the supply chain. A path of products-from ﬁeld to\ntable-aimed at maximizing\
    \ sustainability also has a positive impact on health, since it will\nbe possible\
    \ to bring better controlled and fresher products to ﬁnal consumers than with\n\
    traditional techniques. To quantify these advantages, there is talk of a saving\
    \ of around 30%\nfor production inputs and a 20% increase in productivity, with\
    \ limited use of chemicals.\nThen focusing on the use of data, it must be added\
    \ that being able to count on the real-time\nanalysis of the information coming\
    \ from the ﬁelds is extremely useful to manage any\nactivity related to agriculture\
    \ in a faster and, therefore, more efﬁcient way. In fact, thanks to\nthe data\
    \ analysis, it will be possible to make the use of agricultural machinery as efﬁcient\n\
    as possible, or to use only the amount of water needed, without waste. Thanks\
    \ to the same\nset of information, it will also be possible to prevent plant diseases\
    \ or counteract pests,\nlimiting damage when problems arise thanks to constant\
    \ and simultaneous monitoring of\ncrops. Moreover, it should be emphasized that\
    \ these are advantages that can be obtained\nregardless of the type of crop.\n\
    This study starts from work previously carried out on a speciﬁc agricultural area,\
    \ with\nthe aim of reanalysis with different tools and techniques in order to\
    \ ﬁnd a more efﬁcient\nmonitoring solution.\nIt is possible to use Geomatics techniques,\
    \ and thus to use satellite images, multi-\nspectral drone images (and there are\
    \ already numerous analyses on the integration of\nsatellite images and drone\
    \ images to improve image quality and productivity), other sen-\nsors (humidity,\
    \ pressure, wind, temperature), merge these data with data fusion techniques,\n\
    manage the use of automated vehicles, and collect everything using GIS to optimise\
    \ the\nagricultural production process (fertilisation, irrigation, etc....) according\
    \ to the needs of\nthe population.\nSensors 2022, 22, 7910\n3 of 23\nThe practice\
    \ of Precision Agriculture (PA) and, recently, Agriculture 4.0, has garnered\n\
    a lot of attention in recent years. Through the integration of information technology\
    \ and\nagronomic practices, it has become possible to automate the management\
    \ of parcels of\nland [1].\nThe literature cited below highlights the research\
    \ questions and useful information\nand underlines the shortcomings of previous\
    \ studies.\nPrecision agriculture is a management strategy [2] that utilizes information\
    \ technology\nto collect data from multiple sources in order to use them in decisions\
    \ regarding ﬁeld\nproduction activities [3]. The goal of this strategy is to integrate\
    \ the ideas of business\nmanagement and process automation. Agriculture 4.0 additionally\
    \ brings together var-\nious innovative methodologies applied from time to time\
    \ in other sectors, such as the\nidentiﬁcation of optimal routes for self-driving\
    \ tractors.\nCrop monitoring, which is based on observations carried out directly\
    \ on crops in place\nin order to obtain data on phenological stages, nutritional\
    \ status [4–6], phytosanitary status,\nproduction expectations [7] and production\
    \ maps [8], is of particular interest in order to\naccomplish this. The monitoring\
    \ of crops relies on observations made directly on the crops\nin their natural\
    \ environment. Since massive amounts of data need to be gathered and\nprocessed,\
    \ process automation is necessary [9].\nThe monitoring of crops makes use of remote\
    \ sensing data and is predicated on the link\nthat exists between several parameters\
    \ relating to the leaf curtain [10]. These parameters\ncan express the vegetative–productive\
    \ responses of plants and evaluate the variability as\na function of the different\
    \ behaviours of surfaces and bodies [11] to the phenomenon of\nabsorption or reﬂection\
    \ of light in the visible and infrared regions [12].\nLarge agricultural regions\
    \ have been monitored using satellite remote sensing ever\nsince the 1970s for\
    \ the purpose of stock forecasting [13], which has resulted in the provision\n\
    of useful data for the industry of agriculture itself. The unique optical behaviour\
    \ of plants\nin the infrared radiation band makes remote sensing techniques particularly\
    \ useful for\nevaluating vegetative health [14], as these techniques are useful\
    \ in practice [15]. The time-\nconsuming and ﬁnancially burdensome ﬂights of airplanes\
    \ ﬁtted with specialized cameras\nwere quickly replaced by satellites that, while\
    \ continuously orbiting the Earth, acquire data\non the electromagnetic emission\
    \ of objects on the Earth’s surface, and consequently also of\nthe crops, with\
    \ their multispectral sensors, if passive, or radar, if active. This has resulted\n\
    in a signiﬁcant reduction in the cost of collecting this information. However,\
    \ passive\nsensors have limitations; acquisition is necessarily diurnal and hindered\
    \ by any cloud cover.\nFurthermore, the level of detail that is obtainable precludes\
    \ performing particular kinds of\nanalyses on smaller parcels of land.\nOn the\
    \ other hand, unmanned aerial vehicles (UAVs) have the potential to be very\n\
    helpful because they can collect more speciﬁc georeferenced information using\
    \ a variety of\nsensors [16–19].\nIn viticulture in particular, optimising vineyard\
    \ cultivation and yield procedures\nthrough the use of automatic cultivation machines\
    \ and data fusion, which faces challenges\nduring production cycles by deﬁning\
    \ an adequate crop management, the Agriculture 4.0\napproach has as its ultimate\
    \ goal the improvement of vineyard yield and grape quality while\nsimultaneously\
    \ reducing all wastes, costs, and the negative impact on the environment [20].\n\
    The information collected by optical sensors in multispectral and hyperspectral\
    \ imag-\ning systems is utilized in the calculation of a diverse range of indices\
    \ related to crop\nproduction (such as the Leaf Area Index (LAI) [15,21]). The\
    \ normalized difference vegeta-\ntion index (NDVI) is one of the indices that\
    \ is utilised the most frequently because of its\nrelationship to crop vigour\
    \ and, as a result of this relationship, to the estimated quantity\nand quality\
    \ of ﬁeld production.\nThe MultiSpectral Instrument (MSI) of Sentinel 2 covers\
    \ large areas, and many satellite\nprograms (i.e., Landsat, Sentinel-1 and Sentinel-2)\
    \ now freely supply datasets, which\npromotes the exploitation of satellite imagery\
    \ for many applications, including agricultural\napplications, as multi-sensor\
    \ and multiresolution data fusion [22–26]. The Sentinel-2\nSensors 2022, 22, 7910\n\
    4 of 23\nsatellite, which was developed by the European Space Agency (ESA), has\
    \ a resolution of\none decametre, a revisitation time of six days, and an efﬁcient\
    \ resolution for analysing crop\nvariability and conditions. If, on the other\
    \ hand, we consider crops to be more like orchards\nand vineyards (with breaks\
    \ in their layouts), then remote sensing becomes more challenging.\nActually,\
    \ the occurrence of paths between yields and weedy vegetation within the cultivated\n\
    land can have a noticeable impact on the overall calculation of spectral indices,\
    \ which in\nturn leads to a less precise evaluation of the crop’s status. New\
    \ methods and algorithms\nwere developed that use multispectral information from\
    \ UAVs for circumventing this\ncriticality [27]. These advancements have been\
    \ made in order to resolve this critical issue.\nLow-altitude platforms, as Unmanned\
    \ Aerial Vehicles (UAVs) with airborne sensors,\ncan differentiate pure canopy\
    \ pixels from other objects by acquiring images with a high\nresolution and having\
    \ ﬂexible ﬂight planning [28]. This allows for the classiﬁcation of\ndetails within\
    \ canopies.\nIn particular, it is possible to successfully combine an unmanned\
    \ rotary-wing platform\nwith a multispectral sensor in order to detect and monitor\
    \ water-stressed areas of orchards,\nvineyards, and olive groves. This is possible\
    \ thanks to the fact that the two technologies\ncan be successfully combined.\n\
    In PA, the NDVI index is a parameter that is used because it is directly related\
    \ to the\nhealth of the vegetation. This allows problems such as a lack of nutrients,\
    \ the presence\nof parasitic infections, or conditions of water stress to be discovered.\
    \ The NDVI index is\ncalculated by processing images that were taken in the infrared.\
    \ The early detection of\nsuch situations enables intervention that is both targeted\
    \ and effective, which results in cost\nsavings and increased crop yield. Infrared\
    \ detection is frequently capable of identifying\nissues well in advance of their\
    \ becoming obvious to the human eye [29,30].\nIn this article we present, among\
    \ other things, a comprehensive vineyard survey\nthat also compares MultiSpectral\
    \ Instrument (MSI) data from a satellite with decametre\nresolution and from a\
    \ low-altitude UAV platform. This allowed us to better understand the\ndifferences\
    \ between the two types of instruments. The performance of Sentinel-2′s MSI,\n\
    WorldVew and the aerial UAV sensors, both with very high resolution, when considering\n\
    the relationship between crop vigour and NDVI was determined. In order to investigate\n\
    the role played by the various vineyard components, satellite data were compared\
    \ with\nUAV images using the following three NDVI indices [31,32]: (i) the entire\
    \ agricultural area;\n(ii) only the vine canopies; and (iii) only the inter-row\
    \ soil. These indices were calculated\nby comparing the UAV data with satellite\
    \ images.\nThe multispectral sensors used on UAVs are capable of recording at\
    \ least three chan-\nnels, as a regular camera would, but one of those channels\
    \ is replaced by infrared. Although\nmultispectral sensors can acquire information\
    \ in more than four bands and multispectral\ncameras are capable of recording\
    \ more than the three channels deﬁned here, for the pur-\nposes of this application,\
    \ each image will consist of two visible colours in addition to\ninfrared [33–36].\
    \ Because of this, the NDVI index can be calculated from a single image\nusing\
    \ a modiﬁed version of the conventional formula. The processing is handled in\
    \ an\nautomated practice by the GIS which we used (QGis). The maps that are obtained\
    \ after\nthe processing are false-colour maps known as “Vigour Maps” [37,38].\
    \ On these maps, red\nrepresents regions that have the highest possible vitality\
    \ [39].\nRecent literature also exists on data fusion techniques for agriculture:\
    \ on input devices\nsynchronised with microcontrollers and sending data from sensors\
    \ via IoT (Internet of\nThings) devices to the cloud [40] and the challenges and\
    \ complexity of Agriculture 4.0 [41].\nIt is obvious that the methodology that\
    \ has been proposed can include other kinds of\ncrops that are grown in rows,\
    \ with crop canopies that do not extend over the entire area of\ncultivation,\
    \ or where there is a signiﬁcant presence of bare soil or grass [42–44].\nSensors\
    \ 2022, 22, 7910\n5 of 23\n2. Materials and Methods\n2.1. Remote Sensing\nRemote\
    \ sensing is the acquisition of information about an object or phenomenon\nwithout\
    \ coming into physical contact with the object. In this case we will refer to\
    \ Remote\nSensing from Earth Observation by satellite and, although it is used\
    \ in numerous ﬁelds, in\nour case it is used for monitoring purposes in agriculture,\
    \ particularly vineyard cultivation.\nIt is crucial for winemakers to gain an\
    \ accurate understanding of the spatial variability\nboth between and within crops\
    \ to be able to make accurate predictions regarding yield and\nquality. The Normalized\
    \ Difference Vegetation Index (NDVI) is one of the most widely\nused indices because\
    \ it is related to crop vigour and, as a result, to estimated quantity and\nquality\
    \ of ﬁeld production.\nPlants absorb solar radiation in the spectral region via\
    \ photosynthetically active radia-\ntion (PAR), which they then use as an energy\
    \ source in the photosynthesis process. Strong\nabsorption at these wavelengths\
    \ will only overheat the plant and potentially damage its\ntissue. As a result,\
    \ plants appear relatively dark in the PAR spectrum and relatively bright\nin\
    \ the near infrared spectrum. Clouds and snow, on the other hand, tend to be bright\
    \ in the\nred band (as well as other visible wavelengths) and dark in the near\
    \ infrared. Chlorophyll,\na pigment found in leaves, strongly absorbs visible\
    \ light for use in photosynthesis. In\ncontrast, the cellular structure of leaves\
    \ strongly reﬂects near-infrared light. The more\nleaves a plant has, the more\
    \ wavelengths are affected, and thus the greater the amount\nof light involved.\
    \ Because earth observation instruments collect data in the visible and\nnear-infrared\
    \ ranges, it was natural to use the large differences in reﬂectance of plants\
    \ to\ndetermine their spatial distribution in satellite images.\nThe following\
    \ formula is used to calculate the NDVI:\nNDVI = (NIR − Red)\n(NIR + Red)\n(1)\n\
    Red and NIR are abbreviations for spectral reﬂectance measurements obtained in\
    \ the\nvisible (red) and near-infrared regions, respectively.\n2.2. UAVs/Sensors\n\
    Unmanned aerial vehicles (UAVs) are a type of robotic aircraft that are controlled\n\
    by radio and have their own built-in control systems. They were initially developed\
    \ in\nthe 1920s for use in the military as a replacement for human pilots serving\
    \ on hazardous\nmissions. In the past, the disadvantages of high cost, large sensors,\
    \ poor endurance,\nand primitive ﬂight control systems caused civilian UAV use\
    \ to develop slowly. At the\nbeginning of the twenty-ﬁrst century, only a few\
    \ low-quality products were available for\nuse in scientiﬁc research. These disadvantages\
    \ still exist today. The market for low-cost\nunmanned aerial vehicles (UAVs)\
    \ has expanded at a rapid rate thanks to the development of\nnew technologies\
    \ and the appearance of UAV manufacturers such as DJI (Shenzhen, China).\nThe\
    \ successful transition of UAVs from military to civilian uses has been facilitated\
    \ by\nthe development of several different technologies. There is now an abundance\
    \ of UAVs\navailable to meet the demand in various ﬁelds of use, including scientiﬁc\
    \ research.\nThe development of remote sensing technology has made it possible\
    \ to devise a\nworkable strategy for the collection of speciﬁc data used for mapping\
    \ land-cover changes,\nmonitoring drought conditions, and analysing complex characteristics\
    \ across space and\ntime. This technology uses a variety of sensors onboard satellites,\
    \ airborne or unmanned\naerial vehicles (UAVs), and it offers a variety of classiﬁcation\
    \ methods for vegetation at both\nlarge and small scales. A practical approach\
    \ to designing strategies for the management\nof forest disasters can be found\
    \ by employing the techniques of remote sensing. This can\ninclude evaluating\
    \ landslide-prone areas through airborne, UAV, and ground-based remote\nsensing,\
    \ as well as evaluating changes in vegetation cover after a wildﬁre for post-ﬁre\n\
    management by using satellite-based remote sensing and UAV.\nSensors 2022, 22,\
    \ 7910\n6 of 23\nThere is technology available today that can automatically steer\
    \ agricultural vehicles\nsuch as tractors [45–47] and harvesters along predeﬁned\
    \ paths using precise global navi-\ngation satellite systems (GNSS). Examples\
    \ of these types of vehicles include tractors and\ncombine harvesters. However,\
    \ a human operator is still required in order to monitor the\nsurrounding environment\
    \ and take corrective action if any potential hazards come into\nview in front\
    \ of the vehicle in order to guarantee its safe operation.\nIt is necessary for\
    \ there to be no need for a human operator whatsoever for the\nautonomous farming\
    \ vehicles to be able to operate in a manner that is both productive and\nrisk-free\
    \ without any assistance from a person. A safety system must be able to perform\n\
    accurate obstacle detection and avoidance in real time while maintaining a high\
    \ degree of\nreliability. Furthermore, in order to handle a wide variety of shifts\
    \ in the illumination and\nweather conditions, multiple sensing modalities need\
    \ to complement each other.\nFor a technological development of this magnitude,\
    \ extensive research and experi-\nments are required to investigate various sensor,\
    \ detection algorithm, and fusion\nstrategy combinations.\nToday platforms such\
    \ as drones support the integration of a wide variety of sensors\nemployed for\
    \ agriculture 4.0. However, the utilisation of these sensors in agriculture 4.0\
    \ is\nclosely linked to their capacity to detect the signal over a greater spectral\
    \ range. Fundamen-\ntally, in agricultural sensing technology four parameters\
    \ must be analysed: the spectral,\nspatial, temporal, and radiometric resolutions.\
    \ However, in most cases the sensors provide\ninformation based on their spectral\
    \ resolution (multispectral, super-spectral and hyperspec-\ntral). Multispectral\
    \ sensors typically use from 3 to 10 bands to cover the relevant spectrum.\nEarly\
    \ detection of the disease, improved irrigation, water management, faster and\
    \ more\naccurate plant counts to optimize fertilizer application and pest control\
    \ represent some\nadvantages of this sensor. Super-spectral sensors use from 10\
    \ to 20 bands to cover broad\nportions of the spectrum. Hyperspectral sensors\
    \ compared to multispectral sensors cover\nhundreds or thousands of narrower bands\
    \ (10 to 20 nm), providing greater resolution and a\nhighly detailed electromagnetic\
    \ spectrum of agricultural ﬁelds. In addition, higher spatial\nresolution, ability\
    \ to distinguish smaller elements, higher temporal resolution, higher ra-\ndiometric\
    \ sensitivity and the ability to detect small differences in radiated energy represent\n\
    only some of the advantages.\n2.3. Self-Driving Tractors/GIS/Other Sensors\nTractors\
    \ used in agriculture are typically capable of working in any terrain. Moreover,\n\
    the signals coming from the navigation sensors are subject to a great deal of\
    \ unpredictability\nin terms of disturbances and noise sources. As a consequence\
    \ of this, it is essential for the\nsensor fusion module to contain efﬁcient methods\
    \ for signal conditioning and estimating\nthe state of the system.\nWhen it comes\
    \ to automated tractor guidance in the ﬁeld, an accurate position mea-\nsurement\
    \ is absolutely necessary. Because the GPS antenna was mounted on the roof of\
    \ the\ntractor cab, which was approximately three meters above the ground, any\
    \ inclination of\nthe tractor would result in an inaccurate position reading (roll\
    \ and pitch). An architecture\nthat uses edge devices to carry out a substantial\
    \ amount of computation (edge computing),\nstorage, and communication locally\
    \ and routes it over the Internet backbone is called fog\ncomputing or fog networking,\
    \ also known as fogging. A FOG was used to measure heading\nangle on this research\
    \ platform. Utilizing Euclidean angles, a method of correction that\ncompensates\
    \ for positional errors caused by inclination-related factors was developed.\n\
    Hardware design and software design are the two components that make up the\n\
    entirety of the overall structural design of unmanned agricultural machinery.\
    \ The de-\nsign of the hardware encompasses both the mechanical design and the\
    \ circuit design.\nProgramming for the control system execution process and algorithmic\
    \ formulations for\npath tracking control are components of software design. By\
    \ contrasting the traditional\nProportional–Integral–Derivative (PID) control,\
    \ fuzzy control, and fuzzy PID control, this\narticle concludes that the fuzzy\
    \ PID control algorithm should be used to control the steering\nSensors 2022,\
    \ 22, 7910\n7 of 23\nof agricultural machinery, while the traditional incremental\
    \ PID control algorithm should\nbe used to control the speed of the vehicle body\
    \ while it is in motion [48,49].\nThe quantity of sensors used to collect data\
    \ in various settings, as well as the quality\nof the data collected by those\
    \ sensors, has been steadily increasing. Even complex environ-\nments, such as\
    \ agricultural areas, can now be “sensed” via a wide variety of equipment,\nwhich\
    \ generates vast amounts of data that can be explored to provide helpful information\n\
    about the area that is being observed. Examples of such environments include urban\
    \ and\nwilderness areas. Because of this, an increased number of studies have\
    \ been carried out in\nan effort to research the vast amounts of information that\
    \ are hidden within the sensed data.\nHowever, it can be extremely difﬁcult to\
    \ transfer the advances made in experiments to the\nreal-world conditions that\
    \ are encountered in practice. There are two primary explanations\nfor this phenomenon.\
    \ To begin, the scope of the research projects that are described in\nscientiﬁc\
    \ texts is typically restricted. This is due to the fact that the data that are\
    \ utilized\nin these experiments typically do not cover all of the variables that\
    \ are connected to the\nissue at hand. As a consequence of this, the results that\
    \ are reported in those articles,\ndespite the fact that they might appear to\
    \ be encouraging, typically reveal nothing about\nthe performance of the proposed\
    \ technique under real-world conditions that are unre-\nstricted. Second, even\
    \ if the data adequately cover the variable conditions that are found\nin practice,\
    \ the chosen sensing technology may not be able to acquire enough information\n\
    to unambiguously resolve the data and provide enough information. This is a possibility\n\
    even if the data adequately cover the variable conditions that are found in practice.\
    \ For\ninstance, even powerful artiﬁcial intelligence models that are fed with\
    \ RGB digital images\nfrequently fail to correctly identify plant diseases based\
    \ on their symptoms. This is due to\nthe fact that different disorders can produce\
    \ visual signs that are similar to one another.\nThere are many sensors that can\
    \ be used in Agriculture 4.0, for example, the Soil\nMoisture Sensor used in our\
    \ case study, but also other environmental sensors, capable of\nproviding data\
    \ that can be used for cultivation decisions, also collected in time series that\n\
    can therefore provide trends. Meteorological data [50] can also provide useful\
    \ time series\nin agriculture.\nAs is well known, G.I.S. (Geographical Information\
    \ System)/WebGIS is a tool for\nanalysing, reporting and querying entities or\
    \ events occurring in the territory. Particularly\nin Agriculture 4.0, the use\
    \ of GIS allows researchers to integrate and manage data of\ndifferent natures\
    \ and, if properly implemented (open source), it also allows identiﬁcation\nof\
    \ optimal routes for vehicles and areas of greater interest in different areas\
    \ if integrated\nwith historical data.\nThe GIS makes use of images captured by\
    \ UAVs as well as Very High-Resolution\n(VHR) satellite imagery categorized using\
    \ OBIA. The Geographic Information System\n(GIS) is helpful for agriculture in\
    \ general, and not just for the management of vineyards\nspeciﬁcally. It takes\
    \ into account the geomorphology of the land, as well as the climatic\nconditions\
    \ (wind, rain, etc.), and the moisture conditions of the soil for the crops. This\n\
    system is able to provide alerts in the event that interventions are required\
    \ depending on\nthe water stress experienced by the crop. As a result, we are\
    \ able to highlight the optimal\nroute for the tractor.\n2.4. Data Fusion\nUtilizing\
    \ data fusion techniques is one approach to minimizing the gaps in coverage\n\
    that are the result of insufﬁcient data. The process of combining data from several\
    \ different\nsources in order to produce information that is more precise, consistent,\
    \ and concise than\nthat which is provided by any individual data source is referred\
    \ to as “data fusion.” There\nare also other deﬁnitions that are more stringent,\
    \ which better ﬁt speciﬁc contexts. Since\nthe ﬁrst half of the 1990s, people\
    \ have been applying this method to solve agricultural\nproblems, and recently,\
    \ there has been an increase in the number of cases in which this\nmethod is used.\
    \ Finding the most effective method to completely explore the synergy\nand complementarities\
    \ that may exist between various kinds of data and sources of data\nSensors 2022,\
    \ 22, 7910\n8 of 23\nis arguably the most difﬁcult part of using techniques that\
    \ involve the fusion of data.\nThis is one of the main challenges that is involved\
    \ in the use of data fusion techniques.\nThis is especially the case when the\
    \ data being compared have signiﬁcantly different\ncharacteristics (for example,\
    \ digital images and meteorological data). Given the wide\nvariety of data sources\
    \ and methods utilized in agricultural applications [40,41], it can be\nchallenging\
    \ to ﬁnd a formalization for the data fusion process that is suitable for all\
    \ of these\napplications. A perspective on the data fusion process is given here,\
    \ broken down into\nthree stages and applicable to the vast majority of situations.\
    \ In the ﬁrst, the corresponding\nattributes used for describing information in\
    \ the various sources must be identiﬁed. This\nmust be done before moving on to\
    \ the next step. If the data sources are comparable, then\nﬁnding such a correspondence\
    \ is not difﬁcult; however, if different types of data are used,\nthen ﬁnding\
    \ such a correspondence may be more difﬁcult. This is one of the primary\nreasons\
    \ that led to the development of the three distinct types of data fusion that\
    \ are\ndiscussed in the paragraph that follows this one. In the second step, all\
    \ of the distinct\nobjects that are mentioned in the various data sources have\
    \ to be located and arranged in\nthe correct order. Because misalignments can\
    \ lead to inconsistent representations and, as\na result, unreliable answers,\
    \ this step is particularly important when the data sources are\nimages. Alignment\
    \ errors are a common cause of these problems. The third step, which\nis the application\
    \ of the actual data fusion, can be carried out once the data have been\ncorrectly\
    \ identiﬁed and are consistent. In actual practice, addressing the inconsistent\
    \ data\nthat already exist is frequently ignored. Auxiliary tools, such as data\
    \ proﬁle techniques,\nwhich can reduce inconsistencies by extracting and exploring\
    \ the metadata associated to\nthe data being fused, have the potential to (at\
    \ least partially) rectify this situation and bring\nit closer to an acceptable\
    \ state.\nWe essentially perform data fusion on satellite images and drone images\
    \ and then on\nvarious types of sensors using two different methodologies.\nGeomatics\
    \ uses various types of data (remote sensing from satellites, UAVs, and\nother\
    \ data), so data fusion techniques are natural depending on the various applications\n\
    to be carried out. This work aims to present on a study area the integration of\
    \ remote\nsensing techniques, UAVs, autonomous driving machines, data fusion,\
    \ and GIS in order\nto optimize the vineyard by optimizing cultivation and production\
    \ by managing data\nof various types acquired with different methodologies. Geomatics-type\
    \ methodologies\nused in other works and integrated here are speciﬁcally applied\
    \ in this note for use and\noptimisation to contribute to agriculture 4.0.\n3.\
    \ Case Study\nIn the course of our research on a broader study area, focusing\
    \ in particular on a\nvineyard that was located in Bova Superiore, a small municipality\
    \ in the province of\nReggio Calabria (South Italy), neighbourhood Briga, and\
    \ that encompassed an area of\napproximately 2.2 hectares. The cultivated territory\
    \ includes a series of parcels cultivated\nas vineyards, the most representative\
    \ of which have, respectively, extensions of about 3.2 ha\nand 1.8 ha (Figure\
    \ 1).\nThe vineyard is located on a sloping land with a varied morphology, with\
    \ an alti-tude\nranging from 600 to 800 m above sea level and an orientation mainly\
    \ facing south.\nThe distance between rows is two meters, there is a gap of one\
    \ metre between each\nrow, and the width of the canopy along each row is approximately\
    \ one metre. The planting\ntook place in 2016 at the earliest.\nThere were differences\
    \ in the vine’s vigour both within and between the plots that\nare likely to be\
    \ found in the vineyard due to the irregular land morphology, such as soil\ncharacteristics\
    \ and elevation.\nSensors 2022, 22, 7910\n9 of 23\nSensors 2022, 22, x FOR PEER\
    \ REVIEW \n9 of 23 \n \n \n \n \nFigure 1. Study area: Bova Superiore in Calabria,\
    \ Southern Italy. \nThe vineyard is located on a sloping land with a varied morphology,\
    \ with an alti-\ntude ranging from 600 to 800 m above sea level and an orientation\
    \ mainly facing south. \nThe distance between rows is two meters, there is a gap\
    \ of one metre between each \nrow, and the width of the canopy along each row\
    \ is approximately one metre. The plant-\ning took place in 2016 at the earliest.\
    \ \nThere were differences in the vine’s vigour both within and between the plots\
    \ that \nare likely to be found in the vineyard due to the irregular land morphology,\
    \ such as soil \ncharacteristics and elevation. \n3.1. Remote Sensing and UAV\
    \ \nIn this study area, some experiments were conducted to test what we said above\
    \ for \nagriculture 4.0. with particular reference to vineyards. \nWe conducted\
    \ survey campaigns using satellites and drones between May and Oc-\ntober of 2021\
    \ in order to extend the scope of the study to include different phenological\
    \ \nphases of vines. Since the vigour does change over the course of the phenological\
    \ cycle, \nwe decided to acquire images at four different stages between flowering\
    \ and ripening so \nthat we could examine the plant in its various vegetative\
    \ states. On the other hand, certain \nclimatological patterns (such as below-average\
    \ rainfall), which impeded the growth of \nplants, contributed to the stress that\
    \ was experienced by the crops. \nAs satellite data were used, a Sentinel-2 Level\
    \ 2A image was acquired on 24 May, 28 \nJuly, 27 August, and 21 September 2020\
    \ at 09:40 UTC and the image characteristics are \nreported in Table 1, and a\
    \ WorldView-3 image acquired on 21 October 2021 (you can see \nan example of this\
    \ in Figure 2). \nTable 1. Characteristics of satellite Sentinel 2 imagery. \n\
    Sentinel 2 \nNo. channels \n13 \nSpectral bands used \nB4-Red 650–680 nm \nB8-NIR\
    \ 770–810 nm \nGround Sampling Distance (GSD) per band \n10 m \nGround Dimension\
    \ of the image \n100 km × 100 km \nFigure 1. Study area: Bova Superiore in Calabria,\
    \ Southern Italy.\n3.1. Remote Sensing and UAV\nIn this study area, some experiments\
    \ were conducted to test what we said above for\nagriculture 4.0. with particular\
    \ reference to vineyards.\nWe conducted survey campaigns using satellites and\
    \ drones between May and October\nof 2021 in order to extend the scope of the\
    \ study to include different phenological phases of\nvines. Since the vigour does\
    \ change over the course of the phenological cycle, we decided\nto acquire images\
    \ at four different stages between ﬂowering and ripening so that we could\nexamine\
    \ the plant in its various vegetative states. On the other hand, certain climatological\n\
    patterns (such as below-average rainfall), which impeded the growth of plants,\
    \ contributed\nto the stress that was experienced by the crops.\nAs satellite\
    \ data were used, a Sentinel-2 Level 2A image was acquired on 24 May, 28\nJuly,\
    \ 27 August, and 21 September 2020 at 09:40 UTC and the image characteristics\
    \ are\nreported in Table 1, and a WorldView-3 image acquired on 21 October 2021\
    \ (you can see an\nexample of this in Figure 2).\nTable 1. Characteristics of\
    \ satellite Sentinel 2 imagery.\nSentinel 2\nNo. channels\n13\nSpectral bands\
    \ used\nB4-Red 650–680 nm\nB8-NIR 770–810 nm\nGround Sampling Distance (GSD) per\
    \ band\n10 m\nGround Dimension of the image\n100 km × 100 km\nRegarding instead\
    \ the multispectral images obtained by drone, it is noted that a DJI\nMatrice\
    \ 600 Pro drone [51] was used, integrating a multispectral sensor, Micasense Altum\n\
    Camera [52] suitable for use in agriculture and with the ability to capture images\
    \ of crops\nin both the visible spectrum and the infrared spectrum simultaneously.\
    \ The following\ncomponents are included in this system:\n•\nA multispectral sensor\
    \ recording crop images of crops in four spectral bands: Green\n(500 nm Bandwidth\
    \ 40 nm), Red (660 nm Bandwidth 40 nm), Red-edge (735 nm\nBandwidth 10 nm) and\
    \ Near Infrared (790 nm Bandwidth 40 nm).\n•\nAn RGB camera (16 MP).\n•\nAn integrated\
    \ 64 GB memory.\nSensors 2022, 22, 7910\n10 of 23\n•\nA built-in brightness sensor\
    \ (‘sunshine’ sensor) that records light situation and cali-\nbrates automatically\
    \ the four multispectral sensors. The ‘sunshine’ sensor inte-grates\nan SD card\
    \ slot to expand storage capacity.\n•\nGPS and IMU (Inertial Measurement Unit).\n\
    •\nTable 2 shows UAV, sensor’s image and characteristics.\nSensors 2022, 22, x\
    \ FOR PEER REVIEW \n10 of 23 \n \n \nFigure 2. WorldView-3 acquired on 21 October\
    \ 2021, resolution 30 cm, subset of the province of \nReggio Calabria including\
    \ the study area. \nRegarding instead the multispectral images obtained by drone,\
    \ it is noted that a DJI \nMatrice 600 Pro drone [51] was used, integrating a\
    \ multispectral sensor, Micasense Altum \nCamera [52] suitable for use in agriculture\
    \ and with the ability to capture images of crops \nin both the visible spectrum\
    \ and the infrared spectrum simultaneously. The following \ncomponents are included\
    \ in this system: \n• \nA multispectral sensor recording crop images of crops\
    \ in four spectral bands: Green \n(500 nm Bandwidth 40 nm), Red (660 nm Bandwidth\
    \ 40 nm), Red-edge (735 nm Band-\nwidth 10 nm) and Near Infrared (790 nm Bandwidth\
    \ 40 nm). \n• \nAn RGB camera (16 MP). \n• \nAn integrated 64 GB memory. \n• \n\
    A built-in brightness sensor (‘sunshine’ sensor) that records light situation\
    \ and cali-\nbrates automatically the four multispectral sensors. The ‘sunshine’\
    \ sensor inte-grates \nan SD card slot to expand storage capacity. \n• \nGPS and\
    \ IMU (Inertial Measurement Unit). \n• \nTable 2 shows UAV, sensor’s image and\
    \ characteristics. \nTable 2. Platforms and sensor used: DJI Matrice 600 Pro and\
    \ Micasense Altum Camera. \n \n \nNo. channels \n4 \nSpectral bands \nB2–Red 640–680\
    \ mm \nB4–NIR 770–810 nm \nGSD per band \n5.2 cm \nFlight speed \n30 km/h \nFlight\
    \ altitude \n30 m \nFOV–Field-of-view \n48° × 36.8° \nGround Dimension of \nthe\
    \ Image \n160 m × 30 m \n100 m × 35 m \nBy carefully defining the sets of waypoints\
    \ along the UAV route, it was possible to \nensure that the aircraft would fly\
    \ at a height of approximately 30 m above the ground. \nWith these parameters,\
    \ the aerial GSD images measure 5 cm (Table 2). \nFigure 2. WorldView-3 acquired\
    \ on 21 October 2021, resolution 30 cm, subset of the province of\nReggio Calabria\
    \ including the study area.\nTable 2. Platforms and sensor used: DJI Matrice 600\
    \ Pro and Micasense Altum Camera.\n \n \nFigure 2. WorldView-3 acquired on 21\
    \ October 2021, resolution 30 cm, subset of the province of \nReggio Calabria\
    \ including the study area. \nRegarding instead the multispectral images obtained\
    \ by drone, it is noted that a DJI \nMatrice 600 Pro drone [51] was used, integrating\
    \ a multispectral sensor, Micasense Altum \nCamera [52] suitable for use in agriculture\
    \ and with the ability to capture images of crops \nin both the visible spectrum\
    \ and the infrared spectrum simultaneously. The following \ncomponents are included\
    \ in this system: \n• \nA multispectral sensor recording crop images of crops\
    \ in four spectral bands: Green \n(500 nm Bandwidth 40 nm), Red (660 nm Bandwidth\
    \ 40 nm), Red-edge (735 nm Band-\nwidth 10 nm) and Near Infrared (790 nm Bandwidth\
    \ 40 nm). \n• \nAn RGB camera (16 MP). \n• \nAn integrated 64 GB memory. \n• \n\
    A built-in brightness sensor (‘sunshine’ sensor) that records light situation\
    \ and cali-\nbrates automatically the four multispectral sensors. The ‘sunshine’\
    \ sensor inte-grates \nan SD card slot to expand storage capacity. \n• \nGPS and\
    \ IMU (Inertial Measurement Unit). \n• \nTable 2 shows UAV, sensor’s image and\
    \ characteristics. \nTable 2. Platforms and sensor used: DJI Matrice 600 Pro and\
    \ Micasense Altum Camera. \n \n \nNo. channels \n4 \nSpectral bands \nB2–Red 640–680\
    \ mm \nB4–NIR 770–810 nm \nGSD per band \n5.2 cm \nFlight speed \n30 km/h \nFlight\
    \ altitude \n30 m \nFOV–Field-of-view \n48° × 36.8° \nGround Dimension of \nthe\
    \ Image \n160 m × 30 m \n100 m × 35 m \nBy carefully defining the sets of waypoints\
    \ along the UAV route, it was possible to \nensure that the aircraft would fly\
    \ at a height of approximately 30 m above the ground. \nWith these parameters,\
    \ the aerial GSD images measure 5 cm (Table 2). \n \n \nNo. channels\n4\nSpectral\
    \ bands\nB2–Red 640–680 mm\nB4–NIR 770–810 nm\nGSD per band\n5.2 cm\nFlight speed\n\
    30 km/h\nFlight altitude\n30 m\nFOV–Field-of-view\n48◦ × 36.8◦\nGround Dimension\
    \ of\nthe Image\n160 m × 30 m\n100 m × 35 m\nBy carefully deﬁning the sets of\
    \ waypoints along the UAV route, it was possible to\nensure that the aircraft\
    \ would ﬂy at a height of approximately 30 m above the ground. With\nthese parameters,\
    \ the aerial GSD images measure 5 cm (Table 2).\n3.2. Self-Driving Vehicles/GIS\n\
    Regarding self-driving vehicles, an old experiment was adapted to simulate the\
    \ be-\nhaviour of one or more tractors. The experiments we have conducted in the\
    \ past concern\nself-driving vehicles intended for road monitoring, in Figure\
    \ 3.\nIn this case, they are applied to agriculture monitoring.\nThe following\
    \ items make up the standard instrumental equipment for such surveys:\n•\ncameras\
    \ that can capture images and movies and enable the acquisition and possibly\n\
    later categorisation of objects, as well as integration with the mapping of the\
    \ network\ntechnology in the area (water, electric, telephone, gas, etc.);\n•\n\
    Odometers and GPS.\nSensors 2022, 22, 7910\n11 of 23\n \n \n3.2. Self-Driving\
    \ Vehicles/GIS \nRegarding self-driving vehicles, an old experiment was adapted\
    \ to simulate the be-\nhaviour of one or more tractors. The experiments we have\
    \ conducted in the past concern \nself-driving vehicles intended for road monitoring,\
    \ in Figure 3. \n \nFigure 3. Equipped self-driving vehicle. \nIn this case, they\
    \ are applied to agriculture monitoring. \nThe following items make up the standard\
    \ instrumental equipment for such surveys: \n• \ncameras that can capture images\
    \ and movies and enable the acquisition and possibly \nlater categorisation of\
    \ objects, as well as integration with the mapping of the network \ntechnology\
    \ in the area (water, electric, telephone, gas, etc.); \n• \nOdometers and GPS.\
    \ \nThe combination of uses will be determined by the kind of survey being conducted\
    \ \nor the result that is to be obtained. \nThe use of Global Navigation Satellite\
    \ System (GNSS) data and the transfer of infor-\nmation between the vehicle and\
    \ the processing centre are essential components of any \ntracking system. In\
    \ order to determine the position of the vehicle automatically, an exper-\niment\
    \ was carried out in advance to assess the efficacy of the various configurations;\
    \ we \nselected the European Geostationary Navigation Overlay System (EGNOS) and\
    \ the Real-\nTime Kinematic (RTK) method to check their respective performances.\
    \ \nThe technological components of the system consist of a device for detecting\
    \ the po-\nsition (GPS), a transmission device (mobile phone), and a data processing\
    \ centre equipped \nwith a GIS platform. In addition to other information that\
    \ is gleaned from active sensors \non the vehicle, the data pertaining to the\
    \ vehicle’s position and its instantaneous speed \nare transmitted from the vehicle\
    \ to a processing point that is in charge of maintaining a \ndatabase of field\
    \ data. \nUsing a digital map of the area, special algorithms were applied to\
    \ reduce errors, as \npositioning errors were present. These algorithms combine\
    \ the position and trajectory of \nthe vehicle as determined by the sensors with\
    \ the routes that are available on the digital \nmap. In the meantime, the information\
    \ that is sent from the vehicle using the various sen-\nsors used enables an update\
    \ to be made to the maps in terms of the routes to optimise the \ntractor’s path.\
    \ \nIn order to determine the location of the vehicle, we analysed the results\
    \ of both the \nEGNOS and RTK positioning systems and compared them. However,\
    \ in order to calculate \nthe position object, the RTK method requires real-time\
    \ data processing, whereas the \nEGNOS system immediately provides location data.\
    \ Although it requires more computa-\ntional work, RTK provides more precise results\
    \ than EGNOS does. When it comes to hard-\nware instrumentation and software,\
    \ the use of EGNOS is reliant on commercially availa-\nble devices, whereas the\
    \ RTK method necessitates the creation of customized software \narchitecture.\
    \ \nIn terms of communication systems, the possibility of using a Wi-Fi network\
    \ offers \nbenefits in terms of costs and speed as a result of the extremely low\
    \ latency, but it also \nFigure 3. Equipped self-driving vehicle.\nThe combination\
    \ of uses will be determined by the kind of survey being conducted or\nthe result\
    \ that is to be obtained.\nThe use of Global Navigation Satellite System (GNSS)\
    \ data and the transfer of infor-\nmation between the vehicle and the processing\
    \ centre are essential components of any\ntracking system. In order to determine\
    \ the position of the vehicle automatically, an ex-\nperiment was carried out\
    \ in advance to assess the efﬁcacy of the various conﬁgurations;\nwe selected\
    \ the European Geostationary Navigation Overlay System (EGNOS) and the\nReal-Time\
    \ Kinematic (RTK) method to check their respective performances.\nThe technological\
    \ components of the system consist of a device for detecting the posi-\ntion (GPS),\
    \ a transmission device (mobile phone), and a data processing centre equipped\n\
    with a GIS platform. In addition to other information that is gleaned from active\
    \ sensors\non the vehicle, the data pertaining to the vehicle’s position and its\
    \ instantaneous speed\nare transmitted from the vehicle to a processing point\
    \ that is in charge of maintaining a\ndatabase of ﬁeld data.\nUsing a digital\
    \ map of the area, special algorithms were applied to reduce errors, as\npositioning\
    \ errors were present. These algorithms combine the position and trajectory of\n\
    the vehicle as determined by the sensors with the routes that are available on\
    \ the digital\nmap. In the meantime, the information that is sent from the vehicle\
    \ using the various\nsensors used enables an update to be made to the maps in\
    \ terms of the routes to optimise\nthe tractor’s path.\nIn order to determine\
    \ the location of the vehicle, we analysed the results of both the\nEGNOS and\
    \ RTK positioning systems and compared them. However, in order to calculate\n\
    the position object, the RTK method requires real-time data processing, whereas\
    \ the EGNOS\nsystem immediately provides location data. Although it requires more\
    \ computational work,\nRTK provides more precise results than EGNOS does. When\
    \ it comes to hardware instru-\nmentation and software, the use of EGNOS is reliant\
    \ on commercially available devices,\nwhereas the RTK method necessitates the\
    \ creation of customized software architecture.\nIn terms of communication systems,\
    \ the possibility of using a Wi-Fi network offers\nbeneﬁts in terms of costs and\
    \ speed as a result of the extremely low latency, but it also offers\ndrawbacks\
    \ in terms of the distance limits that can exist between antennas and the signal\n\
    quality that can be achieved. In most cases, the maximum permissible distance\
    \ between\nantennas is one hundred meters when the weather is clear, there is\
    \ a direct line of sight\nbetween them, and there are no obstructions in the way.\
    \ The signal quality can be affected\nby a variety of parameters, including the\
    \ kind of antenna that is used and the possibility\nof interference.\nThe use\
    \ of the mobile phone network, on the other hand, has a number of beneﬁts,\nincluding\
    \ complete independence among stations and vehicles, increased reliability due\n\
    to the fact that it does not require compliance with minimum distances, and the\
    \ capacity\nto process remote data remotely. The disadvantages include signiﬁcantly\
    \ higher latencies\nand increased costs. This is due to the fact that every device\
    \ needs to be outﬁtted with a\nmobile network modulus and a SIM card that is associated\
    \ with a particular data plan or a\nphone contract.\nSensors 2022, 22, 7910\n\
    12 of 23\nAn open-source GIS/WebGIS was used for the processing and visualisation\
    \ of the\nvarious data acquired. The GIS/WebGIS displays the results of the processing\
    \ and the\noptimal routing of the routes, as well as highlighting the needs and\
    \ requirements of the\narea, such as the need for irrigation timing, fertilisation\
    \ timing, and anything else that may\nbe useful for Agriculture 4.0, with appropriate\
    \ alerts based on data fusion with other data.\nIn order to verify the effectiveness\
    \ of the development, a platform for transmission to\nthe GIS and user interface\
    \ is created; it runs a procedure called Data Transfer GIS (DTGIS)\nfor the subsequent\
    \ export of the data acquired within the GIS, where the “historical” update\n\
    is managed in the existing database.\nIn more detail, the DTGIS was designed to\
    \ automatically transfer data acquired in\nthree software modules, each with its\
    \ own set of functions, to the GIS:\nThe Plug-in Module, which increases the number\
    \ of recognizable and classiﬁable\nobjects that can be represented;\nThe kernel,\
    \ which interacts with users and coordinates the different modules, pre-\nprocessing\
    \ and post-processing the Input/Output data of the modules themselves;\nThe GIS\
    \ I/O (Input/Output) Module, which manages the interface with the GIS software.\n\
    In particular, the ﬁles (space database where the various attributes have been\
    \ assigned\nto the objects) are given in Input in the GIS I/O module, returning\
    \ Output polylines and\npolygons in shp-dbf format.\nTo implement the proposed\
    \ system, a variety of algorithms and methodologies were\nused. Speciﬁcally, a\
    \ multi-objective function based on Genetic Algorithms was used to\ndetermine\
    \ the tractor’s route.\nFurthermore, using Machine Learning algorithms, real-time\
    \ hourly and continuous\ncycle trend information was obtained based on a comparison\
    \ with recent and historical\ndata (including the Backpropagation algorithm for\
    \ the historical series).\nIFTTT (If This Then That) is a programming language\
    \ that allows for the real-time\ncreation of condition chains called applets that\
    \ are triggered by other services (e.g., Gmail,\nFacebook, Instagram, etc.) and\
    \ can send a message when the user, for example, uses a\nhashtag in a tweet, or\
    \ can send a copy of a Facebook photo to an archive when the user is\ntagged in\
    \ it. IFTTT can automate processes related to home automation or web applications,\n\
    such as receiving personalized weather forecasts or alerts in the event of an\
    \ emergency,\nsuch as a ﬂood. In our case, we used this service to send alerts\
    \ and to automate tractor’s\nroute when an alert is received.\nApplet programming\
    \ logic is of the following type: if a predetermined event occurs\n(trigger),\
    \ then perform a predetermined action.\n3.3. Other Types of Sensors\nA wide range\
    \ of available sensors can contribute signiﬁcantly to agricultural practices.\n\
    With the availability of low-cost data processing, solar panels, improved batteries\
    \ and\ncommunications technology, the trend is now for these to operate wirelessly\
    \ and transmit\ndata to the user rather than relying on manual data collection.\
    \ A variety of sensors are\navailable for this purpose, including soil temperature,\
    \ soil moisture content, air temperature\nand relative humidity, rainfall, solar\
    \ radiation, barometric pressure, leaf wetness and wind\nspeed and direction.\n\
    3.3.1. Soil Moisture Sensor\nAs mentioned above, the ability to integrate several\
    \ sensors is of crucial importance.\nFor example, the Soil Moisture Sensor is\
    \ used to measure volumetric moisture content of\nsoils and other material for\
    \ scientiﬁc research and agricultural applications. The sensor\nmeasures volumetric\
    \ water content via the dielectric constant of the soil using capacitance\ntechnology.\
    \ It uses a 70 MHz frequency, which minimizes salinity and textural effects,\n\
    making it an ideal sensor in agricultural and standard scientiﬁc projects. Speciﬁcations\
    \ on\ncharacteristics of the Soil Moisture Sensor are given in Table 3.\nSensors\
    \ 2022, 22, 7910\n13 of 23\nTable 3. Characteristics of the Soil Moisture Sensor.\n\
    Property\nCharacteristics\nAccuracy\nApparent Dielectric Permittivity (εa): ±0.5\
    \ from εa of 2 to 10, ±2.5\nfrom εa of 10 to 50\nSoil Volumetric Water Content\
    \ (VWC): Using standard calibration\nequation: ±0.03 m3/m3 (±3% VWC) typical in\
    \ mineral soils that have\nsolution electrical conductivity < 10 dS/m; using soil\
    \ speciﬁc\ncalibration, ±0.02 m3/m3 (±2% VWC) in any soil\nResolution\nεa: 0.1\
    \ from εa of 1 to 30, 0.2 from εa of 30 to 50\nVWC: 0.0008 m3/m3 (0.08% VWC) in\
    \ mineral soils from 0 to 0.50\nm3/m3 (0–50% VWC).\nRange\nεa: 1 (air) to 50\n\
    VWC: Calibration dependent; up to 0–57% VWC with\npolynomial equation\nSensor\
    \ Type\nCapacitance (frequency domain)\nDimensions\n14.5 cm × 3.3 cm × 0.7 cm\n\
    5.5\nReduced soil microbial activity\nCable length\nSensors come standard with\
    \ 5 m cable. Custom cable lengths available.\nMaximum cable length of 40 m. Please\
    \ contact Decagon if you need\nlonger cable lengths.\nMeasurement Time\n10 ms\n\
    Power\n3 VDC @ 12 mA–15 VDC @ 15 mA\nOutput\n300–1250 mV, independent of excitation\
    \ voltage\nOperative\nEnvironment\nSurvival Temperature: −40–50 ◦C\nOperating\
    \ Temperature: 0–50 ◦C\nConnector Types\n3.5 mm “stereo” plug or stripped and\
    \ tinned lead wires\n3.3.2. Leaf Wetness Sensor\nMost of these are based on well-known\
    \ techniques and are used in other applications,\nbut the leaf wetness sensor\
    \ is aimed speciﬁcally at agricultural use and comprises a surface\nof conductive\
    \ combs with a resistance of 2 MΩ when dry. This falls when condensation\noccurs\
    \ on the surface, reaching approximately 5 kΩ when completely wet. The sensor\n\
    generates a voltage that is inversely proportional to the degree of condensation.\n\
    3.3.3. PH Sensor\nThe PH (Potential Hydrogen) meter is a device used to measure\
    \ acidity and alkalinity\nlevels in water, soil and photo chemicals. The PH meter\
    \ consists of a voltmeter attached to\na pH-responsive electrode varying in the\
    \ range of 0 to 14.\nThe solutions with a pH value between 0 and 7 are acidic\
    \ solutions with a large\nconcentration of hydrogen ions, whereas solutions with\
    \ a pH value between 8 and 14 have\nbasic solutions with small concentrations\
    \ of hydrogen. Solutions with a pH value of 7 are\nneutral solutions. In this\
    \ process, we can detect the pH levels in the soil, in Table 4.\n3.3.4. Temperature\
    \ and Humidity Sensor\nThe sensor has a humidity measuring module, a thermistor\
    \ and an integrated circuit on\nthe back of the sensor unit. The humidity measurement\
    \ module consists of two electrodes.\nSandwiched between the two electrodes is\
    \ a substrate that is capable of holding moisture.\nChange in humidity alters\
    \ the conductivity of the moisture-holding substrate, which at the\nsame time\
    \ changes the resistance. The integrated circuit then processes the change in\
    \ the\nresistance and the humidity value is measured. On the other hand, a change\
    \ in temperature\nchanges the resistance of the thermistor, which is processed\
    \ by the integrated circuit and\nthe calibration results in a temperature value.\n\
    Sensors 2022, 22, 7910\n14 of 23\nTable 4. PH (potential of Hydrogen) values and\
    \ plants growth.\nSoil pH\nPlant Growth\n>8.3\nToo alkaline for most plants\n\
    7.5\nIron availability becomes a problem on alkaline soils.\n7.2\n6.8 to 7.2–near\
    \ neutral\n6.0 to 7.5–acceptable for most plants\n7.0\n6.8\n5.5\nReduced soil\
    \ microbial activity\n<4.6\nToo acidic for most plants\n3.3.5. Barometric Pressure\
    \ Sensor\nBarometric pressure sensors measure the absolute pressure of the air\
    \ around them.\nThis pressure varies with both the weather and altitude. Depending\
    \ on how you interpret\nthe data, you can monitor changes in the weather, measure\
    \ altitude, or any other tasks that\nrequire an accurate pressure reading. The\
    \ sensor consists of a piezoelectric transducer based\non the characteristic of\
    \ silicon to generate an electrical potential difference proportional to\nthe\
    \ mechanical stress applied on its surface. This type of transducer is characterized\
    \ by\nextremely accurate performance and stable measurements of atmospheric pressure,\
    \ with\nexcellent repeatability and low hysteresis. An electronic ampliﬁer circuit\
    \ normalizes the\noutput signal in the most common formats used by acquisition\
    \ circuits (0–1 V, 4–20 mA).\nAn electrical circuit for compensating the temperature\
    \ allows more accurate measurements.\n3.4. Data Fusion\nAs mentioned in Section\
    \ 2.4, we use two different methodologies to perform data\nfusion on satellite\
    \ and drone images, as well as data fusion on various types of sensors.\nSensors\
    \ are used in agriculture for everything from weather monitoring to self-\nwatering.\
    \ Designers can create a prototype for a hardware environment to implement\nthe\
    \ data acquisition and mining process by using low-cost sensors. Thus, the relationship\n\
    between sensors can be understood, and a sensor fusion test environment can be\
    \ created.\nVarious input devices are synchronized using a microcontroller system,\
    \ and all data ob-\ntained from the sensors is wirelessly sent to the cloud by\
    \ an IoT (Internet of Things) device,\nby recording and monitoring from the graphical\
    \ user interface on the web as a real-time\nenvironment to apply data mining algorithms\
    \ later. So, we obtain sensor data relations\nfrom various different data sources,\
    \ such as soil moisture, but it is also possible to obtain\ndata on light, temperature,\
    \ humidity, rain, atmospheric pressure, air quality, and dew point.\nIn the ﬁrst\
    \ experiment illustrated here, we use the soil moisture sensor. Each sensor data\n\
    reading has a different effect on agricultural monitoring; however, reducing the\
    \ number of\nsensors can reduce the cost of a system while still providing accurate\
    \ observations via the\nproposed sensor substitution. A hardware test prototype,\
    \ as well as a software design, are\ncreated for data monitoring and sensor fusion\
    \ in various combinations.\nAcquiring useful data from agricultural areas has\
    \ always been difﬁcult because they\nare often vast, remote, and vulnerable to\
    \ weather events. Despite these obstacles, as\ntechnology advances and prices\
    \ fall, a ﬂood of new data is being collected. Although\na wealth of data is being\
    \ collected at various scales (e.g., proximal, aerial, satellite, and\nancillary\
    \ data), this has been geographically unequal, leaving some areas virtually devoid\n\
    of useful data to help them face their speciﬁc challenges. However, even in areas\
    \ with\nabundant resources and well-developed infrastructure, data and knowledge\
    \ gaps persist,\nowing to the fact that agricultural environments are mostly uncontrolled\
    \ and there are\na plethora of factors that must be considered and properly measured\
    \ in order to fully\ncharacterize a given area. As a result, even with very effective\
    \ algorithms and a well-\ndeﬁned and limited-scope problem, data from a single\
    \ sensor type are frequently unable to\nprovide unambiguous answers. One possible\
    \ solution that has been researched for decades\nis fusing the information contained\
    \ in different sensors and data types. The concept behind\ndata fusion is to investigate\
    \ the complementarities and synergies of various types of data in\nSensors 2022,\
    \ 22, 7910\n15 of 23\norder to extract more reliable and useful information about\
    \ the areas being studied. While\nsome success has been achieved, there are still\
    \ many obstacles that prevent this type of\napproach from becoming more widely\
    \ adopted. This is especially true in agricultural areas,\nwhich have highly complex\
    \ environments.\nAmong the various data fusion methods, kriging was used, the\
    \ weights of which were\nthought of as space variants and determined from calculations\
    \ applied to plant growth\nphenomenology. In other words, rainfall and weather\
    \ values in general, NDVI at varying\nseasons, and soil type were sampled at certain\
    \ target points, from which a certain value of\nsoil moisture was estimated. From\
    \ these values, kriging was carried out at the location of\nthe moisture sensor\
    \ and compared with this truth value. The typical abatement parameters\nof the\
    \ method are varied until a conﬁguration of minima is found for which the value\n\
    calculated by kriging and the value measured by the sensor are small. At this\
    \ point, these\nabatement parameters can be used for kriging applicators to neighbouring\
    \ areas, either\nfrom points observed by humidity sensors or derived from other\
    \ devices.\nSo far, we have talked about data fusion between different sensors,\
    \ but data fusion\nbetween images and sensors is also possible, as is the use\
    \ of neural networks to improve\nimage resolution.\nThe technology associated\
    \ with the use of drones has undergone strong development\nin the last decade\
    \ by improving the stability of the craft, lightening the structure, perfect-\n\
    ing the precision and accuracy of acquisition and optimising the software for\
    \ processing\ndata. Among other things, this technology ﬁnds application in environmental\
    \ monitoring,\ncombining data acquisition over a wide area with high resolution\
    \ and multispectral infor-\nmation. However, surveying with UAVs (Unmanned Aerial\
    \ Vehicles) is not always cheaper\nthan using satellite data. This is where the\
    \ use of machine learning, and in particular,\nSuperResolution, comes in.\nThe\
    \ freely available satellite data, as far as the Sentinel missions of the Copernicus\n\
    programme are concerned, give a considerable advantage, but the resolution of\
    \ these data\nmay be too low for the studies to be carried out. It is therefore\
    \ necessary to intervene\nwith processing methods to improve the quality of the\
    \ data. Furthermore, the timing of\nacquisition favours the use of satellite data\
    \ over the drone survey and the processing of the\nrelated data because it is\
    \ time-consuming. The satellite data, on the other hand, supplied\nalready corrected\
    \ in terms of reﬂectance, are directly usable after downloading.\nWith the use\
    \ of a convolutional neural network, a procedure is applied that uses the\nsatellite\
    \ images as the basic data and allows a higher resolution product to be obtained.\
    \ To\nachieve this, the VDSR (Very Deep Super Resolution) neural network is iplemented,\
    \ using\nimages acquired by drone for training the network. The aim of this work\
    \ is to study the\napplicability of the VDSR (Very Deep Super Resolution) neural\
    \ network in the context of\nremote sensing, using drone images as data.\nSuper-resolution,\
    \ a process for obtaining high-resolution images from low-resolution\nimages,\
    \ compensates in Remote Sensing for limitations due to a spatial resolution that\
    \ is\nnot always adequately detailed. Single Image Super-Resolution (SIRS), in\
    \ particular, aims\nto construct a high-resolution image from a single low-resolution\
    \ image. A basic approach\nto achieve the improvement of an image’s resolution\
    \ is interpolation, but there are other,\nmore elaborate strategies that have\
    \ the same goal.\nThe deep learning algorithm VDSR (Very-Deep Super-Resolution)\
    \ is one of the possible\ntechniques that can be used to perform the SISR process.\
    \ Initially, the training of the\nneural network is necessary in order to then\
    \ use the VDSR network to obtain a high-\nresolution image from a single low-resolution\
    \ image. VDSR is a convolutional neural\nnetwork CNN (Convolutional Neural Network)\
    \ with the aim of relating high- and low-\nresolution images that differ mainly\
    \ in high-frequency detail. The procedure is based on\ndetermining the residuals\
    \ between the two images, i.e., a high-resolution reference image\nand a low-resolution\
    \ image scaled to the same size as the reference image by means of\nbicubic interpolation.\n\
    Sensors 2022, 22, 7910\n16 of 23\nThe objective of the multispectral analysis\
    \ was the calculation of the NDVI index,\nwhich can be obtained from the Red and\
    \ NIR band.\nThe tests carried out on areas of different extension highlight the\
    \ different possibility of\nusing the image processed with the VDSR network as\
    \ the survey area varies. For a portion\nof territory of the order of magnitude\
    \ of one hundred metres, the data acquired with a\ndrone possess resolution and\
    \ detail that the other images cannot represent. For an area of\napproximately\
    \ 25 hectares, the improvement obtained by processing with the VDSR neural\nnetwork\
    \ is enhanced; the extension is high enough to evaluate the use of the drone carefully,\n\
    but not so large as to accept the detail of the satellite image. Here, the use\
    \ of the neural\nnetwork emphasises the edges of the framed elements more strongly,\
    \ making them more\neasily recognisable. For an analysis area of the order of\
    \ magnitude of several kilometres\nsideways or larger, processing with a VDSR\
    \ neural network offers an improvement, but\nthe detail required by the study\
    \ can also be satisﬁed by using the original satellite image.\nA crucial aspect\
    \ in the application of deep learning, which must be carefully evaluated in\n\
    combination with the desired image enhancement, is the computing power required\
    \ to\nperform the processing. The processing time for both the training of the\
    \ neural network\nand its activation is non-negligible if adequate equipment is\
    \ not available. To give an\nexample, the training of the VDSR network used for\
    \ the analyses in this study would have\ntaken about ten days on an average commercial\
    \ laptop with an Intel Core i5 5th Generation\nprocessor and 8-Gigabyte RAM. Furthermore,\
    \ obtaining an image with a larger pixel size\nthan the satellite image also increases\
    \ the calculation time for subsequent processing, such\nas classiﬁcation. The\
    \ time factor negatively affects the evaluation of the practical use of the\n\
    neural network, particularly when compared to other methods of improving the resolution\n\
    of an image, such as interpolation.\n4. Results\nAfter selecting from the Sentinel\
    \ and WorldView images and UAVs multispectral im-\nages, and other sensor (Soil\
    \ Moisture Sensor) data, a data fusion procedure was performed\nwith particular\
    \ reference to areas A and B (Figure 4). So, a procedure has been put into place\n\
    so that the value of the NDVI can be automatically determined from satellite images.\
    \ In\norder to achieve homogenization of Sentinel and UAV data, it is necessary\
    \ to automatically\ndetermine the value of NDVI derived from satellites (NDVIsat),\
    \ through a downsampling\nof correlation between pixels s(i,j) from satellite\
    \ and P(i,j) from UAV), to calculate the NDVI\nfrom UAV (NDVIuav) and to calculate\
    \ both the NDVI for the leaf canopies of the vines\n(NDVIvin) and NDVI of inter-row\
    \ area (NDVIint). In fact, an important tool for evaluating\nthe variability in\
    \ the vineyard and therefore the vines’ vigour is the NDVI index, thus\ncalculated\
    \ for the pixels of the Sentinel and WorldView image s(i,j) thanks to the spectral\n\
    data) in RED and NIR bands:\nNDVIsat(i, j) = nN(i, j) − nR(i, j)\nnN(i, j) + nR(i,\
    \ j)\n(2)\nA preliminary downsampling method of the high-resolution UAV images\
    \ was used to\nallow the comparison of the UAV-based MSI and the satellite imaging.\
    \ So, we proceeded to\nsampling the UAVs, data (at higher resolution) for comparing\
    \ them with the corresponding\nsatellite data, i.e., the set of UAV data D corresponding\
    \ to P(i,j):\nG(i, j) = {d(u, v) ∈ D|αs(i, j + 1) ≤ αd(u, v) < αs(i, j), βs(i,\
    \ j) ≤ βd(u, v) < βs(i + 1, j), ∀u, v}\n(3)\nThus the satellite data s(i,j) and\
    \ UAV data P(i,j) show the same subset of the vineyard.\nThree NDVIs were analysed\
    \ from the VHR 2 data from the multispectral sensor mounted\non the UAV, then\
    \ compared with the satellite data on:\n•\n(i) the entire cultivated area P(i,j):\n\
    Sensors 2022, 22, 7910\n17 of 23\nNDVIuav(i, j) =\n∑u ∑v\nmN(u,v)−mR(u,v)\nmN(u,v)+mR(u,v)\n\
    card P(i, j)\n∀d(u, v) ∈ P(i, j)\n(4)\n•\n(ii) the pixels of the canopies:\nNDVIvin(i,\
    \ j) =\n∑u ∑v\nmN(u,v)−mR(u,v)\nmN(u,v)+mR(u,v)\ncard P(i, j)\n∀d(u, v) ∈ Pvin(i,\
    \ j)\n(5)\n•\n(iii) the pixels of the inter-rows:\nNDVIint(i, j) =\n∑u ∑v\nmN(u,v)−mR(u,v)\n\
    mN(u,v)+mR(u,v)\ncard P(i, j)\n∀d(u, v) ∈ Pint(i, j)\n(6)\nSensors 2022, 22, x\
    \ FOR PEER REVIEW \n18 of 23 \n \nαd(u,v) \nLatitude coordinate (in WGS84) of\
    \ pixel d(u,v) centre \nαs(i,j) \nLatitude coordinate (in WGS84) of the upper\
    \ left corner of pixel s(i,j) \nβd(u,v) \nLongitude coordinate (in WGS84) of pixel\
    \ d(u,v) centre \nβs(i,j) \nLongitude coordinate (in WGS84) of the upper left\
    \ corner of pixel s(i,j) \nIn Figure 4 the results are shown. \nFigure 4a shows\
    \ the full set of pixels obtained from the NDVIsat map, selected from \nSatellite\
    \ imagery. \nIn Figure 4b an NDVIuav map congruent (correctly aligned, at the\
    \ same spatial reso-\nlution) to those derived from satellite imagery (NDVIsat)\
    \ is shown. \nIn Figure 4c a complete NDVIvin map is shown. \nIn Figure 4d the\
    \ NDVIint map of the inter-row ground, derived by processing the \nUAV images\
    \ is shown. \n \nFigure 4. Complete NDVI (Normalized Difference Vegetation Index)\
    \ maps: (a) NDVIsat map, with \npixels fully included in “Area A” and “Area B”,\
    \ derived from satellite images S2, and (b) NDVIuav \nobtained from UAV images\
    \ D2. (c) Vineyard NDVIvin map from UAV images D2 obtained only on \ncanopy pixels\
    \ Pvin, (d) NDVIint map that considers inter-row ground Pint. \nThe use of an\
    \ image with a resolution of approximately 30 centimetres, such as a \nWorldView-3,\
    \ would still enable a better definition of the vigour of the vines and, more\
    \ \ngenerally, of the row crops. This is despite the fact that the resolution\
    \ of the drone data is \nnot comparable to that of the image. \nThe ground sampling\
    \ distance (GSD) for the panchromatic band on WorldView-3 is \n31 centimetres,\
    \ while the GSD for the eight multispectral bands is 124 centimetres. Pro-\nceeding\
    \ in the same manner as here with the UAV and using imagery obtained from the\
    \ \nWorldView-3 satellite would result in an analysis of the vigour that is significantly\
    \ more \naccurate. We could also provide a verification with Object-Based Image\
    \ Analysis (OBIA), \nfirst using segmentation of the canopies and inter-row areas,\
    \ then proceeding separately \nto the classification of the vigour through the\
    \ various NDVIs found in the extraction of \nthe objects formed with OBIA. Because\
    \ the spaces between the rows are distinguishable \n(the data obtained from the\
    \ decametric satellite sensor contribute to an inaccurate under-\nstanding of\
    \ the actual vigour of the vines), we could also provide verifying (extracting\
    \ \nobjects directly from satellite imagery is one of the strengths of OBIA, which\
    \ is used in a \nwide range of applications [22,24]). \nData fusion techniques\
    \ make it possible to obtain complete information on an area \nand on the needs\
    \ connected to cultivation from the fusion of different data [40,41] such as \n\
    Figure 4. Complete NDVI (Normalized Difference Vegetation Index) maps: (a) NDVIsat\
    \ map, with\npixels fully included in “Area A” and “Area B”, derived from satellite\
    \ images S2, and (b) NDVIuav\nobtained from UAV images D2. (c) Vineyard NDVIvin\
    \ map from UAV images D2 obtained only on\ncanopy pixels Pvin, (d) NDVIint map\
    \ that considers inter-row ground Pint.\nIn Figure 4 the results are shown.\n\
    Figure 4a shows the full set of pixels obtained from the NDVIsat map, selected\
    \ from\nSatellite imagery.\nIn Figure 4b an NDVIuav map congruent (correctly aligned,\
    \ at the same spatial resolu-\ntion) to those derived from satellite imagery (NDVIsat)\
    \ is shown.\nIn Figure 4c a complete NDVIvin map is shown.\nIn Figure 4d the NDVIint\
    \ map of the inter-row ground, derived by processing the UAV\nimages is shown.\n\
    Table 5 shows the nomenclature of the symbols used.\nThe use of an image with\
    \ a resolution of approximately 30 centimetres, such as a\nWorldView-3, would\
    \ still enable a better deﬁnition of the vigour of the vines and, more\ngenerally,\
    \ of the row crops. This is despite the fact that the resolution of the drone\
    \ data is\nnot comparable to that of the image.\nSensors 2022, 22, 7910\n18 of\
    \ 23\nTable 5. Nomenclature.\nTerm\nNomenclature\nd(u,v)\nPixel in row u and column\
    \ v of D, raster matrix\nD\nHigh-resolution UAV multispectral image\nP(i,j)\n\
    UAV pixels d(u,v) depicting the area of satellite pixels s(i,j)\nPvin(i,j)\nUAV\
    \ pixels d(u,v) showing only vines canopy\nPint(i,j)\nUAV pixels d(u,v) depicting\
    \ only inter-row ground\nNDVIsat(i,j)\nNDVI estimated using satellite images S\n\
    NDVIuav(i,j)\nEntire NDVI calculated on UAV pixels in P(i,j)\nNDVIvin(i,j)\nNDVI\
    \ calculated only on UAV pixels Pvin(i,j) that represent the vine canopy\nNDVIint(i,j)\n\
    NDVI calculated only on UAV pixels Pint(i,j) showing inter-row ground\nmN(i,j)\n\
    Reﬂectance values in the NIR band of pixels d(u,v)\nmR(i,j)\nDNs in the red band\
    \ of pixels d(u,v)\nnN(i,j)\nDNs in the NIR band of pixels s(i,j)\nnR(i,j)\nDNs\
    \ in the red band of pixels s(i,j)\ns(i,j)\nPixels of row i and column j in the\
    \ raster matrix S\nS\nMultispectral image 10 m resolution from Sentinel satellite\n\
    αd(u,v)\nLatitude coordinate (in WGS84) of pixel d(u,v) centre\nαs(i,j)\nLatitude\
    \ coordinate (in WGS84) of the upper left corner of pixel s(i,j)\nβd(u,v)\nLongitude\
    \ coordinate (in WGS84) of pixel d(u,v) centre\nβs(i,j)\nLongitude coordinate\
    \ (in WGS84) of the upper left corner of pixel s(i,j)\nThe ground sampling distance\
    \ (GSD) for the panchromatic band on WorldView-3\nis 31 centimetres, while the\
    \ GSD for the eight multispectral bands is 124 centimetres.\nProceeding in the\
    \ same manner as here with the UAV and using imagery obtained from\nthe WorldView-3\
    \ satellite would result in an analysis of the vigour that is signiﬁcantly\nmore\
    \ accurate. We could also provide a veriﬁcation with Object-Based Image Analysis\n\
    (OBIA), ﬁrst using segmentation of the canopies and inter-row areas, then proceeding\n\
    separately to the classiﬁcation of the vigour through the various NDVIs found\
    \ in the\nextraction of the objects formed with OBIA. Because the spaces between\
    \ the rows are\ndistinguishable (the data obtained from the decametric satellite\
    \ sensor contribute to an\ninaccurate understanding of the actual vigour of the\
    \ vines), we could also provide verifying\n(extracting objects directly from satellite\
    \ imagery is one of the strengths of OBIA, which is\nused in a wide range of applications\
    \ [22,24]).\nData fusion techniques make it possible to obtain complete information\
    \ on an area\nand on the needs connected to cultivation from the fusion of different\
    \ data [40,41] such as\nsatellite data and UAV images, but also from different\
    \ sensors such as soil moisture sensors\n(as Big Data [53]).\nThe automatic vehicle\
    \ is useful as it is capable of working in any terrain including\ndifﬁcult terrain\
    \ conditions, reducing human intervention.\nFigure 5 depicts the optimized tractor\
    \ path derived from data analysis, with the\nattention points for fertilization/irrigation\
    \ derived from data fusion in green.\nFinally, the GIS displays the results of\
    \ the processing (Figure 6) and the optimal\nrouting of the routes (Figure 5),\
    \ and also highlights with appropriate alerts, depending\non the data fusion with\
    \ other data, the needs and requirements of the area, such as the\nneed for irrigation\
    \ timing, fertilisation timing and anything else that may be useful for\nAgriculture\
    \ 4.0.\nFurthermore, the use of historical data implemented in the GIS makes it\
    \ possible to\nhighlight areas where the analysis of historical and socio-economic\
    \ data makes a different\nkind of cultivation appropriate (Figure 7).\nSensors\
    \ 2022, 22, 7910\n19 of 23\n \nsatellite data and UAV images, but also from different\
    \ sensors such as soil moisture sen-\nsors (as Big Data [53]). \nThe automatic\
    \ vehicle is useful as it is capable of working in any terrain including \ndifficult\
    \ terrain conditions, reducing human intervention. \nFigure 5 depicts the optimized\
    \ tractor path derived from data analysis, with the at-\ntention points for fertilization/irrigation\
    \ derived from data fusion in green. \n \nFigure 5. The optimised tractor path\
    \ obtained from data analysis, with the attention points for fer-\ntilisation/irrigation\
    \ obtained from data fusion shown in green. \nFinally, the GIS displays the results\
    \ of the processing (Figure 6) and the optimal rout-\ning of the routes (Figure\
    \ 5), and also highlights with appropriate alerts, depending on the \ndata fusion\
    \ with other data, the needs and requirements of the area, such as the need for\
    \ \nirrigation timing, fertilisation timing and anything else that may be useful\
    \ for Agriculture \n4.0. \n \n \nFigure 6. GIS (Geographic Information System),\
    \ VHR (Very High Resolution) image: green = NDVI \n(Normalized Difference Vegetation\
    \ Index) high; yellow = NDVI medium; red = NDVI low. \nFurthermore, the use of\
    \ historical data implemented in the GIS makes it possible to \nhighlight areas\
    \ where the analysis of historical and socio-economic data makes a different \n\
    kind of cultivation appropriate (Figure 7). \nFigure 5. The optimised tractor\
    \ path obtained from data analysis, with the attention points for\nfertilisation/irrigation\
    \ obtained from data fusion shown in green.\n \ntention points for fertilization/irrigation\
    \ derived from data fusion in green. \n \nFigure 5. The optimised tractor path\
    \ obtained from data analysis, with the attention points for fer-\ntilisation/irrigation\
    \ obtained from data fusion shown in green. \nFinally, the GIS displays the results\
    \ of the processing (Figure 6) and the optimal rout-\ning of the routes (Figure\
    \ 5), and also highlights with appropriate alerts, depending on the \ndata fusion\
    \ with other data, the needs and requirements of the area, such as the need for\
    \ \nirrigation timing, fertilisation timing and anything else that may be useful\
    \ for Agriculture \n4.0. \n \n \nFigure 6. GIS (Geographic Information System),\
    \ VHR (Very High Resolution) image: green = NDVI \n(Normalized Difference Vegetation\
    \ Index) high; yellow = NDVI medium; red = NDVI low. \nFurthermore, the use of\
    \ historical data implemented in the GIS makes it possible to \nhighlight areas\
    \ where the analysis of historical and socio-economic data makes a different \n\
    kind of cultivation appropriate (Figure 7). \nFigure 6. GIS (Geographic Information\
    \ System), VHR (Very High Resolution) image: green = NDVI\n(Normalized Difference\
    \ Vegetation Index) high; yellow = NDVI medium; red = NDVI low.\nEven though the\
    \ method is still experimental, exploiting applications that have already\nbeen\
    \ individually tested in other areas, these analyses nevertheless make it possible\
    \ to\nclearly highlight what the contribution to Agriculture 4.0 can be from the\
    \ integration of\nthe various technologies of Geomatics. In particular, with the\
    \ experiments carried out, it\nis possible to identify on a study area the optimal\
    \ routes for tractors, the points where\nirrigation and top dressing are required,\
    \ the areas that need intervention and the areas of\nvineyard vigour estimated\
    \ through the use of the NDVI index with the pros and cons of\nthe methodology.\n\
    Sensors 2022, 22, 7910\n20 of 23\nSensors 2022, 22, x FOR PEER REVIEW \n20 of\
    \ 23 \n \n \n \nFigure 7. GIS (Geographic Information System): areas where the\
    \ analysis of historical and socio-\neconomic data makes a different kind of cultivation\
    \ appropriate. \nEven though the method is still experimental, exploiting applications\
    \ that have al-\nready been individually tested in other areas, these analyses\
    \ nevertheless make it possible \nto clearly highlight what the contribution to\
    \ Agriculture 4.0 can be from the integration of \nthe various technologies of\
    \ Geomatics. In particular, with the experiments carried out, it \nis possible\
    \ to identify on a study area the optimal routes for tractors, the points where\
    \ \nirrigation and top dressing are required, the areas that need intervention\
    \ and the areas of \nvineyard vigour estimated through the use of the NDVI index\
    \ with the pros and cons of \nthe methodology. \n5. Conclusions \nOur article\
    \ presents an introduction to a more in-depth analysis by comparing mul-\ntispectral\
    \ vineyard imagery obtained from satellite platforms such as Sentinel-2, at a\
    \ res-\nolution of ten meters, and ultra-high-resolution imagery acquired from\
    \ WorldView satel-\nlite and low-altitude UAV platforms. Using NDVI as a measure\
    \ of vineyard vitality, we \ncompared the usefulness of the images obtained from\
    \ the specified satellites and those \nobtained from UAVs. The chosen experimental\
    \ site for the realization of four imaging \ncampaigns that were scheduled according\
    \ to the main phenological stages of the grape-\nvine was a farm located in Bova\
    \ Superiore, which is in the region of Calabria in Southern \nItaly. \nAs the\
    \ aim of this work is to test methodologies for Agriculture 4.0, the activities\
    \ \nconducted concerning data fusion methodologies on satellite images, UAV images,\
    \ and \nadditional sensors data as well as the use of a self-driving vehicle allow\
    \ for experimenta-\ntion in the area of Agriculture 4.0, leaving open broad research\
    \ topics that can be worked \non in the future. \nIn relation to the specific\
    \ situation of the rows of vines, it is noted that new results \ncan be obtained\
    \ by changing sensors and with new, higher-resolution multispectral satel-\nlite\
    \ images. \nPast results have already shown that data acquired from decametre-resolution\
    \ satel-\nlite systems (Sentinel-2) are insufficient to accurately assess vineyard\
    \ conditions and crop \nvariability. In fact, vineyard vigour may not agree with\
    \ that of the inter-row zones, deter-\nmining three distinct NDVI indices from\
    \ the high-resolution UAV images, considering: (i) \nthe entire cultivated area;\
    \ (ii) only the vine canopy; and (iii) only the soil pixels between \nthe rows.\
    \ Indeed, the NDVI calculated from UAV images of only the pixels representing\
    \ \nFigure 7. GIS (Geographic Information System): areas where the analysis of\
    \ historical and socio-\neconomic data makes a different kind of cultivation appropriate.\n\
    5. Conclusions\nOur article presents an introduction to a more in-depth analysis\
    \ by comparing mul-\ntispectral vineyard imagery obtained from satellite platforms\
    \ such as Sentinel-2, at a\nresolution of ten meters, and ultra-high-resolution\
    \ imagery acquired from WorldView\nsatellite and low-altitude UAV platforms. Using\
    \ NDVI as a measure of vineyard vitality,\nwe compared the usefulness of the images\
    \ obtained from the speciﬁed satellites and those\nobtained from UAVs. The chosen\
    \ experimental site for the realization of four imaging\ncampaigns that were scheduled\
    \ according to the main phenological stages of the grapevine\nwas a farm located\
    \ in Bova Superiore, which is in the region of Calabria in Southern Italy.\nAs\
    \ the aim of this work is to test methodologies for Agriculture 4.0, the activities\n\
    conducted concerning data fusion methodologies on satellite images, UAV images,\
    \ and\nadditional sensors data as well as the use of a self-driving vehicle allow\
    \ for experimentation\nin the area of Agriculture 4.0, leaving open broad research\
    \ topics that can be worked on in\nthe future.\nIn relation to the speciﬁc situation\
    \ of the rows of vines, it is noted that new re-\nsults can be obtained by changing\
    \ sensors and with new, higher-resolution multispectral\nsatellite images.\nPast\
    \ results have already shown that data acquired from decametre-resolution satellite\n\
    systems (Sentinel-2) are insufﬁcient to accurately assess vineyard conditions\
    \ and crop vari-\nability. In fact, vineyard vigour may not agree with that of\
    \ the inter-row zones, determining\nthree distinct NDVI indices from the high-resolution\
    \ UAV images, considering: (i) the\nentire cultivated area; (ii) only the vine\
    \ canopy; and (iii) only the soil pixels between the\nrows. Indeed, the NDVI calculated\
    \ from UAV images of only the pixels representing the\nvine canopy more accurately\
    \ described the vigour of the vineyard. The proposed strategy\ncan be applied\
    \ to other types of crops that are cultivated with signiﬁcant spaces between\n\
    the rows.\nThe GIS that was developed for the purpose of monitoring and managing\
    \ agricultural\nland with remote sensing using UAV images and VHR satellite imagery\
    \ classiﬁed with\nOBIA is very helpful for agricultural management and produces\
    \ alerts in the event that\ncrop stress occurs.\nThis research is still open.\
    \ Further experimentation will have to be carried out to\noptimise the system\
    \ by making it usable and extracting more data to obtain ﬁnal information\nto\
    \ be further tested in the ﬁeld or other areas to estimate the beneﬁts of the\
    \ method.\nSensors 2022, 22, 7910\n21 of 23\nAuthor Contributions: Conceptualization,\
    \ V.B. and G.B.; methodology, V.B. and G.B.; software, V.B.\nand R.C.; validation,\
    \ V.B., S.S. and G.B.; formal analysis, G.B.; investigation, V.B. and R.C.; resources,\n\
    V.B., R.C. and G.B.; data curation, S.S. and R.C.; writing—original draft preparation,\
    \ V.B. and G.B.;\nwriting—review and editing, A.F. and G.B.; visualization, S.S.\
    \ and R.C.; supervision, V.B. and G.B.;\nproject administration, V.B. and S.S.;\
    \ funding acquisition, S.S., A.F., R.C. and G.B. All authors have\nread and agreed\
    \ to the published version of the manuscript.\nFunding: This research received\
    \ no external funding.\nInstitutional Review Board Statement: Not applicable.\n\
    Informed Consent Statement: Not applicable\nData Availability Statement: Not applicable.\n\
    Conﬂicts of Interest: The authors declare no conﬂict of interest.\nReferences\n\
    1.\nArnó, J.; Martínez Casasnovas, J.A.; Ribes-Dasi, M.; Rosell, J.R. Review.\
    \ Precision viticulture. Research topics, challenges and\nopportunities in site-speciﬁc\
    \ vineyard management. Span. J. Agric. Res. 2009, 7, 779–790. [CrossRef]\n2.\n\
    Silvestroni, O.; Lanari, V.; Lattanzi, T. Canopy management strategies to control\
    \ yield and grape composition of Montepulciano\ngrapevines. Aust. J. Grape Wine\
    \ Res. 2018, 25, 30–42. [CrossRef]\n3.\nBramley, R.; Hamilton, R. Understanding\
    \ variability in winegrape production systems. Aust. J. Grape Wine Res. 2004,\
    \ 10, 32–45.\n[CrossRef]\n4.\nSong, J.; Smart, R.E.; Dambergs, R.G.; Sparrow,\
    \ A.M.; Wells, R.B.; Wang, H.; Qian, M.C. Pinot Noir wine composition from\ndifferent\
    \ vine vigour zones classiﬁed by remote imaging technology. Food Chem. 2014, 153,\
    \ 52–59. [CrossRef]\n5.\nKhaliq, A.; Comba, L.; Biglia, A.; Ricauda Aimonino,\
    \ D.; Chiaberge, M.; Gay, P. Comparison of Satellite and UAV-Based\nMultispectral\
    \ Imagery for Vineyard Variability Assessment. Remote Sens. 2019, 11, 436. [CrossRef]\n\
    6.\nPrimicerio, J.; Gay, P.; Ricauda Aimonino, D.; Comba, L.; Matese, A.; Di Gennaro,\
    \ S.F. NDVI-based vigour maps production using\nautomatic detection of vine rows\
    \ in ultra-high resolution aerial images. In Proceedings of the 10th European\
    \ Conference on\nPrecision Agriculture, Volcani Center, Israel, 12–16 July 2015;\
    \ pp. 465–470. [CrossRef]\n7.\nHall, A.; Lamb, D.; Holzapfel, B.; Louis, J. Optical\
    \ remote sensing applications in viticulture—A review. Aust. J. Grape Wine Res.\n\
    2002, 8, 36–47. [CrossRef]\n8.\nLanjeri, S.; Melia, J.; Segarra, D. A multi-temporal\
    \ masking classiﬁcation method for vineyard monitoring in central Spain.\nInt.\
    \ J. Remote Sens. 2001, 22, 3167–3186. [CrossRef]\n9.\nBramley, R.; Profﬁtt, A.P.B.\
    \ Managing variability in viticultural production. Grapegrow Winemak. 1999, 427,\
    \ 11–16.\n10.\nEnenkel, M.; Farah, C.; Hain, C.; White, A.; Anderson, M.; You,\
    \ L.; Wagner, W.; Osgood, D. What Rainfall Does Not Tell\nUs—Enhancing Financial\
    \ Instruments with Satellite-Derived Soil Moisture and Evaporative Stress. Remote\
    \ Sens. 2018, 10, 1819.\n[CrossRef]\n11.\nRomero, M.; Luo, Y.; Su, B.; Fuentes,\
    \ S. Vineyard water status estimation using multispectral imagery from an UAV\
    \ platform and\nmachine learning algorithms for irrigation scheduling management.\
    \ Comput. Electron. Agric. 2018, 147, 109–117. [CrossRef]\n12.\nComba, L.; Biglia,\
    \ A.; Aimonino, D.R.; Gay, P. Unsupervised detection of vineyards by 3D point-cloud\
    \ UAV photogrammetry for\nprecision agriculture. Comput. Electron. Agric. 2018,\
    \ 155, 84–95. [CrossRef]\n13.\nDobrowski, S.; Ustin, S.; Wolpert, J. Remote estimation\
    \ of vine canopy density in vertically shoot-positioned vineyards: Determin-\n\
    ing optimal vegetation indices. Aust. J. Grape Wine Res. 2002, 8, 117–125. [CrossRef]\n\
    14.\nSun, L.; Gao, F.; Anderson, M.C.; Kustas, W.P.; Alsina, M.M.; Sanchez, L.;\
    \ Sams, B.; McKee, L.; Dulaney, W.; White, W.A.; et al.\nDaily Mapping of 30 m\
    \ LAI and NDVI for Grape Yield Prediction in California Vineyards. Remote Sens.\
    \ 2017, 9, 317. [CrossRef]\n15.\nJohnson, L.F. Temporal stability of an NDVI-LAI\
    \ relationship in a Napa Valley vineyard. Aust. J. Grape Wine Res. 2003, 9, 96–101.\n\
    [CrossRef]\n16.\nSenthilnath, J.; Kandukuri, M.; Dokania, A.; Ramesh, K.N. Application\
    \ of UAV imaging platform for vegetation analysis based on\nspectral-spatial methods.\
    \ Comput. Electron. Agric. 2017, 140, 8–24. [CrossRef]\n17.\nPeña, J.M.; Torres-Sánchez,\
    \ J.; De Castro, A.I.; Kelly, M.; Lopez-Granados, F. Weed Mapping in Early-Season\
    \ Maize Fields Using\nObject-Based Analysis of Unmanned Aerial Vehicle (UAV) Images.\
    \ PLoS ONE 2013, 8, e77151. [CrossRef] [PubMed]\n18.\nComba, L.; Gay, P.; Primicerio,\
    \ J.; Aimonino, D.R. Vineyard detection from unmanned aerial systems images. Comput.\
    \ Electron. Agric.\n2015, 114, 78–87. [CrossRef]\n19.\nAlbetis, J.; Duthoit, S.;\
    \ Guttler, F.; Jacquin, A.; Goulard, M.; Poilvé, H.; Féret, J.-B.; Dedieu, G.\
    \ Detection of Flavescence dorée\nGrapevine Disease Using Unmanned Aerial Vehicle\
    \ (UAV) Multispectral Imagery. Remote Sens. 2017, 9, 308. [CrossRef]\n20.\nJohnson,\
    \ L.F.; Bosch, D.F.; Williams, D.C.; Lobitz, B.M. Remote Sensing of Vineyard Management\
    \ Zones: Implications for Wine\nQuality. Appl. Eng. Agric. 2001, 17, 557–560.\
    \ [CrossRef]\nSensors 2022, 22, 7910\n22 of 23\n21.\nRobinson, N.P.; Allred, B.W.;\
    \ Jones, M.O.; Moreno, A.; Kimball, J.S.; Naugle, D.E.; Erickson, T.A.; Richardson,\
    \ A.A. A Dynamic\nLandsat Derived Normalized Difference Vegetation Index (NDVI)\
    \ Product for the Conterminous United States. Remote Sens.\n2017, 9, 863. [CrossRef]\n\
    22.\nBarrile,\nV.;\nBilotta,\nG.\nAn\napplication\nof\nRemote\nSensing:\nObject\n\
    oriented\nanalysis\nof\nsatellite\ndata.\nInt. Arch. Photogramm. Remote. Sens.\
    \ Spat. Inf. Sci. 2008, 37, 107–114.\n23.\nBarrile, V.; Bilotta, G.; Fotia, A.;\
    \ Bernardo, E. Road Extraction for Emergencies from Satellite Imagery. In Computational\
    \ Science and\nIts Applications—ICCSA 2020; LNCS, 12252; Springer: Cham, Switzerland,\
    \ 2020; pp. 767–781. [CrossRef]\n24.\nBarrile, V.; Bilotta, G.; Fotia, A.; Bernardo,\
    \ E. Integrated Gis System for Post-Fire Hazard Assessments with Remote Sensing.\
    \ Int.\nArch. Photogramm. Remote Sens. Spat. Inf. Sci. 2020, XLIV-3/W1-2020, 13–20.\
    \ [CrossRef]\n25.\nAngiulli, G.; Barrile, V.; Cacciola, M. SAR Imagery Classification\
    \ Using Multi-Class Support Vector Machines. J. Electromagn. Waves Appl.\n2005,\
    \ 19, 1865–1872. [CrossRef]\n26.\nBarrile, V.; Bernardo, E.; Candela, G.; Bilotta,\
    \ G.; Modafferi, A.; Fotia, A. Road Infrastructure Heritage: From Scan to InfraBIM.\n\
    WSEAS Trans. Environ. Dev. 2020, 16, 633–642. [CrossRef]\n27.\nDeng, L.; Mao,\
    \ Z.; Li, X.; Hu, Z.; Duan, F.; Yan, Y. UAV-based multispectral remote sensing\
    \ for precision agriculture: A comparison\nbetween different cameras. ISPRS J.\
    \ Photogramm. Remote Sens. 2018, 146, 124–136. [CrossRef]\n28.\nReza, N.; Na,\
    \ I.S.; Baek, S.W.; Lee, K.-H. Rice yield estimation based on K-means clustering\
    \ with graph-cut segmentation using\nlow-altitude UAV images. Biosyst. Eng. 2018,\
    \ 177, 109–121. [CrossRef]\n29.\nJohnson, L.; Roczen, D.; Youkhana, S.; Nemani,\
    \ R.; Bosch, D. Mapping vineyard leaf area with multispectral satellite imagery.\n\
    Comput. Electron. Agric. 2003, 38, 33–44. [CrossRef]\n30.\nBorgogno-Mondino, E.;\
    \ Lessio, A.; Tarricone, L.; Novello, V.; de Palma, L. A comparison between multispectral\
    \ aerial and satellite\nimagery in precision viticulture. Precis. Agric. 2017,\
    \ 19, 195. [CrossRef]\n31.\nNavia, J.; Mondragon, I.; Patino, D.; Colorado, J.\
    \ Multispectral mapping in agriculture: Terrain mosaic using an autonomous\nquadcopter\
    \ UAV. In Proceedings of the 2016 International Conference on Unmanned Aircraft\
    \ Systems (ICUAS), Arlington, VA,\nUSA, 7–10 June 2016; pp. 1351–1358.\n32.\n\
    Hall, A.; Louis, J.; Lamb, D.W. A method for extracting detailed information from\
    \ high resolution multispectral images of vine-\nyards. In Proceedings of the\
    \ 6th International Conference on Geocomputation, Brisbane, QLD, Australia, 24–26\
    \ September 2001.\n33.\nSentinel-2A Handbook Overview. Available online: https://sentinel.esa.int/web/sentinel/user-guides/sentinel-2-msi/overview\n\
    (accessed on 24 September 2022).\n34.\nESA Sentinel Online. Available online:\
    \ https://sentinels.copernicus.eu/web/sentinel/home (accessed on 24 September\
    \ 2022).\n35.\nCopernicus Open Access Hub. Available online: https://scihub.copernicus.eu/dhus/#/home\
    \ (accessed on 10 March 2021).\n36.\nLouis, J.; Charantonis, A.; Berthelot, B.\
    \ Cloud Detection for Sentinel-2. In Proceedings of the ESA Living Planet Symposium,\n\
    Bergen, Norway, 27 June–2 July 2010.\n37.\nDucati, J.R.; Bombassaro, M.G.; Fachel,\
    \ J.M.G. Classifying vineyards from satellite images: A case study on Burgundy’s\
    \ Côte d’Or.\nOENO One 2014, 48, 247–260. [CrossRef]\n38.\nJiang, R.; Wang, P.;\
    \ Xu, Y.; Zhou, Z.; Luo, X.; Lan, Y.; Zhao, G.; Sanchez-Azofeifa, A.; Laakso,\
    \ K. Assessing the Operation\nParameters of a Low-altitude UAV for the Collection\
    \ of NDVI Values Over a Paddy Rice Field. Remote Sens. 2020, 12, 1850.\n[CrossRef]\n\
    39.\nBilotta, G.; Bernardo, E. UAV for Precision Agriculture in Vineyards: A Case\
    \ Study in Calabria. In Geomatics and Geospatial\nTechnologies. ASITA 2021. In\
    \ Communications in Computer and Information Science; Borgogno-Mondino, E., Zamperlin,\
    \ P., Eds.;\nSpringer: Cham, Switzerland, 2022; Volume 1507. [CrossRef]\n40.\n\
    Aygün, S.; Güne¸s, E.O.; Suba¸sı, M.A.; Alkan, S. Sensor Fusion for IoT-based\
    \ Intelligent Agriculture System. In Proceedings of\nthe 8th International Conference\
    \ on Agro-Geoinformatics (Agro-Geoinformatics), Istanbul, Turkey, 16–19 July 2019;\
    \ pp. 1–5.\n[CrossRef]\n41.\nBarbedo, J.G.A. Data Fusion in Agriculture: Resolving\
    \ Ambiguities and Closing Data Gaps. Sensors 2022, 22, 2285. [CrossRef]\n[PubMed]\n\
    42.\nCitroni, R.; Di Paolo, F.; Livreri, P. A Novel Energy Harvester for Powering\
    \ Small UAVs: Performance Analysis, Model Validation\nand Flight Results. Sensors\
    \ 2019, 19, 1771. [CrossRef] [PubMed]\n43.\nRen, H.; Zhao, Y.; Xiao, W.; Hu, Z.\
    \ A review of UAV monitoring in mining areas: Current status and future perspectives.\n\
    Int. J. Coal Sci. Technol. 2019, 6, 320–333. [CrossRef]\n44.\nFurukawa, F.; Laneng,\
    \ L.A.; Ando, H.; Yoshimura, N.; Kaneko, M.; Morimoto, J. Comparison of RGB and\
    \ Multispectral Unmanned\nAerial Vehicle for Monitoring Vegetation Coverage Changes\
    \ on a Landslide Area. Drones 2021, 5, 97. [CrossRef]\n45.\nBarrile, V.; Meduri,\
    \ G.M.; Critelli, M.; Bilotta, G. MMS and GIS for Self-driving Car and Road Management.\
    \ In Computational\nScience and Its Applications—ICCSA 2017; Lecture Notes in\
    \ Computer Science; Springer: Cham, Switzerland, 2017; Volume 10407.\n[CrossRef]\n\
    46.\nNoguchi, N.; Zhang, Q.; Han, S.; Reid, J.F. Autonomous Agricultural Tractor\
    \ with an Intelligent Navigation System. IFAC Proc. Vol.\n2001, 34, 197–202. [CrossRef]\n\
    47.\nLi, Y.; Cao, Q.; Liu, F. Design of control system for driverless tractor.\
    \ MATEC Web Conf. 2020, 309, 04001. [CrossRef]\nSensors 2022, 22, 7910\n23 of\
    \ 23\n48.\nSott, M.K.; Nascimento, L.D.S.; Foguesatto, C.R.; Furstenau, L.B.;\
    \ Faccin, K.; Zawislak, P.A.; Mellado, B.; Kong, J.D.; Bragazzi,\nN.L. A Bibliometric\
    \ Network Analysis of Recent Publications on Digital Agriculture to Depict Strategic\
    \ Themes and Evolution\nStructure. Sensors 2021, 21, 7889. [CrossRef]\n49.\nKragh,\
    \ M.F.; Christiansen, P.; Laursen, M.; Steen, K.A.; Green, O.; Karstoft, H.; Jørgensen,\
    \ R.N. FieldSAFE: Dataset for Obstacle\nDetection in Agriculture. Sensors 2017,\
    \ 17, 2579. [CrossRef]\n50.\nDatiMeteo. Available online: https://datimeteo.it\
    \ (accessed on 24 September 2022).\n51.\nDJI Drones©. Available online: https://www.dji.com/it/matrice600-pro\
    \ (accessed on 24 September 2022).\n52.\nMicaSense (Now Ageagle). Available online:\
    \ https://ageagle.com/store/Calibrated-Reﬂectance-Panel-2-p467113700 (accessed\n\
    on 24 September 2022).\n53.\nTonnang, H.; Balemi, T.; Masuki, K.; Mohammed, I.;\
    \ Adewopo, J.; Adnan, A.; Mudereri, B.; Vanlauwe, B.; Craufurd, P. Rapid\nAcquisition,\
    \ Management, and Analysis of Spatial Maize (Zea mays L.) Phenological Data—Towards\
    \ ‘Big Data’ for Agronomy\nTransformation in Africa. Agronomy 2020, 10, 1363.\
    \ [CrossRef]\n"
  inline_citation: (Barrile, Simonetti, Citroni, Fotia, & Bilotta, 2022)
  journal: Sensors
  limitations: The method is still experimental, and the system needs to be optimized
    for usability and additional data extraction for final information to be further
    tested in the field or other areas to estimate the benefits of the method.
  pdf_link: https://www.mdpi.com/1424-8220/22/20/7910/pdf?version=1666074846
  publication_year: 2022
  relevance_score: 0.7
  relevance_score1: 0
  relevance_score2: 0
  title: 'Experimenting Agriculture 4.0 with Sensors: A Data Fusion Approach between
    Remote Sensing, UAVs and Self-Driving Tractors'
  verbatim_quote1: The proposed strategy can be applied to other types of crops that
    are cultivated with signiﬁcant spaces between the rows.
  verbatim_quote2: Of the data sources and types, are critical for addressing the
    challenges of data quality, data gaps, and data heterogeneity which are inherent
    in agriculture 4.0.
  verbatim_quote3: '>'
- DOI: https://doi.org/10.3390/s22176436
  analysis: 'This paper presents the design and implementation of SEMAR, an IoT server
    platform enabling the integration of IoT applications for real-time environmental
    monitoring. It offers flexibility, scalability, and interoperability by seamlessly
    accommodating data from diverse sensors, processing it efficiently, and facilitating
    integration with external systems. The thorough comparison with existing state-of-the-art
    solutions demonstrates its superiority in handling multiple IoT applications,
    device management, data synchronization, filtering, decision-making support, and
    integration capabilities.


    Relevance score: 0.9'
  authors:
  - Yohanes Yohanie Fridelin Panduman
  - Nobuo Funabiki
  - Pradini Puspitaningayu
  - Minoru Kuribayashi
  - Sritrusta Sukaridhoto
  - Wen-Chung Kao
  citation_count: 14
  full_citation: Panduman, Y.Y.F.; Funabiki, N.; Puspitaningayu, P.; Kuribayashi,
    M.; Sukaridhoto, S.; Kao, W.-C. Design and Implementation of SEMAR IoT Server
    Platform with Applications. Sensors 2022, 22, 6436. https://doi.org/10.3390/s22176436
  full_text: ">\nCitation: Panduman, Y.Y.F.;\nFunabiki, N.; Puspitaningayu, P.;\n\
    Kuribayashi, M.; Sukaridhoto, S.;\nKao, W.-C. Design and\nImplementation of SEMAR\
    \ IoT\nServer Platform with Applications.\nSensors 2022, 22, 6436. https://\n\
    doi.org/10.3390/s22176436\nAcademic Editors: Gianluigi Ferrari,\nLuca Davoli,\
    \ Laura Belli and Marco\nMartalò\nReceived: 9 July 2022\nAccepted: 23 August 2022\n\
    Published: 26 August 2022\nPublisher’s Note: MDPI stays neutral\nwith regard to\
    \ jurisdictional claims in\npublished maps and institutional afﬁl-\niations.\n\
    Copyright:\n© 2022 by the authors.\nLicensee MDPI, Basel, Switzerland.\nThis article\
    \ is an open access article\ndistributed\nunder\nthe\nterms\nand\nconditions of\
    \ the Creative Commons\nAttribution (CC BY) license (https://\ncreativecommons.org/licenses/by/\n\
    4.0/).\nsensors\nArticle\nDesign and Implementation of SEMAR IoT Server Platform\n\
    with Applications\nYohanes Yohanie Fridelin Panduman 1, Nobuo Funabiki 1,*, Pradini\
    \ Puspitaningayu 1, Minoru Kuribayashi 1,\nSritrusta Sukaridhoto 2 and Wen-Chung\
    \ Kao 3\n1\nGraduate School of Natural Science and Technology, Okayama University,\
    \ Okayama 700-8530, Japan\n2\nDepartment of Informatic and Computer, Politeknik\
    \ Elektronika Negeri Surabaya, Surabaya 60111, Indonesia\n3\nDepartment of Electrical\
    \ Engineering, National Taiwan Normal University, Taipei 106, Taiwan\n*\nCorrespondence:\
    \ funabiki@okayama-u.ac.jp\nAbstract: Nowadays, rapid developments of Internet\
    \ of Things (IoT) technologies have increased\npossibilities of realizing smart\
    \ cities where collaborations and integrations of various IoT application\nsystems\
    \ are essential. However, IoT application systems have often been designed and\
    \ deployed\nindependently without considering the standards of devices, logics,\
    \ and data communications.\nIn this paper, we present the design and implementation\
    \ of the IoT server platform called Smart\nEnvironmental Monitoring and Analytical\
    \ in Real-Time (SEMAR) for integrating IoT application systems\nusing standards.\
    \ SEMAR offers Big Data environments with built-in functions for data aggregations,\n\
    synchronizations, and classiﬁcations with machine learning. Moreover, plug-in\
    \ functions can be easily\nimplemented. Data from devices for different sensors\
    \ can be accepted directly and through network\nconnections, which will be used\
    \ in real-time for user interfaces, text ﬁles, and access to other systems\nthrough\
    \ Representational State Transfer Application Programming Interface (REST API)\
    \ services. For\nevaluations of SEMAR, we implemented the platform and integrated\
    \ ﬁve IoT application systems,\nnamely, the air-conditioning guidance system,\
    \ the ﬁngerprint-based indoor localization system, the water\nquality monitoring\
    \ system, the environment monitoring system, and the air quality monitoring system.\n\
    When compared with existing research on IoT platforms, the proposed SEMAR IoT\
    \ application server\nplatform offers higher ﬂexibility and interoperability with\
    \ the functions for IoT device managements,\ndata communications, decision making,\
    \ synchronizations, and ﬁlters that can be easily integrated\nwith external programs\
    \ or IoT applications without changing the codes. The results conﬁrm the\neffectiveness\
    \ and efﬁciency of the proposal.\nKeywords: Internet of Things; server platform;\
    \ SEMAR; IoT application system; sensor; MQTT;\nREST API\n1. Introduction\nThe\
    \ rapid growth of urban populations has increased the risk toward quality of life\n\
    (QoL) around the world [1]. Smart cities have been studied for identifying, preventing,\
    \ and\nacting in certain situations. In smart cities, QoL is commonly handled\
    \ with indicators that\nmeasure the effectiveness of the services and sustainability\
    \ of a city in domains/verticals,\nsuch as environments, health cares, securities,\
    \ transportation, economies, educations, and\ngovernments [2]. Particularly, the\
    \ environment vertical has drawn special attention in\nrecent years. Indicators\
    \ of environmental pollutants, such as air and water quality, road\nconditions,\
    \ and house conditions, must be monitored to detect adverse situations associated\n\
    with overpopulated regions. In this sense, Internet of Things (IoT) applications\
    \ must provide\ninteroperability tools that collect, store, and disseminate data\
    \ from several sensors, and\nprovide them to other systems [3,4]. Thus, smart\
    \ cities require collaboration and integration\nof various IoT application systems.\
    \ Studies of IoT server platforms have emerged for\nsuch purposes, where several\
    \ challenges hinder better management and analysis of IoT\napplication data using\
    \ platforms.\nSensors 2022, 22, 6436. https://doi.org/10.3390/s22176436\nhttps://www.mdpi.com/journal/sensors\n\
    Sensors 2022, 22, 6436\n2 of 28\nThe ﬁrst challenge involves the lack of a common\
    \ data format between data sensors\nand data communication protocols. For instance,\
    \ to measure the air and water quality,\ndifferent sensors with different geo-location\
    \ concepts such as addresses, buildings, re-\ngions, or cities can be handled\
    \ in different ways. Thus, an IoT server platform should be\nable to handle various\
    \ data types from different sensors, which makes it necessary to be\nable to work\
    \ with each other despite the diversity in communication protocols or sensor\n\
    technologies.\nThe second challenge is the standard parameters for data processing.\
    \ As an example,\nthe majority of air quality monitoring systems use Air Pollution\
    \ Index (API) to deﬁne the\nindicators of the carbon monoxide (CO), the nitrogen\
    \ dioxide (NO2), the sulfur dioxide\n(SO2), the ozone (O3), and the particulate\
    \ matter (PM10) [5]. However, other researchers\nmentioned that it might be necessary\
    \ to consider other indicators such as the temperature\nand the humidity for their\
    \ measurements [6].\nThe third challenge concerns the data interoperability between\
    \ various IoT application\nsystems within the same domain. It can be described\
    \ as the integration of plural systems\nby sharing output data through information\
    \ networks [3]. For example, a smart building\nsystem should integrate the human\
    \ Indoor Positioning System (IPS) with the environment\nmonitoring system to improve\
    \ QoL while reducing energy usage.\nHowever, in general, IoT application systems\
    \ for smart cities have been designed\nwithout considering these challenges. They\
    \ have been deployed independently and cannot\nbe integrated with other systems.\n\
    In this paper, we propose an IoT server platform called Smart Environmental Monitoring\n\
    and Analytical in Real-Time (SEMAR) for integrating various IoT application systems.\
    \ SE-\nMAR is able to offer Big Data environments with rich built-in functions\
    \ for data aggregations,\nsynchronizations, and classiﬁcations with machine learning.\
    \ Moreover, plug-in functions can\nbe easily implemented and added there. Data\
    \ from devices for different sensors can be\naccepted directly and through network\
    \ connections, which will be used in real-time for\nuser interfaces, text ﬁles,\
    \ and access to other systems through Representational State Transfer\nApplication\
    \ Programming Interface (REST API) services.\nFor evaluations of SEMAR, we implemented\
    \ the platform and integrated ﬁve IoT\napplications, namely, the air-conditioning\
    \ guidance system, the ﬁngerprint-based indoor local-\nization system, the water\
    \ quality monitoring system, the environment monitoring system, and\nthe air quality\
    \ monitoring system. The results conﬁrm the effectiveness and efﬁciency of the\n\
    proposal, including the reduction in the data transmission delay with the implemented\n\
    Message Queue Telemetry Transport (MQTT) service [7].\nThe rest of this paper\
    \ is organized as follows: Section 2 presents related works.\nSection 3 presents\
    \ the design of SEMAR. Section 4 presents the implementation of SE-\nMAR. Sections\
    \ 5–9 brieﬂy describe the IoT application systems implemented in the SEMAR.\n\
    Section 10 describes comprehensive performance evaluations and comparative analysis\n\
    with similar related work. Section 11 presents the threats to validity. Finally,\
    \ Section 12\nconcludes this paper with future works.\n2. Related Works\nIn [8],\
    \ Kamienski et al. proposed a three-layered Open IoT ecosystem approach for\n\
    smart application architectures. It includes input, process, and output in IoT\
    \ application\nsystems. The input gathers information from multiple sources, such\
    \ as sensors and other\nservices. The standard communication protocols cover the\
    \ device connections. The process\nis given by a collection of methodologies,\
    \ procedures, and algorithms for effective and\nefﬁcient data processing. The\
    \ output provides capabilities for data visualizations and\naccessibility.\nIn\
    \ [9], Bansal et al. proposed ﬁve layers for the IoT application system architecture,\n\
    consisting of perception, transport, processing, middleware, and application.\
    \ They divided\ndata processing into two layers, where the processing layer concentrates\
    \ on ﬁltering and\nSensors 2022, 22, 6436\n3 of 28\nformatting the data, and the\
    \ middleware layer intends to execute various logical and\nanalytic operations.\n\
    The connectivity in IoT systems was discussed in [10], where Li et al. examined\
    \ the\nnetworking technologies, and described that IEEE 802.11 (WLAN), IEEE 802.15.1\
    \ (Bluetooth,\nLow-energy Bluetooth), IEEE 802.15.6 (wireless body area networks),\
    \ and 3G/4G were the\nmost widely adopted in IoT application systems and smart\
    \ city environment systems.\nSince IoT systems might consist of various physical\
    \ things and sensors, it is essential\nto provide a device-to-device communication\
    \ protocol. Malche et al. in [11] proposed\nthe MQTT communication protocol for\
    \ environmental monitoring systems with multiple\ndevice sensors. Sharma et al.\
    \ in [12] deﬁned the Representational State Transfer (REST) web\nservice as the\
    \ gateway to collect device data through the HTTP POST protocol. Zhang et al.\n\
    in [13] studied NATS open source messaging to communicate between IoT devices\
    \ [14].\nThe numerous options of communication protocols were surveyed by Dizdarevic\
    \ et al.\nin [15]. They concluded that MQTT and HTTP POST are the most suitable\
    \ for IoT applica-\ntion systems since they are well matured and stable.\nIn [16],\
    \ Marques et al. proposed the IoT system architecture for the indoor air quality\n\
    (IAQ) system in a laboratory environment named iAQ Plus (iAQ+). It collects data\
    \ from\ndevices through Wi-Fi connections and stores data in the SQL server. The\
    \ authors proposed\na web portal and mobile application to manage and visualize\
    \ the obtained data; however,\nthe system does not offer data analysis functions\
    \ to process sensor data.\nIn [17], Benammar et al. proposed the IAQ system that\
    \ is integrated with the Emoncms\nIoT platform for storing and visualizing air\
    \ quality data, temperature, and humidity. The\nauthors used a Waspmote microcontroller\
    \ connected to Raspberry PI as sensor nodes and\nthe MQTT service to send data.\n\
    In [18], Mandava et al. proposed to integrate machine learning algorithms and\
    \ the\nIoT platform infrastructure for monitoring air pollution in smart cities.\
    \ The system collects\nenvironmental and location data to determine air pollution\
    \ conditions in speciﬁc areas, and\nuses the collected data to build a data model\
    \ for air pollution detections using supervised\nmachine learning algorithms.\
    \ The experiment results conﬁrmed the effectiveness of the\nproposed data model\
    \ for air pollution detections.\nIn [19], Senožetnik et al. proposed a management\
    \ framework for groundwater data in\nsmart cities. The system uses a web-based\
    \ IoT service to receive data through HTTP POST,\nconvert it into the JavaScript\
    \ Object Notation (JSON) format, and store it in the MongoDB\nNoSQL database.\
    \ It also allows sharing collected data through REST API. This system is\nsimilar\
    \ to our proposed one; however, the system only provided data communications\n\
    through HTTP POST. Moreover, it did not implement data processing functions to\
    \ analyze\nthe obtained data.\nIn [20], Kazmi et al. proposed a platform that\
    \ provides interoperability of diverse IoT\napplications in smart cities named\
    \ VITAL-OS. It can be integrated with other IoT application\nsystems through REST\
    \ API.\nIn [21], Toma et al. proposed an IoT platform for monitoring air pollution\
    \ in smart\ncities. The system contains wireless and wired connections with sensors\
    \ to send data\nthrough MQTT communications to the server using cellular networks.\
    \ It allows sharing\ndata through REST API; however, this platform was built and\
    \ implemented only for this\nIoT application of monitoring air pollution.\nIn\
    \ [22], Javed et al. proposed an IoT platform for smart buildings. It consists\
    \ of the\ndiscovery, storage, and service planes. The discovery plane performs\
    \ connectivity control\nwith devices through HTTP communications. The storage\
    \ plane manages data storage\nusing Apache Cassandra [23]. The service plane provides\
    \ data processing composed of data\nindexing, visualizing, and analysis.\nIn [24],\
    \ Badii et al. proposed an open source IoT framework architecture for smart cities\n\
    called Snap4City. The system offers modules for device managements, data processing,\n\
    data analysis, and data visualizations.\nSensors 2022, 22, 6436\n4 of 28\nIn [25],\
    \ Putra et al. proposed an implementation of wireless sensor networks in smart\n\
    cities to monitor air pollution. A device will transmit data regarding the air\
    \ pollution to a\nserver through a Wi-Fi network.\nIn [26], Gautam et al. proposed\
    \ an IoT application for the water supply management\nsystem in smart cities.\
    \ The proposed architecture uses General Purpose Input Output (GPIO)\ncommunications\
    \ for connecting ultrasonic sensors and water pumps with Raspberry PI.\nMoreover,\
    \ it uses Ethernet cables as network interfaces to Raspberry PI and the router.\
    \ It\noffers data analysis services and real-time predictions using machine learning\
    \ algorithms\nfor processing data; however, this framework is only built for this\
    \ single IoT application.\nIn [27], Oliveira et al. proposed an IoT application\
    \ for road environment monitoring\nusing mobile-based sensors. The system receives\
    \ sensor data through HTTP POST commu-\nnications in the JSON format, and allows\
    \ processing and visualizing it. It also provides a\nfunction to export data in\
    \ CSV ﬁles.\nIn [28], Metia et al. proposed a digital ﬁlter for the IoT-based\
    \ air pollution monitoring\nsystem. The experiment results in this study show\
    \ that the data processing using Kalman\nﬁlter has enhanced the reliability and\
    \ accuracy of the system; however, they did not\nimplement the real-time data\
    \ processing.\nIn [29], Twahirwa et al. proposed the system for monitoring roads,\
    \ weathers, and\nenvironments by attaching multiple sensors to a vehicle and sending\
    \ sensor data to the\nIoT server. The IoT server can process, store, and visualize\
    \ data with the web application\nsystem.\nIn [30], D’Ortona et al. showed the\
    \ beneﬁts of implementing MQTT communications in\nIoT application systems for\
    \ smart cities. The MQTT communications allow the construction\nof highly scalable\
    \ and ﬂexible IoT systems.\nIn [31], Kumar et al. proposed an anomaly-based intrusion\
    \ detection system (IDS) to secure\nIoT networks from threats such as spying and\
    \ malicious controls. It was implemented at\nthe fog node level. The proposed\
    \ approach might be adopted as an additional system that\ncan avoid threats before\
    \ the IoT platform receives them. Moreover, in [32,33], a method was\nproposed\
    \ to protect IoT networks by data pre-processing functions. It comprises feature\n\
    mapping, missing value inputting, normalization, and feature selection techniques.\
    \ The\nproposed method is similar to our approach in the data aggregation function.\
    \ SEMAR only\nprocesses and stores sensor data registered in the sensor format\
    \ data storage.\nIn [34], Kumar et al. designed PEFL for secure open communication\
    \ channels in\nIoT application systems. The proposed method utilized Long Short-Term\
    \ Memory (LSTM)\nand privacy encoding techniques in order to reduce security risk\
    \ and maintain privacy.\nMoreover, in [35], authors proposed an framework for\
    \ preventing cyber attacks on IoT-fog\ncomputing. It offered virtualized northbound\
    \ interfaces such as load balancer and resource\nmanagement to manage networks\
    \ in IoT systems. The proposed architecture can be utilized\nto enhance network\
    \ performances for the SEMAR IoT application server platform in future\nworks.\n\
    3. Design of SEMAR IoT Server Platform\nIn this section, we present the design\
    \ of the SEMAR IoT server platform for integrating\nvarious IoT application systems.\n\
    3.1. System Overview\nFigure 1 shows the proposed design of the SEMAR IoT server\
    \ platform. The main\ncomponents are data input, data process, and data output.\
    \ The data input is responsible\nfor accepting data from various sources. It consists\
    \ of network interface devices and\ncommunication protocols. The data process\
    \ provides the modules for data processing,\ncontrol, and collection. The data\
    \ output enables visualizations and sharing of collected\ndata. In Table 1 we\
    \ summarize the nomenclature of all the symbols and variables used in\nthis paper.\n\
    Sensors 2022, 22, 6436\n5 of 28\nFigure 1. Design overview of SEMAR IoT server\
    \ platform.\nTable 1. Nomenclature used in the paper.\nParameters\nDescription\n\
    Decision Tree algorithm:\nt\nthe node of decision tree\nn\nnumber of targets classes\n\
    P(i|t)\nthe probability of the speciﬁc data class i in node t\nSupport Vector\
    \ Machine algorithm:\nyi\nthe class label of dataset\nαi\nthe learned weight\n\
    xi\nthe support vector\nx\nthe labeled training sample data.\nK()\nthe kernel\
    \ function\nRadial Basis Function kernel:\nl\nthe length scale of the kernel RBF\n\
    d(xi, xj)\nthe Euclidean distance between xi and xj\n3.2. Data Input\nSEMAR needs\
    \ to collect data from a number of different devices using various network\nconnectivity\
    \ and communication methods; therefore, the following network interfaces\nfor\
    \ constructing physical network connections are implemented in the platform, where\n\
    standard IoT communication protocols for data transmission, namely HTTP and MQTT,\n\
    are included. In the context of IoT, physical devices as a perception layer consist\
    \ of a\nnumber of sensors connected to a controller. With the growth of IoT technology,\
    \ controllers\nsuch as Arduino and Raspberry PI have provided diverse network\
    \ connectivity to accept\ndata from various sensors. General Purpose Input Output\
    \ (GPIO) is the programmable\ninterface in the device controller to receive or\
    \ send command signals from/to IoT sensor\ndevices [36]. In IoT application systems,\
    \ GPIO is the standard interface for connecting\nsensor devices with the controller.\
    \ In addition, it is used for connecting controllers with\nexternal modules such\
    \ as Wi-Fi ones for data communications. Universal Serial Bus (USB) is\nthe serial\
    \ communication media to link devices with computers via USB ports. Currently,\n\
    Sensors 2022, 22, 6436\n6 of 28\nnumerous sensor instruments and devices can transmit\
    \ data using USB connections. The\nUSB connection offers a high data transfer\
    \ capacity. In addition, external communication\nmodules such as Wi-Fi for data\
    \ communication can also be added using USB connection.\nRegarding the IoT data\
    \ transmission concept, diverse hardware and software con-\nnectivity should be\
    \ considered. Diverse network interfaces utilize hardware-based trans-\nmissions,\
    \ such as Wi-Fi, Ethernet, and Cellular—this enables machine-to-machine and\n\
    device-to-server communication.\nIEEE 802.11 wireless LAN (Wi-Fi) is the most\
    \ prevalent network interface in IoT systems.\nIt connects devices with each other\
    \ and to servers. Wi-Fi is useful to connect a lot of devices\nregardless of their\
    \ locations with computers, which improves IoT application developments.\nEthernet\
    \ offers secure and dependable wired connectivity. It is one of the most used\
    \ network\ninterfaces in IoT systems; however, the implementation can be difﬁcult\
    \ over long distances.\nAlthough Wi-Fi and Ethernet offer excellent network performance,\
    \ we should consider\ntheir security and coverage area. The alternative network\
    \ interface that can be utilized is\ncellular networks. Cellular is the network\
    \ interface allowing the mobility of devices with\nthe existing widespread availability\
    \ of cells to connect with the internet. Currently, 5G\ncellular connections offer\
    \ solutions with wider bandwidths than Wi-Fi or Ethernet. The IoT\nplatform can\
    \ use it through Wi-Fi interfaces with mobile routers.\nThe last part of Data\
    \ Input is the communication protocol between IoT devices and\nservers. An IoT\
    \ server should support publish–subscribe and push-and-pull messaging\nsystems\
    \ for sending and receiving data. Thus, our proposed system utilizes MQTT and\n\
    REST API for the communication protocol service.\nMQTT is one of the protocols\
    \ that have been designed for data communications in IoT\napplication systems.\n\
    It can work with minimal memory and the processing\npower [37]. The MQTT broker\
    \ works for receiving messages from clients, ﬁltering the\nmessages according\
    \ to a topic, and distributing the messages to subscribers [38]. The\nMQTT broker\
    \ is implemented in the IoT gateway function of the platform to provide data\n\
    communication services in SEMAR. The IoT gateway function offers communication\
    \ ser-\nvices to connect sensor devices to the server. Using this protocol, sensor\
    \ devices can\ntransmit messages containing sensor data in the JSON format with\
    \ MQTT topics. By\nsubscribing data at the same MQTT topic, the data aggregation\
    \ program in the platform\nobtains each sensor data. In addition, the study by\
    \ Al-Joboury in [39] shows that the load\nbalancer can increase the performance\
    \ and the capacity of MQTT data communications.\nThe IoT gateway function also\
    \ implemented the REST API for receiving sensor data\nthrough the HTTP POST communication\
    \ protocol. It can only receive data in the JSON for-\nmat. The REST API provides\
    \ URLs for sensor data transmission. The management function\nin the platform\
    \ creates the unique URL for each device. The HTTP POST communication\nprotocol\
    \ is compatible with standard network interfaces. Using REST API, sensor devices\n\
    can transmit data in the JSON format.\n3.3. Data Process\nThe data process in\
    \ the SEMAR server platform offers various functions. The large\namount of data\
    \ from data input will be processed to obtain meaningful information using\nsome\
    \ functions. The functions are implemented as independent modules to reduce system\n\
    crashes at system failures. They can be extended to microservices [40,41]. The\
    \ concept of\nmicroservices is the method of developing a large-scale system with\
    \ a set of small indepen-\ndent services. For their implementations, thread-based\
    \ programs are adopted to improve\ntheir performances for real-time data processing.\
    \ Each service will initiate a new thread to\nprocess the newly coming data.\n\
    3.3.1. Data Management (Storage, Aggregator, and Plug-in Functions)\nThe data\
    \ management system is the main function of the IoT platform. In the context\n\
    of IoT, systems must provide data storage, transaction management, query processing,\
    \ and\ndata access for application systems. Thus, the IoT platform must offer\
    \ services to process\nSensors 2022, 22, 6436\n7 of 28\nthe data ﬂow from input\
    \ to output. Moreover, towards developing diverse IoT applications,\ndevices involved\
    \ in IoT should be able to generate different kinds of data types according\n\
    to the application.\nIn order to provide various IoT application systems, SEMAR\
    \ should be a useful\nplatform for a variety of IoT application systems. Thus,\
    \ it needs to support massive\namounts of data in different formats. Moreover,\
    \ it needs to store all the necessary data by\noffering data storage for every\
    \ application. The management data storage is the database that\nstores the operating\
    \ parameters in the SEMAR server platform including the implemented\nIoT application\
    \ systems. The data include the information regarding connected devices,\ncommunications,\
    \ and parameters for the process modules running on the platform. On\nthis platform,\
    \ each device has its own unique sensor format. The management data storage\n\
    database keeps the sensor format as the template to help the development of an\
    \ IoT\napplication system on this platform.\nMeanwhile, the sensor data storage\
    \ is the database that stores all the sensor data in\nthe platform. In IoT application\
    \ systems, sensor devices may offer various data and it\nmay change it over time\
    \ with unstructured formats; therefore, the platform uses the big\ndata technology\
    \ to store unstructured JSON objects generates the unique data storage for\neach\
    \ device. This data storage utilized only accepts registered device data; therefore,\
    \ we\nimplement additional data stored in the form of Log ﬁles. Log Files are\
    \ used to keep the\nvalues of any deﬁned or undeﬁned data using the CSV format.\
    \ The deﬁned data represents\na sensor data that ﬁts the format registered in\
    \ the management data storage. The undeﬁned\ndata represents data whose format\
    \ is not registered.\nThe schema data storage is the database that can be used\
    \ to help the users of IoT\napplication systems by dynamically specify the names,\
    \ ﬁelds, and data types in accessing\nthis storage. It supports multiple data\
    \ types, including integer, ﬂoat, date, time, date-time,\nand string.\nFigure\
    \ 1 illustrates that this database is used to store data synchronization results.\n\
    Through REST API, other systems can access to the sensor data storage. As the\
    \ advantage\nof this database, it can be dynamically deﬁned and modiﬁed by the\
    \ user. It can assist\nintegration of various complex IoT application systems.\n\
    In an IoT system, the data lifecycle begins with the communication gateway re-\n\
    ceiving sensor data, continues with data aggregation and preprocessing, and concludes\n\
    with data storage. For this purpose, SEMAR provides a data aggregator function.\
    \ The\ndata aggregator is the module of collecting data from various data sources,\
    \ applying\nthe value-added processing, and repackaging the information in a consumable\
    \ format.\nAlgorithm 1 illustrates the data processing procedure in this module.\
    \ It forwards the result\nto the following data ﬁlter or stores it in the data\
    \ storage through the database access.\nThe data management system plays a role\
    \ in the sensor data storage process and\nprovides access to additional data processing\
    \ functions. Those services are not only for\nsystems integrated in the IoT platform\
    \ (built-in) but also for plug-in functions that may be\ndeployed as an extension.\
    \ Because an IoT application system may require unique data\nprocessing that has\
    \ not been implemented in the platform. Thus, the platform is designed\nand implemented\
    \ so that users can easily implement plug-in functions without modifying\nexisting\
    \ codes, to fulﬁll the demands of IoT application systems. The plug-in functions\
    \ can\nuse REST API to access the data in the platform.\nSensors 2022, 22, 6436\n\
    8 of 28\nAlgorithm 1 Data aggregator\nInput\n:Raw sensor data received through\
    \ a communication protocol (RSensor)\nDevice code (Dcode)\nOutput:Sensor data\
    \ in a consumable format (MSensor)\nbegin\nSave RSensor in a log ﬁle\nConvert\
    \ RSensor to JSON object\nFind the sensor format from the database using Dcode\
    \ as S f ormat\nif S f ormat not empty then\nInitialize MSensor ← empty JSON object\n\
    for each item in S f ormat do\nif item in RSensor then\nSet MSensor[item] ← RSensor[item]\n\
    end\nend\nSet MSensor[”time”] ← currenttimestamp\nreturn MSensor\nend\nend\n3.3.2.\
    \ Data Filter and Synchronization\nIn this research, we additionally explore the\
    \ data processing capabilities required\nby IoT applications that are not included\
    \ in the standard data management services. For\nexample, sensors of IoT devices\
    \ may generate measurement errors and noise during the\nmeasuring process. It\
    \ can impact the risk of data analysis problems. In addition, IoT\napplications\
    \ such as indoor localization systems require real-time sensor data from several\n\
    devices simultaneously; therefore, our platform deploys the data ﬁlter and synchronization\n\
    functionalities for processing sensor data.\nThe functions of ﬁltering sensor\
    \ data before being saved in a data storage are imple-\nmented. Digital ﬁlters\
    \ are adopted to reduce noise and inaccuracies in data. The following\nprocedure\
    \ is applied for ﬁltering data:\n•\nIt receives sensor data in a JSON format.\n\
    •\nIt selects the sensor ﬁeld’s value to be ﬁltered.\n•\nIt add the ﬁeld value\
    \ in the JSON object with the ﬁlter result.\n•\nIt stores the JSON object in the\
    \ database.\nThe data synchronization function can synchronize the data from different\
    \ devices\nby referring to the timestamp in the data store schema. The timestamp\
    \ was given when the\nplatform receives the data from the sensor device. Thus,\
    \ the platform requests the data\nfrom each sensor’s storage at a speciﬁed detection\
    \ time. For each sensor data, the ﬁeld for\nthe identiﬁer (Fi) to group sample\
    \ data in a speciﬁc value, the ﬁeld for the value (Fv) to be\nsynchronized, the\
    \ default value (de f ault), and the four functions to process the data are\n\
    prepared. The following functions are implemented to process the data:\n•\nAverage:\
    \ it returns the average value of the data collected during the detection time.\n\
    •\nCurrent: it returns the last value among the data collected during the detection\
    \ time.\n•\nMax: it returns the highest value among the data collected during\
    \ the detection time.\n•\nMin: it returns the lowest value among the data collected\
    \ during the detection time.\nAlgorithm 2 illustrates the data processing procedure\
    \ in this module.\nSensors 2022, 22, 6436\n9 of 28\nAlgorithm 2 Data Synchronization\n\
    Input\n: Detection time (Dtime), List of sensor data will be synchronized (LSensor)\n\
    Output:List of synchronized data (SyncData)\nbegin\nSet TimeStart ← currenttime\n\
    Set TimeEnd ← TimeStart + Dtime\nwhile True do\nif TimeEnd = currenttime then\n\
    Set DataSource, Identi f ierList, SyncData ← empty vector\nfor each sensor ∈ LSensor\
    \ do\nSet DSensor ← captured sensor data between TimeStart and TimeEnd\nSet GroupData\
    \ as empty vector\nfor each row in DSensor do\nif row[Fi] not in Identi f ierList\
    \ then\nAppend row[Fi] to Identi f ierList\nend\nAppend row[Fv] to GroupData[row[Fi]]\n\
    end\nfor each i ∈ GroupData do\nSet DataSource[sensor][i] ← processed GroupData[i]\
    \ use the selected\nfunction\nend\nend\nfor each ID ∈ Identi f ierList do\nSet\
    \ SyncItem ← empty vector\nAppend ID to SyncItem[”identi f ier”]\nfor each sensor\
    \ ∈ LSensor do\nif DataSource[sensor][ID] is not empty then\nAppend DataSource[sensor][ID]\
    \ to SyncItem\nend\nAppend sensor[de f ault] to SyncItem\nend\nAppend SyncItem\
    \ to SyncData\nend\nStores SyncData to the schema data storage\nSet TimeStart\
    \ ← currenttime\nSet TimeEnd ← Tstart + Dtime\nend\nend\nend\n3.3.3. Machine Learning\
    \ and Real-time Classiﬁcation\nOne of the exploitation scenarios for the massive\
    \ quantity of IoT data is its predictive\ncapability by utilizing machine learning\
    \ approaches. Several researchers approved the\neffectiveness of machine learning\
    \ implementation in IoT applications [42–44]. Moreover,\nKumar et al. in [45]\
    \ proposed the ensemble design combining machine learning algorithms\nto protect\
    \ networks on the Internet of Medical Things in real-time; therefore, we implement\n\
    machine learning and real-time classiﬁcation function in SEMAR.\nThe machine learning\
    \ algorithms are implemented to help data classiﬁcations. The\nSupport Vector\
    \ Machine [46,47] and Decision Tree [48–50] are implemented in this platform as\n\
    standard machine learning algorithms in IoT application systems.\nDecision Tree\
    \ employs tree decisions including event outcomes, resource costs, and\nutility\
    \ costs. It can create a data model for predicting outcomes by learning simple\
    \ decision\nrules according to the data features. The data model structure consists\
    \ of internal nodes\nrepresenting an attribute, branches representing a decision\
    \ rule, and leaf nodes indicating\nan outcome. Here, C4.5, CART (Classiﬁcation\
    \ and Regression Trees), and Naive Bayes Tree\nSensors 2022, 22, 6436\n10 of 28\n\
    are selected and incorporated into the platform as the most well-known machine\
    \ learning\nalgorithms [48]. CART is the binary recursive partitioning method\
    \ that can handle both\nnumerical and category data [48–50]. It can determine\
    \ the impurity degree of acceptable\ndata and build a binary tree in which each\
    \ internal node provides two classes for the\naccepted attribute. The tree is\
    \ formed by iteratively picking the attribute with the lowest\nGini index. The\
    \ Gini index for each node is calculated by the following equation [48]:\nGini(t)\
    \ = 1 −\nn\n∑\ni=1\nP(i|t)2\n(1)\nSupport Vector Machine (SVM) is utilized as\
    \ the regression and classiﬁcation\ntechnique [51]. This approach has been used\
    \ for the big data classiﬁcation [47]. The\nSVM computes linear decision boundary\
    \ lines that can separate the data for the labeled\ngroups. The SVM decision boundary\
    \ line is calculated by the following equation:\nf (x) = ∑\n∀i\nyiαiK(xi, x)\n\
    (2)\nwhere yi represents the class label, αi represents the learned weight, K()\
    \ represents the\nkernel function, xi denotes the support vector, and x denotes\
    \ the labeled training sample\ndata. The kernel function is given by a collection\
    \ of mathematical operations used to\nprocess the input data and convert it into\
    \ the required format. The radial basis function (RBF)\nkernel is one of the common\
    \ kernel functions in SVM. The following equation illustrates\nthe formula of\
    \ the (RBF) kernel:\nK(xi, xj) = exp(−d(xi, xj)2\n2l2\n)\n(3)\nwhere l represents\
    \ the length scale of the kernel and d(xi, xj) denotes the Euclidean distance\n\
    between xi and xj.\nDecision Tree and SVM have several hyper parameters. For them,\
    \ the Randomized Search\nMethod is implemented in SEMAR to ﬁnd the optimal combination\
    \ of hyper parameters,\ndue to its superior performances with the low cost and\
    \ short computing time compared to\nother methods.\nFor reference, the Decision\
    \ Tree algorithm has the following hyper parameters:\n•\nMaximum depth (max_depth):\
    \ represents the maximum depth of the tree model result.\nIt is used to select\
    \ the optimal model to prevent over-ﬁtting.\n•\nMinimum samples split (min_samples_split):\
    \ represents the minimal amount of data\nrequired to separate an internal node.\
    \ If it is large, it can prevent over-ﬁtting; however,\nif it is very large, it\
    \ can cause under-ﬁtting.\n•\nMinimum samples leaf (min_samples_lea f): represents\
    \ the minimal amount of data\nrequired to be left at the leaf node. It is similar\
    \ to the minimum samples split parameter.\n•\nMinimum weighted fraction leaf (min_weight_fraction_lea\
    \ f): represents the total weight\nrequired at a leaf node.\nThe Support Vector\
    \ Machine algorithm has the following main hyper parameters:\n•\nKernel: represents\
    \ the function of transforming the training dataset into the higher\ndimension\
    \ space. The standard kernel consists of Radial Basis Function (RBF), linear,\n\
    polynomials, and sigmoid.\n•\nC: represents the penalty parameter that controls\
    \ the trade-off between the decision\nboundary and the misclassiﬁcation. C value\
    \ controls the margin of the decision\nboundary line to avoid misclassiﬁcations.\
    \ The large value can prevent the model\nfrom allowing any misclassiﬁcation. If\
    \ the dataset is linearly separable, it will work;\nhowever, if the dataset is\
    \ non-separable/nonlinear, it is better to use a small C value\nto avoid overﬁtting,\
    \ although it allows misclassiﬁcations to occur.\nSensors 2022, 22, 6436\n11 of\
    \ 28\n•\nGamma: represents the coefﬁcient of the kernel used to decide the curvature\
    \ of the\ndecision boundary line. The value of Gamma determines the shape of the\
    \ decision\nboundary line according to the number of dataset points. The large\
    \ value causes the\ndecision boundary to be easily affected by fewer data points,\
    \ and the shape becomes\ncomplex. It can be helpful for nonlinear datasets; however,\
    \ if it is too large, it tends to\nbe over-ﬁtting. On the other hand, for the\
    \ linear dataset, the small values make the\ndecision boundary line more general\
    \ and useful.\nThe machine learning algorithms allow the user to use the data\
    \ stored in the data\nstorage as the sample data. This module can generate a data\
    \ model for the real-time data\nclassiﬁcation module.\nThe real-time data classiﬁcation\
    \ function is implemented to analyze a huge amount of\ndata from various sensor\
    \ devices by periodically running the following procedure:\n1.\nIt loads the data\
    \ classiﬁcation model made by the machine learning algorithm.\n2.\nIt receives\
    \ sensor data from the database.\n3.\nIt classiﬁes data into classes by running\
    \ the data model.\n4.\nIt stores results in the database.\nThe classiﬁcation model\
    \ can be created by each user separately. Moreover, the user\ncan start or stop\
    \ the real-time data classiﬁcation at the user interface.\n3.4. Data Output\n\
    Several output components, such as the monitor display, the user interface, the\
    \ data\nexport, REST API, and the notiﬁcation function, are considered to use\
    \ the data in the\nplatform. The monitor display is attached to the sensor node,\
    \ and accesses the user\ninterface in the platform through a network connection.\
    \ It can easily show sensor data for\neach device.\nThe user interface is provided\
    \ at the web browser to allow users to see the sensor\nand synchronized data by\
    \ tables, graphs, or maps. The platform allows users to access the\nsensor data\
    \ using the time of data receipt. It receives the sensor data in the JSON format\
    \ by\naccessing REST API. The column in the table is formed automatically based\
    \ on the sensor\nformat of each device. The platform can generate the graph for\
    \ each registered format\nsensor. Visualization maps will display the data in\
    \ digital maps based on the GPS data. The\ndata export feature is designed and\
    \ implemented to allow users to download data in Excel,\nJSON, text, or CSV format\
    \ at the speciﬁed time. Users can use this feature by accessing to\nthe user interfaces.\n\
    REST API is employed as a back-end system to access the sensor data. The sensor\
    \ data\nare retrieved from the database and is converted to the JSON format. It\
    \ will be sent to the\nuser interface and plug-in functions using HTTP POST communications.\
    \ The platform can\nexchange and integrate data with other IoT application systems\
    \ via REST API.\nThe notiﬁcation function allows the user to deﬁne the threshold\
    \ for each sensor data\nas the trigger of the message notiﬁcation. If the value\
    \ is over the threshold, the platform\nwill send a notiﬁcation. The platform offers\
    \ two different communication services. First, it\npublishes a message to a speciﬁc\
    \ topic using the MQTT communication protocol. Thus, the\nIoT application system\
    \ can subscribe to topic to receive the messages. Second, it delivers\nemail notiﬁcations\
    \ through the mail server service installed on the server platform. The\nuser\
    \ can dynamically deﬁne email recipients.\n3.5. Management Service\nThe management\
    \ service is used to manage all functions in the SEMAR platform. It\nincludes\
    \ the managements of users, devices, communications, schema data, synchroniza-\n\
    tion functions, analytics, data ﬁlters, and notiﬁcation functions. The management\
    \ of users\nallows us to add users, set permissions, and restrict access to the\
    \ devices.\nThe device management service provides the functions to register the\
    \ devices and the\nsensors of the IoT application system. It allows managing the\
    \ sensor format for each device\ndynamically. The platform can process, save,\
    \ and display the data registered in the sensor\nSensors 2022, 22, 6436\n12 of\
    \ 28\nformat. For convenience, the SEMAR platform provides a template to add the\
    \ device with\nthe same sensor format easily. The schema data management allows\
    \ to create the schema\ndatabase, deﬁne the ﬁeld format, and manage the data.\n\
    The management service provides the functions to add, update, and delete settings\n\
    for data synchronizations, data analytics, data ﬁltering, and notiﬁcations. It\
    \ allows the user\nto run and terminate the module service in the data process.\
    \ All the conﬁguration settings\nare saved as JSON objects.\n4. Implementation\
    \ of SEMAR IoT Server Platform\nIn this section, we present the implementation\
    \ of the SEMAR IoT server platform.\nTable 2 shows the summary of the implementation.\n\
    Table 2. Technology speciﬁcations for implementation of SEMAR IoT server platform.\n\
    IoT Model\nFunction\nComponent\nDescription\nInput\nMQTT\nMQTT Broker\nMosquitto\
    \ v2.0.10\nMQTT Supports\nMQTT v5.0, v3.1.1, and v3.1\nREST API\nLibraries and\
    \ Framework\nTornado Web Server, PyMongo,\nJSON\nCommunication Supports\nHTTP-POST\n\
    Network Interfaces\nNetwork Interfaces Supports\nWi-Fi, Ethernet, Cellular\nProcess\n\
    Server\nOperating System\nUbuntu 18.04.5 LTS\nMemory\n6Gb\nData Storage\nServices\n\
    MongoDB v3.6.3\nData Aggregator\nLibraries and Framework\nTornado Web Server,\
    \ PyMongo,\nJSON, Paho\nCommunication Supports\nHTTP-POST and MQTT\nData Filter\n\
    Libraries and Framework\nPyMongo, JSON, Numpy, Scipy\nand KalmanFilter\nData Synchronization\n\
    Libraries and Framework\nPyMongo, JSON , Pandas, Statistics\nand Threading\nMachine\
    \ Learning and Real-time\nData Classiﬁcation\nLibraries and Framework\nsklearn,\
    \ Pandas, PyMongo, JSON,\nand Threading\nOutput\nUser Interfaces and Data Export\n\
    Programming Language\nPHP, CSS, HTML and Javascript\nLibraries and Framework\n\
    CodeIgniter, Bootstrap, JQuery,\nHighChart JS, DataTables,\nOpenStreetMap\nWeb\
    \ services\nApache v2.4.29, PHP 7.2.24\nDevelopment Pattern\nMVC\nSupported browsers\n\
    Google Chrome, Firefox, Opera\nREST API\nLibraries and Framework\nTornado Web\
    \ Server, PyMongo,\nand JSON\nCommunication Supports\nHTTP-POST\nNotiﬁcation Functions\n\
    Libraries and Framework\nPyMongo, JSON, Paho, smtplib\nNotiﬁcation supports\n\
    Email and MQTT\nEmail Service\nPostﬁx\nManagement\nManagement Services\nLibraries\
    \ and Framework\nTornado Web Server, PyMongo and\nJSON\nCommunication Supports\n\
    HTTP-POST\nIn this implementation, the following two types of communication protocol\
    \ services\nare implemented for data input. Mosquitto [52] is installed for the\
    \ MQTT broker. It allows\nthe platform to receive messages through various MQTT\
    \ versions, and supports connections\nfrom Wi-Fi, Ethernet, and Cellular network\
    \ interfaces. Then, REST API is implemented\nSensors 2022, 22, 6436\n13 of 28\n\
    based on Python programming and Tornado web server [53]. It allows the platform\
    \ to\nreceive messages through HTTP POST and supports connections from Wi-Fi,\
    \ Ethernet, and\nCellular network interfaces.\nThe data process is deployed and\
    \ implemented in the platform. They are developed in\nPython using a variety of\
    \ modules and dependencies. For IoT data management systems,\nwe used two different\
    \ databases service implemented in the platform according to the\ndesign in Section\
    \ 3. The Big Data repository MongoDB [54] is utilized for the data storage\nfor\
    \ managements, sensors, and schema. MongoDB saves data in the JSON format as the\n\
    ﬂexible approach—there is no need to deﬁne data structures, unlike SQL. In addition,\
    \ the\nlog ﬁle is implemented in the CSV format. It can be accessed using a ﬁle\
    \ controller library\nin Python.\nTwo different data aggregators are implemented.\
    \ The ﬁrst one enables message\nreceptions using the MQTT communication protocol.\
    \ It allows a different MQTT communi-\ncation settings for each sensor device.\
    \ The second one does it with REST API. Both data\naggregators access the data\
    \ storage via PyMongo.\nIn this study, the data ﬁlter and synchronization capabilities\
    \ are utilized to process\nsensor data. Scipy and KalmanFilter Python libraries\
    \ are used to apply the data ﬁlters. After\nﬁltering the data, PyMongo is used\
    \ to save it in the data storage. The data synchronization\nused PyMongo for sensor\
    \ data in the data storage. Pandas is used for grouping data sensors.\nThreading\
    \ library is used to enhance the performance of the platform. This function runs\n\
    periodically on the server based on the detection time. The user can stop and\
    \ start this\nservice at the administration page in the user interface. Figure\
    \ 2 illustrates the user interface\nof the data synchronization function for the\
    \ sensor data during 30 s.\nFigure 2. Interface of data synchronization function.\n\
    According to the design systems in Section 3, the data analysis systems consist\
    \ learn-\ning process and real-time analysis service. We implemented both services\
    \ in Python.\nScikit-learn [55] is used to facilitate the learning process. The\
    \ Sklearn library is utilized for\nreal-time analysis to make the classiﬁcation\
    \ model during the learning process.\nData output includes the data visualization\
    \ and the data sharing with other systems\nincluding the plug-in systems. The\
    \ CodeIgniter PHP Framework is adopted to create user\ninterfaces based on the\
    \ Model-View-Control (MVC) design paradigm [56]. A user interface\nwill offer\
    \ data visualizations using HighchartJS, DataTalbes, and OpenStreetMap. Here,\
    \ Apache\nand PHP are required. Figure 3 shows the table of sensor data. Figure\
    \ 4 show graphs of\nsensor data.\nSensors 2022, 22, 6436\n14 of 28\nFigure 3.\
    \ Table of sensor data.\nFigure 4. Graphs of sensor data.\nDataTables library\
    \ is used to allow the user to download sensor data in Excel, JSON,\ntext, and\
    \ CSV formats at the speciﬁed times. Figure 5 show the data export interface.\n\
    REST API is built with Python and Tornado. It allows other application systems\
    \ and plug-in\nfunctions to access to sensor data in JSON formats.\nFigure 5.\
    \ Data export interface.\nFinally, The management service is built in Python and\
    \ Tornado web server. It allows\nus to receive messages through HTTP POST, and\
    \ to access data storage by PyMongo.\n5. Integration of Air Quality Monitoring\
    \ System\nAs the ﬁrst IoT application system, the air quality monitoring system\
    \ is integrated in the\nproposed platform. It can monitor the air quality in smart\
    \ cities.\n5.1. System Architecture\nFigure 6 shows the system overview. This\
    \ system uses a single-board computer (SBC)\nthat is connected to the GPS sensor\
    \ device and the air quality sensor device through Wi-Fi.\nThe air quality sensor\
    \ device covers the carbon monoxide sensor (MQ7), the particulate mat-\nter sensor\
    \ (Shinyei PPD42), the sulfur dioxide sensor (MQ135), the ozone sensor (MQ131),\n\
    Sensors 2022, 22, 6436\n15 of 28\nand the nitrogen dioxide sensor (MiCS 2714.\
    \ The sensor sends the voltage measurement\ndata to the Arduino UNO via GPIO.\
    \ Arduino UNO converts the data into the value of the\npollutant concentration\
    \ level and sends it to the SBC via the MQTT protocol. When the\nair sensor data\
    \ are received, the SBC adds the current time and the location information\n(latitude\
    \ and longitude) from the GPS sensor to the air sensor data, and sends it in the\n\
    JSON format every ﬁve seconds through the MQTT connection.\nFigure 6. System overview\
    \ of air quality monitoring system.\n5.2. Implementation in Platform\nFigure 7\
    \ shows the ﬂow of the functions in the SEMAR server platform for integrating\n\
    this IoT application system. Through the MQTT connection, the data aggregator\
    \ receives\nthe sensor data and stores it in the data storage. The real-time classiﬁcation\
    \ estimates the air\nquality index from the data between 0 and 4 that corresponds\
    \ to the air quality categories\nof good, moderate, poor, very poor, and hazardous.\
    \ The output data are shown at the user\ninterface.\nFigure 7. Function ﬂow for\
    \ air quality monitoring system in platform.\nTo evaluate the system integration,\
    \ we run the system to monitor actual air quality\nconditions. The sensor device\
    \ is mounted on the vehicle, and the single-board computer\nsystem is placed inside\
    \ the vehicle during the experiment. The device system sends air\nquality and\
    \ GPS data every ﬁve seconds. The evaluation results show that SEMAR has\nsuccessfully\
    \ received the sensor data, processed it, and classiﬁed the air quality index\
    \ based\non it. The results can be displayed on the user interface in real-time.\
    \ Table 3 shows the\nevaluation results of the classiﬁcation model used in this\
    \ experiment. We compare two\nalgorithms consisting of Support Vector Machine\
    \ (SVM) and Decision Tree (DT).\nTable 3. Evaluation of air quality monitoring\
    \ classiﬁcation model.\nFeatures\nAlgorithm\nMislabel\nAccuracy\nMSE\nAir Quality\n\
    Support Vector Machine\n605/10,053\n0.94239\n0.05761\nDecision Tree\n43/10,053\n\
    0.99591\n0.00409\nSensors 2022, 22, 6436\n16 of 28\nTable 3 illustrates that the\
    \ accuracy of the developed model is higher than 90%; there-\nfore, we can conclude\
    \ that the real-time classiﬁcation function to determine the air quality\nin SEMAR\
    \ provides advantages over similar studies, including the study by Toma et al.\n\
    in [21].\nMoreover, we also conducted experiment for hyper parameters tuning.\
    \ Table 4 shows\nthe experiment setup for optimizing the hyper parameters using\
    \ the randomized search\nmethod in this IoT Application.\nTable 4. Experiment\
    \ setup for hyper parameter optimizations in air quality monitoring.\nComponent\n\
    Speciﬁcation\nOperating System\nWindows 10 Enterprise, 64-bit\nProcessor\nAMD\
    \ Ryzen 5 3550H\nRAM memory\n8.0 GB\nMachine Learning Library\nScikit-learn [55]\n\
    Machine Learning Method\nSupport Vector Machine and Decision Tree\nDatasets\n\
    25,000 rows air quality data (5 labels, 5\nfeatures)\nFigure 8 shows the confusion\
    \ matrices for the Decision Tree algorithm and the Support\nVector Machine algorithm\
    \ in the air quality monitoring application. For Decision Tree,\nmax_depth = 12,\
    \ min_samples_split = 4, min_samples_lea f = 9, and min_weight_fraction\n_lea\
    \ f = 0.0 are obtained, where the accuracy of the model is 99%. For Support Vector\n\
    Machine, kernel = ”linear”, C = 1, and gamma = 0.01 are obtained, where accuracy\
    \ of the\nmodel is 95%.\nFigure 8. Confusion matrices of Decision Tree and Support\
    \ Vector Machine.\n6. Integration of Water Quality Monitoring System\nAs the second\
    \ IoT application system, the water quality monitoring system is integrated.\n\
    It can monitor the water quality in rivers ﬂowing in smart cities.\n6.1. System\
    \ Architecture\nFigure 9 shows the overview of the system architecture. This system\
    \ utilizes the sensor\ndevice equipped with water quality sensors for the hydrogen\
    \ potential (pH), the oxidation\nreduction potential (ORP), the dissolved oxygen\
    \ (DO), the electrical conductivity (EC),\nthe temperature, total dissolved solids\
    \ (TDS), the salinity (Sal), and the speciﬁc gravity\n(SG). The edge computing\
    \ device Raspberry Pi 3 collects the sensor data every ﬁve seconds\nand sends\
    \ it to a server. The system was tested at various points in the river in Surabaya,\n\
    Indonesia. The sensor node detects multiple parameters of water quality.\nSensors\
    \ 2022, 22, 6436\n17 of 28\nFigure 9. The system overview of the water monitoring\
    \ system.\n6.2. Implementation in Platform\nFigure 10 shows the ﬂow of the functions\
    \ in the platform for integrating this IoT\napplication system. Through the MQTT\
    \ connection, the data aggregator receives sensor\ndata from the devices and stores\
    \ it in the data storage. The real-time classiﬁcation function\nestimates the\
    \ water quality index from the collected data with a number between 0 and\n3 corresponding\
    \ to lightly polluted, heavy polluted, and polluted. The output data are\nshown\
    \ in the user interface.\nFigure 10. Function ﬂow for water quality monitoring\
    \ system in platform.\nWe evaluated the efficacy of the integration of SEMAR with\
    \ the water quality monitoring\nsystem. The evaluation was conducted by operating\
    \ the system in a real-world environment\nto monitor the water quality of a river.\
    \ The device transmits the water sensor data to the\nSEMAR server every five seconds\
    \ through MQTT communications. The experiment results\nindicate that the server\
    \ received the sensor data, classified the water quality index based on the\n\
    obtained data, and displayed it on the user interface in real-time. In addition,\
    \ we compared\nthe SVM and DT machine learning algorithms. are presented in Table\
    \ 5 shows the evaluation\nresults of the classification model utilized in the\
    \ real-classification function.\nTable 5. Evaluation of water quality monitoring\
    \ classiﬁcation model.\nFeatures\nAlgorithm\nMislabel\nAccuracy\nMSE\nWater Quality\n\
    Support Vector Machine\n289/45,397\n0.9936\n0.0064\nDecision Tree\n34/45,397\n\
    0.9993\n0.0007\nTable 5 shows that the accuracy of the classiﬁcation model for\
    \ the water quality is\nhigher than 90%. Thus, the superiority of SEMAR on the\
    \ integration with water quality\nmeasurement systems was conﬁrmed with abilities\
    \ to receive and classify data in real-time.\n7. Integration of Road Condition\
    \ Monitoring System\nAs the third IoT application system, the road condition monitoring\
    \ system is integrated.\nIt can monitor road surface conditions in smart cities.\n\
    Sensors 2022, 22, 6436\n18 of 28\n7.1. System Architecture\nFigure 11 shows the\
    \ system architecture overview. This system is implemented as a\nmobile-based\
    \ sensor network attached to the vehicle. This concept is called Vehicle as a\n\
    Mobile Sensor Network (VaaMSN). This system consists of the edge computing device,\
    \ the\nportable wireless camera, and the sensor device. The camera records the\
    \ road conditions in\nfront of the vehicle and transmits the image frames through\
    \ Real-Time Streaming Protocol\n(RTSP). The sensor device collects GPS, accelerometer,\
    \ and gyroscopes data, and transmits\nthem to the edge computing device via MQTT\
    \ protocol.\nFigure 11. System overview of road condition monitoring system.\n\
    The edge computing device detects potholes from the camera images using the deep\n\
    learning approach, OpenCV [57], and Tensorﬂow [58]. When detecting a pothole,\
    \ image\ndata are recorded in the directory ﬁle. Figure 12 shows the detected\
    \ pothole example by\nthe system. The edge computing will send the location, the\
    \ accelerometer, the gyroscopes,\nand the pothole state to the server through\
    \ the MQTT connection.\nFigure 12. Detected pothole example.\nSensors 2022, 22,\
    \ 6436\n19 of 28\n7.2. Implementation in Platform\nFigure 13 shows the ﬂow of\
    \ the functions in the platform for integrating this IoT\napplication system.\
    \ The data aggregator receives sensor data from the device through the\nMQTT connection,\
    \ and stores it in the data storage. The output data appear in the user\ninterface.\n\
    Figure 13. Function ﬂow for road condition detection system in platform.\nTo evaluate\
    \ the system integration, we run the road condition monitoring system\nto monitor\
    \ road surfaces in actual conditions. We place the sensor device in the vehicle\n\
    according to the layout shown in the system overview. They send JSON data consisting\n\
    of the GPS location, accelerometer, gyroscope, and pothole status to the server\
    \ through\nMQTT communications when the system detects a pothole, as shown in\
    \ Figure 12. The\nexperiment results show that the system can receive data from\
    \ the device, process it, and\ndisplay it on the map of the user interface in\
    \ real-time.\n8. Integration of Air-conditioning Guidance System\nAs the fourth\
    \ IoT application system, the air-conditioning guidance system (AC-Guide) is\n\
    integrated. It can offer the guidance for the optimal use of air-conditioning\
    \ (AC) in smart\ncities [59].\n8.1. System Architecture\nFigure 14 illustrates\
    \ the system architecture overview. AC-Guide uses a web camera,\na DHT22 sensor,\
    \ and Raspberry Pi 3 model b+ as the sensor device. The Python program\nof the\
    \ system periodically (1) collects the humidity and temperature of the room and\
    \ the\nAC control panel photo, (2) collects the standard outdoor weather data\
    \ by accessing to\nOpenWeatherMap API [60], (3) calculates the indoor discomfort\
    \ index (DI) to determines\nwhether the indoor state is comfort or discomfort,\
    \ (4) calculates the outdoor DI to determines\nwhether the outdoor state is comfort\
    \ or discomfort, (5) detects the on/off state of the AC from\nthe photo, (6) sends\
    \ the message to turn on or turn off the AC considering the indoor DI,\nthe outdoor\
    \ DI, and the on/off state of AC, (7) saves the data in the log ﬁle, and (8) send\n\
    the data to the server using the MQTT connection.\nFigure 14. System overview\
    \ of AC-Guide.\nSensors 2022, 22, 6436\n20 of 28\n8.2. Implementation in Platform\n\
    Figure 15 shows the ﬂow of the functions in the platform for integrating this\
    \ IoT\napplication system.\nFigure 15. Function ﬂow for AC-Guide in platform.\n\
    We evaluated the effectiveness of the integration of SEMAR with the air-conditioning\n\
    guidance system. The experiment was carried out by running the system at the #2\
    \ Engineer-\ning Building in Okayama University. The device sends JSON data containing\
    \ the indoor\nhumidity, indoor temperature, indoor discomfort index (DI), outdoor\
    \ humidity, outdoor\ntemperature, outdoor discomfort index (DI), and state of\
    \ AC using MQTT communications\nevery one minute. The evaluation results show\
    \ that SEMAR can receive sensor data and\ndisplay sensor data in real-time on\
    \ the user interface. Previously, these data were not\naccessible from other systems.\
    \ By integrating SEMAR, they can access the data through\nREST API. In addition,\
    \ SEMAR allows adding new sensors to the system without changing\nthe codes; therefore,\
    \ the advantages of integrating the SEMAR system is conﬁrmed.\n9. Integration\
    \ of Fingerprint-based Indoor Localization System\nAs the last IoT application\
    \ system, the ﬁngerprint-based indoor localization system using\nIEEE802.15.4\
    \ protocol (FILS15.4) is integrated. It detects the user locations in indoor environ-\n\
    ments according to the ﬁngerprints of the target location. The process is divided\
    \ into the\ncalibration phase and the detection phase [61,62].\n9.1. System Architecture\n\
    Figure 16 illustrates the overview of FILS15.4 architecture. This system adopts\
    \ trans-\nmitting and receiving devices by Mono Wireless which employs the IEEE802.15.4\
    \ protocol\nat 2.4 GHz [63]. The transmitter Twelite 2525 is small with 2.5 ×\
    \ 2.5 cm and can be powered\nwith a coin battery for a long time. The receiver\
    \ Mono Stick is connected to Raspberry Pi over\na USB port. To improve the detection\
    \ accuracy, the sufﬁcient number of receivers should be\nlocated at proper locations\
    \ in the target area.\nFigure 16. System overview of FILS15.4.\nRaspberry Pi receives\
    \ data from a transmitter, determines the link quality indication\n(LQI) for each\
    \ transmitter, sends the LQI with the ID to the MQTT broker using the MQTT\nprotocol.\
    \ The server receives them from the MQTT broker, synchronizes the data from all\n\
    the receivers, calculates the average LQI with the same transmitter ID, and keeps\
    \ the results\nSensors 2022, 22, 6436\n21 of 28\nin one record in the SQLite database.\
    \ The previous implementation used a free public\nMQTT service.\n9.2. Calibration\
    \ Phase\nThe calibration phase generates and stores the ﬁngerprint dataset. Each\
    \ ﬁngerprint\nconsists of n LQI values where n represents the number of receivers.\
    \ It represents the\ntypical LQI values when a transmitter is located at the corresponding\
    \ location (room in\nFILS15.4).\n9.3. Detection Phase\nThe detection phase detects\
    \ the current room by calculating the Euclidean distance\nbetween the current\
    \ LQI data and the ﬁngerprint for each room and ﬁnding the ﬁngerprint\nwith the\
    \ smallest distance.\n9.4. Implementation in Platform\nFigure 17 shows the ﬂow\
    \ of the functions in the platform for integrating this IoT\napplication system.\
    \ The data synchronization function synchronizes the measured LQI\nvalues among\
    \ all the receivers using the transmitter’s ID, and saves it in the schema data\n\
    storage. The detection program is implemented as the plug-in function in the platform,\
    \ and\nreceives data through REST API services.\nFigure 17. Function ﬂow for FILS15.4\
    \ in platform.\nWe evaluate the integration of SEMAR with the ﬁngerprint-based\
    \ indoor localization\nsystem by running the system at two ﬂoors in the #2 Engineering\
    \ Building of Okayama\nUniversity. This system used six receivers to measure LQI\
    \ from each transmitter. The\nreceiver sent the LQI data every 500 ms to the server\
    \ through MQTT communications.\nThe evaluation results show that SEMAR can receive,\
    \ process, and visualize the data. We\nalso evaluate the data synchronization\
    \ of the LQI data at the multiple receivers from the\nsame transmitter. Figure\
    \ 18 shows the synchronized LQI data for transmitter 1 during 30 s,\nwhere LQi\
    \ for i = 1, . . . , 6 indicates the LQI data at receiver i. They are saved in\
    \ the schema\ndata storage and can be accessed from other programs through REST\
    \ API. This system can\nrun without interruptions even if it processes empty LQI\
    \ data or if error detection occurs.\nWhen the system detects an error, it sets\
    \ the LQI data to the default value. According to the\nevaluation results, the\
    \ effectiveness of integrating the SEMAR system is conﬁrmed.\nFigure 18. LQI data\
    \ of transmitter 1.\nSensors 2022, 22, 6436\n22 of 28\n10. Evaluations\nIn this\
    \ section, we evaluate the implementation of SEMAR IoT server platform.\n10.1.\
    \ Performance Analysis\nTo evaluate the performance of SEMAR at the parameter\
    \ level, ﬁrst, we investigate the\naverage response time for MQTT data communications\
    \ when the number of IoT devices is\nincreased from 1 to 125. In the experiments,\
    \ a virtual IoT device is created in the system\ninstead of a real device. Then,\
    \ each virtual IoT device sends one message through a\ndifferent topic every second.\
    \ During this experiment, the CPU usage rate of the machine is\nalso measured.\n\
    As the response time, the time difference at a virtual IoT device from the data\
    \ transmis-\nsion to the server to the message reception from the server is measured.\
    \ For HTTP POST, it\ncan easily be obtained. When the IoT device sends data to\
    \ the server, the REST API service\nreturns the response message; however, for\
    \ MQTT, the program is modiﬁed to measure the\nresponse time where it will send\
    \ the MQTT message to the device when it stores data in\nthe storage.\nFigures\
    \ 19 and 20 show the average response time and the average CPU usage rate\nwhen\
    \ the number of virtual IoT devices is increased from 1 to 125, respectively.\
    \ The average\nresponse time is 315ms and the CPU usage rate is 74% for 125 devices.\
    \ Thus, SEMAR our\ncan handle hundreds of devices with acceptable delay and CPU\
    \ rate.\nFigure 19. Average response time for MQTT communications with different\
    \ numbers of devices.\nFigure 20. Average CPU usage rate with different numbers\
    \ of devices.\n10.2. The State-of-the-Art Comparative Analysis\nWe compare the\
    \ SEMAR IoT server platform with 14 recent research works that have\nthe similar\
    \ approach. In the comparison with the recent related works in the literature,\
    \ we\nconsider the following features to characterize each proposal:\nSensors\
    \ 2022, 22, 6436\n23 of 28\n•\nIoT application: represents the IoT application\
    \ that is covered or implemented in each\nwork.\n•\nDevice management: indicates\
    \ the capability of the IoT platform to manage devices (Yes\nor No).\n•\nCommunication\
    \ protocol: describes the communication protocol utilized in each work.\n•\nData\
    \ synchronization: implies the capability to synchronize data across several devices\n\
    (Yes or No).\n•\nData ﬁltering function: indicates the implementation of digital\
    \ ﬁlters to process data\n(Yes or No).\n•\nDecision-making assistance: indicates\
    \ the implementation of tools to evaluate data or\ngenerate alerts based on data\
    \ obtained (Yes or No).\n•\nFlexibility: shows the abilities to allow to join\
    \ new devices, to handle different commu-\nnication settings, to deﬁne data types,\
    \ and to easily interact with external systems (Yes\nor No).\n•\nInteroperability:\
    \ represents the ability to be integrated with plural external systems\nthrough\
    \ deﬁned protocols (Yes or No).\n•\nScalability: demonstrates the capability of\
    \ processing a number of data simultaneously\n(Yes or No).\nTable 6 compares the\
    \ fulﬁllment of the nine features among the 14 related works and\nthe proposed\
    \ SEMAR.\nTable 6. State-of-the-art comparison between the existing related studies\
    \ and the proposed solution.\nWork\nReference\nIoT Appli-\ncation\nDevice\nManagement\n\
    Data\nSynchronization\nData Filter\nDecision-\nmaking\nassistance\nFlexibility\n\
    Interoperability\nScalability\nCommunication\nProtocol\n[17]\nIndoor Air Quality\n\
    ✓\n\x17\n\x17\n\x17\n✓\n\x17\n✓\nHTTP\n[64]\nSmart Agriculture\n✓\n\x17\n\x17\n\
    ✓\n✓\n✓\n✓\nMQTT\n[18]\nAir Pollution\n✓\n\x17\n\x17\n✓\n\x17\n\x17\n✓\nHTTP\n\
    [19]\nWater Management\n✓\n\x17\n\x17\n\x17\n\x17\n\x17\n✓\nHTTP\n[65]\nWater\
    \ Management\n✓\n\x17\n\x17\n✓\n✓\n✓\n✓\nMQTT\n[21]\nAir Pollution\n✓\n\x17\n\x17\
    \n\x17\n✓\n✓\n✓\nMQTT\n[66]\nIndoor Air Quality\n✓\n\x17\n\x17\n✓\n\x17\n✓\n✓\n\
    MQTT\n[67]\nSmart City\n✓\n\x17\n\x17\n\x17\n\x17\n\x17\n✓\nHTTP & AMQP\n[68]\n\
    Smart Industry\n✓\n\x17\n\x17\n✓\n✓\n✓\n✓\nMQTT\n[69]\nSmart Agriculture and Smart\
    \ City\n✓\n\x17\n\x17\n\x17\n✓\n✓\n✓\nMQTT\n[70]\nSmart Farming\n✓\n\x17\n\x17\
    \n✓\n✓\n✓\n✓\nMQTT\n[22]\nSmart Building\n✓\n\x17\n\x17\n✓\n\x17\n✓\n✓\nHTTP &\
    \ Web Socket\n[71]\nSmart Irrigation\n✓\n\x17\n\x17\n✓\n\x17\n\x17\n✓\nMQTT\n\
    [72]\nSmart Green and Smart City\n✓\n\x17\n\x17\n\x17\n✓\n✓\n✓\nHTTP, MQTT, AMQP\n\
    SEMAR\nVarious IoT applications\n✓\n✓\n✓\n✓\n✓\n✓\n✓\nHTTP & MQTT\n10.2.1. IoT\
    \ Application\nAlthough the works by Hernández-Rojas et al. in [64], Marcu et\
    \ al. in [69], and\nAntunes et al. in [72] have potentials of use in various IoT\
    \ applications, they have been\nstudied in speciﬁc IoT applications. On the other\
    \ hand, SEMAR has been integrated and\nimplemented in several types of IoT applications.\n\
    10.2.2. IoT Device Management\nAll the related works provide functions to add\
    \ or remove IoT devices. Some works\nsupport device management services. Some\
    \ works include capabilities to deﬁne the sensor\nSensors 2022, 22, 6436\n24 of\
    \ 28\nformat for each IoT device dynamically. The work by Trilles et al. in [70]\
    \ provides the\neasy-to-use user interface to manage IoT devices. On the other\
    \ hand, SEMAR provides all\nof the functions on IoT devices.\n10.2.3. Communication\
    \ Protocol\nHTTP and MQTT are the most adopted communication protocols in IoT\
    \ application\nplatforms. In addition, Del Esposte in [67] and Antunes in [72]\
    \ introduce AMQP as another\nprotocol utilizing TCP connections. Thus, it is suitable\
    \ for server–client communications\n[73]. None of the related works reported functions\
    \ to synchronize data from several\ndevices and digital ﬁlters to process sensor\
    \ data. Only SEMAR provides both the data\nsynchronization capability and digital\
    \ ﬁlters to process data.\n10.2.4. Decision Making Assistance\nFor decision-making\
    \ assistance, a lot of works have offered functions for perspec-\ntive data analysis\
    \ based on collected data. The works by Mandava et al. in [18], by\nKamienski\
    \ et al. in [65], by Chiesa et al. in [66], and by Boursianis et al. in [71] applied\n\
    machine learning algorithms for real-time classiﬁcations, and show the results\
    \ for user\ninterfaces. The work by Hernández-Rojas et al. in [64] utilized message\
    \ notiﬁcations\naccording to a speciﬁc data threshold. The work by Trilles et\
    \ al. in [70] and our SEMAR\nincluded both of them.\n10.2.5. Interoperability\
    \ and Flexibility\nSeveral works provided interoperability. The works by Hernández-Rojas\
    \ et al. in [64],\nby Trilles et al. in [70], and SEMAR allow outer programs to\
    \ process data without changing\nthe existing program in the systems.\nSome works\
    \ consider the ﬂexibility as the IoT application platform. The works by\nHernández-Rojas\
    \ et al. in [64] and by Trilles et al. in [70] provide the capability to dynami-\n\
    cally deﬁne the sensor format and the data type for each device, similar to SEMAR.\n\
    However, any work cannot be connected with other MQTT servers. Only SEMAR\nﬂexibly\
    \ allows users to use other MQTT servers, which will allow IoT applications to\
    \ be\neasily integrated with SEMAR.\n11. Threats to Validity\nThere are two kinds\
    \ of threats to the validity of this research, which are as follows:\n•\nInternal\
    \ validity threat: validates the potential errors in the SEMAR implementation.\n\
    In this study, SEMAR is integrated with ﬁve different IoT application systems.\
    \ Each\nIoT application utilized various kinds of sensors. Possible threats may\
    \ occur when\nsubmitting invalid or incomplete data. Moreover, the integration\
    \ of SEMAR with the\nﬁngerprint-based indoor localization system requires the\
    \ synchronization of data from\neach receiver to determine the location of the\
    \ transmitter. To eliminate potential\nthreats, SEMAR checks sensor data with\
    \ the format. In addition, the data synchro-\nnization function will provide default\
    \ values for devices with no data within the data\nsynchronization timeframe.\n\
    •\nExternal validity threat: validates the generalization ability of the obtained\
    \ results. We\ncompare the results of SEMAR to those of previous IoT-related studies.\
    \ The primary\npotential external threat revealed by the comparison results is\
    \ that not all of the related\nIoT-related research provided comprehensive and\
    \ clear explanations of the proposals.\n12. Conclusions\nThis paper presented\
    \ the design and implementation of the IoT server platform for\nintegrating various\
    \ IoT application systems, called Smart Environmental Monitoring and\nAnalytical\
    \ in Real-Time (SEMAR). It offers Big Data environments with built-in functions\
    \ for\ndata aggregations, synchronizations, and classiﬁcations with machine learning,\
    \ and plug-in\nfunctions that access to the data through REST API. The platform\
    \ was implemented and\nSensors 2022, 22, 6436\n25 of 28\nintegrated with ﬁve IoT\
    \ application systems. The results conﬁrmed the effectiveness and\nefﬁciency of\
    \ the proposal.\nIn future studies, we will continue improving the platform by\
    \ implementing Rules\nEngine and Complex Event Processing (CEP) [74] for the data\
    \ processing. Rules Engine\nwill support user-deﬁned rules, actions, and notiﬁcations.\
    \ CEP will offer the real-time\ndata analysis based on rule patterns [75]. It\
    \ will control the device action or deliver\nmessages to users when rule patterns\
    \ are matched; however, these functions meet issues in\nparallelism, resource\
    \ allocations, distributed networks, and multi-rules optimizations [76],\nwhich\
    \ will be studied. Then, we will continue integrating the proposal with various\
    \ IoT\napplication systems.\nAuthor Contributions: Conceptualization, Y.Y.F.P.,\
    \ N.F. and S.S.; Methodology, Y.Y.F.P.; Software,\nY.Y.F.P. and P.P.; Writing—Original\
    \ Draft Preparation, Y.Y.F.P.; Writing—Review and Editing, N.F.; Vali-\ndation,\
    \ M.K. and W.-C.K. All authors have read and agreed to the published version of\
    \ the manuscript.\nFunding: This research received no external funding.\nInstitutional\
    \ Review Board Statement: Not applicable.\nInformed Consent Statement: Not applicable.\n\
    Data Availability Statement: Not applicable.\nAcknowledgments: The authors thank\
    \ the reviewers for their thorough reading and helpful comments.\nConﬂicts of\
    \ Interest: The authors declare no conﬂict of interest.\nReferences\n1.\nTheoﬁlou,\
    \ P. Quality of Life: Deﬁnition and Measurement. Eur. J. Psychol. 2013, 9, 150–162.\
    \ [CrossRef]\n2.\nMacke, J.; Casagrande, R.; Sarate, J.; Silva, K. Smart City\
    \ and Quality of Life: Citizens’ perception in a Brazilian case study.\nJ. Clean.\
    \ Prod. 2018, 182, 717–726. [CrossRef]\n3.\nNoura, M.; Atiquzzaman, M.; Gaedke,\
    \ M. Interoperability in Internet of Things: Taxonomies and Open Challenges. Mob.\
    \ Networks\nAppl. 2018, 24, 796–809. [CrossRef]\n4.\nCubo, J.; Nieto, A.; Pimentel,\
    \ E. A Cloud-Based Internet of Things Platform for Ambient Assisted Living. Sensors\
    \ 2014, 14,\n14070–14105. [CrossRef]\n5.\nLeong, W.; Kelani, R.; Ahmad, Z. Prediction\
    \ of Air Pollution Index (API) using Support Vector Machine (SVM). J. Environ.\
    \ Chem.\nEng. 2020, 8, 103208. [CrossRef]\n6.\nPerlmutt, L.; Cromar, K. Comparing\
    \ Associations of Respiratory Risk for The EPA Air Quality Index and Health-Based\
    \ Air\nQuality Indices. Atmos. Environ. 2019, 202, 1–7. [CrossRef]\n7.\nMQTT Org.\
    \ Message Queuing Telemetry Transport Protocol. Available online: http://mqtt.org/\
    \ (accessed on 12 May 2022).\n8.\nKamienski, C.; Prati, R.; Kleinschmidt, J.;\
    \ Soininen, J.P. Designing an Open IoT Ecosystem. In Proceedings of the Workshop\
    \ on\nCloud Networks 2019, Belem, Brazil, 16 July 2019.\n9.\nBansal, S.; Kumar,\
    \ D. IoT Ecosystem: A Survey on Devices, Gateways, Operating Systems, Middleware\
    \ and Communication. Int.\nJ. Wirel. Inf. Netw. 2020, 27, 340–364. [CrossRef]\n\
    10.\nLi, S.; Xu, L.; Zhao, S. The Internet of Things: A Survey. Inf. Syst. Front.\
    \ 2014, 17, 243–259. [CrossRef]\n11.\nMalche, T.; Maheshwary, P.; Kumar, R. Environmental\
    \ Monitoring System for Smart City Based on Secure Internet of Things (IoT)\n\
    Architecture. Wirel. Pers. Commun. 2019, 107, 2143–2172. [CrossRef]\n12.\nVenkanna,\
    \ U.; Sharma, S.; Katiyar, B.; Prashanth, Y. A Wireless Sensor Node Based Efﬁcient\
    \ Parking Slot Availability Detection\nSystem for Smart Cities. In Proceedings\
    \ of the 2018 Recent Advances on Engineering, Technology and Computational Sciences\n\
    (RAETCS), Allahabad, India, 6–8 February 2018; pp. 1–6.\n13.\nZhang, Q.; Zhong,\
    \ H.; Shi, W.; Liu, L. A Trusted and Collaborative Framework for Deep Learning\
    \ in IoT. Comput. Netw. 2021, 193,\n108055. [CrossRef]\n14.\nJain, V.; Ahuja,\
    \ A.; Saini, D. Evaluation and Performance Analysis of Apache Pulsar and NATS.\
    \ In Cyber Security and Digital\nForensics; Lecture Notes on Data Engineering\
    \ and Communications Technologies; Springer: Singapore, 2021; pp. 179–190.\n[CrossRef]\n\
    15.\nDizdarevi´c, J.; Carpio, F.; Jukan, A.; Masip-Bruin, X. A Survey of Communication\
    \ Protocols for Internet of Things and Related\nChallenges of Fog and Cloud Computing\
    \ Integration. ACM Comput. Surv. 2019, 51, 1–29. [CrossRef]\n16.\nMarques, G.;\
    \ Pitarma, R. An Internet of Things-Based Environmental Quality Management System\
    \ to Supervise the Indoor\nLaboratory Conditions. Appl. Sci. 2019, 9, 438. [CrossRef]\n\
    17.\nBenammar, M.; Abdaoui, A.; Ahmad, S.; Touati, F.; Kadri, A. A Modular IoT\
    \ Platform for Real-Time Indoor Air Quality Monitoring.\nSensors 2018, 18, 581.\
    \ [CrossRef] [PubMed]\nSensors 2022, 22, 6436\n26 of 28\n18.\nMandava, T.; Chen,\
    \ S.; Isaﬁade, O.; Bagula, A. An IoT Middleware for Air Pollution Monitoring in\
    \ Smart Cities: A Situation\nRecognition Model. In Proceedings of the IST Africa\
    \ 2018 Conference, Gabarone, Botswana, 9–11 May 2018.\n19.\nSeno`zetnik, M.; Herga,\
    \ Z.; Šubic, T.; Brade`sko, L.; Kenda, K.; Klemen, K.; Pergar, P.; Mladeni´c,\
    \ D. IoT Middleware for Water\nManagement. Proceedings 2018, 2, 696. [CrossRef]\n\
    20.\nKazmi, A.; Serrano, M.; Soldatos, J. VITAL-OS: An Open Source IoT Operating\
    \ System for Smart Cities. IEEE Commun. Stand.\nMag. 2018, 2, 71–77. [CrossRef]\n\
    21.\nToma, C.; Alexandru, A.; Popa, M.; Zamﬁroiu, A. IoT Solution for Smart Cities’\
    \ Pollution Monitoring and the Security Challenges.\nSensors 2019, 19, 3401. [CrossRef]\
    \ [PubMed]\n22.\nJaved, A.; Malhi, A.; Kinnunen, T.; Framling, K. Scalable IoT\
    \ Platform for Heterogeneous Devices in Smart Environments. IEEE\nAccess 2020,\
    \ 8, 211973–211985. [CrossRef]\n23.\nThe Apache Cassandra Software Project Website.\
    \ Available online: https://cassandra.apache.org/ (accessed on 22 August 2022).\n\
    24.\nBadii, C.; Bellini, P.; Diﬁno, A.; Nesi, P. Smart city IoT Platform Respecting\
    \ GDPR Privacy and Security Aspects. IEEE Access 2020,\n8, 23601–23623. [CrossRef]\n\
    25.\nPutra, K.; Chen, H.; Prayitno; Ogiela, M.; Chou, C.; Weng, C.; Shae, Z. Federated\
    \ Compressed Learning Edge Computing\nFramework with Ensuring Data Privacy for\
    \ PM2.5 Prediction in Smart City Sensing Applications. Sensors 2021, 21, 4586.\n\
    [CrossRef]\n26.\nGautam, G.; Sharma, G.; Magar, B.; Shrestha, B.; Cho, S.; Seo,\
    \ C. Usage of IoT Framework in Water Supply Management for Smart\nCity in Nepal.\
    \ Appl. Sci. 2021, 11, 5662. [CrossRef]\n27.\nOliveira, F.; Costa, D.; Lima, L.;\
    \ Silva, I. iBikeSafe: A Multi-Parameter System for Monitoring, Evaluation and\
    \ Visualization of\nCycling Paths in Smart Cities Targeted at Cycling Adverse\
    \ Conditions. Smart Cities 2021, 4, 56. [CrossRef]\n28.\nMetia, S.; Nguyen, H.;\
    \ Ha, Q. IoT-Enabled Wireless Sensor Networks for Air Pollution Monitoring with\
    \ Extended Fractional-Order\nKalman Filtering. Sensors 2021, 21, 5313. [CrossRef]\
    \ [PubMed]\n29.\nTwahirwa, E.; Rwigema, J.; Datta, R. Design and Deployment of\
    \ Vehicular Internet of Things for Smart City Applications.\nSustainability 2021,\
    \ 14, 176. [CrossRef]\n30.\nD’Ortona, C.; Tarchi, D.; Raffaelli, C. Open-Source\
    \ MQTT-Based End-to-End IoT System for Smart City Scenarios. Future Internet\n\
    2022, 14, 57. [CrossRef]\n31.\nKumar, P.; Gupta, G.; Tripathi, R. Design of Anomaly-Based\
    \ Intrusion Detection System Using Fog Computing for IoT Network.\nAutom. Control.\
    \ Comput. Sci. 2021, 55, 137–147. [CrossRef]\n32.\nKumar, P.; Gupta, G.; Tripathi,\
    \ R. A Distributed Ensemble Design Based Intrusion Detection System Using Fog\
    \ Computing to\nProtect The Internet of Things Networks. J. Ambient. Intell. Humaniz.\
    \ Comput. 2020, 12, 9555–9572. [CrossRef]\n33.\nKumar, P.; Gupta, G.; Tripathi,\
    \ R. Toward Design of an Intelligent Cyber Attack Detection System using Hybrid\
    \ Feature Reduced\nApproach for IoT Networks. Arab. J. Sci. Eng. 2021, 46, 3749–3778.\
    \ [CrossRef]\n34.\nKumar, P.; Gupta, G.; Tripathi, R. PEFL: Deep Privacy-Encoding-Based\
    \ Federated Learning Framework for Smart Agriculture.\nIEEE Micro 2022, 42, 33–40.\
    \ [CrossRef]\n35.\nKumar, P.; Tripathi, R.P.; Gupta, G. P2IDF: A Privacy-preserving\
    \ Based Intrusion Detection Framework for Software Deﬁned\nInternet of Things-fog\
    \ (SDIoT-Fog). In Proceedings of the 2021 International Conference on Distributed\
    \ Computing and\nNetworking, Nara, Japan, 5–8 January 2021; pp. 37–42.\n36.\n\
    Wu, H.; Chen, C.; Weng, K. Two Designs of Automatic Embedded System Energy Consumption\
    \ Measuring Platforms Using\nGPIO. Appl. Sci. 2020, 10, 4866. [CrossRef]\n37.\n\
    Munshi, A. Improved MQTT Secure Transmission Flags in Smart Homes. Sensors 2022,\
    \ 22, 2174. [CrossRef]\n38.\nDinculean˘a, D.; Cheng, X. Vulnerabilities and Limitations\
    \ of MQTT Protocol Used between IoT Devices. Appl. Sci. 2019, 9, 848.\n[CrossRef]\n\
    39.\nAl-Joboury, I.; Al-Hemiary, E. IoT-F2CDM-LB: IoT Based Fog-to-Cloud and Data-in-Motion\
    \ Architectures with Load Balancing.\nEAI Endorsed Trans. Internet Things 2018,\
    \ 4, 155332. [CrossRef]\n40.\nWaseem, M.; Liang, P.; Shahin, M. A Systematic Mapping\
    \ Study on Microservices Architecture in DevOps. J. Syst. Softw. 2020,\n170, 110798.\
    \ [CrossRef]\n41.\nFridelin, Y.; Ulil Albaab, M.; Anom Besari, A.; Sukaridhoto,\
    \ S.; Tjahjono, A. Implementation of Microservice Architectures on\nSEMAR Extension\
    \ for Air Quality Monitoring. In Proceedings of the 2018 International Electronics\
    \ Symposium on Knowledge\nCreation and Intelligent Computing (IES-KCIC) 2018,\
    \ Bali, Indonesia, 29–30 October 2018; pp. 218–224.\n42.\nKumar, P.; Gupta, G.;\
    \ Tripathi, R.; Garg, S.; Hassan, M. DLTIF: Deep Learning-Driven Cyber Threat\
    \ Intelligence Modeling and\nIdentiﬁcation Framework in IoT-Enabled Maritime Transportation\
    \ Systems. IEEE Trans. Intell. Transp. Syst. 2021, 1–10.\n43.\nKumar, P.; Kumar,\
    \ R.; Gupta, G.; Tripathi, R. BDEdge: Blockchain and Deep-Learning for Secure\
    \ Edge-Envisioned Green CAVs.\nIEEE Trans. Green Commun. Netw. 2022, 1330–1339.\n\
    44.\nKumar, P.; Gupta, G.; Tripathi, R. TP2SF: A Trustworthy Privacy-Preserving\
    \ Secured Framework for Sustainable Smart Cities by\nLeveraging Blockchain and\
    \ Machine learning. J. Syst. Archit. 2021, 115, 101954. [CrossRef]\n45.\nKumar,\
    \ P.; Gupta, G.; Tripathi, R. An Ensemble Learning and Fog-cloud Architecture-driven\
    \ Cyber-attack Detection Framework\nfor IoMT Networks. Comput. Commun. 2021, 166,\
    \ 110–124. [CrossRef]\n46.\nChang, C.; Lin, C. LIBSVM: A Library for Support Vector\
    \ Machines. ACM Trans. Intell. Syst. Technol. 2011, 2, 1–27. [CrossRef]\nSensors\
    \ 2022, 22, 6436\n27 of 28\n47.\nSuárez Sánchez, A.; García Nieto, P.; Riesgo\
    \ Fernández, P.; del Coz Díaz, J.; Iglesias-Rodríguez, F. Application of an SVM-based\n\
    regression model to the air quality study at local scale in the Avilés urban area\
    \ (Spain). Math. Comput. Model. 2011, 54, 1453–1466.\n[CrossRef]\n48.\nGhiasi,\
    \ M.; Zendehboudi, S. Decision Tree-Based Methodology to Select a Proper Approach\
    \ for Wart Treatment. Comput. Biol.\nMed. 2019, 108, 400–409. [CrossRef]\n49.\n\
    Hagan, D.; Isaacman-VanWertz, G.; Franklin, J.; Wallace, L.; Kocar, B.; Heald,\
    \ C.; Kroll, J. Calibration and Assessment of\nElectrochemical Air Quality Sensors\
    \ by Co-Location with Regulatory-Grade Instruments. Atmos. Meas. Tech. 2018, 11,\
    \ 315–328.\n[CrossRef]\n50.\nWei, W.; Ramalho, O.; Malingre, L.; Sivanantham,\
    \ S.; Little, J.; Mandin, C. Machine Learning and Statistical Models for Predicting\n\
    Indoor Air Quality. Indoor Air 2019, 29, 704–726. [CrossRef] [PubMed]\n51.\nGhosh,\
    \ S.; Dasgupta, A.; Swetapadma, A. A Study on Support Vector Machine Based Linear\
    \ and Non-Linear Pattern Classiﬁcation.\nIn Proceedings of International Conference\
    \ on Intelligent Sustainable Systems (ICISS) 2019, Palladam, India, 21–22 February\
    \ 2019;\npp. 24–28.\n52.\nMQTT Mosquitto Server. Available online: https://mosquitto.org/\
    \ (accessed on 12 May 2022).\n53.\nDory, M.; Parrish, A.; Berg, B. Introduction\
    \ to Tornado; O’Reilly Media: Sebastopol, CA, USA, 2012.\n54.\nMongoDB, Mongodb:\
    \ The Application Data Platform. Available online: https://www.mongodb.com/(accessed\
    \ on 12 May 2022).\n55.\nHao, J.; Ho, T. Machine Learning Made Easy: A Review\
    \ of Scikit-learn Package in Python Programming Language. J. Educ. Behav.\nStat.\
    \ 2019, 44, 348–361. [CrossRef]\n56.\nGamma, E.; Helm, R.; Johnson, R.; Vlissides,\
    \ J.M. Design Patterns: Elements of Reusable Object-Oriented Software; Addison-Wesley\n\
    Professional; Addison-Wesley: Boston, MA, USA, 1994.\n57.\nVillán, A.F. Mastering\
    \ OpenCV 4 with Python: A Practical Guide Covering Topics from Image Processing,\
    \ Augmented Reality to Deep\nLearning with OpenCV 4 and Python 3.7; Packt Publishing\
    \ Ltd.: Birmingham, UK, 2019.\n58.\nPang, B.; Nijkamp, E.; Wu, Y. Deep Learning\
    \ With TensorFlow: A Review. J. Educ. Behav. Stat. 2019, 45, 227–248. [CrossRef]\n\
    59.\nHuda, S.; Funabiki, N.; Kuribayashi, M.; Sudibyo, R.; Ishihara, N.; Kao,\
    \ W. A Proposal of Air-Conditioning Guidance System Using\nDiscomfort Index. In\
    \ Proceedings of the 15th International Conference on Broad-Band and Wireless\
    \ Computing, Communication\nand Applications (BWCCA-2020), Yonago, Japan, 28–30\
    \ October 2020; pp. 154–165.\n60.\nOpenWeatherMap. Current Weather and Forecast—OpenWeatherMap.\
    \ Available online: https://openweathermap.org/\n(accessed on 12 May 2022).\n\
    61.\nHuo, Y.; Puspitaningayu, P.; Funabiki, N.; Hamazaki, K.; Kuribayashi, M.;\
    \ Kojima, K. A. Proposal of the Fingerprint Optimization\nMethod for the Fingerprint-Based\
    \ Indoor Localization System with IEEE 802.15.4 Devices. Information 2022, 13,\
    \ 211. [CrossRef]\n62.\nPuspitaningayu, P.; Huo, Y.; Funabiki, N.; Hamazaki, K.;\
    \ Kuribayashi, M.; Kao, W. Investigations of Detection Accuracy\nImprovements\
    \ for Fingerprint-based Indoor Localization System Using IEEE 802.15.4. In Proceedings\
    \ of the Fourth International\nConference on Vocational Education and Electrical\
    \ Engineering (ICVEE) 2021, Surabaya, Indonesia, 2–3 October 2021; pp. 1–5.\n\
    63.\nMono Wireless. Mono Wireless Product Information. Available online: https://mono-wireless.com/jp/products/index.html\n\
    (accessed on 12 May 2022).\n64.\nHernández-Rojas, D.; Fernández-Caramés, T.; Fraga-Lamas,\
    \ P.; Escudero, C. A Plug-and-Play Human-Centered Virtual TEDS\nArchitecture for\
    \ the Web of Things. Sensors 2018, 18, 2052. [CrossRef]\n65.\nKamienski, C.; Soininen,\
    \ J.; Taumberger, M.; Dantas, R.; Toscano, A.; Salmon Cinotti, T.; Filev Maia,\
    \ R.; Torre Neto, A. Smart\nWater Management Platform: IoT-Based Precision Irrigation\
    \ for Agriculture. Sensors 2019, 19, 276. [CrossRef]\n66.\nChiesa, G.; Cesari,\
    \ S.; Garcia, M.; Issa, M.; Li, S. Multisensor IoT Platform for Optimising IAQ\
    \ Levels in Buildings through a Smart\nVentilation System. Sustainability 2019,\
    \ 11, 5777. [CrossRef]\n67.\nDe M. Del Esposte, A.; Santana, E.; Kanashiro, L.;\
    \ Costa, F.; Braghetto, K.; Lago, N.; Kon, F. Design and Evaluation of a Scalable\n\
    Smart City Software Platform with Large-Scale Simulations. Future Gener. Comput.\
    \ Syst. 2019, 93, 427–441. [CrossRef]\n68.\nChristou, I.; Kefalakis, N.; Zalonis,\
    \ A.; Soldatos, J.; Bröchler, R. End-to-End Industrial IoT Platform for Actionable\
    \ Predictive\nMaintenance. IFAC-PapersOnLine 2020, 53, 173–178. [CrossRef]\n69.\n\
    Marcu, I.; Suciu, G.; B˘al˘aceanu, C.; Vulpe, A.; Dr˘agulinescu, A. Arrowhead\
    \ Technology for Digitalization and Automation\nSolution: Smart Cities and Smart\
    \ Agriculture. Sensors 2020, 20, 1464. [CrossRef] [PubMed]\n70.\nTrilles, S.;\
    \ González-Pérez, A.; Huerta, J. An IoT Platform Based on Microservices and Serverless\
    \ Paradigms for Smart Farming\nPurposes. Sensors 2020, 20, 2418. [CrossRef] [PubMed]\n\
    71.\nBoursianis, A.; Papadopoulou, M.; Gotsis, A.; Wan, S.; Sarigiannidis, P.;\
    \ Nikolaidis, S.; Goudos, S. Smart Irrigation System for\nPrecision Agriculture—The\
    \ AREThOU5A IoT Platform. IEEE Sens. J. 2021, 21, 17539–17547. [CrossRef]\n72.\n\
    Antunes, M.; Santiago, A.; Manso, S.; Regateiro, D.; Barraca, J.; Gomes, D.; Aguiar,\
    \ R. Building an IoT Platform Based on Service\nContainerisation. Sensors 2021,\
    \ 21, 6688. [CrossRef]\n73.\nDepari, A.; Fernandes Carvalho, D.; Bellagente, P.;\
    \ Ferrari, P.; Sisinni, E.; Flammini, A.; Padovani, A. An IoT Based Architecture\n\
    for Enhancing the Effectiveness of Prototype Medical Instruments Applied to Neurodegenerative\
    \ Disease Diagnosis. Sensors\n2019, 19, 1564. [CrossRef] [PubMed]\n74.\nMazon-Olivo,\
    \ B.; Hernández-Rojas, D.; Maza-Salinas, J.; Pan, A. Rules Engine and Complex\
    \ Event Processor in the Context of\nInternet of Things for Precision Agriculture.\
    \ Comput. Electron. Agric. 2018, 154, 347–360. [CrossRef]\nSensors 2022, 22, 6436\n\
    28 of 28\n75.\nDa Costa Bezerra, S.; Filho, A.; Delicato, F.; da Rocha, A. Processing\
    \ Complex Events in Fog-Based Internet of Things Systems for\nSmart Agriculture.\
    \ Sensors 2021, 21, 7226. [CrossRef]\n76.\nFlouris, I.; Giatrakos, N.; Deligiannakis,\
    \ A.; Garofalakis, M.; Kamp, M.; Mock, M. Issues in Complex Event Processing:\
    \ Status and\nProspects in the Big Data Era. J. Syst. Softw. 2017,127, 217–236.\
    \ [CrossRef]\n"
  inline_citation: null
  journal: Sensors
  limitations: This paper primarily focuses on the design and implementation of the
    SEMAR IoT platform and its integration with a few specific IoT application systems.
    While the platform is designed to be flexible and extensible, its scalability
    and performance under large-scale deployment and handling a wider range of IoT
    applications may need further evaluation. Additionally, aspects related to security,
    privacy, and data protection have not been explicitly addressed in this paper.
    These aspects are crucial in IoT deployments and should be carefully considered
    in future work.
  pdf_link: https://www.mdpi.com/1424-8220/22/17/6436/pdf?version=1661833595
  publication_year: 2022
  relevance_score: 0.9
  relevance_score1: 0
  relevance_score2: 0
  title: Design and Implementation of SEMAR IoT Server Platform with Applications
  verbatim_quote1: '"The ﬁnal challenge involves the data interoperability between
    various IoT application systems within the same domain. It can be described as
    the integration of plural systems  by sharing output data through information
    networks. Thus, smart cities require collaboration and integration of various
    IoT application systems."'
  verbatim_quote2: '"However, in general, IoT application systems for smart cities
    have been designed without considering these challenges. They have been deployed
    independently and cannot  be integrated with other systems. "'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.3844/ajeassp.2022.230.238
  analysis: 'The paper presents the development of a digital twin architecture for
    a greenhouse setting, focusing on optimizing productivity and resource consumption.
    It emphasizes the need for data collection, processing, and analysis to inform
    decision-making and control strategies for climate and crop management. The paper
    also discusses the potential benefits of using simulation applications to model
    and optimize greenhouse conditions. Some key elements of the proposed architecture
    include sensors for data collection, a controller for data processing and communication,
    a portal for data storage, an intelligence layer for decision-making, and digital
    twins for simulating and optimizing greenhouse conditions.


    Relevance to the outline point regarding considerations for data volume, frequency,
    format, and source is moderate (0.6-0.69). While the paper mentions the importance
    of data collection for the digital twin architecture, it does not provide specific
    details or considerations for data volume, frequency, format, or source in the
    context of greenhouse management.


    **verbatim_quote1**: "The physical twin, for example, will contain some media
    (e.g., sensors) for data collection. Then the data are transferred to a corresponding
    processing system to be applied to the digital twin. This is used for the subsequent
    data in processing so that it is possible to study problems and performance issues
    to improve the physical object or system."


    **verbatim_quote2**: "The application of Digital Twins in production enables the
    user to decrease the downtime of the equipment and at the same time increase productivity"


    **verbatim_quote3**: "Digital Twin''s architecture development work to optimize
    productivity is conducted through the development of a controlled greenhouse environment."'
  authors:
  - Antreas Kantaros
  - Dimitrios Piromalis
  citation_count: 3
  full_citation: Setting up a Digital Twin Assisted Greenhouse Architecture
  full_text: ">\n \n \n© 2022 Antreas Kantaros and Dimitrios Piromalis. This open-access\
    \ article is distributed under a Creative Commons \nAttribution (CC-BY) 4.0 license.\
    \ \nAmerican Journal of Engineering and Applied Sciences \n \n \n \nReview \n\
    Setting up a Digital Twin Assisted Greenhouse Architecture \n \n1Antreas Kantaros\
    \ and 2Dimitrios Piromalis \n \n1Department of Industrial Design and Production\
    \ Engineering, University of West Attica, Greece \n2Department of Electrical and\
    \ Electronics Engineering, University of West Attica, Greece \n \nArticle history\
    \ \nReceived: 25-10-2022 \nRevised: 11-11-2022 \nAccepted: 11-11-2022 \n \nCorresponding\
    \ Author:  \nAntreas Kantaros \nDepartment of Industrial \nDesign and Production\
    \ \nEngineering, University of \nWest Attica, Greece \nEmail: akantaros@uniwa.gr\
    \ \nAbstract: The present article contains a study about utilizing the Digital\
    \ \nTwins concept in the field of contemporary agricultural production. Through\
    \ \nthis study, an exemplary architecture has been developed regarding the \n\
    conversion of a conventional greenhouse to a digital greenhouse. A digital \n\
    greenhouse modus operandi features a great number of advantages compared \nwith\
    \ the traditional workflow in a conventional greenhouse. The purpose of \nthe\
    \ work is to propose tools for assisting the possible reduction of the \nconsumption\
    \ of the used resources for the crops. This requires the application \nof automation\
    \ of tools for cultivation such as Controlled Environment \nAgriculture (CEA).\
    \ The article shows that the Digital Twins concept can \nimmensely contribute\
    \ towards controlling the agricultural environment and \nat the same time improve\
    \ performance and quality while reducing the \nconsumption of resources for a\
    \ variety of crops. The proposed workflow \nstarts by identifying the parameters\
    \ that need to be taken into account and \nfinally proposes several cyber and\
    \ physical tools for setting up a Digital Twin \nfor the case of a greenhouse.\
    \ The objective of this study was the development \nof a DT architecture that\
    \ would be able to optimize productivity in the context \nof CEA applications.\
    \ \n \nKeywords: Digital Twin, Cyber-Physical Systems, Simulation, Smart \nAgriculture,\
    \ Greenhouse, 4th Industrial Revolution \n \nIntroduction  \nCurrently, there\
    \ is a need to increase productivity and \nreduce the resources being consumed.\
    \ According to the \ndata and statistics, it is estimated that by 2050 the world\
    \ \npopulation will reach over 9.6 billion people. Today the \npopulation is estimated\
    \ at 7.9 billion according to the \nUN's average estimate. Agricultural production\
    \ must \nincrease food production compared to today to ensure the \nnutrition\
    \ demands of this population are met. However, \nthere are many obstacles to this\
    \ effort. Thus, arises the \nneed for applying new, state-of-the-art innovative\
    \ \ntechnologies in agricultural production systems. In this \ncontext, Digital\
    \ Twin (DT) technology comes to the \nforefront. DTs in agriculture can offer\
    \ productivity \noptimization by balancing production and resource \nconsumption\
    \ by using their prediction/forecasting ability. \nThis will be achieved through\
    \ the construction of a Digital \nTwin \narchitecture \nfor \nControlled \nEnvironment\
    \ \nAgriculture (CEA) which will optimize the following \ncrucial elements depicted\
    \ in Fig. 1. \nAccording to Asseng and Cowan calculations \n(Asseng et al., 2020;\
    \ Cowan et al., 2022), the wheat \nharvest using CEA is about 700±40 and 1940±230\
    \ \ntons/hectare/year \nwhereas \nit \nwas \nonly \n3.2 \ntons/hectare/year with\
    \ traditional open field harvest. In \naddition, according to Nicole's finding\
    \ (Nicole et al., \n2016), lettuce quality is improved by growing it in plant\
    \ \nfactories, and the improvement is observed both in the \ncolor and nutritive\
    \ value offered when consumed. \n \n \n \nFig. 1: Digital Twin architecture for\
    \ Controlled Environment \nAgriculture (CEA) \nAntreas Kantaros and Dimitrios\
    \ Piromalis / American Journal of Engineering and Applied Sciences 2022, 15 (4):\
    \ 230.238 \nDOI: 10.3844/ajeassp.2022.230.238 \n \n231 \nHowever, the aforementioned\
    \ optimization procedure \nhas certain drawbacks. As the applied automation percentage\
    \ \nincreases, energy consumption increases as well, elevating \noperating costs.\
    \ Graamans et al. (2018), found that by \ncomparing the production of 1 kg of\
    \ lettuce in a greenhouse \nor plant, 70, 111, 182, and 211 kWh are required in\
    \ \ngreenhouses and 247 kWh in plants in the Netherlands, while \nin the United\
    \ Arab Emirates and Swe-den energy \nconsumption is twice as high as in the Netherlands\
    \ (in terms \nof building total energy). These data came from the study of \n\
    2 greenhouses in Sweden, one with additional artificial \nlighting and the other\
    \ without. Based on the above data, it is \nobvious that the production benefits\
    \ come into conflict with \nthe energy consumption that creates a need for optimized\
    \ \nchoices in applying CEA systems. This is where Digital \nTwin technology can\
    \ offer a potential solution. According to \nKritzinger et al. (2018); Negri et\
    \ al. (2017), DT \"utilizes \nsensible data, mathematical models and real-time\
    \ data \nprocessing to predict and optimize physical asset behavior in \neach\
    \ phase of the life cycle, in real-time.\" \nDigital Twins \nDigital twins are\
    \ virtual representations of real-time \ndata on an object or system using simulations,\
    \ engineer \nlearning, and logical reasoning to aid in decision-making \n(Piromalis\
    \ and Kantaros, 2022; Kantaros et al., 2021; \nTsaramirsis et al., 2022; Singh\
    \ et al., 2021). The operation \nof the Digital Twin is achieved through the precise\
    \ \nrepresentation of a physical object through the designed \nvirtual model.\
    \ The physical twin, for example, will \ncontain some media (e.g., sensors) for\
    \ data collection. \nThen the data are transferred to a corresponding \nprocessing\
    \ system to be applied to the digital twin. This is \nused for the subsequent\
    \ data in processing so that it is \npossible to study problems and performance\
    \ issues to \nimprove the physical object or system. Mainly the data are \ncollected\
    \ to re-apply the corresponding actions to be done \non the original physical\
    \ object. The application of Digital \nTwins in production enables the user to\
    \ decrease the \ndowntime of the equipment and at the same time increase \nproductivity\
    \ (Tao et al., 2019; Parrott and Warshaw, \n2017; Erol et al., 2020; Barricelli\
    \ et al., 2019; Liu et al., \n2021; He and Bai, 2021). \nAt the highest level,\
    \ a digital twin is an architectural \ncompilation powered by a combination of\
    \ cutting-edge \ntechnologies such as IoT (Internet of Things), Cloud \nComputing,\
    \ Edge Computing, Fog Computing, Artificial \nIntelligence, Robotics, Machine\
    \ Learning, and Big Data \nAnalytics. A Digital Twin is designed by collecting\
    \ data and \ncreating computational models for testing. This may include \nan\
    \ interface between the digital model and a real physical \nobject for sending\
    \ and receiving real-time feedback and data. \nBy combining all the necessary\
    \ digital technologies in a \ncoherent platform, a virtual representation of agricultural\
    \ \nproduction will be created consisting of natural elements, \nprocesses, systems,\
    \ resources, etc., (Lu et al., 2020; \nGrieves, 2016; Batty, 2018; Markets and\
    \ Markets, 2020; \nTao et al., 2019). \nSimulation Applications for Agriculture\
    \ \nIn agricultural production, the fundamental resources \nthat determine crop\
    \ production are water, nitrogen, \nenergy, and crop disease-tackling measures.\
    \ In addition, \ndata such as weather, soil characteristics, field hydrology,\
    \ \ncrop characteristics, sowing, and other factors should also \nbe taken into\
    \ account. For the compilation of a Digital Twin \nin agriculture and specifically\
    \ for a greenhouse, simulation \napplications are needed for the digital display\
    \ of the \ngreenhouse. Simulation applications use tailored models for \nbetter\
    \ management of specific physical object parameters to \nmake the best possible\
    \ production decisions. \nIn this context, applications from the literature were\
    \ \nsought that will offer improvement in the way crops are \nmanaged and in monitoring\
    \ the condition of crops, and for \nthe reduction of crop treatments. A crucial\
    \ factor that \nconcerns all growers is the consumption of resources. The \nconsumption\
    \ of resources used for plant production is high \nwater consumption, heating,\
    \ and ventilation. The goal of \ngrowers is to reduce this consumption as much\
    \ as possible. \nTable 1 depicts some suggested applications/systems \nfor the\
    \ Digital Twin Greenhouse that can help manage \nenergy, water, and crop health.\
    \  \nEnergy Plus \nEnergy Plus is a simulation application for engineers, \narchitects,\
    \ and researchers designed to model energy i.e., \nenergy such as heating, cooling,\
    \ ventilation, lighting, and \npower receivers during loading, and also model\
    \ the use of \nwater. Energy Plus applies detailed building physics to the \n\
    transfer of air, moisture, and heat, including radiation transfer \nand heat (convection\
    \ and conduction) transfer separately to \nsupport the modeling of radiation systems\
    \ and the calculation \nof thermal comfort measurements. It calculates light,\
    \ shading, \nand visual comfort measurements. Flexible configuration \nis supported\
    \ at the level of HVAC system components, \ninstallation cooling, and heating\
    \ as well as including a \nlarge set of HVAC component models and installations.\
    \ It \nsimulates hourly time steps to quickly manipulate system \ndynamics and\
    \ control strategies and has a programmed \nexternal interface for modeling control\
    \ sequences and \ninterfacing with other analyzes (Energy Plus, 2022). \n \nTable\
    \ 1: Greenhouse Digital Twins applications/systems \nGreenhouse digital twins’\
    \ applications/systems \nEnergy Plus \nTRNSYS \nDSSAT (decision support system\
    \ for agrotechnology transfer) \nCropX \n \nClimate Field View \nAPSIM \nCropSyst\
    \ \nAntreas Kantaros and Dimitrios Piromalis / American Journal of Engineering\
    \ and Applied Sciences 2022, 15 (4): 230.238 \nDOI: 10.3844/ajeassp.2022.230.238\
    \ \n \n232 \nTRNSYS \nTRNSYS offers a flexible graphical-based software \nenvironment,\
    \ used to simulate the behavior of transient \nsystems. It offers, like other\
    \ similar systems, evaluation of \nthe efficiency of thermal and electrical systems,\
    \ but also can \nbe used for modeling other dynamic systems, such as the \nflow\
    \ circulation or biological processes. TRNSYS consists \nof two parts. The first\
    \ is a Camera (called a kernel) that reads \nand processes the input file, repeatedly\
    \ solves the system, \ndetermines convergence, and plots the system variables.\
    \ The \nkernel also provides utilities that (among other things) \ndetermine the\
    \ thermophysical properties, invert arrays, \nperform linear regressions and interrupt\
    \ external data files. \nThe second part of TRNSYS is an extensive data library,\
    \ \nwhich models the performance of one part of the system. \nThe application\
    \ library offers approximately 150 models \nranging from pumps to multi-zone buildings,\
    \ wind \nturbines to electrolytes, weather data processors to \neconomical routines,\
    \ and basic HVAC equipment to \nemerging cutting-edge technologies (TRNSYS, 2022).\
    \ \nDSSAT (Decision Support System for \nAgrotechnology Transfer) \nThe Rural\
    \ Technology Transfer Decision Support \nSystem (DSSAT) is an application that\
    \ offers crop \nsimulation models and tools for their more efficient use. The\
    \ \ntools offer database management for soil, weather, crop \nmanagement, experimental\
    \ data, utilities, and application \nprograms. Application models simulate growth\
    \ and yield as \na function of soil-plant-atmosphere dynamics. Includes farm \n\
    management and accuracy, regional assessments of the \nimpact of climate variability\
    \ and climate change, genetic \nmodeling and reproduction selection, water use,\
    \ greenhouse \ngas emissions, and long-term viability through soil organic \n\
    carbon and nitrogen balances. Crop models require daily \nweather data, soil surface,\
    \ and profile information, and \ndetailed crop management as data. At the end\
    \ of each day, \nthe water, nitrogen, phosphorus, and carbon balances of the \n\
    plants and the soil are updated, as well as the stage of \ngermination and reproductive\
    \ development of the crop. For \napplications, DSSAT combines crop, soil, and\
    \ weather \ndatabases with crop models and implementation programs \nto simulate\
    \ multiannual results of crop management \nstrategies (DSSAT, 2022). \nCropX \n\
    CropX application is a system that offers automation and \ncrop management with\
    \ advanced analysis technologies for \nagriculture. The system offers management\
    \ of irrigation, and \nfertilization with accurate forecasts, offering the best\
    \ possible \nresult. It processes data from the soil for an even better \npicture\
    \ of the crop and the atmosphere that surrounds the \ncrop. Thus, the system will\
    \ be able to adapt the strategies of \noptimal cultivation. It then offers an\
    \ adapted variable rate \nirrigation system based on changing soil and weather\
    \ \nconditions. It constantly adapts the specific needs of the crop \nto its development\
    \ stage (CropX, 2022). \nClimate Field View \nThe Climate Field View application\
    \ helps in making \ndecisions from crop data to maximize the yield of each \n\
    cultivated acre. The system collects, stores, and visualizes \ncritical data.\
    \ In this way, it will be possible to monitor and \nmeasure the decisions made\
    \ regarding the cultivation to \nimprove the yield and maximize the profit (Climate\
    \ Field \nView, 2022). \nAPSIM \nThe \nAgricultural \nProduction \nSystems \n\
    Simulator \n(APSIM) is internationally recognized as an extremely \nadvanced platform\
    \ for modeling and simulation of systems \ncontaining a platform that enables\
    \ the simulation of systems \nwith a variety of plant, animal, soil, climate,\
    \ and management \ninteractions. APSIM is constantly evolving, with new features\
    \ \nbeing added to APSIM Next Generation. Its development and \nmaintenance are\
    \ based on strict standards of software science \nand engineering (APSIM, 2022).\
    \ \nCropSyst \nCropSyst is a multi-year multi-crop crop simulation \nmodel developed\
    \ by a team at the Department of Biological \nSystems Engineering at Washington\
    \ State University. The \nmodel is used to study the impact of pruning system\
    \ \nmanagement on productivity (Stöckle et al., 2003). \nDigital Twin Architecture\
    \ Design and Compilation \nfor a Greenhouse \nDigital Twin's architecture development\
    \ work to \noptimize productivity is conducted through the development \nof a\
    \ controlled greenhouse environment. A greenhouse is an \nenclosed space, covered\
    \ with a permeable (transparent or \nopaque) material, which allows sunlight to\
    \ enter to heat the \ngreenhouse during the day. In general, a greenhouse is \n\
    necessary for the modification of climatic conditions internally \nin contrast\
    \ to the external environment, to plant plants, and \nproduction of plant products\
    \ regardless of the external \nclimatic conditions. In case of an unwanted temperature\
    \ rise, \nventilation is necessary, while for cold nights or days, a \nheating\
    \ system is necessary to maintain the desired \ntemperature for plant growth (Howard\
    \ et al., 2021;         \nVerdouw et al., 2021; Pylianidis et al., 2021; Tekinerdogan\
    \ \nand Verdouw, 2020; Monteiro et al., 2018; Howard et al., \n2020a; Mukhtar\
    \ et al., 2022; Borowski, 2021; Howard et al., \n2020b; Yang et al., 2022). The\
    \ necessary prerequisites for the \ncreation of a greenhouse are depicted in Fig.\
    \ 2. \nThe additional equipment required consists of the \nautomation infrastructure\
    \ elements of the greenhouse which \nAntreas Kantaros and Dimitrios Piromalis\
    \ / American Journal of Engineering and Applied Sciences 2022, 15 (4): 230.238\
    \ \nDOI: 10.3844/ajeassp.2022.230.238 \n \n233 \ninclude systems of heating, ventilation,\
    \ humidity, automatic \ncontrol of the climatic conditions, and irrigation. \n\
    Construction of DT \nFor the proper compilation of the architecture for \ncreating\
    \ a greenhouse DT, the following elements \ndepicted in Fig. 3 must be included.\
    \ \nIn this context, Chaux's methodology based on virtual \nsimulation technology\
    \ is used for indicative development \nof the DT greenhouse architecture (Chaux\
    \ et al., 2021; \nTraoré, 2021). It proposes a strategy to modernize production\
    \ \nwith DT systems including the following elements depicted \nin Table 2. According\
    \ to Chaux’s methodology, ’The data \nnecessary for the optimization must be available\
    \ in the \ncloud and the user must download them in his/her local \ndevice. The\
    \ optimization occurs in the local device and \nthe optimal crop treatment and\
    \ climate control strategy \nare communicated to the controller for its implementation\
    \ \nthrough a gateway (Chaux et al., 2021). \nFramework. \nThis stage includes\
    \ the design of subsequent stages \nin which the developing architecture will\
    \ operate with \nspecific functions' definitions. This categorization \nincludes\
    \ the following parts with corresponding \nfunctions, i.e.: \n \n1. Greenhouse\
    \ \n \nA natural element that needs the help of DT to \noptimize production and\
    \ where after the training the \nselected strategies will be verified. \n \n2.\
    \ Controller \n \nIt is a set of measuring instrument layers, actuators, \nsensors,\
    \ monitors, and controllers for the greenhouse. \nWhich are important for the\
    \ collection of data to be used \nin DT. Then the controller exchanges data with\
    \ the \nnetwork portal to make the corresponding appropriate \ndecisions for the\
    \ crop. \n \n3. Portal \n \nIt is the software that will be used for the connection\
    \ \nbetween different network environments, i.e., at work, it \nis the connection\
    \ between the physical and digital \ncomponents. Its function is to transfer data\
    \ to storage for \nlater use. \n \n4. Storage \n \nThe data used by the simulation\
    \ (current and \nhistorical) requires space to be stored as well as for \ndecisions\
    \ made. So that the data can be processed at any \ntime and there is a record\
    \ of successful decisions to be used \nin the physical element. It is a very important\
    \ part of DT tests. \n \n5. Intelligence Layer \n \nThe Intelligence Layer organizes\
    \ and provides smart \nservices. It is the main element used to direct the service.\
    \ \nIt is responsible for the evaluation and then the selection \nof the best\
    \ strategy. \n \n6. Digital Twin (1) \n \nOne of the recommended or equivalent\
    \ simulation \napplications to control power consumption resources. \n \n7. Digital\
    \ Twin (2) \n \nOne of the recommended or equivalent simulation \napps for controlling\
    \ atmospheric conditions and selecting \ncase-specific treatments. \n \n \n \n\
    Fig. 2: Necessary prerequisites for the creation of a greenhouse \n \n \n \nFig.\
    \ 3: Elements comprising the architecture set-up of a Digital \nTwin for a greenhouse\n\
    Antreas Kantaros and Dimitrios Piromalis / American Journal of Engineering and\
    \ Applied Sciences 2022, 15 (4): 230.238 \nDOI: 10.3844/ajeassp.2022.230.238 \n\
    \ \n234 \nTable 2: Development stages of a DT greenhouse architecture \n \n \n\
    \ \n \nPhysical-Cyber \nFramework:  \nTechnologies: \nDigital Twin: \nIntelligence\
    \ Layer: \nInterface: \nImplementation: \nIt is the framework on \nThe point where\
    \ \nThe Use of selected \nThis part is the \nHere is the part of \nUpon completing\
    \ all the \nwhich the entire DT \nthe non-structural \nsimulation \nlevel of intelligence\
    \ \nthe interaction and \nstages, the elaboration \nthe architecture will be elements\
    \ of the \nto develop and \nwhose main function data transmission \nand application\
    \ of the \nbased. An initial \nframework- planned \nuse of software and \nto compare\
    \  \nthe physical \narchitecture is applied, \ntheoretical multilevel \nare implemented,\
    \ \nmodels to optimize \napplied strategies \nand digital element, \nwhich is\
    \ applied to the \nstructure with functions applying the technologies \nto the\
    \ physical \n and choose the  \nit as also a responsible physical element for\
    \ \nthe mode of \nnecessary for operation \nelement \nbest one. It interacts \n\
    for determining the  \nverification \nOperation of the  \nof the DT and the way\
    \  \n \nwith the applied  \nway of interaction \ndesigned DT \nin which they will\
    \ interact \n \ntechnologies of  \n \n \n \nthe system \n \nTechnologies \n \n\
    • \nGreenhouse \n \nFor the collection of data from the physical element, \nsensors\
    \ are needed to receive inside and outside \ntemperature, humidity, and automatic\
    \ mechanisms that \nbased on the desired temperature and humidity will \nself-excite\
    \ (regulate). \n \n• \nController \n \nThe Arduino Uno Microcontroller can be\
    \ used as a \ncontroller. \n \n• \nPortal \n \nThe portal is used for communication\
    \ between the \ncontroller and storage. Communication can be either \nwireless\
    \ or serial. \n \n• \nStorage \n \nStorage of all data requires cloud storage\
    \ which can \nhost the data for example a database. i.e., the MySQL \nDatabase,\
    \ specifically the phpMyAdmin. \n \n• \nIntelligence Layer \n \nAn operating system\
    \ to store, and connect with \ninformation such as data and financial aspects\
    \ `to achieve \ncommunication between the level of intelligence and the DT. \n\
    \ \n• \nDigital Twin (1) \n \nOne of the recommended or equivalent simulation\
    \ \napplications to control power consumption resources. \n \n• \nDigital Twin\
    \ (2) \n \nOne of the recommended or equivalent simulation \napps for controlling\
    \ atmospheric conditions and selecting \ncase-specific treatments. \nIntelligence\
    \ Layer \nThe control and automation of agricultural production \nand in particular\
    \ of a green-house consisting of distinct \nworkflows. By properly defining the\
    \ workflow sequence, \nthe categorization of actions and their position in the\
    \ value \nchain from farm to consumer can be achieved, which will \nbe the optimization\
    \ of productivity. \nWorkflow Optimization \n \n1. Climate conditions data flow:\
    \ At the intelligence \nlevel, all data comes from the database, i.e., database\
    \ \ncloud, which must be sent for processing to be used \nto create improvement\
    \ strategies, as follows: \n \n• \nData on the atmospheric conditions of the \n\
    Climate inside the greenhouse which are \ntemperature, relative humidity, solar\
    \ gain/loss, \nand outdoor air speed \n• \nData on the atmospheric conditions\
    \ of the \nClimate outside the greenhouse which are \ntemperature and relative\
    \ humidity \n• \nAll data on the previous cultivation conditions \n(atmospheric\
    \ conditions and treatments) \n \n2. Climate conditions: The level of intelligence\
    \ through \nthe evaluation of the sent data and predicted data \ntransfers to\
    \ the software \n3. Data therapy cultivation data: The level of \nintelligence\
    \ \nreceives \nthe \npredicted \nenergy \nconsumption data and atmospheric data\
    \ to produce \nappropriate suitable conditions for the necessary \napplication\
    \ of therapies \n4. Crop treatments: Where the level of intelligence \nthrough\
    \ the evaluation of the sent data and predicted \ndata transfers them to the software\
    \ for the selection \nof appropriate treatments \n5. \nCompletion of the data\
    \ flow: After all possible \ncultivation conditions have been obtained and tested,\
    \ the \nbest cultivation conditions are selected and applied with \nas little\
    \ resource consumption as possible. It is the final \nstage where the final optimization\
    \ is achieved \n \nFigure 4 depicts a flowchart of the aforementioned \nsteps\
    \ regarding workflow optimization. \nAntreas Kantaros and Dimitrios Piromalis\
    \ / American Journal of Engineering and Applied Sciences 2022, 15 (4): 230.238\
    \ \nDOI: 10.3844/ajeassp.2022.230.238 \n \n235 \n \n \nFig. 4: Workflow optimization\
    \ sequence \n \nPhysical-Cyber Interface \nThe interaction of the cyber-physical\
    \ and physical \nsystem is an intelligent system, is a computer system \nthrough\
    \ which the mechanism developed by computer-\nbased algorithms is applied. Physical\
    \ data is collected and \ncomputer components are integrated to operate a process\
    \ \nsafely and efficiently. CPS grasps the majority of \nbeneficial elements that\
    \ the Internet of Things (IoT) can \noffer, in its basic architecture. Thus, CPS\
    \ can achieve a \nhigh combination and coordination between physical and \ncomputational\
    \ components. \nAfter defining the workflow, its operation consists of \nthe following:\
    \ \n \n• \nThe controller-level data received is transmitted \nthrough the network\
    \ gateway continuously to the \nstorage level \n• \nIn case of success of the\
    \ strategic optimization, the \ncorresponding data is sent to the local device,\
    \ i.e., to \nthe controller, so that the stream of optimization tasks \ncan be\
    \ applied at the level of intelligence \n \nImplementation \nIn this stage, all\
    \ the aforementioned steps are \nimplemented, including the actual coding compilation\
    \ and its \napplication i.e., in the Arduino microcontroller and a \nplatform\
    \ such as Node-RED (Node-RED, 2022). Node-RED \nis a programming tool for combining\
    \ hardware devices, APIs \n(Application Programming Interface), and online services\
    \ \nfor such purposes. In this context, it provides a browser-\nbased editor that\
    \ enables the simultaneous wiring of program \nflows using a wide range of nodes\
    \ in the offered palette that \ncan be deployed in a single click. \nConclusion\
    \ \nAgricultural production systems should innovate \ntowards increasing production\
    \ while utilizing fewer \nresources to assure food security. Digital twins and\
    \ \ncontrolled environment agriculture may prove to be \nessential mechanisms\
    \ for maximizing output and ensuring \nthe world's food security.  \nThe present\
    \ work presents a step-by-step approach to the \ndevelopment of architecture regarding\
    \ a Digital Twin-\nassisted controlled greenhouse. The goal was achieved by \n\
    creating an architecture that makes use of simulation \nsoftware (such as DTs)\
    \ and allows for the optimization of \nclimate control techniques connected to\
    \ crop microclimate \ncontrol. The proposed tools and actions show that it is\
    \ \npossible to implement such a practice in an already existing \ngreenhouse.\
    \ Achieving a controlled environment in \nagriculture with the help of Digital\
    \ Twins can be considered \nan essential tool to achieve productivity optimization\
    \ to \nreduce the consumption of resources as well as to immensely \ncontribute\
    \ towards the seamless food supply of the planet \n(Symeonaki et al., 2021a; 2021b;\
    \ 2019a,b; Aversa et al., \n2016a,b; Petrescu and Petrescu, 2019; Petrescu et\
    \ al., 2017). \nSuch practices propose a new innovative approach for \nvertical\
    \ integration and optimization of greenhouse \nprocesses to achieve elevated energy\
    \ efficiency and \nproduction outputs without compromising the quality of \nthe\
    \ offered products or sustainability. In this context, the \ndeveloped Digital\
    \ Twins will be able to forecast how the \nphysical twin will perform under constantly\
    \ changing \noperational conditions.  \nFuture work can be identified as the proposed\
    \ \narchitecture's constant evolution due to the introduction of \nnew software\
    \ and hardware tools that will allow swifter \ndevelopment and integration of\
    \ such practices. In this \ncontext, to confirm the capacity of the suggested\
    \ DT \narchitecture to maximize productivity, a case study must be \nimplemented\
    \ to validate the productivity increase. \nAntreas Kantaros and Dimitrios Piromalis\
    \ / American Journal of Engineering and Applied Sciences 2022, 15 (4): 230.238\
    \ \nDOI: 10.3844/ajeassp.2022.230.238 \n \n236 \nFunding Information \nThis study\
    \ did not receive any funding.  \nAuthor’s Contributions \nAntreas Kantaros: Writing,\
    \ edited. \nDimitrios Piromalis: Conceptualization, edited. \nEthics \nThere is\
    \ no ethical concern, to the knowledge of the \nauthors, that arises from the\
    \ present work. \nReferences \nAPSIM. (2022). https://www.apsim.info/ \nAsseng,\
    \ S., Guarin, J. R., Raman, M., Monje, O., Kiss, G., \nDespommier, D. D., ...\
    \ & Gauthier, P. P. (2020). \nWheat yield potential in controlled-environment\
    \ \nvertical farms. Proceedings of the National Academy \nof Sciences, 117(32),\
    \ 19131-19135. \n \nhttps://doi.org/10.1073/pnas.2002655117 \nAversa, R., Petrescu,\
    \ R. V., Petrescu, F. I., & Apicella, A. \n(2016a). Smart-factory: Optimization\
    \ and process \ncontrol of composite centrifuged pipes. American \nJournal of\
    \ Applied Sciences, 13(11), 1330-1341. \nhttps://papers.ssrn.com/sol3/papers.cfm?abstract_id\n\
    =3075399 \nAversa, R., Petrescu, R. V., Petrescu, F. I., & Apicella, A. \n(2016b).\
    \ Biomimetic and evolutionary design-driven \ninnovation in sustainable products\
    \ development. \nAmerican Journal of Engineering and Applied \nSciences, 9(4).\
    \ \nhttps://papers.ssrn.com/sol3/papers.cfm?abstract_id\n=3074457 \nBarricelli,\
    \ B. R., Casiraghi, E., & Fogli, D. (2019). A \nsurvey on digital twin: Definitions,\
    \ characteristics, \napplications, \nand \ndesign \nimplications. \nIEEE \nAccess,\
    \ 7, 167653-167671. \n \nhttps://doi.org/10.1109/ACCESS.2019.2953499 \nBatty,\
    \ M. (2018). Digital twins. Environment and Planning \nB: Urban Analytics and\
    \ City Science, 45(5), 817-820. \nhttps://doi.org/10.1177/2399808318796416 \n\
    Borowski, P. F. (2021). Digitization, digital twins, \nblockchain, and industry\
    \ 4.0 as elements of \nmanagement process in enterprises in the energy sector.\
    \ \nEnergies, 14(7), 1885. \n \nhttps://doi.org/10.3390/en14071885 \nChaux, J.\
    \ D., Sanchez-Londono, D., & Barbieri, G. \n(2021). A digital twin architecture\
    \ to optimize \nproductivity \nwithin \ncontrolled \nenvironment \nagriculture.\
    \ Applied Sciences, 11(19), 8875. \n \nhttps://doi.org/10.3390/app11198875 \n\
    Climate Field View. (2022). https://climate.com/ \nCowan, N., Ferrier, L., Spears,\
    \ B., Drewer, J., Reay, D., & \nSkiba, U. (2022). CEA systems: The means to achieve\
    \ \nfuture \nfood \nsecurity \nand \nenvironmental \nsustainability? Frontiers\
    \ in Sustainable Food Systems, \n6, 891256. https://doi.org/10.3389/fsufs.2022.891256\
    \ \nCropX. (2022). https://cropx.com/ \nDSSAT. (2022) https://dssat.net/ \nEnergy\
    \ Plus. (2022). https://energyplus.net/ \nErol, T., Mendi, A. F., & Doğan, D.\
    \ (2020, October). Digital \ntransformation revolution with digital twin technology.\
    \ \nIn 2020 \n4th \ninternational \nsymposium \non \nmultidisciplinary studies\
    \ and innovative technologies \n(ISMSIT) (pp. 1-7). IEEE. \n \nhttps://ieeexplore.ieee.org/abstract/document/9254288\
    \ \nGraamans, L., Baeza, E., Van Den Dobbelsteen, A., \nTsafaras, I., & Stanghellini,\
    \ C. (2018). Plant factories \nversus greenhouses: Comparison of resource use\
    \ \nefficiency. Agricultural \nSystems, 160, \n31-43. \nhttps://doi.org/10.1016/j.agsy.2017.11.003\
    \ \nGrieves, M. (2016). Origins of the Digital Twin \nConcept. 2016. \n \nhttps://www.researchgate.net/publication/30750972\n\
    7_Origins_of_the_Digital_Twin_Concept \nHe, B., & Bai, K. J. (2021). Digital twin-based\
    \ sustainable \nintelligent manufacturing: A review. Advances in \nManufacturing,\
    \ 9(1), 1-21. \n \nhttps://doi.org/10.1007/s40436-020-00302-5 \nHoward, D. A.,\
    \ Ma, Z., & Jørgensen, B. N. (2020a, June). \nDigital Twin Framework for Energy\
    \ Efficient \nGreenhouse \nIndustry \n4.0. \nIn International \nSymposium on Ambient\
    \ Intelligence (pp. 293-297). \nSpringer, Cham. https://doi.org/10.1007/978-3-030-\n\
    58356-9_34 \nHoward, D. A., Ma, Z., Aaslyng, J. M., & Jørgensen, B. \nN. (2020b,\
    \ October). Data architecture for digital twin \nof commercial greenhouse production.\
    \ In 2020 RIVF \nInternational \nConference \non \nComputing \nand \nCommunication\
    \ Technologies (RIVF) (pp. 1-7). IEEE. \nhttps://doi.org/10.1109/RIVF48685.2020.9140726\
    \ \nHoward, D. A., Ma, Z., Veje, C., Clausen, A., Aaslyng, J. \nM., & Jørgensen,\
    \ B. N. (2021). Greenhouse industry \n4.0–digital \ntwin \ntechnology \nfor \n\
    commercial \ngreenhouses. Energy Informatics, 4(2), 1-13. \n \nhttps://doi.org/10.1186/s42162-021-00161-9\
    \ \nKantaros, A., Piromalis, D., Tsaramirsis, G., Papageorgas, \nP., & Tamimi,\
    \ H. (2021). 3D printing and \nimplementation of digital twins: Current trends\
    \ and \nlimitations. Applied System Innovation, 5(1), 7. \nhttps://doi.org/10.3390/asi5010007\
    \  \nKritzinger, W., Karner, M., Traar, G., Henjes, J., & Sihn, \nW. (2018). Digital\
    \ Twin in manufacturing: A \ncategorical literature review and classification.\
    \ \nIFAC-PapersOnLine, 51(11), 1016-1022. \n \nhttps://doi.org/10.1016/j.ifacol.2018.08.474\
    \ \nAntreas Kantaros and Dimitrios Piromalis / American Journal of Engineering\
    \ and Applied Sciences 2022, 15 (4): 230.238 \nDOI: 10.3844/ajeassp.2022.230.238\
    \ \n \n237 \nLiu, M., Fang, S., Dong, H., & Xu, C. (2021). Review \nof digital\
    \ twin about concepts, technologies, and \nindustrial applications. Journal of\
    \ Manufacturing \nSystems, 58, 346-361. \n \nhttps://doi.org/10.1016/j.jmsy.2020.06.017\
    \ \nLu, Y., Liu, C., Kevin, I., Wang, K., Huang, H., & Xu, X. \n(2020). Digital\
    \ Twin-driven smart manufacturing: \nConnotation, reference model, applications\
    \ and \nresearch issues. Robotics and Computer-Integrated \nManufacturing, 61,\
    \ 101837. \n \nhttps://doi.org/10.1016/j.rcim.2019.101837 \nMarkets & Markets.\
    \ (2020). Digital Twin Market by \nTechnology, Type (Product, Process, and System),\
    \ \nApplication (Predictive Maintenance and Others), \nIndustry (Aerospace & Defense,\
    \ Automotive & \nTransportation, \nHealthcare, \nand \nothers), \nand \nGeography—Global\
    \ Forecast to 2026; Markets and \nMarkets: Pune, India, 2020; p. 177. \nMonteiro,\
    \ J., Barata, J., Veloso, M., Veloso, L., & Nunes, \nJ. (2018, September). Towards\
    \ sustainable digital \ntwins for vertical farming. In 2018 Thirteenth \nInternational\
    \ Conference on Digital Information \nManagement \n(ICDIM) (pp. \n234-239). \n\
    IEEE. \nhttps://doi.org/10.1109/ICDIM.2018.8847169 \nMukhtar, H., Wunderlich,\
    \ R. F., & Lin, Y. P. (2022). \nDigital Twins of the Soil Microbiome for Climate\
    \ \nMitigation. Environments, 9(3), 34. \n \nhttps://doi.org/10.3390/environments9030034\
    \ \nNegri, E., Fumagalli, L., & Macchi, M. (2017). A review of \nthe roles of\
    \ the digital twin in CPS-based production \nsystems. \nProcedia \nManufacturing,\
    \ 11, \n939-948. \nhttps://doi.org/10.1016/j.promfg.2017.07.198 \nNicole, C. C.\
    \ S., Charalambous, F., Martinakos, S., Van \nDe Voort, S., Li, Z., Verhoog, M.,\
    \ & Krijn, M. (2016, \nMay). Lettuce growth and quality optimization in a \nplant\
    \ factory. In VIII International Symposium on \nLight \nin \nHorticulture \n1134\
    \ (pp. \n231-238). \nhttps://doi.org/10.17660/ActaHortic.2016.1134.31 \nNode-RED.\
    \ (2022). https://nodered.org/ \nParrott, A., & Warshaw, L. (2017). Industry 4.0\
    \ and the \ndigital twin. Deloitte Insights. \nPetrescu, N., & Petrescu, F. I.\
    \ (2019). Energy Sources \nToday. Energy Research Journal. \n \nhttps://papers.ssrn.com/sol3/papers.cfm?abstract_id\n\
    =3460767 \nPetrescu, R. V., Aversa, R., & Florian, I. (2017). \nPermanent \ngreen\
    \ \nenergy \nproduction \nttp://www.altenergymag.com/article/2017/04/perma\nnent-green-energy-production/25973\
    \ \nPiromalis, D., & Kantaros, A. (2022). Digital Twins in the \nAutomotive Industry:\
    \ The Road toward Physical-\nDigital Convergence. Applied System Innovation, \n\
    5(4), 65. https://doi.org/10.3390/asi5040065 \nPylianidis, C., Osinga, S., & Athanasiadis,\
    \ I. N. (2021). \nIntroducing digital twins to agriculture. Computers \nand \n\
    Electronics \nin \nAgriculture, 184, 105942. \nhttps://doi.org/10.1016/j.compag.2020.105942\
    \ \nSingh, M., Fuenmayor, E., Hinchy, E. P., Qiao, Y., \nMurray, N., & Devine,\
    \ D. (2021). Digital twin: \nOrigin to future. Applied System Innovation, 4(2),\
    \ 36. \nhttps://doi.org/10.3390/asi4020036 \nStöckle, C. O., Donatelli, M., &\
    \ Nelson, R. (2003). CropSyst, \na cropping systems simulation model European\
    \ J. \nhttps://doi.org/10.1016/S1161-0301(02)00109-0 \nSymeonaki, E. G., Arvanitis,\
    \ K. G., & Piromalis, D. D. \n(2019a). Current trends and challenges in the \n\
    deployment of IoT technologies for climate-smart \nfacility agriculture. International\
    \ Journal of Sustainable \nAgricultural Management and Informatics, 5(2-3), \n\
    181-200. https://doi.org/10.1504/IJSAMI.2019.101673 \nSymeonaki, E., Arvanitis,\
    \ K. G., Loukatos, D., & \nPiromalis, D. (2021a). Enabling IoT wireless \ntechnologies\
    \ in sustainable livestock farming toward \nagriculture 4.0. In IoT-based Intelligent\
    \ Modelling \nfor Environmental and Ecological Engineering (pp. \n213-232). Springer,\
    \ Cham. \n \nhttps://doi.org/10.1007/978-3-030-71172-6_9 \nSymeonaki, E., Arvanitis,\
    \ K., Papageorgas, P., & \nPiromalis, D. (2021b). AI-Based Chatbot System \nIntegration\
    \ to a Social Media Platform for \nControlling IoT Devices in Smart Agriculture\
    \ \nFacilities. \nIn Information \nand \nCommunication \nTechnologies \nfor \n\
    Agriculture—Theme \nIV: \nActions (pp. \n193-209). \nSpringer, \nCham. \nhttps://doi.org/10.1007/978-3-030-84156-0_10\
    \ \nSymeonaki, E., Arvanitis, K., Piromalis, D., & \nPapoutsidakis, \nM. \n(2019b,\
    \ \nSeptember). \nConversational \nUser \nInterface \nIntegration \nin \nControlling\
    \ \nIoT \nDevices \nApplied \nto \nSmart \nAgriculture: Analysis of a Chatbot\
    \ System Design. \nIn Proceedings \nof \nSAI \nIntelligent \nSystems \nConference\
    \ (pp. \n1071-1088). \nSpringer, \nCham. \nhttps://doi.org/10.1007/978-3-030-29516-5_80\
    \ \nTao, F., Zhang, M., & Nee, A. Y. C. (2019). Digital twin-\ndriven smart manufacturing.\
    \ Academic Press.  \nTekinerdogan, B., & Verdouw, C. (2020). Systems \narchitecture\
    \ design pattern catalog for developing \ndigital twins. Sensors, 20(18), 5103.\
    \ \n \nhttps://doi.org/10.3390/s20185103 \nTraoré, M. K. (2021). Unifying Digital\
    \ Twin framework: \nSimulation-based \nproof-of-concept. IFAC-Papers \nOnline,\
    \ 54(1), 886-893. \n \nhttps://doi.org/10.1016/j.ifacol.2021.08.105 \nTRNSYS.\
    \ (2022). https://www.trnsys.com/ \nAntreas Kantaros and Dimitrios Piromalis /\
    \ American Journal of Engineering and Applied Sciences 2022, 15 (4): 230.238 \n\
    DOI: 10.3844/ajeassp.2022.230.238 \n \n238 \nTsaramirsis, G., Kantaros, A., Al-Darraji,\
    \ I., Piromalis, \nD., Apostolopoulos, C., Pavlopoulou, A., ... & Khan, \nF. Q.\
    \ (2022). A modern approach towards an industry \n4.0 \nmodel: \nFrom \ndriving\
    \ \ntechnologies \nto \nmanagement. Journal of Sensors, 2022. \n \nhttps://doi.org/10.1155/2022/5023011\
    \ \nVerdouw, C., Tekinerdogan, B., Beulens, A., & Wolfert, \nS. (2021). Digital\
    \ twins in smart farming. \nAgricultural Systems, 189, 103046. \n \nhttps://doi.org/10.1016/j.agsy.2020.103046\
    \ \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n\
    \ \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nYang, B., Lv, Z.,\
    \ & Wang, F. (2022). Digital Twins for \nIntelligent Green Buildings. Buildings,\
    \ 12(6), 856. \nhttps://doi.org/10.3390/buildings12060856 \n"
  inline_citation: (Kantaros and Piromalis, 2022)
  journal: American Journal of Engineering and Applied Sciences
  limitations: While the paper presents a general overview of a digital twin architecture
    for greenhouse management, it lacks specific details and considerations for data
    volume, frequency, format, and source in this context. Additionally, the paper
    does not provide empirical evidence or case studies to support the effectiveness
    of the proposed architecture.
  pdf_link: https://thescipub.com/pdf/ajeassp.2022.230.238.pdf
  publication_year: 2022
  relevance_score: 0.69
  relevance_score1: 0
  relevance_score2: 0
  title: Setting up a Digital Twin Assisted Greenhouse Architecture
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.3390/electronics12102336
  abstract: In the future, agriculture will face the need for increasing production,
    sustainability, wisdom, and efficiency, which will bring significant challenges
    to the development of modern agriculture. With the commercialization and popularization
    of smart 5G technology, its characteristics of high speed, super-large connection,
    and ultra-low delay will have a profound impact on agricultural IoT. Combined
    with the rapid development of artificial intelligence, edge computing, cloud services,
    and other fields, it will achieve an epoch-making revolution in agricultural production
    mode. Smart Agriculture and 5G-IoT smart agriculture are respectively introduced
    below. The concept of smart agriculture is distinguished, and the category scenarios
    of smart agriculture are summarized. Following that, the current review research
    on 5G-IoT is analyzed. This paper focuses on the analysis and summary of the changes
    brought by 5G to various key scenarios in smart agriculture. This paper analyzes
    the related key technologies and challenges, puts forward some key scientific
    problems, and summarizes the research ideas. Finally, the development trend and
    application value of 5G smart agriculture Internet of Things are shown.
  analysis: The paper thoroughly reviews the research progress of 5G joint IoT in
    smart agriculture, analyzes the impact and challenges of 5G on the Internet of
    Things for smart agriculture, and summarizes the potential application scenarios
    and existing challenges. Based on the development and application of 5G and IoT
    technologies, it further explores the evolution of smart agricultural IoT 2.0
    for 5G, proposes a system architecture for 5G smart agricultural IoT 2.0, and
    discusses the potential key technologies and challenges in the future. This article
    has a certain reference value for researchers in the field of smart agriculture
    Internet of Things technology.
  authors:
  - Jun Liu
  - Lei Shu
  - Xu Lu
  - Ye Liu
  citation_count: 4
  doi: 10.3390/electronics12102336
  full_citation: Survey of Intelligent Agricultural IoT Based on 5G
  full_text: ">\nCitation: Liu, J.; Shu, L.; Lu, X.; Liu, Y.\nSurvey of Intelligent\
    \ Agricultural IoT\nBased on 5G. Electronics 2023, 12,\n2336. https://doi.org/10.3390/\n\
    electronics12102336\nAcademic Editor: Djuradj Budimir\nReceived: 1 March 2023\n\
    Revised: 29 April 2023\nAccepted: 6 May 2023\nPublished: 22 May 2023\nCopyright:\n\
    © 2023 by the authors.\nLicensee MDPI, Basel, Switzerland.\nThis article is an\
    \ open access article\ndistributed\nunder\nthe\nterms\nand\nconditions of the\
    \ Creative Commons\nAttribution (CC BY) license (https://\ncreativecommons.org/licenses/by/\n\
    4.0/).\nelectronics\nReview\nSurvey of Intelligent Agricultural IoT Based on 5G\n\
    Jun Liu 1\n, Lei Shu 2,3,*\n, Xu Lu 4,*\nand Ye Liu 2\n1\nSchool of Automation,\
    \ Guangdong Polytechnic Normal University, Guangzhou 510665, China\n2\nCollege\
    \ of Artiﬁcal Intelligence, Nanjing Agricultural University, Nanjing 210095, China\n\
    3\nSchool of Engineering, University of Lincoln, Lincoln LN6 7TS, UK\n4\nSchool\
    \ of Computer Science, Guangdong Polytechnic Normal University, Guangzhou 510665,\
    \ China\n*\nCorrespondence: lei.shu@njau.edu.cn (L.S.); bruda@126.com (X.L.)\n\
    Abstract: In the future, agriculture will face the need for increasing production,\
    \ sustainability, wisdom,\nand efﬁciency, which will bring signiﬁcant challenges\
    \ to the development of modern agriculture. With\nthe gradual popularization of\
    \ 5G, advanced information technologies such as the Internet of Things\nand artiﬁcial\
    \ intelligence promoted the evolution of modern agriculture to intelligent agriculture.\n\
    The 5G-based Internet of Things will play an essential role in the development\
    \ of smart agriculture.\nThis paper investigates the research progress of 5G Internet\
    \ of Things in smart agriculture. It sorts\nout the development status of 5G smart\
    \ agriculture Internet of Things in recent years. Following that,\nthe concept\
    \ of 5G smart agriculture Internet of Things is put forward. It expounds on the\
    \ connotation,\narchitecture, and enabling key technologies. According to the\
    \ key application scenarios of smart\nagriculture, practical cases are presented,\
    \ the development trend and application value of 5G smart\nagriculture Internet\
    \ of Things are shown, and the future development direction is put forward. Firstly,\n\
    the concept of smart agriculture is distinguished, and the category scenarios\
    \ of smart agriculture\nare summarized. Following that, the current review research\
    \ on 5G-IoT is analyzed. This paper\nfocuses on the analysis and summary of the\
    \ changes brought by 5G to various key scenarios in smart\nagriculture. This paper\
    \ analyzes the related key technologies and challenges, puts forward some\nkey\
    \ scientiﬁc problems, and summarizes the research ideas. Finally, the development\
    \ trend and\napplication value of 5G smart agriculture Internet of Things are\
    \ shown. The future development\ndirection is also proposed.\nKeywords: 5G; smart\
    \ agriculture; IoT; monitoring; deep learning; cloud-edge\n1. Introduction\nThe\
    \ future of agriculture is facing serious challenges as people demand higher quality\n\
    food. As shown in Figure 1, by 2050, the gap is expected to be huge, and this\
    \ will pose a\ngreat challenge to resources and the environment. Academician Zhao\
    \ Chunjiang claimed\nthat the intelligent revolution of agriculture in the form\
    \ of smart agriculture has arrived\nin the ﬁrst issue of “Smart Agriculture”.\
    \ Smart agriculture is an advanced stage of the\ndevelopment of agricultural information\
    \ from digitalization to networking and then to\nintelligence, which is a milestone\
    \ for the development of agriculture, and agriculture is\nentering stage 4.0 [1].\n\
    With the commercialization and popularization of smart 5G technology, its charac-\n\
    teristics of high speed, super-large connection, and ultra-low delay will have\
    \ a profound\nimpact on agricultural IoT. Combined with the rapid development\
    \ of artiﬁcial intelligence,\nedge computing, cloud services, and other ﬁelds\
    \ will achieve an epoch-making revolution\nin agricultural production mode. Smart\
    \ Agriculture and 5G-IoT smart agriculture are\nrespectively introduced below.\n\
    Electronics 2023, 12, 2336. https://doi.org/10.3390/electronics12102336\nhttps://www.mdpi.com/journal/electronics\n\
    Electronics 2023, 12, 2336\n2 of 46\nREVIEW \n2 of\nIncreas\ne 49%\nIncreased\
    \ demand \nfor food\n2020\n2050\n2020\n2050\n10B\n7.6B\nMore water\nMore land\
    \ resources\nCarbon emissions from \nagricultural production\nExcessive resource\
    \ \nconsumption\nreduce carbon emissions\nIncrease in \nPopulation\n \nFigure\
    \ 1. Challenges to sustainable agricultural development in the future. \nWith\
    \ the commercialization and popularization of smart 5G technology, its chara\n\
    teristics of high speed, super-large connection, and ultra-low delay will have\
    \ a profou\nimpact on agricultural IoT. Combined with the rapid development of\
    \ artificial inte\ngence, edge computing, cloud services, and other fields will\
    \ achieve an epoch-maki\nrevolution in agricultural production mode. Smart Agriculture\
    \ and 5G-IoT smart agric\nture are respectively introduced below. \n1.1. Smart\
    \ Agriculture \nThere are many kinds of agriculture, including water-saving agriculture,\
    \ facility a\nriculture, ecological agriculture, three-dimensional agriculture,\
    \ organic agriculture, p\ncision agriculture, and so on. Smart agriculture is\
    \ a new agricultural production mo\nwith the core element of information and knowledge.\
    \ By deeply integrating modern \nformation technology such as the Internet, Internet\
    \ of Things, big data, cloud computin\nand artificial intelligence with agriculture,\
    \ it realizes agricultural information perceptio\nquantitative decision-making,\
    \ intelligent control, precise input, and personalized servi\nSmart agriculture\
    \ is an advanced stage of agricultural informatization development fro\ndigitalization\
    \ to networking and intelligence [2,3]. Smart agriculture is a new agricultu\n\
    Figure 1. Challenges to sustainable agricultural development in the future.\n\
    1.1. Smart Agriculture\nThere are many kinds of agriculture, including water-saving\
    \ agriculture, facility agri-\nculture, ecological agriculture, three-dimensional\
    \ agriculture, organic agriculture, precision\nagriculture, and so on. Smart agriculture\
    \ is a new agricultural production mode with the\ncore element of information\
    \ and knowledge. By deeply integrating modern information\ntechnology such as\
    \ the Internet, Internet of Things, big data, cloud computing, and artiﬁcial\n\
    intelligence with agriculture, it realizes agricultural information perception,\
    \ quantitative\ndecision-making, intelligent control, precise input, and personalized\
    \ service. Smart agricul-\nture is an advanced stage of agricultural informatization\
    \ development from digitalization\nto networking and intelligence [2,3]. Smart\
    \ agriculture is a new agricultural production\nmode and ecosystem based on digital\
    \ and precision agriculture, as well as a production\nform in the era of Agriculture\
    \ 4.0. Figure 2 shows the evolution of agriculture from stage 1.0\nto 4.0 [4].\
    \ This revolution that Agriculture 4.0 will completely change how people produce\n\
    food and effectively help people cope with the future population explosion, ecological\n\
    imbalance, food crisis, and other potential challenges [5].\nSmart agriculture\
    \ covers many categories and scenarios. This paper combines previous\nsummaries\
    \ [6,7] and summarizes them according to the large ﬁelds and categories involved\n\
    in agriculture, as shown in the ﬁgure below. In this paper, smart agriculture\
    \ is mainly\noriented to the ﬁeld of planting and breeding, including crop planting,\
    \ animal husbandry,\nand aquatic products. According to the production mode of\
    \ this agriculture, it can be\ndivided into facility agriculture, ﬁeld agriculture,\
    \ precision agriculture, and so on. This\nincludes most areas of agriculture.\
    \ In addition, various types of agricultural production\nElectronics 2023, 12,\
    \ 2336\n3 of 46\ninclude multiple scenarios, such as moisture monitoring, pest\
    \ management, harvesting,\nand so on. The crop or production facing each scenario\
    \ may differ, but many of the key\ntechnologies involved are broadly similar,\
    \ so they are also grouped together. The following\nis a summary of the key technologies\
    \ involved in the scenario, as shown in Figure 3.\nand artificial intelligence\
    \ with agriculture, it realizes agricultural information perception, \nquantitative\
    \ decision-making, intelligent control, precise input, and personalized service.\
    \ \nSmart agriculture is an advanced stage of agricultural informatization development\
    \ from \ndigitalization to networking and intelligence [2,3]. Smart agriculture\
    \ is a new agricultural \nproduction mode and ecosystem based on digital and precision\
    \ agriculture, as well as a \nproduction form in the era of Agriculture 4.0. Figure\
    \ 2 shows the evolution of agriculture \nfrom stage 1.0 to 4.0 [4]. This revolution\
    \ that Agriculture 4.0 will completely change how \npeople produce food and effectively\
    \ help people cope with the future population explo-\nsion, ecological imbalance,\
    \ food crisis, and other potential challenges [5]. \n \nFigure 2. Smart agriculture\
    \ and agriculture 4.0 evolution. \nFigure 2. Smart agriculture and agriculture\
    \ 4.0 evolution.\nPEER REVIEW \n3 of 46 \nSmart agriculture covers many categories\
    \ and scenarios. This paper combines previ-\nous summaries [6,7] and summarizes\
    \ them according to the large fields and categories \ninvolved in agriculture,\
    \ as shown in the figure below. In this paper, smart agriculture is \nmainly oriented\
    \ to the field of planting and breeding, including crop planting, animal \nhusbandry,\
    \ and aquatic products. According to the production mode of this agriculture,\
    \ \nit can be divided into facility agriculture, field agriculture, precision\
    \ agriculture, and so \non. This includes most areas of agriculture. In addition,\
    \ various types of agricultural pro-\nduction include multiple scenarios, such\
    \ as moisture monitoring, pest management, har-\nvesting, and so on. The crop\
    \ or production facing each scenario may differ, but many of \nthe key technologies\
    \ involved are broadly similar, so they are also grouped together. The \nfollowing\
    \ is a summary of the key technologies involved in the scenario, as shown in Fig-\n\
    ure 3. \nSmart Agriculture\nIntelligent \nmonitoring\nWater/Soil \nManagement\n\
    Planting \ngrowth \nmanagement\nPest \nmanagement\nSupply chain \nmanagement\n\
    Typical Scenarios \nof Smart \nAgriculture\nSmart agricultural machinery: \nplanting,\
    \ weeding, picking and \nharvesting\nFishery and aquatic \nproducts\nAnimal \n\
    husbandry\nCrop planting\nGrowth \nmonitoring\nMonitoring of \naquaculture \n\
    environment\nRemote sensing \nmonitoring\nUAV \nmonitoring\nIntelligent \nirrigation\n\
    Moisture \nmonitoring\nWeather \nforecast\nHumidity/\nrainfall \nmonitoring\n\
    Crop phenotype \nmonitoring\nFertilization and \nfeeding \nmanagement\nGeographic\
    \ fence, \nanimal \nmanagement\nNutritional \npesticide \napplication\nInsect\
    \ \nmonitoring\nDisease \nmonitoring/\nprevention\nPhysical sign \nmonitoring/water\
    \ \nquality management\nLivestock \nmonitoring\nIntelligent \nweeding\nIntelligent\
    \ \npicking\nIntelligent \nspraying\nIntelligent \nharvesting\nTransportation\
    \ of \nagricultural \nproducts\nProcessing of \nagricultural \nproducts\nTraceability\
    \ \nmanagement of \nagricultural products\nAgricultural \nproduct storage\nGreenhouse\n\
    Smart animal \nhusbandry\nPlant factory\nIntelligent \nphenotype\nPrecisionAgriculture\n\
    Organic Agriculture\nSightseeing Agriculture\nFacility Agriculture\nField Agriculture\n\
    \  \n \nFigure 3. Smart agriculture field and classification. \nThe Internet of\
    \ Things and other key technologies in smart agriculture, as well as the \nfinal\
    \ target vision, are shown in Figure 4. The ultimate goal of intelligent agriculture\
    \ is to \nrealize intelligent, unmanned, precise, efficient, high-quality, and\
    \ green. The key technol-\nogies needed to achieve the above goals include 5G,\
    \ Internet of Things, big data, artificial \nintelligence, robotics, blockchain,\
    \ drones, and so on. \nSmart \nagriculture\nSmart\nUnmann\ned\nAccurate\nEfficient\n\
    Superior \nquality\nGreen\nTarget\nFigure 3. Smart agriculture ﬁeld and classiﬁcation.\n\
    The Internet of Things and other key technologies in smart agriculture, as well\
    \ as\nthe ﬁnal target vision, are shown in Figure 4. The ultimate goal of intelligent\
    \ agriculture\nis to realize intelligent, unmanned, precise, efﬁcient, high-quality,\
    \ and green. The key\ntechnologies needed to achieve the above goals include 5G,\
    \ Internet of Things, big data,\nartiﬁcial intelligence, robotics, blockchain,\
    \ drones, and so on.\nThe following introduces the research progress of 5G agricultural\
    \ Internet of Things\nin relevant countries around the world, as shown in Table\
    \ 1. It can be seen that the\nrapid progress of 5G commercial deployment in China\
    \ has driven the development of 5G\nagricultural Internet of Things.\nIt is predicted\
    \ that, by 2025, the proportion of 5G connections in the total number of\nconnections\
    \ will increase from 8% in 2021 to 25% in 2025. 5G is expected to account for\n\
    nearly 60% of global mobile service revenue in 2026. With the commercial popularization\n\
    of 5G worldwide, it will lay the foundation for the application of smart agricultural\
    \ IoTs,\nbringing new opportunities.\nElectronics 2023, 12, 2336\n4 of 46\nFigure\
    \ 3. Smart agriculture field and classification. \nThe Internet of Things and\
    \ other key technologies in smart agriculture, as well as the \nfinal target vision,\
    \ are shown in Figure 4. The ultimate goal of intelligent agriculture is to \n\
    realize intelligent, unmanned, precise, efficient, high-quality, and green. The\
    \ key technol-\nogies needed to achieve the above goals include 5G, Internet of\
    \ Things, big data, artificial \nintelligence, robotics, blockchain, drones, and\
    \ so on. \nSmart \nagriculture\nRobot\nInternet \nof Things\nUAV\nAI\nBlockcha\n\
    in\nBig data\n5G\nSmart\nUnmann\ned\nAccurate\nEfficient\nSuperior \nquality\n\
    Green\nTey \nTechnology\nTarget\n \nFigure 4. Key technologies and objectives\
    \ of smart agriculture. \nThe following introduces the research progress of 5G\
    \ agricultural Internet of Things \nin relevant countries around the world, as\
    \ shown in Table 1. It can be seen that the rapid \nFigure 4. Key technologies\
    \ and objectives of smart agriculture.\nTable 1. Global 5G agricultural Internet\
    \ of Things development [8].\nCountry\nAgricultural Type\n5G Agricultural Internet\n\
    of Things\nDevelopment Representa-\ntive/Development\nCharacteristics\n5G Policy\n\
    America\nLarge farms\n5G + UAV + GPS+ satellite\nremote sensing\nFarmLogs, Cropx\n\
    FCC—$9 billion 5G\nsubsidy program\nEurope\nPrecision agriculture\n5G + big data\
    \ + smart\nagricultural machinery\nmonitoring and control, smart\nagricultural\
    \ machinery\nHolland, Switzerland,\nHuawei, Sunrise\n5G commercial\npromotion\n\
    Japan\nGreen agriculture and\necological agriculture\n5G + agricultural Internet\
    \ of\nThings + smart monitoring\nA new farming model with\nautomation and\nintelligence\n\
    5G falls behind, 6G\nworks\nIsrael\nFacility agriculture\nIntelligent depth sense\
    \ +\nintelligent control\nInnovative agriculture\n5G networking\nChina\nMixed\
    \ existence of\nvarious types of\nagriculture\nAgricultural production is\ndeveloping\
    \ towards automation\nand smart agriculture by leaps\nand bounds\n5G, smart agriculture,\n\
    smart agricultural\nmachinery\n5G is being\ncomprehensively\npromoted and\ndemonstrated\
    \ in\nagricultural application\n1.2. 5G-IoT Smart Agriculture\nThe wireless communication\
    \ capability of 5G with low delay, high density, and large\nbandwidth provides\
    \ a communication guarantee for the application of other information\ntechnologies\
    \ in the smart agricultural Internet of Things. Smart agriculture has relied on\
    \ the\nﬁfth generation of information technology 5G, the Internet of Things, robotics,\
    \ drones, big\ndata, AI, machine learning, blockchain, and other key technologies\
    \ to transform modern\nagriculture. It realizes the deep integration of the physical\
    \ world and the information\nworld, changing the current mode of agricultural\
    \ production. Industry-oriented universal\nwide-area Internet of Things is becoming\
    \ the main force [9]. It can promote the expansion\nand upgrading of IoTs in smart\
    \ agriculture and expedite the landing application of big data\nin smart agriculture.\
    \ It is the key to the in-depth application of UAV in agriculture and is\nan important\
    \ booster for integrating artiﬁcial intelligence and robot blockchain in smart\n\
    agriculture [10].\nThe Internet of Things continues to evolve with the evolution\
    \ of information technol-\nogy and sensors. It should not only perceive and transmit\
    \ data but also have functions such\nas recognition, computation, service, semantics,\
    \ and even cognitive decision-making [11].\nThe detection, management, and maintenance\
    \ functions of the Internet of Things will\nalso gradually become intelligent\
    \ and unmanned. The in-depth integration of the Inter-\nnet of Things, big data,\
    \ and artiﬁcial intelligence will revolutionize the current form of\nElectronics\
    \ 2023, 12, 2336\n5 of 46\nthe Internet of Things and generate huge social value\
    \ [12]. As an important part of new\ndigital infrastructure, the Internet of Things\
    \ (IoT) is deeply integrated with 5G, big data,\ncloud computing, artiﬁcial intelligence,\
    \ blockchain, digital twin, and other technologies,\nand is evolving into a smart\
    \ IoT system (IoTs 2.0) [13], which is profoundly changing\nthe process of the\
    \ modern agricultural industry and promoting the rapid development of\nsmart agriculture.\n\
    In the ﬁeld of smart agriculture, the Agricultural Internet of Things (AIoT) is\
    \ devel-\noping rapidly, but still faces many challenges. This includes the new\
    \ application of the\nagricultural scene, the transformation of the new agricultural\
    \ production mode, and the\ndeep integration with other technologies. As a basic\
    \ condition for the in-depth application\nof the agricultural Internet of Things,\
    \ 5G communication technology will promote the\nin-depth application of the agricultural\
    \ Internet of Things in smart agriculture. 5G can\nprovide MTC communication with\
    \ high reliability, low delay, and wide coverage, and its\nthree typical application\
    \ scenarios have broad prospects in smart agriculture [14]. 5G IoT\ntechnology\
    \ can be extended to the scope of current, which cannot be achieved with the\n\
    ﬁeld, making IoT depth perception of the intelligent environment perception, enlarging\n\
    the coverage of the Internet of Things of agriculture and the ascending scale,\
    \ expanding\nthe communication capacity, and realizing large-scale equipment interact\
    \ with each other\nand data sharing so as to realize the agricultural decision-making\
    \ process depth [15]. 5G-\nIoT is expected to provide real-time, on-demand, online,\
    \ reconﬁgurable, and end-to-end\ncoordinated capabilities for a variety of agricultural\
    \ applications. It can provide logically\nindependent network applications and\
    \ conﬁgure networks on demand. According to the\nfuture agricultural needs, the\
    \ integration of 5G with smart agriculture and the Internet of\nThings will be\
    \ able to achieve network characteristics, as shown in Figure 5.\nof the modern\
    \ agricultural industry and promoting the rapid dev\nculture. \nIn the field of\
    \ smart agriculture, the Agricultural Internet of \noping rapidly, but still faces\
    \ many challenges. This includes the\nagricultural scene, the transformation of\
    \ the new agricultural pro\ndeep integration with other technologies. As a basic\
    \ condition for t\nof the agricultural Internet of Things, 5G communication technolo\n\
    depth application of the agricultural Internet of Things in smart a\nvide MTC\
    \ communication with high reliability, low delay, and \nthree typical application\
    \ scenarios have broad prospects in smart \ntechnology can be extended to the\
    \ scope of current, which cann\nfield, making IoT depth perception of the intelligent\
    \ environmen\nthe coverage of the Internet of Things of agriculture and the asce\n\
    the communication capacity, and realizing large-scale equipment \nand data sharing\
    \ so as to realize the agricultural decision-making\nIoT is expected to provide\
    \ real-time, on-demand, online, reconfig\ncoordinated capabilities for a variety\
    \ of agricultural applications.\nindependent network applications and configure\
    \ networks on de\nfuture agricultural needs, the integration of 5G with smart\
    \ agricu\nThings will be able to achieve network characteristics, as shown in\n\
    Fine grained network\nSmart Agriculture \n5G Internet of \nThings Characteristic\
    \ \nDemand\nHigh data rate\nScalability\nReliable elasticity\nHigh density connection\n\
    Mobility\nSecurity\nHigh endurance\nlow power consumption\n \nFigure 5. Characteristics\
    \ of smart agriculture 5G Internet of Things dema\nThe above content will be able\
    \ to promote the landing of sm\nsent, many scholars are paying attention to the\
    \ opportunities and\nthe commercialization of 5G to the Internet of Things and\
    \ have ca\nview studies [16–23]. The relevant summaries are shown in Table \n\
    Table 2. 5G-IoT review papers overview. \nTime \nOverview Journals  \nMain Focus\
    \ \n2016\nM. R. Palattella et al. From technology, standardization\nFigure 5.\
    \ Characteristics of smart agriculture 5G Internet of Things demand.\nThe above\
    \ content will be able to promote the landing of smart agriculture. At present,\n\
    many scholars are paying attention to the opportunities and challenges brought\
    \ by the\ncommercialization of 5G to the Internet of Things and have carried out\
    \ a series of review\nstudies [16–23]. The relevant summaries are shown in Table\
    \ 2.\nElectronics 2023, 12, 2336\n6 of 46\nTable 2. 5G-IoT review papers overview.\n\
    Time\nOverview Journals\nMain Focus\nScene\n2016\nM. R. Palattella et al. [16]\n\
    From technology, standardization and\nmarket prospect\nMarket Paradigm\n2018\n\
    Shancang Li et al. [17]\nKey implementation technologies, main research\ntrends\
    \ and challenges\nKey technologies and trends\n2018\nD. Wang et al. [18]\nNew\
    \ paradigm of 5G intelligent Internet of\nThings (5G l-loT): big data mining,\
    \ deep\nlearning, and reinforcement learning\nNew paradigm\n2018\nG. A. Akpakwu\
    \ et al. [19]\nApplication requirements of the Internet of\nThings and the development\
    \ status of related\ncommunication technologies\nCommunications technology\n2019\n\
    N. Wang et al. [20]\nPhysical layer security\nSecurity\n2020\nK. Shaﬁque et al.\
    \ [21]\nProspects of 5G key technologies for the Internet\nof Things\n5G Key Technology\n\
    2021\nYu Tang et al. [22]\nOpportunities, challenges, and key technologies\nSmart\
    \ agriculture\n2022\nOgbodo E U et al. [23]\n5G and LPWAN-IoT for Improved Smart\
    \ Cities\nand Remote Area Applications\n5G LPWAN-IoT\n2022\nKhanh Q V et al. [24]\n\
    Wireless communication technologies for IoT in\n5G: vision, applications, and\
    \ challenges\nWireless communication\ntechnologies\nDespite a great deal of research\
    \ on 5G-IoT, there are few reviews on 5G IoT in agri-\nculture. Secondly, there\
    \ is a notable amount of research on smart agriculture, as shown in\nTable 3.\n\
    It can be seen that smart agriculture and the Internet of Things are both hot-tracking\n\
    directions, and there are many review articles and rapid technological development.\
    \ Many\nscholars have conducted research from various perspectives. Based on 5G,\
    \ there is not\nmuch in-depth research, and the following method is to carry out\
    \ in-depth research and\ndiscussion from this aspect.\nDomestic literature research\
    \ on 5G intelligent agricultural Internet of Things is also\nbecoming a new hotspot.\
    \ There is a rapid growth trend in related papers, and the main\nresearch ﬁelds\
    \ include smart agriculture, the Internet of Things, 5G, and so on. The above\n\
    distribution obtained from 5G, smart agriculture, and the Internet of Things retrieved\
    \ from\nCNKI shows that research is increasing rapidly as show in Figure 6.\n\
    PEER REVIEW \n7 of 46 \n2021 \nGodwin Idoje et al. \n[41] \nTechnological progress\
    \ and chal-\nlenges of smart farms \nSmart Farm \n2022 N. N. Misra et al. [42]\
    \ \nInternet of Things, Artificial Intelli-\ngence and Big Data in Agriculture\
    \ \nand Food Industry \nFood industry \nIt can be seen that smart agriculture\
    \ and the Internet of Things are both hot-tracking \ndirections, and there are\
    \ many review articles and rapid technological development. \nMany scholars have\
    \ conducted research from various perspectives. Based on 5G, there is \nnot much\
    \ in-depth research, and the following method is to carry out in-depth research\
    \ \nand discussion from this aspect. \nDomestic literature research on 5G intelligent\
    \ agricultural Internet of Things is also \nbecoming a new hotspot. There is a\
    \ rapid growth trend in related papers, and the main \nresearch fields include\
    \ smart agriculture, the Internet of Things, 5G, and so on. The above \ndistribution\
    \ obtained from 5G, smart agriculture, and the Internet of Things retrieved \n\
    from CNKI shows that research is increasing rapidly as show in Figure 6. \n \n\
    Figure 6. Shows the overall trend analysis of related papers. \n1.3. Summary \n\
    1.3.1. Contribution \nIn this paper, the research and prospects of 5G joint IoT\
    \ in smart agriculture are sum-\nmarized. Firstly, it reviews the differences\
    \ between 5G compared with current and previ-\nous communication technologies.\
    \ Following that, combined with the characteristics of the \nagricultural Internet\
    \ of Things, the reform and impact of 5G on it are summarized and \nFigure 6.\
    \ Shows the overall trend analysis of related papers.\nElectronics 2023, 12, 2336\n\
    7 of 46\nTable 3. Summary of smart agriculture.\nTime\nOverview Journals\nTheme\n\
    Key Words\n2017\nMekala M S et al. [25]\nSmart agriculture cloud computing\nSmart\
    \ agriculture, cloud\ncomputing\n2018\nRahul Dagar et al. [26]\nIntelligent Farm\
    \ IoT\nSmart Farm, IoT\n2019\nFarooq M S et al. [27]\nInvestigation on the Role\
    \ of the Internet of\nThings in Smart Farms\nSmart Farm, IoT\n2019\nDevare J et\
    \ al. [28]\nCrop generation detection and control\nDetection, crops\n2019\nFiona\
    \ J R et al. [29]\nImage processing and disease detection\nbased on image detection\
    \ in agriculture\nImage processing, disease\ndetection\n2019\nBh Ag At M et al.\
    \ [30]\nInternet of Things in Smart Farm\nSmart Farm, IoT\n2019\nSarker V et al.\
    \ [31]\nEdge computing Lora in the Internet\nof Things\nEdge computing, Lora\n\
    2019\nSmart et al. [32]\nSmart Farm\nSmart Farm\n2020\nVIPPON et al. [33]\nProgress\
    \ of Internet of Things\nin Agriculture\nIoT, Agriculture\n2020\nFriha O et al.\
    \ [34]\nNew technologies of the Internet of Things\nfor smart agriculture in the\
    \ future\nFuture smart agriculture IoT\n2021\nRayhana R et al. [35]\nRFID sensing\
    \ technology in\nsmart agriculture\nSmart agriculture, RFID,\nperception\n2021\n\
    Xing Yang et al. [36]\nInternet of Things for Smart Agriculture in\nthe Future\n\
    Smart agriculture, IoT\n2021\nYe Liu et al. [37]\nIndustry 4.0 to Agriculture\
    \ 4.0\nAgriculture 4.0\n2021\nBhat S A et al. [38]\nBig data and AI revolution\
    \ for\nprecision agriculture\nBig data, AI, precision\nagriculture\n2021\nGodwin\
    \ Idoje. et al. [39]\nProgress and challenges of intelligent\nagriculture Internet\
    \ of Things\nSmart agriculture, IoT\n2021\nWen Tao et al. [40]\nProgress and challenge\
    \ of intelligent\nagriculture Internet of Things\ncommunication technology\nSmart\
    \ agriculture, IoT,\ncommunication technology\n2021\nGodwin Idoje et al. [41]\n\
    Technological progress and challenges of\nsmart farms\nSmart Farm\n2022\nN. N.\
    \ Misra et al. [42]\nInternet of Things, Artiﬁcial Intelligence\nand Big Data\
    \ in Agriculture and\nFood Industry\nFood industry\n1.3. Summary\n1.3.1. Contribution\n\
    In this paper, the research and prospects of 5G joint IoT in smart agriculture\
    \ are\nsummarized. Firstly, it reviews the differences between 5G compared with\
    \ current and\nprevious communication technologies. Following that, combined with\
    \ the characteristics\nof the agricultural Internet of Things, the reform and\
    \ impact of 5G on it are summarized\nand prospected. Finally, combined with the\
    \ application paradigm of 5G and smart agricul-\ntural IoT, the possible challenges\
    \ are put forward, and some potential research issues are\npointed out.\n1.3.2.\
    \ Organization\n5G-oriented intelligent agricultural Internet of Things is an\
    \ essential direction of smart\nagriculture in the future. This paper intends\
    \ to summarize the relevant research status\nand possible research directions\
    \ from the following perspectives. The rest of this article is\nElectronics 2023,\
    \ 12, 2336\n8 of 46\nstructured as show in Figure 7. In this paper, the impact\
    \ of 5G on the Internet of Things\nfor smart agriculture is sorted out, and the\
    \ potential application scenarios and existing\nchallenges are summarized.\nPEER\
    \ REVIEW \n8 of 46\nThesises Overview\n• \nSmart agriculture\n• \n5G-IoT in Smart\
    \ agriculture\n• \nSummary\nPart I: Introduction\n• \n5G Characteristics\n• \n\
    Typical Applications of Smart Agricultural \nIoT based on 5G\n• \nFuture Trends\
    \ and Key Technologies of 5G \nIoT Application in Smart Agriculture\nPart II:\
    \ Integration and Application of 5G and \nSmart Agricultural Internet of Things\n\
    • \n5G Smart Agricultural IoT 2.0 Architecture\n• \n5G Smart agricultural IoT\
    \ Depth \nComprehensive Sense\n• \nReliable Data-driven detection of 5G Smart\
    \ \nAgricultural IoT\n• \nCloud Edge Fog Computing Fusion in 5G \nSmart Agricultural\
    \ IoT\n• \n5G Smart Agricultural IoT in-depth Service\n• \n5G Smart Agricultural\
    \ IoT Production \nintelligent control\nPart III: Evolution of Smart Agricultural\
    \  2.0 for \n5G\n• \nMain Application Scenarios of 5G Smart \nAgricultural IoT\n\
    • \nDepth Sense of 5G Smart Agriculture\n• \n5G Smart Agricultural Machinery\n\
    • \n5G Agricultural UAV\n• \nSmart agricultural Supply Chain \nManagement under\
    \ 5G\nPart IV: Revolution of smart agricultural iot \napplication paradigm under\
    \ 5G\n• \nFusion and Optimization of Sparse 5G base \nStation and Heterogeneous\
    \ Sensing \nnetwork in Smart agriculture\n• \nOptimization Control for Edge Computing\
    \ \nin 5G Smart Agricultural Production\n• \nScheduling Optimization of Heterogeneous\
    \ \nNodes under 5G Smart Agriculture\n• \nFault Detection and Self-healing for\
    \ 5G \nSmart Agricultural Platform\n• \nAI Application Optimization for 5G Smart\
    \ \nAgricultural IoT\n• \n5G-IoT System Service Model for Smart \nAgriculture\n\
    • \nSecurity Issues of 5G IoTs for Smart \nAgriculture\nPart V: Key Issues and\
    \ Challenges of 5G Smart \nAgricultural IoT\nPart VI: Summary\n \nFigure 7. Structure\
    \ of this article. \n2. Integration and Application of 5G and Smart Agricultural\
    \ Internet of Things \n2.1. 5G Characteristics \nThe existing agricultural IoT\
    \ uses various communication technologies in its appli-\ncation, including Zigbee,\
    \ Wifi, Sigfox, and so on. As a new generation of communication\nmode, 5G is compared\
    \ with the characteristics of other communication modes in agricul-\ntural scenes.\
    \ Table 4 summarizes how 5G compares to other communication technologies\ncommonly\
    \ used in the Internet of Things. 5G has its own characteristics. \nFigure 7.\
    \ Structure of this article.\n2. Integration and Application of 5G and Smart Agricultural\
    \ Internet of Things\n2.1. 5G Characteristics\nThe existing agricultural IoT uses\
    \ various communication technologies in its appli-\ncation, including Zigbee,\
    \ Wiﬁ, Sigfox, and so on. As a new generation of communication\nmode, 5G is compared\
    \ with the characteristics of other communication modes in agricul-\ntural scenes.\
    \ Table 4 summarizes how 5G compares to other communication technologies\ncommonly\
    \ used in the Internet of Things. 5G has its own characteristics.\nElectronics\
    \ 2023, 12, 2336\n9 of 46\nTable 4. 5G compared with other related communication\
    \ technologies.\nParameter\nStandard\nFrequency\nBand\nTime\nDelay\nData Rate\n\
    Transmission\nDistance\nEnergy Con-\nsumption\nCost\nNetwork\nSize\n5G\n3GPP\n\
    Release-16\n3–6 GHz\nLow\n100 Mb/s–\n10 Gb/s\nBase station\nsignal\ncoverage area\n\
    Medium\nMedium\nInﬁnite\n4G\nLTE\n2.4 G/865\nMHz\nMedium\n10 Mb/s–\n1 Gb/s\nBase\
    \ station\nsignal\ncoverage area\nMedium\nMedium\nInﬁnite\nZigbee\nIEEE\n802.15.4\n\
    2.4 G\nHigh\n20–250\nKb/s\nWithin 100 m\nLow\nLow\nBelow 500\nWiﬁ\nIEEE 802.11\n\
    5 GHz-60\nGHz\nMedium\n1 Mb/s–\n7 Gb/s\nLess than\n100 m\nMedium\nMedium\nBelow\
    \ 100\nNB-IoT\n3GPP\nRelease 13\n850–900\nMHz\nHigh\n160–250\nkbps\nBase station\n\
    signal\ncoverage area\nExtremely\nlow\nLow\n<50,000\nSigFox\nSigFox\n200 KHz\n\
    High\n100–600\nbit/s\nBase station\nsignal\ncoverage area\nLow\nLow\n<50,000\n\
    RFID\nISO18000-\n6C\n860–960\nMhz\nLow\n40–160\nkbit/s\n1–5 m\nLow\nLow\n<1000\n\
    It can be seen that 5G has its own characteristics compared with other communication\n\
    technologies, with incomparable advantages in terms of large bandwidth, large\
    \ connection,\nand low delay. Therefore, the emergence of 5G may bring new changes\
    \ and opportunities\nto the existing agricultural production mode in many agricultural\
    \ application scenarios.\nCompared with the 1G voice era, 2G text era, 3G picture\
    \ era, and the recent 4G video\nera, the application scenarios of 5G will get\
    \ a leapfrog development. Compared with 2G\nto 4G, which are born to connect “people”,\
    \ with the advent of the Internet of everything\nera, mobile communication networks\
    \ need to evolve to connect “things”. 5G is facing the\ncommon demand of large\
    \ trafﬁc and small data, mobile broadband on the one hand, and\nthe Internet of\
    \ Things on the other. Its main features are as follows in Figure 8.\nElectronics\
    \ 2023, 12, x FOR PEER REVIEW \n9 of 46 \n \nNB-IoT \n3GPP Re-\nlease 13 \n850–900\
    \ MHz \nHigh \n160–250 \nkbps \nBase station \nsignal coverage \narea \nExtremely\
    \ low \nLow \n<50,000 \nSigFox \nSigFox \n200 KHz \nHigh \n100–600 \nbit/s \n\
    Base station \nsignal coverage \narea \nLow \nLow \n<50,000 \nRFID \nISO18000-\n\
    6C \n860–960 Mhz \nLow \n40–160 \nkbit/s \n1–5 m \nLow \nLow \n<1000 \nIt can\
    \ be seen that 5G has its own characteristics compared with other communication\
    \ \ntechnologies, with incomparable advantages in terms of large bandwidth, large\
    \ connec-\ntion, and low delay. Therefore, the emergence of 5G may bring new changes\
    \ and oppor-\ntunities to the existing agricultural production mode in many agricultural\
    \ application sce-\nnarios. \nCompared with the 1G voice era, 2G text era, 3G\
    \ picture era, and the recent 4G video \nera, the application scenarios of 5G\
    \ will get a leapfrog development. Compared with 2G \nto 4G, which are born to\
    \ connect “people”, with the advent of the Internet of everything \nera, mobile\
    \ communication networks need to evolve to connect “things”. 5G is facing the\
    \ \ncommon demand of large traffic and small data, mobile broadband on the one\
    \ hand, and \nthe Internet of Things on the other. Its main features are as follows\
    \ in Figure 8. \nq eMBB Enhanced Mobile \nBroadband\nq URLLC ultra reliable low\
    \ delay \ncommunication\nq mMTC Massive Machine Class \nCommunication\nFour characteristics\
    \ of 5G\n• \nUbiquitous\n• \nlow power \nconsumption\n• \nNetwork \nvirtualization\n\
    • \nNetwork intelligence\nq Wireless access technology\nq Network reconfiguration\
    \ \ntechnology\nq Distributed Business Services\nThree application scenarios of\
    \ \n5G\n 5G key technologies\n \nFigure 8. 5G technical introduction. \nThe development\
    \ and deployment of 5G have provided the communication layer \nfoundation for\
    \ access and transmission to realize the “Internet of everything” in a real \n\
    sense. Gb/S span will be realized not only in the field of mobile communication.\
    \ It can also \nprovide 3D, UHD video, AR/VR, cloud office, and other immersive\
    \ interactive methods \nto upgrade. It will also give birth to more new agricultural\
    \ application scenarios. The three \nmajor application scenarios of 5G application\
    \ services include Enhanced Mobile Broad-\nband (eMBB), Massive Machine Type Communications\
    \ (mMTC), and ultra-reliable and \nLow Latency Communications (uRLLC). The latter\
    \ two belong to the application scenarios \nof the Internet of Things [43,44],\
    \ as shown in Figure 9. \n100Gbps \neMBB\nSmart \nagriculture\nSmart \nhome\n\
    3D Video\nvirtual \nreality\nIndustrial \nInternet of\nLow\nMiddle High\nConnection\
    \ \ndensity：\n100m/km2\nPeak data \nrate: \n10Gpbs\nSpace \ncapacity: \n10Mbit/s/\n\
    m2\nEnergy \nefficiency\nFigure 8. 5G technical introduction.\nThe development\
    \ and deployment of 5G have provided the communication layer\nfoundation for access\
    \ and transmission to realize the “Internet of everything” in a real\nsense. Gb/S\
    \ span will be realized not only in the ﬁeld of mobile communication. It can also\n\
    provide 3D, UHD video, AR/VR, cloud ofﬁce, and other immersive interactive methods\
    \ to\nupgrade. It will also give birth to more new agricultural application scenarios.\
    \ The three\nmajor application scenarios of 5G application services include Enhanced\
    \ Mobile Broadband\n(eMBB), Massive Machine Type Communications (mMTC), and ultra-reliable\
    \ and Low\nLatency Communications (uRLLC). The latter two belong to the application\
    \ scenarios of\nthe Internet of Things [43,44], as shown in Figure 9.\nElectronics\
    \ 2023, 12, 2336\n10 of 46\nFigure 9. 5G: The three major application scenarios.\n\
    2.2. Typical Applications of Intelligent Agricultural Iot Based on 5G\nBased on\
    \ the above analysis, the three application scenarios of 5G, eMBB, mMTC,\nand\
    \ uRLLC will be widely applied in smart agriculture. It will signiﬁcantly improve\n\
    the connectivity between smart agriculture stakeholders, user products, and data.\
    \ The\nfollowing Figure 10 shows the typical application scenarios.\nElectronics\
    \ 2023, 12, x FOR PEER REVIEW \n10 of 46 \n \n2.2. Typical Applications of Intelligent\
    \ Agricultural Iot Based on 5G \nBased on the above analysis, the three application\
    \ scenarios of 5G, eMBB, mMTC, \nand uRLLC will be widely applied in smart agriculture.\
    \ It will significantly improve the \nconnectivity between smart agriculture stakeholders,\
    \ user products, and data. The follow-\ning Figure 10 shows the typical application\
    \ scenarios. \nSmart Agriculture Scenarios \nunder 5G\nEnhanced Mobile \nBroadband\
    \ (eMBB)\nLarge scale machine \ncommunication (mMTC)\nUltra high reliability and\
    \ low delay \ncommunication (uRLLC)\nVideo monitoring of \nplant protection\n\
    UAV mapping/spectral \nimaging\nComplex Image/Video \nProcessing Based on Deep\
    \ \nLearning/AI\nFacility agriculture/stereoscopic \nagriculture: massive sensor\
    \ data \ntransmission\nIntelligent agricultural \nmachinery operation\nPerceptual\
    \ Monitoring \nof Field Agriculture\nData perception in \nfacility agriculture\n\
    Massive perceptual \nmonitoring in fishery and \naquaculture scenes\nAgricultural\
    \ UAV \noperation\nAutomatic driving of \nagricultural machinery\nHigh intelligence\
    \ and \nprecision agriculture scene: \nmassive sensing equipment\nKey point monitoring\
    \ \nand early warning\n \nFigure 10. 5G application scenarios in smart agriculture.\
    \ \n2.2.1. Enhance Mobile Broadband Applications (eMBB) in Smart Agricultural\
    \ IoT \nWith the improvement of intelligence in smart agriculture, there is increasing\
    \ data \ninformation, which needs the support of large data transmission rate.\
    \ The high bandwidth \nof 5G will be able to support high-definition video transmission\
    \ and massive data trans-\nmission. Successful real-time transmission of HD data\
    \ will enable remote real-time detec-\ntion, as well as the combination of machine\
    \ learning algorithms to transmit HD video back \nfor rapid analysis and computation.\
    \ Secondly, massive data transmission can be combined \nwith deep learning algorithms\
    \ to analyze and calculate plant diseases and insect pests \n[45,46] and quick\
    \ weed control. \nThe integrated application of 5G will promote the planting industry\
    \ to realize intel-\nligent planting technology, intelligent agricultural management,\
    \ open planting process, \nand intelligent labor management. 5G network, artificial\
    \ intelligence image recognition, \nsatellite remote sensing [47], big data, and\
    \ other technologies are used to drive all kinds \nof unmanned agricultural machinery\
    \ equipment to realize automatic operation. Including \naerial plant protection\
    \ UAV, unmanned highland gap plant protection machines, rototil-\nler, corn planters,\
    \ unmanned sprinkler irrigation systems, etc., to achieve safe, reliable, \nenvironmental\
    \ protection and energy-saving farm operations. It can also monitor agricul-\n\
    tural production in real-time, realize rapid detection of crop diseases, pests,\
    \ weeds, farm-i\nFigure 10. 5G application scenarios in smart agriculture.\n2.2.1.\
    \ Enhance Mobile Broadband Applications (eMBB) in Smart Agricultural IoT\nWith\
    \ the improvement of intelligence in smart agriculture, there is increasing data\n\
    information, which needs the support of large data transmission rate. The high\
    \ band-\nwidth of 5G will be able to support high-deﬁnition video transmission\
    \ and massive data\ntransmission. Successful real-time transmission of HD data\
    \ will enable remote real-time\ndetection, as well as the combination of machine\
    \ learning algorithms to transmit HD video\nback for rapid analysis and computation.\
    \ Secondly, massive data transmission can be\ncombined with deep learning algorithms\
    \ to analyze and calculate plant diseases and insect\npests [45,46] and quick\
    \ weed control.\nThe integrated application of 5G will promote the planting industry\
    \ to realize intel-\nligent planting technology, intelligent agricultural management,\
    \ open planting process,\nand intelligent labor management. 5G network, artiﬁcial\
    \ intelligence image recognition,\nsatellite remote sensing [47], big data, and\
    \ other technologies are used to drive all kinds of\nunmanned agricultural machinery\
    \ equipment to realize automatic operation. Including\naerial plant protection\
    \ UAV, unmanned highland gap plant protection machines, rototiller,\ncorn planters,\
    \ unmanned sprinkler irrigation systems, etc., to achieve safe, reliable, envi-\n\
    Electronics 2023, 12, 2336\n11 of 46\nronmental protection and energy-saving farm\
    \ operations. It can also monitor agricultural\nproduction in real-time, realize\
    \ rapid detection of crop diseases, pests, weeds, farmland\nwater quality, and\
    \ soil, provide ﬁne-grained nutrition, ventilation, and water supply for\ncrops,\
    \ and improve productivity [48,49].\nIn the 5G smart farm [50], the shading system,\
    \ fresh air system, cooling system,\nfertilization and watering system, data acquisition\
    \ system, and light supplement system\nachieved 5G control. For example, intelligent\
    \ glass greenhouse food production can also\nachieve substantial growth. Mobile\
    \ robots based on 5G can complete panoramic collection.\nAlong with the cultivation\
    \ tank of the greenhouse, it automatically completes inspection,\nﬁxed-point collection,\
    \ automatic return, automatic charging, and other actions. If there\nare obstacles\
    \ along the way, it can automatically go around. Real-time acquisition of\nhigh-deﬁnition\
    \ video data by video sensing nodes can solve the delay problem of massive\ndata\
    \ transmission based on edge computing devices and artiﬁcial intelligence, improve\n\
    quick response ability, and realize front-end intelligent decision-making [51].\
    \ All kinds of\nintelligent agriculture applications based on video processing\
    \ are shown in Table 5.\nTable 5. Video image processing in smart agriculture.\n\
    Literature\nApplication Scenario\nData Type\nGarcia [52]\nDistributed precision\
    \ agriculture\nVideo and Data\nHe Liu [53]\nVideo segmentation\nVideo\nSabzi S\
    \ [54]\nMonitoring of potato weeds in video\nVideo\nHe Jiang [55]\nFruit disease\
    \ surveillance based on deep learning\nImage\nIt can be seen that there are many\
    \ intelligent agricultural applications based on video\nimage detection at present.\
    \ With the continuous development of video acquisition equip-\nment, HD images\
    \ and videos are becoming increasingly popular. Optimizing data trans-\nmission\
    \ has always been a challenge. The integrated application of smart agriculture\
    \ based\non 5G is a big direction.\n2.2.2. Large-Scale Machine Type Communication\
    \ (mMTC) in Smart Agricultural IoT\nSmart agricultural IoT is the next generation\
    \ of agricultural IoT for smart agriculture.\nIt needs a depth perception of the\
    \ agricultural production process. Large-scale agricultural\nproduction scenarios\
    \ require large-scale sensing nodes to transmit data [56]. Traditional\nsensor\
    \ networks have some difﬁculties in networking reliability, energy efﬁciency,\
    \ and\ndeployment cost. However, large-scale machine-type communication based\
    \ on 5G can\nachieve a smart agricultural IoT with low cost, high reliability,\
    \ low power consumption,\nand convenient networking and deployment. For example,\
    \ NB-IoT can be deployed to\nquickly monitor soil, fertilizer, and plants in farmland.\
    \ In this way, the comprehensive\nperception and depth perception of agricultural\
    \ production can be realized, providing\nsupport for the deepening application\
    \ of smart agriculture [57].\n5G-oriented NB-IoT enables dense sensing network\
    \ deployment. Combining com-\nputer vision and other technologies can effectively\
    \ extract plant phenotypic variation\nand its related information. Moreover, machine\
    \ learning, artiﬁcial intelligence, and other\ncutting-edge technologies are used\
    \ for processing [58]. Deep learning convolutional neural\nnetworks were used\
    \ to evaluate crop phenotypic characteristics and soil conditions. Multi-\nspectral\
    \ imaging in agricultural areas is based on IoT sensors and small unmanned aerial\n\
    vehicles (UAVs). It identiﬁes plant quality and leaf diseases.\n2.2.3. Ultra-Reliable\
    \ Low Latency Communication (uRLLC) in Smart Agricultural IoT\nSuch ultra-reliable\
    \ low-latency communication applications are generally oriented to\nmission-critical,\
    \ real-time transmission of critical data and control of major agricultural\n\
    equipment [59]. Drones based on 5G networks can achieve precision operations.\
    \ The\nElectronics 2023, 12, 2336\n12 of 46\nﬂight trajectory and situation data\
    \ of the UAV can be returned to the 5G network UAV\nmanagement and operation platform\
    \ in real-time through the 5G network. Flight status can\nbe monitored in real-time\
    \ [60]. Through the agricultural information collected by UAV and\nsatellite remote\
    \ sensing technology, the platform can intelligently and dynamically analyze\n\
    the crop situation in the monitoring region, make a macroscopic estimation of\
    \ the real-time\nseedling situation, environmental dynamics and distribution of\
    \ crops, and output scientiﬁc\nreports [61]. According to the report, farmers\
    \ can clearly grasp the growth situation of\ncrops and soil moisture and manage\
    \ production in response to problems so as to ensure\nmore scientiﬁc and efﬁcient\
    \ farming activities.\nThe universal application of 5G will provide the communication\
    \ basis for unmanned,\nintelligent, and intelligent agricultural machinery and\
    \ equipment because 5G technology\nhas the characteristics of high speed, short\
    \ delay, low power consumption, ubiquitous\nnetwork, and scalability. It will\
    \ shine in the ﬁelds of agricultural Internet of Things,\nprecision planting,\
    \ agricultural products circulation traceability, agricultural drones, smart\n\
    farming, agricultural industry services, and so on, and promote agriculture to\
    \ be more\ninformationalized and intelligent [62,63].\n2.3. Future Trends and\
    \ Key Technologies of 5G-IoT Application in Smart Agriculture\nIt can be seen\
    \ from the above analysis that the integration of 5G and IoT has a wide\napplication\
    \ prospect in the scenario of smart agriculture. Agricultural IoT can be used\
    \ to\ncollect environmental monitoring information on crop growth and process\
    \ this information\nto develop the production plan of precision agriculture. Precision\
    \ agriculture requires\nthe network to support the connection of massive devices\
    \ and a large number of small\ndata packets. Since agricultural IoT devices are\
    \ often deployed in areas where signals are\nchallenging to reach, such as mountains,\
    \ forests, and waters, 5G can meet the requirements\nwith stronger coverage capability,\
    \ ﬂexibility, scalability, and lower power consumption,\ndelay, and cost. The\
    \ future trends of intelligent agricultural IoT facing 5G mainly reﬂect\nthe following:\n\
    1.\nCloud edge collaboration: agricultural monitoring terminal and cloud collaboration.\n\
    2.\nCloud computing/AI/big data/Internet of Things/digital twin and other agricul-\n\
    tural integration.\n3.\nVirtualization and servitization of perception/access/communication\
    \ layer, software\ndeﬁned network.\n4.\nModel-driven, cloud-native new application\
    \ (APP) development environment for\nsmart Internet of Things.\n5.\nThe deep integration\
    \ of people, information space, and physical space will form\na deep intelligent\
    \ smart agriculture and achieve a harmonious ecology of human–\nmachine symbiosis.\n\
    The key technologies of IoT applications in smart agriculture include vital informa-\n\
    tion sensor technology, phenotype information acquisition technology, phenotype\
    \ group\ndata analysis technology, phenotype group big data management and database\
    \ building\ntechnology, etc. [64,65]. All these technologies need the support\
    \ of 5G. Among them,\nthe life information sensor technology collects information\
    \ about seeds and their propa-\ngation/seed production environment and obtains\
    \ the corresponding physiological and\necological information through signal transformation\
    \ and AI data processing. Phenotypic\ninformation acquisition technology automatically\
    \ extracts important phenotypic features\nand logical relationships from massive\
    \ amounts of information to realize automatic and\naccurate identiﬁcation of phenotypic\
    \ traits. Phenotypic data analysis technology covers the\ncomplete process from\
    \ the initial data collection to the ﬁnal reﬁnement analysis. Phenotype\ngroup\
    \ big data management and database building technology are used to manage, store,\n\
    and share tabular data.\nElectronics 2023, 12, 2336\n13 of 46\n3. Evolution of\
    \ Intelligent Agricultural IoT 2.0 for 5G\nIntelligent Internet of Things (IoT\
    \ 2.0) refers to a complex system that integrates “hu-\nman, information space\
    \ and physical space” [66] under the guidance of 5G and other\ncommunication technologies\
    \ and AI technologies and intelligently interconnects and serves\ncooperatively.\
    \ Among them, the new generation of AI technologies includes data-driven\ndeep\
    \ reinforcement learning intelligence, network-based swarm intelligence, hybrid\
    \ in-\ntelligence oriented by human–machine and brain–computer interaction technology,\
    \ cross-\nmedia inference intelligence, autonomous intelligent system, etc. The\
    \ “wisdom” of the\nsmart IoT system refers to the interconnection of people, information\
    \ space and physi-\ncal space, and the digitalization, IoT, servitization (cloud),\
    \ collaboration, customization,\nﬂexibility, greenness, and intelligence of the\
    \ layered and progressive system [67].\nThe Internet of Things is evolving into\
    \ the next generation. Under the role of 5G, the\nInternet of Things combined\
    \ with big data, machine learning, cloud services, and so on, will\nhave intelligent\
    \ characteristics. It can make the physical process and the information world\n\
    deep integration. The network level of the Internet of Things mainly includes\
    \ monitoring,\ndetection, computing, service, and control from bottom to top,\
    \ and these connotations will\nalso undergo profound changes.\n3.1. 5G Smart Agricultural\
    \ IoT 2.0 Architecture\nWith the rapid development of video business and various\
    \ vertical business applica-\ntions in smart agriculture, centralized data storage\
    \ and processing modes will face difﬁcult\nbottlenecks and pressures. The existing\
    \ Internet of Things architecture is difﬁcult to meet\nthe data return of big\
    \ data, which easily deteriorates network indicators and affects user\nexperience.\
    \ In this case, data processing capabilities and services need to be provided\n\
    near the edge of the network where the data are generated. With the development\
    \ of\n5G and the availability of relevant business requirements and network conditions,\
    \ edge\ncomputing has gradually achieved great development. Agricultural IoT is\
    \ evolving to\nSmart Agricultural IoT 2.0, where edge computing can alleviate\
    \ these defects of centralized\nIoT, and transfer computing tasks to the edge\
    \ service side to signiﬁcantly improve delay\nand energy consumption, especially\
    \ for delay and energy-sensitive IoT applications.\n5G IoT for smart agriculture\
    \ achieves optimal resource allocation through network\nslicing, SDN/VFN, and\
    \ other technologies. However, due to a large amount of sensing\ndata in the smart\
    \ agriculture scene, the real-time requirement is high. With the increase in\n\
    terminal computing power, the network architecture for smart agriculture will\
    \ also change.\nThe architecture of a smart IoT system is shown in Figure 11.\n\
    5G-based agricultural IoT can be implemented by deploying edge computing based\
    \ on\napplication needs. Edge computing migrates IT resources, such as computing\
    \ and storage,\nfrom traditional cloud data centers to users. IT shortens the\
    \ physical distance between\nusers and IT resources, achieves lower data interaction\
    \ delay, and saves network trafﬁc.\nThis provides users with low latency and high\
    \ stability of IT solutions. Edge computation\ndepends on edge nodes. The requirements\
    \ of edge nodes for smart agricultural IoT are\nnot strictly regulated. Compared\
    \ with the general sensor node thought and its computing\npower, the communication\
    \ ability is stronger. The deployment position is usually at the\nend of the network,\
    \ that is, the application site. After IoT edge applications are deployed,\nedge\
    \ nodes serve as extensions of remote IoT platforms on devices. Devices are managed\n\
    through cloud-edge collaboration. Edge nodes can provide computing and management\n\
    services for nearby devices, such as local management of low-latency services,\
    \ local control,\nand rule execution when disconnected from the cloud. The device\
    \ accesses the edge node\nand ﬁnally uploads data to the remote IoT platform through\
    \ the edge node, as shown in\nFigure 12.\nElectronics 2023, 12, 2336\n14 of 46\n\
    energy consumption, especially for delay and energy-sensitive IoT applications.\
    \ \n5G IoT for smart agriculture achieves optimal resource allocation through\
    \ netwo\nslicing, SDN/VFN, and other technologies. However, due to a large amount\
    \ of sensi\ndata in the smart agriculture scene, the real-time requirement is\
    \ high. With the increase\nterminal computing power, the network architecture\
    \ for smart agriculture will al\nchange. The architecture of a smart IoT system\
    \ is shown in Figure 11. \nPrivate \nnetwork \ntechnology\nInternet \nof Things\n\
    Smart sensor \nnetwork\nEthernet\nNew sensing unit\nRFID/Smart sensor/Camera coil,\
    \ GPS, Remote sensing, Radar, QR code\nEdge \ncomputing\nPerception and \nimplementation\
    \ \nof smart \nagriculture\nFog computing\nCloud \ncomputing\nSmart \nagriculture\
    \ \napplication\nEdge computing node \ndomain gateway\nPerception&M\nonitoring\n\
    Detection and \ncalculation\nComputing\nCloud \nservice\nControl\nSmart information\
    \ fusion \nand processing\n \nFigure 11. Architecture of the smart Internet of\
    \ Things system based on 5G. \n5G-based agricultural IoT can be implemented by\
    \ deploying edge computing bas\non application needs. Edge computing migrates\
    \ IT resources, such as computing and sto\nage, from traditional cloud data centers\
    \ to users. IT shortens the physical distance betwe\nusers and IT resources, achieves\
    \ lower data interaction delay, and saves network traf\nThis provides users with\
    \ low latency and high stability of IT solutions. Edge computati\ndepends on edge\
    \ nodes. The requirements of edge nodes for smart agricultural IoT a\nnot strictly\
    \ regulated. Compared with the general sensor node thought and its computi\npower,\
    \ the communication ability is stronger. The deployment position is usually at\
    \ t\nend of the network, that is, the application site. After IoT edge applications\
    \ are deploye\nedge nodes serve as extensions of remote IoT platforms on devices.\
    \ Devices are manag\nthrough cloud-edge collaboration. Edge nodes can provide\
    \ computing and manageme\nservices for nearby devices, such as local management\
    \ of low-latency services, lo\nFigure 11. Architecture of the smart Internet of\
    \ Things system based on 5G.\nElectronics 2023, 12, x FOR PEER REVIEW \ncontrol,\
    \ and rule execution when disconnected from the cloud. The de\nedge node and finally\
    \ uploads data to the remote IoT platform through \nshown in Figure 12. \n***\n\
    ***\n***\n***\n***\n***\n***\n***\n***\n***\n***\n***\n***\n***\n***\n***\n***\n\
    ***\n***\n***\n***\n***\nField agriculture\nPlant factory\nSmart breeding\nEdge\
    \ Server\nEdge Server\nEdge Server\n5G gateway\n5G gateway\n5G gateway\nRemote\
    \ cloud \nservice\n \nFigure 12. Application scenario diagram of the edge computing\
    \ system of the a\nof Things. \n3.1.1. Personalized Service Network Slice in 5G\
    \ Intelligent Agricultural \nThings \nRequirements on network characteristics\
    \ (network speed, delay, n\nFigure 12. Application scenario diagram of the edge\
    \ computing system of the agricultural Internet\nof Things.\nElectronics 2023,\
    \ 12, 2336\n15 of 46\n3.1.1. Personalized Service Network Slice in 5G Intelligent\
    \ Agricultural Internet of Things\nRequirements on network characteristics (network\
    \ speed, delay, number of connec-\ntions, energy consumption, etc.) in different\
    \ agricultural application scenarios are different,\nand some are even contradictory.\
    \ For example, agricultural high-deﬁnition video surveil-\nlance cares about the\
    \ picture quality, and the overall delay of a few seconds or even more\nthan ten\
    \ seconds is not felt. In remote agricultural machinery driving, a delay of more\n\
    than 10 ms will seriously affect safety. Therefore, the purpose of splitting and\
    \ reﬁning the\nnetwork is to respond more ﬂexibly to the needs of smart agriculture\
    \ scenarios. Based on 5G\ntechnology, Network Slicing can be implemented, and\
    \ the Network can be divided into N\nlogical networks according to application\
    \ scenarios as shown in Figure 13. Different logical\nnetworks serve different\
    \ scenarios. Because of the diversiﬁcation of demand, networks\nneed diversiﬁcation.\
    \ The network must be ﬂexible because it needs to be sliced. Because\nthey move\
    \ ﬂexibly, the connections between networks also change ﬂexibly [68].\n \nThings\
    \ \nRequirements on network characteristics (network speed, delay, number of \n\
    tions, energy consumption, etc.) in different agricultural application scenarios\
    \ ar\nent, and some are even contradictory. For example, agricultural high-definition\
    \ vi\nveillance cares about the picture quality, and the overall delay of a few\
    \ seconds \nmore than ten seconds is not felt. In remote agricultural machinery\
    \ driving, a d\nmore than 10 ms will seriously affect safety. Therefore, the purpose\
    \ of splitting an\ning the network is to respond more flexibly to the needs of\
    \ smart agriculture sc\nBased on 5G technology, Network Slicing can be implemented,\
    \ and the Network\ndivided into N logical networks according to application scenarios\
    \ as shown in Fi\nDifferent logical networks serve different scenarios. Because\
    \ of the diversificatio\nmand, networks need diversification. The network must\
    \ be flexible because it nee\nsliced. Because they move flexibly, the connections\
    \ between networks also change\n[68]. \nNetwork slicing is a logical network partitioning\
    \ scheme implemented to m\ndifferent requirements of various applications, which\
    \ can ensure resource isolat\nservice guarantee between slices where different\
    \ services are located [69]. \nCrop growth \nmonitoring VWSN\nMoisture detection\
    \ \nNB IoT\nAgricultural UAV \nspraying formation\nRobot pest inspection \nformation\n\
    Slice 1 Video \nPerception\nSlice 2 narrowband \nsmall data\nOther slices\n5G\n\
    Intelligent agriculture IoT\nSlice 3 High real-time data \ntransmission service\n\
    \  \n \nFigure 13. Smart agriculture 5G-IoT network slice.\nNetwork slicing is\
    \ a logical network partitioning scheme implemented to meet the\ndifferent requirements\
    \ of various applications, which can ensure resource isolation and\nservice guarantee\
    \ between slices where different services are located [69].\n3.1.2. The 5G Intelligent\
    \ Agricultural Internet of Things (IoT) System Is Integrated with\n“Cloud, Network,\
    \ Edge, and End”\nThe impact of 5G on the Internet of Things for smart agriculture,\
    \ including the system\nnetwork architecture, will bring new changes. 5G intelligent\
    \ agricultural Internet of Things\nwill realize the integration of “cloud–network–edge–end”\
    \ and profoundly change the\nagricultural production form [70].\nUnder the role\
    \ of 5G, the future intelligent agricultural Internet of Things must be a\nsystem\
    \ of cloud-net-edge-end deep integration as shown in Figure 14. Realize the deep\
    \ in-\ntegration and control of agricultural production and information world.\
    \ The cloud realizes\nthe cloud of services and data, and the network includes\
    \ all kinds of networks represented\nby 5G. The self-consistency of intelligent\
    \ agricultural IoT is realized by combining edge\ncomputing and terminal nodes\
    \ [71].\nElectronics 2023, 12, 2336\n16 of 46\nUnder the role of 5G, the future\
    \ intelligent agricultural Internet of Things must be a \nsystem of cloud-net-edge-end\
    \ deep integration as shown in Figure 14. Realize the deep \nintegration and control\
    \ of agricultural production and information world. The cloud real-\nizes the\
    \ cloud of services and data, and the network includes all kinds of networks repre-\n\
    sented by 5G. The self-consistency of intelligent agricultural IoT is realized\
    \ by combining \nedge computing and terminal nodes [71]. \nCloud\nEdge \ncomputing\n\
    Sense \ndevice\nInterface\nComputing \nresource\nStorage \nresources\nNetwork\
    \ \nresource\nComputing/Network/Storage API\nControl area\nFunctional \nmodule\n\
    Analysis field\nFunctional \nmodule\nOptimization field\nFunctional module\nEdge\
    \ node:\nEdge gateway\nEdge controller\nEdge server\nEdge sensor\n  \nModel based\
    \ business \norchestration\nDirect resource call\nManagement Service\nSmart agriculture\
    \ Internet of Things application\nCloud service\n5G \n \nFigure 14. 5G-IoT service\
    \ architecture of cloud-edge collaborative smart agriculture. \n3.2. Perception\
    \ of Deep Fusion of 5G-Intelligent Agricultural Internet of Things \nSmart agriculture\
    \ is a form of deep intelligence of agricultural production and a form \nof deep\
    \ integration of the physical production process and information world. First,\
    \ the \nsmart agricultural IoT requires comprehensive and in-depth monitoring\
    \ of agricultural \nproduction processes and objects. This requires the support\
    \ of 5G, the intensive access of \nmassive sensing devices, the transmission of\
    \ large amounts of data, and the support of the \noperating system basic software\
    \ platform suitable for the new generation of IoT systems. \nThe end devices will\
    \ evolve. Meanwhile, the communication modules and architectures \nwill change.\
    \ \n3.2.1. Intelligent Agricultural IoT Sensing Device Based on 5G \nIn order\
    \ to adapt to the performance of the smart agricultural Internet of Things and\
    \ \nthe advantages of 5G, such as high speed, high density, low delay, low power\
    \ consump-\ntion, and wide coverage, the software and hardware of traditional\
    \ sensing devices need \nto be changed. \nThe carrier bandwidth of 5G communication\
    \ varies from 180 K to 200 M [72]. Com-\nmunication rates also range from a multi-point\
    \ uplink rate of 56 kbps for narrowband IoT \nto a maximum peak rate of 10 Gbps.\
    \ The 180 K carrier bandwidth is specifically targeted \nat low-rate NB-IoT applications,\
    \ featuring strong signal strength, strong penetration, and \ngood coverage radius\
    \ and depth coverage. It is mainly suitable for some IoT terminal \nFigure 14.\
    \ 5G-IoT service architecture of cloud-edge collaborative smart agriculture.\n\
    3.2. Perception of Deep Fusion of 5G-Intelligent Agricultural Internet of Things\n\
    Smart agriculture is a form of deep intelligence of agricultural production and\
    \ a form\nof deep integration of the physical production process and information\
    \ world. First, the\nsmart agricultural IoT requires comprehensive and in-depth\
    \ monitoring of agricultural\nproduction processes and objects. This requires\
    \ the support of 5G, the intensive access of\nmassive sensing devices, the transmission\
    \ of large amounts of data, and the support of the\noperating system basic software\
    \ platform suitable for the new generation of IoT systems.\nThe end devices will\
    \ evolve. Meanwhile, the communication modules and architectures\nwill change.\n\
    3.2.1. Intelligent Agricultural IoT Sensing Device Based on 5G\nIn order to adapt\
    \ to the performance of the smart agricultural Internet of Things and\nthe advantages\
    \ of 5G, such as high speed, high density, low delay, low power consumption,\n\
    and wide coverage, the software and hardware of traditional sensing devices need\
    \ to\nbe changed.\nThe carrier bandwidth of 5G communication varies from 180 K\
    \ to 200 M [72]. Com-\nmunication rates also range from a multi-point uplink rate\
    \ of 56 kbps for narrowband IoT\nto a maximum peak rate of 10 Gbps. The 180 K\
    \ carrier bandwidth is speciﬁcally targeted\nat low-rate NB-IoT applications,\
    \ featuring strong signal strength, strong penetration, and\ngood coverage radius\
    \ and depth coverage. It is mainly suitable for some IoT terminal\napplications\
    \ with low data rates and most of the time in hibernation state. Such applica-\n\
    tions are widely used in smart agriculture and many other applications, such as\
    \ ecological\nenvironment monitoring, because many plants and animals have long\
    \ growth cycles and\nslow changes. There are four typical applications of NB-IoT,\
    \ as shown in Table 6.\nSecondly, such applications mainly change the hardware\
    \ of sensor nodes in terms of\nantenna communication module and low-power design\
    \ [73,74]. The module of the terminal\nnode device based on NB-IoT will also change\
    \ correspondingly, as shown in Figure 15.\nElectronics 2023, 12, 2336\n17 of 46\n\
    Table 6. Four typical business types of NB-IoT.\nType\nDescribe\nScene\nAutonomous\
    \ exception\nreporting service type\nFor example, the notiﬁcation of smoke and\
    \ fog alarm\ndetector and smart electricity meter power failure, the\nminimum\
    \ data demand for uplink data (in the order of\ncross knots), and the cycle is\
    \ usually in years and months.\nFishery breeding, precision\nagriculture\nBusiness\
    \ type of independent\nperiodic report\nFor example, the measurement report of\
    \ intelligent utilities\n(gas/water/electricity), intelligent agriculture, intelligent\n\
    environment, etc., the uplink demand for small data volume\n(hundreds of bytes),\
    \ and the cycle is mostly in days\nand hours.\nPlant moisture, environmental\n\
    monitoring, climate monitoring\nNetwork instruction service\ntype\nFor example,\
    \ when the device is turned on/off, it triggers\nsending an uplink report, requests\
    \ meter reading and\nrequires minimal downlink data (in the order of cross knots).\n\
    The cycle is usually in days and hours.\nAutomatic irrigation, automatic\noxygenation,\
    \ etc.\nSoftware update business type\nFor example, software patches/updates require\
    \ a large\namount of data (kilobyte level) for uplink and downlink,\nand the cycle\
    \ is usually in days and hours.\nRemote System Update\nporting service \ntype\
    \ \nof cross knots), and the cycle is usually in years and \nmonths. \nture \n\
    Business type \nof independ-\nent periodic \nreport \nFor example, the measurement\
    \ report of intelligent \nutilities (gas/water/electricity), intelligent agriculture,\
    \ \nintelligent environment, etc., the uplink demand for \nsmall data volume (hundreds\
    \ of bytes), and the cycle \nis mostly in days and hours. \nPlant moisture, en-\n\
    vironmental moni-\ntoring, climate \nmonitoring \nNetwork in-\nstruction ser-\n\
    vice type \nFor example, when the device is turned on/off, it trig-\ngers sending\
    \ an uplink report, requests meter reading \nand requires minimal downlink data\
    \ (in the order of \ncross knots). The cycle is usually in days and hours. \n\
    Automatic irriga-\ntion, automatic ox-\nygenation, etc. \nSoftware up-\ndate business\
    \ \ntype \nFor example, software patches/updates require a large \namount of data\
    \ (kilobyte level) for uplink and down-\nlink, and the cycle is usually in days\
    \ and hours. \nRemote System \nUpdate \nSecondly, such applications mainly change\
    \ the hardware of sensor nodes in terms of \nantenna communication module and\
    \ low-power design [73,74]. The module of the termi-\nnal node device based on\
    \ NB-IoT will also change correspondingly, as shown in Figure \n15. \nPower supply\
    \ module\nSensor node\nData \nacquisition \nmodule\nMicrocontroller/\nMCU\nWireless\
    \ \nprocessing \nmodule\nWireless \ncommunication \nmodule\nStorage\nPower supply\
    \ module\nSensor node\nData \nacquisition \nmodule\nMicrocontroller/\nMCU\nWireless\
    \ \nprocessing \nmodule\nNB IoT \ncommunication \nmodule\nStorage\nNB-SIM \ncard\n\
    \ \nFigure 15. Sensing device communication module changes. \nThe communication\
    \ module is usually made of off-the-shelf modules or selected \nchips for design.\
    \ NB-IoT chips can be used by carriers of China Telecom, China Mobile, \nand China\
    \ Unicom. At the same time, Sim cards are required to order corresponding data\
    \ \nplans. \nMany application scenarios facing smart agriculture also require\
    \ large bandwidth \ndata transmissions, such as video and VR. 5G-oriented sensor\
    \ nodes can select 5G-ori-\nented high-bandwidth communication modules. Its communication\
    \ module baseband \nchips require specialized chips, such as Qualcomm, Huawei,\
    \ etc. Due to the high data rate, \nthe number and type of corresponding sensors\
    \ can also be diverse. In the meantime, the \ncorresponding processor, memory,\
    \ and power supply modules are completely different, \nas shown in Figure 16.\
    \ \nFigure 15. Sensing device communication module changes.\nThe communication\
    \ module is usually made of off-the-shelf modules or selected chips\nfor design.\
    \ NB-IoT chips can be used by carriers of China Telecom, China Mobile, and\nChina\
    \ Unicom. At the same time, Sim cards are required to order corresponding data\
    \ plans.\nMany application scenarios facing smart agriculture also require large\
    \ bandwidth\ndata transmissions, such as video and VR. 5G-oriented sensor nodes\
    \ can select 5G-oriented\nhigh-bandwidth communication modules. Its communication\
    \ module baseband chips\nrequire specialized chips, such as Qualcomm, Huawei,\
    \ etc. Due to the high data rate,\nthe number and type of corresponding sensors\
    \ can also be diverse. In the meantime, the\ncorresponding processor, memory,\
    \ and power supply modules are completely different, as\nshown in Figure 16.\n\
    Sensor nodes are equipped with 5G high-rate baseband chips for high-rate data\
    \ com-\nmunication. Multiple sensors can be integrated into appropriate scenarios\
    \ to improve\nthe integration degree, reduce the number of nodes and optimize\
    \ the network architec-\nture [75,76]. For example, the smart insecticidal lamp\
    \ can integrate a variety of sensors,\nas shown in Figure 17. When multiple sensors\
    \ are integrated, the bandwidth of the data\nstream changes. In the 5G scenario,\
    \ the architecture of the Internet of Things changes ac-\ncordingly, replacing\
    \ the traditional Zigbee network, etc. [77]. The change of communication\nmodule\
    \ will lead to an overall change of hardware. For example, low-power design, the\n\
    architecture of the main control chip, software change, power supply system design,\
    \ sensor\nintegration, etc. [78].\nElectronics 2023, 12, 2336\n18 of 46\nElectronics\
    \ 2023, 12, x FOR PEER REVIEW \n \nPower supply module\nSense Module \n1\nMicrocontroller/\n\
    MCU\nWireless \nprocessing \nmodule\n5G baseband \nchip\nMass storage\nSIM \n\
    card\nSense Module \n2\nSense Module \n3\nSense \nModule  \n4K Video Module\n\
    \ \n \nFigure 16. Sensor node composition model facing high rate facing 5G. \n\
    Sensor nodes are equipped with 5G high-rate baseband chips for high-rate da\n\
    munication. Multiple sensors can be integrated into appropriate scenarios to imp\n\
    integration degree, reduce the number of nodes and optimize the network arch\n\
    [75,76]. For example, the smart insecticidal lamp can integrate a variety of sen\n\
    shown in Figure 17. When multiple sensors are integrated, the bandwidth of t\n\
    stream changes. In the 5G scenario, the architecture of the Internet of Things\
    \ cha\ncordingly, replacing the traditional Zigbee network, etc. [77]. The change\
    \ of com\ntion module will lead to an overall change of hardware. For example,\
    \ low-power\nthe architecture of the main control chip, software change, power\
    \ supply system\nsensor integration, etc. [78]. \nScreen\nSoil moisture\nSoil\
    \ temperature and humidity\nEvaporation\nSoil PH\nRainfall\nPhotosynthetically\
    \ active radiation\nWind speed/direction\nSoil electrical conductivity\n \nFigure\
    \ 17. Multi-sensor system. \n3.2.2. 5G Intelligent Agricultural IoT Operating\
    \ System \nWith 5G, the hardware of IoT sensor nodes for smart agriculture has\
    \ change\nder to adapt to the application scenario, the corresponding software\
    \ system wi\nfected and changed. The vision goal of the Internet of Things with\
    \ 5G is the inter\ntion and interconnectivity of everything However the current\
    \ operating system\nFigure 16. Sensor node composition model facing high rate\
    \ facing 5G.\n4K Video Module\n \nFigure 16. Sensor node composition model facing\
    \ high rate f\nSensor nodes are equipped with 5G high-rate base\nmunication. Multiple\
    \ sensors can be integrated into ap\nintegration degree, reduce the number of\
    \ nodes and \n[75,76]. For example, the smart insecticidal lamp can\nshown in\
    \ Figure 17. When multiple sensors are integ\nstream changes. In the 5G scenario,\
    \ the architecture of\ncordingly, replacing the traditional Zigbee network, et\n\
    tion module will lead to an overall change of hardwar\nthe architecture of the\
    \ main control chip, software cha\nsensor integration, etc. [78]. \nScreen\nSoil\
    \ moisture\nSoil temperature and humidity\nEvaporation\nSoil PH\nRainfall\nPhotosynthetically\
    \ active radiation\nWind speed/direction\nSoil electrical conductivity\n \nFigure\
    \ 17. Multi-sensor system. \n3.2.2. 5G Intelligent Agricultural IoT Operating\
    \ System\nWith 5G, the hardware of IoT sensor nodes for sm\nder to adapt to the\
    \ application scenario, the correspo\nfected and changed. The vision goal of the\
    \ Internet of \ntion and interconnectivity of everything. However, the\nlt t\n\
    t thi\nl\nh\nth\nl\nk\nf i t\nFigure 17. Multi-sensor system.\n3.2.2. 5G Intelligent\
    \ Agricultural IoT Operating System\nWith 5G, the hardware of IoT sensor nodes\
    \ for smart agriculture has changed. In order\nto adapt to the application scenario,\
    \ the corresponding software system will be affected\nand changed. The vision\
    \ goal of the Internet of Things with 5G is the interconnection\nand interconnectivity\
    \ of everything. However, the current operating system is difﬁcult to\nsupport\
    \ this goal, such as the lack of interoperability of a lightweight operating system\
    \ [79].\nThe status quo of the Internet of Things operating system is shown in\
    \ Figure 18.\nElectronics 2023, 12, 2336\n19 of 46\nElectronics 2023, 12, x FOR\
    \ PEER REVIEW \n18 of 46 \n \n \nThe connection volume \nof IoT equipment has\
    \ \nreached 10 billion\nSoftware and hardware \ncoupling is seriously lagging\
    \ \nbehind the industry \nstandard\nThe R&D cycle of the \noperating system is\
    \ 4-\n5 years\nThe cost of software development \nand system integration R&D of\
    \ a \nsingle SKU is more than 300000 \ndollars\nMany terminals\nSystem mismatch\n\
    Long R&D cycle\nHigh R&D cost\nMany brands\nIncompatible\nThe products cannot\
    \ be linked \nwith each other, and the sense of \nuse of intelligent operation\
    \ is poor\nThe Internet of Things giant has \nformed a monopoly and the \nmarket\
    \ competition is insufficient\n \nFigure 18. The status quo of the Internet of\
    \ Things operating system. \nThe current Internet of Things operating system has\
    \ made great progress [80]. Inter-\nnet of Things operating system brands, and\
    \ complementary compatibility, restrict the \ngreat development of the Internet\
    \ of Things. In order to achieve the goal of the Internet of \neverything in the\
    \ 5G scenario, its operating system will need to change in the future. \nA typical\
    \ IoT system is shown in the following Figure 19. Among them, the operating \n\
    system is an important middle part applied to the bottom layer, which is related\
    \ to the \nkey to cloud interconnection and is the key to realizing the seamless\
    \ interaction between \npeople and things. Future IoT operating system requirements\
    \ are shown in Figure 20. \nAgentTiny\nLiteOS\nMCU\nCloud\nDevice\nOceanConnet\
    \ \nIoT Platform\nOther IoT \nPlatform\n \nFigure 19. Huawei 5G IoT system. \n\
    Cross \nplatform\nInteroperabi\nlity\nlow cost\nStrong \nsecurity\nCloud\nHeterogeneous\
    \ \nterminal\n \nFigure 20. Future IoT operating system requirements. \nMany scholars\
    \ have conducted many beneficial studies on the operating system of \nthe Internet\
    \ of Things [81,82], mostly for applications, real-time scheduling, kernel design,\
    \ \nand so on. Less attention is paid to the architecture of future sensor operating\
    \ systems. It \nsummarized the current major IoT operating systems in Table 7.\
    \ In the future, under the \ncondition that the data bandwidth is satisfied, highly\
    \ intelligent is the due connotation of \nsmart agriculture. The concept of a\
    \ sensor node is more general, as there is not only a \nFigure 18. The status\
    \ quo of the Internet of Things operating system.\nThe current Internet of Things\
    \ operating system has made great progress [80]. Internet\nof Things operating\
    \ system brands, and complementary compatibility, restrict the great\ndevelopment\
    \ of the Internet of Things. In order to achieve the goal of the Internet of\n\
    everything in the 5G scenario, its operating system will need to change in the\
    \ future.\nA typical IoT system is shown in the following Figure 19. Among them,\
    \ the operating\nsystem is an important middle part applied to the bottom layer,\
    \ which is related to the key\nto cloud interconnection and is the key to realizing\
    \ the seamless interaction between people\nand things. Future IoT operating system\
    \ requirements are shown in Figure 20.\nThe connection volume \nof IoT equipment\
    \ has \nreached 10 billion\nSoftware and hardware \ncoupling is seriously lagging\
    \ \nbehind the industry \nstandard\nThe R&D cycle of the \noperating system is\
    \ 4-\n5 years\nThe cost of software development \nand system integration R&D of\
    \ a \nsingle SKU is more than 300000 \ndollars\nMany terminals\nSystem mismatch\n\
    Long R&D cycle\nHigh R&D cost\nMany brands\nIncompatible\nThe products cannot\
    \ be linked \nwith each other, and the sense of \nuse of intelligent operation\
    \ is poor\nThe Internet of Things giant has \nformed a monopoly and the \nmarket\
    \ competition is insufficient\n \nFigure 18. The status quo of the Internet of\
    \ Things operating system. \nThe current Internet of Things operating system has\
    \ made great progress [80]\nnet of Things operating system brands, and complementary\
    \ compatibility, restr\ngreat development of the Internet of Things. In order\
    \ to achieve the goal of the Inte\neverything in the 5G scenario, its operating\
    \ system will need to change in the futur\nA typical IoT system is shown in the\
    \ following Figure 19. Among them, the ope\nsystem is an important middle part\
    \ applied to the bottom layer, which is related\nkey to cloud interconnection\
    \ and is the key to realizing the seamless interaction be\npeople and things.\
    \ Future IoT operating system requirements are shown in Figure\nAgentTiny\nLiteOS\n\
    MCU\nCloud\nDevice\nOceanConnet \nIoT Platform\nOther IoT \nPlatform\n \nFigure\
    \ 19. Huawei 5G IoT system. \nCross \nplatform\nInteroperabi\nlity\nlow cost\n\
    Strong \nsecurity\nCloud\nHeterogeneous \nterminal\n \nFigure 20. Future IoT operating\
    \ system requirements. \nMany scholars have conducted many beneficial studies\
    \ on the operating sys\nthe Internet of Things [81,82], mostly for applications,\
    \ real-time scheduling, kernel d\nand so on. Less attention is paid to the architecture\
    \ of future sensor operating syst\nsummarized the current major IoT operating\
    \ systems in Table 7. In the future, und\ncondition that the data bandwidth is\
    \ satisfied, highly intelligent is the due connota\nsmart agriculture. The concept\
    \ of a sensor node is more general, as there is not \nFigure 19. Huawei 5G IoT\
    \ system.\nThe connection volume \nof IoT equipment has \nreached 10 billion\n\
    Software and hardware \ncoupling is seriously lagging \nbehind the industry \n\
    standard\nThe R&D cycle of the \noperating system is 4-\n5 years\nThe cost of\
    \ software development \nand system integration R&D of a \nsingle SKU is more\
    \ than 300000 \ndollars\nMany terminals\nSystem mismatch\nLong R&D cycle\nHigh\
    \ R&D cost\nMany brands\nIncompatible\nThe products cannot be linked \nwith each\
    \ other, and the sense of \nuse of intelligent operation is poor\nThe Internet\
    \ of Things giant has \nformed a monopoly and the \nmarket competition is insufficient\n\
    \ \nFigure 18. The status quo of the Internet of Things operating system. \nThe\
    \ current Internet of Things operating system has made great progress [80]\nnet\
    \ of Things operating system brands, and complementary compatibility, restr\n\
    great development of the Internet of Things. In order to achieve the goal of the\
    \ Inte\neverything in the 5G scenario, its operating system will need to change\
    \ in the futur\nA typical IoT system is shown in the following Figure 19. Among\
    \ them, the ope\nsystem is an important middle part applied to the bottom layer,\
    \ which is related\nkey to cloud interconnection and is the key to realizing the\
    \ seamless interaction be\npeople and things. Future IoT operating system requirements\
    \ are shown in Figure\nAgentTiny\nLiteOS\nMCU\nCloud\nDevice\nOceanConnet \nIoT\
    \ Platform\nOther IoT \nPlatform\n \nFigure 19. Huawei 5G IoT system. \nCross\
    \ \nplatform\nInteroperabi\nlity\nlow cost\nStrong \nsecurity\nCloud\nHeterogeneous\
    \ \nterminal\n \nFigure 20. Future IoT operating system requirements. \nMany scholars\
    \ have conducted many beneficial studies on the operating sys\nthe Internet of\
    \ Things [81,82], mostly for applications, real-time scheduling, kernel d\nand\
    \ so on. Less attention is paid to the architecture of future sensor operating\
    \ syst\nsummarized the current major IoT operating systems in Table 7. In the\
    \ future, und\ncondition that the data bandwidth is satisfied, highly intelligent\
    \ is the due connota\nsmart agriculture. The concept of a sensor node is more\
    \ general, as there is not \nFigure 20. Future IoT operating system requirements.\n\
    Many scholars have conducted many beneﬁcial studies on the operating system of\n\
    the Internet of Things [81,82], mostly for applications, real-time scheduling,\
    \ kernel design,\nand so on. Less attention is paid to the architecture of future\
    \ sensor operating systems. It\nsummarized the current major IoT operating systems\
    \ in Table 7. In the future, under the\nElectronics 2023, 12, 2336\n20 of 46\n\
    condition that the data bandwidth is satisﬁed, highly intelligent is the due connotation\n\
    of smart agriculture. The concept of a sensor node is more general, as there is\
    \ not only a\nsingle perception function but it may also have an executive function,\
    \ etc., based on edge\ncomputing, etc., to achieve node interoperability.\nTable\
    \ 7. List of IoT operating systems.\nIoT OS\nDescription/Provider\nNetworked Operating\
    \ System\nDescription/Provider\nBrillo [80]\nGoogle’s solution for building\n\
    connected devices\nLiteOS\nHuawei\nmbedOS\nARM Internet of Things device platform\n\
    TinyOS\nTencent\nRIoT [83]\nInternet of Things friendly operating system\nAliOS\
    \ Things\nAlibaba\nContiki [84]\nOpen source IoT operating system\nRT-Thread\n\
    Real time operating\nsystem (open source)\nZephyr\nScalable real-time operating\
    \ system for\nresource constrained systems\nWindows 10 IoT Core\nWindows\nNuttx\n\
    Standard compliant and small footprint\nreal-time operating system\nWatchOS\n\
    Apple\nWith an IoT operating system, from service connection to service application,\
    \ the\nultimate goal is service intelligence. In smart agriculture, with a 5G\
    \ scenario, the operating\nsystem of the Internet of Things also needs to serve\
    \ smart agriculture. Fuchsia OS and\nHarmony OS were developed by Google and Huawei.\
    \ The goal is to be able to run on a\nvariety of different hardware platforms,\
    \ with distributed operating systems based on the\nmicrokernel structure and running\
    \ more efﬁciently.\n3.2.3. Large-Scale Terminal Access of 5G Smart Agricultural\
    \ Monitoring Terminals\nA large number of sensing devices will be deployed in\
    \ the smart agricultural IoT for\nbreeding moisture monitoring, ﬁne agriculture,\
    \ and other scenarios. How to access massive\nterminals in LPWA for 5G low-power\
    \ wide area networks [85] is a challenging problem.\nWith the continuous improvement\
    \ of the capabilities of the air interface at the access end,\nthe performance\
    \ bottleneck of the whole system is gradually reﬂected in the core end, edge\n\
    end, and other areas. Therefore, there must also be corresponding innovative technologies\n\
    at the core or edge end to meet the nearly demanding requirements of 5G IoT applications\n\
    in the future [86]. However, the existing cellular network core architecture is\
    \ not suitable\nfor the development of the Internet of Things.\nThe deployment\
    \ of 5G has created the possibility for large-scale and intensive IoT\ndeployment,\
    \ but there are also challenges concerning reliable access and data transmission\n\
    and processing, as shown in Figure 21.\n3.3. Reliable Data-Driven Detection of\
    \ 5G Smart Agricultural IoT\nBased on the various kinds of data acquired by the\
    \ massive sensing devices, they can\nbe detected and processed to serve the upper-layer\
    \ applications. These acquired termi-\nnal underlying data can be used to detect\
    \ complex events in the process of agricultural\nproduction, provide intelligent\
    \ decision-making for smart agricultural production, im-\nproving the degree of\
    \ intelligence. Secondly, based on the breakthrough of current data\nvolume acquisition,\
    \ the breakthrough of machine learning algorithms, and the innovation\nof communication\
    \ technology, all kinds of image processing based on machine learning\nare gradually\
    \ popularized in smart agriculture. These lay the foundation for intelligent\n\
    agricultural production.\nElectronics 2023, 12, 2336\n21 of 46\n3.3.1. Complex\
    \ Event Detection in Agricultural Production\nComplex event detection for agricultural\
    \ production process [87]. Complex event\ndetection abstracts business data into\
    \ a sequence of events. Through the complex event\ndescription method, the potentially\
    \ valuable composite data are described as a speciﬁc\nevent-matching structure.\
    \ The complex event detection engine then detects the event\nsequence satisfying\
    \ the matching structure from a large number of event streams and\nﬁnally outputs\
    \ the data fusion results. The basic strategy of the event detection engine is\n\
    that all Events in the time window are called candidate Events, and the candidate\
    \ Events\ngenerate Matching sets according to the rules.\nectronics 2023, 12,\
    \ x FOR PEER REVIEW \nSupplier\nWarehouse\nCLOUD\n \nFigure 21. 5G large-scale\
    \ access of smart agricultural Internet of Things perce\n3.3. Reliable Data-Driven\
    \ Detection of 5G Smart Agricultural IoT \nBased on the various kinds of data\
    \ acquired by the massive sensin\nbe detected and processed to serve the upper-layer\
    \ applications. Thes\nunderlying data can be used to detect complex events in\
    \ the process \nduction, provide intelligent decision-making for smart agricultural\
    \ p\ning the degree of intelligence. Secondly, based on the breakthrough \nume\
    \ acquisition, the breakthrough of machine learning algorithms, an\ncommunication\
    \ technology, all kinds of image processing based on m\ngradually popularized\
    \ in smart agriculture. These lay the foundation\ncultural production. \n3.3.1.\
    \ Complex Event Detection in Agricultural Production \nComplex event detection\
    \ for agricultural production process [87]\ntection abstracts business data into\
    \ a sequence of events. Through the\nscription method, the potentially valuable\
    \ composite data are des\nFigure 21. 5G large-scale access of smart agricultural\
    \ Internet of Things perception terminal.\nThese data can be multimodal structural\
    \ and unstructured types of data. They are\nwidely used in smart agriculture scenarios.\
    \ When the sensing data are rich enough, the\ncomplex event rules can be established\
    \ through various moisture data and crop growth\nmodels to determine whether drip\
    \ irrigation and fertilization are needed [88,89]. In ﬁsh\nfarming, data collected\
    \ by various sensor devices deployed in ponds are used to determine\nwhether there\
    \ is a lack of oxygen or other complex events, and so on.\nThe detection conditions\
    \ of complex events ﬁrstly need rich physical world data, and\nenough sensing\
    \ devices need to be deployed so that various relationships can be discovered.\n\
    Second, complex computational processing power is required. For pattern matching\
    \ and\nso on, we need quick calculation and judgment. In addition, some complex\
    \ event detection\nis real-time, and these requirements become feasible with 5G.\n\
    3.3.2. Depth Detection of Pests and Diseases Based on Machine Learning\nWith the\
    \ development of information technology, methods based on machine learning\nhave\
    \ been widely used in agricultural production in recent years. Many scholars combine\n\
    image processing with pattern recognition, and widely use it in crop disease and\
    \ pest\nrecognition. The color, shape, texture, and other parameters extracted\
    \ were screened and\noptimized. The linear classiﬁer, Bayesian decision theory,\
    \ fuzzy recognition, and other\npattern recognition techniques were used to identify\
    \ and classify various crop pests and\nElectronics 2023, 12, 2336\n22 of 46\n\
    diseases, which improved the recognition accuracy. Thus, the development of agricultural\n\
    informatization and precision was further promoted [90].\nAs an important branch\
    \ of machine learning, deep learning network is becoming\na hot technology with\
    \ its powerful data analysis ability. Deep learning networks can\ncontain hundreds\
    \ of hidden layers, and the features will be transformed a lot of times.\nDeep\
    \ learning can be applied to identify crop pests and disease targets. For achieving\n\
    the relationship ﬁtting of complex sample data, the core idea is not only to automatically\n\
    extract multi-layer feature representations from a large amount of data through\
    \ a variety of\nlinear and nonlinear transformations but also to complete the\
    \ task of feature extraction and\ntransformation using supervised and unsupervised\
    \ combined training methods [91]. Due\nto the structure of a deep neural network,\
    \ the error features extracted by the previous layer\nnetwork can be weakened\
    \ to a certain extent, and the complex function can be expressed\nwith fewer parameters.\
    \ The structure of the deep neural network will be more compact,\nwhich improves\
    \ the efﬁciency and performance of the network.\nIt is obvious that the current\
    \ methods with strong pattern recognition ability are\nparticularly dependent\
    \ on a large amount of data, which requires enough data to draw\nuseful conclusions.\
    \ The traditional agricultural IoT data are limited, which is challenging to\n\
    support the data collection needs of future smart agriculture development. The\
    \ introduction\nof 5G and smart agricultural IoT provides conditions for the collection\
    \ of massive data.\n3.4. Cloud Edge Fog Computing Fusion in 5G Intelligent Agricultural\
    \ Internet of Things\nIn future smart agricultural IoT, data will be extremely\
    \ abundant, and how to conduct\nanalysis and calculation from these data to guide\
    \ modern agricultural production is an\nimportant challenge.\nDue to the limitations\
    \ of volume and battery life, many mobile devices deployed in\nagricultural production\
    \ cannot meet the requirements of these applications in terms of\ncomputing, storage,\
    \ energy, and other resources. Therefore, Mobile Cloud Computing\n(MCC) technology\
    \ has been proposed. It provides reorganized computing resources for\nmobile devices\
    \ in the cloud platform, migrates data processing and storage to the cloud,\n\
    and reduces constraints on its own resources. With the development of smart agriculture,\n\
    massive data will be generated in the future to be analyzed, processed, and stored\
    \ in the\ncentral cloud [92]. At the same time, there may be a large number of\
    \ connections between\nsensing devices, and these MCCS cannot meet the demand.\
    \ New computing methods, such\nas edge computing and fog computing, will be integrated\
    \ into the intelligent agricultural\nIoT system [93]. Edge sensors no longer need\
    \ to continuously transmit various sensing\ndata to the data center. It can judge\
    \ the sensing data on its own, contacting the data center\nonly when there is\
    \ a signiﬁcant change in the reading to decide what action to take. Cloud\ncomputing\
    \ is suitable for non-real-time, long-period data, and business decision scenarios,\n\
    while edge computing plays an irreplaceable role in real-time, short-period data,\
    \ and local\ndecision-making. Edge computing and cloud computing are two important\
    \ supports for\nthe digital transformation of the industry. Their collaboration\
    \ in the network, business,\napplication, intelligence, and other aspects will\
    \ help support the agricultural IoT to create\ngreater value. Intelligent edge\
    \ computing based on 5G power can use the cloud for large-\nscale security conﬁguration,\
    \ deployment, the management of edge devices, and the ability\nto assign intelligence\
    \ based on device type and scenario, allowing intelligence to ﬂow\nbetween the\
    \ cloud and the edge. The edge computing model in smart agriculture is shown\n\
    in Figure 22.\nSecondly, with the continuous enrichment of data in smart agricultural\
    \ IoT, the tra-\nditional forms of computing will become richer and richer. Distributed\
    \ computing based\non cloud computing, fog computing, and other forms will be\
    \ deeply integrated with 5G\ncommunication capabilities and applied to smart agriculture.\
    \ Agriculture, for wisdom in\ngreenhouse cultivation, oriented precision fertilization,\
    \ aquaculture, animal husbandry,\nand aquaculture, the scene such as plant monitoring,\
    \ needs the edge of the Internet of\nThings system IoT terminal according to the\
    \ scientiﬁc planting and breeding, fertilizers\nElectronics 2023, 12, 2336\n23\
    \ of 46\nand other professional industry model, implement local sampling, local\
    \ operations, and\nlocal decisions at the same time, according to the requirement\
    \ of the center’s continuously\nupdated mathematical model and iteration. Therefore,\
    \ the intelligent Internet of Things\nterminal should be based on the requirements\
    \ of fog computing and edge computing\narchitecture, rely on the machine learning\
    \ and algorithm training of cloud computing\ncenter, complete, reliable real-time\
    \ deep computing, accurately control on-site facilities and\nequipment, and achieve\
    \ the purpose of scientiﬁc planting and breeding.\nFigure 22. Smart agriculture\
    \ edge computing model.\n3.5. 5G Intelligent Agricultural IoT In-Depth Service\n\
    The intelligent Internet of Things platform under the 5G will provide personalized,\n\
    customized, and in-depth services for agriculture. The smart agriculture IoT big\
    \ data\nservice platform is shown in Figure 23.\nFigure 23. Smart agriculture\
    \ Internet of Things service platform.\nBased on the power of 5G and the improvement\
    \ of computing power and storage\ncapacity, combined with the latest service platform\
    \ architecture SaaS, PaaS, IaaS, etc., the\nservices of smart agriculture will\
    \ be extremely friendly and convenient. By shielding the\nunderlying details,\
    \ users will be provided with QoS humanized services, as shown in\nFigure 24.\n\
    Electronics 2023, 12, 2336\n24 of 46\nnics 2023, 12, x FOR PEER REVIEW \n23 of\
    \ 46 \nApplication \nlayer SaaS\nIrrigat\nion \nAPP\nInsect \nmonitoring \nAPP\n\
    Moisture \nanalysis\nWeather \nanalysis\nIntelligent operation and \nmaintenance\
    \ of \nagricultural machinery\nPlatform layer \nPaaS\nFacility layer \nIaaS\n\
    Marginal \nlayer\nEquipmen\nt access\nProtocol \nresolution\nEdge data \nprocessing\n\
    Cloud infrastructure (server, storage, network, virtualization)\nAgricultural\
    \ data modeling, calculation and analysis (mechanism modeling, machine \nlearning,\
    \ visualization)\nAgricultural big data system (Data cleaning, Filling, Matching,\
    \ Management, Analysis, \nVisualization, etc.)\nEquipment Management Resource\
    \ Management Operation and Maintenance \nManagement Fault Diagnosis\nEdge data\
    \ \nprocessing\nEdge data \nprocessing\nBusiness \noperation\n \nFigure 24. 5G\
    \ smart agriculture Internet of Things service. \nConcerning 5G, the Internet,\
    \ the Internet of Things, big data and cloud computing, \nartificial intelligence,\
    \ and other modern information technology and agricultural depth \nfusion, the\
    \ implementation of agricultural information perception and quantitative deci-\n\
    sion-making, intelligent control, accurate, and personalized service, the new\
    \ way of agri-\ncultural production is the agricultural informationization development\
    \ from the ad-\nvanced stage of digital to network and intelligent. \n3.6. 5G\
    \ Intelligent Agricultural IoT Production Intelligent Control \nThe application\
    \ of intelligent agricultural IoT based on 5G is bound to involve pro-\nduction\
    \ control, and control of various agricultural machinery such as irrigation and\
    \ \nspraying [94]. The innate advantages of 5G have innate advantages for the\
    \ control of smart \nagriculture—mainly low delay, high bandwidth, and other technical\
    \ characteristics, as \nshown in Figure 25. \nBreeding\nGrow \nseedlings\nPick\n\
    Grafting\nSpray\nWeed\nFarming\nSpray\nOxygenati\non\nSunshade\nSunshade\nReliability\n\
    High \nbandwidth\nLow delay\n5G\n5G\nScene\n \nFigure 25. 5G of intelligent control\
    \ of intelligent agriculture production. \nFor example, a project uses drones\
    \ to take photos of farmland, and the raw data will \nbe transmitted to the cloud\
    \ via 5G network for real-time data analysis and identification. \nThe results\
    \ can then be re-matched to the field, and a tractor or farm robot, guided by\
    \ GPS, \ncan then navigate to the area where the weeds are growing and carry out\
    \ precise removal. \nThis could reduce pesticide use by up to 90 percent, with\
    \ the possibility of replacing pes-\nticides with hot water to remove weeds later.\
    \ Neural networks and self-learning algo-\nrithms make plant identification more\
    \ and more accurate, but they also generate a lot of \nFigure 24. 5G smart agriculture\
    \ Internet of Things service.\nConcerning 5G, the Internet, the Internet of Things,\
    \ big data and cloud computing,\nartiﬁcial intelligence, and other modern information\
    \ technology and agricultural depth\nfusion, the implementation of agricultural\
    \ information perception and quantitative decision-\nmaking, intelligent control,\
    \ accurate, and personalized service, the new way of agricultural\nproduction\
    \ is the agricultural informationization development from the advanced stage of\n\
    digital to network and intelligent.\n3.6. 5G Intelligent Agricultural IoT Production\
    \ Intelligent Control\nThe application of intelligent agricultural IoT based on\
    \ 5G is bound to involve pro-\nduction control, and control of various agricultural\
    \ machinery such as irrigation and\nspraying [94]. The innate advantages of 5G\
    \ have innate advantages for the control of smart\nagriculture—mainly low delay,\
    \ high bandwidth, and other technical characteristics, as\nshown in Figure 25.\n\
    Electronics 2023, 12, x FOR PEER REVIEW \n23 of 46\n \nApplication \nlayer SaaS\n\
    Irrigat\nion \nAPP\nInsect \nmonitoring \nAPP\nMoisture \nanalysis\nWeather \n\
    analysis\nIntelligent operation and \nmaintenance of \nagricultural machinery\n\
    Platform layer \nPaaS\nFacility layer \nIaaS\nMarginal \nlayer\nEquipmen\nt access\n\
    Protocol \nresolution\nEdge data \nprocessing\nCloud infrastructure (server, storage,\
    \ network, virtualization)\nAgricultural data modeling, calculation and analysis\
    \ (mechanism modeling, machine \nlearning, visualization)\nAgricultural big data\
    \ system (Data cleaning, Filling, Matching, Management, Analysis, \nVisualization,\
    \ etc.)\nEquipment Management Resource Management Operation and Maintenance \n\
    Management Fault Diagnosis\nEdge data \nprocessing\nEdge data \nprocessing\nBusiness\
    \ \noperation\n \nFigure 24. 5G smart agriculture Internet of Things service.\
    \ \nConcerning 5G, the Internet, the Internet of Things, big data and cloud computing\n\
    artificial intelligence, and other modern information technology and agricultural\
    \ depth\nfusion, the implementation of agricultural information perception and\
    \ quantitative deci-\nsion-making, intelligent control, accurate, and personalized\
    \ service, the new way of agri-\ncultural production is the agricultural informationization\
    \ development from the ad-\nvanced stage of digital to network and intelligent.\
    \ \n3.6. 5G Intelligent Agricultural IoT Production Intelligent Control \nThe\
    \ application of intelligent agricultural IoT based on 5G is bound to involve\
    \ pro-\nduction control, and control of various agricultural machinery such as\
    \ irrigation and\nspraying [94]. The innate advantages of 5G have innate advantages\
    \ for the control of smart\nagriculture—mainly low delay, high bandwidth, and\
    \ other technical characteristics, as\nshown in Figure 25. \nBreeding\nGrow \n\
    seedlings\nPick\nGrafting\nSpray\nWeed\nFarming\nSpray\nOxygenati\non\nSunshade\n\
    Sunshade\nReliability\nHigh \nbandwidth\nLow delay\n5G\n5G\nScene\n \nFigure 25.\
    \ 5G of intelligent control of intelligent agriculture production. \nFor example,\
    \ a project uses drones to take photos of farmland, and the raw data will\nbe\
    \ transmitted to the cloud via 5G network for real-time data analysis and identification\n\
    The results can then be re-matched to the field, and a tractor or farm robot,\
    \ guided by GPS\ncan then navigate to the area where the weeds are growing and\
    \ carry out precise removal\nThis could reduce pesticide use by up to 90 percent,\
    \ with the possibility of replacing pes-\nticides with hot water to remove weeds\
    \ later. Neural networks and self-learning algo-\nrithms make plant identification\
    \ more and more accurate, but they also generate a lot of\nFigure 25. 5G of intelligent\
    \ control of intelligent agriculture production.\nFor example, a project uses\
    \ drones to take photos of farmland, and the raw data will be\ntransmitted to\
    \ the cloud via 5G network for real-time data analysis and identiﬁcation. The\n\
    results can then be re-matched to the ﬁeld, and a tractor or farm robot, guided\
    \ by GPS, can\nthen navigate to the area where the weeds are growing and carry\
    \ out precise removal. This\ncould reduce pesticide use by up to 90 percent, with\
    \ the possibility of replacing pesticides\nwith hot water to remove weeds later.\
    \ Neural networks and self-learning algorithms make\nElectronics 2023, 12, 2336\n\
    25 of 46\nplant identiﬁcation more and more accurate, but they also generate a\
    \ lot of data. Therefore,\nthe combination of 5G and other technologies is crucial\
    \ to the success of this innovation\nproject [95,96].\n4. Revolution of Smart\
    \ Agricultural IoT Application Paradigm under 5G\n4.1. Typical Application Scenarios\
    \ of 5G Smart Agricultural IoT\nThe development of 5G network will provide the\
    \ infrastructure needed for smart\nagriculture for agricultural production. The\
    \ main application scenarios include the follow-\ning aspects.\n4.1.1. Smart Farm\n\
    The two characteristics of 5G network, high speed and large connection, will help\n\
    the agricultural industry implement large-scale machine services. Centralized\
    \ control\nof environmental sensors, planters, UAVs, and other monitoring equipment\
    \ and real-\ntime data transmission. Finally, the purpose of intensive farming,\
    \ accurate fertilization,\nand reasonable irrigation is achieved [97]. Agricultural\
    \ machinery automatic agricultural\nmachinery equipment based on 5G was integrated\
    \ to achieve rapid, large-area, efﬁcient,\nand precise spraying operation [98].\n\
    4.1.2. Smart Forestry\nSmart forestry utilizes 5G network video, UAV, and other\
    \ monitoring equipment to\ncarry out forest inspection, realize the monitoring\
    \ of forest resources, forest pests and\ndiseases, wild animals and plants, forest\
    \ ﬁre prevention, and provide guide and rescue\nservices for staff and tourists\
    \ [99].\n4.1.3. Intelligent Animal Husbandry\n5G intelligent animal husbandry\
    \ can improve the production efﬁciency of animal\nhusbandry, reduce the cost of\
    \ breeding, prevent livestock epidemic and livestock loss, and\nprotect animal\
    \ husbandry ecology [100,101]. For example, the use of 5G drone technology,\n\
    wearing 5G terminals on the necks of cows, and the use of Internet of Things technology\
    \ to\nmanage yaks have brought great changes to the traditional herding work of\
    \ plateau herders.\n4.1.4. Smart Fishing Ground\n5G smart ﬁshing grounds use monitoring\
    \ equipment such as high-deﬁnition net-\nwork cameras and underwater camera systems\
    \ to carry out real-scene monitoring, aquatic\nproduct growth monitoring, and\
    \ precise bait casting to improve the safety of underwater\noperations and save\
    \ labor costs [102]. In the Marine ranch, 5G panoramic monitoring appli-\ncation\
    \ is realized through 5G coverage. The panoramic high-deﬁnition camera equipment\n\
    and 5G underwater camera system were set up to realize the 24-h panoramic monitoring\
    \ of\nthe ranch. Managers can observe the growth of aquatic products, including\
    \ underwater\nobservation, from their ofﬁces or homes through mobile phones [103].\
    \ Based on 5G technol-\nogy, the intelligent control of the production process\
    \ of Marine cash crops, including kelp\nand other seedlings, can also be realized,\
    \ making it possible to have unmanned Marine\nranching.\n4.2. Deep Sense of 5G\
    \ Smart Agriculture\n4.2.1. Agricultural 5G Image Processing\nIn smart agriculture,\
    \ a large number of scenes need to realize monitoring or identiﬁ-\ncation and\
    \ detection of various targets. With the rapid development of machine learning\n\
    technology in image processing, many problems in agriculture can be solved by\
    \ video\nmonitoring and image detection. This paper summarizes the typical application\
    \ scenarios\nof agricultural image processing, as shown in Figure 26. It mainly\
    \ includes three categories:\nplant pest and disease identiﬁcation [104,105],\
    \ crop growth analysis and detection [106],\nand livestock and aquaculture monitoring\
    \ [107,108]. Each category is divided into many\nElectronics 2023, 12, 2336\n\
    26 of 46\nspeciﬁc problems. The core mode is to collect image data and then combine\
    \ data with\nan artiﬁcial intelligence machine learning algorithm to train the\
    \ model and then detect\nthe model.\ntechnology in image processing, many problems\
    \ in agriculture can be sol\nmonitoring and image detection. This paper summarizes\
    \ the typical applica\nof agricultural image processing, as shown in Figure 26.\
    \ It mainly includes\nries: plant pest and disease identification [104,105], crop\
    \ growth analysis \n[106], and livestock and aquaculture monitoring [107,108].\
    \ Each category i\nmany specific problems. The core mode is to collect image data\
    \ and then \nwith an artificial intelligence machine learning algorithm to train\
    \ the mode\ntect the model. \nAgricultural image \nprocessing\nIdentification\
    \ of plant \ndiseases and pests\nCrop analysis and \ndetection\nLivestock and\
    \ aquatic \nproducts monitoring\n▪ 1.Fungal diseases\n▪ 2.Citrus diseases\n▪ 3.Grapevine\
    \ diseases\n▪ 4.Detection of citrus spider \nand aphid\n▪ 5.Corn crop diseases\n\
    ▪ 6.Pumpkin disease\n▪ 7.Rice disease\n▪ 8.Identification of \nSpodoptera gracilis\
    \ \n▪ 9.Apple leaf disease\n▪ 1.Crop detection\n▪ 2.Crop row detection\n▪ 3.Smart\
    \ Farm\n▪ 4.Yield detection\n▪ 5.Tomato maturity \ndetection\n▪ 6.Weed detection\n\
    ▪ 7.Ear detection\n▪ 8.Grapefruit shape \ndetection\n▪ 9.Phenotype detection of\
    \ \nbroccoli\n▪ 1.Pig behavior monitoring\n▪ 2.Behavior monitoring of \nwhite\
    \ feather chickens\n▪ 3.Oestrus monitoring of \ndairy cows\n▪ 4.Fish growth monitoring\n\
    ▪ 5.Monitoring of bovine \nprotein content\n▪ 6.Floating feed monitoring\n▪ 7.Feeding\
    \ behavior \nmonitoring\n▪ 8.Bullfrog behavior \nmonitoring\n▪ 9.Monitoring of\
    \ water fly \nbreeding\n▪ 10.Underwater monitoring \nof cage culture\n \nFigure\
    \ 26. Image processing in agriculture. \nWith the popularity of high-definition\
    \ cameras, more images need to b\nin agricultural IoT. The transmission of these\
    \ high-definition images poses a\nthe network. Second, many scenarios require\
    \ real-time detection and proces\npopularity of 5G technology, the effective transmission\
    \ and real-time proce\nand image big data can be realized by building a 5G-oriented\
    \ heterogeneo\nThings. \n4.2.2. Agricultural Intelligence Detection Based Machine\
    \ Learning \nThe development of artificial intelligence machine learning has brough\n\
    tunities for smart agriculture. Many researchers have conducted a great de\nby\
    \ combining machine learning algorithms. The main goal of machine learn\ncation\
    \ and detection [109,110]. In agricultural application scenarios, mac\nmainly\
    \ realizes agricultural sensing data, including video, image, text, and\nmodal\
    \ data, and trains models for data detection. The following figure show\nmodel\
    \ processed by machine learning, as shown in Figure 27. \nFigure 26. Image processing\
    \ in agriculture.\nWith the popularity of high-deﬁnition cameras, more images\
    \ need to be transmitted\nin agricultural IoT. The transmission of these high-deﬁnition\
    \ images poses a challenge for\nthe network. Second, many scenarios require real-time\
    \ detection and processing. With\nthe popularity of 5G technology, the effective\
    \ transmission and real-time processing of\nvideo and image big data can be realized\
    \ by building a 5G-oriented heterogeneous Internet\nof Things.\n4.2.2. Agricultural\
    \ Intelligence Detection Based Machine Learning\nThe development of artiﬁcial\
    \ intelligence machine learning has brought new opportu-\nnities for smart agriculture.\
    \ Many researchers have conducted a great deal of research by\ncombining machine\
    \ learning algorithms. The main goal of machine learning is classiﬁcation\nand\
    \ detection [109,110]. In agricultural application scenarios, machine learning\
    \ mainly\nrealizes agricultural sensing data, including video, image, text, and\
    \ other multi-modal\ndata, and trains models for data detection. The following\
    \ ﬁgure shows the general model\nprocessed by machine learning, as shown in Figure\
    \ 27.\nHowever, the autonomous training model is limited by the resources and\
    \ computing\npower of the sensing device, and the effect is not always ideal.\
    \ At present, there are many\nopen-source deep learning platforms for artiﬁcial\
    \ intelligence, which can optimize model\ntraining and provide detection accuracy\
    \ with the help of platform capabilities. The open\nAI deep learning platform\
    \ is shown in Figure 28.\nElectronics 2023, 12, 2336\n27 of 46\ntronics 2023,\
    \ 12, x FOR PEER REVIEW \n26 of \nData \nset\nData \nprep\nroce\nssin\ng\nData\
    \ \ncleaning\nData \nconversion\nData filling\nTraini\nng \ndata\nTest \ndata\n\
    Training \nmodel\nTest \nmodel\nModel\nEvaluation \noptimization\nDeploy\nAgricultural\
    \ \nsense data\n \nFigure 27. An agricultural intelligence detection framework\
    \ for machine learning. \nHowever, the autonomous training model is limited by\
    \ the resources and computi\npower of the sensing device, and the effect is not\
    \ always ideal. At present, there are ma\nopen-source deep learning platforms\
    \ for artificial intelligence, which can optimize mod\ntraining and provide detection\
    \ accuracy with the help of platform capabilities. The op\nAI deep learning platform\
    \ is shown in Figure 28. \nMicrosoft Azure\nIBM System ML\nTencent TML\nAlibaba\
    \ DTPAI\nBaidu BML\nAmazon ML\nGoogle Cloud \nPlatform\nMahout\nHadoop\nSpark\n\
    GraphLab\nMPICH 2\nDMLC\nPetuum\n \nFigure 28. Open artificial intelligence deep\
    \ learning platform. \nDeep learning is an important branch of machine learning.\
    \ It can automatically an\nefficiently extract target features and recognize targets\
    \ through model training. The app\ncation of deep learning technology combined\
    \ with image processing to the recognition\ncrop diseases and insect pests is\
    \ an inevitable trend in the future development of precisi\nagriculture. The performance\
    \ of deep learning networks is very dependent on data se\nHigh quality, high correlation,\
    \ complete annotation, and large-scale agricultural data se\nare of great significance\
    \ for model training. In the application of crop disease and pe\nrecognition,\
    \ in addition to color images taken by cameras and mobile phones of sensi\ndevices,\
    \ multimodal agricultural data such as hyperspectral, near-infrared, and infrar\n\
    images are becoming a trend, and their acquisition provides support for model\
    \ trainin\nas shown in Figure 29. In addition to publicly available data sets,\
    \ an important source f\ndata set sources is self-collection. However, it is very\
    \ difficult to collect graphs of cr\ndiseases and insect pests, and there are\
    \ some problems, such as page occlusion and victi\narea concealment, which require\
    \ multi-angle sensing equipment to collect at the who\ntime, which requires a\
    \ large amount of data collection and transmission. Based on 5\nhigh-speed transmission\
    \ of data from terminal sensing nodes to the platform can be re\nized, real-time\
    \ detection of data can be realized, and the degree of intelligence can be e\n\
    panded [111]. \nCamera\nVideo\nIR/NIR\n5G\nAgricultural \nimage data set \nplatform\n\
    Training \nmodel\nApplication \nplatform\nFigure 27. An agricultural intelligence\
    \ detection framework for machine learning.\nData \nset\nData \nprep\nroce\nssin\n\
    g\nData \ncleaning\nData \nconversion\nData filling\nTraini\nng \ndata\nTest \n\
    data\ng\nmodel\nTest \nmodel\nModel\nEvaluation \noptimization\nDeploy\nral \n\
    ta\n \nFigure 27. An agricultural intelligence detection framework for machine\
    \ learning. \nHowever, the autonomous training model is limited by the resources\
    \ and computing \npower of the sensing device, and the effect is not always ideal.\
    \ At present, there are many \nopen-source deep learning platforms for artificial\
    \ intelligence, which can optimize model \ntraining and provide detection accuracy\
    \ with the help of platform capabilities. The open \nAI deep learning platform\
    \ is shown in Figure 28. \nMicrosoft Azure\nIBM System ML\nTencent TML\nAlibaba\
    \ DTPAI\nBaidu BML\nAmazon ML\nGoogle Cloud \nPlatform\nMahout\nHadoop\nSpark\n\
    GraphLab\nMPICH 2\nDMLC\nPetuum\n \nFigure 28. Open artificial intelligence deep\
    \ learning platform. \nDeep learning is an important branch of machine learning.\
    \ It can automatically and \nefficiently extract target features and recognize\
    \ targets through model training. The appli-\ncation of deep learning technology\
    \ combined with image processing to the recognition of \ncrop diseases and insect\
    \ pests is an inevitable trend in the future development of precision \nagriculture.\
    \ The performance of deep learning networks is very dependent on data sets. \n\
    High quality, high correlation, complete annotation, and large-scale agricultural\
    \ data sets \nare of great significance for model training. In the application\
    \ of crop disease and pest \nrecognition, in addition to color images taken by\
    \ cameras and mobile phones of sensing \ndevices, multimodal agricultural data\
    \ such as hyperspectral, near-infrared, and infrared \nimages are becoming a trend,\
    \ and their acquisition provides support for model training, \nas shown in Figure\
    \ 29. In addition to publicly available data sets, an important source for \n\
    data set sources is self-collection. However, it is very difficult to collect\
    \ graphs of crop \ndiseases and insect pests, and there are some problems, such\
    \ as page occlusion and victim \narea concealment, which require multi-angle sensing\
    \ equipment to collect at the whole \ntime, which requires a large amount of data\
    \ collection and transmission. Based on 5G, \nhigh-speed transmission of data\
    \ from terminal sensing nodes to the platform can be real-\nized, real-time detection\
    \ of data can be realized, and the degree of intelligence can be ex-\npanded [111].\
    \ \nCamera\nVideo\nIR/NIR\nSpectral camera\n5G\nAgricultural \nimage data set\
    \ \nplatform\nTraining \nmodel\nApplication \nplatform\n \nFigure 28. Open artiﬁcial\
    \ intelligence deep learning platform.\nDeep learning is an important branch of\
    \ machine learning. It can automatically\nand efﬁciently extract target features\
    \ and recognize targets through model training. The\napplication of deep learning\
    \ technology combined with image processing to the recognition\nof crop diseases\
    \ and insect pests is an inevitable trend in the future development of precision\n\
    agriculture. The performance of deep learning networks is very dependent on data\
    \ sets.\nHigh quality, high correlation, complete annotation, and large-scale\
    \ agricultural data sets\nare of great signiﬁcance for model training. In the\
    \ application of crop disease and pest\nrecognition, in addition to color images\
    \ taken by cameras and mobile phones of sensing\ndevices, multimodal agricultural\
    \ data such as hyperspectral, near-infrared, and infrared\nimages are becoming\
    \ a trend, and their acquisition provides support for model training, as\nshown\
    \ in Figure 29. In addition to publicly available data sets, an important source\
    \ for data\nset sources is self-collection. However, it is very difﬁcult to collect\
    \ graphs of crop diseases\nand insect pests, and there are some problems, such\
    \ as page occlusion and victim area\nconcealment, which require multi-angle sensing\
    \ equipment to collect at the whole time,\nwhich requires a large amount of data\
    \ collection and transmission. Based on 5G, high-speed\ntransmission of data from\
    \ terminal sensing nodes to the platform can be realized, real-time\ndetection\
    \ of data can be realized, and the degree of intelligence can be expanded [111].\n\
    Test \ndata\nTest \nmodel\noptimization\nFigure 27. An agricultural intelligence\
    \ detection framework for machine learning. \nHowever, the autonomous training\
    \ model is limited by the resources an\npower of the sensing device, and the effect\
    \ is not always ideal. At present, th\nopen-source deep learning platforms for\
    \ artificial intelligence, which can op\ntraining and provide detection accuracy\
    \ with the help of platform capabili\nAI deep learning platform is shown in Figure\
    \ 28. \nMicrosoft Azure\nIBM System ML\nTencent TML\nAlibaba DTPAI\nBaidu BML\n\
    Amazon ML\nMahout\nHadoop\nSpark\nGraphLab\nMPICH 2\nDMLC\nFigure 28. Open artificial\
    \ intelligence deep learning platform. \nDeep learning is an important branch\
    \ of machine learning. It can auto\nefficiently extract target features and recognize\
    \ targets through model traini\ncation of deep learning technology combined with\
    \ image processing to the \ncrop diseases and insect pests is an inevitable trend\
    \ in the future developmen\nagriculture. The performance of deep learning networks\
    \ is very dependen\nHigh quality, high correlation, complete annotation, and large-scale\
    \ agricul\nare of great significance for model training. In the application of\
    \ crop dis\nrecognition, in addition to color images taken by cameras and mobile\
    \ phon\ndevices, multimodal agricultural data such as hyperspectral, near-infrared\n\
    images are becoming a trend, and their acquisition provides support for m\nas\
    \ shown in Figure 29. In addition to publicly available data sets, an import\n\
    data set sources is self-collection. However, it is very difficult to collect\
    \ g\ndiseases and insect pests, and there are some problems, such as page occlusi\n\
    area concealment, which require multi-angle sensing equipment to collect\ntime,\
    \ which requires a large amount of data collection and transmission. \nhigh-speed\
    \ transmission of data from terminal sensing nodes to the platfor\nized, real-time\
    \ detection of data can be realized, and the degree of intellige\npanded [111].\
    \ \nCamera\nVideo\nIR/NIR\nSpectral camera\n5G\nAgricultural \nimage data set\
    \ \nplatform\nTraining \nmodel\nApplication \nplatform\n \nFigure 29. Machine\
    \ learning detection platform based on 5G. \nFigure 29. Machine learning detection\
    \ platform based on 5G.\nElectronics 2023, 12, 2336\n28 of 46\n4.3. 5G Intelligent\
    \ Agricultural Machinery\nUnder the conditions of high speed and low delay of\
    \ 5G, intelligent agricultural\nmachinery can realize deep real-time perception,\
    \ such as the state information collection,\nfault location, and operation monitoring\
    \ of agricultural machinery can be displayed online\nin real time. The system\
    \ can diagnose the failure of agricultural machinery in real-time and\nschedule\
    \ the cooperative operation of multiple agricultural machineries. The advantage\n\
    of low latency is that route decisions can be made in time, increasing the speed\
    \ of sowing\nor harvesting and making the operation more accurate. Secondly, agricultural\
    \ robots are\nmainly divided into two categories. First, walking robots. The second\
    \ is the robotic hand\nrobot. The robot is mainly based on visual recognition\
    \ technology to identify and locate\nplants and then plant and pick them. 5G technology\
    \ enables robots to receive commands\nfaster, transmit high-deﬁnition pictures\
    \ and videos, and promote the development of\nrobot visual recognition technology.\
    \ 5G has increased the number of robots that can\nbe accessed, allowing multiple\
    \ robots to be remotely controlled to work and improving\noperational efﬁciency.\n\
    4.3.1. Intelligent Agricultural Machinery\nAgricultural machinery plays an important\
    \ role in agricultural production practice.\nIt can effectively improve the efﬁciency\
    \ of agricultural production to promote large-scale\nand industrial planting.\
    \ All kinds of machinery used in the process of agriculture, forestry,\nanimal\
    \ husbandry, deputy, and ﬁshery production are collectively referred to as agricultural\n\
    machinery. Agricultural machinery can be broadly divided into two categories:\
    \ power\nmachinery and working machinery. The following diagram summarizes the\
    \ classiﬁcation\ndiagram of agricultural machinery and equipment according to\
    \ different functions [112,113],\nas shown in Figure 30.\ng\ng\ny\nUnder the conditions\
    \ of high speed and low delay of 5G, intelligent agricultu\nchinery can realize\
    \ deep real-time perception, such as the state information col\nfault location,\
    \ and operation monitoring of agricultural machinery can be dis\nonline in real\
    \ time. The system can diagnose the failure of agricultural machinery \ntime and\
    \ schedule the cooperative operation of multiple agricultural machineries. T\n\
    vantage of low latency is that route decisions can be made in time, increasing\
    \ the sp\nsowing or harvesting and making the operation more accurate. Secondly,\
    \ agricultu\nbots are mainly divided into two categories. First, walking robots.\
    \ The second is \nbotic hand robot. The robot is mainly based on visual recognition\
    \ technology to i\nand locate plants and then plant and pick them. 5G technology\
    \ enables robots to \ncommands faster, transmit high-definition pictures and videos,\
    \ and promote the d\nment of robot visual recognition technology. 5G has increased\
    \ the number of robo\ncan be accessed, allowing multiple robots to be remotely\
    \ controlled to work and im\ning operational efficiency. \n4.3.1. Intelligent\
    \ Agricultural Machinery \nAgricultural machinery plays an important role in agricultural\
    \ production p\nIt can effectively improve the efficiency of agricultural production\
    \ to promote larg\nand industrial planting. All kinds of machinery used in the\
    \ process of agriculture, fo\nanimal husbandry, deputy, and fishery production\
    \ are collectively referred to as a\ntural machinery. Agricultural machinery can\
    \ be broadly divided into two cate\npower machinery and working machinery. The\
    \ following diagram summarizes th\nsification diagram of agricultural machinery\
    \ and equipment according to differen\ntions [112,113], as shown in Figure 30.\
    \ \nIntelligent agricultural \nmachinery and equipment\nTillage \nmachinery\n\
    Plant protection \nmachinery\nIrrigation and \ndrainage \nmachinery\nPower transmission\
    \ \nmachinery\nHarvesting \nmachinery\nAnimal husbandry \nmachinery\nPlanting\
    \ and fertilizing \nmachinery\nFishery and \naquatic products\nAnimal husbandry\n\
    Crop planting\nAuxiliary \nmachinery\n▪ \nCultivator\n▪ \nRotary cultivator\n\
    ▪ \nMicro cultivator\n▪ \nDisc plough\n▪ \nRotary cultivator\n▪ \nScarifier\n\
    ▪ \nStubble cleaner\n▪ \nGrader\n▪ \nDigger\n▪ \nFurrowing and \nridging machine\n\
    ▪ \nCombined grader\n▪ \nDisc harrow\n▪ \nBallast\n▪ \nPruning \nMachineCultivat\n\
    or\n▪ \nEradicator\n▪ \nFogger\n▪ \nSpray\n▪ \nLawnmower\n▪ \nDuster\n▪ \nLawn\
    \ mower\n▪ \nInsecticidal lamp\n▪ \nBooby trap\n▪ \nPlant protection \nUAV\n▪\
    \ \nWater lifting, \ndrainage and \nirrigation\n▪ \nSprinkler \nirrigation \n\
    equipment\n▪ \nDrip irrigation \nequipment\n▪ \nMicro spray \nequipment\n▪ \n\
    Outlet valve\n▪ \nAirbrush\n▪ \nWater and \nfertilizer \nEquipment\n▪ \nWater\
    \ pump\n▪ \nHydraulic turbine\n▪ \nGasoline engine\n▪ \nDiesel engine\n▪ \nEngine\n\
    ▪ \nTractor\n▪ \nLoading and \nunloading \nvehicle\n▪ \nLifting platform\n▪ \n\
    Conveyor\n▪ \nHoist\n▪ \nFeeder\n▪ \nLoader\n▪ \nForklift\n▪ \nSeeder\n▪ \nDrill\n\
    ▪ \nAcupoint planter\n▪ \nPlanter\n▪ \nRice transplanter\n▪ \nTransplanter\n▪\
    \ \nFertilizer \nApplicator\n▪ \nTopdressing \nmachine\n▪ \nMulching \nmachine\n\
    ▪ \nSpray machine\n▪ \nUAV\n▪ \nHarvester\n▪ \nHarvester\n▪ \nThreshing \nmachine\n\
    ▪ \nFruit picking \nmachine\n▪ \nBaler\n▪ \nSheller\n▪ \nCleaner\n▪ \nDrying machine\n\
    ▪ \nWarehousing \nequipment\n▪ \nSeed processor\n▪ \n▪ \nChicken breeding \nequipment\n\
    ▪ \nPig breeding \nequipment\n▪ \nIncubation \nequipment\n▪ \nFan equipment\n\
    ▪ \nHeating \nequipment\n▪ \nAquaculture \nEquipment \n▪ \nCapture \nequipment\n\
    ▪ \nSlaughtering \nequipment\n▪ \nCrushing equipment\n▪ \nStacking equipment\n\
    ▪ \nDrying equipment\n▪ \nCooling equipment\n▪ \nGranulation \nequipment\n▪ \n\
    Screening \nequipment\n▪ \nMixing and stirring\n▪ \nQuantitative \npackaging\n\
    ▪ \nFertilizer production \nmachine\n \nFigure 30. Classification of agricultural\
    \ machinery and equipment. \nThe trend of intelligent agriculture development\
    \ is necessarily intelligent. W\ndevelopment of technology based on automated\
    \ equipment, the intelligent opera\nagriculture will be realized by means of sensors,\
    \ information transmission, and\nmation integration processing, which are based\
    \ on the Internet of Things, big da\nartificial intelligence [114]. \nFor example,\
    \ the intelligent agricultural machine can form a highly intelligen\nating system\
    \ by configuring various sensing devices and computing chips on the a\ntural machine,\
    \ combined with satellite positioning detection terminal equipment,\nintegration\
    \ module, and IoT system. Intelligent agricultural machinery can also \ninformation\
    \ on agricultural machinery operation through the management cente\nFigure 30.\
    \ Classiﬁcation of agricultural machinery and equipment.\nThe trend of intelligent\
    \ agriculture development is necessarily intelligent. With the\ndevelopment of\
    \ technology based on automated equipment, the intelligent operation of\nagriculture\
    \ will be realized by means of sensors, information transmission, and information\n\
    integration processing, which are based on the Internet of Things, big data, and\
    \ artiﬁcial\nintelligence [114].\nFor example, the intelligent agricultural machine\
    \ can form a highly intelligent operat-\ning system by conﬁguring various sensing\
    \ devices and computing chips on the agricultural\nmachine, combined with satellite\
    \ positioning detection terminal equipment, digital in-\ntegration module, and\
    \ IoT system. Intelligent agricultural machinery can also display\nElectronics\
    \ 2023, 12, 2336\n29 of 46\ninformation on agricultural machinery operation through\
    \ the management center informa-\ntion platform. The perception information will\
    \ be monitored for statistics and management,\nagricultural machinery macro management,\
    \ command scheduling, and operation statis-\ntics. Information technology and\
    \ agricultural machinery chain integration, through data\nanalysis, get a scientiﬁc\
    \ decision.\nHigher intelligent agricultural machines require more sensory data\
    \ intake for com-\nputational processing decisions. This requires a smart agricultural\
    \ Internet of Things.\nFor example, the irrigation system of farmland can be completed\
    \ by simple operation of\nfarmers. However, the question of when and how much\
    \ to irrigate depends on people’s\nexperience. The intelligent irrigation system\
    \ can be judged comprehensively through the\nmonitoring data of crop production\
    \ status, temperature, and humidity, meteorological\nconditions, etc., which saves\
    \ manpower and ensures the health of crop growth.\nThe problem is that the traditional\
    \ Internet of Things cannot meet the requirements\nof real-time transmission of\
    \ large amounts of data. With the integration of 5G, smart\nagricultural machines\
    \ can achieve a data communication rate, which is expected to change\nthe production\
    \ mode of smart agricultural machines and the degree of wisdom, as shown\nin Figure\
    \ 31 and Table 8.\nElectronics 2023, 12, x FOR PEER REVIEW \n \nstatistics. Information\
    \ technology and agricultural machinery chain integration, t\ndata analysis, get\
    \ a scientific decision. \nHigher intelligent agricultural machines require more\
    \ sensory data intake f\nputational processing decisions. This requires a smart\
    \ agricultural Internet of Thi\nexample, the irrigation system of farmland can\
    \ be completed by simple operation \ners. However, the question of when and how\
    \ much to irrigate depends on people\nrience. The intelligent irrigation system\
    \ can be judged comprehensively through th\nitoring data of crop production status,\
    \ temperature, and humidity, meteorologica\ntions, etc., which saves manpower\
    \ and ensures the health of crop growth. \nThe problem is that the traditional\
    \ Internet of Things cannot meet the requi\nof real-time transmission of large\
    \ amounts of data. With the integration of 5G, sm\ncultural machines can achieve\
    \ a data communication rate, which is expected to cha\nproduction mode of smart\
    \ agricultural machines and the degree of wisdom, as sh\nFigure 31 and Table 8.\
    \ \nMechanical \narm\nVideo sensing \ndevice\nInfrared \nspectrum\nCamera\n5G+Mechanical\
    \ arm+AGV Independent patrol inspection\nAGV\n \nFigure 31. 5G + robotic arm +\
    \ AGV independent inspection. \nTable 8. Image recognition and detection of intelligent\
    \ agriculture. \nLiterature \nContent \nField \nType \nB. Bose et al. [115] \n\
    Diagnosis, detection, and classifica-\ntion of cannabis diseases \nPlant protection\
    \ \nClassification algo\nD. Brunelli et al. [116] \nIdentify and kill apple pests\
    \ \nPlant protection \nNeural netwo\nR. Medar et al. [117] \nCrop yield prediction\
    \ \nPlant protection \nMachine learn\nN. Gobalakrishnan [118] \nPlant disease\
    \ detection \nCrop diseases and in-\nsect pests \nImage process\nM. Merchant [119]\
    \ \nVarious nutritional deficiencies of \nmango leaves \nCrop protection \nImage\
    \ process\nQ. Feng [120] \nTomato harvesting machine \nHarvest \nImage segmentati\n\
    cessing \nUnder the background of 5G, the smart agricultural IoT will transform\
    \ the \nagricultural machinery equipment and make it more intelligent. Intelligent\
    \ agri\nFigure 31. 5G + robotic arm + AGV independent inspection.\nTable 8. Image\
    \ recognition and detection of intelligent agriculture.\nLiterature\nContent\n\
    Field\nType\nB. Bose et al. [115]\nDiagnosis, detection, and\nclassiﬁcation of\
    \ cannabis diseases\nPlant protection\nClassiﬁcation algorithm\nD. Brunelli et\
    \ al. [116]\nIdentify and kill apple pests\nPlant protection\nNeural network\n\
    R. Medar et al. [117]\nCrop yield prediction\nPlant protection\nMachine learning\n\
    N. Gobalakrishnan [118]\nPlant disease detection\nCrop diseases and insect pests\n\
    Image processing\nM. Merchant [119]\nVarious nutritional deﬁciencies of\nmango\
    \ leaves\nCrop protection\nImage processing\nQ. Feng [120]\nTomato harvesting\
    \ machine\nHarvest\nImage segmentation\nprocessing\nElectronics 2023, 12, 2336\n\
    30 of 46\nUnder the background of 5G, the smart agricultural IoT will transform\
    \ the existing\nagricultural machinery equipment and make it more intelligent.\
    \ Intelligent agricultural\nmachinery can perceive its position, surrounding environment\
    \ relationship, and the inter-\nnal working state of machinery by building machine\
    \ vision, multi-dimensional perception,\nand satellite positioning based on 5G\
    \ agricultural Internet of Things. It can achieve good\ncooperation and scientiﬁc\
    \ implementation, effectively improving the effect of agricultural\nmechanization\
    \ by controlling and operating each process. Intelligent agricultural machin-\n\
    ery 5G-based agricultural Internet of Things can realize real-time monitoring\
    \ of agricultural\nmachinery’s own condition, operating state of machinery and\
    \ tools, meteorological condi-\ntions, and operating environment. It can also\
    \ guide agricultural machinery to adjust the\noperation plan in time according\
    \ to the obtained information and effectively reduce the\nindustrial machinery\
    \ in the process of operation failure, such as machine damage, poor\nquality,\
    \ and other problems. In addition to the above, intelligent agricultural machinery\n\
    will reduce the amount of ineffective operation of industrial machinery. Energy\
    \ efﬁciency\nhas been signiﬁcantly improved. The precise operation also realizes\
    \ the precise applica-\ntion of pesticides and fertilizers and truly realizes\
    \ the requirements of energy-saving and\nenvironmental protection.\nIt is clear\
    \ that smart agriculture combined with the Internet of Things and machine\nlearning\
    \ algorithm big data can transform traditional agricultural machinery and equip-\n\
    ment, making them more intelligent. In addition, the operation of intelligent\
    \ detection\nand sensing equipment can realize the functions of agricultural machinery\
    \ positioning,\nreal-time statistics of agricultural machinery working area, and\
    \ real-time calculation of\noperation quality. The system supports a variety of\
    \ agricultural machinery operations such\nas sowing, transplanting, plant protection,\
    \ harvesting, deep loosening, and land prepara-\ntion, straw returning, and so\
    \ on. It can measure fuel consumption and obtain the working\ncondition information\
    \ of agricultural machinery in real-time. This facilitates the control\nof agricultural\
    \ production progress and facilitates the real-time control of the working\narea,\
    \ working quality, and working power consumption. Being based on geospatial remote\n\
    sensing technology, multi-sensor fusion technology, 5G technology, and big data\
    \ technology,\nthe system realizes the comprehensive upgrading of smart agricultural\
    \ machinery.\n4.3.2. Automatic Driving of Agricultural Machinery\nThe automatic\
    \ driving technology of agricultural machinery is to use high-precision\nsatellite\
    \ positioning and navigation information and controls the hydraulic system of\n\
    agricultural machinery by the controller so that the agricultural machinery can\
    \ drive\nautomatically according to the set route (straight line or curve). It\
    \ can effectively improve\nthe working accuracy, improve the land utilization\
    \ rate, reduce the labor intensity of\nmachine hands, and extend the working time\
    \ (ﬁeld work can also be carried out at night).\nMoreover, it is easy to operate\
    \ and reduces the requirement for the driving ability of the\nmanipulator [121,122].\
    \ Based on the Beidou Navigation Satellite System (BDS) [123,124], a\nglobal Positioning\
    \ system (GPS) can achieve intelligent driving of all kinds of agricultural\n\
    machinery, including rice transplanters, seed drills, combine harvesters, etc.\
    \ The high-\nprecision positioning and navigation technology, image recognition,\
    \ and transmission\ntechnology are applied to the intelligent driving of these\
    \ machines to realize the precise\nnavigation of agricultural machinery driving\
    \ and automatically complete the land tillage,\nsowing, ﬁeld management, and harvest,\
    \ as shown in Figure 32.\nIntelligent agricultural machinery automatic driving\
    \ system uses satellite positioning,\nmechanical control, inertial navigation,\
    \ and other technologies so that agricultural machin-\nery, according to the planned\
    \ route, automatically adjusts the direction of travel. Operation\nprecision can\
    \ reach the centimeter level, and can be used for ditching, raking, sowing, ridge,\n\
    fertilization, spraying, harvesting, transplanting, and other agricultural operations.\n\
    Unmanned agricultural machinery has many problems to be solved, such as real-time\n\
    control, low speed, and complex scenes. Sensing data do not easily meet the needs\
    \ of\nElectronics 2023, 12, 2336\n31 of 46\nintelligent control. The high bandwidth\
    \ and real-time performance of 5G will be able to\nmeet the above requirements\
    \ of unmanned agricultural control operations.\nElectronics 2023, 12, x FOR PEER\
    \ REVIEW \n \nGPS/Beidou \nNavigation \nTerminal\nSatellite \nreceiving \nantenna\n\
    Traveling \ncontroller\nHydraulic \ncontrol \nsystem\nAngle/video \nsensor\n \n\
    Figure 32. 5G unmanned agricultural machinery model. \nIntelligent agricultural\
    \ machinery automatic driving system uses satellite p\ning, mechanical control,\
    \ inertial navigation, and other technologies so that agri\nmachinery, according\
    \ to the planned route, automatically adjusts the direction o\nOperation precision\
    \ can reach the centimeter level, and can be used for ditching\nsowing, ridge,\
    \ fertilization, spraying, harvesting, transplanting, and other agricult\nerations.\
    \ \nUnmanned agricultural machinery has many problems to be solved, such\ntime\
    \ control, low speed, and complex scenes. Sensing data do not easily meet th\n\
    of intelligent control. The high bandwidth and real-time performance of 5G will\n\
    to meet the above requirements of unmanned agricultural control operations. \n\
    4.3.3. 5G Automatic Coordination of Multiple Agricultural Machines \nThe 5G agricultural\
    \ machinery unmanned operating system is deployed on\ncloud network fusion platform.\
    \ With the intelligent agricultural machinery equ\ndocking, we realized the agricultural\
    \ machinery from the hangar, and machine\nway to the operation plot of the whole\
    \ process of unmanned operation. It cover\nproduction links of rice cultivation,\
    \ seed, pipe, and harvest. In the hangar and on t\nthe location map modeling is\
    \ first carried out, and the application equipment dep\nbased on RTK differential\
    \ GNSS positioning technology, IMU data, and UWB pre\nsitioning technology were\
    \ used to achieve the indoor and outdoor centimeter-lev\ntioning accuracy. Secondly,\
    \ the core control system deployed in the edge cloud \nvisual and radar terminals\
    \ installed in the agricultural machinery were combined\nthe surrounding environment\
    \ intelligently. Finally, the AI deep learning algorit\nused to complete the mark\
    \ line recognition and obstacle detection when agricultu\nchinery is moving forward\
    \ and backing up. In this way, unmanned driving, park\nstacle recognition, and\
    \ automatic obstacle avoidance can be realized, as shown in\n33. \nFigure 32.\
    \ 5G unmanned agricultural machinery model.\n4.3.3. 5G Automatic Coordination\
    \ of Multiple Agricultural Machines\nThe 5G agricultural machinery unmanned operating\
    \ system is deployed on the 5G\ncloud network fusion platform. With the intelligent\
    \ agricultural machinery equipment\ndocking, we realized the agricultural machinery\
    \ from the hangar, and machine plough\nway to the operation plot of the whole\
    \ process of unmanned operation. It covers all the\nproduction links of rice cultivation,\
    \ seed, pipe, and harvest. In the hangar and on the road,\nthe location map modeling\
    \ is ﬁrst carried out, and the application equipment deployment\nbased on RTK\
    \ differential GNSS positioning technology, IMU data, and UWB precise\npositioning\
    \ technology were used to achieve the indoor and outdoor centimeter-level\npositioning\
    \ accuracy. Secondly, the core control system deployed in the edge cloud and the\n\
    visual and radar terminals installed in the agricultural machinery were combined\
    \ to sense\nthe surrounding environment intelligently. Finally, the AI deep learning\
    \ algorithm was used\nto complete the mark line recognition and obstacle detection\
    \ when agricultural machinery\nis moving forward and backing up. In this way,\
    \ unmanned driving, parking, obstacle\nrecognition, and automatic obstacle avoidance\
    \ can be realized, as shown in Figure 33.\n4.4. 5G Agricultural UAV\nUAVs require\
    \ a high time delay of network signals. 5G networks give UAVs important\ncapabilities\
    \ such as ultra-high-deﬁnition video transmission, remote networking, and\nautonomous\
    \ ﬂight. 5G technology makes it possible for ﬂeets of drones to work together\n\
    and around the clock. It has huge development space in agriculture, security,\
    \ electricity,\nand other industries [125]. The plant protection UAV is small\
    \ in size, light in weight,\nﬂexible for ﬂight control, and has good applicability\
    \ to different plots and crops. At the\nplatform end, the networked UAV can be\
    \ remotely controlled to set functions such as\nassigning tasks, designing routes\
    \ independently, sending back spraying data in real time,\nand automatically returning\
    \ after an operation. Plant protection UAVs reduce pesticides,\nsave water consumption\
    \ and improve pesticides [126]. The steady wind ﬁeld generated\nby the rotor of\
    \ the UAV can penetrate the bottom of the crop, and the atomization effect is\n\
    good, reaching the back of the blade.\nLive broadcasts of rice by unmanned aerial\
    \ vehicles are relatively popular in south\nChina, which can sow 300~600 mu per\
    \ day, 3~5 times that of ground machinery. At the\nElectronics 2023, 12, 2336\n\
    32 of 46\nsame time, it eliminates the process of seedling, raising, transporting,\
    \ and transplanting.\nThe drone can adjust the nozzle size according to the size\
    \ of the seed. Spray the seeds in\nrows and columns as needed. The UAV can also\
    \ spray granular fertilizer and pesticides.\nAccording to the difference in particle\
    \ density and quality, it can automatically adjust\nthe parameters of the medicine\
    \ box to provide efﬁcient and intelligent fertilization and\napplication schemes.\n\
    Electronics 2023, 12, x FOR PEER REVIEW \n31 of 46 \n \nUAV/satellite high-\n\
    definition field \nmap construction\nGPS, BeiDong, \nGNSS navigation \nand positioning\n\
    Automatic turning \ncontrol of \nagricultural \nmachinery\nField path planning\
    \ \nof agricultural \nmachinery\nMulti machine \ncooperative task \nallocation\
    \ of \nagricultural machinery\nUnmanned \nagricultural \nmachinery\n \nFigure\
    \ 33. Schematic diagram of unmanned agricultural machinery collaboration based\
    \ on 5G. \n4.4. 5G Agricultural UAV \nUAVs require a high time delay of network\
    \ signals. 5G networks give UAVs im-\nportant capabilities such as ultra-high-definition\
    \ video transmission, remote networking, \nand autonomous flight. 5G technology\
    \ makes it possible for fleets of drones to work to-\ngether and around the clock.\
    \ It has huge development space in agriculture, security, elec-\ntricity, and\
    \ other industries [125]. The plant protection UAV is small in size, light in\
    \ \nweight, flexible for flight control, and has good applicability to different\
    \ plots and crops. \nAt the platform end, the networked UAV can be remotely controlled\
    \ to set functions such \nas assigning tasks, designing routes independently,\
    \ sending back spraying data in real \ntime, and automatically returning after\
    \ an operation. Plant protection UAVs reduce pesti-\ncides, save water consumption\
    \ and improve pesticides [126]. The steady wind field gen-\nerated by the rotor\
    \ of the UAV can penetrate the bottom of the crop, and the atomization \neffect\
    \ is good, reaching the back of the blade. \nLive broadcasts of rice by unmanned\
    \ aerial vehicles are relatively popular in south \nChina, which can sow 300~600\
    \ mu per day, 3~5 times that of ground machinery. At the \nsame time, it eliminates\
    \ the process of seedling, raising, transporting, and transplanting. \nThe drone\
    \ can adjust the nozzle size according to the size of the seed. Spray the seeds\
    \ in \nrows and columns as needed. The UAV can also spray granular fertilizer\
    \ and pesticides. \nAccording to the difference in particle density and quality,\
    \ it can automatically adjust the \nparameters of the medicine box to provide\
    \ efficient and intelligent fertilization and appli-\ncation schemes. \nThe drones\
    \ carry a range of remote sensing equipment that can photograph the \ngrowth of\
    \ crops. Remote sensing images combined with extensive data analysis can real-\n\
    ize the functions of crop monitoring, fertilization advice, and pest and disease\
    \ prediction. \nDifferent yields reflect different infrared spectra, which can\
    \ be used to measure the area \nof crops. Pests and diseases can be analyzed by\
    \ infrared spectroscopy and high-definition \nphotographs. \nFor forest management,\
    \ 5G drone ground stations will be deployed around the forest \nfarm, covering\
    \ an area of about 100 km. The drones are equipped with equipment, such \nas optical\
    \ cameras and high-definition cameras, to monitor vegetation growth and forest\
    \ \ncover. Through big data analysis of tree varieties and survival rate, replanting\
    \ suggestions \ncan also predict the occurrence of forest pests and diseases and\
    \ put forward prevention \nFigure 33. Schematic diagram of unmanned agricultural\
    \ machinery collaboration based on 5G.\nThe drones carry a range of remote sensing\
    \ equipment that can photograph the growth\nof crops. Remote sensing images combined\
    \ with extensive data analysis can realize the\nfunctions of crop monitoring,\
    \ fertilization advice, and pest and disease prediction. Different\nyields reﬂect\
    \ different infrared spectra, which can be used to measure the area of crops.\
    \ Pests\nand diseases can be analyzed by infrared spectroscopy and high-deﬁnition\
    \ photographs.\nFor forest management, 5G drone ground stations will be deployed\
    \ around the forest\nfarm, covering an area of about 100 km. The drones are equipped\
    \ with equipment, such as\noptical cameras and high-deﬁnition cameras, to monitor\
    \ vegetation growth and forest cover.\nThrough big data analysis of tree varieties\
    \ and survival rate, replanting suggestions can also\npredict the occurrence of\
    \ forest pests and diseases and put forward prevention and control\nsuggestions.\
    \ In terms of forest ﬁre control, inspection routes can be planned according to\n\
    daily needs, and the UAV will automatically alarm if there is any abnormality\
    \ [127]. If the\nforest is on ﬁre, drones can be sent to check the ﬁre, and the\
    \ ﬁre can be used to identify the\npoint of ﬁre.\nAccording to the different functions\
    \ of agricultural UAVs, as shown in Figure 34,\nthey can be divided into two categories:\
    \ agricultural operation and farmland information\ncollection. Agricultural operation\
    \ refers to the use of unmanned aerial vehicles (UAVs) to\nreplace some human\
    \ agricultural operations and to solve the shortage of human operations\nin quality,\
    \ efﬁciency, and labor, as well as the safety problems of operations. The collection\n\
    of farmland information refers to the timely and accurate collection of ﬁeld information\n\
    using remote sensing detection technology, including photosynthetic quality, soil\
    \ moisture,\nand crop population growth [128,129].\nElectronics 2023, 12, 2336\n\
    33 of 46\n \ncan be divided into two categories: agricultural operation and farmland\
    \ information col-\nlection. Agricultural operation refers to the use of unmanned\
    \ aerial vehicles (UAVs) to \nreplace some human agricultural operations and to\
    \ solve the shortage of human opera-\ntions in quality, efficiency, and labor,\
    \ as well as the safety problems of operations. The \ncollection of farmland information\
    \ refers to the timely and accurate collection of field in-\nformation using remote\
    \ sensing detection technology, including photosynthetic quality, \nsoil moisture,\
    \ and crop population growth [128,129]. \nAgricultural UAV\nPlant protection \n\
    operation\nForestry \nmonitoring\nCrop \npollination\nHerd \npositioning\nSingle\
    \ rotor UAV\nMulti rotor UAV\n \nFigure 34. Type of agricultural UAV. \nSeveral\
    \ challenges remain in the current application of agricultural drones: \nFirst,\
    \ the endurance time of agricultural UAVs is short, which cannot adapt to multi-\n\
    ple types of complex operations in the field. \nSecond, it is difficult to control.\
    \ Most of the intelligence degree is low, and anti-colli-\nsion and other functions\
    \ are lacking. \nThird, the precision application control technology based on\
    \ agricultural information \nis not mature enough. During aerial spraying operations,\
    \ agricultural information such as \ncrop growth, pests, and diseases in different\
    \ operating areas were obtained by aerial re-\nmote sensing technology, and prescription\
    \ maps were generated to determine the pesti-\ncide preparations and dosage required\
    \ for aerial spraying in different areas. The precision \napplication of plant\
    \ protection UAVs was realized by variable control technology. \nAll the above\
    \ have put forward new requirements for the intelligence degree of \nUAVs, mainly\
    \ including intelligent control, precise operation, better function, and optimi-\n\
    zation of spraying equipment. For the precise control of UAVs, it is necessary\
    \ to consume \nmore abundant information to meet its control needs. Secondly,\
    \ the real-time control \nneeds to be strengthened and satisfied, and the large\
    \ bandwidth and low delay of 5G can \nmeet the above requirements. It can be expected\
    \ that the popularity of 5G will be expected \nto promote the further development\
    \ of agricultural drones. \n4.5. 5G Intelligent Agricultural Supply Chain Management\
    \ \nAgricultural products have various production processes, long cycles, and\
    \ numerous \nfactors, so it is challenging to realize standardized production\
    \ and management [130]. The \nsupply chain of agricultural products is in all\
    \ stages of agriculture before, during, and \nafter production. Participants participate\
    \ in different roles of producers and consumers to \nrealize the supply and circulation\
    \ of agricultural products among agricultural producers, \nagricultural materials/agricultural\
    \ service enterprises, wholesale and retail markets, reg-\nulatory agencies, and\
    \ end consumers. It connects the production, processing, transporta-\ntion, sales,\
    \ and other links of agricultural products and integrates logistics, capital flow,\
    \ \nand information flow. It is important to establish a chain structure network\
    \ composed of \nagricultural product suppliers, manufacturers, distributors, retailers,\
    \ and end consumers \n[131]. Traditional agricultural supply chain participants\
    \ mainly use the Internet of Things \ntechnology to achieve information collection,\
    \ transmission, processing, processing, and \nother businesses. However, as IoT\
    \ systems are built in different participant systems, they \nbelong to different\
    \ platforms. For the seemingly interconnected network, the business is \nFigure\
    \ 34. Type of agricultural UAV.\nSeveral challenges remain in the current application\
    \ of agricultural drones:\nFirst, the endurance time of agricultural UAVs is short,\
    \ which cannot adapt to multiple\ntypes of complex operations in the ﬁeld.\nSecond,\
    \ it is difﬁcult to control. Most of the intelligence degree is low, and anti-collision\n\
    and other functions are lacking.\nThird, the precision application control technology\
    \ based on agricultural information\nis not mature enough. During aerial spraying\
    \ operations, agricultural information such as\ncrop growth, pests, and diseases\
    \ in different operating areas were obtained by aerial remote\nsensing technology,\
    \ and prescription maps were generated to determine the pesticide\npreparations\
    \ and dosage required for aerial spraying in different areas. The precision\n\
    application of plant protection UAVs was realized by variable control technology.\n\
    All the above have put forward new requirements for the intelligence degree of\
    \ UAVs,\nmainly including intelligent control, precise operation, better function,\
    \ and optimization\nof spraying equipment. For the precise control of UAVs, it\
    \ is necessary to consume more\nabundant information to meet its control needs.\
    \ Secondly, the real-time control needs to\nbe strengthened and satisﬁed, and\
    \ the large bandwidth and low delay of 5G can meet\nthe above requirements. It\
    \ can be expected that the popularity of 5G will be expected to\npromote the further\
    \ development of agricultural drones.\n4.5. 5G Intelligent Agricultural Supply\
    \ Chain Management\nAgricultural products have various production processes, long\
    \ cycles, and numerous\nfactors, so it is challenging to realize standardized\
    \ production and management [130]. The\nsupply chain of agricultural products\
    \ is in all stages of agriculture before, during, and\nafter production. Participants\
    \ participate in different roles of producers and consumers to\nrealize the supply\
    \ and circulation of agricultural products among agricultural producers,\nagricultural\
    \ materials/agricultural service enterprises, wholesale and retail markets, regu-\n\
    latory agencies, and end consumers. It connects the production, processing, transportation,\n\
    sales, and other links of agricultural products and integrates logistics, capital\
    \ ﬂow, and\ninformation ﬂow. It is important to establish a chain structure network\
    \ composed of agri-\ncultural product suppliers, manufacturers, distributors,\
    \ retailers, and end consumers [131].\nTraditional agricultural supply chain participants\
    \ mainly use the Internet of Things tech-\nnology to achieve information collection,\
    \ transmission, processing, processing, and other\nbusinesses. However, as IoT\
    \ systems are built in different participant systems, they belong\nto different\
    \ platforms. For the seemingly interconnected network, the business is relatively\n\
    independent, unable to quickly and effectively complete the exchange of information,\
    \ the\nreal realization of the whole process of sharing, presentation, and other\
    \ difﬁculties.\nThe traditional Internet is to reduce intermediate links, reduce\
    \ transaction costs,\nexpand the scope of service, improve service quality, and\
    \ so on. Embedding blockchain\ntechnology may deepen the meaning of the Internet.\
    \ It can form credit by recording, storing,\ntransferring, verifying, and analyzing\
    \ information data programmatically. Blockchain can\nsave a great deal of labor\
    \ costs and intermediary costs, and the recorded credit information\nis completer\
    \ and more difﬁcult to fake. The internal structure of the network architecture\
    \ of\neach subsystem is different. The network slice network virtualization of\
    \ 5G can realize the\nisolation and organic combination of each sub-platform.\
    \ An agricultural products supply\nchain management schematic diagram of 5G block\
    \ chain is shown in Figure 35.\nElectronics 2023, 12, 2336\n34 of 46\nsave a great\
    \ deal of labor costs and intermediary costs, and the recorded credit infor-\n\
    mation is completer and more difficult to fake. The internal structure of the\
    \ network ar-\nchitecture of each subsystem is different. The network slice network\
    \ virtualization of 5G\ncan realize the isolation and organic combination of each\
    \ sub-platform. An agricultural\nproducts supply chain management schematic diagram\
    \ of 5G block chain is shown in Fig-\nure 35. \nAgricultural \nproducer\nAgricultural\
    \ materials/\nagricultural clothing \nsupplier\nWholesale \nsales market\nShop/\n\
    Supermarket\n \nRegulators\nConsumer\nBlock 1\nParent chunk \nhash value\npro\n\
    duct\nion \ninfo\nrma\ntion\nLogi\nstics \ninfo\nrma\ntion\nOrd\ner \ninfo\nrma\n\
    tion\nInve\nntor\ny \ninfo\nrma\ntion\nBlock \nhead\n \nParticipant A Internet\
    \ \nof Things Platform\nBlockchain entry\nBlock 2\nParent chunk \nhash value\n\
    pro\nduct\nion \ninfo\nrma\ntion\nLogi\nstics \ninfo\nrma\ntion\nOrd\ner \ninfo\n\
    rma\ntion\nInve\nntor\ny \ninfo\nrma\ntion\nBlock \nhead\n \nParticipant B Internet\
    \ \nof Things Platform\nBlockchain entry\nBlock 3\nParent chunk \nhash value\n\
    pro\nduct\nion \ninfo\nrma\ntion\nLogi\nstics \ninfo\nrma\ntion\nOrd\ner \ninfo\n\
    rma\ntion\nInve\nntor\ny \ninfo\nrma\ntion\nBlock \nhead\n \nParticipant C Internet\
    \ \nof Things Platform\nBlockchain entry\nBlock 4\nParent chunk \nhash value\n\
    pro\nduct\nion \ninfo\nrma\ntion\nLogi\nstics \ninfo\nrma\ntion\nOrd\ner \ninfo\n\
    rma\ntion\nInve\nntor\ny \ninfo\nrma\ntion\nBlock \nhead\n \nParticipant D Internet\
    \ \nof Things Platform\nBlockchain entry\n5G agricultural product supply chain\
    \ cloud platform\nNetwork \nSlice 1\nNetwork \nSlice 2\nNetwork \nSlice 3\nNetwork\
    \ \nSlice 4\n5G\n5G\n5G\n5G\n \nFigure 35. 5G block chain agricultural products\
    \ supply chain management schematic diagram. \n5. Challenges of 5G Smart Agricultural\
    \ IoT \n5G will bring new development opportunities to agriculture, making the\
    \ smart agri-\ncultural IoT evolve in a smarter direction. At the same time, it\
    \ also brings many new prob-\nlems, and smart agriculture faces new challenges,\
    \ as shown in Figure 36. \nIntelligent \nmonitoring\nWater/Soil \nManagement\n\
    Management of \nplanting, breeding \nand growth\nPest \nmanagement\nSupply chain\
    \ \nmanagemen\nt\nIntelligent \nAgriculture \nPractice\nSmart agricultural machinery:\
    \ \nplanting, weeding, picking and \nharvesting\nLarge data of video and \nimage\
    \ types\nLarge amount of data\nTransmission \ndifficulties\nMultiple node \ndeployments\n\
    Numerous sensing \nnodes\nDifficulty in \nnetworking\nLarge amount of \nremote\
    \ sensing \ndata\nAI intelligence combined \nwith large amount of \ndata\nNode\
    \ intensive \ndeployment\nWide area deployment\nLarge amount of remote \nsensing\
    \ data\nLarge quantity \nof high-\nprecision \nmonitoring\nHigh real-time \nperformance\n\
    AI intelligence \ncombines large \namount of data\nHigh real-time\nRequire immediate\
    \ \nresponse\nMultiple \nterminal \ntypes\nPlatform \nhybrid\nAI intelligence\
    \ \ncombined with \nlarge amount of \nremote sensing \ndata\nNode wide area \n\
    deployment\n \nFigure 36. The new problems in the smart agriculture Internet of\
    \ Things. \nThese new problems bring new challenges to the application of smart\
    \ agriculture\nMany of these key issues may be partially solved with the introduction\
    \ of 5G technology\nFigure 35. 5G block chain agricultural products supply chain\
    \ management schematic diagram.\n5. Challenges of 5G Smart Agricultural IoT\n\
    5G will bring new development opportunities to agriculture, making the smart agricul-\n\
    tural IoT evolve in a smarter direction. At the same time, it also brings many\
    \ new problems,\nand smart agriculture faces new challenges, as shown in Figure\
    \ 36.\nproducts supply chain management schematic diagram of 5G block chain is\
    \ shown in\nure 35. \nAgricultural \nproducer\nAgricultural materials/\nagricultural\
    \ clothing \nsupplier\nWholesale \nsales market\nShop/\nSupermarket\n \nRegulators\n\
    Consumer\nBlock 1\nParent chunk \nhash value\npro\nduct\nion \ninfo\nrma\ntion\n\
    Logi\nstics \ninfo\nrma\ntion\nOrd\ner \ninfo\nrma\ntion\nInve\nntor\ny \ninfo\n\
    rma\ntion\nBlock \nhead\n \nParticipant A Internet \nof Things Platform\nBlockchain\
    \ entry\nBlock 2\nParent chunk \nhash value\npro\nduct\nion \ninfo\nrma\ntion\n\
    Logi\nstics \ninfo\nrma\ntion\nOrd\ner \ninfo\nrma\ntion\nInve\nntor\ny \ninfo\n\
    rma\ntion\nBlock \nhead\n \nParticipant B Internet \nof Things Platform\nBlockchain\
    \ entry\nBlock 3\nParent chunk \nhash value\npro\nduct\nion \ninfo\nrma\ntion\n\
    Logi\nstics \ninfo\nrma\ntion\nOrd\ner \ninfo\nrma\ntion\nInve\nntor\ny \ninfo\n\
    rma\ntion\nBlock \nhead\n \nParticipant C Internet \nof Things Platform\nBlockchain\
    \ entry\nBlock 4\nParent chunk \nhash value\npro\nduct\nion \ninfo\nrma\ntion\n\
    Logi\nstics \ninfo\nrma\ntion\nOrd\ner \ninfo\nrma\ntion\nInve\nntor\ny \ninfo\n\
    rma\ntion\nBlock \nhead\n \nParticipant D Internet \nof Things Platform\nBlockchain\
    \ entry\n5G agricultural product supply chain cloud platform\nNetwork \nSlice\
    \ 1\nNetwork \nSlice 2\nNetwork \nSlice 3\nNetwork \nSlice 4\n5G\n5G\n5G\n5G\n\
    \ \nFigure 35. 5G block chain agricultural products supply chain management schematic\
    \ diagram\n5. Challenges of 5G Smart Agricultural IoT \n5G will bring new development\
    \ opportunities to agriculture, making the smart \ncultural IoT evolve in a smarter\
    \ direction. At the same time, it also brings many new p\nlems, and smart agriculture\
    \ faces new challenges, as shown in Figure 36. \nIntelligent \nmonitoring\nWater/Soil\
    \ \nManagement\nManagement of \nplanting, breeding \nand growth\nPest \nmanagement\n\
    Supply chain \nmanagemen\nt\nIntelligent \nAgriculture \nPractice\nSmart agricultural\
    \ machinery: \nplanting, weeding, picking and \nharvesting\nLarge data of video\
    \ and \nimage types\nLarge amount of data\nTransmission \ndifficulties\nMultiple\
    \ node \ndeployments\nNumerous sensing \nnodes\nDifficulty in \nnetworking\nLarge\
    \ amount of \nremote sensing \ndata\nAI intelligence combined \nwith large amount\
    \ of \ndata\nNode intensive \ndeployment\nWide area deployment\nLarge amount of\
    \ remote \nsensing data\nLarge quantity \nof high-\nprecision \nmonitoring\nHigh\
    \ real-time \nperformance\nAI intelligence \ncombines large \namount of data\n\
    High real-time\nRequire immediate \nresponse\nMultiple \nterminal \ntypes\nPlatform\
    \ \nhybrid\nAI intelligence \ncombined with \nlarge amount of \nremote sensing\
    \ \ndata\nNode wide area \ndeployment\n \nFigure 36. The new problems in the smart\
    \ agriculture Internet of Things. \nThese new problems bring new challenges to\
    \ the application of smart agricul\nMany of these key issues may be partially\
    \ solved with the introduction of 5G techno\nFigure 36. The new problems in the\
    \ smart agriculture Internet of Things.\nThese new problems bring new challenges\
    \ to the application of smart agriculture.\nMany of these key issues may be partially\
    \ solved with the introduction of 5G technology.\n5G is the infrastructure of\
    \ the intelligent era. Its characteristics of “extremely high\nspeed, enormous\
    \ capacity and extremely low delay” can provide basic support for meeting\nthe\
    \ development needs of smart agriculture in the future. Compared with the 2–4G\
    \ era,\nthe demand for base stations and network control equipment has increased\
    \ signiﬁcantly\nin 5G. The large-scale application of 5G technology not only increases\
    \ the cost of network\ninfrastructure, but also the cost of power and operation,\
    \ and maintenance is much higher\nthan that of 4G, which brings challenges to\
    \ the ﬁeld agricultural production with low added\nvalue. However, 5G technology\
    \ still has limits when it comes to applications such as virtual\nreality, intelligent\
    \ production, and driverless driving. First, the deployment of 5G base\nstations\
    \ is not balanced. As many 5G base stations are distributed in sparsely populated\n\
    areas, such as ﬁelds, agriculture, and farming, there may be only a few 5G base\
    \ stations\nElectronics 2023, 12, 2336\n35 of 46\nin these areas, which cannot\
    \ effectively cover all of them, which brings challenges to the\npopularization\
    \ and application. Secondly, the introduction of 5G will bring a change of the\n\
    whole smart agriculture application paradigm. The architecture, perception, transmission,\n\
    computing, service, processing, and application mode of 5G Internet of Things\
    \ for smart\nagriculture will bring changes, and there will be challenges.\n5.1.\
    \ Fusion and Optimization of Sparse 5G Base Station and Heterogeneous Sensing\
    \ Network in\nSmart Agriculture\n5.1.1. Optimization of Hybrid Deployment of 5G\
    \ and Sensing Network\nAccording to the analysis, the characteristics of 5G network\
    \ in agriculture are sparse,\nuneven, and they have low coverage of network base\
    \ stations and slow deployment of\nfarm base stations in remote areas. This brings\
    \ challenges for the application of 5G in ﬁeld\nagriculture and plantation agriculture.\n\
    For this imbalance and sparsity feature, it can be conﬁgured from two aspects.\
    \ One is\nto optimize the deployment of sensing nodes, and the other is to deploy\
    \ in combination\nwith heterogeneous networks. The hybrid deployment strategy\
    \ for ﬁeld agriculture, for ex-\nample, 5G sensing nodes are deployed in key areas,\
    \ and other sensing nodes are deployed\nin other areas, and sensing deployment\
    \ optimization is realized through network resource\nvirtualization and other\
    \ technologies. When the communication nodes of large-scale in-\ntelligent agricultural\
    \ sensor networks are deployed in three-dimensional space under the\nbackground\
    \ of 5G, the traditional random node deployment mode has the problems of high\n\
    energy consumption, high cost, and node disconnection. Firstly, by taking advantage\
    \ of the\ncharacteristics of the high bandwidth of 5G communication, a hierarchical\
    \ communication\nscheme can be designed, and a hierarchical node optimal deployment\
    \ model, a communi-\ncation energy consumption model, and a fully connected sensor\
    \ information transmission\nnetwork model are established. On the premise of ensuring\
    \ the full connectivity of sensor\ncommunication network nodes in farmland, the\
    \ life cycle of communication network nodes\nis improved.\n(a) 5G sparse deployment\
    \ based on ﬁeld agricultural planting scenarios.\nCombined with the actual ﬁeld\
    \ agricultural planting scene, the 5G base station has a\nhigh working frequency\
    \ band and a large signal attenuation, and its coverage radius is only\n0.3–0.5\
    \ times that of the 4G base station. It is difﬁcult to meet the goal of low cost\
    \ and high\nbeneﬁt of network construction only by deploying a macro base station.\
    \ The micro-base\nstation has a small coverage radius and low construction cost.\
    \ In order to optimize the\ndeployment cost of 5G base stations, the heterogeneous\
    \ network architecture of “macro\nand micro collaboration” can be adopted. How\
    \ to combine smart agricultural business for\noptimal deployment is an important\
    \ issue. Heterogeneous networks can optimize the cost\nof 5G signal deployment\
    \ while realizing the coverage of agricultural operation areas and\noptimizing\
    \ the perceived cost.\n(b) Intensive deployment optimization of 5G and sensing\
    \ nodes in ﬁne agriculture.\nIn ﬁne agriculture, there are many parameters to\
    \ monitor, many types of business, and\nthe need for intensive sensing equipment,\
    \ which generates an explosion of mobile data.\nHow to realize intelligent and\
    \ efﬁcient green deployment planning of intelligent nodes such\nas base stations\
    \ and gateways with large area coverage for various intelligent agricultural\n\
    applications is one of the key issues. By deploying small base stations with lower\
    \ cost\nand closer to users, it becomes a feasible solution to construct ultra-dense\
    \ heterogeneous\nnetworks centered on monitoring objects.\n5.1.2. Optimization\
    \ of 5G and Sensing Network Gateway Deployment\nPreviously, the deployment optimization\
    \ of sensing nodes and 5G base stations were\nproposed in ﬁne agriculture. In\
    \ the integration of 5G and sensing devices in deployment, it\nis necessary to\
    \ combine the collaboration of the Internet of Things gateway to realize the\n\
    high-low speed switching and transmission of sensing data.\nElectronics 2023,\
    \ 12, 2336\n36 of 46\n(a) The deployment of edge gateway in the Internet of Things.\
    \ The conditions of edge\ngateway coverage and service terminal trafﬁc generator,\
    \ the factors affecting the ofﬂoad-\ning delay of computing tasks, and the constraints\
    \ of edge gateway capacity allocation.\nFollowing that, the edge gateway deployment\
    \ optimization model was established and\noptimized.\n(b) To solve the problem\
    \ of base station deployment in the Low Power Wide Area\nNetwork (LPWAN), the\
    \ received signal values of all terminal test points can be predicted\nby combining\
    \ the terminal receiving signal prediction module. Then, the prediction results\n\
    are transformed into the weight values of all terminal test points during clustering,\
    \ and\nthe terminal test points are clustered. In addition, the location of the\
    \ base station was\nadjusted to achieve the optimal coverage effect and realize\
    \ the deployment optimization in\nthe whole application scenario.\n5.2. Optimization\
    \ Control under Edge Computing in 5G Intelligent Agricultural Production\nThe\
    \ popularization and application of 5G intelligent agricultural Internet of Things\
    \ will\nbring major challenges to the traditional cloud computing model, such\
    \ as high latency and\njitter, no support for location awareness and mobility,\
    \ and non-adaptive communication\ntypes. The production of smart agriculture often\
    \ needs to deploy edge computing to\nachieve real-time computing and reasonable\
    \ allocation of resources.\n5.2.1. Automatic Phenotype Monitoring Based on 5G\
    \ Internet of Things\nBy monitoring and sensing plant growth phenotype, the analysis\
    \ of crop traits is\nof great reference signiﬁcance for cultivating crop varieties\
    \ with excellent traits such as\ndrought resistance, poison resistance, lodging\
    \ resistance, high nutrient rate, and salt and\nalkali resistance. It helps researchers\
    \ select seeds of good quality for the next generation of\nbreeding objects. There\
    \ are many common image-based phenotyping methods in the ﬁeld\nof plant phenotype.\
    \ Among them, the image recognition method based on visible light has\nlower requirements\
    \ on experimental equipment, higher practicability, and can collect large-\nscale\
    \ plant image data. Therefore, the current deep learning can be better applied\
    \ to those\nalgorithms that use visible light images. All these require high-speed\
    \ data transmission,\nand how to collect and control real-time data in multi-source\
    \ sensing devices is a problem\nworth studying. At present, the main concern of\
    \ plant leaf recognition methods based on\nvisible light images is that there\
    \ are not many kinds of recognition methods. There are many\nresearchers working\
    \ on automatic phenotypic sensing platforms, which require automatic\nsensing\
    \ data pickup. Combining the advantages of high bandwidth and dense deployment\n\
    of 5G to realize automatic measurement and real-time computation of phenotype\
    \ is a\nproblem worth studying.\n5.2.2. Intelligent Sensing Real-Time Control\
    \ for Intelligent Agricultural Machinery\nMore intelligent agricultural machinery\
    \ will participate in the future smart agriculture.\nThey can combine 5G Internet\
    \ of Things and edge computing to realize smart agricultural\nproduction. Among\
    \ them they face the real-time control of equipment, which requires\nrapid data\
    \ collection and processing.\nIn the operation of smart agricultural machinery,\
    \ sensors deployed on the roadside of\nfarmland can sense all kinds of environments\
    \ and obtain important trafﬁc information. For\nexample, ﬁxed sensors such as\
    \ vision sensors and millimeter wave sensors are installed\non the side of the\
    \ road, and the information collected by the sensors is sent to the edge\nserver\
    \ for processing to extract information such as vehicle location and vehicle trajectory.\n\
    According to the multi-source information obtained by roadside sensors, crop sensors,\n\
    and smart agricultural sensing equipment, real-time data processing is carried\
    \ out to\nanalyze the operation status and calculate the results. Mobile edge\
    \ computing provides\npowerful computing and storage capabilities. The side camera\
    \ and millimeter wave radar\nare fused based on the edge server. Through data\
    \ preprocessing, space synchronization,\ntime synchronization, and tracking algorithm,\
    \ they can cooperate with each other, jointly\nElectronics 2023, 12, 2336\n37\
    \ of 46\nbuilding an intelligent agricultural machinery environment sensing system\
    \ to make it more\nstable and reliable.\nDuring the operation of intelligent agricultural\
    \ machinery, target tracking should focus\non the following points: (1) Object\
    \ association: radar detection should be associated with\ncamera detection, while\
    \ the current fusion detection must be associated with the existing\ntrajectory;\
    \ (2) Tracking link: appropriate ﬁlter should be selected for tracking; (3) Tracking\n\
    management: tracking object database needs to be maintained.\n5.3. Scheduling\
    \ Optimization of Heterogeneous Nodes under 5G Smart Agriculture\nHow to optimize\
    \ the scheduling of sensing nodes in different rates, resources, and\nnetworks\
    \ is a problem to be studied in the intelligent agricultural IoT under 5G.\n5.3.1.\
    \ Sense Scheduling for 5G Smart Agriculture\nUnder such circumstances, how to\
    \ optimize the deployment of network resources and\nnodes to achieve better overall\
    \ network performance is a problem worth studying.\n(a). Sensing task collaboration\
    \ based on 5G: Sensing task collaboration is a hot issue in\nsensor networks.\
    \ Based on the connectivity, coverage, survivability, and task completion\nrequirements\
    \ of the network, this paper proposes a collaboration mechanism based on\nthe\
    \ limited energy, computing, and storage capacity of the sensing nodes and the\
    \ task\ncompletion requirements. The network topology is reconstructed by adjusting\
    \ the transmit\npower of nodes, neighbor selection, sleep scheduling, or mobile\
    \ node location. The decom-\nposition, assignment, scheduling, and execution of\
    \ tasks are accomplished cooperatively by\ncoordinating the behavior of mobile\
    \ sensor nodes. Topology reconstruction optimization is\nmainly carried out in\
    \ edge nodes and load balancing. In smart agriculture, the perception\nequipment\
    \ is more diverse, and the perception task is more complex.\n(b). Cooperative\
    \ scheduling of large agricultural machinery equipment: agriculture-\noriented\
    \ large agricultural machinery includes unmanned aerial vehicles (UAVs), mutual\n\
    sensing, and task coordination of multi-aerial robots. For example, building the\
    \ social\nInternet of Things creates a dynamic social network for each object\
    \ connected to the Internet\nof Things. Social networks are extended through node\
    \ proﬁles and trust levels to ﬁnd\nobjects that contribute to IoT applications\
    \ and solve resource management problems. Assign\nsensitive tasks fairly to objects\
    \ in the social network. How to optimize the sensing task\nof massive heterogeneous\
    \ sensing devices in the Internet of Things for smart agriculture.\nIt is still\
    \ a challenge to realize the efﬁcient collection of sensing data and the maximum\n\
    efﬁciency of network resources by abstracting network resources.\n5.3.2. Optimization\
    \ of 5G Network Signal Coverage Scheduling for Agricultural UAV\nIn addition to\
    \ the upstream and downstream rate, end-to-end delay of services, end-\nto-end\
    \ delay of control, and positioning accuracy, the coverage height of wireless\
    \ signals is\none of the most important requirements for 5G networks in agriculture.\n\
    According to the requirements of UAV network indicators in each scenario in IMT-\n\
    2020 (5G), Advance Group—White Paper on 5G UAV Application, the coverage height\n\
    requirements of wireless signals of networked UAV in the application ﬁeld are\
    \ shown in\nTable 9.\nOn the basis of the existing network, it is technically\
    \ feasible to deploy a small number\nof base stations for the 5G communication\
    \ requirements of agricultural UAVs. However,\nthe actual network planning still\
    \ needs to focus on several issues.\n(a) Adjacent area planning.\nIn order to\
    \ make connected UAVs ﬂy continuously in the air, in addition to seamless\n5G\
    \ wireless network signals, civil UAVs also need to be able to switch smoothly\
    \ between\ndifferent cells and different base stations. In this way, it is necessary\
    \ to cover the high\nlevel of the community to have a reasonable neighborhood\
    \ relationship. In addition, the\nUAV communication terminal needs to switch from\
    \ the low-level 5G wireless network\nto the high-level 5G wireless network when\
    \ taking off. This also requires reasonable\nElectronics 2023, 12, 2336\n38 of\
    \ 46\nneighborhood planning between the 5G cell covering the high-rise and its\
    \ neighboring 5G\ncell. Similarly, the UAV communication terminal needs to switch\
    \ from the high-level 5G\nwireless network to the low-level 5G wireless network\
    \ when landing. It is also necessary to\nmake reasonable neighborhood planning\
    \ between the 5G cell covering the low layer and\nits adjacent high-rise 5G cell.\
    \ Its switching band is controlled at about 100 m in the air.\n(b) Interference\
    \ problem.\n5G wireless networks are also self-interfering systems. All base stations\
    \ share a band-\nwidth of 100 MHz. Therefore, it is necessary to control the coverage\
    \ of the signal through\nreasonable planning and optimization. In this way, it\
    \ is necessary to avoid discontinuous\ncoverage or blind coverage caused by insufﬁcient\
    \ signal, and to avoid interference in other\ncommunities due to over coverage.\
    \ At the same time, the mutual interference between\nthe 5G cell covering the\
    \ lower layer and the 5G cell covering the upper layer should be\navoided. Of\
    \ course, this will require a long period of experimentation and exploration.\n\
    Table 9. Requirements for coverage height of wireless signals of networked UAVs\
    \ in application ﬁelds.\nNo.\nApplication Area\nBusiness Attribute\nCover Height/m\n\
    Coverage\n1\nAgricultural and forestry plant\nprotection\nSpraying pesticide\n\
    10\ncountryside\n2\nAgricultural and forestry\nsurveying and mapping\nAgricultural\
    \ land survey\n200\ncountryside\n3\nAgricultural inspection\n1080p Video return\n\
    100\nPatrol inspection\ncovers ﬁeld agriculture\n4\nAgricultural formation ﬂight\n\
    UAV formation ﬂight\n200\ncountryside\n5\nFuture cloud AI\nUAV cloud-based autonomous\n\
    ﬂight\n300\ncountryside\n6\nAgricultural and forestry\nmonitoring\nCrop growth\
    \ monitoring\n100\ncountryside\n5.4. Fault Detection and Self-Healing for 5G Intelligent\
    \ Agricultural Platform\nSmart agriculture 5G-IoT faces increasing network scale\
    \ and density, dense terminal\nconnections, and higher intelligence, and the failure\
    \ rate will increase. The production\nefﬁciency of large-scale smart agriculture\
    \ is an important issue. With the integration of\n5G, many intelligent applications\
    \ will be gradually popularized. These apps are built\naround the 5G Internet\
    \ of Things. How to quickly identify the faulty node or device and\nthe self-healing\
    \ ability of the platform are important research issues.\n5.4.1. Node Fault Identiﬁcation\
    \ and Early Warning Based on Heterogeneous Sensing\nData Fusion\nCombining the\
    \ collected sensing data for computational analysis and network topol-\nogy to\
    \ identify node faults is a problem worth studying. Due to the mixed deployment\n\
    of 5G and various sensing devices, mixed data sources, multi-hop communication,\
    \ and\ntransmission route changes, how to realize the fault identiﬁcation of sensing\
    \ nodes and\npossible fault detection is an important research issue.\n5.4.2.\
    \ Research on Fault Tolerance Based on 5G Heterogeneous Fusion Sensing Network\n\
    Traditional perceptual networks generally assume unreliable perception. The actual\n\
    agricultural production will appear to be all kinds of failures. Because of the\
    \ intensive\ndeployment, the cost of ensuring all reliable operations is high.\
    \ Therefore, it is worth\nstudying that fault tolerance can guarantee the normal\
    \ operation of the whole agricultural\nproduction in a certain period of time\
    \ under limited fault.\nElectronics 2023, 12, 2336\n39 of 46\n5.4.3. Self-Healing\
    \ Mechanism Based on 5G Heterogeneous Fusion Sensing Network\nIn smart agriculture,\
    \ production is blocked due to the failure of the sensing equipment\nnetwork,\
    \ which affects efﬁciency. Therefore, it is necessary to study how to self-heal\
    \ after\nfaults occur, such as network topology self-healing, to guarantee node\
    \ pathways. For\nexample, perceptual repair under dense nodes. An additional example\
    \ is 5G gateway\ncoverage self-healing.\n5.5. AI Application Optimization for\
    \ 5G Intelligent Agricultural Internet of Things\nThe application of 5G brings\
    \ new opportunities for smart agriculture, which is ex-\npected to solve the problem\
    \ of data transmission and storage. With the development of\nartiﬁcial intelligence,\
    \ it is an important issue to study lightweight deep artiﬁcial intelligence\n\
    algorithms or platforms combined with various scenarios of smart agriculture.\n\
    Artiﬁcial intelligence algorithms represented by deep learning have laid the foundation\n\
    for many scenarios of smart agriculture applications. With the popularization\
    \ of 5G, the\nrange of application scenarios of smart agriculture will be greatly\
    \ expanded. However, the\ncurrent existence represented by deep learning will\
    \ face the important challenge of how to\nachieve reliable and effective operation\
    \ under the condition of small cost in the scenario of\nsmart agriculture, relying\
    \ on massive data and powerful computing power.\n5.5.1. Lightweight Deep Learning\
    \ Algorithm Based on 5G-IoT Edge Computing\nEdge computing equipment has some\
    \ computing ability, but its computing ability is\nnot enough for massive data\
    \ model training. The challenge is how to design deep learning\nor machine learning\
    \ algorithms suitable for agricultural production. Better results can\nbe obtained\
    \ by training on small sample data, reducing the amount of data transmission,\n\
    reducing the cost of communication resources, and improving the real-time accuracy,\
    \ which\nis a problem worth studying.\n5.5.2. Multi-Source Data-Sensing Machine\
    \ Learning Algorithm for Smart Agriculture\nIn the 5G scenario, sensing nodes\
    \ are densely deployed, and heterogeneous sensing\ndata need to be calculated\
    \ and analyzed to serve the upper layer. However, there are\noften low data quality,\
    \ multi-source, heterogeneous, and multi-modal sensing data, and\nchanges in network\
    \ topology. How to calculate these mixed and redundant low-quality\ndata by clustering,\
    \ statistics, Bayesian, and other machine learning methods is an important\nresearch\
    \ problem.\n5.6. 5G-IoT System Service Model for Smart Agriculture\nAn important\
    \ means to promote the implementation of smart agriculture is the in-\nformation\
    \ physical fusion system based on 5G. The typical application mode of smart\n\
    agriculture is to comprehensively perceive agricultural information through the\
    \ agricul-\ntural Internet of Things. Massive sensing devices for agricultural\
    \ IoT are deployed in the\nwhole process of agricultural production and processing.\
    \ Various information (environ-\nmental temperature and humidity, soil moisture,\
    \ carbon dioxide, images, etc.) is collected\nthrough various networks, including\
    \ 5G. Traditional agricultural models will be changed\nby means of cloud computing,\
    \ big data, edge computing, and artiﬁcial intelligence. It can\nrealize intelligent\
    \ perception, intelligent warning, intelligent decision-making, intelligent\n\
    analysis, and expert online guidance of agricultural production environment to\
    \ provide\nprecise planting, visual management, and intelligent decision-making\
    \ for agricultural\nproduction. This is to realize the intelligent management\
    \ of agricultural visual remote\ndiagnosis, remote control, disaster warning,\
    \ and so on, and gradually establish the visual\ncommunication and application\
    \ mode of agricultural information services. Relying on\nthe knowledge of agricultural\
    \ experts stored in the knowledge base, reasoning, analysis,\nand other mechanisms\
    \ were used to guide the production and circulation of agriculture\nand animal\
    \ husbandry. It promotes the transformation of traditional agriculture, which\
    \ is\nhuman-centered and relies on isolated machinery production mode, to modern\
    \ smart agri-\nElectronics 2023, 12, 2336\n40 of 46\nculture, which is based on\
    \ information and software production mode. How to construct\nan appropriate application\
    \ service paradigm and model for intelligent agriculture 5G-IoT\nis an important\
    \ issue to be studied.\n5.7. Security Issues of 5G Internet of Things for Smart\
    \ Agriculture\nThe future of intelligent agriculture is highly intelligent, informationized,\
    \ and un-\nmanned, and security issues should be a concern. Due to the application\
    \ of 5G technology,\nthere are many data ﬂows and information ﬂows which are prone\
    \ to data deception, etc.,\nwhich will lead to serious consequences, such as the\
    \ death of crops or the poor quality of\nanimal husbandry objects caused by incorrect\
    \ pesticide spraying.\nAt present, there are many research results on the security\
    \ of the Internet of Things.\nIn general, attacks in IoT applications are classiﬁed\
    \ using the following two criteria: (1)\ninternal or external attacks and (2)\
    \ passive or active attacks. Therefore, the threat model can\nbe classiﬁed into\
    \ attacks targeting privacy, authentication, conﬁdentiality, availability, and\n\
    integrity attributes based on the characteristics of attacks that attempt to compromise\
    \ IoT\nagricultural nodes, namely IoT devices, fog nodes, and cloud nodes. 5G\
    \ itself is relatively\nsecure. However, due to the speciﬁc application scenarios,\
    \ the security problems of smart\nagriculture have their speciﬁc characteristics,\
    \ which require joint analysis and research.\n5.7.1. Information Traceability\
    \ of the Whole Process of Intelligent Agricultural Production\nBased on 5G Blockchain\n\
    Food safety has always been a matter of great concern to the public. The traditional\n\
    tracing system has some shortcomings, such as information opacity, data easy to\
    \ be tam-\npered with, poor security, and relative closure. In the future, the\
    \ development of 5G,\ncombined with blockchain technology and its unique advantages,\
    \ will provide a new\nsolution for the reliable traceability of the agricultural\
    \ supply chain. In combination with\nthe communication capability of 5G, blockchain\
    \ technology can be combined with the\nsensing equipment of the agricultural Internet\
    \ of Things for semantic segmentation and\ntracking to achieve high security.\n\
    5.7.2. Intrusion Detection for Intelligent Agricultural Production Based on 5G\n\
    With the popularization of 5G Internet of Things in smart agriculture, the degree\n\
    of intelligent and networked agricultural production is getting higher and higher,\
    \ and\nmore and more security issues need to be paid attention to. Unique security\
    \ issues and\nvulnerabilities may arise, including network, control, communications,\
    \ services, etc. How\nto combine the agricultural production process and the structural\
    \ characteristics of 5G IoT\nto establish a security mechanism, rapid detection,\
    \ and early warning of the intrusion of\nkey steps in the production process is\
    \ an important challenge in the future.\n6. Summary\nIn the future, smart agriculture,\
    \ after 5G technology transformation and upgrading,\nwill show the following characteristics:\
    \ unmanned operation, precise production, reﬁned\ncultivation, standardized production,\
    \ and intelligent supervision. Due to its low latency,\nmassive data transmission,\
    \ and massive connectivity, 5G is contributing to the development\nof IoT in agriculture.\
    \ The combination of 5G with other technologies has spawned a number\nof agricultural\
    \ applications to reduce the environmental impact of pesticides, protect natural\n\
    resources, improve animal welfare and help farmers increase yields and save costs.\
    \ This\npaper summarizes the impact of 5G on the Internet of Things, smart agriculture,\
    \ and related\ntechnologies. The key technologies and scientiﬁc issues affecting\
    \ the development of 5G-IoT\nwere analyzed to provide some ideas for the development\
    \ of 5G in smart agriculture. The\nscope of smart agriculture is relatively large,\
    \ and many details have not been discussed\nin-depth. Further efforts will be\
    \ made in the future.\nAuthor Contributions: Conceptualization, J.L., L.S. and\
    \ X.L.; methodology, X.L.; investigation, J.L.;\nresources, X.L.; data curation,\
    \ L.S.; writing—original draft preparation, J.L. and Y.L.; writing—review\nElectronics\
    \ 2023, 12, 2336\n41 of 46\nand editing, J.L. and Y.L.; visualization, J.L.; supervision,\
    \ X.L. All authors have read and agreed to\nthe published version of the manuscript.\n\
    Funding: This research was fundedby the National Natural Science Foundation of\
    \ China (62176067);\nJoint Fund for Basic and Applied Basic Research in Guangdong\
    \ Province (20A1515111162); Scientiﬁc\nand Technological Planning Project of Guangzhou\
    \ (201903010041, 202103000040); Key Project of\nGuangdong Province Basic Research\
    \ Foundation (2020B1515120095); Project Supported by Guang-\ndong Province Universities\
    \ and Colleges Pearl River Scholar Funded Scheme (2019).\nConﬂicts of Interest:\
    \ The authors declare no conﬂict of interest.\nReferences\n1.\nZhao, C. Research\
    \ on the development status and strategic objectives of smart agriculture. Smart\
    \ Agric. 2019, 1, 1–7. (In Chinese)\n2.\nAyaz, M.; Ammad-Uddin, M.; Sharif, Z.;\
    \ Mansour, A.; Aggoune, E.-H.M. Internet-of-Things (IoT)-based smart agriculture:\n\
    Toward making the ﬁelds talk. IEEE Access 2019, 7, 129551–129583. [CrossRef]\n\
    3.\nQazi, S.; Khawaja, B.A.; Farooq, Q.U. IoT-Equipped and AI-Enabled Next Generation\
    \ Smart Agriculture: A Critical Review,\nCurrent Challenges and Future Trends.\
    \ IEEE Access. 2022, 10, 21219–21235. [CrossRef]\n4.\nJawhar, I.; Mohamed, N.;\
    \ Kesserwan, N.; Al-Jaroodi, J. Networking Architectures and Protocols for Multi-Robot\
    \ Systems in\nAgriculture 4.0. In Proceedings of the 2022 IEEE International Systems\
    \ Conference (SysCon), Montreal, QC, Canada, 25–28 April\n2022; pp. 1–6. [CrossRef]\n\
    5.\nOruma, S.O.; Misra, S.; Fernandez-Sanz, L. Agriculture 4.0: An Implementation\
    \ Framework for Food Security Attainment in\nNigeria’s Post-COVID-19 Era. IEEE\
    \ Access 2021, 9, 83592–83627. [CrossRef]\n6.\nMishra, S.; Nayak, S.; Yadav, R.\
    \ An Energy Efﬁcient LoRa-based Multi-Sensor IoT Network for Smart Sensor Agriculture\
    \ System.\nIn Proceedings of the 2023 IEEE Topical Conference on Wireless Sensors\
    \ and Sensor Networks, Las Vegas, NV, USA, 22–25 January\n2023; pp. 28–31. [CrossRef]\n\
    7.\nQuy, V.K.; Hau, N.V.; Anh, D.V.; Quy, N.M.; Ban, N.T.; Lanza, S.; Randazzo,\
    \ G.; Muzirafuti, A. IoT-Enabled Smart Agriculture:\nArchitecture, Applications,\
    \ and Challenges. Appl. Sci. 2022, 12, 3396. [CrossRef]\n8.\nValecce, G.; Strazzella,\
    \ S.; Grieco, L.A. On the interplay between 5g, mobile edge computing and robotics\
    \ in smart agriculture\nscenarios. In Proceedings of the Ad-Hoc, Mobile, and Wireless\
    \ Networks: 18th International Conference on Ad-Hoc Networks\nand Wireless, ADHOC-NOW\
    \ 2019, Luxembourg, 1–3 October 2019; Springer International Publishing: Berlin/Heidelberg,\n\
    Germany, 2019; pp. 549–559.\n9.\nLiya, M.L.; Arjun, D. A survey of LPWAN technology\
    \ in agricultural ﬁeld. In Proceedings of the 2020 Fourth International\nConference\
    \ on I-SMAC (IoT in Social, Mobile, Analytics and Cloud)(I-SMAC), Palladam, India,\
    \ 7–9 October 2020; pp. 313–317.\n10.\nRadoglou-Grammatikis, P.; Sarigiannidis,\
    \ P.; Lagkas, T.; Moscholios, I. A compilation of UAV applications for precision\
    \ agriculture.\nComput. Netw. 2020, 172, 107148. [CrossRef]\n11.\nKaur, H.; Kushwaha,\
    \ A.S. A Review on Integration of Big Data and IoT. In Proceedings of the 2018\
    \ 4th International Conference\non Computing Sciences (ICCS), Jalandhar, India,\
    \ 30–31 August 2018; pp. 200–203. [CrossRef]\n12.\nShobanadevi, A.; Maragatham,\
    \ G. Data mining techniques for IoT and big data—A survey. In Proceedings of the\
    \ 2017 International\nConference on Intelligent Sustainable Systems (ICISS), Palladam,\
    \ India, 7–8 December 2017; pp. 607–610. [CrossRef]\n13.\nLi, B.-H.; Chai, X.-D.;\
    \ Liu, Y.; Chen, L.; Wei, D.-Y. Wisdom Iot System Development Strategy Study.\
    \ China Engineering Science:\n1–11. Available online: http://kns.cnki.net/kcms/detail/11.4421.G3.20220720.1149.002.html\
    \ (accessed on 28 September 2022).\n(In Chinese).\n14.\nShaﬁ, M.; Molisch, A.F.;\
    \ Smith, P.J.; Haustein, T.; Zhu, P.; De Silva, P.; Tufvesson, F.; Benjebbour,\
    \ A.; Wunder, G. 5G: A Tutorial\nOverview of Standards, Trials, Challenges, Deployment,\
    \ and Practice. IEEE J. Sel. Areas Commun. 2017, 35, 1201–1221. [CrossRef]\n15.\n\
    Chih-Lin, I.; Han, S.; Xu, Z.; Wang, S.; Sun, Q.; Chen, Y. New Paradigm of 5G\
    \ Wireless Internet. IEEE J. Sel. Areas Commun. 2016,\n34, 474–482. [CrossRef]\n\
    16.\nPalattella, M.R.; Dohler, M.; Grieco, A.; Rizzo, G.; Torsner, J.; Engel,\
    \ T.; Ladid, L. Internet of Things in the 5G Era: Enablers,\nArchitecture, and\
    \ Business Models. IEEE J. Sel. Areas Commun. 2016, 34, 510–527. [CrossRef]\n\
    17.\nLi, S.; Da Xu, L.; Zhao, S. 5G Internet of Things: A survey. J. Ind. Inf.\
    \ Integr. 2018, 10, 1–9. [CrossRef]\n18.\nWang, D.; Chen, D.; Song, B.; Guizani,\
    \ N.; Yu, X.; Du, X. From IoT to 5G I-IoT: The Next Generation IoT-Based Intelligent\n\
    Algorithms and 5G Technologies. IEEE Commun. Mag. 2018, 56, 114–120. [CrossRef]\n\
    19.\nKalyani, Y.; Collier, R. A Systematic Survey on the Role of Cloud, Fog, and\
    \ Edge Computing Combination in Smart Agriculture.\nSensors 2021, 21, 5922. [CrossRef]\n\
    20.\nWang, N.; Wang, P.; Alipour-Fanid, A.; Jiao, L.; Zeng, K. Physical-Layer\
    \ Security of 5G Wireless Networks for IoT: Challenges and\nOpportunities. IEEE\
    \ Internet Things J. 2019, 6, 8169–8181. [CrossRef]\n21.\nShaﬁque, K.; Khawaja,\
    \ B.A.; Sabir, F.; Qazi, S.; Mustaqim, M. Internet of Things (IoT) for Next-Generation\
    \ Smart Systems: A\nReview of Current Challenges, Future Trends and Prospects\
    \ for Emerging 5G-IoT Scenarios. IEEE Access 2020, 8, 23022–23040.\n[CrossRef]\n\
    22.\nTang, Y.; Dananjayan, S.; Hou, C.; Guo, Q.; Luo, S.; He, Y. A survey on the\
    \ 5G network and its impact on agriculture: Challenges\nand opportunities. Comput.\
    \ Electron. Agric. 2021, 180, 105895. [CrossRef]\nElectronics 2023, 12, 2336\n\
    42 of 46\n23.\nOgbodo, E.U.; Abu-Mahfouz, A.M.; Kurien, A.M. A Survey on 5G and\
    \ LPWAN-IoT for Improved Smart Cities and Remote Area\nApplications: From the\
    \ Aspect of Architecture and Security. Sensors 2022, 22, 6313. [CrossRef]\n24.\n\
    Khanh, Q.V.; Hoai, N.V.; Manh, L.D.; Le, A.N.; Jeon, G. Wireless communication\
    \ technologies for IoT in 5G: Vision, applications,\nand challenges. Wirel. Commun.\
    \ Mob. Comput. 2022, 2022, 3229294. [CrossRef]\n25.\nMekala, M.S.; Viswanathan,\
    \ P. A Survey: Smart agriculture IoT with cloud computing. In Proceedings of the\
    \ 2017 International\nConference on Microelectronic Devices, Circuits and Systems\
    \ (ICMDCS), Vellore, India, 10–12 August 2017.\n26.\nDagar, R. Smart Farming—IoT\
    \ in Agriculture. In Proceedings of the ICIRCA 2018, Coimbatore, India, 11–12\
    \ July 2018.\n27.\nFarooq, M.S.; Riaz, S.; Abid, A.; Abid, K.; Naeem, M.A. A Survey\
    \ on the Role of IoT in Agriculture for the Implementation of\nSmart Farming.\
    \ IEEE Access 2019, 7, 156237–156271. [CrossRef]\n28.\nDevare, J.; Hajare, N.\
    \ A Survey on IoT Based Agricultural Crop Growth Monitoring and Quality Control.\
    \ In Proceedings of the\n2019 International Conference on Communication and Electronics\
    \ Systems (ICCES), Coimbatore, India, 17–19 July 2019.\n29.\nFiona, J.R.; Anitha,\
    \ J. Automated Detection of Plant diseases and Crop Analysis in Agriculture using\
    \ Image Processing Techniques:\nA Survey. In Proceedings of the 2019 IEEE International\
    \ Conference on Electrical, Computer and Communication Technologies\n(ICECCT),\
    \ Coimbatore, India, 20–22 February 2019.\n30.\nBh Ag At, M.; Kumar, D.; Kumar,\
    \ D. Role of Internet of Things (IoT) in Smart Farming: A Brief Survey. In Proceedings\
    \ of the\nDevices for Integrated Circuit Conference, CSE Department, NIT Jamshedpur,\
    \ Jamshedpur, India, 23–24 March 2019.\n31.\nSarker, V.K.; Queralta, J.P.; Gia,\
    \ T.N.; Tenhunen, H.; Westerlund, T. A Survey on LoRa for IoT: Integrating Edge\
    \ Computing. In\nProceedings of the International Workshop on Smart Living with\
    \ IoT, Cloud and Edge Computing (SLICE 2019), Rome, Italy,\n10–13 June 2019.\n\
    32.\nBacco, M.; Berton, A.; Ferro, E.; Gennaro, C.; Gotta, A.; Matteoli, S.; Paonessa,\
    \ F.; Ruggeri, M.; Virone, G.; Zanella, A. Smart\nfarming: Opportunities, challenges\
    \ and technology enablers. In Proceedings of the 2018 IoT Vertical and Topical\
    \ Summit on\nAgriculture-Tuscany (IOT Tuscany), Tuscany, Italy, 8–9 May 2018;\
    \ pp. 1–6.\n33.\nKour, V.P.; Arora, S. Recent Developments of the Internet of\
    \ Things in Agriculture: A Survey. IEEE Access 2020, 8, 129924–129957.\n[CrossRef]\n\
    34.\nFriha, O.; Ferrag, M.A.; Shu, L.; Maglaras, L.; Wang, X. Internet of Things\
    \ for the Future of Smart Agriculture: A Comprehensive\nSurvey of Emerging Technologies.\
    \ IEEE/CAA J. Autom. Sin. 2020, 8, 718–752. [CrossRef]\n35.\nRayhana, R.; Xiao,\
    \ G.; Liu, Z. RFID Sensing Technologies for Smart Agriculture. IEEE Instrum. Meas.\
    \ Mag. 2021, 24, 50–60.\n[CrossRef]\n36.\nYang, X.; Shu, L.; Chen, J.; Ferrag,\
    \ M.A.; Wu, J.; Nurellari, E.; Huang, K. A Survey on Smart Agriculture: Development\
    \ Modes,\nTechnologies, and Security and Privacy Challenges. IEEE/CAA J. Autom.\
    \ Sin. 2021, 8, 273–302. [CrossRef]\n37.\nLiu, Y. From Industry 4.0 to Agriculture\
    \ 4.0 Current Status Enabling Technologies and Research Challenges. IEEE Trans.\
    \ Ind.\nInform. 2021, 17, 4322–4334. [CrossRef]\n38.\nBhat, S.A.; Huang, N.F.\
    \ Big Data and AI Revolution in Precision Agriculture: Survey and Challenges.\
    \ IEEE Access 2021, 9,\n110209–110222. [CrossRef]\n39.\nSinha, B.B.; Dhanalakshmi,\
    \ R. Recent advancements and challenges of Internet of Things in smart agriculture:\
    \ A survey. Future\nGener. Comput. Syst. 2021, 126, 169–184. [CrossRef]\n40.\n\
    Tao, W. Review of the internet of things communication technologies in smart agriculture\
    \ and challenges. Comput. Electr. Eng.\n2021, 189, 106352. [CrossRef]\n41.\nIdoje,\
    \ G. Survey for smart farming technologies: Challenges and issues. Comput. Electr.\
    \ Eng. 2021, 92, 107104. [CrossRef]\n42.\nMisra, N.N.; Dixit, Y.; Al-Mallahi,\
    \ A.; Bhullar, M.S.; Upadhyay, R.; Martynenko, A. IoT, Big Data, and Artiﬁcial\
    \ Intelligence in\nAgriculture and Food Industry. IEEE Internet Things J. 2022,\
    \ 9, 6305–6324. [CrossRef]\n43.\nYarali, A. AI, 5G, and IoT. In Intelligent Connectivity:\
    \ AI, IoT, and 5G; IEEE: Piscataway, NJ, USA, 2022; pp. 117–131.\n44.\nKar, S.;\
    \ Mishra, P.; Wang, K.-C. 5G-IoT Architecture for Next Generation Smart Systems.\
    \ In Proceedings of the 2021 IEEE 4th 5G\nWorld Forum (5GWF), Montreal, QC, Canada,\
    \ 13–15 October 2021; pp. 241–246. [CrossRef]\n45.\nKhakimov, A.; Salakhutdinov,\
    \ I.; Omolikov, A.; Utaganov, S. Traditional and current-prospective methods of\
    \ agricultural plant\ndiseases detection: A review. In Proceedings of the IOP\
    \ Conference Series: Earth and Environmental Science, 3rd International\nConference\
    \ on Agriculture and Bio-industry (ICAGRI 2021), Banda Aceh, Indonesia, 13–14\
    \ October 2021; Volume 951.\n46.\nDeb, S.D.; Jha, R.K.; Kumar, S. ConvPlant-Net:\
    \ A Convolutional Neural Network based Architecture for Leaf Disease Detection\
    \ in\nSmart Agriculture. In Proceedings of the 2023 National Conference on Communications\
    \ (NCC), Guwahati, India, 23–26 February\n2023; pp. 1–6. [CrossRef]\n47.\nTreboux,\
    \ J.; Genoud, D. High Precision Agriculture: An Application Of Improved Machine-Learning\
    \ Algorithms. In Proceedings\nof the 2019 6th Swiss Conference on Data Science\
    \ (SDS), Bern, Switzerland, 14 June 2019; pp. 103–108. [CrossRef]\n48.\nAsokan,\
    \ A.; Anitha, J. Machine Learning based Image Processing Techniques for Satellite\
    \ Image Analysis—A Survey. In\nProceedings of the 2019 International Conference\
    \ on Machine Learning, Big Data, Cloud and Parallel Computing (COMITCon),\nFaridabad,\
    \ India, 14–16 February 2019; pp. 119–124. [CrossRef]\n49.\nGarcia, M.B.; Ambat,\
    \ S.; Adao, R.T. Tomayto, Tomahto: A Machine Learning Approach for Tomato Ripening\
    \ Stage Identiﬁcation\nUsing Pixel-Based Color Image Classiﬁcation. In Proceedings\
    \ of the 2019 IEEE 11th International Conference on Humanoid,\nNanotechnology,\
    \ Information Technology, Communication and Control, Environment, and Management\
    \ (HNICEM), Laoag,\nPhilippines, 29 November–1 December 2019; pp. 1–6. [CrossRef]\n\
    Electronics 2023, 12, 2336\n43 of 46\n50.\nThakor, H.P.; Iyer, S. Development\
    \ and Analysis of Smart Digi-farming Robust Model for Production Optimization\
    \ in Agriculture.\nIn Proceedings of the 2019 6th International Conference on\
    \ Computing for Sustainable Global Development (INDIACom), New\nDelhi, India,\
    \ 13–15 March 2019; pp. 461–465.\n51.\nBandara, T.M.; Mudiyanselage, W.; Raza,\
    \ M. Smart farm and monitoring system for measuring the Environmental condition\
    \ using\nwireless sensor network—IOT Technology in farming. In Proceedings of\
    \ the 2020 5th International Conference on Innovative\nTechnologies in Intelligent\
    \ Systems and Industrial Applications (CITISIA), Sydney, Australia, 25–27 November\
    \ 2020; pp. 1–7.\n[CrossRef]\n52.\nGarcia-Sanchez, A.J.; Garcia-Sanchez, F.; Garcia-Haro,\
    \ J. Wireless sensor network deployment for integrating video-surveillance\nand\
    \ data-monitoring in precision agriculture over distributed crops. Comput. Electron.\
    \ Agric. 2011, 75, 288–303. [CrossRef]\n53.\nLiu, H.; Reibman, A.R.; Ault, A.C.;\
    \ Krogmeier, J.V. Spatial segmentation for processing videos for farming automation.\
    \ Comput.\nElectron. Agric. 2021, 184, 106095. [CrossRef]\n54.\nSabzi, S.; Abbaspour-Gilandeh,\
    \ Y.; Arribas, J.I. An automatic visible-range video weed detection, segmentation\
    \ and classiﬁcation\nprototype in potato ﬁeld. Heliyon 2020, 6, e03685. [CrossRef]\n\
    55.\nJiang, H.; Li, X.; Safara, F. IoT-based agriculture: Deep learning in detecting\
    \ apple fruit diseases. Microprocess. Microsyst. 2021,\n104321. [CrossRef]\n56.\n\
    Hejazi, H.; Rajab, H.; Cinkler, T.; Lengyel, L. Survey of platforms for massive\
    \ IoT. In Proceedings of the 2018 IEEE International\nConference on Future IoT\
    \ Technologies (Future IoT), Eger, Hungary, 18–19 January 2018; pp. 1–8. [CrossRef]\n\
    57.\nZhang, F.; Wan, X.; Zheng, T.; Cui, J.; Li, X.; Yang, Y. Smart Greenhouse\
    \ Management System based on NB-IoT and Smartphone.\nIn Proceedings of the 2020\
    \ 17th International Joint Conference on Computer Science and Software Engineering\
    \ (JCSSE), Bangkok,\nThailand, 4–6 November 2020; pp. 36–41. [CrossRef]\n58.\n\
    Valecce, G.; Petruzzi, P.; Strazzella, S.; Grieco, L.A. NB-IoT for Smart Agriculture:\
    \ Experiments from the Field. In Proceedings of\nthe 2020 7th International Conference\
    \ on Control, Decision and Information Technologies (CoDIT), Prague, Czech Republic,\
    \ 29\nJune 2020–2 July 2020; pp. 71–75. [CrossRef]\n59.\nFei, Y.; Zhuang, Y.;\
    \ Liu, X.; Zhao, Q.; Liao, G.; Fu, Q. Development of an Intelligent Monitoring\
    \ System for Agricultural Machinery.\nIn Proceedings of the 2019 3rd International\
    \ Conference on Robotics and Automation Sciences (ICRAS), Wuhan, China, 1–3 June\n\
    2019; pp. 161–165. [CrossRef]\n60.\nDong, Z.; Duan, J.; Wang, M.; Zhao, J.; Wang,\
    \ H. On Agricultural Machinery Operation System of Beidou Navigation System. In\n\
    Proceedings of the 2018 IEEE 3rd Advanced Information Technology, Electronic and\
    \ Automation Control Conference (IAEAC),\nChongqing, China, 12–14 October 2018;\
    \ pp. 1748–1751. [CrossRef]\n61.\nZhang, J.; Zhou, F.; Jing, C.; Wei, S.; Wu,\
    \ Y.; Jing, C. Research and Design of Automatic Navigation System for Agricultural\n\
    Machinery Based on GPS. In Proceedings of the 2020 IEEE International Conference\
    \ on Power, Intelligent Computing and Systems\n(ICPICS), Shenyang, China, 28–30\
    \ July 2020; pp. 984–986. [CrossRef]\n62.\nLi, C.; Tang, Y.; Wang, M.; Zhao, X.\
    \ Agricultural Machinery Information Collection and Operation Based on Data Platform.\
    \ In\nProceedings of the 2018 IEEE International Conference of Safety Produce\
    \ Informatization (IICSPI), Chongqing, China, 10–12\nDecember 2018; pp. 472–475.\
    \ [CrossRef]\n63.\nDong, Z.; Zhao, J.; Duan, J.; Wang, M.; Wang, H. Research on\
    \ Agricultural Machinery Fault Diagnosis System Based on Expert\nSystem. In Proceedings\
    \ of the 2018 2nd IEEE Advanced Information Management, Communicates, Electronic\
    \ and Automation\nControl Conference (IMCEC), Xi’an, China, 25–27 May 2018; pp.\
    \ 2057–2060. [CrossRef]\n64.\nFan, J.; Zhang, Y.; Wen, W.; Gu, S.; Lu, X.; Guo,\
    \ X. The future of Internet of Things in agriculture: Plant high-throughput\n\
    phenotypic platform. J. Clean. Prod. 2021, 280, 123651. [CrossRef]\n65.\nZhang,\
    \ Y.; Wang, J.; Du, J.; Zhao, Y.; Lu, X.; Wen, W.; Gu, S.; Fan, J.; Wang, C.;\
    \ Wu, S.; et al. Dissecting the phenotypic components\nand genetic architecture\
    \ of maize stem vascular bundles using high-throughput phenotypic analysis. Plant\
    \ Biotechnol. J. 2021, 19,\n35–50. [CrossRef]\n66.\nLi, B.H.; Chai, X.D.; Liu,\
    \ Y.; Chen, L.; Wei, D.Y. Research on Development Strategy of Intelligent Internet\
    \ of Things System.\nEngineering Science of China in Chinese. Available online:\
    \ https://kns.cnki.net/kcms/detail/11.4421.G3.20220720.1149.002.html\n(accessed\
    \ on 28 September 2022).\n67.\nLi, B.H.; Chai, X.D.; Hou, B.C.; Lin, T.Y.; Zhang,\
    \ L.; Li, T.; Liu, Y.; Xiao, Y.Y. Cloud manufacturing system 3.0: A new intelligent\n\
    manufacturing system in the era of “Intelli-gence+”. Comput. Integr. Manuf. Syst.\
    \ 2019, 25, 2997–3012.\n68.\nWu, D.; Zhang, Z.; Wu, S.; Yang, J.; Wang, R. Biologically\
    \ inspired resource allocation for network slices in 5G-enabled Internet of\n\
    Things. IEEE Internet Things J. 2018, 6, 9266–9279. [CrossRef]\n69.\nEscolar,\
    \ A.M.; Alcaraz-Calero, J.M.; Salva-Garcia, P.; Bernabe, J.B.; Wang, Q. Adaptive\
    \ Network Slicing in Multi-tenant 5G IoT\nNetworks. IEEE Access 2021, 9, 14048–14069.\
    \ [CrossRef]\n70.\nLiyanage, M.; Porambage, P.; Ding, A.Y.; Kalla, A. Driving\
    \ forces for multi-access edge computing (MEC) IoT integration in 5G.\nICT Express\
    \ 2021, 7, 127–137. [CrossRef]\n71.\nGupta, N.; Sharma, S.; Juneja, P.K.; Garg,\
    \ U. Sdnfv 5G-iot: A framework for the next generation 5G enabled iot. In Proceedings\
    \ of\nthe 2020 International Conference on Advances in Computing, Communication\
    \ & Materials (ICACCM), Dehradun, India, 21–22\nAugust 2020; pp. 289–294.\n72.\n\
    Ghosh, A.; Maeder, A.; Baker, M.; Chandramouli, D. 5G Evolution: A View on 5G\
    \ Cellular Technology beyond 3GPP Release 15.\nIEEE Access 2019, 7, 127639–127651.\
    \ [CrossRef]\nElectronics 2023, 12, 2336\n44 of 46\n73.\nRasyad, R.M.; Murti,\
    \ M.A.; Rizki, A.P. Design and Realization of Node MCU Module Based on NB-IoT\
    \ for General IoT Purpose.\nIn Proceedings of the 2019 IEEE International Conference\
    \ on Internet of Things and Intelligence System (IoTaIS), Bali, Indonesia,\n5–7\
    \ November 2019; pp. 189–194. [CrossRef]\n74.\nPaiva, S.; Branco, S.; Cabral,\
    \ J. Design and Power Consumption Analysis of a NB-IoT End Device for Monitoring\
    \ Applications. In\nProceedings of the IECON 2020 The 46th Annual Conference of\
    \ the IEEE Industrial Electronics Society, Singapore, 18–21 October\n2020; pp.\
    \ 2175–2182. [CrossRef]\n75.\nYang, F.; Shu, L.; Yang, Y.; Han, G.; Pearson, S.;\
    \ Li, K. Optimal Deployment of Solar Insecticidal Lamps over Constrained Locations\n\
    in Mixed-Crop Farmlands. IEEE Internet Things J. 2021, 8, 13095–13114. [CrossRef]\n\
    76.\nYang, F.; Shu, L.; Huang, K.; Li, K.; Han, G.; Liu, Y. A Partition-Based\
    \ Node Deployment Strategy in Solar Insecticidal Lamps\nInternet of Things. IEEE\
    \ Internet Things J. 2020, 7, 11223–11237. [CrossRef]\n77.\nFitzgerald, P.; Berney,\
    \ H.; Lakshmanan, R.; Coburn, N.; Geary, S.; Mulvey, B. Devices and Sensors Applicable\
    \ to 5G System\nImplementations. In Proceedings of the 2018 IEEE MTT-S International\
    \ Microwave Workshop Series on 5G Hardware and System\nTechnologies (IMWS-5G),\
    \ Dublin, Ireland, 30–31 August 2018; pp. 1–3. [CrossRef]\n78.\nAmato, F.; Amendola,\
    \ S.; Marrocco, G. Upper-bound Performances of RFID Epidermal Sensor Networks\
    \ at 5G Frequencies. In\nProceedings of the 2019 IEEE 16th International Conference\
    \ on Wearable and Implantable Body Sensor Networks (BSN), Chicago,\nIL, USA, 19–22\
    \ May 2019; pp. 1–4. [CrossRef]\n79.\nYaqoob, A.; Ashraf, M.A.; Ferooz, F.; Butt,\
    \ A.H.; Khan, Y.D. WSN Operating Systems for Internet of Things (IoT): A Survey.\
    \ In\nProceedings of the 2019 International Conference on Innovative Computing\
    \ (ICIC), Semarang, Indonesia, 16–17 October 2019;\npp. 1–7. [CrossRef]\n80.\n\
    Steiner, R.; Gracioli, G.; de Cássia Cazu Soldi, R.; Fröhlich, A.A. An Operating\
    \ System Runtime Reprogramming Infrastructure\nfor WSN. In Proceedings of the\
    \ 2012 IEEE Symposium on Computers and Communications (ISCC), Cappadocia, Turkey,\
    \ 1–4 July\n2012; pp. 000621–000624. [CrossRef]\n81.\nRamachandran, G.S.; Michiels,\
    \ S.; Joosen, W.; Hughes, D.; Porter, B. Analysis of Sensor Network Operating\
    \ System Performance\nThroughout the Software Life Cycle. In Proceedings of the\
    \ 2013 IEEE 12th International Symposium on Network Computing and\nApplications,\
    \ Boston, MA, USA, 22–24 August 2013; pp. 211–218. [CrossRef]\n82.\nChovanec,\
    \ M.; Šarafín, P. Real-time schedule for mobile robotics and WSN applications.\
    \ In Proceedings of the 2015 Federated\nConference on Computer Science and Information\
    \ Systems (FedCSIS), Lodz, Poland, 13–16 September 2015; pp. 1199–1202.\n[CrossRef]\n\
    83.\nMathane, V.; Lakshmi, P.V. Deterministic Real Time Kernel for Dependable\
    \ WSN. In Proceedings of the 2018 4th International\nConference for Convergence\
    \ in Technology (I2CT), Mangalore, India, 27–28 October 2018; pp. 1–4. [CrossRef]\n\
    84.\nSava, A.; Zoican, S. Wireless Sensors Network Framework for Developing Boards\
    \ using Contiki Operating System. In Proceedings\nof the 2020 13th International\
    \ Conference on Communications (COMM), Bucharest, Romania, 16–18 June 2020; pp.\
    \ 423–426.\n[CrossRef]\n85.\nAkpakwu, G.A.; Silva, B.J.; Hancke, G.P.; Abu-Mahfouz,\
    \ A.M. A survey on 5G networks for the Internet of Things: Communication\ntechnologies\
    \ and challenges. IEEE Access 2017, 6, 3619–3647. [CrossRef]\n86.\nTendolkar,\
    \ A.; Ramya, S. CareBro (personal farm assistant): An IoT based smart agriculture\
    \ with edge computing. In Proceedings\nof the 2020 Third International Conference\
    \ on Multimedia Processing, Communication & Information Technology (MPCIT),\n\
    Shivamogga, India, 11–12 December 2020; pp. 97–102.\n87.\nHuaji, Z.; Huarui, W.;\
    \ Xiang, S. Research on the ontology-based complex event processing engine of\
    \ RFID technology for agricul-\ntural products. In Proceedings of the 2009 International\
    \ Conference on Artiﬁcial Intelligence and Computational Intelligence,\nShanghai,\
    \ China, 7–8 November 2009; Volume 1, pp. 328–333.\n88.\nKamilaris, A.; Gao, F.;\
    \ Prenafeta-Boldu, F.X.; Ali, M.I. Agri-IoT: A semantic framework for Internet\
    \ of Things-enabled smart\nfarming applications. In Proceedings of the 2016 IEEE\
    \ 3rd world forum on internet of things (WF-IoT), New Orleans, LA, USA,\n12–14\
    \ December 2016; pp. 442–447.\n89.\nBayrakdar, M.E. Employing sensor network based\
    \ opportunistic spectrum utilization for agricultural monitoring. Sustain. Comput.\n\
    Inform. Syst. 2020, 27, 100404. [CrossRef]\n90.\nLiu, J.; Wang, X. Plant diseases\
    \ and pests detection based on deep learning: A review. Plant Methods 2021, 17,\
    \ 22. [CrossRef]\n[PubMed]\n91.\nFuentes, A.; Yoon, S.; Kim, S.C.; Park, D.S.\
    \ A robust deep-learning-based detector for real-time tomato plant diseases and\
    \ pests\nrecognition. Sensors 2017, 17, 2022. [CrossRef] [PubMed]\n92.\nBu, F.;\
    \ Wang, X. A smart agriculture IoT system based on deep reinforcement learning.\
    \ Future Gener. Comput. Syst. 2019, 99,\n500–507. [CrossRef]\n93.\nZhang, R.;\
    \ Li, X. Edge Computing Driven Data Sensing Strategy in the Entire Crop Lifecycle\
    \ for Smart Agriculture. Sensors 2021,\n21, 7502. [CrossRef]\n94.\nSekaran, K.;\
    \ Meqdad, M.N.; Kumar, P.; Rajan, S.; Kadry, S. Smart agriculture management system\
    \ using internet of things.\nTelkomnika 2020, 18, 1275–1284. [CrossRef]\n95.\n\
    Khujamatov, K.E.; Toshtemirov, T.K.; Lazarev, A.P.; Raximjonov, Q.T. IoT and 5G\
    \ technology in agriculture. In Proceedings of the\n2021 International Conference\
    \ on Information Science and Communications Technologies (ICISCT), Tashkent, Uzbekistan,\
    \ 3–5\nNovember 2021; pp. 1–6.\nElectronics 2023, 12, 2336\n45 of 46\n96.\nVan\
    \ Hilten, M.; Wolfert, S. 5G in agri-food—A review on current status, opportunities\
    \ and challenges. Comput. Electron. Agric.\n2022, 201, 107291. [CrossRef]\n97.\n\
    Hsu, C.K.; Chiu, Y.H.; Wu, K.R.; Liang, J.M.; Chen, J.J.; Tseng, Y.C. Design and\
    \ implementation of image electronic fence with 5G\ntechnology for smart farms.\
    \ In Proceedings of the 2019 IEEE VTS Asia Paciﬁc Wireless Communications Symposium\
    \ (APWCS),\nSingapore, 28–30 August 2019; pp. 1–3.\n98.\nArrubla-Hoyos, W.; Ojeda-Beltrán,\
    \ A.; Solano-Barliza, A.; Rambauth-Ibarra, G.; Barrios-Ulloa, A.; Cama-Pinto,\
    \ D.; Arrabal-\nCampos, F.M.; Martínez-Lao, J.A.; Cama-Pinto, A.; Manzano-Agugliaro,\
    \ F. Precision Agriculture and Sensor Systems Applications\nin Colombia through\
    \ 5G Networks. Sensors 2022, 22, 7295. [CrossRef]\n99.\nKai-zheng ZH, F.; Feng,\
    \ X. Intelligent Forestry System Design Based on Big Data. Comput. Telecommun.\
    \ 2020, 1, 56–59.\n100. Farooq, M.S.; Sohail, O.O.; Abid, A.; Rasheed, S. A survey\
    \ on the role of iot in agriculture for the implementation of smart\nlivestock\
    \ environment. IEEE Access 2022, 10, 9483–9505. [CrossRef]\n101. Zhang, M.; Wang,\
    \ X.; Feng, H.; Huang, Q.; Xiao, X.; Zhang, X. Wearable Internet of Things enabled\
    \ precision livestock farming in\nsmart farms: A review of technical solutions\
    \ for precise perception, biocompatibility, and sustainability monitoring. J.\
    \ Clean. Prod.\n2021, 312, 127712. [CrossRef]\n102. Liu, T.; Liu, J.; Wang, J.;\
    \ Xu, J. Optimization of the Intelligent Sensing Model for Environmental Information\
    \ in Aquaculture\nWaters Based on the 5G Smart Sensor Network. J. Sens. 2022,\
    \ 2022, 6409046. [CrossRef]\n103. Kim, K. Development of Buoy Information Monitoring\
    \ System Based on 5G Against the Abandoned, Lost and Discarded Fishing\nGears.\
    \ In Proceedings of the International Conference on Computational Intelligence,\
    \ Cyber Security, and Computational Models,\nCoimbatore, India, 14–16 December\
    \ 2017; Springer: Singapore, 2017; pp. 135–143.\n104. Yuan, L.; Bao, Z.; Zhang,\
    \ H.; Zhang, Y.; Liang, X. Habitat monitoring to evaluate crop disease and pest\
    \ distributions based on\nmulti-source satellite remote sensing imagery. Optik\
    \ 2017, 145, 66–73. [CrossRef]\n105. Fang, L. Research on Plant Diseases and Insect\
    \ Pests Monitoring Technology under the Background of Internet of Things\nTechnology.\
    \ In Proceedings of the 2020 International Wireless Communications and Mobile\
    \ Computing (IWCMC), Limassol,\nCyprus, 15–19 June 2020; pp. 1999–2001.\n106.\
    \ Varshney, R.K.; Sinha, P.; Singh, V.K.; Kumar, A.; Zhang, Q.; Bennetzen, J.L.\
    \ 5Gs for crop genetic improvement. Curr. Opin. Plant\nBiol. 2020, 56, 190–196.\
    \ [CrossRef]\n107. Lafont, M.; Dupont, S.; Cousin, P.; Vallauri, A. Back to the\
    \ future: IoT to improve aquaculture: Real-time monitoring and\nalgorithmic prediction\
    \ of water parameters for aquaculture needs. In Proceedings of the 2019 Global\
    \ IoT Summit (GIoTS), Aarhus,\nDenmark, 17–21 June 2019; pp. 1–6.\n108. Zhang,\
    \ J.; Zhang, R.; Yang, Q.; Hu, T.; Guo, K.; Hong, T. Research on application technology\
    \ of 5G Internet of Things and big data\nin dairy farm. In Proceedings of the\
    \ 2021 International Wireless Communications and Mobile Computing (IWCMC), Harbin\
    \ City,\nChina, 28 June–2 July 2021; pp. 138–140.\n109. Murugamani, C.; Shitharth,\
    \ S.; Hemalatha, S.; Kshirsagar, P.R.; Riyazuddin, K.; Naveed, Q.N.; Islam, S.;\
    \ Mazher Ali, S.P.; Batu,\nA. Machine Learning Technique for Precision Agriculture\
    \ Applications in 5G-Based Internet of Things. Wirel. Commun. Mob.\nComput. 2022,\
    \ 2022, 6534238. [CrossRef]\n110. Lin, B.S.P. Toward an AI-enabled SDN-based 5G\
    \ & IoT network. Netw. Commun. Technol. 2021, 5, 1–7.\n111. Restuccia, F.; Melodia,\
    \ T. Deep learning at the physical layer: System challenges and applications to\
    \ 5G and beyond. IEEE\nCommun. Mag. 2020, 58, 58–64. [CrossRef]\n112. Meng, H.\
    \ Research on key technologies of intelligent agriculture under 5G environment.\
    \ J. Phys. Conf. Ser. 2019, 1345, 042057.\n[CrossRef]\n113. Zhu, L.; Fan, R. Convenience\
    \ of Voice Interaction Design in the 5G Era to Adapt to Agricultural Machinery.\
    \ In Proceedings of the\n2020 Asia-Paciﬁc Conference on Image Processing, Electronics\
    \ and Computers (IPEC), Hong Kong, China, 14–18 December 2020;\npp. 208–212.\n\
    114. Kim, W.S.; Lee, W.S.; Kim, Y.J. A review of the applications of the internet\
    \ of things (IoT) for agricultural automation. J. Biosyst.\nEng. 2020, 45, 385–400.\
    \ [CrossRef]\n115. Bose, B.; Priya, J.; Welekar, S.; Gao, Z. Hemp Disease Detection\
    \ and Classiﬁcation Using Machine Learning and Deep Learning. In\nProceedings\
    \ of the 2020 IEEE Intl Conf on Parallel & Distributed Processing with Applications,\
    \ Big Data & Cloud Computing,\nSustainable Computing & Communications, Social\
    \ Computing & Networking (ISPA/BDCloud/SocialCom/SustainCom), Exeter,\nUK, 17–19\
    \ December 2020; pp. 762–769. [CrossRef]\n116. Brunelli, D.; Albanese, A.; d’Acunto,\
    \ D.; Nardello, M. Energy Neutral Machine Learning Based IoT Device for Pest Detection\
    \ in\nPrecision Agriculture. IEEE Internet Things Mag. 2019, 2, 10–13. [CrossRef]\n\
    117. Medar, R.; Rajpurohit, V.S.; Shweta, S. Crop Yield Prediction using Machine\
    \ Learning Techniques. In Proceedings of the 2019\nIEEE 5th International Conference\
    \ for Convergence in Technology (I2CT), Bombay, India, 29–31 March 2019; pp. 1–5.\
    \ [CrossRef]\n118. Gobalakrishnan, N.; Pradeep, K.; Raman, C.J.; Ali, L.J.; Gopinath,\
    \ M.P. A Systematic Review on Image Processing and Machine\nLearning Techniques\
    \ for Detecting Plant Diseases. In Proceedings of the 2020 International Conference\
    \ on Communication and\nSignal Processing (ICCSP), Chennai, India, 28–30 July\
    \ 2020; pp. 0465–0468. [CrossRef]\n119. Merchant, M.; Paradkar, V.; Khanna, M.;\
    \ Gokhale, S. Mango Leaf Deﬁciency Detection Using Digital Image Processing and\n\
    Machine Learning. In Proceedings of the 2018 3rd International Conference for\
    \ Convergence in Technology (I2CT), Mangalore,\nIndia, 6–8 April 2018; pp. 1–3.\
    \ [CrossRef]\nElectronics 2023, 12, 2336\n46 of 46\n120. Feng, Q.; Wang, X.; Wang,\
    \ G.; Li, Z. Design and test of tomatoes harvesting robot. In Proceedings of the\
    \ 2015 IEEE International\nConference on Information and Automation, Lijiang,\
    \ China, 8–10 August 2015; pp. 949–952. [CrossRef]\n121. Liu, C.; Wang, M.; Zhou,\
    \ J. Coordinating control for an agricultural vehicle with individual wheel speeds\
    \ and steering angles\n[Applications of Control]. IEEE Control Syst. 2008, 28,\
    \ 21–24. [CrossRef]\n122. Ma, J.; Wang, D.; Tang, Y.; Zhao, J. Automatic control\
    \ system of agricultural machinery based on Beidou navigation. In Proceedings\n\
    of the 2017 IEEE 3rd Information Technology and Mechatronics Engineering Conference\
    \ (ITOEC), Chongqing, China, 3–5 October\n2017; pp. 318–323. [CrossRef]\n123.\
    \ Liu, K.; Cheng, G.; Kong, Z. Beidou agricultural machinery automatic driving\
    \ software design. In Proceedings of the 2019\nIEEE 4th Advanced Information Technology,\
    \ Electronic and Automation Control Conference (IAEAC), Chengdu, China, 20–22\n\
    December 2019; pp. 1770–1775. [CrossRef]\n124. Liu, K.; Cheng, G.; Kong, Z. Agricultural\
    \ Machinery Automatic Driving Algorithm Based on Beidou System. In Proceedings\
    \ of\nthe 2019 IEEE 4th Advanced Information Technology, Electronic and Automation\
    \ Control Conference (IAEAC), Chengdu, China,\n20–22 December 2019; pp. 2041–2045.\
    \ [CrossRef]\n125. Chien, W.C.; Hassan, M.M.; Alsanad, A.; Fortino, G. UAV–Assisted\
    \ Joint Wireless Power Transfer and Data Collection Mechanism\nfor Sustainable\
    \ Precision Agriculture in 5G. IEEE Micro 2021, 42, 25–32. [CrossRef]\n126. Alabi,\
    \ C.A.; Tooki, O.O.; Imoize, A.L.; Faruk, N. Application of UAV-Assisted 5G Communication:\
    \ A Case Study of the Nigerian\nEnvironment. In Proceedings of the 2022 IEEE Nigeria\
    \ 4th International Conference on Disruptive Technologies for Sustainable\nDevelopment\
    \ (NIGERCON), Abuja, Nigeria, 17–19 May 2022; pp. 1–5.\n127. Sharma, A.; Singh,\
    \ P.K. UAV-based framework for effective data analysis of forest ﬁre detection\
    \ using 5G networks: An effective\napproach towards smart cities solutions. Int.\
    \ J. Commun. Syst. 2021, e4826. [CrossRef]\n128. Shahzadi, R.; Ali, M.; Khan,\
    \ H.Z.; Naeem, M. UAV assisted 5G and beyond wireless networks: A survey. J. Netw.\
    \ Comput. Appl.\n2021, 189, 103114. [CrossRef]\n129. Mishra, D.; Natalizio, E.\
    \ A survey on cellular-connected UAVs: Design challenges, enabling 5G/B5G innovations,\
    \ and experimen-\ntal advancements. Comput. Netw. 2020, 182, 107451. [CrossRef]\n\
    130. Khandelwal, C. Agriculture Supply Chain Management: A Review (2010–2020).\
    \ Mater. Today Proc. 2021, 47, 3144–3153. [CrossRef]\n131. Taboada, I.; Shee,\
    \ H. Understanding 5G technology for future supply chain management. Int. J. Logist.\
    \ Res. Appl. 2021, 24,\n392–406. [CrossRef]\nDisclaimer/Publisher’s Note: The\
    \ statements, opinions and data contained in all publications are solely those\
    \ of the individual\nauthor(s) and contributor(s) and not of MDPI and/or the editor(s).\
    \ MDPI and/or the editor(s) disclaim responsibility for any injury to\npeople\
    \ or property resulting from any ideas, methods, instructions or products referred\
    \ to in the content.\n"
  inline_citation: null
  journal: Electronics
  limitations: "The limitations of the paper are as follows: \n- Limited scope: The\
    \ paper mainly focuses on the application of 5G and IoT in smart agriculture,\
    \ and does not cover other important aspects of smart agriculture, such as data\
    \ analytics, decision support systems, and precision agriculture.\n- Lack of empirical\
    \ evidence: The paper lacks empirical evidence to support the claims and findings\
    \ presented. Experimental results or case studies would have strengthened the\
    \ paper's credibility.\n- Lack of discussion on security and privacy: The paper\
    \ does not discuss the security and privacy challenges associated with the integration\
    \ of 5G and IoT in smart agriculture, which are important considerations for the\
    \ deployment of these technologies."
  page_count: 14
  pdf_link: https://www.mdpi.com/2079-9292/12/10/2336/pdf?version=1684748770
  publication_date: '2023-05-22'
  publication_year: 2023
  publisher: MDPI
  relevance_score: 0.9
  relevance_score1: 0
  relevance_score2: 0
  title: Survey of Intelligent Agricultural IoT Based on 5G
  verbatim_quote1: '"5G and the application of smart agricultural IOT based on 5G
    is expected to make new changes and opportunities for the existing agricultural
    production mode in many agricultural application scenarios."'
  verbatim_quote2: '"It can be seen that smart agriculture and the internet of things
    are both hot-tracking directions, and there are many review articles and rapid
    technological development."'
  verbatim_quote3: '>'
  word_count: 46

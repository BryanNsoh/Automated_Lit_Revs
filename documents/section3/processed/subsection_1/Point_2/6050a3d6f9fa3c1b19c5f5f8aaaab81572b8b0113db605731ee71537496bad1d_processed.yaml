- DOI: https://doi.org/10.3390/plants11233344
  analysis: '## Different data types (e.g., soil moisture, canopy temperature, weather)
    and their collection and use


    Citation: Chandel, N.S.; Rajwade, Y.A.; Dubey, K.; Chandel, A.K.; Subeesh, A.;
    Tiwari, M.K. Water Stress Identification of Winter Wheat Crop with State-of-the-Art
    AI Techniques and High-Resolution Thermal-RGB Imagery. Plants 2022, 11, 3344.
    https://doi.org/10.3390/plants11233344


    Academic Editors: John T. Hancock and Mikihisa Umehara

    Received: 8 October 2022

    Accepted: 27 November 2022

    Published: 2 December 2022


    Publisher’s Note: MDPI stays neutral with regard to jurisdictional claims in published
    maps and institutional afﬁliations.


    Copyright: © 2022 by the authors. Licensee MDPI, Basel, Switzerland. This article
    is an open access article distributed under the terms and conditions of the Creative
    Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/
    4.0/).


    Two-year study was conducted on non-invasive winter wheat water stress monitoring
    using state-of-the-art computer vision and thermal-RGB imagery inputs.


    **Field treatment plots were irrigated using two irrigation systems (ﬂood and
    sprinkler) at four rates (100, 75, 50, and 25% of crop evapotranspiration [ETc]).
    A total of 3200 images under different treatments were captured at critical growth
    stages, that is, 20, 35, 70, 95, and 108 days after sowing using a custom-developed
    thermal-RGB imaging system. Crop and soil response measurements of canopy temperature
    (Tc), relative water content (RWC), soil moisture content (SMC), and relative
    humidity (RH) were signiﬁcantly affected by the irrigation treatments showing
    the lowest Tc (22.5 ± 2 ◦C), and highest RWC (90%) and SMC (25.7 ± 2.2%) for 100%
    ETc, and highest Tc (28 ± 3 ◦C), and lowest RWC (74%) and SMC (20.5 ± 3.1%) for
    25% ETc. The RGB and thermal imagery were then used as inputs to feature-extraction-based
    deep learning models (AlexNet, GoogLeNet, Inception V3, MobileNet V2, ResNet50)
    while, RWC, SMC, Tc, and RH were the inputs to function-approximation models (Artiﬁcial
    Neural Network (ANN), Kernel Nearest Neighbor (KNN), Logistic Regression (LR),
    Support Vector Machine (SVM) and Long Short-Term Memory (DL-LSTM)) to classify
    stressed/non-stressed crops. Among the feature extraction-based models, ResNet50
    outperformed other models showing a discriminant accuracy of 96.9% with RGB and
    98.4% with thermal imagery inputs. Overall, classiﬁcation accuracy was higher
    for thermal imagery compared to RGB imagery inputs. The DL-LSTM had the highest
    discriminant accuracy of 96.7% and less error among the function approximation-based
    models for classifying stress/non-stress.


    The study suggests that computer vision coupled with thermal-RGB imagery can be
    instrumental in high-throughput mitigation and management of crop water stress.'
  authors:
  - Narendra Singh Chandel
  - Yogesh Anand Rajwade
  - Kumkum Dubey
  - Abhilash K. Chandel
  - A. Subeesh
  - Mukesh Tiwari
  citation_count: 8
  full_citation: '>'
  full_text: ">\nCitation: Chandel, N.S.; Rajwade,\nY.A.; Dubey, K.; Chandel, A.K.;\n\
    Subeesh, A.; Tiwari, M.K. Water\nStress Identiﬁcation of Winter Wheat\nCrop with\
    \ State-of-the-Art AI\nTechniques and High-Resolution\nThermal-RGB Imagery. Plants\
    \ 2022,\n11, 3344. https://doi.org/10.3390/\nplants11233344\nAcademic Editors:\
    \ John T. Hancock\nand Mikihisa Umehara\nReceived: 8 October 2022\nAccepted: 27\
    \ November 2022\nPublished: 2 December 2022\nPublisher’s Note: MDPI stays neutral\n\
    with regard to jurisdictional claims in\npublished maps and institutional afﬁl-\n\
    iations.\nCopyright:\n© 2022 by the authors.\nLicensee MDPI, Basel, Switzerland.\n\
    This article is an open access article\ndistributed\nunder\nthe\nterms\nand\n\
    conditions of the Creative Commons\nAttribution (CC BY) license (https://\ncreativecommons.org/licenses/by/\n\
    4.0/).\nplants\nArticle\nWater Stress Identiﬁcation of Winter Wheat Crop with\n\
    State-of-the-Art AI Techniques and High-Resolution\nThermal-RGB Imagery\nNarendra\
    \ S. Chandel 1, Yogesh A. Rajwade 2,*\n, Kumkum Dubey 1, Abhilash K. Chandel 3,4,*\n\
    , A. Subeesh 1\nand Mukesh K. Tiwari 5\n1\nAgricultural Mechanization Division,\
    \ ICAR—Central Institute of Agricultural Engineering,\nBhopal 462038, MP, India\n\
    2\nIrrigation and Drainage Engineering Division, ICAR—Central Institute of Agricultural\
    \ Engineering,\nBhopal 462038, MP, India\n3\nDepartment of Biological Systems\
    \ Engineering, Virginia Tech Tidewater AREC, Suffolk, VA 23437, USA\n4\nCenter\
    \ for Advanced Innovation in Agriculture (CAIA), Virginia Tech, Blacksburg, VA\
    \ 24061, USA\n5\nCollege of Agricultural Engineering and Technology, Anand Agricultural\
    \ University, Godhra 389001, GJ, India\n*\nCorrespondence: yogesh.rajwade@icar.gov.in\
    \ (Y.A.R.); abhilashchandel@vt.edu (A.K.C.)\nAbstract: Timely crop water stress\
    \ detection can help precision irrigation management and minimize\nyield loss.\
    \ A two-year study was conducted on non-invasive winter wheat water stress monitoring\n\
    using state-of-the-art computer vision and thermal-RGB imagery inputs. Field treatment\
    \ plots were\nirrigated using two irrigation systems (ﬂood and sprinkler) at four\
    \ rates (100, 75, 50, and 25% of crop\nevapotranspiration [ETc]). A total of 3200\
    \ images under different treatments were captured at critical\ngrowth stages,\
    \ that is, 20, 35, 70, 95, and 108 days after sowing using a custom-developed\
    \ thermal-\nRGB imaging system. Crop and soil response measurements of canopy\
    \ temperature (Tc), relative\nwater content (RWC), soil moisture content (SMC),\
    \ and relative humidity (RH) were signiﬁcantly\naffected by the irrigation treatments\
    \ showing the lowest Tc (22.5 ± 2 ◦C), and highest RWC (90%)\nand SMC (25.7 ±\
    \ 2.2%) for 100% ETc, and highest Tc (28 ± 3 ◦C), and lowest RWC (74%) and SMC\n\
    (20.5 ± 3.1%) for 25% ETc. The RGB and thermal imagery were then used as inputs\
    \ to feature-\nextraction-based deep learning models (AlexNet, GoogLeNet, Inception\
    \ V3, MobileNet V2, ResNet50)\nwhile, RWC, SMC, Tc, and RH were the inputs to\
    \ function-approximation models (Artiﬁcial Neural\nNetwork (ANN), Kernel Nearest\
    \ Neighbor (KNN), Logistic Regression (LR), Support Vector Machine\n(SVM) and\
    \ Long Short-Term Memory (DL-LSTM)) to classify stressed/non-stressed crops. Among\n\
    the feature extraction-based models, ResNet50 outperformed other models showing\
    \ a discriminant\naccuracy of 96.9% with RGB and 98.4% with thermal imagery inputs.\
    \ Overall, classiﬁcation accuracy\nwas higher for thermal imagery compared to\
    \ RGB imagery inputs. The DL-LSTM had the highest\ndiscriminant accuracy of 96.7%\
    \ and less error among the function approximation-based models for\nclassifying\
    \ stress/non-stress. The study suggests that computer vision coupled with thermal-RGB\n\
    imagery can be instrumental in high-throughput mitigation and management of crop\
    \ water stress.\nKeywords: winter wheat; crop water stress; canopy temperature;\
    \ computer vision; irrigation\nmanagement\n1. Introduction\nWater stress forces\
    \ leaf stomata closure, which reduces transpiration and increases\ncanopy temperature\
    \ (Tc) [1]. Timely estimation of those stressors may not only help preci-\nsion\
    \ irrigation management but also minimize yield losses [2]. The penalty gap between\n\
    actual and potential yield will widen further as a result of climate change that\
    \ projects\na decline in rainfall frequency, and rising ambient temperatures [3].\
    \ Water stress is typ-\nically assessed using xylem water potentials [4], canopy\
    \ thermometry [5], and stomatal\nPlants 2022, 11, 3344. https://doi.org/10.3390/plants11233344\n\
    https://www.mdpi.com/journal/plants\nPlants 2022, 11, 3344\n2 of 21\nconductance\
    \ measurements [6]. However, these methods are often invasive and tend\nto have\
    \ limited sampling accuracy due to low throughput or point data acquisitions [7].\n\
    Non-invasive proximal or remote sensing techniques have emerged as high throughput\n\
    alternatives for monitoring crop water stress through color features, reﬂectance,\
    \ and ther-\nmal emissivity of the vegetable, fruit, and specialty crops [8–10].\
    \ However, monitoring\ncrop water content using visible-range RGB imaging not\
    \ only requires speciﬁc leaf ori-\nentation relative to the camera but also pre-deﬁned\
    \ illumination conditions. This limits\nthe applicability of RGB imaging to determine\
    \ water content in ﬁeld conditions. Using\nscanner-type imaging devices could\
    \ be a cost and time-effective alternative [11]. Unlike\nthermometry, Tc from\
    \ thermal infrared imagery reﬂects upon the entire canopy emissivity\nproﬁle,\
    \ which is directly proportional to the canopy water content [9]. Thermal imagery\n\
    (8000–14,000 nm) also outperforms color RGB imagery (400–700 nm), and reﬂectance\
    \ char-\nacteristics in terms of robustness to characterize crop water stress\
    \ [8,9]. Nonetheless, the\nadaptability of thermal imaging in agricultural production\
    \ management is still at a nascent\nstage and is consistently evolving to maintain\
    \ imaging quality against drastic variations\nin relative humidity and wind speeds.\
    \ Thermal imaging cameras are also relatively more\nexpensive than simple-to-operate\
    \ RGB cameras. It is for these reasons; thermal imaging\nis still limitedly adopted\
    \ as a golden standard for crop stress mapping. Above all, long-\nwave infrared\
    \ wavelengths (thermal imaging) have a higher penetrating capability over\nvisible-range\
    \ wavelengths, making them more reliable and sensitive to crop water content\n\
    variations. Thermal imaging is therefore a better alternative for precision irrigation\
    \ man-\nagement unlike RGB imaging or using standard crop coefﬁcients coupled\
    \ with reference\nevapotranspiration [8,9].\nRGB imagery has been used to assess\
    \ crop water stress using different deep learning\n(DL) and machine learning (ML)\
    \ techniques [10,12,13]. ML techniques derive unique\nfeatures from input and\
    \ output datasets, which could be used for discrimination between\ndifferent object\
    \ types or classes. ML techniques such as Naïve Bayes, artiﬁcial neural\nnetworks\
    \ (ANNs), support vector machine (SVM), and random forests (RFs) have been\nwidely\
    \ used with RGB images for weed detection, biotic and abiotic stress identiﬁcation\n\
    and/or classiﬁcation, yield predictions, and other crop phenotyping applications\
    \ [14,15].\nThermal imagery has also been used with RFs and decision trees for\
    \ crop water status\nmonitoring in the vineyard and automated irrigation scheduling\
    \ [16]. However, there are\nseveral limitations associated with ML techniques.\
    \ The output quality is highly dependent\non input data quality, the presence\
    \ of noise and outliers, and other unaccounted biases\nthat have been reported\
    \ to signiﬁcantly affect the model performance. Furthermore, ML\ntechniques also\
    \ require skilled operators [17] for deﬁning input features that may also often\n\
    affect the model performances through unintentional subjectivity and bias [10,12].\n\
    DL has emerged as an advanced vision-based learning technique that enables au-\n\
    tomated feature extraction without human dependencies unlike ML [18]. Pertinent\
    \ to\nagricultural applications, crop phenological stages have been detected using\
    \ a deep con-\nvolution neural network (DCNN) trained on RGB imagery [19,20].\
    \ Similarly, different DL\ntechniques (AlexNet, GoogLeNet, and Inception V3) have\
    \ also been used to classify non-\nstressed and water-stressed soybean, maize,\
    \ and okra crops with digital RGB images [10].\nLong Short Term Memory (LSTM)\
    \ is a novel DL approach (DL-LSTM) that has been used\nfor different ﬁeld applications\
    \ like time series forecasting of wheat yield and productiv-\nity [21], irrigation\
    \ requirement [22], predicting agricultural product sale volumes based\non seasonal\
    \ and historical data [23], and identiﬁcation and classiﬁcation of weeds [24].\n\
    Most of the image processing studies have used RGB images (or visible range imagery)\
    \ to\nclassify crop water stress [25,26]. Thermal imagery has been reported to\
    \ be more robust\nfor crop water stress characterization compared to RGB or multispectral\
    \ imagery [27,28].\nThis is majorly due to the fact that the canopy emissivity\
    \ can be highly sensitive to water\ncontent [8,9,29,30].\nSo far, crop water stress\
    \ characterization has been carried out through traditional\nand destructive methods\
    \ that often have restricted commercial applicability. Moreover,\nPlants 2022,\
    \ 11, 3344\n3 of 21\nthese techniques have been limitedly explored using robust\
    \ computer-vision techniques\n(ML or DL models) for thermal infrared imagery inputs.\
    \ Small unmanned aerial system\n(UAS)-based thermal and multispectral remote sensing\
    \ is also being explored for high\nthroughput crop water stress phenotyping. However,\
    \ the frequency of data acquisition\nis limited to once or a few times a day and\
    \ atmospheric interferences including weather\nconditions may severely impact\
    \ the quality of thermal imaging. Additionally, onboard\ndata processing potential\
    \ for complex and robust algorithms is still limited for small UASs.\nContrarily,\
    \ proximal thermal imaging is subjected to the least atmospheric interference\n\
    and imaging frequency constraints. These systems can continuously collect data\
    \ at critical\ngrowth stages and also offer ﬂexibility for custom modiﬁcation\
    \ to implement onboard edge\nprocessing algorithms for real-time decision support\
    \ and management actuation. On the\ncost side, thermal and RGB imaging sensors\
    \ and the UASs are still far more expensive than\nthe proximal imaging systems,\
    \ which can be custom-assembled using miniature sensing\nmodules. However, such\
    \ miniature sensing modules neither offer sufﬁcient resolution nor\ndesired image\
    \ quality when integrated with UASs.\nObtaining robust data handling and the analytical\
    \ pipeline is the major obstacle to\nderiving real-time decision support for crop\
    \ management but is achievable using custom-\nassembled edge devices. This study\
    \ is a step toward alleviating those obstacles and\nfocuses on the evaluation\
    \ of non-invasive and cost-effective thermal-RGB imaging with\nrobust ML and DL\
    \ models for stress characterization in winter wheat crops. This could\nbe critical\
    \ from a precision irrigation scheduling and management perspective and may\n\
    potentially have high grower adaptability. Speciﬁc objectives for this two-year\
    \ study were\nto (a) non-invasively assess the crop responses to two irrigation\
    \ systems and four deﬁcit\nirrigation treatments, and (b) identify the water-stressed\
    \ and non-stressed crops by feature\nextraction using thermal-RGB imagery and\
    \ function approximation approaches using crop\nphysiological parameters and ambient\
    \ weather inputs.\n2. Materials and Methods\n2.1. Experiment Design\nWinter wheat\
    \ (Triticum aestivum L., cv. HI 1544) was planted (November to April,\n2019–2020,\
    \ and 2020–2021) in the research farm (77.24◦ E, 23.18◦ N) of the Central Institute\n\
    of Agricultural Engineering (CIAE), ICAR Bhopal, India (Figure 1). The meteorological\n\
    data are being recorded at the institute observatory since 1985. According to\
    \ Koppen’s\nclassiﬁcation (1934), Bhopal is a Mediterranean climatic zone with\
    \ an average annual\nrainfall of about 1127 mm. The soil type is heavy clay (Vertisols)\
    \ with clay content over 50%\nand moderate fertility with negligible salinity.\
    \ Soil structure is sub-angular blocky with a\nﬁeld capacity of 29.5–32% (db)\
    \ and wilting point of 18-19.5% (db). The average inﬁltration\nand percolation\
    \ rates of the soil are 10–12 mm day−1 and 6.3–7.0%, respectively. The plots\n\
    were irrigated using ﬂood and sprinkler systems at four treatment rates: 100,\
    \ 75, 50, and\n25% of full crop evapotranspiration (ETc). Micro sprinklers of\
    \ 120 lph discharge capacity\n(Make: Netaﬁm) were installed at 3.5 m spacing.\
    \ The reference crop evapotranspiration was\ncalculated using weather data with\
    \ the FAO56 Penman–Montieth method and standard\nnon-stressed crop coefﬁcient\
    \ [31]. The seasonal ETc of wheat during the ﬁrst and second\nyears of growth\
    \ was 380 mm and 345 mm, respectively. The application efﬁciencies of\n0.65 for\
    \ ﬂood irrigation and 0.90 for sprinkler irrigation were used as determined from\n\
    the experiment trials on the same site using the measurements of water applied\
    \ and the\nwater retained in the crop root zone. A total of six irrigation cycles\
    \ were implemented for\n100% ETc treatment (non-stressed) at sowing, crown root\
    \ initiation (CRI), tillering, booting,\nﬂowering, and grain ﬁlling stages. One\
    \ to three irrigation cycles were implemented for\ndeﬁcit treatments (75, 50,\
    \ and 25% of ETc) at jointing, booting, and ﬂowering stages.\nPlants 2022, 11,\
    \ 3344\n4 of 21\nPlants 2022, 11, x FOR PEER REVIEW \n4 of 22 \n \n \ncrown root\
    \ initiation (CRI), tillering, booting, flowering, and grain filling stages. One\
    \ to \nthree irrigation cycles were implemented for deficit treatments (75, 50,\
    \ and 25% of ETc) at \njointing, booting, and flowering stages. \n \nFigure 1.\
    \ Experimental layout of the winter wheat crop irrigated at different rates using\
    \ sprinkler \nand flood irrigation systems [32]. R—Replicates. Layout is prepared\
    \ over google map. \n2.2. Data Collection \nRGB and thermal imagery were synchronously\
    \ captured using a multifunctional \ncustom integrated thermal-RGB imaging system.\
    \ The system has a single board com-\nputer (B+, Raspberry Pi foundation), a thermal\
    \ imaging module (8000–14,000 nm, HTPA, \nHeimann, Pixel resolution: 80 × 64,\
    \ Horizontal and vertical FOV: 120° × 90°), an RGB \nimaging module (400–700 nm,\
    \ Raspberry Pi V2, Sony IMX219, Raspberry Pi foundation, \nPixel resolution: 3280\
    \ × 2464, HFOV: 62.2°, VFOV: 48.8°), a GPS receiver module (NEO \n6M V2, Adafruit)\
    \ for image geotagging, a capacitive touchscreen (LCD 800 × 400 mm, \nRobokit),\
    \ a keypad (Robokits), and a power source (20,000 mAh, 5V/2A, MI power bank).\
    \ \nThe computer used the NOOBS operating system with module-pertinent libraries\
    \ for \ndifferent operations. Imagery data were collected at critical crop growth\
    \ stages in the \n2019 and 2020 growing seasons (five times in each season). Ground\
    \ truth plant biophys-\nical and soil parameters were also measured synchronously.\
    \ \n2.2.1. Imagery Data \nThe developed imaging system was placed 1 m from the\
    \ crop and titled at 45° from \nthe horizontal. A total of 3200 images (400 per\
    \ treatment) were acquired (1600 RGB and \n1600 thermal) in two seasons at Crown\
    \ root initiation (20 days after sowing (DAS)), till-\nering (35 DAS) (Figure\
    \ 2), jointing (70 DAS), flowering and milking (95 DAS), and dough \n(108 DAS)\
    \ stages, between 11 am to 1 pm on clear sky days. Sample masked thermal and \n\
    RGB canopy images for model training are shown in Figure 2.  \nFigure 1. Experimental\
    \ layout of the winter wheat crop irrigated at different rates using sprinkler\n\
    and ﬂood irrigation systems [32]. R—Replicates. Layout is prepared over google\
    \ map.\n2.2. Data Collection\nRGB and thermal imagery were synchronously captured\
    \ using a multifunctional cus-\ntom integrated thermal-RGB imaging system. The\
    \ system has a single board computer (B+,\nRaspberry Pi foundation), a thermal\
    \ imaging module (8000–14,000 nm, HTPA, Heimann,\nPixel resolution: 80 × 64, Horizontal\
    \ and vertical FOV: 120◦ × 90◦), an RGB imaging mod-\nule (400–700 nm, Raspberry\
    \ Pi V2, Sony IMX219, Raspberry Pi foundation, Pixel resolution:\n3280 × 2464,\
    \ HFOV: 62.2◦, VFOV: 48.8◦), a GPS receiver module (NEO 6M V2, Adafruit)\nfor\
    \ image geotagging, a capacitive touchscreen (LCD 800 × 400 mm, Robokit), a keypad\n\
    (Robokits), and a power source (20,000 mAh, 5V/2A, MI power bank). The computer\n\
    used the NOOBS operating system with module-pertinent libraries for different\
    \ operations.\nImagery data were collected at critical crop growth stages in the\
    \ 2019 and 2020 growing\nseasons (ﬁve times in each season). Ground truth plant\
    \ biophysical and soil parameters\nwere also measured synchronously.\n2.2.1. Imagery\
    \ Data\nThe developed imaging system was placed 1 m from the crop and titled at\
    \ 45◦ from\nthe horizontal. A total of 3200 images (400 per treatment) were acquired\
    \ (1600 RGB\nand 1600 thermal) in two seasons at Crown root initiation (20 days\
    \ after sowing (DAS)),\ntillering (35 DAS) (Figure 2), jointing (70 DAS), ﬂowering\
    \ and milking (95 DAS), and dough\n(108 DAS) stages, between 11 am to 1 pm on\
    \ clear sky days. Sample masked thermal and\nRGB canopy images for model training\
    \ are shown in Figure 2.\n2.2.2. Weather and Ground Truth Data\nWeather data were\
    \ acquired for the imaging days from a standard station (Indian\nMeteorological\
    \ Department, Pune, India) installed at 300 m from the study site. The\nparameters\
    \ included, pan evaporation (mm/day), rainfall (mm), maximum and minimum\nair\
    \ temperature (◦C), relative humidity (RH, %), and wind velocity (m/s). The ambient\n\
    and soil ground truth data of air temperature (Ta), RH, and soil moisture content\
    \ (SMC)\nwere collected for each treatment plot during the imaging campaigns each\
    \ year. The Ta\nand RH parameters were recorded using the DHT22 module (Adafruit,\
    \ New York, NY,\nPlants 2022, 11, 3344\n5 of 21\nUSA). SMC was monitored in the\
    \ root zone depth (0–150 mm typical to wheat crops\ngrown in the experimental\
    \ site, soil type: vertisols) using a soil moisture meter of 200 mm\nsensing probe\
    \ length (ICT, MPM-160-B, Armidale, Australia). The probe was inserted at\nﬁve\
    \ different locations in each replication for measurement of soil moisture, acquiring\
    \ 15\ndata points of soil moisture content per measurement. The relative water\
    \ content (RWC)\nof leaves was calculated as the crop ground truth data [33].\
    \ For this, 10 matured and fully\nexpanded leaves from each sample plot were collected\
    \ and fresh weight was recorded on\neach sampling date, immediately following\
    \ the imagery acquisition. Collected samples\nwere then oven-dried at 70 ◦C, dry\
    \ weight was recorded, and RWC was calculated. A\ntotal of 30 samples were collected\
    \ per treatment per campaign amounting to a total of\n150 samples per treatment\
    \ in each year for RWC calculations. End-season yield was also\nrecorded from\
    \ 2 × 2 m areas from three plots in each replication, making nine sample\npoints\
    \ (36 m2 area) per treatment to characterize the effects of crop water stress.\n\
    Plants 2022, 11, x FOR PEER REVIEW \n5 of 22 \n \n \nFigure 2. Sample raw and\
    \ canopy masked RGB images ((a) non-stressed; (b) stressed) and thermal \nimages\
    \ ((c) non-stressed, (d) stressed) captured 35 days after sowing. Pseudo-color\
    \ thermal images \nhere are only for presentation and were scaled between 10 °C\
    \ (RGB: [25, 25, 113]) and 80 °C (RGB: \n[235, 246, 255]). \n2.2.2. Weather and\
    \ Ground Truth Data \nWeather data were acquired for the imaging days from a standard\
    \ station (Indian \nMeteorological Department, Pune, India) installed at 300 m\
    \ from the study site. The pa-\nrameters included, pan evaporation (mm/day), rainfall\
    \ (mm), maximum and minimum \nair temperature (°C), relative humidity (RH, %),\
    \ and wind velocity (m/s). The ambient \nand soil ground truth data of air temperature\
    \ (Ta), RH, and soil moisture content (SMC) \nwere collected for each treatment\
    \ plot during the imaging campaigns each year. The Ta \nand RH parameters were\
    \ recorded using the DHT22 module (Adafruit, New York, NY, \nUSA). SMC was monitored\
    \ in the root zone depth (0–150 mm typical to wheat crops \ngrown in the experimental\
    \ site, soil type: vertisols) using a soil moisture meter of 200 mm \nsensing\
    \ probe length (ICT, MPM-160-B, Armidale, Australia). The probe was inserted at\
    \ \nfive different locations in each replication for measurement of soil moisture,\
    \ acquiring 15 \ndata points of soil moisture content per measurement. The relative\
    \ water content (RWC) \nof leaves was calculated as the crop ground truth data\
    \ [33]. For this, 10 matured and fully \nexpanded leaves from each sample plot\
    \ were collected and fresh weight was recorded on \neach sampling date, immediately\
    \ following the imagery acquisition. Collected samples \nwere then oven-dried\
    \ at 70 °C, dry weight was recorded, and RWC was calculated. A \ntotal of 30 samples\
    \ were collected per treatment per campaign amounting to a total of 150 \nsamples\
    \ per treatment in each year for RWC calculations. End-season yield was also \n\
    recorded from 2 × 2 m areas from three plots in each replication, making nine\
    \ sample \npoints (36 m2 area) per treatment to characterize the effects of crop\
    \ water stress. \nFigure 2. Sample raw and canopy masked RGB images ((a) non-stressed;\
    \ (b) stressed) and thermal\nimages ((c) non-stressed, (d) stressed) captured\
    \ 35 days after sowing. Pseudo-color thermal images\nhere are only for presentation\
    \ and were scaled between 10 ◦C (RGB: [25, 25, 113]) and 80 ◦C (RGB:\n[235, 246,\
    \ 255]).\n2.2.3. Statistical Analysis\nThe impact of irrigation type (ﬂood and\
    \ sprinkler), rate (100, 75, 50, and 25% ETc),\nand interaction of both on crop\
    \ biophysical parameters were statistically evaluated using a\none-way analysis\
    \ of variance at a 5% level of signiﬁcance [34].\n2.3. Crop Water Stress Classiﬁcation\n\
    Two different approaches (1) feature extraction-based (DL models: AlexNet, GoogLeNet,\n\
    Inception V3, MobileNet V2, and ResNet50) and (2) function approximation-based\
    \ ML\nmodels (Artiﬁcial neural network (ANN), K-nearest neighbors (KNN), Support\
    \ vector\nmachine (SVM), and Logistic regression (LR)); and a DL model (DL-LSTM)\
    \ were adopted\nfor crop water stress classiﬁcation. Feature extraction-based\
    \ models were trained on thermal\nas well as RGB imagery. Function approximation-based\
    \ models were trained on ambient\nweather and soil parameters, and Tc inputs from\
    \ thermal imagery.\nDeep CNNs typically have complex architecture and some may\
    \ require signiﬁcant\ncomputational resources. All CNN model training and validation\
    \ processes were performed\non a desktop computer (Intel Core I7 Processor with\
    \ base frequency 2.60 GHz, 16 GB RAM,\n6 GB NVIDIA GeForce GTX 1660 Ti GPU) with\
    \ Windows 10 operating system (64 bits).\nPlants 2022, 11, 3344\n6 of 21\nCNN\
    \ models were developed in MATLAB 2019b using the deep learning and machine\n\
    learning toolbox. All the models are detailed in the following sub-sections.\n\
    2.3.1. Feature Extraction-Based Approaches\nFive DL models were selected as the\
    \ feature extraction-based approaches (1) AlexNet;\n(2) GoogLeNet; (3) Inception\
    \ V3; (4) MobileNet V2; and (5) ResNet50. These models were se-\nlected for their\
    \ extraordinary capabilities of automated feature extraction, easy and efﬁcient\n\
    training of the raw images with optimum computation resources, and their transferability\n\
    to edge computation devices [10,17]. The selected models ranged from the simplest\
    \ architec-\nture (AlexNet and MobileNet V2) to the most complex architecture\
    \ (GoogLeNet, Inception\nV3, and ResNet50) in order to evaluate their robustness\
    \ and efﬁciencies for crop water stress\nprediction. Successful application of\
    \ these models has been reported with accuracies up to\n100% for crop abiotic\
    \ and biotic stress classiﬁcation in recent studies [35–37]. Standardized\narchitectures\
    \ were used in the models for performance comparisons (Table 1).\nTable 1. Architecture\
    \ parameters in the feature extraction-based models for crop water stress classification.\n\
    Architecture Parameters\nAlexNet\nGoogLeNet\nInception V3\nMobileNet V2\nResNet50\n\
    Input image size\n227 × 227 × 3\n224 × 224 × 3\n299 × 299 × 3\n224 × 224 × 3\n\
    224 × 224 × 3\nNo. of layers\n25\n141\n316\n154\n177\nRelu layer\n7\n57\n95\n\
    35\n49\nMax Pooling layer\n3\n13\n4\n-\n01\nConvolutional layers\n5\n57\n94\n\
    35\n53\nDropout layer\n2\n1\n-\n-\n-\nFully connected\n3\n1\n1\n1\n1\nFully connected\
    \ layer Function\nFC8\nLoss3 classiﬁer\nPredictions\nLogits\nFC1000\nDepth\n8\n\
    22\n48\n53\n50\nParameters\n61 × 106\n7 × 106\n23.9 × 106\n3.5 × 106\n25.6 × 106\n\
    The DL-based classification includes steps of pre-trained model selection, data\
    \ pre-\nprocessing using morphological operators, data splitting, setting the\
    \ training hyper-parameters,\nmodel training, model tuning, cross-validation,\
    \ evaluation, and model testing (Figure 3).\nDL models were developed in MATLAB\
    \ (version 2019a, Mathworks, Natick, Boston, MA,\nUSA) using libraries of AlexNet,\
    \ GoogLeNet, Inception V3, MobileNet V2, and ResNet50.\nThe convolutional kernels\
    \ in AlexNet were extracted using the cost function optimized by\na stochastic\
    \ gradient descent with momentum (Sgdm) algorithm. While GoogLeNet pro-\ncesses\
    \ and classiﬁes images by alternately factorizing the convolutions and regularization\n\
    layers. To train a GoogLeNet model, the model’s loss 3-classiﬁer, prob, and output\
    \ layers\nwere replaced by fully connected, softmax and output class layers which\
    \ connected with\nother traditional layers. The inception V3 extracted (a) local\
    \ features of the stressed crop by\nusing small convolutions and (b) high abstracted\
    \ features with large convolutions. The last\nthree prediction layers in inception\
    \ V3 were replaced by three new layers; fully connected,\nsoftmax, and classiﬁcation\
    \ output layer. These layers were interconnected with average\npooling and a fully\
    \ connected layer of the pre-trained DL. MobileNet V2 and ResNet50 are\nthe very\
    \ recently proposed DL models for classiﬁcation problems. MobileNet V2 requires\n\
    less computational power compared to conventional CNN. ResNet50 is a deep residual\n\
    network that uses the shortcut connections by reducing the convolutional layers\
    \ and by\nalso solving the vanishing gradient issue typical to CNN. The residual\
    \ modules in ResNet50\nwere used to connect different layers of CNN to improve\
    \ the model performance [38].\nGeneralization can be poor for feature extraction-based\
    \ models when the number of\nepochs and batch sizes are more than the optimum\
    \ [39]. This is because the model can\noverlearn when trained on a speciﬁc dataset\
    \ at large epochs and batch sizes, and may lose\nits performance and generalization\
    \ capability when trained on new datasets. Conversely,\nthe smaller epochs and\
    \ bath sizes may lead to insufﬁcient learning and underﬁtting of the\nmodel and\
    \ hence may not perform as expected with the new datasets [40]. Therefore, to\n\
    Plants 2022, 11, 3344\n7 of 21\nmaximize the model performance and minimize their\
    \ overﬁtting, optimum hyperparameter\ntuning is required. In this study, all the\
    \ selected feature extraction-based models were\nextensively tuned with learning\
    \ rates, solvers, epochs, and batch sizes as detailed in Table 2.\nPlants 2022,\
    \ 11, x FOR PEER REVIEW \n7 of 22 \n \n \nThese layers were interconnected with\
    \ average pooling and a fully connected layer of the \npre-trained DL. MobileNet\
    \ V2 and ResNet50 are the very recently proposed DL models \nfor classification\
    \ problems. MobileNet V2 requires less computational power compared \nto conventional\
    \ CNN. ResNet50 is a deep residual network that uses the shortcut con-\nnections\
    \ by reducing the convolutional layers and by also solving the vanishing gradient\
    \ \nissue typical to CNN. The residual modules in ResNet50 were used to connect\
    \ different \nlayers of CNN to improve the model performance [38].  \n \nFigure\
    \ 3. Data processing pipeline for stress prediction using selected deep learning\
    \ and machine \nlearning models. \nGeneralization can be poor for feature extraction-based\
    \ models when the number of \nepochs and batch sizes are more than the optimum\
    \ [39]. This is because the model can \noverlearn when trained on a specific dataset\
    \ at large epochs and batch sizes, and may \nlose its performance and generalization\
    \ capability when trained on new datasets. Con-\nversely, the smaller epochs and\
    \ bath sizes may lead to insufficient learning and under-\nfitting of the model\
    \ and hence may not perform as expected with the new datasets [40]. \nTherefore,\
    \ to maximize the model performance and minimize their overfitting, optimum \n\
    hyperparameter tuning is required. In this study, all the selected feature extraction-based\
    \ \nmodels were extensively tuned with learning rates, solvers, epochs, and batch\
    \ sizes as \ndetailed in Table 2. \nTable 2. Hyperparameter tuning considerations\
    \ to reduce overfitting and performance enhance-\nment of the feature extraction-based\
    \ models. \nFigure 3. Data processing pipeline for stress prediction using selected\
    \ deep learning and machine\nlearning models.\nCollected thermal and RGB images\
    \ (1600 each) were labeled into stressed and non-\nstressed classes by the domain\
    \ experts based on the values of crop water stress indicators of\nSMC, RWC, and\
    \ Tc (Table 3). After this, 80% of the labeled dataset (separately for thermal\n\
    and RGB images) was used for DL model training based on features of object dimensions,\n\
    pixel intensity, pixel values (Tc), edges, etc. The remaining 20% of the labeled\
    \ dataset was\nused for model validations and testing.\nTable 2. Hyperparameter\
    \ tuning considerations to reduce overﬁtting and performance enhancement\nof the\
    \ feature extraction-based models.\nParameters\nValue\nEpoch\n5, 10, and 20\n\
    Batchsize\n5, 10, 15, and 20\nIterations\n250 and 300\nSolver\nSgdm and Adam\n\
    Learning rate\n1 × 10−4, 2 × 10−4, and 3 × 10−4\nSgdm: stochastic gradient descent\
    \ with momentum; Adam: adaptive moment estimation.\nPlants 2022, 11, 3344\n8 of\
    \ 21\nTable 3. Crop and auxiliary data ranges for stressed and non-stressed labeling.\n\
    Crop Label\nParameter\nOutput\nReferences\nStressed\nCanopy temperature (Tc):\
    \ >23 ◦C &\nRelative water content (RWC): <90% &\nSoil moisture content (SMC):\
    \ <25%\n0\n[41–46]\nNon-Stressed\nneither of the “stressed” conditions\n1\n2.3.2.\
    \ Function Approximation-Based Approaches\nFour ML models; ANN, KNN, LR, and SVM\
    \ and a DL-based LSTM (DL-LSTM) were\nselected as the function approximation approaches\
    \ for crop water stress classiﬁcation. The\nML models were selected as those provide\
    \ an opportunity to analyze numerous features\nsimultaneously unlike traditional\
    \ methods. ANN is effective in learning complex nonlinear\nfunctions and segmenting\
    \ data based on the learned weights. The input layer had four\nvariables to extract\
    \ features from 1600 samples while the output layer had one neuron to\ncalculate\
    \ the probability of each class [47]. KNN classiﬁes a data point based on its\
    \ distance\nfrom the maximum number of training data points in the neighborhood.\
    \ Typically, KNN\nuses Euclidean, Minkowski, Manhattan, or Hamming distances out\
    \ of which Minkowski\ndistance has been reported to be more reliable [48] and\
    \ was therefore selected in the model.\nLR classiﬁes data points into discrete\
    \ classes based on probability using a sigmoid or logistic\nfunction [49]. SVM\
    \ shifts data points to a higher dimension using linear, non-linear, and\nradial\
    \ kernels to achieve linear separability [50] and then identiﬁes a hyperplane\
    \ for the\nhighest possible distance between data points of the two classes. DL-LSTM\
    \ uses a chain of\nrepeated modules comprising memory cells with a backpropagation\
    \ algorithm to solve the\nclassiﬁcation problems. This model solves premature\
    \ overﬁtting and vanishing gradient\nissues by using the previously stored information\
    \ in the memory cell. The information\nis then used to generate the features during\
    \ the training process to predict the output\nclass [51]. ML models automatically\
    \ tuned their hyperparameter values by using Bayesian\noptimization. The optimization\
    \ minimizes the model loss based on the hyperparameter\ncombination and yields\
    \ the best possible set of parameters. Further, the models were\ntrained and validated\
    \ on these tuned hyperparameters. All function-approximation models\nwere deployed\
    \ on crop environment (Ta, RH, and SMC) and temperature (Tc, from thermal\nimages)\
    \ inputs for classiﬁcation into stressed and non-stressed through binary outputs\
    \ (0\nor 1, Table 3). The models (operating parameters in Table 4) were developed\
    \ in Python 3.7\nwith Keras and TensorFlow libraries.\nTable 4. Training parameters\
    \ of function approximation-based classiﬁcation models.\nFunction Approximation\
    \ Model\nParameters\nArtiﬁcial Neural Network (ANN)\nHidden layers: 2\nNeurons:\
    \ 64, 32\nLearning rate (alpha): 0.01\nActivation functions: sigmoid\nBatch size:\
    \ 8\nNumber of epochs: 300\nOptimizer: Adam\nLoss function: binary cross entropy\n\
    Kernel Nearest Neighbour (KNN)\nNumber of Neighbors (K): 8\nDistance Metric: minkowski\n\
    Weights: uniform\nAlgorithm: ball-tree\nLogistic Regression (LR)\nPenalty parameter:\
    \ L1\nInverse of regularization parameter (C): 5\nMaximum iteration: 100\nTolerance:\
    \ 0.0001\nPlants 2022, 11, 3344\n9 of 21\nTable 4. Cont.\nFunction Approximation\
    \ Model\nParameters\nSupport Vector Machine (SVM)\nKernel Type (Kernel): RBF (Radial\
    \ basis Function)\nPenalty parameter (C): 100\nbandwidth parameter (gamma): 0.001\n\
    Degree of the polynomial kernel: 3\nDeep Learning-Long Short Term Memory (DL-LSTM)\n\
    Number of neurons: 180\nEpochs: 200\nBatch size: 10\nOptimizer: Adam\nNumber of\
    \ hidden layers: 2\nLoss activation function: MAE (Mean absolute error)\nAdam:\
    \ adaptive moment estimation.\n2.4. Model Performance Evaluation\nThe performance\
    \ of both feature extraction and function approximation-based models\nwas evaluated\
    \ through accuracy (A), sensitivity (Se), speciﬁcity (Sp), precision (P), and\
    \ F1\nscore parameters (Equations (1)–(5)). Accuracy is the correct prediction\
    \ rate of non-stressed\nand stressed crops, precision is the fraction of true\
    \ positive (TS) or correctly predicted\nstressed crop from an overall prediction\
    \ of the stressed crop (PS), speciﬁcity is the true\nnegative (TN) or correctly\
    \ predicted non-stressed crops from the actual non-stressed crops\n(AN). Sensitivity\
    \ represents a fraction of the correctly predicted stressed crops (TS) from the\n\
    actual stressed crops (AS) and the F1 score is the harmonic mean of precision\
    \ and sensitivity.\nThe F1 score evaluates the accuracy of a binary classiﬁcation\
    \ problem as in this study, which\naims to classify the crops into two classes\
    \ (stressed and non-stressed). Often, the accuracy\nestimate is affected by true\
    \ negatives and therefore F1 score is highly used over accuracy to\nseek a balance\
    \ between the precision and recall (sensitivity) parameters and when there is\n\
    an uneven class distribution (a large number of actual negatives).\nA = TS + TN\n\
    TT\n(1)\nSe = TS\nAS\n(2)\nSp = TN\nAN\n(3)\nP = TS\nPS\n(4)\nF1 =\n2 ∗ TS\nAS\
    \ + PS\n(5)\nwhere TT is the total number of predictions. Stress/non-stress misclassiﬁcation\
    \ was rep-\nresented by type1 (TE1) (false positive) and type2 errors (TE2) (false\
    \ negative). TE1 is the\nnumber of actual stressed crops misclassiﬁed as non-stressed\
    \ (row 1-column 2 of the confu-\nsion matrix) while TE2 is the number of actual\
    \ non-stressed crops misclassiﬁed as stressed\n(row 2-column 1 of the confusion\
    \ matrix).\n3. Results\n3.1. Plant Water Stress Indicators\nThe thermal imagery\
    \ derived canopy temperatures (Tc (◦C)) under sprinkler irrigation\nat 100, 75,\
    \ 50 and 25% of ETc irrigation levels were 22.1 (2.0) (Mean, standard deviation\n\
    (SD)), 25.6 (1.6), 26.4 (2.2), and 27.9 ◦C (3.0 ◦C), respectively (Figure 4).\
    \ While Tc for ﬂood\nirrigation at the above irrigation levels were 23.2 (2.0),\
    \ 25.9 (1.5), 26.8 (2.4), and 28.1 ◦C\n(3.1 ◦C), respectively. Similarly, mean\
    \ RWC (%) at selected sprinkler irrigation rates were\nPlants 2022, 11, 3344\n\
    10 of 21\n90.4 (2.7), 87.7 (4.2), 75.8 (9.4), and 74.2% (8.2%) while at corresponding\
    \ irrigation levels in\nﬂood irrigation were 89.8 (2.7), 87.2 (4.3), 75.0 (9.4)\
    \ and 73.9% (8.3%), respectively. The mean\nSMCs (%) for respective sprinkler\
    \ irrigation were 26.6 (2.3), 26.2 (2.7), 22.5 (3.3), and 21.1%\n(3.0%) while\
    \ those for respective ﬂood irrigation were 24.9 (2.0), 24.4 (2.5), 21.4 (3.0),\
    \ and\n20.4% (3.1%). When analyzed statistically, Tc, RWC, and SMC were signiﬁcantly\
    \ affected\nby the irrigation method (ﬂood and sprinkler), irrigation rate (100,\
    \ 75, 50, and 25% ETc), as\nwell as their interaction (One-way ANOVA, p < 0.001).\
    \ The RWC and SMC decreased with\nthe decrease in irrigation level, while the\
    \ Tc increased. Based on the categories detailed in\nTable 3, the mean Tc for\
    \ the stressed crop was 26.6 ◦C (±2.6), and that for the non-stressed\ncrop was\
    \ 21.2 ◦C (±1.4). The mean RWC for the non-stressed crop was 92.2% (±1.5) and\n\
    for the stressed crop was 78.9% (±9.2) while the mean SMC for the non-stressed\
    \ crop was\n27.1% (1.6) and for the stressed crop was 21.2% (±2.4).\n3.2. Water\
    \ Stress Prediction\n3.2.1. Feature Extraction-Based Approaches\nThe performances\
    \ of AlexNet, GoogLeNet, Inception V3, MobileNet V2, and ResNet50\nmodels for\
    \ RGB and thermal imagery were tested for different combinations of epochs\nand\
    \ batch sizes (Table 5). The model training accuracies increased with the increase\
    \ in\nthe number of epochs from 5 to 10 and over-ﬁtting was observed for all the\
    \ models when\nepochs increased to 20. Over different epochs, accuracy increased\
    \ with the increase in\nbatch size from 5 to 20. For the batch size of 20 and\
    \ 250 iterations, overﬁtting was observed\nin Inception and ResNet50 with RGB\
    \ imagery inputs and in AlexNet, GoogLeNet, and\nResNet50 with thermal imagery\
    \ inputs (Table 5). Extensive hyperparameter tuning was\nperformed with parameters\
    \ listed in Table 2 to minimize overﬁtting and maximize the\nmodel accuracies.\
    \ Post-tuning, the maximum training accuracies of 94.6%, 96.7%, and 95.6%\nwere\
    \ observed for AlexNet, GoogLeNet, and MobileNet V2, respectively with RGB imagery\n\
    inputs at 10 epochs and batch size of 20 (Figure 5). While the Inception V3 and\
    \ ResNet50\nfor RGB imagery inputs converged at 10 epochs, batch size of 15, and\
    \ 300 iterations with\nrespective accuracies of 92.7% and 97.1% (Figure 5c,e).\
    \ For the thermal imagery inputs, the\noptimum hyperparameters were 10 epochs\
    \ and a batch size of 15, which yielded maximum\naccuracies of 96.4%, 97.2%, and\
    \ 98.5% for AlexNet, GoogLeNet, and ResNet50, respectively.\nFurthermore, 10 epochs\
    \ and a batch size of 20 were found optimum for Inception V3\nand MobileNet V2\
    \ models, and pertinent maximum accuracies were 98.0% and 95.3%,\nrespectively\
    \ (Figure 6). During hyperparameter tuning, the model overﬁtting reduced\nsigniﬁcantly\
    \ at 10 epochs without sacriﬁcing accuracy. The training accuracies fell below\n\
    50% for learning rates of 1 × 10−4 and 4 × 10−4 and went over 50% for the learning\
    \ rate of\n3 × 10−4. Moreover, the model overﬁtting was reduced when the solver\
    \ was shifted from\nSgdm to Adam. All the models converged with training accuracies\
    \ > 90% at the learning\nrate of 3 × 10−4 and Adam as the solver (Figures 5 and\
    \ 6).\nTable 5. Training accuracies of feature extraction-based models to characterize\
    \ wheat water stress\nusing RGB and thermal imagery inputs under different epoch\
    \ and batch size combinations.\nAccuracy (%)\nEpochs\nBatch Size\nAlexNet\nGoogLeNet\n\
    Inception V3\nMobileNet V2\nResNet50\nFeature Extraction-Based Approaches with\
    \ RGB Imagery Inputs\n5\n5\n90.4\n95.2\n91.9\n95.1\n96.3\n5\n10\n89.4\n94.3\n\
    90.5\n93.0\n92.7\n5\n15\n92.3\n94.6\n90.4\n92.3\n93.5\n5\n20\n92.6\n95.0\n90.8\n\
    92.7\n94.6\n10\n5\n93.8\n95.5\n92.2\n93.1\n95.8\n10\n10\n92.7\n95.7\n92.4\n94.2\n\
    95.1\n10\n15\n93.4\n95.9\n92.7\n94.4\n97.1\n10\n20\n94.6\n96.7\n93.6\n95.6\n97.2\n\
    20\n5\n95.3\n97.2\n93.8\n94.4\n92.3\nPlants 2022, 11, 3344\n11 of 21\nTable 5.\
    \ Cont.\nAccuracy (%)\nEpochs\nBatch Size\nAlexNet\nGoogLeNet\nInception V3\n\
    MobileNet V2\nResNet50\nFeature Extraction-Based Approaches with RGB Imagery Inputs\n\
    20\n10\n95.6\n97.5\n94.2\n95.5\n97.2\n20\n15\n96.6 *\n98.0\n94.5\n96.7 *\n97.9\
    \ *\n20\n20\n96.2\n98.2 *\n95.0 *\n96.1\n95.8\nFeature extraction-based approaches\
    \ with thermal imagery inputs\n5\n5\n94.4\n96.2\n97.0\n94.8\n95.9\n5\n10\n95.9\n\
    95.8\n96.8\n94.7\n95.9\n5\n15\n96.4\n95.4\n95.9\n93.1\n98.4\n5\n20\n92.7\n96.0\n\
    96.2\n92.7\n97.6\n10\n5\n94.5\n96.5\n97.2\n93.5\n96.7\n10\n10\n96.0\n96.7\n97.4\n\
    94.2\n97.3\n10\n15\n96.4\n97.2\n97.5\n94.7\n98.5\n10\n20\n96.5\n97.2\n98.0\n95.3\n\
    98.7\n20\n5\n97.2\n97.6\n98.2\n97.2\n99.0\n20\n10\n97.4\n98.1\n98.5\n97.5\n99.2\n\
    20\n15\n98.2 *\n98.5 *\n98.7 *\n98.1 *\n99.5 *\n20\n20\n98.0\n98.0\n98.5\n97.9\n\
    99.0\n* Highest accuracy for the epoch and batch size combinations.\nPlants 2022,\
    \ 11, x FOR PEER REVIEW \n11 of 22 \n \n \nFigure 4. Variations in (a) canopy\
    \ temperature; (b) soil moisture content; (c) relative water content; \nand (d)\
    \ grain yield from wheat plots irrigated at different rates. S and F represent\
    \ sprinkler and \nflood irrigations, respectively and the numbers followed by\
    \ these letters denote irrigation rates \nlevels as % of full crop evapotranspiration\
    \ (ETc). \n3.2. Water Stress Prediction \n3.2.1. Feature Extraction-Based Approaches\
    \ \nThe performances of AlexNet, GoogLeNet, Inception V3, MobileNet V2, and Res-\n\
    Net50 models for RGB and thermal imagery were tested for different combinations\
    \ of \nepochs and batch sizes (Table 5) The model training accuracies increased\
    \ with the in\nFigure 4. Variations in (a) canopy temperature; (b) soil moisture\
    \ content; (c) relative water content;\nand (d) grain yield from wheat plots irrigated\
    \ at different rates. S and F represent sprinkler and ﬂood\nirrigations, respectively\
    \ and the numbers followed by these letters denote irrigation rates levels as\
    \ %\nof full crop evapotranspiration (ETc).\nPlants 2022, 11, 3344\n12 of 21\n\
    \ \n \nhigher for the models with thermal imagery inputs compared to those with\
    \ RGB imagery \ninputs. The individual accuracy and errors for all the feature\
    \ extraction-based models \nwith validation datasets are shown in Figure 7. The\
    \ mean errors were higher for the RGB \nimagery compared to the thermal imagery\
    \ irrespective of the selected models.  \n \nFigure 5. Accuracy and loss curves\
    \ for (a) AlexNet; (b) GoogLeNet; (c) Inception V3; (d) MobileNet \nV2; and (e)\
    \ ResNet50 models with RGB imagery inputs for crop water stress identification.\
    \ \nFigure 5. Accuracy and loss curves for (a) AlexNet; (b) GoogLeNet; (c) Inception\
    \ V3; (d) MobileNet\nV2; and (e) ResNet50 models with RGB imagery inputs for crop\
    \ water stress identiﬁcation.\nThe training time elapsed for AlexNet, GoogLeNet,\
    \ Inception V3, MobileNet V2, and\nResNet50 was 76, 92, 609, 149, and 217 min\
    \ with RGB imagery inputs, and 42, 88, 287,\n134, 168 min with thermal imagery\
    \ inputs, respectively. While the classiﬁcation of an\nindependent image using\
    \ trained models into stressed/non-stressed class consumed less\nthan 5 s. The\
    \ overall validation accuracies (combined for stressed and non-stressed classes)\n\
    for AlexNet, GoogLeNet, Inception V3, MobileNet V2, and ResNet50 models were 93.4%,\n\
    95.9%, 92.5%, 94.4%, and 96.9%, respectively with RGB imagery inputs (Figure 7).\
    \ The\nhighest precision (100%) and F1 score (96.6%) were observed for GoogLeNet\
    \ and ResNet50,\nrespectively while maximum sensitivity was achieved for MobileNet\
    \ V2 (Table 6). Pertinent\nto thermal imagery inputs, overall validation accuracies\
    \ (combined for stressed and non-\nstressed classes) with AlexNet, GoogLeNet,\
    \ Inception V3, MobileNet V2, and ResNet50\nmodels were 96.2%, 96.9%, 97.5%, 94.7%,\
    \ and 98.4%, respectively. Alike RGB imagery,\nResNet50 for thermal imagery had\
    \ the highest precision (96.7%), sensitivity (100%), and\nF1 score (98.3%) (Table\
    \ 6). Additionally, the accuracies were higher for the models with\nthermal imagery\
    \ inputs compared to those with RGB imagery inputs. The individual\naccuracy and\
    \ errors for all the feature extraction-based models with validation datasets\n\
    are shown in Figure 7. The mean errors were higher for the RGB imagery compared\
    \ to the\nthermal imagery irrespective of the selected models.\nPlants 2022, 11,\
    \ 3344\n13 of 21\nPlants 2022, 11, x FOR PEER REVIEW \n14 of 22 \n \n \n \nFigure\
    \ 6. Accuracy and loss curves for (a) AlexNet; (b) GoogLeNet; (c) Inception V3;\
    \ (d) MobileNet \nV2; and (e) ResNet50 models with thermal imagery inputs for\
    \ crop water stress identification. \nTable 6. Validation performance of feature\
    \ extraction and function approximation models to \ncharacterize wheat water stress.\
    \ \nModels \nAccuracy (%) \nPrecision (%) \nSensitivity (%) \nF1 Score (%) \n\
    Feature Extraction-Based Approaches with only RGB Imagery Inputs \nAlexNet \n\
    93.4 \n91.4 \n94.5 \n92.2 \nGoogLeNet \n95.9 \n100 \n91.1 \n95.3 \nInception V3\
    \ \n92.5 \n94.4 \n89.4 \n91.8 \nMobileNet V2 \n94.4 \n89.0 \n100.0 \n94.1 \nResNet50\
    \ \n96.9 \n95.9 \n97.3 \n96.6 \nFeature extraction-based approaches with only\
    \ thermal imagery inputs \nAlexNet \n96.2 \n95.9 \n95.9 \n95.9 \nGoogLeNet \n\
    96.9 \n96.6 \n96.6 \n96.6 \nInception V3 \n97.5 \n96.6 \n98.0 \n97.3 \nMobileNet\
    \ V2 \n94.7 \n94.0 \n94.7 \n94.3 \nResNet50 \n98.4 \n96.7 \n100.0 \n98.3 \nFunction\
    \ approximation-based approaches (with RWC, SMC, Tc, and RH inputs) \nANN \n93.5\
    \ \n92.7 \n92.7 \n93.0 \nKNN \n88.1 \n90.2 \n84.1 \n86.9 \nLR \n89.2 \n95.1 \n\
    82.9 \n88.6 \nSVM \n91.4 \n95.1 \n86.7 \n90.8 \nDL-LSTM \n96.7 \n96.0 \n97.9 \n\
    97.0 \nFigure 6. Accuracy and loss curves for (a) AlexNet; (b) GoogLeNet; (c)\
    \ Inception V3; (d) MobileNet\nV2; and (e) ResNet50 models with thermal imagery\
    \ inputs for crop water stress identiﬁcation.\nTable 6. Validation performance\
    \ of feature extraction and function approximation models to charac-\nterize wheat\
    \ water stress.\nModels\nAccuracy (%)\nPrecision (%)\nSensitivity (%)\nF1 Score\
    \ (%)\nFeature Extraction-Based Approaches with only RGB Imagery Inputs\nAlexNet\n\
    93.4\n91.4\n94.5\n92.2\nGoogLeNet\n95.9\n100\n91.1\n95.3\nInception V3\n92.5\n\
    94.4\n89.4\n91.8\nMobileNet V2\n94.4\n89.0\n100.0\n94.1\nResNet50\n96.9\n95.9\n\
    97.3\n96.6\nFeature extraction-based approaches with only thermal imagery inputs\n\
    AlexNet\n96.2\n95.9\n95.9\n95.9\nGoogLeNet\n96.9\n96.6\n96.6\n96.6\nInception\
    \ V3\n97.5\n96.6\n98.0\n97.3\nMobileNet V2\n94.7\n94.0\n94.7\n94.3\nResNet50\n\
    98.4\n96.7\n100.0\n98.3\nFunction approximation-based approaches (with RWC, SMC,\
    \ Tc, and RH inputs)\nANN\n93.5\n92.7\n92.7\n93.0\nKNN\n88.1\n90.2\n84.1\n86.9\n\
    LR\n89.2\n95.1\n82.9\n88.6\nSVM\n91.4\n95.1\n86.7\n90.8\nDL-LSTM\n96.7\n96.0\n\
    97.9\n97.0\nPlants 2022, 11, 3344\n14 of 21\nPlants 2022, 11, x FOR PEER REVIEW\
    \ \n15 of 22 \n \n \n \nFigure 7. Confusion matrices for AlexNet, GoogLeNet, Inception\
    \ V3, MobileNet V2, and ResNet50 \nmodels pertinent validation datasets of RGB\
    \ imagery (a–e) and thermal imagery (f–j). Cell values \n(%) in row 1 column 2\
    \ represent type 1 error (TE1) while those in row 2 column 1 represent type 2\
    \ \nerror (TE2) (details in Section 2.4). Numbers (% and actual counts) in green\
    \ color indicate prediction \naccuracy while those in red color are prediction\
    \ errors for stressed and non-stressed crop classes. \nNumbers in green box represent\
    \ correct prediction and those in red box represent misclassification \nof non-stressed/stressed\
    \ classes. \n3.2.2. Function Approximation-Based Approaches \nAmongst the function\
    \ approximation approaches, the highest prediction accuracy \nwas obtained with\
    \ the DL-LSTM model (96.7%) followed by ANN (93.5%), SVM (91.4%), \nLR (89.2%),\
    \ and KNN models (88.1%) (Table 6). Moreover, the precision, sensitivity, and\
    \ \nF1 score were also highest for the DL-LSTM (96.0, 97.9, and 97.0%, respectively)\
    \ com-\npared to other ML models. The training and validation accuracies with\
    \ DL-LSTM \nshowed early convergence for which the loss on the validation dataset\
    \ reached minima at \n40 epochs (Figure 8). The TE1 for ANN, KNN, LR, SVM, and\
    \ LSTM were 3.2, 4.3, 2.2, 2.2, \nand 2.1%, respectively and TE2 were 3.2, 7.5,\
    \ 8.6, 6.5, and 1.1%, respectively (Figure 9). The \nDL-LSTM outperformed ML models\
    \ with the lowest mean error (Figure 9). \n \nFigure 8. Accuracy and loss corves\
    \ for Long Short Term memory based deep learning model for \ncrop water stress\
    \ identification. \nFigure 7. Confusion matrices for AlexNet, GoogLeNet, Inception\
    \ V3, MobileNet V2, and ResNet50\nmodels pertinent validation datasets of RGB\
    \ imagery (a–e) and thermal imagery (f–j). Cell values (%)\nin row 1 column 2\
    \ represent type 1 error (TE1) while those in row 2 column 1 represent type 2\
    \ error\n(TE2) (details in Section 2.4). Numbers (% and actual counts) in green\
    \ color indicate prediction\naccuracy while those in red color are prediction\
    \ errors for stressed and non-stressed crop classes.\nNumbers in green box represent\
    \ correct prediction and those in red box represent misclassiﬁcation of\nnon-stressed/stressed\
    \ classes.\n3.2.2. Function Approximation-Based Approaches\nAmongst the function\
    \ approximation approaches, the highest prediction accuracy was\nobtained with\
    \ the DL-LSTM model (96.7%) followed by ANN (93.5%), SVM (91.4%), LR\n(89.2%),\
    \ and KNN models (88.1%) (Table 6). Moreover, the precision, sensitivity, and\
    \ F1\nscore were also highest for the DL-LSTM (96.0, 97.9, and 97.0%, respectively)\
    \ compared\nto other ML models. The training and validation accuracies with DL-LSTM\
    \ showed early\nconvergence for which the loss on the validation dataset reached\
    \ minima at 40 epochs\n(Figure 8). The TE1 for ANN, KNN, LR, SVM, and LSTM were\
    \ 3.2, 4.3, 2.2, 2.2, and 2.1%,\nrespectively and TE2 were 3.2, 7.5, 8.6, 6.5,\
    \ and 1.1%, respectively (Figure 9). The DL-LSTM\noutperformed ML models with\
    \ the lowest mean error (Figure 9).\nPlants 2022, 11, x FOR PEER REVIEW \n15 of\
    \ 22 \n \n \n \nFigure 7. Confusion matrices for AlexNet, GoogLeNet, Inception\
    \ V3, MobileNet V2, and ResNet50 \nmodels pertinent validation datasets of RGB\
    \ imagery (a–e) and thermal imagery (f–j). Cell values \n(%) in row 1 column 2\
    \ represent type 1 error (TE1) while those in row 2 column 1 represent type 2\
    \ \nerror (TE2) (details in Section 2.4). Numbers (% and actual counts) in green\
    \ color indicate prediction \naccuracy while those in red color are prediction\
    \ errors for stressed and non-stressed crop classes. \nNumbers in green box represent\
    \ correct prediction and those in red box represent misclassification \nof non-stressed/stressed\
    \ classes. \n3.2.2. Function Approximation-Based Approaches \nAmongst the function\
    \ approximation approaches, the highest prediction accuracy \nwas obtained with\
    \ the DL-LSTM model (96.7%) followed by ANN (93.5%), SVM (91.4%), \nLR (89.2%),\
    \ and KNN models (88.1%) (Table 6). Moreover, the precision, sensitivity, and\
    \ \nF1 score were also highest for the DL-LSTM (96.0, 97.9, and 97.0%, respectively)\
    \ com-\npared to other ML models. The training and validation accuracies with\
    \ DL-LSTM \nshowed early convergence for which the loss on the validation dataset\
    \ reached minima at \n40 epochs (Figure 8). The TE1 for ANN, KNN, LR, SVM, and\
    \ LSTM were 3.2, 4.3, 2.2, 2.2, \nand 2.1%, respectively and TE2 were 3.2, 7.5,\
    \ 8.6, 6.5, and 1.1%, respectively (Figure 9). The \nDL-LSTM outperformed ML models\
    \ with the lowest mean error (Figure 9). \n \nFigure 8. Accuracy and loss corves\
    \ for Long Short Term memory based deep learning model for \ncrop water stress\
    \ identification. \nFigure 8. Accuracy and loss corves for Long Short Term memory\
    \ based deep learning model for crop\nwater stress identiﬁcation.\nPlants 2022,\
    \ 11, 3344\n15 of 21\nPlants 2022, 11, x FOR PEER REVIEW \n16 of 22 \n \n \n \n\
    Figure 9. The confusion matrices for function approximation-based (a) ANN; (b)\
    \ KNN; (c) LR; (d) \nSVM; and (e) DL-LSTM models. Cell values (%) in row 1 column\
    \ 2 represent type 1 error (TE1) while \nthose in row 2 column 1 represent type\
    \ 2 error (TE2) (details in Section 2.4). Numbers (% and actual \ncounts) in green\
    \ color indicate prediction accuracy while those in red color are prediction errors\
    \ for \nstressed and non-stressed crop classes. Numbers in green box represent\
    \ correct prediction and \nthose in red box represent misclassification of non-stressed/stressed\
    \ classes. \n4. Discussion \nSprinkler irrigation applies a predetermined quantity\
    \ of water and wets the entire \ncanopy, unlike traditional flood irrigation.\
    \ This cools down the microclimate and in-\ncreases relative air humidity to reduce\
    \ the microclimate’s water demand [52]. This could \nbe the reason for lower Tc\
    \ in all the sprinkler irrigation treatments compared to the cor-\nresponding\
    \ flood irrigation treatments (Figure 4). Lowered microclimate water demand \n\
    could have also resulted in lower soil moisture depletion from the root zone and\
    \ there-\nfore higher SMC with sprinkler irrigation [53]. In addition to sufficient\
    \ SMC, sprinkler \nirrigation results in lower deep percolation and nutrient leaching\
    \ compared to conven-\ntional flood irrigation [54–56]. This could have resulted\
    \ in a higher average yield for \nsprinkler irrigation treatment plots (5719 kg/ha)\
    \ compared to the flood irrigation treat-\nment plots (4898 kg/ha). With the projected\
    \ future climate change impacts in the form of \nlow rainfall frequencies and\
    \ high ambient temperatures, crop water stresses are further \nexpected to multiply,\
    \ which will multiply the penalties in yield potentials [3]. Therefore, \nstress-tolerant\
    \ crop cultivars need to be developed and planted for uncompromised yield \ngoals.\
    \ As also reported in our prior work based on canopy reflectance [57], water stress\
    \ \nstarted to occur before the CRI stage in both methods of irrigation. RWCs\
    \ were lower at \nlate jointing and flowering stages in case of flood irrigation.\
    \ Water stress at the flowering \nstage can result in significant yield and biomass\
    \ reductions [58] suggesting that it is also \ninfluenced by the phenological\
    \ growth stage. For robust analysis of this aspect, large \ndatasets are being\
    \ collected at each phenological growth stage. Water stress lowers CO2 \navailability\
    \ due to stomatal closure, thereby affecting photosynthesis and ultimately \n\
    growth, yield, and biomass [59,60]. \nCNNs have been increasingly used for plant\
    \ phenotyping applications over the past \ndecade for their capability of modeling\
    \ complicated plant processes by distinguishing \nand extracting regularized data\
    \ patterns [61,62]. It is for this reason; CNN models were \nhighly accurate in\
    \ predicting stressed and non-stressed crops using thermal and RGB \nimagery.\
    \ Chlorophyll is vital for photosynthesis, while carotenoids are critical \nnon-enzymatic\
    \ antioxidants. Water stress reduces chlorophyll and carotenoid contents, \nas\
    \ well as the ratio of chlorophyll ‘a’ to ‘b’, leading to leaf coloration changes.\
    \ This is the \nreason for RGB images also yielding satisfactory accuracy of up\
    \ to 94.6% for tracing leaf \ncolor changes [63]. Compared to RGB imagery, thermal\
    \ imagery is a more detailed and \nbetter presenter of the crop stress that alters\
    \ the emissivity patterns proportionally \n[64,65]. The canopy temperature is\
    \ affected by the microclimate conditions and the \navailable soil moisture [53].\
    \ This is the reason for the relatively lower accuracy of water \nstress detection\
    \ with RGB images (94.6%) than with thermal images (96.7%) irrespective \nFigure\
    \ 9. The confusion matrices for function approximation-based (a) ANN; (b) KNN;\
    \ (c) LR;\n(d) SVM; and (e) DL-LSTM models. Cell values (%) in row 1 column 2\
    \ represent type 1 error (TE1)\nwhile those in row 2 column 1 represent type 2\
    \ error (TE2) (details in Section 2.4). Numbers (% and\nactual counts) in green\
    \ color indicate prediction accuracy while those in red color are prediction\n\
    errors for stressed and non-stressed crop classes. Numbers in green box represent\
    \ correct prediction\nand those in red box represent misclassiﬁcation of non-stressed/stressed\
    \ classes.\n4. Discussion\nSprinkler irrigation applies a predetermined quantity\
    \ of water and wets the entire\ncanopy, unlike traditional ﬂood irrigation. This\
    \ cools down the microclimate and increases\nrelative air humidity to reduce the\
    \ microclimate’s water demand [52]. This could be the\nreason for lower Tc in\
    \ all the sprinkler irrigation treatments compared to the corresponding\nﬂood\
    \ irrigation treatments (Figure 4). Lowered microclimate water demand could have\n\
    also resulted in lower soil moisture depletion from the root zone and therefore\
    \ higher\nSMC with sprinkler irrigation [53]. In addition to sufﬁcient SMC, sprinkler\
    \ irrigation\nresults in lower deep percolation and nutrient leaching compared\
    \ to conventional ﬂood\nirrigation [54–56]. This could have resulted in a higher\
    \ average yield for sprinkler irrigation\ntreatment plots (5719 kg/ha) compared\
    \ to the ﬂood irrigation treatment plots (4898 kg/ha).\nWith the projected future\
    \ climate change impacts in the form of low rainfall frequencies\nand high ambient\
    \ temperatures, crop water stresses are further expected to multiply, which\n\
    will multiply the penalties in yield potentials [3]. Therefore, stress-tolerant\
    \ crop cultivars\nneed to be developed and planted for uncompromised yield goals.\
    \ As also reported in\nour prior work based on canopy reﬂectance [57], water stress\
    \ started to occur before the\nCRI stage in both methods of irrigation. RWCs were\
    \ lower at late jointing and ﬂowering\nstages in case of ﬂood irrigation. Water\
    \ stress at the ﬂowering stage can result in signiﬁcant\nyield and biomass reductions\
    \ [58] suggesting that it is also inﬂuenced by the phenological\ngrowth stage.\
    \ For robust analysis of this aspect, large datasets are being collected at each\n\
    phenological growth stage. Water stress lowers CO2 availability due to stomatal\
    \ closure,\nthereby affecting photosynthesis and ultimately growth, yield, and\
    \ biomass [59,60].\nCNNs have been increasingly used for plant phenotyping applications\
    \ over the past\ndecade for their capability of modeling complicated plant processes\
    \ by distinguishing and\nextracting regularized data patterns [61,62]. It is for\
    \ this reason; CNN models were highly\naccurate in predicting stressed and non-stressed\
    \ crops using thermal and RGB imagery.\nChlorophyll is vital for photosynthesis,\
    \ while carotenoids are critical non-enzymatic an-\ntioxidants. Water stress reduces\
    \ chlorophyll and carotenoid contents, as well as the ratio\nof chlorophyll ‘a’\
    \ to ‘b’, leading to leaf coloration changes. This is the reason for RGB\nimages\
    \ also yielding satisfactory accuracy of up to 94.6% for tracing leaf color changes\
    \ [63].\nCompared to RGB imagery, thermal imagery is a more detailed and better\
    \ presenter of the\ncrop stress that alters the emissivity patterns proportionally\
    \ [64,65]. The canopy tempera-\nture is affected by the microclimate conditions\
    \ and the available soil moisture [53]. This\nis the reason for the relatively\
    \ lower accuracy of water stress detection with RGB images\n(94.6%) than with\
    \ thermal images (96.7%) irrespective of the selected DL models (Table 5).\nA\
    \ similar observation is reported in a prior study [64] where higher accuracy\
    \ was obtained\nPlants 2022, 11, 3344\n16 of 21\nwith thermal imagery (89%) compared\
    \ to RGB imagery (82%) for wheat ear counting using\nDCNN models. Since thermal\
    \ imaging is often affected by the wind or RH factors of the\nenvironment, the\
    \ quality of data will be critical for training the DL models, especially when\n\
    acquired using aerial platforms [30,64]. Therefore, to maintain thermal data quality,\
    \ imag-\ning campaigns were launched when wind velocities were below 5 kmph. The\
    \ ResNet50\nhad relatively the highest accuracy among the feature extraction models.\
    \ Although it\nis the basic version of GoogLeNet and Inception V3, the performance\
    \ would be highly\nimpacted by the quality of input imagery, size, and robustness\
    \ of the dataset, especially\nfor the agricultural environments. ResNet50 addresses\
    \ the neural network degradation\nproblem by introducing identity mapping, which\
    \ results in the disappearance of gradient\nparameters and the non-ideal convergence\
    \ effect on the deeper networks [66,67]. This fea-\nture contributed to the enhanced\
    \ performance of ResNet50 compared to the other models\nthereby suggesting the\
    \ suitability of ResNet50 for agricultural applications for various\ncrop biotic\
    \ and abiotic stress characterizations. CNN models were also applied to thermal\n\
    imagery for water stress classiﬁcation in maize under well-irrigated, moderately\
    \ irrigated,\nand water-stressed treatments, obtaining an overall accuracy of\
    \ 89% [68]. Color and grey\nimages of maize were also used as inputs to the DCNN\
    \ model for water stress identiﬁcation\nwhere stress identiﬁcation and classiﬁcation\
    \ accuracies were 98% and 95%, respectively [26].\nThe inception-ResNet V2 framework\
    \ utilized for water stress identiﬁcation in sugarcane\nyielded an accuracy of\
    \ 83% with available soil water capacity as input [65]. Thus far, most\nof the\
    \ computer vision models have utilized single-dimensional data inputs, unlike\
    \ this\nstudy which advances water-stress identiﬁcation in wheat crops using multidimensional\n\
    data inputs. Multidimensional data modeling enhances the robustness and applicability\
    \ of\ndeveloped approaches across various agroclimatic conditions.\nCrop growth\
    \ or its water stress response is not necessarily linear to the weather or\nsoil\
    \ conditions [69]. Therefore, the linear (LR) and non-linear function approximation\n\
    approaches (ANN, KNN, SVM, and DL-LSTM) were evaluated to predict the stress class\
    \ of\nthe crop. ANN and SVM had a better stress prediction accuracy (Table 6)\
    \ compared to KNN\nand LR possibly due to two reasons (1) KNN or LR either use\
    \ locally linear segments or a\ngeneralized linear approach for making predictions\
    \ [66,69] and (2) KNN and LR models\ntrain on an unsupervised learning approach,\
    \ unlike ANN and SVM, which train on a\nsupervised learning approach [18]. ANN\
    \ and SVM had comparable accuracies for crop\nstress prediction. However, SVM\
    \ suits small datasets; while ANN can process relatively\nlarger datasets. Therefore,\
    \ ANN would have more conﬁdence in prediction classes.\nCrop phenotyping with\
    \ traditional function approximation approaches (ML mod-\nels) is often subjective\
    \ compared to the advanced DL-LSTM approach as those require\nmanual feature selection\
    \ of Tc, Ta, RH, and SMC. This restricts the robustness and accu-\nracy of the\
    \ ML models. Therefore, DL-LSTM outperformed the traditional ML models\n(Figure\
    \ 9) due to its automated and stabilized feature selection advantage [12,70].\
    \ This\nwas supported by minimum model loss compared to other function approximation-based\n\
    ML models. DL-LSTM not only integrates the thermal imagery features employed in\n\
    DL models but also combines the auxiliary soil and weather data inputs, of function\
    \ ap-\nproximation models. This eventually led to its superior performance over\
    \ the other ML\nmodels evaluated in this study as well as in prior studies of\
    \ crop stress and yield phenotyp-\ning [51] or irrigation forecasting [22]. However,\
    \ GoogleNet, Inception V3, and ResNet50\nprovided comparable or higher stress\
    \ prediction accuracy compared to the DL-LSTM model\n(Table 6). Stress/non-stress\
    \ misclassiﬁcation could be minimized through improved data\nsampling, increasing\
    \ training data size, and optimizing hyper-parameters, or by merging\ndifferent\
    \ ML and DL models for crop’s thermal emissivity and environment data inputs.\n\
    Among the feature extraction and function approximation-based approaches, the\
    \ feature\nextraction-based models outperformed all the function approximation-based\
    \ models for\nwater stress classiﬁcation.\nThe CNN models evaluated in this study\
    \ can be adopted for water stress identiﬁ-\ncation in other wheat cultivars while\
    \ for other crops and their cultivars, sufﬁcient data\nPlants 2022, 11, 3344\n\
    17 of 21\nacquisition, model training, and validations would be required. Along\
    \ similar lines, gath-\nering sufﬁcient data at different crop phenological stages\
    \ will enable growth stage-wise\naccuracy evaluation of ML and DL models in future\
    \ studies. The developed algorithms\nrequired below 5 sec to be successfully implemented\
    \ on independent images for classiﬁca-\ntion into stressed/non-stressed classes.\
    \ This is critical from a real-time stress diagnosis and\nmanagement perspective.\
    \ Trained algorithms are therefore transferrable to handheld or\nedge devices\
    \ for real-time stress detection by breeders, researchers, farmers, and students,\n\
    among others. For commercial adoption of the developed and tested approaches,\
    \ capital\ninvestment would be initially required following which high returns\
    \ may be expected\nthrough improvements in crop stress mitigation and management\
    \ at reduced costs [11].\n5. Conclusions\nThe canopy temperatures, relative water\
    \ content, soil moisture content, and grain\nyield for the wheat crop were signiﬁcantly\
    \ affected by the irrigation type and rates. Lower\nTc and higher RWC, SMC, and\
    \ yield were observed for irrigation at 100% of ETc compared\nto deﬁcit irrigation\
    \ (75, 50, and 25% of ETc). Moreover, a comparable or higher yield was\nobserved\
    \ for sprinkler irrigation compared to conventional ﬂood irrigation and amounted\n\
    to 20% of the water savings.\nThermal images resulted in higher crop water stress\
    \ classification accuracy (94.7–98.4%)\ncompared to RGB imagery (92.5–96.9%).\
    \ Moreover, the DL models (including DL-LSTM)\nperformed better than the ML models\
    \ for stressed and non-stressed crop classiﬁcation.\nAmong the function approximation-based\
    \ approaches, DL-LSTM had the highest accuracy\n(96.7%). Among the feature extraction-based\
    \ methods, ResNet50 had the highest accuracy\nof 96.9% and 98.4% with RGB and\
    \ thermal imagery inputs, respectively.\nOverall, DL models with thermal imagery\
    \ inputs could be highly efﬁcient for crop\nwater stress phenotyping. As a future\
    \ scope, feature extraction-based DL models could\nbe implemented on edge-computing\
    \ devices for real-time water stress monitoring and\nactuation of irrigation systems\
    \ through the internet of things.\nAuthor Contributions: Conceptualization, Y.A.R.\
    \ and N.S.C.; methodology, N.S.C. and M.K.T.;\nsoftware, K.D. and A.S.; validation,\
    \ A.S., K.D., N.S.C. and A.K.C.; resources, Y.A.R.; data curation,\nK.D., M.K.T.\
    \ and A.K.C.; writing—original draft preparation, N.S.C., Y.A.R., and A.K.C.;\
    \ writing—\nreview and editing, A.K.C. and M.K.T. All authors have read and agreed\
    \ to the published version of\nthe manuscript.\nFunding: This research was supported\
    \ by the Indian Council of Agricultural Research-Central\nInstitute of Agricultural\
    \ Engineering Bhopal, India, project# 824.\nData Availability Statement: Data\
    \ will be made available on personalized requests due to restrictions\nfrom the\
    \ parent organization.\nAcknowledgments: The authors would like to thank C.R.\
    \ Mehta and P.S. Tiwari from ICAR-CIAE\nBhopal, for their technical support in\
    \ the conduct of this study.\nConﬂicts of Interest: The authors declare no conﬂict\
    \ of interest.\nAbbreviations\nAbbreviation\nExpanded Form\nAdam\nAdaptive Moment\
    \ Estimation\nAN\nActual Non-Stressed Crop\nANN\nArtiﬁcial Neural Network\nANOVA\n\
    Analysis of Variance\nCIAE\nCentral Institute of Agricultural Engineering\nCNN\n\
    Convolution Neural Network\nDAS\nDay After Sowing\nDCNN\nDeep Convolution Neural\
    \ Network\nDL\nDeep Learning\nPlants 2022, 11, 3344\n18 of 21\nAbbreviation\n\
    Expanded Form\nDL-LSTM\nDeep Learning-Long Short Term Memory\nETc\nEvapotranspiration\n\
    F1\nF1 Score\nICAR\nIndian Council of Agricultural Research\nKNN\nKernel Nearest\
    \ Neighbor\nLR\nLogistic Regression\nLSTM\nLong Short Term Memory\nMAE\nMean Absolute\
    \ Error\nML\nMachine Learning\nP\nPrecision\nPS\nCorrectly Predicted Stressed\
    \ Crop From all the predictions\nRBF\nRadial Basis Function\nRF\nRandom Forest\n\
    RGB\nRed Green Blue\nRH\nRelative Humidity\nRWC\nRelative Water Content\nSD\n\
    Standard Deviation\nSe\nSensitivity\nSgdm\nStochastic Gradient Descent with Momentum\n\
    SMC\nSoil Moisture Content\nS\nSpeciﬁcity\nVM\nSupport Vector Machine\nTa\nAir\
    \ Temperature\nTc\nCanopy Temperature\nTE1\nType 1 Error\nTE2\nType 2 Error\n\
    TN\nTrue Negative\nTS\nTrue Positive\nUAS\nUnmanned Aerial System\nReferences\n\
    1.\nMega, R.; Abe, F.; Kim, J.-S.; Tsuboi, Y.; Tanaka, K.; Kobayashi, H.; Sakata,\
    \ Y.; Hanada, K.; Tsujimoto, H.; Kikuchi, J. Tuning\nWater-Use Efﬁciency and Drought\
    \ Tolerance in Wheat Using Abscisic Acid Receptors. Nat. Plants 2019, 5, 153–159.\
    \ [CrossRef]\n2.\nIhuoma, S.O.; Madramootoo, C.A. Recent Advances in Crop Water\
    \ Stress Detection. Comput. Electron. Agric. 2017, 141, 267–275.\n[CrossRef]\n\
    3.\nSeiﬁkalhor, M.; Niknam, V.; Aliniaeifard, S.; Didaran, F.; Tsaniklidis, G.;\
    \ Fanourakis, D.; Teymoorzadeh, M.; Mousavi, S.H.;\nBosacchi, M.; Li, T. The Regulatory\
    \ Role of γ-Aminobutyric Acid in Chickpea Plants Depends on Drought Tolerance\
    \ and Water\nScarcity Level. Sci. Rep. 2022, 12, 7034. [CrossRef]\n4.\nOletic,\
    \ D.; Bilas, V. How Thirsty the Crops Are: Emerging Instrumentation for Plant-Based\
    \ Field Measurement of Water Stress.\nIEEE Instrum. Meas. Mag. 2020, 23, 37–46.\
    \ [CrossRef]\n5.\nZhang, L.; Niu, Y.; Zhang, H.; Han, W.; Li, G.; Tang, J.; Peng,\
    \ X. Maize Canopy Temperature Extracted from UAV Thermal and\nRGB Imagery and\
    \ Its Application in Water Stress Monitoring. Front. Plant Sci. 2019, 10, 1270.\
    \ [CrossRef]\n6.\nAgam, N.; Cohen, Y.; Berni, J.A.J.; Alchanatis, V.; Kool, D.;\
    \ Dag, A.; Yermiyahu, U.; Ben-Gal, A. An Insight to the Performance of\nCrop Water\
    \ Stress Index for Olive Trees. Agric. Water Manag. 2013, 118, 79–86. [CrossRef]\n\
    7.\nElsayed, S.; Elhoweity, M.; Ibrahim, H.H.; Dewir, Y.H.; Migdadi, H.M.; Schmidhalter,\
    \ U. Thermal Imaging and Passive Reﬂectance\nSensing to Estimate the Water Status\
    \ and Grain Yield of Wheat under Different Irrigation Regimes. Agric. Water Manag.\
    \ 2017, 189,\n98–110. [CrossRef]\n8.\nChandel, A.K.; Khot, L.R.; Osroosh, Y.;\
    \ Peters, T.R. Thermal-RGB Imager Derived in-Field Apple Surface Temperature Estimates\n\
    for Sunburn Management. Agric. For. Meteorol. 2018, 253, 132–140. [CrossRef]\n\
    9.\nChandel, A.K.; Khot, L.R.; Molaei, B.; Peters, R.T.; Stöckle, C.O.; Jacoby,\
    \ P.W. High-Resolution Spatiotemporal Water Use Mapping\nof Surface and Direct-Root-Zone\
    \ Drip-Irrigated Grapevines Using Uas-Based Thermal and Multispectral Remote Sensing.\
    \ Remote\nSens. 2021, 13, 954. [CrossRef]\n10.\nChandel, N.S.; Chakraborty, S.K.;\
    \ Rajwade, Y.A.; Dubey, K.; Tiwari, M.K.; Jat, D. Identifying Crop Water Stress\
    \ Using Deep\nLearning Models. Neural Comput. Appl. 2021, 33, 5353–5367. [CrossRef]\n\
    11.\nTaheri-Garavand, A.; Mumivand, H.; Fanourakis, D.; Fatahi, S.; Taghipour,\
    \ S. An Artiﬁcial Neural Network Approach for\nNon-Invasive Estimation of Essential\
    \ Oil Content and Composition through Considering Drying Processing Factors: A\
    \ Case\nStudy in Mentha Aquatica. Ind. Crops Prod. 2021, 171, 113985. [CrossRef]\n\
    Plants 2022, 11, 3344\n19 of 21\n12.\nSingh, A.K.; Ganapathysubramanian, B.; Sarkar,\
    \ S.; Singh, A. Deep Learning for Plant Stress Phenotyping: Trends and Future\n\
    Perspectives. Trends Plant Sci. 2018, 23, 883–898. [CrossRef]\n13.\nGoldstein,\
    \ A.; Fink, L.; Meitin, A.; Bohadana, S.; Lutenberg, O.; Ravid, G. Applying Machine\
    \ Learning on Sensor Data for\nIrrigation Recommendations: Revealing the Agronomist’s\
    \ Tacit Knowledge. Precis. Agric. 2018, 19, 421–444. [CrossRef]\n14.\nPetrie,\
    \ P.R.; Wang, Y.; Liu, S.; Lam, S.; Whitty, M.A.; Skewes, M.A. The Accuracy and\
    \ Utility of a Low Cost Thermal Camera and\nSmartphone-Based System to Assess\
    \ Grapevine Water Status. Biosyst. Eng. 2019, 179, 126–139. [CrossRef]\n15.\n\
    Subeesh, A.; Bhole, S.; Singh, K.; Chandel, N.S.; Rajwade, Y.A.; Rao, K.V.R.;\
    \ Kumar, S.P.; Jat, D. Deep Convolutional Neural\nNetwork Models for Weed Detection\
    \ in Polyhouse Grown Bell Peppers. Artif. Intell. Agric. 2022, 6, 47–54. [CrossRef]\n\
    16.\nGutiérrez, S.; Diago, M.P.; Fernández-Novales, J.; Tardaguila, J. Vineyard\
    \ Water Status Assessment Using On-the-Go Thermal\nImaging and Machine Learning.\
    \ PLoS ONE 2018, 13, e0192037. [CrossRef]\n17.\nGhosal, S.; Blystone, D.; Singh,\
    \ A.K.; Ganapathysubramanian, B.; Singh, A.; Sarkar, S. An Explainable Deep Machine\
    \ Vision\nFramework for Plant Stress Phenotyping. Proc. Natl. Acad. Sci. USA 2018,\
    \ 115, 4613–4618. [CrossRef]\n18.\nSchmidhuber, J. Deep Learning in Neural Networks:\
    \ An Overview. Neural Netw. 2015, 61, 85–117. [CrossRef]\n19.\nChakraborty, S.K.;\
    \ Chandel, N.S.; Jat, D.; Tiwari, M.K.; Rajwade, Y.A.; Subeesh, A. Deep Learning\
    \ Approaches and Interventions\nfor Futuristic Engineering in Agriculture. Neural\
    \ Comput. Appl. 2022. [CrossRef]\n20.\nYalcin, H. Plant Phenology Recognition\
    \ Using Deep Learning: Deep-Pheno. In Proceedings of the 2017 6th International\n\
    Conference on Agro-Geoinformatics, Fairfax VA, USA, 7–10 August 2017; pp. 1–5.\n\
    21.\nHaider, S.A.; Naqvi, S.R.; Akram, T.; Umar, G.A.; Shahzad, A.; Sial, M.R.;\
    \ Khaliq, S.; Kamran, M. LSTM Neural Network Based\nForecasting Model for Wheat\
    \ Production in Pakistan. Agronomy 2019, 9, 72. [CrossRef]\n22.\nMouatadid, S.;\
    \ Adamowski, J.F.; Tiwari, M.K.; Quilty, J.M. Coupling the Maximum Overlap Discrete\
    \ Wavelet Transform and\nLong Short-Term Memory Networks for Irrigation Flow Forecasting.\
    \ Agric. Water Manag. 2019, 219, 72–85. [CrossRef]\n23.\nYoo, T.-W.; Oh, I.-S.\
    \ Time Series Forecasting of Agricultural Products’ Sales Volumes Based on Seasonal\
    \ Long Short-Term Memory.\nAppl. Sci. 2020, 10, 8169. [CrossRef]\n24.\nArif, S.;\
    \ Kumar, R.; Abbasi, S.; Mohammadani, K.; Dev, K. Weeds Detection and Classiﬁcation\
    \ Using Convolutional Long-Short-Term\nMemory; Research Square: Durham, NC, USA,\
    \ 2021.\n25.\nZhuang, S.; Wang, P.; Jiang, B.; Li, M.; Gong, Z. Early Detection\
    \ of Water Stress in Maize Based on Digital Images. Comput. Electron.\nAgric.\
    \ 2017, 140, 461–468. [CrossRef]\n26.\nAn, J.; Li, W.; Li, M.; Cui, S.; Yue, H.\
    \ Identiﬁcation and Classiﬁcation of Maize Drought Stress Using Deep Convolutional\
    \ Neural\nNetwork. Symmetry 2019, 11, 256. [CrossRef]\n27.\nNiu, Y.; Zhang, H.;\
    \ Han, W.; Zhang, L.; Chen, H. A Fixed-Threshold Method for Estimating Fractional\
    \ Vegetation Cover of Maize\nunder Different Levels of Water Stress. Remote Sens.\
    \ 2021, 13, 1009. [CrossRef]\n28.\nBiju, S.; Fuentes, S.; Gupta, D. The Use of\
    \ Infrared Thermal Imaging as a Non-Destructive Screening Tool for Identifying\n\
    Drought-Tolerant Lentil Genotypes. Plant Physiol. Biochem. 2018, 127, 11–24. [CrossRef]\n\
    29.\nChandel, A.K.; Khot, L.R.; Yu, L.-X. Alfalfa (Medicago Sativa L.) Crop Vigor\
    \ and Yield Characterization Using High-Resolution\nAerial Multispectral and Thermal\
    \ Infrared Imaging Technique. Comput. Electron. Agric. 2021, 182, 105999. [CrossRef]\n\
    30.\nPrashar, A.; Jones, H.G. Infra-Red Thermography as a High-Throughput Tool\
    \ for Field Phenotyping. Agronomy 2014, 4, 397–417.\n[CrossRef]\n31.\nAllen, R.G.;\
    \ Pereira, L.S.; Raes, D.; Smith, M. Crop Evapotranspiration-Guidelines for Computing\
    \ Crop Water Requirements-FAO\nIrrigation and Drainage Paper 56. FAO: Rome, Italy,\
    \ 1998; Volume 300, p. D05109.\n32.\nGoogle Experimental Layout of Winter Wheat\
    \ Crop at Different Rates Using Sprinkler and Flood Irrigation. 2022. Available\n\
    online: https://www.google.com/maps/ (accessed on 8 October 2022).\n33.\nPanigrahi,\
    \ N.; Das, B.S. Canopy Spectral Reﬂectance as a Predictor of Soil Water Potential\
    \ in Rice. Water Resour. Res. 2018, 54,\n2544–2560. [CrossRef]\n34.\nGomez, K.A.;\
    \ Gomez, A.A. Statistical Procedures for Agricultural Research; John Wiley & Sons:\
    \ Hoboken, NJ, USA, 1984; ISBN\n978-0-471-87092-0.\n35.\nTürko˘glu, M.; Hanbay,\
    \ D. Plant Disease and Pest Detection Using Deep Learning-Based Features. Turk.\
    \ J. Electr. Eng. Comput. Sci.\n2019, 27, 1636–1651. [CrossRef]\n36.\nHendrawan,\
    \ Y.; Damayanti, R.; Al Riza, D.F.; Hermanto, M.B. Classiﬁcation of Water Stress\
    \ in Cultured Sunagoke Moss Using\nDeep Learning. TELKOMNIKA (Telecommun. Comput.\
    \ Electron. Control) 2021, 19, 1594–1604. [CrossRef]\n37.\nEsgario, J.G.; Krohling,\
    \ R.A.; Ventura, J.A. Deep Learning for Classiﬁcation and Severity Estimation\
    \ of Coffee Leaf Biotic Stress.\nComput. Electron. Agric. 2020, 169, 105162. [CrossRef]\n\
    38.\nFulton, L.V.; Dolezel, D.; Harrop, J.; Yan, Y.; Fulton, C.P. Classiﬁcation\
    \ of Alzheimer’s Disease with and without Imagery Using\nGradient Boosted Machines\
    \ and ResNet-50. Brain Sci. 2019, 9, 212. [CrossRef]\n39.\nTurkoglu, M.; Hanbay,\
    \ D.; Sengur, A. Multi-Model LSTM-Based Convolutional Neural Networks for Detection\
    \ of Apple Diseases\nand Pests. J Ambient Intell Hum. Comput 2022, 13, 3335–3345.\
    \ [CrossRef]\n40.\nKandel, I.; Castelli, M. The Effect of Batch Size on the Generalizability\
    \ of the Convolutional Neural Networks on a Histopathology\nDataset. ICT Express\
    \ 2020, 6, 312–315. [CrossRef]\n41.\nBlum, A.; Shpiler, L.; Golan, G.; Mayer,\
    \ J. Yield Stability and Canopy Temperature of Wheat Genotypes under Drought-Stress.\n\
    Field Crops Res. 1989, 22, 289–296. [CrossRef]\nPlants 2022, 11, 3344\n20 of 21\n\
    42.\nRashid, A.; Stark, J.C.; Tanveer, A.; Mustafa, T. Use of Canopy Temperature\
    \ Measurements as a Screening Tool for Drought\nTolerance in Spring Wheat. J.\
    \ Agron. Crop Sci. 1999, 182, 231–238. [CrossRef]\n43.\nDeJonge, K.C.; Taghvaeian,\
    \ S.; Trout, T.J.; Comas, L.H. Comparison of Canopy Temperature-Based Water Stress\
    \ Indices for Maize.\nAgric. Water Manag. 2015, 156, 51–62. [CrossRef]\n44.\n\
    Olsovska, K.; Kovar, M.; Brestic, M.; Zivcak, M.; Slamka, P.; Shao, H.B. Genotypically\
    \ Identifying Wheat Mesophyll Conductance\nRegulation under Progressive Drought\
    \ Stress. Front. Plant Sci. 2016, 7, 1111. [CrossRef]\n45.\nLaxa, M.; Liebthal,\
    \ M.; Telman, W.; Chibani, K.; Dietz, K.-J. The Role of the Plant Antioxidant\
    \ System in Drought Tolerance.\nAntioxidants 2019, 8, 94. [CrossRef]\n46.\nWang,\
    \ X.; Vignjevic, M.; Jiang, D.; Jacobsen, S.; Wollenweber, B. Improved Tolerance\
    \ to Drought Stress after Anthesis Due to\nPriming before Anthesis in Wheat (Triticum\
    \ Aestivum L.) Var. Vinjett. J. Exp. Bot. 2014, 65, 6441–6456. [CrossRef]\n47.\n\
    Kukanov, I.; Hautamäki, V.; Lee, K.A. Recurrent Neural Network and Maximal Figure\
    \ of Merit for Acoustic Event Detection.\nIn Proceedings of the Proceedings of\
    \ the Workshop on Detection and Classiﬁcation of Acoustic Scenes and Events, Munich,\n\
    Germany, 16–17 November 2017.\n48.\nCastro-Zunti, R.; Park, E.H.; Choi, Y.; Jin,\
    \ G.Y.; Ko, S. Early Detection of Ankylosing Spondylitis Using Texture Features\
    \ and\nStatistical Machine Learning, and Deep Learning, with Some Patient Age\
    \ Analysis. Comput. Med. Imaging Graph. 2020, 82, 101718.\n[CrossRef]\n49.\nFan,\
    \ Y.; Bai, J.; Lei, X.; Zhang, Y.; Zhang, B.; Li, K.-C.; Tan, G. Privacy Preserving\
    \ Based Logistic Regression on Big Data. J. Netw.\nComput. Appl. 2020, 171, 102769.\
    \ [CrossRef]\n50.\nRehman, T.U.; Mahmud, M.S.; Chang, Y.K.; Jin, J.; Shin, J.\
    \ Current and Future Applications of Statistical Machine Learning\nAlgorithms\
    \ for Agricultural Machine Vision Systems. Comput. Electron. Agric. 2019, 156,\
    \ 585–605. [CrossRef]\n51.\nZhang, J.; Zhu, Y.; Zhang, X.; Ye, M.; Yang, J. Developing\
    \ a Long Short-Term Memory (LSTM) Based Model for Predicting Water\nTable Depth\
    \ in Agricultural Areas. J. Hydrol. 2018, 561, 918–929. [CrossRef]\n52.\nFanourakis,\
    \ D.; Aliniaeifard, S.; Sellin, A.; Giday, H.; Körner, O.; Nejad, A.R.; Delis,\
    \ C.; Bouranis, D.; Koubouris, G.;\nKambourakis, E. Stomatal Behavior Following\
    \ Mid-or Long-Term Exposure to High Relative Air Humidity: A Review. Plant\nPhysiol.\
    \ Biochem. 2020, 153, 92–105. [CrossRef]\n53.\nZhang, W.-Z.; Han, Y.-D.; Du, H.-J.\
    \ Relationship between Canopy Temperature at Flowering Stage and Soil Water Content,\
    \ Yield\nComponents in Rice. Rice Sci. 2007, 14, 67–70. [CrossRef]\n54.\nCavero,\
    \ J.; Medina, E.T.; Puig, M.; Martínez-Cob, A. Sprinkler Irrigation Changes Maize\
    \ Canopy Microclimate and Crop Water\nStatus, Transpiration, and Temperature.\
    \ Agron. J. 2009, 101, 854–864. [CrossRef]\n55.\nHome, P.G.; Panda, R.K.; Kar,\
    \ S. Effect of Method and Scheduling of Irrigation on Water and Nitrogen Use Efﬁciencies\
    \ of Okra\n(Abelmoschus Esculentus). Agric. Water Manag. 2002, 55, 159–170. [CrossRef]\n\
    56.\nWang, P.; Song, X.; Han, D.; Zhang, Y.; Zhang, B. Determination of Evaporation,\
    \ Transpiration and Deep Percolation of Summer\nCorn and Winter Wheat after Irrigation.\
    \ Agric. Water Manag. 2012, 105, 32–37. [CrossRef]\n57.\nChandel, N.S.; Rajwade,\
    \ Y.A.; Golhani, K.; Tiwari, P.S.; Dubey, K.; Jat, D. Canopy Spectral Reﬂectance\
    \ for Crop Water Stress\nAssessment in Wheat (Triticum Aestivum, L.). Irrig. Drain.\
    \ 2021, 70, 321–331. [CrossRef]\n58.\nGupta, N.K.; Gupta, S.; Kumar, A. Effect\
    \ of Water Stress on Physiological Attributes and Their Relationship with Growth\
    \ and\nYield of Wheat Cultivars at Different Stages. J. Agron. Crop Sci. 2001,\
    \ 186, 55–62. [CrossRef]\n59.\nYousefzadeh, K.; Houshmand, S.; Shiran, B.; Mousavi-Fard,\
    \ S.; Zeinali, H.; Nikoloudakis, N.; Gheisari, M.M.; Fanourakis, D.\nJoint Effects\
    \ of Developmental Stage and Water Deﬁcit on Essential Oil Traits (Content, Yield,\
    \ Composition) and Related Gene\nExpression: A Case Study in Two Thymus Species.\
    \ Agronomy 2022, 12, 1008. [CrossRef]\n60.\nOsakabe, Y.; Osakabe, K.; Shinozaki,\
    \ K.; Tran, L.-S. Response of Plants to Water Stress. Front. Plant Sci. 2014,\
    \ 5, 86. [CrossRef]\n61.\nNasiri, A.; Taheri-Garavand, A.; Fanourakis, D.; Zhang,\
    \ Y.-D.; Nikoloudakis, N. Automated Grapevine Cultivar Identiﬁcation via\nLeaf\
    \ Imaging and Deep Convolutional Neural Networks: A Proof-of-Concept Study Employing\
    \ Primary Iranian Varieties. Plants\n2021, 10, 1628. [CrossRef]\n62.\nTaheri-Garavand,\
    \ A.; Rezaei Nejad, A.; Fanourakis, D.; Fatahi, S.; Ahmadi Majd, M. Employment\
    \ of Artiﬁcial Neural Networks\nfor Non-Invasive Estimation of Leaf Water Status\
    \ Using Color Features: A Case Study in Spathiphyllum Wallisii. Acta Physiol.\n\
    Plant. 2021, 43, 78. [CrossRef]\n63.\nZomorrodi, N.; Rezaei Nejad, A.; Mousavi-Fard,\
    \ S.; Feizi, H.; Tsaniklidis, G.; Fanourakis, D. Potency of Titanium Dioxide\n\
    Nanoparticles, Sodium Hydrogen Sulﬁde and Salicylic Acid in Ameliorating the Depressive\
    \ Effects of Water Deﬁcit on Periwinkle\nOrnamental Quality. Horticulturae 2022,\
    \ 8, 675. [CrossRef]\n64.\nGrbovic, Z.; Panic, M.; Marko, O.; Brdar, S.; Crnojevic,\
    \ V. Wheat Ear Detection in RGB and Thermal Images Using Deep Neural\nNetworks.\
    \ Environments 2019, 11, 13.\n65.\nde Melo, L.L.; de Melo, V.G.M.L.; Marques,\
    \ P.A.A.; Frizzone, J.A.; Coelho, R.D.; Romero, R.A.F.; Barros, T.H. da S. Deep\
    \ Learning\nfor Identiﬁcation of Water Deﬁcits in Sugarcane Based on Thermal Images.\
    \ Agric. Water Manag. 2022, 272, 107820. [CrossRef]\n66.\nMhapsekar, M.; Mhapsekar,\
    \ P.; Mhatre, A.; Sawant, V. Implementation of Residual Network (ResNet) for Devanagari\
    \ Handwritten\nCharacter Recognition. In Advanced Computing Technologies and Applications;\
    \ Springer: Berlin/Heidelberg, Germany, 2020;\npp. 137–148.\n67.\nWang, F.; Qiu,\
    \ J.; Wang, Z.; Li, W. Intelligent Recognition of Surface Defects of Parts by\
    \ Resnet. J. Phys. Conf. Ser. 2021, 1883, 012178.\n[CrossRef]\nPlants 2022, 11,\
    \ 3344\n21 of 21\n68.\nZhuang, S.; Wang, P.; Jiang, B.; Li, M. Learned Features\
    \ of Leaf Phenotype to Monitor Maize Water Status in the Fields. Comput.\nElectron.\
    \ Agric. 2020, 172, 105347. [CrossRef]\n69.\nArchontoulis, S.V.; Miguez, F.E.\
    \ Nonlinear Regression Models and Applications in Agricultural Research. Agron.\
    \ J. 2015, 107,\n786–798. [CrossRef]\n70.\nWijaya, D.R.; Sarno, R.; Zulaika, E.\
    \ DWTLSTM for Electronic Nose Signal Processing in Beef Quality Monitoring. Sens.\
    \ Actuators\nB Chem. 2021, 326, 128931. [CrossRef]\n"
  inline_citation: '>'
  journal: Plants
  limitations: '>'
  pdf_link: https://www.mdpi.com/2223-7747/11/23/3344/pdf?version=1669960246
  publication_year: 2022
  relevance_score: 0.9
  relevance_score1: 0
  relevance_score2: 0
  title: Water Stress Identification of Winter Wheat Crop with State-of-the-Art AI
    Techniques and High-Resolution Thermal-RGB Imagery
  verbatim_quote1: '"Among the feature extraction-based models, ResNet50 outperformed
    other models showing a discriminant accuracy of 96.9% with RGB and 98.4% with
    thermal imagery inputs."'
  verbatim_quote2: '"Overall, classiﬁcation accuracy was higher for thermal imagery
    compared to RGB imagery inputs. The DL-LSTM had the highest discriminant accuracy
    of 96.7% and less error among the function approximation-based models for classifying
    stress/non-stress."'
  verbatim_quote3: '>'

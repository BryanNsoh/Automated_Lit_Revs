- DOI: https://doi.org/10.1016/j.jhydrol.2011.11.054
  analysis: 'The paper by Huo et al. (2011) presents a novel approach to streamflow
    estimation in arid inland basins. Their integrated artificial neural network (ANN)
    model explicitly considers the spatial variations in rainfall and catchment heterogeneity,
    which are often neglected in traditional lumped ANN models. This leads to improved
    streamflow estimates, particularly in basins with significant spatial variability
    in hydrological processes.


    To assess the performance of the integrated ANN model, the authors compare it
    to a lumped ANN model and a local linear regression (LLR) model on a dataset from
    the Shiyang River Basin in Northwest China. The integrated ANN model outperforms
    both the lumped ANN and LLR models in terms of root mean square error (RMSE),
    relative error (RE), and coefficient of determination (R2). The authors also conduct
    a sensitivity analysis to determine the optimal number of hidden nodes in the
    ANN models. The results of this study suggest that the integrated ANN model is
    a promising tool for streamflow estimation in arid inland basins.'
  authors:
  - Zailin Huo
  - Shuyi Feng
  - Shaozhong Kang
  - Guanhua Huang
  - Fengxin Wang
  - Ping Guo
  citation_count: 47
  full_citation: Zailin Huo, Shaoyuan Feng, Shaozhong Kang, Guanhua Huang, Fengxin
    Wang, Ping Guo Integrated neural networks for monthly river flow estimation in
    arid inland basin of Northwest China Journal of Hydrology, Volume 420–421, 14
    February 2012, Pages 159-170 https://doi.org/10.1016/j.jhydrol.2011.11.054
  full_text: '>

    Skip to main content Skip to article Journals & Books Search Register Sign in
    Brought to you by: University of Nebraska-Lincoln View PDF Download full issue
    Outline Abstract Keywords 1. Introduction 2. Materials and methods 3. Integrated
    ANN model for monthly streamflow 4. Result analysis and discussion 5. Conclusions
    Acknowledgements References Show full outline Cited by (55) Figures (11) Show
    5 more figures Tables (9) Table 1 Table 2 Table 3 Table 4 Table 5 Table 6 Show
    all tables Journal of Hydrology Volumes 420–421, 14 February 2012, Pages 159-170
    Integrated neural networks for monthly river flow estimation in arid inland basin
    of Northwest China Author links open overlay panel Zailin Huo a, Shaoyuan Feng
    a b, Shaozhong Kang a, Guanhua Huang a, Fengxin Wang a, Ping Guo a Show more Add
    to Mendeley Share Cite https://doi.org/10.1016/j.jhydrol.2011.11.054 Get rights
    and content Abstract Streamflow model including rainfall–runoff and river flow
    models play an important role in water resources management, especially in arid
    inland area. Traditional conceptual models have the disadvantage of requirement
    of spatial variation parameters about the physical characteristics of the catchments.
    To overcome this difficulty, in this study, several integrated Artificial Neural
    Networks (ANNs) were presented to estimate monthly river flow, and the models
    include the semi-distributed forms of ANNs that can explore spatial variation
    in hydrological process (such as rainfall distribution and evaporation distribution)
    and no requirement of physical characteristic parameters of the catchments. In
    an arid inland basin of Northwest, integrated ANNs were developed using hydrological
    and agricultural data, and its performance was compared with that of lumped ANN
    and local linear regression model (LLR). Results showed that the integrated ANNs
    perform well to estimate the monthly streamflow at outlet of mountain with Root
    Mean Square Error (RMSE) of 0.36 × 107 m3 and Relative Error (RE) of 9%. Similarly,
    the integrated ANNs can also accurately estimate the monthly river flow downstream
    of the basin with RMSE of 0.35–0.38 × 107 m3 and RE of 22–27%. When compared with
    integrated ANNs, the lumped ANN and LLR models have lower precision to simulate
    monthly streamflow in arid inland basin. Presented integrated ANN models retain
    the advantages of the semi-distributed models considering the heterogeneity and
    spatial variation of hydrological factors and the physical characteristics in
    the catchment, while taking advantage of the potential of ANNs as an effective
    tool in nonlinear mapping or functional relationship establishment. In contrast
    to traditional models either in the lumped ANN or in empirical regression forms,
    the new approach of integration of Artificial Neural Networks has shown great
    potential in streamflow modeling. Highlights ► Integrated ANNs were present to
    estimate monthly river flow and the models. ► Integrated ANNs can explore spatial
    variation in rainfall and evaporation distribution. ► Integrated ANNs’ performance
    was compared with that of lumped ANN and local linear regression model. ► Integrated
    ANNs perform well to estimate the monthly streamflow than other models. Previous
    article in issue Next article in issue Keywords Artificial Neural NetworkRiver
    flowSimulationNorthwest China 1. Introduction Streamflow model including rainfall–runoff
    and river flow models plays an important role in water resources management. Especially
    in arid regions where water resources are scarce, streamflow simulations are useful
    to water resources’ temporal and spatial plan and distributions. To address this,
    different types of models with various degrees of complexity have been developed.
    Recently, hydrologists have endeavored to better understand the streamflow transformation
    process and many conceptual models had been developed, such as the Xinanjiang
    Model (Zhao and Liu, 1995), the Soil Moisture Accounting and Routing (SMAR) Model
    (Tan and Connor, 1996), and the Tank Model (Sugawara, 1995). However, the rainfall–runoff
    transformation is one of the most complex hydrological phenomena to comprehend,
    as it usually involves a number of interconnected elements, such as evapotranspiration,
    infiltration, surface and subsurface runoff generation and routing. It is hard
    to accurately describe rainfall–runoff in a catchment. In fact, the streamflow
    process is further complicated as heterogeneity of the catchment geomorphological
    characteristics (such as soil type and vegetation cover) and the spatial and temporal
    variations of model’s inputs (such as rainfall patterns). For further improving
    the performance of rainfall–runoff, a lot of recent researches focus on the distributed
    hydrological model (Schumann et al., 2000), such as Soil and Water Assessment
    Tool (SWAT) model. However, the distributed hydrological model need a number of
    catchment parameters, such as soil type and vegetation cover, and generally these
    data are hard to be observed. Although some optimized techniques, such as genetic
    algorithm (GA) and fuzzy optimal model (FOM), were used to calibrate the model
    (Cheng et al., 2002), and web-based flood forecasting system has been attempted
    (Li et al., 2006), the distributed hydrological model is not convenient to use
    widely. Artificial Neural Networks (ANNs) are flexible mathematical structures,
    which are capable of identifying complex nonlinear relationships between input
    and output data. A comparison between model performances was made by Hsu et al.
    (1995) using daily time steps. They concluded that ANN could better simulate the
    rainfall–runoff relationship on a river basin in Mississippi, USA, when compared
    to a conceptual model and a linear autoregressive moving average with exogenous
    inputs (ARMAX) model. ANNs have been compared to other methods including genetic
    algorithm (GA), support vector machine (SVM), fuzzy logic (FL), and linear transfer
    function (LTF) for river flow simulation and obtained better performance (Wang
    et al., 2009, Lohani et al., 2011, Lin et al., 2006). The recent decade has seen
    a tremendous growth in the interest of application of ANNs in streamflow modeling
    (Kumar and Minocha, 2001; Tokar and Markus, 2000, Sajikumar and Thandaveswara,
    1999, Zhang and Govindaraju, 2003). Some researches had been conducted to improve
    ANNs’ performance, such as the data-preprocessing techniques of singular spectrum
    analysis (SSA) and moving average (MA) (Wu et al., 2009), and particle swarm optimization
    techniques (PSO) for ANNs’ training (Chau, 2006). ANNs had also been used to predict
    further long-term streamflows (Gao et al., 2010). However, most of the ANN models
    for streamflow process reported in literature used a total rainfall value over
    the catchments in the input vector, that is, a single ANN was used to simulate
    hydrological processes for a catchment. Similar to traditional conceptual hydrological
    model, present ANN models cannot reflect the effect of heterogeneity of the catchment’s
    geomorphological characteristics on hydrological processes. Furthermore, the ANN
    and conceptual models have been combined to estimate the river flow (Ashu and
    Sanaga, 2006, Corzo et al., 2009, Chen and Adams, 2006, Kamp and Savenijie, 2007,
    Jeong and Kim, 2005, Nilsson et al., 2006). These models combining conceptual
    hydrological models and ANN models usually include two parts, a conceptual model
    for streamflow of every sub-catchment and an ANN model to ensemble the streamflow
    from each catchment. In fact, these combined distributed hydrological models have
    not avoided the requirement of parameters for conceptual hydrological model for
    every sub-catchment. In addition, overall, traditional conceptual models have
    the disadvantage of requirement of spatial variation parameters about the physical
    characteristics of the catchments, and a single ANN cannot reflect the spatial
    variations of hydrometeorological factors and geomorphological characteristics.
    Thus, a kind of integrated ANN model is a better method to overcome these faults
    for hydrological process simulation over a catchment. The integrated ANN model
    will model flow for every sub-catchment and does not require physical characteristic
    parameters of the catchments. The objectives of the present study are (i) to propose
    an integrated ANN model to estimate streamflow; (ii) to perform a case study and
    compare the performance of the integrated ANNs with that of single ANN and of
    local linear regression (LLR) models to estimate monthly streamflow. 2. Materials
    and methods 2.1. Study area The Shiyang River Basin, one of three continental
    rivers in the Hexi corridor, located in the eastern portion of the corridor in
    Gansu Province of Northwest China was selected as the study area. The basin encompasses
    an area of 4.16 × 104 km2 with a population of 2.2 million and covers the area
    between 101°41′–104°16′E and 36°29′–39°27′N (Fig. 1). The Shiyang River Basin
    includes three climate zones (Kang et al., 2004). The Qilian Mountain in the south
    of the basin comprises a very frigid, semiarid humid area. The middle part of
    the basin is the Wuwei sub-basin, cool and arid. The northern part of the basin,
    also called the Minqin sub-basin, is warmer and more arid. The Shiyang River starts
    from the north of the Qilian Mountains and includes eight tributaries, but only
    five tributaries (the Zamu, Gulang, Huangyang, Jinta, and Xiying) converge as
    the Shiyang River in the outlet of the Qilian Mountains, and then flow into the
    Hongyashan reservoir in the Minqin oasis, the largest desert reservoir in Asia
    (Fig. 1). Characteristics of five catchments in the Shiyang River Basin and proportion
    of major land use in the five catchments of the Shiyang River Basin in 2000 were
    presented in Tables 1 and 2, respectively. The five tributaries are mainly fed
    by rainfall, snowmelt, and glacier melt from the Qilian Mountain. In summary,
    all streamflows have steadily decreased, particularly the inflow into the Hongyashan
    reservoir, as climate changes and water-related human activities such as irrigation
    using river flow have increased in recent years. Download : Download full-size
    image Fig. 1. Study area and the hydrological station location map. Table 1. Characteristics
    of five catchments in the Shiyang River Basin. Catchment Area (km2) Streamflow
    (108 m3) Precipitation (mm) ET (mm) Elevation (m) Slope (%) Xiying 1455 3.6 520
    800 3335 32 Jinta 841 1.3 460 860 2982 22.2 Zamu 851 2.3 559 781 3482 31.6 Huangyang
    828 1.3 482 843 2997 22 Gulang 878 0.6 470 866 2876 18.1 Table 2. Proportion of
    major land use in the eight catchments of the Shiyang River Basin in 2000 (Ma
    et al., 2008). Catchments Crop (%) Forest (%) Pasture (%) Residential area (%)
    Bare soil (%) Xiying 1.61 26.24 53.78 0.15 17.32 Jinta 14.11 15.25 56.83 0.07
    13.68 Zamu 1.20 33.65 47.74 0.04 17.36 Huangyang 25.83 28.39 35.98 0.86 7.64 Gulang
    35.69 33.82 27.72 1.06 1.61 2.2. Data sets As the climate differences are significant
    over space within the Shiyang River Basin, data including monthly total precipitation,
    monthly average maximum air temperature and minimum air temperature, relative
    humidity, sunshine hours, wind speed for the period of 1956–2003 from 15 weather
    stations located within the basin and the surrounding areas were selected. Potential
    evapotranspiration (ET) was calculated using the Penman–Monteith equation recommended
    by Food and Agriculture Organization (FAO) (Allen et al., 1998). Linear regression
    relationship between monthly precipitation and catchments’ characteristics such
    as elevation, latitude, and longitude was developed. Similar relationships were
    also developed for monthly potential evapotranspiration. A digital elevation model
    (DEM) with grid resolution 100 m × 100 m supplied by Western Eco-environmental
    Data Center of National Natural Science Foundation of China (WEDC-NSFC) was used
    to interpolate monthly precipitation and ET according to elevation, latitude,
    and longitude. Then, average monthly precipitation and ET for every tributary
    and downstream of the basin can be calculated in Geographic Information System
    (GIS) (Ma et al., 2008). Previous researches have showed that average annual precipitation
    varied between 513 and 660 mm during 1950–1975 and decreased to 441 and 557 mm
    during 1975–2005. Average potential evapotranspiration showed an increasing trend
    over the two periods (Ma et al., 2008, Huo et al., 2008). It is clear that these
    changes in precipitation and potential evapotranspiration would lead to reduction
    in streamflow. Monthly streamflow time series from 1956 to 2003 for five tributaries
    and downstream of the basin was used in this study. The streamflow data for the
    five tributaries are from observation stations at mountain outlets. Flow data
    downstream of Shiyang River were measured at the Caiqi station (Fig. 1). Flows
    for both the tributaries and the Shiyang River exhibit decreasing tendencies.
    The total flow in mountain outlets varied from 12.1 × 108 m3 in 1950s to 9.2 ×
    108 m3 in 1970s and 8.2 × 108 m3 in 1990s. Similarly, observation data show that
    annual streamflow at Caiqi station has decreased from 5.4 × 108 m3 in 1950s to
    3.2 × 108 m3 in 1970s and 1.1 × 108 m3 in 1990s (Fig. 2). In addition, irrigation
    area and irrigation water ratio for unit area was collected to estimate the effect
    of agricultural activities on streamflow. Download : Download full-size image
    Fig. 2. Total streamflow of five tributaries and river flow at Caiqi station downstream
    of the Shiyang River from 1956 to 2003. 2.3. ANN technology The ANNs are mathematical
    models that attempt to exploit the massively parallel local processing and the
    distributed storage properties believed to exist in the human brain. In recent
    decades, the ANN technique, also called parallel distributed processing, has received
    a great deal of attention as a tool of computation by many researchers and scientists.
    There are many kinds of ANNs, and the most common learning rule for ANNs is the
    back propagation algorithm. Back propagation involves two phases, a feed-forward
    phase in which the external input information at the input nodes is propagated
    forward to compute the output information signal at the output unit, and a backward
    phase in which modifications to the connection strengths are made based on the
    differences between the computed and observed information signals at the output
    units (Rumelhart et al., 1986). There are several parameters including numbers
    of hidden layers and hidden nodes, and learning rate for ANN architecture and
    training. Theoretically, the numbers of hidden layers and hidden nodes in a neural
    network can be unlimited. However, as pointed out by Funahashi (1989) and Hornik
    et al. (1989), an ANN with a single hidden layer containing a sufficient number
    of nodes can approximate any functional relationships to any degree of accuracy.
    Therefore, ANNs designed with three layers, including only one hidden layer, are
    usually preferred in practical applications. So, the neural network structure
    in this study possessed a three-layer learning network consisting of an input
    layer, a hidden layer and an output layer. Furthermore, trial-and-error experiments
    can be performed to determine the optimal nodes of hidden layer by starting with
    a few hidden layer nodes and comparing validation error when the number of hidden
    layers and nodes are gradually increased. The procedure of adding hidden nodes
    is repeated and network training is restarted until the validation error is observed
    to bottom out and start increasing. Usually, every input and output of ANN does
    not belong to the same dimension, and all inputs and outputs need to be normalized
    to the same dimension, which mean that all input and output values are within
    the same scope. In this study, the input and output data were normalized in the
    range from 0.1 to 0.9. From the input layer to the hidden layer, the log sigmoid
    function has been commonly used in hydrological ANN models. From the hidden layer
    to the output layer, a linear function was employed as the transfer function as
    other studies. In the present study, the scaled conjugate gradient method (SCGM)
    proposed by Moler (1993) is employed. Learning rate can be adjusted automatically
    according to error of ANN when trained, and effect of initial learning rate on
    ANN training is little. So, this technique is more powerful than the conventional
    gradient descent techniques (Cigizogilu, 2005) and had been used to training ANNs
    for river flow model (Turan and Yurdusev, 2009). The scaled conjugate gradient
    method, an efficient second-order learning algorithm, is somewhat intermediate
    between the steepest descent method and Newton’s method. It accelerates the typically
    slow convergence associated with the steepest descent, while maintaining calculation
    simplicity by avoiding the requirements associated with the evaluation, the storage,
    and the inversion of the Hessian matrix in the Newton’s method (Liu et al., 2005).
    Its advantages are the increased learning speed (since it avoids the line search)
    and the fact that it eliminates the dependence on critical user-selected parameters
    (Learning rate, Momentum Coefficient) (Falas and Stafylopatis, 2005). The detailed
    calculating process of the SCGM can be found in literature Moler (1993). 2.4.
    Local linear regression (LLR) model The local linear regression model is a popular
    nonparametric regression technique that has been widely used in many low-dimensional
    forecasting and smoothing problems (Remesan et al., 2009). Reliable modeling even
    on a small amount of sample data and accurate predictions in regions of high data
    density in the input space are considered as the major advantages of LLR models.
    The LLR procedure requires only three data points to obtain an initial prediction
    and then uses all newly updated data in the order they are available to make further
    predictions. Deciding the size of pmax, (the number of near neighbors to be included
    for the local linear modeling) is the tricky part in LLR modeling. Given a neighborhood
    of pmax points, we must solve a linear matrix equation, (1) where X is a pmax
    × d matrix of the pmax input points in d-dimensions, xi (1 ⩽ i ⩽ pmax) are the
    nearest neighbor points, y is a column vector of length pmax of the corresponding
    outputs, and m is a column vector of parameters that must be determined to provide
    the optimal mapping from X to y. If the matrix X is square and not singular, then
    a unique solution to equation is m = X−1y. If X is not square or singular, we
    should find a vector m that minimizes (2) where the unique solution to this problem
    is provided by m = Xy where X is a pseudo-inverse matrix. 3. Integrated ANN model
    for monthly streamflow 3.1. Schematic diagram of the integration of ANNs In the
    development of the lumped ANN models, the spatial variations of model parameters
    and model inputs are not explicitly considered in the modeling process. However,
    spatial variations in rainfall and catchment heterogeneity are common in nature
    and can be significant factors affecting the overall model performance. Traditionally,
    the river flow for an inland basin can be estimated by combining two ANNs, namely
    lumped ANN (Fig. 3). One ANN is to estimate total streamflow at outlet of mountain
    using weather data upstream of the basin, and another is to estimate the river
    flow downstream of the basin using output of first ANN, weather data, and human
    activity data. In this lumped ANN, precipitation and evaporation for every tributary
    are respectively averaged to one value and as the inputs of first ANN. In other
    words, the heterogeneity and spatial variation of the rainfall, evaporation, and
    land cover are not considered in the lumped ANN. Download : Download full-size
    image Fig. 3. Structure of lumped ANN model (LANN). To overcome this deficiency,
    two integrated forms of the ANN models are proposed in this study. These integrated
    forms of ANNs retain the advantages of the semi-distributed models considering
    the heterogeneity and spatial variation of the rainfall in the catchment, while
    taking advantage of the potential of ANNs as an effective tool in nonlinear mapping
    or functional relationship establishment. Flowcharts of the two integrated ANNs
    are illustrated in Figs. 4 and 5. As shown in the figures, similar to the lumped
    ANN, the integrated ANNs contain two parts. The first part is the distributed
    form with several ANNs for sub-catchments, and the second part is a single ANN
    for middle stream. The development of a distributed form of ANNs is intended to
    reflect the spatial variations of rainfall, evapotranspiration, and the heterogeneity
    of the catchment characteristics across the catchment. As indicated in Figs. 4
    and 5, the entire catchment is divided into five sub-catchments based on the characteristics
    of the catchment as illustrated in Fig. 1, and five ANNs were developed to simulate
    streamflow from the five sub-catchments respectively. Download : Download full-size
    image Fig. 4. Structure of integrated ANN model (IANN1, streamflow from tributaries
    are summed as one input of second part). Download : Download full-size image Fig.
    5. Structure of integrated ANN model (IANN2, streamflow from tributaries are respectively
    inputs of second part). There are two methods to develop a single ANN for streamflow
    downstream of the basin. For the first model (IANN1), the outputs of five ANNs
    were added up as the inputs of ANN for flow downstream (Fig. 4). For another (IANN2),
    the outputs of five ANNs for streamflow of tributaries were used respectively
    as the inputs of ANN for streamflow downstream (Fig. 5). Similar to the lumped
    ANN, the inputs of ANN in the second part include weather and water-related human
    activity data besides streamflow from tributaries. 3.2. Training and testing integrated
    ANN model for monthly streamflow An important issue in the ANN modeling is the
    choice of input variables, but there is no general theory yet to solve this issue,
    and it is still a problem. According to the hydrological processes in sub-catchments,
    the five tributaries are mainly fed by rainfall, snowmelt, and glacier melt from
    the Qilian Mountain. Snowmelt and glacier are determined by some meteorological
    factors such as temperature and wind speed. In addition, soil moisture over the
    catchment also affects the rainfall–runoff processes and correlates with evapotranspiration.
    So, input variables used for these monthly streamflow models are the previous
    and current month’s precipitation and evapotranspiration calculated by Peman–Motieth
    equation, and using the current month’s streamflow as the target variable. However,
    in the middle stream of the catchments, the Wuwei Basin, river flows were affected
    by human activities, especially agricultural production activities, besides climate
    conditions. As a result, input variables used for monthly streamflow model are
    current monthly streamflow from tributaries, the previous and current month’s
    precipitation and evaporation, irrigation area, and irrigation ratio of unit area.
    Cross-correlation analysis between the target streamflow Q(t) and different lag
    time series of precipitation and ET data (viz P(t), P(t − 1), P(t − 2), P(t −
    3), P(t − 4), ET(t), ET(t − 1), ET(t − 2), ET(t − 3), ET(t − 4)) was performed
    to obtain the important factors for streamflow estimation. The analysis results
    are shown in Tables 3 and 4, respectively, for five tributaries and Caiqi station.
    As observed in Tables 3 and 4, up to a time lag of 2 months, the cross-correlations
    are higher for precipitation and ET information. It indicated that the two hydrological
    factors time series after a time lag of 2 months would not possess any significant
    effect on the target streamflow data, Q(t), as the cross-correlation values are
    close to zero. For the application of the model, rainfall (P(t)) can be obtained
    from public weather forecast information in several stations. Similarly, some
    meteorologic variables such as temperature, humidity, and wind speed can also
    be obtained from weather forecast information. Then, potential evapotranspiration
    (E(t)) can be calculated using P–M equation. Table 3. Cross-correlations of Q(t)
    with different time lags of precipitation (P(t − i)) and evaporation (ET(t − i))
    for the five sub-catchments. Time lags Xiying Jingta Huangyang Zamu Gulang Q(t)
    vs. P(t − i) Q(t) vs. ET(t − i) Q(t) vs. ET(t − i) Q(t) vs. ET(t − i) Q(t) vs.
    ET(t − i) Q(t) vs. ET(t − i) Q(t) vs. ET(t − i) Q(t) vs. ET(t − i) Q(t) vs. ET(t
    − i) Q(t) vs. ET(t − i) Zero month (i = 0) 0.56 0.38 0.53 0.29 0.48 0.33 0.50
    0.25 0.61 0.33 One month (i = 1) 0.43 0.21 0.40 0.18 0.35 0.2 0.32 0.18 0.38 0.24
    Two months (i = 2) 0.2 0.11 0.13 0.10 0.09 0.11 0.12 0.05 0.13 0.09 Three months
    (i = 3) 0.08 0.09 0.1 0.06 0.07 0.04 0.08 0.05 0.1 0.04 Four months (i = 4) 0.11
    0.03 0.08 0.02 0.03 0.02 0.01 0.03 0.04 0.02 Table 4. Cross-correlations of Q(t)
    with different time lags of precipitation (P(t − i)) and evaporation (ET(t − i))
    downstream of the basin. Time lags Q(t) vs. P(t − i) Q(t) vs. ET(t − i) Zero month
    (i = 0) 0.21 0.13 One month (i = 1) 0.18 0.09 Two months (i = 2) 0.07 0.03 Three
    months (i = 3) 0.04 0.02 Four months (i = 4) 0.01 0.01 The training and testing
    patterns should be representative of similar physical systems for the development
    of ANN models. For this study, the physical process of streamflow change is typical
    agreement over the period of 1956 to 2003. So, the observed precipitation, ET,
    irrigation data, and streamflow data from 1956 to 1991 were used for training
    ANNs for monthly streamflow, and the recent 12-year data from 1992 to 2003 were
    used for testing the performance of the trained ANN models. Furthermore, scope
    of rainfall, evaporation, and streamflow from testing sample are within the scope
    of training sample. In this study, each member model of the integrated ANN models
    was developed using the same procedure as the single modeling. For example, the
    SCGM algorithm, the log sigmoid, the linear transfer functions, and the early
    stopping method were also employed for the each ANN. The capacity of each ANN
    to estimate monthly streamflow was checked by applying the calibrated or generated
    model to the testing data. Results were compared by means of the Root Mean Square
    Error (RMSE), the mean relative error (MRE), and the coefficient of determination
    (R2). RMSE and MRE provided different types of information about the predictive
    capabilities of the model. The RMSE measured the goodness of fit relevant to high
    streamflow, whereas the RE yielded a more balanced perspective of the goodness
    of fit at moderate groundwater levels. The R2 measures the degree to which two
    variables were linearly related. The RMSE and RE were respectively defined as:
    (3) (4) (5) where m is the number of observations, and Oi and yi are the ith observed
    and predicted data, respectively, (using the ANN procedures). and are the averages
    of the data arrays of yi and Oi. In addition, residual statistic analysis was
    also carried out to indicate error change of ANN model. Hidden nodes of ANNs for
    five tributaries (ANN1, ANN2, ANN3, ANN4, ANN5) and outlet of mountain (IANN-om,
    LANN-om), downstream (LANN, IANN1, IANN2) were optimized by trial-and-error method.
    RMSE, MRE, and R2 were used to assess the precision of ANN with different hidden
    nodes. All of ANNs with hidden nodes from 5 to 20 were trained and tested. As
    demonstrated earlier (Dai et al., 2011), error of ANN decreases with an increase
    in hidden node until the optimized node number was reached. After this node number,
    the error keeps changing slightly for training sample. However, error will rise
    when hidden node is more than the optimized node number. According to this fundamental
    principle, an optimized hidden node can be obtained. 4. Result analysis and discussion
    4.1. Performance of ANNs for five tributaries The optimized hidden node architecture
    and performances of ANNs for streamflows of five tributaries are evaluated using
    the three criteria, RMSE, RE, and R2, presented in Table 5. Results showed that
    there is a consistent trend between observed and simulated monthly streamflow
    from ANN data for five tributaries (Fig. 6). According to the evaluated criteria,
    all ANN models have higher precision with RMSE of 0.08–0.33 × 107 m3, MRE of 13–19%,
    and R2 of 0.89–0.93 for training data and RMSE of 0.18–0.53 × 107 m3, MRE of 18–37%,
    and R2 of 0.88–0.91 for testing data. It was also observed that the higher the
    monthly stream values, the higher the RMSE of the model. For example, RMSE of
    Xiying and Zamu tributaries are 0.33 × 107 m3 and 0.25 × 107 m3, and 0.53 × 107
    m3 and 0.42 × 107 m3, respectively, for training and testing data. RMSE of ANNs
    for other three tributaries is comparably lower than that of Xiying and Zamu tributaries
    both for training and testing data. Residual statistic analysis results are presented
    in Table 6, which showed that there are some variations among ANNs for five tributaries.
    Table 5. Error statistics of ANNs for monthly streamflow of five tributaries.
    Empty Cell Optimized ANN structure Training data Testing data RMSE MRE R2 RMSE
    MRE R2 (107 m3) (%) Empty Cell (107 m3) (%) Empty Cell Xiying 4:7:1 0.33 13 0.93
    0.42 18 0.91 Jingta 4:7:1 0.14 17 0.9 0.18 20 0.88 Zamu 4:6:1 0.25 16 0.89 0.35
    22 0.88 Huangyang 4:7:1 0.14 15 0.91 0.53 32 0.89 Gulang 4:6:1 0.08 19 0.9 0.32
    37 0.9 Download : Download full-size image Fig. 6. Observed and estimated by ANN
    monthly streamflow of tributaries. Table 6. Statistical analysis of the residuals
    from ANN steamflow models for five tributaries and downstream. Empty Cell Training
    data Testing data Max Min Var Max Min Var Xiying 6.38 −5.12 1.31 4.40 −4.11 1.81
    Jingta 3.19 −2.40 0.25 1.95 −3.23 0.39 Zamu 5.04 −2.61 0.59 3.98 −4.36 1.28 Huangyang
    2.97 −1.37 0.20 1.23 −1.96 0.26 Gulang 1.39 −1.10 0.07 1.11 −1.76 0.12 Outlet
    of mountain 5.83 −3.32 0.18 4.34 −2.75 0.38 Caiqi-IANN1 5.93 −2.78 0.17 3.40 −2.08
    0.22 Caiqi-IANN2 6.01 −3.01 0.20 3.67 −2.12 0.21 Note: Max and Min mean maximum
    and minimum residual from ANN. Var means the variance of residual from ANN. However,
    MRE of ANN models is higher for tributaries where agricultural activities are
    comparably intensive. For example, MRE of ANN models is 19% and 37%, respectively,
    for training and testing data in Gulang tributary where the planted area makes
    up 35.69% of the total land area. Similarly, RE of ANN models is 17% and 32%,
    respectively, for training and testing data in Huangyang tributary where the planted
    area makes up 25.83% of the total land area. For other three tributaries, agricultural
    activities are comparably few and the proportion of planted area is lower than
    15%. As a result, MRE of ANN models is within the scope of 13–16% and 18–22%,
    which is obviously lower than that of ANN models for Gulang and Huangyang tributaries.
    It can be concluded that agricultural activities affect the hydrological process
    of land surface and that rainfall–runoff becomes complex in these tributaries.
    ANNs are more difficult to model streamflow in catchments where agricultural activities
    are intensive. 4.2. Comparison of integrated ANNs with lumped ANN for streamflow
    at outlet of mountain For assessing the overall performance of integrated ANNs
    to simulate monthly streamflow at outlet of mountain, monthly streamflow of the
    five tributaries estimated by ANNs was summed as the total monthly streamflow
    at outlet of mountain. Fig. 7 presents the time series plot of observed and estimated
    monthly streamflow at outlet of mountain with integrated ANNs. This resulted in
    the overall RMSE value of 0.25 × 107 m3 and 0.36 × 107 m3, respectively, for training
    and testing data. The MRE is 7% and 9%, respectively, for training and testing
    data when compared with observed streamflow. Furthermore, R2 is 0.91 and 0.9,
    respectively, for training and testing data. Compared with that of single ANN
    respectively for the five tributaries, errors of ANN for outlet of mountain are
    significantly lower. The RMSE of integrated ANNs had the same scope with that
    of single ANN for every tributary, and this can be contributed to the offset of
    errors of every single ANN when estimated streamflow of five tributaries was summed
    as the streamflow at outlet of mountain. However, the MRE of the integrated ANNs
    to estimate monthly streamflow at outlet of mountain is markedly lower than that
    of single ANN for every tributary as a notable increase in total streamflow at
    outlet of mountain comparing to streamflow of single tributaries. Download : Download
    full-size image Fig. 7. Observed and estimated by ANN total monthly streamflow
    at outlet of mountain ((a) lumped ANN; (b) integrated ANNs). At the same time,
    a lumped ANN for monthly streamflow at outlet of the mountain was developed to
    compare its performance with that of integrated ANNs. As pointed in the former
    sections, precipitations and ET of the five sub-catchments were averaged as the
    inputs of the lumped ANN, and the lag of precipitation and evaporation was two
    months. The output of the lumped ANN was total monthly streamflow of the five
    tributaries. The same technology was used to develop a single ANN, and the training
    and testing data were consistent with those of integrated ANNs. The time series
    of observed and estimated monthly streamflow at outlet of mountain with lumped
    ANN is presented in Fig. 7. The difference between observed and estimated values
    is evident when streamflow values are relatively high. The optimized hidden node
    architecture and error statistics for the two ANN models (integrated ANN and lumped
    ANN) are listed in Table 7. It can be observed that errors of the lumped ANN are
    obviously higher than those of the integrated ANNs to estimate monthly streamflow
    at outlet of mountain. The RMSE of the lumped ANN is 1.64 × 107 m3 and 2.43 ×
    107 m3, respectively, for training and testing data and increases by about five
    times when compared with that of the integrated ANNs. Similarly, the MRE and R2
    of the lumped ANN are 42% and 52%, and 0.79 and 0.75, respectively, for training
    and testing data and increase remarkably when compared with those of the integrated
    ANNs. Table 7. Error statistics of integrated ANNs and lumped ANN for total streamflow
    of outlet of mountain. Empty Cell Optimized ANN structure Training data Testing
    data RMSE MRE R2 RMSE MRE R2 (107 m3) (%) Empty Cell (107 m3) (%) Empty Cell Integrated
    ANNs – 0.25 7 0.91 0.36 9 0.9 Lumped ANN 4:7:1 1.64 42 0.79 2.43 52 0.75 Difference
    in precision of the two models that estimate streamflow at outlet of mountain
    can be explained by the structure of the models. The integrated ANNs include several
    single ANNs for tributaries and consider the spatial variation of precipitation
    and ET. In other words, the integrated ANNs are similar to semi-distributed models,
    which represents the change in parameters affecting hydrological processes. However,
    the lumped ANN assumed that the rainfall and ET are uniformly distributed over
    the catchments and can be understood as a lumped nonlinear ‘total-response’ model.
    As a result, precision of the integrated ANNs is significantly higher than the
    lumped ANN. 4.3. Comparison of integrated ANNs with lumped ANN for monthly streamflow
    downstream Two integrated ANNs (IANN1 and IANN2) and one lumped ANN (LANN) were
    used to estimate monthly streamflow at Caiqi station located downstream of the
    study area, and the time series of observed and estimated monthly streamflow is
    presented in Fig. 8. It is obvious that the results of IANN1 and IANN2 models
    are better than that of LANN because the former estimates the streamflow at outlet
    of mountain using semi-distributed method while the latter estimates using lumped
    method. Download : Download full-size image Fig. 8. Observed and estimated by
    ANN monthly streamflow downstream ((a) IANN1; (b) IANN2; (c) LANN). The optimized
    hidden node architecture errors of the three combined ANN models for monthly streamflow
    downstream are listed in Table 8, and the results indicate that IANN1 and IANN2
    perform significantly better than LANN. For training data, two IANN models have
    the same precision with RMSE of 0.28–0.29 × 107 m3, MRE of 13%, and R2 of 0.91–0.92.
    However, the LANN obviously has higher error with RMSE of 0.58 × 107m3, MRE of
    27%, and R2 of 0.78 for training data. Similarly, errors of two IANN models are
    lower with RMSE of 0.35–0.38 × 107 m3, MRE of 22–27%, and R2 of 0.88–0.90 for
    testing data, but RMSE, MRE, and R2 of LANN increased respectively to 0.71 × 107
    m3, 46%, and 0.7 for testing data. Overall, the LANN has about twice the error
    than IANN to estimate monthly streamflow downstream. In fact, the differences
    between the two kinds of combining ANN models to estimate streamflow downstream
    are from their different precision to estimate streamflow at outlet of mountain.
    Table 8. Error statistics of integrated ANNs and lumped ANN for monthly river
    flow at Caiqi station downstream of the Shiyang River Basin. Empty Cell Optimized
    ANN structure Training data Testing data RMSE MRE R2 RMSE MRE R2 (107 m3) (%)
    Empty Cell (107 m3) (%) Empty Cell Integrated ANN1 7:10:1 0.28 13 0.92 0.35 22
    0.9 Integrated ANN2 11:15:1 0.29 13 0.91 0.38 27 0.88 Lumped ANN 7:11:1 0.55 27
    0.78 0.71 44 0.7 As for the two IANN models, IANN1 has higher precision than IANN2
    and this can be explained with structure of ANN. There are seven inputs for IANN1
    and 11 inputs for IANN2 that are relatively complex. For ANN, the increase in
    input factors can make ANN more complex and the parameters (weights and thresholds)
    further increase. It is difficult to train a more complex ANN, especially when
    excess input factors do not include further useful information to output. In this
    study, streamflow from five tributaries at outlet of mountain was summed as an
    input of ANN in IANN1, but they were respectively different in IANN2. In fact,
    inputs of IANN1 contain the information of inputs of IANN2. As a result, IANN2
    can be overtrained and its ability had been declined. Furthermore, another ANN
    model for monthly streamflow downstream was developed to test the capability of
    different ANN models to simulate streamflow of arid inland area. In this ANN,
    P and ET in every tributary were directly arranged as inputs. It is noticeable
    that the precision of the model is lower than the two IANN models, and the RMSE,
    MRE, and R2 are respectively 0.60 × 107 m3, 30%, and 0.77 for testing sample.
    This error is almost equivalent to that of LANN. This can be attributed to change
    cause of streamflow in upper reach of basin is different than in down reach in
    arid region. Again, usually there are hydrological stations in every outlet of
    tributary, and ANNs for river flow at outlet of mountain and down reach can be
    easily developed and used. 4.4. Comparison of ANN models with LLR models for monthly
    streamflow Several LLR models were developed to further assess the performance
    of ANNs to estimate monthly streamflow. The hydrological data used to develop
    LLRs are same as those of ANNs. For the LLRs downstream of the basin, estimated
    monthly streamflow by a lumped LLR model was arranged as inputs. The observed
    and estimated scatter plots of using LLR and ANN monthly streamflow for the five
    tributaries are shown in Fig. 9. Similarly, the observed and estimated scatter
    plots of using monthly streamflow data obtained from both the methods at outlet
    of mountain and Caiqi station downstream are presented in Figs. 10 and 11, respectively.
    The performance of LLRs in terms of the two model evaluation criteria, namely
    RMSE and RE, are presented in Table 9. Download : Download full-size image Fig.
    9. Scatter plot of observed and estimated by ANN and LLR monthly streamflow for
    tributaries. Download : Download full-size image Fig. 10. Scatter plot of observed
    and estimated by ANN and LLR monthly streamflow at outlet of mountain. Download
    : Download full-size image Fig. 11. Scatter plot of observed and estimated by
    ANN and LLR monthly river flow at Caiqi station downstream. Table 9. Error statistics
    of LLRs for monthly streamflow of five tributaries and the Caiqi station of the
    Shiyang River Basin. Empty Cell Training data Testing data RMSE MRE R2 RMSE MRE
    R2 (107 m3) (%) Empty Cell (107 m3) (%) Empty Cell Xiying 0.47 19 0.8 0.64 27
    0.77 Jingta 0.25 30 0.78 0.32 36 0.73 Zamu 0.38 24 0.79 0.48 30 0.75 Huangyang
    0.28 30 0.81 0.7 42 0.7 Gulang 0.14 33 0.83 0.49 57 0.66 Outlet of mountain 1.91
    50 0.71 2.62 61 0.63 Caiqi 0.64 30 0.77 0.85 56 0.65 Results imply that errors
    of LLRs to estimate monthly streamflow of five tributaries, outlet of mountain,
    and downstream of the basin are higher than corresponding ANNs. For the five tributaries,
    LLRs have errors with RMSE of 0.14–0.47 × 107 m3, MRE of 19–33%, R2 of 0.78–0.83,
    and RMSE of 0.32–0.64 × 107 m3, MRE of 27–57%, and R2 of 0.66–0.77, respectively,
    for training and testing data. Overall, the errors of LLRs are significantly higher
    than those of ANNs and especially at the period in which the streamflow values
    are low (Fig. 9). For the total monthly streamflow of an outlet of mountain, the
    LLR has errors with RMSE of 1.91 × 107 m3, MRE of 50%, and R2 of 0.71 in training
    period and RMSE of 2.62 × 107 m3, MRE of 61% and R2 of 0.63 in testing period.
    Although error of the LLR is near to that of the lumped ANN, it is obviously higher
    than that of the integrated ANNs with RMSE of 0.36 × 107 m3 and RE of 61%. Also,
    it can be observed from Fig. 10 that the observed and estimated scatter plot of
    using the integrated ANN is near to 1:1 line very much, but the plots for the
    LLR and the lumped ANN are dispersive. Similarly, integrated ANNs performed remarkably
    well in both training and testing data than LLR downstream (Fig. 11). According
    to the two evaluation criteria, LLR have errors with RMSE of 0.64 × 107 m3, MRE
    of 30%, and R2 of 0.77 for training data, and RMSE of 0.85 × 107 m3, MRE of 56%,
    and R2 of 0.65 for testing data, which are more than twice than that of integrated
    ANNs. As pointed out in former sections, hydrological process is a complex and
    nonlinear system, and LLRs do not have enough ability to capture the relationship
    between runoff and rainfall, evaporation, etc. However, ANN can statistically
    simulate the hydrological process as its nonlinear feature. Especially in this
    study, the integrated ANNs considered variations in rainfall and evaporation among
    the five sub-catchments and can simulate total monthly streamflow at outlet of
    mountain well than lumped ANN and LLR. Downstream of the basin, a number of agricultural
    activities impact the hydrological process and change the streamflow. Although
    the streamflow estimate is more difficult to obtain using LLRs, integrated ANNs
    have higher precision to estimate monthly streamflow downstream of the basin.
    5. Conclusions The new approach of integration of Artificial Neural Networks (integrated
    ANN model) for streamflow estimation has been developed and used in an arid inland
    basin. The integrated ANN model has shown great potential in streamflow modeling
    when compared with traditional models. By developing the semi-distributed form
    of ANNs to explore the spatial variation in hydrological process, such as rainfall
    distribution and evaporation distribution, streamflow generated from individual
    sub-catchments can be summed as the streamflow at the outlet of mountain. Furthermore,
    river flow estimation downstream of the basin can be improved by the application
    of the semi-distributed form of ANNs upstream. The integrated ANN models in this
    study retain the advantages of the semi-distributed models considering the heterogeneity
    and spatial variation of hydrological factors and physical characteristics in
    the catchment, while taking advantage of the potential of ANNs as an effective
    tool in nonlinear mapping or functional relationship establishment. As demonstrated
    in this study, the integrated form of ANNs offer the most promising results compared
    to single ANN and LLR models. However, it need be pointed out that use of the
    integrated ANNs is limited in some regions where long-term hydrological and meteorological
    data are lacking. Moreover, because of the limitation of soil and other parameters,
    the distribution physics model has not been further used to assess the ability
    of integrated ANNs and this will be performed in future study. Acknowledgements
    The authors are grateful for support from National Nature Science Foundation of
    China (No. 50909094). Two anonymous reviewers are appreciated as some good suggestions
    improved the quality of the paper. References Allen et al., 1998 Allen, R.G.,
    Pereira, L.S., Raes, D., Smith, M., 1998. Crop evapotranspiration:guidelines for
    computing crop requirements. FAO Irrigation and Drainage Paper No. 56. FAO, Rome,
    Italy. Google Scholar Ashu and Sanaga, 2006 J. Ashu, S. Sanaga Integrated approach
    to model decomposed flow hydrograph using artificial neural network and conceptual
    techniques J. Hydrol., 317 (2006), pp. 291-306 Google Scholar Chau, 2006 K.W.
    Chau Particle swarm optimization training algorithm for ANNs in stage prediction
    of Shing Mun River J. Hydrol., 329 (3–4) (2006), pp. 363-367 View PDFView articleView
    in ScopusGoogle Scholar Chen and Adams, 2006 J. Chen, B.J. Adams Integration of
    artificial neural networks with conceptual models in rainfall–runoff modeling
    J. Hydrol., 318 (2006), pp. 232-249 View PDFView articleView in ScopusGoogle Scholar
    Cheng et al., 2002 C.T. Cheng, C.P. Ou, K.W. Chau Combining a fuzzy optimal model
    with a genetic algorithm to solve multiobjective rainfall–runoff model calibration
    J. Hydrol., 268 (1–4) (2002), pp. 72-86 View PDFView articleView in ScopusGoogle
    Scholar Cigizogilu, 2005 H.K. Cigizogilu Application of generalized regression
    neural networks to intermittent flow forecasting and estimation J. Hydrol. Eng.,
    10 (4) (2005), pp. 336-341 Google Scholar Corzo et al., 2009 G.A. Corzo, D.P.
    Solomatine, Hidayat, M. de Wit, M. Werner, S. Uhlenbrook, R.K. Price Combining
    semi-distributed process-based and data-driven models in flow simulation: a case
    study of the Meuse river basin Hydrol. Earth Syst. Sci., 13 (2009), pp. 1619-1634
    CrossRefView in ScopusGoogle Scholar Dai et al., 2011 X. Dai, Z. Huo, H. Wang
    Simulation for response of crop yield to soil moisture and salinity with artificial
    neural network Field Crops Res., 121 (2011), pp. 441-449 View PDFView articleView
    in ScopusGoogle Scholar Falas and Stafylopatis, 2005 Falas, T., Stafylopatis,
    A., 2005. Symbolic rule extraction with a scaled conjugate gradient version of
    CLARION. In: Neural Networks 2005, IEEE International Joint Conference, vol. 2,
    pp. 845–848. Google Scholar Funahashi, 1989 K. Funahashi On the approximate realization
    of continuous mappings by neural networks Neural Networks, 2 (1989), pp. 183-192
    View PDFView articleView in ScopusGoogle Scholar Gao et al., 2010 C. Gao, M. Gemmer,
    X. Zeng, B. Liu, B. Su, Y. Wen Projected streamflow in the Huaihe River Basin
    (2010–2100) using artificial neural network Stochastic Environ. Res. Risk Assess.,
    24 (5) (2010), pp. 685-697 CrossRefView in ScopusGoogle Scholar Hornik et al.,
    1989 K. Hornik, M. Stinchcombe, H. White Multilayer feedforward networks are universal
    approximators Neural Networks, 2 (1989), pp. 359-366 View PDFView articleView
    in ScopusGoogle Scholar Hsu et al., 1995 K. Hsu, H.V. Gupta, S. Sorooshian Artificial
    neural network modeling of the rainfall–runoff process Water Resour. Res., 31
    (10) (1995), pp. 2517-2530 View in ScopusGoogle Scholar Huo et al., 2008 Z. Huo,
    S. Feng, S. Kang, W. Li, S. Chen Effect of climate changes and water-related human
    activities on annual streamflows of the Shiyang River basin in arid north-west
    China Hydrol. Process., 22 (2008), pp. 3155-3167 CrossRefView in ScopusGoogle
    Scholar Jeong and Kim, 2005 D. Jeong, Y. Kim Rainfall–runoff models using artificial
    neural networks for ensemble streamflow prediction Hydrol. Process., 19 (2005),
    pp. 3819-3835 CrossRefView in ScopusGoogle Scholar Kamp and Savenijie, 2007 R.G.
    Kamp, H.H.G. Savenijie Hydrological model coupling with ANNs Hydrol. Earth Syst.
    Sci., 11 (2007), pp. 1869-1881 CrossRefView in ScopusGoogle Scholar Kang et al.,
    2004 S. Kang, X. Su, L. Tong The impact of human activities on the water-land
    environment of the Shiyang River basin, an arid region in Northwest China Hydrol.
    Sci. Sci. Hydrol., 49 (3) (2004), pp. 413-426 View in ScopusGoogle Scholar Kumar
    and Minocha, 2001 A. Kumar, K. Minocha Discussion on rainfall runoff modeling
    using artificial neural networks J. Hydrol. Eng., 6 (2) (2001), pp. 176-177 View
    in ScopusGoogle Scholar Li et al., 2006 X.Y. Li, K.W. Chau, C.T. Cheng, Y.S. Li
    A web-based flood forecasting system for Shuangpai region Adv. Eng. Softw., 37
    (3) (2006), pp. 146-158 View PDFView articleView in ScopusGoogle Scholar Lin et
    al., 2006 J.Y. Lin, C.T. Cheng, K.W. Chau Using support vector machines for long-term
    discharge prediction J. Hydrol. Sci., 51 (4) (2006), pp. 599-612 CrossRefView
    in ScopusGoogle Scholar Liu et al., 2005 T. Liu, S. Boumaiza, F.M. Ghannouchi
    Application of neural networks to 3G power amplifier modeling Int. Joint Conf.
    Neural Networks, 2378 (2005), p. 2382 Google Scholar Lohani et al., 2011 A.K.
    Lohani, N.K. Goel, K.K.S. Bhatia Comparative study of neural network, fuzzy logic
    and linear transfer function techniques in daily rainfall–runoff modelling under
    different input domains Hydrol. Process., 25 (2) (2011), pp. 175-193 CrossRefView
    in ScopusGoogle Scholar Ma et al., 2008 Z. Ma, S. Kang, L. Zhang, L. Tong, X.
    Su Analysis of impacts of climate variability and human activity on streamflow
    for a river basin in arid region of Northwest China J. Hydrol., 352 (2008), pp.
    239-249 View PDFView articleView in ScopusGoogle Scholar Moler, 1993 M.F. Moler
    A scaled conjugate gradient algorithm for fast supervised learning Neural Networks,
    6 (4) (1993), pp. 525-533 Google Scholar Nilsson et al., 2006 P. Nilsson, C.B.
    Uvo, R. Berndtsson Monthly runoff simulation: comparing and combining conceptual
    and neural network models J. Hydrol., 321 (2006), pp. 344-363 View PDFView articleView
    in ScopusGoogle Scholar Remesan et al., 2009 R. Remesan, M.A. Shamim, D. Han,
    J. Mathew Runoff prediction using an hybrid modeling scheme J. Hydrol., 372 (2009),
    pp. 48-60 View PDFView articleView in ScopusGoogle Scholar Rumelhart et al., 1986
    D.E. Rumelhart, G.E. Hinton, R.J. Williams Learning representations by back-propagating
    errors Nature, 323 (1986), pp. 533-536 CrossRefView in ScopusGoogle Scholar Sajikumar
    and Thandaveswara, 1999 N. Sajikumar, B.S. Thandaveswara A non-linear rainfall
    runoff model using an artificial neural network J. Hydrol., 216 (1999), pp. 32-55
    View PDFView articleView in ScopusGoogle Scholar Schumann et al., 2000 A.H. Schumann,
    R. Funke, G.A. Schultz Application of a geographic information system for conceptual
    rainfall–runoff modeling J. Hydrol., 240 (2000), pp. 45-61 View PDFView articleView
    in ScopusGoogle Scholar Sugawara, 1995 M. Sugawara V.P. Singh (Ed.), Tank Model,
    in Computer Models of Catchment Hydrology, Water Resources Publications, Littleton,
    CO (1995) Google Scholar Tan and Connor, 1996 B.Q. Tan, K.M. Connor Application
    of an empirical infiltration equation in the SMAR conceptual model J. Hydrol.,
    185 (1996), pp. 275-295 View PDFView articleView in ScopusGoogle Scholar Tokar
    and Markus, 2000 A.S. Tokar, M. Markus Precipitation–runoff modeling using artificial
    neural networks and conceptual models J. Hydrol. Eng., 5 (2) (2000), pp. 156-161
    View in ScopusGoogle Scholar Turan and Yurdusev, 2009 M.E. Turan, M.A. Yurdusev
    River flow estimation from upstream flow records by artificial intelligence method
    J. Hydrol., 369 (2009), pp. 71-77 View PDFView articleView in ScopusGoogle Scholar
    Wang et al., 2009 W.C. Wang, K.W. Chau, C.T. Cheng, L. Qiu A comparison of performance
    of several artificial intelligence methods for forecasting monthly discharge time
    series J. Hydrol., 374 (3–4) (2009), pp. 294-306 View PDFView articleView in ScopusGoogle
    Scholar Wu et al., 2009 C.L. Wu, K.W. Chau, Y.S. Li Predicting monthly streamflow
    using data-driven models coupled with data-preprocessing techniques Water Resour.
    Res., 45 (2009), p. W08432, 10.1029/2007WR006737 View in ScopusGoogle Scholar
    Zhang and Govindaraju, 2003 B. Zhang, R.S. Govindaraju Geomorphology-based artificial
    neural networks (GANNs) for estimation of direct runoff over catchments J. Hydrol.,
    273 (1–4) (2003), pp. 18-34 View PDFView articleView in ScopusGoogle Scholar Zhao
    and Liu, 1995 R.J. Zhao, X.R. Liu The Xinanjiang model V.P. Singh (Ed.), Computer
    Models of Catchment Hydrology, Water Resources Publications, Littleton, CO (1995)
    Google Scholar Cited by (55) A novel fully hybrid simulation-optimization approach
    for enhancing the calibration and verification performance of the TUW hydrological
    model 2023, Journal of Hydrology Citation Excerpt : Prediction of runoff time
    series is an important task in water resources planning and management studies.
    Since conversion of rainfall to runoff is a highly nonlinear process and influenced
    by numerous natural and anthropogenic factors, accurate prediction of the runoff
    is usually difficult (Yuan and Forshay, 2021; Alizadeh et al., 2017; Huo et al.,
    2012). Hydrological models are the key elements for runoff prediction studies
    by considering simplified versions of the real-world systems including surface
    water, groundwater, etc. Show abstract Regional hydrological frequency analysis
    at ungauged sites with random forest regression 2021, Journal of Hydrology Show
    abstract Streamflow forecasting: Overview of advances in data-driven techniques
    2021, Advances in Streamflow Forecasting: From Traditional to Modern Approaches
    Show abstract Assessing combinations of artificial neural networks input/output
    parameters to better simulate daily streamflow: Case of Brazilian Atlantic Rainforest
    watersheds 2019, Computers and Electronics in Agriculture Citation Excerpt : The
    development of an ANN consists in determining its architecture, that is, the number
    of layers and neurons in each layer, as well as fitting their free parameters
    (connections), in a phase known as training (Hagan and Menhaj, 1994; Moreira et
    al., 2016). In recent years, several studies have applied ANNs in hydrological
    science, showing the potential of this tool for hydrological modelling, especially
    rainfall-runoff transformation for daily, weekly and monthly time intervals (Aichouri
    et al., 2015; Danandeh Mehr et al., 2015; Dariane and Azimi, 2018; Huo et al.,
    2012; Jain and Kumar, 2007; Kişi, 2007; Lin et al., 2018; Noori and Kalin, 2016;
    Rezaeian-Zadeh et al., 2013a; Veintimilla-Reyes et al., 2016; Yaseen et al., 2015).
    The scope of improving the efficiency of ANNs in predicting streamflow by using
    different combinations of input/output data needs to be analyzed (Ray and Sarma,
    2016), as successfully forecasted in some geosciences applications (Carcano et
    al., 2008; Zhu et al., 2017a; Zhu et al., 2018a). Show abstract Wavelet neural
    networks and gene expression programming models to predict short-term soil temperature
    at different depths 2018, Soil and Tillage Research Show abstract Operational
    policy development for dynamic restoration of lakes in a changing climate; application
    of innovative hedging rules in a system dynamics platform 2023, Applied Water
    Science View all citing articles on Scopus View Abstract Copyright © 2011 Elsevier
    B.V. All rights reserved. Recommended articles Modelling mutual thermal interactions
    between power LEDs in SPICE Microelectronics Reliability, Volume 55, Issue 2,
    2015, pp. 389-395 Krzysztof Górecki View PDF Impact assessment of climate change
    and human activities on streamflow signatures in the Yellow River Basin using
    the Budyko hypothesis and derived differential equation Journal of Hydrology,
    Volume 591, 2020, Article 125460 Wei Wang, …, Qiuhong Tang View PDF Linking the
    Budyko framework and the Dunne diagram Journal of Hydrology, Volume 535, 2016,
    pp. 581-597 Ralph Trancoso, …, Stuart Phinn View PDF Show 3 more articles Article
    Metrics Citations Citation Indexes: 53 Captures Readers: 53 View details About
    ScienceDirect Remote access Shopping cart Advertise Contact and support Terms
    and conditions Privacy policy Cookies are used by this site. Cookie settings |
    Your Privacy Choices All content on this site: Copyright © 2024 Elsevier B.V.,
    its licensors, and contributors. All rights are reserved, including those for
    text and data mining, AI training, and similar technologies. For all open access
    content, the Creative Commons licensing terms apply.'
  inline_citation: Huo et al. (2011)
  journal: Journal of Hydrology
  limitations: The paper does not consider the effect of climate change on streamflow.
    Climate change is likely to alter the frequency and intensity of extreme rainfall
    events, which could impact streamflow patterns. The authors also do not consider
    the effect of land use change on streamflow. Land use change can alter the amount
    of impervious surface in a watershed, which can lead to changes in runoff and
    streamflow. Finally, the authors do not provide any guidance on how to apply the
    integrated ANN model to other watersheds. Developing a set of guidelines for applying
    the model to other watersheds would increase the utility of the model.
  pdf_link: null
  publication_year: 2012
  relevance_score: 0.9
  relevance_score1: 0
  relevance_score2: 0
  title: Integrated neural networks for monthly river flow estimation in arid inland
    basin of Northwest China
  verbatim_quote1: null
  verbatim_quote2: null
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1080/07900627.2016.1259101
  analysis: 'The paper applies a hydrological model (WaterWorld) to assess the impacts
    of climate change on streamflow in the Peruvian Andes. It combines a range of
    statistically downscaled climate models from the IPCC AR4 with WaterWorld, which
    is capable of simulating snowfall, snowmelt dynamics, and meltwater production.
    The study finds that while overall discharge may not change much, there are significant
    changes in seasonality under climate change due to the loss of water stored and
    released seasonally by glaciers.


    The paper contributes to the review''s point by providing a comprehensive analysis
    of how different data types (e.g., soil moisture, canopy temperature, weather)
    can be used to inform automated irrigation management systems, particularly in
    the context of climate change. The paper''s findings underscore the importance
    of considering various data types to capture the complex interactions between
    soil, plant, and atmospheric conditions in order to optimize irrigation scheduling.


    The paper''s most relevant verbatim quotes are:


    "Water resources in the Santa Basin in the Peruvian Andes are increasingly under
    pressure from climate change and population increase. Impacts of temperature-driven
    glacier retreat on streamflow are better studied than those of precipitation changes,
    yet present and future water resources are mostly dependent on precipitation,
    which is more difficult to predict with climate models."


    "This study combines a broad range of projections from climate models with a hydrological
    model (WaterWorld), showing a general trend towards an increase in water availability
    due to precipitation increases over the basin. However, high uncertainties in
    these projections necessitate basin-wide policies aimed at increased adaptability."


    "The results of this analysis are a clear indication that projected climate change
    across a wide range of scenarios generally leads to increased water availability
    for the Rio Santa basin and a trend towards runoff being more rainfall-dominated,
    particularly in the dry season. Though snowmelt increases, rainfall increases
    more, so the relative contribution of snowmelt lessens."


    The paper''s relevance score is 0.7, indicating that it is "very relevant" to
    the review''s point. It provides a thorough analysis of the use of different data
    types in automated irrigation management systems, considering the impacts of climate
    change. However, it could be further strengthened by discussing the specific implications
    of these findings for the design and implementation of automated irrigation systems
    in real-world settings.


    One limitation of the paper is that it does not explicitly address the issue of
    data quality and availability, which can be a significant challenge in implementing
    automated irrigation systems in data-scarce regions.'
  authors:
  - Arnout van Soesbergen
  - Mark Mulligan
  citation_count: 7
  full_citation: van Soesbergen, A., & Mulligan, M. (2016). Potential outcomes of
    multi-variable climate change on water resources in the Santa Basin, Peru. International
    Journal of Water Resources Development, 34(2), 150-165.
  full_text: '>

    Access provided by University of Nebraska, Lincoln Log in  |  Register Cart Home
    All Journals International Journal of Water Resources Development List of Issues
    Volume 34, Issue 2 Potential outcomes of multi-variable cli .... Search in:                                        This
    Journal                                                                                Anywhere                                                                  Advanced
    search International Journal of Water Resources Development Volume 34, 2018 -
    Issue 2 Submit an article Journal homepage Full access 450 Views 7 CrossRef citations
    to date 4 Altmetric Listen Articles Potential outcomes of multi-variable climate
    change on water resources in the Santa Basin, Peru Arnout van Soesbergen & Mark
    Mulligan Pages 150-165 | Received 07 Jul 2016, Accepted 05 Nov 2016, Published
    online: 07 Dec 2016 Cite this article https://doi.org/10.1080/07900627.2016.1259101
    In this article Abstract Introduction Study area Methods Results and discussion
    Conclusions Disclosure statement Supplemental data Supplemental material Acknowledgements
    References Full Article Figures & data References Supplemental Citations Metrics
    Reprints & Permissions View PDF Abstract Water resources in the Santa Basin in
    the Peruvian Andes are increasingly under pressure from climate change and population
    increase. Impacts of temperature-driven glacier retreat on streamflow are better
    studied than those of precipitation changes, yet present and future water resources
    are mostly dependent on precipitation, which is more difficult to predict with
    climate models. This study combines a broad range of projections from climate
    models with a hydrological model (WaterWorld), showing a general trend towards
    an increase in water availability due to precipitation increases over the basin.
    However, high uncertainties in these projections necessitate basin-wide policies
    aimed at increased adaptability. Keywords: Water resourcesclimate changeWaterWorldtropical
    glaciersuncertaintyPeru Previous article View issue table of contents Next article
    Introduction Water resources in many regions of the world are increasingly under
    pressure from climate change, with precipitation changes affecting water availability
    and runoff directly, and temperature, radiation and humidity impacting evapotranspiration
    (Solomon, 2007) and snow and ice dynamics. In the Peruvian Andes, climate change
    pressure on water resources is considered to be exacerbated by the retreat of
    glaciers that act as seasonal water stores, providing freshwater during the dry
    season (Vuille et al., 2008). More than 99% of all tropical glaciers are in the
    Andes (Kaser & Georges, 1999), of which nearly 70% are in Peru (Vuille et al.,
    2008). Most water resources on the Pacific slopes of Peru originate from snow
    and ice in the Andes, according to Vuille et al. ( 2008). Pressures of climate
    change and glacier retreat are particularly pertinent for Peru’s Rio Santa basin,
    where growing water demand has resulted from increases in human population, export
    agriculture, mining and hydropower production, leading to increased competition
    for water (Lynch, 2012). This competition and developing strategies for better
    sharing the benefits of available water were the focus of the CGIAR Challenge
    Programme on Water and Food Project AN3 (COMPANDES), under which the research
    for this article was carried out (CGIAR Research Program on Water, Land & Environment,
    2014). Most studies on the impacts of climate change on water resources in the
    Peruvian Andes focus on glacier retreat and associated impacts on streamflow.
    For example, Pouyaud et al. ( 2005), using an increase in temperature of 0.1 °C/decade,
    projected increases in streamflow for the next 20–50 years under melting glacier
    conditions in the Llanganuco River basin, after which streamflow will become rain-
    and snowmelt-dominated. Juen ( 2007) obtained similar results using a more sophisticated
    tropical-glacier-hydrology model driven by four IPCC AR4 (Fourth Assessment Report;
    Solomon, 2007) emission scenarios, which resulted in less dry-season runoff because
    of diminishing glacier size but more wet-season runoff due to more direct runoff
    from more rainfall. Generally, these studies show that overall discharge may not
    change very much, but there are significant changes in seasonality under climate
    change due to the loss of water stored and released seasonally by glaciers. There
    are however significant differences between the various climate change projections,
    which lead to large differences in glacier discharge between scenarios (Vuille,
    2008), and these are a key uncertainty associated with assessing the impacts of
    climate change on water resources, particularly in the Peruvian Andes. These uncertainties
    derive from a number of sources associated with the general circulation models
    (GCMs), most importantly the emission scenario but also difficult-to-model mechanisms
    such as rainfall and cloud behaviour and sub-grid heterogeneity associated with
    simplified representation of topography. This can result in different GCMs producing
    very different projections. Even more uncertainty is introduced when combining
    these GCMs with hydrological models, as the GCM outputs will need to be downscaled.
    Due to the typically coarse resolution of GCMs, natural gradients in precipitation
    and temperature are smoothed out, and this is particularly problematic in mountainous
    regions, as their hydrology is characterized by strong elevational gradients (Buytaert,
    Vuille, Dewulf, Urrutia, & Karmalkar, 2010; Wilby et al., 2004). This article
    aims to evaluate the potential outcomes of climate change on the water resources
    of the Santa Basin by combining a range of statistically downscaled climate models
    using scenarios from the IPCC AR4 with a physically based spatial hydrological
    model (WaterWorld, Mulligan, 2013a) which is capable of simulating snowfall and
    snowmelt dynamics (WaterWorld version 2, Mulligan, 2013b). This allows the assessment
    of some of the uncertainty in future discharge projections and water resource
    availability in the basin, and especially the relative roles of changes in different
    fluxes (particularly rainfall, snowfall and meltwater) on water resources at different
    scales. Study area Study location and topography The Rio Santa basin is in Peru,
    in the Ancash Region, about 400 km north of the capital, Lima (Figure 1). The
    basin has a total drainage area of around 12,200 km2 and a total length of 316
    km, which makes it the second-largest river and the most regular flowing Peruvian
    river to flow into the Pacific ocean (Mark, 2010). The river originates at Lake
    Conococha at an altitude of 4080 m and then runs north through the Callejón de
    Huaylas Valley, which is between the Cordilleras Blanca and Negra. It then turns
    west at the confluence with the Rio Manta towards the city of Chimbote, at the
    Pacific coast (McKinney, Anderson, & Byers, 2011). The Cordillera Blanca towards
    the east of the Rio Santa has about one-quarter of all tropical glaciers (more
    than 600 km2) and over 30 peaks that are higher than 6000 m above sea level (Kaser,
    Juen, Georges, Gómez, & Tamayo, 2003; Vuille et al., 2008). Of the 23 tributary
    streams of the Rio Santa, 20 originate from the glaciers of the Cordillerra Blanca,
    making glacier melt an important contributor to the Rio Santa discharge, particularly
    in the dry season (McKinney, 2011). Conservative estimates of this contribution
    by Mark, McKenzie, and Gomez ( 2005) indicate that about two-thirds of the dry-season
    flow of the Rio Santa in the Huaylas Valley originates in the Cordillera Blanca,
    with 40% of the total flow in the dry season coming from glacier melt. Annual
    and wet-season contributions were not assessed in this study. Figure 1. Rio Santa
    Basin in Peru with main rivers and location of two largest high altitude cities
    Caraz and Huaraz. Display full size Current and recent climate Temperature in
    the area is dominated by the Intertropical Convergence Zone and trade winds, leading
    to only small variations in annual air temperature seasonally (Mark et al., 2005).
    Mean annual temperature in the basin, based on WorldClim data (Hijmans, Cameron,
    Parra, Jones, & Jarvis, 2005), is 9.6 °C, with a mean monthly minimum of 8.2 °C
    in August and a mean monthly maximum of 10.9 °C in March. More than 80% of precipitation
    falls in the wet season, between October and May, when the Intertropical Convergence
    Zone is in the region (Mark, 2010; Mark et al., 2005). The Cordillera Blanca acts
    as a barrier between the humid Amazon and the extremely dry coastal region, with
    the Amazonian side being up to three times wetter than the Pacific side (Racoviteanu,
    Arnaud, Williams, & Ordoñez, 2008). Average precipitation for the basin amounts
    to 548 mm a year, according to WorldClim data. However, this is extremely spatially
    variable, with the highest precipitation found along the Cordillera Blanca and
    the lowest in the dry coastal region. Recent and projected climate changes A temperature
    increase of around 0.35–0.39 °C per decade has been found in central Peru between
    1951 and 1999 based on 29 temperature stations (Mark et al., 2005), while Vuille
    et al. ( 2008), using 279 temperature stations, found a 0.10 °C increase per decade
    between 1939 and 2006 for the tropical Andes between 1° N and 23° S, leading to
    an overall temperature increase of nearly 0.7 °C since 1939. No clear trends in
    precipitation have been found, partly as a result of the lack of long-period,
    high-quality precipitation records. Vuille, Bradley, Werner, and Keimig ( 2003)
    analyzed 42 precipitation stations in the region and found only 5 with a significant
    increase and 2 with a significant decrease in annual precipitation. There was
    no clear dependence on elevation. Some other studies have found clear precipitation
    increases, mostly on the Eastern slopes of the Andes (Vuille et al., 2003). Projected
    changes in climate for the region under the IPCC AR4 emission scenarios point
    to a warming of 3–3.5 °C for 2041–2071 as well as a consistent pattern of increasing
    precipitation, up to 10%. However, for the precipitation projections, there is
    relatively low agreement between climate models (Met Office, 2011). Water resources
    and land use The basin can roughly be divided into three zones based on elevation:
    the high mountains, above 2000 metres; the Callejón de Huaylas Valley, between
    1000 and 2000 metres; and the coastal region, below 1000 metres. The highland
    areas mostly support subsistence farming and grazing. Land use in the Callejón
    de Huaylas Valley mostly consists of small irrigated farming, and the coastal
    region is dominated by large commercial irrigated agriculture in the Chavimochic
    and Chinecas project areas. Furthermore, the coastal cities of Chimbote and Trujillo
    further north are dependent on water from the Rio Santa for their drinking water
    supplies. Methods To assess the implications and uncertainties of climate change
    for water supply in the Santa Basin the WaterWorld hydrological model (Mulligan,
    2013a) was used, with a total of six multi-model ensemble climate change scenarios,
    in order to capture the widest range of possible futures. Changes in meltwater
    contribution, total streamflow and meltwater-generated streamflow were analyzed
    at the basin level and for two of the largest, most populous, high-altitude cities
    in the basin: Caraz, with a population of ca. 13,000; and Huaraz, with a population
    of ca. 96,000. The WaterWorld hydrological model WaterWorld is a fully distributed,
    process-based hydrological model that utilizes remotely sensed and globally available
    data-sets to support hydrological analysis and decision making at national and
    local scales globally, with a particular focus on ungauged and/or data-poor environments,
    which makes it well suited to this study. The model (version 2) currently runs
    on either 10° tiles, large river basins or countries at 1 km2 resolution or 1°
    tiles at 1 ha resolution utilizing different data-sets. It simulates a hydrological
    baseline as a mean for the period 1950–2000 and can be used to calculate the hydrological
    impact of scenarios of climate change, land use change, land management options,
    impacts of extractives (oil and gas and mining) and impacts of changes in population
    and demography as well as combinations of these. The model is “self parameterising”
    (Mulligan, 2013a) in the sense that all data required for model application anywhere
    in the world are provided with the model, removing a key barrier to model application.
    However, if users have better data than those provided, it is possible to upload
    these to WaterWorld as GIS files and use them instead. Results can be viewed visually
    in the web browser or downloaded as GIS maps. The model’s equations and processes
    are described in more detail by Mulligan and Burke ( 2005) and Mulligan ( 2013b).
    The model’s parameters are not routinely calibrated to observed flows, as it is
    designed for hydrological scenario analysis, in which the physical basis of the
    parameters must be retained, and the model is also often used in ungauged basins.
    Calibration is inappropriate under these circumstances (Sivapalan, Blöschl, Zhang,
    & Vertessy, 2003). The freely available nature of the model means that anyone
    can apply it and replicate the results shown here. Snow and ice model A number
    of studies have modelled water resources under future climate scenarios in the
    tropical Andes using various approaches and models for capturing snow and ice
    responses. For instance, Chevallier, Pouyaud, Suarez, and Condom ( 2011) used
    a simple temperature–discharge correlation approach to project future discharges
    given temperature increases. Condom et al. ( 2012) extended the Water Evaluation
    and Planning (WEAP; Yates, Sieber, Purkey, & Huber-Lee, 2005) model with a glacier
    module based on a degree-day model approach, while Andres, Vegas Galdos, Lavado
    Casimiro, and Zappa ( 2014) used a semi-distributed hydrological model (PREVAH;
    Viviroli, Zappa, Gurtz, & Weingartner, 2009). While the latter type of model provides
    good results, such models are calibrated to current conditions and require large
    amounts of (daily) input data, which are generally lacking in this region and
    for the future (Huggel et al., 2015). In WaterWorld, the snow and ice dynamics
    are resolved in a fully distributed, integrated approach without the need for
    additional parameterization data and applicable at the wider basin scale. WaterWorld’s
    (version 2) snow and ice module is capable of simulating the processes of meltwater
    production, snowfall and snowpack, making this version well suited to the current
    application. The model component is based on a full energy balance for snow accumulation
    and melting based on Walter et al. ( 2005), with input data provided globally
    by the SimTerra database (Mulligan, 2011), upon which the model relies. In particular,
    initial monthly snow cover is based on Moderate-Resolution Imaging Spectroradiometer
    (MODIS) snow-cover data processed by Mulligan ( 2006), and precipitation where
    ground-level temperature is below 0 °C is assumed to fall as snow. Changes in
    meltwater production and snowpack as a result of climate change are based on changes
    in seasonal and spatial patterns of temperature and precipitation for scenario
    conditions. Higher temperatures lead to less precipitation falling as snow and
    to more snow and ice melt, while more precipitation can lead to more snowfall.
    Both snow melt and glacier melt are governed by temperature, with temperatures
    above 0 °C leading to melting conditions. This means that on days with temperatures
    above 0 °C and no snowpack available, glacier melt will occur. WaterWorld takes
    into account diurnal temperature ranges by iterating through four diurnal time-steps
    that represent the mean diurnal cycle for each of the 12 monthly time-steps represented
    by the 50-year climatology. Glaciers are represented by the World Glacier Inventory
    of the World Glacier Monitoring Service and National Snow and Ice Data Center
    (NSIDC, 1989/2012), whose water equivalents are added to the initial snowpack
    water equivalent in the model. Changes in glacier extent under scenario conditions
    are accounted for by allowing the model to spin up. The database identifies some
    390 km2 of glacier within the Santa Basin (2.8% of the surface area), with a mean
    water equivalent of 0.9 mm, but ranging up to 146 mm on a 1 km grid cell basis.
    Model validation In order to test model performance in the basin, simulated streamflow
    was compared with observed flow. Data for observed streamflow were obtained through
    the COMPANDES project, with original data supplied by the Peruvian Institute of
    Natural Resources (INRENA), with data available for 16 sub-catchments for measurement
    periods ranging from 9 to 57 years. Two input precipitation data-sets were used
    in the validation, the WaterWorld default WorldClim data (Hijmans et al., 2005),
    based on 15 precipitation stations in and around the basin for observation periods
    of up to 50 years, and a TRMM (Tropical Rainfall Measuring Mission) monthly precipitation
    climatology, based on the TRMM 2B31 data-set for the years 1997–2006 developed
    by Mulligan ( 2006). According to Condom et al. ( 2012), there are 39 precipitation
    stations in the Santa watershed, which is more than are included in the WorldClim
    data-set; hence this underrepresentation of stations may account for uncertainty
    in the precipitation input data. However, Ward, Buytaert, Peaver, and Wheater
    ( 2011) showed that observational climatology data products such as the CRU CL
    2.0 and WorldClim data-sets compare well with Thiessen-interpolated averages of
    observed data for long-term mean annual precipitation in two Andean basins, mainly
    due to these products being generated from very similar observed data-sets; differences
    may be attributed to availability of precipitation data and averaging time period.
    Table 1 shows the results of the streamflow validation for both precipitation
    climatologies for all available observed streamflow stations and for stations
    that have an average flow of at least 5 m3/s (eight stations). Modelled annual
    streamflow shows a good fit to observed data for all stations (R2 = 0.84), but
    particularly for the stations with higher flow rate (R2 = 0.99), using WorldClim
    precipitation. Validation results for TRMM climatology show a slightly weaker
    fit, probably due to underestimation of precipitation in TRMM data. This underestimation
    of TRMM precipitation has also been shown by Ward, Buytaert, Peaver, and Wheater
    ( 2011) and Lavado Casimiro et al. ( 2009) for a number of basins in the Andes
    and Andes-Amazon. Table 1. WaterWorld streamflow (Q) validation for WorldClim
    and TRMM rainfall climatologies. Download CSVDisplay Table Climate change scenarios
    In order to better understand the high uncertainties in projections of climate
    change, the full available range of GCMs from IPCC AR4, downscaled to 1 km spatial
    resolution by the Research Program on Climate Change Agriculture and Food Security
    of the CGIAR (Ramirez and Jarvis, 2010) using the delta method for the 2050s,
    is used in this study. Two AR4 emissions scenarios were used: the SRES A2A scenario,
    representing high growth and a global 3.5 °C warming (relative to 1900) by 2100;
    and the SRES A1B scenario, a more balanced scenario representing moderate growth
    and a global 2.5 °C warming by 2100 (Nakicenovic et al., 2000). Individual monthly
    downscaled GCM output (Ramirez & Jarvis, 2010) for temperature and precipitation
    were combined by WaterWorld into multi-model ensemble per-pixel mean scenarios
    using 17 available GCMs for the A2A scenario and 24 GCMs for the A1B scenario
    (see Appendix Table A1, in the supplemental online material at http://dx.doi//10.1080/07900627.2016.1259101,
    for more details on the GCMs used). Using ensembles of GCMs is advocated as a
    way to obtain reliable information on the range of possible regional changes and
    associated uncertainties (Murphy et al., 2004; Solomon, 2007). More recent downscaled
    GCM data is currently available (e.g. Coupled Model Intercomparison Project phase
    5, CMIP5) using the Representative Concentration Pathways (RCP) scenarios (van
    Vuuren et al., 2011). At the time of analysis these were not yet incorporated
    in the WaterWorld model, but analysis of mean monthly precipitation and temperature
    changes for 17 GCMs under the RCP 4.5 scenario for the basin for 2050 resulted
    in similar directions of change and model disagreement as for the A2A and A1B
    scenarios. Figure 2 shows the range of monthly GCM projections for the Santa Basin
    for precipitation and temperature for both A2A and A1B emission scenarios. Clearly,
    between-model differences are significant, particularly for precipitation, which
    differs between GCMs in the direction of projected change (i.e. positive or negative
    relative to baseline) as well as the magnitude of change for nearly all months.
    To capture this wide range of possible futures, as well as the multi-model mean
    for A2A and A1B, the multi-model mean plus and minus the inter-model standard
    deviation (SD) for both temperature and precipitation were also used as scenarios
    to drive the WaterWorld model, resulting in a total of six ensemble scenarios
    (mean, mean – 1 SD, and mean + 1 SD for two emissions scenarios). Mean – 1 SD
    can be considered the cool, dry end of projections, whilst mean + 1 SD is the
    warm, wet end of projections. Figure 2. a-d: between scenario variability for
    precipitation and temperature projections for the Santa basin for 17 GCM under
    A2A scenario (a,b) and 24 GCM under A1B scenario (c,d). Boxplots show median,
    quartiles and range of the data. Outliers, shown on the plots as hollow circles,
    are defined as extreme values Display full size Results and discussion Basin-wide
    changes Table 2 shows the annual contributions of the different fluxes to projected
    change in water balance derived from WaterWorld as averages for the Rio Santa
    basin for the six multi-model climate change scenario-ensemble metric combinations
    as well as the proportion of the basin that contributes to that direction of change
    (a metric calculated by WaterWorld to better understand spatial variability when
    examining basin mean changes). The mean and mean + 1 SD scenarios result in increases
    in water balance, in all cases because change is dominated by increases in rainfall
    (Figures 2a and 2b). Temperature-driven change in actual evapotranspiration (ET)
    increases for all scenarios, but in all cases this is only a marginal increase
    compared to increases in rainfall (change in ET is 5–6% of the change in rainfall
    for the mean of all GCM scenarios). Table 2. Contribution of annual change in
    different fluxes to the change in mean basin wide water balance and overall outcome
    of the ensemble mean (% values relative to baseline). Download CSVDisplay Table
    Changes in annual total fog inputs are only significant in the A2A + 1 SD scenario
    as a result of changes in lifting condensation level due to higher temperatures,
    which results in more fog capture on exposed ridges in the band between the former
    and new maximum lifting condensation levels, while less fog interception occurs
    at lower elevations as a result of a higher cloud base level. Annual total snow
    and ice melt decreases for all scenarios as a result of precipitation falling
    as rain instead of snow due to higher temperatures, and this is reflected in the
    observed decrease in the snowfall model output. Therefore, in all scenarios except
    A1B – 1 SD, the water balance becomes more rainfall-dominated (with less influence
    of snowmelt). Under baseline conditions, around 60% of the water balance derives
    from rainfall, which increases to 70–75% for the mean of all models and mean +
    1SD scenarios. It should be noted that meltwater production in the model combines
    melt from new snowfall as well as glacial and snowpack melt. The contribution
    of glacial melt is not output as a separate variable. Declines in meltwater production
    are mostly attributable to reductions in snowfall. This means that reductions
    in snowmelt are as much a function of changes in precipitation as they are of
    changes in temperature in the short term, until an equilibrium with the new temperature
    has been established. Given the uncertainties in precipitation projections by
    GCMs for this and any other high mountain area (Buytaert et al., 2010; Ramirez
    & Jarvis, 2010), the resulting impacts on changes in meltwater are also highly
    uncertain. Seasonal changes The results in Table 2 describe the annual impacts
    of climate change on the water balance, but since the supply of water resources
    in this region is highly seasonal, it is necessary to assess changes in seasonality
    of the various fluxes. Under baseline conditions the hydrology in the basin is
    governed by highly seasonal precipitation, with 80% of rain falling in the wet
    season (October–April), meaning that stores such as glaciers are required to sustain
    streamflow in the dry season. However, changes in precipitation under climate
    change could either increase or reduce this seasonality. To assess shifts in seasonality
    for the Rio Santa basin for all water balance fluxes, the seasonality index of
    Walsh and Lawler ( 1981), modified to handle negative values (by offsetting by
    the minimum so that all negatives become positive), was calculated using WaterWorld
    for the baseline and for the climate change scenarios for comparison. An index
    over 0.4 is considered seasonal, over 0.8 marked seasonal with a long dry season,
    and over 1.2 extreme seasonal, with almost all water available in one or two months.
    Table 3 shows the basin-average index values as well as the direction of change
    from the baseline, indicated by up and down arrows. Changes in water balance seasonality
    are minor at the basin scale, with three scenarios showing an increase and three
    scenarios showing a decrease, although none of the values are considered highly
    seasonal. In general, small increases in water balance seasonality can be found
    in the uplands and small decreases at lower elevations. Rainfall seasonality,
    however, is already seasonal under the baseline, and this seasonality is projected
    to decrease at the basin scale for the multi-GCM mean scenarios as well as the
    multi-GCM mean + 1 SD scenarios. This effectively means that the increase in basin
    average precipitation seen in Table 2 and Figure 3a is more evenly distributed
    throughout the year than current precipitation. Table 3. Seasonality statistics
    for baseline and scenarios and direction of change. All increases compared to
    baseline indicated in grey. Download CSVDisplay Table Figure 3. a-d: Seasonal
    distribution and variability of a) precipitation, b) temperature and the basin
    runoff the ensemble climate change scenarios c) A1B and d) A2A. Red dots (a and
    b) represent the baseline precipitation and temperature. Grey areas (c and d)
    represent the range between the upper (+SD) and lower (-SD) scenarios for basin
    runoff. Display full size Snowfall and meltwater are extremely seasonal but are
    projected to become more so under all climate change scenarios, since snowfall
    and snowmelt occur over a shorter time period, with significant melt on average
    occurring in only two to three months, compared to six in the baseline. However,
    their impact on catchment average water balance is low, so their impact on catchment
    average water balance seasonality is also low. Figures 3c and 3d show the impacts
    of the changing water balance fluxes on runoff at the outlet of the basin for
    the A1B and A2A mean scenarios, respectively, with the mean + 1 SD and mean –
    1 SD scenarios representing the boundaries of the potential range of runoff under
    these scenarios. Figures 3a and 3b show the variability of (a) precipitation and
    (b) temperature projections for all scenarios. Both A1B and A2A mean scenarios
    result in more runoff from the basin for nearly all months, with A1B showing more
    uncertainty in the wet season while the A2A scenarios have a wider range in the
    dry season. The majority of the range of projections for both A1B and A2A scenario
    sets show a tendency towards increased runoff in the dry season as a result of
    increased precipitation in those months. Implications for water resources So far
    all results have been presented as basin-wide averages. However, water resource
    availability varies significantly throughout the basin, as does demand. To assess
    the implications of climate change for water supply, including changes in meltwater
    contribution, total streamflow and meltwater-generated streamflow, two of the
    largest, most populous high-altitude cities in the basin were identified: Caraz
    (population of ca. 13,000) and Huaraz (population of ca. 96,000). For these locations,
    runoff and contributions to it for the baseline and for the climate change scenarios
    were analyzed (see Figure 1 for locations). Furthermore, to assess the impact
    of changes in meltwater contribution to basin outflow, modelled streamflow and
    meltwater contribution near the outflow of the Santa River into the Pacific was
    analyzed. Table 4 shows the annual total streamflow, meltwater-generated streamflow
    and the proportion of total streamflow derived from meltwater for these areas.
    The contribution of meltwater to total streamflow diminishes for all scenarios,
    but overall streamflow volume is projected to increase for all mean and mean +
    1 SD scenarios. Under baseline conditions, the proportion of snow and ice melt
    in the streamflow at Huaraz and Caraz is more than 10%, while for all climate
    change scenarios this decreases to below 10% for the A2A scenarios (2.7% and 6.5%
    for Huaraz and Caraz, respectively, for the mean of all models scenario) and well
    below 10% for the A1B scenarios (2.6% and 1.2% for Huaraz and Caraz ,respectively,
    for the mean of all models scenario). Baseline meltwater contribution to streamflow
    at the basin outlet is around 5%, which decreases to a maximum of 1.6% under projected
    climate change. Table 4. Percentage of snowmelt-generated runoff (Q) at cities
    of Caraz and Huaraz and at Santa outflow under different multi-model climate change
    scenarios. All increases compared to baseline indicated in grey. Download CSVDisplay
    Table Policy implications The results of this analysis are a clear indication
    that projected climate change across a wide range of scenarios generally leads
    to increased water availability for the Rio Santa basin and a trend towards runoff
    being more rainfall-dominated, particularly in the dry season. Though snowmelt
    increases, rainfall increases more, so the relative contribution of snowmelt lessens.
    However, projections of precipitation by GCMs are highly uncertain, particularly
    for a highly heterogeneous landscape such as the Andes mountain range (Buytaert,
    Celleri, & Timbe, 2009; Ramirez & Jarvis, 2010). This is clear from our different
    ensemble summaries (mean, mean + 1 SD, and mean – 1 SD), which show very different
    results. Therefore, to best deal with this unpredictability and uncertainty in
    future streamflow, more and better-distributed storage and distribution systems,
    alongside efficient water use, are essential. This analysis did not take into
    account groundwater stores, even though a number of studies have demonstrated
    that groundwater contributions in small glacier-dominated sub-watersheds of the
    Santa Basin are proportionally as important as glacier melt for dry-season streamflows
    (Baraer et al., 2015; Gordon et al., 2015; Mark, 2010). WaterWorld assumes groundwater
    stores to be in equilibrium in the long term as it uses a long-term climatology
    and groundwater resources at these timescales are controlled by the long-term
    water balance. In reality, a projected reduction or increase of water balance
    because of the combined impacts on precipitation, evapotranspiration and snowmelt
    will thus affect both runoff and groundwater stores in the same direction. Therefore,
    under those scenarios that project overall increases in water balance (four of
    the six scenarios), it is likely that groundwater stores will be adequately replenished
    and can thus act as seasonal buffers, whereas the reverse might be true for scenarios
    projecting a decrease in water balance. While groundwater stores are important
    for freshwater resources in the region, they cannot replace the storage function
    of current snow and ice. With the disappearance of these stores, new storage solutions
    that can provide a buffer against seasonal shortage should be considered. This
    could include small reservoirs, modified lakes and household-scale water storage
    systems (Vuille, 2008; McKinney, Anderson, & Byers, 2011). A recognition of the
    potential of natural infrastructure for harnessing and storing glacial and snow
    meltwater, particularly at high altitudes, is therefore required in policy and
    implementation institutions. In addition, targeted investments in physical water
    infrastructure can increase resilience to uncertain climate changes by regulating
    water flows. On the demand side, policies aimed at changes in irrigation practices
    and shifts in crop types and varieties could lead to diminished water demand and
    less competition in times of low supply. The continuing population growth, however,
    will increase domestic demands year-round, as will agricultural, hydropower and
    mining water users, who are all dependent on reliable water flows throughout the
    year. To balance these competing demands amongst all water users in the basin
    necessitates watershed-level dialogue between all upstream and downstream water
    users. The range of possible outcomes of climate change highlighted in this study
    require policies aimed at creating capacity to respond to such changing and unpredictable
    conditions and strategies that are robust under the full range of possible future
    scenarios: in short a focus on adaptability rather than a specific adaptation
    per se. Conclusions Impacts of climate change on water resources are extremely
    difficult to project, particularly in a highly heterogeneous landscape such as
    the Peruvian Andes. The uncertainties in projections by GCMs, particularly for
    precipitation, lead to a wide range of possible outcomes for water resources even
    for the same emissions scenario. Model simulations with the WaterWorld model and
    climate change scenarios that encompass a very broad range of projections for
    the Santa Basin show a general trend towards an increase in water availability
    as a result of projected increases in precipitation. This is in contrast to previous
    studies that examined the impact of temperature increases on snow and ice alone
    (Chevallier et al., 2011; Pouyaud et al., 2005). Although the level of uncertainty
    around glacial retreat with warming is already high, if studies do not examine
    the impact of precipitation change then impacts on water resources are not fully
    accounted for. Although impacts on precipitation change are even more uncertain,
    they have to be considered alongside snow and ice melt in basins like the Santa.
    Higher temperatures lead to less snowfall (more precipitation falls as rain),
    and thus less snowpack accumulation, ultimately producing decreases in snow melt
    volumes (even though the per-unit-area rate of melting of the snowpack may increase
    with warming, the extent of the snowpack – and thus total snowmelt – declines).
    This leads to a more rainfall-dominated hydrological system at the basin scale
    and also at critical sites of water demand (for example key cities). A more rainfall-dominated
    system is more prone to short-onset drought in response to monthly rainfall than
    one fed from snow and ice stores that respond to longer-term accumulation and
    melt dynamics. Seasonal water availability is likely to be affected, but the projected
    decreases in water storage in glaciers and snowpack are potentially offset by
    an increase in direct runoff from greater rainfall in the dry season. The very
    high uncertainties associated with climate change in these environments necessitate
    basin-wide policies aimed at increased adaptability, and the development of adaptive
    capacity to respond to such changing conditions, including through demand-side
    management. Simplistic notions of climate change leading to drying-up of Andean
    water supplies as a result of deglaciation have to be considered within the context
    of projected changes in precipitation and in the partitioning of precipitation
    between rain and snow, as well as the commonly studied impact of warming on snow
    and ice melt. Without the former, studies on the latter alone can be highly misleading.
    Disclosure statement No potential conflict of interest was reported by the authors.
    Supplemental data The supplemental material for this article is available online
    at http://dx.doi//10.1080/07900627.2016.1259101. Supplemental material Supplemental
    data.pdf Download PDF (270 KB) Acknowledgements The WaterWorld Policy Support
    System has been developed over many years under a wide range of EU and other funding
    sources, including the CGIAR Challenge Programme on Water and Food BFPANDES and
    the AN3 COMPANDES project under which this study was carried out. The programme
    and its donors are gratefully acknowledged. The many providers of global data-sets
    used in WaterWorld are also gratefully acknowledged. References Andres, N., Vegas
    Galdos, F., Lavado Casimiro, W. S., & Zappa, M. (2014). Water resources and climate
    change impact modelling on a daily time scale in the Peruvian Andes. Hydrological
    Sciences Journal, 59, 2043–2059.10.1080/02626667.2013.862336  Web of Science ®Google
    Scholar Baraer, M., McKenzie, J., Mark, B. G., Gordon, R., Bury, J., Condom, T.,
    … Fortner, S. K. (2015). Contribution of groundwater to the outflow from ungauged
    glacierized catchments: A multi-site study in the tropical Cordillera Blanca.
    Hydrological Processes, 29, 2561–2581.10.1002/hyp.v29.11  Web of Science ®Google
    Scholar Buytaert, W., Celleri, R., Timbe, L. (2009). Predicting climate change
    impacts on water resources in the tropical Andes: Effects of GCM uncertainty.
    Geophysical Research Letters, 36.  Web of Science ®Google Scholar Buytaert, W.,
    Vuille, M., Dewulf, A., Urrutia, R., & Karmalkar, A. (2010). Uncertainties in
    climate change projections and regional downscaling in the tropical Andes: Implications
    for water resources management. Hydrology and Earth System Sciences, 14, 1247–1258.10.5194/hess-14-1247-2010  Web
    of Science ®Google Scholar CGIAR Research Program on Water, Land and Environment.
    (2014). Summary of CPWF research in the Andean system of river basins. Retrieved
    from https://cgspace.cgiar.org/handle/10568/35113  Google Scholar Chevallier,
    P., Pouyaud, B., Suarez, W., & Condom, T. (2011). Climate change threats to environment
    in the tropical Andes: Glaciers and water resources. Regional Environmental Change,
    11, 179–187.  Web of Science ®Google Scholar Condom, T., Escobar, M., Purkey,
    D., Pouget, J. C., Suarez, W., Ramos, C., & Apaestegui, J. (2012). Simulating
    the implications of glaciers’ retreat for water management: A case study in the
    Rio Santa basin. Water International, 37, 442–459.10.1080/02508060.2012.706773  Web
    of Science ®Google Scholar Gordon, R. P., Lautz, L. K., McKenzie, J. M., Mark,
    B. G., Chavez, D., & Baraer, M. (2015). Sources and pathways of stream generation
    in tropical proglacial valleys of the Cordillera Blanca, Peru. Journal of Hydrology,
    522, 628–644.10.1016/j.jhydrol.2015.01.013  Web of Science ®Google Scholar Hijmans,
    R. J., Cameron, S. E., Parra, J. L., Jones, P. G., & Jarvis, A. (2005). Very high
    resolution interpolated climate surfaces for global land areas. International
    Journal of Climatology, 25, 1965–1978.10.1002/(ISSN)1097-0088  Web of Science
    ®Google Scholar Huggel, C., Scheel, M., Albrecht, F., Andres, N., Calanca, P.,
    Jurt, C., … Zappa, M. (2015). A framework for the science contribution in climate
    adaptation: Experiences from science-policy processes in the Andes. Environmental
    Science & Policy, 47, 80–94.10.1016/j.envsci.2014.11.007  Web of Science ®Google
    Scholar Juen, I. (2007). Modelling observed and future runoff from a glacierized
    tropical catchment (Cordillera Blanca, Peru). Global and Planetary Change, 59,
    37–48.10.1016/j.gloplacha.2006.11.038  Web of Science ®Google Scholar Kaser, G.,
    & Georges, C. (1999). On the mass balance of low latitude glaciers with particular
    consideration of the Peruvian Cordillera Blanca. Geografiska Annaler, Series A:
    Physical Geography, 81, 643–651.10.1111/geoa.1999.81.issue-4  Google Scholar Kaser,
    G., Juen, I., Georges, C., Gómez, J., & Tamayo, W. (2003). The impact of glaciers
    on the runoff and the reconstruction of mass balance history from hydrological
    data in the tropical Cordillera Blanca. Journal of Hydrology, 282, 130–144.10.1016/S0022-1694(03)00259-2  Web
    of Science ®Google Scholar Lavado Casimiro, W. S., Labat, D., Guyot, J. L., Ronchail,
    J., Ordonez, J. J., Yilmaz, K. K., & Pomeroy, J. (2009). TRMM rainfall data estimation
    over the Peruvian Amazon-Andes basin and its assimilation into a monthly water
    balance model. In New approaches to hydrological prediction in data-sparse regions.
    Proceedings of Symposium HS. 2 at the Joint Convention of The International Association
    of Hydrological Sciences (IAHS) and The International Association of Hydrogeologists
    (IAH), held in Hyderabad, India, 6-12 September 2009. (pp. 245–252). IAHS Press.  Google
    Scholar Lynch, B. D. (2012). Vulnerabilities, competition and rights in a context
    of climate change toward equitable water governance in Peru’s Rio Santa Valley.
    Global Environmental Change, 22, 364–373.10.1016/j.gloenvcha.2012.02.002  Web
    of Science ®Google Scholar Mark, B. G. (2010). Climate change and tropical andean
    glacier recession: Evaluating hydrologic changes and livelihood vulnerability
    in the Cordillera Blanca, Peru. Annals of the Association of American Geographers,
    100, 794–805.10.1080/00045608.2010.497369  Web of Science ®Google Scholar Mark,
    B. G., McKenzie, J. M., & Gomez, J. (2005). Hydrochemical evaluation of changing
    glacier meltwater contribution to stream discharge: Callejón de Huaylas, Peru.
    Hydrological Sciences, 50, 975–987.  Web of Science ®Google Scholar McKinney,
    D. C., Anderson, G., & Byers, A. (2011). Adaptation to climate change: Case study
    - glacial retreat and adaptation options in Peru’s rio Santa basin. International
    Resources Group (IRG). Retrieved from http://www.caee.utexas.edu/prof/mckinney/Peru/Peru%20Case%20Study%20Jul2011_v6_Draft_Final.pdf.  Google
    Scholar Met Office. (2011). Climate: Observations, projections and impacts. Retrieved
    from http://eprints.nottingham.ac.uk/2040/18/Peru.pdf  Google Scholar Mulligan,
    M. (2006). Estimates mean snow water equivalent. Retrieved from http://www.policysupport.org/simterra  Google
    Scholar Mulligan, M. (2011). Simterra: A consistent global gridded database of
    environmental properties for spatial modelling. Retrieved from http://www.policysupport.org/simterra
    [based on multiple sources].  Google Scholar Mulligan, M. (2013a). WaterWorld:
    A self-parameterising, physically-based model for application in data-poor but
    problem-rich environments globally. Hydrology Research, 44, 748–769.10.2166/nh.2012.217  Web
    of Science ®Google Scholar Mulligan, M. (2013b). WaterWorld v2.x documentation.
    Retrieved from http://www.policysupport.org/waterworld.  Google Scholar Mulligan,
    M., Burke, S. (2005). FIESTA fog interception for the enhancement of streamflow
    in tropical areas. Final technical report for AMBIOTEK contribution to DFID FRP
    R7991.  Google Scholar Murphy, J. M., Sexton, D. M. H., Barnett, D. N., Jones,
    G. S., Webb, M. J., Collins, M., & Stainforth, D. A. (2004). Quantification of
    modelling uncertainties in a large ensemble of climate change simulations. Nature,
    430, 768–772.10.1038/nature02771  PubMed Web of Science ®Google Scholar Nakicenovic,
    N., Alcamo, J., Davis, G., De Vries, B., Fenhann, J., Gaffin, S., ... La Rovere,
    E. L. (2000). Special report on emissions scenarios, Working Group III, Intergovernmental
    Panel on Climate Change (IPCC). Cambridge, UK: Cambridge University Press.  Google
    Scholar Pouyaud, B., Zapata, M., Yerren, J., Gomez, J., Rosas, G., Suarez, W.,
    & Ribstein, P. (2005). Avenir des ressources en eau glaciaire de la Cordillère
    Blanche [On the future of the water resources from glacier melting in the Cordillera
    Blanca, Peru]. Hydrological Sciences Journal, 50, 999–1022.  Web of Science ®Google
    Scholar Racoviteanu, A. E., Arnaud, Y., Williams, M. W., & Ordoñez, J. (2008).
    Decadal changes in glacier parameters in the Cordillera Blanca, Peru, derived
    from remote sensing. Journal of Glaciology, 54, 499–510.10.3189/002214308785836922  Web
    of Science ®Google Scholar Ramirez, J., Jarvis, A. (2010). Disaggregation of Global
    Circulation Model outputs. Decision and policy analysis working paper no.2. Retrieved
    from http://www.ccafs-climate.org/media/ccafs_climate/docs/Disaggregation-WP-02.pdf  Google
    Scholar Sivapalan, M., Blöschl, G., Zhang, L., & Vertessy, R. (2003). Downward
    approach to hydrological prediction. Hydrological Processes, 17, 2101–2111.10.1002/hyp.v17:11  Web
    of Science ®Google Scholar Solomon, S. (Ed.). (2007). Climate change 2007. The
    physical science basis, working group I contribution to the fourth assessment
    report of the intergovernmental panel on climate change (Vol. 4). Cambridge, UK:
    Cambridge University Press.  Google Scholar Viviroli, D., Zappa, M., Gurtz, J.,
    & Weingartner, R. (2009). An introduction to the hydrological modelling system
    PREVAH and its pre- and post-processing-tools. Environmental Modelling & Software,
    24, 1209–1222.10.1016/j.envsoft.2009.04.001  Web of Science ®Google Scholar Vuille,
    M., Bradley, R. S., Werner, M., & Keimig, F. (2003). 20th century climate change
    in the tropical Andes: Observations and model results. In H. F. Diaz (Ed.), Climate
    variability and change in high elevation regions: Past, present & future (pp.
    75–99). Dordrecht: Springer.  Google Scholar Vuille, M., Francou, B., Wagnon,
    P., Juen, I., Kaser, G., Mark, B. G., & Bradley, R. S. (2008). Climate change
    and tropical Andean glaciers: Past, present and future. Earth Science Reviews,
    89, 79–96.10.1016/j.earscirev.2008.04.002  Web of Science ®Google Scholar van
    Vuuren, D. P., Edmonds, J., Kainuma, M., Riahi, K., Thomson, A., Hibbard, K.,
    & Hurtt, George C. (2011). The representative concentration pathways: An overview.
    Climatic Change, 109, 5–31.10.1007/s10584-011-0148-z  Web of Science ®Google Scholar
    Walsh, R. P. D., & Lawler, D. M. (1981). Rainfall seasonality: Description, spatial
    patterns and change through time. Weather, 36, 201–208.10.1002/wea.1981.36.issue-7  Google
    Scholar Walter, M. T., Brooks, E. S., McCool, D. K., King, L. G., Molnau, M.,
    & Boll, J. (2005). Process based snowmelt modelling: Does it require more input
    data than temperature index modelling? Journal of Hydrology, 300, 65–75.10.1016/j.jhydrol.2004.05.002  Web
    of Science ®Google Scholar Ward, E., Buytaert, W., Peaver, L., & Wheater, H. (2011).
    Evaluation of precipitation products over complex mountainous terrain: A water
    resources perspective. Advances in Water Resources, 34, 1222–1231.10.1016/j.advwatres.2011.05.007  Web
    of Science ®Google Scholar WGMS, NSIDC. (1989/2012). updated. World glacier inventory.
    Compiled and made available by the World Glacier Monitoring Service, Zurirch,
    Zwitserland, and the National Snow and Ice Data Center, Boulder CO, USA.  Google
    Scholar Wilby, R. L., Charles, S. P., Zorita, E., Timbal, B., Whetton, P., & Mearns,
    L. O. (2004). Guidelines for use of climate scenarios developed from statistical
    downscaling methods. IPCC Task Group on Data and Scenario Support for Impact and
    Climate Analysis (TGICA). Retrieved from http://ipcc-ddc.cru.uea.ac.uk/guidelines/index.html  Google
    Scholar Yates, D. N., Sieber, J., Purkey, D. R., & Huber-Lee, A. (2005). WEAP21
    – A demand-, priority-, and preference-driven water planning model part 1: Model
    characteristics. Water International, 30, 487–500.10.1080/02508060508691893  Web
    of Science ®Google Scholar Download PDF X Facebook LinkedIn Email Share   Related
    research  People also read Recommended articles Cited by 7 Water resources and
    climate change impact modelling on a daily time scale in the Peruvian Andes Norina
    Andres et al. Hydrological Sciences Journal Published online: 23 Sep 2014 Information
    for Authors R&D professionals Editors Librarians Societies Open access Overview
    Open journals Open Select Dove Medical Press F1000Research Opportunities Reprints
    and e-prints Advertising solutions Accelerated publication Corporate access solutions
    Help and information Help and contact Newsroom All journals Books Keep up to date
    Register to receive personalised research and resources by email Sign me up Copyright
    © 2024 Informa UK Limited Privacy policy Cookies Terms & conditions Accessibility
    Registered in England & Wales No. 3099067 5 Howick Place | London | SW1P 1WG     Cookies
    Button About Cookies On This Site We and our partners use cookies to enhance your
    website experience, learn how our site is used, offer personalised features, measure
    the effectiveness of our services, and tailor content and ads to your interests
    while you navigate on the web or interact with us across devices. By clicking
    "Continue" or continuing to browse our site you are agreeing to our and our partners
    use of cookies. For more information seePrivacy Policy CONTINUE'
  inline_citation: null
  journal: International Journal of Water Resources Development
  limitations: 'The paper assumes continuous operation of the automated irrigation
    systems and does not examine the potential impacts of system downtime or disruptions
    on crop yields. Additionally, it does not consider the specific costs or economic
    benefits of implementing automated irrigation systems, which can be important
    factors in decision-making.


    Furthermore, the study is based on historical climate data and does not account
    for potential changes in future climate patterns and the impact these changes
    may have on the effectiveness of automated irrigation systems.'
  pdf_link: null
  publication_year: 2016
  relevance_score: 0.7
  relevance_score1: 0
  relevance_score2: 0
  title: Potential outcomes of multi-variable climate change on water resources in
    the Santa Basin, Peru
  verbatim_quote1: '"Water resources in the Santa Basin in the Peruvian Andes are
    increasingly under pressure from climate change and population increase. Impacts
    of temperature-driven glacier retreat on streamflow are better studied than those
    of precipitation changes, yet present and future water resources are mostly dependent
    on precipitation, which is more difficult to predict with climate models."'
  verbatim_quote2: '"This study combines a broad range of projections from climate
    models with a hydrological model (WaterWorld), showing a general trend towards
    an increase in water availability due to precipitation increases over the basin.
    However, high uncertainties in these projections necessitate basin-wide policies
    aimed at increased adaptability."'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1109/cloud.2014.101
  analysis: 'The paper explores the practical implications and potential advantages
    of cloud computing, distributed processing, and big data technologies in the context
    of agricultural decision-making support systems. Specifically, the Big Weather
    solution integrates these technologies to enable the processing and analysis of
    large-scale climate-related datasets for decision-making in agriculture. The findings
    suggest that the integration of Hadoop and cloud computing can improve performance
    and scalability in handling big data in distributed environments.


    Relevance to Point:

    The paper addresses the use of different data types and their collection and use
    in automated irrigation management systems. It discusses the integration of large-scale
    climate-related datasets into the decision-making process for agricultural production.'
  authors:
  - Walter Akio Goya
  - Marcelo Risse de Andrade
  - Artur Carvalho Zucchi
  - Nelson Mimura Gonzalez
  - Rosangela de Fátima Pereira
  - Karen Langona
  - Tereza Cristina de Carvalho
  - Jan-Erik Mångs
  - Azimeh Sefidcon
  citation_count: 5
  full_citation: null
  full_text: '>

    This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org
    IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal
    Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln
    Sign Out All Books Conferences Courses Journals & Magazines Standards Authors
    Citations ADVANCED SEARCH Conferences >2014 IEEE 7th International C... The Use
    of Distributed Processing and Cloud Computing in Agricultural Decision-Making
    Support Systems Publisher: IEEE Cite This PDF Walter Akio Goya; Marcelo Risse
    de Andrade; Artur Carvalho Zucchi; Nelson Mimura Gonzalez; Rosangela de Fatima
    Pereira; Karen Langona; Tereza Cristina Melo de Brito Carvalho All Authors 6 Cites
    in Papers 422 Full Text Views Abstract Document Sections I. Introduction II. Related
    Works III. Big Data and Distributed Processing IV. Big Weather: Distributed Processing
    Solution V. Tests and Results Show Full Outline Authors Figures References Citations
    Keywords Metrics Footnotes Abstract: One of the main challenges in agriculture
    is to sustainably meet the demand for food while preserving natural resources
    for future productions. Information Technology can assist producers to make better
    decisions by providing them with data and tools that enhance decision-making process,
    consequently allowing better management of the natural resources. Cloud-computing
    platforms and the extraction of data available on public weather related data
    sets allow the development of web applications that can assist producers with
    their investing and planning decisions. This paper describes the Big Weather solution,
    an agricultural decision-making support system that utilizes a cloud-computing
    platform, distributed processing technologies, and a big data framework. This
    paper also presents Big Weather architecture and an example of metric calculations
    (average temperature and humidity) and discusses the performance of the solution
    when tested in different virtual machine scenario configurations. The novelty
    is the transparency of the framework, which allows farmers to make better decisions
    based on data available on the cloud. Published in: 2014 IEEE 7th International
    Conference on Cloud Computing Date of Conference: 27 June 2014 - 02 July 2014
    Date Added to IEEE Xplore: 04 December 2014 ISBN Information: ISSN Information:
    DOI: 10.1109/CLOUD.2014.101 Publisher: IEEE Conference Location: Anchorage, AK,
    USA SECTION I. Introduction Agriculture plays a crucial role in economic development.
    It is the backbone of many countries'' economic systems around the world. Agriculture
    not only provides food and raw material but also employment opportunities to a
    very large portion of the population. In the last 50 years, world population has
    been increasing and according to the United States Census Bureau is estimated
    to reach 7.09 billion by the end of 2013 [2]. Being able to meet the demand for
    food while maintaining soil fertility, dealing with water shortage in many parts
    of the world [1], controlling pests and diseases that are affecting crops and
    livestock, meeting the increasingly rigorous standards for quality and food safety,
    applying sustainable techniques to crop production represent great challenges
    to be overcome in the 21 st century. According to the Finnish Meteorological Institute,
    agricultural activities are very sensitive to climate and weather [7]. From temperature,
    solar radiation, evaporation, wind speed, rainfall, relative humidity and evapotranspiration
    metrics is possible to characterize local agroclimatological aspects and gain
    insights to support decisions related to best plant or varieties to be cultivated
    on certain region. Developments in technology and the application of information
    technology to collect, store, and analyze data can contribute to global improvements
    in crop and livestock production and are great aiding tools to surpass the previously
    mentioned challenges. Information Technology can be applied to agriculture in
    many different ways, such as precision agriculture (or Precision Farming), spatially
    variable field operations [3], decision support agricultural systems (productivity,
    implementation and/or need of irrigation systems, rational use of pesticides,
    land acquisition), farmland soil moisture and temperature monitoring systems based
    on wireless sensor networks, and others. Today''s commodity hardware, ubiquitous
    computing (use of tablets, smartphones, and laptop computers), cloud-computing
    architecture, and open-source software bring big data processing into the reach
    of less well-resourced users. Big data analytics can reveal insights hidden previously
    by data too costly to process and high level of skills necessary to deal with
    the technology. This paper describes Big Weather, an agricultural decision-making
    support system that utilizes Hadoop framework to process large climate related
    data sets. Big Weather simplifies the usage of big data processing through a friendly
    and easy to use Web interface. It provides a high-level of abstraction to the
    user by shifting the installation, configuration, and application development
    complexities to the solution provider. The interface is accessible through any
    computing device able to connect to the Internet using a Web browser. In this
    paper, we also present performance analyses of distributed processing execution
    in different configurations of virtualized computing environments. The main contribution
    of this paper is to show through the development and test of a prototype that
    cloud computing, distributed processing and a big data framework could be used
    all together to offer a system that can support decision-making on agriculture.
    The novelty is to show that the framework and platform can be configured to work
    on a transparent way to the user. This type of system allows farmers to make better
    decisions based on data available on the cloud. The remainder of this paper is
    organized as follows. Section II presents the related works, section III explains
    big data and distributed processing concepts, section IV describes Big Weather
    solution, section V presents and analyzes the results collected from a test environment,
    and finally, section VI discusses the conclusions and proposes future work. SECTION
    II. Related Works Distributed processing frameworks such as Hadoop1 are widely
    used in big data analysis to meet performance demands [8], which are affected
    by business needs and service-level agreements. However, the use of a distributed
    processing framework still requires the setup of a computing cluster and involves
    numerous tasks related to software installation and configuration. Additionally,
    it implies the maintenance of this infrastructure and the management of updates
    and upgrades. All these activities are costly and demand specific knowledge potentially
    unrelated to the end-user''s business. These tasks can be delegated to other parties
    or services. A possible organization of these services is presented in Figure
    1. In a conventional scenario the user is responsible for the full stack of tasks.
    On the other hand, by adopting a specialized computing service, most of the infrastructural
    tasks are performed by the service provider. The user has only to generate data
    and choose the programs and algorithms to be used to process this data. Some examples
    for each service type: Infrastructure: Amazon Elastic Compute Cloud2 Rackspace
    Managed Cloud3. Cloud orchestration: OpenStack4 Eucalyptus5. Distributed cloud:
    Amazon Elastic MapReduce6, Cloud-era CDH7, IBM InfoSphere BigInsights78. Specialized
    computing: Big Weather, Eagle9, Climate Corp10. Eagle is a bioinformatics solution
    for management and analysis of genomic data. A Web interface is provided for researchers
    to upload, analyze and share data over the Web. Specialized tools are embedded
    to the solution, such as Ensembl11 (which produces genome databases and makes
    this information freely available online) and Galaxy12 (an open platform for data
    intensive biomedical research). The concept of offering specialized tools through
    Web interfaces is similar to the Big Weather solution, outsourcing the infrastructural
    tasks and providing ready-to-use analytics tools. Command line tools are also
    available for power users. Climate Corp. helps growers to manage weather risk,
    as 90% of crop losses are due to adverse weather. The agriculture analytics service
    is associated to an insurance solution for farmers to provide profit protection
    by complementing the federal crop insurance. The service generates a weather risk
    report based on crop, location, soil type, and target yield. Climate Corp. analyzes
    200 TB of historical data stored in Amazon S3. Each simulation uses over four
    thousand computing cores on Amazon Elastic MapReduce, considering ten thousand
    possible scenarios for each of the next 730 days. Five trillion data points are
    analyzed and 20 TB of uncompressed data is consumed [6]. All features are offered
    through easy-to-use Web interfaces. From academia there is a clear claim for decision
    support tools for crop production [9]. Attempts to develop such tools had limited
    success due to lack of farmer interest, as a consequence of the inherent software
    complexity and the need to fit working patterns and organizational structures.
    Farmers rely on non-linear decision models with continuous updating of plans,
    quick analysis, and incremental implementation [12]. Therefore, IT applications
    available to farmers do not suit their needs. In this regard the Big Weather solution
    is focused on offering simple, intuitive interfaces, and accessible from a multitude
    of devices using a simple Web browser. The operations require simple commands
    and the data input, and the user can continuously check the progress of the submitted
    job until it is finished, when the final results are displayed. SECTION III. Big
    Data and Distributed Processing Technological advances in communications, storage,
    and computing have allowed data to be obtained from several sources, such as social
    media sites, sensor networks, GPS signals, and mobile devices. Therefore, many
    types of data in unstructured form can be collected. Examples include log file,
    sensor data, audio, image, and video. Recent researches are focusing on discover
    and propose solutions able to leverage the value hidden into data and process
    very large data sets. In this scenario, emerges big data, a term applied to large
    amount of data sets that can not be handle using traditional software tools. The
    size refers to data that grows in a unprecedented rate [10]. Beyond the high volume,
    it is also associated with the vast variety and high velocity that data has to
    be collected and processed. Fig. 1: Services and task delegation Show All A wide
    range of benefits has been obtained from big data. Fraud detection, recommendation
    engines, risk management, and strategic decision making are some areas in which
    big data has been applied. A growing number of companies are starting to adopt
    this approach to gain business value, by extracting valuable information from
    their non-traditional data sources. However, even though it is a promising approach,
    information extraction process over big data is quite complex. It requires tools
    with capabilities to collect, store, search, process, analyze, and visualize large
    data sets. With respect to data storage and processing, these solutions are in
    general performed in a distributed environment. Typically it is adopted an horizontal
    scaling approach, where the processing is performed across a cluster. This provides
    a more affordable and elastic scenario, where computing resources can be added
    or removed on demand. Implement and execute a distributed application is noticeable
    more difficult than a serial [4]. This is caused by additional necessary management
    operations such as task co-ordination, scheduling, load balancing, and fault tolerance.
    If not handled correctly, these operations can dramatically reduce the performance
    of an application. Besides, when related to big data processing, these operations
    must be efficiently per-formed, since high performance is one of the key requirements
    for big data. One big data technology that efficiently performs these operations
    is Hadoop. Hadoop is an open source framework for distributed processing and storage
    of large data sets across a cluster. It has been widely adopted as the appropriate
    solution to batch processing of big data. Well-known enterprises such as Ya-hoo,
    eBay, Facebook, and Twitter are users of this solution. Hadoop supplies a transparent
    management of a distributed application. This abstraction is enabled by its core
    system, which consists of two main components: Hadoop Distributed File System
    (HDFS) and Hadoop MapReduce. Both solutions were inspired by two papers published
    by Google [5] [4]. HDFS is a reliable and scalable distributed file system for
    large data sets [11]. After uploading the data set files (CSV files) to HDFS,
    the data storage is performed by partitioning the data into blocks of equal size
    (64 MB by default) and distributing them over data nodes. This special file system
    provides fault tolerance by allocating replicas of a same block (3 by default)
    in different data nodes. This mechanism supports an automatic recovery of the
    file system in case of a node fail. The data processing on Hadoop is provided
    by MapReduce. This component has been applied in most big data technologies to
    solve several data-intensive computing problems. Its concept consists of dividing
    a problem into independent tasks to be processed in parallel. As depicted in Figure
    2, the processing is mainly performed by the following phases: map and reduce.
    1) Map Phase The number of map tasks assigned for a job is based on the number
    of the data blocks of the input data loaded into HDFS. Each of these tasks is
    executed in parallel over a particular block and produces an intermediate result
    of key-value pairs. 2) Reduce Phase The reduce phase has the function of copying,
    sorting and aggregating the intermediate data generated by map phase. Each list
    of values of each key is iterated, generating a result associated with the key.
    These operations produce an output file in HDFS, containing the final result of
    the application. These phases are implemented by user-defined functions and the
    iteration can be performed in a variety of ways (e.g., one map and one reduce,
    two maps and one reduce, two maps and two reduces). A typical Hadoop cluster follows
    a master/slave architecture. The master contains the NameNode and JobTracker.
    They act as the managers of HDFS and MapReduce, respectively. There is only one
    instance of the master per cluster. But on the other hand, there are several slave
    nodes throughout the cluster. The distributed storage and processing are effectively
    performed on these nodes. Each slave node contains one instance of the DataNode
    and one of the TaskTracker. The first is responsible for storing data blocks assigned
    by the NameNode. The latter executes map and reduce tasks designated by the JobTracker.
    Fig. 2: Overview of a Mapreduce execution Show All SECTION IV. Big Weather: Distributed
    Processing Solution Hadoop simplifies the complexity existing in distributed programming
    such as scheduling, load balancing, data distribution’ and fault tolerance. Despite
    of this benefit, managing a Hadoop cluster and implementing a MapReduce application
    are still challenging activities. Service providers have been noticing an increase
    in the number of users interested in distributed processing services. Therefore,
    the tasks of setting up Hadoop environment for each scheduled job, providing job-execution
    status and making the results available become challenges to be overcomed by service
    providers. This section describes Big Weather architecture and its main modules,
    detailing the tasks automatization and the benefits of cloud-computing abstractions.
    A. Architecture Big Weather solution is composed by three main modules: Web Portal,
    Data Server and the Hadoop Cluster (storage and processing). Each of these modules
    is responsible for a specific part of the system. Figure 3 presents the interactions
    among the three modules. An interesting point to notice is that jobs are run in
    parallel on the same Hadoop cluster. Web Portal is a Web interface between users
    and the Big Weather solution. Some of the information the users can register are:
    high level parameters as data input (the climate data to be analyzed), specific
    information about the fields to be handled by the calculations, and the processing
    power to be applied (number of machines in the cluster). Figure 4 highlights the
    fields to be filled out by the user. Data Server is a repository where copies
    of the data provided by the users are stored. Big Weather solution uploads these
    data sets on HDFS cluster, increasing availability and allowing the use of MapReduce
    functions from Hadoop framework. Hadoop Cluster is a preconfigured cluster running
    HDFS and MapReduce software. The cluster processing power is selected by the user
    in the Web portal interface, by selecting the number of virtual machines to be
    utilized. Fig. 3: Big weather architecture Show All B. Cloud Computing: Multi-Layer
    System Features Sharing common computing resources using the same physical machines
    for different users/jobs can be accomplished by two different approaches: the
    first approach is to schedule the job execution requisitions in a queue and execute
    each one of them sequentially and the second one is to execute the job requisitions
    in parallel, running them on isolated virtual clusters using the physical machines
    as hosts to virtual machines guests. Big Weather allows users to choose between
    these two approaches. Figure 5 illustrates this feature, showing two different
    users running isolated Hadoop jobs on the same Hadoop Cluster (isolated connections
    represented by different line patterns). The solution has multi-service layers
    characteristics working mainly as Platform and Software as a Service (PaaS and
    SaaS, respectively). Platform as a Service (PaaS) Functionalities in order to
    setup Hadoop to run distributed processing is necessary to configure the machines
    that will be part of the storage and computing cluster. Using the Web portal interface,
    users can choose different configurations regarding to the number of virtual machines
    such as: a single virtual machine, two virtual machines, etc. The predefined configuration
    already implies in the separation of the different input folders for each different
    user and job request. Hence, facilitating the data management. Fig. 4: Web portal
    screenshot Show All Fig. 5: Cluster virtualization Show All Software as a Service
    (SaaS) Functionalities the abstraction of software framework services is provided
    by Hadoop MapReduce using applications developed in Java programming language.
    The application current settings allow calculations of average temperature and
    humidity from a large climate related data set, but it is easily extensible to
    calculate other metrics such as minimum, maximum, and evapotranspiration metrics.
    Figure 6, shows a sequence of the main screenshots from the Web portal interface:
    (A) user registration, (B) log-in, (C) job request, and (D) results. C. Job Execution
    Big Weather solution simplifies common execution tasks by automatically managing
    jobs from different owners. The five sequential steps necessary to complete a
    job processing are: 1) Configuring Slave Nodes in order to execute MapReduce calculations,
    firstly is necessary to setup the cluster to be utilized to store (HDFS) and process
    (MapReduce) the data sets. This task is performed by initially writting the host
    names of the selected slaves nodes in the “slaves” file in the Hadoop configuration
    folder. Then is necessary to instantiate and initialize all the selected virtual
    machines by starting the hadoop modules on each one of them. This setup time directly
    impacts the total time necessary to process the raw data. The more virtual machines
    selected to execute the calculations the faster the job will be finished. However,
    the number of computing nodes in a cluster is not the unique factor impacting
    the total processing time (Amdahl''s law). 2) Loading Data Sets to HDFS the second
    step is to copy the user data sets (CSV files) from the Big Weather Data Server
    to the HDFS Name Node. The Name Node divides this data into blocks and distributes
    them throughout the cluster (HDFS Data Nodes). Although this task can be time
    consuming, the data distribution needs to be performed only one time. Once stored,
    different jobs can be performed on the same data without requiring any additional
    actions. Fig. 6: Web portal screenshots Show All 3) Executing Mapreduce Job this
    step consists of processing a MapReduce job selected by the user among the options
    available on the Web portal. Each job contains a MapReduce program to solve a
    specific problem. Our current solution is able to calculate the average temperature
    and humidity. The goal is to provide relevant information that can assist producers
    in the decision-making process for agricultural production. 4) Reporting Job Progress
    in this step the user can follow the execution progress of the submitted job.
    This is performed by periodically reporting the job progress from Hadoop cluster
    to the Web portal interface. 5) Transferring Results to the Web Portal in the
    last step, a copy of the output data from HDFS is transferred to the Web portal
    interface. The final results are now accessible to the user, allowing the visualization
    and downloading of the results. D. Web Portal Interface Big Weather Web portal
    is implemented in Java programming language utilizing tools and functionalities
    from Java Server Faces 13 (JSF). JSF is a set of Web-based Graphical User Interface
    (GUI) controls with Ajax support. It simplifies the management of objects and
    Java Beans and the development of web pages. Furthermore, the Web portal has components
    of Prime-Faces14, a third-party JSF component library. PrimeFaces complements
    JSF adding rich and useful elements. Thereby, it is possible to build dynamic
    web pages that offer ease-to-use interfaces and a good experience to the final
    user. Big Weather Web portal runs its Java code on Apache ''Tomcat15, an open
    source web server and servlet container. Tomcat is designed based on Java Servlet
    and JavaServer Pages specifications. For storing user information, job history
    and job details, Big Weather Web portal uses MySQL 16, a relational database management
    and an open source software. SECTION V. Tests and Results In order to evaluate
    the integration of Hadoop and cloud computing we have configured a cloud infrastructure
    on a test environment. The test environment was created using a set of five identical
    Intel Xeon E3–1230 machines with 3.2 GHz and 16 GB of RAM memory. The tests were
    performed with the purpose of identifying areas related to integration of cloud
    computing and Hadoop that require further investigation. In terms of software,
    we have used KVM as the hypervisor, and libvirt to monitor and control the virtual
    machines. The Operating System used was Ubuntu 12.04 and the Apache Hadoop version
    was 2.2, the latest stable release available. The size of the HDFS blocks was
    configured to 128 MB. We have validated the performance of Hadoop on top of virtual
    machines by running a MapReduce job over a climate related data set. This data
    set was extracted from the Canadian National Climate Data and Information Archive
    17. It consists of more than 40 million records containing information about station
    number, timestamp, temperature, and humidity of a Canadian province. The data
    set contains non-structured hourly weather information collected from 190 stations,
    which some of them have historical data from over 50 years. The MapReduce job
    implemented calculates monthly average temperature and humidity for each Canadian
    province. The map function receives an input containing the temperature and humidity
    at a certain time of a province and outputs a set of key/value pairs. The key
    contains the province name and month of the temperature and humidity collected.
    The value contains the sum of the temperature and humidity and the number of times
    that each one was accounted. The reduce function receives the intermediate values,
    calculates the sum of the values associated with each key, and generates a final
    output containing the average monthly temperature and humidity of each province.
    We have used a dedicated virtual machine to serve as the master. All the virtual
    machines configured in the tests as slave node were responsible for storing (HDFS)
    and processing (MapReduce) a portion of the data set. To evaluate the best performance
    to run the jobs on virtual machines, we have compared the processing time of the
    job in several scenarios. To execute a MapReduce job, is necessary to send the
    data set to the HDFS throughout the slave machines, execute the map and reduce
    functions and transfer the output data from HDFS to another file system. In our
    tests we have considered only the time to process the map and reduce functions.
    The first test consists of comparing the processing time to process the job in
    a scenario with 4 virtual machines running on the same physical machine (illustrated
    in Figure 7), versus the scenario with the same number of virtual machines (Figure
    8), but having each one of them in different physical machines. Fig. 7: Scenario
    1 - virtual machines sharing the same physical machine Show All Figure 9 reports
    the results of this comparison. Although there is additional time to transfer
    computation across the network to other physical machines, using different physical
    machines to execute the job was 56% faster than executing the job over the slaves
    nodes on the same physical machine. In order to analyze the Hadoop scalability,
    we have performed a second test that consists of comparing the results obtained
    when more virtual machines are added to the cluster. The goal was to investigate
    whether Hadoop is able to improve the processing time when more virtual machines
    are integrated to the cluster. Therefore, we have tested the processing time of
    the MapReduce job execution using 4 physical machines with the following number
    of virtual machines in each one of them: 1, 2, 3, and 4. Figure 10 presents the
    results of the processing time of these executions. A performance improvement
    has been observed, as the number of virtual machines increases. Despite of the
    fact that the addition of virtual machines on the same physical machine decreased
    the processing time, this running approach requires an additional logic distribution
    of data blocks to maintain the fault-tolerance mechanism provided by Hadoop. Since
    all the virtual machines are in the same physical machine, the data distribution
    are allocated in the same disk space. Consequently, the data replication will
    not be able to recover the data if the physical machine fails. This problem could
    be solved by creating a mechanism that replicates each block in different physical
    machines. Fig. 8: Scenario 2 - virtual machines instantiated in different physical
    machines Show All Fig. 9: Processing time to execute the mapreduce job with 4
    virtual machines Show All Fig. 10: Processing time to execute the Mapreduce job
    by increasing the number of virtual machines in each physical machine Show All
    SECTION VI. Conclusions and Future Work In this paper we have described the Big
    Weather solution: an agricultural decision-making support system that can help
    farmers to improve their productivity based on climate related data. The solution
    offers new PaaS functionalities related to data management, by simplifying the
    cluster configuration and separating user and job requests folders. The results
    collected indicate relevant performance improvement by increasing the number of
    virtual machines running in a cluster. As future extensions, we are interested
    in replicating Big Weather solution in a cluster composed only by physical machines,
    collecting and comparing the same metrics analyzed in this paper in order to evaluate
    the consequences of virtualization in the cluster performance. ACKNOWLEDGMENTS
    This work was sponsored by the Re-search and Development Center, Ericsson Telecomunicações
    S.A., Brazil. Authors Figures References Citations Keywords Metrics Footnotes
    More Like This Energy-Efficient Statistical Live Virtual Machine Placement for
    Big Data Information Systems in Cloud Computing Environments 2015 IEEE International
    Conference on Smart City/SocialCom/SustainCom (SmartCity) Published: 2015 Cloud
    service oriented architecture (CSoA) for agriculture through internet of things
    (IoT) and big data 2017 IEEE International Conference on Electrical, Instrumentation
    and Communication Engineering (ICEICE) Published: 2017 Show More IEEE Personal
    Account CHANGE USERNAME/PASSWORD Purchase Details PAYMENT OPTIONS VIEW PURCHASED
    DOCUMENTS Profile Information COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION
    TECHNICAL INTERESTS Need Help? US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732
    981 0060 CONTACT & SUPPORT Follow About IEEE Xplore | Contact Us | Help | Accessibility
    | Terms of Use | Nondiscrimination Policy | IEEE Ethics Reporting | Sitemap |
    IEEE Privacy Policy A not-for-profit organization, IEEE is the world''s largest
    technical professional organization dedicated to advancing technology for the
    benefit of humanity. © Copyright 2024 IEEE - All rights reserved.'
  inline_citation: null
  journal: ''
  limitations: 'The study is limited to a test environment and may not fully reflect
    real-world scenarios.

    The paper focuses primarily on the technical aspects of data integration and processing,
    without delving into the specific agricultural applications and decision-making
    processes that utilize the data.'
  pdf_link: null
  publication_year: 2014
  relevance_score: 0.7
  relevance_score1: 0
  relevance_score2: 0
  title: The Use of Distributed Processing and Cloud Computing in Agricultural Decision-Making
    Support Systems
  verbatim_quote1: The solution offers new PaaS functionalities related to data management,
    by simplifying the cluster configuration and separating user and job requests
    folders.
  verbatim_quote2: The results collected indicate relevant performance improvement
    by increasing the number of virtual machines running in a cluster.
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1080/17538947.2022.2115567
  analysis: RSBD applications mainly include two types, data-separable computing and
    data-inseparable computing. For data-separable computing, parallelism can be easily
    implemented, and a simple batch computing paradigm can be applied. However, data-inseparable
    computing is more complex due to dependencies among computational tasks. Both
    MapReduce and array-based processing technologies are suitable for data-inseparable
    computing, but MapReduce lacks user friendliness and cannot meet the high computational
    requirements of data-intensive RSBD analysis. Array-based processing, which is
    more user-friendly and oriented to large-scale array processing, is a better option
    for data-inseparable computing. However, current array-based processing technologies
    have specific issues, such as high construction costs, technical challenges, and
    limited computational resources.
  authors:
  - Chen Xu
  - Xiaoping Du
  - Xiangtao Fan
  - Grégory Giuliani
  - Zhongyang Hu
  - Wei Wang
  - Jie Liu
  - Teng Wang
  - Zhenzhen Yan
  - Junjie Zhu
  - Tianyang Jiang
  - Huadong Guo
  citation_count: 11
  full_citation: '>'
  full_text: '>

    Access provided by University of Nebraska, Lincoln Log in  |  Register Cart Home
    All Journals International Journal of Digital Earth List of Issues Volume 15,
    Issue 1 Cloud-based storage and computing for re .... Search in:                                        This
    Journal                                                                                Anywhere                                                                  Advanced
    search International Journal of Digital Earth Volume 15, 2022 - Issue 1 Submit
    an article Journal homepage Open access 4,794 Views 2 CrossRef citations to date
    12 Altmetric Listen Articles Cloud-based storage and computing for remote sensing
    big data: a technical review Chen Xu , Xiaoping Du , Xiangtao Fan , Gregory Giuliani
    , Zhongyang Hu , Wei Wang , show all Pages 1417-1445 | Received 10 Jun 2022, Accepted
    17 Aug 2022, Published online: 24 Aug 2022 Cite this article https://doi.org/10.1080/17538947.2022.2115567
    In this article ABSTRACT 1. Introduction 2. Concerns and challenges 3. Cloud-based
    RSBD storage 4. Cloud-based RSBD computing 5. Conclusion Disclosure statement
    Additional information References Full Article Figures & data References Citations
    Metrics Licensing Reprints & Permissions View PDF View EPUB Formulae display:?
    ABSTRACT The rapid growth of remote sensing big data (RSBD) has attracted considerable
    attention from both academia and industry. Despite the progress of computer technologies,
    conventional computing implementations have become technically inefficient for
    processing RSBD. Cloud computing is effective in activating and mining large-scale
    heterogeneous data and has been widely applied to RSBD over the past years. This
    study performs a technical review of cloud-based RSBD storage and computing from
    an interdisciplinary viewpoint of remote sensing and computer science. First,
    we elaborate on four critical technical challenges resulting from the scale expansion
    of RSBD applications, i.e. raster storage, metadata management, data homogeneity,
    and computing paradigms. Second, we introduce state-of-the-art cloud-based data
    management technologies for RSBD storage. The unit for manipulating remote sensing
    data has evolved due to the scale expansion and use of novel technologies, which
    we name the RSBD data model. Four data models are suggested, i.e. scenes, ARD,
    data cubes, and composite layers. Third, we summarize recent research on the application
    of various cloud-based parallel computing technologies to RSBD computing implementations.
    Finally, we categorize the architectures of mainstream RSBD platforms. This research
    provides a comprehensive review of the fundamental issues of RSBD for computing
    experts and remote sensing researchers. KEYWORDS: Remote sensingbig datacloud
    computingdata cubeanalysis ready dataparallel computingdata model 1. Introduction
    The accumulation of historical archives and the advancement of sensors in recent
    years has led to an explosion of remote sensing datasets (Toth and Jóźków 2016;
    Zhu et al. 2019), which are often regarded as remote sensing big data (RSBD) (Ma
    et al. 2015) or big remotely sensed data (Casu et al. 2017). With the launch of
    Landsat 9 on 27 September 2021, the Landsat series of satellites has been continuously
    observing Earth for nearly 50 years (Masek et al. 2020; Roy et al. 2014). The
    Sentinel satellites from the European Space Agency (ESA) had acquired 24.87 petabytes
    of remote sensing data by the end of 2020 (Drusch et al. 2012). Series of high-resolution
    remote sensing satellites such as SPOT (French ‘Satellite pour l''Observation
    de la Terre’), Gaofen (Chinese high-resolution Earth imaging satellites), and
    IRS (Indian Remote Sensing Satellites) have been successively launched for various
    applications. Satellite data can be better leveraged and explored with the efforts
    of international organizations such as the Global Earth Observation System of
    Systems (Mhawish et al. 2021). RSBD has profoundly advanced remote sensing science,
    enabling a global perspective and a long-term historical view to re-conceptualize
    Earth (Guo et al. 2020). It not only expands the spatiotemporal scope of the study
    area but also stimulates a revolution in the remote sensing methodology. Over
    the past several decades, remote sensing research has gradually developed from
    qualitative remote sensing based on the statistical models of digital signal processing
    to quantitative remote sensing characterized by the consideration of physical
    models (Asrar et al. 1985; Liang 2003). Recently, remote sensing research has
    entered the data-driven era (Hey, Tansley, and Tolle 2009; Zhang et al. 2019),
    e.g. machine learning (Jordan and Mitchell 2015) and deep learning (Lecun, Bengio,
    and Hinton 2015). Most of all, with the progress of RSBD, an increasing number
    of researchers and engineers are working with RSBD, effectively contributing to
    research on global sustainable development, global climate, food security, natural
    disasters, agriculture, etc. (Allen et al. 2021; Gray et al. 2020; Moon, Kim,
    and Chan 2019; Liu et al. 2020; Neal et al. 2019). Although RSBD has a promising
    future, its technical implementation remains difficult, and the identification
    of current technical challenges facing RSBD remains a broad issue. Yang et al.
    ( 2017) identified eleven main challenges for implementing RSBD, including data
    storage, transmission, analysis, architecture, and quality. In addition, Chi et
    al. ( 2016) found three common challenges, including proper data identification
    and big data computing and collaboration. These challenges have been mainly induced
    by the dramatic increase in data volume, which far exceeds the capacity of conventional
    computing technologies. For instance, Hansen et al. ( 2013) mapped global forest
    gains and losses from 2000 to 2012 at a 30 m spatial resolution, processing 20
    terapixels of data. However, the manipulation of these massive datasets requires
    abundant human and material resources. As a result, only a few leading research
    institutions or companies have had access to RSBD, unfortunately leading to difficulty
    in leveraging RSBD and seriously restricting development. Cloud computing is a
    big data service delivered through the Internet (Yu et al. 2017; Armbrust et al.
    2010). It originated from E-commerce and social networks (Sakr et al. 2011), and
    has been widely applied to RSBD over the past several years (Varghese and Buyya
    2018). These applications include Google Earth Engine (GEE) (Tamiminia et al.
    2020), Microsoft Planetary Computer (‘Planetary Computer’ 2022), and Earth on
    Amazon Web Services (AWS) (‘Data and Information Access Services’ 2021). Cloud
    computing is underpinned by big data technology and mainly consists of five service
    models, including Software as a Service (SaaS), Platform as a Service (PaaS),
    Infrastructure as a Service (IaaS), Data storage as a Service (DaaS), and Function
    as a Service (FaaS) (Dillon, Wu, and Chang 2010). These services differ from previous
    computing technologies (e.g. high-performance computing) and make RSBD more accessible
    to the public. First, cloud computing typically relies on a set of commodity machines,
    and is usually priced as ‘pay-per-use’ and supports the elastic expansion of resources
    on-demand (Wang et al. 2010). As a result, the cost is much lower than sophisticated
    and expensive high-performance computers (Ferreira et al. 2020; Gupta et al. 2013).
    Second, cloud computing is delivered through the Internet, which helps the open
    sharing of remote sensing data and research, therefore promoting the progress
    of FAIR principles (findable, accessible, interoperable, and reusable) (Wilkinson
    et al. 2016). Third, a robust big data ecology has been formed around cloud computing
    after years of development, shielding users from the technicalities of massive
    computing. Thus, cloud computing helps RSBD researchers and engineers focus more
    on algorithms and analysis rather than being hindered by computer technology (Saxena
    et al. 2020). Fourth, cloud computing is suitable for data-intensive computing
    such as RSBD applications (Yang et al. 2019). The combination of cloud computing
    and remote sensing has proven to facilitate and promote RSBD. This has attracted
    a growing interest in remote sensing research as a potential solution for large-scale
    spatiotemporal analysis. Previous studies have evaluated the progress of cloud-based
    RSBD in terms of the acquisition, storage, computing, analysis, transmission,
    and visualization (Ma et al. 2015; Chi et al. 2016; Zhang, Zhou, and Luo 2021;
    Wang and Yan 2020) and in specific applications (Sarker et al. 2020; Balti et
    al. 2020; Qu et al. 2020). In this research, we performed a broad technical review
    of cloud-based RSBD storage and computing and summarized the key architectures
    of cloud-based RSBD platforms. Section 2 discusses four concerns posed by RSBD
    storage and computing, namely raster storage, metadata management, data homogeneity,
    and the computing paradigm. Section 3 and 4 review the available cloud-based technologies
    and our current understanding of RSBD storage and computing. Finally, Section
    5 provides the conclusion of the review. Overall, four data models, two computing
    types, four processing models, and five types of RSBD platform architectures are
    identified and discussed in this research, which broadly assesses state-of-the-art
    RSBD technologies and helps readers explore advanced RSBD. 2. Concerns and challenges
    2.1. Raster storage The volume of remote sensing data long ago stepped into the
    petabyte era and is moving towards the exabyte and zettabyte era. Conventionally,
    raster data is stored as arrays in multiple file formats, including the hierarchical
    data format (HDF) (MODIS), GeoTIFF (Landsat), and JP2000 (Sentinel-2). The size
    of a single dataset generally ranges from megabytes to terabytes. In addition,
    some cloud-based platforms store raster data as tiles in lightweight data formats
    (Yao et al. 2020) following grid discretization with Discrete Global Grid Systems
    (DGGS) for fast visualization and online computing. These include portable network
    graphics (PNG) and the Joint Photographic Experts Group (JPEG) image format. The
    unprecedented increase in remote sensing data poses severe challenges for RSBD
    raster data storage (Guo et al. 2020). First, the volume of RSBD far exceeds the
    capacity of standalone storage hardware, such as block storage or the redundant
    array of independent disks (RAID) (Gomes, Queiroz, and Ferreira 2020). Distributed
    storage systems (DFS, introduced in Section 3.1) can preserve petabytes of data
    (Lü et al. 2011). However, the storage cost is extremely high for both individuals
    and government departments. For instance, the United States Geological Survey
    (USGS) considered charging for access to widely used sources of remote sensing
    data (e.g. Landsat) in 2018 to recover costs from users (Popkin 2018). Second,
    the retrieval of array data generates costly operations due to the specificity
    of remote sensing data structures, leading to a decrease in I/O efficiency and
    an increase in access latency. These types of operations differ from conventional
    big data I/O operations and are rarely optimized by existing big data technologies
    (Zhao et al. 2018). For example, in the case of time-series analysis, remote sensing
    data are often scattered in several individual files/objects, resulting in numerous
    random access and expensive data transformations (Extract-Transform-Load). Consequently,
    data storage schemes need to be further developed to support big data storage
    technologies and remote sensing data. 2.2. Metadata management Remote sensing
    data comes with complex and vital metadata information. The full utilization of
    metadata is valuable for the reliability and quality of raster data. The management
    of remote sensing datasets must rely on metadata information, such as the band,
    resolution, capturing time, etc. In addition, the complete metadata describes
    essential information for tracing raster data quality, such as cloudiness and
    solar altitude, and ensuring the robustness and reliability of the subsequent
    analysis (Barsi et al. 2019). Several bottlenecks limit the use of complete metadata.
    First, there are substantial metadata entries for remote sensing datasets, and
    the quantity often exceeds the capacity of conventional metadata management systems.
    For example, the European Space Agency (ESA) Sentinel-2 product includes hundreds
    of metadata fields. Second, there are differences in metadata information formats.
    Generally, the metadata for remote sensing data is stored in the form of key-value
    pairs. However, some metadata, such as cloud masks and pixel quality assessments,
    are stored as vectors or rasters. Unfortunately, traditional metadata storage
    technologies do not support the management of unstructured metadata. Third, the
    metadata structures of the remote sensing data acquired from different sources
    are heterogeneous and lack a unified standard, leading to semantic ambiguities
    between datasets (Closa et al. 2019). Therefore, standards and management systems,
    such as the National Aeronautics and Space Administration’s (NASA) Unified Metadata
    Model (‘NASA Unified Metadata Model’ 2022), need to be formulated for metadata
    to ensure multi-source remote sensing data interoperability. These standards need
    to be developed and adapted for the novel RSBD applications emerging in the era
    of cloud computing (e.g. tile data retrieval, metadata queries). Therefore, it
    is crucial to implement the technology migration from big data to remote sensing
    metadata (Al-Yadumi et al. 2021). 2.3. Homogeneity The homogeneity of input data
    is essential for data mining (Yu et al. 2017), while heterogeneity is a common
    feature of big data (Wu et al. 2014). In Section 2.2, we mentioned the heterogeneous
    characteristics of metadata. However, the heterogeneity of raster data is more
    complex and essential, especially for multisource remote sensing data (Zhan et
    al. 2018; Pastor-Guzman et al. 2020). Specifically, we assess the homogeneity
    of remote sensing raster data in terms of two aspects. Homogeneity refers to the
    identical physical characteristics and quality of remote sensing data, such as
    the spectral meaning (e.g. central wavelength), processing level, accuracy, resolution,
    and projection. These characteristics can affect the accuracy and robustness of
    any subsequent analysis. Typically, heterogeneous data can be fixed during pre-processing
    (Young et al. 2017). However, pre-processing large amounts of data is difficult
    because some pre-processing steps still require manual intervention and cannot
    be executed in a fast and parallelized fashion (Rittger et al. 2021; Wei, Chang,
    and Bai 2020). Moreover, homogeneity restricts the integrity and continuity of
    remote sensing data in both the temporal and spatial dimensions. Spatiotemporal
    continuity is necessary for remote sensing analysis to ensure greater accuracy
    over a more extensive scale (Kuo et al. 2018). A remote sensing analysis with
    discontinuous data can lead to inconsistent results (Li and Long 2020). Nevertheless,
    continuity is commonly inaccessible over a large region of interest due to the
    specificity of remote sensing data acquisition modes and plans (Figure 1). Figure
    1. Composite NDVI map of Bangladesh based on Sentinel-2 L2A datasets. a) NDVI
    map with continuous remote sensing coverage. b) NDVI map with discontinuous remote
    sensing coverage due to cloud cover. Display full size It is a challenge to improve
    the types of homogeneity mentioned above, which relates to remote sensing science
    and big data processing. Specific data pre-processing theories and algorithms
    are needed for technical support. Recent research has made great efforts toward
    improving the homogeneity of remote sensing data, e.g. spatial–temporal data fusion
    (Liu et al. 2021; Zhu et al. 2018) and multi-source remote sensing data harmonization
    (Claverie et al. 2018). Additionally, corresponding computational technologies
    are expected to implement rapid homogenization for large remote sensing datasets
    (Guo et al. 2020; Gao et al. 2022). 2.4. Parallel computing Parallel computing
    simultaneously implements computation by dividing the main computation into smaller
    processes (Almasi and Gottlieb 1989). Parallel remote sensing computing lies at
    the core of RSBD, and enables the full exploitation of big data’s scalable computing
    capability. Previous reviews have described the processing in remote sensing computing
    as (Chi et al. 2016): Y = F ( X ) (1) where Y denotes the computing results, X
    is the input remote sensing dataset, and F is the mapping function that transfers
    the input datasets into the result. There is no need to consider implementing
    parallelized computing for a single-threaded application scenario. Therefore,
    Eq. (1) can be simplified as: Y = f ( X ) (2) where f refers to a single-threaded
    remote sensing algorithm. Eq. (2) is the most basic case. However, in a big data
    scenario, the scale of X may be huge and beyond the capacity of a standalone computing
    node. In this case, the computation needs to be simultaneously processed with
    more computational resources to reduce the overhead time cost. However, the parallelization
    execution strategies are largely different among algorithms. Therefore, it is
    not easy to find a generalized computational framework that can be adapted to
    all remote sensing analysis algorithms, such as Eq. (1) . RSBD analysis can be
    grouped into two types, data-separable computing and data-inseparable computing,
    to further decompose the problem and investigate different solutions. Data-inseparable
    computing cannot be parallelized by partitioning the data. This type of computing
    requires a large amount of global information from the whole dataset, such as
    unsupervised classification, principal component analysis (PCA), etc. A parallel
    processing method that simply divides the dataset will produce side effects due
    to the tile edges (Lassalle et al. 2015). Parallel computing methods for such
    analysis are usually individualized. In other words, it is difficult to generalize
    a parallel computing paradigm for all data-inseparable remote sensing algorithms.
    Google Earth Engine’s ‘spatial aggregations data distribution model’ pre-implements
    several data-inseparable computing algorithms. Each algorithm is implemented individually
    and transparently by Earth Engine using the MapReduce computing paradigm (introduced
    in Section 4) (Gorelick et al. 2017). On the contrary, data-separable computation
    can be considered as a series of independent sub-tasks by partitioning the datasets.
    In other words, not much external information is needed while processing each
    partition, and: Y = F X ( f x ( x 0 ) , f x ( x 1 ) , … , f x ( x n ) ) (3) where
    f is the processing algorithm for a sub-partition, F is the algorithm for integrating
    the partitions into a complete output Y, x is a sub-partition of X, and X = {
    x 0 , x 1 , … , x n } . Data-separable computing is supported by cloud computing
    and is known as embarrassingly parallel or pleasingly parallel computing in computer
    science (Barcelona-Pons et al. 2019). This type of computing has been widely applied
    in RSBD using quantitative remote sensing, artificial intelligence, etc. For example,
    Pekel et al. integrated the computing power of 10,000 computers to map 30 m global
    water bodies for almost 30 years based on an expert system classifier (Pekel et
    al. 2016). Ni et al. extracted 10 m rice-growing areas in northeast China using
    machine learning (Ni et al. 2021). Xie et al. produced 30 m annual irrigation
    maps based on MODIS and Landsat data for the United States from 1997 to 2017 using
    a random forest classifier (Xie and Lark 2021). All of the above studies have
    relied on the parallelization of data-separable computing. Additionally, the studies
    used Earth Engine’s ‘image tilling data distribution model’ for spatial partitioning
    and ‘streaming collections’ for temporal partitioning (Gorelick et al. 2017).
    Overall, data-inseparable computing requires custom implementation, while data-separable
    computing can be implemented based on generic processing paradigms. However, despite
    the similarities in parallel computing paradigms, there are differences in the
    data partitioning strategies, analysis algorithms, and combination algorithms
    for each specific analysis. In addition, there are strong relationships between
    the way the data is partitioned and parallel algorithms. Therefore, a unified
    framework is urgently needed to regulate and constrain remote sensing algorithms
    and distributed execution paradigms. 2.5. Challenges in the DIKW hierarchy This
    section introduces the four primary challenges facing RSBD, which are expected
    to be resolved with cloud-based approaches. However, there are significant differences
    between RSBD and traditional data processing. RSBD involves both remote sensing
    technology and computer science, which fully illustrates its multidisciplinary
    nature. Traditionally, remote sensing science has only been applied to limited
    scales and needs to be re-examined to support large-scale applications. In addition,
    computer science and technology have been traditionally oriented to conventional
    business, and need to be tailored to remote sensing to support the management
    and mining of RSBD. This cross-fertilization perspective is closely related to
    the four challenges. Rowley ( 2007) defined the Data-Information-Knowledge-Wisdom
    (DIKW) hierarchy. This concept can help explain the relationships between the
    four identified challenges and RSBD (Figure 2). DIKW Data corresponds to raw remote
    sensing data, which is associated with the challenges of data storage and metadata
    management. DIKW Information corresponds to data that conforms to homogeneity,
    such as the data cube or analysis ready data (ARD) (‘CEOS’ 2022). Homogeneity
    should be addressed when transforming DIKW Data into DIKW Information. The parallel
    computing problem exists in both the process of transforming DIKW Data into DIKW
    Information and DIKW Information into DIKW Knowledge. Finally, DIKW Information
    is transformed into DIKW Wisdom using human intelligence, which is used to assist
    real-world decisions and practices. The process of transforming and formalizing
    wisdom from knowledge remains challenging for RSBD. Figure 2. Relationship between
    the DIKW pyramid and the four major concerns. Display full size 3. Cloud-based
    RSBD storage 3.1. Cloud-based big data storage Currently, there are five leading
    cloud computing and big data technologies applicable to RSBD storage, including
    the Object Storage System (OSS), Distributed File System (DFS), Relational Database
    Management System (RDBMS), NoSQL, and array database management systems (array
    DBMSs). The Object Storage System (OSS) manages data in the form of objects, each
    of which is identified with a globally unique identifier. In particular, the RESTful
    API allows data access via HTTP, which means that the object can be easily accessed
    from anywhere on the network. In addition, OSS can manage additional metadata
    for data descriptions. However, OSS does not support I/O operations such as open,
    read, write, etc. Users can deploy OSS in the cloud using open-source software
    or directly leverage OSS-based storage services (e.g. Amazon S3 and Microsoft
    Azure). The Distributed File System (DFS) is another commonly used big data storage
    technology, and examples include the Google File System (Ghemawat, Gobioff, and
    Leung 2003) known as Colossus (Dean and Denis 2021) and the Hadoop Distributed
    File System (Shvachko et al. 2010). DFS supports more comprehensive interfaces
    and features in comparison to OSS (Weil et al. 2006). However, DFS can suffer
    from the bottleneck problems of primary nodes, which restricts the upper limit
    of scaling to some extent. For example, the metadata of the Hadoop Distributed
    File System is stored in the primary node''s memory, which restricts the number
    of files that are stored (Shvachko et al. 2010). In addition, the files stored
    in DFS can only be accessed through the mounted hosts, which is not as flexible
    as OSS. Relational database management systems (RDBMS) are a widely used database
    model (Codd 1970). RDBMS is oriented toward transactional operations and focuses
    on the properties of atomicity, consistency, isolation, and durability (ACID).
    The reliability and stability of RDBMS have been greatly improved with the development
    of RSBD. Some RDBMS, such as PostgreSQL, can manage spatial data and have been
    widely used for remote sensing metadata management. However, there are apparent
    bottlenecks in the standalone RDBMS load capacity. A cloud-based distributed RDBMS,
    NewSQL, was proposed to enhance the scalability of traditional RDBMS for massive
    structured data (Pavlo and Aslett 2016). Google Spanner is an example of this
    technology (Corbett et al. 2013). The onset of Web 2.0 drove an increasing need
    to manage a large amount of unstructured data, which gave rise to NoSQL, e.g.
    MongoDB, HBase (Mehul Nalin 2011), and Google Big Table (Chang et al. 2006). Unlike
    RDBMS, NoSQL does not support transactional operations and ACID properties. On
    the contrary, NoSQL emphasizes the principles of consistency, availability, and
    partition tolerance (CAP) (Gray and Reuter 1992; Cattell 2010), thus improving
    concurrency, efficiency, and horizontal scalability. The various NoSQL technologies
    have distinct technical characteristics that can be applied in different application
    scenarios. These are generally classified into four types, including wide-column,
    key-value, document, and search engine. More detailed reviews of NoSQL can be
    found in the respective literature (Davoudian, Chen, and Liu 2018; Guo and Onstein
    2020). Array database management systems (array DBMSs) are a type of scientific
    database dedicated to the storage and management of array-like scientific data
    (Zalipynis 2021). Array DBMSs are often grouped as NoSQL. However, we decided
    to introduce them individually due to their natural affinity for remote sensing
    and geospatial data (Zalipynis 2020). Array DBMSs support SQL-like queries and
    operations on arrays (e.g. resampling and aggregations). Such advanced manipulations
    are essential for remote sensing data management because they simplify data retrieval
    and pre-processing (Zalipynis 2021; Appel et al. 2018). In addition, array DBMSs
    generally optimize I/O through the underlying technology, which is beneficial
    for online RSBD computing. For example, TileDB optimizes the performance of concurrent
    I/O and sparse arrays by turning multiple random-writes into a single sequential
    write (Papadopoulos et al. 2016). Furthermore, some advanced array DBMSs support
    horizontal scaling. For example, SciDB (Brown 2010) and RasDaMan (Baumann et al.
    2018) support distributed deployment, and TileDB supports share-nothing cloud
    computing architecture, storing files as AWS (Amazon Web Services) S3 objects
    in the cloud. However, importing massive scientific data into an array DBMS may
    be time-consuming. In addition, as far as we know, no cloud services directly
    provide array DBMS services, and users can only build an array DBMS through IaaS.
    Users can build most of the storage technologies introduced above using IaaS.
    In addition, cloud services also provide out-of-the-box storage services (SaaS).
    SaaS helps users focus more on business by avoiding database maintenance. Table
    1 identifies the open-source technologies corresponding to different storage technologies
    and mainstream cloud computing SaaS products. Table 1. Storage technologies for
    RSBD (open source Google Microsoft and Amazon). Download CSVDisplay Table 3.2.
    Cloud-based data storage for RSBD Massive remote sensing data storage consists
    of raster data and metadata storage. 3.2.1. Raster storage Currently, remote sensing
    raster data is generally stored as cloud-optimized data formats in an OSS or DFS.
    In addition, it can be stored in NoSQL databases in the form of tiles or in an
    array DBMS in the form of arrays. Cloud-optimized data formats are optimized to
    improve I/O performance in cloud storage. As we mentioned earlier, OSS does not
    support file opening and writing operations, which is inconvenient for computing.
    For example, even though only a portion of the data is accessed, the complete
    remote sensing dataset must be downloaded, resulting in high redundant overhead
    costs. Cloud-optimized data storage formats for remote sensing data such as Zarr
    and Cloud Optimized GeoTiff (COG) have emerged and improved the performance of
    RSBD data storage. Among them, Cloud Optimized GeoTiff (COG), a GeoTiff data format
    optimized for cloud computing and storage, has been widely adopted (‘Cloud Optimized
    GeoTIFF’ 2022). A 16-kilobyte header file is first parsed when accessing COG within
    OSS. Subsequently, a portion of the remote sensing data can be read on demand
    without downloading the entire dataset. Furthermore, the COG file retains the
    original data resolution and creates internal overview copies for lower resolutions,
    significantly improving the data retrieval efficiency of web-based applications.
    As a result, COG can improve the retrieval efficiency in both DFS and OSS. Currently,
    COG is attracting increased attention. For example, COG replaced GeoTiff in 2021
    as the standard data format for Landsat series data Collection 2. OSS can store
    remote sensing tile and raster data, and cloud-optimized data formats, especially
    COG, are becoming major storage formats for OSS. Amazon, Microsoft, and Google
    currently use OSS to store a large amount of remote sensing data (Table 2). The
    data stored in an OSS can be easily shared through the Internet and leveraged
    for analysis and visualization, promoting open sharing and the use of remote sensing
    data. Users can efficiently access the data with little charge and without considering
    data management and server maintenance, greatly promoting FAIR principles. Table
    2. Remote sensing data stored in the OSSs published by Amazon Microsoft and Google.
    Download CSVDisplay Table DFS is a mature big data storage technology and the
    dominant storage system of RSBD platforms. Distributed file systems cannot share
    data as easily as OSS, but provide advantageous functions such as appending writes
    and modifications. There is no apparent requirement for direct data sharing for
    a computing platform, but there is a clear need for functions such as append write
    and random read. For example, Digital Earth Australia (successor of the Australian
    Geoscience Data Cube) stores Landsat archives in the Lustre system (Braam 2019)
    within the Australian National Computational Infrastructure (Lewis et al. 2017).
    The JRC Earth Observation Data and Processing Platform (JEODPP) stores remote
    sensing datasets in EOS, a DFS designed for the European Organization for Nuclear
    Research (Peters, Sindrilaru, and Adde 2015; Soille et al. 2018), and Earth Engine
    stores a large amount of remote sensing data in Google Colossus. NoSQL supports
    the storage of large amounts of unstructured data and can therefore preserve RSBD
    raster data. Wide-column NoSQL is suitable for storing a vast amount of unstructured
    data such as tiles. GeoTrellis (Kini and Emanuele 2014), a Spark-based RSBD computation
    engine, stores remote sensing tiles and vector geospatial data in wide-column
    NoSQL. However, wide-column NoSQL lacks support for data indexing, especially
    the spatial index needed for remote sensing data. Therefore, users must carefully
    design the row keys to enable spatiotemporal queries (Xu et al. 2020). In-memory
    key-value NoSQL databases store data as key-value pairs in distributed memory
    and can cache the intermediate data for online remote sensing computation. For
    example, Earth Engine stores the cached data from the service in an in-memory
    database to reduce secondary access latency (Gorelick et al. 2017). However, the
    volume of remote sensing data can far exceed the memory storage capacity. Thus,
    in-memory key-value NoSQL is not suitable for persistent remote sensing data.
    Document NoSQL provides spatial indexing capability and can support the storage
    of extensive individual data with more comprehensive capabilities. Wang et al.
    ( 2019) and Cheng et al. ( 2020) implemented storage systems for RSBD based on
    MongoDB. They stored the data in MongoDB after further slicing and achieved the
    management of remote sensing data based on MongoDB’s rich query capability. Overall,
    NoSQL supports more advanced functions than OSS or DFS, such as spatiotemporal
    data management. It has obvious advantages in RSBD application scenarios, but
    the cost of NoSQL is much greater than DFS or OSS. As far as we know, the practice
    of petabyte-level NoSQL-based RSBD storage still requires further research and
    exploration. Unlike other storage systems that store remote sensing data as files,
    array DBMSs store and manipulate remote sensing data as arrays. Array DBMSs optimize
    efficiency based on the underlying storage technology. More importantly, array
    DBMSs support high-level array manipulation for managing remote sensing data,
    including data storage, metadata management, indexing, etc. In other words, an
    array DBMS can be used as an RSBD data management system with a few additional
    components. For example, EarthServer (Baumann et al. 2016) implements the storage
    of a large amount of remote sensing data using RasDaMan (Baumann et al. 1998).
    Furthermore, some array DBMSs can process remote sensing data (e.g. reprojection,
    resampling) and have been applied in tandem with machine learning (Ordonez, Zhang,
    and Lennart Johnsson 2019). However, array DBMS-based RSBD data management is
    still in its infancy. One of the major challenges lies in incorporating data into
    NoSQL, which can be costly. Specifically, all raw datasets should be pre-processed
    into the unified format recognized by each type of array DBMS, which is a time-consuming
    process (Lewis et al. 2017). 3.2.2. Metadata storage & management RSBD metadata
    storage and management are mainly based on NoSQL, RDBMS, and NewSQL. RDBMS is
    suitable for storing and managing remote sensing metadata and is the mainstream
    technical approach for RSBD management systems. For example, Li and Tang ( 2019)
    and Zhou et al. ( 2021) stored remote sensing data in distributed MySQL and PostgreSQL
    systems, respectively. The Open Data Cube stores metadata in PostgreSQL (Killough
    2018). In our case, we managed the metadata of petabytes of remote sensing datasets
    (ten million metadata entries) with a standalone PostgreSQL instance. However,
    there is an upper limit to the storage capacity of RDBMS. Therefore, RDBMS is
    only suitable for the rapid construction of structured remote sensing metadata
    storage for medium-sized datasets. Cloud-native NewSQL overcomes the problems
    with scalability and is ideal for storing significant metadata volumes. For example,
    Earth Engine uses Spanner as one of its data management tools (Gorelick et al.
    2017). NewSQL open-source technology and cloud computing services are still being
    developed. NoSQL can store unstructured data such as heterogeneous remote sensing
    metadata (Guo and Onstein 2020). For RSBD data storage systems, data and metadata
    are often rarely modified after they are input into the database. Therefore, compared
    to RDBMS, NoSQL’s lack of support for ACID is acceptable for RSBD management systems.
    Search engine is a type of NoSQL that supports full-text search such as Solr and
    Elastic Search. Search engine NoSQL builds inverted indexes in memory to achieve
    high performance and a robust full-text index. Fan et al. ( 2017) stored the metadata
    of remote sensing in SolrCloud and implemented a full-text search. Their process
    supports advanced functions such as fuzzy queries and has good adaptability for
    the complex structures of remote sensing metadata. However, it is costly to implement
    such storage systems using search engine NoSQL. Wide-column and document NoSQL
    are also used for metadata storage. For example, Earth Engine adopted the Big
    Table storage system (Gorelick et al. 2017). Wang et al. ( 2019) and Cheng et
    al. ( 2020) used MongoDB to store both raster data and metadata to achieve integrated
    data/metadata storage. 3.3. Data model: scene, ARD, data cube, composite layer
    The ultimate purpose of data storage is to prepare data for analysis, and thus,
    homogeneity must be considered. The homogeneity of raster data is not prominent
    in the case of small-scale remote sensing analysis, and computing is mainly implemented
    within a scene by a standalone processing node. There is an increasing requirement
    for advanced remote sensing data organization due to the expansion of spatiotemporal
    scales, which we propose as a data model related to data organization, data structure,
    and data production methods. It is necessary to adopt a suitable remote sensing
    data model for large-scale analysis within cloud computing for specific application
    scenarios (algorithms, parallel computing strategies, etc.). In the past few years,
    several data organization schemes have been developed for RSBD analysis, including
    scenes, ARD, data cubes, and composite layers (Figure 3). Figure 3. Relationships
    between scenes ARD data cubes and composite layers. Display full size Scenes are
    the most basic organization for remote sensing data and have been widely applied
    during the past several decades. Conventionally, satellites collect remote sensing
    data in strips and transmit them to the ground segment. The ground segment processes
    the remote sensing data through corrections and evaluations and profiles them
    according to a regular grid (e.g. the Military Grid Reference System adopted by
    Sentinel). The pre-processed remote sensing data are the most common form of remote
    sensing data corresponding to the remote sensing images fetched from data providers
    (e.g. USGS, ESA Copernicus). The use of cloud computing greatly diminishes the
    cost of acquiring scene data. In addition, COG technology also enhances the efficiency
    of remote sensing data access with higher degrees of freedom. Analysis Ready Data
    (ARD) (Potapov et al. 2020) was initiated by the Committee on Earth Observation
    Satellites (CEOS) (‘CEOS’ 2022). The original intent of ARD was to reduce the
    threshold for users to leverage the data by reorganizing discrete datasets into
    regular blocks with a fixed size, resolution, and projection, thus minimizing
    data processing and correction (Dwyer et al. 2018). ARD must be radiometrically
    and geometrically corrected, and evaluated for quality at the pixel level using
    a uniform standard to achieve homogeneous physical characteristics (Frantz 2019).
    In addition, ARD is commonly reorganized into global unified Discrete Global Grid
    Systems in the form of tiles. For example, the USGS produces Landsat ARD applying
    the latest Collection 2 archive standard. Zhong et al. ( 2021) developed an ARD
    data product based on GaoFen satellite data. Most of the previous RSBD research
    stacked multiple datasets into a ‘composite’ before analysis according to specific
    rules, which we name as the composite layer (Thorp and Drajat 2021). The composite
    layer refers to layer-like datasets produced by pre-processing and combining all
    available data over a certain spatial–temporal range, such as remote sensing data
    products (Gong et al. 2020). We borrowed the term ‘layer’ from geographic information
    systems (GIS) to emphasize that there is one and only one value for each pixel
    in the region of interest. It is characterized by its ideal homogeneity. Thus,
    it is the best input data model for non-time series analysis. Therefore, the composite
    layer is the closest remote sensing data model to the ‘Information’ in DIKW. For
    small-scale applications, scenes or ARD can be approximated as the composite layer,
    especially when the scale of the region of interest is comparable to that of scenes
    or ARD. However, data coverage at large scales is not guaranteed for medium and
    high-resolution remote sensing data, which is caused by the data acquisition model
    or long revisit periods. Therefore, the differences between scenes and layers
    are more prominent in large-scale applications. Recently, the data cube has gradually
    become the focus of RSBD research, especially cloud-based RSBD applications (Lewis
    et al. 2016; Giuliani et al. 2017). The data cube reorganizes and stacks ARD data
    along a time dimension and dissects them according to a regular grid. A data cube
    can be a sparse collection of time-series data or a dense mosaic of the best available
    values over time. In contrast to the composite layer, which discards multiple
    available values, the data cube aggregates all available ARD datasets over time
    to approximate the layer as closely as possible. It is the best input for large-scale
    remote sensing analysis (especially time-series analysis). However, the data cube
    tends to be sparse in medium- and high-resolution remote sensing applications.
    Xu et al. ( 2022) further developed the connotation of the data cube to improve
    the homogeneity and proposed Computation Ready Data (CRD). CRD considers the continuity
    of remote sensing data and the diverse computational needs. This approach helps
    promote the use of interpolation and spatiotemporal fusion algorithms to fill
    missing data in the data cube. CRD further reorganizes data according to computational
    needs and fills in the data model and computation gap. As shown in Figure 3, the
    relationships between the data models can be summarized as follows. The data volume
    and information quantity decrease from left to right. The scene datasets retain
    the most information and the largest volume. The generation of ARD data filters
    out poor-quality data and reduces the data volume. The data cube screens out data
    outside a specific spatial and temporal range according to certain conditions,
    which further decreases the available data. Ultimately, the composite layer generally
    reduces the dimensionality of the data cube and therefore possesses the smallest
    data volume. The smaller the data volume, the more convenient it is for transmission
    and sharing. Consequently, the composite layer is the ideal data model for data
    propagation. There is a significant difference in the complexity of data production
    between data models. The production of ARD from raw scene data involves time-consuming
    and computation-intensive processing, such as rigorous radiation and geometric
    correction. However, the creation of the data cube or composite layer is mostly
    a reorganization of datasets with relatively low computational complexity. The
    cost has been significantly reduced for such data-intensive processing due to
    the support of cloud computing technologies (e.g. COG). Hence, it is not efficient
    to produce ARD on-demand since the online construction of the data cube can be
    quickly implemented with the use of cloud computing (Giuliani et al. 2020). Any
    processing will cause a loss of accuracy, and the accuracy loss of different data
    models can vary. The loss of accuracy caused by the correction process in ARD
    production is acceptable and unavoidable in most RSBD applications (Qiu et al.
    2018). However, the production of data cubes or composite layers will affect accuracy
    in comparison with the original datasets. In most cases, data cubes transform
    the original datasets with different projections and resampling, and composite
    layers filter values according to customized rules. Therefore, storing datasets
    in the form of data cubes or composite layers can lead to irreversible losses
    in accuracy compared with ARD. Homogeneity gradually increases from left to right.
    ARD datasets possess homogeneous physical characteristics and data cubes and composite
    layers are observed to approach continuity. Additionally, the layers and data
    cubes are closer to the array data model in computer science. Therefore, both
    are suitable for implementing remote sensing analysis. In this section, the current
    cloud-based storage technologies are introduced and cloud-based remote sensing
    data storage technologies are reviewed. Finally, we provide insights into the
    data models for RSBD applications. Table 3 summarizes the remote sensing data
    storage schemes and data models for fifteen systems and studies produced from
    2016 to 2021. The conclusions are drawn as follows. NoSQL, DFS, Array DBMS, and
    OSS can store raster data, while NoSQL and RDBMS can manage remote sensing metadata.
    Figure 4 further summarizes the characteristics of the four NoSQL databases, aside
    from array DBMS. For cloud-based RSBD raster storage, OSS is the mainstream solution
    for sharing open data, while DFS is the primary solution for RSBD platforms. In
    the context of cloud computing, public cloud-based OSS services can significantly
    lower the cost of RSBD management. Therefore, the RSBD systems in recent years
    have been more inclined to use OSS. NoSQL and array DBMSs have great potential,
    but there are still some limitations such as the high cost of use. Both NoSQL
    and RDBMS can be used to implement cloud-based RSBD metadata storage, and the
    choice of technology depends on the specific application scenario. On the one
    hand, NoSQL can manage the complete archive of remote sensing data, which is difficult
    to achieve through RDBMS (Wang et al. 2019; Cheng et al. 2020). On the other hand,
    the functionality and performance of RDBMS has been widely demonstrated. For example,
    RDBMS has a higher cost performance in the scenario of small and medium volume
    RSBD management. However, NoSQL is more applicable for larger RSBD systems. Data
    models are becoming critical for RSBD applications. The cost of producing ARD
    is generally high and results in an acceptable loss of accuracy (D’Andrimont et
    al. 2021). Therefore, it is appropriate to store remote sensing data as ARD in
    the cloud for common applications. In contrast, data cubes and composite layers
    have less production overhead, suffer from significant accuracy loss, and possess
    a much smaller data volume than scenes (Sudmanns et al. 2020). Therefore, it is
    better to produce data cubes or composite layers on-demand in the cloud before
    propagation (Li et al. 2019). Most importantly, composite layer and data cube
    models are more suitable for implementing remote sensing computing due to their
    homogeneity. Figure 4. The pros and cons of the four types of NoSQL databases
    and an evaluation of the associated scale cost search and I/O (radar chart in
    the middle). Display full size Table 3. RSBD management solutions for different
    studies and systems (DC = Data Cube CL = Composite Layer). Download CSVDisplay
    Table 4. Cloud-based RSBD computing 4.1. Cloud-based big data processing Technologies
    for cloud computing and big data are complex, specialized issues that are beyond
    this work''s scope. This section introduces three active and promising processing
    technologies for RSBD computing: simple batch, MapReduce, and array-based processing
    (Figure 5). In addition, we introduce a lightweight virtualization technology
    known as containerization. Figure 5. Simplified frameworks for the three processing
    models. Display full size 4.1.1. Simple batch processing Simple batch processing
    refers to a simple processing model where each task is independent of others.
    This method has been used for more than twenty years. Some examples include the
    Portable Batch System (PBS), Azure Batch, and AWS Batch (Casado and Younas 2015;
    Henderson 1995). Typically, users pre-define the execution program and execute
    a series of identical computing tasks in a batch. Each input set corresponds to
    a processing instance and outputs a result. Each independent computing task does
    not affect other computing tasks, and such tasks can be executed asynchronously.
    Simple batch processing has been widely used in offline batch processing. However,
    simple batch processing cannot accomplish complex analysis because it does not
    support inter-task communication. 4.1.2. Mapreduce processing MapReduce (Wang
    et al. 2010) is a popular batch processing model for cloud and distributed processing
    that was first announced by Google in 2004 (Dean and Ghemawat 2008). MapReduce
    adapts the idea of functional programming and uses two core operators, Map and
    Reduce, to implement individual data and aggregate operations, respectively. In
    2010, Zaharia et al. developed Spark based on MapReduce, a memory-based distributed
    processing engine (Zaharia et al. 2010). Spark supports more affluent operators
    and uses programming languages to support flexible batch processing. In addition,
    Spark optimizes scheduling by building directed acyclic graphs (DAGs) for workflows
    and employing a ‘lazy’ mechanism. Under the ‘lazy’ mechanism, some of Spark''s
    operators only record processes and defer the actual computation to optimize the
    execution route. Spark preserves intermediate data with a memory-based data model
    called Resilient Distributed Datasets (RDDs). RDD can improve the computation
    efficiency by nearly a hundred times compared with MapReduce (Zaharia et al. 2010),
    especially for tasks with multiple iterations such as machine learning and deep
    learning (Lunga et al. 2020). However, the large data volume of data-intensive
    computations often exceeds memory storage capacity, leading to decreased efficiency.
    Cloud processing provides services that help users quickly implement MapReduce
    jobs. Users can build their MapReduce clusters on virtual machines or directly
    use cloud-hosted Hadoop or Spark services, such as Amazon Elastic MapReduce (Amazon
    EMR) and Google Dataproc. 4.1.3. Array-based processing Array-based processing
    is a computational technology for scientific array data (Lu, Appel, and Pebesma
    2018). The well-known Numpy and OpenCV can implement a variety of complex processes
    for array data. However, such software is limited by the resources of a single
    machine and cannot be efficiently applied to very-large arrays. Recent technologies
    have implemented array manipulations with parallel batch processing for large-scale
    arrays, e.g. Dask (Rocklin 2015), such as the computational functions of Earth
    Engine and array DBMSs. Earth Engine adopts FlumeJava (Chambers et al. 2010),
    a MapReduce processing engine, to manipulate remote sensing data as an array-like
    Collection or Image. However, from the usage point of view, such array-based processing
    is different from MapReduce processing. Users of array-based processing do not
    need to worry about the underlying parallel processing implementation, such as
    task scheduling, but directly use arrays as the processing object. At present,
    array-based processing is still developing and has some known flaws. Array DBMSs
    lack the flexibility for implementing user-defined functions (Mehta et al. 2017).
    Furthermore, performance optimization is still not as robust as traditional batch
    processing technologies (Mehta et al. 2017). However, most scientific data, such
    as remote sensing, mainly consist of arrays. The direct manipulation of arrays
    can shield users from many underlying problems. Therefore, we believe that array-based
    processing will play an increasingly important role in scientific big data processing
    in the future. All three processing technologies introduced above can implement
    large-scale remote sensing analysis computations. In Table 4 we briefly summarize
    the mainstream open-source technologies and the related cloud-based solutions.
    However, batch processing technology requires the rewrite of remote sensing analysis
    algorithms, which hinders researchers from performing scientific analysis based
    on RSBD to some extent (Mehta et al. 2017; Camara et al. 2016). Table 4. Processing
    technologies for RSBD (Open Source Google Microsoft and Amazon). Download CSVDisplay
    Table 4.1.4. Containerization Containerization is one of the core concepts of
    cloud-native computing (Li 2019; Pelle et al. 2019). It is widely used in cloud-based
    processing such as FaaS and serverless applications. Containerization is a virtualization
    technology that packages algorithms with lightweight containers and provides the
    runtime environments needed for algorithms, e.g. Docker (Merkel 2014). This technology
    allows the stable execution of various remote sensing algorithms in different
    host environments, which improves the portability of remote sensing algorithms
    by decoupling the algorithms from the host machine (Xu et al. 2022). The technology
    is essential for cloud-based RSBD because it can port remote sensing algorithms
    from the local environment to the cloud (Wang et al. 2015). Containers can be
    leveraged jointly with the big data processing technologies mentioned above (e.g.
    batch processing). In addition, they can be managed by container orchestration
    platforms in the cloud. Kubernetes is one of the most famous open-source container
    orchestration platforms; it was developed by Google and contributed to the Cloud
    Native Computing Foundation in 2015 (Bernstein 2014). Borg (Verma et al. 2015),
    the internal Google version of Kubernetes, is used for resource scheduling and
    load balancing within Earth Engine. 4.2. Cloud-based computing for RSBD As introduced
    in Section 2.4, RSBD applications can be grouped into two types, data-separable
    computing and data-inseparable computing. We introduce cloud-based computing for
    RSBD from these two perspectives. 4.2.1. Data-separable computing Data-separable
    computing covers most remote sensing analysis applications, such as pixel-based
    and tile-based analysis and has a simple parallelization strategy with better
    feasibility. The following example illustrates the processing paradigm. Bishop-Taylor
    et al. ( 2021) extracted the coastal zone changes for Australia from 1988 to 2019.
    The study partitioned the region of interest into sub-regions by space and then
    produced data cube datasets for each sub-region. Subsequently, the shoreline changes
    from 1988 to 2019 in each sub-region were extracted using simple batch processing.
    Finally, the study combined all sub-regions and obtained the complete coastline
    change for Australia. This example outlines most of the routines for data-separable
    computing with a simple batch, including (1) partitioning the region of interest,
    (2) constructing data cubes for each partition, (3) computing each partition,
    and (4) combining the partitions. This kind of computing has been widely applied
    in RSBD, especially in data pre-processing and mapping. Each partition’s implementation
    can be considered as an individual computing task, which corresponds with the
    computing paradigm of simple batch processing. In addition, other processing models,
    such as MapReduce, can perform such computing as well. 4.2.2. Data-inseparable
    computing There are dependencies between data-inseparable computing tasks, and
    thus, the input data should be homogeneous as data cubes or composite layers.
    Currently, data-inseparable computing is mainly processed using MapReduce and
    array-based processing. The implementation of parallel remote sensing processing
    algorithms based on MapReduce provides flexibility (Chebbi et al. 2018). MapReduce
    and Spark offer a range of flexible operators which can build complex computational
    pipelines to implement diverse parallelized computations for remote sensing analysis.
    There are a number of studies that have implemented various data-inseparable remote
    sensing computations based on MapReduce-like technologies, such as K-Means clustering
    analysis (Chebbi, Boulila, and Farah 2016), parallelized mosaics (Jing et al.
    2017), deep learning (Sun et al. 2019), and object-based segmentation (Wang et
    al. 2020). GeoTrellis (Kini and Emanuele 2014) is a Spark-based MapReduce processing
    technology that is oriented to remote sensing data processing and provides a set
    of APIs for remote sensing analysis. The MapReduce paradigm has also been widely
    used in the spatial information domain, such as SpatialHadoop (Eldawy and Mokbel
    2015), GeoSpark (Yu, Wu, and Sarwat 2015), and GeoMesa (Hughes et al. 2015). However,
    there are still some known shortcomings in implementing data-inseparable computing
    with MapReduce. Compared with high-performance computing and message passing interfaces,
    there has been an attempt to shield the user from the underlying programming issues
    as much as possible. However, remote sensing researchers still must deal with
    complicated issues in manual parallel computing. The performance of some memory-based
    MapReduce technologies, such as Spark, is considerable. Yet, they are not suitable
    for ‘data-intensive’ RSBD analysis (Makrani et al. 2018). Memory-based processing
    requires a large memory capacity to handle large remote sensing datasets, but
    there is a slight improvement for algorithms with low iterative computation requirements.
    Apart from MapReduce processing, array-based processing is also suitable for data-inseparable
    computing. Arrays, especially composite layers, are the principal unit of remote
    sensing analysis. Array-based processing generally pre-defines diversified APIs
    to manipulate arrays in parallel. The built-in array operations and machine learning
    algorithms can be used for remote sensing analysis, such as vegetation index extraction
    and classification (Villarroya and Baumann 2020). For example, Earth Engine is
    dedicated to remote sensing analysis with many algorithms specializing in remote
    sensing science, such as time series analysis (Hamunyela et al. 2020) and cloud
    detection algorithms (Qiu, Zhu, and He 2019). Array-based processing shields remote
    sensing researchers from the underlying implementation of parallel computing,
    thus helping them to focus more on the computation itself. However, current array-based
    processing still has specific problems. Most array-based processing technologies,
    such as array DBMSs or Dask, are not designed for remote sensing applications,
    and the provided APIs do not support professional remote sensing processing. Therefore,
    additional computing implementations are required as post-processers. For example,
    (Pagani and Trani 2018) constructed a data system with RasDaMan and implemented
    subsequent remote sensing analysis based on R programming. Furthermore, the highly
    packaged APIs reduce the flexibility of implementing user-defined algorithms.
    For example, users cannot extend any analysis that Earth Engine does not support.
    Fortunately, this problem might be gradually alleviated with the development of
    open-source array-based processing technologies. Furthermore, the efficiency of
    current array-based processing (e.g. Dask) is lower than that of MapReduce (e.g.
    Spark) with some additional restrictions (Fu et al. 2020). Finally, current array-based
    processing services are mainly maintained by the open-source community (e.g. Pangeo),
    restricting the available computational resources. 4.3 RSBD platforms The RSBD
    platform is the best practice for RSBD applications. Any RSBD storage or computing
    systems cannot work individually. Instead, RSBD computing should work closely
    with storage systems, and platforms should implement RSBD applications by integrating
    storage and computing. Figure 6 summarizes the five architectures of RSBD platforms
    as characterized by the data model. The four components from left to right are
    storage, the data model, processing, and output. Type 1 platforms parallelize
    the computation of scenes using simple batch processing and data-separable computing.
    The outcome of such platforms is delivered in the form of scenes. In terms of
    architecture, Type 1 platforms are composed of two parts, the data storage system
    and simple batch processing system. The data storage system is responsible for
    providing data services to the processing system, and the simple batch processing
    system manages the analysis algorithms and maintains execution tasks. Such platforms
    were widely used in early batch remote sensing data production and analysis (Li
    and Tang 2019; Giuliani et al. 2017). For example, the European Space Agency''s
    G-POD project pre-populates many algorithms for remote sensing scenes and data
    and offers batch processing services. Type 2 platforms are the mainstream technology
    route adopted for large-scale remote sensing analysis and computation. They consist
    of three main parts: the data storage system, data cube production system, and
    simple batch processing system. Type 2 platforms are similar to Type 1 platforms
    in that they support data-separable computing. In contrast, this type of platform
    processes the data into data cubes as the input and then outputs data cube datasets.
    For example, JEODPP divides the computational tasks of the data cube into independent
    subtasks and then uses HTCondor to implement multi-task batch processing (Soille
    et al. 2018; Corbane et al. 2017). Type 3 platforms adopt MapReduce processing
    and support data-inseparable computing. For example, the ScienceEarth platform
    has been used to process remote sensing data as a data cube with the implementation
    of large-scale remote sensing analysis using Spark (Xu et al. 2022; Xu et al.
    2020). Though MapReduce is powerful, it is not friendly to remote sensing researchers.
    Users must deal with detailed configuration issues in parallel computing by themselves,
    which prevents the widespread use of MapReduce in RSBD applications. Therefore,
    such platforms have a high difficulty threshold for their implementation and use.
    Type 4 platforms use array-based processing as the data processing system and
    support data-inseparable computing. Such platforms consist of three parts, including
    the data storage system, data cube production system, and array-based processing
    system. To be specific, the data cube production system is responsible for processing
    remote sensing scene data into array-like data types (e.g. data cubes and composite
    layers). The array-based processing system pre-defines many high-level APIs for
    the analysis of large arrays. Type 5 platforms use array DBMSs as the core component
    and support data-inseparable computing. An array DBMS can store and manage massive
    remote sensing data with distributed systems. More importantly, it can internally
    implement array-based processing. Therefore, an array DBMS can independently construct
    an RSBD platform. For example, Kuo et al. ( 2018) built an RSBD platform based
    on SciDB, which supported shared-memory parallelization (SMP) and distributed
    memory parallelization (DMP). However, only simple array processing is supported
    by current array DBMS technology. Therefore, other computing systems are needed
    in most cases to achieve the complex analysis and computation of remote sensing
    data (Pagani and Trani 2018). Figure 6. Five architectures of RSBD platforms.
    Display full size In addition to the five types of platforms, some studies further
    package the technologies on top of existing RSBD platforms. For example, BACI
    offers web-based services based on Google Earth Engine (Poortinga et al. 2018).
    OpenEO proposes a unified API for data management as well as the computational
    resources of different platforms (Schramm et al. 2021). OpenEO accesses data and
    services in virtual data cubes, allowing for deeper comparisons between compatible
    Earth observation cloud services rather than accessing them directly. This section
    identifies four significant cloud-based processing technologies and provides insights
    into data-separable and data-inseparable computing for RSBD. In addition, we summarize
    the five major architectures of current RSBD platforms in terms of their data
    models, data storage, and type of processing. As shown in Table 5, we summarize
    the representative platforms according to their technology routes. The conclusions
    are provided below. Simple batch processing has been widely applied in RSBD applications,
    especially in data-separable computing, while data-inseparable computing is becoming
    a popular topic in RSBD. Data-inseparable computing can be implemented using MapReduce
    or array-based processing. Although current array-based processing is in its infancy,
    this promising technology may lead to the next generation of remote sensing processing.
    There are five principal types of RSBD platforms. Type 1 and Type 2 architectures
    can only handle the most basic data-inseparable computing. Type 3 platforms have
    the best scalability for various algorithms but have a specific use threshold
    for computer technologies. Type 4 platforms are the most advanced implementation
    at present. However, Type 4 platforms require high construction costs and pose
    significant technical challenges. Type 5 platforms have reasonable prospects but
    are restricted by the development of array DBMSs. Regardless of the type of RSBD
    platform, no single platform can comprehensively handle all diversified RSBD applications
    (Ni et al. 2021; Xie and Lark 2021; Chen et al. 2021). Under these circumstances,
    multiple platforms should be jointly leveraged. Thus, data must be transported
    between platforms (Lu and Wang 2021; Arvor et al. 2021; Brombacher et al. 2020),
    and a standard RSBD data model is necessary. Data cubes are a promising approach
    for meeting this standard. Table 5. Summary of the RSBD platforms (DC = Data Cube
    CL = Composite Layer). Download CSVDisplay Table 5. Conclusion The joint promotion
    of space technology, remote sensing science and technology, and computer technology
    has enabled humans to enter a new era of Remote Sensing Big Data (RSBD). RSBD
    is the best means to realize global remote sensing analysis and will become the
    backbone of Big Earth Data, making additional contributions to sustainable human
    development (Guo et al. 2017; Guo et al. 2021). This research introduces state-of-the-art
    technologies and research trends concerning RSBD storage and computing. In addition,
    this study provides a preliminary glance over the basic issues of RSBD for computing
    experts and remote sensing researchers, especially those who tend to work with
    large-scale remote sensing research and applications. We would like to arouse
    the reader’s interest in RSBD through this research. However, RSBD is a broad
    topic, and we could not thoroughly review it from a comprehensive perspective.
    Therefore, some issues (e.g. open data, data security, confidentiality, visualization,
    etc.) are not mentioned. Additionally, despite our extensive literature references,
    there are inevitably controversial representations and claims in the manuscript.
    Remote sensing data mainly consists of raster data and metadata. Many studies
    have already accumulated valuable research for RSBD storage. The storage technology
    for RSBD has achieved satisfactory results for moving data from a single machine
    to clusters and from the local environment to the cloud. Among them, cloud-based
    optimized remote sensing data storage technology and cloud storage technology
    represented by OSS, NewSQL, and NoSQL will become mainstream technical solutions
    for RSBD storage and management. Data homogeneity is necessary for large-scale
    analysis. In this regard, the current RSBD technology mainly adopts four data
    models with different homogeneity characteristics; these include scenes, ARD,
    data cubes, and composite layers. The data cube has good compatibility with cloud
    computing and can provide RSBD analysis through homogeneous multi-dimensional
    remote sensing data. We suspect that this data model will become the mainstream
    RSBD data model in the future. According to the computational paradigm, RSBD computing
    can be divided into data-separable and data-inseparable computing. Data-separable
    computing has better parallelism and remains the computation type in most RSBD
    analyses. On the other hand, data-inseparable computing is the current hot topic.
    There are three mainstream cloud-based big data technologies for remote sensing
    data analysis: simple batch processing, MapReduce processing, and array-based
    processing. Simple batch processing has been widely used. The MapReduce-based
    parallel computing paradigm can be applied to more complex remote sensing analysis
    applications. Moreover, array-based processing provides an easy-to-use and promising
    technical tool for remote sensing scientists. In this review, the five types of
    RSBD platform architectures were summarized. Type 4 has the most advanced architecture,
    which adopts the data cube model and array-based processing. The multidisciplinary
    methodologies of RSBD are growing rapidly, and RSBD platforms have already played
    important roles in various fields. However, in the future, the integration of
    satellite, airborne, ground-based, geospatial, and even socioeconomic data is
    needed to produce more effective solutions to real-world problems, which will
    face additional challenges. Novel real-time data processing paradigms, artificial
    intelligence algorithms, and innovative tools are expected to be assembled into
    RSBD platforms to extract more desired information from remote sensing data. The
    emergence of Federated Learning, a novel distributed processing paradigm, guarantees
    data security during training and RSBD analysis. In addition, recent advancements
    in deep learning models provide a promising approach for RSBD interpretation over
    large scales. GPU-accelerated RSBD platforms are an ideal host for neural network
    architectures and open datasets. The high-quality information extracted at a global
    scale will provide a new impetus for improving RSBD methodologies and platforms
    in remote sensing. In addition, the information will aid the scientific community
    in assessing global disaster risk, monitoring climate change, and addressing the
    United Nations Sustainable Development Goals (SDGs). Disclosure statement No potential
    conflict of interest was reported by the author(s). Additional information Funding
    This work was supported by Strategic Priority Research Program of the Chinese
    Academy of Sciences, Project title: CASEarth: [Grant Number XDA19080103,XDA19080101];
    Innovation Drive Development Special Project of Guangxi: [Grant Number GuikeAA20302022];
    National Natural Science Foundation of China: [Grant Number 41974108]. References
    Al-Yadumi, Sohaib, Tan Ee Xion, Sharon Goh Wei Wei, and Patrice Boursier. 2021.
    “Review on Integrating Geospatial Big Datasets and Open Research Issues.” IEEE
    Access 9: 10604–10620. doi:10.1109/ACCESS.2021.3051084.  Web of Science ®Google
    Scholar Allen, Cameron, Maggie Smith, Maryam Rabiee, and Hayden Dahmm. 2021. “A
    Review of Scientific Advancements in Datasets Derived from Big Data for Monitoring
    the Sustainable Development Goals.” Sustainability Science 16 (5): Springer Japan:
    1701–1716. doi:10.1007/s11625-021-00982-3.  Web of Science ®Google Scholar Almasi,
    G. S., and A. Gottlieb. 1989. Highly Parallel Computing. USA: Benjamin-Cummings
    Publishing Co., Inc.  Google Scholar Appel, Marius, Florian Lahn, Wouter Buytaert,
    and Edzer Pebesma. 2018. “Open and Scalable Analytics of Large Earth Observation
    Datasets: From Scenes to Multidimensional Arrays Using SciDB and GDAL.” ISPRS
    Journal of Photogrammetry and Remote Sensing 138 (April): The Authors: 47–56.
    doi:10.1016/j.isprsjprs.2018.01.014.  Google Scholar Armbrust, Michael, Armando
    Fox, Rean Griffith, Anthony D. Joseph, Randy Katz, Andy Konwinski, Gunho Lee,
    et al. 2010. “A View of Cloud Computing.” Communications of the ACM 53 (4): 50–58.
    doi:10.1145/1721654.1721672.  Web of Science ®Google Scholar Arvor, Damien, Julie
    Betbeder, Felipe R.G. Daher, Tim Blossier, Renan Le Roux, Samuel Corgne, Thomas
    Corpetti, Vinicius de Freitas Silgueiro, and Carlos Antonio da Silva Junior. 2021.
    “Towards User-Adaptive Remote Sensing: Knowledge-Driven Automatic Classification
    of Sentinel-2 Time Series.” Remote Sensing of Environment 264: Elsevier Inc.:
    112615. doi:10.1016/j.rse.2021.112615.  Web of Science ®Google Scholar Asrar,
    G., E. T. Kanemasu, R. D. Jackson, and P. J. Pinter. 1985. “Estimation of Total
    Above-Ground Phytomass Production Using Remotely Sensed Data.” Remote Sensing
    of Environment 17 (3): 211–220. doi:10.1016/0034-4257(85)90095-1.  Web of Science
    ®Google Scholar Balti, Hanen, Ali Ben Abbes, Nedra Mellouli, Imed Riadh Farah,
    Yanfang Sang, and Myriam Lamolle. 2020. “A Review of Drought Monitoring with Big
    Data: Issues, Methods, Challenges and Research Directions.” Ecological Informatics
    60 (July): Elsevier: 101136. doi:10.1016/j.ecoinf.2020.101136.  Google Scholar
    Barcelona-Pons, Daniel, Pedro García-López, Álvaro Ruiz, Amanda Gómez-Gómez, Gerard
    París, and Marc Sánchez-Artigas. 2019. FaaS Orchestration of Parallel Workloads.”
    In Proceedings of the 5th International Workshop on Serverless Computing - WOSC
    ‘19, 25–30. New York, New York, USA: ACM Press. doi:10.1145/3366623.3368137.  Google
    Scholar Barsi, Árpad, Zsófia Kugler, Attila Juhász, György Szabó, Carlo Batini,
    Hussein Abdulmuttalib, Guoman Huang, and Huanfeng Shen. 2019. “Remote Sensing
    Data Quality Model: From Data Sources to Lifecycle Phases.” International Journal
    of Image and Data Fusion 10 (4): Taylor & Francis: 280–299. doi:10.1080/19479832.2019.1625977.  Web
    of Science ®Google Scholar Baumann, P., A. Dehmel, P. Furtado, R. Ritsch, and
    N. Widmann. 1998. “The Multidimensional Database System RasDaMan.” ACM SIGMOD
    Record 27 (2): 575–577. doi:10.1145/276305.276386.  Google Scholar Baumann, Peter,
    Paolo Mazzetti, Joachim Ungar, Roberto Barbera, Damiano Barboni, Alan Beccati,
    Lorenzo Bigagli, et al. 2016. “Big Data Analytics for Earth Sciences: The EarthServer
    Approach.” International Journal of Digital Earth 9 (1): 3–29. doi:10.1080/17538947.2014.1003106.  Web
    of Science ®Google Scholar Baumann, Peter, Dimitar Misev, Vlad Merticariu, Bang
    Pham Huu, and Brennan Bell. 2018. Rasdaman: Spatio-Temporal Datacubes on Steroids
    Peter.” In Proceedings of the 26th ACM SIGSPATIAL International Conference on
    Advances in Geographic Information Systems, 604–607. New York, NY, USA: ACM. doi:10.1145/3274895.3274988.  Google
    Scholar Bernstein, David. 2014. “Containers and Cloud: From LXC to Docker to Kubernetes.”
    IEEE Cloud Computing 1 (3): 81–84. doi:10.1109/MCC.2014.51.  Google Scholar “Big
    Data Analytics Platform”. 2021. Accessed December 2. https://jeodpp.jrc.ec.europa.eu/apps/gitlab/for-everyone/documentation/-/wikis/home.  Google
    Scholar Bishop-Taylor, Robbi, Rachel Nanson, Stephen Sagar, and Leo Lymburner.
    2021. “Mapping Australia’s Dynamic Coastline at Mean Sea Level Using Three Decades
    of Landsat Imagery.” Remote Sensing of Environment 267 (March): Elsevier Inc.:
    112734. doi:10.1016/j.rse.2021.112734.  Google Scholar Braam, Peter. 2019. “The
    Lustre Storage Architecture,” March. http://arxiv.org/abs/1903.01955.  Google
    Scholar Brombacher, Joost, Johannes Reiche, Roel Dijksma, and Adriaan J. Teuling.
    2020. “Near-Daily Discharge Estimation in High Latitudes from Sentinel-1 and 2:
    A Case Study for the Icelandic Þjórsá River.” Remote Sensing of Environment 241
    (May 2019): Elsevier: 111684. doi:10.1016/j.rse.2020.111684.  Google Scholar Brown,
    Paul G. 2010. Overview of SciDB.” In Proceedings of the 2010 International Conference
    on Management of Data - SIGMOD ‘10, 963. New York, New York, USA: ACM Press. doi:10.1145/1807167.1807271.  Google
    Scholar Camara, Gilberto, Luiz Fernando Assis, Gilberto Ribeiro, Karine Reis Ferreira,
    Eduardo Llapa, Lubia Vinhas, Victor Maus, Alber Sanchez, and Ricardo Cartaxo Souza.
    2016. Big Earth Observation Data Analytics: Matching Requirements to System Architectures.”
    Proceedings of the 5th ACM SIGSPATIAL International Workshop on Analytics for
    Big Geospatial Data, BigSpatial 2016, no. October: 1–6. doi:10.1145/3006386.3006393.  Google
    Scholar Casado, Rubén, and Muhammad Younas. 2015. “Emerging Trends and Technologies
    in Big Data Processing.” Concurrency and Computation: Practice and Experience
    27 (8): 2078–2091. doi:10.1002/cpe.3398.  Web of Science ®Google Scholar Casu,
    F., M. Manunta, P. S. Agram, and R. E. Crippen. 2017. “Big Remotely Sensed Data:
    Tools, Applications and Experiences.” Remote Sensing of Environment 202 (September):
    Elsevier: 1–2. doi:10.1016/j.rse.2017.09.013.  Google Scholar Cattell, Rick. 2010.
    “Scalable SQL and NoSQL Data Stores.” ACM SIGMOD Record 39 (4): 12–27. doi:10.1145/1978915.1978919.  Web
    of Science ®Google Scholar “CEOS”. 2022. https://ceos.org/ard/.  Google Scholar
    Chambers, Craig, Ashish Raniwala, Frances Perry, Stephen Adams, Robert R. Henry,
    Robert Bradshaw, and Nathan Weizenbaum. 2010. “FlumeJava.” ACM SIGPLAN Notices
    45 (6): 363–375. doi:10.1145/1809028.1806638.  Google Scholar Chang, Fay, Jeffrey
    Dean, Sanjay Ghemawat, Wilson C. Hsieh, Deborah A. Wallach, Mike Burrows, Tushar
    Chandra, Andrew Fikes, and Robert E. Gruber. 2006. “BigTable: A Distributed Storage
    System for Structured Data.” In OSDI 2006 - 7th USENIX Symposium on Operating
    Systems Design and Implementation, 205–218.  Google Scholar Chebbi, I., W. Boulila,
    and I. R. Farah. 2016. Improvement of Satellite Image Classification: Approach
    Based on Hadoop/MapReduce.” 2nd International Conference on Advanced Technologies
    for Signal and Image Processing, ATSIP 2016. IEEE, 31–34. doi:10.1109/ATSIP.2016.7523046.  Google
    Scholar Chebbi, I., W. Boulila, N. Mellouli, M. Lamolle, and I. R. Farah. 2018.
    A Comparison of Big Remote Sensing Data Processing with Hadoop MapReduce and Spark.”
    2018 4th International Conference on Advanced Technologies for Signal and Image
    Processing, ATSIP 2018. IEEE, 1–4. doi:10.1109/ATSIP.2018.8364497.  Google Scholar
    Chen, Shijuan, Curtis E. Woodcock, Eric L. Bullock, Paulo Arévalo, Paata Torchinava,
    Siqi Peng, and Pontus Olofsson. 2021. “Monitoring Temperate Forest Degradation
    on Google Earth Engine Using Landsat Time Series Analysis.” Remote Sensing of
    Environment 265 (August), doi:10.1016/j.rse.2021.112648.  PubMedGoogle Scholar
    Cheng, Yinyi, Kefa Zhou, Jinlin Wang, and Jining Yan. 2020. “Big Earth Observation
    Data Integration in Remote Sensing Based on a Distributed Spatial Framework.”
    Remote Sensing 12 (6), doi:10.3390/rs12060972.  Web of Science ®Google Scholar
    Chi, Mingmin, Antonio Plaza, Jon Atli Benediktsson, Zhongyi Sun, Jinsheng Shen,
    and Yangyong Zhu. 2016. “Big Data for Remote Sensing: Challenges and Opportunities.”
    Proceedings of the IEEE 104 (11): 2207–2219. doi:10.1109/JPROC.2016.2598228.  Web
    of Science ®Google Scholar Claverie, Martin, Junchang Ju, Jeffrey G. Masek, Jennifer
    L. Dungan, Eric F. Vermote, Jean Claude Roger, Sergii V. Skakun, and Christopher
    Justice. 2018. “The Harmonized Landsat and Sentinel-2 Surface Reflectance Data
    Set.” Remote Sensing of Environment 219 (August): Elsevier: 145–161. doi:10.1016/j.rse.2018.09.002.  Google
    Scholar Closa, Guillem, Joan Masó, Alaitz Zabala, Lluís Pesquer, and Xavier Pons.
    2019. “A Provenance Metadata Model Integrating ISO Geospatial Lineage and the
    OGC WPS: Conceptual Model and Implementation.” Transactions in GIS 23 (5): 1102–1124.
    doi:10.1111/tgis.12555.  Web of Science ®Google Scholar “Cloud Optimized GeoTIFF”.
    2022. Accessed April 6. https://www.cogeo.org/.  Google Scholar Codd, E. F. 1970.
    “A Relational Model of Data for Large Shared Data Banks.” Communications of the
    ACM 13 (6): 377–387. doi:10.1145/362384.362685.  Web of Science ®Google Scholar
    Corbane, Christina, Martino Pesaresi, Panagiotis Politis, Vasileios Syrris, Aneta
    J. Florczyk, Pierre Soille, Luca Maffenini, et al. 2017. “Big Earth Data Analytics
    on Sentinel-1 and Landsat Imagery in Support to Global Human Settlements Mapping.”
    Big Earth Data 1 (1–2): Taylor & Francis: 118–144. doi:10.1080/20964471.2017.1397899.  Google
    Scholar Corbett, James C., Jeffrey Dean, Michael Epstein, Andrew Fikes, Christopher
    Frost, J. J. Furman, Sanjay Ghemawat, et al. 2013. “Spanner.” ACM Transactions
    on Computer Systems 31 (3): 1–22. doi:10.1145/2491245.  Web of Science ®Google
    Scholar D’Andrimont, Raphaël, Astrid Verhegghen, Guido Lemoine, Pieter Kempeneers,
    Michele Meroni, and Marijn van der Velde. 2021. “From Parcel to Continental Scale
    – A First European Crop Type Map Based on Sentinel-1 and LUCAS Copernicus in-Situ
    Observations.” Remote Sensing of Environment 266 (May), doi:10.1016/j.rse.2021.112708.  Google
    Scholar “Data and Information Access Services”. 2021. Accessed September 27. https://www.copernicus.eu/en/access-data/dias.  Google
    Scholar Davoudian, Ali, Liu Chen, and Mengchi Liu. 2018. “A Survey on NoSQL Stores.”
    ACM Computing Surveys 51 (2), doi:10.1145/3158661.  Web of Science ®Google Scholar
    Dean, Hildebrand, and Serenyi Denis. 2021. “Colossus under the Hood: A Peek into
    Google’s Scalable Storage System.” Accessed October 2. https://cloud.google.com/blog/products/storage-data-transfer/a-peek-behind-colossus-googles-file-system.  Google
    Scholar Dean, Jeffrey, and Sanjay Ghemawat. 2008. “MapReduce.” Communications
    of the ACM 51 (1): 107–113. doi:10.1145/1327452.1327492.  Web of Science ®Google
    Scholar Dillon, Tharam, Chen Wu, and Elizabeth Chang. 2010. Cloud Computing: Issues
    and Challenges.” In 2010 24th IEEE International Conference on Advanced Information
    Networking and Applications, 27–33. IEEE. doi:10.1109/AINA.2010.187.  Google Scholar
    Drusch, M., U. Del Bello, S. Carlier, O. Colin, V. Fernandez, F. Gascon, B. Hoersch,
    et al. 2012. “Sentinel-2: ESA’s Optical High-Resolution Mission for GMES Operational
    Services.” Remote Sensing of Environment 120 (May): 25–36. doi:10.1016/j.rse.2011.11.026.  Google
    Scholar Dwyer, John L., David P. Roy, Brian Sauer, Calli B. Jenkerson, Hankui
    K. Zhang, and Leo Lymburner. 2018. “Analysis Ready Data: Enabling Analysis of
    the Landsat Archive.” Remote Sensing 10 (9): 1363–1319. doi:10.3390/rs10091363.  Web
    of Science ®Google Scholar Eldawy, Ahmed, and Mohamed F. Mokbel. 2015. “SpatialHadoop:
    A MapReduce Framework for Spatial Data.” Proceedings - International Conference
    on Data Engineering 2015-May, IEEE: 1352–1363. doi:10.1109/ICDE.2015.7113382.  Google
    Scholar Fan, Junqing, Jining Yan, Yan Ma, and Lizhe Wang. 2017. “Big Data Integration
    in Remote Sensing Across a Distributed Metadata-Based Spatial Infrastructure.”
    Remote Sensing 10 (2): 7. doi:10.3390/rs10010007.  Google Scholar Ferreira, K.
    R., G. R. Queiroz, G. Camara, R. C. M. Souza, L. Vinhas, R. F. B. Marujo, R. E.
    O. Simoes, et al. 2020. Using Remote Sensing Images and Cloud Services on Aws
    to Improve Land Use and Cover Monitoring.” In 2020 IEEE Latin American GRSS &
    ISPRS Remote Sensing Conference (LAGIRS), 558–562. IEEE. doi:10.1109/LAGIRS48042.2020.9165649.  Google
    Scholar Ferreira, Karine R., Gilberto R. Queiroz, Lubia Vinhas, Rennan F. B. Marujo,
    Rolf E. O. Simoes, Michelle C. A. Picoli, Gilberto Camara, et al. 2020. “Earth
    Observation Data Cubes for Brazil: Requirements, Methodology and Products.” Remote
    Sensing 12 (24): 4033. doi:10.3390/rs12244033.  Web of Science ®Google Scholar
    Frantz, David. 2019. “FORCE—Landsat + Sentinel-2 Analysis Ready Data and Beyond.”
    Remote Sensing 11 (9): 1124. doi:10.3390/rs11091124.  Web of Science ®Google Scholar
    Fu, Kaiyu, Qiuhong Li, Siyu Fan, Ting Li, Tian Huang, and Yuan Luo. 2020. “Big
    Data in Astronomy.” Big Data in Astronomy. Elsevier Inc, doi:10.1016/b978-0-12-819084-5.00001-8.  Google
    Scholar Gao, Huan, Xiaolin Zhu, Qingfeng Guan, Xue Yang, Yao Yao, Wen Zeng, and
    Xuantong Peng. 2022. “CuFSDAF: An Enhanced Flexible Spatiotemporal Data Fusion
    Algorithm Parallelized Using Graphics Processing Units.” IEEE Transactions on
    Geoscience and Remote Sensing 60: IEEE. doi:10.1109/TGRS.2021.3080384.  Web of
    Science ®Google Scholar Ghemawat, Sanjay, Howard Gobioff, and Shun-Tak Leung.
    2003. The Google File System.” In Proceedings of the Nineteenth ACM Symposium
    on Operating Systems Principles - SOSP ‘03, 75:29. New York, New York, USA: ACM
    Press. doi:10.1145/945445.945450.  Google Scholar Giuliani, Gregory, Bruno Chatenoux,
    Andrea De Bono, Denisa Rodila, Jean-Philippe Richard, Karin Allenbach, Hy Dao,
    and Pascal Peduzzi. 2017. “Building an Earth Observations Data Cube: Lessons Learned
    from the Swiss Data Cube (SDC) on Generating Analysis Ready Data (ARD).” Big Earth
    Data 1 (1–2): Taylor & Francis: 100–117. doi:10.1080/20964471.2017.1398903.  Google
    Scholar Giuliani, Gregory, Bruno Chatenoux, Thomas Piller, Frédéric Moser, and
    Pierre Lacroix. 2020. “Data Cube on Demand (DCoD): Generating an Earth Observation
    Data Cube Anywhere in the World.” International Journal of Applied Earth Observation
    and Geoinformation 87 (December 2019): Elsevier: 102035. doi:10.1016/j.jag.2019.102035.  Google
    Scholar Giuliani, Gregory, Hy Dao, Andrea De Bono, Bruno Chatenoux, Karin Allenbach,
    Pierric De Laborie, Denisa Rodila, Nikos Alexandris, and Pascal Peduzzi. 2017.
    “Live Monitoring of Earth Surface (LiMES): A Framework for Monitoring Environmental
    Changes from Earth Observations.” Remote Sensing of Environment 202: Elsevier
    Inc.: 222–233. doi:10.1016/j.rse.2017.05.040.  Web of Science ®Google Scholar
    Gomes, Vitor C.F., Gilberto R. Queiroz, and Karine R. Ferreira. 2020. “An Overview
    of Platforms for Big Earth Observation Data Management and Analysis.” Remote Sensing
    12 (8): 1253–1225. doi:10.3390/RS12081253.  Web of Science ®Google Scholar Gong,
    Peng, Xuecao Li, Jie Wang, Yuqi Bai, Bin Chen, Tengyun Hu, Xiaoping Liu, et al.
    2020. “Annual Maps of Global Artificial Impervious Area (GAIA) Between 1985 and
    2018.” Remote Sensing of Environment 236 (November 2019): Elsevier: 111510. doi:10.1016/j.rse.2019.111510.  Google
    Scholar Gorelick, Noel, Matt Hancher, Mike Dixon, Simon Ilyushchenko, David Thau,
    and Rebecca Moore. 2017. “Google Earth Engine: Planetary-Scale Geospatial Analysis
    for Everyone.” Remote Sensing of Environment 202 (December): The Author(s): 18–27.
    doi:10.1016/j.rse.2017.06.031.  Google Scholar “G-POD”. 2021. Accessed December
    2. https://wiki.services.eoportal.org/tiki-index.php?page=GPOD Wiki.  Google Scholar
    Gray, Andrew, Monika Krolikowski, Peter Fretwell, Peter Convey, Lloyd S. Peck,
    Monika Mendelova, Alison G. Smith, and Matthew P. Davey. 2020. “Remote Sensing
    Reveals Antarctic Green Snow Algae as Important Terrestrial Carbon Sink.” Nature
    Communications 11 (1): Springer US: 2527. doi:10.1038/s41467-020-16018-w.  PubMed
    Web of Science ®Google Scholar Gray, Jim, and Andreas Reuter. 1992. Transaction
    Processing: Concepts and Techniques. Elsevier.  Google Scholar Guo, Huadong, Fang
    Chen, Zhongchang Sun, Jie Liu, and Dong Liang. 2021. “Big Earth Data: A Practice
    of Sustainability Science to Achieve the Sustainable Development Goals.” Science
    Bulletin 66 (11): Science China Press: 1050–1053. doi:10.1016/j.scib.2021.01.012.  PubMed
    Web of Science ®Google Scholar Guo, Huadong, Zhen Liu, Hao Jiang, Changlin Wang,
    Jie Liu, and Dong Liang. 2017. “Big Earth Data: A New Challenge and Opportunity
    for Digital Earth’s Development.” International Journal of Digital Earth 10 (1):
    Taylor & Francis: 1–12. doi:10.1080/17538947.2016.1264490.  Web of Science ®Google
    Scholar Guo, Huadong, Stefano Nativi, Dong Liang, Max Craglia, Lizhe Wang, Sven
    Schade, Christina Corban, et al. 2020. “Big Earth Data Science: An Information
    Framework for a Sustainable Planet.” International Journal of Digital Earth 13
    (7): Taylor & Francis: 743–767. doi:10.1080/17538947.2020.1743785.  Web of Science
    ®Google Scholar Guo, Dongming, and Erling Onstein. 2020. “State-of-the-Art Geospatial
    Information Processing in NoSQL Databases.” ISPRS International Journal of Geo-Information
    9 (5), doi:10.3390/ijgi9050331.  Web of Science ®Google Scholar Guo, Dizhou, Wenzhong
    Shi, Ming Hao, and Xiaolin Zhu. 2020. “FSDAF 2.0: Improving the Performance of
    Retrieving Land Cover Changes and Preserving Spatial Details.” Remote Sensing
    of Environment 248 (July): Elsevier: 111973. doi:10.1016/j.rse.2020.111973.  Google
    Scholar Gupta, Abhishek, Laxmikant V. Kale, Filippo Gioachin, Verdi March, Chun
    Hui Suen, Bu Sung Lee, Paolo Faraboschi, Richard Kaufmann, and Dejan Milojicic.
    2013. “The Who What Why and How of High Performance Computing in the Cloud.” Proceedings
    of the International Conference on Cloud Computing Technology and Science CloudCom
    1: IEEE: 306–314. doi:10.1109/CloudCom.2013.47.  Google Scholar Hamunyela, Eliakim,
    Sabina Rosca, Andrei Mirt, Eric Engle, Martin Herold, Fabian Gieseke, and Jan
    Verbesselt. 2020. “Implementation of BFASTmonitor Algorithm on Google Earth Engine
    to Support Large-Area and Sub-Annual Change Monitoring Using Earth Observation
    Data.” Remote Sensing 12 (18), doi:10.3390/RS12182953.  Web of Science ®Google
    Scholar Hansen, M. C., P. V. Potapov, R. Moore, M. Hancher, S. A. Turubanova,
    A. Tyukavina, D. Thau, et al. 2013. “High-Resolution Global Maps of 21st-Century
    Forest Cover Change.” Science 342 (6160): 850–853. doi:10.1126/science.1244693.  PubMed
    Web of Science ®Google Scholar Henderson, Robert L. 1995. Job Scheduling under
    the Portable Batch System.” In 279–294. doi:10.1007/3-540-60153-8_34.  Google
    Scholar Hey, Tony, Stewart Tansley, and Kristin Tolle. 2009. “The Fourth Paradigm:
    Data-Intensive Scientific.” Microsoft Research.  Google Scholar Hughes, James
    N., Andrew Annex, Christopher N. Eichelberger, Anthony Fox, Andrew Hulbert, and
    Michael Ronquest. 2015. “GeoMesa: A Distributed Architecture for Spatio-Temporal
    Fusion.” In Geospatial Informatics Fusion and Motion Video Analytics V, edited
    by Matthew F. Pellechia, Kannappan Palaniappan, Peter J. Doucette, Shiloh L. Dockstader,
    and Gunasekaran Seetharaman (9473), 94730F. doi:10.1117/12.2177233.  Google Scholar
    Jing, Weipeng, Shuaiqi Huo, Qiucheng Miao, and Xuebin Chen. 2017. “A Model of
    Parallel Mosaicking for Massive Remote Sensing Images Based on Spark.” IEEE Access
    5: 18229–18237. doi:10.1109/ACCESS.2017.2746098.  Web of Science ®Google Scholar
    Jordan, M. I., and T. M. Mitchell. 2015. “Machine Learning: Trends Perspectives
    and Prospects.” Science 349 (6245): 255–260. doi:10.1126/science.aaa8415.  PubMed
    Web of Science ®Google Scholar Killough, Brian. 2018. Overview of the Open Data
    Cube Initiative.” In IGARSS 2018 - 2018 IEEE International Geoscience and Remote
    Sensing Symposium 2018-July:8629–8632. IEEE. doi:10.1109/IGARSS.2018.8517694.  Google
    Scholar Kini, Ameet, and Rob Emanuele. 2014. “Geotrellis: Adding Geospatial Capabilities
    to Spark.” Spark Summit.  Google Scholar Kuo, Kwo-sen, Yu Pan, Feiyu Zhu, Jin
    Wang, Michael L Rilee, and Hongfeng Yu. 2018. A Big Earth Data Platform Exploiting
    Transparent Multimodal Parallelization.” In IGARSS 2018 - 2018 IEEE International
    Geoscience and Remote Sensing Symposium 6532–6535. IEEE. doi:10.1109/IGARSS.2018.8518304.  Google
    Scholar Lassalle, Pierre, Jordi Inglada, Julien Michel, Manuel Grizonnet, and
    Julien Malik. 2015. “A Scalable Tile-Based Framework for Region-Merging Segmentation.”
    IEEE Transactions on Geoscience and Remote Sensing 53 (10): IEEE: 5473–5485. doi:10.1109/TGRS.2015.2422848.  Web
    of Science ®Google Scholar Lecun, Yann, Yoshua Bengio, and Geoffrey Hinton. 2015.
    “Deep Learning.” Nature 521 (7553): 436–444. doi:10.1038/nature14539.  PubMed
    Web of Science ®Google Scholar Lewis, Adam, Leo Lymburner, Matthew B.J. Purss,
    Brendan Brooke, Ben Evans, Alex Ip, Arnold G. Dekker, et al. 2016. “Rapid High-Resolution
    Detection of Environmental Change Over Continental Scales from Satellite Data
    – the Earth Observation Data Cube.” International Journal of Digital Earth 9 (1):
    106–111. doi:10.1080/17538947.2015.1111952.  Web of Science ®Google Scholar Lewis,
    Adam, Simon Oliver, Leo Lymburner, Ben Evans, Lesley Wyborn, Norman Mueller, Gregory
    Raevksi, et al. 2017. “The Australian Geoscience Data Cube — Foundations and Lessons
    Learned.” Remote Sensing of Environment 202 (December): Elsevier Inc.: 276–292.
    doi:10.1016/j.rse.2017.03.015.  Google Scholar Li, Feifei. 2019. “Cloud-Native
    Database Systems at Alibaba.” Proceedings of the VLDB Endowment 12 (12): 2263–2272.
    doi:10.14778/3352063.3352141.  Web of Science ®Google Scholar Li, Xueying, and
    Di Long. 2020. “An Improvement in Accuracy and Spatiotemporal Continuity of the
    MODIS Precipitable Water Vapor Product Based on a Data Fusion Approach.” Remote
    Sensing of Environment 248 (October): 111966. doi:10.1016/j.rse.2020.111966.  Google
    Scholar Li, Hongyi, and Ping Tang. 2019. The Data Preparation Research on Global
    Multi-Source Synergized Quantitative Remote Sensing Production System.” In IGARSS
    2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium 4340–4343.
    IEEE. doi:10.1109/IGARSS.2019.8899119.  Google Scholar Li, Chunlin, Jing Zhang,
    Tao Ma, Hengliang Tang, Lei Zhang, and Youlong Luo. 2019. “Data Locality Optimization
    Based on Data Migration and Hotspots Prediction in Geo-Distributed Cloud Environment.”
    Knowledge-Based Systems 165: Elsevier B.V.: 321–334. doi:10.1016/j.knosys.2018.12.002.  Web
    of Science ®Google Scholar Liang, Shunlin. 2003. Quantitative Remote Sensing of
    Land Surfaces. Hoboken, NJ, USA: John Wiley & Sons Inc. doi:10.1002/047172372X.  Google
    Scholar Liu, Han, Peng Gong, Jie Wang, Xi Wang, Grant Ning, and Bing Xu. 2021.
    “Production of Global Daily Seamless Data Cubes and Quantification of Global Land
    Cover Change from 1985 to 2020 - IMap World 1.0.” Remote Sensing of Environment
    258 (June): 112364. doi:10.1016/j.rse.2021.112364.  Google Scholar Liu, Jie, Wei
    Wang, and Hua Zhong. 2020. “EarthDataMiner: A Cloud-Based Big Earth Data Intelligence
    Analysis Platform.” IOP Conference Series: Earth and Environmental Science 509
    (1): 012032–012012. doi:10.1088/1755-1315/509/1/012032.  Google Scholar Liu, Luo,
    Xiangming Xiao, Yuanwei Qin, Jie Wang, Xinliang Xu, Yueming Hu, and Zhi Qiao.
    2020. “Mapping Cropping Intensity in China Using Time Series Landsat and Sentinel-2
    Images and Google Earth Engine.” Remote Sensing of Environment 239 (June 2019):
    Elsevier: 111624. doi:10.1016/j.rse.2019.111624.  Google Scholar Lu, Meng, Marius
    Appel, and Edzer Pebesma. 2018. “Multidimensional Arrays for Analysing Geoscientific
    Data.” ISPRS International Journal of Geo-Information 7 (8): 313–320. doi:10.3390/ijgi7080313.  Web
    of Science ®Google Scholar Lü, Xuefeng, Chengqi Cheng, Jianya Gong, and Li Guan.
    2011. “Review of Data Storage and Management Technologies for Massive Remote Sensing
    Data.” Science China Technological Sciences 54 (12): 3220–3232. doi:10.1007/s11431-011-4549-z.  Web
    of Science ®Google Scholar Lu, Ying, and Le Wang. 2021. “How to Automate Timely
    Large-Scale Mangrove Mapping with Remote Sensing.” Remote Sensing of Environment
    264 (June): Elsevier Inc.: 112584. doi:10.1016/j.rse.2021.112584.  Google Scholar
    Lunga, Dalton, Jonathan Gerrand, Lexie Yang, Christopher Layton, and Robert Stewart.
    2020. “Apache Spark Accelerated Deep Learning Inference for Large Scale Satellite
    Image Analytics.” IEEE Journal of Selected Topics in Applied Earth Observations
    and Remote Sensing 13: 271–283. doi:10.1109/JSTARS.2019.2959707.  Web of Science
    ®Google Scholar Ma, Yan, Haiping Wu, Lizhe Wang, Bormin Huang, Rajiv Ranjan, Albert
    Zomaya, and Wei Jie. 2015. “Remote Sensing Big Data Computing: Challenges and
    Opportunities.” Future Generation Computer Systems 51 (October): Elsevier B.V.:
    47–60. doi:10.1016/j.future.2014.10.029.  Google Scholar Makrani, Hosein Mohammadi,
    Hossein Sayadi, Sai Manoj Pudukotai Dinakarra, Setareh Rafatirad, and Houman Homayoun.
    2018. A Comprehensive Memory Analysis of Data Intensive Workloads on Server Class
    Architecture.” In Proceedings of the International Symposium on Memory Systems
    19–30. New York NY USA: ACM. doi:10.1145/3240302.3240320.  Google Scholar Masek,
    Jeffrey G., Michael A. Wulder, Brian Markham, Joel McCorkel, Christopher J. Crawford,
    James Storey, and Del T. Jenstrom. 2020. “Landsat 9: Empowering Open Science and
    Applications Through Continuity.” Remote Sensing of Environment 248 (June): Elsevier:
    111968. doi:10.1016/j.rse.2020.111968.  Google Scholar Mehta, Parmita, Sven Dorkenwald,
    Dongfang Zhao, Tomer Kaftan, Alvin Cheung, Magdalena Balazinska, Ariel Rokem,
    Andrew Connolly, Jacob Vanderplas, and Yusra Al-Sayyad. 2017. “Comparative Evaluation
    of Big-Data Systems on Scientific Image Analytics Workloads.” Proceedings of the
    VLDB Endowment 10 (11): 1226–1237. doi:10.14778/3137628.3137634.  Web of Science
    ®Google Scholar Mehul Nalin, Vora. 2011. Hadoop-HBase for Large-Scale Data.” In
    Proceedings of 2011 International Conference on Computer Science and Network Technology
    1:601–605. IEEE. doi:10.1109/ICCSNT.2011.6182030.  Google Scholar Merkel, Dirk.
    2014. “Docker : Lightweight Linux Containers for Consistent Development and Deployment
    Docker : A Little Background Under the Hood.” Linux Journal 2014 (239): 2–7.  Google
    Scholar Mhawish, Alaa, Meytar Sorek-Hamer, Robert Chatfield, Tirthankar Banerjee,
    Muhammad Bilal, Manish Kumar, Chandan Sarangi, et al. 2021. “Aerosol Characteristics
    from Earth Observation Systems: A Comprehensive Investigation Over South Asia
    (2000–2019).” Remote Sensing of Environment 259 (June): 112410. doi:10.1016/j.rse.2021.112410.  Google
    Scholar Moon, Il-Ju, Sung-Hun Kim, and Johnny C. L. Chan. 2019. “Climate Change
    and Tropical Cyclone Trend.” Nature 570 (7759): Springer US: E3–E5. doi:10.1038/s41586-019-1222-3.  PubMed
    Web of Science ®Google Scholar “NASA Earth Exchange”. 2022. Accessed January 14.
    https://www.nasa.gov/nex.  Google Scholar “NASA Unified Metadata Model”. 2022.
    Accessed January 13. https://earthdata.nasa.gov/eosdis/science-system-description/eosdis-components/cmr/umm.  Google
    Scholar Neal, C. A., S. R. Brantley, L. Antolik, J. L. Babb, and Etc. 2019. “The
    2018 Rift Eruption and Summit Collapse of Kīlauea Volcano.” Science 363 (January):
    367–374. doi:10.1126/science.aav7046  PubMedGoogle Scholar Ni, Rongguang, Jinyan
    Tian, Xiaojuan Li, Dameng Yin, Jiwei Li, Huili Gong, Jie Zhang, Lin Zhu, and Dongli
    Wu. 2021. “An Enhanced Pixel-Based Phenological Feature for Accurate Paddy Rice
    Mapping with Sentinel-2 Imagery in Google Earth Engine.” ISPRS Journal of Photogrammetry
    and Remote Sensing 178 (February): Elsevier B.V.: 282–296. doi:10.1016/j.isprsjprs.2021.06.018.  Google
    Scholar Ordonez, Carlos, Yiqun Zhang, and S. Lennart Johnsson. 2019. “Scalable
    Machine Learning Computing a Data Summarization Matrix with a Parallel Array DBMS.”
    Distributed and Parallel Databases 37 (3): 329–350. doi:10.1007/s10619-018-7229-1.  Web
    of Science ®Google Scholar Pagani, Giuliano Andrea, and Luca Trani. 2018. Data
    Cube and Cloud Resources as Platform for Seamless Geospatial Computation.” 2018
    ACM International Conference on Computing Frontiers CF 2018 - Proceedings 293–298.
    doi:10.1145/3203217.3205861.  Google Scholar Papadopoulos, Stavros, Kushal Datta,
    Samuel Madden, and Timothy Mattson. 2016. “The TileDB Array Data Storage Manager.”
    Proceedings of the VLDB Endowment 10 (4): 349–360. doi:10.14778/3025111.3025117.  Google
    Scholar Pastor-Guzman, J., L. Brown, H. Morris, L. Bourg, P. Goryl, S. Dransfeld,
    and J. Dash. 2020. “The Sentinel-3 OLCI Terrestrial Chlorophyll Index (OTCI):
    Algorithm Improvements Spatiotemporal Consistency and Continuity with the MERIS
    Archive.” Remote Sensing 12 (16): 2652. doi:10.3390/rs12162652.  Web of Science
    ®Google Scholar Pavlo, Andrew, and Matthew Aslett. 2016. “What’s Really New with
    NewSQL?” ACM SIGMOD Record 45 (2): 45–55. doi:10.1145/3003665.3003674.  Web of
    Science ®Google Scholar Pekel, Jean François, Andrew Cottam, Noel Gorelick, and
    Alan S. Belward. 2016. “High-Resolution Mapping of Global Surface Water and Its
    Long-Term Changes.” Nature 540 (7633): Nature Publishing Group: 418–422. doi:10.1038/nature20584.  PubMed
    Web of Science ®Google Scholar Pelle, Istvan, Janos Czentye, Janos Doka, and Balazs
    Sonkoly. 2019. Towards Latency Sensitive Cloud Native Applications: A Performance
    Study on AWS.” In 2019 IEEE 12th International Conference on Cloud Computing (CLOUD)
    272–280. IEEE. doi:10.1109/CLOUD.2019.00054.  Google Scholar Peters, A. J., E.
    A. Sindrilaru, and G. Adde. 2015. “EOS as the Present and Future Solution for
    Data Storage at CERN.” Journal of Physics: Conference Series 664 (4): 042042.
    doi:10.1088/1742-6596/664/4/042042.  Google Scholar “PIE Engine”. 2022. Accessed
    January 14. https://www.piesat.cn/product/PIE-Engine-yaoganyunpingtai/index.html.  Google
    Scholar “Planetary Computer”. 2022. https://planetarycomputer.microsoft.com/.  Google
    Scholar Poortinga, Ate, Nicholas Clinton, David Saah, Peter Cutter, Farrukh Chishtie,
    Kel N. Markert, Eric R. Anderson, et al. 2018. “An Operational Before-After-Control-Impact
    (BACI) Designed Platform for Vegetation Monitoring at Planetary Scale.” Remote
    Sensing 10 (5), doi:10.3390/rs10050760.  Web of Science ®Google Scholar Popkin,
    Gabriel. 2018. “US Government Considers Charging for Popular Earth-Observing Data.”
    Nature 556 (7702): 417–418. doi:10.1038/d41586-018-04874-y.  PubMedGoogle Scholar
    Potapov, Peter, Matthew C. Hansen, Indrani Kommareddy, Anil Kommareddy, Svetlana
    Turubanova, Amy Pickens, Bernard Adusei, Alexandra Tyukavina, and Qing Ying. 2020.
    “Landsat Analysis Ready Data for Global Land Cover and Land Cover Change Mapping.”
    Remote Sensing 12 (3): 426. doi:10.3390/rs12030426.  Web of Science ®Google Scholar
    Qiu, Shi, Yukun Lin, Rong Shang, Junxue Zhang, Lei Ma, and Zhe Zhu. 2018. “Making
    Landsat Time Series Consistent: Evaluating and Improving Landsat Analysis Ready
    Data.” Remote Sensing 11 (1): 51. doi:10.3390/rs11010051.  Web of Science ®Google
    Scholar Qiu, Shi, Zhe Zhu, and Binbin He. 2019. “Fmask 4.0: Improved Cloud and
    Cloud Shadow Detection in Landsats 4–8 and Sentinel-2 Imagery.” Remote Sensing
    of Environment 231 (June): Elsevier: 111205. doi:10.1016/j.rse.2019.05.024.  Google
    Scholar Qu, Tengteng, Lizhe Wang, Jian Yu, Jining Yan, Guilin Xu, Meng Li, Chengqi
    Cheng, Kaihua Hou, and Bo Chen. 2020. “STGI:a Spatio-Temporal Grid Index Model
    for Marine Big Data.” Big Earth Data 4 (4): 435–450. doi:10.1080/20964471.2020.1844933.  Google
    Scholar Rittger, Karl, Mitchell Krock, William Kleiber, Edward H. Bair, Mary J.
    Brodzik, Thomas R. Stephenson, Balaji Rajagopalan, Kat J. Bormann, and Thomas
    H. Painter. 2021. “Multi-sensor Fusion Using Random Forests for Daily Fractional
    Snow Cover at 30 m.” Remote Sensing of Environment 264 (August): Elsevier Inc.:
    112608. doi:10.1016/j.rse.2021.112608.  Google Scholar Rocklin, Matthew. 2015.
    “Proceedings of the Python in Science Conference.” In Proceedings of the 14th
    Python in Science Conference, 126–132. doi:10.25080/Majora-7b98e3ed-013.  Google
    Scholar Rowley, Jennifer. 2007. “The Wisdom Hierarchy: Representations of the
    DIKW Hierarchy.” Journal of Information Science 33 (2): 163–180. doi:10.1177/0165551506070706.  Web
    of Science ®Google Scholar Roy, D. P., M. A. Wulder, T. R. Loveland, C. E. Woodcock,
    R. G. Allen, M. C. Anderson, D. Helder, et al. 2014. “Landsat-8: Science and Product
    Vision for Terrestrial Global Change Research.” Remote Sensing of Environment
    145: Elsevier B.V.: 154–172. doi:10.1016/j.rse.2014.02.001.  Web of Science ®Google
    Scholar Sakr, Sherif, Anna Liu, Daniel M. Batista, and Mohammad Alomari. 2011.
    “A Survey of Large Scale Data Management Approaches in Cloud Environments.” IEEE
    Communications Surveys & Tutorials 13 (3): IEEE: 311–336. doi:10.1109/SURV.2011.032211.00087.  Web
    of Science ®Google Scholar Sarker, Md Nazirul Islam, Yang Peng, Cheng Yiran, and
    Roger C. Shouse. 2020. “Disaster Resilience Through Big Data: Way to Environmental
    Sustainability.” International Journal of Disaster Risk Reduction 51 (July): Elsevier
    Ltd: 101769. doi:10.1016/j.ijdrr.2020.101769.  Google Scholar Saxena, Manvi, Shweta
    Jha, Saba Khan, John Rodgers, Peggy Lindner, and Edgar Gabriel. 2020. Comparison
    of MPI and Spark for Data Science Applications.” In 2020 IEEE International Parallel
    and Distributed Processing Symposium Workshops (IPDPSW) 682–690. IEEE. doi:10.1109/IPDPSW50202.2020.00123.  Google
    Scholar Schramm, Matthias, Edzer Pebesma, Milutin Milenković, Luca Foresta, Jeroen
    Dries, Alexander Jacob, Wolfgang Wagner, et al. 2021. “The Openeo Api–Harmonising
    the Use of Earth Observation Cloud Services Using Virtual Data Cube Functionalities.”
    Remote Sensing 13 (6): 1125–1121. doi:10.3390/rs13061125.  Web of Science ®Google
    Scholar “Sentinel Hub”. 2022. Accessed January 14. https://www.sentinel-hub.com/.  Google
    Scholar Shvachko, Konstantin, Hairong Kuang, Sanjay Radia, and Robert Chansler.
    2010. The Hadoop Distributed File System.” In 2010 IEEE 26th Symposium on Mass
    Storage Systems and Technologies (MSST) 454:1–10. IEEE. doi:10.1109/MSST.2010.5496972.  Google
    Scholar Soille, P., A. Burger, D. De Marchi, P. Kempeneers, D. Rodriguez, V. Syrris,
    and V. Vasilev. 2018. “A Versatile Data-Intensive Computing Platform for Information
    Retrieval from Big Geospatial Data.” Future Generation Computer Systems 81: Elsevier
    B.V.: 30–40. doi:10.1016/j.future.2017.11.007.  Web of Science ®Google Scholar
    Sudmanns, Martin, Dirk Tiede, Stefan Lang, Helena Bergstedt, Georg Trost, Hannah
    Augustin, Andrea Baraldi, and Thomas Blaschke. 2020. “Big Earth Data: Disruptive
    Changes in Earth Observation Data Management and Analysis?” International Journal
    of Digital Earth 13 (7): Taylor & Francis: 832–850. doi:10.1080/17538947.2019.1585976.  Web
    of Science ®Google Scholar Sun, Jin, Yi Zhang, Zebin Wu, Yaoqin Zhu, Xianliang
    Yin, Zhongzheng Ding, Zhihui Wei, Javier Plaza, and Antonio Plaza. 2019. “An Efficient
    and Scalable Framework for Processing Remotely Sensed Big Data in Cloud Computing
    Environments.” IEEE Transactions on Geoscience and Remote Sensing 57 (7): IEEE:
    4294–4308. doi:10.1109/TGRS.2018.2890513.  Web of Science ®Google Scholar Tamiminia,
    Haifa, Bahram Salehi, Masoud Mahdianpari, Lindi Quackenbush, Sarina Adeli, and
    Brian Brisco. 2020. “Google Earth Engine for Geo-Big Data Applications: A Meta-Analysis
    and Systematic Review.” ISPRS Journal of Photogrammetry and Remote Sensing 164
    (March): Elsevier: 152–170. doi:10.1016/j.isprsjprs.2020.04.001.  Google Scholar
    Tecuapetla-Gómez, Inder, Gerardo López-Saldaña, María Isabel Cruz-López, and Rainer
    Ressl. 2021. “TATSSI: A Free and Open-Source Platform for Analyzing Earth Observation
    Products with Quality Data Assessment.” ISPRS International Journal of Geo-Information
    10 (4), doi:10.3390/ijgi10040267.  PubMed Web of Science ®Google Scholar Thorp,
    K. R., and D. Drajat. 2021. “Deep Machine Learning with Sentinel Satellite Data
    to Map Paddy Rice Production Stages Across West Java Indonesia.” Remote Sensing
    of Environment 265 (November): 112679. doi:10.1016/j.rse.2021.112679.  Google
    Scholar Toth, Charles, and Grzegorz Jóźków. 2016. “Remote Sensing Platforms and
    Sensors: A Survey.” ISPRS Journal of Photogrammetry and Remote Sensing 115 (May):
    22–36. doi:10.1016/j.isprsjprs.2015.10.004.  Google Scholar Varghese, Blesson,
    and Rajkumar Buyya. 2018. “Next Generation Cloud Computing: New Trends and Research
    Directions.” Future Generation Computer Systems 79: Elsevier B.V.: 849–861. doi:10.1016/j.future.2017.09.020.  Web
    of Science ®Google Scholar Verma, Abhishek, Luis Pedrosa, Madhukar Korupolu, David
    Oppenheimer, Eric Tune, and John Wilkes. 2015. Large-Scale Cluster Management
    at Google with Borg.” In Proceedings of the Tenth European Conference on Computer
    Systems 2018-Janua:1–17. New York NY USA: ACM. doi:10.1145/2741948.2741964.  Google
    Scholar Villarroya, Sebastian, and Peter Baumann. 2020. On the Integration of
    Machine Learning and Array Databases.” In 2020 IEEE 36th International Conference
    on Data Engineering (ICDE) 1786–1789. IEEE. doi:10.1109/ICDE48307.2020.00170.  Google
    Scholar Wang, Ning, Fang Chen, Bo Yu, and Yuchu Qin. 2020. “Segmentation of Large-Scale
    Remotely Sensed Images on a Spark Platform: A Strategy for Handling Massive Image
    Tiles with the MapReduce Model.” ISPRS Journal of Photogrammetry and Remote Sensing
    162 (February): 137–147. doi:10.1016/j.isprsjprs.2020.02.012.  Google Scholar
    Wang, Shuang, Guoqing Li, Xiaochuang Yao, Yi Zeng, Lushen Pang, and Lianchong
    Zhang. 2019. “A Distributed Storage and Access Approach for Massive Remote Sensing
    Data in Mongodb.” ISPRS International Journal of Geo-Information 8 (12), doi:10.3390/ijgi8120533.  Web
    of Science ®Google Scholar Wang, Lizhe, Gregor Von Laszewski, Andrew Younge, Xi
    He, Marcel Kunze, Jie Tao, and Cheng Fu. 2010. “Cloud Computing: A Perspective
    Study.” New Generation Computing 28 (2): 137–146. doi:10.1007/s00354-008-0081-5.  Web
    of Science ®Google Scholar Wang, Lizhe, and Jining Yan. 2020. “Stewardship and
    Analysis of Big Earth Observation Data.” Big Earth Data 4 (4): Taylor & Francis:
    349–352. doi:10.1080/20964471.2020.1857055.  Google Scholar Wang, X. Z., H. M.
    Zhang, J. H. Zhao, Q. H. Lin, Y. C. Zhou, and J. H. Li. 2015. “AN INTERACTIVE
    WEB-BASED ANALYSIS FRAMEWORK FOR REMOTE SENSING CLOUD COMPUTING.” ISPRS Annals
    of the Photogrammetry, Remote Sensing and Spatial Information Sciences II-4/W2
    (July): 43–50. doi:10.5194/isprsannals-II-4-W2-43-2015.  Google Scholar Wei, Xiaoli,
    Ni Bin Chang, and Kaixu Bai. 2020. “A Comparative Assessment of Multisensor Data
    Merging and Fusion Algorithms for High-Resolution Surface Reflectance Data.” IEEE
    Journal of Selected Topics in Applied Earth Observations and Remote Sensing 13:
    4044–4059. doi:10.1109/JSTARS.2020.3008746.  Web of Science ®Google Scholar Weil,
    Sage A, Scott A Brandt, Ethan L Miller, Darrell D E Long, and Carlos Maltzahn.
    2006. “Ceph: A Scalable High-Performance Distributed File System.” In Proceedings
    of the 7th Symposium on Operating Systems Design and Implementation, 307–320.
    https://www.usenix.org/legacy/events/osdi06/tech/full_papers/weil/weil_html/.  Google
    Scholar Wilkinson, Mark D., Michel Dumontier, IJsbrand Jan Aalbersberg, Gabrielle
    Appleton, Myles Axton, Arie Baak, Niklas Blomberg, et al. 2016. “The FAIR Guiding
    Principles for Scientific Data Management and Stewardship.” Scientific Data 3:
    1–9. doi:10.1038/sdata.2016.18.  Web of Science ®Google Scholar Wu, Xindong, Xingquan
    Zhu, Gong Qing Wu, and Wei Ding. 2014. “Data Mining with Big Data.” IEEE Transactions
    on Knowledge and Data Engineering 26 (1): IEEE: 97–107. doi:10.1109/TKDE.2013.109.  Web
    of Science ®Google Scholar Xie, Yanhua, and Tyler J. Lark. 2021. “Mapping Annual
    Irrigation from Landsat Imagery and Environmental Variables Across the Conterminous
    United States.” Remote Sensing of Environment 260 (April): Elsevier Inc.: 112445.
    doi:10.1016/j.rse.2021.112445.  Google Scholar Xu, Chen, Xiaoping Du, Xiangtao
    Fan, Zhenzhen Yan, Xujie Kang, Junjie Zhu, and Zhongyang Hu. 2022. “A Modular
    Remote Sensing Big Data Framework.” IEEE Transactions on Geoscience and Remote
    Sensing 60: IEEE: 1–11. doi:10.1109/TGRS.2021.3100601.  Google Scholar Xu, Chen,
    Xiaoping Du, Hongdeng Jian, Yi Dong, Wei Qin, Haowei Mu, Zhenzhen Yan, Junjie
    Zhu, and Xiangtao Fan. 2022. “Analyzing Large-Scale Data Cubes with User-Defined
    Algorithms: A Cloud-Native Approach.” International Journal of Applied Earth Observation
    and Geoinformation 109 (January): Elsevier B.V.: 102784. doi:10.1016/j.jag.2022.102784.  Google
    Scholar Xu, Chen, Xiaoping Du, Zhenzhen Yan, and Xiangtao Fan. 2020. “ScienceEarth:
    A Big Data Platform for Remote Sensing Data Processing.” Remote Sensing 12 (4):
    607. doi:10.3390/rs12040607.  Web of Science ®Google Scholar Yan, Jining, Yan
    Ma, Lizhe Wang, Kim-Kwang Raymond Choo, and Wei Jie. 2018. “A Cloud-Based Remote
    Sensing Data Production System.” Future Generation Computer Systems 86 (September):
    Elsevier B.V.: 1154–1166. doi:10.1016/j.future.2017.02.044.  Google Scholar Yang,
    Chaowei, Qunying Huang, Zhenlong Li, Kai Liu, and Fei Hu. 2017. “Big Data and
    Cloud Computing: Innovation Opportunities and Challenges.” International Journal
    of Digital Earth 10 (1): Taylor & Francis: 13–53. doi:10.1080/17538947.2016.1239771.  Web
    of Science ®Google Scholar Yang, Chaowei, Manzhu Yu, Yun Li, Fei Hu, Yongyao Jiang,
    Qian Liu, Dexuan Sha, Mengchao Xu, and Juan Gu. 2019. “Big Earth Data Analytics:
    A Survey.” Big Earth Data 3 (2): Taylor & Francis: 83–107. doi:10.1080/20964471.2019.1611175.  Google
    Scholar Yao, Xiaochuang, Guoqing Li, Junshi Xia, Jin Ben, Qianqian Cao, Long Zhao,
    Yue Ma, Lianchong Zhang, and Dehai Zhu. 2020. “Enabling the Big Earth Observation
    Data via Cloud Computing and DGGS: Opportunities and Challenges.” Remote Sensing
    12 (1): 62–15. doi:10.3390/RS12010062.  Web of Science ®Google Scholar Young,
    Nicholas E., Ryan S. Anderson, Stephen M. Chignell, Anthony G. Vorster, Rick Lawrence,
    and Paul H. Evangelista. 2017. “A Survival Guide to Landsat Preprocessing.” Ecology
    98 (4): 920–932. doi:10.1002/ecy.1730.  PubMed Web of Science ®Google Scholar
    Yu, Shui, Meng Liu, Wanchun Dou, Xiting Liu, and Sanming Zhou. 2017. “Networking
    for Big Data: A Survey.” IEEE Communications Surveys & Tutorials 19 (1): IEEE:
    531–549. doi:10.1109/COMST.2016.2610963.  Web of Science ®Google Scholar Yu, Jia,
    Jinxuan Wu, and Mohamed Sarwat. 2015. GeoSpark: A Cluster Computing Framework
    for Processing Large-Scale Spatial Data.” In Proceedings of the 23rd SIGSPATIAL
    International Conference on Advances in Geographic Information Systems 1–4. New
    York NY USA: ACM. doi:10.1145/2820783.2820860.  Google Scholar Zaharia, Matei,
    Mosharaf Chowdhury, Michael J. Franklin, Scott Shenker, and Ion Stoica. 2010.
    “Spark: Cluster Computing with Working Sets.” HotCloud 10 (10–10): 95.  Google
    Scholar Zalipynis, Ramon Antonio Rodriges. 2020. “BitFun.” Proceedings of the
    VLDB Endowment 13 (12): 2909–2912. doi:10.14778/3415478.3415506.  Google Scholar
    Zalipynis, Ramon Antonio Rodriges. 2021. “Array DBMS.” Proceedings of the VLDB
    Endowment 14 (12): 3186–3189. doi:10.14778/3476311.3476404.  Web of Science ®Google
    Scholar Zhan, Tao, Maoguo Gong, Xiangming Jiang, and Shuwei Li. 2018. “Log-Based
    Transformation Feature Learning for Change Detection in Heterogeneous Images.”
    IEEE Geoscience and Remote Sensing Letters 15 (9): 1352–1356. doi:10.1109/LGRS.2018.2843385.  Web
    of Science ®Google Scholar Zhang, Bing, Zhengchao Chen, Dailiang Peng, Jon Atli
    Benediktsson, Bo Liu, Lei Zou, Jun Li, and Antonio Plaza. 2019. “Remotely Sensed
    Big Data: Evolution in Model Development for Information Extraction [Point of
    View].” Proceedings of the IEEE 107 (12): 2294–2301. doi:10.1109/JPROC.2019.2948454.  Web
    of Science ®Google Scholar Zhang, Xin, Ya’nan Zhou, and Jiancheng Luo. 2021. “Deep
    Learning for Processing and Analysis of Remote Sensing Big Data: A Technical Review.”
    Big Earth Data, Taylor & Francis 1–34. doi:10.1080/20964471.2021.1964879.  Google
    Scholar Zhao, Jianghua, Xuezhi Wang, Yuanchun Zhou, and Qiming Qin. 2018. Towards
    a Framework for Offering Remote Sensing Data in an Analysis-Ready Format.” In
    IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium
    2018-July:5258–5261. IEEE. doi:10.1109/IGARSS.2018.8518458.  Google Scholar Zhong,
    Bo, Aixia Yang, Qinhuo Liu, Shanlong Wu, Xiaojun Shan, Xihan Mu, Longfei Hu, and
    Junjun Wu. 2021. “Analysis Ready Data of the Chinese Gaofen Satellite Data.” Remote
    Sensing 13 (9): 1709–1716. doi:10.3390/rs13091709.  Web of Science ®Google Scholar
    Zhou, Xiaohua, Xuezhi Wang, Yuanchun Zhou, Qinghui Lin, Jianghua Zhao, and Xianghai
    Meng. 2021. “RSIMS: Large-Scale Heterogeneous Remote Sensing Images Management
    System.” Remote Sensing 13 (9): 1815. doi:10.3390/rs13091815.  Web of Science
    ®Google Scholar Zhu, Xiaolin, Fangyi Cai, Jiaqi Tian, and Trecia Kay Ann Williams.
    2018. “Spatiotemporal Fusion of Multisource Remote Sensing Data: Literature Survey
    Taxonomy Principles Applications and Future Directions.” Remote Sensing 10 (4),
    doi:10.3390/rs10040527.  Web of Science ®Google Scholar Zhu, Zhe, Michael A. Wulder,
    David P. Roy, Curtis E. Woodcock, Matthew C. Hansen, Volker C. Radeloff, Sean
    P. Healey, et al. 2019. “Benefits of the Free and Open Landsat Data Policy.” Remote
    Sensing of Environment 224 (February): 382–385. doi:10.1016/j.rse.2019.02.016  Google
    Scholar Download PDF X Facebook LinkedIn Email Share   Related research  People
    also read Recommended articles Cited by 2 Big Data and cloud computing: innovation
    opportunities and challenges Chaowei Yang et al. International Journal of Digital
    Earth Published online: 3 Nov 2016 Deep learning for processing and analysis of
    remote sensing big data: a technical review Xin Zhang et al. Big Earth Data Published
    online: 30 Aug 2021 A multi-source spatio-temporal data cube for large-scale geospatial
    analysis Fan Gao et al. International Journal of Geographical Information Science
    Published online: 14 Jun 2022 View more Information for Authors R&D professionals
    Editors Librarians Societies Open access Overview Open journals Open Select Dove
    Medical Press F1000Research Opportunities Reprints and e-prints Advertising solutions
    Accelerated publication Corporate access solutions Help and information Help and
    contact Newsroom All journals Books Keep up to date Register to receive personalised
    research and resources by email Sign me up Copyright © 2024 Informa UK Limited
    Privacy policy Cookies Terms & conditions Accessibility Registered in England
    & Wales No. 3099067 5 Howick Place | London | SW1P 1WG     Cookies Button About
    Cookies On This Site We and our partners use cookies to enhance your website experience,
    learn how our site is used, offer personalised features, measure the effectiveness
    of our services, and tailor content and ads to your interests while you navigate
    on the web or interact with us across devices. By clicking "Continue" or continuing
    to browse our site you are agreeing to our and our partners use of cookies. For
    more information seePrivacy Policy CONTINUE'
  inline_citation: '>'
  journal: International Journal of Digital Earth
  limitations: '>'
  pdf_link: null
  publication_year: 2022
  relevance_score: 0.9
  relevance_score1: 0
  relevance_score2: 0
  title: 'Cloud-based storage and computing for remote sensing big data: a technical
    review'
  verbatim_quote1: RSBD applications can be grouped into two types, data-separable
    computing and data-inseparable computing, to further decompose the problem and
    investigate different solutions.
  verbatim_quote2: 'There are three mainstream cloud-based big data technologies for
    remote sensing data analysis: simple batch processing, MapReduce processing, and
    array-based processing.'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1201/9781003337454-7
  analysis: 'This paper thoroughly explores various aspects of data analytics in the
    context of IoT systems. It begins by presenting the evolving concept of IoT and
    the significant challenges associated with integrating IoT data and analytics
    due to its unique nature. The authors describe the essential requirements for
    IoT data analytics, emphasizing end-to-end techniques and solutions for data collection,
    discovery, and adaptable analysis methods. They also address the role of standards
    in achieving interoperability across IoT devices and systems.


    The paper extensively covers the concept of Deep IoT data analytics, which is
    proposed to handle the complexities and dynamic nature of IoT data. This approach
    leverages semantic annotation and resource description frameworks to improve data
    interoperability and enable efficient analytics. The authors highlight the need
    for dynamic semantic methods to accommodate the evolving nature of IoT data and
    support real-time data analytics.


    Furthermore, the paper discusses the need for cloud-based IoT analytics platforms
    to manage the massive volume of data generated by IoT devices. They explore the
    requirements of such platforms, including distributed processing, scalability,
    real-time capabilities, and security. The authors present the iKaaS platform as
    an example of a cloud-based IoT analytics platform and discuss its key functionalities
    and architecture.


    The paper also addresses the significance of IoT analytics in healthcare and social
    care, emphasizing the need for scalable and distributed analytics approaches to
    handle the large and diverse data generated in these domains. The authors discuss
    architectural design considerations and potential benefits of IoT analytics in
    improving healthcare delivery, such as enabling personalized medicine, enhancing
    disease management, and facilitating remote patient monitoring.


    Finally, the paper explores the challenges of data governance and privacy in IoT
    analytics. It emphasizes the need for fine-grained access control mechanisms and
    fair non-repudiation technologies to ensure data security and protect user privacy.
    The authors discuss the importance of establishing clear data governance policies
    and implementing privacy-preserving techniques to mitigate the risks associated
    with handling sensitive IoT data.


    Overall, this document offers a comprehensive analysis of the current state and
    future directions of IoT analytics, considering various technical, architectural,
    and privacy aspects. It provides valuable insights and recommendations for researchers
    and practitioners working in the field of IoT and data analytics.'
  authors:
  - Payam Barnaghi
  - Martin Bauer
  - Abdur Rahim Biswas
  - Maarten Botterman
  - Bin Cheng
  - Flavio Cirillo
  - Markus Dillinger
  - Hans Graux
  - Seyed Amir Hoseinitabatabaie
  - Ernő Kovács
  - Salvatore Longo
  - Swaroop Nunna
  - Alois Paulin
  - R. R. Venkatesha Prasad
  - John Soldatos
  - Christoph Thüemmler
  - Mojca Volk
  citation_count: 1
  full_citation: 'IoT Analytics: Collect, Process, Analyze, and Present Massive Amounts
    of Operational Data – Research and Innovation Challenges'
  full_text: '>

    7

    IoT Analytics: Collect, Process, Analyze, and

    Present Massive Amounts of Operational

    Data – Research and Innovation Challenges

    Payam Barnaghi2, Martin Bauer8, Abdur Rahim Biswas3,

    Maarten Botterman9, Bin Cheng8, Flavio Cirillo8, Markus Dillinger7,

    Hans Graux10, Seyed Amir Hoseinitabatabaie2, Ernö Kovacs8,

    Salvatore Longo8, Swaroop Nunna7, Alois Paulin5,

    R. R. Venkatesha Prasad4, John Soldatos1,

    Christoph Thuemmler5 and Mojca Volk6

    1GR, Athens Information Technology, Greece

    2University of Surrey, UK

    3CREATE-NET, Italy

    4TU Delft, Netherlands

    5Edinburgh Napier University, UK

    6University of Ljubljana, Slovenia

    7Huawei, Germany

    8NEC, Germany

    9GNKS Consult BV, Netherlands

    10Timelex, Belgium

    7.1 Introduction

    Internet-of-Things (IoT) Analytics refers to the process of transforming

    vast amounts of information from heterogeneous internet-connected objects,

    data sources and devices (e.g., sensors, appliances, cyber-physical systems,

    Machine-to-Machine systems) to business and application intelligence. Sev-

    eral tools and techniques for IoT analytics have their roots in conventional

    web analytics, which process and combine data streams from web-connected

    computers,cellphonesandwebdatabases.However,IoTanalyticsbroadenthe

    scope of web analytics on the basis of the collection, processing and analysis

    221

    222

    IoT Analytics: Collect, Process, Analyze, and Present Massive Amounts

    of information produced by internet-connected devices, thus enhancing the

    scope and functionalities of related applications.

    Nowadays, IoT analytics have a growing momentum, which is highly due

    to the proliferation of IoT devices and the overall momentum of IoT technolo-

    gies and services. IoT analytics hold the promise to enable a wide range of

    novel applications that are not currently possible, which could revolutionize

    applications areas with signiﬁcant socio-economic impact such as healthcare,

    energy management, public safety and more. The IoT analytics vision, while

    fantastic, is associated with several challenges spanning both technical and

    policy issues. For example, at the technical and scientiﬁc forefront, IoT

    devices tend to produce high-velocity streams, which challenge the capabil-

    ities of state-of-the-art BigData systems (such as MapReduce). Furthermore,

    the heterogeneity and diversity of IoT devices is a serious set-back to the

    collection, consolidation and uniﬁed processing of IoT data streams. Other

    challenges relate to the selection, reﬁnement and deployment of effective data

    analytics algorithms that can respond to the stringent QoS (Quality of Service)

    requirements of IoT applications. Likewise, at the policy forefront, there is

    a need for addressing security, privacy and data protection challenges in-line

    with existing regulations, but also in a way that encourages user participation.

    The present chapter of the 2015 IERC Book aims at presenting the

    above-listed challenges of IoT analytics, while at the same time providing

    insights in possible solutions, notably solutions that are being developed

    in the scope of the IERC community. The second section of the chapter

    (following this introductory one), is titled “Deep Internet of Things Data

    Analytics”. It presents challenges and solutions associated with the collection

    and semantic uniﬁcation of diverse data streams, which is one of the ﬁrst

    prerequisite steps for analyzing IoT data sources. Likewise, the third section
    of

    the chapter presents the challenges of IoT/BigData convergence and illustrates

    techniques for integrating IoT with cloud and BigData infrastructures. The

    fourth section of the chapter provides insights associated with the practical

    application of IoTanalytics in healthcare and social care, while the ﬁfth section

    presents an IoT analytics case for public safety. Finally, the sixth section of

    the chapter deals with the ever important policy issues, through presenting

    challenges and providing a perspective for solutions that are in-line with

    existing and emerging EU directives. It also identiﬁes gaps of these directives

    and proposes relevant remedies. Overall, this chapter provides the reader with

    a nice overview of the technical and policy issues associated with the wider

    deployment of advanced IoT analytics, along with some solutions introduced

    and advanced by the IERC community.

    7.2 Deep Internet of Things Data Analytics

    223

    7.2 Deep Internet of Things Data Analytics

    7.2.1 Introduction

    Computers in their early days were not designed for personal use and

    individual applications. They were usually large machines and mainframes

    that specialists worked with. Rapid hardware and software innovations and

    advancements and the emergence of global networks and the Internet made

    computers widely available for everyone to use. Mobile devices and wireless

    technologies made it potentially possible to connect to communication net-

    works and the Internet anytime and anywhere. We now live in an era in which

    physical objects (i.e. “Things”) can be embedded with their own computing

    devices and with networking capabilities. The Internet of Things (IoT) is

    an umbrella term that refers to technologies that enable communication and

    interaction between various devices and real world objects and human users.

    IoT is mainly enabled by advancements in manufacturing low-cost sensors

    and actuators, smart phones, embedded devices, and communication and

    networking technologies. These advancements have resulted in rapid growth

    and the deployment of networked-enabled devices and sensing and actuation

    systems that interconnect the physical word with the cyber-world. The number

    of devices connected to the Internet has already exceeded the number of people

    on earth and is estimated to grow to 50 billion devices by 2020 [39].

    Data collected by different devices are of various types (e.g. temperature,

    light, humidity, video) and are inherently diverse and dynamic (i.e. the quality

    and validity of data can vary with different devices over time; data is also

    mostly location and time dependent). Sensory devices can be ubiquitous

    and are often constrained in power, memory, processing and communication

    capabilities. As the scale of interactions between devices and the load of

    communications rapidly increase, real world data and service trafﬁc become

    voluminous; the current Internet/Web architecture will not be suited to deliv-

    ering reliable, efﬁcient and time-sensitive data and services for large volumes

    of networked devices [1].

    In following paragraphs we discuss that IoT data analytics cannot be

    separated from data collection, device and network conditions and limitations.

    The ability of the resources to effectively publish, discover and access the data

    in large-scale distributed environments will have an impact on the efﬁciency

    of the data analytics methods. Effective data analytics solutions in the IoT

    need to consider the dynamicity and constraints of data collection devices

    and communication networks and should be able to optimise the processes

    for different purposes and requirements, such as latency, accuracy, data and

    224

    IoT Analytics: Collect, Process, Analyze, and Present Massive Amounts

    sampling rates, and energy efﬁciency. We discuss data analytics in the IoT

    domain and describe some of the key issues to provide integrated and end-

    to-end solutions for large-scale and efﬁcient data analytics. The integration

    of device and network parameters and their characteristics in the IoT data

    analytics in this work is referred to as Deep IoT data analytics.

    7.2.2 Designing for Real World Problems

    IoT research covers a broad range of technologies and solutions that aim

    to tackle the challenges in networking and communications, interoperability,

    services and stream processing and data analytics. IoT is an integration of

    different systems and technologies. Industry based solutions and services in

    this domain are often under development or do not interoperate on a global

    and large scale, due to a lack of standardisation. Data processing and analytics

    solutions in the IoTare mainly based on conventional data mining and machine

    learning techniques. There are also several solutions and de-facto standards

    for annotation and semantic integration of IoT data.

    However, IoT data is inherently different from other types of data on

    the Web and database systems. Uncertainty, incompleteness, sporadic data

    distributions, scale and energy and resource constraints of the data provider

    devices are among the key issues that make processing IoT data different and

    more challenging than the usual data on the Web and database systems.

    Data analytics solutions in the IoT, in contrast to many existing BigData

    analysis works, cannot be separated from data collection, selection, network

    status and issues such as energy efﬁciency. Efﬁcient and intelligent data

    analysis methods for the IoT domain should consider end-to-end and inte-

    grated solutions and should be adaptable and ﬂexible enough to work with

    incomplete and uncertain data and should also be able to adjust themselves to

    concept drifts (i.e. changes in the data or the objectives of data processing)
    [2]

    and requirement changes. The IoT is an online network of resources and data

    analytics solutions and should be able to process and analyse dynamic data in

    real-time.

    Figure 7.1 (adapted from [3]) shows some of the key dimensions that need

    to be taken into account when designing data analytics methods for the IoT.

    As shown in the ﬁgure, the connectivity and data publication can potentially

    be at any time, from any place and can be related to any-thing. The volume

    of data is a key issue and the networks and communication technologies have

    an impact on various aspects of data access and use, such as latency, quality

    and availability. IoT data can be related to people, personal spaces and living

    7.2 Deep Internet of Things Data Analytics

    225

    Figure 7.1

    Key dimensions in production and deployment of IoT data.

    environments; so reliability, security and privacy are among key issues in

    designing any solutions, including data analytics for the IoT. Having access

    to new types of data and connectivity and interaction with the real world

    provides an opportunity to design new services and applications that rely

    on ambient intelligence. However, data analytics methods for extracting this

    ambient intelligence have to deal with time and location dependency and

    dynamicity of data and the solutions should be able to handle uncertainty

    and quality issues often in a real-time manner. IoT services and applications

    will have an impact on people’s lives and the way that personal and public

    spaces and services are planned and designed (e.g. smart homes and smart

    cities). Industrial IoT applications and services require the processing of large

    volumes of data to make autonomous decisions to control and operate various

    systems and machines.

    Wireless communication is the dominant component in overall energy

    consumption of the remote IoT devices (i.e. in the current systems the

    computationusuallyconsumeslessenergythanthecommunication[4]).Inthis

    regard, careful considerations should be made to minimise the communication

    load in IoT networks. IoT resources are usually programmed to collect and

    forward data based on a given data acquisition frequency and are often

    ignorant of information within the data packets. This could lead to the creation

    226

    IoT Analytics: Collect, Process, Analyze, and Present Massive Amounts

    of redundant and unnecessary communication load when data is noisy and

    unreliable or when it does not contain any signiﬁcant or new information.

    The other important issue is the scalability of the data processing and

    computation. Recent efforts in distributing processing tasks among different

    resources (e.g. using software deﬁned solutions [5]), have mitigated the

    problems associated with conventional centralised processing architectures

    to some extent. However, with the scale of the IoT resources, problems such

    as effective use of computational resources on devices and distribution of

    data analytics processes between IoT devices and Cloud based resources are

    challenging issues.

    7.2.3 Real World Data

    To better understand the requirements of data analytics we ﬁrst need to look at

    the data sources and the type of devices and networks that produce and handle

    this data. Access to live real world data and connected worlds of physical

    objects, people and devices are rapidly changing the way we work and interact

    with our surroundings and have had a profound impact on different domains,

    such as healthcare, environmental monitoring, urban systems, industry, and

    control and management applications and decision support systems.

    IoT data is usually collected via sensing devices that are connected to

    wireless or wired networks (e.g. wireless sensor and actuator networks),

    smart phones and other embedded and network-enabled devices. The devices

    can be directly connected to the core network and data analysis compo-

    nents or gateway components can provide data communication between IoT

    devices and higher-level services and applications, including the data analytics

    components in the core networks.

    Figure 7.2 shows a generic framework for IoT data communication where

    some nodes can use Internet and Web based protocols and some are connected

    via gateway components. There are also platforms and solutions that enable

    crowd sourcing of IoT data collection and publication using smart phone

    and network-enabled devices and sensing technologies. Quality, trust and

    reliability, together with the availability and delays in accessing the data are

    key issues in crowd sourced data collection and publication use-cases.

    IoTdata is often published as streaming data with multiple streams that can

    provide similar data (but can have different quality or parameters) or other

    relevant data that need to be integrated and processed together. Extracting

    patterns and ﬁnding correlations between different parts of the data is an

    important task in data analytics for IoT data streams. However, there are two

    7.2 Deep Internet of Things Data Analytics

    227

    Figure 7.2

    A generic framework for IoT data publication and communication.

    key issues: causation vs. co-occurrence requires further analysis and often

    background knowledge is required to interpret and separate the causations;

    time lag between different pattern occurrences and spatial dependencies

    should also be considered when analysing the patterns in the streams. For

    example, an occurrence in a data stream (i.e. an event) can cause a related

    pattern in a different stream (and in a different location) after a period of

    time. So the spatio-temporal interdependencies should also be considered

    in the analysis. The streaming data can sometimes have missing values due

    to communication and device errors or different sampling rates. Different

    interpolation techniques (e.g. Gaussian process or multivariate interpolation

    techniques) or machine learning methods can be employed to compensate for

    the missing values in the data streams.

    7.2.4 Data Interoperability

    Data collection and publication is the initial step for accessing and processing

    IoT data. As discussed, there are several issues regarding the device, network

    and end-user application and service state and requirements that need to be

    taken into consideration when collecting and publishing the IoT data.

    Data is usually published in various forms and via distributed devices

    and sources. There are several existing metadata models and description

    228

    IoT Analytics: Collect, Process, Analyze, and Present Massive Amounts

    frameworks that are designed and proposed by academia and industry to

    provide interoperable resource and data descriptions in the IoT domain. For

    example, the W3C Incubator Group on Semantic Sensor Networks developed

    a higher-level model for describing sensors and their capabilities called SSN

    Ontology [6].

    These semantic and metadata models and description frameworks are

    designed to improve the interoperability of the data and resource descriptions.

    Machine-readable and automatically interpretable data descriptions and data

    engineering solutions to enhance the structure and representation of data

    will strongly improve the analytics and integration methods, especially in

    the IoT world, where multi-modality and heterogeneity are among the key

    issues. However, the semantic annotation requirements and the complexity

    of providing structured information with several attributes often hinders

    the effective use of the semantic models that are proposed for real world

    data. Some of the parameters, such as quality of data, are also dynamic

    variables. Most of the current semantic annotation models construct a semantic

    description model and annotate the data according to that model without

    providing an end-to-end set of tools and solutions to add and update more

    attributes and metadata to the annotation after the data is published. However,

    thedynamicityandchangesintheannotatedvalues(e.g.themeaningofquality

    for a data item can change after the time of measurement; provenance of data

    can change as more processing methods are applied to the data) is not captured

    in the models and annotation methods.

    Many of the current semantic annotation frameworks for the IoT are static

    and the provenance and changes to the data and metadata updates are not

    directly supported. Providing “dynamic semantics” in the IoT domain and

    developing tools, APIs and methods that can publish, update and extend the

    semantics as the data is processed and integrated with other sources, or as

    more information is collected and analysed from the environment will help to

    resolve this issue. This will not only address the interoperability issues but
    will

    also create more enhanced and ﬂexible annotations that reﬂect the actual and

    up-to-date attributes of the data. The dynamic semantic methods should also

    use linked-data descriptions to link between different resources and also use

    common vocabularies to describe the concepts and content of the annotations.

    Using common vocabularies and topical ontologies for describing events

    and occurrences and other common attributes of the data, such as units of

    measurement, will signiﬁcantly improve the interoperability and effectiveness

    of data analytics operations.

    7.2 Deep Internet of Things Data Analytics

    229

    7.2.5 Deep Data Analytics Methods

    Edge-level pre-processing, ﬁltering the noise and removing the corrupted data

    and data aggregation mechanisms on the IoT device could help to minimise

    the use of communication resources at source level. Pre-processing and data

    aggregation at device level is a remedy for the congestion problem that often

    occurs in centralised and hierarchical architectures and will lead to a more

    scalable design.

    In the IoT, data analysis algorithms should be able to automatically make

    adjustments and adapt the overall solutions to different information extraction

    and optimisation goals. For example, in an emergency response scenario

    the algorithms need to be optimised for reducing latency; in an elderly

    care scenario increasing the quality of the extracted information would be

    the main priority; in an environmental monitoring framework using a large

    number of wireless sensors and increasing the life-time of the network can

    be one of the main goals of the overall application and consequently the data

    analytics method should also be adjusted and optimised to meet these goals

    and requirements. Obviously IoT devices in large deployments will not run

    for just one application and will not respond to a single demand, so cross-

    application optimisation is also an essential task in developing large-scale and

    multi-purpose IoT frameworks. To perform such optimisation and integrated

    data processing efﬁcient data discovery and selection algorithms for choosing

    the best set of resources at the given time, and adaptable and customisable

    data analytics methods that can push the processing to the edges of the IoT

    networks, are required.

    Most of the conventional machine learning and data analytics methods are

    also designed based on the assumption of having normalised distribution and

    reliable datasets. For example, processing techniques, such as the Symbolic

    Aggregate approXimation (SAX) [7] algorithm for constricting patterns from

    streaming data, assume that the data distribution are normalised. SAX divides

    the normalised probability distributions to equi-probable segments and assigns

    a symbolic representation for each segment. These symbolic representations

    are then used to create representative patterns of the streaming data. While

    SAX or other similar methods have been used effectively in the data analysis

    and stream processing ﬁelds, using them in the IoT has some limitations. SAX

    patterns can still be constructed from the IoT data streams but the distribution

    of the IoTdata in short-time windows, which is often the key focus of the (near)

    real-time data analytics methods, is not normalised and can be a sporadic and

    multivariate distribution. This will require pre-processing and analysis of the

    230

    IoT Analytics: Collect, Process, Analyze, and Present Massive Amounts

    data at source level and determining the distribution and other attributes of

    the data before constructing the symbolic representation and constructing the

    patterns.

    Data analytics for dynamic environments such as IoT requires resource-

    aware analysis techniques that focus on both the data and also the resources

    that provide the data. Optimisation for different objectives such as latency,

    accuracy, energy efﬁciency, and network trafﬁc should be supported and the

    algorithms should be able to adjust and adapt to these objectives dynamically.

    The key target of data analytics in the IoT is to create situation-awareness and

    ambient intelligence and to extract actionable information that can be used

    in decision support systems and higher-level applications and services. The

    results of the data analytics can also be used to visualise and demonstrate

    different patterns, occurrences and events in the physical environments. Most

    of these are online applications and services that require (near) real-time

    learning and feedback mechanisms.

    Figure 7.3 shows a multi-level view of data analytics in an IoT framework.

    The device and resources are the edge-level and their parameters at any given

    time will have an impact on real-time data collection and other parameters,

    such as quality and granularity of the data. The analytics methods need to take

    into account these parameters and to also try to control and adjust these using

    Figure 7.3

    A view of data analytics levels in an IoT framework.

    7.2 Deep Internet of Things Data Analytics

    231

    software deﬁned and adjustable solutions to provide more resource-aware

    solutions. The middle layer is the core network and Cloud based services

    that can provide back-end support for discovery, integration, publication and

    storage, and large-scale distributed analytics methods. The functions at this

    level will be adapted according to requirements, concept drifts at the end-user

    and application/service layer and also condition and priorities at the device

    level.

    In the machine learning domain and the Big Data world there are deep

    learning methods that attempt to learn representations and model abstractions

    of data [8]. The deep learning methods often also improve the performance of

    the learning methods by analysing and processing large volumes of data. In the

    IoT domain, the use of deep learning and other conventional and novel data

    analytics and stream processing methods can be very beneﬁcial. However, the

    deep analytics, as described in the paper, mainly describes the adaptability

    and adjustability of the methods towards various optimisation objectives and

    concept drifts and is an attempt to develop analytics and machine learning

    techniques that can take device and network parameters into account and can

    work efﬁciently with multivariate and sporadic data provided by multiple

    sources and by various qualities.

    The data analytics solutions in this IoT domain also rely on semantic anno-

    tations and descriptions of the resources. The more expressive the attributes

    of the data and their provider resource are, the better the interpretation and

    analysis that can be provided. However, expressive semantic annotations

    and metadata will require a higher communication and computation load

    (and consequently will consume more energy in constrained environments).

    The update, query and processing of complex semantics can also their hinder

    efﬁcient utilisation. So a trade-off between semantic descriptions, efﬁcient

    publication, query and discovery methods and adaptable and ﬂexible learning

    and analytics solutions are required in the IoT framework.

    7.2.6 Conclusions

    Increased interest in using the IoT in different domains, such as smart cities,

    healthcare and industry, plays a key role in the production of massive amounts

    of real world data. This data is mainly collected in order to extract actionable

    information, create ambient intelligence and provide situation awareness for

    different higher-level applications and services [9]. IoT is a dynamic environ-

    ment with various devices that are often resource constrained and deployed

    on a large scale. Consequently, IoT data is also dynamic and heterogeneous.

    232

    IoT Analytics: Collect, Process, Analyze, and Present Massive Amounts

    In contrast to many Web and database systems, data analytics methods

    depend on the context of the data production source and network and device

    parameters.

    Efﬁcient IoT data analytics methods require end-to-end techniques and

    solutionsforcollectionandpublication,discoveryandselection,andadaptable

    and adjustable data analysis mechanisms and techniques. Drifts and changes,

    both in the end-user targets and operational environments and optimisation

    goals and network and device parameters, should be monitored and captured

    and should be fed back to control mechanisms that can adapt and control

    the data analytics methods. Key challenges for the future generation of IoT

    data analytics, in addition to overcoming the scale, computation and multi-

    modality issues, is to provide software controlled and adaptable solutions that

    can monitor the changes deep in the networks and physical environments and

    optimise their functions and goals based on end-user requirements, network

    and platform context, and changes in the surrounding environment.

    7.3 Cloud-Based IoT Big Data Platform

    7.3.1 Introduction

    The third generation Internet of Things (IoT) comprises millions of appli-

    cations, billions of users and trillions of devices. Over the last years, IoT

    has moved from being a futuristic vision to market reality. It is not any

    more a question that whether IoT will exist surpassing the hype, but it is

    already there and IoT industry race has already begun. Trillions of connected

    devices are the enablers; however the value of IoT is in the data and advanced

    processing of the collected data. IoT data is more dynamic & heterogeneous,

    imperfect & unstructured and, unprocessed & real-time than typical busi-

    ness data. It demands more sophisticated IoT-speciﬁc analytics to make a

    meaningful inference. The exploitation of the real-time big data obtained

    from sensors/actuators in IoT context by processing in sophisticated cloud is

    very much a necessity. This data processing leads to advanced, proactive and

    intelligent applications and services. The colligation of IoT and Big data can

    offer:i)deepunderstandingofthecontextandsituation,ii)real-timeactionable

    insight – detect and reacted to in real-time, iii) performance optimization,

    and iv) proactive and predictive advanced knowledge. Cloud technologies

    offer decentralized and scalable information processing and analytics, and

    data management capabilities.

    Following paragraphs address the cloud based IoT and Big data platform

    concept and their emerging requirements on the convergence of sensors and

    7.3 Cloud-Based IoT Big Data Platform

    233

    devices, big data analytics, cloud data management, edge-heavy computing,

    machine learning and virtualization. Initial results from iKaaS (Intelligent

    Knowledge as a Service) an EU-Japan project on IoT/Cloud/Big data are also

    discussed.

    7.3.2 Big Data in the Context of IoT

    Big data is deﬁned by 4Vs (Figure 7.4), these are Volume-, Velocity, Variety,

    Veracity. Volume means large data size in 100s of terabytes. Velocity means

    the real-time and/or stream of data. Variety means the heterogeneous data

    (e.g., structure and unstructured, diverse data models and query languages,

    and diverse data sources). Veracity means data uncertainty due to data incon-

    sistency, incompleteness, ambiguities, latency, model approximations, etc.

    IoT faces all 4Vs of the Big Data challenges. However the velocity is the

    main IoT Big data challenge because of real-time and stream of data coming

    from diverse IoT devices and sensors. Real-Time Big Data terminology is

    often replaced by the term IoT Big Data. The data coming from the IoT devices

    have to be processed in real-time to arrive at reliable and intelligent decision.

    For example, healthcare wearables (like ECG (Electrocardiogram) devices)

    produce up to 1000 events per second which is a challenge for real-time

    processing considering miniaturized devices and number of such devices.

    Next is the volume, for example, large scale IoT deployments gather and

    process millions pieces of data from millions of sensors per day. Likewise, a

    wearable sensor produces about 55 million data points per day.

    Figure 7.4

    Big Data Properties.

    234

    IoT Analytics: Collect, Process, Analyze, and Present Massive Amounts

    7.3.3 Applications of IoT Big Data Analytics

    The applications of IoT Big Data analytics can be classiﬁed into ﬁve main

    categories which are depicted in Figure 7.5 and include:

    • Predictive analytics,

    • Prescriptive analytics,

    • Descriptive analytics,

    • Monitoring and

    • Control and optimization.

    All these require a deep understanding of the domains, situation and the

    requirements of services by users.

    Gaining insights and knowledge in real time and actionable insights

    can lead to performance optimization. All the above ﬁve applications are

    inter-related and requires multiple tools like machine learning, reasoning,

    optimization, etc.

    Predictive analytics is used in many applications where users require

    services that can foresee the situation and act on it. Prescriptive analytics
    can

    provide many possible actionable decisions and also can provide the trade-off

    between them.

    Descriptive analytics offers the insights into the situation and helps in deep

    understanding. Monitoring, control and optimization are legacy applications,

    but with big data analytics they can be improved immensely.

    Figure 7.5

    IoT-Big Data Applications.

    7.3 Cloud-Based IoT Big Data Platform

    235

    Thus, analytics can indeed offer multiple services such as observing

    behaviour of things, gaining important insights and processing in real time

    for immediate actions. For example, in healthcare services IoT analytics can

    be used for understanding the cause of diseases, as well as for identifying

    emergency situations.

    This vision boils down to solving multiple challenges: to store all the

    events (velocity & volume); to run queries over the stored events; (velocity &

    volume) to perform analytics (data mining and machine learning) over the

    data to gain insights. Examples include real-time fall detection and potential

    reactions for aging population. Real-time detection and action represent

    multiple challenges.

    7.3.4 Requirements of IoT Big Data Analytic Platform

    An IoT BigData Analytics Platform is a real-time online platform that

    dynamically manages IoT data/objects but it also provides connectivity to the

    diverse heterogeneous objects, considering the interoperability issues. Next

    is deriving useful information and knowledge from this connection and large

    volume of IoT data. The platform needs to offer ubiquitous accessibility and

    connectivity in facilitation of maximum accessibility as well as connectivity

    of the diverse heterogeneous objects/services and various volumes of users

    including mobility. Dynamic management/orchestration of users, billions of

    devices as well as massive amount of data produced by those connected

    devices, maximum resource utilization, and sharing of IoT resources (objects,

    applications, platforms) are all necessary. Personalized, secure, and privacy

    by design services based on preferences of users and requirements including

    real-world context are the important requirements. Some of the requirements

    are brieﬂy discussed in following paragraphs.

    7.3.4.1 Intelligent and dynamic

    The platform should include intelligent and autonomic features in order to

    dynamically mange the platform functions, components and applications. The

    platform should also be capable of making a proactive decision, dynamic

    deployment, and intelligent decision to understand the context of the envi-

    ronment, users and application requirements, etc. Considering performance

    targets/constraints, ofﬂoading from clients/hosts to cloud is necessary but the

    performance should be guaranteed. Dynamic resource sharing and service

    migration is a must for large scale IoT applications. Dynamic metering may

    be also necessary when IoT devices are shared.

    236

    IoT Analytics: Collect, Process, Analyze, and Present Massive Amounts

    7.3.4.2 Distributed

    The platform should include distributed information processing and comput-

    ing capabilities, distributed storage, distributed intelligence, and distributed

    datamanagementcapabilities.Thisneedtobedistributedacrosssmartdevices,

    gateway/server and multiple cloud environments. More distributed processing

    and storage of the massive data as well as cloud functionalities is a must.

    Decentralized (and infrastructure-less) clouds will be the order of the day

    through processing capabilities and positioning data closer to users.

    7.3.4.3 Scalable and elastic

    The platform has to be scalable to address the connectivity from small to large

    number of the devices, manage the different scale of the data and services, as

    well as users. Cloud and edge data management, storage and processing, need

    to be scalable and at the same time elastic.

    7.3.4.4 Real-time

    Real-time data processing and service provisioning of “Big data”, is necessary.

    Un-structured and semi-structured data coming from distributed sources

    should be processed to provide real-time/near real-time services.

    7.3.4.5 Heterogeneous (uniﬁed)

    Interoperability between cloud/IoT services and infrastructure, and federation

    between cloud, Big data and IoT devices has to be in place to realize full

    potential. Standard APIs to deal with heterogeneity need to evolve. Open

    software components, standard data structure and modeling and abstraction

    of heterogeneous IoT devices and the data is necessary. Data always raise

    heterogeneity problems: many data formats, many metadata schema descrip-

    tions, mix of various levels of complexity, etc., are the cases in point.The target

    is to deliver a data model and the speciﬁcation of required mechanisms for

    exploiting both structured and unstructured data, for moving from raw data to

    linked data, enabling the adoption of a common understanding, the recognition

    of similar data, and unambiguous description of relevant information for

    multimodal and cross-domain smart space applications.

    7.3.4.6 Security and privacy

    Security and privacy by design is also needed including different privacy and

    security features like data integrity, localization, conﬁdentiality, SLA(Service

    Level Agreements), security and privacy-preserving data management mod-

    ules. Holistic approaches are required to address privacy & security issues

    7.3 Cloud-Based IoT Big Data Platform

    237

    across value chains including privacy by design aspects, software algorithms

    and new data management models.

    7.3.5 Cloud-Based IoT Analytic Platform

    The cloud-based platform is dynamic in nature and offers ﬂexible resources

    sharing and service provisioning. It also offers a scalable and elastic service/

    resources management platform. The platform also offers reliable and easy

    access to the services using large amount of computing and storage resources.

    The cloud-based platform is also homogeneous (uniﬁed) which reduces the

    technological heterogeneity. On the other hand, IoT depends on massive

    resources available when needed and scaled back when not needed. This

    can only be achieved using cloud paradigm. For IoT, cloud computing

    functionalities enable the realization of the IoTvision. For Cloud, IoTprovides

    huge opportunities for cloud services. There are two basic approaches for

    the convergence of IoT-Big data and Cloud. These are (i) Cloud-centric IoT

    (bringing IoT functionalities into Cloud) and (ii) IoT-Centric Cloud (bringing

    Cloud functionalities into IoT).

    In the following, we provide an overview of the iKaaS platform that

    has been developed as an example and which is illustrated in Figure 7.6.

    It combines ubiquitous and heterogeneous sensing, along with big data and

    cloud computing technologies. iKaaS enables IoT processing consisting of

    continuous iterations on data ingestion, data storage, analytics, knowledge

    Figure 7.6

    iKaaS Platform.

    238

    IoT Analytics: Collect, Process, Analyze, and Present Massive Amounts

    generation and knowledge sharing phases, while at the same time providing

    a foundation for service provisioning. The iKaaS platform comprises of the

    cloud ecosystem that consists of Local Clouds and a Global Cloud. More

    speciﬁcally:

    • Alocal cloud is created on-demand; it comprises of sufﬁcient/appropriate

    computing/storage/networking capabilities, and provides requested ser-

    vices to users in a certain geographical area and time period as well as

    offers additional processing and storage capability to services.

    • The global cloud is seen in the “traditional” sense, as a construct with

    on-demand/elastic processing power and storage capability. It is a

    “backbone infrastructure”, which increases the business opportunities

    for service providers, and the ubiquity/reliability/scalability of service

    provisioning. It offers more opportunities for offering services, more

    options on which service features are based in case of context changes,

    more resources for deriving meaningful decisions, and elastic provision

    of resources on demand.

    Local clouds can involve an arbitrarily large number of nodes (sensors, actu-

    ators, smart-phones, etc.). The aggregation of resources comprises sufﬁcient

    processing power and storage space. The goal is to serve users in a certain

    area. In this respect, a local cloud is the virtualised processing, storage and

    networking environment, which comprise IoT devices in the vicinity of the

    users; users will exploit the various services composed of the devices in local

    clouds and their capabilities e.g., a sensor and its gateway equipped with the

    iKaaS platform.

    The global cloud can enable, as a special (yet important) case, the existence

    of IoT service providers capable of providing larger scale services without

    owning actual IoT infrastructure.

    The Cloud ecosystem comprises the following essential functionalities:

    • Consolidated service-logic/resource descriptions/registries as part of the

    Global Cloud enabling the reuse of services. Practically, a set of registr-

    ies will be developed enabling the pooling of service logic and resources.

    • Autonomic service management, ﬁrst the global cloud and then, in the

    local cloud. This functionality will be in charge of (i) dynamically

    understanding the requirements, decomposing the service (ﬁnding the

    components that are needed); (ii) ﬁnding the best service conﬁguration

    and migration (service component deployment) pattern; (iii) during the

    service execution, reconﬁguring the service, i.e., conducting dynamic

    additions, cessations, substitutions of components.

    7.4 IoT Analytics in Health and Social Care

    239

    • Distributed data storage and processing is anticipated for global and

    local clouds. This means capabilities for efﬁciently communicating,

    processing and storing massive amounts of, quickly-emerging, versatile

    data (i.e., “big data”), produced by a huge number of diverse IoT devices.

    • Derivation of information and knowledge (e.g., on device behaviour,

    service provision, user aspects, etc.), while ensuring security and privacy

    as a top concern.

    • Knowledge as a service (KaaS) will be primarily part of the Global Cloud.

    This area covers: (i) device behaviour aspects; (ii) the way services have

    been provided (e.g., through which IoTresources) and the respective

    quality levels; and (iii) user preferences.

    Thus the iKaaS functionality will determine the optimal way to offer a service.

    For instance service components may need to be migrated as close as possible

    to the required (IoT) data sources. IoT services may need generic service

    support functionality that is offered within the cloud, and, at the same time,

    they do rely on local information (e.g., streams of data collected by sensors
    in

    a given geographic area), therefore, the migration of components close to the

    data sources will help in reduction of data trafﬁc.

    7.4 IoT Analytics in Health and Social Care

    7.4.1 Introduction

    Following a protracted start back in the early 2000, IoT is nowadays an

    undeniable force, which will dictate our (virtual) reality in years to come.

    According to ﬁgures by Cisco the global amount of mobile data will grow

    dramatically to an annual run rate up from 30 exabytes in 2014 to 249 exabytes

    by 2019 [10]. While a signiﬁcant share of this data, almost 79% will account

    for IP video streaming by 2018 it is reasonable to assume that by then 5–10%

    of the overall trafﬁc will be generated by smart devices, sensors, attenuators,

    embedded – and cyber-physical systems. Although these developments are

    currently driven in the ﬁrst instance by industrial domains such as automotive,

    retail and logistics there is evidence for massive utilization of IoT strategies

    in the health and social care domains in the near future.

    It has become increasingly clear that the way health and social care

    will be delivered in the future is undergoing substantive changes. These

    changes are driven by the demographic and socio-economic developments

    in our societies and also the technological and bio-medical progress. As a

    general trend the availability of smart IoT capable devices has dramatically

    240

    IoT Analytics: Collect, Process, Analyze, and Present Massive Amounts

    improved. Wearables are everywhere, from smart glucometers for blood-

    glucose measurement, insulin-pumps and highly complex brain-pacemakers

    for the treatment of Parkinson’s disease to the “iWatch” or similar products.

    Portability has increased since storage capacity of smart phones has reached

    hundreds of Gigabytes and the battery capacity is signiﬁcantly improved.

    Governments in Europe are now publically debating the utilization of IoT

    technology to control health and social care costs by enabling and empowering

    patients and their informal carers [11]. However, while the focus of IoT

    research has so far been placed on creating reference architectures and conduct

    design- and feasibility studies in order to interlink devices and capture and

    collect information the issues around analytics and the creation of value are

    now taking center stage [12].

    Even though the focus of this section is clearly on analytics and enabling

    architectural designs it is certainly important to underline that in sensitive

    areas (such as healthcare), the discussed technologies and their possibilities

    have to always be set into perspective with the relevant ethical and legal

    considerations [13]. For further information on this topic the interested reader

    may wish to consult the ethics, science and technology section at the European

    Political Strategy Centre [14].

    7.4.2 Architectural Approach to Data Analytics

    Essential to the health – and social care domains is the understanding that

    architecture should be scalable and able to cater for the analysis of big and

    small data whereby the topology is becoming more and more relevant [15,

    16]. Conventional cloud computing has long been regarded as the holy grail

    of big data analysis and is certainly a powerful method. The ability to share

    computing resources and balance the load according to the need of the task

    at hand makes cloud infrastructures clearly a formidable approach. Typical

    examples include the analysis of pre-existing large databases such as censuses

    or genetic information (genomics) databases.

    However, standard cloud approaches seem to struggle with some require-

    ments of the health and care domains, especially with regards to time critical

    processes.Although cloud approaches are powerful strategies, the bottle-neck

    seems to be the network and the relatively high latencies associated with it.

    Furthermore, there are continuous privacy and security concerns associated

    with public clouds for the use in health and care.

    The biggest challenge seems to be the fact that the predicted growth of

    network trafﬁc, especially mobile trafﬁc, will outperform the network capacity

    7.4 IoT Analytics in Health and Social Care

    241

    by 2019 [10].At the same time there is clear evidence for a signiﬁcant increase

    in sensors, attenuators, embedded and cyber-physical systems, which on the

    one hand clearly drives the utilization of IoT technology in e-Health but also

    drives the increase in data, which further widens the gap between trafﬁc

    demand and network capacity. This dilemma has caused a paradigm shift

    towards a distributed analytics approach, which might be the way forward in

    the health and care domains, which are set to generate very large amount of

    data with the potential to jam up existing infrastructures.

    While hybrid-cloud models were early manifestations of the attempt to

    solve the privacy problem in sensitive areas such as health and care, most

    recently this has been developed further into more sophisticated strategies

    involving mobile edge cloud computing and lately the so called “fogging”

    [16–18]. Fog computing in a way merges the beneﬁts of cloud computing and

    grid computing as it on the one hand integrates peripheral smart devices in

    one distributed approach while on the other hand allows for local problems

    to be solved locally. This has implications with regards to latency, privacy,

    precision, autonomy and liability [19, 20].

    While politicians and administrators still push for electronic patient ﬁles or

    electronic health records there is an urgent demand to clarify the terminology.

    As it is unlikely that a homogeneous data base system ideal for the assessment

    through classic cloud strategies can be achieved in most European countries

    in the foreseeable future hyper-distributed models where patients will be

    using their own smart devices to collect and manage their own data will

    become the norm. Fogging, supported through mobile edge clouds might be

    far superior to conventional clouds in such a scenario. New hyper-distributed

    architectures could also protect clinical infrastructures from being over-loaded

    with irrelevant information while it allows for patients and informal carers to

    be in full control of their information. It will also protect health care providers

    from the risk of loss or theft of information and reduce their exposure to

    litigation.

    7.4.3 IoT Data Analytics

    Big data analytics in healthcare is considered a transformational science,

    which has gained much attention in recent years. Doubtlessly, this can be

    attributed to unsustainable costs in healthcare, which calls for IT-assisted

    solutions. Growing adoption of patient-centred mobile digital health appli-

    cations, availability of advanced cloud and connectivity options, and the rise

    of the wearables allowing for continuous observation of health-related events

    242

    IoT Analytics: Collect, Process, Analyze, and Present Massive Amounts

    have already massively increased the amount of health-related information.

    Known as mobile or pervasive healthcare, remote collection of personal health

    and environmental data through sensor networks and mobile devices is well

    underway. This creates opportunity to track healthy behaviours, understand

    diseases at a granular level and provide true patient-centred care, and might

    fundamentally alter healthcare services as the industry moves to value-based

    models.

    In order to exploit and fully leverage this long-term potential in the context

    of healthcare, advanced big data analytics are needed to enable extraction

    of valuable and actionable insights and establish sustainable value chains

    [21, 22]. The use of analytics solutions in healthcare is being increasingly

    recognized for its value in delivering quality care and gaining competitive

    edge. Most importantly, tools are needed to cope with the 4Vs [23] of Big

    Data in healthcare (i.e. Volume, Velocity, Variety and Veracity) and to translate

    “noisy masses of data” into unambiguous, quality and meaningful insights

    that can be safely applied with conﬁdence to practice on both patients’ and

    experts’ sides. In turn, the healthcare analytics market is growing at a rapid

    pace, and there are several good practice examples of use resulting for example

    in lower hospital readmissions and shorter hospital stays, and successful mon-

    itoring and prevention of chronic diseases. According to MarketsAndMarkets

    [24], the healthcare analytics market is experiencing substantial growth at a

    Compound Annual Growth Rate (CAGR) of 25.2% and is expected to reach

    $21,346.4 Million in 2020. However, obviously the potential comes with a

    price – expectations are high and requirements are strict around security,

    privacy and protection of sensitive information and establishment of trust

    is necessary throughout the value chains. If not addressed appropriately, these

    might present the biggest barriers for adoption.

    In terms of research and science, Big Data is a well-developed ﬁeld when

    it comes to principles, algorithms, methods and tools for data collection,

    cleaning, description and interpretation. The presently established descrip-

    tive analytics in healthcare are giving way to predictive and prescriptive

    techniques to process volumes of heterogeneous messy data harvested from

    various sources and integrated across distributed infrastructures. Semantic

    science, machine learning and classiﬁcation mechanisms provide for powerful

    interpretation and translation techniques, for example to integrate and quantify

    sources with insights into patients’ personal point of view, such as Twitter or

    self-reportingmobileapps,andtranslatesubjectiveobservationsintoobjective

    medical terms. Other recognized techniques are also statistical analytics, fact

    clustering, and natural language processing. However, regardless of such

    7.4 IoT Analytics in Health and Social Care

    243

    advanced techniques, data analysis is frequently the application’s bottleneck,

    both due to insufﬁcient scalability of the underlying algorithms and due to the

    increasing volume and complexity of the source data, which is continuously

    challenging current approaches. This, in addition to data processing and

    interpretation science, opens also a whole new avenue of research related

    to capabilities, capacities and coping strategies when transmitting masses of

    healthcare data. In this respect, the rise of cloud computing has introduced

    dramatic shifts in how data is processed ﬂexibly, efﬁciently and in a scalable

    way over distributed architectures and shared resources. The cloud computing

    market for healthcare itself is expected to reach $5.4 billion by 2017, according

    toMarketsAndMarkets[25],whereastheconceptsofDataasaService(DaaS),

    Software as a Service (SaaS), Platform as a Service (PaaS) and Infrastructure

    as a Service (IaaS) are examples of already highly adopted cloud services for

    bioinformatics data processing. This drives further research in various areas,

    which is now looking for example into declarative approaches for expressing

    programs to achieve transparency and optimizations of large and heteroge-

    neous cloud clusters on a global scale. Another research direction focuses

    on new communication technologies, such as Software Deﬁned Networking

    (SDN) and Software Design Data Centres (SDDC) intended to support the

    massive increases in Internet bandwidth and complexities introduced by IoT,

    which extend beyond bandwidth requirements and device count, such as

    lower latency, greater determinism and processing closer to the edge of the

    network [26]. The latter, known as fog or edge computing, is a step fur-

    ther towards coping with bandwidth and latency constraints as well as to

    support scalable distributed big data analysis using context-aware localized

    computing.

    In essence, fog computing capitalizes on the proliferation of smart devices

    with increasingly powerful processing capacities and moves some of the

    transactions and resources from the centre of the cloud to its edge and inven-

    tively reuses processing capacities of existing devices rather than establishing

    channels for cloud storage and utilization [27]. This aggregates selected data

    at a certain access point and localizes selected processes, hereby reducing

    the need for large bandwidth capacities on the cloud channels, processing

    delays and enormous data management capacities at central locations, and

    ﬁnally leading to improved efﬁciency and reduced costs. This approach is

    highly promising for IoT in general and including healthcare, and seems to

    be particularly well-suited for applications for which cloud-based approaches

    might be either less suitable or less feasible, for example applications that

    are latency-sensitive, highly distributed in geographic terms or fast-operating

    244

    IoT Analytics: Collect, Process, Analyze, and Present Massive Amounts

    in near-real time, especially in Health 4.0 applications [16]. In addition, fog

    computing keeps the data at its source without sending it into global networks,

    which presents another crucial beneﬁts for healthcare, namely facilitating the

    software-to-data paradigm, which is recognized as the approach to be taken

    in healthcare to better cope with the security, privacy and data protection

    requirements as well as to reinsure the users about where their privacy-

    sensitive data is located [17]. Current approaches suggest the use of machine

    learning models to support the training process taking place on a fraction of

    data in the cloud, followed by localized and highly optimized data processing

    on a resource-constrained smart device, for example smartphone or embedded

    device, using techniques such as decision trees, fuzzy logic or deep belief

    network [28]. These new avenues of research, hand in hand with the rising

    5th generation of telecommunications networks (5G), represent promising

    advancements towards transformational patient-centred and quality-driven

    healthcare for the future.

    7.4.4 IoT Data Governance and Privacy Implications

    Along with increasing computerization tendencies towards “informated

    healthcare”, focus shifts on novel issues such as the governance of data

    ownership, data access control, accountability, security, and privacy. In a

    nutshell, challenges arise on questions such as who has access to the collected

    and stored data, how is it anonymised and/or de-personalized, and how non-

    repudiation of data exchange, possession and creation can be assured, which

    is a crucial prerequisite for the integrity and trust in the data at stake.

    Healthcare data is very speciﬁc data – unlike data which is collected for

    traditional purposes of e.g. commerce, transport, logistics, or control over

    manufacturing processes, healthcare data is a special kind of personal data,

    which is subject to detailed legal regulations, policies and jural decisions.

    Data used in the healthcare domain is often so-called personal data, which

    is a legal term denoting (1) any information, which is (2) relating to (3) an

    identiﬁed or identiﬁable (4) natural person. This legal concept is deliberately

    kept rather broad and lacks clear and direct applicability for information

    systems developers. There is a however a need to separately clarify whether

    or not a piece of data has to be considered personal data under the respective

    regulations. A good and substantiated overview on what constitutes personal

    data with regard to the EC Directive 95/46/EC (Data Protection Directive) and

    Directive 2002/58/EC (E-Privacy Directive) is provided by Opinion 4/2007 of

    the Data Protection Working Party [29], nevertheless, legal assistance might

    be advisable in order to determine how to treat data properly.

    7.4 IoT Analytics in Health and Social Care

    245

    Aside from the particularities emerging from legal data, system designers

    and developers must take into consideration that access to the thus collected

    and stored data might be requested by multiple heterogeneous stakeholders.

    The data subject, i.e. the person, who the data is about, is entitled to know

    which data is collected and to receive access to the collected data, to demand
    its

    rectiﬁcation, and in certain cases, its destruction. Aside from the data subject,

    access to the data in the healthcare domain can be requested by third parties

    for reasons of research, disease prevention/control, and for other purposes

    of governance bodies. Access to the collected personal data thus can be

    requested by a set of stakeholders with justiﬁed interest, which cannot be

    fully foreseen at design time of the information system. A further level of

    complexity is introduced, as the data subject is eligible to know with whom

    the data has been shared and who is in possession of its data, in order to

    demand deletion/rectiﬁcation of the data. The resulting constraints imply new

    demands to information system designers and developers, who need to take

    into account complex requirements, which might unforeseeably change in the

    future due to interventions by law [30].

    In order to accommodate for these constraints, new principles of data

    governance have been introduced in the past years, most importantly the

    concept of ﬁne grained access control (FGAC), and fair non-repudiable

    message exchange (FNR). FGAC refers to the ability of databases to govern

    access to core data based on access policies, which take into account the

    contents of the data query, the context of the request, and the identity of

    the requester. Unlike with traditional approaches, which categorize access

    permissions based on the pre-assigned role of the requester, FNR does not

    rely on roles, but rather on the complex context. Technologies for FNR have

    been described e.g., in [31] and [32] which focus on FNR technologies that

    utilize SQL query rewriting for governing access to the data. Standardization

    efforts have been conducted by OASIS, which provides the eXtensible

    Access Control Markup Language (XACML), while IBM introduced the

    Enterprise PrivacyAuthorization Language (EPAL). XACMLplays an impor-

    tant role also in the European Future Internet landscape, where a dedicated

    FIWARE Generic Enabler module aims to provide XACML to the IoT

    domain.

    Fair non-repudiation (FNR) reveals its utility when personal data between

    two entities must be exchanged in such way, that the exchange cannot be

    refuted by any of the participating parties. This way, a non-repudiable trace

    chain is coined, which then can be accessed by parties with a vested interest.

    A state-of-the-art summary on FNR has been provided in [33], where an

    246

    IoT Analytics: Collect, Process, Analyze, and Present Massive Amounts

    internet-based approach is described for the direct message exchange between

    two technical systems.

    Combining FGAC and FNR enables the creation of sustainable technology

    for the governance of data in domains of healthcare, public governance, or

    public education, i.e. in domains, where governance of access to personal data

    is subject to public domain policies and inﬂuenced by the legal domain.

    7.5 IoT Analytics for Public Safety

    7.5.1 Introduction

    Today Internet of Things (IoT) technologies are transforming our living space

    into intelligent Smart Environments (Smart City, Smart Home, Smart Building

    etc.). Smart Environments are equipped with a variety of sensors for capturing

    informationandanalysingdataina‘SmartWay’,extractingactionableinsights

    and adapting their behaviour to the needs of the users. With the number of

    connected IoT devices growing into the billions – e.g., Cisco forecasts 50

    billion devices connected by 2020 [39] – IoT analytics start to become more

    and more popular because only raw sensor data are not sufﬁcient to deliver the

    right QoS to the users. Only if we can give a meaning to IoT data and extract

    the relevant information on the right abstraction level, the Internet of Things

    vision can become reality.

    7.5.1.1 IoT analytics

    Under the constraints of IoT system and the requirements from IoT applica-

    tions, analytics are playing an important role in the information lifecycle of

    IoT. Ultimately, IoT analytics enables to ﬁnd the relevant piece of information

    in the ﬂood of IoT data, identifying the anomalies that require attention,

    extracting the unknown patterns and helping to predict what is going to happen

    next.

    IoT analytics need to deal with the IoT system characteristics where the

    data are highly heterogeneous, dimensional, and unstructured, coming from

    various data sources even in different business domains. This creates new

    challenges in the analytics area where problems like data distribution, data

    reliability, real-time data processing and many others need to be addressed.

    In addition to that, IoT applications are also expecting a certain quality in
    the

    provided data, ranging from insightful statistic results and meaningful patterns

    for making planning and optimization to real-time predictions and suggestions

    for making timely or even automated decisions.

    7.5 IoT Analytics for Public Safety

    247

    Smart cities are a good example of large-scale IoT systems where IoT

    analytics is highly demanded with great potential to make beneﬁts. For exam-

    ple, there are about 12,000 sensors deployed in the city of Santander [34] that

    provides information about environmental conditions, parking availability,

    trafﬁc density, weather and irrigation information. Therefore, in today’s Smart

    Cities, there is already a large quantity of information, but by applying more

    advanced IoT analytics, more relevant information can be extracted.

    7.5.1.2 IoT analytics for public safety

    In following paragraphs, we explain the challenges of IoT analytics using

    Public Safety as the application domain, which is one of the most important

    aspects of a Smart City. Based on the results delivered by advanced IoT data

    analytics, we cannot only make city planning and operation smarter, but we can

    also improve and ensure the safety of citizens [35]. As the sensors deployed

    in Smart Cities monitor the city pulse and report various situations all around

    our cities in an 24 × 7 basis, potential safety problems can be identiﬁed early

    and be localized better, therefore effective actions can be taken in time to

    improve the safety and well-being of the citizens. Many studies show that,

    even with cheap but widely deployed sensors, important safety issues can be

    identiﬁed early and swiftly addressed, e.g. the formation of a crowd of people,

    the breakout of a ﬁre [40], a burst pipe [41] or a blocked street.

    One of the challenges for IoT analytics to enable Public Safety is to be able

    to sense and react to critical situations and mine raw sensor data in real-time.

    This is mainly because the raw sensor data are very noisy, heterogeneous,

    and high dimensional, which introduce many complexity and computation

    difﬁcultiestoextracthighqualityresultsinreal-time.Toaddressthischallenge,

    the following technical problems have been taken into account in our IoT

    analytics solutions for Public Safety.

    • Establishing dynamic communication channels: in a typical IoTsystem

    like Smart Cities, IoT data ﬂow from sensors to various analytics

    applications and then actionable results are derived. Automated actions

    are requested from deployed actuators. The ﬁrst problem to be solved

    for IoT analytics is to establish communication channels among sensors,

    analytics applications, and actuators, in a dynamic, ﬂexible, and scalable

    way, so that information ﬂow between different components can be easily

    ensured.

    • Dealing with big data in real time: Real-time is a very important aspect

    regarding Public Safety, because critical situations need to be detected

    248

    IoT Analytics: Collect, Process, Analyze, and Present Massive Amounts

    immediately or to be predicted early enough. In this case, authorities

    will have enough time to take actions to avoid potential safety problems.

    For example, an algorithm of Crowd Detection must be fast enough

    to identify an emerging crowd situation and then trigger an alarm to

    inform authorities. To reduce the latency from generating raw data to

    taking actions, the following issues must be considered by IoT analytics:

    1) how to control the frequency of data generation; 2) where to do data

    pre-processing; 3) how to design algorithms for parallelized real-time

    data stream processing; 4) how to orchestrate resources in the cloud and

    at the edge to do scalable data processing.

    • Achieving actionable insights with good accuracy: results derived from

    IoT data must be actionable, meaning that the results are understandable,

    accurate and timely enough to allow authorities to make effective actions.

    If the results of Crowd Detection come one hour after the crowd event

    happens or most of the detected crowds are false positive, this type

    of analytics is not usable for enhancing the Public Safety. Therefore,

    efﬁcient and advanced machine learning or prediction algorithms must

    be used by IoT analytics to provide real-time feedback to the authorities.

    • Preserving user privacy: as data are collected from different sources,

    one obvious issue is the user privacy. Privacy protection and governance

    must be seriously taken into account from the start. This will affect the

    choice of our solutions.

    Of course, data and system security is another technical issue for IoT analytics,

    but it is not regarded as a key focuses of this paper. In the remainder of this

    paper,twospeciﬁcsolutionsareintroducedtoexplainhowweimprovedPublic

    Safety via IoT analytics for outdoor and indoor use cases.

    7.5.2 Crowd Detection Solution for a Safer City

    Efﬁcient emergency systems require a number of different technologies to

    monitor and detect dangerous events in real-time. Several problems arise in

    the design, implementation and development of such systems. One of the main

    problems that affect such systems is human behaviour in critical situations.

    Being able to detect dangerous situations and act in real-time is a need for

    enhancing people’s safety but is not an easy task due to the variety of the

    human behaviours. In this case, IoT analytics can help to fuse and mine sensor

    data from various installations to produce actionable insights. One example of

    IoT analytics’ solution is the privacy preserving Crowd Detection component

    from NEC.

    7.5 IoT Analytics for Public Safety

    249

    Concretely, the Crowd Detection core functionality is on understand-

    ing the dynamics of crowd. This requires in-depth understanding of how

    humans move in an indoor space over time. Most state of the art approaches

    are using video based crowd analysis. They face deployability issues on

    account of privacy regulations and the public’s perception of surveillance.

    Our approach is based on privacy preserving sensors, guaranteeing that no

    collected information can be used to identify an individual.

    In addition to the citizens’safety, our crowd analysis can provide relevant

    information for the design of public spaces, e.g., making shopping malls more

    comfortable for customers, enhancing their safety, or coordinating evacuation

    plans based on the real-time crowd behaviour. The Crowd Detection solution

    can also be used for automated detection of anomalies and alarms and is a

    prerequisite for assisting people during crowd emergencies.

    7.5.2.1 The privacy preserving approach

    The goal of our Crowd Detection solution is to provide real-time estimation

    regarding the crowd density in the target area. We focused on a solution for

    estimating crowd of people in an indoor scenario, taking into account privacy

    related issues and deployment costs. Using the sensor fusion approach, we

    are able to estimate the crowd density by sampling the area with carefully

    positioned sensors in the indoor environment, which will be used to measure

    the human activities and correlate them to the density of the crowd present on

    the scene. In addition, using more traditional sensors such as sound, pressure
    or

    CO2 sensors, inexpensive and privacy preserving infrared proximity sensors

    is a core part of our approach.

    Our solution has the advantage that it estimates the crowd levels with low

    cost sensors and without infringing any individual’s privacy rights. In fact,

    as Chan et al. describe in [36], there are various Crowd Detection solutions

    based on computer vision on the market, however privacy is a well-known

    problem for computer vision technologies for two reasons: ﬁrst, the perception

    of compromised privacy is particularly strong for technologies which record

    the people’s actions; second, current vision-based monitoring is usually based

    on object tracking or image primitives, both of which imply the identiﬁcation

    of the individuals.

    The NEC Crowd Detection solution has been deployed and tested for a

    trial in a Singapore shopping mall, where our system has been running for

    a period of two months and proving the feasibility of such solution. During

    the trial 23 sensors were deployed using a similar sensor installation plan as

    described in Figure 7.7 for estimating the crowd levels.

    250

    IoT Analytics: Collect, Process, Analyze, and Present Massive Amounts

    Figure 7.7

    Example of sensor installation in a shopping mall.

    7.5.3 Mobile Operation Centres (MOC)

    The Crowd Detection solution shows how IoT can be used to enhance people

    safety for indoor environments. However, for big public events like the

    Football World Cup or the Olympics, IoT analytics is also required to preserve

    people safety. During such events, many agencies are collaborating to ensure

    the people safety. As more and more sensors are deployed in urban area

    by different city service departments like police, ﬁre department, homeland

    security etc., it is extremely important to share sensor information and derived

    situations across different agencies in order to improve the safety of such big

    events.

    Typically, a Central Control Centre is designed to deal with normal tasks

    but has limited amount of resource to handle big events. To overcome such a

    problem, the capabilities of the control centres can be enhanced by deploying

    mobile operation centres (MOC), which can be easily setup in a ﬁxed location.

    Traditionally, MOCs are equipped with voice communication and video cam-

    eras to capture critical situations. With the help of the IoT systems, we are
    able

    to capture more information about the real world using sensors that have been

    built into wearables devices, attached to the normal tools of a law enforcement

    ofﬁcers, or built into devices like cars, riot control barriers, entrance gates,

    etc. Still, human intelligence is needed to understand the situations and react

    to them even with the assistance of derived information from IoT analytics. In

    this context, ensuring dynamic information ﬂow between the physical world

    and different authorities is important for enhancing the people’s safety.

    NEC developed a Mobile Operational Centre (MOC) solution for inter-

    agency collaboration in a Smart City, which enables the dynamic data

    exchange of real-time sensor data streams between different agencies. The

    7.5 IoT Analytics for Public Safety

    251

    MOC is realized combining a dynamic and federated IoT system with an IoT

    discovery component [38], which is able to handle presence registration of

    resources with their locations, types etc., and an IoT broker [37], which is

    able to fetch data by querying/subscribing to the IoT discovery component

    and requesting data from the underlying data sources. In such system IoT

    analytics play a role of mining and visualizing the sensor data in real-time to

    be used within a dashboard shown in Figure 7.8.

    7.5.4 Conclusions and Outlook

    As sensors and actuators are becoming cheap and being widely deployed in

    modern cities like Santander in Spain and Chicago in US, the Internet of

    Things is now providing us great potential to improve our society in terms

    of safety, security, efﬁciency and equality by leveraging collected data. Our

    research goal in IoT analytics is turn collected data into actionable insights

    to improve and ensure Public Safety in various business domains. For Public

    Safety, the main challenge to be addressed is to sense critical situations and

    act on them in real-time. This paper introduced the major technical issues that

    we are trying to solve in the IoT analytics area, in terms of privacy-preserving,

    sensor data fusion, anomaly detection, and dynamic data exchange.

    Two concrete solutions have been presented in detail to explain how

    we improve Public Safety using IoT analytics techniques at different levels.

    Figure 7.8

    Mobile Operation Center Dashboard.

    252

    IoT Analytics: Collect, Process, Analyze, and Present Massive Amounts

    Regarding the Crowd Detection system, additional advantages compared to

    the existing solutions are: the approach is privacy preserving, the amount

    of sensors required scales better with the area to be monitored and the cost

    of the individual sensors and computing nodes is considerably lower than

    the hardware commonly used in the state-of-the art. In addition to that, our

    solution estimate crowd levels in real-time and this is also an advantage for

    trigger quick actions and preserve the people safety without compromise their

    privacy.

    The second is the Mobile Operational Centre solution, enabling dynamic

    data exchange of real-time sensor data streams between different agencies.

    This can be used by city authorities like police ofﬁces to quickly enable

    inter-agency collaboration. Both solutions have been deployed and tested in

    Singapore as part of the Safer City solution.

    As future work, we intend to complement the current approaches by

    addressing additional challenges in the IoT analytics for Public Safety. In the

    case of Crowd Detection, we are exploring how reinforcement learning can

    improve the current solution in real-time without losing in system performance

    or how to distinguish the crowd estimation from other type of emergency

    without a human interaction. In addition to that, we are extending the Crowd

    Detection solution to outdoor areas exploring new techniques like Bluetooth

    and Wi-Fi monitoring.

    7.6 Towards a Positive Approach in Dealing with Privacy

    in IoT Data Analytics

    7.6.1 Introduction

    Businesses are looking for guidance on how to deal with big data in a

    responsible/legal way as they see the opportunities offered by big data, big

    data generation, collection, and analytics. IoT is a major driver in this, as

    “connected things” will generated endless streams of data that will be captured

    and used.According to the European Data Protection Supervisor Peter Hustinx

    (December 2014): “If big data operators want to be successful, they should

    invest in good privacy and data protection, preferably at the design stages of

    their projects”.

    While we want to beneﬁt from the value that IoT and its data have to offer,

    the key outcome should be “trust” by citizens and consumers. This requires

    that privacy and data protection are taken into account in every step of the

    development cycle of IoT technologies and services.

    7.6 Towards a PositiveApproach in Dealing with Privacy in IoTDataAnalytics

    253

    7.6.2 IoT and Privacy

    It is clear: in terms of pervasiveness, IoT has already contributed to the

    emergence of a society in which almost everything is or can be moni-

    tored, well beyond the des criptions as used by George Orwell in his book

    “1984” [42]. The novel is set in Airstrip One (formerly known as Great

    Britain), a province of the super state Oceania in a world of perpetual war,

    omnipresent government surveillance, and public manipulation, dictated by a

    political system euphemistically named English Socialism (or Ingsoc in the

    government’s invented language, Newspeak) under the control of a privileged

    Inner Party elite that persecutes all individualism and independent thinking

    as “thought crime”. “Big Brother is watching you”, and trust in society and

    freedom is sketched as very low (Figure 7.9). This book had a great inﬂuence

    of the thinking of a generation that grew up after World War 2 and reﬂects

    some of the thinking that is fundamental in the discussions about privacy.

    Now: whereas the levels of monitoring are very high and well beyond the

    imagination of Orwell in terms of what technically is possible, in Europe

    trust in government and society has remained at a relatively high level.

    When Snowden revealed, starting in June 2013, some evidence reﬂecting the

    pervasiveness of monitoring through numerous global surveillance programs,

    many of them run by the NSA and the Five Eyes1 with the cooperation of

    Figure 7.9

    1984, a society in which you can trust nobody – and “Big brother” sees it all,
    and

    a reality of pervasive monitoring by security forces in 2013 [43].

    1“Five Eyes”, often abbreviated as “FVEY”, refer to an intelligence alliance comprising

    Australia, Canada, New Zealand, the United Kingdom, and the United States that
    was formed.

    These countries are bound by the multilateral Agreement, a treaty for joint cooperation
    in

    signals intelligence.

    254

    IoT Analytics: Collect, Process, Analyze, and Present Massive Amounts

    telecommunication companies and European governments, this resulted in

    widely expressed concern and even outrage by the general public, civil society

    and politicians.

    This led to a global discussion making clear that monitoring is a necessity,

    yet should not take place at all costs, and a balance is yet to be found. This

    results in a discussion that will continue to stretch over the decades to come.

    7.6.3 European Way Forward

    Within this setting, the discussion in Europe about privacy and data protection

    is ﬁnding its way, moving from a Directive on Data protection and privacy

    towards an anticipated General Data Protection Regulation. The reform aims

    to strengthen individual rights and tackle the challenges of globalisation and

    new technologies. It furthermore attempts to “simplify” compliance as the

    Regulation would become directly applicable law in all EU member states,

    whereas the Directive was implemented through national Privacy Acts in

    similar but not always identical ways.

    When the original Data Protection Directive was developed and agreed in

    1995, the Internet was by far not as important as today, and nobody had even

    mentioned the term “Internet of Things” yet. The current reform has been

    under way since 2011 and culminated in a Proposal to Council and Parliament

    by the European Commission on 25 January 2012.This proposal was approved

    by the European Parliament in March 2014, and, assuming that a compromise

    can be reached in the course of this year, is expected to come into force in 2017.

    It should be noted however that signiﬁcant differences still exist between the

    Commission, Council and Parliament, so that a consensus text in 2015 is not

    yet a certainty.

    7.6.4 Challenges Ahead

    Yet, when the Regulation was ﬁrst being discussed in 2011, “big data” was

    not yet a widely recognised issue. Today, we know that big data, and big

    data analytics, fundamentally challenge the concept of “personal data”. Big

    data analytics allows seemingly anonymous data to be linked together and

    correlated in order to allow individual persons to be identiﬁed. A recent

    Opinion from the Article 29 Working Party – Europe’s pre-eminent data

    protection body – recognises the value of IoT, but also the potential intrusions

    it can generate to privacy. In this Opinion, statements are made that alarmed

    businesses around the world, as what is suggested may put a lock on many

    current developments in the ﬁeld.

    7.6 Towards a PositiveApproach in Dealing with Privacy in IoTDataAnalytics

    255

    Legal uncertainty remains on many issues, even if it is clear that current

    law also applies to IoT applications used to collect or analyse personal data.

    Business are looking for guidance on this, as big data is a subject of interest

    to many, and companies around the world are looking into the opportunities

    offered by big data, big data generation, collection, and analytics.

    As already noted above, the European Data Protection Supervisor Peter

    Hustinx has stressed the importance of investment in solid privacy and

    data protection, and recognizes the role of “soft law” on this point. These

    investments can drive the innovation, development and deployment of IoT,

    and are a pre-condition for European (co-)sponsored research.

    7.6.5 Way Forward

    A way forward could include the habit/obligation of a Privacy Impact Assess-

    ment in the design stage of new IoT products and services, and conscious

    implementation of Privacy Enhancing Technologies and Methods from the

    outset when thinking of which (and how) data to collect, store, and share.

    This approach would ensure that new ideas are not hamstrung by regulation,

    but rather that a culture of privacy awareness and advance consideration

    is promoted: the impact of any new IoT solution on individuals should be

    considered prior to deployment, rather than as an issue that may require ﬁxing

    afterwards.

    We need IoTto deal with certain societal challenges.As IoTin combination

    with big data analytics brings a paradigm shift in ways that data can be related

    to people, it will take a number of years to come to a better understanding on

    how to deal with this.

    Legislation related to consumer protection, ranging from product safety,

    to product reliability, product information reliability and personal data pro-

    tection, tends to be static and oblivious to rapid technology shifts. We need
    to

    ensurethattheapplicationofthelawreﬂectsanunderstandingofthesensitivity

    of data in a big data and big data analytics context.

    From an innovation and deployment perspective, it will be important to

    design products and services in such a way that they can continue to serve

    (local?) society even if values and choices are different in different markets,

    and/or change over time.

    This requires transparency (what data are collected, in what way, how are

    they stored and unlocked, and who has access to it), accountability (if someone

    isnotusingthedatainacorrect,authorizedway–whoisaccountablefortaking

    action), and choice (can I adapt the settings related to IoTin my environment
    to

    256

    IoT Analytics: Collect, Process, Analyze, and Present Massive Amounts

    my speciﬁc legal and cultural preferences?).This goes beyond mere regulatory

    actions, and requires greater awareness of where sensitive issues may emerge,

    and the implementation of robust and ﬂexible technological solutions that can

    be tailored to reﬂect these changes in society.

    7.6.6 Conclusions and Outlook

    It is highly important to ensure that our European privacy approach does not

    prevent the use of data, but rather that it prevents abuse of data – simply

    because:

    • Increasingly almost all data will be relatable to persons, from the outset,

    and we need to ﬁnd a way to deal with that responsibly;

    • We cannot afford not using data at large scale, both from societal

    perspective, and as there is clear commercial (thus economic) value;

    If Europe wants to beneﬁt from the emerging opportunities arising with

    IoT – and it is the opinion of the authors that this is a boat Europe cannot

    afford to miss – we will need to use data in a responsible way (both collecting,

    storage and sharing – and actively ﬁght abuse).

    “Going ethical” when building IoT products and services can bring us new

    growth and innovation and helps us to create a world we want our children

    to live in, respecting European values, including privacy but also and perhaps

    more importantly transparency and choice. The law cannot do it all for us. It
    is

    our own standards and ethics that will transform the world. Hence, legislation

    enabling, supporting and promoting these priorities is required.

    Ethicalbehaviorisaculturalthing:itneedstobeembraced,lived,inevery

    aspect of the business. It needs to be talked about and to be an explicit value.

    Ethics is a living thing and can only thrive when welcomed and constantly

    encouraged.

    Acknowledgment

    Part of the work described in Section 7.3 Cloud-Based IoT Big Data Plat-

    form has been carried out in the scope of the Horizon 2020 iKaaS project

    (iKaaS.com) (Grant Agreement number 643262).

    Bibliography

    [1] P. Barnaghi, A. Sheth, and C. Henson. “From Data to Actionable

    Knowledge: Big Data Challenges in the Web of Things”, IEEE Intelli-

    gent Systems, vol. 28, no. 6, pp. 6–11, Nov/Dec. 2013.

    Bibliography

    257

    [2] J. Gama, I. Zliobaite,A. Bifet, M. Pechenizkiy,A. Bouchachia. “Asurvey

    on concept drift adaptation”, ACM Computer Surveys 46, 4, article 44,

    2014.

    [3] P. Barnaghi et al. I. Borthwick. (editor), “Digital Technology Adoption

    in the Smart Built Environment”, IET Sector Technical Brieﬁng, The

    Institution of Engineering and Technology (IET),Technical report, March

    2015.

    [4] H. Karl and A. Willig. “Protocols and Architectures for Wireless Sensor

    Networks”, Wiley-Blackwell, 2007.

    [5] S. Nastic, S. Sehic, H. L. Truong, S. Dustdar. “Provisioning Software-

    deﬁned IoT Cloud Systems”, The 2nd Int. Conf. on Future Internet of

    Things and Cloud (FiCloud-2014), 2014.

    [6] M. Compton et al, “The SSN ontology of the W3C semantic sensor

    network incubator group”, Web Semantics: Science, Services and Agents

    on the World Wide Web, vol. 17, pp. 25–32, 2012.

    [7] J. Lin, E. Keogh, S. Lonardi. et al., “A Symbolic Representation of Time

    Series, with Implications for Streaming Algorithms”, Proceedings of the

    8th ACM SIGMOD workshop on Research issues in data mining and

    knowledge, 2003, pp. 2–11.

    [8] Y. Bengio,A. Courville, P. Vincent. “Representation Learning:AReview

    and New Perspectives”, IEEE Trans. PAMI, special issue Learning Deep

    Architectures, 2013.

    [9] P. Barnaghi, A. Sheth, A. Singh, M. Hauswirth. “Physical-Cyber-

    Social Computing: Looking Back, Looking Forward”, Guest Editors

    Introduction, IEEE Internet Computing, May/June, 2015.

    [10] Cisco, “Cisco Visual Networking Index: Global Mobile Data Trafﬁc

    ForecastUpdate2014–2019WhitePaper,”03-Feb-2015. [Online].Avail-

    able:http://www.cisco.com/c/en/us/solutions/collateral/service-provider

    /visual-networking-index-vni/white paper c11-520862.html.[Accessed:

    23-May-2015].

    [11] HM Government, “Personalised health and care 2020: a framework

    foraction,”13-Nov-2014.[Online].Available:https://www.gov.uk/gover

    nment/publications/personalised-health-and-care-2020/using-data-and-t

    echnology-to-transform-outcomes-for-patients-and-citizens. [Accessed:

    23-May-2015].

    [12] A. Bassi, M. Bauer, M. Fiedler, T. Kramp, R. van Kranenburg, S. Lange,

    and S. Meissner, Eds., Enabling things to talk: designing IoT solutions

    with the IoT architectural reference model; [Iot-A, Internet of things –

    architecture]. Heidelberg: Springer, 2013.

    258

    IoT Analytics: Collect, Process, Analyze, and Present Massive Amounts

    [13] H. R. Schindler, J. Cave, N. Robinson, V. Horvath, P. Hackett, S.

    Gunashekar, M. Botterman, S. Forge, and H. Graux, Europe’s policy

    options for a dynamic and trustworthy development of the Internet of

    Things: SMART 2012/0053. Santa Monica, CA: RAND Corporation,

    2013.

    [14] EC: European Political Strategy Centre, “Ethics, science and technol-

    ogy,” 25-Mar-2015. [Online]. Available: http://ec.europa.eu/epsc/ege en

    .htm. [Accessed: 23-May-2015].

    [15] E. Niehaus, M. Herselman, and A. N. Babu, “Principles of Neuroempiri-

    cism and generalization of network topology for health service delivery,”

    Indian J. Med. Inform., vol. 4, no. 1, 2009.

    [16] O. Ferrer-Roca, R. Tous, and R. Milito, “Big and Small Data: The Fog,”

    2014, pp. 260–261.

    [17] C. Thuemmler, J. Mueller, S. Covaci, T. Magedanz, S. de Panﬁlis, T.

    Jell, and A. Gavras, “Applying the Software-to-Data Paradigm in Next

    Generation E-Health Hybrid Clouds,” in Proceedings of the 2013 10th

    International Conference on Information Technology: New Generations,

    Washington, DC, USA, 2013, pp. 459–463.

    [18] S. Nunna, A. Kousarida, M. Ibrahim, M. Dillinger, C. Thuemmler,

    H. Feussner, and A. Schneider, “Enabling Real-Time Context-Aware

    Collaboration through 5G and Mobile Edge Computing,” in Proceedings

    of Information Technology New Generations 2015, 2015.

    [19] R. Vargheese and H. Dahir, “An IoT/IoE enabled architecture frame-

    work for precision on shelf availability: Enhancing proactive shopper

    experience,” 2014, pp. 21–26.

    [20] N. Khan, “Fog Computing: Better Solutions for IT,” Int. J. Eng. Tech.

    Res., vol. 3, no. 2, Feb. 2015.

    [21] R. Bond, “Big Data and Healthcare,” Charles Russell Speachlys.

    [Online].Available: http://www.charlesrussellspeechlys.com/updates/pu

    blications/commercial-new/big-data-and-healthcare/?UTM SOURCE=

    MONDAQ&UTM MEDIUM=SYNDICATION&UTM CAMPAIGN=

    VIEW-ORIGINAL. [Accessed: 23-May-2015].

    [22] Deloitte, “Big data revolution: six trends unlocking the power of health

    care analytics,” A view from the Center, 10-Feb-2014. [Online]. Avail-

    able: http://blogs.deloitte.com/centerforhealthsolutions/2014/02/big-dat

    a-revolution-six-trends-unlocking-the-power-of-health-care-analytics.ht

    ml#.VWB75HuJgb4. [Accessed: 23-May-2015].

    Bibliography

    259

    [23] C. Tan, L. Sun, and K. Liu, “Big Data Architecture for Pervasive Health-

    care: A Literature Review,” presented at the 23rd European Conference

    on Information Systems, Muenster, 2015.

    [24] MarketsAndMarkets, “Healthcare Mobility Solutions Market by Prod-

    ucts & Services (Mobile Devices, Mobile Apps, Enterprise Plat-

    forms),Application (Patient Care, Operations, Workforce Management),

    End Users (Payers, Providers, Patients) – Global Forecast to 2020,”

    May 2015.

    [25] MarketsAndMarkets, “Global Healthcare Cloud Computing Market

    worth $5.4 Billion by 2017.” [Online].Available: http://www.marketsand

    markets.com/PressReleases/cloud-computing-healthcare.asp

    [26] F. Fernandez and G. C. Pallis. “Opportunities and challenges of the

    Internet of Things for healthcare: Systems engineering perspective,”

    in Wireless Mobile Communication and Healthcare (Mobihealth), 2014

    EAI 4th International Conference on, 2014, pp. 263–266.

    [27] A. Banafa, “Fog Computing: From the Center to the Edge of the Cloud,”

    New Trends in Hi Tech, 22-Aug-2014.

    [28] M. Ectors, “Fog Computing Might Save Operators From an IoT Data

    Tsunami,” DZone: Smart Content for Tech Professionals, 07-Feb-2014.

    [29] Data Protection Working Party, “Opinion 4/2007 on the concept of

    personal data.” 20-Jun-2007.

    [30] A. Paulin. “Towards Self-Service Government – A Study on the Com-

    putability of Legal Eligibilities,” J. Univers. Comput. Sci., vol. 19,

    no. 12, pp. 1761–1791, Jun. 2013.

    [31] E. Bertino, G. Ghinita, and A. Kamra. Access control for databases

    concepts and systems. Boston: Now, 2011.

    [32] A. Paulin, “Towards the Foundation for Read-Write Governance of

    Civilizations,” in Third International Conference on Software, Services

    and Semantic Technologies S3T 2011, vol. 101, D. Dicheva, Z. Markov,

    and E. Stefanova, Eds. Berlin, Heidelberg: Springer, 2011, pp. 95–102.

    [33] A. Paulin and T. Welzer. “A Universal System for Fair Non-Repudiable

    Certiﬁed e-Mail without a Trusted Third Party,” Comput. Secur., 2013.

    [34] L. Sanchez, R. Ramdhany, A. Gluhak, S. Krco, E. Theodoridis, D.

    Pﬁsterer, L. Mu˜noz; J. A. Galache, P. Sotres, J. R. Santana, V. Gutierrez.

    SmartSantander: IoT Experimentation over a Smart City Testbed.

    [35] NEC public safety whitepaper [Online]: http://www.nec.com/en/global/

    solutions/safety/pdf/Safer Cities WP.pdf

    260

    IoT Analytics: Collect, Process, Analyze, and Present Massive Amounts

    [36] Chan,AntoniB.,Z-SJLiang,andNunoVasconcelos.“Privacypreserving

    crowd monitoring: Counting people without people models or tracking.”

    IEEE Conference on Computer Vision and Pattern Recognition (CVPR),

    2008.

    [37] NEC IoT Broker component [Online]: https://github.com/Aeronbroker/

    Aeron

    [38] M. Bauer and S. Longo. “Geographic Service Discovery for the Internet

    of Things.” Ubiquitous Computing and Ambient Intelligence. Person-

    alisation and User Adapted Services. Springer International Publishing,

    2014. 424–431.

    [39] Cisco IoT Forecast [Online]: http://share.cisco.com/internet-ofthings

    .html

    [40] H. Soliman, K. Sudan, A. Mishra. A smart forest-ﬁre early detection

    sensory system: Another approach of utilizing wireless sensor and neural

    networks, IEEE Sensors, vol., no., pp. 1900, 1904, 1–4 Nov. 2010.

    [41] NEC water leak detection service [Online]: http://www.nec.com/en/

    global]/solutions/waterloss-management/

    [42] G. Orwell. Nineteen Eighty-Four. A novel. London: Secker & Warburg,

    1949.

    [43] G. Farvell., http://www.csmonitor.com/Commentary/Monitor-Political-

    Cartoons, retrieved 10 Jan. 2015.

    '
  inline_citation: null
  journal: River Publishers eBooks
  limitations: null
  pdf_link: https://api.taylorfrancis.com/content/chapters/oa-edit/download?identifierName=doi&identifierValue=10.1201/9781003337454-7&type=chapterpdf
  publication_year: 2022
  relevance_score: 0.9285714285714286
  relevance_score1: 0
  relevance_score2: 0
  title: 'IoT Analytics: Collect, Process, Analyze, and Present Massive Amounts of
    Operational Data – Research and Innovation Challenges'
  verbatim_quote1: In contrast to many Web and database systems, data analytics methods
    depend on the context of the data production source and network and device parameters.
  verbatim_quote2: An IoT BigData Analytics Platform is a real-time online platform
    that dynamically manages IoT data/objects but it also provides connectivity to
    the diverse heterogeneous objects, considering the interoperability issues.
  verbatim_quote3: '>'
